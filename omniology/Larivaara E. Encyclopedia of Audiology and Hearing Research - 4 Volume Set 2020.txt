

AUDIOLOGY AND HEARING RESEARCH ADVANCES 
 
 
 
 
 
 
 
 
 
ENCYCLOPEDIA OF AUDIOLOGY  
AND HEARING RESEARCH 
 
(4 VOLUME SET) 
 
No part of this digital document may be reproduced, stored in a retrieval system or transmitted in any form or
by any means. The publisher has taken reasonable care in the preparation of this digital document, but makes no
expressed or implied warranty of any kind and assumes no responsibility for any errors or omissions. No
liability is assumed for incidental or consequential damages in connection with or arising out of information
contained herein. This digital document is sold with the clear understanding that the publisher is not engaged in
rendering legal, medical or any other professional services. 

AUDIOLOGY AND HEARING  
RESEARCH ADVANCES 
 
 
Additional books and e-books in this series can be found on Nova’s website  
under the Series tab. 
 
 
 

AUDIOLOGY AND HEARING RESEARCH ADVANCES 
 
 
 
 
 
 
 
 
ENCYCLOPEDIA OF AUDIOLOGY  
AND HEARING RESEARCH 
 
(4 VOLUME SET) 
 
 
 
 
 
ERNO LARIVAARA 
AND 
SENJA KORHOLA 
EDITORS 
 
 
 
 
 
 
 
 

Copyright © 2020 by Nova Science Publishers, Inc. 
 
 
All rights reserved. No part of this book may be reproduced, stored in a retrieval system or 
transmitted in any form or by any means: electronic, electrostatic, magnetic, tape, mechanical 
photocopying, recording or otherwise without the written permission of the Publisher. 
 
We have partnered with Copyright Clearance Center to make it easy for you to obtain permissions 
to reuse content from this publication. Simply navigate to this publication’s page on Nova’s 
website and locate the “Get Permission” button below the title description. This button is linked 
directly to the title’s permission page on copyright.com. Alternatively, you can visit 
copyright.com and search by title, ISBN, or ISSN.  
  
For further questions about using the service on copyright.com, please contact:  
Copyright Clearance Center 
Phone: +1-(978) 750-8400 Fax: +1-(978) 750-4470  
E-mail: info@copyright.com. 
 
NOTICE TO THE READER 
The Publisher has taken reasonable care in the preparation of this book, but makes no expressed or 
implied warranty of any kind and assumes no responsibility for any errors or omissions. No 
liability is assumed for incidental or consequential damages in connection with or arising out of 
information contained in this book. The Publisher shall not be liable for any special, 
consequential, or exemplary damages resulting, in whole or in part, from the readers’ use of, or 
reliance upon, this material. Any parts of this book based on government reports are so indicated 
and copyright is claimed for those parts to the extent applicable to compilations of such works. 
 
Independent verification should be sought for any data, advice or recommendations contained in 
this book. In addition, no responsibility is assumed by the Publisher for any injury and/or damage 
to persons or property arising from any methods, products, instructions, ideas or otherwise 
contained in this publication. 
 
This publication is designed to provide accurate and authoritative information with regard to the 
subject matter covered herein. It is sold with the clear understanding that the Publisher is not 
engaged in rendering legal or any other professional services. If legal or any other expert 
assistance is required, the services of a competent person should be sought. FROM A 
DECLARATION OF PARTICIPANTS JOINTLY ADOPTED BY A COMMITTEE OF THE 
AMERICAN BAR ASSOCIATION AND A COMMITTEE OF PUBLISHERS. 
 
Additional color graphics may be available in the e-book version of this book. 
 
Library of Congress Cataloging-in-Publication Data 
 
 
ISBN: 978-1-53617-702-2 
Library of Congress Control Number: 2020934580 
 
Published by Nova Science Publishers, Inc. † New York 

 
 
 
 
 
 
 
 
 
CONTENTS 
 
 
Preface 
 
xiii 
                                                                                      VOLUME 1 
 
Chapter 1 
Inner Ear Endothelial Dysfunction Due to Oxidative Stress:  
A Possible Role in the Pathogenesis of Sensorineural Hearing Loss 
1 
Andrea Ciorba, Laura Crema, Francesco Maldotti  
and Chiara Bianchini 
Chapter 2 
Hearing Screening for School Children 
7 
Carlie J. Driscoll, Bradley McPherson and Wayne J. Wilson 
Chapter 3 
Working with Learners with Hearing Loss in STEM 
39 
C. Jonah Eleweke 
Chapter 4 
Hearing and Cognitive Outcomes of Cochlear Implantation in  
the Elderly 
51 
L. Girasoli, A. Benatti, R. Bovo and A. Martini 
Chapter 5 
Effects of Impulse Noise on Hearing in Members of the  
Police Special Operations Battalion 
59 
Adriana Betes Heupa, Cláudia Giglio de Oliveira Gonçalves, 
Evelyn Joice Albizu and Adriana Bender Moreira de Lacerda 
Chapter 6 
Hearing Health and Stress for Military Police 
77 
Débora Lüders, Cláudia Giglio de Oliveira Gonçalves  
and Adriana Betes Heupa 
Chapter 7 
Effectiveness of Hearing Protection Devices (HPD) in  
Activities with Firearms 
83 
Cláudia Giglio de Oliveira Gonçalves, Adriana Betes Heupa  
and Heraldo Lorena Guida 
Chapter 8 
Hearing Impairment after Perinatal Asphyxia 
93 
Ze Dong Jiang 
 

Contents 
vi
Chapter 9 
“I will Make a Difference”; Using the 5As Model to Improve  
Issues for Adults with Learning Disabilities and Hearing Loss 
111 
Lynzee McShea 
Chapter 10 
Hearing Loss and Intellectual Disabilities 
145 
Siobhán Brennan and Sarah Bent 
Chapter 11 
Looking with Ears, Hearing with Eyes: Visual and  
Aural Interaction in Cervantes and Shakespeare 
167 
José Manuel González 
Chapter 12 
Universal Newborn Hearing Screening in the United States 
179 
Shibani Kanungo and Dilip R. Patel 
Chapter 13 
Hearing Loss in Neonatal Intensive Care Units (NICUs):  
Follow-Up Surveillance 
187 
Federico Sireci, Sergio Ferrara, Rosalia Gargano,  
Marianna Mucia, Fulvio Plescia, Serena Rizzo,  
Pietro Salvago and Francesco Martines 
Chapter 14 
Endothelial Dysfunction, Microvascular Disease and  
Sensorineural Hearing Loss 
195 
V. Corazzi, A. Ciorba, C. Bianchini and C. Aimoni 
Chapter 15 
Superoxide Dismutase and Sensorineural Hearing Loss 
203 
V. Corazzi, C. Bianchini, C. Aimoni and A. Ciorba 
Chapter 16 
Cardiovascular Risk Factors and Sensorineural Hearing Loss 
211 
V. Corazzi, C. Bianchini, C. Aimoni and A. Ciorba 
Chapter 17 
Audiology, Hearing Aids and Cochlear Implants 
221 
Deborah L. Carlson and Carol L. Ross 
Chapter 18 
Hearing Loss: Conductive and Sensorineural 
239 
Joshua M. Sappington 
Chapter 19 
Sign Acquisition and Development by Hearing Children with 
Autism Spectrum Disorders 
247 
John D. Bonvillian 
Chapter 20 
Hyperbaric Oxygen Therapy in Sudden Sensorineural Hearing Loss 
265 
Sema Zer Toros, Omer Cagatay Ertugay  
and Cigdem Kalaycik Ertugay 
Chapter 21 
Aminoglycoside Mediated Ototoxicity and Hearing Loss in 
Cystic Fibrosis Patients: An Unmet Medical Need 
271 
Rahul Mittal, Luca H. Debs and Kalai Mathee 
Chapter 22 
Low-Level Laser Therapy: Progress and Future Trends in  
Hearing Loss and Vestibular Dysfunction 
275 
Vikrant Rai 
 

Contents 
vii 
                                                                                    VOLUME 2 
 
Chapter 23 
Novel Deafness Genes and Mutations Identified by  
Next Generation Sequencing 
285 
Xue Gao 
Chapter 24 
The Molecular Pathogenesis of  
Dominant Deafness-Onychodystrophy (DDOD) Syndrome 
293 
Yongyi Yuan, Xi Lin and Pu Dai 
Chapter 25 
Association between Sensorineural Hearing Loss and  
Sleep-Disordered Breathing: Literature Review 
311 
Antonella Ballacchino, Rosalia Gargano and Francesco Martines 
Chapter 26 
Occupational Exposure to Ototoxic Chemicals 
319 
M. P. Gatto, R. C. Bonanni, G. Tranfo, E. Strafella, L. Santarelli 
and M. Gherardi 
Chapter 27 
Conduct Disorder in Children and Youth with Hearing Impairment 
341 
Fadilj Eminovic and Sanja Dimoski 
Chapter 28 
Sudden Sensorineural Hearing Loss and Polymorphisms in  
Iron Homeostasis Genes 
365 
D. Gemmati, A. Castiglione, M. Vigliano, A. Ciorba and C. Aimoni 
Chapter 29 
Chronic Tinnitus: Pith, Loudness, and Discomfort in Adults and 
Elderly Patients 
373 
Adriane Ribeiro Teixeira, Letícia Petersen Schmidt Rosito,  
Bruna Macagnin Seimetz, Celso Dall’Igna and  
Sady Selaimen da Costa 
Chapter 30 
Effect of Hearing Loss on Traffic Safety and Mobility 
385 
Birgitta Thorslund 
Chapter 31 
Genetics of Hearing Loss: Testing Methodologies and  
Counseling of Audiology Patients and Their Families 
439 
Danielle Donovan Mercer 
Chapter 32 
Audiological and Surgical Outcome after Cochlear Implant 
Revision Surgery 
489 
Mohamed Salah Elgandy, Marlan R. Hansen and Richard S. Tyler 
Chapter 33 
Posturology: The Scientific Investigation of Postural Disorders 
505 
Giuseppe Messina, Valerio Giustino, Francesco Dispenza, 
Francesco Galletti, Angelo Iovane, Serena Rizzo  
and Francesco Martines 
Chapter 34 
The Influence of Otovestibular System on Body Posture 
513 
Francesco Martines, Valerio Giustino, Francesco Dispenza, 
Francesco Galletti, Angelo Iovane, Serena Rizzo  
and Giuseppe Messina 

Contents 
viii
Chapter 35 
Auditory Brainstem Response and Frequency Following Response 
in Patients with Sickle Cell Disease 
521 
Adriana L. Silveira, Adriane R. Teixeira, Christina M. Bittar,  
João Ricardo Friedrisch, Daniela P. Dall’Igna  
and Sergio S. Menna Barreto 
Chapter 36 
The Relationship between Self-Reported Restriction in Social 
Participation, Self-Reported Satisfaction/Benefit and the Time  
of Use of Hearing Aids 
531 
João Paulo N. A. Santos, Nathany L. Ruschel,  
Camila Z. Neves and Adriane R. Teixeira 
                                                                                    VOLUME 3 
 
Chapter 37 
Telecommunications Relay Service: FCC Should Strengthen Its 
Management of Program to Assist Persons with Hearing or  
Speech Disabilities 
543 
United States Government Accountability Office 
Chapter 38 
Video Relay Service: Program Funding and Reform 
577 
Patricia Moloney Figliola 
Chapter 39 
Sensorineural Hearing Loss Secondary to Otitis Media 
587 
Henrique F. Pauna and Rafael C. Monsanto 
Chapter 40 
Sudden Sensorineural Hearing Loss:  
Pathophysiology, Diagnosis, Treatment Options,  
and Prognostic Factors 
599 
Rafael da Costa Monsanto, Ana Luiza Kasemodel, Luiza Mazzola, 
Marielle Albrechete and Fabio Tadeu Moura Lorenzetti 
Chapter 41 
Up-to-Date in Auditory Neuropathy Spectrum Disorder:  
Clinical, Diagnostic and Therapeutic Features 
615 
Henrique Furlan Pauna, Alexandre Caixeta Guimarães,  
Edi Lucia Sartorato and Guilherme Machado de Carvalho 
Chapter 42 
Genetic Kidney Diseases with Sensorineural Hearing Loss 
623 
Consolación Rosado Rubio and Alberto Domínguez Bravo 
Chapter 43 
Stepwise Approach to the Diagnosis of Hearing Loss in Children 
635 
C. Aimoni, V. Corazzi, V. Conz, C. Bianchini and A. Ciorba 
Chapter 44 
Hearing Loss After Traumatic Conditions:  
Histopathology and Clinical Features 
645 
Henrique Furlan Pauna, Raquel Andrade Lauria,  
Thiago Messias Zago, Alexandre Caixeta Guimarães  
and Guilherme Machado de Carvalho 
Chapter 45 
Idiopathic Sudden Sensorineural Hearing Loss and  
Cardiovascular Risk Factors 
655 
Andrea Ciorba and Chiara Bianchini 

Contents 
ix
Chapter 46 
Hearing Loss of Volga-Ural Region in Russia 
661 
Lilya U. Dzhemileva, Simeon L. Lobov, Dmitriy U. Kuznetzov,  
Alsu G. Nazirova, Elvira M. Nurgalina, Nikolay A. Barashkov, 
Sardana A. Fedorova and Elza K. Khusnutdinova 
Chapter 47 
Sudden Sensorineural Hearing Loss, an Invisible Male:  
State of the Art 
681 
Rizzo Serena, Daniela Bentivegna, Ewan Thomas,  
Eleonora La Mattina, Marianna Mucia, Pietro Salvago,  
Federico Sireci and Francesco Martines 
Chapter 48 
The Influence of Sounds in Postural Control 
691 
E. Thomas, A. Bianco, G. Messina, M. Mucia, S. Rizzo, P. Salvago, 
F. Sireci, A. Palma and F. Martines 
Chapter 49 
Chronic Otitis Media and Hearing Loss 
699 
Letícia S. Rosito, Mariana M. Smith, Daniela Marques,  
Marina Faistauer and Gustavo V. Severo 
Chapter 50 
Binaural, Sequential or Simultaneous Cochlear Implants in 
Children: A Review 
715 
C. Aimoni, V. Corazzi, N. Mazza, C. Bianchini, M. Rosignoli and  
A. Ciorba 
Chapter 51 
Virtual Reality for Cochlear Implant Surgery 
723 
Patorn Piromchai 
Chapter 52 
Cross-Modal Plasticity in Deaf Children with Visual-Impairment: 
Electrophysiological Results after Long-Term Use of  
Cochlear Implants 
739 
Lidia E. Charroó-Ruíz, Alfredo Álvarez Amador,  
Antonio S. Paz Cordovés, Sandra Bermejo Guerra,  
Yesy Martín García, Beatriz Bermejo Guerra,  
Beatriz Álvarez Rivero, Manuel Sevila Salas, José Antelo Cordovés, 
Eduardo Aubert Vázquez, Lourdes Díaz-Comas Martínez,  
Lídice Galán García, Fernando Rivero Martínez,  
Ana Calzada Reyes and Mario Estévez Báez 
                                                                                    VOLUME 4 
Chapter 53 
Anatomy and Physiology of the Peripheral and  
Central Auditory System 
755 
Fabio Bucchieri, Fabio Carletti, Sabrina David,  
Francesco Cappello, Giuseppe Ferraro and Pierangelo Sardo 
Chapter 54 
Genetics in Sensorineural Hearing Loss 
775 
Alessandro Castiglione 
 
 

Contents 
x
Chapter 55 
Congenital Sensorineural Hearing Loss 
785 
Sara Ghiselli, Bruno Galletti, Francesco Freni,  
Rocco Bruno and Francesco Galletti 
Chapter 56 
Neuroplasticity and Sensorineural Hearing Loss 
801 
Francesco Dispenza, Alessia Maria Battaglia, Gabriele Ebbreo, 
Alessia Ceraso, Vito Pontillo and Antonina Mistretta 
Chapter 57 
Neuroradiology of the Hearing System 
813 
Cesare Gagliardo, Silvia Piccinini and Paola Feraco 
Chapter 58 
Age-Related Hearing Loss 
883 
Rocco Bruno, Bruno Galletti, Pietro Abita, Giuseppe Impalà, 
Francesco Freni and Francesco Galletti 
Chapter 59 
Traumatic Sensorineural Hearing Loss 
901 
Michele Cassano, Valeria Tarantini, Eleonora M. C. Trecca, 
Antonio Moffa and Gianluigi Grilli 
Chapter 60 
Advanced Otosclerosis 
919 
Nicola Quaranta, Vito Pontillo and Francesco Dispenza 
Chapter 61 
Sudden Sensorineural Hearing Loss 
935 
Valerio Giustino, Francesco Lorusso, Serena Rizzo,  
Pietro Salvago and Francesco Martines 
Chapter 62 
Cause, Pathogenesis, Clinical Manifestations and  
Treatment of Meniere’s Disease and Endolymphatic Hydrops 
945 
Sergio Ferrara and Francesco Dispenza 
Chapter 63 
Autoimmune Inner Ear Disease 
959 
Francesco Dispenza, Alessia Ceraso, Antonina Mistretta,  
Gabriele Ebbreo, Francesco Barbara and Alessia Maria Battaglia 
Chapter 64 
Occupational Hearing Loss 
975 
Giampietro Ricci, Egisto Molini, Mario Faralli,  
Lucia Calzolaro and Luca D’Ascanio 
Chapter 65 
Single Side Deafness in Children 
989 
Antonio della Volpe, Arianna Di Stadio, Antonietta De Lucia, 
Valentina Ippolito and Vincenzo Pastore 
Chapter 66 
Pharmacological Treatment of Sensorineural Hearing Loss 
999 
Angela Cavallaro, Carla Cannizzaro, Francesco Martines, 
Gianluca Lavanco, Pietro Salvago, Fabiana Plescia,  
Anna Brancato and Fulvio Plescia 
Chapter 67 
Management of Sensorineural Hearing Loss with Hearing Aids 
1013 
Pasquale Marsella, Alessandro Scorpecci and Sara Giannantonio 
Chapter 68 
Cochlear Implant of SNHL Patients 
1025 
Pasquale Marsella, Sara Giannantonio and Alessandro Scorpecci 

Contents 
xi
Chapter 69 
Presbyastasis: From Diagnosis to Management 
1063 
Serena Rizzo, Valeria Sanfilippo, Pietro Terrana,  
Lorenza Lauricella, Dalila Scaturro, Francesco Martines  
and Giulia Letizia Mauro 
Index 
 
1073 


 
 
 
 
 
 
 
 
 
 
PREFACE 
 
 
This 4 volume set presents important research on audiology and hearing. Some of the 
topics discussed herein include: 
 
 
cochlear implantation 
 
chronic tinnitus 
 
the auditory brainstem response 
 
sensorineural hearing loss 
 
autoimmune inner ear disease 
 
presbyastasis 


 
 
 
 
 
 
 
 
 
 
 
VOLUME 1 
 
 


In: Encyclopedia of Audiology and Hearing Research 
ISBN: 978-1-53617-702-2 
Editors: Erno Larivaara and Senja Korhola 
© 2020 Nova Science Publishers, Inc. 
 
 
 
 
 
 
Chapter 1 
 
 
 
INNER EAR ENDOTHELIAL DYSFUNCTION DUE TO 
OXIDATIVE STRESS: A POSSIBLE ROLE IN THE 
PATHOGENESIS OF SENSORINEURAL HEARING LOSS 
 
 
Andrea Ciorba, Laura Crema,  
Francesco Maldotti and Chiara Bianchini 
ENT and Audiology Department, University Hospital of Ferrara, Ferrara, Italy 
 
 
ABSTRACT 
 
Over the past years, researchers have identified reactive oxygen species (ROS) as 
major factors mediating sensorineural hearing loss (SNHL). SNHL is caused by loss of 
cochlear hair cells or neurons and this damage is irreversible. SNHL is a common 
disorder as it is reported to affect millions of people, of any age, around the world; SNHL 
also has different presentations, from mild to profound, including low and high 
frequencies patterns.  
ROS can damage inner ear directly by injuring cellular DNA or indirectly by 
inducing apoptosis of the inner ear sensory cells (hair cells or spiral ganglion neurons). 
Recent observations also link oxidative stress to further damage in the inner ear by 
causing endothelial dysfunction in the cochlear microcirculation. Since the role of 
endothelial cells in microcirculation is crucial as they control and regulate the local blood 
flow (i.e., through the expression of several adhesion molecules), their injury can induce 
relevant damages to cochlear hair cells or spiral ganglion neurons. The cochlea, in fact, is 
particularly vulnerable to hypoxic or ischaemic damage as: (i) it is provided with a 
terminal capillary bed and it is not supplied by collateral vessels which could restore 
blood flow in ischaemic regions; (ii) cochlear hair cells have a high metabolic activity. 
Understanding the aethiopathogenetic mechanisms of SNHL is crucial also in order to 
indentify possible innovative therapeutic approaches. 
 
 
                                                        
 Corresponding Author’s Email: andrea.ciorba@unife.it. 

Andrea Ciorba, Laura Crema, Francesco Maldotti et al. 
2
INTRODUCTION 
 
Deafness is one of the most prevalent disabilities in our society, and there is a 
considerable social and economic demand for the development of new therapeutic approaches 
for hearing loss. Also, it is well known that the loss of hair cells within the human inner ear 
results in hearing disorders that significantly impair quality of life [1]. 
The mammalian cochlea is unable to replace lost hair cells (inner and outer) and this is 
the cause of an irreversible hearing impairment. Hair cell loss may results from several 
conditions such as aging, exposure to noise, infectious diseases and use of ototoxic drugs 
such as cisplatin and aminoglycosides [2, 3, 4]. Several studies show that oxidative stress can 
play a relevant role in the pathogenesis and development of inner ear diseases [2, 3, 4, 5]; 
oxidative stress can directly mediate metabolic cellular damages in the inner ear sensory cells, 
but it has recently been proposed that it may also cause further damage by inducing 
endothelial dysfunction in inner ear microcirculation [6, 7, 8]. 
Understanding the inner ear mechanisms of damage and, therefore, protecting the inner 
ear from irreversible degeneration represent a primary objective, since, up until now, there are 
no therapeutic options for sensorineural hearing loss except for hearing aids and cochlear 
implants [1]. 
 
 
ENDOTHELIAL DYSFUNCTION AND INNER EAR 
 
There is rising evidence that endothelium is at major risk of ROS-induced lesions and 
that this damage is most evident in microcirculation. A damage to endothelial cells, and in 
particular of those of the cochlear microcirculation, can be relevant as they actively 
participate to the control and the regulation of the microcirculation at several levels, such as 
a) mainteining blood in a fluid state; b) regulating the exchange of fluid and macromolecules 
between blood and tissues, at capillary level; c) regulating local blood flow and local 
immuno-surveillance [8, 9, 10-18].  
It has been reported that high concentrations of circulating ROS (especially hydrogen 
peroxide, H2O2) may induce apoptosis or sudden death of endothelial cells. In “in vitro” 
models of oxidative stress, it has been shown that high amounts of H2O2 can cause 
endothelial cells apoptosis or, at highest doses, sudden death of cultured endothelial cells [9, 
19]. 
The failure of endothelial cells to perform their activities, as it can results form 
endothelial cells apoptosis / death, can be therefore defined as endothelial dysfunction [8]. 
 
 
Experimental Data 
 
Only few experimental data about endothelial dysfunction and pathogenesis of inner ear 
disease, mostly guinea pigs and rats, are currently available. Guo et al. described inner ear 
histopathological changes possibly related to endothelial dysfunction [20]. They detected hair 
cell loss (mainly at the cochlear basal turn), thickening of vascular intima, and stenosis of the 
cochlear arteries of apolipoprotein E gene deficient mice, in which impairment of endothelial 

Inner Ear Endothelial Dysfunction Due to Oxidative Stress 
3
function is caused by increased production of superoxide radical (O2-) and reduced 
endothelial NO synthase activity [20]. In a guinea pig model, Selivanova et al. also reported a 
reduced expression of Vascular Endothelial Growth Factor, a mitogen for endothelial cells 
that specifically promotes angiogenesis and vascular permeability of endothelial cells, due to 
intense noise exposure (70 db SPL / 1 hour), in all cell types of the organ of Corti, including 
those of the stria vascularis [21]. Noise induced hearing loss has been associated with 
alterations in cochlear blood flow, and also Picciotti et al. suggest a role for VEGF in the 
regulation of the vascular network in guinea pigs inner ear after acoustic trauma and during 
auditory recovery [22]. 
Syka et al. also showed that mice treated with statins present larger amplitudes of 
distortion product otoacoustic emissions than non-treated control group, indicating a better 
survival/function of outer hair cells. The decreased expression of intercellular and vascular 
adhesion molecules in the aortic wall and the reduced endothelial inflammatory effects may 
therefore influence positively the inner ear blood supply [23]. 
In addition, Gloddlek et al., advanced the hypothesis that microvascular inner ear disease 
could be related to EC damages, as disrupted ECs promote the onset of a local vasculitis by 
secreting proinflammatory cytokines like IL-1, IL-6 or TNF-alpha in addition to expressing of 
adhesion molecules, in a guinea pig model [24]. Microvascular stenosis with consequent inner 
ear ischemic damages could result from the persistence of these immunopathological 
mechanisms, in experimental conditions [24]. 
 
 
Clinical Evidences 
 
In humans, ROS appeared to be involved in hair cell damage in some cases of hearing 
loss (i.e., Menière syndrome). Moreover, recent literature reports link endothelial dysfunction 
to some inner ear diseases such as sudden sensorineural hearing loss, tinnitus and presbycusis. 
Sudden Sensorineural Hearing Loss (SSNHL). Quaranta et al. and Haubner et al. 
investigated the role of endothelial dysfunction in the inner ear, indicating that as increased 
expression of circulating adhesion molecules (VCAM-1) in patients affected by sudden 
sensorineural hearing loss, could be linked to endothelial dysfunction and micro-vascular 
impairment in SSNHL [6, 7]. 
Tinnitus. Neri et al. observed that oxidative stress markers (such as malondialdehyde, 4-
hydroxynonenal, glutathione peroxidase, nitric oxide, L-ornitine, thrombomodulin and von 
Willebrand factor) are increased and nitric oxide production reduced in brain circulation 
reflux blood of patients with acute tinnitus. These oxidative stress conditions could be able to 
cause a general cerebro-vascular endothelial dysfunction, and therefore also a inner ear 
microcirculation dysfunction for the Authors [25]. 
Presbycusis. Studies of the aging cochlea showed a decrease of antioxidant defences such 
as glutathione level in the auditory nerve or antioxidant enzymes in the organ of Corti (hair 
cells) and spiral ganglion neurons. Significant loss of hair cells and spiral ganglion neurons, 
as well as a systematic degeneration of endothelial cells of the stria vascularis, has been 
experimentally observed in mice lacking superoxide dismutase [26-29]. 
Unilateral vestibular syndrome (AVS). Labyrinth microvascular abnormalities have been 
hypothesized in AVS patients. Speculating that skin microcirculation may mirror vascular 
function in other body districts, Rossi et al. have demonstrated that AVS patients present skin 

Andrea Ciorba, Laura Crema, Francesco Maldotti et al. 
4
endothelial dysfunction using endothelial-dependent vasodilator acetylcholine (ACh) and 
endothelial-independent vasodilator sodium nitroprusside (SNP), and this can be linked to a 
more probable ischemic origin of AVS [30]. 
 
 
CONCLUSION 
 
It is already well known that oxidative stress, due to an increase activity of reactive 
oxygen species (ROS) and consequent damage of intracellular biochemical processes, 
represents an important factor in the pathophysiology of several types of inner ear disease 
(i.e., sudden sensorineural hearing loss, acoustic trauma). However, recent evidence also 
suggests that, in some situations oxidative stress could cause further damage by inducing 
endothelial dysfunction within inner ear microcirculation. Unfortunately, so far, the 
involvement of endothelial dysfunction in the pathogenesis of inner ear disease is supported 
by few and weak evidences available on animal models, and clinical evidences are also 
inconsistent. Further studies will be then necessary in order to understand the possible 
pathophysiological mechanisms involved in endothelial dysfunction within inner ear 
microcirculation [8]. 
 
 
REFERENCES 
 
[1] 
Ciorba A, Astolfi L Martini A. Otoprotection and inner ear regeneration. Audiological 
Medicine, 2008, 6, 3, 170-175. 
[2] 
Kawamoto K, Sha SH, Minoda R, Izumikawa M, Kuriyama H, Schacht J, Raphael Y. 
Antioxidant gene therapy can protect hearing and hair cells from ototoxicity. Mol. Ther. 
2004; 9:173-181. 
[3] 
Bánfi B, Malgrange B, Knisz J, Steger K, Dubois-Dauphin M, Krause KH. NOX3, a 
superoxidegenerating NADPH oxidase of the inner ear. J. Biol. Chem. 2004; 29:46065-
46072. 
[4] 
Park SN, Back SA, Park KH, Kim DK, Park SY, Oh JH, Park YS, Yeo SW. 
Comparison of cochlear morphology and apoptosis in mouse models of presbycusis. 
Clin. Exp. Otorhinolaryngol. 2010; 3:126-135. 
[5] 
Ciorba A, Gasparini P, Chicca M, Pinamonti S, Martini A. Reactive oxygen species in 
human inner ear perilymph. Acta Otolaryngol. 2010; 130:240-246. 
[6] 
Quaranta N, Ramunni A, Brescia P, D'Elia A, Vacca A, Ria R. Soluble intercellular 
adhesion molecule 1 and soluble vascular cell adhesion molecule 1 in sudden hearing 
loss. Otol. Neurotol. 2008; 29:470-474. 
[7] 
Haubner F, Martin L, Steffens T, Strutz J, Kleinjung T. The role of soluble adhesion 
molecules and cytokines in sudden sensorineural hearing loss. Otolaryngol. Head Neck 
Surg. 2011; 144:575-580. 
[8] 
Ciorba A., Chicca M., Bianchini C., Aimoni C., Pastore A. Sensorineural hearing loss 
and endothelial dysfunction due to oxidative stress: Is there a connection? Int. Adv. 
Otol. 2012; 8:(1) 16-20. 

Inner Ear Endothelial Dysfunction Due to Oxidative Stress 
5
[9] 
Pober JS, Min W, Bradley JR. Mechanisms of endothelial dysfunction, injury, and 
death. Annu. Rev. Pathol. 2009; 4: 71-95. 
[10] Arnout J, Hoylaerts MF, Lijnen HR.. Haemostasis. Handb. Exp. Pharmacol. 2006; 
176:1–41. 
[11] Minshall RD, Malik AB. Transport across the endothelium: regulation of endothelial 
permeability. Handb. Exp. Pharmacol. 2006; 176: 107-144. 
[12] Bazzoni G, Dejana E.. Endothelial cell-to-cell junctions: molecular organization and 
role in vascular homeostasis. Physiol. Rev. 2004; 84: 869-901. 
[13] Busse R, Fleming I.. Vascular endothelium and blood flow. Handb. Exp. Pharmacol. 
2006; 176:43-78.  
[14] Sessa WC. eNOS at a glance. J. Cell Sci. 2004; 117:2427-2429. 
[15] Ley K, Reutershan J.. Leukocyte-endothelial interactions in health and disease. Handb. 
Exp. Pharmacol. 2006; 176:97-133.  
[16] Kuhlencordt PJ, Rosel E, Gerszten RE, Morales- Ruiz M, Dombkowski D, Atkinson 
WJ, Han F, Preffer F, Rosenzweig A, Sessa WC, Gimbrone MA Jr, Ertl G, Huang PL. 
Role of endothelial nitric oxide synthase in endothelial activation: insights from eNOS 
knockout endothelial cells. Am. J. Physiol. Cell Physiol. 2004; 286:1195-202. 
[17] Choi J, Enis DR, Koh KP, Shiao SL, Pober JS. T lymphocyte–endothelial cell 
interactions. Annu. Rev. Immunol. 2004; 22: 683-709. 
[18] Shiao SL, McNiff JM, Pober JS.. Memory T cells and their costimulators in human 
allograft injury. J. Immunol. 2005; 175: 4886-4896. 
[19] Bradley JR, Johnson DR, Pober JS.. Endothelial activation by hydrogen peroxide. 
Selective increases of intercellular adhesion molecule 1 and major histocompatibility 
complex class I. Am. J. Pathol. 1993; 142:1598-1609. 
[20] Guo Y, Zhang C, Du X, Nair U, Yoo TJ. Morphological and functional alterations of 
the cochlea in apolipoprotein E gene deficient mice. Hear. Res., 2005; 208:54-67. 
[21] Selivanova O, Heinrich UR, Brieger J, Feltens R, Mann W. Fast alterations of vascular 
endothelial growth factor (VEGF) expression and that of its receptors (Flt-1, Flk-1 and 
Neuropilin) in the cochlea of guinea pigs after moderate noise exposure. Eur. Arch. 
Otorhinolaryngol. 2007; 264:121-128. 
[22] Picciotti PM, Fetoni AR, Paludetti G, Wolf FI, Torsello A, Troiani D, Ferraresi A, Pola 
R, Sergi B. Vascular endothelial growth factor (VEGF) expression in noise-induced 
hearing loss. Hear. Res. 2006 Apr;214(1-2):76-83.  
[23] Syka J1, Ouda L, Nachtigal P, Solichová D, Semecký V. Atorvastatin slows down the 
deterioration of inner ear function with age in mice. Neurosci. Lett. 2007 Jan 
10;411(2):112-6. 
[24] Gloddek B, Lamm K, Arnold W. Pharmacological influence on inner ear endothelial 
cells in relation to the pathogenesis of sensorineural hearing loss. Adv. 
Otorhinolaryngol. 2002; 59:75-83. 
[25] Neri S, Signorelli S, Pulvirenti D, Mauceri B, Cilio D, Bordonaro F, Abate G, Interlandi 
D, Misseri M, Ignaccolo L, Savastano M, Azzolina R, Grillo C, Messina A, Serra A, 
Tsami A. Oxidative stress, nitric oxide, endothelial dysfunction and tinnitus. Free 
Radic. Res. 2006; 40:615-618. 
[26] Henderson D, Bielefeld EC, Harris KC, Hu BH. The role of oxidative stress in noise-
induced hearing loss. Ear Hear. 2006 Feb; 27:1-19. 

Andrea Ciorba, Laura Crema, Francesco Maldotti et al. 
6
[27] Lautermann, J, Crann, SA, McLaren J, Schacht J. Glutathione dependent antioxidant 
systems in the mammalian inner ear: Effects of aging, ototoxic drugs and noise. Hear. 
Res., 1997, 114, 75-82. 
[28] Jiang, H, Talaska A.E., Schacht J, Sha S.H.. Oxidative imbalance in the aging inner ear. 
Neurobiol. Aging, 2007, 28, 1605-1612. 
[29] McFadden SL, Ding D, Salvi R. Anatomical, metabolic and genetic aspects of age-
related hearing loss in mice. Audiology, 2001, 40, 313-321. 
[30] Rossi M, Casani AP, Pesce M, Cerchiai N, Santoro G, Franceschini SS. Assessment of 
skin microvascular endothelial function in patients with acute unilateral vestibular 
syndrome. Clin. Hemorheol. Microcirc. 2013; 53(4):327-35. 
 

In: Encyclopedia of Audiology and Hearing Research 
ISBN: 978-1-53617-702-2 
Editors: Erno Larivaara and Senja Korhola 
© 2020 Nova Science Publishers, Inc. 
 
 
 
 
 
 
Chapter 2 
 
 
 
HEARING SCREENING FOR SCHOOL CHILDREN 
 
 
Carlie J. Driscoll1,, Bradley McPherson2 and Wayne J. Wilson1 
1University of Queensland, Brisbane, QLD, Australia 
2University of Hong Kong, Pokfulam, Hong Kong 
 
 
ABSTRACT 
 
Hearing screening is an integral component in virtually all school health screening 
programs. It has long been recognized that hearing loss will have negative consequences 
on children’s communication abilities and educational performance unless early 
identification and management is arranged. School-based screening allows for the 
detection of children with hearing loss who have not been identified at an earlier stage 
(for example, in a newborn hearing screening program) and for children who have 
developed hearing loss after early childhood (for example, children with a progressive, 
inherited hearing disorder). This chapter provides an overview of pure-tone audiometry, 
the standard method for hearing screening in school children, and details the main 
established guidelines for screen protocols. Other hearing and ear health methods have 
also been considered for school-based programs, such as tympanometry, otoacoustic 
emission recording, and teacher/parent questionnaires. These procedures are discussed 
and their advantages and limitations outlined. Conventional hearing screening programs 
are not effective in detecting children with high tone, noise-induced hearing loss or 
children with auditory processing difficulties. Potential alternative screening protocols to 
identify children with such problems are presented. Advances in technology may alter the 
practice of hearing screening in the future. For example, telehealth-based screening may 
serve a useful role in future programs and genetic screening for hearing disorders may 
enhance the early detection of some cases of hearing loss. 
 
 
DEVELOPMENT OF SCHOOL HEARING SCREENING 
 
Children with sensory disorders have been of particular concern to school health 
screening services from their foundation. 
                                                        
 Corresponding Author’s Email: carlie.driscoll@uq.edu.au. 

Carlie J. Driscoll, Bradley McPherson and Wayne J. Wilson 
8
Permanent childhood hearing loss may have a serious long-term impact on the 
communication abilities, educational achievement, socioeconomic status, and overall quality 
of life of an individual, as well as generating major financial costs for the community as a 
whole (Access Economics, 2006). School health services recognized that the early identifi-
cation and management of hearing loss could mitigate the associated level of disability. 
Henderson (1975, p. 15) cites the Chief Medical Officer’s 1908 report to the British Board of 
Education which stated that: “It is not usually practical during the routine examination of 
large numbers of children to test accurately the exact condition of the hearing capacity of a 
child … [but] it is important that a careful examination should be made of all children in 
whom there is any reason to suspect defective hearing.” By 1911, the Chief Medical Officer 
had revised this guidance and considered a hearing test should be given to “every child who is 
old enough to respond.” A whispered voice test for school children was introduced in the 
United Kingdom in the 1920s, although its inadequacies were acknowledged (Henderson, 
1975) and more scientific methods of hearing screening were introduced in the 1930s. By the 
1940s pure-tone audiometry screening was a standard test throughout the country (Stevens 
and Parker, 2009). Australian school medical services incorporated a rudimentary hearing 
assessment component from the early 1900s (Skurr, 1978) and, in the United States, formal 
school hearing health examinations also developed as early as 1924 (McFarlan, 1927). Wall 
and Bührer (1987) noted that, by 1943, twenty American states had laws requiring school 
screening for hearing loss. With economic advancement, hearing screening was initiated in 
many other regions. For example, in Hong Kong audiometric screening for children in 
government primary (elementary) schools commenced in 1968 and became universal by 1981 
(Lam et al., 2006). Screening audiometry has now come to be considered an established and 
essential aspect of school health practice throughout the developed world, and in many 
developing countries (McPherson and Olusanya, 2008). 
School screening audiometry has concentrated on the detection of possible hearing 
disorders in elementary grade school children. This is appropriate because it is advantageous 
to arrange the earliest possible treatment or habilitation for hearing loss and because many 
cases of previously undetected hearing loss are noted at the time of school entry (Roeser and 
Northern, 1981). From the viewpoint of educators, intervention should be as early as possible 
so that is does not negatively affect academic performance. 
In many countries, universal newborn hearing screening programs have now been 
established and the early detection of congenital hearing loss is common (Leigh, Schmulian-
Taljaard, and Poulakis, 2010). However, the hearing screening of school children can be 
justified by the prevalence of hearing loss that is not detected by universal newborn hearing 
screening, due to factors such as delayed onset hearing loss or acquired hearing loss. British 
data suggests that the prevalence of bilateral, permanent hearing impairment increases by at 
least 50% (and perhaps up to 90%) between the newborn period and the ages of 9-16 years 
(Fortnum, Summerfield, Marshall, Davis, and Bamford, 2001). 
In addition, there are limitations to newborn screening technology that mean it may not 
detect cases of mild hearing loss (Leigh, Schmulian-Taljaard, and Poulakis, 2010) and 
newborn screening programs may have a high non-compliance rate for follow-up (Danhauer, 
Pecile, Johnson, Mixon, and Sharp, 2008), leading to some children remaining unidentified 
until school entry. Approximately 3% of school age children in developed countries may have 
hearing loss in one or both ears (Marttila, 1986; Mehra, Eavey, and Keamy, 2009; Parving, 
1999). 

Hearing Screening for School Children 
9
GOALS OF SCHOOL HEARING SCREENING 
 
Screening programs need clear goals to be effective (Lescouflair, 1975). The two most 
influential sets of professional guidelines for hearing screening, both within and outside of 
North America, are those issued by the American Association for Speech, Language, and 
Hearing (ASHA) and the American Academy of Audiology (AAA). The broad ASHA (1997) 
goal for hearing screening is to identify children likely to have hearing impairment that may 
interfere with education, health, development, or communication and this aim is widely 
adopted in school programs. The AAA guidelines (2011) are similarly concerned with the 
identification of hearing loss that affects perception of speech and, hence, development of 
language-based skills. In both guidelines, it is implicitly or explicitly stated that this goal 
includes detection of children with unilateral as well as bilateral hearing loss. 
 
 
PURE TONE SCREENING AUDIOMETRY 
 
Nearly all school hearing health programs make use of pure tone screening audiometry as 
the fundamental component of their procedures (see Figure 4.1). This is for a number of 
reasons. Pure tone diagnostic audiometry is the gold standard for assessment of hearing loss. 
This involves measurement of perceived threshold intensities for a series of standard tones 
that cover the range of sounds required for optimal detection of speech. 
It is convenient to base screening on the same procedure, using a pass/fail criterion 
intensity instead of determining threshold and to use a restricted range of test tones (test 
frequencies) that are critical for speech perception. 
In addition, the sensitivity and specificity of pure tone screening audiometry has always 
been found to be better than that of any rival technique (Berg, Papri, Ferdous, Khan, and 
Durkin, 2006; Sideris and Glattke, 2006). FitzZaland and Zink (1984) noted sensitivity and 
specificity of 93% and 99%, respectively, in a well-conducted screening program. 
Essentially, tones at fixed, single frequencies are presented at fixed intensity levels and 
the child is instructed to respond to a perceived signal by raising a hand, pressing a response 
button, or in some other standard manner. Earphones are the sound source and generally a 
practice tone is first presented to the child at a level clearly above the test tones (often at 40 or 
60 dB HL) to introduce the child to the type of sound to be used. Test sounds are then 
presented first to one ear and later the other ear, and the presence or absence of a behavioral 
response from the child is recorded for each tone. No attempt is made to find the hearing 
threshold for a tone if the child does not respond at a particular frequency (Roeser and 
Northern, 1981). 
Since the goal of screening is to detect hearing loss that may adversely affect speech 
perception, the test frequencies and intensities chosen should reflect this aim. ASHA guide-
lines (1997, p. 41) call for screening at 20 dB HL “in the frequency region most important for 
speech recognition”. Generally, this frequency region is considered to be from 500 Hz to 
4000 Hz. However, ambient noise conditions in schools are rarely optimal for hearing 
screening (Choi and McPherson, 2005; Knight, Nelson, Whitelaw, and Feth, 2002; Shield, 
Greenland, and Dockrell, 2010) and low frequency ambient noise will often mask quiet test 
tones at 500 Hz, leading to high false-positive rates (McPherson, Law, and Wong, 2010). 

Carlie J. Driscoll, Bradley McPherson and Wayne J. Wilson 
10
The current ASHA guidelines recognize this constraint and recommend testing at 1000 
Hz, 2000 Hz, and 4000 Hz only. The AAA (2011) guidelines make identical recommenda-
tions. A recent European consensus statement on hearing screening (Skarzynski and 
Piotrowska, 2012), while not making specific suggestions for test frequencies, states that 
hearing loss greater than 20 dB HL may have adverse effects on the development of commu-
nication skills, cognitive development, and academic achievement—in effect endorsing the 
ASHA and AAA recommendations for screening intensity level. It should be noted that many 
school screening agencies set their own criterion intensities and frequencies and these may 
not reflect standard guidelines (Meinke and Dice, 2007). However, any criterion set should be 
evidence-based (Wong and Hickson, 2012) and rigorously justified. 
Pass/fail criteria may vary a great deal in pure-tone screening audiometry programs. 
Wall, Naples, Buhrer, and Capodanno (1985), in a large survey of American professionals 
involved in school screening, found that failure to detect a signal at two frequencies was 
deemed a test failure for about one-third of respondents, others used one frequency, more than 
two frequencies, two consecutive frequencies, or a pure-tone average greater than a pre-
determined level as a criterion for ‘failure’. Both ASHA and AAA guidelines define failure as 
a lack of response at any frequency in either ear. 
The two guidelines differ somewhat in how ‘failure’ is determined. AAA (2011, p. 45) 
guidelines recommend “presenting a tone at least twice but no more than four times” if a child 
fails to respond. ASHA (1997) guidelines call for reinstruction, repositioning of earphones, 
and same day rescreening for any child who fails to respond at any frequency. Screening 
audiometers can be purchased specifically for this task. 
These instruments provide a restricted test frequency range, usually from 500 Hz to 4000 
Hz, and also limit earphone output intensity levels. 
 
 
Figure 4.1. School screening using pure tone audiometry. 

Hearing Screening for School Children 
11
PERIODICITY OF SCREENING 
 
Ideally, it would be advantageous to screen all elementary school children for hearing and 
middle ear disorders on an annual basis. However, the associated practicalities rarely allow 
for this (Roeser and Clark, 2004). Guidelines tend to prioritize the screening of younger 
grades and/or high-risk populations, defined by Roeser and Clark (2004, p. 118) as those 
cases that are: new to a school, repeating a grade, commencing speech-language therapy, 
returning to school following serious illness, delayed in development, displaying emotional or 
behavioral problems, involved in noisy coursework, or are absent during previous routine 
screening. To assist in the decision-making regarding which particular grades to screen, AAA 
(2011) provided a summary of findings from an unpublished analysis of hearing screening 
results from three school districts in Colorado and Florida, US. 
Notably, it was found that approximately 90% of new hearing losses were detected by 
screening in preschool, kindergarten, and grades 1, 2, and 3. This rate increased to up to 97% 
if including grade 5 or 6 also. 
Alternatively, ASHA’s (1997) guidelines specify annual screening of all children from 
kindergarten through to grade 3, as well as in grades 7 and 11. Furthermore, children should 
be screened as needed, requested, or mandated. ASHA is also a proponent of screening of 
high-risk cases as described above, with the addition of the factors of: concern from parent/ 
caregiver, health care provider, teacher, or other school personnel; family history of late or 
delayed onset hereditary hearing loss; recurrent or persistent otitis media with effusion 
(OME) for at least three months; craniofacial anomalies, including those with morphological 
abnormalities of the pinna and ear canal; stigmata or other findings associated with a 
syndrome known to include sensorineural and/or conductive hearing loss; head trauma with 
loss of consciousness; and, reported exposure to potentially damaging noise levels or ototoxic 
drugs. 
Program managers should carefully consider the time of year when hearing screening is 
held. It is preferable to avoid times of the year that are known to be peak seasons for colds 
and influenza or for environment-related allergies (Richburg, Davie, and Smiley, 2012) since 
these are times of higher student absence rates and higher prevalence of transient conductive 
hearing loss. 
 
 
PROGRAM MANAGEMENT 
 
Hearing screening in the school environment may be performed by a variety of personnel, 
including, but not limited to: audiologists, audiometrists, speech-language pathologists, 
audiology assistants, school nurses, psychologists and specialist educators, and health 
workers. Personnel choices may be dictated by state licensure requirements or by district/ 
program managers. Richburg and Imhoff (2008) noted that when hearing screening programs 
were supervised by an educational audiologist, testing protocols were more uniform than 
when non-audiologists were in management positions. The World Health Organization (2001) 
reported significant variation in the screening results obtained by minimally trained, junior 
testers in comparison with experienced testers (with ≥ one year’s experience in audiometry). 
Further, Northern and Downs (2002) noted that inexperienced testers, by incorrectly 
placing headphones, can create a threshold shift of up to 35 dB HL. 

Carlie J. Driscoll, Bradley McPherson and Wayne J. Wilson 
12
They may also provide unsuitable instructions, provide verbal and physical cues, and use 
inappropriate stimulus presentation length. In recognition of such studies and of the fact that 
many school districts in the US use screening programs that are managed by personnel other 
than audiologists, AAA (2011) recommended that school hearing screening programs at least 
utilize a single or small group of local audiologists in an advisory capacity. 
The audiologist(s) could provide valuable input regarding higher administrative functions 
of the program, such as choice of screening technology and protocols, training and 
monitoring of testers, equipment maintenance and calibration, and follow-up pathways and 
procedures (Roeser and Clark, 2004). 
ASHA’s (1997) guidelines clearly specified that performance of hearing and/or middle 
ear screening of children aged 0-18 years should be limited to clinically certified audiologists 
and speech-language pathologists, or support personnel under the direct supervision of a 
certified audiologist. 
 
 
Test Environment 
 
In order to minimize the false-positive rate, it is crucial that testing is performed in an 
environment with low ambient noise (Roeser and Clark, 2004). For instance, the school room 
selected for testing should be located away from high noise sources such as cafeterias, music 
rooms, air-conditioners and other mechanical equipment, high-volume road traffic, and high-
volume pedestrian traffic as often occurs near offices and toilet facilities. 
Alternatively, the use of mobile test vans and booths could be considered if finances 
allow. This is particularly important if wanting to ensure that under-identification does not 
occur for cases of unilateral and minimal/mild bilateral hearing loss (White and Munoz, 
2008). Roeser and Clarke (2004) recommend against the routine use of noise-excluding 
headsets, in view of placement effects, unless utilized by experienced testers. 
These authors also remind us of the importance of performing simple biological checks to 
assess whether background noise levels are appropriate (i.e., establishing hearing thresholds 
at least 10 dB below the screening level at all test frequencies for a person with known 
normal hearing, AAA, 2011) or, if possible, directly measuring noise levels using a sound 
level meter against ANSI standards (1999). 
The maximum allowable noise levels for pure tone screening in accordance with ASHA 
(1997) protocols are: 49.5 dB SPL at 1000 Hz, 54.5 dB SPL at 2000 Hz, and 62 dB SPL at 
4000 Hz. For AAA (2011) protocols, these are 50, 58, and 76 dB SPL at 1000, 2000, and 
4000 Hz, respectively. Finally, testing should occur in environments with minimal visual 
distractions that could impact upon the child’s concentration and contribute to elevated false-
positive rates. 
 
 
Accountability and Other Concerns 
 
The program supervisor, preferably an audiologist, should assume responsibility for the 
screening system’s accountability, risk management, and program evaluation (see AAA, 
2011, and ASHA, 1997, for full details). 

Hearing Screening for School Children 
13
Accountability refers to adherence to confidentiality and consent requirements, main-
tenance of the system database, referral tracking, and counseling. Risk management requires 
the audiologist to evaluate risk factors associated with the screening program and to develop 
procedures to minimize or eliminate those factors (e.g., consideration of infection control, 
calibration of equipment, quality assurance procedures, and system errors at all levels). 
Program evaluation to ascertain the effectiveness of a screening system is discussed in 
Chapter 1. 
 
 
ALTERNATIVE SCREENING METHODS 
 
As noted by Meinke (2011), school-based hearing screening has become synonymous 
with pure tone screening. Despite multiple, promising technological advances since the 
inception of school screening in the 1920’s, very little has changed and the hearing screening 
landscape is still characterized by standard pure tone testing with a widespread lack of 
standardization between programs (Bamford et al., 2007; Meinke, 2011). It is certainly time 
for the everyday practice of school hearing screening to benefit from the type of rigorous 
research, systematic evaluation, and in-depth attention that has been typically afforded to 
universal newborn hearing screening programs worldwide. Presented below are some 
alternative screening methods that could be considered for inclusion in the modern school 
hearing screening test battery, followed by discussion of follow-up management pathways, 
and mention of some potential future directions in this field. 
 
 
Tympanometry 
 
Tympanometry is used in the assessment of middle ear function; it is not a test of hearing 
but, rather, a test of the mechanical properties of the tympanic membrane and other middle 
ear structures. The middle ear system is an essential component of the auditory pathway, 
conducting sound from the outer to the inner ear. Disruption of middle ear function can 
produce a conductive hearing loss that can be temporary, fluctuating, or permanent in nature. 
Tympanometry is a minimally invasive, quick, painless, and objective test that involves 
placement of a small, disposable probe tip into the entrance of the external auditory canal in 
order to create an hermetic seal (refer to Figure 4.2). 
As the air pressure within the canal is varied from +200 to -400 daPa, the volume of the 
canal alters accordingly due to movement of the middle ear. A tympanogram is produced; a 
graph of the admittance (compliance or mobility) of the middle ear system against pressure. 
When air is present in the middle ear cavity, the tympanogram will display a peak pressure 
that corresponds with the air pressure within the middle ear space (Roush, 2001). 
Measurement parameters obtained typically include equivalent ear canal volume (Vea), 
peak compensated static acoustic admittance (Ytm), tympanometric peak pressure (TPP), and 
tympanometric width (TW). 
The shape of the tympanogram, along with the associated values, is judged either against 
the classification system developed by Jerger (1970), against specific normative criteria, or 
against professional practice guidelines. 

Carlie J. Driscoll, Bradley McPherson and Wayne J. Wilson 
14
Under Jerger’s system, a “type A” tympanogram is associated with normal middle ear 
compliance and pressure (usually indicative of normal middle ear function), a “type B” tym-
panogram is associated with no changes in compliance with changes in pressure (suggestive 
of middle ear pathology such as OME or tympanic membrane perforation if accompanied by 
an abnormally large ear canal volume), and a “type C” tympanogram is associated with 
normal compliance in the presence of excessively negative pressure (as is seen in Eustachian 
tube dysfunction). Refer to Figure 4.3 for display of these typical tympanogram shapes seen 
in school children.  
In regard to the use of specific normative criteria, these may take into consideration the 
age, gender, ear, or even racial heritage of the child (e.g., Li, Bu, and Driscoll, 2006). Finally, 
tympanometric screening results for school children may be analyzed in accordance with 
professional practice guidelines, such as those produced by AAA (2011), whereby a “failed” 
screen would be indicated by a TW of ≥250 daPa (the preferred criteria), or Ytm of <0.2 
mmhos, or TPP of -200 to -400 daPa (although this criterion alone should not trigger a 
medical referral). 
As previously mentioned, although not a direct test of hearing status, tympanometry can 
be a useful addition to the audiological battery, as 49-66% of children with a type B 
tympanogram will have at least a mild degree of conductive hearing loss, compared with only 
2-13% with other tympanometric profiles (National Health and Medical Research Council, 
NHMRC, 2002). For children aged 4-6 years, FitzZaland and Zink (1984) reported type B or 
C tympanograms to have a sensitivity ranging from 91.2 – 92.7% and a specificity ranging 
from 91.1 – 97.8% in the detection of hearing loss. These values increased to 100% and 97%, 
respectively, when tympanometry (type B tympanogram or Type C with ≤ -200 daPa) was 
used in conjunction with pure tone screening. 
 
 
Figure 4.2. Tympanometry screening at a rural elementary school near Nanjing, Jiangsu province, 
People’s Republic of China. 

Hearing Screening for School Children 
15
 
Figure 4.3. Typical tympanogram shapes observed during school screenings, using Jerger’s (1970) 
classification system. 
Furthermore, tympanometry demonstrates high sensitivity and specificity in the detection 
of OME when measured against a gold standard of myringotomy or pneumatic otoscopy 
(New Zealand Health Technology Assessment, 1998). In particular, type A tympanograms 
have a very high sensitivity in ruling out the presence of OME, and type B tympanograms 
have a sensitivity of 78-90% and a specificity of 63-94% in ruling in the presence of OME. 
These latter rates alter to 100% and 75%, respectively, if combined with type C tympano-
grams (New Zealand Health Technology Assessment, 1998). 
Whilst there is little doubt concerning the appropriateness of tympanometry in detection 
of OME, support for its application in school-based screening programs is less conclusive. A 
suitable rationale for its inclusion might be if (a) OME was found to definitively cause long-
lasting adverse effects upon a child’s development and (b) that such effects could be averted 
by intervention (New Zealand Health Technology Assessment, 1998). However, the evidence 
to support these assumptions is conflicting and although a short‐term correlation between 
OME and development has been recognized, a precise causal relationship has not. Adding to 
the uncertainty is the very nature of OME in childhood; it is a fluctuating disease subject also 
to seasonal variation, thus, single screening points throughout time are unlikely to detect all 
affected children. Furthermore, the rate of spontaneous resolution of OME is known to be 
high (Tos, 1984; Williamson, Dunleavy, Baine, and Robinson, 1994). Consequently, several 
professional bodies currently recommend against the routine, first-line use of tympanometry 
in school hearing screening programs (e.g., NHMRC, 2002; AAA, 2011). 
It is suspected that the effects of OME on child development appear to be mediated by 
the associated hearing loss, although the exact degree and duration of loss needed to produce 
the negative sequelae remain unclear (AAA, 2011). In addition, of children with OME, 30-
40% will experience recurrent episodes and 5-10% will experience episodes lasting in excess 
of one year (Tos, 1984; Williamson et al., 1994). Should the middle ear effusion be present 
for longer than three months, recovery is unlikely to occur in the absence of medical 
intervention (Tos, 1984; Williamson et al., 1994). Further, pure tone screening alone is not 
overly sensitive to middle ear disorders (Roeser and Clark, 2004). For these reasons, 
combined with the recognition of the noisy environments in which all school children must 
listen and learn and in which those with any degree or type of hearing loss can be 
considerably disadvantaged, some programs choose to include tympanometry in their basic 
test battery that is administered to all children. Others choose to apply tympanometry in the 
testing of those at high-risk of OME as per the AAA Position Statement on Identification of 
Hearing Loss and Middle Ear Dysfunction in Preschool and School-Age Children (1997). 

Carlie J. Driscoll, Bradley McPherson and Wayne J. Wilson 
16
Still others recommend its use as a follow-up or rescreening method. For instance, the 
AAA Childhood Hearing Screening Guidelines (2011, p. 46) state that tympanometry should 
be employed as an immediate next stage screening and/or a second stage screening for those 
who have failed pure tone or otoacoustic emission screening. 
Tympanometry results should assist in clarifying the nature of the failure and in 
promoting the most efficient management pathway. Furthermore, AAA proposes that tympa-
nometry could be considered as a first line screening tool for children in preschools, kind-
ergartens, and grade 1 in situations where medical professionals and the school systems 
jointly decide to target OME in addition to cases with hearing loss. 
The AAA guidelines also provide test protocol recommendations for tympanometry. 
Importantly, the tympanometer should be calibrated on a daily basis in accordance with 
manufacturer instruction. (A lightweight, easily portable device with a 226 Hz probe tone 
should be selected.) Prior to test commencement, visual inspection of the outer/middle ear 
using otoscopy should occur, in order to check for conditions that may necessitate medical 
referral or prohibit testing (e.g., tympanic membrane perforation, foreign bodies, blood in the 
ear canal, excessive cerumen, active discharge, etc.). Test results should be interpreted in 
accordance with the previously described criteria. Exceptions to these criteria include children 
with ventilation tubes who may be passed in the presence of a type B tympanogram with large 
Vea, and children of Asian heritage who may be passed with Ytm values of <0.2. 
 
 
Otoacoustic Emissions 
 
Otoacoustic emissions (OAEs) may be defined as low-intensity, acoustic energy 
produced by the cochlea and recorded in the ear canal (Probst, Lonsbury-Martin, and Martin, 
1991). Originally described by Kemp (1978), such emissions are believed to reflect energy 
leakage that is radiated out by the cochlea as a result of its outer hair cells actively processing 
and amplifying incoming low-intensity sound. One particular class of OAEs occurs as a result 
of deliberate acoustic stimulation; evoked OAEs, which include both transient evoked OAEs 
(TEOAEs) and distortion product OAEs (DPOAEs). TEOAEs are so named as the emissions 
are commonly elicited by brief acoustic stimuli, such as Gaussian-shaped broadband clicks or 
tone bursts. Presentation of the stimulus results in a clear, frequency-dispersive response or 
“echo” detected in the ear canal within a short, time-locked window. The nomenclature of 
DPOAEs reflects the stimulus being a pair of pure tones that interact in the cochlea to 
produce a third tone (the distortion product). 
To complete this electrophysiological test, the screener must place a small probe 
(comprised of a transducer and microphone/receiver) into the entrance of the ear canal, to 
create an acoustic seal. The adequacy of the probe fit is then assessed via visual analysis of 
the waveform display. Automatic stimulus presentation is followed by automatic amplifica-
tion, filtering, and digitization of the response, after which the software can provide a 
programmed pass/fail judgment based on the OAEs signal-to-noise ratio (SNR) and other so 
desired measurement parameters, such as reproducibility (for TEOAEs, see Figure 4.4) or 
amplitude (for DPOAEs, see Figure 4.5). Refer to Roush (2001) for further details of the 
OAE test method. 

Hearing Screening for School Children 
17
 
Figure 4.4. An example of the TEOAE test screen (taken using an Otodynamics ILO88 system). 
 
Source: Taken using a Starkey DP2000 system, image courtesy of Starkey Laboratories. 
Figure 4.5. An example of the DPOAE test screen. (Note: “DP” refers to the amplitude of the distortion 
product emission, and “NF” refers to the noise floor.) 

Carlie J. Driscoll, Bradley McPherson and Wayne J. Wilson 
18
 
Figure 4.6. School-based screening using Otoacoustic Emissions testing. 
Typically, TEOAEs can be detected in persons with normal hearing sensitivity and 
otological status. DPOAEs can be detected in those with less than a moderate degree of 
hearing loss (i.e., normal hearing or a mild loss). Although neither are tests of hearing per se, 
they are often used to suggest or confirm the presence of hearing loss. Their presence is 
usually interpreted as indicative of normal cochlear (inner ear) function, whilst their absence 
can suggest outer hair cell damage and, hence, hearing loss. However, it is worth keeping in 
mind that failure of OAE testing is also associated with a plethora of potential influences 
including middle ear dysfunction (e.g., OME), instrumental factors (e.g., inappropriate 
stimulus characteristics), and environmental factors (e.g., high levels of ambient noise). 
In summary, passing of an OAE test is suggestive of normal audiological function up to 
the level of the cochlea; however, failure merely indicates increased risk of the presence of a 
conductive or sensory hearing loss and/or middle ear pathology. 
Both tests carry the advantages of being simple in test administration, non-invasive, 
objective, and resilient in non-sound treated settings. The duration of testing is also 
remarkably short, at less than a minute, assuming low noise levels. For these reasons, OAEs 
have been employed extensively in universal newborn hearing screening programs across the 
world. Researchers are now interested in their application in the screening of older children, 
such as in elementary schools, as a potential replacement for the traditional pure tone test (see 
Figure 4.6). However, professional guidelines, including those of ASHA (1997), AAA 
(2011), and NHMRC (2002), have yet to endorse their routine use in this context, due to the 
inferior sensitivity and specificity of OAEs, as well as an extensive need for further research. 
What is known to date concerning TEOAE screening in school-aged populations is that: 
 
● 
The test is highly feasible for mass screening in elementary schools (AAA, 2011; 
Driscoll, Kei, and McPherson, 2001; Georgalas, Xenellis, Davilis, Tzangaroulakis, 
and Ferekidis, 2008; Nozza, Sabo, and Mandel, 1997; Taylor and Brooks, 2000); 

Hearing Screening for School Children 
19
● 
Sensitivity has been shown to range between 0.65-1.0, depending on the gold 
standard of choice (AAA, 2011; Driscoll et al., 2001; Georgalas et al., 2008; Nozza 
et al., 1997; Sabo, Winston, and Macias, 2000); 
● 
Specificity has been shown to range between 0.8-0.969 (AAA, 2011; Driscoll et al., 
2001; Nozza et al., 1997; Sabo et al., 2000; Sliwa, Hatzopoulos, Kochanek, 
Senderski, and Skarzynski, 2011; Taylor and Brooks, 2000); 
● 
Negative predictive values tend to be high, for example, 0.98, whilst positive 
predictive values are typically low, for example, 0.25 (Driscoll et al., 2001; 
Georgalas et al., 2008); 
● 
Accuracy and efficiency indices are also typically high, for example, up to 0.88 and 
0.91, respectively (Driscoll et al., 2001); 
● 
Combining tympanometry with TEOAE testing does not lead to improved sensitivity 
and specificity (AAA, 2011; Driscoll et al., 2001; Georgalas et al., 2008; Nozza et 
al., 1997); 
● 
TEOAEs cannot predict middle ear status and, thus, cannot replace otoscopy or 
tympanometry (AAA, 2011; Driscoll et al., 2001; Georgalas et al., 2008; Nozza et 
al., 1997);  
● 
Choice of pass/fail criteria is paramount to achieving adequate test performance, with 
criteria used for neonates not necessarily transferrable to older children (AAA, 2011; 
Driscoll et al., 2001); 
● 
Failure rates can range up to 21%, dependent upon the pass/fail criteria selected 
among other factors (Driscoll et al., 2001; Sabo et al., 2000); 
● 
Normal emissions may be recorded in children with mild hearing losses (20-30 dB 
HL) (AAA, 2011); 
● 
Testing is unlikely to be able to be completed for low-frequency stimuli (e.g., <1000 
Hz or <2000 Hz), even in sound-treated environments, due to physiological and 
ambient noise levels (AAA, 2011; McPherson and Olusanya, 2008); 
● 
Low-frequency pass/fail criteria have not been established to date (AAA, 2011); and 
● 
The test does not assess beyond the outer hair cells of the cochlea and, thus, cannot 
detect children with auditory neuropathy/dys-synchrony (AN/AD) whereby outer 
hair cell function is normal but neural transmission in the auditory pathway is 
impaired producing a neural hearing loss (AAA, 2011; Rance, 2005). 
 
Regarding DPOAEs in school-based screening programs, it has been found that: 
 
● 
The test is highly feasible for mass screening in elementary schools (Lyons, Kei, and 
Driscoll, 2004); 
● 
Sensitivity and specificity have been shown to approximate 0.7 and 0.9, respectively, 
if excluding low frequencies such as 1.1 kHz (Lyons et al., 2004); 
● 
Negative predictive values have been reported as high, for example, 0.94, whilst 
positive predictive values appear moderately high, for example, 0.76 (Lyons et al., 
2004); 
● 
A high efficiency index has also been reported, for example, 0.87-0.91 (Lyons et al., 
2004); 
● 
Combining tympanometry with DPOAE testing does not lead to improved sensitivity 
and specificity (Lyons et al., 2004); 

Carlie J. Driscoll, Bradley McPherson and Wayne J. Wilson 
20
● 
DPOAEs cannot predict middle ear status and, thus, cannot replace a screening 
battery comprised of both pure tone testing and tympanometry (AAA, 2011; Lyons et 
al., 2004); 
● 
Choice of pass/fail criteria (SNR cut-offs) is frequency dependent (AAA, 2011; 
Lyons et al., 2004); 
● 
Failure rates range up to 18% and may be reduced further by incorporating two-stage 
screening protocols, however, loss to follow-up then becomes a concern (AAA, 
2011); 
● 
Normal emissions may be recorded in children with mild hearing losses (up to 40 dB 
HL) (McPherson and Olusanya, 2008); 
● 
Testing is unlikely to be able to be completed for low-frequency stimuli (e.g., <1000 
Hz), even in sound-treated environments, due to physiological noise levels (AAA, 
2011; McPherson and Olusanya, 2008); 
● 
Low-frequency pass/fail criteria have not been established to date (AAA, 2011); and 
● 
As per the TEOAE test, testing cannot detect children with AN/AD (AAA, 2011; 
Rance, 2005). 
 
Based upon these findings, it is clear that further research is necessary before OAEs can 
be accepted as a replacement for the typical pure tone screening test. In particular, AAA 
(2011) noted that test and equipment parameters require additional investigation, along with 
blinded test performance studies, the establishment of developmental norms and associated 
pass/fail criteria, training protocols, cost analyses, noise reduction schemes, and, potentially, 
the development of technology that would mitigate the effects of abnormal middle ear 
function upon the recorded emissions. 
Nonetheless, AAA (2011) concluded that the use of OAEs combined with reflectance 
measures of middle ear status may result in improved screening practices in the future. 
 
 
Questionnaires 
 
Although an obviously cost effective method, with the added benefit of raising awareness 
of childhood hearing loss and its consequences (McPherson and Olusanya, 2008), the use of 
questionnaires to detect children at risk of hearing loss and/or other otologic pathologies is 
limited by their dependency on third party observation and motivation (Newton, Macharia, 
Mugwe, Ototo, and Kan, 2001). Other limitations of the questionnaire method include its 
known weakness in detecting cases with milder degrees of hearing loss and unilateral 
impairments (Newton et al., 2001). In addition, although parental concern is an important risk 
factor for sensorineural hearing loss in children, the sensitivity and specificity of parental 
concern are low even in the presence of severe or profound hearing loss (NHMRC, 2002). 
Furthermore, at least 50% of children who develop a postnatal hearing loss do not display any 
notable risk factors (Kennedy, Kimm, Cafarelli Dees, Campbell, and Thornton, 1998; Mehl 
and Thomson, 2002), upon which questionnaires are usually based. In general, questionnaires, 
as a sole method, have not been viewed as suitable for hearing screening purposes. 
Despite the common perception, several studies have shown questionnaires to possess 
some potential in school-based hearing screening applications (Hind, Aitkins, Haggard, 
Brady, and Grinham, 1999; Li, Driscoll, and Culbert, 2009; Newton et al., 2001). For 

Hearing Screening for School Children 
21
instance, Li and colleagues (2009) examined the test performance of a questionnaire designed 
specifically for the screening of rural Chinese school children (the revised Chinese Hearing 
Questionnaire for School Children; CHQS-II). 
This questionnaire, completed by parents/caregivers, consisted of an 11-item, Yes/No 
checklist constructed by the researchers to detect children at risk of otitis media with effusion 
(OME) and/or at least a moderate hearing loss in one or both ears. Analysis showed the 
CHQS-II to be moderately accurate (.62) as a screening system when compared with the gold 
standard diagnostic test battery of otoscopy, tympanometry, and pure tone audiometry. Its 
sensitivity, or ability to detect those at risk of hearing loss or middle ear infection, was also 
moderate (.67). However, its overall efficiency was poor (.56). In essence, there was a high 
likelihood that a passing child would not have a hearing loss/middle ear disease but only a 
low likelihood that a failing child would actually have an otologic problem. As the CHQS-II 
test performances indices did not approximate those of conventional screening techniques, its 
immediate use was not recommended. A very similar pattern of findings was observed in a 
hearing questionnaire study of Brazilian preschoolers by Gomes and Lichtig (2005). 
It appears that the potential of questionnaires in the hearing screening of school children 
may lie not so much in their use as an alternative to traditional methods but, perhaps, as an 
adjunct. In particular, questionnaires may provide valuable information concerning auditory 
status and history that is not otherwise easily obtained. For example, questionnaires could 
prompt parents/caregivers to ask their children about the occurrence of tinnitus and exposure 
to noise. Similarly, they may be used to collect risk factor data, such as: a family history of 
late-onset hearing loss; otitis media with effusion for at least three months; craniofacial 
anomalies; stigmata associated with syndromes including hearing loss; head trauma with loss 
of consciousness; ototoxic drug use; and parent/teacher/health care provider concern 
regarding hearing, speech, language, or learning abilities (ASHA, 1997). 
 
 
Modifications to Traditional Pure Tone Screening 
 
Liao, Lien, and Young (2010) commented on the limitations of traditional pure tone 
screening in school-aged children; notably that pure tone screening typically produces 
pass/fail results only, providing little information concerning exact hearing status. This does 
not allow for easy and accurate comparison of repeat or monitoring screenings, of the like that 
may be performed for cases of otitis media or noise-induced hearing loss. In addition, a 
simple “fail” result can lead to distrust from parents and teachers, who may be wary of false 
positives associated with school hearing screenings, leading to a lack of cooperation with 
management recommendations. 
Thus, Liao and colleagues devised the Hearing Scale Test (HST), a modified pure tone 
screening method, based on the concept of the Landolt C vision-test chart. The HST utilizes 
10 hearing scales from S1 to S10, with each scale containing four frequencies (0.5, 1, 2, and 4 
kHz) and separated by 5 dB HL (range = 0 – 45 dB HL). Minimum audible hearing scales 
(the stimulus level at which the child responds correctly at all four test frequencies) are 
determined using a computerized, semi-automated audiometer. Scales S1 to S5 are equivalent 
to a typical pure tone screening “pass,” whilst S6 to S10 are comparable with a pure tone 
“fail.” The procedure was trialed on 384 third-graders in a Taiwanese elementary school, 
taking approximately 2-3 minutes per child to complete. No significant difference (and a high 

Carlie J. Driscoll, Bradley McPherson and Wayne J. Wilson 
22
level of agreement) was observed between the results of the HST and the results of traditional 
pure tone screening methods. Further analysis showed that the HST results could be 
interpreted as follows: S1 to S5 are indicative of normal hearing, S6 and S7 are suggestive of 
possible hearing loss, and S8 to S10 or no response are symptomatic of confirmed hearing loss. 
With further widespread trials, the HST could be a successful alternative to the standard pure 
tone screen. 
Other modifications to the traditional pure tone technique include the use of video testing 
(Bento, Albernaz, Di Francesco, Wiikmann, Frizzarini, and Castilho, 2003), whereby the four 
frequency sequence generated by an audiometer has been digitally recorded onto a video/CD. 
The disk can then be played in any test location that has access to a VCR or CD player. Bento 
et al. (2003) applied this method to 122 first-grade school children in Brazil and reported 
100% sensitivity and 79.8% specificity when compared with pure tone audiometry. Although 
not capable of detecting unilateral hearing impairment, the researchers noted that such a 
modified technique may be useful for school screening in regions where standard test 
equipment and suitably qualified staff are not readily available. 
With the increasing viability of computer-based audiometry, computerized screening 
audiometry methods deserve consideration. In the majority of school screening situations the 
screener is not an audiologist and a procedure that was based on an automatic test algorithm 
could enhance the quality of testing and reduce personnel training time and costs. 
A recent pilot study of one commercially available audiometer software package found a 
good relationship between conventional hearing screening and computer-based screening in a 
group of 80 elementary school children (McPherson, Law, and Wong, 2010). 
Finally, costs associated with false-positive cases could be reduced by development of 
noise-cancelling earphones for school screening purposes. Noise-cancelling technology is 
now commonly used in headphones (Schumacher, Kruger, Jeub, Vary, and Beaugeant, 2011). 
Lo (2012) reported, in a study of 232 elementary school students, that significantly fewer 
referrals were made in a screening program when noise-cancelling headphones were used 
compared to conventional audiometric earphones. 
 
 
Other Methods 
 
Alternatives for the hearing screening of school children such as acoustic reflex testing 
and the use of speech stimuli tests are currently not supported due to unacceptably high false-
positive and high false-negative rates, respectively (AAA, 2011; NHMRC, 2002). 
Furthermore, non-calibrated stimuli (e.g., the whisper test) should not be used in any 
capacity (ASHA, 1997). 
 
 
FOLLOW-UP ACTIONS 
 
A two-stage screening program is recommended by AAA (2011), in view of variables 
such as earphone placement, child behavior, and fluctuating/transient pathologies. By defini-
tion, AAA suggests that the two-stage protocol should include a same-day retest of failed 

Hearing Screening for School Children 
23
cases, followed by a rescreening performed after a designated period of weeks (see Figure 4.7 
for an example of a two-tiered program pathway). 
For suspected cases of middle ear pathology, ASHA’s (1997) guidelines recommend this 
period to be 6-8 weeks; AAA state a minimum of 8 and a maximum of 10 weeks. 
As noted by AAA, there is a trend for lower failure and referral rates with increased 
periods between screenings. However, for suspected cases of permanent hearing loss, it 
would be wise to minimize delays in diagnostic assessment and, therefore, it would be wholly 
appropriate to refer immediately following same-day rescreen (refer to AAA, 2011, for full 
details of rescreening recommendations). 
In the event that referral to a medical practitioner is required for investigation of 
suspected middle ear pathology, AAA (2011, p. 50) suggests that the screener should include, 
if known, information concerning the duration and laterality of pathology, all test results from 
each test occasion, evidence/concern regarding speech and language abilities, and additional 
conditions that may exacerbate the effects of middle ear pathology in the referred case. 
 
 
Figure 4.7. An example of a two-tiered hearing screening protocol based upon AAA (2011) 
recommendations. 
Screening can be an almost useless endeavor if it does not lead on to diagnostic 
assessment and timely intervention. Unfortunately, receipt of follow-up care in school hearing 
screening programs has been not infrequently reported as sub-optimal. For example, Kemper, 
Fant, Bruckman, and Clark (2004), in their analysis of Michigan’s program where 500,000 
children are screened each year, found that only 73% of referred cases in grades 1-5 actually 
went on to receive follow-up services. This figure reduced to 57% for cases in grades 6-12. 
The most common reason cited by parents for failure to pursue follow-up was that the child 
had been previously evaluated for suspicion of hearing loss, followed by lack of concern, and 
doubt regarding screening accuracy. 
To alleviate poor follow-up rates, AAA (2011) proposes: presenting results in the 
families’ native language, including educational pamphlets on the effects of undiagnosed 
hearing loss, and propagating close relationships between screening personnel and the local 

Carlie J. Driscoll, Bradley McPherson and Wayne J. Wilson 
24
medical community. Mundy (2001) further suggests engaging school personnel to facilitate 
receipt of follow-up, staff that may assist those with transportation problems, with lack of 
information concerning local medical resources, with lack of medical/health fluency in 
general, and those with second-language related issues. 
 
 
FUTURE CONSIDERATIONS 
 
Screening for Central Auditory Processing Disorder 
 
Central auditory processing disorder (CAPD) has caught the attention of researchers, 
clinicians, educators, and parents alike, with a Google search for “central auditory processing 
disorder” in 2013 bringing up over a quarter of a million hits. Despite this attention, screening 
for central auditory processing disorder (CAPD) is as controversial as the disorder itself, and 
with this in mind, this section will briefly review the definition of CAPD before considering 
the current evidence for its screening. 
 
Defining CAPD 
Despite several decades of research, we still lack gold standards for defining and 
diagnosing CAPD (Wilson and Arnott, 2012). This led Dawes and Bishop (2009, p. 440) to 
postulate that “APD, as currently diagnosed, is not a coherent category”. Through this contro-
versy, the definition of CAPD offered by the American Speech-Language-Hearing Associa-
tion’s (ASHA) Working Group on Auditory Processing Disorders Technical Report (ASHA 
[2005]; an update on ASHA [1996]) has come to be the most cited. 
They define CAPD as “a deficit in neural processing of auditory stimuli that is not due to 
higher order language, cognitive, or related factors” (ASHA, 2006, p. 2), and as difficulties in 
the perceptual processing of auditory information in the CNS as demonstrated by poor 
performance in sound localization and lateralization; auditory discrimination; auditory pattern 
recognition; temporal aspects of audition, including temporal integration, temporal discrimi-
nation (e.g., temporal gap detection), temporal ordering, and temporal masking; auditory 
performance in competing acoustic signals (including dichotic listening); and auditory 
performance with degraded acoustic signals (ASHA, 2006, p.2). 
While this is the definition of CAPD that will be used in this section, the reader should 
consider other definitions such as those offered offered by AAA (2010) and BSA (2011a). 
 
Screening for CAPD 
Efforts to identify children with CAPD have been driven by at least three main factors. 
First is the incidence of CAPD, which is estimated to be as high as three to five percent in 
school-aged children (Chermak and Musiek, 1997). Second is the potential impact this 
disorder could have on listening, communication, and academic success (ASHA, 2005). Third 
is the need for early intervention “to exploit the plasticity of the CNS, maximize successful 
therapeutic outcomes, and minimize residual functional deficits” (ASHA, 2005, p. 11). 
While the motivation to screen for CAPD appears to be strong, agreement is lacking on 
the “who, when, and how” of this screening. The guidelines for screening offered by Wilson 
and Jungner (1968) suggest we should screen children at risk for CAPD, who have access to 

Hearing Screening for School Children 
25
appropriate diagnostic and treatment facilities at an affordable cost, who can be screened 
before CAPD becomes a problem or at least when they can benefit from intervention, and for 
whom we have suitable screening tools that can be applied by suitably qualified screening 
personnel. 
Converting these principles into practice has remained a significant challenge, however. 
Deciding who is at risk for CAPD has proven to be as controversial as the definition of 
CAPD itself. ASHA (2005, p. 5) state that individuals suspected of having CAPD frequently 
present with one or more behavioral characteristics, with their list being: 
 
Difficulty understanding spoken language in competing messages, noisy back-grounds, 
or in reverberant environments; misunderstanding messages; inconsistent or inappropriate 
responding; frequent requests for repetitions, saying “what” and “huh” frequently; taking 
longer to respond in oral communication situations; difficulty paying attention; being 
easily distracted; difficulty following complex auditory directions or commands; 
difficulty localizing sound; difficulty learning songs or nursery rhymes; poor musical and 
singing skills; and associated reading, spelling, and learning problems. 
 
They also warn, however, that this list is illustrative and not exhaustive, and that these 
behavioral characteristics are not exclusive to CAPD. 
 
How to Screen for CAPD 
Deciding how to screen for CAPD is difficult. ASHA (2005) states that while there is no 
universally accepted method of screening for CAPD, current screening approaches typically 
involve systematic observation of listening behavior and/or performance on tests of auditory 
function that probe auditory behaviors related to academic achievement, listening skills, and 
communication. In the absence of an appropriate tool for primary screening for CAPD, Bellis 
(2003) has argued that such screening should be left to parents and teachers who are best 
positioned to regularly observe the child’s behavior. 
If a parent and/or teacher reported a child showed behaviors associated with CAPD, then 
Bellis (2003) recommends a secondary screening be conducted by a team of professionals 
that could include an audiologist, speech-language pathologist, educator, psychologist, social 
worker, the parents and a physician. The aim of this secondary screening is to gather 
information about the child’s central auditory processing and educational, social, speech/ 
language, cognitive, and medical characteristics. 
This aims to “provide a picture of the child’s strengths and weaknesses across domains” 
so that the team can decide if there exists “sufficient evidence to support the likelihood that a 
CAPD is present” (Bellis, 2003, p. 170). 
Suspected CAPD then triggers a referral to an audiologist for a diagnostic CAPD 
assessment, whereas suspicions of other disorders triggers referrals to more appropriate 
professionals (e.g., to a speech-language pathologist if a language disorder is suspected, to a 
psychologist if a cognitive disorder is suspected, etc.). Such a team approach does need to be 
balanced with practical issues including timing and cost (BSA, 2011b), which has left many 
researchers searching for the best single tool or small group of tools to screen for CAPD. 
 

Carlie J. Driscoll, Bradley McPherson and Wayne J. Wilson 
26
Tools Used to Screen for CAPD 
It is beyond the scope of this section to describe all of the tools that have been used to 
screen for CAPD. Instead, this section will consider some of the tools that have been widely 
used by audiologists in the US (Chermak, Silva, Nye, Hasbrouck, and Musiek, 2007) where 
the diagnostic criteria for CAPD had been clearly stated and the data had been published in 
the peer reviewed, scientific literature. 
Four questionnaires that have been used to screen for CAPD are the Children’s Auditory 
Performance Scale (CHAPS), the Fisher’s Auditory Problems Checklist (FAPC), the 
Listening Inventory For Education–Revised (LIFE-R), and the Screening Instrument for 
Targeting Educational Risk (SIFTER). The CHAPS (Smoski, Brunt, and Tannahill, 1998) 
requires teachers and/or parents to complete 36 questions rating a child’s listening behavior in 
different listening conditions. Reports that the CHAPS cannot separate children with or 
without CAPD (Dawes, Bishop, Sirimanna, and Bamiou, 2008; Drake et al., 2006; Lam and 
Sanchez, 2007; Sharma, Purdy, and Kelly, 2009; W. J. Wilson et al., 2011) are evenly 
matched by those that report it can separate children with or without CAPD (Dawes and 
Bishop, 2010; Ferguson, Hall, Riley, and Moore, 2011; Iliadou and Bamiou, 2012; Moore, 
Ferguson, Edmondson-Jones, Ratib, and Riley, 2010).  
The FAPC (Fisher, 1976) requires teachers and/or parents to use a simple checklist to 
identify any of 25 auditory behaviors of concern. A single study has reported it cannot 
separate children with or without CAPD (Dawes et al., 2008).  
The LIFE-R series includes: the Before–LIFE-R (Anderson, Smaldino, and Spangler, 
2011c), which requires students to mark items that describe their classroom setting; the LIFE-
R Student Appraisal of Listening Difficulty (LIFE-R SALD) (Anderson, Smaldino, and 
Spangler, 2011a), which requires students to rate how difficult they find it to listen in 15 
different classroom environments; and the After LIFE-R (Anderson, Smaldino, and Spangler, 
2011b), which requires students to mark items that describe how they would respond in six 
difficult classroom environments. Teacher versions are also available (the LIFE-R Teacher 
Appraisal of Listening Difficulty [LIFE-R TALD] [Anderson, Smaldino, and Spangler, 
2011d] and the LIFE-R Teacher Checklist: Self-Advocacy and Instructional Access 
[Anderson, Smaldino, and Spangler, 2011e]). A single study has reported one of the original 
LIFE questionnaires contained only two items that could separate children with or without 
CAPD (Johnston, John, Kreisman, Hall, and Crandell, 2009). 
The SIFTER series includes the Preschool SIFTER (Anderson and Matkin, 1996), 
SIFTER (Anderson, 1989) and Secondary SIFTER (Anderson, 2004), each of which requires 
teachers and/or parents to rate a child’s performance on 15 aspects of academics, attention, 
communication, class participation, and school behavior in the classroom setting. One study 
reported the SIFTER’s academics subscore could (Johnston et al., 2009) and one study 
reported the whole questionnaire could not (W. J. Wilson et al., 2011) separate children with 
or without CAPD.  
The most popular screening test for CAPD has been the Tests for Auditory Processing 
Disorders for Children, now in its third generation (SCAN-3:C; Keith, 2012), which requires 
professionals trained in standardized assessments to present children with pre-recorded 
stimuli to assess a range of central auditory processing tasks including gap detection, 
auditory-figure ground, and competing words. One study reported the original SCAN 
(Domitz and Schow, 2000) and one study reported the second generation SCAN-C (Madison, 

Hearing Screening for School Children 
27
Hallberg, Anfinson, DeMaio, and Drake, 2005) could not separate children with or without 
CAPD. 
 
Conclusion 
Screening for CAPD remains controversial. Many screening tools have been offered and 
of the few that have been assessed the evidence for their use remains equivocal with no one 
tool standing out as a best candidate for screening for CAPD. Based on these results, it 
appears that two statements by AAA (2010, p. 13) on screening measures for CAPD should 
remain in place: 1. “While a number of questionnaires have been used to screen for CAPD …, 
they generally have poor specificity, tend to over-refer, and have not been validated”, and 2. 
“Further studies are needed to determine the efficiency of currently available screening 
instruments, including the efficiency of diagnostic tests used for screening purposes, and to 
develop new screening tools for CAPD.” 
 
 
Noise-Induced Hearing Loss 
 
Recent research has drawn attention to the high prevalence of noise-induced hearing loss 
(NIHL) in adolescents, with preventative educational programs subsequently arising. For 
instance, the United States of America National Center for Health Statistics 2005-2006 
NHAMES III data provided a prevalence rate of noise-induced hearing threshold changes of 
16.8% (95% CI: 13.9%–19.7%) for adolescents aged 12 to 19 years (see Henderson, Testa, 
and Hartnick, 2011, for full details) and programs such as “Hear Today, Hear Tomorrow” a 
school curriculum based hearing health program by the National Acoustic Laboratories 
(www.nal.gov.au) and “Dangerous Decibels” by Oregon Health and Science University 
(www.dangerousdecibels.org) have been recommended to counteract this excessive 
occurrence of NIHL in older children. However, less is known about the prevalence of noise-
induced hearing changes in younger, elementary school children. The Oregon Health and 
Science University’s Hearing Research Centre has accumulated data from over 30,000 cases 
during 2002-2011 to show that approximately 17% of 5-12 year children have a hearing loss 
of at least 20 dB HL at 4 kHz – an indicator of NIHL (http://www.dangerousdecibels.org/ 
research/omsi-research-data/). AAA (2011) also reported unpublished data from three US 
school districts that showed that there was a trend for decreased identification of new hearing 
losses in grades 1-3 but an increased identification rate at grade 5, suggesting a possible 
increased prevalence of high frequency hearing loss in the upper grades of elementary 
schools. Moreover, the role that routine screening in elementary schools could play in the 
immediate and long-term prevention of NIHL has been under-researched to date. 
NIHL results from exposure to hazardous noise levels, be they very high levels for short 
periods of time (e.g., 120 dB A for 30 seconds) or lower levels for longer periods (e.g., 90 dB 
A for 3 hours per day). The increasing use of personal listening devices, such as iPods and 
MP3 players, has been frequently implicated in the causation of NIHL in children (Hender-
shot, Pakulski, Thompson, Dowling and Price, 2011; Niskar, Kieszak, Holmes, Esteban, 
Rubin, and Brody, 2001; Shargorodsky, Curhan, Curhan, and Eavey, 2010). 
However, the World Health Organization (1997) have also noted that US children may 
receive more adverse noise exposure during a typical day at school than workers during an 8-
hour factory shift. Such noise sources may include, but are not limited to: educational toys, 

Carlie J. Driscoll, Bradley McPherson and Wayne J. Wilson 
28
musical equipment, sound field amplification systems, concerts, theatre productions, trade 
equipment, computers with headphones, and traffic noise.  
NIHL is produced due to permanent damage to the delicate hair cells of the cochlea (see 
Figure 4.8). It is typically progressive, with a gradual onset, and appears on the audiogram as 
a high-frequency notched pattern. That is, “dips” in the audiogram will be seen in the high 
frequencies, most notably at the test frequencies of 3, 4, or 6 kHz with recovery at 8 kHz in 
the early stages. Niskar and colleagues in 2001 reported that 12.5% of 6- to 19-year-old 
children in the US were estimated to display such a notch in at least one ear, with 6 kHz being 
the most commonly affected frequency (Sekhar, Rhoades, Longenecker, Beiler, King, 
Widome, and Paul, 2011). 
 
 
a 
 
 
 
 
b 
Reproduced with the permission of the House Research Institute©. All rights reserved. 
Figure 4.8. (A) Normal cochlear hair cells showing three rows of healthy outer hair cells (OHCs) and 
one row of healthy inner hair cells (IHCs), (B) damaged cochlear hair cells producing a sensorineural 
hearing loss. 
As the condition progresses, hearing loss will extend into the lower and higher ranges 
(Meinke and Dice, 2007). At this point, the typical negative consequences of permanent 
childhood hearing loss may be experienced, including delayed/disordered speech and 
language development, learning difficulties, social and behavioral problems, and, ultimately, 
reduced quality of life. 
A hearing screening protocol capable of detecting NIHL (or, for that matter, any other 
form of hearing loss that produces a high-frequency notched audiometric configuration, such 
as is seen in ototoxicity or head trauma) must include assessment of the frequency range from 
3 to 6 kHz. If utilizing pure tone screening as the method of choice, this will necessitate a 
longer test time with potential reliability implications when testing the younger grades in non-
sound treated environments. 
In addition, screening failure rates can be expected to dramatically increase. Sekhar et al. 
(2011) noted that when utilizing a pure tone screening criteria designed for detection of 
NIHL, 26.4% of 296 eleventh grade students received a failing result. Program management 

Hearing Screening for School Children 
29
pathways would need to be carefully revised to deal with such a large proportion of follow-up 
cases – it would hardly be feasible to refer a quarter of all students for in-depth diagnostic 
testing. Schlauch and Carney (2010), in their examination of the NHANES III data, suggested 
that careful elimination of calibration errors, as well as utilizing headphones with low 
measurement variability, and repeating/averaging threshold measurements, may help to 
reduce the unacceptably high false-positive rate that could be associated with screening at 6 
kHz. 
An alternative to pure tone screening for NIHL may very well be the use of otoacoustic 
emissions to provide early detection of cochlear changes that occur prior to the advent of a 
measurable hearing loss (Meinke, 2011). Although further, extensive research is required 
regarding this application in elementary school settings, otoacoustic emission screening could 
serve as a useful adjunct to pure tone screening whereby, for instance, cases with normal pure 
tone results at the standard test frequencies of 0.5, 1, 2, and 4 kHz, but with abnormal 
otoacoustic emission SNRs at the frequency bands centered around 3 kHz, 4 kHz, and/or 6 
kHz, would be marked for monitoring screens through time (perhaps on a yearly basis) and 
would receive preventative, educational counseling. A well-constructed computerized data 
management system (of the kind described in Chapter 11) would allow for easy analysis of 
changes in baseline measures. 
Whilst true that NIHL is irreversible, its progression can be halted to a certain extent by 
avoidance of exposure to continual hazardous noise (Niskar, Kieszak, Holmes, Esteban, 
Rubin, and Brody, 1998). There is much scope for research to contribute toward hearing loss 
prevention at the earliest possible age and the investigation of otoacoustic emission protocols 
in elementary schools would be an obvious starting point. 
 
 
Telehealth 
 
Telehealth is the general term used to describe the application of medically-related 
services over a distance (Givens and Elangovan, 2003), typically associated with the use of 
telecommunication technology such as high-speed computer networks and the internet. Tele-
audiology, providing audiological services using telehealth, has been studied by a few 
researchers using synchronous methods (where services are provided and results transmitted 
in real time) and asynchronous methods (where results are stored and forwarded for later 
analysis). Synchronous methods include the possibilities of (a) the audiologist utilizing 
interactive video to supervise a technician at a distant clinical site, then providing diagnosis 
and management recommendations or (b) the audiologist utilizing remote technology to 
directly test the case at a distant site, with the technician’s role limited to headphone and 
probe placement, et cetera (Lancaster, Krumm, Ribera, and Klich, 2008). 
Young and Ireson (2003) reported telehealth services in schools to be cost effective and 
highly acceptable to key stakeholders including parents, children, and school officials 
(Lancaster et al., 2008). Furthermore, Lancaster et al. (2008) conducted a thorough 
examination of the feasibility and test performance of a tele-audiology school hearing 
screening program. Forty-three third grade students in a Utah elementary school were 
screened by an audiologist on-site using otoscopy, tympanometry, and pure tone audiometry. 
A second audiologist performed the tele-audiology screenings from a distance of 
approximately 30 miles, with the first examiner acting as a facilitator only. In the tele-

Carlie J. Driscoll, Bradley McPherson and Wayne J. Wilson 
30
audiology model, video otoscopy and pure tone testing results were synchronously interpreted 
by the distant examiner, with tympanometry results being asynchronously forwarded and 
analyzed. Full agreement between results obtained on-site and those obtained via tele-
audiology was obtained for all otoscopy and tympanometry findings. For pure tone testing, 
disagreement occurred for 5/43 cases, although such was not considered statistically 
significant. These cases included four false-positive responses and one false-negative. 
Therefore, in this study, although sensitivity for pure tone screening was found to be very 
high, specificity was less than optimal. The researchers concluded that tele-audiology 
demonstrated great potential for application in the hearing screening of school-aged children 
and suggested that further research should be conducted with larger cohorts and over greater 
distances, with attention given to proper training of technicians/facilitators and adherence to 
teleheath privacy requirements. 
Tele-audiology may prove to be a very useful alternative to traditional on-site hearing 
screening in schools, helping to increase the productivity of pediatric audiologists who are, in 
many countries, in short supply. It may reduce the inefficiencies and inequities associated 
with hearing health care services in rural and remote locations. 
Finally, it may be found to offer an improvement in the accuracy of screening, as it has 
been noted that school hearing screenings are often plagued by non-standardized protocols 
and procedures, non-calibrated equipment, inappropriate noise levels, and performed by 
poorly trained staff (Blair, 1991). 
 
 
Genetic Screening 
 
As it currently stands, many professional bodies concerned with the genetic testing of 
children advise against genetic analysis for adult-onset conditions. For instance, The 
Committee on Bioethics of the American Academy of Pediatrics state that such testing in 
general should be deferred until adulthood or until an adolescent is capable of mature 
decision-making (Committee on Bioethics, 2001). 
Similarly, the United Kingdom’s Clinical Genetics Society considers predictive genetic 
testing of children inappropriate until they can make such requests for themselves, as 
autonomous adults (Clarke and Working Party of the Clinical Genetics Society, 1994). 
However, as noted by Caga-anan, Smith, Sharp, and Lantos (2012), not all adult-onset 
conditions are alike. For some conditions, the early diagnosis offered by genetic testing may 
promote improved management of the condition or psychological benefits regardless of the 
test outcome. In these cases, the ethical case for early genetic testing is clear (Caga-anan et 
al., 2012). 
Further, the American Academy of Pediatrics’ expert committee on the subject (AAP, 
2013) advises against school-based genetic carrier testing or screening programs as “the 
school environment is unlikely to be conducive to voluntary participation, thoughtful consent, 
privacy, confidentiality, or appropriate counseling” (p. 621).  
Currently, there are no known genetic screening programs available for operation in 
elementary schools. If programs of the like were to be devised, it would require extremely 
careful examination of the potential risks versus harms. Geneticists, genetic counselors, and 
bioethicists would be needed to determine the specific medical benefits, psychological risks 

Hearing Screening for School Children 
31
(including the impact upon the child and upon family dynamics), and personal histories of the 
cohort (Caga-anan et al., 2012). 
At present, no discussions of this kind have been published in regard to genetic screening 
of elementary school children for markers of late-onset hearing loss. Future applications, if 
considered at all, perhaps may be related to genetic testing for susceptibility markers 
associated with age-related or noise-induced hearing loss, which is still a relatively new and 
unexplored field. The potential benefits of predictive genetic screening of this nature might 
include access to preventative education and new treatment strategies, such as gene therapy, 
pharmacological interventions, stem cell implantation, et cetera, which are designed to halt or 
slow the development of hearing loss. 
However, prior to implementation in elementary schools, it is likely that this new 
direction will first be explored in relation to adolescent screening. 
 
 
CONCLUSION 
 
To instigate the detection and re/habilitation of undiagnosed hearing loss in children, 
school hearing screening programs are a necessity. They present as a useful adjunct to new-
born hearing screening, especially for postnatal cases, where the loss is acquired, progressive, 
or late-onset, as well as for milder cases that may have been missed by the newborn screen, 
and for cases where newborn screening was not available or desired. However, significant 
planning is required in order to operate an efficient and effective school hearing screening 
program. This chapter has provided an overview of the main methods and protocols for 
school screening. It has also offered suggestions for alternative screening techniques and has 
highlighted some potential future directions that may improve the current state of school 
hearing screening programs. It is posed that further, rigorous research and evaluation will 
soon lead to vast improvements in this screening endeavor. 
 
 
REFERENCES 
 
Access Economics. (2006). Listen hear! The economic impact and cost of hearing loss in 
Australia. Melbourne: Author. 
American Academy of Audiology (AAA). (1997). Position statement: Identification of 
hearing loss and middle ear dysfunction in preschool and school-age children. Retrieved 
from http://www.audiology.org/resources/documentlibrary/Pages/HearingLossChildren. 
aspx. 
American Academy of Audiology (AAA). (2010). Clinical practice guidelines: Diagnosis, 
treatment and management of children and adults with central auditory processing 
disorder. 
Retrieved 
from 
http://www.audiology.org/resources/documentlibrary/ 
Documents/CAPD%20Guidelines%208-2010.pdf. 
American Academy of Audiology (AAA). (2011). Childhood hearing screening guidelines. 
Retrieved from http://www.audiology.org/resources/documentlibrary/Documents/2011 
0926_ChildhoodHearingScreeningGuidelines.pdf. 

Carlie J. Driscoll, Bradley McPherson and Wayne J. Wilson 
32
American Academy of Pediatrics Committee on Bioethics, Committee on Genetics, The 
American College of Medical Genetics, Genomics Social, Ethical and Legal Issues 
Committee (AAP). (2013). Ethical and policy issues in genetic testing and screening of 
children. Pediatrics, 130(1), 620-622. 
American National Standards Institute (ANSI). (1999). Maximum permissible ambient noise 
for audiometry testing (ANSI S3.1-1999). NY: Author. 
American Speech-Language-Hearing Association (ASHA). (1996). Central auditory 
processing: Current status of research and implications for clinical practice. American 
Journal of Audiology, 5(2), 41-54. 
American Speech-Language-Hearing Association (ASHA). (1997). Guidelines for audiologic 
screening. Retrieved from http://www.asha.org/docs/html/GL1997-00199.html#sec1.7. 
American Speech-Language-Hearing Association (ASHA). (2005). (Central) auditory proce-
ssing disorders. Retrieved from www.asha.org/policy/TR2005-00043.htm. 
Anderson, K. L. (1989). S.I.F.T.E.R.: Screening Identification For Targeting Educational 
Risk in children identified by hearing screening or who have known hearing loss. Tampa, 
FL: The Educational Audiology Association. 
Anderson, K. L. (2004). Secondary S.I.F.T.E.R. Screening Instrument For Targeting 
Educational Risk in secondary students. Westminster, CO: The Educational Audiology 
Association. 
Anderson, K. L. and Matkin, N. D. (1996). Preschool S.I.F.T.E.R. Screening Identification 
For Targeting Educational Risk in preschool children (age 3-kindergarten). West-
minster, CO: The Educational Audiology Association. 
Anderson, K. L., Smaldino, J. J. and Spangler, C. (2011a). Listening Inventory For Education 
- Revised (L.I.F.E.-R.). Student Appraisal of Listening Difficulty. Retrieved from https:// 
successforkidswithhearingloss.com/ 
Anderson, K. L., Smaldino, J. J. and Spangler, C. (2011b). Listening Inventory For Education 
- Revised (L.I.F.E.-R.). Student Appraisal of Listening Difficulty: After-LIFE questions 
for students. Retrieved from https://successforkidswithhearingloss.com/ 
Anderson, K. L., Smaldino, J. J. and Spangler, C. (2011c). Listening Inventory For Education 
- Revised (L.I.F.E.-R.). Student Appraisal of Listening Difficulty: Before-LIFE questions 
for students. Retrieved from https://successforkidswithhearingloss.com/ 
Anderson, K. L., Smaldino, J. J. and Spangler, C. (2011d). Listening Inventory For Education 
- Revised (L.I.F.E.-R.). Teacher Appraisal of Listening Difficulty. Retrieved from https:// 
successforkidswithhearingloss.com/ 
Anderson, K. L., Smaldino, J. J. and Spangler, C. (2011e). Listening Inventory For Education 
- Revised (L.I.F.E.-R.). Teacher checklist: Self-advocacy and instructional access. 
Retrieved from https://successforkidswithhearingloss.com/ 
Bamford, J., Fortnum, H., Bristow, K., Smith, J., Vamvakas, G., Davies, L., … and Hind, S. 
(2007). Current practice, accuracy, effectiveness and cost-effectiveness of the school 
entry hearing screen. Health Technology Assessment, 11(32). 
Bellis, T. J. (2003). Assessment and management of central auditory processing disorders in 
the educational setting: From science to practice (2nd ed.). San Diego, CA: Singular. 
Bento, R. F., Albanez, P. L. M., Di Francesco, R. C., Wiikmann, C., Frizzarini, R., and 
Castilho, A. M. (2003). Video test for hearing screening in children. International 
Congress Series, 1240, 217-220. 

Hearing Screening for School Children 
33
Berg, A. L., Papri, H., Ferdous, S., Khan, N. Z., and Durkin, M. S. (2006). Screening methods 
for childhood hearing impairment in rural Bangladesh. International Journal of Pediatric 
Otorhinolaryngology, 70, 107-114. 
Blair, J. (1991). Educational audiology and methods for bringing about change in schools. 
Seminars in Hearing, 12, 318-328. 
British Society of Audiology (BSA). (2011a). Position statement: Auditory processing 
disorder (APD). Retrieved from http://www.thebsa.org.uk/images/stories/docs/BSA_ 
APD_PositionPaper_31March11_FINAL.pdf. 
British Society of Audiology (BSA). (2011b). Practice guidance: An overview of current 
management of auditory processing disorder (APD). Draft document to Council for 
approval to press ahead with consultation. Retrieved from http://www.thebsa.org.uk/ 
images/stories/docs/BSA_APDMgmt_31March2011_Consultation.pdf. 
Caga-anan, E. C. F., Smith, L., Sharp, R. R., and Lantos, J. D. (2012). Testing children for 
adult-onset genetic diseases. Pediatrics, 129(1), 163-167. 
Chermak, G. D. and Musiek, F. E. (1997). Central auditory processing disorders: New 
perspectives. San Diego, CA: Singular. 
Chermak, G. D., Silva, M. E., Nye, J., Hasbrouck, J., and Musiek, F. E. (2007). An update on 
professional education and clinical practices in central auditory processing. Journal of the 
American Academy of Audiology, 18(5), 428-452. 
Choi, C. Y. and McPherson, B. (2005). Noise levels in Hong Kong primary schools: Implica-
tions for classroom listening. International Journal of Disability, Development and Edu-
cation, 52, 345-360. 
Clarke, A. and Working Party of the Clinical Genetics Society (UK). (1994). The genetic 
testing of children. Journal of Medical Genetics, 31(10), 785–797. 
Committee on Bioethics. (2001). Ethical issues with genetic testing in pediatrics. Pediatrics, 
107(6), 1451–1455. 
Danhauer, J. L., Pecile, A. F., Johnson, C. E., Mixon, M., and Sharp, S. (2008). Parents’ 
compliance with and impressions of a maturing community-based early hearing detection 
and intervention program: An update. Journal of the American Academy of Audiology, 
19, 612-629. 
Dawes, P. and Bishop, D. V. M. (2009). Auditory processing disorder in relation to develop-
mental disorders of language, communication and attention: A review and critique. Inter-
national Journal of Language and Communication Disorders, 44(4), 440-465. 
Dawes, P. and Bishop, D. V. M. (2010). Psychometric profile of children with auditory 
processing disorder and children with dyslexia. Archives of Disease in Childhood, 95(6), 
432-436. 
Dawes, P., Bishop, D. V. M., Sirimanna, T., and Bamiou, D. E. (2008). Profile and aetiology 
of children diagnosed with auditory processing disorder (APD). International Journal of 
Pediatric Otorhinolaryngology, 72(4), 483-489. 
Domitz, D. M. and Schow, R. L. (2000). A new CAPD battery - Multiple auditory processing 
assessment (MAPA): Factor analysis and comparisons with SCAN. American Journal of 
Audiology, 9, 101-111. 
Drake, M., Brager, M., Leyendecker, J., Preston, M., Shorten, E., Stoos, R., and DeMaio, L. 
(2006). Comparison of the CHAPPS screening tool and APD diagnosis. Paper presented 
at the ASHA Convention, Miami Beach, FL. Retrieved from http://convention.asha.org/ 
2006/handouts/855_0427Drake_Mary_072995_120106033139.pdf. 

Carlie J. Driscoll, Bradley McPherson and Wayne J. Wilson 
34
Driscoll, C., Kei., J. and McPherson, B. (2001). Outcomes of transient evoked otoacoustic 
emission testing in six-year-old school children: A comparison with pure tone screening 
and tympanometry. International Journal of Pediatric Otorhinolaryngology, 57, 67-76. 
Ferguson, M. A., Hall, R. L., Riley, A., and Moore, D. R. (2011). Communication, listening, 
cognitive and speech perception skills in children with Auditory Processing Disorder 
(APD) or Specific Language Impairment (SLI). Journal of Speech, Language, and 
Hearing Research, 54(1), 211-227. 
Fisher, L. I. (1976). Fisher's Auditory Problems Checklist. Tampa, FL: The Educational 
Audiology Association. 
FitzZaland, R. E. and Zink, G. D. (1984). A comparative study of hearing screening procedu-
res. Ear and Hearing, 5, 205-210. 
Fortnum, H. M., Summerfield, A. Q., Marshall, D. H., Davis, A. C., and Bamford, J. M. 
(2001). Prevalence of permanent childhood hearing impairment in the United Kingdom 
and implications for universal neonatal hearing screening: Questionnaire based ascertain-
ment study. British Medical Journal, 323, 1-6. 
Georgalas, C., Xenellis, J., Davilis, D., Tzangaroulakis, A., and Ferekidis, E. (2008). 
Screening for hearing loss and middle ear effusion in school-age children, using transient 
evoked otoacoustic emissions: A feasibility study. Journal of Laryngology and Otology, 
122, 1299-1304. 
Givens, G. and Elangovan, S. (2003). Internet application to tele-audiology: “Nothin’ but 
net.” American Journal of Audiology, 12, 59-65. 
Gomes, M. and Lichtig, I. (2005). Evaluation of the use of a questionnaire by non-specialists 
to detect hearing loss in preschool Brazilian children. International Journal of Rehabili-
tation Research, 28, 171-174. 
Hendershot, C., Pakulski, L. A., Thompson, A., Dowling, J., and Price, J. H. (2011). School 
nurses' role in identifying and referring children at risk of noise-induced hearing loss. 
Journal of School Nursing, 27, 380-389. 
Henderson, E., Testa, M. A. and Hartnick, C. (2011). Prevalence of noise-induced hearing-
threshold shifts and hearing loss among US youths. Pediatrics, 127, e39-e46. 
Henderson, P. (1975). The School Health Service 1908-1974. London: HMSO. 
Hind, S. E., Aitkins, R. L., Haggard, M. P., Brady, D., and Grinham, G. (1999). Alternatives 
in screening at school entry: Comparison of the childhood middle ear disease and hearing 
questionnaire (CMEDHQ) and the pure tone sweep test. British Journal of Audiology, 33, 
403-414. 
Iliadou, V. and Bamiou, D. E. (2012). Psychometric evaluation of children with auditory 
processing disorder (APD): Comparison with normal-hearing and clinical non-APD 
groups. Journal of Speech, Language, and Hearing Research, 55, 791-799. 
Jerger, J. F. (1970). Clinical experience with impedance audiometry. Archives of Otolaryngo-
logy, 92, 311-324. 
Johnston, K. N., John, A. B., Kreisman, N. V., Hall, J. W., and Crandell, C. C. (2009). 
Multiple benefits of personal FM system use by children with auditory processing 
disorder (APD). International Journal of Audiology, 48(6), 371-383. 
Keith, R. W. (2012). Technical report. SCAN-3 for Children. Tests for auditory processing 
disorders. London: Pearson. 
Kemp, D. T. (1978). Stimulated acoustic emissions from within the human auditory system. 
Journal of the Acoustical Society of America, 64(5), 1386-1391. 

Hearing Screening for School Children 
35
Kemper, A. R., Fant, K. E., Bruckman, D., and Clark, S. J. (2004). Hearing and vision 
screening program for school-aged children. American Journal of Preventative Medicine, 
26(2), 141-146. 
Kennedy, C., Kimm, L., Cafarelli Dees, D., Campbell, M., and Thornton, A. (1998). 
Controlled trial of universal neonatal screening for early identification of permanent 
childhood hearing impairment. Wessex Universal Neonatal Hearing Screening Trial 
Group. Lancet, 352(9145), 1957-1964. 
Knecht, H. A., Nelson, P. B., Whitelaw, G. M., and Feth, L. L. (2002). Background noise 
levels and reverberation times in unoccupied classrooms: Predictions and measurements. 
American Journal of Audiology, 11, 65-71. 
Lam, C. C. C., Poon, M. T., Doo, S., Lau, K. W. Y., Lo, Y. W. H., Chan, Y. B. V., and 
Wong, T. P. S. (2006). Hearing impairment. In: R. H. L. Mak, C. C. C. Lam, C. C. Y. Ho 
and M. M. Y. Wong (Eds.), A primer in common developmental disabilities. Experience 
at Child Assessment Service, Hong Kong (pp. 281-331). Hong Kong: Department of 
Health. 
Lam, E. and Sanchez, L. (2007). Evaluation of screening instruments for auditory processing 
disorder (APD) in a sample of referred children. Australian and New Zealand Journal of 
Audiology, 29(1), 26-39. 
Lancaster, P., Krumm, M., Ribera, J., and Klich, R. (2008). Remote hearing screenings via 
telehealth in a rural elementary school. American Journal of Audiology, 17(2), 114-122. 
Leigh, G., Schmulian-Taljaard, D. and Poulakis, Z. (2010). Newborn hearing screening. In: C. 
J. Driscoll and B. McPherson (Eds.), Newborn screening systems: The complete 
perspective (pp. 95-115). San Diego: Plural. 
Lescouflair, G. (1975). Critical view on audiometric screening in school. Archives of Otola-
ryngology, 101, 469-473. 
Li, X., Bu, X. and Driscoll, C. (2006). Tympanometric norms in Chinese schoolchildren. 
International Journal of Audiology, 45, 55-59. 
Li, X., Driscoll, C. and Culbert, N. (2009). Investigating the performance of a questionnaire 
for hearing screening of school children in China. Australian and New Zealand Journal 
of Audiology, 31(1), 45-52. 
Liao, W.-H., Lien, C.-F. and Young, S.-T. (2010). The hearing scale test for hearing 
screening of school-age children. International Journal of Pediatric Otorhinolaryngolo-
gy, 74, 760-764. 
Lo, H. C. (2012). Hearing screening for school children: Utility of noise-cancelling head-
phones. Master of Science (Audiology) dissertation, University of Hong Kong. 
Lyons, A., Kei, J. and Driscoll, C. (2004). Distortion product otoacoustic emissions in 
children at school entry: A comparison with pure tone screening and tympanometry 
results. Journal of the American Academy of Audiology, 15, 702-715. 
Madison, W. I., Hallberg, A., Anfinson, J., DeMaio, L., and Drake, M. (2005). Comparison of 
composite SCAN scores to APD diagnosis. Paper presented at the American Speech 
Language Hearing Association Annual Meeting, San Diego, CA. 
Marttila, T. I. (1986). Results of audiometrical screening in Finnish school children. Inter-
national Journal of Pediatric Otorhinolaryngology, 11, 39-46. 
McFarlan, D. (1927). The voice test of hearing. Archives of Otolaryngology, 5, 1-5. 

Carlie J. Driscoll, Bradley McPherson and Wayne J. Wilson 
36
McPherson, B., Law, M. M. S. and Wong, M. S. M. (2010). Hearing screening for school 
children: Comparison of low-cost, computer-based and conventional audiometry. Child: 
Care, Health and Development, 36(3), 323-331. 
McPherson, B. and Olusanya, B. O. (2008). Screening for hearing loss in developing 
countries. In: B. McPherson and R. Brouillette (Eds.), Audiology in Developing Countries 
(pp. 73-105). NY: Nova Science. 
Mehl, A. L. and Thomson, V. (2002). The Colorado newborn hearing screening project, 
1992-1999: On the threshold of effective population-based universal newborn hearing 
screening. Pediatrics, 109(1), e7. 
Mehra, S., Eavey, R. D. and Keamy, D. G. (2009). The epidemiology of hearing impairment 
in the United States: Newborns, children, and adolescents. Otolaryngology-Head and 
Neck Surgery, 140, 461-472. 
Meinke, D. K. (2011). School-based hearing screening won’t prevent noise-induced hearing 
loss. Archives of Pediatrics and Adolescent Medicine, 165(12), 1135-1136. 
Meinke, D. K. and Dice, N. (2007). Comparison of audiometric screening criteria for the 
identification of noise-induced hearing loss in adolescents. American Journal of Audio-
logy, 16, S190-S202. 
Moore, D. R., Ferguson, M. A., Edmondson-Jones, A. M., Ratib, S., and Riley, A. (2010). 
Nature of auditory processing disorder in children. Pediatrics, 126(2), e382-390. 
Mundy, M. R. (2001). The Chapel Hill-Carrboro (NC) schools: Hearing and middle ear 
screening for preschool and school-age children. In: J. Roush (Ed.), Screening for 
Hearing Loss and Otitis Media in Children (pp. 158-176). San Diego, CA: Singular 
Thomson Learning. 
National Health and Medical Research Council (NHMRC). (2002). Child health screening 
and surveillance: A critical review of the evidence. Canberra: Author. 
Newton, V. E., Macharia, I., Mugwe, P., Ototo, B., and Kan, S. W. (2001). Evaluation of the 
use of a questionnaire to detect hearing loss in Kenyan preschool children. International 
Journal of Pediatric Otorhinolaryngology, 57, 229–234. 
New Zealand Health Technology Assessment. (1998). Screening programs for the detection 
of otitis media with effusion and conductive hearing loss in preschool and new entrant 
school children: A critical appraisal of the literature. Christchurch: Author. 
Niskar, A. S., Kieszak, S. M., Holmes, A., Esteban, E., Rubin, C., and Brody, D. J. (1998). 
Prevalence of hearing loss among children 6 to 19 years of age: The third National Health 
and Nutrition Examination Survey. Journal of the American Medical Association, 279 
(14), 1071-1075. 
Niskar, A. S., Kieszak, S. M., Holmes, A. E., Esteban, E., Rubin, C., and Brody, D. J. (2001). 
Estimated prevalence of noise-induced hearing threshold shifts among children 6 to 19 
years of age: The third National Health and Nutrition Examination Survey, 1988-1994, 
United States. Pediatrics, 108(1), 40-43. 
Northern, J. and Downs, M. (2002). Hearing in children (5th ed.). Denver, CO: Lippincott 
Williams and Wilkins. 
Nozza, R. J., Sabo, D. L. and Mandel, E. M. (1997). A role for otoacoustic emissions in 
screening for hearing impairment and middle ear disorders in school-age children. Ear 
and Hearing, 18(3), 227-239. 

Hearing Screening for School Children 
37
Parving, A. (1999). Hearing screening: Aspects of epidemiology and identification of hearing 
impaired children. International Journal of Pediatric Otorhinolaryngology, 49(Suppl. 1), 
S287-292. 
Probst, R., Lonsbury-Martin, B. L. and Martin, G. K. (1991). A review of otoacoustic 
emissions. Journal of the Acoustical Society of America, 89(5), 2027-2067. 
Rance, G. (2005). Auditory neuropathy/dys-synchrony and its perceptual consequences. 
Trends in Amplification, 9(1), 1-43. 
Richburg, C. M., Davie, J. M. and Smiley, D. F. (2012). Hearing screenings in the schools. 
In: C. M. Richburg and D. F. Smiley (Eds.), School-based audiology (pp. 69-86). San 
Diego: Plural. 
Richburg, C. and Imhoff, L. (2008). Survey of hearing screeners: Training and protocols used 
in two district school systems. Journal of Educational Audiology, 14, 31-41. 
Roeser, R. J. and Clark, J. L. (2004). Screening for auditory disorders. In: R. J. Roeser and M. 
P. Downs (Eds.), Auditory disorders in school children: The law, identification, remedia-
tion (4th ed.) (pp. 96-123). NY: Thieme. 
Roeser, R. J. and Northern, J. L. (1981). Screening for Hearing Loss and Middle Ear 
Disorders. In: R. J. Roeser and M. P. Downs (Eds.), Auditory Disorders in School 
Children (pp. 120-150). NY: Thieme-Stratton. 
Roush, J. (2001). Methods of screening for hearing loss and otitis media. In: J. Roush (Ed.), 
Screening for hearing loss and otitis media in children (pp. 33-82). San Diego, CA: 
Singular Thomson Learning. 
Sabo, M. P. Winston, R. and Macias, J. D. (2000). Comparison of pure tone and transient 
evoked otoacoustic emission screening in a grade school population. American Journal of 
Otolaryngology, 21, 88-91. 
Schlauch, R. and Carney, E. (2010). Are false positive rates leading to an overestimation of 
noise‐induced hearing loss? Journal of Speech, Language, and Hearing Research, 54(2), 
679-692. 
Schumacher, T., Kruger, H., Jeub, M., Vary, P., and Beaugeant, C. (2011, May 22-27). Active 
noise control in headsets: A new approach for broadband feedback ANC. Paper 
presented at the IEEE International Conference on Acoustics, Speech and Signal 
Processing (ICASSP), Prague, Czech Republic. 
Sekhar, D. L., Rhoades, J. A., Longenecker, A. L., Beiler, J. S., King, T. S., Widome, M. D., 
and Paul, I. M. (2011). Improving detection of adolescent hearing loss. Archives of 
Pediatrics and Adolescent Medicine, 165(12), 1094-1100. 
Shargorodsky, J., Curhan, S. G., Curhan, G. C., and Eavey, R. (2010). Change in prevalence 
of hearing loss in US adolescents. Journal of the American Medical Association, 304(7), 
772-778. 
Sharma, M., Purdy, S. C. and Kelly, A. S. (2009). Comorbidity of auditory processing, 
language, and reading disorders. Journal of Speech, Language, and Hearing Research, 52 
(3), 706-722. 
Shield, B., Greenland, E. and Dockrell, J. (2010). Noise in open plan classrooms in primary 
schools: A review. Noise and Health, 12(49), 225-234. 
Sideris, I. and Glattke, T. J. (2006). A comparison of two methods of hearing screening in the 
preschool population. Journal of Communication Disorders, 39, 391-401. 

Carlie J. Driscoll, Bradley McPherson and Wayne J. Wilson 
38
Skarzynski, H. and Piotrowska, A. (2012). Screening for pre-school and school-age hearing 
problems: European consensus statement. International Journal of Pediatric Otorhino-
laryngology, 76, 120-121. 
Skurr, B. A. (1978). Hearing screening as a community health service in N.S.W. In: 
Proceedings of the Third Conference of the Audiological Society of Australia (pp. 115-
129). Sydney: Audiological Society of Australia. 
Sliwa, L., Hatzopoulos, S., Kochanek, K., Pilka, A., Senderski, A., and Skarzynski, P. H. 
(2011). A comparison of audiometric and objective methods in hearing screening of 
school children: A preliminary study. International Journal of Pediatric Otorhinolaryn-
gology, 75, 483-488. 
Smoski, W. J., Brunt, M. A. and Tannahill, J. C. (1998). Children's auditory performance 
scale. Tampa, FL: The Educational Audiology Association. 
Stevens, J. and Parker, G. (2009). Screening and surveillance. In: V. E. Newton (Ed.), 
Paediatric audiological medicine (2nd ed.) (pp. 29-51). Chichester: Wiley-Blackwell. 
Taylor, C. L. and Brooks, R. P. (2000). Screening for hearing loss and middle ear disorders in 
children using TEOAEs. American Journal of Audiology, 9, 50-55. 
Tos, M. (1984). Epidemiology and natural history of secretory otitis. American Journal of 
Otology, 5, 459-462. 
Wall, L. G. and Bührer, K. (1987). Hearing identification of the preschool child: A proposed 
training program. Folia Phoniatrica, 39, 145–152. 
Wall, L. G., Naples, G. M., Buhrer, K., and Capodanno, C. (1985). A survey of audiological 
services within the school system. ASHA, 27, 31–34. 
White, K. R. and Munoz, K. (2008). Screening. Seminars in Hearing, 29(2), 149-158. 
Williamson, I., Dunleavy, J., Baine, J., and Robinson, D. (1994). The natural history of otitis 
media with effusion: A three-year study of the incidence and prevalence of abnormal 
tympanograms in four South West Hampshire infant and first schools. Journal of 
Laryngology and Otology, 108, 930-934. 
Wilson, J. M. G. and Jungner, G. (1968). Principles and practice of screening for disease. 
WHO Public Health Papers, No. 34. 
Wilson, W. J. and Arnott, W. (2012). Evidence about the effectiveness of interventions for 
auditory processing disorder. In: L. Wong and L. Hickson (Eds.), Evidence-based 
practice in audiology (pp. 283-308). San Diego: Plural. 
Wilson, W. J., Jackson, A., Pender, A., Rose, C., Wilson, J., Heine, C., and Khan, A. (2011). 
The CHAPS, SIFTER, and TAPS–R as predictors of (C)AP skills and (C)APD. Journal 
of Speech, Language, and Hearing Research, 54, 278-291. 
Wong, L. and Hickson, L. (2012). Evidence-based practice in audiology. In: L. Wong and L. 
Hickson (Eds.), Evidence-based practice in audiology (pp. 3-21). San Diego: Plural. 
World Health Organization (WHO). (1997). Report of a World Health Organization-Preven-
tion of deafness/hearing impairment - Informal consultation III. Geneva: Author. 
World Health Organization (WHO). (2001). Hearing aids for developing countries: Informal 
consultation. Geneva: Author. 
Young, T. and Ireson, C. (2003). Effectiveness of school-based telehealth care in urban and 
rural elementary schools. Pediatrics, 112, 1088-1094. 
 
 

In: Encyclopedia of Audiology and Hearing Research 
ISBN: 978-1-53617-702-2 
Editors: Erno Larivaara and Senja Korhola 
© 2020 Nova Science Publishers, Inc. 
 
 
 
 
 
 
Chapter 3 
 
 
 
WORKING WITH LEARNERS WITH HEARING  
LOSS IN STEM 
 
 
C. Jonah Eleweke, PhD 
College of Liberal Arts and Sciences, World Languages and Literatures 
Portland State University, Portland, Oregon 
 
 
ABSTRACT 
 
Learners with hearing loss can acquire science, technology, engineering, and 
mathematics (STEM) knowledge and skills. There is evidence in history that several 
important inventions in STEM were made by individuals with hearing loss. The vast 
majority of young people with hearing loss come from families with no previous 
experience of raising children with hearing loss. It is argued that these families should be 
provided unbiased and clear information regarding all aspects of the development of 
children with hearing loss. With such information, they can make informed choices that 
will positively impact their involvement in early intervention programs for their children. 
Thus they will begin to lay the foundation for the development of STEM knowledge and 
skills in their children by being able to consistently communicate with them. The 
implications of utilizing educational materials and programs with rich visual effects such 
as videos, animations, 3-Ds, and subtitles; having effective teachers who plan and address 
the unique learning needs of learners with hearing loss; and supporting learners with 
hearing loss to be actively involved in their own learning process to facilitate the 
development of STEM knowledge and skills are discussed.  
 
 
INTRODUCTION 
 
In this chapter, important factors for understanding and enhancing the educational 
experiences, and outcomes for learners who have hearing loss in science, technology, 
engineering, and mathematics (STEM) are highlighted. Hearing loss is used in this chapter as 
a broad generic term for any hearing dysfunction that precludes successful processing of all 
                                                        
 Corresponding Author’s Email: jeleweke@pdx.edu. 

C. Jonah Eleweke 
40
linguistic information through the ears regardless of severity, etiology, and age of onset. 
Nonetheless, the different degrees of hearing loss: mild, moderate, severe, and profound 
clearly suggest that children who have hearing loss have different communication and 
educational needs (see for example, Gomez, Piehota, & Dischner, 2012; McKay, Gravel, & 
Tharpe, 2008) for a review. 
In the United States, Canada, United Kingdom, and other Western countries, there have 
been concerted efforts toward developing strategies for addressing STEM and other 
educational needs of individuals with hearing loss over the past decades (Spencer & 
Marschark, 2010). This has been due to increased understanding of people with hearing loss, 
their communication methods, and ongoing changes and progress in pedagogy, psychology, 
psycholinguistics, and technology. Evidence suggests that more progress has been made in 
the education of children with hearing loss in the United States during the last 30 years than 
in the previous 300 years (Marschark, Lang, & Albertini, 2002).  
Although history is replete with amazing feats of many famous individuals with hearing 
loss in STEM, for example, Thomas Edison’s light bulb and thousands of other inventions; 
Sir John Warcup Cornfield, winner of the Nobel Prize in 1975 for his work in Chemistry and 
cholesterol; Robert Weitbretch, inventor of the special telephone for deaf people 
(teletypewriter or TTY, for short); Annie Jump Ganon, in astronomy; to mention just a few 
(Deaf Scientist Corner, 2013); current evidence indicates that majority of learners with 
hearing loss have lower achievements in STEM compared to their hearing peers (Blatto-
Vallee, Kelly, Porter, & Fonzi, 2007; Vosganoff, Paatsch, & Toe, 2011). 
Consequently, new options and perspectives that could lead to achieving better outcomes 
for learners with hearing loss in STEM should be continually provided to families and their 
children with hearing loss, their teachers, and other professionals in the field. Controversies 
regarding the best strategies for instructions and services to achieve this goal, especially in 
terms of methods of communication, have continued to be prevalent in the field (Mukaria & 
Eleweke, 2010). Nonetheless, it is argued that learners with hearing loss can achieve success 
in STEM if such controversies are set aside, and efforts are focused on providing appropriate 
services that will foster their learning and cognitive development immediately following the 
diagnosis of hearing loss. Given that the majority of children with hearing loss in this country 
and other Western countries now live at home and are in inclusion educational programs due 
to numerous legislative mandates (Hyde & Power, 2003; Marschark, Sapere, Convertino, & 
Pelz, 2008) programs and services to enhance their educational development and subsequent 
success in STEM must begin immediately after the diagnosis of hearing loss. To effectively 
provide meaningful foundation for the success of children with hearing loss in acquiring 
STEM knowledge and skills, the following are important considerations: (1) supporting 
families, (2) appropriate and effective early intervention programs, (3) use of relevant 
technology and software, and (4) effective teaching strategies and study habits.  
 
 
SUPPORTING FAMILIES TO PROVIDE STEM DEVELOPMENT SUCCESS 
 
Majority of children with hearing loss in the United States, Canada, United Kingdom and 
most Western countries live at homes with their families due to legislative mandates 
supporting inclusion of learners with special needs in regular education programs in these 

Working with Learners with Hearing Loss in STEM 
41
countries (see for example, Marschark, Sapere, Convertino & Pelz, 2008). Consequently, the 
foundation for the success of these children in all aspects of development including STEM 
must be laid at homes by supporting families. Evidence indicates that the vast majority of 
children with hearing loss, more than 90%, come from hearing families with no previous 
experience of hearing loss (Mitchell & Karchmer, 2004). With no previous experience of 
raising children with hearing loss, the parents could experience various devastating 
psychological reactions when the hearing loss was diagnosed and disclosed to them (Borum, 
2012; Jackson, 2011). Without timely support, some parents could remain in denial and 
shopping around for a ‘cure’ for too long (Scheetz, 2012). There is a real danger that the 
child’s developmental needs could be neglected if the adverse psychological reactions parents 
may experience by the diagnosis of hearing loss persisted for too long. These parents, 
therefore, require timely support and education regarding childhood hearing loss and its 
implications for the child’s development. They need to know about the various 
communication and educational options for children with hearing loss (Marschark, 2007). 
For parents to be effective in meeting the developmental needs of their children with 
hearing loss and ensure their success in all aspects of development including STEM, they 
should be empowered to take the initiative in seeking out programs and services that would 
foster the development of their children. To achieve this goal, families of children with 
hearing loss require clear and unbiased information on all the issues that are essential for the 
communication, educational, social-emotional and other aspects of the development of their 
children with hearing loss (Jamison, Zaidman-Zait, & Poon, 2011). Although the importance 
of providing such information is acknowledged in the literature, it seems to the case that in 
many instances, parents may not receive such information (Eleweke, Bays, Gilbert, & Austin, 
2008). The failure to provide clear and unbiased information has adverse consequences. For 
instance, a family’s ability to adapt to the child’s hearing loss may be hindered by the lack of 
information about available services. Evidence clearly indicates that many parents are still not 
receiving adequate information and support during the critical early development years, and 
many remain uninformed and unable to assist their children at home. Lacking information, 
many parents are unable to make appropriate choices about the communication and 
educational needs of their children (Davila, 2004).  
Providing unbiased and clear information is the critical modality of supporting families 
with young children who have hearing loss to enable them to lay the foundation for the 
development of STEM knowledge and skills in young children with hearing loss. When 
unbiased and clear information is provided, they will be able to make informed choices that 
will address the STEM knowledge and skills and other developmental needs of their children. 
However, concerns remain about the nature of the information professionals provide to 
families. Evidence indicates that many parents are aware that they are not getting all the 
information they need, and that some of the information they receive is patently biased 
(Marschark, 2007). 
Nonetheless, evidence is consistent that the provision of unbiased and clear information 
and support are critically important to enable families to participate actively in the 
development and education of their children with hearing loss (Eleweke, et al., 2008; 
Jamison, Zaidman-Zait, & Poon, 2011). The information and support provided to families 
could make the biggest differences in their lives by empowering them to take the initiative to 
seek services that would help them and their children (Turnbull, Turnbull, Shank, & Smith, 
2004). This demands that the family-centered approach which calls for collective 

C. Jonah Eleweke 
42
empowerment rather than a more traditional relationship where the professional had power 
over the family should be utilized in sharing information and providing support to parents of 
children with hearing loss. With this approach, parents and family members must become 
essential partners in the decision-making process. Consequently, teachers and other service 
providers should consider the family constellation as the appropriate focal point of 
professional attention in providing information about developmental needs of children with 
hearing loss and supporting their families to follow through. 
Using family-centered approaches will assist parents of children with hearing loss to 
acquire the information and supports they need in order to foster the STEM and other aspects 
of their children’s development. For instance, a family’s ability to adapt to the child’s hearing 
loss may be facilitated by the provision of relevant information about available services. 
Equipped with appropriate information, support, and knowledge, many parents of children 
with hearing loss will be able to make appropriate choices about the communication and 
educational needs of their children, which will in turn facilitate the development of STEM 
knowledge and skills in the children. Evidence from the Colorado Home Intervention 
Program (CHIP) and studies in the United Kingdom indicated that families with young 
children with hearing loss could benefit immensely from programs provided within their 
homes (Yoshinaga-Itano, 2004). Parents could be visited by professionals such as teachers, 
speech and language pathologists, audiologists, early childhood special educators, bilingual 
educators, psychologists, and social workers. These professionals provide information about 
counseling, developmental assessment, communication, and educational options. Targets 
should be established for timing of initial visit by professionals to the family of a newly 
diagnosed child with hearing loss. The visits should be carefully planned and conducted with 
the goal of giving unbiased information and empowering parents so that they can make 
informed choices.  
It is critical that professionals give contact information about local and national 
organizations concerned with hearing loss to the parents. These professionals, especially 
those with hearing loss, should be included in the team that makes the initial visit to families 
since they have first-hand experience of living with a hearing loss. Consequently, apart from 
providing information and mentoring families, they could give hope and inspiration to 
families and their children. Additionally, it is imperative that parents with newly diagnosed 
children have the opportunity of meeting and chatting with other parents who have been or 
are currently working their way through similar issues. These parents provide mutual and 
social supports to each other to cope better in meeting the challenges of raising a child with a 
hearing loss. Such parents manifest better behavioral interactions and greater sensitivity to 
their children’s communication and other needs (Turnbull & Turnbull, 2006).  
 
 
EFFECTIVE EARLY INTERVENTION PROGRAMS SUPPORTING  
STEM KNOWLEDGE AND SKILLS DEVELOPMENT 
 
Given that the majority of parents of children with hearing loss are hearing people with 
no previous experience of raising children with hearing loss, it becomes imperative that 
following information and supports provided to the families to deal with their adverse 
reactions to the diagnosis of the hearing loss and obtaining understanding of what raising 

Working with Learners with Hearing Loss in STEM 
43
children with hearing loss entails, effective early intervention measures should be established 
to foster the development of STEM knowledge and other skills in children with hearing loss. 
Effective early intervention services could greatly enrich the conceptual store of children with 
hearing loss. Through such programs, communication barriers posed by hearing loss could be 
dealt with as parents and family members are supported to learn how best to communicate 
with their children (Fulcher, Purcell, Baker, & Munro, 2012). 
Timely initiation of early intervention services could prevent or greatly reduce the 
communication barriers posed by hearing loss (Holzinger, Fellinger, & Beitel, 2011). These 
services are necessary because of their focus on language development, parent–child 
communication, social skills, educational, cognitive and other aspects of development, and 
support for the utilization of any residual hearing the children with hearing loss may possess. 
All these areas are important for the development of STEM knowledge and skills in children 
with hearing loss. It has been argued that there is evidence of strong relationship between 
language skills, especially reading and writing, and performance on STEM tasks and 
assessments (Vosganoff, Paatsch, & Toe, 2011). Consequently, appropriate early intervention 
programs may provide parents with strategies for enhancing their children’s language and 
educational development through sign language instruction, speech training skills, or both 
depending on the particular program (Kasai, Fukushima, Omori, Sugaya, & Ojima, 2012). 
The goal of early intervention must be to foster effective parent–child communication starting 
soon after diagnosis of hearing loss. This kind of communication is the best single predictor 
of success in STEM knowledge and skills and virtually all other areas of development of 
children with hearing loss, (Marschark, 2007). Clearly, effective interactions, with the most 
appropriate means of communication, between caregivers and the child will provide 
opportunities for involvement in most normal activities of childhood in both social and 
academic areas, which foster the development of STEM knowledge and skills. 
Thus, an important goal of early intervention should be to provide children with hearing 
loss with the opportunity to acquire language in the appropriate modality (sign or spoken) by 
having accessible and competent language models. Consistent means of communication, in 
the appropriate modality that is congruent for the child, will create opportunities for positive 
social interactions critical for the social-emotional development and STEM educational 
success of all children including those with hearing loss. Evidence indicates that children with 
hearing loss who are identified early and participate in early intervention programs achieve 
significantly better language, speech, social, and emotional developments than those who are 
not identified early and who receive intervention at a later time (Fulcher, et al., 2012; 
Holzinger, et al., 2011). To provide effective early intervention for children and their families, 
the program should not be influenced by the controversy regarding the best communication 
approach that has characterized the field of education of children with hearing loss for 
decades. There seems to be a common agreement with Marschark (2007) that there is no 
single correct answer about the best or superior method of communication for children with 
hearing loss. These children are different and therefore their communication and other 
developmental needs will be different. Consequently, no one method can be applied to all or 
even most of them. The important thing is to establish, as early as possible, an effective mode 
of parent–child communication, one that the child can access fully (Calderon, 2000). This is 
the foundation for successful social, emotional, and academic, STEM knowledge and skills, 
and other aspects of development of children with hearing loss. Through objective 

C. Jonah Eleweke 
44
assessment, open-mindedness, and willingness to be flexible, the mode of communication 
that would be appropriate for each child could be found. 
 
 
FOSTERING STEM KNOWLEDGE AND SKILLS USING INFORMATION 
COMMUNICATION TECHNOLOGY AND SOFTWARE 
 
Over the decades there has been tremendous developments in the field of information and 
communication technology (ICT) that provide great benefits to learners with or without 
special needs. For many learners without special needs, learning materials on the internet, 
world wide web (WWW), CDs/DVDs, flash-drives, and so on support their independent 
learning. Using these resources, they can become self-directed learners. They can use these 
resources to learn in the school and at home. Unfortunately, the same cannot be said for 
learners who have hearing loss. Given the poor literacy skills of the majority of these learners, 
(Debevc & Peljhan, 2004; Vosganoff, Paatsch, & Toe, 2011), these ICT resources must be in 
forms rich with visual reinforcements. It has been argued that learners with hearing loss must 
be considered as visual learners (Moores, 2010). Consequently, educational materials and 
resources meant to foster STEM knowledge and skills that are based in print or spoken 
English or other national languages may be of very little benefit to the majority of learners 
with hearing loss who have poor skills with English literacy (Coppens, Tellings, Schreuder, & 
Verhoeven, 2013). Nonetheless, evidence suggests that ICT resources rich with visual 
elements can enhance the teaching and learning of STEM materials in learners with hearing 
loss (Debevc & Peljhan, 2004). According to these authors, the inclusion of visual or multi-
media elements such as animation, videos, and subtitles in ICT-based educational materials 
and resources is mandatory to achieve the goal of enhancing STEM knowledge and skills in 
learners with hearing loss. These authors argue that these visual elements are appropriate for 
the visual abilities possessed by learners with hearing loss. Given that hearing loss creates 
challenges in mastering spoken and written English or other national languages, it is evident 
that these visual elements will greatly promote the acquisition of STEM knowledge and skills 
in learners with hearing loss. There is evidence that in some cases, learners with hearing loss 
will master materials and resources with the appropriate visual elements in less time than 
materials or resources lacking those elements (Debevc & Peljhan, 2004). It is clear then that 
ICT materials and resources that will facilitate the development of STEM knowledge and 
skills in learners with hearing loss must have these visual elements. Subtitles in English 
should be mandatory. Other elements such as animations and videos will be equally helpful. 
The assimilation of educational resources and materials with these visual and other interactive 
elements by learners with hearing loss will be greatly enhanced (Marschark, et al. 2008). 
 Clearly, multi-media visual elements will facilitate the acquisition of STEM knowledge 
and skills by learners with hearing loss in that the materials can be learned repeatedly in the 
school and at home. Due to legislative mandates, the majority of these learners live at home 
and attend day schools. Therefore, with ICT materials and resources rich with visual 
elements, easy and user-friendly interfaces, learners with hearing loss can repeatedly receive 
support in the school and from family members to learn and practice these materials and 
resources. 

Working with Learners with Hearing Loss in STEM 
45
In addition to ensuring that resources and materials to facilitate the development of 
STEM knowledge and skills in learners with hearing loss have user-friendly visual interfaces 
such as videos, animation, and subtitles, the use of software specifically developed for this 
group of learners to facilitate their STEM learning and progress has been documented. For 
instance, Adamo-Villani and Wilbur (2010) reported two novel approaches to teaching 
mathematics and science concepts using 3-D animated interactive software for learners with 
hearing loss.  
According to these authors, the content of the software program is based on the academic 
curriculum. This suggests that this software can address the material learners with hearing 
loss need to learn at different grade levels. There are animated characters constructed with the 
latest technology and design that use sign language in this software. This feature is 
particularly beneficial to learners with hearing loss who use American Sign Language (ASL).  
 
 
EFFECTIVE TEACHING STRATEGIES AND STUDY HABITS ON  
STEM SKILLS IN LEARNERS WITH HEARING LOSS 
 
As stated earlier, parents of children with hearing loss should be supported to understand 
these children’s developmental needs. With this understanding, they could take actions that 
can lay the foundation for the development of STEM knowledge and skills in their children, 
for example, by learning how to communicate meaningfully with their children. Ultimately, 
these children will attend schools, pre-kindergarten (PK) to colleges and universities, where 
they must acquire deeper STEM knowledge and skills.  
Do teachers of learners with hearing loss possess the knowledge and skills to effectively 
impact STEM knowledge and skills to these learners? This has been and remains an important 
issue in educating learners with hearing loss. With the enactment of legislation promoting 
education of learners with hearing loss and other special needs in regular schools in the 
United States and other Western countries, majority of learners with hearing loss attend 
regular schools, colleges and universities (Marschark, Sapere, Convertino, & Pelz, 2008). It 
could be the case that learners with hearing loss will need the support of sign language 
interpreters or captioning and real-time writers in the regular classroom. Concerns remain that 
even with these supports, learners with hearing loss in inclusive classrooms may be learning 
less than their hearing peers (see for example, Marschark, Sapere, Convertino, Seewagen, & 
Maltzen, 2004). 
Experiments conducted by Marschark et al. (2008) indicated that the quality of 
instruction in terms of accessibility of the material offered to learners with hearing loss in 
inclusive environments is critically important to how well these students will understand and 
learn the materials. Given that learners with hearing loss may come to the classroom with 
lower literacy, metacognition, memory and problem-solving challenges when compared to 
their normally hearing peers, Marschark, et al. (2008) suggested that to effectively impact the 
desired knowledge and skills to learners with hearing loss, instructors will have 
“…exceptional teaching skills beyond their familiarity with the academic abilities and diverse 
learning styles of deaf students” (p. 558). The question then arises: Do teachers of learners 
with hearing loss at the various levels of education possess such exceptional teaching skills? 
Data to address this question are scarce. 

C. Jonah Eleweke 
46
Given that the majority of teachers at the various levels of education in inclusive settings 
may possess very little or no background training and experience in the methods of educating 
learners with hearing loss, it could be argued that very few teachers in inclusive settings 
possess such exceptional teaching skills. The implication of this could be that strategies to 
share information and skills about effective methods for teaching learners with hearing loss 
will have to be made available to teachers in the regular schools through various in-service 
training, seminars and workshops on a continuous basis.  
Learners ultimately must take responsibility for their learning as they advance through 
the various levels of education. At the early stages PK – middle grades, a lot of support will 
be required from the parents or guardians. As learners advance through the various levels of 
learning, they will need to develop effective study habits in order to learn materials properly, 
and acquire the necessary knowledge and skills. Sulman and Naz (2012) have argued that 
effective study habits hold the key to the success of learners with hearing loss in acquiring 
STEM knowledge and skills. While the literature is replete with tips for effective study habits 
such as having regular times for study, studying in conducive environments, knowing how to 
make the best use of resources, making and reviewing notes, etc., the question remains: What 
is known about the study habits of learners with hearing loss? Data to answer this question are 
scanty. Learners with hearing loss are different in their degrees of hearing loss, family 
background, and experiences. Study habits are difficult to examine because as Marchark, 
Sarchet, Convertino, Borgna, Morrison, and Remet (2012) pointed out it is difficult to 
determine the veracity of responses to questions on this very personal issue. Nonetheless, 
evidence indicates that personal factors such as the ability to make effective use of resources 
such as support services, tutors, interpreters, student peers, and faculty could contribute to the 
success of students with hearing loss in institutions of higher education (Albertini, Kelly, & 
Matchett, 2012). Interestingly, areas of weaknesses identified by the deaf students involved in 
Albertini, et al. (2012) study include their inabilities to prepare for classes, manage their time, 
concentrate on assignments, identifying important information, preparing for tests and 
anxiety, motivation, and attitude.  
According to Albertini et al. (2012) deaf “students reported high levels of academic 
difficulty compared to the national norms. They also expressed concern about their study 
habits, lower levels of verbal confidence, lower motivation to finish college, and less than 
positive attitudes toward teachers compared to the national norm group of typical entering 
college students” (p. 99). This implies that deliberate efforts must be made by schools and 
other educational authorities to explore strategies that will help learners with hearing loss to 
be aware of their own responsibilities for success in STEM and other areas of academics. 
Despite availability of abundant technological resources, personal effort is essential to acquire 
knowledge and develop mastery. It is suggested that adults with hearing loss who are 
successful in STEM should be identified in the communities.  
There are certainly such people. With proper planning, it may be possible for such people 
to visit educational programs where learners with hearing loss are studying. Meeting, 
discussing with the students, and responding to their questions could inspire and motivate the 
students to cultivate the personal habits that will ensure their success in acquiring STEM 
knowledge and skills. 
 
 

Working with Learners with Hearing Loss in STEM 
47
CONCLUSION 
 
Supporting learners with hearing loss to be successful in STEM must begin immediately 
following the diagnosis of hearing loss. Given that the vast majority of parents of young 
children with hearing loss have no previous experience of raising such children, the starting 
point of the effort to ensure children with hearing loss develop STEM knowledge and skills 
must be the provision of unbiased and clear information and support to their families. This is 
necessary to assist the parents and other family members make the necessary adjustments to 
raising the child with hearing loss. With unbiased and clear information and appropriate 
supports, the parents could learn about all the resources that could facilitate the raising of 
their children with hearing loss available to them in the communities. Consequently, they will 
be aware of their responsibilities in ensuring the success of early intervention programs for 
the benefit of their children with hearing loss. Research suggests that timely instigation of 
early intervention programs will ensure that children with hearing loss achieve the same 
milestones in language development like their hearing peers. Poor literacy skills is one of the 
greatest challenges to learning STEM materials by learners with hearing loss. Thus the goal 
of early intervention programs is to ensure these children are successful in language 
development. In this context ‘language’, means whatever mode of communication that works 
for each young person with hearing loss. While a few may, with technology such as cochlear 
implants, and extensive speech and language therapy services, develop spoken language 
skills, the majority of children with hearing loss may not develop such language skills 
regardless of the technologies and services provided. It is very important that professionals in 
the field provide unbiased and clear information about all the issues in language development 
of children with hearing loss to their parents. Spoken language is one form of communication. 
Using manual methods is yet another. The focus must be that the method of communication 
that is effective with children with hearing loss is consistently used at home and school. This 
will foster learning and enrich the child’s conceptual store. With a consistent medium to 
communicate and learn, the child with hearing loss will be able to make progress in all 
aspects of development including acquiring STEM knowledge and skills. 
Progress in science and technology is resulting in the development of programs and 
software rich with visual effects – videos, animations, subtitles, 3-D, etc., that can facilitate 
the acquiring of STEM knowledge and skills by learners with hearing loss. Nonetheless, 
given that the majority of children with hearing loss live at homes and attend regular schools 
due to legislative mandates, it remains a concern whether the teachers in inclusive classrooms 
are able to utilize these technological resources for the benefit of learners with hearing loss. 
Many of these teachers may have very little or no background knowledge about educating 
children with hearing loss and the special ICT resources that could enhance their education. 
In a very large class in a regular classroom there may be just one or two learners with hearing 
loss. These students may have a sign language interpreter. The interpreter is a professional 
trained to facilitate communication between the teacher and students with hearing loss and 
not a ‘teacher’. It remains the task of the teacher to ensure that learners with hearing loss 
access and comprehend the materials being taught. It is imperative that general education 
classroom teachers should be made aware of these technological resources that can facilitate 
the acquisition of STEM knowledge and skills in learners with hearing loss. This can be 
achieved by regularly conducting in-service training for these teachers by experienced 

C. Jonah Eleweke 
48
teachers of learners with hearing loss. It is possible that through this activity, teachers in 
inclusive programs will become very aware of the unique needs of students with hearing loss 
in their classrooms and always plan to address such needs. Otherwise, there is real danger that 
the needs of learners with hearing loss in inclusive classrooms will not be met. Consequently, 
acquiring the knowledge and skills in STEM and other academic areas will be problematic. 
Finally, as learners with hearing loss advance through the various levels of education, it 
may be necessary for them to be provided mentors who will be working with them and 
reinforcing the development of effective study skills. Intrinsic motivation is necessary for 
academic success. Thus some learners with hearing loss may benefit if they have mentors 
who check-in with them, discuss their challenges and progress. Especially beneficial will be 
mentors who are successful in STEM and who have hearing loss themselves. These will make 
wonderful role-models as well as inspire and encourage young learners with hearing loss. It 
may be the case that education authorities will set up a program focused at identifying such 
successful role-models with hearing loss. With proper planning, many of such people may be 
glad to visit schools, meet and discuss with learners with hearing loss on a voluntary basis. 
Taken together, learners with hearing loss can, with the appropriate supports starting 
immediately after the diagnosis of hearing loss, acquire STEM knowledge and skills. History 
is replete with successful people in these fields who had hearing loss. Given continuing 
progress in science and technology and development of innovative, user-friendly, multi-media 
educational programs and materials almost on a daily basis, learners with hearing loss can be 
very successful in acquiring STEM knowledge and skills and be able to contribute to the 
development of society. 
 
 
REFERENCES 
 
Adamo-Villani, N., & Wilbur, R. (2010). Software for math and science education for the 
deaf. Disability and Rehabilitation: Assistive Technology, 5(2), 115-124. 
Albertini, J. A., Kelly, R. R., & Matchett, M. K. (2012). Personal factors that influence deaf 
college students’ academic success. Journal of Deaf Studies and Deaf Education, 17(1), 
85-101. 
Blatto-Vallee, G., Kelly, R. R., Porter, J., & Fonzi, J. (2007).Visual-spatial representation in 
Mathematical problem solving by deaf and hearing students. Journal of Deaf Studies and 
Deaf Education, 12(4), 432-448. 
Borum, Y. (2012). Perceptions of communication choice and usage among African American 
hearing parents: Afrocentric cultural implications for African-American deaf and hard of 
hearing children. American Annals of the Deaf, 157(1), 7-15. 
Calderon, R. (2000). Parents’ involvement in deaf children’s education programs as 
predictors of child language, early reading, and social-emotion development. Journal of 
Deaf Studies and Deaf Education 5, 140–155. 
Coppens, K. M., Tellings, A., Schreuder, R., & Verhoeven, L. (2013). Developing structural 
model of reading: The role of hearing status in reading developing over time. Journal of 
Deaf Studies and Deaf Education, 18(2), 1-24. 

Working with Learners with Hearing Loss in STEM 
49
Davila, R. R. (2004). Reviewing the past, assessing the present, and projecting the future. In 
D. Powers, & G. Leigh, (Eds.) Educating deaf children: Global perspective, pp 3–12. 
Washington, DC: Gallaudet University Press. 
Deaf Scientists Corner. (2013). Deaf scientists’ corner: A website devoted to the biographies 
of famous deaf scientists. Retrieved from: http://www.twu.edu/dsc/index.htm  
Debevc, M., & Peljhan, Z. (2004).The role of video technology in on-line lectures for the 
deaf. Disability & Rehabilitation 26(17), 1048-1059.  
Eleweke, C. J., Bays, D., Gilbert, S., & Austin, E. (2008). Information about support services 
for families of young children with hearing loss: A review of some useful outcomes and 
challenges. Deafness and Education International, 10(4), 190 -212. 
Fulcher, A., Purcell, A. A., Baker E., & Munro, N. (2012). Listen up: Children with early 
identified hearing loss achieve age-appropriate speech/language outcomes by 3 years-of-
age. International Journal of Pediatric Otorhinolaryngology 76(12), 1785-1794.  
Gomez, G. M., Piehota, L. D., & Dischner, R. R. B. (2012). Providing a program to meet the 
needs of toddlers with hearing loss and deafness. Perspectives on Hearing & Hearing 
Disorders in Childhood. 22(1), 4-10. 
Holzinger, D., Fellinger, J., & Beitel, C. (2011). Early onset of family-centered intervention 
predicts language outcomes for children with hearing loss. International Journal of 
Pediatric Otorhinolaryngology, 75(2), 256-260. 
Hyde, M. B., & Power, D. J. (2003). Characteristics of deaf and hard of hearing students in 
Australian regular schools: Hearing level comparisons. Deafness & Education 
International, 5, 133-143. 
Jackson, C. W. (2011). Family supports and resources for parents of children who are deaf or 
hard of hearing. American Annals of the Deaf, 156(4), 343-362. 
Jamison, J. R., Zaidman-Zait, A., & Poon, B. (2011). Family support as perceived by parents 
of preadolescents and adolescents who are deaf or hard of hearing. Deafness & Education 
International, 13(3), 110-130. 
Kasai, N., Fukushima, K., Omori, K., Sugaya, A., & Ojima, T. (2012). Effects of early 
identification and intervention on language development in Japanese children with 
prelingual severe to profound hearing impairment. The Annals of Otology, Rhinology & 
Laryngology. Supplement, 202, 16-20. 
Marschark, M. (2007). Raising and educating a deaf child: A comprehensive guide to the 
choices, controversies, and decisions faced by parents and educators. New York: Oxford 
University Press. 
Marschark, M., Lang, H. G., & Albertini, J. A. (2002). Educating deaf students: From 
research to practice. New York: Oxford University Press. 
Marchark, M., Sarchet, T., Convertino, C. M., Borgna, G., Morrison, C., & Remet, S. (2012). 
Print exposure, reading habits, reading achievement among deaf and hearing college 
students. Journal of Deaf Studies and Deaf Education, 17(1), 61-74. 
Marschark, M., Sapere, P., Convertino, C., & Pelz, J. (2008). Learning via direct and 
mediated instruction by deaf students. Journal of Deaf Studies and Deaf Education, 
13(4), 546-561. 
Marschark, M., Sapere, P., Convertino, C., Seewagen, R., & Maltzen, H. (2004). 
Comprehension of sign language interpreting: Deciphering a complex task situation. Sign 
Language Studies, 4, 345-368.  

C. Jonah Eleweke 
50
McKay, S., Gravel, J. S., & Tharpe, A. M. (2008). Amplification considerations for children 
with minimal or mild bilateral hearing loss and unilateral hearing loss. Trends in 
Amplification, 12(1), 43-54. 
Mitchell, R. E., & Karchmer, M. A. (2004). Chasing the mythical ten percent: Parental 
hearing status of deaf and hard of hearing students in the United States. Sign Language 
Studies, 4(2), 138-163. 
Moores, D. F. (2010). Epistemologies, deafness, learning and teaching. American Annals of 
the Deaf, 154(5), 447-455. 
Mukuria, G. M., & Eleweke, C. J. (2010). Educating children with deafness and hearing 
impairments. In: P. Penelope, B. Eva, & M. Barry, (Eds.), International encyclopedia of 
education, 2, 628-633. Oxford, England: Elsevier. 
Scheetz, N.A. (2012). Deaf education in the 21st Century: Topics and trends. Boston, MA: 
Pearson. 
Spencer, E. P., & Marschark, M. (2010). Evidence-based practices in educating deaf and hard 
of hearing students (Professional perspectives on deafness: Evidence and applications). 
New York: Oxford. 
Sulman, N., & Naz, S. (2012). Relationship between study habits of deaf students and their 
performance in general science. Interdisciplinary Journal of Contemporary Research in 
Business, 3(12), 489-495. 
Turnbull, A. P., & Turnbull, H. R. (2006). Families and exceptionalities, 5th edition. Upper 
Saddle River, NJ: Pearson/Merrill/Prentice Hall. 
Turnbull, A. P., Turnbull, A., Shank, M., & Smith, S. J. (2004). Exceptional lives: Special 
education in today’s schools, 4th edition. Upper Saddle River, NJ: Pearson/ 
Merrill/Prentice-Hall. 
Vosganoff, D., Paatsch, L. E., & Toe, D. M. (2011). The mathematical and science skills of 
students who are deaf or hard of hearing educated in inclusive settings. Deafness & 
Education International, 13(2), 70-88. 
Yoshinaga-Itano, C. (2004). Levels of evidence: universal newborn hearing screening 
(UNHS) and early hearing detection and intervention systems (EHDI). Journal of 
Communication Disorders 37, 451–465. 
 
 
 

In: Encyclopedia of Audiology and Hearing Research 
ISBN: 978-1-53617-702-2 
Editors: Erno Larivaara and Senja Korhola 
© 2020 Nova Science Publishers, Inc. 
 
 
 
 
 
 
 
Chapter 4 
 
 
 
HEARING AND COGNITIVE OUTCOMES  
OF COCHLEAR IMPLANTATION IN THE ELDERLY 
 
 
L. Girasoli, A. Benatti, R. Bovo and A. Martini 
ENT Department, University Hospital of Padua, Italy 
 
 
ABSTRACT 
 
At the present time, 50 to 60% of the population above 70 years of age suffers from a 
hearing impairment and from 0.6 to 1.1% has a severe to profound loss, which cannot 
benefit from an hearing aid. Moreover, it is expected that this prevalence will grow by 
more than two-fold in the next 40 years. There is strong evidence that hearing loss in 
older adults is associated with both cognitive load and social isolation, which in turn, are 
associated with cognitive and physical functioning. Cochlear implant (CI) dramatically 
improves sound audibility and speech understanding. The aim of this paper was to 
analyze outcome and complications of CI treatment in elderly patients. 
A retrospective study on 25 patients, aged at implantation between 65 and 79 years 
(mean = 70.03 ± 3.53), unilaterally implanted for severe to profound bilateral hearing 
loss. The following data were statistically evaluated: pre-implant pure-tone threshold and 
tests of speech recognition, both with hearing aid that without; post-implant threshold and 
speech perception with CI off and on. Moreover, statistical correlations of PTA 
improvement between two age groups (65 to 70 and over 70 years) were carried out. 
Mean PTA improved from 113.86 (pre-implant) to 41.78 (post-implant); and the 
mean SRT improved from 90 dB to 56.06 dB. Moreover there was no statistical 
difference in PTA improvement between the two age groups (65 to 70 and over 70 years).  
The comparison between speech perception threshold and cognitive-motivational 
status shows negative correlation with the cognitive test and, but a positive correlation 
with the depression test. 
In the elderly, CI is a safe procedure that significantly improves hearing threshold 
(p<0.01) and speech perception (p<0.01). Support of family and professionals, as well as 
duration of deafness and pre-implant scores greatly influence the results of rehabilitation 
and its perceived benefit. CI should not be denied in older individuals who are otherwise 
in good health. 
                                                        
 Corresponding Author’s: Email: roberto.bovo@sanita.padova.it 

L. Girasoli, A. Benatti, R. Bovo et al. 
 
52
Keywords: cochlear implant, hearing loss, elderly, cognitive deterioration 
 
 
LIST OF ABBREVIATIONS 
 
CI 
Cochlear Implant 
PTA 
Pure Tone Average 
SDT 
Speech Detection Threshold 
SRT 
Speech Recognition Threshold 
MOCA 
Montreal Cognitive Assessment 
GDS 
Geriatric Depression Scale 
 
 
INTRODUCTION 
 
At the present time, 50 to 60% of the population above 70 years of age suffers from a 
hearing impairment and from 0.6 to 1.1% [1,2] has a severe to profound loss, which cannot 
benefit from an hearing aid. Moreover, it is expected that this prevalence of hearing loss in 
the elderly will grow by more than two-fold in the next 40 years.  
Presbycusis has been attribuited to degeneration of a component of the auditory system, 
both central and peripheral. The peripheral location of damage can be sensory epithelium, 
spiral ganglion or stria vascularis; Schuknecht proposed a classification system with three 
major forms of age-related loss-hearing, namely sensory, neural, and strial presbycusis. [3] 
The central pathways of the auditory system are frequently involved with a slowdown of 
the information transmitted; the less the quality of the peripherycal data is detected, the more 
the processing at the central level has distortions. 
Profound hearing loss among the elderly people is responsible for a significant reduction 
in quality of life due to social isolation, increased dependence, anxiety and depression that 
may contribute to the worsening of the cognitive and physical functions [4]. Auditory 
rehabilitation of the profound hearing impaired elders is important and, to date, cochlear 
implantantion is the most effective procedure. 
Individuals with a mild, moderate and severe hearing loss had a two-, three-, and five-
fold increased risk of developing incident dementia, respectively, compared to normal-
hearing individuals [4]. Moreover, analyses of the association of hearing loss with self-
reported falls demonstrated that a 10 dB increase in hearing loss was associated with a 1.4 
fold increased odds of having a fall. A 25 dB hearing loss was associated with a nearly three-
fold increased odds of a fall over the preceding year. These results were substantively 
unchanged after adjusting for demographic and cardiovascular risk factors as well as 
vestibular balance function [5].  
It is well demonstrated that cochlear implant (CI) dramatically improves sound audibility 
and speech understanding for the elderly patients, similarly to the young implanted patients. 
CI was a significant surgical innovation in the 20th century and represented the first artificial 
sensory organ applied in clinical medicine.  
It was previously thought that CI in the elderly may not be beneficial because of age-
related degeneration of both the central and peripheral auditory systems, surgical risk, and 

Hearing and Cognitive Outcomes of Cochlear Implantation in the Elderly 
 
53
overall cost to benefit ratio. However, recent studies have shown that this procedure improves 
auditory performance, is well tolerated even in the most elderly, enhances self-confidence, 
reduces in most cases tinnitus and stress and increases the health-related quality of life. The 
risk of anesthetic and surgical complications remains low provided that a through 
multidisciplinary evaluation is performed before the procedure.  
The cost-effectiveness still remains acceptable, including patients over 70 [6] because 
even if healthcare costs are high, the savings in terms of indirect costs and quality of life are 
important. Among patients with pre-implant severe tinnitus, a partial or total tinnitus 
reduction was observed in 70% of cases [7].  
Aim of this study was to evaluate audiological and cognitive outcomes in a group of 25 
elderly subjects with cochlear implant. 
 
 
METHODS 
 
This is a retrospective study of 25 consecutive post-lingual, profoundly hearing impaired 
elderly adults selected among the overall 376 patients who were implanted at Padua ENT-Ear 
Surgery Department between May 2010 and February 2014. Selection criteria were age ≥ 65 
yrs at surgery and unilateral implantation. Pre-implant evaluation consisted of pure-tone 
audiometry and tests of speech recognition, both with hearing aid that without. Post-implant 
evaluation included the same tests with CI off and on, carried out with free field stimulation 
in a sound proof booth. Threshold evaluation were conducted by using pure-tone average 
(PTA), that is the mean of the air-conduction thresholds at 500, 1000 and 2000 Hz. On the 
other hand, in the analyses of speech perception we considered the Speech Detection 
Threshold (SDT) and Speech Recognition Threshold (SRT). SDT corresponds to the value of 
sound intensity at which the verbal message is not understood but perceived as generic sound, 
therefore with a percentage of intelligibility of 0%. The SRT indicates the level of intensity at 
which the patient correctly repeats 50% of the words. 
Cognitive functions and motivational status were assessed using the MOCA (Montreal 
Cognitive Assessment) and GDS (Geriatric Depression Scale) tests.  
The results obtained were correlated with post-implantation PTA (pure tone average 500-
1000-2000 Hz) and speech perception threshold (50% of speech recognition). We also 
correlated MOCA and GDS scores obtained among cochlear implant users. 
Surgical outcome looked at the presence of any medical or surgical complication related 
to the implant surgery or to the age of these patients. Furthermore, the personal satisfaction 
degree was evaluated with a specific questionnaire developed at our clinic.  
 
 
RESULTS 
 
Our sample is composed by 25 patients (13F - 12 M) aged at implantation between 65 
and 79 years (mean = 70.03 ± 3.53), that represents a 6.6% of our cochlear implantations 
during the considered period. Based on our experience, with respect to younger CI-recipients, 
this group of elderly had a higher incidence of associated comorbidities such as arterial 
hypertension, cardio-vascular diseases, usage of anticoagulants. Despite this, no surgical 

L. Girasoli, A. Benatti, R. Bovo et al. 
 
54
events or complications with the anesthesia were observed and there was no need for 
additional intensive postoperative care. 
The duration of hearing loss ranged from 1 to 50 years: 12 patients were deaf from ≤15 
years and 13 were deaf from >15 years. The etiology was unknown in the majority of cases 
(52%), while the most frequent known cause was otosclerosis (32 %).  
 
Table 1. General information of implanted patients 
 
Patient 
Sex 
Age implant 
(years) 
Date implant 
Side 
Aetiology 
Duration 
hearing loss 
(years) 
1 
M 
66 
28/05/2010 
L 
otosclerosis 
15 
2 
F 
72 
05/11/2010 
L 
unknown 
10 
3 
M 
70 
07/12/2010 
R 
unknown 
15 
4 
M 
68 
18/03/2011 
R 
trauma 
1 
5 
F 
72 
05/04/2011 
L 
unknown 
9 
6 
F 
77 
19/05/2011 
L 
unknown 
45 
7 
F 
72 
22/07/2011 
R 
unknown 
30 
8 
M 
71 
14/09/2011 
R 
otosclerosis, trauma 
8 
9 
F 
73 
02/11/2011 
L 
unknown 
30 
10 
F 
67 
29/02/2012 
L 
neurinoma, trauma 
30 
11 
M 
72 
13/03/2012 
L 
unknown 
15 
12 
F 
66 
25/07/2012 
L 
otosclerosis 
40 
13 
F 
66 
07/09/2012 
L 
otosclerosis 
15 
14 
M 
69 
17/10/2012 
L 
otosclerosis 
30 
15 
M 
79 
05/10/2012 
R 
unknown 
50 
16 
M 
65 
08/02/2013 
R 
streptomycin 
50 
17 
F 
73 
27/02/2013 
R 
unknown 
18 
18 
M 
65 
18/04/2013 
R 
unknown 
15 
19 
M 
67 
18/07/2013 
L 
otosclerosis, neurinoma 
10 
20 
F 
70 
20/09/2013 
L 
otosclerosis 
30 
21 
F 
72 
27/09/2013 
L 
unknown 
13 
22 
M 
72 
17/10/2013 
R 
otosclerosis 
40 
23 
M 
69 
13/12/2013 
R 
unknown 
50 
24 
F 
70 
12/02/2014 
L 
unknown 
30 
25 
F 
68 
13/02/2014 
L 
device-failure 
15 
 
First examination occurred one month after initial switch-on and programming of the 
speech processor (“activation”), followed by a second exam at 4 months, then at 7,11 and 15 
months. Many of our elderly patients expressed initial disappointment, during the first switch-
on session, mainly due to the novel sound quality provided through the electrical stimulation, 
but also due to the initial lack of benefit. However, all patients have adapted and over time 
becoming regular daily CI users.  
PTA values were compared between pre- and post-implant exams demonstrating a 
significant improvement with CI. 

Hearing and Cognitive Outcomes of Cochlear Implantation in the Elderly 
 
55
 
Figure 1. Pre- and post-operative PTA (P1=pre-op, side implanted; P2=pre-op, free field without 
hearing aids; P3=pre-op, free field with hearing aids; A=post-op at activation; C1=post-op, 1st control; 
C2=post-op, 2nd control; C3=post-op, 3rd control; C4=post-op, 4th control; C5=post-op, 5th control). 
 
Figure 2. Pre- and post-implant mean speech detection threshold (SDT) and mean speech recognition 
threshold (SRT) (P2=pre-op, free field without hearing aids; P3=pre-op, free field with hearing aids; 
C1=post-op, 1st control; C2=post-op, 2nd control; C3=post-op, 3rd control; C4=post-op, 4th control; 
C5=post-op, 5th control). 

L. Girasoli, A. Benatti, R. Bovo et al. 
 
56
Also speech perception scores showed a significant improvement both in the detection 
threshold (SDT) that in perception threshold (SRT). These variables were analyzed using 
descriptive statistic, Student t test (P < .01) and Pearson test (P < .05). 
Dizziness was the most common temporary complication and was observed in 5 cases 
(20%). It was not correlated with the pre-op morbidities of the affected patients and was 
resolved within a few days in post-op for all cases. One transient-incomplete facial nerve 
weakness was found 3 days post-surgery and completely resolved in a few days. 
 
 
CONCLUSION 
 
Our results demonstrated that CI in older adults is a safe procedure, which significantly 
improves hearing threshold (p<0.01) and speech understanding (p<0.01). In particular, mean 
PTA improved in our patients from 113.86 (pre-implant) to 41.78 (post-implant); and the 
mean SRT improved from 90 dB to 56.06 dB. Our data are similar to those reported by 
Skarzynsky et al., [8] and by Luntz et al., [9], who evaluated an elderly population of similar 
age with respect to our(mean age at implantation respectively of 67.2 yrs and 66.7 yrs). In 
fact, these authorsobserved mean word recognition scores increasing respectively from 17% 
(pre-implant) to 66% (post-implant) and from 18% to 60%.By comparing these results with 
those of children and young adults implanted at our center during the same period, we 
observed that the elderly need a longer rehabilitative period, but eventually all of them were 
regular CI users and reached similar good results. Major post-CI complications were not 
encountered in this cohort. Post-implantation vertigo was not as significant as might be 
expected in this age group.  
The present pilot study shows a strongly negative correlation between MOCA and speech 
perception threshold and a weakly negative correlation between MOCA and age. 
Furthermore, the results obtained confirm a strongly negative correlation between MOCA and 
GDS, and a positive correlation between GDS and speech perception threshold, in terms of 
stimulation levels (dB SPL) necessary to achieve a 50% of speech recognition. 
The comparison between the MOCA scores and PTA values revealed a weakly positive 
correlation (Pearson= +0.31; p value= 0.68). The same correlation was found between GDS 
and PTA (Pearson= +0.31; p value= 0.68). 
In our experience, support of family and professionals, as well as duration of deafness 
and pre-implant scores greatly influence the results of rehabilitation and its perceived benefit. 
In conclusion, we strongly recommend that CI should not be denied in older individuals who 
are otherwise in good health. 
The preliminary results of the present study indicate that cochlear implant outcomes are 
better when cognitive and mental status of the patient is less deteriorated. Nevertheless, the 
correlation between age and cognitive assessment is not as strong as we expected. It’s 
reasonable to obtain good results even in very advanced age. The patient’s depression can 
affect both cognitive status and outcome with cochlear implant. The PTA seems to be 
important for the evaluation of cochlear implant positioning; nevertheless it is not sufficient 
for a good prediction of the speech recognition threshold. 
In conclusion, cochlear implantation has proven to be a safe procedure, with low 
morbidity and complication rate even in the elderly patients that can obtain a significant 

Hearing and Cognitive Outcomes of Cochlear Implantation in the Elderly 
 
57
improvement in the auditory performance and quality of life. Counseling, auditory 
rehabilitation, speech training, psychological motivations, family support, mental and 
cognitive status are important aspects that can influence the outcome of cochlear 
implantation. 
 
 
Competing Interests 
 
The authors declare that they have no competing interests. 
All the authors had given final approval of the version to be published. 
 
 
REFERENCES 
 
[1] 
Mosnier I. Cochlear Implant Outcomes in the Eldery (from the Cochlear Science and 
Research Seminar. Paris, France. March 19-20, 2012). Audiol. Neurootol. 2012 Jan;17 
Suppl 1:20–2.  
[2] 
Bovo R, Ciorba A, Martini A. Environmental and genetic factors in age-related hearing 
impairment. Aging Clin. Exp. Res. 2011 Feb;23(1):3–10.  
[3] 
Schuknecht HF, Gacek MR. Cochlear pathology in presbycusis. Ann. Otol. Rhinol. 
Laryngol. 1993 Jan;102(1 Pt 2):1–16.  
[4] 
Lin FR. Hearing loss and cognition among older adults in the United States. J. Gerontol 
A. Biol. Sci. Med. Sci. 2011 Oct;66(10):1131–6.  
[5] 
Lin FR, Ferrucci L. Hearing loss and falls among older adults in the United States. Arch 
Intern Med. American Medical Association; 2012 Feb 27;172(4):369–71.  
[6] 
Criteria of candidacy for unilateral cochlear implantation in postlingually deafened 
adults II: cost-effectiveness analysis. Ear. Hear. 2004 Aug;25(4):336–60.  
[7] 
Bovo R, Ciorba A, Martini A. Tinnitus and cochlear implants. Auris. Nasus. Larynx. 
2011 Feb;38(1):14–20.  
[8] 
Skarzynsk PH, Olszewskia L, Skarzynski H, Lorens A. Cochlear Implantation in the 
Aging Population. Audiol Neurotol. Karger Publishers; 2012 Aug 7;17(Suppl. 1):15–7.  
[9] 
Luntz M, Yehudai N, Most T, Shpak T. Cochlear Implantation in the Elderly: Surgical 
and Hearing Outcomes. Audiol. Neurotol. Karger Publishers; 2012 Aug 7;17(Suppl. 
1):14–5.  
 
 


In: Encyclopedia of Audiology and Hearing Research 
ISBN: 978-1-53617-702-2 
Editors: Erno Larivaara and Senja Korhola 
© 2020 Nova Science Publishers, Inc. 
 
 
 
 
 
 
 
Chapter 5 
 
 
 
EFFECTS OF IMPULSE NOISE ON HEARING  
IN MEMBERS OF THE POLICE SPECIAL 
OPERATIONS BATTALION 
 
 
Adriana Betes Heupa, Cláudia Giglio de Oliveira Gonçalves,  
Evelyn Joice Albizu and Adriana Bender Moreira de Lacerda 
 
 
ABSTRACT 
 
This chapter presents a study of members of the Military Special Operations 
Battalion. This study, aiming for the deployment of a Hearing Preservation Program, 
analyzed the effects of impact noise on the hearing of military personnel who regularly 
conduct shooting practice. It was a case-control study with 115 military personnel, with 
65 being exposed to noise from firearms and 50 not being exposed. Assessment of noise 
emitted by firearms was performed during shooting practice was carried out, and research 
on the knowledge about hearing health was measured. Pure tone audiometry and 
(transient and distortion product) otoacoustic emissions testing was also conducted. The 
results show that the level of noise emitted by firearms exceeds the limits established by 
regulatory standards. Also it was shown that despite the military personnel’s having 
knowledge as to the importance of using hearing protection when exposed to weapons 
noise, many never received guidance on its proper use. And there are still significant 
differences in the hearing of those exposed to firearms noise when compared to those 
who are unexposed. For this population, it is necessary to implement a Hearing 
Preservation Program with the goal of not only to avoid hearing loss, but also to educate 
these military personnel on the importance of proper use of hearing protection and other 
hearing care issues.  
 
 
INTRODUCTION 
 
The main characteristic of the military profession is to live with risk, whether in training, 
daily life, or war. These professionals are subject to the strict precepts of hierarchy and 
discipline, absolute dedication, continuous availability, physical force, and constant 

Adriana Betes Heupa, Cláudia Giglio de Oliveira Gonçalves et al. 
 
60
professional improvement. Even during inactivity and paid reserve time, military 
professionals remain bound to their profession and ready to serve upon being summoned to 
return to active duty, despite restrictions on labor rights [1].  
In Brazil, after graduation from training, soldiers are placed in military units within the 
federal states, according to their characteristics and specialties. One is the Special Operations 
Battalion (BOPE). This Battalion was formed in 1977, originally named Company of Riot 
Police. It was remodeled in 1988 and went on to perform specialized police actions, being 
subdivided into three units: K9 (in charge of police dogs and search training), Special 
Operations Command (COE) and Specialized Public Patrols (RONE) [2].  
RONE is prepared to combat violent crime such as robbery, kidnapping and drug 
trafficking. It uses midsized cars, weapons and special equipment, and camouflaged uniforms. 
This subunit has the mission to control civil unrest, urban and rural guerrilla warfare, 
occupation, and the defense and recovery of sensitive locations. It operates in locations where 
there are higher rates of violent crime. It is high risk duty, with operations such as raids, 
blockades, escorts, and sieges. Comparatively, COE is a small group of police officers 
specially trained for hostage situations, situations involving heavily armed groups, or where 
there is a need for special equipment and weapons. It is a similar squad to U.S. SWAT 
(Special Weapons and Tactics), a period of training and selection is necessary. It consists of 
teams of negotiators (psychologists), assault police (location and identification), snipers, and 
bomb disposal personnel [2].  
When the personnel enter the Brazilian military, regardless of the unit in which they will 
serve, they must take the Shooting for Police course, which teaches the use of firearms. 
Taught in the course are theoretical concepts and definitions of arms and weapons, weapon 
types, ignition systems, weapons operation, and the characteristics of each weapon [3].  
There is also a number of hours required for shooting practice, which varies with each 
course or each state. In the course of military personnel training in the State of Paraná, for 
example, over the three-year course, trainees log a total of 120 hours of classroom instruction 
and 160 hours of shooting practice [4].  
In the disciplines of “Shooting for Police”, taught in the various courses of the Military 
Police of Paraná, shooting instructors are responsible for all theory and practice. In 2009, a 
book was published with some specifications addressed in disciplines such as the history of 
firearms, safety rules, generalities and types of weapons, ammunition, explosives, chemical 
weapons, shooting accidents, personal protective equipment (basic equipment, bullet-proof 
vests, helmets, shields, and vehicles) and police equipment (holster, belt, baton, handcuffs, 
knives, etc.) [5].  
With regard to personal safety, one of the rules is to always use personal protective 
equipment during training. This equipment is mandatory by all who are participating in 
shooting instruction, for students as well as assistants and instructors. The devices mentioned 
are: goggles, earmuffs, and bullet-proof vests. Gloves, knee pads, elbow pads, helmets and 
gas masks are not mandatory.  
In the internal arms manual used in the training course for military police officers in the 
state of Paraná, some guidelines are given regarding earplugs as protection from exposure to 
loud noise [6]:  
 
 
The placement, size and fit of hearing protectors should be comfortable.  
 
Use with glasses or other equipment can prejudice the seal with the face.  

Effects of Impulse Noise on Hearing in Members… 
 
61
 
Earplug scan be moved or misplaced while shooting practice or even due to jaw 
movement.  
 
Deterioration of the ear protector, which is natural, with cracks or hardening of the 
plastic parts.  
 
Wear of the hearing protector pads, which can make the device loose, damaging the 
noise seal. Frequent inspections are necessary to prevent degradation of attenuation.  
 
Ear protectors must be worn during all instruction.  
 
These topics are passed on to the trainees, emphasizing the need to keep their hearing 
intact, because of the daily dangers that officer’s face. In this way, it is necessary for the 
police officers to become aware of the importance of safety by breaking with some beliefs 
that associate the use of hearing protection as weakness, this behavior being a cause of bias in 
the military [6].  
Upon entry into the military, the officer does not have laws or regulations that require 
them to perform periodic medical examinations. They are only done when conducting 
ongoing training or postgraduate specializations for promotion. In the selection for inclusion 
in the COE, for example, one of the medical examinations required for admission is to have a 
hearing exam by audiometry. The exam, however, need not be conducted by military police, 
and may be done elsewhere.  
Most of the courses and competitions for the military police always require an audiogram 
as a necessary condition [7]: 
 
“(...) suitable candidates are those who are experiencing hearing loss in either ear of up to 20 
dB HL at frequencies of 500Hz and 1000Hz; 30 dB HL at a frequency of 2000 Hz and 35 dB 
HL at frequencies of 3000 to 8000 Hz, for air and bone conduction.” (Item No. 14.1.12) 
 
Hearing is considered important for entry into a military career, however, there is need 
for greater attention to hearing health during military that career, especially for those who are 
exposed to firearms noise, such as members of the Military Special Operations Battalion. This 
is because periodic medical examinations do not require auditory exams.  
 
 
STUDY ON HEARING OF THE MILITARY POLICE  
 
The study was conducted with police officers belonging to BOPE (exposed group) and 
compared with the administrative sectors of the Military Police of Paraná (non-exposed 
group).  
Administrative sectors make up a large part of the Military Police force, with about five 
thousand personnel distributed among the units. BOPE currently has approximately 250 
members, with 23 members in the COE.  
The sample consisted of 115 police officers, divided into two groups.  
Exposed group: 65 members of the riot police (43 from RONE doing shooting practice 
once a month or less, and 22 from COE that doing shooting practice weekly or fortnightly). 
There was no significant difference between average age and average hearing thresholds of 
these two subgroups.  

Adriana Betes Heupa, Cláudia Giglio de Oliveira Gonçalves et al. 
 
62
Non-exposed group: 50 military personnel who work in administrative sectors of the 
Military Police force. These officers had not been exposed to firearm noise for more than 
twelve months.  
The mean age of the exposed group was 32.2 (23-44) with a mean of 9.1 years of service 
(1-25 years). The subjects of the non-exposed group had a mean age of 33 (23-46) with a 
mean of 11.1 years of service (1-24 years). There was no significant difference when 
comparing the groups in age (p = 0.5165) and length of service (p = 0.1136).  
 
 
RESEARCH PROCESS 
 
The research was divided into 3 stages: (1) an assessment on the noise level for the 
weapons used, (2) a survey on the knowledge of the officers regarding the preservation of 
hearing health, and (3) an evaluation of the auditory profile of police officers exposed to 
impact noise, comparing this group with police not exposed to noise.  
 
 
1) Noise Level for Firearms  
 
The noise measurement for the weapons used by BOPE was performed in a training 
facility, both outdoors and indoors (in a bunker made of tires) (Figures 1 and 2). 
The evaluation was performed with a Bruel&Kjaer sound level meter model 2230 and 
adjusted to perform the measurements of the peak level, on the C weighted, fast response, 
linear, and impulse settings. With the microphone placed inside the auditory zone of the 
shooter.  
The assessment of the noise level reached the maximum limits of the equipment when 
measured in linear mode (peak dB SPL). For the dB (C) mode, the response for impact had a 
variation from 119 to 133dB (C).  
The levels found are similar to the literature, ranging from 113 to 147dB (C) [8-11]. 
These results exceed the limits of Norm 15 indicating the tolerance threshold for impact noise 
intensity as 120 dB (C), and also the maximum number of impacts per hour, taking into 
account the intensity, is much higher than advised by the Standards for Occupational Hygiene 
by Fund a centro, which does not tolerate exposures above 127dB (C) [12-13]. 
 
 
Figure 1. Noise measurement .40 pistol. 

Effects of Impulse Noise on Hearing in Members… 
 
63
 
Figure 2. Bunker made of tires and a Grenade. 
 
 
2) Knowledge about Hearing Health by Police Officers 
 
The police filled out a questionnaire with open and closed questions about their auditory 
history, auditory symptoms, and insights pertaining to hearing.  
Regarding the use of hearing protectors during shooting practice, most police officers 
always use hearing protection in shooting practice, with the plug-type models being the most 
commonly used, and which are purchased by the officers themselves, but are not specific to 
military use. It was also noted that many never received information on the use of these 
devices (Table 1).  
The hearing protectors provided by the force for use at marksmanship training sites are 
the earmuff type with no record of make, model or NRR (noise reduction level). They have 
no quality control or periodic evaluation on the effectiveness of these devices. Each police 
officer, however, has free choice to use any other protection that maybe acquired outside the 
force.  
In relation to police officer knowledge and perception about noise, the majority (92.3%) 
reported using hearing protection during shooting practice, and most use the plug type 
(70.7%).  
On the guidelines received about the use of hearing protection, most reviews said that the 
guidance received was superficial (38.4%), and 32.3% reported having never received 
guidance. When asked who directed the use of the ear protection, most reported receiving 
instructions from superiors (47.6%), while few reported having received information from 
specialized professionals (12.3%) (Table 1).Upon verifying the instruction received and the 
subsequent use of hearing protection, the effectiveness of such instruction is called into 
question because low frequency of use. 
The use of hearing protection is the responsibility of superiors, but its effectiveness 
depends on the military personnel exposed to noise. There are reports of the use of other 
devices that were not hearing protectors, such as fingers, cotton, and empty ammunition 
cartridges. The ability of these devices to act in preventing NIHL is questionable. Even the 

Adriana Betes Heupa, Cláudia Giglio de Oliveira Gonçalves et al. 
 
64
placement of hearing protectors is often inefficient to prevent damage to the auditory system, 
leading to permanent and progressive symptoms [8, 14].  
 
Table 1. Use of hearing protection for shooting practice by noise exposure group  
(n = 65) 
 
Hearing Protection 
Absolute Frequency (n) 
Relative Frequency (%) 
Frequency of use  
Always 
60 
92.30 
Usually 
3 
4.61 
Sometimes 
2 
3.97 
Type used 
Plugs 
46 
70.76 
Earmuffs 
7 
10.76 
Earmuffs + Plugs  
11 
16.92 
Use  
Shooting range practice 
46 
70.76 
Shooting range and outdoor practice 
15 
23.07 
All noisy situations 
12 
18.46 
Always when there is shooting 
5 
7.69 
Instructions given  
Never received 
21 
32.30 
Superficially  
25 
38.46 
Only when enlisting in the police 
8 
12.30 
Well instructed 
8 
12.30 
Periodic updates 
3 
4.61 
Instructor 
Military superiors 
31 
47.69 
Communication materials 
12 
18.46 
Specialized professionals 
8 
12.30 
 
It is recommended that every military officer have his own hearing protection equipment, 
as is the case with bullet-proof vests and helmets. It is known that there is a resistance in the 
military to the use of hearing protectors, especially in external service and in combat, and 
there is no motivation from military superiors to do so, since many believe that the use of 
hearing protection jeopardizes the safety of personnel [15, 16]. 
A survey of occupational risk management in the Brazilian Army found that the question 
of the use of hearing protection is addressed superficially and it is left to the responsibility of 
instructors to pass on, or not, the relevant information. Therefore it is up to the population that 
performs shooting practice, to have guidelines that are more meticulous about using hearing 
protectors [8].  
To check if there was knowledge about the hazards of noise exposure on hearing, there 
was an open question asking about what the effects of noise exposure on health for both 
BOPE members and to administrative services members. There was a significant difference 
(p = 0.0034) between the groups in terms of knowledge of the noise to cause hearing loss, 
showing greater knowledge in the population exposed to noise. This demonstrates that the 
exposed group has more contact with questions about noise, even being required to wear 

Effects of Impulse Noise on Hearing in Members… 
 
65
hearing protection during shooting practice. When asked about the best form of protection 
against noise, 96.9% of the exposed police officers reported that the use of hearing protectors 
is the best way, compared to 68% of the non-exposed group. There was a significant 
difference between the answers, and this difference justifies the increasing knowledge about 
the effects of noise on hearing for personnel who practice shooting (Table 2).  
 
Table 2. Comparison of knowledge of exposed (n = 65) and non-exposed (n = 50) officers 
on the effects of noise 
 
Answers 
Exposed Group (n=65) 
Non-exposed Group (n=50) 
Absolute 
Frequency (n) 
Relative 
Frequency (%) 
Absolute 
Frequency (n) 
Relative 
Frequency (%) 
Hearing loss 
51 
78.46 
26 
52.00 
Stress 
10 
15.38 
13 
26.00 
Headache 
4 
6.15 
5 
10.00 
Earache 
4 
6.15 
2 
4.00 
Sleep changes 
1 
1.53 
5 
10.00 
Depression 
1 
1.53 
0 
0.00 
Malaise/ dizziness 
1 
1.53 
0 
0.00 
Don’t know/don’t know how 
to respond 
8 
12.30 
14 
28.00 
No problem caused 
1 
1.53 
0 
0.00 
 
Table 3. Complaints of auditory and extra-auditory symptoms reported by the exposed 
(n = 65) and non-exposed (n = 50) groups. 
 
Symptoms 
Exposed Group  
(n=65) 
Non-exposed Group 
(n=50) 
Absolute Frequency (n) 
Relative Frequency (%) 
Absolute 
Frequency 
(n) 
Relative 
Frequency 
(%) 
Auditory 
Tinnitus 
10 
15.30 
9 
18.00 
Muffled hearing 
9 
13.80 
3 
6.00 
Difficulty hearing 
7 
10.70 
2 
4.00 
Dizziness 
4 
6.15 
4 
8.00 
Otalgia 
3 
4.60 
1 
2.00 
Extra-Auditory 
Headache 
13 
20.00 
1 
2.00 
Stress/Irritation  
10 
15.30 
6 
12.00 
Gastric problem 
9 
13.80 
8 
16.00 
Sleep problem 
8 
12.30 
5 
10.00 
Muscle pain 
4 
6.15 
4 
8.00 
Hypertension 
3 
4.60 
1 
2.00 
Lack of concentration  
2 
3.07 
2 
4.00 
Cholesterol 
2 
3.07 
3 
6.00 
 

Adriana Betes Heupa, Cláudia Giglio de Oliveira Gonçalves et al. 
 
66
Table 4. Auditory and extra-auditory complaints and symptoms stated by police shortly 
after shooting practice (n = 65) 
 
Symptom 
Absolute Freq. (n) 
Relative Freq. (%) 
No symptoms 
42 
64.60 
Tinnitus 
15 
23.00 
Temporary hearing loss 
5 
7.60 
Headache 
2 
3.07 
Irritation 
2 
3.07 
Ear already cleared 
1 
1.53 
 
As for auditory and extra-auditory symptoms commonly perceived by both the BOPE and 
administrative groups, no significant differences were observed between groups with respect 
to symptoms and complaints (Table 3). 
The most frequently reported auditory complaints were tinnitus and hearing difficulty, in 
quiet areas, as reported by personnel exposed to noise in this study [17-19]. 
Shortly after shooting practice, BOPE members reported symptoms and complaints. As 
shown in Table 4, the most frequent symptom was tinnitus, followed by temporary hearing 
loss.  
As seen, most of the exposed group claims touse hearing protection in all shooting 
practice (92.6%). If this result suggests efficiency in hearing protection, then there should not 
be hearing complaints after shooting practice (23%). It is known that the attenuation of a 
hearing protector depends not only on its physical characteristics, but also the person who 
uses it. Intermittent and inefficient use drastically reduces its effectiveness [20]. This 
statement agrees with a study of British soldiers which found that although all had knowledge 
about the effects of noise on hearing and the use of hearing protectors being the most used 
method to avoid these effects, many did not use it properly because they felt difficulties in 
communication, discomfort and an inability to use them in certain circumstances [21].  
The knowledge that police officers have about hearing health preservation is superficial, 
and it necessary to have an appropriate education program to raise awareness of hearing care.  
 
 
3) Auditory Profile of Police Officers 
 
For 
the 
hearing 
profile, 
the 
officers 
underwent 
pure 
tone 
audiometry 
(InteracousticsAD229b Audiometer) held in a soundproof booth (TDH39P headphones) at 
frequencies of 250 to 8000 Hz bilaterally and when necessary, bone conduction (B71bone 
vibrator) at 500 to 4000 Hz. Sensorineural hearing loss was considered for thresholds above 
25 dB HL [22].  
For transient evoked and distortion product otoacoustic emissions testing we used the 
Interacoustics Eclipse equipment. In transient evoked OAE (TEOAE) we adopted a pass/ fail 
criterion, presenting up to 1000 stimuli in the form of a click in each ear, at 75dB SPL, with a 
maximum noise level of 45dBSPL. As criteria for TEOAE, the algorithm for 3dB-bandwidth 
method was used in which reproducibility must be greater than 75% in at least 3 consecutive 
frequency bands with signal/ noise level minimum of 3dB. As for the distortion product 
otoacoustic emissions (DPOAE), the extended DP-gram method was used. The standard used 

Effects of Impulse Noise on Hearing in Members… 
 
67
for the examination was an intensity of L1-L2=10dB, with L1=65dB and L2=55dB; the f1/f2 
ratio = 1.22. The test lasted a maximum of 90 seconds. Frequencies used: F1: 819, 1639, 
2459, 3278, 4918, 6557 Hz and f2: 1000, 2000, 3000, 4000, 6000 and 8000 Hz. Distortion 
product was analyzed for frequencies of 638, 1278, 1918, 2556, 3836 and 5114Hz. The 
frequency of 500 Hz was not tested due to the level of noise present in the room that could 
mask the results. Distortion product otoacoustic emissions were considered present when they 
presented an amplitude greater than-10dB and with a signal/ noise difference greater than or 
equal to 6 dB. 
The police in BOPE (exposed group), for analysis of the influence of service time on 
hearing, were divided into one group with service time of less than 15 years and another with 
longer than 15 years (Figures 3 and 4).  
 
 
Figure 3. Comparison between the mean thresholds of the groups under 15 years and 15 or more years 
of service time - right-ear. 
 
 
Figure 4.Comparison between the mean thresholds of the groups under 15 years and 15 or more years 
of service time - left ear. 
 

Adriana Betes Heupa, Cláudia Giglio de Oliveira Gonçalves et al. 
 
68
The results indicated significant differences in the frequencies of 1, 2, 4 and 6 kHz 
bilaterally, between police exposed to noise in relation to length of service. The group with 
less than 15 years of service had mean pure tone thresholds that were better than the group 
with longer service. These data agree with the literature that the longer the exposure to noise, 
the greater the chances of developing hearing loss [9,15,19,23]. In the United States, for 
example, 40-50% of military personnel with over 10 years of service develop hearing loss due 
to noise and about 20-30% of the military with over two years of service already have some 
type of hearing impairment [24]. An Australian study also found that 40% of military 
respondents with more than 10 years of service had hearing loss suggestive of NIHL [14].  
Excluding the age factor when comparing the results of all audiometric tests between the 
exposed and the non-exposed groups, we find the results shown in Table 5.  
To characterize the impact of firearms noise exposure on hearing, excluded from the 
analysis were policemen with no hearing impairment suggestive of NIHL, i.e., not presenting 
an acoustic notch at 3000 Hz, and/ or 4,000, and/ or 6,000 Hz (nine subjects from both 
exposed and non-exposed groups).  
The results in Table 6 characterize the auditory profile of the policemen who are exposed 
to fire arms noise. The differences between exposed and non-exposed groups are also shown 
in many previous studies with military personnel [14.25-27].  
Testing of Transient Evoked Otoacoustic Emissions was calculated as a percentage of 
presence and absence, and the difference between the exposed and non-exposed group. Figure 
5 shows the higher percentage of TEOAE absence in the exposed group (58.92%), while the 
non-exposed group shows higher presence of TEOAE (54.16%). 
Among the officers exposed to noise, 14 of them showed symptoms suggestive of NIHL 
in the audiogram, of these, 78.5% had bilateral TEOAE absence, 7.2% with absence on the 
right and 14.3% with absence on the left.  
 
Table 5. Classification of audiograms for Exposed and Non-Exposed Groups to firearms 
noise, according to NR7 Annex I (N = 115) 
 
Audiogram classification (NR7) 
Exposed Group (n=65) 
Non-Exposed Group (n=50) 
Within acceptable limits 
64.61% (42) 
96% (48) 
Suggestive of NIHL 
21.5% (14) 
0% (0) 
Not suggestive of NIHL 
13.8% (9) 
4% (2) 
 
Table 6. Audiograms for Exposed and Non-Exposed Groups to firearms noise, excluding 
cases not suggestive of NIHL (N = 104) 
 
Audiogram classification (NR7) 
Exposed Group (n=56) 
Non-Exposed Group 
(n=48) 
p 
Within acceptable limits 
75% (42) 
100%(48) 
0.0001 
Suggestive of NIHL 
25% (14) 
0%(0) 
 

Effects of Impulse Noise on Hearing in Members… 
 
69
 
Figure 5. Comparison between the results of transient evoked otoacoustic emissions between the 
exposed and non-exposed groups (N = 104). 
 
 
Figure 6. Comparison between the averages of DPOAE amplitudes of the right ear for frequencies, 
between Exposed Group (GE) and Non-Exposed Group (GNE) (N = 104). 
 

Adriana Betes Heupa, Cláudia Giglio de Oliveira Gonçalves et al. 
 
70
 
Figure 7. Comparison between the amplitudes of DPOAE, left, for frequencies between Exposed Group 
(GE) and Non-Exposed Group (GNE) (N = 104). 
 
It was found that only 21.42% of the exposed group officers had bilaterally present 
TEOAE, while 54.16% of the non-exposed group showed bilateral TEOAE. This difference 
was significant, indicating that frequent exposure to impact noise may damage the outer hair 
cells. Other studies also indicate that there is a higher incidence of absent TEOAE among 
workers exposed to noise who present normal audiograms, showing that this is an effective 
test for early detection of cochlear hearing loss [10, 28-30].  
Regarding the DPOAE, the response amplitudes in both groups were compared. Figures 6 
and 7 illustrate the amplitudes in each ear from both groups. In them you can see that the 
frequencies of 3, 4 and 6 kHz decrease in amplitude between subjects in the exposed group.  
With the results of TEOAE and DPOAE it is possible to say that these tests are of great 
importance and that only the most efficient audiometry detects early cochlear injury by 
firearms noise. Additional occupational audiology in the battery of tests for monitoring the 
hearing of workers exposed to noise would be a fast, objective and effective test for early 
detection of hearing loss induced by noise, making this test another important 
epidemiological surveillance tool in occupational health [10, 28, 30-32].  
 
 
HEARINGPRESERVATION FOR OFFICERS EXPOSED TO 
FIREARMS NOISE 
 
From the characterization of risk, a Hearing Preservation Program can be planned and 
organized. The goal of the program is the reduction and/ or elimination of occupational 
hearing loss. The minimum recommendations for the implementation of a Hearing 
Preservation Program are to assess auditory risk, audiometric management, protection 

Effects of Impulse Noise on Hearing in Members… 
 
71
measures, education, as well as individual and collective motivation, besides the evaluation of 
the program [20].  
The program can be approached in three dimensions: the study and intervention in the 
work environment (risk identification); analysis of auditory profile and health of workers 
(audiometric monitoring); and educational activities [33]. Thus, through preventive measures, 
it is possible to maintain the hearing thresholds of military personnel and prevent worsening 
or onset of occupational hearing loss, thus preventing future harm not only to the health of 
individuals in the military, but the overall force in general.  
The use of noise control measures, collective or individual, such as the use of hearing 
protectors in firing ranges, is not yet a common practice in the military. This is proven in the 
United States, where the first Hearing Preservation Programs started in the 70s. Since then, it 
has been demonstrated through regular audiometric testing, that the audiometry alone does 
not prevent hearing loss, but it does help to detect temporary or definitive hearing loss related 
to the use, or non-use, of hearing protectors. In military operations, both in training and in 
combat, the motivation to use hearing protection is very limited [15].  
Studies in England have investigated about the knowledge of British soldiers on hearing 
preservation. The author noted that all the soldiers believed that hearing could be affected by 
exposure to noise in their work, but many were not aware of the presence of hearing 
conservation policies in the unit. A number of factors also prevented the proper use of hearing 
protection, despite being aware of its effectiveness. The military personnel cited 
communication difficulties, discomfort, and the inability to use protection in certain 
circumstances. The author of the study concluded that an effective Public Hearing Loss 
Prevention Program in the Army should incorporate appropriate knowledge, sociological 
issues, and economic considerations [21].  
Noise exposure in the military profession is associated with armed conflict, which is 
highly detrimental exposure, because the noise sources are not predictable and the military are 
afraid that hearing protection can endanger safety by reducing locating signals and distorting 
communication [16].  
The Committee on Noise-Induced Hearing Loss and Tinnitus Associated with Military 
Service in the U.S. states that Hearing Preservation Programs in the military environment are 
not fully adequate in preventing hearing loss in the military. And for better assessment, yearly 
monitoring is required not only for military personnel exposed to noise, but also for the 
implemented programs themselves [15]. So, like Hearing Preservation Programs, audiological 
services remain an important and growing need in the military.  
Based on these data, we propose some steps to implement a Hearing Preservation 
Program in the Special Operations Battalion of the Military Police, with the aim of preserving 
hearing, as well as stabilizing and preventing occupational hearing loss:  
 
1) Evaluation of the military work environment. Not only the shooting range, but also 
the places where there is normally exposure to noise, like cars, traffic, events, and 
emergencies. 
2) Health assessments for military personnel that include periodic general health 
examinations like hearing tests and psychological evaluations.  
3) Annual auditory monitoring of personnel exposed to noise, including otoacoustic 
emissions testing, in order to detect any worsening of the hearing.  

Adriana Betes Heupa, Cláudia Giglio de Oliveira Gonçalves et al. 
 
72
4) Activities in the environment for noise control, such as sound insulation where there 
is a possibility, use of silencers on weapons, security warnings in risk areas, as well 
as studies on hearing protection appropriate for military action.  
5) Direct involvement with the military personnel through educational activities, 
especially regarding awareness, not only about the use of hearing protection, but also 
on the importance of maintaining hearing health. For the population studied, it was 
noted that there is little expert guidance on the use of hearing protection, and what 
little guidance is provided is not standardized for quality control for which brands, 
models and attenuation levels are best.  
 
To fulfill these steps, it is necessary that the institution incorporate, into its routine, the 
presence of specialized professionals (audiologists) that will maintain the program 
effectively.  
Thus, through the characterization, monitoring and guidance of this population exposed 
to impact noise, it is possible to assist in its hearing preservation.  
The proposal of a Hearing Preservation Program emphasizes the importance of training 
on the use of hearing protection and the need to educate military personnel about the 
importance of preserving hearing health for their professional and personal lives.  
 
 
CONCLUSION 
 
We found that the majority of military personnel exposed to high intensity noise show 
hearing loss and other symptoms like stress and headaches. Most personnel know that the best 
way to protect their hearing from impact noise is through the use of hearing protection. 
However, the protection offered by the force has no make, model or standardized level of 
attenuation, with the choice to use it or not being left to the discretion of the military 
personnel themselves. Also it was noted that there is little guidance on the use of these 
protectors. And the most common complaint among the group is the presence of tinnitus.  
A quarter of the officers whose work exposes them to firearm noise, have audiograms 
suggestive of NIHL. The OAE testing proved its effectiveness in the early detection of 
hearing loss caused by impact noise exposure, and in the hearing monitoring of these subjects 
it was shown that most of the exposed personnel had TEOAE that were absent and with 
smaller amplitudes in DPOAE.  
There is a need for monitoring and starting a program with educational activities aimed at 
preserving the hearing health of this group.  
 
 
REFERENCES 
 
[1] 
Exército Brasileiro [homepage Internet]. 2009. http://www.exercito. gov.br/02ingr/ 
Profmili.htm 
[2] 
Choque- PMPR. [homepage Internet]. Companhia de Choque da Polícia Militar do 
Paraná. 2009. http://www.pm.pr.gov.br/pmpr/ciachq 

Effects of Impulse Noise on Hearing in Members… 
 
73
[3] 
Setúbal, RSR. Tiro policial: uma proposta de mudança na formação e capacitação do 
policial militar [Police shooting: a proposal to change the training and qualification of 
the military police]. 2003. 115f. [monografia]. Cuiabá (MT): Universidade Federal do 
MatoGrosso; 2003. 
[4] 
PMPR. 
Polícia 
Militar 
do 
Paraná. 
[homepage 
Internet]. 
2007. 
http://www.policiamilitar.pr.gov.br/modules/conteudo/conteudoo.php?conteudo =3. 
[5] 
Machado, MCP. Coleção Armamento: armas, munições e equipamentos policiais 
[Armament Collection: weapons, ammunition and police equipment]. 1ª ed. Curitiba: 
Gráfica Tuicial, 2009. 
[6] 
Machado, MCP; et al. cols. EPI e proteções balísticas. Manual Interno da PMPR [PPE 
and ballistic protections. PMPR Internal Manual]. 2003.  
[7] 
Brasil. Policia Militar do Paraná. Diretoria de Pessoal. Centro de Recrutamento e 
Seleção: Edital n. 061/2009 – Concurso público para preenchimento de vagas de 
soldado policial militar (QPM 1-0) e de soldado bombeiro militar (QPM 2-0) da 
Polícia militar [Military Police of Paraná. Personnel Directorate. Recruitment and 
Selection Center: Notice n. 061/2009 - Public tender to fill vacancies for military police 
soldier (QPM 1-0) and military fireman soldier (QPM 2-0) of the military police]. 
http://www.policiamilitar.pr.gov.br/arquivos/File/pmpr/Edital.pdf. 
[8] 
Neves, EB; Mello, MGS. O uso de dispositivos de proteção auditiva nos tiros de fuzil e 
de artilharia [The use of hearing protection devices in rifle and artillery shots]. Cad. 
Saúde Pública. 2007; 15:97-116. 
[9] 
Balatsouras, DG; Tisimpiris, N;Korres, S;Karapantzos, I; Papadimitriou, N;Danielidis, 
V. The effectof impulse noise on distortion product otoacoustic emissions. Int J 
Audiol.2005, 44, 440-449. 
[10] Konopka, W; Pawlaczyk-Luszczynska, M; Sliwinska-Kowalska, M; Grzanka, A; 
Zalewski, P. Effects of impulse noise on transiently evoked otoacoustic emission in 
soldiers. Int J Audiol. 2005, 44, 3-7.  
[11] Silva, RCL;Zuba, DCD. Perfil audiológico dos instrutores de tiro da Polícia Militar de 
Montes Claros – MG. Rev [Audiological profile of the shooting instructors of the 
Military Police of Montes Claros - MG. Rev]. Consciência Extensão. 2008, 1, 14-24. 
[12] Brasil. Norma Regulamentadora NR 15 – Atividades e Operações Insalubres 
[Regulatory Standard NR 15 - Unhealthy Activities and Operations]. In: Segurança e 
MedicinadoTrabalho. 56th ed. São Paulo: Atlas, 2005. 
[13] Fundacentro. Norma de higiene ocupacional. Avaliação da exposição ocupacional ao 
ruído [Occupational hygiene standard. Assessment of occupational noise exposure]. 
NHO 01. 2001. 
[14] Santos, JM; et al. Avaliação do perfil audiológico dos policiais da Policia Militar de 
Minas Gerais [Evaluation of the audiological profile of the policemen of the Minas 
Gerais Military Police]. Braz J Otorhinolaryngol.2006, 6, 20-25. 
[15] Humes, LE; Joellenbeck, LM,Durch, JS. Noise and military service: implications for 
hearing loss and tinnitus. Washington: Institute of Medicine, 2006. 
[16] Saunders GH. Griest SE. Hearing loss in veterans and the need for hearing loss 
prevention programs. Noise Health, 2009, 11, 14-21. 
[17] Korbes, N; et al. Das medidas de prevenção auditiva aos militares do 4º. Batalhão de 
Aviação do Exército de Manaus, AM [From hearing prevention measures to the 
military of the 4th. Aviation Battalion of the Manaus Army, AM. International 

Adriana Betes Heupa, Cláudia Giglio de Oliveira Gonçalves et al. 
 
74
Audiology Meeting]. Encontro Internacional de Audiologia, 24, 2009, São Paulo: Tema 
Livre, p. 2386, 2009. 
[18] Sousa, MNC; Fiorini, AC; Guzman, MB. Incômodo causado pelo ruído a uma 
população de bombeiros [Discomfort caused by noise to a population of firefighters]. 
Rev Soc. Bras. Fonoaudiol. 2009,14, 508-514.  
[19] Guida, HL; Diniz, TF; Kinoshita, SK. Perfil Audiológico em Policiais Militares do 
Estado de São Paulo [Audiological Profile in Military Police of the State of São Paulo]. 
Arq Int Otorrinolaringol., 2010, 14, 426-432. 
[20] NIOSH - National Institute for Occupational Safety and Health. Preventing 
occupational hearing loss – a practical guide. DHHS. 1996, Pub. n. 96-110, p.1, 1996. 
[21] Okpala, NC. Knowledge and attitude of infantry soldiers to hearing conservation.Mil. 
Medical., 2007, 172, 520-522. 
[22] Brasil. Norma Regulamentadora NR 7 – Programa de controle médico de saúde 
ocupacional. Portaria 19, Anexo I. Diretrizes e Parâmetros mínimos para avaliação e 
acompanhamento da audição em trabalhadores expostos a níveis de pressão sonora 
elevados [Regulatory Norm NR 7 - Occupational health medical control program. 
Ordinance 19, Annex I. Guidelines and minimum parameters for assessing and 
monitoring hearing in workers exposed to high sound pressure levels]. In: Segurança e 
Medicinado Trabalho. 56th ed. São Paulo: Atlas, 2005. 
[23] Russo, ICP. Acústica e psicoacústicaaplicada à fonoaudiologia [Acoustics and 
psychoacoustics applied to speech therapy]. 2nd ed. São Paulo: Lovise, 1999. 
[24] Henselman, LW; et al. Effects of noise exposure, race and years of service on hearing 
in US army soldiers. Ear Hearing.,1995, 16, 382-391. 
[25] Pelausa, E; et al. Prevention of noise induced hearing loss in Canadian Military. J 
Otolaryngol.,1995, 1, 271-280. 
[26] Weckl, C; Fantinel, RG; Silva, NRS. Achados audiológicos em indivíduos das forças 
armadas da Região Sul [Audiological findings in individuals from the armed forces of 
the South Region]. Rev. CEFAC.,2003, 1, 265-271. 
[27] Silva, AP; Costa, EA; Rodrigues, S; Souza, H; Massafera, V. Avaliação do perfil 
auditivo de militares de um quartel do exército brasileiro. Rev. Bras. Otorrinolaringol., 
2004, 70, 344-350. 
[28] Attias, J; et al. Protection and clinical diagnosis of noise induced hearing loss by 
otoacoustic emissions. Noise Health.,2001, 12, 19-31. 
[29] Fiorini, AC; and Fischer, FM. Expostos e não expostos a ruído ocupacional: estudo dos 
hábitos sonoros, entalhe audiométrico e teste de emissões otoacústicas evocadas por 
estímulo transiente [Exposed and not exposed to occupational noise: study of sound 
habits, audiometric notch and test of otoacoustic emissions evoked by transient 
stimulus]. Distúrbios da Comunicação. 2004, 16, 371-383.  
[30] Souza, DV. Estudo comparativo das emissões otoacústicas evocadas em militares 
expostos e não expostos ao ruído [Comparative study of evoked otoacoustic emissions 
in military personnel exposed and not exposed to noise]. [dissertação]. Rio de Janeiro 
(RJ): UniversidadeVeiga de Almeida, Rio de Janeiro, 2009.  
[31] Bernardi, APA. Trabalhadores expostos simultaneamente a ruído e tolueno: estudo das 
emissões otoacústicas evocadas transitórias e efeito de supressão [Workers 
simultaneously exposed to noise and toluene: study of transient evoked otoacoustic 

Effects of Impulse Noise on Hearing in Members… 
 
75
emissions and suppression effect] [dissertação]. Faculdade de Saúde Pública da 
Universidade de São Paulo. 2000. 
[32] Azevedo, MF. Emissões Otoacústicas. In: Figueiredo, MS.org. Conhecimentos 
essenciais para entender bem Emissões Otoacústicas e BERA [Essential knowledge to 
understand Otoacoustic Emissions and BERA well]. São José dos Campos: Pulso, 2003.  
[33] Gonçalves, CGO. Saúde do trabalhador: da estruturação à avaliação de programas de 
preservação auditiva [Occupational health: from structuring to evaluating hearing 
preservation programs]. São Paulo: Roca, 2009. 


In: Encyclopedia of Audiology and Hearing Research 
ISBN: 978-1-53617-702-2 
Editors: Erno Larivaara and Senja Korhola 
© 2020 Nova Science Publishers, Inc. 
 
 
 
 
 
 
 
Chapter 6 
 
 
 
HEARING HEALTH AND STRESS FOR  
MILITARY POLICE 
 
 
Débora Lüders, Cláudia Giglio de Oliveira Gonçalves  
and Adriana Betes Heupa 
Universidade Tuiuti do Paraná, Brazil 
 
 
ABSTRACT 
 
Nowadays it is necessary for military personnel to have good hearing, mental and 
general health in order to enter military service. To this end, not only are hearing 
evaluations such as audiometric tests required, but also qualitative assessments on quality 
of life, which verifies the subject’s emotional health and stress levels. This chapter will 
present theoretical concepts about the quality of life at work focusing on stress caused by 
military activity. The studies conclude the need to give more attention to the quality of 
life in military work, because it is not only exposure to noise that causes hearing loss and 
social stress, but also the nature of the profession itself that is stressful and often degrades 
the performance of military police. 
 
 
INTRODUCTION 
 
The proposal for quality of life at work is the improvement of conditions of work 
environments and technologies, according to the International Labor Organization. It is 
considered, from this perspective, the organization of work, understood as the division of 
tasks that determine away to produce and the division of workers into hierarchies involving 
relationships between operators and supervisors. The work environment involves, in addition 
to wages, the risk of accidents and disease, the technologies used to produce, the degree of 
autonomy and creativity of the worker, and the degree of worker control over the work 
process, which all influence health. 
For the World Health Organization (WHO, 1995), quality of life is “an individual’s 
perception of their position in life in the context of the culture and value systems in which 
they live and in relation to their goals, expectations, standards and concerns”[1]. 

D. Lüders, C. G. de Oliveira Gonçalves and A. Betes Heupa 
 
78
Regarding the discussion on Quality of Work Life (QWL), it had its beginning in the 70s, 
when there were struggles from workers and students against the Taylorist/ Fordist production 
systems. 
At first, QWL was understood only as job satisfaction, which only refers to working 
conditions and remuneration received, thus being an individual reaction to a job. Later the 
term took into account more cooperative projects, which although seeking to provide greater 
worker satisfaction, was still associated with increased worker productivity. 
Currently, the concern with QWL focuses on the search for humanization at work, 
changing it and adapting it to allow greater worker satisfaction and greater organizational 
productivity, considering key elements for solving problems, the restructuring of the basic 
nature of work, innovation in compensation and the rewards system, and improving the work 
environment. 
Therefore, quality of work life is related, currently, to a way of thinking that involves 
humans, their work and its organization, focused on the welfare of workers in the workplace 
along with organizational effectiveness [3, 11]. 
However, there are several factors that can decrease the quality of life, such as the 
emergence of various illnesses, including stress. 
Several studies have shown that stress is one of the factors most responsible for excessive 
tardiness and absences at work, as well as for medical leave, relationship problems with 
superiors, subordinates, colleagues and customers, decreased productivity, lack of creativity 
and originality in ideas, and even depression, alcoholism, smoking, and drug use. 
Stress is the new challenge of this century and is directly related to the ability of an 
individual to bear a particular responsibility, for a time, uninterruptedly, while being under 
some kind of psychological pressure. Preventing psychological stress becomes a challenge as 
the subjectivity of the problem does not accurately allow a determination of what the triggers 
are, and, therefore, how to avoid it. However, one should not only focus on the emotional 
reasons for stress. Workplaces that have thermal and/ or acoustic discomfort; long hours 
without interruption; physical, sensory or postural stress can also be considered stressors [2]. 
 
 
OCCUPATIONAL STRESS 
 
One of the most common characteristics of the organization of contemporary societies is 
stress, which although originally constitutes a natural reaction of adaptation of the human 
body, has assumed the status of a disease. This is probably due to the fact that the 
performance requirements of roles and tasks are beyond the adaptive capacity of the 
individual. 
The same happens today in relation to the working environment into which the individual 
is inserted, generating what we call occupational stress, which can be caused not only by 
issues relating to the work itself, but also, and perhaps mainly, by organizational 
characteristics at work. These are events, situations, or contingencies to which the worker is 
subjected that may exceed their threshold of tolerance to pressure and put the worker in a 
vulnerable situation, depending on the psychophysical structure of each person. 
Occupational stress has been investigated to be present in most organizational 
environments. The stress in this case may be due to an inability of the individual to cope with 

Hearing Health and Stress for Military Police 
 
79
the stressor present in work contexts, commonly causing mental and/ or physical illnesses, 
which can in turn cause damage [5]. 
Gradually, there has also been an increase in studies on stress in professions involving 
risk of life, and, at the same time, are critical to the orderly operation of society, as in the case 
of military and civil police officers and firefighters. 
The military police force is a complex organization with groups of interests that are 
resistant to change. Reflections on the health of police work in Brazil are still quite limited, 
and this is because the military dictatorship silenced these issues for a long time, and those 
policies still echo today. For this reason, in the context of the state military police forces, one 
must consider both the aspects of work organization as well as the risk situations to which 
these professionals are exposed, especially considering the significant increase in violence 
and lack of jobs [6]. 
In this context, it was exactly the significant increase in violence that put the performance 
of the civil and military police into the spotlight. However, it can be observed in Brazil that 
there is a significant distrust of the police, unlike what can be seen in countries such as 
Germany and the United States. This fact may result from constant accusations of corruption 
and excessive police violence, as well as the ignorance of the public about domestic politics, 
culture, and other issues relating to these institutions. This ignorance has prevented society 
from perceiving the dissatisfaction that the police themselves have with various aspects of 
their work. One source that contributes most to the controversial image of the police officer is 
provided by the media, which now puts officers in the position of the hero, showing their 
actions in combating crime, but sometimes in the position of villains who are corrupt or kill 
innocent people. Perhaps society is unaware of police work, whose function is to contain 
violence, but at the same time running the risk of reproducing violence or being its victim [5]. 
Besides being a life-threatening activity, the characteristics of the military police 
organization, including its structure, hierarchy, discipline and rules of conduct, which can be, 
in many cases, also considered stressors, as they impose severe restrictions on expression and 
personal development of the police officers, with low pay as a significant factor of general 
dissatisfaction among the officers. 
One of the characteristics of the military profession is to live with risk, either in training, 
in daily life, or at war, and that comes across in every day with very adverse situations 
requiring rapid solutions, intervening in situations with human problems full of conflict and 
tension. These professionals are also subjected to strict principles of hierarchy and discipline, 
absolute dedication, continuous availability, physical forceand constant professional 
improvement. Even when inactive, officers must remain bound to their profession and ready 
to serve if called up with an eventual return to active service, even when paid as a reservist; 
plus they have restrictions regarding labor rights [6]. 
Moreover, the risk to which they are exposed, which creates uncertainty and tension, not 
only accompanies the police at the time and place of work, but also outside of it, since they 
are recognized by their uniforms [7]. 
Studies on the health of civil and military police in the state of Rio de Janeiro affirm that 
the police, as workers, are underserved with health issues, and this has deep historical roots, 
which intensified with the military dictatorship in Brazil. The field of occupational health 
cannot omit consideration of jobs in public safety, a segment which is one of the most 
vulnerable to accidents and death at work [8]. 

D. Lüders, C. G. de Oliveira Gonçalves and A. Betes Heupa 
 
80
Another important factor relates to the fact that in a male-dominated work place, we must 
consider that illness, stress or distress may be associated with male weakness, causing the 
police officers to hide these issues from colleagues, thereby not seeking necessary treatment 
in order to defend himself against negative labels [5]. 
However, contradicting this situation, a study of Brazilian military police in the state of 
Paraíba revealed that between 2003 and 2005 there was an average of 489 police officers 
away on sick leave [6]. 
 
 
STUDIES ON STRESS IN THE MILITARY POLICE IN BRAZIL 
 
The military profession is a high risk activity because these professionals deal with 
violence, brutality and death in their daily lives, being among the professionals who often 
suffer from stress, not only due to the characteristics of their work but also because ofthe 
pressure society puts on them demanding their competence and commitment. One study 
investigated the occurrence and stages of stress among 264 military police, obtaining as a 
result that 47.4% of the police had symptoms of stress. Psychological symptoms were 
recorded in 76.0% of the police with stress, and physical symptoms in 24.0%, with women 
being more affected than men. Although the conclusion was that the levels of stress and 
symptoms do not indicate a critical situation of fatigue, it recommended preventative action 
by the police organization, which could include the implementation of a program of 
diagnosis, counseling, and stress management [9]. 
A survey of 50 members of the Military Police in Brazil found that 38% of police officers 
had symptoms of stress, with no significant difference between police officers who perform 
administrative duties and officers who have duties that take them to the streets [10]. 
Another study diagnosed the quality of life at work and occupational stress in 1,152 
military police officers in the state of Minas Gerais. Although the study revealed a high level 
of satisfaction with the military police work itself, there was a significant level of 
dissatisfaction with aspects of the culture and organizational structure of the military police, 
which, along with dissatisfaction with pay, constituted the main sources of active pressure on 
the military and caused high levels of stress, stemming from a high level of dissatisfaction 
with the institution. 
A series of recommendations arising from the findings, which include rethinking the 
organization of work, possibility of expression and autonomy, recovering self-esteem, the 
image of the police in society, and also the realization of a program for jobs and wages that 
reduce or eliminate the need to moonlight [11]. 
Studies have also addressed the issue of gender in the military police. In a predominantly 
male work environment, being a woman is a powerful trigger of stress. One of the most 
important findings is that the presence of women does not have a gender perspective and real 
understanding of differences, which eliminates existing inequalities in the force, both for 
officers as well as precincts, regarding health or operational units [12, 13]. 
In 2009 a detailed survey of the literature about police work and its implications for 
mental health was conducted and found that, despite the significant increase in scientific 
production since 2000, the results are inadequate when compared with the relevance of the 
topic. The author justifies this as being probably due to the difficulty of gathering qualitative 

Hearing Health and Stress for Military Police 
 
81
data within the police force due to issues of hierarchy and protocols relevant to the 
organization as an institution. For the author, qualitative studies could lead us to consider the 
police officers in a subjective manner, giving voice to these players and bringing up issues 
that would hardly be captured by quantitative studies, although these studies are also 
unquestionably valuable [7]. 
In 2010, a study was conducted with 75 police officers from Santa Maria, divided into 
three groups: 26 officers working in the emergency-call operations center, 7 officers working 
in administrative areas, and 42 in patrolling activities. As a result, a significant presence of 
stress levels in the emergency-call center and patrolling sector was found, totaling more than 
half of the participants surveyed. The most common stress symptoms found were a feeling of 
physical exhaustion, fatigue, muscle tension, memory problems, insomnia, irritability, 
excessive emotional sensitivity, and constantly thinking on one subject. The authors warn that 
such symptoms are worrisome because they can impair the performance of the activities 
developed by the military police, generating losses for society [13]. 
 
 
FINAL CONSIDERATIONS 
 
It can be seen that working as a policeman is a stressful activity, and that this 
characteristic is perhaps necessary in the working of an effective officer. On the other hand, 
the high level of stress may end up damaging the health of the officers. 
There is a need for larger studies made with the aim not only of characterizing the level 
of stress, but also proposing improvements in the quality of life for military police officers, 
starting with an awareness of the risks involved to educational measures and other approaches 
that preserve the health of these professionals. 
The development of preventive programs for police officers should include: 
investigations into health conditions with a focus on epidemiological methods; healthcare 
planning, in seeking solutions with an emphasis on health promotion, using intervention 
activities not only for officers, but also for the workplace; an evaluation program developed 
as part of the planning, forecasting and provision of solutions for managing the 
implementation for improving health conditions. 
 
 
REFERENCES 
 
[1] 
The WHOQOL Group. The World Health Organization quality of life assessment 
(WHOQOL): position paper from the World Health Organization. Social Science and 
Medicine, 1995; 10: 1403-1409. 
[2] 
Almeida M. A. B., Gutierrez G. L., Marques R. Qualidade de Vida [Quality of life]. São 
Paulo: Escola de Artes, Ciências e Humanidades – EACH/USP; 2012. 
[3] 
Moraes L. F. R., Ferreira, S. A. A., Rocha D. B. Trabalho e Organização: influências na 
Qualidade de Vida e Estresse na Polícia Militar do Estado de Minas Gerais [Work and 
Organization: influences on Quality of Life and Stress in the Military Police of the State 
of Minas Gerais]. In: Anais do V Congresso de Ciências Humanas, Letras e Artes. 
2001; Ouro Preto. Minas Gerais. Brasil [Proceedings of the V Congress on Human 

D. Lüders, C. G. de Oliveira Gonçalves and A. Betes Heupa 
 
82
Sciences, Letters and Arts. 2001; Black gold. Minas Gerais. Brazil]. [Acesso em 2014 
mai 02]. Disponível em: http:// www.ichs.ufop.br/conifes/anais/OGT/ogt0203.htm. 
[4] 
Silva M. B., Vieira S. B. O Processo de Trabalho do Militar Estadual e a Saúde Mental 
[The Work Process of the State Military and Mental Health]. Saúde Soc. São Paulo, 
2008; 17:161-170. 
[5] 
Ely F. R. O super-herói (nem tanto) também adoece: um estudo em Saúde do 
Trabalhador com servidores da Polícia Federal de Santa Catarina. (Tese) [The 
superhero (not so much) also gets sick: a study in Occupational Health with employees 
of the Federal Police of Santa Catarina. (Thesis). Santa Catarina: Universidade Federal 
de Santa Catarina. Centro Sócio-Econômico. Programa de Pós-Graduação em Serviço 
Social. 2007. 
[6] 
Exército Brasileiro [Brazilian Army]. [Documento On-line]. Última atualização em 
2009. [Acesso em 2010 fev 24]. Disponível em: http://www. exercito.gov.br/ 
02ingr/Profmili.htm. 
[7] 
Silva J. H. R. Estudo sobre o trabalho do policial e suas implicações na saúde mental 
[Study on police work and its implications for mental health]. [Dissertation]. São Paulo: 
Universidade de São Paulo. Instituto de Psicologia. 2009. 
[8] 
Souza E. R., Minayo M. C. S. Policial, risco como profissão: mobimortalidade 
vinculada ao trabalho [Police, risk as a profession: mobility linked to work]. Ciência 
and Saúde Coletiva, 2005; 10: 917-928. 
[9] 
Costa M., Accioly H. Jr., Oliveira J., Maia E. Estresse: diagnóstico dos policiais 
militares em uma cidade brasileira [Stress: diagnosis of military police in a Brazilian 
city]. Rev. Panam. Salud Publica, 2007; 21:217–22. 
[10] Cusatis R. Sr., Martins J. L. Nível de estresse na Polícia Militar [Military Police stress 
level]. Fisioter. Bras., 2003; 4: 108-116. 
[11] Moraes L. F. R., Pereira L. Z., Lopes H. E. G., Rocha D. B., Ferreira S. A. A., Portes P. 
C. P. Estresse e Qualidade de Vida no Trabalho na Polícia Militar do Estado de Minas 
Gerais. In: Anais do XXV Encontro da ANPAD. 2001; Campinas. São Paulo. Brasil. 
[Stress and Quality of Life at Work in the Military Police of the State of Minas Gerais. 
In: Proceedings of the XXV ANPAD Meeting. 2001; Campinas. Sao Paulo. Brazil] 
[Acesso em 2014 mai 02]. Disponível em 
http://www.anpad.org.br/admin/ 
pdf/enanpad2001-grt-359.pdf. 
[12] Bezerra C. M., Minayo M. C. S., Constantino P. Estresse ocupacional em mulheres 
policiais [Occupational stress in police women]. Ciência and Saúde Coletiva, 2013; 18: 
657-666. 
[13] Oliveira P. L. M., Bardagi M. P. Estresse e comprometimento com a carreira em 
policiais militares [Stress and career commitment in military police]. Boletim de 
Psicologia, 2010, 59: 153-166. 
 
 

In: Encyclopedia of Audiology and Hearing Research 
ISBN: 978-1-53617-702-2 
Editors: Erno Larivaara and Senja Korhola 
© 2020 Nova Science Publishers, Inc. 
 
 
 
 
 
 
 
Chapter 7 
 
 
 
EFFECTIVENESS OF HEARING PROTECTION DEVICES 
(HPD) IN ACTIVITIES WITH FIREARMS 
 
 
Cláudia Giglio de Oliveira Gonçalves,  
Adriana Betes Heupa and Heraldo Lorena Guida 
 
 
ABSTRACT 
 
Hearing protection devices have the function of protecting the hearing against 
potential risks in environments that may threaten safety and health as a result of exposure 
to loud noise. This measure is used when it is unfeasible to adopt collective protection or 
until it is effectively implemented. The hearing protector is still the main instrument of 
hearing loss prevention in all fields of work where there is noise. This is no different in 
the military population. We present in this chapter a survey covering different aspects of 
one type of hearing protection (attenuation and comfort) provided for some aspiring 
officers of the Military Police.  
 
 
INTRODUCTION  
 
Exposure to intense sound pressure levels (SPL) can be minimized with the use of 
Hearing Protection Devices HPD to protect hearing The choice of the type and model of PPE, 
as well as training for its proper use are aspects that deserve attention from health 
professionals [1, 2, 3].  
The use of hearing protection involves many aspects that must be considered in order to 
obtain an efficient use in reducing the noise that reaches the inner ear. Among these aspects 
should be considered: noise attenuation and noise leakage, comfort, proper placement, as well 
as care and maintenance of hearing protectors. 
The estimation of noise attenuation by HPD has been studied by several authors. The 
methods used in laboratories (well-controlled laboratory conditions - ANSI S3.19 (ANSI, 
1974) or ISO 4869-1 (ISO, 1990) are criticized for not representing realistic situations for 
their use. Even when not using an artificial head in the tests, as with the protocols for 
estimating noise attenuation using the REAT (real-ear-attenuation-at-threshold) method - 

Cláudia Giglio de Oliveira Gonçalves, Adriana Betes Heupa et al. 
 
84
based on ISO 4869-1/90, ANSI S3.19-1974 ANSI S12.6-1984 and ANSI S12.6-1997 - A and 
B), critics point to the great variability that can occur between the test subjects and real users 
These differences relate to the small number of samples for the generalization performed and 
the threshold comparison, of the test subjects and those who will actually use the HPD.  
The literature in this area has shown that the attenuation data obtained in laboratories and 
used by hearing protector manufacturers are smaller than those evaluated in real situations 
among users. This is because the correct placement of HPD is a factor that interferes with 
noise attenuation [4].  
In an attempt to minimize these criticisms, estimated attenuation using the microphone-
in-real-ear (MIRE) method has been employed by some researchers. This method uses two 
microphones: one miniature microphone inside the HPD, placed in the ear canal of the 
subject, which captures the attenuated sound that reaches the ear, and another external 
microphone outside the ear, which captures the ambient sound.  
The ideal noise attenuation will be analyzed for each situation, it is expected that the 
hearing be protected, but without the individual losing contact with the surrounding 
environment. The way attenuation is expressed, and the method used, either by frequency 
bands in decibels or by a global attenuation value such as: the Noise Reduction Rating - NRR 
or Noise Reduction Rating Subject-Fit - NRRsf, to be considered for choice of HPD.  
However, it is important to consider that noise can reach the inner ear by bone and human 
tissue transmission, by the vibration of the ear itself, noise transmission through the material 
of the HPD, and leakage due to inadequate contact between the ear protector and the user's 
body, which depends on proper training regarding the placement of HPD [5].  
So, in addition to noise reduction, other aspects are important in choosing the most 
appropriate HPD for each activity, as they relate to ease of use. These aspects of the HPD are: 
its weight, the pressure it puts on the ear, its texture, its ability to dissipate heat generated, its 
ability to absorb perspiration, its interference in achieving the activity, its interference in 
verbal communication, and the way it is placed on/ in the ear [6].  
The variety of HPD available on the market has grown significantly in the last 40 years 
[1, 7, 8]. Selecting the correct device for each situation is important. Attenuation may not 
even be the most important criterion to be considered, for some authors, as what must also be 
considered is comfort, the need for communication, appropriate use, cost, durability, and even 
its suitability for the activity being practiced by the user [2]. For the hearing protectors to 
actually be used, it is necessary that they be comfortable [5].  
This chapter aims to analyze some HPD for the users of firearms, and their different 
characteristics, such as attenuation and comfort.  
 
 
TYPES OF HPD FOR EXPOSURE TO FIREARMS NOISE  
 
Hearing protection against the SPL produced by firearms, considered to be impact noise, 
has peculiarities in relation to protection against continuous noise, typical of industrial 
activities.  
The noise reduction rating (NRR) required for HPD used for firearms noise must be 
higher than for PPE used for continuous noise, for use in industries. Moreover, in many 
situations, the user of a firearm needs to be able to communicate for safety reasons. Among 

Effectiveness of Hearing Protection Devices (HPD)… 
 
85
these are mostly professionals who are using firearms daily for occupational reasons, such as 
the police and military.  
To adapt to these hearing protection needs, there have been a few attempts over the years 
to produce HPD specifically for firearms users. The first HPD for protection from firearms 
noise was designed in the First World War. Mallock, in 1914, in England, designed an ear 
plug type for use by the military in the war [9]. And Tod, in 1914, based on the idea of the 
diaphragm, developed a hearing protector placed over the ear with a damper that closed in the 
presence of impact noise for use in exposure to firearms. Still in 1914, Kalse and Kalse 
adapted a manual phone-type device in an earmuff protector, which had non-linear noise 
attenuation properties for shooters [10].  
Described below are some of the types of headphones available on the market today 
designed to protect users’ hearing from firearms noise:  
 
1) Passive Hearing Protection:  
In this group are HPD with mechanical noise attenuation, without any electronic 
device that regulates the attenuation for frequency or sound pressure level. They can 
be:  
1.1) Earmuffs:  
This type of hearing protection is designed to fully enclose the ear. Some models 
of this type are suitable for ear protection when using firearms with high levels 
of noise attenuation, between 21 and 25 dB (NRR) according to the 
manufacturers;  
1.2) Earplugs:  
Frequency dependent: nonlinear, with small holes creating an acoustic filter that 
allows the passage of low-frequency sounds and more attenuation for high and 
medium frequencies, which enables improved verbal communication awareness. 
NRR 20-22 dB;  
1.3) Earplugs with filters:  
Dependent on sound intensity (variable attenuation) using filters of different 
sizes and materials; adjustable to the different needs for noise attenuation, with 
some models incorporating a valve that lets you manually adjust the attenuation 
level. The NRR increases with the increase of intensity (12 to 22 dB);  
 
2) Electronic Hearing Protection:  
These include electronic devices that enable attenuation dependent on sound pressure 
levels. Running on batteries, they are designed to increase speech sounds, but reduce 
impact noise to a safe level, recommended for shooting activities for both sport 
shooting and police activities. Some types allow reception of communication through 
the device.  
2.1) Electronic earplugs: come in various models such as: custom, open ear, or with 
headset for communication. Attenuate ambient noise and cancel out peaks of 
impact noise. There is great variation in NRR depending on the model and 
brand.  
2.2) Electronic earmuffs: control the sound pressure level, mitigate noise impact 
immediately, with NRR around 19-20 dB.  

Cláudia Giglio de Oliveira Gonçalves, Adriana Betes Heupa et al. 
 
86
2.3) Electronics earmuffs with transmission dependent on sound pressure level: 
contain a microphone and an amplification system that transmit external noise to 
headphones placed inside the earmuffs. This system was designed to amplify 
only certain areas of the sound spectrum. The amplification system has 
adjustable maximum sound pressure inside the device and a cutout level, at 
which the electronic system shuts down. NRR around 21-26 dB  
2.4) Electronics earmuffs with communicators: enable communication between 
wearers of hearing protectors by having microphones transmit and receive 
speech sounds. NRR of 20 dB.  
 
 
PARAMETERS OF COMFORT FOR MILITARY HPD  
 
The proper use of hearing protection is a challenge for hearing loss prevention. Lack of 
knowledge about the risk of exposure to noise and the lack of guidance on how to properly 
use HPD are mentioned as factors that discourage use. Among the reasons for not using 
hearing protection adequately is discomfort, as well as difficulties in communicating and 
hearing environmental sounds important for safety. In addition to the difficulties in choosing 
HPD, having guidelines regarding use of these devices is a concern [11]. The effectiveness of 
a hearing protector is not only measured in noise attenuation, but also in the way it is used. 
For this reason, it is essential that military personnel understand the risks and understand the 
need for using HPD. This understanding can ensure the right to request the proper HPD that is 
specific to certain activities [12].  
Thinking about these issues, we developed a study that aimed to understand the 
perception of military police who practice shooting every week on the important aspects in 
relation to HPD and an evaluation on the comfort of earplugs. The selected group was part of 
the training course for officers in the Military Police of Paraná - Brazil who had no prior 
experience with using the earplugs used in the research. The work proceeded in three steps:  
 
1st) guidelines to the subjects about the risks of exposure to firearms and training on the 
proper use of the hearing protection used in the study, conducted at the Military 
Police Battalion HQ;  
2nd) identification of aspects considered important for the police in relation to HPD;  
3rd) review of the aspects of comfort in using an earplug with a noise filter.  
 
The study included 19 police officers, all male, with a mean age of 24.8 (minimum 19, 
maximum 34, standard deviation/ SD = 4.48 years), most (14) with high school diplomas and 
(5) with college degrees. Among the officers, three had noise induced hearing loss (NIHL) 
with an acoustic notch.  
The earplug used in the study was the 3M COMBAT ARMS® model, a pre-molded insert 
type, which is a device that changes the noise reduction to the situation of exposure to impact 
noise from the shot (Open or Shot mode: the sound moves to the ear through a special filter 
that allows the passage of low-frequency sounds, but attenuates high frequency sounds, or, 
the more intense the impulse noise, the more limited the noise will be; and Closed or Constant 
Protection mode: that attenuates continuous noise mainly from high frequency sound (such as 

Effectiveness of Hearing Protection Devices (HPD)… 
 
87
engine and ambient noise), allowing the military to carry out operations without removing the 
earplugs. Thus, there are two attenuation types: Open or Shooting mode with a NRR of 7 dB 
and the Closed or Continuous Protection mode with a NRR of 23 dB (ANSI S3.19-1974).  
In 2006, the proposed instrument was used in a survey consisting of two questionnaires 
[13]: the Evaluation of Comfort Parameters (Appendix 1), which evaluates the relevance of 
the comfort parameters for hearing protectors, and the Assessment of Hearing Protectors 
(Appendix 2), to evaluate the comfort in the use of earplugs (a). The instrument uses a Likert 
scale, with Questionnaire 1 (Appendix 1) covering issues on a scale of 1 to 5, with 1 being 
Insignificant and 5 being Very Important, and Questionnaire 2 (Appendix 2) applied after 30 
days experience with earplugs (a), allows the classification of hearing protectors used by the 
subjects associated on a scale of 1 to 5, where 1 is the Most Favorable and 5 the Least 
Favorable situation.  
The following are the results of the questionnaires:  
 
Table 1. Average scores on the questionnaire on aspects considered important by 
officers for hearing protection (N = 19) 
 
Points 
Attenuation 
Pressure 
Weight 
Texture 
Heat 
Sweat 
Do tasks 
Insertion  
Communication 
Average 
4.8 
4.4 
3.7 
3.6 
4.1 
3.8 
4.5 
4.4 
4.6 
Std Dev. 
0.40 
0.81 
1.10 
0.92 
0.70 
1.08 
0.93 
0.81 
0.67 
1= insignificant / 5=very important 
 
Observe that all questions were assessed as significant (all had scores above 2.5, which is 
considered to be “normal”), however, the question for “attenuation” was considered the most 
significant aspect in the perception of the police, with texture and weight being less 
significant.  
The officers’ evaluation of the COMBAT ARMS® hearing protectors is in the table 
below.  
Questions regarding pressure in the ear (2.7) and difficulty in performing tasks (2.7) had 
averages above 2.5 (considered normal), but the remaining questions scored higher.  
In relation to the overall comfort in the ear, the average score was 3.1 (SD = 1.36) 
showing the earplug to be comfortable.  
 
 
EVALUATION OF ATTENUATION EARMUFF TYPE PROTECTOR  
USED BY MILITARY  
 
The study with the group of 19 police officers, with the objective of evaluating the 
effectiveness of hearing protection in shooting practice by the military police, was continued 

Cláudia Giglio de Oliveira Gonçalves, Adriana Betes Heupa et al. 
 
88
to review the attenuation of an earmuff-type device during practice shooting for the military 
Police Battalion in Curitiba - Brazil.  
The PELTOR H10A® earmuff-type protector, made by 3M Brazil, has attenuation 
indicated by the manufacturer for a NRR of 30 dB and 27 dB of NRR(SF).  
 
Table 2. Evaluation of the police regarding the earplugs (N=19). 
 
Points 
Attenuation 
Pressure 
Weight 
Texture 
Heat 
Sweat 
Do tasks 
Insertion  
Communication 
Average 
1.8 
2.7 
1 
2.4 
1.3 
1.7 
2.7 
2 
1.6 
Std Dev. 
0.94 
1.44 
0.00 
1.18 
0.82 
1.03 
1.49 
1.56 
0.83 
1=most favorable / 5=least favorable. 
 
We conducted the evaluation of sound pressure levels at an outdoor firing range for 
shooting practice for the military police with a Taurus® .40 pistol and with a 12 gauge 
shotgun firing slugs, both weapons were loaded with CBC (Companhia Brasileira de 
Cartuchos) brand cartridges. We used the MIRE method, and the measurement was 
performed using a Svantek (Poland) model SV 102 sound level meter, with programming for 
channel 3 using the following weights: (1) A/ “slow”; (2) C/ “impulse” and (3) C/ “fast”. The 
peak measuring range was between 60 and 146 dB. The sound level meter was attached to the 
belt of the subject with a microphone on the collar of his shirt. Before each measurement, the 
microphones were calibrated by means of acoustic calibrator, model CR:514 by Cirrus 
Research plc.  
The measurements were performed following Brazilian [14] and international [15] 
recommendations. The peak values and maximum limit (Lmax) were measured and the noise 
frequency spectrum (octave band) was analyzed.  
According to Annex 2 (Limits for impulse noise) from Norm n.15 [14]:  
 
1. Impulse noise shall mean that which presents acoustic energy peaks of less than one 
(1) second with intervals of longer than 1 (one) second.  
2. Impulse levels should be evaluated in decibels (dB), with a sound pressure level 
meter operating in the linear circuit with circuit response set at impulse. The readings 
should be made near the ear of the worker. The tolerance limit for impulse noise will 
be 130 dB (linear). In between the peaks, the existing noise should be evaluated as 
continuous noise.  
3. In case of unavailability of measuring the sound pressure level in using the impulse 
setting, it shall be valid to use the fast setting and “C” weighting. In this case, the 
tolerance limit will be 120 dB(C).  
4. Activities or operations that expose workers without adequate protection, to impulse 
noise levels of greater than 140 dB (linear) measured at impulse response setting, or 

Effectiveness of Hearing Protection Devices (HPD)… 
 
89
greater than 130 dB(C) measured at the fast response setting, offer a serious and 
imminent risk.  
 
By international standards, the International Institute of Noise Control Engineering 
provides 140 dB(C) as the limit of exposure to impulse noise [15].  
Considering the above regulations, the police officers should not be exposed to values 
greater than 140 dB(C) peak, and the value of Lmax should not exceed 120 dB(C).  
For data that will be presented in this chapter two series of shots (and instruction) were 
considered: for the .40 pistol, training was conducted for 35 minutes, and for the 12 gauge 
shotgun, the session lasted 19 minutes. The lines of fire consisted of 10 officers in each 
battery, each of whom fired 5 shots per series. There were four series of .40 pistol shots and 
two series for the 12 gauge shotgun.  
The following are the results.  
 
Table 3. Results of noise from the .40 pistol 
 
Weapon / Pistol 
Filter 
Detector 
Peak (dB) 
Max (dB) 
Leq (dB) 
External Microphone  
A 
Slow 
143.9 
115.3 
95.7 
C 
Impulse 
141.8 
126.9 
97.4 
C 
Fast 
141.8 
122.4 
97.4 
MIRE 
A 
Slow 
135.5 
102.5 
77.8 
C 
Impulse 
134.1 
126.5 
93.3 
C 
Fast 
134.1 
123 
93.3 
 
Table 4. Results of noise from the 12 gauge shotgun 
 
Weapon / Shotgun 
Filter 
Detector 
Peak (dB) 
Max (dB) 
Leq (dB) 
External Microphone  
A 
Slow 
144.9 
111.7 
93 
C 
Impulse 
141.8 
127.8 
95.4 
C 
Fast 
141.8 
123.1 
95.4 
MIRE 
A 
Slow 
117.7 
89.8 
64.8 
C 
Impulse 
128.1 
121 
86.7 
C 
Fast 
128.1 
117.2 
86.7 
 
Table 5. Results of the noise attenuation for the weapons used (MIRE) 
 
Weapon 
Microphone 
125 Hz 
250 Hz 
500 Hz 
1000 Hz 
2000 Hz 
4000 Hz 
8000 Hz 
Total A 
Total C 
.40 Pistol 
External 
68.3 
78.1 
88.6 
92.2 
89.5 
84.8 
81.7 
95.7 
97.4 
Internal 
61.4 
67.4 
68.1 
65.2 
72.3 
71 
71.3 
77.8 
93.3 
Difference 
6.9 
10.7 
20.5 
27 
17.2 
13.8 
10.4 
17.9 
4.1 
12 gauge 
shotgun 
External 
70.2 
79.3 
85.7 
89.8 
85.9 
81.9 
78.8 
93 
95.4 
Internal 
56 
59.6 
54.2 
53.2 
58.4 
54.2 
48.9 
64.8 
86.7 
Difference 
14.2 
19.7 
31.5 
36.6 
27.5 
27.7 
29.9 
28.2 
8.7 
Legend: Total A – results for average total of all A frequency measurements; Total C - results for 
average total of all C frequency measurements. 
 

Cláudia Giglio de Oliveira Gonçalves, Adriana Betes Heupa et al. 
 
90
Table 6. Comparison of the results of attenuation found in comparison to the numbers 
from the earmuff-type manufacturer (values in dBA) 
 
Octave Band (Hz) 
125 
250 
500 
1000 
2000 
4000 
8000 
Total A 
Manufacturer 
16 
22.9 
34 
36.8 
35.9 
38 
38.2 
27 
.40 Pistol 
6.9 
10.7 
20.5 
27 
17.2 
13.8 
10.4 
17.9 
12 gauge shotgun 
14.2 
19.7 
31.5 
36.6 
27.5 
27.7 
29.9 
28.2 
Legend: Total A – results for average total of all A frequency measurements. 
 
From the presented results, it was identified that evaluated the earmuff protector was 
efficient for hearing protection for the officers, except in the “Lmax / fast” setting, where a 
value of 123 dB(C) was observed for the .40 pistol, so the measured values exceeded the limit 
recommended by NR-15 [14].  
Possibly due to the differences in weapons, cartridges, distance from the wall, and, hence, 
the physical characteristics of noise, it was observed that the earmuff protector was rated most 
effective for noise attenuation for shotgun noise, relative to the noise of the pistol. While 
average attenuation for the shotgun stood at 28.2 dB(A) (above the 27 dB(A) described by the 
manufacturer), the attenuation of the noise from the pistol was 17.9 dB(A).  
 
 
CONCLUSION  
 
The theme of hearing protection for noise impulse is challenging and very current. There 
are several models and brands of hearing protection devices on the market, but often the 
attenuation values provided by the manufacturers are not proven by measurements taken in 
the field. The challenge for professionals working in this area increases when we see the need 
to associate good quality in noise attenuation with device comfort.  
The above noise levels in training with the .40 pistol and 12 gauge shotgun are above 
those permitted by law, showing the need to use hearing protection during training.  
For hearing protection to be used properly and all the times by the military, the main 
thing is comfort. And to assess the comfort of a hearing protector, it is necessary to have the 
opinion of its users [8]. This opinion, in this study, was shown in the questionnaire, in that the 
COMBAT ARMS® brand pre-molded earplug hearing protector has a medium level of 
comfort (3.1), and is therefore characterized as comfortable by users surveyed.  
For choosing the best protector made for this population, we need to evaluate more 
protectors, not only for comfort, but also for attenuation. This type of analysis was performed 
with the PELTOR H10A® brand earmuff hearing protector, which was proven effective in 
noise reduction for the 12 gauge shotgun, however with regards to training with the .40 pistol, 
its performance was just “fair”. Therefore, other actions should be introduced to protect the 
hearing of the police officers.  
The ideal would be to test both aspects of each of the hearing protectors available and 
then come to the conclusion for the most appropriate device for the population in question.  
 
 
 

Effectiveness of Hearing Protection Devices (HPD)… 
 
91
APPENDICES 
 
Questionnaire 1. Evaluation of Comfort Parameters  
 
Name: 
Job Title: 
Sector: 
(Note: this questionnaire is to know which topics are of the greatest importance to be evaluated in the short 
term and not specifically on the protector that is being tested. Remember that 1 is insignificant and 5 is 
very important.)  
 
Rate, in your opinion, the relevance of each of the comfort parameters for Personal 
Protection Equipment for Hearing, the overall comfort of the protector, on a scale of 1 to 5, 
wherein:  
 
Attenuation 
Insignificant 
1 
2 
3 
4 
5 
Very Important 
Pressure 
Dampers – done by rods – in ear canal 
Insignificant 
1 
2 
3 
4 
5 
Very Important 
Weight 
Insignificant 
1 
2 
3 
4 
5 
Very Important 
Texture 
Insignificant 
1 
2 
3 
4 
5 
Very Important 
Ability to dissipate generated heat  
Insignificant 
1 
2 
3 
4 
5 
Very Important 
Ability to absorb sweat  
Insignificant 
1 
2 
3 
4 
5 
Very Important 
Inconvenience when doing tasks 
Insignificant 
1 
2 
3 
4 
5 
Very Important 
Insertion 
Insignificant 
1 
2 
3 
4 
5 
Very Important 
Verbal Communication 
Insignificant 
1 
2 
3 
4 
5 
Very Important 
 
Questionnaire 2.- Evaluation of Personal Hearing Protector 
 
Name: 
Job Title: 
Job Title: 
 
Rate the hearing protector used based on the topics that are shown below, on a scale of 1 
to 5, for: 
 
Attenuation 
Good 
1 
2 
3 
4 
5 
Poor 
Pressure 
Dampers – done by rods – in ear canal 
Adequate 
1 
2 
3 
4 
5 
Inadequate 
Weight 
Light 
1 
2 
3 
4 
5 
Very Heavy 
Texture 
Soft 
1 
2 
3 
4 
5 
Rough 
Ability to dissipate generated heat  
Good 
1 
2 
3 
4 
5 
Poor 
Ability to absorb sweat  
Good 
1 
2 
3 
4 
5 
Poor 
Inconvenience when doing tasks 
None 
1 
2 
3 
4 
5 
High 
Insertion 
Easy 
1 
2 
3 
4 
5 
Difficult 
Verbal Communication 
Easy 
1 
2 
3 
4 
5 
Difficult 
 
Overall, how would you classify the protector that was used?  
 
Uncomfortable 
1 
2 
3 
4 
5 
Comfortable 

Cláudia Giglio de Oliveira Gonçalves, Adriana Betes Heupa et al. 
 
92
REFERENCES 
 
[1] 
Arezes, PM; Miguel AS. Hearing protectors acceptability in noise. Ann Occup Hyg., 
2002, 46, 531-36. 
[2] 
Gonçalves, CGO. Saúde do Trabalhador: da estruturação à avaliação de Programas 
de Preservação Auditiva [Occupational Health: from structuring to evaluating 
Hearing Preservation Programs]. São Paulo: Roca, 2009. 
[3] 
Voix, J; Hager, LD. Individual Fit Testing of Hearing Protection Devices. Int J Occup 
Saf Ergon., 2009, 15, 211-19. 
[4] 
Berger, EH. Review and tutorial: methods of measuring the attenuation of hearing 
protection devices. J. Acoust. Soc. Am., 1996, 79, 1655-87. 
[5] 
Gerges, SNY. Protetores auriculares [Hearing protectors], Florianópolis: NR editor; 
2003. 
[6] 
Arezes, PM. Análise do conforto e eficiência de protectores individuais auditivos em 
meio industrial [Analysis of the comfort and efficiency of individual hearing protectors 
in an industrial environment]. 1998. [Dissertação]. Portugal: Universidade do Minho; 
1998.  
[7] 
Berger, EH; Kieper RW; Gauger D. Hearing protection: Surpassing the limits to 
attenuation imposed by the bone-conduction pathways. J Am Soc Acoust., 2003, 114, 
1955-67. 
[8] 
Gerges, SNY. Ruído: Fundamentos e Controle [Noise: Fundamentals and Control]. 2 
ed. Florianópolis: UFSC, 2000. 
[9] 
Mallock, A. Ear protectors. British Patent Specification. 1914 fev, 4821, s/p. 
[10] Tod, HF. Preventing gun-deafness. British Patent Specification. 1914 dez 10, 23.863: 
s/p. 
[11] Morata, TC; Fiorini, AC; Fischer, FM; Krieg, EF; Gozzoli, L.; Colacioppo, S. Factors 
affecting the use of hearing protectors in a population of printing workers. Noise 
health. 2001, 4, 25 - 32. 
[12] Neves, EB; Mello, MGS. O uso de dispositivos de proteção auditiva nos tiros de fuzil e 
de artilharia [The use of hearing protection devices in rifle and artillery shots. 
Collective Health Cad]. Cad. Saúde Coletiva 2007, 15, 97-116. 
[13] Abelenda, CSS. Avaliação do Conforto de Protectores Individuais Auditivos. 2006. 
[Dissertação]. Portugal: Universidade do Minho; 2006. 
[14] Brasil. Norma Regulamentadora n.º 15. Atividades e Operações Insalubres [Regulatory 
Standard No. 15. Unhealthy Activities and Operations]. In: Segurança e Medicina do 
Trabalho. 56º ed. São Paulo: Atlas, 2005. 
[15] United States of America. International Institute of Noise Control Engineering (I-
INCE). 2012. Disponível em: http://www.i-ince.org/. 
 
 

In: Encyclopedia of Audiology and Hearing Research 
ISBN: 978-1-53617-702-2 
Editors: Erno Larivaara and Senja Korhola 
© 2020 Nova Science Publishers, Inc. 
 
 
 
 
 
 
 
Chapter 8 
 
 
 
HEARING IMPAIRMENT AFTER PERINATAL ASPHYXIA 
 
 
Ze Dong Jiang, MD, Ph.D 
Department of Paediatrics, University of Oxford, John Radcliffe Hospital,  
Oxford, United Kingdom, and Division of Neonatology,  
Children’s Hospital, Fudan University, Shanghai, China 
 
 
ABSTRACT 
 
Perinatal asphyxia, i.e., hypoxia-ischemia occurring during perinatal period can 
damage both the cochlea and the neural and central auditory pathway in newborn infants. 
It has been considered to be one of the major risk factors for acquired auditory 
impairment in infants and children. In the last three decades, the immature auditory 
system in human infants has been assessed and monitored mainly using non-invasive 
neurophysiological techniques, typically auditory evoked potentials for functional 
integrity of the auditory pathway and otoacoustic emissions (OAEs) or distortion product 
otoacoustic emissions (DPOAEs) for cochlea function. These techniques have also been 
commonly used to study maturation of the auditory system and detect functional 
abnormalities or impairment of the system. Among these neurophysiological techniques, 
brainstem auditory evoked response (BAER) is the most widely used evoked potential to 
assess the developing auditory system and detect abnormality in clinical conditions that 
may affect the brainstem auditory pathway. This article reviews literatures for the effects 
of perianal asphyxia on the immature peripheral hearing, and mainly discusses our 
findings obtained using the BAER and DPOAEs during the neonatal and postnatal 
periods in term infants after perinatal asphyxia. Particular attention is paid to the dynamic 
changes in BAER threshold during the first one month after perinatal asphyxia. The 
threshold is elevated significantly on day 1. The elevated threshold is then decreased 
progressively on days 3 and 5, continuously decreased more slowly on days 10 and 15, 
and returns to a near normal level in most infants on day 30. During the first month, the 
threshold elevation, suggesting hearing impairment, occurs in one-third of term infants 
after perinatal asphyxia. By the end of the first month, one in ten still has threshold 
elevation. Postnatal studies documented that with increasing age the impaired hearing 
tends to improve further. However, by 3 months after birth, the hearing impairment that 
exists in a small proportion of the infants after perinatal asphyxia is unlike to show any 
                                                        
 Corresponding Author’s Email: zedong.jiang@paediatrics.ox.ac.uk. 

Ze Dong Jiang 
 
94
further significant improvement, and is more likely to be persistent or permanent. These 
findings indicate that hearing impairment after perinatal asphyxia is mostly temporary, 
with only a few infants having persistent impairment. More recently, auditory neuropathy 
has attracted considerable interest. Whether perinatal asphyxia can cause auditory 
neuropathy in human infants remains to be determined, although early animal 
experiments suggested that hypoxia and hypoxia-ischemia in immature animals could 
cause auditory neuropathy. This is an interest area to be explored. 
 
 
INTRODUCTION 
 
In human infants there is a critical period for hearing development that extends from 
before birth to about possibly 3 months after birth (Jiang and Tierney, 1995). During this 
critical period of development, the peripheral auditory system is particularly susceptible to 
various unfavourable factors, including asphyxia (Fahnenstich et al., 1999; Mencher, et al. 1981; 
Newton, 2001; Norton, 2000a,b; Pujol et al., 1990; Uziel, 1985; Wilkinson and Jiang, 2006). 
Perinatal asphyxia, i.e., hypoxia-ischemia occurring during perinatal period, is considered to be 
one of the major risk factors for acquired hearing impairment in infants and children (Borg, 
1997; Flint, 1983; Hecox and Cone 1981; Jiang, 1995,1998; Kountakis et al., 2002; Mencher 
and Mencher, 1999; Mencher, et al. 1981; Newton, 2001; Yasuhara et al., 1986). It is generally 
accepted that hearing impairment after perinatal asphyxia is more likely to be temporary than 
permanent (Borg, 1997; Jiang et al., 2004a). Only a small proportion of infants after perinatal 
asphyxia have a persistent or permanent hearing impairment (Jiang, 1995,1998; Sano et al., 
2005).  
Unlike in animal experiment, in human infants after perinatal asphyxia, hypoxic-ischaemic 
damage to the cochlea and neural pathway may not be the only cause of hearing impairment. 
Infants after perinatal asphyxia are often associated with other perinatal problems or conditions, 
some of which can also affect the immature hearing, e.g., neonatal meningitis, persistent 
pulmonary hypertension, treatments with ototoxic drugs, and hyperbilirubinaemia, resulting in 
sensorineural hearing impairment and hearing threshold elevation (Hall, 2007; Jiang, 2013; 
Kountakis et al., 2002; Mencher and Mencher, 1999; Marron et al., 1992; Meyer et al., 1999; 
Newton, 2001; Wilkinson and Jiang, 2006). In addition, middle ear disorders, typically middle 
ear effusion, may also partly account for the detected hearing abnormality (e.g., threshold 
elevation). Therefore, when interpreting the cause of hearing impairment in infants after perianal 
asphyxia, one cannot simply attribute the hearing impairment exclusively to perinatal asphyxia. 
The functional status of the immature auditory system can be assessed and monitored 
using non-invasive neurophysiological techniques, typically auditory evoked potentials, 
OAEs or DPOAEs (Hall 2007; Jiang, 2013; Kemp and Ryan, 1993; Norton, 2000a,b; 
Wilkinson and Jiang, 2006). These techniques can also be used to assess maturation of the 
auditory system and detect functional abnormalities or impairment of the system, typically 
after asphyxia. Among these neurophysiological techniques, BAER is the most commonly 
and widely used evoked potential to assess the developing auditory system and detect 
abnormality in clinical problems or conditions that may affect the brainstem auditory 
pathway. This article discusses the effects of perianal asphyxia on peripheral hearing mainly 
in term infants. Particular attention is paid to the findings obtained using the BAER and 
DPOAEs. More recently, auditory neuropathy has attracted considerable interest. A brief 

Hearing Impairment after Perinatal Asphyxia 
 
95
literature review was also made regarding whether perinatal asphyxia can cause auditory 
neuropathy in human infants. So far, there is a lack of reported full studies to demonstrate or 
confirm that perinatal asphyxia can cause auditory neuropathy. 
 
 
PART I. BAER STUDIES 
 
BAER Threshold and Perinatal Hypoxia or Hypoxia-Ischemia 
 
Hearing threshold is inversely related to the magnitude of the endocochlear potential of 
the scala media in the inner ear, which partially determines auditory sensitivity (Gafni and 
Sohmer, 1976; Sewell, 1984). The endocochlear potential is generated by the sodium pump 
that has high energy requirements. Lack of sufficient oxygen supply to the stria vascularis 
suppresses the sodium-potassium pump and hence depresses the endocochlear potential 
(Gafni and Sohmer, 1976). As a result, the same sound intensity stimulus produces a smaller 
receptor potential and cochlear action potential, resulting in an elevation in hearing threshold. 
Hypoxia reduces auditory peripheral sensitivity and increases auditory threshold by 
depressing the endocochlear potential in the scala media of the inner ear (Sohmer et al., 
1986). Early animal experiments showed that the auditory system could recover from hypoxia 
even during the critical period of endocochlear potential development (Cycowicz et al., 
1988).  
The BAER is a major clinically diagnostic tool for both hearing impairment in newborn 
infants with various perinatal conditions or problems, including asphyxia (Hall, 2007; Jiang, 
2013). The threshold of BAER gives a good objective estimate of the amount of hearing loss, 
and has been widely used in audiometry in infants and children (Hecox and Cone, 1981; Jiang 
et al., 2001,2004a-c,2007,2011,2012a; Wang and Jiang, 2015; Yasuhara et al., 1986). It has 
been documented to be very sensitive to arterial blood oxygen content and hypoxia occurring 
during the perinatal period in both human studies and animal experiments (Sohmer et al., 
1989,1994a,b; Sohmer and Freeman, 1991). Experiments in animal models showed that 
BAER threshold and auditory sensitivity are an inverse function of arterial blood oxygen 
levels (Sohmer et al., 1989). After perinatal asphyxia BAER threshold is often elevated, 
which can be interpreted as a reduction of auditory sensitivity due to a depression in the 
endocochlear potential. The elevation is a major pattern of abnormality in the BAER in both 
human neonates and animal models following hypoxia or hypoxia-ischemia (Sohmer and 
Freeman, 1991; Sohmer et al., 1989,1994a,b). In animals with experimental hypoxia, BAER 
threshold was found to be elevated during and immediately following hypoxia but returned to 
normal several hours later after breathing room air (Cycowicz et al., 1988). Similarly, in 
human neonates, BAER threshold was found to be elevated shortly after perinatal hypoxia-
ischemia, and the elevation often recovers later (Jiang, 1995,1998; Jiang et al., 2004a). 
Animal experiments revealed that BAER abnormalities following hypoxia are mainly due 
to ischemia even when the initial insult is hypoxic alone (Sohmer et al., 1986). Hypoxaemia 
has a direct effect on the cochlea and an indirect effect by way of cardiovascular collapse and 
cerebral ischemia (Sohmer et al., 1986). Persistent, particularly permanent, hearing 
impairment is primarily caused by prolonged periods of hypoxic-ischaemic insult secondary 

Ze Dong Jiang 
 
96
to the hypoxia, as opposed to primary or direct hypoxic injury, and the complicated factors 
associated with hypoxia.  
 
 
Change in BAER Threshold during the Neonatal Period 
 
To explore the time course of change in hearing threshold during the neonatal period after 
asphyxia Jiang et al. (2004a) recorded serially the BAER from birth to the end of the first 
month in term infants who suffered perinatal asphyxia (Jiang et al., 2004a). As shown in Figs. 
1 and 2, BAER threshold in infants after perinatal asphyxia was elevated significantly on day 
1. The elevated threshold was decreased progressively on days 3 and 5, but was still 
significantly higher than in normal controls. The decrease, though slower, continued on days 
10 and 15. The threshold approached to a normal level on da 30. These results suggest that 
hearing threshold in infants after perinatal asphyxia is significantly elevated on the first day 
after birth, and then decreased progressively. After day 5, the elevated threshold is 
continuously decreased, but more slowly with some variation. By the end of the first month, 
the threshold has nearly returned to normal. Clearly, the elevated threshold shortly after 
perinatal asphyxia is decreased progressively with the increase in postnatal age. Significant 
(i.e., moderate to severe) elevation of the hearing threshold occurs mainly during the first 
week, especially on day 1. Thereafter, significant elevation is very rare.  
In some infants after perinatal asphyxia, BAER threshold elevation could occur and/or 
becomes more significant after the first 3-5 days after birth (Jiang et al., 2004a). This 
elevation is unlikely to be caused by perinatal hypoxic-ischaemic damage to the auditory 
system, but more likely to be due to middle ear disorders. This is because perinatal hypoxic-
ischaemic damage to the auditory system is unlikely to start more than 3-5 days after birth. 
Thus, the slightly further elevation on day 7, shown in Figures 1 and 2, is at least partly 
explained by the occurrence of middle ear disorders. The extent of threshold elevation 
contributed to by hypoxia-ischemia should be less than the level of the elevation depicted in 
Figures 1 and 2. Although it is difficult to assess accurately the contribution of middle ear 
disorders to the elevation of BAER threshold, it is clear that peripheral hearing impairment 
due to hypoxic-ischaemic insult recovers progressively during the neonatal period. 
The elevation in BAER threshold after perinatal asphyxia was generally more significant 
in infants who had severe hypoxic-ischaemic encephalopathy. However, the relationship 
between BAER threshold and the severity of encephalopathy varied with individuals (Jiang et 
al., 2004a). The infants who had severe encephalopathy were not necessarily associated with 
BAER threshold elevation. On the other hand, some infants who had mild encephalopathy 
were associated with significant threshold elevation. As shown in Figure 3, the group mean 
BAER threshold in infants with mild encephalopathy was slightly higher than in infants with 
moderate encephalopathy, although this difference did not reach statistical significance. 
BAER threshold correlated only weakly, though statistically significantly, with the severity of 
encephalopathy during the first 3 days, and did not thereafter.  

Hearing Impairment after Perinatal Asphyxia 
 
97
 
Figure 1. Group means and standard errors of BAER thresholds in infants after perinatal asphyxia on 
different days during the first month after birth. The BAER threshold in normal controls is almost the 
same on day 1-3 and day 30, whereas the mean threshold in the infants after asphyxia changes 
significantly with the increase in the day after birth. The mean threshold after asphyxia is elevated 
significantly on day 1. The elevated threshold is decreased progressively on day 3 and 5, but is still 
significantly higher than that in the controls. The threshold is elevated slightly further on day 7. 
Thereafter, the elevated threshold is continuously decreased more slowly on day 10 and day 15. By the 
end of the first month, the threshold is decreased to a level slightly higher than in the controls, and does 
not differ significantly between the asphyxiated and normal groups. 
 
Figure 2. Distribution of BAER thresholds in infants after perinatal asphyxia on different days during 
the first month after birth. Throughout the first month, most of the infants after asphyxia have a BAER 
threshold within normal range (≤20 dB nHL). On day 1, nearly one-third (31.7%) of the infants show 
threshold elevation (i.e., >20 dB nHL). Thereafter, the rate of the elevation is decreased progressively. 
On day 30, only 10.6% of the infants show threshold elevation. 
Day after birth
30
15
10
7
5
3
1
30
25
20
15
10
5
0
Asphyxia
Normal
BAER threshold
Day after birth
30
15
10
7
5
3
1
70
60
50
40
30
20
10
0
dB nHL
 >= 60
  55
  50
  45
  40
  35
  30
  25
  <=20

Ze Dong Jiang 
 
98
 
Figure 3. Means and standard errors of BAER thresholds in infants with different (mild, moderate and 
severe) degrees of hypoxic-ischaemic encephalopathy after perinatal asphyxia on different days during 
the first month after birth. Within the first 10 days, BAER elevation is always most significant in 
infants with severe encephalopathy. There is a significant difference in BAER threshold among 
different degrees of encephalopathy on day 1, but not on any other days. The threshold in infants with 
severe encephalopathy is significant higher than in infants with mild and moderate encephalopathy on 
day 1 and on day 3. No significant difference is found on any other days. 
These findings suggest that hearing threshold after perinatal asphyxia does not correlates 
closely with the severity of brain damage. There are at least two possible explanations of this 
weak correlation. One is that there are individual differences in the vulnerability of peripheral 
auditory system and central system to hypoxic-ischaemic insult. The other is that threshold 
elevation which is related to other confounding factors, particularly middle ear disorders, can 
occur in infants with or without hypoxic-ischaemic brain damage. The threshold elevation 
starting after days 3-5 is more likely to be due to middle ear disorders, although the elevation 
during the first 3 days is most likely to be caused by or related to hypoxic-ischaemic damage 
to the peripheral auditory system. 
 
 
Prevalence of Hearing Impairment during the Neonatal Period 
 
The prevalence of hearing impairment in infants after perinatal asphyxia has been 
reported to be varied widely (e.g., Abramovich et al., 1979; Anagnostakis et al., 1982; Flint, 
1983; Hecox and Cone, 1981; Jiang et al., 2004a; Mencher, et al., 1981; Yasuhara et al., 
1986). In Flint’s report (1983), hypoxia induced hearing impairment accounted for 36% of the 
perinatal incidence. It seems that perinatal hypoxia is the most important cause of perinatally 
acquired hearing impairment. Mencher, et al. (1981) and Robertson and Whyte (1983) found 
that nearly 30% of the congenital hearing impairment was related to hypoxia. Hecox and Cone 
(1981) reported that peripheral hearing impairment occurred in 20% of infants within 3 months 
Day after birth
30
15
10
7
5
3
1
50
40
30
20
10
0
HIE
Normal
control
Mild
Moderate
Severe

Hearing Impairment after Perinatal Asphyxia 
 
99
after the onset of asphyxia. The study by Yasuhara et al. (1986) found that as high as 67% of the 
infants with severe asphyxia demonstrated threshold elevation. In contrast, some others 
described an incidence of hearing impairment as low as 9% (Abramovich et al., 1979; 
Anagnostakis et al., 1982). The considerable variation in the reported prevalence of hearing 
impairment (between 9-67%) are largely related to the differences in the population studied, the 
severity of asphyxia, and the age or the time after birth at which the subjects were examined 
among various studies. It should be noted that hearing threshold elevation and impairment in 
infants after perinatal asphyxia can be related to or due to other associated perinatal 
complications or risk factors, not exclusively asphyxia. Most previous investigators did not 
describe whether they had strictly excluded other perinatal complications that may cause hearing 
impairment and confound their results. Therefore, there might be certain bias in the reported 
prevalence of hearing impairment due to perinatal asphyxia.  
After perinatal asphyxia, with the improvement of clinical condition the elevated BAER 
threshold usually returns to normal or near normal. Figure 2 shows the distribution of term 
infants with different BAER thresholds after perinatal asphyxia on day 1 through to day 30 after 
birth (Jiang et al., 2004a). Elevation of BAER threshold occurred in 31.7% of the infants on 
day 1, and 34.5% during the first 3 days, suggesting that hearing threshold is elevated in 
about one-third of term infants after perinatal asphyxia (Jiang et al., 2004a). Thereafter, the 
rate of elevation was decreased progressively. By the end of the first month, the elevated 
threshold in most infants has returned to a near normal level, with only 10.6% of the infants 
showing threshold elevation. Moderate to severe elevation occurred mainly during the first 
week and severe elevation occurred predominately on day 1. Taken together, peripheral 
hearing impairment, which is related to hypoxic-ischaemic insult, occurs in about one-third of 
the infants after perinatal asphyxia during the perinatal period. The impairment persists in about 
one in ten of the infants by the end of the first month after birth. 
 
 
Postnatal Change in BAER Threshold  
 
After the first month, the elevation of hearing threshold due to perinatal asphyxia recovers 
further in most infants. Jiang (1998) followed BAER during the first year of life in 44 infants 
who suffered perinatal asphyxia. The postnatal change in BAER threshold was generally 
similar to that in normal controls, i.e., the threshold was decreased with an increase in age, 
with a rapid change occurring at the first three months. However, the threshold, particularly in 
severe asphyxiated infants, was higher compared to normal controls, mainly at the first three 
months. In those asphyxiated infants who had a threshold elevation (greater than 20 dB HL), 
the latency-intensity functions for wave V were different from the age-matched normal 
controls at low stimulus intensities and the difference was much smaller at high intensities, 
suggesting sensorineural hearing impairment. At 3 months of age, BAER threshold elevation 
was seen in 4.3% of the infants after mild asphyxia and 9.5% of the infants after severe 
asphyxia. Thereafter, the elevated BAER threshold in these infants did not show any further 
significant improvement. These observations indicate that after perinatal asphyxia the 
elevated hearing threshold occurring shortly after birth continues to improve up to about 3 
months post term. Thereafter, the threshold elevation, which occurs only in a few cases, often 
does not show any further significant improvement, suggesting persistent or permanent 
hearing impairment. 

Ze Dong Jiang 
 
100
Persistent or Permanent Hearing Impairment  
 
Previous studies showed that persistent or permanent hearing impairment occurs in only a 
small proportion of the infants or children after perinatal asphyxia (Jiang, 1995,1998; Jiang et 
al., 2004a; Zheng and Jiang, 1992). In an effort to explore the long-term effect of asphyxia on 
the development of infant’s hearing, Jiang (1995) examined BAER in children who survived 
perinatal asphyxia. Most of these children had a BAER threshold less than 20 dB nHL. In 48 
children without developmental delay or cerebral palsy, only 3 (6.8%) exhibited a slightly 
elevated response threshold (>20 dB nHL). In 41 children with developmental delay or 
cerebral palsy, BAER threshold was generally higher than those without developmental delay 
or cerebral palsy. 7 (17.1%) children had a BAER threshold greater than 20 dB nHL, which 
was higher than in those children without developmental delay and cerebral palsy (6.5%). It 
appears that there was some coincidence in the occurrence of peripheral hearing impairment 
and residual neurodevelopmental deficits, although this correlation was not statistically 
significant (Jiang, 1995).  
The latencies of BAER waves are generally normal in the children with a normal 
threshold after perinatal asphyxia, but prolonged in those with threshold elevation. The 
latency and latency-intensity function for wave V in the children with threshold elevation 
often show a large difference from the age-matched normal controls at low click intensities, 
whereas the difference is much smaller at high intensities (Jiang, 1995). Such a characteristic 
change in the latency-intensity function is indicative of sensorineural hearing impairment.  
The prevalence of persistent or permanent hearing impairment is higher in the children 
after severe perinatal asphyxia than in those after mild asphyxia (Jiang, 1995). Nevertheless, 
this prevalence is not closely related to the degree of perinatal asphyxia. This is consistent 
with clinical observations of the relationship between the occurrence of neurodevelopmental 
deficits and the severity of perinatal asphyxia. Neurodevelopmental deficits occur not only 
after severe perinatal asphyxia but also occur after mild asphyxia. Some children with mild 
perinatal asphyxia exhibit residual neurodevelopmental deficits, while many children with 
severe asphyxia may develop without any apparent residual deficits. This relatively poor 
relationship is at least partly interpreted by the susceptibility to hypoxia that varies among 
individuals. In addition, the occurrence of hypoxic injury to the auditory system depends on 
the duration as well as the degree of asphyxia.  
To detect any differences in the effect of perinatal and postnatal asphyxia on the 
developing auditory system, Jiang (1995) examined BAER in children who survived severe, 
prolonged postnatal asphyxia due to serious pneumonia associated with severe hypoxia and 
respiratory failure, aspiration of foreign bodies with severe hypoxia, or drowning. These 
children exhibited residual neurodevelopmental deficits. In contrast to those who survived 
server perinatal asphyxia, the children survived postnatal asphyxia did not show any evidence 
of permanent peripheral hearing impairment. It seems that a critical period of particularly 
sensitive to the effect of hypoxia may exist during the development of human peripheral 
auditory system. This period may range from some time prenatally to some time shortly after 
birth, probably the third postnatal month (Jiang and Tierney, 1995). After the critical period, 
hypoxia is unlikely to lead to permanent peripheral hearing impairment. 
The exact sites of lesions in the auditory pathway in childen with hearing impairment 
after perinatal asphyxia remain to be determined. Orita et al. (2002) conducted a 
histopathologic examination on the temporal bones in a patient with severe bilateral 

Hearing Impairment after Perinatal Asphyxia 
 
101
sensorineural hearing impairment after perinatal and postnatal hypoxia and asphyxia. In the 
left temporal bone, there were severe atrophy of the organ of Corti throughout the entire 
cochlea, decrease in the number of the spiral ganglion cells especially in the basal turn, and 
mild atrophy of saccular macula. In the right temporal bone, similar but milder abnormalities 
were observed in the inner ear, No other distinct pathologic finding was observed in either 
ear. These findings suggest that the presence of severe hypoxia-ischemia causes 
cochleosaccular atrophy in the inner ear. Such pathology could manifest elevation in BAER 
threshold and prolongation in BAER wave latencies, and abnormality in OAEs or DPOAEs. 
 
 
PART II. DOAES STUDIES 
 
DPOAE Changes and Cochlear Impairment  
 
Understanding of what frequencies on the audiogram of the cochlea are affected by 
asphyxia is important for intervention of hearing impairment after perinatal asphyxia. The 
BAER, which is elicited commonly by click stimuli, lacks frequency-specificity, and cannot 
identify which frequencies of the cochlear audiogram are affected in the cases with hearing 
impairment. In contrast, DPOAEs can objectively assess frequency-specific hearing, and have 
been widely used to examine cochlear function (American Academy of Pediatrics, 1999; Joint 
Committee on Infant Hearing, 1995,2000; Salata et al., 1998). The DP audiogram has proven 
useful in estimating audiometric configuration (Gaskill and Brown, 1993; Kimberley et al., 
1994; Lonsbury-Martin and Martin, 1990). The frequency pattern of DPOAE amplitude 
reduction or absence often follows the configuration of hearing impairment in the audiogram. 
DPOAEs, which can be obtained quickly, have now become a widely used objective 
audiometric tool to assess infant’s cochlear function and identify hearing impairment (Berg et 
al., 2005; Cone-Wesson et al., 2000; Gorga et al., 2000; Jiang et al., 2012b; Joint Committee 
on Infant Hearing, 1995,2000; Kemp and Ryan, 1993; Mencher and Mencher, 1999; Norton 
et al., 2000a,b; Vatovec et al., 2001). The emissions are absent when hearing impairment due 
to cochlear pathology is 45 to 50 dB or greater (Sininger and Abdala, 1998). Early 
experiments showed that hypoxia for a few minutes can severely inhibit OAE (Frolenkov et 
al., 1998; Kemp and Brown, 1984; Whitehead et al., 1992). Severe or lethal hypoxia can 
result in the DPOAEs disappearing at low-level stimulation (45–60 dB sound pressure level - 
SPL), as a result of the damage of cochlea (Rebillard et al., 1993).  
Severe hypoxemia has a direct effect on the cochlea and an indirect effect by way of 
cardiovascular collapse and cerebral ischemia (Sohmer et al., 1986). The effects may lead to 
sensory or sensorineural hearing impairment, although the impairment is mostly temporary 
(Jiang, 1998; Jiang et al., 2004a). Previous BAER studies in experimental animals suggests 
that peripheral hearing impairment after hypoxia is reversible and the recovery occurs soon 
after the termination of hypoxia (Sohmer et al., 1994a; Sohmer H, Freeman, 1991). Similar 
finding was observed in the human fetus (Sohmer et al., 1994b). However, permanent 
sensorineural hearing impairment does happen in some infants after perinatal asphyxia (Jiang, 
1995; Sano et al., 2005). For these infants, selection and implementation of a proper plan to 
intervene in hearing impairment, e.g., fitting a hearing aid or performing a cochlear implant, 
requires accurate information about the hearing impairment at all frequencies important for 

Ze Dong Jiang 
 
102
speech and language development. Thus, it is crucial to obtain detailed information about 
cochlear function in the infant or child who has hearing impairment.  
 
 
DPOAE Changes after Perinatal Asphyxia  
 
To elucidate what frequencies in the cochlear audiogram are susceptible to perinatal 
asphyxia we studied DPOAEs across the frequencies between 0.50 and 10 kHz during the 
first postnatal year in term infants who suffered perinatal asphyxia (Jiang et al., 2005,2012b; 
Zang et al., 2008). DPOAEs were obtained serially at 3-5 days after birth, and 1, 6 and 12 
months of age to examine functional status of the cochlea and depict a picture of age-related 
postnatal changes in DPOAE and, in turn, cochlear function after perinatal asphyxia.  
DPOAEs at 3-5 days after birth. DPOAE pass rates across the frequency range between 1 
and 10 kHz, particularly at 1-5 kHz in the infants after perinatal asphyxia were all 
significantly lower than in age-matched normal term controls. The overall DPOAE pass rate 
(83.7%) was also significantly lower than in normal controls (95.7%). In normal infants 
DPOAE pass rate was decreased with the decrease in the frequency of the f2 primary tone 
(Zang and Jiang, 2007). In the infants after perinatal asphyxia DPOAE pass rates at various 
frequencies showed a similar trend, although the decrease was more significantly. The pass 
rates, particular at 1-5 kHz, were much lower than in normal infants. The overall DPOAE 
pass rate was also lower. Obviously, perinatal asphyxia suppresses neonatal DPOAEs at the 
frequencies across 1-10 kHz, mainly 1-5 kHz. 
DPOAEs at 1 month. The infants after perinatal asphyxia showed a further decrease in 
DPOAE pass rates at all frequencies (Jiang et al., 2005). This was more significant at 1 and 2 
kHz than at other frequencies. The overall DPOAE pass rate (83.8%) was the same as that on 
days 3-5 (83.7%). It seems that the frequency-specific hearing impairment detected on days 
3-5 after birth remains or even slightly worsens at the later neonatal period. 8.8% of the tested 
ears with a type A tympanogram (i.e., without middle ear disorders) failed the DPOAE test, 
suggesting that nearly 10% of the infants after perinatal asphyxia have hearing impairment 
that persists for at least 1 month. It seems that the cochlear impairment detected on days 3-5 
after birth is unlikely to improve or even slightly worsens in the later neonatal period. This is 
in agreement with our finding of 10.6% of the asphyxiated infants showing BAER threshold 
elevation on day 30 after birth, i.e., one in ten having persisten hearing impairment (Jiang et al., 
2004a). 
DPOAEs at 6 months. DPOAE pass rates, mainly at the frequencies 1-4 kHz, in the 
infants after perinatal asphyxia were lower than those in age-matched normal infants (Zang et 
al., 2008). The overall DPOAE pass rate (81.8%) remained lower, compared with that 
(98.5%) in normal controls. Apparently, there is still a certain degree of impairment in 
cochlear function at 6 months after birth in the infants who suffer perinatal asphyxia.  
The general pattern of DPOAE pass rates at various frequencies at 6 months was similar 
to that obtained at 1 month of age (Jiang et al., 2005). The same was true of overall DPOAE 
pass rate. However, compared to those at 1 month, DPOAE pass rates at 6 months were 
increased at almost all frequencies. The increase was statistically significant at 3, and 5-8 
kHz. Thus, DPOAE pass rates in the infants after perinatal asphyxia has demonstrated some 
improvement. With time passing, the cochlear impairment due to perinatal asphyxia tends to 

Hearing Impairment after Perinatal Asphyxia 
 
103
recover, but there still is a certain degree of impairment, mainly at 1-4 kHz, at 6 months of 
age. 
 
Figure 4. DPOAE pass rate (%) at various frequencies of the f2 primary tone in infants after perinatal 
asphyxia during the first year of life. The date of DPOAEs on days 3-5 after birth are not included 
because no tympanometry was performed at that time and, thus, a possible certain effect of middle ear 
disorders in some infants on DPOAEs cannot be excluded. As the age increases from 1 month onwards, 
the pass rates at most frequencies tend to be increased, suggesting some improvement in cochlear 
impairment with time passing.  
DPOAEs at 1 year. Compared to age-marched normal infants, the infants after perinatal 
asphyxia showed similar pattern of the pass rates at various frequencies of the f2 primary tone, 
but the pass rates at most individual frequencies remained lower (Jiang et al., 2012b). 
DPOAE pass rates in the infants after perinatal asphyxia were decreased at all frequencies of 
the f2 primary tone between 0.75 and 10 kHz, particularly at 1 and 2 kHz. The pass rates at all 
1-10 kHz, except for 6 kHz, of the f2 primary tone were significantly lower than those in the 
controls (Figure 4). The greatest difference occurred at the frequencies 1 and 2 kHz. The 
overall DPOAE pass rate in the infants after perinatal asphyxia (84.9%) was significantly 
lower than the rate in the controls (100.0%). These results suggest that after perinatal 
asphyxia cochlear function, particularly at 1 and 2 kHz, remains relatively poor at 1 year of 
age. 
Compared to those at 6 months after perinatal asphyxia, DPOAE pass rates at 1 year were 
increased at most frequencies, with a statistically significant difference at 0.5 kHz. The 
overall DPOAE pass rate at 1 year (84.9%) was slightly greater than at 6 months (81.8%). 
Thus, during the second half of the first year of life the impaired cochlear function in infants 
born with perinatal asphyxia is slightly improved. As a whole, at 1 year DPOAE pass rates at 
most frequencies tended to be increased when compared with those obtained at earlier ages. It 
appears that following the hypoxic-ischemic insult durig the perinatal period, the impairment 

Ze Dong Jiang 
 
104
in cochlear function improves slightly with time passing during the first postnatal year of life. 
By the end of first year, there is still a certain degree of cochlear impairment.  
Persistent decrease in cochlear function at 1 and 2 kHz. The above DPOAE results in 
term infants after perinatal asphyxia during the first year of life depict a picture of postnatal 
changes in DPOAEs and, in turn, cochlear function after perinatal asphyxia. We pooled 
together the DPOAE data, obtained at different ages during the first 1 year, and plotted the 
data in Figure 4 showing postnatal changes in DPOAEs after perinatal asphyxia (Jiang et al., 
2005; Zang et al., 2008). There is a tendency of increase in DPOAE pass rates at almost all 
frequencies of the f2 primary tone from 1 month to 1 year of age although the pass rate at 1 
kHz was decreased slightly. These longitudinal DPOAEs studies demonstrated that perinatal 
hypoxia-ischimia adversely affects functional status of the cochlea, specifically the outer hair 
cells. Within the first few days after birth, cochlear function is mainly affected or impaired at 
1-5 kHz, particularly 1 and 2 kHz, suggesting that hypoxic-ischemic insult occurring during 
the perinatal period adversely affects newborn cochlear function. During the postnatal 
development, there is only a slight improvement in the cochlear impairment. By the end of 
the first year, cochlear function, mainly at 1 and 2 kHz, remains relatively poor. It appears 
that cochlear impairment attributable to perinatal asphyxia is unlikely to completely recover 
in some infants. These findings contribute to our understanding of the effect of perinatal 
asphyxia on cochlear function. The finding of persistent impairment at 1 and 2 kHz during the 
first year of life provides valuable information for early interventions of hearing impairment 
in infants after perinatal asphyxia, particularly for hearing aid fitting or cochlear implant that 
requires accurate information about the hearing impairment at all frequencies important for 
speech and language development. 
 
 
PART III. AUDITORY NEUROPATHY  
 
The most common type of permanent hearing impairment is sensorineural hearing 
impairment. Auditory neuropathy, also known as Auditory Dysynchrony or Auditory 
Neuropathy Spectrum Disorder, is a less common type of hearing impairment. It was first 
identified in the 1980s when OAEs became available to measure cochlea function. It is a 
hearing disorder where outer hair cell function within the cochlea is normal, but inner hair 
cell and/or the auditory nerve function is disrupted. The exact site of lesion for auditory 
neuropathy remains to be determined. The possibilities include cochlear inner hair cells, 
cochlear spiral ganglia, the synapse between the inner hair cells and the auditory nerve and 
the auditory nerve (Starr et al., 1996).  
Auditory neuropathy is a heterogeneous disorder which can have either congenital or 
acquired causes. The aetiology of auditory neuropathy is vast, which may include 
prematurity, hyperbilirubinaemia, anoxia, hypoxia, congenital brain anomalies, ototoxic drug 
exposure, and genetic factors. It is estimated that the largest proportion (approximately 40%) 
of auditory neuropathy have an underlying genetic basis, which can be inherited in both 
syndromic and non syndromic conditions (Manchaiah et al., 2011). Different gene mutations 
may trigger different pathological changes in patients with auditory neuropathy.  
In experimental animal studies, there is evidence suggsting that perinatal anoxia or 
hypoxia can result in auditory neuropathy. Harrison (1998) described an animal model of 

Hearing Impairment after Perinatal Asphyxia 
 
105
auditory neuropathy in which subjects have extensive, scattered inner hair cell loss but with a 
relatively intact outer hair cell population, produced in the chinchilla by treatment with the 
anticancer agent carboplatin. They found that in these chinchilla, OAEs and cochlear 
microphonics remained normal while BAER thresholds were significantly elevated. However, 
the response thresholds in the central auditory neurons (in the inferior colliculus) were 
considerably lower (by up to 50 dB) than BAER thresholds. The authors suggested that 
scattered inner hair cell lesions can also result from long-term cochlear hypoxia, which is 
likely candidate for the etiology of many types of auditory neuropathy in human subjects. 
Later, Sawada et al. (2001) examined the effects of long-term mild hypoxia and of 
glutamate poisoning on the functional properties of the cochlea. They used OAEs and 
cochlear microphonics to monitor outer hair cell activity and used cochlear action potentials 
or BAER to measure inner hair cell/cochlear afferent function. In contrast to the effects of 
acute anoxia, in which all aspects of cochlear function were simultaneously lost, mild long-
term hypoxia resulted in a clear differential effect on outer versus inner hair cell systems. 
During a 2-hour period of mild hypoxia, BAER amplitude and threshold deteriorates 
significantly, whereas outer hair cell function, as reflected by otoacoustic emissions, showed 
little or no change. A similar dissociation between inner and outer hair cell function was 
observed during instillation of glutamate, where the cochlear microphonic and the otoacoustic 
emissions were unchanged, whereas cochlear action potential amplitudes were reduced. Thus, 
there was a difference in vulnerability of inner and outer hair cell systems. The inner hair 
cell/cochlear afferent system is vulnerable to long-term, mild hypoxia; this may be an 
etiologic factor in hearing impairment of cochlear origin, particularly in high-risk birth infants 
with auditory neuropathy.  
Whether perinatal asphyxia can cause auditory neuropathy in human infants remains to 
be determined. Although perinatal asphyxia has been suggested to be a possible risk factor of 
auditory neuropathy in infants (Xu et al., 2011), so far there is a lack of reported full studies 
in human infants to demonstrate or confirm that perinatal asphyxia can result in auditory 
neuropathy. This is certainly an interest area to be explored. 
 
 
REFERENCES 
 
Abramovich SJ, Gregory S, Slemick M, Stewart A. Hearing loss in very low birth-weight 
infants treated with neonatal intensive care. Arch Dis Child 1979;54:421-6. 
American Academy of Pediatrics. Newborn and infant hearing loss: detection and 
intervention. Pediatrics 1999;103:527-30. 
Anagnostakis D, Petmezakis J, Papazissis G, Messaritatis J, Matsaniotis N. Hearing loss in 
low-birth-weight infants. Am J Dis Child 1982;136:602-4. 
Berg AL, Spitzer JB, Towers HM, Bartosiewicz C, Diamond BE. Newborn hearing screening 
in the NICU: profile of failed auditory brainstem response/passed otoacoustic emission. 
Pediatrics 2005;116:933-8.  
Borg E. Perinatal asphyxia, hypoxia, ischemia and hearing loss. An overview. Scand Audiol 
1997;26:77-91. 

Ze Dong Jiang 
 
106
Cone-Wesson B, Vohr BR, Sininger YS, Widen JE, Folsom RC, Gorga MP, Norton SJ. 
Identification of neonatal hearing impairment: infants with hearing loss. Ear Hear 
2000;21:488-507.  
Cycowicz Y, Schmuel M, Freeman S, Wanszelbaum A, Sohmer H. Perinatal hypoxia and 
auditory brainstem response thresholds: no evidence of permanent hearing loss. Hear Res 
1988;33:239-44. 
Fahnenstich H, Rabe H, Rossi R, Hartmann S, Gortner L. Neonatal screening for hearing 
disorders in infants at risk: incidence, risk factors, and follow-up. Pediatrics 
1999;104:900-4. 
Flint EF. Severe childhood deafness in Glasgow, 1965-1979. J Laryngol Otol 1983;97:421-5. 
Frolenkov GI, Belyantseva IA, Kurc M, Mastroianni MA, KachaR B. Cochlear outer hair cell 
electromotility can provide force for both low and high intensity distortion product 
otoacoustic emissions. Hear Res 1998;126:67-74. 
Gafni M, Sohmer H. Intermediate endocochlear potential levels induced by hypoxia. Acta 
Otolaryngol (Stockh) 1976;82:345-8. 
Gaskill SA, Brown AM. Comparison the level of the acoustic distortion product, 2f1–f2, with 
behavioural threshold audiograms from normal-hearing and hearing-impaired ears. Br J 
Audiol 1993;27:397-407. 
Gorga MP, Norton SJ, Sininger YS, Cone-Wesson B, Folsom RC, Vohr BR, Widen JE, Neely 
ST. Identification of neonatal hearing impairment: distortion product otoacoustic 
emissions during the perinatal period. Ear Hear 2000;21:400-24.  
Hall III JW. ABR: Pediatric clinical application and populations. In: Hall III JW, (ed), New 
Handbook of Auditory Evoked Responses. Boston, Pearson Education, 2007. p. 313-65. 
Harrison RV. An animal model of auditory neuropathy. Ear Hear 1998;19:355-61. 
Hecox K, Cone B. Prognostic importance of brainstem auditory evoked response after 
asphyxia. Neurology 1981;31:1429-33. 
Jiang ZD. Long-term effect of perinatal and postnatal asphyxia on developing human auditory 
brainstem responses: peripheral hearing loss. Int J Pediatr Otorhinolaryngol 1995;33:225-
38. 
Jiang ZD. Maturation of peripheral and brainstem auditory function in the first year following 
perinatal asphyxia - a longitudinal study. J Speech Lang Hear Res 1998;1:83-93. 
Jiang ZD. Brainstem auditory evoked response in neonatal brain damage. Cur Trend Neurol 
2013;7:1-14.  
Jiang ZD, Tierney TS. Development of human peripheral hearing revealed by brainstem 
auditory evoked potentials. Acta Paediatr 1995;84:1216-20. 
Jiang ZD, Brosi DM, Wilkinson AR. Hearing impairment in preterm very low birth weight 
babies at term revealed by brainstem auditory evoked responses. Acta Paediatr 
2001;90:1411-5. 
Jiang ZD, Brosi DM, Wang J, Wilkinson AR. One-third of term babies after perinatal 
hypoxia-ischaemia have transient hearing impairment: dynamic change in hearing 
threshold during the neonatal period. Acta Paediatr 2004a;93:82-7. 
Jiang ZD, Xu X, Yin R, Shao XM, Wilkinson AR. Differential changes in peripheral and 
central components of the brainstem auditory evoked potentials during the neonatal period 
in term infants after perinatal hypoxia-ischaemia. Ann Otol Rhinol Laryngol 
2004b;113:571-6. 

Hearing Impairment after Perinatal Asphyxia 
 
107
Jiang ZD, Yin R, Shao XM, Wilkinson AR. Brainstem auditory impairment during the 
neonatal period in infants after asphyxia: dynamic changes in brainstem auditory evoked 
responses to clicks of different rates. Clin Neurophysiol 2004c;115:1605-15.  
Jiang ZD, Zheng Z, Wilkinson AR. Distortion product otoacoustic emissions in term infants 
after hypoxia-ischaemia. Euro J Pediatr 2005;164:84-7. 
Jiang ZD, Yin R, Wilkinson AR. Brainstem auditory evoked responses in very low 
birthweight infants with chronic lung disease. Eur J Pediatr Neurol 2007;11:153-9. 
Jiang ZD, Zhou Y, Ping LL, Wilkinson AR. Brainstem auditory response findings in late 
preterm infants in intensive care unit. Acta Paediatr 2011;100:51-4. 
Jiang ZD, Ping LL, Chen C, Wilkinson AR. Brainstem auditory response findings in preterm 
infants after neonatal necrotizing enterocolitis. Acta Paediatr 2012a;101;e531-4.  
Jiang ZD, Zang Z, Wilkinson AR. Cochlear function in 1-year-old term infants born with 
hypoxia-ischemia or low Apgar scores. J. Paediatr Child Health 2012b; 2012;48:160-5. 
Joint Committee on Infant Hearing. Position Statement: American Academy of Pediatrics. 
Pediatrics 1995;95:152-6. 
Joint Committee on Infant Hearing. Position statement: principles and guidelines for early 
hearing detection and intervention programs. Pediatrics 2000;106:798-817. 
Kemp DT, Brown AM. Ear canal acoustic and round window electrical correlates of 2f1–f2 
distortion generated in the cochlea. Hear Res 1984;13:39–46. 
Kemp DT, Ryan S. The use of transient evoked otoacoustic emissions in neonatal hearing 
screening programs. Semin Hear 1993;14:30-43. 
Kimberley BP, Hemadi I, Lee AM, Brown DK. Predicting pure tone thresholds in normal and 
hearing-impaired ears with distortion product emission and age. Ear Hear 1994;15:199-
209.  
Lonsbury-Martin BL, Martin GK. The clinical utility of distortion-product otoacoustic 
emissions. Ear Hear 1990;11:144-54. 
Kountakis SE, Skoulas I, Phillips D, Chang CYJ. Risk factors for hearing loss in neonates: a 
prospective study. Am J Otolaryngol 2002;23:133-7. 
Manchaiah VK, Zhao F, Danesh AA, Duprey R. The genetic basis of auditory neuropathy 
spectrum disorder (ANSD). Int J Pediatr Otorhinolaryngol 2011;75:151-8.  
Marron MJ, Crisafi MA, Driscoll JM Jr, Wung JT, Driscoll YT, Fay TH, James LS. Hearing 
and neurodevelopmental outcome in survivors of persistent pulmonary hypertension of 
the newborn. Pediatrics 1992;90:392-6. 
Mencher GT, Baldursson G, Mencher LS. Prologue: The way we were. In G. T. Mencher, & 
S. E. Gerber, (Eds.), Early Management of Hearing Loss. New York: Grune and Stratton 
Inc. 1981. 
Mencher LS, Mencher GT. Neonatal asphyxia, definitive markers and hearing loss. Audiology 
1999;38:291-5. 
Meyer C, Witte J, Hildmann A, Hennecke KH, Schunck KU, Maul K, Franke U, Fahnenstich 
H, Rabe H, Rossi R, Hartmann S, Gortner L. Neonatal screening for hearing disorders in 
infants at risk: incidence, risk factors, and follow-up. Pediatrics 1999;104:900-4. 
Newton V. Adverse perinatal conditions and the inner ear. Semin Neonatol 2001;6:543-51. 
Norton SJ, Gorga MP, Widen JE, Folsom RC, Sininger Y, Cone-Wesson B, Vohr BR, 
Mascher K, Fletcher K. Identification of neonatal hearing impairment: evaluation of 
transient evoked otoacoustic emission, distortion product otoacoustic emission, and 
auditory brain stem response test performance. Ear Hear 2000a;21:508-28.  

Ze Dong Jiang 
 
108
Norton SJ, Gorga MP, Widen JE, Folsom RC, Sininger Y, Cone-Wesson B, Vohr BR, 
Fletcher KA. Identification of neonatal hearing impairment: summary and 
recommendations. Ear Hear 2000b;21:529-35.  
Orita Y, Sando I, Miura M, Haginomori S, Hirsch BE. Cochleosaccular pathology after 
perinatal and postnatal asphyxia: histopathologic findings. Otol Neurotol 2002;23:34-8. 
Pujol R, Lavigne-Rebillard M, Uziel A. Physiological correlation of development of the 
human cochlea. Semin Perinatol 1990;14:275-80. 
Rebillard G, Klis JFL, Lavigne-Rebillard M, Devaux P, Puel JL, Pujol R. Changes in 2f1–f2 
distortion product otoacoustic emission following alterations of cochlear metabolism. Br 
J Audiol 1993;27:117–21. 
Robertson, C. & Whyte, L. prospective identification of infants with hearing loss and multiple 
handicaps. In Mencher, G. T. & S. E. Gerber (Eds.), The Multiply Handicapped Hearing 
Impaired Child. New York, Grune & Stratton Inc. 1983. 
Salata JA, Jacobson JT, Strasnick B. Distortion product otoacoustic emissions hearing 
screening in high-risk newborns. Otolaryngol Head Neck Surg 1998;118:37-43. 
Sano M, Kaga K, Kitazumi E, Kodama K. Sensorineural hearing loss in patients with cerebral 
palsy after asphyxia and hyperbilirubinemia. Int J Pediatr Otorhinolaryngol 
2005;69:1211-7. 
Sawada S, Mori N, Mount RJ, Harrison RV. Differential vulnerability of inner and outer hair 
cell systems to chronic mild hypoxia and glutamate ototoxicity: insights into the cause of 
auditory neuropathy. J Otolaryngol 2001;30:106-14. 
Sininger YS, Abdala C. Physiologic assessment of hearing. In: Lalwani AK, Grund KM, 
editors. Pediatric Otology and Neurotology. Philadelphia: Lippicott-Raven; 1998:127-54. 
Sohmer H, Freeman S, Gafni M, Goitein K. The depression of the auditory nerve-brainstem 
evoked response in hypoxemia - mechanism and site of effect. Electroencephalogr Clin 
Neurophysiol 1986;64:334-8. 
Sohmer H, Freeman S. Hypoxia induced hearing loss in animal models of the fetus in utero. 
Hear Res 1991;55:92-7. 
Sohmer H, Freeman S, Schmuel M. ABR threshold is a function of blood oxygen level. Hear 
Res 1989;40:87-92 
Sohmer H, Goitein K, Freeman S. Improvement in sensorineural auditory threshold of the 
guinea-pig fetus following delivery. Hear Res 1994a;73:116-20. 
Sohmer H, Geal-Dor M, Weinstein D. Human fetal auditory threshold improvement during 
maternal oxygen respiration. Hear Res 1994b;75:145-50. 
Starr A, Picton TW, Sininger Y, Hood LJ, Berlin CI. Auditory Neuropathy. Brain 
1996;119:741–53. 
Sewell WF. The effect of furosemide on the endocochlear potential and auditory nerve fiber 
tuning curves in cats. Hear Res 1984;14:305-14. 
Vatovec J, Velickovic Perat M, Smid L, Gros A. Otoacoustic emissions and auditory 
assessment in infants at risk for early brain damage. Int J Pediatr Otorhinolaryngol 
2001;58:139-45. 
Wang C, Jiang ZD. Brainstem auditory response findings in very preterm babies in intensive 
care unit. Neonatology 2015;107:157-60. 
Whitehead ML, Lonsbury-Martin BL, Martin GK. Evidence for two discrete sources of 2f1–f2 
distortion-product otoacoustic emission in rabbit. II: Differential physiological 
vulnerability. J Acoust Soc Am 1992;92:2662–82. 

Hearing Impairment after Perinatal Asphyxia 
 
109
Wilkinson AR, Jiang ZD. Brainstem auditory evoked response in neonatal neurology. Semin 
Fet Neonatol Med 2006;11:444-51. 
Xu ZM, Cheng WX, Yang XL. Performance of two hearing screening protocols in NICU in 
Shanghai. Int J Pediatr Otorhinolaryngol 2011;75:1225-9.  
Yasuhara A, Kinoshita Y, Hori A, Iwase S, Kobayashi Y. Auditory brainstem response in 
neonates with asphyxia and intracranial haemorrhage. Eur J Pediatr 1986;145:347-50. 
Zang Z, Jiang ZD. Distortion product otoacoustic emissions during the first year in term 
infants: a longitudinal study. Brain Dev 2007;29:346-51. 
Zang Z, Wilkinson AR, Jiang ZD. Distortion product otoacoustic emissions at 6 months in 
term infants after perinatal hypoxia-ischaemia or with a low Apgar score. Eur J Pediatr 
2008;167:575-8. 
Zheng M, Jiang ZD. Development of the brainstem auditory pathway in low birthweight and 
perinatally asphyxiated children with neurological sequelae. Early Hum Dev 1992;30:61-
73. 
 


In: Encyclopedia of Audiology and Hearing Research 
ISBN: 978-1-53617-702-2 
Editors: Erno Larivaara and Senja Korhola 
© 2020 Nova Science Publishers, Inc. 
 
 
 
 
 
 
 
Chapter 9 
 
 
 
“I WILL MAKE A DIFFERENCE”: USING THE 5AS 
MODEL TO IMPROVE ISSUES FOR ADULTS WITH 
LEARNING DISABILITIES AND HEARING LOSS 
 
 
Lynzee McShea*  
Audiology, City Hospitals Sunderland NHS Foundation Trust  
Sunderland UK 
 
 
ABSTRACT 
 
This chapter details a piece of original qualitative research, designed to improve 
audiological issues for adults with learning disabilities and hearing loss who are 
supported by paid caregivers. The research study comprised of four action research 
cycles. The first cycle involved visiting and interviewing paid caregivers in their 
workplace to explore their baseline knowledge and experience of hearing loss and 
hearing aids. Findings indicated that the majority of participants underestimated the 
prevalence of hearing loss and had inaccurate knowledge regarding assessment and 
hearing aids. Symbolic interactionism was used as a theoretical tool to account for their 
perspectives. 
The second cycle involved designing and piloting a training package for a wider 
group of caregivers. The content and delivery of the training was informed by 
suggestions from participants of cycle one and other key stakeholders. Situated learning 
and experiential learning theory were the theoretical basis for the training design. 44 
individuals were trained across 6 homes and constant refinement of the training occurred 
throughout the pilot phase. Early indications were positive; participants’ knowledge and 
confidence increased post training and pledges were made to continue the change 
process. 
The third cycle was concerned with evaluation of the effectiveness of the training. 
Follow up visits were made to each home and a reassessment of knowledge and 
confidence suggested the improvements had largely persisted. Within six months, 96% of 
all pledges made had been achieved and the estimated prevalence of hearing loss in those 
supported by staff increased from 23 to 54%, with several new confirmed diagnoses of 
hearing loss. Focus group discussions were held with staff to explore their experiences 
                                                        
* DProf; Corresponding Author’s Email: lynzee.mcshea@chsft.nhs.uk. 

Lynzee McShea 
 
112
post training. Many described “new chapters” in their working lives, suggesting they had 
completed their own cycle of experiential learning. These discussions also revealed 
barriers to Audiology within primary care which necessitated investigation in a further 
cycle. 
The fourth cycle involved visiting and interviewing primary care practitioners in 
their workplace in order to explore their experiences, in a similar manner to cycle one. 
Findings from this group suggested a significant underestimation of hearing loss in 
people with learning disabilities and negative attitudes around the worth and benefit of 
referral. 
This study has shown that training in audiological issues can evoke a change in 
working practice, which had not been demonstrated in the literature prior. Contact 
between caregivers and Audiology was also important and the need to develop the role of 
Audiology within the community, transpired as one of the key findings of this research. 
Theoretical development of the findings has led to creation of a conceptual model (the 
5As model), which acknowledges the need for multidisciplinary engagement in 
assessment and management of hearing loss in people with learning disabilities. Though 
the model was created for hearing issues, it has broader application and relevance across 
other health disciplines. 
 
Keywords: hearing, caregiver, audiology, training, primary care, 5As model 
 
 
1. INTRODUCTION 
 
Hearing loss is the partial or total inability to perceive (hear) sounds. The spectrum of 
hearing loss is vast, ranging from individuals with no hearing, to those with partial hearing 
loss affecting only certain pitches of sound. The consequences for any individual with hearing 
loss can include increased mortality, poorer health and poorer quality of life (McCormack & 
Fortnum, 2013). Hearing aids are the most common “treatment” for hearing loss and due to 
improved technology, cosmetic appearance and increased awareness, more people are seeking 
hearing aids than ever before. However, this is not the case for people with learning 
disabilities, despite high levels of need (McShea, 2013). Audiological research into the 
assessment and support of people with learning disabilities is lacking (McCracken et al., 
2011). 
 
 
1.1. Coexistence 
 
People with learning disabilities are much more likely to have a hearing problem than the 
general population. Syndromes involving both hearing loss and learning disability are 
relatively common (e.g., Down’s syndrome). Not only is permanent hearing loss more likely 
in people with learning disabilities (Hild et al., 2008), but this group are also more prone to 
ear infections, structural ear abnormalities and wax occlusion (Hardy et al., 2011; Fransman, 
2006). The exact prevalence of hearing loss in people with learning disabilities is unknown. 
The most commonly used estimate is 40% (Emerson et al. 2012), though this is likely to be an 
underestimate, as many of the studies that have published estimates of prevalence have 
arrived at these figures by review of medical records or interview alone (Bent et al., 2015). 
High risk groups (e.g., individuals with Down's syndrome) are thought to experience a 

“I Will Make a Difference” 
 
113
prevalence of hearing loss between 50-100% (Miller & Kiani, 2008). Despite this need, the 
majority of this population have never had their hearing tested (Hardy et al., 2011). 
 
 
1.2. Hearing Loss with Learning Disabilities; Double Jeopardy 
 
For any adult with a hearing loss, there are individual and social consequences 
(Hindhede, 2011). If that hearing loss is unknown or undiagnosed, it affects the potential of 
that individual and underestimates their abilities (Van Schrojenstein Lantman-de Valk, 2005). 
There are many overlapping features of hearing loss and learning disability, for example 
reduced comprehension and communication, frustration, and reduced social engagement 
(Pryce & Gooberman-Hill, 2012). The relationship between learning disability and hearing 
loss is thought to be multiplicative rather than additive (Carvill, 2001). The combined effect 
of having both “conditions” is greater than their sum. This means, it is even more imperative 
that hearing loss is not underestimated by those involved with people with learning 
disabilities. In many cases, the degree of a person’s learning disability may be less severe 
than first thought, following diagnosis and treatment of hearing loss (Sigafoos, 2000). 
Providing habilitation for hearing loss can improve quality of life considerably and 
unexpectedly (McShea et al., 2014). 
 
 
1.3. Conceptualising the Issue; the 3As 
 
With hearing loss so common in people with learning disabilities, and its effect so 
profound, it is imperative that detection improves. I created a model, termed “the 3As” to 
conceptualise this complex situation. The 3As are Access, Assessment and Aftercare and are 
relevant to any health discipline: 
 
 
Access - Individuals with learning disabilities and their advocates must have an 
awareness of the prevalence of hearing loss, must be able to identify hearing loss and 
be able to access appropriate referral to specialist services, via a General Practitioner 
(GP). 
 
Assessment - Once known to specialist services (e.g., Audiology), attendance should 
be facilitated, and accurate, successful diagnostic testing should be achievable. 
 
Aftercare - Following diagnosis of hearing loss, management and rehabilitation 
should be appropriate and adhered to. This may include use of hearing aids, assistive 
listening devices and adherence to any follow up appointments. 
 
1.3.1. Understanding Access 
Prior to accessing services, there needs to be identification of a problem (for example, 
difficulty hearing). In the UK, primary care requires an element of self-referral and 
motivation (Newsam et al., 2010). This in itself is the first barrier to access (Felce et al., 
2008). People with learning disabilities may not have the communication skills to seek 
referral for their own health needs, if indeed there are even aware of a need themselves. 
Therefore, the onus is on another relevant individual close to that person usually the 

Lynzee McShea 
 
114
“caregiver”, to recognise the problem and access appropriate services on their behalf. Clearly, 
this relies on the individual and their caregiver communicating effectively and the caregiver 
having the skills to detect hearing loss. However, caregivers often misjudge the 
communication abilities of people with learning disabilities (Banat et al., 2002; Kevan, 2003).  
Although the clues of hearing loss are usually present, they are often attributed to the 
known learning disability (“diagnostic overshadowing”, Carvill 2001). There is plentiful 
evidence in the literature (e.g., Kerr et al., 2003), to suggest that most caregivers cannot 
recognise hearing loss in those they support. The more severe a learning disability, the more 
likely a hearing loss is to be overlooked (Carvill, 2001). For people with learning disabilities 
who do access services either directly or by proxy, some responsibility also lies with primary 
care regarding their attitudes and beliefs surrounding the worth of referrals to specialist 
services (Lindsey, 2002). As GPs are “gatekeepers” to services, their input is vital, not only 
for access, but also assessment. 
 
1.3.2. Understanding Assessment 
The initial assessment begins in the GP consultation. It is up to the GP to decide whether 
referral to specialist services is necessary. Cook & Lennox (2000) suggest 92% of GPs find it 
difficult to obtain a clear medical history from the individual or their caregiver and that care 
suffers significantly as a result. Not only do these authors advocate further training of GPs, 
but also place some responsibility on the attending caregiver. Lennox et al. (1997) stress the 
importance of having familiar and knowledgeable caregivers attend assessments. 
There is a misconception people with learning disabilities cannot have their hearing 
tested, perhaps because historically, assessment has been suboptimal (McMillan et al., 2000). 
However there are a range of techniques now available in contemporary Audiology (McShea, 
2013) which means it is incorrect to label someone as “untestable”. Audiology assessment is 
the most accurate way of detecting the presence of hearing loss. Lavis et al. (1997), found that 
prevalence of hearing loss was between 13-73% when formal assessment methods were 
employed, compared to 7-20% when relying on staff opinion or questionnaire. 
 
1.3.3. Understanding Aftercare 
Even if the barriers of accessing a service and completing an assessment are overcome, 
the worth of this is called into question if aftercare is not sufficient. Even in the general 
population, first time hearing aid users report feeling overwhelmed and leave the appointment 
with both informational and support needs (Kelly et al., 2013). If these needs are not fulfilled 
by aftercare, it is likely rejection of the device will occur. For many, this outcome could be 
avoided with better training (Gianopoulos et al., 2002). If this is the case for individuals who 
have the self-motivation to attend; it is perhaps even more likely to occur for individuals who 
rely on others to meet their needs. There are misguided assumptions that people with learning 
disabilities will not tolerate hearing aids or benefit from them (Meuwese-Jongejeugd et al., 
2007). Evidence is available to show hearing aid benefit (e.g., Coppens-Hofman et al., 2013), 
but this evidence has not been translated from professional to individual (or caregiver). 
Without this, how can we expect people to comply? 
Though Audiology professionals have a duty to cascade information to patients and their 
caregivers, they are relatively powerless outside of the clinic as to what happens. In the home 
environment, this responsibility shifts to the individual or their caregiver. However, paid 
caregivers have difficulties understanding the use and maintenance of hearing aids (Miller & 

“I Will Make a Difference” 
 
115
Kiani, 2008). Even those who experience hearing aids as part of their work have poor 
practical skills (Rocks & Ferguson, 2014). A survey by Pryce & Gooberman-Hill (2013) 
revealed that 44% of staff working with elderly hearing aid users, did not know how to fix  
broken devices. Many people with learning disabilities also rely on caregivers to be 
responsible for their hearing aid care. Training is recommended around the purpose of hearing 
aids, their function and correct maintenance (Meuwese-Jongejeugd et al., 2007). Because 
caregivers are integral to successful aftercare, this barrier must be overcome and meaningful 
engagement with caregivers must be achieved. 
This research had two broad aims: 
 
1. To improve the awareness and practice of paid caregivers with respect to hearing loss 
and Audiology using training. 
2. To evaluate the effectiveness of this training and determine the key factors in this. 
 
 
2. METHODOLOGY 
 
Action research was my chosen methodology for this study, as it has real emphasis on 
change. It can be viewed as a holistic methodology; not only regarding inclusion of a wider 
community, but also in its approach to problem identification, investigation and change. I am 
unaware of any other research within Audiology that has used action research methodology. 
An increase in qualitative research is occurring in Audiology (Knudsen et al., 2012), and Ng 
(2013) advocated inverting the hierarchy of evidence, to give more weighting to alternative 
methodologies which could explore and understand the experiences of individuals. Moodie et 
al. (2011), feel that collaboration with service users represents a more modern way of 
conducting research in Audiology. 
Action research stems from a critical theory paradigm; which is not only concerned with 
examining practice but also wider influencing factors (Fulton et al., 2013). Critical theory 
does share some commonalities with interpretivism, such as qualitative information gathering 
and appreciation of values and experience. Though interpretivists use qualitative information, 
the researcher remains objective and impartial (Koshy et al., 2011). In critical theory, the 
researcher takes a conscious and active role, and believes value can be obtained from this 
(McNiff & Whitehead, 2011). I felt this approach was preferable as it helped to demonstrate 
the collaborative nature of hearing loss between caregivers and Audiology and aimed to 
reduce any power differential that may have been felt. Action research embraces context 
(Baum et al., 2006), tacit knowledge and experience (Stringer, 1999). By including such 
opinions and experiences, people have a genuine voice and influence (McIntosh, 2010), 
meaning the elite position of the researcher is reduced. By involving caregivers directly in the 
research, a sense of ownership may mean initiatives are more likely to be adopted. 
Action research has often been credited with bridging the gap between theory and 
practice (Holter & Schwartz-Barcott, 1993). One of the strengths of action research clearly 
lies in its flexibility and responsiveness. All action research has certain elements of 
commonality; a holistic and iterative nature, with modifications and evaluations influencing 
subsequent cycles. The cyclical and reflective nature of action research is important. It 
ensures that action is timely and relevant and provides a robust framework for understanding 

Lynzee McShea 
 
116
complex situations (Reason & Bradbury, 2008). This research was completed using four 
cycles, with ethical approval for the whole study granted by the University of Sunderland: 
 
 
Cycle 1 – Defining the problem 
 
Cycle 2 – Designing and piloting a solution 
 
Cycle 3 – Evaluating the solution 
 
Cycle 4 – Investigating an unexpected issue 
 
 
3. CYCLE 1 – DEFINING THE PROBLEM (SEE MCSHEA ET AL., 2015) 
 
In order to work collaboratively with caregivers, this first cycle was necessary to gain an 
understanding of their baseline knowledge. I feel caregivers are central to access and aftercare 
in the 3As model. Did they agree? What did they know about hearing problems and hearing 
aids? An appreciation of their knowledge and beliefs meant it would be possible to work 
together more effectively. 
Qualitative methods are valuable in providing rich and deep information about the 
experience of individuals (Bryman, 2016). Semi-structured interviews were the method 
chosen for this cycle, preferable to group interviews when discussing personal or sensitive 
topics (Patton, 2015). They also allow specific issues to be addressed, and are recommended 
for use in action-orientated research (Bryman, 2016). I felt that I approached Cycle 1 with 
clear subject areas to be addressed (such as knowledge of Audiology, attitudes towards 
hearing aids, etc.) and could therefore use semi-structured interviews in a focussed manner. 
 
 
3.1. Recruitment of Caregivers 
 
Caregivers were recruited following on online search for registered care facilities (n = 40) 
and a recruitment mailing to each one. Though collaboration was a later goal, care managers 
may have felt the initial postal contact was random and unexpected. However, for ethical 
purposes, it was not appropriate to contact facilities I was aware of or had come into contact 
with as a result of my clinical work. Once contact had been made, it was important to ensure 
participants felt involved and empowered. I chose the wording of documents carefully, 
focussing on improvements rather than problems, and emphasised the need for collaboration. 
A return of 18% was achieved and 6 facilities were visited. 
With each facility I attended, I was usually required to meet and speak to the manager 
first. This was a brief conversation, confirming the purpose of my visit and my requirements. 
The manager then introduced me to other staff present and showed me to a room appropriate 
for the interviews. In most cases, this was the dining room. I explained the purpose of the 
interview to each participant and asked them to sign a consent form. This included notice of 
the use of a recording device and possible verbatim quotations. The device was placed 
carefully, to minimise its intrusive nature. Information sheets were available, along with the 
opportunity to ask questions and withdraw at any time. Questions covered several areas 
including: 
 

“I Will Make a Difference” 
 
117
 
Basic demographic information 
 
A contemporary caregiver’s role  
 
Questions about hearing loss  
 
Experiences of training to engage caregivers in the next research cycle 
 
Although the main subject areas were covered with all interviewees, the exact wording 
and question order were flexible. Twenty members of staff were interviewed across the six 
facilities. Almost every interviewee had a National Vocational Qualiﬁcation (NVQ) in Health 
and Social Care, and all were engaged in mandatory training. Analysis of the interviews 
generated ﬁve central themes: 
 
1. Motivation and expectations  
2. Prevalence and experience of hearing loss  
3. Knowledge of hearing, Audiology and hearing aids  
4. Communication 
5. Training and future needs 
 
 
3.2. Motivation and Expectations 
 
People clearly understood that their actions had a direct impact on service users and felt a 
responsibility to ensure their health needs were met. They took satisfaction in their work 
when those they supported were happy and content. Many staff spoke of the need to advocate 
for their service users, regarding health needs. They were aware that it was their responsibility 
to detect needs for those unable to do so themselves. 
Every interviewee was asked to estimate the prevalence of hearing loss in people with 
intellectual disabilities as a percentage. The median estimate was 25%, although estimates 
varied from 2 to 80%. A ﬁfth of staff gave responses of 50% or above. However, almost 
every interviewee said they had only ever known one or two individuals with a hearing loss in 
their whole career: 
 
I haven’t thought about it. I mean with the people we come across, it isn’t an issue. 
 
111 individuals are supported by staff across these facilities, and at the time of these 
visits, only eight individuals were known to have some level of hearing loss. This 7% 
prevalence is below the estimated prevalence of 40% suggesting there was signiﬁcant 
undetected hearing loss in this group. 
 
 
3.3. Knowledge of Hearing, Audiology and Hearing Aids 
 
Not only did people doubt their ability to detect hearing problems, but they also doubted 
the capabilities of Audiology in achieving an accurate hearing assessment: 
 
 

Lynzee McShea 
 
118
To be honest you don’t know, cos a lot of our guests wouldn’t be able to go through a hearing 
test. 
 
In addition to doubts around hearing assessment, there was a very negative perception of 
hearing aids. Every staff member who mentioned hearing aids was critical of them. Not a 
single positive comment was mentioned. 
 
 
3.4. Communication 
 
Effective communication was the greatest challenge for staff and was mentioned by all. 
Staff described a variety of communication strategies, though none of these including hearing. 
 
 
3.5. Training and Future Needs 
 
Interviewees discussed their preferences for training format and content. Personalisation 
of training was suggested, particularly activities that involved simulation or experience. There 
was an overwhelming preference for practical, hands on sessions with group activities. There 
was no clear preference over whether training should occur within the workplace or at an 
external location (e.g., a training centre). 
 
 
3.6. Perception of Audiology 
 
The majority of comments about hearing loss, hearing assessment or hearing aids made 
by participants were incorrect or misinformed. These included: 
 
 
Misconceptions around hearing aids – including who they are suitable for, whistling 
from hearing aids, and their correct function 
 
Incorrect belief that people with learning disabilities cannot have their hearing tested 
or benefit from hearing aids 
 
Misconceptions around the prevalence of hearing loss 
 
It is not expected of staff to have a detailed knowledge of the different assessment 
methods available in Audiology, but it is interesting that the assumption is that it would not 
be possible. If staff hold the belief that hearing professionals would be unable to detect 
hearing problems, it absolves them of responsibility too. Though there is evidence to the 
contrary for these assumptions and beliefs (e.g., Coppens-Hofman et al., 2013), the daily 
experience of caregivers reinforces their perceptions. Viewed in another way, it also suggests 
disengagement between Audiology and the community. As Audiology professionals we are 
aware of the wealth of assessment methods and benefits to hearing aid use, but it appears we 
were not sharing this message with key groups. 
 
 
 

“I Will Make a Difference” 
 
119
3.7. Symbolic Interactionism; A Theory 
 
Symbolic interactionism explains individuals, their actions and the meaning they ascribe 
to events and interactions. Depending on experiences, meanings can vary between people, but 
also within a person over time. The behaviour of an individual can change and adapt 
depending on their environment (Denzin, 1992). This explains why it was important to visit 
individuals in their workplaces and see how their beliefs were contextualised. In my 
“environment”, (e.g., a clinic room where individuals are successfully issued with hearing 
aids), caregiver beliefs about lack of hearing aid benefit do not make sense. However, this is 
not their environment and the judgements they make about hearing aids reflect their prior 
interactions: 
 
They are disastrous little things, the noise it makes, it whistles something terrible on occasions 
 
The experience that this participant had when visiting her Father who wears hearing aids 
has altered her perception. If she began supporting a service user who wore hearing aids who 
also had trouble with whistling, her prior interaction would affect how she dealt with this 
issue. If she had already lost confidence in hearing aids, she may approach the issue more 
negatively, which may affect outcomes for the individual she supported. Kochkin (2007) 
discovered that successful hearing aid uptake relies on at least 3 events: 
 
1. Recognition of hearing loss 
2. Recognition of the problems caused by the hearing loss 
3. Belief that the cost of the problem exceeds the cost of the solution 
  
It is therefore clear to see why hearing aid uptake is low in this community. In addition, if 
staff are supporting individuals with high levels of need on a daily basis and are aware of the 
difficulties they have in completing basic tasks, they are likely to use this experience to doubt 
whether hearing assessment would be possible. If they have undergone a hearing test 
themselves, then their experience of a routine hearing test would further reinforce this belief. 
Though evidence is available in the literature explaining that alternative hearing assessments 
are possible, these are unlikely to be accessed by caregivers, who will rely on their own 
perceptions (Demorest & Erdman, 1994). Because staff spend so much time with those they 
support, they see themselves as “experts” regarding that individual: 
 
The one person that knows more about these people than anybody is the caregiver because 
they are with them all the time. If there was a problem we would spot it. 
 
Despite some holding the belief that hearing loss is extremely common, this perception 
may actually desensitise caregivers to reflecting on the low prevalence of hearing loss in their 
workplaces. Hearing loss is invisible; a known learning disability is not. This is why 
diagnostic overshadowing occurs and why staff have difficulty believing hearing loss could 
be present in someone they know so well (Kevan, 2003). If caregivers are part of a 
community of practice that as a whole does not encounter hearing loss frequently, this view is 
reinforced and becomes difficult to break out of, almost like a “script” (Davies et al., 2000). 
This cultural viewpoint can be difficult to transform (Langer, 1997). 

Lynzee McShea 
 
120
However, social situations are variable, meaning perceptions can change with 
experiences and time (Foddy, 1994). This suggests any misguided or unhelpful perceptions 
can be modified. Just as a long term smoker reluctant to stop smoking, may suddenly cease 
following a close friend’s diagnosis of lung cancer, experiences can alter meanings for people 
if they are relevant and relatable to their circumstances. This first cycle suggested that 
because the daily working practice of caregivers was not sufficient to change their 
perceptions, an experience would need to be created, and this was the focus of Cycle 2. 
 
 
4. CYCLE 2 – DESIGNING AND PILOTING A SOLUTION  
(SEE MCSHEA, 2015) 
 
The first cycle of this research revealed a low prevalence of known hearing loss of only 
7% (compared to an expected prevalence of at least 40%). The caregiver interviews also 
uncovered misconceptions towards hearing aids, often brought about by family (rather than 
work) experience. Despite this, staff generally appeared to be motivated not by financial 
incentives, but by supporting people with learning disabilities. They engaged with training 
that they felt was necessary, though this did not include hearing. 
It became clear that staff were unconsciously incompetent i.e., they would benefit from 
learning about audiological issues, but were unaware of this need. This is partly due to their 
environment and interactions, as explained by symbolic interactionism. The solution to the 
problems identified would therefore be to make staff competent in audiological matters by 
giving them knowledge and changing their perspectives. Dennison & Kirk (1990) suggest the 
first step should be to raise the consciousness of staff, to create a desire to learn. A method of 
learning would be required which not only increased knowledge, but changed perspectives. 
 
 
4.1. Traditional Approaches to Learning 
 
Historically, learning has been “teacher focused”, where information was delivered 
didactically, and knowledge was based on subject only (Dennison & Kirk, 1990). This 
conditioning approach viewed people as machines, who could be programmed (Horwath & 
Morrison, 1999). However, the shortcomings of this approach were realised and the classic 
curriculum was transformed to include elements such as a student-centred focus (Warner 
Weil & McGill, 1989). Terminology changed to shift emphasis from “teaching” to “learning” 
to reflect this. Learning came to be recognised as a social construction (Seely Brown & 
Duguid, 1991), a continuous process involving experience (Kolb, 1984). 
In the traditional view of teaching, students were passive and had no active participation 
(Dennison & Kirk, 1990). This meant their cognition, beliefs and past influences were not 
accounted for. It is clear to see how difficult it would be for some students to engage with 
learning on a deep or personal level, if their thinking did not align closely with their teacher. 
A traditional approach suggests that as long as a teacher has expertise in their field, student 
learning is inevitable (Horwath & Morrison, 1999). This would not have been a suitable 
solution for training of the caregivers in this study and would have gone against the 
collaborative nature of the action research methodology employed. An alternative method of 

“I Will Make a Difference” 
 
121
learning was required, in order to appreciate and encourage the experiences and participation 
of all involved. 
 
 
4.2. Experiential Learning; an Alternative Approach 
 
Warner Weil & McGill (1989) explain that experiential learning is not only a framework, 
but also a philosophy. Experiential learning is also known as action learning, so the parallels 
between it and action research are clear: 
 
Experiential learning is a client focused, support approach to individual group and 
organisational development, which engages learners, using the elements of action, reflection 
and transfer  
Beard & Wilson (2002, p1) 
 
Experiential learning is said to be one of the most effective methods for adults (Burnard, 
1989), particularly as it involves peer-learning (Evans, 1994). Evans also advocated the use of 
experiential learning for individuals discouraged by formal education. Social care workers are 
recognised as generally being low-skilled with few prior qualifications (Philpott, 2014b), 
suggesting formal education did not engage them fully. By approaching transmission of 
knowledge in a more learner centred way, it was hoped caregivers would become involved in 
the learning process (Evans, 1994). 
As well as providing benefits for learners, there is also the expectation that the trainer 
gains something (Dennison & Kirk, 1990). Rather than being present as a traditional teacher, 
the role of the trainer in experiential learning is not neutral in terms of values and feelings 
(Horwath & Morrison, 1999). This brings an authenticity to the learning experience and helps 
to make learners feel this is a shared venture. This also aligns with the aims of action research 
methodology and the dual thrust in this work to increase caregiver knowledge and develop the 
role of the Audiology professional. 
 
 
4.3. The Kolb Cycle of Experiential Learning (Kolb, 1984) 
 
 
Concrete experience 
 
Reflective observation 
 
Abstract conceptualisation 
 
Active experimental 
 
Kolb’s model is arguably the most popular model of experiential learning (Philpott, 
2014). Other learning cycles exist, many summarised by Juch (1983). Most alternatives are 
four stage cycles like Kolb’s, using similar themes (e.g., doing, sensing, thinking, 
addressing). Kolb’s cycle provides a framework for the integration of education, work and 
personal development (Zuber-Skerritt, 1992). It highlights four different aspects of 
experiential learning which together provide the link between theory and practice, through the 
use of reflection and action (Burnard, 1989). 

Lynzee McShea 
 
122
Kolb’s model has been subject to some criticism, describing it as too simplistic (Jarvis et 
al., 2003), with no recognition of tacit knowledge (Moon, 2004). Knowledge has social and 
emotional influences, which are also not acknowledged (Eraut, 1994). However, it is a useful 
tool to describe the process of effective learning. Often experiential learning is 
misunderstood, as it is wrongly assumed the experience itself will translate to learning 
(Evans, 1994). Kolb’s model clearly demonstrates the cyclical process required for effective 
learning. 
 
 
4.4. Experiential Learning in Practice 
 
The caregivers interviewed in this research expressed a preference for learning which 
incorporated group activities and practical elements. Previous training that had been 
memorable to them included simulation and emotion. An experiential approach should 
therefore be appropriate and effective for this group. It has also been recommended in the 
literature for staff development through action research (Zuber-Skerritt, 1992). 
There is no evidence of experiential learning of this nature in the literature between 
caregivers and Audiology. This training was designed to be more than basic information 
sharing. It involved evoking a change in practice through the use of reflection and action. 
There are people in the community with undiagnosed hearing loss that are being missed 
through diagnostic overshadowing. The best way to reduce the effect of diagnostic 
overshadowing is to make people familiar with hearing loss by simultaneously increasing 
knowledge and their emotional exposure to it. The findings from Cycle 1 suggest that 
exposure to people with learning disabilities and hearing loss in the workplace alone is not 
sufficient. Therefore, the experience has to be provided through experiential learning 
methods. With regards to hearing aid perception, the training must go beyond teaching people 
simply how to look after hearing aids. It must change their attitudes to hearing aids, increase 
their confidence and pre-empt problems that can and do occur. 
 
 
4.5. How Training Took Place 
 
Six residential care facilities were involved in this cycle. All provide care and support to 
people with learning disabilities. Arrangements were made to visit each facility and provide 
training at a time convenient for them. It has been suggested that training should occur in the 
workplace to increase relevance (Purcell et al., 2000; Windley & Chapman, 2010) and 
promote authenticity of the material being delivered (Eraut & Hirsh, 2007); i.e., “situated 
learning”. All training materials were brought to each home; staff were not asked to 
contribute or prepare anything prior to training. It was requested that as many staff be 
released as possible. Group processes are thought to be a rich resource for experiential 
learning to take place (Warner Weil & McGill, 1989). Each session included 5 – 10 
individuals, though evidence suggests group size and duration of training is of no 
consequence (Lillyman & Farquharson, 2013). Training sessions lasted around 2 hours  
 

“I Will Make a Difference” 
 
123
minimum, depending on the number of additional questions asked. Training always occurred 
in the dining rooms of the houses as this was the most appropriate environment in terms of 
size and seating. 
The training was designed to fulfil three aims; to increase knowledge and to change 
attitudes, with a view to long term change to practice. 
 
4.5.1. Aim 1 – Increase Knowledge 
There is evidence in the literature to suggest that training programmes can be successful 
in increasing the knowledge of participants (e.g., Kyle et al., 2009). And this is a basic, but 
vital initial aim. In general, Cycle 1 revealed that caregivers are unable to detect hearing loss 
in those they support, and are largely unaware of the high prevalence. They also had very 
limited knowledge of hearing aids. In part, training must educate staff around these basic 
principles. 
Much of the hearing aid training was practical and hands on, where each participant was 
given their own hearing aid, batteries and cleaning materials to work with. Use of objects is 
often a feature of experiential learning (Beard & Wilson, 2002). This endorsement of 
practical skills increased authenticity (Eraut & Hirsh, 2007) and helped participants to 
integrate theory and practice (Seely-Brown & Duguid, 1991). 
 
4.5.2. Aim 2 – Change Attitudes 
One of the most important findings of Cycle 1 was the number of individuals who 
believed hearing loss was common in people with learning disabilities, and then asserted that 
no individuals they had ever supported had hearing problems. These individuals had accurate 
knowledge, but were unable to apply this in their working environment. The second aim of 
the training was to change attitudes; to convince staff that their viewpoints were incorrect and 
that they were looking after individuals who did have undetected hearing problems. 
How can this be done, if their real-life experiences are not enough? As Repper and 
Breeze (2007) comment, caregivers own exposure in daily work does not seem sufficient. A 
change in attitude is less likely to occur in traditional methods of learning and instead requires 
personal engagement (Borbasi et al., 2008). Therefore as well as providing knowledge, the 
training also needed to evoke emotional responses for deeper learning (Ashmore & Robinson, 
2015). However, it was important that these emotions were harnessed in a positive manner. If 
not engaged correctly, emotions could block learning (Moon, 2004). For this reason, rather 
than directly challenging the practice of participants, artificial experiences were provided, 
which would still have the required effect. 
 
Key Element of Aim 2 - Stories and Storytelling 
Storytelling is a powerful tool and facilitates emotional learning (Fairbairn, 2002). Real 
life examples were used as much as possible throughout the training in order to bring life to 
the principles being discussed and to encourage person centred care. Rather than abstract 
principles, stories align with how people think and make sense of experiences and as such 
they reinforce understanding (Ashmore & Robinson, 2015). They provide a safe environment 
for staff to challenge poor care, make mistakes and reflect on their own practice without 
feeling vulnerable (Price, 2013). Storytelling is a powerful way of sharing tacit knowledge, 
which is often overlooked in traditional training (Eraut & Hirsh, 2007). 

Lynzee McShea 
 
124
The activity “Steven’s Story” proved particularly emotive for staff in the training. Steven 
was a fictitious individual living with a hearing loss, and when the story was told from his 
point of view, this seemed obvious. It was also having a very negative impact on his life. 
When the story was retold from his caregiver’s perspective, staff were shocked at her attitude 
and beliefs, as she felt he had no hearing difficulty and had explained away the signs of 
hearing loss he presented. By asking staff to write a positive end to the story, it heightened 
their experience (Fairbairn, 2002). As a result of the activity (an external experience), many 
staff then began to discuss real individuals they support and draw parallels. It prompted 
honest discussions about misconceptions, misunderstandings and a realisation that there were 
perhaps individuals being supported by staff who were living with undiagnosed hearing loss, 
which then evoked an internal emotional experience (appresentation; Moon, 2004). 
 
4.5.3. Aim 3 – Long Term Change to Practice 
This aim is arguably the most important, as it is the one that remains unsolved in the 
literature and frequently discussed as a need (e.g., Windley & Chapman, 2010; Chadwick & 
Joliffe, 2008). As part of this aim (and the model of experiential learning adopted), it was 
important to provide opportunities for reflection on assumptions and expectations as this 
should lead to more permanent transformation (Koski et al., 2010).  
Reflective learning occurs when the internal experience of an individual is challenged 
(Moon, 2004). The storytelling and emotional activities were designed to do this by changing 
attitudes. Individual reflection provides an opportunity to challenge thinking in relation to 
factors such as society and culture which then transforms the reflection into something 
outward looking (Ashmore & Robinson, 2015). It is then hoped that change to practice will 
result from a deep examination of attitudes and beliefs (Lindsey, 2002). Reflection 
encourages participants to take a holistic view and provides a sense of ownership of the 
learning (Moon, 2004), again important in promoting sustainable change to practice. 
 
Key Element of Aim 3 - Pledges 
Though courses can result in effective learning, often the knowledge acquired is not 
translated to practice as the contexts of the training and work environment are too diverse 
(Moon, 2004). Though training was conducted in the work environment to promote 
authenticity, pledges were also used to make the application to working practice explicit. At 
the end of each session, staff were provided with a piece of paper entitled “I will make a 
difference” and were asked to write their own pledges. This helped to view the issue as a 
“shared difficulty” between individual and staff (Pryce & Gooberman-Hill, 2012). It also 
served as the first step to a longer term commitment. Photographs of staff were taken at the 
end of training sessions holding their pledges, and were used to create certificates of training. 
Staff were keen for follow up visits to be arranged in order to observe their progress. This 
highlighted their self-confidence (Kyle et al., 2009), in an area they had previously admitted 
to feeling unconfident in. By organising these follow up visits, it also created adjustment time 
and a chance to apply their knowledge practically, time which is not always allocated in 
learning (Eraut & Hirsh, 2007).  
 
 

“I Will Make a Difference” 
 
125
5. CYCLE 3 – EVALUATING THE SOLUTION (SEE MCSHEA, 2015) 
 
The purpose of this cycle was to reconnect with caregivers after the training sessions and 
assess the impact of the training, not only on their working practice, but also regarding their 
experiences since. Changes to knowledge and attitude are relatively worthless if there is no 
change to practice, but this transformation of practice can be difficult to measure (Hodkinson 
& Issitt, 1995). At the end of all training sessions I asked participants the question “how will 
we know if we have made a difference?” Independently, each home offered the same 
solution; to do a follow up visit to observe the changes made. This seemed a sensible and 
positive option. Each home chose when my re-visit would take place. This was important as it 
should not have been something imposed on them and had to be something they thought was 
realistic. 
In order to reduce the likelihood of initiative decay (Firth et al., 2008), certificates were 
sent to each home at the half way point between training and the re-visit. Certificates included 
a photograph of staff teams holding their pledges and a list of all of the pledges made per 
home to act as a reminder and reinforce learning. This also acted as a small reward which has 
been suggested as a useful incentive in training and follow up (Stewart et al., 2009). 
Arrangements were made to revisit homes at a convenient time, where staff who had been 
part of the training would be available. 
 
 
5.1. Focus Group Discussions 
 
Group discussions were held with all available staff at the time of the visit, including staff 
who had not been trained. It was important to include such staff in these discussions, not only 
to ensure they did not feel excluded from the process, but also as their views were important, 
regarding inclusion and dissemination of knowledge. Patton (2015) describes focus groups 
used in this manner as “evaluation focus groups”; providing participants with opportunities to 
share their perspectives and experiences with specific interventions. 
Consent forms were completed by all participants and recordings were made of all 
discussions. Each discussion began by reminding staff of the pledges they had made at the 
end of their training session and asking staff to verify whether they felt each one had been 
achieved or not, with reasons/ evidence in either case. This activity revealed that 96% of the 
pledges made had been completed and in many cases, were able to provide evidence to verify 
this. However, staff sometimes found it difficult to verbalise examples. By discussing issues 
in more detail in each group, a deeper insight was gained. Audio recordings facilitated 
transcription and thematic analysis, which was carried out in a similar manner to Cycle 1. 
Codes identified in the thematic analysis were collapsed into central themes: 
 
 
Knowledge creation 
 
Translation to practice 
 
Empowerment and confidence 
 
Experience of primary care 
 
 

Lynzee McShea 
 
126
5.2. Knowledge Creation 
 
Some staff admitted they had not appreciated how common hearing problems were in this 
group. They spoke about feeling more aware and having more understanding of hearing 
issues. They were more knowledgeable about wax management and the process of requesting 
a hearing test for a service user. Staff were surprised to learn how complex hearing is, and 
that responding to some environmental sounds, does not necessarily mean speech sounds will 
be heard. It was clear that on a basic level, staff had learnt something. But what was also 
evident, was that they were using this knowledge to reflect on previous practice and make 
sense of it: 
 
We were trained to think about it more, that it’s not just the learning disability, they aren’t 
just ignoring you. It’s not just them. 
When we ask X if he wants a cup of tea, he claps and gets excited but now we think it’s not 
because he hears us, it’s because he has seen the cup. 
 
 
5.3. Translation to Practice 
 
Language like “thinking again”, “now” and “think more” were repeated often to replace 
the “habit” and “routine” of previous practice. One person even described post training as “a 
new chapter”. They looked at individuals with a fresh perspective and began to see 
behaviours and actions in a different way, now considering the possibility of hearing loss. 
This made them question not only the hearing ability of their service users, but also their 
previous practice. Staff applied the principles learnt in training to their workplace and the 
people they support. 
 
And we’re now looking at the other ladies, it’s making us think “is it their hearing? 
When they are watching the telly we can’t tell, we take them to the pictures, we have no idea if 
they can hear it. I’ve been here five years and it’s never crossed my mind before.  
 
As well as enabling staff to rationalise their past actions, their fresh understanding 
provided a platform to transform this knowledge into action. Steps have been taken in some 
of the homes to improve communication by adapting the home environment. Using tactics 
such as reducing background noise, speaking clearly, and supporting speech with visual cues 
were all mentioned. Staff also felt these actions could be transferred to other facilities and one 
person spoke about solving a problem with a hearing aid when they were on cover, only 
possible with knowledge gained from the training. 
Several individuals had been supported to attend GP appointments post training, where 
no attendances were planned prior to this. Some have needed treatment for wax occlusion or 
infection and others have been/are in the process of being referred to secondary care for 
further assessment. Every individual referred so far has been found to have some form of 
health need. Knowing the range of techniques that were available in secondary care, gave 
staff confidence to make referrals they would not have considered previously. 
 
 

“I Will Make a Difference” 
 
127
5.4. Empowerment and Confidence 
 
Staff reported confidence from the training, because they could watch and copy someone 
qualified handling a hearing aid and this reduced fear around making mistakes or breaking the 
device. A major theme in the focus group discussions was around staff feeling more confident 
in detecting hearing difficulties and more empowered in seeking referrals: 
 
Before I would have thought “oh the GP is just going to turn us away”, but now it’s better 
‘cos we have some information to go with.  
 
Caregiver confidence was increased for two reasons; not only feeling more 
knowledgeable about the subject and the pathways available, but also knowing I was 
available as a contact who could provide support. Each focus group was next asked to provide 
estimates of the number of individuals they believed to have a hearing loss before and after 
training: 
 
 
Total 
Visible to Audiology 
Suspected hearing loss prior to cycle 2 
23% 
4% 
Suspected hearing loss after cycle 3 
54% 
31% 
 
The perceived prevalence of hearing loss has more than doubled across the six homes. 
Though these are caregiver estimations (meaning the actual percentage pre and post training 
may not be entirely accurate), it does highlight an increased awareness. The percentage of 
those actually known to Audiology could therefore be seen as the translation of knowledge to 
practice and evidence of a functioning referral pathway. 
As a result of the training, several individuals have been referred and supported to access 
Audiology. Each one has been diagnosed with a significant hearing loss. Certainly for these 
individuals, change has been achieved. However, if staff now believe that 54% individuals in 
their care have a hearing loss, why have only 31% been referred to Audiology? Staff admitted 
that in some cases they had not acted on their suspicions and were yet to make a GP 
appointment. By maintaining contact with caregivers, it may be possible to facilitate referral 
for more individuals in the longer term. However, I was also made aware of several instances 
where referral to Audiology was refused by primary care. 
 
 
5.5. Experience of Primary Care 
 
It appeared that some GPs may lack the knowledge the caregivers now have. What is 
surprising (if true), is that any individuals were refused a referral. This questions the manner 
and nature of annual health checks performed in primary care (where hearing should be 
included). It also questions the knowledge and attitude of primary care professionals. As one 
staff member explained, it portrays an image of an uncaring, unethical health service, which 
does not have time for people with learning disabilities. The training was designed to pre-
empt some GP reluctance (based on my clinical experience), but did not predict those who 
would refuse to refer outright. In order to investigate caregiver concerns properly, a fourth 
cycle of research was completed. 

Lynzee McShea 
 
128
6. CYCLE 4 – INVESTIGATED AN UNEXPECTED ISSUE 
(SEE MCSHEA, 2015B) 
 
This cycle was unplanned and occurred in response to caregiver concerns mentioned in 
the previous cycle. This highlights the reactive strength of an action research approach. 
Though there is minimal literature for hearing loss and people with learning disabilities 
accessing primary care, there are publications which stress the need for an exploration of 
primary care’s knowledge and attitudes towards hearing loss in older people and the barriers 
faced (e.g., McCullagh & Frank, 2013). This suggests this final cycle is timely and necessary 
across Audiology and may help to improve communication and visibility. 
 
 
6.1. Requirements 
 
Not all caregivers mentioned difficulties in securing referrals from GPs. However, it 
would be unethical to seek out the GPs in question and interview them. Instead, mailings 
were sent to all surgeries within Sunderland Clinical Commissioning Group (n = 53) and 
seven surgeries accepted the invitation to participate. One possible limitation of this approach 
may have been that smaller areas of poor practice would remain undetected, due to the 
reliance of practitioners to volunteer themselves to participate. If anything, this method of 
recruitment should encourage the best practitioners to come forward. It could be argued 
therefore, that some of the negative findings of this cycle are even more poignant. None of the 
GP surgeries mentioned by caregivers in the previous cycle volunteered to participate in this 
cycle. 
Individual, semi-structured interviews were chosen, conducted and analysed in a similar 
manner to Cycle 1, to promote consistency of method. The interviews in this cycle involved 
practice nurses and GPs. An individual approach encouraged more honest responses 
(Bryman, 2016), given the potentially sensitive nature of the questioning i.e., sub-optimal 
care for people with learning disabilities. Pragmatically, individual interviews were also the 
most feasible option as most surgeries were only able to spare one staff member due to 
clinical pressures. In this cycle, the questions that were asked were informed by the previous 
cycles. For example, some caregivers had suspicions that people with learning disabilities 
would be treated differently to adults in the general population. 
It appears that the concerns of some caregivers in the previous cycle were founded. It is 
interesting to compare the prevalence data provided by primary care professionals with the 
caregivers at an equivalent stage: 
 
 
Median prevalence 
estimate 
Prevalence actual 
Caregivers at interview phase (Cycle 1) 
25% 
7% 
Primary care staff at interview phase (Cycle 4) 
20% 
0-14% 
 
The findings for primary care, like caregivers in Cycle 1, may be explained in part by 
symbolic interactionism (that in primary care few people with learning disabilities actually 
present with hearing problems, therefore the perceived prevalence reflects this). 

“I Will Make a Difference” 
 
129
Practice nurses had little knowledge of Audiology; they felt their expertise lay in general 
health and health promotion. However, referrals from GPs were also rare due to assumptions 
and judgements being made. Mencap (2012) stress the need to challenge such assumptions 
and ensure consistent care, regardless of a learning disability. The GPs interviewed felt 
confident making referrals to Audiology when adults in the general population presented with 
hearing concerns. They relied on history taking, ear examination and the need for active 
concerns from the individual or their caregiver. This is a high referral threshold for people 
with learning disabilities. Some may not tolerate a physical examination, or may not be able 
to provide a detailed medical history. Often the caregivers that accompany individuals or not 
able to provide this on their behalf. In many cases a GP may only refer on the basis of active 
concerns, which is unlikely to be the case for this group, due to diagnostic overshadowing. In 
general practice it may not be common place to look for problems that are not causing 
concern, but this is the purpose of the annual health check, to redress the disparities people 
with learning disabilities face. There seemed to be a misunderstanding that something causing 
concern would always be visible. This is not always the case for people with learning 
disabilities. 
However, there is also evidence to suggest that even if a caregiver does present an active 
complaint on behalf of an individual, this is not always acknowledged or acted upon (Ali et 
al., 2013) and that even for adults in the general population, around 45% of individuals are 
not referred to Audiology when presenting with hearing loss (Action on Hearing Loss, 2011). 
The reasons for this are said to include time constraints, lack of awareness of assessment or 
benefits to rehabilitation (Schneider et al., 2010). 
Some individuals felt that hearing loss was rare, or had already been dealt with for 
individuals they saw in their clinics. Others felt that for this group, addressing hearing loss 
was not a priority, as it was unclear how an individual’s life would improve following 
treatment. Some believed that it would not be possible to assess hearing accurately or even 
facilitate attendance at an Outpatient clinic. Using this model, it becomes clear that simply 
improving caregiver knowledge is not sufficient to transform the whole cycle. Though 
improved caregiver knowledge may highlight to primary care that a problem does exist, it 
does nothing to transform its perceived importance, or availability of solutions. 
Audiology has a responsibility to share the positive outcomes that can stem from treating 
hearing loss, not only from a personal perspective, but also a financial one. By publicising the 
Audiology service and the reasonable adjustments it can provide, this would help to influence 
referrers. Locally it was disappointing to hear staff say they thought there would be no one in 
Audiology “who would care” about people with learning disabilities, when there has been a 
dedicated service in place for 7 years. This reinforces the invisible nature of Audiology but 
also highlights the need for this issue to be viewed with shared responsibility. 
 
 
7. DISCUSSION 
 
The issue of improving audiological care for people with learning disabilities is complex 
and involves a variety of stakeholders. There is clear evidence of poor audiological care 
within Audiology literature, but limited dissemination of the message to those impacted by it. 
There is also little reflection on the responsibility of the profession. This research was more 

Lynzee McShea 
 
130
about understanding the role and influence of an Audiology professional, than simply 
educating caregivers. 
 
 
7.1. Contextualising the Findings 
 
Cycle 1 
The findings from this cycle agree closely with the literature. The 7% prevalence of 
hearing loss known to the participants reinforces the findings of Kerr et al. (2003), who 
suggested that caregivers have difficulty detecting hearing problems. There was evidence of 
diagnostic overshadowing in this research group and agreement with McMillan et al. (2000) 
and Pryce & Gooberman-Hill (2013) that knowledge of hearing issues obtained by work 
experience alone is not sufficient. In contrast, it appeared that caregiver experiences actually 
reinforced their misconceptions. Negative judgements were made regarding hearing aids and 
their benefit. Coppens-Hofman et al. (2013) also found the benefits of hearing aids were 
under-reported and believed this was due to lack of initial concern regarding hearing. 
This research explores the issue further and aims to provide a theoretical explanation for 
these findings, using symbolic interactionism (Denzin, 1992). The unconscious incompetence 
of staff, their prior experiences with hearing aids and the lack of visible hearing difficulty in 
the people they support, has led them to construct meanings which justify low prevalence of 
hearing loss, regardless of their estimates of general prevalence. They are not surprised when 
they do not encounter individuals with hearing difficulty, and so the cycle of unconscious 
incompetence continues. Though they were aware of their responsibilities in advocating 
referral for services users, their experiences suggested this was not something that was 
required frequently or would be successful if attempted. 
The theory of symbolic interactionism suggests that although individuals form their own 
meanings based on experience, these can also be transformed by experience (Denzin, 1992). 
This suggests the issue could be improved. Teamwork and involvement were important to 
staff and it became clear they would engage with collaborative methods. Though this has 
been suggested generally in the literature, there was no evidence of an attempt to do this 
between caregivers and Audiology. Action research methodology was integral to this, and 
allowed caregivers to make suggestions about training which were integral to the next cycle. 
 
Cycle 2 
Though further training and education is frequently mentioned (e.g., Lennox et al., 1997; 
Tracy & McDonald, 2015), there have been no real attempts to demonstrate a translation of 
knowledge to practice, particularly for hearing loss and people with learning disabilities. In 
order to determine whether this was possible, it was necessary to provide caregivers with a 
novel learning opportunity. Traditional teaching methods are successful if the thinking of the 
student and teacher align. However, there is evidence in the literature to suggest caregivers 
often feel ways of working are imposed on them, by people who do not understand their role 
(DH, 2007). This may explain why simply relaying knowledge between two groups is not 
successful, as there is no context to the information. For example, McMillan et al. (2000) 
successfully increased the knowledge of their participants, but were unable to demonstrate a 
convincing transformation to practice. 

“I Will Make a Difference” 
 
131
This was the justification for designing training in this cycle using experiential learning 
theory. This requires opportunities for reflection, with the aim of evoking change. Seely 
Brown & Duguid (1991) describe this as the difference between learning to become a 
practitioner, and merely learning about practice. During both Cycles 1 and 2, participants 
were encouraged to offer ideas and suggestions in order to reach a common understanding, 
leading to agreed action. Again this appeared to be a novel approach in the Audiology / 
learning disability literature. In addition, by situating the learning within caregivers’ 
workplaces, it made the learning authentic and promoted translation to practice (Borich, 
2011). This also provided me with a novel opportunity to visit these homes and experience 
the culture and daily practice. This was important to reflect upon and provided an opportunity 
for some situated learning of my own. 
 
Cycle 3 
As this approach was novel, it is difficult to contextualise the findings of the evaluation 
of the training with other studies in the literature. Though there is agreement that translation 
of knowledge to action is difficult (e.g., Windley & Chapman, 2010), there has been minimal 
research to understand the reasons for this (Eraut & Hirsh, 2007). Hithersay et al. (2014) 
agree, that more research is required to understand how best to engage caregivers. In this 
regard, the findings of Cycles 2 and 3 add to the evidence base. Experiential learning was a 
successful approach for these caregivers, and there was evidence to suggest all three training 
aims were met. On the whole, knowledge and confidence increased as shown by 
questionnaire. A focus on storytelling was important in facilitating reflection that is integral to 
experiential learning. This assisted in changing attitudes around hearing loss. Participants also 
mentioned the value of having a known contact in Audiology, and the reassurance that they 
had support in specialist services. This led to focus groups reported increased confidence and 
empowerment. Such caregiver support was one of the key findings of this cycle and was also 
cited by Ali et al. (2013) as important in general healthcare. 
Caregiver estimations of hearing loss prevalence increased significantly from 23 to 54%, 
which correlates more closely with the expected prevalence reported in the literature (40%; 
Emerson et al., 2012). Though these are estimations and may not be entirely accurate, 
caregiver estimations are used more frequently in the literature to comment on prevalence 
than actual assessment (Bent et al., 2015). In this research, further investigations were made 
involving actual diagnoses known to Audiology. Four individuals were diagnosed with 
hearing loss following this cycle, with caregivers in these homes admitting that it was 
unlikely these hearing losses would have been identified or actioned without the training they 
received. Many other caregivers began using better communication tactics with those they 
support. This suggests people with learning disabilities benefited as a result of the process. 
Horwath & Morrison (1999) state that this is the most effective test of knowledge transfer. 
There was evidence to suggest that more individuals are now suspected of having hearing 
loss than have actually been referred. Whilst the lack of referrals was partly due to caregiver 
inertia, there was also suggestions of barriers in primary care. Firth et al. (2008) voice the 
concern of oversimplifying an issue to simply a problem with caregivers and the findings in 
this cycle and the next would support this concern. 
 

Lynzee McShea 
 
132
Cycle 4 
This final cycle occurred through identified need rather than prior planning, highlighting 
the reactive strength of action research. The findings of this cycle suggest that the concerns 
raised by caregivers previously were founded and widespread. Despite evidence that health 
checks in primary care are generally effective (Robertson et al., 2010) this research agrees 
with McClimens et al. (2014), who assert that this is not the case for hearing loss. These 
authors suggest further evaluation is needed, which this research helps to provide. The 
prevalence data obtained from surgeries reveals inertia in primary care, similar to that 
observed in Cycle 1 with caregivers. Many of the primary care professionals involved made 
negative value judgements about the worth and benefit of treating people with learning 
disabilities and their hearing difficulties. Even for some, where a hearing loss was 
documented in their medical records, referrals had still not been actioned. This echoes the 
findings of Felce et al. (2008), where health checking did not lead to increased contact with 
specialist services. 
This cycle found that GPs needed three key elements in order to feel confident in making 
referrals to Audiology; physical examination, history and active concerns. One or more of 
these elements may be more difficult to obtain for people with learning disabilities, 
highlighting the importance of a familiar and knowledgeable caregiver (Lennox et al., 1997). 
However, the account of some caregivers in Cycle 3 suggested that their active concerns were 
not being acted upon. This is not a finding unique to this study and had previously been 
described in more general terms by Mencap (2012). It appears that on some occasions, 
improved caregiver knowledge alone was insufficient to achieve a referral to Audiology 
services. The perceived importance of hearing well and the availability of a solution to 
hearing loss for people with learning disabilities was still under suspicion by some primary 
care professionals. Staff in primary care had limited understanding of the patient journey 
within Audiology, also highlighted by Monitor (2015). It was disappointing to hear so many 
professionals say that there was no local audiological provision for people with learning 
disabilities, when a service has been in place in their local area since 2008. What became 
clear was that the visibility of the Audiology service, and the referral mechanisms to access it 
must be improved. 
Though caregivers were the focus of the first three cycles, the findings in primary care 
could be considered even more significant. Where caregivers are not considered to be 
professionals and their mandatory training does not prepare them adequately for detections of 
hearing problems, primary care practitioners are professional and have explicit 
responsibilities towards meeting the health needs of their patients, including hearing. The fact 
that their prevalence estimates fell below those of the caregivers is a concern, particularly 
when coupled with some poor attitudes regarding people with learning disabilities. 
 
 
7.2. What were the Key Elements in Ensuring the Research Aims were Met? 
 
Rather than focussing on determining an absolute value of effectiveness, it is more 
important to determine what was effective. Although the content of the training was 
important, it appeared more significant that I was physically available to caregivers. The key 
elements that caregivers required were: 
 

“I Will Make a Difference” 
 
133
 
Knowledge that hearing loss is more common in people with learning disabilities 
 
Assertion that hearing problems can and should be addressed 
 
An explanation of the referral process 
 
The training content helped to provide legitimacy to the issue. The use of situated 
learning and experiential learning meant the training was designed to make these issues 
interesting, memorable and relevant. Meeting an Audiology contact who spoke about these 
issues personally, made caregivers feel empowered and confident. Vygotsky describes this as 
a “scaffold” of support, where caregivers could feel supported and encouraged to learn and 
develop (Borich, 2011). It meant that the caregivers were more observant for signs of hearing 
loss in those they supported, not only because they were educated in what to look for, but also 
because they knew there was something that could be done. It could be argued that caregivers 
should not need to retain advanced hearing knowledge, only that they know who to seek this 
information from. The only real health contact caregivers have in the community is primary 
care, and the final cycle of research suggested that in many cases, primary care has the same 
needs as caregivers. The common denominator in this is Audiology, which has a professional 
responsibility to increase its visibility in the community. 
 
 
7.3. A Multidisciplinary Team (MDT) 
 
Traditionally, professions have become specialised, resulting in a narrowing of vision 
(Schön, 1983). This narrowing can affect the experience and understanding of individuals to 
an extent where perceptions become fixed, almost like a “script” (Davies et al., 2000). This 
viewpoint can be difficult to transform (Langer, 1997) and perhaps unlikely to transform 
spontaneously, without external influence. 
Heyman et al. (2004) feel that specialisms are still required for people with learning 
disabilities and that secondary complexity can arise when standardisation of services is 
attempted. A more effective solution therefore, is to adapt the processes between specialisms 
and work together. Owens et al. (1995) describe the differences between multi-
professionalism (retaining specific knowledge but working across boundaries) and inter-
professionalism (surrendering work roles and integrating procedures). Multi-professionalism 
is the less disruptive and therefore most feasible option. For hearing loss in people with 
learning disabilities, with such diverse stakeholders, it would be difficult to imagine true 
inter-professionalism. 
By working with stakeholders in the community, the benefits to Audiology are clear. It 
provides an opportunity to communicate with the key gatekeepers to its service, not only to 
encourage appropriate and quality referrals, but also to address any barriers or issues that may 
not be obvious within the profession. For example, prior to commencing this research, I was 
unaware how negative the community perception of hearing aids was. This may help to 
explain why, although hearing aid technology has improved hugely, uptake of hearing aids 
has increased less so (Kochkin, 2007). By learning this in Cycle 1, it allowed me to design 
training which could change attitudes. Without this feedback, the training would not have 
been tailored as effectively and may therefore have resulted in a less favourable outcome. 
 
 

Lynzee McShea 
 
134
7.4. Audiology’s Visibility within a Multidisciplinary Framework 
 
It is believed that assessment and management of hearing loss should be multidisciplinary 
(Miller & Kiani, 2008). It is therefore even more surprising to consider the omission of 
Audiology when hearing issues are being discussed. This appears to be a widespread issue, 
and is a concern if Audiology is not associated with hearing. For example, Lindsey (2002) 
writes about the range of professionals required to meet special health care needs in people 
with learning disabilities. She acknowledges the increased risk of sensory impairment, but 
discusses this in relation to the responsibility of speech and language therapists only. The 
National Institute for Health and Care Excellence (NICE) produce guidance on improving 
health and social care. There is only one document which mentions hearing issues for people 
with learning disabilities (document reference CG142; for adults with autism). Though 
hearing tests are mentioned, there is no reference to Audiology. 
Similarly, Newsam (2010) asked caregivers who they would approach for advice on 
sensory impairment. Opticians, GPs and even a charity for those with visual loss were 
mentioned; though there was no mention of Audiology whatsoever. Though vision and 
hearing share many parallels, there are significant differences in perception. Glasses are more 
socially acceptable, often perceived as a fashion accessory or a sign of intelligence. Whilst 
people can self-refer for a sight test, the process of obtaining a hearing test relies on primary 
care and therefore creates distance between the public and Audiology. 
There is also evidence in the literature to suggest that Audiology is infrequently 
recognised as part of a wider team. A key example is MacDonald et al. (2010). This was a 
case study highlighting the outcomes for an individual regarding behaviour support planning 
to reduce challenging behaviour. Although he did not communicate verbally, had limited 
understanding of speech, found noisy environments difficult and did not like group situations 
(all key indicators of hearing loss), there was no attempt to test his hearing, nor was there 
mention of hearing issues in the whole publication. The inclusion of Audiology and a 
potential diagnosis of hearing loss could have led to a very different outcome for this 
individual. The case study presented in McShea et al. (2014), highlights this and the 
significant benefits inclusion can bring, not only for the person concerned, but also financial 
benefits for services.  
 
 
7.5. Creating an MDT for Audiology and People with Learning Disabilities 
 
Benefits to Caregivers 
A multidisciplinary approach is needed to allow Audiology, caregivers and primary care 
professionals to come together to best support people with learning disabilities and hearing 
loss. This research has demonstrated that increasing contact with caregivers can influence 
their practice in a productive manner.  
Time pressure is already a feature of caregivers’ practice, so involvement in a new 
initiative may be met with some resistance. However, the high prevalence of hearing loss in 
people with learning disabilities, justifies the need for such an initiative (Meuwese-
Jongejeugd et al., 2007). By working together, pathways can actually become more cost and 
time effective. For example, if a caregiver had concerns about the hearing of an individual 

“I Will Make a Difference” 
 
135
they supported, they may have had to support the individual to their GP on several occasions 
before a referral was processed (if at all). By having greater awareness of the 
multidisciplinary team and its remit, the referral process should be quicker and easier for 
staff, who would be more informed and empowered. 
Working together has also been suggested by Fyson & Cromby (2013) as a way to 
improve the difficulties created by neoliberal service structures. Though neoliberalism is 
thought to create choice and opportunity for individuals, it is unlikely to have such a positive 
impact on people with learning disabilities, who may have difficulty making autonomous 
choices. Equally, their caregivers may have difficulty making appropriate choices on their 
behalf, if they are uninformed and unaware. Supported decision making has therefore been 
advocated, not only in social care, but also in Audiology (e.g., Pryce & Hall, 2014). MDT 
working can be a vital tool to facilitate this. 
 
Benefits to Primary Care 
Schneider et al. (2010) feel the management of hearing loss in primary care is 
questionable. The findings from Cycle 4 indicated that many primary care professionals held 
dated beliefs that it would not be possible to test the hearing of a person with learning 
disabilities or that hearing aids would make no difference to their lives. By having closer links 
with Audiology, these perceptions would change and would make referral more likely. In 
addition to this, visibility of a contact in Audiology helps to raise awareness of the issues and 
referral procedures and could therefore save money. Prior to our engagement with primary 
care locally, individuals often reached the complex needs service in hospital Audiology after 
being referred inappropriately to other providers, who were unable to meet their needs. 
Delivering the right service first time is not only preferable for the individual, but also for 
commissioners and providers of services. 
 
Benefits to Audiology 
For Audiology, an MDT would facilitate increased presence and influence in the 
community. It would also help to provide feedback on how the profession is represented 
elsewhere. By being part of an MDT, Audiology would be more aware of issues that affect 
the profession and would lead to a presence outside of the clinic room. 
 
 
7.6. A Theoretical Model for the MDT 
 
Regardless of the exact organisation and membership of an MDT, the main objectives 
should be timely detection, access to support and longer term management (Miller & Kiani, 
2008). Taken the research findings into consideration, an enhancement to the 3As model is 
proposed, to transform it into a 5As model with the addition of “Assembly” and 
“Awareness”: 
 
Assembly 
One focus of the 5As model is now the stakeholders. There is no minimum or maximum 
number of stakeholders, this can be determined according to the need and remit of the group. 

Lynzee McShea 
 
136
Initially, an assembly of stakeholders is necessary to consider the issue and determine 
membership. 
 
 
 
Initially, there may be resistance to adopting an MDT approach. Stakeholders may be 
more comfortable within their own disciplines, which are familiar and predictable (Hills et al., 
2007). The assembly should therefore be driven by a stakeholder who is central to the issue 
and is affected by all other parties. Though this could potentially be the individual or their 
caregiver, they are unlikely to have the capability or resources to coordinate this. For hearing 
loss and learning disabilities, Audiology seems to be a valid alternative. Shames & Simpson 
(2012) suggest Audiology is well placed to be at the centre of patient focussed care. This 
would also increase the visibility and responsibility of the profession. 
 
Awareness 
Once assembly has occurred, awareness should follow. Key contacts could determine 
roles and capabilities and would streamline the patient journey. By sharing practice, it could 
be determined who was best placed to act on needs as they arose. It may be that the number of 
stakeholders involved varies as required. Symbolic interactionism states that individuals 
construct meaning from their experiences and environment. Multidisciplinary information 
sharing can be effective in modifying experience and perception.  
Once assembly and awareness are in place, the established flow of access, assessment 
and aftercare could continue and could be conceptualised in a spiral of cycles, rather than one 
discrete event. By having a robust core of assembly and awareness supporting this spiral, the 
developments made are more likely to be sustained. This would also mean that initiatives 
would not rely on individual stakeholders, as there would be shared ownership. By 
encouraging shared meaning and experience, values would align and mutual understanding 
would occur. The focus would shift from service centred to person centred. 
 
 
7.7. Generalisability/Transferability of the Model 
 
It is recognised in the literature that qualitative research is not generalisable at the level of 
populations, but at the level of theory (Bryman, 2016), meaning the quality of the inferences 

“I Will Make a Difference” 
 
137
to theory are important. For example, Silverman (2013) shows that qualitative research can be 
classed as generalisable if the findings are presented to demonstrate what groups can do, 
rather than absolute descriptions of what they actually do. In this research therefore, rather 
than looking at the exact prevalence numbers before and after caregiver training for example, 
the findings are more generalisable when considered as the possibility of change to practice. 
Despite the dual thrust within action research methodology, it is said that the action 
component is often prioritised over the research component (Dick, 2003). It was important 
throughout this process to remember that this was a piece of research which intended to 
generate theory, and was not just a project in practice. It was helpful to use the cyclical nature 
of the process, which provided natural pauses for reflection, evaluation and future planning. 
Dick (2003) suggests that theory can be generated in action research by examining the 
overlaps between the data sets generated by cycles. This is similar to the process of 
triangulation (Greene 2014), where validation of findings occurs through use of multiple 
sources. For example in this research, the invisibility of Audiology in community settings was 
made clear from participants in two separate cycles (1 and 4). It was from overlaps such as 
these that the 5As model was conceptualised. A model is a framework for examining reality 
(Silverman, 2013). Therefore, by returning to the earlier point made about generalisability in 
qualitative research i.e., “can do, not does do” then the 5As model could be classed as 
generalisable across other Audiology / care providers and wider health and care networks. In 
addition, as the focus of the 5As model is on groups and organisations rather than individuals, 
the level and sustainability of change it proposes is maximised (Handy, 2009). 
 
 
CONCLUSION 
 
I believe this research has made an important contribution to both theory and practice. 
Through the use of action research methodology, this research can be viewed as a successful 
educational intervention. I have established that it is possible to increase the audiological 
knowledge of paid caregivers and facilitate translation of that knowledge to changes in 
practice. This had not been demonstrated in the literature previously. 
Such translation resulted in significant benefits, not only for the caregivers themselves, 
but for the individuals they support. The lives of some individuals have been transformed as a 
result. It highlights the need for greater importance to be placed on audiological issues for 
people with complex needs and a greater awareness of their supporters, advocates and 
healthcare providers. 
This research has highlighted the role of the wider team and other stakeholders through 
development of a conceptual model (the 5As model) to facilitate multidisciplinary 
engagement for Audiology. 
 
 
REFERENCES 
 
Action on Hearing Loss. (2011). The Facts - Facts and Figures on hearing loss and tinnitus 
[Online] Available from: http://www.actiononhearing loss.org.uk/your-hearing/about-
deafness-and-hearing-loss/statistics.aspx. [Accessed: 6th September 2015]. 

Lynzee McShea 
 
138
Ali, A., Scior, K., Ratti, V., Strydom, A., King, M. & Hassiotis, A. (2013). Discrimination 
and Other Barriers to Accessing Health Care: Perspectives of Patients with Mild and 
Moderate Intellectual Disability and their Carers. Public Library of Science ONE, 8(8), 1-
13. 
Ashmore, L. & Robinson, D. (eds.) (2015). Learning, Teaching and Development. Strategies 
for Action. London: SAGE. 
Banat, D., Summers, S. & Pring, T. (2002). An Investigation into Carers’ Perceptions of the 
Verbal Comprehension Ability of Adults with Severe Learning Disabilities. British 
Journal of Learning Disabilities, 30, 78 – 81. 
Baum, F., MacDougall, C. & Smith, D. (2006). Participatory Action Research. Journal of 
Epidemiology and Community Health, 60, 854 – 857. 
Beard, C. & Wilson, J. P. (2002). The Power of Experiential Learning. A Handbook for 
Trainers and Educators. London: Kogan Page Limited. 
Bent, S., McShea, L. & Brennan, S. (2015). The Importance of Hearing: a Review of the 
Literature on Hearing Loss for Older People with Learning Disabilities. British Journal 
of Learning Disabilities, 43, 277-284. 
Borbasi, S., Bottroff, V., Williams, R. P., Jones, J. & Douglas, H. (2008). “No going back” to 
Institutional Care for People with Severe Disability: Reflections on Practice Through an 
Interpretive Study. Disability and Rehabilitation, 30(11), 837 – 847. 
Borich, G. (2011). Effective Teaching Methods, 7th edition. Research Based Practice. London: 
Pearson. 
Bryman, A. (2016). Social Research Methods 5th edition. Oxford: University Press. 
Burnard, P. (1989). Teaching Interpersonal Skills. A Handbook of Experiential Learning for 
Health Professionals. London: Chapman and Hall. 
Carvill, S. (2001). Sensory Impairments, Intellectual Disability and Psychiatry. Journal of 
Intellectual Disability Research, 45(6), 467 - 483. 
Chadwick, D. D. & Jolliffe, J. (2008). A Pilot Investigation into the Efficacy of a Signing 
Training Strategy for Staff Working with Adults with Intellectual Disabilities. British 
Journal of Learning Disabilities, 37, 34 - 42. 
Cook, A. & Lennox, N. (2000). General Practice Registrars’ Care of People with Intellectual 
Disabilities. Journal of Intellectual & Developmental Disability, 25(1), 69 – 77. 
Coppens-Hofman, M. C., Koch, H. H., Maassen, B. A. M. & Snik A. F. M. (2013). 
Evaluating the Subjective Benefit of Hearing Rehabilitation in Adults with Intellectual 
Disability. Hearing, Balance and Communication, 11, 24-29. 
Davies, C., Finlay, L. & Bullman, A. (2000). Changing Practice in Health and Social Care. 
London: SAGE.  
Dennison, B. & Kirk, R. (1990). Do, Review, Learn, Apply: A Simple Guide to Experiential 
Learning. Oxford: Basil Blackwell. 
Denzin, N. K. (1992). Symbolic Interactionism and Cultural Studies. The Politics of 
Interpretation. Oxford: Blackwell. 
Department of Health. (2007). Services for People with Learning Disabilities and 
Challenging Behaviour or Mental Health Needs. London: Department of Health. 
Dick, B. (2003). What Can Action Researchers Learn from Grounded Theorists? [Online] 
Available from: http://www.aral.com.au/ DLitt/DLitt_P60andgt.pdf. [Accessed 20th 
February 2016]. 

“I Will Make a Difference” 
 
139
Emerson, E., Baines, S., Allerton, L. & Welch, V. (2012). Health Inequalities & People with 
Learning Disabilities in the UK: 2012. Improving Health and Lives: Learning 
Disabilities. 
Eraut, M. (1994). Developing Professional Knowledge and Competence. London: Falmer. 
Eraut, M. & Hirsh, W. (2007). The Significance of Workplace Learning for Individuals, 
Groups and Organisations. Oxford: SKOPE Monograph 9. 
Evans, N. (1994). Experiential Learning for All. London: Cassell. 
Fairbairn, G. (2002). Ethics, Empathy and Storytelling in Professional Development. 
Learning in Health and Social Care, 1(1), 22 – 32. 
Felce, D., Baxter, H., Lowe, K., Dunstan, F., Houston, H., Jones, G., Grey, J., Felce, J. & 
Kerr, M. (2008). The Impact of Checking the Health of Adults with Intellectual 
Disabilities on Primary Care Consultation Rates, Health Promotion and Contact with 
Specialists. Journal of Applied Research in Intellectual Disabilities, 21, 597-602. 
Firth, G., Elford, H., Leeming, C. & Crabbe, M. (2008). Intensive Interaction as a Novel 
Approach in Social Care: Care Staff’s Views on the Practice Change Process. Journal of 
Applied Research in Intellectual Disabilities, 21, 58–69. 
Foddy, W. (1994). Constructing Questions for Interviews and Questionnaires. Theory and 
Practice in Social Research. Cambridge: University Press. 
Fransman, D. (2006). Can Removal of Back Teeth Contribute to Chronic Earwax 
Obstruction? British Journal of Learning Disabilities, 34(1), 36-41. 
Fulton, J., Kuit, J., Sanders, G. & Smith, P. (2013). The Professional Doctorate. Basingstoke: 
Palgrave McMillan. 
Fyson, R. & Cromby, J. (2013). Human Rights and Intellectual Disabilities in an Era of 
‘Choice’. Journal of Intellectual Disability Research, 57(12), 1164-1172. 
Gianopoulos, I., Stephens, D. & Davis, A. (2002). Follow Up of People Fitted with Hearing 
Aids after Adult Hearing Screening: the Need for Support After Fitting. British Medical 
Journal, 325, 471. 
Greene, M. J. (2014). On the Inside Looking in: Methodological Insights and Challenges in 
Conducting Qualitative Insider Research. The Qualitative Report, 19(15), 1-13. 
Handy, C. (2009). Gods of Management. The Changing Work of Organisations. Sparkford: 
Haynes. 
Hardy, S., Woodward, P., Woolard, P. & Tait, T. (2011). Meeting the Health Needs of People 
with Learning Disabilities. RCN Guidance for Nursing Staff. Second edition. London: 
Royal College of Nursing. 
Heyman, B., Swain, J. & Gillman, M. (2004). Organisational Simplification and Secondary 
Complexity in Health Services for Adults with Learning Disabilities. Social Science & 
Medicine, 58, 357 – 367. 
Hild, U., Hey., C., Baumann, U., Montgomery, J., Euler, H. A. & Neumann, K. (2008). High 
Prevalence of Hearing Disorders at the Special Olympics Indicate Need to Screen 
Persons with Intellectual Disability. Journal of Intellectual Disability Research, 52(6), 
520 - 528. 
Hills, M., Mullett, J. & Carroll, S. (2007). Community-based Participatory Action Research: 
Transforming Multidisciplinary Practice in Primary Health Care. Revista Panamericana 
de Salud Publica, 21, 125-135. 
Hindhede, A. L. (2011). Negotiating Hearing Disability and Hearing Disabled Identities. 
Health, 16(2), 169 – 185. 

Lynzee McShea 
 
140
Hithersay, R., Strydom, A., Moulster, G. & Buszewicz, M. (2014). Carer-led Health 
Interventions to Monitor, Promote and Improve the Health of Adults with Intellectual 
Disabilities in the Community: A Systematic Review. Research in Developmental 
Disabilities, 35, 887-907. 
Hodkinson, P. & Issitt, M. (1995). The Challenge of Competence – Professionalism through 
Vocational Education and Training. London: Cassell. 
Holter, I. M. & Schwartz-Barcott. (1993). Action Research: What is it? How Has It Been 
Used and How Can It Be Used in Nursing? Journal of Advanced Nursing, 18, 298 –304. 
Horwath, J. & Morrison, T. (1999). Effective Staff Training in Social Care. From Theory to 
Practice. London: Routledge. 
Jarvis, P., Holford, J. & Griffin, C. (2003). The Theory and Practice of Learning, 2nd edition. 
London: Kogan Page. 
Juch, A. (1983). Personal Development: Theory and Practice in Management Training. 
Wiley: Shell International. 
Kelly, T. B., Tolson, D., Day. T., McColgan, G., Kroll, T. & Maclaren, W. (2013). Older 
People’s Views on What They Need to Successfully Adjust to Life with a Hearing Aid. 
Health and Social Care in the Community, 21(3), 293 – 302. 
Kerr, A. M., McCulloch, D., Oliver, K., McLean, B., Coleman, E., Law. T., Beaton, P., 
Wallace. S., Newell, E., Eccles, T. & Prescott, R. J. (2003). Medical Needs of People 
with Intellectual Disability Require Regular Reassessment, and the Provision of Client- 
and Carer-Held Reports. Journal of Intellectual Disability Research, 47(2), 134-145. 
Kevan, F. (2003). Challenging Behaviour and Communication Difficulties. British Journal of 
Learning Disabilities, 31, 71 – 80. 
Knudsen, L. V., Laplante-Levesque, A., Jones, L., Preminger, J. E., Nielsenm C., Lunner, T., 
Hickson, L., Naylor, G. & Kramer, S. E. (2012). Conducting Qualitative Research in 
Audiology: A Tutorial. International Journal of Audiology, 51, 83 - 92. 
Kochkin, S. (2007). MarkeTrak VII: Obstacles to Adult Non-User Adoption of Hearing Aids. 
The Hearing Journal, 60(4), 24-51. 
Kolb, D. A. (1984). Experiential Learning. Experience as the Source of Learning and 
Development. New Jersey: Prentice Hall. 
Koshy, E., Koshy, V. & Waterman, H. (2011). Action Research in Healthcare. London: 
SAGE. 
Koski, K., Martikainen, K., Burakoff, K. & Launonen, K. (2010). Staff Members 
Understandings about Communication with Individuals Who Have Multiple Learning 
Disabilities: A Case of Finnish OIVA Communication Training. Journal of Intellectual & 
Developmental Disability, 35(4), 279 – 289. 
Kyle, S., Melville, C. A. & Jones, A. (2009). Effective Communication Training 
Interventions for Paid Carers Supporting Adults with Learning Disabilities. British 
Journal of Learning Disabilities, 38, 210 – 216. 
Langer, E. J. (1997). The Power of Mindful Learning. Boston: De Capo. 
Lavis, D., Cullen, C. & Roy, A. (1997). Identification of Hearing Impairment in People with a 
Learning Disability: From Questioning to Testing. British Journal of Learning 
Disabilities, 25, 100-105. 
Lennox, N. G., Diggens, J. N. & Ugoni, A. M. (1997). The General Practice Care of People 
with Intellectual Disabilities: Barriers and Solutions. Journal of Intellectual Disability 
Research, 41(5), 380 – 390. 

“I Will Make a Difference” 
 
141
Lillyman, S. & Farquharson, N. (2013). Self-Care Management Education Models in Primary 
Care. British Journal of Community Nursing, 18(11), 556 – 560. 
Lindsey, M. (2002). Comprehensive Health Care Services for People with Learning 
Disabilities. Advances in Psychiatric Treatment, 8, 138 – 148. 
MacDonald, A., Hume, L. & McGill, P. (2010). The Use of Multi Element Behaviour 
Support Planning with a Man with Severe Learning Disabilities and Challenging 
Behaviour. British Journal of Learning Disabilities, 38, 280 – 285. 
McClimens, A., Brennan, S. & Hargreaves, P. (2014). Hearing Problems in the Learning 
Disability Population: is Anybody Listening? British Journal of Learning Disabilities, 
doi: 10.1111/bld.12090. 
McCormack, A. & Fortnum, H. (2013). Why Do People Fitted with Hearing Aids Not Wear 
Them? International Journal of Audiology, 52, 360-368. 
McCracken, W., Lumm, J. & Laoide-Kemp, S. (2011). Hearing in Athletes with Intellectual 
Disabilities: The Need for Improved Ear Care. Journal of Applied Research in 
Intellectual Disabilities, 24(1), 86–93. 
McCullagh, M. C. & Frank, K. (2013). Addressing Adult Hearing Loss in Primary Care. 
Journal of Advanced Nursing, 69, 896-904. 
McIntosh, P. (2010). Action Research and Reflective Practice; Creative and Visual Methods 
to Facilitate Reflection and Learning. London: Routledge. 
McMillan, L., Bunning, K. & Pring, T. (2000). The Development and Evaluation of a Deaf 
Awareness Training Course for Support Staff. Journal of Applied Research in Intellectual 
Disabilities, 13, 283 - 291. 
McNiff, J. & Whitehead, J. (2011). All You Need to Know About Action Research, 2nd 
edition. London: SAGE. 
McShea, L. (2013). Hearing Loss in People with Learning Disabilities. British Journal of 
Healthcare Assistants, 7(12), 601 - 605. 
McShea, L., Corkish, C. & McAnelly, S. (2014). Audiology Services: Access, Assessment 
and Aftercare. Learning Disability Practice, 17(2), 20 - 25. 
McShea, L. (2015). “I will make a difference” – Training Caregivers to Improve the Hearing 
of Adults with Learning Disabilities. British Journal of Healthcare Assistants, 9(3), 124-
127. 
McShea, L. (2015b). Managing Hearing Loss in Primary Care. Learning Disability Practice, 
18(10), 18-23. 
McShea, L., Fulton, J. & Hayes, C. (2015). Paid Support Workers for Adults with Intellectual 
Disabilities; their Current Knowledge of Hearing Loss and Future Training Needs. 
Journal of Applied Research in Intellectual Disabilities, doi 10.1111/jar.12201. 
Mencap. (2012). Death by Indifference: 74 Deaths and Counting. A Progress Report 5 years 
on. London: Mencap. 
Meuwese-Jongejeugd, A., Verschuure, H. & Evenhuis, H. M. (2007). Hearing Aids: 
Expectations and Satisfaction of People with an Intellectual Disability, a Descriptive Pilot 
Study. Journal of Intellectual Disability Research, 51(11), 913-922. 
Miller, H. & Kiani, R. (2008). Inter-Relationships between Hearing Impairment, Learning 
Disability Services and Mental Health: are Learning Disability Services “deaf” to 
Hearing Impairments? Advances in Mental Health and Learning Disabilities, 2(2), 25 – 
30. 

Lynzee McShea 
 
142
Monitor, (2015). Choice in Adult Hearing Services: The GP Perspective on Age Related 
Hearing Loss. Shropshire: Creative Research. 
Moodie, S. T., Kothari, A., Bagatto, M. P., Seewald, R., Miller, L. T. & Scollie, S. D. (2011). 
Knowledge Translation in Audiology: Promoting the Clinical Application of Best 
Evidence. Trends in Amplification, 15(1-2), 5 –22. 
Moon, J. A. (2004). A Handbook of Reflective and Experiential Learning. Theory and 
Practice. Oxford: Routledge Falme. 
Newsam, H., Walley, R. M. & McKie, K. (2010). Sensory Impairment in Adults with 
Intellectual Disabilities – An Exploration of the Awareness and Practices of Social Care 
Providers. Journal of Policy and Practice in Intellectual Disabilities, 7(3), 211 – 220. 
Ng, S. L. (2013). Theory and Research in Audiology Education: Understanding and 
Representing Complexity through Informed Methodological Decisions. Journal of the 
American Academy of Audiology, 24, 344 – 353. 
Owens, P., Carrier, J. & Horder, J. (eds.) (1995). Inter-professional Issues in Community and 
Primary Health Care. London: Macmillan. 
Patton, M. Q. (2015). Qualitative Research & Evaluation Methods 4th edition. London: 
SAGE. 
Philpott, C. (2014). Theories of Professional Learning. A Critical Guide for Teacher 
Educators. Northwich: Critical Publishing. 
Philpott, J. (2014b). Rewarding Work for Low-Paid Workers. York: Joseph Rowntree 
Foundation. 
Price, B. (2013). Using Narratives and Discourses in Neglect-Prevention Training. Nursing 
Management, 20(3)3, 28 - 35. 
Pryce, H. & Gooberman-Hill, R. (2012). ‘There’s a Hell of a Noise’: Living with a Hearing 
Loss in Residential Care. Age and Ageing, 41, 40-46. 
Pryce, H. & Gooberman-Hill, R. (2013). Foundations of an Intervention Package to Improve 
Communication in Residential Care Settings: A Mixed Methods Study. Hearing, Balance 
& Communication doi 10.3109/21695717.2012.756224. 
Pryce, H. & Hall, A. (2014). The Role of Shared Decision Making in Audiological 
Rehabilitation. SIG 7 Perspectives on Aural Rehabilitation and Its Instrumentation, 
21(1), 15-23. 
Purcell, M., McConkey, R. & Morris, I. (2000). Staff Communication with People with 
Intellectual Disabilities: the Impact of a Work-Based Training Programme. International 
Journal of Language and Communication Disorders, 35(1), 147 - 158. 
Reason, P. & Bradbury, H. (eds.) (2008). The SAGE Handbook of Action Research; 
Participative Inquiry and Practice. London: SAGE.  
Repper, J. & Breeze, J. (2007). User and Carer Involvement in the Training and Education of 
Health Professionals: A Review of the Literature. International Journal of Nursing 
Studies, 44, 511 –519. 
Robertson, J., Roberts, H. & Emerson, E. (2010). Health Checks for People with Learning 
Disabilities: A Systematic Review of Evidence. Improving Health and Lives: Learning 
Disabilities Observatory. 
Rocks, T. & Ferguson, M. (2014). Does Training Care Staff using Interactive Videos Improve 
their Hearing Aid Practical Skills, Understanding and Perception of the Importance of 
Hearing Aids? Unpublished poster presentation, Nottingham Hearing Biomedical 
Research Unit.  

“I Will Make a Difference” 
 
143
Schneider, J. M., Gopinath, B., McMahon, C. M., Britt, H. C., Harrison, C. M., Usherwood, 
T., Leeder, S. R. & Mitchell, P. (2010). Role of General Practitioners in Managing Age-
Related Hearing Loss. Medical Journal of Australia, 192, 20-23. 
Schön, D. A. (1983). The Reflective Practitioner. How Professionals Think in Action. 
Hampshire: Arena Ashgate. 
Seely-Brown, J. & Duguid, P. (1991). Organizational Learning and Communities of Practice: 
Toward a Unified View of Working, Learning and Innovation. Organization Science, 
2(1), 40 – 57. 
Shames, Y. & Simpson, J. (2012). Audiology’s Struggle for Independence. The Hearing 
Journal, 65(5), 26-30. 
Sigafoos, J. (2000). Communication Development and Aberrant Behaviour in Children with 
Developmental Disabilities. Education and Training in Mental Retardation, 35(2), 168 – 
176. 
Silverman, D. (2013). Doing Qualitative Research 4th edition. London: SAGE. 
Stewart, S., Macha, R., Hebblethwaite. & Hames, A. (2009). Residential Carers’ Knowledge 
and Attitudes Towards Physiotherapy Interventions for Adults with Learning Disabilities. 
British Journal of Learning Disabilities, 37, 232 – 238. 
Stringer, E. T. (1999). Action Research 2nd edition. London: Sage. 
Tracy, J. & McDonald, R. (2015). Health and Disability: Partnerships in Health Care. Journal 
of Applied Research in Intellectual Disabilities, 28, 22 – 32. 
Van Schrojenstein Lantman-de Valk, H. M. J. (2005). Health in People with Intellectual 
Disabilities: Current Knowledge and Gaps in Knowledge. Journal of Applied Research in 
Intellectual Disabilities, 18, 325 - 333. 
Warner Weil, S. & McGill, I. (Eds.) (1989). Making Sense of Experiential Learning. Diversity 
in Theory and Practice. Buckingham: The Society for Research into Higher Education 
and Open University Press. 
Windley, D. & Chapman, M. (2010). Support Workers within Learning/Intellectual Disability 
Services Perception of their Role, Training and Support Needs. British Journal of 
Learning Disabilities, 38, 310 - 318. 
Zuber-Skerritt, O. (1992). Professional Development in Higher Education. A Theoretical 
Framework for Action Research. London: Kogan Page. 
 
 


In: Encyclopedia of Audiology and Hearing Research 
ISBN: 978-1-53617-702-2 
Editors: Erno Larivaara and Senja Korhola 
© 2020 Nova Science Publishers, Inc. 
 
 
 
 
 
 
 
Chapter 10  
 
 
 
HEARING LOSS AND INTELLECTUAL DISABILITIES 
 
 
Siobhán Brennan1,2,* and Sarah Bent3 
1Audiology and Deafness, School of Psychological Sciences,  
University of Manchester, England, UK 
2Regional Department of Neurotology,  
Sheffield Teaching Hospitals, Sheffield, England, UK 
3Betsi Cadwaladr University Health Board, Wales, UK 
 
 
ABSTRACT 
 
There is a high prevalence of hearing loss in individuals with intellectual disabilities 
and it can affect communication, personal relationships and mental health. Awareness of 
this issue is increasing, as is our ability to assess hearing and offer appropriate 
rehabilitation, however significant developments in audiological care and management 
are still required and further research needed. This chapter discusses the importance of 
hearing loss identification and rehabilitation, aimed at professionals across different 
disciplines and also as a starting point for those new to the audiology profession. Various 
points on the Audiological care pathway for people with intellectual disabilities are 
presented including: identification of individuals who require hearing loss investigation, 
methods of assessment of hearing loss, and appropriate rehabilitation. This chapter 
includes the challenges faced by PwID and hearing loss and by clinicians. The chapter 
will conclude with some of the authors’ recommendations for improved Audiological 
care for PwID. 
 
 
1. INTRODUCTION 
 
Our relationship with sound is personal and unique. The impact that hearing loss has on 
quality of life will vary enormously depending on the person, but is known to potentially 
affect communication, education, relationships and mental health. There is growing 
awareness of the importance of hearing health in the general population internationally; 
                                                        
* Corresponding Author’s Email: Siobhan.brennan@manchester.ac.uk. 

Siobhán Brennan and Sarah Bent 
 
146
however, this issue is still under-recognised for those with intellectual disabilities. In this 
population, not only is the prevalence of hearing loss greater but the impact on life is too, 
particularly if not recognized; yet this is little known by those in caring or other health roles. 
The authors aim to provide a summary of the importance of hearing loss identification and 
rehabilitation, both for professionals across different disciplines and as a starting point for 
those new to the audiology profession. 
This chapter discusses the points along the Audiological care pathway for people with 
intellectual disabilities (PwID) including: identification of individuals who require hearing 
loss investigation, methods of assessment of hearing loss, and appropriate rehabilitation. This 
includes the challenges faced by PwID and hearing loss and by clinicians. This is drawn from 
both peer-reviewed and grey literature internationally, with additional recommendations from 
the authors’ experience individually and as part of the UK special interest group for 
professionals working in hearing and people with learning disabilities, HaLD. The chapter 
will conclude with presentations of the authors’ recommendations for improved Audiological 
care for PwID.  
 
 
2. HEARING LOSS 
 
According to the World Health Organization, there are currently 360 million people with 
disabling hearing loss globally (WHO, 2015). The prevalence varies with country, but to take 
as an example the UK, hearing loss affects approximately 1 in 6 of the population. Prevalence 
figures are considerably higher in individuals with intellectual disabilities and higher still with 
certain syndromes; however, there are significant limitations to this data. This is partly related 
to the accuracy of hearing tests in the literature - some of the adjustments that should be taken 
when testing hearing in this client group are often not available. Many authors draw 
prevalence data from hearing screening programmes carried out at the Special Olympics; this 
data is restricted to individuals who are usually in good physical condition and often with 
milder intellectual disabilities, and so possibly not truly representative of the population as a 
whole. However, Hey et al. (2014) compared the prevalence figures from the Special 
Olympics with that of the residents of a school for individuals with intellectual impairment 
and found the 2 sets of prevalence data very similar.  
Despite this high prevalence, hearing loss is still not widely recognised. As an example, 
one study suggested 70% of adults over the age of 40 with Down Syndrome to have 
significant hearing loss undiagnosed before systematic hearing testing (Van Buggenhout et 
al., 1999). Possible reasons for this are discussed further below.  
 
 
2.1. Cause of Hearing Loss 
 
The leading cause of hearing loss in any population varies by country due to factors 
including general health, genetics and exposure to drugs and noise. One of the primary aims 
of professionals such as Audiology or Ear Nose and Throat teams, who see individuals 
referred with concerns about their hearing, is to identify what type of hearing loss they may 
have. The type of hearing loss will partly determine the most appropriate management, as 

Hearing Loss and Intellectual Disabilities 
 
147
there are simple surgical and medical options available for some causes. Hearing losses can 
be loosely grouped into conductive hearing loss and sensori-neural hearing loss (or a mixed 
loss, which means there are multiple causes for the hearing loss). This section outlines some 
of the more common issues that are identified as causing a hearing difficulty in both the 
general population and those with intellectual disabilities. 
 
2.1.1. Conductive Hearing Loss 
A conductive hearing loss is an issue that arises in the outer or middle ear, so reducing 
the level of sound before it can reach the cochlea (the organ of hearing). A very frequent 
cause of conductive hearing losses is earwax. Individuals with intellectual disability as a 
result of a syndrome may have narrow ear canals or dysmorphic ears that restrict the natural 
passage of earwax. An additional aspect of narrow or tortuous ear canals is that otoscopy 
(examining the ears visually) may not be achieved, as a clear view of the ear drum may not be 
possible. Excessive earwax affects approximately 2% of the general population; in the 
population of individuals with intellectual disabilities it has been found to be in the order of 
30% (Crandell & Roeser, 1993; Smith et al., 2000). Long-standing impacted earwax can 
increase the risk of infection, cause discomfort and result in or increase tinnitus (noises 
experienced in the ears or head). Its presence will also prevent an accurate hearing 
assessment. Earwax can be removed using a range of methods, including softening (ear 
drops) which can be administered at home, and ear syringing, manual removal or micro-
suction by trained professionals. For many with intellectual disabilities this is a simple 
process and, if checked and acted on regularly, can be managed effectively. If a client is 
tactile defensive, however, other approaches may be needed and working closely with carers 
may enable the practitioner to provide appropriate adjustments. As standard, hearing 
assessment appointment letters will often advise ear canals are checked and any wax removed 
before attending. In the authors’ experience, this advice is frequently not followed. A further 
referral to remedy this, such as to an Ear, Nose and Throat department may be required, 
increasing the number of visits and length of the care pathway. Foreign objects found in ear 
canals may also cause hearing loss along with physical risks if not dealt with, and should also 
be removed professionally.  
Beyond the eardrum, the middle ear space should be air-filled, however there are times 
when it can be filled with a fluid which stays for a long period, commonly known as “glue 
ear.” Glue ear is very common in children. It can also be present in adults, associated with 
temporary upper respiratory tract infections, but will often drain naturally afterwards along 
the “eustachian tube” into the back of the throat. There are often surgical solutions to longer 
standing conductive hearing losses, such as insertion of small temporary tubes known as 
“grommets” in the eardrums to drain the fluid. This is a simple procedure which may be 
completed with local or general anesthetic although that brings risks to those with other 
medical conditions, such as may occur in those with syndromes. Due to these risks, an 
increasing number of patients with this type of conductive hearing loss are opting for hearing 
aid use instead of surgery, which will be expanded on later in this chapter. If not treated, there 
is a possibility that glue ear can cause permanent damage to the ear (Balkney et al., 1979) and 
consultation with an Ear, Nose and Throat specialist should be sought in the case of 
longstanding glue ear.  
The prevalence of chronic ear infections varies dramatically across the world. According 
to the World Health Organization (2013) “over 90% of the burden of chronic ear infections is 

Siobhán Brennan and Sarah Bent 
 
148
borne by countries in the south-east Asia, western pacific and African regions, and ethnic 
minorities in the pacific rim.” In addition to causing a hearing loss, chronic ear infections can 
lead to other life threatening conditions. In the case of an individual who does not accurately 
self-report, ear infections are more likely to be identified by family members or carers than 
other causes of conductive hearing loss because there is often a discharge or smell that can be 
observed. Also, this is more likely to cause pain than other causes of hearing loss.  
 
2.1.2. Sensori-Neural Hearing Loss 
A sensori-neural hearing loss is the catch-all term for hearing losses that affect the 
“cochlea,” or that affect the “auditory nerve.” Sensori-neural losses are usually permanent 
with no surgical or medical interventions to resolve them. They can be progressive. The most 
common form of sensori-neural hearing loss results from damage to the cochlea, however it is 
estimated that approximately 10% of sensori-neural hearing losses may be due to an “auditory 
neuropathy spectrum disorder” (ANSD) (Uus & Bamford, 2006). This term is used to 
describe a combination of Audiological findings which would suggest good cochlear function 
but pathology of the auditory nerve, distorting the signal travelling to the “auditory cortex” in 
the brain.  
In some countries, for example the UK and the US, sensori-neural age-related hearing 
loss (presbyacusis) is the most common cause of hearing loss; as an example, Action on 
Hearing Loss in the UK report that the numbers affected increases to over 40% of those over 
50 years old and over 70% of those over 70 years old. As human longevity increases, so the 
prevalence of hearing loss will also increase. An increased prevalence with age has also been 
observed in the population of individuals with intellectual disabilities. In a recent review of 
the literature on this topic, Bent et al. (2015) identified studies that reported on hearing loss 
prevalence with age. The prevalence of hearing loss in adults with intellectual disabilities 
under the age of 50 was found to range from 27% to 45%, and over 50 years of age from 59% 
to 68% (Buchanan, 1990; Venhuis, 1995; Evenhuis et al., 2001; Meuwese-Jongejeugd et al., 
2006; Van Buggenhout et al., 1999).  
 
 
2.2. Hearing Loss and Down Syndrome 
 
While there are multiple syndromes which feature hearing loss and an intellectual 
impairment, Down Syndrome has the highest incidence of hearing loss. The prevalence of 
sensori-neural hearing loss is higher in this group from birth, and this incidence increases as 
the individual gets older. Age related hearing loss is not only more common in Down 
Syndrome but also at an earlier age, often by 20 to 30 years. Three studies looked specifically 
at the prevalence of hearing loss in individuals with Down Syndrome, due to the associated 
high rate of sensory issues and precocious ageing. For this specific group under the age of 50, 
prevalence was reported from 38% to 76%, and for those over 50 years of age, from 62% to 
93% (Evenhuis et al., 2001; Meuwese-Jongejeugd et al., 2006; Van Buggenhout et al., 1999).  
Appropriate management will be discussed later in this chapter, but it should be 
highlighted that ear wax is a particular issue for this group as ear canals are typically narrow, 
so only a relatively small amount of ear wax is sufficient to block the ears.  
Additionally, for individuals with Down Syndrome, glue ear is much more common than 
in the general population, due to a number of factors such as narrower eustachian tubes and 

Hearing Loss and Intellectual Disabilities 
 
149
the middle ear fluid tending to be of a different viscosity than in other people, taking longer to 
drain and more likely to become infected (Sacks & Wood, 2003). 
 
 
2.3. Hearing Loss and Other Causes of Intellectual Disabilities 
 
There are many syndromes which commonly present with both hearing loss and 
intellectual disabilities, including Down Syndrome, CHARGE syndrome and Cornelia de 
Lange. In addition to syndromic causes, there are genetic causes of the co-morbidities of 
hearing loss and intellectual disabilities, such as chromosomal and mitochondrial disorders. 
There are also a wide range of perinatal factors that can influence hearing and intellect, 
including extreme prematurity and congenital infections. Some causes of intellectual 
disability have specific types or patterns of hearing loss, or other symptoms that are 
uncommon with other causes. It is beyond the scope of this chapter to provide a thorough 
discussion of these factors.  
Intellectual disabilities are usually present with multi-morbidities, some of which will 
compound the impact of hearing loss and should also be taken into account when the hearing 
is being assessed and managed. These are discussed as relevant to each section. 
 
 
3. ACCESSING AUDIOLOGY SERVICES 
 
Those with concerns about their hearing should seek help in order that any pathology 
may be addressed, to understand what is causing the difficulties, and to seek rehabilitation. 
Hearing loss which is not identified or managed can have serious effects on communication, 
social activity and participation, along with increased risk of depression and dementia (Action 
on Hearing Loss 2014). It is known that there tends to be a ten year delay in seeking help for 
hearing in the general population (Davis et al., 2007); it is thought to be worse still in those 
with intellectual disabilities. This may be in part due to some carers’ lack of awareness of 
symptoms of hearing loss. Also, in the case of adults with long standing undiagnosed hearing 
loss, if the individual has developed an alternative form of communication that is effective 
there may be a lack of interest in hearing assessment. Hearing loss is as affected by diagnostic 
overshadowing as any medical condition, with typical misconceptions being that lack of 
response to speech or an observed behaviour change is related simply to a person’s 
intellectual disability. 
 
 
3.1. Referral Pathways 
 
If there are concerns about hearing, the starting point is to identify if earwax is 
obstructing the ears, given the high occurrence as mentioned above, and the ease of resolving 
this in the majority of people. Wax is a healthy and normal part of the ear, and should not be 
‘cleaned out’ by the individual or family or carers; cotton wool buds and tips carry a warning 
in some countries (e.g., UK) due to the risk of puncturing the ear drum and the abrasive effect 
on the canal wall. Instead, ears should be checked regularly by healthcare professionals in 

Siobhán Brennan and Sarah Bent 
 
150
those with excessive production of wax, or those with ear structure that prevents natural 
migration of wax out from the ear. Appropriate advice on management can then be given. 
However, when the ears are free from obstruction, further consideration should be given 
to hearing loss in other parts of the ear. It should go without saying that looking into the ears 
is only a small part of the hearing pathway, and a referral to hearing professionals, such as an 
Audiology department should follow. The authors’ experience is that regrettably it is a widely 
held – but inaccurate – belief that hearing assessment is not possible with individuals with 
intellectual disabilities. This belief is likely to be a contributing factor to those with a hearing 
loss not accessing services. While modifications to standard hearing assessment is often 
necessary and there may be limitations to the outcomes of such assessments, it is rare that 
hearing assessment of some form cannot be achieved.  
 
 
3.2. Screening 
 
A majority of countries in the world now offer universal newborn hearing screening, as 
this is widely recognized as the optimum time to identify a hearing loss in the general 
population (Davis et al., 1997), and screening checks available for this age are quick to 
complete. However, this only identifies a proportion of permanent hearing losses and 
progressive losses exist, so further hearing screening at later ages is usually recommended. 
Hearing screening for adults continues to be debated (e.g., Lamb & Archbold, 2016; Pronk et 
al., 2011). There is arguably a strong case for offering a targeted hearing screening to 
individuals with intellectual disabilities in adulthood as the prevalence of hearing loss is so 
high in this population. Also the impact of hearing loss is likely to be multiplicative (Wiley & 
Moeller 2007). Furthermore self-report may not be accurate for individuals within this group 
(Emerson et al., 2013). At the time of writing, the European Federation of Audiology 
Societies is working on recommendations for screening this population (EFAS, 2015).  
In the UK, an annual Health Check is offered to some adults with an intellectual 
disability by their general practitioner, and includes a small section on hearing and 
communication (RCGP, 2010). Despite the potential that this routine targeted consideration 
of hearing should bring, the check currently relies heavily on client and carer report, which 
has been found to significantly under-identify hearing loss (Bent et al., 2015). It has also been 
suggested of general practitioners’ role “Current training is not sufficient to provide the skills 
for detection and management of hearing problems” (McShea et al., 2015).  
 
 
3.3. Suitability of Audiology Services  
 
Hearing professionals’ services for PwID internationally tend to be based either in 
hospital settings or community settings. Across the UK, the services also vary by 
geographical location due to a range of factors including differences in funding streams, 
overall departmental size, local staff experience and other demands on the service. While 
there are advantages in services being standardized nationally, local differences in provision 
can be beneficial if those differences are due to considerations of the needs of the local 
population. Specialist services for those with a specific syndrome, Down Syndrome for 
example, may have the advantage of being tailored for the needs of those particular clients, 

Hearing Loss and Intellectual Disabilities 
 
151
but at the exclusion of others that could benefit. Services offered for all those for whom 
standard Audiological care is not appropriate are by design inclusive, but require highly 
skilled professionals in their operation. Some have separate services for those with 
intellectual disabilities from birth as opposed to those with cognitive decline relating to for 
instance dementia, often due to the history of the creation of those services. 
Coming to a hospital setting can be unnerving, to the point that an individual may be so 
anxious that hearing assessment at that visit is not possible. Audiology departments usually 
include sound proof rooms, for the purpose of hearing testing accurately without interference 
from background sounds; these are spaces that can be a strange experience for most people. 
Time can be taken for the client to familiarize themselves with that environment or a further 
appointment arranged. 
 
 
3.4. Impact on Other Services 
 
There are other services which have close relationships with audiology. As well as the 
Ear, Nose and Throat team, a hearing assessment will often have a major impact on the 
outcomes of Speech and Language Therapy and Psychology. With regards to Psychology, the 
frequent relationship between hearing loss and poor mental health is well established (Saito et 
al., 2010; Monzani et al., 2008; De Graaf & Bijl, 2002; Cooper, 1976). This is frequently due 
to depression arising from isolation (Matthews, 2013). An increasing amount of research 
suggests that there may be a correlation between hearing loss and cognitive decline, and at the 
time of writing, a growing body of work is investigating whether therefore the use of hearing 
aids slows this change (e.g., Ameiva et al., 2015). For individuals with Down Syndrome, 
dementia often occurs earlier than in the general population (Van Buggenhaut et al., 1999). 
This, combined with the early onset of presbycusis, can have a multiplicative impact. There 
are strong arguments for a hearing assessment being a standard part of the dementia test 
battery, and cognition being considered alongside hearing assessment. As a minimum, links 
should be in place between services to ensure awareness and ease of referral in both 
directions. 
 
 
3.5. Considerations for a Specialist Service Model 
 
Guidelines for Audiological Care for Adults with Learning Disabilities (NHS Scotland, 
2009) suggest that a specialist service should be available for this group. Table 1 presents the 
authors’ suggested targets for inclusion in a specialist service.  
 
Table 1. Specialist audiology service considerations 
 
Service 
Choice 
 Specialised audiology service for individuals with intellectual disabilities should be offered 
within a mainstream service and with easy access to that service if preferred by the client. 
Staff 
 Staff with training and experience in Audiological care for PwID. 
 Clinic managed by 2 members of audiology team; however, for those who prefer fewer people 
in the room, the option to be seen by a single member of staff should be available. 
 

Siobhán Brennan and Sarah Bent 
 
152
Table 1. (Continued) 
 
Staff 
 Continuity of care – the same clinicians to see the client throughout their care as far as 
possible, to reduce anxiety for clients who may find adaptation to change difficult. 
 A dedicated co-ordinator responsible for evaluating and developing the service and the 
introduction of initiatives. 
 A named individual for each referral received who is responsible to ensure their care is 
delivered. 
Location 
 Access to the clinic room for orientation before the appointment if requested.  
 Home visits available if required. 
 Private or alternative quiet waiting area available if required. 
Equipment 
 
 All required equipment available at the time of the appointment to reduce unnecessary 
additional appointments. 
 Non-essential equipment cleared away as far as is reasonable to reduce the sense of a 
“clinical” environment. 
Time 
 
 Clinics on different days and times of day with a flexible booking system, allowing the 
client to be seen at a suitable time. 
 Longer appointments available, but staff aware of benefits of keeping appointments 
brief. 
 
 
4. HEARING ASSESSMENT 
 
There are multiple aims in hearing assessment. Some of the questions the clinician hopes 
to answer include “What are the quietest sounds this person can hear?,” “Can this person 
discriminate sound sufficiently to understand speech?” but fundamentally “Does this person 
have sufficient hearing to lead the life they want to lead?”. Different tests carried out in an 
Audiology clinic can contribute to answering these questions, ideally in conjunction with the 
reported experience of sound from the client or carers. The priorities for the assessment 
should be established early in the clinical encounter. The hearing assessment battery should 
consist of multiple tests – each test represents different parts of the hearing pathway and there 
are many instances where 2 people with the same single test result can ultimately have very 
different hearing capabilities. Only collectively can the assessments inform the Audiologist 
about the client’s possible experience of sound. In addition to guiding the management 
process the hearing assessment can also provide an opportunity to demonstrate to both the 
client and their carers the presence and extent of a hearing loss. This is particularly useful as 
carers reports are known to overestimate hearing ability (Bent et al., 2015) and a proficient 
hearing test provides some level of clear evidence. 
This section of the chapter aims to present a range of commonly used clinical hearing 
assessments, their limitations and considerations when being used to assess hearing for PwID. 
Recommendations for reasonable adjustments are then suggested that could be used to 
address some of the challenges of these tests.  
 
 
 
 

Hearing Loss and Intellectual Disabilities 
 
153
4.1. Getting to know the Patient’s Auditory History 
 
The extent of a hearing loss is often difficult to ascertain by any individual themselves 
because they may be unaware of the sounds that they have missed. Friends and family 
members may help to give a view of hearing abilities. This is more so the case for individuals 
with intellectual disabilities, and family or carers accompanying a client should be asked to 
report or clarify on all aspects. The Cambridge-Calgary model could be used to frame the 
appointment (Silverman, Kurtz and Draper, 2013). It is necessary to ensure that possible 
responses to sounds are not, in fact, responses to accompanying visual gestures or a client’s 
understanding of context. Offering a cup of tea is frequently accompanied with a hand symbol 
of a cup, and an individual may be very aware that on walking toward a door it will be 
necessary to get ready without ever hearing “please put on your coat.” It may be possible to 
glean information on hearing from reported reactions to different types of sound. Being more 
responsive to male voices might suggest that hearing is better at low frequencies. Enjoying 
some music genres more than others may suggest that there is sufficient hearing to identify 
the differences. Caution should be used when drawing conclusions on hearing capabilities 
based entirely on observation – for instance the teenager who turns music up may indeed be a 
sign of deteriorating hearing, but may also be due to enjoyment commonly gained from loud 
music. Table 2 presents some observations that may indicate that someone should have a 
hearing assessment.  
 
Table 2. Behavioral indications of hearing issues 
 
Behaviour directed 
towards ears 
 Puts 1 hand or both over each ear for no reason 
 Bangs or slaps face 
 Frequent touching of ears 
 Unusual head movements 
 Pulls ear lobes 
 Cups hand behind ear 
Auditory behavior 
changes 
 Developing behaviour that challenges 
 Unexpected changes in behaviour 
 Seems confused 
 A lack of response to specific sounds 
 Tends to respond more consistently to sound presented on one side 
 Attention span decreasing 
Medical changes 
 Frequent catarrh (blocked nose) 
 Discharge or smell from one or both ears 
 Dizziness 
 
The communication form that someone has chosen to use may be in part due to an 
underlying hearing loss. Also, some forms of communication may obscure signs of a 
progressive hearing loss – for example, with largely visual forms of communication such as 
Makaton, responses to speech may not change as dramatically as someone who relies on 
heard speech. While understanding a client’s preferred form of communication is a 
fundamental part of assessing the appropriate management, the reality is that audiology 

Siobhán Brennan and Sarah Bent 
 
154
clinicians with a working knowledge of communication methods such as Makaton, PECS and 
Objects of Reference are in the minority. Music is often more motivating for people than 
speech. If someone is involved in music therapy sessions, this may be an opportunity to more 
clearly identify difficulties in hearing.  
Attempts must be made to understand the communication needs of the client, priorities of 
these needs, and how these fit into their wider needs. The communication needs of people 
involved in the client’s life and their priorities should also be taken into account. There are 
clients for whom all the information typically gleaned from a hearing assessment will not be 
achieved. For these clients, consideration has to be given to which aspect of their hearing is 
most useful to understanding needs, and future rehabilitation and management. The clients 
and their carers must be involved in this prioritisation. As an example, some individuals are 
much more interested in music than verbal speech. Should this then be used during the 
assessment? Can rehabilitation be tailored to maximize music enjoyment over speech 
discrimination? There are a range of methods used within audiology to record priorities and 
extent of hearing difficulties being encountered by the patient in situations they are typically 
in, with recent emphasis on goal setting, such as with individual management plans, and 
associated outcome measures (BSA, 2012). These should be used before and after any 
rehabilitation.  
 
 
4.2. Ear Health 
 
In addition to understanding how well the client hears, the Audiologist is also concerned 
with ear health. “Otoscopy” involves viewing the outer ear and eardrum using a small light 
with a magnifier. This allows observation of issues such as infection or earwax in the outer 
ear. It typically takes under a minute in each ear. This is unobtrusive for many, but 
individuals who are tactile defensive or dislike other people being in close proximity may find 
this process uncomfortable. 
 
 
4.3. Behavioural Assessment 
 
While otoscopy and discussion with the client and those people closest to them is the 
starting point of a hearing assessment, it is imperative that a hearing assessment goes beyond 
this. Hearing can be tested in a range of ways depending on aim of the assessment.  
 
4.3.1. Observation 
During the initial discussion with the client and anyone they choose to bring to the 
appointment it is a good opportunity for the Audiologist to observe the client’s ability to hear 
the questions being asked and their interest in conversation. This dialogue may be affected by 
level of comfort with the situation in addition to their hearing abilities. Observations can also 
be carried out at home and at day services to evaluate a client’s functional hearing, that is how 
someone uses their hearing.  
 

Hearing Loss and Intellectual Disabilities 
 
155
4.3.2. Audiometry 
Pure tone audiometry (PTA) is a standard hearing test to identify the quietest sounds that 
the individual can hear at a range of tones (frequencies). These levels are then compared to 
levels expected in those with satisfactory hearing. The client is asked to wear headphones and 
respond every time they hear a sound which will vary in volume and frequency. The response 
is often pressing a button, but where there are additional physical disabilities affecting the 
response, the tester should use a creative approach to enable the patient to respond 
comfortably and reliably. For an individual with an intellectual disability, there are aspects of 
this test that may influence its accuracy:  
 
Responses to No Sound 
The test depends on an individual’s ability to wait. In the general population people 
occasionally respond when there is no sound presented. This risk tends to be higher for 
individuals with intellectual disabilities. This may be due to lack of understanding of the need 
to wait for the sound or the wish to “please” the tester by relating that they have heard a 
sound even when this may not be the case. There are tactics that the tester can employ to 
identify when this may occur such as lengthened and more variable gaps between sound 
presentation, and lateralisation (“ear choice” audiometry (Lloyd & Melrose, 1966)). 
Lateralisation in this context involves randomly changing the ear that the sound is presented 
to and asking the client on which side the sound is. For some individuals, this change of task 
is sufficient to improve the accuracy of the test.  
 
No Responses to Any Sound 
While this might be due to the client having severe hearing loss, it is usually known prior 
to the test whether this is likely from the clinician and client conversation. Not responding to 
any sound can be due to reduced levels of confidence. Frequent encouragement through the 
test can be useful. There are instances when the stimulus frequency changes, and the patient 
does not react to this change immediately. The tester may then misread this lack of response 
as a lack of hearing to this stimulus. 
 
Starting and Not Finishing 
It is necessary to test a range of volumes and frequencies. A client with an intellectual 
disability may not react to stimulus change immediately. In this instance the tester may 
misread this lack of response as a lack of hearing. This can be accommodated by reinstructing 
when changing frequency. Shorter periods of concentration may reduce test duration, so a 
smaller number of test frequencies may be possible. The tester can extrapolate results to 
estimate the remaining test frequencies if needed, however this has limitations in accuracy. 
Also, carers or family members can help to identify the point at which someone has stopped 
responding due to lack of concentration. The tester may wish to divide the testing into 
separate sessions to address this issue.  
 
Dislike of Headphones 
For some people headphones are unpleasant to wear, particularly those typically used in 
an Audiology clinic. Presenting the sounds through a speaker (free-field), usually a hand-held 
device, can address this. This has the advantage of accompanying family or carers being able 

Siobhán Brennan and Sarah Bent 
 
156
to hear the levels of sound at which the individual can hear, and the differences across 
frequencies. The major disadvantage of this method however is that because the sound is 
travelling to both ears, it is not possible to be sure which ear is responding.  
If there are significant differences in hearing between the 2 ears, it may indicate that 
further medical investigation is required. Aside from the medical concerns that an asymmetric 
hearing loss raises, there are other disadvantages in this type of hearing loss. While it is 
possible hear well with one ear, if hearing is good in both ears it is easier to “localize,” or 
identify where a sound is coming from. This has safety implications and can increase the 
feeling of comfort in a range of situations. Another benefit of hearing well in both ears is that 
hearing speech in background noise is improved. This is because the brain compares the 
information from each ear, along with visual cues if we are able to find the speaker and look 
at their faces. 
 
4.3.3. Visual Reinforcement Audiometry (VRA) 
For individuals who do not have the capacity to wait for the presentation of a sound or 
carry out an agreed action, visual reinforcement audiometry is an option. During this test, a 
sound is presented through a speaker or headphones and if the client turns towards the source 
of the sound there is an image of interest to encourage them to continue to turn to sounds so 
that a range of volumes and frequencies can be tested. Responses to sound in this situation 
can vary widely and it is imperative that the tester and someone who knows the client well 
work together to interpret reactions that the client may have in response to sound. There are 
some who may not make the connection between the sound presentation and the image, 
however in this case the tester and family member or carer together can observe any 
responses the client makes to presented sound. Examination of the outcomes of VRA testing 
at a specialist clinic over the space of a year identified that responses sufficiently reliable to 
draw conclusions about hearing status were found in a third of clients for whom VRA was 
used (Dubb & Brennan, 2013).  
 
4.3.4. Speech Discrimination Testing 
In addition to identifying the quietest sound that a client can hear, it is useful to identify 
at what level their hearing can discriminate speech. There are a range of tests available which 
can consist of a word being presented and the client being asked to either repeat the word or 
select it from a range of pictures. There are very few tests of speech discrimination that have 
been verified for use with adults with intellectual disabilities. This should be taken into 
account when using this type of testing. The extent of the client’s vocabulary should also be 
taken into account when selecting the most appropriate test. If a presented word is not within 
the client’s lexicon they may not respond at all or will respond with a similar word that is 
known to the client and this could be mis-interpreted as a lack of hearing. Another risk of this 
type of testing that it is often assumed that speech is the primary sound of interest, however 
for some individuals this isn’t the case, and lack of interest in the stimulus does not 
necessarily reflect the inability to hear that stimulus. Additionally, speech tests are sometimes 
pre-recorded; if someone struggles to recognize words spoken in an unfamiliar accent this can 
affect the accuracy of the results.  
 
 

Hearing Loss and Intellectual Disabilities 
 
157
4.4. Electrophysiological Assessment 
 
There are also “objective” measures of hearing assessment. These are ways of testing 
hearing that do not require an action from the client in response to a presented sound. It is 
often used when behavioural assessments are not sufficiently repeatable. The majority of 
these tests can be carried out on an outpatient basis, for which the client should be relatively 
still and quiet. If this is not possible, some of these types of tests can be offered to take place 
under general anesthetic; in which case there is benefit to completing on the same occasion as 
any other procedures the client is to have which require a general anesthetic.  
 
4.4.1. Otoacoustic Emissions (OAEs) 
Otoacoustic emissions are often used as a screening tool in babies and younger adults. 
This test involves placing a small soft tip at the entrance to the ear canal for approximately 2 
minutes. A quiet sound travels as far as the cochlea, and the normal hearing ear generates a 
sound of its own which is recorded by a small microphone. The major advantage of this type 
of testing is that it is ear specific and very fast. There are disadvantages however: commonly 
recorded otoacoustic emissions are not frequency specific so someone may have very good 
hearing at some frequencies but not others and this will not be known. Additionally, this 
method only tests the auditory system as far as the cochlea and no further, so if there are 
issues relating to the auditory nerve this will also not be known. The test is only possible if 
background noise is low – so this test is not appropriate for someone who has perhaps 
involuntary vocalizations.  
 
4.4.2. Auditory Brainstem Response Audiometry 
Auditory Brainstem Response (ABR) testing involves placing electrodes on the head to 
record the electrical signal travelling up the auditory brainstem portion of the auditory nerve 
in response to sound presented via headphones. To reduce the response being obscured by 
electrical activity from other parts of the body the person being tested needs to be relaxed, 
and can be recorded while the person is asleep. This test is ideal for hearing assessment under 
general anesthetic. This test can be frequency specific and can take anything from 10 minutes 
to an hour depending on how much information is needed and how low the background noise 
is.  
 
4.4.3. Cortical Evoked Response Audiometry 
Cortical Evoked Response Audiometry (CERA) also involves placing electrodes on the 
head to record the electrical signal travelling up the auditory nerve in response to sound 
presented via headphones; however, due to the nature of the stimulus and recording 
parameters used, the response recorded originates higher up the auditory pathway. For this 
reason, this response is dramatically reduced if someone is asleep and therefore not suitable 
for recording under general anesthetic. This test is also frequency specific and again can take 
anything from 10 minutes to an hour depending on how much information is needed and how 
low the background noise is.  
 
 
 

Siobhán Brennan and Sarah Bent 
 
158
4.5. Assessment Recommendations 
 
 
Ear canals should be checked regularly and impacted ear wax addressed  
 
Family members and carers should be involved in the assessment process  
 
The client should be able to visit the department before their appointment and/or be 
provided with a story board of the appointment. Images of the staff should also be 
available to see prior to the appointment.  
 
A creative approach should be used when attempting behavioural testing. 
 
The option of testing at the hospital or a home environment should be available. 
There are major disadvantages to carrying out a hearing test in a domestic 
environment; they are rarely sufficiently quiet, and not all of the equipment is 
portable, limiting the testing that can be done, however it may be much more 
palatable for the client than a hospital setting. 
 
It may be necessary to use electrophysiology to assess hearing – these techniques 
should be available and familiar to the tester. 
 
Research is needed to develop the accuracy and acceptability of Audiological 
assessment for PwID. Urgent areas include; 
 
Optimising test parameters for electrophysiological testing, 
 
Verification of speech discrimination tests for PwID. 
 
 
5. REHABILITATION 
 
The impact of hearing impairment on each person is different. When considering 
rehabilitation, there are a large number of factors which should be taken into account. What 
are the forms of communication used by the individual? Will the use of technology, such as a 
hearing aid, help or hinder that existing form of communication? Is the person with the 
hearing impairment motivated to improve their hearing? The experience of activity 
limitations and participation restrictions are equally important as the hearing test in providing 
the effect and experience of that hearing loss. If an amplification device is being considered, 
are there barriers to its use, that taken into account with the benefits would result in an overall 
decrease in quality of life? What reasonable adjustments could be considered to facilitate 
hearing aid use? Are there equitable alternatives?  
 
 
5.1. Hearing Aids 
 
Like so many areas of applied science, hearing aid technology is developing at a 
prodigious rate and satisfaction with hearing aids has increased over recent years. Hearing 
aids have been shown to improve outcomes for PwIDs as well as the general population 
(Cupples et al., 2013). Wearing a hearing aid is not equivalent to wearing glasses. Whereas 
glasses will return most wearer’s vision to an experience very similar to that of a non-glasses 
wearer, the same cannot be said for hearing aids and the hearing impaired listener. When 

Hearing Loss and Intellectual Disabilities 
 
159
hearing is impaired, sound is not only quieter, but in most cases also distorted to a certain 
extent.  
The uptake of hearing aids is influenced by a great many factors – some intrinsic to the 
hearing aids, and some intrinsic to the wearer. Often factors which influence the likelihood of 
an individual seeking help are also those which impact the likelihood of success with hearing 
aids when they are issued. Factors external to the hearing aids include self-confidence about 
ability to manage the hearing aids and support of significant others. Taking the group as a 
whole, it has been found that the expectations and wishes around hearing aids by individuals 
with intellectual impairment are similar to those of the general population, including sound 
quality, cosmetics and comfort (Meuwese-Jongejeugd, 2007).  
 
5.1.1. Setting Hearing Aids 
The most common hearing aids are Behind-the-ear (BTE) and In-the-ear (ITE). The BTE 
consists of an earmould which fits in the outer ear and directs amplified sound into the ear 
from the main body of the hearing aid which sits behind the ear in the same location as a 
glasses leg/arm. Earmould selection will depend not only on the Audiological needs of the 
patient but also the nature of their external ear. A significant proportion of individuals with 
intellectual disabilities have cranio-facial abnormalities and a higher prevalence of canal 
stenosis than the general population. Canal stenosis is a narrowing of the ear canal. In 
addition to often being smaller, the external part of the ear in individuals with Down 
Syndrome has been found to be softer and shallower than in individuals without Down 
Syndrome (Miller, 1997). An implication that this has been found to have on hearing aid 
uptake in this population is the frequency with which the hearing aid will fall from the ear.  
The ITE however is a single entity which sits in the outer ear and tends to be more 
appropriate for mild and moderate losses than severe or profound hearing loss. Additionally, 
considerations around which to select include ease of insertion, likelihood of loss and risks of 
ingestion.  
The outcomes of the hearing assessment are used to program the hearing aids using 
“prescription formulae.” These use group data to predict the hearing aid settings that will 
maximize clarity of speech. The fact that group data is used means that for an individual the 
optimum settings may be significantly different. Evidence is currently limited regarding the 
optimum approach to take in hearing aid fitting and management for adults with intellectual 
disabilities, for example at the time of writing the standard prescription formulae have not 
been validated in this group. For these reasons, once a hearing aid is set up, the wearer is 
asked their opinion regarding the quality of sounds, and “aided” speech discrimination tests 
too. Hearing aid fine tuning can then be carried out accordingly. For individuals with 
intellectual disabilities, communicative skills may not be sufficient to articulate their opinion 
on this. Also, questions directed to the wearer should take into account the increased 
likelihood of acquiescence in individuals with intellectual disabilities.  
Programming the hearing aid often requires making Real Ear Measures (REMs). This 
involves placing a small tube in the ear canal with the hearing aid in place to measure the 
sound. Placing an identical hearing aid on 2 different ears can sound very different - imagine 
how different your voice sounds in a cave to how it sounds in your living room! If a client has 
too much involuntary movement or earwax to make this a safe procedure the hearing aid can 
be set up in a coupler (a small tube which imitates an ear) using average data called “Real Ear 
to Coupler Difference (RECD).” However, there are syndromes associated with intellectual 

Siobhán Brennan and Sarah Bent 
 
160
disabilities and hearing loss such as Down Syndrome which present with smaller external ears 
than expected and the standard RECD may be inaccurate. For these individuals, coupler 
fittings may be inaccurate. How someone perceives familiar voices will be more crucial than 
their perception of the Audiologist. Additionally, it can take longer for an individual with an 
intellectual disability to acclimatise to the voices of people who they are not familiar with. 
The family member or carer accompanying the client can be involved with establishing 
whether or not the hearing aid is making a discernable difference to their communication. 
This could include presentation of different environmental sounds that the client is familiar 
with presented at different levels.  
Multiple programs can be incorporated allowing the user to adjust the hearing aid settings 
depending on the situations they happen to be in. It is thought that the use of additional 
hearing aid programs should be removed unless a user has full comprehension of their 
appropriate use. This may be less of a need as hearing aids are developed with increasingly 
sophisticated ways of self-adjustment with scene analysis.  
 
5.1.2. Adapting to Hearing Aids 
Time is required for an individual to acclimatise to a hearing aid, and for a person with an 
intellectual disability the introduction of change can be particularly stressful. It is essential 
that careful consideration and treatment planning is put into place to ensure that the potential 
benefits of amplification can be gained by those who wish to use them. There may have been 
an extended period of time between developing a hearing impairment and using hearing aids, 
as there is a higher incidence of long term undiagnosed hearing loss in this group. The 
introduction of amplification may be an unsettling experience. If this is not managed 
appropriately there is a high risk of the patient rejecting amplification entirely. For these 
reasons in the case of a bilateral hearing loss (in both ears) there is an argument that the first 
hearing aid fitting should be a unilateral fit (hearing aid for one ear only), and only once it is 
established that the patients enjoys the use of the hearing aid and gets benefit from it, should a 
second hearing aid be considered.  
Hearing aids are becoming much better in terms of their ability to cope with music. It 
should be explored at the point of assessment whether the client has an interest in music, so 
that this can be taken into account in the hearing aid fitting. This could be a stimulus that is 
used to develop a person’s relationship with their hearing aid.  
The uptake of hearing aids is known to be poor in individuals with intellectual disabilities 
if there is insufficient provision of adequate support and follow-up. Review appointments are 
to assess the outcomes of hearing aid use after it has been worn for a time. In addition to the 
identification of any logistical issues, discussions should also focus around particular parts of 
a person’s life where they found the hearing aid of benefit or that it caused specific 
difficulties. “Datalogging” is a feature that allows the Audiologist to discover how frequently 
the hearing aid has been on. For individuals with multiple programmes and an adjustable 
volume control, datalogging can also reveal user preferences and indicate whether, for 
example, the user needs more gain if there is evidence that the volume is repeatedly being 
turned up. It may take repeated review appointments for a client to fully adapt to hearing aid 
use.  
Some issues relating to rejection of hearing aids may be related to clients and/or their 
carers not being confident in their use. This can occur in larger institutions where instructions 
have been issued to a single carer on the date of the hearing aid fitting and that information 

Hearing Loss and Intellectual Disabilities 
 
161
has not been effectively passed on to the other members of the patient’s care team. This can 
be addressed by additional training sessions being offered to clients and staff which include 
reiterating the benefits of a hearing aid for a client with an intellectual disability and hearing 
loss, insertion and removal of the hearing aid, maintenance including cleaning, battery 
replacement and trouble shooting. 
 
 
5.2. Alternative Rehabilitation 
 
For those clients for whom hearing aids are not wanted or appropriate, there are still 
many benefits of hearing assessment. If the client and their family or carers are aware that 
there is a hearing issue, a greater amount of support can be offered and hearing tactics can be 
developed. Also there are a wide range of adaptations and assistive listening devices 
available, such as connecting fire alarms to the lights, or amplified telephones. The form of 
communication that someone uses should be considered within the context of their hearing 
loss.  
 
5.2.1. Hearing Tactics 
Hearing tactics refer to strategies that an individual can use to maximize the clarity of the 
signal being listened to. These tactics make hearing easier for most people, with or without a 
hearing loss. Training in using these tactics would benefit in particular those who have a 
hearing loss, but are unable or choose not to wear a hearing aid. For example, Action on 
Hearing Loss recommended tactics for the listener include: 
 
 
Looking at the speaker 
 
If there is a difference between the ear moving the better ear toward the speaker 
 
Make the speaker aware of a hearing loss 
 
Tactics for the speaker can include: 
 
 
Getting someone’s attention before speaking 
 
Don’t cover any part of the face or exaggerate facial movement  
 
Reducing background noise 
 
There are many more tactics that can assist the listener with a hearing impairment. If a 
client works with multiple of carers, it would be useful for all of these carers to become 
familiar with them. 
 
5.2.2. Assistive Listening Devices 
In addition to hearing aids, there are a wide range of devices that can be used to 
complement hearing aid use and others which can be used entirely independently. Devices 
which can be used with or without hearing aids include loud doorbells, telephones or TV 
listeners which may use headphones. The form of communication used by an individual with 
an intellectual disability and whether they are tactile defensive and can tolerate headphones is 
likely to influence which devices are most appropriate.  

Siobhán Brennan and Sarah Bent 
 
162
If a client uses hearing aids, there are also devices that work with the hearing aid to 
reduce the impact of background noise. These include frequency modulation (FM) systems. 
These generally consist of a microphone which is placed as close as possible to the speaker 
and the signal is transmitted like a radio signal to the hearing aid. FM systems can be either 
personal FM systems where the speaker may wear the microphone such as in a classroom 
setting, or FM systems which have a fixed microphone to help in a public setting, such as a 
bank or theatre. When the user has an intellectual disability care it may be necessary for the 
individual or anyone supporting them to become familiar with these devices. In some 
countries these devices are offered through social care services or 3rd sector voluntary 
organizations. New technology is also becoming available rapidly, including wireless and 
Bluetooth options for connecting hearing aids to the client’s own personal technology such as 
telephones. 
 
 
5.3. Rehabilitation Recommendations 
 
 
Regular wax monitoring and removal at the GP surgery or Ear Nose and Throat 
department is recommended for PwID.  
 
Hearing aid checks relying on questioning should be done with caution in light of 
possible acquiescence. Measures of hearing aid levels by audiology are 
recommended instead. 
 
A range of communication devices should be available alongside hearing aids. 
 
Hearing tactics should be offered to both PwID and their carers. 
 
In coming to terms with using and hearing through the hearing aid, both the 
individual’s and their carers’ needs should be considered and supported.  
 
Prior to any demonstration and instructions, patients should be advised on becoming 
accustomed to the hearing aid, being counselled, encouraged and reassured.  
 
Both patients and their carers should be provided with verbal and written information 
as appropriate.  
 
Other professionals relevant to the individual’s care should be considered, such as 
Hearing Therapy or Speech and Language Therapy specialists.  
 
Prior to routine monitoring a rehabilitation pathway should continue until the 
clinician is confident that the auditory needs are realistically met, and that the patient 
and their carer are having no major practical difficulties with hearing aid use. 
 
Greater research is needed surrounding Audiological management for individuals 
with intellectual disabilities. This research should include; 
 
comparing the outcomes of different service models, 
 
verification of optimising hearing aid fitting targets for PwID, 
 
appropriate outcomes for assessing when individualised needs are met. 
 
 
CONCLUSION 
 
Regrettably, hearing loss is one of the many health issues that is under-identified in 
individuals with intellectual disabilities. Even if suspected, the effect of hearing loss is often 

Hearing Loss and Intellectual Disabilities 
 
163
underestimated or not prioritised. As longevity increases, the prevalence of hearing loss 
across the population as a whole increases and demands on Audiological care also increase. 
The need for improved access to appropriate hearing assessment and personalised 
Audiological care is widely recognised. While there are additional challenges to accessing 
and utilising audiology services for individuals with intellectual disabilities and hearing loss, 
this chapter had outlined many steps known to minimise these, and the benefits for most 
people outweigh the issues. As health and hearing screening programmes continue to expand, 
the opportunities for accessing audiology services increase. Awareness of sensory needs is 
increasing. 
 
 
REFERENCES 
 
Action on Hearing Loss (2014) Caring for older people with hearing loss Retrieved May 
2016 from file://nask.man.ac.uk/home$/Caring%20for%20older%20people%20with%20 
hearing%20loss_March%202013.pdf 
Action on Hearing Loss (2016). Communication Tips. Retrieved May 2016, from 
www.actiononhearingloss.org.uk/your-hearing/ways-of-communi cating/communication-
tips/tips-for-people-with-hearing-loss.aspx. 
Action on Hearing Loss (n.d.). Communication Tips. Retrieved May 2016, from 
www.actiononhearingloss.org.uk/your-hearing/ways-of-communi cating/communication-
tips/tips-for-people-with-hearing-loss.aspx. 
Action on Hearing Loss (n.d.). Communication Tips. Retrieved May 25th, 2016, from 
www.actiononhearingloss.org.uk/your-hearing/ways-of-communicating/communication-
tips/tips-for-people-with-hearing-loss.aspx. 
Balkany, T.J., Mischke, R.E., Downs, M.P. & Jafek, B.W. (1979). Ossicular abnormalities in 
Down's syndrome. Otolaryngology: Head and Neck Surgery, 87, 372-384. 
British Society of Audiology (2012) Common Principles of rehabiliation for adults with 
hearing and/or balance related problems in routine audiology. Practice Guidance. 
Bent S., McShea L., Brennan S. (2015). The importance of hearing: a review of the literature 
on hearing loss for older people with learning disabilities. British Journal of Learning 
Disabilities, 43(4), 277-284. 
Brister F., Fullwood H.L., Ripp T., Blodgett C. (1986). Incidence of occlusion due to 
impacted cerumen among mentally retarded adolescents. American Journal of Mental 
Deficiency, 91(3), 302-4. 
Cooper. A.F. (1976). Deafness and psuchiatric illness. British Journal of Psychiatry, 129, 
216-226. 
Crandell C.C., Roeser R.J. (1993). Incidence of excessive/impacted cerumen in individuals 
with mental retardation: a longitudinal investigation. American Journal of Mental 
Retardation, 97(5) 568:74. 
Cupples L., Ching T.Y., Crowe K., Seeto M., Leigh G., Street L., Day J., Marnane V., 
Thomson J. (2013). Outcomes of 3-year -old children with hearing loss and different 
types of additional disabilities. Journal of Deaf Studies and Deaf Education, 19(1), 20-
39. 

Siobhán Brennan and Sarah Bent 
 
164
Davis A., Bamford J., Wilson I., Ramkalawan T., Forshaw M., Wright S. (1997). A critical 
review of the role of neonatal hearing screening in the detection of congenital hearing 
impairment. Health Technology Assessment, 1(10). 
Davis A., Smith P., Ferguson M., Stephens D., Gianopoulos I. (2007). Acceptability, benefit, 
and costs of early screening for hearing disability: A study of potential screening tests 
and models. Health Technology Assessment, 11, 1-294. 
De Graaf R., Bijl R.V. (2002). Determinants of mental distress in adults with a severe 
auditory impairment: differences between prelingual and postlingual deafness. 
Psychosomatic medicine, 64, 61-70. 
Dubb M., Brennan. S. (2013). To Determine The Effectiveness of Current VRA Protocol 
When Testing Adults With A Learning Disability. British Academy Audiology Annual 
Conference. 
Emerson E., Felce D., Stancliffe R.J. (2013). Issues concerning self-report data and 
population based data sets involving people with intellectual disabilities. Intellectual and 
Developmental Disabilities, 333-348. 
Hey C., Fessler S., Hafner N., Lange B.P., Euler H.A., Neumann K. (2014). High prevalence 
of hearing loss at the special olympics: is this representative of people with intellectual 
disability? Journal of Applied Research in Intellectual Disability, 27(2), 125-33. 
Kumar Sinha A., Montgomery J.K., Heree G.R., McPherson D.L. (2008). Hearing screening 
outcomes for persons for persons with intellectual disability: a preliminary report of 
findings from the 2005 Special Olympics World Winder Games. International Journal of 
Audiology, 47(7), 399-403. 
Lamb B., Archbold S. (2016). Adult Hearing Screening: Can we afford to wait any longer? 
The Ear Foundation. 
Lees L.M., Govindaraju R., Hon S.K. (2008). Cotton bud and ear cleaning - a loose tip cotton 
bud? Medical Journal of Malaysia, 60(1), 85-8. 
Lloyd L.L., Melrose J. (1966). Reliability of selected auditory responses of normal hearing 
mentally retarded children. American Journal of Mental Deficiency, 71(1), 133-143. 
Matthews L., Action on Hearing Loss (2013). Hearing loss, tinnitus and mental health: A 
literature review. 
McShea L., Fulton J., Hayes C. (2015). Paid Support Workers for Adults with Intellectual 
Disabilities: Their Current Knowledge of Hearing Loss and Future Training Needs. 
Journal of Applied Research in Intellectual Disability, Epub ahead of print. 
Meuwese-Jongejeugd A., Verschuure H., Evenhuis H.M. (2007). Hearing aids: expectations 
and satisfaction of people with an intellectual disability, a descriptive pilot study. Journal 
of Intellectual Disability Research, 51(11), 913-22. 
Miller M. (1997) Identification of difficulties experienced with the physiolcal application of 
behind-the-ear hearing aids and their association with auricular anatomy: a study of 
Down’s Syndrome compared to non-Down’s Syndrome individuals Thesis University of 
Manchester. 
Monzani D., Galeazzi G.M., Genovese E., Marrara A., Martini A. (2008). Psychological 
profile and social behaviour of working adults with mild or moderate hearing loss. Acta 
Otothinolaryngologica, 28, 61-66. 
Quaranta N., Coppola F., Casulli M., Barulli M.R., Panza F., Tortelli R., Capozzo R., Leo A., 
Tursi M., Grasso A., Solfrizzi V., Sobbà C., Logroscino G. (2014). The prevalence of 

Hearing Loss and Intellectual Disabilities 
 
165
peripheral and central hearing impairment and its relation to cognition in older adults. 
Audiology and Neurotology, S1 P10-4. 
NHS Health Scotland. (2009). Guidelines for meeting Audiological needs of adults with 
learning disabilities.  
Pronk M., Kramer S.E., Davis A.C., Stephens D., Smith P.A., Thodi C., Anteunis L.J., 
Parazzini M., Grandori F. (2011). Interventions following hearing screening in adults: A 
systematic descriptive review. International Journal of Audiology, 50, 594-609. 
Royal College of General Practitioners (RCGP). (2010). A Step by Step Guide for GP 
Practices: Annual Health Checks for People with a Learning Disability. London: Royal 
College of General Practitioners. 
Sacks B., Wood A. Hearing disorders in children with Down syndrome. Down Syndrome 
News and Update. 2003;3(2);38-41. 
Saito H., Nishiwaki Y., Michikawa T., Kikuchi Y., Mizutari K., Takebayashi T., Ogawa K. 
(2010). Hearing handicap predicts the development of depressive symptoms after three 
years in older community-dwelling Japanese. Journal of the American Geriatrics Society, 
58(1), 93-7. 
Silverman J., Draper J., Kurtz S.M. (2013). Skills for communicating with patients (3rd ed.). 
Oxford: Radcliffe Publishing. 
Skellington O.K., Leven T., Bryan R., Wilson E. (2006). Community Care and Mental Health 
Services for Adults with Sensory Impairment in Scotland. Edinburgh: Scottish Executive 
Social Research. 
Smith W.K., Mair R., Marshall L., Bilous S., Birchall M.A. (2000). Assessment of hearing in 
persons with learning disabilities: the Phoenix NHS Trust, January 1997 to September 
1998. The Journal of Laryngology and Otology, 114 (12) 940-3. 
European Fedaration of Audiology Societies (2015). EFAS Working Group on Audiology 
Intellectual Disabilities Minutes.  
Uus K., Bamford J. (2006). Effectiveness of population-based newborn hearing screening in 
England: ages of interventions and profile of cases. Pediatrics, 117(5), 887-93. 
Van Buggenhout G.J., Trommelen J.C., Schoenmaker A., DeBal C., Verbeek J.J., Smeets 
D.F., Ropers H.H., Devriendt K., Hamel B.C., Fryns J.P. (1999). Down Syndrome in a 
population of elderly mentally retarded patients: Genetic-diagnostic survey and 
implications for medical care. American Journal of Medical Genetics, 85(4), 376-384. 
Zigman W.B. (2013). Atypical aging in Down syndrome. Developmental Disabilities 
Research Reviews, 18, 51-67. 
Wiley S. Moeller M.P. (2007) Red Flags for disabilities in children who are deaf/hard of 
hearing. The ASHA Leader 12 8-29 
WHO. (2015). Deafness and Hearing Loss Fact Sheet No 300.  
WHO. (2013). Millions of people in the world have hearing loss that can be treated or 
prevented.  
Yoshinaga-Itano C. (2004). Levels of evidence: universal newborn hearing screening (UNHS) 
and early hearing detection and intervention systems (EDHI). Journal of Communication 
Disorders, 451-65. 
 


In: Encyclopedia of Audiology and Hearing Research 
ISBN: 978-1-53617-702-2 
Editors: Erno Larivaara and Senja Korhola 
© 2020 Nova Science Publishers, Inc. 
 
 
 
 
 
 
 
Chapter 11  
 
 
 
LOOKING WITH EARS, HEARING WITH EYES: 
VISUAL AND AURAL INTERACTION  
IN CERVANTES AND SHAKESPEARE 
 
 
José Manuel González* 
English Department, University of Alicante, Alicante, Spain 
 
 
ABSTRACT 
 
Early modern culture found in the faculties of sight and hearing the highest orders of 
the senses. They were considered a key to explaining human perceptions, owing to the 
powerful way in which they can influence and disturb human life. Shakespeare’s and 
Cervantes’s treatment of them includes a full acknowledgment of their mental and bodily 
aspects and functions. As seeing and hearing do not come in a pure state, they mutually 
interact in the characters and in their responses, which are often contradictory. Since we 
are visually and aurally minded, it is worth inquiring into how, in Cervantes and 
Shakespeare, the eye and the ear are used and abused by the characters; how their 
interaction affects them as hearers and beholders who respond to what is happening by 
such processes as sympathy or antagonism; and how they make characters react in one 
way or another, as their actions and emotions depend on what they hear and see.  
 
Keywords: ears, eyes, Shakespeare, Cervantes, perception, emotion, senses, interaction 
 
 
Early modern culture found in the faculties of sight and hearing the highest orders of the 
senses. They were considered a key to explaining human perceptions, owing to the powerful 
way in which they could influence and disturb human life. Shakespeare’s and Cervantes’s 
treatment of them includes a positive acknowledgment of their mental and bodily aspects and 
functions. As seeing and hearing do not come in a pure state, this paper will examine how 
they mutually interact in the characters and in their responses, which are often contradictory. 
Since we are visually and aurally minded, it is worth inquiring into how, in Cervantes and 
                                                        
* Corresponding Author’s Email: jm.gonzalez@ua.es. 

José Manuel González 
 
168
Shakespeare, the eye and the ear are used and abused by the characters; how their interaction 
affects them as hearers and beholders who respond to what is happening by such processes as 
sympathy or antagonism; and how they make characters react in one way or another, since 
their actions and emotions depend on what they hear and see. 
Cervantes, like Shakespeare, shared an interest in the culture of the senses, locating the 
senses in relation to the body, the mind and society, thereby providing a broader 
understanding of their centrality in human life. But how can we describe them? How can we 
differentiate them? Can we really trust them and understand what they signify, as we are often 
wrong about our own sensations and deceive ourselves about their meaning? In general, the 
senses are usually considered natural bodily perceptions that have a direct influence on 
human behaviour. And yet sensory experience varies in time and place, from person to 
person, from culture to culture, depending on the social and cultural context in which it 
occurs, so as to make it an important constituent of life. 
Though Aristotle first defined the five human senses (436b), definitions and theories 
about them have varied widely. Augustine maintained that there was a sixth, inner sense, 
which perceived not only external objects, but also the five senses themselves. He also held 
that “together, the five bodily organs of sight, sound, smell, taste, and touch express a 
hierarchy based on how the four physical elements (fire, air, earth, and water) engage the 
human soul” (in Vance 16). The enumeration of the senses, as well as their anatomical 
function, relationship to the imagination, and position between spaces inside and outside the 
body, were big issues within the debate in the late sixteenth and early seventeenth centuries in 
England and Spain. Helkiah Crooke in Microcosmographia (1615) referred to classical 
sources and contemporary debates, comparing Aristotle, Galen and Vesalius, among others, 
and presenting his own view in the “Labyrinth concerning the Senses” (716) where he 
examined the complex nature of senses. He, together with Wright and Reynolds, accepted the 
model of perception that had its origin in Aristotle’s De Anima. 
Eyes and ears were held in an exclusive position above the other senses. Although Wright 
associated vision with the passions and hearing with reason, seeing and hearing were 
generally viewed as the intellectual senses. They were considered active mediators between 
the inner self and the outer world. John Bulwer, in his definition of gesturing as a language, 
conflated seeing with hearing: “for as the tongue speaketh to the ear, so gesture speaketh to 
the eye” (5). For Sir John Davies sight and hearing were closely tied to thought, as they were 
the “conduit pipes of knowledge” to “feed the mind.” He groups them above “th’other three” 
senses (44). However, the Aristotelian model concerning sensation, cognition and the mind, 
which was so influential in diverse ways in the Middle Ages and the Renaissance, 
characteristically privileged sight as the noblest sense and most compatible with rational life. 
Robert Burton in The Anatomy of Melancholy (1628) calls sight the most precious sense and 
the best because it “sees the whole body at once” and because “by it we learn, and discern all 
things” (157). Shakespeare’s and Cervantes’ treatment of these two senses included a full 
acknowledgment of the bodily aspects. Their workings also showed the effect of the belief in 
the humoural composition of the self. Considered in essence processes of the mind, humours 
were believed to manifest themselves through material symptoms and bodily effects on the 
senses. 
They considered the sight and the ear were complementary senses that made possible the 
sensorial process. There was, therefore, a close relation between them as Sonnet 23 clearly 
shows: 

Looking with Ears, Hearing with Eyes 
 
169
O let my books be then the eloquence  
And dumb presagers of my speaking breast,  
Who plead for love and look for recompense  
More than that tongue that more hath more express´d. 
O, learn to read what silent love hath writ:  
To hear with eyes belongs to love´s fine wit. 
(9-14) 
 
Shakespeare was aware of the potential of visual and aural power, drawing attention to 
their connection. In Venus and Adonis he sets up a structure of mirroring between the 
seduction of one character by another and the seduction of the reader by the text. While the 
attempt to seduce Adonis by Venus is the most obvious aspect of persuasion in the poem, 
Venus also argues for the disruption of the senses caused by Adonis. There is no resistance to 
Adonis’s voice other than deafness, and his voice penetrates to her heart. But it is not hearing 
alone that is the problem, and she continues: 
 
Had I no eyes but ears, my ears would love 
That inward beauty and invisible; 
Or were I deaf, thy outward parts would move 
Each part in me that were but sensible: 
Though neither eyes nor ears, to hear nor see, 
Yet should I be in love by touching thee. 
(480-486) 
 
Rather than different senses giving access to different experiences or forms of 
knowledge, it leads to the same end: love. With it goes the problem of which sense to use in 
the perception of beauty. While I refer to the relationship between the aural and the visual, it 
would be wise to note the further step in Venus’s speech from eye to ear, from ear to touch. 
But it is also possible to render this differently; from sight to blindness, from blindness to 
hearing, from hearing to deafness, and from deafness to touch. One sense activates another, 
but only at the cost of its own deprivation. Venus’s rhetorical display, in which she attempts 
to argue her way into Adonis’s affections, parallels Shakespeare’s desire to persuade and 
seduce the reader. Like the character within the poem, the ear of the reader is open to 
penetration, to another form of productive hearing. Yet again, such a penetration of the heart 
comes through the ear, but for the reader this is enacted through the eye. 
Sight is the sense par excellence in Don Quixote. Countless adventures begin when the 
knight and his squire see someone or something approaching, and each one sees 
something different. The power to see, or not to see, and to be seen or not by others, 
determines Don Quixote’s fortunes. The problems of vision and perception become one 
of the central themes in the two parts. For instance, during the night-long vigil Don 
Quixote spent guarding his arms, on his very first night out, the moon was “so bright that 
it competed with the source of its brightness, and every action of the novice knight could 
be clearly observed by all” (1/3.38). Even darkness turns bright to make his strange 
appearance visible. But Cervantes does not always set action in clear open landscapes. In 
The Trials of Persiles and Sigismunda (1617) for instance, there are numerous dark and 
foggy scenes in which it is almost impossible for the characters to see anything. It is as if 

José Manuel González 
 
170
Cervantes had decided to place the action in an ideal setting for testing knowledge and 
theories about optics, refraction, and the anatomy of human sight. He lived at the time 
“when decisive developments in science, such as the invention of the telescope, were 
expanding the range of human vision, and when the discipline of ophthalmology was 
making great advances.” (Echevarría 218).  
According to the popular early modern theory of extramission, the eye was seen as the 
sense for agency and activity. Believed to send out beams to illuminate objects in view, the 
eye was related to “notions of activity, individualism, aggression, and technical innovation” 
whereas the ear was related to “passivity” (Folkerth 18). However, this exclusive active 
attribution of sight was contested by Richard Brathwaite, who suggested that “the Eare is one 
of the actiuest & laborioust faculties” (12). Besides, “A discreet eare seasons the 
vnderstanding, marshals the rest of the sences wandring, renewes the minde” (9). Part of the 
fascination with the ear and hearing stemmed from a clear connection between the ear and the 
tongue, emphasised by the fact that one could hear oneself speak in a way that one could not 
see oneself seeing. Stephen Egerton and Robert Wilkinson similarly privileged the ear as the 
entrance into the deepest reaches of the body. For Wilkinson the ear was the door through 
which the word of God entered the listener. Thus the ear was given prominence as a direct 
conduit to the soul.  
Though the ear that fascinated early modern anatomists like Crooke, it was also thought 
as a perfectly sinister vehicle for murder, and one that substantiated fears about aural attention 
(587). We witness how characters who suffer from sensorial inattention and stands against 
seemingly more naive alternative views in Shakespeare’s works, such as that expressed in 
Othello by Brabantio: “words are words; I never yet did hear / That the bruis’d heart was 
pierced through the ear.” (1.3.216-19). The irony of Brabantio’s lack of insight is that 
Desdemona is indeed won over by Othello’s stories, and the play, which is more frequently 
read through Othello’s desire for “ocular proof,” is full of references to the ear (1.3.377). Of 
particular interest here is the movement from hearing to “the eye and the world within 
speech.” Rupturing any sense of the self-enclosed relay from tongue to ear, Derrida counts 
self-overhearing as an indication of the continuity of speech and world that refuses to be 
closed off as an expression of “self.” It is not that there is not a world elsewhere, it is that it 
refuses to remain safely “over there,” outside the body (in Robson, 1). 
In this way, the eye and the ear become problematic senses in Shakespeare, as there is 
some discord between things seen and heard. Innogen’s first impression of Milford Haven 
involves a contradiction between what she has heard about and what she sees there. The two 
senses are also the source of deceit and manipulation, as when Iago suggests that he will 
“abuse Othello’s ear” (1.3.377) from which Othello’s tragedy arises. Unable to discern the 
truth between what she has seen and what she hears from Hamlet, Ophelia begins to realize 
she has been “the more deceived” (3.1.124). She acknowledges her visual and aural abuse 
from Hamlet:  
 
Like sweet bells jangled out of tune and harsh,  
That unmatch’d form and feature of blown youth  
Blasted with ecstasy. O, woe is me,  
T’have seen what I have seen, see what I see!  
(3.1.156-59) 
 

Looking with Ears, Hearing with Eyes 
 
171
Besides, the eye and the ear can cause confusion, as there is much discrepancy between 
what is seen and heard and what really happens. This confusion between sight and sound is 
clearly expressed by Hero’s answer “Nothing certainer” to Claudio’s question “Another 
Hero?” (5.4.62), posing a big question mark over sensory perception. The same reserve and 
questioning of the two senses appear in Hamlet where two radically opposed epistemologies 
are at crossroads. “On the one hand, thinking happens only through the body and its properly 
functioning perceptions. On the other hand, Shakespeare’s era witnessed an increasingly 
serious skepticism over their viability as mechanisms to secure knowledge” (Marchitello 
139). The Prince is not the only one who sees his father’s ghost in the opening scene of the 
play; but later, in the bedroom scene with his mother, Hamlet is the only one who can see it 
(3.4.105). For him, the ghost’s appearance is something real, while Gertrude only sees Hamlet 
addressing an empty space. What Shakespeare might be querying here is whether something 
can ever be considered real or true if only one person can see it; in other words, he questions 
the limits of vision of truth that requires social confirmation before it can be accepted. 
In many ways, Don Quixote is a novel about how Don Quixote perceives the world and 
about how other characters perceive Don Quixote. His tendency to transform everyday people 
and objects into more dramatic, epic, and fantastic versions of themselves forces those around 
him to choose between adapting to his imaginary world or opposing it. Some, such as the 
barber and the priest, initially try to coax Don Quixote back into a more conventional view of 
the world and away from his unconventional life as a knight-errant. To get Don Quixote to 
communicate, however, they must play along with his world, pretending to believe in his wild 
fantasies. By the end of the novel, these characters achieve a more harmonious relationship 
with Don Quixote’s fantasy world, recognizing its value even if they do not believe it is 
literally true. 
Those who oppose Don Quixote—namely, Sampson Carrasco and the Duke and 
Duchess—find their lives disrupted by Don Quixote’s perceptions of the world. Sampson 
temporarily becomes a knight to seek vengeance on Don Quixote, sacrificing his own 
perceptions of the world because he is obsessed with altering Don Quixote’s world. The Duke 
and Duchess find that the people and events around them actually match Don Quixote’s 
vision much more closely than they expected, as adventures such as Sancho’s governorship 
and the adventure of Doña Rodriguez fit well into Don Quixote’s world and not so well into 
their own.  
Perception and deception are major topics in Cervantes’s interludes, in which the 
capacity to deceive, to be deceived and to deceive oneself becomes a central concern. 
The eight interludes are variations on the binaries of illusion and reality. Language is 
used to deceive as in The Sham Biscayan, whose trickster-protagonist employs a stylized 
Basque dialect, in The Cave of Salamanca through the character of the wife who must 
convince her husband of her love, although she has none, and in The Jealous Old Man in 
which the discovery of truth fools the jealous old man. In The Miracle Show the power of the 
word is not only capable of manipulating the characters on the stage, but also of deceiving the 
public through aural and visual confusion. But if Cervantes sometimes seems to approve 
deceit, it is only to show how human foolishness can justify it. 
But sensorial abuse can have powerful, even dangerous, effects on the human body. 
Romeo, like Demetrius in A Midsummer Night´s Dream, acknowledges the deceptive as well 
as fleeting nature of visual and aural perceptions, which are as insubstantial as dreams and 
“smoke” that vanishes in the air. Romeo and Juliet, there are a number of characters that are 

José Manuel González 
 
172
prone to an excess of emotion. Romeo in particular seems to have an addiction to emotion, as 
his speeches reveal. When Romeo describes his love for Rosaline, for example, he says “Love 
is a smoke made with the fume of sighs, / Being purged, a fire sparkling in lovers’ eyes, / 
Being vexed, a sea nourished with lovers’ tears. / What is it else? A madness most discreet” 
(1.1.187‒191). But love, with its binding, twisting labyrinth of emotions, often has diverse 
effects on those caught in its grasp. It is an overwhelming, overpowering emotion beyond 
reason, producing “most discreet” madness as in the case of Don Quixote: 
 
And in the porches of my ears [he] did pour  
The leperous distilment whose effect  
Holds such an enmity with the blood of man  
That swift as quicksilver it courses through 
The natural gates and alleys of the body 
And with a sudden vigour it doth possess 
And curd like eager droppings into milk  
The thin and wholesome blood.  
(1.5.63-70).  
 
However, not only the text and the reader, but also the writer may be seen as an 
indispensable source of sensorial power/influence. He cannot remain indifferent to what 
happens, particularly in emotional contexts. The writer is somehow involved in what he 
writes about. He plays a central role in the creation of fictional networks. Accordingly, having 
some knowledge of the authorial affective engagement would enable us to know more about 
what is going on in the text, as well as about the characters. Otherwise, we would be missing 
relevant information in the exploration of the senses. The problem lies in the fact that we have 
no direct access to this knowledge; such is the case of Shakespeare’s Sonnets which are 
deeply personal, disclosing the author’s most private sentiments. 
Besides visual and aural activity becomes more complex when the same character 
encompasses and integrates diverse experiences. Radical changes in the same character 
abound in Hamlet and Don Quixote from the beginning. How can we explain those extreme 
behaviours? Why does Don Quixote see a giant in a windmill; or does Macbeth have the 
vision of the dagger? At this point we should consider that every action, however trivial, 
leaves a mark on the characters and becomes a causal link for the rest of their lives. It is 
through apperception that “…new experience is assimilated to and transformed by the 
residuum of past experience of an individual to form a new whole” (Runes). They perceive 
new experience in relation to past experience. It means that what we perceive through the 
eyes and the ears is more than mere sensations, as Don Quixote and Hamlet show. Their 
visual and aural perceptions cannot be separated from their basic experiences and 
commitments. When Don Quixote says in relation to Dulcinea, “I imagine that everything I 
say is precisely as I say it is, and I depict her in my imagination as I wish her to be, both in 
beauty and in rank” (1/25.216), he describes a process through which he can define his own 
reality. Two different meanings can be rendered from the physical and psychological 
connotations of the verb “to see” at this point: to accept as fact everything the eyes see, or to 
believe everything the mind thinks. However, Don Quixote often sees with his eyes 
manifestations he creates in his mind. In the episode of “Mambrino’s helmet” he says to 
Sancho “Tell me! Do you not see that knight coming towards us, upon a dapple-grey steed, 

Looking with Ears, Hearing with Eyes 
 
173
wearing a helmet of gold?” to which Sancho replies “All I can make out...is a bloke on a 
donkey, brown like mine, with something shiny on his head.” (1/21.166). Don Quixote 
believes everything he hears or sees is exactly as he interprets it in his imagination. In many 
ways, Don Quixote is about how Don Quixote sees the world and about how other characters 
see Don Quixote. His tendency to transform everyday people and objects into more dramatic, 
epic, and fantastic versions of themselves forces those around him to choose between 
adapting to his imaginary world or opposing it. 
The ear and the eye also appear as subjects rather than objects. They actively do things. 
They are not merely specialized anatomical faculties for receiving stimuli. In Coriolanus 
appearances and hearing play a central role, as the characters’ actions are motivated by what 
is seen and heard rather than what is thought. Shouting and violence, noise and visual 
manipulation, make it hard to live in the city of Rome, as we learn right at the opening of the 
play when the common people are rioting against the patricians. They make it clear that 
“Caius Martius is chief enemy to the people” (1.1.7). In return, he also despises the mob, 
though he is dependent upon them. His antisocial attitude reflects his fragmentary and 
dichotomous perceptions. Coriolanus’s tragedy lies in his inability to react against what he 
hears and sees. Moreover, family ties make Coriolanus’s perceptions fragile and 
contradictory, such as when his mother pleads with him to give up his real feelings in order to 
get the consulship nomination. He underestimates the power of the senses that finally 
produces a permanent maladjustment, as he is incapable of adapting to the critical situation of 
Rome burning in popular rebellion. But sensations are transitory, shifting and provisional. 
Coriolanus will no longer be a Roman hero but a “traitorous innovator” among the Volscians.  
In Shakespeare and Cervantes, characters use the information gathered through the eyes 
and the ears to achieve particular goals, as well as to change others’ perceptions and situations 
in form and degree for a particular reason, producing an immediate reaction and creating 
conflicts that can cause the transformation of other characters through sensorial processes. 
Besides, the senses are conveyed through interpersonal dynamics that also depend on the 
particular temperament and reaction of the characters, giving them a new insight into those 
events and providing them with a different experience. In the case of “The Tale of 
Inappropriate Curiosity” (1.33), while the priest is reading the story, the characters/listeners 
are observing the performance. At the beginning Anselmo composes a drama in which his 
friend, Lotario, plays the role of seducer so that he can see the reaction of his wife, Camila. 
But when the fiction becomes reality, and Lotario actually does become Camila’s lover, they 
plot a counter-drama, in which Camila will be the protagonist, forcing Anselmo to assume the 
role of spectator. Ultimately, Anselmo becomes the victim of the plot he has devised.  
Observing and perceiving, therefore, are regarded as a dynamic and immersive process of 
exchange between the viewer and the viewed, between the hearer and the sound, and between 
the performer and the beholder. In this way, characters create a network of sensorial 
interaction with other characters, who are somehow forced to respond. Sophie Ratcliffe has 
explored the relationship between sympathy, knowledge and perception underlining the 
function of sympathy as a vehicle for connecting characters. It implies an effective 
involvement of the characters as hearers, viewers and beholders. They generate reactions of 
different sorts in other characters that affect their responses. While waiting for Sancho to 
return, the priest and the barber encounter Cardenio, who tells them his story: 
 

José Manuel González 
 
174
Suspecting Don Fernando’s treachery as little as I did, she told me to try to come back soon, 
because she believed that the accomplishment of our wishes would be delayed by no longer 
than our fathers’ conversation. I don’t know why, but when she finished saying this, her eyes 
filled with tears and a knot seemed to form in her throat, stopping her from speaking any more 
of the very many words that she appeared to want to say to me. I was astonished at this 
strange faltering, because it had never happened before and, whenever good fortune and my 
diligence had allowed us to talk, we’d done so with great joy without any tears, sighs, 
jealousy, suspicion or fear. I would dwell on my good fortune, because heaven had given her 
to me as my lady; I would extol her beauty, marvel at her merit and her understanding. 
(1/27.235) 
 
Cardenio’s account is the only access to Luscinda’s reaction. We then get the full story 
from Cardenio because Don Quixote is not present to interrupt the storytelling. Cardenio, like 
Don Quixote, appears as a grief-stricken character who stumbles through a life of unrequited 
love.  
Witnessing the pain of others through the spectacle of suffering is another form of visual 
and aural interaction. Nowhere in King Lear do the traumatic episodes produce bewilderment 
more clearly in the viewers than in act 4.6. when we see the blind Gloucester being led to 
Dover by the disguised Edgar: 
 
Gloucester. When shall I come to th’ top of that same hill?  
Edgar. You climb up it now: Look how we labour.  
Gloucester. Methinks the ground is even.  
Edgar. Horrible steep  
Hark, do you hear the sea?  
Gloucester. No, truly,  
Edgar. Why, then, your other senses grow imperfect  
By your eyes anguish.  
Gloucester. So it’ may be, indeed: 
Methinks thy voice is altered and thou speak’st  
In better phrase and matter than thou didst.  
Edgar. You’ re much deceived: in nothing am I changed  
But my garments.  
Gloucester. Methinks you’re better spoken.  
(4.5.1-14) 
 
Thus the play makes us acutely aware of the horror of gratuitous violence, and offers no 
consolatory prospect that humans might act differently. It is indeed an inverted and violent 
world. As “senses grow imperfect,” pain, violence and cruelty develop in Shakespeare’s plays 
as a sensational element, where characters not only know how to be violent but also assume 
their right to use violence. Edgar is trying hard to lead Gloucester away from reality, placing 
him in a world of his own perception. Edgar is cruel only to be kind, frustrating Gloucester’s 
suicide. Don Quixote’s violence works in a different manner. It is cruel not to be kind but to 
be comic.  
The characters are also an indispensable source of sensorial power/influence. They 
cannot remain indifferent to what happens, and are somehow involved in what they see and 
hear. They play a central role in the creation of fictional networks, as they have the sense of 

Looking with Ears, Hearing with Eyes 
 
175
being there and of participating in what is going on. Thus Shakespeare and Cervantes also 
bring us up close to the characters to see them, hear them, and witness the subtlest changes. 
Furthermore, our perceptions are channelled to us by way of the consciousness of characters 
who themselves are witnesses of the action. This suggests that characters assume the tasks 
that we would otherwise assume more directly, and our perceptions depend on their hearing, 
seeing, and feeling. Don Quixote —from about Chapter 15 until nearly the end of Part I— 
continually directs our attention to those who respond emotionally to something or someone 
else. Our only access to events is often by way of witnesses’ responses: 
 
A little before dawn the ladies heard a voice which was so fine and  
tuneful that they all had to listen, particularly Dorotea, who was already  
awake and by whose side Doña Clara de Viedma, the judge’s daughter,  
was fast asleep. None of them could imagine who it was singing so well,  
and unaccompanied. Sometimes the voice seemed to be coming from the  
courtyard, at other times from the stables; and as they lay there  
listening in bewilderment Cardenio came to their door and said:  
—If any of you are awake, do listen and you’ll hear a young footman singing.  
It’s the most gorgeous sound: enchanting chanting, one might say. 
—We’re already trying to listen, sir, Dorotea replied.  
So Cardenio crept away, and Dorotea, listening as hard as she could,  
heard that what was being sung was the following... 
(1/43.401)  
 
Our only connection to that voice is by way of those characters who hear it and react to it 
in awe, thus giving form and colour to our own expectations. Much the same interaction 
occurs in other cases, as when the Pérez de Viedma brothers, the captive and the judge or 
oidor meet up in 1/42. A very excited Ruy Pérez confirms that the newcomer to the inn is his 
brother, but he is assailed by doubts about whether this brother will receive him well. Hence 
the priest’s intervention to clarify it, and while the priest puts the oidor to the test, we feel the 
intensity of the emotions of the captive, who is watching and listening to every sound, while 
the attentive oidor is overwhelmed by what he hears. He “was all ears – never had he heard 
any case as attentively as he did this one” (1/42.398).  
In Twelfth Night the reunion of the twins is the inevitable climax of the play; before this 
moment, Sebastian has had no idea that Viola could still be alive, so he manifests his disbelief 
at hearing and seeing her again, dressed to look like him:  
 
Ant. How have you made division of yourself?  
An apple cleft in two, is not more twin  
Than these two creatures. Which is Sebastian?  
Oli. Most wonderful! 
Seb. Do I stand there? I never had a brother;  
Nor can there be that deity in my nature,  
Of here and everywhere. I had a sister,  
Whom the blind waves and surges have devoured.  
Of charity, what kin are you to me?  
What countryman? what name? what parentage?  

José Manuel González 
 
176
Vio. Of Messaline: Sebastian was my father;  
Such a Sebastian was my brother too,  
So went he suited to his watery tomb.  
If spirits can assume both form and suit  
You come to fright us.  
Seb. A spirit I am indeed,  
But am in that dimension grossly clad 
Which from the womb I did participate.  
Were you a woman, as the rest goes even,  
I should my tears let fall upon your cheek,  
And say ‘Thrice-welcome, drownèd Viola!’  
(5.1.207-227) 
 
Viola is calmer, since her encounter with Antonio led her to think that Sebastian was still 
alive and well; yet, there is great emotion on both sides at this lucky reunion. But Sebastian 
and Viola need to see and hear each other to believe it. Visual and aural perception is the 
ultimate reason for their mutual recognition. At last, the theme of mistaken or hidden identity 
is resolved, with everyone having been revealed as their true selves. 
Cervantes and Shakespeare show the variety and complexity of sight and hearing, with an 
emphasis on its bodily material aspects, so as to involve the reader/spectator in the event. 
What matters is not only what happens in the text, but also how it is visually and aurally 
perceived and how it affects other characters. It is not only the act of hearing or seeing the 
event that is relevant, but also the representation of the emotional and sensorial framework 
created by the characters. In this way, they anticipate modern ways of experiencing and 
representing perception and the senses. They show us how we can discover a world of new 
experiences and sensations of which “The eye of man hath not heard, the ear of man hath not 
seen…” (MND 4.1.201-202). 
 
 
REFERENCES 
 
Aristotle (1936). De Sensu (On Sense and Sensible Objects). Aristotle. Trans. W. S. Hett, vol. 
8, Loeb Classical Library. Cambridge, MA: Harvard UP.  
Brathwaite, Richard (1620). Essaies Upon the Five Senses. London. 
Burton, Robert (2001). The Anatomy of Melancholy, New York: New York Review Books. 
Bulwer, John (1974). Chirologia: or the Natural Language of the Hand and Chironomia: or 
the Art of Manual Rhetoric. James W. Cleary (ed), Carbondale: Southern Illinois UP. 
Cascardi, Anthony (ed.) (2002). The Cambridge Companion to Cervantes. Cambridge UP. 
Cervantes, Miguel de (2000). Don Quixote. Trans. by John Rutherford. New York: Penguin 
Books. 
Crooke, Helkiah (1615). Microcosmographia. London.  
Davies, John (1599). Sir John (1599). Nosce Teipsum. London. 
Dugan Holly (2009). “Shakespeare and the Senses.” Literature Compass 6/3. 726–740. 
Folkerth, W. (2002). The Sound of Shakespeare. New York: Routledge. 

Looking with Ears, Hearing with Eyes 
 
177
Gallagher, Lowell and Shankar Raman (eds.) (2010). Knowing Shakespeare. Senses, 
Embodiment and Cognition. Houndmills: Macmillan. 
Gilbert, Miriam (2007). “Hearing with Eyes: Watching Shakespeare.” Shakespeare Bulletin. 
25/4. 35-45. 
González Echevarría, Roberto (2005). “Don Quixote. Crossed Eyes and Vision.” Cervantes’ 
Don Quixote, Roberto González Echevarría (ed.). Oxford University Press. 
Marchitello, Howard (2010). “Artifactual Knowledge in Hamlet.” Knowing Shakespeare. 
Senses, Embodiment and Cognition. Lowell Gallagher and Shankar Raman (eds.). 
Houndmills: Palgrave Macmillan. 137-154. 
Ratcliffe, Sophie (2008). On Sympathy. Oxford: Oxford UP. 
Robson, Mark (2001). “Looking with ears, hearing with eyes: Shakespeare and the ear of the 
early modern.” Early Modern Literary Studies 7.1 (May): 1-23. 
Runes, Dagobert D. (ed.) (1972). Dictionary of Philosophy, Totowa: Littlefield, Adams, and 
Company. 
Schoenfeldt, Michael C. (1999). Bodies and Selves in Early Modern England. Cambridge UP. 
Shakespeare, William (2007). William Shakespeare. The Complete Works. Jonathan Bate and 
Eric Rasmussen (eds.). Houndmills: Macmillan. 
Vance, Eugene (2008). “Seeing God: Augustine, Sensation, and the Mind Eye,” Rethinking 
the Medieval Senses. Stephen G. Nichols and Others (eds.). The John Hopkins UP, 2008. 
Wilkinson, Robert (1605). A Iewell for the Eare. London. 
Wright, Thomas (1604). The Passions of the Mind in Generall. London. 
 
 
ABOUT THE AUTHOR 
 
José Manuel González is Professor of English Literature at the University of Alicante. He 
is the author of a number of books and articles on various aspects of early modern poetry and 
drama in England and Spain. He has been Visiting Professor at the universities of Delaware, 
South Carolina, Groningen, Bangor, Lodz and King´s College London. He is a member of the 
International Committee of Correspondents of the World Shakespeare Bibliography, and of 
the editorial board of Revista Alicantina de Estudios Ingleses, and Shakespeare until 2011. He 
is the editor of Shakespeare and Spain (Mellen, 2002), Spanish Studies in Shakespeare and 
His Contemporaries (Delaware, 2006), Shakespeare, and Cervantes and Rabelais. New 
Interpretations and Comparative Studies (Mellen, 2011). His contributions have appeared in 
Women Making Shakespeare (Bloomsbury, 2013), Neophilogus (2015) and Shakespeare and 
the Visual Arts (Routledge, 2017). He has edited the last issue of Multicultural Shakespeare, 
entitled “Shakespeare, National Origins, and Originality.” His latest book Cervantes y 
Shakespeare. Una aproximación comparativa has been published by Síntesis in 2016. 
 
 


In: Encyclopedia of Audiology and Hearing Research 
ISBN: 978-1-53617-702-2 
Editors: Erno Larivaara and Senja Korhola 
© 2020 Nova Science Publishers, Inc. 
 
 
 
 
 
 
 
Chapter 12 
 
 
 
UNIVERSAL NEWBORN HEARING SCREENING IN  
THE UNITED STATES 
 
 
Shibani Kanungo1,, MD and Dilip R. Patel2, MD 
1Metabolic Genetics and Newborn Screening, Geisinger Health System,  
Danville, Pennsylvania, US 
2Department of Pediatric and Adolescent Medicine,  
Western Michigan University Homer Stryker MD School of Medicine,  
Kalamazoo, Michigan, US 
 
 
ABSTRACT 
 
Hearing impairment or loss can be defined by the partial or total inability to hear 
sounds experienced in the environment, represent a wide spectrum of disease due to 
congenital or acquired causes and seen with various developmental disorders requiring 
early intervention services for optimal health outcomes. Early detection to decrease 
morbidity and prevent life-long disability was the principle of newborn screening adapted 
to Universal Newborn Hearing Screening. We explore how Universal Newborn 
Screening evolved, from history to epidemiology, from policy to shaping of a public 
health program and from cost benefits of current universal screening to possible next 
steps in decreasing morbidity and preventing lifelong disability nationally and 
internationally. 
 
Keywords: newborn hearing screening, hearing loss, public health 
 
 
INTRODUCTION 
 
Hearing impairment or loss is the partial or total inability to hear sounds experienced in 
the environment. According to the World Health Organization (WHO), there are 
approximately 360 million people worldwide with hearing impairment (1). Hearing 
                                                        
 Corresponding Author’s Email: skanungo@geisinger.edu. 

Shibani Kanungo and Dilip R Patel 
 
180
impairment is a diagnosis encompassing a wide spectrum of presentations and disease 
processes, a vital impact on human development, a major public health concern, a 
battleground for cultural identity and the conception of health, and a research field rich with 
ongoing questions. Hearing loss can be further differentiated into conductive and 
sensorineural hearing loss (SNHL) and can be unilateral or bilateral or differentiated by 
different risk factors (2). Auditory anatomical and physiological shaping begins early in 
embryologic development and is refined throughout early childhood, which has important 
implications for possible congenital and acquired hearing impairment resulting from toxic 
exposures to underlying genetic defects. The epidemiology of newborn hearing loss along 
with the ease of available technology was instrumental in the development of “Universal 
newborn hearing screening” (UNHS) programs in the US and worldwide. Discussion about 
UNHS in the United States is incomplete without understanding the history and evolution as a 
public health program with active participation of all stake holders–parents, specialists, 
professional societies and the government. 
 
 
EPIDEMIOLOGY 
 
Best evidence on national prevalence of newborn hearing loss is noted in the MMWR 
2010 report (3) with CDC (Center for Disease Control and Prevention analysis of EHDI 
(Early hearing detection and intervention) surveillance data in United States from 1999-2007; 
geared to determine the status of efforts to identify newborns and infants with hearing loss. 
Though, data until 2005 was passively reported to CDC, 2005-2007 CDC-EHDI active data 
collection did not demonstrate a huge difference between prevalence of newborn hearing loss 
– 1.1 versus 1.2 per 1,000 screened; even though the percentage of infants screened increased 
from 46.5% in 1999 to 97% in 2007 and the number of States reporting increased from nine 
States and territories to 44 States and territories. In January 2000, Statement of the American 
College of Medical Genetics on Universal Newborn Hearing Screening noted that hearing 
loss is present at birth in 1-2 per 1,000 infants (4). The CDC-EHDI prevalence data in the US 
is similar to public and private institution reports in different European countries/regions, but 
there seems to be reports of higher prevalence of newborn hearing loss reported from 
developing countries as noted in Table 1. 
 
Table 1. Prevalence of hearing loss 
 
Country 
Prevalence 
Author  
Published 
year 
Pubmed 
reference 
United Kingdom  
1.8 per 1000 
Watkin et al. (5) 
2012 
22686437 
Switzerland 
1.2 per 1000  
Metzger-Müller et al. (6)  
2013 
24338080 
Ireland  
1.3 per 1,000  
O’connor etal (7)  
2013 
23456183 
Israel 
1.3 per 1,000  
Gilbey et al. (8)  
2013 
23122541 
Belgium  
1.5 per 1000  
Van Kerschaver et al. (9)  
2013 
22452806 
Turkey 
2.2 per 1000  
Tasci et al. (10)  
2010 
20015280 
Brazil 
0.96 per 1000 
Bevilacqua et al. (11)  
2010 
20303604 
Brazil 
2 per 1000  
Oliviera et al. (12)  
2013 
24142311 
UAE 
2.6 per 1000  
Ur Rehman et al. (13)  
2012 
23301401 
India 
8 per 1000  
Rai et al. (14)  
2013 
23642585 

Universal Newborn Hearing Screening in the United States 
 
181
THE HISTORY OF UNIVERSAL NEWBORN HEARING SCREENS (UNHS) 
IN THE UNITED STATES 
 
The history of Newborn Screening for any disorder is incomplete without mentioning Dr. 
Robert Guthrie’s (1916-1995) work establishing PKU (phenylketon-uria) screening in 1960s 
as a public health program initiative in the State of Massachusetts. Though, around the same 
time as initial PKU screening, a varied range of efforts by different disciplines towards early 
detection, diagnosis and intervention for hearing loss were in the works Downs et al. (15, 16) 
and, initial hospital based screening for hearing loss took place as early as 1970s. By the late 
1980s, Dr. C. Everett Koop (1916-2013), then US Surgeon General, pioneered that detection 
of hearing loss to be included in the Healthy People 2000 goals for the nation (17). 
In 1988, the Maternal and Child Health Bureau (MCHB), a division of the US Health 
Resources and Services Administration (HRSA), funded pilot projects in Rhode Island, Utah, 
and Hawaii to test the feasibility of a universal statewide screening program to screen 
newborn infants for hearing loss before hospital discharge (18). Wide spread practice of 
hospital based screening did not occur until after the 1993 NIH Consensus Development 
Conference on Early Identification of Hearing Impairment in Infants and Young Children that 
recommended that all newborn infants be screened for hearing shortly after birth (19). 
O March 18, 1999, Congressman James Walsh (R, NY) introduced the Newborn Infant 
and Hearing Screening and Intervention Act of 1999 (20). In May, 1999, Senator Olympia 
Snowe (R, ME) introduced the companion bill in the Senate. At the end of the legislative 
session, federal appropriations committees in both the House and Senate earmarked new 
funding for newborn hearing screening. The language was included in the Omnibus 
Appropriations bill President Clinton signed in November, 1999. This landmark federal 
legislation ‘Newborn and Infant Hearing Screening Intervention Act of 1999’ enacted by the 
federal government provided funding to states from the Health Resources and Services 
Administration and the Centers for Disease Control and Prevention to support the 
infrastructure required for planning, development, implementation, and refinement of early 
hearing detection and intervention (EHDI) programs and for EHDI tracking and data 
management systems. Universal Newborn Hearing Screening as an essential component of 
early detection and intervention for infants with hearing loss was adopted after support from 
multiple professional societies, advocacy groups, and government agencies participating in 
the Joint Committee on Infant Hearing (JCIH) (21, 22). 
In 2007, the Joint Committee on Infant Hearing (JCIH) endorsed early detection of and 
intervention for infants with hearing loss through integrated, interdisciplinary community, 
state, and federal systems of universal newborn hearing screening, evaluation, and family-
centered intervention (23). The goal of EHDI was determined to maximize linguistic and 
communicative competence and literacy development for children who are deaf or hard of 
hearing. The updated 2007 JCIH position statement delineated specifics addressing:  
 
 
Definition of targeted hearing loss;  
 
Hearing-screening and -rescreening protocols - separate protocols recommended for 
NICU and well-infant nurseries;  
 
Diagnostic audiology evaluation by Audi-ologists with skills and expertise in 
evaluating newborn and young infants and including ABR testing;  

Shibani Kanungo and Dilip R Patel 
 
182
 
Medical evaluation including genetics and otolaryngology consultation for every 
confirmed hearing loss;  
 
Early intervention service establishment;  
 
Surveillance and screening in the medical home;  
 
Communication between the birth hospital, State and parents;  
 
Information infrastructure for data manage-ment and outcome tracking.  
 
The national resource for EHDI at the National Center for Hearing Assessment and 
Management (NCHAM) provides timeline, summary and details of each State specific 
mandates and enacted Newborn Hearing Screen legislation (24).  
After 10 years of being introduced as a legislation, in December 2010, the United States 
Senate and the House of Representatives each voted to approve the Early Hearing Detection 
and Intervention Act of 2010 (HR. 1246, S. 3199). President Obama signed the legislation 
into law on December 22nd 2010 (25, 26).  
The Early Hearing Detection and Intervention Act of 2010 amends the Public Health 
Service Act to: 1) expand the newborn and infant hearing loss program to include diagnostic 
services among the services provided and 2) require the Secretary of Health and Human 
Services (HHS), acting through the Administrator of the Health Resources and Services 
Administration, to assist in the recruitment, retention, education, and training of qualified 
personnel and health care providers to implement the program. 
It revised program purposes to include: 1) developing and monitoring the efficacy of 
statewide programs and systems for hearing screening of newborns and infants, prompt 
evaluation and diagnosis of children referred from screening programs, and appropriate 
education, audiological, and medical interventions for children identified with hearing loss; 2) 
developing efficient models to ensure that newborns and infants who are identified with a 
hearing loss through screening receive follow-up by a qualified healthcare provider and 3) 
ensuring an adequate supply of qualified personnel to meet the screening, evaluation, and 
early intervention needs of children.  
It amended the definition of “early intervention” to require that families be given the 
opportunity to obtain the full range of appropriate early intervention services, educational and 
program placements, and other options for their child from highly qualified providers. 
It requires the Secretary to establish a postdoctoral fellowship program to foster research 
and development in the area of early hearing detection and intervention. 
The 2013 supplement to the recommendations in the year 2007 position statement of the 
Joint Committee on Infant Hearing (JCIH) provides comprehensive best practices guidelines 
for early hearing detection and intervention (EHDI) programs on establishing strong early 
intervention (EI) systems with appropriate expertise to meet the needs of children who are 
deaf or hard of hearing (D/HH) (27).  
 
 
COST BENEFIT 
 
The varying disease burden in different parts of the world as noted under ‘Epidemiology 
of newborn hearing loss’, along with more recent data suggesting need of targeted 
surveillance in at-risk children who pass the hearing screen (5, 28) or school entry hearing 

Universal Newborn Hearing Screening in the United States 
 
183
screening as in the United Kingdom (29) requires us to take into consideration of cost benefit 
of universal hearing screen and its implementation as a public health program across the 
world. We know that implementation of any public health program includes a cost- benefit 
analysis of a proposed project – a process by which the costs of a program to proposed 
benefits to the individual and society is taken into consideration. Often such calculations are 
based on available literature as evidence or conducted prospectively taking outcome measures 
into consideration. 
There is a paucity of comprehensive long term data in form of randomized control trials, 
or observational parallel cohorts or epidemiological evidence that takes into consideration at 
all probable variables and outcomes. In general, cost of universal newborn hearing screening 
(UNHS) include capital (cost of equipment) and operating expenses (costs for disposables and 
personnel), as well expenses for follow-up (diagnostic testing costs) and early intervention 
programs and services. Taking into consideration various model assumptions, it was shown 
that even though initially, the costs of UNHS exceed its benefits; but there are short term and 
long term reaching a maximum annual benefit of seven billion dollars 75 years after initiation 
of the program, which also results in the societal benefit for all years thereafter (30). 
Short term cost benefits analysis projects the benefit of improved language reduced the 
lifetime costs associated with deafness by approximately $430 000 per deaf individual (31). 
Long-term benefits, both individual and societal are yet to be predetermined conclusively and 
understandably difficult to estimate with accuracy. With varying prevalence of newborn 
hearing loss in different parts of the world, the cost-effectiveness of universal newborn 
hearing screening (UNHS) in United Kingdom was compared to selective screening of 
newborns with risk factors in India (32) and demonstrated that the cost-effectiveness of a 
screening intervention was largely dependent upon two key factors: the cost (per patient) of 
the intervention drives the model substantially, with higher costs leading to higher cost-
effectiveness ratios and the baseline prevalence (risk) of hearing impairment. Though, the 
economic limitations of developing countries or regions may warrant implementation of ‘at-
risk’ or targeted newborn hearing loss screening more feasible than UNHS (33, 34). There are 
also suggested values in adding bloodspot-based genetic testing of common mutations as 
second tier testing for bedside newborn hearing screening (35). 
 
 
CONCLUSION 
 
Universal newborn hearing screening helps with early diagnosis and intervention of 
hearing impairment - a complex and multi-faceted public health concern that can have long-
term impacts on health, education, and quality of life outcomes in a child and a future 
generation. There may be a paradigm shift requiring a second phase to UNHS with pre-school 
based screening to improve long term educational and quality of life outcomes. Lifetime costs 
associated with hearing loss per child/disabled adult far outweighs costs of UNHS or early 
childhood screening. 
 
 
 

Shibani Kanungo and Dilip R Patel 
 
184
ACKNOWLEDGMENTS 
 
This paper is an updated and revised version of an earlier publication. 
 
 
REFERENCES 
 
[1] 
World Health Organization. Deafness and hearing loss fact sheet, 2013. URL: 
http://www.who.int/mediacentre/factsheets/fs300/en/. 
[2] 
Chung P, Kanungo S, Patel DR. Hearing impairment, In: Rubin IL, Merrick J, 
Greydanus DE, Patel DR, eds. Rubin and Crocker health care for people with 
intellectual and developmental disabilities across the lifespan, Dordrecht: Springer, 
2015, in press. 
[3] 
Gaffney M, Eichwald J, Grosse SD, Mason CA. Identifying infants with hearing loss, 
United States, 1999-2007. MMWR 2010;59(08):220-3. 
[4] 
American College of Medical Genetics (ACMG). Statement of the American College of 
Medical Genetics on universal newborn hearing screening. Genet Med 2000;2:149-50. 
[5] 
Watkin P, Baldwin M. The longitudinal follow up of a universal neonatal hearing 
screen: the implications for confirming deafness in childhood. Int J Audiol 
2012;51(7):519-28.  
[6] 
Metzger D, Pezier TF, Veraguth D. Evaluation of universal newborn hearing screening 
in Switzerland 2012 and follow-up data for Zurich. Swiss Med Wkly 2013;143:w13905. 
Doi: 10.4414/smw. 2013.13905. 
[7] 
O'Connor A, O'Sullivan PG, Behan L, Norman G, Murphy B. Initial results from the 
newborn hearing screening programme in Ireland. Ir J Med Sci 2013; 182(4):551-6.  
[8] 
Gilbey P, Kraus C, Ghanayim R, Sharabi-Nov A, Bretler S. Universal newborn hearing 
screening in Zefat, Israel: the first two years. Int J Pediatr Otorhinolaryngol 
2013;77(1):97-100.  
[9] 
Van Kerschaver E, Boudewyns AN, Declau F, Van de Heyning PH, Wuyts FL. Socio-
demographic determinants of hearing impairment studied in 103,835 term babies. Eur J 
Public Health 2013; 23(1):55-60.  
[10] Tasci Y, Muderris II, Erkaya S, Altinbas S, Yucel H, Haberal A. Newborn hearing 
screening programme outcomes in a research hospital from Turkey. Child Care Health 
Dev 2010;36(3):317-22.  
[11] Bevilacqua MC, Alvarenga Kde F, Costa OA, Moret al.. The universal newborn hearing 
screening in Brazil: from identification to intervention. Int J Pediatr Otorhinolaryngol 
2010;74(5):510-5.  
[12] Oliveira JS, Rodrigues LB, Aur?lio FS, Silva VB. Risk factors and prevalence of 
newborn hearing loss in a private health care system of Porto Velho, Northern Brazil. 
Rev Paul Pediatr 2013;31(3):299-305.  
[13] Ur Rehman M, Mando K, Rahmani A, Imran A, Ur Rehman N, Gowda K, Chedid F. 
Screening for neonatal hearing loss in the Eastern region of United Arab Emirates. East 
Mediterr Health J 2012; 18(12):1254-6.  
[14] Rai N, Thakur N. Universal screening of newborns to detect hearing impairment—Is it 
necessary? Int J Pediatr Otorhinolaryngol 2013; 77(6):1036-41.  

Universal Newborn Hearing Screening in the United States 
 
185
[15] Downs MP, Sterritt GM. Identification audiometry for neonates: a preliminary report. J 
Audiol Res 1964;4:69–80. 
[16] Downs MP, Sterritt GM. A guide to newborn and infant hearing screening programs. 
Arch Otolaryngol 1967; 85(1):15-22. 
[17] US Department of Health and Human Services, Office of Disease Prevention and 
Health Promotion. Healthy People 2000: National Health Promotion and Disease 
Prevention Objectives. Washington, DC: US Government Printing Office, 1991. 
[18] Forsman 
I. 
Universal 
newborn 
hearing 
screening, 
2006. 
URL: 
http://www.infanthearing.org/ ncham/presentation s/2006amchpmeetig.pdf  
[19] NIH Consensus Statement. Early identification of hearing impairment in infants and 
young children. NIH Consensus Statement 1993;11:1–24. 
[20] H.R.1193 (106th). URL: https://www.govtrack.us/con gress/bills/106/hr1193. 
[21] Joint Committee on Infant Hearing; American Academy of Audiology, American 
Academy of Pediatrics, American Speech-Language-Hearing Association, Directors of 
Speech and Hearing Programs in State Health and Welfare Agencies. Year 2000 
position statement: principles and guidelines for early hearing detection and 
intervention programs. Pediatrics 2000; 106:798–817. 
[22] American Academy of Pediatrics, Joint Committee on Infant Hearing. Year 2007 
position statement: principles and guidelines for early hearing detection and 
intervention programs. Pediatrics 2007;120(4):898–921. 
[23] Joint Committee on Infant Hearing. Supplement to the JCIH 2007 position statement: 
Principles and guidelines for early intervention after confirmation that a child is deaf or 
hard of hearing. Pediatrics 2013;131(4):e1324-49. 
[24] National Center for Hearing Assessment and Management (NCHAM), Utah State 
University. URL: http://www.infanthearing.org/legislative/mandates.html. 
[25] Govtrack.us. Early Hearing Detection and Intervention Act, 2010. URL: https://www. 
govtrack.us/congress/bills/111/s3199. 
[26] Committee on Energy and Commerce. The Early Hearing Detection and Intervention 
Act, 2010. URL: http://democrats.energycommerce.house.gov/index.php?q=bill/s-3199-
the-early-hearing-detection-and-intervention-act-of-2010. 
[27] American Academy of Pediatrics. Statement of endorsement. Supplement to the JCIH 
2007 Position Statement: Principles and guidelines for early intervention after 
confirmation that a child is deaf or hard of hearing. Pediatrics 2013 Mar 25. Doi: 
10.1542/peds.2013-0008. 
[28] Wood SA, Davis AC, Sutton GJ. Effectiveness of targeted surveillance to identify 
moderate to profound permanent childhood hearing impairment in babies with risk 
factors who pass newborn screening. Int J Audiol 2013;52(6):394-9.  
[29] Bristow K1, Fortnum H, Fonseca S, Bamford J. United Kingdom school-entry hearing 
screening: current practice; Arch Dis Child 2008;93(3):232-5.  
[30] Gorga MP, Neely ST. Cost-effectiveness and test-performance factors in relation to 
universal newborn hearing screening. Ment Retard Dev Disabil Res Rev 2003;9(2):103-
8.  
[31] Keren R, Helfand M, Homer C, McPhillips H, Lieu TA. Projected cost-effectiveness of 
statewide universal newborn hearing screening. Pediatrics 2002;110 (5): 855-64. 

Shibani Kanungo and Dilip R Patel 
 
186
[32] Burke MJ, Shenton RC, Taylor MJ. The economics of screening infants at risk of 
hearing impairment: an international analysis. José Manuel González 2012;76(2):212-
8.  
[33] Huang LH, Zhang L, Tobe RY, Qi FH, Sun L, Teng Y, et al.. Cost-effectiveness 
analysis of neonatal hearing screening program in China: should universal screening be 
prioritized? BMC Health Serv Res 2012;12:97.  
[34] Rai N, Thakur N. Universal screening of newborns to detect hearing impairment—Is it 
necessary? Int J Pediatr Otorhinolaryngol 2013;77(6):1036-41. 
[35] Schimmenti LA, Warman B, Schleiss MR, Daly KA, Ross JA, McCann M, Jurek AM, 
Berry SA. Evaluation of newborn screening bloodspot-based genetic testing as second 
tier screen for bedside newborn hearing screening. Genet Med 2011;13(12):1006-10. 
 
 

In: Encyclopedia of Audiology and Hearing Research 
ISBN: 978-1-53617-702-2 
Editors: Erno Larivaara and Senja Korhola 
© 2020 Nova Science Publishers, Inc. 
 
 
 
 
 
 
 
Chapter 13 
 
 
 
HEARING LOSS IN NEONATAL INTENSIVE CARE 
UNITS (NICUS): FOLLOW-UP SURVEILLANCE 
 
 
Federico Sireci1, Sergio Ferrara1, Rosalia Gargano1, Marianna 
Mucia1, Fulvio Plescia2, Serena Rizzo1, Pietro Salvago1  
and Francesco Martines1,3, 
1Bio. Ne. C. Department University of Palermo Palermo, Italy 
2Department of Sciences for Health Promotion  
and Mother and Child Care “Giuseppe D’Alessandro”  
University of Palermo, Palermo, Italy 
3Istituto Euro-Mediterraneo della Scienza e Tecnologia (I.E.ME.S.T.) 
Palermo, Italy 
 
 
ABSTRACT 
 
Infants admitted to the neonatal intensive care unit (NICU), who represent the 4-8% 
of all births, present problems such as prematurity, low Apgar scores, infections, 
hyperbilirubinemia and hearing impairment. In particular significant hearing loss is the 
most common disorder at birth, occurring in 1 to 2 newborns per 1000 in the general 
population and 24% to 46% of newborns who are admitted to a NICU. This leads more 
difficulty to develope verbal skills (learning vocabulary, grammar, word order and 
idiomatic expressions), language, learning and speech. Hearing impairment influences 
also cognitive and affective development of infants making consequences in their 
interpersonal relationships. Joint Committee on Infants Hearing (JCIH) identified many 
risk factors in NICU infants like as prolonged mechanical ventilation, asphyxia, low birth 
weight and ototoxic medication and therefore the first step for early diagnosis of hearing 
loss is identify these factors. Second step is to plan a correct screening strategy. 
Screening procedures to detect hearing impairment may be divided into two categories: 
behavioral and electrophysiological. Behavioral techniques produce a high number of 
false-negative results due to the relative subjectivity of the assessment and difficulty in 
detecting mild or unilateral hearing loss. Electrophysiological procedures have greater 
                                                        
 Corresponding Author’s Email: francesco.martines@unipa.it. 

Federico Sireci, Sergio Ferrara, Rosalia Gargano et al. 
 
188 
sensitivity and specificity and include measuring the following: auditory brainstem 
responses (ABR), automated auditory brainstem responses (AABR), and evoked 
otoacoustic emissions (EOAE). In this chapter will analyze the prevalence of the risk 
factors in NICU infants most often associated with hearing loss and the screening 
methods to arrive as soon as possible an early diagnosis. 
 
 
INTRODUCTION 
 
The prevalence of hearing impairment among infants varies between 0.5 and 3.0 cases 
per thousand, but in children hospitalized in neonatal intensive care unit (NICU) the 
prevalence is 10-20 times greater [1, 2, 3]. The international guides claim that an important 
factor for the risk of hearing loss is the hospitalization in NICU for more than five days, in 
fact, in these cases it is recommended the audiological screening with A-TEOAE and A-ABR 
followed by a close follow-up. 
The hospitalization in NICU contains a number of risk factors for the development of 
hearing loss, such as prematurity, low birth weight, the use of ototoxic drugs, hypoxic 
ischemic insult, hyperbilirubinemia requiring exanguino-transfusion. In most cases, the 
hearing loss is associated to the coexistence of more than one of the above conditions, as 
these are often related to one another [4]. 
Following, an analysis of the most important risk factors in the newborn NICU will be 
performed with particular attention to follow-up surveillance. 
 
 
CYTOMEGALOVIRUS 
 
Congenital CMV infection is transmitted to the fetus through the placenta with a 
transmission rate of about 32% in the case of primary maternal infection and about 1.4% in 
the case of reactivation or reinfection CMV seropositive. CMV infections can therefore 
represent the hidden etiology of many cases considered of unknown origin and is probably the 
most frequent cause of non-genetic hearing loss, as well as the most frequent cause of 
congenital defect and disability in children [5]. 
CMV infection is one of the most frequent causes of neonatal SNHL, in fact 25% of 
hearing losses arising before the fourth year [6, 7]; it can be associated with microcephaly, 
visual impairments, motor and cognitive disabilities, cerebral palsy and seizures 
(symptomatic form). 33-50% of cases of SNHL related to congenital CMV infection are 
delayed-onset and occur early in life, usually after 11 months in asymptomatic respect to 
symptomatic. The hearing deficiency occurs frequently progressive and fluctuating, involving 
some frequency, unilateral or bilateral [8]. Foulon et al. showed, in 68 children with 
congenital cytomegalic infection and subjected to three audiological evaluations in the first 18 
months of life, a tardive SNHL in 4.3% cases, unstable in 29,8% and fluctuating in 16.2%. In 
the cases of hearing impairment, it was observed a worsening of the hearing threshold in 
27.3% of patients and an improvement in 40.9% [9]. Given the heterogeneity of the clinical 
picture and the risk of late-onset or progression of hearing loss, it is recommended careful 
monitoring by means of audiological evaluations performed at 6 month intervals until the 
fifth year of life and a closer follow-up every three months until the child begins to speak. 

Hearing Loss in Neonatal Intensive Care Units (NICUs) 
 
189
BACTERIAL MENINGITIS 
 
Among the postnatal bacterial meningitis, 5-35% of patients can present a damage of the 
cochlear neuroepithelium in with a profound bilateral sensorineural hearing loss. Kutz et al. 
analyzing data from a cohort of 134 children (mean age of 3.4 years) and between these, 
30.6% of bacterial meningitis were identified. Some of these patients with a sensorineural 
hearing loss, above all in cases with unilateral involvement and mild grade, showed to a few 
months from infection the tendency to regression [10]. Adachi et al. and Ballacchino et al. 
carried out a diagnosis of SNHL in 24% of the bacterial meningitis, showing a profound 
degree of hearing loss in about half of the subjects and a greater risk of audiology in case of 
pneumococcal etiology [11, 12]. 
 
 
HEAD INJURY 
 
Head injury, associated or not with temporal bone fracture, is in 23-64% of cases, a 
potential cause of transmission, sensorineural or mixed hearing loss. Dunklebarger et al. 
found, in 71 children with head trauma history associated with temporal bone fracture, the 
presence of sensorineural hearing loss and transmission respectively in 20% and 24% of 
cases. Evidence of damage to the otic capsule was found a positive predictor of SNHL (p = 
0.025) [13, 14]. Bowman et al. proposed an algorithm to identify children at greater risk of 
hearing impairment after head injury in case of radiological evidence of temporal bone 
fracture, patients under the age of three years, subject with Glasgow Coma Scale (GCS) < 13 
with or without loss of consciousness. For those “low-risk” the authors suggested performing 
audiometric tests only in cases of clinical evidence of hearing loss. However, this algorithm 
has some limitations because it doesn't identify the forms of hearing impairment caused by 
mild head trauma or those forms no identifiable by recording OAEs or not discoverable 
subjectively by the infant [15]. 
 
 
OTOTOXIC DRUGS 
 
In the neonatal period ototoxic drugs, above all some antibiotics and diuretics, are a risk 
factor for SNHL with early and delayed onset. In fact, an audiological follow-up and hearing 
screening must be made by the 24th-30th month of life to the children that these drugs were 
administered. Despite these guidelines, the results of some recently published studies have 
highlighted controversial aspects about the actual risk of hearing loss following 
administration of aminoglycosides and diuretics. Vella-Brincat et al. analyzing the results of 
the 2347 OAEs recorded in newborns admitted to NICU, they showed a higher risk of 
absence of otoacoustic emission in patients treated with vancomycin (p = 0.003), in contrast 
to individuals observed in exposed to gentamicin alone where this risk was even reduced [16, 
17]. Similar findings were reported by de Hoog and Kraft, who have not observed an 
increased risk of hearing loss in newborns to undergo therapy with tobramycin, respectively, 
and diuretics. A special mention deserve those individuals submitted to therapy with 
aminoglycosides because carrier of mitochondrial mutations m.1555A > G. About ototoxic 

Federico Sireci, Sergio Ferrara, Rosalia Gargano et al. 
 
190 
chemotherapy drugs (cisplatin and alkylating agent) used in pediatric oncology, it was 
associated with progressive symmetrical bilateral SNHL initially limited to high frequencies. 
The hearing deficiency can occur even several months after completion of chemotherapy 
cycle, more frequently in subjects during treatment do not show any impairment of hearing 
thresholds. This entails the indication to submit such patients to a hearing assessment before 
chemotherapy and to a regular follow-up [18, 19]. Al-Khatib et al., in a retrospective work 
performed on 31 children with treated with cisplatin, revealed a variable degree of hearing 
loss from mild to severe in 42% of cases; in particular, the long-term follow-up audiological 
(1.5 to 6.6 years) of the 21 individuals studied, showed a worsening of audiometric threshold 
in 33% of cases (7/21) with the need, in 5 subjects, of prostesis [20, 21]. 
 
 
FOLLOW-UP SURVEILLANCE 
 
To date the application of audiological monitoring programs of children with risk factors 
combined with continuous monitoring by family members, pediatrician and teachers are the 
foundation of the follow-up audiological post-screening in child age. In particular, the 
guidelines of JCIH 2007 assert that the timing of follow-up for children with risk factors 
should be structured and individualized in relation to the possibility of a possible progressive 
deafness or a late onset. Children who pass the neonatal screening but have a risk factor 
should be received at least one diagnostic audiologic evaluation between 24-30 months of 
age. Early and more frequent evaluations are recommended for children infected with 
cytomegalovirus (CMV), trauma, postnatal infections associated with sensorineural hearing 
loss, extracorporeal membrane oxygenation (ECMO) chemotherapy, a family history of 
childhood hearing impairment, verbal perception, language development or developmental 
delays. Any child who demonstrates delays in the development of auditory skills and/or 
communication should be submitted to an audiological evaluation to rule out hearing loss, 
although it has passed newborn screening [22]. In the presence of the above mentioned risk 
factors of the child is normally subjected to audiologic visit every six months until the third 
year of life and then annually for the next three years. It is also imperative that the family 
pediatrician, during health assessments, investigate the proper achievement of the main stages 
of auditory development and the acquisition of language. 
It seems appropriate to identify some forms of SNHL insurgents in the postnatal period, 
such as: 1) the auditory deficits in subjects with no past history of audiological risk factors; 2) 
cases in which the family unit is not careful in reporting the risk factors related to the little 
patient and not to do perform audiological visits recommended or is not vigilant to 
anknowledge behavioral abnormalities secondary to a hearing impairment, particularly when 
grade mild; 3) disputes about the actual association of some of the risk factors identified by 
JCIH (2007) and the development of SNHL. 
In 2012 Beswick et al. published the results of a work done to evaluate the effectiveness 
and the limits of a surveillance program post-audiological screening in children with risk 
factors. The study included 261.328 infants undergoing neonatal hearing screening in two 
steps by AABR, of which 7320 subjects were selected results “PASS” bilaterally and have at 
least one risk factor. These individuals were included in a follow-up program of audiology as 
follows: patients with a family history of congenital SNHL were subjected to TEOAEs, 

Hearing Loss in Neonatal Intensive Care Units (NICUs) 
 
191
Tympanometry and Visual Reinforcement Audiometry (VRA) to 6, 12, 18, 24 and 36 months 
life while patients with infection feedback to ABR to 3 months of life and then to 6, 12, 18, 
24 months; patients with other risk factors were revalued using TEOAEs, Tympanometry and 
VRA to 9 or 12 months of life. The main audiological risk factors highlighted in the study 
population were: family history (40.5%), low birth weight (31.6%) and assisted prolonged 
mechanical ventilation (25%). In 56 subjects of 2107 (2.7%), with an average age of 22.7 
months it was diagnosed with postnatal hearing loss, mainly sensorineural (64.3%), bilateral 
(76.8%) and mild (50%). Despite the achievement of an important objective, which the early 
diagnosis of a number of cases of post-natal SNHL, the authors have highlighted some 
limitations arisen from the application of a “audiological monitoring program targeted” 
structured. First and foremost is the high percentage of children, more than 20% of the total, 
who have not attended any of the events planned by the Protocol, in particular those 
belonging to the indigenous population (p < 0.001) and individuals with a single factor risk (p 
< 0.001), indicator of a heterogeneous distribution of audiology services in its territory and 
incorrect or missing information on campaigns [23]. 
Watkin et al., studying the prevalence of SNHL (3.65/1000) in a cohort of 35668 
followed from birth until completion of the first year of primary school, they identified 57 
cases of postnatal SNHL of which 20 to late-onset (0.56/1000) [24]. 
A possible screening system in pre-school children was proposed by Wu et al. who tested 
on 6288 children aged between 3 and 6 years a system called “Smart Hearing Screening”, 
which uses tablet devices to perform an behavioral audiometric test investigating the 1-2-4 
kHz frequencies for pure tones between 20-60 dB HL. Among 463 subjects results “REFER” 
and then sent at tertiary center, 12 cases of SNHL (1.91/1000), demonstrating high specificity 
(92.6%) and a low sensitivity (37.5%). This screening system has some advantages: 
equipment used is cheap respect to audiometers, software processes directly response of 
patients, and is particularly valuable in subjects until four years, because of their greater 
capacity to complete the test independently. 
Conversely, the use of questionnaires as possible audiological screening tool in the 
Primary epoch is still debated, because, although inexpensive, does not have that degree of 
accuracy and efficiency that they can be introduced on a large scale [25]. This is underlined 
by Bu et al. and Muñoz et al. who subjected, respectively, 317 and 4616 children screened in 
two steps by means of questionnaires and subsequent audiometric test, showing a low 
correlation between the results of the first and the presence of a hearing impairment [26, 27]. 
 
 
CONCLUSION 
 
The analysis of recent literature shows the efforts made by research in the identification 
of a follow-up audiological system that can, in association with the newborn hearing 
screening, allowing early diagnosis of SNHL in childhood. However it is clear that some of 
the main characteristics that it should have, such as population “target“, the timing of 
assessments and instrumental investigations still do not find a common consent. It is well 
evident that an audiological monitoring program should cover all children, given the high rate 
of cases found no risk factors among patients with hearing loss results; monitoring should 
also ensure supervision in the early years of life and given the possible following onset of 

Federico Sireci, Sergio Ferrara, Rosalia Gargano et al. 
 
192 
deafness. Finally, the means and resources employed should have a high accuracy in 
identifying suspected cases without selecting an excessive number of false positives reducing 
the cost of audiological centers. 
 
 
REFERENCES 
 
[1] 
Robertson CM, Howarth TM, Bork DL, Dinu IA. Permanent bilateral sensory and 
neural hearing loss of children after neonatal intensive care because of extreme 
prematurity: a thirty-year study. Pediatrics, 2009; 123(5): e797-807. doi: 10.1542/peds. 
2008-2531. 
[2] 
Martines F, Bentivegna D, Ciprì S, Costantino C, Marchese D, Martines E. On the 
threshold of effective well infant nursery hearing screening in Western Sicily. Int. 
Pediatr. Otorhinolaryngol., 2012; 76: 423-427. 
[3] 
Salvago P, Martines E, La Mattina E, Mucia M, Sammarco P, Sireci F et al. 
Distribution and phenotype of GJB2 mutations in 102 Sicilian patients with congenital 
non syndromic sensorineural hearing loss. Int. J. Audiol., 2014; 53(8): 558-563. doi: 
10.1016/ j.bbrc.2008.10.086. 
[4] 
Salvago P, Martines E, Martines F, Prevalence and risk factors for sensorineural 
hearing loss: Western Sicily overview. Eur. Arch. Otorhinolaryngol., 2013; 270: 3049-
3056. doi: 10.1007/ s00405-013-2379-2. 
[5] 
Manicklal S, Emery VC, Lazzarotto T, Boppana SB, Gupta RK. The “silent” global 
burden of congenital cytomegalovirus. Clin. Microbiol. Rev., 2013; 26 (1): 86-102. doi: 
10.1128/ CMR.00062-12. 
[6] 
Morton CC, Nance WE. Newborn hearing screening--a silent revolution. N Engl. J. 
Med., 2006; 354(20):2151–2164. 
[7] 
Martines F, Salvago P, Bentivegna D, Bartolone A, Dispenza F, Martines E. Audiologic 
profile of infants at risk: Experience of a Western Sicily tertiary care centre. Int. J. 
Pediatr. Otorhinolaryngol., 2012; 76: 1285-1291. 
[8] 
Dahle AJ, Fowler KB, Wright JD et al. Longitudinal investigation of hearing disorders 
in children with congenital cytomegalovirus. J. Am. Acad. Audiol., 2000 May; 
11(5):283-90. 
[9] 
Foulon I, Naessens A, Faron G et al. Hearing thresholds in children with a congenital 
CMV infection: a prospective study. Int. J. Pediatr. Otorhinolaryngol., 2012 May; 
76(5):712-7. 
[10] Kutz JW, Simon LM, Chennupati SK et al. Clinical predictors for hearing loss in 
children with bacterial meningitis. Arch. Otolaryngol. Head Neck Surg., 2006 Sep.; 
132(9):941-5. 
[11] Adachi N, Ito K, Sakata H. Risk factors for hearing loss after pediatric meningitis in 
Japan. Ann. Otol. Rhinol. Laryngol., 2010 May; 119(5):294-6. 

Hearing Loss in Neonatal Intensive Care Units (NICUs) 
 
193
[12] Ballacchino A, Mucia M, Cocuzza S, Ferrara S, Salvago P, Sireci F, Martines F. 
Newborn hearing screening in sicily: Lesson learned. Acta Medica Mediterranea, 2014; 
(29)4: 731-734. 
[13] Dunklebarger J, Branstetter B, Lincoln A et al. Pediatric temporal bone fractures: 
current trends and comparison of classification schemes. Laryngoscope, 2014 Mar.; 
124(3):781-4. 
[14] Martines F, Martines E, Mucia M, Sciacca V, Salvago P. Prelingual sensorineural 
hearing loss and infants at risk: Western Sicily report. Int. J. Pediatr. 
Otorhinolaryngol., 2013; 77: 513-518. 
[15] Bowman MK, Mantle B, Accortt N et al. Appropriate hearing screening in the pediatric 
patient with head trauma. Int. J. Pediatr. Otorhinolaryngol., 2011 Apr.; 75(4):468-71. 
[16] Vella-Brincat JW, Begg EJ, Robertshawe BJ et al. Are gentamicin and/or vancomycin 
associated with ototoxicity in the neonate? A retrospective audit. Neonatology, 2011 
Apr.; 100(2): 186-93. 
[17] Cannizzaro E, Cannizzaro C, Plescia F, Martines F, Soleo L, Pira E et al. Exposure to 
ototoxic agents and hearing loss: A review of current knowledge. Hearing Balance 
Commun., 2014; 12(4): 166-175. 
[18] De Hoog M, van Zanten BA, Hop WC et al. Newborn hearing screening: tobramycin 
and vancomycin are not risk factors for hearing loss. J. Pediatr., 2003 Jan.; 142(1):41-
6. 
[19] Kraft CT, Malhotra S, Boerst A et al. Risk indicators for congenital and delayed-onset 
hearing loss. Otol. Neurotol., 2014 Dec.; 35(10):1839-43. 
[20] Al-Khatib T, Cohen N, Carret AS et al. Cisplatinum ototoxicity in children, long-term 
follow up. Int. J. Pediatr. Otorhinolaryngol., 2010 Aug.; 74(8):913-9. 
[21] Plescia F, Cannizzaro E, Brancato A, Di Naro A, Mucia M, Plescia F, Vita C, Salvago 
P, Mulè A, Rizzo S, Sireci F, Cannizzaro C. Acetaldehyde effects in the brain. Acta 
Medica Mediterranea, 2015; 31(4): 813-817. 
[22] Joint Committee on Infant Hearing. Year 2007 Position Statement: Principles and 
Guidelines for Early Hearing Detection and Intervention Programs. Pediatrics, Vol. 120 
No. 4 October 2007: 898-921. 
[23] Beswick R, Driscoll C, Kei J et al. Targeted surveillance for postnatal hearing loss: a 
program evaluation. Int. J. Pediatr. Otorhinolaryngol., 2012 Jul.; 76(7):1046-56. 
[24] Watkin PM, Baldwin M. Identifying deafness in early childhood: requirements after the 
newborn hearing screen. Arch. Dis. Child., 2011 Jan.; 96(1):62-6. 
[25] Wu W, Lü J, Li Y et al. A new hearing screening system for preschool children. Int. J. 
Pediatr. Otorhinolaryngol., 2014 Feb.; 78(2):290-5. 
[26] Bu X, Li X, Driscoll C. The Chinese Hearing Questionnaire for School Children. J. Am. 
Acad. Audiol., 2005 Oct.; 16(9):687-97. 
[27] Muñoz K, Luzuriaga E, Callow-Heusser C et al. Evaluation of a hearing screening 
questionnaire for use with Ecuadorian school-aged children. Int. J. Audiol., 2015 Sep.; 
54(9):587-92. 


In: Encyclopedia of Audiology and Hearing Research 
ISBN: 978-1-53617-702-2 
Editors: Erno Larivaara and Senja Korhola 
© 2020 Nova Science Publishers, Inc. 
 
 
 
 
 
 
 
Chapter 14 
 
 
 
ENDOTHELIAL DYSFUNCTION, MICROVASCULAR 
DISEASE AND SENSORINEURAL HEARING LOSS 
 
 
V. Corazzi, A. Ciorba*, C. Bianchini and C. Aimoni 
ENT & Audiology Department, University Hospital of Ferrara, Italy 
 
 
ABSTRACT 
 
The Stria Vascularis of the inner ear represents a fundamental element to ensure the 
endolymphatic homeostasis and, consequently, the regular function of the auditory-
vestibular system [1]. In particular it allows electrolytes and metabolites exchange, in 
order (i) to preserve the inner ear fluids osmolality, and (ii) to protect the inner ear 
neuroepithelium from toxicity [1]. Reactive oxygen species (ROS) are considered 
responsible of inner ear cells damage and, as a consequence, of sensorineural hearing loss 
(SNHL); they act through (i) a direct cell metabolic damage, but also (ii) causing 
endothelial dysfunction and inducing apoptosis in cochlear neuroepithelial cells [2]. In 
the last decades, many Authors have investigated the role of cochlear microvascular 
disease and endothelial dysfunctions as a possible cause of SNHL. Cardiovascular risk 
factors 
(such 
as 
diabetes 
mellitus, 
hypertension, 
hypercholesterolemia, 
hyperhomocysteinemia et al) have been reported to be associated to an increased risk of 
endothelial dysfunction and microangiopathy in the inner ear. These mechanisms have 
also been proposed to be involved in the pathophysiological process of idiopathic sudden 
sensorineural hearing loss (SSNHL) [3]. 
Aim of this chapter is to review the etiopathogenetic mechanisms of the cochlear 
endothelial dysfunction and of the cochlear microvascular disease and their links to 
sensorineural hearing loss. 
 
Keywords: sensorineural hearing loss, sudden sensorineural hearing loss; reactive oxygen 
species, endothelial dysfunction, microvascluar disease. 
 
 
                                                        
* Corresponding Author’s Email: andrea.ciorba@unife.it. 

V. Corazzi, A. Ciorba, C. Bianchini et al. 
 
196
INTRODUCTION 
 
Endothelial factors play a fundamental role also in the cochlear function. The endothelial 
tissue is responsible of the balance between proaggregant and antiaggregant factors, produces 
vasodilator factors, such as nitric oxide (NO), and can be influenced by the vasoconstrictor 
effect of angiotensin II or endothelin [4]. Furthermore, in the endothelial structure, there is a 
reserve of proinflammatory interleukins, which can be released in case of stimulation by 
vascular, mechanical and metabolic risk factors [5]. Also pericytes and myocytes, 
surrounding endothelial cells, can release vasoactive substances (such as histamine, serotonin, 
prostaglandins) involved in the microvascular autoregulation, also according to the local 
metabolic requirements. Different studies assessed the importance of NO in increasing 
cochlear blood flow and in protecting inner ear in some stressful conditions; in fact, NO 
production seems to be incremented during ischemia, ototoxicity and endolymphatic hydrops 
[6]. 
The cochlea lateral wall and, in particular, the Stria Vascularis (SV), is responsible for 
the endolymph production and for the maintenance of cochlear fluids electrochemical 
balance. This is necessary in order to the generate the endocochlear potential and, as a 
consequence, to the correct auditory function [7]. SV is a complex epithelial structure, made 
of three layers with different cells (marginal, intermediate and basal cells), and provided by a 
terminal capillary bed. It is a vascularized epithelial tissue with a great oxygen requirement, 
due to the high metabolic activity of hair cells. This condition makes the inner ear vulnerable 
to ischemic events [8]. Also, SV is very sensitive to variation of blood viscosity, therefore 
each modification of haematocrit, plasmatic viscosity, cellular and platelet aggregation and 
red cells deformability could have a repercussion on the SV function and, as a consequence, 
on the endolymphatic homeostasis [9]. 
The inner ear vascularization is supplied by the internal auditory artery (also known as 
labyrinthine artery), an anterior inferior cerebellar artery branch [8]. The anterior vestibular, 
the vestibulocochlear and the main cochlear arteries are the terminal branches of labyrinthine 
artery. Thus, the cochlear blood supply is a terminal capillary bed and this makes the cochlea 
very sensitive to vascular accidents, as there are no other collateral vessels [8]. 
Furthermore, SV is a blood-labyrinth barrier, which represents the principal element for 
the protection of inner ear from toxic substances conveyed from blood through cochlear 
vessels [10]. The physiological mechanisms of regulation of intrastrial fluid-blood barrier 
permeability are still not completely known, but para-cellular and transcellular pathways have 
been proposed to be involved in the control of vascular permeability as much as basement 
membrane alteration [7]. 
 
 
SENSORINEURAL HEARING LOSS AND ENDOTHELIAL DYSFUNCTION 
 
Sensorineural hearing loss (SNHL) is a hearing function disorder caused by loss of 
cochlear hair cells and/or neurons of the spiral ganglion and/or of the central auditory 
pathway. Generally, the damage of inner ear cells is irreversible and it is associated to a 
permanent SNHL. There are many factors capable to injury cochlear cells: age, noise, 
ototoxic drugs (such as aminoglycosides, cisplatin and furosemide) or infections [2]. It has 

Endothelial Dysfunction, Microvascular Disease … 
 
197
been stated that also a SV dysfunction could be involved in damaging the cochlea, 
considering its important role of intrastrial fluid-blood barrier, which physiologically protect 
inner ear from blood toxic substances [7]. Since inner ear cells are very sensitive to minimal 
changes of blood flow, an impaired SV microvascular perfusion could impact on hair cells. A 
cochlear microvascular disease could be related to a systemic microangiopathy due to 
traditional cardiovascular risk factors (such as hypertension, hyperlipemia, diabetes mellitus, 
etc.) [11, 12]. 
Diabetes mellitus is a well-known prevalent chronic systemic disease, characterized by an 
incremented blood sugar level. Some of its complications are related to vascular damage 
(macro and micro -angiopathy, such as retinopathy, nephropathy and neuropathy), due to 
endothelial indirect dysfunction or direct cellular damage: advanced glycation end-product 
(AGE) creation, polyol and hexosamine metabolic pathway and protein kinase C activation 
[13]. Diabetes predisposes to precocious and more frequent atherosclerosis compared with 
healthy population [9] in labyrinthine vascularization as well as in other peripheral capillary 
beds [14]. Few studies in literature investigated among the specific role of diabetes in the 
pathophysiology of SNHL. Rust and coworkers assessed that hyperglycemia and glucose 
intolerance genetic-based in type 2 diabetes could be associated to an inner ear alteration due 
to the loss of outer hairy cells [15]. Also Frisina, in 2006, reported diabetes to damage inner 
ear function in older patients affected by presbycusis [16]. 
Presbycusis itself could be related to age-related microvascular disorders [17]. In the 
elderly, the loss of cochlear neuroepithelial cells, but also of spiral ganglion neurons, are 
secondary to alterations of the local blood flow, systematic degeneration of endothelial tissues 
and a reduction of antioxidant factors (such as glutathione) [18]. In human temporal bone 
studies, atrophy of SV, thickened basement membrane and deposits of immunoglobulin and 
laminin in strial vessels have been found in these patients [7]. It is also widely accepted that 
aging is due to accumulated oxidative tissue injuries and to increased ROS production. In 
particular, an incremented production of ROS is reported during hypoxia and it may impact 
mitochondria in the apoptosis process [6]. Also in the aging inner ear, an increased ROS 
concentration and a decrease antioxidant functions are responsible of mitochondrial DNA 
mutations and, as a consequence, of a reduction of the energy production and consequent 
cochlear damage [17, 2, 19]. The oxidative stress theory for the onset of SNHL has been 
described in only few studies, in which Authors demonstrated the correlation between inner 
ear disease and endothelial dysfunction caused by increased production of ROS [20, 21, 22, 
23]. Reactive oxygen species (ROS) can act through (i) a direct cell metabolic damage, but 
also (ii) causing endothelial dysfunction and inducing apoptosis or necrosis in cochlear 
neuroepithelial cells [2]. 
The principal source of ROS in the inner ear could be located in hair cells mitochondria; 
however, also cytoplasmatic enzymes such as NADPH oxidase and xanthine oxidase have 
been reported to be responsible of ROS production. Nevertheless, also high blood 
concentration of ROS may lead to direct cochlear cellular death, because of their direct 
oxidizing effect on cellular lipids, proteins and DNA, as well as due to their negative effect on 
endothelial cells. ROS and, particularly, hydrogen peroxide, may act on endothelial cells and 
activate cellular apoptosis pathways through apoptosis signalling kinase 1 (ASK1) and c-Jun 
N-terminal kinase (JNK) [24]. The subsequent endothelial dysfunction could contribute to the 
pathogenesis and maintenance of vascular diseases and, therefore to cochlear damage. 

V. Corazzi, A. Ciorba, C. Bianchini et al. 
 
198
Oxidative stress represents also the pathogenetic mechanism of noise-induced SNHL: a 
prolonged exposition to noise determines an increased production of ROS and a capillary 
vasoconstriction of the basilar membrane, spiral ligament and SV [7]. Furthermore, it has also 
been reported that an increased vascular permeability, leukocytes aggregation, endothelial 
cells injury and structural and molecular alterations in the blood-labyrinth barrier can be 
present in mouse inner ear, after acoustic trauma. This finding indirectly supports a 
microvascular disease and endothelial dysfunction as pathogenetic mechanism of SNHL [7]. 
Also some autoimmune diseases can determine a progressive SNHL onset and the 
pathogenetic mechanism proposed involves strial vessels as target of autoantibodies (e.g., 
immune-complexes deposition) [25]. 
 
 
SUDDEN SENSORINEURAL HEARING LOSS  
AND ENDOTHELIAL DYSFUNCTION 
 
Sudden sensorineural hearing loss (SSNHL) is an acute hearing disorder involving at 
least 3 consecutive frequencies over a 72-h period [26]. Only in few cases is possible to 
demonstrate an aetiologic agent (7-45%) [27], and the remaining cases are therefore classified 
as idiopathic [28]. 
Many etiopathogenetic hypothesis have been proposed: viral infection [29, 30], immune-
mediated damage [31, 32], injury / rupture of cochlear labyrinthine membranes [33, 34] and 
inner ear vascular disease [35]. The latter has been proposed particularly considering the 
terminal arterial supply of the inner ear [8]. It has been hypothesized that (i) either a micro-
thromboembolism, (ii) either a micro-haemorrhage (iii) either a vascular spasm of the 
labyrinthine artery could be responsible of cochlear damage therefore inducing a SSNHL 
[36]. Furthermore, this theory could be supported by the fact that in systemic conditions 
characterized by microvascular dysfunction (such as atherosclerosis, hypertension, diabetes 
mellitus, polycythemia, bacterial endocarditis…), SSNHL is generally reported to be more 
frequent. In a case-control study, Aimoni and coworkers [37] reported a significant 
correlation between SSNHL and cardiovascular risk factors, such as diabetes (especially if 
insulin-dependent) and hypercholesterolemia, suggesting that these factors are correlated to a 
higher risk to develop a SSNHL. Marcucci et al. [9] found that incremented blood levels of 
homocysteine and plasminogen activator inhibitor-1 (PAI-1) and the presence of 
anticardiolipin antibodies are associated to SSNHL. Hyperhomocysteinemia is considered a 
major cardiovascular risk factor, as well as PAI-1 as the major factor inhibiting fibrinolytic 
system (and then, in an increased concentration, it represents an important pro-thrombotic 
factor), as well as anticardilipin antibodies [9]. With their study, these Authors indirectly 
supported the vascular etiopathogenetic theory of SSNHL. 
Quaranta and coworkers [3] and Haubner and collaborators [38] assessed the role of 
endothelial dysfunction of the cochlear microcirculation in the development of SSNHL, 
showing an increased concentration of circulating VCAM-1 (vascular cell adhesion protein 1) 
in SSNHL patients, as a confirm of a vascular involvement in SSNHL development [39].  
Moreover, according to Merchant’s stress response theory [40]: inflammatory cytokines 
could activate intracellular oxidative pathways of cochlear neuroepithelium, involving 

Endothelial Dysfunction, Microvascular Disease … 
 
199
transcription factors (such as NFk B). This aberrant activation can damage the cochlear 
homeostasis and could be related to the development of a SSNHL. 
Even though the vascular hypothesis for SSNHL could be very plausible, to day, the 
question is still debated [9, 6, 29, 37, 41]; in particular cardiovascular risk factors have also 
been reported to play a controversial role in SSNHL threshold recovery [37, 42]. 
Also an inner ear electrolytic imbalance has been investigated as a possible pathogenetic 
mechanism [43]. A sudden electrolytic disorder of the inner ear could explain either the rapid 
onset of sensorineural hearing loss, either the hearing threshold recovery (partial or complete) 
[44, 45]. According to this theory, an etiologic agent could impact the inner ear 
neuroepithelium function indirectly, acting on metabolic function of the inner ear structure 
involved in the electrolytes transport (cochlear lateral wall) [43, 45, 46]. Therefore, a cochlear 
lateral wall damage could impact the ionic (Na+, K+, Fe2+, Cl-) transport between blood and 
endocochlear fluids and, for this reason, could be associated to a sudden hearing impairment 
[43, 47]. 
Furthermore, it is well known that inner ear is particularly sensitive to pH levels and that 
its reduction could lead to hearing loss [48]; for this reason, an acute damage of the cochlear 
lateral wall, implicated in the cochlear pH maintaining, could be responsible of a SSNHL 
development. 
 
 
CONCLUSION 
 
Disruption of blood-labyrinth barrier, cochlear microvascular disease and endothelial 
dysfunction could be involved in the pathogenesis of SNHL. Oxidative stress theory could 
represent a possible pathogenetic mechanism of cochlear injury, and ROS could act through 
(i) a direct hair cells metabolic damage and (ii) also causing endothelial disorder, inducing, as 
a consequence, apoptosis in cochlear neuroepithelial cells [2]. 
Cardiovascular 
risk 
factors, 
such 
as 
diabetes 
mellitus, 
hypertension, 
hypercholesterolemia, hyperhomocysteinemia, have been found to be associated to an 
increased risk of microvascular inner ear disorder [9, 37, 29, 36]. To date, there are few 
diagnostic possibilities to assess inner ear lesions in patients affected by SNHL. Recent 
improvements in imaging techniques, such as magnetic resonance imaging with specific 
contrast agents, could offer interesting prospective in order to study cochlear structural, 
functional, metabolic and also vascular permeability features [7]. More studies are necessary 
in order to understand the relationships between inner ear injury, endothelial dysfunction and 
micro-vascular disorders also in order to develop new potential diagnostic and therapeutical 
interventions. 
 
 
REFERENCES 
 
[1] 
Trune, D. R.; Nguyen-Huynh, A. Vascular pathophysiology in hearing disorders. 
Seminars in Hearing, 2012;33:242–250. 
[2] 
Ciorba, A.; Gasparini, P.; Chicca, M.; Pinamonti, S.; Martini, A. Reactive oxygen 
species in human inner ear perilymph. Acta Otolaryngol., 2010;130:240-246. 

V. Corazzi, A. Ciorba, C. Bianchini et al. 
 
200
[3] 
Quaranta, N.; De Ceglie, V.; D’Elia, A. Endothelial dysfunction in idiopathic sudden 
sensorineural hearing loss: a review. Audiol. Res., 2016;6(1):151. 
[4] 
Pober, J. S.; Min, W.; Bradley, J. R. Mechanisms of endothelial dysfunction, injury, and 
death. Annu. Rev. Pathol., 2009;4:71-95. 
[5] 
Arnout, J.; Hoylaerts, M. F.; Lijnen, H. R. Haemostasis. Handb. Exp. Pharmacol., 
2006;176:1-41. 
[6] 
Gul, F.; Muderris, T.; Yalciner, G.; Sevil, E.; Bercin, S.; Ergin, M.; Babademez, M. A.; 
Kiris, M. A comprehensive study of oxidative stress in sudden hearing loss. Eur Arch 
Otorhinolaryngol, 2017;274(3):1301-1308. 
[7] 
Shi, X. Pathophysiology of the cochlear intrastrial fluid-blood barrier (review). Hear 
Res., 2016;228:52-63. 
[8] 
Mudry, A.; Tange, R. A. The vascularization of the human cochlea its historical 
background. Acta Oto-Laryngologica, 2009;129 (Suppl. 561):3-16. 
[9] 
Marcucci, R.; Alessandrello Liotta, A.; Cellai, A. P.; Rogolino, A.; Berloco, P.; Leprini, 
E., Pagnini, P.; Abbate, R.; Prisco, D.; Cardiovascular and thrombophilic risk factors 
for idiopathic sudden sensorineural hearing loss. J. Thromb. Haemost., 2005;3:929-934. 
[10] Shi, X. Resident macrophages in the cochlear blood-labyrinth barrier and their renewal 
via migration of bone-marrow-derived cells. Cell and Tissue Research, 2010;342:21-
30. 
[11] Capaccio, P.; Pignataro, L., Gaini, L. M.; Sigismund, P. E.; Novembrino, C.; De 
Giuseppe, R.; Uva, V.; Tripodi, A.; Bamonti, F. Unbalanced oxidative status in 
idiopathic sudden sensorineural hearing loss. Eur. Arch. Otorhinolaryngol., 
2012;269(2):449-53. 
[12] Miller, J. M.; Ren, T. Y.; Nuttall, A. L. Studies of inner ear blood flow in animals and 
human beings. Otolaryngol. Head Neck Surg., 1995;112:101-113. 
[13] Huang, E. S.; Laiteerapong, N.; Liu, J. Y.; John, P. M.; Moffet, H. H.; Karter, A. J. 
Rates of complications and mortality in older patients with diabetes mellitus: the 
diabetes and aging study. JAMA Intern. Med., 2014;174(2):251-8. 
[14] Fukui, M.; Kitagawa, Y.; Nakamura, N.; Kadono, M.; Mogami, S.; Ohnishi, M.; Hirata, 
C.; Ichio, N.; Wada, K.; Kishimoto, C.; Okada, H., Miyata, H.; Yoshikawa, T. 
Idiopathic sudden hearing loss in patients with type 2 diabetes. Diabetes Res. Clin. 
Pract., 2004;63:205-2011. 
[15] Rust, K. R.; Prazma, J.; Triana, R. J.; Michaelis, O. E. 4th; Pillsbury, HC. Inner ear 
damage secondary to diabetes mellitus. II. Changes in aging SHR/N-cp rats. Arch. 
Otolaryngol. Head Neck Surg., 1992;118:397-400. 
[16] Frisina, S. T.; Mapes, F.; Kim, S.; Frisina, D. R.; Frisina, R. D. Characterization of 
hearing loss in aged type II diabetics. Hear Res., 2006;211:103-113. 
[17] Fujimoto, C.; Yamasoba, T. Oxidative stresses and mitochondrial dysfunction in age-
related hearing loss. Oxid. Med. Cell Longev., 2014;2014:582849. 
[18] Jiang, H.; Talaska, A. E.; Schacht, J., Sha, S. H. Oxidative imbalance in the aging inner 
ear. Neurbiol. Aging, 2007;28:1605-1612. 

Endothelial Dysfunction, Microvascular Disease … 
 
201
[19] Joachims, H. Z.; Segal, J.; Golz, A.; Netzer, A.; Goldenberg, D. Antioxidants in 
treatment of idiopathic sudden hearing loss. Otol. Neurotol., 2003;24(4):572-5. 
[20] Guo, Y.; Zhang, C., Du, X.; Nair, U.; Yoo, T. J. Morphological and functional 
alterations of the cochlea in apolipoprotein E gene deficient mice. Hear res., 
2005;208:54-67. 
[21] Gloddek, B.; Lamm, K., Arnol, W. Pharmacological influence on inner ear endothelial 
cells in relation to the pathogenesis of sensorineural hearing loss. Adv. 
Otorhinolaryngol., 2002;59:75-83. 
[22] Selivanova, O.; Heinrich, U. R.; Brieger, J.; Feltens, R.; Mann, W. Fast alterations of 
vascular endothelial growth factor (VEGF) expression and that of its receptors (Flt-1, 
Flk-1 and Neuropilin) in the cochlea of guinea pigs after moderate noise exposure. Eur. 
Arch. Otorhinolaryngol., 2007;264:121-128. 
[23] Ciorba, A.; Chicca, A.; Bianchini, C.; Aimoni, C.; Pastore, A. Sensorineural hearing 
loss and endothelial dysfunction due to oxidative stress: is there a connection? Int. Adv. 
Otol., 2012;8(1):16-20. 
[24] Pober, J. S.; Min, W.; Bradley, J. R. Mechanisms of endothelial dysfunction, injury, and 
death. Annu. Rev. Pathol., 2009;4:71-95. 
[25] Goodall, A. F. Current understanfing of the pathogenesis of autoimmune inner ear 
disease: a review. Clin. Otolaryngol., 2015;40(5):412-9. 
[26] Wilson, W. R.; Byl, F. M., Laird, N. The efficacy of steroids in the treatment of 
idiopathic sudden sensorineural hearing loss- A double-blind clinical study. Arch. 
Otolaryngol., 1980;160(12):772-6. 
[27] Huy, P. T.; Sauvaget, E. Idiopathic sudden sensorineural hearing loss is not an otologic 
emergency. Otol. Neurotol., 2005;26(5):896-902. 
[28] Chau, J. K.; Lin, J. R.; Atashband, S.; Irvine R. A.; Westerberg, B. D. Systematic 
review of the evidence for the etiology of adult sudden sensorineural hearing loss. 
Laryngoscope, 2010;120(5):1011-21. 
[29] Merchant, S. N.; Durand, M. L.; Adams, J. C. Sudden deafness: is it viral? ORL J. 
Otorhinolaryngol. Relat. Spec., 2008;70(1):52-62. 
[30] van Dishoek, H.; Bierman, T. Sudden perceptive deafness and viral infection (report of 
the first one hundred patients). Ann. Otol. Rhinol. Laryngol., 1957;66:963-980. 
[31] Veldman, J. E. Cochlear and retrocochlear immune-mediated inner ear disorders. 
Pathogenetic mechanisms and diagnostic tools. Ann. Otol. Rhinol. Laryngol., 
1986;95:535-540. 
[32] Cho, C. H.; Jung, B. S.; Jung, J. H.; Lee, J. H.; Lee, J. H. Expression of autoantibodies 
in patients with sudden sensorineural hearing loss. Ann. Otol. Rhinol. Laryngol., 
2013;122(2):131-4. 
[33] Simmons, F. B. Theory of membrane breaks in sudden hearing loss. Arch. Otolaryngol., 
1968;88:41-48. 
[34] Harris, I. Sudden hearing loss: membrane rupture. Am. J. Otol., 1984;5(6):484-7. 
[35] Rasmussen, H. Sudden deafness. Acta Otolaryngol, 1949;37:65-70. 

V. Corazzi, A. Ciorba, C. Bianchini et al. 
 
202
[36] Fisch, U.; Nagahara, K.; Pollak, A. Sudden hearing loss: Circulatory. American Journal 
of Otology 1984;5:488-91. 
[37] Aimoni, C.; Bianchini, C.; Borin, M.; Ciorba, A.; Fellin, R.; Martini, A.; Scanelli, G.; 
Volpato, S. Diabetes, cardiovascular risk factors and idiopathic sudden sensorineural 
hearing loss: a case-control study. Audiol. Neurootol., 2010;15(2):11-5. 
[38] Haubner, F.; Martin, L.; Steffens, T., Strutz, J.; Kleinjung, T. The role of soluble 
adhesion molecules and cytokines in sudden sensorineural hearing loss. Otolaryngol. 
Head Neck Surg., 2011;144:575-580. 
[39] Krieglstein, C. F.; Granger, D. N. Adhesion molecules and their role in vascular 
disease. Am. J. Hypertens., 2001;14:44S-54S. 
[40] Merchant, S. N.; Adams, J. C.; Nadol, J. B. Pathology and Pathophysiology of 
idiopathic sudden sensorineural hearing loss. Otol. Neurotol., 2005;26(2):151-60. 
[41] Passamonti, S. M.; Di Berardino, F.; Bucciarelli, P.; Berto, V.; Artoni, A.; Giannello, 
F.; Ambrosetti, U.; Cesarani, A.; Pappalardo, E.; Martinelli, I. Risk factors for 
idiopathic sudden sensorineural hearing loss and their association with clinical 
outcome. Thromb. Res., 2015;135:508-12. 
[42] Ciorba, A.; Hatzopoulos, S.; Bianchini, C.; Iannini, V.; Rosignoli, M.; Skarzynski, H., 
Aimoni, C. Idiopathic sudden sensorineural hearing loss: cardiovascular risk factors do 
not influence hearing threshold recovery. Acta Otorhinolaryngol. Ital., 2015; 35(2):103-
9. 
[43] Ciorba, A.; Corazzi, V.; Bianchini, C.; Aimoni, C.; Skarzynski, H.; Skarzynski, P. H.; 
Htzopoulos, S. Sudden sensorineural hearing loss: is there a connection with inner ear 
electrolytic disorders? A literature review. Int. J. Immunopathol. Pharmacol., 
2016;29(4):595-602.  
[44] Hellier, W. P.; Wagstaff, S. A.; O’Leary, S. J.; Shepherd, R. K. Functional and 
morphological response of the stria vascularis following a sensorineural hearing loss. 
Hear Res., 2002;172(1-2):127-36. 
[45] Hoya, N.; Okamoto, Y.; Kamiya, K.; Fujii, M.; Matsunaga, T. A novel animal model of 
acute cochlear mitochondrial dysfunction. Neuroreport, 2004;15(19):1597-600. 
[46] Okamoto, Y.; Hoya, N., Kamiya, K., Fujii, M.; Ogawa, K.; Matsunaga, T. Permanent 
threshold shift caused by acute cochlear mitochondrial dysfunction is primarily 
mediated by degeneration of the lateral wall of the cochlea. Audiol. Neurootol., 
2005;10(4):220-33. 
[47] Trune, D. R.; Nguyen-Huynh, A. Vascular pathophysiology in hearing disorders. 
Semin. Hear, 2012;33(3):242-250. 
[48] Ciuman, R. R. Stria vascularis and vestibular dark cells: characterisation of main 
structures responsible for inner-ear homeostasis, and their pathophysiological relations. 
J. Laryngol. Otol., 2009;123(2):151-62. 

In: Encyclopedia of Audiology and Hearing Research 
ISBN: 978-1-53617-702-2 
Editors: Erno Larivaara and Senja Korhola 
© 2020 Nova Science Publishers, Inc. 
 
 
 
 
 
 
 
Chapter 15 
 
 
 
SUPEROXIDE DISMUTASE  
AND SENSORINEURAL HEARING LOSS 
 
 
V. Corazzi, C. Bianchini, C. Aimoni and A. Ciorba* 
ENT & Audiology Department, University Hospital of Ferrara, Italy 
 
 
ABSTRACT 
 
Superoxide dismutase (SOD) is an antioxidant agent that can be found in almost 
every cell exposed to oxygen. It is responsible for the dismutation of superoxide anions 
resulting from cellular metabolism into oxygen and hydrogen peroxide. In particular, 
superoxide dismutase (SOD), in its cytoplasmic isoform, contains copper (Cu) and zinc 
(Zn), and can be found in cochlear tissue (stria vascularis, spiral ligament, spiral ganglion 
neurons and organ of Corti). The antioxidant function of SOD is important for protection 
of the inner ear cells from toxic substances, such as reactive oxygen species (ROS). The 
role of SOD has been investigated in noise-induced hearing loss and in presbycusis, 
whereas elevated concentrations of ROS are responsible for inner ear damage. In the last 
decades, many authors have tested the protective role of SOD in the cochlea of animal 
models. Recently, the role of SOD gene polymorphisms in the susceptibility of sudden 
sensorineural hearing loss has been investigated as well. 
The aim of this chapter is to review the role of SOD in the cochlear metabolism and 
its involvement in the pathogenesis of noise induced hearing loss, age related hearing loss 
and sudden sensorineural hearing loss. 
 
Keywords: sensorineural hearing loss, superoxide dismutase, reactive oxygen species, 
oxidative stress, noise-induced hearing loss, presbycusis 
 
 
INTRODUCTION 
 
The oxygen metabolism represents the fundamental engine for aerobic cells, which is 
necessary for the cellular production of energy. Reactive oxygen species (ROS), such as 
                                                        
* Corresponding Author’s Email: andrea.ciorba@unife.it 

V. Corazzi, C. Bianchini, C. Aimoni et al. 
 
204
hydrogen peroxide, superoxide and hydroxyl radical, are chemically reactive elements 
obtained as a normal product of the oxygen metabolism and play an important role in cellular 
homeostasis and signalling [1]. In a standard cellular environment, ROS oxidant activity is 
counterbalanced by an antioxidant system, which represents the cellular antiradical defence, 
including some molecules such as glutathione peroxidase, catalase, vitamin A, C and E and 
superoxide dismutase (SOD) [2]. 
Several conditions, such as exposition to ionizing radiation and inflammatory processes, 
may determine an augmented production of ROS, configuring a so-called ‘oxidative stress’ 
status. In such circumstances, a loss of balance between oxidant and antioxidant agents occurs 
and the excessive ROS concentration can cause cellular damage. The mechanisms, through 
which incremented ROS levels may cause cellular injury, are well established: lipid 
perixodation, protein oxidation and DNA damage. These mechanisms are also able to induce 
cellular death through necrosis or apoptosis [1]. 
Oxidative stress is known to be involved in the normal ageing process [3]; also, it is 
known to play a pivotal role in the pathogenesis of different diseases, such as carcinogenesis 
[4], ischaemia [5] and neurodegenerative disorders, including Alzheimer disease [6]. 
Furthermore, it has been reported that oxidative stress may be linked to hearing loss [7]: 
incremented ROS levels, among inner ear cells, have been reported in several conditions such 
as presbycusis [8], ototoxicity (i.e., cisplatin, aminoglycosides) [9] and noise exposure [10]. 
Inner ear hair cells are particularly susceptible to variation of cochlear blood flow and to 
oxygen levels [11]. Moreover, the cochlear lateral wall (stria vascularis and spiral ligament), 
involved in the preservation of the endolymphatic homeostasis and the endocochlear 
potential, is particular vulnerable to ischemic conditions [12]. 
It has been described that in case of cochlear ischemic injury, an increased ROS 
production may determine inner ear cells damage through two mechanisms: (i) a direct cell 
metabolic impairment and (ii) an endothelial dysfunction [13]. Some authors [14,15,16,17] 
have also linked oxidative stress to the onset of sensorineural hearing loss (SNHL), describing 
a correlation between ROS-induced endothelial dysfunction and inner ear disease. 
In this scenario, SOD represents an important defence system against oxidative stress in 
the inner ear. 
 
 
SUPEROXIDE DISMUTASE AND THE INNER EAR 
 
SOD is a cellular oxidoreductase enzyme involved in the dismutation of the superoxide 
into hydrogen peroxide. SOD is a crucial cellular antioxidant element, which can be found in 
almost every cell exposed to oxygen [18]. In mammals there are three isoforms of SOD: they 
differ mainly in the ion included in the active site (copper, iron, zinc, nickel and manganese) 
and in their distribution: SOD1 is located in the cytoplasm, SOD2 in mitochondria, while 
SOD3 is an extracellular form [18]. 
During the last decades, many authors have already demonstrated the crucial importance 
of the oxidoreductive function of SOD with animal models. Mice lacking SOD activity 
develop several pathologies, such as hepatocellular carcinoma [19], early cataract [20], and 
also hearing loss [21]. Furthermore, other authors have demonstrated the protective role of 
SOD towards outer hair cells in vitro [22] and in the mice cochlea [23]. 

Superoxide Dismutase and Sensorineural Hearing Loss 
 
205
SOD1, the cytoplasmic isoform, has been found prevalently in cochlear tissue (stria 
vascularis, spiral ligament, spiral ganglion neurons and organ of Corti), with a minor 
concentration also located in the mitochondria intramembrane space [24,25]. Stria vascularis 
retains high SOD concentration, as it is involved in the maintenance of the endocochlear 
potential due to its central role in ionic transportation; in addition, this process requires a 
continue active aerobic oxidation in order to obtain ATP [12]. High SOD concentration in 
stria vascularis plays a relevant role in detoxification from oxygen free radicals [25]. In spiral 
ganglion neurons and in the organ of Corti, SOD has been reported to protect directly neural 
and hair cells from ROS damages as well [21]. 
 
 
SUPEROXIDE DISMUTASE  
AND NOISE-INDUCED HEARING LOSS 
 
The pathogenic role of oxidative stress in noise-induced hearing loss has been already 
described [26]; increased levels of ROS after noise exposure have been linked to hair cells 
damage [27]. Recently, Fetoni et al., [10] demonstrated the morphological and functional 
alterations of hair cells and spiral ganglion neurons after a repeated noise exposure in a rat 
model: they described a cochlear damage, at the medial and basal parts, with a consequent 
hearing loss as showed by an increased ABR thresholds. This phenomenon was due to an 
oxidative imbalance, described by the Author as an increase in the cellular production of 
superoxide and the consequent lipid peroxidation. They also observed an amendment of 
cochlear injuries and of the auditory thresholds, following the administration of an 
antioxidant treatment to reverse the noise-induced redox unbalance. 
In 1999, Ohlemiller et al., demonstrated an augmented susceptibility to noise-induced 
hearing impairment in a group of mice lacking SOD1 [28], highlighting the defensive 
significance of intracellular controlled levels of SOD. 
Liu et al., [29] explored the relationship between SOD1 polymorphisms and the 
susceptibility to noise-induced hearing loss, describing a significant difference between noise-
resistant and noise-sensitive workers. In particular, they suggested that rs2070424 and 
rs10432782 SOD1 polymorphisms might be responsible for an increased susceptibility to 
noise-induced hearing impairment. A more recent meta-analysis performed by Wang et al., 
[30] examined the same relationship, considering a specific SOD2 polymorphism (c47t): in 
this study, the authors did not find any statistically significant correlation. 
 
 
SUPEROXIDE DISMUTASE AND PRESBYCUSIS 
 
Oxidative stress is already known to be involved in the aging process; an unbalanced 
cochlear redox status also plays an important role in the development of presbycusis. A 
reduction of SOD enzymes levels (especially SOD2) in aged tissues of rats and mice has been 
comprehensively described more than 30 years ago [31, 32]. The relationship between 
oxidative stress and the aging of inner ear was investigated in mice [8]: oxidative stress levels 
in the aging cochlea increase, while antioxidant factors, such as mitochondrial apoptosis-
inducing factor and SOD2, decrease. In particular, it has been found that SOD2 levels are 

V. Corazzi, C. Bianchini, C. Aimoni et al. 
 
206
reduced in outer hair cells, supporting cells and spiral ganglion cells. McFadden et al, in 
1999, demonstrated that in a group of SOD1 lacking mice, the loss of inner ear outer hair 
cells was greater than in the control wild type mice group, highlighting that the deficiency of 
SOD activity enhances the age-related degeneration of neuroepithelium of the inner ear [21]. 
These results are consistent with the study performed by Keithley et al., in a mice model in 
2005 [33]. 
 
 
SUPEROXIDE DISMUTASE AND SUDDEN SENSORINEURAL 
HEARING LOSS 
 
Genetic alterations of SOD enzymes have been associated with several diseases; for 
example, mutations of SOD1 can cause familial amyotrophic lateral sclerosis, a form of 
motor neuron disease [34]. Different authors examined the role of SOD gene polymorphisms 
in hearing loss development [29, 30], which appears to be race-specifically distributed. More 
recently, Kitoh et al., explored the potential correlation between a particular polymorphism of 
SOD1 gene and the susceptibility to sudden sensorineural hearing loss (SSNHL) [35]. 
There are many proposed classical etiological theories of SSNHL, including the vascular 
hypothesis, based on a hemorrhagic or ischemic insult to cochlea [36]. Considering this 
possible etiology, ROS may represent an important factor in cochlear damage and sudden 
hearing loss. The relation between SOD genetic polymorphisms and SSNHL has not been 
largely investigated yet. Kitoh et al., [35] found in SOD1 rs4998557 a polymorphism likely 
associated with susceptibility to SSNHL, however no SOD2 polymorphisms were found to be 
correlated with a predisposition to SSNHL. Earlier, Teranishi et al., [37] explored the SOD2 
polymorphism in two groups of patients, one group of patients with SSNHL and another 
group of patients with Ménière’s Disease. They found no statistically significant differences 
in the distribution of polymorphisms among the two groups. In conclusion, they did not 
suggest any association between specific genotypes and incremented risk of SSNHL or 
Ménière’s Disease. Nonetheless, they described a particular C allele of SOD2 (rs4880) to be 
associated with progression of the hearing impairment in Ménière patients. 
 
 
CONCLUSION 
 
SOD represents an important protective antioxidant system of eukaryotic cells. In the 
cochlea, SOD seems to play a crucial role in protecting auditory neuroepithelium against 
toxic substances, such as ROS.  
A possible ‘therapeutic – protective’ role of increased SOD levels has been described. 
Nonetheless, it has been reported that an over expression of SOD1 in mice does not protect 
inner ear cells from age-related or noise induced damage [33,38]; however, some authors 
demonstrated a potential protection provided by SOD against ototoxicity induced by 
antibiotic drug administration (kanamycin) in mice [23] and in guinea pigs [39].  
Recently, Serra et al., [40] proposed a brand-new application of SOD as a nutraceutical 
treatment in patients with obstructive sleep apnea-hypopnea syndrome (OSAHS), a condition 

Superoxide Dismutase and Sensorineural Hearing Loss 
 
207
known to be associated with oxidative unbalance. However, a similar approach to inner ear 
disease treatment has not been previously suggested to our knowledge. 
So far, the role of SOD in the pathogenesis of inner ear diseases remains an unresolved 
issue. Since SOD is involved in hearing function and protection, it could represent a possible 
therapeutic target for certain inner ear diseases. 
 
 
REFERENCES 
 
[1] 
Slimen, I. B.; Najar, T.; Ghram, A.; Dabbebi, H., Ben Mrad, M.; Abdrabbah, M. 
Reactive oxygen species, heat stress and oxidative-induced mitochondrial damage. A 
review. Int. J. Hyperthermia, 2014; 30(7):513-23. 
[2] 
Vives-Bauza, C.; Starkov, A.; Garcia-Arumi, E. Measurements of the antioxidant 
enzyme activities of superoxide dismutase, catalase, and glutathione peroxidase. 
Methods Cell. Biol., 2007; 80:379-93. 
[3] 
Kong, Y.; Trabucco, S. E.; Zhang, H. Oxidative stress, mitochondrial dysfunction and 
the mitochondria theory of aging. Interdiscip. Top Gerontol. 2014;39:86-107. 
[4] 
Lee, J. C.; Son, Y. O.; Pratheeshkumar, P.; Shi, X. Oxidative stress and metal 
carcinogenesis. Free Radic. Biol. Med., 2012; 53(4):742-57. 
[5] 
Rodrigo, R.; Fernández-Gajardo, R.; Gutiérrez, R.; Matamala, J. M.; Carrasco, R.; 
Miranda-Merchak, A.; Feuerhake W. Oxidative stress and pathophysiology of ischemic 
stroke: novel therapeutic opportunities. CNS Neurol. Disord. Drug Targets, 2013; 
12(5):698-714. 
[6] 
Swomley, A. M.; Butterfield, D. A. Oxidative stress in Alzheimer disease and mild 
cognitive impairment: evidence from human data provided by redox proteomics. Arch. 
Toxicol., 2015; 89(10):1669-80. 
[7] 
Kamogashira, T.; Fujimoto, C.; Yamasoba, T. Reactive oxygen species, apoptosis, and 
mitochondrial dysfunction in hearing loss. Biomed. Res. Int., 2015; 2015:617207. 
[8] 
Jiang, H.; Talaska, A. E.; Schacht, J.; Sha, S. H. Oxidative imbalance in the aging inner 
ear. Neurobiol. Aging. 2007;28(10):1605-12. 
[9] 
Lanvers-Kaminsky, C.; Zehnhoff-Dinnesen, A. A.; Parfitt, R.; Ciarimboli, G. Drug-
induced ototoxicity: Mechanisms, Pharmacogenetics, and protective strategies. Clin. 
Pharmacol. Ther. 2017; 101(4):491-500. 
[10] Fetoni, A. R.; De Bartolo, P., Eramo, S. L.; Rolesi, R.; Paciello, F.; Bergamini, C.; Fato, 
R.; Paludetti, G.; Petrosini, L.; Troiani, D. Noise-induced hearing loss (NIHL) as a 
target of oxidative stress-mediated damage: cochlear and cortical responses after an 
increase in antioxidant defense. J. Neurosci., 2013; 33(9):4011-23. 
[11] Mudry, A.; Tange, R. A. The vascularization of the human cochlea its historical 
background. Acta Oto-Laryngologica, 2009; 129(Suppl. 561):3-16. 
 
 

V. Corazzi, C. Bianchini, C. Aimoni et al. 
 
208
[12] Ciorba, A.; Corazzi, V.; Bianchini, C.; Aimoni, C.; Skarzynski, H.; Skarzynski, P. H.; 
Hatzopoulos, S. Sudden sensorineural hearing loss: Is there a connection with inner ear 
electrolytic disorders? A literature review. Int. J. Immunopathol. Pharmacol. 
2016;29(4):595-602. 
[13] Ciorba, A.; Gasparini, P.; Chicca, M.; Pinamonti, S.; Martini, A. Reactive oxygen 
species in human inner ear perilymph. Acta Otolaryngol. 2010;130:240-246. 
[14] Guo, Y.; Zhang, C., Du, X.; Nair, U.; Yoo, T. J. Morphological and functional 
alterations of the cochlea in apolipoprotein E gene deficient mice. Hear Res., 2005; 
208:54-67. 
[15] Gloddek, B.; Lamm, K.; Arnol, W. Pharmacological influence on inner ear endothelial 
cells in relation to the pathogenesis of sensorineural hearing loss. Adv. 
Otorhinolaryngol., 2002; 59:75-83. 
[16] Selivanova, O.; Heinrich, U. R.; Brieger, J.; Feltens, R.; Mann, W. Fast alterations of 
vascular endothelial growth factor (VEGF) expression and that of its receptors (Flt-1, 
Flk-1 and Neuropilin) in the cochlea of guinea pigs after moderate noise exposure. Eur. 
Arch. Otorhinolaryngol., 2007; 264: 121-128. 
[17] Ciorba, A.; Chicca, A.; Bianchini, C.; Aimoni, C.; Pastore, A. Sensorineural hearing 
loss and endothelial dysfunction due to oxidative stress: is there a connection? Int. Adv. 
Otol., 2012; 8(1):16-20. 
[18] Fetherol, M. M.; Boyd, S. D.; Winkler, D. D.; Winge, D. R. Oxygen-dependent 
activation of Cu, Zn-superoxide dismutase-1. Metallomics, 2017; 9(8):1047-1059. 
[19] Elchuri, S.; Oberley, T. D.; Qi, W.; Eisenstein, R. S.; Jackson Roberts, L.; Van 
Remmen, H.; Epstein, C. J.; Huang, T. T. CuZnSOD deficiency leads to persistent and 
widespread oxidative damage and hepatocarcinogenesis later in life. Oncogene, 2005; 
24(3):367–80. 
[20] Behndig, A.; Karlsson, K.; Reaume, A. G.; Sentman, M. L.; Marklund, S. L. In vitro 
photochemical cataract in mice lacking copper-zinc superoxide dismutase. Free Radic. 
Biol. Med., 2001; 31(6):738-44. 
[21] McFadden, S. L.; Ding, D.; Reaume, A. G.; Flood, D. G.; Salvi, R. J. Age-related 
cochlear hair cell loss is enhanced in mice lacking copper/zinc superoxide dismutase. 
Neurobiol. Aging. 1999; 20(1):1-8. 
[22] Clerici, W. J.; DiMartino, D. L.; Prasad, M. R. Direct effects of reactive oxygen species 
on cochlear outer hair cell shape in vitro. Hear. Res., 1995; 84(1-2):30-40. 
[23] Sha, S. H.; Zajic, G.; Epstein, C. J.; Schacht, J. Overexpression of copper/zinc-
superoxide dismutase protects from kanamycin-induced hearing loss. Audiol. 
Neurootol. 2001;6(3):117-23. 
[24] Pierson, M. G.; Gray, B. G. Superoxide dismutase activity in the cochlea. Hear. Res., 
1982; 6:141-151. 
[25] Yao, X.; Rarey, K. E. Detection and regulation of Cu/Zn-SOD and Mn-SOD in rat 
cochlear tissues. Hear. Res., 1996; 96(1-2):199-203. 
[26] Henderson, D.; Bielefeld, E. C.; Harris, K. C.; Hu, B. H. The role of oxidative stress in 
noise-induced hearing loss. Ear. Hear. 2006; 27(1):1-19. 

Superoxide Dismutase and Sensorineural Hearing Loss 
 
209
[27] Henderson, D.; McFadden, S. L.; Liu, C. C.; Hight, N.; Zheng, X. Y. The role of 
antioxidants in protection from impulse noise. Ann. N Y Acad. Sci., 1999; 884: 368-80. 
[28] Ohlemiller, K. K.; McFadden, S. L.; Ding, D. L.; Flood, D. G.; Reaume, A. G.; 
Hoffman, E. K.; Scott, R. W.; Wright, J. S.; Putcha, G. V.; Salvi, R. J. Targeted deletion 
of the cytosolic Cu/Zn-superoxide dismutase gene (Sod1) increases susceptibility to 
noise-induced hearing loss. Audiol. Neurootol. 1999; 4(5):237-46. 
[29] Liu, Y. M.; Li, X. D.; Guo, X.; Liu, B.; Lin, A. H.; Rao, S. Q. Association between 
polymorphisms in SOD1 and noise-induced hearing loss in Chinese workers. Acta 
Otolaryngol. 2010;130(4):477-86. 
[30] Wang, J.; Li, J.; Peng, K.; Fu, Z. Y.; Tang, J.; Yang, M. J.; Chen, Q.C.; Wang, J.; Li, J.; 
Peng, K.; Fu, Z. Y.; Tang, J.; Yang, M. J.; Chen, Q.C. Association of the C47T 
polymorphism in superoxide dismutase gene 2 with noise-induced hearing loss: a meta-
analysis. Braz. J. Otorhinolaryngol., 2017; 83(1):80-87. 
[31] Dahn, H. C.; Benedetti, M. S.; Dostert, P. Differential changes in superoxide dismutase 
activity in brain and liver of old rats and mice. J. Neurochem., 1983; 40:1003-1007. 
[32] Dovrat, A.; Gershon, D. Rat lens superoxide dismutase and glucose-6-phosphate 
dehydrogenase: studies on the catalytic activity and the fate of enzyme antigen as a 
function of age. Exp. Eye. Res., 1981; 33(6):651-61. 
[33] Keithley, E. M.; Canto, C.; Zheng, Q. Y.; Wang, X.; Fischel-Ghodsian, N.; Johnson, K. 
R. Cu/Zn superoxide dismutase and age-related hearing loss. Hear. Res., 2005; 209(1-
2):76-85. 
[34] Gagliardi, S.; Cova, E.; Davin, A.; Guareschi, S.; Abel, K.; Alvisi, E.; Laforenza, U.; 
Ghidoni, R.; Cashman, J. R.; Ceroni, M.; Cereda, C. SOD1 mRNA expression in 
sporadic amyotrophic lateral sclerosis. Neurobiology of Disease, 2010;39(2):198–203. 
[35] Kitoh, R.; Nishio, S. Y.; Ogawa, K.; Okamoto, M.; Kitamura, K.; Gyo, K.; Sato, H.; 
Nakashima, T.; Fukuda, S.; Fukushima, K.; Hara, A.; Yamasoba, T.; Usami, S. SOD1 
gene polymorphisms in sudden sensorineural hearing loss. Acta Otolaryngol., 
2016;136(5):465-9. 
[36] Gyo, K. Experimental study of transient cochlear ischemia as a cause of sudden 
deafness. World J. Otorhinolaryngol., 2013; 3(1):1-15. 
[37] Teranishi, M.; Uchida, Y.; Nishio, N.; Kato, K.; Otake, H.; Yoshida, T.; Suzuki, H.; 
Sone, M.; Sugiura, S.; Ando, F.; Shimokata, H.; Nakashima, T. Polymorphisms in 
genes involved in oxidative stress response in patients with sudden sensorineural 
hearing loss and Ménière’s disease in a Japanese population. DNA Cell. Biol., 2012; 
31(10):1555-62. 
[38] Coling, D. E.; Yu, K. C.; Somand, D.; Satar, B.; Bai, U.; Huang, T. T.; Seidman, M. D.; 
Epstein, C. J.; Mhatre, A. N.; Lalwani, A. K. Effect of SOD1 overexpression on age- 
and noise-related hearing loss. Free Radic. Biol. Med., 2003; 34(7):873-80. 
[39] Kawamoto, K.; Sha, S. H.; Minoda, R.; Izumikawa, M.; Kuriyama, H.; Schacht, J.; 
Raphael, Y. Antioxidant gene therapy can protect hearing and hair cells from 
ototoxicity. Mol. Ther., 2004; 9(2):173-81. 

V. Corazzi, C. Bianchini, C. Aimoni et al. 
 
210
[40] Serra, A.; Maiolino, L.; Cocuzza, S.; Di Luca, M.; Campione, G.; Licciardello, L.; Di 
Mauro, P. Assessment of oxidative stress markers and hearing thresholds in patients 
with obstructive sleep apnea-hypopnoea treated with cysteine and superoxide dismutase 
therapy. Acta Biomed. 2017;87(3):253-258. 

In: Encyclopedia of Audiology and Hearing Research 
ISBN: 978-1-53617-702-2 
Editors: Erno Larivaara and Senja Korhola 
© 2020 Nova Science Publishers, Inc. 
 
 
 
 
 
 
 
Chapter 16 
 
 
 
CARDIOVASCULAR RISK FACTORS AND 
SENSORINEURAL HEARING LOSS 
 
 
V. Corazzi1, C. Bianchini1, C. Aimoni1 and A. Ciorba1,* 
1ENT & Audiology Department, University Hospital of Ferrara,  
Ferrara, Italy 
 
 
ABSTRACT 
 
The inner ear may be impaired by vascular affections since it is supplied by a 
terminal blood flow and has a sustained metabolic activity [1]. It has been reported that 
the function of labyrinthine vessels can be influenced by several local factors such as 
perivascular sympathetic innervation, arterial systemic blood pressure and labyrinth 
liquids pressure ratio, antidiuretic hormone receptors, endothelial dysfunction and ionic 
transport mechanisms [2]. 
A possible link between microvascular inner ear disease and sudden sensorineural 
hearing loss (SSNHL) has been proposed: a sudden labyrinth oxygen lack may be 
responsible for acute inner ear damage, involving hair cells and then affecting hearing or 
vestibular function [3]. Moreover, a primary autonomic vascular dysregulation has been 
related to acute cochlear damage [2]. Many Authors have investigated the possible 
involvement of cardiovascular risk factors (i.e., hypertension, diabetes mellitus, 
hypercholesterolemia, 
hyperhomocysteinemia) 
in 
the 
pathogenesis 
of 
sudden 
sensorineural hearing loss [4]. Furthermore, microcirculation defects, frequently 
associated to atherosclerosis, have been reported to play a major role in the onset of acute 
cochlear damage [5]. 
The aim of this chapter is to review the relationship between cardiovascular risk 
factors, systemic circulatory diseases and inner ear disorders, particularly focusing on the 
involvement of cardiovascular factors in the pathogenesis of SSNHL. 
 
Keywords: sensorineural hearing loss, sudden sensorineural hearing loss, cardiovascular risk 
factors, hypertension, diabetes mellitus, smoking 
 
 
                                                        
* Corresponding Author’s Email: andrea.ciorba@unife.it. 

V. Corazzi, C. Bianchini, C. Aimoni et al. 
 
212
INTRODUCTION 
 
The inner ear is a sensorial organ characterized by neuroepithelial cells with a high 
oxygen-dependent metabolism. Its vascularization is provided by a terminal circulation: the 
labyrinthine artery is a branch of the anterior inferior cerebellar artery (rarely of the basilar 
artery directly) and it is the only vessel responsible for the inner ear blood supply [1]. This 
anatomic and functional configuration (in particular, the absence of collateral vessels and the 
sustained metabolic activity of the inner ear cells) represents the main reason for the high 
sensitivity of the inner ear to vascular accidents [1]. There are three terminal branches 
originating from the labyrinthine artery: (1) the anterior vestibular, (2) the vestibulocochlear 
and (3) the main cochlear artery, which supply different parts of the inner ear (vestibular and 
cochlear partitions) [1]. Towards the terminal extremity of these vessels, the arteries decrease 
in size and lose their muscular layers, therefore increasing their predisposition to peripheral 
vasomotion disorders [6]. This vascular subdivision represents the anatomical explanation for 
the different clinical features (matching hearing loss and vertigo) resulting from vascular 
accidents, such as localized ischemic events [7]. Therefore, alteration of platelet aggregation, 
red cells deformability, haematocrit and plasmatic viscosity (as described in several 
conditions 
such 
as 
leukaemia, 
leucocytosis, 
polycythaemia, 
sickle-cell 
anaemia, 
cryoglobulinemia, macroglobulinemia) may have implications also on inner ear function [8]. 
There are several local factors influencing the inner ear perfusion, such as perivascular 
sympathetic innervation, arterial systemic blood pressure or labyrinthic liquids pressure ratio 
[2]. The labyrinthic blood flow is also regulated by blood labyrinthine barrier, pericytes, 
smooth muscle cells and fibrocytes; endothelial dysfunction and alterations of ionic transport 
could represent another mechanism of cochlear injury, as well [9]. 
Concerning the autonomic nervous system control on local inner ear perfusion [10, 11], 
the function of distal arterioles has been reported to affect directly the number of perfused 
capillaries and the partition of local blood distribution. In particular, many studies have 
focused on stria vascularis capillaries and on their capacity to interact with different signals, 
such as iron ions and nitric oxide in presence of an acoustic stimulus, then determining an 
increase of local blood flow [12]. 
Alterations of the intracranial venous circulation have been related to the pathogenesis of 
inner ear disorders, in consideration of the delicate balance existing between intracranial and 
labyrinthic fluids pressure; it has been reported that a variation of venous pressure may 
interfere with inner ear homeostasis [13, 14, 15]. 
 
 
SENSORINEURAL HEARING LOSS AND CARDIOVASCULAR 
RISK FACTORS 
 
The inner ear may be damaged by hemodynamic or metabolic events in case of systemic 
diseases, such as cardiovascular, renal, inflammatory, autoimmune and/or metabolic disorders 
[16]. Hearing loss has been related to cardiovascular risk factors (such as male gender, 
hypertension, dyslipidaemia, obesity, lack of physical activity, diabetes mellitus, 
atherosclerosis, smoking) and also, in the Framingham Heart Study, to cardiovascular events, 
such as cerebrovascular and coronary artery disease [16, 17, 18]. In addition, other 
cardiovascular risk factors, such as body mass index, waist circumference and socioeconomic 

Cardiovascular Risk Factors and Sensorineural Hearing Loss 
 
213
status, have been found to be linked to the incidence of hearing loss in longitudinal studies 
[19, 20, 21]. 
Obesity has been considered to cause inner ear cells injury through ischaemic damage 
and oxidative stress, the same mechanisms through which tobacco, potentially, could act as 
risk factor for hearing loss [21]. 
High systolic blood pressure (more than the diastolic) was found to have a positive 
correlation with hearing loss in frequencies above 500Hz [22]. 
Increased blood sugar levels may damage the vascular endothelial walls. Moreover, an 
increased prevalence of hearing loss has been reported in patients with an impaired glucose 
control [23]. In 2006 Fukushima demonstrated a condition of angiopathy and degeneration of 
outer hair cells and of stria vascularis examining temporal bones of diabetic patients [24]. 
Elevated lipid blood levels (low-density lipoproteins in particular) have been linked to 
microvascular damage [25], nonetheless a direct association between blood lipids and hearing 
loss has not been demonstrated yet [26]. 
Recently, the relationship between hearing loss and levels of serum C-reactive protein 
(CRP), another cardiovascular risk marker, has been investigated; Nash [27] found an 
increased 10-year risk of hearing loss in case of high levels of CRP [26], but further confirms 
are necessary. 
Subclinical atherosclerosis has been related to an increased incidence of hearing loss in a 
large cohort study (1984 middle-aged patients - increased risk of about 15%) [28]. 
Atherosclerotic plaques may affect inner ear perfusion due to a decreased availability of 
oxygen and nutrients to the cochlea [22]. In 1978, Makishima found a positive association 
between (i) the narrowing of the internal auditory artery, (ii) stria vascularis atrophy, and (iii) 
hearing loss, suggesting that a spiral ganglion atrophy could result from a chronic reduction 
of cochlear blood flow caused by atherosclerosis [29]. However, the precise role of 
atherosclerosis, as a risk factor for hearing impairment, has not been completely understood 
[17], since systemic atherosclerosis may also coexist with a normal hearing function [30]. 
Presbycusis is among the most frequent sensorial deficit in elderly and its prevalence 
increases with age, as much as cardiovascular diseases [31]. Since cardiovascular risk factors 
are generally more frequent in the elderly, it could be difficult to distinguish the effects of 
cardiovascular diseases on inner ear function, from those related to (i) ageing, (ii) 
occupational or environmental noise exposure, or (iii) use of ototoxic drugs[17, 32]. 
The interaction between presbycusis and diabetes mellitus has been investigated [33]. 
Frisina studied a population of aged diabetic patients compared to age-matched healthy 
control patients, performing both peripheral and central auditory tests [33]: the Author 
evidenced significant differences between the two groups in both auditory categories tests 
with poorer performances in the diabetics group, highlighting that hyperglycemia may 
damage not only the inner ear cells, but also the central nervous system. 
 
 
SUDDEN SENSORINEURAL HEARING LOSS AND CARDIOVASCULAR 
RISK FACTORS 
 
To date, the pathogenesis of idiopathic sudden sensorineural hearing loss (SSNHL) 
remains unclear. Among the different etiopathogenetic hypotheses, the vascular theory is one 

V. Corazzi, C. Bianchini, C. Aimoni et al. 
 
214
of the most investigated [6, 34]. Several Authors evaluated the existence of a link between 
cardiovascular factors and the onset of sudden hearing loss [7, 8, 35]. Marcucci [8] and 
Capaccio [36] found an increased concentration of cholesterol, fibrinogen and homocysteine 
as cardiovascular risk factors in patients affected by SSNHL. In addition, several inherited 
and acquired cardiovascular risk factors have been found to increase the risk of hearing 
impairment development: Ballesteros [35] found a higher prevalence of the 807T 
thrombophilic polymorphism of platelet glycoprotein Ia/IIa in patients affected by idiopathic 
SSNHL compared to healthy control patients and assessed a poorer hearing recovery rate in 
patients homozygous for this polymorphism. 
Aimoni et al. [4] evidenced hypercholesterolemia and diabetes mellitus (particularly 
associated with insulin therapy) to be significantly more frequent in patients affected by 
SSNHL and, later, Chang [25] found the same two issues to be independent risk factors for 
SSNHL, even if some conflicting data exist [37]. 
Mosnier [7] did not find any significant difference in the prevalence of cardiovascular 
risk factors (such as total lipids, diabetes mellitus, and smoking) among patients with SSNHL 
and the healthy controls, whereas reported that cardiovascular accidents (including 
myocardial infarction, stroke, transient ischemic attack) were significantly more prevalent in 
patients with SSNHL. 
In a case-control study, Ciccone et al. [38] found a significant lower flow-mediated 
dilation of the brachial artery and significant higher total cholesterol and low density 
lipoprotein cholesterol blood levels in patients affected by SSNHL compared to the healthy 
control group, suggesting a possible correlation between idiopathic SSNHL and vascular 
endothelial disorder. Previously, Balletshofer [39] found that 5 out of 6 patients affected by 
idiopathic SSNHL showed endothelial dysfunction, supporting an involvement of 
microcirculation disorders in the pathogenesis of hearing impairment. 
In a large cohort-control study, a higher risk of stroke (1.64 rate) has been estimated in 
patients with idiopathic SSNHL [40]. 
Keller [41] found an association between acute myocardial infarction and previous onset 
of SSNHL; Lin [42] defined SSNHL as a possible independent risk factor for myocardial 
infarction, in particular for patients aged ≥ 50 years. These observations may allow 
considering SSNHL as a possible predictor of major cardiovascular accidents [40, 41, 42]. 
In 2015, Pirodda speculated a possible involvement of a primary autonomic vascular 
dysregulation in the acute cochlear damage [43]. The primary vascular dysregulation 
syndrome, a condition of inappropriate vasoconstriction and vasodilatations of arteries, veins 
and capillaries, has been previously associated to several ophthalmological diseases [44]. In 
this syndrome low blood pressure, minor resistance to psychological stress, major sensitivity 
to pain, autonomic imbalance, migraine are often present [44] and have been linked also to 
the onset of a labyrinthine acute impairment [43]. Schulz and co-workers showed an altered 
autonomic regulation in patients affected by idiopathic SSNHL, particularly demonstrating 
modifications in their blood pressure regulation, in comparison to normal hearing patients 
[45, 46, 47]. Hultcrantz and collaborators [10] supposed that in case of reduced cochlear 
blood flow (i.e., in case of hypotension), cochlear circulation could depend on sympathetic 
tone. 
The involvement of cardiovascular risk factors in the pathogenesis of idiopathic SSNHL 
seems to be plausible, but remains a hypothesis to date. The role of cardiovascular risk factors 
in hearing threshold recovery after a SSNHL is also unclear [48]. 

Cardiovascular Risk Factors and Sensorineural Hearing Loss 
 
215
CONCLUSION 
 
Micro-vascular defects can damage the inner ear, since it is a sensory-neural organ with a 
sustained metabolic activity, supplied by a terminal blood flow [1]. Many Authors have 
investigated the role of cardiovascular risk factors in the pathogenesis of hearing loss and, in 
particular, of idiopathic SSNHL [16-30, 34]. Even if, to date, clear evidences do not support 
the vascular etiopathogenetic hypothesis, it is possible to consider hearing disorders as a 
potential sign of circulatory instability [2, 21]. In this regard, there are also evidences 
supporting links between SSNHL and major cardiovascular diseases such as stroke [40, 41, 
42]; a careful evaluation of cardiovascular risk factors should be recommended among these 
patients [21, 49]. 
For these reasons, in case of hearing impairment, Audiologist and Otolaryngologist 
should (i) investigate patients cardiovascular history, (ii) refer for blood tests, 
electrocardiogram and supra-aortic trunks ultrasound, (iii) possibly refer to a cardiologist for 
further diagnostic investigation and (iv) encourage patients to reduce modifiable 
cardiovascular risk factors. 
 
 
REFERENCES 
 
[1] 
Mudry, A.; Tange, R. A. The vascularization of the human cochlea its historical 
background. Acta Oto-Laryngologica, 2009; 129(Suppl. 561):3-16. 
[2] 
Pirodda, A.; Cicero, A. F.; Brandolini, C.; Borghi, C. Inner ear symptoms: can we use 
them to approach cardiovascular diseases? Intern. Emerg. Med., 2014; 9(8):825-7. 
[3] 
Gyo, K. Experimental study of transient cochlear ischemia as a cause of sudden 
deafness. World J. Otorhinolaryngol., 2013; 3:1-15. 
[4] 
Aimoni, C.; Bianchini, C.; Borin, M.; Ciorba, A.; Fellin, R.; Martini, A.; Scanelli, G.; 
Volpato, S. Diabetes, Cardiovascular Risk Factors and Idiopathic Sudden Sensorineural 
Hearing Loss: A Case-Control Study. Audiol. Neurotol., 2010; 15:111-115. 
[5] 
Rajati, M.; Azarpajooh, M. R.; Mouhebati, M.; Nasrollahi, M.; Salehi, M.; Khadivi, E.; 
Nourizadeh, N.; Hashemi, F.; Bakhshaee, M. Is Sudden Hearing Loss Associated with 
Atherosclerosis? Iran J. Otorhinolaryngol., 2016;28(86):189-95. 
[6] 
Schuknecht, H. F.; Benitez, J.; Beekhuis, J.; Igarashi, M.; Singleton, G.; Ruedi, L. The 
pathology of sudden deafness. Laryngoscope, 1962; 72:1142-57. 
[7] 
Mosnier, I.; Stepanian, A.; Baron, G.; Bodenez, C.; Robier, A.; Meyer, B.; Fraysse, B.; 
Bertholon, P.; Defay, F.; Ameziane, N.; Ferrary, E.; Sterkers, O.; de Prost, D. 
Cardiovascular and thromboembolic risk factors in idiopathic sudden sensorineural 
hearing loss: a case-control study. Audiol. Neurootol., 2011; 16(1): 55-66. 
[8] 
Marcucci, R.; Alessandrello Liotta, A.; Cellai, A. P.; Rogolino, A.; Berloco, P.; Leprini, 
E., Pagnini, P.; Abbate, R.; Prisco, D.; Cardiovascular and thrombophilic risk factors 
for idiopathic sudden sensorineural hearing loss. J. Thromb. Haemost., 2005; 3:929-
934. 

V. Corazzi, C. Bianchini, C. Aimoni et al. 
 
216
[9] 
Shi, X. Physiopathology of the Cochlear Microcirculation. Hear. Res., 2001; 282(1–
2):10–24. 
[10] Hultcrantz, E.; Linder, J.; Angelborg, C. Sympathetic effects on cochlear blood flow at 
different blood pressure levels. INSERM, 1977; 68:71Y8. 
[11] Seidman, M. D.; Quirk, W. S.; Shirwany, N. A. Mechanisms of alterations in the 
microcirculation of the cochlea. Ann. NY Acad. Sci., 1999; 884:226–32. 
[12] Dai, M.; Shi, X. Fibro-vascular coupling in the control of cochlear blood flow. PLoS. 
One., 2011; 6(6):e20652. 
[13] Chiarella, G.; Bono, F.; Cassandro, C.; Lopolito, M.; Quattrone, A.; Cassandro, E. 
Bilateral transverse sinus stenosis in patients with tinnitus. Acta. Otorhinolaryngol. 
Ital., 2012; 32(4):238-43. 
[14] Dietz, R. R.; Davis, W. L.; Harnsberger, H. R.; Jacobs, J. M.; Blatter, D. D. MR 
imaging and MR angiography in the evaluation of pulsatile tinnitus. AJNR, 1994; 
15:879-889. 
[15] Koenigsberg, R. A. Spontaneous pulsatile tinnitus secondary to a dural malformation 
not visualized by magnetic resonance angiography. Clinical imaging, 1996; 20:95-98. 
[16] Pirodda, A.; Brandolini, C.; Ferri, G. G.; Modugno, G. C.; Degli Esposti, D.; Borghi, C. 
Inner ear dysfunction of uncertain origin: a multidisciplinary approach could give 
something more. Med. Hypotheses, 2009; 72:188–189. 
[17] Oron, Y.; Elgart, K.; Marom,T.; Roth, Y. Cardiovascular risk factors as causes for 
hearing impairment. Audiol. Neurotol., 2014; 19:256-60. 
[18] Gates, G. A.; Cobb, J. L.; D’Agostino, R. B.; Wolf, P. A. The relation of hearing in the 
elderly to the presence of cardiovascular disease and cardiovascular risk factors. Arch. 
Otolaryngol. Head Neck Surg., 1993; 119(2):156-161. 
[19] Curhan, S. G.; Eavey, R.; Wang, M.; Stampfer, M. J.; Curhan, G. C. Body mass index, 
waist circumference, physical activity, and risk of hearing loss in women. Am. J. Med., 
2013; 126(12):1142.e1-1142.e8. 
[20] Linssen, A. M.; van Boxtel, M. P.; Joore, M. A.; Anteunis, L. J. Predictors of hearing 
acuity: cross-sectional and longitudinal analysis. J. Gerontol. A. Biol. Sci. Med. Sci., 
2014; 69(6):759-765. 
[21] Tan, H. E.; Lan, N. S. R.; Knuiman, M. W.; Divitini, M. L.; Swanepoel, D. W.; Hunter, 
M.; Brennan-Jones, C. G.; Hung, J.; Eikelboom, R. H.; Santa Maria, P. L. Associations 
between cardiovascular disease and its risk factors with hearing loss-A cross-sectional 
analysis. Clin. Otolaryngol., 2018; 43(1):172-181. 
[22] Brant, L. J.; Gordon-Salant, S.; Pearson, J. D.; Klein, L. L.; Morrell, C. H.; Metter, E. 
J.; Fozard, J. L. Risk factors related to age-associated hearing loss in the speech 
frequencies. J. Am. Acad. Audiol., 1996; 7: 152-160. 
[23] Oiticica, J.; Bittar, S. Metabolic disorders prevalence in sudden deafness. Clinics, 2010; 
65:1149-1153. 
[24] Fukushima, H.; Cureoglu, S.; Schachern, P. A.; Paparella, M. M.; Harada, T.; Oktay, 
M. F. Effects of type 2 diabetes mellitus on cochlear structure in humans. Arch. 
Otolaryngol. Head Neck. Surg., 2006; 132: 934-938. 

Cardiovascular Risk Factors and Sensorineural Hearing Loss 
 
217
[25] Chang, S. L.; Hsieh, C. C.; Tseng, K. S.; Weng, S. F.; Lyn, Y. S. Hypercholesterolemia 
is correlated with an increased risk of idiopathic sudden sensorineural hearing loss: a 
historical prospective cohort study. Ear. Hear., 2014; 35:256-261. 
[26] Simpson, A. N.; Matthews, L. J.; Dubno, J. R. Lipid and C-reactive protein levels as 
risk factors for hearing loss in older adults. Otolaryngol. Head Neck Surg., 2013; 
148(4):664-70. 
[27] Nash, S. D.; Cruickshanks, K. J.; Klein, R.; Klein, B. E.; Nieto, F. J.; Chappell, R.; 
Schubert, C. R.; Tsai, M. Y. Long-term variability of inflammatory markers and 
associated factors in a population-based cohort. J. Am. Geriatr. Soc., 2013; 61(8):1269-
1276. 
[28] Fischer, M. E.; Schubert, C. R.; Nondahl, D. M.; Dalton, D. S.; Huang, G. H.; Keating, 
B. J.; Klein, B. E.; Klein, R.; Tweed, T. S. Cruickshanks KJ10. Subclinical 
atherosclerosis and increased risk of hearing impairment. Atherosclerosis, 2015; 
238(2):344-9. 
[29] Makishima, K. Arteriolar sclerosis as a cause of presbycusis. Otolaryngology, 1978; 
86:322-326. 
[30] Pirodda, A.; Brandolini, C.; Borghi, C. The influence of systemic circulation on 
hearing: The reliability of a different impact of microcirculatory defects and 
atherosclerosis. Med. Hypotheses., 2016; 91:6-8. 
[31] Benjamin, E. J.; Blaha, M. J.; Chiuve, S. E.; Cushman, M.; Das, S. R.; Deo, R.; de 
Ferranti, S. D.; Floyd, J.; Fornage, M.; Gillespie, C.; Isasi, C. R.; Jiménez, M. C.; 
Jordan, L. C.; Judd, S. E.; Lackland, D.; Lichtman, J. H.; Lisabeth, L.; Liu, S.; 
Longenecker, C. T.; Mackey, R. H.; Matsushita, K.; Mozaffarian, D.; Mussolino, M. E.; 
Nasir, K.; Neumar, R. W.; Palaniappan, L.; Pandey, D. K.; Thiagarajan, R. R.; Reeves, 
M. J.; Ritchey, M.; Rodriguez, C. J.; Roth, G. A.; Rosamond, W. D.; Sasson, C.; 
Towfighi, A.; Tsao, C. W.; Turner, M. B.; Virani, S. S.; Voeks, J. H.; Willey, J. Z.; 
Wilkins, J. T., Wu, J. H., Alger, H. M.; Wong, S. S.; Muntner, P.; American Heart 
Association Statistics Committee and Stroke Statistics Subcommittee. Heart Disease 
and Stroke Statistics-2017 Update: A Report From the American Heart Association. 
Circulation, 2017; 135(10):e146-e603. 
[32] Cruickshanks, K. J.; Nondahl, D. M.; Dalton, D. S.; Fischer, M. E.; Klein, B. E.; Klein, 
R.; Nieto, F. J.; Schubert, C. R.; Tweed, T. S. Smoking, central adiposity, and poor 
glycemic control increase risk of hearing impairment. J. Am. Geriatr. Soc., 2015; 
63(5):918-24. 
[33] Frisina, S. T.; Mapes, F.; Kim, S.; Frisina, D. R.; Frisina, R. D. Characterization of 
hearing loss in aged type II diabetics. Hear. Res., 2006; 211(1-2):103-13. 
[34] Trune, D. R.; Nguyen-Huynh, A. Vascular Pathophysiology in Hearing Disorders. 
Semin. Hear., 2012; 33(3):242-250. 
[35] Ballesteros, F.; Alobid, I.; Tassies, D.; Reverter, J. C.; Scharf, R. E.; Guilemany, J. M.; 
Bernal-Sprekelsen, M. Is there an overlap between sudden neurosensorial hearing loss 
and cardiovascular risk factors? Audiol. Neurootol., 2009; 14:139-145. 

V. Corazzi, C. Bianchini, C. Aimoni et al. 
 
218
[36] Capaccio, P.; Ottaviani, F.; Cuccarini, V.; Bottero, A.; Schindler, A.; Cessana, B. M.; 
Censuales, S.; Pignataro, L. Genetic and acquired prothrombotic risk factors and sudden 
hearing loss. Laryngoscope, 2007; 117: 547–551. 
[37] Rudack, C.; Langer, C.; Stoll, W.; Rust, S.; Walter, M. Vascular risk factors in sudden 
hearing loss. Thromb. Haemost., 2006; 95(3):454-61. 
[38] Ciccone, M. M.; Cortese, F.; Pinto, M.; Di Teo, C.; Fornarelli, F.; Gesualdo, M.; 
Mezzina, A.; Sabatelli, E.; Scicchitano, P.; Quaranta, N. Endothelial function and 
cardiovascular risk in patients with Idiopathic Sudden Sensorineural Hearing Loss. 
Atherosclerosis., 2012; 225(2):511-6. 
[39] Balletshofer, B. M.; Stock, J.; Rittig, K.; Lehn-Stefan, A.; Braun, N.; Burkart, F.; 
Plontke, S.; Klingel, R.; Häring, H. U. Acute effect of rheopheresis on peripheral 
endothelial dysfunction in patients suffering from sudden hearing loss. Ther. Apher. 
Dial., 2005; 9(5): 385-90. 
[40] Lin, H. C.; Chao, P. Z.; Lee, H. C. Sudden sensorineural hearing loss increases the risk 
of stroke: a 5-year follow-up study. Stroke, 2008; 39:2744Y8. 
[41] Keller, J. J.; Wu, C. S.; Kang, J. H.; Lin, H. C. Association of acute myocardial 
infarction with sudden sensorineural hearing loss: a population-based case-control 
study. Audiol. Neurootol., 2013; 18(1): 3-8. 
[42] Lin, C.; Lin, S. W.; Lin, Y. S.; Weng, S. F., Lee, T. M. Sudden sensorineural hearing 
loss is correlated with an increased risk of acute myocardial infarction: a population-
based cohort study. Laryngoscope, 2013; 123(9):2254-8. 
[43] Pirodda, A.; Brandolini, C.; Cassandro, E.; Borghi, C. Primary vascular dysregulation 
syndrome: Possible implications for inner ear acute diseases? Med. Hypotheses., 2015; 
85(5):586-7. 
[44] Flammer, J.; Konieczka, K.; Flammer, A. J. The primary vascular dysregulation 
syndrome: implications for eye diseases. EPMA J., 2013; 4(1):14. 
[45] Schulz, S.; Witt, K.; Fischer, C.; Bär, K. J.; Ritter, J.; Guntinas-Lichius, O.; Voss, A. 
Altered cardiovascular coupling in patients with sudden sensorineural hearing loss in 
comparison to healthy subjects. Conf. Proc. IEEE. Eng. Med. Biol. Soc., 2013; 2013: 
3933Y6. 
[46] Schulz, S.; Ritter, J.; Oertel, K.; Witt, K.; Bär, K. J.; Guntinas-Lichius, O., Voss, A. 
Quantification of autonomic regulation in patients with sudden sensorineural hearing 
loss. Auton. Neurosci., 2013; 178:9Y14. 
[47] Schulz, S., Ritter, J.; Oertel, K.; Witt, K.; Bär, K. J.; Guntinas-Lichius, O.; Voss, A. 
Altered autonomic regulation as a cardiovascular risk marker for patients with sudden 
sensorineural hearing loss. Otol. Neurotol., 2014; 35(10):1720-9. 
[48] Ciorba, A.; Hatzopoulos, S.; Bianchini, C.; Iannini, V.; Rosignoli, M.; Skarzynski, H.; 
Aimoni, C. Idiopathic sudden sensorineural hearing loss: cardiovascular risk factors do 
not influence hearing threshold recovery. Acta. Otorhinolaryngol. Ital., 2015; 
35(2):103-9. 
 

Cardiovascular Risk Factors and Sensorineural Hearing Loss 
 
219
[49] Haremza, C.; Klopp-Dutote, N.; Strunski, V.; Page, C. Evaluation of cardiovascular 
risks and recovery of idiopathic sudden sensorineural hearing loss in hospitalised 
patients: comparison between complete and partial sudden sensorineural hearing loss. J. 
Laryngol. Otol., 2017; 131(10):919-924. 


In: Encyclopedia of Audiology and Hearing Research 
ISBN: 978-1-53617-702-2 
Editors: Erno Larivaara and Senja Korhola 
© 2020 Nova Science Publishers, Inc. 
 
 
 
 
 
 
 
Chapter 17 
 
 
 
AUDIOLOGY, HEARING AIDS  
AND COCHLEAR IMPLANTS 
 
 
Deborah L. Carlson*, PhD and Carol L. Ross, AuD 
Department of Otolaryngology, University of Texas Medical Branch,  
Galveston, TX, US 
 
 
HEARING 
 
 
In 2008, MarkeTrak, a well-known research group estimated that 1/10 individuals 
complain of hearing loss.  
 
In 2012, the World Health Organization (WHO) estimated that 1/3 of individuals 
over the age of 65 had significant (i.e., >40 dB HL) hearing loss; 17% of those 
individuals lived in the USA.  
 
In 2014, researchers from the U.S. National Center for Health Statistics reviewed 
self-reported hearing health data from the National Health Survey and found that 
hearing problems were reported by 43% of participants over age 70 and by 19% of 
participants between the ages of 40-69. Men attributed their hearing loss to noise and 
women attributed their hearing loss to age. 
 
Age-related hearing loss (Presbyacusis): 
 
23% chance of age-related hearing loss in men and women aged 60-69, and a 
48% chance of age-related hearing loss in men and women aged 70-79.  
 
In adults 50-69 years of age, greater threshold shifts occurred in the 3000-8000 
Hz range. In adults 70-89 years of age, greater threshold shifts occurred in the 
500-2000 Hz range. 
 
Men typically have greater hearing loss as compared to women at all ages. 
                                                        
* Corresponding Author’s Email: dlcarlso@UTMB.EDU. 

Deborah L. Carlson and Carol L. Ross 
 
222
 
The rate of threshold shift in men aged 48-59 was 0.4 dB per year at 500 Hz and 
approximately 1.6 dB per year at 8000 Hz, while the reverse was true in men age 
80 and above (i.e., 2.1 dB per year at 500 Hz and 1.05 dB at 8000 Hz). 
 
Despite the creation of the Occupational Safety and Health Administration (OSHA) in 
1971, the occurrence of noise-induced hearing loss (NIHL) continues to be an issue in 
the United States. In 2010, the Bureau of Labor Statistics revealed that NIHL is the 
most commonly cited health condition among workers in manufacturing. Some facts 
pertinent to NIHL: 
 
The approximate resonant peak frequency of the external ear canal is 2800-3000 
Hz. 
 
Damage from noise exposure typically occurs at a frequency approximately ½ 
octave above the frequency of the offending noise. 
 
There is evidence that the middle frequencies of a broadband noise, as is typical 
of occupational noise, may be more hazardous to hearing.  
 
The greatest shift in threshold typically occurs at or around 4000 Hz; however, it 
may also occur at adjacent frequencies of 3000 and 6000 Hz when the frequency 
composition of the noise is not broadband. 
 
Damage is usually greatest during the first ten years of exposure. 
 
OSHA requires employers to have a hearing conservation program when 
workers are exposed to a time-weighted average noise level > 85 dBA in an 8 
hour period (Table 1).  
 
Table 1. OSHA Permissible Exposure Limits (29 CFR 1910.95) 
 
Permissible Exposure Limit (TWA) 
Maximum Exposure 
90 dBA 
8 hours 
95 dBA 
4 hours 
100 dBA 
2 hours 
105 dBA 
1 hour 
110 dBA 
½ hour 
115 dBA 
¼ hour 
 
 
In children, hearing loss is usually related to middle ear problems. Acute otitis media 
may occur at least once in approximately 80% of children before the age of 3, and at 
least three times in approximately 40% of children before the age of 3. Middle ear 
effusion may cause the following: 
 
Hearing losses that range between slight (i.e., 16-25 dB) to moderate (i.e., 41-55 
dB), dependent upon the level and viscosity of the middle ear effusion (MEE).  
 
Greater hearing loss in the high frequency range. 
 
A dampening of soft (i.e., 20-30 dB loud) high frequency speech sounds (i.e., /f/, 
/s/, /θ/) such that a child may find it difficult to recognize those sounds in 
conversational speech (i.e., 40-55 dB HL). 
 

Audiology, Hearing Aids and Cochlear Implants 
 
223
AUDIOLOGICAL EVALUATION: AIR AND BONE CONDUCTION 
 
 
The audiogram is a graph comprised of vertical and horizontal lines representing a) 
the frequencies most important for understanding speech (250-8000 Hz), and b) the 
decibel levels (-10 to 110 dB HL) at which said frequencies are heard by the 
individual being tested via either air conduction or bone conduction.  
 
Air conduction testing, with insert phones or headphones, reflects the total response 
of the hearing system, and is dependent upon the transmission of sound via the 
external ear, the tympanic membrane (TM), and the ossicular chain before it is 
delivered to the inner ear (i.e., cochlea/VIIIN/spiral ganglion).  
 
The combined influences of the head, the pinna, and the ear canal can amplify 
sounds within the 2000-4000 Hz range as much as 10-15 dB. 
 
Due to the difference in size between the TM and oval window, the leverage 
action of the ossicular chain (i.e., manubrium is 1.3 times longer than the arm of 
the incus) and the unique movement of the TM (i.e., more force on the umbo due 
to greater displacement of the TM on either side), the pressure exerted on the 
stapes/oval window is approximately 44:1. These effects result in an 
approximate 30 dB gain in sound pressure level at the stapes, which is necessary 
to overcome the dampening effect on sound being transmitted from the air-filled 
middle ear cavity to the fluid-filled cochlea. 
 
Bone conduction testing refers to the transmission of sound primarily to the inner ear 
via “distortion” of the skull from the vibration of a bone oscillator. This “distortion” 
is transmitted from the skull to the bony labyrinth and causes compression and 
expansion of the membranous labyrinth thereby stimulating the structures 
responsible for transducing the auditory signal into a neuro-electric signal the brain 
will recognize. 
 
Sound energy travels following the presentation of a bone-conducted signal to the 
skull by three major pathways. (This is important to know because it is the basis for 
changes in bone conduction scores dependent upon the status of the outer and middle 
ear.)  
 
Route #1: osseo-tympanic, the movement of the external ear canal walls 
produces sound energy that impinges on the TM 
 
Route #2: inertial-movement of the ossicular chain results in stimulation of the 
cochlea  
 
Route #3: distortional-the compression/expansion of the skull that results in 
movement of the basilar membrane and the outer and inner hair cells 
 
Carhart’s notch: A depression in the bone conduction score at 2000 Hz (a classic sign 
of otosclerosis). This phenomenon occurs due to a change in the inertial response of 
the middle ear system. Given that the resonant frequency of the ossicular chain is 
approximately 2000 Hz, fixation of the ossicular chain will result in a depression in 
the bone conduction score at that frequency.  

Deborah L. Carlson and Carol L. Ross 
 
224
 
A similar depression to Carhart’s notch can also be seen at other frequencies as a 
result of MEE, with a resulting improvement in bone conduction responses once the 
MEE has been resolved. 
 
If the outer ear is occluded, a low frequency bone conduction score can be artificially 
improved. This is known as the “occlusion effect”. Recall the three pathways of bone 
conducted energy. Route #1 is via the movement of the outer ear canal. If the outer 
ear canal is occluded, the low frequency bone conducted energy is trapped in the 
outer ear canal and sent on to the cochlea, falsely improving the low frequency bone 
conduction scores. If the outer ear canal is open, the low frequency energy escapes.  
 
There are approximately 12,000 outer hair cells and 3,500 inner hair cells in each 
cochlea. 
 
Outer hair cells are stimulated by soft sounds while inner hair cells are stimulated by 
incoming sounds of 40 – 60 dB SPL. 
 
Damage to the outer hair cells typically results in hearing loss in the 40 – 60 dB HL 
range. Hearing loss greater than 60 dB involves both outer and inner hair cell 
damage.  
 
Ninety-five (95%) of afferent cochlear nerve fibers arise from inner hair cells and 
carry information to the brain. Efferent fibers terminate on the outer hair cells and 
carry information from the brain back to the cochlea.  
 
 
AUDIOGRAM/SPEECH PERCEPTION/INTER-TEST CHECKS 
 
 
The Speech Detection Threshold (SDT) refers to the softest level at which the 
presence of speech is detected 50% of the time. 
 
The Speech Reception Threshold (SRT) refers to the softest level at which a speech 
signal (i.e., two-syllable highly redundant words known as Spondees) is identified 
50% of the time. 
 
The Word Recognition Test utilizes phonetically balanced words and estimates one’s 
ability to recognize speech at various sensation levels above the SRT. A “sensation 
level” (SL) refers to the total number of dB above a given pure-tone or speech 
threshold, at which the test stimuli is given. For example, a normal hearing 
individual, with an SRT of 10 dB HL, will likely achieve a score of 100% when word 
recognition testing is completed at 50 dB HL (aka 40 dB SL) re: his SRT. 
 
PEARL: The range of audibility between the softest and loudest speech sounds is 
approximately 30-35 dB. 
 
The SRT should be within 5-7 dB of the three-frequency average of the pure tone 
thresholds at 500, 1000, and 2000 Hz (i.e., the Pure Tone Average or PTA). A spread 
of 8-10 dB may occur in individuals with reduced word recognition abilities due to 
moderately severe or greater hearing loss.  

Audiology, Hearing Aids and Cochlear Implants 
 
225
 
Differences in pure tone responses between tests should not vary by more than 5-10 
dB (i.e., test-retest). 
 
PEARL: Word recognition abilities are known to be poor (25-50%) at lower 
sensation levels (i.e., 5-10 SL) with respect to the SRT. This is relevant when we 
obtain a word recognition score of 75% or greater at reduced sensation levels when 
testing an individual with a suspected non-organic hearing loss.  
 
 
NATURE OF HEARING LOSS 
 
 
Conductive: Air conduction (AC) thresholds are below normal hearing levels and 
bone conduction thresholds are normal. Air Bone gap >15 dB. 
 
Sensorineural: Both AC and bone conduction (BC) scores are below normal hearing 
levels with air-bone gaps of <10 dB. 
 
Mixed: Both AC and BC thresholds are outside of normal limits and there is a 
difference between the air and bone conduction thresholds of >15 dB, or a hearing 
loss within an ear has both conductive and sensory components. 
 
PEARL: Every 10 dB increase in sound pressure level (SPL) is equivalent to a 10-
fold increase in sound intensity, which generally equates to a doubling in loudness. A 
20 dB increase in SPL is equivalent to 100-fold increase in sound intensity, which 
generally equates to 4x the loudness. 
 
 
AUDIOMETRIC FINDINGS FOR DIFFERENT AGES/PATHOLOGIES 
 
 
Presbyacusis is typically sensorineural and initially gently sloping; however, the 
slope becomes steeper with increased age (i.e., over 60), with the greatest depression 
seen at 8000 Hz. 
 
NIHL may be a sloping SNHL or a notched SNHL at 3000, 4000, or 6000 Hz. 
 
Hearing loss secondary to middle ear disease is often a flat conductive hearing loss 
(CHL) but can also slope slightly in the low and high frequency ranges. 
 
Perforations of the TM can result in no hearing loss or up to a moderate CHL 
dependent upon the size of the TM perforation and the volume of the middle ear 
space. The highest hearing loss with TM perforation and no ossicular discontinuity 
does not typically exceed 50 dB HL. 
 
A vestibular schwannoma may initially cause no hearing loss or a slowly progressive 
asymmetric high frequency SNHL. There can also be a low or mid-frequency SNHL 
in approximately 1/3 of individuals with vestibular schwannoma.  
 
 
 

Deborah L. Carlson and Carol L. Ross 
 
226
IMMITTANCE BATTERY 
 
 
An evaluation of hearing is not complete without immittance testing (i.e., the 
measurement of ear canal volume, tympanometry and acoustic reflexes). 
 
Tympanometry: Equivalent ear canal volumes, static compensated acoustic 
admittance, tympanometric peak pressure, and tympanometric width (also known as 
gradient). 
 
Acoustic reflex testing: Stapedius muscle reflexes. 
 
Tympanometry utilizes measurements of Tympanic Membrane (TM) “mobility” (or 
more accurately “admittance” and “impedance”) to infer middle ear function while 
the acoustic reflex test confirms the neural integrity of the VII and VIII nerve 
pathways in the low brainstem. Acoustic reflex testing can also help determine if 
there is a neural component to a SNHL. 
 
Tympanometry and ear canal measurements are initiated by sealing the ear canal 
with a specially designed probe containing a manometer, a speaker, and a 
microphone. 
 
The manometer increases the air pressure in the ear canal to +200daPa so that 
TM admittance of acoustic energy is negligible. While the speaker is 
simultaneously emitting a 226 Hz tone, a measurement of equivalent ear canal 
volume is made. 
 
Ear canals volumes may range from 0.30-1.00 ml in children and from 0.65-1.75 
ml in adults.  
 
The air pressure is then decreased from +200 daPa to 0 daPa. 
 
In a normally functioning ear, as the air pressure is decreasing, the TM 
admittance of acoustic energy is increasing, resulting in an upward moving 
tracing on the tympanometric graph. 
 
Maximum displacement of the TM (or peak compensated static acoustic 
admittance) should occur when the air pressure in the outer ear canal is similar to 
that within the middle ear space (Normal range is approximately -100 daPa to 
+50 daPa). 
 
The expression peak “compensated” static acoustic admittance indicates the ear 
canal admittance and volume have been subtracted from the overall admittance 
value obtained at the point of maximum TM displacement. 
 
The pressure at which maximum displacement of the TM is obtained is 
considered the tympanometric pressure peak. 
 
Once a peak is obtained, the air pressure is again increased from 0 daPa to -300 
daPa (more negative values may be utilized during tests of ET function), once 
again decreasing TM admittance of acoustic energy, and resulting in a downward 
moving tracing on the tympanometric graph. 

Audiology, Hearing Aids and Cochlear Implants 
 
227
 
Tympanometric width refers to the range of pressure at the approximate middle 
of the tympanometric tracing. A wider width and reduced admittance (i.e., 
mobility) are consistent with middle ear disorder. 
 
Tympanometry typically results in five commonly known tracings, developed by 
Liden and Jerger. 
 
 
Figure 1. Common tympanogram types. Used with permission from https//:entokey.com/acoustic-
immittance-assessment. 
 
Acoustic reflex testing depends on normal TM mobility and middle ear pressure.  
 
Utilizes the same probe as that used for tympanometry.  
 
Is typically performed utilizing 500, 1000, and 2000 Hz tones.  
 
Technique: A loud pure tone or pulsed tone is presented at 75-110 dB HL. The 
loud tone elicits the contraction of the stapedius muscle (i.e., the reflex), which in 
turn pulls the stapes and hence stiffens the ossicular chain, decreasing TM 
admittance (“compliance”), and the vibratory pattern received by the inner ear. 
 
Normal acoustic reflex responses typically fall within 80-100 dB HL (or 0-85 dB 
SL re: pure tone thresholds at the frequencies tested). 
 
A 3-neuron pathway that includes the ipsilateral VIIIN neurons, the ventral 
cochlear nuclei, and the VIIN motor nuclei primarily supports ipsilateral acoustic 
reflexes. Note: All nerve fibers from the cochlear nuclei will pass through the 
trapezoid body. Some of the nerve fibers will travel from the trapezoid body to the 
ipsilateral superior olivary complex before continuing to the VIIN motor nuclei, 
resulting in a 4-neuron pathway. 
 
Contralateral acoustic reflexes are always dependent upon a 4-neuron pathway 
inclusive of the ipsilateral VIIIN neurons, the ipsilateral ventral cochlear nuclei, 
the ipsilateral superior olivary complex and the contralateral VIIN nuclei. 
 
Elevated contralateral acoustic reflex responses (i.e., > 100 dB HL) are uncommon 
in normal hearing (-10 to 15 dB HL), slight hearing loss (16-25 dB HL), or mild 

Deborah L. Carlson and Carol L. Ross 
 
228
hearing loss (26-40 dB HL), and are expected in hearing losses at or greater than 
45 dB HL. 
 
 
SPECIAL TESTS 
 
 
A Stenger test is particularly useful in verifying a non-organic hearing loss. A signal 
is presented to the “better ear” at a level slightly above the volunteered threshold 
(i.e., the level at which the patient has chosen to respond versus the level at which the 
signal is just barely audible) while the same frequency signal is presented to the 
“poorer ear” at a level slightly below the volunteered threshold. If there is an actual 
hearing loss, the listener should respond because the signal is technically louder in 
the “better ear.” However, if the “poorer ear” is better than volunteered, the signal 
may be perceived as louder and the listener will not respond. 
 
Oto-acoustic emissions (OAE): Are a pre-neural by-product of the motile action of 
the outer hair cells as they respond to sound. They can be measured in the outer ear 
canal, provided there is normal outer hair cell function, middle ear space, and and 
minimal debris in the outer ear canal. The presence of OAE’s infer normal sensory 
function within the cochlea. 
 
OAE testing has expanded our ability to evaluate the very young, confirm or 
disprove atypical pure tone configurations, and monitor for changes in hearing due to 
ototoxicity before there is a change in audiometric findings.  
 
There are two types of clinically used evoked OAE’s: Transient Evoked Otoacoustic 
Emissions (TEOAE’s) and Distortion Product Evoked Otoacoustic Emissions 
(DPOAE’s) 
 
TEOAE’s are stimulated by transient clicks (wideband) and typically present in 
individuals with a hearing loss no greater than 30 dB HL. Present TEOAEs in an 
individual with SNHL may herald either a retro-cochlear pathology or a non-organic 
hearing loss. 
 
DPOAE’s are a bi-product of the simultaneous delivery of 2 strategically selected 
pure-tones to the cochlea. The first pure tone is known as “f1” and the second is 
known as “f2” with “f1” being a lower frequency. The ratio of “f1” to “f2” is 1.20. The 
“distortion product” that results from their simultaneous presentation typically occurs 
within the frequency range of 2f₁-f₂. 
 
Of note: The “distortion product” is not the value that best correlates with estimated 
responses on the audiogram: “f2” is. A “distortion product” can actually occur within 
an area of the cochlea that has damaged hair cells, as it is the result of basilar 
membrane movement due to the interaction of two other entities, and not a directly 
elicited response from that region of the cochlea. 
 
DPOAE’s may be used to look at outer hair cell function with hearing loss up to 45 – 
55 dB HL.  

Audiology, Hearing Aids and Cochlear Implants 
 
229
 
The presence of a pressure equalization tube in the TM reduces the chances of 
obtaining TEOAEs by 50%. 
 
Auditory brainstem response (ABR) tests retro-cochlear function and is the 
composite result of electrophysiological responses (i.e., a change in resting potentials 
in response to an auditory stimulus) from several sites along the auditory pathway. It 
is obtained by placing electrodes behind the mastoid and on the high forehead or 
vertex. The ABR occurs within the first 10 milliseconds following the stimulus 
presentation.  
 
The evoked potentials may be greater in voltage at some points along the auditory 
pathway (i.e., “peaks”) as compared to others (“troughs”). These responses are very 
repeatable in a normal hearing person and can be represented graphically by a series 
of waveforms. 
 
Although there is the potential for 7 peaks within the auditory brainstem response, 
waves I-V are typically the most prominent, with waves I, III, and V primarily used 
in the analyses of the ABR. 
 
Two primary indices utilized to describe or evaluate ABR waveforms are absolute 
and inter-peak latencies (i.e., time of occurrence of each waveform and the intervals 
between each waveform in msec.) and amplitude (i.e., total response in microvolts). 
 
Of equal importance are the inter-aural differences between wave V absolute 
latencies (a normal difference would be 0.3-0.4 msec) and the shift in each wave V 
absolute latency at an increased click rate (a normal shift = 0.1 msec increase in wave 
V absolute latency per each 10 point increase in stimulus rate). 
 
With decreases in stimulus intensity, the amplitudes of waveforms will decrease and 
the latencies will increase. When searching for a threshold response, early 
waveforms will no longer be identifiable. The lowest intensity that Wave V can be 
identified is considered the eHL threshold. 
 
CHL and SNL can either influence the time of occurrence of the ABR waveforms or 
result in their total absence (e.g., CHL results in the prolongation of all waveform 
latencies and/or a reduction in amplitudes while a significant high frequency SNHL 
can result in the absence of wave I). 
 
The dB values utilized when reporting ABR responses do not have a one-to-one 
correlation with an audiogram. A “0” dB ABR stimulus correlates with 0-25 dB HL. 
Thus, 0 dB nHL for ABR testing is representative of an average response from a pool 
of normal listeners for a given stimulus. This phenomenon is due in part to the 
difference in stimuli utilized to evoke the ABR. 
 
Electrocochleography (ECOG) refers to the measurement of neuroelectric events that 
are produced by the cochlear structures in response to acoustic stimulation. The 
response includes the cochlear microphonic, the summating potential (SP), a DC 
current, and the whole-nerve action potential (AP), an AC current by the auditory 
nerve. In Meniere’s disease, the elasticity of the basilar membrane is believed to be 
affected resulting in a large SP/AP amplitude ratio.  

Deborah L. Carlson and Carol L. Ross 
 
230
HEALTH CONDITIONS AND HEARING LOSS 
 
 
Cardiovascular disease: low frequency SNHL may be an indicator.  
 
Chronic kidney disease: results in a higher prevalence of hearing loss.  
 
Diabetes: The 1999-2004 National Health and Nutrition Examination suggested a 
high occurrence of hearing loss among diabetic participants; however, more than 
50% of participants also had high cholesterol, and/or hypertension, and 20% had 
coronary artery disease.  
 
Cognitive function: Unaided hearing loss has been associated with a greater rate of 
decline (i.e., 30-40%) in cognitive function in older adults with hearing loss as 
compared to older adults with normal hearing.  
 
 
HEARING AIDS 
 
 
Hearing aids and assistive listening device selections are individualized to patient’s 
communication and lifestyle needs and are assessed during a hearing aid evaluation.  
 
Common considerations include: degree and nature of hearing loss, dynamic range, 
speech-in-noise and/or localization abilities, complexity of listening situations, 
hearing handicap, dexterity, phone use, and concomitant medical conditions.  
 
 
TERMINOLOGY 
 
 
Dynamic range: Range of hearing between a person’s hearing threshold and 
uncomfortable loudness/loudness discomfort level. 
 
Gain: difference in sound pressure between the amount of sound coming in to the 
hearing aid and the resulting sound as it leaves the hearing aid receiver (i.e., output 
minus input). 
 
Output: the maximum power output (MPO) or saturation sound pressure level 
(SSPL) of the hearing aid (i.e., the maximum sound level that the hearing aid can 
produce).  
 
Frequency Response Curve: the range of frequencies in which sound is amplified. 
 
Compression: variance in gain as input level changes. 
 
Kneepoint: Level of sound that result in a reduction in the gain of a signal, 
relative to an increase in input.  
 
Compression ratio: Amount of change in input relative to the resulting change in 
output.  
 
Attack and release: Amount of time it takes the hearing aid circuit to respond to 
changes in input.  

Audiology, Hearing Aids and Cochlear Implants 
 
231
 
Linear compression: Gain stays the same as input changes (1:1 relationship) until 
maximum output of hearing aid is reached.  
 
Output limiting: Peak clipping when the hearing aid reaches limits of 
amplification. 
 
Input compression: Hearing aid compresses a signal before it reaches the volume 
control. Changes in volume control affect both gain and output.  
 
Output compression: Hearing aid compresses a signal after it reaches the volume 
control. Changes in volume control affect gain not output.  
 
Wide Dynamic Range Compression (WDRC): Compression activates throughout 
the dynamic range, typically allows greatest gain for soft sounds and less gain 
for loud sounds.  
 
Acoustic feedback: Oscillations resulting when sound produced by the hearing aid 
receiver reaches the microphone and is re-amplified. Resulting sound is a high-
pitched squeal.  
 
Adaptive feedback suppression: Hearing aid detects feedback and applies an 
algorithm to reduce it. Methods used include notch filters, phase cancellation, or a 
combination thereof.  
 
Vent: Opening or bore made in an earmold or custom hearing aid to allow the 
passage of sound and/or air into an ear canal which is otherwise blocked by the 
device. Venting offers acoustic changes to the hearing aid response and can offer 
pressure release or aeration to the ear. A shorter vent with large diameter is most 
effective at reducing low frequency output.  
 
 
HEARING AID COMPONENTS/STYLES 
 
 
Traditional amplification includes component parts of a microphone, digital filters, 
receiver and power source.  
 
Analog hearing aids have been replaced by digital technology.  
 
Earmolds: Custom earmolds are made from an impression of the hearing aid user’s 
ear and typically result in a better fit. Non-custom molds (eg domes) can be used 
with RITE/RIC and slim- or thin-tube hearing aids. 
 
Behind-the-ear (BTE) hearing aid – all components are housed in the hearing aid that 
sits behind the ear and is coupled via a tube to a custom earmold. BTE’s hearing aids 
are commonly used for those with severe-to-profound hearing loss, excessive 
cerumen production, ear drainage, and poor vision or dexterity. BTE’s are also used 
with children and allow coupling to Frequency Modulation (FM) listening systems.  
 
Slim- or Thin-Tube – A thin tube can be connected to a BTE hearing aid for a mild 
or moderate hearing loss with normal low frequency hearing. 
 
Receiver-in-the-ear (RITE) aka Receiver in the canal (RIC) – the microphone, 
amplifier and power supply are housed in the hearing aid which generally sits on top 

Deborah L. Carlson and Carol L. Ross 
 
232
of and slightly behind the ear and is coupled to a receiver inside the ear canal. This 
style provides an “open” fit with the receiver covered by a non-custom earmold or 
dome. For more severe hearing loss, the receiver can be covered with an occluding 
dome or can be encased in a custom earmold to prevent feedback. RITE and RIC 
hearing aids can be fit from mild to severe hearing loss including normal to steeply 
sloping hearing loss. RITE/RIC hearing aids are generally covered by the superior 
portion of the pinna and are most preferred for improved directional hearing as well 
as cosmetic appeal.  
 
In–the-Ear (ITE) – all components are housed into a custom fit hearing aid that fills 
the concha and helix portions of the ear. This style is most appropriate for those with 
a moderate to severe hearing loss who desire a single piece. Those with limited fine 
motor skills find the ITE easier to place.  
 
In-the-Canal (ITC) - all components are housed in a custom fit hearing aid that fills 
the concha and fits up to a severe hearing loss.  
 
Completely-in-the-canal (CIC) – all components are housed into a custom fit hearing 
aid that fits deeply in the canal placing the receiver closer to the eardrum. This 
hearing aid is for high frequency hearing loss and does not provide adequate gain for 
low frequency loss. CIC and mini CIC hearing aids are preferred by some for 
cosmetic advantages.  
 
Bone conduction - BTE hearing aids can be modified to power a bone oscillator for 
severe CHL. Developments in osseointegrated aka bone-anchored hearing aids 
(BAHA) have nearly replaced the need for or use of traditional bone conduction 
devices.  
 
Custom hearing aids (e.g., CIC, ITC, ITE) have a greater chance of feedback due to 
the short distance between the receiver and microphone. Amplified sound leaking 
from the ear has a direct path back into the microphone of the hearing aid. BTE and 
RITE hearing aids can also have feedback with a poorly fit earmold.  
 
When fit binaurally, hearing aids offer advantages such as: a) improved localization, 
b) a 2-3 dB signal to noise ratio improvement due to elimination of the head shadow 
effect and binaural squelch, and c) enhanced hearing due to summation between ears. 
 
 
CROS/BICROS 
 
 
A wireless contralateral routing of signal (CROS) system utilizes a microphone and 
transmitter behind the poorer ear routing sound to a receiver on the better, normal 
hearing, ear.  
 
CROS (Contralateral Routing of Signal) hearing aid is used for unilateral SNHL 
hearing loss. Sound is transmitted from the poor ear to the normal hearing ear.  
 
A Bi-CROS hearing system is utilized when hearing loss also exists in the better ear. 
In this case, the receiving instrument also functions as a hearing aid to amplify sound 
to the better ear.  

Audiology, Hearing Aids and Cochlear Implants 
 
233
OSSEOINTEGRATED DEVICES (OID)/ AKA BONE ANCHORED 
HEARING AIDS (BAHA) 
 
 
These devices provide bone conducted sound via direct vibration coupled to a 
titanium fixture or magnetic coupling that has been surgically implanted into the 
skull. They are appropriate for CHL (e.g., microtia, atresia, stenosis, chronic 
drainage) and mixed hearing loss with bone conduction scores no worse than a 
moderate severity level. For patients under the age of five whom do not yet have the 
appropriate bone thickness, the bone oscillator portion of the device can be coupled 
to a soft headband.  
 
OID/BAHA devices can be effective for single-sided deafness (SSD) by which the 
sound from the poorer ear is transmitted through the skull to the better cochlea. This 
is most successful in those with normal hearing in the “good ear”.  
 
 
MIDDLE EAR IMPLANTABLE HEARING AIDS 
 
 
Maxum is a partially implantable hearing device that consists of a rare-earth magnet 
implanted on the middle ear bones and works with a canal style processor that uses 
electromagnetic energy to vibrate the implant. Working without a speaker, the 
Maxum has less distortion, reduces feedback and minimizes occlusion. The ideal 
candidate is an adult with moderate to severe sensorineural hearing loss  
 
The Esteem hearing aid is a fully implantable device. The device has 3 components, 
a sensor that picks up vibrations from the incus, a driver that delivers increased 
mechanical energy to the stapes, and the sound processor that processes and 
amplifies the acoustic signal. The Esteem fits adults with moderate to severe SNHL 
and requires normal TM, middle ear, and Eustachian tube function. Additionally, the 
middle ear space must be adequate in size to house the implant. Cosmetic and 
lifestyle advantages (e.g., swimming, showering) are appealing; however, surgery is 
required every few years to change the battery. 
 
 
COCHLEAR IMPLANTS (CI) 
 
 
The CI processor is an external device that works with the implant. Components 
include a microphone to pick up sound, a sound processor that converts sound to an 
electric signal that is sent to a headpiece to stimulate the internal implant.  
 
CI processors are available in multiple styles including BTE processors, a smaller off 
the ear style processor that is fully contained in the headpiece, and a body worn 
waterproof device. US FDA approved CI’s are currently available from Advanced 
Bionics, Cochlear and MedEl.  
 

Deborah L. Carlson and Carol L. Ross 
 
234
CANDIDACY 
 
 
A 3 – 6 month hearing aid trial is recommended prior to implantation with exceptions 
for special circumstances (e.g., meningitis due to cochlear ossification).  
 
General candidacy for adults (18+ years): moderate to profound SNHL in both ears; 
limited benefit from appropriately fit binaural amplification defined by scores of < 
50% sentence recognition in the ear to be implanted and < 60% in better ear or 
binaurally. Medicare coverage currently has a stricter definition of candidacy, <40% 
in best-aided condition. 
 
Candidacy for children (2 – 17 years): severe to profound SNHL bilaterally, limited 
benefit from binaural amplification with appropriately fit hearing aids.  
 
Candidacy for children (12 -24 mos.): profound SNHL, limited benefit form binaural 
amplification trial including failure to reach auditory developmental milestones.  
 
Off label use of implants is increasingly considered as technology improves (eg <12 
months of age, unilateral hearing loss).  
 
The Minimal Speech Test Battery (MSTB) is the recommended test battery, for 
adults, by all three US FDA approved CI companies for use in cochlear implant 
candidacy and post-implant testing. The MSTB consists of AZ Bio sentences in quiet 
and in noise, CNC monosyllabic words in quiet, and BKB-SIN sentences in noise 
test. A Pediatric AZ-Bio test is also available.  
 
CI’s can be implanted in one or both ears (bilateral) or work in conjunction with a 
hearing aid in the opposite ear (bimodal). Hybrid and Electrical Acoustic Stimulation 
are combined cochlear implant and hearing aid solutions built into a single processor. 
These devices allow acoustic energy to be used for the better hearing in the low 
frequencies and electrical stimulation for the severe-to-profound hearing loss in the 
mid and high frequencies. 
 
Hybrid CI’s are available for adults (18 years +) who have aidable hearing in the low 
frequencies (e.g., through 500 Hz) and a severe-to-profound hearing loss in the mid 
to high frequencies. General candidacy considers recognition of CNC words between 
10 and 50% in the poor ear and <80% in the better ear, using appropriately fit 
hearing aids.  
 
Electric Acoustic Stimulation CI’s are available for adults (18 years +) with normal 
to moderate SNHL hearing loss in the low frequencies sloping to severe-to-profound 
hearing loss in the high frequencies with CNC word scores of <60% in the ear to be 
implanted.  
 
 
ASSISTIVE LISTENING DEVICES (ALD’S) 
 
 
ALD’s can be used with all forms of amplification or with special receivers for those 
who do not wear hearing aids.  

Audiology, Hearing Aids and Cochlear Implants 
 
235
 
A variety of frequency modulated (FM) and infrared devices are available to work 
with or without amplification to improve the signal to noise (SNR) ratio in difficult 
listening situations (e.g., classrooms, TV). These are most commonly used with kids 
in classrooms.  
 
Personal FM systems wirelessly transmit sound via a receiver attached to a BTE 
hearing aid or cochlear implant, or through a neckworn hearing loop that connects to 
a custom hearing aid via a telecoil.  
 
SNR ratios are improved with FM systems by separating the microphone from the 
receiver. The speaker (e.g., the teacher) wears the microphone and the listener wears 
the receiver (e.g., hearing aid, ear level receiver, and headset). 
 
Childhood mild hearing loss, particularly transient or unilateral, may be treated with 
personal or classroom FM systems. FM systems are wire-free, portable, and are not 
obstructed by physical barriers therefore can be used indoors and outdoors. Personal 
FM systems have a distance of about 50 feet (up to max of 300 feet). A disadvantage 
of FM systems is interference from other signals using radio waves in the same 
frequency range (e.g., radios, walkie talkies).  
 
Permanent mild hearing loss may be better treated with hearing aids. Classroom FM 
systems (aka Classroom Audio Distribution Systems) provide an improvement in the 
signal to noise ratio for everyone in the classroom. These systems assist students in 
hearing above typical classroom noise (e.g., shuffling papers, noise from fans or 
ventilation systems, moving of chairs, students talking) and are helpful for those with 
mild or transient hearing loss and auditory processing disorders.  
 
FM signals are wireless and transmitted across a large area such as a classroom, 
living room, auditorium or church. 
 
Infrared assistive listening devices are wire-free and operate on line of site. They 
have excellent transmission of music and speech (e.g., TV listening). Disadvantages: 
can only be used inside, AC powered so limited portability, and signal easily 
disrupted by objects within the line of site.  
 
Bluetooth devices transmit directly to the receiver via wireless radio waves. A 
variety of Bluetooth devices connect to BTE and RITE hearing aids and CI’s via a 
streaming device. Bluetooth transmission is limited to 40 – 60 feet.  
 
Commonplace Bluetooth devices stream sound between a sound source (e.g., cell 
phone, TV, remote microphone) and the hearing aid. The interfacing device (ie 
streamer) receives sound from the sound source and transmits that sound to the 
hearing aid. 
 
Advanced hearing aid technology now allows direct Bluetooth connection between 
the hearing aids and the signal source (e.g., cell phone).  
 
Hearing Loops are special sound systems placed around a perimeter of a room or 
large public area and transmits magnetic energy to telecoil-equipped hearing aids, 
cochlear implants or neck loops with earphones.  
 

Deborah L. Carlson and Carol L. Ross 
 
236
REFERENCES 
 
Abrams, HB and Kihm, J. An Introduction to MarkeTrak IX: A New Baseline for the Hearing 
Aid Market. Hearing Review. 2015; 22(6):16.  
Ahmad, I and Pahor, AI. Carhart’s notch: a finding in OM with effusion. Int Journ of Ped 
Otorhinolaryngol. 2002;64:165-170.  
Cruikshanks, KJ, Tweed, TS, Wiley, TL, Klein, BE, Klein, R, Chappell, R, et al. The 5-year 
incidence and progression of hearing loss. Arch Otolaryngol Head Neck Surg. 
2003;129:1041-1046.  
Friedland, DR, Cederberg, C, and Tarima S. Audiometric pattern as a predictor of 
cardiovascular status: Development of a model for assessment of risk. Laryngoscope. 
2009;119(3):473-486. 
Hall, JW III, Chandler, D. Tympanometry in clinical audiology. In Jack Katz (Ed), 
Handbook of Clinical Audiology (283-299). Baltimore, Maryland. Williams and 
Wilkins; 1994. 
Hall, JW III. Distortion products and transient evoked OAEs: measurement and analysis. 
JW Hall, Handbook of Otoacoustic Emissions (95-161). Clifton Park, NY. Thomson 
Delmar Learning; 2000. 
Henshaw, JL and Chao, EL. Hearing Conservation (Report No. 3074). 2002. Retrieved from: 
Hyperlink 
https://www.osha.gov/Publications/osha3074.pdf 
https://www.osha.gov/ 
Publications/osha3074.pdf. 
Kochkin S. MarkeTrak VIII: 25 year trends in the hearing health market. Hearing Review. 
2009;16 (11):12-31. 
Kochkin S. MarkeTrak VIII: The key influencing factors in hearing aid purchase intent. 
Hearing Review. 2012;19(3):12-25. 
Lin FR, Yaffe K, Xia J, Xue QL, Harris TB. Hearing Loss and Cognitive Decline in Older 
Adults. JAMA Intern Med. 2013;173(4): 293-299. 
Mehta RP, Rosowski JJ, Voss SE, O’Neil EO, Merchant, SN. Determinants of hearing loss in 
perforations 
of 
the 
TM. 
Otol 
Neurotol. 
2006;27(2):136-143. 
doi:10.1097/ 
01.mao.0000176177.17636.53. 
National Institute for Occupational Safety and Health (NIOSH). Occupationally induced 
hearing loss (Publication No. 2010-136). 2014 Retrieved from: Hyperlink 
https://www.cdc.gov/niosh/docs/2010-136/; https://www.cdc.gov/niosh/docs/2010-136/. 
Occupational Safety and Health Administration (OSHA). Occupational Safety and Health 
Standards, Occupational Health and Environmental Control, Occupational noise 
Exposure, Standard No.1910.95.Retrieved From: Hyperlink https://www.osha.gov/ 
pls/oshaweb/owadisp.show_document?p_table=STANDARDS&p_id=9735; 
https://www.osha.gov/pls/oshaweb/owadisp.show_document?p_table=STANDARDS&p
_id=9735. 
Ramos JA, Kristensen SGB, Beck DL. An overiew of OAEs and normative data for 
DPOAEs. Hearing Review. 2013;20(11):30-33. 
Shanks J, Shohet J. Tympanometry in clinical practice. In Jack Katz (Ed), Handbook of 
Clinical Audiology (157-184). Baltimore, Maryland. Lippincott Williams & Wilkins; 
2009. 

Audiology, Hearing Aids and Cochlear Implants 
 
237
Teele DW, Klein JO, Rosner B., and the Greater Boston OM Study Group. Epidemiology of 
OM during the first seven years of life in children in greater Boston: a prospective, cohort 
study. Journ of ID. 1989;160(1):83-94. 
Vilayur E, Gopinath B, Harris DC, Burlutsky G, McMahon CM, Mitchel P. The association 
between reduced GFR and hearing loss: a cross-sectional population-based study. Am 
Jour of Kid Dz. 2010;56(4): 661-669. doi 10.1053/j.ajkd.2010.05.015. 
Ward WD, Royster LH, Royster JD. Anatomy and physiology of the ear: normal and 
damaged hearing. In EH Berger (Ed). Fairfax, VA: American Industrial Hygiene 
Association. The Noise Manual; 2003.p. 101-122. 
Ward WD, Royster JD, Royster LH. Auditory and non-auditory effects of noise. In EH Berger 
(Ed). Fairfax, VA: American Industrial Hygiene Association. The Noise Manual; 2003. p. 
123-147. 
Wiley TL, Chappell, R, Carmichael L, Nondahl DM, Cruikshanks, KJ. Changes in hearing 
thresholds over 10 years in older adults. J Am Acad Audiol. 2008; 19(4): 281-290. 
World Health Organization (WHO). (February, 2017). Deafness and hearing loss (Fact Sheet 
300). 
Retrieved 
from: 
Hyperlink 
http://www.who.int/topics/deafness/en/ 
http://www.who.int/topics/deafness/en/. 
Zelaya CE, Lucas JW, Hoffman, HJ. (2015). Self-reported hearing trouble in adults aged 18 
and over: United States, 2014. (National Center for Health Statistics). Retrieved from: 
Hyperlink 
https://www.cdc.gov/nchs/data/databriefs/db214.pdf 
https://www.cdc.gov/ 
nchs/data/databriefs/db214.pdf. 
 
 
 


In: Encyclopedia of Audiology and Hearing Research 
ISBN: 978-1-53617-702-2 
Editors: Erno Larivaara and Senja Korhola 
© 2020 Nova Science Publishers, Inc. 
 
 
 
 
 
 
 
Chapter 18  
 
 
 
HEARING LOSS: CONDUCTIVE AND SENSORINEURAL 
 
 
Joshua M. Sappington*, MD 
Department of Otolaryngology, Saint Louis University School of Medicine,  
Saint Louis, MO, US 
 
 
 
Congenital hearing loss is the most common sensory defect occurring in 1 in 
1,000-2,000 live births. 
 
Early identification and intervention is key. 
 
70% of cases are nonsyndromic. 
 
30% of cases are related a syndrome. 
 
75-80% of cases are due to autosomal recessive genes.  
 
18-20% are due to autosomal dominant genes. 
 
1-3% are due to X-linked or chromosomal disorders. 
 
Environmental factors include but are not limited to: rubella, cytomegalovirus, 
kernicterus, syphilis, herpes simplex virus, and hypothyroidism. 
 
Nonsydromic congenital hearing loss that accounts for 70% of cases is likely 
linked to over 100 genes. Connexin 26 mutations are the most common 
mutations for nonsyndromic congenital SNHL. 
 
Select Autosomal Dominant Syndromes. 
 
Branchio-Oto-Renal Syndrome – children have ear pits/tags, cervical fistula 
and renal involvement. 75% of patients have hearing loss with 30% being 
conductive, 20% SNHL, and 50% mixed. 
 
Osteogenesis Imperfecta – presents with varying degrees of bone fragility, blue 
sclera, conductive, mixed, or SNHL. 
 
Stickler Syndrome – characterized by cleft palate, micrognathia, myopia, retinal 
detachments with a marfanoid habitus.  
                                                        
* Corresponding Author’s Email: Joshua.sappington@health.slu.edu. 

Joshua Sappington 
 
240
 
Treacher Collins – constellation of facial malformations including hypoplasia 
of the mandible and maxilla, congenital aural atresia, microtia, cleft palate and 
dental malocclusion. CHL is present approximately 30% of the time but SNHL 
can also be present. 
 
Waardenburg Syndrome – most common form of autosomal dominant 
congenital hearing loss. Variability in presentation there can be unilateral or 
bilateral SNHL.  
 
Select Autosomal Recessive Syndromes. 
 
Jervell and Lange – Nielsen Syndrome – profound SNHL and cardiac 
dysrhythmias. Mutation affects a potassium channel gene that effects conduction 
within the heart. Children with early hearing loss should get an EKG for 
evaluation. 
 
Pendred Syndrome – profound SNHL and thyroid goiter. Hearing loss can be 
progressive in approximately 15% of patients. Mutation in PDS gene coding for 
pendrin protein. 
 
Usher Syndrome – most common type AR syndromic hearing loss and affects 
almost one half of deaf and blind in the United States. Characterized by SNHL 
and retinitis pigmentosa. 3 different subtypes of the syndrome. Patients with 
hearing loss should undergo formal ophthalmologic examination. 
 
Alport Syndrome – X-linked disorder where the collagen of the basement 
membrane of the kidneys ad inner ear effected. Patients have progressive renal 
decline and progressive SNHL.  
 
 
SENSORINEURAL HEARING LOSS 
 
 
Sensorineural hearing loss is exceptionally common and effects patients of ages. 
It can range from being undetectable to a severe impairment affecting nearly all 
aspects of life. 
 
Between 30-35% of patients over the age 65 have hearing loss significant enough 
to necessitate a hearing aid. That number rises to 40% by age 75. 
 
SNHL results from damage to hair cells, structures within the inner ear, or the 
eighth cranial nerve.  
 
Causes for SNHL can include: 
 
Noise Exposure 
 
Meningitis 
 
Cochlear otosclerosis 
 
Aging 
 
Meniere’s Syndrome  
 
Temporal bone fractures 

Hearing Loss 
 
241
 
Pathogen Infections 
 
Medications 
 
Idopathic 
 
Autoimmune  
 
Retrocochlear lesions i.e., tumors  
 
Ototoxic medications can cause sensorineural hearing loss: 
 
Aminoglycoside antibiotics  
 
Acetaminophen  
 
Chemotherapeutic agents notably cisplatin 
 
Salicylates 
 
Quinine and synthetic analogs of quinine 
 
Presbyacusis – age associated hearing loss in adults. Most common cause for 
hearing in adults. Typically presents as symmetric, high frequency hearing loss 
that progresses to involve lower frequencies. Patients experience a decline in the 
clarity of their hearing. As neuronal loss progresses patients will have 
progressive loss in speech discrimination and yet may retain relatively good pure 
tone average. In seeing patients with hearing loss, the word recognition is just as 
important as the pure tone average. Recent studies have shown associations with 
hearing loss social isolation and poorer cognitive function in the elderly. 
 
Noise induced hearing loss – preventable form of SNHL and the second most 
common form of SNHL. Approximately 20 million Americans are exposed to 
hazardous noise. Avoiding loud noise exposure and regular use of hearing 
protection can help to prevent or limit noise exposure. OSHA regulations require 
hearing protection at 85 dB for 8 hours, 100 dB for 2 hours and 115 dB for 15 
minutes. Temporary threshold shift is a temporary SNHL that resolves within 24 
hours following exposure to loud noises.  
 
Sudden Sensorineural hearing loss – loss of over 35 dB in at least 3 adjacent 
frequencies over less than 3 days. Overal incidence is approximately 1 in 5,000. 
Worse prognosis in the elderly, total hearing loss, longer duration of deafness, 
down-sloping audiogram, delayed treatment and in those patients with associated 
vestibular symptoms. Tinnitus is common and is seen in 80-100% of patients. 
Typically idiopathic can be autoimmune, viral, or vascular in etiology or 
represent first episode of Meniere’s syndrome. Blood tests are rarely obtained but 
can include CBC, ESR, FTA-ABs, coagulation and thyroid studies. Key point is 
to obtain and MR to exclude retrocochlear lesion which is present in 1 in 20 of 
these patients. In idiopathic cases, patients are typically treated with high dose 
oral steroids (typically 1 mg/kg for 10-20 days) initially with transtympanic 
steroids for salvage or initially for patients that cannot tolerate high dose oral 
steroids. Hyperbaric oxygen has not shown reliable rates of improvement 

Joshua Sappington 
 
242
compared to natural history. AAO-HNS guidelines indicate that it can be offered 
as adjuvant therapy within 3 months of onset. 
 
Autoimmune inner ear disease – Typically presents as progressive and 
ultimately bilateral SNHL. Often will be asymmetric SNHL at a given point of 
time. Presumed to be due to immunological attack on the inner ear or an 
associated systemic autoimmune disorder. Unknown pathophysiology with 15-
30% of patients having systemic autoimmune disease. History is very important 
in making the diagnosis. Made by serial audiograms demonstrating rapidly 
progressive usually bilateral hearing loss. Heat shock protein 70 has been shown 
to be a helpful marker. Treatment involves corticosteroids and for some patients 
steroid-sparing immunosuppressants. Typical causes include Polyarteritis nodosa, 
Wegener granulomatosis, SLE, Cogan syndrome (interstitial keratitis, vestibular 
dysfunction and SNHL),  
 
Meningitis – Meningitis with associated labyrinthitis ossificans is overall a 
relatively rare cause of SNHL. This is due to wide scale pneumococcal 
vaccination helping to prevent the development of meningitis and the resulting 
labyrinthtitis ossificans. Typically, ossification occurs basally near the round 
window most likely via the cochlear aqueduct. High suspicion and early MR and 
CT are key. MR identifies early fibrosis and demonstrates fluid patency whereas 
CT demonstrates neo-ossification. In patients with SNHL hearing loss, that meet 
criteria early implantation should be considered when fibrosis is demonstrated. 
 
Retrocochlear – Though overall rare retrocochlear lesions are an important 
diagnostic consideration. The two most common lesions are acoustic neuromas 
(vestibular schwannomas) and meningioma. Patients with retrocochlear lesions 
characteristically will have an asymmetric SNHL often with often a surprisingly 
poor speech discrimination score on that side. Often patients will seek evaluation 
evaluation stating they are having a hard time using a cellular phone on that side. 
Patients with asymmetric SNHL, SSNHL, unilateral tinnitus or other otologic 
symptom warrant an MR to exclude a retrocochlear lesion. If they cannot 
undergo an MR then CT with contrast and ABR (if their hearing permits) are 
another diagnostic consideration. 
 
Auditory neuropathy – Spectrum disorder that abnormally activates the 
auditory system. Lesion site can range from the inner hair cells to the cochlear 
nerve itself. OAEs will be present and ABR will be abnormal to absent. 
Audiologic performance and speech perception abilities can be variable in this 
population and can range from normal to profound.  
 
Treatment – Treatment for SNHL can range from preventing it in the case of 
noise induced hearing loss to utilization of hearing aids, middle ear implants, and 
cochlear implantation.  
 

Hearing Loss 
 
243
CONDUCTIVE HEARING LOSS 
 
 
Conductive hearing loss occurs when there is an issue transmitting sound waves 
from the environment to the inner ear. The issue can arise at the outer ear, within 
the EAC, tympanic membrane, ossicles or within the middle ear. This can occur 
in isolation or occur in conjunction with SNHL resulting in a mixed hearing loss.  
 
Differential diagnosis for CHL: 
 
Cerumen obstruction 
 
EAC lesion 
 
Otitis externa  
 
Otitis media  
 
TM perforation 
 
Otosclerosis 
 
Cholesteatoma  
 
Hemotympanum  
 
Ossicular discontinuity  
 
Third Window Effects 
 
Middle ear lesion 
 
Cerumen obstruction – can be a cause for CHL or MHL if there is a preexisting 
SNHL. Examination will demonstrate cerumen completely filling the EAC 
obstructing sound waves from reaching the tympanic membrane. Removal of the 
cerumen results in resolution of the CHL. 
 
EAC Lesion – EAC lesions most commonly seen are exostoses and osteomas 
that rarely can cause CHL. 
 
Otitis externa – In approximately 30% of cases patients can develop CHL due to 
stenosis of the EAC. Resolves with appreciate treatment and aural toilet. In 
patients that are immunocompromised esp. diabetics and patients that have 
worsening otalgia, develop cranial neuropathies, and/or fail to improve with 
usual treatment consideration should be made for a diagnosis of malignant otitis 
externa. 
 
Otitis media – Acute otitis media (AOM), otitis media with effusion (OME), and 
chronic otitis media (COM) all can result in CHL. The reason for CHL for each 
varies. For AOM acute inflammation and the development of purulence within 
the middle ear. OME is defined by the presence of non-infected effusion which 
can cause CHL. COM can cause CHL via tympanic membrane perforation, 
adhesive OM with TM retraction, ossicular erosion, and cholesteatoma.  
 
Tympanic Membrane perforation – Tympanic membrane perforation can be 
caused by several different injuries. These can include cotton – tipped applicator 
and other foreign body, slap to the ear, pressure from diving into water, sudden 
loud noises, slag, barotrauma and otitis media. Degree of CHL hearing loss 

Joshua Sappington 
 
244
varies on the size and the location of the perforation. The larger the perforation 
the greater the hearing loss and posterior perforations generally tend to have 
greater hearing loss.  
 
Cholesteatoma – Lesions of keratinizing stratified squamous epithelium that 
contain keratin. Most often occur within the middle ear and mastoid but can 
involve any part of the temporal bone that has pneumatization or intracranial 
space. Can be congenital, primary acquired, or secondary acquired. Early stages 
of disease can be asymptomatic with the most common presenting symptom 
being otorrhea. Progressive CHL is often present during the natural history of the 
disease. Of note, it is possible for the cholesteatoma to erode the ossicles and for 
the patient to effectively hear through the cholesteatoma. Primary objective in 
ears with cholesteatoma is provide a safe, dry, and disease free ear with the best 
hearing outcome as a secondary objective. 
 
Otosclerosis  
 
Disease characterized by abnormal bone remodeling of the otic capsule. Foci of 
endochondral bone are replaced by hypercellular bone which than can develop 
into sclerotic bone. Approximately 50% of patients will have a family history 
and up to 70% will have bilateral disease. Autosomal dominant with variable 
penetrance.  
 
Can be due to fixation of the stapes footplate with the development of CHL or 
cochlear involvement with SNHL development.  
 
It is the most common cause of progressive CHL in adults. Mean age of 
diagnosis is between 20 and 40 years of age and is twice as common in women 
as men.  
 
Most common site of stapes footplate fixation is the fissula ante fenestram 
(anterior to the oval window). Clinically, dilation of the vessels on the 
promontory can be seen (Schwartze’s sign). Tuning fork shows negative Rinne 
at 250 Hz early in disease, and then worsening to other frequencies. A negative 
Rinne at 250 indicates 15 dB loss, at 512 indicates 25-30 dB loss and at 1,024 Hz 
of at least 35 dB hearing loss. Audiogram shows flat or “cookie bite” with 
excellent discrimination. Tympanogram may show As configuration. CT may 
reveal “double ring” sign that represents cochlear demineralization. Stapedial 
reflexes should be absent. Histologically, can see “blue mantles of Manasse” on 
H&E stain that represents areas of ground substance deposition.  
 
Most common presentation is a normal dry ear with little otologic history with 
conductive hearing loss as the presenting symptom. A significant number of 
patients will demonstrate paracusis of Willis that effected patients hear better in 
noise. Indications for surgery include a CHL over 25 dB in speech frequencies. 
Contraindications include only hearing ear, TM perforation, middle ear disease, 
and vestibular symptoms. Options to discuss with patients include observation, 
amplification and surgery. In experienced hands closure of ABG less than 10 dB 

Hearing Loss 
 
245
90-95%. Risks of surgery include failure to improve hearing, loss of hearing 
(less than 1%), tinnitus, vestibular dysfunction, perilymphatic fistula, facial 
nerve injury, dysgeusia, TM perforation, and late surgery failure.  
 
Surgery: The risks, benefits, and expectations of each treatment option need to 
be discussed in detail with the patient. The patients’ options include observation, 
amplification, stapes surgery and BAHA placement. Patients do not need to have 
an amplification trial prior to proceeding with stapes surgery. They do need to 
understand completely and consent that there is a very rare risk of complete 
hearing loss even with a perfect surgery. 
 
Reparative granuloma presents as progressive SNHL with lower discrimination 
scores (granulation tissue on the oval window area and exam shows reddish 
discoloration behind TM). This is very rare and associated with gelfoam use. 
Surgery is needed immediately.  
 
Fluctuating hearing loss after surgery may indicate perilymph fistula (requires 
exploration). Persistent vertigo after surgery may indicate long prosthesis.  
 
Failure of stapedectomy is most commonly a result of prosthesis displacement  
 
Hemotympanum – Most commonly secondary to trauma, diagnosed on 
microscopic otoscopy. Results in a conductive hearing loss that will clear over 6 
weeks. Obtain audio after clearance and breakdown of blood to ensure resolution 
of hearing loss and may identify ossciular discontinuity. 
 
Ossicular discontinuity – Typically occurs after trauma. Presents as CHL that is 
present after resolution of hemotympanum. Most common discontinuity is 
incudostapedial joint disarticulation followed by incus dislocation and stapes 
crura fracture. Options include observation, hearing aid, bone conducting hearing 
aid, and middle ear exploration with ossiculoplasty. 
 
Third window effects – Presence of an abnormal window in the otic capsule 
such as superior semicircular canal dehiscence, fenestration, or enlarged 
vestibular aqueduct can cause CHL. Loss of acoustic energy through such a 
dehiscence causes an abnormal shunting through the vestibular system causing 
hearing and balance issues.  
 
Middle ear lesion – Overall a rare cause for CHL but an important diagnostic 
consideration. Patients with these types of lesions typically have isolated 
conductive hearing loss unless there is labyrinthine involvement. These lesions 
include: 
 
Paraganglioma – arise from chief cells that are of neural crest origin. Key 
pathology – cluster of nonchrmaffin-staining cells known as zellballen. 
Tympanicum most common middle ear neoplasm arising from Jacobson’s (IX) 
and Arnold’s nerve (X). Jugulare are the most common jugular foramen lesion 
and originate from paraganglion cells in the adventitia of the jugular bulb. Due to 
location of jugular bulb, a growing lesion can involve the middle ear causing 

Joshua Sappington 
 
246
CHL. Vagal lesions originate along the path of the vagus nerve and cause CHL 
via similar means to jugulare lesions. 
 
Primary middle ear adenomas – another rare cause for CHL. 
 
Unilateral effusions – Though not a true lesion of the middle ear the presence of 
a unilateral middle ear effusion in an adult should raise ones clinical suspicion 
for a potentially sinister cause and start further investigation. This could be the 
result of nasopharyngeal lesion causing Eustachian Tube dysfunction and cause 
the unilateral effusion. Adult patients with a unilateral effusion should undergo 
endoscopic evaluation of their NP to evaluate for a lesion. Another important 
consideration is the potential for a skull base defect and a resulting unilateral 
CSF effusion. 
 
 
REFERENCES 
 
Cummings CW. Cummings Otolaryngology – Head and Neck Surgery. 5th ed. Philadelphia: 
Lippincott Williams & Wilkins; 2010. 
Haynes DS, O’Malley M, Cohen S, Watford K, Labadie RF. Intratympanic dexamethasone 
for sudden sensorineural hearing loss after failure of systemic therapy. Laryngoscope. 
2006;117:3-15. 
Lee KJ, ed. Essential Otolaryngology Head and Neck Surgery. 11th ed. New York, NY: 
McGraw-Hill; 2003. 
Lin FR, Yaffe K, Xia J, Xue QL, Harris TB, Purchase-Helzner E, et al. Hearing loss and 
cognitive decline in older adults. JAMA Intern Med. 2013;174(4):293-299. 
McRackan TR, Brackmann DE. Otology, Neurotology, and Skull Base Surgery: Clinical 
Reference Guide. San Diego: Plural Publishing; 2016. 
Pasha R. Otolaryngology – Head and Neck Surgery: Clinical Reference Guide. 2nd ed. San 
Diego: Plural Publishing; 2006. 
Strachler RJ, Chandrasekhar SS, Archer SM, Rosenfeld RM, Schwartz SR, Barrs DM, et al. 
Clinical practice guideline: sudden hearing loss. Otolaryngol-Head Neck Surg. 
2012;146:S1-S35. 
 
 
 

In: Encyclopedia of Audiology and Hearing Research 
ISBN: 978-1-53617-702-2 
Editors: Erno Larivaara and Senja Korhola 
© 2020 Nova Science Publishers, Inc. 
 
 
 
 
 
 
 
Chapter 19 
 
 
 
SIGN ACQUISITION AND DEVELOPMENT BY HEARING 
CHILDREN WITH AUTISM SPECTRUM DISORDERS 
 
 
John D. Bonvillian 
Department of Psychology and the Program in Linguistics,  
University of Virginia, VA, US 
 
 
Keywords: Autism Spectrum Disorder, behavioural techniques, gesture, iconicity, 
intervention, PECS, technology, signing, Simplified Sign System, spoken language 
 
 
INTRODUCTION 
 
Childhood autism, once viewed as a rare clinical disorder, has come to be recognised as a 
major form of developmental disability. This change in perspective rests largely on the 
rapidly increasing estimates of the incidence of children on the Autism Spectrum (ASD) or 
with other closely related syndromes. Sixty years ago, childhood ASD was depicted as very 
uncommon, occurring in only one or two children per 10,000. By 1996, the estimated 
incidence had climbed to about one in every 500 children (Bristol et al., 1996). More recently, 
an estimated incidence of one in every 59 children was reported1. This marked increase in the 
number of children diagnosed with ASD has sparked alarm in many quarters and led to ASD 
being recognized as a major public health priority (Bonnet-Brilhault, 2017). This chapter 
reviews research into the use of sign to support spoken language in children with ASD (that 
is, using some form of simultaneous communication or key word signing system), referencing 
also some recent studies of deaf children on the Autism Spectrum, a topic explored in more 
detail in Chapter 7. 
What factors might be behind this apparent rapid increase in the incidence of childhood 
ASD? An important factor is that our understanding of what constitutes autism has changed. 
In the initial description of the syndrome of childhood autism by Leo Kanner (1943), these 
children were depicted as self-absorbed and as having serious behavioural, social, and 
                                                        
1 (https://www.cdc.gov/mmwr/volumes/67/ss/ss6706a1.htm Accessed 10th July 2018. 

John D. Bonvillian 
 
248
communicative difficulties. Early understandings of autism grew out of the childhood 
schizophrenia literature, often with psychoanalytic interpretations. This depiction prevailed 
until recent years, although differing perspectives were occasionally presented. Hans 
Asperger, a contemporary of Kanner, described autistic children somewhat differently. 
Although the children he worked with were portrayed as having many of the same 
behavioural characteristics first described by Kanner, some of the youngsters with whom 
Asperger worked demonstrated good formal language skills and scored quite highly on 
measures of intellectual abilities. It is this more inclusive view of childhood autism, with a 
much wider range of abilities represented, that has become the more generally accepted view 
of autism (Frith, 2008; Silberman, 2015). This diversity of abilities is captured in the now 
widely used term Autism Spectrum disorder (ASD). 
The expansion of diagnostic criteria probably accounts for much of the apparent increase 
in the incidence of ASD (Gernsbacher, Dawson & Goldsmith, 2005), along with diagnostic 
substitution. For example, many individuals who had previously been identified as 
intellectually disabled were subsequently diagnosed as autistic (Croen et al., 2002). A 
growing awareness of the characteristics of childhood ASD by both parents and professionals 
has probably also led to more children being identified. Finally, the increasing availability of 
programmes for these children may have sparked more parents to push for a formal diagnosis 
in order to qualify for support. Other factors, such as parents having children at older ages, 
medications used during pregnancy, and environmental pollution, may also be contributing to 
an increased incidence While the above factors probably account for most of the apparent 
increase in the incidence of ASD, it should be acknowledged that there is an ongoing debate 
as to whether this increase is real.  
 
 
COMMUNICATION TRAINING INTERVENTIONS 
 
In the two decades following Kanner’s initial account of the characteristics of children 
with ASD in 1943, very little progress was made in developing effective therapeutic 
interventions for these children. An area of particular difficulty, and one often resistant to 
change, was their atypical communication. Difficulties included delayed spoken language 
development, particularly in the area of pragmatics; the immediate or delayed repetition of 
others’ utterances (or echolalia), and the absence of speech. These problems in 
communication were of special concern to therapists because the prognosis for those children 
who failed to acquire useful speech by the age of 5 or 6 years was very bleak (Eisenberg, 
1956), with lifelong institutionalisation the likely outcome (Lotter, 1974). For those children 
who did acquire useful speech, much more positive long-term outcomes were reported 
(Howlin et al., 2004; Lord & Bailey, 2002). 
 
 
Behaviour Modification Programmes 
 
An important innovation in the fostering of language or communication skills in children 
with ASD was the introduction of behavioural techniques. Now generally referred to as 
Applied Behavioural Analysis (ABA), the approaches have been criticised on several 

Sign Acquisition and Development by Hearing Children… 
 
249
grounds, including the use of negative reinforcement and the emphasis on control (see Gruson 
Wood, 2016), although there is a continuum of implementation (Kates-McElrath & Axelrod, 
2006). The approach originated in the 1960s with the research of Ivar Lovaas and his 
associates. They showed that by systematic application of rewards contingent on the 
children’s behaviour, many children with ASD were able to make substantial progress in 
spoken language (Lovaas, 1977; 1987; Lovaas et al., 1973). However, this progress was not 
shared equally amongst the children involved. Whereas those children who had some useful 
speech or who repeated others’ speech (that is, they were echolalic) often made considerable 
gains, others did not fare as well. In particular, those children who were mute or minimally 
verbal at the time they entered Lovaas’ programme typically made little progress in acquiring 
communication skills (1977). Such minimally verbal children, moreover, constituted a 
significant proportion of the children diagnosed with ASD. Historically, those children who 
had no or little speech were estimated to account for between one-third and one-half of 
children with ASD (Lord & Paul, 1997; Mesibov, Adams & Klinger, 1997; Peeters & 
Gillberg, 1999). With the expansion of the diagnostic criteria for ASD and the introduction of 
early intervention programmes in recent years, the proportion of children with little or no 
speech skills has decreased. More recent estimates of those children diagnosed with ASD who 
fail to acquire useful spoken language skills range from 20 to 30 percent (Kim & Lord, 2014; 
Tager-Flusberg & Kasari, 2013; Wodka, Mathy & Kalb, 2013). 
 
 
Sign Communication Programmes 
 
A second important innovation in language and communication training for children with 
ASD occurred in the 1970s with the introduction of sign communication programmes. This 
approach was employed primarily with minimally verbal youngsters, a number of whom had 
previously made only very limited progress in speech-oriented programmes. Studies showed 
that many were able to learn to convey their basic needs through sign. 
One of the initial efforts to teach sign communication skills to “non-speaking” or 
minimally verbal students occurred at Benhaven beginning in 1971 (Lettick, 1972; 1979). 
Benhaven, a school in New Haven, Connecticut, served students with ASD or with brain 
damage, ranging in age from 6 to 21 years. Many were minimally verbal and had failed to 
demonstrate progress in acquiring communication skills at other institutions. When a deaf 
child with ASD entered Benhaven, an administrative decision was made to embark on signing 
lessons for the school’s entire staff and to embrace a programme of sign and speech input for 
all students who were not making progress in acquiring useful speech. Although all the 
participating students made at least some progress in learning to sign, the range in outcomes 
was very wide. At the low end were those students whose progress was limited to learning the 
meaning of only a few signs. In contrast, others were reported to have learned to comprehend 
and produce numerous signs, to respond appropriately in signed sentences to questions, and to 
engage in signed conversations. It is not clear how these assessments were made, and from a 
contemporary perspective, such reports may appear somewhat optimistic; nevertheless at the 
time they helped to open up opportunities for young people whose abilities were under-
estimated. 
Another important pioneering study of the use of signs to foster communication skills in 
children with ASD was conducted by Creedon (1973; see also Offir, 1976). The 30 children 

John D. Bonvillian 
 
250
in her study were provided with both sign and speech input. All of the children acquired at 
least some sign communication skills and a number became quite effective users of signs. 
Forty percent of the participants acquired some spoken language skills as well. Of the 
participants who acquired some speech skills, seven demonstrated considerable facility in 
spoken English by forming complex, multi-word utterances. Creedon also reported that those 
children who showed the greatest progress in acquiring communication skills were typically 
those who entered the training programme at younger ages. This study is significant because 
it showed that learning to sign did not preclude the development of spoken language skills 
and because it underlined the importance of starting intervention programmes early in 
children’s development. 
Altogether, the findings from more than 30 studies of sign acquisition in minimally 
verbal children with ASD have demonstrated the potential effectiveness of sign 
communication training (Goldstein, 2002; Lal, 2010; Layton, 1987; Tan et al., 2014; 
Valentino & Shillingsburg, 2011; Wendt, 2009). In most of these studies, the children’s 
teachers or caregivers took individual signs from existing sign languages or sign 
communication systems and paired them with their spoken language equivalents in their 
interactions with their children. As a result, the children typically were receiving input in two 
modalities. The gains in communication skills shown by the children, moreover, could be 
retained for a long time (Webster et al., 2016), whereas rather poor word retention skills were 
often seen in participants in vocal language intervention programmes (Gaines et al., 1988). As 
with the early studies, some of the children were reported to acquire spoken language skill, 
albeit of a relatively modest nature (Millar, Light & Schlosser, 2006). Only a minority of 
participants acquired real facility in speech. 
Along with their enhanced communication skills, many of the children with ASD who 
were taught to sign also showed improvements in their adaptive behaviours (Lal, 2010). 
These included: increased attention span, declines in the number of temper tantrums, a 
reduction in the incidence of stereotypies (e.g., finger flicking, head banging), greater 
willingness to engage in group activities, and many fewer soiling incidents. These 
improvements appear not as the product of direct training in these areas, but are rather 
associated with the children’s greater success in communication through signs. Because many 
of the children’s challenging behaviours (e.g., tantrums, stereotypies) may have served a 
communication function, the learning of sign communication skills probably reduced the 
children’s need for them. 
 
 
ADVANTAGES OF THE SIGN MODALITY 
 
A range of explanations has been advanced to try to account for these findings. One area 
of interest is the auditory-vocal modality itself, as auditoryprocessing problems are very 
common in individuals with ASD (Baranek, 2002; Condon, 1975). Moreover, vocal stimuli, 
but not non-vocal sounds (such as environmental sounds), have been found to be processed 
abnormally in both adults and children with ASD (Gervais et al., 2004; Sperdin & Schaer, 
2016). Even highly articulate persons on the Autism Spectrum may find the processing of 
speech quite difficult, as Temple Grandin, an accomplished scholar has observed (Grandin, 
1995; Grandin & Panek, 2013). These findings and other related results have led some 

Sign Acquisition and Development by Hearing Children… 
 
251
investigators to advance the view that for many individuals with ASD, their visual and 
kinesthetic abilities are relatively more intact than their auditory-processing abilities 
(Mirenda, 2014; Mitchell & Ropar, 2004). 
Other explanations focus primarily on the visual-gestural modality of signs, which is 
essentially more conducive to direct instruction than speech. For children with at least some 
ability to imitate gestures, teachers and caregivers are able to slow down the rate at which 
they form a sign and may even hold their hands in place until the children are able to copy 
how the sign is made. Moreover, for those children who experience great difficulty imitating 
their teachers’ sign formation, the teachers could directly mould the children’s hands into the 
correct sign formation. Such direct instruction is simply impossible with spoken words. 
Another possible advantage is that by teaching the children to sign, teachers and caregivers 
may indirectly help the children to control their motor stereotypies (e.g., finger flicking, 
twirling) (Bram, Meier & Sutherland, 1977). By having the ability to communicate through 
signs, the children may be better able to regulate or control many aspects of their 
environments. And because these stereotypies or repetitive gestures may interfere with the 
children’s cognitive processing, lowering their frequency may help the children to learn and 
to communicate more effectively. 
Although signs are typically acquired more readily than spoken words by minimally 
verbal children with ASD, investigators observed early on that certain signs were learned and 
recalled more easily than others. In particular, highly iconic signs - those signs that clearly 
resembled the concepts that they stood for - were acquired faster and remembered better than 
those signs without such transparent ties to their referents (Konstantareas, Oxman & Webster, 
1978). These iconic signs often represented meaningful sensori-motor actions or resembled 
the shapes of objects. This is not to say that non-iconic signs cannot be learned by children 
with ASD. Rather, it is often the case that the learning of non-iconic signs takes considerably 
longer to achieve. It is also likely that iconic signs may hold more meaning for the children. 
This interpretation would be in accord with the results of studies that showed that children 
with ASD were more likely to imitate meaningful gestures than gestures without clearly 
discernible meanings (Smith & Bryson, 2007; Vanvuchelen, Roeyers & De Weerdt, 2007). 
(For further discussion of iconicity and sign and gesture learning, see Chapters 3 and 4, this 
volume).  
 
 
PROBLEMS IN SIGN ACQUISITION AND USE 
 
Although studies have demonstrated that signs can provide an effective system of 
communication, they also make it clear that outcomes often varied widely. Whereas some 
children acquired hundreds of signs and progressed to multi-sign communicative utterances, 
many children fared less well. They might learn to understand or produce only a few signs, 
with a limited range of information, despite years of training. Of course, if a minimally verbal 
child can sign to indicate hunger, or need to use the bathroom, then there will be 
improvements to the daily life of both the child and their teachers and caregivers (Tan et al., 
2014). However, it is important to consider what factors seem to impact on the success of sign 
learning (see also Chapter 11, this volume).  
 

John D. Bonvillian 
 
252
Delays in Implementing Intervention 
 
One issue would appear to be that sign training often did not begin until after their early 
childhood and it is not entirely clear what the quality of the input and support was outside 
formal teaching contexts. Some of the delay in initiating sign training is attributable to 
parental attitudes and decisions. Many parents often expressed great reluctance to start sign 
communication training until after their hopes that their children would learn to speak had 
essentially vanished (Cress & Marvin, 2003). This decision to rely solely on spoken language 
training was a bad one for several reasons. One reason is that if such speech training proved 
ineffective, then those children were denied the opportunity to learn a useful non-speech 
means of communication during their important early years. Also contributing to this late start 
in the initiation of many programmes of sign communication was the fact that the diagnosis 
of childhood ASD usually occurred at a much later date than it does today (typically between 
2 and 4 years nowadays). Moreover, children with more severe impairments can now often be 
identified at younger ages; it is those children with more advanced language and adaptive 
skills that are not reliably identified until 3 years or older (Zwaigenbaum et al., 2016). Earlier 
diagnosis provides an opportunity to remove an important obstacle to commencing 
communication training programmes with such minimally verbal children. Recent studies on 
deaf children with ASD whose first language is sign also promise to deepen our 
understanding of the role of early input within a sign environment for children who are 
autistic (Shield, 2014; Shield, Cooley, & Meier, 2017; Shield & Meier, 2012; Shield, Meier, 
& Tager-Flusberg, 2015; Shield, Pyers, Martin,, & Tager-Flusberg, 2016; Shield et al., 2017; 
see also see Chapter 7, this volume).  
The reluctance of many parents to grant approval for their children with ASD to begin a 
programme of sign communication training appears to rest largely on the parents’ mistaken 
belief that starting to sign was tantamount to admitting that their dream of ever hearing their 
children’s voices was gone forever. However, the notion that if children learn to communicate 
in one mode (such as sign) then this will impair or preclude their development of 
communication skills in another mode (such as speech) is fundamentally misguided. Indeed, 
in recent years it has been recognised that development in one mode often facilitates the 
development of communication skills in another (Dunst, Meter & Hamby, 2011; Millar, 
2009). Rather than precluding spoken language development, learning to sign has often been 
associated with improvements in speech production and comprehension in both mute and 
echolalic children with ASD. This finding, moreover, was reported many years ago (Creedon, 
1973; see Offir, 1976). In addition, our understanding of language acquisition processes in 
general has changed substantially in recent decades. Today, the language acquisition of 
typically developing children is seen as a multi-modal process. That is, typically developing 
children and their caregivers often make extensive use of pointing and other gestures in their 
early communicative exchanges, where the use of gesture is predictive of later language 
development (Rowe & Goldin-Meadow, 2009; Chapters 3 and 4, this volume). Thus, the 
combining of gestures and spoken utterances is the way that most children learn to 
communicate. 
 
 
 

Sign Acquisition and Development by Hearing Children… 
 
253
Deficits in Motor Skills and Imitation 
 
Although using signs to communicate may avoid the auditory-vocal processing 
difficulties present in many children with ASD, the switch to employing signs also comes 
with its own set of difficulties. One major difficulty is that children with ASD typically have 
serious deficits in motor development and in motor processing. Another is that they often 
have problems imitating the actions of others (see Chapter 3, this volume). In the production 
and understanding of signs, which rely heavily on motor production and on the visual 
processing of information, such deficits represent very serious obstacles, and appear to 
account for some of the widely different outcomes among children with ASD in learning to 
sign. 
Those children who acquired larger sign vocabularies and who formed longer sign 
utterances were shown to have scored higher on tests of intelligence, and to have better social 
skills, receptive language abilities, and fine motor skills (Bonvillian & Blackburn, 1991; 
Gaines et al., 1988). Deficits in motor abilities are now recognised to occur very often in 
these children and may well be an integral part of the syndrome (Bo, Lee, Colbert & Shen, 
2016; Bodison & Mostofsky, 2014; Mirenda, 2008). Both fine and gross motor skills are 
affected (Chukoskie, Townsend & Westerfield, 2013; Slavoff, 1998) and problems include 
difficulties in gait, posture, balance and coordination (Gidley Larson & Mostofsky, 2006). 
These deficits, furthermore, emerge early in the children’s development and appear to persist 
as children get older (Biscaldi et al., 2014). 
The finding that motor skill levels were related to success in sign learning (Bonvillian & 
Blackburn, 1991) subsequently led to more systematic probes of the language (sign and 
speech) processing and motor functioning of children with ASD. In one study (Seal & 
Bonvillian, 1997), 14 minimally verbal children with ASD were videotaped while they were 
interacting with their teachers in sign. Although all of the children made errors in their sign 
formation, the error rates varied widely across participants. The children who had learned the 
most signs generally had very low sign formation error rates, whereas the children who 
learned the fewest signs typically had much higher rates. The examination of the children’s 
sign formations also showed that the children often found the movement parameter of the 
signs an area of particular difficulty. Following up on this observation, the investigators 
administered tests of apraxia to 11 of the children. (Apraxia or dyspraxia is a neuromotor 
disorder that limits one’s ability to produce planned, voluntary, and purposeful motor 
movements in the absence of paralysis.) The children’s scores were consistent with a 
diagnosis of apraxia.  
Subsequent studies have confirmed that apraxia impacts on the sign acquisition of both 
hearing and deaf children with ASD (Page & Boucher, 1998; Bhat et al., 2016). Soorya 
(2003) found an association between apraxia scores and accuracy of sign production. Page 
and Boucher found that almost 80 percent of the 33 children they studied showed marked 
impairment in various aspects of motor functioning. These deficits included oromotor skills 
(lip and tongue movements), manual skills (object manipulation, making correct handshapes), 
and gross motor skills (running, hopping). While the children exhibited deficits in all three 
areas, the most prevalent difficulties were in the oromotor and manual skill areas. The 
investigators advanced the view that dyspraxia probably played a very important role in the 
impaired speech and signing of many children with ASD. Performance in oromotor and 

John D. Bonvillian 
 
254
manual skills also significantly predicted children’s speech fluency in middle childhood and 
adolescence (Gernsbacher et al., 2008). 
In recent years, it has also been shown that difficulties in imitation are very widespread 
among children with ASD (Shield et al., 2017) and are particularly pronounced in minimally 
verbal children on the ASD spectrum. Although such deficits may make learning to sign more 
difficult for children with ASD, it should be noted that these children’s initially limited 
abilities to imitate do appear to improve with increasing age (Biscaldi et al., 2014). 
 
 
Relationships between Motor Skills and Language and  
Communication Development 
 
There is strong evidence of close relationships between praxis performance, severity of 
impairment, comprehension and communicative skills in children with ASD (Dowell et al., 
2009; Shield et al., 2017). Gesture and motor imitation abilities have been found to be highly 
related to measures of vocabulary size, language development, and language usage 
(Özçalışkan et al., 2017; Slavoff, 1998). Various theories have been advanced in explanation. 
Neither nonverbal intelligence nor chronological age appear to be implicated (Shield et al., 
2017). One view is that children with ASD have problems in forming internal models or 
representations of actions (Haswell et al., 2009). A second interpretation is that the children 
have difficulties in motor planning (Lloyd, MacDonald & Lord, 2011; Smith & Bryson, 
1994). Another explanation specific to the problem of imitating a visual model is that children 
with ASD often have a dysfunctional observation matching system (Bernier et al., 2007). 
Finally, it is also possible that the representations of actions in the working memories of 
children with ASD may have decayed much more quickly than they do in typically 
developing children. These views that children with ASD have difficulties forming internal 
models or that the children’s working memories decay more rapidly may help to explain the 
finding that children with ASD often will successfully imitate only the final action of a 
gestural sequence (Gonsiorowski, Williamson, & Robins, 2016). For further discussion of 
praxis and motor skills in ASD, see Chapters 3 and 7, this volume. 
Because of the difficulties many children with ASD experience in imitation, moulding of 
children’s hands may offer a more effective way of teaching signs. This is where a teacher or 
caregiver takes the child’s hands in their own and then physically guides the correct sign 
formation. As the children learn how to form the sign appropriately, the adults gradually 
reduce their control of the children’s hands. Over time, the children should learn to produce 
their signs on their own (Some children may however resist this approach, which is discussed 
in some detail in Chapter 13, this volume).  
 
 
INTERVENTION APPROACHES 
 
The Simplified Sign System  
 
This system was created by Bonvillian, Kissane-Lee, Dooley and Loncke (2018) to help 
facilitate the development of communication skills in minimally verbal children. At present, it 

Sign Acquisition and Development by Hearing Children… 
 
255
consists of over 1800 signs that were selected or developed to be more readily formed and 
remembered than most signs from existing sign languages or sign communication systems. 
This was accomplished in three ways: (a) the signs in this new system generally consist of a 
single distinct movement (other than repetitions), as most multi-movement signs were not 
included; (b) those sign handshapes and movements, which previous research had shown 
were problematic for children with ASD, were largely avoided by modifying the formation of 
existing signs or creating new signs without these more difficult handshapes and movements; 
and (c) by selecting or developing signs that were highly iconic in that they had readily 
transparent meanings. Although not all of the children learning these new signs are likely to 
recognise the link between the signs and their underlying concepts or meanings, past research 
indicates that many of the children are likely to find the Simplified Sign System signs easier 
to recall than existing signs. Moreover, the children’s teachers and parents also are likely to 
find that this iconic component is very helpful in their learning and remembering of the signs. 
 
 
Aided Communication 
 
For children who do not seem to progress through speech or sign intervention a number 
of augmentative and alternative communication (AAC) systems have been developed in 
recent decades (Beukelman & Mirenda, 2013; Romski et al., 2015). These approaches often 
emphasise the use of pictures, real objects, and electronic and speech-generating devices. 
These systems are based largely on the observation that many of the minimally verbal 
children with ASD have better visual-processing skills than auditory-vocal skills. These 
include PECS (Picture Exchange System: Bondy & Frost, 2002; 2009) which has proved 
efficacious with many children, who are reported to have increased their vocabulary size and 
frequency of communication (Flippin, Reszka & Watson, 2010; Ganz et al., 2012; Gordon et 
al., 2011; Preston & Carter, 2009). And for at least a few of the children involved, there may 
also be an increase in their spoken language skills (Bondy & Frost, 2009), although these 
gains are likely to be small in magnitude (Flippin et al., 2010). An important difference 
between PECS and other systems that involve a child’s pointing at pictures is that PECS 
requires that the child interact directly with another person, through the supported prompting 
to exchange a card for a desired object. However, given the critical importance of pointing in 
language development, for both typically developing and autistic children (Manwaring et al., 
2017; Özçalışkan et al., 2017), it is vital that PECS is employed in a discriminating way - if a 
child is already pointing to objects or pictures, this natural form of communication needs to 
be encouraged.  
There have been relatively few studies that have systematically compared the use of signs 
with that of PECS. Such comparison studies, furthermore, are difficult to conduct because 
children on the autism spectrum often differ widely in their backgrounds and abilities. 
Anderson (2001) largely overcame these problems by teaching the six children she examined 
in sessions that alternated between signs and PECS. The children ranged in age from 2 to 4 
years. Anderson found that the children, as a group, showed a faster rate of item acquisition 
and item generalisation with PECS. In contrast, the children showed greater eye contact, more 
initiation of interaction and communication, and vocalised more frequently with sign training. 
Of the six participants, three of the young children behaviourally preferred PECS and three 
preferred to sign. Probing more deeply, Anderson observed that the three participants who 

John D. Bonvillian 
 
256
preferred to sign tended to be somewhat older and to have higher levels of gross motor skills 
and fine motor skills. In light of these trends, Anderson commented that young children with 
ASD might initially be taught to communicate effectively with PECS and then transition to 
signs after they had developed higher levels of cognitive and motor functioning. 
The results from several other studies (Moodie-Ramdeen, 2008; Nollet, 2008; Tincani, 
2004) that compared children’s learning of PECS with that of signs largely echoed the 
findings from Anderson’s (2001) early study. Although there were frequently wide individual 
differences, the following trends were discerned: (a) progress in learning to communicate was 
faster in PECS than sign; (b) particular children often preferred one approach to another, with 
some preferring to sign and others preferring PECS; (c) there was a trend for children to 
vocalise more while signing than when using PECS; and (d) the children’s problem 
behaviours declined over the course of their training programmes as their communication 
skills improved. In the light of the highly variable outcomes across participants, it is likely 
that the characteristics of the individual children are driving the outcomes of these 
intervention approaches rather than the particular systems themselves. It is also important to 
reflect that these studies focus almost exclusively on request behaviours, so that the effect 
may also be due to the immediate gratification of the reward provided with PECS. The PECS 
approach focuses on instrumental success (acquiring an item chosen by the teacher), while 
more communication-oriented approaches focus on communicative success, that is, on the 
child being understood and being answered (rather than just given something), and on 
communication about agents other than the self in I-WANT and I-SEE of PECS. The 
comparative success of PECS and sign in facilitating a wider range of communicative 
purposes such as social, commenting, joking, narrating has not been explored to date. At least 
one study of autistic children has found that those with vocabularies in excess of 20 words did 
use some of these communication functions (Angeleri et al., 2016). 
Advances in technology in recent years are also transforming the way that many severely 
speech-limited children with ASD are able to communicate. A number of these children have 
learned to effectively use speech-generating devices (Bornman & Alant, 1999; Schlosser, 
Sigafoos & Koul, 2009). Applications such as Proloquo2Go™ (Sennott & Bowker, 2009), 
have essentially overcome the limitation of pre-stored messages. These handheld devices are 
able to produce digitised or synthetic speech after a user presses a picture symbol or other 
key. The large storage capacities of these devices, moreover, means that the children do not 
need to carry with them large communication books or collections of pictures. Using these 
electronic devices, children on the autism spectrum have been shown to acquire the ability to 
label things (Lorah & Parnell, 2017) and to make multistep requests (Alzrayer, Banda & 
Koul, 2017). In teaching the children to use their devices, the investigators often framed their 
intervention in a behavioural modification approach by breaking down the teaching and 
learning process to small steps and rewarding the children on their progress. The teachers also 
would often physically guide the children’s hands as the children learned to navigate the 
system. 
Another advantage to using the Proloquo2Go™ application is that children on the ASD 
spectrum who use it are likely to blend with the peer group, rather than stand out, because the 
widespread use of portable electronic devices. Opportunities may also be provided for 
communication modelling and interaction with the children throughout the day than has been 
the case in the past (Sennott, Light & McNaughton, 2016). Furthermore, typically developing 
children often have more positive attitudes towards an unfamiliar peer with complex 

Sign Acquisition and Development by Hearing Children… 
 
257
communication needs who uses these electronic devices than towards a peer who uses a low-
technology communication board (Dada et al., 2016). 
Investigators have begun to compare the learning and use of signs, PECS, and speech-
generating devices (with Proloquo2Go™ application) in children with ASD (Achmadi et al., 
2014; Couper et al., 2014; McLay et al., 2015). In each of these studies, children learned all 
three communication systems to criterion. There was, however, a general acquisition pattern: 
the children typically reached the criterion faster and maintained performance better with 
PECS and the speech-generating devices than with signs. The principal explanation advanced 
by the investigators to account for this pattern was that these two systems relied 
predominantly on the children’s recognition memory skills, whereas the learning and use of 
signs depended more on the children’s recall skills. Fine motor skills, now recognised to be 
frequently affected children with ASD, are also implicated in these comparisons (Manwaring 
et al., 2017). Also, when probed as to their preferences, the majority of the children opted to 
use the speech-generating devices. It should be noted, however, that – once again – the 
children were being taught to express requests for toys or desired objects: clearly the quickest 
and easiest way of satisfying desire is to point or touch a picture rather than to form a sign.  
These preliminary findings bode well for the continued and expanded use of speech-
generating devices (with Proloquo2Go™ application) with hearing children on the ASD 
spectrum. But it should be recognised that important research work remains to be conducted.  
 
 
CONCLUSION 
 
This chapter has reviewed the history and application of the use of signs to support 
communication development in hearing children with ASD. In the future, it will be important 
to learn which systems results in greater communication success by the children over the long 
term, as well as whether certain systems are more effective at fostering communication skills 
for children of different ages and with diverse constellations of abilities. In the light of the 
very wide range of abilities among children on the ASD spectrum, the recognition of these 
difficulties in signing deaf populations, and the need to commence intervention as early as 
possible, it is likely that the optimal course of intervention may involve the use of more than 
one communication system. 
 
 
ACKNOWLEDGMENTS 
 
Thanks to Aaron Shield for comments and additions to this chapter, and to Bill 
Bonvillian for his help with submission of the MS. 
 
 
REFERENCES 
 
Achmadi, D., Sigafoos, J., van der Meer, L., Sutherland, D., Lancioni, G. E., O’Reilly, M. F., 
Hodis, F., Green, V. A., McLay, L., & Marschik, P. B. (2014). Acquisition, preference, 

John D. Bonvillian 
 
258
and follow-up data on the use of three AAC options by four boys with developmental 
disability/delay. Journal of Developmental and Physical Disabilities, 26, 565-583. 
Alzrayer, N. M., Banda, D. R., & Koul, R. (2017). Teaching children with autism spectrum 
disorder and other developmental disabilities to perform multistep requesting using an 
iPad. Augmentative and Alternative Communication, 33, 65-76. 
Anderson, A. E. (2001). Augmentative communication and autism: A comparison of sign 
language and the Picture Exchange Communication System. Unpublished doctoral 
dissertation, University of California, San Diego, CA. (UMI Microform No.: 3027052) 
Angeleri, R., Gabbatore, I., Bosco, F. M., Sacco, K. & Colle, L. (2016) Pragmatic abilities in 
children and adolescents with autism spectrum disorder: A study with the ABaCo battery. 
Minerva Psichiatrica, 57(3), 93-103.  
Baranek, G. T. (2002). Efficacy of sensory and motor interventions for children with autism. 
Journal of Autism and Developmental Disorders, 32, 397-422. 
Bernier, R., Dawson, G., Webb, S., & Murias, M. (2007). EEG mu rhythm and imitation 
impairments in individuals with autism spectrum disorder. Brain and Cognition, 64, 228-
237. 
Beukelman, D. R., & Mirenda, P. (2013). Augmentative and alternative communication: 
Supporting children and adults with complex communication needs (4th ed.). Baltimore, 
MD: Paul H. Brookes Publishing. 
Bhat, A. N., Srinivasan, S. M., Woxholdt, C., & Shield, A. (2016). Differences in praxis 
performance and receptive language during fingerspelling between deaf children with and 
without autism spectrum disorder. Autism, 22, 271-282.  
Biscaldi, M., Rauh, R., Irion, L., Jung, N. H., Mall, V., Fleischhaker, C., & Klein, C. (2014). 
Deficits in motor abilities and developmental fractionation of imitation performance in 
high-functioning autism spectrum disorders. European Child and Adolescent Psychiatry, 
23, 599-610. 
Bo, J., Lee, C.-M., Colbert, A., & Shen, B. (2016). Do children with autism spectrum 
disorders have motor learning difficulties? Research in Autism Spectrum Disorders, 23, 
50-62. 
Bodison, S., & Mostofsky, S. (2014). Motor control and motor learning processes in autism 
spectrum disorders. In F. R. Volkmar, R. Paul, S. J. Rogers, & K. A. Pelphrey (Eds.), 
Handbook of autism and pervasive developmental disorders: Vol. 1. Diagnosis, 
development, and brain mechanisms (4th ed., pp. 354-377). Hoboken, NJ: John Wiley & 
Sons. 
Bondy, A., & Frost, L. (2002). A picture’s worth: PECS and other visual communication 
strategies in autism. Bethesda, MD: Woodbine House. 
Bondy, A., & Frost, L. (2009). The Picture Exchange Communication System: Clinical and 
research applications. In P. Mirenda & T. Iacono (Eds.), Autism spectrum disorders and 
AAC (pp. 279-302). Baltimore, MD: Paul H. Brookes Publishing. 
Bonnet-Brilhault, F. (2017). L’autisme: Un trouble neuro-développemental précoce. Archives 
de Pédiatrie, 24, 384-390. 
Bonvillian, J. D., & Blackburn, D. W. (1991). Manual communication and autism: Factors 
relating to sign language acquisition. In P. Siple & S. D. Fischer (Eds.), Theoretical 
issues in sign language research: Vol. 2. Psychology (pp. 255-277). Chicago, IL: 
University of Chicago Press. 

Sign Acquisition and Development by Hearing Children… 
 
259
Bonvillian, J. D., Kissane-Lee, N. A., Dooley, T. T., & Loncke, F. T. (2018). Simplified 
Signs: A manual sign communication system for special populations. Vol. 1. Principles, 
background, and application & Vol. 2. Sign descriptions and illustrations. Unpublished 
manuscript, University of Virginia, Charlottesville, VA. 
Bornman, J., & Alant, E. (1999). Training teachers to facilitate interaction with autistic 
children using digital voice output devices. South African Journal of Education, 19, 364-
373. 
Bram, S., Meier, M., & Sutherland, P. J. (1977). A relationship between motor control and 
language development in an autistic child. Journal of Autism and Childhood 
Schizophrenia, 7, 57-67. 
Bristol, M. M., Cohen, D. J., Costello, E. J., Denckla, M., Eckberg, T. J., Kallen, R., Kraemer, 
H. C., Lord, C., Maurer, R., McIlvane, W. J., Minshew, N., Sigman, M., & Spence, M. A. 
(1996). State of the science in autism: Report to the National Institutes of Health. Journal 
of Autism and Developmental Disorders, 26, 121-154. 
Centers for Disease Control and Prevention. (2016). Prevalence and characteristics of autism 
spectrum disorder among children aged 8 years—Autism and Developmental Disabilities 
Monitoring Network, 11 sites, United States, 2012. (MMWR Surveillance Summaries 
Publication 
65(No.SS-3).Accessed 
online 
at 
http://www.cdc.gov/mmwr/ 
volumes/65/ss/ss6503a1.htm. 
Chukoskie, L., Townsend, J., & Westerfield, M. (2013). Motor skill in autism spectrum 
disorders: A subcortical view. International Review of Neurobiology, 113, 207-249. 
Condon, W. S. (1975). Multiple response to sound in dysfunctional children. Journal of 
Autism and Childhood Schizophrenia, 5, 37-56. 
Couper, L., van der Meer, L., Schäfer, M. C. M., McKenzie, E., McLay, L., O’Reilly, M. F., 
Lancioni, G. E., Marschik, P. B., Sigafoos, J., & Sutherland, D. (2014). Comparing 
acquisition of and preference for manual signs, picture exchange, and speech-generating 
devices 
in 
nine 
children 
with 
autism 
spectrum 
disorder. 
Developmental 
Neurorehabilitation, 17, 99-109. 
Creedon, M. P. (1973). Language development in nonverbal autistic children using a 
simultaneous communication system. Paper presented at the biennial meeting of the 
Society for Research in Child Development, Philadelphia, PA. 
Cress, C. J., & Marvin, C. A. (2003). Common questions about AAC services in early 
intervention. Augmentative and Alternative Communication, 19, 254-272. 
Croen, L. A., Grether, J. K., Hoogstrate, J., & Selvin, S. (2002). The changing prevalence of 
autism in California. Journal of Autism and Developmental Disorders, 32, 207-215. 
Dada, S., Horn, T., Samuels, A., & Schlosser, R. W. (2016). Children’s attitudes toward 
interaction with an unfamiliar peer with complex communication needs: Comparing high- 
and low-technology devices. Augmentative and Alternative Communication, 32, 305-311. 
Dowell, L., Mahone, M. & Mostofsky, S. (2009). Associations of postural knowledge and 
basic motor skill with dyspraxia in autism: Implication for abnormalities in 
distributed connectivity and motor learning.  Neuropsychology, 23, 563-570. 
Dunst, C. J., Meter, D., & Hamby, D. W. (2011). Influences of sign and oral language 
interventions on the speech and oral language production of young children with 
disabilities. CELL reviews, 4, 1-20. 
Eisenberg, L. (1956). The autistic child in adolescence. American Journal of Psychiatry, 112, 
607-612. 

John D. Bonvillian 
 
260
Flippin, M., Reszka, S., & Watson, L. R. (2010). Effectiveness of the Picture Exchange 
Communication System (PECS) on communication and speech for children with autism 
spectrum disorders: A meta-analysis. American Journal of Speech-Language Pathology, 
19, 178-195. 
Frith, U. (2008). Autism: A very short introduction. Oxford, UK: Oxford University Press. 
Gaines, R., Leaper, C., Monahan, C., & Weickgenant, A. (1988). Language-learning and 
retention in young language-disordered children. Journal of Autism and Developmental 
Disorders, 18, 281-296. 
Ganz, J. B., Davis, J. L., Lund, E. M., Goodwyn, F. D., & Simpson, R. L. (2012). Meta-
analysis of PECS with individuals with ASD: Investigation of targeted versus non-
targeted outcomes, participant characteristics, and implementation phase. Research in 
Developmental Disabilities, 33, 406-418. 
Gernsbacher, M. A., Dawson, M., & Goldsmith, H. H. (2005). Three reasons not to believe in 
an autism epidemic. Current Directions in Psychological Science, 14, 55-58. 
Gernsbacher, M. A., Sauer, E. A., Geye, H. M., Schweigert, E. K., & Goldsmith, H. H. 
(2008). Infant and toddler oral- and manual-motor skills predict later speech fluency in 
autism. Journal of Child Psychology and Psychiatry, 49, 43-50. 
Gervais, H., Belin, P., Boddaert, N., Leboyer, M., Coez, A., Sfaello, I., Barthélémy, C., 
Brunelle, F., Samson, Y., & Zilbovicius, M. (2004). Abnormal cortical voice processing 
in autism. Nature Neuroscience, 7, 801-802. 
Gidley Larson, J. C., & Mostofsky, S. H. (2006). Motor deficits in autism. In R. Tuchman & 
I. Rapin (Eds.), Autism: A neurological disorder of early brain development (pp. 231-
247). London, UK: Mac Keith Press. 
Goldstein, H. (2002). Communication intervention for children with autism: A review of 
treatment efficacy. Journal of Autism and Developmental Disorders, 32, 373-396. 
Gonsiorowski, A., Williamson, R. A., & Robins, D. L. (2016). Brief report: Imitation of 
object-directed acts in young children with autism spectrum disorders. Journal of Autism 
and Developmental Disorders, 46, 691-697. 
Gordon, K., Pasco, G., McElduff, F., Wade, A., Howlin, P., & Charman, T. (2011). A 
communication-based intervention for nonverbal children with autism: What changes? 
Who benefits? Journal of Consulting and Clinical Psychology, 79, 447-457. 
Grandin, T. (1995). Thinking in pictures and other reports from my life with autism. New 
York, NY: Doubleday. 
Grandin, T., & Panek, R. (2013). The autistic brain: Thinking across the spectrum. New 
York, NY: Houghton Mifflin Harcourt.Gruson-Wood, J. (2016). Autism, expert 
discourses and subjectification: A critical examination of applied behavioural therapies. 
Studies in Social Justice, 10, 38-58. 
Haswell, C. C., Izawa, J., Dowell, L. R., Mostofsky, S. H., & Shadmehr, R. (2009). 
Representation of internal models of action in the autistic brain. Nature Neuroscience, 12, 
970-972. 
Howlin, P., Goode, S., Hutton, J., & Rutter, M. (2004). Adult outcome for children with 
autism. Journal of Child Psychology and Psychiatry, 45, 212-229. 
Kanner, L. (1943). Autistic disturbances of affective contact. The Nervous Child,  
2, 217-
250.Kates-McElrath, K., & Axelrod, S. (2006). Behavioral intervention for autism: A 
distinction between two behavior analytic approaches. The Behavior Analyst Today, 7(2), 
242-252. 

Sign Acquisition and Development by Hearing Children… 
 
261
Kim, S. H., & Lord, C. (2014). Autism and language development. In P. J. Brooks & V. 
Kempe (Eds.), Encyclopedia of language development (pp. 36-39). Los Angeles, CA: 
SAGE Publications. 
Konstantareas, M. M., Oxman, J., & Webster, C. D. (1978). Iconicity: Effects on the 
acquisition of sign language by autistic and other severely dysfunctional children. In P. 
Siple (Ed.), Understanding language through sign language research (pp. 213-237). New 
York, NY: Academic Press. 
Layton, T. L. (1987). Manual communication. In T. L. Layton (Ed.), Language and treatment 
of autistic and developmentally disordered children (pp. 189-213). Springfield, IL: 
Charles C Thomas. 
Lal, R. (2010). Effect of alternative and augmentative communication on language and social 
behaviour of children with autism. Educational Research Reviews, 5(3), 119-125 
Lettick, A. L. (1972, June). Pre-vocational training program at Benhaven. Paper presented at 
the 4th annual meeting of the National Society for Autistic Children, Flint, MI. 
Lettick, A. L. (1979). Benhaven then and now. New Haven, CT: The Benhaven Press. 
Lloyd, M., MacDonald, M., & Lord, C. (2011). Motor skills of toddlers with autism spectrum 
disorders. Autism, 17, 133-146. 
Lorah, E. R., & Parnell, A. (2017). Acquisition of tacting using a speech-generating device in 
group learning environments for preschoolers with autism. Journal of Developmental and 
Physical Disabilities, 29, 597-609. 
Lord, C., & Bailey, A. (2002). Autism spectrum disorders. In M. Rutter & E. Taylor (Eds.), 
Child and adolescent psychiatry (4th ed., pp. 636-663). Oxford, UK: Blackwell Science. 
Lord, C., & Paul, R. (1997). Language and communication in autism. In D. J. Cohen & F. R. 
Volkmar (Eds.), Handbook of autism and pervasive developmental disorders (2nd ed., pp. 
195-225). New York, NY: John Wiley & Sons. 
Lotter, V. (1974). Factors related to outcome in autistic children. Journal of Autism and 
Childhood Schizophrenia, 4, 263-277. 
Lovaas, O. I. (1977). The autistic child: Language development through behavior 
modification. New York, NY: Irvington Publishers, John Wiley & Sons. 
Lovaas, O. I. (1987). Behavioral treatment and normal educational and intellectual 
functioning in young autistic children. Journal of Consulting and Clinical Psychology, 
55, 3-9. 
Lovaas, O. I., Koegel, R., Simmons, J. Q., & Long, J. S. (1973). Some generalization and 
follow-up measures on autistic children in behavior therapy. Journal of Applied Behavior 
Analysis, 6, 131-166. 
Manwaring, S. Mead, D., Swineford, L. & Thurm, A. (2017). Modelling gesture use and early 
language development in autism spectrum disorder. International Journal of Language 
and Communication Disorders, 52, 637-651. 
McLay, L., van der Meer, L., Schäfer, M. C. M., Couper, L., McKenzie, E., O’Reilly, M. F., 
Lancioni, G. E., Marschik, P. B., Green, V. A., Sigafoos, J., & Sutherland, D. (2015). 
Comparing acquisition, generalization, maintenance, and preference across three AAC 
options in four children with autism spectrum disorder. Journal of Developmental and 
Physical Disabilities, 27, 323-339. 
Mesibov, G. B., Adams, L. W., & Klinger, L. G. (1997). Autism: Understanding the disorder. 
New York, NY: Plenum Press. 

John D. Bonvillian 
 
262
Millar, D. C. (2009). Effects of AAC on the natural speech development of individuals with 
autism spectrum disorders. In P. Mirenda & T. Iacono (Eds.), Autism spectrum disorders 
and AAC (pp. 171-192). Baltimore, MD: Paul H. Brookes Publishing. 
Millar, D. C., Light, J. C., & Schlosser, R. W. (2006). The impact of augmentative and 
alternative communication intervention on the speech production of individuals with 
developmental disabilities: a research review. Journal of Speech, Language, and Hearing 
Research, 49, 248-264. 
Mirenda, P. (2008). A back door approach to autism and AAC. Augmentative and Alternative 
Communication, 24, 220-234. 
Mirenda, P. (2014). Augmentative and alternative communication. In F. R. Volkmar, R. Paul, 
S. J. Rogers, & K. A. Pelphrey (Eds.), Handbook of autism and pervasive developmental 
disorders: Vol. 2. Assessment, interventions, and policy (4th ed., pp. 813-825). Hoboken, 
NJ: John Wiley & Sons. 
Mitchell, P., & Ropar, D. (2004). Visuo-spatial abilities in autism: A review. Infant and Child 
Development, 13, 185-198. 
Moodie-Ramdeen, T. (2008). Sign language versus Picture Exchange Communication System 
in language acquisition in young children with autism. Unpublished doctoral dissertation, 
Capella University, Minneapolis, MN. (UMI Microform No.: 3339029). 
Nollet, M. D. (2008). A systematic investigation of picture exchange and sign language for 
the acquisition of mands in young children with autism. Unpublished master’s thesis, 
University of Nevada, Reno, NV. (UMI Microform No.: 1455653) 
Offir, C. W. (1976, June). Visual speech: Their fingers do the talking. Psychology Today, 10, 
72-78. 
Özçalışkan, S., Adamson, L., Dimitrova. N. & Baumann. S. (2017) Early gesture provides a 
helping hand to spoken vocabulary development for children with autism, Down 
Syndrome, and typical development, Journal of Cognition and Development, 18:3, 325-
337. 
Page, J., & Boucher, J. (1998). Motoric impairments in children with autistic disorder. Child 
Language Teaching and Therapy, 14, 233-259. 
Peeters, T., & Gillberg, C. (1999). Autism: medical and educational aspects. London, UK: 
Whurr Publishers. 
Preston, D., & Carter, M. (2009). A review of the efficacy of the Picture Exchange 
Communication System intervention. Journal of Autism and Developmental Disorders, 
39, 1471-1486. 
Romski, M., Sevcik, R. A., Barton-Hulsey, A., & Whitmore, A. S. (2015). Early intervention 
and AAC: What a difference 30 years makes. Augmentative and Alternative 
Communication, 31, 181-202Rowe,J. & Goldin-Meadow, S. (2009). Early gesture 
selectively predicts later language learning. Developmental Science, 12, 182-187. 
Schlosser, R. W., Sigafoos, J., & Koul, R. K. (2009). Speech output and speech-generating 
devices in autism spectrum disorders. In P. Mirenda & T. Iacono (Eds.), Autism spectrum 
disorders and AAC (pp. 141-169). Baltimore, MD: Paul H. Brookes Publishing. 
Seal, B. C., & Bonvillian, J. D. (1997). Sign language and motor functioning in students with 
autistic disorder. Journal of Autism and Developmental Disorders, 27, 437-466. 
Sennott, S., & Bowker, A. (2009). Autism, AAC, and Proloquo2Go. Perspectives on 
Augmentative and Alternative Communication, 18, 137-145. 

Sign Acquisition and Development by Hearing Children… 
 
263
Sennott, S. C., Light, J. C., & McNaughton, D. (2016). AAC modeling intervention research 
review. Research and Practice for Persons with Severe Disabilities, 41, 101-115. 
Shield, A. (2014). Preliminary findings of similarities and differences in the signed and 
spoken language of children with autism. Seminars in Speech and Language, 35, 309–
320. 
Shield, A. Cooley, F. & Meier, R. (2017). Sign language echolalia in deaf children with ASD. 
Journal of Speech, Language and Hearing Research, 60, 1622-1634.  
Shield, A., Knapke, K., Henry, M., Srinivasan, S. & Bhat, A. (2017). Impaired praxis in 
gesture imitation by deaf children with autism spectrum disorder. Autism & 
Developmental Language Impairments, 2, 1–14. 
Shield, A., & Meier, R. P. (2012). Palm reversal errors in native-signing children with autism. 
Journal of Communication Disorders, 45, 439–454.  
Shield, A., Meier, R. P., & Tager-Flusberg, H. (2015). The use of sign language pronouns by 
native-signing children with autism. Journal of Autism and  
Developmental 
Disorders, 45, 2128–2145. 
Shield, A., Pyers, J., Martin, A., & Tager-Flusberg, H. (2016). Relations between language 
and cognition in native-signing children with autism spectrum disorder. Autism Research, 
9, 1304–1315.  
Silberman, S. (2015). NeuroTribes: The legacy of autism and the future of neurodiversity. 
New York, NY: Avery. 
Slavoff, G. (1998). Motor development in children with autism. Unpublished doctoral 
dissertation, University of Virginia, Charlottesville, VA. (UMI Microform No.: 9824251) 
Smith, I. M., & Bryson, S. E. (1994). Imitation and action in autism: A critical review. 
Psychological Bulletin, 116, 259-273. 
Smith, I. M., & Bryson, S. E. (2007). Gesture imitation in autism: II. Symbolic gestures and 
pantomimed object use. Cognitive Neuropsychology, 24, 679-700. 
Soorya, L. V. (2003). Evaluation of motor proficiency and apraxia in autism: Effects on sign 
language acquisition. Unpublished doctoral dissertation, Binghamton University, State 
University of New York, Binghamton, NY. (UMI Microform No.: 3102088) 
Sperdin, H. F., & Schaer, M. (2016). Aberrant development of speech processing in young 
children with autism: New insights from neuroimaging biomarkers. Frontiers in 
Neuroscience, 10, AR 393. 
Tager-Flusberg, H., & Kasari, C. (2013). Minimally verbal school-aged children with autism 
spectrum disorder: The neglected end of the spectrum. Autism Research, 6, 468-478. 
Tan, X., Trembath, D., Tennison, O., Bloomberg, K. & Iacono, T. (2014). Acquisition and 
generalisation 
of 
signing 
by 
three 
children 
with 
autism. 
Developmental 
Neurorehabilitation, 17, 99-109. 
Tincani, M. (2004). Comparing the Picture Exchange Communication System and sign 
language training for children with autism. Focus on Autism and Other Developmental 
Disabilities, 19, 152-163. 
Valentino, A. L., & Shillingsburg, M. A. (2011). Acquisition of mands, tacts, and intraverbals 
through sign exposure in an individual with autism. The Analysis of Verbal Behavior, 
27(1), 95-101. 
Vanvuchelen, M., Roeyers, H., & De Weerdt, W. (2007). Nature of motor imitation problems 
in school-aged boys with autism: A motor or a cognitive problem? Autism, 11, 225-240. 

John D. Bonvillian 
 
264
Webster, C. D., Fruchter, D., Dean, J., Konstantareas, M. M., & Sloman, L. (2016). Lessons 
that linger: A 40-year follow-along note about a boy with autism taught to communicate 
by gestures when aged six. Journal of Autism and Developmental Disorders, 46, 2561-
2564. 
Wendt, O. (2009). Research on the use of manual signs and graphic symbols in autism 
spectrum disorders: A systematic review. In P. Mirenda & T. Iacono (Eds.), Autism 
spectrum disorders and AAC (pp. 83-139). Baltimore, MD: Paul H. Brookes Publishing. 
Wodka, E. L., Mathy, P., & Kalb, L. (2013). Predictors of phrase and fluent speech in 
children with autism and severe language delay. Pediatrics, 131, 1-7. 
Zwaigenbaum, L., Bryson, S. E., Brian, J., Smith, I. M., Roberts, W., Szatmari, P., Roncadin, 
C., Garon, N., & Vaillancourt, T. (2016). Stability of diagnostic assessment for autism 
spectrum disorder between 18 and 36 months in a high-risk cohort. Autism Research, 9, 
790-800. 
 

In: Encyclopedia of Audiology and Hearing Research 
ISBN: 978-1-53617-702-2 
Editors: Erno Larivaara and Senja Korhola 
© 2020 Nova Science Publishers, Inc. 
 
 
 
 
 
 
 
Chapter 20 
 
 
 
HYPERBARIC OXYGEN THERAPY IN SUDDEN 
SENSORINEURAL HEARING LOSS 
 
 
Sema Zer Toros1, MD, Omer Cagatay Ertugay2, MD  
and Cigdem Kalaycik Ertugay2,, MD 
1Haydarpasa Numune Education and Research Hospital, Department of 
Otorhinolaryngology/Head and Neck Surgery, Istanbul, Turkey 
2Istanbul Education and Research Hospital, Department of Otorhinolaryngology/ 
Head and Neck Surgery, Istanbul, Turkey 
 
 
ABSTRACT 
 
Sudden sensorineural hearing loss (SSNHL) is a common clinical entity and defined 
as a rapid onset of hearing impairment, occurring within three days. It has an audiometric 
criteria identified as a decrease in hearing of at least 30 dB over three contiguous test 
frequencies in one or both ears. It has a significant effect on quality of life. As the 88% of 
SSNHL cases is idiopathic at presentation, there is usually no known exact specific 
etiologic factor. However, multiple reasons such as vascular compromise and associated 
cochlear ischemia or viral etiologies, etc. have been presumed and the treatment 
modalities have been empiric. Although oral steroid therapy is the mainstay treatment in 
clinical practice, in most of the centers, several different treatment modalities proposed in 
the literature. Hyperbaric oxygen therapy (HBOT), which has been used for SSNHL 
treatment since 1979, exposes a patient to 100% oxygen at a pressure level higher than 1 
atmosphere absolute in a specially designed sealed chamber. This facilitates a delivery of 
increased partial pressure of oxygen to the tissues. Based on this fact, it is thought that 
HBOT may prevent damage caused from ischemia by improving the supply of oxygen to 
the inner ear and result in an improvement in hearing. This review focuses on the benefits 
and harms of HBOT in treating SSNHL. 
 
Keywords: sudden sensorineural hearing loss, hyperbaric oxygen therapy, hearing 
impairment 
 
                                                        
 Corresponding Author’s Email: ckalaycik@gmail.com. 

S. Z. Toros, O. C. Ertugay and C. K. Ertugay 
 
266
INTRODUCTION 
 
Sudden sensorineural hearing loss (SSNHL) is a common clinical entity and defined as a 
rapid onset of hearing impairment in one or both ears, occurring within three days. It has an 
audiometric criteria identified as a decrease in hearing of at least 30 dB over three contiguous 
test frequencies in one or both ears. Patients usually admit to the emergency department 
because of the frightening symptoms such as aural fullness, tinnitus or vertigo. It affects 4000 
new people per year in the United States [1-2]. Approximately 88% of SSNHL cases is 
idiopathic at presentation. However, multiple reasons such as vascular compromise and 
associated cochlear ischemia, viral etiologies, autoimmune, trauma, schwannoma, 
demyelinating disease, etc. have been presumed [3]. If the clinicians cannot identify the 
reason, it is named as idiopathic SSNHL and the treatment is empiric. The exact spontaneous 
recovery rate cannot be determined, because most of the patients seek medical care in the 
early period and are treated empirically. The reported rate of spontaneous recovery ranges 
from 32% to 65% [2, 4]. Although hearing aids are recommended in nonhealing patients with 
moderate or severe hearing loss, SSNHL has a significant effect on quality of life. There are 
various different treatment modalities such as systemic and intratympanic steroids, 
vasodilators, antiviral agents, diuretics, hyperbaric oxygen therapy (HBOT), etc. However, 
the exact efficacy of these treatments is not known due to the fact that clinicians cannot 
determine a definitive etiology in most of the cases. Although oral steroid therapy is the 
mainstay treatment in clinical practice in most of the centers, there are several randomized 
controlled studies for only HBOT [5-7]. 
 
 
INDICATIONS 
 
The blood supply of inner ear and vestibulocochlear nerve is maintained by labyrinthine 
artery and also by diffusion through perilymph and cortilymph. The labyrinthine artery has no 
anastomosis. Therefore, cochlea is very sensitive to ischemia and cochlear hypoxia results in 
progressive degenerative changes, loss of neurons, and hearing loss. 
Vascular compromise and associated cochlear ischemia is one of the possible etiologic 
factors of SSNHL. HBOT exposes a patient to 100% oxygen at a pressure level higher than 1 
atmosphere absolute in a specially designed sealed chamber. This facilitates a delivery of 
increased partial pressure of oxygen to the tissues. Moreover, it may improve the host 
reaction against infection and ischemia by reducing hypoxia and edema due to its complex 
effects on immunity, oxygen transport, and hemodynamics [8]. Based on these facts, it is 
thought that HBOT may prevent damage caused from ischemia by improving the supply of 
oxygen to the inner ear, increasing the oxygen tension in perilymph and result in an 
improvement in hearing. The patency of labyrinthine artery and the rising rate of oxygen 
tension in perilymph influence the efficacy of HBOT in SSNHL [9]. 
The clinical guideline of The American Academy of Otolaryngology indicated that 
corticosteroids and HBOT are treatment options whereas other pharmacologic therapies such 
as antivirals, thrombolytics, vasodilators, vasoactive substances, or antioxidants should not be 
prescribed routinely by clinicians. The guideline stated that patient needs multiple 1- to 2-
hour sessions (mostly 5 to 10 times) over days to weeks for HBOT which is expensive and 

Hyperbaric Oxygen Therapy in Sudden Sensorineural Hearing Loss 
 
267
the reports about HBOT had small number of patients and methodological shortcomings. 
However, they indicated that HBOT may have benefits according to the reported studies and 
offered HBOT as an adjunctive therapy. They emphasized that it may have better effect in the 
early period (within 3 months of the onset of SSNHL), younger patients (younger than 50-60 
years), and patients with moderate to severe or severe to profound hearing loss [10]. 
 
 
SIDE EFFECTS AND COMPLICATIONS 
 
The possible side effects of HBOT include oxygen poisoning, claustrophobia, temporary 
worsening of short-sightedness, and damage to sinuses, lungs, and ears due to the pressure 
changes [10]. The cochrane database review including seven randomized controlled trials, 
which evaluated the efficacy of HBOT on treatment of SSNHL, reported no systemic side 
effects [11]. The most common complication of HBOT is middle ear barotrauma [9]. Plafki et 
al. evaluated the complications and side effects of HBOT in 782 patients with 11,376 
sessions. The indication of HBOT in this patients was various. They identified that ear pain or 
discomfort was the predominant complaint of patients which was seen in 17% of patients. 
They indicated that this is due to the difficultly equalizing pressure in the middle ear [12]. 
Fernau et al. evaluated the effect of HBOT on eustachian tube function in patients who 
undergone HBOT for several different indications and detected eustachian tube dysfunction 
in 45% of patients [13]. On the other hand, the complication rate in the patients undergoing 
HBOT for SSNHL is fewer. The concurrent use of systemic steroids might be the reason of 
this, because steroids may decrease the edema or inflammation which enhances the pressure 
equalization [10]. Pilgramm et al. reported that three of their participants who were 
performed HBOT for SSNHL were withdrawn the therapy due to the middle ear barotrauma 
[14]. Another study observed 6.25% ear or sinus barotrauma in 80 patients undergoing HBOT 
for SSNHL [15]. 
 
 
CONTRAINDICATIONS 
 
The major contraindications include pneumothorax, severe reactive airways disease, 
severe congestive heart failure, concomitant doxorubicin or bleomycin therapy, and 
confinement anxiety [9]. 
 
 
RELATED ARTICLES 
 
The first usage of HBOT in SSHNL in the literature was in 1979 [16]. Since that time, 
various studies have been performed [5-7, 11]. The improvement of hearing loss with HBOT 
was indicated in a cochrane database review but the certain level or clinical relevance of this 
improvement was not clear. This report reviewed seven trials published between 1985 and 
2004 including 392 participants in whom 207 received HBOT and 185 was control. The dose 
of oxygen per treatment session varied between 1.5 and 2.5 ATA as a maximum oxygen 
pressure and the total course of treatment varied between 10 to 25 sessions in these 

S. Z. Toros, O. C. Ertugay and C. K. Ertugay 
 
268
randomized controlled studies included in this review. They determined the chance of a 25% 
increase following HBOT. They indicated that better results may be seen if the patient was 
treated within 2 weeks of acute onset and the amelioration may be associated with onset 
severity of the hearing loss [11]. 
Naiboglu et al. evaluated the effects of three treatment modalities which were 
intratympanic steroid, systemic steroid, and HBOT on SSNHL treatment. They indicated that 
patients with profound hearing loss might have better success rate if these three treatment 
modalities are applied together [17]. 
Ajduk et al. investigated 93 patients with SSNHL who did not get benefit from steroid 
therapy. Forty-three of these patients had undergone HBOT as a salvage therapy. They found 
that although patients with moderate hearing loss (≤60 dB) had improvement only at low 
frequencies (0.25 and 0.5 kHz), patients with severe hearing loss (>61 dB) had improvement 
at all frequencies [18]. 
Alimoglu et al. investigated the impact of HBOT as a salvage treatment of SSNHL by 
retrospectively reviewing the medical records of their patients who had received a 14-day 
course of failed oral corticosteroid therapy. They found that the mean gain of pure tone 
average was more prominent in lower frequencies (0.25 kHz and 0.5 kHz) than higher ones. 
They proposed that the reason might be the increased vulnerability of the basal turn of the 
cochlea to damage which leads to a lower predisposition to the recovery [19]. Similar to the 
report of Alimoglu et al., Muzzi et al. observed higher gains in lower frequencies in 19 
patients who received 30 sessions of HBOT after failed medical treatment. However, they did 
not state the details of applied medical treatment [20]. 
On the other hand, Cekin et al. studied the efficacy of HBOT on SSNHL as an adjunctive 
treatment by treating 36 patients with HBOT with concomitant medical therapy with 
prednisolone (study group) and treating 21 patients with only prednisolone (control group). 
They compared these two patient groups. Although they found higher success rate in the 
study group, this difference was not statistically significant. They suggested HBOT as an 
alternative therapy only if the patients have contraindications for medical therapy such as 
peptic ulceration, hypertension, old age, etc. [21]. 
 
 
REFERENCES 
 
[1] 
Byl F. M. Seventy-six cases of presumed sudden hearing loss occurring in 1973: 
prognosis and incidence. Laryngoscope. 1977;87(5, pt 1):817-825. 
[2] 
Mattox D. E., Simmons F. B. Natural history of sudden sensorineural hearing loss. Ann. 
Otol. Rhinol. Laryngol. 1977;86(4, pt 1):463-480. 
[3] 
Rauch S. D. Clinical practice: idiopathic sudden sensorineural hearing loss. N. Engl. J. 
Med. 2008;359(8):833-840. 
[4] 
Conlin A. E., Parnes L. S. Treatment of sudden sensorineural hearing loss, II: a meta-
analysis. Arch. Otolaryngol. Head Neck Surg. 2007;133(6):582-586. 
[5] 
Narozny W., Kuczkowski J., Mikaszewski B. HBO effectively supports SSNHL 
therapy. Eur. Arch. Otorhinolaryngol. 2005;262(2):163-4. 

Hyperbaric Oxygen Therapy in Sudden Sensorineural Hearing Loss 
 
269
[6] 
Racic G., Maslovara S., Roje Z., et al. Hyperbaric oxygen in the treatment of sudden 
hearing loss. ORL J. Otorhinolaryngol. Relat. Spec. 2003;65(6):317-20. 
[7] 
Horn C. E., Himel H. N., Selesnick S. H. Hyperbaric oxygen therapy for sudden 
sensorineural hearing loss: a prospective trial of patients failing steroid and antiviral 
treatment. Otol. Neurotol. 2005;26(5):882-9. 
[8] 
Gill A. L., Bell C. N. Hyperbaric oxygen: its uses, mechanisms of action and outcomes. 
QJM. 2004;97(7):385-395. 
[9] 
Murphy-Lavoie H. M., Mutluoglu M. Hyperbaric, Sensorineural Hearing Loss. In: 
StatPearls [Internet]. Treasure Island (FL): StatPearls Publishing; 2019-2018 Oct 27. 
[10] Stachler R. J., Chandrasekhar S. S., Archer S. M., et al. Clinical practice guideline: 
sudden hearing loss. Otolaryngol. Head Neck Surg. 2012;146(3 Suppl.):S1-35. 
[11] Bennett M. H., Kertesz T., Yeung P. Hyperbaric oxygen for idiopathic sudden 
sensorineural 
hearing 
loss 
and 
tinnitus. 
Cochrane 
Database 
Syst. 
Rev. 
2007;1:CD004739. 
[12] Plafki C., Peters P., Almeling M., Welslau W., Busch R. Com- plications and side 
effects of hyperbaric oxygen therapy. Aviat. Space Environ. Med. 2000;71(2):119-124. 
[13] Fernau J. L., Hirsch B. E., Derkay C., Ramasastry S., Schaefer S. E. Hyperbaric oxygen 
therapy: effect on middle ear and eusta- chian tube function. Laryngoscope. 
1992;102(1):48-52. 
[14] Pilgramm M., Lamm H., Schumann K. Hyperbaric oxygen therapy in sudden deafness 
[Zur hyperbaren Sauerstofftherapie beim Hörsturz]. Laryngologie, Rhinologie, Otologie 
1985;64(7):351-4. 
[15] Korpinar S., Alkan Z., Yigit O., et al. Factors influencing the outcome of idiopathic 
sudden sensorineural hearing loss treated with hyperbaric oxygen therapy. Eur. Arch. 
Otorhinolaryngol. 2011;268(1):41-47. 
[16] Goto F., Fujita T., Kitani Y., et al. Hyperbaric oxygen and stellate ganglion blocks for 
idiopathic sudden hearing loss. Acta Otolaryngol. 1979;88(5-6):335-42. 
[17] Naiboğllu B., Külekçi S., Sürmeli M., Verim A., Kalaycik Ertugay Ç., İhvan Ö., 
Şeneldir L., Zer Toros S. Efficacy of multimodality approach to sudden hearing loss. 
The Turkish Journal of Ear Nose and Throat, 2015;25(2), 77-81. 
[18] Ajduk J., Ries M., Trotic R., Marinac I., Vlatka K., Bedekovic V. Hyperbaric Oxygen 
Therapy as Salvage Therapy for Sudden Sensorineural Hearing Loss. J. Int. Adv. Otol. 
2017;13(1):61-64. 
[19] Alimoglu Y., Inci E. Is hyperbaric oxygen therapy a salvage treatment option for 
sudden sensorineural hearing loss? J. Laryngol. Otol. 2016 Oct;130(10):943-947. 
[20] Muzzi E., Zennaro B., Visentin R., Soldano F., Sacilotto C. Hyperbaric oxygen therapy 
as salvage treatment for sudden sensorineural hearing loss: review of rationale and 
preliminary report. J. Laryngol. Otol. 2010;124:e2. 
[21] Cekin E., Cincik H., Ulubil S. A., Gungor A. Effectiveness of hyperbaric oxygen 
therapy in management of sudden hearing loss. J. Laryngol. Otol. 2009;123(6):609-612. 


In: Encyclopedia of Audiology and Hearing Research 
ISBN: 978-1-53617-702-2 
Editors: Erno Larivaara and Senja Korhola 
© 2020 Nova Science Publishers, Inc. 
 
 
 
 
 
 
 
Chapter 21 
 
 
 
AMINOGLYCOSIDE MEDIATED OTOTOXICITY AND 
HEARING LOSS IN CYSTIC FIBROSIS PATIENTS:  
AN UNMET MEDICAL NEED 
 
 
Rahul Mittal1,*, Luca H. Debs1 and Kalai Mathee2,3 
1Department of Otolaryngology,  
University of Miami Miller School of Medicine, Miami, FL, US 
2Department of Human and Molecular Genetics,  
Herbert Wertheim College of Medicine,  
Florida International University, Miami, FL, US 
3Biomolecular Sciences Institute,  
Florida International University, Miami, FL, US 
 
 
ABSTRACT 
 
Cystic Fibrosis (CF) is a highly debaliting disease that occurs with high prevalence 
worldwide. Due to the frequent infections observed in CF patients, physicians 
recommend antibiotics especially aminoglycosides. However, it leads to cochlear 
ototoxicity and consequent hearing loss in CF patients. In this commentary, we have 
highlighted the serious issue of aminoglycoside mediated hearing loss in CF patients. 
Through this commentary, we want to draw the attention of the clinicians that an active 
collaboration between pulmonologists and otolaryngologists will facilitate in early 
detection of hearing loss in CF patients and hence better clinical outcomes. We have also 
discussed the alternative approaches to avoid aminoglycoside-induced cochleotoxicity in 
CF patients. 
 
 
 
 
                                                        
* Corresponding Author’s: Email: r.mittal11@med.miami.edu. 

Rahul Mittal, Luca H. Debs and Kalai Mathee 
 
272
INTRODUCTION 
 
Cystic fibrosis (CF) is a genetic disease affecting about 30,000 people in the U.S. and 
more than 70,000 individuals worldwide. It is a progressive and detrimental illness that 
causes persistent lung irritation and increased susceptibility to air-borne pathogens, with the 
latter being the primary cause of mortality in CF patients. Despite new advancements in 
medical technology, CF remains a deadly disease with a median survival of 40 years. As new 
infections of the airways commonly occur in CF patients, clinicians recommend the use of 
broad-spectrum antibiotics. Pseudomonas aeruginosa is the most prevalent pulmonary 
pathogen in CF patients. However, the emergence of antibiotic resistance has limited the 
treatment options. Members of the aminoglycoside family of antibiotics become the last 
treatment modality in cases of severe and resistant infection in CF patients. However, the use 
of aminoglycosides (AGs) leads to undesirable side effects including irreversible hearing loss 
(HL) due to cochlear ototoxicity. A study reported a prevalence of HL as high as 23% in AG-
treated CF patients [1]. CF itself is a very debilitating disease, and occurrence of HL further 
deteriorates the quality of life of CF patients. 
 
 
MOLECULAR MECHANISMS UNDERLYING OTOTOXICITY 
 
A number of molecular mechanisms have been implicated in the pathophysiology of AG 
ototoxicity. The mitochondria of epithelial cells in the lateral wall of the cochlear duct act as 
secondary targets for AGs that can cause mitochondrial damage [2]. This can lead to 
insufficient energy production in the cochlea inducing sensory cell death and HL. 
Furthermore, the overabundance of free radicals caused by deactivation of antioxidant 
enzymes results in higher physiological stress and more sensory cell death, further worsening 
the problem of HL [3]. Histopathological examination of temporal bone specimens from 
deceased CF donors exposed to AGs demonstrated a significant loss of vestibular hair cells 
(both type I and II), dark cells, and spiral ganglion neurons in Rosenthal’s canal at the apical 
turn of the cochlea. A decrease in the area of the stria vascularis at the apical turn of the 
cochlea was also observed compared to the control group. 
 
 
ALTERNATIVE APPROACHES TO AVOID  
AMINOGLYCOSIDE OTOTOXICITY 
 
One strategy to prevent HL in CF patients is to screen for mitochondrial mutations that 
determine predisposition to AG ototoxicity. In particular, the mitochondrial mutation 
m.1555A>G can lead to severe and rapid HL when exposed to even low levels of the drugs 
[4]. Additionally, adjunct therapies should be considered for those receiving AGs. The risk 
for HL, though lower in the absence of the mitochondrial mutation, remains too high to be 
negligible. The presence of AGs in the cochlea promotes the formation of reactive oxygen 
species that do not get cleared adequately. The parallel administration of free radical 
scavengers such as mannitol can overcome this deficiency. Mannitol have potent free radical 
scavenging properties when applied to its target site [5]. Albeit more involved than an oral 

Aminoglycoside Mediated Ototoxicity and Hearing Loss… 
 
273
intake, intracochlear administration of mannitol with direct application to the round window 
is a feasible approach. Another compound to be considered for preventative therapy is 
fenofibrate that is used for treatment of lipid disorders appears to protect against gentamicin-
induced ototoxicity. Fenofibrate interacts with the DNA promoter regions of genes for 
catalase and superoxide dismutase-1, anti-oxidant enzymes that prevent the build-up of 
oxidative stress [3]. By inhibiting the oxidative cascade, fenofibrate directly blocks the 
production of reactive oxygen species and reduces apoptosis in hair cells. An additional 
approach in preventing ototoxicity would be to block cellular entry of antibiotics in the 
cochlea. Phenoxybenzamine, an alpha-blocker mainly used in the treatment of 
pheochromocytoma, can inhibit uptake of AGs into hair cells [6]. Phenoxybenzamine is the 
only agent identified so far to abrogate AG interaction with the mitochondria of inner and 
outer hair cells. Thus, there is a need to explore the efficacy of phenoxybenzamine in 
preventing AG-mediated ototoxicity in clinical trials. 
Since the therapeutic properties of AGs remain unparalleled, a slight change in their 
design aiming at conserving the therapeutic benefits while minimizing the significant side 
effects could offer a better solution. Physicians are looking for new ways to develop effective 
treatment modalities for CF. Indeed, an effective strategy to prevent AG-mediated HL could 
be found in the structural modification of the antibiotics [7]. The development of modified 
AG antibiotics is already underway. These designer antibiotics are derived from the structural 
backbones of existing AGs and are less ototoxic while still maintaining their therapeutic 
efficacy against pathogens. 
 
 
CONCLUSION 
 
Bacterial infections are the plague of the 21st century posing a growing challenge to 
public health. Despite a vast arsenal available to fight them, we often find ourselves left with 
very few options when it comes to treating CF patients infected by recurring resistant 
pathogens. As they are cheap, widely available, and broad-spectrum, AGs are often the drugs 
of choice. Nevertheless, with a significant risk of selective sensory hair cell loss caused by 
their use, it is imperative to find new venues for providing care for the fragile CF patient 
population. In our opinion, modified AGs (designer drugs) show the most potential as they 
maintain efficacy while making these drugs less or non-ototoxic with a broader therapeutic 
index. Adjunct therapies have shown positive results but are associated with a few problems: 
(a) the route of administration, although feasible, might not be appreciated by the patients 
which could result in lower adherence to treatment; (b) the compounds discussed are used as 
primary treatment for other pathologies and could therefore affect patients with side effects of 
their own; (c) polypharmacy, the concurrent use of multiple medications by a patient, is a less 
desirable option. 
Otolaryngologists can play a crucial role in developing preventive and therapeutic 
modalities to preclude AG-mediated ototoxicity in CF patients, which is still an unmet 
medical need. The detection of HL in the initial stages will lead to early intervention and 
hence better clinical outcomes. Thus, there is a need to implement routine audiological 
monitoring for cochleotoxicity in CF centers worldwide. Genetic testing to detect the 
m.1555A>G mutation in the CF patients will help in predicting their sensitivity to AG-

Rahul Mittal, Luca H. Debs and Kalai Mathee 
 
274
mediated ototoxicity. Besides, there is a need to develop a consensus for identifying HL in CF 
patients. Active collaboration between pulmonologists and otolaryngologists holds a great 
potential to prevent AG-mediated HL in pursuit of improving the quality of life of CF patients 
and their families. 
 
 
ACKNOWLEDGMENTS 
 
We are thankful to Dr. Valerie Gramling for critical reading of the manuscript. 
 
 
REFERENCES 
 
[1] 
Handelsman, JA; Nasr, SZ; Pitts, C; King, WM. Prevalence of hearing and vestibular 
loss in cystic fibrosis patients exposed to aminoglycosides. Pediatr Pulmonol., 2017, 
52(9), 1157-1162. doi: 10.1002/ppul.23763. Epub 2017 Jul 24. 
[2] 
O’Sullivan, ME; Perez, A; Lin, R; Sajjadi, A; Ricci, AJ; Cheng, AG. Towards the 
prevention of aminoglycoside-related hearing loss. Front Cell Neurosci., 2017, 18, 11, 
325. doi: 10.3389/fncel.2017. 00325. 
[3] 
Park, C; Ji, HM; Kim, SJ; et al. Fenofibrate exerts protective effects against 
gentamicin-induced toxicity in cochlear hair cells by activating antioxidant enzymes. 
Int J Mol Med., 2017, 39(4), 960-968. doi: 10.3892/ijmm.2017.2916.  
[4] 
Abusamra, R; McShane, D. Is deafness mutation screening required in cystic fibrosis 
patients? Paediatr Respir Rev., 2016, Suppl, 24-26. doi: 10.1016/j.prrv.2016.06.010. 
[5] 
Wood, JW; Bas, E; Gupta, C; Selman, Y; Eshraghi, A; Telischi, FF; Van De Water, 
TR. Otoprotective properties of mannitol against gentamicin induced hair cell loss. 
Otol Neurotol., 2014, 35(5), e187-94. doi: 10.1097/MAO.0000000000000342. 
[6] 
Majumder, P; Moore, PA; Richardson, GP; Gale, JE. Protecting mammalian hair cells 
from aminoglycoside-toxicity: Assessing Phenoxybenzamine’s potential. Front Cell 
Neurosci., 2017, 11, 94. doi: 10.3389/fncel.2017.00094.  
[7] 
Huth, ME; Han, KH; Sotoudeh, K; et al. Designer aminoglycosides prevent cochlear 
hair cell loss and hearing loss. J Clin Invest., 2015, 125(2), 583-592. doi: 
10.1172/JCI77424. 
 
 

In: Encyclopedia of Audiology and Hearing Research 
ISBN: 978-1-53617-702-2 
Editors: Erno Larivaara and Senja Korhola 
© 2020 Nova Science Publishers, Inc. 
 
 
 
 
 
 
 
Chapter 22 
 
 
 
LOW-LEVEL LASER THERAPY: PROGRESS AND 
FUTURE TRENDS IN HEARING LOSS AND 
VESTIBULAR DYSFUNCTION 
 
 
Vikrant Rai 
Department of Biomedical Sciences,  
Creighton University School of Medicine, Omaha, NE, US 
 
 
ABSTRACT 
 
Noise, drug, or age-related disabling hearing loss is a major public health problem 
affecting nearly 48 million American, 466 million people worldwide, 34 million of whom 
are children. It poses an annual global cost of US$750 billion. The main cause of hearing 
loss is damage to the hearing cells (HC) and recent research is focused on the 
regeneration of HC by various strategies. Low-level laser therapy (LLLT) has been used 
to promote healing in damaged cells and as a treatment strategy for damaged nervous 
systems. Thus, LLLT may be used in the treatment of hearing loss and has been used in 
the treatment of hearing loss, tinnitus, and hyperacusis. However, the results are 
equivocal. Some studies in the animal model reported a significant increase in the number 
and recovery of hair cells and improved hearing with LLLT suggesting its cytoprotective 
effect while others reported no significant improvement with LLLT. Similarly, the 
studies in clinical settings have reported improvement in patients with tinnitus and 
hyperacusis. The results showed that LLLT is effective short-term treatment in alleviating 
tinnitus in patients with noise-induced hearing loss but for a short period of time and its 
impact may be fade over time. Patients with hyperacusis have also reported better 
tolerability of general noise with LLLT but were associated with reactive tinnitus and/or 
pain. However, no clinically statistically significant differences with LLLT in patients 
with hearing loss has also been reported. Thus, the role of LLLT in the treatment of 
hearing loss warrants further research. This chapter is focused on discussing the role of 
LLLT in the treatment of hearing the loss in animal models as well as in clinics. 
 
 
 
 

Vikrant Rai 
 
276
INTRODUCTION 
 
Noise, drug, or age-related disabling hearing loss is a major public health problem 
affecting nearly 48 million Americans, 466 million people worldwide, 34 million of whom 
are children. It poses an annual global cost of US$750 billion. Death of the auditory hair cells 
(HCs) induces the trans-differentiation of adjacent supporting cells (SCs) into new HCs in 
non-mammalian vertebrates, however, this capacity is absent in juvenile and adult mammals 
and lead to a permanent hearing loss [1-3]. Thus, it is important to protect the cochlear 
structure from ongoing degeneration to prevent further hearing loss. A cochlear implant is the 
only effective treatment available for hearing loss at present [4]. Regeneration of the drug- or 
noise-induced damaged hair cells and the gene therapy are the current area of research, 
however, no definitive strategies have been investigated till date [5-8]. Thus, investigation of 
a definitive treatment warrants further research. Since low-level laser therapy (LLLT) is 
useful in the treatment of inflammation, swelling, regeneration, and wound healing, the 
combinational therapies of hearing cell regeneration with LLLT may be a potential 
therapeutic strategy [9-11]. LLLT (laser energy in the red and near-infrared light spectrum) 
has been used for the treatment of pain, swelling, and postsurgical tissue repair for years. The 
therapeutic effect of LLLT is due to stimulation of mitochondria in the cells to produce more 
energy through the production of adenosine triphosphate [9]. The advantage of LLLT in the 
regeneration of the hair cells may also be due to the notion that both cochlear hair cells and 
neural cells are from the same developmental origin. LLLT may have a beneficial effect in 
the treatment of hearing loss as it has become a popular strategy for the treatment of injuries 
and/or pathologies to the nervous system. Laser therapy is effective in wound healing, 
inflammation reduction, and nerve regeneration. The effectiveness and popularity of LLLT 
are due to its capability to penetrate soft tissue and the deepest part of the body without 
damaging non-target soft tissues depending on the wavelength [12]. The effects of LLLT on 
hearing loss and tinnitus have been studies by various researchers, however, the results have 
been equivocal. This chapter focuses on the use of LLLT to treat impaired hearing and 
vestibular dysfunction. 
 
 
ROLE OF LLLT IN HEARING LOSS (ANIMAL MODELS) 
 
The hypothesis that LLLT may be useful in repairing the damaged hair cells and 
improving cochlear function have been studied by various researchers and it was found that 
anatomic and physiologic changes in the cochlea can be induced by laser stimulation. Rhee et 
al. [13] studied the effects of LLLT on hair cell survival following gentamicin exposure using 
organotypic cultures of the cochlea of rats and reported that LLLT promotes hair cell survival 
after gentamicin damage. The organotypic cultures of rat cochlea were irradiated with a laser 
(wavelength of 810 nm at 8 mW/cm2 for 60 min per day with 0.48 J/cm2) for 6 days. After 
laser irradiation to the gentamicin-treated group, a significant increase in the number of hair 
cells suggested the beneficial effect of LLLT on the recovery of cochlear hair cells. Further, 
the same group using the rat model of noise-induced hearing loss irradiated with 830-nm 
diode laser once a day for 10 days with a power density of 900 mW/cm2 and a fluence of 162 
to 194 J reported significantly increased number of hair cells in middle and basal turns and 

Low-Level Laser Therapy 
 
277
significantly improved hearing. A significant improvement in hearing thresholds of the 
auditory brainstem responses (ABR) which were measured before treatment, after gentamicin, 
and after 10 days of LLLT and an increase in the hair-cell count was noticed. No adverse 
tissue reaction on the intact tympanic membrane was found at the end of the experiment [14, 
15]. These results suggest that rat hair cells were repaired with LLLT following noise 
exposure without any adverse reaction. In another study, Tamura et al. [16] studied the 
therapeutic effect of LLLT on noise-induced hearing loss (NIHL) using an NIHL model of 
Sprague–Dawley rats. After intense noise trauma, the right ear of the rats was irradiated with 
808 nm diode laser at an output power density of 110 or 165 mW/cm2 for 5 consecutive days 
for a 30 min period. LLLT irradiation resulted in accelerated recovery of auditory function 
(ABR) and significantly higher OHC survival rate (as indicated by the morphological studies) 
in LLLT treated group compared to the control group at 2, 4, 7 and 14 days after noise 
exposure. A significant reduction in the inducible nitric oxide synthase (iNOS) and cleaved 
caspase-3 was observed 165 mW/cm2 power density. These results suggested the 
cytoprotective effects of LLLT against NIHL via the inhibition of iNOS expression and 
apoptosis. 
The basilar membrane, which is tonotopically tuned based on the spatial variation of its 
mass, stiffness and damping, consist of collagen fibers and these fibers define its biophysical 
properties. Hence, alteration in collagen fibers density and organization may affect cochlear 
tuning. Wenzel et al. [17] using guinea pig studied the effect of LLLT on collagen within the 
basilar membrane using histological analysis. Excised guinea pig cochleae stained with trypan 
blue were irradiated with a 600 nm and 5 J/cm2 pulsed dye laser and collagen organization 
was analyzed using polarization microscopy. A reduction in birefringence within the basilar 
membrane and other stained collagen-containing structures directly proportional to the laser 
pulse was found with laser irradiation. The study reported immediate alterations in collagen 
organization within the cochlea after laser irradiation and these alterations may affect 
cochlear tuning. Lee et al. [12] studied the effectiveness of simultaneous bilateral laser 
therapy compared with unilateral laser therapy on NIHL in a NIHL Sprague-Dawley rat 
model by exposing them to narrow-band noise at 115 dB SPL for 6 h and then laser 
irradiation (diode laser with 808 nm wavelength, 165 mW/cm2, 594 J) for 60 mins for 15 days 
in both ears. ABR (4, 8, 12, 16, and 32 kHz) was measured after each irradiation and cochlear 
hair cells were counted after the 15th such irradiation. The study found that 5% of the laser 
energy from one ear reached the contralateral cochlea. Both unilateral and bilateral laser 
therapy decreased the hearing threshold after noise overstimulation, but bilateral laser therapy 
showed faster functional recovery, however, no difference was found in the final hair cell 
survival and the endpoint ABR results. 
Ouabain is a cardiac glycoside and causes auditory neuropathy by impaired auditory 
nerve function. Lee et al. [18] induced the auditory neural degeneration sparing the sensory 
epithelium with local ouabain application in gerbils and investigated the therapeutic effect of 
photobiomodulation (PBM) after seven days of laser irradiation based on the notion that laser 
therapy enhances nerve growth or induce axonal regeneration. Histological analysis of 
cochlea mid-modiolar sections after treatment showed damaged spiral ganglion cells, 
neurofilaments, and postsynaptic puncta. The authors did not observe any change in distortion 
product otoacoustic emission (DPOAE) suggesting no change in outer hair cell function, 
however, ABR thresholds were increased after ouabain application. Laser irradiation after 
ouabain treatment lowered the ABR thresholds compared to only ouabain treated group. 

Vikrant Rai 
 
278
Laser treatment also showed a higher number of spiral ganglion cells, a higher density of 
neurofilaments, and higher number postsynaptic puncta counts in the laser treated group 
compared with ouabain application group. Alleviation of the hearing loss with recovered 
auditory function and improved histologic outcome suggests the rescue effect of PBM and its 
potential for inner ear diseases accompanied by spiral ganglion degeneration. These results 
suggests the potential of LLLT in restoring the hearing loss by increases HC regeneration and 
the possibility of LLLT as a therapeutic promising option in hearing field. 
 
 
ROLE OF LLLT IN HEARING LOSS IN HUMAN 
 
The effects of LLLT on hearing loss and tinnitus have been investigated in humans. The 
reported studies in the literature showed equivocal results; some studies showed that LLLT 
improved the hearing thresholds and tinnitus symptoms [19-23], while others found no 
significant effect of LLLT [24-28]. The discrepancy in results might be due to study design, 
subject characteristics, LLLT methodology, and outcome measures used to assess the effects 
of LLLT. Goodman et al. [29] using a randomized, double-blind, placebo-controlled design 
studied the effect of LLLT on hearing loss, speech understanding, and/or cochlear function in 
adults. LLLT was applied three times in a week by shining low-level lasers for five minutes 
onto the outer ear, head, and neck. LLLT was applied using an Erchonia EHL laser with a 
hand-held probe with two laser diodes and a main body, one producing light of 532 nm 
wavelength (green; constant) and the other diode producing light of 635 nm wavelength (red; 
pulsed with frequencies of 15 and 33 Hz alternating every 30s) with both diodes producing 
energy levels of 7.5 mW (class IIIb). Pure-tone audiometry, the Connected Speech Test, and 
transient-evoked otoacoustic emissions were carried out immediately before the first 
treatment and immediately after the third treatment. No clinically and statistically significant 
differences on auditory functions were found between treatment and control group. These 
results suggest that LLLT is not effective in restoring hearing loss. In another study, Zhou GY 
[30] investigated the therapeutic effect of LLLT on acupoint and external auditory canal 
combined with auricular point sticking (APS) on moderate and severe sudden deafness. After 
one and two sessions of LLLT, fifteen days each, the therapeutic effect was better after the 
second session compared to one session only. Decreased frequency audiometry and improved 
auditory function were found after LLLT on acupoint and external auditory canal combined 
with APS and electroacupuncture and the therapeutic effects was better with prolongation of 
treatment time. Further, Lapchenko et al. [31] evaluated the efficacy of supravascular laser 
irradiation of blood for the treatment of cochleovestibular disorders and to confirm the 
beneficial effect of LLLT in patients with acute hearing disorders. 165 patients with 
neurosensory impairment of hearing and Meniere’s disease were irradiated with supravascular 
(extracorporeal) laser. The study finds the effectiveness of LLLT in alleviating the 
labyrinthine hydropsis in patients with Meniere’s disease, however, it was less efficacious for 
the management of long-standing hearing impairment and chronic hearing loss. The authors 
conclude that LLLT may be effective in preventing the development of these conditions. The 
potential role of laser therapy in improving auditory function and other diseases of the ear in 
human subjects indicates the potential therapeutic role of LLLT in hearing restoration. 
However, discrepancies in results warrant further research. 

Low-Level Laser Therapy 
 
279
TREATMENT OF TINNITUS 
 
Tinnitus is listening to the sound without any external auditory stimulus. At least one 
episode of tinnitus is experienced by about 15% of the general population. The prevalence of 
tinnitus increases by age and reaches 85% in individuals older than 60 years and is more 
prevalent among individuals with hearing disorders. Tinnitus may lead to such complications 
as depression, irritability, sleep disorders, and loss of concentration. Thus, treatment of 
tinnitus is a must to get rid of unwanted hearing and associated complications. Several 
modalities for the treatment of tinnitus have been proposed, however, an effective standard 
treatment is still to be confirmed [32]. In this regards, as there is lack of a definitive therapy, 
LLLT might be a potential therapeutic option. Mollasadeghi et al. [32] evaluated the effect of 
LLLT on tinnitus accompanied by NIHL (noise-induced hearing loss) using a double-blind 
randomized clinical trial and found that LLLT is effective in alleviating tinnitus in patients 
with NIHL, however, the effect fade after 3 months. LLLT with wavelength of 650 nm and 
intensity of 5 mW was irradiated to the ear via mastoid bone for 20 sessions every other day 
with each session of 20 minutes. Pure-tone audiometry at 250, 500, 1000, 2000, 3000, 4000, 
6000, and 8000 Hz frequencies and tympanometry were performed after LLLT. Tinnitus was 
assessed by visual analog scale, tinnitus handicap inventory, and tinnitus loudness at baseline, 
immediately and 3 months after the intervention. Similarly, Drvis et al. [33] studied the effect 
of LLLT in treating chronic subjective tinnitus. 42 patients with unilateral or bilateral tinnitus 
for more than 3 months were treated with LLLT (wavelength 650 nm, output 50 mW) for 
twenty minutes per session, 10 sessions, 2-3 sessions per week. Pre and post-LLLT tinnitus 
was measured with the Tinnitus Handicap Inventory (THI) and Visual Analog Scale (VAS). 
No statistically significant difference in pre and post LLLT in THI in this study suggest that 
LLLT is not an effective modality for the treatment of tinnitus. In another study, Mirvakili et 
al. [34] in a cross-sectional study on 120 patients with tinnitus and sensorineural hearing loss 
(SNHL) studied the therapeutic effect of LLLT on intractable tinnitus. The experimental 
group received LLLT with a low-level laser device (TINNImed, made in Switzerland) with an 
intensity of 5mW and wavelength of 650 nm for 20 sessions of 20 minutes. THI and VAS 
were used to evaluate the severity of patients’ symptoms and Audiometric tests for severity 
and frequency of tinnitus. The study found a statistically significant mean difference of 
severity of tinnitus between the experimental and control group at the end of the study and 3 
months after completion of treatment. The VAS and THI mean differences were statistically 
significant between the experimental and control group, however, were not statistically 
significant after 3 months after completing the study. These results suggest the effectiveness 
of LLLT for short-term treatment of tinnitus caused by SNHL. 
To assess the effect of LLLT on chronic cochlear tinnitus, Dehkordi et al. [35] conducted 
a prospective, double-blind, placebo-controlled study with 66 patients equally divided in two 
groups; one receiving active LLLT and other inactive dummy treatment. LLLT (5 mV with a 
wavelength of 650 nm) was irradiated for 20 minutes a day, 5 days a week, for 4 weeks. 
Tinnitus Severity Index (TSI), a subjective 10-point self-assessment scale for tinnitus 
loudness, and Tinnitus Evaluation Test (TET) was used to evaluate the degree of tinnitus 
before and after the treatment. Authors did not find any statistically significant difference in 
the number of patients experiencing a reduction in TSI values, a reduction in subjective self-
assessment scores, and a reduction in the loudness and frequency of tinnitus. The study 

Vikrant Rai 
 
280
concluded that 5-mV LLLT does not have any therapeutic effect in improving hearing 
thresholds or for treating tinnitus regarding age, sex, environmental noise level, and the 
duration of tinnitus. Further, Salahaldin et al. [23] in a prospective clinical study investigated 
the therapeutic effectiveness of LLLT in 65 patients aged 15–76 years with chronic unilateral 
or bilateral tinnitus and not responding to conventional therapy. Transmeatally laser 
irradiation with 5mW laser with a wavelength of 650 nm applied for 20 minutes once daily 
for 3 months showed significant improvement in tinnitus symptoms in 56.9% patients. Out of 
this 6.15 % of patients reported full improvement, 16.9% of patients reported moderate 
improvement, and 33.8% of patients reported mild improvement. Improvement in dizzy spells 
was also reported in 27.7% (mild improvement) and 16.9% (full improvement) patients. 20% 
of the patients reported the mild side effects of LLLT which disappeared within a few days. 
These results are suggestive of the effectiveness of LLLT in the treatment of chronic tinnitus. 
 
 
ROLE OF LLLT IN GENE THERAPY FOR HEARING LOSS 
 
Hearing loss affects millions of people and genetic mutations play a direct role in both 
congenital and late-onset cases of SNHL. At present, the cochlear implant is the only 
available effective treatment for moderate to severe hearing loss. Since mutation plays a 
direct role in SNHL, manipulating the causal gene by gene- and cell-based therapies are the 
current areas of research to develop a therapy which potentially may preserve or restore 
hearing with more natural sound perception. Preclinical studies of cochlear gene therapy have 
made major progress, however, there are hurdles (such as the delivery of the gene to the inner 
ear) and the outcome is not effective, and efficacy of therapy is low. Thus, there is a need for 
better strategies for gene therapy to be more effective [4]. Chang et al. [36] using the HEI-
OC1 cells investigated the effect of PBM on gene therapy to see whether LLLT improves the 
rate of adenovirus (Ad)-mediated viral delivery. HEI-OC1 cells treated with Ad viral vector 
carrying green fluorescent protein (GFP) were irradiated with 808 nm at 15mW for 15 min 
LLLT at 2 h and again at 24 h. The study results showed increased epifluorescence of GFP 
expression/cell in 1μL Ad-GFP + LLLT, and 3μL Ad-GFP + LLLT groups compared to 1μL 
and 3μL Ad-GFP cells. These results are suggestive of the notion that LLLT enhanced the 
gene delivery of Ad-mediated viral transduction and combination of Ad-mediated viral 
transduction with LLLT may be a promising tool for gene delivery. 
 
 
ROLE OF LLLT IN VESTIBULAR DYSFUNCTION 
 
Gentamicin used as an antibiotic to treat infections is a known vestibular toxic agent and 
cause varying degrees of balance problems. Because PBM has the ability to reach deep inner 
ear organs, Lee et al. [37] using a rat model investigated the effect of PBM on vestibular 
toxicity and balance dysfunction caused by gentamicin. The study reported minimized 
damage from gentamicin treatment evidenced by slow harmonic acceleration (SHA) 
asymmetry and recovered gain in the laser treated ear compared to untreated ear. Further, 
increased hair cell density and epifluorescence intensity in laser-treated cupulae on 
histopathology suggested the beneficial therapeutic effect of laser therapy. Similarly, the 

Low-Level Laser Therapy 
 
281
beneficial effect of LLLT on vestibular dysfunction was reported by Rhee et al. [38] who 
evaluated the adverse effects of transmeatal LLLT on OHC and IHC structures and its effect 
on gentamicin-induced unilateral vestibulopathy in guinea pigs. The group also measured the 
penetration rate of transmeatal LLLT into the perilymphatic space of cochlea through a 
tympanic membrane and did the histopathologic analysis of ear canal skin and eardrum to 
assess the damage by LLLT. Laser of 830 nm wavelength with an output power of 80 mW for 
30 min (144 J/cm2) irradiated into the left ear through the external ear canal for 5 days and 
daily for 2 weeks. The animals received the sinusoidal oscillation about a vertical and off 
vertical axis for 5 days after injection. Post-LLLT, no hearing loss and no damage to ear canal 
skin and eardrum suggested the restoring capacity of LLLT function on dysfunction in guinea 
pigs. The study found 8% penetration rate of LLL through the drum and of this 5% was 
penetrated the perilymphatic space. Further, it was found that the left side gains of the LLLT 
treated group was significantly higher than the control group, however, the gains of the right 
ear in both groups were not significantly different. 
 
 
CONCLUSION 
 
LLLT has been found beneficial in the treatment of inflammation, decreasing swelling, 
wound healing, hair transplant, and alleviating side effects of chemotherapy. Based on the 
capacity of LLLT to penetrate the deep tissue without any side effects, LLLT may be 
beneficial in restoring hearing loss. Based on the results of above discussed studies it is 
conceivable that laser irradiation may have therapeutic benefits for patients with hearing loss, 
tinnitus, Meniere’s disease, and vestibular dysfunction. However, discrepancies in results of 
various studies and equivocal results in others warrant further research.  
 
 
REFERENCES 
 
[1] 
Groves AK (2010) The challenge of hair cell regeneration. Experimental Biology and 
Medicine 235: 434-446. 
[2] 
Rai V, Abdo J, Agrawal S, Agrawal DK (2017) Vitamin D Receptor Polymorphism and 
Cancer: An Update. Anticancer Res 37: 3991-4003. 
[3] 
Rai V, Abdo J, Alsuwaidan AN, Agrawal S, Sharma P, et al. (2018) Cellular and 
molecular targets for the immunotherapy of hepatocellular carcinoma. Mol Cell 
Biochem 437: 13-36. 
[4] 
Zhang W, Kim SM, Wang W, Cai C, Feng Y, et al. (2018) Cochlear Gene Therapy for 
Sensorineural Hearing Loss: Current Status and Major Remaining Hurdles for 
Translational Success. Front Mol Neurosci 11: 221. 
[5] 
Yamashita T, Zheng F, Finkelstein D, Kellard Z, Carter R, et al. (2018) High-resolution 
transcriptional dissection of in vivo Atoh1-mediated hair cell conversion in mature 
cochleae identifies Isl1 as a co-reprogramming factor. PLoS Genet 14: e1007552. 

Vikrant Rai 
 
282
[6] 
Hazlitt RA, Teitz T, Bonga JD, Fang J, Diao S, et al. (2018) Development of Second-
Generation CDK2 Inhibitors for the Prevention of Cisplatin-Induced Hearing Loss. J 
Med Chem 61: 7700-7709. 
[7] 
Ma Y, Wise AK, Shepherd RK, Richardson RT (2019) New molecular therapies for the 
treatment of hearing loss. Pharmacol Ther. 
[8] 
Chien WW, Monzack EL, McDougald DS, Cunningham LL (2015) Gene therapy for 
sensorineural hearing loss. Ear Hear 36: 1-7. 
[9] 
Rai V (2016) Role of Reactive Oxygen Species in Low-Level Laser Therapy. 
Handbook of Low-Level Laser Therapy: Pan Stanford. pp. 177-200. 
[10] Yin R, Agrawal T, Khan U, Gupta GK, Rai V, et al. (2015) Antimicrobial 
photodynamic inactivation in nanomedicine: small light strides against bad bugs. 
Nanomedicine 10: 2379-2404. 
[11] Agrawal T, Gupta GK, Rai V, Carroll JD, Hamblin MR (2014) Pre-conditioning with 
low-level laser (light) therapy: light before the storm. Dose-Response 12: dose-
response. 14-032. Agrawal. 
[12] Lee JH, Chang SY, Moy WJ, Oh C, Kim SH, et al. (2016) Simultaneous bilateral laser 
therapy accelerates recovery after noise-induced hearing loss in a rat model. Peer J 4: 
e2252. 
[13] Rhee CK, He P, Jung JY, Ahn JC, Chung PS, et al. (2012) Effect of low-level laser 
therapy on cochlear hair cell recovery after gentamicin-induced ototoxicity. Lasers Med 
Sci 27: 987-992. 
[14] Rhee CK, He P, Jung JY, Ahn JC, Chung PS, et al. (2013) Effect of low-level laser 
treatment on cochlea hair-cell recovery after ototoxic hearing loss. J Biomed Opt 18: 
128003. 
[15] Rhee CK, Bahk CW, Kim SH, Ahn JC, Jung JY, et al. (2012) Effect of low-level laser 
treatment on cochlea hair-cell recovery after acute acoustic trauma. J Biomed Opt 17: 
068002. 
[16] Tamura A, Matsunobu T, Mizutari K, Niwa K, Kurioka T, et al. (2015) Low-level laser 
therapy for prevention of noise-induced hearing loss in rats. Neurosci Lett 595: 81-86. 
[17] Wenzel GI, Pikkula B, Choi CH, Anvari B, Oghalai JS (2004) Laser irradiation of the 
guinea pig basilar membrane. Lasers Surg Med 35: 174-180. 
[18] Lee MY, Bae SH, Chang SY, Lee JH, Kim SH, et al. (2016) Photobiomodulation by 
laser therapy rescued auditory neuropathy induced by ouabain. Neurosci Lett 633: 165-
173. 
[19] Plath P, Olivier J (1995) Results of combined low-power laser therapy and extracts of 
Ginkgo biloba in cases of sensorineural hearing loss and tinnitus. Lasers in 
Otorhinolaryngology, and in Head and Neck Surgery: Karger Publishers. pp. 101-104. 
[20] Tauber S, Schorn K, Beyer W, Baumgartner R (2003) Transmeatal cochlear laser 
(TCL) treatment of cochlear dysfunction: a feasibility study for chronic tinnitus. Lasers 
in medical science 18: 154-161. 

Low-Level Laser Therapy 
 
283
[21] Gungor A, Dogru S, Cincik H, Erkul E, Poyrazoglu E (2008) Effectiveness of 
transmeatal low power laser irradiation for chronic tinnitus. The Journal of 
Laryngology & Otology 122: 447-451. 
[22] Cuda D, De Caria A (2008) Effectiveness of combined counseling and low-level laser 
stimulation in the treatment of disturbing chronic tinnitus. International Tinnitus 
Journal 14: 175-180. 
[23] Salahaldin AH, Abdulhadi K, Najjar N, Bener A (2012) Low-level laser therapy in 
patients with complaints of tinnitus: a clinical study. ISRN otolaryngology 2012. 
[24] Rogowski M, Mnich S, Gindzieńska E, Lazarczyk B (1999) Low-power laser in the 
treatment of tinnitus--a placebo-controlled study. Otolaryngologia polska = The Polish 
otolaryngology 53: 315-320. 
[25] Mirz F, Zachariae R, Andersen SE, Nielsen AG, Johansen LV, et al. (1999) The low-
power laser in the treatment of tinnitus. Clin Otolaryngol Allied Sci 24: 346-354. 
[26] Nakashima T, Ueda H, Misawa H, Suzuki T, Tominaga M, et al. (2002) Transmeatal 
low-power laser irradiation for tinnitus. Otol Neurotol 23: 296-300. 
[27] Teggi R, Bellini C, Fabiano B, Bussi M (2008) Efficacy of low-level laser therapy in 
Meniere’s disease: a pilot study of 10 patients. Photomed Laser Surg 26: 349-353. 
[28] Teggi R, Bellini C, Piccioni LO, Palonta F, Bussi M (2009) Transmeatal low-level laser 
therapy for chronic tinnitus with cochlear dysfunction. Audiol Neurootol 14: 115-120. 
[29] Goodman SS, Bentler RA, Dittberner A, Mertes IB (2013) The effect of low-level laser 
therapy on hearing. ISRN Otolaryngol 2013: 916370. 
[30] Zhou GY (2012) [Moderate and severe sudden deafness treated with low-energy laser 
irradiation combined with auricular acupoint sticking]. Zhongguo Zhen Jiu 32: 413-416. 
[31] Lapchenko AS, Kucherov AG, Levina Iu V, Ivanets IV, Krasiuk AA, et al. (2011) [The 
application of supravascular laser irradiation of blood for the treatment of 
cochleovestibular disorders]. Vestn Otorinolaringol: 39-40. 
[32] Mollasadeghi A, Mirmohammadi SJ, Mehrparvar AH, Davari MH, Shokouh P, et al. 
(2013) Efficacy of low-level laser therapy in the management of tinnitus due to noise-
induced hearing loss: a double-blind randomized clinical trial. Scientific World Journal 
2013: 596076. 
[33] Drviš P, Trotić R, Ries M, Ajduk J, Muslim A, et al. (2013) Low level laser therapy 
(LLT) for chronic tinnitus. Laser in medicine 1. 
[34] Mirvakili A, Mehrparvar A, Mostaghaci M, Mollasadeghi A, Mirvakili M, et al. (2014) 
Low level laser effect in treatment of patients with intractable tinnitus due to 
sensorineural hearing loss. J Lasers Med Sci 5: 71-74. 
[35] Dehkordi MA, Einolghozati S, Ghasemi SM, Abolbashari S, Meshkat M, et al. (2015) 
Effect of low-level laser therapy in the treatment of cochlear tinnitus: a double-blind, 
placebo-controlled study. Ear Nose Throat J 94: 32-36. 
[36] Chang SY, Park YH, Carpena NT, Pham TT, Chung PS, et al. (2019) 
Photobiomodulation promotes adenoviral gene transduction in auditory cells. Lasers 
Med Sci 34: 367-375. 

Vikrant Rai 
 
284
[37] Lee MY, Hyun JH, Suh MW, Ahn JC, Chung PS, et al. (2017) Treatment of peripheral 
vestibular dysfunction using photobiomodulation. J Biomed Opt 22: 1-7. 
[38] Rhee C, Chang SY, Chung PS, Ahn JC, Jung JY (2014) Transmeatal Low Level Laser 
Therapy (LLLT) on Vestibular Inner Ear after Topical Gentamicin Ototoxicity. Medical 
Lasers; Engineering, Basic Research, and Clinical Application 3: 65-70. 
 

 
 
 
 
 
 
 
 
 
 
 
 
VOLUME 2 
 


In: Encyclopedia of Audiology and Hearing Research 
ISBN: 978-1-53617-702-2 
Editors: Erno Larivaara and Senja Korhola 
© 2020 Nova Science Publishers, Inc. 
 
 
 
 
 
 
 
Chapter 23 
 
 
 
NOVEL DEAFNESS GENES AND MUTATIONS 
IDENTIFIED BY NEXT GENERATION SEQUENCING 
 
 
Xue Gao1,2, 
1Department of Otorhinolaryngology, Head and Neck 
Surgery, PLA General Hospital, Beijing, Haidian, China 
2Department of Otolaryngology, the Second Artillery 
General Hospital, Beiging, China 
 
 
ABSTRACT 
 
Identifying the genetic basis of deafness provides crucial information for diagnosis, 
intervention and treatment of the disease. Non-syndromic sensorineural hearing loss, 
however, are extremely heterogeneous, with both common and rare forms occurring due 
to mutations over estimated 500 genes. Due to the larger number and presumably low 
mutation frequencies of those genes, it would be highly expensive and time-consuming to 
address this issue by conventioanl gene-by-gene Sanger sequencing. Next generation 
sequencing (NGS) has become a highly efficient strategy for identifying novel causative 
genes and mutations involved in heritable disease. Both simple nonsyndromic and 
complex syndromic forms of hearing loss can be resolved efficiently using NGS, 
especially in small families with distinct and interesting phenotypes that were once too 
small to map. To date, more than a dozen syndromic or nonsyndromic deafness genes 
have been identified using targeted genomic enrichment and NGS. Here, we summarized 
novel deafness genes and mutations identified by NGS methodologies. 
 
 
INTRODUCTION 
 
To date, more than 100 genes and 100 genetic loci have been implicated in NSHL 
(http://hereditaryhearingloss.org/). The marked heterogeneity of genetic hearing loss can be 
explained by the complexity of the auditory system, which requires coordination of multiple 
                                                        
 Corresponding Author’s Email: mixueer0110@126.com. 

Xue Gao 
 
286
processes involving the inner ear and nervous system. A defect in any part of this complex 
chain of events can lead to hearing impairment. For many decades, linkage analysis has been 
the most powerful and widely used strategy to identify the gene defects responsible for 
inherited disorders. However, this approach is time consuming and requires the availability of 
cohorts of homogeneous and informative, possibly large families and a large proportion of 
NSHL remain genetically unexplained. 
These limitations, however, may be overcome by the next-generation sequencing (NGS) 
technologies. 
NGS offers an unprecedented ability to identify rare variants and new causative genes. 
Several next generation sequencing platforms allow for a DNA-to-diagnosis protocol to 
identify the molecular basis of inherited non-syndromic hearing loss, including whole genome 
sequencing (WGS), whole exome sequencing (WES) and targeted deafness gene capture. 
Updated guidelines from the American College of Medical Genetics and Genomics 
(ACMG) recommend that clinicians consider NGS when testing for genetic causes of hearing 
loss [1]. The guideline, which is build on guidelines issued in 2002, include panel tests 
targeted at genes related to hearing loss, whole exome sequencing, and whole genome 
sequencing after negative results are returned on initial single-gene testing indicated by a 
patient’s family medical history and presentation. 
 
 
WHOLE GENOME SEQUENCING 
 
Whole genome sequencing (WGS) by next generation sequencing technologies has the 
potential for simultaneous, comprehensive, differential diagnostic testing of monogenic 
illnesses. 
In 2003, the cost of sequencing a single human genome was estimated to be 2.7 billion 
dollars, that price had dropped to 4,000 dollars by 2012, and it is anticipated that this cost will 
soon be 1,000 dollars. Clinical use of WGS by NGS has taken at least a month. Researchers 
already have been able to help clinicians aid some children born with rare birth defects by 
sequencing and analyzing their whole genomes to diagnose and treat their illness [2]. 
This is only the beginning of the whole genome sequencing era, which has the potential 
to revolutionize medicine. 
However, there is no report about application of whole genome seuqencing on the 
inherited non-syndromic hearing loss. There are major obstacles to the clinical 
implementation of WGS, such as hidden costs, issues surrounding sequencing and analysis, 
quality assurance and standardization protocols, ethical dilemmas, and difficulties with 
interpretation of the results. With the availability of human WGS data from many individuals, 
it’s now clear that two unrelated individuals have at least two million differences in their 
genomic DNA sequences [3]. The full potential of WGS can be realized only when we gain a 
much better understanding of the functions of noncoding regions. WGS should be carefully 
implemented in the clinic to allow the realization of its potential to improve patient health in 
specific indications. 
 
 

Novel Deafness Genes and Mutations… 
 
287
WHOLE EXOME SEQUENCING 
 
Approximately 85% of disease-related mutations in Mendelian disorders have been found 
in the protein-coding region, although this portion constitutes only approximately 1% of the 
human genome [4, 5]. WES has become a highly efficient strategy for identifying novel 
causative genes and mutations involved in heritable disease. 
Over 1,778 publications since 2009 whose abstracts contain the term “whole exome 
sequencing”, confirm the success of exome sequencing as a new and effective technological 
paradigm within human genetics. 
 
Table 1. List of genes and mutations related with non-syndromic hearing loss  
identified by WES 
 
GENE NAME 
Mutation (protein) 
References 
OSBPL2 
p.Gln53Argfs*100 
p.Leu195Met 
[6] 
TBC1D24 
p.Ser178Leu 
[7] 
TNC 
p. Thr 1796Ser 
p.V1773M 
[8] 
ELMOD3 
p.Leu265Ser 
[9] 
KARS 
p.Asp377Asn 
p.Tyr173His 
[10] 
GRXCR2 
c.714dupT 
[11] 
ATP1A2 
p.Val191Met 
[12] 
ADCY1 
p.Arg1038X 
[13] 
BDP1 
p.*2625Gluext*11 
[14] 
EPS8 
p.Gln30* 
[15] 
PNKP 
p.Gly292Arg 
[16] 
PCDH15 
p.Met65Ile 
p.Ser404Arg 
[16] 
CDH23 
p.Pro240Leu 
p.Glu1595Lys 
p.Asn342Ser 
[17] 
POU4F3 
p.Arg326Lys 
[18] 
MYO15A 
p.Ser1481 Pro 
p.Gln1425X 
p.Ala1551Asp 
IVS11 + 1 
p.Arg2146Q 
[19, 20, 21] 
TMC1 
p.Ser530X 
p.Gly197Arg 
p.Gln391X 
[19, 22] 
ACTG1 
p.Met305Thr 
[23] 
LOXHD1 
p. Arg1494X 
p. Glu955X 
[19] 
GIPC3 
p.His170Asn 
[19] 
ILDR1 
p. Gln 274X 
[19] 
MYO7A 
p.Gly2163 Ser 
[19] 
TECTA 
p. Tyr 1737Cys 
[19] 
TMPRSS3 
p.F13Lfs*10 
[19] 
TRIOBP 
p. Arg785 Ser fs*50 
[19] 
 

Xue Gao 
 
288
Whole exome sequencing has proven useful for identifyding the molecular defects 
underlying single gene disorders (Mendelian inheritance), as well as some genetically 
heterogeneous disorders, such as inherited non-syndromic hearing loss. 
Inherited non-syndromic hearing loss can be resolved efficiently using WES, especially 
in small families with distinct and interesting phenotypes that were once too small to map 
using linkage analysis. 
Recently, there have been many successful applications of WES in identifying the 
causative genes and mutations of inherited non-syndromic hearing loss (Table 1). 
To date, 10 non-syndromic deafness genes and more than 30 novel causative mutations 
were identified by WES (Table 1). These studies show that WES, followed by verification 
and functional and immunolabeling examinations, can reveal critical disease-causing genes 
from small pedigrees. 
Even with the rapid maturarion of this field, there are a number of areas that are still 
many work in progress: (1) WES fails to solve a substantial proportion of presumably 
Mendelian phenotypes [24]. (2) There is tremendous interest understanding the contribution 
of rare variation to the genetic basis of common disease. Many such studies have been 
initiated using WES, but are still ongoing as they require other samples to tesifty the results. 
(3) The discrete prioritazation of all protein-altering variation over all other variations has 
clearly proven to be useful, but is undeniably crude. 
 
 
TARGETED DEAFNESS GENE CAPTURE AND NGS 
 
The popular application of targeted gene capture is all of the genes involved in causing 
hearing loss, including all exons, exon/intron boundaries and promoter sequences could be 
fully sequenced on a diagnostic platform to produce a specific genetic test for hearing loss. 
Targeted deafness gene capture combined with NGS is suited to identify the causative 
mutations of non-syndromic hereditary hearing loss owing to the following advantages: 1) 
comprehensive coverage of large numbers of genes and large genes associated with the 
disease; 2) significant cost saving; 3) higher sequencing accuracy because of deeper 
achievable coverage; 4) a significantly shorter turnaround time and 5) more convincing 
dataset by excluding other deafness genes [25]. 
To date, more than 100 human genes implicated in non-syndromic hearing loss are 
confirmed [25]. Approximately 100Gbp of sequencing is needed to obtain NGS results for 
one human genome (~3.2G bp) at about 30× average coverage. Targeted gene enrichment 
typically increases this proportion by at least 1,000 fold [26, 27, 28]. 
Therefore, the same sequencing capacity can theoretically be used to sequence more than 
1,000 samples for a panel of genes associated with deafness. 
The recent studies demonstrated the feasibility of conducting diagnostic tests for all 
deafness-related genes by targeted gene capture and NGS [26, 27]. Its success in research has 
already resulted in its translational uses in clinical care, and many of them are for diagnostic 
mutation detection of focused panels of disease genes. 
OtoSCOPE (Otological Sequence Capture Of Pathogenic Exons) is the first massively 
parallel sequencing platform that utilizes targeted sequence capture and NGS for genetic 
testing of hearing loss [27]. It has been developed by the University of Iowa and is being  

Novel Deafness Genes and Mutations… 
 
289
used in a research setting to fully sequence all exons of 57 deafness genes 
(http://www.healthcare.uiowa.edu/labs/morl/index_CDS.htm). 
At 
this 
stage 
in 
its 
development various methods of targeted sequence capture and NGS are being compared to 
determine which combination has the greatest level of sequence coverage. Otogenetics 
Corporation in the US is currently offering a genetic mutation testing service using targeted 
sequence capture and NGS for the detection of variants in 131 known deafness genes for 
approximately $500 per sample (www.otogenetics. com). 
Richard J.H. Smith, MD, Director of the Molecular Otolaryngology and Renal Research 
Laboratories at the Iowa Institute of Human Genetics at University of Iowa in Iowa City, is a 
proponent of panel testing for hearing loss. His lab offers a test that covers 90 genes known to 
cause hearing loss, which he suggests over any initial single-gene test. Because panel tests 
offer more depth of coverage in genes associated with hearing loss, they are superior to WES 
at some extent, which looks at 20,000 genes and may miss parts of them. 
The drawbacks of panel tests are these tests that use disease-targeted exon capture 
focused on specific genes may only sequence a subset of the genes known to cause hearing 
loss, and there is limited knowledge of which genes are involved in hearing loss. 
 
 
CHALLENGE AND FUTURE 
 
Applications of NGS technologies are now beginning to enter clinical practice. 
Interpreting the data and translating the research results into applications that improve 
healthcare is still challenging. Filtering through the millions of vatiants in an individual’s 
genome for the pathogenic mutation seems to be the most urgent task at hand. Another 
important aspect is the concurrent development of genetic counseling capabilities to interpret 
the large amount of data revealed by NGS for clinical use. In the near future, physicians may 
combine a past medical history and family history with NGS diagnostic data to identity 
disease predisposition vatiants and variants that affect drug metabolism in individuals. 
Althoght NGS-based molecular diagnostic tests are still in their infancy, they have 
demonstrated excellent clinical utility for single-gene disorders. With further developments in 
NGS technologies for data generation and with more effective bioinformatics tools for data 
analysis and clinical extraction, the full potential of WES/WGS that we expect to be revealed 
in the coming years will greatly enrich and empower the practice of genomic medicine 
beyond the rare single-gene disorders. The improvements in patient care demonstrated in 
recent studies justify all effort and cost for moving these new and exciting approaches into 
molecular diagnostics practics. 
In our opinion, WES, WGS, and targeted deafness gene capture should remain as options 
to be considered for inherited non-syndromic hearing loss and be used according to a patient’s 
specific conditions. Alternatively, a combined approach can be used to capture all variety of 
genomic variations. 
 
 
 
 

Xue Gao 
 
290
REFERENCES 
 
[1] 
Levenson, D. (2014) New testing guidelines for hearing loss support next-generation 
sequencing: testing method may help determine genetic causes of hearing loss among 
patients whose phenotypes are not easily distinguished clinically. Am. J. Med. Genet. A 
164: vii-viii. 
[2] 
Saunders, C. J., Miller, N. A., Soden, S. E., Dinwiddie, D. L., Noll, A., et al. (2012) 
Rapid whole-genome sequencing for genetic disease diagnosis in neonatal intensive 
care units. Sci. Transl. Med. 4: 154ra135. 
[3] 
Moore, B., Hu, H., Singleton, M., De La Vega, F. M., Reese, M. G., et al. (2011) 
Global analysis of disease-related DNA sequence variation in 10 healthy individuals: 
implications for whole genome-based clinical diagnostics. Genet. Med. 13: 210-217. 
[4] 
Ng, S. B., Turner, E. H., Robertson, P. D., Flygare, S. D., Bigham, A. W., et al. (2009) 
Targeted capture and massively parallel sequencing of 12 human exomes. Nature 461: 
272-276. 
[5] 
Teer, J. K., Mullikin, J. C. (2010) Exome sequencing: the sweet spot before whole 
genomes. Hum. Mol. Genet. 19: R145-151. 
[6] 
Xing, G., Yao, J., Wu, B., Liu, T., Wei, Q., et al. (2014) Identification of OSBPL2 as a 
novel candidate gene for progressive nonsyndromic hearing loss by whole-exome 
sequencing. Genet. Med. 
[7] 
Azaiez, H., Booth, K. T., Bu, F., Huygen, P., Shibata, S. B., et al. (2014) TBC1D24 
mutation causes autosomal-dominant nonsyndromic hearing loss. Hum. Mutat. 35: 819-
823. 
[8] 
Zhao, Y., Zhao, F., Zong, L., Zhang, P., Guan, L., et al. (2013) Exome sequencing and 
linkage analysis identified tenascin-C (TNC) as a novel causative gene in nonsyndromic 
hearing loss. PLoS One 8: e69549. 
[9] 
Jaworek, T. J., Richard, E. M., Ivanova, A. A., Giese, A. P., Choo, D. I., et al. (2013) 
An alteration in ELMOD3, an Arl2 GTPase-activating protein, is associated with 
hearing impairment in humans. PLoS Genet. 9: e1003774. 
[10] Santos-Cortez, R. L., Lee, K., Azeem, Z., Antonellis, P. J., Pollock, L. M., et al. (2013) 
Mutations in KARS, encoding lysyl-tRNA synthetase, cause autosomal-recessive 
nonsyndromic hearing impairment DFNB89. Am. J. Hum. Genet. 93: 132-140. 
[11] Imtiaz, A., Kohrman, D. C., Naz, S. (2014) A frameshift mutation in GRXCR2 causes 
recessively inherited hearing loss. Hum. Mutat. 35: 618-624. 
[12] Oh, S. K., Baek, J. I., Weigand, K. M., Venselaar, H., Swarts, H. G., et al. (2014) A 
missense variant of the ATP1A2 gene is associated with a novel phenotype of 
progressive sensorineural hearing loss associated with migraine. Eur. J. Hum. Genet. 
[13] Santos-Cortez, R. L., Lee, K., Giese, A. P., Ansar, M., Amin-Ud-Din, M., et al. (2014) 
Adenylate cyclase 1 (ADCY1) mutations cause recessive hearing impairment in 
humans and defects in hair cell function and hearing in zebrafish. Hum. Mol. Genet. 23: 
3289-3298. 
[14] Girotto, G., Abdulhadi, K., Buniello, A., Vozzi, D., Licastro, D., et al. (2013) Linkage 
study and exome sequencing identify a BDP1 mutation associated with hereditary 
hearing loss. PLoS One 8: e80323. 

Novel Deafness Genes and Mutations… 
 
291
[15] Behlouli, A., Bonnet, C., Abdi, S., Bouaita, A., Lelli, A., et al. (2014) EPS8, encoding 
an actin-binding protein of cochlear hair cell stereocilia, is a new causal gene for 
autosomal recessive profound deafness. Orphanet J. Rare Dis. 9: 55. 
[16] Nakashima, M., Takano, K., Osaka, H., Aida, N., Tsurusaki, Y., et al. (2014) Causative 
novel PNKP mutations and concomitant PCDH15 mutations in a patient with 
microcephaly with early-onset seizures and developmental delay syndrome and hearing 
loss. J. Hum. Genet. 59: 471-474. 
[17] Woo, H. M., Park, H. J., Park, M. H., Kim, B. Y., Shin, J. W., et al. (2014) 
Identification of CDH23 mutations in Korean families with hearing loss by whole-
exome sequencing. BMC Med. Genet. 15: 46. 
[18] Kim, H. J., Won, H. H., Park, K. J., Hong, S. H., Ki, C. S., et al. (2013) SNP linkage 
analysis and whole exome sequencing identify a novel POU4F3 mutation in autosomal 
dominant late-onset nonsyndromic hearing loss (DFNA15). PLoS One 8: e79063. 
[19] Diaz-Horta, O., Duman, D., Foster, J., 2nd, Sirmaci, A., Gonzalez, M., et al. (2012) 
Whole-exome sequencing efficiently detects rare mutations in autosomal recessive 
nonsyndromic hearing loss. PLoS One 7: e50628. 
[20] Gao, X., Zhu, Q. Y., Song, Y. S., Wang, G. J., Yuan, Y. Y., et al. (2013) Novel 
compound heterozygous mutations in the MYO15A gene in autosomal recessive 
hearing loss identified by whole-exome sequencing. J. Transl. Med. 11: 284. 
[21] Woo, H. M., Park, H. J., Baek, J. I., Park, M. H., Kim, U. K., et al. (2013) Whole-
exome sequencing identifies MYO15A mutations as a cause of autosomal recessive 
nonsyndromic hearing loss in Korean families. BMC Med. Genet. 14: 72. 
[22] Gao, X., Su, Y., Guan, L. P., Yuan, Y. Y., Huang, S. S., et al. (2013) Novel compound 
heterozygous TMC1 mutations associated with autosomal recessive hearing loss in a 
Chinese family. PLoS One 8: e63026. 
[23] Park, G., Gim, J., Kim, A. R., Han, K. H., Kim, H. S., et al. (2013) Multiphasic analysis 
of whole exome sequencing data identifies a novel mutation of ACTG1 in a 
nonsyndromic hearing loss family. BMC Genomics 14: 191. 
[24] Fairfield, H., Gilbert, G. J., Barter, M., Corrigan, R. R., Curtain, M., et al. (2011) 
Mutation discovery in mice by whole exome sequencing. Genome Biol. 12: R86. 
[25] Lin, X., Tang, W., Ahmad, S., Lu, J., Colby, C. C., et al. (2012) Applications of 
targeted gene capture and next-generation sequencing technologies in studies of human 
deafness and other genetic disabilities. Hear. Res. 288: 67-76. 
[26] Brownstein, Z., Friedman, L. M., Shahin, H., Oron-Karni, V., Kol, N., et al. (2011) 
Targeted genomic capture and massively parallel sequencing to identify genes for 
hereditary hearing loss in Middle Eastern families. Genome Biol. 12: R89. 
[27] Shearer, A. E., DeLuca, A. P., Hildebrand, M. S., Taylor, K. R., Gurrola, J., 2nd, et al. 
(2010) Comprehensive genetic testing for hereditary hearing loss using massively 
parallel sequencing. Proc. Natl. Acad. Sci. US 107: 21104-21109. 
[28] Tang, W., Qian, D., Ahmad, S., Mattox, D., Todd, N. W., et al. (2012) A low-cost exon 
capture method suitable for large-scale screening of genetic deafness by the massively-
parallel sequencing approach. Genet. Test Mol. Biomarkers 16: 536-542. 
 
 


In: Encyclopedia of Audiology and Hearing Research 
ISBN: 978-1-53617-702-2 
Editors: Erno Larivaara and Senja Korhola 
© 2020 Nova Science Publishers, Inc. 
 
 
 
 
 
 
 
Chapter 24  
 
 
 
THE MOLECULAR PATHOGENESIS OF DOMINANT 
DEAFNESS-ONYCHODYSTROPHY (DDOD) 
SYNDROME 
 
 
Yongyi Yuan1,2, Xi Lin2 and Pu Dai1 
1Department of Otolaryngology, Chinese PLA General Hospital,  
Beijing, P.R.C. 
2Department of Otolaryngology, Emory University School of Medicine,  
Atlanta, GA, US 
 
 
ABSTRACT 
 
Dominant deafness-onychodystrophy syndrome (DDOD, MIM 124480) is a type of 
ectodermal dysplasia characterized mainly by congenital deafness, absent nails and/or 
toes with variable presence of brachydactyly, hypoplastic distal phalanges, and bulbous 
distal phalanges. Using the whole-exome sequencing approach, we identified a de novo 
mutation (c.1516 C>T [p.Arg506X]) in ATP6V1B2 as the cause of DDOD syndrome in 
three independently identified individuals. Molecular epidemiology analysis showed that 
the ATP6V1B2 p.Arg506X mutation was not present in 1053 ethnically matched normal 
hearing controls. ATP6V1B2 encodes a component of the vacuolar ATPase (V-ATPase, 
also known as H+-ATPase), a multisubunit enzyme that mediates acidification of 
eukaryotic intracellular organelles. We generated an Atp6v1b2 knockdown mouse model 
and found that Atp6v1b2 deficiency leads to severe sensorineural hearing loss. In vitro 
pathogenic evaluation showed that the ATP6V1B2 p.Arg506X mutation is a dominant 
haplo-insufficient mutation that caused abnormal acidification in the lysosomes. The 
acidification defect in lysosomes may cause decreased activity of acid-dependent 
hydrolases and thus hydrolytic dysfunction of the lysosome affects development of 
multiple systems such as the inner ear, phalanx, and nail in the DDOD syndrome. The 
findings provide the molecular basis for DDOD genetic diagnosis as well as exciting 
developments in future therapeutic interventions. 
 
 
 

Yongyi Yuan, Xi Lin and Pu Dai 
 
294
INTRODUCTION 
 
Dominant deafness-onychodystrophy syndrome (DDOD syndrome, MIM 124480) is 
characterized mainly by congenital sensorineural hearing loss, and accompanied by 
dystrophic or absent nails. In some individuals, conical and hypoplastic teeth may also be 
observed. Prominent differences between DDOD and DOORS syndrome (deafness, 
onychodystrophy, osteodystrophy, intellectual disability and seizures, MIM 220500) are the 
intellectual disability and seizure aspects of DOORS [1]. TBC1D24 mutations were verified 
as a cause of DOORS syndrome recently [2]. The association between deafness and 
onychodystrophy segregating as an autosomal dominant condition was first recognized in 
1962 by Robinson et al. [3], and later was confirmed by Kondoh et al.[4] as well as White and 
Fahey [5]. To date, ten families with DDOD syndrome in various ethnic populations have 
been reported [2-9]. However, the molecular etiology of DDOD remains unknown. In this 
chapter, we report the identification of a common de novo mutation in ATP6V1B2 among 
three independent Chinese families with the DDOD syndrome. We will present evidence 
supporting that ATP6V1B2 is essential for hearing and that the identified mutation causes 
abnormal acidification in the lysosome.  
 
 
Pedigrees and Clinical Evaluations 
 
Three DDOD pedigrees were collected in China during the year 2011~2012. The DDOD 
pedigrees 1 and 3 were ascertained from Shanxi province, and pedigree 2 was from Jilin 
province of mainland China. The probands displayed identical phenotypes including severe 
congenital sensorineural hearing loss, absence of all toe nails, absence of nails on the little 
finger and thumb, phalanx deficiency of the little finger, onychodystrophy-like malacia, and 
pitting of the middle three fingernails (Figure 1). The gross inner ear structure was normal in 
all probands in this study as assessed by magnetic resonance imaging and high-resolution 
temporal bone computed tomography (Figure 1). All three individuals had unilateral cochlea 
implantation at the ages of 2.5, 2, and 18 years, respectively. Cognitive evaluation was 
performed using selected subclasses from a Chinese revised version of Griffiths Mental 
Development Scales (GMDS, 0-8 years of age) prior to cochlea implant operation[10]. The 
normal range of General Quotients of the Griffith test was above 70 in non-syndromic 
Chinese hearing loss individuals, and cases 1 and 2 scored 75 and 77, respectively. After 
cochlea implantation, language rehabilitation in the probands from pedigree 1 and pedigree 2 
showed no distinct difference compared to other nonsyndromic hearing loss individuals. 
Although the proband in pedigree 3 had prelingual hearing loss and had received a cochlea 
implant as an adult, she made significant improvement in speech perception in both listening 
and pronunciation skills due to speech training in a language rehabilitation school from the 
age of 3 years. This successful language rehabilitation in the three DDOD probands further 
confirmed their normal mental development. 
 
 
 

The Molecular Pathogenesis of Dominant… 
 
295
 
(A) Pedigree of three DDOD families and segregation of the c.1516 C>T mutation. The DNA sample of II:3 
is not available in Pedigree 3.  
(B) Audiograms of three probands showing bilateral severe sensorineural hearing loss. The blue curves 
indicate the left ear and red curves indicate the right ear. 
(C) High-resolution radiology results using computed tomography (CT) or magnetic resonance imaging 
(MRI) show normal inner ear development indicated by white arrows. Note: Due to infection of the first 
cochlear implant, the proband of Pedigree 2 received a second cochlear implant operation. The CT 
image shown here was obtained prior to implantation of the second cochlear implant. The implanted 
cochlea is indicated by the blue arrow. 
(D) Pictures of the hands show the absence of the fifth finger and thumb nails indicated by black arrows, 
fifth finger phalanx deficiency indicated by white arrows, as well as onychodystrophy-like malacia and 
pitting of the middle three fingernails.  
(E)  X-ray of the hand shows fifth finger phalanx deficiency indicated by white arrows. 
(F) Pictures of the feet show the absence of all toenails.  
(G) X-ray of the foot shows no abnormalities. 
Figure 1. Phenotype of the three Chinese DDOD (dominant deafness-onychodystrophy) probands. 
 

Yongyi Yuan, Xi Lin and Pu Dai 
 
296
Evidence Support that a De Novo Mutation in ATP6V1B2 Causes the  
DDOD Syndrome 
 
Blood samples (~3-5 ml) were drawn from 6 participants so that genomic DNA could 
be extracted with the Genomic DNA isolation kit (QIAGEN). Paternity was confirmed by 
genotype analysis of 19 informative short tandem repeats (STRs) using GoldeneyeTM 20A 
kit (Peoplespot, Beijing, China) [11], yielding a probability of paternity of 0.999999 
(assuming a prior probability of 0.50). Exome capture was performed in pedigrees 1 and 2, 
including the two probands and their parents, by BGI–Shenzhen using NimbleGen SeqCap 
EZ Human Exome Library v2.0 (Roche NimbleGen, Inc., Madison, WI, USA) according to 
the manufacturer’s protocols, and sequencing was performed using a HiSeq2000 platform 
(Illumina, San Diego, CA, USA). Illumina base calling Software 1.7 was used with default 
parameters to process the raw image files and to sequence the individual products as 90-bp 
paired-end reads. The sequenced reads were aligned to the human genome reference 
(UCSC hg19 version, build37.1) using SOAP aligner/SOAP2 [12]. SNP or indels were 
called using Soapsnp [13] software and bwa [14], respectively. The alignment results were 
identified using GATK [15] to identify the breakpoints.  
 
Table 1. Filtering of SNP variants obtained in whole exome NGS[9] 
 
SNP Filter process 
Individual 1 
Individual 2 
Total 
110722 
117704 
Functional 
14472 
14642 
Filtered_1000Genomes 
2491 
2545 
Filtered_1000Genomes_Hapmap 
2469 
2521 
Filtered_1000Genomes_Hapmap_EVS 
2469 
2521 
Filtered_1000Genomes_Hapmap_EVS_control 
215 
242 
Filtered_1000Genomes_Hapmap_EVS_control_BGI 
83 
96 
Genes shared by individual 1 and individual 2 
6* 
* Details were shown in Table 2. 
 
In each sample, we obtained approximately 5.9–6.9 Gb of data after whole exome 
sequencing. The data mapped to the targeted region have a mean depth of 145.74 folds, and 
99.41% of the targeted bases was covered. For bioinformatic analysis, we focused on variants 
in coding regions. Variants in individuals and their parents were filtered by four databases, 
including the 1000 Genomes Project, HapMap database, the EVS database, and in-house 
database from the BGI, with the Minor Allele Frequency lower than 0.005. Based on 1) the 
dominant inheritance of DDOD, 2) the identical phenotype of the two probands, and 3) the 
pedigree traits (only one individual and neither parent had symptoms) based on the 
assumption that there may be a de novo mutation following the dominant inheritance 
characteristics. Under assumptions of the autosomal-dominant analysis strategy (when 
incomplete penetrance can be excluded), the case must have a heterozygous mutation in a 
certain gene, while the control has no mutation. After completing such a filtering process, we 
identified 6 genes with variants shared by the two individuals (Table 1). Detailed variants in 
the six shared genes can be found in Table 2. Among the six genes, no known hearing-loss-
related gene was identified. The 14 variants in the six shared genes were then tested by 

The Molecular Pathogenesis of Dominant… 
 
297
Sanger sequencing. Considering the sequencing results, the prediction results by SIFT, 
Polyphen, Mutationtaster, the genes’ pathway and their expressions in human fetal cochlear 
ESTs database, ATP6V1B2 was identified as the gene associated with DDOD. An identical 
heterozygous missense mutation (c.1516 C>T [p.Arg506X]) in ATP6V1B2 was verified in 
two probands but not in their parents (Figure 2). The above results were further confirmed by 
Sanger sequencing in another DDOD pedigree (Pedigree 3) we collected in China, in which 
we found that the proband carried the same ATP6V1B2 mutation. The ATP6V1B2 c.1516 C>T 
(p.Arg506X) mutation segregated with the phenotype within the three DDOD families. 
The p.Arg506X in ATP6V1B2 is a nonsense mutation that inserts a premature stop codon, 
which results in a truncated protein that lacks the last five amino acids. Conservation analysis 
of amino acids in nine ATP6V1B2 orthologs indicated that the last five amino acids (residues 
506 to 511) are highly conserved (Figure 2). Three-dimensional protein structure modeling 
suggested that the p.Arg506X altered structure of ATP6V1B2, resulting in a failure of 
hydrogen bond formation between Tyr 504 and Asp 507 (Figure 3). The absence of this 
mutation in the parents of the three individuals indicates its de novo nature. Using a restriction 
enzyme (Taq I) assay to perform a molecular epidemiology analysis of the ATP6V1B2 c.1516 
C>T variation in 1053 ethnically matched normal hearing control subjects, we found that 
none of the normal hearing individuals showed such a mutation (Figure 4). In addition, the 
c.1516C>T variant is not seen in ESP65000 database. 
Immunostaining of mouse cochlea sections and cultured cochlea tissues showed 
Atp6v1b2 expression in the organ of Corti, spiral ganglion neurons, the limbus, and fibrocytes 
close to the stria vascularis (Figure 5). This expression pattern was found in both the early 
postnatal (postnatal day 2, orP2) and the adult (P30) cochleae. 
 
 
A),(B) 
Partial sequences of exon 14 in ATP6V1B2 from normal-hearing parents and affected DDOD 
probands 1 and 2, respectively, showing the c.1516 C>T(p.Arg506X) nonsense mutation. 
(C) Conservation analysis shows that the last six amino acids, p.Arg506, p.Asp507, p.Ser508, 
p.Ala509, p.Lys510 and p.His511 in ATP6V1B2 are conserved across human, pongo, macaca, 
mouse, canis, bos taurus, Xenopus and danio. 
Figure 2. Mutation Analysis of ATP6V1B2. 
 

 
 
Table 2. Variants in the 6 genes shared by 2 DDOD cases[9] 
 
 
Gene Name 
Codons 
Substitution 
Detailed Information for 
cases 
Genotype Quality 
Gene description 
Case 1 
 
CIB1 
- 
- 
W34A4T3,000, 
spliceAcceptorSite+6 
Low_Confidence 
calcium and integrin binding 1 
(calmyrin) 
MUC4 
CAC11271CAG 
H3757Q 
S99G123C9,000,missense 
High_Confidence 
mucin 4, cell surface associated 
MUC4 
CCT4703CGT 
P1568R 
S41G191C7,000,missense 
High_Confidence 
mucin 4, cell surface associated 
OR5H6 
ACT368CTT 
T123L 
Y97C23T9,000,missense 
Low_Confidence 
olfactory receptor, family 5, 
subfamily H, member 6 
PRAMEF1 
ATG122AGG 
M41R 
K20T251G4,000,missense 
High_Confidence 
- 
AMBN 
GGA539GTA 
G180V 
K43G137T9,000,missense 
Low_Confidence 
ameloblastin (enamel matrix 
protein) 
ATP6V1B2 
CGA1516TGA 
R506* 
Y99T56C44,000,nonsense 
High_Confidence 
ATPase, H+ transporting, 
lysosomal 56/58kDa, V1 
subunit B2 
Case 2 
 
CIB1 
- 
- 
W32T5A3,000,spliceAcceptor
Site+6 
Low_Confidence 
calcium and integrin binding 1 
(calmyrin) 
MUC4 
CCT12574TCT 
P4192S 
R39G140A8,000,missense 
High_Confidence 
mucin 4, cell surface associated 
MUC4 
ACC12568GCC 
T4190A 
Y45T119C7,000,missense 
High_Confidence 
mucin 4, cell surface associated 
MUC4 
ATG4604ACG 
M1535T 
R22A54G5,000,missense 
High_Confidence 
mucin 4, cell surface associated 
OR5H6 
GGG239GAG 
G80E 
R27G216A7,000,missense 
High_Confidence 
olfactory receptor, family 5, 
subfamily H, member 6 
PRAMEF1 
ATG82GTG 
M28V 
R35A178G8,000,missense 
High_Confidence 
- 
AMBN 
GGA539GCA 
G180A 
S22G129C6,000,missense 
Low_Confidence 
ameloblastin (enamel matrix 
protein) 
ATP6V1B2 
CGA1516TGA 
R506* 
Y99T61C62,000,nonsense 
High_Confidence 
ATPase, H+ transporting, 
lysosomal 56/58kDa, V1 
subunit B2 

The Molecular Pathogenesis of Dominant… 
 
299
 
Structure analysis of the wild-type ATP6V1B2 and mutant ATP6V1B2 (by Swiss model Workspace: 
http://swissmodel.expasy.org/workspace/). p.Arg506X results in failure of hydrogen bond 
formation between Tyr 504 and Asp in ATP6V1B2. 
Figure 3. Altered protein structure by ATP6V1B2 p.Arg506X. 
 
Example gel showing that three bands, 252bp, 165bp and 87bp, in individual with heterozygous 
ATP6V1B2 c.1516 C>T mutation, and two bands, 165bp and 87bp, in wild-type controls. The pair 
of primers used for restriction enzyme reaction was designed around ATP6V1B2 c.1516 C, which 
can amplify a fragment of 252bp. The restriction enzyme Taq I recognizes the ‘TC’ at c.1515 and 
c.1516. After the Taq I reaction, the 252bp fragment is cut into two fragments of 165 and 87 bp. 
However, the mutation c.1516 C>T deletes the Taq I restriction endonuclease site. Thus, for the 
heterozygous c.1516 C>T mutation, three bands (252, 165 and 87 bp) were detected, while in 
controls lacking the c.1516 C>T mutation, two bands (165 and 87 bp) were detected. 
Figure 4. Taq I restriction enzyme assay showing normal versus ATP6V1B2 c.1516 C>T mutant PCR 
fragments. 

Yongyi Yuan, Xi Lin and Pu Dai 
 
300
 
(A) Atp6v1b2 distribution in mouse cochlea. Atp6v1b2 expresses mainly in the organ of Corti, spiral 
ganglion neurons, the limbus, and fibrocytes close to the stria vascularis; (B) Atp6v1b2 expression 
in hair cells; (C) Atp6v1b2 expression in the spiral ganglia (SG) neurons; (D) Double staining of 
Atp6v1b2 and tubulin in ganglia neurons. Green: Atp6v1b2, Red: ß-tubulin; (E) Double staining of 
Atp6v1b2 and Myo6 in cultured hair cells. Green: Atp6v1b2, Red: Myo6 
Figure 5. Atp6v1b2 expression in the cochlea. 
 
 
Atp6v1b2 Cochlea Knockdown Mouse Shows Hearing Loss 
 
To further investigate the function of ATP6V1B2 in the cochlea, we generated a mouse 
model in which the expression of Atp6v1b2 was specifically reduced in the cochlea using a 
morpholino oligomer. The oligomer was designed to anneal at the junction of intron 12 and 
exon 13, which resulted in a partial inclusion of intron 12 followed by a stop codon that 
excluded the expression of exons 13 and 14 in the mature mRNA (Figure 6A). The Atp6v1b2 
morpholino oligomer was microinjected (0.05–5.0 µg/µL) into the scala media of the basal turn 
of the mouse cochlea before postnatal day three. Hearing sensitivity has been shown to be 
unaffected by such an injection procedure if the injection was done to mice younger than 
postnatal day 5 (P5) [16]. Reverse transcription-polymerase chain reaction (RT-PCR) was used 
to verify the abnormal transcript product containing part of intron 12 in the mouse cochlea 3 
days after injection (Figure 6A). At 4 weeks post-injection, auditory brainstem response (ABR) 
tests measured across a frequency range of 4–32 kHz showed that hearing thresholds in the ear 
injected with the morpholino oligomer at the concentration of 0.5, 1.25, 2.5 and 5.0 µg/µL were 
elevated by 30–50 dB compared to wild-type mice. However, hearing thresholds in mice  
 

 
 
 
(A) RT-PCR analysis shows intron 12 retention in the Atp6v1b2 transcript of Atp6v1b2-specific morpholino oligomer (MO)-knockdown mouse cochlea. The morpholino oligomer was 
designed to anneal at the junction of intron 12 and exon 13, which resulted in a partial inclusion of intron 12 followed by a stop codon UAA (indicated by the red arrow). The 
forward RT-PCR primer was in exon 11 and the reverse primer was in intron 12. The RNA was extracted 3 days after morpholino inner ear injection. Since the reverse primer 
corresponded to intron 12 sequences, it could not bind to the normal Atp6v1b2 transcript. No bands were observed in the wild-type (WT)- or scrambled morpholino oligomer 
(SMO)-injected mice. The primer pairs amplified a product of 581 bp, including part of exon 11, exon 12 and part of intron 12 in the presence of abnormal splicing due to the 
Atp6v1b2-specific morpholino.  
(B) Hearing thresholds (y-axis) were determined based on ABR measurements at various frequencies (x-axis) for Atp6v1b2-specific morpholino oligomer (MO)-knockdown 
mice, scrambled morpholino oligomer (SMO) control mice and wild-type mice. ABR thresholds were measured at postnatal day 30 (P30), 4 weeks after cochlea injection. 
Hearing thresholds in Atp6v1b2-knockdown mice at 0.5, 1.25, 2.5 and 5.0 µg/µL were elevated by ~30–50 dB compared with wild-type and scrambled-morpholino-injected 
mice. Hearing thresholds in Atp6v1b2-specific-MO-cochlea-injected mice at 0.05 µg/µL were within the normal range. Legends for different mouse groups are shown in the 
panel, n= the number of ears. Vertical bars represent standard errors of the mean.  
(C) Flattened whole mount cochlea staining shows the degeneration of hair cells in the Atp6v1b2-knockdown mice. At 21 days after cochlea injection with Atp6v1b2-specific 
morpholino oligomer (MO, 0.5 µg), the majority of hair cells in the basal, middle, and apical turns had died. At 21 days after cochlea injection with the scrambled morpholino 
oligomer (SMO, 0.5 µg), the hair cells in the basal, middle and apical turns remained normal. Green: Atp6v1b2; Red: Phalloidin. 
Figure 6. Atp6v1b2-knockdown analysis in the mouse cochlea. 

Yongyi Yuan, Xi Lin and Pu Dai 
 
302
 
(A) Knockdown of Atp6v1b2 in the whole cochlea 30 days after cochlea injection with Atp6v1b2- 
specific morpholino (0.5 µg); (B) Hair cell degeneration 30 days after cochlea injection with 
Atp6v1b2-specific morpholino (0.5 µg); (C) Spiral ganglia neuron degeneration 30 days after 
cochlea injection with Atp6v1b2-specific morpholino (0.5 µg); (D) to (F) Whole cochlea, hair cells 
and spiral ganglia neurons remain normal 30 days after cochlea injection with scrambled 
morpholino (0.5 µg). Green: Atp6v1b2 
Figure 7. Degeneration of mouse spiral ganglia neurons and organ of Corti in Atp6v1b2 knockdown 
mice. 
injected with 0.05 µg/µL morpholino oligomer was within the normal range, indicating the 
dosage dependence of the hearing loss phenotype. In addition, all the mice received scrambled 
morpholino oligomer (0.5 µg/µL) displayed normal hearing (Figure 6B). These results 
supported the specific effects of the injected morpholino oligomer. Immunological staining 
observations revealed that Atp6v1b2 expression was knocked down significantly in the gross 
cochlea (Figure 7), especially in the hair cells and the spiral ganglion neurons. In addition, we 
observed hair cell degeneration in the cochlea that received the morpholino oligomer to 
knockdown the Atp6v1b2 expression (Figure 6C).  
 
 
Western Blot Analysis of Atp6v1b2 Shows Reduced Expression of Atp6v1b2  
in the Spiral Ganglion Neurons and the Organ of Corti 
 
Western blot analysis performed 7 days after injections demonstrated significantly 
decreased levels of V-ATPase encoded by Atp6v1b2 in the group that received morpholino 
oligomer in both the spiral ganglion neurons (Tukey’s multiple comparison test, P=0.0073, 
q=25.99) and in the organ of Corti. The comparsion was made between the experimental 
group and the group that received scrambled morpholino oligomer as well as the wild-type 
group. At three weeks after morpholino oligomer injection, the V-ATPase level was 
decreased further in the organ of Corti (Tukey’s Test, P=0.039, q=10.37, Figure 8).  
 

The Molecular Pathogenesis of Dominant… 
 
303
 
(A) Western blots of ATP6V1B2 in the organ of Corti (OC) and spiral ganglion (SG) of wild-type 
(WT), scrambled-morpholino-oligomer (SMO, 0.5 µg/µl) control and Atp6v1b2-specific 
morpholino oligomer (MO, 0.5 µg/µl)-knockdown mice. Legends for each lane are shown in the 
figure. Protein was extracted from the postnatal day 9 (P9) mouse cochlea 7 days after inner ear 
injection. 
(B) Western blots of ATP6V1B2 in the organ of Corti (OC) of wild-type (WT), scrambled-
morpholino-oligomer (SMO, 0.5 µg/µl) control and Atp6v1b2-specific-morpholino-oligomer (MO, 
0.5 µg/µl)-knockdown mice. Legends for each lane are shown in the figure. Protein was extracted 
from postnatal day 23 (P23) mouse, 21 days after inner ear injection. 
(C) The band intensities in Figure 8A were normalized to the corresponding ß-actin bands for 
quantification. Two asterisks on top of bars indicate significant reductions in ATP6V1B2 
expression compared with the WT and SMO control in the spiral ganglion (Tukey’s multiple 
comparison test, P<0.01). Data are presented as means ± standard deviation. Four biological 
replicates are represented in the bar graphs. 
(D) The band intensities in Figure 8B were normalized to the corresponding ß-actin bands for 
quantification. The asterisk on top of the bars indicates significant reductions in ATP6V1B2 
protein expression compared with the WT and SMO control in the organ of Corti (Tukey’s 
multiple comparison test, P<0.05). Data are presented as means ± standard deviation. Four 
biological replicates are represented in the bar graphs. 
Figure 8. Protein levels of ATP6V1B2 in two regions of the cochlea from wild-type, scrambled-
morpholino-control and Atp6v1b2-knockdown mice. 
 
ATP6V1B2 C.1516 C>T is a Dominant Loss-of-Function Mutation, Causing 
Abnormal Acidification in Lysosomes 
 
To evaluate the pathogenicity of the ATP6V1B2 c.1516 C>T mutation, we transfected the 
pIRES2-EGFP-ATP6V1B2 wild-type plasmid and pIRES2-EGFP-ATP6V1B2 c.1516 C>T 

 
 
 
 
 

 
 
(A) ATPase assays showed that ATPase hydrolysis activity decreased significantly in the transfected cells as the ratio of the mutant increased. The data in each 
group represent a sample size (n) of 9. The asterisk on the top of bars indicates a significant increase or reduction in ATPase hydrolysis activity (P<0.05), 
compared to the empty vector control pIRES2-EGFP or pIRES2-EGFP-ATP6V1B2, respectively. Statistical analyses were performed by the Newman-
Keuls Multiple Comparison Test. Data are presented as means ± standard deviation. 
(B) Calibration curve for determining the lysosomal pH in HEK 293 cells. Calibration was performed as described in the Materials and Methods to generate a 
curve relating to the emission intensity ratio at 460 and 528 nm using an excitation at 360 nm to lysosomal pH. Vertical bars represent standard errors of the 
mean of four identical samples. 
(C) The lysosomal pH increased in transfected cells as the ratio of the mutant increased, indicating that ATPase proton transport activity decreased as the ratio 
of the mutant increased. The data in each group represent a sample size (n) of 4. The asterisk on top of bars indicates significant reduction or increase in 
lysosomal pH (P<0.05), compared to the empty vector control pIRES2-EGFP or pIRES2-EGFP-ATP6V1B2, respectively. Statistical analyses were 
performed using the LSD Test. Data are presented as means ± standard deviation. 
Figure 9. Effects of the ATP6V1B2 p.Arg506X mutant on ATPase activity in transfected HEK293 cells. 

Yongyi Yuan, Xi Lin and Pu Dai 
 
306
mutant plasmid into HEK293 cells. V-ATPase is expressed in HEK293 cells, and transfection 
with ATP6V1B2 caused an overexpression of the V-ATPase. However, no change in 
ATP6V1B2 intracellular distribution was detected in c.1516 C>T mutant-transfected cells. We 
found that the ATPase hydrolysis activity significantly decreased in the transfected cells when 
the ratio of the mutant increased. The ATPase hydrolysis in cells transfected with ATP6V1B2 
was 42.24 ± 2.11, that in cells transfected with a 1:1 mixture of ATP6V1B2 and the c.1516 
C>T mutant was 38.48 ± 2.87, and that in cells transfected with c.1516 C>T mutant was 
36.09 ± 2.89. The ATPase hydrolysis activity in cells transfected with empty vector was 
30.28 ± 2.79 (Newman-Keuls Multiple Comparison Test, P=0.032,q=4.508, Figure 9A). This 
trends indicated the c.1516 C>T mutant had reduced ATPase hydrolysis compared with the 
wild-type ATP6V1B2.  
We measured the proton transport activity of V-ATPase in lysosomes using a lysosome-
specific dye. The lysosome pH measurements were 5.02 ± 0.05 in cells transfected with 
empty vector control, 4.72 ± 0.046 in cells transfected with the c.1516 C>T mutant, 4.65 ± 
0.042 in cells transfected with a 1:1 mixture of ATP6V1B2 and the c.1516 C>T mutant, and 
4.59 ± 0.048 in cells transfected with wild-type ATP6V1B2. A statistically significant 
difference in lysosomal pH was detected between ATP6V1B2 and c.1516 C>T mutant-
transfected cells (LSD test, P=0.02, Figure 9B and 9C). The ATPase hydrolysis activity and 
proton transport activity did not differ significantly between HEK293 cells and pIRES2-
EGFP-transfected HEK293 cells. These results of the c.1516 C>T mutant that the V-ATPase 
hydrolysis decreased and the lysosome pH increased which indicated the reduced 
acidification suggest that ATP6V1B2 c.1516 C>T is a loss-of-function mutation.  
 
 
DISCUSSION 
 
Deafness and onychodystrophy diseases (DODs) are classified into two genetically 
distinct groups: the autosomal recessive form (DOOR syndrome) and the dominant (D) form 
(DDOD). Clinically, individuals with DOOR syndrome show features such as mild to severe 
mental retardation, seizures, mutism, hypotonia, congenital sensorineural deafness, 
triphalangeal thumbs, and hypoplastic nails. The phenotypes of DDOD are milder than those 
in the recessive form [3], and do not usually involve mental retardation. Features in our 
DDOD families resembled those reported in several previous studies [4-8] and included 
deafness, absence of nails and/or toes with more variable presence of brachydactyly, 
hypoplastic distal phalanges, and bulbous distal phalanges. Of note, the probands reported by 
Feinmesser and Zelig [8] were affected sisters from a consanguineous family; both had 
normal intellect, which was suggestive of autosomal recessive inheritance, genetic 
heterogeneity, or possibly gonadal mosaicism for an autosomal dominant condition. The 
conditions in the other reported families segregated in an autosomal dominant manner. To 
date, the hereditary pathogenesis has not been clarified for either DDOD or DOOR syndrome 
[1], although a neurometabolic etiology has been postulated for latter. 
Prior to our study, White and Fahey [5] performed an SNP microarray analysis of one 
DDOD individual from Australia. However, they found no evidence of a change in copy 
number. Our study is the first report of a de novo heterozygous mutation in the ATP6V1B2 
gene that appeared to be a cause of autosomal DDOD syndrome. The ATP6V1B2 gene on 

The Molecular Pathogenesis of Dominant… 
 
307
chromosome 8p21.3 contains 14 exons and normally encodes 511 amino acids. The 
availability of two independent individuals with a strikingly similar phenotype was very 
useful for identifying the causative gene and we took advantage of it. Our results obtained 
from these two individuals indicated that the ATP6V1B2 defect causes DDOD syndrome, and 
this was further verified in a third independent family. The identification of the specific 
ATP6V1B2 c.1516 C>T (p.Arg506X) mutation in three independently identified DDOD 
individuals, but not in a large number (1053 cases) of normal hearing controls, provides 
further supporting evidence that the p.Arg506X in ATP6V1B2 is responsible for the DDOD 
syndrome.  
Schinzel-Giedion syndrome (MIM 269150) and Kabuki syndrome (MIM 147920) [17,18] 
are known to be caused by dominant de novo mutations. De novo mutations have recently 
been shown to play a major role in human diseases with reduced reproductive ﬁtness [18-21]. 
The identiﬁcation of a same de novo dominant mutation in 3 unrelated DDOD individuals by 
chance should be extremely unlikely. Our results indicate a high correlation between 
phenotype and genotype in these individuals with the DDOD syndrome. Given a transmission 
risk of 50% and a recurrence risk of <1% for de novo autosomal dominant mutations, 
compared to a transmission risk of <1% and a recurrence risk of 25% for autosomal recessive 
inheritance, the relatively high frequency of the de novo mutation in our cohort has significant 
implications for genetic counseling in our individuals and their relatives. 
ATP6V1B2 encodes a component of the vacuolar ATPase (V-ATPase, also known as H+-
ATPase), which is a multisubunit enzyme that mediates acidification of eukaryotic 
intracellular organelles. V-ATPase-dependent organelle acidification is necessary for 
intracellular processes such as protein sorting, zymogen activation, receptor-mediated 
endocytosis, and synaptic vesicle proton gradient generation. V-ATPase is composed of a 
cytosolic V1 domain and a transmembrane V0 domain. The V1 domain is responsible for 
ATP hydrolysis, and the V0 domain is responsible for protein translocation. The protein 
encoded by ATP6V1B2 is one of the two V1 domain B subunit isoforms, and as it is highly 
expressed in the organ of cerebrum and in the organelle of Atp6v1b2, it is usually called a 
brain isoform or lysosomal V1 subunit B2 [22,23]. Deficiency in ATP6V1B2 has been related 
to hereditary diseases such as osteopetrosis and renal tubular acidosis. It has been suggested 
that deficiencies of ATP6V1B1 and ATPV0A4 is related to distal renal tubular acidosis and 
hearing loss [24-27]. To the best of our knowledge, no report has linked the function of 
ATP6V1B2 to hearing. The distribution of Atp6v1b2 in hair cells and spiral ganglia neurons in 
mouse indicates it may play a role in the auditory system. The gene related to DOORS 
syndrome, TBC1D24, encodes a member of the Tre2–Bub2–Cdc16 (TBC) domain-containing 
Rab (Ras-related proteins in brain)-specific GTPase-activating proteins, which coordinate 
Rab proteins and other GTPases for the regulation of membrane trafficking. TBC1D24 and 
ATP6V1B2 are all known to be widely expressed, most highly in the brain and kidneys. 
Tbc1d24 expresses in the stereocilia of the hair cells as well as in the spiral ganglion neurons 
[28]. TBC1D24 and ATP6V1B2’s identical distribution regions and their function with 
GTPases or ATPases indicate they may have some physiological link. The hearing loss 
phenotype of our Atp6v1b2 cochlea knockdown mouse model confirmed that the normal 
function of the gene is required for normal hearing. Significantly reduced Atp6v1b2 
expression in the mouse cochlea resulted in the death of hair cells and spiral ganglion 
neurons, leading to hearing loss.  

Yongyi Yuan, Xi Lin and Pu Dai 
 
308
Cell metabolism depends on the endocytic pathway [29,30]. Lysosomes, the terminal 
organelles in the endocytic pathway, play an important role in hydrolyzing macromolecules 
and making their components available as nutrients for the cell. Hydrolytic enzymes in 
lysosomes are activated by the acidic pH (between 4.5 and 5.0), which is generated and 
maintained by the activity of the proton-pumping V-ATPase, using metabolic energy in the 
form of ATP to pump protons into the lysosome lumen [31,32]. Our functional studies 
demonstrating that the c.1516 C>T mutation caused a decrease in the ATP production and an 
increase in lysosomal pH indicate that ATP6V1B2 c.1516C>T is a dominant loss-of-function 
mutation. According to PhyloP vertebrate conservation scores, the ATP6V1B2 c.1516 C is a 
highly conserved base in the genome. The coded amino acid 506 is highly conserved 
according to multiple sequence alignment and mutant protein structure abnormality predicted 
by SWISS-MODEL [33]. These support the pathogenicity of the mutation. We propose that 
insufficient acidification in the lysosome caused by ATP6V1B2 c.1516 C>T mutation may 
result in decreased activity of acid-dependent hydrolases, thereby limiting the decomposition 
of proteins, lipids, and polysaccharides in cells and affecting the development of multiple 
ectoderm-derived systems. Embryologically, the inner ear, nails, and teeth are all ectoderm-
derived organs. The fact that ATP6V1B2 is ubiquitously expressed in humans makes it 
reasonable to assume that ATP6V1B2 may play important roles in other developing ectoderm-
derived organs. Knock-in mouse model studies are underway in our laboratory to elucidate 
the consequences of ATP6V1B2 mutation on ectoderm-derived organs, with the goal of 
targeting these effects therapeutically.  
In summary, whole-exome sequencing in DDOD pedigrees revealed a de novo c.1516 
C>T (p.Arg506X) mutation in ATP6V1B2 that was present in three independently identified 
individuals with DDOD. Immunolabeling for localization of ATP6V1B2 in the mouse cochlea 
as well as functional and morphological studies in the ATP6V1B2 knockdown mouse model 
provided further evidences that support the idea that ATP6V1B2 is a syndromic deafness 
gene. Direct assessment of the in vitro effects of the ATP6V1B2 c.1516 C>T mutation in 
transfected cells indicated that it is a dominant haplo-insufficient mutation leading to 
insufficient acidification of the lysosome. Understanding molecular mechanisms in rare 
syndromic hearing impairments might lead to valuable insights into the molecular triggers for 
hair cell and spiral ganglion neuron degeneration and provide the basis for genetic diagnosis 
as well as new developments in future therapeutic interventions.  
 
 
REFERENCES 
 
[1] 
James, A. W., Miranda, S. G., Culver, K., Hall, B. D. & Golabi, M. (2007). DOOR 
syndrome: clinical report, literature review and discussion of natural history. Am J Med 
Genet A, 143A, 2821-2831. 
[2] 
Vind-Kezunovic, D. & Torring, P. M. (2013). A Danish family with dominant 
deafness-onychodystrophy syndrome. Journal of dermatological case reports, 7, 125-
128. 
[3] 
Robinson, G. C., Miller, J. R. & Bensimon, J. R. (1962). Familial ectodermal dysplasia 
with sensorineural deafness and other anomalies. Pediatrics, 30, 797-802. 

The Molecular Pathogenesis of Dominant… 
 
309
[4] 
Kondoh, T., Tsuru, A., Matsumoto, T., Matsuzaka, T. & Tsuji, Y. (1999). Autosomal 
dominant onychodystrophy and congenital sensorineural deafness. J Hum Genet, 44, 
60-62. 
[5] 
White, S. M. & Fahey, M. (2011). Report of a further family with dominant deafness-
onychodystrophy (DDOD) syndrome. Am J Med Genet A, 155A, 2512-2515. 
[6] 
Moghadam, H. & Statten, P. (1972). Hereditary sensorineural hearing loss associated 
with onychodystrophy and digital malformations. Can Med Assoc J, 107, 310-312. 
[7] 
Goodman, R. M., Lockareff, S. & Gwinup, G. (1969). Hereditary congenital deafness 
with onychodystrophy. Arch Otolaryngol, 90, 474-477. 
[8] 
Feinmesser, M. & Zelig, S. (1961). Congenital deafness associated with 
onychodystrophy. Arch Otolaryngol, 74, 507-508. 
[9] 
Yuan, Y., Zhang, J, Chang, Q., Zeng, J., Xin, F., et al. (2014). De novo mutation in 
ATP6V1B2 impairs lysosome acidification and causes dominant deafness-
onychodystrophy syndrome. Cell research 10.1038/cr.2014.77. 
[10] Wang, H. Q. ea (2007). Standardization of the Griffith Mental Development Scales for 
Children Aged 0~ 7 Years in the C ities of Shanxi Province. Chinese Mental Health 
Journal, 121, 700-703. 
[11] Tong, D., Chen, Y., Ou, X., Chen, W., Liu, S., et al. (2013). Polymorphism analysis 
and evaluation of 19 STR loci in the Han population of Southern China. Ann Hum Biol, 
40, 191-196. 
[12] Li, R., Yu, C., Li, Y., Lam, T. W., Yiu, S. M., et al. (2009). SOAP2: an improved 
ultrafast tool for short read alignment. Bioinformatics, 25, 1966-1967. 
[13] Li, R., Li, Y., Fang, X., Yang, H., Wang, J., et al. (2009). SNP detection for massively 
parallel whole-genome resequencing. Genome Res, 19, 1124-1132. 
[14] Li, H. & Durbin, R. (2010). Fast and accurate long-read alignment with Burrows-
Wheeler transform. Bioinformatics, 26, 589-595. 
[15] McKenna, A., Hanna, M., Banks, E., Sivachenko, A., Cibulskis, K., et al. (2010). The 
Genome Analysis Toolkit: a MapReduce framework for analyzing next-generation 
DNA sequencing data. Genome Res, 20, 1297-1303. 
[16] Wang, Y., Sun, Y., Chang, Q., Ahmad, S., Zhou, B., et al. (2013). Early postnatal virus 
inoculation into the scala media achieved extensive expression of exogenous green 
fluorescent protein in the inner ear and preserved auditory brainstem response 
thresholds. J Gene Med, 15, 123-133. 
[17] Ng, S. B., Bigham, A. W., Buckingham, K. J., Hannibal, M. C., McMillin, M. J., et al. 
(2010). Exome sequencing identifies MLL2 mutations as a cause of Kabuki syndrome. 
Nat Genet, 42, 790-793. 
[18] Hoischen, A., van Bon, B. W., Gilissen, C., Arts, P., van Lier, B., et al. (2010). De 
novo mutations of SETBP1 cause Schinzel-Giedion syndrome. Nat Genet, 42, 483-485. 
[19] Vissers, L. E., de Ligt, J., Gilissen, C., Janssen, I., Steehouwer, M., et al. (2010). A de 
novo paradigm for mental retardation. Nat Genet, 42, 1109-1112. 
[20] Vadlamudi, L., Dibbens, L. M., Lawrence, K. M., Iona, X., McMahon, J. M., et al. 
(2010). Timing of de novo mutagenesis--a twin study of sodium-channel mutations. N 
Engl J Med, 363, 1335-1340. 
[21] Hamdan, F. F., Gauthier, J., Spiegelman, D., Noreau, A., Yang, Y., et al. (2009). 
Mutations in SYNGAP1 in autosomal nonsyndromic mental retardation. N Engl J Med, 
360, 599-605. 

Yongyi Yuan, Xi Lin and Pu Dai 
 
310
[22] Wagner, C. A., Finberg, K. E., Breton, S., Marshansky, V., Brown, D., et al. (2004). 
Renal vacuolar H+-ATPase. Physiol Rev, 84, 1263-1314. 
[23] Nelson, N., Perzov, N., Cohen, A., Hagai, K., Padler, V., et al. (2000). The cellular 
biology of proton-motive force generation by V-ATPases. J Exp Biol, 203, 89-95. 
[24] Stover, E. H., Borthwick, K. J., Bavalia, C., Eady, N., Fritz, D. M., et al. (2002). Novel 
ATP6V1B1 and ATP6V0A4 mutations in autosomal recessive distal renal tubular 
acidosis with new evidence for hearing loss. J Med Genet, 39, 796-803. 
[25] Stehberger, P. A., Schulz, N., Finberg, K. E., Karet, F. E., Giebisch, G., et al. (2003). 
Localization and regulation of the ATP6V0A4 (a4) vacuolar H+-ATPase subunit 
defective in an inherited form of distal renal tubular acidosis. J Am Soc Nephrol, 14, 
3027-3038. 
[26] Sobacchi, C., Frattini, A., Orchard, P., Porras, O., Tezcan, I., et al. (2001). The 
mutational spectrum of human malignant autosomal recessive osteopetrosis. Hum Mol 
Genet, 10, 1767-1773. 
[27] Sly, W. S., Hewett-Emmett, D., Whyte, M. P., Yu, Y. S. & Tashian, R. E. (1983). 
Carbonic anhydrase II deficiency identified as the primary defect in the autosomal 
recessive syndrome of osteopetrosis with renal tubular acidosis and cerebral 
calcification. Proc Natl Acad Sci U S A, 80, 2752-2756. 
[28] Lima, F. B., Ota, F. H., Cabral, F. J., Del Bianco Borges, B. & Franci, C. R. (2014). 
Estrogen, but not progesterone, induces the activity of nitric oxide synthase within the 
medial preoptic area in female rats. Brain research, 1578, 23-29. 
[29] Sorkin, A. & von Zastrow, M. (2009). Endocytosis and signalling: intertwining 
molecular networks. Nat Rev Mol Cell Biol, 10, 609-622. 
[30] Doherty, G. J. & McMahon, H. T. (2009). Mechanisms of endocytosis. Annu Rev 
Biochem, 78, 857-902. 
[31] Recchi, C. & Chavrier, P. (2006). V-ATPase: a potential pH sensor. Nat Cell Biol, 8, 
107-109. 
[32] Mindell, J. A. (2012). Lysosomal acidification mechanisms. Annu Rev Physiol, 74, 69-
86. 
[33] Arnold, K., Bordoli, L., Kopp, J. & Schwede, T. (2006). The SWISS-MODEL 
workspace: a web-based environment for protein structure homology modelling. 
Bioinformatics, 22, 195-201. 

In: Encyclopedia of Audiology and Hearing Research 
ISBN: 978-1-53617-702-2 
Editors: Erno Larivaara and Senja Korhola 
© 2020 Nova Science Publishers, Inc. 
 
 
 
 
 
 
 
Chapter 25  
 
 
 
ASSOCIATION BETWEEN SENSORINEURAL HEARING 
LOSS AND SLEEP-DISORDERED BREATHING: 
LITERATURE REVIEW 
 
 
Antonella Ballacchino1, Rosalia Gargano2  
and Francesco Martines2 
1Università degli Studi di Palermo, Dipartimento di Biotecnologie Mediche  
e Medicina Forenze Sezione di Audiologia, Palermo, Italy 
2Università degli Studi di Palermo, Dipartimento di Biomedicina Sperimentale  
e Neuroscienze Cliniche, Sezione di Otorinolaringoiatria, Palermo, Italy 
 
 
ABSTRACT 
 
The cochlea is especially sensitive to circulatory alterations because it is supplied by 
a single terminal artery and lacks adequate collateral blood supply. 
To examine the putative association between Sensorineural Hearing Loss (SNHL) 
and Sleep Disordered Breathing (SDB) through the literature review is very interesting. 
In fact these medical disorders usually are associated to cerebral circulatory 
alterations resulting in hypoxia, acute hemodynamic change, and decreased cerebral 
blood flow, because the Sleep Disorder Breathing (SDB), for example OSAHS 
(Obstructive Sleep Apnea Hypopnea Syndrome), is characterized by periodic 
hyposia/reoxygenation. These noxious stimuli can, in turn, activate the sympathetic 
nervous system, depress parasympathetic activity which results in oxidative stress, 
endothelial dysfunction, and activation of the inflammatory cascade of different 
anatomical structure as inner ear. Is reasonable to assume that could cause and/or 
esacerbate sensorineural hearing loss with/or without tinnitus.  
Based on these clinical evidences some authors studied the association between SDB 
and a dysfunction of auditory pathway showing an improved risk of sensorineural hearing 
loss, a lower transient otoacoustic emissions (TEOAE) reproducibility and an impairment 
of auditory brainstem responses in OSAHS populatio. In fact it is known that the 
transduction mechanism of the inner ear and the transmission of nerve impulses along the 
auditory way are highly dependent upon the oxygen supply. Recent studies evidenced 
how through oxidative injury due to a hypoxic stress induced apoptosis in spiral ligament 

Antonella Ballacchino, Rosalia Gargano and Francesco Martines 
 
312
and in the cochlear basal turn of the Organ of Corti of obese CD/1 mouses, causes a high 
frequencies sensorineural hearing loss. 
Therefore OSAHS may lead to cerebral vascular insufficiency resulting in hypoxia, 
acute hemodynamic change, and decreased cerebral blood flow during episodes of apnea 
with consequent ischemic injury to the cochlea.  
 
Keywords: Sensorineural Hearing Loss (SNHL), Sleep Disordered Breathing (SDB), 
Hypoxia, OSAHS (Obstructive Sleep Apnea Hypopnea Syndrome), Endothelial 
dysfunction 
 
 
INTRODUCTION 
 
Sleep Disordered breathing (SDB), including Obstructive Sleep Apnea Hypopnea 
Syndrome (OSAHS) is a condition, affecting 24% of men and 9% of women in their middle 
age, associated to high values either of Body Mass Index (BMI) and neck circumference, 
where intermittent obstruction of the airway during sleep causes sleep fragmentation and 
repeated desaturations. This disorder carries potentially serious consequences: excessive 
daytime sleepiness, neurocognitive deterioration, endocrine and metabolic derangements, and 
is universally recognized as independent risk factor for cardiovascular disease and its related 
mortality 1-3. Ear hypoxia is linked to damage of cochlear structures, vascular streaks, 
afferent synapses, internal ciliated cells but above all it is external ciliated cells of the basal 
turn which seem most vulnerable: this damage is responsible for sensorineural hearing loss 
and tinnitus 4-9. These phenomena lead to a chronic state of oxidative stress resulting in 
endothelial inflammation, in fact some studies estimated that in patients with sleep-related 
breathing disorders the probability of a cerebral vascular infarction (CVI) is 3.1 times that in 
patients without sleep apnea and that 25-50% of all patients who have a stroke suffer from 
sleep apnea (OSAHS) and have a respiratory disturbance index (RDI) higher than 10. CVI 
may be caused by variations in intracranial pressure or in intracranial hemodynamics owing 
to decreasing pO(2) and increasing pCO(2) during cessation of airflow. It is suspected that the 
most common causes of sudden deafness are vasospasm, thrombosis, embolism, 
hypercoagulation and sludging 10-15.  
Basing on these clinical evidences some authors studied the association between OSAHS 
and a dysfunction of auditory pathway showing an improved risk of sudden sensorineural 
hearing loss (SSNHL), a lower transient otoacoustic emissions (TEOAE) reproducibility and 
an impairment of auditory brainstem responses in OSAHS population 16,17. 
 
 
WHAT ARE THE MECHANISMS THAT DETERMINE  
THE AUDIOLOGICAL DAMAGE IN PATIENTS WITH SDB? 
 
The transduction mechanism of the inner ear and the transmission of nerve impulses 
along the auditory way are highly dependent upon the cochlear oxygen supply,  
SDB, in particular OSAHS, is characterised by repetitive airway occlusion resulting in 
cyclical surges of hypoxia which may occur hundreds of times a night. In addition, OSAHS is 

Association between Sensorineural Hearing Loss... 
 
313
associated with heart failure, stroke and coronary artery disease 18-22. Endothelial 
dysfunction, linked to oxidative stress (“Oxidative stress” is the general phenomenon of 
oxidant exposure and antioxidant depletion, or oxidant-antioxidant balance), a key early event 
in hypertension and atherosclerosis, has been implicated as a possible mechanism linking the 
acute cyclical vascular stresses during sleep in OSAHS and the increased prevalence of 
chronic vascular diseases. Oxidative stress may induce neurotoxicity phenomena that lead to 
neurodegeneration. As the hair cells of Corti is particularly sensitive to oxidative stress, 
especially at the mitochondrial level, can go more easily meet degeneration or cell death 
(disorganization of cochlear homeostasis induced), resulting in an irreversible hearing 
damage 23. In addition, the metabolic implications in common with hearing disorders and 
SDB are obvious, in fact, one of the most important is that anoxia during OSAHS is a potent 
stimulus for catecholamine secretion and glycogenolysis. An indirect effect regards obesity, 
as it is tightly connected with diabetes (to emphasize this connection the term “diabesity” has 
been created) 24,25. There are also some studies that demonstrate the increase of 
inflammatory factors in subjects with OSASH: among these, C-reactive protein and 
cytokines, which are responsible for systemic atherosclerosis and probably have a role in the 
appearance of neoplasms 26,27 and also evidence of an increase of atherogenic 
dyslipidaemia 28,29. Hyperlipidemia determines, at the level of small vessels, a suffering of 
flow related to increased blood viscosity. This results in a reduced supply of oxygen to the 
inner ear and its suffering. 
 
 
LITERATURE REVIEW 
 
Many authors investigated the epidemiologic association between OSAHS and either 
sudden SNHL and dysfunction of auditory pathway. In a study of Fischer et al. a 7-channel 
polygraph was used to test 33 subjects with normal hearing and 27 patients suffering from 
sudden hearing loss and found that 29.6% of the patient group and 21.2% of those in the 
study control group were suffering from OSA and had RDI >10; this difference was not 
significant (p=0.554). Sudden hearing loss may also be an indicator of arteriosclerosis 
secondary to such risk factors as hypertension (p=0.005), diabetes (p=0.003), and 
hyperlipidemia (p=0.004), which were highly significant for the patient group 10. Sheu et 
al. evidenced how in a case-control study performed on 19152 patients, OSAHS is present on 
1.7% of SSNHL population respect to the 1.2% of the controls with a significant difference 
between the groups (P<0.04) [16]. Recently Casale et al. studied 30 patients divided in two 
groups, cases (18 subjects) with severe OSA and controls (21 subjects) with snoring without 
OSAHS and evidenced higher mean values at pure tone audiogram and lower TEOAE signal 
to noise ratio in severe OSAHS group with significant differences among cases and controls 
(P<0.01) [17]. The authors suggested as possible explanation for the association between 
SDB and SSNHL, that OSAHS indirectly contributes to the development of SSNHL, the 
effects of cardiovascular disease and cardiovascular risk factors and that is associated with 
reduced basal and functional capillarity rarefaction with an additional risk of impaired 
peripheral perfusion and therefore dysfunction of cochlear hair cells 16,17. Hwang et al. 
evidenced how through oxidative injury due to a hypoxic stress induced apoptosis in spiral 
ligament and in the cochlear basal turn of the Organ of Corti of obese CD/1 mouses, causes a 

Antonella Ballacchino, Rosalia Gargano and Francesco Martines 
 
314
high frequencies sensorineural hearing loss 30; as also demonstrated by a study of CAO 
Yongmao et al. which analyzed the hearing at extended high frequencies of patients with 
obstructive sleep apnea-hyponea syndrome. The youth group, adult group and OSAHS group 
were tested with pure tone audiometry and high frequency audiometry, and the res ponse ratio 
was calculated [31]. The conclusion was: the high frequency thresholds increased obviously 
when OSAHS group comparing with the adult group (P0.01), and the indicating ratio 
decreased obviously (P 0.05) 31.  
One of the most interesting studies on this topic was conducted by Jau-Jiuan Sheu et al., 
in this case-control study, identified 3192 patients diagnosed with SSNHL from the Taiwan 
Longitudinal Health Insurance Database as the study group and randomly extracted the data 
of 15 960 subjects matched by sex, age and year of first SSNHL diagnosis as controls. Of 19 
152 patients, 1.2% had OSA diagnoses prior to the index date; OSA was diagnosed in 1.7% 
of the SSNHL group and 1.2% of the controls. After adjusting for sociodemographic 
characteristics and comorbid medical disorders, we found that male patients with SSNHL 
were more likely to have prior OSA than controls (odds ratio, 1.48; 95% CI, 1.02-2.16) 
(P=.04) 32. Dziewas et al. in a study performed in 2007 showed how the recurrent 
intermittent hypoxaemia may be considered a risk factor for peripheral sensory nerve 
dysfunction and suggested that the treatment for OSAHS might result in an improved 
function of these nerves 33. 
 
 
CONCLUSION 
 
The cochlea is especially sensitive to circulatory alterations because it is supplied by a 
single terminal artery and lacks adequate collateral blood supply 34. Obstructive sleep 
apnea may lead to cerebral vascular insufficiency resulting in hypoxia, acute hemodynamic 
change, and decreased cerebral blood flow during episodes of apnea 2. In addition, elevated 
sympathetic nerve activity secondary to the reflex effects of hypoxia and hypercapnia as well 
as oscillations in blood pressure occurring during episodes of apnea may result in adverse 
cerebrovascular events and hence ischemic injury to the cochlea 35. 
The correlations between SDB and hearing disorders are widely demonstrated in the 
literature and is still studied.  
The presence of sensorineural hearing loss associated with essential hypertension, high 
cholesterol and high BMI should suspect the presence of SDB misunderstood. This would 
allow an early diagnosis of these disorders, the resolution of hearing loss and protection to 
cardiovascular and cerebrovascular accidents. 
In fact the early treatment of OSAHS with CPAP (continuous positive airway pressure) 
improves systemic vascular endothelial function. OSAHS has been implicated in the 
pathogenesis of hypertension, cardiovascular disease, heart failure, and stroke, all of which 
are associated with impaired endothelial responses. CPAP treatment may therefore provide an 
opportunity to reduce the vascular risk attributable to OSAHS, as well as hearing loss, 
allowing a better and continuous oxygenation of the blood vessels smaller 36.  
 
 

Association between Sensorineural Hearing Loss... 
 
315
REFERENCES 
 
[1] 
Bradley TD, Floras JS (2009). Obstructive sleep apnoea and its cardiovascular 
consequences. Lancet 373:82–93 286. 
[2] 
Redline S, Tishler P (2003). The genetics of sleep apnea. Sleep Med Rev 4:583–602. 
[3] 
Fletcher EC (1995). The relationship between systemic hypertension and obstructive 
sleep apnea: facts and theory. Am J Med 98:118–128. 
[4] 
Morris L, Kleinberger A, Lee K, et al. (2008). Rapid risk stratification for obstructive 
sleep apnea, based on snoring severity  and body mass index. Otolaryngology-Head 
and Neck Surgery; 139: 615-618. 
[5] 
Rebillard G, Lavigne-Rebillard M. Effect of reversible hypoxia on the compared time 
courses of endocochlear potential and 2f1-f2 distortion products, (1992) Hearing 
Reserch; 62(2): 142-148. 
[6] 
Martines F, Sireci F, Cannizzaro E et al, (2014). Clinical observations and risk factors 
for tinnitus in a Sicilian cohort. Eur Arch Otorhinolaryngol.; Sep. 5; DOI 
10.1007/s00405-014-3275-0. 
[7] 
Salvago P, Martines E, Martines F, (2013). Prevalence and risk factors for 
sensorineural hearing loss: Western Sicily overview. Eur Arch Otorhinolaryngol.; 
270:3049–56. 
[8] 
Martines F, Bentivegna D, Martines E et al, (2010). Assessing audiological, 
pathophysiological and psychological variables in tinnitus patients with or without 
hearing loss. Eur Arch Otorhinolaryngol.; 267:1685-1693 
[9] 
Martines F, Bentivegna D, Martines E et al, (2010). Characteristics of tinnitus with or 
without hearing loss: clinical observations in Sicilian tinnitus patients. Auris Nasus 
Larynx; 37:685-693. 
[10] Fischer Y, Yakinthou A, (2003 Jun). Prevalence of obstructive sleep apnea syndrome 
(OSA) in patients with sudden hearing loss. A pilot study. WJ. HNO.; 51(6):462-6. 
[11] Martines F, Maira E, Ferrara S, (2011). Age related hearing impairment (ARHI): a 
common sensory deficit in the elderly. Acta Medica Mediterranea; 27:47–52. 
[12] Martines F, Dispenza F, Gagliardo C, Martines E, Bentivegna D, (2011). Sudden 
sensorineural hearing loss as prodromal symptom of anterior inferior cerebellar artery 
infarction. ORL; 73:137–40. 
[13] Martines F, Martinciglio G, Bucalo C et al, (2008). Neurovascular conflict in patient 
with tinnitus and essential hypertension: case report. Otorinolaringol; 58: 191-196. 
[14] Gagliardo C, Martines F, Bencivinni F, (2013). Intratumoral Haemorrhage Causing an 
Unusual Clinical Presentation of a Vestibular Schwannoma. Neuroradiol J.; 26(1):30-
4. 
[15] Martines F, Agrifoglio M, Bentivegna D, (2012). Treatment of tinnitus and dizziness 
associated vertebrobasilar insufficiency with a fixed combination of cinnarizine and 
dimenhydrinate. Acta Medica Mediterranea; 28:291–296. 
[16] Sheu JJ, Wu CS, Lin HC, (2012). Association Between Obstructive Sleep Apnea and 
Sudden Sensorineural Hearing Loss. A Population-Based Case-Control Study. Arch 
Otolaryngol Head Neck Surg.;138(1):55-9. 

Antonella Ballacchino, Rosalia Gargano and Francesco Martines 
 
316
[17] Casale M, Vesperini E, Potena M, Pappacena M, Bressi F, Baptista PJ, Salvinelli F, 
(2012). Is obstructive sleep apnea syndrome a risk factor for auditory pathway? Sleep 
Breath 16:413–417. 
[18] Javaheri S, Parker TJ, Liming JD, et al. (1998). Sleep apnea in 81 ambulatory 
malepatients with stable heart failure. Types and their prevalences, consequences, and 
presentations. Circulation; 97:2154–2159. 
[19] Dyken ME, Somers VK, Yamada T, e al. (1996). Investigating the relationship between 
stroke and obstructive sleep apnea. Stroke; 27:401–407. 
[20] Wessendorf TE, Teschler H, Wang YM, et al. (2000) Sleep-disordered breathing 
among patients with first-ever stroke. J Neurol; 247:41–47. 
[21] Hung J, Whitford EG, Parsons RW, et al. (1990). Association of sleep apnoea with 
myocardial infarction in men. Lancet; 336:261–264. 
[22] Peker Y, Kraiczi H, Hedner J, et al. (1999). An independent association between 
obstructive sleep apnoea and coronary artery disease. Eur Respir J;14:179–84. 
[23] Serra A, Maiolino L, (2011). Ruolo delle Biossidazione nelle patologie dell’orecchio 
interno. Argomenti di acta otorhinolaryngologica italica, vol. 5, no2, pp. 7-9. 
[24] Tatti B, Passali D, Bellussi L.M, (2012). The undisclosed role of anoxia/hypoxia and 
disturbed sleep on glucose metabolism. J Diabete Mellitus; 2:186-90. 
[25] Spiegel K, (2004). Sleep curtailment in healthy young men is associated with decreased 
leptin levels, elevated ghrelin levels, and increased hunger and appetite; Ann Internal 
Med;141:846-50. 
[26] Passali D, Tatti P, Passali F.M, et al. (2013). The undisclosed role of disturbed sleep 
and hypoxia on metabolism: the importance of upper airways pathology. Sleep 
Breath;17:5-6. 
[27] Popko K, Gorska E, Potapinska O, et al. (2008). Frequency of dis- tribution of 
inflammatory cytokines IL-1, IL-6 and TNF-gene polymorphism in patients with 
obstructive sleep apnea. J Physiol Pharmacol; 59 (Suppl. 6):607-14. 
[28] Ciftci TU, Kokturk O, Bukan N, et al. (2004) The relationship between serum cytokine 
levels with obesity and obstructive sleep apnea syndrome. Cytokine; 28:87-91. 
[29] Williams CJ, Hu FB, Patel SR, et al. (2007). Sleep duration and snoring in relation to 
cardiovascular disease risk in women with type 2 diabetes. Diabetes Care; 30:1233-40. 
[30] Hwang JH, Hsu CJ, Yu TC, et al. (2013). Diet-Induced Obesity Exacerbates Auditory 
Degeneration via Hypoxia, Inflammation, and Apoptosis Signaling Pathways in CD/1 
Mice. PLoS ONE, vol. 8, issue 4, p. e60730. 
[31] Cao Y, Luo Z, Tao Z, et al. (2006). Analysis of the hearing of patients with obstructive 
sleep apnea-hypopnea syndrome. Journal of Clinical Otorhinolaryngology Head and 
Neck Surgery 1001-1781 Issue 1. 
[32] Sheu JJ, Wu CS, Lin HC, (2012). Association Between Obstructive Sleep Apnea and 
Sudden Sensorineural Hearing Loss. A Population-Based Case-Control Study. Arch 
Otolaryngol Head Neck Surg.; 138(1):55-59. 
[33] Dziewas R, Schilling M, Engel P, Boentert M, Hor H, Okegwo A, Lüdemann P, 
Ringelstein EB, Young P (2007) Treatment for obstructive sleep apnoea: effect on 
peripheral nerve function. J Neurol Neurosurg Psychiatr 78:295–297 
[34] Gross JB, Bachenberg KL, Benumof JL, (2006). Practice guidelines for the 
perioperative management of patients with obstructive sleep apnea: a report by the 

Association between Sensorineural Hearing Loss... 
 
317
American Society of Anesthesiologists Task Force on Perioperative Management of 
patients with obstructive sleep apnea. Anesthesiology;104:1081-93.  
[35] Chung F, Subramanyam R, Liao P, et al, (2012). High STOP-Bang score indicates a 
high probability of obstructive sleep apnoea. Br J Anaesth: 108(5):768-775. 
[36] Lattimore JL, Wilcox I, Skilton M, et al. (2006). Treatment of obstructive sleep apnoea 
leads to improved microvascular endothelial function in the systemic circulation. 
Thorax; 61:491–495.  
 


In: Encyclopedia of Audiology and Hearing Research 
ISBN: 978-1-53617-702-2 
Editors: Erno Larivaara and Senja Korhola 
© 2020 Nova Science Publishers, Inc. 
 
 
 
 
 
 
 
Chapter 26  
 
 
 
OCCUPATIONAL EXPOSURE TO  
OTOTOXIC CHEMICALS  
 
 
M. P. Gatto1, R. C. Bonanni1, G. Tranfo1,  
E. Strafella2, L. Santarelli2 and M. Gherardi1 
1INAIL, Department of Occupational and Environmental Medicine,  
Epidemiology and Hygiene, Monte Porzio Catone (RM), Italy 
2Marche Polytechnic University, PhD School,  
Safety and Health at the Workplace, Ancona, Italy 
 
 
ABSTRACT 
 
There is a growing awareness that a variety of different chemical substances can 
cause hearing damage in humans. The literature of the last decade on the effect of 
different chemical compounds on the human auditory system has been reviewed with 
reference to the exposure in the workplace. Scientific evidence has emerged that the 
exposure to styrene, p-xylene, solvent mixtures and lead may be a cause of hearing loss. 
For these substances the number of studies is relatively large and a variety of approaches 
have been undertaken to test their effect on the auditory system. For other chemical 
substances, for example certain metals such as mercury, cadmium and arsenic, and some 
neurotoxic pesticides, the available data indicate a possible ototoxic action, although in 
some cases only when in combination with noise. A number of critical aspects have been 
noticed: firstly, this review highlights the need to consider the possible synergistic effect 
of the interactions between different ototoxic agents, primarily the co-exposure to noise. 
These interactions are complex and difficult to predict, since synergistic, additive and 
sub-additive effects have to be contemplated. Then, the individual variability of exposed 
subjects, 
due 
to 
genetic 
differences, 
personal 
clinical 
histories, 
and 
occupational/environmental exposures cannot be disregarded. Finally, there are 
conceptual differences among the studies in the definition of hearing loss, which may 
partly account for the different prevalence values found in the examined documents. In 
conclusion, it is suggested to adopt the precautionary principle, while awaiting, on one 
hand, a stronger evidence on the ototoxicity of some classes of chemicals, particularly for 
exposures at low doses, and, on the other hand, new scientific studies on the effects of the 

M. P. Gatto, R. C. Bonanni, G. Tranfo et al. 
 
320
interaction between physical and chemical agents on the hearing loss that are a priority in 
future research needs. 
 
 
INTRODUCTION 
 
The problem of hearing loss, with the consequences resulting from this disease, is of 
great concern in the medical community. Deafness is one of the most widespread, costly and 
poorly understood disabilities in the world. According to the World Health Organization 
(WHO) about 250 million people have disabling hearing loss and two-thirds of them live in 
the developing world. Millions of people progressively lose their most important means of 
communication and became socially isolated, especially in the later years of their life (Gatto 
et al., 2013). Previous studies have shown that hearing deficits can also contribute to 
occupational injury, although most of these studies evaluated traumatic injury (Hétu et al., 
1995; Sprince et al., 2003; Choi et al., 2005). Even if age-related changes, noise exposure and 
head trauma are the most common causes of damage to cochlear hair cells, several other 
factors may also cause hearing loss. Since the early 1980s, indeed, some chemical agents 
have been investigated in order of their potential ototoxic properties in humans. An ototoxic 
substance is any chemical or mixture that may impair the structures and/or the function of the 
inner ear (auditory plus vestibular apparatus) and the connected neural pathways; those 
substances that instead impair hearing and balance by affecting mainly the central or 
peripheral nervous system are considered neurotoxic. Ototoxic agents are generally divided 
into two groups, occupational and non-occupational chemicals: this study focused on the first 
one, even if a brief mention about other xenobiotics that may affect the auditory system is 
essential. Drugs are considered the main non-occupational substances that may damage 
hearing: these include, for example, antibiotics, with a place of absolute importance for the 
aminoglycosides, diuretics, and salicylates, certain antineoplastics such as cisplatin and 
carboplatin, and anti-malarial medications. In addition, despite the presence of a considerable 
uncertainty, some lifestyle habits, such as cigarette smoking and alcohol consumption, are 
also believed to be ototoxic. The classes of compounds discussed in this chapter include 
organic solvents, metals, pesticides, and other chemicals, including polychlorinated biphenyls 
and asphyxiants, grouped in a separate class. 
 
 
ORGANIC SOLVENTS 
 
There is ample scientific evidence that the exposure to several solvents, either alone or in 
concert with noise exposure, has ototoxic effects. The aromatic solvents of the alkylbenzene 
family are the largest group among the solvents that have been found to affect the auditory 
system. Animal models have demonstrated that the relative ototoxicity may vary among the 
aromatic solvents (Gagnaire & Langlais, 2005). A tentative ranking of increasing ototoxocity 
for aromatic solvents could be proposed on the basis of cochlea morphological investigation 
and histological hair cell losses as: α-methylstyrene, trans-β-methylstyrene = toluene ≤ p-
xylene < n-propylbenzene < styrene = ethylbenzene < allylbenzene. No relationship between 
the degree of ototoxicity and the lipophilic properties of the ototoxic agents as expressed by 
the octanol/water partition coefficients was observed. However, correlations between some 

Occupational Exposure to Ototoxic Chemicals 
 
321
structural properties and ototoxicity were observed. A single side-chain on the aromatic ring, 
except with p-xylene, is essential for ototoxicity. The other aromatic solvents with two side-
chains were not ototoxic. When the saturated side-chain was branched (isopropylbenzene, 
isobutylbenzene, sec-butylbenzene, tert-butylbenzene), no ototoxicity was found. Also the 
saturation and the number of carbon atoms in the side-chain are of importance. The ototoxic 
potency increases when the length of the saturated side-chain extended from one carbon atom 
to two carbon atoms. Of the xylene isomers, p-xylene showed ototoxic effects whereas o-
xylene and m-xylene did not (Maguin et al., 2006). Moreover, branching of the unsaturated 
chain (α-methylstyrene and trans-β-methylstyrene) decreased the ototoxicity of styrene. 
Finally, some aliphatic solvents, such as n-hexane and n-heptane, as well as trichloroethylene 
and carbon disulphide, have effects on neurons in the central nervous system, and 
consequently are supposed to also affect the auditory system (Morata, 1989; Nylén et al., 
1994; Simonsen & Lund, 1995; Vyskocil et al., 2008a.b).  
 
 
Styrene  
 
Styrene is used in the production of plastics, rubber, and resins. Several occupational 
studies have been investigated the effects of styrene on the auditory system alone or in 
concert with noise. Reviewed papers were cross-sectional epidemiological studies or 
occupational health cohort studies. Exposure assessment was based on styrene measurements 
in the breathing zone, usually also supported by the biological monitoring of its urinary 
metabolites. In many studies, lifetime exposure to both styrene and noise was calculated using 
company records and questionnaire data. The results are equivocal. Some studies (Johnson et 
al., 2006; Mascagni et al., 2007; Morata et al., 2011; Sisto et al., 2013) claimed to have 
demonstrated styrene-induced hearing loss in industrial populations, also with synergism 
between styrene and noise, but others (Hoffmann et al., 2006; Triebig et al., 2009) have 
indicated no ototoxic effects of styrene exposure. Johnson et al. (2006) studied the health 
effects in 313 workers exposed to noise (> 85dBA) and styrene and to styrene alone (noise < 
85 dBA). Workers exposed to styrene alone or in combination with noise resulted to have 
significantly poorer pure-tone thresholds in the high-frequency range (3-8 kHz) than the 
control, noise-only exposed workers and non occupationally noise-exposed. In a smaller 
study, hearing thresholds of 32 workers in a fiberglass reinforced industry were compared to 
60 unexposed control subjects (Mascagni et al., 2007). Twenty-four of the exposed subjects 
had slightly but significantly higher thresholds at all frequencies (except at 8 kHz on the right 
ear). The study confirmed the results from earlier studies with larger population that styrene 
alone can cause a slightly elevated hearing threshold (Muijser et al., 1988; Morioka et al., 
1999; Sliwińska-Kowalska et al., 2003). Similar findings were reported by a large cross-
sectional study on styrene-exposed workers from Sweden, Finland, and Poland (Morata et al., 
2011). Among the important results obtained from this multicenter study, such as the 
corroboration of association between styrene exposure and hypoacusis, the authors observed 
that noise exposure from 80 to 84 dBA did not have a significant effect on hearing, except 
when in combination with styrene. In a recent study Sisto et al. (2013) evaluated the ototoxic 
effect of styrene by means of otoacoustic emissions, used as biomarkers of mild cochlear 
damage. The authors found a significant correlation between the otoacoustic emission levels 

M. P. Gatto, R. C. Bonanni, G. Tranfo et al. 
 
322
and the concentration of the styrene urinary metabolites. Besides, on a subsample of styrene 
exposed subjects with low exposure to noise and short exposure lifetime, cochlear 
functionality degradation has been evidenced, manifesting itself with a significant reduction 
of the otoacoustic signals. In contrast, other studies failed to find any effect of styrene on 
hearing thresholds. An investigation on 32 workers of a boat building factory found no 
consistent association and only few isolated correlations between the parameters of hearing 
acuity and exposure indices (Hoffmann et al., 2006). No clear ototoxic effects were also 
reported by Triebig et al. (2009). The study examined associations between occupational 
styrene exposure and impairment of hearing function of a group of workers from a boat 
building plant. With the exception at frequencies of 1,000 and 1,500 Hz, no dose-response 
relationship between threshold and exposure data was found. In conclusion, there is some 
suggestion of a likely ototoxic effect of styrene exposure, but hearing dysfunction deficits, in 
particular at low concentrations, have not been demonstrated by scientifically reliable 
argument. Further studies in humans are necessary to clarify this question. 
 
 
Toluene  
 
Toluene has a number of industrial uses as solvent, carrier, or thinner in the paint, rubber, 
printing, cosmetic, adhesives and resin industries, as a starting material for the synthesis of 
other chemicals and as a constituent of fuels. Information gained from animal studies support 
the observations in humans that toluene can be ototoxic (Pryor & Howd, 1986; Johnson et al., 
1988; Sullivan et al., 1989; Li et al., 1992) and demonstrate that toluene exposure can 
aggravate auditory degeneration in genetically predisposed mice. The data on the ototoxic 
effect of toluene in humans originate mainly from case reports of acute toluene poisoning. In 
studies focused on the voluntary inhalation of toluene, severe hearing loss in the central 
auditory pathways was reported (Ryback, 1992; Morata et al., 1994). Two studies on 
association between auditory damage and occupational exposure to toluene were identified in 
the literature of the last 10 years. Chang et al. (2006) described hearing impairment from 
simultaneous exposure to toluene and noise in 174 workers at an adhesive materials 
manufacturing plant. Diametrically opposite conclusions have been reached by Schaper et al. 
(2008). In a five year follow-up study, 333 rotogravure printers exposed to a relatively high 
level of toluene in the printing area were compared with those exposed to a low level of 
toluene in the end-processing area. No toluene exposure-related variables (duration, level, 
urine metabolites) were found to be significant in the logistic regression model. To sum up, 
toluene may be associated with hearing impairment when the exposure reaches a certain level 
(Chang et al., 2006); the risk effect may not be observed when the level is lower than 50 ppm 
(Schaper et al., 2008). However, more studies are needed to confirm these findings. 
 
 
Xylenes 
 
Xylenes are found in various solvent mixtures, including paints, varnishes, and thinners; 
they are also used in histology laboratories. Several studies have been compared the 
ototoxicity of three xylene isomers (Pryor et al., 1987; Cappaert et al., 1999, 2000; Campo et 

Occupational Exposure to Ototoxic Chemicals 
 
323
al., 2001; Gagnaire et al., 2001; Maguin et al., 2006). Unlike o-xylene and m-xylene, an 
ototoxic effect was observed after a sub chronic p-xylene exposure. 
In 2008, Draper & Bamiou presented a case-study of a patient with auditory neuropathy 
after exposure to xylene, and in the absence of any other risk factor. More recently, in a study 
on a group of 30 medical laboratory workers, Fuente et al. (2013) found significant different 
ABR latencies for xylene-exposed workers than non-exposed workers. 
 
 
Dichloromethane  
 
Dichloromethane is a widely used organic solvent in a diverse range of industries such as 
metals and plastics, electronics, pesticides and textiles. The effects of dichloromethane on the 
auditory system have been debated in a recent study conducted by Bonfiglioli et al. (2014). 
The authors reported the case of a transient bilateral hypoacusis after acute exposure to 
dichloromethane, suggesting a possible ototoxic effect of this solvent. 
 
 
Trichloroethylene  
 
Trichloroethylene is primarily used as a grease remover, but is also used as a dry-
cleaning agent and as a chemical intermediary in the production of paints, waxes, pesticides, 
and other products, such as adhesive and lubricants. 
In animal models, exposure to high concentrations of trichloroethylene has been shown to 
disrupt cochlear sensory hair and spiral ganglion cells, mainly in the middle turn, as well, i.e., 
the auditory nervous pathways within the cochlea (Prasher et al., 2004; Albee et al., 2006). In 
a review of the literature on the effects of low-level exposure to trichloroethylene on the 
auditory system, Vyskocil et al. (2008b) found no convincing scientific evidence of 
trichloroethylene-induced hearing losses in workers. No human study on the interaction 
between occupational trichloroethylene exposure and noise was found.  
 
 
Carbon Disulphide 
 
Despite the usage of carbon disulfide (CS2) is strictly controlled by legislation, because of 
its physico-chemical and toxicological properties, it is still widely used in various sectors 
such as in the textile industry for the production of rayon fibers and in industrial applications, 
mainly in tires and other reinforced rubber articles. Carbon disulphide is known to be a 
neurotoxicant and in some previous studies the effects on the auditory system in workers have 
been interpreted as a consequence of the known central nervous system (CNS) toxicity of the 
substance. 
Gelbke et al. (2009), in a review of literature on CS2 health effects, suggest that hearing 
deficits will only occur at relatively high carbon disulfide exposures, and there may be an 
interaction between CS2 exposure and ambient noise levels. The authors concluded that the 
studies with highest utility support that an Occupational Exposure Limits (OEL) of 10 ppm 
“may be low enough to protect workers from significant aggravated hearing impairment due 
to CS2 exposure in a noisy working condition” (Chang et al., 2003). However, the number of 

M. P. Gatto, R. C. Bonanni, G. Tranfo et al. 
 
324
investigations on electroencephalogram (EEG) alterations and especially on the audio-
vestibular system is too small to come to a final decision. Audiometric studies in workers 
under defined long-term exposure conditions would be helpful in this respect. 
 
 
Solvent Mixtures 
 
Several other organic solvents, such as ethylbenzene, n-hexane, methyl ethyl ketone 
(MEK), ethyl acetate, butyl acetate, have been hypothesized to impair hearing. These 
chemicals are rarely present separately in workplaces, but mostly as solvent mixtures. Over 
the recent literature, five occupational studies examining the relationship between solvent 
mixtures and hearing impairment have been identified. A variety of workplaces was 
investigated, including paint and lacquer industry, petroleum refineries, aviation industry, 
shipyards, and work environments exposed to jet fuel. Kim et al., (2005) studied hearing 
impairments as consequence of simultaneous exposure to noise and mixed solvents in the 
aviation industry. The major components in the solvent mixtures were methyl ethyl ketone, 
toluene, xylene, and methyl isobutyl ketone. The study found a prevalence of hearing loss of 
54.9% among workers exposed to noise and mixed solvents simultaneously; 17.1% among 
workers exposed only to noise; 27.8% among workers only exposed to a solvent mixture; and 
6% among non-exposed workers. Relative risks were estimated to be 4.3 for the noise-only 
group, 8.1 for the noise and solvents group, and 2.6 for the solvents mixture group. In a 
similar study conducted by Kaufman et al. (2005), the exposure to jet fuels, containing 
several solvents such as n-hexane, n-heptanes, toluene, and xylenes, was found to increase the 
odds ratio when it is combined with noise exposure during the first twelve years of exposure. 
The effects of jet fuel exposure on hearing were found statistically non-significant for more 
than 12 years of combined noise and jet fuel exposure, suggesting a plateau effect for jet fuel 
exposure and/or that the noise-induced hearing loss may become more important for those 
continuing to have exposure to both agents. In the last decade two studies on the association 
between hearing impairment and the exposure to solvent mixtures and noise were published 
by Sliwinska-Kowalska et al. In the first study (Sliwinska-Kowalska et al., 2004), the authors 
compared the hearing impairments of 701 dockyard workers (517 noise and organic solvent 
mixture exposed and 184 noise only exposed) with 205 control subjects not exposed to either 
noise or solvents. The odds ratio of hearing loss resulted significantly increased by about 
three times in the noise-only group and by almost five times in the noise and solvent group. In 
the second study (Sliwinska-Kowalska et al., 2005) hearing disabilities of 1117 workers 
exposed to both mixtures of solvents (xylene, styrene, n-hexane and toluene) and noise were 
confronted with 66 workers exposed to noise only and 157 controls. A positive linear 
relationship was found between exposure to solvents and hearing thresholds at high 
frequencies. All solvent exposures were found to be associated with hearing impairment, with 
the lowest odds ratios in the solvent-mixture-exposed group (xylene as the main component), 
and the highest in the n-hexane and toluene exposed group. The authors also indicated that 
additional deterioration of hearing at 8 kHz could be caused by co-exposure to solvents and 
noise. More recently, Fuente et al. (2011) conducted an investigation on central auditory 
functioning in normal hearing, solvent-exposed subjects (n=46) compared to normal-hearing, 
non-exposed subjects (n=46). Although all subjects had normal-hearing thresholds, solvent-
exposed participants exhibited significantly poorer hearing thresholds in comparison to non-

Occupational Exposure to Ototoxic Chemicals 
 
325
exposed subjects. Data were in agreement with results from a study conducted in 2007, in 
which Fuente et al. demonstrated that solvents were significantly associated with poorer pure-
tone thresholds, lower amplitudes of transient evoked otoacoustic emissions (TEOAEs), and 
poorer results for central auditory functioning tests.  
In summary, the literature data revealed the increased risk of hearing loss in workers 
exposed to organic solvent mixture only, and well documented the potentiating of harmful 
effects of combined exposure to solvents and noise. Hearing impairment is mainly observed 
in high frequencies, but lower frequencies can also be involved. Some studies have revealed 
that pure-tone audiometry might be insufficient to differentiate between noise and chemical 
ototoxic effects (Sliwinska-Kowalska et al., 2004; Fuente et al., 2008, 2011). Finally, it must 
be emphasized that current exposure limits for solvents, established separately for each single 
chemical, are probably not effective in hearing protection when they are mixed.  
 
Table 1. Occupational studies on auditory effects of solvents exposure 
 
Substance 
[CAS] 
Structure 
ACGIH TLV-TWA 
(STEL)* 
Industrial Uses 
Weight of 
evidence 
References 
Styrene 
[100-42-5] 
 
20 
(40) 
Fiberglass, rubber, 
plastic, insulation. 
 
O/PO 
Johnson et al., 2006; 
Hoffmann et al., 
2006; Mascagni et 
al., 2007; Triebig et 
al., 2009; Morata et 
al., 2011; Sisto et al., 
2013 
Toluene 
[108-88-3] 
20 
Solvent of paints, 
lacquers, thinners, 
glues and industrial 
feedstock 
O/PO 
Chang et al., 2006; 
Schaper et al., 2008  
 
p-xylene 
[106-42-3] 
 
100 
(150) 
Solvent in leather, 
rubber and printing 
industries 
O/PO 
Draper & Bamiou, 
2008; Fuente et al., 
2010  
 
Dichloromethane 
[75-09-2] 
 
50 
In paint removers, in 
manufacturing 
process of film 
coatings, as aerosol 
spray propellant.  
NC 
Bonfiglioli et al., 
2014 
Trichloroethylene 
[79-01-6] 
 
10 
(25) 
Degreaser in metal 
industry and in 
chemical laundries. 
NE 
Vyskocil et al., 2008 
Carbon Disulphide 
[75-15-0] 
 
 
1 
(3.1) 
Man-made cellulosic 
fibers, tires and other 
reinforced rubber 
articles.  
PO 
Gelbke et al., 2009 
Solvent mixtures 
 
Ethylbenzene, n-
hexane, carbon 
disulfide, methyl 
ethyl ketone 
(MEK), ethyl 
acetate, butyl 
acetate 
 
In dry cleaning, as 
paint thinners, and 
glue solvents 
O/PO 
Sliwinska-Kowalska 
et al., 2004, 2005; 
Kaufman et al., 
2005; Kim et al., 
2005; Fuente et al., 
2008, 2011 
CAS: Chemical Abstracts Service; TLV: Threshold Limit Value – TWA: time-weighted average; STEL: Short-Term 
Exposure Limit; O: ototoxic substance, PO: possibly ototoxic substance, NC: nonconclusive, NE: no evidence. 
*Values in Parts Per Million (ppm).  

M. P. Gatto, R. C. Bonanni, G. Tranfo et al. 
 
326
METALS 
 
In animal studies, metals such as lead, mercury, cadmium, and manganese are reported to 
impair inner ear cells, leading to auditory function disorders (Yamamura et al., 1989; Lasky et 
al., 1995; Ozcaglar et al., 2001; Jones et al., 2008; Kim et al., 2008). Human studies are 
sparse, but there are some data supporting their effect on auditory system (Chuang et al., 
2007; Shargorodsky et al., 2011; Choi et al., 2012; Saunders et al., 2013). The interaction 
with the noise has been poorly studied either in animals or in humans. Some of the ototoxic 
metals are discussed in the following section.  
 
 
Lead 
 
Lead can be found in various workplaces, such as constructions, wholesale trade, 
industries involved in the manufacture of ammunition, batteries, chemical compounds, 
explosives, glassware, and metal products. OSHA estimates that approximately 804,000 
workers in general industry and an additional 838,000 workers in construction are potentially 
exposed to lead. Experimental studies on animal models suggest that lead exposure induces 
degeneration in the inner ear receptor cells and latency in auditory nerve conduction velocity 
(Yamamura et al., 1989; Lasky et al., 1995). There are contradictory findings on hearing loss 
from human lead exposure. Several epidemiological studies on lead-exposed workers whose 
blood lead levels have been related to audiological findings, suggest a probable ototoxic 
effect for this metal (Chuang et al., 2007; Hwang et al., 2009; Galal et al., 2011). The study 
conducted by Galal et al. (2011) on a sample of 61 lead-exposed and 50 non-exposed found a 
significant correlation r=0.7 between blood lead levels and binaural hearing impairment. 
Similar results were observed on 412 workers exposed to low-level lead in a steel plant 
(Hwang, 2009). In addition of results on lead ototoxicity, Chuang et al., (2007) found that 
selenium was inversely associated with hearing thresholds, and it may be considered an 
antagonist to Pb ototoxicity. On the contrary, Counter et al., (2009) were unable to 
substantiate this in their study on a group of subjects with a history of chronic exposure from 
occupational Pb glazing. In the past it has also been suggested that lead exposure results in 
hearing loss may be due to developmental learning disabilities consequent to the exposure to 
the metal (Schwartz & Otto, 1991; Bellinger, 1995). However, given the current evidence 
from several human studies, we recommend treating lead as an ototoxic agent. 
 
 
Mercury (Methyl Mercury Chloride, Mercuric Sulfide) 
 
Occupational exposure to inhaled mercury vapor occurs in many industrial applications, 
including the production of caustic soda and chlorine, and in the manufacture of 
thermometers, thermostats, fluorescent light bulbs, batteries, and manometers. Since mercury 
is known to be neurotoxic, many studies have focused only on the central auditory system, 
whereas other studies have shown that acute or chronic exposure to mercury generates 
alterations in both the peripheral and/or central auditory systems (Murata et al., 2004; 
Rothwell & Boyd, 2008; Prasher, 2009). A recent cross sectional study was carried out by Al-
Betanony et al. (2013) on 138 workers and 151 matched controls in a fluorescent lamp factory 

Occupational Exposure to Ototoxic Chemicals 
 
327
in Egypt. The measured noise levels inside the factory were below the maximal permissible 
limit of the sound intensity inside closed working areas (90 dB according to the Egyptian 
low). Audiometric air conduction results showed a significantly higher prevalence of hearing 
loss in the exposed than the comparison group. Other mercury compounds such as dimethyl-
mercury, methyl-mercury, and mercuric sulfide have been shown to affect auditory brain stem 
potentials (Pazderová et al., 1974; Chuu et al., 2001; Clarkson & Magos, 2006). 
 
 
Cadmium 
 
Industrial use of cadmium mainly occurs in nickel-cadmium batteries, PVC plastics, and 
paint pigments. Cadmium has a dose-dependent deleterious effect on the auditory system in 
animal models, causing apoptosis and arrangement alteration of inner ear receptor cells 
leading to an elevation in auditory thresholds (Ozcaglar et al., 2001; Kim et al., 2008). A 
probable ototoxic action of cadmium in association with noise exposure was shown by De 
Abreu & Suzuki (2002), who observed more severe auditory damages, at the frequencies of 
4000 and 6000 Hz, in a group of workers exposed to noise and cadmium than in the subjects 
exposed only to noise.  
 
 
Chromium 
 
Chromium is used in the manufacturing of stainless steel and to produce several alloys, in 
plating, corrosion inhibition, wood preservatives, glassware-cleaning solutions, metal 
finishing and in the production of pigments. In a recent experimental study on animal models, 
Zhan et al. (2012) found auditory damages with flatness of auditory brain stem responses 
(ABR) in rats exposed to chromium. Besides, a protective effect of copper and manganese has 
been supposed, since it has been observed a certain restoration of the hearing function in rats. 
Regarding human occupational studies, the multiple exposures to a mixture of chromium and 
lead in combination with noise and their effects on the auditory system were examined by 
Muttamara & Leong (2004). Elevated concentrations of chromium and lead were found in 
biological matrices (blood and urine) of exposed workers, as well as high levels of noise, 
frequently higher than 90 dBA. According to the audiometric test, the workers showed signs 
of noise-induced hearing loss, but the effect of the co-exposure to the heavy metals cannot be 
excluded.  
 
 
Tin 
 
Organic tin compounds are used as heat stabilizers for polyvinyl chloride in piping, 
siding, and window casings, as antifouling marine paints, wood preservatives fungicides and 
acaricides. Structural alterations of the auditory system, such as losses or shortening of outer 
hair cells (OHC) in the basal turn of the cochlea and loss of type 1 spiral ganglion cells, have 
been reported in animal exposed to trimethyltin (Ruppert et al., 1984; Hoeffding & Fechter, 
1991) and triethyltin (Clerici et al., 1993). No study on the effect of occupational exposure to 
tin compounds on human auditory system has been found in the recent literature. 

M. P. Gatto, R. C. Bonanni, G. Tranfo et al. 
 
328
Arsenic  
 
Arsenic is used in the smelting process of copper, zinc, and lead, as well as in the 
manufacturing of chemicals and glass. Target organs are: blood, kidneys, and the central 
nervous, digestive, and skin systems. Animal studies of compounds containing arsenic 
(sodium arsenilate and its acetylated derivative) have shown histopathological changes in the 
organ of Corti and the stria vascularis (Anniko, 1976; Miller, 1985). Hearing loss, with 
particularly marked changes in low-frequency region, has been also reported in human 
exposed to arsenic pollution (Bencko & Symon, 1977). 
To summarize, although some studies show conflicting results, data seem to confirm 
previous observation of auditory toxicity in workers exposed to lead; and selenium was 
supposed to reduce its ototoxic effect. Mercury, as well as other compounds containing 
mercury, affects hearing, with central conduction time delay, but cochlear function may be 
unaffected. Cadmium causes dose-dependent loss of hearing in animal models; chromium is 
assumed to worsen the ototoxic action of noise and lead in humans. Studies on arsenic and tin 
exposures show structural alterations of the auditory system in animal models and low- and 
high-frequency loss with balance disturbance in humans. Finally, recent studies on cochlear 
organotypic cultures and animal models (Mao et al., 2011; Apostoli et al., 2013), have 
confirmed previous findings on the ototoxic properties of other metals, such as manganese 
and cobalt, which can be also exacerbated by noise exposure. 
 
Table 2. Studies on auditory effects in animals and workers exposed to metals 
 
Substance 
[CAS] 
ACGIH 
TLV-TWA 
(STEL)* 
Industrial uses 
Weight of evidence 
References 
Animal 
models 
Human 
studies 
Lead 
[7439-92-1] 
0.05 mg/m3 
Car batteries, soldering and 
electrodes in the process of 
electrolysis, cable covering, 
plumbing, glazing 
O 
O /PO 
Yamamura et al., 1989; 
Lasky et al., 1995; 
Chuang et al., 2007; 
Hwang, 2009; Galal et 
al., 2011; Counter et al., 
2009 
Mercury 
[7439-97-6] 
0.025 mg/m3 
Production of caustic soda and 
chlorine, manufacture of 
thermometers, thermostats, 
fluorescent light bulbs, batteries, 
and manometers 
O 
PO 
Murata et al., 2004; 
Rothwell & Boyd, 
2008; Prasher, 2009; 
Al-Betanony et al., 
2013 
Cadmium 
[7440-43-9] 
0.01 mg/m3 
Nickel-cadmium batteries, PVC 
plastics, paint pigments 
O 
PO 
Ozcaglar et al., 2001; 
De Abreu &Suzuki, 
2002; Kim et al., 2008  
Chromium 
[7440-47-3] 
0.5 mg/m3 
 
Stainless steel, plating, metal 
finishing, wood preservative, 
production of pigments 
O/PO 
PO 
Muttamara & Leong, 
2004; 
Zhan et al., 2012 
Tin 
[7440-31-5] 
2 mg/m3 
Stabilizer, antifouling marine 
plants 
PO 
NE 
Hoeffding & Fechter, 
1991;  
Clerici et al., 1993 
Arsenic 
[7440-38-2] 
0.01 mg/m3 
Smelting process, chemicals and 
glass manifacturing 
PO 
PO 
Anniko, 1976; Miller, 
1985 
CAS: Chemical Abstracts Service; TLV: Threshold Limit Value – TWA: time-weighted average; STEL: Short-Term 
Exposure Limit; O: ototoxic substance, PO: possibly ototoxic substance, NC: nonconclusive, NE: no evidence. 
 

Occupational Exposure to Ototoxic Chemicals 
 
329
PESTICIDES  
 
Several pesticides are expected to be neurotoxic to humans; consequently these 
compounds may also affect auditory system. In the following section two classes of potential 
neurotoxic pesticides are evaluated for their effects on auditory system in exposed workers: 
organophosphates (OPs) and pyrethroids. 
 
 
Organophosphates (OPs)  
 
OPs represent the largest class of insecticides sold worldwide. Hoshino et al. (2008) 
studied associations between hearing impairments and chronic exposure to OPs at low doses 
on a cohort of 18 Brazilian rural workers. Audiometric tests found that 7 exposed (38.8%) 
had altered results, 4 of them (22.22%) with decreased performances at high frequencies and 
the remaining 3 subjects (16.67%) with sensorineural hearing loss. Besides, the authors 
observed associations between time of exposure and test results. The combined effect of noise 
and OPs on auditory systems was investigated by Guida et al. (2010). Two groups of 40 
individuals each, exposed to malathion and noise (group I) and to noise only (group II) were 
considered. Both groups showed similar hearing loss values in the high frequencies, but at 
frequencies of 3 kHz (left ear) and 4 KHz (bilaterally) significant differences were found, 
with a worsening of thresholds for group I. As the more pronounced hearing loss was found 
in individuals exposed to both elements, it is conceivable a possible interaction between noise 
and OPs. Similar findings were observed on 43 rural workers exposed to OPs by Camarinha 
et al. (2011). A high percentage of subjects (83.7%) resulted with worse than expected 
responses and the results were consistent for all three tests performed – Frequency Pattern 
Test (FTP), Duration Pattern Test (DPT) and Gaps-in-noise (GIN) test. 
 
 
Pyrethroids 
 
Pyrethroids are modern insecticides, in most cases more neurotoxic to insects and less 
neurotoxic to humans than organophosphates. Two types of pyrethroid structures exist: type 
II contain a cyano-group in the α-position, whereas type I do not contain a cyano-group 
(Bradberry et al., 2005). Human pyrethroid poisoning is rare, and almost entirely involves 
type II. The ototoxic effects of the exposure to a mixture containing pyrethroids and OPs have 
been investigated by a large study among 14,229 subjects (Crawford et al., 2008). The authors 
found some evidence that pesticide exposures, including poisoning and medical treatment 
after high exposure events, could increase the incidence of self-reported hearing loss. In 
particular, the odds ratio for the highest quartile of exposure was 1.19 (95% CI 1.04-1.35) for 
insecticides and 1.17 (95% CI 1.04-1.35) for OPs. On the contrary, carbamates, 
organochlorines and pyrethroids resulted not associated with hearing loss.  
In two different studies, published in 2000 and 2004 respectively, Beckett et al. obtained 
conflicting results. In the first study (Beckett et al., 2000) a statistically significant association 
(p<0.05) was found between hearing loss and pesticide mixture exposure (mainly OPs and 
pyrethroids) of 185 farm workers. Furthermore, the exposed group presented a higher 

M. P. Gatto, R. C. Bonanni, G. Tranfo et al. 
 
330
incidence (3%) of auditory damages compared to controls. Contrary to these previous 
findings, the authors found no significant association between pesticide exposure and hearing 
loss in their further 5-year follow-up study (Beckett et al., 2004). Possible biases, such as the 
smaller sample size (n=65) than the previous study (n=185), the non-random selection of 
participating subjects, and the exposure estimation based on recall, might have jeopardized 
the results of this second survey.  
The literature linking pesticide exposure to hearing loss is sparse. Results from recent 
studies suggest that occupational exposure to some pesticides can induce damage to the 
central auditory system. Nevertheless, no meaningful conclusions can be drawn, also 
considering a number of deficiencies of some of the examined studies, such as the lack of 
detailed information on the level of the exposures. No evidence on the potentiation of noise-
induced auditory impairments can be supported. Finally, since many pesticide formulations 
include solvents, metals, and other so-called inert ingredients, it is possible that these 
exposures can play a role in the association between hearing loss and pesticide exposure. 
 
 
OTHER CHEMICALS 
 
There is growing evidence that other chemicals, such as polychlorinated biphenyls 
(PCBs) and asphyxiants, produce oxidative stress in the cochlea and consequently may have 
ototoxic potential by themselves and can potentiate noise-induced hearing loss as well 
(Fechter et al., 2002a.b, 2003; Morata, 2003; Pouyatos et al., 2005, 2007). Occupational 
exposure to asphyxiant gases is mainly a result of accidental events; therefore, in this section 
we will analyze the effects on the auditory system of the only carbon monoxide (CO), for 
which a chronic occupational exposure cannot be excluded.  
 
Table 3. Epidemiological studies on ototoxic action of occupational exposure  
to pesticides 
 
Pesticide 
class 
Exposed  
Controls 
Noise 
Auditory test 
Weight of 
evidence 
Reference 
OPs 
n = 18 
- 
NR 
Audiometry, VENG, 
three questionnaires 
PO 
Hoshino et al., 2008 
n = 40 
 
n = 40 
98.5 dB(A) 
Audiometry, 
interview, acoustic-
immittance measures 
PO 
Guida et al., 2010 
n = 48 
- 
NR 
Audiometry, FTP, 
DPT and GIN, 
questionnaire 
PO 
Camarinha et al., 
2011 
n = 18 
- 
NR 
Audiometry, VENG, 
three questionnaires 
PO 
Hoshino et al., 2008 
Pyrethroids 
and OPs 
65 
- 
76.4÷93dB(A) 
Self-reported 
interview 
NE 
Beckett et al., 2004 
n = 4926 
 
n = 9303 
YES 
Self-reported 
interview 
PO 
Crawford et al., 
2008 
n, number of subjects; NR, not reported; VENG, Vector Electronystagmography; FTP, Frequency 
Pattern Test; DPT, Duration Pattern Test; GIN, Gaps-in-noise; PO: possibly ototoxic substance, 
NE: no evidence. 
 

Occupational Exposure to Ototoxic Chemicals 
 
331
Polychlorinated Biphenyls (PCBs) 
 
Polychlorinated biphenyls (PCBs) consist of 209 synthetic organic compounds, called 
“congeners,” in which 1 to 10 chlorine atoms are attached to a biphenyl ring. Occupational 
exposure to PCBs can take place during the renovating and demolishing of buildings, repair 
and maintenance of PCB transformers, accidents, fires, or spills involving PCB transformers 
and older computers and instruments, and disposal of PCB materials. Rodent studies provided 
the first evidence for auditory deficits after developmental PCBs exposure. Perinatal exposure 
to a commercial PCB mixture, Aroclor 1254 (A1254), resulted in long-lasting low-frequency 
hearing loss (Goldey et al., 1995). The cochlea was specifically indicated as the likely site of 
action in a study that found loss of outer hair cells in perinatally PCB-exposed rats (Crofton et 
al., 2000). The effects of developmental exposure to PCBs on cochlear function seem to be 
confirmed also by cross-sectional epidemiological studies on children (Longnecker et al., 
2004; Trnovec et al., 2008; Newman et al., 2009; Boucher et al., 2010). No current 
occupational studies were identified. 
 
 
Carbon Monoxide (CO) 
 
CO is generated by incomplete combustion of any carbon-containing fuel or materials in 
machines or fire accidents. Occupational exposure to CO, often in combination with noise, 
notably concerns firemen (Treitman et al., 1980; Lees, 1995; Melius, 2001; Fechter et al., 
2002), as well as car mechanics, traffic police and parking lot attendants, bus drivers, truck 
drivers and taxi drivers (Steenland, 1996; Wickramatillake et al., 1998; Morley et al., 1999; 
Fechter et al., 2002), motor sport athletes (Walker et al., 2001), service stations workers 
(Kamei & Yanagisawa, 1997; Herbert et al., 2001), industrial cooks. Studies on animal 
models have demonstrated the ototoxic action of carbon monoxide and the potentiation of 
noise-induced hearing loss by CO. The auditory dysfunction produced by carbon monoxide is 
frequency-specific, as the basal high frequency region of the cochlea is more vulnerable to its 
effect (Tawackoli et al., 2001). Over the human auditory system, the negative effects of CO 
exposure have been described mainly after acute exposures to CO (Mehrparvar et al., 2013; 
Berent et al., 2005; Razzaq et al., 2010). These studies confirm a potential ototoxic action of 
CO on human auditory system, but did not control or report exposure to noise as a contributor 
to the observed hearing deficits. The only recent study on the effect of chronic exposure to 
low level of carbon monoxide in a noisy work environment has been published by Lacerda et 
al. (2005). The authors analyzed a database with 8647 hearing exams realized by the Quebec 
National Institute of Public Health between 1983 and 1996. The results demonstrated 
significant differences (p<0.001) in the auditory thresholds of groups I, composed by subjects 
exposed to CO and noise (90dBA) and group II, exposed only to noise (90dBA), especially 
for high frequencies (3, 4 and 6 kHz). These findings in humans and the available evidence on 
animal models indicate the need for further research on the effects of CO exposure to the 
auditory system, particularly in populations exposed simultaneously to CO and noise in the 
workplace (WHO, 1994; Morata et al., 2002). 
 
 

M. P. Gatto, R. C. Bonanni, G. Tranfo et al. 
 
332
CONCLUSION 
 
Recent studies have brought attention to the occupational exposure assessment to 
ototoxic chemicals. Given the growing complexity of the workplace environment, where 
various ototoxic agents can be simultaneously present, a clear relationship between chemicals 
and hearing impairment is difficult to assess with epidemiological studies. Quite often, in fact, 
workers were exposed to various substances that can interact in a synergistic, additive and 
sub-additive way, highlighting the need to develop further studies, which can provide a better 
understanding of the dose-effect relationship. The findings over the literature of the last 
decade suggest that chemicals such as solvents, metals and pesticides may have ototoxic 
properties. In particular, human studies in workers exposed to solvents including styrene, 
toluene, p-xylene, have shown a higher prevalence of hearing loss among solvent-exposed 
workers when compared with unexposed controls. It is a concern that, in some studies, 
increased risk of hearing loss was found at exposure concentrations of toluene and styrene 
lower than the recommended exposure limits. Furthermore, studies carried out in both animal 
models and human subjects exposed to metals, such as lead, mercury, chromium and 
cadmium, indicate that these chemicals may result in auditory dysfunction. There are 
indications that also other organic pollutants, such as pesticides and PCBs, are associated with 
poorer hearing thresholds of the exposed population, which consists not only of workers but 
also of particularly vulnerable subjects, such as children and pregnant women.  
A concomitant agent very often present in many workplaces is noise exposure. 
Epidemiological studies report conflicting data, but in some cases indicate a conceivable 
interaction between chemicals and noise, at least for high exposure levels. No meaningful 
conclusions, however, can be drawn, also considering a number of uncertainties of these 
studies, including the lack of detailed information on levels and modalities of the exposure 
and the deficiency of comparable exposure between groups. Furthermore, in most of these 
studies, the chronic effects were related to chemical concentrations and noise levels measured 
at the time of the study, which in some cases could result different than those ascertained in 
past years. While awaiting more evidence for dose-response assessments, for precautionary 
action, work exposure standards cannot rule out a likely relationship between solvent 
exposure and hearing impairments. In conclusion, it is believed useful to report the following 
recommendations as a general guideline for industrial hygienists: 
 
 
Risk management measures aimed at reducing exposure to ototoxic substances 
should be encouraged. 
 
For workers co-exposed to noise and ototoxic substances a more frequent health 
surveillance should be considered, regardless of the level of exposure to noise.  
 
Appropriate tools should be developed for early diagnosis of chemically induced 
hearing impairment. Otoacoustic emissions tests could be a valuable complement 
to pure tone audiometry. 
 
In workplaces characterized by simultaneous exposure to noise and ototoxic 
substances, on the basis of the precautionary principle, the use of personal 
protective equipment by the noise from exposure levels greater than 80 dB (A) 
should be recommended. 

Occupational Exposure to Ototoxic Chemicals 
 
333
 
Finally, training and information of workers should highlight the risk of possible 
synergistic effect of exposure to chemicals ototoxic and noise. 
 
 
REFERENCES 
 
Al-Batanony, M.A.; Abdel-Rasul, G.M.; Abu-Salem, M.A; Al-Dalatony M.M.; Allam, H.K. 
(2013). Occupational exposure to mercury among workers in a fluorescent lamp factory, 
Quisna industrial zone, Egypt. Int. J. Occup. Environ. Med., 4, 149-156. 
Albee, R.R.; Spencer, P.J.; Johnson, K.A.; Bradley, G.J.; Marable, B.R.; Wilmer, J.W.; 
Mattsson, J.L. (2006). Lack of trigeminal nerve toxicity in rats exposed to 
trichloroethylene vapor for 13 weeks. Int. J. Toxicol., 25, 531-540. 
Anniko, M. (1976). The cytochochleogram in atoxyl-treated guinea pigs. Acta Otolaryngol., 
82 (1-2), 70-81. 
Apostoli, P.; Catalani, S.; Zaghini, A.; Mariotti, A.; Poliani, P.L.; Vielmi, V.; Semeraro, F.; 
Duse, S.; Porzionato, A.; Macchi, V.; Padovani, A.; Rizzetti, M.C.; De Caro, R. (2013). 
High doses of cobalt induce optic and auditory neuropathy. Exp. Toxicol. Pathol., 65 (6), 
719-727. 
Beckett, W.S.; Chamberlain, D.; Hallman, E.; May, J.; Hwang, S.A.; Gomez, M.; Eberly, S.; 
Cox, C.; Stark, A. (2000). Hearing conservation for farmers: source apportionment of 
occupational and environmental factors contributing to hearing loss. J. Occup. Environ. 
Med., 42, 806- 813. 
Beckett, W.S.; Hallman, E.; May, J.; Hwang, S.A.; Gomez, M.; Eberly, S.; Cox, C. (2004). 
Follow-up to farm family health and hazard survey. J. Occup. Environ. Med., 46, 314-
315. 
Bellinger, D.C. (1995). Interpreting the literature on lead and child development: the 
neglected role of the “experimental system”. Neurotoxicol. Teratol., 17, 201-212.  
Bencko, V.; Symon. K. (1977). Test of environmental exposure to arsenic and hearing 
changes in exposed children. Environ. Health Perspect., 19, 95–101.  
Berent, A.C.; Todd, J.; Sergeeff, J.; Powell, L.L. (2005). Carbon monoxide toxicity: A case 
series. J. Vet. Emerg. Crit. Care, 15 (2), 128-135. 
Bonfiglioli, R.; Carnevali, L.; Di Lello, M.; Violante, F.S. (2014). Bilateral hearing loss after 
dichloromethane poisoning: A case report. Am. J. Ind. Med., 57 (2), 254-257. 
Boucher, O.; Bastien, C.H.; Saint-Amour, D.; Dewailly, T.; Ayotte, P.; Jacobson, J.L.; 
Muckle, G. (2010). Prenatal exposure to methylmercury and PCBs affects distinct stages 
of information processing: An event-related potential study with inuit children. 
Neurotoxicology, 31 (4), 373-384. 
Bradberry, S.M.; Cage, S.A.; Proudfoot, A.T.; Vale, J.A. (2005). Poisoning due to 
pyrethroids. Toxicol. Rev., 24, 93-106.  
Camarinha, C.R.; Frota, S.M.; Pacheco-Ferreira, H.; Lima, M.A. (2011). Auditory temporal 
processing assessment in rural workers exposed to organophosphate pesticides. J. Soc. 
Bras. Fonoaudiol., 23 (2), 102-106. 
Campo, P.; Lataye, R.; Loquet, G.; Bonnet, P. (2001). Styrene-induced hearing loss: a 
membrane insult, Hear. Res., 154, 170-180. 

M. P. Gatto, R. C. Bonanni, G. Tranfo et al. 
 
334
Cappaert, N.L.; Klis, S.F.; Baretta, A.B.; Muijser, H.; Smoorenburg, G.F. (2000). Ethyl 
benzene-induced ototoxicity in rats: a dose-dependent mid-frequency hearing loss. J. 
Assoc. Res. Otolaryngol., 1, 292-299. 
Cappaert, N.L.; Klis, S.F.; Muijser, H.; de Groot, J.C.; Kulig, B.M.; Smoorenburg, G.F. 
(1999). The ototoxic effects of ethyl benzene in rats’, Hear. Res., 137 (1-2), 91-102. 
Chang, S.J.; Shih, T.S.; Chou, T.C.; Chen, C.J.; Chang, H.Y.; Sung, F.C. (2003). Hearing loss 
in workers exposed to carbon disulfide and noise. Environ. Health. Perspect.,111,1620-
1624. 
Chang, S.J.; Chen, C.J.; Lien, C.H.; Sung, F.C. (2006). Hearing loss in workers exposed to 
toluene and noise. Environ. Health. Perspect., 114,1283-1286. 
Choi, S.W.; Peek-Asa, C.; Sprince, N.L.; Rautiainen, R.H.; Donham, K.J.; Flamme, G.A.; 
Whitten, P.S.; Zwerling, C. (2005). Hearing loss as a risk factor for agricultural injuries. 
Am. J. Ind. Med., 48 (4), 293-301.  
Choi, Y.H.; Hu, H.; Mukherjee, B.; Miller, J.; Park, S.K. (2012). Environmental cadmium 
and lead exposures and hearing loss in U.S. adults: the National Health and Nutrition 
Examination Survey, 1999 to 2004. Environ. Health Perspect., 120 (11), 1544-1550.  
Chuu, J.J.; Hsu, C.J.; Lin-Shiau, S.Y. (2001). Abnormal auditory brainstem responses for 
mice treated with mercurial compounds: involvement of excessive nitric oxide. 
Toxicology, 162 (1), 11-22.  
Clarkson, T.W.; Magos, L. (2006). The toxicology of mercury and its chemical compounds. 
Crit. Rev. Toxicol., 36 (8), 609-662.  
Clerici, W.J.; Chertoff, M.E.; Brownell, W.E.; Fechter, L.D. (1993). In vitro organotin 
administration alters guinea pig cochlear outer hair cell shape and viability. Toxicol. 
Appl. Pharmacol., 120 (2), 193-202.  
Counter, S.A.; Buchanan, L.H.; Ortega, F. (2009). Neurophysiologic and neurocognitive case 
profiles of Andean patients with chronic environmental lead poisoning. J. Toxicol. 
Environ. Health A, 72 (19), 1150-1159.  
Crawford, J.M.; Hoppin, J.A.; Alavanja, M.C.; Blair, A.; Sandler, D.P.; Kamel, F. (2008). 
Hearing loss among licensed pesticide applicators in the agricultural health study. J. 
Occup. Environ. Med., 50 (7), 817-826.  
de Abreu, M.T.; Suzuki, F.A. (2002) Audiometric evaluation of workers exposed to noise and 
cadmium. Rev. Bras. Otorinolaringol, 68 (4), 488-494. 
Draper, T.H.J.; Bamiou, D.E. (2009). Auditory neuropathy in a patient exposed to xylene: 
case report. J. Laryngol. Otol., 123, 462-465.  
Fechter, L.D.; Chen, G.D.; Rao, D. (2002a). Chemical Asphyxiants and Noise. Noise Health., 
4 (14), 49-61.  
Fechter, L.D.; Chen, G.D.; Johnson, D.L. (2002b). Potentiation of noise-induced hearing loss 
by low concentrations of hydrogen cyanide in rats. Toxicol. Sci., 66 (1), 131-138.  
Fechter, L.D.; Klis, S.F.; Shirwany, N.A.; Moore, T.G.; Rao, D.B. (2003). Acrylonitrile 
produces transient cochlear function loss and potentiates permanent noise-induced 
hearing loss. Toxicol.Sci., 75 (1), 117-123.  
Fuente, A.; McPherson, B. (2007). Central auditory processing effects induced by solvent 
exposure. Int.J.Occup.Med.Environ.Health, 20 (3), 271-279.  
Fuente, A.; McPherson, B.; Cardemil, F. (2013). Xylene-induced auditory dysfunction in 
humans. Ear Hear., 34 (5), 651-660.  

Occupational Exposure to Ototoxic Chemicals 
 
335
Fuente, A.; McPherson, B.; Hickson, L. (2011). Central auditory dysfunction associated with 
exposure to a mixture of solvents. Int.J.Audiol., 50 (12), 857-865.  
Gagnaire, F.; Langlais, C. (2005). Relative ototoxicity of 21 aromatic solvents. Arch.Toxicol., 
79 (6), 346-354.  
Gagnaire, F.; Marignac, B.; Langlais, C.; Bonnet, P. (2001). Ototoxicity in rats exposed to 
ortho-, meta- and para-xylene vapours for 13 weeks. Pharmacol.Toxicol., 89 (1), 6-14.  
Galal, S.; El-Samra, G.H.; Mazhar, M.; El-Kholy, F.; Hegazy, A. (2011). Risk Behaviour of 
lead-exposed Workers and Hearing Impairment. Int. J. Collab. Res. Internal Med. Public 
Health, 3 (2), 132-142.  
Gatto, M.P.; Fioretti, M.; Fabrizi, G.; Gherardi, M.; Strafella, E.; Santarelli, L. (2014). Effects 
of potential neurotoxic pesticides on hearing loss: a review. Neurotoxicology, 42, 24-32.  
Gelbke, H.P.; Goen, T.; Maurer, M.; Sulsky, S.I. (2009). A review of health effects of carbon 
disulfide in viscose industry and a proposal for an occupational exposure limit. 
Crit.Rev.Toxicol., 39 Suppl 2, 1-126.  
Goldey, E.S.; Kehn, L.S.; Lau, C.; Rehnberg, G.L.; Crofton, K.M. (1995). Developmental 
exposure to polychlorinated biphenyls (Aroclor 1254) reduces circulating thyroid 
hormone concentrations and causes hearing deficits in rats. Toxicol.Appl.Pharmacol., 135 
(1), 77-88.  
Guida, H.L.; Morini, R.G.; Cardoso, A.C. (2010). Audiological evaluation in workers 
exposed to noise and pesticide. Braz J.Otorhinolaryngol., 76 (4), 423-427.  
Herbert, R.; Szeinuk, J.; O'brien, S. (2001).Occupational health problems of bridge and tunnel 
officers. Occup. Med-State Art, 16 (1), 51-65. 
Hetu, R.; Getty, L.; Quoc, H.T. (1995). Impact of occupational hearing loss on the lives of 
workers. Occup. Med., 10 (3), 495-512.  
Hoeffding, V.; Fechter, L.D. (1991). Trimethyltin disrupts auditory function and cochlear 
morphology in pigmented rats. Neurotoxicol. Teratol., 13 (2), 135-145.  
Hoffmann, J.; Ihrig, A.; Hoth, S.; Triebig, G. (2006). Field study to explore possible effects of 
styrene on auditory function in exposed workers. Ind. Health, 44 (2), 283-286.  
Hoshino, A.C.; Pacheco-Ferreira, H.; Taguchi, C.K.; Tomita, S.; Miranda Mde, F. (2008). 
Ototoxicity study in workers exposed to organophosphate. Braz. J. Otorhinolaryngol., 74 
(6), 912-918.  
Hwang, S.A.; Gomez, M.I.; Sobotova, L.; Stark, A.D.; May, J.J.; Hallman, E.M. (2001). 
Predictors of hearing loss in New York farmers. Am. J. Ind. Med., 40 (1), 23-31.  
Johnson, A.C.; Juntunen, L.; Nylen, P.; Borg, E.; Hoglund, G. (1988). Effect of interaction 
between noise and toluene on auditory function in the rat. Acta Otolaryngol., 105 (1-2), 
56-63.  
Johnson, A.C.; Morata, T.C.; Lindblad, A.C.; Nylen, P.R.; Svensson, E.B.; Krieg, E.; 
Aksentijevic, A.; Prasher, D. (2006). Audiological findings in workers exposed to styrene 
alone or in concert with noise. Noise Health., 8 (30), 45-57.  
Jones, L.G.; Prins, J.; Park, S.; Walton, J.P.; Luebke, A.E.; Lurie, D.I. (2008). Lead exposure 
during development results in increased neurofilament phosphorylation, neuritic beading, 
and temporal processing deficits within the murine auditory brainstem. J. Comp. Neurol., 
506 (6), 1003-1017.  
Kamei, M.; Yanagisawa, Y. (1997). Estimation of CO exposure of road construction workers 
in tunnel. Ind. Health, 35 (1), 119-125.  

M. P. Gatto, R. C. Bonanni, G. Tranfo et al. 
 
336
Kaufman, L.R.; LeMasters, G.K.; Olsen, D.M.; Succop, P. (2005). Effects of concurrent noise 
and jet fuel exposure on hearing loss. J. Occup. Environ. Med., 47 (3), 212-218.  
Kim, J.; Park, H.; Ha, E.; Jung, T.; Paik, N.; Yang, S. (2005). Combined effects of noise and 
mixed solvents exposure on the hearing function among workers in the aviation industry. 
Ind. Health, 43 (3), 567-573.  
Kim, S.J.; Jeong, H.J.; Myung, N.Y.; Kim, M.C.; Lee, J.H.; So, H.S.; Park, R.K.; Kim, H.M.; 
Um, J.Y.; Hong, S.H. (2008). The protective mechanism of antioxidants in cadmium-
induced ototoxicity in vitro and in vivo. Environ. Health Perspect., 116 (7), 854-862.  
Lacerda, A.; Leroux, T.; Gagn, J.P. (2005). The combined effect of noise and carbon 
monoxide on hearing thresholds of exposed workers. J. Acoust. Soc. Am., 117 (4), 2481-
2481. 
Lasky, R.E.; Maier, M.M.; Snodgrass, E.B.; Hecox, K.E.; Laughlin, N.K. (1995). The effects 
of lead on otoacoustic emissions and auditory evoked potentials in monkeys. 
Neurotoxicol. Teratol., 17 (6), 633-644.  
Lees, P.S. (1995). Combustion products and other firefighter exposures. Occup. Med., 10 (4), 
691-706.  
Li, H.S.; Johnson, A.C.; Borg, E.; Hoglund, G. (1992). Auditory degeneration after exposure 
to toluene in two genotypes of mice. Arch. Toxicol., 66 (6), 382-386.  
Maguin, K.; Lataye, R.; Campo, P.; Cossec, B.; Burgart, M.; Waniusiow, D. (2006). 
Ototoxicity of the three xylene isomers in the rat. Neurotoxicol. Teratol., 28 (6), 648-656.  
Mao, X.; Wong, A.A.; Crawford, R.W. (2011). Cobalt toxicity--an emerging clinical problem 
in patients with metal-on-metal hip prostheses? Med. J. Aust., 194 (12), 649-651.  
Mascagni, P.; Formenti, C.; Pettazzoni, M.; Feltrin, G.; Toffoletto, F. (2007). Hearing 
function and solvent exposure: study of a worker population exposed to styrene. G. Ital. 
Med. Lav. Ergon., 29 (3 Suppl), 277-279.  
Mehrparvar, A.H.; Davari, M.H.; Mollasadeghi, A.; Vahidi, M.R.; Mostaghaci, M.; Bahaloo, 
M.; Shokouh, P. (2013). Hearing Loss due to Carbon Monoxide Poisoning. Case Rep. 
Otolaryngol., 2013, 940187.  
Melius, J. (2001). Occupational health for firefighters. Occup. Med., 16 (1), 101-108.  
Miller, J.J. (1985). Handbook of ototoxicity, CRC Press, Boca Raton.  
Morata, T.C. (2003). Chemical exposure as a risk factor for hearing loss. J. Occup. Environ. 
Med., 45 (7), 676-682.  
Morata, T.C. (1989). Study of the effects of simultaneous exposure to noise and carbon 
disulfide on workers' hearing. Scand. Audiol., 18 (1), 53-58.  
Morata, T.C.; Dunn, D.E.; Sieber, W.K. (1994). Occupational exposure to noise and ototoxic 
organic solvents. Arch. Environ. Health, 49, 359–365.  
Morata, T.C.; Johnson, A.C.; Nylen, P.; Svensson, E.B.; Cheng, J.; Krieg, E.F.; Lindblad, 
A.C.; Ernstgard, L.; Franks, J. (2002). Audiometric findings in workers exposed to low 
levels of styrene and noise. J. Occup. Environ. Med., 44 (9), 806-814. 
Morata, T.C.; Sliwinska-Kowalska, M.; Johnson, A.C.; Starck, J.; Pawlas, K.; Zamyslowska-
Szmytke, E.; Nylen, P.; Toppila, E.; Krieg, E.; Pawlas, N.; Prasher, D. (2011). A 
multicenter study on the audiometric findings of styrene-exposed workers. Int. J. Audiol., 
50 (10), 652-660. 
Morioka, I.; Kuroda, M.; Miyashita, K.; Takeda, S. (1999). Evaluation of organic solvent 
ototoxicity by the upper limit of hearing. Arch. Environ. Health, 54 (5), 341–346. 

Occupational Exposure to Ototoxic Chemicals 
 
337
Morley, J.C.; Seitz, T.; Tubbs, R. (1999). Carbon monoxide and noise exposure at a monster 
truch and motocross show. Appl. Occup. Environ. Hyg., 14 (10), 645-655. 
Muijser, H.; Hoogendijk, E.M.; Hooisma, J. (1988). The effects of occupational exposure to 
styrene on high-frequency hearing thresholds. Toxicology, 49 (2-3), 331-340. 
Murata, K.; Weihe, P.; Budtz-Jorgensen, E.; Jorgensen, P.J.; Grandjean, P. (2004). Delayed 
brainstem auditory evoked potential latencies in 14-year-old children exposed to 
methylmercury. J. Pediatr., 144 (2), 177-183. 
Muttamara, S; Leong, S.T. (2004). Health implication among occupational exposed workers 
in a chromium alloy factory, Thailand. J. Environ. Sci. (China),16 (2),181-186. 
Newman, J.; Gallo, M.V.; Schell, L.M.; DeCaprio, A.P.; Denham, M.; Deane, G.D.; 
Akwesasne Task Force on Environment (2009). Analysis of PCB congeners related to 
cognitive functioning in adolescents. Neurotoxicology, 30 (4), 686-696. 
Nylen, P.; Hagman, M.; Johnson, A.C. (1994). Function of the auditory and visual systems, 
and of peripheral nerve, in rats after long-term combined exposure to n-hexane and 
methylated benzene derivatives. I. Toluene. Pharmacol. Toxicol., 74 (2), 116-123. 
Ozcaglar, H.U.; Agirdir, B.; Dinc, O.; Turhan, M.; Kilincarslan, S.; Oner, G. (2001). Effects 
of cadmium on the hearing system. Acta Otolaryngol., 121 (3), 393-397. 
Pazderova, J.; Jirasek, A.; Mraz, M.; Pechan, J. (1974). Post-mortem findings and clinical 
signs of dimethyl mercury poisoning in man. Int. Arch. Arbeitsmed., 33 (4), 323-328. 
Pouyatos, B.; Gearhart, C.A.; Fechter, L.D. (2005). Acrylonitrile potentiates hearing loss and 
cochlear damage induced by moderate noise exposure in rats. Toxicol. Appl. Pharm., 204 
(1); 46-56.  
Pouyatos, B.; Gearhart, C.; Nelson-Miller, A.; Fulton, S.; Fechter, L. (2007). Oxidative stress 
pathways in the potentiation of noise-induced hearing loss by acrylonitrile. Hear. Res., 
224 (1-2), 61-74. 
Prasher, D. (2009). Heavy metals and noise exposure: Health effects. Noise Health, 11 (44), 
141-144. 
Prasher, D.; Morata, T; Campo, P.; Fechter, L.; Johnson, A.C.; Lund, S.P.; Pawlas, K.; 
Starck, J.; Sliwinska-Kowalska, M.; Sulkowski, W. (2002). NoiseChem: An European 
Commission research project on the effects of exposure to noise and industrial chemicals 
on hearing and balance. Noise Health, 4, 41-48. 
Pryor, G.T.; Howd, R.A. (1986). Toluene-induced ototoxicity by subcutaneous 
administration. Neurobeh. Toxicol. Ter., 8, 103–104. 
Pryor, G.T.; Rebert, C.S.; Howd, R.A. (1987). Hearing loss in rats caused by inhalation of 
mixed xylenes and styrene. J. Appl. Toxicol. 7 (1), 55-61. 
Razzaq, M.; Dumbala, S.; Moudgil, S.S. (2010). Sudden deafness due to carbon monoxide 
poisoning. J. Neurol. Neurosur. Ps., 81 (6), 658.  
Rothwell, J.A.; Boyd, P.J. (2008). Amalgam dental fillings and hearing loss. Int. J. Audiol., 
47 (12), 770-776. 
Ruppert, P.H.; Dean, K.F.; Reiter, L.W. (1984). Trimethyltin disrupts acoustic startle 
responding in adult rats. Toxicol. Lett., 22 (1), 33-38. 
Ryback, L.P. (1992). Hearing: The effects of chemicals. Otolaryngol. Head Neck Surg., 106, 
677-686. 
Saunders, J.E.; Jastrzembski, B.G.; Buckey, J.C.; Enriquez, D.; MacKenzie, T.A.; Karagas, 
M.R. (2013). Hearing loss and heavy metal toxicity in a Nicaraguan mining community: 
audiological results and case reports. Audiol. Neurootol., 18 (2),101-113. 

M. P. Gatto, R. C. Bonanni, G. Tranfo et al. 
 
338
Schaper, M.; Demes, P.; Zupanic, M.; Blaszkewicz, M.; Seeber, A. (2003). Occupational 
toluene exposure and auditory function: results from a follow-up study. Ann. Occup. 
Hyg., 47 (6), 493-502. 
Schwartz, J.; Otto, D. (1991). Lead and minor hearing impairment. Arch. Environ. Health, 46 
(5), 300-305. 
Shargorodsky, J.; Curhan, S.G.; Henderson, E.; Eavey, R.; Curhan, G.C. (2011). Heavy 
metals exposure and hearing loss in US adolescents. Arch. Otolaryngol. Head Neck 
Surg., 137 (12), 1183-1189. 
Simonsen, L.; Lund, S.P. (1995). Four weeks inhalation exposure to n-heptane causes loss of 
auditory 
sensitivity 
in 
rats. 
Pharmacol. 
Toxicol., 
76 
(1),  
41-46. 
Sisto, R.; Cerini, L.; Gatto, M.P.; Gherardi, M.; Gordiani, A.; Sanjust, F.; Paci, E.; Tranfo, G.; 
Moleti, A. (2013). Otoacoustic emission sensitivity to exposure to styrene and noise. J. 
Acoust. Soc. Am., 134 (5), 3739-3748. 
Sliwińska-Kowalska, M.; Zamyslowska-Szmytke, E.; Szymczak, W.; Kotylo, P.; Fiszer, M.; 
Wesolowski, W.; Pawlaczyk-Luszczynska, M. (2003). Ototoxic effects of occupational 
exposure to styrene and co-exposure to styrene and noise. J. Occup. Environ. Med., 45 
(1), 15-24. 
Sliwinska-Kowalska, M.; Zamyslowska-Szmytke, E.; Szymczak, W.; Kotylo, P.; Fiszer, M.; 
Wesolowski, W.; Pawlaczyk-Luszczynska, M.; Bak, M.; Gajda-Szadkowska, A. (2004). 
Effects of coexposure to noise and mixture of organic solvents on hearing in dockyard 
workers. J. Occup. Environ. Med., 46 (1), 30-38. 
Sliwinska-Kowalska, M.; Zamyslowska-Szmytke, E.; Szymczak, W.; Kotylo, P.; Fiszer, M.; 
Wesolowski, W.; Pawlaczyk-Luszczynska, M. (2005). Exacerbation of noise-induced 
hearing loss by co-exposure to workplace chemicals. Environ. Toxicol. Phar., 19(3), 547-
553.  
Sprince, N.L.; Zwerling, C.; Lynch, C.F.; Whitten, P.S.; Thu, K.; Logsden-Sackett, N.; 
Burmeister, L.F.; Sandler, D.P.; Alavanja, M.C. (2003). Risk factors for agricultural 
injury: a casecontrol analysis of Iowa farmers in the Agricultural Health Study. J. Agric. 
Safety Health, 9, 5–18. 
Steenland, K. (1996). Epidemiology of occupation and coronary heart disease: research 
agenda. Am. J. Ind. Med., 30 (4), 495-499. 
Sullivan, M.J.; Rarey, K.E.; Conolly, R.B. (1988). Ototoxicity of toluene in rats. 
Neurotoxicol. Teratol., 10 (6), 525-530. 
Tawackoli, W.; Chen, G.D.; Fechter, L.D. (2001). Disruption of cochlear potentials by 
chemical asphyxiants. Cyanide and carbon monoxide. Neurotoxicol. Teratol., 23 (2), 157-
165. 
Treitman, R.D.; Burgess, W.A.; Gold, A. (1980). Air contaminants encountered by 
firefighters. Am. Ind. Hyg. Assoc. J., 41 (11), 796-802. 
Triebig, G.; Bruckner, T.; Seeber, A. (2009). Occupational styrene exposure and hearing loss: 
a cohort study with repeated measurements. Int. Arch. Occup. Environ. Health, 82 (4), 
463-480. 
Trnovec, T.; Sovcikova, E.; Hust'ak, M.; Wimmerova, S.; Kocan, A.; Jureckova, D.; Langer, 
P.; Palkovicova, L.; Drobna, B. (2008). Exposure to polychlorinated biphenyls and 
hearing impairment in children. Environ. Toxicol. Pharmacol., 25 (2), 183-187. 

Occupational Exposure to Ototoxic Chemicals 
 
339
Vyskocil, A.; Leroux, T.; Truchon, G.; Gendron, M.; El Majidi, N.; Viau, C. (2008a). 
Occupational ototoxicity of n-hexane. Hum. Exp. Toxicol., 27 (6), 471-476. 
Vyskocil, A.; Leroux, T.; Truchon, G.; Lemay, F.; Gagnon, F.; Gendron, M.; Viau, C. 
(2008b). Ototoxicity of trichloroethylene in concentrations relevant for the working 
environment. Hum. Exp. Toxicol., 27 (3), 195-200. 
Walker, S.M.; Ackland, T.R.; Dawson, B. (2001). The combined effect of heat and carbon 
monoxide on the performance of motorsport athletes. Comp. Biochem. Physiol. A. Mol. 
Integr. Physiol., 128 (4), 709-718. 
WORLD HEALTH ORGANIZATION - WHO. (1994). International workshop: setting 
priorities in environmental epidemiology- report on a Word Health Organization 
Meeting. Arch. Environ. Health, 49 (4), 239-245. 
Wickramatillake, H.D.; Gun, R.T.; Ryan, P. (1998). Carbon monoxide exposures in 
Australian workplaces could precipitate myocardial ischaemia in smoking workers with 
coronary artery disease. Aust. N. Z. J. Public Health, 22 (3 Suppl), 389-393. 
Yamamura, K.; Terayama, K.; Yamamoto, N.; Kohyama, A.; Kishi, R. (1989). Effects of 
acute lead acetate exposure on adult guinea pigs: electrophysiological study of the inner 
ear. Fundam. Appl. Toxicol., 13 (3), 509-515. 
Zhan, K.; Wu, S.; Ji, X.; Li, N.; Yu, J.; Gao, X. (2012). Chromium-induced hearing loss in 
rats and the protective effect of copper and manganese. Trace Elem. Electroly., 29 (1), 
72-77. 
 


In: Encyclopedia of Audiology and Hearing Research 
ISBN: 978-1-53617-702-2 
Editors: Erno Larivaara and Senja Korhola 
© 2020 Nova Science Publishers, Inc. 
 
 
 
 
 
 
 
Chapter 27  
 
 
 
CONDUCT DISORDER IN CHILDREN AND 
YOUTH WITH HEARING IMPAIRMENT 
 
 
Fadilj Eminovic* and Sanja Dimoski 
Faculty of Special Education and Rehabilitation, 
University of Belgrade, Belgrade, Serbia 
 
 
ABSTRACT 
 
Hearing impairment is a condition that involves medical, psychological and social 
aspects. Surveys report that children and adolescents with hearing impairment show high 
prevalence of psychopathology. Among numerous definitions which are largely 
overlapping (Oppositional Defiant Disorders, Externalizing Disorder, Behavior Problems, 
Socio-emotional Problems), we have chosen the definition of conduct disorder given by 
the World Health Organization in ICD -10. Some of the criteria for the diagnosis are: 
violation of the rules of adults, frequent anger and resentment, deliberate destruction of 
other people's property. The aim of this paper is to examine the relationships between 
hearing impairment and conduct disorder. The survey was conducted in Serbia, the 
environment characterized by specific circumstances concerning the educational and 
socio-economic conditions. This society has not developed a tradition of inclusive 
education for children, and inclusive trends are slow in general. The study was conducted 
on 375 patients of whom 169 are with a hearing impairment, and 178 with no hearing 
impairment. The respondents with hearing impairment attended school for hearing-
impaired children. Some of the respondents with hearing impairment live in abroad 
school and some with their families. As an instrument, we used a scale for assessing 
behavioral disorders (Dimoski, 2004), which was filled by the specialists working in the 
institutions for children and youth with hearing impairments. The survey did not show 
statistically significant differences in the presence of behavioral disorders in the sample 
without hearing impairment and the sample of individuals with hearing impairment. 
However, the results showed that the children with hearing impairment showed 
significantly greater degree of two indicators of behavioral disorders - the tendency to 
steal (t = -3.18, p = 0.002) and extortion of money or benefit from the younger or weaker 
(t = -2.07, p = 0.039). This paper also deals with correlates of behavioral disorders in all 
                                                        
* Corresponding Author’s Email: eminovic73@gmail.com. 

Fadilj Eminovic and Sanja Dimoski 
 
342
patients (sex, age, academic achievement, socio-economic status) and with connection to 
the onset, severity of hearing impairment and type of accommodation (boarding or 
family) in the group of patients with hearing impairment. The male respondents (t = 3:07, 
p = 0.003) with lower school achievement (F = 11.219, p = 0.000) have more evident 
indicators of behavioral disorders. This work has important implications relating to the 
practice of working with children and youth with hearing impairment. It was 
recommended to work on prevention of behavioral disorders, and suggested which types 
of psychosocial interventions for those who express this disorder may be used. 
 
Keywords: hearing impairment, conduct disorder, children, youth, practice of working 
 
 
CONDUCT DISORDER IN CHILDREN AND YOUTH  
WITH HEARING IMPAIRMENT 
 
Problematic behavior in children and adolescents is a common subject of studies in 
contemporary researches. It is approached to these researches from the perspective of 
psychology, psychiatry, pedagogy and other related scientific fields. The research of 
problematic behavior in children and adolescents is followed by methodological difficulties 
related to the lack of precise terminology used to determine the object of study, and various 
criteria by which certain manifestations of behavior are treated as problematic behavior in 
children and adolescents. The large number of various definitions, which are often at least 
partially overlapping is used. The terms: antisocial behavior, externalized behavioral 
problems, oppositional defiant disorder, behavioral problems, socio-emotional problems, 
conduct disorder, and specific criteria that define this phenomenon were used. In Serbian 
language the terms that are in common use are: juvenile offenders and delinquents. There are 
also various categorical and dimensional approaches to the definition of these phenomena. 
The approaches of the researchers are not in compliance neither. Some senior researchers 
support the attitude that antisocial behavior in childhood and adolescents is a unique 
syndrome, regardless of variety of symptoms relating to the phenomenon (Robins, 1966, 
Robins & Ratcliff, 1980) while many recent studies, as well as factor analysis do not confirm 
this hypothesis. Summing up the results of the factor analysis of a large number of different 
studies, it was concluded that the problematic behavior of children can best be conceptualized 
on the basis of two dimensions, namely discovered-hidden dimensions and destructive-non-
destructive dimension (Frick et al., 1993). 
In Diagnostic and Statistical Manual (DSM-IV) conduct disorder is related to the 
repeated and persistent patterns of behavior that violates the basic rights of others and the 
general norms and rules appropriate to age (aggression toward people and animals, 
destruction of property, deceitfulness or theft, and serious violation of rules). 
In modern dimensional systems the division of the externalized and internalized behavior 
problems is accepted (Achenbach & Rescorla, 2001). We have isolated two externalized 
syndrome, which are only partially consistent with the diagnosis of DSM-IV. The first 
syndrome, called aggressive behavior, includes oppositional defiant behavior and aggressive 
conduct disorder, while other syndrome, so-called behavior that violates the rules, includes 
only non-aggressive forms of behavior disorders. This division implies the existence of two 
types of behavioral disorders. The first “discovered” or “aggressive” type, characterized by 

Conduct Disorder in Children and Youth with Hearing Impairment 
 
343
hostile confrontations with others, either in the form of a legal opposition or aggressive 
behavior, and other “hidden” or “non-aggressive” type includes symptoms of conduct 
disorder, which does not includes a confrontation with the victim, substance abuse and 
association with delinquent peers (Loeber & Schmaling, 1985). 
We have accepted the definition of conduct disorder offered by the World Health 
Organization ICD-10, 1993. In the scientific and professional practice in Serbia none of the 
definitions is unanimously accepted. Determination of the ICD-10 is largely used in clinical 
work with children and young people with this kind of disorder which led us to choose this 
definition. Some of the criteria for the diagnosis of conduct disorder are: often reluctance or 
refusal of requests and rules of adults, deliberately destroying other people's property, 
sensitivity and tendency to be annoyed by others (Often touchy or easily annoyed by others), 
frequent anger and resentment (Often angry or resentful) excessive fighting with other 
children, excluding children in the family (Excessive fighting with other children, with 
frequent initiation of fights (not including fights with siblings), criminogenic episodes 
involving confrontation with the victim - intimidation, extortion, frequent truancy from 
school beginning before 13 years of age. It is considered that it is more significant for the 
foresight to take into account the severity and not the exact type of symptoms. During 
diagnosis, manifestations of behavioral disorders that last no less than six months and are not 
isolated antisocial acts are taken into account. This classification makes a distinction between 
socialized, none-socialized and oppositional defiant disorder. 
The existence of different approaches in diagnosing the problematic behavior in 
childhood is a major reason for the inconsistency of the data on their prevalence. In a study in 
which the criteria of the DSM are applied, the prevalence of conduct disorder among children 
and adolescents ranges from 1% to 9%, while the opposition defiant disorder is not so 
present, with prevalence of about 2% (Essau, 2003). Frequency of externalized problems in 
the total population of children and adolescents ranges between 2% and 15% (Hinshaw, 
1992). Conduct disorder, which involves persistent patterns of rule-breaking and violent 
behavior, is estimated to have a prevalence of 9% for boys and 2% for girls (Offord et al, 
1986). In Serbia, the research Zunic-Pavlovic et al, (2009) shows that 12% of students 
exhibited antisocial behavior, and in 6% of the deficit of social competence and antisocial 
behavior is present. 
The presence of psychopathology during developmental period in children and 
adolescents with hearing impairment is a frequent subject of study. Also, the presence of 
behavioral problems of children and youth with hearing impairments has been studied, 
although in this area there are several approaches of the authors and defining disorder. 
However, the development of research dealing with the presence of specific behavioral 
disorders in children and adolescents in this population is absent. 
Imprecise terminology and a variety of criteria for diagnosis are followed by specific 
methodological difficulties related to the procedures and instruments by which we determine 
the presence of problem behavior in children and young people with hearing impairment. 
Assessment of children is difficult, due to the inability of deaf children to understand verbal 
instructions or verbal tasks placed before them, and the limited expressive aspects of language 
and speech. Experts generally do not have enough experience or social skills to conduct 
diagnostic assessments and are not familiar with sign language. Sometimes they include sign 
language interpreters, whose presence necessarily affects the tested situation. The presence of 
behavioral disorders is generally assessed based on the reports of parents and teachers, and 

Fadilj Eminovic and Sanja Dimoski 
 
344
some research suggests peer evaluation about the functioning of a particular child in the 
school context. However, estimates of the parents must not be objective, and are often 
saturated by subjective interpretations of children's behavior. Some authors (Van Gent, 2007) 
believe that the most reliable are the estimates of experts. In addition, certain symptoms 
(especially those related to internalized problems) have distinct subjective tone and are best 
detected on the basis of introspection. 
In Serbia, the studying of children and youth with impaired hearing by psychologically 
measuring instruments is accompanied by the difficulties related to the lack of a standardized 
sign language in which it would be possible to translate the items of the instrument, as well as 
a shortage of professionals who are trained in the diagnosis of psychopathology, 
developmental age of this specific population. Families and children and youth with hearing 
impairments use the expression of spontaneous gestural communication to achieve 
communication. Schools and medical facilities for persons with impaired hearing have no 
systematized praxis on the field of communication using the sign language. 
Contemporary research practice is followed by attitude that different variables, which are 
often not sufficiently controlled in research studies of personality of children and youth with 
hearing impairments (speech development, the degree of experiential, emotional, social and 
educational deprivation, etiology and time of occurrence of hearing loss, the time of initiation 
and duration of rehabilitation, the existence of cochlear implants, etc.) strongly influence the 
results of this group of people on personality tests. This situation is particularly applicable to 
the assessment of the developmental period of psychopathology, including the presence of a 
behavioral disorder. In studies dealing with psychopathology developmental age of children 
and youth with hearing loss in our society, the control of the relevant variables often lack. 
This particularly concerns the variables related to socio-emotional deprivation of children and 
youth with hearing impairments characteristics of dynamics of family relationships and the 
conditions of education and rehabilitation. 
In Serbia, the children and young people with hearing impairment attend almost 
exclusively special schools for education of this population and a large number of them is 
housed in dormitories, or are separated from their families, already at the preschool level. A 
significant percentage of children and youth with hearing impairments who are educated in 
this system of special education have not enough well-developed language and speech 
abilities. The percentage of children with cochlear implants is negligible. 
The importance of language and verbal abilities for adequate development many studies 
have emphasized. Quirin & Lane (2012) show that poor language skills can cause difficulties 
in understanding the social environment and, in turn, are related to an impaired emotion 
understanding. Many studies suggest that a delay in language development of children and 
youth with hearing impairment is in connection with serious difficulties in developing a 
proper understanding of emotion (Rieff & Terwogt 2006; Meerum Terwogt & Rieff, 2004). 
Some studies (Dammayer, 2009) even show that good oral or sign communication with the 
environment is in relation to the normal prevalence of psychosocial problems in deaf children 
and youth. 
These difficulties may explain that the prevalence rates of mental disorders in hearing-
impaired children and adolescents found in the literature vary from 15% to 60% (Bailly et al., 
2003). Some studies provide disturbing data on the prevalence of psychiatric disorders in 
young people with hearing impairment. Hindly (1994) provides information about more than 
50% of children between 11 and 16 years, Colvin et al. (1979) cites 54%. Van Gent et al, 

Conduct Disorder in Children and Youth with Hearing Impairment 
 
345
(2007) provide a comprehensive overview of recent studies of psychopathology in children 
and adolescents with hearing impairment analysis instruments for the evaluation. Their 
research indicates elevated levels of psychopathology. However, some studies do not confirm 
a difference in the manifestation of symptoms of psychopathology in a population of deaf and 
hearing respondents. Sinnkoen (1994) confirmed the slightly higher incidence of 
psychopathology in young people with hearing impairment, but this difference was not 
statistically significant. 
Hearing impairment among children affects psychosocial development, but there is no 
consensus about the rate of prevalence. Older studies (Meadow, 1980, Freeman et al, 1975) 
suggest prevalence of 8-23% presence of socio-emotional problems. The largest number of 
recent studies (Vostanis et al, 1997; van Eldik, 1994; van Eldik et al, 2004) confirms these 
results. Dammajer (2009) states that studies that were performed in the last two decades 
provide data on the prevalence of psychosocial problems in childhood from 20% to 50%. 
However, the findings of the authors from Belgium, Maes & Grietens (2004) did not find 
elevated levels of these disorders in deaf children that were assessed by parents. Bailly et al. 
(2003) reported that some studies have shown the presence of normal levels of behavior 
emotional functioning of deaf children and youth. 
Older studies (Schlesinger & Meadow, 1971), which gave information about the elevated 
levels of behavioral problems in this population, were the impetus for further research. 
Children with hearing loss have a higher level of externalized behavioral problems (30-38% 
van Eldik; Vostanis, et al., 1997) than children with normal hearing. Mitchell & Quittner 
(1996) reported that half or one-third of children and adolescents with hearing impairment 
(depending on whether they are evaluated by parents or teachers) exhibit behavior problems. 
Regarding behavioral disorder studies indicate the presence of a 12% and 14% of children 
and adolescents with hearing impairment compared to 7% in the control group (Hintermair, 
2007). Expert’s estimates show the presence of behavioral disorders in 11% of children and 
youth with hearing impairments (Van Gent, 2007). 
Complex relations between neurological, family and social factors are basis of conduct 
disorders in children and adolescents with hearing impairment (Meadow, 1980). Theoretical 
perspectives on this issue are related to assumptions about the specific environmental 
conditions of children with hearing impairments which affect their emotional development or 
lead to the manifestation of behavioral problems. Family environment, in this respect, has a 
very important role. Difficulty in verbal communication and gestures between parents and 
hearing impaired children strongly influence the overall development of children, not just the 
transfer of information. Conditions of wider social environment are related to environmental 
factors, the socio-economic, through general social factors, conditions, rehabilitation and 
education, and especially terms of social acceptance of people with hearing impairment, 
contributes to the development or maintenance of various psychopathological symptoms. 
Attempts to understand the development of conduct disorder in contemporary literature 
range from taking into account the role of genetic and biological predisposition over the 
characteristics of temperament, socio-cultural context, family relationships, experience 
rejection by peers, social-cognitive factors etc. 
Contemporary concepts are characterized by eclectic approach to the authors and involve 
the effects of multiple factors in the development of the disorder and emphasize the need for 
verification of theoretical concepts in empirical research. Many models are a synthesis of 
different theoretical approaches and research findings (Moffitt, 1993; Patterson & Yoerger, 

Fadilj Eminovic and Sanja Dimoski 
 
346
1997; Lahey & Waldman, 2002, Dodge and Pettit, 2003; Frick and Morris, 2004). Dodge & 
Pettit (2003) offered a bio-psychosocial model of the development of chronic conduct 
problems. This model posits that biological dispositions and sociocultural contexts place 
certain children at risk in early life but that life experiences with parents, peers, and social 
institutions increment and mediate this risk. They point out that certain types of mutual 
influences that occur between predispositions, context and life experiences of the child or 
adolescent, may contribute to the occurrence of behavioral disorders. In the process of 
developing this disorder cognitive and emotional processes play the role of mediator. 
The nature of conduct disorders, as defined by ICD-10 criteria is related to the expression 
of resistance and aggressiveness towards the environment (peers, adults, things, institutions, 
rules, etc.). We believe that we should take into account the hypothesis on the tendency of 
children and youth with hearing loss to a more distinct expression of aggression through such 
nonverbal (behavioral) ways, rather than through verbal, which are not sufficiently developed 
for this population. The expression of emotions, including aggression in children and 
adolescents with hearing impairment is different than the normal hearing children and youth. 
As stated Rieff et al. (2003) recent findings have shown that deaf children have a different 
rationale for the emergence of emotions than their hearing peers. They have restricted 
opportunities to learn from their own and others' experiences in this respect. The research of 
Reiff & Terwogt (2006) showed that deaf children employed the communicative function of 
anger expression differently from hearing children. Whereas hearing children used anger 
expression to reflect on the anguish that another child caused them, deaf children used it 
rather bluntly and explained less. 
One of the few epidemiological studies of the presence of psychopathology in children 
and youth impaired in our community (Tadić, 1998) dealt with the presence of behavioral 
problems. This study demonstrated the presence of lying in 3.2% of subjects with impaired 
hearing, conflicts with friends in 8% of patients, conflicts with teachers at 3.2%, and the fits 
of rage, breaking objects and hitting the 8.8% of respondents. 
Research are trying to detect variables that may be associated with conduct disorders - 
gender, age, academic achievement, socio-emotional status, the nature of relationships with 
peers, especially the experience of rejection by peers, characteristics of temperament, 
character relationships with parents, the influence of parental styles of parents, presence of 
criminal and maladjustment behavior in close environment... When it comes to children and 
youth with hearing impairments in personality tests of the population, usually controlled 
variables affecting the degree of hearing loss are the occurrence of the hearing loss, 
rehabilitation characteristics, ways of communication with the environment and especially in 
the family and etc. We will discuss the variables in more details that are often taken into 
account in the various studies, which are included in this research. 
Surveys consistently show a statistically significant relation between conduct disorder 
and half of respondents. Boys are more prone to these impairments than girls (Friedrich et al. 
1984; Kerr et al. 2004; Björkqvist et al. 1992; Cohen et al. 1993; Crick, 1995; Grotpeter & 
Crick, 1995; Feehan et al., 1994; Offord et al. 1987, Keenan & Loeber, 1994). Peterson 
(1961) showed that age comparison showed that boys displayed more severe conduct 
problems than girls at all age levels. From about 4 years of age, boys are more likely than 
girls to engage in conduct problems (Keenan & Shaw, 1997; Moffitt et al., 2001; Lahey et al., 
2000, Tremblay et al., 1996). Lahey et al. (2000) find that the behavioral problems of youth 
can not be explained without taking into account the gender (and age) differences. These 

Conduct Disorder in Children and Youth with Hearing Impairment 
 
347
authors, in a large sample of respondents aged 9 to 17 years found that boys were more likely 
to express aggression, and to have a common property, and misdemeanor offenses. Instead of 
physical aggression, females tend to use indirect, verbal and relational aggression. Moffit et 
al. (2001) present new findings on a number of subjects of both sexes from 3 to 21 years 
aligning approaches of developmental psychology, psychiatry and criminology. They suggest 
the need for revision of the diagnostic criteria of conduct disorder suitable for girls. Study 
Keenan et al. (1999) report on studies of behavioral disorders limitation only regarding boys. 
They believe that understanding gender differences in the course and severity of conduct 
disorder may lead to important information about etiology. 
Research findings on the relation of conduct disorders and academic achievement are 
consistent, and an interest in author large. Children and adolescents of lower academic 
achievement are more likely to express behavioral disorder than those of academic 
achievement. Antisocial behavior is treated as a variable that has a negative impact on 
academic achievement throughout the years of educating (Bardone et al., 1996; Stott, 1981, 
Hawkins et al., 2003, Masten et al., 1995; Williams & McGee, 1994). Research (Dodge & 
Pettit, 2003; Hinshaw, 1992; Maguin & Loeber, 1996; Hinshaw & Anderson, 1996) show that 
externalized behavioral problems (externalizing behavior) are quite stable in early childhood, 
the relationship between antisocial behavior and academic skills may establish more in pre-
school period and in the later period, this relationship becomes more apparent. 
The researchers' interest was stimulated by the fact that the existence of behavioral 
problems of children with poor school achievement represents an impairment which required 
professional intervention. But the presence of lower academic achievement phenomenon can 
not be seen only in the educational context, since it can lead to self-esteem deficits and 
interpersonal difficulties (Mann & Brady, 1988; Lagreca & Stone, 1990). 
Also, the common occurrence of behavioral disorders and poor academic achievement 
may be treated as a clear predictor of later lack of adaptation in adolescence, which can lead 
to antisocial behavior and substance abuse (Hinshaw, 1992). Vostanis et al. (1997) found that 
poor functioning in school variable best predicts the presence of behavioral and emotional 
problems in children and adolescents with hearing impairment. Many authors (Williams & 
McGree, 1994) pointed out the importance of reading skills in commonly injured children and 
youth with hearing impairments and their relationship with challenging behavior. 
Developed research practice concerns the attempts to determine the relationships between 
risk factors of the environment and the occurrence of antisocial behavior. Environmental 
effects, those related to family and related to the environment, highly correlate (Ingoldsby & 
Shaw, 2002; Leventhal & Brooks-Gunn, 2000), although it is considered useful to separate 
them for a deeper understanding of the etiology (Schonberg & Shaw, 2007). From about five 
to six years of age, differences in conduct problems in children living in disadvantaged 
neighborhoods become more pronounced even after controlling family demographic 
characteristics (Brooks-Gunn, Duncan, Klebanov & Sealand, 1993; Chase-Landsdale & 
Gordon, 1996). Research findings (Lahey et al., 1999, Sampson et al., 1997), generally 
suggest that children and adolescents from families of lower socioeconomic status are more 
likely to express behavioral disorder than those from the upper. Keenan et al. (1997) have 
given the finding that child from low-income families in nearly 5% of express behavior 
disorder. Research (Hausman & Hammen, 1993; Carr, 1999) indicates the relationship of low 
socio-economic status, poverty and social isolation and behavioral disorders. Duncan et al. 

Fadilj Eminovic and Sanja Dimoski 
 
348
(1994) find that it seems that the longer the child has been living in poverty within the first 
four years of life, the more prevalent externalizing behavior problems become. 
Many studies confirm that the prevalence of conduct disorder and delinquency is in 
relation to the different characteristics of the immediate environment (neighborhood), 
including socioeconomic and cultural conditions of the general (Bursik & Grasmick, 1993; 
Loeber & Wikstrom, 1993, Sampson & Groves, 1989; Stouthamer- Loeber et al. 1999; 
Wikstrom, 1991, 1998). 
Significant research data (Moffitt et al., 1996; Nagin & Tremblay, 1999) show that nearly 
half of all children who engage in high levels of conduct problems show considerable 
improvement by early adolescence. Research suggests that risk factors have a different impact 
on the occurrence of behavioral disturbances during development and highlights the 
importance of understanding these complex interactions. 
 
 
METHOD 
 
Participants 
 
The total sample of this study is N = 347 respondents. Part of the sample consists of 
children and young people with hearing impairment (N = 169), or 48.7% of the respondents. 
They are students of only two special schools for pupils with hearing impairment in Belgrade, 
capital of Serbia. In these schools the highest percentage of children with hearing impairment 
are being educated, because in inclusive programs, which are defined by law only in 2013, 
only small percentage of children and youth is included. The sample did not include the 
children and young people with hearing impairment who still have some kind of associated 
disturbances. Regarding the degree of hearing loss, the sample consisted of (N = 120) deaf 
patients, or 71% of the sample (N = 49) partially deaf, hard of hearing respondents, or 29% of 
the sample. Hearing loss is caused by perilingualy N = 141, or 83% of the sample, a lingual 
with N = 28 respondents, or 17% of the sample. 
Children and youth with hearing impairment attending special schools and living in the 
dorms, N = 107, or 63% of the sample. These are respondents whose families do not live in 
the Serbian capital (or other cities where there are schools for children and the youth 
impaired). These children leave the family in the pre-school period and the entire education 
live in boarding schools. The second part of the sample of children and youth impaired 
respondents, N = 62 who live with their families, the capital of Serbia and attend a special 
school for the deaf, or 37% of the sample. 
The children and youth who were included in the study aged from 7 to 18 years. Included 
are children of eight years of primary school, and youth first three years of high school. 
Sample respondents with hearing loss male consisted of N = 102 and female N= 67.  
As an indicator of academic achievement the sample of achievement in school subjects in 
the previous academic year was taken into account. This variable was divided into three 
categories: good or underachievement success in school, very good grades in school and 
excellent school. Success in school subjects with impaired hearing is the largest in the 
category of great success, 54% of respondents. 

Conduct Disorder in Children and Youth with Hearing Impairment 
 
349
Considering the economy, the situation in Serbia and the transition through which the 
country is going, there are simple difficulties in identifying indicators of socio-economic 
status of the family, which would be relevant for research purposes. We have opted for the 
educational attainment of the respondent’s father, which is one indicator of the socio-
economical position of the family that often accompanies the research in our community. This 
variable is divided into four categories: elementary school, finished vocational training 
school, high school and university or university degree. Educational level of the father is in 
nearly 30% of the sample primary school, or the lowest category of education in Serbia, 
which implies a low socio-economic position. 
The control group consisted of children and young people with a normal hearing (N = 
178), or 51.3% of the total sample. They are regular students of primary and secondary school 
in Belgrade. The sample consisted of male respondents N = 84, a female N = 94. According 
to school success they were distributed relatively equally in all three categories. Academic 
success of finished high school of the father of the respondent’s is most frequent followed by 
fathers with secondary education, that is 40% of the sample with proper hearing. 
Statistical comparison of groups of patients (with and without hearing loss) showed the 
following:  
 
1. Group 1 was significantly different from the variable gender (χ2 = 6.041, p = 0.005, 
Cramer's V = 0.132)  
2. Groups are significantly different in relation to school success, subjects with 
impaired hearing have better academic success than subjects without hearing 
impairment (χ2 = 15.760, p = 0.001, Cramer's V = 0.213). Explanation of this 
difference can be found in a weaker assessment criteria in a special school for deaf 
students;  
3. Groups are significantly different compared to graduates father of respondents (χ2 = 
67,132, p = 0.001, Cramer's V = 0.441); Respondents with impaired hearing come 
from lower socioeconomic families compared with patients with normal hearing. 
 
 
Instrument  
 
In Serbia not one instrument to measure conduct disorders was used in the research 
practice which is used in Anglo-Saxon scientific research. Also, there are no standardized 
instruments that are designed for subjects with impaired hearing in this region. Therefore, we 
decided to use the instrument of the local authors (Dimoski, 2001), Scale for assessment of 
the presence of behavioral disorders. This instrument is filled by teachers of children and 
youth, the survey respondents. Assessment of teachers matched the plan of this research, 
given that a large percentage of respondents with impaired hearing lived away from their 
families, and parents often do not have the relevant data on the investigated phenomena. 
Some authors (Van Gent, 2007) suggest that the most reliable are the estimates of experts.  
The instrument consists of 15 statements that are evaluated on a scale in which 1 point 
denoted the absence of manifestations of behavior disorder, 2 points, the presence of low 
intensity, medium presence of 3 points, 4 points expressed presence. The claims set in the 
instrument are mainly related to the manifestation of conduct disorder as defined in this  
 

Fadilj Eminovic and Sanja Dimoski 
 
350
disorder ICD-10. The instrument is accompanied by a recommendation from the ICD-10, 
which suggests that the manifestation of behavioral disorders should be present in the last six 
months.  
Detailed instruction is preceded by the instrument.  
Reliability of the instrument, measured by Cronbach's Alpha is 0.921. The reliability of 
the instrument for sample hearing impaired subjects was 0.934, and the sample of respondents 
without hearing damage is 0.917. 
 
Procedure  
After the detailed planning of the sample, we have started the research. The subjects with 
hearing impairment were evaluated by their teachers in special schools. Teachers are 
professionals for hearing impairments (special educators) who are well familiar with the 
children, at least several years. They are also their homeroom teachers or principal 
professional persons for training and general care of a particular child.  
Subjects without hearing impairment were assessed by their teachers, homeroom teachers 
in regular education system.  
All participants in the study who gave their assessment by filling the Scale of the the 
presence of conduct disorder were given detailed oral and written instructions. The purpose of 
the study was explained and their consent to use the results for research purposes was 
obtained. Previously, the consent of parents of children and youth, and school management 
was obtained. 
 
 
RESULTS  
 
The main results of this study concern the estimation of the presence of conduct disorders 
in hearing impaired children and young people in Serbia.  
 
Table 1. Total score on a scale of conduct disorders in a sample with and without 
hearing loss  
 
Group 
N 
AS 
SD 
T 
df 
p 
No damage 
178 
21.51 
7.02 
 
1.304 
 
262.836 
 
0.193 
With hearing damage 
169 
20.59 
5.24 
  
When used a total score on a scale of conduct disorders it is not possible to determine a 
statistically significant difference (p = 0.193) between patients with and without hearing 
impairments.  
We have accessed to the additional analysis of the items of the instrument in order to 
supplement the basic findings of research that is not indicating the difference between the two 
groups in terms of the presence of conduct disorders. For the purpose of the work we have 
selected items which have statistically significant difference present.  
 
 
 

Conduct Disorder in Children and Youth with Hearing Impairment 
 
351
Table 2. T test for items found to have statistically significant differences in the 
manifestations of conduct disorders in the groups with and without damage 
 
Item 
Group 
AS 
SD 
T 
df 
p 
Prone to theft 
No damage 
1.03 
0.15 
 
3.176 
 
208.20 
 
0.002 
With hearing 
damage 
1.53 
0.42 
Extort money from 
younger or weaker 
students 
Without damage 
1.02 
0.18 
 
 
2.074 
 
 
240.55 
 
 
0.005 
With hearing 
damage 
1.39 
0.38 
 
The research included the identification of correlates of conduct disorders in children and 
adolescents with hearing impairment. The following are findings that are related to assumed 
variables that are related to behavioral disorders in children and adolescents with hearing 
impairment.  
 
Table 3. Summary scores of conduct disorder distributed according to the degree of 
hearing loss  
 
Degree of 
hearing 
impairment 
N 
AS 
SD 
T 
df 
P 
Deaf 
120 
19.63 
 
4.50 
 
-1.518 
 
167 
 
0.131 
Hard of hearing 
49 
20.98 
5.48 
  
Analysis of the total score of conduct disorder shows that in a sample of individuals with 
hearing loss there were no statistically significant differences (p = 0.131) between the deaf 
and hard of hearing patients. The level of impairment is not related to the presence of conduct 
disorders in hearing impaired children and youth.  
 
Table 4. Total score of conduct disorders distributed by time of origin of hearing loss 
 
Time of occurence of the hearing 
impairment 
N 
AS 
SD 
T 
df 
p 
Prelingnual 
141 
20.67 
5.10 
0.449 
167 
0.654 
Postlingual 
28 
20.18 
5.59 
 
The analysis of the total scores of conduct disorder shows that in a sample of individuals 
with hearing loss there was no statistically significant difference (p = 0.654) between patients 
who had hearing loss caused prelingually and postlingually. Time of occurrence of the 
hearing impairment was not related to the presence of conduct disorders in hearing impaired 
children and youth.  
Analysis of the total scores of conduct disorder in relation to gender shows that there is a 
statistically significant difference (p = 0.003) in the expression of conduct disorders among 
boys and girls with hearing impairment. Male respondents expressed a greater presence of 
behavioral disorders.  

Fadilj Eminovic and Sanja Dimoski 
 
352
Table 5. Total score of conduct disorders in boys and girls with hearing impairment 
 
Gender 
N 
AS 
SD 
t 
df 
p 
Male 
102 
21.55 
5.127 
 
3.072 
 
149 
 
0.003 
Female 
67 
19.12 
4.86 
 
Table 6. T test for items in which we found statistically significant difference in the 
manifestations of conduct disorders in boys and girls with hearing impairment 
 
Item 
Gender 
AS 
SD 
T 
df 
p 
Prone to physical cruelty 
toward younger and weaker 
students 
Boys 
1.73 
0.80 
 
3.408 
 
166 
 
0.001 
Girls 
1.37 
0.55 
Prone to purposefully annoy 
others 
Boys 
1.75 
0.78 
 
3.954 
 
164 
 
0.000 
Girls 
1.33 
0.59 
Tends to threaten, intimidate 
and harass other 
Boys 
1.29 
0.48 
 
2.811 
 
147 
 
0.006 
Girls 
1.09 
0.45 
Prone to fights 
Boysi 
1.50 
0.66 
 
4.359 
 
165 
 
0.000 
Girls 
1.12 
0.48 
Destructive towards common 
things (eg. School inventory) 
Boys 
1.26 
0.45 
 
3.457 
 
160 
 
0.001 
Girls 
1.06 
0.24 
 
Table 7. Total score of conduct disorder scores assigned to the school success of children 
and youth with impaired hearing 
 
Academic achievement 
N 
AS 
SD 
Weaker and average grades in school 
32 
23.34 
5.59 
Very good grades in school 
45 
21.87 
6.24 
Excellent grades in school 
92 
19.00 
5.24 
  
Table 8. Analysis of variance for scores on a scale of conduct disorders in general 
assigned to the school success 
 
 
The sum of 
squares 
df 
Average square 
F 
p 
Between groups 
548.587 
2 
274.294 
11.219 
0.000 
Within groups 
4058.419 
166 
24.448 
 
 
Total 
4607.006 
168 
 
 
 
 
Analysis of variance showed a statistically significant difference between the cumulative 
score on a scale of conduct disorders among respondents with hearing impairments in relation 
to school success (p = 0.000). Respondents with lower school achievement are more likely to 
express conduct disorder than those with better school achievement.  
Given the established statistical significance of difference between the better and worse 
hearing impaired students, the T test for items in which statistically significant difference was 
found.  
 

Conduct Disorder in Children and Youth with Hearing Impairment 
 
353
Table 9. T test for items found in which a statistically significant difference in the 
manifestations of conduct disorders among groups with different academic success  
was found 
 
Item 
The sum of squares 
df 
The average of 
squares 
F 
p 
Prone to physical 
cruelty toward 
younger and weaker 
students 
Between 
groups 
6.738 
2 
3.369 
6.798 
 
 
0.001 
Within groups 
82.268 
166 
0.496 
 
Total 
89.006 
168 
 
 
Prone to 
purposefully annoy 
others 
Between 
groups 
4.294 
2 
2.147 
4.102 
 
 
0.018 
Within groups 
86.877 
166 
0.523 
 
Total 
91.172 
168 
 
 
Tends to threaten, 
intimidate and 
harass other 
Between 
groups 
1.187 
2 
0.933 
4.249 
 
 
0.016 
Within groups 
36.465 
166 
0.220 
 
Total 
38.331 
168 
 
 
Prone to fight 
Between 
groups 
2.744 
2 
1.372 
3.694 
 
 
0.027 
Within groups 
61.658 
166 
0.371 
 
Total 
64.402 
168 
 
 
Destructive towards 
common things (eg. 
School inventory) 
Between 
groups 
1,314 
2 
0.657 
4.414 
 
 
0.014 
Within groups 
24.710 
166 
0.149 
 
Total 
26.024 
168 
 
 
Destructive 
towardsother 
persons`s things 
Between 
groups 
2.202 
2 
0.101 
3.991 
 
 
0.020 
 
 
Within groups 
45.798 
166 
0.276 
 
Total 
48.000 
168 
 
 
Prone to theft 
Between 
groups 
1.923 
2 
0.961 
5.865 
 
 
0.003 
Within groups 
27.213 
166 
0.164 
 
Total 
29.136 
168 
 
 
Prone to lying from 
personal reasons 
Between 
groups 
7.657 
2 
3.829 
10.489 
 
 
0.000 
Within groups 
60.591 
166 
0.365 
 
Total 
68.249 
168 
 
 
Unexcused absence 
from school 
Between 
groups 
6.974 
2 
3.487 
9.628 
 
 
0.000 
Within groups 
60.126 
166 
0.362 
 
Total 
67.101 
168 
 
 
Tantrums 
Between 
groups 
4.797 
2 
2.389 
7.212 
 
 
0.001 
Within groups 
55.203 
166 
0.333 
 
Total 
60.000 
168 
 
 
Often opposition 
and strife in 
relationships with 
adults 
Between 
groups 
3.109 
2 
1.554 
4.308 
 
 
0.015 
Within groups 
59.897 
166 
0.361 
 
Total 
63.003 
168 
 
 
 
Analysis of the total scores of conduct disorder in the scale shows no statistically 
significant difference (p = 0.341) between patients who live with their families and those 

Fadilj Eminovic and Sanja Dimoski 
 
354
living in a boarding school for children and youth impaired in relation to the presence of 
conduct disorders.  
 
Table 10. Total scores of conduct disorder assigned to the residence of children and 
youth with hearing impairments 
  
Residence 
N 
AS 
SD 
t 
df 
P 
Family 
107 
20.88 
5.67 
0.954 
167 
0.341 
Boarding school 
62 
20.08 
4.40 
 
Table 11. Total scores of conduct disorder assigned to age of the respondents  
 
Age 
 
N 
AS 
SD 
7-10 
45 
19.82 
4.30 
11-14 
67 
20.97 
5.43 
15-18 
57 
20.74 
5.69 
 
Table 12. Analysis of variance for the total score of conduct disorder scores assigned by 
age of the subjects with hearing impairment 
 
 
The sum of squares 
df 
The average of squares 
F 
Between groups 
37.435 
2 
18.718 
0.680 
Within groups 
4569.571 
166 
27.528 
 
Total 
4607.006 
168 
 
 
 
Table 13. Total score of conduct disorders distributed by educational level of the father 
of respondents 
 
Educational level of father 
N 
AS 
SD 
Primary School  
50 
21.40 
5.62 
Trade school  
47 
21.43 
5.77 
High school  
62 
19.82 
4.59 
Higher or university degree 
10 
17.30 
1.77 
 
The results show that there is no statistically significant difference (p = 0.508) in the total 
score of conduct disorders among subjects with impaired hearing of different age. 
The table shows that there is no normal distribution of the variable of educational level of 
the father of the hearing impaired subjects. Fathers of children and youth with hearing 
impairments with college or university education comprise just over 6% of this part of the 
sample.  
Table 14. Analysis of variance for scores on a scale of conduct disorders in general 
distributed by educational level of father of respondents 
 
 
The sum of 
squares 
df 
The average of 
squares 
F 
p 
Between groups 
210.368 
2 
70.123 
2.632 
0.050 
Within groups 
4396.638 
166 
26.646 
 
Total 
4607.006 
168 
 

Conduct Disorder in Children and Youth with Hearing Impairment 
 
355
Analysis of variance showed that the differences in the educational attainment of fathers 
of those with hearing loss is at the limit of statistical significance (p = 0.050). Children and 
young people with hearing impairment from lower educational and socio-economic 
conditions are somewhat more likely to express conduct disorder.  
 
Table 15. T test for the item in which was a statistically significant difference was found 
in the manifestations of conduct disorders in patients whose fathers have different 
educational level 
 
Item 
The sum of squares 
df 
The average of 
squares 
F 
p 
Prone to lie for 
personal gain 
Between gropus 
3.507 
3 
1.169 
2.979 
 
 
0.033 
Within groups 
64.741 
165 
0.392 
 
Total 
68.249 
168 
 
 
 
Discussion  
 
Results of this study show that children and adolescents with impaired hearing are not 
more prone to conduct disorder than children and youth with no impairments as indicated by 
the total score on a scale that measured the presence of conduct disorder (Table 1). However, 
analysis of the individual items of the instrument shows that children and youth with hearing 
impairments showed statistically more emphasized some manifestations of conduct disorders 
(Table 2). It is the tendency of theft and extortion of money or benefits from younger or 
weaker students. 
The findings of our study are not in accordance with the highest number of surveys that 
provide information that in children and youth with hearing impairments the problematic 
behavior is more present, no matter how they are defined, such as: behavioral problems, 
antisocial behavior, externalized problems, etc. Conduct disorder, as defined by ICD-10 
refers, for its quality and intensity of the serious developmental problems and in this fact 
should be sought the explanation of our findings. Namely, the used definitions indicate more 
severe developmental problems than those tested in alleged researches (Schlesinger & 
Meadow, 1971 Freeman, et al., 1975; Meadow, 1980; van Eldik et al., 2004; Vostanis, at al., 
1997). Studying developmental problems and psychopathology in children and adolescents 
with hearing impairments, the authors did not specifically directed their attention to the 
conduct disorder, as was the case with this research. Authors Prinstein & La Greca (2004) 
argue that the results of the study depend on how the phenomenon that is being studied is 
defined (ie, delinquency, aggression, illegal offenses, and nonspecific outcomes). 
On the other hand, the results on variables that are assumed to be related to conduct 
disorders in hearing impaired in children and young people are in accordance with the 
findings and theoretical assumptions about the development of conduct disorder. 
Our findings indicate that conduct disorder in children and adolescents with hearing 
impairments, in relation to the gender of the respondents - male respondents expressed a 
greater tendency to disorder behaviors than female respondents. Published studies (Peterson, 
1961; Friedrich et al., 1984, Kerr et al. 2004; Björkqvist et al., 1992, Cohen et al. 1993; Crick, 
1995; Grotpeter & Crick, 1995; Feehan et al. 1994; Offord et al., 1987, Lahey et al., 2000, 

Fadilj Eminovic and Sanja Dimoski 
 
356
Loeber & Keenan, 1994;) on gender differences in the presence of behavioral disorders, are 
consistent with our results. 
In addition, the findings of our studies are consistent with the findings (Bardone et al. 
1996; Stott, 1981; Hawkins et al., 2003, Masten, et al., 1995, Williams & McGee, 1994; 
Dodge & Pettit, 2003; Hinshaw, 1992; Maguin & Loeber, 1996; Hinshaw & Anderson, 1996) 
that show that children and youth of lower academic achievement are more likely to express 
behavioral disorder. 
The results of our research show that children and young people with hearing impairment 
who come from lower socio-economic status, if it is used as an indicator of educational level 
of their fathers are more prone to disorder behaviors than those from higher status families. 
Our findings are consistent with studies (Lahey et al., 1999, Sampson et al., 1997) on 
expressed emergence of behavioral disorders in families of lower socio-economic position. 
The assumptions that the variables (degree of hearing loss, the time of occurrence of 
hearing loss and accommodation during training - a boarding school or family) are related to 
conduct disorders in hearing impaired children and youth are not confirmed. Also, the age of 
subjects is not related to the presence of behavioral disorders in children and adolescents with 
hearing impairment. 
The value of the findings of this study is that they suggest that in the development of 
conduct disorders in children and adolescents with hearing impairment the specific patterns 
that are related specifically to the loss of auditory communication channels are not needed. 
The presence of the conduct disorder is more pronounced in boys, children and adolescents of 
lower school achievement and those from families of lower socioeconomic status. It seems 
that the presence of conduct disorders in childhood and adolescence is not characteristic for 
children and youth with hearing impairment, that is in conjunction with the hearing loss. 
On the other hand, it should be considered that the diagnosis the disorder involves severe 
forms of antisocial behavior. Impacts of variables related specifically to children and youth 
with hearing impairments may be identified with less serious forms of maladaptive behaviors 
(eg. externalized behavioral problems). 
 
 
Limitations  
 
This study had a number of limitations. The study did not take into account the many 
variables that are associated with conduct disorders in children and adolescents. One of the 
most important, as we consider, is relation with parents and the general situation in family. 
This is related to a second limitation of the research. It has failed to learn the impact of 
specific characteristics of families of children with hearing impairments (primarily a way of 
communication and acceptance of a deaf child) that can be assumed to have effects on the 
development of conduct disorder. Research has failed to examine the relationship or other 
potentially relevant variables related to hearing loss (the time of initiation of rehabilitation, 
the development of sign language, the linguistic peculiarities and speech development). The 
study sample consisted of children who are educated in special forms of education, including 
isolation, lack of contact with normal hearing population, reduced educational expectations, 
and low assessment criteria and so on) or circumstances that may have affected the results of 
the research. Also, we were not able to attach the control related to the general characteristics 
of the environment (poor economic situation, transition, disrupted the system of values, the 

Conduct Disorder in Children and Youth with Hearing Impairment 
 
357
characteristics of the educational system) that could affect children and young people with 
hearing impairments and those without damage. Given that the environment variables are 
considered as possible determinants of the disturbance of conduct, we believe that their 
consideration in this research would be desirable. 
 
 
Praxis Implications 
 
The results of this study have implications relating to work with children and youth with 
hearing disorders and the prevention of potential developmental disorders and later 
psychopathology. Although the survey results did not indicate the prominent conduct disorder 
in children and adolescents with hearing impairment, we should not ignore the fact that 
certain indicators are more present than in children and young people without hearing loss. It 
would be important to check to what extent the presence of these indicators is a consequence 
of boarding lifestyle and isolated education that is available to a large number of children and 
youth with hearing impairments in Serbia. 
Prevention programs that are expected to be able to have a positive impact on reducing 
the risk factors for occurrence of conduct disorders in children and adolescents with hearing 
impairments are related to psychosocial interventions. In schools for children and youth with 
hearing impairment it is advisable to conduct additional sports activities (especially for boys), 
and consider the possible positive impact of martial arts that would help control aggression 
and destructiveness. Art therapy and projective, non-directive non-verbal therapeutic 
techniques may be considered desirable for all children and youth with hearing impairments. 
In those who have stronger risk factors for occurrence of conduct disorders the additional 
psychotherapeutic intervention and family support is required. Prevention programs should be 
directed to the environment of children and youth with hearing impairments, particularly for 
reducing prejudice, given the research results (Dimoski, et al., 2013) demonstrated the 
presence of indifference and resistance to children and youth with impaired hearing. 
Preventive interventions for improving the academic achievement of children and young 
people with hearing impairment, according to research findings (e.g., Hawkins, Catalano, 
Kosterman, Abbott, & Hill, 1999) are in relation to a reduced risk of developing behavioral 
problems, including conduct disorders. Positive interventions in the education system in 
Serbia may have a potential very large positive impact because it would contribute to the 
development of inclusive trends that are still in their beginning. These changes would have a 
positive effect on strengthening the implicit self-esteem of children and youth with hearing 
impairments, reducing the risk of developing psychopathology, developmental age, including 
behavioral disorders. 
 
 
CONCLUSION  
 
This study did not find that children and young people with hearing impairments in 
Serbia have a higher presence of conduct disorders compared to children and youth with no 
damage. Findings suggest similar patterns of development of conduct disorders, regardless of 
hearing damage, since that established correlates of conduct disorders in hearing impaired 

Fadilj Eminovic and Sanja Dimoski 
 
358
children and young people this research detected with hearing population. Since conduct 
disorder involves serious manifestations of antisocial behavior, future research should 
examine the presence of developmental disorders that are characterized by less severe 
symptoms (externalizing disorder, behavior problems, socio-emotional problems) in children 
and adolescents with hearing impairment and determine any specificity in the occurrence 
related to hearing loss (method of communication during start-up and success of 
rehabilitation, acceptance of violence, experience with normal hearing peers, etc.). Also, 
future research should examine the presence and effects of risk factors of disturbance 
behaviors that have already been established in children and adolescents without impairments 
and their impact on children and young people with hearing impairment.  
 
 
REFERENCES 
 
American Psychiatric Association. (2000). Diagnostic and statistical manual of mental 
disorders. 4th ed. American Psychiatric Association; Washington, DC: text revision. 
Achenbach, T.M. (1996). Het cross‐informant programma voor de CBCL/4‐18, TRF & YSR 
[Computer software]. Burlington, VT: University of Vermont Department of Psychiatry 
(programmeurs: Arnold, J. en Jacobowitz, D.). 
Achenbach, T. M., & Rescorla, L. A. (2001). Manual for the ASEBA school-age forms and 
proles. Burlington: University of Vermont, Research Center for Children, Youth & 
Families. 
Bailly, D., Dechoulydelenclave, M.B., Lauwerier, L. (2003). Hearing impairment and 
psychopathological disorders in children and adolescents. Review of the recent literature. 
Encephale. 4 (1). 329-37. 
Bardone, A. M., Moffitt, T. E., Caspi, A., Dickson, N., & Silva, P. A. (1996). Adult mental 
health and social outcomes of adolescent girls with depression and conduct disorder. 
Development and Psychopathology, 8, 811–829. 
Barker, D.H., Quittner, A.L., Fink, N.E., Eisenberg, L.S., Tobey, E.A., Niparko, J.K. (2009). 
Predicting behavior problems in deaf and hearing children: The influences of language, 
attention, and partn-child communication. Developmental Psychopathology. 21(2).373-
392. 
Björkqvist, K., Lagerspetz, K.M.J., Kaukianen, A. (1992). Do girls manipulate and boys 
fight? Developmental trends in regard to direct and indirect aggression. Aggressive Behav 
18:117–127. 
Brooks-Gunn, J., Duncan, G. J., Klebanov, P. K.,& Sealand, N., (1993), Do 
neighborhoodsinfluence child and adolescent development?American journal of 
sociology, 99, 353-395. 
Bursik, R. J., & Grasmick, H. G. (1993). Neighborhoods and crime. New York: Lexington 
Books. 
Crick, N.R. (1995), Relational aggression: the role of intent attributions, feelings of distress, 
and provocation type. Devalop Psychopathology. 7. 313–322. 
Crick, N.R., & Grotpeter, J.K. (1995). Relational aggression, gender, and socialpsychological 
adjustment. Child Devalopmnt. 66.710–722. 

Conduct Disorder in Children and Youth with Hearing Impairment 
 
359
Cohen, P., Cohen, J., Kasen, S. Velez, C.N., Hartmark, C., Johnson, J., Rojas, M., Brook, J., 
Streuning, E.L. (1993). An epidemiological study of disorders in late childhood and 
adolescence, I: age and gender-specific prevalence. Journal of Child Psychologu and 
Psychiatry. 34. 851–867. 
Carr, A.(1999). Handbook of Child and Adolescent Clinical Psychology: A Contecutal 
Approach. London: Routledge. 
Chase-Landsdale, P. L., & Gordon, R. A. (1996).Economic hardship and the development 
offive- and six-year-olds: Neighborhood andregional perspectives, Child development, 
67, 3338-3367. 
Dammeyer, J. (2009). Psychosocial Development in a Danish Population of Children With 
Cochlear Implants and Deaf and Hard-of-Hearing Children. Journal of Deaf Studies and 
Deaf Education. 15(1). 50-58. 
Dimoski, S., Eminovic, F., Stojkovic, I., Stanimirovic, D., (2013). Contact with Persons with 
Hearing Impairments as a Correlate of Children’s and Adults’Attitudes towards These 
Persons Croatian Journal of Education.15 (3). 611-628. 
Dodge, K. A., & Pettit, G. S. (2003). A biopsychosocial model of the development of chronic 
conduct problems in adolescence. Developmental Psychology, 39, 349–371. 
Duncan, G.J., & Brooks-Gunn, J. (1994). Economic Deprivation and Early Childhood 
Development. Child Development. 65 (2). 296–318.  
Essau, C. A. (2003). Epidemiology and comorbidity. In C. A. Essau (Ed.), Conduct and 
oppositional de!ant disorders: epidemiology, risk factors, and treatment. Mahwah: 
Lawrence Erlbaum Associates, Inc. 
Frick, P. J., Van Horn, J., Lahey, B. B., Christ, M. A. G., Loeber, R, Hart, E. A., et al. (1993). 
Oppositional defant disorder and conduct disorder: a meta-analytic review of factor 
analyses and cross-validation in a clinic sample. Clinical Psychology Review, 13 (4). 319-
340. 
Frick, P. J., and Morris, A. S. (2004). Temperament and developmental pathways to conduct 
problems. Journal of Clinical Child and Adolescent Psychology. 33: 54–68. 
Freeman, R. D., Malkin, S. F., & Hastings, J. O. (1975). Psychosocial problems of deaf 
children and their families: A comparative study. American Annals of the Deaf. 120. 275–
304. 
Friedrich, W.N., Urquiza, A.J., Beilke, R.L. (1984).Behavior Problems in Sexually Abused 
Young Children . Journal of Pediatric Psychology. 11(1).47-57. 
Feehan, M., McGee, R., Raja, S.N., Williams, S.M. (1994). DSM-III-R disorders in New 
Zealand 18-year-olds. Australian New Zeland Journal of Psychiatry. 28.87–99. 
Hawkins, D.J., Catalano, R.F., Kosterman, R., Abbot, R., & Hill, K.G. (1999). Preventing 
adolescent health-risk behaviors by strengthening protection during childhood. Archive 
of Pediatric and Adolescent Medicine.153(3). 226-34. 
Hinshaw, S. P. (1992). Externalizing behavior problems and academic underachievement in 
childhood and adolescence: causal relationships and underlying mechanism. 
Psychological Bulletin, 111 (1). 127-155. 
Hinshaw, S. P., & Anderson, C. A. (1996). Conduct and oppositional defiant disorders. In E. 
J. Mash & R. A. Barkley (Eds.), Child psychopathology (pp. 113–149). New York: 
Guilford Press. 
Hawkins, J. D., Smith, B. H., Hill, K. G., Kosterman, R. F. C., Catalano, F. C., & Abbott, R. 
D. (2003). Understanding and preventing crime and violence: Findings from the Seattle 

Fadilj Eminovic and Sanja Dimoski 
 
360
Social Development Project. In T. P. Thornberry & M. D. Krohn (Eds.), Taking stock of 
delinquency: An overview of findings from contemporary longitudinal studies (pp. 255– 
312). New York: Kluwer Academic/Plenum Press. 
Hausman, B. & Hammen, C. (1993). Parenting in homeless families: The double crisis. 
American Journal of Orthopsychiatry. 63(3), 358-369. 
Hindley, P. A., Hill, P. D., McGuigan, S., & Kitson, N. (1994). Psychiatric disorder in deaf 
and hearing impaired children and young people: a prevalence study. Journal of Child 
Psychology and Psychiatry. 35. 917–934. 
Hintermair, M. (2007). Prevalence of Socioemotional Problems in Deaf and Hard of Hearing 
Children in Germany. American Annals of the Deaf. 152(3). 320-330. 
Ingoldsby, E. M., & Shaw, D. S. (2002). Neighborhood contextual factors and early-starting 
antisocial pathways. Clinical Child and Family Psychology Review. 5. 21–55. 
Kerr, D.C.R., Lopez, N.L. Olson, S.L., Sameroff, A.J. (2004).Parental Discipline and 
Externalizing Behavior Problems in Early Childhood: The Roles of Moral Regulation and 
Child Gender. Journal of Abnormal Child Psychology. 32(4). 369-383.  
Keenan, K., & Shaw, D. (1997). Developmental and social influences on young girls' early 
problem behavior. Psychological Bulletin. 121. 95-113.  
Keenan, K., Loeber, R., Green, S. (1999). Conduct Disorder in Girls: A Review of the 
Literature. Clinical Child and Family Psychology Review. 2 (1). 3-19.  
Kolvin, I., Fundudis, T., Spuy, H. I. J., Tweddle, E. G., & van der George, G. S. (1979). The 
hearing impaired child: Behavior and personality. In T. Fundudis, I. Kolvin, & R. F. 
Garside (Eds.), Speech retarded and deaf children: Their psychological development. 
(pp. 175–184). London: Academic Press. 
Lahey, B.B, Schwab-Stone, M, Goodman, S.H, Waldman, I.D, Canino, G, Rathouz, P.J, 
Miller, T.L, Dennis, K.D, Bird, H, Jensen, P.S. (2000). Age and gender differences in 
oppositional behavior and conduct problems: a cross-sectional household study of middle 
childhood and adolescence. Journal of Abnormal Psychology. 109(3). 488-503. 
Lahey, B.B., Miller, T.L., Gordon, R.A., Riley, A.W. (1999). Developmental epidemiology of 
the disruptive behavior disorders. In: Handbook of the Disruptive Behavior Disorders, 
Quay HC, Hogan A, eds. New York: Plenum, 23–48. 
Loeber, R., & Schmaling, K. (1985). Empirical evidence for over tand covert patterns of 
antisocial conduct problems: a metaanalysis. Journal of Abnormal Child Psychology. 13 
(2). 379-390. 
Loeber, R., and Wikstro m, P. H. (1993). Individual pathways to crime in different types of 
neighborhoods. In D. P. Farrington, R. J. Sampson, & P. H. Wikstrom (Eds.) Integrating 
individual and ecological aspects of crime (pp. 169–204). Stockholm, Sweden: National 
Council for Crime Prevention. 
Loeber, R., & Keenan, K. (1994). Interaction between conduct disorder and its comorbid 
conditions: Effects of age and gender. Clinical Psychology Review. 14. 497–523. 
Leventhal, T., and Brooks-Gunn, J. (2000). The neighborhoods they live in: The effects of 
neighborhood residence on child and adolescent outcomes. Psychological Bulletin. 126. 
309–337. 
Offord, D.R., Boyle, M.H., Szatmari, P., Rae-Grant, N.I., Links, P.S., Cadman, D.T., Byles, 
J.A., Crawford, J.W., Blum, H.M., Byrne, C. (1987). Ontario Child Health Study, II: six-
month prevalence of disorder and rates of service utilization. Archives of General 
Psychiatry. 44. 832–836. 

Conduct Disorder in Children and Youth with Hearing Impairment 
 
361
Offord, D. R., Alder, R., & Boyle, M. H. (1986). Prevalence and sociodemographic correlates 
of conduct disorder. American Journal of Social Psychiatry. 6. 272-278. 
Parker, J. G., & Asher, S. R. (1987). Peer relations and later personal adjustment: Are low-
accepted children at risk? Psychological Bulletin. 102. 357–389. 
Patterson, G. R., & Yoerger, K. (1997). A developmental modelfor late-onset delinquency. In 
D. W. Osgood (Ed.) Motivation and delinquency: Nebraska Symposium on Motivation 
(pp. 119– 177). 44 Lincoln: University of Nebraska Press. 
Peterson, D. R. (1961). Behavior problems of middle childhood. Journal of Consulting 
Psychology. 25(3). 205-209. 
Prinstein, M.J., & La greca, A.M.(2004). Childhood Peer Rejection and Aggression as 
Predictors of Adolescent Girls’ Externalizing and Health Risk Behaviors:A 6-Year 
Longitudinal Study. Journal of Consulting and Clinical Psychology . 72(1). 103-112. 
Robins,L.N.(1966) Deviant Children Grown-Up: A Sociological and Psychiatric Study of 
Sociopathic Personalities. MD: Williams and Wilkins. 
Robins, L.N., & Ratcliff, K.S. (1980). The long-term outcome of truancy. In L. Hersov & I. 
Berg (Eds.), Out of school: Modern perspectives in truancy and school refusal (pp. 65-
83). New York: John Wiley. 
Reiffe, C., Terwogt, M.M., Smit, C. (2003). Deaf Children on the Causes of Emotions. 
Educational Psychology: An International Journal of Experimental Educational 
Psychology. 23(2). 159-168. 
Reiffe, C., & Terwogt, M.M. (2006). Anger communication in deaf children. Cognition and 
Emotion. 20.(8). 1261-1273. 
Sampson, R. J.,& Groves,W. B. (1989). Community structure and crime: Testing social-
disorganization theory. American Journal of Sociology. 94(4). 774–802. 
Sinkkonen, J. (1994). Evaluation of mental health problems among Finnish hearing impaired 
children. Psychiatrica Fennica. 25. 52–65. 
Stone, W L., & LaGreca, A. M. (1990). The social status of children with learning 
disabilities: A reexamination. Journal of Learning Disabilities. 23. 32-37. 
Stott, D. H. (1981). Behaviour disturbance and failure to learn: A study of cause and effect. 
Educational Research. 23.163-172. 
Schlesinger, H.J., & Meadow, K. (1971). Deafness and mental health: Developmental 
approach. Berkeley, CA, itd: University of California Press. 
Schonberg, M.A., & Shaw, D.S. (2007). Do the Predictors of Child Conduct Problems Vary 
by High- and Low-Levels of Socioeconomic and Neighborhood Risk? Clinical Child and 
Family Psychology. 10(2).101-36. 
Sampson, R.J., Raudenbusch, S.W., Earls, F. (1997). Neighborhoods and violent crime: a 
multilevel study of collective efficacy. Science. 277. 918–924. 
Stouthamer-Loeber, M., Drinkwater, M., & Loeber, R. (1999-2000). Family functioning 
profiles, early onset of offending, and disadvantaged neighborhoods. International 
Journal of Child and Family Welfare. 4. 247-256. 
Tadić, N. (2010). Psihijatrija detinjstva i mladosti. Naučna knjiga. Beograd. (Psychiatry of 
childhood and adolescence. Scientific books. Belgrade). 
Tremblay, R.E., Boulerice, B., Harden, P.W., McDuff, P., Perusse, D., Pihl, R.O., & 
Zoccolillo, M. (1996). Do children in Canada become more aggressive as they approach 
adolescence? In M. Cappe & I. Fellegi (Eds.), Growing up in Canada. Ottawa: Statistics 
Canada. 

Fadilj Eminovic and Sanja Dimoski 
 
362
Meadow, K. P. (1980). Deafness and child development. Berkeley, CA: University of 
California Press. 
Moffitt, T. E. (1993). Adolescence-limited and life-course-persistentantisocial behavior: A 
developmental taxonomy. Psychological Review. 100. 674–701. 
Moffitt,T.E., Caspi, A., Dickson, N., Silva, P.A., Stanton, W. (1996). Childhood-onset versus 
adolescent-onset antisocial conduct problems in males: Natural history from ages 3 to 18 
years.Development and Psychopathology. 8. 399-424. 
Moffitt,T.E., Caspi, A., Rutter, M. and Silva, P.A. (2001) Sex Differences in Antisocial 
Behaviour: Conduct Disorder, Delinquency, and Violence in the Dunedin Longitudinal 
Study. Cambridge University Press. 
Maes, B., & Grietens H. (2004). Parent-reported problem behavior among children with 
sensory disabilities attending elementary regular schools. Journal of Developmental and 
Physical Disabilities. 16. 361–375. 
Meerum Terwogt, M., & Rieffe, C. (2004). Behavioural problems in deaf children: Theory of 
mind delay or communication failure?. European Journal of Developmental Psychology. 
1. 231–240. 
Masten, A. S., Coatsworth, J. D., Neemann, J., Gest, S. D., Tellegen, A., & Garmezy, N. 
(1995). The structure and coherence of competence from childhood through adolescence. 
Child Development. 66. 1635–1659. 
Mitchell, T.V., & Quittner, A.L. (1996). Multimethod study of attention and behavior 
problems in hearing-impaired children. Journal of Clinical Child Psychology. 25(1). 83-
96. 
Mann, V. A., & Brady, S. (1988). Reading disability: The role of guage deficiencies. Journal 
of 'Consulting and Clinical Psychology. 56. 811-816. 
Maguin, E., & Loeber, R. (1996). Academic performance and delinquency. Crime and 
Justice: A Review of Research. 20. 145–264. 
Nagin, D., & Tremblay, R.E. (1999). Trajectories of boys' physical aggression, opposition, 
and hyperactivity on the path to physically violent and nonviolent juvenile delinquency. 
Child Development. 70(5).1181-96. 
Quirin M., & Lane R. D. (2012). The construction of emotional experience requires the 
integration of implicit and explicit emotional process. Behavioral and Brain Science. 35. 
159–160. 
Žunić-Pavlović, V., Kovačević-Lepojvić, M., Pavlović, M. (2009). Procena socijalnog 
funkcionisanja učenika u školskoj sredini. Nastava i vaspitanje. 3(1). 399-420. 
(Assessment of social functioning of students in the school environment. Teaching and 
Education.) 
Van Eldik, T. (1994). Behavior problems withdeaf Dutch boys. American Annals of the Deaf. 
139. 394–399. 
Van Eldik, T., Treffers, P. D. A., Veerman, J. W., & Verhulst, F. C. (2004). Mental health 
problems of Dutch children as indicated by parents’ responses to the Child Behavior 
Checklist. American Annals of the Deaf. 148. 390–395. 
Vostanis, P., Hayes, M., Di Feu, M., & Warren, J. (1997). Detection of behavioural and 
emotional problems in deaf children and adolescents: Comparison of two rating scales. 
Child Care, Health, and Development, 23, 233–246. 

Conduct Disorder in Children and Youth with Hearing Impairment 
 
363
Van Gent T., Goedhart, A.W., Hindley, P.A., & Treffers, P.D.A.(2007). Prevalence and 
correlates of psychopathology in a sample of deaf adolescents. Journal of Child 
Psychology and Psychiatry. 48. 950–58.  
Williams, S., & McGee, R. (1994). Reading attainment and juvenile delinquency. Journal of 
Child Psychology and Psychiatry. 35. 441–459. 
Wikstrom, P.O. (1991). Urban crime, criminals and victims. New York: Springer-Verlag. 
Wikstrom, P. O. (1998). Communities and crime. In M. Tonry (Ed.) The handbook of crime 
and punishment (pp. 269–301). NY: Oxford University Press. 
 


In: Encyclopedia of Audiology and Hearing Research 
ISBN: 978-1-53617-702-2 
Editors: Erno Larivaara and Senja Korhola 
© 2020 Nova Science Publishers, Inc. 
 
 
 
 
 
 
 
Chapter 28  
 
 
 
SUDDEN SENSORINEURAL HEARING LOSS AND 
POLYMORPHISMS IN IRON HOMEOSTASIS GENES 
 
 
D. Gemmati1, A. Castiglione2, M. Vigliano1,  
A. Ciorba3 and C. Aimoni3 
1Ctr. Hemostasis & Thrombosis, Dept. of Medical Sciences,  
University Hospital of Ferrara, Italy 
2ENT & Otosurgery Department, University Hospital of Padua, Italy 
3ENT & Audiology Department, University Hospital of Ferrara, Italy 
 
 
ABSTRACT 
 
Sudden sensorineural hearing loss (SSNHL) is an important cause of acquired 
hearing deficits in the adults. Several pathophysiological hypothesis have been proposed 
so far, however the cause of sudden hearing loss is still unclear. Even if local 
hypoxic/ischemic events as well as inner ear viral infection have been reported to be the 
main hypothesis leading to transient or permanent cochlear dysfunction, and therefore to 
Sudden Sensorineural Hearing Loss, still there are other hypothesis that have been 
claimed. 
Aim of the present study is to investigate about the possible role of iron metabolism, 
and in particular about the presence of genetic variants of the principal iron-related genes, 
and acute inner ear disorders such as sudden sensorineural hearing loss.  
 
 
INTRODUCTION 
 
Sudden sensorineural hearing loss (SSNHL) represents an acute inner ear disorder, 
mostly unilateral, that generally affect adults worldwide, even if higher occurrence rates are 
reported in developed countries [1, 2]. It has been estimated that SSNHL has an overall 
incidence rate of 5–20 / 100,000 individuals per year, though this is most likely an 
underestimate [2, 3].  
Several pathophysiological mechanisms for idiopathic SSNHL have been proposed in the 
literature. The most reported are: local hypoxic/ischemic events (such as coagulopathies, 

D. Gemmati, A. Castiglione, M. Vigliano et al. 
 
366
vascular hypotension and thrombo-embolism), autoimmune disorders, metabolic diseases, 
viral inner ear infections, rupture of the inner ear membranes, free radicals induced-damage, 
neuronal damage and dysregulation of the local inflammatory response [3-5] leading to 
transient or permanent dysfunction of cochlear microcirculation [6].  
Since iron has been linked to oxidative stress, we hypothesized that iron metabolism 
regulatory genes could have a role in the homeostasis of the oxidative balance also in the 
inner ear and, consequently, in the pathophysiology of acute inner ear disorders such as 
SSNHL. 
Aim of this chapter is to focus on the possible role of divalent metallic ions, and in 
particular on the presence of genetic variants of the principal iron-related genes, in the 
aetiopathogenesis of SSNHL [7].  
 
 
METHODS 
 
The Pubmed database was searched up to September 2014 (going back for 10 years); full 
text articles were obtained when the title, abstract or key words suggested that the study may 
be eligible for this study. The search was carried out independently, and restricted to papers in 
English language. Other papers were also identified from the references in the published 
literature.  
The medical subject heading (MeSH) used included: Sudden Sensorineural Hearing Loss, 
Iron metabolism, Iron Homeostasis, Iron genes, Oxidative stress, Inner ear. 
 
 
IRON METABOLISM AND OXIDATIVE STRESS  
 
There is a growing interest in the possible association between iron metabolism and 
oxidative stress, as it has been reported that local iron excess is a potential cause of increased 
oxidative stress and therefore could be involved in cellular injury and death. Iron is an 
essential nutrient, but its divalent form (Fe2+), as well as other divalent metal ions, also 
retains the capacity to enhance redox cycling and free radical formation [8, 9]. Iron-mediated 
oxidative stress is hypothesized to be involved in the pathogenesis of several degenerative 
disorders, including thrombosis, venous ulcers, chronic venous disease, and central nervous 
system disorders such as multiple sclerosis and other neurodegenerative diseases, or 
neoplasms [10-13]. In addition, a novel iron-driven aetiopathogenetic mechanism, responsible 
for increase free radical generation, has been formulated in degenerative skin lesions 
appearance comprehending coexistence of local iron overload and iron homeostasis gene 
variants [14]. Similar conditions could also be potentially associated with sudden hearing loss 
[15]. So, divalent ions homeostasis could be a central pathway involved in the 
pathophysiology of sudden hearing loss [16, 17, 18].  
The main genes and their variants that could be possibly involved in the 
aetiopathogenesis of SSNHL are described below [10, 19]. 
The HFE gene (6p21.3-22.2) encodes a membrane protein of 348 amino acids that 
belongs to the MHC class I family. The protein is normally expressed in cryptal enterocytes 
of the duodenum, liv-er, placenta, kidney, central nervous system, plasma and platelets. By 

Sudden Sensorineural Hearing Loss and Polymorphism ... 
 
367
complexing with beta 2 microglobulin and transferrin receptor 2 (TFR2), it plays a crucial 
role in iron homeostasis, and, when mutated, it is believed to be responsible for 
hemochromatosis, variegate porphyria and microvascular complications of diabetes. Gene 
variants and/or mutated proteins bind to the transferrin receptor and reduce its affinity for 
iron-loaded transferrin. Thus, they finally unbalance the iron intake. Recent increasing 
interest in neuro-degenerative disorders mediated by iron overload, have highlighted the HFE 
gene among candidates for further investigations into iron homeostasis involvement in similar 
conditions. A review of the literature suggests a potential role even in iron-mediated hearing 
loss also in the past [20, 21]. Finally, it is important to note that the HFE gene is also 
expressed in the brain, spinal cord, cortex and cerebellum [22, 23]. Thus, it could be directly 
involved or responsible for specific conditions concerning the central nervous system. 
The FPN1 (SLC40A1) gene is located on chromosome 2 (2q32.2), and it encodes a 
protein (ferro-portin) of 570 amino acids with the specific function of exporting iron out from 
cells in the basolateral space, except for the reticulo-endothelial cells, which can spread iron 
ions into the blood circulation. Consequently, FPN1 plays a crucial role in iron homeostasis 
[24], and, generally, it has the opposite function of the divalent metal transporter 1 (DMT1) 
protein product [25], which allows intracellular passage of divalent iron (Fe2+). Ferroportin is 
expressed in different tissues, brain and spinal cord included, though to the best of our 
knowledge, there are no previous reported studies that document its localization specifically 
into the cochlea. Similar to other iron genes, it undergoes iron regulation at the transcriptional 
and translational level [26-28]. 
Another important gene related to ferroportin expression and function is the HEPC gene 
(19q13.1) encoding the protein Hepcidin Anti-Microbial Peptide (HAMP). This protein is a 
25-amino acid peptide, derived from the cleavage of an 84-amino-acid long pro-peptide that 
is mainly synthesized by hepatocytes, but it is expressed also in brain, spinal cord, cortex and 
cerebellum included. HEPC is the major regulator of iron balance activity via binding to the 
FPN1 protein on the cell membrane, sup-pressing it [29, 30]. HEPC expression and its role in 
iron homeostasis may play a crucial role in dif-ferent conditions [31].  
The TF gene (3q22.1) encodes for the protein transferrin, which forms a stable complex 
with the HFE protein, which facilitates iron transfer via the transferrin receptor. The function 
of this protein is to transport iron from the intestine, reticuloendothelial system, and liver 
parenchymal cells to all proliferating cells in the body. Tansferrin is expressed in different 
tissues, brain, spinal cord included, cortex and cerebellum included. The effect of HFE on 
iron absorption depends on its relationship with the transferrin receptor. HFE variants affect 
TF binding, determining a loss of HFE-repressor function for TF uptake, thereby increasing 
iron transport within the cells [32-34]. 
 
 
IRON METABOLISM AND THE INNER EAR  
 
Sudden hearing loss has been reported to be associated with a huge number of clinical 
conditions and its aetiopathogenesis is still unclear [35-38]. The uncertainty of reasonable 
etiologies has encouraged continuous investigations aimed at identifying the most convincing 
pathological explanations. Far from the identification of an unequivocal mutated gene, the 
study of genetic variants of several conditions has attracted several researchers even if a 

D. Gemmati, A. Castiglione, M. Vigliano et al. 
 
368
specific correlation between a precise inner ear gene mutation and SSNHL still has to be 
proved. Some studies have reported a correlation of various polymorphisms with an increased 
[39-43] or reduced [44] risk of developing hearing impairment.  
Recent findings concerning ROS-mediated damage, NO activity and inner ear iron 
metabolism have encouraged researchers to focus their studies on possible connections 
between microvascular damage and free radical production in the inner ear [45-47, 49]. In this 
sense, some have speculated that polymorphisms of genes related to iron metabolism, such as 
FPN1 (SLC40A1) gene, the HFE gene or the TF gene, could be involved in the pathogenesis 
of some acute inner ear disorders, such as sudden sensorineural hearing loss [47,48,49]. Of 
particular interesting are the observations among iron metabolism within the stria vascularis. 
Stria vascularis is particular sensitive to free radical stress due to its high metabolic activity 
and dense vascular system [50], and, consequently, when iron cheletor proteins are not 
adequately functioning to contrast and neutralize the damaging effect of iron and linked free 
radicals, its function can be dramatically impaired, therefore hampering inner ear homeostasis 
[50]. The significant presence of ferritin [47] and DMT1 [48,49], within the cochlear stria, 
suggest that these proteins have an active role in restoration and deposition of iron, and can 
retain a role in reducing the endolymphatic concentration of divalent ions [51, 52]. In fact, 
preliminary experimental studies on mouse models have shown that free radical stress, 
induced by the loss of specific protein expression related to iron metabolism in stria 
vascularis, cause hearing loss [18]. It is possible to speculate that polymorphism of genes 
related to iron metabolism such as FPN1 (SLC40A1) gene, or of the HFE gene or the TF 
gene, could possibly contribute in altering the inner ear oxidative homeostasis. 
Apart from the stria vascularis, the exact location of the proteins involved in the 
metabolism of iron, within other inner ear settings, is still not clear. The identification of their 
position could offer indications in understanding how iron metabolism works within the inner 
ear oxidative homeostasis.  
Unfortunately, the knowledge among the iron metabolism within the inner ear is still very 
limited; further experimental studies are necessary in order to understand which could be its 
role within the inner ear homeostasis. 
 
 
IRON METABOLISM AND SUDDEN SENSORINEURAL HEARING LOSS 
 
So far, there are no clinical evidences to support this association, clinically. Only very 
few studies have claimed a relationship between these two conditions. In particular, Chung et 
al. have observed a relation between SSNHL and iron deficiency anemia [53]. Also, Sun et al. 
described significant improvements in clinical results using iron therapy in patients with 
SSNHL [54]. However, their clinical success only warranted the use of iron therapy in 
managing SSNHL, and their limited case numbers meant that the relationship between 
patients affected by iron deficiency anemia and SSNHL should still be further elucidated [54]. 
Even if the few available studies on animal models seem to encourage this hypothesis as 
described in the previous paragraph, the aetiopathogenetic mechanism that links the onset of 
an acute inner ear disorder, such as SSNHL, and iron metabolism is still far to be understood, 
though it can be an intriguing hypothesis.  
 

Sudden Sensorineural Hearing Loss and Polymorphism ... 
 
369
CONCLUSION 
 
In conclusion, clinical and genetic studies are required to further elucidate the 
pathophysiological mechanisms of SSNHL. Such a complex disease is to consider a 
multifactorial and polygenic condition in which gene-environment interactions have a key 
role. In particular, considering the possible link between iron metabolism and inner ear 
oxidative stress, more efforts should be performed in order to better understand the complex 
biochemical environment and mechanisms of the inner ear.  
 
 
REFERENCES 
 
[1] 
Nakashima T, Itoh A, Misawa H, Ohno Y. Clinicoepidemiologic features of sudden 
deafness diagnosed and treated at university hospitals in Japan. Otolaryngol Head Neck 
Surg. 2000;123(5):593-7. 
[2] 
Olzowy B, Osterkorn D, Suckfull M. [The incidence of sudden hearing loss is greater 
than previously assumed]. MMW Fortschritte der Medizin. 2005;147(14):37-8. 
[3] 
Aimoni C, Bianchini C, Borin M, Ciorba A, Fellin R, Martini A, et al. Diabetes, 
cardiovascular risk factors and idiopathic sudden sensorineural hearing loss: a case-
control study. Audiol Neurootol. 2010;15(2):111-5. 
[4] 
Zajtchuk JT, Falor WH, Jr., Rhodes MF. Hypercoagulability as a cause of sudden 
neurosensory 
hearing 
loss. 
Otolaryngology 
and 
head 
and 
neck 
surgery. 
1979;87(2):268-73. 
[5] 
Yildiz Z, Ulu A, Incesulu A, Ozkaptan Y, Akar N. The importance of thrombotic risk 
factors in the development of idiopathic sudden hearing loss. Clinical and applied 
thrombosis/hemostasis: Official journal of the International Academy of Clinical and 
Applied Thrombosis/Hemostasis. 2008;14(3):356-9. 
[6] 
Yoon TH, Paparella MM, Schachern PA, Alleva M. Histopathology of sudden hearing 
loss. The Laryngoscope. 1990;100(7):707-15. 
[7] 
Garrick MD. Human iron transporters. Genes & nutrition. 2011;6(1):45-54. 
[8] 
Zheng G, Chen J, Zheng W. Relative contribution of CTR1 and DMT1 in copper 
transport by the blood-CSF barrier: implication in manganese-induced neurotoxicity. 
Toxicology and applied pharmacology. 2012;260(3):285-93. 
[9] 
Liu X, Zheng G, Wu Y, Shen X, Jing J, Yu T, et al. Lead exposure results in hearing 
loss and disruption of the cochlear blood-labyrinth barrier and the protective role of 
iron supplement. Neurotoxicology. 2013;39:173-81. 
[10] Gemmati D, Zeri G, Orioli E, De Gaetano FE, Salvi F, Bartolomei I, et al. 
Polymorphisms in the genes coding for iron binding and transporting proteins are 
associated with disability, severity, and early progression in multiple sclerosis. BMC 
medical genetics. 2012;13:70. 
[11] Williams BB, Kwakye GF, Wegrzynowicz M, Li D, Aschner M, Erikson KM, et al. 
Altered manganese homeostasis and manganese toxicity in a Huntington's disease 
striatal cell model are not explained by defects in the iron transport system. 
Toxicological sciences: an official journal of the Society of Toxicology. 
2010;117(1):169-79. 

D. Gemmati, A. Castiglione, M. Vigliano et al. 
 
370
[12] Mills E, Dong XP, Wang F, Xu H. Mechanisms of brain iron transport: insight into 
neurodegeneration and CNS disorders. Future medicinal chemistry. 2010;2(1):51-64. 
[13] Gemmati D, Federici F, Catozzi L, Gianesini S, Tacconi G, Scapoli GL, et al. DNA-
array of gene variants in venous leg ulcers: detection of prognostic indicators. Journal 
of vascular surgery. 2009;50(6):1444-51. 
[14] Zamboni P, Izzo M, Tognazzo S, Carandina S, De Palma M, Catozzi L, et al. The 
overlapping of local iron overload and HFE mutation in venous leg ulcer pathogenesis. 
Free radical biology & medicine. 2006;40(10):1869-73. 
[15] Yamasoba T, Sakai K, Sakurai M. Role of acute cochlear neuritis in sudden hearing 
loss in multiple sclerosis. Journal of the neurological sciences. 1997;146(2):179-81. 
[16] Wink DA, Hines HB, Cheng RY, Switzer CH, Flores-Santana W, Vitek MP, et al. 
Nitric oxide and redox mechanisms in the immune response. Journal of leukocyte 
biology. 2011;89(6):873-91. 
[17] Brissot P, Ropert M, Le Lan C, Loreal O. Non-transferrin bound iron: a key role in iron 
overload and iron toxicity. Biochimica et biophysica acta. 2012;1820(3):403-10. 
[18] Singh R, Wangemann P. Free radical stress-mediated loss of Kcnj10 protein expression 
in stria vascularis contributes to deafness in Pendred syndrome mouse model. 
American journal of physiology Renal physiology. 2008;294(1):F139-48. 
[19] Singh AV, Subhashree L, Milani P, Gemmati D, Zamboni P. Interplay of iron 
metallobiology, metalloproteinases, and FXIII, and role of their gene variants in venous 
leg ulcer. The international journal of lower extremity wounds. 2010;9(4):166-79. 
[20] Sun AH, Wang ZM, Xiao SZ, Li ZJ, Ding JC, Li JY, et al. Idiopathic sudden hearing 
loss and disturbance of iron metabolism. A clinical survey of 426 cases. ORL; Journal 
for oto-rhino-laryngology and its related specialties. 1992;54(2):66-70. 
[21] Sun AH, Wang ZM, Xiao SZ, Li ZJ, Zheng Z, Li JY. Sudden sensorineural hearing 
loss induced by experimental iron deficiency in rats. ORL; Journal for oto-rhino-
laryngology and its related specialties. 1992;54(5):246-50. 
[22] Hanninen MM, Haapasalo J, Haapasalo H, Fleming RE, Britton RS, Bacon BR, et al. 
Expression of iron-related genes in human brain and brain tumors. BMC neuroscience. 
2009;10:36. 
[23] Johnstone D, Graham RM, Trinder D, Delima RD, Riveros C, Olynyk JK, et al. Brain 
transcriptome perturbations in the Hfe(-/-) mouse model of genetic iron loading. Brain 
research. 2012;1448:144-52. 
[24] Mao J, McKean DM, Warrier S, Corbin JG, Niswander L, Zohn IE. The iron exporter 
ferroportin 1 is essential for development of the mouse embryo, forebrain patterning 
and neural tube closure. Development. 2010;137(18):3079-88. 
[25] Bai SP, Lu L, Luo XG, Liu B. Cloning, sequencing, characterization, and expressions 
of divalent metal transporter one in the small intestine of broilers. Poultry science. 
2008;87(4):768-76. 
[26] Ward DM, Kaplan J. Ferroportin-mediated iron transport: expression and regulation. 
Biochimica et biophysica acta. 2012;1823(9):1426-33. 
[27] Gardenghi S, Marongiu MF, Ramos P, Guy E, Breda L, Chadburn A, et al. Ineffective 
erythropoiesis in beta-thalassemia is characterized by increased iron absorption 
mediated by down-regulation of hepcidin and up-regulation of ferroportin. Blood. 
2007;109(11):5027-35. 

Sudden Sensorineural Hearing Loss and Polymorphism ... 
 
371
[28] Troadec MB, Ward DM, Lo E, Kaplan J, De Domenico I. Induction of FPN1 
transcription by MTF-1 reveals a role for ferroportin in transition metal efflux. Blood. 
2010;116(22):4657-64. 
[29] Zhang DL, Senecal T, Ghosh MC, Ollivierre-Wilson H, Tu T, Rouault TA. Hepcidin 
regulates ferroportin expression and intracellular iron homeostasis of erythroblasts. 
Blood. 2011;118(10):2868-77. 
[30] Ganz T. Molecular control of iron transport. Journal of the American Society of 
Nephrology: JASN. 2007;18(2):394-400. 
[31] Ding H, Yan CZ, Shi H, Zhao YS, Chang SY, Yu P, et al. Hepcidin is involved in iron 
regulation in the ischemic brain. PloS one. 2011;6(9):e25324. 
[32] Haberkamp TJ, Tanyeri HM. Management of idiopathic sudden sensorineural hearing 
loss. Am J Otol. 1999;20(5):587-92; discussion 93-5. 
[33] Clark JG. Uses and abuses of hearing loss classification. Asha. 1981;23(7):493-500. 
[34] Tran Ba Huy P, Sauvaget E. [Idiopathic sudden sensorineural hearing loss is not, at this 
time, an otologic emergency]. Ann Otolaryngol Chir Cervicofac. 2007;124(2):66-71. 
[35] Young YH, Lou PJ. Post-irradiation sudden deafness. J Laryngol Otol. 
1999;113(9):815-7. 
[36] Yossepowitch O, Lossos A, Lossos IS. Sudden hearing loss following acute hepatitis. 
Postgraduate medical journal. 1999;75(883):309-12. 
[37] Yoshimoto Y. Clinico-statistical study on acoustic tumors with sudden hearing loss. 
Auris Nasus Larynx. 1988;15(3):165-71. 
[38] Yin T, Huang F, Ren J, Liu W, Chen X, Li L, et al. Bilateral sudden hearing loss 
following habitual abortion: a case report and review of literature. International journal 
of clinical and experimental medicine. 2013;6(8):720-3. 
[39] Uchida Y, Sugiura S, Ando F, Shimokata H, Nakashima T. Association of the C677T 
polymorphism in the methylenetetrahydrofolate reductase gene with sudden 
sensorineural hearing loss. The Laryngoscope. 2010;120(4):791-5. 
[40] Uchida Y, Sugiura S, Nakashima T, Ando F, Shimokata H. Contribution of 1425G/A 
polymorphism in protein kinase C-Eta (PRKCH) gene and brain white matter lesions to 
the risk of sudden sensorineural hearing loss in a Japanese nested case-control study. 
Journal of neurogenetics. 2011;25(3):82-7. 
[41] Uchida Y, Teranishi M, Nishio N, Sugiura S, Hiramatsu M, Suzuki H, et al. 
Endothelin-1 gene polymorphism in sudden sensorineural hearing loss. The 
Laryngoscope. 2013;123(11):E59-65. 
[42] Teranishi M, Uchida Y, Nishio N, Kato K, Otake H, Yoshida T, et al. Polymorphisms 
in genes involved in the free-radical process in patients with sudden sensorineural 
hearing loss and Meniere's disease. Free radical research. 2013;47(6-7):498-506. 
[43] Capaccio P, Ottaviani F, Cuccarini V, Ambrosetti U, Fagnani E, Bottero A, et al. 
Sudden hearing loss and MTHFR 677C>T/1298A>C gene polymorphisms. Genetics in 
medicine: official journal of the American College of Medical Genetics. 2005;7(3):206-
8. 
[44] Cho SH, Chen H, Kim IS, Yokose C, Kang J, Cho D, et al. Association of the 4 g/5 g 
polymorphism of plasminogen activator inhibitor-1 gene with sudden sensorineural 
hearing loss. A case control study. BMC ear, nose, and throat disorders. 2012;12:5. 

D. Gemmati, A. Castiglione, M. Vigliano et al. 
 
372
[45] Zhang Z, Zhang F, An P, Guo X, Shen Y, Tao Y, et al. Ferroportin1 deficiency in 
mouse macrophages impairs iron homeostasis and inflammatory responses. Blood. 
2011;118(7):1912-22. 
[46] Liu X-b, Hill P, Haile DJ. Role of the Ferroportin Iron-Responsive Element in Iron and 
Nitric Oxide Dependent Gene Regulation. Blood Cells, Molecules, and Diseases. 
2002;29(3):315-26. 
[47] Santos-Sacchi J, Marovitz WF. A ferritin-containing cell type in the stria vascularis of 
the mouse inner ear. Acta Otolaryngol. 1985;100(1-2):26-32. 
[48] Ding D, Salvi R, Roth JA. Cellular localization and developmental changes of the 
different isoforms of divalent metal transporter 1 (DMT1) in the inner ear of rats. 
Biometals: an international journal on the role of metal ions in biology, biochemistry, 
and medicine. 2013. 
[49] Mazurek B, Amarjargal N, Haupt H, Fuchs J, Olze H, Machulik A, et al. Expression of 
genes implicated in oxidative stress in the cochlea of newborn rats. Hearing research. 
2011;277(1-2):54-60. 
[50] Marcus DC, Thalmann R, Marcus NY. Respiratory rate and ATP content of stria 
vascularis of guinea pig in vitro. The Laryngoscope. 1978;88(11):1825-35. 
[51] Hansen JB, Tonnesen MF, Madsen AN, Hagedorn PH, Friberg J, Grunnet LG, et al. 
Divalent metal transporter 1 regulates iron-mediated ROS and pancreatic beta cell fate 
in response to cytokines. Cell metabolism. 2012;16(4):449-61. 
[52] Abouhamed M, Wolff NA, Lee WK, Smith CP, Thevenod F. Knockdown of 
endosomal/lysosomal divalent metal transporter 1 by RNA interference prevents 
cadmium-metallothionein-1 cytotoxicity in renal proximal tubule cells. American 
journal of physiology Renal physiology. 2007;293(3):F705-12. 
[53] Chung SD, Chen PY, Lin HC, Hung SH. Sudden sensorineural hearing loss associated 
with iron-deficiency anemia: a population-based study. JAMA Otolaryngol Head Neck 
Surg. 2014 May;140(5):417-22. 
[54] Sun AH,Wang ZM, Xiao SZ, et al. Idiopathic sudden hearing loss and disturbance of 
iron metabolism: a clinical survey of 426 cases. ORL J Otorhinolaryngol Relat Spec. 
1992;54(2):66-70. 
 

In: Encyclopedia of Audiology and Hearing Research 
ISBN: 978-1-53617-702-2 
Editors: Erno Larivaara and Senja Korhola 
© 2020 Nova Science Publishers, Inc. 
 
 
 
 
 
 
 
Chapter 29 
 
 
 
CHRONIC TINNITUS: PITH, LOUDNESS, AND 
DISCOMFORT IN ADULTS AND ELDERLY PATIENTS 
 
 
Adriane Ribeiro Teixeira1, Letícia Petersen Schmidt Rosito2,  
Bruna Macagnin Seimetz3, Celso Dall’Igna4  
and Sady Selaimen da Costa5  
1Department of Human and Communication Disorders –  
Federal University of Rio Grande do Sul – Brazil 
2Surgical Clinic, Hospital Clinics of Porto Alegre – Brazil 
3Federal University of Rio Grande do Sul – Brazil 
4Department of Ophthalmology and Otorhinolaryngology –  
Federal University of Rio Grande do Sul – Brazil 
5Department of Ophthalmology and Otorhinolaryngology –  
Federal University of Rio Grande do Sul – Brazil 
 
 
ABSTRACT 
 
Tinnitus is a common symptom in individuals of various age groups, but the impact 
it causes is variable, depending on the characteristics of subjects. The aim of this study is 
to analyze the characteristics of tinnitus and the discomfort it causes in individuals 
assessed in a specific outpatient clinic in a tertiary hospital. Participants were evaluated 
by medical history interview, medical examination, grading of tinnitus severity, hearing 
screening and testing, measurement of tinnitus pitch and loudness and THI instrument for 
identifying tinnitus discomfort. The sample consisted of 199 individuals; 124 of them 
(62.30%) were females, with a mean age of 58.18 ± 12.79 years, with bilateral tinnitus 
(50.8%) and average length of tinnitus presence was 5.18 ± 4.67 years. Tinnitus pitch was 
acute and tinnitus loudness was moderate, within the values reported in the technical 
literature. Mean tinnitus severity was 5.18 ± 4.67 years and the THI score ranged from 0 
to 98 points (mean 40.03 ± 25.48 points). No difference was observed between THI 
scores and sex and tinnitus location. Correlation was observed between tinnitus severity 
                                                        
 Corresponding Author’s Email: adriane.teixeira@gmail.com. 

A. R. Teixeira, L. Petersen Schmidt Rosito, B. Macagnin Seimetz et al. 
 
374
and THI scores, between age and tinnitus loudness in the left ear, and between age and 
THI scores. 
INTRODUCTION 
 
Tinnitus is a common symptom in medical and audiological exams. It is defined as the 
sound perceived by the subject without an external source being present. [1,2] It may be 
caused by otological, neurological, cardiovascular, rheumatological, endocrine, metabolic and 
immune diseases. Trauma, temporomandibular joint disorders, psychological problems and 
use of ototoxic medication are also causes of tinnitus. [2,3] 
Tinnitus can be graded in several ways. Tinnitus can be considered as subjective 
(perceived only by the affected individual) or objective (perceived by others), continuous or 
intermittent, pulsatile or non-pulsatile, unilateral or bilateral or located in the center of the 
head. The onset may be sudden or insidious. [2,4] Grading is used by health professionals to 
categorize the symptom as shown by individuals. It assists in determining etiology and 
treatment. 
The prevalence of tinnitus varies depending on the population studied. A study conducted 
in South Korea showed that 19.7% of individuals aged 12 years or older had the symptom. [5] 
Another study with Japanese elderly showed that 18.7% of them had tinnitus. [6] In Egypt, 
the prevalence was 5.17% and in the United States, 25.3%. [7, 8] The prevalence of tinnitus 
in the elderly is higher than in adults, with values ranging between 33% and 72.5%. [9,10] 
General data show that in 2004, tinnitus affected 15% of the world population, [11] and its 
prevalence increased to 25.3% in 2012. [12] 
Although it is a more frequent complaint by adults and the elderly, children can also have 
tinnitus. Research conducted in Brazil showed a high prevalence of tinnitus in children. In a 
study that evaluated 477 children, continuous tinnitus was found in 21.7% and pulsatile 
tinnitus in 3.8% of them. [13] Another more recent study showed that 54.7% of the children 
interviewed had had tinnitus for the past 12 months. [12] 
The relationship between tinnitus and gender of affected individuals is still controversial 
in the literature. [14] Some studies showed a similar number of affected individuals, [6, 14] 
while others showed a higher prevalence of women [10, 15, 16] or men. [17, 18, 19] 
Despite the high prevalence of tinnitus, the discomfort it causes is variable, because some 
individuals reported tinnitus but their activities were not affected by the symptom, while 
others reported severe problems. [2, 19] It is believed that approximately 20% of tinnitus 
patients feel discomfort. [20] Factors such as personality traits, depression, anxiety, difficulty 
in dealing with problems, and concentration difficulties influence the level of discomfort 
caused by tinnitus. [21, 22] It is actually a prognostic factor for treatment.23 Thus, primary 
psychological factors influence the level of discomfort and the result in the treatment of 
tinnitus. [4, 14, 20] Patients' concern about tinnitus is crucial for adapting to it, and there may 
be a vicious circle that patients cannot cope with. [14] 
On the same line of reasoning, depression can be caused by tinnitus, but it can also be 
indicative of poor adaptation to it. [24] Likewise, sleep disorders may be caused by tinnitus, 
but they could also exist prior to the appearance of the symptom, i.e., they could be a 
comorbidity rather than a consequence of it. [14] These and other disorders (anxiety and 
stress, for example) lead to loss of quality of life, which is widely described in the literature. 
[2, 23, 25, 26] However, in a study with subjects outside the hospital or clinical environment, 
there was no influence of tinnitus on quality of life. [17] This seems to reinforce the idea that 

Chronic Tinnitus 
 
375
the discomfort and the consequences of tinnitus are related to the psychological aspects of 
individuals. 
Research conducted to date showed no influence of the variables age and gender on 
discomfort caused by tinnitus. [14, 20] 
The evaluation of individuals with tinnitus aims to define the etiology and treatment of it. 
It is supposed to include detailed history, physical examination, laboratory tests, audiological 
evaluation and radiological assessment. [27] Moreover, questionnaires should be used to 
determine the impact of tinnitus on a patient's life. The Tinnitus Handicap Inventory (THI) is 
one of the most used, and it has already been translated, adapted and validated into several 
languages. Originally created in the English language, [28] it has versions in Brazilian 
Portuguese [29], Chinese - Mandarin and Cantonese [30, 31], French, [32] Italian, [33] 
Spanish, [34] Filipino [35] and Persian, [36] among others. 
THI is composed of 25 questions for assessing the effects of tinnitus in the restriction of 
daily activities of affected individuals. [37] There are three types of response for each 
situation: Yes (4 points), Sometimes (2 points) or No (0 points). The sum of points obtained 
in each response allows one to assess the level of discomfort caused by the symptom: slight 
(0-16 points), mild (18-36 points), moderate (38-56 points), severe (58 to 76 points) and 
catastrophic (78-100 points). [14] Because it is quick and easy to apply and interpret, 
addresses the influence of tinnitus on a patient's life, and has adequate validity and reliability, 
THI is routinely used in the clinical evaluation of patients. [28, 38]  
Although tinnitus is studied by researchers from various countries, further research about 
tinnitus and its effects is still needed, especially in light of the contradictions in the literature. 
Thus, the objective of this study is to analyze the characteristics of tinnitus and the discomfort 
it causes in subjects evaluated in a specific outpatient clinic in a tertiary hospital.  
 
 
METHODOLOGY 
 
This was a cross-sectional study conducted in a tertiary care hospital in southern Brazil. 
The sample consisted of both male and female patients suffering from chronic tinnitus and 
history of tinnitus discomfort, who were seen in a specific outpatient clinic. The presence of 
the symptom for a period of time greater than six months was defined as chronic tinnitus. [26] 
Patients were evaluated by otolaryngologists and audiologists who determine the 
presence of hearing loss, tinnitus characteristics, the etiology of it and the presence of other 
comorbidities, such as depression, anxiety, metabolic disorders, etc. 
ENT evaluation consisted of medical history interview, physical examination and 
otoscopy. After that, patients wree evaluated by audiologists through pure tone audiometry 
testing of hearing thresholds for high frequencies and conventional frequencies, speech 
audiometry, acuphenometry, measurement of loudness discomfort levels and acoustic 
immitance. Next, patients underwent laboratory tests and imaging tests, if necessary. 
The medical history interview, conducted through oral questions to be answered by 
patients, investigated sociodemographic data (age, gender, race), health history (diseases, 
medication use) and tinnitus history (length of symptom presence, laterality, improvement or 
worsening factors, etc.). Patients were also asked about tinnitus severity. Patients were asked: 

A. R. Teixeira, L. Petersen Schmidt Rosito, B. Macagnin Seimetz et al. 
 
376
“On a 0-10 scale, how much does tinnitus bother you in your life?”. After that, the version of 
the THI instrument that was validated and translated into Portuguese. [29]  
Then, patients underwent audiological evaluation, and a complete audiological evaluation 
was made. At first, all patients underwent pure tone audiometry; conventional frequencies and 
high frequencies were measured. The examination was conducted in a soundproof booth, and 
thresholds were measured by air (250Hz to 16000Hz) and bone conduction (500Hz to 
4000Hz). Then, acuphenometry was performed. It is a subjective measurement of tinnitus 
pitch and loudness, since it is not possible to objectively measure the intensity and frequency 
of the symptom.  
Pitch corresponds to the sense of frequency and loudness to the sense of intensity of 
tinnitus reported by the patient. Patients were asked to compare their tinnitus to sounds 
emitted by the audiometer (pure tone or narrow band noise). [39] Acuphenometry was 
performed according to the procedure described by Branco-Barreiro. [40] Initially, pitch was 
measured. The hearing threshold of patients was selected in all frequencies, 10dBNA were 
added, and either pure tone or noise was presented, depending on patients’ description of the 
characteristics of their tinnitus. Patients was asked to raise their hand when they realized that 
the sound they heard was similar to their tinnitus. After that, loudness was measured. The 
stimulus (pure tone or noise) was presented at the frequency indicated by the patient as 
similar to tinnitus, with initial intensity of 10dBNA below the patient's threshold. Then, 
intensity was increased 2dBNA at a time, and patients were asked to raise their hand at the 
time realized that the intensity presented was similar to that of their tinnitus. Such intensity 
was recorded and subtracted from the individual's hearing threshold. This calculation 
determined tinnitus loudness. 
After that, the following measurements were performed: loudness discomfort levels, 
acoustic immitance, with tympanometry and contralateral and ipsilateral acoustic reflexes, 
transient evoked otoacoustic emissions and distortion product otoacoustic emissions. In 
specific situations, patients were evaluated for auditory evoked potentials. 
After the completion of all tests, the subjects underwent medical evaluation again to 
determine the etiology and appropriate treatment for each case. 
This study focuses on results of the evaluation of patients through acuphenometry, 
considering tinnitus pitch and loudness. Patients who had all assessments described above 
were included in the study.  
The analysis was done by descriptive quantitative statistics, considering the absolute and 
relative values of the variables studied. The comparison of the results for THI between the 
groups used non-parametric tests (Mann-U-Whitney and Kruskal-Wallis), because the 
variable follows a non-normal distribution. To study the correlations between variables, the 
Spearman correlation coefficient was used. 
 
 
RESULTS 
 
Examinations were evaluated for 199 patients seen at the chronic tinnitus outpatient 
clinic. According to data shown in Table 1, the highest prevalence was in females (62.3%), 
the mean age was 58.18 ± 12.79 years, with bilateral tinnitus (50.8%). The length of presence 
of the symptom ranged from less than one year to 32 years, with a mean time of 5.18 ± 4.67 

Chronic Tinnitus 
 
377
years. Mean tinnitus pitch in both ears was approximately 4000Hz, while mean loudness was 
approximately 15dBNA. THI scores showed a mean of 40.03 ± 25.48. However, the analysis 
of grading by the instrument showed a greater number of individuals with slight, mild and 
moderate discomfort levels. In comparison, the grading of tinnitus severity, by the question 
about this, showed that subjects graded the discomfort caused by tinnitus between 2 and 10 
points, averaging 5.18 ± 4.67 points. 
 
Table 1. Descriptive analysis of the sample 
 
Variables 
N 
% 
Gender 
Male 
75 
62.3 
Female 
124 
37.7 
Age (years) 
Average ± standard deviation 
58.18 ± 12.79 
 
Minimum - Maximum 
19 - 82 
 
Time of tinnitus (years) 
Average ± standard deviation 
5.18 ± 4.67 
 
Minimum - Maximum 
0 – 32 
 
Location of tinnitus 
Right ear 
47 
23.6 
Left ear 
51 
25.6 
Both ears 
101 
50.8 
Pitch of tinnitus (Hz) 
Right ear 
 
 
Average ± standard deviation 
4359.80 ± 2735.54 
 
Minimum - Maximum 
250 - 8000 
 
Left ear  
 
 
Average ± standard deviation 
4458.88 ± 2678.63 
 
Minimum - Maximum 
250 -9000 
 
Loudness of tinnitus (dB) 
Right ear 
 
 
Average ± standard deviation 
16.65 ± 14.99 
 
Minimum - Maximum 
0 -75 
 
Left ear 
 
 
Average ± standard deviation 
15.84 ± 14.05 
 
Minimum - Maximum 
0 - 70 
 
Score THI 
Average ± standard deviation 
40.03 ± 25.48 
 
Minimum - Maximum 
0 - 98 
 
Classification THI 
Slight 
44 
22.1 
Mild 
62 
31.2 
Moderate 
41 
20.6 
Severe 
31 
15.6 
Catastrophic 
21 
10.6 
Gravity of tinnitus  
Average ± standard deviation 
5.18 ± 4.67 
 
Minimum - Maximum 
2 - 10 
 
 

A. R. Teixeira, L. Petersen Schmidt Rosito, B. Macagnin Seimetz et al. 
 
378
Correlation was analyzed between the variables THI score, age, tinnitus length, tinnitus 
severity, tinnitus pitch and tinnitus loudness (Table 2 and Table 3). There was a positive 
correlation between tinnitus severity and THI score (r = 0.32, p <0.001) and negative and 
statistically significant correlations between age and THI score (r = -0.254, p <0.001), and 
between age and tinnitus loudness in the left ear (r = -0.18, p = 0.02). There were no 
correlations between other variables: age and length of tinnitus (r = 0.08, p = 0.24), age and 
tinnitus severity (r = 0.11, p = 0.11), age and tinnitus pitch and tinnitus loudness in the right 
ear (r = -0.03, p = 0.67 and r = -0.18, p = 0.29, respectively), age and tinnitus pitch in the left 
ear (r = 0, 02, p = 0.80), length of tinnitus and THI score (r = 0.01, p = 0.78), length of 
tinnitus presence and tinnitus severity (r = -0.06; p = 0.38), length of tinnitus presence and 
tinnitus pitch and loudness in the right ear (r = -0.06, p = 0.43 and r = -0.24, p = 0.78, 
respectively) and in the left ear (r = -, 014, p = 0.06 and r = -0.33, p = 0.68, respectively). 
Tinnitus severity was not associated with length of tinnitus presence (r = -0.06, p = 0.38), nor 
with tinnitus pitch and loudness in the right ear (r = 0.00, p = 0, 91 r = -0.32, p = 0.70, 
respectively) and in the left ear (r = -0.49, p = 0.55 and r = 0.03, p = 0.63, respectively).  
 
Table 2. Analysis of the correlation between gender and scores on THI 
 
 
THI score 
 
Average 
Median 
Minimum 
Maximum 
Female 
40.3 
36 
0 
98 
Male 
39.6 
36 
0 
90 
p-value – 0,82 (Mann-Whitney) 
 
Table 3. Location of the THI score and tinnitus 
 
 
THI Score 
 
Average 
Median 
Minimum 
Maximum 
Right ear 
40.4 
36 
6 
96 
Left Ear 
37.8 
32 
0 
98 
Both ears 
41.0 
36 
0 
90 
p-value – 0,69 (Kruskal-Wallis) 
 
 
 
Discussion 
 
The results obtained in the study show that the sample was composed mostly by females. 
This finding is in disagreement with some studies that showed a similar number of men and 
women, [14] or a greater number of men,17-19 but it is equivalent to others. [10, 15, 16] In the 
study group, women may be considered to be more affected by tinnitus, but the data may also 
reflect a situation that Brazilian women seek health services more often. [41, 42] 
The age of the studied subjects ranged between 19 and 82 years, with a mean of 58.18 ± 
12.79 years. It was found that 121 (60.80%) patients were younger than 65 years old, which is 
indicative that the sample consisted primarily of adults, similar to samples of other recent 
studies. [18,26] The lower presence of elderly in the sample was not expected by the 

Chronic Tinnitus 
 
379
researchers, since the literature reports an increase in the symptom with aging, [9] but it can 
be indicative of two possibilities. One is the decrease of the current age of individuals 
affected by tinnitus who seek specialized care. Another possibility to explain the age of 
treated patients is the association between tinnitus and resilience. Patients who complain 
about tinnitus and discomfort are seen in the outpatient clinic. It is known that elderly people 
have higher levels of resilience than adults, and that greater resilience is associated with less 
discomfort caused by tinnitus. A study on resilience showed that it is associated with better 
emotional health, which, in turn, stops tinnitus from having such a negative impact on quality 
of life. [23] 
No children and adolescents were evaluated, although the technical literature reported 
that tinnitus can be observed in individuals of various age groups, and there is a high 
prevalence of children with the symptom. [12, 13] This can be explained by the fact that 
parents do not always know the complaints and otologic symptoms of their children, and the 
latter rarely report tinnitus spontaneously. [13] Thus, it is crucial for parents and health 
professionals who evaluate children to investigate the presence of tinnitus, so that etiology is 
clarified and appropriate treatment is given, since 19.6% of children may report discomfort by 
the presence of the symptom. [43] 
The length of tinnitus presence in the subjects of the sample was 5.18 ± 4.67 years, 
similar to the results of one study conducted in the USA, whose sample was comprised of 
some Brazilian individuals. [26] Length, however, was lower than in other studies, [44-46] 
and most evaluated patients had bilateral tinnitus (50.8%), which is consistent with previous 
studies [46-48] but it is in disagreement with others, where there was a predominance of 
tinnitus in the left ear. [18, 26] It is believed that the results obtained in the present research, 
as regards tinnitus location, can be attributed to the etiology of the symptom, predominantly 
caused by presbycusis, noise-induced hearing loss and metabolic changes. 
The study of psychoacoustic characteristics of tinnitus showed mean pitch of about 4000 
Hz in both ears and mean loudness of 16.65 dB HL in the right ear and 15.84 dB HL in the 
left ear. The values were lower than in other studies. [45, 46] Previous studies showed an 
average tinnitus pitch of 6000 Hz and tinnitus loudness between 51dBNA and 61dBNA. This 
large difference in loudness can be explained by the evaluation method used in the studies. 
THI scores ranged between 0 and 98 points, averaging 40.03 ± 25.48 points. The values 
were similar to those of another study. [46] The analysis of THI grading showed that most of 
the evaluated patients had mild discomfort (31.2%), followed by slight (22.1%) and moderate 
discomfort (20.6%).  
The analysis of THI score and gender, and THI score and tinnitus location showed no 
significant differences. These data had already been described by other authors. [14, 48]  
The analysis of the correlations between the characteristics of tinnitus, tinnitus discomfort 
and tinnitus severity showed that there was a positive correlation between tinnitus severity 
graded by patients and THI score. Thus, the higher the score on the scale, the greater the 
discomfort caused by tinnitus in the assessment made by THI. These data were expected by 
the researchers, since both tests evaluated the impact of tinnitus on patients’ life. A similar 
result was obtained in a previous study which analyzed the relationship between the responses 
from THI and the visual analogue scale. [38] 
There was also a negative and significant correlation between age and THI score, 
indicating that the higher the age, the lower the score. The analysis of these data and the fact 
that there was no correlation between age and most psychoacoustic characteristics of tinnitus 

A. R. Teixeira, L. Petersen Schmidt Rosito, B. Macagnin Seimetz et al. 
 
380
(pith and loudness), seem to confirm that individuals adapt more easily to the symptom as 
they grow older. Again, resilience must be taken into account. [23] These data, however, 
differ from results of other studies that used the same instrument to assess the impact of 
tinnitus and found no relationship between age and THI score [18, 20,48, 49] or even an 
increase of the impact of tinnitus with increasing age. [47] 
 
 
CONCLUSION 
 
Data analysis has shown that the majority of the sample was comprised of female adults 
who had had tinnitus for about five years in both ears. Tinnitus pitch was acute and tinnitus 
loudness was moderate, within the values reported by the technical literature. The discomfort 
caused by tinnitus was mostly mild, slight or moderate, and subjects rated the discomfort 
caused by tinnitus as grade 5. 
No difference was found between THI scores and gender and tinnitus location. There was 
correlation between severity of tinnitus and THI score, between age and tinnitus loudness in 
the left ear, and between age and THI score. 
 
 
REFERENCES  
 
[1] 
Jastreboff PJ. Tinnitus retraining therapy. Prog. Brain Res., 2007 166, 415-423. 
[2] 
Baguley D; McFerran D; Hall D. Tinnitus. Lancet, 2013 382, 1600-1607. 
[3] 
Fernandes 
G; 
Gonçalves 
DAG; 
Siqueira 
JTT; 
Camparis 
CM. 
Painful 
temporomandibular disorders, self reported tinnitus, and depression are highly 
associated. Arq. Neuropsiquiatr. 2013 71, 943-947. 
[4] 
Landgrebe M; Zeman F; Koller M; Eberl Y; Mohr M; Reiter J; Staundinger S; Hajak G; 
Langguth B. The tinnitus research initiative (TRI) database: a new approach for 
delineation of tinnitus subtypes and generation of predictors for treatment outcome. 
BMC Medical Informatics and Decision Making, 2010 10, 42.  
[5] 
Park KH; Lee SH; Koo J; Park HY; Lee KY; Choi YS; Oh KW; Lee A; Yang J; Woo 
SY; Kim SW; Choo YS. Prevalence and factors associated factors of tinnitus: data from 
the Korean National Health and nutrition examination survey 2009-2011. J. Epidemiol., 
2014, 24, 417-426.  
[6] 
Michikawa T; Nishiwaki Y; Kikuchi Y; Salto H; Mizutari K; Okamoto M; Takebayashi 
T. Prevalence and factors associated with tinnitus: a community-based study of 
Japanese elders. J. Epidemiol., 2010 20, 271-276. 
[7] 
Khedr EM; Ahmed MA; Shawky OA, Mohamed ES; El Atar GS; Mohammad KA. 
Epidemiological study of chronic tinnitus in Assiut, Egypt. Neuroepidemiology, 2010 
35: 45-52. 
[8] 
Shagorodsky J; Curhan CG; Farwell WR. Prevalence and characteristics of tinnitus 
among US adults. Am. J. Med., 2010 123, 711-718. 
[9] 
Jastreboff PJ; Hazzel JWP. A neurophysiological approach of tinnitus: clinical 
implications. Br. J. Audiol., 1993 27,7-17. 

Chronic Tinnitus 
 
381
[10] Carmo LC; Silveira JAM; Marone SAM; D’Ottaviano FG; Zagati LL; Lins EMDS. 
Audiological study of an elderly brazilian population. Braz. J. Otorhinolaryngol., 2008, 
74, 342-349. 
[11] Coelho CCB; Sanchez TG; Bento RP. Caracterização do zumbido de pacientes 
atendidos em serviço de referência. Arq. Int. Otorrinolaringol., 2004 8. 
[12] Sanchez TG. “Epidemics” of tinnitus in the 21st century: preparing our children and 
grandchildren. Braz. J. Otorhinolaringol., 2014 80, 3-4. 
[13] Knobel KAB; Lima MCMP. Are parents aware of their children’s hearing complaints? 
Braz. J. Otorhinolaryngol., 2012 78, 27-37. 
[14] Fioretti AB; Fusetti M; Eibenstein A. Association between sleep disorders, hyperacusis 
and tinnitus questionnaires. Noise Health, 2013 15, 91-95. 
[15] Seydel C; Haupt H; Olze H; Szczepek AJ; Mazurek B. Gender and chronic tinnitus: 
differences in tinnitus-related distress depend on age and duration of tinnitus. Ear hear, 
2013 34, 661-672. 
[16] Lin Z; Qi M; Zeng X. Study on gender difference of tinnitus in medical staff. Lin chung 
er bi yan hou tou jing wai ke za zhi, 2013 27: 465-467. 
[17] Teixeira AR; Nunes MGP; Freitas CLR; Gonçalves AK; Teixeira, SB. Analysis of 
quality of life of seniors with tinnitus’ symptoms. Intl. Arch. Otorhinolaryngol., 2010 
14, 54-59. 
[18] Udupi VA; Uppunda AK; Mohan KM; Alex J; Mahendra MH. The relationship of 
perceived severity of tinnitus with depression, anxiety, hearing status, age and gender in 
individuals with tinnitus. Int. Tinnitus J., 2013 18, 29-34. 
[19] Zeman F; Koller M; Langguth B; Landgrebe M. Which tinnitus-related aspects are 
relevant for quality of life and depression: results from a large international multicentre 
sample. Health Qual. Life Outcomes, 2014 12:7. 
[20] Pinto PCL; Sanchez TG; Tomita S. The impacto of gender, age and hearing loss on 
tinnitus severity. Braz. J. Otorhinolaryngol., 2010 76, 18-24 
[21] Langguth B; Goodey R; Azevedo A; Bjorne A; Cacace A; Crocetti A; Vergara R. 
Consensus for tinnitus patient assessment and treatment outcome measurement: 
Tinnitus Research Initiative meeting. Progress in brain research, 2007 166: 525-536.  
[22] Holgers KM; Zoger S; Svedlund K. Predictive factors for development of severe 
tinnitus suffering further characterization. Int. J. Audiol., 2005 44, 584-592. 
[23] Wallhäuser-Franke E; Delb W; Balkenhol T; Hiller W; Hörmann K. Tinnitus-related 
distress and the personality characteristic resilience. Neural Plasticity, 2014 article ID 
370307, 6 pages. 
[24] Geocze L; Mucci S; Abranches DC; Marco MA; Penido NO. Systematic review on the 
evidences 
of 
an 
association 
between 
tinnitus 
and 
depression. 
Braz. 
J. 
Otorhinolaryngol., 2013 79, 106-111. 
[25] Langguth B; Kleinjung T; Landgrebe M. Tinnitus: the complexity of standartization. 
Eval. Health Prof., 2011 34: 429-433. 
[26] Zeman F; Koller M; Scheklmann M; Langguth B; Landgrebe M. Tinnitus assessment 
by means of standartized self-reported questionnaires: psychometric properties of the 
Tinnitus Questionaire (TQ), the Tinnitus handicap Inventory (THI), and their short 
versions in an international multi-lingual sample. Health Qual. Life Outcomes, 2012 
10:128. 

A. R. Teixeira, L. Petersen Schmidt Rosito, B. Macagnin Seimetz et al. 
 
382
[27] Kumral TL; Yldrm G; Yilmaz HB; Ulusoy S; Berkiten G; Onol SD; Ozturkçu Y; Uyar 
Y. Is it necessary to do temporal bone computed tomography of the internal auditory 
canal in tinnitus with normal hearing? The Scientific World Journal, 2013. 
[28] Newman CW, Jacobson GP, Spritzer JB. Development of the Tinnitus Handicap 
Inventory. Arch. Otolaryngol. Head Neck Surg., 1996 122, 143-148. 
[29] Schimidt LP; Teixeira VN; Dall’Igna C; Dallagnol D; Smith MM. Brazilian Portuguese 
language version of th “Tinnitus Handicap Inventory”: validity and reproducibility. 
Braz. J. Otorhinolaryngol., 2006 72, 808-810. 
[30] Meng Z; Zheng Y; Liu S; Wang K; Kong X; Tao Y; Xu K; Liu G. Reliability and 
validity of the Chinese (mandarin) tinnitus handicap inventory. Clin. Exp. 
Otorhinolaryngol., 2012 5, 10-16. 
[31] Kam AC; Cheung AP; Chan PY; Leung EK; Wong TK; van Hasselt CA; Tong MC. 
Psychometric properties of the Chinese (Cantonese) tinnitus handicap inventory. Clin. 
Otolaryngol., 2009 34: 309-315.  
[32] Ghulyan-Bédikian V; Paolino M; Giorgetti-D’Esclers F; Paolino F. Psychometric 
properties of a French adaptation of the tinnitus handicap inventory. Encephale, 2010 
36, 390-396. 
[33] Monzani D; Genovese E; Marrara A; Gherpelli C; Pingani L; Forghieri M; Rigatelli M; 
Guadagnin T; Arslan E. Validity of the Italian adaptation of the tinnitus handicap 
inventory; focus on quality of life and pdychological distress in tinnitus-sufferers. Acta 
Otorrinolaryngol. Ital., 2008 28, 126-134. 
[34] Der C; Alzérreca E; San Martín JT; Román L; Zamorano I; Malhue J; Aliaga P; 
Coronelli L; Sarda S. National linguistic validation of the tinnitus handicap inventory 
(THI). Assessment of disability caused by tinnitus in chilean spanish-speaking 
population. Int. Tinnitus J., 2012 17, 146-151. 
[35] Tobias CA; Llanes EG; Chiong C. Validity of a Filipino translation of the tinnitus 
handicap inventory. Int. Tinnitus J., 2012 17: 64-69. 
[36] Mahmoudian S; Shahmiri E; Rouzbahani M; Jafari Z; Keyhani M; Rahimi F; 
Mahmoudian G; Akbarvand L; Barzegar G; Farhadi M. Persian language version of the 
tinnitus handicap inventory: translation, standartization, validity and reliability. Int 
.Tinnitus J., 2011 16: 93-103. 
[37] Newman CW; Sandridge SA; Bolek L. Development and psychometric adequacy of the 
screening version of the tinnitus handicap inventory. Otol. Neurotol., 2008 29: 276-281. 
[38] Figueiredo RR; Azevedo AA; Oliveira PM. Correlation analysis of the visual-analogue 
scale and the Tinnitus Handicap Inventory in tinnitus patients. Braz. J. 
Otorhinolaryngol., 2009 75, 76-79. 
[39] Sanchez TG; Ferrari GMS. O que é zumbido? In: Samelli AG. Zumbido – avaliação, 
diagnóstico e reabilitação. São Paulo: Lovise, 2004. 
[40] Branco-Barreiro FMA. Avaliação audiológica básica e psicoacústica do zumbido. In: 
In: Samelli AG. Zumbido – avaliação, diagnóstico e reabilitação. São Paulo: Lovise, 
2004. 
[41] Pinheiro RS; Viacava F; Travassos C; Brito AS. Gender, morbidity, access and 
utilization of health services in Brazil. Ciência e Saúde Coletiva, 2002 7, 687-707. 
[42] Couto MT; Pinheiro TF; Valença O; Machin R; Silva GSN; Gomes R; Schraiber LB; 
Figueiredo WS. Men in primary healthcare: discussing (in)visibility based on gender 
perspectives. Interface (Botucatu), 2010 14: 257-270. 

Chronic Tinnitus 
 
383
[43] Coelho CB; Sanchez TG; Tyler RS. Tinnitus in children and associated risk factors. 
Prog. Brain Res., 2007 166, 179-191. 
[44] Dib GC; Kasse CA; Andrade TA; Testa JRG; Cruz OLM. Tinnitus treatment with 
tradozone. Braz. J. Otorhinolaryngol., 2007 73, 390-397. 
[45] Hoekstra CEL; Wesdorp FM; Zanten GA. Socio-demographic, health, and tinnitus 
related variables affecting tinnitus severity. Ear Hear, 2014 35, 544-554. 
[46] Schecklmann M; Landgrebe M; Langguth B. Phenothypic characteristics of hyperacusis 
and tinnitus. Plos. One, 2014 9, e86944. 
[47] Hiller W; Goebel G. Factors influencing tinnitus loudness and annoyance. Arch. 
Otolaryngol. Head Neck Surg., 2006 132, 1323-1330. 
[48] Mondelli MFCG; Rocha AB. Correlation between the audiologic findings and tinnitus 
disorder. Intl. Arch. Otorhinolaryngol., 2011 15, 172-180. 
[49] Milerová J; Anders M; Dvorak T; Sand PG; Königer S; Langguth B. The influence of 
psychological factors on tinnitus severity. Gen. Hosp. Psychiatr., 2013 35, 412-416. 
 


In: Encyclopedia of Audiology and Hearing Research 
ISBN: 978-1-53617-702-2 
Editors: Erno Larivaara and Senja Korhola 
© 2020 Nova Science Publishers, Inc. 
 
 
 
 
 
 
 
Chapter 30 
 
 
 
EFFECT OF HEARING LOSS ON TRAFFIC 
SAFETY AND MOBILITY 
 
 
Birgitta Thorslund, PhD 
The Swedish National Road and Transport Research Institute, Sweden 
 
 
ABSTRACT 
 
Research into the effect of hearing loss (HL) on traffic safety and mobility is limited 
and the empirical findings are somewhat inconsistent. HL is one of the most frequent 
sensory deficits in humans, leading to loss of auditory information, which may affect 
behavior in traffic situations and might reduce traffic safety and mobility. The prevalence 
of age-related HL in Europe is roughly 30% for men and 20% for women at the age of 70 
years, and 55% for men and 45% for women at the age of 80 years. The prevalence of 
age-related HL is increasing, and as a consequence the number of road users with HL will 
also increase.  
The aim of this PhD thesis was to investigate traffic safety and mobility for 
individuals with HL. Three studies were conducted: 1. a questionnaire survey aimed to 
evaluate differences in choice of transportation that might be related to HL, 2. a driving 
simulator study that looked into compensatory strategies and evaluated the efficiency of a 
tactile signal to alert the driver, and 3. a field study to evaluate these effects in real traffic 
and to evaluate a navigation system with a supportive tactile signal.  
The results of the three studies indicate that there are effects of HL on traffic safety 
and mobility. The effects are relatively small and often bound to driving complexity; but, 
systematic and consistent in replicated study. Differences in transportation habits related 
to HL include less likelihood of having a driver’s license and a higher valuing of written 
information, with the latter possibly prioritized before time and safety issues. Moreover, 
respondents with more HL were less concerned about the effects of HL, which suggests 
that they might be using compensatory strategies.  
In the experimental studies, differences in driving behavior related to HL were bound 
to driving conditions and occurred when the complexity of the driving task increased. 
There was also an effect of HL on visual behavior, indicated in the simulator and 
confirmed in the field study, suggesting that drivers with HL have more active visual 
behaviors with more frequent glances in the rear-view mirror and a general scanning of 
the environment before looking away from the road. A tactile signal in the driver seat was 

Birgitta Thorslund 
 
386
found useful in both experimental studies, both for calling for the driver’s attention and 
facilitating navigation using a GPS navigation device.  
It was concluded that there are effects of HL on both traffic safety and mobility, 
consistently pointing toward a generally more cautious driving behavior with the use of 
both compensatory and coping strategies, which suggests a difference in experienced 
safety. Compensatory strategies associated with HL include driving at lower speeds and 
using a more comprehensive visual search behavior. Coping strategies associated with 
HL include engaging less in distracting activities. Evaluation of the tactile signal suggests 
that it may make driver assistance systems more accessible, not only to drivers with HL, 
but to all drivers. At the same time, the systems might become more effective for all 
users, since visual resources can be more focused on the road, which could increase both 
traffic safety and mobility in general.  
 
 
LIST OF PAPERS 
 
Paper I: Thorslund, B., Peters, B., Lyxell, B., & Lidestam, B. (2013). The Influence of 
Hearing Loss on Transport Safety and Mobility. European Transport Research Review, 
5(3), 117-127. 
Paper II: Thorslund, B., Peters, B., Lidestam, B., & Lyxell, B. (2013). Cognitive workload 
and driving behavior in persons with hearing loss. Submitted to Transportation Research 
Part F: Traffic Psychology and Behaviour, 21, 113-121. 
Paper III: Thorslund, B., Ahlström, C., Peters, B., Eriksson, O., Lyxell, B., & Lidestam, B. 
(2014, May 29). Cognitive workload and visual behavior in elderly persons with hearing 
loss. 
European 
Transport 
Research 
Review, 
published 
online 
first, 
1-9. 
doi:10.1007/s12544-014-0139-z  
Paper IV: Thorslund, B., Peters, B., Herbert, N., Holmqvist, K., Lidestam, B., Black, A., 
Lyxell, B. (2013). Hearing loss and a supportive tactile signal in a navigation system: 
Effects on driving behavior and eye movements. Journal of Eye Movement Research, 
6(5), 1-9.  
 
 
LIST OF ABBREVIATIONS 
 
ADAS 
Advanced driver assistance system 
CDT 
Clock-drawing test 
EF 
Executive function 
HL 
Hearing loss 
HMI 
Human machine interaction 
HRF 
Swedish Association for Hard of Hearing People 
ICF 
International Classification of Functioning, Disability and Health  
LTM 
Long-term memory 
MCZ 
Multiple comfort zone model 
NH 
Normal hearing 
OR 
Odds ratio 
PTA 
Pure tone average 
RAT 
Risk allostasis theory 

Effect of Hearing Loss on Traffic Safety and Mobility 
 
387
RHM 
Risk homeostasis model 
RMM 
Risk monitor model 
TDH 
Task difficult homeostasis 
TIPS 
Text information processing system 
TMT 
Trail making test 
UFOV 
Useful field of view 
WHO 
World Health Organization 
WM 
Working memory 
 
 
CONCEPTS AND DEFINITIONS 
 
Age-related HL Presbycusis: The most common type of HL typically starting around middle 
adulthood and then progressing, particularly affecting the high frequency ranges. 
Compensatory strategies: Efforts made by the individual (consciously or unconsciously) to 
maintain a given level of functioning despite decline in, or loss of, previously available 
resources 
Coping strategies: Use of conscious effort to solve personal and interpersonal problems and 
to seek to master, minimize, or tolerate stress or conflict. 
Mobility: The quality or state of being mobile. The ability to move freely. 
Older adults: Individuals over 65 years 
 
 
INTRODUCTION 
 
For many people transportation is a part of everyday life and is so established that we do 
not think about how complex even the simplest task really is. Being a road user demands 
cognitive skills in order to assemble new information in the traffic environment, apply it to 
stored knowledge, and make decisions. This thesis examines the travel habits and driving 
behaviors of individuals with hearing loss (HL) and how cognitive skills interact with their 
driving behavior. Driving a car is a cognitively initiated and controlled task, and thus one 
approach to understand driving behavior is to examine how cognitive skills are involved. 
Cognitive psychology is the area that describes the internal processes involved in making 
sense of the environment and deciding what action might be appropriate (Eysenck & Keane, 
2010; Neisser, 1976).  
HL is one of the most frequent sensory deficits in humans, with a prevalence of 
approximately 10% in the general population in the western world, and it is a common 
chronic condition among the elderly (Stevens et al., 2013). HL entails a loss of auditory 
information, which may affect behavior in traffic and might reduce traffic safety. Research 
into the effect of HL on traffic safety and mobility is limited and the empirical findings are 
somewhat inconsistent. From a legal perspective, based on this relatively low level of 
knowledge, HL is not considered an increased traffic safety risk (Englund, 2001; Glad, 1977), 
and therefore hearing is not required for obtaining a driver’s license for passenger cars.  
From a safety perspective, some studies suggest an association between HL and increased 
risks of traffic accidents (Ivers, Mitchell, & Cumming, 1999; Picard et al., 2008). However, 

Birgitta Thorslund 
 
388
other studies show no such relation (Green, McGwin, & Owsley, 2013; McCloskey, Koepsell, 
Wolf, & Buchner, 1994). Schmolz (1987) examined the importance of hearing for road users 
and found that HL is associated with a higher degree of inattention. With regard to attention, 
Hickson et al. (2012) showed that HL in older drivers was associated with poorer driving 
performance in the presence of distraction, but not without distraction. On the other hand, 
Picard et al. (2008) suggested that HL leads to a reduction in speeding violations, probably 
due to self-regulation. In sum, the effect of HL on traffic safety remains mostly unknown, and 
possibly connected to specific situations; although its associations with attention and driving 
speed have been shown.  
From a mobility perspective, it is possible that of HL leads to self-regulation due to 
feelings of unsafety. This is an important aspect to consider, because mobility is important for 
quality of life (Farquhar, 1995), often connected to factors such as psychological well-being 
and independence (Bonnel, 1999; Fonda, Wallace, & Herzog, 2001; Gabriel & Bowling, 
2004; Marottoli et al., 1997), and also associated with higher life satisfaction (Banister & 
Bowling, 2004; Hakamies-Blomqvist & Wahlström, 1998 Gagliardi, Marcellini, Papa, Giuli, 
& Mollenkopf, 2010).  
Physiologically, disruption of any part along the auditory pathway (central to peripheral) 
may lead to HL and there are two main diagnoses. Problems in the outer ear (such as 
blockage of the ear canal) or middle ear (such as ossicular chain discontinuity) cause 
conductive hearing loss, and problems in the inner ear (such as loss of outer or inner hair cells 
in the cochlea) or problems in the auditory nerve leading to the central auditory pathway 
(such as auditory neuropathy) can result in sensorineural HL (Arlinger, 2007).  
This thesis is focused on age-related HL, also known as presbycusis. This is the most 
common type of HL typically starting around middle adulthood and progressing, affecting the 
high frequency ranges particularly (Pearson et al., 1995; Schneider, Pichora-Fuller, & 
Daneman, 2010) and inducing distortion (Moore, 1995). The prevalence of age-related HL in 
Europe is roughly 30% for men and 20% for women at the age of 70 years, and 55% for men 
and 45% for women at the age of 80 years (Roth, Hanebuth, & Probst, 2001). The prevalence 
of age-related HL is increasing, due to populations becoming progressively older and thus 
presenting symptoms of reduced sensory function. A consequence of the increasing 
prevalence of HL is that the number of road users (not only drivers) with HL will also 
increase. This certainly leads to an increased need of knowledge about these individuals with 
regard to traffic safety and mobility.  
Hearing is important for our sense of spatial orientation and temporal resolution and thus 
of high relevance for traffic safety. Sounds behind us provide information about events that it 
not possible to see and we receive information about positions and distances. Most frequency 
spectra of exterior tires or road noise display a prominent peak in the range of 700–1300 Hz 
(Sandberg, 2003). Since the noise from cars driving on roads is mainly in low frequencies, 
i.e., with low-pitched sounds (Wu, Stangl, Bentler, & Stanziola, 2013), individuals with 
presbycusis should be able to hear these specific sounds rather well. However, there might be 
other vital auditory input in high frequencies (e.g., a bicycle bell can be hard to hear for a 
pedestrian), which is partly or totally missed, and may therefore lead to loss of critical 
information for the listener. Distortion leads to increased difficulties in hearing masked 
sounds, in other words low frequency traffic noise can mask high frequency sounds. Research 
on effective siren characteristics suggest either a sufficiently loud, wide frequency spectrum 
(1-4 kHz) to overcome masking noise (De Lorenzo & Eilers, 1991; Catchpole & McKeown, 

Effect of Hearing Loss on Traffic Safety and Mobility 
 
389
2007) or sirens that broadcast low frequencies so that the siren sound can penetrate into 
vehicle cabins (Howard et al., 2011). Furthermore, the use of in-vehicle systems for 
information, support, and navigation is rapidly increasing. These systems often use auditory 
signals that may not be accessible to drivers with HL. Thus, investigating other modalities 
such as light or vibration should be considered to also make these systems accessible to 
drivers with HL. 
 
 
Figure 1. Overview of the thesis. The three main topics are Traffic Safety, Audiology and Cognition. 
These are presented and discussed separately, in relation to each other and in relation to age. Concepts 
included in the thesis are listed in black and terms excluded or mentioned only briefly are listed in 
white.  
In the present thesis, traffic safety and mobility for individuals with HL is examined from 
the perspective of cognitive psychology. That is, how different cognitive skills in combination 
with HL affect traffic safety and mobility. Focus is on the intersection between three research 
areas: audiology, cognition, and traffic safety. The background and central expressions of 
these areas and their interrelations with each other and with age are presented in the following 
chapters. Figure 1 presents an overview of the thesis in terms of what is covered or excluded 
in each area, as well as in the intersection between them.  
 
 
HEARING LOSS 
 
The International Classification of Functioning, Disability and Health (ICF) suggested by 
the World Health Organization (WHO) is a framework based on the biopsychosocial model 
that describes the consequences of a particular health condition or disability in terms of 

Birgitta Thorslund 
 
390
various levels of disablement and functioning (WHO, 2001). These may include body 
functions on the organic level, activities on the personal level, and participation on the social 
level. These levels also interact with each other and may be further influenced by personal 
and environmental factors. Thus, it is important to understand the consequences of a 
particular health condition or disability from multiple perspectives (Rimmer, 2006).  
According to the ICF, functioning and disability are typically conceptualized as a 
complex interaction between an individual’s health condition, contextual factors of the 
environment, and personal factors (WHO, 2001). The consequences of HL include the 
inability to interpret speech sounds, often producing a reduced ability to communicate, delay 
in language acquisition in children, economic and educational disadvantage, social isolation, 
and stigmatization. This may also be worsened by some medical conditions such as diabetes 
(Mathers, Smith, & Concha, 2003). 
The degree of HL is categorized according to the better ear hearing level averaged over 
the frequencies of 0.5, 1, 2, and 4 kHz and divided into mild (26-40 dB), moderate (41-60 
dB), severe (61-80 dB), and profound (> 80 dB) (Mathers, et al., 2003). Individuals with a HL 
of 95 dB or more are commonly referred to as deaf.  
Age-related HL, the focus of this thesis, originates with the deterioration of auditory 
function and is part of normal aging, usually starting in the middle adulthood (Pearson et al., 
1995; Schneider, Pichora-Fuller, & Daneman, 2010). Outer hair-cell damage, degeneration of 
the stria vascularis (producing endocochlear potential) and the auditory nerve are the main 
causes (Pichora-Fuller & Singh, 2006), and auditory processes, such as temporal resolution 
and duration discrimination, are negatively affected (Fitzgibbons & Gordon-Salant, 2010; 
Saremi & Stenfelt, 2013).  
 
 
Assessment of Hearing Ability 
 
Assessment of hearing ability is performed either psychoacoustically with an active 
listener (e.g., tone audiometry) or by objective methods using a physiological reaction such as 
electro-physical methods or otoacoustic emissions (Arlinger, 2007). Pure-tone average (PTA) 
is a common hearing test, relying on a patient’s response to pure-tone stimuli. With PTA both 
air and bone conduction can be tested thus, enabling the determination of degree, type, and 
configuration of HL in an individual. Test frequencies begin at 1000 Hz and include at a 
minimum octave steps up to 8000 Hz and down to 125 Hz. Often 750, 1500, 3000, and 6000 
Hz are also included. Figure 2 shows results from a PTA marked in an audiogram with test 
frequencies on the horizontal axis and hearing thresholds on the vertical.  
 
 
COGNITION 
 
Cognitive psychology is a necessary part for explaining human behavior. The cognitive 
approach is used to explain the mental processes essential for our ability to perceive and 
attend to, as well as memorize and communicate with, the world around us. These cognitive 
processes also are fundamental for our language perception, production and use, thinking, and 
problem solving (Eysenck & Keane, 2010). The concept ‘attention’ is successively being 

Effect of Hearing Loss on Traffic Safety and Mobility 
 
391
replaced by executive functions (EFs), which are defined as a high-level process with the 
main obligation of adapting to new and complex situations (Diamond, 2013; Eysenck & 
Keane, 2010). Working memory (WM) and long-term memory (LTM) are 2 separate memory 
systems, which according to Baddeley (2012) are linked together by an episodic buffer 
working as an interface between the 2 memory systems. In order to understand the possible 
cognitive consequences of HL relevant for traffic safety it is important to understand both 
cognitive consequences of HL and road user behavior.  
 
 
Figure 2. An audiogram presenting hearing thresholds from a PTA (air conduction).  
The main focus in the present thesis is on car drivers with age- related HL. WM, LTM 
and EFs are involved since previous research has shown the effects of age (e.g., McDowd & 
Shaw, 2000; Verhaeghen et al., 2003) and HL (e.g., Andersson & Lyxell 1999; Lin et al., 
2011, 2013; Rönnberg et al., 2011) on these systems. Cognitive factors such as perception 
and decision making is not actively examined even though effects of aging have been 
observed in previous studies (e.g., Johnson, 1989; Kennedy, Taylor, Reade, & Yesavage, 
2010). The reason for this is the limited knowledge in this area and there is a need for 
constraints to be able to focus on some specific issues.  
 
 

Birgitta Thorslund 
 
392
Working Memory 
 
WM refers to a memory system with a limited capacity, and that serves to simultaneously 
store and process new information over a short period of time (Daneman & Carpenter, 1980; 
Daneman & Merikle, 1996; Miyake & Shah, 1999; Baddeley, 2012). WM is necessary in 
daily life in that it helps us keep things in mind when approaching a task. For example, 
remembering what to write down once we have found the piece of paper and a pencil or 
remembering what we have read once we get to the end of the sentence. In the 
multicomponent model of WM (Baddeley, 2012; Repovs & Baddeley, 2006) there are 4 
components, each serving a specific purpose. A central executive serves as a modality 
independent control system, which directs and divides attention between tasks. It is involved 
whenever manipulation within WM is required (Repovs & Baddeley, 2006). This means the 
central executive controls the function of the subordinate storage components, namely: the 
phonological loop (dealing with language-based verbal information); the visuospatial 
sketchpad (processing visuospatial information); and the episodic buffer (providing a link 
between new and old information) (Repovs & Baddeley, 2006).  
The phonological loop comprises 2 components: a passive phonological store, which 
holds memory traces, like speech, in acoustic or phonological form for a few seconds; and an 
articulatory rehearsal process linked to speech production, recoding information from other 
modalities (Repovs & Baddeley, 2006). According to this words and letters presented 
auditorily are processed differently from those presented visually. Auditory sensations have 
direct access to the phonological store, regardless of whether the articulatory control process 
is used. In contrast visual presentation of words and letters only produces indirect access 
through sub-vocal articulation (Baddeley, 2012; Eysenck & Keane, 2010).  
The visuospatial sketchpad is dedicated to the storage and manipulation of visual and 
spatial information. The fourth component is the episodic buffer, which serves as an interface 
for binding information from different sensory sources, the other 2 subsidiary systems, and 
LTM. The episodic buffer also serves as an interface between perception and LTM, where the 
phonological and semantic representations in the lexicon are stored (Baddeley, 1983; Repovs 
& Baddeley, 2006). WM capacity is related to performance in most other complex cognitive 
tasks such as reading comprehension and problem solving (Conway, Kane & Engle, 2003). 
WM capacity is one reflection of individual differences in the ability to focus and maintain 
attention, specifically when other events are serving to capture one’s attention (Kane & 
Engle, 2002).  
In sum, WM is the ability to temporarily hold information, manipulate and use this for a 
special cause over a short period of time. One example from a traffic situation is a road user 
(driver, pedestrian or cyclist) who is about to cross the street. They must keep track of the 
positions of the other road users and use this information to calculate when to cross.  
 
 
Long-Term Memory 
 
LTM is a memory system where information is stored for long periods of time and 
remains indefinitely. In this system, declarative memory includes episodic memory and 
semantic memory, while non-declarative memory is divided into repetition priming and 
procedural memory (Eysenck & Keane, 2010). Episodic memory is the memory of personal 

Effect of Hearing Loss on Traffic Safety and Mobility 
 
393
events (e.g., times, places, associated emotions, and other contextual knowledge) that can be 
explicitly stated, which is used when driving to a specific known place. The semantic LTM 
includes general knowledge about the world (e.g., languages, game rules, names of capital 
cities, authors of books, traffic rules) that the individual shares with others. The perceptual 
representation system recognizes items and terms, permitting rapid identification of 
previously encountered stimulants (perceptual or conceptual). As the name implies, 
procedural memory stores information on how to perform certain procedures such as walking, 
riding a bike and maneuvering a car (Eysenck & Keane, 2010).  
 
 
Executive Functions 
 
EFs are a set of mental processes that help us stay focused on what we are supposed to 
focus on (Diamond, 2013). EFs is a relatively new concept in the sense that we can relate to it 
more theoretically today than previously. EFs are used to perform activities such as planning, 
organizing, making, and using strategies, paying attention to and remembering details, and 
managing time and space. EFs make it possible to play with ideas, take the time to think 
before acting, meet novel, unanticipated challenges, resist temptations, and stay focused 
(Diamond, 2013). Miyake et al. (2000) defined shifting, updating and inhibiting as 3 
specifically important EFs, correlated but separable. Shifting was defined by Monsell (1996) 
as responsible for attentional or task shifting. Updating monitors and codes incoming 
information according to relevance for the current task. This manipulation, instead of just 
storing, was described as the most important function of the updating function by Morris and 
Jones (1990). Miyake defined inhibition as the possibility of deliberately stopping dominant, 
automatic or powerful reactions and necessary to minimize distraction effects (Miyake et al., 
2000).  
Researchers have argued that WM capacity reflects the efficiency of EFs, especially the 
ability to maintain a few task-relevant representations and neglecting irrelevant information 
(Engle, Tuholski, Laughlin, & Conway, 1999). According to Diamond (2013), the main EFs 
are: inhibition, which is divided into response inhibition (self-control-resisting temptations 
and resisting acting impulsively) and interference control (selective attention and cognitive 
inhibition); WM; and cognitive flexibility (including creatively thinking outside the box, 
seeing anything from different perspectives, and quickly and flexibly adapting to changed 
circumstances).  
In sum, EFs are essential in helping us in our daily life. They help us stay focused on 
what we are doing by updating us with relevant information and neglecting unrelated 
information. EFs also help us shift between tasks and think before acting, which is essential 
for driving a car. For example, visualization of consequences, analysis of information, and 
judgment of time, distance and power are necessary to be able to drive a car safely.  
 
 
Assessment of Cognitive Ability 
 
Cognitive decline is, just like HL, a part of normal aging and also related to HL (Baltes & 
Lindenberger, 1997; Rönnberg et al., 2011; Valentijn, van Boxtel, & van Hooren, 2005). 
Therefore, it is important to control for differences in cognitive abilities when comparing 

Birgitta Thorslund 
 
394
driving performance between a group with HL and a group with NH. This can be 
accomplished by cognitive testing.  
 
WM Capacity 
There are several tests designed to evaluate WM capacity. A commonly used measure is 
a dual-task paradigm combining a memory span measure with a concurring processing task. 
Daneman and Carpenter (1980) invented the first version of this kind of task, called the 
“reading span test”. In their test participants read a number of sentences (usually between 2-6) 
and tried to remember the last word of each sentence. At the end of the list of sentences, they 
tried to repeat back the words in the correct order. Individual WM capacity, as measured by 
the reading span test (Andersson, Lyxell, Rönnberg, & Spens, 2001; Daneman & Carpenter, 
1980; Rönnberg, 1990), has shown to account for 40% of the inter-individual variance of 
speech recognition in noise among participants with similar levels of HL (Lunner, 2003).  
Impairments in visuospatial ability (measured by, for example, copying the wire cube, 
pentagons, drawing a clock face) are good markers of increased driving risk (Kipps & 
Hodges, 2005). The clock drawing test (CDT) is a simple tool that is used to screen people for 
signs of neurological problems such as Alzheimer’s and other dementias. CDT assesses 
primarily EFs by letting the participant draw a clock with hands pointing at a specific time.  
TIPS (Text Information Processing System, Ausmeel, 1988), is a cognitive test platform 
developed according to established cognitive models of WM, phonological and lexical ability 
(see Baddeley, 2012; Abreu, Gathercole, & Martin, 2011; Shah & Miyake, 1996). The battery 
intends to measure WM capacity, phonological abilities and lexical abilities, and thus 
includes several tests for each of these cognitive aspects. A shorter computer-based version of 
TIPS was developed for use in clinics. Both this and TIPS have been used in a large number 
of studies (e.g., Hällgren, Larsby, Lyxell, & Arlinger, 2001, Bergemalm, Hennerdal, Persson, 
Lyxell, & Borg, 2009; Lidestam, Lyxell, & Andersson, 1999; Hua, 2014). The reading span 
test aims to measure the WM capacity. Two tests include reaction time measure of 
phonological ability (deciding whether 2 letters are identical and deciding whether 2 words 
rhyme).  
 
Processing Speed, Divided Attention, Selective Attention 
Skills measured by Useful Field of View (UFOV) are used during driving (Ball & 
Owsley, 1993), and the test is intended to be indicative of accident risk in the older population 
(Ball, Owsley, Sloane, Roenker, & Bruni, 1993; Owsley et al., 1998). In the first subtest, 
measuring processing speed, the participant is asked to identify which vehicle (car or truck) is 
displayed on the screen for a short time. In the second subtest, evaluating divided attention, 
the participant should, in addition to the first task, localize a car placed in the periphery on the 
screen. The third subtest, assessing selective attention, is identical to subtest 2 but with the 
rest of the screen filled with distracting triangles.  
The trail-making test (TMT) assesses visual search, processing speed and mental 
flexibility (Reitan, 1986). Part A consists of targets marked with numbers, which are 
connected in numerical order, and part B are targets marked with both numbers and letters, 
which are connected in a combined numerical and alphabetical order such as 1-A-2-B-3-C 
and so on. On a computerized version of TMT developed by Summala et al. (2008), the target 
locations are fixed on the screen but the content, that is numbers or letters, are either the same 

Effect of Hearing Loss on Traffic Safety and Mobility 
 
395
(fixed) or randomly changed after each tap on a touch screen instead of the traditional pen and 
paper version.  
 
 
Hearing Loss, Cognition and Aging 
 
Commonly, when talking about older people, older adults and elderly, this refers to 
individuals over the age of 65 (Gordon-Salant, 2005; Gorman, 1999; Roebuck, 1979). This 
also applies for this present thesis. Numerous studies have shown that there is a correlation 
between HL and cognitive decline in old age (Granick, Kleban, & Weiss, 1976; Thomas, 
Hunt, Garry, Hood, Goodwin, & Goodwin, 1983; Lindenberger & Baltes, 1994; Baltes & 
Lindenberger, 1997; Li & Lindenberger, 2002; Lin, Ferrucci, Metter, An, Zonderman, & 
Resnick, 2011; Rönnberg et al., 2011), which will be presented more specifically in a 
subsequent section.  
Because age-related HL is the most common type (Roth, Hanebuth, & Probst, 2001; 
WHO, 2001), it is important to understand other consequences of normal aging, which more 
or less affect or are affected by HL. For example, the deterioration of auditory functions such 
as like speech understanding is worsened by age-related changes in the cognitive system 
(Grady, 2012; Rönnlund, Nyberg, Bäckman, & Nilsson, 2005). Older adults with NH have 
also shown more difficulties with speech recognition than younger individuals with NH 
(Frisina & Frisina, 1997; Gordon-Salant, 2005), which can, for example, affect the possibility 
of using auditory-based driver assistance systems.  
 
 
Cognitive Consequences of Aging 
 
Aging is associated with the decline in the control processes involved in coordinating 
distinct tasks such as reaction times, WM tasks, tests of episodic memory, tests of spatial and 
reasoning abilities, mental rotation, and visual search performance (McDowd & Shaw, 2000; 
Verhaeghen et al., 2003). However, on specific vocabulary tests, no effects of age have been 
shown, for example by Elliott et al. (2003) using the Wechsler Adult Intelligence Scale 
Vocabulary subtest (Jastak & Jastak, 1964) and by Bowles and Salthouse (2009) using 
multiple-choice synonyms, multiple-choice antonyms and produce-the-definition.  
The effects of aging have also been demonstrated when switching between specific tasks 
(e.g., switching between responding to color or form and responding only to color, Mayr et 
al., 2001; Verhaeghen et al. 2005), and are also related to attention (Craik & Salthouse, 2000; 
Phillips & Lesperance, 2003). Slower cognitive processing is also associated with aging 
(Cerella, 1990; Salthouse, 1996) and it is estimated that processing takes 1.5-2 times longer in 
older than in younger adults (Cerella, 1990). This affects most age-related declines in 
performing complex cognitive tasks such as problem solving, reasoning and language 
comprehension (Salthouse, 1996; Verhaegen et al., 2003).  
Aging is also associated with reductions in WM for both processing (van der Linden et 
al., 1994, 1999; Bopp & Verhaeghen, 2005) and capacity (Bopp & Verhaeghen, 2005; 
Salthouse & Babcock, 1991). Specifically, the episodic memory of LTM is negatively 
affected by age while semantic memory remains relatively stable or may even increase, and 

Birgitta Thorslund 
 
396
on the non-declarative memory no conclusive aging effect has been shown (Brickman & 
Stern, 2009).  
Some of these age-related cognitive declines can be of major importance for safe 
mobility (e.g., reaction times, visual search performance, processing speed, problem solving), 
specifically for driving, which according to Groeger (2000) is one of the most complex and 
safety critical everyday tasks in modern society.  
 
 
Cognitive Consequences of HL 
 
Specific and general effects of HL on cognitive functions have been demonstrated (e.g., 
Andersson, 2002, Lin et al., 2011, Rönnberg et al., 2011). For example, a relationship 
between severe to profound HL and deficiency in certain aspects of phonological processing 
has been demonstrated and suggested to come from a gradual loss of specificity of 
phonological representations (Andersson, 2002; Andersson & Lyxell 1999; Lyxell, 
Andersson, Borg, & Ohlson 2003; Rönnberg et al., 2011; Classon, 2013). Andersson (2002) 
concluded that specific aspects of the phonological system deteriorate in the HL population as 
a function of auditory deprivation. In particular, the phonological representations are impaired 
and this impairment also affects the ability to rapidly perform phonological operations.  
HL has been demonstrated as independently associated with accelerated cognitive decline 
(30-40%) and incident cognitive impairment (24%) among older adults during a six-year 
period. (Lin et al., 2011). These effects have been shown with the Modified Mini-Mental 
State test (Teng & Chui, 1987), which is a verbal cognitive test, as well as with a non-verbal 
cognitive test (called Digit Symbol Substitution, Wechsler, 1981), in both cross-sectional and 
prospective studies (Valentijn et al., 2005; Peters, Potter, & Scholer, 1988). Specifically, 
verbal tests have shown the relationship between HL and cognitive decline more extensively 
than non-verbal tests (Granick et al., 1976; Thomas et al., 1983).  
The more general effects of HL on cognitive functions may affect traffic safety more and 
are in line with Baddeley (2012), who found that articulatory suppression leads to WM 
decline. Prospective studies have found accelerated cognitive decline and increased risk of 
dementia and Alzheimer’s in individuals with HL (Lin et al., 2011, 2013). Cross-sectional 
studies have shown that HL is associated with lower performance in tests of EFs and free 
recall (Lin, 2011) and has a negative effect on episodic and semantic LTM (Rönnberg et al., 
2011). With a decline in WM, EFs and LTM, it might, for example, be more difficult to stay 
focused on the driving task, keep track of the surrounding traffic or to remember traffic rules.  
Another aspect worth considering is cognitive fatigue, due to higher effort in listening, 
leading to decreased cognitive capacity. This effect has been shown on both young and adult 
listeners with HL (Arlinger, 2003; Hicks & Tharpe, 2002; Tun, McCoy, & Wingfield, 2009). 
In addition, several studies have shown that hearing aids do not fully restore speech 
difficulties of individuals with HL (e.g., Dimitrijevic et al., 2004; Moradi, Lidestam, 
Hällgren, & Rönnberg, 2014; Nakeva von Mentzer, 2014), which made perceiving speech 
stimuli cognitively demanding (Moradi et al., 2014; Rönnberg et al., 2013).  
This cognitively demanding processing of speech stimuli may increase fatigue in 
individuals with HL during conversations with their partners while they are driving. 
Cognitive fatigue could, among other things, lead to decreased attention and thus be relevant 

Effect of Hearing Loss on Traffic Safety and Mobility 
 
397
to traffic safety. Moreover, mobility might be affected if cognitive fatigue leads to decreased 
driving.  
Furthermore, dual sensory decline (hearing and vision) is associated with cognitive 
decline and for a functional decline on everyday activities over a period of 4 years (Lin, 
Guttierrez, & Stone et al., 2004). Thus, research questions with regard to age-related HL and 
traffic safety require the combined study of several factors associated with declines due to 
aging.  
In sum, specific cognitive declines of HL have been demonstrated and include, for 
example, phonological deficiencies (processing and representation) as a consequence of less 
auditory stimulation (specificity of phonological representations). Traffic safety might be 
affected due to a decline in WM, EFs and LTM, which can lead to difficulties to stay focused 
on the driving task, keep track of the traffic around or to remember traffic rules. Also, 
cognitive fatigue could lead to decrease in attention and thus be of relevance for traffic safety.  
 
 
Cognition and Traffic Safety 
 
Groeger (2000) described driving a car as one of the most complex and safety critical 
daily tasks in modern society (Groeger, 2000). Driving is a cognitively motivated and 
controlled task. When demands are high, driving is carried out in a force-paced way, while 
when the demands are low, in a more self-paced way (Peters & Nilsson, 2006). Thus, 
workload is an aspect of driving that should be considered, and in this thesis the term 
cognitive workload is used, when others might be using mental workload. De Waard (1996) 
defined driver workload as the individual reaction to driving task demand and further refers to 
Rouse et al., who defined experienced load, which is not only task-specific but also person-
specific. (Rouse Edwards, & Hammer, 1993).  
More specifically, workload is the specification of the amount of information processing 
capacity that is used for task performance. Therefore, workload depends on the individual, 
and owing to the interaction between operator and task structure the same task demands do 
not result in an equal level of workload for all individuals (de Waard, 1996).  
Directly related to driving task demand is task complexity. According to de Waard 
(1996), complexity increases with an increase in the number of stages of processing that are 
required to perform a task. Task demand and complexity are mainly external, but both depend 
on subjective goals set for task performance. Difficulty of a task is related to the processing 
effort that is required by the individual for task performance, and is dependent on context, 
state, capacity, and strategy or policy of allocation of resources (de Waard, 1996).  
Driving effort is dynamic, as the cognitive demands can change back and forth from very 
low to extremely high, sometimes within fractions of a second (Michon, 1985; Peters & 
Nilsson, 2006). Among the factors determining the driving task demand, of which the driver 
has immediate and direct control, driving speed is the most significant (Fuller, 2005). It has 
been demonstrated that when a threshold of a certain preferred driving speed is exceeded, 
experienced task difficulty, effort and feeling of risk is affected (Lewis-Evans, 2011).  
In sum, driver workload is the individual reaction to driving task demand, which is 
directly related to task complexity. Task demand and complexity changes back and forth due 
to external circumstances and subjective goals, which makes the driving task and driver 

Birgitta Thorslund 
 
398
workload very dynamic. Feelings of risk arise when the task complexity goes above a certain 
threshold.  
 
Driver Behavior Models 
An advance within traffic behavioral research has been the increased understanding of the 
driving task from a cognitive perspective, and consequently the skills needed for carrying out 
this task successfully and safely. Since perceptual and psychomotor abilities are essential to 
model driving behavior, driving can be viewed as a cognitive task of control in a context 
perceived through the senses and manipulated with control actions based on unconscious 
(automated) or conscious decisions (Peters & Nilsson, 2006).  
Carsten (2007) distinguishes between 2 broad types of driver models. The first type is 
descriptive of parts or the whole of a driving task in terms of what the driver has to do and 
includes, for example, task models (Michon, 1985; McKnight & Adams, 1970), adaptive 
control models (McRuer et al., 1977; Hollnagel et al., 2003), and production models (Michon, 
1985). Michon (1985) described driving a car as a complex task with processes at a minimum 
of 3 hierarchical levels. At the top level, the strategic level, strategic decisions are made such 
as the choice of means of transport, setting of a route goal, and route-choice while driving. At 
the intermediate level, the maneuvering level, reactions to local situations, including reactions 
to the behavior of other traffic participants, take place. Basic vehicle-control processes, such 
as lateral-position control, occur at the lowest level, the control level. At this level automatic 
processes occur, while at higher levels higher controlled processing is required.  
The second type is motivational models, aiming to describe how the driver manages task 
difficulty. In contrast to the descriptive models, sometimes being merely descriptive or 
analytical, motivational models attempt to explain which psychological factors affect driver 
behavior and why drivers make certain decisions (Michon, 1985).  
According to Ranney (1994), errors associated with the variability of human behavior 
may be more important to roadway crash causation than systematic errors, which are 
attributable to the known limits of the human information-processing system. Furthermore, 
given the ever-increasing variety of driving situations, including changes in the driving task 
associated with different technologies, and the corresponding variety of skills and abilities 
required, Ranney (1994) claimed it unlikely that a comprehensive model of driver behavior 
will ever be feasible.  
For the purpose of this thesis, we expect that differences related to HL are not as likely to 
occur in terms of what the driver has to do, but rather may occur in the management of task 
difficulty and when making certain decisions. Therefore, motivational driver behavior models 
will be presented and discussed in more detail from the HL perspective.  
 
Motivational Models 
The most well-known motivational model is Wilde’s (1982) Risk Homeostatis Model 
(RHM), introducing the notion of driver capability affecting risk (Carsten, 2007). Wilde 
proposed that there is a preferred target level of risk of being involved in an accident that 
drivers seek to maintain. Fuller and Santos (2002) proposed the Task Difficult Homeostasis 
(TDH) (see also Fuller, 2005, 2007; Fuller et al., 2008; Fuller, McHugh et al., 2008), stating 
that people have a set range of experienced task difficulty at which they prefer to operate. 
TDH was then re-conceptualized into Risk Allostasis Theory (RAT), where the acceptable 

Effect of Hearing Loss on Traffic Safety and Mobility 
 
399
range of task difficulty is accompanied by and essentially interchangeable with a range of 
preferred feeling of risk (Fuller, 2008; Fuller, 2011).  
The Risk Monitor Model (RMM) (Vaa et al., 2000; Vaa, 2003, 2007, 2011) suggests that 
all individuals have a drive to maintain or obtain a target best feeling, which is variable in 
both its value and the type of feeling, however, including, for example: tension or anxiety, 
arousal, sensation, pleasure, relaxation, difficulty avoidance, compliance, and non-compliance 
(Vaa, 2007). 
The Multiple Comfort Zone model (MCZ) by Summala (2005) is an evolution of the 
earlier zero-risk theory (Näätänen & Summala, 1974). Being a motivational model it views a 
driver’s excitatory motives, personality and driving goals as prevailing factors. These motives 
interact with the road system and push drivers toward changing their behavior to satisfy their 
driving goals, for example by increasing speed to arrive at a destination on time (Summala, 
2005; Summala, 2007).  
What the presented motivational models all have in common is the level of risk, and it is 
suggested that the driver aims at maintaining this level. Whether drivers with HL are at higher 
risk than NH drivers or not is uncertain since there are studies suggesting connections 
between HL and higher risks of traffic accidents (Ivers, Mitchell, & Cumming, 1999; Picard 
et al., 2008) and also research where no such relationship has been found (Green, McGwin, & 
Owsley, 2013; McCloskey, Koepsell, Wolf, & Buchner, 1994). However, if there is a 
difference in risk related to HL there should, according to the motivational models, also be a 
different level of risk in which the drivers with HL aim to maintain. This could be driving at a 
lower speed, for example.  
Lewis-Evans (2012) experimentally tested 4 motivational models of driver behavior: 
TDH, RAT, RMM, and the MCZ (Summala, 2005; Summala, 2007). He concluded that the 
speed is not solely a conscious choice but handled, at least at some difficulty level, by 
automatic processes, and that the existence of these processes can be inferred when the 
cognitive capability of drivers is put to the test. Furthermore, results from the experiments 
supported the idea of a threshold to account for the perception of subjective variables such as 
task difficulty, effort, comfort, crash risk, and feeling of risk. For predicting difficulty of the 
task, the variables that the participants were most sensitive to changes in were speed and 
following distance. Lewis-Evans (2012) claims that these findings support models such as the 
MCZ (Summala, 2005; Summala, 2007) due to the reliance of this model on actual 
performance measures in driving such as time to line crossing or time to collision.  
In line with Lewis-Evans’ findings are the results from Lidestam, Lundqvist and 
Rönnberg (2010), who tested the external validity of theoretical driver behavior models by 
letting traffic inspectors rate the importance of theoretical concepts found in research 
literature on risk awareness. It was revealed that visual search was the most important 
concept, and that the assessment of risk awareness can be conceptualized as assessment of 
lower-order (maneuvering and position, cf. Michon’s control level) and higher-order 
(attention, traffic behavior and speed, cf. Michon’s manoeuver level) cognitive functions.  
In sum, according to motivational driver behavior models, drivers aim to maintain a 
preferred level of risk. The results in Lewis-Evans (2012) with regard to speed and following 
distance suggest time-based safety margins as relevant measures of this individual level of 
risk, and visual search is proposed as a valid indicator of risk awareness (Lidestam et al., 
2010). This is all in line with Gibson and Crooks’ very first model of driver behavior: field of 
safe travel (Gibson & Crooks, 1938). All of this is relevant for understanding the effect of HL 

Birgitta Thorslund 
 
400
on driving behavior and for the evaluation of driver support systems. Recurring in the models 
is the driving speed, and several studies have linked speed perception to the amount of noise 
in car cabins or to the driving sound (Evans, 1970; Ohta & Komatsu, 1991). Thus, speed 
might be perceived differently by drivers with hearing loss, due to a reduced sensitivity to 
sounds. 
 
 
TRAFFIC SAFETY 
 
One goal of traffic research should be to provide the safest possible mobility for all road 
users, regardless of their levels or types of abilities or disabilities. In all motivational models 
presented above, drivers aim to maintain a preferred level of risk, above a certain threshold. 
Whether drivers with HL are at higher risk than NH drivers is uncertain because previous 
findings are contradictory. For example, some studies found increased risk for drivers with 
HL (Ivers, Mitchell, & Cumming, 1999; Picard et al., 2008), while others did not (Green, 
McGwin, & Owsley, 2013; McCloskey, Koepsell, Wolf, & Buchner, 1994).  
According to Rumar (1988), there is always a risk in being mobile, and he divided risk 
into statistical (objective) risk and experienced (also called subjective or perceived) risk. For 
drivers with HL, research results are limited and rather contradictory on objective risk, and 
we found no results on subjective risk in our extensive literature surveys. Thus, it might be 
that drivers with HL can experience a subjective risk even if there is no objective risk. 
Research results so far do not identify clearly increased objective or subjective risks for 
drivers with HL, but this might be due to lack of knowledge. Therefore, there may be no 
increased risk at all for drivers with HL; there might be a small and unimportant risk; or there 
could be an important increased risk research has yet to reveal.  
The level of knowledge on the relationship between HL and statistical traffic safety is 
relatively low and too inconsistent to draw any conclusions. Crash data have shown that 
drivers with HL are at higher risks of traffic accidents (Ivers, Mitchell, & Cumming, 1999; 
Picard et al., 2008). However, there is also research on crash data and medical record data 
where such relationships have not been found (Green, 2013; McCloskey, Koepsell, Wolf, & 
Buchner, 1994). On the effect of HL on subjective traffic safety the literature is even scarcer. 
Lundälv (2004) found that adult pedestrians and cyclists with moderate HL had no self-
reported experiences of feeling insecure in the traffic environment; however, he also 
suggested that these individuals are at higher risk of being injured by a vehicle because they 
report that they find it difficult to identify the direction sounds come from. 
While traffic safety and mobility for drivers with HL is almost unexplored, the research 
literature regarding older drivers is relatively extensive. With age-related HL being the most 
common type (Roth, Hanebuth, & Probst, 2001; WHO, 2001), the effects of age are very 
relevant and will be discussed further in the following sections, along with the possible 
effects of HL.  
 
 
 
 
 

Effect of Hearing Loss on Traffic Safety and Mobility 
 
401
Mobility and Quality of Life 
 
Transportation is a part of everyday life and may be necessary for participation in 
activities and social life. Several studies suggest that travel habits will further increase for 
older adults in the future (Dillén, Schmidt, & Jarlebring, 2005; Hausten et al., 2013; Hjorthol, 
Levin, & Sirén, 2010) and this is explained by attitudinal effects (higher mobility needs, more 
active lifestyles), improved physical possibilities (fitness and health conditions), and cohort 
effects (being born at about the same time, exposed to the same events in society, and 
influenced by the same demographic trends and thus having similar experiences; Haustein, 
2013). 
In this thesis, mobility refers to the quality or state of being mobile - the ability to move 
freely. The ICF model includes mobility in activity and participation. Several studies have 
proven that limitation of activities increase with the degree of HL (Gopinath, Schneider, 
Hickson et al., 2012; Grue et al., 2009; Wallhagen et al., 2001; Schneider et al., 2010). HL 
has also been found to affect instrumental activities such as talking on the telephone or using 
public transportation more than daily activities such as getting dressed or eating (Gopinath, 
Schneider, McMahon, et al., 2012).  
Car access is associated with better health and well-being among the elderly (Ellaway, 
Macintyre, Hiscock, & Kearns, 2003; Macintyre, Hiscock, Kearns, & Ellaway, 2001). By 
enabling older people with physical limitations to still live independently and to participate in 
normal daily activities, the car can act as a compensational tool for functional limitations 
(Sirén & Hakamies-Blomqvist, 2004, 2009). According to Köpke, Deubel, Engeln and Schlag 
(1999), car availability and car use are related to positive self-perception in older people, and 
research suggests driving cessation may be a risk factor for a depressive development (Fonda, 
Wallace, & Herzog 2001; Marottoli et al., 1997). With age-related HL being the most 
common type of HL (Pearson et al., 1995; Schneider, Pichora-Fuller, & Daneman, 2010) and 
with increasing travel habits among older adults (and the gap between actual mobility and 
desirable mobility), it is important to understand the effect of HL on mobility.  
Self-regulation of driving usually refers to the voluntary reduction or avoidance of certain 
(typically challenging or demanding) driving situations (Haustein, 2013). This could also be a 
way of maintaining the level of risk by not exposing oneself to specific traffic situations. 
Factors found to be associated with self-regulation of driving are functional decline, and 
increasing cognitive and visual restrictions (Ball et al., 1998; Charlton, Oxley, Fildes, Oxley, 
& Newstead, 2003; Holland & Rabbit, 1992), and one’s perceived driving skills (Gabaude, 
Marquié, & Obriot-Claudel, 2010; Rimmö & Hakamies-Blomqvist, 2002).  
The most common medical conditions affecting driving cessation include sensory 
problems, cognitive impairment, stroke, cardiovascular, and other heart conditions, diabetes, 
and physical mobility and activity problems (Brayne et al., 2000; Dellinger, Kresnow, White, 
& Sehgal 2004; Forrest, Bunker, Songer, Cohen, & Cauley, 1997; Hakamies-Blomqvist & 
Wahlström, 1998). Edwards et al. (2009) indicated that driving cessation is associated with 
declines in physical and social functioning, as well as in general health (Edwards, Lunsman, 
Perkins, Rebok, & Roth, 2009).  
In sum, various age-related declines are associated with self-regulation and driving 
cessation. Because car access is associated with better health among the elderly, it is 
important to assist driving for older adults when possible. One way of achieving this is to 
ensure that driver assistance systems are also accessible for drivers with HL.  

Birgitta Thorslund 
 
402
Effects of Aging on Driving Behavior 
 
Factors associated with old age and that have a negative impact on the ability to drive 
include impaired perceptual abilities, memory decline, reduction in the ability to sustain and 
switch attention, and mobility constraints (Groeger, 2000). However, aging is usually a 
gradual process and while some skills deteriorate with increasing age, others (more strategic) 
are used more with increasing age (Haustein, 2013).  
As car drivers, older persons perceive certain driving situations and conditions as 
demanding and potentially dangerous. These include driving in specific weather conditions 
(e.g., fog, rain or a storm), when feeling physically unwell or excited, in high traffic density, 
on specific road types (e.g., motorways or highways), on roads with certain characteristics 
(e.g., signals, traffic lights, curves, roundabouts), and in response to others’ driving behaviors 
(e.g., tailgating) (Jansen et al., 2001; Sullivan, Smith, Horswill, & Lurie-Beck, 2011).  
Compensatory strategies addresses the regulation of loss as a function of aging or 
disability (Riediger, Li, & Lindenberger, 2006; Lindenberger, Lövdén, Michael Schellenbach, 
Li, & Krüger, 2008). It involves efforts (consciously or unconsciously) to maintain a given 
level of functioning despite decline in, or loss of, previously available resources (Riediger, Li, 
& Lindenberger, 2006; Lindenberger, Lövdén, Michael Schellenbach, Li, & Krüger, 2008; 
Donorfio, Mohyde, Coughlin, & D’Ambrosio, 2008; Haustein et al., 2013; Monterde-i-Bort, 
2004). Compensation, in contrast to optimization, aims at counteracting or avoiding losses 
rather than achieving higher levels of functioning (Riediger, Li, & Lindenberger, 2006). 
When driving, compensatory strategies could be a way to maintain the level of risk as 
described in the driver behavior models.  
Older drivers often show a more defensive driving style with lower average speeds 
(Chipman, MacGregor, Smiley, & Lee-Gosselin, 1992; Haustein et al., 2013) and keep a 
larger following distance (Rajalin, Hassel, & Summala, 1997). Age-related changes in driving 
patterns can be seen as a strategy to compensate for age-related decline and thus prolong the 
period of independent safe mobility (Donorfio et al., 2008). 
In psychology, coping refers to the use of conscious effort to solve personal and 
interpersonal problems, seeking to master, minimize or tolerate stress or conflict (e.g., Ben-
Zur, 2009; Carver & Connor-Smith, 2010). One way of coping can be to simply avoid 
situations that cause stress or discomfort. Older drivers have been found to choose not to 
drive in certain conditions or environments and avoid risk-taking (Haustein et al., 2013). 
Driving conditions avoided by older drivers include rush hours, darkness, poor weather or 
road surface conditions, driving in unfamiliar areas (D'Ambrosio et al., 2008; Gwyther & 
Holland, 2012; Hakamies-Blomqvist, 1994; Rothe, 1990). Moreover, older drivers are less 
likely than middle-aged drivers to be engaged in distracting activities such as adjusting in-
vehicle equipment or using a mobile phone (Fofanova & Vollrath, 2012; McEvoy, Stevenson, 
& Woodward, 2006). Avoidance of distracting activities while driving is one coping strategy.  
To summarize, the ability to drive is affected by the deficits that come with age and lead 
to changes in driving behaviors. The behavioral patterns of older drivers are more cautious 
and include both compensatory strategies (e.g., lower speed, longer distance) and coping 
strategies (e.g., avoidance of certain situations or distracting activities).  
 
 

Effect of Hearing Loss on Traffic Safety and Mobility 
 
403
Assessment of Driver Behavior 
 
According to de Waard (1996), good reflectors of primary-task performance at the 
control level (c.f. Michon, 1985) are measures of lateral position (LP) and steering wheel 
(SW) movements and at the maneuvering level (c.f. Michon, 1985) include the time-to-line-
crossing (TLC; Godthelp, 1984). Standard Deviation Lateral Position (SDLP) has been shown 
to be a sensitive performance measure (e.g., Hicks & Wierwille, 1979, O’Hanlon et al., 1982, 
O’Hanlon, 1984). De Waard (1996) showed that increased road complexity could lead to an 
increase in the SD of the SW movements, while the addition of a secondary task reduced the 
SD of the SW movements. Manipulation of both driving speed (e.g., Fuller, 2008; Summala, 
2007; Levis-Evans, 2012) and degree of engagement in secondary tasks (Fuller, 2005) may be 
most important in maintaining the preferred level of risk. 
Visual-search strategy has been shown to be indicative of informational needs (Hughes & 
Cole, 1988). According to de Waard (1996), eye-tracking measures are related to primary-
task performance; however, they can also be used as a secondary-task performance measure 
in the case of embedded tasks. This is how eye tracking was used in the experimental studies 
in the present thesis. In the simulator study, driving was the primary task and an additional 
device was used for the secondary task. In the field study, drivers had to look at the 
navigation display to know which way to go. Relationships between frequency of fixation and 
instrument importance, as well as between length of fixations and difficulty in obtaining 
information from instruments, have been shown by Wilson and Eggemeier (1991). O’Donnell 
and Eggemeier (1986) reported that an increase in workload was accompanied by an 
increased fixation time.  
 
 
Advanced Driver Assistance Systems 
 
One approach to accident prevention and injury reduction is the introduction of in-
vehicle-based preventive safety functions, also known as Advanced Driver Assistance 
Systems (ADAS) (e.g., lane-keeping support, adaptive cruise controllers, collision warning 
systems). In contrast to protective, or passive, in-vehicle safety functions (e.g., seat belt, 
airbag), whose purpose is to mitigate crash consequences, the general goal of ADAS is to 
prevent crashes from occurring at all. This is meant to be achieved either by alerting the 
driver to potential hazards (warning) or by taking over the driving task to some extent 
(intervention), using, for example, autonomous braking in emergency situations (Ljung Aust, 
2012). Carsten and Nilsson (2001) made the distinction between information systems, that 
interact with the driver, and other intervening systems, that interact directly with the vehicle. 
Navigation systems are typical of the former category and adaptive cruise control of the latter. 
An ADAS typically consists of one or more environment sensors mounted on the vehicle, 
for example radars or cameras. Software that uses sensor input determines what actions the 
ADAS should take and the particular driver or vehicle interface is used to alert the driver or 
control the vehicle. Examples of safety technologies, which fall under the ADAS umbrella, 
are Forward Collision Warning (FCW), Adaptive Cruise Control, Lane Departure Warning, 
and Drowsiness Warning (Ljung Aust, 2012).  
A key issue for ADAS systems is to verify that they actually improve traffic safety. 
While the safety potential of ADAS can be affected by many factors, Carsten and Nilsson 

Birgitta Thorslund 
 
404
(2001) proposed that all safety implications can be classified as belonging to either of three 
general aspects: the function safety aspect (technical reliability of the system); the Human 
Machine Interaction (HMI) aspect (operating, and communicating with, the system); and the 
traffic safety aspect (system influence on driving behavior, including changes in interactions 
with other road users).  
Relevant for both the HMI aspect and the traffic safety aspect is the multiple resource 
theory (MRT) presented by Wickens and Hollands (1999). This theory describes information 
processing with stages (perception, WM and cognition, responding), modalities (visual, 
auditory) and codes (verbal, spatial). An important implication of the difference between 
processing codes is the ability to judge which control to use for response. Manual control may 
reduce performance if there are heavy demands on spatial working memory, for instance 
while driving, whereas voice control may disturb the performance of tasks with heavy verbal 
demands (Wickens & Hollands, 1999). 
The HMI aspect is central to the effect of HL on the use of driver assistance systems, 
since communication with the system must be set such that NH is not crucial, meaning that 
output cannot be only auditory. Several studies have shown that tactile support is an intuitive 
and effective way of presenting direction information and alerting drivers to potential 
collisions (van Erp & van Veen, 2004; Ho, Tan, & Spence, 2005; Ho, Reed, & Spence, 2006). 
From the traffic safety aspect, this may release other heavily loaded sensory channels and 
therefore potentially provide a major safety enhancement.  
Another issue is whether there are effects of HL on driving behavior. Concerning the fact 
that most HL is age-related, Li and Perkins (2007) showed that seniors view technology in the 
same way as the general public, and that education has a larger influence on the willingness to 
learn about new technology than age does. For training, simulators can be used to provide 
hands-on experience of new driver support systems and may therefore be valuable supportive 
tools for the elderly driver (Peters & Nielsen, 2007).  
In sum, ADAS aim to increase traffic safety by preventing crashes. To make the systems 
accessible for drivers with HL, alternatives to auditory signals are necessary. Tactile signals 
have been shown to be effective and intuitive in warning and providing directional 
information.  
 
 
GENERAL AIM AND RESEARCH QUESTIONS 
 
The general aim of this thesis is to investigate traffic safety and mobility for individuals 
with HL from a perspective of cognitive psychology by using subjective and objective 
performance indicators. With the limited previous research and knowledge on this specific 
topic, the approach has been necessary exploratory. Three studies were conducted: a 
questionnaire survey and two experimental studies, whereof one driving simulator study and 
one field study. The overall aim of the questionnaire study was to evaluate whether there were 
any differences related to HL with regard to the choice of transportation or on the view of 
hearing in transport situations. With the limited previous knowledge in the field, there were 
no expected differences between the groups. The studies following the questionnaire study 
had more specific research questions and expectations. Henceforth, the population included in 

Effect of Hearing Loss on Traffic Safety and Mobility 
 
405
the studies was older adults, in order to create homogenous groups and also because the 
majority of HL is age-related.  
Based on the results from the survey, the driving simulator study was conducted to 
examine if HL had an effect on driving behavior or on increased workload. Gaze data was 
analyzed to compare visual behavior and in addition, the efficiency of a tactile signal to alert 
the driver was evaluated. A more cautious driving behavior was expected among the drivers 
with HL, because of compensatory strategies such as longer distance to other vehicles, lower 
driving speed and a more active visual search behavior. Coping strategies such as paying less 
attention to the secondary task were also expected.  
A field study was conducted to replicate and validate the effects from the simulator study 
in real traffic. In the field study, the aim was to also evaluate a driver assistance system 
(navigation system) with a supportive tactile signal. Compensatory strategies such as slower 
driving speed and more glances in the mirrors were expected for the drivers with HL. The 
tactile support was expected to lead to more focus on the road, better driving performance and 
higher satisfaction with the system.  
 
 
METHODS 
 
Ethical Considerations 
 
In the studies presented in this thesis, the aim was to create as homogenous groups as 
possible with regard to age-related HL, and to control for vision loss and cognitive decline. 
Ethical considerations mainly concerned integrity issues (no data could be tracked back to 
any individual). Potential ethical problems identified in the studies include missing or lacking 
information with regard to the aim of the studies, the optional participation (participants could 
resign at any time without having to give any motive), the noncompulsory sharing of personal 
audiograms, and the receipt and treatment of the audiograms. All of the studies presented in 
this thesis were conducted during 2011-12 in Linköping and received ethical approval from 
the Research Ethics committee (Etikprövningsnämnden, EPN 2011/125-31; 2012/345-31) in 
Linköping.  
 
 
Methodological Challenges 
 
There were three different assessments to evaluate the effect of HL on traffic safety and 
mobility: the assessment of HL; the assessment of cognition, and the assessment of traffic 
safety each challenging and each with several possible methods. The results from each 
assessment were then to be put in relation to the other 2, which was even more challenging. 
Some of these challenges are presented in this section.  
 
HL Population and Recruitment of Participants 
Individuals with HL constitute a heterogeneous population due to a large variation in age, 
level of HL, and onset and cause of HL. Additionally, HL may be either unilateral or bilateral. 
This heterogeneity, in combination with the low level of knowledge in the area of HL and 

Birgitta Thorslund 
 
406
traffic safety, makes designs with sharp hypothesis-testing difficult to conduct. However, the 
population is large and thus, for the experimental studies and from a heterogeneous 
population included in the questionnaire study, we recruited as homogenous a group as 
possible. This was sensible and realistic, and provided a perspective based on the reality of 
those living with HL.  
Geographical differences and variations in driving experience had also to be considered. 
Traffic situations may be very different in large cities and small towns, and individual driving 
experience may affect how people cope with any particular situation. However, in the studies 
included in this thesis, all participants were recruited from the same region and at least 
mileage per year and years with a driver’s license was controlled for.  
As well as HL, loss of vision is also a part of normal aging (e.g., Risacher et al., 2013; 
Heyl & Wahl, 2012). Wearing glasses can cause problems with eye tracking (Eachus, 
Cassidy, Norgate, Marrow, & Greene, 2008; O'Brien & Sharon, 2009), and this consideration 
restricted our potential participants. Furthermore, there will always be uncertainty of the 
representativeness of participants in any study. Not all individuals are willing to take part in 
research studies, and there is a risk that whatever characterizes those willing to participate 
from those not willing will lead to systematic sampling errors.  
Response rate and completeness of questionnaires are difficult to control when 
participation is voluntary. There are arguments for and against using Internet (electronic) or 
paper and pencil versions. One advantage of electronic versions, besides the efficiency of 
receiving all answers in a database, is the opportunity to control that all questions have been 
answered before submission. However, paper versions have been found to have a higher 
response rate than electronic versions (73.2% compared to 17.9%, respectively) (Kongsved, 
Basnov, Holm-Christensen, & Hjollund, 2007).  
 
Driving Simulator Versus Real Driving 
The advantages of performing simulator studies, including the opportunity to offer a safe 
convenient alternative to measuring driving performance on the road and the ability to keep 
driving conditions and environmental conditions constant, also come with limitations 
(Mullen, Charlton, Devlin, & Bédard, 2001; Nilsson, 1993). For example, motion, velocity 
and acceleration ranges are limited. It is impossible to fully represent a real traffic 
environment, and there is also the chance of simulator sickness, a type of motion sickness 
specifically experienced in simulators (Nilsson, 1993). Moreover, the simulated world does 
not contain the same level of detail and roughness as the real world. Since there is a limited 
amount of details in the simulated world, there is also less to focus on. It is not known how 
much this limitation affects visual behavior. Simulator performance shows medium to strong 
correlations with many on-road driving performance measures, and with other cognitive and 
physiological measures. However, simulators must be validated for each new setting (Mullen 
et al., 2001). 
 
Challenges with Cognitive Assessments 
One of the greatest concerns when creating a test for cognitive assessment is whether or 
not it actually measures what we think it is measuring. A test has construct validity if it 
demonstrates an association between the test scores and the prediction of a theoretical 
characteristic. Hughes, Sapp, and Kohler (2006) presented the challenges of conducting 
accurate cognitive assessments of students with HL. The authors pointed out that poor 

Effect of Hearing Loss on Traffic Safety and Mobility 
 
407
performance on an assessment may not necessarily indicate lower ability, but may be the 
result of a misunderstanding of the type or language of the assessment. Thus, they suggested 
using a variety of measures to assess participants, especially individuals with HL.  
 
 
Procedures and Validity 
 
Procedures and validity are first discussed for the questionnaire study and then for both of 
the experimental studies since several measures are included in the simulator study and the 
field study. 
 
Questionnaire Study 
Along with questions about hearing and transport habits, aspects found in the literature to 
be avoided by older drivers were included in the questionnaire (long distances, rush hours, 
darkness, poor weather, road surface conditions, and driving in unfamiliar areas) 
(D’Ambrosio, 2008; Gwyther, 2012; Hakamies-Blomqvist, 1994; Rothe, 1990). In the 
questions about traffic incidents and accidents definitions from a report from the Swedish 
Road Administration (STRADA, 2007) were used.  
Questionnaire responses were mainly scored using a 5-point scale. The odd number was 
chosen to allow neutral answers, and 5 points was chosen instead of a larger number because 
the data were not expected to be skewed in either direction (Johnston, 2008). The alternatives 
of “do not know” or “not relevant” were also included to avoid forcing participants to tick 
wrong alternatives. A few open questions were also included to allow respondents to answer 
in their own words, and likewise after each closed question there was room for comments. 
 
Experimental Studies 
According to de Waard (1996), self-report scales and performance measures are the most 
appropriate for workload assessment, and a useful experimental design in traffic research is to 
compare task performance in an experimental (e.g., mental load) condition with performance 
under baseline conditions. Evaluation of workload due to complexity should, according to de 
Waard et al., either involve an increase in road complexity or an increase in task complexity, 
for example with the addition of a secondary task. This approach was used in both 
experimental studies. In the simulator study, load conditions with and without a secondary 
task were compared with baseline conditions with and without the secondary task. In the field 
study, road complexity varied between city and ring road, while task complexity either by 
varied including a tactile support in the navigation system or leaving that out. Self-report 
scales during (only in the simulator study) and after the drive were used, as well as 
performance measures.  
Critical incidents, law violations, and LP errors are measures of driving performance and 
have been used as such in task-performance assessments (e.g., Pohlmann & Traenkle, 1994). 
In particular, complex behavior, such as the occurrence of critical incidents or behavior in a 
complex driving environment, can be easier, or more accurately, detected and judged by an 
observer than captured in a single performance measure (de Waard, 1996).  
 

Birgitta Thorslund 
 
408
Pretests 
In both experimental studies, hearing tests were performed on all drivers with NH and for 
participants with HL audiograms were provided from the audiology clinic. The inclusion 
criterion for the NH group was a hearing threshold of maximum 20 dB at each frequency 
(500, 1000, 2000, and 4000 Hz), measured with a pure tone audiometer. Inclusion criterion 
for the HL group was a moderate HL (41-60 dB) according to WHO categories (Arlinger, 
2007), measured with a pure-tone average of 4 mean values, PTA4 (means of 500, 1000, 
2000, and 4000 Hz).  
In the field study (Paper IV), more pretests were included to control for differences 
between the experimental groups. Apart from HL, normal consequences of aging also include 
declining visual abilities, such as visual acuity and contrast sensitivity (e.g., Risacher et al., 
2013; Heyl & Wahl, 2012) and cognition (e.g., McDowd & Shaw, 2000; Verhaeghen et al., 
2003; Mayr et al., 2001; Verhaeghen et al., 2005, Craik & Salthouse, 2000; Phillips & 
Lesperance, 2003). Relationships between sensory and cognitive losses in older adults have 
also been presented (Clay et al., 2009; Heyl & Wahl, 2012; Holland, 2009; Vreeken et al., 
2013). Therefore, in the field study, vision tests and cognitive tests were included to control 
for differences between the groups. 
Clinical vision measures included binocular distance visual acuity using a logMAR chart 
(Ferris, Kassoff, Bresnick, & Bailey, 1982) and binocular contrast sensitivity (log CS) using 
the Pelli-Robson chart (Pelli, Robson, & Wilkins, 1988). Cognitive tests included: verbal 
ability (The F-test, Psykologiförlaget, Stockholm); a cognitive test battery, including physical 
matching, physical lexical matching, rhyme and reading span (Hällgren, Larsby, Lyxell, & 
Arlinger, 2001); a computerized dynamic TMT, shown to be related to driving performance 
(Lehtonen, Dahlström, Hiltunen, & Summala, 2012), and the Useful Field of View test 
(UFOV), measuring skills thought to be used during driving (Ball & Owsley, 1993).  
 
Secondary Task 
In the simulator study, to create 2 levels of cognitive workload in the secondary task the 
phonological similarity effect was used (Conrad & Hull, 1964; Baddeley, 1968; Hitch & 
Halliday, 1983), and the sequences consisted of randomized letters that were either 
phonologically alike (e.g., BDPT) or not phonological alike (e.g., RKNJ). Each letter was 
displayed for 0.7 seconds, which is an adaptation of Sternberg’s scanning paradigm 
(Sternberg, 1966). The display time had to be long enough for recognition of the letters, but 
short enough for the participants to keep their eyes on the display.  
 
Performance Indicators 
Performance indicators in the simulator study were mean LP, SDLP, minimum TLC 
(TLCmin; Brookhuis, Waard, & Fairclough, 2003), mean driving speed, SD driving speed, 
and secondary task performance. For subjective ratings during the simulator test drive, the 
following question was presented on the screen after each event: How critical did you 
experience the situation to be? The participants answered on a scale from 1 = not critical at all 
to 7 = extremely critical. This is an adaptation (specifically the dimension of the degree of 
complication) from the Situation Awareness Rating Technique (SART) 10 Dimension-scale, 
with each dimension ranging from 1-7 (Endsley & Garland, 2000).  

Effect of Hearing Loss on Traffic Safety and Mobility 
 
409
In the field study, mean driving speed and SD driving speed were included along with 
eye tracking (specifically frequency and length of fixations) and driving performance 
assessment according to an on-road protocol (Selander, Lee, Johansson, & Falkmer, 2011).  
 
Table 1. Participants’ demographic details and data collection method  
in the studies 
 
Study 
Participants 
Gender 
(Male/Female) 
Age Mean (SD) 
Male/Female 
Data collection 
method 
I 
93 self-reported NH 
48 mild HL 
105 moderate HL 
47 severe HL 
18 profound HL 
50/43 
17/31 
44/61 
28/19 
7/11 
71.5 (13.2)/63.4 (14.5) 
69.0 (11.1)/68.7 (12.4) 
74.8 (7.7)/61.1 (15.9) 
55.5 (15.1)/75.1 (14.7) 
57.3 (12.6)/65.8 (9.7) 
Questionnaire 
survey 
II 
24 NH 
24 moderate HL 
12/12 
13/11 
60.1 (7.1)/59.6 (5.0) 
62.0 (7.9)/61.0 (9.8) 
Driving simulator 
study with driving 
performance, eye 
tracking, and 
survey 
III 
16 NH 
16 moderate HL 
5/10 
7/8 
51.2 (8.3)/52.8 (11.0) 
60.2 (12.4)/53.0 (13.3) 
Field study with 
eye tracking, 
questionnaire and 
driving assessment 
 
 
Participants and Data Collection 
 
For the questionnaire survey, participants were recruited from the local branch of the 
Swedish hard of hearing association. A control group with normal hearing (NH), matched 
with age, gender and geographical location, was then selected from a commercial database. 
The survey was also used to recruit participants for the other studies by including a question 
about their interest in taking part in further research in the field of HL and traffic safety. The 
VTI participant database was used to recruit participants with NH. Information about 
participants’ demographic details is listed in Table 1 together with the data collection method 
used for each study.  
 
 
Design and Statistical Analyses 
 
Questionnaire Survey 
Logistic regression (binary for dichotomous questions answered by “yes” or “no” and 
ordinal for questions with more than 2 ordered alternatives) was used to analyze the results of 
the questionnaire study because it was explorative and had no inbuilt expectations to examine. 
This is a type of regression analysis with binary or ordinal response variables. The 
probabilities describing the possible outcomes of a single trial are modelled as a function of 
the explanatory (predictor) variables, using a logistic function (Bishop, 2006).  
 
 

Birgitta Thorslund 
 
410
All predictor variables were entered simultaneously, since there was no presumption of 
which one would explain more. The results from the logistic regression are presented using 
odds ratio (OR), which quantifies how strongly the presence or absence of property A in the 
response variable is associated with the values on the predictor variables (McHugh, 2009; 
Mosteller, 1968). That is, this gives a measure of the influence of the predicting variables 
(e.g., degree of HL, gender, age) on the dependent variable (e.g., having a driver’s license). 
OR = 1 means no influence, OR > 1 means an increasing probability, and OR < 1 means a 
decreasing probability.  
 
Driving Simulator Study 
The driving simulator study had a 2 × 2 × 2 factor design with the fixed factors hearing 
status (NH vs. HL), gender (men vs. women), and difficulty level (lower vs. higher). 
Participant (participants 1-48) within hearing status and gender was included as a random 
factor. On driving behavior measures (e.g., speed) and secondary task, analysis with planned 
comparisons within and between the Hearing status levels was carried out using a mixed 
model. For the post-trip questionnaire, with questions on subjects including subjective driving 
performance on ordinal scales, logistic regression and OR were used.  
Analysis of gaze data was conducted in 2 steps. The strategy for analyzing the 
distribution of glances was to start with a model as comprehensive as possible, with several 
variables, interactions, and multidimensional responses. A multivariate analysis of variance 
(MANOVA) was performed to examine whether condition (with or without secondary task), 
hearing status, gender or any two-factor interactions of these had an effect on the distribution 
of glances, where the distribution is governed by a vector representing the 7 target gaze 
zones. In this model, hearing, gender and condition were included as fixed variables, and a 
participant nested within hearing and gender was included as a random variable. The 
significant interaction effect of condition and hearing led to the analysis of each condition and 
each hearing status. ANOVA (analysis of variance) were performed to test hypotheses 
examining one zone at a time. 
 
Field Study 
In the field study a 2 × 2 × 2 factorial design with the between-groups factor hearing 
status (NH vs. HL), and the two within-groups factors system information (visual vs. visual 
tactile), and complexity (lower vs. higher) were used. Generalized estimating equations 
(GEEs) were used to model correlated data from this repeated measures design. GEEs are 
used to estimate the parameters of a generalized linear model with a possible unknown 
correlation between outcomes, and have the advantage of overcoming the classical 
assumptions of statistics, for example independence and normality, which are too restrictive 
for many problems (Liang & Zeger, 1986; James & Joseph, 2003).  
GEEs were used on the following linear or continuous outcome measures: speed, on-road 
performance, gaze behavior patterns, and usability questions. Predictor variables were system 
information (within subjects), hearing category, and age (between subjects). Outputs were 
Wald statistics (χ2), showing the significance, and an unstandardized regression coefficient 
(B), presenting the relationship between the groups. For background questions in the 
questionnaire, cognitive tests, and vision tests one-way ANOVAs were performed.  
 
 

Effect of Hearing Loss on Traffic Safety and Mobility 
 
411
SUMMARY OF STUDIES AND PAPERS 
 
In experimental psychology there are often several parts of a study presented in one 
paper. In this thesis, the studies are fewer and larger and have generated one or 2 papers each, 
which is more common in traffic safety research.  
An overview of studies, papers, and findings is presented in Figure 3. Three studies were 
conducted and generated four scientific papers, which are included in this thesis. Since the 
initial level of knowledge was low and somewhat contradictory, a questionnaire study was the 
first step on the path to evaluate differences in traffic safety and mobility related to HL. The 
results from the first study are presented in the first scientific paper and also included in the 
background to the second study conducted in the driving simulator. The results from this 
study generated the second and third scientific papers and were (together with the results from 
the questionnaire study) included in the background to the third study conducted in real 
traffic. This study generated the fourth scientific paper. Summaries of each study are 
presented in the following sections.  
 
 
Study 1: A Questionnaire Survey 
 
Paper I: The Influence of Hearing Loss on Transport Safety and Mobility 
 
Purpose 
The purpose of study 1 was to examine how road users with different degrees of HL, 
compared to road users with NH, experience traffic safety and mobility. Specifically, three 
general research questions were investigated: how HL affects the choice of transportation 
type (e.g., driving your own car vs. public transport); personal view of HL in relation to 
transport situations, and the need for and design of driver support systems (e.g., collision 
warning, parking aid, navigation systems, lane keeping systems) for drivers with HL.  
 
Method 
A questionnaire survey was conducted with participants recruited from the local branch 
of the Swedish Association for Hard of Hearing People (HRF). A NH control group, random 
and matched by age, gender and geographical location, was selected from a commercial 
database. From audiogram data, participants were sorted into groups according to their degree 
of HL. A web-based questionnaire was constructed to capture the 3 research questions 
mentioned above. With assistance from HRF, letters were sent out to members of their local 
branches with an invitation to take part in the study. There was also the possibility of 
receiving a paper version of the questionnaire. The response rate was 35% (n = 194) in the 
group with HL and 42% (n = 125) in the group with NH. The individuals with hearing loss 
were grouped into four groups according to the degree of their hearing loss (mild, moderate, 
severe, and profound). After receiving permission from the participants, audiograms were 
provided by the local audiology clinic for the HL group.  
 

Birgitta Thorslund 
 
412
 
Figure 3. Overview of studies, papers and findings.  
Results 
A higher degree of HL was associated with less likelihood of having a driver’s license. 
However, individuals with HL who had a driver’s license, drove as much as NH drivers. HL 
was related to the criteria for choosing the type of transport, such that individuals with more 

Effect of Hearing Loss on Traffic Safety and Mobility 
 
413
HL rated written information as more important and time cost and safety as less important 
than those with less HL. However, in the aggregate, no difference between the groups could 
be shown in the distribution of how much each mode of transportation was used. 
With a few exceptions, HL did not affect the ratings of importance of hearing for 
different transportation types. The exceptions were walking and public transportation, where 
respondents with moderate HL rated hearing as significantly more important than those with 
NH. There was no effect of HL on involvement in incidents or accidents.  
Degree of HL was related to several questions of driving ability, and the general pattern 
was that individuals with a higher degree of HL rated driving ability less affected by HL. This 
indicates that they might be using compensatory strategies. The interest in a warning system 
for inattention and the attitude toward strengthening of or complementing auditory 
information in traffic situations was high regardless of HL.  
 
Conclusion 
From this study, it was concluded that HL influences the prevalence of a driver’s license 
and criteria for choosing type of transportation; however, HL has no effect on the distribution 
of how much each type of transportation was used. In general, respondents with more HL 
were less concerned about the effect of HL, indicating that they might be using compensatory 
strategies (adjustments to compensate for a decline). The interest in a warning system for 
inattention and the attitude toward strengthening of auditory information in traffic situations 
was high regardless of HL or not. This suggests a need for further research on compensatory 
strategies and on the design of support systems accessible for drivers with HL. 
 
 
Study 2: A Driving Simulator Study 
 
Purpose 
A simulator study was conducted to compare the effect of cognitive workload in 
individuals with and without HL, respectively, in driving situations with varying degree of 
complexity. The effectiveness of a tactile signal used to call for driver attention was also 
evaluated.  
 
Method 
Twenty-four participants with moderate HL and 24 with NH experienced 3 different 
driving conditions: baseline driving on a 35-km long rural road with a speed limit of 70 
km/hr; critical events with a need to act fast; and a parked car event with the possibility to 
adapt the workload to the situation (e.g., by deciding whether or not to focus on the secondary 
task). A secondary task (observation and recalling of 4 visually displayed letters) was present 
during the drive, with 2 levels of difficulty in terms of load on the phonological loop.  
A tactile signal, presented by means of a vibration in the seat, was used to announce the 
secondary task and thereby simultaneously evaluated in terms of effectiveness when calling 
for driver attention. The letters were displayed on a screen at a low down angle, so that the 
driver had to look away from the road. Twice per minute, drivers were prompted by the tactile 
signal in the seat to first look at and then read back a complete sequence of 4 letters appearing 

Birgitta Thorslund 
 
414
on the display. The total duration of the task corresponds to a critical situation in which 
drivers take their eyes off the road to look at the display. 
For the critical events, to create near collisions, the drivers were distracted by means of 
the secondary task, and then “pushed” across the median toward an oncoming vehicle by 
introducing a steering angle in the simulated vehicle without submitting this information to 
the motion platform. The parked car event was a situation when the participants saw a parked 
car ahead (from 360 meters) with warning lights activated. This study generated 2 papers with 
different focus presented separately below.  
 
Paper II: Cognitive Workload and Driving Behavior in Persons with Hearing Loss 
In this paper, objective driver behavior measures from the simulator study accompanied 
by subjective ratings during and after the test drive are presented, as well as the result from 
secondary task and the questionnaire after driving.  
 
Method 
Driver behavior measures were mean driving speed; SD of Driving speed; mean LP; SD 
of LP; and minimum time to line crossing. The secondary task was analyzed with respect to 
the number of correct recalled letters per task, number of skipped letters per task, and number 
of correct recalled letters per task ignoring the order. Subjective ratings during and after the 
test drive were included to evaluate the realism of the simulated event. There was also a 
questionnaire after driving including self-reported driving behavior, realism of the simulator, 
and evaluation of the tactile signal used to announce the secondary task.  
 
Results 
HL had no effect on driving behavior during baseline driving, where no events occurred. 
During both the secondary task and the parked car event, HL was associated with decreased 
mean driving speed compared with baseline driving. Participants with HL drove 
approximately 6 km/hr slower during the secondary task than NH participants did (approx. 65 
km/hr vs. 70 km/hr), F(1, 44) = 7.68, p = 0.01, ηp2 = 0.14. At the parked car event, 
participants with HL drove approximately 5 km/hr slower, F(1, 44) = 2.42, p = 0.05, ηp2 = 
0.05.  
The effect of HL on the secondary task performance, both at baseline driving and at 
critical events, was more skipped letters and fewer correctly recalled letters. Furthermore, at 
critical events task difficulty affected participants with HL more. There was no effect of HL 
on the secondary task at the parked car event. Participants were generally positive about the 
use of a tactile signal in the seat as a means for announcing the secondary task. There was no 
effect of HL on self-reported driving performance.  
 
Conclusion 
It was concluded that differences in driving behavior and secondary task performance 
related to HL appear when demands increase, either when driving demands exceed baseline 
driving or when the secondary task becomes more cognitively demanding or both. Increased 
demands lead to a more cautious driving behavior with a decreased mean driving speed and 
less focus on the secondary task. This indicate that HL is associated with both compensatory 

Effect of Hearing Loss on Traffic Safety and Mobility 
 
415
strategies and coping strategies. Seat vibration was found to be a feasible way to alert drivers 
with or without HL.  
 
Paper III: Cognitive Workload and Visual Behavior in Elderly Drivers with  
Hearing Loss 
The objective of this paper was to compare visual behavior in individuals with NH and 
with moderate HL, and reveal possible differences by analyzing eye-tracking data from the 
simulator study.  
 
Method 
The cockpit was divided into 7 target zones: windshield, right, left, center mirror, 
speedometer, task display, other. Gaze data were analyzed with respect to distribution of 
glances, fixations in target zones and eye movement behavior. Eye gaze behavior was 
assessed during normal driving and driving with the loading secondary task. The following 
performance indicators were used: number of glances away from the road, mean duration of 
glances away from the road, maximum duration of glances away from the road, and the 
percentage of time when the driver was looking at the road. During the secondary task, 
additional eye movement data were assessed in terms of number of glances to the secondary 
task display, mean duration of glances to the secondary task display, and maximum duration 
of glances to the secondary task display.  
 
Results 
Vertical and horizontal gaze directions showed only small differences between the NH 
and HL groups, such that the HL group tended to have narrower and more distinct gaze 
manners corresponding to the speedometer and the mirrors in the cockpit. There were also 
some indications that, during the secondary task, the HL group looked in the center rear-view 
mirror and further to the right more often than the NH group. Also, it could be seen that 
glances toward the secondary task display were preceded by glances to the mirrors more often 
in the HL group than in the NH group. 
The main result from the analysis of target zones (the objects that the driver looks at 
within the car’s cockpit) was that during the secondary task, drivers with HL looked twice as 
often in the rear-view mirror as they did during normal driving and twice as often as drivers 
with NH regardless of the driving condition.  
Also, during secondary task, drivers with HL showed a different strategy when looking 
away from road. They looked away from the road as much as drivers with NH; however, with 
more frequent glances of shorter duration.  
 
Conclusion 
It was concluded that differences in visual search behavior between drivers with NH and 
drivers with HL are bound to driving condition. During the secondary loading task, drivers 
with HL looked twice as often in the rear-view mirror than during normal driving and than 
drivers with NH, regardless of driving condition. Moreover, during secondary task, drivers 
with HL looked away from the road as much as drivers with NH, but with more frequent 
glances of shorter duration. The results also indicate that drivers with HL performed a visual 
scan of the surrounding traffic environment before looking away toward the secondary task 

Birgitta Thorslund 
 
416
display. This more active visual search behavior might indicate that drivers with HL use 
compensatory strategies to a higher extent than NH drivers.  
 
 
Study 3: A Field Study in Real Traffic 
 
Paper IV: Hearing Loss and a Supportive Tactile Signal in a Navigation System: 
Effects on Driving Behavior and Eye Movements 
 
Purpose 
The purpose of the third study, conducted in real traffic, was to replicate and further 
examine findings from previous simulator study, namely driver compensatory strategies 
associated with HL and evaluate possible effects of additional tactile support in a navigation 
system. Furthermore, since the simulator study indicated differences in gaze behavior 
between drivers with and without HL, eye-tracking data was analyzed as part of the study  
 
Method 
Thirty-two participants (16 HL and 16 NH) performed two pre-programmed navigation 
tasks in an urban environment. In one task, participants received only visual navigation 
information, while in the other vibration in the seat was used as a complement. This tactile 
support was given in the left or the right side of the driver’s seat to indicate the direction of 
the next turn. Performance indicators and measures included driving speed, driving behavior 
observations (using a protocol filled out by a test leader), eye tracking, and a post-drive 
questionnaire. SMI glasses were used for eye tracking, recording the point of gaze within the 
scene. Analysis of gaze data was performed on predefined regions such as windscreen, 
mirrors, navigation display, and speedometer. The questionnaire examined participants’ 
experience of the two navigation tasks in terms of their feelings of safety, usefulness, and 
comfort.  
 
Results 
On road sections with a speed limit of 70 km/hr, participants with a HL drove 4 km/hr 
slower than participants with NH. The same tendency was also seen on sections with a speed 
limit of 50 km/hr; however, this result was not statistically significant.  
During observed driving, participants with NH had on average 0.3 more marks on the 
measure ‘speed too high’ than participants with HL, and participants with HL had 0.5 more 
marks on the measure ‘speed too low’ than those with NH. Participants with HL also 
averaged 1 mark higher on the measure ‘uneven speed’ than participants with NH. 
Participants with HL spent on average 1.4% more time looking in the rear-view mirror than 
NH participants. HL participants looked an average of 3 times as often (0.3 times per minute 
vs. 0.1 times) in the rear-view mirror as the NH group, but there was no effect on the duration 
of glances.  
When driving without the tactile information activated, participants had on average 0.5 
more marks on the measure ‘inattention straight’ and 0.5 more marks on the measure 
‘position distance’ than when they had the tactile information. With the tactile information 
activated, participants looked on average 7% less at the navigation display and consequently 

Effect of Hearing Loss on Traffic Safety and Mobility 
 
417
on average 7% more through the windscreen than without the tactile information. The number 
of glances per minute revealed that without the tactile information, on average participants 
looked once more per minute at the navigation display and there was no effect on the duration 
of glances. With the tactile information activated, both hearing groups were significantly 
more satisfied with their ability to navigate and with the help they got from the system. 
Participants also felt safer and more comfortable in this condition. Furthermore, participants 
in the HL group were significantly more satisfied than the NH group with their ability to 
navigate when the tactile information was activated. There was no effect of HL on self-rated 
driving performance.  
 
Conclusion 
Results from this study revealed that drivers with HL drove more slowly than drivers 
with NH, drove slower and looked more often in their rear-view mirror. These compensatory 
strategies suggest a more cautious driving behavior. The study also showed that tactile 
support leads to higher satisfaction with the navigation system, less time spent looking at the 
navigation display (in terms of frequency), and thus more focus on the road and better driving 
performance (in terms of both attention and distance).  
 
 
GENERAL DISCUSSION 
 
The general aim of this thesis was to investigate traffic safety and mobility for older 
individuals with HL from the perspective of cognitive psychology. With the limited previous 
research and relatively low level of knowledge in this field the approach has been exploratory 
with subjective and objective performance indicators, and the findings from each study have 
been included for further evaluation.  
The questionnaire survey investigated how HL affects the choice of transportation, 
personal views of HL in relation to transport situations, and the design requirements for driver 
support systems accessible for road users with HL. The simulator study examined differences 
in driving behavior and visual behavior between drivers with NH and drivers with HL and the 
effectiveness of a tactile signal to alert drivers. The field study further examined possible 
compensatory strategies associated with HL, the usefulness of an additional tactile support in 
a navigation system, and differences in eye movement patterns.  
 
 
Summary of Results 
 
Summarizing and abstracting the effects of HL throughout the studies included in this 
thesis reveal that the effects of HL on traffic safety and mobility are existing, but small (in 
terms of effect sizes), often bound to workload condition and rather specific, but still 
consistent in the replicated studies.  
The questionnaire revealed that differences in transportation habits related to HL include 
the less likelihood of having a driver’s license and a higher valuing of written information, 
with the latter possibly prioritized before time and safety issues. Moreover, respondents with 
more HL were less concerned about the effect of HL, indicating that they might be using 

Birgitta Thorslund 
 
418
compensatory strategies. In addition, the interest in a warning system and the attitude toward 
strengthening of or complementing auditory information in traffic situations was high 
regardless of hearing ability. These are all new findings, pointing to a few potentially 
important effects of HL from a traffic safety and mobility perspective.  
Furthermore, the questionnaire revealed that HL was not related to the frequency of using 
any of the transportation types (e.g., cars, cycling, or public transportation). There was no 
difference in the patterns with regard to transportation types during wintertime or any effect 
of HL on self-reported incidents or accidents.  
In the experimental studies, differences related to HL in terms of driving behavior 
(mostly lower driving speed) were bound to driving conditions and occurred when the 
complexity of driving task increased (simulator study) or at a higher speed limit (field study). 
There was also an effect of HL on visual behavior, indicated in the simulator study and 
confirmed in the field study. Drivers with HL had a more active visual behavior with more 
frequent glances on the secondary task (simulator study), more frequent glances in the rear-
view mirror, and more general scanning of the environment before looking away from the 
road (simulator study). Secondary task performance was lower for the HL group, with more 
skipped letters, suggesting this group is less willing to perform this task. These are all new 
findings, in line with the expectations, and the effect of HL on driving behavior and on visual 
search behavior suggest people with HL use more compensatory strategies and coping 
strategies leading to a more cautious driving behavior.  
The tactile signal in the driver seat was found useful in both experimental studies, both 
for driver attention and for facilitating navigation with a GPS navigation device. The field 
study showed that the tactile support led to higher satisfaction with the navigation system. 
The tactile support also led to less time spent looking at the navigation display, and thus more 
focus on the road and better driving performance in terms of both attention and distance. 
These are new findings, supporting the expectations and adding to the growing body of 
evidence of the benefits of using tactile information in cars (van Erp & van Veen, 2004; Ho, 
Tan, & Spence, 2005; Ho, Reed, & Spence, 2006).  
In the simulator study (study II), HL had no effect on driving behavior at baseline 
driving, where no events occurred and when no secondary task was present. In the field study, 
the effect of HL on driving speed displayed the same pattern, however was not significantly 
lower, at the lower speed limit. In neither of the experimental studies, there was an effect of 
HL on the self-rated driving performance. 
 
 
Choice of Transportation 
 
ICF, conceptualizing functioning and disability as an interaction between an individual’s 
health condition, contextual factors of the environment and personal factors, includes 
mobility in activity and participation (WHO, 2001). There were some effects of HL found, 
which according to the hierarchical model suggested by Michon (1985), belong to the top 
level, where strategic decisions are made by control processing such as the choice of type of 
transport.  
That the likelihood of having a driver’s license is negatively associated with the degree of 
HL is a new finding. There was no effect of HL on mileage and also no relation between the 
degree of HL and driving cessation. This suggests that in the studied population difficulties or 

Effect of Hearing Loss on Traffic Safety and Mobility 
 
419
lack of interest associated with HL and car driving emerge when deciding whether or not to 
learn to drive. This is an indication of individuals with HL using coping. Knowing that 
difficulty in taking part in activities increase with the degree of HL (Gopinath, Schneider, 
Hickson, et al., 2012a; Grue et al., 2009; Wallhagen et al., 2001; Schneider et al., 2010), one 
could speculate that taking driving lessons might be too difficult for some individuals with 
HL, as some respondents mentioned. The main focus in this thesis is on those with moderate 
HL who are still driving; however, this driver’s license issue is something for further 
research, since car access can act as a compensational tool for functional limitations (Sirén & 
Hakamies-Blomqvist, 2004, 2009) and is associated with better health and well-being among 
the elderly (Ellaway, Macintyre, Hiscock, & Kearns, 2003; Macintyre, Hiscock, Kearns, & 
Ellaway).  
That individuals with HL sometimes find written information more important than time 
cost, and safety issues is also a new finding. According to Rumar (1988), there is always a 
risk in being mobile, and risk can be divided into statistical and experienced risk. There is a 
possibility that individuals with HL feel safer when they have written information and 
therefore prioritize this before statistical safety and time cost. Furthermore, individuals with 
moderate HL expressed a higher need to be able to hear on public transportation than those 
with NH. This is in line with Gopinath et al. (2012), who found that using public 
transportation is harder for individuals with HL, and there might be a need for more written 
information on public transportation to increase experienced safety, activity and participation 
for individuals with HL.  
 
 
Driving Behavior 
 
Motivational driving behavior models all have in common maintenance of the acceptable 
level of risk (Wilde, 1982; Fuller & Santos, 2002; Fuller, 2005, 2007; Fuller et al., 2008; 
Fuller, McHugh et al., 2008; Vaa et al., 2000; Vaa, 2003, 2007, 2011; Näätänen & Summala, 
1974). Consistent with results from Wu et al. (2014), effects on driving behavior for 
individuals with HL emerge when driving task exceeds baseline driving. The main effects 
from the simulator study are consistent with Fuller (2005), suggesting that manipulating 
driving speed and engagement in a secondary tasks are the primary mechanisms for 
maintaining the preferred level of difficulty.  
Lewis-Evans (2012) concluded that speed is not only a conscious choice but rather a 
challenge to be handled, at least on some level, by automatic processes, and that the existence 
of these processes can be inferred when the cognitive capability of drivers is loaded. There is 
a higher risk of cognitive fatigue in individuals with HL, and also possibly a different 
perception of speed (cf. Evans, 1970; Ohta & Komatsu, 1991). Taking this together, there is a 
possibility that drivers with HL may have decreased speed control, and therefore drive slower 
and at a more uneven speed (field study).  
In addition, considering Lewis-Evans’ (2012) suggestion that there is a threshold to 
account for the perception of subjective variables (e.g., task difficulty, effort, comfort, crash 
risk, and feeling of risk), drivers with HL might experience an increased feeling of risk 
(Rumar, 1988) and therefore aim to maintain a different level of risk. This increased feeling 
of risk might come from a decreased perception of the surroundings and decreased feedback 
leading to a decreased feeling of control, which is also reflected in the gaze behavior. That is, 

Birgitta Thorslund 
 
420
they might compensate for the increased risk by driving at a lower speed (e.g., Haustein et al., 
2013), and be less engaged in distracting activities, which is a coping strategy (e.g., Ben-Zur, 
2009; Fofanova & Vollrath, 2012).  
 
 
Visual Behavior 
 
Drivers with HL showed more watchful manners with regard to visual behavior. The 
higher frequency of glances in the mirrors point to the fact that individuals with HL might 
value this kind of information more than that with NH. This new finding is in line with the 
expectations of a compensatory strategy with a more active visual search behavior, due to the 
fact that hearing gives us valuable spatial and temporal resolution. This is also in line with 
Wilson and Eggemeier (1991), who found a relationship between frequency of fixation and 
instrument importance, and this, might be a part of a compensatory behavior.  
Visual search strategy is according to traffic inspectors the most important concept 
related to risk awareness (Lidestam et al., 2010). The difference between drivers with HL and 
drivers with NH in the strategy of looking away from the road was apparent during the 
secondary task in the driving simulator. Drivers with HL looked away more often and for a 
shorter period each time; however, there was no effect of HL on total time with the eyes off 
the road. Again, this behavior might be connected to the experienced safety and feeling of 
risk, suggesting that avoiding long glances away is a coping strategy on the part of those with 
HL.  
With the descriptive and explorative approach of this thesis, the relationship between the 
secondary task performance in Paper II and the gaze behavior in Paper III is interesting. In 
Paper II, we concluded that drivers with HL might be less willing to make an effort to 
perform the secondary task. Their lower performance might also be due to the fact that the 
task loads on the phonological loop and is thus more cognitively demanding for drivers with 
HL. An acquired HL may lead to a deteriorated function in the phonological loop, which 
means that drivers with HL should need to look at the letters for a longer time. However, as 
seen in Paper III, on the contrary they look at the secondary task display more frequently and 
with shorter duration compared to drivers with NH. This indicates that with the limited 
capacity during the secondary task, which also results in decreased speed for drivers with HL, 
driving safety is prioritized before performance on the task, which could be a sign of 
compensatory behavior.  
 
 
Driver Assistance Systems 
 
In the questionnaire survey, the interest in driver assistance systems was not affected by 
HL and suggested evaluation of alternative modality for driver support systems. From the 
classifications suggested by Carsten and Nilsson (2001), the HMI aspect (operating and 
communicating with the system) and the traffic safety aspect (system influence on driving 
behavior, including changes in interactions with other road users) are relevant for evaluating 
the effect of HL. Concerning the HMI aspect, and in line with the expectations and previous 
findings (e.g., van Erp & van Veen, 2004;), the tactile signal in the driver’s seat was useful in 
both experimental studies, for both calling for driver attention and facilitating navigation with 

Effect of Hearing Loss on Traffic Safety and Mobility 
 
421
a GPS device. Furthermore, of high relevance for the traffic safety aspect, regardless of 
hearing status, the tactile support led to higher satisfaction with the navigation system, less 
time spent looking at the navigation display, more focus on the road, and better driving 
performance. This was in line with the expectations too, and may increase traffic safety for 
drivers regardless of HL or not, since this may release other heavily loaded sensory channels 
(c.f. Wickens and Hollands, 1999) and therefore potentially provide a major safety 
enhancement.  
 
 
Methodological Discussion 
 
The advantages of performing a simulator study also come with limitations (Mullen, 
Charlton, Devlin, & Bédard, 2001; Nilsson, 1993). For example, motion, velocity and 
acceleration ranges are limited, it is impossible to fully represent a real traffic environment, 
and participants may suffer from simulator sickness, a type of motion sickness experienced 
only in simulators (Nilsson, 1993). 
There was an effect of HL, such that drivers with NH experienced the simulator as more 
realistic. Also, some effects of eye movement behavior indicated in the simulator were 
confirmed in the field study. These two effects might be related, such that the realism was 
needed for some of the effects to show. Also, female drivers with HL reported the highest 
values of simulator sickness, which might be connected to the realism of the simulator, such 
that higher experienced realism lead to less simulator sickness.  
Age-related HL is the most common type of HL and thus it is most relevant to look at the 
effects of HL in the group of older people. With a quasi-experimental design (HL vs. NH) 
follows a heterogeneity between groups. To create as homogenous groups as possible, apart 
from hearing status, the aim was to recruit participants under 65 years of age to avoid age 
effects.  
 
 
CONCLUSION 
 
From the studies included in this thesis, it can be concluded that there are effects of HL 
on both traffic safety and mobility, such that individuals with HL are less likely to have a 
driver’s license, more likely to show a more cautious driving behavior, and will sometimes 
prioritize experienced safety before statistical safety. The effects of HL revealed in this thesis 
are new findings and add to the knowledge and understanding of the influence of HL on 
traffic safety and mobility. Differences found consistently point to a generally more cautious 
behavior, which suggests an effect of HL on experienced safety. 
Compensatory strategies and coping strategies associated with HL are bound to driving 
complexity and appear when complexity increases. These strategies include driving at lower 
speeds, using a more comprehensive visual search behavior (compensatory) and being less 
engaged in distracting activities (coping).  
The influence of HL on the choice to drive a car is limited to the decision of whether or 
not to learn to drive, since HL does not affect mileage or driving cessation.  

Birgitta Thorslund 
 
422
Evaluation of a tactile signal suggests that by adding a tactile modality, some driver 
assistance systems can also be made accessible to drivers with HL. At the same time, the 
systems might be more effective for all users, since visual resources can be more focused on 
the road, which could generally increase both traffic safety and mobility.  
Based on the results in this thesis, drivers with HL cannot be considered an increased 
traffic safety risk, and there should be no need for adjustments of the requirements of hearing 
for a license to drive a car. 
 
 
SUGGESTIONS FOR FUTURE RESEARCH 
 
This thesis presents exploratory and experimental research on the effects of HL on traffic 
safety and mobility. Some effects of HL have been found (suggesting a more cautious driving 
behavior), which can be used in future recommendations. There are also some aspects worth 
looking into further. Generally, it is possible that individuals with disabilities (of different 
kinds) might contribute to a better understanding of how to design better driver support 
systems. Since they are more sensitive to higher workload, they might be able to indicate how 
to develop support systems, which might be more useful for all drivers.  
The compensatory strategies found, indicating maintenance of a different level of 
difficulty, suggest further investigation of the effect of HL on feeling of risk.  
The possibility of individuals with HL experiencing higher safety when there is written 
information and therefore prioritizing this before statistical safety and time cost is worth 
further evaluation.  
The accessibility of written information on public transportation is relevant to evaluate, 
since differences appeared in this and other studies (Gopinath et al., 2012b) related to the 
degree of HL.  
Less likelihood of having a driver’s license suggests further evaluation of the driving 
lesson situation for individuals with HL.  
Positive effects of tactile signals in driver assistance systems suggest further research on 
how to implement accessible signals in these systems.  
The effect of the use of hearing aid technologies when driving should be further 
investigated. This was not included in the studies presented in this thesis although there is 
reason to believe that the right aid can increase traffic safety and mobility (e.g., McCloskey, 
Koepsell, Wolf, & Buchner, 1994; Wu et al., 2014).  
The fact that there is a decline in various abilities (e.g., cognitive, visual, auditory) 
associated with normal aging, makes further examination of the effects of decline in each type 
and combination of types, and also the effects of aid for each type, relevant for future study.  
The effects of HL on perception and decision-making have not been examined explicitly 
in studies presented in this thesis. However, the results pointing at a difference in experienced 
safety associated with HL suggest that these aspects should be further studied.  
The studies included in this thesis focus on age-related HL. It would be of interest to look 
at the effects of other types of HL such as genetic deafness or individuals with CI.  
It would be relevant to study the effects of HL on cognitive fatigue and of cognitive 
fatigue on traffic safety, since cognitive fatigue is a known effect of HL (e.g., Moradi et al., 

Effect of Hearing Loss on Traffic Safety and Mobility 
 
423
2014; Rönnberg et al., 2013) and could lead to decreased attention. Also, studying the effect 
of reducing cognitive fatigue on traffic safety can add to the understanding of the problem.  
In this field of research, investigation into specific effects of decline in different aspects 
of EF, rather than attention to the broad perspective, is more likely to yield a more 
comprehensive picture.  
It could be worthwhile to study other modalities of driver assistance systems than 
auditory and tactile, such as ambient (light), and to evaluate which modalities and ways of 
presenting the information are most suitable to which driver group or in which situations.  
 
 
ACKNOWLEDGMENTS 
 
Many people contributed to this work in many different ways and made the PhD journey 
possible, more solid, or simply more enjoyable. I want to express my greatest thanks to: 
All the wonderful participants, who took part in my studies, shared your ideas, and 
showed your great interest in my work. 
My boss Jan Andersson, the coaching master, for making this possible. You liked this 
idea from the start and you have supported me all the way with your positive attitude and 
enthusiasm. 
Björn Lyxell, my main supervisor. Your professional way of restricting the study 
population and guiding me towards sensible frames was invaluable, as were your friendly 
phone calls just to check on how things were going. I also appreciate how you led me through 
the funding jungle, resulting in 4 great months in Australia for me and my family. 
Björn Peters, who was concerned that co-supervising me would affect our friendship. 
Well, I was not concerned at all, and I believe I was right. You showed great generosity in 
inviting me to and inspiring me in your area of expertise, which is one of the main reasons I 
enjoy working with you. I am also grateful for your establishment of national and 
international contacts for me. 
Björn Lidestam, my co-supervisor. Although you often expressed doubts about your own 
contribution to this work, I have always appreciated your involvement. You have the ability 
to recognize the most essential and most interesting results and a remarkable way of un-
complicating things by breaking them down to pieces. I look forward to working more with 
you now that you have joined our group. 
Louise Hickson, for your positive response to my query on visiting you as a guest PhD 
student. Thanks to you, Joanne Wood, Alex Black, and Alicja Malicka, my time at QUT and 
UQ in Brisbane was both enlightening and enjoyable. I look forward to future collaborations 
between our groups. 
I am fortunate to work at an institute where people are professional, friendly, and truly 
helpful. Lena Nilsson, you are the one who first hired me and recommended me to the 
ergonomics course, and this was crucial in the decisions that led me to where I am now. Jonas 
Jansson, you handed over a simulator project to me at a perfect time and this allowed me to 
collect a great amount of data in a short time, resulting in 2 published papers. Christer 
Ahlström, co-writer and dedicated data analyst, I appreciate your efficient and exemplary way 
of working, whether with study planning, data processing, or writing. Olle Eriksson, co-writer 
and statistics expert, I am grateful for your never-ending patience with my statistics questions 

Birgitta Thorslund 
 
424
and your good collaboration on Paper III. Thanks are also due to many colleagues, who with 
their expertise have all contributed in some valuable way to the studies: Anders Andersson, 
Jonas Andersson Hultgren, Björn Blissing, Anne Bolling, Anders Genell, Per Henriksson, 
Kristina Kindgren, Lena Levin, Katarina Nestor, Beatrice Söderström, Gunilla Sörensen, 
Harry Sörensen. 
During my years at VTI, I have met some of my best friends. Sara Nygårdhs, thank you 
for simply being the genuine you. Katja Kircher, regardless of how busy you are, you always 
find the time to stay updated on and support my activities. Magnus Hjälmdahl, Jessica Berg, 
and Therese Jomander, the chats we have during lunch, coffee breaks, and between breaks 
are invaluable and the first thing I miss when I am away. Jerker Sundström, thank you for this 
advice: If you ever go for a PhD, chose a subject that really interests you. Malin Eliasson, I 
have always appreciated your rationality and never-ending energy. 
I am grateful for the colleagues that I got to know at the Disability Research Division and 
HEAD graduate school. Specifically, I want to thank Håkan Hua, for being a good friend 
through this journey and also for sharing your knowledge on Audiology; Jakob Dahl, for our 
interesting discussions on any topic; Claes Möller, for good and recurring email discussions 
on balance and motion sickness; Shahram Moradi for sharing your knowledge on cognitive 
fatigue; Malin Wass, for sharing your experience on how to apply for grants and go to 
Australia; Mary Rudner, for your guidance through the special research project, definitely my 
best course, and Maria Hugo Lindén for your fine administrative help, including organizing 
ticket and room bookings for courses located in other cities. 
I have met many helpful people here and there to whom I want to express my thanks: 
Birgitta Larsby for lending me equipment, sharing your knowledge on audiology and helping 
me with participant recruitment. I am looking forward to more collaborations with you!; 
Therese Bohn Eriksson and Henrik Lindgren and the audiology clinics in Linköping and 
Norrköping for providing audiograms on the recruited participants; HRF, and in particular 
Jan-Olof Bergold, Diego Hedman, and Lautaro Aranda, for your cooperation with participant 
recruitment and input on the questionnaire; Kenneth Holmqvist for lending me the eye-
tracking equipment, sharing your knowledge, and cooperating so helpfully in the field study, 
Nicholas Herbert for good teamwork in the field study. I hope we get a chance to work 
together again in the future, and the father of WM, Alan Baddeley, for responding so quickly 
and helpfully to my email with a question about display time. 
A big thank to my near and dear ones, my family and friends, for being my source of 
energy. You all know who you are and that I love to have you around! Among these, a special 
thanks to Mum and Dad, for always believing in me, and being constantly supportive but 
never intrusive, and to my cousin Mattias, for your great interest in what I am doing and your 
instant support in the English language.  
Finally, my wise and loving husband Tobias, thank you for being just the way you are, 
my favorite person. I love you.  
 
 
REFERENCES 
 
Andersson, U. (2002). Deterioration of the phonological processing skills in adults with an 
acquired severe hearing loss. European Journal of Cognitive Psychology, 14(3), 335-352. 

Effect of Hearing Loss on Traffic Safety and Mobility 
 
425
Andersson, U., & Lyxell, B. (1999). Phonological deterioration in adults with an acquired 
severe hearing impairment. Scandinavian Audiology, 28(4), 241-247. 
Andersson, U., Lyxell, B., Rönnberg, J. & Spens, K.-E. (2001). Cognitive correlates of visual 
speech understanding in hearing-impaired individuals. Journal of Deaf Studies and Deaf 
Education, 6, 103-116. 
Arlinger, S. (2003). Negative consequences of uncorrected hearing loss – A review. 
International Journal of Audiology, 42(2), 17-20. 
Arlinger, S. (Ed.) (2007). Nordisk Lärobok i Audiologi [Nordic textbook of audiology]. 
Bromma: C-A Tegnér AB. 
Atkinson, R. C., & Shiffrin, R. M. (1968). Human memory: A proposed system and its control 
processes. In K. W. Spence & J. T. Spence (Eds), The psychology of learning and 
motivation (Vol 2). New York: Academic Press. pp. 89-195. 
Ausmeel H. (1988). TIPS (Text-Information-Processing-System): A user’s guide. Linköping, 
Sweden: Department of Education and Psychology, Linköping University. 
Baddeley, A. (2012). Working memory: Theories, models, and controversies. Annual Revue 
of Psychology 63, 1-29. 
Baddeley, A. D. (1968). How does acoustic similarity influence short term memory? 
Quarterly Journal of Experimental Psychology, 20, 249-264. 
Baddely, A. (2000). The episodic buffer: a new component of working memory? Trends in 
Cognitive Sciences, 4(11), 417-423. 
Baddeley, A. (1983). Working memory. Philosophical Transactions of the Royal Society, 
302, 311–324. 
Ball, K., & Owsley, C. (1993). The Useful Field of View Test: a new technique for evaluating 
age-related declines in visual function. Journal of the American Optometric Association, 
64(1), 71-79. 
Ball, K., Owsley, C., Sloane, M. E., Roenker, D. L., & Bruni, J. R. (1993). Visual-attention 
problems as a predictor of vehicle crashes in older drivers. Investigative Ophthalmology 
& Visual Science, 34(11), 3110-3123. 
Ball, K., Owsley, C., Stalvey, B., Roenker, D. L., Sloane, M. E., & Graves, M. (1998). 
Driving avoidance and functional impairment in older drivers. Accident Analysis & 
Prevention, 30, 313-323. 
Baltes, P. B. & Lindenberger, U. (1997). Emergence of a powerful connection between 
sensory and cognitive functions across the adult life span: a new window to the study of 
cognitive aging? Psychology and Aging, 12, 12-21. 
Banister, D., & Bowling, A. (2004). Quality of life for the elderly: the transport dimension. 
Transport Policy, 11(2), 105-115. 
Ben-Zur, H. (2009). Coping styles and affect. International Journal of Stress Management, 
16(2), 87-101. 
Bishop, C. M. (2006). Pattern recognition and machine kearning. New York: Springer-
Verlag. 
Bonnel, W. (1999). Giving up the car: older women’s losses and experiences. Journal of 
Psychosocial Nursing and Mental Health Services, 37, 10-15. 
Bopp, K. L., & Verhaeghen, P. (2005). Aging and verbal memory span: a meta-analysis. 
Journals of Gerontology Series B: Psychological Sciences and Social Sciences, 60(5), 
223-233. 

Birgitta Thorslund 
 
426
Bowles, R. P., & Salthouse, T. A. (2008). Vocabulary test format and differential relations to 
age. Psychology and Aging, 23(2), 366-376. 
Brayne, C., Dufouil, C., Ahmed, A., Dening, T. R., Chi, L-Y., McGee, M., & Huppert, F. A. 
(2000). Very old drivers: Findings from a population cohort of people aged 84 and over. 
International Journal of Epidemiology, 29(4), 704-707. 
Brookhuis, K. A., Waard, D. D., & Fairclough, S. H. (2003). Criteria for driver impairment. 
Ergonomics, 46(5), 443-445. 
Brickman A. M., & Stern Y. (2009). Aging and memory in humans. In: L.R. Squire (Ed.) 
Encyclopedia of Neuroscience (Vol. 1) Oxford: Academic Press. pp. 175-180. 
Carsten, O., & Nilsson, L. (2001). Safety assessment of driver assistance systems. European 
Journal of Transport and Infrastructure Research, 1(3), 225-243. 
Carver, C. S., & Connor-Smith, J. (2010). “Personality and Coping”. Annual Review of 
Psychology, 61, 679-704. 
Catchpole, K., & McKeown, D. (2007). A framework for the design of ambulance sirens. 
Ergonomics, 50(8), 1287-1301. 
Cerella, J. (1990). Aging and information-processing rate. In: J.E. Birren, & K.W. Schaie 
(Eds.), Handbook of the psychology of aging, 3rd ed. San Diego, CA: Academic Press, 
pp. 201-221. 
Charlton, J. L., Oxley, J., Fildes, B., Oxley, P., & Newstead S. (2003). Self-regulatory 
behaviours of older drivers. Annual Proceedings Advancement of Automotive Medicine, 
47, 181-194. 
Chipman, M. L., MacGregor, C. G., Smiley, A. M., & Lee-Gosselin, M. (1992). Time vs. 
distance as measures of exposure on driving surveys. Accident Analysis & Prevention, 
24(6), 679-684. 
Classon, L. (2013) Phonological decline and compensatory working memory in acquired 
hearing impairment. Doctoral Dissertation. The Swedish Institute for Disability 
Research. Linköping University. 
Clay, O. J., Edwards, J. D., Ross, A. L., Okonkwo, O., Wadley, V. G., Roth, D. L., & Ball, K. 
K. (2010). Visual function and cognitive speed of processing mediate age-related decline 
in memory span and fluid intelligence. Journal of Aging Health, 21(4): 547-566. 
Conrad, R., & Hull, A. J. (1964). Information, acoustic confusion and memory span. British 
Journal of Psychology, 55, 429-437. 
Conway A. R., Kane M. J., & Engle R. W. (2003). Working memory capacity and its relation 
to general intelligence. Trends in Cognitive Sciences, 7(12): 547-552. 
Craik, F. I. M., & Salthouse, T. A. (2000). The handbook of aging and cognition (Second 
ed.). London: Lawrence Erlbaum Associates. 
D’Ambrosio, L. A., Donorfio, L. K. M., Coughlin, J. F., Mohyde, M., & Meyer, J. (2008). 
Gender differences in self-regulation patterns and attitudes toward driving among older 
adults. Journal of Women & Aging, 20(3-4), 265-282. 
Daneman, M. & Carpenter, P. (1980). Individual differences in working memory and reading. 
Journal of Verbal Learning and Verbal Behavior, 19, 450-466. 
Daneman, M. & Merikle, P. M. (1996). Working memory and language comprehension: a 
meta-analysis. Psychonomic Bulletin and Review, 3, 422-433. 
De Lorenzo, R. A., & Eilers, M. A. (1991). A review of emergency warning systems. Annals 
of Emergency Medicine, 20(12), 1331-1335 

Effect of Hearing Loss on Traffic Safety and Mobility 
 
427
De Waard, D. (1996). The measurement of drivers’ mental workload. Thesis. University of 
Groningen, Netherlands. 
Dellinger, A. M., Kresnow, M., White, D. D., & Sehgal, M. (2004). Risk to self versus risk to 
others: how do older drivers compare to others on the road? American Journal of 
Preventive Medicine, 26(3), 217-221. 
Diamond, A. (2013). Executive functions. Annual Review of Psychology, 64, 135-168. 
Dillén, J., Schmidt, L., & Jarlebring, I. (2005). Äldre personers resvanor och aktiviteter 
[Older adults’ travel habits and activities]. Solna: Transek. 
Dimitrijevic, A., John, M. S., & Picton, T. W. (2004). Auditory steady-state responses and 
word recognition scores in normal-hearing and hearing-impaired adults. Ear and 
Hearing, 25, 68-84. 
Donorfio, L. K. M., Mohyde, M., Coughlin, J., & D’Ambrosio, L. (2008). A qualitative 
exploration of self-regulation behaviors among older drivers. Journal of Aging & Social 
Policy, 20(3), 323-339. 
Eachus, P., Cassidy, S., Norgate, S., Marrow, L., & Greene, L. (2008). Internet self-efficacy 
and visual search strategies: The use of eye tracking technology in the development of 
web-based learning resources. Informing Science & IT Education Conference. Varna, 
Bulgaria. 
Edwards, J. D., Lunsman, M., Perkins, M., Rebok, G. W., & Roth D. L (2009). Driving 
cessation and health trajectories in older adults. Journals of Gerontology Series A: 
Biological Sciences and Medical Sciences, 64(12), 1290-1295. 
Ferris, F. L., Kassoff, A., Bresnick, G. H., & Bailey, I. (1982). New visual acuity charts for 
clinical research. American Journal of Ophthalmology, 94, 91-96. 
Ellaway, A., Macintyre, S., Hiscock, R., & Kearns, A. (2003). In the driving seat: 
psychosocial benefits from private motor vehicle transport compared to public transport. 
Transportation Research Part F: Traffic Psychology and Behaviour, 6, 217-231. 
Elliott, E. M., Cherry, K. E., Brown, J. S., Smitherman, E. A., Jazwinski, S. M., Yu, Q., & 
Volaufova, J. (2011). Working memory in the oldest-old: evidence from output serial 
position curves. Memory & Cognition, 39(8), 1423-1434. 
Endsley, M. R., & Garland, D. J. (2000). Situation awareness analysis and measurement. 
London: Lawrence Erlbaum Associates. 
Engle, R. W., Tuholski, S. W., Laughlin, J. E., Conway, A. R. (1999). Working memory, 
short-term memory, and general fluid intelligence: A latent-variable approach. Journal of 
Experimental Psychology: General 128(3), 309-31. 
Englund, L. (Ed.). (2001). Medicinska förhållanden av betydelse för innehav av körkort - 
Hörsel och balanssinne [Medical conditions of importance for obtaining a driving 
license]: Vägverket, Trafikmedicinska rådet. 
Evans, L. (1970). Speed estimation from a moving automobile. Ergonomics, 13(2). 
Eysenck, M. W., & Keane, M. T. (2010). Cognitive psychology: a student’s handbook (6th 
ed.): East Sussex: Psychology Press. 
Farquhar, M. (1995). Elderly people’s definitions of quality of life. Social Science & 
Medicine, 41(10), 1439-1446. 
Fitzgibbons, P. J., & Gordon-Salant, S. (2010). Behavioral studies with aging humans: 
Hearing sensitivity and psychoacoustics In S. Gordon-Salant, R. D. Frisina, A. Popper, & 
D. Fay (Eds.), The aging auditory system: Perceptual characterization and neural bases 
for presbyacusis. Berlin: Springer. 

Birgitta Thorslund 
 
428
Fofanova, J., & Vollrath, M. (2012). Distraction in older drivers –a face-to-face interview 
study. Safety Science, 50(3), 502-509. 
Fonda, S. J., Wallace, R. B., & Herzog, A. R. (2001). Changes in driving patterns and 
worsening depressive symptoms among older adults. Journals of Gerontology Series B: 
Psychological Sciences and Social Sciences, 56B (6), 343-351. 
Forrest, K. Y. Z., Bunker, C. H., Songer, T. J., Cohen, J. H., & Cauley, J. A. (1997). Driving 
patterns and medical conditions in older women. Journal of the American Geriatrics 
Society, 45(10), 1214-1218. 
Frisina, D. R., & Frisina, R. D. (1997). Speech recognition in noise and presbycusis: relations 
to possible neural mechanisms. Hearing Research, 106(1-2), 95-104. 
Fuller, R. (2000). The Task Capability Interface Model of the driving process. Recherche 
Transports Sécurité, 66, 47-59. 
Fuller, R. (2005). Towards a general theory of driver behaviour. Accident Analysis & 
Prevention, 37(3), 461-472. 
Fuller, R. (2007). Motivational determinants of control in the driving task. In: P. Cacciabue 
(Ed.), Modelling driver behaviour in automotive environments: critical issues in driver 
interactions with intelligent transport systems. London: Springer; pp. 165-188. 
Fuller, R. (2011). Driver control theory: From task difficulty homeostasis to risk allostasis. In 
B. Porter (Ed.), Handbooks of Traffic Psychology. Waltham, MA: Academic Press. 
Fuller, R., Bates, H., Gormley, M., Hannigan, B., Stradling, S., Broughton, P., Kinnear, N., & 
O’Dolan, C. (2008). The conditions for inappropriate high speed: a review of the 
research literature from 1995 to 2006. London: Department of Transport. 
Fuller, R., McHugh, C., & Pender, S. (2008). Task difficulty and risk in the determination of 
driver behaviour. Revue Européenne De Psychologie Appliquée/European Review of 
Applied Psychology, 58(1), 13-21. 
Fuller, R., & Santos, J.A. (2002). Psychology and the highway engineer. In R. Fuller, & J. A. 
Santos (Eds.), Human factors for highway engineers. Bingley, UK: Pergamon. 
Gabaude, C., Marquié, J., & Obriot-Claudel, F. (2010). Self-regulatory behaviour in the 
elderly: relationships with aberrant driving behaviours and perceived abilities. Le Travail 
Humain, 73(1), 31-52. 
Gabriel, Z., & Bowling, A. (2004). Quality of life from the perspectives of older people. 
Ageing and Society, 24, 675-691. 
Gagliardi, C., Marcellini, F., Papa, R., Giuli, C., & Mollenkopf, H. (2010). Associations of 
personal and mobility resources with subjective well-being among older adults in Italy 
and Germany. Archives of Gerontology and Geriatrics, 50(1), 42-47. 
Gibson, J. J., & Crooks, L. E. (1938). A theoretical field-analysis of automobile-driving. The 
American Journal of Psychology, 51(3), 453-471. 
Glad, A. (1977). Requirements regarding drivers: hearing ability. Oslo: Institute of Transport 
Economics. 
Godthelp, J. (1984). Studies on human vehicle control. PhD Thesis, Soesterberg, The 
Netherlands: Institute for Perception, TNO. 
Gopinath B., Schneider, J., McMahon, C. M., Teber, E., Leeder, S. R, Mitchell, P. (2012). 
Severity of age-related hearing loss is associated with impaired activities of daily living. 
Age and Ageing 41(2):195-200. 

Effect of Hearing Loss on Traffic Safety and Mobility 
 
429
Gopinath, B., Schneider, J., Hickson, L., McMahon, C. M., Burlutsky, G., Leeder, S. R., & 
Mitchell, P. (2012). Hearing handicap, rather than measured hearing impairment, predicts 
poorer quality of life over 10 years in older adults. Maturitas, 72(2), 146-151. 
Gordon-Salant, S. (2005). Hearing loss and aging: new research findings and clinical 
implications. Rehabilitation Research and Development, 42(4), 9-23. 
Gorman M. (1999) Development and the rights of older people. In: Randel, J., German, T., 
Ewing, D. (Eds.). The ageing and development report: poverty, independence and the 
world’s older people. London: Earthscan Publications; pp 3-21. 
Grady, C. (2012). The cognitive neuroscience of ageing. Nature Reviews Neuroscience, 
13(7), 491-505. 
Granick, S., Kleban, M. H. & Weiss, A. D. (1976). Relationships between hearing loss and 
cognition in normally hearing aged persons. Journal of Gerontology, 31(4), 434-440. 
Green, K. A., McGwin, G., & Owsley, C. (2013). Associations between visual, hearing, and 
dual sensory impairments and history of motor vehicle collision involvement of older 
drivers. Journal of the American Geriatrics Society, 61(2), 252-257. 
Groeger, J. A. (2000). Understanding driving: Applying cognitive psychology to a complex 
everyday task. London: Routledge. 
Grue, E. V., Schroll, M., Jónsson, P. V., Ranhoff, A. H., Noro, A., Finne-Soveri, H., Jonsén, 
E. (2009). Vision and hearing impairments and their associations with falling and loss of 
instrumental activities in daily living in acute hospitalized older persons in five Nordic 
hospitals. Scandinavian journal of Caring Sciences, 23(4), 635-643. 
Gwyther, H., & Holland, C. (2012). The effect of age, gender and attitudes on self-regulation 
in driving. Accident Analysis & Prevention, 45, 19-28. 
Hakamies-Blomqvist, L. (1994). Aging and fatal accidents in male and female drivers. Social 
Sciences, 49(6), 286-290. 
Hakamies-Blomqvist, L., & Wahlström, B. (1998). Why do older drivers give up driving? 
Accident Analysis & Prevention, 30(3), 305-312. 
Hardin, J., & Hilbe, J. (2003). Generalized estimating equations. London: Chapman and 
Hall/CRC 
Hatakka, M., Keskinen, E., Gregersen, N. P., Glad, A., & Hernetkoski, K. (2002). From 
control of the vehicle to personal self-control; broadening the perspectives to driver 
education. Transportation Research Part F: Traffic Psychology and Behaviour, 5(3), 
201-215. 
Haustein, S., Sirén, A., Franke E., Pokrieke, E., Alauzet, A., Marin-Lamellet, C., Armoogum, 
J., O’Neill, D. (2013). Demographic change and transport. Final report of WP1:Consol. 
Heyl, V., & Wahl, H. W. (2012). Managing daily life with age-related sensory loss: cognitive 
resources gain in importance. Psychology and Aging, 27(2):510-521. 
Hitch, G. J., & Halliday, M. S. (1983). Working memory in children. Philosophical 
Transactions of the Royal Society of London: Series B, 302, 325-340. 
Hicks, C. B., Tharpe, A. M. (2002). Listening effort and fatigue in school-age children with 
and without hearing loss. Journal of Speech, Language, and Hearing Research, 45, 573-
584. 
Hicks, T. G. & Wierwille, W. W. (1979). Comparison of five mental workload assessment 
procedures in a moving-base driving simulator. Human Factors, 21(2), 129-143. 

Birgitta Thorslund 
 
430
Hickson, L., Wood, J., Chaparro, A., Lacherez, P., & Marszalek, R. (2010). Hearing 
impairment affects older people’s ability to drive in the presence of distracters. Journal of 
the American Geriatrics Society, 58(6), 1097-1103. 
Hjorthol, R., Levin, L. & Sirén, A. (2010). Mobility in different generations of older persons. 
The development of daily travel in different cohorts in Denmark, Norway and Sweden. 
Journal of Transport Geography, 18(5), 624-633. 
Ho, C., Reed, N., Spence, C. (2006). Assessing the effectiveness of “intuitive” vibrotactile 
warning signals in preventing front-to-rear-end collisions in a driving simulator. Accident 
Analysis and Prevention, 38, 988-996. 
Ho, C., Tan, H. Z., Spence, C. (2005). Using spatial vibrotactile cues to direct visual attention 
in driving scenes. Transportation Research Part F: Traffic Psychology and Behaviour, 8, 
397-412. 
Holland, C. A. (2009). The relationships between sensory and cognitive decline in older age. 
ENT & Audiology News, 18(4), 94-95. 
Holland, C. A., & Rabbitt, P. M. A. (1992). People’s Awareness of their age-related sensory 
and cognitive deficits and the implications for road safety. Applied Cognitive Psychology, 
6 (3), 217-231. 
Hollnagel, E., Nåbo, A., & Lau, I. V. (2003). A systemic model for driver-in-control. Paper 
presented at the Second International Driving Symposium on Human Factors in Driver 
Assessment, Training and Vehicle Design. Utah, July 21-24. 
Howard, C. Q., Maddern, A. J., & Privopoulos, E. P. (2011). Acoustic characteristics for 
effective ambulance sirens. Acoustics Australia, 39, 2-43. 
Hua, H. (2014). Employees with Aided Hearing Impairment: An Interdisciplinary 
Perspective. (Doctoral dissertation). Linköping: Linköping University Electronic Press. 
Hughes, D., Sapp, G., and Kohler, M. (2006). Issues in the Intellectual assessment of hearing 
impaired children. ERIC Digest. Education Resources Information Center. Available 
online 
at: 
http://www. 
eric.ed.gov/ERICDocs/data/ericdocs2sql/content_storage_01/0000019b/80/1b/f1/a4.pdf, 
pp 1-17. Accessed on September 25, 2014. 
Hughes, P. K. & Cole, B. L. (1988). The effect of attentional demand on eye movement 
behaviour when driving. In A. G. Gale, M. H. Freeman, C. M. Haslegrave, P. Smith & S. 
P. Taylor (Eds.), Vision in vehicles-II (pp. 221–230). Amsterdam: North-Holland. 
Hällgren, M., Larsby, B., Lyxell, B., & Arlinger, S. (2001). Evaluation of a cognitive test 
battery in young and elderly normal-hearing and hearing-impaired persons. Journal of the 
American Academy of Audiology, 12(7), 357-370. 
Ivers, R. Q., Mitchell, P., & Cumming, R. G. (1999). Sensory impairment and driving: The 
Blue Mountains Eye Study. American Journal of Public Health, 89(1), 85-87. 
Jansen, E., Holte, H., Jung, C., Kahmann, V., Moritz, K., Rietz, C., Rudinger, G., & 
Weidemann, 
C. 
(2001). 
Ältere 
Menschen 
im 
künftigen 
Sicherheitssystem 
Straße/Fahrzeug/Mensch. 
[Senior 
citizens 
in 
the 
future 
safety 
system: 
street/vehicle/person]. Bremerhaven: Wirtschaftsverlag NW. 
Jastak, J. F., & Jastak, S. R. (1964). Short forms of the WAIS and WISC vocabulary subtests. 
Journal of Clinical Psychology, 20(2), 167-199. 
Johnston, B. (2008). Building better surveys: Effective scales. Best practices. Available at 
http://www.surveygizmo.com/survey-blog/question-scale-length/. Accessed in August 
2014. 

Effect of Hearing Loss on Traffic Safety and Mobility 
 
431
Kane, M. J., & Engle, R. W. (2002). The role of prefrontal cortex in working-memory 
capacity, executive attention, and general fluid intelligence: An individual-differences 
perspective. Psychonomic Bulletin & Review 9(4), 637-671. 
Kennedy, Q., Taylor, J. L., Reade, G., & Yesavage, J. A. (2010). Age and expertise effects in 
aviation decision making and flight control in a flight simulator. Aviation, Space, and 
Environmental Medicine, 81(5), 489. 
Kipps, C. M., & Hodges, J. R. (2005). Cognitive assessment for clinicians. Journal of 
Neurology Neurosurgery & Psychiatry, 76 (Suppl 1): 22-30. 
Kongsved, S. M., Basnov, M., Holm-Christensen, K., & Hjollund, N. H. (2007). Response 
rate and completeness of questionnaires: a randomized study of internet versus paper-
and-pencil versions. Journal of Medical Internet Research, 9(3), e25. 
Köpke, S., Deubel, K., Engeln, A., & Schlag, B. (1999). Mobilitätswahrnehmung und 
Selbstbild von älteren Autofahrern [Mobility awareness and self-image of older drivers]. 
In B. Schlag (Ed.), Empirische Verkehrspsychologie [Empirical traffic psychology]. 
Lengerich: Pabst Science Publishers; pp. 159-175. 
Lehtonen, E., Dahlström, I., Hiltunen, H., & Summala, H. (2012). On-road visual search and 
executive functions in elderly drivers. Paper presented at the International Conference on 
Traffic and Transport Psychology Groningen, Netherlands August 29-31. 
Lewis-Evans, B. (2012). Testing models of driver behaviour. (Doctoral dissertation). 
University of Groningen. 
Lewis-Evans, B., de Waard, D., & Brookhuis, K. (2011). Speed maintenance under cognitive 
load: Implications for theories of driver behaviour. Accidents Analysis and Prevention, 
43(4), 1497-1507. 
Li, K. Z. & Lindenberger, U. (2002). Relations between aging sensory/ sensorimotor and 
cognitive functions. Neuroscience and Biobehavioral Reviews, 26(7), 777-783. 
Li, Y., & Perkins, A. (2007). The impact of technological developments on the daily life of 
the elderly. Technology in Society, 29(3), 361-368. 
Lidestam, B., Lundqvist, A., & Rönnberg, J. (2010). Concepts from research literature and 
practical assessment of risk awareness: the Swedish driving test from the perspective of 
cognitive psychology. Transportation Research Part F: Traffic Psychology and 
Behaviour, 13(6), 409-425. 
Liang, K.-Y., & Zeger, S. (1986). Longitudinal data analysis using generalized linear models. 
Biometrika 73(1), 13-22. 
Lin, F. R., Ferrucci, L., Metter, E. J., An, Y., Zonderman, A. B., & Resnick, S. M. (2011). 
Hearing loss and cognition in The Baltimore Longitudinal Study of Aging. 
Neuropsychology, 25 (6), 7637-70. 
Lin, F. R., Metter, E. J., O’Brien, R. J., Resnick, S. M., Zonderman, A. B., & Ferrucci, L. 
(2011). Hearing loss and incident dementia. Archives of Neurology, 68(2), 214-220. 
Lin, F. R., Yaffe, K., Xia, J., Xue, Q. L., Harris, T. B., Purchase-Helzner, E., Satterfield, S., 
Ayonayon, H. N., Ferrucci, L., Simonsick, E. M. (2013). Hearing loss and cognitive 
decline in older adults. JAMA Internal Medicine, 173(4), 293-299. 
Lin, M. Y., Guttierrez, P. R., Stone, K. L., Yaffe, K., Ensrud, K. E., Fink, H. A. et al.; Study 
of Osteoporotic Fractures Research Group. (2004). Vision impairment and combined 
vision and hearing impairment predict cognitive and functional decline in older women. 
Journal of the American Geriatrics Society, 52, 1996-2002. 

Birgitta Thorslund 
 
432
Lindenberger, U. & Baltes, P. B. (1994). Sensory functioning and intelligence in old age: a 
strong connection. Psychology and Aging, 9, 339-355. 
Lindenberger, U., Lövdén, M., Schellenbach, M., Li, S., & Krüger, A. (2008). Psychological 
Principles of Successful Aging Technologies: A Mini-Review. Gerontology, 54, 59-68. 
Ljung Aust, M. (2012). Improving the evaluation process for active safety functions: 
Addressing key challenges in functional formative evaluation of advanced driver 
assistance systems. Thesis, Department of Applied Mechanics, Chalmers University of 
Technology, Gothenburg, Sweden. 
Lundälv J. (2004). Self-reported experiences of incidents and injury events in traffic among 
hearing impaired people as pedestrians and cyclists. A follow-up study of mobility and 
use of hearing equipment. International Journal of Rehabilitation Research, 27(1):79-80. 
Lunner, T. (2003). Cognitive function in relation to hearing aid use. International Journal of 
Audiology, 42 (Suppl 1), S49-S58. 
Lyxell, B., Andersson, U., Borg, E., & Ohlsson, I. S. (2003). Working-memory capacity and 
phonological processing in deafened adults and individuals with a severe hearing 
impairment. International Journal of Audiology, 42, 86-89. 
Macintyre, S., Hiscock, R., Kearns, A., & Ellaway, A. (2001). Housing tenure and car access: 
further exploration of the nature of their relation with health in a UK setting. Journal of 
Epidemiology and Community Health, 52, 657-664. 
Magnet, W. (1992). Empirische Untersuchung zur Kompensationsfrage bei Gehörlosen 
Autofahrern. Eine Differentielle Analyse der Visuellen Wahrnehmung von Gehörlosen 
Kraftfahrern [Empirical examination of compensation made by deaf car drivers. A 
differential analysis of visual perception by deaf drivers]. Unpublished Dissertation, 
Universität Innsbruck, Innsbruck. 
Marottoli, R., Mendes de Leon, C., Glass, T., Williams, C., Cooney, L. J., Berkman, L. F., & 
Tinetti, M. (1997). Driving cessation and increased depressive symptoms: prospective 
evidence from the New Haven EPESE (Established Populations for Epidemiologic 
Studies of the Elderly). Journal of the American Geriatrics Society, 45, 202-206. 
Mathers, C., Smith, A., & Concha, M. (2003). Global burden of hearing loss in the year 
2000. Working paper. Geneva: World Health Organization. 
Mayr, U., Spieler, D. H., Kliegl, R. (2001). Aging and executive control. New York: 
Routledge. 
McCloskey, L. W., Koepsell, T. D., Wolf, M. E., & Buchner, D. M. (1994). Motor-vehicle 
collision injuries and sensory impairments of older drivers. Age and Ageing, 23(4), 267-
273. 
McDowd, J. M., & Shaw, R. J. (2000). Attention and aging: A functional perspective. In: F. I. 
M. Craik, & T. A. Salthouse (Eds.), The handbook of aging and cognition, 2nd ed. 
Mahwah, NJ: Erlbaum; pp. 221-292. 
McEvoy, S. P., Stevenson, M. R., & Woodward, M. (2006). The impact of driver distraction 
on road safety: results from a representative survey in two Australian states. Injury 
Prevention, 12, 242-247. 
McHugh, M. L. (2009). The odds ratio: calculation, usage, and interpretation. Biochemia 
Medica, 19(2):120-126. 
McKnight, A. J., & Adams, B. B. (1970). Driver education task analysis. Vol.1: Task 
descriptions. Human Resources Research Organization, Alexandria, Virginia. Final 
Report, Contract No. FH 11-7336. 

Effect of Hearing Loss on Traffic Safety and Mobility 
 
433
McRuer, D. T., Allen, R. W., Weir, D. H., & Klein, R. H. (1977). New results in driver 
steering control models. Human Factors, 19, 381-397. 
Michon, J. A. (1985). A critical view of driver behavior models: What do we know, what 
should we do? In L. A. Evans, & R. C. Schwing (Eds.), Human behavior and traffic 
safety. New York: Plenum. 
Mitzi M. S., & Johnson, M. (1989). Age differences in decision making: A process 
methodology for examining strategic information processing. Journal of Gerontology, 
45(2), 75-78. 
Miyake, A., Friedman, N. P., Emerson, M. J., Witzki, A. H., & Howerter, A. (2000). The 
unity and diversity of executive functions and their contributions to complex ‘‘frontal 
lobe’’ tasks: A latent variable analysis. Cognitive Psychology, 41, 49-100. 
Miyake, A. & Shah, P. (1999). Models of working memory. Cambridge, UK: Cambridge 
University Press. 
Monsell, S. (1996). Control of mental processes. In V. Bruce (Ed.), Unsolved mysteries of the 
mind: tutorial essays in cognition. Hove, UK: Erlbaum; pp. 93-148. 
Monterde-i-Bort, H. (2004). Factorial structure of recklessness: to what extent are older 
drivers different? Journal of Safety Research, 35, 329-335. 
Moore, B. C. (1996). Perceptual consequences of cochlear hearing loss and their implications 
for the design of hearing aids. Ear and Hearing, 17(2), 133-161. 
Moradi, S., Lidestam, B., Hällgren, M., & Rönnberg, J. (2014). Gated auditory speech 
perception in elderly hearing aid users and elderly normal-hearing individuals: Effects of 
hearing impairment and cognitive capacity. Trends in Hearing, Jul 31;18. pii: 
2331216514545406. doi: 10.1177/ 2331216514545406. 
Morris, N., & Jones, D. M. (1990). Memory updating in working memory: the role of the 
central executive. British Journal of Psychology, 81, 111-121. 
Mosteller, F. (1968). Association and estimation in contingency tables. Journal of the 
American Statistical Association, 63 (321), 1-28. 
Mullen, N., Charlton, J., Devlin., A., & Bédard, M. (2001). Simulator validity: Behaviors 
observed on the simulator and on the road. In D. L. Fisher, M. Rizzo, J. K. Caird, & J. D. 
Lee (Eds.), Driving simulation for engineering, medicine and psychology. Florida: Taylor 
and Francis. 
Nakeva von Mentzer, C. (2014). Rethinking Sound: Computer-assisted reading intervention 
with a phonics approach for deaf and hard of hearing children using cochlear implants 
or hearing aids. (Doctoral dissertation). Linköping: Linköping University Electronic 
Press. 
Näätänen, R., & Summala, H. (1974). A model for the role of motivational factors in drivers’ 
decision-making. Accident Analysis & Prevention, 6(3-4), 243-261. 
Neisser, U. (1976). Cognition and reality: Principles and implications of cognitive 
psychology: New York: W.H. Freeman. 
Nilsson, L. (1993). Contributions and limitations of simulator studies to driver behaviour 
research. In A. A. M. Parkes, & S. Franzen (Eds.), Driving future vehicles: Taylor & 
Francis; pp. 401-407. 
O’Brien, S. (2009) Eye tracking in translation process research: Methodological challenges 
and solutions. In: I. M. Mees, F. Alves, & S. Gopferich (Eds.), Methodology, technology 
and innovation in translation process research: A tribute to Arnt Lykke Jakobsen. 
Copenhagen Studies in Language, vol. 38. Copenhagen: Samfundslitteratur; pp. 251-266. 

Birgitta Thorslund 
 
434
O’Donnell, R. D. & Eggemeier, F. T. (1986). Workload assessment methodology. In K. R. 
Boff, L. Kaufman, & J. P. Thomas (Eds.), Handbook of perception and human 
performance, vol. II, Cognitive processes and performance. New York: Wiley; pp. 42/1-
42/49. 
O’Hanlon, J. F. (1984). Driving performance under the influence of drugs: rationale for, and 
application of, a new test. British Journal of Clinical Pharmacology, 18, 121S-129S. 
O’Hanlon, J. F., Haak, T. W., Blaauw, G. J. & Riemersma, J. B. J. (1982). Diazepam impairs 
lateral position control in highway driving. Science, 217, 79-80. 
Ohta, H., & Komatsu, H. (1991). Speed perception in driving. Vision in vehicles, vol. III. 
Amsterdam: Elsevier Science Publishers; pp. 415-426. 
Owsley, C., Ball, K., McGwin, G., Sloane, M. E., Roenker, D. L., White, M. F. et al. (1998). 
Visual processing impairment and risk of motor vehicle crash among older adults. 
Journal of the American Medical Association, 279(14), 1083-1088. 
Parasuraman, R., & Riley, V. (1997) Humans and automation: use, misuse, disuse, abuse. 
Human Factors, 39(2), 230-253. 
Pearson, J. D., Morrell, C. H., Gordon-Salant, S., Brant, L. J., Metter, E. J., Klein, L. L., & 
Fozard, J. L. (1995). Gender differences in a longitudinal-study of age-associated 
hearing-loss. Journal of the Acoustical Society of America, 97(2), 1196-1205. 
Pelli, D. G., Robson, J. G., & Wilkins, A. J. (1988). The design of a new letter chart for 
measuring contrast sensitivity. Clinical Vision Sciences, 2, 187-199. 
Peters, B., & Nielsen, B. (2007). A strategy aiming to compensate degraded abilities among 
elderly drivers. 11th International Conference on Mobility and Transport for Elderly and 
Disabled Persons, Montreal, Canada. 
Peters, B., & Nilsson, L. (2006). Modelling the driver in control. In P. Cacciabue (Ed.), 
Modelling driver behaviour in automotive environments: Critical issues in driver 
interactions with intelligent transport systems. London: Springer. 
Peters C. A., Potter J. F., & Scholer S. G. (1988). Hearing impairment as a predictor of 
cognitive decline in dementia. Journal of the American Geriatriatrics Society, 
36(11):981-986. 
Phillips, N. A., & Lesperance, D. (2003). Breaking the waves: age differences in electrical 
brain activity when reading text with distractors. Psychology and Aging, 18(1), 126-139. 
Picard, M., Girard, S.A., Courteau, M., Leroux, T., Larocque, R., Turcotte, F., et al. (2008). 
Could driving safety be compromised by noise exposure at work and noise-induced 
hearing loss? Traffic Injury Prevention, 9(5), 489-499. 
Pichora-Fuller, M. K., & Singh, G. (2006). Effects of age on auditory and cognitive 
processing: implications for hearing aid fitting and audiologic rehabilitation. Trends in 
Amplification, 10(1), 29-59. 
Rajalin, S., Hassel, S. O., & Summala, H. (1997). Close-following drivers on two-lane 
highways. Accident Analysis & Prevention, 29(6), 723-729. 
Ranney, T. (1994) Models of driving behavior: a review of their evolution. Accident Analysis 
& Prevention, 26(6), 733-750. 
Pohlmann, S. & Traenkle, U. (1994). Orientation in road traffic. Age-related differences using 
an in-vehicle navigation system and a conventional map. Accident Analysis & 
Prevention, 26, 689-702. 
Reitan, R. (1986). Trail making test. Manual for administration and scoring. Tuscon, AZ: 
Neuropsychological Laboratory. 

Effect of Hearing Loss on Traffic Safety and Mobility 
 
435
Repovs, G. & Baddeley, A. (2006). The multi-component model of working memory: 
explorations in experimental cognitive psychology. Neuroscience Special Issue, 139, 5-
21. 
Riediger, M., Li, S. C., & Lindenberger, U. (2006). Selection, optimization, and 
compensation as developmental mechanisms of adaptive resource allocation: Review and 
preview. Handbook of the psychology of aging, 6, 289-313. 
Rimmer, J. (2006). Use of the ICF in identifying factors that impact participation in physical 
abilities/rehabilitation among people with disabilities. Disability and Rehabilitation, 28, 
1087-1095. 
Rimmö, P.-A., & Hakamies-Blomqvist, L. (2002). Older drivers’ aberrant driving behaviour, 
impaired activity, and health as reasons for self-imposed driving limitations. 
Transportation Research Part F: Traffic Psychology and Behaviour, 5, 345-360. 
Risacher, S. L., Wudunn, D., Pepin, S. M., MaGee, T. R., McDonald, B. C., Flashman, L. A. 
et al. (2013). Visual contrast sensitivity in Alzheimer's disease, mild cognitive 
impairment, and older adults with cognitive complaints. Neurobiology of Aging, 
34(4):1133-1144. 
Roebuck, J. (1979). When does old age begin? The evolution of the English definition. 
Journal of Social History, 12(3):416-428. 
Roth, T. N., Hanebuth, D., & Probst, R. (2001). Prevalence of age-related hearing loss in 
Europe: a review. European Archives of Oto-Rhino-Laryngology, 268(8), 1101-1107. 
Rothe, J. P. (1990). The safety of elderly drivers. London: Transaction Publishers. 
Rouse, W. B., Edwards, S. L. & Hammer, J. M. (1993). Modelling the dynamics of mental 
workload and human performance in complex systems. IEEE transactions on systems, 
man, and cybernetics, 23, 1662-1671. 
Rumar, K. (1988). Collective risk but individual safety. Ergonomics, 31(4), 507-518. 
Rönnberg, J. (1990). Cognitive and communicative function: the effects of chronological age 
and “handicap age”. European Journal of Cognitive Psychology, 2, 253-273. 
Rönnberg, J., Danielsson, H., Rudner, M., Arlinger, S., Sternang, O., Wahlin, A., & Nilsson, 
L. G. (2011). Hearing loss is negatively related to episodic and semantic long-term 
memory but not to short-term memory. Journal of Speech Language and Hearing 
Research, 54(2), 705-726. 
Rönnlund, M., Nyberg, L., Bäckman, L., & Nilsson, L. G. (2005). Stability, growth, and 
decline in adult life span development of declarative memory: cross-sectional and 
longitudinal data from a population based study. Psychology and Aging, 20(1), 3-18. 
Salthouse, T. A., Babcock, R. L. (1991). Decomposing adult age-differences in working 
memory. Developmental Psychology, 27(5), 763-776. 
Salthouse, T. A. (1996). The processing-speed theory of adult age differences in cognition. 
Psychological Review. 103: 403-428. 
Salvucci D. D. (2006) Modeling Driver Behavior in a Cognitive Architecture. Human 
Factors, 48 (2), 362-380 
Sandberg, U. (2003). The multi-coincidence peak around 1000 Hz in tyre/road noise spectra. 
Paper presented at the Euronoise. May, 19-21, Naples.  
Saremi, A., & Stenfelt, S. (2013). Effect of metabolic presbyacusis on cochlear responses: a 
simulation approach using a physiologically-based model. Journal of the Acoustic Society 
of America, 134(4), 2833-2851. 

Birgitta Thorslund 
 
436
Schmolz, W. (1987). Die Bedeutung des Hoehrens im Verkehr. [The effect of hearing in 
traffic]. Polizei Verkehr Technik, 32(11), 379-380. 
Schneider, B. A., Pichora-Fuller, M. K., & Daneman, M. (2010). Effects of senescent changes 
in audition and cognition on spoken language comprehension. In S. Gordon-Salant, R. R. 
Frisina, R. R. Fay, & A. Popper(Eds.), The aging auditory system. New York: Springer. 
Schneider, J., Gopinath, B., Karpa, M. J., McMahon, C. M., Rochtchina, E., Leeder, S. R., & 
Mitchell, P. (2010). Hearing loss impacts on the use of community and informal supports. 
Age and Ageing, 39(4), 458-464. 
Selander, H., Lee, H. C., Johansson, K., & Falkmer, T. (2011). Older drivers: on-road and off-
road test results. Accidents Analysis and Prevention, 43 (4). 1348-1354. 
Shinar, D. (2007). Traffic safety and human behavior. Oxford: Elsevier. 
Sirén, A., & Hakamies-Blomqvist, L. (2004). Private car as the grand equaliser? 
Demographic factors and mobility in Finnish men and women aged 65+. Transportation 
Research Part F: Traffic Psychology and Behaviour, 7(2), 107-118. 
Sirén, A. & Hakamies-Blomqvist, L. (2009). Mobility and well-being in old age. Topics in 
Geriatric Rehabilitation, 25(1), 3-11. 
Sternberg, S. (1966). High-speed scanning in human memory. Science, 153, 652-654. 
Stevens, G., Flaxman, S., Brunskill, E., Mascarenhas, M., Mathers, C. D., & Finucane, M. 
(2013). Global and regional hearing impairment prevalence: an analysis of 42 studies in 
29 countries. European Journal of Public Health, 23(1), 146-152. 
Sullivan, K. A., Smith, S. S., Horswill, M. S., & Lurie-Beck, J. K. (2011). Older adults’ 
safety perceptions of driving situations: towards a new driving self-regulation scale. 
Accident Analysis & Prevention, 43(3), 1003-1009. 
Summala, H. (2005). Traffic psychology theories: Towards understanding driving behaviour 
and safety efforts. In G. Underwood (Ed.), Traffic and Transport Psychology. 
Amsterdam: Elsevier; pp. 383-394, 
Summala, H. (2007). Towards understanding motivational and emotional factors in driver 
behaviour: Comfort through satisficing. In C. Cacciabue (Ed.), Modelling Driver 
Behaviour in Automotive Environments. London: Springer; pp. 189-207. 
Summala, H., Etholén, T., Leino, N., Niskakangas, M., Laine, M. & Saarinen, S. (2008). FR-
TMT: Visuospatial (working) memory in a computerized Trail-Making test. Poster 
presented at the Psykologia 2008 Congress, August 20-22, Helsinki. 
Teng E. L., Chui H. C. (1987) The Modified Mini-Mental State (3MS) Examination. Journal 
of Clinical Psychiatry, 48(8):314-318. 
Thomas, P. D., Hunt, W. C., Garry, P. J., Hood, R. B., Goodwin, J. M. & Goodwin, J. S. 
(1983). Hearing acuity in a healthy elderly population: effects on emotional, cognitive, 
and social status. Journal of Gerontology, 38, 321-325. 
Tun, P. A., McCoy, S., & Wingfield, A. (2009) Aging, hearing acuity, and the attentional 
costs of effortful listening. Psychology and Aging, 24(3), 761-766. 
Vaa, T. (2003). Survival or deviance? A model for driver behaviour. (TOI report 666/2003). 
Oslo: Institute of Transport Economics. 
Vaa, T. (2007). Modelling driver behaviour on basis of emotions and feelings: Intelligent 
transport systems and behavioural adaptations. In C. Cacciabue (Ed.), Modelling driver 
behaviour in automotive environments. London: Springer; pp. 208-232. 
Vaa, T. (2011). Proposing a driver behaviour model based on emotions and feelings: 
Exploring the boundaries of perception and learning. In M. Regan, T. Victor & J. Lee 

Effect of Hearing Loss on Traffic Safety and Mobility 
 
437
(Eds.), Driver distraction and inattention: advances in research and countermeasures. 
Farnham, UK: Ashgate Publishing. 
Vaa, T., Glad, A., & Sagberg, F. (2000). Developing a model of driver behaviour: 
Introductory working papers. (TOI report 503/2000). Oslo: Institute of Transport 
Economics. 
Valentijn S. A., van Boxtel M. P., van Hooren S. A., Bosma H., Beckers H. J., Ponds R. W., 
& Jolles J. (2005). Change in sensory functioning predicts change in cognitive 
functioning: results from a 6-year follow-up in the Maastricht Aging Study. Journal of 
the American Geriatrics Society 53(3), 374-380. 
Van der Linden, M., Brédart, S., & Beerten, A. (1994). Age-related differences in updating 
working memory. British Journal of Psychology, 85, 145-152. 
Van der Linden, M., Hupet, M., Feyereisen, P., Schelstraete, M., Bestgen, M., Bruyer, G. L., 
Abdessadek, E. A., & Seron., X. (1999). Cognitive mediators of age-related differences 
in language comprehension and verbal processing. Aging, Neuropsychology, and 
Cognition, 6, 32-55. 
Van Erp, J. B. F., & van Veen, H. A. H. C. (2004). Vibrotactile in-vehicle navigation system. 
Transportation Research Part F: Traffic Psychology and Behaviour, 7, 247-256. 
Verhaeghen, P., Cerella, J., Bopp, K. L., & Basak, C. (2005). Aging and varieties of cognitive 
control: a review of meta-analyses on resistance to interference, coordination, and task 
switching, and experimental exploration of age-sensitivity in the newly identified process 
of focus switching. In: R. W. Engle, G. Sedek, U. von Hecker, & D. N. McIntosh (Eds), 
Cognitive limitations in aging and psychopathology. New York: Cambridge University 
Press; pp. 160-189. 
Verhaeghen, P., Steitz, D. W., Sliwinski, M. J., & Cerella, J. (2003). Aging and dual-task 
performance: a meta-analysis. Psychology and Aging, 18, 443-460. 
Vreeken, H. L., van Rens, G., Knol, D. L., van Reijen, N. A., Kramer, S. E., Festen, M. J., & 
van Nispen, R. M. A. (2013). Dual sensory loss: a major age-related increase of comorbid 
hearing loss and hearing aid ownership in visually impaired adults. Geriatrics and 
Gerontology 
International. 
Available 
at 
http://www.biomedcentral.com/1471-
2318/13/84. Accessed on September 25, 2014. 
Wallhagen, M. I. (2010). The stigma of hearing loss. Gerontologist, 50(1), 66-75. 
Wechsler D. (1981). Manual for the Wechsler Adult Intelligence Scale-revised. New York: 
Psychological Corp. 
Wickens, C. D., & Hollands, J. G. (1999). Engineering Psychology and Human Performance 
(3nd ed.). New York: Harper Collins. 
Wilson, G. F. & Eggemeier, F. T. (1991). Psychophysiological assessment of workload in 
multi-task environments. In D. L. Damos (Ed.), Multiple-task performance. London: 
Taylor & Francis; pp. 329–360. 
World Health Organization (WHO). (2001). International Classification of Functioning, 
Disability and Health (ICF). Geneva: World Health Organization. 
Wu, Y. H., Aksan, N., Rizzo, M., Stangl, E., Zhang, X., & Bentler, R. (2014). Measuring 
listening effort: driving simulator versus simple dual-task paradigm. Ear and Hearing, 
doi: 10.1097/AUD.0000000000000079. 
Wu, Y. H., Stangl, E., Bentler, R., & Stanziola, R. W. (2013). The effect of hearing aid 
technologies on listening in an automobile. Journal of Clinical Experimental 
Neuropsychology of the American Academy of Audiology, 24(6), 474-485. 


In: Encyclopedia of Audiology and Hearing Research 
ISBN: 978-1-53617-702-2 
Editors: Erno Larivaara and Senja Korhola 
© 2020 Nova Science Publishers, Inc. 
 
 
 
 
 
 
 
Chapter 31  
 
 
 
GENETICS OF HEARING LOSS: TESTING 
METHODOLOGIES AND COUNSELING OF AUDIOLOGY 
PATIENTS AND THEIR FAMILIES 
 
 
Danielle Donovan Mercer, AuD* 
State of Louisiana Early Hearing Detection and Intervention Program,  
New Orleans, LA, US 
 
 
ABSTRACT 
 
Approximately 2 to 3 per 1,000 newborns are diagnosed with permanent hearing 
loss. It is estimated that 75 to 80% of these cases are due to a genetic etiology. Genetic 
hearing loss can be syndromic, meaning other clinical features are present along with the 
hearing loss; or nonsyndromic, meaning hearing loss occurs in isolation. More than 400 
genes have been reported to contribute to hearing loss and more than 100 genes have 
been reported to cause nonsyndromic hearing loss. Genes causing hearing loss display 
various modes of inheritance, with autosomal recessive being the most common. With so 
many cases of hearing loss having a genetic etiology, audiologists are certain to 
encounter these patients on a fairly regular basis. Audiologists who possess basic 
knowledge about genetics are better equipped to recognize when a genetics referral is 
warranted, thereby enhancing patient care. A genetics evaluation can yield valuable 
information for patients and their families, such as prognosis, estimates of recurrence 
risks, and diagnosis of other family members. A variety of testing methodologies are 
available, and are chosen based on such considerations as clinical presentation, cost, 
analysis time, laboratory availability, previous testing performed, and likelihood of a 
positive result, among others. As technologies for genetic testing advance, sequencing 
techniques such as whole exome sequencing, genomic sequencing, and targeted 
sequencing are becoming more affordable, allowing for more patients to receive a 
diagnosis than was previously possible.  
 
Keywords: genetics, hearing loss, deafness, audiology, hearing loss counseling, sequencing, 
syndromic hearing loss, nonsyndromic hearing loss, genetic testing 
                                                        
* Corresponding Author’s Email: Danielle.Mercer@la.gov. 

Danielle Donovan Mercer 
 
440
1. INTRODUCTION 
 
Approximately 2 to 3 per 1,000 newborns will be diagnosed with permanent hearing loss 
[1], making it one of the most common birth conditions. When factoring in delayed-onset and 
minimal hearing losses, prevalence increases to 20% in adolescence [2]. Historically, 50% of 
these cases have been attributed to genetic causes and 50% to environmental causes [3, 4]. 
However, estimates in recent years have suggested that the true proportion of permanent 
childhood hearing loss cases attributable to genetics in developed countries is closer to 80% 
[5]. This perceived increase in genetic hearing loss is likely due to a decrease in cases caused 
by infections, such as rubella. Prenatal rubella infection, a common cause of deafness in the 
1960s and prior, has largely been eradicated in developed countries through vaccination [6]. 
Thus, the proportion of permanent hearing loss cases with a genetic etiology has increased. In 
addition, it is unknown how many genetic causes are undiagnosed. New epidemiological 
studies are needed to more accurately characterize the etiology of permanent childhood 
hearing loss.  
The human genome contains approximately 20,000 genes [7]. These genes code for 
proteins which carry out all of the functions necessary for life. More than 400 genes have 
been reported to contribute to hearing loss [8] and more than 100 genes have been reported to 
cause hearing loss in isolation [9]. For a better understanding of genes, it is important to 
discuss what makes up genes: DNA.  
 
 
2. DNA PROVIDES THE GENETIC CODE 
 
2.1. Structure of DNA 
 
DNA (deoxyribonucleic acid) is a nucleic acid. Nucleic acids are one of the four 
biological macromolecules essential for life, along with carbohydrates, proteins, and lipids. 
The structure of DNA was first described in 1953 by James Watson and Francis Crick, whose 
predictions were assisted by radiographs taken by Rosalind Franklin and suggested by 
Maurice Wilkins. Despite the complexity of functions required of the genetic code by humans 
and other species alike, the structure of DNA was found to exhibit surprising simplicity.  
DNA is made up of nitrogen-containing bases called nucleotides bound to a sugar-
phosphate backbone. The sugar is deoxyribose, a 5-carbon sugar. While the sugar-phosphate 
backbone remains constant, the nucleotides do not. There are four different nitrogenous bases 
in DNA: adenine, guanine, cytosine, and thymine, commonly abbreviated as A, G, C, and T, 
respectively. A and G are classified as purines (double-ringed structures) while C and T are 
classified as pyrimidines (single-ringed structures). DNA is structured as two chains which 
form a double helix shape (Figure 1). The two strands are connected via hydrogen bonds 
between bases on each strand. The bases form bonds in predictable fashion: A always bonds 
with T, and G always bonds with C. The two strands are thus complementary. These bases 
make up the genetic code. Genes are transcribed into mRNA (messenger RNA), which is in 
turn translated into proteins.  
 

Genetics of Hearing Loss 
 
441
 
Figure 1. DNA structure.DNA is structured into a double helix with 4 nucleic acid bases: adenine (A), 
guanine (G), cytosine (C), and thymine (T). Adenine always pairs with thymine while guanine always pairs 
with cytosine. AT pairs are connected with two hydrogen bonds while GC pairs are connected with three 
hydrogen bonds. 
 
2.2. DNA Is Packaged into Chromosomes 
 
The roughly 3 billion base pairs of DNA that make up the human genome must be 
packaged into cells [10]. To accomplish this, DNA utilizes several mechanisms of 
compaction, which includes involvement of various proteins such as histones [11]. The 
human genome is arranged into 46 chromosomes. When the chromosomes are at maximal 
condensation, they can be stained and analyzed microscopically (see Section 6.1.1). The 
chromosomes are located in the nucleus of the cell. Most cells of the human body have 46 
chromosomes packaged in the nucleus. Notable exceptions are the gametes (egg and sperm 
cells), which contain 23 chromosomes, and mature red blood cells, which do not have a 
nucleus. Somatic cells (cells that are not gametes) divide through a process known as mitosis, 
while gametes divide via meiosis. Mitosis and meiosis are similar processes, but meiosis 
involves two cell divisions as compared to one cell division in mitosis. Both processes 
precede with DNA replication (doubling). Mitosis follows with a division into two daughter 
cells each with the same amount of DNA as the parent cell. Meiosis follows with two cell 
divisions resulting in four daughter cells with half the amount of DNA as the parent cell.  
 
 
2.3. Chromosomes Come in Pairs 
 
The 46 chromosomes that contain the human genome consist of 23 pairs. One pair is 
inherited from a person’s mother and one pair is inherited from the father. Egg and sperm 
cells contain 23 chromosomes each, creating a zygote with 46 chromosomes when they come 
together. The chromosomes are designated as either autosomes or sex chromosomes. The sex 
chromosomes are X and Y, and they determine sex. Females possess an XX sex chromosome 

Danielle Donovan Mercer 
 
442
complement, while males possess an XY chromosome complement. When passing on a sex 
chromosome to a child, females can only pass on an X chromosome. 
 
 
 
 
 
Figure 2. Human male karyotype.Normal male karyotype: 46,XY.Karyotype courtesy of the laboratory of Dr. 
Fern Tsien, Louisiana University Health Sciences Center Department of Genetics, used with permission.  
Males can pass on either an X or a Y chromosome, which is why fathers are described as the 
sex-determining parent. The remaining chromosomes are autosomes, denoted by numbers 1 
through 22. They are arranged into karyotypes by descending size, with 1 being the largest, 
and the sex chromosomes at the end. Chromosome 21 is the smallest chromosome. (Because 
of the difficulty visualizing chromosomes with early staining methods, chromosomes 21 and 
22 were mistakenly put in reverse order. This assignment has remained.) A normal male 
karyotype is shown in Figure 2.  
 
 
3. PATTERNS OF INHERITANCE 
 
The four major patterns of inheritance are autosomal dominant, autosomal recessive, X-
linked, and mitochondrial. These are each described in more detail in this section. Autosomal 
and X-linked both indicate the type of chromosome involved. X-linked genes are located on 
the X chromosome. Autosomal genes are located anywhere on chromosomes 1 to 22. Traits 
or disorders can be dominant or recessive. In Section 2.3, we learned that for any given gene 
(with the exception of mitochondrial genes), we inherit two copies: one from our mother and 
one from our father. These alternative gene copies are alleles. Alleles can interact in different 
ways. If one allele masks the other allele, it is a dominant allele. In contrast, a recessive allele 
is one that is capable of being masked by another allele. The combination of alleles inherited 
represents an individual’s genotype while the expression of the genetic make-up represents an 
individual’s phenotype. Alleles which differ from the norm may be deemed mutations or 
polymorphisms. Mutations typically describe allele variants which are disease-causing, while 
polymorphisms describe benign allele variants, though technically, the terms can be used 

Genetics of Hearing Loss 
 
443
interchangeably. Figures 3-7 show pedigrees of families with genetic deafness of different 
inheritance patterns. A pedigree is a diagrammatic representation of a family used by genetic 
counselors and clinical geneticists to record and evaluate genetic traits. In our examples we 
will use the trait of hearing loss.  
 
 
 
Figure 3. Pedigree of autosomal dominant deafness.Three generations of a family are shown in this pedigree. 
Males are represented by squares, females by circles; matings are denoted by a horizontal line, offspring by a 
vertical line. The proband (presenting patient) is indicated with an arrow. Family members affected with 
deafness are indicated with shading. For someone with autosomal dominant deafness, approximately half of 
their children would be expected to be deaf. Males and females are affected in roughly equal numbers. 
 
 
Figure 4. Pedigree of autosomal recessive deafness.Four generations of a family are shown in this pedigree. 
Males are represented by squares, females by circles; matings are denoted by a horizontal line, offspring by a 
vertical line. The proband (presenting patient) is indicated with an arrow. Family members affected with 
deafness are indicated with shading. Unaffected carriers are indicated with a dot. Deaf family members 
inherited two gene copies for deafness: one from each parent. For unaffected parents who are both carriers for 
autosomal recessive deafness in the same gene, approximately one-quarter of their children would be 
expected to be deaf. Males and females are affected in roughly equal numbers. 

Danielle Donovan Mercer 
 
444
 
 
Figure 5. Pedigree of X-linked dominant deafness.Three generations of a family are shown in this pedigree. 
Males are represented by squares, females by circles; matings are denoted by a horizontal line, offspring by a 
vertical line. The proband (presenting patient) is indicated with an arrow. Family members affected with 
deafness are indicated with shading. Affected males will have all daughters affected and no sons affected. For 
affected females, half of their children will be affected (by probability) regardless of gender. X-linked 
inheritance will not display male-to-male transmission. 
 
 
Figure 6. Pedigree of X-linked recessive deafness.Four generations of a family are shown in this pedigree. 
Males are represented by squares, females by circles; matings are denoted by a horizontal line, offspring by a 
vertical line. The proband (presenting patient) is indicated with an arrow. Family members affected with 
deafness are indicated with shading. Unaffected carriers are indicated with a dot. Those affected are 
disproportionately (sometimes exclusively) male. Carrier females may be affected (usually mildly) if X-
inactivation is skewed toward the X chromosome with the normal allele. Affected males will pass the 
deafness gene to all of their daughters and none of their sons. Affected females will pass the gene on to half 
of their children (by probability), which is expected to result in all of their sons being affected and all of their 
daughters being carriers. X-linked inheritance will not display male-to-male transmission. 

Genetics of Hearing Loss 
 
445
 
 
Figure 7. Pedigree of mitochondrial deafness.Four generations of a family are shown in this pedigree. Males 
are represented by squares, females by circles; matings are denoted by a horizontal line, offspring by a 
vertical line. The proband (presenting patient) is indicated with an arrow. Family members affected with 
deafness are indicated with shading. Affected females will pass the gene on to all of their children, while 
affected males will pass the gene on to none of their children. Males and females are affected in roughly 
equal numbers.  
 
3.1. Autosomal Dominant 
 
When a given trait or condition displays an autosomal dominant inheritance pattern, only 
one copy of a gene is necessary to cause the given trait. A person with autosomal dominant 
hearing loss will be expected to have received one copy of a hearing loss gene from one 
parent and a normal copy from the other parent. A parent with a mutation for autosomal 
dominant hearing loss will have a 50% chance of passing on the mutation to each child 
(Figure 8). Since the trait is dominant, we expect that each child receiving this allele will be 
affected with hearing loss. However, this is not always the case because some autosomal 
dominant traits exhibit reduced penetrance. If a trait is fully penetrant, all individuals who 
receive the allele will exhibit the trait. If the trait has reduced penetrance, there will be 
individuals who carry the allele but do not possess the trait. It is not clear why this occurs, but 
it may be due to the influence of other genes. 
In a minority of cases of autosomal dominant hearing loss, the hearing loss arises due to a 
new mutation in the patient. When this occurs, neither parent will carry the mutation, and the 
odds of having another child with the same mutation are very low. This is why genetic testing 
of parents is necessary to estimate recurrence risks. While new mutations can occur in any 
type of disorder, they are seen far more frequently in autosomal dominant disorders because 
only one mutation is necessary.  
 

Danielle Donovan Mercer 
 
446
 A 
 B 
Figure 8. Autosomal dominant inheritance: risk to offspring. Autosomal dominant inheritance most 
commonly occurs when one parent is affected. In 8A, the father is affected with autosomal dominant 
deafness. We will use capital “D” and lowercase “d” to represent the dominant and recessive alleles for the 
gene in question, respectively. Since this gene is autosomal dominant, “D” is the deafness allele and “d” is 
the normal allele. The deaf father carries a “D” allele and a “d” allele, and therefore his sperm cells will be 
one of two varieties. Each of his children will inherit either a “D” allele or a “d” allele from him. There is a 
50% chance of each of these possibilities for each child. The unaffected mother has two “d” alleles, and thus 
all of her children will inherit the “d” allele from her. Since the “D” allele is dominant and will result in 
deafness, 50% of the children born to this couple will be expected to exhibit deafness. In 8B, both parents 
have autosomal dominant deafness for the same gene. Both of them have one “D” allele and one “d” allele 
they can pass on to their children. When we evaluate each of the four combinations in which these alleles can 
come together, each child born to this union would have a 75% chance of being deaf (DD or Dd) and a 25% 
chance of being unaffected (dd). 
 
3.2. Autosomal Recessive 
 
A person with autosomal recessive hearing loss will have two copies of a mutation for the 
involved gene. Unlike dominant conditions, two copies are required for a recessive condition 
to appear. Those who carry one copy of a recessive gene are known as carriers because they 
do not show outward signs of the mutation they carry. The frequent mechanism of inheritance 
for an individual with autosomal recessive hearing loss is two unaffected parents who each 
carry a mutation for the causative gene. This is by far the most common scenario in genetic 

Genetics of Hearing Loss 
 
447
hearing loss, and explains in large part why more than 90% of children with permanent 
hearing loss are born to hearing parents [12]. Each child of parents who are carriers for 
mutations in the same gene will have a 25% chance of inheriting both copies, and therefore 
being affected. They will have a 50% chance of being an unaffected carrier (Figure 9). While 
new mutations can occur in recessive conditions, this is seen far less frequently because it 
would be unusual for two new mutations to occur in the same gene. Another slightly more 
probable mechanism has been observed in autosomal recessive disorders, whereby an 
individual receives one copy of a disease gene from one parent and experiences a new 
mutation in the same gene inherited from the other parent.  
 
 A 
 B 
Figure 9. Autosomal recessive inheritance: risk to offspring. In autosomal recessive inheritance, the deafness 
gene is the lowercase “d”. Deafness will only manifest if an individual carries both copies of the “d” deafness 
allele. Autosomal recessive inheritance most commonly occurs when two unaffected parents are carriers 
(9A). Both parents have the genotype Dd and can pass on either allele to each child. The four combinations 
possible from this union lead to a 25% chance of a deaf child (dd), a 50% chance of a child who is a carrier 
(Dd), and a 25% chance of an unaffected child (DD) from each conception. In 9B, the mother is affected with 
autosomal recessive deafness and the father is an unaffected carrier for the same gene. In this mating, each 
child has a 50% chance of being deaf (dd) and a 50% chance of being an unaffected carrier (Dd).  

Danielle Donovan Mercer 
 
448
3.3. X-Linked 
 
X-linked genes are inherited on the X chromosome, and are thus also known as sex-
linked genes because they are inherited differently in males and females. Males are far more 
likely to exhibit an X-linked disorder, and they tend to be more severely affected than their  
 
 
 
A 
B 
 C 
C 
Figure 10. X-linked inheritance: risk to offspring. With X-linked inheritance, females have two X 
chromosomes, and therefore two alleles, while males have one X chromosome and one allele. 10A 
demonstrates X-linked dominant inheritance with an affected mother. The deafness allele is capital “D”. The 
mother can pass on “D” or “d” to each of her children. The father can only pass on “d” to his daughters; he 
does not pass on an allele from the X chromosome to his sons because his sons will inherit a Y chromosome 
from him. Each child from this mating will have a 50% chance of being affected (Dd for daughters and D for 
sons) and a 50% chance of being unaffected (dd for daughters and d for sons). 10B illustrates X-linked 
recessive inheritance with a carrier mother (Dd) and an unaffected father (D). Since this is recessive 
inheritance, “d” is the deafness allele, which will only manifest in the absence of a “D”. Sons can receive 
either “D” or “d” from their mother, and thus have a 50% chance of being deaf and a 50% chance of being 
unaffected. Since daughters can only receive a normal allele from their father, they will have a 50% chance of 
being a carrier (Dd) and a 50% chance of being unaffected (DD). Combining all offspring together for this 
mating, we expect 25% to be deaf, 25% to be carriers, and 50% to be unaffected. Finally in 10C, we have X-
linked recessive inheritance with a deaf father (d) and an unaffected (noncarrier) mother (DD). In this mating 
all daughters will be carriers (Dd) and all sons will be unaffected (D).  
 
 
 

Genetics of Hearing Loss 
 
449
female counterparts. Males are more vulnerable to X-linked disorders because they only 
possess one X chromosome. By having one X chromosome, males only have one copy of 
each gene located on the X-chromosome. Females have two X chromosomes, so a second 
allele could potentially mask a mutation on the other allele. For males, X-linked traits are 
maternally-inherited because males only inherit X chromosomes from their mothers. 
Likewise, a male with an X-linked disorder will pass this trait on to all of his daughters and 
none of his sons (Figure 10). X-linked genes can also be dominant or recessive, but some 
clinicians prefer not to use these descriptors because dominance and recessiveness are not as 
clear-cut with X-linked inheritance. When considering males, they will be affected with an  
X-linked disorder if they receive a gene with a mutation associated with a disorder. Since 
males will only have one copy of this gene, it is not particularly relevant to their condition 
whether or not it is dominant or recessive (though it may have relevance in regards to 
recurrence risks to offspring).  
Dominance and recessiveness have greater relevance with females, who have two X 
chromosomes. It would therefore be expected that a female would be affected with an  
X-linked dominant disorder if she carries one copy of the mutation, and would be affected 
with an X-linked recessive disorder only if she carries two copies of the mutation. However, 
there are cases of unaffected or mildly affected females with a mutation for an X-linked 
dominant disorder, as well as cases of affected females for an X-linked recessive disorder 
who carry only one copy of a mutation. This is due to a phenomenon known as skewed  
X-inactivation. During development, one of the X chromosomes in every cell of a female’s 
body is inactivated. The X chromosome inactivated in each cell is largely random. As a result, 
females carrying one copy of an X-linked disease gene display wide variability depending on 
the proportions of inactivation for each X chromosome. It is because of skewed  
X-inactivation that an X-linked disorder that is dominant or recessive may not always appear 
to be inherited in a family as expected. It should also be noted that some X-linked disorders 
are actually more common in females. These tend to be X-linked dominant disorders with a 
severe clinical presentation. An example is Rett syndrome, characterized by severe 
developmental delay and autistic features. Rett syndrome is inherited on the X chromosome, 
but it is observed almost exclusively in females because it is lethal to males in utero. A 
similar outcome occurs in many autosomal dominant disorders when two mutation copies are 
inherited.  
 
 
3.4. Mitochondrial 
 
Mitochondria are cellular organelles primarily responsible for energy production, hence 
their nickname “powerhouse of the cell.” The mitochondria are located outside the nucleus, 
where the chromosomes are located (Figure 11). Mitochondria have their own genome of 
only 37 genes located on one circular chromosome whose structure and function are 
reminiscent of a bacterial chromosome. Mitochondria are found in many cells throughout the 
body, including egg cells, but they are not found in mature sperm cells. Because they are not 
in sperm cells, mitochondrial genes are exclusively inherited maternally. A mother with a 
mutation in a mitochondrial gene will pass on the mutation to all of her children, while a man 
with a mitochondrial mutation will not pass it on to any of his children (Figure 12). The 

Danielle Donovan Mercer 
 
450
primitive mitochondrial genome does not have the sophisticated DNA repair mechanisms 
observed in the nuclear genome, and thus, is highly prone to mutations.  
 
 
Figure 11. Human Cell. This figure illustrates the position of the nuclear and mitochondrial genomes in the 
human cell. The nucleus contains 46 chromosomes (23 chromosomes in gametes), which hold nearly all of 
the approximately 20,000 human genes. Mitochondria are organelles located in the cytoplasm, outside of the 
nucleus. Mitochondria have their own genome consisting of 37 genes. The inheritance of these genes does 
not follow the same inheritance pattern as nuclear genes. Rather, mitochondrial genes are inherited 
exclusively from the mother, as they are found in egg cells but not in sperm cells.  
 
Figure 12. Mitochondrial inheritance: risk to offspring. Since mature sperm cells do not contain 
mitochondria, a father’s genotype for a mitochondrial gene has no effect on his offspring. A mother who is 
affected with a mitochondrial gene will pass this on to all of her children. (Though not discussed in this 
chapter, mitochondrial inheritance is sometimes more complex than this. An individual can carry 
mitochondria which are all of the same genotype, known as homoplasmy, or mitochondria with different 
genotypes, known as heteroplasmy. Homoplasmy is demonstrated here.) 

Genetics of Hearing Loss 
 
451
4. SYNDROMIC HEARING LOSS 
 
A syndrome is a disease, disorder, or condition that is associated with a particular set of 
signs, symptoms, or characteristics. Though many syndromes have a genetic etiology, this is 
not always the case.  
Syndromic hearing loss is a syndrome which typically includes hearing loss as one of its 
clinical features. While many syndromes are characterized by distinct facial or physical 
features, bear in mind that clinical features are not always readily visible. Below is a brief 
overview of selected syndromes with hearing loss as a clinical feature in many patients.  
 
 
4.1. Syndromes with Autosomal Dominant Inheritance 
 
4.1.1. Stickler Syndrome 
Stickler syndrome has an incidence of 1 in 7,500 to 9,000. It is associated with visual 
problems, which may include severe nearsightedness, glaucoma, cataracts, and retinal 
detachment. There is a characteristic flattened facial appearance, which often includes a large 
tongue, small lower jaw, and cleft palate. Joints are very flexible. Conductive, sensorineural, 
or mixed hearing loss may be seen, as the middle ear and inner ear can be affected [13, 14].  
Stickler syndrome is inherited in an autosomal dominant fashion, though a small number 
of cases are inherited in an autosomal recessive fashion or are due to new mutations. It is 
caused by mutations in various genes which code for collagen proteins: COL2A1, COL9A1, 
COL11A1, and COL11A2 [14]. The abnormal collagen causes the bones of the face to not 
form properly and leads to hyperflexibility in the joints. Breathing and feeding difficulties 
result from the combination of a large tongue and small lower jaw. Hearing loss is usually 
present at birth and gets worse over time [13, 14].  
 
4.1.2. CHARGE Syndrome 
CHARGE syndrome is a serious medical disorder characterized by a number of physical 
and developmental problems and distinct facial features. It has an incidence of 1 in 10,000. It 
was originally named for what was believed to be its major features: Coloboma, Heart 
defects, Atresia of choanae, Retardation of growth and development, Genital and/or urinary 
abnormalities, and Ear abnormalities and deafness. Many patients are born with life-
threatening birth defects, such as heart defects and breathing problems. Intelligence is 
variable but most patients have severe intellectual disability. Choanal atresia or stenosis 
(narrow or blocked passages from the back of the nose to the throat) cause breathing 
problems. Cranial nerve abnormalities may be present, especially of nerves I, VII, and IX/X, 
leading to absent or decreased sense of smell, facial palsy, and swallowing difficulties, 
respectively. Coloboma of the eye (cleft of the iris, retina, choroids, macula, or disc) may be 
associated with vision loss. Cleft lip and/or palate, kidney problems, and tracheo-esophageal 
fistula may be present [15, 16].  
The outer, middle, and inner ear can all be affected, and thus hearing loss may be 
conductive, sensorineural, or mixed. Severity of hearing loss ranges from mild to profound 
and may be progressive. Outer ear abnormalities reported include a short, wide pinna with 
little or no lobe, triangular concha, decreased cartilage leading to a floppy ear, and a missing 

Danielle Donovan Mercer 
 
452
piece of helix, giving the appearance that a piece of the helix has been snipped. Malformed 
ossicles have been reported in the middle ear, as well as chronic, recurrent otitis media with 
effusion. Mondini defects and small or absent semicircular canals may occur in the inner ear 
[15, 16]. 
Characteristic facies are a square face with a broad prominent forehead, arched eyebrows, 
ptosis, flat midface, small mouth, facial asymmetry, and prominent nasal bridge with square 
root. A common physical feature is a palmar crease in the shape of a hockey stick [15, 16]. 
CHARGE syndrome is caused by a mutation in the CHD7 gene. CHD7 helps regulate 
gene expression during development. A mutation in this gene causes disrupted development, 
resulting in many physical abnormalities. Only about 2/3 of patients test positive for a CHD7 
mutation, so there may be other causative genes that have not been identified. Diagnosis is 
most frequently made clinically. Inheritance pattern is autosomal dominant, but almost all 
cases are due to new mutations. Recurrence risks are therefore very low for parents with an 
affected child [17-20].  
 
4.1.3. Cornelia de Lange Syndrome 
The exact incidence of Cornelia de Lange syndrome is unknown, but it is estimated at 1 
in 10,000 to 30,000. Clinical presentation is variable from one patient to the next, but there 
are many physical signs associated with Cornelia de Lange syndrome, including: severe to 
profound intellectual disability and growth retardation, microcephaly, hirsutism, confluent 
eyebrows, small nose with anteverted nares, downturned upper lip, micrognathia, long curly 
eyelashes, cleft palate, cardiac defects, and severely malformed upper limbs, possibly with 
missing fingers or toes and webbed toes. Auditory system defects may include low-set 
auricles and small external auditory canals. Hearing loss is variable and may be conductive, 
sensorineural, or mixed [21, 22]. 
Cornelia de Lange syndrome has been reported to be caused by mutations in five 
different genes: NIPBL, SMC1A, HDAC8, RAD21, and SMC3 [23-26]. Mutations in NIPBL 
are responsible for more than half of cases. These genes code for proteins important for 
prenatal growth development. The cause is unknown in about 30% of cases, suggesting there 
are more genes yet to be identified. Inheritance pattern is typically autosomal dominant, 
though approximately 5% of cases are X-linked dominant. Most cases are due to new 
mutations, and thus occur in patients with no family history [23-26].  
 
4.1.4. Neurofibromatosis Type 2 
Neurofibromatosis type 2 (NF2) is a disorder featuring growth of benign tumors in the 
nervous system, primarily in the brain. In many patients this includes growths on one or both 
vestibulocochlear nerves. These vestibular schwannomas/acoustic neuromas lead to the same 
sequelae as patients without NF2: neural hearing loss, tinnitus, and vertigo. A notable 
difference is that a patient with NF2 is likely to be affected bilaterally, though not necessarily 
at the same time. In those affected bilaterally, loss of VIIIth nerve function is common [27, 
28]. If loss of VIIIth nerve function is bilateral, the patient is not a cochlear implant candidate 
but may pursue an auditory brainstem implant. However, auditory brainstem implant 
outcomes have been reported to be poorer for NF2 patients compared with non-NF2 patients 
[29]. Other NF2 tumors may cause vision changes, peripheral numbness or weakness, or fluid 
in the brain. The incidence of NF2 is estimated at 1 in 33,000. Signs often show up in 
childhood, though they can develop at any age [27, 28]. 

Genetics of Hearing Loss 
 
453
NF2 is caused by mutations in the NF2 gene, which codes for a protein important for 
insulating neurons [30]. NF2 is an autosomal dominant disorder, but it is inherited from an 
affected parent in only half of cases. The remainder are due to new mutations. NF2 should not 
be confused with the more common neurofibromatosis type 1 (NF1, incidence of 1 in 4,000), 
which is not typically associated with hearing loss. Physical signs of NF1 include café-au-lait 
spots (areas of darker pigmentation on the skin), Lisch nodules (growths on the iris of the 
eyes), axillary and inguinal freckling, subcutaneous neurofibromas, and optic gliomas, which 
may lead to vision loss [27, 28].  
 
4.1.5. Branchio-oto-Renal Syndrome 
Branchio-oto-renal syndrome affects the neck (branchio), the ears (oto), and the kidneys 
(renal). Estimated prevalence of this syndrome is 1 in 40,000. This syndrome arises from a 
disruption in the development of tissues in the neck. Primary physical signs include branchial 
cleft cysts, fistulae between the skin of the neck and the throat, preauricular pits or tags, 
malformed or misshapen pinnae, middle or inner ear structural defects, and abnormal kidney 
structure and function [31, 32]. Surgery may be warranted to treat cysts or fistulae of the 
neck. Dialysis may be needed to treat kidney disease. Hearing loss can vary in severity, and 
may be conductive, sensorineural, or mixed. Approximately 2% of the profoundly deaf are 
thought to have branchio-oto-renal syndrome [33].  
Mutations in three different genes have been reported to cause branchio-oto-renal 
syndrome: EYA1, SIX1, and SIX5, with EYA1 being responsible for about 40% of cases [34-
36]. The resultant proteins from these genes are involved in embryonic development. 
Branchio-oto-renal syndrome is inherited in an autosomal dominant fashion. About 10% of 
cases are due to new mutations [37]. 
 
4.1.6. Waardenburg Syndrome 
Waardenburg syndrome consists of sensorineural hearing loss along with specific 
physical features, including a white forelock; pale blue eyes, different-colored eyes (complete 
heterochromia), or two different colors in the same eye (partial heterochromia); widely-
spaced eyes (hypertelorism); lateral displacement of medial canthi; prominent broad nasal 
root; and hypertrichosis of the medial part of the eyebrows [38, 39]. Its prevalence is 
estimated at 1 in 42,000 [39]. Hearing loss severity can range from mild to profound, and is 
usually bilateral, though unilateral cases have been reported [40]. Some individuals will show 
physical features but have normal hearing. About 2% of cases of profound congenital hearing 
loss are attributable to Waardenburg syndrome [38].  
There are four distinct types of Waardenburg, with types I and II being the most 
common. Physical features vary between types but also between individuals of the same type. 
For example, hypertelorism is commonly seen in type I and not in type II, while hearing loss 
is more common in type II than in type I [41]. Waardenburg syndrome exhibits reduced 
penetrance, meaning individuals who carry a mutation for Waardenburg syndrome do not 
always manifest the disorder. These individuals can, however, pass it on to their children 
where it may be fully penetrant in the offspring. This syndrome also demonstrates variable 
expressivity, meaning that individuals with the same mutation may have different clinical 
presentations. This can even occur in members of the same family. Inheritance pattern is 
typically autosomal dominant, but a small number of cases are due to autosomal recessive 
inheritance or new mutations. Several genes have been implicated in Waardenburg syndrome, 

Danielle Donovan Mercer 
 
454
many of which are involved in melanocyte development [42]. The reader is referred to OMIM 
(Online Mendelian Inheritance in Man) at https://www.omim.org/ for a current review [43].  
 
4.1.7. Treacher Collins Syndrome 
Treacher Collins syndrome has an incidence of 1 in 50,000 live births. This condition 
arises from abnormal development of facial bones and tissues. Characteristic facial features 
include 
down-slanting 
palpebral 
fissures, 
notched 
lower 
eyelids, 
micrognathia, 
underdevelopment or absence of cheekbones and eye socket floor, and cleft palate. About half 
of individuals with Treacher Collins syndrome have conductive hearing loss due to atresia, 
microtia, and/or malformed ossicles [44, 45]. 
Most cases of Treacher Collins syndrome display autosomal dominant inheritance, but 
less than 2% show autosomal recessive inheritance. Approximately 60% of autosomal 
dominant cases are due to new mutations. More than 80% of cases are due to the TCOF1 
gene, with a small minority due to POLR1C and POLR1D [46, 47]. These genes play roles in 
the development of facial bones and tissues. Variable expressivity is seen in Treacher Collins 
syndrome ranging from unnoticeable to severe facial malformation [48]. Because of this, it 
should not be assumed that a patient’s Treacher Collins syndrome is due to a new mutation 
when neither of the parents exhibit signs of the condition. Patients and their parents should 
receive genetics evaluations if the families desire accurate estimates of recurrence risks.  
 
4.1.8. Crouzon Syndrome 
Crouzon syndrome is the most common craniosynostosis disorder, with an incidence of 1 
in 60,000 live births. Facial features include midface hypoplasia, shallow orbits with 
protruding eyes, strabismus, beaked nose, underdeveloped upper jaw, and large forehead. 
Dental problems and cleft lip and palate are also common. Conductive hearing loss occurs 
due to deformed or narrow external ear canals, narrowed internal auditory canals, chronic 
otitis media with effusion, and poor Eustachian tube function [49, 50].  
Crouzon syndrome is caused by mutations in the FGFR2 gene. This gene has many 
functions, including signaling cellular differentiation during embryonic development [50]. 
Mutations lead to premature fusion of sutures in the skull. Inheritance for Crouzon syndrome 
is autosomal dominant, though approximately 25% of cases are due to new mutations [51].  
 
4.1.9. Apert Syndrome 
Apert syndrome is a craniosynostosis disorder with many similarities to Crouzon 
syndrome. Reported incidence and prevalence data vary, but Apert syndrome affects 
approximately 1 in 70,000 live births with a prevalence of about 1 in 100,000. Common 
physical features are frontal bossing, midface hypoplasia, protruding eyes, strabismus, low-set 
ears, syndactyly, hyperhidrosis, oily skin with severe acne, patches of missing hair in the 
eyebrows, and cleft lip and palate. Shallow eye sockets can cause vision problems. Cognitive 
abilities range from normal to mild to moderate intellectual disability. Conductive hearing 
loss and recurrent otitis media are common [49, 52]. 
Like Crouzon syndrome, Apert syndrome is caused by mutations in the FGFR2 gene and 
has an autosomal dominant inheritance pattern. Unlike Crouzon syndrome, virtually all cases 
of Apert syndrome are due to new mutations [49, 52]. 
 
 

Genetics of Hearing Loss 
 
455
4.2. Syndromes with Autosomal Recessive Inheritance 
 
4.2.1. Pendred Syndrome 
Pendred syndrome is a disorder associated with sensorineural hearing loss and thyroid 
goiter. Exact incidence is unknown but it is estimated to affect 1 in 13,000 to 15,000 people. 
Thyroid goiter is most likely to appear between late childhood and early adulthood, and it 
usually does not affect thyroid function. Severe to profound sensorineural hearing loss is 
typically congenital and may be progressive or fluctuating. Enlarged vestibular aqueduct is 
typically present, which may cause balance disturbances [53-55]. About half of individuals 
with Pendred syndrome have a Mondini malformation [55].  
Pendred syndrome is caused by mutations in the SLC26A4 gene, which codes for pendrin, 
a protein that transports anions in and out of cells. While its role is not fully understood, it is 
known to be important for normal functioning of the thyroid and inner ear [56]. Inheritance of 
Pendred syndrome is autosomal recessive. Mutations in SLC26A4 are also responsible for 
some cases of nonsyndromic hearing loss. Altogether this gene is thought to account for 5 to 
10% of hereditary deafness [57, 58].  
 
4.2.2. Usher Syndrome 
Usher syndrome is a condition of combined hearing loss and vision loss, sometimes 
accompanied by vestibular dysfunction. Its prevalence worldwide is estimated at 4 per 
100,000, but it is reported to be much more common in certain populations, particularly in 
Ashkenazi Jewish and Louisiana Acadian populations [59, 60]. Though rare, Usher syndrome 
is responsible for about half of all concurrent deafness and blindness in adults [61, 62]. There 
are three types of Usher syndrome, with type I being the most severe. Vision loss first 
presents as night blindness and later progresses to retinitis pigmentosa [59].  
The typical course for type I Usher syndrome is congenital bilateral profound 
sensorineural deafness, with progressive vision loss beginning around 10 years of age [59]. 
The vision deteriorates to blindness by early adulthood. There is also an absence of vestibular 
function, which frequently goes unnoticed. Mothers of children with Usher syndrome 
commonly report they were late to begin walking, often 18 months to 2 years of age. As the 
child grows and develops, the central nervous system adapts to this lack of vestibular 
function. A typical presentation of type II Usher syndrome is congenital moderate to severe 
sensorineural hearing loss, and vision loss beginning in adolescence [63]. Progression to 
blindness commonly occurs in the 30s. Vestibular function remains intact. Type III is the 
mildest form of Usher syndrome. It accounts for only 2-4% of cases worldwide, but up to 
40% of cases in the Finnish population [63]. Hearing loss is progressive and typically less 
severe. Onset of both hearing loss and retinitis pigmentosa is variable. Vestibular function 
among patients is also variable, with everything from normal to absent vestibular function 
reported. A summary of Usher syndrome clinical presentations by type is shown in Table 1.  
 
Table 1. Usher syndrome clinical presentations by type 
 
 
Type I 
Type II 
Type III 
Hearing Loss 
Profound 
Severe 
Progressive 
Vestibular function 
Absent 
Normal 
Variable 
Onset of blindness (decade) 
First 
Second 
Variable 

Danielle Donovan Mercer 
 
456
Usher syndrome is an autosomal recessive disorder. It is thought to be more common in 
certain populations, such as the Louisiana Acadians, due to the founder effect, illustrated in 
Figure 13 [60]. A founder effect results when a small group of individuals become “founders” 
of a new population. This new founder population becomes isolated, either geographically or 
culturally, from other populations for several generations. The ultimate effect is that they 
become genetically isolated. Since the original founders were from a very small group, they 
may not be genetically diverse. After many generations certain traits or disorders may be 
amplified. In the case of the Louisiana Acadians, their roots can be traced back to French 
descendants of Canadian Nova Scotia Acadians. A few hundred of these descendants 
migrated to southern Louisiana in the 1700s. At this writing there are 11 genes associated 
with Usher syndrome and 3 genetic loci [63]. A locus is a fixed position on a chromosome, in 
this case where a gene is located. A locus (plural loci) may be described in association with a 
certain trait or condition prior to the identification of the responsible gene. Hence, there will 
likely be more genes recognized as causative for Usher syndrome. Genes responsible for 
Usher syndrome code for proteins of different classes and families. For more information on 
the functions of these proteins, the reader is referred to Yan and Liu, 2010 [63]. The genes 
involved in Usher syndrome are listed in Table 2. 
 
 
Figure 13. Founder effect. The founder effect is observed when a population is derived from a founding 
population which consisted of relatively few members. This figure illustrates the concept of the founder 
effect. A few members of the original larger population broke off and formed a new colony. Due to the small 
starting population size, the colony has reduced genetic variation and a non-random sample of the genes from 
the original population. After many generations of geographic and cultural isolation, gene variants which 
were once rare have propagated and become relatively common. As a result, some diseases are found more 
frequently in these groups than in other populations, or they have distinct clinical or genetic features due to 
unique mutations.  
Table 2. Genes involved in Usher syndrome 
 
Type I 
Type II 
Type III 
MYO7A 
USH2A 
USH3A 
USH1C 
ADGRV1 
HARS 
CDH23 
WHRN 
 
PCD15 
 
 
SANS 
 
 
CIB2 
 
 

Genetics of Hearing Loss 
 
457
4.2.3. Jervell and Lange-Nielsen Syndrome 
Jervell and Lange-Nielsen syndrome affects 1.6 to 6 per 1,000,000 people. Though rare, 
it has been suggested that up to 3 out of 1,000 people born deaf have Jervell and Lange-
Nielsen syndrome [64]. It is characterized by congenital bilateral profound sensorineural 
hearing loss and cardiac defects. Since the cardiac issues are not present at birth, a proper 
diagnosis is often late or missed altogether. The first physical signs of cardiac problems are 
irregular heartbeats in early childhood, which may lead to episodes of fainting, or syncope. 
Long QT syndrome, a serious condition causing heart muscle to take longer than usual to 
recharge between beats, may be present [65]. There is a risk of cardiac arrest and sudden 
death in patients with this syndrome. Treatment may involve beta-adrenergic blockers for 
long QT syndrome and implantable cardioverter defibrillators (ICDs) for patients with a 
history of cardiac arrest [66].  
Jervell and Lange-Nielsen syndrome is caused by mutations in either the KCNQ1 or 
KCNE1 genes. KCNQ1 is responsible for 90% of cases while KCNE1 is responsible for 10% 
of cases [66]. These genes code for potassium ion channels. Mutations in one of these genes 
lead to faulty potassium ion channels, which disrupts the usual flow of ions through the inner 
ear and cardiac muscle. The heart and inner ear are the areas of the body with the greatest 
utilization of potassium ions. Therefore, these areas are most affected by the faulty channels 
[66]. Jervell and Lange-Nielsen syndrome is an autosomal recessive disorder.  
 
 
4.3. Syndrome with X-Linked Inheritance: Alport Syndrome 
 
Alport syndrome is characterized by hearing loss, kidney disease, and eye abnormalities, 
which may include a decrease in vision in a minority of patients [67]. It has a reported 
incidence of 1 in 50,000 [68]. Hearing loss varies from mild to severe sensorineural hearing 
loss, often sloping, and may be progressive. Typical age of onset for hearing loss is late 
childhood to early adolescence. More than half of patients with Alport syndrome have hearing 
loss, with males much more likely than females to exhibit this clinical feature. Kidney disease 
is preceded by blood in the urine (hematuria). As kidney disease progresses, proteinuria and 
hypertension develop. Many patients develop end-stage renal disease and require dialysis and 
kidney transplantation. Males are almost always more severely affected than females. Eye 
abnormalities may include anterior lenticonus (an abnormally-shaped lens), cataracts, corneal 
erosions, and retinal thinning [69]. 
Alport syndrome is caused by mutations in COL4A3, COL4A4, and COL4A5, genes 
coding for type IV collagen [70, 71]. This type of collagen is an important structural 
component in the glomeruli of the kidneys. Approximately 80 to 85% of cases are inherited in 
an X-linked dominant fashion, explaining why males are affected more frequently and more 
severely than females. About 15% of cases display an autosomal recessive inheritance pattern 
and 1% show an autosomal dominant pattern [72].  
 
 
4.4. Syndromes with Mitochondrial Inheritance: MELAS and MERRF 
 
MELAS and MERRF are two syndromes caused by mitochondrial mutations. The exact 
incidences of these syndromes are unknown, but they are both very rare. As with all 

Danielle Donovan Mercer 
 
458
mitochondrial disorders, they are inherited maternally, though they can be due to new 
mutations. MELAS and MERRF both affect many systems of the body, especially the 
muscles, brain, and nervous system, cell types rich in mitochondria [73, 74]. Severity is 
variable, sometimes even amongst affected family members. Sensorineural hearing loss can 
appear in both syndromes. They are named after their most prominent features: MELAS 
(Mitochondrial encephalomyopathy, Lactic acidosis, and Stroke-like episodes); MERRF 
(Myoclonic epilepsy with Ragged red fibers). Muscle pain/weakness/twitches and seizures are 
common features [73, 74]. 
 
 
4.5. Down Syndrome: The Most Common Genetic Syndrome 
 
Down syndrome occurs in 1 out of every 700 live births, making it the most common 
genetic syndrome [75]. Down syndrome differs from the other genetic syndromes discussed 
in this chapter in that it is a cytogenetic, or chromosomal disorder. Also known as trisomy 21, 
Down syndrome is caused by an extra chromosome 21. An individual with Down syndrome 
will therefore have a chromosome complement of 47 in every cell, as opposed to the typical 
46 chromosomes. This is essentially a duplication of every gene on chromosome 21. (A 
minority of cases display mosaicism, in which some cells have 47 chromosomes and some 
cells have 46 chromosomes. These patients tend to be affected more mildly.) Chromosome 21 
has over 700 genes, 200 to 300 of which code for proteins [76]. Down syndrome is one of the 
few trisomies that is compatible with life, owing to the fact that there are fewer genes on 
chromosome 21 than any other autosome. (The Y chromosome, a sex chromosome, contains 
about 200 fewer genes.) 
Down syndrome consists of intellectual disability, characteristic facial and physical 
features, and heart defects in about half of patients. Physical features include hypotonia, flat 
facial profile, epicanthal folds, up-slanting palpebral fissures, small low-set ears with folded 
helix, shortened limbs, and transpalmar crease [77]. Gastrointestinal problems associated with 
intestinal or esophageal blockages may occur. There is an increased risk of developing heart 
disease and leukemia. Hearing loss is common, especially conductive hearing loss owing to 
small ear canals and short Eustachian tubes. These attributes frequently lead to cerumen 
blockage and chronic otitis media with effusion, respectively. Sensorineural hearing loss is 
also not uncommon in individuals with Down syndrome, with permanent hearing loss being 
reported in 25% of patients [78].  
Down syndrome occurs during a nondisjunction event during cell division, whereby the 
homologous pair of chromosome 21s do not segregate appropriately into each daughter cell. 
This nondisjunction can occur via three different mechanisms: during meiosis of the egg cell, 
during meiosis of the sperm cell, or during postzygotic mitosis. Nondisjunction during 
meiosis of the egg cell is the most common mechanism, and is illustrated in Figure 14. It is 
unknown why nondisjunction occurs, but it happens much more frequently in egg cells as a 
woman ages. Advanced maternal age is therefore a major risk factor for Down syndrome. It 
can be diagnosed prenatally through cytogenetic testing via maternal blood sample (cell-free 
fetal DNA), amniocentesis, or chorionic villus sampling (CVS).  
 

Genetics of Hearing Loss 
 
459
 
Figure 14. Chromosome nondisjunction during meiosis. Meiosis is cell division in gametes (egg and sperm 
cells). It consists of two cell divisions, vs. one cell division in mitosis (somatic cells). For simplicity, this 
figure shows one chromosome pair. (Human cells contain 23 chromosome pairs.) In meiosis I, the 
chromosome pair segregates into two separate cells. In meiosis II, the chromosome splits at the centromere, 
halving the genetic material. The process of meiosis II is similar to mitosis. The cells circled in green resulted 
from correct cell divisions. The remaining cells experienced a nondisjunction event in either meiosis I or 
meiosis II. Nondisjunction produces cells with too much or too little genetic material, which are almost 
always incompatible with life. However, excess genetic material can be compatible with life if the 
chromosome is very small, such as chromosome 21. An extra chromosome 21 is known as trisomy 21, or 
Down syndrome.  
 
5. NONSYNDROMIC HEARING LOSS 
 
Nonsyndromic hearing loss refers to hearing loss occurring in isolation, in the absence of 
other clinical features. In this context, we are referring to nonsyndromic hearing losses with 
genetic etiologies. However, the term “nonsyndromic hearing loss” may be used in cases of 
isolated hearing loss due to other etiologies or when the etiology is unknown. Bear in mind 
that many cases of nonsyndromic hearing loss of unknown etiology will in fact have a genetic 
etiology or a genetic contributor. 
Approximately 70% of genetic hearing loss cases are nonsyndromic [79]. Of these 
genetic nonsyndromic cases, 75 to 80% show an autosomal recessive inheritance pattern, 20% 
show an autosomal dominant inheritance pattern, and 1 to 2% show an X-linked or 
mitochondrial inheritance pattern [79]. More than 100 genes have been identified as causative 
for nonsyndromic hearing loss. For the most up-to-date data, visit the Hereditary Hearing 
Loss Homepage [9].  
 
 

Danielle Donovan Mercer 
 
460
5.1. Nonsyndromic Hearing Loss: Autosomal Recessive Inheritance 
 
5.1.1. Connexin 26 Hearing Loss Is Caused by the GJB2 Gene 
The most common cause of all forms of genetic nonsyndromic hearing loss is the GJB2 
gene, commonly known as connexin 26 [80]. You may also see it referred to as DFNB1, its 
locus name. Connexins are proteins that play supporting roles in the cochlea, and are thought 
to be important for the recycling of potassium ions in the cochlea [81]. Mutations in the GJB2 
gene are responsible for about half of all cases of autosomal recessive nonsyndromic hearing 
loss [80]. More than 100 mutations have been reported in this gene [82]. By far, the most 
common mutation is the 35delG mutation, accounting for about 70% of cases [83]. The 
35delG mutation is found in populations all over the world, but it is most common in 
Caucasian populations, particularly those of northern European or Mediterranean descent [79, 
84]. Likewise, this population has the highest carrier rate for the 35delG mutation. The carrier 
rate refers to the proportion of individuals in a given population who are carriers for a genetic 
trait or disorder. It generally is used to describe autosomal recessive conditions because 
carriers of an autosomal recessive condition will not be affected. As previously discussed in 
section 3.2, a carrier of an autosomal recessive disorder will not exhibit the disorder 
themselves because they only have one copy of the mutation. Their other gene copy, or allele, 
is normal, and thus protein function from this gene copy is normal. When a carrier passes on 
genes to their offspring, each child may get the normal copy or the affected copy, the 35delG 
mutation in this case. In populations where the carrier rate is high, there is a greater likelihood 
that two individuals who are carriers for the same disorder will mate. For the 35delG 
mutation, carrier rates are 2 to 3% for Caucasians, 4 to 5% for Ashkenazi Jewish, and 1% for 
Japanese [79, 84]. 
Connexin 26 hearing loss shows a great deal of clinical variability, likely a reflection of 
the many different mutations and populations in which it is found [80, 85]. As in most forms 
of autosomal recessive hearing loss, the hearing loss in connexin 26 tends to have an early 
onset. Hearing loss is usually present in early childhood and may be congenital. In many 
cases, the hearing loss remains stable, but some cases show a progressive worsening of 
hearing loss. The type of hearing loss is sensorineural, but the degree is variable. Individuals 
with connexin 26 can have anywhere from mild to profound hearing loss [85]. The degree of 
hearing loss can even vary between members of the same family. Both ears are usually 
affected to the same degree. Though far less common, autosomal dominant mutations in 
connexin 26 also exist. 
 
5.1.2. Other Genes 
There are too many genes associated with hearing loss to discuss here. What follows is a 
brief description of the next seven most common causative genes in autosomal recessive 
hearing loss. The reader is encouraged to further investigate any genes of interest on OMIM 
[43]. An exhaustive list can be accessed on the Hereditary Hearing Loss Homepage [9]. 
 
5.1.2.1. SLC26A4 
SLC26A4 codes for pendrin. This is the same gene that causes Pendred syndrome, 
discussed in section 4.2.1, and thus, hearing loss configuration shows similarities to Pendred 
syndrome. Different mutations in this gene cause nonsyndromic hearing loss. Onset of 

Genetics of Hearing Loss 
 
461
hearing loss is prelingual, frequently congenital. Typical audiometric configuration is 
moderate to profound sensorineural hearing loss, affecting anywhere from high frequencies to 
all frequencies. Hearing loss may be fluctuating or progressive. As observed in occurrences of 
Pendred syndrome, most patients have an enlarged vestibular aqueduct. Mondini defects may 
be present in some patients [57, 58].  
 
5.1.2.2. MYO15A 
MYO15A codes for myosin 15A, one of the myosins, a group of motor proteins of many 
functions, some of which are important for the structure of stereocilia. Onset of hearing loss is 
prelingual, usually congenital. Typical audiometric configuration is severe to profound 
sensorineural hearing loss with all frequencies affected [86-88].  
 
5.1.2.3. OTOF 
The OTOF gene codes for otoferlin, a protein thought to be involved in vesicle 
membrane fusion. Onset of hearing loss is prelingual. This is the most common genetic cause 
of auditory neuropathy [89].  
 
5.1.2.4. CDH23 
CDH23, also known as cadherin 23, is another protein expressed in the stereocilia of hair 
cells [90, 91]. Onset of hearing loss is prelingual, and configuration is severe to profound 
sensorineural hearing loss. All frequencies are typically affected, but hearing loss may be 
seen in the high frequencies first [92]. Mutations in the CDH23 gene are also associated with 
Usher syndrome type 1D [90]. 
 
5.1.2.5. TMC1 
The TMC1 gene codes for transmembrane channel-like protein 1. The exact function of 
this gene is unknown, but it is required for normal function of cochlear hair cells. Autosomal 
recessive and autosomal dominant mutations have been reported. Hearing loss is usually 
congenital profound sensorineural with an autosomal recessive mutation, or rapidly 
progressive severe to profound sensorineural with an autosomal dominant mutation [93-95].  
 
5.1.2.6. TMPRSS3 
TMPRSS3 codes for transmembrane protease serine 3, a protein whose function is 
unknown. Hearing loss can be congenital profound or postlingual progressive, often with a 
ski slope audiogram that eventually progresses to a flat loss [96, 97]. 
 
5.1.2.7. TECTA 
TECTA codes for alpha tectorin, a major structural component of the tectorial membrane. 
Mutations in this gene are a common cause of mid-frequency hearing loss, exhibiting “notch” 
or “cookie-bite” audiograms. When inherited recessively, onset is either prelingual or 
postlingual during childhood or adolescence. (Autosomal dominant mutations are associated 
with a later age of onset.) Sensorineural hearing loss severity is moderate to profound, often 
with mid frequencies most affected, and may be progressive [98]. Mutations in this gene have 
been suggested to be associated with Jacobsen syndrome, a rare disorder characterized by 
developmental delays and abnormal blood clotting [99].  

Danielle Donovan Mercer 
 
462
5.2. Nonsyndromic Hearing Loss: Autosomal Dominant inheritance 
 
Genes associated with autosomal dominant nonsyndromic hearing loss are responsible for 
a minority, though significant portion of cases. Again, there are too many genes for an 
exhaustive review. A brief description of the most common causative genes in autosomal 
dominant hearing loss follows.  
 
5.2.1. WFS1 
WFS1 codes for wolframin, a protein involved in ion homeostasis. Onset of hearing loss 
may be prelingual or postlingual in childhood or adolescence. It is characterized by a low-
frequency sensorineural hearing loss. Frequencies up to 2 kHz are likely to be affected, but 
severity usually falls short of profound [100]. Tinnitus is a frequent complaint. Mutations in 
this gene also cause Wolfram syndrome. Wolfram syndrome is extremely rare and affects 
many systems. Deafness, progressive vision loss, diabetes mellitus, and diabetes insipidus are 
characteristic features [101].  
 
5.2.2. KCNQ4 
KCNQ4, also known as potassium voltage-gated channel, is another protein involved in 
ion homeostasis. Onset of hearing loss is postlingual, commonly in childhood to young 
adulthood. Hearing loss is sensorineural, with high frequencies affected first and mid to low 
frequencies affected later [102, 103]. Severity usually presents as mild to moderate and later 
progresses to profound. Around 25 to 35% of patients have an increased vestibulo-ocular 
reflex [104].  
 
5.2.3. COCH 
The COCH gene codes for cochlin, an extracellular matrix protein. Hearing loss tends to 
present in adulthood, and is progressive sensorineural, with high frequencies most affected. 
Aside from the hearing loss configuration, clinical presentation often closely mimics 
Meniere’s disease. Vertigo, tinnitus, and aural fullness are all common complaints. 
Oculomotor disturbances are also common [105, 106].  
 
5.2.4. GJB2 
GJB2 codes for connexin 26, as previously discussed in section 5.1.1. This is the most 
common gene associated with autosomal recessive nonsyndromic hearing loss, but there are 
also mutations in this gene that cause autosomal dominant hearing loss. Onset of hearing loss 
may be later than the autosomal recessive variety, but often is prelingual or childhood-onset. 
Sensorineural hearing loss frequently begins in the high frequencies and progresses to affect 
the mid frequencies. In about half of cases, skin disorders are present, characterized by 
hyperkeratotic skin lesions [107]. The GJB6 gene, also known as connexin 30, is a less 
common autosomal dominant hearing loss gene which shows a similar presentation, absent 
the skin lesions.  
 
 
 

Genetics of Hearing Loss 
 
463
5.3. Nonsyndromic Hearing Loss: X-Linked Inheritance 
 
X-linked nonsyndromic hearing loss is rare. The best-known gene in X-linked 
nonsyndromic hearing loss is POU3F4. Onset is prelingual. Mutations in this gene lead to 
defects in the bony labyrinth. Stapes fixation is common, and thus hearing loss may be mixed 
or sensorineural [108]. The stapes fixation may be addressed surgically, but there is a risk of 
perilymphatic gusher during surgery. Perilymphatic gusher is a phenomenon whereby a rush 
of perilymph exits the cochlea during stapedotomy or stapedectomy [109]. Because of this 
risk it is very helpful for the surgeon to know in advance of POU3F4 involvement, both for 
risk assessment and surgery strategy. As with other X-linked genes, most affected individuals 
are male.  
 
 
5.4. Nonsyndromic Hearing Loss: Mitochondrial Inheritance 
 
Hearing loss due to a mutation in a mitochondrial gene is rare, but they are noteworthy 
because of their role in ototoxic-induced hearing loss. Recall from section 3.4 that 
mitochondria have their own genome separate from the nuclear genome. The mitochondrial 
genome consists of only 37 genes. A1555G is a mitochondrial mutation in the 12S rRNA 
gene, and it is the most common mitochondrial mutation causing hearing loss [110]. Since 
this is a mitochondrial mutation, it is inherited from the mother. The carrier rate is highest in 
Asian populations [110-112]. About half of individuals with this mutation develop hearing 
loss, usually after age 30. However, hearing loss can occur much earlier if an individual with 
this mutation receives aminoglycoside antibiotics (amikacin, dihydro-streptomycin, 
gentamicin, kanamycin, neomycin, streptomycin, tobramycin). Though rarely encountered in 
the United States, deafness associated with this mutation is much more common in China. 
The combination of high carrier rates and overuse of antibiotics has increased the rates of 
deafness due to this mutation in China [111, 112]. Use of aminoglycoside antibiotics over 
non-aminoglycosides should be carefully considered and utilized only when the benefits 
outweigh the risks.  
The type of hearing loss is sensorineural. The degree of hearing loss can vary from mild 
to profound, but is likely to be severe to profound if the individual is exposed to 
aminoglycoside antibiotics. Hearing loss can occur a few days or weeks after aminoglycoside 
administration, even after a single dose [110]. As mitochondria are thought to have been 
independent single-celled organisms billions of years ago, their cellular structure and genome 
are similar to that of bacteria. Aminoglycoside antibiotics work by binding to the bacterial 
ribosome and disrupting protein function. The A1555G mutation essentially makes the 
ribosome more similar to a bacterial ribosome [113].  
 
 
6. TECHNOLOGIES IN GENETIC TESTING 
 
6.1. Cytogenetics 
 
Cytogenetics is the branch of genetics that evaluates chromosome structure and function. 
This can be viewed as assessing the genome at the cellular level (cyto=cell). Visualizing 

Danielle Donovan Mercer 
 
464
chromosomes means we are “zoomed out” relative to molecular testing. The cellular view 
corresponds to a bird’s-eye view: we are getting a large-scale view, but we cannot see small 
details. Cytogenetic testing is useful for detecting changes in chromosome number and 
structure: too many chromosomes, missing chromosomes, and large structural aberrations. It 
will not detect small rearrangements or mutations such as point mutations (substitution of one 
base of DNA for another). These rearrangements are simply too small for us to see from our 
zoomed-out vantage point. The major testing tools in cytogenetics are karyotyping, FISH, and 
array CGH. An explanation of each follows.  
 
6.1.1. Classical Cytogenetics: Creation of a Karyotype 
A karyotype is a preparation of chromosomes from one cell, in which the chromosomes 
are arranged according to their numerical assignments. Recall from section 2.3 that a human 
cell is expected to contain 46 chromosomes: 44 autosomes and 2 sex chromosomes. Males 
and females differ only in their sex chromosome complement. A typical male will have a 
karyotype of 46,XY and a typical female will have a karyotype of 46,XX. There are several 
steps necessary to prepare a karyotype. First, cells must be cultured anywhere from 24 hours 
to 8 to 10 days, depending on sample type and viability. Many sample types require addition 
of a mitogen, such as PHA (phytohemagglutinin) to stimulate cell division. Direct samples 
without culturing are sometimes used when results are needed urgently, but this is not utilized 
frequently, as morphology tends to be poor. Many different tissue types can be used for 
cytogenetic testing, including peripheral blood, bone marrow, amniotic fluid, chorionic villus 
sampling, skin biopsy, tumors, and products of conception (abortus material, typically from 
spontaneous abortions), among others. These tissue types represent the diverse patients who 
undergo cytogenetic testing. Diagnostic usefulness encompasses disparate needs, such as 
prenatal, cancer, developmental delay, and infertility. Buccal cells, epithelial cells collected 
through saliva or cheek swabs, cannot be used for cytogenetic testing because they do not 
grow sufficiently in culture. They can, however, be used in DNA testing (Sections 6.2 and 
6.3). 
After cells are cultured to increase cell growth and cell division, samples are harvested to 
obtain chromosome spreads which can be used in a karyotype. The purpose of the harvest 
procedure is to accumulate cells in metaphase of mitosis. This is the phase of mitosis where 
the chromosomes reach maximal condensation and are most readily analyzed. The harvest 
procedure requires a series of steps and takes several hours: 
 
1.  Incubation with colchicine: Colchicine poisons the mitotic spindle, which is 
necessary for chromosomes to split into two daughter cells and complete mitosis. 
Colchicine allows for a greater number of cells in culture to accumulate in 
metaphase. Without colchicine, very few cells would be in metaphase, making 
analysis difficult to impossible. 
2.  Incubation in a hypotonic solution: Cells are collected by centrifugation and a 
hypotonic solution is added. This solution will be at a concentration that is slightly 
hypotonic to the cells in culture. Through the property of osmosis, water will move 
from a less concentrated solution to a more concentrated solution. Water will 
therefore move from the hypotonic solution and into the cells. The purpose of this 
solution is to swell the cells just enough to allow the chromosomes to spread, but not 

Genetics of Hearing Loss 
 
465
enough so that the cells burst. Spreading the chromosomes aids greatly in analysis. 
Commonly used hypotonic solutions are potassium chloride and sodium citrate. 
3.  Addition of a fixative: After the appropriate incubation time in hypotonic solution, a 
fixative is added, typically a 3:1 solution of methanol:acetic acid. This fixes, or 
preserves the cells, and removes excess water and cellular debris. At this point the 
cells are no longer alive. Several fixative changes may be necessary. 
4.  Slide preparation: Cells are dropped onto slides and aged overnight on a hot plate. 
5.  Slide staining: Slides are treated with trypsin, an enzyme that digests proteins bound 
to DNA and allows the chromosomes to take up stain in a characteristic banding 
pattern. Slides are then stained with a deep stain, such as Giemsa or Wright stain. 
6.  Chromosome analysis and karyotyping: Chromosomes are analyzed under a light 
microscope at 100x magnification. An imaging system attached to the microscope is 
used to photograph desired cells, which are then karyotyped on a computer. The end 
result is a completed karyotype (Figure 2).  
 
For a more detailed review, see Howe et al. [114].  
During chromosome analysis, the technologist will find a metaphase cell under the 
microscope suitable for analysis. The chromosomes are counted, and then evaluated one 
chromosome at a time to ensure all expected bands are present. For a typical case, 20 cells are 
analyzed. This may be increased to 50 or 100 cells if mosaicism is suspected or discovered. 
Mosaicism means that there is more than one chromosome complement in an individual. This 
is not common, but does sometimes occur due to a postzygotic nondisjunction event (see 
section 4.5). 
Aside from chromosome number, cytogenetic analysis also seeks to discover structural 
aberrations. There are 4 major types of chromosome aberrations: 
 
1.  Deletion: A section of a chromosome is missing. 
2. Duplication: A section of a chromosome is repeated. 
3.  Inversion: A section of a chromosome is flipped, as if a piece was removed, turned 
around, and then inserted back into the chromosome. With an inversion, no material 
is missing or gained, just rearranged. In most cases this is benign, such that the 
individual carrying a chromosomal inversion does not know unless they happen to 
get a karyotype. In rare cases an inversion can cause problems if the chromosome 
happens to be cut within a gene. A person carrying an inversion is also at increased 
risk of having a child with a deletion or duplication in the breakpoint regions. 
4. Translocation: Sections of two or more chromosomes are exchanged with one 
another. Translocations can be balanced or unbalanced. When balanced, there is 
rarely a consequence to the individual carrying a translocation. However, like 
inversions, there is a risk to offspring because a child can inherit an unbalanced form. 
When unbalanced, there will be extra material from one chromosome and missing 
material from another chromosome. This is essentially like having both a deletion 
and a duplication. 
 
How deleterious these chromosomal aberrations are depends on several factors, and are 
not always predictable. In general, larger deletions and duplications are more deleterious than 
smaller ones, but very small deletions and duplications can have enormous consequences as 

Danielle Donovan Mercer 
 
466
well. The number of genes affected, redundancy of those genes, and influence of modifier 
genes will all affect the patient’s clinical presentation. Chromosome analysis is useful for 
identifying these aberrations, but even the smallest deletions and duplications can only be 
visualized microscopically if they involve hundreds of thousands of base pairs of DNA. This 
is a major limitation of karyotyping. The next two techniques allow us to zoom in a bit further 
and identify smaller aberrations.  
 
6.1.2. FISH: A Molecular Cytogenetic Technique 
The smallest of chromosomal deletions that are visible microscopically are about 200 to 
300 kilobases of DNA (1 kilobase=1,000 bases), and even that size is difficult unless 
chromosome length, spreading, and banding are optimal. These small deletions, also known 
as microdeletions, can be visualized by a technique known as FISH (fluorescence in situ 
hybridization). FISH is considered a molecular cytogenetic technique because it utilizes 
similar principles to that employed in polymerase chain reaction and other molecular 
techniques. The process is relatively simple. A slide is prepared after chromosome harvest, 
but the slide is not aged or stained. The slide is heated at high temperature to denature the  
 
 A
 B 
Figure 15. Fluorescence in situ hybridization (FISH). Pictures of human lymphocytes from two patients 
stained with FISH probes. These cells were probed for the RB1 gene, a tumor suppressor gene located on 
chromosome 13, tagged with a red fluorescent probe. Deletion of RB1 is associated with retinoblastoma, an 
aggressive ocular cancer. A centromere probe on chromosome 10, tagged with a green fluorescent probe, is 
used as a control. Since two copies of each RB1 and chromosome 10 are expected, the anticipated result is 
two red signals and two green signals. The cell in A is normal, with two copies of each signal. The cell in B 
only has one red signal due to deletion of one copy of the RB1 gene. This patient would be expected to 
develop retinoblastoma. FISH pictures are courtesy of the laboratory of Dr. Fern Tsien, Louisiana University 
Health Sciences Center Department of Genetics, used with permission.  
 

Genetics of Hearing Loss 
 
467
DNA into two separate strands. A FISH probe is added to the slide and incubated. This probe 
consists of two components: a stretch of DNA (~100-300 kilobases) complementary in 
sequence to the desired area attached to a fluorophore. During incubation, the denatured DNA 
will renature with the FISH probe. The slide is visualized under a fluorescent microscope in 
the dark. The fluorophore present will excite and fluoresce when exposed to the appropriate 
wavelength of light. Fluorophores are available in a variety of colors, with red, green, and 
aqua being the most commonly used.  
 
 
Figure 16. Array CGH. Array CGH (comparative genomic hybridization) is illustrated here. Thousands of 
probes are attached to a slide. DNA from the patient is mixed with normal control DNA and labeled with 
fluorescent dyes. After hybridization, the slide is scanned and analyzed with specialized software. The red 
and green dyes will appear yellow when combined in equal amounts. Areas of gene deletions will appear 
green (patient DNA is missing), while areas of gene duplications will appear red (patient DNA is in excess of 
control DNA). Balanced rearrangements are undetectable with this method.  
FISH has a few advantages over the karyotype. Its greatest advantage is in identifying 
microdeletions or microduplications that are too small to detect with standard cytogenetics. 
For most FISH probes, interphase cells can be analyzed, yielding many more cells to work 
with. Preparations by FISH also work fairly well on uncultured cells and the test has a fast 
turnaround time, making FISH more amenable to “stat” testing. A major drawback with FISH 
is that each probe used is only testing a very specific chromosomal region. In other words, 

Danielle Donovan Mercer 
 
468
you need to know what you are looking for. This usually means the physician must suspect 
the correct syndrome and request FISH testing for that syndrome. Figure 15 shows a picture 
of a cell tested with a FISH probe.  
 
6.1.3. Array CGH: Molecular Cytogenetics of the Entire Genome 
In the last decade, the karyotype has been largely replaced with array CGH (comparative 
genomic hybridization). Array CGH is a technique that combines important components of 
karyotyping and FISH. A simplified view of array CGH is demonstrated in Figure 16. A 
microarray is a slide containing thousands of probes covering the entire human genome. DNA 
from the patient’s sample is isolated and labeled with a fluorescent dye (red in this example). 
DNA from a known genetically normal individual of the same gender is labeled with a 
different fluorescent dye (green). The samples are mixed together and applied to the 
microarray, where they are incubated and allowed to hybridize to the thousands of probes on 
the array. The microarray slide is scanned by a computer with specialized software. Deletions 
and duplications are identified based on the color of every probe in the array. If there is no 
gain or loss of material, the color will appear yellow due to the mixing of the red and green 
probes. A loss of material (deletion) will appear green and a gain of material (duplication) 
will appear red. When a deletion or duplication is identified, it is confirmed by FISH testing.  
Array CGH has many of the advantages of FISH probes, but the whole genome is 
evaluated much as in the karyotype. With this technique, it is not necessary to know exactly 
what you are looking for because all of the probes are already included. There is a major 
limitation of array CGH compared to karyotyping. Array CGH only shows gains and losses of 
genetic material. It will not show balanced rearrangements. Therefore, an individual carrying 
a balanced translocation or inversion will not be detected by array CGH. It is for this reason 
that the karyotype will not be completely supplanted by array CGH. 
 
 
6.2. Polymerase Chain Reaction and Gel Electrophoresis 
 
The polymerase chain reaction (better known as PCR) is perhaps the most significant 
advancement in molecular biology. Developed by Kary Mullis in 1983, PCR has 
revolutionized molecular genetics, being widely used in medicine, forensics, and scientific 
research. PCR is a method of amplifying DNA. This allows one to analyze a particular region 
of DNA when there are very small quantities present. The amplification of DNA is analogous 
to photocopying a page from a large book, as if that page was torn out and photocopied 
millions of times. PCR reactions are generally 30 to 100 µl in volume, but can be as low as 10 
µl. Small quantities of the following are transferred by micropipet into PCR tubes:  
 
1.  DNA template: DNA from the sample to be tested 
2.  Primers: 2 short DNA sequences (~15-25 bases) complementary to the region/gene 
being tested 
3.  dNTPs (deoxynucleotide triphosphates): nucleotide bases A, G, C, T of DNA 
4.  DNA polymerase: enzyme that makes new DNA through addition of bases 
5.  Magnesium ions: works as a cofactor for DNA polymerase 
6. Buffer solution: for stability of DNA polymerase.  
 

Genetics of Hearing Loss 
 
469
The prepared PCR reactions are placed in a thermal cycler. A thermal cycler is a machine 
capable of rapidly changing temperature. This is the key to the PCR process, the bulk of 
which involves repeated cycles of short incubations at three different temperatures. First, the 
samples are heated to a high temperature around 95°C to denature the DNA sample. Once 
denatured, the temperature is quickly lowered to around 60°C, a temperature ideal for 
annealing. Annealing is where the primers bind to their complementary sequence of DNA. 
The temperature is then raised to 72°C for elongation, a temperature at which the polymerase 
enzyme works optimally. The polymerase adds bases from the dNTP mix. The polymerase 
used in PCR is Taq polymerase, obtained from the bacteria Thermus aquaticus. This species 
of bacteria thrives in very hot environments, and thus its polymerase is stable at very high 
temperatures. At the end of each PCR cycle, there are twice as many DNA fragments of the 
desired region. After 30 to 40 cycles of PCR, you are left with millions of copies of this DNA 
fragment, even if you started with just one. Figure 17 shows a simplified schematic diagram 
of this process.  
 
 
Figure 17. Polymerase Chain Reaction (PCR). One cycle of PCR is illustrated here. The DNA sample being 
tested is mixed with nucleotides and primers which will form the building blocks necessary to produce more 
DNA copies of a desired region of DNA. One cycle consists of denaturation, annealing, and elongation. The 
DNA is denatured into two strands by heating at a high temperature. The temperature is lowered to allow the 
primers to anneal to their complementary strands. The temperature is raised back up to the optimal working 
temperature of DNA polymerase, which will add nucleotides to build a new DNA strand. At the end of the 
PCR cycle, you are left with double the amount of DNA from the start of the cycle. A typical PCR run will 
include 30 to 40 cycles, resulting in millions of DNA copies of the desired gene or region. The PCR products 
can then be visualized via gel electrophoresis.  

Danielle Donovan Mercer 
 
470
 
Figure 18. Gel electrophoresis.Agarose gel electrophoresis after PCR for the G216A mutation in the USH1C 
gene. The normal genotype at this site is GG. A substitution of G to A results in Usher syndrome if two 
copies are present (Usher syndrome is autosomal recessive). PCR products are separated by size, with smaller 
fragments moving faster through the gel. Fragment sizes in base pairs (bp) are listed on the left of the picture. 
The far right lane contains a DNA ladder of known fragment sizes. Three patient samples are labeled: GG 
(normal), GA (carrier for Usher syndrome), and AA (Usher syndrome). Gel picture courtesy of the laboratory 
of Dr. Fern Tsien, Louisiana University Health Sciences Center Department of Genetics, used with 
permission.  
The PCR products can be loaded on a gel and run through gel electrophoresis to visualize 
the results. The main types of gels used are agarose and acrylamide. The gels are of a 
somewhat porous material so the DNA can move through the gel. An electric current is run 
through the gel after the samples are loaded. Since DNA has a negative charge, the samples 
are loaded at the negative pole and migrate toward the positive pole once the electric current 
is introduced. The gel acts as a sieve, allowing smaller DNA fragments to migrate through the 
gel at a faster rate than the larger fragments. The end result is a separation of DNA fragments 
based on size. A chemical dye such as ethidium bromide is added to the gel to allow for 
visualization. Ethidium bromide binds to DNA and fluoresces under ultraviolet light. An 
example of an agarose gel electrophoresis following PCR is shown in Figure 18.  
PCR is specific and, if designed properly, can identify single base-pair changes. It is 
relatively cheap to run and has a great deal of versatility. There are many downstream 
applications for PCR which are too complex to describe here. It can be regarded as a 
“zoomed-in” procedure. We are evaluating specifically what we designed our primers for, not 
the entire genome. We will therefore not identify a disorder in a different gene.  
 
 
6.3. DNA Sequencing 
 
DNA sequencing determines the exact base sequence of a strand of DNA. This can be a 
targeted sequencing or a whole genome sequencing. Targeted sequencing tests a specific 
region, usually a particular gene or set of genes. Whole genome sequencing tests the entire 
genome of an individual. The latter is obviously far more complex, time-consuming, and 

Genetics of Hearing Loss 
 
471
expensive. Major methods of DNA sequencing employed today are Sanger sequencing and 
next generation sequencing. Sanger sequencing was one of the original DNA sequencing 
techniques developed, and has largely been replaced by next generation sequencing 
techniques in the last decade. However, Sanger sequencing is still used, mostly for targeted 
sequencing. The process of DNA sequencing will not be discussed here. The interested reader 
is encouraged to explore this topic independently.  
 
6.3.1. Genome Sequencing 
In 1990, the Human Genome Project was launched as an international collaborative effort 
to sequence the entire human genome. It took years to complete, but finished ahead of 
schedule in 2003. Today’s next generation sequencing techniques have managed to drastically 
cut down the testing time. In recent years, whole genome sequencing is gaining widespread 
use in clinical testing. It has become cheaper and faster, and has allowed for a diagnosis in 
patients who previously tested normal by other methods. However, it is still expensive 
relative to other methods, and turnaround time by a clinical laboratory takes several weeks or 
months for testing and analysis of results. Exome sequencing is a frequently-used alternative 
that cuts down on the amount of DNA to analyze. 
 
6.3.2. Exome Sequencing 
Over 98% of the human genome does not code for proteins. When performing clinical 
testing on a patient suspected of a genetic disorder, sequencing analysis can be greatly 
reduced by focusing on these coding regions. Recall from section 2.1 that genes are 
transcribed into mRNA. The initial mRNA is a complement to the DNA gene from which it 
was transcribed. Human genes contain exons and introns. Exons are the sequences 
responsible for coding for the resultant protein, while introns contain regulatory elements and 
non-coding sequences. The evolutionary purpose of introns is unclear. As the introns are 
unnecessary for coding of the protein, they are removed from the mature mRNA molecule.  
 
 
Figure 19. Exons and introns. The DNA sequence of a gene includes exons (coding regions) and introns 
(noncoding regions). Once a DNA sequence is transcribed into mRNA, the introns are removed and the exons 
are joined together during a process known as RNA splicing. Exome sequencing analyzes only the exons. 
Most disease-causing mutations will be found in the exons, and thus exome sequencing is a quicker and more 
cost-effective method for identifying mutations. However, deleterious mutations do occur on occasion in the 
introns if they lead to aberrant splicing. Genomic sequencing analyzes both exons and introns.  
This is illustrated in Figure 19. The exons now can be sequenced without the baggage of the 
introns. This process is exome sequencing. It has the advantage over whole genome 

Danielle Donovan Mercer 
 
472
sequencing of being cheaper and faster while still having the capability of finding most of the 
same mutations. However, while uncommon, deleterious intronic mutations do exist. An 
intronic mutation can affect a regulatory element, which can cause the exons to be spliced in 
an alternative way. This can affect the protein product and cause disease. Exome sequencing 
will not identify all intronic mutations. 
While genome and exome sequencing are not yet mainstream clinical applications for 
testing patients with nonsyndromic hearing loss, they are being used in research settings. This 
is leading to identification of more genes associated with hearing loss. As the cost continues 
to drop these tests may gain traction for diagnosis of genetic hearing loss.  
 
 
7. MAKING A GENETICS REFERRAL 
 
7.1. When Should a Genetics Referral Be Made? 
 
For most patients who may benefit from genetic testing, a referral from a health care 
professional is needed, as few patients or families will seek this out themselves. In cases of 
hearing loss with a genetic etiology, the audiologist is a key player in achieving this 
diagnosis. Of course, any health care professional can recommend a genetics evaluation, and 
this is frequently initiated by primary care physicians and specialty physicians. However, in 
cases of hearing loss, physicians may defer to audiologists to make these calls. On the other 
hand, audiologists frequently defer to physicians to address genetic testing because the 
evaluation is viewed as medical in nature. Unfortunately, this results in many patients being 
missed until other health effects from a syndrome surface or hearing loss recurs in another 
family member. By this time many of the benefits of genetic testing have been lost. If 
audiologists want to be viewed as the authority on hearing loss, we must take a leadership 
role in all aspects of hearing and balance, including genetics of hearing loss. This is 
particularly applicable to pediatric audiologists, whose patients and families have the most to 
gain from a genetics evaluation. Deferring the referral to physicians, many of whom know far 
less about both hearing loss and genetics than audiologists, we are missing an opportunity to 
assert our expertise. This ultimately results in a disservice to our patients. This does not mean 
that every audiologist must be an expert in genetics or have an in-depth understanding of 
genes involved in hearing loss or genetic testing methods. It does mean, however, that every 
audiologist should understand when to make a genetics referral, how to talk to patients and 
families about genetic testing, and what the ramifications are of various test results. (For 
clarification, the use of the term referral in this chapter is roughly equivalent to 
recommendation. It is not used in association with insurance coverage, which varies by plan 
and may require a physician order. Insurance coverage is inconsistent for genetic testing.) 
So when should an audiologist make a referral for a genetics evaluation? Put simply, a 
referral can be made in any case of permanent hearing loss with an unknown etiology if the 
patient or family desires. This will start with a discussion with the patient or the patient’s 
family (in pediatric cases) about the possibility of a genetic etiology. This should be done in a 
sensitive manner, and may begin by asking if they have ever considered genetic testing or a 
genetic etiology. This will help assess whether anyone else has suggested a genetic etiology 
and what the family thinks about it. This can begin the conversation and allow the audiologist 

Genetics of Hearing Loss 
 
473
to discuss possible benefits of receiving a genetics evaluation. It should be noted that genetic 
testing is not for everyone, and it will not benefit everyone. Some patients and families will 
elect to decline a genetics referral for a variety of reasons. This is their choice and that choice 
should be respected. Patients and families should never feel pressured to undergo genetic 
testing or shamed for declining. Our role as audiologists is to ensure patients are made aware 
of the possibility of a genetic etiology and have the opportunity to seek that out should they 
desire. Patients should also be made aware that an evaluation with a geneticist and/or genetic 
counselor does not mean they will or must receive genetic testing. Part of this evaluation 
should include assessment for emotional readiness for genetic testing, which may conclude 
with declination of testing. 
There are several characteristics which, when present, increase the likelihood of a genetic 
etiology, and should therefore be considered when discussing a genetics referral. Perhaps the 
strongest is a family history of hearing loss, particularly a family history of congenital or 
early-onset hearing loss. An increase in the number of relatives and closeness of relationship 
with the patient will each increase the likelihood that the cause is genetic. First-degree 
relatives (children, parents, and siblings) carry the most weight because these relatives share, 
on average, half of their DNA with one another (or all of their DNA, in the case of 
monozygotic twins). Second-degree relatives (aunts, uncles, grandparents) share, on average, 
a quarter of their DNA, and are also significant in the family history. Third-degree relatives 
(such as first cousins) should not be dismissed, especially if there are two or more affected 
family members. Third-degree relatives carry greater weight in families with consanguinity, 
meaning there is a mating between blood relatives. In families with consanguinity there is an 
increased risk of having offspring with an autosomal recessive disorder. This may include 
deafness/hearing loss. While a family history of hearing loss increases the chances of a 
genetic etiology, the absence of a family history does not exclude a genetic cause. Recall that 
over 90% of children born with permanent hearing loss are born to hearing parents, and in 
many cases there is no known family history on either side. Genetics referrals should not be 
dismissed because there is no family history. The Joint Committee on Infant Hearing position 
statement recommends referral for a genetics evaluation for children born with permanent 
hearing loss [115]. 
Another characteristic increasing the likelihood of a genetic etiology is the presence of 
other clinical features. These features may be readily apparent, such as dysmorphologies or 
distinct facial features, or they may be less conspicuous. Hearing loss accompanied by cardiac 
problems, kidney problems, thyroid problems, vision loss, fainting spells, or skin lesions 
should be heavily suspected as being genetic. In addition, hearing loss (especially deafness) 
occurring after administration of a normal dose of aminoglycoside antibiotics may be due to a 
genetic mutation. If common hearing loss-associated infections have been ruled out as the 
cause, odds are increased that the cause is genetic. Finally, unusual audiometric 
configurations (such as “cookie-bite” audiograms or low-frequency sensorineural hearing 
loss) often have a genetic cause, especially if there is a family history. 
Most genetics referrals are made for pediatric patients or cases where a syndrome is 
suspected. These are the patients and families who have the most to gain from genetic testing. 
In cases of adult-onset nonsyndromic hearing loss, a referral may or may not be made. For 
many of these patients the costs may outweigh the benefits. Nonetheless, a discussion could 
be held with the patient, and a referral considered in the presence of a strong family history if 
the patient desires. In the absence of a strong family history in a patient with adult-onset 

Danielle Donovan Mercer 
 
474
hearing loss, genetic testing is unlikely to yield useful information. Genetic testing can be 
laborious, expensive, and emotionally draining, and it is not always fruitful. Benefits, 
impacts, and limitations of genetic testing must all be considered with each patient. This will 
be the responsibility of clinical geneticists and genetic counselors.  
 
 
7.2. Benefits of Genetic Testing 
 
There are several potential benefits of genetic testing for patients with hearing loss. In 
cases of syndromic hearing loss, the diagnosis can direct clinical evaluation and treatment for 
associated disorders. For example, a diagnosis of Jervell and Lange-Nielsen syndrome will 
lead to close monitoring for cardiac issues. Without this diagnosis, the patient would not 
know to seek treatment until experiencing an adverse event. Likewise, a diagnosis of Usher 
syndrome received before the onset of vision loss would allow for the patient to undergo 
ophthalmologic evaluation and the patient’s family to prepare for the future, such as early 
teaching of Braille. Patients have a better opportunity to take care of themselves if they are 
aware of potential health consequences associated with their syndrome.  
Another major benefit of genetic testing is an allowance of estimation of recurrence risks 
for patients and/or their families. For some families this will be very important and may be 
the driving motivation for obtaining genetic testing. For other families, this will not be 
important at all. Discussions on recurrence risks, handled by the genetics team, should be 
addressed sensitively. It should not be assumed that all families will want this information, 
and some may feel offended by the topic. However, there will be families who would like to 
know the odds of having another affected child, and they may or may not use this information 
for family-planning purposes.  
A genetic diagnosis may affect distant members of the patient’s family, should the family 
opt to share this information. Depending on the family, this may be viewed as a benefit, a 
drawback, or of no consequence. If other family members are informed of the diagnosis, this 
may enable them to receive an early diagnosis, thereby optimizing treatment and yielding risk 
estimates for their offspring. However, distant family members may not welcome this 
information, and may even be resentful that it is thrust upon them. On the other hand, some 
families may not want to share their diagnosis with family members, either because they are 
not close to their family, they want to keep their medical information private, or they are 
unsure if the information will be welcome. These different scenarios may cause tension 
amongst family members or feelings of guilt in members of the presenting family. 
In some cases there may be no real benefit other than having a diagnosis. For some 
families it is satisfying to know the reason behind the hearing loss and other features (if 
present) even if it is of no consequence in family-planning or health monitoring. Some 
patients or parents find peace of mind in knowing the cause, which can be a benefit in and of 
itself. The benefits of genetic testing are less clear with adult-onset hearing loss. By 
adulthood, a syndrome likely would have been identified already, and recurrence risks are 
usually not important to individuals who may pass on adult-onset hearing loss. Also, by the 
time someone reaches adulthood there are many other potential causes to consider, lowering 
the chances of identifying a genetic etiology. Nonetheless, there may be patients where 
testing may be pursued. Again, genetic testing for these patients is often futile unless there are 

Genetics of Hearing Loss 
 
475
several family members affected with a similar presentation (i.e., type, onset, progression, and 
configuration of hearing loss).  
 
 
7.3. Impacts of a Positive Genetic Test Result 
 
During the genetics evaluation, the genetic counselor will discuss with the patient and/or 
patient’s family how they may be impacted by the results of the test. This will be taken into 
consideration before genetic testing is performed. A positive test result can have negative 
psychological or social effects for the patient and the patient’s family. Genes make up who 
we are, causing a genetic diagnosis to feel deeply personal for some people. As previously 
discussed, a positive test result can affect other family members who may or may not be 
prepared to receive this information. For parents, feelings of guilt are common. Tension 
between parents may ensue, especially if the mutation in question is found to be inherited 
exclusively from one parent. Parents may be prone to assign blame, even if inadvertently. 
Some have raised ethical concerns with the genetic testing of children, arguing such testing 
violates a child’s right not to know. There is legitimacy to this argument; genetic testing of 
minor children should never be taken lightly. These issues should be explored with the 
genetic counselor when the family is deciding whether or not to pursue genetic testing.  
 
 
7.4. Limitations of Genetic Testing 
 
Just as there are potential ramifications to patients and their families with a positive test 
result, families must also face the possibility of a negative test result. Families may complete 
genetic testing feeling lost and confused if the process does not result in a diagnosis. This 
outcome is far more common than one might expect when considering the prevalence of 
genetic hearing loss, and there are a few reasons why this would happen. The most obvious 
explanation for a negative test result is that the cause of the hearing loss is not genetic. 
However, one cannot conclude this based on a negative genetic test result unless there is 
another viable explanation for the etiology, in which case genetic testing probably would 
never have been initiated. This may be the most common error made by patients and health 
care providers alike regarding genetic test results. On the contrary, a negative result on a 
genetic test does not necessarily mean the cause is not genetic. Rather, one can only conclude 
that a genetic etiology for what the test examined can be ruled out.  
Recall that there are over 400 genes associated with syndromic hearing loss and over 100 
genes associated with nonsyndromic hearing loss. Consider a patient with nonsyndromic 
congenital deafness with an extensive family history presents for genetic testing. Based on 
evaluation of family history of autosomal recessive inheritance and limited insurance 
coverage for genetic testing, a decision is made to sequence the patient’s GJB2 gene, also 
known as connexin 26. Because mutations in connexin 26 cause more cases of nonsyndromic 
hearing loss than any other gene, this approach is reasonable. Testing comes back as negative 
and this is reported to the family. All that can be concluded from this result is that connexin 
26 is not the cause of deafness in this patient (and presumably in this family, although some 
families have been found to have more than one causative gene). We have no information on 
the 100+ other genes which were not tested. If a result is still desired, another gene must be 

Danielle Donovan Mercer 
 
476
selected for testing, and it is not easy deciding which way to go next. To make this example 
even more specific, let us imagine that instead of sequencing connexin 26, a molecular test is 
performed for 35delG, the most common mutation in connexin 26 deafness. The test may be 
ordered this way because it is even more cost-effective than sequencing of the entire gene, but 
it will only detect cases caused by the 35delG mutation. In this example, a negative result 
would not even rule out connexin 26 as the causative gene. Rather, it would only rule out a 
connexin 26 35delG mutation. 
Because testing is expensive and insurance companies will not always cover it, starting 
with the most likely gene to yield a positive result is a common approach. Over the last 
decade gene panels for various disorders, including hearing loss have been developed. 
Hearing loss panels are offered by some testing laboratories, and allow for simultaneous 
molecular testing of many mutations in several different genes, increasing the likelihood of a 
positive result in a single test. Sequencing tests will identify more mutations, but the time and 
costs involved make it prohibitive for many patients, especially in cases of nonsyndromic 
hearing loss. Fortunately, these comprehensive tests have been getting gradually faster and 
cheaper, so they may be more accessible for clinical testing in the future. However, even 
sequencing does not identify the causative gene for all patients. Exome sequencing only 
sequences the coding regions of genes, which is where most mutations occur. But mutations 
in introns can disrupt regulatory elements in genes, affecting gene expression. Sequencing the 
entire genome will include intronic regions, but the large amount of data generated can be 
difficult to interpret. Thus, sequencing can miss the cause because the gene in question has 
not been identified to be associated with the disorder being tested. As testing methods 
improve there will be fewer patients who do not obtain a diagnosis. But in today’s world, a 
negative test result is common for families of hearing loss as well as many genetic disorders.  
 
 
7.5. Testing Recommendations 
 
The testing panel will be determined by the geneticist. Audiologists can aid the process 
by communicating pertinent information about the patient’s audiological evaluation [116]. 
This includes type of hearing loss, severity, age of onset, progression, audiometric 
configuration, family history, and presence of auditory neuropathy or vestibular disturbance. 
These characteristics can give clues on which gene may be involved. If audiograms are 
available from affected family members, these may prove to be helpful as well. In cases of 
nonsyndromic hearing loss, the presenting characteristics may be suggestive of inheritance 
pattern. Nonsyndromic hearing loss with an autosomal recessive inheritance pattern is more 
likely to have a prelingual onset, be stable in degree, and affect most or all frequencies. 
Conversely, nonsyndromic hearing loss with an autosomal dominant inheritance pattern is 
more likely to have a postlingual onset, be progressive, and affect a subset of frequencies. 
These are general characteristics, and vary by gene, mutation, individual, and family. They 
will not always hold true, but should be considered in conjunction with the inheritance pattern 
displayed in the family history. Due to the high incidence of congenital and early-onset 
hearing loss caused by cytomegalovirus (CMV), this infection should be considered when 
reviewing a patient’s medical history. Newborn screening for CMV is being tested in 
hospitals in the United States, and may be incorporated in the future as part of the newborn 
hearing screening program [117]. CMV-related hearing loss presentation can appear similar 

Genetics of Hearing Loss 
 
477
to genetic hearing loss. A positive CMV test will prevent unnecessary genetic testing. 
Unfortunately, CMV testing methods lack sensitivity to reliably detect congenital CMV after 
3 weeks of age [117]. This topic is sure to receive a great deal of attention in the years to 
come.  
If the patient exhibits dysmorphic features along with hearing loss, testing may begin 
with array CGH followed by exome sequencing if the array CGH test is negative. If the 
geneticist suspects a specific syndrome, a molecular test specific for that syndrome may be 
ordered. This may involve a panel if it is a syndrome with multiple causative genes. 
Molecular tests for a specific syndrome are generally more cost-effective than sequencing 
techniques, but if results continue to be negative, exome sequencing may be warranted. A 
diagnosis is invaluable for patients who have significant health problems.  
Once all tests have been exhausted, a negative result can be discouraging for a patient 
who stands to benefit from a genetic diagnosis. For these patients, audiologists may revisit the 
topic every 3 to 5 years and suggest a new genetics evaluation. Testing methods evolve 
quickly. A patient who received a negative result a few years ago may now be eligible for a 
test that either was not available previously or was too expensive. If the patient or the family 
still desires and could benefit from a genetic diagnosis this may be welcomed.  
 
 
CONCLUSION 
 
Audiologists are central figures in the health care teams treating patients with hearing 
loss. Since as many as 75-80% of early-onset permanent hearing losses are genetic and most 
adult-onset permanent hearing losses probably have a genetic component, it is imperative 
audiologists have a basic understanding of genetics if we are to fully serve our patients. 
Audiologists need not be genetics experts, but should understand when a genetics referral 
should be proposed and should be comfortable discussing this topic with their patients. 
Genetic testing has limitations and potential negative consequences which must be 
considered. The benefits of testing should outweigh the risks. If a patient is willing to 
complete a genetics evaluation, the geneticist and/or genetic counselor will determine if 
genetic testing is appropriate. To locate a genetic counselor, visit the National Society of 
Genetic Counselors at https://www.nsgc.org [118].  
Completion of the Human Genome Project has allowed for the identification of thousands 
of genes, including many new genes found to be associated with deafness/hearing loss. As 
technology advances, more patients are able to receive a genetic diagnosis, and the tests 
continue to become faster, cheaper, and more sensitive. While new genes are sure to be linked 
to hearing loss in the future, genetic research is beginning to shift toward bioinformatics. 
Bioinformatics marries biology with computer science. Sophisticated software is used to 
analyze biological data and make predictions about their functions. This means that many 
research studies are moving out of the laboratory and onto the computer. Bioinformatics 
analyses may include predicting whether a gene mutation will cause deleterious protein 
function, predicting how a protein will fold, or examining how two different genes interact 
with one another. These studies will add new layers of complexity to our understanding of 
genes and how they function. In addition, our understanding of adult-onset hearing loss, to 
include presbycusis and noise-induced hearing loss, is bound to expand. Limited studies have 

Danielle Donovan Mercer 
 
478
suggested genetic determinants may influence our susceptibility to noise-induced hearing 
loss. It has been recognized for decades that individuals respond differently to noise exposure. 
Genetic polymorphisms or gene-environment interactions may help explain this phenomenon 
and could lead to noise protection recommendations customized for each individual. 
Likewise, presbycusis (age-related hearing loss), known to vary widely across the population, 
may have more to do with genetic differences than the aging process itself. The decades to 
come are sure to deliver exciting new discoveries in the world of genetic hearing loss. 
 
 
REFERENCES 
 
[1] 
National Institutes of Health. 2010. “Newborn hearing screening fact sheet.” Accessed 
December 
24, 
2018. 
https://report.nih.gov/NIHfactsheets/ViewFactSheet. 
aspx?csid=104. 
[2] 
Shargorodsky, J., Curhan, S.G., Curhan, G.C., and Eavey, R. 2010. “Change in 
prevalence of hearing loss in US adolescents.” JAMA 304(7):772-778. 
[3] 
Rehm, H.L. 2005. “A genetic approach to the child with sensorineural hearing loss.” 
Semin Perinatol 29, 173-181. 
[4] 
Smith, R.J., Bale, Jr., J.F., and White, K.R. 2005. “Sensorineural hearing loss in 
children.” Lancet 365, 879-890. 
[5] 
Shearer, A.E., Hildebrand, M.S., and Smith, R.J.H. 2017. “Hereditary hearing loss and 
deafness overview.” In Gene Reviews, edited by M.P. Adam, H.H. Ardinger, R.A. 
Pagon, Wallace, S.E., Bean, L.J.H., Stephens, K., and Amemiya, A. Seattle, WA: 
University of Washington, Seattle Press. (PMID 20301607).  
[6] 
Cohen, B.E., Durstenfeld, A., and Roehm, P.C. 2013. “Viral causes of hearing loss: a 
review for hearing health professionals.” Trends Hear 18, 1-17. 
[7] 
Ezkurdia, I., Juan, D., Rodriguez, J.M., Frankish, A., Diekhans, M., Harrow, J., 
Vazquez, J., Valencia, A., and Tress, M.L. 2014. “Multiple evidence strands suggest 
that there may be as few as 19,000 human protein-coding genes.” Hum Mol Genet 
23(22):5866-5878. 
[8] 
Toriello, H.V., Reardon, W., and Gorlin, R.J. 2004. Hereditary hearing loss and its 
syndromes. New York: Oxford University Press. 
[9] 
Van Camp, G., and Smith, R. 2018. “Hereditary Hearing Loss Homepage.” Accessed 
November 3, 2018. http://hereditaryhearingloss.org. 
[10] Venter, J.C. et al. 2001. “The sequence of the human genome.” Science 
291(5507):1304-1351. 
[11] Strachan, T., and Read, A.P. 1999. Human molecular genetics. New York: Wiley-Liss. 
[12] Mitchell, R.E., and Karchmer, M.A. 2004. “Chasing the mythical ten percent: parental 
hearing status of deaf and hard of hearing students in the United States.” Sign 
Language Studies 4(2):138-163. 
[13] Robin, N.H., Moran, R.T., and Ala-Kokko, L. 2017. “Stickler syndrome.” In Gene 
Reviews, edited by M.P. Adam, H.H. Ardinger, R.A. Pagon, Wallace, S.E., Bean, 

Genetics of Hearing Loss 
 
479
L.J.H., Stephens, K., and Amemiya, A. Seattle, WA: University of Washington, Seattle 
Press. (PMID 20301479).  
[14] Acke, F.R., Dhooge, I.J., Malfait, F., and De Leenheer, E.M. 2012. “Hearing 
impairment in Stickler syndrome: a systematic review.” Orphanet J Rare Dis 7:84. 
Accessed November 17, 2018. doi:10.1186/1750-1172-7-84. 
[15] Blake, K.D., and Prasad, C. 2006. “CHARGE syndrome.” Orphanet J Rare Dis 1:34. 
[16] Lalani, S.R., Hefner, M.A., Belmont, J.W., and Davenport, S.L.H. 2012. “CHARGE 
syndrome.” In Gene Reviews, edited by M.P. Adam, H.H. Ardinger, R.A. Pagon, 
Wallace, S.E., Bean, L.J.H., Stephens, K., and Amemiya, A. Seattle, WA: University of 
Washington, Seattle Press. (PMID 20301296).  
[17] Bergman, J.E., Janssen, N., Hoefsloot, L.H., Jongmans, M.C., Hofstra, R.M., van 
Ravenswaaij-Arts, C.M. 2011. “CHD7 mutations and CHARGE syndrome: the clinical 
implications of an expanding phenotype.” J Med Genet 48(5):334-342. 
[18] Hale, C.L., Niederriter, A.N., Green, G.E., and Martin, D.M. 2016. “Atypical 
phenotypes associated with pathogenic CHD7 variants and a proposal for broadening 
CHARGE syndrome clinical diagnostic criteria.” Am J Med Genet A 170A(2):344-354. 
[19] Sanlaville, D., Etchevers, H.C., Gonzales, M., Martinovic, J., Clement-Ziza, M., 
Delezoide, A.L., Aubry, M.C., Pelet, A., Chemouny, S., Cruaud, C., Audollent, S., 
Esculpavit, C., Goudefroye, G., Ozilou, C., Fredouille, C., Joye, N., Morichon-
Delvallez, N., Dumez, Y., Weissenbach, J., Munnich, A., Amiel, J., Encha-Razavi, F., 
Lyonnet, S., Vekemans, M., and Attie-Bitach, T. 2006. “Phenotype spectrum of 
CHARGE syndrome in fetuses with CHD7 truncating mutations correlates with 
expression during human development.” J Med Genet 43(3):211-217. 
[20] Zentner, G.E., Layman, W.S., Martin, D.M., and Scacheri, P.C. 2010. “Molecular and 
phenotypic aspects of CHD7 mutation in CHARGE syndrome.” Am J Med Genet A 
152A(3):674-686. 
[21] Boyle, M.I., Jespersgaard, C., Brondum-Nielsen, K., Bisgaard, A.M., and Tumer, Z. 
2015. “Cornelia de Lange syndrome.” Clin Genet 88(1):1-12. 
[22] Deardorff, M.A., Noon, S.E., and Krantz, I.D. 2016. “Cornelia de Lange syndrome.” In 
Gene Reviews, edited by M.P. Adam, H.H. Ardinger, R.A. Pagon, Wallace, S.E., Bean, 
L.J.H., Stephens, K., and Amemiya, A. Seattle, WA: University of Washington, Seattle 
Press. (PMID 20301283).  
[23] Deardorff, M.A., Bando, M., Nakato, R., Watrin, E., Itoh, T., Minamino, M., Saitoh, 
K., Komata, M., Katou, Y., Clark, D., Cole, K.E., De Baere, E., De Croos, C., Di 
Donato, N., Ernst, S., Francey, L.J., Gyftodimou, Y., Hirashima, K., Hullings, M., 
Ishikawa, Y., Jaulin, C., Kaur, M., Kiyono, T., Lombardi, P.M., Magnaghi-Jaulin, L., 
Mortier, G.R., Nozaki, N., Petersen, M.B., Seimiya, H., Siu, V.M., Suzuki, Y., 
Takagaki, K., Wilde, J.J., Willems, P.J., Prigent, C., Gillesen-Kaesbach, G., 
Christianson, D.W., Kaiser, F.J., Jackson, L.G., Hirota, T., Krantz, I.D., and Shirahige, 
K. 2012. “HDAC8 mutations in Cornelia de Lange syndrome affect the cohesin 
acetylation cycle.” Nature 489(7415):313- 317. 

Danielle Donovan Mercer 
 
480
[24] Deardorff, M.A., Wilde, J.J., Albrecht, M., Dickinson, E., Tennstedt, S., Braunholz, D., 
Monnich, M., Yan, Y., Xu, W., Gil-Rodriguez, M.C., Clark, D., Hakonarson, H., 
Halbach, S., Michelis, L.D., Rampuria, A., Rossier, E., Spranger, S., Van Maldergem, 
L., Lynch, S.A., Gillesen-Kaesbach, G., Ludecke, H.J., Ramsay, R.G., McKay, M.J., 
Krantz, I.D., Xu, H., Horsfield, J.A., and Kaiser, F.J. 2012. “RAD21 mutations cause a 
human cohesinopathy.” Am J Hum Genet 90(6):1014-1027. 
[25] Krantz, I.D., McCallum, J., DeScipio, C., Kaur, M., Gillis, L.A., Yaeger, D., Jukofsky, 
L., Wasserman, N., Bottani, A., Morris, C.A., Nowaczyk, M.J., Toriello, H., Bamshad, 
M.J., Carey, J.C., Rappaport, E., Kawauchi, S., Lander, A.D., Calof, A.L., Li, H.H., 
Devoto, M., and Jackson, L.G. 2004. “Cornelia de Lange syndrome is caused by 
mutations in NIPBL, the human homolog of Drosophila melanogaster Nipped-B.” Nat 
Genet 36(6):631-635. 
[26] Tonkin, E.T., Wang, T.J., Lisgo, S., Bamshad, M.J., and Strachan, T. 2004. “NIPBL, 
encoding a homolog of fungal Scc2-type sister chromatid cohesion proteins and fly 
Nipped-B, is mutated in Cornelia de Lange syndrome.” Nat Genet 36(6):636-641. 
[27] Asthagiri, A.R., Parry, D.M., Butman, J.A., Kim, H.J., Tsilou, E.T., Zhuang, Z., and 
Lonser, R.R. 2009. “Neurofibromatosis type 2.” Lancet 373(9679):1974-1986. 
[28] Evans, D.G. 2018. “Neurofibromatosis 2.” In Gene Reviews, edited by M.P. Adam, 
H.H. Ardinger, R.A. Pagon, Wallace, S.E., Bean, L.J.H., Stephens, K., and Amemiya, 
A. Seattle, WA: University of Washington, Seattle Press. (PMID 20301380).  
[29] Shannon, R.V. 2011. “Auditory brainstem implants.” The ASHA Leader.  
Accessed 
December 
28, 
2018. 
https://leader.pubs.asha.org/doi/10.1044/ 
leader.FTR3sb3.16032011.17 
[30] Evans, D.G. 2009. “Neurofibromatosis type 2 (NF2): a clinical and molecular review.” 
Orphanet J Rare Dis 4:16. Accessed November 18, 2018. doi:10.1186/1750-1172-4-
16. 
[31] Kochhar, A., Fischer, S.M., Kimberling, W.J., and Smith, R.J. 2007. “Branchio-oto-
renal syndrome.” Am J Med Genet A 143A(14):1671-1678. 
[32] Smith, R.J.H. 2018. “Branchiootorenal spectrum disorder.” In Gene Reviews, edited by 
M.P. Adam, H.H. Ardinger, R.A. Pagon, Wallace, S.E., Bean, L.J.H., Stephens, K., and 
Amemiya, A. Seattle, WA: University of Washington, Seattle Press. (PMID 
20301554).  
[33] Fraser, F.C., Sproule, J.R., and Halal, F. 1980. “Frequency of the branchio-oto-renal 
(BOR) syndrome in children with profound hearing loss.” Am J Med Genet 7:341-349. 
[34] Chang, E.H., Menezes, M., Meyer, N.C., Cucci, R.A., Vervoort, V.S., Schwartz, C.E., 
and Smith, R.J. 2004. “Branchio-oto-renal syndrome: the mutation spectrum in EYA1 
and its phenotypic consequences.” Hum Mutat 23(6):582-589. 
[35] Hoskins, B.E., Cramer, C.H., Silvius, D., Zou, D., Raymond, R.M., Orten, D.J., 
Kimberling, W.J., Smith, R.J., Weil, D., Petit, C., Otto, E.A., Xu, P.X., and 
Hildebrandt, F. 2007. “Transcription factor SIX5 is mutated in patients with branchio-
oto-renal syndrome.” Am J Hum Genet 80(4):800-804. 

Genetics of Hearing Loss 
 
481
[36] Orten, D.J., Fischer, S.M., Sorensen, J.L., Radhakrishna, U., Cremers, C.W., Marres, 
H.A., Van Camp, G., Welch, K.O., Smith, R.J., and Kimberling, W.J. 2008. “Branchio-
oto-renal syndrome (BOR): novel mutations in the EYA1 gene, and a review of the 
mutational genetics of BOR.” Hum Mutat 29(4):537- 544. 
[37] Genetics Home Reference. 2018. “Branchiootorenal/branchiootic syndrome.” Accessed 
November 10, 2018. https://ghr.nlm.nih.gov/condition/branchiootorenal-branchiootic-
syndrome#inheritance. 
[38] de Sousa Andrade, S.M., Monteiro, A.R., Martins, J.H., Alves, M.C., Santos Silva, 
L.F., Quadros, J.M., and Ribeiro, C.A. 2012. “Cochlear implant rehabilitation 
outcomes in Waardenburg síndrome children.” Int J Pediatr Otorhinolaryngol 76, 
1375-1378. 
[39] Read, A.P., and Newton, V.E. 1997. “Waardenburg syndrome.” J Med Genet 34, 656-
665. 
[40] Newton, V. 1990. “Hearing loss and Waardenburg syndrome: implications for genetic 
counseling.” J Laryngol Otol 104, 97-103. 
[41] Pardono, E., van Bever, Y., van den Ende, J., Havrenne, P.C., Iughetti, P., Maestrelli, 
S.R., Costa, F.O., Richieri-Costa, A., Frota-Pessoa, O., and Otto, P.A. 2003. 
“Waardenburg syndrome: clinical differentiation between types I and II.” Am J Med 
Genet A 117A(3):223-235. 
[42] Pingault, V., Ente, D., Dastot-Le Moal, F., Goossens, M., Marlin, S., and Bondurand, 
N. 2010. “Review and update of mutations causing Waardenburg syndrome.” Hum 
Mutat 31(4):391-406. 
[43] National Center for Biotechnology Information. 2018. “OMIM- Online Mendelian 
Inheritance in Man.” Johns Hopkins University. Accessed December 23, 2018. 
https://www.omim.org/  
[44] Marszalek, B., Wojcicki, P., Kobus, K., and Trzeciak, W.H. 2002. “Clinical features, 
treatment and genetic background of Treacher Collins syndrome.” J Appl Genet 
43(2):223-233. 
[45] Posnick, J.C., and Ruiz, R.L. 2000. “Treacher Collins syndrome: current evaluation, 
treatment, and future directions.” Cleft Palate Craniofac J 37(5):434. 
[46] Katsanis, S.H., and Jabs, E.W. 2018. “Treacher Collins syndrome.” In Gene Reviews, 
edited by M.P. Adam, H.H. Ardinger, R.A. Pagon, Wallace, S.E., Bean, L.J.H., 
Stephens, K., and Amemiya, A. Seattle, WA: University of Washington, Seattle Press. 
(PMID 20301704).  
[47] Sakai, D., and Trainor, P.A. 2009. “Treacher Collins syndrome: unmasking the role of 
Tcof1/treacle.” Int J Biochem Cell Biol 41(6):1229-1232. 
[48] Dixon, J., and Dixon, M.J. 2004. “Genetic background has a major effect on the 
penetrance and severity of craniofacial defects in mice heterozygous for the gene 
encoding the nuclear protein Treacle.” Dev Dyn 229, 907-914. 
[49] Carinci, F., Pezzetti, F., Locci, P., Becchetti, E., Carls, F., Avantaggiato, A., Becchetti, 
A., Carinci, P., Baroni, T., and Bodo, M. 2005. “Apert and Crouzon syndromes: 
clinical findings, genes and extracellular matrix.” J Craniofac Surg 16(3):361-368. 

Danielle Donovan Mercer 
 
482
[50] Robin, N.H., Falk, M.J., and Haldeman-Englert, C.R. 2011. “FGFR-related 
craniosynostosis syndromes.” In Gene Reviews, edited by M.P. Adam, H.H. Ardinger, 
R.A. Pagon, Wallace, S.E., Bean, L.J.H., Stephens, K., and Amemiya, A. Seattle, WA: 
University of Washington, Seattle Press. (PMID 20301628).  
[51] Gale Encyclopedia of Genetic Disorders. 2002. “Crouzon syndrome.” Accessed 
December 24, 2018. https://www.encyclopedia.com/science/encyclopedias-almanacs-
transcripts-and-maps/crouzon-syndrome 
[52] Ibrahimi, O.A., Chiu, E.S., McCarthy, J.G., and Mohammadi, M. 2005. 
“Understanding the molecular basis of Apert syndrome.” Plast Reconstr Surg 
115(1):264-270. 
[53] Azaiez, H., Yang, T., Prasad, S., Sorensen, J.L., Nishimura, C.J., Kimberling, W.J., and 
Smith, R.J. 2007. “Genotype-phenotype correlations for SLC26A4- related deafness.” 
Hum Genet 122, 451-457. 
[54] Fraser, G.R. 1965. “Association of congenital deafness with goiter (Pendred’s 
syndrome). A study of 207 families.” Ann Hum Genet 28, 201-249. 
[55] Illum, P., Kiaer, H.W., Hvidberg-Hansen, J., and Sondergaard, G. 1972. “Fifteen cases 
of Pendred’s syndrome. Congenital deafness and sporadic goiter.” Arch Otolaryngol 
96, 297-304. 
[56] Bizhanova, A., and Kopp, P. 2010. “Genetics and phenomics of Pendred syndrome.” 
Mol Cell Endocrinol 322(1-2):83-90. 
[57] Albert, S., Blons, H., Jonard, L., Feldman, D., Chauvin, P., Loundon, N., Sergent-
Allaoui, A., Houang, M., Joannard, A., Schmerber, S., Delobel, B., Leman, J., Journel, 
H., Catros, H., Dollfus, H., Eliot, M.M., David, A., Calais, C., Drouin-Garraud, V., 
Obstoy, M.F., Tran Ba Huy, P., Lacombe, D., Duriez, F., Francannet, C., Bitoun, P., 
Petit, C., Garabedian, E.N., Couderc, R., Marlin, S., and Denoyelle, F. 2006. 
“SLC26A4 gene is frequently involved in nonsyndromic hearing impairment with 
enlarged vestibular aqueduct in Caucasian populations.” Eur J Hum Genet 14, 773-779. 
[58] Park, H.J., Shaukat, S., Liu, X.Z., Hahn, S.H., v, S., Ghosh, M., Kim, H.N., Moon, 
S.K., Abe, S., Tukamoto, K., Riazuddin, S., Kabra, M., Erdenetungalag, R., 
Radnaabazar, J., Khan, S., Pandya, A., Usami, S.I., Nance, W.E., Wilcox, E.R., and 
Griffith, A.J. 2003. “Origins and frequencies of SLC26A4 (PDS) mutations in east and 
south Asians: global implications for the epidemiology of deafness.” J Med Genet 40, 
242-248. 
[59] Lentz, J., and Keats, B.J.B. 2016. “Usher syndrome type I.” In Gene Reviews, edited by 
M.P. Adam, H.H. Ardinger, R.A. Pagon, Wallace, S.E., Bean, L.J.H., Stephens, K., and 
Amemiya, A. Seattle, WA: University of Washington, Seattle Press. (PMID 
20301442).  
[60] Umrigar, A., Musso, A., Mercer, D., Hurley, A., Glausier, C., Bakeer, M., Marble, M., 
Hicks, C., and Tsien, F. 2017. “Delayed diagnosis of a patient with Usher syndrome 1C 
in a Louisiana Acadian family highlights the necessity of timely genetic testing for the 
diagnosis and management of congenital hearing loss.” SAGE Open Med Case Rep 
5:2050313X17745904. 

Genetics of Hearing Loss 
 
483
[61] Gorlin, R.J. 1995. “Genetic hearing loss associated with eye disorders.” In Hereditary 
Hearing Loss and its Syndromes, edited by R.J. Gorlin, H.V. Toriello, and M.M. 
Cohen. New York: Oxford University Press. 
[62] Vernon, M. 1969. “Usher’s syndrome- deafness and progressive blindness. Clinical 
cases, prevention, theory, and literature survey.” J Chronic Dis 22:133-151. 
[63] Yan, D., and Liu, X.Z. 2010. “Genetics and pathological mechanisms of Usher 
syndrome.” J Hum Genet 55:327-335. 
[64] Wahl, R.A., and Dick II, M. 1980. “Congenital deafness with cardiac arrhythmias: the 
Jervell and Lange-Nielsen syndrome.” Am Ann Deaf 125, 34- 37. 
[65] Kang, S.L., Jackson, C., and Kelsall, W. 2011. “Electrocardiogram screening of deaf 
children for long QT syndrome: are we following UK national guidelines?” J Laryngol 
Otol 125, 354-356. 
[66] Tranebjaerg, L., Samson, R.A., and Green, G.E. 2017. “Jervell and Lange- Nielsen 
syndrome.” In Gene Reviews, edited by M.P. Adam, H.H. Ardinger, R.A. Pagon, 
Wallace, S.E., Bean, L.J.H., Stephens, K., and Amemiya, A. Seattle, WA: University of 
Washington, Seattle Press. (PMID 20301579).  
[67] Kruegel, J., Rubel, D., and Gross, O. 2013. “Alport syndrome- insights from basic and 
clinical research.” Nat Rev Nephrol 10, 170-178. 
[68] Pajari, H., Kaariainen, H., Muhonen, T., and Koskimies, O. 1996. “Alport’s syndrome 
in 78 patients: epidemiological and clinical study.” Acta Paediatr 85, 1300-1306. 
[69] Alport Syndrome Foundation. 2017. “What is Alport Syndrome?” Accessed November 
11, 2018. https://alportsyndrome.org/what-is-alport-syndrome/ 
[70] Kashtan, C.E. 2004. “Familial hematurias: what we know and what we don’t.” Pediatr 
Nephrol 20(8):1027-1035. 
[71] Slajpah, M., Gorinsek, B., Berginc, G., Vizjak, A., Ferluga, D., Hvala, A., Meglic A., 
Jaksa, I., Furlan, P., Gregoric, A., Kaplan-Pavlovcic, S., Ravnik-Glavac, M., and 
Glavac, D. 2007. “Sixteen novel mutations identified in COL4A3, COL4A4, and 
COL4A5 genes in Slovenian families with Alport syndrome and benign familial 
hematuria.” Kidney Int 71(12):1287-1295. 
[72] Hertz, J.M., Thomassen, M., Storey, H., and Flinter, F. 2012. “Clinical utility gene card 
for: Alport syndrome.” Eur J Hum Genet 20. 
[73] Sproule, D.M., and Kaufmann, P. 2009. “Mitochondrial encephalopathy, lactic 
acidosis, and stroke-like episodes: basic concepts, clinical phenotype, and therapeutic 
management of MELAS syndrome.” Ann N Y Acad Sci 1142:133-158. 
[74] DiMauro, S. and Hirano, M. 2015. “MERRF.” In Gene Reviews, edited by M.P. Adam, 
H.H. Ardinger, R.A. Pagon, Wallace, S.E., Bean, L.J.H., Stephens, K., and Amemiya, 
A. Seattle, WA: University of Washington, Seattle Press. (PMID 20301693).  
[75] Sherman, S.L., Allen, E.G., Bean, L.H., and Freeman, S.B. 2007. “Epidemiology of 
Down syndrome.” Ment Retard Dev Disabil Res Rev 13(3):221-227. 
[76] National Center for Biotechnology Information. 2018. “Ensembl- Chromosome 21.” 
Accessed 
December 
25, 
2018. 
http://useast.ensembl.org/Homo_sapiens/ 
Location/Chromosome?chr=21;r=21:1-46709983 

Danielle Donovan Mercer 
 
484
[77] Bull, M.J., and the Committee on Genetics. 2011. “Health supervision for children with 
Down syndrome.” Pediatrics 128:393-406. 
[78] Nightengale, E., Yoon, P., Wolter-Warmerdam, K., Daniels, D., and Hickey, F. 2017. 
“Understanding hearing and hearing loss in children with Down syndrome.” Am J 
Audiol 26(3):301-308. 
[79] Hilgert, N., Smith, R.J.H., and Van Camp, G. 2009. “Forty-six genes causing 
nonsyndromic hearing impairment: which ones should be analyzed in DNA 
diagnostics?” Mutat Res 681, 189-196. 
[80] Kenneson, A., Van Naarden Braun, K., and Boyle, C. 2002. “GJB2 (connexin 26) 
variants and nonsyndromic sensorineural hearing loss: a HuGE review.” Genet Med 4, 
258-274. 
[81] Rabionet, R., Gasparini, P., and Estivill, X. 2000. “Molecular genetics of hearing 
impairment due to mutations in gap junction genes encoding beta connexins.” Hum 
Mutat 16(3):190-202. 
[82] Angeli, S., Lin, X., and Liu, X.Z. 2012. “Genetics of hearing and deafness.” Anat Rec 
295, 1812-1829. 
[83] Snoeckx, R.L., Huygen, P.L., Feldmann, D., Marlin, S., Denoyelle, F., Waligora, J., 
Mueller-Malesinska, M., Pollak, A., Ploski, R., Murgia, A., Orzan, E., Castorina, P., 
Ambrosetti, U., Nowakowska-Szyrwinska, E., Bal, J., Wiszniewski, W., Janecke, A.R., 
Nekahm-Heis, D., Seeman, P., Bendova, O., Kenna, M.A., Frangulov, A., Rehm, H.L., 
Tekin, M., Incesulu, A., Dahl, H.H., du Sart, D., Jenkins, L., Lucas, D., Bitner-
Glindzicz, M., Avraham, K.B., Brownstein, Z., del Castillo, I., Moreno, F., Blin, N., 
Pfister, M., Sziklai, I., Toth, T., Kelley, P.M., Cohn, E.S., Van Maldergem, L., Hilbert, 
P., Roux, A.F., Mondain, M., Hoefsloot, L.H., Cremers, C.W., Lopponen, T., 
Lopponen, H., Parving, A., Gronskov, K., Schrivjer, I., Roberson, J., Gualandi, F., 
Martini, A., Lina-Granade, G., Pallares-Ruiz, N., Correia, C., Fialho, G., Cryns, K., 
Hilgert, N., Van de Heyning, P., Nishimura, C.J., Smith, R.J., and Van Camp, G. 2005. 
“GJB2 mutations and degree of hearing loss: a multicenter study.” Am J Hum Genet 
77, 945-957.  
[84] Mahdieh, N., and Rabbani, B. 2009. “Statistical study of 35delG mutation of GJB2 
gene: a meta-analysis of carrier frequency.” Int J Audiol 48, 363-370. 
[85] Denoyelle, F., Martin, S., Weil, D., Moatti, L., Chauvin, P., Garabedian, E.N., and 
Petit, C. 1999. “Clinical features of the prevalent form of childhood deafness, DFNB1, 
due to a connexin-26 gene defect: implications for genetic counselling.” Lancet 353, 
1298-1303. 
[86] Rehman, A.U., Bird, J.E., Faridi, R., Shahzad, M., Shah, S., Lee, K., Khan, S.N., 
Imtiaz, A., Ahmed, Z.M., Riazuddin, S., Santos-Cortez, R.L.P., Ahmad, W., Leal, 
S.M., Riazuddin, S., and Friedman, T.B. 2016. “Mutational spectrum of MYO15A and 
the molecular mechanisms of DFNB3 human deafness.” Hum Mutat 37(10), 991-1003. 
[87] Miyagawa, M., Nishio, S.Y., Hattori, M., Moteki, H., Kobayashi, Y., Sato, H., 
Watanabe, T., Naito, Y., Oshikawa, C., and Usami, S. 2015. “Mutations in the 
MYO15A gene are a significant cause of nonsyndromic hearing loss: massively 

Genetics of Hearing Loss 
 
485
parallel DNA sequencing-based analysis.” Ann Otol Rhinol Laryngol 124 Suppl 
1:158S-168S. 
[88] Nal, N., Ahmed, Z.M., Erkal, E., Alper, O.M., Luleci, G., Dinc, O., Waryah, A.M., 
Ain, Q., Tasneem, S., Husnain, T., Chattaraj, P., Riazuddin, S., Boger, E., Ghosh, M., 
Kabra, M., Riazuddin, S., Morell, R.J., and Friedman, T.B. 2007. “Mutational spectrum 
of MYO15A: the large N-terminal extension of myosin XVA is required for hearing.” 
Hum Mutat 28(10):1014-1019. 
[89] Varga, R., Avenarius, M.R., Kelley, P.M., Keats, B.J., Berlin, C.I., Hood, L.J., Morlet, 
T.G., Brashears, S.M., Starr, A., Cohn, E.S., Smith, R.J.H., and Kimberling, W.J. 2006. 
“OTOF mutations revealed by genetic analysis of hearing loss families including a 
potential temperature sensitive auditory neuropathy allele.” J Med Genet 43(7):576-
581. 
[90] Siemens, J., Kazmierczak, P., Reynolds, A., Sticker, M., Littlewood-Evans, A., and 
Muller, U. 2002. “The Usher syndrome proteins cadherin 23 and harmonin form a 
complex by means of PDZ-domain interactions.” PNAS 99(23):14946-14951. 
[91] Kazmierczak, P., Sakaguchi, H., Tokita, J., Wilson-Kubalek, E.M., Milligan, R.A., 
Muller, U., and Kachar, B. 2007. “Cadherin 23 and protocadherin 15 interact to form 
tip-link filaments in sensory hair cells.” Nature 449:87-91. 
[92] Schultz, J.M., Yang, Y., Caride, A.J., Filoteo, A.G., Penheiter, A.R., Lagziel, A., 
Morell, R.J., Mohiddin, S.A., Fananapazir, L., Madeo, A.C., Penniston, J.T., and 
Griffith, A.J. 2005. “Modification of human hearing loss by plasma- membrane 
calcium pump PMCA2.” New Eng J Med 352:1557-1564. 
[93] Kitajiri, S.I., McNamara, R., Makishima, T., Husnain, T., Zafar, A.U., Kittles, R.A., 
Ahmed, Z.M., Friedman, T.B., Riazuddin, S., and Griffith, A.J. 2007. “Identities, 
frequencies, and origins of TMC1 mutations causing DFNB7/B11 deafness in 
Pakistan.” Clin Genet 72:546-550. 
[94] Kurima, K., Peters, L.M., Yang, Y., Riazuddin, S., Ahmed, Z.M., Naz, S., Arnaud, D., 
Drury, S., Mo, J., Makishima, T., Ghosh, M., Menon, P.S., Deshmukh, D., Oddoux, C., 
Ostrer, H., Khan, S., Riazuddin, S., Deininger, P.L., Hampton, L.L., Sullivan, S.L., 
Battey, J.F., Jr., Keats, B.J., Wilcox, E.R., Friedman, T.B., and Griffith, A.J. 2002. 
“Dominant and recessive deafness caused by mutations of a novel gene, TMC1, 
required for cochlear hair-cell function.” Nat Genet 30:277-284. 
[95] Makishima, T., Kurima, K., Brewer, C.C., and Griffith, A.J. 2004. “Early onset and 
rapid progression of dominant nonsyndromic DFNA36 hearing loss.” Otol Neurotol 
25:714-719.  
[96] Lee, Y.J., Park, D., Kim, S.Y., and Park, W.J. 2003. “Pathogenic mutations but not 
polymorphisms in congenital and childhood onset autosomal recessive deafness disrupt 
the proteolytic activity of TMPRSS3.” J Med Genet 40(8):629-631. 
[97] Weegerink, N.J., Schraders, M., Oostrik, J., Huygen, P.L., Strom, T.M., Granneman, 
S., Pennings, R.J., Venselaar, H., Hoefsloot, L.H., Elting, M., Cremers, C.W., 
Admiraal, R.J., Kremer, H., and Kunst, H.P. 2011. “Genotype-phenotype correlation in 

Danielle Donovan Mercer 
 
486
DFNB8/10 families with TMPRSS3 mutations.” J Assoc Res Otolaryngol 12(6):753-
766. 
[98] Plantinga, R.F., de Brouwer, A.P., Huygen, P.L., Kunst, H.P., Kremer, H., and 
Cremers, C.W. 2006. “A novel TECTA mutation in a Dutch DFNA8/12 family 
confirms genotype-phenotype correlation.” J Assoc Res Otolaryngol 7(2):173-181. 
[99] Hughes, D.C., Legan, P.K., Steel, K.P., and Richardson, G.P. 1998. “Mapping of the 
alpha-tectorin gene (TECTA) to mouse chromosome 9 and human chromosome 11: a 
candidate for human autosomal dominant nonsyndromic deafness.” Genomics 
48(1):46-51. 
[100] Minami, S.B., Masuda, S., Usui, S., Mutai, H., and Matsunaga, T. 2012. “Comorbidity 
of GJB2 and WFS1 mutations in one family.” Gene 501(2): 193-197. 
[101] Urano, F. 2016. “Wolfram syndrome: diagnosis, management, and treatment.” Curr 
Diab Rep 16(1):6. 
[102] Coucke, P., Van Camp, G., Djoyodiharjo, B., Smith, S.D., Frants, R.R., Padberg, G.W., 
Darby, J.K., Huizing, E.H., Cremers, C., Kimberling, W.J., Oostra, B.A., Van de 
Heyning, P.H., and Willems, P.J. 1994. “Linkage of autosomal dominant hearing loss 
to the short arm of chromosome 1 in two families.” N Engl J Med 331:425-431. 
[103] Van Camp, G., Coucke, P.J., Kunst, H., Schatteman, I., Van Velzen, D., Marres, H., 
van Ewijk, M., Declau, F., Van Hauwe, P., Meyers, J., Kenyon, J., Smith, S.D., Smith, 
R.J.H., Djelantik, B., Cremers, C.W.R.J., Van de Heyning, P.H., and Willems, P.J. 
1997. “Linkage analysis of progressive hearing loss in five extended families maps the 
DFNA2 gene to a 1.25-Mb region on chromosome 1p.” Genomics 41(1):70-74. 
[104] Marres, H., van Ewijk, M., Huygen, P., Kunst, H., Van Camp, G., Coucke, P., Willems, 
P., and Cremers, C. 1997. “Inherited nonsyndromic hearing loss: an audiovestibular 
study in a large family with autosomal dominant progressive hearing loss related to 
DFNA2.” Arch Otolaryngol Head Neck Surg 123:573-577. 
[105] Jones, S.M., Robertson, N.G., Given, S., Giersch, A.B.S., Liberman, M.C., and 
Morton, C.C. 2011. “Hearing and vestibular deficits in the Coch(-/-) null mouse model: 
comparison to the Coch(G88E/G88E) mouse and to DFNA9 hearing and balance 
disorder.” Hear Res 272(1-2):42-48. 
[106] Fransen, E., Verstreken, M., Verhagen, W.I., Wuyts, F.L., Huygen, P.L., D’Haese, P., 
Robertson, N.G., Morton, C.C., McGuirt, W.T., Smith, R.J., Declau, F., Van de 
Heyning, P.H., and Van Camp, G. 1999. “High prevalence of symptoms of Meniere’s 
disease in three families with a mutation in the COCH gene.” Hum Mol Genet 
8(8):1425-1429. 
[107] Iossa, S., Marciano, E., and Franze A. 2011. “GJB2 gene mutations in syndromic skin 
diseases with sensorineural hearing loss.” Curr Genomics 12, 475-485. 
[108] Bademci, G., Lasisi, A.O., Yariz, K.O., Montenegro, P., Menendez, I., Vinueza, R., 
Paredes, R., Moreta, G., Subasioglu, A., Blanton, S., Fitoz, S., Incesulu, A., 
Sennaroglu, L., and Tekin, M. 2015. “Novel domain-specific POU3F4 mutations are 
associated with X-linked deafness: examples from different populations.” BMC Med 

Genetics of Hearing Loss 
 
487
Genet 
16:9. 
Accessed 
December 
23, 
2018. 
doi:10.1186/s12881-015- 
0149-2.  
[109] de Melo, C.E.F.S., Ferreira, T.C., Higino, T.C.M., Maia, M.S., and Boccalini, M.C.C. 
2010. “Gusher in stapedotomy- a case report.” Int Arch Otolaryngol 14(2). Accessed 
November 23, 2018. doi:10.7162/S1809- 48722010000200015. 
[110] Li, Z., Li, R., Chen, J., Liao, Z., Zhu, Y., Qian, Y., Xiong, S., Heman-Ackah, S., Wu, 
J., Choo, D.I., and Guan, M.X. 2005. “Mutational analysis of the mitochondrial 12S 
rRNA gene in Chinese pediatric subjects with amino- glycoside-induced and non-
syndromic hearing loss.” Hum Genet 117(1): 9-15.  
[111] Bindu, L.H., and Reddy, P.P. 2008. “Genetics of aminoglycoside-induced and 
prelingual non-syndromic mitochondrial hearing impairment: a review.” Int J Audiol 
47(11):702-707. 
[112] Qian, Y., and Guan, M.X. 2009. “Interaction of aminoglycosides with human 
mitochondrial 12S rRNA carrying the deafness-associated mutation.” Antimicrob 
Agents Chemother 53(11):4612-4618. 
[113] Prezant, T.R., Agapian, J.V., Bohlman, M.C., Bu. X., Oztas, S., Qiu, W.Q., Arnos, 
K.S., Cortopassi, G.A., Jaber, L., and Rotter, J.I. 1993. “Mito- chondrial ribosomal 
RNA mutation associated with both antibiotic-induced and non-syndromic deafness.” 
Nat Genet 4(3):289-294. 
[114] Howe, B., Umrigar, A., and Tsien, F. 2014. “Chromosome preparation from cultured 
cells.” J Vis Exp 83:e50203. Accessed December 22, 2018. doi: 10.3791/50203. 
[115] Joint Committee on Infant Hearing. 2007. “Year 2007 position statement: principles 
and guidelines for early hearing detection and intervention programs.” Pediatrics 
120(4):898-921. 
[116] Mercer, D. 2015. “Guidelines for audiologists on the benefits and limitations of genetic 
testing.” Am J Audiol 24(4):451-461. 
[117] Fowler, K.B., McCollister, F.P., Sabo, D.L., Shoup, A.G., Owen, K.E., Woodruff, J.L., 
Cox, E., Mohamed, L.S., Choo, D.I., and Boppana, S.B. 2017. “A targeted approach 
for congenital cytomegalovirus screening within newborn hearing screening.” 
Pediatrics 
139(2). 
Accessed 
December 
24, 
2018. 
doi:10.1542/ 
peds.2016-2128. 
[118] National Society of Genetic Counselors. 2018. Accessed December 26, 2018. 
https://www.nsgc.org. 


In: Encyclopedia of Audiology and Hearing Research 
ISBN: 978-1-53617-702-2 
Editors: Erno Larivaara and Senja Korhola 
© 2020 Nova Science Publishers, Inc. 
 
 
 
 
 
 
 
Chapter 32 
 
 
 
AUDIOLOGICAL AND SURGICAL OUTCOME AFTER 
COCHLEAR IMPLANT REVISION SURGERY 
 
 
Mohamed Salah Elgandy1,2,*, Marlan R. Hansen2,3  
and Richard S. Tyler2,4 
1Department of Otolaryngology-Head and Neck Surgery, Zagazig University, Egypt  
2Departments of Otolaryngology-Head and Neck Surgery,  
University of Iowa, Iowa City, IA, US  
3Neurosurgery, and Communication Sciences and Disorders  
4University of Iowa, Iowa City, IA, US 
 
 
ABSTRACT 
 
Cochlear implantation is now widely accepted as a safe and effective treatment 
for children and adults with profound deafness. As with all electronic devices, a 
cochlear implant (CI) is susceptible to breakdown or failure. Although the CI 
reliability rate is now very high, the continually increasing population of implant 
recipients will result in the continued need for revision surgeries. The first report of a CI 
revision surgery occurred in 1985, by Hochmair-Desoyer and Burian. Since then, several 
reports have addressed the safety of this procedure, including the preservation or increase 
of speech per ception performance, although there have also been reports of decreases in 
electrode activation, decreased speech per ception and intra cochlear trauma, suggesting 
that cochlear reimplantation may have negative functional consequences in some 
patients, requiring careful consideration of the expected indications and benefits. This 
paper will review causes of revision surgery, how to diagnose cases of failed CI and will 
discuss surgical and audiological outcome of revision CI surgeries, Speech recognition 
ability with a replacement CI may significantly increase or decrease from that with the 
original implant. Experienced CI patients facing reimplantation must be counseled 
regarding the possibility of differences in sound quality and speech recognition 
performance with their replacement device. 
 
                                                        
* Corresponding Author’s Email: drmoh-ent@yahoo.com. 

Mohamed Salah Elgandy, Marlan R. Hansen and Richard S. Tyler 
 
490
Keywords: cochlear implant failure, revision surgery, surgical outcome, auditory 
performance 
 
 
INTRODUCTION 
 
Cochlear implant (CI) surgery began over 30 years ago. During the subsequent decades, 
auditory performance has improved, resulting in broader implantation criteria. As the number 
of implanted patients grows and the lifespan of devices is outlived, an increasing number of 
device failures are expected. In consequence, the odds of ensuing complications are higher. 
Therefore, analyzing performance and complications after revision cochlear implantation is of 
the utmost importance [1]. 
Revision surgery has always been cause for concern because of the potential risk of 
creating greater damage to delicate inner ear structures when removing the original device 
and replacing it with a new one. Moreover, there is the fear of not being able to follow the 
path of the original electrode and achieve the same depth of insertion. Lastly, there is the 
possibility that functional performance will not be restored to levels achieved prior to device 
failure. This is of particular concern for the pediatric population in view of the fact that most 
children with CIs are pre linguistically deafened and are in the process of developing spoken 
communication skills. Disruption of sound input in the short term coupled with potential 
decrements in performance are serious consequences for the child requiring revision implant 
surgery. Owing to these potential adverse effects, investigating the prevalence of revision 
surgery and performance outcomes remains essential to clinical practice [2]. 
 
 
CAUSES OF REIMPLANTATION 
 
Causes for reimplantation follow the classification proposed by Zeitler [3]. They include 
hard failure, soft failure, device infection or extrusion, improper initial placement, wound or 
flap complications, and upgrade of cochlear implant technology. 
 
 
Device Failure 
 
Hard failure occurs when there no auditory stimulation resulting from a confirmed 
malfunction of a component of the cochlear implant device; this might result from head 
trauma especially in children preventing communication between the internal and external 
components. Hard failures may be heralded by a sudden failure or an abnormal sound and no 
link to the processor. It is diagnosed by failed integrity test [3]. 
Soft failures are typically more challenging to recognize because the recipient has 
improved hearing compared to preimplantation and many factors are known to affect growth 
of auditory skills. Among all CI recipients, improvements in speech perception and 
localization varies widely across individuals Tyler et al. [4]. 
 

Audiological and Surgical Outcome after Cochlear Implant … 
 
491
Table 1. shows check list symptoms for soft failure in both young children and adults 
 
Young children 
A- behavioral 
 Increase in bad behavior 
 Aggressiveness 
 Un willing to wear device 
 Inattentiveness 
 Regression in speech/language 
B-teacher\therapist concern 
 Intermittent responsiveness 
 Frequent appearance of being off task 
 Deterioration of school performance 
 Plateau in performance 
 Failure to meet appropriate expectations 
C- other factors 
 Educational placement 
 Type and amount of therapy 
 Familial involvement  
 Puberty 
Older children/adults 
A-auditory 
 atypical tinnitus 
 buzzing 
 roaring 
 engine like noise 
 static 
 popping 
B-non auditory 
 pain over implant site 
 pain down neck 
 shocking 
 itching 
 fascial stimulations 
C-performance 
 sudden drop in performance 
 decrement in performance over time 
 failure to meet expected performance 
 intermittent performance 
D- mapping 
 change in levels over time 
 changes in pulse width\duration 
 loss of channels 
 type and amount of therapy 
 change in impedance 
 shorts/open circuits 
E-hardware 
 replacements of all externals 
F-objective assessment 
 surface potential testing 
 neural response measures 
 evoked potentials 
 stimulus artifact  
 
Symptoms of soft failure can be subtle and include decreased performance and speech 
perception, poor performance relative to expectations based on preimplantation 
characteristics, aversive stimuli causing subjective discomfort or pain especially at low 
stimulation levels, and hearing static while the device is off. A frequent need for 
reprogramming or difficulty programming often mis-attributed to complicated patients may 

Mohamed Salah Elgandy, Marlan R. Hansen and Richard S. Tyler 
 
492
be related to the device. A strong index of suspicion may be needed to detect accompanying 
signs [5]. 
Balkany TJ et al. [6] suggested a checklist to evaluate soft failure in both children and 
adults. 
 
 
Scalp Infection 
 
Device infection may appear in the form of redness and fluctuation of the skin located 
over the receiver stimulator or an ulcerated wound. Once an infection or exposure of the 
device is suspected, antibiotics should be initiated immediately. If the infection persists, the 
explantation of the device is recommended. 
According to Cohen [7], minor scalp flap complications are those that require minimal 
treatment or no treatment. They are less frequently reported than major complications. Signs 
of flap infection should be immediately recognized and treated. Local symptoms and signs 
include erythema, warmth, and drainage and crusting at the incision site. 
Major scalp complications, include flap necrosis is often the result of poorly 
planned/executed incisions or flap designs. In patients with previous post auricular or face-lift 
incisions consideration should be given to modifications of the standard anteriorly based, C-
shaped flap, as the blood supply to the flap may be inadequate. A “lazy S,” straight, or 
inverted U- or J-flap have been proposed to improve survival of the flap. Infection and/or 
underlying inflammatory conditions (e.g., vasculitis) may also predispose to flap necrosis and 
problems with wound healing. There have been case reports acclaiming the use of hyperbaric 
oxygen to speed recovery/healing and even to “prepare” the bed for rotational flap. 
 
 
Electrode Extrusion 
 
Extra cochlear electrode extrusion is also an indication for revision surgery and may be 
suggested by a decline in speech perception for which there is no alternative explanation. 
After device-related indications, it is the most common cause of need for re implantation in 
children [8]. 
The exact etiology is unknown, but it may be related to initial misplacement, cochlear 
ossification, aggressive host inflammatory responses to the implanted biomaterials, or 
physical forces placed on the cochlea that pull the electrode out of position. This latter 
circumstance might manifest with a progressive decline in performance over time. Despite the 
intuitiveness of this theory as it relates to skull growth in patients implanted when they were 
young children, studies have not documented electrode migration in the developing pediatric 
population. The slow decline in speech perception found in these patients before revision CI 
suggests that extrusion may be a dynamic process that can progress.  
Some theorize that the use of perimodiolar electrodes which are stable by hugging the 
modiolus may decrease the likelihood of electrode extrusion. Additionally, tightly packing the 
cochleostomy site may aid in keeping the electrode in place [9]. 
 
 

Audiological and Surgical Outcome after Cochlear Implant … 
 
493
Cochlear Implant Electrode Misplacement 
 
The standard location for insertion of the CI electrode array is into the scala tympani of 
the cochlea. Failure to insert the electrode array into the scala tympani has been documented 
in the literature [10]. This can range from misplacement of the electrode array into the 
vestibule or internal auditory canal, placement into scala vestibuli or scala media or, more 
commonly, translocation of an array that is initially placed in scala tympani into the scala 
media or vestibuli as the electrode array advances apically. Fortunately, misplacement of the 
electrode array into extra cochlear locations (e.g., vestibule) considered to be a major 
complication is rare. 
Inner ear malformations increase the likelihood of electrode array misplacement. 
Preoperative radiographic examination should help to avoid such complications. Yet, a 
normal preoperative CT scan does not exclude inner ear malformation that could lead to 
misplacement of the electrode array, such as malformation of the osseous spiral lamina. In 
addition, incomplete ossification of the tympano meningeal fissure (Hyrtl’s fissure) that 
usually occurs by the 24th week in utero can result in permanent patency and provide another 
potential route for extra cochlear misplacement of the electrode array. 
Jain and Mukherji [11] reported that the electrode array may be misplaced into the middle 
ear cavity, mastoid bowl, cochlear aqueduct, petrous carotid canal, Eustachian tube, or may 
be only partially inserted into the cochlea. The electrode may also be inserted into the 
vestibular system, most commonly the superior or lateral semicircular canal. Therefore, 
vestibular symptoms that are associated with cochlear implantation should arouse suspicion 
of electrode array misplacement. In addition, electrode array malposition should be 
considered in all cases when no benefit is achieved, and should be evaluated both by device-
integrity testing and CT imaging, even in the setting of late presentation weeks after implant 
surgery. 
Beyond extra cochlear misplacement; electrode array misplacement within the cochlea 
can also reduce overall performance. since clinical functional outcome would be expected to 
be quite different. Regarding mal insertion of cochlear electrode within the cochlea, various 
patterns have been recognized [12]. 
 
1. Tip Rollover. Some newer, peri modilar electrode arrays are particularly prone to a 
tip roll-over and in these cases intraoperative imaging is helpful to confirm 
appropriate placement [13]. 
2. Over insertion of array: placing it deeper into the cochlea than desired, resulting in 
absence of electrodes in the proximal basal turn of the cochlea where high-frequency 
information is typically delivered. 
3. Atwist in the electrode, the electrode bends or twists over on itself.  
4. partial electrode insertion, electrode not inserted completely. 
5. Translocation of the electrode array into scala media or vestibuli: This complication 
is relatively common, especially for electrode arrays placed deep in the cochlear 
apex. It is associated with increased scarring/fibrosis, neural degeneration, and 
diminished performance [14]. 
 
 

Mohamed Salah Elgandy, Marlan R. Hansen and Richard S. Tyler 
 
494
Magnet Displacement  
 
A potentially problematic complication after cochlear implantation is the migration or 
displacement of the internal magnet. For older implant models in which there was a ceramic 
case that houses the internal receiver, this is not an issue. The advantage of having a 
removable magnet stems largely from the possibility of obtaining postoperative magnetic 
resonance imaging (MRI) scans. In a simple outpatient procedure, the internal magnet can be 
removed, scan obtained, and the magnet replaced. As compared with MRI-compatible 
implants without a removable magnet, the quality of an MRI of the head in a patient with an 
implant with the magnet removed is far superior [15]. To facilitate MRIs, most newer model 
implants contain removable magnets; however, it is possible that these removable magnets 
are more prone to dislodgement. 
In the most common scenario, a child sustains some trauma to the skull overlying the 
receiver, thereby causing the magnet to literally pop out of its bed within the housing. 
Children are likely at greater risk for this than adults as a result of their developing motor 
skills and associated play activities and thinner scalps. In such a scenario, the patient may 
notice a lack of function of the implant or a hard lump just underneath the skin adjacent to the 
scalp. 
When a displaced magnet is encountered, the patient or family should be counseled to not 
wear the device until the magnet can be replaced as a result of the risk for injuring the skin 
flap. Fortunately the repair of the problem is relatively straightforward. In rare cases, if the 
magnet becomes dislodged on multiple occasions and there is a tear in the Silastic ring 
holding the magnet in place, the entire implant may have to be replaced [16]. 
 
 
SURGICAL STEPS 
 
After detection of a problem with the CI device, all efforts will be made to reimplant 
within the shortest time feasible. The surgery should ideally be performed by an experienced 
CI team. 
In cases in which anatomy is preserved, re implantation is typically surgery performed 
following the same surgical steps. After skin incision and elevation of the skin flap, dissection 
should be done meticulous to try and preserve the physical integrity of the electrode array, 
which is encapsulated in a fibrous sheath. The lead is followed to the facial recess, round 
window and cochleostomy site; if present, are identified. If the implant is being removed and 
the reimplantation is being staged for a later date (e.g., in cases of infection), the array lead is 
cut as close as possible near to the posterior tympanotomy. This enables removal of the 
implant body and proximal electrode lead, without tension on the intra cochlear array and the 
risk of either inadvertent electrode removal or trauma to the cochlea. In such staged cases, the 
intra cochlear electrode lead is left in situ as a stent to preserve a tract for subsequent 
implantation. 
If the cochlea is to be reimplanted with a new device at the same time (e.g., a device 
failure), the area around the cochleostomy is prepared in advance of the array change. 
Generally the implanted array can gently be withdrawn from the cochlea under microscopic 
visualization. If necessary, an incision can be made into the fibrous sheath that had formed 

Audiological and Surgical Outcome after Cochlear Implant … 
 
495
around the old electrode array. The new device is positioned the pocket under the scalp [17] 
and the new array is inserted carefully without disruption of the fibrous sheath. It is important 
to note that ideally the diameter of the new electrode array should be the same diameter or 
smaller than the original one. Rarely, there may be intra cochlear ossification or fibrosis that 
obscures the electrode tract. If so, this is often encountered around the cochleostomy and can 
be removed with micro rasps, picks or even a small diamond burr. 
After the old array was removed, it was used for biofilm research [18], while the body 
and the attached lead were sent back to the manufacturer for cause-of-failure testing. If 
reimplantation is not planned at the same procedure, we left the electrode in the cochlea as a 
stent to prevent cochlear ossification and to facilitate reimplantation in the future. 
Regarding insertion depth, reinsertion is usually a smooth step and results in a full 
insertion of the electrode array, but partial reinsertion may occur [19, 20]. Use an electrode 
array that is smaller or equal diameter of original one may help mitigate the risk of partial 
insertion. 
If resistance to insertion is high, it would be wise to use straight electrode or styleted 
array because these are stiffer and may over resistance when it is encountered. 
The implant team should develop a surgical contingency plan if reinsertion is not 
possible. For example, intervening ossification and/or intra cochlear granulation tissue may 
prohibit reinsertion of the new electrode. The surgeon should not first propose the question, 
“Can we implant the other ear?” in the operating room. Rather, the implant team should 
evaluate the suitability of the contralateral ear before revision surgery and counsel the patient 
accordingly. In cases of soft failure not associated with adverse stimuli, implantation of the 
contralateral ear may obviate removal of a functional device. 
 
 
SURGICAL OUTCOME 
 
Insertion of an electrode into the scala tympani often causes trauma to the spiral ligament 
and basilar membrane in the area of the basal turn [21]. Many histologic studies have 
indicated that while cochlear explantation followed by reimplantation can result in additional 
cochlear trauma in some cases, the trauma does not preclude successful use of the device 
[22]. 
Insertion of an electrode into the scala tympani often causes trauma to the spiral ligament 
and basilar membrane in the area of the basal turn [23]. However, surgical trauma to an 
already damaged cochlea does not appear to affect neural stimulation or auditory performance 
with an implant [24, 25]. Mounting evidence suggests that stimulation of remaining neural 
elements occurs at the level of the spiral ganglion cells or higher up the auditory pathway, 
because some patients with no hair cells or dendrites and markedly reduced spiral ganglion 
cell counts have received substantial benefit from their cochlear implants. 
Greenberg et al. [26] reported in guinea pig that there was no significant difference in 
pathology of single implanted or reimplanted cochleae. 
Jackler et al. [27] reported that cochlear explanation followed by immediate 
reimplantation may be not accompanied by damage to cochlea or its neural population. 
However, in cases with marked granulation tissue proliferation at round window and scala 
tympani, incidence of trauma is high. 

Mohamed Salah Elgandy, Marlan R. Hansen and Richard S. Tyler 
 
496
Shepherd et al. [28] reported the histopathologic change after cochlear reimplantation 
using long multichannel intra cochlear electrodes in the macaque, where electrode insertion 
trauma involving the osseous spiral lamina or basilar membrane was greater in the 
reimplanted cochleae and also resulted in more extensive loss of basal ganglion cells, 
particularly when proliferation of granulation tissue at the cochleostomy was identified. 
Linthicum et al. [29] reported that reimplantation histopathology showed marked new 
bone formation fibrous tissue and low count of spiral ganglion cells compared to single 
implanted cochlea. 
Fayad et al. [30] reported that new bone formation around electrode especially greatest in 
scala tympani of basal turn and spiral ganglion cell count was marked reduced c representing 
less than 10% of normal spiral ganglion cells.  
Li et al. [31] by using a scoring system for damage to the lateral cochlear wall and a 
three-dimensional reconstruction method reported that marked level of new bone and fibrous 
tissue formation with cochlear re implantation. In addition they reported that insertional 
trauma to lateral cochlear wall play an important role in subsequent fibrosis and neo 
ossification following implantation and reimplantation. They also reported high levels of 
osteoprotegerin within the spiral ligament which may serve to inhibit bone remodeling and 
exposure of the underlying endosteum which may provide a nidus for inflammatory process 
to enhance ossification and inflammatory mediators may contribute to general increase in new 
bone formation. 
The complications of cochlear reimplantation surgery can be summarized as follows: 
 
1. Incomplete Electrode Extraction During Cochlear Implant Revision; Although the 
majority of revision operations are completed without complication, the current 
report demonstrates that one cannot universally assume that complete extraction of 
an indwelling cochlear implant electrode array will be straightforward. Kang et al. 
[32] reported 3 cases in which incomplete electrode removal with fracture of distal 
part of it inside cochlea and authors attributed that due to dense fibrous and bony 
tissue response at the cochleostomy site that extended into the cochlea. It is possible 
that, in some pediatric patients, a robust inflammatory response results in a fibrous 
and/or bony sheath that completely encases the array and fixes it within the cochlea, 
additionally, some patients had cochlear implants with intra cochlear positioners, 
which are designed to achieve juxtamodiolar positioning by displacing the array 
against the medial wall of the cochlea. It is possible that the shim like effect of the 
positioners contributed to the difficulties encountered during extraction of the 
electrode. 
2. C.S.F leakage; was considered the the sole complication encountered during revision 
surgery in the past as reviewed by Lassig et al. [33] who reported 1 intraoperative 
outflow of CSF as the only surgical complication in 61 revision operations. 
Similarly, Buchman et al. [34] reported 1 instance of CSF leakage in 33 revision 
operations. Fayad et al. [35] also reported 2 occurrences of CSF leakage in 43 
revision operations. Excessive cerebrospinal fluid (CSF) can access the cochlea 
through patent developmental pathways of the otic capsule or after traumatic 
disruption of the temporal bone. 
3. facial nerve injury; Facial nerve injury risk is also high in revision and re-
implantation surgery. Presence of fibrosis in the mastoid bowl, which requires 

Audiological and Surgical Outcome after Cochlear Implant … 
 
497
meticulous dissection with careful avoidance of the facial nerve to free the original 
electrode array. Adequate irrigation in order to prevent thermal injury is also 
important. The surgeon should be cautious about atypical positioning of the facial 
nerve in labyrinth abnormality cases [36]. 
4. Injury of the annulus or bony external auditory canal skin; due to marked thinning of 
canal in revision cases to identify anatomical landmarks will lead to cholesteatoma if 
it is not adequately repaired, retraction pockets and lastly protrusion of electrode 
through external auditory canal [37]. 
5. Perilymphatic fistula; through a cochleostomy and insertion trauma to the labyrinth 
may lead to postoperative vestibular problems. In addition, a serous labyrinthitis 
caused by electrode placement in the cochlea was suspected as being the possible 
etiology for vertigo in CI patients [38]. 
6. Acute mastoiditis, post traumatic wound breakdown and receiver-stimulator/magnet 
displacement occurred also as complications of revision surgery which are similar to 
primary surgery [39]. 
 
 
AUDIOLOGICAL OUTCOME 
 
Cochlear implantation has been proven to be very effective surgery in rehabilitation of 
prelingual deaf children and post lingual deaf adult, but for some reasons, removal of cochlear 
implant may be required. For both child and family, it is a stressful condition as patient will 
undergo repeated surgery, a period of nonuse, and a period of rehabilitation again. There is 
also a greater concern about complications such as reduced performance following repeated 
surgery. 
Here we will discuss audiological performance following revision cochlear implant 
surgery starting by impedance. 
Although reimplantation is an undesirable consequence of cochlear implantation, many 
studies have shown good post-reimplantation results in terms of speech-perception scores [40, 
41]. Only a few studies have reported patients who did not achieve the same perception scores 
after reimplantation [42]. 
In most, if not all, published studies, the period between first implantation, occurrence of 
the defect, and subsequent reimplantation was fairly long. For that reason, in most cases, a 
newer type of implant or another brand had become available and was implanted instead of 
the device that was initially used [43]. As a result, the newer device was an upgraded version 
of the former device and was coupled with improved software to drive the new implant. 
Hence, those changes in design, brand, or software could be the explanation of the same, or 
even better, speech-perception scores. Consequently, the confounding variable of a different 
type of implant weakens the comparison between speech- perception outcomes from the first 
implantation and the reimplantation. 
 
 
 
 

Mohamed Salah Elgandy, Marlan R. Hansen and Richard S. Tyler 
 
498
Impedance 
 
Impedance is a measure of electrical resistance at the electrode. it depends upon design of 
electrode, including materials used, surrounding tissues, fluid through which current exist and 
the electrode location into cochlea [44]. 
It can be increased by amount of cell cover and fibrous tissue growth around electrode 
array. As a result of repeated surgery there is increase in scar tissue formation and new bone 
and ossification. Thus increased impedance can be used post-operative as marker or proxy for 
increased inflammation [45]. High impedance is of clinical concern because it can cause 
saturation (compliance) of electrodes and reduce the dynamic range of stimulation.  
Reduction in electrical impedance of cochlear implant electrodes is important as less 
energy is used, and this prolongs the cochlear battery life. Lower impedance with lower 
current allows for more focused stimulation of the neural elements in the cochlea, giving 
greater differentiation of sounds [46]. 
Neuburger et al. [47] found that increases in impedance are often accompanied by clinical 
inflammatory precipitation, with exudate and labyrinthitis and this can be in some cases of 
revision not all cases due to new bone formation with accompanying fibrosis. 
Measurement of impedance will be conducted at time of surgery to identify very high 
impedance(open circuit) which is indicative of break in the wire lead, damage of electrode 
contact point, air bubbles around electrode contact, electrode malposition either (incomplete 
insertion or delayed extrusion) and ossification of cochlea fibrosis and inflammation, or low 
impedance (short circuit) which is indicator of one or two electrodes share a common 
electrical course, or partial short circuit which means that impedance decreased over time but 
failed to reach a value that will be flagged by software as a short circuit [48].  
Steroids can decrease impedance levels and are used in hearing preservation techniques 
and cases with cochlear explant and reimplant which result in impedance elevation, although 
the duration of protection, areas of cochlea protected, and the best mode of delivery is still 
under investigation [49]. 
 
 
Speech Recognition 
 
Does cochlear reimplantation affect speech recognition? 
As electronic devices, cochlear implants are occasionally subject to damage or 
breakdowns. Obviously, in the event that a cochlear implant becomes unusable, 
reimplantation becomes necessary. Doubts may arise in the patient about his subsequent 
speech recognition performance with a new implant.  
Hamzavi et al. [50] recently demonstrated substantial benefits in patients in whom an 
analogue single-channel implant was upgraded to a digital multichannel device. In that study, 
he observed that, 3 months following reimplantation, five of seven patients achieved speech 
recognition performance at about the same level experienced with the original implant. A 
decrease in speech recognition was noted in one subject only, and was related to her central 
auditory system.  
Henson et al. [51] evaluated a group of 28 patients (Nucleus 22 cochlear implant) who 
were reimplanted. 37% of patients achieved significantly higher sentence or word scores with 
their replacement cochlear implants than with their original implants, while 26% showed no 

Audiological and Surgical Outcome after Cochlear Implant … 
 
499
significant change. The reason for the decline in speech recognition in that group was unclear, 
and parameters such as insertion depth or surgical complications did not seem to be relevant. 
Parisier et al. [52] analyzed the outcomes of cochlear reimplantation in 25 children 
provided with Nucleus 22 cochlear implants. They found that open-set speech recognition 
scores and speech perception abilities remained stable or improved compared with results 
before reimplantation. 
Balkany et al. [53] also found the speech recognition scores following reimplantation to 
be at least as good as with their initial implant. To achieve further beneficial audiological 
performance upon reimplantation, it appears that the same conditions which were applied to 
the initial implantation, such as insertion depth, implant type, and number of active channels, 
might be important indicators, as described by Miyamoto et al. [54]. 
Manrique et al. [55] reported a study on 38 patients requiring reimplantation and found 
that aided pure-tone hearing thresholds improved in 44% of the reimplanted patients, with 
11% showing no change in their threshold. 64% percent of the patients showed an 
improvement between 20% and 35% points in their disyllabic word recognition score after 
reimplantation, with a further 9% showing no change in their speech recognition scores (SRS) 
from before to after reimplantation. 
Rivas et al. [56] reviewed 34 patients who underwent cochlear reimplant, scores after 
reimplantation were better in 65% of cases, the same in 32%, and worse in 3%, when 
compared with the score obtained just prior to reimplantation. 
Mahtani et al. [57] reported 32 reimplantation surgeries for 30 patients and reported that 
For the 25 adults with available scores in the quiet condition, 56% had no change in scores 
after reimplantation, 36% had improved scores, and 8% had poorer scores. For the 16 
recipients tested in noise, 50% demonstrated no significant difference after reimplantation, 
25% obtained significantly better scores, and the 25% obtained significantly worse scores. 
 
 
CONCLUSION 
 
Although cochlear implant surgery has been proven as a safe and effective method in 
rehabilitation of postlingual deaf adult and prelingual deaf children, these devices are 
subjected to damage, breakdown, need to upgrade and failure. in such cases, reimplantation is 
necessary. Although surgical problems leading to revision surgery and reimplantation are 
expected to diminish by experience, every center has to deal with device failures. Both 
revision surgery and reimplantation require extra care and it should be better carried out by 
experienced surgeons. Implant performances are expected to be comparable with primary 
implantations and a lot of studies showed improve audiological outcome after reimplantation. 
 
 
REFERENCES 
 
[1] 
Lassig, AA; Zwolan, TA; Telian, SA. Cochlear implant failures and revision. Otol 
Neurotol, 2005, 26, 624–34. 
[2] 
Weise, JB; Muller-Deile, J; Brademann, G; et al. Impact to the head increases cochlear 
implant reimplantation rate in children. Auris Nasus Larynx, 2005, 32, 39–43. 

Mohamed Salah Elgandy, Marlan R. Hansen and Richard S. Tyler 
 
500
[3] 
Zeitler, DM; Budenz, CL; Roland, JL. Jr. (2009). Revision cochlear implantation. Curr 
Opin Otolaryngol Head Neck Surg, 17, 334–338. 
[4] 
Tyler, RS; Parkinson, AJ; Woodworth, GG; Lowder, MW; Gantz, BJ. Performance 
over time of adult patients using the Ineraid and Nucleus cochlear implants. Journal of 
the Acoustical Society of America, (1997), 102(1), 508-522. 
[5] 
Balkany, TJ; et al. Cochlear reimplantation. Laryngoscope, 1999, 109, 351–355. 
[6] 
Balkany, TJ; et al. Cochlear implant soft failures consensus development conference 
statement. Otol Neurotol, 2005, 26, 815–818. 
[7] 
Cohen, NL; Hoffman, RA; Stroschein, M. Medical or surgical complications related to 
the nucleus multichannel cochlear implant. Ann Otol Rhinol Laryngol, 135, 8-13, 1988. 
[8] 
Brown, KD; Connell, SS; Balkany, TJ; Eshraghi, AE; Telischi, FF; Angeli, SA. 
Incidence and indications for revision cochlear implant surgery in adults and children. 
Laryngoscope, 2009, 119(1), 152–157. 
[9] 
Ambyraja, R; Gutman, MA; Megrian, CA. Cochlear implant complications. Arch Oto-
Head Neck Surg, 2005, 131, 245–250. 
[10] Marlowe, Al; Chinnici, JE; Rivas, A; et al. Revision cochlear implant surgery in 
children: The Johns Hopkins experience. Otol Neurotol, 2010, 31, 74–82. 
[11] Jain, R; Mukherji, SK. Cochlear implant failure: imaging evaluation of the electrode 
course. Clin Radiol, 2003, 58, 288–93. 
[12] Hughes, M. Objective measures in cochlear implants. San Diego, CA: Plural 
Publishing, 2013. 
[13] Zuniga, M. Geraldine; Rivas, Alejandro; Hedley-Williams, Andrea; Gifford, Rene H; 
Dwyer, Robert; Dawant, Benoit M; Sunderhaus, Linsey W; Hovis, Kristen L; Wanna, 
George B; Noble, Jack H; Labadie, Robert F. Tip Fold-over in Cochlear Implantation 
Otology & Neurotology, Issue, Volume 38(2), February 2017, p. 199–206. 
[14] Fischer, N; Pinggera, L; Weichbold, V; Dejaco, D; Schmutzhard, J; Widmann, G. 
American Journal of Neuroradiology, February 2015, 36 (2), 372-377. Radiologic and 
Functional Evaluation of Electrode Dislocation from the Scala Tympani to the Scala 
Vestibuli in Patients with Cochlear Implants. 
[15] 35-Migirov, L; Kronenberg, J. Magnet displacement following cochlear implantation. 
Otol Neurotol, 2005, 26, 646–648. 
[16] 36-Yun, JM; Colburn, MW; Antonelli, PJ. Cochlear implant magnet displacement with 
minor head trauma. Otolaryngol Head Neck Surg, 2005, 133, 275–277. 
[17] Lenarz, T. Cochlea-implantat. Ein praktischer Leitfaden furs die Versorgung von 
Kindern und Erwachsenen [in German]. Berlin: Springer, 1998. 
[18] Frijns-van Putten, A; Beers, M; Snieder, SG; Frijns, JHM. Hoortraining voor 
volwassen CI-dragers: Het cochleaire leer model [in Dutch]. Logopedie en Foniatrie, 
2005, 77, 50–59. 
[19] Lassig, AA; Zwolan, TA; Telian, SA. Cochlear implant failures and revision. Otol 
Neurotol, 2005, 26, 624–634. 
[20] Miyamoto, RT; Svirsky, MA; Myres, WA; Kirk, KI; Schulte, J. Cochlear implant 
reimplantation. Am J Otol, 1997, 18, S60–S61. 

Audiological and Surgical Outcome after Cochlear Implant … 
 
501
[21] Fayad, J; Linthicum, FH; Jr. Otto, SR; et al. Cochlear implants: histopathologic 
findings related to performance in 16 human temporal bones. Ann Otol Rhinol 
Laryngol, 1991, 100, 807-11. 
[22] Miller, JM; Altschuler, RA; Carlisle, L; et al. Cochlear prosthesis: histologic 
observations on reimplantation in the monkey. In: Abstracts of the Tenth Mid-Winter 
Research Meeting. Clearwater Beach, FL: Association for Research in Otolaryngology, 
1987, p. 54. 
[23] Lehnhardt, M; Von Wallenberg, EL; Brinch, J. Cochlear implant reliability. Fifth 
International Cochlear Implant Conference, New York, NY, May 1-3, 1997. 
[24] Hamzavi, J; Baumgartner, WD; Pok, SM. Does cochlear reimplantation affect speech 
recognition? Int. J Audio, 2002, 41, 151-6. 
[25] Shepherd, RK; Graeme, MC; Xu, SA; et al. Cochlear pathology following 
reimplantation of a multi-channel scala tympani electrode array in the macaque. Am J 
Otol, 1995, 16, 186-99? 
[26] Greenberg, AB; Myers, MW; Hartshorn, DO; Miller, JM; Altschuler, RA. Cochlear 
electrode reimplantation in the guinea pig. Hear Res, 1992, 61, 19–23. 
[27] Jackler, RK; Leake, PA; McKerrow, WS. Cochlear implant revision: effects of 
reimplantation on the cochlea. Ann Otol Rhinol Laryngol, 1989, 98, 813–820. 
[28] Shepherd, RK; Clark, GM; Xu, SA; Pyman, BC. Cochlear pathology following 
reimplantation of a multichannel scala tympani electrode array in the macaque. Am J 
Otol, 1995, 16, 186–199. 
[29] Linthicum, FH; Jr. Fayad, J; Otto, SR; Galey, FR; House, WF. Cochlear implant 
histopathology. Am J Otol, 1991, 12, 245–311. 
[30] Fayad, JN; Baino, T; Parisier, SC. Revision cochlear implant surgery: causes and 
outcome. Otolaryngol Head Neck Surg, 2004, 131, 429–432. 
[31] Li, PMMC; Somdas, MA; Eddington, DK; Nadol, JB. Jr. Analysis of intra cochlear 
new bone and fibrous tissue formation in human subjects with cochlear implants. Ann 
Otol Rhinol Laryngol, 2007, 116, 731–738. 
[32] Kang, SY; Zwolan, TA; Kileny, PR; Niparko, JK; Driscoll, CL; Shelton, C; Telian, SA. 
Incomplete electrode extraction during cochlear implant revision. Otology and 
Neurotology, 2009, 30(2), 160-164.  
[33] Lassig, AA; Zwolan, TA; Telian, SA. Cochlear implant failures and revision. Otol 
Neurotol, 2005, 26, 624Y34. 
[34] Buchman, CA; Higgins, CA; Cullen, R; et al. Revision cochlear implant surgery in 
adult patients with suspected device malfunction. Otol Neurotol, 2004, 25, 504Y10, 
discussion 10. 
[35] Fayad, JN; Baino, T; Parisier, SC. Revision cochlear implant surgery: causes and 
outcome. Otolaryngol Head Neck Surg, 2004, 131, 429Y32. 
[36] Kubo, K; Matsuura, S; Iwaki, T. Complications of cochlear implant surgery, Oper. 
Tech. Otolaryngol., 16, (2005), 154–158. 

Mohamed Salah Elgandy, Marlan R. Hansen and Richard S. Tyler 
 
502
[37] Lescanne, E; Zahrani, MA; Bakhos, D; Robier, A; Moriniere, S. Revision surgeries and 
medical interventions in young cochlear implant recipients, Int. J. Pediatric. 
Otorhinolaryngol., 75, (2011), 1221–1224. 
[38] Kubo, T; Yamamoto, K; Iwaki, T; Doi, K; Tamura, M. DiVerent forms of dizziness 
occurring after cochlear implant. Eur Arch Otorhinolaryngol, 2001, 258, 9–12. 
[39] Kandogan, T; Olgun, L; Gu¨ntekin, G. Complications of paediatric cochlear 
implantations: experience in I˙ zmir, J. Laryngol. Otol., 119 (8), (2005), 606–610. 
[40] Alexiades, G; Roland, JT; Jr. Fishman, AJ; Shapiro, W; Waltzman, SB; Cohen, NL. 
Cochlear reimplantation: surgical techniques and functional results. Laryngoscope, 
2001, 111, 1608–1613.  
[41] Cote, M; Ferron, P; Bergeron, F; Bussieres, R. Cochlear reimplantation: causes of 
failure, outcomes, and audiologic performance. Laryngoscope, 2007, 117, 1225–1235. 
[42] Henson, AM; Slattery, WH; III. Luxford, WM; Mills, DM. Cochlear implant 
performance after reimplantation: a multicenter study. Am J Otol, 1999, 20, 56–64. 
[43] Lassig, AA; Zwolan, TA; Telian, SA. Cochlear implant failures and revision. Otol 
Neurotol, 2005, 26, 624–634. 
[44] Paasche, G; Bockel, F; Tasche, C; Lesinski-Schiedat, A; Lenarz, T. Changes of 
postoperative impedances in cochlear implant patients: the short-term effects of 
modified electrode surfaces and intra cochlear corticosteroids. Otol Neurotol, 2006, 27, 
639Y47. 
[45] Newbold, C; Richardson, R; Huang, CQ; Milojevic, D; Cowan, R; Shepherd, R. An in 
vitro model for investigating impedance changes with cell growth and electrical 
stimulation: implications for cochlear implants. J Neural Eng, 2004, 1, 218Y27. 
[46] Micco, AG; Richter, CP. Tissue resistivities determine the current flow in the cochlea. 
Curr Opin Otolaryngol Head Neck Surg, 2006, 14, 352Y5. 
[47] Neuburger, J; Lenarz, T; Lesinski-Schiedat, A; Buchner, A. Spontaneous increases in 
impedance following cochlear implantation: suspected causes and management. Int. J 
Audiol, 2009, 48, 233Y9. 
[48] Carlson, M; Archibald, D; Dabade, T; Gifford, R; Neff, B; Beatty, C; et al. Prevalence 
and timing of individual cochlear implant electrode failures. Otol Neurotol., 2010, 
31(6), 893–8. 
[49] De Ceulaer, G; Johnson, S; Yperman, M; et al. Long-term evaluation of the effect of 
intra cochlear steroid deposition on electrode impedance in cochlear implant patients. 
Otol Neurotol, 2003, 24, 769Y74. 
[50] Hamzavi, J; Baumgartner, WD; Adunka, O; Franz, P; Gstoettner, W. Audiological 
performances with cochlear reimplantation from analog single channel to digital 
multichannel devices. Audiology, (2000), 39, 305-10. 
[51] Henson, AM; Slattery, WH; 3rd. Luxford, WM; Mills, DM. Cochlear implant 
performance after reimplantation: a multicenter study. Am J Otol, (1999), 20(1), 56-64. 
[52] Parisier, SC; Chute, PM; Popp, AL; Suh, GD. Outcome analysis of cochlear implant 
reimplantation in children. Laryngoscope, (2001), 111(1), 26-32. 

Audiological and Surgical Outcome after Cochlear Implant … 
 
503
[53] Balkany, TJ; Hodges, AV; Gomez-Marin, O; et al. Cochlear reimplantation. 
Laryngoscope, (1999), 109(3), 351-5. 
[54] Miyamoto, RT; Svirsky, MA; Myres, WA; Kirk, KI; Schulte, J. Cochlear implant 
reimplantation. Am J Otol, (1997), 18, 60-1. 
[55] Manrique-Huarte, R; Huarte, A; Manrique, MJ. Surgical findings and auditory 
performance after cochlear implant revision surgery. European Archives of Oto-Rhino-
Laryngology, (2016), 273(3), 621–629. 
[56] Rivas, A; Marlowe, AL; Chinnici, JE; Niparko, JK; Francis, HW. Revision cochlear 
implantation surgery in adults: Indications and results. Otology & Neurotology, (2008), 
29(5), 639–648. 
[57] Mahtani, S; Glynn, F; Mawman, DJ; O’Driscoll, MP; Green, K; Bruce, I; Lloyd, SKW. 
Outcomes of cochlear reimplantation in adults. Otology & Neurotology, (2014), 35(8), 
1366–1372. 
 
 


In: Encyclopedia of Audiology and Hearing Research 
ISBN: 978-1-53617-702-2 
Editors: Erno Larivaara and Senja Korhola 
© 2020 Nova Science Publishers, Inc. 
 
 
 
 
 
 
 
Chapter 33 
 
 
 
POSTUROLOGY: THE SCIENTIFIC INVESTIGATION OF 
POSTURAL DISORDERS 
 
 
Giuseppe Messina1,2, MD, Valerio Giustino3,  
Francesco Dispenza4,5, MD, PhD, Francesco Galletti6,  
Angelo Iovane1, MD, Serena Rizzo7, MD  
and Francesco Martines5,8,, MD, PhD 
1Department of Psychology, Educational Science and Human Movement,  
University of Palermo, Palermo, Italy 
2PosturaLab Italia Research Institute, Palermo, Italy 
3PhD Program in Health Promotion and Cognitive Sciences,  
University of Palermo, Palermo, Italy 
4A.O.U.P. Paolo Giaccone, Palermo, Italy 
5Istituto Euromediterraneo di Scienza e Tecnologia – IEMEST, Palermo, Italy 
6Department of Otorhinolaryngology, University of Messina, Messina, Italy 
7Di. Chir. On. S. Department, Physical Medicine and Rehabilitation,  
University of Palermo, Palermo, Italy 
8Bio. Ne. C. Department, Audiology Section, University of Palermo, Palermo, Italy 
 
 
ABSTRACT 
 
The human posture, regulated by the tonic postural system in response to the 
phenomenon of the force of gravity, is organized by feedback and feedforward processes 
according to a non-linear cybernetic system in which the central nervous system 
integrates sensory inputs from interoceptive, proprioceptive and exteroceptive organs 
modulating the muscular tone. According to this scheme, afferences from sensory organs 
such as the muscular proprioceptors organs, the stomatognathic apparatus, the visual 
system as well as the auditory and the vestibular system are responsible for controlling 
balance and postural control. If one of these postural receptors is dysfunctional (i.e., it 
                                                        
 Corresponding Author’s Email: francescomartines@hotmail.com. 

Giuseppe Messina, Valerio Giustino, Francesco Dispenza et al. 
 
506
does not function physiologically), it sends aberrant informations to the central nervous 
system, which modulates a response that generates an adaptation of the muscular tone 
through muscle chains according to a non-linear dynamic relationship. The 
posturography, comprising the baropodometric evaluation and the stabilometric 
assessment, is an instrumental evaluation that allows, through a platform, to measure 
body posture. In particular, pressure and plantar surface contribute to provide 
fundamental postural characteristics, whereas, the study of the centre of pressure (i.e., the 
point of the load pressure sum of the ground reaction force vector) is used to evaluate 
body balance and postural control.  
The purpose of this chapter is to understand the main features of human posture and 
how it is possible to analyze it. 
 
Keywords: posture, stability, body balance 
 
 
INTRODUCTION 
 
 
Figure 1. The non-linear cybernetic system of the human posture. 

Posturology: The Scientific Investigation of Postural Disorders 
 
507
The Posturology is the science that studies human posture in static and dynamic and the 
relationship existing between body segments. The human posture can be represented as a non-
linear cybernetic system that is regulated by the tonic postural system, antigravity 
musculature which allows to control body stability subject to the force of gravity. Indeed, the 
muscle apparatus maintains a basal activity, called tone, in order to react to the force of 
gravity without performing changing on physical location or movements of skeletal parts of 
human body [1]. 
Body posture is influenced by afferents from sensory receptors as the stomatognathic 
system, the visual apparatus, the audio-vestibular system, the feet, the muscular 
proprioceptors organs, the skin [2-8]. As represented in the Figure 1, these organs project 
sensory information into the central nervous system that integrates the afferents and processes 
a response to the tonic postural system [1]. A change in the inputs from these systems due to a 
physiological decline or a pathological condition causes adaptation mechanism through the 
muscle chains causing altered effects on body balance [9-14]. Moreover, it is important to 
note that, according to the non-linear dynamic relationship, cause and effect could not 
correspond in terms of proportion and for a small phenomenon could be present a major 
consequence.  
In case of altered sensory information from a postural receptor the tonic postural system 
responds changing muscular activity modulating the tone leading adaptation mechanisms as 
long as it is possible until the postural disorder. 
The role of the posturologist is to evaluate body balance and posture features, in 
qualitative and quantitative manner, in order to understand the cause of a possible postural 
disorder.  
 
 
HUMAN POSTURE EVALUATION 
 
Body posture assessment comprehends: patient history acquisition, visual postural 
analysis, postural clinical tests and the posturography (including baropodometric assessment 
and the stabilometric assessment).  
 
 
PATIENT HISTORY 
 
An accurate patient history obtainment facilitates the identification of the cause of the 
postural disorder. Accordingly, the inquiry should provide elements of knowledge about: 
trauma, accidents, injuries as well as previous surgical operations, allergies/intolerances, 
pains but also diseases/impairments and/or taking drugs, treatments in progress, sight or 
hearing loss, audiovestibular characteristics as the presence of tinnitus, vertigo/dizziness, 
aural fullness [15-22]. Furthermore, the posturologist should collect data regarding lifestyle 
features as sleep quality, stress or anxiety state, physical activity level and type of job, 
important contributors that determine human posture [23-29]. Moreover, it was widely 
investigated in the literature the role of occlusal or orthopedic devices on human posture, for 
this reason for the expert in posturology it is important to annotate also these informations 
[30-32]. 

Giuseppe Messina, Valerio Giustino, Francesco Dispenza et al. 
 
508
VISUAL POSTURAL ANALYSIS 
 
The observation of the posture is an essential part of the body posture evaluation. This 
qualitative assessment take into consideration the spatial location of peculiar points of the 
body in order to analyze any deviations respect to the vertical line for the sagittal and the 
frontal plane and possible rotations in the horizontal plane [33]. Moreover, it is possible to 
examine the alignement of body segments and the differences between rightward and leftward 
hemibody [33]. 
For the visual postural analysis the subject is asked to maintain the orthostatic stance as 
comfortably as possible wearing only underwear, barefoot and looking forward while the 
posturologist records the location of the landmarks for all the anatomical planes as 
represented in the figures 2,3,4. In particular, in the frontal plane the following lines are 
considered: the bipupillary line, the connection line of acoustic meatus, the line connecting 
left and right labial commissures, the bi-acromial line, the bi-styloid line and the bi-ischial 
line (Figure 1). In absence of any postural disorder, all these reference lines should be parallel 
to each other. To assess postural features in the sagittal plane, the alignment of peculiar points 
passing through the vertical axis, i.e., the acoustic meatus, the odontoid process of the second 
cervical vertebra, the body of the third lumbar vertebra and the lateral malleolus, is taken into 
consideration (Figure 2). Moreover, the cervical curve of the spine should measure 6 - 8 cm 
and the lumbar curve 4-6 cm. In the evaluation of the horizontal plane the main reference 
lines concern the parallelism between the shoulder girdle and the pelvic girdle (Figure 3). 
 
 
Figure 2,3,4. The visual postural analysis in the frontal, sagittal and horizontal plane respectively. 
 
POSTURAL CLINICAL TESTS 
 
Since, as mentioned above, all the postural receptors lead sensory information to the 
central nervous system influencing the tonic postural system, postural clinical tests are 

Posturology: The Scientific Investigation of Postural Disorders 
 
509
performed to identify a dysfunctional postural receptor. Indeed, these tests allow the 
evaluation of the physiological function of the organs involved on postural regulation. Among 
these assessments, it is important to mention the ocular motility exam, the swallowing 
evaluation and the vestibular function tests. 
 
 
POSTUROGRAPHY 
 
Posturography, or instrumental postural assessment, includes a baropodometric test, an 
examination that allows the measurement of the foot pressure and the plantar surface and a 
stabilometric test, for the measurement of the regulation of the activity of the postural tonic 
system. Posturography is measured using a platform that samples real time postural sway at 
different frequency based on the type of the platform. 
The baropodometry is measured in 5 seconds during which the patient maintains the 
orthostatic position on the platform with the head in a neutral position facing forward, the 
arms along the trunk and the feet positioned next to each other. The main features measured 
through this test are the load distribution between feet, the rearfoot/forefoot ratio of the load 
pressure for each foot and the plantar surface characteristics. 
The duration of the stabilometry is 51.2 seconds and provides that the subject mantains 
the feet positioned side-by-side and forming an angle of 30° and both heels at 4 cm apart [34]. 
Basic, participant repeate the stabilometric test in two different conditions: with eyes open 
and then with eyes closed to examine the impact of sight on posture. Moreover, 
complementary stabilometric tests are used to investigate the influence of all the others 
receptors on stability, such as the test with caloric vestibular stimulation for the vestibule or 
the stabilometric assessment with mouth open to evaluate the effect of the stomatognathic 
system on postural control [35,36]. In the Table 1 are illustrated some methods to analyze the 
influence of sensory information from postural organs on body balance. The parameters 
considered for the postural sway are the coordinates of the center of pressure (CoP) and in 
particular the Sway Path Length (SPL), i.e., the path length of the center of pressure, and the 
Ellipse Sway Area (ESA), i.e., the surface that contains the movement of the CoP. 
 
 
INTERVENTION PROGRAMS 
 
As mentioned previously, a postural disorder is caused by an altered postural receptor. 
For this reason, if the posturologist identifies a postural disorder by posture evaluation, the 
treatment to rebalance the system depends on which receptor is in dysfunction. Furthermore, 
intercepted the receptor, the intervention can provide a wide range of approaches. 
The role of the posturologist, in presence of a postural disorder, is to advise and direct the 
patient to visit the specialist (such as the gnathologist in case of swallowing disorder or the 
otorhinolaryngologist in presence of vertigo).  
Anyhow, it is widely known that, within the various treatments proposed, physical 
activity is always recommended in order to improve balance [37]. 
 

Giuseppe Messina, Valerio Giustino, Francesco Dispenza et al. 
 
510
Table 1. Some stabilometric tests for postural receptors 
 
Visuo-Oculomotor System 
With eyes closed 
With eyes towards different directions 
With prisms 
Audio-Vestibular System 
Caloric vestibular stimulation 
Galvanic vestibular stimulation 
Stomatognathic System 
With mouth open 
With occlusal splint 
 
 
REFERENCES 
 
[1] 
Gagey, P. M. (1991). A critique of posturology: towards an alternative neuroanatomy?. 
Surg Radiol Anat, 13 (4): 255 - 257. 
[2] 
Cuccia, A. & Caradonna, C. (2009). The relationship between the stomatognathic 
system and body posture. Clinics (Sao Paulo), 64 (1): 61 - 66. 
[3] 
Pociask, F. D., DiZazzo-Miller, R., Goldberg, A. & Adamo, D. E. (2016). Contribution 
of Head Position, Standing Surface, and Vision to Postural Control in Community-
Dwelling Older Adults. American journal of occupational therapy, 70 (1): 
7001270010, 1-8. 
[4] 
Thomas, E., Bianco, A., Messina, G., Mucia, M., Rizzo, S., Salvago, P., Sireci F., 
Palma, A. & Martines, F. (2017). The influence of sounds in postural control. Hearing 
Loss: etiology, management and societal implications, 1 - 12. 
[5] 
Martines, F., Messina, G., Patti, A., Battaglia, G., Bellafiore, M., Messina, A., Rizzo, 
S., Salvago, P., Sireci, F., Traina, M. & Iovane, A. (2015). Effects of tinnitus on 
postural control and stabilization: A pilot study. Acta Medica Mediterranea, 31: 907 - 
912. 
[6] 
Cobb, S. C., Bazett-Jones, D. M., Joshi, M. N., Earl-Boehm, J. E. & James, C. R. 
(2014). The relationship among foot posture, core and lower extremity muscle 
function, and postural stability. Journal of athletic training, 49 (2): 173 - 80. 
[7] 
Li, S., Zhuang, C., Hao, M., He, X., Marquez, J. C., Niu, C. M. & Lan, N. (2015). 
Coordinated alpha and gamma control of muscles and spindles in movement and 
posture. Frontiers in computational neuroscience, 9: 122. 
[8] 
Beaudette, S. M., Zwambag, D. P., Bent, L. R. & Brown, S. H. M. (2017). Spine 
postural change elicits localized skin structural deformation of the trunk dorsum in 
vivo. Journal of the mechanical behavior of biomedical materials, 67: 31 - 39. 
[9] 
Whipple, R., Wolfson, L., Derby, C., Singh, D. & Tobin, J. (1993). Altered sensory 
function and balance in older persons. Journal of Gerontology, 48 Spec No: 71 - 76. 
[10] Helbostad, J. L., Vereijken, B., Hesseberg, K. & Sletvold, O. (2009). Altered vision 
destabilizes gait in older persons. Gait Posture, 30 (2): 233 - 238. 

Posturology: The Scientific Investigation of Postural Disorders 
 
511
[11] Thomas, E., Martines, F., Bianco, A., Messina, G., Giustino, V., Zangla, D., Iovane, A. 
& Palma, A. (2018). Decreased postural control in people with moderate hearing loss. 
Medicine (Baltimore), 97 (14): e0244. 
[12] Sung, P. S. & Maxwell, M. J. (2017). Kinematic chain reactions on trunk and dynamic 
postural steadiness in subjects with recurrent low back pain. Journal of biomechanics, 
59: 109 -115. 
[13] Fortin, C., Feldman, D. E., Tanaka, C., Houde, M. & Labelle, H. (2012). Inter-rater 
reliability of the evaluation of muscular chains associated with posture alterations in 
scoliosis. BMC musculoskeletal disorders, 13: 80. 
[14] Hamaoui, A., Friant, Y. & Le Bozec, S. (2011). Does increased muscular tension along 
the torso impair postural equilibrium in a standing posture?. Gait Posture, 34 (4): 457 - 
461. 
[15] Salvago, P., Rizzo, S., Bianco, A. & Martines, F. (2017). Sudden sensorineural hearing 
loss: is there a relationship between routine haematological parameters and audiogram 
shapes?. International Journal of Audiology, 56 (3): 148 - 153. 
[16] Scorpecci, A., Massoud, M., Giannantonio, S., Zangari, P., Lucidi, D., Martines, F., 
Foligno, S., Di Felice, G., Minozzi, A., Luciani, M. & Marsella, P. (2018). Otogenic 
lateral sinus thrombosis in children: proposal of an experience-based treatment 
flowchart. Eur. Arch. Otorhinolaryngol., 275 (8): 1971 - 1977. 
[17] Tjernström, F., Fransson, P. A., Holmberg, J., Karlberg, M. & Magnusson, M. (2009). 
Decreased postural adaptation in patients with phobic postural vertigo — an effect of 
an “anxious” control of posture?. Neuroscience letters, 454 (3): 198 - 202. 
[18] Sasaki, O., Gagey, P. M., Ouaknine, A. M., Martinerie, J., Le Van Quyen, M., Toupet, 
M. & L’Heritier, A. (2001). Nonlinear analysis of orthostatic posture in patients with 
vertigo or balance disorders. Neuroscience letters, 41 (2): 185 - 192. 
[19] Borel, L., Lopez, C., Péruch, P. & Lacour, M. (2008). Vestibular syndrome: a change 
in internal spatial representation. Neurophysiol Clin., 38 (6): 375 - 389. 
[20] Di Stadio, A., Dipietro, L., Toffano, R., Burgio, F., De Lucia, A., Ippolito, V., 
Garofalo, S., Ricci, G., Martines, F., Trabalzini, F. & Della Volpe, A. (2018). Working 
Memory Function in Children with Single Side Deafness Using a Bone-Anchored 
Hearing Implant: A Case-Control Study. Audiol Neurootol, 23 (4): 238 - 244. 
[21] Kogler, A., Lindfors, J., Odkvist, L. M. & Ledin, T. (2000). Postural stability using 
different neck positions in normal subjects and patients with neck trauma. Acta 
Otolaryngol., 120 (2): 151 - 155. 
[22] Thomas, E., Ferrara, S., Messina, G., Passalacqua, M. I., Rizzo, S., Salvago, P., Palma, 
A. & Martines, F. (2017). The motor development of preterm infants after the neonatal 
intensive care unit. Neonatal Intensive Care Units (NICUs): Clinical and Patient 
Perspectives, Levels of Care and Emerging Challenges. 
[23] Staab, J. P., Balaban, C. D. & Furman, J. M. (2013). Threat assessment and 
locomotion: clinical applications of an integrated model of anxiety and postural 
control. Seminars in neurology, 33 (3): 297 - 306. 

Giuseppe Messina, Valerio Giustino, Francesco Dispenza et al. 
 
512
[24] Coco, M., Fiore, A. S., Perciavalle, V., Maci, T., Petralia, M. C., Perciavalle, V. 
(2015). Stress exposure and postural control in young females. Molecular medicine 
reports, 11 (3): 2135 - 2140. 
[25] Barcellona, M., Giustino, V., Messina, G., Battaglia, G., Fischetti, F., Palma, A. & 
Iovane, A. (2018). Effects of a specific training protocol on posturographic parameters 
of a taekwondo elite athlete and implications on injury prevention: A case study. Acta 
Medica Mediterranea, 34: 1533 - 1538. 
[26] Goulème, N., Gérard, C. L. & Bucci, M. P. (2015). The Effect of Training on Postural 
Control in Dyslexic Children. PLoS One, 10 (7): e0130196. 
[27] Bellafiore, M., Battaglia, G., Bianco, A., Paoli, A., Farina, F. & Palma, A. (2011). 
Improved postural control after dynamic balance training in older overweight women. 
Aging clinical and experimental research, 23 (5-6): 378 - 385. 
[28] Hlavenka, T. M., Christner, V. F. K. & Gregory, D. E. (2017). Neck posture during 
lifting and its effect on trunk muscle activation and lumbar spine posture. Applied 
ergonomics, 62: 28 - 33. 
[29] Caneiro, J. P., O’Sullivan, P., Burnett, A., Barach, A., O’Neil, D., Tveit, O. & 
Olafsdottir, K. (2010). The influence of different sitting postures on head/neck posture 
and muscle activity. Manual therapy, 15 (1): 54 - 60. 
[30] Battaglia, G., Giustino, V., Iovane, A., Bellafiore, M., Martines, F., Patti, A., Traina, 
M., Messina, G. & Palma, A. (2016). Influence of occlusal vertical dimension on 
cervical spine mobility in sports subjects. Acta Medica Mediterranea, 32: 1589 - 1595. 
[31] De Giorgi, I., Castroflorio, T., Cugliari, G. & Deregibus, A. (2018). Does occlusal 
splint affect posture? A randomized controlled trial. Cranio, 1 - 9. 
[32] Kendall, J. C., Bird, A. R. & Azari, M. F. (2014). Foot posture, leg length discrepancy 
and low back pain — their relationship and clinical management using foot orthoses — 
an overview. Foot (Edinb), 24 (2): 75 - 80. 
[33] Ferreira, E. A., Duarte, M., Maldonado, E. P., Bersanetti, A. A., Marques, A. P. (2011). 
Quantitative assessment of postural alignment in young adults based on photographs of 
anterior, posterior, and lateral views. J Manipulative Physiol Ther, 34 (6): 371 - 380. 
[34] Scoppa, F., Gallamini, M., Belloni, G. & Messina, G. (2017). Clinical stabilometry 
standardization: Feet position in the static stabilometric assessment of postural 
stability. Acta Medica Mediterranea, 33: 707 - 713. 
[35] Rode, G., Tiliket, C., Charlopain, P., Boisson D. (1998). Postural asymmetry reduction 
by vestibular caloric stimulation in left hemiparetic patients. Scand J Rehabil Med, 30 
(1): 9 - 14. 
[36] Ohlendorf, D., Riegel, M., Lin Chung, T., Kopp, S. (2013). The significance of lower 
jaw position in relation to postural stability. Comparison of a premanufactured occlusal 
splint with the Dental Power Splint. Minerva Stomatol, 62 (11 - 12): 409 - 417. 
[37] Whitney, S. L., Alghwiri, A., Alghadir, A. (2015). Physical therapy for persons with 
vestibular disorders. Curr Opin Neurol, 28 (1): 61 - 68. 

In: Encyclopedia of Audiology and Hearing Research 
ISBN: 978-1-53617-702-2 
Editors: Erno Larivaara and Senja Korhola 
© 2020 Nova Science Publishers, Inc. 
 
 
 
 
 
 
 
Chapter 34 
 
 
 
THE INFLUENCE OF OTOVESTIBULAR SYSTEM  
ON BODY POSTURE 
 
 
Francesco Martines1,2,, MD, PhD, Valerio Giustino3,  
Francesco Dispenza1,4, MD, PhD, Francesco Galletti5,  
Angelo Iovane6, MD, Serena Rizzo7, MD  
and Giuseppe Messina6,8, MD 
1Istituto Euromediterraneo di Scienza e Tecnologia – IEMEST, Palermo, Italy 
2Bio. Ne. C. Department, Audiology Section, University of Palermo, Palermo, Italy 
3PhD Program in Health Promotion and Cognitive Sciences,  
University of Palermo, Palermo, Italy  
4A.O.U.P. Paolo Giaccone, Palermo, Italy 
5Department of Otorhinolaryngology,  
University of Messina, Messina, Italy 
6Department of Psychology, Educational Science and Human Movement,  
University of Palermo, Palermo, Italy 
7Di. Chir.On.S. Department, Physical medicine and rehabilitation,  
University of Palermo, Palermo, Italy 
8PosturaLab Italia Research Institute, Palermo, Italy 
 
 
ABSTRACT 
 
It is well-known that body posture is controlled by an integration, at the level of the 
central nervous system, of afferences coming from various organs that influences the 
tonic postural system responsible for the alignment of the skeletal body segment of the 
human body, for balance and for postural control. Many studies have shown that the 
auditory and the vestibular systems contribute significantly to posture. The scientific 
literature reported that patients suffering from hearing impairment or vestibular disorders 
may be affected by loss of balance or inability to maintain postural control. Furthermore, 
                                                        
 Corresponding Author’s Email: francescomartines@hotmail.com. 

Francesco Martines, Valerio Giustino, Francesco Dispenza et al. 
 
514
many researchers have demonstrated a significant correlation between hearing loss and 
the risk of falling. Non-physiological sensory information from the otovestibular system 
negatively interferes on posture inducing asymmetrical muscular tensions that determines 
postural disorders. In these patients, a postural sway analysis, using a stabilometric 
platform, and a gait analysis, through a dynamic baropodometric test, can be considered 
in order to measure their ability to maintain static and dynamic balance and to examine 
their potential improvement after an otovestibular rehabilitation. The aim of this work is 
to investigate the influence of hearing loss and vestibular disorders on body posture. 
 
Keywords: body balance, vestibular disorders, hearing loss 
 
 
THE OTOVESTIBULAR SYSTEM 
 
Among the sensory organs, the otovestibular apparatus represents a complex system able 
to project to the central nervous system the sensory information concerning auditory, sense of 
position, and perception of movement in the space of the head in order to regulate 
approppriately static and dynamic body balance [1]. 
The cochlea is an auditory organ responsible for the transduction of mechanical waves 
into electrical signals that reach the central nervous system (CNS) through the cochlear nerve. 
Regarding the vestibular component, the afferents from this apparatus are integrated at the 
level of the central nervous system (CNS) in addition to the visuo-oculomotor and 
proprioceptive information. Consequently, the CNS produces efferent responses to the ocular 
muscles and the spinal cord, generating the vestibulo-ocular reflex (VOR) and the 
vestibulospinal reflex (VSR). The latter generates compensatory movements in order to 
regulate and maintain body balance, the former movements of the oculomotor muscles in base 
of changing head positions [1]. Both reflexes are fundamental to adjust and control body 
balance. 
The cochlea as well as the vestibule are located in the inner ear and both sensory 
information coming from these organs influences human posture [2-6].  
 
 
OTOVESTIBULAR SENSORY INFORMATIONS 
 
Although it is well-known that all the sensory systems contribute to the regulation of 
posture and to the maintenance of balance, a physiological prevalence of discernment of 
sensory informations in correlation with age exists [7]. In particular, at birth, body posture 
depends mainly on labyrinthic and sound stimuli, whereas when the human being adopts a 
bipedal stance, the static postural control is managed above all by proprioceptive inputs from 
the foot and the paravertebral muscles instead, and for the dynamic postural control, from 
visual afferences. However, the scientific literature has demonstrated the importance of 
audio-vestibular sensory information on body posture in children as well as in elderly [8-12]. 
 
 
 
 

The Influence of Otovestibular System on Body Posture 
 
515
OTOVESTIBULAR DISORDERS AND BODY BALANCE 
 
As the regulation of the activity of the tonic postural system and the abilty to maintain 
body balance depends on all the sensory postural receptors, a physiological decline of the 
audio-vestibular system, hearing impairment, or vestibular disorders affect body balance [13-
17]. In particular, hearing loss, the most common sensorial deterioration, has disadvantageous 
effects on the life quality and, among the adverse consequences, causes a possible alteration 
on body balance increasing the risk of falling especially in the elderly [18-21]. Likewise, it is 
widely recognized that, vestibular disorers such as tinnitus, vertigo, or dizziness have a 
significant impact on physiological and vital functions, and moreover, negatively influence 
postural control [16, 22-25]. 
In patients with damaging/disease of a sensory organ, the use of assistive devices, such as 
hearing aids or cochlear implants for the audio-vestibular system, can improve daily activities 
and, in general, the quality of life [8, 26, 27]. 
 
 
POSTUROGRAPHY: A QUANTITATIVE ASSESSMENT 
OF BODY BALANCE 
 
The posturography allows the measurement of muscular activity of the tonic postural 
system. In these patients, this instrumental postural assessment is fundamental in order to 
measure their ability to maintain static and dynamic balance, and moreover, to examine any 
change after an otovestibular rehabilitation or a cochlear implant surgery [27-30]. In 
particular, by means of a baropodometric platform, it is possible to evaluate postural sway 
analysis, through a stabilometric test, and a gait analysis, through a dynamic baropodometric 
test [31].  
Through the stabilometry it is possible to analyze the statokinesigram graph, i.e., the path 
of the center of pressure (CoP) and the surface that contains the movement of the CoP (the 
Sway Path Length (SPL) and the Ellipse Sway Area (ESA) respectively), and the stabilogram 
graph that shows the CoP displacement during the time distinguished by direction 
(backwards/forwards and medial/lateral sway). 
 
 
Figure 1. Statokinesigram (on the left) and stabilogram (on the right) of the stabilometric test. 
http://posturografia.it/wp-content/uploads/2017/04/posturografia_11.jpg.  

Francesco Martines, Valerio Giustino, Francesco Dispenza et al. 
 
516
 
Figure 2. Stabilometric test. 
 
Figure 3. Study of the gait analysis through a dynamic baropodometric test 
http://pedanabaropodometrica.it/wp-content/uploads/2017/05/pedanabaropodometrica_ 
10.jpg.  
 
Figure 4. Baropodometric test https://www.sensormedica.com/site/images/pedana_120_50.jpg. 
As sensitive and specific measures are a priority in order to detect vestibular disorders, Di 
Fabio has investigate the sensitivity and specificity of static and dinamic posturography to 
identify these patients [32]. The author shows that the posturography, if applied in isolation, 

The Influence of Otovestibular System on Body Posture 
 
517
turns out to be ineffective, in terms of sensitivity, to detect vestibular impairment. However, 
the association of posturography with the other vestibular function tests increased the 
sensitivity of identifying vestibular deficits from 61% to 89%. 
 
 
INFLUENCE OF OTOVESTIBULAR SYSTEM ON BODY BALANCE 
 
Many authors have investigated the impact of auditory stimuli, in terms of frequency, 
intensity, as well as sound duration, on body balance and the relationship between hearing 
loss and the risk of fall [7, 10, 14, 20, 21, 27, 29].  
Although Mainenti et al. reported no significant differences on stabilometric parameters 
when subjects were submitted to different types of sound stimulation [33], contrarily, Raper 
and Soames [34] showed higher sway in sound conditions compared with no sound condition, 
with frequency stimulations at 250 Hz. In addition, a study by Park et al. reported that the 
Sway Path Length on the anterior-posterior axis increased with higher frequencies of sound 
[35]. Siedlecka et al. suggested that sound stimuli with frequencies from 1000 Hz to 4000 Hz 
influence cody stability [3]. 
Many studies have examined the role of sound intensity on body posture and the results 
seems to indicate that sound intensity higher than 90 dB affects postural stability [3, 36].  
As reported in the scientific literature, sound duration affects body sway [33, 37, 38]. In 
particular, Kapoula et al. performed a stabilometry for 51.2 seconds finding a significant 
affect of sound disturbances on postural sway in patients with highly modulated tinnitus [37]. 
Contrariwise, many researches reported no significant influence when the stabilometric tests 
were performed for 20 or 30 seconds [33, 38]. 
 
 
THE ROLE OF PHYSICAL ACTIVITY ON BODY BALANCE 
 
The scientific literature reported that, among the intrinsic factors, falls are related to the 
physiological decline of hearing, hearing impairments and vestibular disorders [39]. It is well-
known that, among the treatments, exercise improves balance ability that induces a 
consequent fall reduction, and proves to be an effective intervention of falls prevention, in 
particular for older people [40, 41, 42]. The literature seems to be in agreement that balance 
exercises appears to be the most efficacious type of physical activity in order to improve body 
stability [43]. 
 
 
REFERENCES 
 
[1] 
Spasiano, R., Mira, E. (2005). Anatomia e fisiologia del sistema vestibolare. Clinica 
delle labirintopatie periferiche, 45 - 64. 
[2] 
Zhong, X., Yost, W. A. (2013). Relationship between postural stability and spatial 
hearing. J Am Acad Audiol, 24 (9): 782 - 788. 
[3] 
Siedlecka, B., Sobera, M., Sikora, A., Drzewowska, I. (2015). The influence of sounds 
on posture control. Acta Bioeng Biomech, 17 (3): 96 - 102. 

Francesco Martines, Valerio Giustino, Francesco Dispenza et al. 
 
518
[4] 
Sakellari, V., Soames, R. W. (1996). Auditory and visual interactions in postural 
stabilization. Ergonomics, 39 (4): 634 - 648. 
[5] 
Lopez, C. (2015). Making Sense of the Body: the Role of Vestibular Signals. Multisens 
Res, 28 (5-6): 525 - 557. 
[6] 
Guerraz, M., Day, B. L. (2005). Expectation and the vestibular control of balance. J 
Cogn Neurosci, 17 (3): 463 - 469. 
[7] 
Thomas, E., Bianco, A., Messina, G., Mucia, M., Rizzo, S., Salvago, P., Sireci F., 
Palma, A. and Martines, F. (2017). The influence of sounds in postural control. Hearing 
Loss: etiology, management and societal implications, 1 - 12. 
[8] 
Ebrahimi, A. A., Movallali, G., Jamshidi, A. A., Haghgoo, H. A., Rahgozar, M. (2016). 
Balance Performance of Deaf Children With and Without Cochlear Implants. Acta Med 
Iran, 54 (11): 737 - 742. 
[9] 
Huang, M. W., Hsu, C. J., Kuan, C. C., Chang, W. H. (2011). Static balance function in 
children with cochlear implants. Int J Pediatr Otorhinolaryngol, 75 (5): 700 - 703. 
[10] Thomas, E., Martines, F., Bianco, A., Messina, G., Giustino, V., Zangla, D., Iovane, A., 
Palma, A. (2018). Decreased postural control in people with moderate hearing loss. 
Medicine (Baltimore), 97 (14): e0244. 
[11] Davis, A., McMahon, C. M., Pichora-Fuller, K. M., Russ, S., Lin, F., Olusanya, B. O., 
Chadha, S., Tremblay, K. L. (2016). Aging and Hearing Health: The Life-course 
Approach. Gerontologist, 56 Suppl 2: S 256 - 267. 
[12] Criter, R. E., Honaker, J. A. (2017). Fall risk screening protocol for older hearing clinic 
patients. Int J Audiol, 56 (10): 767 - 774. 
[13] Melo Rde, S., Lemos, A., Macky, C. F., Raposo, M. C., Ferraz, K. M. (2015). Postural 
control assessment in students with normal hearing and sensorineural hearing loss. Braz 
J Otorhinolaryngol, 81 (4): 431 - 438. 
[14] Rumalla, K., Karim, A. M., Hullar, T. E. (2015). The effect of hearing aids on postural 
stability. Laryngoscope, 125 (3): 720 - 723. 
[15] Martines, F., Messina, G., Patti, A., Battaglia, G., Bellafiore, M., Messina, A., Rizzo, 
S., Salvago, P., Sireci, F., Traina, M., Iovane, A. (2015). Effects of tinnitus on postural 
control and stabilization: A pilot study. Acta Medica Mediterranea, 31: 907 - 912. 
[16] Schlick, C., Schniepp, R., Loidl, V., Wuehr, M., Hesselbarth, K., Jahn, K. (2016). Falls 
and fear of falling in vertigo and balance disorders: A controlled cross-sectional study. 
J Vestib Res, 25 (5-6): 241 - 251. 
[17] Söhsten, E., Bittar, R. S., Staab, J. P. (2016). Posturographic profile of patients with 
persistent postural-perceptual dizziness on the sensory organization test. J Vestib Res, 
26 (3): 319 - 326. 
[18] Salvago, P., Rizzo, S., Bianco, A., Martines, F. (2017). Sudden sensorineural hearing 
loss: is there a relationship between routine haematological parameters and audiogram 
shapes? International Journal of Audiology, 56 (3): 148 - 153. 
[19] Di Stadio, A., Dipietro, L., Toffano, R., Burgio, F., De Lucia, A., Ippolito, V., Garofalo, 
S., Ricci, G., Martines, F., Trabalzini, F., Della Volpe, A. (2018). Working Memory 

The Influence of Otovestibular System on Body Posture 
 
519
Function in Children with Single Side Deafness Using a Bone-Anchored Hearing 
Implant: A Case-Control Study. Audiol Neurootol, 23 (4): 238 - 244. 
[20] Jiam, N. T., Li, C., Agrawal, Y. (2016). Hearing loss and falls: A systematic review and 
meta-analysis. Laryngoscope, 126 (11): 2587 - 2596. 
[21] Agmon, M., Lavie, L., Doumas, M. (2017). The Association between Hearing Loss, 
Postural Control, and Mobility in Older Adults: A Systematic Review. J Am Acad 
Audiol, 28 (6): 575 - 588. 
[22] Matsushima, J. I., Sakai, N., Ifukube, T. (1999). Effects of tinnitus on posture: a study 
of electrical tinnitus suppression. Int Tinnitus J, 5 (1): 35 - 39. 
[23] Lin, H. W., Bhattacharyya, N. (2014). Impact of dizziness and obesity on the 
prevalence of falls and fall-related injuries. Laryngoscope, 124 (12): 2797 - 2801. 
[24] Scorpecci, A., Massoud, M., Giannantonio, S., Zangari, P., Lucidi, D., Martines, F., 
Foligno, S., Di Felice, G., Minozzi, A., Luciani, M., Marsella, P. (2018). Otogenic 
lateral sinus thrombosis in children: proposal of an experience-based treatment 
flowchart. Eur. Arch. Otorhinolaryngol., 275 (8): 1971 - 1977. 
[25] Thomas, E., Ferrara, S., Messina, G., Passalacqua, M. I., Rizzo, S., Salvago, P., Palma, 
A., Martines, F. (2017). The motor development of preterm infants after the neonatal 
intensive care unit. Neonatal Intensive Care Units (NICUs): Clinical and Patient 
Perspectives, Levels of Care and Emerging Challenges. 
[26] Battaglia, G., Giustino, V., Iovane, A., Bellafiore, M., Martines, F., Patti, A., Traina, 
M., Messina, G., Palma, A. (2016). Influence of occlusal vertical dimension on cervical 
spine mobility in sports subjects. Acta Medica Mediterranea, 32: 1589 - 1595. 
[27] Shayman, C. S., Earhart, G. M., Hullar, T. E. (2017). Improvements in Gait With 
Hearing Aids and Cochlear Implants. Otol Neurotol, 38 (4): 484 - 486. 
[28] Whitney, S. L., Marchetti, G. F., Schade, A. I. (2006). The relationship between falls 
history and computerized dynamic posturography in persons with balance and 
vestibular disorders. Arch Phys Med Rehabil, 87 (3): 402 - 407. 
[29] Soto-Varela, A., Gayoso-Diz, P., Rossi-Izquierdo, M., Faraldo-García, A., Vaamonde-
Sánchez-Andrade, I., del-Río-Valeiras, M., Lirola-Delgado, A., Santos-Pérez, S. 
(2015). Reduction of falls in older people by improving balance with vestibular 
rehabilitation (ReFOVeRe study): design and methods. Aging Clin Exp Res, 27 (6): 841 
- 848. 
[30] Vitkovic, J., Le, C., Lee, S. L., Clark, R. A. (2016). The Contribution of Hearing and 
Hearing Loss to Balance Control. Audiol Neurootol, 21 (4): 195 - 202. 
[31] Scoppa, F., Gallamini, M., Belloni, G., Messina, G. (2017). Clinical stabilometry 
standardization: Feet position in the static stabilometric assessment of postural stability. 
Acta Medica Mediterranea, 33: 707 - 713. 
[32] Di Fabio, R. P. (1995). Sensitivity and specificity of platform posturography for 
identifying patients with vestibular dysfunction. Phys Ther, 75 (4): 290 - 305. 
[33] Mainenti, M. R., De Oliveira, L. F., De Melo Tavares De Lima, M. A., Nadal, J. (2007). 
Stabilometric signal analysis in tests with sound stimuli. Exp Brain Res, 181 (2): 229 - 
236. 

Francesco Martines, Valerio Giustino, Francesco Dispenza et al. 
 
520
[34] Raper, S. A., Soames, R. W. (1991). The influence of stationary auditory fields on 
postural sway behaviour in man. Eur J Appl Physiol Occup Physiol, 63 (5): 363 - 367. 
[35] Park, S. H., Lee, K., Lockhart, T., Kim, S. (2011). Effects of sound on postural stability 
during quiet standing. J Neuroeng Rehabil, 8: 67. 
[36] Tanaka, T., Kojima, S., Takeda, H., Ino, S., Ifukube, T. (2001). The influence of 
moving auditory stimuli on standing balance in healthy young adults and the elderly. 
Ergonomics, 44 (15): 1403 - 1412. 
[37] Kapoula, Z., Yang, Q., Lê, T. T., Vernet, M., Berbey, N., Orssaud, C., Londero, A., 
Bonfils, P. (2011). Medio-lateral postural instability in subjects with tinnitus. Front 
Neurol, 2: 35. 
[38] Alessandrini, M., Lanciani, R., Bruno, E., Napolitano, B., Di Girolamo, S. (2006). 
Posturography frequency analysis of sound-evoked body sway in normal subjects. Eur 
Arch Otorhinolaryngol, 263 (3): 248 - 252. 
[39] Callis, N. (2016). Falls prevention: Identification of predictive fall risk factors. Appl 
Nurs Res, 29: 53 - 58. 
[40] Battaglia, G., Bellafiore, M., Bianco, A., Paoli, A., Palma, A. (2010). Effects of a 
dynamic balance training protocol on podalic support in older women. Pilot Study. 
Aging Clin Exp Res, 22 (5-6): 406 - 411. 
[41] Barcellona, M., Giustino, V., Messina, G., Battaglia, G., Fischetti, F., Palma, A., 
Iovane, A. (2018). Effects of a specific training protocol on posturographic parameters 
of a taekwondo elite athlete and implications on injury prevention: A case study. Acta 
Medica Mediterranea, 34: 1533 - 1538. 
[42] Puccio, G., Giuffré, M., Piccione, M., Piro, E., Malerba V., Corsello. G. (2014) 
Intrauterine growth pattern and birthweight discordance in twin pregnancies: a 
retrospective study. Ital J Pediatr, 40:43. doi: 10.1186/1824-7288-40-43 
[43] Sherrington, C., Whitney, J. C., Lord, S. R., Herbert, R. D., Cumming, R. G., Close, J. 
C. (2008). Effective exercise for the prevention of falls: a systematic review and meta-
analysis. J Am Geriatr Soc, 56 (12): 2234 - 2243. 

In: Encyclopedia of Audiology and Hearing Research 
ISBN: 978-1-53617-702-2 
Editors: Erno Larivaara and Senja Korhola 
© 2020 Nova Science Publishers, Inc. 
 
 
 
 
 
 
 
Chapter 35 
 
 
 
AUDITORY BRAINSTEM RESPONSE AND  
FREQUENCY FOLLOWING RESPONSE IN PATIENTS 
WITH SICKLE CELL DISEASE 
 
 
Adriana L. Silveira1,*, Adriane R. Teixeira1,†,  
Christina M. Bittar2, João Ricardo Friedrisch2,  
Daniela P. Dall’Igna2 and Sergio S. Menna Barreto2 
1Children and Adolescent Health Post Graduate Program,  
Universidade Federal do Rio Grande do Sul and Speech Therapy  
and Audiology Service, Hospital de Clínicas de Porto Alegre,  
Porto Alegre, Rio Grande do Sul, Brazil 
2Health and Human Communication Department,  
Universidade Federal do Rio Grande do Sul and Speech Therapy  
and Audiology Service, Hospital de Clínicas de Porto Alegre,  
Porto Alegre, Rio Grande do Sul, Brazil 
 
 
ABSTRACT 
 
The aim of this study was to analyze the auditory brainstem response (ABR) and 
frequency following response (FFR) in patients diagnosed with Sickle Cell Disease 
(SCD) who were referred to the outpatient hemoglobinopathy clinic at a public hospital 
in southern Brazil. Fifty-four individuals aged between 6 and 24 years [mean age ± SD 
(years), 14.1 ± 4.6] were evaluated. Pure tone audiometry, high frequency tonal 
audiometry, tympanometry, and transient evoked otoacoustic emission for determination 
of peripheral normality were performed; the overall results indicted normal auditory 
thresholds in all individuals. Subsequently, electrophysiological evaluations including 
ABR and FFR were performed; the analysis of the ABR responses revealed an alteration 
in 88.9% of the individuals and that of FFR in 98.1%. The achievement of auditory 
thresholds within the normal range and presence of otoacoustic emissions enabled but did 
not guarantee excellence in the auditory pathway of the evaluated individuals.  
                                                        
* Corresponding Author’s Email: alsilveira@hcpa.edu.br. 
† Corresponding Author’s Email: adriane.teixeira@gmail.com. 

Adriana L. Silveira, Adriane R. Teixeira, Christina M. Bittar et al. 
 
522
Keywords: sickle cell disease, hearing, auditory evoked potentials, electrophysiology 
 
 
INTRODUCTION 
 
Sickle cell disease (SCD) is an inherited disease characterized by abnormality of the 
hemoglobin in the red blood cell. Hemoglobin is composed of proteins and iron which 
imparts a red color to the blood and allows the fixation of oxygen for transport to the cells of 
tissues and organs in the living organism. During periods of decreased oxygen tension in the 
red blood cell’s environment, the abnormal hemoglobin content results in the transformation 
to a sickle cell pattern. The morphological and associated physiological changes drastically 
reduce the ability of the red blood cells to navigate and provide oxygen throughout the body 
[1]. 
The World Health Organization report indicates that SCD is a common disease, affecting 
approximately 5% of the world’s population [2]. In Brazil, it is the most prevalent genetic 
disease, predominantly affecting individuals of Black/African ethnicity, with heterogeneous 
distribution among the regions. The diagnosis is made through the foot test on the 5th day of 
life [3]. The prevalence rate is approximately 6 to 10% in the north and northeast regions and 
at a lower rate of 2 and 3% in the south and southeast regions. The prevalence rate in Rio 
Grande do Sul is estimated at only 2% of the present population [4]. 
Due to the vaso-occlusive nature of SCD, there is potential for hearing damage. The 
relationship between SCD and peripheral hearing loss has been reported, but the studies 
reveal variable findings. Some reports have indicated that peripheral hearing loss is correlated 
with possible damage caused by low oxygenation of the cochlea in patients with vaso-
occlusions through the disease [1, 5, 6]. Other reports have indicated that neurological 
symptoms could lead to central impairment [6, 7]. The discrepancies between studies could 
be due to the differences in audiological evaluation and incidence of hearing loss of 12 to 
66% [6]. 
The auditory changes impact the individual’s quality of life through the difficulty in 
analyzing sound information as well as overall communication impairment. There are no 
studies to investigate the speech-evoked ABR in this population; hence, research in this field 
is of interest. 
This study aimed to analyze the ABR and FFR in patients diagnosed with SCD with 
normal peripheral auditory evaluation. 
 
 
METHODS 
 
This was an observational cross-sectional case series study of patients referred to the 
hemoglobinopathy outpatient clinic at a public hospital in Rio Grande do Sul, Brazil 
(southern region of the country). The study was approved by the Research Ethics Committee 
at the hospital where the study was developed (number 44486215000005327) and conducted 
under ethical principles that protect the rights, dignity, and well-being of the participants. 
Patients of the age group of 6 to 24 years were included. The exclusion criteria were the 
presence of clinically relevant comorbidities, quitting during the evaluation, and unilateral or 
bilateral peripheral hearing loss. 

Auditory Brainstem Response and Frequency … 
 
523
Table 1. Parameters and Range of Normality Considered for ABR and FFR 
 
ABR 
FFR 
Parameters Used 
Stimulus 
click 
Stimulus 
syllable [da_40 ms] 
Number of sweeps 
2 cycles 2048 
Number of sweeps 
3 cycles 
1000 
Presentation 
ipsilateral 
Presentation 
ipsilateral 
Rate 
27.7/s 
Rate 
11.1/s 
Polarity 
rarefied 
Polarity 
alternating 
Window 
12 ms 
Window 
60 ms 
Intensity 
80 dB 
Intensity 
80 dB 
Gain 
100 
Gain 
150 
Low-pass filter 
1.5 KHz 
Low-pass filter 
3.0 KHz 
High-pass filter 
100 Hz 
High-pass filter 
100 Hz 
Rejection EEG 
20% 
Rejection EEG 
30% 
Range of Normality Considered 
Measure 
Latency (ms) 
Measure 
Latency (ms) 
Amplitude (mV) 
Wave I 
1.11-2.07 
Wave III 
3.30-3.98 
Wave V 
6.11-7.11 
0.16-0.46 
Wave V 
5.25-5.89 
Wave A 
6.83-8.19 
(-0.27)–(-1.03) 
Interpeak I-III 
1.91-2.19 
VA Complex 
0.51-1.27 
0.41-1.53 
Interpeak III-V 
1.91-1.95 
Peak C 
16.73-18.65 
(-0.18)–(-0.54) 
Interpeak I-V 
3.48-4.48 
Peak F 
38.51-40.95 
(-0.24)–(-0.62) 
ms, milisecond; dB, decibel; Hz, hertz; V, microvolt. 
 
The sequence of evaluations was as follows: tonal threshold audiometry, high frequency 
tonal audiometry, tympanometry, transient evoked otoacoustic emission, ABR, and FFR 
(syllable /da/). Equipment used for the evaluations were: AC-40 (Interacoustics), AT235h 
(Interacoustics), Eclipse EP25 (Interacoustics), and SmpartEP (Intelligent Hearing Systems). 
The first four exams were used only to establish peripheral normality. 
The parameters for obtaining recordings for both the uptake and range of normality for 
ABR and FFR are described in Table 1. The parameters were adapted from the equipment 
protocol [8] for ABR, and those of Russo et al. [9] and Gonçalves [10] for FFR. To determine 
the range of normality, two standard deviations of each measurement were considered, except 
for those for the amplitude of Wave V and Peak F that considered only one deviation due to 
asymmetry of the distribution under neural conduction. The tracings were analyzed and sent 
to two audiologists for judgment of the demarcation of the waves. 
 
 
RESULTS 
 
We evaluated 54 patients with a medical diagnosis of SCD, with mean age of 14.1 years. 
The sample was distributed in three age groups: twelve years-old (17 subjects, 31.5%); 12 to 
18 years-old (24 subjects, 44.4%); 18 to 24 years-old (13 subjects, 24.1%). Twenty-four male 
individuals (44.4%) and 30 female individuals (55.6%) participated. 
The ABR with click stimulus revealed a change in 88.9% of the sample, and the increase 
of absolute latency of waves III and V and interpeak I-III were predominant. There were no 
significant differences between the latencies obtained between the bilateral ears (Table 2); 

Adriana L. Silveira, Adriane R. Teixeira, Christina M. Bittar et al. 
 
524
however, there was greater impairment in the male individuals and age group of 12 to 18 
years-old (Table 3). 
 
Table 2. Comparison of ABR results between the bilateral ears 
 
Variables 
Right Ear 
Left Ear 
p 
Mean ± SD 
Mean ± SD 
Wave I 
1.78 ± 0.10  
1.76 ± 0.14 
0.167 
Wave III 
3.98 ± 0.16 
3.98 ± 0.18 
0.873 
Wave V 
5.90 ± 0.20 
5.90 ± 0.17 
0.844 
I-III 
2.20 ± 0.16 
2.21 ± 0.17 
0.303 
III-V 
1.92 ± 0.11 
1.92 ± 0.09 
0.931 
I-V 
4.12 ± 0.20 
4.14 ± 0.19 
0.365 
SD, standard deviation. 
 
Table 3. Comparison of changes in ABR results according to sex and age group 
 
Variables 
Ears 
Total Sample 
Female  
Male  
p 
n (%) 
n (%) 
n (%) 
click 
 
 
 
 
 
Wave I 
Right 
1 (1.9) 
0 (0.0) 
1 (4.2) 
0.444 
 
Left 
3 (5.6) 
2 (6.7) 
1 (4.2) 
1.000 
Wave III 
Right 
26 (48.1) 
11 (36.7) 
15 (62.5) 
0.107 
 
Left 
23 (42.6) 
9 (30.0) 
14 (58.3) 
0.069 
Wave V 
Right 
31 (57.4) 
12 (40.0) 
19 (79.2) 
0.009 
 
Left 
28 (51.9) 
13 (43.3) 
15 (62.5) 
0.260 
I-III 
Right 
30 (55.6) 
11 (36.7) 
19 (79.2) 
0.004 
 
Left 
35 (64.8) 
15 (50.0) 
20 (83.3) 
0.024 
III-V 
Right 
18 (33.3) 
7 (23.3) 
11 (45.8) 
0.146 
 
Left 
22 (40.7) 
11 (36.7) 
11 (45.8) 
0.687 
I-V 
Right 
3 (5.6) 
1 (3.3) 
2 (8.3) 
0.579 
 
Left 
3 (5.6) 
0 (0.0) 
3 (12.5) 
0.082 
WaveV interaural differencea 
- 
6 (11.1) 
1 (3.3) 
5 (20.8) 
0.078 
Global Modification 
- 
48 (88.9) 
24 (80.0) 
24 (100) 
0.028 
Variables 
Ears 
<12 years 
12–18 years 
>18 years 
p 
 
 
n (%) 
n (%) 
n (%) 
 
Wave I 
Right 
0 (0.0) 
1 (4.2) 
0 (0.0) 
0.529 
 
Left 
2 (11.8) 
1 (4.2) 
0 (0.0) 
0.350 
Wave III 
Right 
8 (47.1) 
14 (58.3) 
4 (30.8) 
0.276 
 
Left 
8 (47.1) 
13 (54.2) 
2 (15.4) 
0.068 
Wave V 
Right 
10 (58.8) 
17 (70.8) 
4 (30.8) 
0.062 
 
Left 
8 (47.1) 
14 (58.3) 
6 (46.2) 
0.694 
I-III 
Right 
11 (64.7) 
16 (66.7) 
3 (23.1) 
0.026 
 
Left 
10 (58.8) 
20 (83.3) 
5 (38.5) 
0.020 
III-V 
Right 
3 (17.6) 
11 (45.8) 
4 (30.8) 
0.165 
 
Left 
6 (35.3) 
11 (45.8) 
5 (38.5) 
0.781 
I-V 
Right 
0 (0.0) 
2 (8.3) 
1 (7.7) 
0.480 
 
Left 
0 (0.0) 
2 (8.3) 
1 (7.7) 
0.480 
WaveV interaural differencea  
- 
1 (5.9) 
4 (16.7) 
1 (7.7) 
0.503 
Global Modification  
- 
15 (88.2) 
24 (100) 
9 (69.2) 
0.017 
n, number; aWave V interaural difference of latency of ≤0.2 ms is considered as normal. 
 

Auditory Brainstem Response and Frequency … 
 
525
The FFR showed a change in 98.1% of the sample, indicating worse Wave V latency for 
the left ear, and smaller amplitudes of Wave A and Peak F for the right ear (Table 4). There 
was no statistically significant difference between the sexes, but the latency of Wave A was 
later detected in the left ear in the age groups of ≤12 years old and 12 to 18 years old  
(Table 5). 
 
Table 4. Comparison of FFR results between the bilateral ears 
 
Variables 
Right Ear 
Left Ear 
p 
Mean ± SD 
Mean ± SD 
Latency V 
7.10 ± 0.74 
7.37 ± 1.04 
0.018 
Latency A 
8.61 ± 0.95 
8.89 ± 1.22 
0.065 
Latency VA 
1.50 ± 0.56 
1.52 ± 0.53 
0.893 
Latency C 
18.6 ± 1.00 
18.3 ± 1.25 
0.269 
Latency F 
41.1 ± 1.34 
41.5 ± 1.75 
0.098 
Amplitude Va 
0.33 (0.25-0.44) 
0.35 (0.27-0.46) 
0.766 
Amplitude Aa 
0.19 (0.14-0.31) 
0.29 (0.19-0.37) 
0.004 
Amplitude VAa 
0.51 (0.41-0.74) 
0.64 (0.48-0.80) 
0.139 
Amplitude Ca 
0.26 (0.16-0.39) 
0.29 (0.16-0.43) 
0.287 
Amplitude Fa 
0.26 (0.20-0.40) 
0.35 (0.25-0.50) 
0.012 
SD, standard deviation; a described by median (25-75 percentile). 
 
Table 5. Comparison of the alterations of the FFR results according to sex and  
age group 
 
Variables 
Ears 
Total Sample 
Female 
Male 
p 
 
n (%) 
n (%) 
n (%) 
Speech-Evoked 
 
 
 
 
 
Latency V 
Right 
20 (37.0) 
8 (26.7) 
12 (50.0) 
0.139 
Left 
24 (44.4) 
10 (33.3) 
14 (58.3) 
0.118 
Latency A 
Right 
30 (55.6) 
14 (46.7) 
16 (66.7) 
0.232 
Left 
34 (63.0) 
15 (50.0) 
19 (79.2) 
0.055 
Latency VA 
Right 
29 (53.7) 
15 (50.0) 
14 (58.3) 
0.737 
Left 
33 (61.1) 
18 (60.0) 
15 (62.5) 
1.000 
Latency C 
Right 
22 (40.7) 
10 (33.3) 
12 (50.0) 
0.337 
Left 
17 (31.5) 
8 (26.7) 
9 (37.5) 
0.578 
Latency F 
Right 
26 (48.1) 
11 (36.7) 
15 (62.5) 
0.107 
Left 
29 (53.7) 
15 (50.0) 
14 (58.3) 
0.737 
Amplitude V 
Right 
4 (7.4) 
2 (6.7) 
2 (8.3) 
1.000 
Left 
3 (5.6) 
2 (6.7) 
1 (4.2) 
1.000 
Amplitude A 
Right 
34 (63.0) 
19 (63.3) 
15 (62.5) 
1.000 
Left 
25 (46.3) 
16 (53.3) 
9 (37.5) 
0.376 
Amplitude VA 
Right 
12 (22.2) 
6 (20.0) 
6 (25.0) 
0.913 
Left 
9 (16.7) 
5 (16.7) 
4 (16.7) 
1.000 
Amplitude C 
Right 
18 (33.3) 
13 (43.3) 
5 (20.8) 
0.146 
Left 
16 (29.6) 
8 (26.7) 
8 (33.3) 
0.816 
Amplitude F 
Right 
18 (33.3) 
9 (30.0) 
9 (37.5) 
0.771 
Left 
10 (18.5) 
7 (23.3) 
3 (12.5) 
0.483 
Alteration Conduction  
- 
53 (98.1) 
29 (96.7) 
24 (100) 
1.000 
Variables 
Ears 
<12 years 
12 – 18 years 
>18 years 
p 
Latency V 
Right 
7 (41.2) 
11 (45.8) 
2 (15.4) 
0.171 
Left 
9 (52.9) 
13 (54.2) 
2 (15.4) 
0.053 

Adriana L. Silveira, Adriane R. Teixeira, Christina M. Bittar et al. 
 
526
Table 5. (Continued) 
 
Variables 
Ears 
Total Sample 
Female 
Male 
p 
 
n (%) 
n (%) 
n (%) 
Latency A 
Right 
12 (70.6) 
12 (50.0) 
6 (46.2) 
0.313 
Left 
13 (76.5) 
17 (70.8) 
4 (30.8) 
0.021 
Latency VA 
Right 
10 (58.8) 
12 (50.0) 
7 (53.8) 
0.856 
Left 
13 (76.5) 
13 (54.2) 
7 (53.8) 
0.292 
Latency C 
Right 
8 (47.1) 
10 (41.7) 
4 (30.8) 
0.662 
Left 
6 (37.5) 
9 (37.5) 
1 (7.7) 
0.126 
Latency F 
Right 
7 (41.2) 
13 (54.2) 
6 (46.2) 
0.705 
Left 
6 (35.3) 
15 (62.5) 
8 (61.5) 
0.184 
Amplitude V 
Right 
1 (5.9) 
3 (12.5) 
0 (0.0) 
0.367 
Left 
1 (5.9) 
1 (4.2) 
1 (7.7) 
0.903 
Amplitude A 
Right 
9 (52.9) 
14 (58.3) 
11 (84.6) 
0.168 
Left 
9 (52.9) 
9 (37.5) 
7 (53.8) 
0.510 
Amplitude VA 
Right 
4 (23.5) 
5 (20.8) 
3 (23.1) 
0.976 
Left 
2 (11.8) 
4 (16.7) 
3 (23.1) 
0.712 
Amplitude C 
Right 
3 (17.6) 
9 (37.5) 
6 (46.2) 
0.220 
Left 
7 (41.2) 
5 (20.8) 
4 (30.8) 
0.371 
Amplitude F 
Right 
4 (23.5) 
9 (37.5) 
5 (38.5) 
0.584 
Left 
5 (29.4) 
4 (16.7) 
1 (7.7) 
0.301 
Alteration Conduction  
- 
16 (94.1) 
24 (100) 
13 (100) 
0.330 
 
 
DISCUSSION 
 
In the present study, the results of electrophysiological evaluation of hearing in patients 
with SCD were analyzed, and central alterations were revealed through both ABR and FFR. 
Reports on the etiology and abnormal findings of ABR have indicated that several 
diseases may generate similar patterns of response, under condition of effects at the same 
level of the structure and function of the system [11, 12]. The increase in latencies to the click 
stimulus can therefore promote a brain stem lesion. 13 In addition, reports have indicated that 
there is alteration of the central auditory processing associated with the increase of absolute 
and interpeak latency, and increased latency of the I-III interpeak of the sample indicative of 
the presence of a low brain stem lesion which is closely associated with auditory processing 
disorder [14, 15]. These findings may be due to the synaptic delay or delay in neural 
transmission through incomplete myelination and reduced synaptic efficiency [15]. 
The FFR is considered an excellent target method to detect central auditory processing 
disorders [16]. A report has indicated a 85.15% probability of alteration of the central 
auditory processing in individuals with changes in the FFR [17]. Modification of both the 
latencies and amplitudes of FFR can be found in the population with altered central auditory 
processing and language deficits; such findings provide crucial information regarding the 
generation and propagation of responses along the auditory pathway [16]. 
The difficulty in perceiving consonants is due to their characteristics of fast and transient 
low-amplitude signal for speech; whereas, the perception of vowels is more resistant because 
they constitute a periodic, sustained, and generally higher signal than that of the consonants. 
Perception of the consonant (transient on set) and vowel (sustained) elicit responses through 
independent mechanisms [9, 18]. 

Auditory Brainstem Response and Frequency … 
 
527
Findings caused by central auditory processing disorder, such as delayed latencies and 
diminished amplitudes, observed in our study, have also been reported in a previous study 
[19]. Evaluation through speech provides a more sensitive method to investigate the changes 
in the synchronicity of response generators and extent of neural allocation represented by the 
amplitude differences, and rate of transmission of neural impulses during processing 
represented by the latency differences. 
A study has shown significantly increased latencies in the V, A, and C waves of the 
responses in children with learning disabilities [20]. Another report indicated that the latency 
deficits through FFR have a negative impact on the processing of acoustic signals in 
specialized cortical structures for speech [16]. 
With regard to sex, women tend to have earlier absolute latencies and shorter interpeak 
intervals than men; this difference is associated with the anatomical inequality of the skull 
and brain, and size of the cochlea [13, 21, 22, 23]. In our study, this difference was observed 
in the sample corresponding to male individuals (44.4%). 
The delay in the wave for both the ABR and FFR was more significant in the age group 
of 12 to 18 years-old. In adolescents, the signs and symptoms of the disease alter performance 
and learning which leads to backwardness in schooling [23, 24]. At the stage of adolescence, 
many problems arise due to the transition from pediatric treatment to that of the adult and 
greater avoidance of disease control; [23] these also include death rates of 78.6% in 
individuals up to 29 years [24]. A study using advanced neuroradiological techniques has 
reported the occurrence of complications of the central nervous system in 44% and 49% of 
patients with SCD. A report has indicated that silent ischemic injury associated with several 
neurocognitive deficits, such as learning problems, attention deficit, lack of executive 
abilities, poor activity status, and long-term memory [7]. 
Few studies have focused on the evaluation of ABR in the population with SCD, and 
none on that of FFR. Ondzotto et al. emphasized the importance of encouraging regular 
hearing assessment in this population [25]. Further studies are needed to clarify these findings 
due to the high variability of those between studies; however, the variability may be 
unavoidable due to the characteristic of SCD itself. Serjeant reported that different geographic 
areas as well as genetic and environmental factors influence variability in the population with 
SCD [23]. 
The analysis of auditory evoked potentials at the level of the brainstem revealed a change 
in 88.9% of subjects with click stimuli and 98.1% with speech stimulus. 
Our overall findings highlight the need for prevention, diagnosis, and systematic follow-
up in individuals with SCD, since hearing loss that is undiagnosed or diagnosed late can 
cause irreparable damage to speech, biopsychosocial, and emotional development. 
 In conclusion, the changes of the ABR and FFR may be considered as indicators of the 
individuals’ hearing status. The finding of auditory thresholds within the normal range and 
otoacoustic emissions helps, but does not guarantee excellent sound transmission through the 
auditory pathway. A new approach as well as further studies focused on central auditory 
processing and rehabilitation in this population are required. The combined use of 
electrophysiological assessments such as FFR and behavioral tests of central auditory 
processing may have effectiveness to clearly guide the possible communicative difficulties 
and enable earlier and more accurate diagnosis in this population. 
 
 

Adriana L. Silveira, Adriane R. Teixeira, Christina M. Bittar et al. 
 
528
REFERENCES 
 
[1] 
Burch-Sims GP and Matlock VR. 2005. “Hearing loss and auditory function in sickle 
cell disease.” Journal of Communication Disorders 38: 321–329. Accessed September 
24, 2017. doi: 10.1016/ j.jcomdis. 2005.02.007. 
[2] 
World Health Organization. 2005. “Sickle Cell Anaemia.” Report by the secretaria, 
Executive Board 117th session. 5f. 2005. 
[3] 
Ministério da Saúde. Secretaria de Atenção à Saúde. Departamento de Atenção 
Hospitalar e de Urgência. 2015. “Relatório de Gestão 2013” Coordenação‑Geral de 
Sangue e Hemoderivados [recurso eletrônico]. Brasília: Ministério da Saúde. [Ministry 
of Health. Secretary of Health Care. Department of Hospital Attention and Emergency. 
2015. 
“Management 
Report 
2013” 
General 
Coordination 
of 
Blood 
and 
Hemoderivatives [electronic resource]. Brasília: Ministry of Health] 
[4] 
Cançado RD and Jesus JA. 2007. A doença falciforme no Brasil. Revista Brasileira de 
Hematologia e Hemoterapia 29: 203-206. Accessed October 05, 2017 doi: 
10.1590/S1516-848420070 00300002. [Cançado RD and Jesus JA. 2007. Sickle cell 
disease in Brazil. Brazilian Journal of Hematology and Hemotherapy 29: 203-206. 
Accessed October 05, 2017 doi: 10.1590/S1516-848420070 00300002] 
[5] 
Hungria H. Otorrinolaringologia. Rio de Janeiro: Guanabara Koogan Ltda., 1995). 
[Hungria H. Otolaryngology. Rio de Janeiro, Guanabara Koogan, 1995] 
[6] 
Silva LP, Nova CV, and Lucena R. 2012. “Sickle cell anemia and hearing loss among 
children and youngsters: literature review.” Brazilian Journal of Otorhinolaryngology 
78: 126–31.  
[7] 
Ângulo, IL. 2007. “Acidente vascular cerebral e outras complicações do sistema 
nervoso central nas doenças falciformes.” Revista Brasileira de Hematologia e 
Hemoterapia 29:262-67. Accessed September 18, 2017. doi: 10.1590/S1516-
8484200700030 0013. [Ângulo IL. 2007. “Stroke and other complications of the central 
nervous system in sickle cell disease.” Brazilian Journal of Hematology and 
Hemotherapy 29: 262-67. Accessed September 18, 2017. doi: 10.1590 / S1516-
8484200700030 0013] 
[8] 
Intelligent Hearing Systems (IHS). 2017. “Acquiring Click ABR with SmartEP.” 
Auditory Brainstem Response, Using Smart EP.  
[9] 
Russo N, Nicol T, Musacchia G, Kraus N. 2004. “Brainstem responses to speech 
syllables.” Clinical Neurophysiology 115: 2021-30. Accessed March 20, 2017. doi 
10.1016/j.clinph.2004.04.003. 
[10] Gonçalves IC. “Aspectos Audiológicos da Gagueira: Evidências Comportamentais e 
Eletrofisiológicas.” (Tese (doutorado), Faculdade de Medicina da Universidade de São 
Paulo, 2013). [Gonçalves IC. “Audiological Aspects of Stuttering: Behavioral and 
Electrophysiological Evidence.” (Thesis (doctorate), Faculty of Medicine, University of 
São Paulo, 2013)]. 
[11] Durrant JD and Ferraro JA, “Potenciais auditivos evocados de curta latência: 
eletrococleografia e audiometria de tronco encefálico,” in Perspectivas Atuais em 

Auditory Brainstem Response and Frequency … 
 
529
Avaliação Auditiva, ed. Frank E. Musiek and William F. Rintelmann, (Barueri: Manole, 
2001), 193-238. [Durrant JD and Ferraro JA, “Short-latency evoked auditory potentials: 
electrocochleography and brainstem audiometry,” in Current Perspectives on Auditory 
Assessment, ed. Frank E. Musiek and William F. Rintelmann, (Barueri: Manole, 2001), 
193-238.] 
[12] Matas CG and Magliaro FCL, “Potencial evocado auditivo de tronco encefálico,” in 
Tratado de Audiologia, ed. Edilene Boechat (São Paulo: Santos, 2015) 118-112. [Matas 
CG and Magliaro FCL, “Brainstem auditory evoked potential,” in Audiology, ed. 
Edilene Boechat (São Paulo: Santos, 2015) 118-112] 
[13] Misulis KE. Manual do Potencial Evocado de Spehlmann: Potenciais Visual, Auditivo 
e Somatossensitivo Evocados no Diagnóstico Clínico. (Rio de Janeiro: Revinter, 2003). 
[Misulis KE. Spehlmann Evoked Potential Manual: Visual, Auditory and 
Somatosensory Potentials Evoked in Clinical Diagnosis. (Rio de Janeiro: Revinter, 
2003)]. 
[14] Pfeifer M and Silvana F. 2009. “Auditory processing and auditory brainstem response 
(ABR).” 
CEFAC 
11(suppl 
1): 
31-37. 
Accessed 
in 
July 
23, 
2017. 
http://dx.doi.org/10.1590/S1516-18462009000500006  
[15] Rocha-Muniz CN, “Processamento de Sinais Acústicos de Diferentes Complexidades 
em Crianças com Alteração de Percepção da Audição ou da Linguagem.” (Tese 
(Doutorado), Faculdade de Medicina da Universidade de São Paulo, 2011). [Rocha-
Muniz CN, “Processing of Acoustic Signs of Different Complexities in Children with 
Altered Hearing or Language Perception.” (Thesis, Faculty of Medicine, University of 
São Paulo, 2011)]. 
[16] Wible B, Nicol T, and Kraus N. 2004. “Atypical brainstem representation of onset and 
formant structure of speech sounds in children with language-based learning problems.” 
Biological Psychology 67: 299–317. Accessed in September 16, 2017. doi: 
10.1016/j.biopsycho.2004.02.002. 
[17] Rocha-Muniz CN, Filippini R, Neves-Lobo IF, Rabelo CM, Morais AA, Murphy CF, 
Calarga KS, et al. 2016. “Can speech-evoked auditory brainstem response become a 
useful tool in clinical practice?” Codas 28: 77–80. Accessed July 23, 2017. doi: 
10.1590/ 2317-1782/20162014231. 
[18] Abrams DA and Kraus N, “Auditory pathway representations of speech sounds in 
humans.” in Handbook of Clinical Audiology, 7th ed. Jack Katz (Philadelphia: Wolters 
Kluwer, 2015), 527–44.  
[19] Filippini R and Schochat E. 2009. “Brainstem evoked auditory potentials with speech 
stimulus in the auditory processing disorder.” (in English, Portuguese) Brazilian 
Journal of Otorhinolaryngology 75: 449–55. Accessed September 20, 2017. 
[20] Kraus N and Nicol T. 2003. “Aggregate neural responses to speech sounds in the 
central auditory system.” Speech Communication 41:35–47. Accessed September 16, 
2017. doi:10.1016/S0167-6393(02)00091-2. 
[21] de Sousa LCA, de Toledo Piza MR, de Freitas Alvarenga K, and Cóser PL, 
Eletrofisiologia da Audição e Emissões Otoacústicas: Princípios e Aplicações Clínicas. 

Adriana L. Silveira, Adriane R. Teixeira, Christina M. Bittar et al. 
 
530
(Ribeirão Preto: Novo Conceito, 2010). [de Sousa LCA, Toledo Piza MR, Freitas 
Alvarenga K, and Cóser PL, Electrophysiology of Hearing and Otoacoustic Emissions: 
Principles and Clinical Applications. (Ribeirão Preto: New Concept, 2010)]. 
[22] Burkard R and Don M, “Introduction to auditory evoked potentials.” in Handbook of 
Clinical Audiology, 7th ed. Jack Katz (Philadelphia: Wolters Kluwer, 2015). 
[23] Serjeant GR. 2013. “The natural history of sickle cell disease.” Cold Spring Harbor 
perspectives in medicine 3(10): a011783. doi: 10.1101/cshperspect.a011783. 
[24] Martins GVR, “Adolescente com Doença Falciforme: Conhecimento da Doença e 
Adesão ao Tratamento.” (Dissertação Mestrado, Universidade Federal do Espírito 
Santo, Centro de Ciências da Saúde, Vitória, 2015). [Martins GVR, “Adolescent with 
Sickle Disease: Knowledge of Disease and Adherence to Treatment.” (Master's 
Dissertation, Federal University of Espírito Santo, Health Sciences Center, Vitória, 
2015)]. 
[25] Ondzotto G, Malanda F, Galiba J, Ehouo F, Kouassi B, Bamba M. 2002. “Sudden 
deafness in sickle cell anemia: a case report.” (in French) Bulletin de la Société de 
pathologie exotique 95: 248–49.  
 
  

In: Encyclopedia of Audiology and Hearing Research 
ISBN: 978-1-53617-702-2 
Editors: Erno Larivaara and Senja Korhola 
© 2020 Nova Science Publishers, Inc. 
 
 
 
 
 
 
 
Chapter 36 
 
 
 
THE RELATIONSHIP BETWEEN SELF-REPORTED 
RESTRICTION IN SOCIAL PARTICIPATION, SELF-
REPORTED SATISFACTION/BENEFIT AND THE TIME 
OF USE OF HEARING AIDS  
 
 
João Paulo N. A. Santos1, Nathany L. Ruschel2,  
Camila Z. Neves3 and Adriane R. Teixeira4, 
1Speech Therapy and Audiology Service, Hospital de Clínicas de Porto Alegre,  
Porto Alegre, Rio Grande do Sul, Brazil  
2Child and Adolescent Health Post-Graduate Program, Universidade Federal  
do Rio Grande do Sul, Porto Alegre, Rio Grande do Sul, Brazil 
3Comunicare Hearing Aids, Porto Alegre, Rio Grande do Sul, Brazil 
4Health and Human Comunication Department, Universidade Federal do  
Rio Grande do Sul and Speech Therapy and Audiology Service,  
Hospital de Clínicas de Porto Alegre, Porto Alegre, Rio Grande do Sul, Brazil 
 
 
ABSTRACT 
 
To correlate the results obtained through questionnaires concerning self-reported 
restriction in social participation and patient satisfaction/benefit with objective time 
assessment of device use. This is a descriptive, cross-sectional study sample composed of 
and elderly and non-elderly adults of both sexes diagnosed with hearing loss and 
approved as candidates for hearing aid fitting at a university hospital. Subjects answered 
questionnaires that measure restriction in social participation restriction and user 
satisfaction/benefit, namely the Hearing Handicap Inventory for Adults (HHIA) for non-
elderly adult patients; the Hearing Handicap Inventory for the Elderly Screening Version 
(HHIE-S), for elderly patients, and the International Outcome Inventory for Hearing Aids 
(IOI-HA) for both age groups. Average daily usage time of the devices was verified 
objectively through datalogging. A total of 49 users elderly and non-elderly of both sexes 
participated in the study. Self-reported hearing aid times of use were compared with those 
                                                        
 Corresponding Author’s Email: adriane.teixeira@gmail.com. 

João Paulo N. A. Santos, Nathany L. Ruschel, Camila Z. Neves et al. 
 
532
measured by datalogging. There was overestimation on the part of patients when 
reporting hearing aid use, which was verified when compared with software data. There 
was no significant correlation between questionnaire scores and the datalogged time of 
use. There was a negative correlation between the HHIE-S and IOI-HA questionnaires, 
and a positive correlation between the variable of age and the IOI-HA questionnaire, as 
well as another positive correlation between the variable of sex and the HHIA 
questionnaire. No relation was found between datalogged time of use and self-reported 
restriction in social participation or hearing aid user satisfaction/benefit. 
 
Keywords: hearing aids, hearing loss, questionnaires 
 
 
INTRODUCTION 
 
According to the National Health Survey of 2013, 1.1% of the Brazilian population - 
approximately 2.27 million people - are hearing impaired, with the South of the country 
representing the highest proportion of this indicator (1.5%). Research data also reveal that 
hearing loss is more frequent in the elderly (5.2%) or among people with lower levels of 
education or an incomplete elementary education. These findings are highly significant when 
compared to other data on age and education [1]. Hearing impairment causes disturbances in 
the social life of elderly patients as well as non-elderly adults and is also associated with other 
symptoms, such as depression, as well as functional and cognitive decline [2]. In relation to 
the elderly, it has been shown that hearing loss frequently entails a restriction in social 
participation and a lack of communicative competence; that is to say, it has a significant 
impact on the subjects’ quality of life [3]. 
In the Brazilian Unified Health System (SUS), the cost-free fitting of hearing aids (HAs) 
has been granted since 2000. Public provision policies were amplified after the 
implementation of the Hearing Care Network for the Hearing Impaired and preceded the 
elaboration of the National Attention to Hearing Health policy. Since the implementation of 
these public protocols, demands for promotion, prevention and rehabilitation have been better 
met at federal, state and municipal levels [4, 5]. 
In order to facilitate a satisfactory hearing aid adaptation process, a speech-language 
pathologist qualified in audiology should carry out an appropriate HA selection and then give 
detailed and careful advice to the patient [6]. After fitting, successful adaptation also depends 
on the daily time of the use of the HA. This can be accurately measured through datalogging, 
a feature present in sound amplification devices. In order to validate success or setbacks in the 
adjustment process, the speech-language pathologist uses questionnaires to subjectively gauge 
patient satisfaction and benefit from hearing aid use [6]. In scientific literature, studies have 
been found that describe the importance of measuring user satisfaction/benefit in the process 
of adaptation. However, few studies correlate datalogged daily time of use with 
questionnaires that aim at validating the adaptation process. 
It is known that the process of selecting and adapting to hearing aids aims to, among 
other goals, circumvent restrictions in social participation and help the user to effectively 
make use of their devices, thus favoring user satisfaction/benefit. In this sense, for a well-
structured process of verification and validation, orientation, adaptation and self-assessment, 
questionnaires should be used in the best way possible [7]. 

The Relationship between Self-Reported Restriction in Social… 
 
533
Among the questionnaires used to evaluate patient hearing loss are the Hearing Handicap 
Inventory for Adults (HHIA) and the Hearing Handicap Inventory for the Elderly - Screening 
Version (HHIE-S) [8]. The first is used to verify participation restriction caused by hearing 
loss in non-elderly adults and the second is used to verify the same phenomenon in the 
elderly. Participation restriction or handicap is considered to be any disadvantage imposed by 
hearing impairment which limits an individual psychosocially. Many times elderly and non-
elderly patients with hearing losses need to use hearing aids in order to compensate for the 
reported deficits caused by hypoacusia. Although these devices are used as a way to address 
negative social impacts, some accompanying strategies are even more decisive for their 
successful use, such as the elaboration of realistic expectations together with the patient 
regarding the compensation provided by the hearing aid. Moreover, appropriate advice and 
orientation by the speech-language pathologist directly supports patient adjustment, which in 
turn results in increased perception of satisfaction/benefit and a reduction in handicap [9]. 
Another necessary task for a speech and language pathologist who works with the 
selection and adaptation of HAs is to analyze self-reported user satisfaction and benefit. With 
this objective, after a minimal period of fifteen days post-fitting, the internationally used 
Outcome Inventory for Hearing Aids (IOI-HA) [10] can be applied to verify adjustment to the 
HA from the user’s point of view. It takes into account daily evolution, degree of user 
satisfaction, impact on other people, restriction in social participation and limitations in basic 
activities. In addition, the IOI-HA questionnaire allows the patient to report the daily time of 
use of the hearing aid [11]. 
In peer-reviewed literature, there are few studies that correlate datalogging to the 
protocols mentioned previously, with the exception of the IOI-HA protocol. Some studies 
have found a significant correlation between the time of use of the hearing aid registered 
through datalogging and the self-reports of users, as well as a correlation between the time of 
use registered by datalogging with other protocols that measure patient satisfaction/benefit 
[12, 13]. Thus, the present study has as a general objective the correlation of findings 
regarding restrictions in social participation caused by the hearing loss, hearing aid user 
satisfaction/ benefit and the datalogged times of use of these devices. Furthermore, our 
specific objectives are to analyze the relationship between the questionnaires themselves; to 
correlate the datalogged time of use and questionnaires with different variables such as age, 
education and type and degree of hearing loss. What is more, we aim to analyze the 
correlation between self-reported daily time of use and the datalogged time of use of these 
devices. 
 
 
METHODS 
 
The study was of the transversal and descriptive type. The sample consisted of elderly 
and non-elderly patients of both sexes who had been diagnosed with hearing loss by an Ear, 
Nose and Throat (ENT) specialist had gone through an audiological evaluation. These 
subjects were approved as candidates for hearing aid fitting and subsequently received these 
devices through the National Hearing Health Program at a university hospital. 
Inclusion criteria were that recruited patients should sign an Informed Consent form (IC) 
and have undergone an ENT and audiological evaluation (pure tone audiometry, speech 

João Paulo N. A. Santos, Nathany L. Ruschel, Camila Z. Neves et al. 
 
534
audiometry and acoustic impedance tests measures). Subjects who received their hearing aids 
via the program should have been using their devices for at least 15 days. Users under the age 
of 18 were excluded from the sample as well as patients who demonstrated partial or total 
incomprehension of the questionnaires due to cognitive, neurological or language issues. 
In the process of selection and adaptation of the hearing aids, initial evaluations were 
carried out to verify the type and degree of hearing loss, along with the most appropriate type 
of device for each patient’s needs. After fitting, patients received individual guidance on the 
proper use, handling and care of the devices. It should be noted that patients were not 
informed about the possibility of checking the time of use through datalogging. 
After a minimal period of fifteen days, patients returned for a follow-up appointment. 
This period is a guideline at the outpatient clinic where the research was done. At that time, 
adjustments, verifications and further explanations about patients’ hearing aids were 
performed, with the aim of guaranteeing continuity of use. Patients were also invited to 
participate in the research project. After signing the IC form, subjects were shown to a 
specific room in the outpatient clinic to answer questionnaires. At this stage, only the 
interviewer and the HA user were present in the interview room, in order to avoid interference 
from family members and caregivers.  
First, subjects answered questionnaires regarding social participation restriction due to 
hearing loss: the HHIE-S questionnaire for elderly patients or the HHIA for non-elderly adult 
subjects. Next, the IOI-HA questionnaire was applied to assess user satisfaction/benefit. 
After, the datalogged daily time of use was verified for the subsequent analysis and 
correlation of the questionnaire scores and self-reported average daily time of use. 
Questionnaires were applied during one-on-one interviews which were adjusted 
according to the level of education of each research participant. The differences between first 
two questionnaires, the HHIES-S and HHIA, lie in their distinct target populations as well as 
the overall number of questions. The former is a shorter version, containing ten questions, 
five of which address emotional aspects and the other five social/situational aspects. As such, 
the cut-off points that determine user participation are different than those of the HHIA, 
which is a questionnaire composed of twenty-five questions. As for the score, four points, two 
points and zero points were given for the answers “yes”, “maybe” and “no”, respectively. In 
both cases, the higher the score, the greater the self-reported restriction in social participation. 
The HHIE-S questionnaire has a total score of forty points: zero to eight points represents no 
perceived restriction in social participation, ten to twenty-three a mild to moderate restriction 
and twenty-four to forty a significant restriction. The HHIA questionnaire has a total score of 
100 points: a score of zero to sixteen is indicative of no perceived restriction in social 
participation, eighteen to thirty points indicate slight restriction, thirty-two to forty points 
indicate moderate restriction and scores above forty-two points indicate a significant 
restriction in social participation [14]. 
The IOI-HA questionnaire was also applied during the interview. This particular 
instrument should be used within the first 15 days after hearing aid fitting. The questions take 
into account degree of user satisfaction/benefit, restrictions in social participation and 
limitations in basic activities [7]. It consists of seven questions, each worth a score of between 
one to five, where one represents the most negative response and five the most positive. The 
maximum score is thirty-five points, which is indicative of a very positive evaluation by the 
HA user, whereas the minimum score of five points is indicative of a negative evaluation by 
the HA user. 

The Relationship between Self-Reported Restriction in Social… 
 
535
After the application of the questionnaires, an objective verification of time of use was 
carried out through the datalogging feature, which is present in all HAs distributed at the 
outpatient clinic. Data regarding sex, age and type and degree of hearing loss were also 
obtained through patients’ electronic records. 
The sample size calculation was performed in the WinPEPI program (Programs for 
Epidemiologists for Windows) version 11.43 [12, 13]. For a level of significance of 5%, to the 
power of 80%, and estimating a minimum correlation coefficient of 0.4 between the variables 
of satisfaction, benefit and restriction in social participation and time of use, a minimum total 
of 47 patients was obtained. 
Quantitative variables were described by mean and standard deviation or interquartile 
range and median. Categorical variables were described by absolute and relative frequencies. 
To compare means between ears, the t-student test for paired samples was applied. In cases of 
asymmetry, the Wilcoxon test was used. For the categorical variables, the McNemar test was 
applied. To compare means between gender and type of loss, the t-student test for 
independent samples or Analysis of Variance (ANOVA) were applied. In cases of 
asymmetry, the Mann-Whitney and Kruskal-Wallis tests were used. To evaluate the 
association between continuous and ordinal variables, the Pearson or Spearman correlation 
tests were applied. The significance level adopted was 5% (p ≤ 0.05) and the analyses were 
performed though the SPSS program, version 21.0. 
The present study was submitted to and approved by the Research Ethics Committee 
(CEP) of the institution, and approved (protocol number 2.086.280). Was regulated according 
to the norms concerning research involving human beings, duly governed by resolution 
466/12 of the National Health Council. 
 
 
RESULT 
 
The present study consisted of a sample of 49 subjects, the majority of whom were 
elderly patients (71.42%). Among study subjects, there was equal distribution with regard to 
sex. Most of the participants in the sample had lower levels of education. The greater part of 
the group was fitted bilaterally with hearing aids (Table 1). 
The HHIE-S questionnaire for the elderly presented a median of 6 and, for non-elderly 
adults, the HHIA median was 0. Thus, most of the study subjects, both elderly and non-
elderly adults, declared no restriction in social participation after the use of HAs. The 
quantitative data collected through the IOI-HA questionnaire revealed an average score of 
29.3 points, which is a good indication of HA user satisfaction/benefit (Table 1). 
Regarding the type of hearing loss, the predominant profile was sensorineural, 
symmetrical, bilateral loss. The most frequent degree of bilateral loss was moderate, based on 
the quadratic mean (500Hz, 1000Hz, 2000Hz and 4000Hz). The mean post-fitting period until 
follow up was one month and three days. The average datalogged time of use is presented in 
Table 2. 
 
 
 

João Paulo N. A. Santos, Nathany L. Ruschel, Camila Z. Neves et al. 
 
536
Table 1. Characterization of the sample 
 
Variables 
n = 49 (35 elderly users and 14 non-elderly adult users) 
Age (years) – average ± SD 
66.0 ± 14.2 
Minimum age/maximum age 
24/91 
Sex – n (%) 
 
Female 
24(49.0) 
Male 
25(51.0) 
Education (years) – median (P25 – P75) 
6 (4 – 8) 
Hearing aid use – n (%) 
 
Unilateral 
8 (16.3) 
Bilateral 
41(83.7) 
Period of adjustment to HA – average ± SD 
33.6 ± 3.0 
HHIE – S – median (P25 – P75) 
6 (0 -10) 
HHIE Classification– S – n (%) 
 
No participation restriction 
24(68.6) 
Slight to moderate participation restriction 
9 (25.7) 
Significant participation restriction 
2(5.7) 
HHIA – median (P25 – P75) 
0 (0 - 15.5) 
HHIA Classification– n (%) 
 
No participation restriction 
11(78.6) 
Slight participation restriction 
1(7.1) 
Moderate participation restriction 
0(0.0) 
Significant participation restriction 
2 (14.3) 
IOI-HA – average ± SD 
29.3 ± 5.8 
Legend: SD – standard deviation; % - percentage; HHIE – Hearing Handicap Inventory for Elderly-S – Screening version; 
HHIA – Hearing Handicap Inventory for Adult; IOI-HA = International Outcome Inventory for Hearing Aid; HA – 
Hearing Aids. 
 
Table 2. Patient hearing data and hearing aid time of use registered by datalogging 
 
Variables 
Right ear 
Left ear 
p 
(n = 48) 
(n = 46) 
Time of use in hours/day 
3 (2 – 7) 
3 (1 – 7) 
0.380 
median (P25 – P75) 
 
 
 
Type of hearing loss – n (%) 
 
 
0.513 
Sensorineural 
36(78.3) 
36(80.0) 
 
Conductive 
2(4.3) 
3(6.7) 
 
Mixed 
8 (17.4) 
6 (13.3) 
 
Degree of hearing loss – n (%) 
 
 
0.214 
High-frequency hearing loss  
2(4.2) 
1(2.2) 
 
Mild 
16(33.3) 
15(32.6) 
 
Moderate 
28(58.3) 
23(50.0) 
 
Severe 
2(4.2) 
5 (10.9) 
 
Profound 
0(0.0) 
2(4.3) 
 
Quadratic mean – mean ± SD 
47.1 ± 15.4 
51.5 ± 22.7 
0.228 
Legend: SD – standard deviation; n – absolute number; p – percentage. 
 
There was a significant negative correlation between the scores of the HHIE-S and IOI-
HA questionnaires, showing that the greater the self-reported benefit and satisfaction, the 
lower the perception of restriction in social participation due to hearing loss. There was no 

The Relationship between Self-Reported Restriction in Social… 
 
537
significant correlation between the scores of the HHIA and IOI-HA questionnaires, nor was 
there a correlation between the scores of the questionnaires and the objective measures of HA 
time of use (Table 3). 
 
Table 3. Datalogged time of use and its relationship with subjective measures of hearing 
aid use (questionnaires) 
 
Relationships 
Correlation coefficient 
p 
HHIE – S and IOI-HA 
- 0.635 
< 0.001 
HHIE – S and time of use RE 
0.107 
0.545 
HHIE – S and time of use LE 
0.145 
0.428 
HHIA and IOI-HA 
- 0.240 
0.410 
HHIA and time of use RE 
- 0.354 
0.235 
HHIA and time of use LE 
- 0.087 
0.799 
IOI-HA and time of use RE 
0.159 
0.287 
IOI-HA and time of use LE 
0.152 
0.331 
Legend: RE – right ear; LE – left ear; HHIE-S – Hearing Handicap Inventory for Elderly – Screening Version; HHIA - 
Hearing Handicap Inventory for Adult; IOI-HA = International Outcome Inventory for Hearing Aids. 
 
An analysis of the variables of education, age, quadratic mean and type of hearing loss 
and the scores from the questionnaires showed that there was no significant correlation 
between most of them, except for the negative correlation between the age variable and the 
IOI-HA questionnaire. This would suggest that the older the hearing aid user, the lower the 
level of self-reported satisfaction/benefit (Table 4). There was also an association between the 
variable of sex and the HHIA questionnaire (p = 0.020), revealing that female subjects 
declared more restriction in social participation, even after fitting, when compared to the male 
subjects. 
In our analysis, we observed a difference between self-reported time of hearing aid use 
and the time of use objectively measured by datalogging software (Table 5) (z = - 4,74). It 
should be noted that, for such an analysis, self-reported daily time of use was classified 
according to the scales used in the IOI-HA questionnaire (i.e., ‘never’, ‘less than 1 h/day’, ‘1 - 
4 h/day’, ‘4 - 8 h/day’, ‘8  h/day’). 
 
Table 4. 
 
Relationships 
HHIE – S 
HHIA 
IOI-HA 
Education 
rs = - 0.060 (p = 0.731) 
rs = 0.033 (p = 0.910) 
rs = 0.211 (p = 0.146) 
Age 
rs = 0.265 (p = 0.124) 
rs = - 0.078 (p = 0.792) 
r = - 0.317 (p = 0.026) 
Quadratic mean 
RE 
rs = 0.159 (p = 0.363) 
rs = 0.090 (p = 0.758) 
r = - 0.121 (p = 0.409) 
LE 
rs = 0.288 (p = 0.094) 
rs = 0.237 (p = 0.415) 
r = 0.049 (p = 0.736) 
Type of hearing loss 
RE 
rs = 0.084 (p = 0.644) 
rs = - 0.101 (p = 0.742) 
rs = - 0.064 (p = 0.667) 
LE 
rs=0.237 (p = 0.177) 
rs = 0.430 (p = 0.124) 
rs = 0.120 (p = 0.428) 
Legend: RE – right ear; LE – left ear; HHIE-S – Hearing Handicap Inventory for Elderly – Screening Version; HHIA - 
Hearing Handicap Inventory for Adult; IOI-HA = International Outcome Inventory for Hearing Aids. 
 

João Paulo N. A. Santos, Nathany L. Ruschel, Camila Z. Neves et al. 
 
538
Table 5. Analysis of self-reported HA time of use and its relationship with datalogged 
time of use 
 
 
Never 
n (%) 
Less than 
1h/day 
n (%) 
1 – 4 h/day 
n (%) 
4 – 8 
h/day 
n (%) 
< 8h/day 
n (%) 
Total 
n (%) 
Never n (%) 
0 (0) 
0 (0) 
0 (0) 
0 (0) 
0 (0) 
0 (0) 
Less than 1h/day 
n (%) 
1 (2.05) 
0 (0) 
1 (2.05) 
0 (0) 
0 (0) 
2 (4.1) 
1 – 4 h/day n (%) 
0 (0) 
0 (0) 
4 (8.2) 
0 (0) 
0 (0) 
4 (8.2) 
4 – 8 h/day n (%) 
1 (2.05) 
2 (4.1) 
10 (20.4) 
4 (8.2) 
0 (0) 
17 (34.7) 
< 8h/day n (%) 
0 (0) 
1 (2.05) 
12 (24.5) 
2 (4.1) 
11 (22.4) 
26 (53.1) 
Total n (%) 
2 (4.1) 
3 (6.15) 
27 (55.1) 
6 (12.2) 
11 (22.4) 
49 (100) 
 
In our analysis of education and hearing aid time of use, no relevant association was 
found, either for the right ear (r s  0.221 and  0.135) or for the left ear (r s  0.241 and  
0.120). No association between age and time of use was observed, either for the RE (r s  
0.174 - 0.202 p) or for the LE (r s  - 0.213  p 0.170). 
 
 
DISCUSSION 
 
Population aging is currently one of the predominant themes in different fields, in Brazil 
and around the world. Senescence brings about physical changes that justify special health 
care for this population, which is rapidly changing the morphology of the Brazilian age 
pyramid [15, 16]. This fact would explain the large number of elderly patients in the present 
study sample, a reality which can also be corroborated by previously mentioned data 
concerning hearing loss. In that national health survey, the southern region of Brazil scored 
higher numbers of hearing loss handicap. Moreover, within this particular group, elderly 
adults constitute a higher proportion when compared with non-elderly adults [1]. 
On the other hand, the balance in patient sex observed in our study does not support 
findings in scientific literature that describe a greater demand for health care by female 
subjects [17]. The balance in the sample may be justified by the higher prevalence of men 
over 60 diagnosed with hearing loss, which has also been described in scientific literature 
[18]. 
Most of the sample consisted of subjects with lower levels of education or with an 
incomplete elementary education. This was expected due to the general social profile of the 
population attended at the university hospital [19]. This common factor among almost all 
sample participants prevented further analysis due to the homogeneous characteristic of this 
variable.  
A predominant part of the subjects in our sample presented bilateral hearing loss, with the 
most prevalent type being sensorineural moderate loss. No significant difference between ears 
was observed. These data confirm those described in specialized literature [20]. During the 
fitting process, hearing aids were adapted in accordance with the characteristics of hearing 
loss presented by each patient in the sample. Most were fitted bilaterally, which benefits 
patients with hearing loss since it better facilitates sound localization and binaural summation, 
as well as better speech recognition in noisy environments [21]. 

The Relationship between Self-Reported Restriction in Social… 
 
539
We found no significant correlation between the results of the questionnaires used in the 
present study and the variables of schooling, age, quadratic mean and type of hearing loss, 
with the exception of the relationship between the IOI-HA questionnaire and the variable of 
age. This further substantiates findings in scientific literature that the older the HA user, the 
weaker the perception of satisfaction/benefit, since elderly individuals tend to understand age 
as a reason for disabilities. This general attitude might, therefore, make elderly HA users 
more demanding in terms of the satisfaction/benefit they expect from hearing aids [9]. 
Scores from questionnaires that measured self-reported restrictions in social participation 
or patient satisfaction/benefit in the post-fitting period were similar to those already found in 
specialized literature [9]. These results justify the negative correlation between the HHIE-S 
and the IOI-HA questionnaires. There was a significant correlation between the HHIA 
questionnaire and the variable of sex. Among non-elderly adults, follow-up self-reports 
revealed a greater perception of restriction in social participation. This may be explained by a 
stronger concern on the part of the adult female subjects for health issues, which may have 
influenced the results [17]. 
The non-association between questionnaire scores and datalogged time of use may be 
explained by the low average HA use by participants. This data may point to the need for 
closer and more frequent follow-ups for new users, in order to adjust and verify the adaptation 
process; two steps which have been referred to in the literature as important for better patient 
habituation to hearing aids [15]. It is important to note that, even with an average of three 
hours per day in the first month of adaptation, the subjects in this study predominantly 
reported benefit and satisfaction with their HAs. What is more, reports regarding restriction in 
social participation were mostly absent, both in elderly and non-elderly adults. This finding is 
also similar to those present in scientific literature [11]. It should be taken into account, 
however, that results may also have been influenced by the fact that these patients received 
their hearing aids through the unified public health system, at no financial cost to themselves. 
The present study showed that sample subjects overestimated the average daily time of 
use of the hearing aids in their self-report. This finding corroborates previous research [22], in 
which there was also overestimation in the self-reported time of use of hearing devices; 
however, the study group was smaller than the sample in this study. It is worth noting that 
data may reflect certain characteristics of the each sample, since in another study no 
overestimation in self-reports of sample subjects was observed when compared to the time of 
use provided by datalogging [13]. 
It is important to highlight that our study was carried out with participants whose health 
evaluations and care are provided by a unified public health system. This fact, in turn, 
probably influenced results with respect to patient perception of time of use, 
satisfaction/benefit and restriction in social participation. Apart from this, lower levels of 
education may have compromised patient understanding of the need for hearing aids, as well 
as instructions regarding the proper handling and care of these devices. In like manner, the 
overestimated time of use in self-reports may correspond to certain characteristics of 
particular groups of users who may feel the need to declare increased times because of the 
way in which the hearing aids are distributed to the public.  
Thus, our data show, above all, the need for improved guidance for patients attended at 
the hospital, taking into consideration the way in which hearing aids are made available to 
them (for example, via public funds), the need for continued use so that greater and better 

João Paulo N. A. Santos, Nathany L. Ruschel, Camila Z. Neves et al. 
 
540
benefits can be obtained, as well as the relation between hearing and different aspects of daily 
life, especially social and cognitive ones. 
 
 
CONCLUSION 
 
Through questionnaires applied to the patient sample of the present study, we were able 
to verify that the majority of and elderly and non-elderly users fitted with hearing aids felt 
satisfied and considered the devices beneficial. Additionally, for the most part, responses 
revealed no significant restriction in social participation. However, no association was found 
between the questionnaires and the datalogged times of use. Nonetheless, there was a 
significant difference between question one of the IOI-HA questionnaire and datalogged 
times of use, suggesting an overestimation in the self-reported time of use of hearing aids by 
patients. There was a negative correlation between the HHIE-S and IOI-HA questionnaires. 
This brings to the fore the important relationship between patients self-reporting no restriction 
in social participation as well as satisfaction and benefit after being fitted with hearing aids. 
 
 
REFERENCES 
 
[1] 
Brazilian Institute of Geography and Statistics. National Health Survey 2013: life 
cycles. Brasil, 2013. 
[2] 
Cruz, Mariana S., Oliveira, Luiz R., Carandina, Luana, Lima, Maria Cristina P., César, 
Chester Luiz G., Barros, Marilisa B. A., Alves, Maria Cecília G. P. & Goldbaum, 
Moises. (2009). Prevalence of self-reported hearing loss and attributed causes: a 
population-based study. Cadernos de Saúde Pública, 25, 1123-31. Accessed December 
18, 2018. doi: 10.1590/S0102-311X2009000500019. 
[3] 
Teixeira, Adriane R., Almeida, Luciane., Jotz, Geraldo P. & De Barba, Marion. (2008). 
Quality of life of adults and elderly people after hearing aids adaptation. Revista da 
Sociedade Brasileira de Fonoaudiologia, 13, 357-61.  
[4] 
Ministério, da Saúde. (2004). Portaria 589 (National Politics of Hearing Health). 
Ministério 
da 
Saúde. 
Accessed 
in 
November 
25, 
2018. 
http://bvsms.saude.gov.br/bvs/saudelegis/sas/2004/prt0589_ 08_10_2004_rep.html. 
[5] 
Ministério, da Saúde. (2011). Portaria 793 (Network of care for people with disabilities 
under the Unified Health System). Accessed in November 25, 2018. http:// 
bvsms.saude.gov.br/bvs/saudelegis/ gm/2012/prt0793_24_04_2012.html. 
[6] 
Ferraz, Tatiane N., Sant’Ana, Erika S. N., Mazini, Jéssica B. & Scharlach, Renata C. 
(2015). Verification and Validation Procedures in the Individual Hearing Aid Selection 
and Fitting Process: Choices of the Audiologists. Revista Equilíbrio Corporal e Saúde, 
6, 
40-7. 
Accessed 
in 
November 
30, 
2018. 
http://www.pgsskroton.com.br/ 
seer/index.php/reces/article/view/2442. 
[7] 
Broca, Vanessa S. & Scharlach, Renata C. (2014). The use of self-assessment 
questionnaires for validation of the results in hearing aid selection and fitting process. 

The Relationship between Self-Reported Restriction in Social… 
 
541
Revista CEFAC, 16, 1808-19. Accessed in December, 30, 2018. doi: 10.1590/1982-
0216201410513. 
[8] 
Silva, Deide P. C. B., Silva, Virginia B. & Aurélio, Fernanda S. (2013). Auditory 
Satisfaction of patients fitted with hearing aids in the Brazilian Public Health Service 
and benefit offered by the hearing aids. Brazilian Journal of Otorhinolaryngology, 79, 
538-45. Accessed in December 30, 2018. doi: 10.5935/1808-8694.20130098. 
[9] 
Grossi, Letícia M. R. & Scharlach, Renata C. (2011). Satisfaction and Participation 
restriction in hearing aids’ users: a study with elderly. Revista Equilíbrio Corporal e 
Saúde, 3, 3-15. Accessed in December 30, 2018. http://www.pgsskroton.com.br/ 
seer/index.php/reces/article/ view/44/3147. 
[10] Cox, Robin M. & Alexander, Genevieve C. (2002). The International Outcome 
Inventory for Hearing Aids (IOI-HA): psychometric properties of the English version. 
International Journal of Audiology, 41, 30-5.  
[11] Moda, Isabela., Mantello, Erika B., Reis, Ana Claudia M. B., Isaac, Myriam L., 
Oliveira, Andreia A. & Hyppolito, Miguel Angelo. (2013). Evaluation of hearing aid 
user satisfaction. Revista CEFAC, 15, 778-85. Accessed ind December 12, 2018. doi: 
10.1590/S1516-18462013000400006. 
[12] Laperuta, Erika B. & Fiorini, Ana Claudia. (2012). Satisfaction of elderly individuals 
with hearing aids in the first six months of use. Jornal Sociedade Brasileira de 
Fonoaudiologia, 
24, 
316-21. 
Accessed 
in 
December 
30, 
2018. 
https://www.researchgate.net/ 
publication/234104774_Satisfaction_of_elderly_individuals_with_hearing_aids_in_the
_first_six_months_of_use. 
[13] Makan, Aarti. (2015). “The value of using the Operational Model of behaviour change 
on adultaural rehabilitation outcomes.” MD diss., University of Pretoria. 
[14] Souza, Valquiria C. & Lemos, Stela Maris. (2015). Tools for evaluation of restriction 
on auditory participation: systematic review of the literature. CoDAS, 27, 400-6. 
Accessed in December 30, 2018. doi: 10.1590/2317-1782/20152015008. 
[15] Mondelli, Maria Fernanda C. G. & Silva, Letícia L. (2011). Profile of the Patients 
Serviced 
in 
a 
High 
Complexity 
System. 
Arquivos 
Internacionais 
de. 
Otorrinolaringologia, 15, 29-34. Accesssed in December 20, 2018. doi: 
10.1590/S1809-48722011000100004. 
[16] Silva, Alexandre M. M., Mambrini, Juliana V. M., Peixoto, Sergio V., Malta, Deborah 
C. & Lima-Costa, Maria Fernanda. (2017). Use of health services by brazilian elderly 
with and without functional limitation. Revista de Saúde Pública, 51, 1-10. Accessed in 
December 20, 2018. doi: 10.1590/s1518-8787.2017051000243. 
[17] Vieira, Katiuscia L. D., Gomes, Vera Lúcia O., Borba, Marta R. & Costa, César 
Francisco S. (2013). Health care for male population in basic unit of family health: 
reasons for (not) attendance. Escola Anna Nery Revista de Enfermagem, 17, 120-7. 
Accessed in December 30, 2018. doi: 10.1590/S1414-81452013000100017. 

João Paulo N. A. Santos, Nathany L. Ruschel, Camila Z. Neves et al. 
 
542
[18] Petry, T. (2007). “Epidemiological profile of the patients treated at the hearing aid 
laboratory of the Federal University of Santa Maria.” Specialization monograph., 
Universidade Federal de Santa Maria. 
[19] Picinini, Taís A., Weigert, Liese L., Neves, Camila Z. & Teixeira, Adriane R. (2017). 
Restriction of social participation and satisfaction of hearing aids - post-adaptation 
study. Audiology Communication Research, 22, 1-8. Accessed in December 30, 2018. 
doi:10.1590/ 2317-6431-2016-1830. 
[20] Baraldi, Giovana S., Almeida, Lais C. & Borges, Alda C. C. (2007). Hearing loss in 
aging. Revista Brasileira de Otorrinolaringologia, 73, 64-70. Accessed in December 
30, 2018. http://www.scielo.br/pdf/ rboto/v73n1/a10v73n1.pdf. 
[21] Mueller, Gustav H., Ricketts, Todd. & Bentler, Ruth. (2014). Modern hearing aids: 
pre-fitting testing and selection considerations. San Diego, Plural. 
[22] Gaffney, Patricia. (2008). Reported hearing aid use versus datalogging in a VA 
population. Hearing Review, 15, 42. Accessed in December 30, 2018. 
http://www.hearingreview.com/2008/06/ reported-hearing-aid-use-versus-datalogging-
in-a-va-population/. 
 
 

 
 
 
 
 
 
 
 
 
 
 
 
VOLUME 3 


In: Encyclopedia of Audiology and Hearing Research 
ISBN: 978-1-53617-702-2 
Editors: Erno Larivaara and Senja Korhola 
© 2020 Nova Science Publishers, Inc. 
 
 
 
 
 
 
 
Chapter 37  
 
 
 
TELECOMMUNICATIONS RELAY SERVICE:  
FCC SHOULD STRENGTHEN ITS MANAGEMENT OF 
PROGRAM TO ASSIST PERSONS WITH HEARING OR 
SPEECH DISABILITIES* 
 
 
United States Government Accountability Office 
 
 
WHY GAO DID THIS STUDY 
 
TRS allows persons with hearing or speech disabilities to place and receive telephone 
calls, often with the help of a communications assistant who acts as a translator or facilitator 
between the two parties having the conversation. FCC is the steward of the TRS program and 
the federal TRS Fund, which reimburses TRS providers. 
GAO was asked to examine FCC’s management of the TRS program. This report 
examines, among other things, (1) changes in TRS services and costs since 2002, (2) FCC’s 
TRS performance goals and measures and how they compare with key characteristics of 
successful performance goals and measures, and (3) the extent to which the design of the 
program’s internal control system identifies and considers program risks. GAO analyzed 2002 
through 2014 service and cost data, compared TRS performance goals and measures to key 
characteristics of successful performance goals and measures, compared the design of the 
TRS’s internal control system with GAO’s standards for internal control, and interviewed 
officials from FCC, the 10 companies providing interstate TRS, and associations representing 
the deaf and hard of hearing. 
 
 
 
 
                                                        
* This is an edited, reformatted and augmented version of a United States Government Accountability Office 
publication, No. GAO-15-409, dated April 2015. 

United States Government Accountability Office 
 
544
WHAT GAO RECOMMENDS 
 
GAO recommends that FCC develop specific TRS performance goals and measures, 
conduct a robust program risk assessment, and improve the communication of TRS’s rules 
and procedures. In commenting on a draft of this report, FCC agreed with the 
recommendations and discussed actions it plans to take to implement them. 
 
 
WHAT GAO FOUND 
 
Since 2002, the overall minutes of use and costs for the Telecommunications Relay 
Service (TRS) program have grown significantly due to the advent of Internet-based forms of 
TRS and increased usage by the deaf and hard-ofhearing communities. Program data show 
that total TRS minutes have grown from about 53 million in “rate year” (July-to-June) 2002–
2003 to about 249 million in rate year 2013–2014, an almost five-fold increase. Total TRS 
costs have grown from about $104 million in the 2002–2003 rate year to about $818 million 
in the 2013–2014 rate year, an almost eight-fold increase. These increases stem from the 
popularity of new forms of TRS that use the Internet—such as Video Relay Service (VRS) 
and Internet Protocol Captioned Telephone Service—and the growth in consumers’ use of 
them, according to FCC, some providers, and one consumer group that GAO interviewed. 
The purpose of the TRS program under federal law is to provide persons who are deaf or 
hard of hearing or have a speech disability with telecommunications services that are 
“functionally equivalent” to those provided to persons without a hearing or speech disability, 
but FCC has not established specific performance goals to guide its efforts. FCC has 
established some performance measures for TRS in the form of minimum performance 
standards for TRS providers, such as regulations requiring that TRS communications 
assistants must answer 85 percent of TRS calls (except VRS) within 10 seconds; however, 
these standards are not linked to higher-level performance goals. By establishing performance 
measures before establishing performance goals, FCC may be spending time and resources on 
efforts not well linked to key dimensions of the program. Because of the lack of specific TRS 
performance goals—and specific performance measures crafted around those goals—it is 
difficult to determine in an objective, quantifiable way if TRS is making available 
functionally equivalent telecommunications services, and it is difficult for FCC to manage the 
program in a proactive, results-oriented manner. 
FCC has designed some internal controls for the TRS program, but lacks a 
comprehensive internal-control system to manage program risks. To address fraud, FCC has 
designed numerous controls to address compliance risks. For example, FCC eliminated the 
ability of TRS providers to use subcontractors in 2011 and strengthened TRS’s provider-
certification rules and user registration rules in 2013. Internal control standards call for the 
completion of a risk assessment to identify and analyze program risks. FCC’s last risk 
assessment, in 2013, was a one-page document that did not comprehensively identify 
programmatic risks. A robust risk assessment would help FCC identify risks to providing 
functionally equivalent services and inform the development of the overall internal-control 
system. Internal control standards also call for effective external communications to groups 
that can impact the program, such as TRS’s users and providers. FCC’s program policies are 

Telecommunications Relay Service 
 
545
spread across numerous reports and orders. Six of 10 TRS providers told us they experienced 
difficulties understanding TRS rules. FCC has sought comment on how best to reorganize its 
rules to improve clarity, but has not yet adopted any such changes. Doing so could improve 
FCC’s communication of TRS rules and procedures to the deaf community and the 
companies providing services. 
 
 
ABBREVIATIONS 
 
ADA 
Americans with Disabilities Act of 1990 
ASL 
American Sign Language 
CA  
“communications assistant” 
CTS 
Captioned Telephone Service 
FCC 
Federal Communications Commission 
FMFIA 
Federal Managers’ Financial Integrity Act of 1982 
GPRAMA GPRA Modernization Act of 2010 
HHI 
Herfindahl-Hirschman Index 
IP CTS 
Internet Protocol Captioned Telephone Service 
IP Relay 
Internet Protocol Relay 
NAD 
National Association of the Deaf 
NECA 
National Exchange Carrier Association 
MARS 
Multi-state Average Rate Structure 
OIG 
Office of Inspector General 
RLSA 
Rolka Loube Saltzer Associates 
STS 
Speech-to-Speech Relay Service 
TRS 
Telecommunications Relay Service 
TTY 
Text Telephone 
VRS 
Video Relay Service 
 
* * * 
 
April 29, 2015 
 
The Honorable Jeff Sessions  
United States Senate 
 
Dear Senator Sessions: 
 
Persons with hearing or speech disabilities want or need to have telephone conversations 
with persons who do not have such a disability— for example, a call to their doctor, their 
child’s school, or a close relative. The Telecommunications Relay Service (TRS) allows 
persons with a hearing or speech disability to place and receive telephone calls with the help 
of a “communications assistant,” (CA) who acts in various ways as an interpreter or facilitator 
between the two parties having the conversation.1 Different forms of TRS involve different 
technologies, including the use of video, the Internet, or special caption telephones. Section 

United States Government Accountability Office 
 
546
401(a) of the Americans with Disabilities Act of 1990 (ADA)2 requires the Federal 
Communications Commission (FCC), the steward of the TRS program and the Interstate 
Telecommunications Relay Services Fund (TRS Fund),3 to ensure that TRS is available, to 
the extent possible and in the most efficient manner, to persons in the United States with 
hearing or speech disabilities.4 TRS Fund disbursements were approximately $818 million in 
the 2013–2014 “rate year,”5 up from about $104 million in the 2002–2003 rate year, when 
according to FCC, Video Relay Service (VRS)—a popular form of TRS—began to be widely 
offered.6 
In 2008, the FCC Office of Inspector General (OIG) initiated an investigation into VRS 
fraud. Several individuals eventually pleaded guilty to committing VRS fraud, and FCC made 
changes to program rules intended to prevent and detect fraud, waste, or abuse in the 
program. You requested that we examine FCC’s management of the TRS program.7 This 
report addresses the following questions: 
 
1) How have the services and costs of the TRS program changed since 2002? 
2) What are FCC’s performance goals and measures for the TRS program, and how do 
they compare with key characteristics of successful performance goals and 
measures? 
3) To what extent does the design of the TRS program’s internal control system identify 
and consider program risks? 
4) According to program stakeholders, what challenges, if any, exist in ensuring quality 
services for users and a competitive environment for providers? 
 
For each of our research questions, we reviewed relevant FCC TRS orders and comments 
filed in FCC proceedings. We also conducted interviews with officials from the FCC; the 
FCC Office of Inspector General (OIG); Rolka Loube Saltzer Associates (RLSA), the current 
TRS Fund administrator; the National Exchange Carrier Association (NECA), the previous 
TRS Fund administrator; each of the 10 companies currently providing TRS; and associations 
representing the deaf, hard of hearing, and speech-disabled (referred to in this report as 
consumer groups). We analyzed these interviews to identify major themes that emerged about 
how and why TRS services have changed over time and what issues exist regarding quality, 
competition, and management of the program. To determine how the services and costs of the 
TRS program have changed since 2002, we obtained and analyzed FCC program data on 
costs and minutes of usage from 2002 through 2014 for the six major TRS services. We 
selected 2002 as the start date for our review because it was the first year that VRS—the 
service that accounts for the majority of TRS Fund payments—was widely offered. Based on 
documentation and conversations with FCC about how the data are collected and managed, 
we determined the cost and usage data were sufficiently reliable for the purposes of 
presenting program trends. To assess FCC’s performance goals and measures, we reviewed 
FCC documents, including strategic plans and performance plans, and interviewed FCC staff 
about the program’s goals and measures. We compared the goals and measures to key 
characteristics of successful goals and measures, as developed by GAO in previous work8 and 
as contained in the GPRA Modernization Act of 2010 (GPRAMA).9 To assess how the design 
of the TRS program’s internal control system identifies and considers program risk, we 
obtained TRS’s internal control documentation, including risk assessments, descriptions of 
control activities, and audit reports. We compared the design of the TRS internal control 

Telecommunications Relay Service 
 
547
system with the requirements contained in GAO’s Standards for Internal Control in the 
Federal Government.10 To obtain quantifiable information about issues related to TRS quality 
and competition, we conducted a survey of all 10 current TRS providers. We obtained a 100-
percent response rate to our survey. In addition, we conducted a market concentration 
analysis of the six main forms of TRS by analyzing the number of providers for each service 
from 2008 through 2014.11 We also analyzed other measures of market concentration for the 
two largest forms of TRS (VRS and Internet Protocol Captioned Telephone Service) in terms 
of current compensation received by providers for the most recent rate years. Appendix I 
provides additional information about our objectives, scope, and methodology, including a 
list of the organizations we interviewed. 
We conducted this performance audit from April 2014 to April 2015, in accordance with 
generally accepted government auditing standards. Those standards require that we plan and 
perform the audit to obtain sufficient, appropriate evidence to provide a reasonable basis for 
our findings and conclusions based on our audit objectives. We believe that the evidence 
obtained provides a reasonable basis for our findings and conclusions based on our audit 
objectives. 
 
 
BACKGROUND 
 
FCC manages and oversees the federal TRS program. FCC develops program rules and 
policies, sets annual rates for compensating providers, and oversees compliance with program 
rules. FCC contracts out the daily administration of the TRS Fund to a third-party 
administrator. NECA was the fund administrator from 1993 through June 2011; RLSA has 
been the administrator since July 2011. The administrator calculates proposed TRS 
compensation rates and contribution factors, collects fees, and handles the disbursements 
from the TRS Fund to TRS providers. 
According to FCC officials, prior to the ADA, there was no federal requirement for 
telephone providers to offer a means for people who were deaf, hard of hearing, or speech 
disabled to access the nation’s telephone services, although many states provided a form of 
TRS at that time. The ADA created the first requirement for a federal program, and the TRS 
program was established in 1993 in response. The ADA requires that persons with hearing or 
speech disabilities be provided with telecommunications services that are “functionally 
equivalent” to the services provided to persons without hearing or speech disabilities.12 Until 
2000, text-to-voice communication using a text telephone (TTY), a text input device, was the 
only form of TRS available to users. The advent of Internet-based TRS technologies, 
however, has increased telecommunications options for people who are deaf and hard of 
hearing. TRS is available in all 50 states, the District of Columbia, and the U.S. territories for 
local and long distance calls and some international calls. TRS involves no additional charges 
for the TRS user.13 According to FCC officials, FCC has plans to develop a central user-
registration database, but currently the number of TRS users is unknown. FCC officials told 
us that there are roughly 250,000 assigned VRS numbers, but assigned numbers do not equate 
one-to-one with the number of users.14 The Centers for Disease Control and Prevention’s 
National Center for Health Statistics reported in February 2014 that there are about 38-million 
individuals with hearing disabilities in the United States. Although the number of current 

United States Government Accountability Office 
 
548
TRS users is likely much lower than that, according to the National Association of the Deaf, 
this number could represent the number of potential users. 
There are currently six main forms of TRS: Video Relay Service (VRS), Text Telephone 
(TTY), Captioned Telephone Service (CTS), Internet Protocol Captioned Telephone Service 
(IP CTS), Internet Protocol Relay (IP Relay), and Speech-to-Speech Relay Service (STS) (see 
fig. 1). 
 
 
Source: GAO analysis of FCC data. ǀ GAO-15-409. 
Note: In December 2014, FCC’s Consumer and Governmental Affairs Bureau adopted a mid-year 
adjustment of the IP Relay rate for the sole provider remaining in this market. The rate is currently 
set at $1.37 for the first 300,000 minutes through June 30, 2015, and $1.67 for minutes over 
300,000 until May 31, 2015. This adjustment was made because the remaining provider asserted 
that it would be unable to remain in this business without such rate increases and FCC was 
concerned that ending this service would harm consumers. 
Figure 1. Description of the Six Forms of Telecommunications Relay Service (TRS) (as of January 1, 
2015). 
TRS providers include both traditional telecommunications companies, such as AT&T or 
Sprint, and companies primarily focused on providing TRS service, such as Convo or the 
Communication Axess Ability Group. Companies are compensated from state TRS funds for 
the costs of providing intrastate TRS and from the federal TRS Fund for the costs of 

Telecommunications Relay Service 
 
549
providing interstate and Internet-based TRS. There are currently 10 TRS providers that are 
compensated from the federal TRS Fund. No single company offers all six forms of TRS. For 
example, in October 2014, six companies provided VRS, while three provided TTY and CTS. 
For all forms of Internet-based TRS, providers must be certified by FCC before they can offer 
service. 
TRS companies provide TRS services and are then reimbursed on a per-minute basis out 
of the TRS Fund.15 The TRS reimbursement rate varies by service and is typically set by FCC 
annually based on reported provider costs, which include an 11.25-percent return on capital 
investment. For example, as shown in figure 1, the 2014–2015 reimbursement rates ranged 
from $1.03 per minute to $5.29 per minute for the different forms of TRS. In the 2013–2014 
rate year, approximately $818 million in total reimbursements were paid out of the TRS Fund 
to the companies that provided TRS services. 
The rates for the various forms of TRS are determined in the following ways:16 
 
• 
Text Telephone, Speech-to-Speech, Captioned Telephone Service, and Internet 
Protocol Captioned Telephone Service: FCC uses the Multi-state Average Rate 
Structure (MARS) methodology to determine compensation. MARS uses an average 
of competitively bid state rates for intrastate TRS to determine predictable, fair, and 
reasonable costs of interstate TRS. 
• 
Internet Protocol Relay: FCC employs a price cap regulation to determine the 
compensation rate for IP Relay. 
• 
Video Relay Service: According to FCC, to encourage competition while 
recognizing efficiencies through economies of scale, FCC compensates VRS 
providers using a three-tiered rate structure based on the minutes of service provided. 
For January 1, 2015, through June 30, 2015, VRS rates are: 
• 
Tier I rate: $5.29 per minute for minutes up to 500,000 per month; 
• 
Tier II rate: $4.82 per minute for minutes from 500,000.1 to 1,000,000 per 
month; and 
• 
Tier III rate: $4.25 per minute for minutes over 1,000,000 per month. 
 
All VRS providers are compensated at the tier I rate for their first 500,000 minutes, but as 
providers become larger and provide more minutes of service, they are compensated at lower 
rates for the additional minutes. The three-tier rate structure is intended to reflect cost 
differences among large and small providers and encourage current entrants to remain in the 
VRS market, while improving their efficiency over time. FCC intends to eliminate the rate 
tiers over time. In its 2013 VRS Reform Order, FCC adopted a schedule to phase out the 
differences between tier I and tier II rates by January 2016 as part of a “glide path” toward an 
eventual unitary cost-based rate for VRS.17 According to FCC, it is seeking to replace the 
cost-of-service ratemaking approach for VRS with more market-based approaches, to the 
extent that this approach can be accomplished without adversely affecting the public interest 
and goals of the ADA. FCC believes that a market-based approach to providing VRS will 
result in lower costs for the TRS program. 
 
 

United States Government Accountability Office 
 
550
TOTAL TRS MINUTES AND COSTS HAVE GROWN SIGNIFICANTLY 
SINCE 2002 DUE TO INTERNET-BASED TRS AND INCREASED USAGE 
 
According to officials from FCC, most of the TRS providers, and all of the consumer 
groups that we interviewed, the development of Internet-based TRS technologies and 
increased usage of these technologies have led to growth in overall program minutes and 
costs. TRS program data show that total TRS minutes have grown from about 53 million in 
rate year 2002–2003 to about 249 million in rate year 2013–2014, an almost fivefold increase. 
Total TRS costs have grown from about $104 million in 2002 to about $818 million in rate 
year 2013–2014, an almost eight-fold increase (see fig. 2). According to FCC, some 
providers, and one consumer group we spoke with, the development of TRS technologies that 
use the Internet—such as VRS, IP Relay, and IP CTS, along with consumer knowledge about 
them—has led to wider use of TRS services. Since the federal TRS Fund supports the 
provision of Internet-based TRS, a rise in federal TRS costs occurred in concert with the 
development and popularity of the Internet-based services (VRS initially and then IP CTS). 
According to FCC, some providers, and one consumer group, other technology advancements 
also have increased TRS usage. For example, CTS and IP CTS involve the use of a telephone 
that provides people who are hard of hearing with captions of what the other party to the 
conversation is saying. CTS and IP CTS have opened the TRS market to a new group of 
users—senior citizens—some of whom can become increasingly unable to follow everything 
said in a telephone conversation due to hearing loss late in life. Also, two consumer groups 
noted that consumers can now use mobile phone applications to access most TRS, thus no 
longer being tied to specialized equipment in the home and likely further increasing total 
program usage. 
The largest portion of TRS costs are for VRS, which is used by members of the deaf 
population who communicate in American Sign Language (ASL). According to the National 
Association of the Deaf (NAD), the primary reason for VRS’s increased use is that it allows 
users to communicate at roughly 200 words-per-minute instead of the 60 words¬per-minute 
enabled by the typing of traditional TTY. In addition, according to NAD, ASL can be a deaf 
individual’s native language and, when used as part of a telephone conversation, provides a 
richer communication experience, much closer to that of a hearing individual. VRS requires a 
specialized CA workforce of ASL interpreters who, according to some of the stakeholders we 
spoke with, can be in low supply and can command fairly high salaries. These higher CA 
costs and, according to one provider, the more expensive video link between the deaf 
individual and the CA have led to VRS costs per minute that are higher than other forms of 
TRS. VRS costs grew from about $25 million in rate year 2002–2003 to about $601 million 
in rate year 2013–2014. VRS reimbursement costs peaked in the 2008–2009 rate year at $621 
million, which accounted for about 85 percent of the TRS fund at that time. In rate year 
2013–2014, VRS accounted for about 74 percent of the $818 million in TRS reimbursements 
(see fig. 3). IP CTS is the second most reimbursed TRS service at about 21 percent of total 
TRS costs. 

Telecommunications Relay Service 
 
551
 
Source: GAO analysis of FCC data. ǀ GAO-15-409. 
Note: According to FCC officials, cost data from some TRS forms prior to July 2011 either could not 
be located or were not reliable, so these data are not part of this graphic. However, these omissions 
do not significantly affect this graphic because they were low amounts at the beginning of the TRS 
forms’ availability. 
Figure 2. Total Telecommunications Relay Service Program Costs, 2002–2003 to 2013–2014. 
 
 
Source: GAO analysis of FCC data. ǀ GAO-15-409. 
Figure 3. Percentage of Total Costs of Each Form of Telecommunications Relay Service in Rate Year 
2013–2014. 

United States Government Accountability Office 
 
552
Although VRS costs are the largest percentage of current program costs, IP CTS costs are 
growing at the fastest rate. From rate years 2009–2010 through 2013–2014, IP CTS grew 
from $9 million to $174 million, or about a 19-fold increase (see fig. 4). Some stakeholders 
we spoke with saw IP CTS as an area where TRS usage is likely to continue increasing as 
baby boomers age and face increased hearing loss. Today, VRS and IP CTS, both Internet-
based technologies, account for about 95 percent of TRS costs. 
 
 
Source: GAO analysis of FCC data. ǀ GAO-15-409. 
Note: We did not include cost data for CTS and IP CTS prior to July 2009 in this graphic because, 
according to FCC officials, it either did not exist or was not reliable. In addition, according to FCC 
officials, prior to July 2006, STS cost data were combined with TTY cost data. 
Figure 4. Total Costs for Each Form of Telecommunications Relay Service, 2002–2003 to 2013–2014. 
As shown in figures 4 and 5, other forms of TRS are declining or staying the same in 
terms of costs and usage. IP Relay and traditional TTY, both of which require the person who 
is deaf or hard of hearing to type his or her part of the conversation, are declining in both 
minutes of use and costs. IP Relay minutes have decreased from about 83 million in rate year 
2006–2007 to about 18 million in rate year 2013–2014. TTY minutes have decreased from 
about 27 million in rate year 2002–2003 to about 3 million in rate year 2013–2014. Similarly, 
total program costs for both services have declined as well. Officials from FCC, TRS 
providers, and consumer groups told us that the growth in popularity of VRS and IP CTS 
have contributed to a decrease in the popularity of IP Relay and TTY. VRS and IP CTS allow 
for much quicker and more natural conversations than the text-based IP Relay and traditional 
TTY. In recent years, CTS and STS have remained at a steady level in both minutes of use 
and costs. CTS functions like IP CTS, but uses the traditional telephone network rather than 
the Internet. STS serves a small, discrete population with severe speech disabilities. As shown 
in figure 3, both services account for small percentages of the entire cost of the TRS Fund. In 
rate year 2013–2014, CTS costs accounted for about 2 percent of the fund, while total STS 

Telecommunications Relay Service 
 
553
costs were less than 1 percent of the fund. Figure 5 shows changes in minutes of use from rate 
years 2002–2003 through 2013–2014 for each form of TRS. 
 
 
Source: GAO analysis of FCC data. ǀ GAO-15-409. 
Note: GAO did not include minutes of usage data for CTS and IP CTS prior to July 2009 because, 
according to FCC officials, data did not exist or were not reliable. 
Figure 5. Changes in Minutes of Use for Each Form of Telecommunications Relay Service, 2002–2003 
to 2013–2014. 
The per-minute reimbursement rates for TRS have varied over time, although the 
reimbursement rate for VRS has decreased significantly. VRS reimbursement rates decreased 
from about $17 per minute in 2001– 2002 to about $4.25 per minute for VRS Tier 3 in 2015 
(see fig. 6). Nonetheless, despite this decrease in the VRS reimbursement rate, its costs have 
grown significantly over this time period due to increased usage as discussed previously. The 
reimbursements rates for other forms of TRS, such as CTS, IP CTS, TTY, and STS, have 
increased moderately since 2011, while rates for IP Relay have decreased. 
 

United States Government Accountability Office 
 
554
 
Source: GAO analysis of FCC data. ǀ GAO-15-409. 
Note: GAO used reimbursement rates for VRS tier III from rate year 2007-2008 through rate year 
2013-2014. Reimbursement rates for IP Relay begin in rate year 2002-2003. Reimbursement rates 
for CTS and IP CTS begin in rate year 2007-2008. 
Figure 6. Trends in Telecommunications Relay Service (TRS) Cost Reimbursement Rates over Time. 
According to FCC, one provider and one consumer group, reducing fraud also has played 
a role in reducing costs for some forms of TRS. According to the FCC OIG, as the FCC OIG 
investigated VRS fraud and VRS reimbursement rates decreased, VRS costs decreased from 
rate year 2008–2009 to rate year 2010-2011, as shown in figure 4, even as VRS minutes 
increased in these rate years. In addition, FCC officials have told us that the efforts of the 
FCC Enforcement Bureau and OIG have contributed to a decrease in IP Relay fraud and thus 
IP Relay costs. For example, according to FCC officials, FCC’s Enforcement Bureau 
investigated IP Relay providers to determine whether they had implemented a reasonable 
process to verify the accuracy of users’ registration information.18 Similarly, the FCC OIG 
worked with the Department of Justice to investigate allegations that a TRS provider had 
submitted false claims, such as Nigerian scam calls, from foreign locations in provision of an 
IP Relay.19 The FCC OIG attributes some of the reductions in IP Relay costs since 2008 to 
these fraud reduction efforts. In addition to its fraud reduction efforts, FCC made TRS 
providers’ research and development costs and outreach costs no longer reimbursable in 
FCC’s June 2013 VRS Reform Order, which could also reduce costs for some forms of 
TRS.20 
 
 
 

Telecommunications Relay Service 
 
555
FCC HAS NOT ESTABLISHED PERFORMANCE GOALS AND RELATED 
PERFORMANCE MEASURES FOR THE TRS PROGRAM 
 
We have previously found that results-oriented organizations commonly perform a 
number of key practices to effectively manage program performance.21 In particular, results-
oriented organizations implement two key practices to lay a strong foundation for successful 
program management. First, these organizations set performance goals to clearly define 
desired program outcomes. Second, they develop performance measures that are clearly 
linked to the performance goals. 
With regard to the TRS program, the ADA directs FCC to ensure that 
telecommunications services are available, to the extent possible and in the most efficient 
manner, to persons with a hearing or speech disability, and that such services are 
“functionally equivalent” to the telecommunications services available to individuals without 
a hearing or speech disability. 22 All of the FCC officials with whom we spoke agreed that 
the high-level purpose of the TRS program is this provision of functionally equivalent 
telecommunications to people with hearing or speech disabilities, but FCC has not established 
specific performance goals to guide its efforts toward achieving that purpose. Officials told us 
that they believe that the TRS program’s rules and numerous related reports and orders have 
sufficiently identified the performance goals of the program. We identified some performance 
measures associated with the program, but these measures are not clearly linked to any 
agency or program performance goals and are sometimes not well defined or measureable. 
Without stated program goals, it can be challenging for FCC to determine the extent to which 
it is fulfilling the purpose of the program. 
The Government Performance and Results Act requires agencies to develop a 
performance plan covering each program activity set forth in the budget, which includes 
developing program goals that are objective, quantifiable, and measurable. 23 TRS is 
mentioned in FCC’s most recent budget request and performance plan, which, for budgetary 
purposes, groups TRS with FCC’s four universal service support programs. However, there 
are no stated performance goals specific to the TRS program. There have been performance 
goals for TRS in previous performance plans. For example, in its fiscal year 2012 
performance plan, FCC had a goal to increase access to TRS services. However, this goal 
does not appear in current performance plans, and FCC officials told us they were unable to 
determine how many unique users participated in the TRS program or the number of potential 
TRS users. Thus, no performance measure—or method for obtaining the measurement data— 
was linked to this goal, making it difficult for FCC to demonstrate whether or to what extent 
access to services among the target populations had increased. 
One useful practice for developing successful performance goals that we have identified 
in previous work is to create a set of goals that address important dimensions of a program’s 
performance and balance competing priorities.24 For example, officials told us that important 
dimensions of the program are, among other things, the quality of the services provided to 
users and the existence of competition among TRS providers. However, FCC has not 
established performance goals related to these dimensions. For instance, FCC lacks any goal 
related to interpreter accuracy, which consumer groups we met with stressed was critical to 
achieving quality services. Accurate relay of important medical, legal, or financial calls by 
CAs was of particular concern to consumer groups with whom we spoke. Without goals 

United States Government Accountability Office 
 
556
related to important dimensions of service quality, such as interpreter accuracy, it becomes 
difficult to determine if this attribute of functional equivalency is being met and to identify 
whether programmatic changes need to be made. FCC officials acknowledged that there is no 
interpreter accuracy goal, but stated that they believe there is no practical way to evaluate 
interpreter accuracy. However, the consumer groups and some service providers we met with 
told us that interpreter accuracy could be evaluated with test scripts. Similarly, with regard to 
the important program dimension of competition, different numbers of providers offer 
different forms of TRS, but FCC has no performance goals with relation to levels of 
competition or ratemaking. For example, FCC stated in its 2013 VRS Reform Further Notice 
of Proposed Rulemaking that it believes there is a need to replace its VRS cost-of-service 
ratemaking with more market-based approaches, and proposed transitioning to contract prices 
set through a competitive-bidding process, where feasible, and auctioning a portion of VRS 
traffic.25 However, the proposed rulemaking set forth a number of questions about how such 
an approach would work, including questions about bidder qualifications and ensuring the 
quality of services. Establishing performance goals around competition and ratemaking could 
help guide FCC’s efforts in these areas and improve the transparency of FCC’s actions, as 
decisions could more clearly be linked to the achievement of program goals. 
Although FCC lacks specific performance goals, FCC does have in place some specific 
performance measures for TRS in the form of minimum program standards.26 Compliance 
with the minimum standards is necessary for providers to receive compensation from the TRS 
Fund. These performance measures include, among others, that: 
 
• 
Providers shall transmit traditional TRS conversations in real time. 
• 
CAs must have a typing speed of at least 60 words per minute. 
• 
Providers must have the following service functionalities: (1) call release, (2) speed 
dialing, and (3) three-way calling. 
• 
Emergency calls must be able to be expeditiously transferred to an emergency 
services provider as if a caller had dialed 911 directly. 
• 
TRS calls (except VRS) must be answered by CAs within 10 seconds 85 percent of 
the time. 
 
In addition, to its credit, FCC has formally established performance measures for the TRS 
Fund administrator. For example, measures such as the timeliness of TRS Fund collections, 
payments, and status reports to FCC, among others, are included in FCC’s contract with 
RLSA. 
Although FCC has established some TRS performance measures, these measures are not 
linked to any TRS or universal-service performance goals. By establishing performance 
measures before establishing performance goals, FCC may be spending its time and 
resources, and those of the service providers or program administrator, on efforts not well 
linked to key dimensions of the program. Also, the performance measures FCC is using for 
the program can be difficult to assess because criteria are lacking. For instance, other 
minimum standards state, among other things, that CAs must be “sufficiently trained” to meet 
the needs of individuals with hearing and speech disabilities; must have “competent skills” in 
grammar, spelling, and interpretation of typewritten ASL; and must possess “familiarity” with 
hearing and speech disability cultures, languages, and etiquette. These terms are not defined 
by FCC and, as a result, are difficult to measure in a consistent manner across TRS providers. 

Telecommunications Relay Service 
 
557
It is up to the service providers to determine that they are meeting these requirements and 
self-certify that they are doing so.27 
Thus, although FCC has developed some important performance output measures 
through its minimum standards for the TRS program, best practices for successful 
management of a program call for a well-balanced set of outcome and output measures that 
link to specific program performance goals.28 Performance measurement is critical to 
determining a program’s progress in meeting its intended outcomes and allowing Congress, 
FCC, and RLSA to assess the effectiveness of the TRS program and determine if operational 
changes are needed. Because of the lack of specific TRS performance goals—and specific 
performance measures that are crafted around those goals—it is difficult to determine in an 
objective, quantifiable way if TRS is fulfilling its purpose of making available functionally 
equivalent telecommunications services to persons with hearing and speech disabilities, and it 
is difficult for FCC to manage the program in a proactive, results-oriented manner. 
 
 
FCC HAS DESIGNED SOME INTERNAL CONTROLS BUT LACKS  
A COMPREHENSIVE INTERNAL CONTROL SYSTEM TO MANAGE 
PROGRAM RISKS 
 
An Internal Control System Helps Assure That Program Goals Are Met 
 
Internal control is an integral component of an agency’s management process that 
provides reasonable assurance that the objectives of an agency’s program are being achieved. 
Program objectives can be broadly classified into one or more of the following categories: 
 
• 
Operations: the effectiveness and efficiency of program operations; 
• 
Reporting: the reliability of reporting for internal and external use; and 
• 
Compliance: program compliance with applicable laws and regulations. 
 
GAO’s Standards for Internal Control in the Federal Government commonly referred to 
as the “Green Book,” defines the standards for internal control in the federal government.29 
The Federal Managers’ Financial Integrity Act of 1982 (FMFIA) requires federal executive-
branch entities to establish internal control in accordance with these standards.30 GAO has 
developed a tool to assist agencies in this process,31 as has OMB with its Circular A-123.32 
The Green Book identifies the following five components as being the highest level of the 
hierarchy of standards for internal control in the federal government: 
 
• 
Control Environment: The foundation for an internal control system. The control 
environment provides the discipline and structure to help an entity achieve its 
objectives. 
• 
Risk Assessment: Assesses the risks facing the entity as it seeks to achieve its 
objectives. This assessment provides the basis for developing appropriate risk 
responses. 
• 
Control Activities: The actions management establishes through policies and 
procedures to achieve objectives and respond to risks in the internal control system. 

United States Government Accountability Office 
 
558
• 
Information and Communication: The quality of information that management 
uses to support the internal control system. Communicating quality information is 
vital for an entity to run and control its operations. 
• 
Monitoring: Assesses the quality of performance over time and ensures that the 
findings of audits and other reviews are promptly resolved. 
 
According to the internal control standards, these five components must be effectively 
operating together in an integrated manner to provide assurance that operations, reporting, 
and compliance objectives are met. Management is responsible for an effective internal-
control system. As part of this responsibility, management sets the entity’s objectives, 
implements controls, and evaluates the internal control system. 
 
 
FCC Has Designed Some TRS Internal Controls That Address Compliance 
and Reporting 
 
FCC has designed some internal controls that focus on program compliance and reporting 
objectives. In response to TRS fraud, first identified by the FCC OIG audits of TRS 
providers, FCC implemented rule changes. FCC OIG officials told us that they first became 
suspicious of possible fraudulent activity in the TRS program based on particular 
reimbursement claims that they judged to be unusual. They told us that at the time there was 
insufficient scrutiny of call data for irregularities by NECA, the TRS Fund administrator. The 
FCC OIG began a formal investigation of the TRS program in 2008.33 As a result of the joint 
investigation among FCC’s OIG, the Department of Justice, the Federal Bureau of 
Investigation, and the United States Postal Service, 26 people were charged in a scheme to 
steal more than $50 million from the TRS Fund.34 FCC has addressed many of the 
vulnerabilities identified by the OIG through numerous rulemakings. For example, from 2010 
through 2013, FCC, among other things, designed control activities to address specific fraud 
risks: 
 
• 
Prohibited per-minute reimbursement for internal calls: To address provider 
practices intended to inflate call minutes, FCC reiterated its policy that calls made by 
or to employees of VRS providers were not eligible for compensation from the TRS 
Fund on a per-minute basis. 35 
• 
Eliminated subcontracting: In 2011, FCC changed the certification eligibility 
requirements for TRS providers to require that all Internet-based providers be 
directly certified by the FCC. Prior to this order, providers who were certified by 
FCC or by a state commission were allowed to subcontract some of the provision of 
services to third parties that did not have to be certified. FCC officials and other 
stakeholders told us that much of the fraud that had occurred in the VRS program 
was related to these non-certified subcontractors, specifically in the form of 
inappropriately generating minutes. Now that all providers are directly certified, 
fraud in the VRS market has decreased dramatically, according to FCC.36 
• 
Strengthened certification: In 2011, FCC amended the TRS certification process to 
require that providers submit evidence demonstrating compliance with FCC’s rules 
and authorizing on-site inspections of providers’ facilities.37 In 2013, FCC further 

Telecommunications Relay Service 
 
559
changed provider certification rules to require providers’ senior managers to sign 
under penalty of perjury that their companies’ claims for compensation from the fund 
were valid and that the data they reported were true and accurate.38 This change was 
implemented to deter fraudulent activity and further ensure that providers’ senior 
managers were diligent in verifying the information they submitted for 
reimbursement. 
• 
Strengthened user registration rules: In 2012, the Commission implemented a rule 
that prohibited IP Relay providers from handling non-emergency calls made by first-
time users without first verifying the user’s registration information.39 Prior to this 
rule change, IP relay services entailed some degree of anonymity of end users and 
provided the technical ability to mask one’s calling location. Some individuals 
exploited this anonymity by using IP relay services to perpetrate scams and other 
types of abuse. In 2013, FCC also established new VRS registration rules to address 
the problems of fraud, waste, and abuse by improving the mechanism by which VRS 
users are verified. The new rule requires VRS users to register with each provider 
they use and certify that they had a qualifying disability. Users were also given a 10-
digit number that was associated with their registered account. According to FCC 
officials, this change has drastically reduced the number of fraudulent calls placed 
through the TRS program. 
 
In addition to these controls, FCC has also implemented controls with regard to the TRS 
Fund’s administrator and routine audits of the program. FCC better defined the role of the 
fund administrator in the contract it entered with RLSA. Among other things, the contract 
outlined the fund administrator’s roles in collecting, disbursing, and protecting TRS funds; in 
providing routine reports to FCC on the status of the fund; and in analyzing provider data for 
irregularities and withholding compensation when appropriate. FCC has also implemented an 
audit program, with audits conducted by the OIG, which includes periodic audits on the fund 
administrator and audits of service providers to ensure compliance with several TRS program 
rules. Since 2008, the OIG has conducted one audit of the fund administrator and 33 audits of 
providers.40 OIG officials told us that their audits of TRS have focused on fraud and financial 
risks to the TRS Fund rather than risks related to the overall management of the TRS program 
or the quality of the relay services provided to customers. 
 
 
FCC Lacks a Comprehensive Internal Control System to Manage TRS 
Program Risks 
 
FCC has designed some internal controls for the TRS program, particularly with respect 
to program compliance; however, as previously discussed, FCC does not have clear program 
performance goals. Without performance goals, it is difficult to create a comprehensive 
internal control system which identifies and manages the risks to achieving the program’s 
goals. It is clear from FCC’s agency-wide plans and program-specific orders that combating 
fraud is a priority, and FCC has designed a number of controls to do so. But the purpose of 
the TRS program is to provide functionally equivalent telecommunications to persons with 
hearing or speech disabilities. Thus, it is important that FCC’s internal control system be 
designed around identifying and addressing risks to providing functionally equivalent service, 

United States Government Accountability Office 
 
560
of which fraudulent activity would be one risk. We compared FCC’s control system with 
Green Book standards and found several instances where practices were not aligned. These 
instances, among others, create risks that program’s resources are not being effectively used 
to achieve the program’s purpose. 
 
• 
Risk Assessment: Internal control standards call for a risk assessment that will 
identify risks, both internal and external, and analyze the risks for possible effects. 
Risk assessments are then used to help management formulate an approach for risk 
management. According to documents provided by FCC, the last risk assessment of 
the TRS program was conducted in 2013. FCC’s risk assessment of the TRS program 
was a one-page document that did not comprehensively identify risks or 
considerations of all interactions between FCC and external parties. We found that 
the risk assessment focused on fraud, waste, and abuse and did not look at other risks 
to achieving the provision of functionally equivalent telecommunications to persons 
who are deaf, hard of hearing, or have speech disabilities. Six total risks were 
identified, none of which was specific to TRS. For example, one of the six risks 
identified in the TRS risk assessment was the “failure by management to recognize 
fraud in FCC programs.” 
• 
While it is important that fraud risks and risks to program resources are identified 
and addressed to keep the program efficient and viable, the Green Book and other 
internal control guidance state that a risk assessment should identify all relevant risks 
posed to achieving program goals.41 Without a robust risk assessment of the TRS 
program, FCC may not be able to identify and address the relevant risks to ensuring 
the provision of functionally equivalent telecommunications to people with hearing 
and speech disabilities. 
• 
Information and communication: Internal control standards call for effective 
external communications to those groups that can have an impact on programs; such 
groups in the case of TRS, would include TRS users and service providers. TRS rules 
are contained in federal regulations,42 and FCC program policies are explained across 
numerous reports and orders. Six of 10 providers told us about challenges 
understanding the program’s rules that applied to them in part because rules for a 
specific type of TRS service are discussed throughout FCC orders rather than 
compiled in one place for each type of TRS service. As an example, we found 
changes affecting IP Relay services incorporated into the 2013 VRS Reform Order. 
Specifically, among other things, the order modifies the rules so that all Internet-
based providers are required to obtain individual user consent before a default 
provider change may occur. Thus, a provider of IP CTS, for example, might not 
know that rules for its service were part of a VRS order and could be unaware of 
changes affecting its company. Further, this issue was highlighted in a 2008 OIG 
audit of the program when the OIG recommended that FCC develop a TRS 
handbook for providers to supplement FCC rules and consolidate TRS program and 
administrative policies into a single reference guide. FCC officials told us that such a 
TRS handbook has not been created because they have prioritized other activities in 
managing the TRS program. In 2011, FCC, in observing that TRS rules had become 

Telecommunications Relay Service 
 
561
“somewhat unwieldy” since 2000, sought comment on whether to reorganize section 
64.604 of its rules, which pertains to the TRS program.43  
FCC did not act on that proposal, but in 2013 proposed instead to revise the structure 
of its rules so that they are service specific and transmission specific, where 
appropriate, and sought comments more broadly on how best to reorganize its rules 
to improve program clarity. To date, FCC has not improved its external 
communications to program users or providers through better organization of TRS 
rules and regulations nor provided any specific time frames for doing so. 
• 
Monitoring. Monitoring can include, for a program like TRS that serves the public, 
the analysis of consumer complaints. Such complaints may indicate that deficiencies 
exist—deficiencies that could be investigated to determine any possible underlying 
causes. FCC aggregates the TRS consumer complaints filed with FCC, state 
regulators, and providers, as well as aggregating complaints by service, complaint 
type, and the amount of time it takes to resolve them. For example, 76 percent of the 
272 TRS complaints were about VRS. The types of TRS complaints most frequently 
received included complaints about customer service, interoperability of a 
consumer’s equipment with a service provider’s network, and “slamming” and 
“porting.”44  
Subsequent to our request for any analyses FCC may have conducted on TRS 
complaints, FCC began conducting an analysis in August 2014 on complaints 
received from July 1, 2013, through June 30, 2014.45 According to FCC, there had 
not been any analysis like this conducted before. As a result of not routinely 
analyzing consumer complaints about TRS, FCC was missing an opportunity to 
monitor the TRS program and to proactively identify recurring issues, trends, and 
potential risks to the program and determine if corrective actions were needed.  
We have previously examined and noted concerns with FCC’s complaint process and 
recommended that FCC expand its outreach to consumers about this process and 
establish policies and procedures for monitoring and analyzing trends in consumer 
complaints, among other things.46 FCC agreed with our prior recommendation and, 
with regard to TRS, officials told us that they plan to routinely analyze TRS 
complaints going forward. In January 2015, FCC launched a new online consumer 
help center, which, according to FCC, will make it easier for consumers to file 
complaints and help streamline FCC’s process for synthesizing and analyzing trends 
in consumer complaints. Such analyses could help provide FCC with useful TRS 
data to help it make performance-based decisions and evaluate its efforts with regard 
to management of the TRS program. 
 
 
STAKEHOLDERS CITED SEVERAL CHALLENGES TO TRS SERVICE 
QUALITY AND COMPETITION 
 
Stakeholders Identified Challenges to Providing High Quality Services 
 
Consumer groups and TRS providers identified, through interviews and a survey, the 
following challenges to TRS service’s quality: the lack of skill-based routing, interpreter 
accuracy, and decreasing TRS reimbursement rates. 

United States Government Accountability Office 
 
562
Skill-Based Routing 
Some of the consumer groups told us that the lack of skill-based routing—which would 
allow users making a TRS call to request a CA with a particular specialty, such as a medical 
or legal expertise—negatively affects TRS service quality. For example, one consumer group 
representative told us that under the current program a TRS user’s assignment is based on 
interpreter availability. The expectation that interpreters will be the best fit for all calls is not 
reasonable and can lead to poor communication, especially during medical or legal calls. In 
addition, 7 of the 10 providers responding to our survey said that the lack of skill-based 
routing leads to lower quality service (see app. II for our survey results). Some consumer 
groups have requested that VRS providers be allowed, or required, to offer skill-based 
routing. FCC is not in favor of compensating VRS providers for skill-based routing services 
due in part to a number of implementation issues. For example, FCC pointed out in its 2013 
VRS Reform Order that skill-based routing implementation issues include how to reconcile a 
skill-based routing function with the requirement that VRS calls be answered in the order 
received, the availability of CAs to meet speed of answer requirements, determining the 
appropriate skills needed for specialized routing, and determining if skill-based routing 
should be mandatory or voluntary.47 
 
Interpreter Accuracy 
Some consumer groups we interviewed identified interpreter accuracy as a TRS service 
quality challenge. Specifically, according to one consumer group, the wide range of skill 
levels across CAs creates the greatest challenge to users in obtaining accurate interpretation. 
They noted that some interpreters do not have the required skill level to ensure accuracy, a 
circumstance that can lead to misunderstandings between the two participants. FCC officials 
noted that TRS rules allow users to request a change in the interpreter when the user 
determines that effective communication is not occurring. FCC requires interpreters to be 
“qualified” but leaves it to the providers to make that determination.48 FCC officials told us 
that some providers employ only certified interpreters to meet this requirement, while other 
providers use their own testing and evaluation methods to determine which interpreters are 
qualified. 
 
TRS Reimbursement Rates 
According to providers, decreasing the amount that TRS providers are reimbursed for 
their services can affect a company’s ability to hire and retain qualified interpreters. For 
example, 8 of 10 providers responding to our survey indicated that the current TRS 
reimbursement rates make it much more difficult to hire and retain qualified interpreters. 
Decreases in TRS reimbursement rates, according to one provider, have led some providers to 
find ways to cut costs by hiring less skilled—and therefore less expensive—CAs. However, 
there appears to be disagreement between VRS providers and FCC about whether VRS 
reimbursement rates are set at appropriate levels. According to the 2013 VRS Reform Order, 
in setting TRS Fund compensation rates for VRS for the 2010–11 fund year, FCC found that 
in the prior 4 years—where the rates had been set based on providers’ projected costs—
providers had been overcompensated by more than $2.00 per minute as a result of a reliance 
on projected costs and inaccurate demand forecasts submitted by providers.49 
 
 

Telecommunications Relay Service 
 
563
Stakeholders Identified Challenges to Encouraging Competition  
and Technological Innovation 
 
Consumer groups and TRS providers identified, through interviews and a survey, the 
following TRS-related competition challenges: TRS rate reductions,50 the lack of 
compensation for marketing and outreach and research and development, and the lack of 
interoperability between VRS providers. 
 
TRS Rate Reductions 
The amount of compensation TRS providers receive has decreased over time, 
specifically, for VRS services.51 For example, as previously discussed, VRS rates have 
decreased from 2003 to 2015.52 Providers noted that the rate reductions have affected 
competition. Specifically, all 10 providers stated that TRS rate reductions decreased 
competition, with 6 of those providers stating that TRS rate reductions significantly decreased 
competition. Both providers and some consumer groups told us that TRS rate reductions have 
prevented new entrants from coming into the market and subsequently limited the number of 
providers a user can choose from. Further, providers told us rate reductions and increases in 
compliance requirements will lead more providers to exit the market. However, FCC stated in 
its 2013 VRS Reform Order, that there is no evidence proving that per-minute costs have 
dropped dramatically based on the current TRS-fund administrator’s recalculated average of 
providers’ current reported per-minute costs.53 In addition, according to FCC, there are other 
reasons outside of rate reductions that could compel a provider to leave the market, such as a 
provider’s inability to compete effectively with other more efficient providers. 
We conducted a market concentration analysis and found that competition among TRS 
providers is decreasing as the number of providers for most TRS services is decreasing. For 
example, the number of TRS providers has decreased from rate years 2008 through 2014 for 
all six TRS services except IP CTS. (See app. III for more detailed results of our market 
concentration analysis.) In addition, the VRS and IP CTS services, which have more 
providers and may appear to have the most competition, are dominated by a few providers. 
Our analysis found that in 2013–2014 rate year the top VRS provider controlled most of the 
VRS market while the top three IP CTS providers controlled over 98 percent of the market, 
based on total minutes of service provided.54 
 
Lack of Compensation for Marketing and Outreach and Research and Development 
Most TRS providers noted that the lack of compensation for marketing and outreach and 
research and development hinders competition. For example, 7 out of 10 providers stated that 
the lack of compensation to TRS providers for marketing and outreach has significantly 
decreased their ability to compete. According to one provider, a provider’s marketing and 
outreach efforts cut significantly into a provider’s profit margin, and as a result, the lack of 
marketing and outreach compensation discourages new entrants into the market and inhibits a 
provider’s ability to attract new customers through marketing efforts. According to FCC 
officials, they no longer reimburse providers’ marketing and outreach efforts because they 
cannot effectively determine whether there is a sufficient amount of potential new customers 
to warrant such an incentive. In addition, FCC stated in its 2013 VRS Reform Order that the 
majority of TRS’s marketing compensation appear to have been used by providers to promote 

United States Government Accountability Office 
 
564
individual-branded marketing campaigns focused on winning back TRS users from 
competitors rather than informing the general public about the nature and functions of relay 
services.55 
As mentioned, according to FCC officials, FCC ceased marketing compensation to 
providers and called for the creation of a national marketing and outreach pilot program that 
will, according to the 2013 VRS Reform Order, seek to ensure that potential TRS users and 
the general public are aware of the TRS program and its role in providing functionally 
equivalent services.56 The 2013 VRS Reform Order outlined a nationwide TRS marketing and 
outreach pilot program that is intended to, among other things, establish clear messaging 
about the purposes, functions, and benefits of IP Relay and VRS; educate consumers who are 
deaf, hard of hearing, or have speech disabilities about broadband adoption programs 
available to low-income families; provide materials to local, state, and national governmental 
agencies on the purposes, functions, and benefits of IP Relay and VRS; and explore 
opportunities to collaborate with other entities to disseminate information about IP Relay and 
VRS. The 2013 VRS Reform Order called for the selection of either (1) “outreach 
coordinators” who will conduct and coordinate IP Relay and VRS outreach nationwide and 
will be compensated through the TRS Fund or (2) an FCC contract with the TRS Fund 
administrator to enter into a similar arrangement.57 According to the 2013 VRS Reform order, 
the TRS outreach coordinators will not be affiliated with any TRS provider and they will 
disseminate non-branded information to potential new users and to the general public about 
IP Relay and VRS, the purposes and benefits of the services, and how to access and use the 
services.58 
According to most TRS providers, the elimination of compensation for research and 
development has also reduced competition and limited innovation. For example, 7 out of 10 
providers stated that the lack of compensation from FCC to TRS providers for research and 
development significantly decreases their ability to compete. Specifically, one provider noted 
that the lack of compensation for research and development reduces a provider’s ability to 
compete through quality service improvements and innovations, such as new and unique 
provider-specific features including improved software functionality, enhancing VRS picture 
quality, or increasing captioning speed and accuracy during IP CTS sessions. However, 
according to FCC, TRS research and development compensation is inefficient and 
duplicative. FCC stated in its 2013 VRS Reform Order that TRS research and development 
reimbursement would allow for duplicative spending because multiple providers would be 
able to expend research and development funds on similar or identical enhancements and 
would not share the results with potential or existing competitors.59 In addition, the 2013 VRS 
Reform Order, among other things, directed the FCC Managing Director to enter into an 
arrangement with the National Science Foundation to conduct research to ensure that TRS is 
functionally equivalent to voice telephone services and to improve the efficiency and 
availability of TRS.60 According to FCC officials, in January 2015, FCC and MITRE entered 
into a memorandum of understanding to conduct this research. FCC officials told us that the 
research project establishes a Center of Expertise that is intended to bring together experts, 
representatives of the community of persons with hearing or speech disabilities, and other 
stakeholders to prioritize and address the needs of TRS users. According to FCC officials, the 
Center of Expertise held its inaugural meeting in March 2015. 
 

Telecommunications Relay Service 
 
565
Lack of Interoperability among VRS Providers 
The majority of VRS providers stated that the lack of interoperability among VRS 
providers can inhibit competition. For example, 5 out of 6 VRS providers stated that the lack 
of interoperability can lead to significantly less competition. Multiple providers told us, while 
interoperability of VRS equipment is required by FCC, 61 some services are still not 
interoperable with other providers’ equipment and, as a result, one provider told us that they 
filed a petition with FCC. 
To address interoperability, improve competition, and quality, FCC proposed instituting 
and transitioning to a VRS Advanced Video Communication Platform (formerly known as 
Neutral Video Communication Service Platform).62 According to the 2013 VRS Reform 
Order, a neutral video communication service provider will have multiple benefits, 
specifically: more effective and efficient competition on the basis of service quality, including 
interpreter quality and the capabilities to handle the varied needs of VRS, and more efficient 
and effective VRS CA service competition through the elimination of new entrant barriers 
such as the cost of building and maintaining a video communication service platform.63 In 
addition, the 2013 VRS Reform order directed FCC’s Managing Director to select a neutral 
third party to build, operate, and maintain the Advanced Video Communication Platform.64 In 
the order, FCC stated that it would contract out the above services and responsibilities to a 
third party and that party would be compensated through the TRS Fund.65 However, FCC 
officials stated that this procurement has been cancelled because prices were too high and the 
agency determined that it would not be in the federal government’s interest to accept any of 
the proposals submitted. Contrary to FCC’s perspective about the benefits of the Advanced 
Video Communication Platform, a majority of the providers responding to our survey stated 
that the platform will not improve competition. Specifically, 6 of 10 providers stated that the 
Advanced Video Communication Platform will reduce competition. One provider told us that 
the Advanced Video Communication Platform could disincentivize new companies from 
entering the market because existing TRS requirements, such as 24-hour staffing of 
interpreters, could still be in effect under the proposed Advanced Video Communication 
Platform. Therefore, according to the provider, labor costs could prevent new entrants from 
making profits. 
Some consumer groups and providers told us that the Advanced Video Communication 
Platform could stifle innovation. For example, the Advanced Video Communication Platform 
request for proposal included a number of core features that all participating providers will 
use and offer to its customers. As a result, according to one provider, VRS providers would 
have to give up their proprietary technology and ultimately become a provider of 
interpretation services, rather than competing on unique and provider specific technological 
features in addition to interpretation. For example, another provider told us that as a result of 
a transition to an Advanced Video Communication Platform, existing innovative provider-
specific features would no longer be available and subsequently replaced by Advanced Video 
Platform features. Since Advanced Video Platform features will be the same for all 
providers—as are reimbursement rates— competition will shift from which company has the 
best features to which company has the best interpreters. FCC is in the beginning stages of 
developing the Advanced Video Communication Platform, so it is unclear at this point how it 
will affect VRS service quality and competition. 
 
 

United States Government Accountability Office 
 
566
CONCLUSION 
 
Since 2002, annual TRS Fund expenditures have grown by over $700 million. A variety 
of factors contributed to this growth, including the development of Internet-based TRS 
services, increased TRS usage, and some fraud in VRS and IP Relay. The size of the TRS 
Fund is likely to continue to rise as more persons with hearing or speech disabilities learn 
about these services and the hard-of-hearing population increases as the baby boomers age. 
FCC’s fraud reduction efforts contributed to the decreases in total TRS costs that occurred in 
2010 and 2011. FCC must continue to be vigilant about fraud, especially as new technologies 
emerge that could require the development of new internal controls. Beyond fraud reduction 
efforts, however, it is important that the TRS program be managed in a proactive manner that 
is in accordance with leading management practices. If, for example, FCC does not develop 
specific multiyear and intermediate goals that are objective, quantifiable, and measurable and 
that have performance indicators, targets, and time frames, it becomes difficult to determine 
whether FCC has met the program’s purpose of providing functionally equivalent services. 
Developing linked, TRS-specific performance goals and measures; conducting a full TRS 
program risk assessment; and consolidating rules and procedures for each TRS service will 
help ensure that FCC is managing the program in a proactive, result-oriented manner and, 
ultimately, that the TRS program is meeting its overall purpose of providing functionally 
equivalent telecommunications services to persons who are deaf, hard of hearing, or have 
speech disabilities. 
 
 
RECOMMENDATIONS FOR EXECUTIVE ACTION 
 
To improve performance management of the Telecommunications Relay Service, we 
recommend that the Chairman of the Federal Communications Commission take the 
following three actions. 
 
• 
Develop specific performance goals and measures for the TRS program. FCC should 
establish goals that would guide its efforts on major program dimensions—for 
example, consider goals and performance measures related to, but not limited to, 
service quality or competition among providers. 
• 
Following the establishment of TRS’s performance goals, conduct a robust risk 
assessment that can help FCC design a comprehensive internal-control system. 
• 
Improve FCC’s communication of TRS rules and procedures to the community of 
individuals who are deaf, hard of hearing, or have speech disabilities and the 
companies providing TRS services through the creation and dissemination of a 
handbook, program manual, or other consolidation of TRS rules and procedures. 
 
 
AGENCY AND THIRD-PARTY COMMENTS 
 
We provided a draft of this report to FCC and RLSA for their review and comment. FCC 
agreed with our recommendations and discussed actions it plans to take to implement the 

Telecommunications Relay Service 
 
567
recommendations. FCC also e-mailed technical comments, which we incorporated as 
appropriate. RLSA did not have comments on the report. 
 
Sincerely yours, 
Mark L. Goldstein 
Director, Physical Infrastructure Issues 
 
 
APPENDIX I: OBJECTIVES, SCOPE, AND METHODOLOGY 
 
The objectives of this report were to examine (1) how the services and costs of the 
Telecommunications Relay Service (TRS) program have changed since 2002; (2) the Federal 
Communication Commission’s (FCC) performance goals and measures for the TRS program 
and how they compare with key characteristics of successful performance goals and 
measures; (3) the extent to which the design of the TRS program’s internal control system 
identifies and considers program risks; and (4) the challenges, if any, that exist in ensuring 
quality services for users and a competitive environment for providers. The scope of our audit 
did not include the testing of specific internal control activities. 
To determine how the costs and services of the TRS program have changed since 2002, 
we reviewed FCC documents, including FCC orders and stakeholder comments in FCC 
rulemaking proceedings. In addition, we reviewed FCC’s OIG, GAO, Congressional 
Research Service, and consumer group reports on TRS. We also collected and analyzed TRS 
program data on costs and minutes of usage for all six major forms of TRS from 2002–2014. 
We assessed the reliability of these data through conversations with FCC and RLSA officials 
about how the data are gathered and maintained. We determined the data were sufficiently 
reliable for the purposes of showing trends in program usage and costs. We selected 2002 for 
the scope of our review as that was the year when Video Relay Service (VRS)—a popular 
form of TRS—was first made widely available. We interviewed: 
 
Agencies 
Federal Communications Commission 
Federal Communications Commission-Office of Inspector General 
 
TRS Fund Administrators  
National Exchange Carrier Association Rolka Loube Saltzer Associates 
 
Associations  
American Association of the Deaf-Blind  
Association of Late Deafened Adults  
Cerebral Palsy and Deaf Organization  
Hearing Loss Association of America  
National Association of the Deaf  
Telecommunications for the Deaf, Inc. 
Registry of Interpreters for the Deaf  
 

United States Government Accountability Office 
 
568
TRS Providers 
American Sign Language Services, Inc. 
AT&T Inc. 
Communication Axess Ability Group 
Convo Communications 
CSDVRS 
Hamilton Relay 
InnoCaption, Inc. 
Purple Communications, Inc. 
Sorenson Communications 
Sprint Corporation 
 
We analyzed these interviews to identify how and why TRS services had changed in 
costs and minutes from 2002-2014. 
To identify FCC’s performance goals and measures for the TRS program, we reviewed 
FCC documents, such as strategic plans and performance budgets; reviewed FCC web pages 
pertaining to the TRS program; and interviewed FCC officials about program goals and 
measures. To assess program goals and measures, we compared FCC’s performance goals 
and measures to key characteristics of successful performance goals and measures that GAO 
developed in prior work, as well as to requirements contained in the Government 
Performance and Results Act of 1993, as amended by the GPRA Modernization Act of 2010.1 
To understand the extent to which the design of the TRS program’s internal control 
system appropriately identifies and considers program risks, we reviewed FCC documents 
and rules, and spoke with FCC officials about TRS internal controls. Specifically, FCC, FCC 
OIG, and the current TRS Fund administrator provided us program-related documentation on 
risk assessments, control activities, and audits. We identified what controls were in place and 
then compared the design of the internal control system with the requirements contained in 
the GAO Standards for Internal Control in the Federal Government (the Green Book). 
To assess the challenges to ensuring quality services for users and a competitive 
environment for providers, we first identified challenges that were identified through our 
interviews with representatives from all 10 TRS providers, associations representing the 
community of persons who are deaf or hard of hearing, FCC, FCC OIG, and the current and 
previous TRS Fund administrators. We also reviewed TRS-related FCC orders, standards set 
in the Americans with Disabilities Act, and industry literature. In addition, to develop 
quantifiable information about the providers’ views on the challenges to ensuring quality 
services for users and a competitive environment for providers, we developed a survey 
instrument for the providers. We pretested the survey with one provider to ensure that 
questions were clear, unbiased, comprehensive, and that terminology was used correctly. We 
made changes to the content of the questions in response to the pretest. We surveyed all 10 
providers and received a 100-percent response rate. Because we administered the survey to 
the complete universe of potential respondents, there are no sampling errors. However, the 
practical difficulties of conducting any survey may introduce errors, commonly referred to as 
non-sampling errors. For example, difficulties in how a particular question is interpreted, in  
 
 
 

Telecommunications Relay Service 
 
569
the sources of information that are available to respondents, or in how the data is entered into 
a database or analyzed can introduce unwanted variability into the survey results. In addition, 
to further analyze issues related to TRS competition and market concentration, we calculated 
certain measures of market concentration in the two largest forms of TRS—IP CTS and 
VRS—and analyzed the data on TRS minutes of service from each provider from 2008–2014. 
We selected 2008 as the starting year for this analysis because, according to FCC officials, 
this was the first year with complete market concentration data on all six forms of TRS. 
We conducted this performance audit from April 2014 through April 2015 in accordance 
with generally accepted government auditing standards. Those standards require that we plan 
and perform the audit to obtain sufficient, appropriate evidence to provide a reasonable basis 
for our findings and conclusion based on our audit objectives. We believe that the evidence 
obtained provides a reasonable basis for our findings and conclusions based on our audit 
objectives. 
 
 
APPENDIX II: SURVEY OF TELECOMMUNICATIONS RELAY  
SERVICE PROVIDERS 
 
The questions we asked in our survey of TRS providers are shown below. Our survey 
was comprised of closed- and open-ended questions. In this appendix, we include all the 
survey questions and aggregate results of responses to the closed-ended questions; we do not 
provide information on responses provided to the open-ended questions. For a more detailed 
discussion of our survey methodology see appendix I. 
 
Contact Information: 
 
Please provide the name and contact information of the person 
completing this survey in case GAO needs to follow up on the information provided. 
Name: Title: 
Company: 
Email: Phone: 
 
 
Service Quality Questions: 
 
1. How, if at all, have the current TRS compensation rates affected your company’s 
ability to hire and retain qualified interpreters? 
 
Response 
 
Much more 
difficult to hire and 
retain  
Slightly more 
difficult to hire and 
retain  
No 
effect  
Slightly 
easier to hire 
and retain  
Much easier 
to hire and 
retain  
Don’t 
Know  
Total 
Responses 
8  
0  
2  
0  
0  
0  
10 
 
 

United States Government Accountability Office 
 
570
2. Industry wide, how, if at all, has a lack of skill-based routing affected TRS consumers 
receiving quality service? 
 
Response 
 
Much higher quality service  
Slightly 
higher 
quality 
service  
No 
effect  
Slightly lower 
quality service  
Much 
lower 
quality 
service  
Don’t 
Know  
Total 
Responses 
0  
0  
2  
2  
5  
1  
10 
 
3. Industry wide, how, if at all, has interpreter workload affected TRS quality? 
 
Response 
 
Much higher 
quality  
Slightly higher 
quality  
No effect  
Slightly lower 
quality  
Much 
lower 
quality  
Don’t 
Know  
Total 
Responses 
0  
0  
2  
4  
3  
1  
10 
 
4. Overall, how effective is the FCC’s current oversight and testing of TRS quality? 
 
Response 
 
Extremely 
effective  
Very 
effective  
Somewhat 
effective  
Slightly 
effective  
Not at all 
effective  
Don’t 
Know  
Total 
Responses 
0  
0  
4  
6  
0  
0  
10 
 
5. Do you have any recommendations for how the FCC could better oversee and test TRS 
service quality? If so, please briefly describe below. 
 
6. How much, if at all, will the FCC’s proposed Advanced Video Communication 
Platform (formerly known as Neutral Video Communication Service Platform) improve 
service quality? 
 
Response 
 
A lot  
A little  
Not at all  
Don’t know  
TotalResponses 
0  
1  
5  
4  
10 
 
7. Please rank the following TRS quality challenges from the most significant challenge 
to the least significant challenge. Please place a 1 in front of the most significant challenge, 2 
in front of the second, etc. 
 
 
 
 
 

Telecommunications Relay Service 
 
571
Response 
 
Question 
Rank 1 
Rank 2 
Rank 3 
Rank 4 
Rank 5 
A. TRS compensation rates affect a company’s 
ability to hire and retain qualified interpreters. 
4 
6 
0 
0 
0 
B. Lack of skill-based routing 
0 
1 
5 
3 
1 
C. Interpreter workload 
0 
1 
4 
3 
2 
D. FCC oversight and testing of service quality 0 
2 
3 
1 
4 
E. Other [Open-ended] 
6 
0 
0 
0 
0 
 
Competition Questions: 
 
8. How much, if at all, have TRS rate reductions affected competition in the TRS market? 
 
Response 
 
Significantly 
increased 
competition  
Increased 
competition  
Neither 
increased or 
decreased 
competition  
decreased 
competition  
Significantly 
decreased 
competition  
Don’t 
Know  
Total 
Res-
ponses 
0  
0  
0  
4  
6  
0  
10 
 
9. For those services that your company provides or has provided, how much, if at all, do 
current TRS rates attract new companies to enter the TRS market and provide services? 
(Please respond “Don’t provide” if your company doesn’t currently or hasn’t previously 
provided the service). 
 
 
Response 
 
 
 
 
 
TRS Service Type 
A lot 
A little 
Not at 
all 
Don’t 
know 
Don’t Provide 
Total 
VRS 
8 
0 
0 
0 
2 
10 
Text-to-Voice TTY-based TRS 
0 
1 
2 
0 
7 
10 
Speech-to-Speech (STS) Relay Service 
0 
1 
3 
0 
6 
10 
Captioned Telephone Service 
0 
1 
2 
0 
7 
10 
Internet Protocol (IP) Relay Service 
0 
1 
3 
0 
6 
10 
IP Captioned Telephone Service 
0 
2 
3 
0 
5 
10 
 
10. How, if at all, has a lack of interoperability among providers affected competition? 
 
Response 
 
Significantly less 
competition  
Moderately less 
competition  
Slightly less 
competition  
No 
effect  
There is no lack of 
interoperability 
among providers  
Don’t 
Know  
Total 
Res-ponses 
5  
2  
0  
3  
0  
0  
10 
 
 
 
 
 

United States Government Accountability Office 
 
572
11. How, if at all, has the lack of compensation from the FCC to TRS providers for 
research and development affected your company’s ability to compete? 
 
Response 
 
Significantly less 
ability to compete  
Moderately less 
ability to compete  
Slightly less 
ability to 
compete  
No effect  
Don’t 
Know  
Total Responses 
7  
1  
1  
1  
0  
10 
 
12. How, if at all, has the lack of compensation from the FCC to TRS providers for 
marketing and outreach affected your company’s ability to compete? 
 
Response 
 
Significantly less 
ability to compete  
Moderately less 
ability to compete  
Slightly less 
ability to 
compete  
No effect  
Don’t Know  
Total Responses 
7  
1  
1  
0  
1  
10 
 
13. How, if at all, will the FCC’s proposed Advanced Video Communication Platform 
(formerly known as Neutral Video Communication Service Platform) affect competition? 
 
Significantly 
increase 
competition  
Increase 
competition  
Neither increase 
nor decrease 
competition  
Decrease 
competition  
Significantly 
decrease 
competition  
Don’t 
know  
Total 
Res-
ponses 
1  
1  
0  
1  
5  
2  
10 
 
14. Please rank the following challenges to TRS competition from the most significant 
challenge to the least significant challenge. Please place a 1 in front of the most significant 
challenge, 2 in front of the second, etc. 
 
Response 
 
Question 
Rank 1 
Rank 2 
Rank 3 
Rank 4 
Rank 5 
Rank 6 
Total 
A. TRS rate reductions 
8 
1 
1 
0 
0 
0 
10 
B. Current TRS rate’s ability to attract 
new TRS providers 
1 
0 
3 
1 
3 
2 
10 
C. Lack of interoperability among 
providers 
1 
2 
0 
2 
4 
1 
10 
D. Lack of compensation for research 
and development 
0 
2 
4 
3 
1 
0 
10 
E. Lack of compensation for marketing 
and outreach 
0 
2 
2 
4 
1 
0 
10 
F. Other [Open-ended] 
1 
3 
0 
0 
0 
0 
4 
 
 
 

Telecommunications Relay Service 
 
573
APPENDIX III: GAO ANALYSIS OF PROVIDER CONCENTRATION IN 
TRS PRODUCT MARKETS, 2008–2014 RATE YEARS 
 
Table 1. Provider Concentration in TRS Product Markets  
(annually as of July 1) 
 
 
 
 
A. Number of Providers 
 
 
 
TRS Products 
2008 
2009 
2010 
2011 
2012 
2013 
2014 
TTY 
7 
7 
6 
5 
3 
4 
3 
STS 
7 
7 
6 
5 
3 
4 
NA 
CTS 
4 
4 
4 
4 
3 
4 
3 
IP Relay 
6 
6 
7 
6 
3 
3 
NA 
IP CTS 
NA 
3 
3 
5 
3 
3 
4 
VRS 
10 
9 
8 
9 
6 
6 
6 
 
 
B. Concentration Ratio of Providers by Rate Year 
TRS Products 
2011–12 
2012–13 
2013–14 
IP CTS: Top 2 Providers 
66.6% 
75.2% 
71.7% 
IP CTS: Top 3 Providers 
99.5% 
99.3% 
98.6% 
 
 
 
 
VRS: Top 2 Providers 
92.9% 
91.2% 
90.2% 
VRS: Top 3 Providers 
100% 
99.0% 
98.7% 
 
C. Herfindahl-Hirschman Index (HHI) by Rate Year 
TRS Products 
2011–12 
2012–13 
2013–14 
IP CTS 
3509 
3554 
3403 
VRS 
6973 
6791 
6603 
Source: GAO Analysis of FCC data. | GAO-15-409 
Notes: Under section A, number of providers was calculated in July of each year, which is beginning of the rate year 
The concentration ratios and the HHI are computed for providers with complete data for the rate year; the data are not 
reported for other forms of TRS due to data limitations or confidentiality. 
 
 
End Notes 
 
1 TRS is not intended for communication between two people who are deaf, hard of hearing, or speech disabled if 
both parties to the call are using the same type of relay service. There are circumstances in which calls between 
two deaf people using two different forms of TRS can be compensated. The different forms of TRS are explained 
later in this report. 
2 Pub. L. No. 101-336, § 401(a), 104 Stat. 327, 366 (1990), codified as amended at 47 U.S.C. § 225. 
3 The provision of TRS services is paid for by the TRS Fund. The TRS Fund is a revolving fund financed through 
contributions made by all providers of interstate telecommunications services. Service provider contributions are 
based on a “contribution factor” that is set on an annual basis by FCC. 47 C.F.R. § 64.604(c)(5)(iii). These 
mandatory contributions are generally passed on to consumers as part of the cost of their telephone service. 
4 47 U.S.C. § 225(b)(1). States provide and pay for intrastate TRS services. States usually recover intrastate TRS 
costs through a surcharge applied to the telephone bills of all telephone customers within a state. 
5 The TRS rate year runs from July 1 to June 30 of the following year. 
6 VRS is an Internet-based form of TRS that allows persons whose primary language is American Sign Language 
(ASL) to communicate with a CA in ASL using video conferencing equipment. 
7 At the time of the request, Senator Sessions was the Ranking Member of the Senate Committee on the Budget. 
8 GAO developed a set of key practices based on analyses of leading results-oriented organizations, management 
studies of 23 large federal departments and agencies, and a body of literature on management reform, strategic 
planning, and performance measurement. See GAO, Executive Guide: Effectively Implementing the Government 
Performance and Results Act, GAO/GGD-96-118 (Washington, D.C.: June 1996). 
9 Pub. L. No. 111-352, 124 Stat. 3866 (2011). 

United States Government Accountability Office 
 
574
10 GAO, Standards for Internal Control in the Federal Government, GAO/AIMD-00.21.3.1 (Washington, D.C.: 
November 1999). The scope of our audit did not include the testing of specific internal control activities. 
11 We selected 2008 as the starting year for this analysis because, according to FCC officials, this was the first year 
with complete market concentration data on all 6 forms of TRS. 
12 47 U.S.C. § 225. Although TRS can be considered a universal service program in that it seeks to make 
telecommunications services accessible to all citizens, specifically those with hearing or speech disabilities, the 
program is distinct from FCC’s four universal service programs under the Universal Service Fund. 47 U.S.C. § 
254. Those programs are the High Cost program, which seeks to bring affordable telecommunications services to 
those in rural areas; the Low Income program, which seeks to bring affordable telecommunications services to 
low income individuals; the E-rate program, which funds telecommunications services to eligible schools and 
libraries; and the Rural Health Care Fund, which funds telecommunications services for rural health care 
providers. The construct of the four universal service programs are similar to TRS in that they are managed by 
FCC, but the daily administration of the Universal Service Fund is handled by the Universal Service 
Administrative Company. For more information on the Universal Service Fund and universal service programs, 
including a list of related GAO reports, see GAO, Opportunities to Reduce Potential Duplication in Government 
Programs, Save Tax Dollars, and Enhance Revenue, GAO-11-318SP (Washington D.C.: Mar. 1, 2011), 194– 
197. 
13 According to the National Association of the Deaf, users generally pay for equipment, such as telephones and 
computers, and service, such as Internet and telephone, although some providers have given away telephones to 
encourage the deaf and hard of hearing to use their TRS service. 
14 FCC stated that some of these VRS numbers are assigned to devices with multiple users (e.g., a household with 
more than one deaf individual) and some users have more than one number (e.g., one number at home and 
another at work). 
15 Providers submit monthly reports of minutes to the fund administrator for compensation from the fund. The 
reports are then to be reviewed by the fund administrator to ensure that the minutes were handled in compliance 
with the Commission’s rules and orders before reimbursements are made. 47 C.F.R. § 64.604(c)(7)(E). 
16 We did not evaluate the methodologies behind how FCC established reimbursement rates for each TRS service. 
17 See In the Matter of Structure and Practices of the Video Relay Service Program, Report and Order and Further 
Notice of Proposed Rulemaking, 28 FCC Rcd. 8618 (2013) vacated in part, 765 F. 3d 37 (D.C. Cir. 2014). (VRS 
Reform Order). 
18 The investigations resulted in four actions, the assessment of penalties, and repayments to the TRS Fund. See, 
e.g., Purple Communications, Inc, Notice of Apparent Liability for Forfeiture, 29 FCC Rcd. 5491 (2014). 
19 According to FCC officials, the Nigerian scam calls that took place through IP Relay involved the fraudulent use 
of stolen credit cards to order large quantities of goods from American merchants via the anonymity of IP Relay. 
20 In the Matter of Structure and Practices of the Video Relay Service Program, 28 FCC Rcd. 8618 (2013) (Report 
and Order and Further Notice of Proposed Rulemaking). 
21 GAO, Executive Guide: Effectively Implementing the Government Performance and Results Act. GAO/GGD-96-
118. (Washington, D.C.: June 1996). 
22 47 U.S.C. § 225. 
23 Pub. L. No. 103-62, § 4, 107 Stat. 286 (1993), codified at 31 U.S.C. § 1105(a). 
24 GAO, Agency Performance Plans: Examples of Practices That Can Improve Usefulness to Decisionmakers. 
GAO/GGD-99-69 (Washington, D.C.: February 1999). 
25 VRS Reform Order. 
26 47 C.F.R. §.64.604. 
27 According to FCC officials, FCC exercises its enforcement authority to review and audit the accuracy of provider 
certifications, and takes enforcement action against providers that do not comply with FCC minimum standards. 
28 According to the Government Performance and Results Act, “outcome measures” are assessments of the results of 
a program compared to its intended purpose, and “output measures” are the tabulations, calculations, or 
recordings of activities or efforts and can be expressed in a quantitative or qualitative manner. 
29 GAO, Standards for Internal Control in the Federal Government, GAO/AIMD-00.21.3.1 (Washington, D.C.: 
November 1999). 
30 31 U.S.C § 3512. 
31 GAO, Internal Control Management and Evaluation Tool, GAO-01-1008G (Washington, D.C.: August 2001). 
32 OMB, Management’s Responsibility for Internal Control, Circular A-123 (Washington, D.C.: December 2004). 
33 The Enforcement Bureau also began analyzing provider call records during this period and identified practices 
that resulted in inflated call minutes. 

Telecommunications Relay Service 
 
575
34 FCC, FCC Chief of Staff Praises Decisive Action to Prosecute Fraud in VRS Program, Press Release 
(Washington, D.C.: Nov. 19, 2009). 
35 In the Matter of Structure and Practices of the Video Relay Service Program, Declaratory Ruling, 25 FCC Rcd. 
1868, 1869-70, 3-5 (2010). 
36 The scope of our review did not include testing for fraudulent activity. The FCC OIG continues to conduct audits 
of TRS providers aimed at uncovering fraud, waste, and abuse in the TRS program. In March 2014, it was 
announced that investigations by the FCC OIG, the Department of Justice, and the Federal Bureau of 
Investigation, had led to VRS fraud indictments against two people, bringing the total number of people and 
business entities indicted for VRS fraud to 31. 
37 In the Matter of Structure and Practices of the Video Relay Service Program, Second Report and Order, 26 FCC 
Rcd. 10898 (2011). 
38 In the Matter of Structure and Practices of the Video Relay Service Program, Report and Order and Further 
Notice of Proposed Rulemaking, 28 FCC Rcd. 8618 (2013). 
39 In the Matter of Misuse of Internet Protocol (IP) Relay Service; Telecommunications Relay Services for 
Individuals with Hearing and Speech Disabilities, First Report and Order, 27 FCC Rcd 7866, 13 n.53 (2012). 
40 According to the OIG, 28 of these audits are complete and five are in process. 
41 According to internal control standards, a precondition to risk assessment is the establishment of clear, consistent 
agency goals and objectives. As discussed, FCC has not yet established clear performance goals for the TRS 
program. 
42 47 C.F.R. Part 64, Subpart F.  
43 47 C.F.R. § 64.604. 
44 In general, “slamming” occurs when a VRS provider changes a consumer’s preferred VRS provider without the 
customer’s permission. “Porting” involves changing the preferred VRS provider at the request of the consumer. 
Porting problems may arise if the exiting service provider is not cooperative in releasing the consumer’s 
telephone number to the consumer’s new relay service provider. 
45 FCC’s analysis is available at https://apps.fcc.gov/edocs_public/attachmatch/DOC331113A1.docx. 
46 See GAO, Telecommunications: FCC Needs to Improve Oversight of Wireless Phone Service, GAO-10-34 
(Washington, D.C.: Nov. 10, 2009). 
47 VRS Reform Order, 180. 
48 According to FCC officials, the standard for interpreters to be qualified is that they must be able to interpret 
expressively and receptively, using specialized vocabulary. FCC officials said that the standard is based on case 
law derived from the ADA. 
49 VRS Reform Order, 183. 
50 TRS rate reductions refer to reductions in the reimbursement rates of VRS and IP Relay. 
51 VRS services make up about 70 percent of the payments to providers of all TRS providers from the TRS Fund, 
which makes VRS the largest TRS market in terms of compensation. 
52 VRS rates went from $17 per minute for all VRS providers in 2003 to $5.29 per minute for tier i VRS providers, 
$4.82 per minute for tier II VRS providers, and $4.25 per minute for tier III VRS providers in 2015. 
53 VRS Reform Order, 191. 
54 Our market concentration analysis measured the extent to which the activities in the TRS market are controlled by 
a few providers. We measured TRS provider concentration by calculating the number of providers, the 
concentration ratios of the top providers, and the Herfindahl-Hirschman Index (HHI), which account for the size-
distribution of providers or the relative influence of both small and large providers in the market. 
55 In the Matter of Structure and Practices of the Video Relay Service Program, Report and Order and Further 
Notice of Proposed Rulemaking, 28 FCC Rcd. 8618, 31 (2013) (VRS Reform Order). 
56 VRS Reform Order, 33.  
57 VRS Reform Order, 33.  
58 VRS Reform Order, 34. 
59 VRS Reform Order, 21.  
60 VRS Reform Order, 22. 
61 In the Matter of Telecommunications Relay Services and Speech-to-Speech Services for Individuals with Hearing 
and Speech Disabilities, Declaratory Ruling and Further Notice of Proposed Rulemaking, 21 FCC Rcd. 5442 
(2006). 
62 According to FCC’s 2013 VRS Reform Order, an Advanced Video Communication Platform allows a registered 
Internet-based VRS user to use VRS access technology to make and receive VRS and point-to-point calls 
through a VRS CA service provider. The functions provided by the Advanced Video Communication Service 
Platform include the provision of a video link, user registration and validation, authentication, authorization, 

United States Government Accountability Office 
 
576
ACD platform functions, routing (including emergency call routing), call setup, mapping, call features (such as 
call forwarding and video mail), and such other features and functions not provided by the VRS CA service 
provider. VRS Reform Order 89. 
63 VRS Reform Order 90. 
64 VRS Reform Order 93. 
65 VRS Reform Order 93. 
 
 
End Note for Appendix I 
 
66 Pub. L. No. 103-62, 107 Stat. 285 (1993), as amended by Pub. L. No. 111-352, 124 Stat. 3866 (2010). 

In: Encyclopedia of Audiology and Hearing Research 
ISBN: 978-1-53617-702-2 
Editors: Erno Larivaara and Senja Korhola 
© 2020 Nova Science Publishers, Inc. 
 
 
 
 
 
 
 
Chapter 38 
 
 
 
VIDEO RELAY SERVICE:  
PROGRAM FUNDING AND REFORM 
 
 
Patricia Moloney Figliola 
 
 
SUMMARY 
 
The Federal Communications Commission (FCC) regulates a number of disability-
related telecommunications services, including video relay service (VRS). VRS allows 
persons with hearing disabilities, using American Sign Language (ASL), to communicate 
with voice telephone users through video equipment rather than through typed text. VRS 
has quickly become a very popular service, as it offers several features not available with 
the text-based telecommunications relay service (TRS). 
The FCC has adopted various rules to improve VRS service. Now VRS providers 
must answer 80 percent of all VRS calls within 120 seconds. VRS providers must also 
offer the service 24 hours a day, seven days a week. Additionally, in June 2010, the 
FCC began a comprehensive review of the rates, structure, and practices of the VRS 
program to minimize waste, fraud, and abuse and update compensation rates that had 
become inflated above actual cost. Rules in that proceeding were issued in June 2013. 
The new rules initiated fundamental restructuring of the program to support innovation 
and competition, drive down ratepayer and provider costs, eliminate incentives for 
waste, and further protect consumers. In addition, the new rules transition VRS 
compensation rates toward actual costs over the next four years, initiating a step-by-
step transition from existing tiered TRS Fund compensation rates toward a unitary, 
market-based compensation rate. 
Congressional interest in the VRS program is twofold: eliminating fraud and abuse in 
the program and maintaining the usefulness of the program for users. Controversy has 
arisen over the latest proposals for change to the program being considered by the FCC. 
The FCC believes that rate structure changes are needed to reduce fraud and better manage 
the VRS program, but the deaf and hard-of-hearing community is concerned that funding 
cuts will result in fewer and less-qualified ASL interpreters. Additionally, the FCC has 
proposed changing the technologies used to operate and use the system, but the 
                                                        
 This is an edited, reformatted and augmented version of a Congressional Research Service publication R42830 , 
prepared for Members and Committees of Congress dated August 6, 2015. 

Patricia Moloney Figliola 
 
578
community is concerned that changes in technology will decrease the quality of the system 
as it is now and also potentially pose challenges to some users. 
 
 
INTRODUCTION: HOW VIDEO RELAY SERVICE WORKS 
 
The Federal Communications Commission (FCC) regulates a number of disability-related 
telecommunications services, including video relay service (VRS). VRS is a form of 
telecommunications relay service (TRS).1 The service allows persons with hearing 
disabilities, using American Sign Language (ASL), to communicate with voice telephone 
users through video equipment rather than through typed text. Video equipment links the 
VRS user with a “communications assistant” (CA) so that the VRS user and the CA can see 
and communicate with each other in signed conversation (see Figure 1). 
VRS has quickly become a very popular service. It offers several features not available 
with the text-based TRS: 
 
 
People with hearing disabilities can communicate using ASL rather than typing what 
they want to say. This allows them to incorporate facial expressions and body 
language into their conversations, which cannot be done using text. 
 
A VRS call is more like a telephone conversation between two hearing persons. For 
example, the parties can interrupt each other. The parties cannot interrupt each other 
during a traditional TRS call because the parties have to take turns communicating 
with the CA. 
 
Conversation flows more naturally between the parties, so the conversation may take 
place more quickly than with TRS. 
 
VRS calls may be made between ASL users and hearing persons speaking either 
English or Spanish. 
 
 
Source: Gallaudet University, “Accessible Emergency Notification and Communication: State of the 
Science 
Conference 
(Presentation),” 
http://tap. 
gallaudet.edu/Emergency/Nov05Conference/Presentations/maddix_files/ textmostly/slide2.html. 
Figure 1. How Video Relay Service Works. 

Video Relay Service 
 
579
VRS is different from other forms of TRS in two important ways: (1) the conversation 
between the VRS user and the CA is made through a video link and sign language rather than 
typed text; and (2) the service relies on the Internet, rather than the public telephone system, 
for the connection between the VRS user and the CA. Also, unlike some other forms of TRS, 
VRS is not mandatory. 
 
 
PROGRAM OVERVIEW 
 
VRS is free to the caller, and VRS providers are reimbursed for their costs from the TRS 
Fund. 
 
 
Management 
 
Since July 1, 2011, the TRS Fund has been administered by Rolka Loube Saltzer 
Associates, LLC (RLSA). Prior to that date, the fund was administered by the National 
Exchange Carriers Association. 
 
 
VRS Provider Service Standards 
 
VRS providers are subject to certain requirements and prohibitions: 
 
 
Eighty percent of all VRS calls must be answered within 120 seconds. 
 
Service must be offered 24 hours a day, seven days a week. 
 
VRS providers must provide their users with a 10-digit telephone number, so users 
will be able to make 911 calls and have their location data routed to the appropriate 
emergency agency. 
 
Preferential treatment of calls is prohibited. VRS (and TRS) providers must handle 
calls in the order in which they are received. They cannot selectively answer calls 
from certain consumers or certain locations. 
 
Equipment distributed by a certified VRS provider must be interoperable with the 
technology of other certified VRS providers. 
 
VRS (and TRS) providers may not offer financial incentives to use their service or to 
make more or longer VRS (or TRS) calls. 
 
 
Funding 
 
The VRS program is funded through the larger TRS Fund. The TRS Fund2 is a revolving 
fund that is financed through contributions by all providers of interstate telecommunications 
services.3 
Contributions are based on a “contribution factor” that is set on an annual basis by the 
FCC. Although the FCC generally sets a new rate each year, it maintained the 2011 

Patricia Moloney Figliola 
 
580
contribution factor while it conducts a comprehensive review of the program begun in 2010. 
The current carrier contribution factor is 0.010584 of a service provider’s interstate 
telecommunications revenues during the previous calendar year. 
 
 
Provider Compensation/Reimbursement 
 
VRS compensation rates for the fund year July 1, 2015, through June 30, 2016, were 
established as part of a “glide path” toward cost-based levels pending the implementation of 
structural reforms adopted in 2015. The per-minute VRS compensation rates for the period 
from July 1, 2015, through December 31, 2015, are: 
 
Tier I (a provider’s first 500,000 monthly minutes), $5.06; 
 
Tier II (a provider’s second 500,000 monthly minutes), $4.82; and 
 
Tier III (a provider’s monthly minutes in excess of 1 million), $4.06. 
 
The applicable per-minute VRS compensation rates for the period from January 1, 2016, 
through June 30, 2016, are: 
 
 
Tier I, $4.82; 
 
Tier II, $4.82; and 
 
Tier III, $3.87.5 
 
Based on these compensation rates, projected demand for the services, and projected fund 
administration expenses, the FCC adopted a funding requirement of $1,048,050,673, and a 
carrier contribution factor of 0.01635.6 
 
 
JUNE 2013 REPORT AND ORDER AND FURTHER NOTICE  
OF PROPOSED RULEMAKING 
 
The FCC initiated fundamental restructuring of the VRS program to support innovation 
and competition, drive down ratepayer and provider costs, eliminate incentives for waste 
blamed for burdening the TRS Fund in the past, and further protect consumers. Measures to 
improve the structure and efficiencies of the VRS program while promoting consumer 
protection include: 
 
 
Ensuring that VRS users can easily select their providers of choice by promoting the 
development of voluntary, consensus interoperability and portability standards; 
 
Enabling consumers to use off-the-shelf tablets and smartphones for any provider’s 
VRS services by developing and deploying a VRS application to work with these 
devices, based on the consensus standards; 
 
Creating a centralized TRS user registration database to combat fraud, waste, and 
abuse by ensuring VRS user eligibility; 

Video Relay Service 
 
581
 
Encouraging competition and innovation in VRS call handling services—such as 
ASL interpretation—by contracting with a neutral third party to build, operate, and 
maintain a platform for communications services; and 
 
Spurring research and development on VRS services by entering into a memorandum 
of understanding with the National Science Foundation. 
 
In addition, the new rules transition VRS compensation rates toward actual costs over the 
next four years, initiating a step-by-step transition from existing tiered TRS Fund 
compensation rates toward a unitary, market-based compensation rate. In this manner, VRS 
rates will better approximate the actual, reasonable costs of providing VRS and will 
considerably reduce the costs of operating the program.7 
 
 
Further Notice of Proposed Rulemaking 
 
In a Further Notice of Proposed Rulemaking, the FCC has proposed transitioning to a 
new ratemaking approach that makes use of competitively established pricing—contract 
prices set through a competitive bidding process—where feasible.8 No additional action has 
been taken in this proceeding. 
 
 
POLICY CONSIDERATIONS 
 
The FCC has implemented changes to the VRS program to reduce fraud and abuse, better 
manage the amount of money that is collected to fund the program, and take advantage of 
technological advancements. 
The primary concern of the deaf and hard-of-hearing community appears to be that cuts to 
the fund may result in fewer and less-qualified ASL interpreters, which would decrease the 
functional equivalency of the service. Additionally, it is concerned that changes in 
technology—even “better” technology—will decrease competition among service providers, 
possibly decreasing innovation. Moreover, the community believes that changes in the 
technology could pose challenges to some users and make placing and receiving calls more 
difficult. 
 
 
Congressional Considerations 
 
The deaf and hard-of-hearing community will likely continue to contact Congress 
whenever changes are proposed for the VRS program. The community relies heavily on the 
program, so it is understandable that they might view any proposed changes with concern. 
However, the FCC also has a responsibility to make sure that the fund remains solvent and to 
take advantage of advances in technology that it has determined will improve the system. 
Congress may wish to monitor the current proposed changes to the system to ensure that the 
FCC, while working to modernize TRS technology and minimize financial abuse, also gives 
full consideration to the concerns of the deaf and hard-of-hearing community. 

Patricia Moloney Figliola 
 
582
APPENDIX. HISTORY OF PROPOSED CHANGES TO THE  
VRS PROGRAM, 2010-2013 
 
In June 2010, the FCC began a comprehensive review of the rates, structure, and 
practices of the VRS program. The goal of the review has been to reform the VRS program, 
which for many years had been burdened by waste, fraud, abuse, and compensation rates that 
had become inflated above actual cost.9 Thus far, the commission has acted to improve the 
program by: 
 
 
cutting the reimbursement rate for the bulk of VRS traffic by more than $1.00 per 
minute, the first substantial VRS rate reduction in six years (June 2010); 
 
requiring providers to submit detailed call records to justify their requests for 
reimbursement (April 2011); 
 
instituting annual as well as unscheduled audits and banning providers from tying 
their employees’ wages to the number of calls processed (April 2011); 
 
prohibiting revenue-sharing arrangements between fund-eligible service providers 
and unregulated companies (April 2011); and 
 
tightening the eligibility and certification requirements for VRS providers to ensure 
that only providers operating in compliance with the FCC’s rules would be permitted 
to provide service to the public (July 2011). 
 
The FCC estimates that its actions over the past two years have saved the program 
approximately $300 million.10 
 
 
October 2012 FCC Request for Additional Comment 
 
In October 2012, the FCC asked for input on how it might change the structure of the 
VRS program and update the VRS contribution factor and reimbursement rate.11 Specifically, 
the FCC asked for input on three proposals by CSDVRS, a VRS service provider: (1) 
potential changes to VRS access technology, (2) enhancing iTRS database operations, and (3) 
two rate proposals. 
 
Proposed Changes to VRS Access Technology 
In a July 2012 letter to the FCC,12 CSDVRS proposed that the FCC facilitate the 
migration of all VRS access technologies from the current hardware-based and VRS-
proprietary system to a  
software-based and off-the-shelf application that could be used on a variety of user-
selected hardware. In its request for additional comment, the FCC posed a number of 
questions, including, for example: 
 
 
Should the commission mandate use of a single application or allow development of 
multiple, interoperable applications? 
 
Should providers be able to continue to offer their own internally developed 
applications? If so, under what conditions? 

Video Relay Service 
 
583
 
What off-the-shelf hardware and operating system platforms should be supported? 
Should VRS users or providers be responsible for procuring the offthe-shelf 
equipment used with the new application? 
 
How should VRS users be involved in the development, selection, certification, and 
ongoing enhancement of the application? 
 
How would users obtain support for issues relating to the application or its use on 
their equipment (e.g., network firewall issues, troubleshooting problems)? 
 
Proposed Enhancements to the iTRS Database 
In a separate letter to the FCC submitted in May 2012,13 CSDVRS proposed an industry 
structure in which all service providers would use an enhanced version of the TRS numbering 
directory to provide features such as user registration and validation, call routing, and usage 
accounting. This new structure would separate the video communication service component 
of VRS from the ASL relay CA service component by providing the functions of the video 
component from an enhanced database (“enhanced iTRS database”). In its request for 
additional comment, the FCC posed a number of questions, including, for example: 
 
 
What functions and services should the enhanced iTRS database provide? 
 
How would ASL relay CA service providers interface with the enhanced iTRS 
database? 
 
Proposed Rate Changes 
In April 2012, the FCC stated that the current interim (2011) rates for VRS would remain 
in place pending the completion of its VRS program review.14 The FCC has stated that it 
anticipates completing the proceeding prior to setting rates for the 2013-2014 fund year. It 
requested the fund administrator, RLSA, to submit proposed VRS rates for the remainder of 
the 2012-2013 fund year. In the October 2012 request, the FCC asked for comment on two 
proposed VRS compensation rates as well as any suggestions for alternative rate 
methodologies.15 It asked that parties in disagreement with the proposal offer specific and 
detailed alternatives. 
 
 
Opposition to the October 2012 Proposed Reform Options 
 
The proposals for technical and rate changes to the VRS program, while designed to 
improve the service overall, are not popular with VRS users, who fear that any changes would 
be to the detriment of the service. Specifically, they argue that the proposed changes would 
damage the “functional equivalency” of the VRS program. Functional equivalency is a 
primary element of Title IV of the Americans with Disabilities Act,16 which requires 
 
telephone transmission services [to] provide the ability for an individual who has a 
hearing impairment or speech impairment to engage in communication by wire or radio 
with a hearing individual in a manner that is functionally equivalent to the ability of an 
individual who does not have a hearing impairment or speech impairment to 
communicate using voice communication services by wire or radio.17 

Patricia Moloney Figliola 
 
584
A number of organizations that represent the deaf and hard-of-hearing community have 
begun campaigns aimed at stopping any changes to the program, and one website has been 
created specifically for people to contact the FCC to oppose the changes.18 In its comments 
filed on November 14, 2012, the National Association of the Deaf (NAD)19 summarized the 
concerns of the deaf and hard-of-hearing community.20 
 
Proposed Changes to VRS Access Technology 
The NAD stated in its comments that it believes mandating the use of a single application 
is not good for deaf and hard-of-hearing consumers. The organization believes that 
competition among the currently many service providers encourages innovation. Without 
such competition, the NAD believes that VRS products will not keep pace with technological 
change. The NAD believes that the FCC should address interoperability problems through 
third-party testing and product certification. The NAD is also concerned that changes in the 
technology could pose challenges to some users, making the service less useful. 
 
 
Proposed Enhancements to the iTRS Database 
 
The NAD did not express any opposition to creating a central iTRS database to keep 
track of all phone numbers so long as the information is kept private and is well managed. 
 
Proposed Rate Changes 
The NAD expressed its concern that rate changes could impede providing functionally 
equivalent services through VRS. Specifically, it wants the FCC to ensure that cutting 
reimbursement rates without instituting any minimum quality standards will not decrease 
service quality. It suggested that the FCC could compensate VRS companies for using 
nationally certified interpreters or providing a way for users to be better matched with VRS 
interpreters. 
 
 
End Notes 
 
1 TRS is not specifically addressed in this report. TRS is available to the speech impaired and deaf-blind 
(telebraille). VRS is only for the deaf and hard-of-hearing. Neither the blind nor the speech impaired would 
benefit from VRS since they would not be able to see the operator or speak to the operator, respectively. 
Information about the TRS program is available at http://www.fcc.gov/guides/telecommunications-relay-
service-trs. Information about telebraille is available at http://www. deafblind.com /telebrl.html. 
2 The TRS Fund is similar to another FCC program, the Universal Service Fund (USF). For information on the 
USF, see CRS Report RL33979, Universal Service Fund: Background and Options for Reform, by Angele A. 
Gilroy. 
3 Contributions are made by all carriers who provide interstate services, including, but not limited to, cellular 
telephone and paging, mobile radio, operator services, personal communications service, access (including 
subscriber line charges), alternative access and special access, packet-switched, WATS, 800, 900, message 
telephone service, private line, telex, telegraph, video, satellite, intraLATA, and international and resale 
services. 
4 Rolka Loube Saltzer Associates, Interstate Telecommunications Relay Service Fund Overview, http://www.r-l-s-
a.com/TRS/. 
5 VRS Reform Order, 28 FCC Rcd at 8705-06, paragraph 215. 
6 See 2015 TRS Rate Filing at 32; 2015 TRS Rate Filing Supplement at 3. 

Video Relay Service 
 
585
7 FCC, VRS Overhaul to Improve Phone Service for Americans with Disabilities, CG Docket Nos. 10-51 and 03-
123, FCC 13-82, June 7, 2013, paragraphs 1-216, http://hraunfoss. fcc.gov/edocs_public/attachmatch/FCC-13-
82A1.pdf. 
8 Ibid. 
9 FCC, Structure and Practices of the Video Relay Service Program, CG Docket No. 10-51, and 
Telecommunications Relay Services and Speech-to-Speech Services for Individuals with Hearing and Speech 
Disabilities, CG Docket No. 03-123, DA 12-687, April 30, 2012, http://hraunfoss.fcc.gov/ edocs_ 
public/attachmatch/DA-12-687A1.pdf. 
10 FCC, Structure and Practices of the Video Relay Service Program, and Telecommunications Relay Services and 
Speech-to-Speech Services for Individuals with Hearing and Speech Disabilities, CG Docket No. 03-123, FCC 
11-184, December 15, 2011, http://hraunfoss.fcc. gov/edocs_ public/ attachmatch/FCC-11-184A1.pdf. 
11 FCC, Additional Comment Sought on Structure and Practices of the Video Relay Service (VRS) Program and on 
Proposed VRS Compensation Rates, CG Docket No. 03-123 and CG Docket No. 10-5, DA 12-1644, October 
15, 2012, http://hraunfoss.fcc.gov/ edocs_public/attachmatch/DA-12-1644A1.pdf. 
12 Jeff Rosen, General Counsel, CSDVRS, LLC, letter to Marlene H. Dortch, Secretary, FCC, filed July 10, 2012; 
Rosen, letter to Dortch, filed August 27, 2012. 
13 Rosen, letter to Dortch, filed May 9, 2012. 
14 In general, per §§64.604(c)(5)(iii)(E) and (H) of the commission’s rules, the fund administrator is required to file 
the fund payment formulas and revenue requirements for VRS with the commission on May 1 of each year, to 
be effective that July 1. However, on April 30, 2012, the FCC waived that obligation, extending interim rates 
“to remain in effect until the commission completes its review of the compensation method and market 
structure for VRS.” FCC, Telecommunications Relay Services and Speech-to-Speech Services for Individuals 
with Hearing and Speech Disabilities; Structure and Practices of the Video Relay Service Program, CG Docket 
Number 10-51 and CG Docket No. 03-123, Order, 27 FCC Rcd 7150, June 26, 2012, http://hraunfoss. 
fcc.gov/edocs public/ attachmatch/DA-12- 996A1.doc. 
15 FCC, Additional Comment Sought. 
16 47 U.S.C. §225. 
17 47 U.S.C. §225(a)(1). Emphasis added. 
18 http://SaveMyVRS.com. 
19 The NAD was selected for discussion in this report because it is the largest organization representing the interests 
of the deaf and hard-of-hearing community. 
20 National Association of the Deaf, “NAD Responds to VRS Public Notice,” November 14, 2012, 
http://www.nad.org/ blogs/andrew-phillips/nad-responds-fcc-vrs-public-notice. 


In: Encyclopedia of Audiology and Hearing Research 
ISBN: 978-1-53617-702-2 
Editors: Erno Larivaara and Senja Korhola 
© 2020 Nova Science Publishers, Inc. 
 
 
 
 
 
 
 
Chapter 39 
 
 
 
SENSORINEURAL HEARING LOSS SECONDARY  
TO OTITIS MEDIA 
 
 
Henrique F. Pauna1 and Rafael C. Monsanto2 
1University of Campinas – UNICAMP, Department of Otolaryngology,  
Head & Neck Surgery, Campinas, Brazil 
2Banco de Olhos de Sorocaba Hospital, Department of Otolaryngology, Head & Neck 
Surgery, Sorocaba, Brazil 
 
 
ABSTRACT 
 
Otitis media is an inflammatory condition of the ear, frequently associated to an 
infection (viral or bacterial). The most frequent type of hearing loss caused by this 
disease is the conductive, due to effusion in the middle ear and/or erosions of the 
ossicular chain. Nonetheless, several reports demonstrate sensorineural hearing loss 
secondary to acute episodes of otitis media, or throughout the course of chronic otitis 
media. It is the most common infection of the childhood, but the incidence is also high in 
other age groups. Streptococcus pneumoniae, Haemophilus influenzae, and Moraxella 
catarrhalis are the most frequent bacteria to cause otitis media. The extracranial (e.g., 
facial nerve paresis, labyrinthitis, mastoiditis, and petrositis), and the suppurative 
intracranial 
complications 
(e.g., 
brain 
abscess, 
epidural 
abscess, 
meningitis, 
hydrocephalus, lateral sinus thrombosis, sinus cavernous thrombosis, subdural 
abscess/empyema, cerebellitis, labyrinth sclerosis) are the most feared complications of 
otitis media. Diagnosis is achieved with proper clinical history and examination; 
audiograms and tympanograms demonstrate and classify the presence and degree of 
hearing loss. Computed tomography and magnetic resonance imaging could be used 
during the evaluation of the patients, especially when a complication is suspected. The 
physiopathologic mechanism leading to the sensorineural hearing loss is the passage of 
toxins, bacteria, and inflammatory mediators through the round window membrane to the 
cochlea. Inflammatory damage of the sensory elements in the basal turn of the cochlea 
has been previously demonstrated in human studies. Antibiotic therapy is the preconized 
treatment for otitis media, but patients can develop hearing loss even when under 
adequate treatment. Thus, our objective is to review the concepts of otitis media, focusing 
on the bacteriology, diagnosis, and to highlight the inflammatory mechanisms leading to 
the sensorineural hearing loss secondary to this pathology. 

Henrique F. Pauna and Rafael C. Monsanto 
 
588
INTRODUCTION 
 
Otitis media - a generic term for all types of an inflammatory conditions of the middle ear 
- is a very common disease among infants and young children. The Eustachian tube is usually 
shorter and more horizontal in this population, leading to persistent effusion and, frequently, 
proliferation of bacteria [1]. Although less frequently, otitis media is also considered a 
common cause of infection in adults and elderly. The effusion and ossicular changes interfere 
with the sound transmission through the middle ear, causing conductive hearing loss [1]. The 
hearing loss can lead to impacting consequences, especially in children: auditory deficits 
often delay the behavioral, educational, and speech development [2, 3]. It is suggested, 
however, that sensorineural hearing loss can also occur during the course of otitis media [4]. 
Paparella et al. [5] were the first authors to report sensorineural hearing loss secondary to 
otitis media. These authors also remark that the severity of sensorineural hearing loss depends 
on the extent and duration of the infection.  
 
 
EPIDEMIOLOGY 
 
It is well known that otitis media is the leading cause of antibiotics prescriptions. 
Furthermore, in developed countries, 80% of the children will experience at least one episode 
of acute otitis media until their third birthday [6], and 40% will experience 6 or more 
recurrences by the age of seven [6]. From 1980’s to 1990’s, the number of visits to the 
physician’s office increased more than 200%, only when considering patients with acute otitis 
media [3]. Otitis media was the most common diagnosis recorded in 1985, 1989, and 1992 in 
the United States, and the use of amoxicillin and cephalosporins increased significantly 
during this period to treat this disease [7]. 
In the United States, 8.8 million children under the age of 18 years were reported to have 
ear infections in 2006 [8]. In addition, it is estimated that 65 to 300 million children suffer 
from chronic suppurative otitis media, causing 60% of them to have associated hearing loss 
[3]. Furthermore, in 1990, approximately 28.000 childhood deaths were attributed to otitis 
media [9]. 
Monasta et al. [6] estimated a global acute otitis media incidence rate (new episodes per 
hundred people per year) of 10.85%, or 709 million new cases each year. Children under 5 
years of age account for 51% of these cases. Also, the authors report the incidence rate of 
chronic otitis media as 4.76 per thousand people, in a total of 31 million cases; 22.6% of 
which in children under 5 years of age [6]. The prevalence of hearing impairment due to otitis 
media was between 2 to 97.04 per ten thousand among the different countries [6]. Conductive 
or mixed hearing loss due to chronic otitis media have a prevalence of 1.5% [10]. 
The economic impact of otitis media exceeds $5 billion dollars annually in the U.S. alone 
[3, 8]. Mean cost of the treatment of a single episode of otitis media was $115.80; 
furthermore, treating one episode of recurrent otitis media was significantly more expensive 
than treating an initial episode ($124.64 vs. $107.81, P = 0.0001) [11]. Also, antibiotic use to 
treat this disease in children is more than three times greater than in any other age group [3]. 
Finally, each episode of otitis media causes the children to miss, at best, 2 days of school. The 

Sensorineural Hearing Loss Secondary to Otitis Media 
 
589
estimated cost of the absences from work of their parents varies between $300 and $600 
million dollars [12].  
Preventive interventions, as well as better access to treatment should be the aim of health 
policies and programs. Breastfeeding, smoking avoidance, reduction of exposure to indoor 
and outdoor air pollution are pillars for preventing acute otitis media and its complications 
and sequelae [6].  
 
 
BACTERIOLOGY 
 
Both narrow- and broad-spectrum antibiotics have been heavily relied upon for medical 
management of otitis media. The rate of antibiotic prescription per visit remains about 76-
80% [8]. The over-use of antibacterial agents resulted in the emergence of multiple-antibiotic 
resistant microorganisms, including members of all three genera commonly associated with 
otitis media. 
Young children are in particular risk for otitis media, because of increased viral exposure, 
naive immunologic system, and impaired Eustachian tube function [8, 13]. Bacteria, viruses, 
or both were observed in the middle ear fluid in up to 96% of acute otitis media cases [8]. 
Ruohola et al. [14] reported that, of 79 children subjected to a tympanotomy tube placement, 
the middle ear fluid contained bacteria and viruses in 66% of the cases; 27% had bacteria 
alone; and 4% had only viruses. 
Substantial data demonstrate the three primary causative agents of otitis media to be 
Streptococcus pneumoniae, nontypeable Haemophilus influenzae, and Moraxella catarrhalis 
[3]. Vaccines against S. pneumoniae and H. influenzae are proven to reduce the mortality due 
to meningitis and pneumonia caused by these agents [6]. Nonetheless, the microbiology has 
changed over the past 20 years in cases of otitis media [8]. Chronic otitis media cases are also 
associated with the presence of aerobic bacteria (e.g., Pseudomonas aeruginosa, Escherichia 
coli, Staphylococcus aureus, Streptococcus pyogenes, Proteus mirabilis, Klebsiella species), 
or anaerobic bacteria (e.g., Bacteroides, Paptostreptococcus, Proprionibacterium) [1, 15]. It 
is important to highlight that antibiotic sensitivity of P. aeruginosa or S. aureus has changed 
little in the past few years. However, the antibiotic resistance, specially of P. aeruginosa 
stains to quinolones, has markedly increased [15].  
Among the complications of chronic otitis media, we highlight the extracranial 
suppurative complications (e.g., facial nerve paresis, labyrinthitis, mastoiditis, and petrositis); 
and the intracranial suppurative complications (e.g., brain abscess, epidural abscess, 
meningitis, hydrocephalus, lateral sinus thrombosis, sinus cavernous thrombosis, subdural 
abscess/empyema, cerebellitis, labyrinth sclerosis) [6]. Early diagnosis, including imaging 
exams of the temporal bone with high definition computed tomography [16], and prompt 
treatment are crucial to avoid morbid sequels. 
 
 
 
 
 

Henrique F. Pauna and Rafael C. Monsanto 
 
590
DIAGNOSIS 
 
The most common types of otitis media are: acute purulent otitis media, recurrent acute 
otitis media, otitis media with effusion, and chronic otitis media. Acute otitis media is usually 
preceded by upper respiratory symptoms, which main clinical symptoms include cough and 
rhinorrhea [6, 8]. Chronic otitis media is clinically defined as a chronic inflammation of the 
middle ear and mastoid cavity, with recurrent ear discharges (exudate) or otorrhoea through a 
tympanic membrane perforation, for more than 3 months [1, 6, 17].  
There is still some controversy on how to accurately perform a clinical diagnosis of otitis 
media. Patients with viral infections or other ear diseases are often misdiagnosed as having 
acute otitis media; furthermore, a proper examination of the eardrum can be hard to perform, 
especially in uncooperative children, or patients with cerumen occluding the external auditory 
canal. A study reported that 50% of the patients aged 6 to 35 months with acute otitis media 
actually met its diagnostic criteria [18]. Table 1 highlights the main criteria used to diagnose 
each of the most common types of otitis media. 
The “red eardrum”, or the ear “with fluid”, should not suggest the diagnosis of acute 
otitis media unless when associated with bulging of the tympanic membrane or otorrhea, 
accordingly to the 2013 American Academy of Pediatrics guideline [8]. The appearance of 
the ear drum evolves over the course of the disease and demands repeated examination. In 
addition to scrutinizing the color, position, and contour of the tympanic membrane, pneumatic 
otoscopy or tympanometry could be used to assess the mobility. Absent or reduced mobility, 
as well as the presence of air-fluid level behind the ear drum, suggest the presence of middle 
ear effusion [8].  
Hearing impairment is the term used to refer to a decrease in the auditory function in the 
widest possible sense, ranging from barely appreciable impairments to total deafness. 
According to the World Health Organization, the hearing impairment is classified as: 1- no 
impairment (25 dB or better in the audiogram); 2- slight (26-40 dB); 3- moderate (41-60 dB); 
4- severe (61-80 dB); and 5- profound (81 dB or higher). The mean hearing is calculated 
separately for each ear as the mean value of hearing in the frequencies of 500 Hz, 1000 Hz, 
2000 Hz and 4000 Hz [10]. 
 
Table 1. Criteria for otitis media diagnosis 
 
Term 
Definition 
Acute otitis media (AOM) 
Rapid onset of inflammation of the middle ear 
 -Symptoms include otalgia, irritability, insomnia, anorexia 
 -Signs include fever, otorrhea, full or bulging opaque TM, impaired TM 
mobility, TM erythema 
Recurrent acute otitis 
media (ROM) 
3 or more well-documented and separate AOM episodes in the past 6 
months, or ≥ 4 well-documented and separate AOM episodes in the past 12 
months with more than 1 episode in the past 6 months 
Otitis media with effusion 
(OME) 
Presence of fluid in the middle ear without signs or symptoms of AOM 
Chronic otitis media 
(COM) 
OME persisting for ≥ 3 months from the date of onset (if known) or from 
the date of diagnosis, with a TM perforation  
TM = tympanic membrane. 

Sensorineural Hearing Loss Secondary to Otitis Media 
 
591
 
 
Figure 1. (A) Example of a sensorineural hearing loss in a right ear. The cause lies in the cochlea. Pure-
tone audiometry reveals superposable air and bone conduction curves. (B) Example of a conductive 
hearing loss in a left ear. The cause lies in the external or middle ear. Pure-tone audiometry reveals a 
difference between the air conduction (X-X-X) and bone conduction (<-<-<) thresholds. Both ears 
tested with ear and bone loudspeakers. 
Both conductive and sensorineural hearing loss were reported among patients with otitis 
media (Figure 1). Conductive hearing loss usually occur as a result of middle ear effusion, 
changes in the eardrum or ossicular chain, or secondary to bacterial/viral labyrinthitis [10]. 
The air-bone gap observed in the audiograms is usually more severe in ears with immobile 
compared to mobile ossicular chains [19]. 

Henrique F. Pauna and Rafael C. Monsanto 
 
592
High frequency hearing loss has been reported in several studies among children and 
adults with otitis media. However, the association of the degree of hearing loss with the 
severity of hearing loss is still under debate [20]. A Korean study with 16.063 participants 
aged above 20 years old reported a prevalence of chronic otitis media of 3.8%. They also 
found an odds-ratio to a mild hearing impairment of 1.95 (95% CI, 1.34-2.85), and a 
moderate hearing impairment of 4.00 (95% CI, 2.21-7.22) in chronic middle ear diseased 
patients compared to controls.  
A population-based cohort that included 32.430 adults (aged 20-56 years) who underwent 
pure-tone audiometry, tinnitus questionnaire, and physical examination performed by an 
otolaryngologist, reported that adults with any degree of hearing loss during the childhood 
were more likely to develop tinnitus in adulthood [22]. A Taiwanese study also reported that 
patients with chronic otitis media are in significant higher risk of developing sudden 
sensorineural hearing loss when compared to negative controls [23]. Finally, a Norwegian 
cohort study, in a 30-year follow-up of 32.786 adults, showed and association between 
chronic and recurrent otitis media in childhood with the development of hearing loss in 
adulthood [24]. 
 
 
PHYSIOPATHOLOGY 
 
Chronic otitis media is histopathologically defined as the presence of irreversible tissue 
pathology in the middle ear [17] (Figure 2). This is a broader definition than the clinical one, 
in which the presence of perforation in the tympanic membrane is mandatory. Chronic otitis 
media is usually the final step in the continuum that also include purulent, mucoid, and serous 
otitis media [17, 25]. Many of its sequelae can result in hearing loss, including (but are not 
limited to) atelectasis, ossicular erosion or fixation, tympanosclerosis, and presence of 
abnormal tissue in the ear cleft [25, 26, 27]. These changes can cause conductive hearing loss, 
due to blockage in the sound transmission mechanisms. 
Nonetheless, sensorineural hearing loss, either transient or permanent, is a common 
feature of the clinical course of patients with chronic otitis media. The hearing loss in the high 
frequencies seems to be more frequent among these patients, suggesting a structural damage 
in the basal turn of the cochlea [17, 25, 26]. These assumptions were found to be true in both 
animal and human studies: the loss of outer and inner hair cells in the basal turn of the 
cochlea was reported by many authors [26, 28, 29]. 
These findings led authors to study the interactions between inner and middle ear. 
Paparella [30] was the first to report these interactions, and many subsequent studies proved 
that middle ear inflammatory conditions can lead to inner ear damage. There are several 
possible ways from which the disease could progress towards the inner ear: fistulas (caused 
by trauma or bone erosion due to cholesteatoma); oval window; and round window. The 
studies that followed focused in observing the permeability to both oval and round windows 
to bacteria and other inflammatory products. The permeability of the round window 
membrane was demonstrated by the induced passage of sodium-22 and horseradish 
peroxidase through the membrane and into the labyrinth [31]. Goycoolea et al. [32] observed 
gradual cochlear histopathologic changes followed by obstruction of the Eustachian tube in 
cats; nonetheless, no changes around the oval window were observed. Goycoolea et al. [33] 

Sensorineural Hearing Loss Secondary to Otitis Media 
 
593
reported the passage of traced albumin from the round window niche into the perilymph of 
the cochlea, suggesting that if such a macromolecule could pass through the membrane, 
infiltration of smaller particles such as toxins and enzymes could also occur. Following those 
preliminary studies, several other reports described either passage of substances or recovery 
of them in the perilymph of the basal cochlear turn: nitric oxide, transgenes, proteins, 
bacterial exotoxins, antibiotics, local antiseptics, and intact bacteria [34-42] (Figure 3).  
 
 
Figure 2. A representative horizontal section of a human temporal bone (2x; hematoxilin & eosin) 
demonstrating the middle ear cleft and the cochlea in a chronic otitis media case. 
A. Tympanic membrane; B. Hyperplastic middle ear mucosa; C. Facial nerve in the Fallopian canal; D. 
Round window niche; E. Basal turn of the cochlea; F. Carotid artery; G. Serous-purulent effusion in the 
middle ear cleft; H. Eustachian tube; I. External ear canal. Square: Round window niche and early basal 
turn areas.  
The death of bacteria resulting from immune response and/or antibiotic treatment releases 
inflammatory products in the middle ear cleft, such as lipopolysaccharide, peptidoglycan, and 
DNA [43]. These products exacerbate and prolong inflammation in the middle ear [43-45]. In 
the acute otitis media, the most expressed inflammatory cytokines include tumor necrosis 
factor (TNF)-α, interleukin (IL)-8, and IL-1ß [44, 45]. In chronic otitis media, prolonged 
inflammation increases the risk of tissue destruction and remodeling. MacArthur et al. [46] 
further observed greater cytokine expression in the middle ear of rats with acute otitis media 
when compared to the non-diseased contralateral side. These cytokines not only create a 
persistent inflammatory state in the inner ear, but also affect the ion-homeostasis receptors, 
such as aquaporins and ATPase ion pumps. In a situation of a chronic inflammation, down-
regulation of these mechanisms could increase extracellular fluid accumulation, leading to 

Henrique F. Pauna and Rafael C. Monsanto 
 
594
more severe damage. Trune et al. [47] also observed, in both acute and chronic otitis media, 
increased expression of genes responsible for connective tissue reorganization (matrix 
metalloproteinase - MMP), neovascularization (MMP, and fibroblast growth factor - FGF), 
and bone restructuring (bone morphogenetic protein - BMP). Those genes could be 
responsible for the tissue remodeling and pathologic changes in ears with chronic otitis 
media. 
 
 
Figure 3. A representative horizontal section of a human temporal bone (4x; hematoxilin & eosin) 
demonstrating the round window niche and the early basal turn of the cochlea; this picture represents 
the squared area from figure 2 seen under a higher magnification. This picture represents the infiltration 
of the cochlea (inner ear) by inflammatory products.  
1. Hyperplastic mucosa and granulation tissue blocking the round window niche; 2. Inflammatory cells 
in the round window niche; 3. Inflammatory cells in the basal turn of the cochlea; TNF-alpha: Tumor 
necrosis factor alpha; IL: Interleukin.  
Regarding the histopathologic changes in human temporal bones, Meyerhoff et al. [48] 
described labyrinthitis, inflammatory cells infiltrating the round window membrane, and 
cochlear hydrops. Loss of inner and outer hair cells in the basal turn of the cochlea is another 
marked characteristic feature of the disease; the loss of hair cells is observed even when 
comparing the diseased to the non-diseased contralateral side in the same patient. Joglekar et 
al. [31] found a 39% loss of outer hair cells in chronic otitis media temporal bones, versus 
9.7% in non-diseased controls; similar changes were observed in the inner hair cells (22% of 
loss in the diseased cases versus 3% in the controls). The authors also reported a decrease in 
the volume of the stria vascularis in the basal turn in the otitis group, but no differences in the 

Sensorineural Hearing Loss Secondary to Otitis Media 
 
595
spiral ligament was observed. These findings are responsible for the sensorineural hearing 
loss in high frequencies observed in chronic otitis media patients.  
 
 
CONCLUSION 
 
The sensorineural hearing loss is a potentially morbid consequence of otitis media, 
especially in children. Associated factors such as duration and severity of disease, recurrent 
infections, and permeability of the round window membrane are directly related to the degree 
of sensorineural hearing loss. Correct diagnosis, treatment, and counseling of patients with 
otitis media is mandatory to prevent possible sequels. 
 
 
REFERENCES 
 
[1] 
Alsaimary, I. E., Alabbasi, A. M., Najim, J. M. (2010). Antibiotics susceptibility of 
bacterial pathogens associated with otitis media. J Bacteriol Res, 2(4):41-50. 
[2] 
Casselbrant, M. L., Furman, J. M., Rubenstein, E., Mandel, E. M. (1995). Effect of 
otitis media on the vestibular system in children. Ann Otol Rhinol Laryngol, 104:620-
624. 
[3] 
Bakaletz, L. O. (2012). Bacterial biofilms in the upper airway – evidence for role in 
pathology and implications for treatment of otitis media. Paediatr Respir Rev, 
13(3):154-159. 
[4] 
Cureoglu, S., Schachern, P. A., Paparella, M. M., Lindgren, B. R. (2004). Cochlear 
changes in chronic otitis media. Laryngoscope, 114:622-626. 
[5] 
Paparella, M. M., Brady, D. R., Hoel, R. (1970). Sensori-neural hearing loss in chronic 
otitis media and mastoiditis. Trans Am Acad Ophthalmol Otol, 74:108-115. 
[6] 
Monasta, L., Ronfani, L., Marchetti, F., Montico, M., Brumatti, L. V., Bavcar, A., et al. 
(2012). Burden of disease caused by otitis media: systematic review and global 
estimates. PLoS ONE, 7(4):e36226. 
[7] 
McCaig, L. F., Hughes, J. M. (1995). Trends in antimicrobial drug prescribing among 
office-based physicians in the United States. JAMA, 273:214-219. 
[8] 
Rettig, E., Tunkel, D. E. (2014). Contemporary concepts in management of acute otitis 
media in children. Otolaryngol Clin North Am, 47(5):651-672. 
[9] 
World Health Organization. (2004). Chronic suppurative otitis media: burden of illness 
and management options. 
[10] Zahnert, T. (2011). The differential diagnosis of hearing loss. Dtsch Arztebl Int, 
108(25):433-444. 
[11] Kaplan, B., Wandstrat, T. L., Cunningham, J. R. (1997). Overall cost in the treatment 
of otitis media. Ped Infec Dis J, 16(2):S9-S11.  
[12] Stool, S. E., Field, M. J. (1989). The impact of otitis media. Pediatr Infect Dis J, 8:11-
14. 
[13] Bluestone, C. D. (1983). Eustachian tube function: physiology, pathophysiology, and 
role of allergy in pathogenesis of otitis media. J Allergy Clin Immunol, 72(3):242-251. 

Henrique F. Pauna and Rafael C. Monsanto 
 
596
[14] Ruohola, A., Meurman, O., Nikkari, S., Skottman, T., Salmi, A., Waris, M., et al. 
(2006). Microbiology of acute otitis media in children with tympanostomy tubes: 
prevalences of bacteria and viruses. Clin Infect Dis, 43(11):1417-1422. 
[15] Kim, S. H., Kim, M. G., Kim, S. S., Cha, S. H., Yeo, S. G. (2015). Change in detection 
rate of methicillin-resistant Staphylococcus aureus and Pseudomonas aeruginosa and 
their antibiotic sensitivities in patients with chronic suppurative otitis media. J Int Adv 
Otol, 11(2):151-156. 
[16] Orji, F. T., Ukaegbe, O., Alex-Okoro, J., Ofoegbu, V. C., Okorafor, I. J. (2015). The 
changing epidemiological and complications profile of chronic suppurative otitis media 
in a developing country after two decades. Eur Arch Otorhinoralyngol. [Epub ahead of 
print]. 
[17] Meyerhoff, W. L., Giebink, G. S. (1982). Panel Discussion: Pathogenesis of otitis 
media. Pathology and microbiology of otitis media. Laryngoscope, 92;273-277. 
[18] Laine, M. K., Tahtinen, P. A., Ruuskanen, O., Huovinen, P., Ruohola, A. (2010). 
Symptoms or symptom-based scores cannot predict acute otitis media at otitis-prone 
age. Pediatrics, 125(5):e1154-1161. 
[19] Dinç, A. E., Damar, M., Erdem, D., Eliçora, S. Ś., Akyildiz, I., Kumbul, Y. Ç. (2015). 
Audiometric correlations with pathologies of ossicular chain in 159 ears with chronic 
otitis media. Clin Otolaryngol. [Epub ahead of print].  
[20] Hunter, L. L., Margolis, R. H., Rykken, J. R., Le, C. T., Daly, K. A., Giebink, G. S. 
(1996). High frequency hearing loss associated with otitis media. Ear & Hearing, 
17(1):1-11. 
[21] Park, M., Lee, J. S., Lee, J. H., Oh, S. H., Park, M. K. (2015). Prevalence and risk 
factors of chronic otitis media: The Korean National Health and Nutrition Examination 
Survey 2010-2012. PLos ONE, 10(5):e0125905. 
[22] Aarhus, L., Engdahl, B., Tambs, K., Kvestad, E., Hoffman, H. J. (2015). Association 
between childhood hearing disorders and tinnitus in adulthood. JAMA Otolaryngol 
Head Neck Surg, 141(11):983-989. 
[23] Yen, Y. C., Lin, C., Weng, S. F., Lin, Y. S. (2015). Higher risk of developing sudden 
sensorineural hearing loss in patients with chronic otitis media. JAMA Otolaryngol 
Head Neck Surg, 141(5):429-435. 
[24] Aarhus, L., Tambs, K., Kvestad, E., Engdahl, B. (2015). Childhood otitis media: a 
cohort study with 30-year follow-up of hearing (The HUNT Study). Ear & Hearing, 
36:302-308. 
[25] Paparella, M. M. (1982). Panel Discussion: Pathogenesis of otitis media. Current 
treatment of otitis media based on pathogenesis studies. Laryngoscope, 92:292-296. 
[26] Joglekar, S., Morita, N., Cureoglu, S., Schachern, P. A., Deroee, A. F., Tsuprun, V., et 
al. (2010). Cochlear pathology in human temporal bones with otitis media. Acta 
Otolaryngol, 130:472-476. 
[27] Meyerhoff, W. L., Kim, C. S., Paparella, M. M. (1978). Pathology of chronic otitis 
media. Ann Otol, 87:749-760. 
[28] Schachern, P. A., Paparella, M. M., Hybertson, R., Sano, S., Duvall, A. J. 3rd. (1992). 
Bacterial tympanogenic labyrinthitis, meningitis and sensorineural damage. Arch 
Otolaryngol Head Neck Surg, 118:53-57. 

Sensorineural Hearing Loss Secondary to Otitis Media 
 
597
[29] Cook, R. D., Postma, D. S., Brinson, G. M., Prazma, J., Pillsbury, H. C. (1999). 
Cytotoxic changes in hair cells secondary to pneumococcal middle-ear infection. J 
Otolaryngol, 28:325-331. 
[30] Paparella, M. M. (1991). Interactive inner-ear/middle-ear disease, including 
perilymphatic fistula. Acta Otolaryngol Suppl, 485:36-45. 
[31] Brady, D. R., Pearce, J. P., Juhn, S. K. (1976). Permeability of the round window 
membrane to 22Na or RISA. Arch Otorhinolaryngol, 214(2):183-184. 
[32] Goycoolea, M. V., Muchow, D., Schachern, P. A. (1988). Experimental studies on 
round window structure: function and permeability. Laryngoscope, 98(6 Pt 2 Suppl 
44):1-20. 
[33] Goycoolea, M. V., Paparella, M. M., Goldberg, B., Carpenter, A. (1980). Permeability 
of the round window membrane in otitis media. Arch Otolaryngol, 106:430-433. 
[34] Hanson, J. B., Russel, P. T., Chung, A. T., Kaura, C. S., Kaura, S. H., John, E. O., et al. 
(2003). Effect of round window membrane application of nitric oxide on hearing and 
nitric oxide concentration in perilymph. Int J Pediatr Otorhinolaryngol, 67:585-590. 
[35] Jero, J., Mhatre, A. N., Tseng, C. J., Stern, R. E., Coling, D. E., Goldstein, J. A., et al. 
(2001). Cochlear gene delivery through an intact round window membrane in mouse. 
Hum Gene Ther, 12:539-548. 
[36] Goldberg, B., Goycoolea, M. V., Schleivert, P. M., Shea, D., Schachern, P. A., 
Paparella, M. M., et al. (1981). Passage of albumin from the middle ear to the inner ear 
in otitis media in the chinchilla. Am J Otolaryngol, 2:210-214. 
[37] Goycoolea, M. V., Paparella, M. M., Goldberg, B., Schlievert, P. M., Carpenter, A. M. 
(1980). Permeability of the middle ear to Staphylococcal pyrogenic exotoxin in otitis 
media. Int J Pediatr Otorhinolaryngol, 1:301-308. 
[38] Laurell, G., Teixeira, M., Sterkers, O., Bagger-Sjoback, D., Eksborg, S., Lidman, O., et 
al. (2002). Local administration of antioxidant to the inner ear. Kinetics and 
distribution (1). Hear Res, 173:198-209. 
[39] Witte, M. C., Kasperbauer, J. L. (2000). Round window membrane permeability to 
transforming growth factor-alpha: an in vitro study. Otolaryngol Head Neck Surg, 
123:91-96. 
[40] Harada, T., Iwamori, M., Nagai, Y., Nomura, Y. (1986). Ototoxicity of neomycin and 
its penetration through the round window membrane into the perilymph. Ann Otol 
Rhinol Laryngol, 95:404-408. 
[41] Becvarovski, Z., Bojrab, D. I., Michaelides, E. M., Kartush, J. M., Zappia, J. J., 
LaRouere, M. J. (2002). Round window gentamicin absorption: an in vivo human 
model. Laryngoscope, 112:1610-1613. 
[42] Morizono, T., Johnstone, B. M., Hadjar, E. (1973). The ototoxicity of antiseptics. J 
Otolaryngol Soc Aust, 3:550-553. 
[43] Melhus, Å. (2001). Effects of amoxiclilin on the expression of cytokines during 
experimental acute otitis media caused by non-typeable Haemophilus Influenzae. J 
Antimicrob Chemo, 48:397-402. 
[44] Hunter, S. E., Singla, A. K., Prazma, J., Jewett, B. S., Randell, S. H., Pillsbury, H. C. 
(1999). Mucin production in the middle ear in response to lipopolysaccharides. 
Otolaryngol Head Neck Surg, 120:884-888. 

Henrique F. Pauna and Rafael C. Monsanto 
 
598
[45] Jewett, B. S., Prazma, J. P., Hunter, S. E., Rose, A. S., Clark, J. M., Sartor, B. R., et al. 
(1999). Systemic reactivation of otitis media with effusion in a rat model. Otolaryngol 
Head Neck Surg, 121:7-12. 
[46] MacArthur, C. J., Hausman, F., Kempton, J. B., Sautter, N., Trune, D. R. (2013). Inner 
ear tissue remodeling and ion homeostasis gene alteration in murine chronic otitis 
media. Otol Neurotol, 34:338-346. 
[47] Trune, D. R., Kempton, B., Hausman, F. A., Larrain, B. E., MacArthur, C. J. (2015). 
Correlative mRNA and protein expression of middle and inner ear inflammatory 
cytokines during mouse acute otitis media. Hear Res, 326:49-58. 
[48] Meyerhoff, W. L., Kim, C. S., Paparella, M. M., Hybertson, R., Sano, S., Duvall, A. J. 
(1978). Bacterial tympanogenic labyrinthitis, meningitis, and sensorineural hearing 
loss. Arch Otol Rhinol Laryngol, 87(6, part 1):749-760. 
 
 
Reviewed by: Fabio Tadeu Moura Lorenzetti, MD, PhD (Otolaryngology Department, School 
of Medicine of University of São Paulo, São Paulo, Brazil). 
 
 
 

In: Encyclopedia of Audiology and Hearing Research 
ISBN: 978-1-53617-702-2 
Editors: Erno Larivaara and Senja Korhola 
© 2020 Nova Science Publishers, Inc. 
 
 
 
 
 
 
 
Chapter 40 
 
 
 
SUDDEN SENSORINEURAL HEARING LOSS: 
PATHOPHYSIOLOGY, DIAGNOSIS, TREATMENT 
OPTIONS, AND PROGNOSTIC FACTORS 
 
 
Rafael da Costa Monsanto, Ana Luiza Kasemodel, Luiza Mazzola, 
Marielle Albrechete and Fabio Tadeu Moura Lorenzetti 
Department of Otolaryngology, Head and Neck Surgery – Banco de Olhos de Sorocaba 
Hospital, Sorocaba, Sao Paulo, Brazil 
 
 
ABSTRACT 
 
Introduction: Sudden sensorineural hearing loss (or sudden deafness) is characterized 
as a new onset of unilateral or bilateral hearing loss, in which the symptoms develop 
within 24-72 h. Estimates of the annual incidence of sudden sensory hearing loss range 
from 5-30 cases per 100,000 people. Audiometry of these patients show a loss of 20-30 
dB in at least three connected frequencies. 
Review of the literature: Many theories have been proposed to explain the cause of 
this disease: inflammatory reaction (viral infection of the labyrinth or cochlear nerve), 
vascular disturbances, autoimmunity, rupture of the membranes, or decreased oxygen 
flow to the inner ear. Diagnosing the cause of sudden deafness involves a detailed clinical 
history, audiological, biochemical, vestibular, and imaging tests. The hearing impairment 
should always be considered as secondary to a specific cause; nonetheless, most cases are 
classified as idiopathic. The identifiable causes of the sudden deafness include: Infectious 
diseases, trauma, autoimmune diseases, ototoxic drugs, changes in blood flow, tumors in 
the vestibulocochlear nerve, neurologic diseases, and inner ear disorders (such as 
Meniere’s Disease). Magnetic resonance imaging is considered the gold standard imaging 
exam to detect lesions in the inner ear structures, internal auditory canal, and 
cerebellopontine angle. Since the majority of the cases are diopathic, the treatment of 
these cases is essentially empirical. The decision whether to treat or not to treat idiopathic 
cases is also controversial, since some studies state that 20-65% of the patients recover 
the hearing spontaneously without any treatment. Furthermore, no drug has been proven 
to significantly improve the prognosis of the hearing loss in the idiopathic cases. Based 
on the proposed pathophysiology, some treatments are described in the literature, 
including: corticosteroids, vasodilators, carbogen, intratympanic dexamethasone, 

Rafael da Costa Monsanto, Ana Luiza Kasemodel, Luiza Mazzola et al. 
 
600
hyperbaric oxygen, vitamins, gingko biloba extract, and stellate ganglion blockers. If the 
hearing loss is permanent, hearing aids could be beneficial. The presence of associated 
vertigo, the severity of hearing loss, the pattern shown in the audiogram, time between 
onset and treatment, and hearing loss in the contra-lateral ear, when present, indicate 
worse prognosis. Including tinnitus in the list of prognostic factors is considered 
controversial, since it is present in about 80% of the cases of sudden deafness. 
Conclusion: The symptoms of sudden deafness should be promptly recognized, and 
the search for a possible cause is imperative. Correct diagnosis and treatment could 
prevent the hearing changes from being permanent. 
 
 
INTRODUCTION 
 
The first definition of sudden sensorineural hearing loss (SSNHL) was proposed by 
Kleyn [1]: a rapid-onset hearing loss, which characteristic audiometric finding is 
sensorineural hearing loss of 30 dB or more over at least three contiguous audiometric 
frequencies. The symptoms are usually acute, developing over a period of a few hours to 
days. 
The estimated yearly incidence of SSNHL is 5 to 20 cases per 100,000 people. The 
disease often leads to permanent hearing disability, accounting for about 1% of all 
sensorineural hearing losses [2, 3]. 
The etiology and pathology of SSNHL is still under debate. The main point of discussion 
is the difficulty to find the exact cause of the symptoms: a background cause can be found in 
only 10% to 15% of the cases, as suggested by histopathologic studies of human temporal 
bones [4-9]. 
Several theories have been proposed for explaining the etiology of this disease, including 
viral infections, circulatory disorders, rupture of the inner ear membranes, immune disorders, 
metabolic, and toxic causes [4-9]. However, although defeatist, idiopathic SSNHL is still a 
very frequent diagnosis [7]. 
 
 
PATHOGENESIS 
 
There are several theories trying to explain the pathologic mechanisms leading to 
SSNHL, none of which universally accepted. Among the main theories, we describe in detail 
the viral, vascular, autoimmune, membrane rupture, and toxicity theories. 
 
 
Viral Theory 
 
Several studies indicate viral infection as one of the most common etiologic factors; the 
high incidence of upper respiratory tract infection (30-40%) prior to the symptoms add further 
support to this theory. There is even evidence correlating concomitant seasonal aspects of the 
incidence of respiratory infections and SSNHL [10-12]. 

Sudden Sensorineural Hearing Loss 
 
601
Many viruses have been postulated as possible causes of sudden sensorineural hearing 
loss, including mumps (7% of adult cases) [13], varicella-zoster, rubella, cytomegalovirus, 
Epstein-Barr, adenovirus, and influenza [12]. 
There are two mechanisms proposed to explain how a viral infection can cause SSNHL: 
(1) contamination of the fluid spaces and soft tissues of the cochlea, which cause 
inflammation, or invasion of the cochlear nerve (neuritis) [14], reaching the inner ear either 
via bloodstream or directly from the middle ear, passing through the round window 
membrane [15, 16]; and (2) reactivation of latent viruses within tissues of the inner ear, since 
it has been observed that neurotropic viruses can remain dormant in the cochlear neurons [14, 
17]. 
Histopathological findings also add support to the viral theory, since the reported changes 
are quite similar to what found in cases of sensorineural hearing loss secondary to viral 
infections and idiopathic labyrinthitis [14, 17-19]. The temporal bones had several 
cochleosaccular abnormalities, including collapse of the organ of Corti (Figure 1), loss of 
cochlear hair cells, atrophy of the tectorial membrane, atrophy of the stria vascularis (Figure 
2), decrease in the number of spiral ganglion cells, collapse of the saccular membrane and 
partial absence of the sensory epithelial layer in the saccular macula [14, 17-19]. 
 
 
Figure 1. Two representative horizontal section of a human temporal bone, showing the organ of Corti 
in the scala media of the cochlea (hematoxylin and eosin; 40x). A = a well preserved specimen, with an 
intact organ of Corti; B = complete collapse of the organ of Corti. 1 = tectorial membrane; 2 = inner 
hair cell; 3 = three columns of outer hair cells. 
 
Figure 2. Two representative horizontal sections of a human temporal bone, showing the stria vascularis 
in the scala media (hematoxylin and eosin; 20x). A normal stria vascularis; B = atrophy of the stria 
vascularis. 

Rafael da Costa Monsanto, Ana Luiza Kasemodel, Luiza Mazzola et al. 
 
602
Vascular Theory 
 
Some studies investigated several possible vascular mechanisms leading to SSNHL, and 
these include thromboembolic events, vasoconstriction, hypotension, blood hyper viscosity, 
and atherosclerosis. Factors as excessive weight, hypercholesterolemia, hypertriglyceridemia, 
hyperuricemia, diabetes mellitus, and smoking habits have consistently been more frequently 
found in patients with SSNHL than in non-diseased control patients [20]. 
Igarashi et al. [20] reported cochlear fibrosis and ossification in the inner ear, suggesting 
necrosis of the membranous labyrinth after vascular occlusion. They also suggest that the 
inner ear may be more vulnerable to ischemia within the vertebrobasilar system than the 
vestibular and cochlear nerves. Evidence found in magnetic resonance imaging (MRI) 
demonstrate that peripheral vestibular disorders in elderly patients were frequently associated 
with decrease in the rate of the blood flow to the vertebrobasilar system [21-23]. 
More recently, some authors have investigated the relationship between SSNHL and 
stroke [24, 25], and they suggested that SSNHL could be an early signs of stroke (such as the 
“sentinel headaches” in the occasion of subarachnoid hemorrhages) [24]. Lee et al. [24] 
reported, in a cohort study, that 4 out of 12 patients with SSNHL had stroke (all of them in 
the irrigation territory of the anterior-inferior cerebellar artery (AICA)) within the first 2 
months after the onset of the hearing loss. Furthermore, Lin et al. [25], in a cohort including 
more than 1400 patients with SSNHL, concluded that these patients had, after adjusting for 
other factors, 1.64-times (95% confidence interval, 1.31-2,07; P < 0.001) more chances of 
having a stroke within the 5-year follow-up period when compared to controls. These results 
add further support to the vascular theory for the SSNHL. 
 
 
Autoimmunity Theory 
 
Sudden hearing loss can be the first clinical manifestation of several known and 
suspected autoimmune diseases. The theory of autoimmunity as the cause of the hearing loss 
is supported by several findings, including decreased number of circulating lymphocytes 
CD3+, CD4+, and CD8+ [26], greater presence of antibodies against smooth muscles, and a 
lack of anti-thyroid and antinuclear antibodies [27-29]. Furthermore, it has been described 
several changes in human temporal bones of donors who had autoimmune diseases when 
alive, such as degeneration of the organ of Corti (Figure 1), stria vascularis (Figure 2), and 
spiral ganglion [14]. 
Experiments also demonstrated the existence of a local immune response within the inner 
ear from immunocompetent cell recruitment in the endolymphatic sac from the blood stream 
[30]. The presence of increased anticardiolipin antibodies was also reported, but the 
pathologic mechanism of this finding is still under debate: either the autoimmunity could 
cause direct lesion to the cochlear elements, or the anticardiolipin antibodies can cause micro 
thrombosis in the inner ear small vessels, further supporting the vascular theory [30]. 
The hearing loss diagnosis of autoimmune origin comes from established criteria. Major 
criteria include: (1) bilateral involvement; (2) systemic autoimmune disease; (3) high levels of 
ANAs, (4) reduced number of naive T cells (CD4+ RA); and (5) high rate of hearing recovery 
(above 80%). Minor criteria are defined as (1) unilateral involvement; (2) young or middle-

Sudden Sensorineural Hearing Loss 
 
603
aged patients; (3) serum reactivity against HSP-70; and (4) positive response to steroid 
treatment but with small to no recovery of the hearing levels. 
 
 
Membrane Rupture Theory 
 
In 1971, a report of perilymphatic fistulae was reported as a cause of SSNHL. Surgical 
findings have been described since then, demonstrating fistulae on round, oval, or both 
labyrinthine windows [31]. Nonetheless, until today, the theory of perilymphatic fistulae as 
cause of vestibular or cochlear symptoms is still controversial [32]. 
Simmons [33] reported a few cases of hearing loss secondary to mechanical disruption of 
inner ear membranes. The author suggested a double membrane break theory for idiopathic 
SSNH (both in oval and round windows), leading to pressure changes between the 
endolymph and perilymph compartments. Furthermore, Stroud and Calcaterra [34] suggested 
that these fistulae could occur even without any history of trauma or past surgeries. Thus, the 
authors hypothesized that spontaneous labyrinthine window ruptures could be one of the 
factors included in the etiology of SSNHL. 
The relationships with cerebrospinal fluid pressure changes and perilymphatic spaces 
were explored and showed pathways between cochlear aqueduct and scala tympanic, and 
between internal auditory meatus and scala vestibule. The labyrinth, with its delicately 
balanced perilymph-endolymph system, is surrounding by delicate membranes that present 
intimate relations to hydrodynamic forces in the carotid arterial system, the intracranial 
venous-sinus systems and forces in the subarachnoid space. When a membrane break occurs 
near the vestibule, both audition and balance are disturbed because system’s membrane is 
nearly connected with the cochlea. 
 
 
Toxicity Theory 
 
Some medications are also implicated in the occurrence of SSNHL, including amikacin, 
vancomycin, erythromycin, cisplatin and others [35]. The mechanism is similar to the 
ototoxic causes of long-term sensorineural hearing losses [36], and the degree, severity, and 
time between the use of the drug and the symptoms depend on several factors, including the 
thickness of the round window membrane (for topical medications) [37], and the presence of 
melanin pigment particles in the inner ear elements (for both topical and systemic drugs) [38]. 
 
 
DIAGNOSIS 
 
The diagnosis of SSNHL must be faced as the starting point of the investigation rather 
than an end. When a specific cause is found, timely and correct treatment can decrease (or 
even prevent) the incidence of permanent hearing impairment. 
SSNHL should be suspected when the patient complains of a sudden decrease in the 
hearing in one of the ears. Detailed clinical history should include how long before the 
consult the symptoms began; progression (sudden or delayed); severity of hearing loss; 

Rafael da Costa Monsanto, Ana Luiza Kasemodel, Luiza Mazzola et al. 
 
604
laterality of SSNHL; and associated symptoms, such as vertigo, tinnitus, aural fullness, 
otalgia or neurological deficits [39, 40]. Physical examination is essential to exclude other 
causes of sudden hearing loss, such as impacted cerumen, otitis media, or tumors affecting the 
middle-ear [41]. A careful otoscopy, associated with Weber and Rinne tests (using a 512-Hz 
tuning fork) [42] are enough to exclude other causes of hearing loss, plus further suggesting 
the sensorineural cause of the impairment. 
Furthermore, investigation should always include urgent auditory assessment, 
preferentially with vocal and pure tone audiometry (including both bone and air conduction 
thresholds) – the presence of sensorineural hearing loss of 30 dB or more over at least three 
contiguous audiometric frequencies is diagnostic [42]. Speech discrimination score, 
tympanometry test, and study of the presence of stapedial reflex are also helpful and provide 
further information to the attending physician. Schreiber et al. [41] (2010) advocate that, if 
sensorineural hearing loss is confirmed by audiometry, an oto-neurological examination 
should be performed to evaluate central or peripheral vestibular disorders as demyelination, 
inner-ear dysfunction, pontine angle-lesions or posterior circulation abnormalities. 
The degree of hearing impairment can be classified accordingly to the level of the loss 
observed in the audiometry, graded in decibels (dB): (1) Mild: loss of 26-40dB; (2) moderate: 
41-70dB; (3) severe: 71-90dB; and (4) profound: loss of more than 90 dB [41, 43, 44]. Other 
authors also suggest a different classification: mild (15 or 20-40 dB), moderate (40-60 dB), 
severe (60-80 dB), profound (80-100 dB), and total hearing loss (>100 dB) [45, 46]. Even 
though the literature demonstrate that the degree of hearing impairment due to SSNHL is 
variable, it is usually classified as moderate to profound [45, 47, 48]. 
Regarding diagnostic testing, the brainstem evoked response audiometry (BERA) is 
considered to be a useful test to suggest the presence of retro-cochlear lesions that could be 
the cause of the SSNHL [49]. Although this test is very sensitive in suggesting these lesions, 
it lacks specificity. Furthermore, the MRI constitutes a very reliable imaging exam: it 
demonstrates the presence or absence of inflammatory labyrinthitis, vascular disorders, or 
lesions involving specific areas of the cerebellopontine angle, brain, or brainstem [21, 49, 50]. 
Even though it is suggested that the MRI should be performed in the moment of the 
SSNHL diagnosis [50], other authors recommend the MRI to be performed only when BERA 
suggest retro-cochlear lesions [22]. The most frequent finding in the MRI is enhancement of 
the labyrinth; the enhancement usually occurs due to neoplastic or inflammatory lesions, such 
as autoimmune or viral disorders [49, 50]. Decreased vertebrobasilar flow and lacunar 
infarcts, showing as areas of high-intensity signal, are also frequently found in the MRIs of 
these patients [22, 43]. Mark et al. [49], in MRI studies of 12 cases of SSNHL, observed that 
all the patients had signs of enhancement of the labyrinth in the affected side. Ramos et al. 
[50] reported, in a study involving 49 patients with SSNHL, a 46.9% of MRI changes, 
including labyrinth enhancement, tumors at the cerebellopontine angle, and vascular 
disorders. 
Patients with several cardiovascular risk factors, especially the elderly, should be 
subjected to a magnetic resonance angiogram (MRA); this exam is considered the gold 
standard to evaluate the presence and degree of obstruction of arteries that could lead to 
SSNHL [21, 22, 43, 44, 51, 24, 52]. The AICA is the main vessel supplying the labyrinth; 
thus, infarction of the territory irrigated by this artery is commonly associated with vestibular 
symptoms, including vertigo, tinnitus and hearing loss [43, 24]. Other possible causes for the 
SSNHL that should be investigated include infectious (syphilis, HIV, cytomegalovirus 

Sudden Sensorineural Hearing Loss 
 
605
[CMV], meningitis), autoimmune, trauma, and neurological diseases [11], as well as the use 
of ototoxic medication [41, 51]. Laboratory investigation should include hemogram, blood 
glucose, five-hour blood glucose test, cholesterol and lipid profile, clotting factors, VDRL, 
FTA, C-reactive protein, erythrocyte sedimentation rate, antinuclear and anticardiolipin 
antibodies, lupus antiocoagulant, and antineutrophil cytoplasmatic antibodies. Assessment 
can also include viral serology for herpes simplex types I and II, varicella zoster, Epstein-Barr 
virus (EBV), CMV, HIV and mumps virus [41, 53, 54]. 
 
 
TREATMENT 
 
All of the treatment options for SSNHL are still controversial, since 65% patients achieve 
spontaneous recovery to normal levels of hearing [48]. Furthermore, one of the most debated 
questions when dealing with a patient with a suspected SSNHL is, if treatment with drugs is 
indicated, when to ideally introduce the medications. 
Ideally, the treatment should be focused towards the specific cause of the SSNHL. As the 
screening process leading to the exact cause of SSNHL remains a challenge, treatment in the 
acute phase is mostly empirical. Thus, in literature some authors propose therapies in the 
acute phase that could treat all possible etiologies – that strategy is usually referred to as 
“shotgun therapy” [51]. 
 
 
Anti-Inflammatory Treatment 
 
Oral corticosteroids are widely used to treat SSNHL, but further evidence of the 
beneficial effect in these patients is still needed [41, 55-58]. Furthermore, a meta-analysis 
failed to demonstrate differences in the outcomes of the SSNHL when comparing steroid to 
other treatment options (including anti-virals, carbogens, or other vasoactive agents) [57]. 
Nonetheless, systemic steroids seem to prevent inner ear damage during several 
inflammatory, infectious and immune-mediated conditions [6, 48, 57, 59]; furthermore, 
MacArthur et al. [59] demonstrated that steroid can prevent inner ear damage during 
infectious middle ear diseases in an animal model. The optimal dose of oral or intravenous 
corticosteroids has not yet been determined [48]. Chen et al. [48], in a ten-year retrospective 
analysis, observed that treatment with oral corticosteroids had a significant impact in the 
recovery rate of patients with severe hearing loss, but not on those with mild to severe hearing 
loss. The absence of effect in the mild to severe group might be due to the higher rate of 
spontaneous recovery in these patients; recovery rate in the untreated group was 53%. Oral 
corticosteroid treatment is usually performed for 10-14 days; prednisone is the most 
frequently prescribed steroid, in a dose 1 mg/kg/day or a maximum of 60 mg, followed by a 
taper of 10 mg every 2 days [42]. 
Recently, intra-tympanic dexamethasone (ITD) has been proposed as an additional 
therapy to the conventional modalities, due to the possibility of avoiding the systemic 
collateral effects of the steroids, plus reaching higher concentration in the perilymph. The 
main mechanism for this modality is based on the semi-permeable nature of the round 
window membrane, which allow the penetration of the medication in the inner ear 

Rafael da Costa Monsanto, Ana Luiza Kasemodel, Luiza Mazzola et al. 
 
606
compartments [15, 16, 37, 42, 60, 61]. In a prospective, randomized, and controlled clinical 
study [60], 30 patients were treated with ITD plus systemic steroids, and 30 only received 
systemic steroids. No significant benefit effect of the ITDs in the overall hearing was 
observed; nonetheless, the hearing level at the frequency of 250Hz significantly improved in 
the ITD group. On the other hand, Ho et al. [61] found contrasting results: patients with 
severe to profound SSNHL that received ITD therapy (4 mg/ml, 0.4-0.7 ml, once a week for 3 
weeks) after failure of the standard treatment had significantly higher rates of hearing 
recovery when compared to a non-ITD group. Furthermore, the authors consider ITD to be an 
alternative for patients in which systemic steroids have failed. The optimal dose for ITD must 
be better investigated. 
 
 
Therapy to Increase Cochlear Blood Flow (CBF) 
 
Since vascular etiology is one of the theories for the genesis of sudden deafness, many 
treatments have been proposed in an attempt to improve CBF, including vasodilators 
(histamine, verapamil, carbon dioxide, papaverine hydrochloride) or drugs that decrease 
blood viscosity (dextran, batroxobin, pentoxifylline). 
Carbogen inhalation (composed of 5% carbon dioxide and 95% oxygen) is used for 
treating SSNHL based on its vasodilator effect. Fish et al. [27] demonstrated that the pressure 
of carbon dioxide (PCO2) has a stronger stimulation in cochlear blood flow than pressure of 
oxygen (PO2) only, and PO2 and PCO2 are intensely influenced by hyperventilation, 
hypoventilation or apnea, since these conditions affect the oxygen tension in the 
perilymphatic compartments. The author also demonstrated that carbogen achieved higher 
increments in cochlear oxygenation than 100% O2 or air + 7% CO2. When comparing 
carbogen with other vasodilators (papaverine and dextran IV), he found that carbogen 
inhalation had better hearing recovery than vasodilators when re-evaluated 1 year following 
treatment. Nevertheless, the use and beneficial effects of the carbogen inhalation are still 
considered to be controversial [56]. 
Defibrogenation therapy with batroxobin is another proposed treatment for sudden 
deafness [62]. It has been reported that this drug reduces blood viscosity, with better results in 
hearing improvement and other associated symptoms when compared to systemic steroids. 
Kubo et al. [62] (1988) found better improvement in the hearing levels in the batroxobin 
when compared to the bethametasone group. On the other hand, Cinamon et al. [56] found no 
difference between the use of batroxobin and steroids. 
Gingko biloba has also been described to have good benefits since it contains flavones 
and terpenes, which acts avoiding the formation of free-oxygen radicals, controlling vessel 
contraction [63]. In patients with uncomplicated SSNHL, high dosages of the extract EGb 
761 proved to be beneficial (240 mg per day for 8 weeks) [64]. 
Pentoxifylline is also described as an agent capable of improving CBF by reducing the 
blood viscosity. It inhibits platelet aggregation and rises flexibility of erythrocites and 
leukocytes. Also, a decrease in the hematocrit results in increasing oxygen tension, by 
improving the inner ear perfusion [56]. Reisser and Weidauer [63] compared the hearing 
improvement between Gingko biloba extract EGb 761 (200 mg daily, for 10 days) with 
pentoxifylline (300 mg daily for 10 days) and found that both therapies are effective; 
however, the gingko biloba had better outcomes when considering the tinnitus as well. 

Sudden Sensorineural Hearing Loss 
 
607
Anti-Viral Therapy 
 
To our knowledge, there is no strong scientific evidence that supports the use of antivirals 
[57, 58], in spite of the data supporting a viral cause in histopathologic studies in humans’ 
temporal bones [14, 19, 65]. 
 
 
Shotgun Therapy 
 
A study suggested a standardized treatment for SSNHL, named as the “Belgium cocktail” 
[66]. The proposed drug regimen for these patients is as follows: 
 
 
steroids: prednisolone 1 mg/kg; 
 
piracetam: 3 x 3 1200 mg/day (10.8 g/day) 
 
vitamin E: 2x 600 IU/day 
 
magnesium: 167 mg/day 
 
acyclovir: 5x 800 mg/day for7 days (only when the patient presents within the first 3 
days of the onset of symptoms). 
 
Even though this empirical treatment modality includes a very schematic therapy for the 
acute phase of the SSNHL, to our knowledge, no further randomized, double-blind studies 
were performed to validate the efficacy of this treatment compared to placebo. 
 
 
Other Treatment Modalities 
 
Following the assumption that a decrease in the cochlear blood flow could result in 
hypoxia, some authors hypothesized that therapies which could increase oxygen tension could 
be beneficial for these patients. In an attempt to prove this hypothesis, several treatments have 
been proposed. Hyperbaric oxygen therapy (HBO) has been used to increase oxygen tension 
in inner ear circulation, perilymph and endolymph. In this treatment, the patient inhales, 
through a mask, oxygen at a 100% level, under 2.5 atmospheres, once a day. Each session 
lasts 90 minutes [67]. Aslan et al. [67], in a retrospective chart review, observed that patients 
who underwent treatment HBO associated to the conventional steroid treatment had better 
recovery of hearing, especially in the first 2 weeks of the onset and in younger patients (less 
than 49 years old). They reported that advanced age has a negative influence in the recovery 
of sudden deafness, probably due to microvascular disturbances present in the elderly. The 
authors finally conclude that HBO therapy is recommended in patients with less than 50 years 
old. In addition, elderly population should not be subjected to HBO therapy due to possible 
and serious complications. 
Some authors advocate the use of vitamins to treat SSNHL, based on the hypothesis that 
they could reduce oxygen-free radicals, protecting the sensorial elements of the cochlea 
against cellular damage [47]. These authors reported better hearing outcomes in patients using 
vitamin E associated with steroids when compared to patients using steroids in monotherapy. 

Rafael da Costa Monsanto, Ana Luiza Kasemodel, Luiza Mazzola et al. 
 
608
In addition to the treatment, patients with unilateral SSNHL should also be carefully 
oriented in order to minimize the risk of hearing loss in the good ear [42] (Rauch et al., 2008). 
It is recommended for these patients to use noise protection devices (such as earplugs) to 
avoid acoustic trauma, and avoid scuba diving or activities involving sudden pressure 
changes. The patients should also be oriented to search an otolaryngologist immediately if 
new or recurrent symptoms present. 
 
 
PROGNOSIS 
 
Many studies dedicated to assessing the prognosis of the hearing loss secondary to 
SSNHL. The prognosis depends on several factors, including (but not limited to): 
demographics, etiology, disease process, duration, audiogram characteristics, and impact on 
cochlear and vestibular structures [5, 68]. In untreated patients, 65% completely recover the 
hearing leves spontaneously, in about 14 days [10]. However, in some patients, the hearing 
levels will not improve at all [30]. 
The disease onset age was most important demographic factor to act in the prognosis of 
the SSNHL: patients older than 60 had decreased rates of hearing recovery, and lower 
absolute threshold gains [5, 51]. 
The shape of the hearing loss in the audiogram are also intimately associated with the 
prognosis: patients with low-frequency or mild-frequency hearing losses achieve better final 
auditory results when comparing to those with flat or downsloping hearing loss [4, 5, 10]. 
Patients who present for evaluation within a week after the onset of the first symptoms 
have higher chances of hearing recovery; furthermore, the probability of complete recover is 
also higher when compared to those who presents after the first 7 days. Thus, the chances of 
hearing recovery gradually decrease over time [5, 69]. Although these findings might suggest 
that early treatment improve the chances of better hearing outcomes, this assumptiom has not 
been supported by other following studies [5, 14, 69]. Concomitant imbalance or vertigo is 
also associated to poorer recovery of the hearing levels [5]. Furthermore, patients with 
abnormalities on electronystagmography also had worse chances of recovery when compared 
to those without those abnormalities [51, 69]. 
 
 
CONCLUSION 
 
SSNHL should be promptly recognized, and the search for a possible cause is imperative. 
Correct diagnosis and treatment could prevent the hearing changes from being permanent. 
 
 
ACKNOWLEDGMENTS 
 
We are grateful to all study participants for their contributions; and also to Prof. Michael 
M. Paparella, MD, for the human temporal bone pictures and great technical support. 
 
 

Sudden Sensorineural Hearing Loss 
 
609
REFERENCES 
 
[1] 
Kleyn AD. Sudden complete or partial loss of function of the octavus-system in 
apparently normal persons. Acta Otolaryngol. (Stockh.) 1944;32(5-6):407-29. 
[2] 
Mosnier I, Bouccara D, Atassi-Dumont M, Sterkers O. [Treatments of idiopathic 
sudden sensorineural hearing loss: retrospective study of 144 cases]. Rev. Laryngol. – 
Otol. – Rhinol. 1998;119(2):119-28. 
[3] 
Hughes GB, Freedman MA, Haberkamp TJ, Guay ME. Sudden sensorineural hearing 
loss. Otolaryngol. Clin. North Am. 1996;29(3):393-405. 
[4] 
Mattox DE, Lyles CA. Idiopathic sudden sensorineural hearing loss. Am. J. Otol. 1989; 
10(3):242-7. 
[5] 
Byl FM. Sudden hearing loss: eight years’ experience and suggested prognostic table. 
The Laryngoscope 1984;94(5 Pt 1):647-61. 
[6] 
Haberkamp TJ, Tanyeri HM. Management of idiopathic sudden sensorineural hearing 
loss. Am. J. Otol. 1999;20(5):587-92; discussion 593-5. 
[7] 
McCabe BF. Autoimmune sensorineural hearing loss. Ann. Otol. Rhinol. Laryngol. 
1979;88(5 Pt 1):585-9. 
[8] 
Harris JP, Woolf NK, Ryan AF, Butler DM, Richman DD. Immunologic and 
electrophysiological response to cytomegaloviral inner ear infection in the guinea pig. 
J. Infect. Dis. 1984;150(4):523-30. 
[9] 
Stone JH, Francis HW. Immune-mediated inner ear disease. Curr. Opin. Rheumatol. 
2000;12(1):32-40. 
[10] Mattox DE, Simmons FB. Natural history of sudden sensorineural hearing loss. Ann. 
Otol. Rhinol. Laryngol. 1977;86(4 Pt 1):463-80. 
[11] Rowson KE, Hinchcliffe R. A virological and epidemiological study of patients with 
acute hearing loss. Lancet Lond. Engl. 1975;1(7905):471-3. 
[12] Wilson WR, Veltri RW, Laird N, Sprinkle PM. Viral and epidemiologic studies of 
idiopathic sudden hearing loss. Otolaryngol.--Head Neck Surg. Off J. Am. Acad. 
Otolaryngol.-Head Neck Surg. 1983;91(6):653-8. 
[13] Fukuda S, Chida E, Kuroda T, Kashiwamura M, Inuyama Y. An anti-mumps IgM 
antibody level in the serum of idiopathic sudden sensorineural hearing loss. Auris Nasus 
Larynx 2001;28 Suppl:S3-5. 
[14] Schuknecht HF, Kimura RS, Naufal PM. The pathology of sudden deafness. Acta 
Otolaryngol. (Stockh.) 1973;76(2):75-97. 
[15] Schachern PA, Paparella MM, Goycoolea M, Goldberg B, Schlievert P. The round 
window membrane following application of staphylococcal exotoxin: an electron 
microscopic study. The Laryngoscope 1981;91(12):2007-17. 
[16] Schachern PA, Paparella MM, Goycoolea MV, Duvall AJ, III, Choo Y. THe 
permeability of the round window membrane during otitis media. Arch. Otolaryngol. 
Neck Surg. 1987;113(6):625-9. 
[17] Schuknecht HF, Benitez J, Beekhuis J, Igarashi M, Singleton G, Ruedi L. The 
pathology of sudden deafness. The Laryngoscope 1962;72:1142-57. 
[18] Schuknecht HF, Donovan ED. The pathology of idiopathic sudden sensorineural 
hearing loss. Arch Otorhinolaryngol. 1986;243(1):1-15. 

Rafael da Costa Monsanto, Ana Luiza Kasemodel, Luiza Mazzola et al. 
 
610
[19] Vasama J-P, Linthicum FH. Idiopathic Sudden Sensorineural Hearing Loss: Temporal 
Bone Histopathologic Study. Ann. Otol. Rhinol. Laryngol. 2000;109(6):527-32. 
[20] Igarashi M, Alford BR, Konishi S, Shaver EF, Guilford FR. Functional and 
histopathological correlations after microembolism of the peripheral labyrinthine artery 
in the dog. The Laryngoscope 1969;79(4):603-23. 
[21] Yamasoba T, Kikuchi S, Higo R, O’uchi T, Tokumaru A. Sudden sensorineural hearing 
loss associated with slow blood flow of the vertebrobasilar system. Ann. Otol. Rhinol. 
Laryngol. 1993;102(11):873-7. 
[22] Yamasoba T, Kikuchi S, Higo R, Kaga K, O’uchi T, Tokumaru A. Ischemic brain 
lesions in aged patients with dizziness. Arch. Otolaryngol. Head Neck Surg. 1993;119 
(12):1346-50. 
[23] Kikuchi S, Kaga K, Yamasoba T, Higo R, O’Uchi T, Tokumaru A. Slow blood flow of 
the vertebrobasilar system in patients with dizziness and vertigo. Acta Otolaryngol. 
(Stockh.) 1993;113(3):257-60. 
[24] Lee H, Sohn S-I, Jung D-K. et al. Sudden deafness and anterior inferior cerebellar 
artery infarction. Stroke J. Cereb. Circ. 2002;33(12):2807-12. 
[25] Lin H-C, Chao P-Z, Lee H-C. Sudden sensorineural hearing loss increases the risk of 
stroke: a 5-year follow-up study. Stroke J. Cereb. Circ. 2008;39(10):2744-8. 
[26] Mayot D, Béné MC, Dron K, Perrin C, Faure GC. Immunologic alterations in patients 
with sensorineural hearing disorders. Clin. Immunol. Immunopathol. 1993;68(1):41-5. 
[27] Slattery WH, Fisher LM, Iqbal Z, Liu N. Oral steroid regimens for idiopathic sudden 
sensorineural hearing loss. Otolaryngol.--Head Neck Surg. Off J. Am. Acad. 
Otolaryngol.-Head Neck Surg. 2005;132(1):5-10. 
[28] Yamamoto M, Kanzaki J, Ogawa K, Ogawa S, Tsuchihashi N. Evaluation of hearing 
recovery in patients with sudden deafness. Acta Otolaryngol. Suppl. 1994;514:37-40. 
[29] Veldman JE, Hanada T, Meeuwsen F. Diagnostic and therapeutic dilemmas in rapidly 
progressive sensorineural hearing loss and sudden deafness. A reappraisal of immune 
reactivity in inner ear disorders. Acta Otolaryngol. (Stockh.) 1993;113(3):303-6. 
[30] García Berrocal JR, Ramírez-Camacho R. Immune response and immunopathology of 
the inner ear: an update. J. Laryngol. Otol. 2000;114(2):101-7. 
[31] Goodhill V. Sudden deafness and round window rupture. The Laryngoscope 1971;81 
(9):1462-74. 
[32] Hornibrook J. Perilymph Fistula: Fifty Years of Controversy. ISRN Otolaryngol. 
[Internet] 2012 [cited 2016 May 1];2012. Available from: http://www.ncbi.nlm.nih. 
gov/pmc/articles/PMC3658483/. 
[33] Simmons FB. Theory of membrane breaks in sudden hearing loss. Arch. Otolaryngol. 
Chic. Ill. 1960 1968;88(1):41-8. 
[34] Stroud MH, Calcaterra TC. Spontaneous perilymph fistulas. The Laryngoscope 1970; 
80(3):479-87. 
[35] Chandrika NT, Garneau-Tsodikova S. A review of patents (2011-2015) towards 
combating resistance to and toxicity of aminoglycosides. MedChemComm 2016;7(1): 
50-68. 
[36] Kusunoki T, Cureoglu S, Schachern PA. et al. Effects of gentamicin on sensorineural 
elements of the cochlea in human temporal bones. Am. J. Otolaryngol. 2004;25(5):313-
7. 

Sudden Sensorineural Hearing Loss 
 
611
[37] Goycoolea MV, Lundman L. Round window membrane. Structure function and 
permeability: a review. Microsc. Res. Tech. 1997;36(3):201-11. 
[38] Barrenäs ML, Holgers KM. Ototoxic interaction between noise and pheomelanin: 
distortion product otoacoustic emissions after acoustical trauma in chloroquine-treated 
red, black, and albino guinea pigs. Audiol. Off Organ Int. Soc. Audiol. 2000;39(5):23-
46. 
[39] Vijayendra H, Buggaveeti G, Parikh B, Sangitha R. Sudden Sensorineural Hearing 
Loss: An Otologic Emergency. Indian J. Otolaryngol. Head Neck Surg. 2012;64(1):1-4. 
[40] Leong A. C., Fairley J W., Padgham N D. Sudden hearing loss. Clin. Otolaryngol. 
2007;32(5):391-4. 
[41] Schreiber BE, Agrup C, Haskard DO, Luxon LM. Sudden sensorineural hearing loss. 
Lancet Lond. Engl. 2010;375(9721):1203-11. 
[42] Rauch SD. Clinical practice. Idiopathic sudden sensorineural hearing loss. N. Engl. J. 
Med. 2008;359(8):833-40. 
[43] Lee H, Whitman GT, Lim JG, Lee SD, Park YC. Bilateral sudden deafness as a 
prodrome of anterior inferior cerebellar artery infarction. Arch. Neurol. 2001;58(8): 
1287-9. 
[44] Lee H, Baloh RW. Sudden deafness in vertebrobasilar ischemia: clinical features, 
vascular topographical patterns and long-term outcome. J. Neurol. Sci. 2005;228(1):99-
104. 
[45] Psifidis AD, Psillas GK, Daniilidis JC. Sudden sensorineural hearing loss: long-term 
follow-up results. Otolaryngol.--Head Neck Surg. Off J. Am. Acad. Otolaryngol.-Head 
Neck Surg. 2006;134(5):809-15. 
[46] Cvorović L, Deric D, Probst R, Hegemann S. Prognostic model for predicting hearing 
recovery in idiopathic sudden sensorineural hearing loss. Otol. Neurotol. Off Publ. Am. 
Otol. Soc. Am. Neurotol. Soc. Eur. Acad. Otol. Neurotol. 2008;29(4):464-9. 
[47] Joachims HZ, Segal J, Golz A, Netzer A, Goldenberg D. Antioxidants in treatment of 
idiopathic sudden hearing loss. Otol. Neurotol. Off Publ. Am. Otol. Soc. Am. Neurotol. 
Soc. Eur. Acad. Otol. Neurotol. 2003;24(4):572-5. 
[48] Chen C-Y, Halpin C, Rauch SD. Oral steroid treatment of sudden sensorineural hearing 
loss: a ten year retrospective analysis. Otol. Neurotol. Off Publ. Am. Otol. Soc. Am. 
Neurotol. Soc. Eur. Acad. Otol. Neurotol. 2003;24(5):728-33. 
[49] Mark AS, Seltzer S, Nelson-Drake J, Chapman JC, Fitzgerald DC, Gulya AJ. 
Labyrinthine enhancement on gadolinium-enhanced magnetic resonance imaging in 
sudden deafness and vertigo: correlation with audiologic and electronystagmographic 
studies. Ann. Otol. Rhinol. Laryngol. 1992;101(6):459-64. 
[50] Ramos HVL, Barros FA, Yamashita H, Penido N de O, Souza ACV de, Yamaoka WY. 
Magnetic resonance imaging in sudden deafness. Rev. Bras. Otorrinolaringol. 2005;71 
(4):422-6. 
[51] Fetterman BL, Luxford WM, Saunders JE. Sudden bilateral sensorineural hearing loss. 
The Laryngoscope 1996;106(11):1347-50. 
[52] Lee H, Yi HA, Baloh RW. Sudden bilateral simultaneous deafness with vertigo as a 
sole manifestation of vertebrobasilar insufficiency. J. Neurol. Neurosurg. Psychiatry 
2003;74(4):539-41. 

Rafael da Costa Monsanto, Ana Luiza Kasemodel, Luiza Mazzola et al. 
 
612
[53] Penido N de O, Ramos HVL, Barros FA, Cruz OLM, Toledo RN. Clinical, etiological 
and progression factors of hearing in sudden deafness. Braz. J. Otorhinolaryngol. 2005; 
71(5):633-8. 
[54] Toubi E, Ben-David J, Kessel A, Podoshin L, Golan TD. Autoimmune aberration in 
sudden sensorineural hearing loss: association with anti-cardiolipin antibodies. Lupus 
1997;6(6):540-2. 
[55] Cole RR, Jahrsdoerfer RA. Sudden hearing loss: an update. Am. J. Otol. 1988;9(3):211-
5. 
[56] Cinamon U, Bendet E, Kronenberg J. Steroids, carbogen or placebo for sudden hearing 
loss: a prospective double-blind study. Eur. Arch. Oto-Rhino-Laryngol. Off J. Eur. Fed. 
Oto-Rhino-Laryngol. Soc. EUFOS Affil. Ger. Soc. Oto-Rhino-Laryngol. - Head Neck 
Surg. 2001;258(9):477-80. 
[57] Conlin AE, Parnes LS. Treatment of sudden sensorineural hearing loss: II. A Meta-
analysis. Arch. Otolaryngol. Head Neck Surg. 2007;133(6):582-6. 
[58] Conlin AE, Parnes LS. Treatment of sudden sensorineural hearing loss: I. A systematic 
review. Arch. Otolaryngol. Head Neck Surg. 2007;133(6):573-81. 
[59] MacArthur CJ, DeGagne JM, Kempton JB, Trune DR. Steroid control of acute middle 
ear inflammation in a mouse model. Arch. Otolaryngol. Head Neck Surg. 2009;135(5): 
453-7. 
[60] Ahn JH, Yoo MH, Yoon TH, Chung JW. Can intratympanic dexamethasone added to 
systemic steroids improve hearing outcome in patients with sudden deafness? The 
Laryngoscope 2008;118(2):279-82. 
[61] Ho HG-M, Lin H-C, Shu M-T, Yang C-C, Tsai H-T. Effectiveness of intratympanic 
dexamethasone injection in sudden-deafness patients as salvage treatment. The 
Laryngoscope 2004;114(7):1184-9. 
[62] Kubo T, Matsunaga T, Asai H. et al. Efficacy of defibrinogenation and steroid therapies 
on sudden deafness. Arch. Otolaryngol. Head Neck Surg. 1988;114(6):649-52. 
[63] Reisser CH, Weidauer H. Ginkgo biloba extract EGb 761 or pentoxifylline for the 
treatment of sudden deafness: a randomized, reference-controlled, double-blind study. 
Acta Otolaryngol. (Stockh.) 2001;121(5):579-84. 
[64] Burschka MA, Hassan HA, Reineke T, van Bebber L, Caird DM, Mösges R. Effect of 
treatment with Ginkgo biloba extract EGb 761 (oral) on unilateral idiopathic sudden 
hearing loss in a prospective randomized double-blind study of 106 outpatients. Eur. 
Arch. Oto-Rhino-Laryngol. Off J. Eur. Fed. Oto-Rhino-Laryngol. Soc. EUFOS Affil. 
Ger. Soc Oto-Rhino-Laryngol. - Head Neck Surg. 2001;258(5):213-9. 
[65] Yoon TH, Paparella MM, Schachern PA, Alleva M. Histopathology of sudden hearing 
loss. The Laryngoscope 1990;100(7):707-15. 
[66] Levie P, Desgain O, Burbure C. et al. Sudden hearing loss. B-ENT 2007;3(6):33-43. 
[67] Aslan I, Oysu C, Veyseller B, Baserer N. Does the addition of hyperbaric oxygen 
therapy to the conventional treatment modalities influence the outcome of sudden 
deafness? Otolaryngol.--Head Neck Surg. Off J. Am. Acad. Otolaryngol.-Head Neck 
Surg. 2002;126(2):121-6. 
[68] Meyerhoff WL, Pollock KJ. A patient-oriented approach to perilymph fistula. Arch. 
Otolaryngol. Head Neck Surg. 1990;116(11):1317-9. 
 

Sudden Sensorineural Hearing Loss 
 
613
[69] Xenellis J, Karapatsas I, Papadimitriou N. et al. Idiopathic sudden sensorineural hearing 
loss: prognostic factors. J. Laryngol. Otol. 2006;120(9):718-24. 
 
Reviewed by: Henrique F. Pauna, M.D. 
 
 


In: Encyclopedia of Audiology and Hearing Research 
ISBN: 978-1-53617-702-2 
Editors: Erno Larivaara and Senja Korhola 
© 2020 Nova Science Publishers, Inc. 
 
 
 
 
 
 
 
Chapter 41 
 
 
 
UP-TO-DATE IN AUDITORY NEUROPATHY SPECTRUM 
DISORDER: CLINICAL, DIAGNOSTIC AND 
THERAPEUTIC FEATURES 
 
 
Henrique Furlan Pauna1,  
Alexandre Caixeta Guimarães1, Edi Lucia Sartorato2 
and Guilherme Machado de Carvalho3  
1Department of Otorhinolaryngology, Head and Neck Surgery, University of Campinas – 
UNICAMP, Campinas, SP, Brazil 
2Molecular Genetics Laboratory, Molecular Biology and Genetic Engineering Center – 
CBMEG, University of Campinas – UNICAMP, Campinas, SP, Brazil  
3Medicine Department, Universidade do Minho, Braga, Portugal 
 
 
ABSTRACT 
 
Auditory neuropathy spectrum disorder is a condition in which there is a change in 
the neuronal transmission of the auditory stimuli, due to the involvement of inner hair 
cells of the organ of Corti or involvement of auditory nerve synapses. It is characterized 
by the absence or alteration of waves in the brainstem auditory evoked potentials exams. 
Medical literature shows a great variability in findings related to auditory 
neuropathy, both in its etiology and epidemiological data. About 80 pathogenic mutations 
have been described in individuals with non-syndromic deafness, with an emphasis on 
the GJB2 and p.Q829X mutations. 
Clinical diagnosis may vary in several degrees with unilateral or bilateral hearing 
loss (symmetrically or not), a low speech discrimination (incompatible with audiometric 
thresholds), fluctuating hearing levels, presence of otoacoustic emissions and cochlear 
microphonic detection, with no auditory brainstem responses. 
Cochlear implantation or fitting of hearing aids should be performed as early as 
possible for a better hearing rehabilitation. 
In this upcoming chapter we intend to present the epidemiological features, clinical 
presentation, genetic findings, and treatment options for patients experiencing auditory 
neuropathy spectrum disorder.  
 

Henrique F. Pauna, Alexandre C. Guimarães1, Edi L. Sartorato et al. 
 
616
INTRODUCTION 
 
Auditory neuropathy term was first used in 1996, and during the Conference of 
Consensus on Auditory Neuropathy/Dyssynchrony in Como, Italy (2008) [1], it was changed 
to auditory neuropathy spectrum disorder due to many clinical forms of this particular 
disease.  
The auditory neuropathy spectrum disorder (AN) is a disease believed to be a sensory 
disturbance of the inner ear on its interface with the brain stem and/or in the auditory cortex, 
and it is observed a deficient neural activity of the cochlear nerve, and further related to 
injuries that can affect the inner hair cell synapse, spiral ganglion, axon, the myelin sheath, 
and the nerve dendrite [2-5].  
Many groups studying this entity still disagree with the diagnoses parameters as well as 
with the treatment, mainly because several situations and circumstances in which the 
diagnostic tools are insufficient to properly diagnose it. Anyway, the classical findings are the 
presence of otoacoustic emissions and an absence of response in the auditory brainstem 
response [1]. 
The basic treatment consists in speech and language therapy with auditory training, 
supported by conventional hearing aids or cochlear implantation, when necessary [4]. 
This chapter will briefly review all current data available about this disorder and 
highlight the clinical presentation, and treatment options for this entity. 
 
 
EPIDEMIOLOGY 
 
Hearing loss is the most prevalent sensory disorder in humans. It may be caused by a 
combination of several factors, as environmental (exposure to frequent high-intensity sounds, 
acoustic trauma, infections and ototoxic drugs), or genetic factors [6]. In developed countries, 
more than 60% of all cases of hearing loss result from genetic causes [7]. International 
statistics show one case of hearing loss in every 1,000 births. In Brazil, however, 
environmental factors outweigh those of genetic origin, and the frequency of hearing loss is 
estimated at four per 1,000 births, but depending on the sample and studied area, it may be 
present in 2-7 per 1,000 newborns [6]. 
Auditory neuropathy is an auditory disturbance in which the function of the outer hair 
cells of the organ of Corti is normal, but the function of the inner hair cells is compromised. 
This condition may affect any subject at any age group, with a prevalence between 0.23 to 2% 
of the children [5]. It is believed that about 8% of all new annual cases of hearing loss are 
related to AN. A recent study found a prevalence of 1.2% of AN among 2,292 patients with 
hearing loss [8], and Manchaiah et al. showed that patients with AN have an association with 
hereditary neurological disorders in 42% of the cases; toxic, metabolic, immunological, and 
infectious disorders in 10% of the cases; and unknown cause in 48% of the cases [9]. 
The large number of genes expressed in the cochlea reflects the complexity of the 
molecular mechanisms involved in this organ [10]. Most cases of hereditary hearing loss are 
non-syndromic (70%, approximately). When autosomal dominant, they are named as DFNA; 
autosomal recessive as DFNB, X-linked (X-DFN), or mitochondrial [6]. It is estimated that 
75-80% of cases of non-syndromic genetic deafness are autosomal recessive, 20-25% are 

Up-to-Date in Auditory Neuropathy Spectrum Disorder 
 
617
autosomal dominant, and 1-2% are X-linked. The mitochondrial inheritance is estimated at 
1% [11].  
 
 
DIAGNOSTIC 
 
Auditory neuropathy is a type of sensorineural hearing loss (Figure 1) known with 
auditory stimulus alteration as a result of the involvement of inner hair cells or auditory nerve 
synapses. The absence or alteration of the waves in the auditory brainstem response test and 
the presence of otoacoustic emissions (Figure 2) and/or cochlear microphonism is 
characteristic of this disease [12]. Furthermore, a normal otoscopy, absence of middle ear 
disease, absence of speech recognition threshold, absence of acoustic reflex, and imaging 
examination (computed tomography and magnetic resonance imaging) showing the presence 
of the cochlear nerve and excluding other retrocochlear pathologies are mandatory. 
 
 
Figure 1. Examples of sensorineural hearing loss caused by auditory neuropathy spectrum disorder.  
0
10
20
30
40
50
60
70
80
90
100
110
120
250
500
1000
2000
3000
4000
6000
8000
Patient A
Patient B
Patient C
Patient D
Patient E
Patient F
Patient G
Patient H
Patient I
Patient J

Henrique F. Pauna, Alexandre C. Guimarães1, Edi L. Sartorato et al. 
 
618
 
Figure 2. Examples of present otoacoustic emissions in a case with no ABR response. 
It is related to 7 to 10% of the cases of hearing loss in children, and can be caused by 
genetic factors, or environmental factors, such as hyperbilirubinemia, prematurity, anoxia, 
exposure to ototoxic drugs, infections, and others [13]. When considering the syndromic 
association, AN can be related to systemic neurodegenerative diseases, such as Charcot-
Marie-Tooth disease, Friedreich’s ataxia, Guillain-Barré neuropathy, and others [7]. 
Considering the genetic factors, we can mention that otoferlin (OTOF) gene – located in 
the locus DFNB9, chromosomal region 2p22-23 – is one of the 40 genes associated to 
autosomal recessive non-syndromic hearing loss, and is expressed in the cochlea, vestibule, 
and brain [14]. Another gene, diaphanous-3 (DIAPH3) – located in the locus AUNA1, 
chromosomal region 13q21-q24 – was identified in 2004 and it is associated with autosomal 
dominant postlingual AN [15]. The PJVK gene – located in the locus DFNB59, region 
2q31.1-q31.3 – encodes pejvakin, a protein of the afferent auditory pathway involved in 
signaling form hair cells and neurons [16]. Additionally, mutations in connexin 26, the gap 
junction 2 (GJB2) gene, are also associated with AN [8]. However, it is not clear how the 
mutations in the GJB2 gene may cause changes in the inner hair cells and nerve endings of 
the hair cells, but Carvalho et al. identified homozygous c.35delG deletions in patients with 
AN using polymerase chain reaction (PCR) method [6].  
Lastly, AN associated with mitochondrial disease may be related to hereditary syndromes 
as mentioned before, including Charcot-Marie-Tooth disease, Leber’s hereditary optic 
neuropathy, autosomal dominant optic atrophy, autosomal recessive optic atrophy, 
Fredreich’s ataxia, Mohr-Tranebjaerg syndrome, and Refsum’s disease. Mitochondrial 
mutations are especially related to aminoglycoside-induced hearing loss and maternally 
inherited non-syndromic hearing loss (with no exposition to aminoglycoside). Mitochondrial 
mutations, like m.1095T > C (in the mitochondrial 12S rRNA gene), and m.1555A > G (in 
the MTRNR1 gene) are examples of these mutations [17]. 
 
 
 
 
 

Up-to-Date in Auditory Neuropathy Spectrum Disorder 
 
619
REHABILITATION 
 
The degree of hearing loss in patients with AN varies from moderate to severe, and 
treatment is a special challenge for otolaryngologists and speech therapists, since the 
audiometric thresholds tends to fluctuate, as well as the measurements of speech performance 
[18]. In the past, AN patients were treated in different ways, ranging from a simple 
observation, to the use of hearing aids (Figure 3) and frequency modulation system, with poor 
results predominantly.  
As conventional treatment for AN has been shown refractory to conventional 
amplification, cochlear implantation rises as an alternative therapy for this condition. 
Cochlear implantation has a large evidence for treatment of various forms of hearing loss. It 
has also been demonstrated that earlier fitting of cochlear implants in children with hearing 
loss leads to an important speech development [19]. At the same time, the data available 
about cochlear implantation in patients with AN all over the world has shown different 
results, probably because this entity is so heterogeneous and has so many possible etiologies 
[1].  
Despite this fact, several cochlear implantation groups indicate this procedure to patients 
with AN who do not have a considerable improvement with speech therapy and the use of 
hearing aids. 
 
 
Figure 3. Examples of patients mentioned in Figure 1 fitted with hearing aids. 
 
 
0
10
20
30
40
50
60
70
80
90
100
110
120
250
500
1000
2000
3000
4000
6000
8000
Patient A
Patient B
Patient C
Patient D
Patient E
Patient F
Patient G
Patient H
Patient I
Patient J

Henrique F. Pauna, Alexandre C. Guimarães1, Edi L. Sartorato et al. 
 
620
CONCLUSION 
 
Auditory neuropathy spectrum disorder is a very heterogeneous clinical situation. The 
diagnosis is not clear and the treatment stills a challenge. It is necessary to use of all the 
resources for a detailed diagnosis, establish a clear relationship with the patient and their 
families, individualize each case and focus on a hearing rehabilitation, speech development 
and speech processing, and interpretation of auditory stimuli and sound information by any 
ways.  
Speech therapy, cochlear implant, auditory training, and hearing aids are the main 
therapeutic options and they can be combined to achieve better results. 
 
 
REFERENCES 
 
[1] 
Hayes, D., Sininger, Y. S., Northern, J. (2008). Guidelines for identification and 
management of infants and young children with auditory neuropathy spectrum 
disorder. Conference NHS, Como, Italy. 
[2] 
Jeon, J. H., Bae, M. R., Song, M. H., Noh, S. H., Choi, K. H., Choi, J. Y. (2013). 
Relationship between electrically evoked auditory brainstem response and auditory 
performance after cochlear implant in patients with auditory neuropathy spectrum 
disorder. Otol Neurotol, 34: 1261-1266. 
[3] 
Penido, R. C. and Issac, M. L. (2013). Prevalence of auditory neuropathy spectrum 
disorder in an auditory health care service. Braz J Otorhinolaryngol, 79: 429-433. 
[4] 
Carvalho, G. M., Guimarães, A. C., Sartorato, E. L. (2014). Auditory neuropathy 
spectrum disorder: clinical and therapeutic challenges. Austin J Otolaryngol, 1(5): 
id1021. 
[5] 
Nikolopoulos, T. P. (2014). Auditory dyssynchrony or auditory neuropathy: 
Understanding the pathophysiology and exploring methods of treatment. Int J Pediatr 
Otorhinolaryngol, 78: 171-173. 
[6] 
Carvalho, G. M., Ramos, P. Z., Castilho, A. M., Guimarães, A. C., Sartorato, E. L. 
(2016). Molecular study of patients with auditory neurophaty. Mol Med Rep, doi: 
10.3892/mmr.2016.5226. 
[7] 
Rodríguez-Ballesteros, M., Arslan, E., Medá, C., Curet, C., Völter, C., et al. (2008). A 
multicenter study on the prevalence and spectrum of mutations in the otoferlin gene 
(OTOF) in subjects with nonsyndromic hearing impairment and auditory neuropathy. 
Hum Mutat, 29: 823-831. 
[8] 
Cheng, X., Li, L., Brashears, S., Morlet, T., Ng, S. S., Berlin, C., et al. (2005). 
Connexin 26 variants and auditory neuropathy/dys-synchrony among children in 
schools for the deaf. Am J Med Genet, 139: 13-18. 
[9] 
Manchaiah, V. K., Zhao, F., Danesh, A. A., Duprey, R. (2011). The genetic basis of 
auditory neuropathy spectrum disorder (ANSD). Int J Pediatr Otorhinolaryngol, 75: 
151-158. 
[10] Heller, S., Sheane, C. A., Javed, Z, Hudspeth, A. J. (1998). Molecular markers for cell 
types of the inner ear and candidate genes for hearing disorders. Proc Natl Acad Sci 
USA, 95: 11400-11405. 

Up-to-Date in Auditory Neuropathy Spectrum Disorder 
 
621
[11] Hilgert, N., Smith, R. J. H., Van Camp, G. (2009). Forty-six genes causing 
nonsyndromic hearing impairment: which ones should be analyzed in DNA 
diagnostics? Mutat Res, 681: 189-196. 
[12] Starr, A., Picton, T. W., Sininger, Y. S., Hood, L. J., Berlin, C. I. (1996). Auditory 
neuropathy. Brain, 119: 741-753. 
[13] Sininger, Y. S. (2002). Identification of auditory neuropathy in infants and children. 
Semin Hear, 23: 193-200. 
[14] Yasunaga, S., Grati, M., Cohen-Salmon, M., El-Amraoui, A., Mustapha, M., Salem, N., 
et al. (1992). A mutation in OTOF, encoding otoferlin, a FER-1 like protein, causes 
DFNB9, a nonsyndromic form of deafness. Nat Genet, 21: 363-369. 
[15] Kim, T. B., Isaacson, B., Sivakumaran, T. A., Starr, A., Keats, B. J., Lesperance, M. M. 
(2004). A gene responsible for autosomal dominant auditory neuropathy (AUNA1) 
maps to 13q14-21. J Med Genet, 41: 872-876. 
[16] Delmaghani, S., del Castillo, F. J., Michel, V., Leibovici, M., Aghaie, A., Ron, U., et 
al. (2006). Mutations in the gene encoding pejvakin, a newly identified protein of the 
afferent auditory pathway, cause DFNB59 auditory neuropathy. Nat Genet, 38: 770-
778. 
[17] Bonhin, R. G., Ramos, P. Z., Guimarães, A. C., Castilho, A. M., Paula, A. C., Paschoal, 
J. R., et al. (2015). Hearing loss and M.1555a>G mitochondrial mutation. Global J 
Med Res: Dent Otolaryngol, 15 (1): 23-27. 
[18] Nash-Kille, A. and Sharma, A. (2014). Inter-trial coherence as a marker of cortical 
phase synchrony in children with sensorineural hearing loss ad auditory neuropathy 
spectrum disorder fitted with hearing aids and cochlear implants. Clin Neurophysiol, 
125: 1459-1470. 
[19] Carvalho, G. M., Guimarães, A. C., Macedo, I. S., Onuki, L. C., Danieli, F., Pauna, H. 
F., et al. (2013). Digisonic SP Binaural cochlear implant: the coronal tunneled 
approach. Braz J Otorhinolaryngol, 79: 298-305. 
 
 
Reviewed by: Paulo Rogério Cantanhede Porto, MD, MS. 
 
 
 


In: Encyclopedia of Audiology and Hearing Research 
ISBN: 978-1-53617-702-2 
Editors: Erno Larivaara and Senja Korhola 
© 2020 Nova Science Publishers, Inc. 
 
 
 
 
 
 
 
Chapter 42  
 
 
 
GENETIC KIDNEY DISEASES WITH  
SENSORINEURAL HEARING LOSS 
 
 
Consolación Rosado Rubio1, PhD, MD 
and Alberto Domínguez Bravo2 
1Service of Nephrology, Complejo Asistencial de Ávila, Ávila, Spain 
2Specialist in General Medicine, Servicio de Salud del  
Principado de Asturias, Asturias, Spain 
 
 
ABSTRACT 
 
Kidney diseases does not commonly curse with hearing loss. However, there are 
several groups of genetic diseases who progress to chronic kidney disease and they curse 
with symptoms of bilateral progresive sensorineural hearing loss. 
The most typical example of these diseases is Alport syndrome. This is a group of 
diseases caused by mutations in COL4A3, COL4A4 or COL4A5 genes. These genes 
encode α3, α4 and α5 chains of collagen IV. This kind of collagen is located in the 
glomerular basement membrane, inner ear and eye. 
Alport syndrome shows different forms of inheritance (autosomal dominant, 
autosomal recessive or X-linked), but all of them cause haematuria, proteinuria and 
progressive chronic renal failure, which evolves until the need for renal replacement 
therapy. This renal involvement is accompanied by ocular manifestations as lenticonus or 
maculopathy and high tones progressive bilateral sensorineural hearing loss, which is a 
key symptom of the syndrome. 
Another group of genetic diseases with hearing impairment is caused by different 
mutations in the MYH9 gene. This gene encodes nonmuscle, myosin heavy chain II-A 
(nmMHC-IIA). Their mutations cause different disorders with an autosomal dominant 
inheritance, presenting with macrothrombocytopenia with giant platelets and leukocyte 
inclusion bodies (set of symptoms known as May-Hegglin anomaly), with or without 
deafness, nephropathy and cataracts. These syndromes, formerly known as Fechtner or 
Epstein Syndrome, are now called MYH9-Related Disorders. 
 
 
 

Consolación Rosado Rubio and Alberto Domínguez Bravo 
 
624
1. INTRODUCTION 
 
Renal diseases, which can evolve to chronic kidney disease with the need of a treatment 
with dialysis or kidney transplantation, are not usually related to sensorineural hearing loss. 
Nevertheless, there are two groups of genetic diseases who typically combine, between 
many other features, sensorineural hearing loss and certain kidney injuries which, finally, 
evolve towards chronic kidney disease [1, 2]. These diseases are caused by mutations in 
several genes: those who codify the type IV collagenous chains (whose mutations provoque 
variants of Alport syndrome) and the gen who codifies heavy chain of non-muscle myosin 
IIA (mutations in this gene generate MYH9 related disorders). 
In this chapter we will do a brief summary of these two groups of diseases, to explain 
their physiopathology, clinical features, diagnostic and treatment, focushing on the hearing 
injuries.  
Finally we will explain the relationship between sensorineural hearing loss and chronic 
kidney disease treated with haemodialysis. Although this topic escapes from the general aim 
of this chapter, we find interesting to explain the possible relation between hearing loss and 
kidney disease in an effort to better understand the physiopathology that relates these two 
disorders.  
 
 
2. HEARING LOSS AND ALPORT SYNDROME 
 
Alport syndrome (AS) includes a group of hereditary diseases caused by mutations in the 
COL4A3, COL4A4 or COL4A5 genes. These genes are responsible for the biosynthesis of 
3, 4 and 5 collagen IV chains, which are located in the glomerular basement membrane 
of the kidney, the inner ear and the eye [3].  
AS has three different patterns of inheritance, which generate three different entities: AS 
associated to the X chromosome (OMIM 301050) in 80% of the cases, caused by mutations 
in COL4A5 gene, autosomal recessive AS (OMIM 203780), which is caused by homozygous 
mutations in COL4A3 or COL4A4 genes, and it appears in 15% of the cases; and autosomal 
dominant AS (OMIM 104200), which is the result of heterozygous mutations in COL4A3 or 
COL4A4 genes and it is diagnoses in the remaining 5% of the patients (Figure 1). In all of 
them, mutations of the corresponding genes prevent the production or the proper type IV 
collagen network, which generates the clinical expression of the disease [1, 3]. So, the main 
symptom is haematuria, which progresses to chronic renal failure and dialysis.  
The most frecuent ocular symptom is anterior lenticonus, which generates a special 
myopia that requires frequent changes of corrective lenses [4]. 
 
 
Introduction 
 
The typical hearing impairment in AS is sensorineural bilateral hearing loss [2], with 
variable intensities, progressive and symmetrical, affecting middle and high frequencies. 
It is a key symptom for the diagnosis of AS in haematuric nephropathies, because its 
presence in these cases is highly suggestive of this genetic disorder.  

Genetic Kidney Diseases with Sensorineural Hearing Loss 
 
625
Although there are studies who show a prevalence of 55% in men and 45% in women [4], 
the real prevalence is unknown, since many patients do not undergo routine audiometries  
[1, 3].  
 
 
Figure 1. Different modes of inheritance and clinical expression of Alport syndrome. C. Rosado, ENT 
& audiology news 2015. 
 
Physiopathology 
 
Type IV collagen basal membranes are the main constituents of membranous labyrinth 
[5, 6]. One of the possible role of these collagen chains is the active adjustment of basilar and 
tectorial membranes, a essential stage in the discrimination of frequencies and amplification 
of auditory signs [7, 8].  
The phsiopathological hypothesis is that the injuried synthesis of type IV collagen 
generates the defective adhesion of the Corti´s organ to the basilar membrane [7].  
Our knowledge of the physiopathology of hearing loss in AS come to us especially from 
the study of experimental animal models, since studies in human ears are restricted because of 
different thecnical difficulties. 
These animal models show us the existence of different injuries, like:  
 
 
Thinning of cochlear basal membrane, which may have some effect on the rigidity of 
the membrane [8]. 
 
Affection of stria vascularis, with edema in endothelial cells and reduction of the 
internal diameter of capillaries [8]. These facts may restrict the blood flow through 
the metabolically hyperactive tissue.  

Consolación Rosado Rubio and Alberto Domínguez Bravo 
 
626
 
Absence of 3, 4 and 5 chains in spiral ligament [9], which could result in a 
reduced capacity of myofibroblasts to maintain enough tension in the basilar 
membrane, with loss of perception for high sounds.  
 
 
Clinic 
 
Hearing loss is one of the first signs of AS, but it is not congenital, because it is detected 
for the first time during the late childhood or in the early adolescence in male patients with 
AS associated to the X chromosome, and by the 40 years of age, 80-90% of the male patients 
have developed it. However, in some families, deafness is not detected until later stages of 
life. The reason for these differences on the age of debut and the clinical evolution is that both 
factors are related to the kind of mutation [10]. 
In women affected by AS associated to the X chromosome, hearing loss is less common, 
and it usually appears on a later stage, because only 18% of female patients are affected at 15 
years old, compared to 85% of men, and at 40 years old, only 45% of the female patients are 
affected [2, 3]. 
There does not seem to be any difference regarding to sex in the incidence of clinical 
evolution of the autosomal forms. In patients with autosomal recessive AS, hearing loss 
appears at a young age, but in the autosomal dominant cases, it can develop later in life, 
although these patients show a great clinical variability. 
In its initial stages, the auditory deficiency can only be detected with an audiometry, 
which shows a bilateral decrease in sensitivity to 2000-8000 Hz range tones. This hearing loss 
is progressive and spreads to other frequencies, including those in the conversational range, 
and it can be incapacitating by the second decade of life [10]. 
Regarding the audiometry, a study revealed three different audiometric configurations: 
ascending curve in 47.1% of the patients, descending curve in 41.2% and flat curve in 11.7% 
of the cases. The mean of thresholds in 500, 1000 and 2000 Hz was 33dB HL in flat curve; 42 
dB HL in ascending curve and 50 dB HL in descending curve. Flat curve was seen at the age 
of 8.5 years; ascending at 13.7 years and descending at 17.8 years, which could suggest a 
progression of the curve. 
The fact that hearing loss is one of the first and most typical signs of Alport syndrome is 
very useful in the study of patients with haematuria. Because of this, there are some particular 
patients, like these ones with haematuria laking familiar record (the novo mutations) [4], or 
when performing a kidney biopsy is not possible, the discovery of a sensorineural bilateral 
hearing loss suggests, in a very clear way, the diagnosis of AS. 
On the other hand, we should include the study of urinary sediment in the diagnosis of all 
hearing losses with this form of clinical presentation. 
Different methods for auditory assessment, like audiometry, auditory brainstem responses 
and otoacoustic emissions, should be employed in the research of the index case and the other 
family cases (affected and asymptomatic) to investigate all disease holders [10]. 
Traditionally it had been stated that bilateral sensorineural hearing loss was always 
accompanied by renal failure, although it could start before the appearance of end-stage 
chronic kidney disease, since the hearing impairment is not related to uremia, but it is the 
result of an injury in cochlear basal membranes [4]. 

Genetic Kidney Diseases with Sensorineural Hearing Loss 
 
627
Hearing loss would run parallel to the progression of the renal failure, and this fact would 
suggest a poor renal prognosis. 
This idea has been recently challenged, since a new mutation has been described in the 
COL4A3 gene, in a family with autosomal dominant AS. This mutation is C.345 delG, which 
generates a frameshift (pG115GfsX37), whose result is a truncated 3(IV) collagen chain that 
produces an impaired collagen network. Some members of the affected family, who carry the 
mutation has bilateral sensorineural hearing loss as the single manifestation of the disease, 
while other relatives have all the symptoms of the disease. This fact confirms that hearing loss 
is an independent symptom of the AS, it is not linked to the renal impairment and it does not 
indicate the prognosis of kidney disease [3, 6].  
It has not still be determined the reasons for the great variability of the clinical course of 
deafness in different patients. Several hypotheses have been proposed, such as the kind of 
mutation (frameshift and nonsenses would generate the most aggressive hearing loss), or the 
influence of other proteins which interact with the collagen IV network, but more studies are 
necessary to explain this point [3].  
 
 
Treatment 
 
There is no special treatment for this kind of hearing loss, unless the hearing aid or 
cochlear implant when the deafness is so severe that it diminishes the patient´s quality of life. 
The early diagnosis of Alport syndrome, with or without genetic diagnosis does not allow us 
to use any therapeutic measure to stop or slow the course of deafness. 
The progress of the disease leads to the need of dialysis and, eventually of a kidney 
transplantation. These treatments can worse the hearing function, since haemodialysis 
generates osmotic and electrolytic affections in endolymph, and several drugs used as 
immunosuppressants in kidney transplantation, like cyclosporine A and corticoids) cause 
affection to viscosity of plasma and circulation of inner ear [10].  
These facts carry us to conclude that patients should benefit of a regular follow up and a 
careful rehabilitation of hearing during the curse of the illness.  
Some authors reported stabilization or even slower progression of hearing loss in post-
transplantation patients, but others have not observe that possitive evolution, but a worsening 
[10]. Because of these contradictory and conflicting observations, more studies are needed for 
the complete understand of evolution of hearing loss after the kidney transplantation. 
There is a rare but severe complication of renal transplantation in patients with Alport 
syndrome, which is the development of anti-MBG nephritis (a kind of Goodpasture 
syndrome). This complication is more frecuent in a particular profile of patients: men with 
hearing loss and end-stage renal failure before the age of 30 years [5]. Hearing loss 
assessment may contribute to create this risk profile in order to anticipate the developement of 
this complication.  
 
 
Conclusion 
 
As a conclusion, we can state that sensorineural bilateral hearing loss is a key feature in 
the diagnosis of the all types of AS. Audiometry is an essential diagnostic test that must be 

Consolación Rosado Rubio and Alberto Domínguez Bravo 
 
628
included in the study of haematuria, mainly if there is a strong suspicion of a genetic disease. 
There is no relationship between the pattern of inheritance and its severity nor with the 
development of chronic kidney disease. 
 
 
3. HEARING LOSS AND MYH9-RELATED DISORDERS 
 
MYH9 related disorders (MYH9RD) are a group of autosomal, dominantly inherited 
disorders caused by mutations of MYH9, which encodes the nonmuscle myosin heavy chain 
IIA (NMMHC-IIA) [12]. 
Non-muscle myosins II are members of the myosin superfamily of motor proteins. 
NMMHC-IIA is a heavy chain which is part of the Non-muscle myosin IIA. This protein is 
encoded by the MYH9 gene, which is located on chromosome 22q12–13 and comprises 44 
exons, 40 of which contain the coding sequence. It is expressed in many different tissues, 
including platelets, leukocytes, kidney, and cochlea [12, 13]. 
Between its functions are maintaining the cytoskeleton and regulating cell adhesion, cell 
migration, and cell division (cellular processes in which force and translocation are 
necessary). It is also the end point for the convergence of several signalling pathways. 
Each NMMHC-IIA contains two regions: a globular one at the amino terminus, that 
catalyses ATP hydrolysis and binds to actin to generate force and movement, and an alpha-
helical carboxy-terminal tail region, which facilite the assembly of bipolar filaments [13].  
MYH9 mutations are associated with several clinical entities, which are: May–Hegglin 
anomaly (OMIM 155100), Sebastian syndrome (OMIM 606249), Fechtner syndrome (OMIM 
153640) and Epstein syndrome (OMIM 153650). Some years ago, all these entities where 
considered different illnesses but, after the discovery of MYH9 gene and its mutations, all of 
these disorders have been included under the name “MYH9 related disorders” [12]. 
MYH9RD has been diagnosed worldwide and there is no evidence of variation in 
prevalence across ethnic populations. Although it is considered a very rare disease (for 
instance, the Italian Registry for MYH9RD includes only 180 affected Italians), the actual 
prevalence is expected to be higher, since mild forms are discovered incidentally and severe 
forms are often misdiagnosed as other disorders. 
MYH9RD is characterized by a complex phenotype. The main feature is 
macrothrombocytopenia, which is present in all disorders included in this illness. The 
difference lies in the presence of the other clinical symptoms, which include basophilic 
Döhle-like bodies in neutrophils, progressive nephropathy with haematuria and proteinuria, 
sensorineural hearing loss, presenile cataracts, and glomerulopathy [14].  
 
Table 1. Clinical and laboratory findings in MYH9RD 
 
 
May–Hegglin 
Sebastian 
Fechtner 
Epstein 
Macrothrombocytopenia 
+ 
+ 
+ 
+ 
Döhle-like bodies 
+ 
+ 
+ 
- 
Hearing loss 
- 
- 
+ 
+ 
Cataracts 
- 
- 
+ 
- 
Kidney disease 
- 
- 
+ 
+ 

Genetic Kidney Diseases with Sensorineural Hearing Loss 
 
629
May–Hegglin anomaly and Sebastian syndrome are characterized by thrombocytopenia, 
giant platelets, and granulocyte cytoplasmic inclusion bodies, called Döhle-like inclusion 
bodies, without further organ involvement. Fechtner syndrome has also sensorineural hearing 
loss, progressive glomerulopathy, and presenile cataracts. Epstein syndrome is characterized 
by macrothrombocytopenia, hearing loss, and glomerulopathy but Döhle-like bodies or 
cataracts are absent [13]. 
Symptoms such as hearing loss, glomerulopathy and cataracts may develop many years 
after the diagnosis of macrothrombocytopenia, and so, the diagnosis of idiopathic chronic 
thrombocytopenia is done, delaying the correct diagnosis. This problem is heightened in 
sporadic cases lacking a family history [12, 13]. 
 
 
Introduction 
 
Sensorineural hearing loss is the most frequent extra-hematological, noncongenital 
manifestation of the MYH9RD. It has been reported in 60% of patients and in 36–71% of 
pedigrees. In many individuals it progresses to severe and profound deafness with high 
impact on quality of life. It is a key symptom in the differential diagnosis of chronic 
macrothrombocytopenia [15]. 
 
 
Physiopathology 
 
The pathogenesis of this kind of hearing loss remains unclear, since we only have animal 
studies. Studies on mouse inner ear showed MYH9 immunoreactivity in various cochlear 
tissues, including hair cells, the spiral ligament, and the Reissner membrane, and no 
immunoreactivity was found in the auditory neurons or within the stria vascularis. Further 
studies have indicate that mutant NMMHC-IIA may cause hearing loss by affecting hair cell 
dysfunction through structural and or functional disruption of its stereocilia, plasma 
membrane, and/or mitochondria [16]. These findings could be extrapolated to the humans 
after the verification of some successful treatments with cochear implants.  
Nevertheless, studies in humans remain necessary in order to completely understand the 
physiopathology of this kind of hearing loss. 
 
 
Clinic 
 
The expressiveness of the hearing impairment is heterogeneous. The variable phenotypic 
expression is observable not only between families but also within families having the same 
mutation.  
The general way of expression is that this kind of hearing loss is a bilateral sensorineural 
defect that, at the onset or in mild forms, is evident only for high tones, but it progresses 
towards severe to profound deafness involving also middle and low frequencies. 
The onset of the defect is distributed in a homogeneous way from the first to sixth 
decade. When it begins in childhood or adolescence, the progression is severe and lead to 
deafness by the age of 30 years [13]. 

Consolación Rosado Rubio and Alberto Domínguez Bravo 
 
630
Data from the literature show us that 36% of patients develop hearing loss before age 20 
years, 33% between ages 20 and 40 years, and 31% after age 40 years. Once diagnosed, 
hearing loss frequently progresses over time, although it remains stable in a minority of 
patients. In 90% of patients with an abnormal audiometry, hearing loss interferes with normal 
activities [17].  
The severity of hearing impairment is variable among different patients; some of them 
suffers from a mild or moderate defect, even in the elderly, but in other cases, hearing loss 
presents during childhood and progresses to profound deafness within the first decades of life, 
which generates a great disability for them [13]. 
Several genotype-phenotype studies have shown that mutations in the globular, amino 
terminus domain have a higher risk of early-onset and severe deafness than subjects with 
mutations in the tail region. 
Another fact that may explique the great variability genotype-phenotype is the joint effect 
of specific mutations and environmental factors, as well as multiple gene products, such as 
polymorphic protein variants interacting with MYH9 [15], but these hypothesis must be 
confirmated in further studies. 
 
 
Treatment 
 
Although there is not a definitive treatment for the illness, the early diagnosis is 
important, in order to establish an early vigilance and treatment of some symptoms. 
Thrombopoietin mimetics can control bleeding tendency due to thrombocytopenia, and 
angiotensin receptor blockers and/or angiotensin-converting enzyme inhibitors are used to 
minimize proteinuria [14]. Nevertheless, this early diagnosis is often difficult and it depends 
on physician awareness of MYH9RD.  
There is not any definitive treatment which delay de progression of hearing loss. At 
present, the only recommendation is to avoid ototoxic factors like some drugs or heavy 
noises. 
Drugs like aminoglycosides, salicylates in large quantities, loop diuretics and some 
chemotherapy regimens shoud be avoided or be used only after a careful assessment of the 
risks versus the benefits. 
If noise exposure cannot be avoided (like in some jobs), the use of ear devices, like 
headphones, to attenuate intense sound is necessary.  
When the hearing loss evolves to a high degree, these patients are potential candidates for 
cochlear implantation. Until recent dates, no consistent data were available about the risk to 
benefit ratio of this intervention in MYH9RD patients with severe to profound deafness. But 
recent case reports and case series show us that it is safe and effective in most of these 
patients and should be offered to them as soon as they develop the criteria for candidacy [16]. 
These studies reveal us that the results of the intervention is similarly good in patients 
with different total durations of deafness and with different ages at implantation (childhood 
up to eight decade). The outcome is also similar regarding the specific MYH9 injury or the 
place of mutation in the protein. 
We should think about certain particular aspects of this disease when programming a 
cochlear implant, like reduced platelet counts, that results in an increased risk of bleeding 
complications during or after surgery and the delayed wound healing.  

Genetic Kidney Diseases with Sensorineural Hearing Loss 
 
631
The co-operation of the hematologist is required to assure the establishment of preventive 
measures, like prophylactic transfusion of apheresis platelet concentrates in cases with severe 
thrombocytopenia or the rutinely use of tranexamic acid when the thrombocytopenia is 
moderate [12].  
Another problem in these patients can be the increased risk of infection after the surgery; 
which is not uncommon among MYH9RD patients, due to, for instance, the 
immunosuppressive treatment after kidney transplantation [17]. 
Nevertheless, we can asume the cochlear implant as a safe procedure in MYH9RD 
whenever adequate prophylactic interventions are carried out. 
 
 
Conclusion  
 
Hearing loss observed in MYH9RD is the most frecuent symptom after the 
thrombocytopenia. It is bilateral and It can evolve up to the complete loss of hearing. It is a 
key symptom to distinguish these diseases from other kind of thrombocytopathies. 
The cochlear implant can be an optimal treatment for these patients. 
 
 
4. HEARING LOSS AND CHRONIC KIDNEY DISEASE 
 
Recent studies have revealed an important relationship between chronic kidney disease of 
any etiology and the prevalence of sensorineural hearing loss, in the form of a mild degree 
sensorineural hypoacusis in patients undergoing haemodialysis [1, 2]. 
The prevalence, degree, and patterns of this hearing loss associated with chronic kidney 
disease differ significantly. Some data say that up to one third of patients undergoing 
haemodialysis experiences some degree of hearing impairment. The great part of them suffer 
from mild hearing loss, which can affect both high and low frequencies, although the 
involvement of high frecuencies might be the most common audiometric abnormality in 
chronic kidney disease affected patients.  
These studies show us that this kind on hearing loss is more obvious in the elderly and in 
patients who have received fewer haemodialysis sessions. We can then state that hearing loss 
may be inversely associated with the number of haemodialysis sessions but not with duration 
of disease [18].  
The physiopatogenic mechanism of this association remains unclear, but the antigenic 
similarity between basement membranes of glomeruli and stria vascularis of the inner ear 
may be an important fact. Some other harmful factors can be the use of ototoxic drugs (it is 
very important in these patients), electrolyte disturbances and arterial hypertension [2]. 
The role of haemodialysis in the hearing loss of patients with chronic kidney disease 
remains unclear, since several studies have produced contradictory results, with a great 
number of them reporting that haemodialysis plays no role in in this association, but a recent 
work demonstrated that the greater the duration of disease, the greater the hearing loss [18]. 
Thus, despite the great amount of studies regarding hearing loss in CKD, unanswered 
questions remain regarding the role of haemodialysis and duration of the disease. 

Consolación Rosado Rubio and Alberto Domínguez Bravo 
 
632
For these reasons, well-designed studies with larger sample sizes are needed to elucidate 
the causal relationships between hearing loss in chronic kidney disease and haemodialysis.  
This association makes us also wonder for the usefulness of the generalized screening for 
sensorineural hearing loss in patients affected by chronic kidney disease, or, at least in 
patients receiving haemodialysis, in order to instaurate an early treatment. 
 
 
REFERENCES 
 
[1] 
Bayazit YA, Yilmaz M. An overview of hereditary hearing loss. ORL J 
Otorhinolaryngol Relat Spec. 2006;68(2):57-63. 
[2] 
Izzedine H, Tankere F, Launay-Vacher V, Deray G. Ear and kidney syndromes: 
molecular versus clinical approach. Kidney Int. 2004 Feb;65(2):369-85. 
[3] 
Rosado C, Bueno E, Felipe C, Valverde S, González-Sarmiento R. Study of the True 
Clinical Progression of Autosomal Dominant Alport Syndrome in a European 
Population. Kidney Blood Press Res. 2015;40(4):435-42. 
[4] 
Gubler MC. Diagnosis of Alport syndrome without biopsy? Pediatr Nephrol. 2007 
May;22(5):621-5. 
[5] 
Gubler M, Levy M, Broyer M, Naizot C, Gonzales G, Perrin D et al. Alport's syndrome. 
A report of 58 cases and a review of the literature. Am J Med. 1981 Mar;70(3):493-505. 
[6] 
Rosado C, Bueno E, Fraile P, García-Cosmes P, González-Sarmiento r. A new mutation 
in the COL4A3 gene responsible for autosomal dominant Alport syndrome, which only 
generates hearing loss in some carriers. Eur J Med Genet. 2015 Jan;58(1):35-8. 
[7] 
Hanson H, Storey H, Pagan J, Flinter F. The value of clinical criteria in identifying 
patients with X-linked Alport syndrome. Clin J Am Soc Nephrol. 2011 Jan;6(1):198-
203. 
[8] 
Cosgrove D, Samuelson G, Meehan DT, Miller C, McGee J, Walsh EJ, et al. 
Ultrastructural, physiological, and molecular defects in the inner ear of a gene-knockout 
mouse model for autosomal Alport syndrome. Hear Res 1998; 121: 84-98. 
[9] 
Harvey SJ, Mount R, Sado Y, Naito I, Ninomiya Y, Harrison R, et al. The inner ear of 
dogs with X-linked nephritis provides clues to the pathogenesis of hearing loss in X-
linked Alport syndrome. Am J Pathol 2001; 159(3): 1097-104. 
[10] Alves FR, de A Quintanilha Ribeiro F. Revision about hearing loss in the Alport's 
syndrome, analyzing the clinical, genetic and bio-molecular aspects. Braz J 
Otorhinolaryngol. 2005 Nov-Dec;71(6):813-9. 
[11] Rintelmann FW. Auditory manifestations of Alport’s disease syndrome. Tr Am Acad 
Ophth Otol 1976; 82: 375-87. 
[12] Balduini CL, Pecci A, Savoia A. Recent advances in the understanding and 
management of MYH9-related inherited thrombocytopenias. Br J Haematol. 2011 
Jul;154(2):161-74. 
[13] Sekine T, Konno M, Sasaki S, Moritani S, Miura T, Wong WS, Nishio H, Nishiguchi T, 
Ohuchi MY, Tsuchiya S, Matsuyama T, Kanegane H, Ida K, Miura K, Harita Y, Hattori 
M, Horita S, Igarashi T, Saito H, Kunishima S. Patients with Epstein-Fechtner 
syndromes owing to MYH9 R702 mutations develop progressive proteinuric renal 
disease. Kidney Int. 2010 Jul;78(2):207-14. 

Genetic Kidney Diseases with Sensorineural Hearing Loss 
 
633
[14] Han KH, Lee H, Kang HG, Moon KC, Lee JH, Park YS, Ha IS, Ahn HS, Choi Y, 
Cheong HI. Renal manifestations of patients with MYH9-related disorders. Pediatr 
Nephrol. 2011 Apr;26(4):549-55. 
[15] Dong F, Li S, Pujol-Moix N, Luban NL, Shin SW, Seo JH, Ruiz-Saez A, Demeter J, 
Langdon S, Kelley MJ. Genotype-phenotype correlation in MYH9-related 
thrombocytopenia. Br J Haematol. 2005 Aug;130 (4):620-7. 
[16] Makino S, Kunishima S, Ikumi A, Awaguni H, Shinozuka J, Tanaka S, Maruyama R, 
Imashuku S. Sporadic Epstein syndrome with macrothrombocytopenia, sensorineural 
hearing loss and renal failure. Pediatr Int. 2015 Oct;57(5):977-81. 
[17] Pecci A, Verver EJ, Schlegel N, Canzi P, Boccio CM, Platokouki H, Krause E, Benazzo 
M, Topsakal V, Greinacher A. Cochlear implantation is safe and effective in patients 
with MYH9-related disease. Orphanet J Rare Dis. 2014 Jun 30;9:100. 
[18] Jamaldeen J, Basheer A, Sarma AC, Kandasamy R. Prevalence and patterns of hearing 
loss among chronic kidney disease patients undergoing haemodialysis. Australas Med 
J. 2015 Feb 28;8(2):41-6. 
 
 
 


In: Encyclopedia of Audiology and Hearing Research 
ISBN: 978-1-53617-702-2 
Editors: Erno Larivaara and Senja Korhola 
© 2020 Nova Science Publishers, Inc. 
 
 
 
 
 
 
 
Chapter 43 
 
 
 
STEPWISE APPROACH TO THE DIAGNOSIS OF 
HEARING LOSS IN CHILDREN 
 
 
C. Aimoni, V. Corazzi, V. Conz, C. Bianchini  
and A. Ciorba  
ENT & Audiology Department, University Hospital of Ferrara, Italy 
 
 
ABSTRACT 
 
Hearing loss in children can be congenital or acquired. It can be classified in 
prenatal, perinatal and postnatal, considering the time of occurrence, and it can be 
transitory or permanent. The worldwide estimated prevalence of hearing loss is 1/1000 
for children without risk factors for hearing disease, 2-3/100 for those with risk factors. 
The prevalence of prelingual hearing loss in Italy is reported in 0.7/1000 within the 
Italian population [1]. 
The early detection of hearing loss, as well as the early appropriate intervention, is 
critical for a proper language, relational and cognitive development. Therefore, Universal 
Neonatal Hearing Screening (UNHS) programs have been developed with the intention 
of detecting neonatal hearing loss. UNHS consists in testing TEOAEs (transient evoked 
otoacoustic emissions) eventually followed by ABR (Auditory Brainstem Response), 
when the registration of TEOAEs fails or when there are risk factors for hearing loss. 
Nevertheless, not all forms of hearing loss can be identified through UNHS: children with 
a late onset or a progressive hearing loss can have a delayed diagnosis due to the initial 
negative result at the UNHS. Therefore, it has been recommended to consider with 
particular attention all these children and to establish a tight audiological follow up since 
the first year of life. A careful diagnostic work-up of hearing loss is necessary in order to 
establish the etiological classification and, thus, the most appropriate treatment. This 
multidisciplinary and stepwise approach can involve audiologists, otolaryngologists, 
pediatricians, geneticists, ophthalmologists, maxillofacial surgeons, neurologists, 
radiologists [2]. History taking and physical exam are the first steps in the assessment of 
hearing disorders in children. Audiometric tests are fundamental to evaluate the type and 
the degree of the hearing loss. Also genetic and radiologic evaluations are always 
recommended for a better assessment of hearing loss. Finally, laboratory and serological 
                                                        
 Corresponding Author’s Email: andrea.ciorba@unife.it. 

C. Aimoni, V. Corazzi, V. Conz et al. 
 
636
tests as well as electrocardiogram, ophthalmologic evaluation, kidney and thyroid 
ultrasound and function tests could give important information in order to exclude 
infections or syndromes associated to hearing dysfunction [3]. 
 
 
INTRODUCTION 
 
Hearing loss in children can be congenital or acquired. It can be classified in prenatal, 
perinatal and postnatal, considering the time of occurrence, and it can be transitory or 
permanent. There are many possible causes of hearing loss in children, even if sometimes the 
etiology remains unknown. It is always important to recognize as soon as possible the 
presence of hearing impairment in children, in order to ensure the best possibilities to correct 
the hearing function and, thus, to allow the develop of the best communicative, relational, 
linguistic and cognitive performances. 
Aim of this chapter is to describe the stepwise approach to the diagnosis of hearing loss 
in children in order to establish, when possible, the etiology of hearing loss and, also, the 
most appropriate treatment. 
 
 
EPIDEMIOLOGY AND ETIOPATHOGENESIS 
 
The worldwide prevalence of hearing loss in children is estimated in 1/1000 among 
children without risk factors, and 2-3/100 within children with risk factors for hearing loss. 
The prevalence of prelingual hearing loss in Italy is reported in 0.7/1000 [1]. 
There are many possible causes of hearing loss in children, and these can be congenital or 
acquired. Hearing loss can be classified in prenatal, perinatal and postnatal, considering the 
time of occurrence, and it can be transitory or permanent. 
In 2007, the Joint Committee on Infant Hearing indicated the risk factors associated with 
permanent, congenital, delayed-onset or progressive sensorineural hearing loss (SNHL) in 
children [4]. In particular, a positive familiar history of hearing loss is an undeniable risk 
factor for both prenatal and postnatal hearing impairment. Infants admitted to the Neonatal 
Intensive Care Unit (NICU) for more than 5 days or underwent an exchange transfusion for 
hyperbilirubinemia (in any case when total serum bilirubin is >25 mg/dL, or when it is above 
the exchange level, differently calculated depending on the hyperbilirubinemia risk factors 
and the hours/days of life of children [5]) or an assisted mechanical ventilation or an Extra 
Corporeal Membrane Oxygenation are considered at risk for a SNHL until the first years of 
life [6]. Among congenital hearing loss in children, about 40% is genetic and the transmission 
modalities can be autosomal recessive, autosomal dominant, X-linked or mitochondrial. To 
date, more than 120 genes linked to hearing loss have been identified. In the 70% of genetic 
forms, hearing loss is isolated; in the remaining 30%, it can be associated to other 
malformations (i.e., cardiac, cerebral, ocular), configuring a syndromic form [7, 8, 9, 10]. 
In children, more than 50% of non-syndromic autosomal recessive SNHL and about 40% 
of sporadic cases are linked to a characteristic mutation of connexin 26 (Cx26 or GJB2) gene. 
These congenital hearing loss can be evident at birth, even if some cases may not be revealed 
until the first years of life, because of a late-onset [7, 8, 9, 11]. 

Stepwise Approach to the Diagnosis of Hearing Loss in Children 
 
637
To date, more than 400 syndromes associated to hearing disorders have been identified. 
The most frequent are: Usher syndrome (a progressive SNHL associated to retinitis 
pigmentosa), Waardenburg syndrome (moderate-profound SNHL associated to dystopia 
cantorum and a typical dyschromia of skin, hair and eyes), Pendred syndrome (frequently pre-
lingual progressive SNHL associated occasionally to goiter and to enlarged vestibular 
aqueduct and cochlear dysplasia). Also some craniofacial malformative syndromes (i.e., 
Goldenhar syndrome, Franceschetti syndrome, Apert syndrome) can lead to conductive or 
mixed hearing loss. 
Prenatal forms of hearing loss can also be related to gestational infections, such as 
toxoplasma, rubella, herpes, HIV. Among infectious diseases, cytomegalovirus infection is 
most frequently responsible of neonatal SNHL and can also be responsible of delayed onset 
of SNHL (25% of hearing loss in children before 4 years of age) [7]. 
Ototoxicity (i.e., chemotherapics, aminoglycosides) can also be responsible of prenatal 
hearing loss, as well as maternal metabolic diseases (i.e diabetes mellitus, renal or liver 
failure) or alcoholic/drug abuse [12]. 
Perinatal cases include hypoxia occurred during a difficult labour and jaundice [7, 12, 
13]. 
Acquired postnatal forms of hearing loss can be due to meningitis, viral infections (i.e., 
mumps, measles, cytomegalovirus), noise exposure or cranial traumas [12, 14]. 
Finally, conductive hearing loss (CHL) represents another chapter of hearing disorders in 
children. The most common form of transitory acquired CHL is recurring or persistent otitis 
media, responsible of about 75% of cases [15]. Less frequently, congenital middle ear 
anomalies (such as ossicular malformations or oval window absence) or congenital 
cholesteatoma can lead to a persistent CHL [16]. 
 
 
DIAGNOSIS 
 
Universal Neonatal Hearing Screening 
 
The UNHS is a crucial instrument for the early detection of hearing impairment. It 
consists of TEOAEs testing in all newborns, followed by automated ABR (AABR), when the 
registration of otoacoustic emissions fails or when there are risk factors for hearing loss. 
These measurements are performed through noninvasive techniques and allow to identify the 
physiological cochlear activity nor moderate-severe degrees of hearing loss. UNHS should be 
performed within 1 month of life [3, 4]. 
Children who do not pass TEOAEs nor the AABR, should be referred to an audiologist 
for a proper audiological assessment; children who pass UNHS but have at least one risk 
factor for hearing loss, should be referred to an audiologist, too, for periodic hearing 
assessment until the age of 3 years in order to evaluate with certainty a stable normal hearing 
threshold and auditory and language milestones [4]. 
Nonetheless, hearing loss of delayed onset, nor progressive hearing loss, cannot be 
identified by UNHS. For this reason, it has been recommended to evaluate with particular 
attention also all children with risk factors for hearing loss, establishing a tight audiological 
follow-up within the first years of life. It is imperative to recognize these cases as early as 
possible, in order to ensure the best possibilities to correct the hearing function properly [4]. 

C. Aimoni, V. Corazzi, V. Conz et al. 
 
638
Audiological Evaluation 
 
An accurate history taking (particularly focusing on familiar hearing loss, risk factors, 
comorbidities) and the otoscopic inspection are the first steps in the assessment of hearing 
impairment in children. 
The Joint Committee on Infant Hearing [4] states that children who fail screening and re-
screening, should be evaluated by an audiologist in order to perform an air or, when indicated, 
bone-conducted ABR in order to assess the hearing threshold level. In fact, during infancy, 
electrophysiological techniques are considered the gold standard for auditory threshold 
measurement: ABR in order to assess hearing level at high frequencies, ASSR (auditory 
steady state response) at low-mid frequencies [3, 17]. Tympanometry should always be 
performed in order to evaluate the tympanic membrane and middle ear impedance, and also 
the acoustic reflex threshold should be determined [3]. 
In the early childhood, the audiological evaluation must be individualized and set 
depending on the age and the level of collaboration of the little patient. Starting from 6-8 
months of age, other audiological tests can be performed such as behavioral audiometry, 
visual reinforcement or conditioned-play audiometry. Peep-show can be used from the age of 
3-4 years. Conventional and vocal audiometry can be performed with a sufficient degree of 
reliability starting from the 5th-6th year [4]. 
During the audiological evaluation of children, it is also important to assess the 
perceptive abilities and speech and linguistic milestones. Also with the help of a speech 
therapist, it is necessary to evaluate the language acquisition, nor the transition from the 
prelinguistic to linguistic communication as well as the vocabulary expansion, especially in 
children with hearing aids in order to ensure the best speech and language development [3, 4, 
18]. 
 
 
Infectious Disease Assessment 
 
A difficult diagnostic challenge is represented by congenital infections, related to 
gestational or perinatal transmission. In particular, cytomegalovirus (CMV) infection is one 
of the most frequent causes of neonatal SNHL, and it is responsible for about 25% of hearing 
loss (mono or bilateral) within the first 4 years of life [7, 19]. Considering the heterogeneity 
of CMV infection, a careful audiological follow-up is recommended. In case of suspected 
CMV infection, a PCR blood search of CMV DNA on Guthrie card nor a urine search of 
CMV DNA, has been recommended within the first two weeks of life, in order to 
discriminate a prenatal from a perinatal/postnatal infection [20, 21, 22]. The diagnosis of 
congenital CMV is to be determined no later than the 1st month of life, in order to provide the 
adequate treatment [23]. Although a CMV vaccine is yet under study in order to reduce the 
maternal infection during pregnancy, the recommended treatment for infected symptomatic 
children is represented by antiviral therapy (6 weeks intravenous ganciclovir or 6 months oral 
valganciclovir): recent data in literature show a reduction of hearing and neurodevelopmental 
sequelae after this treatment [22, 24]. 
The onset of postnatal acquired infectious disease (such as Haemophilus influenza type b, 
mumps, measles, rubella), and therefore of related hearing loss, has been reduced due to the 
introduction of conjugate vaccines. 

Stepwise Approach to the Diagnosis of Hearing Loss in Children 
 
639
Neuroimaging 
 
Imaging procedures are essential in order to identify possible structural abnormalities of 
the temporal bone and, in particular, malformations of the middle and/or inner ear [25]. 
Pendred syndrome is a typical example in which neuroimaging has a prevalent role in the 
diagnostic work-up. This autosomal recessive syndrome, responsible of about 7.5% of 
hearing loss in children [26], is caused by a SLC26A4 mutation (encoding for pendrin 
protein, a transmembrane anion transporter) [27]. It is characterized by congenital or short 
onset and typically fluctuating and progressive SNHL, more frequently of the high 
frequencies and often with a conductive quota associated, and sometimes by thyroid 
pathologies [28]. A pathognomonic element of this syndrome, although not exclusive, present 
in about 80% of cases, is the enlargement of the vestibular aqueduct (EVA), sometimes 
associated to a Mondini cochlear displasia [29].  
Radiologic assessment, in particular temporal bone CT, is particular necessary in case of 
cranial trauma; it has been reported that a temporal bone fracture could represent a potential 
cause of conductive, sensorineural or mixed hearing loss in about 23-64% of cases [14, 30]. 
Also, CT scans are essential in view of surgical interventions, for example before a 
cochlear implant or a cholesteatoma surgery [31, 32]. During the last decade, also Cone Beam 
CT (CBCT) has been proposed to study the temporal bone and the middle ear [33]. 
Neuroimaging is indispensable in all children with CHL associated to a normal otoscopy 
and in absence of other risk factors: only a radiologic assessment could highlight, for 
example, congenital minor ossicular malformations [16]. 
A magnetic resonance imaging (MRI) of brain, central auditory system, brainstem and 
pontocerebellar angle and inner ear is also recommended in all children with permanent 
hearing loss. It can allow a detailed study of the 8th nerve and the inner ear, particularly of the 
membranous cochlea, the vestibular system and semicircular canals [34]. MRI is important 
especially for those children showing auditory neuropathy or dyssynchrony [35]. 
 
 
Genetic Assessment 
 
There are numerous types of genetic based hearing loss, syndromic or not. More than 400 
syndromes associated to hearing disorders have been described so far; nonetheless genetic 
forms of hearing loss can be monogenic diseases, caused by little mutations in specific genes. 
In the last 30 years, there has been a rapid advancement of genetics and of DNA analysis 
techniques. Therefore considering the clinical features of little patients, the geneticists should 
choose the most suitable genetic tests case by case. For this reason, the collaboration between 
the audiologist and the geneticist is extremely important when approaching the diagnosis of 
hearing loss in children [7, 9]. 
Mutations of GJB2 (gap junction beta-2) gene, encoding for connexin 26, is responsible 
for more than 50% of non-syndromic autosomal recessive SNHL in children and about for 
40% of sporadic cases [2, 11]. The investigation for these mutations and also for those on 
GJB6 (encoding for connexin 30) has become an essential part of the diagnostic work-up of 
hearing loss in children [8, 9, 36]. Frequently, these genetic forms are associated to severe or 
profound hearing loss, but the same mutation can lead to a large range of phenotypes and, 

C. Aimoni, V. Corazzi, V. Conz et al. 
 
640
therefore, to a various hearing thresholds (from mild to profound) [37, 38]. Moreover, hearing 
loss can be progressive and not necessarily present at birth [39]. 
When hearing loss is syndromic, an accurate physical exam is important in order to 
recognize pathognomonic characteristics that could suggest a specific diagnosis. A 
comprehensive head and neck inspection is recommended and, in particular, the attention 
should be focused on possible craniofacial dysmorphic features (i.e., external ear, neck and 
fingers abnormalities, irises, hair or skin chromatic alterations, anomalous eyes distance) [4, 
40]. 
A kidney ultrasound and function tests are always recommended in the hearing loss 
evaluation in children and, in particular, when BOR (brachio-oto-renal) syndrome, HDR 
syndrome (hypoparathyroidism, sensorineural deafness and renal disease) or Alport syndrome 
are suspected [40]. 
 
 
Other Specific Evaluations 
 
An ophthalmologic evaluation to assess the visual abilities eventually with funduscopic 
examination and an electroretinogram, should be performed, in particular to exclude possible 
retinopathies, as many syndromes with hearing loss are associated to ophthalmologic diseases 
and vision problems [40]. 
Also, laboratory analysis (in order to evaluate ovarian function and metabolic function), 
serological tests, as well as electrocardiogram, kidney and thyroid ultrasound and function 
tests should be performed as integral part of the diagnostic work-up of hearing loss in 
children [40, 41]: these could give important information in order to exclude viral infections, 
metabolic disorders or other syndromes associated to hearing dysfunction. 
 
 
CONCLUSION 
 
A stepwise approach to the diagnosis of hearing loss in children involves not just the 
audiologist and otolaryngologists, but also several other figures such as, pediatricians, 
geneticists, ophthalmologists, maxillofacial surgeons, neurologists, radiologists, parents, 
teachers, In order to improve the early diagnosis of hearing loss in children it is necessary (i) 
not only to implement UNHS programs [42], (ii) but also to promote the early identification 
of late onset and progressive hearing loss forms, even if mild, which UNHS does not 
recognized. Thus, an attentive and continuous surveillance of children with peculiar risk 
factors for hearing loss has been recommended [3, 4]: little patients with unilateral or mild 
hearing loss deserve a careful attention, as well as children with bilateral profound SNHL. In 
fact, if not properly identified and treated, also those children with mild-moderate hearing 
loss show the same risks in language developing as well as in lowering their social and 
scholastic performances [43]. 
It is mandatory to assure always the earliest possible intervention when facing hearing 
loss in childhood; hearing rehabilitation and, when necessary, speech therapy intervention 
should be set as soon as possible in order to allow the develop of adequate speech, language, 
cognitive and behavioral abilities [4]. 

Stepwise Approach to the Diagnosis of Hearing Loss in Children 
 
641
REFERENCES 
 
[1] 
Bubbico, L; Rosano, A; Spagnolo, A. Prevalence of prelingual deafness in Italy. Acta 
Otorhinolaryngol Ital, 2007;27:17-21. 
[2] 
Hart, CK; Choo, DI. What is the optimal workup for a child with bilateral sensorineural 
hearing loss? The Laryngoscope, 2013;123(4):809-810. 
[3] 
Harlor, AD Jr; Bower, C; Committee on Practice and Ambulatory Medicine; Section 
on Otolaryngology-Head and Neck Surgery. Hearing assessment in infants and 
children: recommendations beyond neonatal screening. Pediatrics, 2009;124(4):1252-
63. 
[4] 
American Academy of Pediatrics; Joint Committee on Infant Hearing. Year 2007 
position statement: Principles and guidelines for early hearing detection and 
intervention programs. Pediatrics, 2007;120:898-921. 
[5] 
American Academy of Pediatrics Subcommittee on Hyperbilirubinemia. Management 
of hyperbilirubinemia in the newborn infant 35 or more weeks of gestation. Pediatrics, 
2004;114(1):297-316. 
[6] 
Robertson, CM; Howarth, TM; Bork, DL; Dinu, IA. Permanent bilateral sensory and 
neural hearing loss of children after neonatal intensive care because of extreme 
prematurity: a thirty-year study. Pediatrics, 2009;123:e797-807. 
[7] 
Morton, CC; Nance, WE. Newborn hearing screening – a silent revolution. N Engl J 
Med, 2006;354:2151-64. 
[8] 
Jiang, H; Chen, J; Shan, XJ; Li, Y; He, JG; Yang, BB. Prevalence and range of GJB2 
and SLC26A4 mutations in patients with autosomal recessive non-syndromic hearing 
loss. Mol Med Rep, 2014;10(1):379-86. 
[9] 
Nance, WE. The genetics of deafness. Ment Retard Dev Disabil Rev, 2003;9(2):109-19. 
[10] Vona, B; Nanda, I; Hofrichter, MA; Shehata-Dieler, W; Haaf, T. Non-syndromic 
hearing loss gene identification: A brief history and glimpse into the future. Mol Cell 
Probes, 2015;29(5):260-70. 
[11] Smith, RJ; Bale, JF Jr; White, KR. Sensorineural hearing loss in children. Lancet, 
2005;365(9462):879-90. 
[12] Kenna, MA. Acquired Hearing Loss in Children. Otolaryngol Clin North Am, 
2015;48(6):933-53. 
[13] Akinpelu, OV; Waissbluth, S; Daniel, SJ. Auditory risk of hyperbilirubinemia in term 
newborns: a systematic review. Int J Pediatr Otorhinolaryngol,2013;77:898-905. 
[14] Schell, A; Kitsko, D. Audiometric Outcomes in Pediatric Temporal Bone Trauma. 
Otolaryngol Head Neck Surg, 2016;154(1):175-80. 
[15] William, CJ; Jacobs, AM. The impact of otitis media on cognitive and educational 
outcomes. Med J Aust, 2009;191(9):S69-72. 
[16] Dougherty, W; Kesser, BW. Management of Conductive Hearing Loss in Children. 
Otolaryngol Clin North Am, 2015;48(6):955-74. 
[17] Chou, YF; Chen, PR; Yu, SH; Wen, YH; Wu, HP. Using multi-stimulus auditory 
steady state response to predict hearing thresholds in high-risk infants. Eur Arch 
Otorhinolaryngol, 2012;269(1):73-9. 

C. Aimoni, V. Corazzi, V. Conz et al. 
 
642
[18] Ben-Itzhak, D; Greenstein, T; Kishon-Rabin, L. Parent report of the development of 
auditory skills in infants and toddlers who use hearing aids. Ear and Hearing, 
2014;35:e262-71. 
[19] Dahle, AJ; Fowler, KB; Wright, JS; Boppana, SB; Britt, WJ; Pass, RF. Longitudinal 
investigation of hearing disorders in children with congenital cytomegalovirus. J Am 
Acad Audiol, 2000;11:283-90. 
[20] Ross, SA; Ahmed, A; Palmer, AL; Michaels, MG; Sanchez, PJ; Stewart, A; Bernstein, 
DI; Feja, K; Novak, Z; Fowler, KB; Boppana, SB; National Institute on Deafness and 
Other Communication Disorders CHIMES Study. Urine collection method for the 
diagnosis of congenital Cytomegalovirus infection. Pediatr Infect Dis J, 
2015:34(8):903-5. 
[21] Boudewyns, A; Declau, F; Smets, K; Ursi, D; Eyskens, F; Van den Ende, J; Van 
deHeyning, P. Cytomegalovirus DNA detection in Guthrie cards: role in the diagnostic 
work-up of childhood hearing loss. Otol Neurotol, 2009;30(7):943-9. 
[22] Harrison GJ. Current controversies in diagnosis, management, and prevention of 
congenital cytomegalovirus: updates for the pediatric practitioner. Pediatr Ann, 
2015;44(5):e115-25. 
[23] Mareri, A; Lasorella, S; Anti-viral therapy for congenital cytomegalovirus infection: 
pharmacokinetics, efficacy and side effects. J Matern Fetal Neonatal Med, 2012;29:1-
8. 
[24] James, SH; Kimberlin, DW. Advances in the prevention and treatment of congenital 
cytomegalovirus infection. Curr Opin Pediatr, 2016;28(1):81-5. 
[25] Huang, BY; Zdanski, C; Castillo, M. Pediatric sensorineural hearing loss, part 2: 
syndromic and acquired causes. AJNR Am Journal Neuroradiol, 2012;33:399-406. 
[26] Roesch, S; Moser, G; Rasp, G; Toth, M. CT-scans of cochlear implant patient with 
characteristics of Pendred syndrome. Cell Physiol Biochem, 2013;34:1257-63. 
[27] Royaux, IE; Wall, SM; Karniski, LP; Everett, LA; Suzuki, K; Knepper, MA; Green, 
ED. Pendrin, encoded by the Pendred syndrome gene, resides in the apical region of 
renal intercalated cells and mediates bicarbonate secretion. Proc Natl Acad Sci U S A, 
2001;98(7):4221-6. 
[28] Luxon, LM; Cohen, M; Coffey, RA; Phelps, PD; Britton, KE; Jan, H; Trembath, RC; 
Reardon, W. Neuro-otological findings in Pendred syndrome. Int J Audiol, 
2003;42(2):82-8. 
[29] Reardon, W; Omahoney, CF; Trembath, R; Jan, H; Phelps, PD. Enlarged vestibular 
aqueduct: a radiological marker of Pendred syndrome, and mutation of the PDS gene. 
QJM, 2000;93(2):99-104. 
[30] Dunklebarger, J; Branstetter, B; Lincoln, A; Sippey, M; Cohen, M; Gaines, B; Chi, D. 
Pediatric temporal bone fractures: current trends and comparison of classification 
schemes. Laryngoscope, 2014;124:781-4. 
[31] Vaid, S; Vaid, N. Imaging for cochlear implantation: structuring a clinically relevant 
report. Clinical Radiology, 2014;69:e307-e322. 
[32] Barath, K; Huber, AM; Stampfli, P; Varga, Z; Kollias, S. Neuroradiology of 
cholesteatomas. AJNR Am J Neuroradiol, 2011;32:22-9. 
[33] Hodez, C; Griffaton-Taillandier, C, Bensimon, I. Cone-beam imaging: applications in 
ENT. Eur Ann Otorhinolaryngol Head Neck Dis, 2011;28:65-78. 

Stepwise Approach to the Diagnosis of Hearing Loss in Children 
 
643
[34] Huang, BY; Zdanski, C; Castillo, M. Pediatric sensorineural hearing loss, part 1: 
practical aspects for neuroradiologists. AJNR Am Journal Neuroradiol, 2012;33:211-7. 
[35] Buchman, CA; Roush, PA; Teagle, HF; Brown, CJ; Zdanski, CJ; Grose, JH. Auditory 
neuropathy characteristic in children with cochlear nerve deficiency. Ear Hear, 
2006;27:399-408. 
[36] Petersen, MB; Willems, PJ. Non-syndromic, autosomal-recessive deafness. Clin Genet, 
2006;69(5):371-92. 
[37] Denoyelle, F; Marlin, S; Weil, D; Moatti, L; Chauvin, P; Garabédian, EN; Petit, C. 
Clinical features of prevalent form of childhood deafness, DFNB1, due to a connexin-
26 gene defect: implications for genetic counselling. Lancet, 1999;353(9161):1298-
303. 
[38] Cohn, ES; Kelley, PM. Clinical phenotype and mutations in connexin 26 
(DFNB1/GJB2), the most common cause of childhood hearing loss. Am J Med Genet, 
1999;89:130-6. 
[39] Denoyelle, F; Lina-Granade, G; Plauchu, H; Bruzzone, R; Chaib, H; Lévi-Acobas, F; 
Weil, D; Petit, C. Connexin 26 gene linked to a dominant deafness. Nature, 
1998;393(6683):319-20. 
[40] Bitner-Glindzicz, M. Hereditary deafness and phenotyping in humans. Br Med Bull, 
2002;63:73-94. 
[41] Sanecka, A; Biernacka, EK; Szperl, M; Sosna, M; Mueller-Malesinska, M; Kozicka, U; 
Baranowski, R; Kosiec, A; Lazarczyk, H; Skarzynski, H; Hoffman, P; Bieganowska, 
K; Piotrowicz, R. QTc prolongation in patients with hearing loss: Electrocardiographic 
and genetic study. Cardiol J, 2016:23(1):34-41. 
[42] Sloot, F; Hoeve, HL; de Kroon, ML; Goedegebure, A; Carlton, J; Griffiths, HJ; 
Simonsz, HJ; EUS€REEN Study Group. Inventory of current EU paediatric vision and 
hearing screening programmes. J Med Screen, 2015;22(2):55-64. 
[43] Vohr, B; Topol, D; Girard, N; St Pierre, L; Watson, V; Tucker, R. Language outcomes 
and service provision of preschool children with congenital hearing loss. Early Hum 
Dev, 2012;88(7):493-8. 
 
 


In: Encyclopedia of Audiology and Hearing Research 
ISBN: 978-1-53617-702-2 
Editors: Erno Larivaara and Senja Korhola 
© 2020 Nova Science Publishers, Inc. 
 
 
 
 
 
 
 
Chapter 44 
 
 
 
HEARING LOSS AFTER TRAUMATIC CONDITIONS: 
HISTOPATHOLOGY AND CLINICAL FEATURES 
 
 
Henrique Furlan Pauna, Raquel Andrade Lauria,  
Thiago Messias Zago, Alexandre Caixeta Guimarães  
and Guilherme Machado de Carvalho 
Department of Otorhinolaryngology, Head and Neck Surgery, University of Campinas - 
UNICAMP, Campinas, SP, Brazil 
 
 
ABSTRACT 
 
The human ear is the most susceptible organ to damage from the changes in pressure 
caused by a blast wave. The sensory hair cells are the primary target of noise trauma. 
Many are the symptoms that patients exposed to blasts have developed such as dizziness, 
clumsiness, imbalance and vertigo and have been associated with traumatic brain injury.  
The auditory impairment is also reported in association to the blast injury. The 
peripheral auditory dysfunction is associated with traumatic brain injury due to the blast 
exposure and also increases the vulnerability of the central auditory pathways in the 
central nervous system to blast-induced injury. Previous studies have shown that deafness 
is observed when the loss of outer and inner hair cells, physical rupturing of cochlear 
structural membranes, and swelling and degeneration of the spiral ganglion neurons.  
Many activities involving changes in atmospheric pressure are becoming common: 
airplane traveling, scuba diving, or hunting are some of these activities. However, other 
professional activities may also play an important role on the pathogenesis of this kind of 
situation, as a military duty, professional scuba diving, and many others. The traumatic 
brain injury that can be followed after these situations is a neural damage in the brain 
following a closed-head or open-head injury. Many studies have shown the risk of ear 
trauma on this situations, however only few people are aware of prevention measures.  
Thus, our objective is to review the concepts of traumatic injuries of the ear, 
focusing on the epidemiology, diagnosis, and to highlight the mechanisms leading to both 
sensorineural and conductive hearing loss secondary to these circumstances.  
 
 
 

Henrique F. Pauna, Raquel A. Lauria, Thiago M. Zago et al. 
 
646
INTRODUCTION 
 
Hearing loss is the most frequent sensorial impairment in the world, specially in low and 
middle income countries. Almost 5% of the world population (360 million people) is affected 
by hearing loss [1, 2]. Hearing deficits are highly prevalent among older adults and are 
associated with declines in cognitive, physical, and mental health, especially in the geriatric 
population [3, 4]. 
Trauma situations, such as barotrauma and head trauma, can lead to temporary or 
permanent conductive or sensorineural hearing loss, which can lead to quality of life 
impairment. Hearing loss is a common functional disorder after trauma, and may be caused 
by ossicular, labyrinthine or brain lesions. In minor head trauma, a study demonstrated that 
15% of the patients complained of vertigo, 10% complained of hearing loss, and 2% 
complained of tinnitus [5]. In the USA, it is estimated that 200 in every 100,000 children 
suffer head injury, and hearing loss is reported in about 23–64% of these cases [6]. 
Head trauma may cause hearing loss, facial palsy or dizziness. Conductive hearing loss 
(Figure 1) results from a defect in the conduction of sound, which may occur as a result of 
tympanic perforation, hemotympanum, or ossicular (ie, malleus, incus, stapes) disruption. 
Sensorineural hearing loss (Figure 2) may be secondary to damage of the inner ear (acute 
cochlear concussion, perilymphatic fistula). Dizzinnes may be secondary to trauma to the 
brainstem-eighth nerve complex, the semicircular canals (labyrinthine concussion), benign 
paroxysmal positional vertigo, Meniere's syndrome with only vestibular symptoms, 
perilymphatic fistula, and cervical vertigo [7]. 
 
 
Figure 1. Pure-tone audiometry. Conductive hearing loss in the right ear. 

Hearing Loss After Traumatic Conditions 
 
647
THE EUSTACHIAN TUBE 
 
The Eustachian tube is an osseocartilaginous canal that connects the tympanic cavity 
(middle ear) with the nasopharynx. It is supported in its first two-thirds by a cartilaginous 
portion (anteromedially located) and the last third by a bone portion (posterolaterally located). 
The development of the Eustachian tube is completed with 18 years of age, with significant 
differences between adults and children. The Eustachian tube in children is shorter and 
horizontalized, with 18 mm in length and angle of 10 degrees. In adults, the Eustachian tube 
has a length between 31 and 38 mm, with 45 degrees angle with the horizontal plane [10]. 
Hearing impaiment is clearly associated with lower quality of life in individuals and their 
families and high economic impact to the society [8, 9]. 
The Eustachian tube is responsible for three functions: ventilation, drainage of secretions, 
and middle ear protection. Ventilation and consequent equalization of environmental air and 
tympanic cavity pressures is possible by intermittent tubal opening [11]. This occurs through 
the soft palate tensor muscle contraction during yawning, swallowing, or Politzer maneuver. 
This allows the proper functioning of the eardrum-ossicular system. The tube closes 
passively, due to the elasticity of fibrocartilage system, hydrostatic pressure and venous 
intraluminal mucus layer, providing middle ear protection [10]. 
 
 
Figure 2. Pure-tone audiometry. Sensorineural hearing loss in the right ear. 

Henrique F. Pauna, Raquel A. Lauria, Thiago M. Zago et al. 
 
648
Under nonphysiologic pressure changes, such as diving, ascent or descent in airplane and 
hyperbaric oxygen treatment, the function of the Eustachian tube can be compromised. In 
these situations barotrauma may occur, with resulting hearing loss due to middle ear effusion, 
hemotympanum, tympanic membrane rupture or perilymphatic fistula. 
 
 
BAROTRAUMA 
 
Barotrauma refers to tissue injury due to a pressure difference between an anatomical 
cavity filled with gas and the surrounding environment [12]. Boyle’s law relates to all forms 
of barotrauma. The rule states that the volume of a gas varies inversely with pressure if 
temperature is held constant. When it affects the ear tissues and cells can cause otalgia, 
hearing loss, tinnitus and dizziness.  
Hyperbaric oxygen treatment, scuba diving and air travel can lead to middle or inner ear 
injuries. These situations involve fast or extreme pressure changes and require an active and 
efficient mechanism for pressure equalization, often ineffective. The difference occurs due to 
failure of the Eustachian tube equalizing the middle ear pressure and the environmental 
pressure. 
Ear injuries due to barotrauma can occur in up to 20% of adult and 55% of child 
passengers in a single flight [12] and up to 91% of patients undergoing hyperbaric oxygen 
treatment [13]. Barotrauma can occur to middle and inner ear, simultaneously or separately. 
Aditionally, inner ear barotrauma is seen less frequently but is potentially more serious, and 
can be permanent and disabling. 
 
 
Middle Ear Barotrauma 
 
This condition is by far the most common barotraumatic otologic injury and occurs on 
descent (diving or flight) when the Eustachian tube does not allow air to enter the middle ear. 
In these cases, negative pressure in the middle ear can lead to an ex-vacuum mechanism and 
transudate. High pressure differences may rupture blood vessels, leading to hemorrhagic 
effusion and hemotympanum. In contrast, expanding air in the middle ear during ascent 
passively opens the Eustachian tube. 
When damage is confined in the middle ear, the symptoms such as otalgia, fullness and 
hearing loss, usually has spontaneous remission with no sequelae in weeks. Clinical signs 
include tympanic membrane congestion and hemorrhage, hemorrhage or effusion in the 
middle ear. Audiometry may exhibit conductive hearing loss. The postmortem 
histopathologic findings can show rupture of the tympanic membrane, and blood in the 
middle ear space (Figure 3). Treatment of the middle ear barotrauma is generally 
symptomatic. 

Hearing Loss After Traumatic Conditions 
 
649
 
Figure 3. Example of an incudomalelar dislocation after head trauma. Observe pieces of the tympanic 
bone within the epitympanic space, while there is a gap between the malleus and incus, and the origin 
of the fragments (arrow heads; H&E, 1x magnification). An = antrum; BB = Bill’s bar; FN = facial 
nerve; HSCC = horizontal semicircular canal; I = incus; IAC = internal acoustic canal; M = malleus; V 
= vestibule. 
 
Inner Ear Barotrauma 
 
Inner ear barotrauma is a less common but potentially more serious situation. When 
damage affects inner ear, hearing loss, dizziness and tinnitus can be experienced, in different 
levels. Becker and Parell [14] hypothesized that three mechanisms are involved of injury to 
the inner ear structures: hemorrhage, labyrinthine membrane tear, and perilymph fistula 
through the round or oval window. Injury is produced by transmission of pressure changes 
within the middle ear to the cochlea by the round and oval window. Then, inner ear 
barotrauma results from injudicious equalization of middle ear pressure [14].  
Parell et al. [15] studied 20 patients who suffered inner ear barotrauma. As initial 
symptoms most of the patients complained of vertigo, tinnitus, a sense of fullness, nausea and 
dizziness, and sensorineural hearing loss also found ranged from mild to profound in all 
cases, however with partial to complete recovery for all cases. Otoscopic evaluation may 
reveal middle ear barotrauma and confuse the physician. To differentiate between middle ear 
barotrauma to inner ear barotrauma, serial audiometry studies of bone and air are mandatory 
for those patients. 
Treatment of inner ear barotrauma consists of bed rest (7 to 10 days), noseblowing is 
proscribed, sneezing is done through an open mouth, and avoiding strenous activity for 6 
weeks. To minimize a Valsalva effect during bowel movements, the use of a laxative is 
recommended. Oral steroids are also helpful, starting with prednisone therapy at a dosage of 
60 mg/day and tapering this therapy to zero within 2 weeks [14]. In patients who have either 

Henrique F. Pauna, Raquel A. Lauria, Thiago M. Zago et al. 
 
650
continued deteroration of hearing or newly acquired vertigo, the diagnosis of perilymph 
fistula must be considered and a middle ear exploration is advised. 
 
 
HEAD TRAUMA AND TEMPORAL BONE FRACTURE 
 
Head trauma is a common injury in motor vehicle accidents and can cause skull fracture. 
Of all the patients with skull fractures, 14-22% have temporal bone fracture associated [16]. 
The most common causes of temporal bone fractures include traffic accidents (45%), falls 
(31%), and assaults (11%) [17], predominantly in males (76.6%) [18]. 
Clinical presentation includes conductive hearing loss (65.8%), bloody otorrhea (61.2%) 
(Figure 4), hemotympanum (58.5%), tympanic membrane perforation (25.6%), facial nerve 
palsy (12.3%), cerebrospinal fluid otorrhea (8.5%), and sensorineural hearing loss (5.4%) 
[18].  
Temporal bone fractures can be classified as longitudinal (Figure 5A), when the main 
component is parallel to the long axis of the petrous pyramid, or transverse (Figure 5B), when 
it is perpendicular to the long axis [19], but we can also observe them at the same time 
(Figure 5C). Longitudinal fracture is the most common (80%) as a result of temporoparietal 
trauma, while transverse fractures are mainly caused by occipital or frontal trauma. 
Temporal bone fracture, especially longitudinal type [19], can lead to conductive hearing 
loss. It can be caused by tympanic membrane perforation, hemotympanum and interruption of 
the ossicular chain. The majority of patients with conductive hearing loss recover 
spontaneously [16]. 
 
 
Figure 4. Histological section of a right ear after head trauma (car accident). Observe the fracture lines 
within the middle ear space (arrowheads) and the presence of hemorrhage in the middle ear space 
(H&E, 1x magnification). GG = genniculate ganglion; H = hemorrhage; I = incus; M = malleus; ME = 
middle ear; SSCC = superior semicurcular canal; TTM = tensor tympani muscle. 
 

Hearing Loss After Traumatic Conditions 
 
651
A perforation in the tympanic membrane reduces its vibration. The hearing impairment 
caused depends on the size of the tympanic membrane perforation, its location and the size of 
the middle ear cavity. When the perforation is placed in the posterior or superior portion of 
the tympanic membrane, the largest effect occurs. A large perforation in the tympanic 
membrane in humans commonly results in a 40–50 dB hearing loss [20]. 
After temporal bone trauma blood often fills the middle ear cavity. The sound transferred 
to the fluid exerts almost the same pressure on round and oval windows and affects sound 
conduction. Audiometry shows an average hearing loss of approximately 30 dB with nearly 
normal bone conduction thresholds (air-bone gap). Tympanometry can be flat because the 
acoustic impedance of the ear does not change despite the change in air pressure in the 
external auditory canal. Furthermore, the response of the acoustic middle ear reflex cannot be 
measured [20].  
 
 
Figure 5. Axial computed tomography of the right ear of different patients. A = longitudinal fracture.  
B = Transverse fracture. C = Longitudinal (vertical arrow), and transverse fracture (horizontal arrow) 
with pneumolabyrinth (asterisk). 

Henrique F. Pauna, Raquel A. Lauria, Thiago M. Zago et al. 
 
652
When interruption of the ossicular chain occurs, conductive hearing loss may exceed 60 
dB if the tympanic membrane is intact. The bony conduction threshold is normal, 
tympanometry shows a larger than normal compliance and the acoustic reflex response cannot 
be recorded. The hearing threshold can be re-established by ossicular chain reconstruction 
surgery. The ideal prosthesis for reconstructing the ossicular chain is one that is 
biocompatible, easy to place, and stable over the long term with good sound transmission 
qualities [19].  
High-resolution CT studies may be helpful for detecting such injuries. Different types of 
dislocations of the ossicular chain can occur: incudomalleolar joint separation, 
incudostapedial joint separation, dislocation of the incus, dislocation of the malleoincudal 
complex, and stapediovestibular dislocation. The most common types are incudostapedial and 
incudomalleolar joint separations [16]. 
Fractures that cause otic capsule violation are more likely to develop sensorineural 
hearing loss. Causes of sensorineural hearing loss include labyrinth concussion, fracture of 
the labyrinth, perilymphatic fistula and brainstem injury [16]. 
 
 
CONCLUSION 
 
In summary, this chapter was focused on the epidemiology of hearing loss and traumatic 
injuries to the ear, and on the mechanisms related to these injuries to middle and inner ear 
structures as well. Early identification of a traumatic injury to the ear may lead to an adequate 
treatment and rehabilitation. 
 
 
REFERENCES 
 
[1] 
Quaranta, N., Coppola, F., Casulli, M., Barulli, M. R., Panza, F., Tortelli, R., et al. 
(2015). Epidemiology of age related hearing loss: a review. Hearing Balance Commun, 
13: 77–81.   
[2] 
Morton, C. C., Nance, W. E. (2006). Newborn hearing screening – a silent revolution. 
N Engl J Med, 354: 2151–2164.   
[3] 
Contrera, K. J., Wallhagen, M. I., Mamo, S. K., Oh, E. S., Lin, F. R. (2016). Hearing 
loss health care for older adults. J Am Board Fam Med, 29: 394–403. 
[4] 
Taljaard, D. S., Olaithe, M., Brennan-Jones, C. G., Eikelboom, R. H., Bucks, R. S. 
(2016). The relationship between hearing impairment and cognitive function: A meta-
analysis in adults. Clin Otolaryngol. Version of Record online: 28 FEB 2016 | DOI: 
10.1111/coa.12607 
[5] 
Emerson, L. P. (2012). Hearing loss in minor head injury. In: Sadaf Naz (Ed.) Hearing 
Loss. Croatia: InTech, 135-156.  
[6] 
Vartiainen, E., Karjalainen, S., Kärjä, J. (1985). Auditory disorders following head 
injury in children. Acta Otolaryngol Suppl, 99: 529–536. 
[7] 
Fitzgerald, D. C. (1996). Head trauma: hearing loss and dizziness. J Trauma, 40: 488–
496. 

Hearing Loss After Traumatic Conditions 
 
653
[8] 
Looi, V., Lee, Z. Z., Loo, J. H. Y. (2016). Quality of life outcomes for children with 
hearing impairment in Singapore. Int J Pediatr Otorhinolaryngol, 80: 88–100. 
[9] 
Polat, B., Başaran, B., Kara, H. C., Ataş, A., Süoğlu, Y. (2013). The impact of social 
and demographic features on comprehensive receptive and expressive performance in 
cochlear implant patients. Kulak Burun Bogaz Ihtis Derg, 23: 90–95. 
[10] O'Reilly, R. C., Sando, I. (2010). Anatomy and physiology of the Eustachian tube. In: 
Flint PW, Haughey BH, Lund VJ, Niparko JK, Richardson MA, Robbins KT, Thomas 
JR. Cummings Otolaryngology Head & Neck Surgery – 5th Edition. Mosby Elsevier, 
Vol 2, chapter 131. 
[11] Bluestone, C. D. (1983). Eustachian tube function: physiology, pathophysiology, and 
role of allergy in pathogenesis of otitis media. J Allergy Clin. Immunol, 72: 242-251. 
[12] Mirza, S., Richardson, H. (2005). Otic barotrauma from air travel. J Laryngol Otol, 
119: 366–370. 
[13] Beuerlein, M., Nelson, R. N., Welling, D. B. (1997). Inner and middle ear hyperbaric 
oxygen-induced barotrauma. Laryngoscope, 107: 1350–1356. 
[14] Becker, G. D., Parrel, G. J. (2001). Barotrauma of the ears and sinuses after scuba 
diving. Eur Arch Otorhinolaryngol, 258: 159-163. 
[15] Parell, G. J., Becker, G. D. (1993). Inner ear barotrauma in scuba divers. Arch 
Otolaryngol Head Neck Surg, 119: 455-457. 
[16] Saraiya, P. V., Aygun, N. (2009). Temporal bone fractures. Emergency Radiol, 
16:255–265. 
[17] Ishman, S. L., Friedland, D. R. (2004). Temporal bone fractures: traditional 
classification and clinical relevance. Laryngoscope, 114: 1734–1741. 
[18] Yalçiner, G., Kutluhan, A., Bozdemir, K., Çetin, H., Tarlak, B., Bilgen, A. S. (2012). 
Temporal bone fractures: evaluation of 77 patients and a management algorithm. Ulus 
Travma Acil Cerrahi Derg, 18: 424-428. 
[19] Brackmann, D. E., Shelton, C., Arriaga, M. A. (2010). Otologic surgery — 3rd ed. 
Elsevier, Chapter 29; 347-361.  
[20] Moller, A. R. (2006). Hearing: anatomy, physiology, and disorders of the auditory 
system/A.R. Moller, 2nd ed. Elsevier, Chapter 9; 205-251. 
 
 
Reviewed by: Paulo Rogério Cantanhede Porto, MD, MS 
 
 
 
 


In: Encyclopedia of Audiology and Hearing Research 
ISBN: 978-1-53617-702-2 
Editors: Erno Larivaara and Senja Korhola 
© 2020 Nova Science Publishers, Inc. 
 
 
 
 
 
 
 
Chapter 45 
 
 
 
IDIOPATHIC SUDDEN SENSORINEURAL HEARING 
LOSS AND CARDIOVASCULAR RISK FACTORS 
 
 
Andrea Ciorba and Chiara Bianchini 
ENT & Audiology Department, University Hospital of Ferrara, Ferrara, Italy 
 
 
ABSTRACT 
 
Idiopathic Sudden Sensorineural Hearing Loss (ISSNHL) is an acute inner ear 
disorder that mostly occurs unilaterally. The ISSNHL includes very different potential 
aetiologies, such as autoimmune and metabolic disorders, inner ear viral infections and/or 
impairment of the cochlear micro- circulation; among these, an impaired cochlear 
perfusion is one of the most widely reported hypothesis. In fact, the cochlea is provided 
with a terminal capillary bed and is not supplied by collateral vessels which could 
eventually restore blood flow in case of ischemia. Moreover cochlear hair cells have a 
high metabolic activity, and therefore the cochlea is particularly vulnerable to hypoxic or 
ischaemic damage.  
There is some evidence in the current literature showing that risk factors for 
ischaemic vascular disease, such as diabetes mellitus, cigarette smoking, hypertension 
and hyperlipidaemia, can also be considered risk factors for the development of ISSNHL. 
Furthermore, once the cochlear damage has occurred, oxidative stress, characterized by 
an increase in reactive oxygen species (ROS) and consequent damages to intracellular 
biochemical processes, represents an important factor in the pathophysiology of ISSNHL.  
Aim of this chapter is to evaluate the influence of cardiovascular risk factors among 
the onset of ISSNHL, and also the mechanisms of the inner ear damage, considering the 
evidences available in the literature so far. 
 
 
INTRODUCTION 
 
Idiopathic Sudden Sensorineural Hearing Loss (ISSNHL) is a relatively common disorder 
that can severely impact on a patient’s quality of life. The aetiopathogenetic mechanism of 
                                                        
 Corresponding Author’s Email: andrea.ciorba@unife.it. 

Andrea Ciorba and Chiara Bianchini 
 
656
ISSNHL, however it has been associated with viral, autoimmune, toxic, and vascular 
conditions. In particular, a microvascular impairment of the inner ear microcirculation is 
reported to be one of the possible causes of ISSNHL (Ciorba et al. 2013). The cochlea is 
provided with terminal capillaries and is not supplied by collateral vessels which could 
restore blood flow, if an ischemia occurs. Moreover, since cochlear hair cells have a high 
metabolic activity, they are particularly vulnerable to hypoxic or ischemic damage (Ciorba et 
al. 2013). Consequently, some Authors have identified that risk factors for ischaemic vascular 
disease could also be involved in the pathogenesis of ISSNHL (Ciorba et al. 2012). 
ISSNHL has different presentations in terms of severity of sensorineural hearing loss, 
ranging in severity from mild to profound, including low and high pitch patterns, and can 
affect people of any age. It is likely that the severity of the hearing loss, at the audiogram, 
could reflect the severity of the ischemia nor the cochlear sector in which the ischemia has 
occurred.  
 
 
IDIOPATHIC SUDDEN SENSORINEURAL HEARING LOSS (ISSNHL) 
AND CARDIOVASCULAR RISK FACTORS 
 
Some Authors have indicated that risk factors for ischaemic vascular disease, such as 
diabetes mellitus, cigarette smoking, hypertension and/or hyperlipidaemia, can also be 
considered risk factors for the development of Idiopathic Sudden Sensorineural Hearing Loss 
(ISSNHL) (Aimoni et al. 2012; Quaranta et al. 2008; Haubner et al. 2011; Lin et al. 2008; 
Stachler et al. 2012). 
Cochlear microvascular disorders can be related either to microembolic and/or 
thrombotic events (Ciorba et al. 1013; Lin et al. 2008). A better understanding of the 
relationships between cochlear blood flow and hearing function is fundamental for improving 
treatment and diagnosis of deafness that potentially arises from circulatory abnormalities. 
However, achieving such understanding is challenging also experimentally due to the 
difficulties involved in monitoring cochlear blood flow. The study of cochlear micro-
circulation should include in vivo imaging of blood flow with micron-scale resolution; since 
the deep location of the cochlea within the temporal bone at the skull base, this is very 
difficult to achieve (Monfared et al. 2006; Canis et al. 2010; Ciorba et al. 2013). 
Consequently, most of the hypothesis available in the literature among the cochlea 
physiopathology arises from observational studies.  
Aimoni et al. particularly evaluated the role of cardiovascular risk factors in ISSNHL, 
and observed that diabetes mellitus and hyperlipidaemia can be considered as possible risk 
factors for the onset of ISSNHL (Aimoni et al. 2013). The role of hypercholesterolemia has 
also been studied by Chang SL et al.; specifically, the Authors indicated that this condition 
may represent an independent risk for the occurrence of ISSNHL (Chang et al. 2014). Also 
Quaranta et al. and Haubner et al. investigated the role of the vascular hypothesis in ISSNHL 
mainly studying the role endothelial dysfunction, that can linked to cardiovascular risk 
factors, in the inner ear microcirculation. They have detected an increased expression of 
circulating adhesion molecules (VCAM-1) in patients affected by idiopathic sudden 
sensorineural hearing loss, thus confirming the role of vascular involvement in ISSNHL 
pathogenesis (Quaranta et al. 2008; Haubner et al. 2011). Ballesteros at al have identified that 

Idiopathic Sudden Sensorineural Hearing Loss and Cardiovascular Risk Factors 
 
657
patients with ISSNHL had a higher prevalence of the 807T thrombophilic polymorphism of 
platelet glycoprotein Ia/IIa; platelet glycoprotein Ia/IIa is the major platelet collagen receptor 
and is responsible for platelet adhesion to the exposed vessel and it is reported to be involved 
in platelet-platelet aggregation in vascular diseases (Ballestreros et al. 2009; Ballesteros et al. 
2012). 
 
 
ISSNHL CARDIOVASCULAR RISK FACTORS AND OXIDATIVE 
STRESS: PHYSIOPATHOLOGY OF THE DAMAGE  
 
Particularly, oxidative stress has been proposed to be involved in the physiopathology of 
the micro-vascular damage, when ISSNHL occurs. It has been reported that an increased level 
of intracellular reactive oxygen species (ROS) may be responsible for cochlear damage, 
therefore, the identification of possible cochlear ROS species and sources, could allow to 
develop new approaches to the prevention and rational treatment of specific inner ear 
disorders such as ISSNHL. In other words, the identification of the cellular mechanisms 
involved in the pathogenesis of the cochlear damage, at least could help us to contrast the 
cochlear cellular loss (Capaccio et al. 2012). 
So far, identified ROS species among cochlear cells include: superoxide anion (O2-), 
hydrogen peroxide (H2O2), hydroxyl radical (OH), hypochlorous acid (HOCl), NO, and 
peroxynitrite (ONOO–) (Khun et al. 2011). Main sources of ROS production within the 
cochlea seem to be the mitochondria of inner ear hair cells and/or enzymes such as xanthine 
oxidase and NADPH oxidase. Once generated, the intracellular ROS are responsible for direct 
damage to lipids, proteins and DNA, triggering apoptosis or necrosis (Yavuz et al. 2005; 
Kuhn et al. 2011; Bovo et al. 2007). Also, it has been observed that the different cellular 
components of the cochlea, does not share the same vulnerability to injury induced by ROS. 
In particular, outer hair cells seem more susceptible to damage induced by free radicals 
especially those at the base of the cochlea, while supporting cells have a greater capacity of 
survival (Yavuz et al. 2005; Kuhn et al. 2011; Bovo et al. 2007). Also, glutathione 
(antioxidant agent) has been reported to be mainly expressed in the most apical hair cells and 
NOX3, responsible for the production of superoxide, to be mainly expressed among hair cells 
of the cochlear base nor in the spiral ganglion neurons (Yavuz et al. 2005; Kuhn et al. 2011; 
Bovo et al. 2007). 
In addition, recent evidences suggests that, in some conditions, oxidative stress may 
cause further damage by triggering further endothelial dysfunction within inner ear 
microcirculation; this could be further responsible of further damage in case of ISNHL, and at 
the same time, it could also represent a new and very interesting therapeutic target (Ciccone et 
al. 2012; Ciorba et al. 2012; Cho et al. 2012; Kuhn et al. 2011).  
 
 
CONCLUSION 
 
ISSNHL results from injury to the sensory components (i.e., hair cells) or neuronal 
components (i.e., auditory nerve cells) of the inner ear. Cardiovascular risk factors and 
therefore oxidative stress, characterized by an increase in reactive oxygen species (ROS) and 

Andrea Ciorba and Chiara Bianchini 
 
658
consequent damage to intracellular biochemical processes, represents an important factor in 
the pathophysiology of ISSNHL.  
Targeting the oxidant response by antioxidants and by modulating specific enzymes (e.g., 
NO synthases, NADPH oxidase) could represents a potential therapeutic strategy; however, 
the therapeutic role of antioxidants in the management of hearing loss still is debated 
nowadays (Capaccio et al. 2012). On the other side, monitoring cardiovascular risk factors 
could play a role in prevent the onset of ISSNHL, at least in some cases. 
 
 
REFERENCES 
 
Aimoni C, Bianchini C, Borin M, Ciorba A, Fellin R, Martini A, Scanelli G, Volpato S. 
Diabetes, cardiovascular risk factors and idiopathic sudden sensorineural hearing loss: a 
case-control study. Audiol Neurootol. 2010; 15:111-115. 
Ballesteros F, Tassies D, Reverter JC, Alobid I, Bernal-Sprekelsen M. Idiopathic sudden 
sensorineural hearing loss: classic cardiovascular and new genetic risk factors. Audiol 
Neurootol. 2012;17(6):400-8. 
Ballesteros F, Alobid I, Tassies D, Reverter JC, Scharf RE, Guilemany JM et al. Is there an 
overlap between sudden neurosensorial hearing loss and cardiovascular risk factors? 
Audiology and Neurotology 2009; 14(3): 139-145. 
Bovo R, Ortore R, Ciorba A, Berto A, Martini A. Bilateral sudden profound hearing loss and 
vertigo as a unique manifestation of bilateral symmetric inferior pontine infarctions. Ann 
Otol Rhinol Laryngol. 2007;116(6):407-10. 
Canis M, Arpornchayanon W, Messmer C, Suckfuell M, Olzowy B, Strieth S. An animal 
model for the analysis of cochlear blood flow [corrected] disturbance and hearing 
threshold in vivo. Eur Arch Otorhinolaryngol. 2010 Feb;267(2):197-203. 
Capaccio P, Pignataro L, Gaini LM, Sigismund PE, Novembrino C, De Giuseppe R, Uva V, 
Tripodi A, Bamonti F. Unbalanced oxidative status in idiopathic sudden sensorineural 
hearing loss. Eur Arch Otorhinolaryngol. 2012;269(2):449-53.  
Chang SL, Hsieh CC, Tseng KS, Weng SF, Lin YS. Hypercholesterolemia is correlated with 
an increased risk of idiopathic sudden sensorineural hearing loss: a historical prospective 
cohort study. Ear Hear. 2014 Mar-Apr;35(2):256-61.  
Cho SH, Chen H, Kim IS, Yokose C, Kang J, Cho D, Cai C, Palma S, Busi M, Martini A, 
Yoo TJ. An Association of the 4g/5g polymorphism of plasminogen activator inhibitor-1 
gene with sudden sensorineural hearing loss. A case control study. BMC Ear Nose Throat 
Disord. 2012; 6: 12:5. 
Ciorba A., Chicca M., Bianchini C., Aimoni C., Pastore A. Sensorineural hearing loss and 
endothelial dysfunction due to oxidative stress: Is there a connection? Int. Adv. Otol. 
2012; 8:(1) 16-20. 
Ciorba A, Faita A, Bianchini C, Aimoni C, Scanelli G. Arteriopathy and microvascular 
impairment in sudden sensorineural hearing loss: Clues from two clinical cases. Hearing, 
Balance and Communication, 2013; 11: 87-90. 
Ciccone MM, Cortese F, Pinto M, Di Teo C, Fornarelli F, Gesualdo M, et al. Endothelial 
function and cardiovascular risk in patients with Idiopathic Sudden Sensorineural 
Hearing Loss. Atherosclerosis. 2012; 225(2):511-6. 

Idiopathic Sudden Sensorineural Hearing Loss and Cardiovascular Risk Factors 
 
659
Haubner F, Martin L, Steffens T, Strutz J, Kleinjung T. The role of soluble adhesion 
molecules and cytokines in sudden sensorineural hearing loss. Otolaryngol Head Neck 
Surg. 2011; 144:575-580. 
Kuhn M., Heman-Ackah S.E., Shaikh J.A., Roehm P.C. Sudden Sensorineural Hearing Loss: 
A review of diagnosis, treatment, and prognosis. Trends Amplif 2011; 15(3): 91-105. 
Lin H.C., Chao P.Z, Lee H.C. Sudden Sensorineural Hearing Loss Increases the Risk of 
Stroke. A 5-Year Follow-Up Study. Stroke. 2008; 39: 2744-2748. 
Monfared A, Blevins NH, Cheung EL, Jung JC, Popelka G, Schnitzer MJ. In vivo imaging of 
mammalian cochlear blood flow using fluorescence microendoscopy. Otol Neurotol. 
2006; 27(2):144-52. 
Quaranta N, Ramunni A, Brescia P, D’Elia A, Vacca A, Ria R. Soluble intercellular adhesion 
molecule 1 and soluble vascular cell adhesion molecule 1 in sudden hearing loss. Otol 
Neurotol. 2008; 29:470-474. 
Stachler RJ, Chandrasekhar SS, Archer SM, Rosenfeld RM, Schwartz SR, Barrs DM, et al. 
American Academy of Otolaryngology-Head and Neck Surgery. Clinical practice 
guideline: sudden hearing loss. Otolaryngol Head Neck Surg. 2012;146(3 Suppl):1-35. 
Yavuz E, Morawski K, Telischi FF, Ozdamar O, Delgado RE, Manns F, Parel JM. 
Simultaneous measurement of electrocochleography and cochlear blood flow during 
cochlear hypoxia in rabbits. J Neurosci Methods. 2005; 147(1): 55-64. 
 


In: Encyclopedia of Audiology and Hearing Research 
ISBN: 978-1-53617-702-2 
Editors: Erno Larivaara and Senja Korhola 
© 2020 Nova Science Publishers, Inc. 
 
 
 
 
 
 
 
Chapter 46  
 
 
 
HEARING LOSS OF VOLGA-URAL REGION IN RUSSIA 
 
 
Lilya U. Dzhemileva1,2,3,*, Simeon L. Lobov1,  
Dmitriy U. Kuznetzov1,2, Alsu G. Nazirova3,  
Elvira M. Nurgalina3, Nikolay A. Barashkov4,5,  
Sardana A. Fedorova4,5 and Elza K. Khusnutdinova1,2 
1Institute of Biochemistry and Genetics, Ufa Research Center,  
Russian Academy of Sciences, Ufa, Russian Federation 
2Department of Genetics and Fundamental Medicine,  
Bashkir State University, Ufa, Bashkortostan, Russian Federation 
3Department of Immunology and Human Reproductive Health,  
Bashkir State Medical University, Ufa, Bashkortostan, Russian Federation 
4Department of Molecular Genetics, Federal State Budgetary Scientific Institution  
“Yakut Science Centre of Complex Medical Problems”, Yakutsk, Russian Federation  
5Laboratory of Molecular Biology, Institute of Natural Sciences,  
M. K. Ammosov North-Eastern Federal University,  
Yakutsk, Russian Federation 
 
 
ABSTRACT 
 
We studied the molecular basis of NSHL in Volga-Ural region. The Volga–Ural 
region of Russia is of partiicularinterest, because its ethnic populations mostlybelong to 
the Turkic, Finno-Ugric, and Slavonic linguisticgroups and have complex ethnogenesis 
and combine the Caucasian and Mongoloid components invarious proportions. The data 
on the prevalence of hereditary non-syndromic sensorineural hearing loss in the Volga-
Ural region was received. It was 5.7 per 100000 (1:17543) of the population. The 
heterozygous carrier frequency of c.35delG, c.167delT and c.235delC mutations of the 
GJB2 gene in 17 populations of Eurasia was revealed. The analysis of the spectrum and 
frequency of mutations in genes GJB2, GJB6, GJB3, 12SrRNA, tRNASer(UCN), 
SLC26A4 and SLC26A5 in patients with non-syndromic sensorineural hearing loss from 
Bashkortostan Republic was performed. The mechanism of accumulation of non-
                                                        
* Corresponding Author’s Email: Dzhemilev@mail.ru. 

Lilya U. Dzhemileva, Simeon L. Lobov, Dmitriy U. Kuznetzov et al. 
 
662
syndromic sensorineural hearing loss caused by c.35delG mutation in Volga-Ural region 
is analyzed on the basis of haplotype analysis. The age of c.35delG mutation in the GJB2 
gene in populations of the Volga-Ural region was defined. New approaches are 
developed to prevent hereditary sensorineural hearing loss and to improve medical and 
genetic consulting for patients with the inherited form of hearing impairment in Volga-
Ural region. 
 
Keywords: hearing loss, genes GJB2, GJB6, GJB3, 12SrRNA, tRNASer(UCN), SLC26A4 and 
SLC26A5 
 
 
According to various sources, congenital deafness is found in 0,05% -0,1% of the 
children; what is more, the majority of sick children (92%) suffer from sensorineural deafness 
(NSD). In most cases (about 90%) they are children of hearing parents and their families had 
no cases of hearing-impaired relatives. Depending on the nature of its cause, deafness is 
usually divided into two large groups: hereditary and acquired. Acquired hearing loss occurs 
due to the influence of various adverse environmental factors on a fetus, an infant or an older 
child. Depending on the nature of deafness, they distinguish between conductive and 
sensorineural types, meanwhile intermediate and mixed forms are frequently observed. Mixed 
hearing loss is characterized by the presence of both types of impairments: conductive and 
sensorineural. The cause of conductive hearing loss is a damage of the outer and middle ear 
and nasopharynx. Anomalies of the pinna and ear canal (atresias, microtias, development 
abnormalities of the auditory ossicles or otostapes fixation, etc.) can be attributed to the 
pathology of the external ear. If we talk about the abnormalies of the outer and middle ear, it 
is obvious that these types of pathologies are congenital; with age conductive type of hearing 
loss develops mainly due to otosclerosis (Duman et al., 2013). 
Sensorineural deafness may be determined by the damage in different parts of the inner 
ear: the cochlea (the organ of Corti), the vestibulocochlear nerve, the pathways or the relevant 
structures of the brain. Sensorineural hearing loss is usually divided into cochlear (it occurs 
when hair cells in the organ of Corti are damaged) and retrocochlear in which cochlear 
neuritis is diagnosed (Tavartkiladze et al., 1996; Altman et al., 2003). A number of anomalies 
in the structure of the inner ear have been described in the result of pathomorphological 
studies of temporal bones in deaf individuals. It was found that congenital deafness may be 
determined by primary changes in the cochlea itself (Fishman et al., 1996). 
Until 1995, clinical researchers had to face significant difficulties in the study of NSD, as 
before the methods of molecular genetic analysis of hereditary forms of hearing loss and 
deafness had been introduced into medical practice, scientific literature mainly had the 
descriptions of genealogy with the hypothetic types of inheritance and the attempts of 
segregation analysis. It was impossible to prove the hereditary nature of hearing loss in the 
families with sporadic cases. (Fishman et al., 1996). Assortative marriages and intermarriages 
between the hearing-impaired and deaf individuals should be specifically noted, as they play 
an important role in the spread of certain forms of deafness and hearing loss, having complex 
etiology, pathogenetic and epidemiologic mechanisms. Thus, molecular analysis is the only 
way of non-syndromic deafness adequate diagnosis, especially in the absence of genealogic 
pedigree data. 

Hearing Loss of Volga-Ural Region in Russia 
 
663
 The most common form of hereditary deafness is the so-called nonsyndromic or isolated 
form, characterized by hearing loss only. In some forms of hereditary deafness there is a 
combination of hearing loss and abnormalities of other organs or systems. They are usually 
denoted as syndromic forms. In some syndromes, besides hearing impairment, there are also 
observed vision, thyroid, pigmentation disorders or kidney pathologies, etc. (Everett et al., 
1999). One of the most world common forms of syndromic deafness, that can be found in 3-
6% of all congenital deafness cases, is Usher syndrome (Nance, 2003; Duman et al., 2013). 
Usher syndrome, in its various forms, is a combination of hearing loss and vision impairment. 
Waardenburg syndrome is the cause of hearing loss in about 2 - 5% of congenital deafness 
cases (Ouyang et al., 2002; Morton, 2006). This syndrome is characterized by skin and hair 
pigmentation abnormalities combined with minor facial anomalies in addition to hearing loss. 
At the present moment, there are more than 400 syndromes combined with hearing loss 
pathology (OMIM 2013). 
Clinical polymorphism of many syndromic and nonsyndromic hereditary forms of 
hearing loss and deafness is primarily determined by genetic heterogeneity of this pathology. 
The number of patients with hearing impairments in Russian Federation exceeds 13 
million people; more than 1 million of them are children. Total deafness is recorded in 1 per 
1000 newborns. Moreover, during the first 2-3 years of life, 2-3 children lose hearing. 14% of 
people aged from 45 to 64 and 30% of people aged over 65 have hearing impairment. 
According to WHO, over 30% of the world population will suffer from hearing impairment in 
2020 (Tavartkiladze et al. 2010). 
During the targeted screening of the child population for the hearing impairment in 
several countries (England, Germany, Italy, Spain, Sweden, Finland, USA), averagely, 
deafness was detected in 1 per 650 newborns. The screening was carried out on the basis of 
complete audiological examination (Snoeckx et al., 2005). According to the data of various 
authors, it is noted that in the US at least 1 per 1000 live newborns is born with moderate or 
severe bilateral NSD, including 4 completely deaf children per 10,000. It is three times more 
than Down's syndrome, six times more than spina bifida and 50 times more than 
phenylketonuria (Petersen et al., 2006). 
The analysis of children’s age characteristics at the time of diagnosis in surdologopaedic 
offices of Russian regions showed that the diagnosis of hearing loss and deafness was 
untimely: children under 1 make only 5% of the total number of the examined; aged from 1 to 
3 - 14%; about a third of children (28%) is placed in the dispensary registration list at the age 
of 3-7; 30% of children had hearing impairment detected at the age of 7-14 and 23% at the 
age of 14-18 (Tavartkiladze et al., 2010). 
It is quite a difficult task - to get a complete picture about the frequency of hearing 
impairment among children, since numerous criteria must be taken into account: the nature of 
pathology, age of onset, degree of hearing loss, the child's age, family history, and character 
of the various complications during mother’s pregnancy and labor, past illnesses, place of 
study, and others. Children with severe hearing loss initially fall into a specific group and 
they are available to account for the prevalence registration of deafness due to the possibility 
of studying in specialized correctional institutions. While children with mild and moderate 
degrees of NSD often do not get under audiologists’ supervision, because they can study at an 
elementary school and not complain about hearing loss during medical examinations. It 
requires specific diagnostic and screening programs, including genetic testing, to identify 
such forms of children’s hearing loss that mainly develop during the first year of life. 

Lilya U. Dzhemileva, Simeon L. Lobov, Dmitriy U. Kuznetzov et al. 
 
664
In practice, it is often quite difficult to differentiate congenital hearing loss from hearing 
impairment occurring postpartum during the first year of life, especially if the degree of 
sound perception impairment is slight and the progression of the process is slow (Cryns et al., 
2004; Tavartkiladze et al., 2010). 
The data on the prevalence of prelingual non-syndromic sensorineural deafness in the 
world literature is quite scarce. Thus according to The Gallaudet Encyclopedia of Deaf People 
and Deafness (1986) and The Encyclopedia of Deafness and Hearing Disorders (2004), the 
prevalence of congenital deafness is 50 per 100 000 in the US, 47 per 100 000 in France and 
46 per 100 000 in the UK. In Europe, the incidence of congenital autosomal recessive 
deafness is averagely in 1 per 5000 newborns, autosomal dominant in 1 per 10000, X-linked 
in 1 per 100 000 boys (Alvarez et al., 2010; Duman et al., 2013). According to the register of 
British Columbia (Canada), the frequency of the dominant deafness is 0,19 and recessive is 
0,25 per 10,000 newborns (Petersen at al., 2006; Alvarez et al., 2010). 
Diagnostic screening programs for assessing the frequency of congenital hearing loss in 
newborns are carried out in a number of European and Asian countries, as well as in the 
United States (Tsukada et al., 2010; Duman et al., 2013). 
In the former CIS countries in the period from 1983 to 1989, a study on the prevalence, 
etiology and clinical features of sensorineural hearing impairment in children of the Republic 
of Uzbekistan was carried out (Agzamhodzhaev SS, 1989). It was shown that NSD occurred 
in 9,7 per 10000 children on the territory of the Republic of Uzbekistan. The hereditary nature 
of the disease is established in 44% of cases. Isolated hearing impairments were detected in 
94,8% of children and syndromal hearing impairments in 5,2% of cases. 
Research on the epidemiology of hereditary deafness forms was carried out in a number 
of regions of the Russian Federation in the framework of integrated health and population-
genetic survey of a region, providing a wide range of hereditary diseases detection (including 
different forms of hearing loss), together with the study of the genetic structure peculiarities. 
That made it possible to explain the basic mechanism behind the dissemination of hereditary 
deafness in region’s districts. In these studies it was shown that spatial differences in the 
frequencies of hearing loss in different regions were determined by the peculiarities of the 
genetic structure of the populations studied, in particular, the level of genetic subdivision and 
the influence of genetic drift (Shokarev R.A. et al., 2002; Panakhian V.M. 2004, Markova et 
al., 2005; Zinchenko R.A. et al., 2007; Shokarev R.A. et al., 2005; Zinchenko et al., 2012; 
2013; Bessonova et al., 2012). 
Numerous studies point to a significant contribution of genetic factors in the process of 
sound perception impairment (Cryns et al., 2004; Smith et al., 2005; Petersen et al., 2006; 
Duman et al., 2013). Almost all inheritance types are observed in the inherited forms of 
hearing impairment, including X-linked and mitochondrial forms. Different loci of numerous 
nonsyndromic forms of deafness are denoted by letters DFN, taken from the English word 
deafness and they are numbered in chronological order as they had been discovered. 
Autosomal dominant loci are denoted as DFNA, autosomal recessive as DFNB and X-linked 
as DFN. The most common form of hereditary hearing loss is nonsyndromic deafness. It is 
characterized by clinical polymorphism and genetic heterogeneity (Petit et al., 2001; Morton, 
2006; Petersen et al., 2006). This form of the disease occurs most frequently among the 
patients with hereditary nonsyndromic deafness (from 30 to 75% of all cases) (Denoyelle et 
al., 1997; Estivill et al., 1998; Antoniadi et al., 1999; Loffler et al., 2001; Morton, 2006; 
Petersen et al., 2006; Tekin et al., 2010). Approximately 70-77% of all non-syndromic 

Hearing Loss of Volga-Ural Region in Russia 
 
665
deafness cases occur in autosomal recessive forms, 20-25% in autosomal dominant and all 
other cases in X-linked and mitochondrial forms of deafness (Morton et al., 2006). 
Genetic heterogeneity of hereditary sensorineural deafness forms is determined by the 
fact that more than 60 genes take part in the process of embryonic development of the organ 
of Corti (Duman et al., 2013). Most of the mutations that cause sound perception impairment 
are identified in the genes encoding connexins GJB2, GJB6, GJB3, GJA1, GJB1. Besides, the 
mutations that lead to hearing loss were also found in the genes of other proteins that are 
widely expressed in the inner ear tissues: collagen, actins, tectorines and others. Using the 
method of linkage analysis more than 110 loci for hereditary nonsyndromic sensorineural 
hearing loss and deafness were mapped. At the present time, more than 65 genes where 
mutations are responsible for the occurrence of human deafness were identified. It is 
noteworthy that the search for genes in which mutations are responsible for the development 
of many hereditary defects, including hereditary deafness, got intensified with the end of 
major international research – the project of the human genome sequencing (Human Genome 
Project) (http://www.gdb.org/) and haplotype mapping (Haplotype Mapping Project) 
(http://www.hapmap.org/). These research programs were actually catalysts for the 
development of more effective and rapid technologies of decryption, generating and 
interpreting a large array of genetic databases (http://www.gdb.org/). 
It was found that more than 50% of congenital nonsyndromic NSD is caused by 
mutations in the gene GJB2 (connexin 26 gene) (Smith et al., 2005). The contribution of this 
gene to the development of some nonsyndromic and syndromic forms is 4-80% (Petersen et 
al., 2006; Vivero et al., 2010). 
Protein connexin 26 (Cx26) is involved in the formation of gap junction intercellular 
contacts necessary to move ions and small molecules in the tissues of the cochlea. Six 
connexins are joined together forming a connexon penetrating the cell membrane, which 
forms a channel together with the connexon of the neighboring cell. 
At the present time it is observed that in some ethnic groups there is a high frequency of 
heterozygous carriers of the most frequent mutations the gene GJB2. The most common of 
these are deletions of: guanine at position 35 - c.35delG, cytosine at position 235 - c.235delC, 
thymine at position 167 - c.167delT and replacements - p.Trp24X and p.Arg143Trp. 
Moreover, the mutation c.35delG occurs mainly in populations of Europe, the Middle East 
and North America (Rabionet et al, 2000; Mustapha et al., 2001; Najmabadi et al., 2002; 
Tekin et al., 2003, 2010). The mutation c.235delC is major for the Mongoloid populations 
and occurs mainly in East Asia among the Japanese, Chinese and Koreans. It is also recorded 
among the Mongols and the Altaians (Yan et al., 2003; Posukh et al., 2005). 
Mutation c.167delT is widespread mainly among the Ashkenazi Jewish groups, but there 
are some peoples of the Mediterranean, Eastern Europe and sporadically throughout Eurasia 
(Morell et al., 1998; Lerer et al., 2001; Gasparini et al., 2000; Bors et al., 2004). p.Trp24X 
mutation is most common in India and Slovakia (Mukherjee et al., 2003; Minarik et al., 2003; 
Ramchander et al., 2005) and p.Arg143Trp is a major mutations in Ghana (Africa) (Brobby et 
al., 1998; Hamelmann et al., 2001; Nagla et al., 2004). 
Currently there are more than 130 different dominant and recessive mutations in the gene 
GJB2 (Connexin-Deafness Homepage). Dominant effect of many connexin gene 26 
mutations is mainly being associated with the mutation location in the domains of connexin 
26. It was previously shown that some mutations located in specific regions of the gene GJB2 

Lilya U. Dzhemileva, Simeon L. Lobov, Dmitriy U. Kuznetzov et al. 
 
666
may affect the assembly of various classes of homologous and heterologous connexons 
(Bicego et al., 2006). 
In order to estimate the prevalence of hereditary forms of non-syndromic sensorineural 
hearing loss in the Volga-Ural region, without differentiation into types, we used the 
materials of a complex entire health and population-genetic examination of the population in 
seven districts of the Republic of Bashkortostan (RB), carried out in the period from 2005 to 
2008 in collaboration with Research Center of Medical Genetics (RCMG) of the Russian 
Academy of Medical Sciences (RAMS) (Moscow), the information on all known patients 
with congenital deafness, living on RB territory was obtained from the database of the 
National Surdologic Center where the majority of families with hereditary hearing loss is 
registered, the examination records in special schools of RB for hearing-impaired and deaf, 
documents on medical and social expertise on inspection of hearing-impaired and deaf 
between the years of 2000 and 2012 years. The obtained information was specified at the 
moment of the study through a targeted request to the central city and regional hospitals, 
special schools and correctional kindergartens, as well as during expedition trips in 2000 - 
2012, performed together with the staff of the Republican Surdologic Center aimed at 
additional clinical examination of patients and their families, as well as blood sampling for 
DNA analysis. 
In order to carry out clinical and epidemiological research, the data on each patient that 
has been living on the territory of the Republic of Bashkortostan during the study period from 
1 January 2000 to 1 January 2011 were collected. The criterion for inclusion in the study was 
the diagnosis of “hereditary sensorineural hearing loss / deafness» (G11 according to ICD-10) 
established on the basis of clinical, laboratory and instrumental and molecular genetic 
research methods in accordance with current diagnostic criteria proposed by The National 
Institute on Deafness and Other Communication Disorders (Omaha, USA) and recommended 
in 2003 by European Thematic Network on Genetics Deafness GENDEAF (Mazzoli et al., 
2003). 
During the study the data on the patients’ ethnicity was specified through interviewing 
and finding out the parents’ nationality up to the third generation. Particular attention was 
paid to the establishment of the place of birth of the probands, their parents and grandparents; 
intermarriages revealing in the families of the examined patients. According to the initial data 
analysis and, based on the diagnostic criteria for NSD, nonsyndromic sensorineural hearing 
impairments with a burdened family history of sound perception violations were 
distinguished out of the total number of isolated hearing loss/deafness cases. Thus, 246 
families of patients with NSD from RB were included in the study. According to the degree 
of hearing loss in probands, the families were distinguished as follows: I degree of hearing 
loss was reported in 4 families, II degree of hearing loss - in 17 families, III degree of hearing 
loss - in 31 family, IV degree of hearing loss - in 62 families and deafness - in 132 families. 
The ethnic composition of the examined families using molecular-genetic methods was 
as follows: Russians - 98 families, Tatars - 58 families, Bashkirs - 37 families, Mari - 5 
families, Ukrainians - 3 families, Armenians - 3 families, mixed ethnicity - 42 families. In 
order to analyze the frequencies and spectrum of mutations in the genes of mitochondrial 
DNA, the unrelated individuals from 999 families (520 healthy donors and 479 patients with 
impaired auditory function) from different regions of the Russian Federation were analyzed 
(Table. 1). 

Hearing Loss of Volga-Ural Region in Russia 
 
667
The population sample group consisted of 2 078 DNA samples obtained from healthy 
unrelated individuals. The ethnic composition of the studied samples was as follows: 
Russians (N = 92), Belarusians (N = 97), Ukrainians (N = 90), Abkhazians (N = 80), Avars 
(N = 60), Cherkessians (N = 80), Ingushes (N = 80), Kazakhs (N = 240), Uighurs (N = 116), 
Uzbeks (N = 60), Bashkirs (N = 400), Tatars (N = 96), Chuvashs (N = 100), Udmurts  
(N = 80), Komi-Permyaks (N = 80), Mordvins (N = 80) and Yakuts (N = 247). 
 
Table 1. Number and ethnicity of patients and control groups to analyze the frequencies 
and spectrum of mutations in the genes of the mitochondrial DNA 
 
Ethnicity 
Regions 
The Republic of 
Bashkortostan 
Saint-Petersburg 
The Sakha 
(Yakutia) 
Republic 
The Altai 
Republic 
Patients 
Control 
Patients 
Control 
Patients 
Control 
Patients 
Control 
ASD 
NSD 
Russians 
98 
50 
71 
46 
100 
10 
0 
10* 
- 
Tatars 
45 
50 
- 
- 
- 
- 
- 
- 
- 
Bashkirs 
30 
48 
- 
- 
- 
- 
- 
- 
- 
Yakuts 
- 
- 
- 
- 
- 
48 
120  
- 
- 
Altains 
- 
- 
- 
- 
- 
- 
- 
64* 
150 
Kazakhs 
- 
- 
- 
- 
- 
- 
- 
12* 
- 
Mestizos 
22 
- 
- 
- 
- 
- 
- 
- 
- 
Other 
nationalitie
s 
9 
2 
- 
5 
- 
7 
- 
2 
- 
Total 
204 
150 
71 
51 
100 
65 
120 
88 
150 
* - Also included individuals of mixed ethnicity, maternally related to Russians, Altaians, Kazakhs, 
respectively. ASND is a group of patients with acute sensorineural; NSSND is a group of patients 
with non-syndromic sensorineural deafness/hearing loss.  
 
The clinical material collected in RB was analyzed by segregation analysis, aimed at 
checking the conformity of the distribution of patients and healthy ones in revealed nuclear 
families according to a certain pattern of inheritance - autosomal dominant or autosomal 
recessive. The segregation analysis was performed in order to get the share of sporadic cases 
using the method of maximum probability, taking into account the possibility of registration 
in accordance with the algorithm of complex segregation analysis, developed by Morton 
(Lalouel et al., 1983). 
Molecular genetic studies were performed using standard methods: DNA extraction; 
polymerase chain reaction of DNA synthesis (PCR); amplified fragment length 
polymorphism (AFLP), restriction fragment length polymorphism (RFLP), hybridization on 
(HHL) chips (Asper Biothech Ltd); single-strand conformation polymorphism (SSCP) and 
resequencing. 

Lilya U. Dzhemileva, Simeon L. Lobov, Dmitriy U. Kuznetzov et al. 
 
668
The prevalence of hereditary nonsyndromic deafness in RB ranged from 15 to 30,11 per 
105 people and is one of the most common hereditary diseases among the population in some 
areas of RB (Zinchenko et al., 2009). The results of our research indicate that NSD is 
distributed unevenly on the territory of RB. Its distribution in the regions of RB is shown in 
Fig. 1. 
The NSD prevalence in RB, totally, was 5,7 per 105 (1: 17,543) inhabitants. The disease 
was registered in 35 (out of 54) administrative districts of the Republic. Analysis of the data 
shows wide variation of NSD prevalence: from 0,39 to 39,67 per 100 000 people. There are 
no registered cases of the disease in 19 districts of the Republic: Alsheyevsky, Bakalinsky, 
Belokataysky, Bizhbulyaksky, Blagovarsky, Duvansky, Dyurtyulinsky, Yermekeyevsky, 
Zilairsky, 
Kaltasinsky, 
Kuyurgazinsky, 
Mechetlinsky, 
Miyakinsky, 
Nurimanovsky, 
Sterlibashevsky, Tatyshlinsky, Fyodorovsky, Chekmagushevsky, Sharansky. Minimum 
prevalence of the disease was detected in Ilishevsky, Belebeyevsky, Beloretsky, 
Meleuzovsky, Gafuriysky, Ishimbaysky, Krasnokamsky districts and was less than 3 per 105 
people. The highest rate of 39,67 per 105 was registered in the Arkhangelsky region, second 
place was taken by Salavatsky district and the third one by Baltachevsky (38,57 and 32,39 per 
100000 people, respectively). When determining the causes of the increased disease 
prevalence in some areas (more than 15 per 105) it was found that the highest values of this 
indicator may be associated with territorial dislocation of the correctional schools. This fact 
can be explained by the special lifestyle features of the deaf and hearing-impaired individuals.  
When comparing the NSD prevalence maps on the territory of RB and maps of 
correctional schools for the deaf / hearing-impaired, the correspondence of high NSD 
prevalence rates and geographic location of this or that correctional school. 
 These conclusions are supported by a number of European studies of hereditary forms of 
hearing loss. The introduction of sign language in Europe and the creation of schools for the 
deaf and hearing-impaired more than 300 years ago helped to break a social isolation caused 
by communication defect, and, thusly, helped to increase chances of deaf and hearing-
impaired individuals to marry, which, in its turn, led to increase of the number of assortative 
marriages and birth rate increase in this population group (Tekin et al., 2007; 2010). 
Mutation c.35delG (p.Gly12Valfsx1) of the GJB2 gene is the most common for 
populations of Western Europe where its frequency is 20% of all hereditary isolated hearing 
impairments and every 33rd resident is a heterozygous carrier (Mahdieh et al., 2009). 
During the first phase of research 390 patients from 204 unrelated families of RB 
underwent screening for c.35delG mutations in the gene connexin 26 (GJB2). This deletion 
was detected in the homozygous state in 66 patients (58 unrelated). In 67 (56 unrelated) 
patients c.35delG mutation was identified in the heterozygous state and in 45 (39 unrelated) 
patients it was in the compound heterozygous state with other mutations in the GJB2. Thus, 
mutation c.35delG was discovered in 153 unrelated families, which is 75% of all surveyed 
families with NSD. 
Taking into account the number ratio in families in the probands of which c.35delG 
mutation was identified in homo-, hetero- and compound heterozygous state, we performed 
the evaluation of the deletions frequency in patients, which amounted to 34% in the studied 
samples of patients. This result is consistent with the literature data on the high prevalence of 
this mutation in different ethnic groups. Basically, this mutation is recorded with a high 
frequency among patients with hereditary deafness in Europe, North. America and Eurasia 
(Man et al., 2007). 

Hearing Loss of Volga-Ural Region in Russia 
 
669
The frequency of c.35delG mutation on patients’ chromosomes of Russian ethnicity was 
43%, among the Tatars with NSD - 27%, among the Bashkirs with NSD - 13% (χ2 = 10,644; 
p <0,05; df = 2). Therefore, there are statistically significant differences between the groups 
of patients (Bashkirs, Tatars and Russian)s in the frequency of c.35delG mutation in the gene 
GJB2. In the group of mestizos the c.35delG frequency was 34%. The small number of 
representatives of other ethnic groups in the patients’ samples made impossible to carry out 
statistical analysis and calculate the c.35delG frequency in the gene GJB2. These results 
confirm the data on prevalence of this deletion among the patients from Europe and its lower 
prevalence among patients with NSD from Asia (Dai et al., 2009). 
The cause of hearing loss can be considered established in 66 patients from 54 unrelated 
families on both chromosomes of which c.35delG mutation was identified. Both differential 
diagnosis of hereditary disease etiology and prospective medical and genetic counseling, 
including the possibility of prenatal molecular genetic diagnosis, are possible in these 
families. Taking into account high frequency of assortative marriages between deaf 
individuals (45% of RB patients), it is easy enough to explain the relative prevalence of 
homozygous c.35delG mutations in the gene GJB2 (28%) among the patients with NSD. 
 22 mutations were identified in the result of molecular-genetic analysis of the genes 
GJB2, GJB3, GJB6, SLC26A4, SLC26A5 and MYO7A. The spectrum and frequency of 
mutations found in RB patients with NSD have expressed ethnic heterogeneity. Thus, the 
most common mutation identified with a frequency of 42.8% on chromosomes of Russian 
ethnicity carriers was c.35delG deletion in the gene GJB2. The following mutations had 
frequency higher than 1%: c.314_327del14 (2,5%), c.167delT (1,5%), g.-3179G> A (1,02%) 
and c.224G> A (1,02%). The frequency of other mutations does not exceed 0,5%. 
Following mutations were identified on chromosomes of patients with NSD, having Tatar 
ethnicity: c.35delG (27,8%), c.314_327del14 (6,67%), c.167delT (3,33%), g.-3179G> A 
(3,33%), c.235delC (2,22%), c.358_360delGAG (2,22%), c.333_334delAA (2,22%), 
c.310_325del14 (2,22%), c. 35dupG (1,11%); and two polymorphic variants: c.79G> A 
(6,67%) and c.457G> A (1,1%) in the gene GJB2, mutation g.919-2A> G (1 1%) in the gene 
SLC26A4. Mutations c.35delG (13,3%), c.235delC (1,67%) and r.Val27Ile (c.79G> A) + 
r.Glu114Gly (c.341G> A) (1,67%) and c.101T> C (3,33%) were found among the patients of 
Bashkir ethnicity. r.Val27Ile (c.79G> A) turned out to be the most common polymorphic 
variant, occurring among Bashkirs; its frequency on the chromosomes of patients with 
hearing loss was 15%. A small contribution of the GJB2 gene mutations in the development 
of nonsyndromic deafness among Bashkirs (35%), is possibly connected to the presence of 
mutations in other genes involved in the process of sound perception. The following 
mutations were identified on chromosomes of mestizo NSD patients: c.35delG (34%), 
c.167delT (4,55%), c.551G> C (4,55%), c.299_300delAT (2,27%), c.314_327del14 (2,27%), 
c.109G> A (2,27%), c.95G> A (2,27%), c.101T> C (2,27%) and polymorphic variants 
c.79G> A (4,55%). c.35delG (39%) and c.299_300delAT (5,56%) mutations and 
polymorphic variant c.79G> A (11,1%) were revealed in NSD patients - Ukrainians, 
Armenians, and Mari. Thus, all the mutations and polymorphic variants detected in genes 
GJB2, GJB3, GJB6, SLC26A4, SLC26A5 and MYO7A in patients from RB are specific mainly 
for NSD patients from both European and Asian populations. The most common mutation, 
identified in chromosomes of 34% of NSD patients from RB was c.35delG mutation which 
corresponds to the literature data on high frequency of this deletion among the population of 
Europe and the Near East (Mahdieh et al., 2009). The proportion of chromosomes with 

Lilya U. Dzhemileva, Simeon L. Lobov, Dmitriy U. Kuznetzov et al. 
 
670
c.314_327del14 and c.299_300delAT was 3,94%. c.314_327del14 mutation is the second 
most common mutation in the GJB2 gene among the patients of RB (mainly among the 
patients of Tatar ethnicity). Also, c.167delT and c.235delC mutations were identified in 1% 
of NSD patients from RB. 
mtDNA mutations affecting the auditory function are mainly found in the genes encoding 
components of protein synthesizing apparatus of mitochondria - rRNA and tRNA. There are 
mutations known (m.7445A> G, m.7472insC, m.7510T> C, m.7511T> C) in tRNASer(UCN) 
gene causing nonsyndromic sensorineural deafness (NSD) and in 12S rRNA gene (m.1555A> 
G, m.1494C> T variations near nucleotide at position 961), leading to NSD, including after 
taking aminoglycoside antibiotics. Participation of these mtDNA mutations in hearing loss is 
confirmed by numerous studies (Berrettini et al., 2008). Violation of auditory function in 
carriers of m.1555A> G mutation is characterized by different age of the disease onset, 
varying degree of hearing loss and progression. m.1555A> G mutation was detected in 
samples of two family members K. (proband and her mother) of mixed ethnicity from 
Yakutia, as well as in two family members (proband, a son, and his mother) in Russian family 
from St. Petersburg. The presence of m.1555A> G mutation was verified by direct 
sequencing. In population samples of Vilyuysk Yakuts m.1555A> G mutation was found in 
population samples of Yakuts (N = 120) and it was 0,83%. m.1555A> G was not found in 
other samples of studied population. 
Three Russian unrelated patients from St. Petersburg were found to have m.961insC 
insertion. Two of them, having m.961insC mutation, had IV degree of ASD from early 
childhood after treatment of pneumonia with antibiotics. The third m.961insC patient had a 
clinical diagnosis of III-IV NSD degree. m.961insC (n) mutation was detected in RB patient 
of Tatar ethnicity diagnosed with IV degree of NSD. m.961delTinsC (n) mutation was 
detected in three patients (3 Russians) of RB diagnosed with III degree of NSD. m.961T> G 
replacement was revealed in three unrelated Russian patients, one of them (from St. 
Petersburg) was diagnosed with ASD of unknown etiology, the other two (from Altai 
Republic) had NSD of unknown etiology that occurred at an early age. m.961T> A 
replacement was detected in one Russian patient (St. Petersburg) with congenital NSD, with 
mtDNA change, what is more, such change was detected by us for the first time. m.1095T> C 
mutation (the gene 12S rRNA) was revealed by us in two individuals, Altaians: NSD patient 
with IV degree and in a healthy individual from the Altai population sample. m.1005T> C 
mutation was found in one individual from Altai population samples, and was previously 
identified in a Chinese family with hearing loss caused by the use of aminoglycosides. 
m.827A> G mutation was detected in an individual of Russian ethnicity, from samples of 
patients with ASD from St. Petersburg. He had c.35delG mutation in GJB2 gene in 
homozygous state. m.7444G>A and m.7445A>C mutations were found in two unrelated 
Russian patients with ASD and NSD (IV degree) from St. Petersburg and RB, respectively, 
and in three siblings from one Kazakh family (with progressive NSD (III degree) occurred in 
adulthood). 
Nucleotide substitution m.7444G> A in conjunction with m.1555A>G mutation (gene 
12S rRNA) with 1,33% frequency was found, for the first time, during the study of deaf 
patients from Mongolia (Pandya et al., 1999). The mechanism of pathogenic influence of 
m.7444G>A and m.7445A> C may be similar to the effects of known m.7445A> G mutation 
associated with hearing loss (Jin et al., 2007); it violates normal processing of precursor 
tRNA Ser (UCN) and mRNA of gene ND6, transcribed together from the light strand. 

Hearing Loss of Volga-Ural Region in Russia 
 
671
The prevalence of the most important GJB2 gene deletions, especially c. 35delG 
mutation, is well studied in a number of the world populations (Mahdieh et al., 2009; Kokotas 
et al., 2010c), but until recently such data on populations living in the territory of the Russian 
Federation have been limited (Anichkina et al. 2001; Khidiyatova et al., 2002; Posukh et al., 
2005, Shokarev et al., 2005; Zinchenko et al., 2007; 2008). New data obtained in our work, 
allow, to some extent, to fill in the existing information gaps on the prevalence of c.35delG, 
s.167delT and s.235delC mutations of GJB2 gene in the Volga-Ural region, Central Asia, 
North Caucasus and Yakutia. 
We studied the frequency of heterozygous carrier of c.35delG among both different 
populations of aboriginal population of the Volga-Ural region (Bashkirs, Tatars, Chuvashes, 
Mordovians, Udmurts, Komi-Permyaks) and in Russians samples. In the Turkic-speaking 
populations of the Volga-Ural region c.35delG mutation was detected with a frequency of 
1%, 0,3% and 0% in Tatars, Bashkirs and Chuvashes, respectively. Among the Finno-Ugric 
populations of the Volga-Ural region c.35delG mutation was detected with an extremely high 
frequency of 6,2% in Mordvinians, with 3,7% frequency in Udmurts and absent in Komi-
Permyaks. Previously, high frequency of c.35delG (4,4%) was found among Estonians which 
was obvious exception among the populations of Northern Europe with low frequencies of 
c.35delG (Gasparini et al., 2000). Data on the frequency of c.35delG mutations among the 
populations of Volga-Ural region, obtained by us and in other studies (Anichkina et al., 2001; 
Khidiyatova et al., 2002; Shokarev et al., 2005; Zinchenko et al., 2007; Khusnutdinova et al., 
2005; Dzhemileva et al., 2010), show variability in the frequency of heterozygous carrier 
c.35delG among indigenous populations of the Volga-Ural region. 
The frequency of heterozygous carrier c.35delG detected by us in Russians (2,2%) is 
comparable to the data obtained in other studies of the Russian population in central regions 
of Russia (Anichkina et al., 2001; Shokarev et al., 2005; Zinchenko et al., 2007; Barashkov  
et al., 2011). 
In the studied Turkic-speaking populations of Central Asia (Kazakhs, Uighurs, Uzbeks), 
c.35delG mutation of low frequency was found among Kazakhs (0,8%) and Uighurs (0,9%) 
and was not found among Uzbeks. In the Turkic-speaking populations of Siberia (Yakuts, 
Altaians) c.35delG mutation with a relatively low frequency (0,4%) was found among the 
population of Yakuts, but is not detected among the Altai population (Posukh et al., 2005). 
In the studied populations of the North Caucasus (Abkhazians, Avars, Cherkessians, 
Ingushes) c.35delG mutation was revealed only among Abkhazians (3,8%) and Cherkessians 
(1,3%). 
The spatial frequency distribution of c.35delG mutation in Eurasia created on the basis of 
the data obtained in this study and available in 2010 literature data is presented in Fig. 1. The 
obtained data on c.35delG mutation prevalence among different populations located on 
spacious areas of Eurasia, will allow, to some extent, to clarify or perhaps reconsider modern 
concepts of origin center, age and prevalence mechanisms of c.35delG mutation.  
Thus, the data obtained by us confirm the descent gradient of heterozygous carrier 
frequency of c.35delG mutations from West to East: high frequency of c.35delG among the 
populations of Eastern Europe (Belarusians, Ukrainians), intermediate c.35delG frequency is 
revealed among the populations of the Volga-Ural region and Central Asia, and minimum 
frequency of c.35delG is among Yakuts in East Siberia. 
The observed decrease gradient in c.35delG frequency generally corresponds to the data 
of comparative analysis of mtDNA strands in Finnish and Turkic-speaking populations of 

Lilya U. Dzhemileva, Simeon L. Lobov, Dmitriy U. Kuznetzov et al. 
 
672
Northern Eurasia, where reduction of Caucasoid component in the gene pool of these 
populations as observed, in the direction from West to East from Eastern Europe to Siberia 
(Khusnutdinova E. et al., 2011). 
Previously, it was shown that the frequency of c.167delT heterozygous carrier in 
Ashkenazi Jewish population samples is averagely 4,03%, reaching7.5% in some samples, 
and that there is common ancestral haplotype revealed on patients’ chromosomes carrying 
c.167delT; that may indicate the founder effect in the origin of this mutation (Lerer et al., 
2000). Prevalence of c.167delT in Eurasia is limited, mainly by the territory of the Near East, 
although this mutation is detected sporadically in other regions (Padma et al., 2009). 
In the studied populations c.167delT mutation was found in the aboregenic ethnic groups 
of the Volga-Ural region: the Chuvashes (1%) and Komi-Permyaks (2,5%). These data may 
indicate both outspread of chromosomes having c.167delT mutation of Near-Eastern origin 
among the populations of Chuvashes and Komi-Permyaks and independent occurrence of this 
mutation as c.167delT mutation was not found among the peoples neighboring to Chuvashes 
and Komis. 
 
 
Figure 1. The spatial distribution of c.35delG mutation frequency in GJB2 gene among the populations 
of Eurasia. 
During the analysis of the GJB2 gene in several Asian countries, it was found that 
c.235delC mutation is major in Japan, China, Korea and Mongolia; its frequency is 1,6% - 
20,3% on the chromosomes in the samples of deaf patients, and the frequency of 
heterozygous c.235delC carrier ranges from 0,8% to 1,3% (Han et al., 2008; Dai et al., 2009), 
but c.235delC mutation is virtually absent among the populations of South and South-East 
Asia, and it is found only sporadically in other regions of Eurasia, having a complex ethnic 
composition of the population (Snoeckx et al., 2005). 
c.235delC mutation was detected on the territory of the former Soviet Union with a 
frequency of 3,5% among the Turkic-speaking Altaians (South Siberia) (Posukh et al., 2005) 
with a frequency of 1,3% among Mordvinians (Volga-Ural region), with a frequency of 1,7% 
in the Avars, local group in the Caucasus with a complex ethnogenesis, and with a relatively 
low frequency of 0,4% in the population samples of Kazakhs. 

Hearing Loss of Volga-Ural Region in Russia 
 
673
It is interesting to note that c.235delC mutation was not detected among the Turkic-
speaking Yakuts (Eastern Siberia), although, based on the data of archaeologists, 
anthropologists and linguists, as well as taking into account the data on mtDNA and Y-
chromosome study, it is assumed that Yakuts migrated to North from their the original 
settlement on the Lake Baikal region under the pressure the Mongols expansion between the 
thirteenth and fifteenth centuries AD. 
The spatial distribution of the c.235delC mutations frequency on the territory of Eurasia 
shows c.235delC frequency descent gradient from East to West across Eurasia and 
demonstrates that the Altai-Sayan region could be a potential region of the origin of this 
mutation (Figure 2). 
Thus, results obtained by us contribute to the clarification of heterozygous carrier 
frequency of major recessive mutations c.35delG, c.235delC and c.167delT in the GJB2 
(Cx26) gene which play an important role in the development of hearing loss among the 
populations of Eurasia. The prevalence nature of these major deletions in the GJB2 gene in 
patients belonging to different ethnic groups may further be an evidence of the alleged role of 
the founder effect in the origin and prevalence of these mutations in the world populations. In 
addition, data on the frequency of occurrence of diagnostically significant mutations in the 
genes GJB2, GJB3, GJB6, SLC26A4, SLC26A5 and MYO7A in ethnically heterogeneous 
population of the Russian Federation should be considered when performing DNA diagnosis 
of hereditary hearing impairment. 
 
 
Figure 2. Spatial distribution of c.235delC mutation frequency in the GJB2 gene among the populations 
of Eurasia. 
 
REFERENCES 
 
Agzamkhodzhaev, S. (1989). Prevalence, etiology and clinical peculiarities of sensorineural 
hearing impairment in children: author's abstract of candidate dissertation for Medical 
Sciences. Moscow, 15 p. 
Altman, Ya.A., Tavartkiladze, G.A. (2003). Guidelines for Audiology. Moscow: DMK Press. 

Lilya U. Dzhemileva, Simeon L. Lobov, Dmitriy U. Kuznetzov et al. 
 
674
Anichkina, A., Kulenich, T., Zinchenko, S., Shagina, I., Polyakov, A., Ginter, E., Evgrafov, 
O., Viktorova, T., Khusnitdonova, E. (2001). On the origin and frequency of the 35delG 
allele in GJB2-linked deafness in Europe. European journal of human genetics: EJHG, 
9(2), 151-151. 
Antoniadi, T., Rabionet, R., Kroupis, C., Aperis, G.A., Economides, J., Petmezakis, J., 
Economou-Petersen, E., Estivill, X., Petersen, M.B. (1999). High prevalence in the Greek 
population of the 35delG mutation in the connexin 26 gene causing prelingual deafness. 
Clinical genetics, 55(5), 381-382. 
Barashkov, N.A., Dzhemileva, L.U., Fedorova, S.A., Teryutin, F.M., Posukh, O.L., Fedotova, 
E.E., Lobov, S.L., Khusnutdinova, E.K. (2011). Autosomal recessive deafness 1A 
(DFNB1A) in Yakut population isolate in Eastern Siberia: extensive accumulation of the 
splice site mutation IVS1&plus; 1G> A in GJB2 gene as a result of founder effect. 
Journal of human genetics, 56(9), 631-639. 
Berrettini, S., Forli, F., Passetti, S., Rocchi, A., Pollina, L., Cecchetti, D., Mancuso, M., 
Siciliano, G. (2008). Mitochondrial non-syndromic sensorineural hearing loss: a clinical, 
audiological and pathological study from Italy, and revision of the literature. Bioscience 
reports, 28(1), 49-59. 
Bessonova, L.A., Elchinova, G.I., Zinchenko, R.A. (2012). Population genetics of hereditary 
diseases in the child population of the Republic of Bashkortostan, Chuvashia, and 
Udmurtia. Russian Journal of Genetics, 48(5), 548-557. 
Bicego, M., Beltramello, M., Melchionda, S., Carella, M., Piazza, V., Zelante, L., Bukauskas, 
F.F., Arslan, E., Cama, E., Pantano, S., Bruzzone, R., D'Andrea, P., Mammano, F. 
(2006). Pathogenetic role of the deafness-related M34T mutation of Cx26. Human 
molecular genetics, 15(17), 2569-2587. 
Bors, A., Andrikovics, H., Kalmár, L., Erdei, N., Galambos, S., Losonczi, A., Füredi, S., 
Balogh, I., Szalai, C., Tordai, A. (2004). Frequencies of two common mutations (c. 
35delG and c.167delT) of the connexin 26 gene in different populations of Hungary. 
International journal of molecular medicine, 14, 1105-1108. 
Brobby, G., Muller-Myhsok, B., Horstmann, R. (1998). Connexin 26 R143W mutation 
associated with recessive nonsyndromic sensorineural deafness in Africa. New England 
Journal of Medicine, 338(8), 548-550. 
Cryns, K., Orzan, E., Murgia, A., Huygen, P.L., Moreno, F., del Castillo, I., Chamberlin, 
G.P., Azaiez, H., Prasad, S., Cucci, R.A., Leonardi, E., Snoeckx, R.L., Govaerts, P.J., 
Van de Heyning, P.H., Van de Heyning, C.M., Smith, R.J., Van Camp, G. (2004). A 
genotype-phenotype correlation for GJB2 (connexin 26) deafness. Journal of medical 
genetics, 41(3), 147-154. 
Dai, P., Yu F., Han, B., Liu, X., Wang, G., Li Q., Yuan, Y., Liu, X., Huang, D., Kang, D., 
Zhang, X., Yuan, H., Yao, K., Hao, J., He, J., He, Y., Wang, Y., Ye, Q., Yu, Y., Lin, H., 
Liu, L., Deng, W., Zhu, X., You, Y., Cui, J., Hou, N., Xu, X., Zhang, J., Tang, L., Song, 
R., Lin, Y., Sun, S., Zhang, R., Wu, H., Ma, Y., Zhu, S., Wu, B.L., Han, D., Wong, L.J. 
(2009). GJB2 mutation spectrum in 2063 Chinese patients with nonsyndromic hearing 
impairment. Journal of translational medicine, 7(1), 26. 
Denoyelle, F., Weil, D., Maw, M. (1997). Prelingual deafness: high prevalence of a 30delG 
mutation in the connexin 26 gene. Human molecular genetics, 6(12), 2173-2177. 
Duman, D., & Tekin, M. (2012). Autosomal recessive nonsyndromic deafness genes: a 
review. Frontiers in bioscience: a journal and virtual library, 17, 2213. 

Hearing Loss of Volga-Ural Region in Russia 
 
675
Dzhemileva, L.U., Barashkov, N.A., Posukh, O.L., Khusainova, R.I., Akhmetova, V.L., 
Kutuev, I.A., Gilyazova, I.R., Tadinova, V.N., Fedorova, S.A., Khidiyatova, I.M., Lobov, 
S.L., Khusnutdinova, E.K. (2010). Carrier frequency of GJB2 gene mutations c.35delG, 
c.235delC and c.167delT among the populations of Eurasia. Journal of human genetics, 
55(11), 749-754. 
Estivill, X., Fortina, P., Surrey, S., Rabionet, R., Melchionda, S., D'Agruma, L., Mansfield, 
E., Rappaport, E., Govea, N., Milà, M., Zelante, L., Gasparini, P. (1998). Connexin-26 
mutations in sporadic and inherited sensorineural deafness. The Lancet, 351(9100), 394-
398. 
Everett, L.A., Morsli, H., Wu, D.K., & Green, E.D. (1999). Expression pattern of the mouse 
ortholog of the Pendred’s syndrome gene (Pds) suggests a key role for pendrin in the 
inner ear. Proceedings of the National Academy of Sciences, 96(17), 9727-9732. 
Fishman, A.J., & Sculerati, N. (1996). Database for sensorineural hearing loss.International 
journal of pediatric otorhinolaryngology, 35(2), 155-163. 
Gasparini, P., Rabionet, R., Barbujani, G., Melçhionda, S., Petersen, M., Brøndum-Nielsen, 
K., Metspalu, A., Oitmaa, E., Pisano, M., Fortina, P., Zelante, L., Estivill, X. (2000). 
High carrier frequency of the 35delG deafness mutation in European populations. 
European Journal of Human Genetics, 8(1). 19-23. 
Hamelmann, C., Amedofu, G.K., Albrecht, K., Muntau, B., Gelhaus, A., Brobby, G.W., & 
Horstmann, R.D. (2001). Pattern of connexin 26 (GJB2) mutations causing sensorineural 
hearing impairment in Ghana. Human mutation, 18(1), 84-85. 
Han, S.H., Park, H.J., Kang, E.J., Ryu, J.S., Lee, A., Yang, Y.H., & Lee, K. R. (2008). Carrier 
frequency of GJB2 (connexin-26) mutations causing inherited deafness in the Korean 
population. Journal of human genetics, 53(11-12), 1022-1028. 
Jin, L., Yang, A., Zhu, Y., Zhao, J., Wang, X., Yang, L., Sun, D., Tao, Z., Tsushima, A., Wu, 
G., Xu, L., Chen, C., Yi, B., Cai, J., Tang, X., Wang, J., Li, D., Yuan, Q., Liao, Z., Chen, 
J., Li, Z., Lu, J., Guan, M.X. (2007). Mitochondrial tRNA Ser (UCN) gene is the hot spot 
for mutations associated with aminoglycoside-induced and non-syndromic hearing loss. 
Biochemical and biophysical research communications, 361(1), 133-139. 
Khidiyatova, I.M., Dzhemileva, L.U., Khabibullin, R.M., Khusnutdinova, E.K. (2002). 
Analysis of 35delG mutation frequency connexin gene 26 (GJB2) among the patients 
with non-syndromic autosomal recessive deafness of Bashkortostan and in populations of 
Volga-Ural region. Molecular Biology, 36(3), 438-441. 
Khusnutdinova, E., Kutuev, I. (2011). Chapter 4. Genes and Languages: Is Are There 
Correlations between MTDNA Data and Geography of Altay and Ural Languages. In 
Sergei D. Varfolomyev and Gennady E. Zaikov, Molecular Polymorphism of Man: 
Structural and Functional Individual Multiformity of Biomacromolecules (pp. 129-144). 
New York, Nova Science Publishers.  
Khusnutdinova, E.K, Dzhemileva, L.U. (2005). Molecular genetic analysis of non-syndromic 
autosomal recessive hearing loss and deafness among patients and among the populations 
of the Volga-Ural region. Herald of biotechnology of physico-chemical biology named 
after Y. Ovchinnikov, 1, 24-31. 
Kokotas, H., Grigoriadou, M., Villamar, M., Giannoulia-Karantana, A., del Castillo, I., & 
Petersen, M. B. (2010). Hypothesizing an ancient Greek origin of the GJB2 35delG 
mutation: can science meet history?. Genetic Testing and molecular biomarkers, 14(2), 
183-187. 

Lilya U. Dzhemileva, Simeon L. Lobov, Dmitriy U. Kuznetzov et al. 
 
676
Lalouel, J.M., Rao, D.C., Morton, N.E., & Elston, R.C. (1983). A unified model for complex 
segregation analysis. American journal of human genetics, 35(5), 816. 
Lerer, I., Sagi, M., Ben‐Neriah, Z., Wang, T., Levi, H., & Abeliovich, D. (2001). A deletion 
mutation in GJB6 cooperating with a GJB2 mutation in trans in non‐syndromic deafness: 
a novel founder mutation in Ashkenazi Jews. Human mutation, 18(5), 460-460. 
Lerer, I., Sagi, M., Malamud, E., Levi, H., Raas‐Rothschild, A., & Abeliovich, D. (2000). 
Contribution of connexin 26 mutations to nonsyndromic deafness in Ashkenazi patients 
and the variable phenotypic effect of the mutation 167delT.American journal of medical 
genetics, 95(1), 53-56. 
Löffler, J., Nekahm, D., Hirst-Stadlmann, A., Günther, B., Menzel, H. J., Utermann, G., & 
Janecke, A. R. (2001). Sensorineural hearing loss and the incidence of Cx26 mutations in 
Austria. European Journal of Human Genetics,9(3). 
Mahdieh, N., & Rabbani, B. (2009). Statistical study of 35delG mutation of GJB2 gene: a 
meta-analysis of carrier frequency. International journal of audiology, 48(6), 363-370. 
Man, Y.K., Trolove, C., Tattersall, D., Thomas, A.C., Papakonstantinopoulou, A., Patel, D., 
Scott, C., Chong, J., Jagger, D.J., O'Toole, E.A., Navsaria, H., Curtis, M.A., Kelsell, D.P. 
(2007). A deafness-associated mutant human connexin 26 improves the epithelial barrier 
in vitro. Journal of Membrane Biology, 218(1-3), 29-37. 
Markova, T.G., Nekrasova, N.V., Shagina, I.A., Polyakov, A.V. (2006). Genetic screening 
among children with congenital and neonatal deafness. Vestnik otorinolaringologii, 4, 9-
14. 
Mazzoli, M., Van Camp, G., Newton, V., Giarbini, N., Declau, F., Parving, A. (2003). 
Recommendations for the description of genetic and audiological data for families with 
nonsyndromic hereditary hearing impairment. Audiological Medicine, 1(2), 148-150. 
Minarik, G., Ferak, V., Ferakova, E., Ficek, A., Polakova, H., & Kadasi, L. (2003). High 
frequency of GJB2 mutation W24X among Slovak Romany (Gypsy) patients with non-
syndromic hearing loss (NSHL). General physiology and biophysics,22(4), 549-556. 
Morell, R.J., Kim, H.J., Hood, L.J., Goforth, L., Friderici, K., Fisher, R., Van Camp, G., 
Berlin, C.I., Oddoux, C., Ostrer, H., Keats, B., Friedman, T.B. (1998). Mutations in the 
connexin 26 gene (GJB2) among Ashkenazi Jews with nonsyndromic recessive deafness. 
New England Journal of Medicine,339(21), 1500-1505. 
Morton, C.C., & Nance, W.E. (2006). Newborn hearing screening—a silent revolution. New 
England Journal of Medicine, 354(20), 2151-2164. 
Mukherjee, M., Phadke, S.R., & Mittal, B. (2003). Connexin 26 and autosomal recessive non-
syndromic hearing loss. Indian Journal of Human Genetics, 9(2), 40. 
Mustapha, M., Salem, N., Delague, V., Chouery, E., Ghassibeh, M., Rai, M., ... & 
Mégarbané, A. (2001). Autosomal recessive non-syndromic hearing loss in the Lebanese 
population: prevalence of the 30delG mutation and report of two novel mutations in the 
connexin 26 (GJB2) gene. Journal of medical genetics, 38(10), e36-e36. 
Nagla, M.A., Schmidth, M., Magzoub, M., Macharia, M., Elmustafa, O.M., Ototo, B., 
Winkler, E., Ruge, G., Horstmann, R.D., Meyer, C.G. (2004). Low frequency of 
deafness‐associated GJB2 variants in Kenya and Sudan and novel GJB2 variants. Human 
mutation, 23(2), 206-207. 
Najmabadi, H., Cucci, R.A., Sahebjam, S., Kouchakian, N., Farhadi, M., Kahrizi, K., 
Arzhangi, S., Daneshmandan, N., Javan, K., Smith, R.J. (2002). GJB2 mutations in 

Hearing Loss of Volga-Ural Region in Russia 
 
677
Iranians with autosomal recessive non‐syndromic sensorineural hearing loss. Human 
mutation, 19(5), 572-572. 
Nance, W.E. (2003). The genetics of deafness. Mental retardation and developmental 
disabilities research reviews, 9(2), 109-119. 
Ouyang, X.M., Xia, X.J., Verpy, E., Du, L.L., Pandya, A., Petit, C., Balkany, T., Nance, 
W.E., Liu, X.Z. (2002). Mutations in the alternatively spliced exons of USH1C cause 
non-syndromic recessive deafness. Human genetics, 111(1), 26-30. 
Padma, G., Ramchander, P.V., Nandur, U.V., & Padma, T. (2009). GJB2 and GJB6 gene 
mutations found in Indian probands with congenital hearing impairment. Journal of 
genetics, 88(3), 267-272. 
Panakhian, V.M. (2004). Prevalence and prevention of congenital and hereditary diseases of 
ENT-organs in the Republic of Azerbaijan: author's abstract of doctorate dissertation for 
Medical Sciences. Moscow, 34 p. 
Pandya, A., Xia, X.J., Erdenetungalag, R., Amendola, M., Landa, B., Radnaabazar, J., ... & 
Nance, W. E. (1999). Heterogenous point mutations in the mitochondrial tRNA Ser 
(UCN) precursor coexisting with the A1555G mutation in deaf students from Mongolia. 
The American Journal of Human Genetics, 65(6), 1803-1806. 
Petersen, M.B., & Willems, P.J. (2006). Non‐syndromic, autosomal‐recessive deafness. 
Clinical genetics, 69(5), 371-392. 
Petit, C., Levilliers, J., & Hardelin, J.P. (2001). Molecular genetics of hearing loss.Annual 
review of genetics, 35(1), 589-645. 
Posukh, O., Pallares-Ruiz, N., Tadinova, V., Osipova, L., Claustres, M., & Roux, A.F. 
(2005). First molecular screening of deafness in the Altai Republic population. BMC 
medical genetics, 6(1), 1-7. 
Rabionet, R., Zelante, L., López-Bigas, N., D'Agruma, L., Melchionda, S., Restagno, G., 
Arbonés, M.L., Gasparini, P., Estivill, X. (2000). Molecular basis of childhood deafness 
resulting from mutations in the GJB2 (connexin 26) gene. Human genetics, 106(1), 40-
44. 
Ramchander, P.V., Nandur, V.U., Dwarakanath, K., Vishnupriya, S., & Padma, T. (2005). 
Prevalence of Cx26 (GJB2) gene mutations causing recessive nonsyndromic hearing 
impairment in India. International journal of human genetics, 5(4), 241-246. 
Shokarev, R.A., Amelina, S.S., Kriventsova, N.V. (2005). Genetic-epidemiological and 
molecular-genetic study of hereditary deafness in Rostov region. Medical genetics, 4(12), 
556-567. 
Shokarev, R.A., Zinchenko, R.A., Amelina, S.S., Elchinova, G.I. (2002). International 
conference “Anthropology at the threshold of the III millennium (Results and 
Prospects)”: The study of the prevalence of mutant genes of hereditary diseases in 
populations of Tver region. Moscow. 
Smith, R.J., Bale, J.F., & White, K.R. (2005). Sensorineural hearing loss in children. The 
Lancet, 365(9462), 879-890. 
Snoeckx, R.L., Huygen, P.L., Feldmann, D., Marlin, S., Denoyelle, F., Waligora, J., ... & 
Orzan, E. (2005). GJB2 mutations and degree of hearing loss: a multicenter study. The 
American Journal of Human Genetics, 77(6), 945-957. 
Tavartkiladze, G.A. (1996). Edinaya sistema audiologicheskogo skrininga: metodicheskie 
rekomendatsii. Moscow, 80 p. 

Lilya U. Dzhemileva, Simeon L. Lobov, Dmitriy U. Kuznetzov et al. 
 
678
Tavartkiladze, G.A., Polyakov, A.V., Markova, T.G., Lalayants, M.R., Bliznets, G.A. (2010). 
Genetic screening of hearing loss in newborns, combined with hearing screening. Vestnik 
otorinolaringologii, 3, 15-18. 
Tekin, M., & Arıcı, Z.S. (2007). Genetic epidemiological studies of congenital/prelingual 
deafness in Turkey: population structure and mating type are major determinants of 
mutation identification. American Journal of Medical Genetics Part A, 143(14), 1583-
1591. 
Tekin, M., Duman, T., Boğoçlu, G., Incesulu, A., Comak, E., Fitoz, S., ... & Akar, N. (2003). 
Frequency of mtDNA A1555G and A7445G mutations among children with prelingual 
deafness in Turkey. European journal of pediatrics, 162(3), 154-158. 
Tekin, M., Xia, X.J., Erdenetungalag, R., Cengiz, F.B., White, T.W., Radnaabazar, J., 
Dangaasuren, B., Tastan, H., Nance, W.E., Pandya, A. (2010). GJB2 mutations in 
Mongolia: complex alleles, low frequency, and reduced fitness of the deaf. Annals of 
human genetics, 74(2), 155-164. 
Tsukada, K., Nishio, S., & Usami, S. (2010). A large cohort study of GJB2 mutations in 
Japanese hearing loss patients. Clinical genetics, 78(5), 464-470. 
Vivero, R. J., Fan, K., Angeli, S., Balkany, T. J., & Liu, X. Z. (2010). Cochlear implantation 
in common forms of genetic deafness. International journal of pediatric 
otorhinolaryngology, 74(10), 1107-1112. 
Yan, D., Park, H.J., Ouyang, X.M., Pandya, A., Doi, K., Erdenetungalag, R., ... & Liu, X. Z. 
(2003). Evidence of a founder effect for the 235delC mutation of GJB2 (connexin 26) in 
east Asians. Human genetics, 114(1), 44-50.Aplin, J.D., (1991). Implantation, trophoblast 
differentiation and hemochorial placentation, Mechanistic evidence in vivo and in vitro. J. 
Cell. Sci. 99, 681-692. 
Zinchenko, R.A., Osetrova, A.A., & Sharonova, E.I. (2012). Hereditary deafness in Kirov 
oblast: estimation of the incidence rate and DNA diagnosis in children. Russian Journal 
of Genetics, 48(4), 455-462. 
Zinchenko, R.A., Amelina, S.S., Shokarev, R.A., Valkov, R.A., Valkova, T.I., Vetrova, N.V., 
Kriventsova, N.V., Elchinova, G.I., Petrova, N.V., Khlebnikova, O.V. (2009). 
Epidemiology of monogenic hereditary diseases in Rostov oblast: Population dynamic 
factors determining the differentiation of the load of hereditary diseases in eight districts. 
Russian journal of genetics, 45(4), 469-477. 
Zinchenko, R.A., Elchinova, G.I., Baryshnikova, N.V., Polyakov, A.V., Ginter E.K. (2007). 
Features of hereditary diseases in different populations of Russia. Genetics, 43(9), 1246-
1254. 
Zinchenko, R.A., Elchinova, G.I., Vetrova, N.V., Amelina, M.A., Petrin, A.N., Amelina, S.S. 
(2012). Epidemiology of hereditary diseases among the children’s population in 12 
districts of the Rostov region. Burdening with hereditary diseases and genetic structure of 
the population. Medical Genetics, 12(5), 21-28. 
Zinchenko, R.A., Morozova, A.A., Galkina, V.A., Khidiyatova, I.M., Khlebnikova, O.V., 
Kononov, A.B., Fedotov, V.P., Khusainova, R.I., Akhetova, V.L., Jemileva, L.U., 
Schagina, O.A., Khusnutdinova, E.K., Ginter, E.K. (2007). Medical and genetic study of 
the population of the Republic of Bashkortostan. Report II. Variety of hereditary diseases 
in three districts of the Republic. Medical Genetics, 6(6), 17-21. 

Hearing Loss of Volga-Ural Region in Russia 
 
679
Zinchenko, R.A., Suvorova, K.N., Abrukova, A.V., Rogaev, E.I., Ginter, E.K., Chernova, 
T.A. (2008). Epidemiological, clinical and genetic study of hereditary hypotrichosis. 
Journal of Dermatology and Venereology, 1, 43-50. 
 
 
 


In: Encyclopedia of Audiology and Hearing Research 
ISBN: 978-1-53617-702-2 
Editors: Erno Larivaara and Senja Korhola 
© 2020 Nova Science Publishers, Inc. 
 
 
 
 
 
 
 
Chapter 47 
 
 
 
SUDDEN SENSORINEURAL HEARING LOSS,  
AN INVISIBLE MALE: STATE OF THE ART 
 
 
Rizzo Serena1, MD, Daniela Bentivegna1, MD,  
Ewan Thomas2, PhD, Eleonora La Mattina1 (Tax advisor), 
Marianna Mucia1, MD, Pietro Salvago1, MD, Federico Sireci1, MD 
and Francesco Martines1,, PhD  
1University of Palermo, Bio. Ne. C. Department, ENT Section., Palermo Italy 
2Sport and Exercise Sciences Research Unit, University of Palermo, Italy 
 
 
Sudden sensorineural hearing loss (SSNHL), identified by Dekleyn in 1944, is an 
important otological disorder. It is characterized by a hearing loss greater than 30 dB over 
three consecutive frequencies, in less than 72 hours, with no identifiable etiology. It is a real 
sensorineural emergency that can become a permanent handicap if not adequately treated.  
SSNHL has a prevalence of 5-20 in 100,000 inhabitants. Because of patients recovering 
rapidly or seeking no medical attention, the true figure might be higher. Sudden hearing loss 
occurs typically between 50 and 60 years of age and the lowest among 20-30. The prevalence 
of SSNHL is not significantly different between men and women [1, 2, 3]. There are many 
potential causes of SSNHL, but despite extensive evaluations, the majority of cases elude 
definitive diagnosis and therefore, remain idiopathic. Reports estimate that the etiology of 
SSNHL is diagnosed in only 10% of cases. 
Therapy for SSNHL is a subject of controversy and the unknown etiology justifies 
heterogeneous therapeutic approaches, on one hand therapies’ aim is to correct the primary 
risk factors (smoke, diabetes, hypertension, previous viral or bacterial infection), on the other 
the purpose is to act on the main etiopathogenetic hypotheses (viral infection, immunologic, 
vascular compromise). 
Among the many treatments proposed, the glucocorticoids are the most adopted, but with 
different routes of administration: oral steroid, intratympanic steroid therapy and their 
                                                        
 Corresponding Author’s Email: francescomartines@hotmail. com. 

Rizzo Serena, Daniela Bentivegna, Ewan Thomas et al. 
 
682
combinations. Therefore, it is very important to establish an international therapeutic 
protocol.  
 
 
ETIOLOGY 
 
The etiology of SHL can be broken down into broad categories: viral and infectious, 
autoimmune, labyrinthine membrane rupture/traumatic, vascular, neurologic, and Neoplastic. 
There are multiple conditions within each of these categories that have been associated with 
sudden hearing loss. The following is a partial list of reported causes of SHL [4, 5, 6, 7]: 
 
Infectious 
 
Meningococcal meningitis 
Herpesvirus (simplex, zoster, varicella, cytomegalovirus 
Mumps 
Human immunodeficiency virus 
Lassa fever 
Mycoplasma 
Cryptococcal meningitis 
Toxoplasmosis 
Syphilis 
Rubeola 
Rubella 
Human spumaretrovirus 
 
Autoimmune  
 
Autoimmune inner ear disease (AIED) 
Ulcerative colitis 
Relapsing polychondritis 
Lupus erythematosus 
Polyarteritis nodosa 
Cogan’s syndrome 
Wegener’s granulomatosis 
 
Traumatic  
 
Perilymph fistula 
Inner ear decompression sickness 
Temporal bone fracture 
Inner ear concussion 
Otologic surgery (stapedectomy) 
Surgical complication of nonotologic surgery 
 
Vascular 
 
Vascular disease/alteration of microcirculation 
Vascular disease associated with mitochondriopathy 
Vertebrobasilar insufficiency 
Red blood cell deformability 
Sickle cell disease 
Cardiopulmonary bypass 

Sudden Sensorineural Hearing Loss, an Invisible Male 
 
683
Neurologic 
 
Multiple sclerosis 
Focal pontine ischemia Migraine 
 
Neoplastic 
 
Acoustic neuroma 
Leukemia 
Myeloma 
Metastasis to internal auditory canal 
Meningeal carcinomatosis 
Contralateral deafness after acoustic neuroma surgery 
 
 
CLINICAL DIAGNOSIS 
 
The clinical diagnosis in based on: 
 
1) history 
2) audiometry 
3) tympanometry, including stapedial reflex testing 
4) auditory evoked potentials 
 
1. The history, alone, allows immediate diagnosis. Details of the circumstances 
surrounding the SHL, the time course of its onset, the associated symptoms, such as tinnitus, 
vertigo or dizziness, and aural fullness should be asked. Clinical experience has shown that 
about 77% of patients will have associated with tinnitus and 33% vertigo [9, 10]. Moreover, 
patients should also be questioned about: 
 
1. otologic surgery 
2. drugs use 
3. viral infections 
4. systemic diseases: hypercoagulable states, diabetes and autoimmune disorders [11,12] 
 
2. An audiogram (pure tone relative to the frequencies 125, 250, 500, 1000, 2000, 4000, 
8000 Hz, according to the “International Organization for Standardization”: ISO) is 
fundamental and should be performed on all patients with SHL, in fact, the audiogram is the 
foundation of the diagnosis and the audiogram’s morphology provides prognostic information 
(Figure 1).  
3. The tympanogram and stapedial reflexes directed towards a topographic diagnosis of 
hearing loss. 
4. Tests are complete, when the hearing threshold allows, by auditory evoked potentials, 
because they can direct you to a pathology of the acoustic-facial package. 
 

Rizzo Serena, Daniela Bentivegna, Ewan Thomas et al. 
 
684
 
Figure 1. Most common types of curve. 
 
PATHOPHISIOLOGY OF THE SUDDEN HEARING LOSS 
 
Although we can recognize only 10% of the causes of SHL, it would appear 
that at the base there is a hypoxic condition that causes a cell damage. 
 
 
PATHOPHISIOLOGY OF THE SUDDEN HEARING LOSS:  
VASCULAR THEORY  
 
The inner ear vasculature being terminal, makes this organ at particular risk for a hypoxic 
and the resulting clinical picture turns out to be closely related to the physiology of the 
sprayed area. Must also not surprising that the circulatory system cochleo-vestibular can be 
affected by: 
 
 
increased blood and plasma viscosity 
 
sludge effect 
 
spasms and release of vasoactive substances 
 
embolism and thrombosis 
 
 
PATHOPHISIOLOGY OF THE SUDDEN HEARING LOSS: VIRAL THEORY 
 
The first to take into serious consideration this theory was van Dishoeck in 1957[13]. The 
mechanisms proposed to explain how viral infection can lead to sudden hearing loss are three 
(Figure 2):  

Sudden Sensorineural Hearing Loss, an Invisible Male 
 
685
1. direct invasion of the virus in the tissues of the inner ear or cochlear nerve through 
the bloodstream, cerebrospinal fluid, or middle ear 
2. reactivation of a latent virus in the inner ear tissues: it has been hypothesized, in fact, 
that neurotropic virus, can infect the cochlear neurons, can remain latent and and 
reactivate causing a cocleite or neuritis, leading to sudden deafness 
3. a systemic viral infection stimulates an antibody reaction that causes a cross-reaction 
with an antigen of the inner ear 
 
 
 
A vascular deficiency in the cochlear artery determines an 
insult of the medium and apical part of the cochlea, 
therefore will only auditory symptoms with audiometric 
deficit at the expense of medium and low tones. 
A vascular deficiency in the vestibular-cochlear artery 
determines an insult of the basal part of the cochlea, 
therefore will auditory symptoms with audiometric deficit 
at the expense of high tones associated at vertigo. 
 
A vascular deficiency in the vestibular artery determines an important vertiginous symptoms vertiginous symptoms caused 
by damage to the three semicircular canals. 
Figure 2. Occlusion cochlear, vestibular-cochlear and vestibular artery. From: http://www.orl.uniroma2. 
it/ischemia.htm. 
 
PATHOPHISIOLOGY OF THE SUDDEN HEARING LOSS:  
AUTOIMMUNE THEORY 
 
McCabe first described autoimmune inner ear disease (AIED) in 1979 [14]. The 
immunological hypothesis of the sudden of hearing loss is based on the movement of cross-
reacting antibodies with internal antigens or on the activation of T cells that act directly on the 
inner ear. A group of antigens have been proposed as targets, such as collagen type 2, β-actin, 
the coclina, the β-tectorina, cochlear proteins P30 and P80, the cardiolipidi, phospholipids, 
serotonin and ganglioside. The most documented is the CTL2 protein (choline transporter-like 
protein 2). Finally, in favor of an autoimmune process it has been observed a higher 

Rizzo Serena, Daniela Bentivegna, Ewan Thomas et al. 
 
686
frequency of allele’s human leucocyte antigen (HLA) in patients who respond well to 
treatment with corticosteroids [15, 16, 17, 18, 19]. 
 
 
TREATMENT 
 
Therapy for SSNHL is a subject of controversy and the unknown etiology justifies 
heterogeneous therapeutic approaches. Below is a list of treatment modalities which have 
been used and some of which are currently used today for the treatment of ISSNHL: 
 
Antiinflammatory/immunologic 
agents   
 
 
 
Steroids 
Prostaglandin 
Cyclophosphamide 
Methotrexate 
 
Diuretics  
 
Hydochlorothiazide/ 
triamterene 
Furosemide 
 
Antiviral agents   
 
 
Acyclovir 
Valacyclovir 
 
Vasodilators  
 
 
 
Carbogen 
Papaverine 
Buphenine  
Naftidrofuryl  
Thymoxamine 
Prostacyclin 
Nicotinic acid 
 
 
 
 
 
 
Pentoxifylline 
 
Volume expanders/hemodilutors   
Hydroxyethyl starch 
Low-molecular-weight dextran 
 
Defibrinogenators 
 
 
Batroxobin 
 
Calcium antagonists  
 
 
Nifedipine 
 
 
Other agents and procedures  
 
Amidotrizoate 
Acupunture 
Iron 
Vitamins 
 
 
 
 
 
 
Procaine 

Sudden Sensorineural Hearing Loss, an Invisible Male 
 
687
Among the many treatments proposed, the glucocorticoids are the most adopted, but with 
different routes of administration: oral steroid, intratympanic steroid therapy and their 
combinations [20]. 
 
 
PROGNOSIS 
 
Clinical experience shows that the total recovery of hearing function is reported in about 
25% of cases, in 50% will have a partial recovery and a 25% damage instead remains 
definitively [21, 22, 23]. According to a review carried out in Sicily of 270 patients can be 
identified the following prognostic factors: 
 
 
TYPE OF THERAPY: intratympanic steroids associated with systemic steroid therapy 
is the best treatment approach 
 
TYPE OF CURVE: the upward curve has a greater margin for improvement 
 
HYPERTENSION: patients with hypertension have a smaller chance of recovery 
 
VERTIGO: Patients with severe vertigo had significantly worse outcomes than 
patients with no symptoms 
 
OAE: if OAE’s are present, prognosis is better [25]  
 
 
CONCLUSION 
 
Sudden sensorineural hearing loss is a chapter of great interest to the otolaryngology for 
the clinical relevance its possible outcomes by affecting the quality of life of relationships, 
both social and work of the patients affected that are isolated from the outside world. Despite 
various histopathological, clinical and therapeutic contributions, the etiology, the 
pathogenesis, diagnosis and therapy of this disease are still undefined and have contrasting 
aspects. The increased incidence, described by case studies reported in the literature, probably 
due to new and more widespread pathological noxae and the emergence of new therapeutic 
protocols make this topic very timely. Finally, in accordance with the literature you should 
always treat sudden hearing loss, because all treatments, although with different margins for 
improvement, give an auditory functional recovery, improving the patient’s quality of life.  
 
 
REFERENCES 
 
[1] 
Gignoux M., Martin H., Cajgfinger H., Les surdites brusques. J. Med. Lyon. 1973; 
44/1043, 1701-1718. 
[2] 
Tran Ba Huy P., Bastian D., Ohresser M., Anatomie de l’oreille interne. Encycl. Med. 
Chir. Paris 1980; ORL 20020 A 10. 
[3] 
De Kleyn A., Sudden complete or partial loss of function of the octavus-system in 
apprerently normal persons. Acta Otolaryngol (Stockh) 1994; 32: 407-429. 

Rizzo Serena, Daniela Bentivegna, Ewan Thomas et al. 
 
688
[4] 
Martines F., Ballacchino A., Sireci F., Mucia M., La Mattina E., Rizzo S., Audiologic 
profile of OSAS and simple snoring patients: the effect of chronic nocturnal 
intermittent hypoxia on auditory function, European Archives of Oto-Rhino-
Laryngology 2016; 273: 1419-1424. 
[5] 
Martines F., Messina G., Patti A., Battaglia G., Bellafiore M., Messina A., Rizzo S., 
Salvago P., Sireci F., Traina M., Iovane A., Effects of tinnitus on postural control and 
stabilization: A pilot study, Acta Medica Mediterranea 2015; 31: 907-912. 
[6] 
Ferrara S., Salvago P., Mucia M., Ferrara P., Sireci F., Martines F., Follow-up after 
pediatric myringoplasty: Outcome at 5 years, Otorinolaringologia 2014; 64: 141-146. 
[7] 
Cannizzaro E., Cannizzaro C., Plescia F., Martines F., Soleo L., Pira E., Lo Coco D., 
Exposure to ototoxic agents and hearing loss: A review of current knowledge, Hearing, 
Balance and Comunication 2014; 12: 166-175. 
[8] 
Gagliardo C., Martines F., Bencivinni F., Latona G., Casto A.L.O., Midiri M., 
Intratumoral Haemorrhage Causing an Unusual Clinical Presentation of a Vestibular 
Schwannoma, Neurualradiology Journal 2013; 26: 30-34. 
[9] 
Kiris M, Cankaya H, Icli M, Kutluhan A., Retrospective analysis of our cases with 
sudden hearing loss. J. Otolaryngol. 2003; 32: 384-7. 
[10] Martines F., Dispenza F., Gagliardo C., Martines E., Bentivegna D., Sudden 
sensorineural hearing loss as prodromal symptom of anterior inferior cerebellar artery 
infarction, ORL 2011; 73: 137-140. 
[11] Wilson W.R., Laird N., Moo-Young G., Soeldner J.S., Kavesh D.A., MacMeel J.W., 
The relationship of idiopathic sudden hearing loss to diabetes mellitus, Laryngoscope 
1982; 92: 155-60. 
[12] Campbell KC, Klemens JJ., Sudden hearing loss and autoimmune inner ear disease, J. 
Am. Acad. Audiol. 2000; 11: 361-7. 
[13] Van Dishoeck H., Bierman T., Sudden perceptive deafness and viral infection (report of 
the first one hundred patients), Ann. Otol. Rhinol. Laryngol. 1957; 66: 963-980. 
[14] McCabe, Brian F., Autoimmune inner ear disease: results and therapy, Adv. 
Otorhinolaryngol. 1991; 46:78-81. 
[15] Boulassel MR, Deggouj N, Tomasi JP, Gersdorff M., Inner ear autoantibodies and their 
targets in patients with autoimmune inner ear diseases, Acta Otolaryngol. 2001; 121: 
28-34. 
[16] Solares C.A., Edling A.E., Johnson J.M., Baek M.J., Hirose K., Hughes G.B., Tuohy 
V.K., Murine autoimmune hearing loss mediated by CD4+ T cells specific for inner ear 
peptides. J. Clin. Invest. 2004; 113: 1210-1217. 
[17] Nair T.S., Kozma K.E., Hoefling N.L., Kommareddi P.K., Ueda Y., Gong T.W., Lomax 
M.I., Lansford C.D., Telian S.A., Satar B., Arts H.A., EI-Kashlan H.K., Berryhill W.E., 
Raphael Y., Carey T.E., Identification and characterization of choline transporter-like 
protein 2, an inner ear glycoprotein of 68 and 72 kDa that is the target of antibody 
induced hearing loss, J. Neurosci. 2004; 24: 1772-1779. 
[18] Adams L.E., Clinical implications of inflammatory cytokines in the cochlea: a technical 
note, Otol. Neurotol. 2002; 23:316-322. 
[19] Disher M.J., Ramakrishnan A., Nair T.S., Miller J.M., Telian S.A., Arts H.A., Sataloff 
R.T., Altschuler R.A., Raphael Y., Carey T.E., Human autoantibodies and monoclonal 
antibody KHRI-3 bind to a phylogenetically conserved inner ear supporting cell 
antigen, Ann. NY Acad. Sci. 1997; 830: 253-265. 

Sudden Sensorineural Hearing Loss, an Invisible Male 
 
689
[20] Wilson, Willimam R., Byl, Frederick M., and Laird, Nan, The efficacy of steroids in the 
treatment of idiopathic sudden hearing loss, Archives of Otolaryngology 1980; 106:772-
776 (Dec.). 
[21] Lazarini PR, Camargo AC., Idiopathic sudden sensorineural hearing loss: 
etiopathogenic aspects. Braz. J. Otorhinolaryngol. 2006; 72:554-61. 
[22] O’Malley M.R., Haynes D.S., Sudden hearing loss, Otolaryngol. Clin. North Am. 2008; 
41:633-49. 
[23] Rauch SD., Idiopathic sudden sensorineural hearing loss, N. Engl. J. Med. 2008; 359: 
833-840. 
[24] Salvago P., Rizzo S., Bianco A., Martines F., Int. J. Audiol. 2016; Epub ahead of print. 
[25] Schweinfurth J. M. and others, Clinical applications of otoacoustic emissions in sudden 
hearing loss, Laryngoscope 1997; 107: 1457-1463. 


In: Encyclopedia of Audiology and Hearing Research 
ISBN: 978-1-53617-702-2 
Editors: Erno Larivaara and Senja Korhola 
© 2020 Nova Science Publishers, Inc. 
 
 
 
 
 
 
 
Chapter 48 
 
 
 
THE INFLUENCE OF SOUNDS IN POSTURAL CONTROL 
 
 
E. Thomas1, A. Bianco1, G. Messina1,2, M. Mucia3,  
S. Rizzo3, P. Salvago3, F. Sireci3, A. Palma1  
and F. Martines3 
1Sport and Exercise Sciences Research Unit, University of Palermo, Palermo, Italy 
2Posturalab, Italy 
3Bio.Ne.C. Department, ENT Section, University of Palermo, Palermo, Italy 
 
 
ABSTRACT 
 
Postural control is a polisensory system based on the synergism of visual, 
proprioceptive (kinaesthetic), auditory and labyrinthic (both otolithic and canalar) inputs. 
Each individual, according to age, organizes different somato-sensorial strategies in 
order to manage postural control. Therefore the prevalence of visual, auditory, 
proprioceptive and labyrinthic input management varies from subject to subject during 
growth. 
It is known that during the first year of age, before the achievement of an erect 
posture, this latter is mainly managed according to auditory and labyrinthic stimuli, 
whereas once the bipodalic stance is achieved, afferent proprioceptive information from 
the foot and from the paravertebral muscles become the main stimuli for static postural 
control and visual input for dynamic postural control. 
This shift depends on the development of anatomical and physiological systems. 
Because of the anatomical contiguity of the phonoreceptor and the vestibular organs, 
auditory inputs can influence postural control in the form of a wave of disturbances 
which affects the vestibular system and general postural control. In addition, afferent 
auditory pathways synapse to the inferior colliculus in the mesencephalon that through 
the anterior tectospinal tract together to the superior colliculus, that receive visual inputs, 
synapse to the superior olivary complex that through the olivocerebellar tract synapses in 
the cerebellum, that is the organ mainly responsible for postural control. Therefore, the 
aim of this work will be to elucidate the role of sounds in postural control. 
 
 
 

E. Thomas, A. Bianco, G. Messina et al. 
 
692
INTRODUCTION 
 
Balance is a common term used by health professionals to indicate a wide variety of 
aspects. Such term is often used to indicate, or is associated to the words, stability and 
postural control. The ability of the body to balance is related to its center of mass and the area 
of the base of the body balancing. If the line of gravity falls in the base of the object then the 
object is in balance. If the line of gravity falls out of the base of the object then it will result in 
an imbalance and in case of a person this will fall. In order to increase the stability of an 
object it will be necessary to act on the base of the object or on the center of gravity. In 
Humans, though it is not possible to act on the center of gravity or on the base, thus human 
beings need to control balance through postural control, in order to allow the center of gravity 
to fall in its base. Human stability can be defined as the ‘inherent ability’ of a person to 
maintain, achieve or restore a state of balance, but in this case the ‘inherent ability’ 
encompasses the sensory and motor systems of the person [1]. According to a mechanistic 
approach a body can be stable or unstable. It is labeled stable when the structures are in 
equilibrium with each other and from a stationary position these return stationary after a 
perturbation. The human sensory motor system in order to allow the body to be defined stable 
must develop forces to oppose the external perturbation. This means that the human body in 
order to be defined stable needs to pass from an unstable state to its initial stable state, thus, 
human equilibrium is defined transient disequilibrium or dynamic equilibrium [2].  
The anatomical and physiological components that allow postural balance are the 
musculoskeletal, visual, vestibular and proprioceptive systems and a continuous interaction 
between these systems is needed to allow proper balance [3, 4]. 
The vestibular system, a sensory apparatus located in the inner ear, is the main 
anatomical component that allows the body to maintain its postural equilibrium. The 
vestibular system is also essential to control the position of the head and the movement of the 
eyes [5]. 
The vestibular system is located within cavities that lie inside the temporal bone know as 
the labyrinth. Within the inner ear there are also the semicircular canals and the cochlea.  
There are three semicircular canals: superior, horizontal and posterior, according to their 
position. The superior and posterior canals are both on a vertical plane whereas the horizontal 
canal is on a horizontal plane. Each canal has at his end an expanded area called the ampulla 
that opens into the vestibule. Each canal with its ampulla enters the vestibule in a different 
position. Each canal and their ampulla encloses a membranous semicircular duct that follows 
the same pattern as the canals and the ampulla in the bony labyrinth. Each semicircular canal 
is filled with endolimph and surrounded by perilymph. 
Within the vestibules there are the utricle and the saccule, known as the otolith organs. 
Each sac has in its inner surface a single patch of sensory cells called macula. Each macula 
consists of fine hair bundles which are covered by an otolithic membrane that is jelly-like and 
covered by a blanket of calcium crystals. In the utricle, the macula projects from the anterior 
wall of the tubular sac and lies in the horizontal plane whereas in the saccule the macula is on 
a vertical plane, directly over the bone of the inner ear of the vestibule. Each macula consists 
of an epithelium of sensory cells as well as a membrane of nerve fibers and nerve endings. 
The sensory cells of this epithelium are called hair cells. The nerve fibers are part of the 
vestibule-cochlear nerve. 

The Influence of Sounds in Postural Control 
 
693
When the head changes position, the hair bundles are deflected by the calcium crystals 
and the hair cells change the rate of nervous impulse through the vestibular nerves to the brain 
stem. 
The semicircular canals, respond to rotational movements (angular acceleration) whereas 
the utricle and saccule within the vestibule, respond to changes in the position of the head 
with respect to gravity (linear acceleration). The information these organs deliver is 
proprioceptive in character, dealing with events within the body. Abnormal vestibular signals 
cause the body to try to compensate by making adjustments in the posture of the trunk and 
limbs as well as making changes in eye movements to adjust sight inputs into the brain. 
The other organ located within the inner ear is the cochlea, that may be defined as the 
sensory organ of hearing. The way this organ transmits the sound is through the cochlear 
nerve, a short division of the vestibule-cochlear nerve. The information this organ delivers is 
exteroceptive in nature, delivering sound information from an external source and converting 
this in action potentials. 
Functionally these organs are closely related to the cerebellum and to the reflex centres of 
the spinal cord and brain stem that govern the movements of the eyes, neck, and limbs [6]. 
The vestibulos and the cochlea are anatomically in continuity, meaning that sound and 
balance, are closely related. 
 
 
ANATOMICAL ELEMENTS OF SOUND AND POSTURAL CONTROL 
 
To maintain a certain posture, there must be a control center that activates antigravitary 
muscles, this is generally provided by the somatic motor system. The somatic motor system 
needs to control both axial musculature and limb muscles. Because muscles never act alone 
but always in combination with other muscles, premotor interneurons play a crucial role in 
motorneuron control. Premotor interneural activation can be distinguished in medial for the 
axial muscle motorneurons whereas these become unilateral for the distal muscle 
motorneurons [7]. The reason for this difference is that proximal and axial movements, in 
contrast to the distal movements, are almost always bilaterally organized. 
The pathways of the medial system originate in cell groups belonging to the brain stem. 
Part of the medial tract are the reticulospinal pathways that originate from the medial 
tegmental fields of the caudal pons and the vestibulospinal pathway. The vestibulospinal 
pathway sends fibers ipsi- and controlaterally through the spinal cord where the neck muscles 
premotor and motor neurons are located. This means that the vestibulospinal pathway is 
actively involved in controlling the head, and the neck during postural control. Other function 
of the vestibulospinal tract is to control the extrinsic eye movements [8]. The eyes during 
postural control are also controlled by the pontine reticular formation, and the superior 
colliculus. These two formations are responsible for head, trunk and eye movements. 
Interestingly the inferior colliculus, that receive, visual, somatosensory and auditory 
information, project to the pontine reticular formation through the tectobulbospinal tract, and 
to certain premotor neurons involved in horizontal head movements [9]. This is the 
anatomical relation between, posture, sound and visual information, that together allow a 
human being to control posture. Therefore, proprioception, sounds and visual input are 
fundamental for a proper postural control.  

E. Thomas, A. Bianco, G. Messina et al. 
 
694
As afore mentioned in the previous paragraph the main organ responsible for equilibrium 
is the vestibule. This is innervated by the vestibular nerve, a branch of the vestibule-cochlear 
nerve. The vestibular part of the nerve synapses on the premotor neurons of the brain stem 
that then ends on a set of neurons located in the vestibular ganglia. Some projections from the 
vestibular ganglia reach the nuclear vestibular complex. This is functionally divided in two 
areas, the rostral portion that has the function to detect angular accelerations from afferens 
from the semicircular canals and from the head and the eyes and the ventral portion that is 
mainly related to postural control and muscle tone [10]. The vestibular nerve is also directly 
connected to the cerebellum through the inferior cerebellar peduncle [10]. 
The two nuclei of the vestibular complex are connected to each other and also receive 
ascending and discendig connections. One of the most important ascending connections is 
that with the longitudinal medial fascicle that goes to the ventrobasal complex of the thalamus 
with fibers direct to the parietal ascendent gyrus that allow the vestibular inputs to be 
conscious. Other portions of the vestibular nerve go to the nuclei of the oculomotor, throclear 
and abducent nerve, and together generate the vestibulomotor reflex, that allows 
compensation for head and eye movements during voluntary movements [10]. From the 
medial vestibular nuclei originates the medial vestibulospinal fascicle that discends bilaterally 
to the α e γ motorneurons of the cervical tract that allow the vestibulospinal reflex that is 
responsible for head stability during movements from vestibular stimuli. Lesions to the 
vestibulocochlear nerve may lead to dizziness, nistagmus, tinnitus or hearing loss. All these 
pathologies related to the vestibule-cochlear nerve lead to postural disorders or impairments 
[11]. 
 
 
SOUND AND INNER EAR 
 
A sound is defined as a vibration produced by a vibrating object that produces pulses of 
vibrating air molecules. The ear can distinguish different aspects of sound such as pitch and 
loudness. 
Pitch describes the characteristic of the sound wave that in human beings lays between a 
range of frequencies of 20 to 20.000 Hertz. The range of maximum sensitivity and audibility 
diminishes with age. Loudness is the perception of the intensity of sound, or in other words 
the pressure of the sound wave on the tympanic membrane [12]. The loudness is expressed in 
decibels and on such scale human hearing extends from 0 to 130 decibels, at such level the 
sound becomes painful. The head acts as a barrier between the two ears and thus a sound 
source at one side will produce a more intense stimulus of the ear nearest to it and 
incidentally the sound will also arrive there sooner, helping to provide a mechanism for sound 
localization based on intensity and time of arrival differences of sounds, thus helping postural 
control [13].  
The ear canal acts as a resonating tube and actually amplifies sounds between 3000 and 
4,000 Hz adding sensitivity to the ear at these frequencies. The ear is very sensitive and 
responds to sounds of very low intensity, to vibrations which are hardly greater than the 
natural random movement of molecules of air [14]. To do this the air pressure on both sides 
of the tympanic membrane must be equal. The outer and middle ears serve to amplify the 
sound signal and they do so at intensities of about 30db . 

The Influence of Sounds in Postural Control 
 
695
The function of the inner ear is to transduce vibration into nervous impulses. While doing 
so, it also produces a frequency and intensity analysis of the sound. Nerve fibers can fire at a 
rate of just under 200 times per second. Sound level information is conveyed to the brain by 
the rate of nerve firing, for example, by a group of nerves each firing at a rate at less than 200 
pulses per second. They can also fire in locked phase with acoustic signals up to about 5 kHz. 
At frequencies below 5 kHz, groups of nerve fibers firing in lock phase with an acoustic 
signal convey information about frequency to the brain. Above about 5 kHz frequency 
information conveyed to the brain is based upon the place of stimulation on the basilar 
membrane. So when the sound reaches the tympanum this vibrates and such vibration causes 
the motion of the bones in the middle ear (malleus, incus and stirrup). The ossicles amplify 
the sound and send sound waves to the inner ear and into the cochlea. Once the sound reaches 
the inner ear this is converted in electrical impulses and these translated in the brain to sound 
[12]. 
 
 
THE INFLUENCE OF SOUND ON POSTURAL CONTROL 
 
Because the phonoreceptors and the vestibular organ are situated anatomically close to 
each other, sound vibrations can influence posture control [15, 16]. The anatomical proximity 
of the vestibular labyrinth to the acoustic-energy delivery system, the great similarity in 
cochlear and vestibular hair-cell ultrastructure, the fact that both balance and auditory 
receptors share the membranous labyrinth, and the common arterial blood supply of the 
cochlea and vestibular end organs via the same end artery, all support the possibility of sound 
influencing postural control or causing vestibular symptoms [24]. There is also a condition 
known as superior semicircular canal dehiscence, a defect in the temporal bone between the 
apex of the superior semicircular canal and the middle cranial fossa, that induces vestibular 
responses to sounds [17]. These responses are known as the “Tullio phenomenon”. When 
exposed to sounds, patients that suffer from this condition exhibit dizziness, nausea, vomit or 
nistagmus. This condition may also be caused by trauma or a result of a surgical operation. 
Two types of mechanisms are involved in the destruction of the end organs by noise: direct 
mechanical destruction, and metabolic decompensation with subsequent degeneration of 
sensory elements [25]. A sudden sound provokes destabilization of the upright body posture, 
which results in greater increase in postural sway [16].  
Sound loudness, frequency and sound duration in order to elicit postural responses 
however need to be of a certain intensity. A postural response may be considered either as an 
increase of the length of the stabilogram or a decrease of such length. In addition, depending 
on the source of the auditory stimulus the postural response may vary on a frontal or sagittal 
plane. To be noted, all the comparisons present in scientific literature refer to postural 
responses with and without sound sources, meaning that any variation is always compared to 
the correspondent unbiased measure. Sound sources may increase or decrease the amplitude 
of the oscillations of the stabilogram compared to the stabilogram obtained in silence [18].  
The lengths of the sway has been shown to increase according to increases in the 
frequency of the sound, with higher disturbances around 4000 Hz frequencies, only in the 
anterior-posterior axis. Also the position of the center is pressure is influenced by sound 
frequency [3]. At frequencies of around 2000Hz the length of the sway and the position of the 

E. Thomas, A. Bianco, G. Messina et al. 
 
696
center of pressure seem to be at a minimum variability. Sound seems to affect postural control 
with frequencies ranging between 1000 and 4000 Hz [15]. Higher frequency sounds are able 
to affect postural control. In addition postural responses are greater when a loud sound 
(greater than 90 dB) is applied independently from the frequency of delivery.  
In humans an acoustic stimulus of 500 Hz at 90 dB applied monoaureally may also be 
able to lead to postural responses [22]. It doesn’t seem that sounds of intensities below 90 dB 
are able to affect postural control. Fourier analysis of postural sway demonstrates that low 
frequency oscillations in the postural sway during sound-stimulus at 500 Hz are mainly under 
the influence of the vestibular control, whereas higher frequencies are mainly under 
proprioceptive control during antero-posterior sway [19].  
Sound pressure level influences postural control in normal subjects [3]. The influence of 
sound on postural control seems to be dependent on the intensity of the stimulus. A constant 
tone above 95dB can produce a postural deviation towards the stimulated ear [20]. There is 
physiological evidence that vestibular neurons increase their firing rate in response to loud 
sounds [20]. An increase in the sound amplitude will initially activate irregular otholitic 
neurons, but few semicircular canals that will only be activated at very high intensities [20]. 
However, sounds of low intensities are seen to be able to evoke postural responses in blind 
people [21]. To be noted that normal speaking ranges are between 50 and 90 dB [22].  
The duration of the sound also seems to influence to postural control [3, 23]. Increased 
exposure increases postural sway [3]. Sound influence seems to be critical when exposure 
lasts for at least 30seconds [16, 19, 24]. No responses have been seen when the sound 
stimulus is applied for less than 20 seconds [19]. 
Sound origin seems to be another factor related to postural control alterations. Moving 
auditory stimuli increase human body sway, in a direction dependent manner, related to the 
origin of the sound stimulus[18]. Monoaural loud stimulus in fact seem to affect the body 
sway on the lateral plane [19]. There also seems to be a relation between asimmetrical hearing 
loss and balance. The majority of individuals reported in scientific literature, that exhibit 
vestibular simptoms usually have an asimmetric hearing loss caused by trauma or exposure to 
very loud noises, whereas only 11% of people with simmetrical hearing loss seem to exhibit 
vestibular simptoms [25]. The National Health and Nutrition Examination Survey (2001–
2004) database showed that for each 10 dB of hearing loss, individuals had a 1.4 times 
increased risk of falling [25]. However, hearing aids significantly improve balance in older 
adults that have progressively lost hearing during their lifespan [25]. No differences seem to 
be noted between male and female during postural control after sound influence with open 
eyes [15].  
Scientific literature in regard to postural sway has showed that in groups of sighted 
(blindfolded) subjects and congenitally blind patients with a pair of fixed, external auditory 
sources located immediately adjacent (5 cm lateral) to each ear reduced the movement of the 
center of pressure compared to when standing in silence [25]. Meaning that during visual 
deprivation an auditory stimulus may help postural control. 
A sound-induced saccular activation would evoke a vestibule-postural reflex, expressed 
as a muscular reaction in the lower limbs [19]. The sound induced reaction of the lower limb 
acts on the postural pattern that can indirectly act on the static posturography [26].  
There are three possible explanations by which an auditory stimulus may affect postural 
control through vestibular activation: 1) Both auditory and vestibular receptors have hair cells 
classified as mecanoreceptors, so these receptors process information in a similar way; 2) 

The Influence of Sounds in Postural Control 
 
697
Even with a different perceptive frequency range for each receptor, if there is a very strong 
stimulus, this can activate a varied type of nervous cells; 3) As saccular receptors are in close 
proximity to the footplate of the stapes, these will likely be preferentially activated by the 
abrupt invar movement of the stapes [16]. 
In conclusion, sound may affect both positively and negatively postural control. Loud 
(above 90dB) and high frequency sounds (above 2000Hz) seem to negatively affect postural 
control, increasing body’s postural sway on both an anterior-posterior axis and a medio-
lateral axis. Whereas frequencies of around 2000Hz seem to both decrease the body sway and 
the center of pressure. Body postural sway is directly related on the sound source and on the 
duration of such sound stimulus with no differences between genders. There also seems to be 
a relation between hearing loss and balance in the elderly, that may be improved by the use of 
hearing aids. In addition, sound sources seem to help blind people improving their postural 
sway. 
 
 
REFERENCES 
 
[1] 
Pollock AS, Durward BR, Rowe PJ, Paul JP. What is balance? Clin. Rehabil. 2000 
Aug; 14(4):402-406. 
[2] 
Bouisset S, Do M. C. Posture, dynamic stability, and voluntary movement. 
Neurophysiol. Clin. 2008 Dec; 38(6):345-362. 
[3] 
Park SH, Lee K, Lockhart T, Kim S. Effects of sound on postural stability during quiet 
standing. J. Neuroeng. Rehabil. 2011; 8:67. 
[4] 
Martines F, Messina G, Patti A, Battaglia G, Bellafiore M, Messina A, et al. Effects of 
Tinnitus on Postural Control and Stabilization: A Pilot Study. Acta Medica 
Mediterranea. 2015; 31. 
[5] 
Bademkiran F, Uludag B, Guler A, Celebisoy N. The effects of the cerebral, cerebellar 
and vestibular systems on the head stabilization reflex. Neurol. Sci. 2016 May; 
37(5):737-742. 
[6] 
Standring S., Borley N. R. Gray’s Anatomy: The Anatomical Basis of Clinical Practice: 
Churchill Livingstone/Elsevier; 2008. 
[7] 
Holstege G. The anatomy of the central control of posture: consistency and plasticity. 
Neurosci. Biobehav. Rev. 1998 Jul; 22(4):485-493. 
[8] 
Holstege G. Brainstem-spinal cord projections in the cat, related to control of head and 
axial movements. Rev. Oculomot. Res. 1988; 2:431-470. 
[9] 
Holstege G. The somatic motor system. Prog Brain Res. 1996; 107:9-26. 
[10] Tilikete C., Vighetto A. [Functional anatomy of the vestibular nerve]. Neurochirurgie. 
2009 Apr; 55(2):127-131. 
[11] Bianco A., Pomara F., Petrucci M., Battaglia G., Filingeri D., Bellafiore M., et al. 
Postural stability in subjects with whiplash injury symptoms: results of a pilot study. 
Acta Otolaryngol. 2014 Sep; 134(9):947-951. 
[12] A M. Hearing: Anatomy, Physiology, and Disorders of the Auditory System. 2rd Edition 
ed: Elsevier; 2006. 
[13] Alberti P. The Anatomy and Physiology of the Ear and Hearing. WHO. 1970. 

E. Thomas, A. Bianco, G. Messina et al. 
 
698
[14] Martines F., Ballacchino A., Sireci F., Mucia M., La Mattina E., Rizzo S., et al. 
Audiologic profile of OSAS and simple snoring patients: the effect of chronic nocturnal 
intermittent hypoxia on auditory function. Eur. Arch. Otorhinolaryngol. 2016 Jun; 
273(6):1419-1424. 
[15] Siedlecka B., Sobera M., Sikora A., Drzewowska I. The influence of sounds on posture 
control. Acta Bioeng. Biomech. 2015; 17(3):96-102. 
[16] Mainenti M. R., De Oliveira L. F., De Melo Tavares De Lima M. A., Nadal J. 
Stabilometric signal analysis in tests with sound stimuli. Exp. Brain Res. 2007 Aug; 
181(2):229-236. 
[17] Minor L. B., Solomon D., Zinreich J. S., Zee D. S. Sound- and/or pressure-induced 
vertigo due to bone dehiscence of the superior semicircular canal. Arch. Otolaryngol. 
Head Neck Surg. 1998 Mar; 124(3):249-258. 
[18] Agaeva M. Y., Altman Y. A. Effect of a Sound Stimulus on Postural Reactions. Human 
Physiology. 2005; 31(5):511-514. 
[19] Alessandrini M., Lanciani R., Bruno E., Napolitano B., Di Girolamo S. Posturography 
frequency analysis of sound-evoked body sway in normal subjects. Eur. Arch. 
Otorhinolaryngol. 2006 Mar; 263(3):248-252. 
[20] Halmagyi G. M., Curthoys I. S., Colebatch J. G., Aw S. T. Vestibular responses to 
sound. Ann. N Y Acad. Sci. 2005 Apr; 1039:54-67. 
[21] Millar S. Veering re-visited: noise and posture cues in walking without sight. 
Perception. 1999; 28(6):765-780. 
[22] Tanaka T., Kojima S., Takeda H., Ino S., Ifukube T. The influence of moving auditory 
stimuli on standing balance in healthy young adults and the elderly. Ergonomics. 2001 
Dec 15; 44(15):1403-1412. 
[23] Agaeva M., Al’tman Ia A., Kirillova I. [The effect of auditory image moving in vertical 
plane upon posture responses of humans]. Ross Fiziol. Zh. Im I. M. Sechenova. 2005 
Jul; 91(7):810-820. 
[24] Kapoula Z., Yang Q., Le T. T., Vernet M., Berbey N., Orssaud C., et al. Medio-lateral 
postural instability in subjects with tinnitus. Front. Neurol. 2011; 2:35. 
[25] Rumalla K., Karim A. M., Hullar T. E. The effect of hearing aids on postural stability. 
Laryngoscope. 2015 Mar; 125(3):720-723. 
[26] Russolo M. Sound-evoked postural responses in normal subjects. Acta Otolaryngol. 
2002 Jan; 122(1):21-27. 

In: Encyclopedia of Audiology and Hearing Research 
ISBN: 978-1-53617-702-2 
Editors: Erno Larivaara and Senja Korhola 
© 2020 Nova Science Publishers, Inc. 
 
 
 
 
 
 
 
Chapter 49  
 
 
 
CHRONIC OTITIS MEDIA AND HEARING LOSS 
 
 
Letícia S. Rosito1, PhD, Mariana M. Smith2, MD,  
Daniela Marques1, Marina Faistauer1, MD  
and Gustavo V. Severo1, MD 
1Department of Otolaryngology,  
Federal University of Rio Grande do Sul, Porto Alegre, Brazil 
2Departament of Otolaryngology,  
McGill University, Montreal, Canada 
 
 
ABSTRACT 
 
The otitis media (OM) is defined as an inflammatory process, infectious or not, that 
occurs in the middle ear cleft either as a focal or a generalized process. Because of its 
high prevalence and multiple clinical presentations, OM is often associated with high 
social cost and it can become directly and/or indirectly highly expensive. It is estimated 
that the annual cost of OM is more than 5 billion dollars, considering only the United 
States. Chronic otitis media is a worldwide problem, but is more prevalent among poor 
and developing crountries. Otitis media can also be associated with hearing loss. Chronic 
otitis media with effusion is the main cause of hearing loss in children and it can progress 
over time to more complex conditions such as tympanic membrane perforation, tympanic 
membrane retraction or cholesteatoma. Hearing loss may appear at any time during the 
OM progress and can present with different types and degrees. As for the type, the 
hearing loss caused by OM may be conductive, sensorineural, or mixed. As for the 
degree, depending on how aggressive is the pathological process and the extension of it 
the hearing loss will vary from mild, moderate losses (usually conductive) to even severe 
degrees with severe and profound losses (usually sensorineural). The goal of the OM 
treatment of is not only the resolution of the inflammatory process but also the 
improvement of the hearing deficit. This goal can be achieved simply by the 
reconstitution of the tympanic membrane and ossicular chain or by the use of 
conventional hearing aids and, more recently, by the implantation of bone anchored 
hearing aids. Rarely patients can present profound bilateral hearing loss as a consequence 
of chronic OM. In these cases, cochlear implant surgery is the best option of treatment as 
soon as the resolution of inflammatory process occurs. 
 

Letícia S. Rosito, Mariana M. Smith, Daniela Marques et al. 
 
700
Keywords: hearing loss, otitis media, children 
 
 
1. INTRODUCTION 
 
The otitis media (OM) is defined as an inflammatory process that occurs in the middle 
ear cleft. OM can be acute, generally associated to pain and fewer and usually auto limitated 
or chronic when persistes for more than 3 months. According to continnun theory proposed 
by Paparella, the earlier forms of OM, such as acute or serous, can progress over time to more 
chronic forms like OM with effusion that, without mechanisms that could stop it, can 
progress more complex conditions like severe tympanic membrane retration and 
cholesteatoma.  
Because of its high prevalence and multiple clinical presentations, OM is often associated 
with high social cost and it can become directly and/or indirectly highly expensive. It is 
estimated that the annual cost of OM is more than 5 billion dollars, considering only the 
United States. Chronic otitis media (COM) is a worldwide problem, but is more prevalent 
among poor and developing crountries.  
OM, in all their forms, can also be associated with hearing loss. Hearing loss may appear 
at any time during the OM progress, can present with different degrees and can be not 
associated to other symptoms. Chronic otitis media with effusion (OME), for example, is the 
main cause of hearing loss in children and, if is not associated to recurrent acute otitis media, 
the deafness will be the single children’s complain. 
As for the type, the hearing loss caused by OM may be conductive, sensorineural, or 
mixed. As for the degree, depending on how aggressive is the pathological process and the 
extension of it the hearing loss will vary from mild, moderate losses (usually conductive) to 
even severe degrees with severe and profound losses (usually sensorineural). The goal of the 
OM treatment of is not only the resolution of the inflammatory process but also the 
improvement of the hearing deficit. This goal can be achieved simply by the reconstitution of 
the tympanic membrane and ossicular chain or by the use of conventional hearing aids and, 
more recently, by the implantation of bone anchored hearing aids.  
 
 
2. OTITIS MEDIA WITH EFFUSION 
 
Otitis media with effusion (OME) can be defined as the presence of fluid in the middle 
ear behind an intact tympanic membrane, without symptoms or signs of acute ear infection. 
The fluid can appear during a viral upper respiratory infection, as a result of a poor 
Eustachian tube function, or as an inflammatory response following an acute otitis media 
(AOM). Chronic OME (COME) is defined by the documented presence of OME for more 
than 3 months. 
The incidence of OME varies from different studies but this is a clearly very common 
problem. The literature supports an incidence of more than 60% of children before 2 years of 
age and around 90% would have at least one OME episode at school age [1, 2]. The rate is 
even higher in patients with developmental issues such as Down syndrome and craniofacial 
malformation [3]. 

Chronic Otitis Media and Hearing Loss 
 
701
The natural history of OME is one of resolution, with most individual episodes subsiding 
within several weeks. In a systematic review looking for the natural history of OM the authors 
found OME after untreated AOM had 59% resolution by 1 month and 74% by 3 months [4]. 
Other authors described a persistence of OME for 3 months or longer in about 10 to 25% of 
the OME cases [5]. Although, the same systematic review found that COME had only 26% 
resolution by 6 months.  
Chronic OME can cause hearing loss, delay in language development, auditory problems 
and vestibular symptoms. As a result, COME can have an important impact on children’s 
mood, communication, behaviour, learning and socialisation, affecting the patient’s quality of 
life [4, 6, 7]. The presence of COME in early childhood was also demonstrated of having a 
possible impact on intelligence quotient (IQ), behaviour and reading into teenage ears [6, 7]. 
Therefore, is crucial to achieve the correct identification of OME as well as the hearing 
assessment for children with COME.  
The functional impact of COME can be more intense in those children who already have 
a clinical condition associated with high risk of hearing loss or with development impairment. 
Patients with suspected or confirmed speech and language delay or disorder, autism spectrum 
disorder, any developmental disorder, syndromes or craniofacial disorders that include 
cognitive or language delays, blindness or uncorrectable visual impairment, cleft palate and 
any developmental delay are considered at-risk and should be evaluated in a proper manner. 
Children with Down syndrome, for exemple, have decreased motor tone of the Eustachian 
tube and the cleft palate, because of abnormal insertion of the levator veli palatini and tensor 
veli palatini muscles [3, 8-9]. The at-risk children should be evaluated for OME at the time of 
the condition that classified them as at-risk is diagnosed. If OME is present the hearing should 
be tested promptly in this population.  
The recently published Updated Guideline on OME from the American Academy of 
Otolaryngology recommends that children with effusion for longer than 3 months (COME) 
should be addressed for an age-appropriate hearing test. This recommendation was based on 
cohort studies showing high incidence of hearing loss in children with COME, as well as on 
the clear preponderance of benefit over harm. There is no need for audiology evaluation for 
otherwise healthy children with early onset OME. However, the at-risk group of patients 
should be evaluated for hearing loss at any time if diagnosed with OME.  
There are different tests that can be used to get a reliable response and the choice must be 
age appropriate. The hearing test can be done trough conventional audiometry, 
comprehensive audiologic assessment or frequency-specific auditory evoked potentials. Most 
kids aged 4 years or more are collaborative enough to partake in a conventional audiometry 
done performed by a trained audiologist. A comprehensive audiologic evaluation is chosen 
for most children between 6 months and 4 years as well as for those older than 4 years that 
had failed at conventional study.  
The impact of OME on hearing can vary from normal hearing to moderate conductive 
hearing loss. The average loss described is 28-dB (decibels), with around 20% of cases 
exceeding 35-dB of loss [10-11]. Sabo et al. performed a study comparing different 
audiologic techniques, age groups and middle ear condition and described that OME was 
associated with hearing threshold levels 10 to 15 dB higher than the normative values for the 
corresponding age group [12]. 
It is important to know that the hearing loss, as measured in decibels is a logarithmic 
scale of intensity, and for every 3- dB increase, there is a doubling in sound-intensity levels. 

Letícia S. Rosito, Mariana M. Smith, Daniela Marques et al. 
 
702
A child with normal hearing of 20 dB would experience 8-fold increase in sound intensity 
when compared with a child with OME and average hearing loss of 28 dB [13]. 
Although all periods of language development are important, a sensitive period is defined 
as a time interval in which an organism is biologically prepared to acquire certain behaviors 
as long as there is a stimulating, supporting environment. Prospective studies of children with 
recurrent OME suggest that mild hearing loss associated with OME in early life is associated 
with poorer extended high-frequency hearing sensitivity and atypical auditory brainstem 
pathway indices (elevated crossed, but not uncrossed, middle ear acoustic reflex thresholds, 
and delayed wave V auditory brainstem response (ABR) latencies) at school age but not 
psychoacoustic or speech-in-noise tasks. However, other studies have demonstrated 
compromised deficits in binaural auditory tasks such as binaural release from masking and 
speech-in noise listening. In some cases, difficulties resolved following treatment for middle 
ear disease or an extended period of normal hearing after resolution of OME [14]. 
The hearing loss presence and degree should be objectively assessed once the parents’ 
perception was described as inaccurate. Brody et al. developed a 7-item self-administered 
survey (HL (hearing level)-7 survey) with specific questions about the perception of the 
hearing ability of the child. They described the survey as a reliable and internally consistent 
parent perception but unfortunately these perceptions had no correlation with pure tone 
average results for the better hearing ear [15] .Therefore, the attending physician cannot rely 
on parent perception to guide audiology evaluation for patients with COME. Other authors 
had addressed this topic finding the same result. [16]. 
The main goal when managing patients with COME is to resolve effusion and, 
consequently, restore the optimal hearing and improve the quality of life. Different treatments 
were described with different results.  
The recent reviewed Guideline made a strong recommendation against the use of steroids 
(both intranasal and systemic), antibiotics, antihistamines and decongestants for COME [13]. 
Antihistamines and decongestants are poorly discussed in the literature, but there is a 
controversy about steroids and antibiotics prescription.  
A recent Cochrane review looked on the use of antibiotics for OME. The authors found 
moderate quality evidence from 6 trials (including 484 patients) that children with OME 
treated with antibiotics are more likely to have complete resolution of the OME at 2 to 3 
months post-randomization when compered to control group. However, there is obvious 
evidence indicating the higher incidence of diarrhea, vomiting and skin rash in the treated 
group. Analysing resolution at any time the review found low quality evidence of a beneficial 
effect of antibiotics and the same low quality evidence was found between the use of 
antibiotics and decrease in tympanostomy with tube insertion. There was poor data using 
hearing recovery as outcome. The authors concluded that there is evidence for both benefit 
and harm for the use of antibiotics and suggest that its important to have in mind the low or 
moderate quality of evidence described before prescribing antibiotics for such a common 
condition, specially because of antibiotic resistance induction [17]. 
A Cochrane systematic review in 2011 has found insufficient evidence for the 
effectiveness for oral steroids but sufficient evidence to suggest further research on this topic 
[18]. There is evidence from in vitro and animal models suggesting that steroids can reduce 
effusions and middle ear pressure but there is no clear evidence regarding the use of a short 
course of systemic steroids to treat OME. Based on this assumption Waldron and colleagues 
recently published the OSTRICH (oral steroids for the resolution of otitis media with 

Chronic Otitis Media and Hearing Loss 
 
703
effusion) protocol, promising to be the first adequately powered trial to evaluate the clinical 
effect and the cost-effectiveness of a short course of oral steroids for OME [6]. 
As the natural history of OME is favourable, in most cases there is no need for a specific 
treatment. If the OME is asymptomatic and is likely to resolve spontaneously is possible to 
suggest a watchful waiting, sometimes even if OME persists for more than 3 months. The 
described risk factors associated with reduced likelihood of spontaneous resolution include: 
OME onset in summer or fall, hearing loss >30 dB HL in the better hearing ear, history of a 
prior set of tubes and not having a prior adenoidectomy [13]. Randomized trials suggest that 
healthy children could be safely observed for at least 6 months, with regular follow up at each 
3 months. If there is symptoms modification, hearing loss or alterations of the tympanic 
membrane structure, the indication for surgery can be made. Its important to stress out that 
patients with OME need to be followed closely not only because of the hearing but to ensure 
the integrity of the tympanic membrane. OME is associated with tympanic membrane 
inflammation and chronic low middle ear ventilation and this environment can lead to 
tympanic membrane retraction. The incidence of structural damage increases with effusion 
duration [19]. 
During the watchful waiting period, autoinflation was described as a tool to help 
ventilating the middle ear and there are different devices available. A trial published in 2015 
found modest effect when an autoinflation device was used in children with OME between 4 
and 11 years [20]. However, around 80% of the affected children are under 4 years and the 
autoinflation is probably technically difficult to be used on this young population. 
The surgical approach to COME is a tympanostomy with ventilation tube insertion. The 
2013 Guideline on Tympanostomy Tubes recommends performing this procedure for children 
with bilateral COME (more than 3 months of OME) and hearing loss. For those patients with 
unilateral or bilateral COME and symptoms likely related to OME (vestibular, poor school 
performance, behavioural problems, ear discomfort) the guideline suggest the tympanostomy 
as an option. There is an option also for inserting tubes in children at-risk with OME that is 
unlikely to resolve quickly (with a type B tympanogram) even if its duration is less than 3 
months [21]. 
Its treatment is broadly discussed in the literature, a recent prospective study conducted in 
Moldava and supported by the Mayo’s Clinic compared three types of treatment of COME 
(adenoidectomy + tympanostomy, physical conservative treatment + adenoidectomy and 
physical conservative treatment alone), the T+A group normalized and had stable hearing in 
95% of the ears after 12 months with less middle ear changes like adhesions, retractions and 
thickening of the tympanic membrane when compared to the other groups [22].  
Any child with detected hearing loss secondary to OME should have a hearing test after 
the resolution of the OME to confirm resolution of hearing loss that was attributed to OME 
and to assess for an underlying SNHL.  
Hu et al. in 2015, showed the impact in hearing of tube placement in patients assessed by 
sound field audiometry and evaluated by pure-tone audiometry: the mean sound field 
threshold value was 29.2 dB preoperatively and improved to 17dB, 6 to 10 weeks 
postoperatively in the first ones and the mean preoperative air–bone gap was 20.1 dB and this 
improved to 7.3 dB in the second ones. 
 
 
 

Letícia S. Rosito, Mariana M. Smith, Daniela Marques et al. 
 
704
 
 
Figure 2. Illustration of an otitis media with effusion and retraction of the pars tensa. (Image of the 
Department of Otolaryngology-Head and Neck Surgery, Hospital de Clinicas de Porto Alegre) 
Unresolved OME and associated hearing loss may lead to auditory problems, poor school 
performance, language delay and behavioral problems. If undiagnosed and without treatment 
it can contributes to the progression of OM, recurrent acute otitis media, chronic 
inflammation of the tympanic membrane [23-25] which can induce epithelial migration, and 
predispone to retraction pockets and cholesteatoma formation. 
 
 
3. CHRONIC OTITIS MEDIA 
 
Chronic otitis media COM has been traditionally characterized as an inflammatory 
condition of the middle ear associated with tympanic membrane (TM) perforation and 
otorrhea. Histopathologically, COM has been defined as a condition of the middle ear 
associated with irreversible inflammatory pathology, thus including moderate and severe TM 
retractions, 
cholesterol 
granuloma, 
granulation 
tissue, 
bone 
erosion, 
invasive 
tympanosclerosis and silent chronic otitis media. COM can be also sub-classified into two 
major groups: COM with cholesteatoma (CCOM) and COM without cholesteatoma 
(NCCOM). 

Chronic Otitis Media and Hearing Loss 
 
705
TM perforations can vary in size and appearance. Costa and Rosito used to classify TM 
perforations into inside-out (IOP) and outside in (OIP). While IOP are mostly central and 
kidney shaped, OIP present signs of a previous TM retraction. Stretching the concept we 
would even dare to affirm that IOP represent a disease of the TM while the OIP are truly one 
of the most apparent sub-products of a disturbed homeostasis and physiological imbalance of 
the middle ear. 
Hearing loss associated with this pathology usually is conductive and can vary 
considerably in severity. This variation correlates directly to several sub-factors: size and 
position of the TM perforation, degree of ossicular fixation, presence of major or minor 
ossicular erosions, ossicular dislocation and, obviously, the repercussion of all this process in 
the inner ear. In a study that included children and teenagers, was found a positive association 
at all frequencies between the number of quadrants affected by TM perforation and the 
conductive hearing loss (measured by the air bone gap) [26]. 
The sensorineural hearing loss has been associated to NCCOM, although the real impact 
of it is still object of research. Using the normal contralateral ear as control in patients with 
COM, we observed a statistically significant difference between the average bone conduction 
thresholds of ears with COM and their contralateral ears for all frequencies. Despite being 
statistically significant, however, this difference may not be clinically relevant, since changes 
of 5 to 10 dB on tonal audiometry do not represent an important hearing loss, nor does it 
imply any change in treatment plan, such as indicating use of a hearing aids [27]. 
TM retractions are special conditions. Whereas they may present as an incidental finding 
or with minimal symptoms, clearly they represent irreversible tissue pathology (TM atrophy 
and ossicular erosion) and a potential for cholesteatoma formation. 
 
 
Figure 3. Illustration of a NCCOM, with severe retraction of the TM and fixation of the ossicular chain. 
(Image of the Department of Otolaryngology-Head and Neck Surgery, Hospital de Clinicas de Porto 
Alegre) 
A recent study of Schmidt et al. demonstrated that severe pars tensa retractions with 
incus erosion and TM adhered to the stapes (tympanostapedopexy) were associated with 
small air bone gaps (<25 dB) in 85% of the patients. In other words, this kind of situation 
usually works as a nicely performed natural type III tympanoplasty. So, the need for a 
tympanoplasty to improve the auditory function in these cases is not recommended. 

Letícia S. Rosito, Mariana M. Smith, Daniela Marques et al. 
 
706
 
Figure 4. Illustration of a TM perforation. (Image of the Department of Otolaryngology-Head and Neck 
Surgery, Hospital de Clinicas de Porto Alegre) 
 
4. CHRONIC OTITIS MEDIA WITH CHOLESTEATOMA 
 
Cholesteatoma is the most aggressive spectrum of chronic otitis media (COM). It is a 
progressive disease that causes hearing loss and recurrent otorrhea. Cholesteatoma is 
characterized by the accumulation of exfoliated keratin debris in the middle ear or other 
pneumatized areas of the temporal bone [28]. Since cholesteatoma was first described, many 
classifications have being proposed. In principle, it is accepted that cholesteatomas can be 
classified into two categories: congenital and acquired [29]. As congenital cholesteatomas are 
very rare, the existent classifications are applied to the acquired type. The classifications are 
based on otomicroscopic appearance [30], typical growth patterns [31], disease extension 
[32], surgical findings [28], and otoscopic drum status [33]. 
Hearing loss is one of the more disturbing symptoms in patients with cholesteatoma. In 
our previous study, we found that hypoacusis and otorrhea were the main complaints of most 
patients, and 87% had otorrhea at the time of evaluation. Complaints of hearing loss were 
confirmed by audiometry, which showed that the vast majority of patients had conductive 
hearing loss with larger air-bone gap of 20 dB in speech recognition area. [34]  
We also demonstrated that, compared with posterior epitympanic cholesteatomas, 
posterior mesotympanic cholesteatomas had greater (air bone gap) ABG thresholds at 500 Hz, 
2000 Hz, and ABG PTA (pure-tone average), which correspond to the speech reception 
frequencies. The two growth patterns, however, were very similar with regard to the other 
audiometric parameters. In children, no audiometric differences were found between the two 
groups, whereas, in adults, compared with posterior epitympanic cholesteatomas, posterior 
mesotympanic cholesteatomas showed higher AGB thresholds at 500 Hz to 3000 Hz and 
higher ABG PTA, in addition to higher AC thresholds at several frequencies. [35]  
When we studied the sensorineural hearing loss in cholesteatoma, we found that the 
cholesteatoma ear was associated with greater (bone conduction) BC thresholds than the 
(contralateral ear) CLE. The presence of cholesteatoma in the middle ear was associated with 
greater BC thresholds at all frequencies tested, when compared with the normal CLE. These 
BC differences were observed both in children and adults, and independently of 

Chronic Otitis Media and Hearing Loss 
 
707
cholesteatoma growth pattern. The frequency of labyrinthine fistula in our sample was low, 
and thus it may have little influence in the global sensorineural hearing impairment associated 
with cholesteatoma. The correlation between the air bone gap media in the ear with 
cholesteatoma and the difference in bone conduction thresholds between both ears was direct 
and moderate. In other words, when more damaged the tympanossicular system is, greater the 
sensorineural deficit will be [36]. 
 
 
Figure 5. Illustration of a posterior mesotympanic cholesteatoma. (Image of the Department of 
Otolaryngology-Head and Neck Surgery, Hospital de Clinicas de Porto Alegre) 
 
Figure 6. Illustration of an attical cholesteatoma. (Image of the Department of Otolaryngology-Head 
and Neck Surgery, Hospital de Clinicas de Porto Alegre) 
An understanding of the different types, behavioral patterns, and hearing impairment 
caused by cholesteatomas will enable us to improve the prognosis of this disease by 
optimizing its treatment and improving surgical techniques for both complete removal of the 
pathological tissue and successful reconstruction of the damaged ossicles. We also believe 
that a better understanding of the sensorineural damage associated with cholesteatoma cannot 

Letícia S. Rosito, Mariana M. Smith, Daniela Marques et al. 
 
708
be overstressed. It is quite obvious that all these changes are time-related, so, in our opinion, 
it is very important to monitor these patients very closely in order to decide for a surgical 
intervention during the earlier phases of the disease. In doing so, we may abort the natural 
history of cholesteatoma and its deleterious consequences. To define with precision the 
surgical timing for carrying out such an intervention is still a matter of great debate, but it 
seems plausible that during the early phases surgeries may be less aggressive and residual 
function is maintained. The preservation of an adequate inner ear function is of paramount 
importance especially nowadays with the development of new prosthesis and the advent of 
bone anchored hearing aids and actives middle ear implants specifically indicated for patients 
with COM. This knowledge may assist the development or improvement of new 
technologies, and may be of even more benefit with regard to BC than our demonstration that 
SNHL (sensorineural hearing loss) may be present in most patients with cholesteatoma, and 
that this damage can be clinically relevant in several cases. 
 
 
5. CHRONIC OTITS MEDIA TREATMENT 
 
5.1. Tympanoplasty and Ossicular Reconstruction  
 
Tympanoplasty is the procedure of choice in the treatment of tympanic membrane 
perforation. It is the first step in the resolution of hearing loss by the reconstruction of the 
tympanum with temporal fascia, tragus cartilage or other kinds of enxerts. Is still 
controversial the ideal time to perform tympanoplasty in children. The recommendation is 
around 7 or 8 years, when the child is more collaborative and the otitis media episodes 
ussually slow down. However, several groups around the world perform tympanoplasty in 
children ealier, with good results. The approach can be transcanal, retroauricular, and, more 
recently, transcanal with the use of microscopes. James has demonstrated that use of 
endoscopes in children is safe, providing good results, excellent visibility of all perforation 
without necessity of canaloplasty and with no big scars and little pain.  
Tymanoplasty is also the last step in cholesteatoma surgery. The surgeon may choose 
between open or closed mastoidectomy, but tympanoplasty will be always performed if the 
surgeon sucessfully removed all the epithelium of the middle ear and mastoid.  
One of the complications caused by chronic otitis media with or without cholesteatoma is 
ossicular discontinuity. 
The goals of the COM management are auditory rehabilitation and disease eradication. 
This rehabilitation is usually performed during second look surgery in children, through the 
ossicular reconstruction [37]. 
Nowadays, the most used material to compose the prosthesis on ossicular reconstruction 
is titanium, [37] and partial ossicular replacement prosthesis (PORPs) is more used than total 
ossicular replacement prostheses (TORPs). [38] Probably this is because good auditory 
results are more frequent in partial ossiculoplasty compared with total ossiculoplasty, and the 
displacement of TORP is bigger than PORPs in children [37]. 
Murphy at al. compared hearing results after ossicular reconstruction with PORPs and 
after ossicular reconstruction with TORPs in pediatric patients with COM. They found that 

Chronic Otitis Media and Hearing Loss 
 
709
children who underwent ossicular reconstruction with PORPs had slightly better 
postoperative hearing than children with TORPs [38]. 
In studies with adults, a few predictive factors for postoperative results in ossicular 
reconstruction have been illustrated, like persistent or recurrent abnormalities within the 
middle ear, presence of a malleus handle and preoperative middle ear mucosa status. Nevoux 
at al, in 2011, evaluated predictive factors of a good outcome with the use of a total ossicular 
replacement prosthesis in children and demonstrated that preoperative average air-bone gap 
and the footplate status are predictive factors of the results of ossiculoplasty [37]. 
A study of Jeng at al, in 2003, demonstrated preoperative findings that are related to 
status of the ossicular chain at surgery. Three parameters should be considered feasible 
predictors of ossicular discontinuity in COM: cholesteatoma extension into the tympanic 
sinus, persistently draining ears (cholesteatoma group) and perforation edges adherent to the 
promontory (noncholesteatoma group) [39]. 
 
 
5.2. Bone – Anchored Hearing Aid and Coclhear Implant 
 
Since the introduction of the bone anchored hearing aids (BAHA) at the market in the 
1980s, it become a common treatment of conductive hearing loss in patients who failed with 
the conventional air-conductional aid, in congenital malformations of the external and middle 
ear, chronically discharging ear, conductive hearing losses attributable to ossicular disease 
[2]. It is suitable because the sound is transmitted directly to the cochlea through the cranium, 
circumventing any external or middle ear anomaly or pathology. 
A study conducted in Canada with 12 specialists, showed that congenital aural atresia 
was identified to be a indication for pediatric BAHA for all professionals who performs that 
kind of surgery, other common indications for this procedure were: chronic otitis externa or 
media with hearing loss (92%), allergic reactions to conventional hearing aids (75%), 
congenital fixation or anomaly of the ossicular chain (67%), and unilateral deafness (25%). 
The use of BAHA in this last population is mainly to establish binaural hearing, but the 
audiological benefits is variable [40]. Priwin et al. noted an improvement of speech 
recognition in noisy enviroments without improvements in hearing thresholds or sound 
localization [41]. Despite its inconsistencies, BAHA in children with unilateral hearing loss 
have been found to have a positive impact of quality of life with high rates of user 
compliance. 
Watson et al. used the validated Glasgow Benefit Inventory (GBI) to assess changes in 
general, social and physical health benefits (quality of life benefits) of patients who was fitted 
a BAHA for different conditions and then separated them in subgroups (neuroma acoustics, 
discharging mastoid cavities, chronic active otitis media, otosclerosis, congenital atresia). The 
patients that were submitted for a BAHA because of congenital atresia scored the best 
improvement in quality of life, this could explained by the fact that these patients doesn’t 
compare their improvements with what they had in the past and consider it as a benefit [42]. 
Despite of that, the subgroup that gain more physical benefits than the others was the chronic 
active otitis media, it could be explained for better ventilation and a dry ear, while still 
delivering continuous sound amplification when compares with the conventional air-
conduction aids.  

Letícia S. Rosito, Mariana M. Smith, Daniela Marques et al. 
 
710
One of the main benefits of the bone-anchored hearing aids is the use in mixt hearing 
loss. In these cases, patients can achieve normal hearing even if they have bone conduction 
thresolds aroud 55 dB.  
Rarely patients can present profound bilateral hearing loss as a consequence of chronic 
otitis media. In these cases, cochlear implant surgery is the best option of treatment as soon as 
the resolution of inflammatory process occurs. In cholesteatoma cases, it is recommend that 
the cochlear implant surgery woul be performed after 6 or more months from cholesteatoma 
surgery. Some centers prefer to perform a petrosetomy with cavity obliteration prior to 
cochlear implant surgery. 
 
 
6. IMPACT OF CONDUCTIONAL HEARING LOSS  
IN LANGUAGE DEVELOPMENT 
 
The presence of hearing loss in the first few years of life can have an impact in language 
development [43-46]. Considering that children learn speech and language from listening to 
other people talk, it seems critical to have an optimal sensorial input in this period. 
Otitis media with effusion presents a special problem because symptoms of pain and 
fever are usually not present. Therefore, weeks and even months can go by before parents 
suspect a problem. During this time, the child may miss out on some of the information that 
can influence speech and language development. Parents should pay attention on some signs 
like inattentiveness, wanting the television or radio louder than usual, misunderstanding 
directions, listlessness, unexplained irritability, and pulling or scratching at the ears, because 
they may indicate chronic or recurring fluid in the ear [47]. 
Despite the conceptual logic of the hypothesized relationship between OME and 
language impairment, there is not a consensus about the studies findings. It is important to 
consider that many variables related to hearing loss can interfere in the language acquisition. 
Roberts at al. (1998) pointed out four important reasons to this misunderstood. First, few 
studies have examined hearing loss as an independent variable, instead they use OME as the 
predictor variable. However, the degree of hearing loss associated with OME is not constant; 
some children experience no loss and other children a moderate loss as great as 50 dB HL 
[48]. Second, previous studies have not considered recent models of child development that 
emphasize the transactional and multifactorial nature of development, particularly the 
importance of the caregiving environment. Considerable research supports the influence of a 
responsive style of interaction by parents and by child-care providers in child-care programs 
in facilitating children’s language development. Third, few studies have examined whether 
certain periods of development were particularly sensitive to language difficulties because of 
OME. It is possible that specific periods, such as when children are acquiring the sound 
symbol associations of their native language during the first year of life, may be more 
vulnerable to language difficulties than later periods when children are expanding their 
vocabulary and sentence length. Fourth, the dependent measure of language development in 
previous studies has been measured broadly (eg, receptive language or expressive language), 
and may not be sensitive to the specific effects of OME and associated hearing loss. Specific 
language competencies (eg, vocabulary acquisition and language use) also need to be 
examined when looking for OME sequelae. 

Chronic Otitis Media and Hearing Loss 
 
711
Aiming to contribute with this last concern, Borg et al. (2007), create an reference 
material based on the total population of the Swedish hearing-impaired children at the age of 
4—6 years, who had up to 80 dB HL hearing threshold in the best ear, whose first language 
was and spoken Swedish (and not signed) and who had no other diagnosed major handicaps. 
The reference material analyzes different language aspects and have a healing methodological 
design and statistical analysis [49]. Like this, another studies have to be done to contribute 
with the comprehension of the impact of OME in the language acquisition, considering child 
age, effusion duration, different languages, socioeconomical status and different aspects of 
language (always afilliated with a clear theoretical background). 
 
 
REFERENCES 
 
[1] 
Tos, M. Epidemiology and natural history of secretory otitis. Am J Otol. 1984; 5: 459-
62. 
[2] 
Mandel, EM; Doyle, WJ; Winther, B; Alper, CM. The incidence, prevalence and 
burden of OM in unselected children aged -8 years followed by weekly otoscopy 
through the “common cold” season. Int J Pediatr Otorhinolaryngol. 2008; 72: 491-99. 
[3] 
Flynn, T; Möller, C; Jönsson, R; Lohmander, A. The high prevalence of otitis media 
with effusion in children with cleft lip and palate as compared to children without 
clefts. Int J Pediatrc Otorhinolaryngo.l 2009; 73: 1441-6. 
[4] 
Rosenfeld, RM; Kay, D. Natural History of Untreated Otitis Media. Laryngoscope. 
2003; 113: 1645-57. 
[5] 
Marchant, CD; Shurin, PA; Turczyk, VA; Wasikowski, DE; Tutihasi, MA; Kinney, SE. 
Course and outcome of otitis media in early infancy: a prospective study. J Pediatr. 
1984;104(6):826-31. 
[6] 
Waldron, C; Thomas-Jones, E; Cannings-John, R; Hood, K et al. Oral steroids for the 
resolution of otitis media with effusion (OME) in children (OSTRICH): study protocol 
for a randomised controlled trial. Trials. 2016;17: 115. 
[7] 
Bennet, K; Haggard, M; Silva, P; Stewart, I. Behavior and developmental effects of 
otitis media with effusion into the teens. Arch Dis Child. 2001;85: 91-5. 
[8] 
Broen, PA; Moller, KT; Carlstrom, J; Doyle, SS; Devers, M; Keenan, KM. Comparison 
of the Hearing Histories of Children with and without Cleft Palate. The Cleft Palate-
Craniofacial Journal. 1996;33(2):127-33. 
[9] 
Sheahan, P; Blayney, A. W; Sheahan, J. N; Earley, M. J. Sequelae of otitis media with 
effusion among children with cleft lip and/or cleft palate. Clinical Otolaryngology & 
Allied Sciences. 2002; 27: 494–500.  
[10] Hunter, LL; Margolis, RH; Giebink, GS. Identification of hearing loss in otitis media. 
Ann Otol Rhinol Laryngol Suppl. 1994; 103: 59-61. 
[11] Gravel, JS; Roberts, JE; Roush et al. Early otitis media with effusion, hearing loss, and 
auditory processes at school age. Ear Hear. 2006; 27: 353-68. 
[12] Sabo, DL; Paradise, JL; Kurs-Lasky, M; Smith, CG. Hearing Levels in Infants and 
Young Children in Relation to Testing Technique, Age Group, and the Presence or 
Absence of Middle-Ear Effusion. Ear Hear. 2003; 24: 38-47. 

Letícia S. Rosito, Mariana M. Smith, Daniela Marques et al. 
 
712
[13] Rosenfeld, RM; Shin, JJ; Schwartz, SR et al. Clinical Practice Guideline: Otitis Media 
with Effusion (Update). Otolaryngol Head Neck Surg. 2016; 154 (1S): S1-S41. 
[14] McKay, S; Gravel, JS; Tharpe, AM. Amplification Considerations for Children with 
Minimal or Mild Bilateral Hearing Loss and Unilateral Hearing Loss. Trends Amplif. 
2008; 12(1):43-54. 
[15] Brody, R; Rosenfeld, RM; Goldsmith, AJ; Madell, JR. Parents cannot detect mild 
hearing loss in children. Otolaryngol Head Neck Surg. 1999; 121: 681-6. 
[16] Stewart, MG; Ohlms, LA; Sulek, M et al. Is parental perception an accurate predictor of 
childhood hearing loss? A prospective study. Otolaryngol Head Neck Surg. 1997; 117: 
57-58. 
[17] Venekamp, RP; Burton, MJ; van Dongen, TMA; van der Heijden, GJ; van Zon, A; 
Schilder, AGM. Antibiotics for otitis media with effusion in children (Review). 
Cochrane Database Syst Rev. 2016, Issue 6. Art. No.: CD009163. 
[18] Simpson, S; Lewis, R; van der Voort, J; Butler, C. Oral or topical steroids for hearing 
loss associated with otitis media with effusion in children. Cochrane Database Syst 
Rev. 2011; 5: CD001935. 
[19] Maw, AR; Bawden, R. The long term outcome of secretory otitis media in children and 
the effects of surgical treatment: a ten year study. Acta Otorhinolaryngol Belg. 1994; 
48:317-24. 
[20] Williamson, I; Vennik, J; Harnden, A; Voysey, M; Perera, R; Kelly, S et al. Effect of 
nasal balloon autoinflation in children with otitis media with effusion in primary care: 
an open randomized controlled trial. Can Med Assoc J. 2015; 187:961-9. 
[21] Rosenfeld, RM; Schwartz, SR; Pynnonen, MA et al. Clinical practice guideline: 
tympanostomy tubes in children. Otolaryngol Head Neck Surg. 2013; 149 (1): S1-S35. 
[22] Diacova, S; McDonald, TJ; Ababii, I. Clinical, functional, and surgical findings in 
chronic bilateral otitis media with effusion in childhood. Ear Nose Throat J. 
2016;95(8):E31-7. 
[23] Yellon, RF; Doyle, WJ; Whiteside, TL; Diven, WF; March, AR; Fireman, P. Cytokines, 
immunoglobulins, and bacterial pathogens in middle ear effusions. Arch Otolaryngol 
Head Neck Surg. 1995;121:865-69. 
[24] Samuel, EA; Burrows, A; Kerschner, JE. Cytokine regulation of mucin secretion in a 
human middle ear epithelial model. Cytokine. 2008;41:38-43.  
[25] Kim, SH; Cha, SH; Kim, YI; Byun, JY; Park, MS; Yeo, SG. Age-dependent changes in 
pattern recognition receptor and cytokine mRNA expression in children with otitis 
media with effusion. Int J Pediatr Otorhinolaryngol. 2015;79:229-34. 
[26] Netto, LFS; Costa, SS; Sleifer, P; Braga, MEL. The impact of chronic suppurative otitis 
media on children’s and teenagers’ hearing. Int J Pediatr Otorhinolaryngol. 2009; 
73:1751-56. 
[27] Costa, SS; Rosito, LP; Dornelles, C. Sensorineural hearing loss in patients with chronic 
otitis media. Eur Arch Otorhinolaryngol. 2009; 266(2):221-4.  
[28] Yanagihara, N. Surgical treatment of cholesteatoma using intact canal wall 
tympanoplasty. Acta AWHO, 1996;15:62–74. 
[29] Louw L. Acquired cholesteatoma pathogenesis: stepwise explanations. J Laryngol Otol, 
2010;124:587–93. 
[30] Sudhoff, H; Tos, M. Pathogenesis of sinus cholesteatoma. Eur Arch Otorhinolaryngol, 
2007;264:1137–43. 

Chronic Otitis Media and Hearing Loss 
 
713
[31] Jackler, RK. The surgical anatomy of cholesteatoma. Otolaryngol Clin North Am, 
1989;22:883–96. 
[32] Saleh, HA; Mills, RP. Classification and staging of cholesteatoma. Clin Otolaryngol. 
1999; 24:355-359. 
[33] Black, B; Gutteridge, I. Acquired cholesteatoma: classification and outcomes. Otol 
Neurotol, 2011;32:992–95. 
[34] Rosito, LP; da Silva, MN; Selaimen, FA; Jung, YP; Pauletti, MG; Jung, LP et al. 
Characteristics of 419 patients with acquired middle ear cholesteatoma. Braz J 
Otorhinolaryngol. 2016 [Epub ahead of print].  
[35] Rosito, LP; Teixeira, AR; Netto, LS; Selaimen, FA; da Costa, SS. Cholesteatoma 
growth patterns: are there audiometric differences between posterior epitympanic and 
posterior mesotympanic cholesteatoma? Eur Arch Otorhinolaryngol. 2016 Feb 13. 
[Epub ahead of print]. 
[36] Rosito, LP; Netto, LS; Teixeira, AR; da Costa, SS. Hearing Impairment in Children and 
Adults With Acquired Middle Ear Cholesteatoma: Audiometric Comparison of 385 
Ears. Otol Neurotol. 2015;36(8):1297-300. 
[37] Nevoux, J; Moya-Plana, A; Chauvin, P; Denoyelle, F; Garabedian, EN. Total 
Ossiculoplasty in Children - Predictive Factors and Long-term Follow-up. Otolaryngol 
Head Neck Surg. 2011;137(12):1240-46. 
[38] Murphy, TP. Hearing Results in Pediatric Patients With Chronic Otitis Media After 
Ossicular Reconstruction With Partial Ossicular Replacement Prostheses and Total 
Ossicular Replacement Prostheses. Laryngoscope. 2000;110:536–44. 
[39] Jeng, FC; Tsai, MH; Brown, CJ. Relationship of Preoperative Findings and Ossicular 
Discontinuity in Chronic Otitis Media. Otol Neurotol. 2003; 24:29–32. 
[40] Liu, CC; Chadha, NK; Bance, M; Hong, P. The current practice trends in pediatric 
bone-anchored hearing aids in Canada: a national clinical and surgical practice survey. 
Journal of Otolaryngology - Head and Neck Surgery. 2013; 42:43. 
[41] Priwin, C; Jönsson, R; Hultcrantz, M; Granström G. BAHA in children and adolescents 
with unilateral or bilateral conductive hearing loss: a study of outcome. Int J Pediatr 
Otorhinolaryngol. 2007;71(1):135-45.  
[42] Watson, GJ; Silva, S; Lawless, T; Harling, JL; Sheehan, PZ. Bone anchored hearing 
aids: a preliminary assessment of the impact on outpatients and cost when rehabilitating 
hearing in chronic suppurative otitis media. Clinical Otolaryngology. 2008;33:338–42. 
[43] Furukawa, CT. Conductive hearing loss and speech development. J. Allergy Clin. 
Immunol. 2008;1015-20. 
[44] Lindsay, RL; Tomazic, T; Whitman, BY.; Accairdo, PJ. Early ear problems and 
developmental problems at school age. Clin Pediatr. 1999; 38:123-32. 
[45] Psarommatis, IM.; Goritsa, E; Douniadakis, D; Tsakanikos, M; Kontrogianni, AD et al. 
Hearing loss in speech-language delayed children. International Journal of Pediatric 
Otorhinolaryngology. 2001;58: 205–10. 
[46] Rvachewa, S; Slawinski, EB; Williams, M; Green, CL. The impact of early onset otitis 
media on babbling and early language development. J. Acoust. Soc. Am. 1999; 105 (1): 
467- 75. 
[47] Causes of Hearing Loss in Children – Otitis Media. 2016.09.14. Avaiable from: 
American Speech Hearing Association. URL: www.asha.org.  

Letícia S. Rosito, Mariana M. Smith, Daniela Marques et al. 
 
714
[48] Roberts, JE.; Burchinal, MR.; Zeisel, SA.; Neebe, EC.; Hooper, SR.; Roush, J et al. 
Otitis Media, the caregiving environment, and language and cognitive outcomes at 2 
years. Pediatrics. 1988;102(2): 346 –54. 
[49] Borg, E; Edquist, G; Reinholdson, A; Risberg, A; McAllister, B. Speech and language 
development in a population of Swedish hearing-impaired pre-school children, a cross-
sectional study. International Journal of Pediatric Otorhinolaryngology. 2007;1:1061-
77. 
[50] Soldati, D; Mudry, A. Knowledge about cholesteatoma, from the first description to the 
modern histopathology. OtolNeurotol. 2001;23:723–30. 
[51] Da Costa, SS; Rosito, LP; Dornelles, C; Sperling N. The contralateral ear in chronic 
otitis media: a series of 500 patients. Arch Otolaryngol Head Neck Surg. 2008;134:290-
93. 
[52] Rosito, LP; da Costa, SS; Schachern, PA; Dornelles, C; Cureoglu, S; Paparella, MM. 
Contralateral ear in chronic otitis media: a histologic study. Laryngoscope. 2007; 
117:1809-14.  
[53] Silva, MN; Muller, J dos S; Selaimen, FA; Oliveira, DS; Rosito, LP; Costa, SS. 
Tomographic evaluation of the contralateral ear in patients with severe chronic otitis 
media. Braz J Otorhinolaryngol. 2013; 79:475-9. 
[54] Jackler, RK; Santa Maria, PL; Varsak, YK; Nguyen, A; Blevins, NH. A new theory on 
the pathogenesis of acquired cholesteatoma: Mucosal traction. Laryngoscope. 2015;125 
Suppl 4:S1-S14. 
 

In: Encyclopedia of Audiology and Hearing Research 
ISBN: 978-1-53617-702-2 
Editors: Erno Larivaara and Senja Korhola 
© 2020 Nova Science Publishers, Inc. 
 
 
 
 
 
 
 
Chapter 50 
 
 
 
BINAURAL, SEQUENTIAL OR SIMULTANEOUS 
COCHLEAR IMPLANTS IN CHILDREN: A REVIEW 
 
 
C. Aimoni, V. Corazzi, N. Mazza, C. Bianchini,  
M. Rosignoli and A. Ciorba*  
ENT & Audiology Department, University Hospital of Ferrara, Italy 
 
 
ABSTRACT 
 
The early detection of hearing loss, as well as the early appropriate intervention, is 
critical for proper language, relational and cognitive development. Hearing loss in 
children can be congenital or acquired. It can be classified in prenatal, perinatal and 
postnatal, considering the time of occurrence, and it can be transitory or permanent. The 
worldwide estimated prevalence of hearing loss is 1/1000 for children without risk factors 
for hearing disease, 2-3/100 for those with risk factors. The prevalence of prelingual 
hearing loss in Italy is reported in 0.7/1000 within the Italian population [1]. 
Cochlear Implants (CIs) are considered a safe and effective method for rehabilitation 
of profound hearing loss in infants [2, 3], and particularly in children, bilateral cochlear 
implantation is becoming gradually more common in clinical practice. The advantages of 
bilateral hearing are well known; nonetheless, while among the adults, the benefits of 
bilateral implants have been previously established [4], the data available among children 
are still limited. 
Aim of the present chapter is to discuss and evaluate the effectiveness of the 
application of bilateral CIs in children, either sequentially nor binaurally, affected by 
profound/severe sensorineural hearing loss. 
 
Keywords: hearing loss in children, cochlear implants, language development, pediatric 
neuroradiology  
 
 
 
 
                                                        
* Corresponding Author’s Email: andrea.ciorba@unife.it. 

C. Aimoni, V. Corazzi, N. Mazza et al. 
 
716
INTRODUCTION 
 
Hearing loss in children can be congenital or acquired and it can be classified in prenatal, 
perinatal and postnatal, considering the time of occurrence. The worldwide estimated 
prevalence of hearing loss is 1/1000 for children without risk factor for hearing impairment 
and 2-3/1000 for those with risk factors [5]. The prevalence of prelingual hearing loss in Italy 
is reported to be 0.7/1000 within the Italian population [1]. 
The early detection of hearing loss, as well as the early appropriate rehabilitative 
intervention, is critical for the developing of proper language, relational and cognitive skills 
[6]. 
Since the implementation of newborn hearing screening programs, nowadays it is 
possible to early recognize moderate to severe hearing loss. It has been recommended to 
perform the screening within the first month of life [6, 7]. Even if not all forms of hearing loss 
can be detected by newborn hearing screening, due to the late onset of some sensorineural 
hearing loss, the reported average age of diagnosis of hearing defects (bilateral moderate-to-
severe hearing loss) and intervention in children is lowered from 26 and 32.2 months, 
respectively [8], to 2 and 4 months of life, since the publication of the Joint Committee on 
Infant Hearing statement in 2000 [9, 10, 11]. It is clear that this first period of life is decisive 
for the acquisition of acoustic stimuli and therefore for a regular development of central 
auditory pathways; the correction of hearing loss is necessary since the early age. Language 
development starts at birth with detection and discrimination of sounds and culminate at 8-12 
months, when the linguistic and communicative skills are already settled [12, 13]. 
In 2013, the American Academy of Audiology [14] described the characteristics of 
paediatric amplification, according to hearing loss level and prosthetic technology available, 
in order to guarantee a correct development of verbal production and learning abilities. 
Therefore, a prompt therapeutical-rehabilitative program is recommended by hearing aids in 
those children affected by moderate hearing loss and by cochlear implant in those affected by 
severe/profound hearing defect. 
 
 
COCHLEAR IMPLANTS (CI) 
 
Cochlear implant (CI) is a medical electronic hearing device for auditive rehabilitation in 
case of severe-to-profound hearing loss, that is available also for infants and children. The 
first single-channel CI was introduced by Dr. William F. House in 1961 [15, 16]. Since this 
first implantation surgery, technologies, processing system and the different parts of the 
implant have experienced evolutions and improvements, until the current and innovative 
models. 
CI differs from the traditional hearing aids as it is able to substitute the cochlear function, 
directly providing a stimulation on the acoustic nerve through electrical signals [17]. The 
acoustic stimulus, received by the microphone, is decomposed in frequencies in the external 
sound processor and transduced in electrical stimulus (simulating the cochlear function), 
which is transported by the receiver/stimulator to the electrodes implanted in the cochlea [18]. 
In the modern multi-channel CI, firstly developed in the late 1970s, the electrode array, 

Binaural, Sequential or Simultaneous Cochlear Implants in Children 
 
717
inserted in the scala tympani, is able to stimulate different cochlear areas [17, 19], with the 
minimum interference between electrodes. 
 
 
CI INDICATIONS IN CHILDREN 
 
The conventional candidate for cochlear implantation is represented by a patient with 
bilateral severe-to-profound sensorineural hearing loss (SNHL) and who experiences poor 
advantages from traditional hearing aids [17]. Recently, the FDA (Food and Drug 
Administration) revised the criteria for pediatric cochlear implantation [20], approving 
surgery also in children younger than 2 years, in case of profound bilateral SNHL and in 
children older than 2 years, in case of sever-to-profound bilateral SNHL. In older children (> 
4 years), CI could be proposed in any case of severe SNHL whenever the child does not 
progress in speech and language abilities, just by using traditional hearing aids [21]. 
Since language learning starts in the first months of life, there is a temporal window 
during which is necessary to intervene in children, in order to rehabilitate the hearing 
function. Those children early diagnosed with a profound bilateral SNHL have to be 
implanted as early as possible, between 12 and 24 months of life, also as the reported 
incidence of postoperative complication is low [22]. In these children it has also been 
proposed to perform a bilateral cochlear implantation, simultaneous or sequential [22]; 
binaural stimulation is crucial for spatial orientation and sound localization, particularly in a 
noisy environment [3]. Since the second half of 1990s, bilateral cochlear implantations has 
been performed always more frequently, also considering the fact that in case of malfunction 
of one device, also the other ear is implanted [3]. Audiologists, but also speech therapists, 
teachers, patient family members, are all involved in the rehabilitative strategy, following 
implantation and during the follow-up. 
However it is possible to restore binaural hearing not only with bilateral hearing aids or 
bilateral cochlear implants, but also with a bimodal stimulation. In monolateral implanted 
children, it is always advisable, when possible, to pursue a bimodal stimulation in case of 
residual hearing in the contralateral ear, then still offering important advantages to the little 
patients [23]. 
 
 
CIS IN CHILDREN WITH INNER EAR MALFORMATIONS 
 
Inner ear malformations are not frequently implanted, but represent about 20% of 
congenital SNHL, both sporadic and syndromic forms [24]. In inner ear malformations 
undergoing cochlear implantation, medical imaging is even more important, both for etiologic 
diagnosis and for pre-surgical evaluation. CT (computed tomography) study of temporal bone 
is essential to highlight possible anatomic alterations of the facial nerve course that the 
surgeon should aware. It is also necessary to evaluate the width of internal auditory canal (in 
order evaluate the presence of a VIIIth nerve hypoplasia) and a labyrinth or cochlear aplasia; 
only the latter represent a contraindication to CI. Furthermore, CT can show cochlear 
calcification and/or a reduction of round window size, which may compromise the correct 

C. Aimoni, V. Corazzi, N. Mazza et al. 
 
718
insertion of CI [25]. MRI (magnetic resonance imaging) of the brain allows to analyze 
directly the acoustic nerve course and the labyrinthic fluids. 
In infants presenting a common cavity or incomplete cochlear partition (IP) as IP-I and 
IP-III, according to the classification of Sennaroglu and collaborators [26, 27], it has been 
recommended to perform a CI as early as possible, as frequently this kind of malformations 
have been reported to not to benefit from traditional hearing aids [24]. 
With the exception of common cavity or hypoplastic cochlea, in which the poor 
representation of neural cells could determine insufficient functional outcomes, data in 
literature report that implanted children with inner ear malformations undergo the same 
results of implanted children with normal anatomy, considering both the sound perception 
and the language development [28]. 
 
 
CI IN CHILDREN AND OTHER DISABILITIES 
 
The application of hearing aids and, even more, of CIs in children with hearing loss 
associated to other disabilities is a very complex choice as the rehabilitative process could 
result not adequately efficient compared to hearing impaired children without disabilities 
[29]. About 30-40% of children with hearing impairment shows disabilities associated, and in 
many cases it could be very difficult to predict post-implantation functional outcomes, 
particularly as also the audiologic and neuropsychiatric pre-implant evaluations can be not 
conclusive [30]. But, differently from the past, in the last 20 years an increasing number of 
multi-handicap children have been implanted, as, by now, it is reported that also these 
categories of little patients can benefit from electric hearing rehabilitation. The functional 
results of CI are not just limited to the verbal performances and language abilities, as CIs can 
also influence the global behavioral adjustments, the social development and integration with 
the environment, also having implications among quality of life of these children [31]. Pre-
implantation cognitive level has been reported to represent one of the most significant and 
reliable benefit predictive factor for CI outcome in these children [32]. Severe mental 
retardation, severe autistic disorders and psychiatric disorders with auto-aggressive behavior 
represent conditions that need an accurate pre-implant analysis, because they are frequently 
correlated to failure. 
 
 
BILATERAL CIS IN CHILDREN 
 
Before the 1990s, CI was generally performed unilaterally, considering also the economic 
aspects. In 2007, Murphy and O’Donoghue stated in their review [3] that pediatric bilateral 
cochlear implantation determines better auditive abilities, both in noise and in sound 
localization, compared to the functional outcomes of monolateral implanted children, 
probably due to the head-shadow effect. 
Even if data in literature don’t show significant functional differences between 
simultaneously and sequentially bilaterally implanted adults [33], there are data supporting 
the fact that children undergoing an early bilateral simultaneous implantation show better 
speech recognition and language development, compared to children with sequential bilateral 

Binaural, Sequential or Simultaneous Cochlear Implants in Children 
 
719
implantation [34, 35]. Furthermore, it is well known that there is a critical period for the 
binaural system development, due to the cerebral plasticity of the first months of life and the 
auditive experience. In fact, data in literature show worst functional results in sequentially 
bilateral implanted children, with the second CI introduced with a delay, after this critical 
temporal window [36, 37, 38]. 
The gold standard for a harmonious language and cognitive development is represented 
by cochlear implantation under or around 12 months of life [20, 39, 40, 41], even if, by now, 
there are poor data about this category of candidates for CI and comparative studies between 
implanted children are challenging and scarcely significant, primarily because of an 
insufficient follow-up and of a lack of homogeneity of the verbal perception and production 
evaluations in so little children. 
 
 
CONCLUSION 
 
CI is still an expensive therapeutic solution, in consideration of the advanced implant 
technologies and the continuous evolution of the speech processor, the receiver/stimulator and 
the electrode array. Nonetheless, CI has a so relevant impact on the quality of life that, on the 
whole, it represents a crucial cost-effective device for hearing impaired children [22]. 
It is likely that, in the future, other treatment could be available (i.e., inner ear 
regenerative approaches by stem cell or genetic therapy); also in this view, some authors still 
have some concerns when indicating a bilateral CI. However the possible benefits of restoring 
binaural hearing should be carefully taken in consideration. 
 
 
REFERENCES 
 
[1] 
Bubbico, L., Rosano, A. & Spagnolo, A. (2007). Prevalence of prelingual deafness in 
Italy. Acta Otorhinolaryngol. Ital., 27, 17-21. 
[2] 
Bauer, P. W., Sharma, A., Martin, K. & Dorman, M. (2006). Central auditory 
development in children with bilateral cochlear implants. Arch. Otolaryngol. Head. 
Neck. Surg., 132, 1133–1136. 
[3] 
Murphy, J. & O’Donoghue, G. (2007). Bilateral cochlear implantation: an evidence-
based medicine evaluation. Laryngoscope., 117, 1412–1418. 
[4] 
Bichey, B. G. & Miyamoto, R. T. (2008). Outcomes in bilateral cochlear implantation. 
Otolaryngol. Head. Neck. Surg., 138, 655–661. 
[5] 
Korver, A. M., Admiraal, R. J., Kant, S. G., Dekker, F. W., Wever, C. C., Kunst, H. P., 
Frijns, J. H., Oudesluys-Murphy, A. M. & DECIBEL-collaborative study group, 
(2011). Causes of permanent childhood hearing impairment. Laryngoscope., 121(2), 
409-16. 
[6] 
American Academy of Pediatrics, Joint Committee on Infant Hearing, (2007). Year 
2007 position statement: Principles and guidelines for early hearing detection and 
intervention programs. Pediatrics., 120, 898-921. 
[7] 
Harlor, A. D. & Jr; Bower, C. Committee on Practice and Ambulatory Medicine; 
Section on Otolaryngology-Head and Neck Surgery, (2009). Hearing assessment in 

C. Aimoni, V. Corazzi, N. Mazza et al. 
 
720
infants and children: recommendations beyond neonatal screening. Pediatrics, 124(4), 
1252-63. 
[8] 
Fortnum, H. & Davis, A. (1997). Epidemiology of permanent childhood hearing 
impairment in Trent Region. 1985-1993. Br. J. Audiol., 31, 409-46. 
[9] 
Harrison, M., Roush, J. & Wallace, J. (2003). Trends in age of identification and 
intervention in infants with hearing loss. Ear. Hear., 24, 89-95. 
[10] Nikolopoulos, T. P. (2015). Neonatal hearing screening: what we have achieved and 
what needs to be improved. Int. J. Pediatr. Otorhinolaryngol., 79(5), 635-7. 
[11] Joint Committee on Infant Hearing, American Academy of Audiology, American 
Academy of Pediatrics, American Speech-Language-Hearing Association, Directors of 
Speech and Hearing Programs in State Health and Welfare Agencies, (2000). Year 
2000 position statement: principles and guidelines for early hearing detection and 
intervention programs. Joint Committee on Infant Hearing, American Academy of 
Audiology, American Academy of Pediatrics, American Speech-Language-Hearing 
Association, Directors of Speech and Hearing Programs in State Health and Welfare 
Agencies. Pediatrics., 106(4), 798-817. 
[12] Fagan, M. K. (2015). Why repetition? Repetitive babbling, auditory feedback, and 
cochlear implantation. J. Exp. Child. Psychol., 137, 125-136. 
[13] Marno, H., Guellai, B., Vidal, Y., Franzoi, J., Nespor, M. & Mehler, J. (2016). Infants’ 
selectively pay attention to the information they receive from native speaker of their 
language. Front. Psychol., 7, 1150. 
[14] American Academy of Audiology (A.A.A.). American Academy of Audiology Clinical 
Practice Guidelines on Pediatric Amplification. June 2013. Available from: URL: 
http://www.audiology.org/sites/default/ 
files/publications/PediatricAmplificationGuidelines.pdf. 
[15] Fretz, R. J. & Fravel, R. P. (1985). Design and function: a physical and electrical 
description of the 3M house cochlear implant system. Ear. Hear., 6(3), 14S-19S. 
[16] O’Donoghue, G. (2013). Cochlear implants – science, serendipity, and success. N. 
Engl. J. Med., 369, 1190-3. 
[17] Yawn, R., Hunter, J. B., Sweeney, A. D. & Bennett, M. L. (2015). Cochlear 
implantation: a biomechanical prosthesis for hearing loss. F1000Prime Rep. 7, 45, doi: 
10.12703/P7-45, eCollection 2015. 
[18] Kirkby-Strachan, G. & Que-Hee, C. (2016). Implantable hearing devices – An update. 
Aust. Fam- Physician., 45(6), 370-3. 
[19] Burian, K., Hochmair, E., Hochmair-Desoyer, I. & Lessel, M. R. (1979). Designing of 
and experience with multichannel cochlear implants. Acta Otolaryngol., 87, 190-5. 
[20] Gifford, R. H. Pediatric Cochlear Implantation: candidacy and outcomes for non-
traditional candidates. 2015, May 1st. Available from: URL: http://www.fda.gov/ 
downloads/advisorycommittees/committeesmeetingmaterials/medicaldevices/medicald
evicesadvisorycommittee/earnoseandthroatdevicespanel/ucm445483.pdf. 
[21] Carlson, M. L., Sladen, D. P., Haynes, D. S., Driscoll, C. L., DeJong, M. D., Erickson, 
H. C., Sunderhaus, L. W., Hedley-Williams, A., Rosenzweig, E. A., Davis, T. J. & 
Gifford, R. H. (2015). Evidence for the expansion of pediatric cochlear implant 
candidacy. Otol. Neurotol., 36(1), 43-50. 
[22] Martini, A., Bovo, R., Trevisi, P., Forli, F. & Berrettini, S. (2013). [Cochlear implant in 
children: rational, indications and cost/efficacy]. Minerva Pediatr., 65, 325-339. 

Binaural, Sequential or Simultaneous Cochlear Implants in Children 
 
721
[23] Ching, T. Y. C. (2005). The evidence calls for making binaural-bimodal fittings 
routine. Hear. J., 58, 32-41. 
[24] Sennaroglu, L. (2010). Cochlear implantation in inner ear malformations—a revie 
article. Cochlear Implants Int., 11(1), 4-41. 
[25] Alexander, A., Caldemeyer, K. S. & Rigby, P. (1998). Clinical and surgical application 
of reformatted high-resolution CT of the temporal bone. Neuroimaging Clin. N. Am., 8, 
631-650. 
[26] Sennaroglu, L. & Saatci, I. (2004). Unpartitioned versus incompletely partitioned 
cochleae: radiologic differentiation. Otol. Neurotol., 25, 520-9. 
[27] Sennaroglu, L., Sarac, S. & Ergin, T. (2006). Surgical results of cochlear implantation 
in malformed cochlea. Otol. Neurotol., 27, 615-23. 
[28] Kim, L. S., Jeong, S. W., Huh, M. J. & Park, Y. D. (2006). Cochlear implantation in 
children with inner ear malformations. Ann. Otol. Rhinol. Laryngol., 115, 205-14. 
[29] Nikolopoulos, T. P. & Kiprouli, K. (2004). Cochlear implant surgery in challenging 
cases. Cochlear Implants Int., 5(Suppl1), 56-63. 
[30] Berrettini, S., Forli, F., Genovese, E., Santarelli, R., Arslan, E., Chilosi, A. M. & 
Cipriani, P. (2008). Cochlear implantation in deaf children with associated disabilities: 
challenges and outcomes. Int. J. Audiol., 47(4), 199-208. 
[31] Wiley, S. & Meinzen-Derr, J. (2013). Use of the ages and stages questionnaire in 
young children who are deaf/hard of hearing as a screening for additional disabilities. 
Early Hum. Dev., 89, 295-300. 
[32] Yang, H. M., Lin, C. Y., Chen, Y. J. & Wu, J. L. (2004). The auditory performance in 
children using cochlear implants: effects of mental function. Int. J. Pediatr. 
Otorhinolaryngol., 68(9), 1185-8. 
[33] Reeder, R. M., Firszt, J. B., Holden, L. K. & Strube, M. J. (2014). A longitudinal study 
in adults with sequential bilateral cochlear implants: time course for individual ear and 
bilateral performance. J. Speech Lang. Hear. Res., 57, 1108-26. 
[34] Lammers, M. J., Venekamp, R. P., Grolman, W. & van der Hejden, G. J. (2014). 
Bilateral cochlear implantation in children and the impact of the inter-implant interval. 
Laryngoscope., 124, 993-9. 
[35] Bauer, P. W., Sharma, A., Martin, K. & Dorman, M. (2006). Central auditory 
development in children with bilateral cochlear implants. Arch. Otolaryngol. Head. 
Neck. Surg., 132(10), 1133-6. 
[36] Gordon, K. A., Jiwani, S. & Papsin, B. C. (2013). Benefits and detriments of unilateral 
cochlear implant use on bilateral auditory development in children who are deaf. Front. 
Psychol., 4, 719. 
[37] Lau, E. Critical review: are simultaneous bilateral cochlear implants more effective in 
promoting normal functioning bilateral auditory pathways in children than sequential 
bilateral cochlear implants? 2010. Available from: URL: https://www.uwo.ca/ 
fhs/csd/ebp/reviews/2010-11/Lau.pdf. 
[38] Key, A. P., Porter, H. L. & Bradham, T. (2010). Auditory processing following 
sequential bilateral cochlear implantation: a pediatric case study using event-related 
potentials. J. Am. Acad. Audiol., 21(4), 225-38. 
[39] Szagun, G. & Schramm, S. A. (2016). Sources of variability in language development 
of children with cochlear implants: age at implantation, parental language, and early 
features of children’s language construction. J. Child. Lang., 43(3), 505-36. 

C. Aimoni, V. Corazzi, N. Mazza et al. 
 
722
[40] Szagun, G. & Stumper, B. (2012). Age or experience? The influence of age at 
implantation and social and linguistic environment on language development in 
children with cochlear implants. J. Speech. Lang. Hear. Res., 55, 1640-54. 
[41] Cuda, D., Murri, A., Guerzoni, L., Fabrizi, E. & Mariani, V. (2014). Pre-school 
children have better spoken language when early implanted. Int. J. Pediatr. 
Otorhinolaryngol., 78(8), 1327-31. 
 
 

In: Encyclopedia of Audiology and Hearing Research 
ISBN: 978-1-53617-702-2 
Editors: Erno Larivaara and Senja Korhola 
© 2020 Nova Science Publishers, Inc. 
 
 
 
 
 
 
 
Chapter 51  
 
 
 
VIRTUAL REALITY FOR COCHLEAR  
IMPLANT SURGERY 
 
 
Patorn Piromchai*, MD 
Department of Otorhinolaryngology, Faculty of Medicine,  
Khon Kaen University, Khon Kaen, Thailand 
Department of Otolaryngology, Royal Victorian Eye and Ear Hospital,  
University of Melbourne, East Melbourne, Australia 
 
 
ABSTRACT 
 
The ultimate surgical steps of cochlear implantation are facial recess approach and 
an insertion of the electrode through the cochleostomy which require repetitive practice 
to acquire the appropriate skills before entering the operating room. However, the human 
cadaveric temporal bones are a scarce resource. This problem limited the trainee chance 
to practice to the optimum level. 
Virtual reality has been introduced to the medical field and is now used in medical 
education as an alternative high fidelity simulator. Many studies have found that virtual 
reality simulators have improved the operative performance of the trainees. The major 
components of successful learning that has contributed to the efficacy of the virtual 
reality system are the ability to provide repetitive practice under a controlled 
environment, self-directed learning and proved for a construct validity. 
The author of this chapter is a surgeon and developer of the surgical virtual reality 
system of the temporal bone based in Melbourne, Australia, which is the only institute 
that located in the Asia-Oceania region. He will share his expertise on the future of this 
virtual reality to maximize the goal of cochlear implant surgery. 
 
Keywords: otolaryngology, surgery, planning, virtual reality 
 
 
 
                                                        
* Corresponding Author’s Email: patorn@gmail.com. 

Patorn Piromchai 
 
724
INTRODUCTION 
 
Current advances in the computer-generated virtual environment, namely virtual reality 
(VR) has enabled us to simulate the training environment for surgical education. Surgical 
training in human subjects has the aim for perfection. Any untoward errors, intend or not 
intend, are not acceptable. Unlike the practice on non-human, this can be done with the 
freedom of perfection. The surgeon usually needs to pass the certain amounts of practices on 
non-human models or cadavers to ensure that their skills were close to perfection and ready to 
practice on the patients. 
The proper training configuration to improve the surgical skills such as psychomotor and 
technical skill is essential for excellent surgical outcomes and safety of the patients. Virtual 
reality can simulate the complex surgical procedure, including temporal bone surgery and 
cochlear implantation. Virtual reality offers the attractive possibility for the novice, surgical 
trainee, and experienced surgeons. The novice and surgical trainee can acquire core 
competencies and dexterity in the training platform without doing harm to the patient. On the 
other hands, the experience surgeons can use the virtual reality platform as the surgical 
planning tool in complicated surgical procedures. 
This chapter will explore the current evidence of the virtual reality platforms as the 
surgical training tool for cochlear implant surgery and associated procedures. 
 
 
WHAT IS THE VIRTUAL REALITY SIMULATION? 
 
Surgical training is a field of specialization that is heavily reliant on the model of 
apprenticeship. Traditionally, surgical residents are required to operate on a pre-defined 
number of cases under the supervision of his/her mentor. With recent legislation limiting the 
working hours of surgical trainees, exposing them to an adequate number of cases has 
become a non-trivial issue. Limited training hours combined with the need to serve a growing 
population has resulted in calls for a more efficient program of surgical education. Within this 
context, simulation has emerged as an important platform for which medical education 
programs are developed.  
Simulation is an ideal medium in which principles of adult learning can be effectively 
embodied [1]. While some of these principles are easily accomplished through the traditional 
mentor-mentee model of surgical training, others, such as the need to match the teaching 
technique to the diversity and background of the trainee may be harder to achieve, as it is 
usually dependent on the style of instruction of the mentor. Further, with simulation, it is 
possible to allow trainees to be actively involved in the surgery at an earlier stage of learning 
without undue risk. 
Virtual reality simulation is the combination of computer-generated environments with 
tactile, auditory and visual stimuli that promote increased authenticity [2]. It supports one of 
the major principles of skill acquisition: deliberate practice [3] - goal oriented, repeated 
performance that allows trainees to refine their skills and appreciate variations in the way a 
single activity is constituted. Figure 1 shows the three-dimensional model from the virtual 
reality system. 
 

Virtual Reality for Cochlear Implant Surgery 
 
725
 
Figure 1. Three dimension model of the malleolus, incus, and stapes. 
Virtual reality simulation-based surgical training is fast becoming an attractive area of 
research [4-6]. For example, Madan and Frantzides [7] compared virtual reality laparoscopic 
training with box trainers and no training and found that the post-training score in the virtual 
reality group was significantly higher. Rose and Pedowitz [8] observed that virtual reality 
arthroscopic training improves the skills of trainees. Palter and Grantcharov [9] showed that 
deliberate individualized practice on a virtual reality simulator improves the technical 
performance of surgical trainees in the operating room for laparoscopic cholecystectomy. 
Gala et al. [10] observed that the technical skills of residents performing laparoscopic 
bilateral midsegment salpingectomy trained on a simulator were higher than those taught 
using traditional teaching methods. 
 
 
CHALLENGES IN SURGICAL TRAINING 
 
The surgical skills are complex and can be divided into technical and non-technical skills. 
Technical competencies in the operating theater included psychomotor skill (physical co-
ordination providing precise movement), procedural skill (task accomplishment through a 
sequence of actions), and surgical anatomy skill (knowledge of specific anatomical 
structures). The non-technical competencies in the operating theater included situational 
awareness skill, decision-making skill, communication and teamwork skill, and leadership 
skill. Non-technical skills are equally important for achieving good surgical outcomes. Non-
technical skills can be broadly classed as those required to make the correct decisions at the 
right time during an operation, and those required to integrate and lead the operating room 
team [11]. 
In the current apprenticeship model, the mentor starts as a role model for the trainee to 
observe. Under the mentor’s discretion, the mentor will gradually change to a coach who 
guides the trainee towards competency. The surgical trainee is provided with increasing 
challenges and subsequently achieves the capability for the articulation of the procedural 

Patorn Piromchai 
 
726
steps. Lastly, expertise arises from reflection and the ability to explore and invent new 
strategies [12].  
For patient safety, the mentor needs to ensure that residents have appropriate capabilities 
before practice on patients. While this practice has served the medical community well over 
the years, it has not been entirely devoid of problems. One of the major issues is insufficient 
numbers of patients creating a lack of suitable cases for teaching, resulting in inadequate 
exposure to scenarios trainees may encounter. Other problems are the restrictions on working 
hours limiting the available time for training and the increased awareness of patient, quality 
and safety issues. 
Many of these challenges, resulting in increasing specialization, discontinuity in patient 
care, and an increasing duration of training as consequences [13]. It is clear that the future 
surgical training program can no longer rely on the apprenticeship model only. The virtual 
reality may be the useful tool adjunct to the future training program. 
 
 
VIRTUAL REALITY SURGICAL TRAINING 
 
In the current surgical training program, several training methods were introduced for 
better learning outcomes, including lectures, live or video-recorded demonstration, computer 
assisted learning, and simulation-based learning. Cadaveric dissection has been the standard 
surgical simulation training method since the start of modern medicine. However, due to the 
restraint resource of cadaver availability, the inanimate objects such as mannequins, 
simulated patients and more recently, virtual reality surgical training systems were developed. 
Cook et al. [14] conducted the review on technology-enhanced simulation training for 
health professional learners. They found the large effects on the results of knowledge, skills, 
and behavior, and with moderate effects on patient-related outcomes when using the 
technology-enhanced simulation. The high-fidelity medical simulations such as virtual reality 
can facilitate learning under the right conditions. The recent studies integrate the simulation-
based exercises into the standard medical school or postgraduate educational curriculum. The 
results suggested an essential feature of their efficient use, including a range of task difficulty 
level, multiple learning strategies, capture clinical variation, controlled environment and 
individualized learning [15]. 
 
Table 1. Features and uses of medical simulations that lead  
to effective learning 
 
Features of Simulations (in order of importance) 
1. Feedback is provided during the learning experience. 
2. Learners engage in the repetitive practice. 
3. The simulator is integrated into the medical curriculum. 
4. Learners practice with increasing levels of difficulty. 
5. The simulator is adaptable to multiple learning strategies. 
6. The simulator captures clinical variation. 
7. The simulators are embedded in a controlled environment. 
8. The simulator permits individualized learning. 
9. Learning outcomes are clearly defined and measured. 
10. The simulator is a valid (high-fidelity) approximation of clinical practice 

Virtual Reality for Cochlear Implant Surgery 
 
727
Issenberg et al. [15] and McGaghie et al. [16] have proposed features that should be 
included in a simulator for effective skill acquisition (Table 1). Many surgical simulators have 
been based on these principles, so as to optimize their educational value [17, 18]. 
The simulation-based training can augment with the current apprenticeship model by 
allowing for repeated and deliberate practice for optimal skill development that can map onto 
the real-life clinical situation. Although simulation-based training has fewer of the time and 
safety-related constraints compared with the surgical apprenticeship, implementation into the 
surgical curriculum infrequently considers the individual and timely need of the trainee. 
Instead, simulation-based skills training is often organized as intensive courses, boot camps, 
and similar, isolated, single-instance training opportunities. From an educational point of 
view, this can result in simulation-based training being uncoupled from the trainees’ everyday 
work and the transference of the acquired skills to clinical practice can, therefore, be a 
challenge [19]. 
 
 
TRAINING IN TEMPORAL BONE SURGERY 
 
Temporal bone dissection is the essential and standard practice for current 
Otolaryngology – Head and Neck Surgery residency training programs worldwide. Temporal 
bone dissection will form the anatomical basis and the relation of the temporal bone structure 
such as mastoid, middle ear, and inner ear. During the temporal bone dissection, the trainee 
will collect the surgical skills experience including drill handling, operating microscope use, 
suction and irrigation, and knowledge of surgical procedural steps. The dissection is usually 
done under the supervision of the instructor both in temporal bone dissection workshop or 
temporal bone laboratory. 
The temporal bone dissection workshop was designed for the residents who have minimal 
or no experience with temporal bone. The course often includes lectures, video 
demonstrations, and temporal bone drilling on cadavers and/or simulated temporal bones. 
Currently, there was a cochlear implantation workshop which will cover the surgical 
technique and electrode insertion guidelines. Participants will have their workstation and 
specimens ranging from cadaveric to three dimensions bone models highlighting different 
anatomies and patient age groups. 
The drilling of human cadaveric temporal bones closely mimics real life conditions, 
including the variable pneumatization of the temporal bone. However, temporal bone lab 
facilities need high maintenance costs and limited availability of cadaveric temporal bone. 
The temporal bone workshop is also facing the problem of operating cost. The workshop 
requires the experience and well-known faculties to attract the trainees. For a reason above, 
this limited the trainee opportunity for optimal practice. 
Many authors have addressed these problems and the proposed use of alternative 
simulators that can replace or augment training for cadaveric temporal bone dissection, which 
ranges from simple models to virtual reality simulators [20-22]. Some authors prefer bony 
models to practice temporal bone dissection surgery [22], but the majority prefer virtual 
reality systems. Beside of temporal bone dissection simulators, some authors have also 
developed the middle ear surgery simulator for myringotomy [23, 24] and benign paroxysmal 
positional vertigo treatment [25]. 

Patorn Piromchai 
 
728
VIRTUAL REALITY TEMPORAL BONE SIMULATORS 
 
Current Systems 
 
The VOXEL-MAN TempoSurg simulator is the first commercially available temporal 
bone virtual reality simulator [18]. Volumetric high-resolution computed tomography images 
of the temporal bone are used to produce a 3-dimensional representation. The surgical site is 
displayed in stereoscopic mode, which the user views through shutter glasses. Vital structures 
are color-coded. The station houses a computer with software that is linked to a force-
feedback hand stylus. This stylus serves as a virtual drill, which is activated by the foot pedal 
to alter the appearance of the virtual temporal bone. The drill responds to forces, according to 
the contact situation visible on screen, allowing the user to experience changes in pressure. 
The computer records its location, direction in space, and some performance measures such 
as excessive force or injuries relating to vital structures. The user can alter the surgical 
orientation, drill size, type, and rotation speed. 
Another commercial model of the temporal bone dissection simulator is the Mediseus 
Surgical Simulator (CSIRO/University of Melbourne temporal bone simulator). This 
simulator consists of a simulated operating microscope. The user interacts with a 3-D 
volumetric virtual rendering of a cadaver temporal bone, which is controlled by the surgeon 
using two haptic motorized 3-D pointing devices. These devices allow the computer to track 
the exact movement of the tool relative to the virtual bone model. The bone model was given 
color and hardness properties to provide visual and tactile cues that helped to simulate real 
operating conditions. The coloring of the bone also changes as the bone is progressively 
thinned over the critical structures such as the sigmoid sinus, dura, and facial nerve. 
Physiological functions, such as bleeding from the sigmoid sinus and facial nerve monitoring 
with auditory and visual feedback were also built into the simulator [26]. 
Many ear surgery simulators are currently under development [27-29]. They mostly share 
common features of haptic feedback. Some of them also work with acoustic feedback. 
 
 
Validity of Simulator Systems 
 
For face and content validation, the VOXEL-MAN TempoSurg simulator group recruited 
25 Otolaryngologists and 60 trainees. They found that the familiarization took longer in the 
experienced group (p = 0.01) but user-friendliness was positively rated. Seventy percent of 
participants rated anatomical appearance as acceptable. Trainees were more likely to 
recommend temporal bone simulation to a colleague than trainers (p = 0.01). The 
transferability of skills to the operating room was rated neutral by the participants [18]. 
To evaluate the construct validity, the Mediseus Surgical Simulator group recruited a 
total of 27 participants for the study. Twelve of these participants were Otolaryngology 
surgeons, 6 were residents, and 9 were medical students. The authors found that the experts 
completed the simulated tasks at significantly shorter times than the other two groups (experts 
mean 22 minutes, residents mean 36 minutes, and novices mean 46 minutes; p = 0.001). 
Novices were more likely to injure structures such as the dura compared to experts (23 
injuries vs. 3 injuries, p = 0.001) [26]. 

Virtual Reality for Cochlear Implant Surgery 
 
729
Efficacy of Simulators on Skills Improvement 
 
The VOXEL-MAN TempoSurg simulator group [30] conducted a before-after 
investigation and found that some surgical skills that were evaluated based on the Objective 
Structured Assessment of Technical Skills (OSATS) exhibited a significant improvement 
after practices were conducted by using the virtual reality temporal bone simulator system. 
The OSAT scores were improved for both tegmen task from 2.125 to 3.1 (p = 0.026) and 
sigmoid task from 2 to 2.75 (p = 0.0098). The time to complete the tasks also decreased from 
8.37 to 5.39 minutes (p = 0.018) for tegmen task and from 8.99 to 8.68 minutes (p = 0.594) 
for the sigmoid task. 
The Mediseus Surgical Simulator from University of Melbourne’s virtual reality research 
group did further research on the improvement in the users’ skills by conducting controlled 
trials comparing the simulator training with the standard textbook based training. They found 
that the participants trained on the simulator performed significantly better than the 
participants trained using conventional training methods [20, 21]. The experts were invited to 
review the participant’s task through a sequence of actions (procedural score). They found 
that the virtual reality group performed better than conventional training group (Table 2). 
Also, for procedural skill evaluation, the authors [20, 21] also inspected the dissection 
results by evaluating the end-product temporal bones. 
The end-product score represents the combination of anatomical knowledge, procedural 
skill and psychomotor behavior. They found that the virtual reality group performed better 
than conventional training group, but there was no statistically significant difference  
(Table 3). 
The virtual simulation for temporal bone dissection group (17, 31) conducted a controlled 
trial comparing the virtual reality temporal bone dissection training simulator with the 
cadaveric temporal bone dissection training. Two studies involving 92 participants used the 
35-item Welling scale to determine end-product scores for the virtual reality group and 
cadaveric temporal bone dissection training group. There was no statistically significant 
difference between virtual reality group and cadaveric temporal bone dissection training 
group (Table 4). 
 
Table 2. Comparing the procedural score of the Mediseus virtual reality  
temporal bone dissection training with conventional training 
 
Study 
VRa Mean (SD) 
Control Mean (SD) 
Mean difference (95% CI) 
Zhao 2011a [20] 
3.54 (0.82) 
2.51 (0.97) 
1.03 (0.24 - 1.82) 
Zhao 2011b [21] 
3.56 (1.79) 
2.97 (1.72) 
0.59 (-0.95 - 2.13) 
a. VR = virtual reality. 
 
Table 3. Comparing the end-product score of the Mediseus virtual reality  
temporal bone dissection training with conventional training 
 
Study 
VRa Mean (SD) 
Control Mean (SD) 
Mean difference (95% CI) 
Zhao 2011a [20] 
2.79 (0.79) 
1.98 (1.12) 
0.81 (-0.04 - 1.66) 
Zhao 2011b [21] 
3.48 (1.87) 
2.64 (1.46) 
0.84 (-0.63 - 2.31) 
a. VR = virtual reality. 

Patorn Piromchai 
 
730
Table 4. Comparing the end-product score of virtual reality temporal  
bone dissection training with cadaveric temporal bone dissection training 
 
Study 
VRa Mean (SD) 
Control Mean (SD) 
Mean difference (95% CI) 
Wiet 2009 [17] 
23 (8.6) 
17 (8.5) 
6.00 (-3.68 - 15.68) 
Wiet 2012 [31] 
2.2 (0.54) 
2.14 (0.56) 
0.06 (-0.21 - 0.33) 
a. VR = virtual reality. 
 
The results from these studies showed that the virtual reality temporal bone dissection 
training is more effective than traditional training methods and as effective as cadaveric 
temporal bones as assessed by the summative end-product score. 
 
 
COCHLEAR IMPLANTATION 
 
The cochlear implantation is the procedure to restore hearing for deaf or profound 
hearing loss patients. The procedure itself is highly invasive, and the complications from the 
operation can lead to dead. The implant device needs some space to fit tightly behind the ear. 
The mastoid cortex will be drilled out to make space fit the implant device and make the 
passage access the middle ear. The round window is the anatomical landmark that we usually 
make the cochleostomy antero-inferiorly to it for the cochlear implant electrode. The 
electrode insertion is the essential final step. To avoid the trauma to the cochlea, the surgeon 
needs to be familiar with the anatomy of the cochlea (Figure 2). The proper force and angle of 
electrode placement will lead to better hearing results. After the electrode was inserted, the 
cochlear implant device will be tested. 
The above surgical step will operate under the microscope as the structures are small and 
need a delicate maneuver. Throughout this process, there is a risk to introduce trauma to the 
brain, facial nerve, and vessels. The risk will be increased if the patient has an anatomical 
variation or change of the normal structure affected by the diseases.  
 
 
CURRENT TECHNOLOGY FOR COCHLEAR IMPLANT SURGERY 
 
Based on the virtual temporal bone training system for the trainee physicians, which is 
solely for the educational purpose, the developers step to cochlear implant surgery to make a 
benefit for the patients. The following technology emerges. 
 
 
Virtual Guidance for Cochlear Implantation 
 
Hara M et al. have demonstrated the possibility of using the 3D image as a guide to 
surgery by using preoperative CT images at a slice thickness of 0.5 mm. The inner ear 
labyrinth, auditory ossicles, and FN were manually shaded in blue, red, and yellow, 
respectively, maintaining the shape of these structures. The images were converted from 
colored 2D-CT images to 3D images using the Delta Viewer (DV freeware, Japan).  

Virtual Reality for Cochlear Implant Surgery 
 
731
 
Figure 2. The osseous labyrinth including cochlear. 
 
 
Figure 3. Screenshot from Delta Viewer software. 
The authors successfully depict the structures of the inner ear, ossicles, and facial nerve 
as 3D images, which are very easy to understand visually and intuitively (Figure 3). These 3D 
images of the malformed ear are useful in preoperative image simulation and surgical 
planning for those performing a cochlear implant procedure. 
 
 

Patorn Piromchai 
 
732
Case-Specific Virtual Reality Surgery 
 
The principal aims to make the patient-specific planning before doing the cochlear 
implant surgery is the patient’s safety and benefit. The virtual reality technology can help the 
physicians to improve the patient safety by allowing the surgeon to study the individual’s 
anatomy and perform the virtual surgery under the stress-free environment. For complicated 
cases, the doctor can test the surgical plan options and learn from the mistake to reach the best 
surgical approach for each patient. The system can also be used to train the physician trainees 
to familiar with the operation and surgical anatomy before practicing on the real patient.  
The simulator has been used extensively in other fields to simulate the dangerous 
environment that usually not encounter in the normal activities such as aviation. This 
principle was applied in the medical field. In cochlear implant surgery, the temporal bone 
simulator can create the patient-specific three-dimensional model that enables the surgeon to 
interact freely with the model from the patient-specific data gathering from various imaging 
sources such as computed tomography (CT) or magnetic resonance imaging (MRI). 
The virtual reality surgery system has the potential to be more than just an educational 
tool in the medical school. It is well established that procedural success in complex tasks is 
the result of the utilization of adequate technical as well as nontechnical skills. Human factors 
such as teamwork, situational awareness, communication, and decision-making are vital 
aspects to ensure a good outcome after any operative procedure [32]. 
Arora et al. [33] have investigated the feasibility of performing case-specific virtual 
reality temporal bone simulator at St Mary’s Hospital, Imperial College NHS Trust, London, 
UK in sixteen participants. Most of the patient found that the case rehearsal could refine the 
surgical approach in response to individual anatomy. For example, the variant anatomy such 
as the degree of pneumatization, low-lying dura and high sigmoid sinus influent subsequent 
task performance. However, case rehearsal of procedures involving the facial nerve and 
removal of cholesteatoma were not perceived to be feasible on the existing platform due to 
lack of soft tissue reconstruction and suboptimal depth perception during deeper temporal 
bone dissection. The summary of the benefits and limitations were demonstrated in Table 5. 
The University of Melbourne’s virtual reality team has developed a new auto-
segmentation algorithm to overcome the lack of soft tissue reconstruction. Figure 4 below 
showed the small blue and pink area representing dura mater and sigmoid sinus. 
 
Table 5. Summary of benefits and limitations of case-specific surgical rehearsal and 
other surgical planning strategies 
 
 
Advantages 
Limitations 
Virtual reality surgical 
rehearsal 
Pre-operative practice 
Surgical trial for best 
approach and technique 
Cannot rehearse particular procedure 
due to technical limitation 
3D anatomy reconstruction 
from 2D imaging 
Aid 3D conceptual of the 
anatomy 
Less useful for experienced surgeon 
2D imaging (CT, MRI) 
Surgical planning 
Need the conceptual jump from 2D 
to 3D 
 
 

Virtual Reality for Cochlear Implant Surgery 
 
733
 
Figure 4. The screenshot from University of Melbourne’s virtual reality system. 
 
Real-Time Modeling Electrode Insertion 
 
The electrode insertion is the important step of cochlear implant surgery. The right force 
administration and correct angle of insertion can be influent the hearing outcome. If the 
surgeon uses too much force, the electrode can destroy the hair cells and can adversely 
penetrate the membranous labyrinth that will result in the displacing electrode. The angle of 
insertion is also an important factor to avoid the damage to cochlear. 
After cochleostomy to gaining access to the scala tympani had been done, the cochlear 
implant electrode was prepared and insert through this hole. After the tip of the electrode pass 
the hole, the surgeon will not able to see the tip of the electrode and need the resistance 
sensation to avoid the damage to the regional structure. 
Todd and Naghdy [34] have developed the real-time haptic model based on real physical 
data and force measurements, and analysis of implant behavior during insertion. The force 
feedback provides the simulator user with a more realistic experience; enhancing the sense of 
immersion into the virtual environment than would be expected from visual representation 
alone. The user can see and touch the virtual environment model during manipulation. Touch 
sensation is a vital information channel in real-world scenarios, particularly during surgery 
for tool/object interactions. Haptic-rendered simulators with real-time control have increasing 
application in medical education. Advances in computer processing power and the 
development of high-fidelity force-feedback devices with specialized software enable the 
reproduction of realistic human models that have real-world properties. 
In their model, the scala tympani was created which is the path of trajectory rather than 
modeled the cochlea as one chamber in other studies [35, 36]. Figure 5 shows a scala tympani 
in the cochlea. 
 
 

Patorn Piromchai 
 
734
 
Figure 5. Cross-sectional illustration of cochlear. 
The Toddd and Naghdy system design included cochlear implant insertion analysis and 
scala tympani parametric modeling, model optimizations and integration of features for 
enabling interactive, real-time insertion of a virtual implant into the model, with visual and 
force feedback delivered to the user during cochlear implant advancement. Upon running the 
simulation, the user can interact with the virtual environment using the haptic device. Force 
feedback is provided to the user as the surgeon performs real-time, virtual cochlear 
implantation into a surface description of the human scala tympani. 
The result from this study found that the degree of similarity between their virtual model 
and Teflon model of scala tympani is moderate. The electrode still has a chance of 
displacements from 0 to 5.3mm, 5.9 to 9.6 mm, 11.5 to 11.8 mm and 13.1 to 16.1 mm.  
They proposed the future work that includes modeling the basal membrane as a soft 
tissue structure, enabling surface deformations and puncturing, as well as the construction of 
the scala vestibuli as a secondary chamber for CI insertion. 
 
 
Who Can Get the Benefit of Virtual Reality System for  
Cochlear Implant Surgery? 
 
1. A child with profound hearing loss or deafness will get the most benefit from this 
system. As the anatomical structures of the child are still developing and do not reach 
the maximal growth point, the chance that the structure will be varied from the 
landmark that we usually encounter in the adults is high. 
2. An adult with the distortion of the anatomy. The distortion usually resulted from the 
diseases such as chronic otitis media or cholesteatoma. The diseases will destroy or 
invade the surrounding structure and distort the anatomical landmark. 
3. The profound or deafness patients who will undergo a cochlear implant surgery, but 
does not have a particular condition can also ask the surgeon to do the rehearsal for 
the safety reason. 

Virtual Reality for Cochlear Implant Surgery 
 
735
4. The surgeon himself will get confidence after a rehearsal in complicated cases. 
5. The trainee surgeon can practice in the virtual reality system before entering the 
operating room. 
 
 
CONCLUSION 
 
The virtual reality surgical training for cochlear implantation is in the development stage. 
An early result showed that this procedure is feasible and can enhance the safety of the 
patients. The implementation of this system will be happening soon after the results from 
clinical trials are published. 
 
 
REFERENCES 
 
[1] 
Bryan RL, Kreuter MW, Brownson RC. Integrating adult learning principles into 
training for public health practice. Health Promot Pract. 2009;10(4):557-63. 
[2] 
Lewis R, Strachan A, Smith MM. Is high fidelity simulation the most effective method 
for the development of non-technical skills in nursing? A review of the current 
evidence. The open nursing journal. 2012;6:82-9. 
[3] 
Ericsson KA. Deliberate Practice and the Acquisition and Maintenance of Expert 
Performance in Medicine and Related Domains. Academic Medicine. 2004;79(10):S70-
S81. 
[4] 
Tolsdorff B, Petersik A, Pflesser B, Pommert A, Tiede U, Leuwer R, et al. Individual 
models for virtual bone drilling in mastoid surgery. Computer Aided Surgery. 
2009;14(1-3):21-7. 
[5] 
Tolsdorff B, Pommert A, Hohne KH, Petersik A, Pflesser B, Tiede U, et al. Virtual 
reality: a new paranasal sinus surgery simulator. Laryngoscope. 2010;120(2):420-6. 
[6] 
van Dongen KW, Ahlberg G, Bonavina L, Carter FJ, Grantcharov TP, Hyltander A, et 
al. European consensus on a competency-based virtual reality training program for 
basic endoscopic surgical psychomotor skills. Surg Endosc. 2011;25(1):166-71. 
[7] 
Madan AK, Frantzides CT. Prospective randomized controlled trial of laparoscopic 
trainers for basic laparoscopic skills acquisition. Surgical endoscopy. 2007;21(2):209-
13. 
[8] 
Rose K, Pedowitz R. Fundamental Arthroscopic Skill Differentiation with Virtual 
Reality Simulation. Arthroscopy: the journal of arthroscopic & related surgery: official 
publication of the Arthroscopy Association of North America and the International 
Arthroscopy Association. 2014. 
[9] 
Palter VN, Grantcharov TP. Individualized deliberate practice on a virtual reality 
simulator improves technical performance of surgical novices in the operating room: a 
randomized controlled trial. Annals of surgery. 2014;259(3):443-8. 
[10] Gala R, Orejuela F, Gerten K, Lockrow E, Kilpatrick C, Chohan L, et al. Effect of 
validated skills simulation on operating room performance in obstetrics and gynecology 
residents: a randomized controlled trial. Obstetrics and gynecology. 2013;121(3):578-
84. 

Patorn Piromchai 
 
736
[11] Piromchai P, Avery A, Laopaiboon M, Kennedy G, O’Leary S. Virtual reality training 
for improving the skills needed for performing surgery of the ear, nose or throat. 
Cochrane Database Syst Rev. 2015(9):CD010198. 
[12] Reznick RK. Teaching and testing technical skills. Am J Surg. 1993;165(3):358-61. 
[13] Canter RJ. Training in surgery: time for a new approach. Clin Otolaryngol. 
2009;34(1):90-2. 
[14] Cook DA, Hatala R, Brydges R, Zendejas B, Szostek JH, Wang AT, et al. Technology-
enhanced simulation for health professions education: a systematic review and meta-
analysis. JAMA. 2011;306(9):978-88. 
[15] Issenberg SB, McGaghie WC, Petrusa ER, Lee Gordon D, Scalese RJ. Features and 
uses of high-fidelity medical simulations that lead to effective learning: a BEME 
systematic review. Med Teach. 2005;27(1):10-28. 
[16] McGaghie WC, Issenberg SB, Petrusa ER, Scalese RJ. Effect of practice on 
standardised learning outcomes in simulation-based medical education. Med Educ. 
2006;40(8):792-7. 
[17] Wiet GJ, Rastatter JC, Bapna S, Packer M, Stredney D, Welling DB. Training otologic 
surgical skills through simulation-moving toward validation: a pilot study and lessons 
learned. J Grad Med Educ. 2009;1(1):61-6. 
[18] Arora A, Khemani S, Tolley N, Singh A, Budge J, Varela DA, et al. Face and content 
validation of a virtual reality temporal bone simulator. Otolaryngol Head Neck Surg. 
2012;146(3):497-503. 
[19] Kneebone RL, Nestel D, Vincent C, Darzi A. Complexity, risk and simulation in 
learning procedural skills. Med Educ. 2007;41(8):808-14. 
[20] Zhao YC, Kennedy G, Yukawa K, Pyman B, O’Leary S. Improving temporal bone 
dissection using self-directed virtual reality simulation: results of a randomized blinded 
control trial. Otolaryngol Head Neck Surg. 2011;144(3):357-64. 
[21] Zhao YC, Kennedy G, Yukawa K, Pyman B, O’Leary S. Can virtual reality simulator 
be used as a training aid to improve cadaver temporal bone dissection? Results of a 
randomized blinded control trial. Laryngoscope. 2011;121(4):831-7. 
[22] Varadarajan V, Verma R, Auccott W. The portable temporal bone lab - a useful training 
adjunct for the ENT trainee. Clin Otolaryngol. 2010;35(5):449-50. 
[23] Sowerby LJ, Rehal G, Husein M, Doyle PC, Agrawal S, Ladak HM. Development and 
face validity testing of a three-dimensional myringotomy simulator with haptic 
feedback. J Otolaryngol Head Neck Surg. 2010;39(2):122-9. 
[24] Wheeler B, Doyle PC, Chandarana S, Agrawal S, Husein M, Ladak HM. Interactive 
computer-based simulator for training in blade navigation and targeting in 
myringotomy. Comput Methods Programs Biomed. 2010;98(2):130-9. 
[25] Steiner KV, Teixido M, Kung B, Sorensen M, Forstrom R, Coller P. A virtual-reality 
approach for the treatment of benign paroxysmal positional vertigo. Stud Health 
Technol Inform. 2007;125:451-3. 
[26] Zhao YC, Kennedy G, Hall R, O’Leary S. Differentiating levels of surgical experience 
on a virtual reality temporal bone simulator. Otolaryngol Head Neck Surg. 2010;143(5 
Suppl 3):S30-5. 
[27] Agus M, Giachetti A, Gobbetti E, Zanetti G, Zorcolo A, Picasso B, et al. A haptic 
model of a bone-cutting burr. Stud Health Technol Inform. 2003;94:4-10. 

Virtual Reality for Cochlear Implant Surgery 
 
737
[28] Kuppersmith RB, Johnston R, Moreau D, Loftin RB, Jenkins H. Building a virtual 
reality temporal bone dissection simulator. Stud Health Technol Inform. 1997;39:180-6. 
[29] Stredney D, Wiet GJ, Bryan J, Sessanna D, Murakami J, Schmalbrock P, et al. 
Temporal bone dissection simulation--an update. Stud Health Technol Inform. 
2002;85:507-13. 
[30] Francis HW, Malik MU, Diaz Voss Varela DA, Barffour MA, Chien WW, Carey JP, et 
al. Technical skills improve after practice on virtual-reality temporal bone simulator. 
Laryngoscope. 2012;122(6):1385-91. 
[31] Wiet GJ, Stredney D, Kerwin T, Hittle B, Fernandez SA, Abdel-Rasoul M, et al. Virtual 
temporal bone dissection system: OSU virtual temporal bone system: development and 
testing. Laryngoscope. 2012;122 Suppl 1:S1-12. 
[32] Willaert W, Aggarwal R, Bicknell C, Hamady M, Darzi A, Vermassen F, et al. Patient-
specific simulation in carotid artery stenting. Journal of vascular surgery. 
2010;52(6):1700-5. 
[33] Arora A, Swords C, Khemani S, Awad Z, Darzi A, Singh A, et al. Virtual reality case-
specific rehearsal in temporal bone surgery: a preliminary evaluation. International 
journal of surgery. 2014;12(2):141-5. 
[34] Todd CA, Naghdy F. Real-Time Modeling and Simulation for Cochlear Implantation; 
Visualization and Force Rendering during Virtual Prosthetic Insertions. International 
Journal of Modeling and Optimization. 2012;2(4):518. 
[35] Chen B, Clark GM, Jones R. Evaluation of trajectories and contact pressures for the 
straight nucleus cochlear implant electrode array—a two-dimensional application of 
finite element analysis. Medical engineering & physics. 2003;25(2):141-7. 
[36] Yoo SK, Wang G, Rubinstein JT, Vannier MW. Three-dimensional geometric 
modeling of the cochlea using helico-spiral approximation. Biomedical Engineering, 
IEEE Transactions on. 2000; 47(10):1392-402. 
 
 


In: Encyclopedia of Audiology and Hearing Research 
ISBN: 978-1-53617-702-2 
Editors: Erno Larivaara and Senja Korhola 
© 2020 Nova Science Publishers, Inc. 
 
 
 
 
 
 
 
Chapter 52  
 
 
 
CROSS-MODAL PLASTICITY IN DEAF CHILDREN 
WITH VISUAL-IMPAIRMENT: 
ELECTROPHYSIOLOGICAL RESULTS AFTER  
LONG-TERM USE OF COCHLEAR IMPLANTS 
 
 
Lidia E. Charroó-Ruíz*, MD, Alfredo Álvarez Amador, PhD, 
Antonio S. Paz Cordovés, MD, Sandra Bermejo Guerra, MD,  
Yesy Martín García, Beatriz Bermejo Guerra, MD,  
Beatriz Álvarez Rivero, MD, Manuel Sevila Salas, MD,  
José Antelo Cordovés, Eduardo Aubert Vázquez, PhD, 
Lourdes Díaz-Comas Martínez, PhD, Lídice Galán García, PhD, 
Fernando Rivero Martínez, MD, Ana Calzada Reyes, PhD  
and Mario Estévez Báez, PhD 
 
 
ABSTRACT 
 
Introduction: Given the multidimensional scope of Cochlear Implants (CI), there are 
growing needs to provide others measures for assessing the impact of the cochlear 
implantation, such as brain reorganization besides clinical measures of outcome related to 
communicative abilities.  
Objective: To assess the Cross-Modal Plasticity in deaf children with visual-
impairment after CI use, through the analysis of changes of the topographic distribution 
the cortical response of Somatosensory Evoked Potential by stimulation of median nerve. 
Methods: A case-control prospective study was carried out in a group of nine deaf 
children with visual-impairment. Cross-Modal Plasticity assessment was performed by 
testing Somatosensory Evoked Potentials (cortical response to median nerve stimulation, 
SEP N20) at different periods: prior to cochlear implantation and after the use of CI (after 
one and five years). In this chapter, we describe the results of Low-Resolution Brain 
                                                        
* Corresponding autor: Lidia E. Charroó-Ruíz clinical neurophysiologist. Associate professor, Cuban Center for 
Neuroscience, Havana, Cuba; lidia.charroo@infomed.sld.cu. 

L. E. Charroó-Ruíz, A. Álvarez Amador, A. S. Paz Cordovés et al. 
 
740
Electromagnetic Tomography (LORETA) used for the localization of electrical neuronal 
sources generators of SEP N20 response in deaf children with visua-impairment.  
Results: Cochlear Implants had a positive effect on lives of implanted children and 
their families. The study included results on topographic distribution the cortical response 
of SEP N20 where the visual and auditory areas are widely activated with somestesic 
stimuli in deaf children with visual-impairment with 7 or more years of sensory 
deprivation before implantation. A significant reduction in the topography of SEP N20 
was observed after five years of stimulation via CI. The analysis of the individual maps 
showed reduction of the over-activation found in children with 7 or more years before 
implantation, except for one child. These changes are related to the general development 
potential, possible concurrent conditions, and progression of the severity of the visual-
impairment.  
Conclusion: This study makes available electrophysiological evidence about Cross-
Modal Plasticity in deaf children with visual-impairment after long-term use of 
CIChanges in the topography of cortical response of SEP N20 could be observed in these 
children who receive CI, suggesting new brain reorganization of the auditory cortex when 
stimulated through CI. Evidences of Cross-Modal Plasticity may be an expression of how 
important is the somesthetic information in these subjects, probably due to the 
relationship with tactile language, as well as the functional interaction of auditory and 
somesthetic information during the auditory (re)habilitation post-CI.  
 
Keywords. Cross-Modal Plasticity, deaf children with visual-impairment, Somatosensory 
Evoked Potentials, cochlear implant, low-resolution brain electromagnetic tomography, 
LORETA 
 
 
INTRODUCTION 
 
The severe-to-profound sensorineural hearing loss (SNHL), associated with a visual 
impairement that classified as deaf-blindness, is a serious health problem. It is crucial that, 
once identified, children with these disabilities should be properly studied and the diagnosis 
of their health condition be established.  
Studies in the last decade have shown that the cochlear implant (CI) is an effective 
treatment for children who have a severe-to-profound SNHL, and do not show any benefit 
with modern hearing digitals aids (Archbold and Mayer 2012; Gilley 2010; Wilson and 
Dorman 2008).  
Most studies on the impact of CI have focused on clinical assessments of efficacy 
(hearing and speech skills, and auditory thresholds). However, these measures are only part of 
the effect of CI treatment. Given the multidimensional scope of CI, there are growing needs 
to provide others measures for assessing the impact of the cochlear implantation, such as 
Cross-Modal Plasticity.  
Plasticity in its broadest form refers to the neurons and networks ability to change their 
function as a result of intrinsically or extrinsically driven factors. When cortical regions do 
not receive adequate sensory input, these brain regions become vulnerable to recruitment 
from other sensory modalities (Shiell 2014; Hauthal 2013; Lomber 2010; Finney 2001). Brain 
plasticity is an often overlooked yet important factor that may inﬂuence clinical outcomes in 
hearing impaired individuals who receive intervention via hearing aids or CI. Moreover, brain 

Cross-Modal Plasticity in Deaf Children with Visual-Impairment 
 
741
plasticity provides the framework upon which (re)habilitation and therapy initiatives for these 
clinical populations could be based.  
Functional Magnetic Resonance Imaging (fMRI) is the most used tool in published 
research on neuroplasticity in subjects with single sensory deprivation, visual or auditory 
(Merabet and Pascual-Leone 2010; Bavellier and Neville 2002; Sadato 2002; Finney 2001). 
Recent evidence suggests that deafness is associated with cortical plasticity in temporal brain 
regions that is correlated with CI outcome (Lee 2010, 2001). Unfortunately, research efforts 
in this field have been hindered by the incompatibility of most conventional neuroimaging 
techniques with a CI, due to electromagnetic artefacts associated with the implanted device 
(MRIsafety 2012). However, the electrophysiological techniques such as Evoked Potentials 
are particularly useful for the study of neuroplasticity (Charroó-Ruíz 2013, 2012; Eggermont 
2003; Neville 1987, 1983).  
The study of the topographic distribution maps of Somatosensory Evoked Potential by 
stimulation of median nerve (SEP N20) could reflect possible neuroplastic changes that occur 
at the cortical level as a result of the auditory (re)habilitation post-CI. In this case, it is 
expected that changes that take place in the pattern of activation of brain regions be reflected 
in the SEP N20 topographic maps. To study the dynamics of such reversed cross-modal 
plasticity, we designed a longitudinal study involving the follow-up CI receivers one and five 
years post auditory (re)habilitation. 
Objective: To assess Cross-Modal Plasticity, specifically cortical reorganization in deaf 
children with visual-impairment after Cochlear Implant use, through the analysis of changes 
of Somatosensory Evoked Potential topographic cortical response distribution by stimulation 
of the median nerve. 
 
 
METHODS 
 
This was a case-control prospective study with a group of nine deaf children with visual-
impairment that had received a single CI, with complete insertion of the electrodes. None of 
these children had surgical complications. Table 1 shows additional participant data. 
 
Table 1. Demographic information about deaf children with visual-impairment and CI 
 
Age at surgery (years) 
9 Mean (Min 3 and Max 15), 4,46 DS 
Age at evaluation –one year after CI (years) 
10 Mean (Min 4 and Max 16), 4,48 DS 
Age at evaluation –five years after CI (years) 
14 Mean (Min 8 and Max 20), 4.46 DS 
Sex 
Four male 
Five female 
Unilateral CI 
Right = 5 
Left = 4 
Bilateral SNHL 
Pre-lingual= 7  
Peri-lingual= 2 
 
The deaf children with visual-impairment had been receiving auditory (re)habilitation. 
The results of the auditory (re)habilitation were assessed using tests that were developed and 
validated internationally for such purposes by others authors (Comité Español de 

L. E. Charroó-Ruíz, A. Álvarez Amador, A. S. Paz Cordovés et al. 
 
742
Audiofonología 2005; Huarte 1996). According to the auditory skills and language 
development, each child was assigned to the phases of auditory (re)habilitation: (1) detection, 
(2) discrimination, (3) identification, (4) recognition, and (5) comprehension (Amat and Pujol 
2006). 
A control group of 23 healthy children, with normal hearing and vision, was selected, to 
create reference patterns for the evaluation of the topographic distribution maps of the SEP 
N20 (see Charroó-Ruiz 2012, for details about this sample). 
Cross-Modal Plasticity assessment was performed by testing SEP N20 at different 
periods: prior cochlear implantation and after CI use (one and five years after). Recordings 
post-CI SEP N20 and topographic distribution maps of the cortical response were obtained 
with the same protocol and procedure used in pre-CI study of deaf children with visual-
impairment, and the healthy children of the control group (see Charroó-Ruiz 2012, for details 
about stimuli and methodology used).  
Grand-average SEP N20 topographic maps of deaf children with visual-impairment were 
obtained at 3 different moments (pre-CI, one and five years after implantation). Comparisons 
between one and five years after implantation studies with the pre-CI study (baseline) were 
carried out using the permutation test. 
In this chapter, we used the Low-Resolution Brain Electromagnetic Tomography 
(LORETA, Pascual-Marqui 2002) to localize electric neuronal distribution of the SEP N20 in 
the cortex in deaf children with visual-impairment before and after CI and healthy children of 
the control group.  
The individual maps of each deaf child with visual-impairement were compared, through 
visual inspection, with the average maps of the SEP N20 obtained from the control group as 
reference. (Charroó-Ruiz 2012) Also comparisons between the pre-CI versus post-CI results 
were done for each child. The progress in the auditory (re)habilitation was considered in this 
analysis. 
Ethical issues: The institutional review board approved the study and the free informed 
consent. All parents signed the free informed consent form after agreeing their children to 
participate in the study, in accordance with local ethics committees and with the Declaration 
of Helsinki. 
 
 
RESULTS  
 
Figure 1 shows average maps of the topographic distribution of SEP N20 at 3 different 
moments (pre-CI, one and five years after implantation, up panel). It is observed extensive 
cross-modal reorganization of the areas corresponding to auditory and visual cortices by 
somatosensory stimulation in pre-CI study (baseline, firs map in the up panel). The 
comparison between studies carried out one year after implantation versus baseline (middle 
panel) did not show any statistically signiﬁcant difference when the permutation test was 
used. However, after five years of stimulation via CI an important statistically significant 
reduction in the topography of SEP N20 was observed, in the left temporal regions 
(derivation T5, low panel). 
 
 

Cross-Modal Plasticity in Deaf Children with Visual-Impairment 
 
743
 
Figure 1. Grand-average SEP N20 topographic maps of deaf children with visual-impairment Pre-CI 
and Post-CI (up panel). Results the Permutation Test (low panel). 
 
 
Figure 2. The anatomical distribution of the electric sources of cortical response SEP N20 Pre-CI 
localized by LORETA in deaf children with visual-impairment (on the left) and a healthy children (on 
the right). Maximum projection of the solution (up panel). The scale in the right corner ranging from 
red to yellow shown activation level (yellow is highest level activation). All views (low panel). Axial 
sections from Z=-8 to 68.  

L. E. Charroó-Ruíz, A. Álvarez Amador, A. S. Paz Cordovés et al. 
 
744
One analysis to localize the electric neuronal sources of SEP N20 by LORETA in deaf 
children with visual-impairment, and in healthy children, with normal hearing and vision, 
showed activation in different cortical regions: somatosensory, auditory and visual in children 
with dual sensory deprivation before CI, suggesting cross-modal recruitment of auditory and 
visual regions by somatosensory processing, while the somatosensory stimulation results 
were only significant in somatosensory cortex in healthy children. Figure 2 shows typical 
regions of SEP N20 obtained from electrical stimulation of the median nerve in children of 
both groups, and the name of the activated cortical regions are described in Table 2. 
Figure 3 depicts individual maps of the response to somatosensory stimulation of deaf 
children with visual-impairment before CI (up panel) and five years after implantation (low 
panel). SEP N20 individual topographic maps show regular activation in somatosensory 
cortex (post-central gyrus) 5 years after CI (low panel) in each child. It is shown a reduction 
of the over-activation (SEP N20) found in children with 7 years or more of the deafness 
duration before implantation. Only one child after CI (low panel, and child 5) showed cortical 
activation in the primary somatosensory cortex (post-central gyrus, parietal cortex) as well as 
auditory and visual cortices (an over-representation of the SEP N20 more intense in 
comparison with baseline). 
 
Table 2. Brain areas that showed activation with somatosensory stimulation (SEP N20) 
in deaf children with visual-impairment and healthy children accoring to voxel-by-voxel 
with Low-Resolution Brain Electromagnetic Tomography (LORETA) 
 
 
 
 
 

Cross-Modal Plasticity in Deaf Children with Visual-Impairment 
 
745
 
The Montreal Neurological Institute (MNI) coordinates are given in millimeters, and the origin is at the 
anterior commissure. For x, negative values represent left, and positive values represent right. For 
y, negative values represent posteior, and positive values represent anterior. For z, negative values 
represent inferior, and positive values represent superior. 
 
 
Figure 3. SEP N20 individual topographic maps of the deaf children with visual-impairment before CI, 
and five years after CI. 
In the present study, CI treatment showed a positive effect on the lives of implanted 
children and their families, because communication skills and quality of life were much better 
after years of the auditory (re)habilitation. All these children with CI became able to attend 
school. Only one child remained with significantly limited communication skills, using only 
tactile language. Although this child were 5 years in auditory (re)habilitation, it was observed 
a poor progress in the transited phases of (re)habilitation (see Figure 3, low panel, and child 
5). Meanwhile, the other eight implanted children reached the upper phases of the auditory 
(re)habilitation. Even two of them reached the comprehension phase, the last phase of the 
auditory (re)habilitation indicating a good use of the CI (see Figure 3, low panel, child 2 and 
child 9). 

L. E. Charroó-Ruíz, A. Álvarez Amador, A. S. Paz Cordovés et al. 
 
746
DISCUSSION 
 
Our study provides new evidence of Cross-Modal Plasticity through the changes in the 
topographic distribution of SEP N20, in deaf children with visual-impairment after cochlear 
implantation. SEP N20 topographic changes were interpreted as expression of the relevance 
of the somesthetic information in children with dual sensory deprivation (auditory and 
visual). The most interesting findings were related to the duration of the deprivation, 
presented in children with 7 or more years of sensory deprivation before the CI. While 
somatosensory stimuli activates gyrus post-central in normal subjects, (Charroó-Ruíz 2012; 
Kakigi 1991) the activity level elicited in this region in deaf children with visual-impairement 
is abnormal in studies pre-CI with overall representation in auditory and visual cortices. 
However, these abnormal activity levels decrease with post-implantation time and tend 
towards the levels observed in normal subjects, provided there is no worsening of visual-
impairement or other health problems, such as cognitive limitations andcerebral palsy.  
Cross-Modal Plasticity has been observed in somatosensory modality in deaf subjects 
(Auer 2007; Caetano 2006; Leväne 2001, 1998), while, there are very few studies about the 
neuroplasticity in deaf-blindness (Obretenova 2010; Osaki 2006, 2004). Previous works have 
in common that they have studied a single adult subject with deaf-blindness, and reported 
cortical activation pattern to tactile stimulation, which agree with our findings.  
Our study revealed that neuroplasticity after cochlear implantation involves not only 
auditory processing networks. Our results suggest that with deaf-blindness, the functional 
links between cortical regions specialized in auditory and visual processing are reallocated by 
somatosensory input to support tactile language processing as result of the cross-modal 
reorganization before CI, and this changed after auditory input from the CI. 
Prospective longitudinal studies provide important information concerning the timeline of 
cross-modal reorganization according to duration of hearing loss, including a measure of the 
degree of re-organization. In addition, such studies may indicate the effect of clinical 
interventions, such as cochlear implantation, in reversing cross-modal reorganization, as 
shown in the present study. We sought to examine whether after CI new cross-modal 
recruitment is limited to the early stages after implantation (first year of the auditory 
(re)habilitation post-CI) or whether Cross-Modal Plasticity accompanies the long process of 
(re)habilitation with CI (5 years). These results post-CI showed that the most important and 
significant changes occur at long-term. 
Why do not think that the less intense use of the hands to communicate after the auditory 
(re)habilitation post-CI may reflect changes in the topography of the SEP N20? We could 
speculate that the arrival of the auditory sensory input through the CI on temporal cortex in 
these children competes with the other modalities of sensory input that were established in 
these areas before the CI. The auditory sensory input “competes” with the somesthetic 
information that activated the temporal region in the left hemisphere previously to the 
implantation. This is precisely the cortical brain area where the neural basis of hearing and 
language are established. However, the input and processing of sensory information at the 
cortical level is the result of complex processes taking place, where different areas are 
involved in the information processing that arrive to the brain cortex.  
Nowadays, there have been reported neuroplastic changes involving the activation of the 
temporal region in deaf children who received CI (Gilley 2008). Although less studied in 

Cross-Modal Plasticity in Deaf Children with Visual-Impairment 
 
747
deaf-blindness it has been also reported that the auditory stimulus presentation has been able 
to activate the temporal region, in this case using Positron Emission Tomography (Osaki 
2006). 
A central issue in the field of pediatric CI is the optimal age for implant and predicting 
cochlear implant outcome from brain organization in the deaf (Giraud 2007; Geers 2006; 
Nicholas and Geers 2006; Sharma 2002). The findings support the assertion that early 
cochlear implantation yields the best cochlear implant performance, which is likely associated 
with higher degree of synaptic plasticity within the auditory system. Positive changes in 
speech comprehension and production with time and training after implantation should be 
unsurprising, given the large literature on plasticity within the auditory system in relation to 
language learning and after hearing loss (Eggermont 2008). A common theme among these 
studies is that the auditory cortex can be rapidly, profoundly, and persistently reorganized by 
changes in sensory inputs and practice with speech production and comprehension. The 
perisylvian cortex of the temporal lobe contains Broca´s and Wernicke´s areas, and has been 
found to have an extended maturational period, continuing through at least 14 years of age in 
relation to speech perception and 30 years of age for gray matter thickness (Ross 2011; 
Sowell 2004). Although there is undoubtedly a critical period during early childhood 
development for language learning, recently Schlegel et al. (2012) have used diffusion tensor 
imaging to examine changes to white matter in adults learning a second language. Over a 9 
month period of an intensive course in modern Chinese, imaging in students indicated that 
myelination increased in cortical language centers, and the degree of changes for each subject 
correlated with their proficiency with the new language. Importantly, the cortex seems to 
remain functional and plastic after sensory deprivation and despite the reductions in potential 
Cross-Modal Plasticity, cochlear implant use seems able to recover some degree of 
functionality in central auditory regions (Ross 2011). Ours findings reveal that individuals 
implanted at a late age also benefit from implantation indicative of persistent capacity for 
neuroplasticity within the auditory cortex with a positive effect on the lives of implanted 
children and their families. 
In deaf children the use of a CI allows a recovery of the auditory function, which will 
probably counteract the cortical cross-modal reorganization induced by hearing loss. 
Although the data above presented are a case study, they may add to the growing body of 
evidence that cross-modal reorganization does occur in some CI recipients, and that cross-
modal recruitment may be related with outcomes.  
The new cross-modal reorganization was observed consistently in each child (with 7 or 
more years of sensory deprivation before the CI) across all of the cortical regions examined 
post-CI. The restoration of audition by CI has improved the communication skills (listening, 
and spoken language, or a combination of tactile language and auditory oral) in deaf children 
with visual-impairment, albeit with varied results. Only a child with cerebral palsy and 
cognitive retardation (see Figure 3, low panel, and child 5) showed very poor auditory and 
phonological abilities (tactile language).  
Several causes may be influencing the change of the topographic distribution of the SEP 
N20 post-CI in only one deaf-blind child showing an extensive topographic distribution of 
SEP N20compared with the pre-CI study. This finding could be considered as the result, 
among other causes, of the progression of visual-impairment in this child. We have reported 
that, changes in the topographic distribution of the SEP N20 by right median nerve 
stimulation pre-CI in deaf children with visual-impairment seem to be related to the early-

L. E. Charroó-Ruíz, A. Álvarez Amador, A. S. Paz Cordovés et al. 
 
748
onset of dual sensory deprivation (deaf-blindness) and severity of the visual- impairment 
(Charroó-Ruíz 2012). This child suffers of Retinitis Pigmentosa. The visual test-retest by one 
of our co-authors showed a progression of visual loss after 5 years of the implantation. 
Moreover, in the results of the auditory (re)habilitation of this child it is important to note that 
due to illness and irregularities with the (re)habilitation in her health area, this patient could 
not receive continuous and intensive auditory therapy, such as the other studied children; 
therefore, she did not perform the auditory (re)habilitation schedule proposal according to the 
Cuban Cochlear Implant Program. These reasons could explain the poor and slow progress 
observed 
in 
this 
child, 
who 
only 
reached 
the 
(re)habilitation 
phases 
of 
detecction/discrimination, and continues using the tactile language as a primary mode of 
communication at home and at school. Some authors describe that deaf children with SNHL 
who receive a CI require at least 4 years of intensive auditory (re)habilitation to achieve 
maximum benefit with CI (Archbold and O´Donoghue 2009; Bond 2009). In addition, this 
child that showed over-representation of the SEP N20 post-CI has an additional disability 
(cerebral palsy and cognitive retardation) which should be considered as another factorthat 
may influence on the poor outcome. 
Cognitive limitations and retarded development are found in a significant number of 
cochlear implantation users (Lesinski 1995). Children with cognitive retardation required 
more time and experience with their CI to achieve sentence comprehension and expressive 
language. Overall, they showed less favorable speech development than children without 
cognitive limitations. Lee et al. (2010) showed that speech perception and production were 
negatively correlated with the degree of mental retardation. On the other hand, to date, 
relatively little information is available on children with cerebral palsy, but in general, there is 
considerable variability in performance outcomes, that correlated negatively with the severity 
of additional handicaps present. 
Clinical reports indicate that additional handicaps are found in more than 40% of hearing-
impairment children (Nikolopoulos 2006). The most frequent handicaps are retardation in 
motor and mental development, and visual- impairment among others. Each individual case 
must be examined to address the potential prognosis and, even more importantly, the specific 
needs and capacity of the child to undergo and derive benefit from the (re)habilitation 
process.  
Children with dual sensory deprivation comprise a very heterogeneous group in terms of 
the outcomes displayed post-CI. It must be at least assumed that this disease pattern may have 
an unfavorable influence on the development of speech and hearing skills. Basically, in 
treating patients with multiple handicaps, it is important to consider not only the individual 
constellation of the separate symptoms and comorbidities, but also to define expectations 
from cochlear implantation. Overall, it appears difficult to generally make valid predictions; 
nonetheless, the study by Nikolopoulos et al. (2008) showed that long-term results for 
patients with additional handicaps depend essentially on the number of additional handicaps. 
Our results are in agreement with these criteria. For children considered to be complex cases, 
the aim of CI treatment is not necessarily the oral communication capabilities. The aim may 
be recognition of the parents´ voices or enable awareness, contact, and a sense of security 
with their environment, which concurrently has a positive influence on the functional 
capabilities in areas of social or emotional behavior. It is, however, enormously important that 
the (re)habilitation process after CI appropriately addresses the needs of these complex 
children. 

Cross-Modal Plasticity in Deaf Children with Visual-Impairment 
 
749
There are few published studies in children with dual sensory deprivation (Filipo 2004; 
El-Kashlam 2001; Saeed 1998). In general, publications are limited to the description of the 
auditory progression after the CI, and we did not find othersstudies about electrophysiology 
assessment and neuroplasticity results in these children. It is argued that children with dual 
sensory deprivation, generally, have poor progress in the production of words or sentences 
(Dammeyer 2009). However, the improvement that these children can have from the point of 
view of family interaction, with their environment, in their level of attention and emotional 
state justifies any effort to works in the benefit of these children through CI programs. 
Overall, the electrophysiological and behavioral results that we describe are strongly 
indicative of cross-modal reorganization in deaf children with visual-impairment after CI, and 
at the same time, it is evident the positive benefit of auditory (re)habilitation for these 
children. These are new findings that add to the previous reports about Cross-Modal Plasticity 
that have been obtained in our laboratory in children with deaf-blindness or deafness 
(Charrooó-Ruíz 2014, 2013, 2012). 
It should be noted that deaf-blindness is a condition in which each subject behaves with 
marked individuality, especially, when dual sensory deprivation begins at birth, where the 
two main sensory systems to acquire information from the environment and achieve a normal 
development are affected. In children with dual sensory deprivation occurs a very peculiar 
adaptive brain re-organization, therefore the Central Nervous System matures in a different 
way. It is difficult to form homogeneous groups of children with deaf-blindness to increase 
samples. In addition, nowadays there are few subjects with dual sensory deprivation that 
could be candidates for CI, and definitive candidacy criteria in patients with multiple 
disabilities and cognitive impairment do not exist (Cosetti and Waltzman 2011). In any case, 
deaf-blindness is an interesting model for future research to help get into the particularities 
that occur in auditory cortical processing after of the cochlear implantation and learning of the 
oral language. 
Lastly, importantly and perhaps surprisingly, our study offers evidence of Cross-Modal 
Plasticity in children with long-term sensory deprivation before CI. Understanding Cross-
Modal Plasticity in the context of dual sensory deprivation, and the potential for reversion of 
these changes following intervention, may be vital in directing intervention and 
(re)habilitation options for clinical populations with hearing loss, especially in complex cases 
with other handicaps. As the criteria for cochlear implantation in children are expanding, 
clinical evidence of Cross-Modal Plasticity may play a critical role in determining whether 
implantation may be beneficial in non typical cases of pediatric deafness. However, to date 
most research shows the efficacy of cochlear implantation assessing speech perception 
abilities and quality of life. 
In summary: This study makes available electrophysiological evidence about Cross-
Modal Plasticity in deaf children with long-term visual-impairment before CI. The study 
included results about topographic distribution of SEP N20 where the visual and auditory 
areas are widely activated with somestesic stimuli in deaf children with visual-impairment 
with 7 or more years of sensory deprivation before implantation. Changes in the topography 
of cortical response of SEP N20 can be observed in these children who receive CI, suggesting 
new reorganization of the auditory cortex when stimulated through CI. These changes are 
related to the general development potential, possible concurrent conditions, and progression 
of the severity of the visual-impairment. Evidences of Cross-Modal Plasticity may be an 
expression of how important is the somesthetic information in these subjects, probably due to 

L. E. Charroó-Ruíz, A. Álvarez Amador, A. S. Paz Cordovés et al. 
 
750
the relationship with tactile language, as well as the functional interaction of auditory and 
somesthetic information during the auditory (re)habilitation post-CI. Nontraditional measures 
such as the topographic distribution of SEP N20 could be useful in assessing the neuroplastic 
changes in deaf children with visual-impairment. 
 
 
REFERENCES 
 
Amat, M.T. and Pujol, M.C. (2006) Implante Coclear. Cuaderno de ejercicios de 
rehabilitación. Ed. AICE, Barcelona, pp249.  
Auer, E.T., Bernstein, L.E., Sungkarat, W. and Singh, M. (2007) Vibrotactile activation of the 
auditory cortices in deaf versus hearing adults. Neuroreport, 18:645–648. 
Archbold, S. and O´Donoghue, G.M. (2009) Cochlear implants in children current status. J 
Paediatric Child Health, 19:457-63. 
Archbold, S. and Mayer, C. (2012) Deaf Education: the impact of cochlear implantation. 
Deafness Educ Int, 14:2–15. 
Bavelier, D. and Neville, H. (2002) Cross-Modal Plasticity Where and How? Nature, 3:443-
452. 
Bond, M., Mealing, S., Anderson, R., Elston, J., Weiner, G., Taylor, R.S., Hoyle, M., Liu, Z., 
Price, A. and Stein, K. (2009) The effectiveness and cost-effectiveness of cochlear 
implants for severe to profound deafness in children and adults: a systematic review and 
economic model. Health Technol Assess, 13:1-30. 
Caetano, G. and Jousmaki, V. (2006) Evidence of vibrotactile input to human auditory cortex. 
Neuroimage, 29:15-28.  
Charroó-Ruíz, L., Pérez-Abalo, M.C., Hernández, M.C., Álvarez, B., Bermejo, B., Bermejo, 
S., Galán, L. and Díaz-Comas, L. (2012) Cross-Modal Plasticity in Cuban Visually-
Impaired Child Cochlear Implant Candidates: Topography of Somatosensory Evoked 
Potentials. MEDICC Review, 14:23-29. 
Charroó-Ruíz, L., Picó-Bergantiños, T., Pérez-Abalo, M.C., Hernández, M.C., Bermejo, S., 
Bermejo, B., Álvarez, B., Paz, A., Rodríguez, U., Sevila, M., Martínez, Y. and Galán, L. 
(2013) Cross-Modal Plasticity in Deaf Child Cochlear Implant Candidates Assessed 
Using Visual and Somatosensory Evoked Potentials. MEDICC Review, 15:16-22.  
Charroó-Ruíz, L., Rivero-Martínez, F., Gutiérrez, N., Torres-Fortuny, A., Picó, Th., 
Hernández, M., Bermejo, S., Bermejo, B., Alvarez, B., Paz, A., Sevila, M., Martinez, Y., 
Vega, M., Galán-García, L. and Alvarez-Amador, A. (2014) Cross-Modal Plasticity in 
Deaf-Blind Children Candidates to Cochlear Implants: Effect of Onset Deprivation and 
Handedness. Cochlear Implants. Technological advances, Psychological/Social Impacts 
and Long-Term effectiveness. Editor Samuel H Kirwin. Cap. XII Published by Nova 
Publishers Inc, New York. 
Comité Español de Audiofonología. (2005) Guía para la valoración integral del niño con 
discapacidad auditiva. Comisión de Expertos del Comité Español de Audiofonología - 
Real Patronato sobre Discapacidad. CEAF. España. 
Cosetti, M.K. and Waltzman, S.B. (2011) Cochlear implants: current status and future 
potential. Expert Rev Med Devices, 8:389–401.  

Cross-Modal Plasticity in Deaf Children with Visual-Impairment 
 
751
Dammeyer, J. (2009) Congenitally deaf-blind children and Cochlear Implants: Effects on 
communication. J Deaf Studies and Deaf Education, 14:278-288. 
El-Kashlan, H.K., Boerst, A. and Telian, S.A. (2001) Multichannel cochlear implantation in 
visually impaired patients. Otology and Neurotology, 22:53-56. 
Eggermont, J.J. and Ponton, C.W. (2003) Auditory-evoked potential studies of cortical 
maturation in normal hearing and implanted children: Correlations with changes in 
structure and speech perception. Acta Otolaryngol, 123:249–252. 
Eggermont, I.J. (2008) The role of soud in adult and developmental auditory cortical 
plasticity. Ear Hear, 29:819-829. 
Filipo, R., Bosco, E., Mancini, P. and Ballantyne, D. (2004) Cochlear implants in special 
cases: Deafness in the presence of disabilities and/or associated problems. Acta 
Otolaryngol, 552:74-80. 
Finney, E., Fine, I. and Dobkins, K. (2001) Visual stimuli activate auditory cortex in the deaf. 
Nature Neurosci, 12:1-2.  
Geers, A.E. (2006) Factors influencing spoken language outcomes in children following early 
cochlear implantation. Adv Oto-Rhino-Laryng, 64:50-65. 
Gilley, P.M., Sharma, A. and Dorman, M.F. (2008) Cortical reorganization in children with 
cochlear implants. Brain Research, 1239:56-65. 
Gilley, P.M., Sharma, A., Mitchell, T.V. and Dorman, M.F. (2010) The influence of a 
sensitive period for auditory-visual integration in children with cochlear implants. 
Restorative Neurology and Neuroscience, 28:207-218. 
Giraud, A.L. and Lee, H.J. (2007) Predicting cochlear implant outcome from brain 
organisation in the deaf. Restor. Neurol. Neurosci, 25:381–390. 
Hauthal, N., Sandmann, P., Debener, S. and Thorne, J.D. (2013) Visual movement perception 
in deaf and hearing individuals. Adv. Cogn. Psychol, 9:53–61.  
Huarte, A. (1996) Protocolo para la evaluación de la audición y el lenguaje en la lengua 
española en un programa de implantes cocleares. Acta Otorrinolaring Esp, 47 (Supl 1).  
Kakigi, R. and Shibasaki, H. (1991) Effects of age, gender, and stimulus side on the scalp 
topography of somatosensory evoked potentials following median nerve stimulation. J 
Clin Neurophysiol, 8:320–30. 
Lee, D.S., Lee, J.S., Oh, S.H., Kim, S.K., Kim, J.W., Chung, J.K., Lee, M.C. and Kim, C.S. 
(2001) Cross-modal plasticity and cochlear implants. Nature, 409:149–150. 
Lee, Y.M., Kim, L.S., Jeong, S.W., Kim, J.S. and Chung, S.H. (2010) Performance of 
children withmental retardation after cochlear im`plantation: speech perception, speech 
intelligibility, and language development. Acta Otolaryngol, 130:924-934. 
Lesinski, A., Hartrampf, R., Dahm, M.C., Bertram, B. and Lenarz. T. (1995) Cochlear 
implantation in a population of multihandicapped children. Ann Otol Rhinol Larryngol 
Suppl, 166:332-334. 
Levänen, S., Jousmäki, V. and Harui, R. (1998) Vibration-induced auditory-cortex activation 
in a congenitally deaf adult. Curr Biol, 8:869–872. 
Levänen, S. and Hamdorf, D. (2001) Feeling vibrations: enhanced tactile sensitivity in 
congenitally deaf humans. Neurosci Lett, 301:75–77. 
Lomber, S.G., Meredith, M.A. and Kral, A. (2010) Cross-modal plasticity in speciﬁc auditory 
cortices underlies visual compensation in the deaf. Nat Neurosci, 13:1421–1427.  
 

L. E. Charroó-Ruíz, A. Álvarez Amador, A. S. Paz Cordovés et al. 
 
752
Neville, H.J., Schmidt, A. and Kutas, M. (1983) Altered visualevoked potentials in 
congenitally deaf adults. Brain Res, 266:127–32. 
Neville, H.J. and Lawson, D. (1987) Attention to central and peripheral visual space in a 
movement detection task: an event-related potential and behavioural study. II. 
Congenitally deaf adults. Brain Res, 405:268–83. 
Nicholas, J.G. and Geers, A.E. (2006) Effects of early auditory experience on the spoken 
language of deaf children at 3 years of age. Ear and Hearing, 27:286-298. 
Nikolopouslos, T.P., Archbold, S.M., Wever, C.C. and Lloyd, H. (2008) Speech production in 
deaf implanted children with additional disabilities and comparision with age-equivalent 
implanted children whitout such disorders. Int J Pediatr Otorhinolaryngol, 72:1823-
1828. 
Nikolopoulos, T.P., Lioumi, D., Stamaki, S. and O´Donoghue, G.M. (2006) Evidence based 
overview of ophthalmic disorders in deaf children: a literature update. Otol Neurotol, 
27(2 Suppl 1):S1–24. 
Merabet, L.B. and Pascual-Leone, A. (2010) Neural reorganization following sensory loss: 
the opportunity of change. Nature Reviews Neuroscience, 11:44-52. 
MRIsafety.com [Internet]. California (US): Shellock R&D Services, Inc; c2012. Cochlear 
Implants; [cited 2002 Apr 27]. Available from: http://mrisafety.com/safety_ 
article.asp?subject=22. 
Obretenova, S., Halko, M.A., Plow, E.B., Pascual-Leone, A. and Merabet, L.B. (2010) 
Neuroplasticity associated with tactile language communication in a deaf-blind subject. 
Frontiers in Human Neuroscience, 3:1-14. 
Osaki, Y., Doi, K., Takasawa, M., Noda, K., Nishimura, H., Ihara, A., Iwaki, T., Imaizumi, 
M., Yoshikawa, T., Oku, N., Hatazawa, J. and Kubo, T. (2004) Cortical processing of 
tactile language in a postlingually deaf-blind subject. Neuroreport, 15:287–291. 
Osaki, Y., Takasawa, M., Doi, K., Nishimura, H., Iwaki, T., Imaizumi, M., Oku, N., 
Hatazawa, J. and Kubo, T. (2006) Auditory and tactile processing in a postmeningitic 
deaf–blind patient with a cochlear implant. Neurology, 67:887–890. 
Pascual-Marqui, R.D. (2002) Standardized low-resolution brain electromagnetic tomography 
(sLORETA): Technical details. Methods Find Exp. Clin. Pharmacol, 24:5–12. 
Ross, L.A., Molholm, S., Blanco, D., Gomez-Ramirez, M., Saint-Amour, D. and Foxe, I.J. 
(2011) Development of multisenspry speech percepction continues into the late childhood 
years. Eur J Neurosci, 33:2329-2337. 
Sadato, N., Okada, T., Honda, M. and Yonekura, Y. (2002) Critical period for cross-modal 
plasticity in blind humans: a functional MRI study. Neuroimage, 16:389–400. 
Saeed, S.R., Ramsden, R.T. and Axon, P.R. (1998) Cochlear implantation in the deaf-blind. 
The American J of Otol, 19:774-777. 
Sharma, A., Dorman, M.F. and Spahr, A.J. (2002) A sensitive period for the development of 
the central auditory system in children with cochlear implants: implications for age of 
implantation. Ear Hear, 23:532-539. 
Shiell, M.M., Champoux, F. and Zatorre, R.J. (2014) Enhancement of visual motion detection 
thresholds in early deaf people. PLoS ONE, 9:e90498.  
Shlegel, A.A., Rudelson, J.I. and Tse P.U. (2012) White matter structure changes as adults 
learn a second language. J Cogn Neurosci, 24:1664-1670. 

Cross-Modal Plasticity in Deaf Children with Visual-Impairment 
 
753
Sowell, E.R., Thompson, P.M., Leonard, C.M., Welcome, S.E., Kan, E. and Toga, A.W. 
(2004) Longitudinal mapping of cortical thickness and brain growth in normal children. J 
Neurosci, 8223-8231. 
Wilson, B.S. and Dorman, M.F. (2008) Cochlear implants: a remarkable past and a brilliant 
future. Hear Res, 242:3-21.  
 
 


 
 
 
 
 
 
 
 
 
 
 
 
VOLUME 4 
 
 


In: Encyclopedia of Audiology and Hearing Research 
ISBN: 978-1-53617-702-2 
Editors: Erno Larivaara and Senja Korhola 
© 2020 Nova Science Publishers, Inc. 
 
 
 
 
 
 
 
Chapter 53 
 
 
 
ANATOMY AND PHYSIOLOGY OF THE PERIPHERAL 
AND CENTRAL AUDITORY SYSTEM 
 
 
Fabio Bucchieri, Fabio Carletti, Sabrina David,  
Francesco Cappello, Giuseppe Ferraro and Pierangelo Sardo 
Department of Experimental Biomedicine and Clinical Neuroscience,  
University of Palermo, Palermo, Italy 
 
 
ABSTRACT 
 
The auditory system is responsible for the hearing sense and it consists of the 
peripheral auditory system (outer, middle and inner ear) and of the central auditory 
system (vestibular and cochlear nuclei, auditory and vestibular pathways and vestibular 
and auditory cortices). The outer ear comprises the auricle and the auditory canal and its 
function is to guide air pressure waves to the middle ear. The middle ear consists of the 
tympanic membrane, connected to the inner ear by three ossicles (malleus, incus and 
stapes), which vibrations allow the transmission of originally airborne sound waves to the 
perilymph of the inner ear. The middle ear provides a pressure gain as well as enhanced 
quality of the sound waves transmitted to the inner ear and protects it from high pressure 
levels produced by loud sounds. The stapes footplate of the middle ear connects to the 
oval window of the cochlea, an inner ear spiral-shaped bony canal. The stapes of the 
middle ear connects to the oval window in the cochlea. The vibrations of a flexible 
membrane (basilar membrane) on which sensory cells (hair cells) reside are responsible 
for the transduction of the sound waves into electrical impulses.  
The vestibulocochlear nerve (CN VIII) transmits both hearing and balance 
information from the inner ear to the brain. The vestibular (balance) and cochlear 
(hearing) components of the vestibulocochlear nerve target different nuclei. The 
vestibular component reaches the vestibular nuclei in the pons and medulla oblongata. 
The cochlear component instead reaches the ventral and dorsal cochlear nuclei, located 
laterally at the junction between the pons and medulla, in close proximity to the inferior 
cerebellar peduncle. CN VIII emerges from the brainstem at the cerebellopontine angle 
and exits the posterior cranial fossa of the neurocranium through the internal acoustic 
meatus of the temporal bone. Here the vestibulocochlear nerve splits, thus forming the 
                                                        
 Correspomding Author’s Email: sabrina.david@unipa.it. 

Fabio Bucchieri, Fabio Carletti, Sabrina David et al. 
 
756
vestibular nerve and the cochlear nerve. The vestibular nerve innervates the vestibular 
system of the inner ear, which is responsible for detecting balance. The cochlear nerve 
travels to the cochlea, forming the spiral ganglia of Corti, involved in the sense of 
hearing. 
The hearing pathway originates in the cochlear nuclei which receive first-order 
auditory input from the organ of Corti in the cochlea. The second neuron of this pathway 
is located in the superior olivary nuclei of the pons where the majority of the auditory 
fibers synapse, crossing the midline. The fibers ascend, forming the lateral lemnisc and 
proceed towards the inferior colliculus in the mesencephalus. The last relay, prior to the 
primary auditory cortex, occurs in the medial geniculate body of the thalamus. A 
tonotopic organization is evident throughout the hearing pathway, from cochlea to 
auditory cortices. 
In the balance pathway, neurons synapsing on the hair cells of maculae and cristae 
ampullares of the semicircular canals converge in the vestibular ganglion. The sensory 
fibers originating from here join the sensory fibers from the cochlear ganglion to form the 
vestibulocochlear nerve and terminate in the vestibular nuclei of the pons and medulla. 
The axons originated in these nuclei reach different areas of Central Nervous System 
(CNS), such as the spinal cord, the cerebral cortex, the cerebellum and the nuclei 
controlling extrinsic eyes muscles. The vestibular nuclei also receive input from 
proprioceptive neurons, as well as the visual system. 
 
 
INTRODUCTION 
 
1. Anatomical Bases of Hearing: An Overview 
 
In this paragraph, we describe briefly the main anatomical structures involved in hearing, 
i.e., the ear, the vestibulocochlear nerve, the cochlear nuclei and the auditory cortex. 
 
 
1.1. The Ear 
 
From an anatomical point of view, the ear consists in three parts; the external, the middle 
and the internal ear. In the next paragraph, the morphology of each part will be briefly 
summarized. 
 
External Ear 
The external ear includes the auricle (pinna) and the external auditory canal (meatus). 
The auricle is composed of a thin plate of elastic cartilage, covered by a layer of skin. It is 
attached in place by ligaments, and has two groups of muscles, extrinsic and intrinsic ones. 
There is a deep depression (concha) that leads into the external auditory meatus and is 
covered by two small protrusions: the tragus, in front, and the antitragus, behind. The funnel-
like curves of the auricle collect sound waves and direct them toward the middle ear.  
The external auditory meatus is a slightly curved canal, about 2.5 cm in length, that 
extends from the floor of the concha to the tympanic membrane. The meatus contains two 
types of glands: sebaceous glands and ceruminous glands (modified sweat glands that secrete 
cerumen). 

Anatomy and Physiology of the Peripheral and Central Auditory System 
 
757
Between the external and the middle ear there is the tympanic membrane. It is a 
membranous structure located on the medial part of the auditory meatus. The tympanic 
membrane is comprised of three layers of tissue: an outer cutaneous layer, a fibrous middle 
layer, and a layer of mucous membrane on its innermost surface. The membrane is held in 
place by a thick ring of cartilage. It has the capacity to vibrate and to receive sound waves 
that are amplified to an appropriate magnitude. The membrane vibrates as the sound waves 
strike it, and transmits the vibrations towards the small bones of the middle ear. 
 
Middle Ear 
The middle ear, or tympanic cavity, is connected to the epitympanic recess, the antrum 
and the cells within the mastoid portion of the temporal bone. Medially, the auditory (or 
Eustachian) tube links the tympanic cavity with the nasopharynx. The tympanic cavity is an 
air-filled space, covered by a columnar epithelium, that contains 3 tiny bones (known as 
ossicles), called the malleus (hammer), incus and stapes (stirrup). Sound waves that reach the 
tympanic membrane cause it to vibrate. This vibration is then transmitted to the ossicles, 
which amplify the sound and pass the vibration to the oval window (a thin membrane 
between the middle and the inner ear). Hammer and stirrup movements are limited by two 
small muscles, the tensor tympani and the stapedius, respectively. 
 
The Inner Ear 
The inner ear consists of 1) the otic labyrinth (membranous labyrinth), 2) the periotic 
labyrinth (osseous labyrinth), and 3) the otic capsule (part of the petrous portion of the 
temporal bone which surrounds the internal ear). 
The otic labyrinth is a closed system of endolymph-filled ducts and sacs contained within 
the inner ear. It has the same general shape as the osseous labyrinth and consists of structures 
surrounded by perilymph. 
In particular, it includes the cochlea, which is involved in hearing, and the vestibular 
system (consisting of three semicircular canals, as well as a saccule and an utricle), which is 
responsible for maintaining balance. The cochlea is filled with fluid and contains the organ of 
Corti — a structure that contains thousands of specialized sensory hair cells with projections 
called cilia. The vibrations transmitted from the middle ear produce tiny waves which make 
the cilia vibrate. The hair cells then convert these vibrations into nerve impulses, or signals, 
which are sent to the brain via the auditory nerve. 
The semicircular canals also contain fluid and hair cells, but these hair cells are 
responsible for detecting movement rather than sound. When you move your head, the fluid 
within the semicircular canals (which are oriented vertically at right angles to each other) also 
moves. This fluid motion is detected by the hair cells, which send nerve impulses about the 
position of the head and body to the brain to allow maintaining the balance. 
The utricle and the saccule work in a similar way to the semicircular canals, providing 
information on the body position in relation to gravity, allowing postural adjustments as 
required. 
The periotic labyrinth consists in the vestibule, the periotic semicircular canals, the scala 
vestibule and the scala tympani. The vestibule is the largest portion of the periotic labyrinth. 
It surrounds the utriculus and the sacculus. The periotic semicircular canals surround the otic 
semicircular ducts. They contain a great amount of periotic trabecular tissue. The scala 
vestibule or vestibular duct is a perilymph-filled cavity inside the cochlea of the inner ear that 

Fabio Bucchieri, Fabio Carletti, Sabrina David et al. 
 
758
conducts sound vibrations to the cochlear duct. It is separated from the cochlear duct by 
Reissner's membrane and extends from the vestibule of the ear to the helicotrema, where it 
joins the tympanic duct. 
The tympanic duct or scala tympani is one of the perilymph-filled cavities separated from 
the cochlear duct by the basilar membrane, and it extends from the round window to the 
helicotrema, where it continues as the vestibular duct. 
The purpose of the perilymph-filled tympanic duct and vestibular duct is to transduce the 
movement of air that permits to the tympanic membrane and the ossicles to vibrate, into a 
movement of the liquid and of the basilar membrane. The latter stimulates the organ of Corti 
inside the cochlear duct, composed of hair cells attached to the basilar membrane and their 
stereocilia embedded in the tectorial membrane. Indeed, the organ of Corti is located in the 
scala media of the cochlea, between the vestibular duct and the tympanic duct and is 
composed of mechanosensory cells, known as hair cells. These cells lie on the basilar 
membrane of the organ of Corti and are organized in three rows of outer hair cells (OHCs) 
and one row of inner hair cells (IHCs). These hair cells are supported by Deiters’ cells, also 
called phalangeal cells. Above them is the tectoral membrane which moves in response to 
pressure variations in the fluid-filled tympanic and vestibular canals. The movement of the 
basilar membrane in relation to the tectorial membrane causes the stereocilia to bend. They 
then depolarize and send impulses to the brain via the cochlear nerve. This produces the 
sensation of sound. 
The otic capsule is the portion of the petrous part on the temporal bone which surrounds 
the internal ear, derived from the embryotic mesenchyme which surrounded the early otic 
vescicle. A part of this mesenchymal tissue passes through the precartilaginous and 
cartilaginous stages prior to ossification. Therefore, the bony otic capsule is known as 
cartilage bone. 
 
 
1.2. The Vestibulocochlear Nerve 
 
The vestibulocochlear nerve (CN VIII) transmits both hearing and balance information 
from the inner ear to the brain. It consists mostly of bipolar neurons and forms two branches: 
the cochlear nerve and the vestibular nerve. 
The vestibulocochlear nerve reaches the middle portion of the brainstem called the pons 
(which also contains fibers leading to the cerebellum). It runs between the base of the pons 
(and medulla oblongata, the lower portion of the brainstem) in the cerebellopontine angle. 
The vestibulocochlear nerve is accompanied by the labyrinthine artery, which usually 
branches off from the anterior inferior cerebellar artery (AICA) and then continues along the 
VIII nerve through the internal acoustic meatus to the internal ear. 
The cochlear nerve, responsible of hearing, travels away from the cochlea of the inner ear 
where it starts as the spiral ganglion of the organ of Corti. The inner hair cells of the organ of 
Corti are responsible for the activation of afferent receptors in response to pressure waves 
reaching the basilar membrane through sound transduction.  
The vestibular nerve originates from the vestibular system of the inner ear. The vestibular 
ganglion (Scarpa's ganglion) extends processes to five sensory organs. Three of these are the 
cristae located in the ampullae of the semicircular canals. Hair cells of the cristae activate 
afferent receptors in response to rotational acceleration. The other two sensory organs are the 

Anatomy and Physiology of the Peripheral and Central Auditory System 
 
759
maculae of the saccule and the utricle. Hair cells of the maculae in the utricle activate afferent 
receptors in response to linear acceleration, while hair cells of the maculae in the saccule 
respond to vertically directed linear force.  
CN VIII emerges from the brainstem at the cerebellopontine angle and exits the posterior 
cranial fossa of the neurocranium through the internal acoustic meatus of the temporal bone. 
Here the vestibulocochlear nerve splits, thus forming the vestibular nerve and the cochlear 
nerve. 
 
 
1.3 The Cochlear Nuclei 
 
The vestibular (balance) and cochlear (hearing) components of the vestibulocochlear 
nerve target different nuclei. The vestibular component reaches the vestibular nuclei in the 
pons and medulla oblongata. The cochlear component instead reaches the ventral and dorsal 
cochlear nuclei, located laterally at the junction between the pons and medulla, near the 
inferior cerebellar peduncle.  
The hearing pathway originates in the cochlear nuclei which receive first-order auditory 
input from the organ of Corti in the cochlea. The second neuron of this pathway is located in 
the superior olivary nuclei of the pons where the majority of the auditory fibers synapse, 
crossing the midline. The fibers ascend, forming the lateral lemnisc, and proceed towards the 
inferior colliculus in the mesencephalus. The last relay, prior to the primary auditory cortex, 
occurs in the medial geniculate body of the thalamus. 
In the balance pathway, neurons synapsing on the hair cells of the maculae and cristae 
ampullares of the semicircular canals converge in the vestibular ganglion. The sensory fibers 
originating here join the sensory fibers from the cochlear ganglion to form the 
vestibulocochlear nerve, and terminate in the vestibular nuclei of the pons and the medulla. 
The axons originated in these nuclei reach different areas of the Central Nervous System 
(CNS), spinal cord, the cerebellum, the nuclei controlling extrinsic eyes muscles, thalamus, 
and the cerebral cortex. 
 
 
1.4.The Auditory Cortex 
 
The human auditory cortex is the part of the temporal lobe that processes auditory 
information. 
It is located bilaterally, at the upper sides of the temporal lobes, on the superior temporal 
plane, within the lateral fissure and comprises parts of Heschl's gyrus and the superior 
temporal gyrus. 
The auditory cortex was previously subdivided into primary and secondary projection 
areas and further association areas. The primary auditory cortex (AI) is situated in the 
posterior third of the superior temporal gyrus (also known as Brodmann area 41), next to 
Wernicke's area. The secondary auditory cortex (AII) is located more rostrally in the temporal 
lobe and contains Brodmann area 42. The modern divisions of the auditory cortex are the core 
(which includes AI), the belt, and the parabelt. The belt is the area immediately surrounding 
the core; the parabelt is adjacent to the lateral side of the belt. These latest areas help to 
integrate hearing with other sensory systems.  

Fabio Bucchieri, Fabio Carletti, Sabrina David et al. 
 
760
Studies indicate that auditory fields of the primary auditory cortex (AI) receive ascending 
input from the auditory thalamus, and point-to-point input from the ventral division of the 
medial geniculate complex; thus, it contains a precise tonotopic map. The primary auditory 
cortex (AI) has a topographical map of the cochlea.  
Neurons in the auditory cortex are organized according to the frequency of sound to 
which they respond best. Neurons at one end of the auditory cortex respond best to low 
frequencies; neurons at the other respond best to high frequencies.  
Studies have revealed the presence of six cell layers. The pyramidal cells correspond to 
85% of AI. The remaining 15% are multipolar or stellate cells. Inverted stellate cells also 
exist (Martinotti cells), as well as cells with candelabra-shaped dendritic configurations. Most 
ascending fibers originate in synapse with the pyramidal cells of layer IV, but this is not 
always the case. However, these contacts represent only 20% of the excitatory fibers that 
project to cortical neurons: the other 80% comes from other neurons in the ipsilateral cortex.  
The primary auditory cortex is subject to modulation by numerous neurotransmitters, 
including norepinephrine, which has been shown to decrease cellular excitability in all layers 
of the temporal cortex. Alpha-1 adrenergic receptor activation, by norepinephrine, decreases 
glutamatergic excitatory postsynaptic potentials at AMPA receptors. 
 
 
2.PHYSIOLOGY OF THE AUDITORY SYSTEM 
 
The auditory system detects sounds and uses acoustic cues to both identify them and 
locate their origin in the environment. The perceptual phenomenon called sound is produced 
in the brain by stimulating the ear with periodic longitudinal waves of alternating low and 
high pressure (rarefactions and compressions, respectively). These waves propagate at 
different speed depending on the properties of the elastic medium through which they travel 
(330 - 340 m/s through air). The absolute intensity of sound, measured in pascals (Pa), is 
related to the amplitude of the longitudinal wave; however, the intensity of audible sounds is 
usually measured in decibel sound pressure level (dB SPL): this logarithmic scale relates the 
absolute sound intensity (PT) to a 20 μPa reference pressure (Pref), roughly corresponding to 
the average human threshold at 2000 Hz. Due to its logarithmic nature, in this scale intensities 
of sounds are compressed, in such a way that a tenfold increase in absolute sound intensity 
just corresponds to a 20 dB SPL increase.  
 
dB SPL = 10 × log10
(PT)2
(Pref)2 = 20 × log10
PT
Pref
 
 
Sounds with amplitudes from 0 to 120 dB SPL can be comfortably heard, whereas higher 
sound pressure levels cause pain and can damage the ear. Acoustic waves have typically an 
amplitude of about 60 dB in a normal conversation. 
The subjective experience of tonal discrimination (pitch) of a sound depends on wave 
frequency, measured in hertz (Hz, waves per second). Humans can hear sounds in the 
frequency interval from ~20 to 20,000 Hz; perception of speech encompasses frequencies 
between 60 and 12,000 Hz.  
 

Anatomy and Physiology of the Peripheral and Central Auditory System 
 
761
On the basis of both temporal pattern and regularity of acoustic waves we can distinguish 
pure tones (characterized by a single frequency), sounds (characterized by a perceived 
fundamental frequency, or pitch, and overtones) or noises, with no recognizable periodic 
elements. 
Sounds characterized by the same SPL but different frequencies are not perceived as 
equally loud; these differences in perception are accounted for by the phon scale, developed 
by adjusting the intensities of test tones to be equal in loudness to reference tones of 1000 Hz 
(normal hearing threshold is ~4 phon, whereas discomfort and pain are perceived at 110 and 
130 phon, respectively). 
 
 
2.1 Outer and Middle Ear Actions: Funneling and Conduction of Sound 
 
The auditory system is specialized to discriminate frequency, amplitude, and direction of 
acoustic waves, as well as to interpret temporal patterns of sound amplitude and frequency of 
words and music. 
In the outer ear the pinna and the tragus together funnel sound waves into the external 
auditory canal, focusing sound waves on the tympanic membrane (or eardrum). Depending on 
the angle of incidence, the same sound is reflected differently off the pinna and tragus: on this 
basis, these structures are able to emphasize some sound frequencies over others, inducing 
peaks and notches in the sound spectrum. The positions of peaks and notches depend on (and 
provide information about) location of the sound source, even when using only one ear 
(monaural sound localization); such information is important for localizing sounds in the 
vertical plane (elevation). Then, each heard sound is a combination of both a direct 
component and a reflected one (by pinna and tragus), and causes the tympanic membrane to 
vibrate. 
The middle ear, represented by the air-filled chamber between the tympanic membrane 
on one side and the oval window on the other, ensures efficient transmission of sound from 
air into the fluid-filled inner ear, by transferring vibrations of the tympanic membrane to the 
oval window through a chain of three delicate bones called ossicles: the malleus (or hammer), 
incus (anvil), and stapes (stirrup). Since water is highly incompressible and dense, it has very 
higher acoustic impedance (defined as the ratio of sound pressure to volume velocity) than air 
(about 10,000 times higher) and sound traveling directly from air to water has insufficient 
pressure to move the dense water molecules: then, transferring sound vibrations from air to 
cochlear fluid needs an impedance-matching device that saves most of sound’s energy, which 
would be otherwise largely (>97%) reflected back to air when encountering a watery medium 
exerting a stronger opposition to movement brought about by a pressure wave. Impedance 
matching, and successful transferring of most energy to inner ear fluids, is obtained through 
amplification (gain of about 25 to 30 dB in the middle frequencies), due to both a larger area 
of eardrum than the footplate of the stapes (~ 20:1 ratio) and, to a lesser extent, a lever action 
exerted by malleus and incus, increasing the pressure applied to the footplate (the combined 
action of eardrum/footplate ratio and ossicles lever causes a ~ 55 times pressure increase over 
the oval window). For lower and higher frequencies, however, more energy is lost. 
Equalization of air pressure on opposite sides of the tympanic membrane is realized through 
the eustachian tube, which connects the middle ear to the nasopharynx. 

Fabio Bucchieri, Fabio Carletti, Sabrina David et al. 
 
762
2.2 Inner Ear Function: Transduction of Sound 
 
Movements of the stapes against the oval window create traveling pressure waves within 
the cochlear fluids. Each movement of the oval window induce changes in pressure of scala 
vestibuli (inward = increase, outward = decrease) and opposite movements of round window 
and changes in scala tympani. The different pressure between scala tympani and scala 
vestibuli causes the basilar membrane (and the organ of Corti) to bow upward (when pressure 
in scala vestibuli > scala tympani) or downward. 
The contraction of muscles of the middle ear, tensor tympani (inserted onto the malleus) 
and the stapedius (inserted onto the stapes), reflexively activated by high sound levels, 
dampen the transfer of sound to the inner ear by controlling the stiffness of the ossicular 
chain, in this way exerting a protective action and a suppression of self-produced sounds (e.g., 
voice, chewing). 
Sound frequency and amplitude are encoded in the cochlea and further analyzed in the 
CNS. In fact, the cochlea performs as a spectral analyzer, evaluating complex sounds 
according to their pure tonal components, in such a way that each pure tone stimulates a 
specific region; in fact, different regions of the basilar membrane are tuned to particular 
frequencies. The frequency of the sound determines which region of basilar membrane 
vibrates most along the cochlea, high frequencies generating maximal vibrations in the basal 
region, whereas lower frequencies generate their maximal amplitudes near the cochlear apex, 
thus determining which hair cells of the organ of Corti are stimulated. In the auditory system, 
a place coding is based on this selectivity. Such low-apical to high-basal gradient of 
resonance is underlain by mechanical characteristics (stiffness and taper) of the basilar 
membrane. In fact, whereas the cochlea tapers from base to apex, the basilar membrane tapers 
in the opposite direction, being wider at the apex; moreover, the narrow basal end is stiffer 
(~100 times) than the apical end. However, the intrinsic frequency selectivity afforded by 
basilar membrane tuning is not great enough to account for the very selective responses 
observed in hair cells and auditory nerve fibers; in fact, active mechanisms are necessary to 
achieve this high frequency selectivity (see below). 
 
 
2.3 Hair Cells Functions 
 
The vibration of basilar membrane is transduced by hair cells of organ of Corti, 
mechanoreceptors specialized to detect very small movement along one particular axis, 
located at the junction between endolymph and perilymph; these polarized epithelial cells are 
characterized by an apical end specialized to transduce mechanical energy into receptor 
currents, whereas the basal end is in contact with perilymph and synaptically drives the 
activity of primary afferent neurons of the acoustic nerve (Hudspeth and Corey, 1977). In 
the apical end, the stereovilli of inner hair cells float freely in the endolymph, whereas the 
stereovilli of the outer hair cells project into the cantilevered tectorial membrane, free to tilt 
up and down since it is attached only along one edge. Inner hair cells transduce mechanical 
energy of sound into electrical energy, whereas the active movements of outer hair cells 
modulate the amplification of the signal. Due to a K+ gradient, auditory endolymph has a 
positive voltage relative to the perilymph (+80 to + 90 mV), being this endocochlear potential 

Anatomy and Physiology of the Peripheral and Central Auditory System 
 
763
the driving force for sensory transduction in both inner and outer auditory hair cells. The 
composition of endolymph increases the K+ transduction current flowing from endolymph 
into the hair cells, due to both the concentration gradient and the large electrical gradient. 
Once a sound stimulates the cochlea, K+ flows into the hair cells with little energy 
expenditure by the hair cells, as K+ is flowing down its electrochemical gradient; that is why 
hair cells do not require a high blood flow, that would bring noise and interfere with sound 
reception. 
In hair cells, receptor potentials are evoked by mechanically gated ion channels: in fact, 
specialized elastic filaments called tip links (or gating springs) are present at the tips of 
stereocilia, mechanically attaching (like a spring) the top of each stereocilium to the upper 
side of the adjacent taller one, in line with the axis of maximal bundle sensitivity (Brownell 
et al, 1985; Pickles et al, 1984). Destruction of the tip links by enzymatic (elastase) or 
chemical (calcium chelators) treatments can abolish mechanical transduction. Deflection of 
stereocilia in the excitatory direction stretches the tip links and increases their tension, in this 
way pulling on the channel gate and increasing the probability of channel opening. Deflection 
in the opposite direction release the tip link and let the channels close. Maximum compliance 
of stereocilia bundle occurs when roughly half the transduction channels are open. As a 
consequence of direct gating of transduction channels, hair cell transduction occurs much 
faster than in other sensory modalities: the delay between bundle deflection and the onset of 
receptor current is about 10 ms at 37°C, being such speed essential in order to detect sound 
frequencies in auditory range of Humans. 
When the hair bundle is in resting position a standing inward cations (mainly potassium 
and small amount of calcium) current flows through 15-20% of mechanically activated 
channels, located near the tips of the stereocilia (one or two channels per stereocilium), and 
this inward positive current tends to depolarize the hair cells. Maximal transducer 
conductance changes up to about 10 nS have been observed. The proportion of open channels, 
and consequently the inward current, are increased when the hair bundle is displaced toward 
the tallest stereocilium; the current flowing across the basolateral membrane depolarizes the 
membrane, activating some voltage-dependent conductances. On the contrary, movement of 
the stereocilia bundle away from the tallest stereocilium hyperpolarizes the basolateral 
membrane of hair cells by reducing the inward current: remarkably, displacements in 
depolarizing direction produce larger responses than equal deflections in the opposite 
direction, describing a sigmoidal displacement–response function, shifted from its midpoint; 
because of such relationship, changes in membrane potential due to acoustic stimuli inducing 
symmetrical sinusoidal deflections of the bundle will produce both sinusoidal (AC) and 
superimposed depolarizing steady-state (DC) changes, the system being saturated by 300 nm 
deflections. 
It must be noted that, whereas receptor currents are induced without attenuation across 
frequency, receptor potentials are susceptible to filter characteristics of the basolateral 
membrane depending on the time constant, ranging from sub- millisecond to a few 
milliseconds duration at the resting potential; this passive property lets the membrane act as a 
low-pass filter with a dynamic cutoff frequency ranging from tens of hertz to about 1 kHz. 
Furthermore, receptor potentials may activate voltage-dependent channels in the basolateral 
membrane, in this way modifying the resistive component of the time constant. Moreover, the 
capacitance of the basolateral membrane is also highly voltage dependent in outer hair cells: 

Fabio Bucchieri, Fabio Carletti, Sabrina David et al. 
 
764
in these cells the membrane filter could therefore be influenced by changes in both resistive 
and capacitive components. Due to the filtering of the basolateral membrane, the AC 
component of receptor potential is halved for every octave increase in frequency above the 
cutoff, becoming negligible at very high frequencies; on the contrary, the DC component of 
receptor potential is not affected (this effect is called rectification). A fundamental difference 
is observed between main responses to electrical changes in inner versus outer hair cells: 
inner cells modify the amount of neurotransmitter released at the level of synapses with 
afferent neurons, outer cells change their length and thereby amplify the movement of the 
basilar membrane.  
In the inner hair cells synapse, the release of neurotransmitter depends on membrane 
receptor potential. In resting position the depolarizing inward cation current induces a basal 
neurotransmitter release: further depolarization increases the number of released vesicles, 
whereas hyperpolarization decreases it.  
On the other side, outer hair cells express an integral membrane motor protein termed 
prestin along their lateral wall and are able to respond to electrical stimulation by altering 
their length in a voltage dependent manner: depolarization shortens the cell, whereas 
hyperpolarization induces elongations (Liberman et al, 2002; Zheng et al, 2000). When 
basilar membrane moves upward, a shear force between stereocilia of outer hair cells and the 
tectorial membrane develops, forcing hair bundles to tilt toward longer stereocilia: this 
movement opens transduction channels in outer hair cells, through which K+ flows inward, 
further depolarizing the cells (the voltage change is termed receptor potential). This process is 
called mechanical to electrical transduction, and the consequent depolarization contracts the 
motor protein prestin, a member of the SLC26 family, which outer cells express at very high 
levels: the contraction of reciprocally linked prestin molecules shorten the outer cells (the 
process is called electromotility or electrical to mechanical transduction). This voltage 
dependent mechanical response, only limited to outer hair cells, is not evoked by activation of 
voltage-dependent ionic conductance. 
On 
the 
contrary, 
downward 
movements 
of 
the 
basilar 
membrane 
induce 
hyperpolarization of outer cells and their elongation. This motor activity is restricted to the 
lateral membrane of the outer cell. Length changes up to 5% are observed: they are not 
dependent on ATP, microtubule or actin systems, extracellular Ca2+, or changes in cell 
volume. The maximum sensitivity of the response is about 30 nm/mV, observed at a 
depolarized voltage with respect to the resting potential of the cell. This motor activity is 
maintained and modulated through the intervention of a stretch-activated chloride 
conductance, and intracellular chloride is required for the activity of the voltage sensor. In 
vivo, the motor action of outer hair cells is probably responsible for otoacoustic emissions.  
Remarkably, the voltage-dependent mechanical response of outer cells could be 
influenced by the time constant of the cell, mainly because transmembrane AC receptor 
potentials will be greatly attenuated at high frequencies: this effect could theoretically limit 
the motor response, if this is only driven by receptor potential. Nonetheless, some 
mechanisms let the inner ear overcome the limiting effects of the membrane filter 
encountered for acoustic stimulation at high frequency: in fact, a role of a mechanically 
activated flux of chloride through the lateral plasma membrane is evident in the function of 
prestin in vivo (Rybalchenko et al, 2003), which could underlie a voltage independence; 
moreover, active mechanical responses of the stereocilia bundle may be driven by calcium 

Anatomy and Physiology of the Peripheral and Central Auditory System 
 
765
influx through mechanically activated calcium-sensitive channels, not limited by the 
membrane filter. The motor properties make the outer hair cells act as a cochlear amplifier: 
acting as both receptors and effectors, they are able to sense and enhance movements of the 
basilar membrane; in fact, contraction of outer hair cells enhances upward movement, 
whereas hair cell elongation accentuates the downward movement of the basilar membrane. 
Therefore, outer hair cells electromotility is necessary for sensitive hearing and sharp 
frequency discrimination. Hearing sensitivity and frequency selectivity are impaired by 
mutation of the gene for prestin or if outer cells are damaged (e.g., by some antibiotics) or 
absent.  
The mechanical events originated in outer hair cells boost basilar membrane movements 
and enhance stimulus to the inner hair cells. The amplified upward movement of the basilar 
membrane forces endolymph to flow out from beneath the tectorial membrane, toward its tip; 
this flow causes the hair bundles of the inner hair cells to bend toward longer stereovilli, 
consequently opening transduction channels and depolarizing the cell. This depolarization 
opens voltage-gated Ca2+ channels, and the consequent rise of [Ca2+]i induces synaptic 
vesicles fusion and glutamate release, depolarizing afferent neurons.  
When the stapes moves inward, all described processes reverse as well: the basilar 
membrane bows downward, transduction channels close in the outer hair cells, which undergo 
hyperpolarization and cell elongation, accentuating downward movement of the basilar 
membrane which recalls endolymph back under the tectorial membrane; in this manner 
transduction channels close in inner hair cells, causing cell hyperpolarization and reduced 
neurotransmitter release. 
 
 
3. ROLE OF NERVOUS SYSTEM 
 
3.1. Auditory Nerve 
 
The cochlea receives innervation from the auditory (or cochlear) nerve, a branch of 
cranial nerve VIII (Ruggero, 1982). Sensory cells somata (about 30,000) are found in the 
spiral ganglion and their dendrites contact nearby hair cells: 95% of neurons, termed type I 
cells, contact inner hair cells; the remainder afferent neurons, named type II, innervate the 
outer hair cells, which represent over three-quarters of the receptor cell population. The axons 
of afferent neurons project to the brainstem cochlear nucleus. A type I neuron generally 
contacts a single hair cell through a myelinated large and fast conducting fiber, thus their 
information reaches the brain within a few tenths of a millisecond; type II neurons, instead, 
sends processes to contact 5 to 100 outer hair cell by thin, unmyelinated and slow conducting 
fibers. Both afferent fiber types project centrally into the cochlear nucleus in the brain stem: 
inner hair cells and type I neurons are the main channel for sound-evoked information to 
reach the hierarchically upper structures in the brainstem, whereas outer hair cells contribute 
very little direct information about sound. 
The stimulation with a continuous pure tone originates a wave which, travelling along the 
basilar membrane, has different amplitudes at different points along the base-apex axis. Hair 
cells are tuned to a certain frequency: their frequency sensitivity (or characteristic frequency) 
depends on their position along the basilar membrane of the cochlea, due either to the above-

Fabio Bucchieri, Fabio Carletti, Sabrina David et al. 
 
766
described features of the basilar membrane, or to position-related structural differences 
between inner hair cells, enhancing the tuning. In fact, the ones near the base have shorter, 
stiffer stereovilli, which let them resonate to higher frequencies; on the contrary, the cells near 
the apex display longer and floppier stereovilli which make them resonate to lower 
frequencies; this position-based frequency selectivity of inner cells clearly describe a place 
coding of frequency. Aside, increases in sound amplitude cause an increase in the rate of 
action potentials in auditory nerve axons: then, sound intensity undergoes a rate coding at 
neuronal level, cooperation between neurons being required in order to code the full SPL 
range (0 to 120 dB SPL). The characteristic frequency of an acoustic nerve fiber is the 
frequency that evokes a response at the lowest sound pressure level, as low as 0 dB in the 
most sensitive range of hearing. The tuning curve, plotting the response area for a nerve fiber 
a graph of threshold sound pressure level vs. frequency, is extremely narrow at low sound 
levels, since the fiber responds only to a narrow band of frequencies near characteristic 
frequency, property likely linked to the active motility of the outer hair cells. The tuning 
curve is wider at high sound levels, in particular for frequencies below the characteristic 
frequency, likely reflecting most the passive mechanical characteristics of basilar membrane 
motion than outer hair cells electromotility. Fibers with the lowest characteristic frequencies 
innervate hair cells positioned at the cochlear apex, whereas fibers with higher characteristic 
frequencies contact hair cells located in progressively more basal regions, paralleling the 
pattern of basilar membrane vibration. This tonotopic mapping is preserved in the cochlear 
nucleus and along the central auditory pathway. Therefore, type I fibers respond to sound 
generating action potentials, often locked to particular phases within the cycle of the sound 
waveform following the phasic release of neurotransmitter depending by the AC receptor 
potential; both phase locking and AC receptor potential decrease for frequencies above 1 kHz. 
Action potentials are then conducted toward the brain via discrete pathways which form a 
percept of the stimulus by extracting information about which nerve fibers are responding 
(place code, about frequency of sound, whereby neurons at different places code for different 
frequencies) and the rate and time pattern of the spikes in each fiber (information about sound 
intensity). Auditory nerve fibers with the same characteristic frequency show different 
sensitivity to sound intensity, and the difference between lower and higher thresholds can be 
as large as 70 dB. The sensitivity of response (SR) is correlated with the spontaneous firing 
rate of neurons, varying from one fiber to another over the range of 0 to 100 spikes/s. Three 
main groups of fibers have been classified on the basis of spontaneous firing: low SR (0.5 
spikes/s), medium SR (0.5 to 17.5 spikes/s), high SR (17.5 spikes/s), the latter exhibiting 
higher sensitivities than the others. Low SR fibers play important roles in detecting changes 
in sounds at high intensities, because of both their low sensitivity, which causes them to 
respond mostly at high sound levels, and their lesser tendency to saturate. Information carried 
by the different SR groups may be kept somewhat separate in the brain stem: for example, 
low and medium SR fibers represent the largest afferents to the cochlear nucleus, 
preferentially innervating certain regions. 
The response of a single auditory nerve fiber increases with sound level until it is 
saturated, that is to say the fiber no longer increases its firing rate. This mostly occurs within 
a dynamic range generally between 20 and 30 dB, sometimes greater. Such a narrow 
individual dynamic range does not match the large range in level of audible sound, from 0 to 
100 dB. The auditory nerve can accurately signal within this large intensity range because 
fibers with the same characteristic frequency but lower sensitivity are recruited at higher 

Anatomy and Physiology of the Peripheral and Central Auditory System 
 
767
sound levels, when fibers tuned to other characteristic frequencies also begin to respond, 
since tuning curves become broader.  
 
 
3.2. Descending Control on Inner Ear 
 
The superior olivary complex of the brainstem projects fibers to the inner ear; in 
particular, lateral olivo-cochlear neurons, the function of which is not well known, contact 
dendrites of type I auditory nerve fibers through small diameter axons, whereas medial olivo-
cochlear neurons project to outer hair cells through cholinergic fibers (Guinan, 1996; 
Warr, 1992).  
Acetylcholine activates a nicotinic receptor on the membrane of the outer hair cell, 
allowing Ca2 influx and K+ efflux through Ca2- activated K+ channels: in this manner the 
membrane results hyperpolarized, reducing the electromotility of the outer hair cell and the 
motion of basilar membrane; the responsiveness of inner hair cells and auditory nerve fibers 
is reduced and results shifted to higher sound levels. Consequently, this mechanism may 
control the gain of the cochlear amplifier to prevent saturation of responses, inducing 
suppression of responsiveness to unwanted sounds, protecting hair cells in the cochlea from 
damage due to intense sounds, and letting the fiber signal changes in sound intensity even at 
higher sound levels, being also able to underlie auditory focus in noisy environments. 
 
 
3.3. Central Auditory Pathways 
 
Starting from the cochlear nucleus, the auditory information travels toward the cerebral 
cortex via the thalamus, relaying in several brainstem nuclei with relevant functions (Rhode 
and Greenberg1992). The cochlear nucleus is the best understood among auditory centers, 
being the region where parallel pathways in the auditory system begin. Cochlear nucleus 
neurons, excited by auditory nerve inputs, are classified following both morphological and 
functional criteria (tone burst-evoked firing pattern, map of response, laterality of response). 
On the basis of the cellular firing patterns in response to sound stimulation, cellular units in 
the cochlear nucleus are classified as “pauser” (pyramidal cells), “onset” (“octopus” cells), 
“primary-like with notch” (globular bushy cells), “chopper” (multipolar cells) and “primary-
like” (spherical bushy cells). Like tuning curves, response maps plotted on graphs of sound 
level versus frequency show areas of excitation; however, they can also show areas of 
inhibition in the dorsal subdivision of the cochlear nucleus, the inferior colliculus, and at 
higher stages of the auditory system, since at these levels inhibitory influences are present, 
shaping responses. Five response types have been defined (types I-V) on this basis: type I 
responses have no inhibitory areas, the other types have progressively larger inhibitory areas. 
Type IV neurons correspond to pyramidal cells, the main projection neurons of the dorsal 
cochlear neuron. Laterality of response is defined as whether the neuron responds to the 
contralateral or ipsilateral ear and whether the response is excitatory or inhibitory. Many 
neurons in central auditory nuclei above the cochlear nucleus are binaural and can be 
influenced by sound presented to either ear. A predominant pattern, however, is for the 
neuron to be excited by sound in the contralateral ear, resulting from the fact that many 

Fabio Bucchieri, Fabio Carletti, Sabrina David et al. 
 
768
central auditory pathways cross to the opposite side of the brain. The influence of the 
ipsilateral ear can be excitatory, inhibitory, or mixed. There are also uncrossed pathways; 
these pathways generate the response to the ipsilateral ear. Despite an influence of the 
ipsilateral ear, lesion studies indicate the functional importance of excitation from the 
contralateral ear. For instance, damage to the inferior colliculus or auditory cortex on one side 
decreases the ability to localize sounds on the opposite side. Thus, as in other sensory and in 
motor systems, one side of the brain is concerned primarily with function on the opposite side 
of the body. An important characteristic of most central auditory nuclei is tonotopic 
organization, the mapping of neural characteristic frequencies onto position. This feature is 
determined by basilar membrane features and is relayed into the central nervous system by 
CN VIII, resulting in regions in which neurons share the same characteristic frequency, called 
isofrequency laminae.  
The cochlear nucleus projects in turn to the other auditory nuclei of the brain stem: 
superior olivary complex, nuclei of the lateral lemniscus, and inferior colliculus, important for 
determination of the location of a sound source. In fact, whereas sound frequency is mapped 
along the cochlea, in contrast to other sensory systems the external location of a sound source 
is not directly represented in the auditory receptor organ. In the auditory system, directional 
information is centrally determined, mainly in the brain, by comparing interaural differences 
in responses. 
The location of azimuthal position of sound sources in space is predominantly determined 
by the auditory system at the brain stem level, by using two main binaural cues, respectively 
interaural time differences and interaural level differences, differently useful depending on 
the frequency of the sound (Brand et al, 2002; Wightman and Kistler 1993; Yin and 
Chan 1990). Regarding the former, sound reaches the ear nearest to the source earlier than 
the farther one, markedly depending on the azimuth of the source: interaural time differences 
can be then translated into phase differences in the sound waveforms at the two ears, 
particularly useful at low frequencies; however, they become less affordable for frequencies 
>1.5 kHz because the time interval needed for the sound to reach the farther ear could be 
sufficient for the waveform to repeat by a cycle or multiples. A second reason for differences 
are less important for localizing sounds at high frequencies is linked to the decline in phase 
locking for frequencies above 1 to 3 kHz. 
Interaural level differences are dependent on the sound shadow action exerted by the 
head, which reduces the level of sound at the ear away from the source. These differences are 
significantly large only at high frequencies, being much smaller at low frequencies. Thus, 
interaural time differences are the major cues for sound localization at low frequencies (1 
kHz), whereas interaural level differences for localization at high frequencies (3 kHz). The 
accuracy of azimuthal localization is good at both low and high frequencies, being less 
accurate at middle frequencies because the cues are more ambiguous in this range. The 
minimum discriminable angle for localization of a sound source approaches one degree of 
azimuth, corresponding to about 10 ms in interaural time and 1 dB interaural level 
differences.  
Two neural circuits that provide sensitivity to interaural time or level differences are 
within the superior olivary complex, respectively found in the medial (MSO) and in lateral 
superior olive (LSO), and their inputs. 

Anatomy and Physiology of the Peripheral and Central Auditory System 
 
769
Originated from both left and right cochlear nuclei, the afferents for the MSO of each 
side are from primary-like units (spherical bushy cells), the activity of which preserves the 
timing and phase-locking features of the auditory nerve fibers. For low frequency sounds 
joining from a lateral source, a time difference will exist between phase-locked spikes from 
one side relative to the ones of the other side. During a continuous sound, this time difference 
between phase-locked spikes will repeat for each of the many waveforms. 
An impulse takes time to travel along a fiber, that is way an axon can be considered a 
delay line. In the model proposed by Jeffress, within the MSO neurons respond best when 
they receive coincident input from the two sides, if the delays were about equal. If we 
consider a series of neurons in the MSO, each receiving converging inputs from both cochlear 
nuclei in such a way that the afferents from each cochlear nucleus enter the series from 
opposite sides, we observe that, because of the same conduction speed in afferent fibers, 
neurons in the middle of the series can receive temporally coincident activation only when 
both cochlear nuclei are activated simultaneously, that is to say when sound simultaneously 
reach both ears because its source is located along the midline, equidistant from each ear. For 
sound sources located laterally to the midline, coincident activation will be received by 
neurons more laterally placed in the series: the topography of neurons receiving coincident 
activation is hypothesized to be the key mechanism allowing to exactly perceive the source 
location of a sound.  
Neurons and circuits in the lateral superior olive (LSO) are sensitive to interaural level 
differences. LSO also receive bilateral inputs, excitatory from the ipsilateral side (joining 
from spherical bushy cells of the cochlear nucleus), whereas inhibitory from the contralateral 
side, in particular from globular bushy cells of the cochlear nucleus, and synapses on 
inhibitory neurons in the medial nucleus of the trapezoid body, which use the 
neurotransmitter glycine. LSO neurons compare the difference between sound levels at the 
two ears, being then excited when sound in the ipsilateral ear is of higher level, whereas 
inhibited when sound is of higher level in the contralateral ear. If sound is of equal level in 
the two ears, little neuronal response is observed because of a prevalent contralateral 
inhibition. These neurons are thus excited by sound sources located on the ipsilateral side of 
the head. The lateral superior olive projects centrally either excitatory fibers to the inferior 
colliculus on the opposite side, transforming this ipsilateral response to a contralateral one, or 
inhibitory fibers to the inferior colliculus of the same side. LSO is predominantly composed 
of neurons with high characteristic frequencies and has a tonotopic organization. 
Almost all ascending inputs from lower brain stem centers converges at the inferior 
colliculus, a structure displaying several subdivisions. The central nucleus is organized 
tonotopically and receives direct input from the cochlear nucleus and binaural input from the 
MSO and LSO: the dorsolateral part of the nucleus receives low characteristic frequency 
input, included the one from MSO, whereas the ventromedial part is targeted by LSO and 
generally by high characteristic frequency fibers. In the colliculus, terminals from the MSO 
and LSO may have limited spatial overlap: due to the nature of the afferents, neurons in the 
dorsolateral part of the colliculus are mainly sensitive to interaural time differences, whereas 
cells in the ventromedial region of the nucleus are sensitive to interaural level differences. 
Since additional circuits for the generation of ITD sensitivity have not been identified, the 
colliculus appears to be sensitive to interaural time differences mainly by action of its inputs 
from the MSO. On the contrary, damaging the superior olivary complex does not abolish 
sensitivity to interaural level differences in the colliculus, which can be then created anew at 

Fabio Bucchieri, Fabio Carletti, Sabrina David et al. 
 
770
levels above the LSO, either by the dorsal nucleus of the lateral lemniscus, that sends a large 
inhibitory projection to the colliculus, or by inhibitory mechanisms within the colliculus. 
Differently from other specialized mammals, in the human auditory system there is no 
evidence of a mapping of sound source location to position within the inferior colliculus.  
The inferior colliculus transmits auditory information to both the superior colliculus, 
where a spatial map of sound is found, and the auditory cerebral cortex: in particular, neurons 
of the inferior colliculus project to the medial geniculate body (de Ribaupierre, 1997), 
where principal cells in turn project to the auditory cortex. The pathways from the inferior 
colliculus include a lemniscal (core) pathway and extralemniscal (belt) pathways.  
 
 
3.4. Auditory Cortex 
 
The auditory cortex includes several areas of the dorsal temporal lobe (Clarey et al, 
1992). The ventral region of the medial geniculate nucleus sends the main projection to the 
primary auditory cortex (A1, or Brodmann area 41), which in humans lies on Heschl’s gyrus 
of the temporal lobe, medial to the sylvian fissure, and contains a tonotopic representation of 
characteristic frequencies, that is to say an organized map reflecting the pattern of peripheral 
sensors, based on the frequencies that best stimulate the neurons. In particular, neurons with 
low characteristic frequencies are located rostrally, whereas those tuned to high frequencies 
are found at the caudal end of A1. Then, a smooth frequency gradient is evident in one 
direction, whereas iso-frequency contours are observed along the orthogonal direction. Due to 
larger inputs, representations of relevant frequencies are wider in comparison with 
representations of other frequencies. Other characteristics of auditory stimuli are also 
represented in A1, with less clear mapping rules: for example, at right angles to the axis of 
tonotopic mapping, a map of binaural interactions is evident.  
Like other cortical areas, the auditory cortex is organized in cortical columns running 
across all of the cortical layers and oriented normally to the cortical surface. All neurons 
within a column have similar response characteristics (e.g., similar characteristic frequencies 
and types of responses to binaural sounds): regarding the latter, generally a cortical neuron is 
excited by the main ear (most often the contralateral one), whereas the opposite ear can be 
excitatory (EE neurons) or inhibitory (EI neurons), respectively displaying a summation or a 
suppressive interaction; depending on sound level, some neurons can show both summation 
and suppression interactions. Summation columns alternate with suppression columns, mainly 
in the A1 high frequency region. Neurons within a summation column tend to have large 
projections to the opposite hemisphere, whereas fewer contralateral projections are generally 
sent by suppression columns, unless for columns with neurons inhibited by contralateral ear 
and excited by ipsilateral ear. Thus, the auditory cortex can be subdivided into cortical 
columns responsive to every audible frequency and each type of binaural interaction. 
Others parameters mapped onto the surface of primary auditory cortex are bandwidth 
(responsiveness to a narrow or broad range of frequencies), neuronal response latency, 
loudness, etc. The intersection between different maps is not still understood. In every case, in 
A1 neurons and subregions many independent variables of sound are represented, which 
permit selective sound discrimination on the basis of several independent and/or combined 
analyses.  

Anatomy and Physiology of the Peripheral and Central Auditory System 
 
771
Multiple regions surround A1, many of which show a tonotopic representation. These 
areas receive direct input from the ventral division of the medial geniculate nucleus, primarily 
in cortical layers IIIb and IV. Adjacent tonotopic fields have mirror-image tonotopy, since the 
direction of tonotopy reverses at the boundary between fields. 
Actually, it is suggested by different Authors that primary or primary-like areas (core, 3 
or 4 areas) are surrounded by 7 to 10 secondary areas (belt), the latter receiving input from the 
core areas of auditory cortex, as well as from thalamic nuclei, in some cases (Rauschecker 
et al, 1995). As revealed by recent functional MRI studies, in humans and monkeys core 
regions are primarily activated by pure tones, whereas complex sounds and narrow-band 
noise bursts activate the neurons of belt areas. 
In the auditory cortex, many neurons with large receptive fields and broad tuning are 
sensitive to interaural time and level differences and therefore to spatial localization of 
sounds; however, no organized spatial map of sound is evident in any of the sound location 
sensitive cortical areas, differently from what observed in the midbrain (Buonomano and 
Merzenich, 1998; Cohen and Knudsen1999). These cortical neurons sensitive to sound 
spatial location are found along a sound-localization pathway starting from the central 
nucleus of the inferior colliculus and reaching (through the auditory thalamus) the A1 area, 
cortical association areas and the frontal eye fields, involved in gaze control, which are 
directly connected to brain stem tegmentum premotor nuclei mediating gaze changes, as well 
as to the superior colliculus.  
Cortical pathways are required for more complex sound-localization tasks (forming an 
image of the sound source, remembering it, moving toward it, etc.), being less active if the 
task is only to indicate the side of the sound source.  
As for the output from the primary visual and somatosensory cortex, the circuits 
originating from the auditory cortex are segregated into separate processing streams. In facts, 
the more rostral and ventral areas connect primarily to the more rostral and ventral areas of 
the temporal lobe, generally implicated in nonspatial functions, whereas the more caudal area 
projects to the dorsal and caudal temporal lobe, implicated in spatial processing. In addition, 
these belt areas and their temporal lobe targets both project to largely different areas of the 
frontal lobes. Caudal and parietal areas are more active when a sound must be located or 
moves, and ventral areas are more active during identification of the same stimulus or 
analysis of its pitch. Therefore, an oversimplified schema suggest that identification of 
auditory objects could be made by anterior-ventral pathways by analyzing spectral and 
temporal characteristics of sounds, whereas dorsal-posterior pathways could analyze sound 
source location and detection of source motion.  
As for both visual and somatosensory systems, the auditory cortex massively projects 
back to lower areas: the ratio between descending fibers entering the sensory thalamus and 
axons projecting from the thalamus to the cortex is almost 10:1. Fibers from the auditory 
cortex contact the inferior colliculus, olivo-cochlear neurons and the dorsal cochlear nucleus. 
Through these projections, the auditory cortex can actively increase and adjust the responses 
of neurons in subcortical structures, in this way modulating and sharpening signal processing. 
On the contrary, a decreased cortical activity reduces thalamic and collicular responses. 
Therefore, the cortex exercises a top-down control of perception. 
 
 

Fabio Bucchieri, Fabio Carletti, Sabrina David et al. 
 
772
REFERENCES 
 
Brownell, W. E., Bader, C. R., Bertrand, D., and de Ribaupierre, Y. (1985). Evoked 
mechanical response of isolated hair cells. Science, 227: 194–196. 
Brand, A., Behrend, O., Marquardt, T., McAlpine, D., and Grothe, B. (2002). Precise 
inhibition is essential for microsecond interaural time difference coding. Nature, 417: 
543–547. 
Buonomano, D. V. and Merzenich, M. M. (1998). Cortical plasticity: From synapses to maps. 
Annu. Rev. Neurosci., 21: 149–186. 
Clarey, J. C., Barone, P., and Imig, T. J. (1992). Physiology of thalamus and cortex. In “The 
Mammalian Auditory Pathway: Neurophysiology” (A. N. Popper and R. R. Fay, eds.), 
pp. 232–334. Springer-Verlag, New York. 
Cohen, Y. E. and Knudsen, E. I. (1999). Maps versus clusters: Different representations of 
auditory space in the midbrain and forebrain. Trends Neurosci., 12: 128–135. 
de Ribaupierre, F. (1997). Acoustical information processing in the auditory thalamus and 
cerebral cortex. In “The Central Auditory System” (G. Ehret and R. Romand, eds.), pp. 
317–397. Oxford Univ. Press, New York. 
Guinan, J. J., Jr. (1996). The physiology of olivocochlear efferents. In “The Cochlea” (P. 
Dallos, A. N. Popper, and R. R. Fay, eds.), pp. 435–502. Springer-Verlag, New York. 
Hudspeth, A. J. and Corey, D. P. (1977). Sensitivity, polarity, and conductance change in the 
response of vertebrate hair cells to controlled mechanical stimuli. Proc. Natl. Acad. Sci. 
USA, 74: 2407–2411. 
Liberman, M. C., Gao, J., He, D. Z. Z., Wu, X., Jia, S., and Zuo, J. (2002). Prestin is required 
for electromotility of the outer hair cell and for the cochlear amplifi er. Nature, 419: 300–
304. 
Pickles, J. O., Comis, S. D., and Osborne, M. P. (1984). Cross-links between stereocilia in the 
guinea-pig organ of Corti, and their possible relation to sensory transduction. Hearing 
Res., 15: 103–112. 
Rauschecker, J. P., Tian, B., and Hauser, M. (1995). Processing of complex sounds in the 
macaque nonprimary auditory cortex. Science, 268: 111–114. 
Rhode, W. S. and Greenberg, S. (1992). Physiology of the cochlear nuclei. In “The 
Mammalian Auditory Pathway, Neurophysiology” (A. N. Popper and R. R. Fay, eds.), 
pp. 94–152. Springer-Verlag, New York. 
Ruggero, M. A. (1992). Physiology and coding of sound in the auditory nerve. In “The 
Mammalian Auditory Pathway, Neurophysiology” (A. N. Popper and R. R. Fay, eds.), 
pp. 34–93. Springer-Verlag, New York. 
Rybalchenko, V. and Santos-Sacchi, J. (2003). Cl-flux through a nonselective, stretch 
sensitive conductance influences the outer hair cell motor of the guinea pig. J. Physiol., 
547.3: 873–891. 
Warr, W. B. (1992). Organization of olivocochlear efferent systems in mammals. In “The 
Mammalian Auditory Pathway, Neuroanatomy” (D. B. Webster, A. N. Popper, and R. R. 
Fay, eds.), pp. 410–448. Springer-Verlag, New York. 
Wightman, F. L. and Kistler, D. J. (1993). Sound localization. In “Human Psychophysics” 
(W. A. Yost, A. N. Popper, and R. R. Fay, eds.), pp. 155–192. Springer-Verlag, New 
York. 

Anatomy and Physiology of the Peripheral and Central Auditory System 
 
773
Yin, T. C. T. and Chan, J. C. K. (1990). Interaural time sensitivity in medial superior olive of 
cat. J. Neurophysiol., 64, 465–488. 
Zheng, J., Shen, W., He, D. Z., Long, K. B., Madison, L. D., and Dallos, P. (2000). Prestin is 
the motor protein of cochlear outer hair cells. Nature, 405: 149–155. 


In: Encyclopedia of Audiology and Hearing Research 
ISBN: 978-1-53617-702-2 
Editors: Erno Larivaara and Senja Korhola 
© 2020 Nova Science Publishers, Inc. 
 
 
 
 
 
 
 
Chapter 54  
 
 
 
GENETICS IN SENSORINEURAL HEARING LOSS 
 
 
Alessandro Castiglione*, MD, PhD 
Department of Neurosciences and Complex Operative Unit of Otorhinolaryngology, 
University Hospital of Padua, Italy 
 
 
ABSTRACT 
 
In the field of genetics, this decade will be characterized by the widespread use of 
so-called next-generation sequencers, first described in 2003, based on the human 
genome project publication essentially conducted through Sanger sequencing using the 
first generation of DNA-sequencers. Actually, before long, there was a rapidly growing 
demand for a new system, thus a new generation of non-Sanger-based sequencing 
technologies have been developed to sequence DNA at an unprecedented speed, thereby 
enabling impressive scientific achievements and novel biological applications. The 
premises and promises of similar events open a window on a next generation diagnosis of 
hearing losses. However, this new technology has to overcome the inertia of a field that 
has previously relied on Sanger-sequencing for 30 years. These new methods of DNA 
analysis are promising and could considerably reduce the time and cost of sequencing 
studies, up to the famous spot “the genome for $1,000”. However, the use of technology 
does not necessarily suggest an infallible diagnosis and optimal treatment. There is a need 
to “manage” a substantial amount of information (that at best will be different and 
complementary) to extrapolate meaningful or rather more valuable conclusions than 
previously obtained, as well as interpretations and the resolution of ethical and legal 
aspects paradoxically require increasing amounts of time and money to manage such 
situations. In addition, recent increasing scientific evidences are revaluating the 
Lamarckian approach to hereditary conditions beside to the classical most famous 
Mendelian or Darwinian models. Even more surprising and is the advent of genetic 
therapy for an increasing number of diseases. In conclusion, all events seem to announce 
a revolutionary decade for future diagnosis and treatments of genetic hearing loss. In such 
exciting, but also complex, context, the clinical approach needs to focus on the best and 
simplest solution. 
                                                        
* Corresponding Author address: Via Giustiniani, 2 – Padova, 35128 – PD, Italy, tel. +39 049 8212051, fax. +39 
049 8211994. E-mail: alessandro.castiglione@unipd.it. 

Alessandro Castiglione 
 
776
In this chapter, a brief review and update about genetics of hearing loss will be 
reported in the light of those revolutionary events, in order to help and accompanied the 
reader in reflecting on the new role of clinician in a high rapidly changing context.  
 
Keywords: genetics, hearing loss, syndromic hearing loss 
 
 
INTRODUCTION 
 
In the field of genetics, this decade will be characterized by the widespread use of so-
called next-generation sequencers (Schuster 2008, Shaffer 2007), first described in 2003, 
based on the human genome project publication (2003) essentially conducted through Sanger 
sequencing using the first generation of DNA-sequencers. However, before long, there was a 
rapidly growing demand for a new system. Thus, a new generation of non-Sanger-based 
sequencing technologies have been developed to sequence DNA at an unprecedented speed, 
thereby enabling impressive scientific achievements and novel biological applications. 
However, this new technology has to overcome the inertia of a field that has previously relied 
on Sanger-sequencing for 30 years (Schuster 2008). To characterize the new “tools” available 
to geneticists, we should consider the following example: previously published literature has 
been passed from pen and inkwell to scanner and digital copier in less than ten years. With 
minor inconvenience, in the terms of the previous example, scanners were initially used to 
acquire only parts of a line at a time, and subsequently the need to recreate complete 
sentences, pages, chapters, books and libraries increased as a reference to allow this process. 
In addition, the “writers”, “readers”, “book-shops” and the original sources have not been 
completely adapted and remain based on older technology. However, these new methods of 
DNA analysis are promising and could considerably reduce the time and cost of sequencing 
studies, up to the famous spot sentence “the genome for $1,000” (Dondorp and de Wert 
2013). Unfortunately, possessing a fantastic scanner does equate with being an excellent 
photographer or writer, and similarly the use of technology do not necessarily suggest an 
infallible diagnosis and optimal treatment. Thus, there is a need to “manage” a substantial 
amount of information (that at best will be different and complementary) to extrapolate 
meaningful or rather more valuable conclusions than previously obtained, for example 
interpretations and the resolution of ethical and legal aspects paradoxically require increasing 
amounts of time and money. Ironically, bioinformatics replies to the “genome for $1,000” 
spot with the “consequentially cost of $1 million for data analysis” (Mardis 2010). How could 
this paradox be avoided? How does this paradox affect clinical practice in general or specific 
cases? Although the aim of this chapter is not to resolve controversial scientific (or 
philosophical) debates, it can be argued that physicians, patients and readers benefit from the 
knowledge that there are too many questions about privacy and too many doubts concerning 
the accuracy and in other words, the interpretation of this information.  
Even when the clinical management and professionals involved are perfect, occasionally 
the genetics of hearing loss can generate confusion in patients, physicians and geneticists 
(also), likely reflecting the complexity and knowledge of the field (Salvago et al. 2014, De 
Stefano, Kulamarva, and Dispenza 2012). Indeed, a syndrome can be well known and well 
described (i.e., hearing loss, goiter, suggestive tonal and speech audiometries, CT/MRI scans 
with enlarged vestibular aqueducts and/or Mondini deformity, and positive perchlorate tests), 

Genetics in Sensorineural Hearing Loss 
 
777
although it might be difficult to identify a mutation in the gene responsible for that condition 
(SLC26A4, and/or FOXI1 and/or KCNJ10, etc.).  
 
 
HEARING LOSS AND ITS GENETICS 
 
Hearing impairment is one of the commonest clinical conditions, in particular at birth. It 
has been estimated that approximately 1-2 in 100 person has hearing concerns in the first 
decade of life (Martines et al. 2015, Dispenza, De Stefano, et al. 2013). The prevalence of 
childhood and adolescent hearing loss is around 3%. The causes of hearing loss differ and 
they can vary in severity and physiopathology: the etiology of hearing loss in children 
remains unknown in 30-40% of cases, non-genetic in 30-35%, genetic non-syndromic in 
30%, and genetic syndromic in 3-5% (Bartolotta et al. 2014, Dispenza, Cappello, et al. 2013). 
Most of genetic conditions responsible for hearing loss appear in a non-syndromic form (60-
75% of all genetic cases). The two most common genes involved in hearing loss are GJB2 for 
the non-syndromic forms and SLC26A4 the syndromic ones.  
The main objective of correctly identifying a syndrome should only be the usefulness for 
the patients. If you have doubts or improper diagnostic instruments it would be more helpful 
to describe, more objectively as possible, all available clinical data. Giving a “name” should 
help patients in manage and communicate their conditions, promoting a multidisciplinary 
approach. It should be also remembered that there are not specialists or specialties that can 
singularly approach all syndromes, as well as there is no a syndrome that cannot keep 
advantage from all available specialties. Therefore, the main target should be investigating 
and exploring clinical and genetic conditions trying to bring benefits to whom that are 
suffering from. The correct diagnosis comes next.  
Even if recent advances provide improvement in diagnosis, the most effective procedures 
to suspect a genetic cause of hearing loss still remains history and objective clinical 
examination essentially based on: 1) family history; 2) symmetry of clinical findings (bilateral 
hearing loss); 3) dysmorphic features 4) symptoms onset and/or progression. 
 
 
Non-Syndromic Hearing Loss (Approximately 65% of All Genetic Causes  
of Hearing Loss): Audioprofiles of Dominant and Recessive Patterns 
 
More than 60 genes have been so far associated with non-syndromic hearing loss. 
Mutations in the GJB2 gene still remain the leading cause of non-syndromic sensorineural 
hearing loss on a genetic basis; however today the new NGS panels modify the number of 
mutations identified in a more varied and wide gene range, including TMC1 and TECTA for 
example. A new useful approach especially for the non-geneticist specialist may be to 
consider audioprofiles in different transmission patterns: non-syndromic dominant (sexual or 
autosomal chromosomes), non-syndromic recessive (sexual or autosomal chromosomes) and 
mitochondrial. The definition of a specific audioprofile for genes and mutations provides a 
good genetic knowledge without neglecting the clinical contribution and consists practically 
in collecting clinical data (in essence they are condensed in the audiometric data being non-
syndromic forms, or in any case of a single organ, ear in this case) of all patients with similar 

Alessandro Castiglione 
 
778
mutations matched by age and when possible also by sex. Obviously for these case history is 
essential and collecting data revealed interesting considerations: in most cases non-syndromic 
with recessive patterns show worse entity of hearing loss without o slow progression, with 
early symptoms onset; in contrast dominant pattern has less severe loss of hearing, but high 
rate of progression with late onset. A deepening of these topics concerns the residual function 
of the proteins that has been widely found in the truncating and non-truncating forms of 
connexin 26 with important correlations and responses on the clinical clinic. However, as 
desirable, it would be quite challenging to evaluate and estimate the residual function of 
mutated proteins for each gene potentially involved in hearing loss, in addition to the 
difficulty in collecting an adequate number of identical mutations for each gene. 
 
 
Syndromic Hearing Loss, without Congenital Craniofacial Findings  
and Recessive Inheritance Pattern 
 
Even if initial screening examinations indicate normal hearing, the child remains at risk. 
During infancy and early childhood, parents should be aware of, and questioned about, the 
child’s hearing and language milestones. Some syndromes, such as Pendred, Alport, Refsum, 
neurofibromatosis type II, Usher, and osteopetrosis, may place the patient at risk for 
progressive hearing loss.  
 
 
Pendred Syndrome (Prevalence 7,5:100000, approximately 5% of Cases  
of Congenital Hearing Loss), otherwise the FOXI1-SLC26A4/ KCNJ10 
Genetic Variants Responsible for Ions Disorders in the Inner Ear) 
 
Two clinical pictures come from mutations in the SLC26A4 gene: (1) the syndromic 
form, called Pendred Syndrome, characterized by hearing loss, goiter and eventually 
hypothyroidism, with/without EVA or other inner ear malformations as Mondini deformity; 
(2) the non-syndromic form, called DFNB4 or non-syndromic EVA (when EVA is present), 
characterized by hearing loss with/without EVA or other inner ear malformations. Mutations 
in the FOXI1 (5q34) gene can be also responsible for these conditions. FOXI1 encodes for a 
transcriptional activator that allow the transcription of SLC26A4 and it is fundamental to 
develop normal sense of hearing and balance. Furthermore, mutations in the inwardly 
rectifying K (+) channel gene KCNJ10 (1q23.2) can be also associated with hearing loss in 
carriers of SLC26A4 mutations The inner ear malformations, when present, are generally 
bilateral (even if unilateral involvement is not exceptional), and they not seem to affect the 
auditory rehabilitation through cochlear implantation (Benatti et al. 2013, Busi et al. 2012, 
Busi et al. 2015, Castiglione, Busi, and Martini 2013, Castiglione et al. 2014).  
The type of hearing loss is mixed and variable from moderate to profound; the hearing 
impairment can be progressive and affected patients can benefit from binaural or bimodal 
auditory training with hearing aids or cochlear implantation. Considering the progression of 
the disease required a planning in prescribing auditory device that takes into account this 
concrete possibility. Even if a conductive component can be present, generally patients do not 

Genetics in Sensorineural Hearing Loss 
 
779
take advantages from bone conduction devices (Benatti et al. 2013, Busi et al. 2012, Busi et 
al. 2015, Castiglione, Busi, and Martini 2013, Castiglione et al. 2014). 
 
 
Usher Syndrome (Ciliopathies Reflecting the Potential Effects of  
Variations in the Genes Encoding Actin-Based Structures and  
Tip Links in Inner Ear Cells) 
 
There are 3 types of Usher Syndrome and 10 subtypes, which altogether account for the 
diagnosis of 3.5 cases per 100,000 births. Thus, this syndrome is one of the most common 
illnesses after Pendred Syndrome, characterized by hearing loss without major dysmorphic 
aspects. The genetics of Usher Syndrome are complex, reflecting the high number of genes 
potentially involved in this condition: MYO7A, USH1C, CDH23, PCDH15, SANS, USH2A, 
VLGR1, WHRN, USH3A, and PDZD7 (Reiners et al. 2006). The majority of these genes are 
involved in the formation and constitution of specific structures (called tip-link) and actin 
filaments in inner ear cells. Notably, the cilia outside of the inner ear typically composed of 
tubulin (not actin); therefore, these structures are preserved in Usher Syndrome. However, 
syndromes that show similar aspects, such as Alström Syndrome, could result from mutations 
in genes encoding proteins and elements common to actin and tubulin, suggesting a wide 
clinical spectrum (and more severe) in Alström Syndrome. The retinal pigment epithelium 
contains both actin and tubulin filaments essential for melanosome activity. Retinitis 
pigmentosa in Usher and Alström Syndromes results from defects in actin and/or tubulin in 
the retinal pigment epithelium or photoreceptors. 
Patients with Usher Syndrome develop hearing loss and vestibular and visual 
impairments. This disorder is inherited in an autosomal recessive pattern and characterized by 
progressive blindness resulting from retinitis pigmentosa, and moderate to severe 
sensorineural hearing loss. Usher syndrome has been classified into three types: Type I, 
characterized by severe to profound bilateral congenital hearing loss and poor or absent 
vestibular function with retinitis pigmentosa diagnosed by 10 years of age; Type II, 
characterized by mild to moderate hearing loss at birth and normal vestibular function with 
the onset of retinitis pigmentosa during late adolescence; Type III, characterized by 
progressive hearing loss and vestibular dysfunction with a variable degree of retinitis 
pigmentosa (Castiglione, Busi, and Martini 2013). Due to the lacking of visual reinforcement 
in spatial orientation, these patients can benefit from mandatory binaural auditory 
rehabilitation, when not contraindicated, with hearing aids or cochlear implants. 
 
 
Jervell and Lange-Nielsen Syndrome (Prevalence 0.3: 100,000), or Genetic 
Variants of KCN1/KCNE1 Genes Responsible for Ions Disorders in the 
Inner Ear 
 
Prolongation of the QT interval can come out from genetic defects in channel proteins, 
the same proteins that can be responsible for sensorineural hearing loss when expressed in the 
inner ear. These channels are critical in the function of the inner ear and heart muscle. The 
prolonged QT has the higher prevalence among this patients, and then is called Jervell and 

Alessandro Castiglione 
 
780
Lange-Nielsen syndrome when (and only if) it is accompanied by hearing loss; thus, by 
definition, 100% of patients have hearing loss that tends to be severe to profound. Mutations 
in the KCNQ1, and less commonly, the KCNE1 gene, coding proteins that form potassium 
transport channels, are considered responsible for the Jervell and Lange-Nielsen syndrome.  
 
 
Syndromic Hearing Loss with Congenital Craniofacial Findings  
and Dominant Inheritance Pattern 
 
Describing morphological and clinical aspects still remains the best clinical practice 
involving the precise, thorough and accurate collection of signs and symptoms, suggesting 
that the accurate diagnosis of a syndrome is not an intuitive reaction when examining a 
patient. Indeed, patients must be examined from different point of views: frontal, lateral and 
ventral. Examiners must not estimate abnormalities through sight, but rather anomalies should 
be measured using appropriate instruments. These analyses should proceed stepwise, 
combining until the obtained knowledge facilitates the consideration of clinical aspects other 
specialists have previously described or defined. Useless tests or exams and needless 
considerations of all available tests for patients should be avoided. Even when the diagnosis 
seems accurate, 2-3 alternative solutions should also be considered to avoid misdiagnosis. 
Notably, having a mutation does not prevent the occurrence of other diseases, conditions or 
genetic disorders. In most cases, it is possible to hypothesize fragility in DNA repair or 
function, even when difficult to prove, thus a collection of different mutations could affect the 
phenotype. 
 
 
BOR Syndrome and EYA1 Related Disorders (or Branchial Defects 
Potentially Resulting from Genetic Variants in EYA1, SIX5, and SIX5, 
Genes on the Axis of the Tbx1-Six1/Eya1-Fgf8 Genetic Pathway) 
 
Branchio-oto-renal (BOR) syndrome is an autosomal dominant disorder comprising 
external, middle and inner ear malformations, branchial cleft sinuses, cervical fistulae, mixed 
or conductive hearing loss and renal anomalies with an estimate prevalence of 2-3:100000 
newborns, responsible for approximately 2% of deaf children. BOR syndrome is perhaps one 
of the most frequent syndromes responsible for hearing loss, with most difficulties in defining 
and performing auditory rehabilitation. With respect to syndromes in otolaryngology, the 
BOR disorder represents the first ones among congenital malformations (together with the 
Treacher Collins syndrome). Furthermore, BOR syndrome is perhaps one with the widest 
clinically variable diseases with uncertain auditory assessment and rehabilitation. The best 
advice in these cases is to exclusively to rely on audiometric profiling and patient 
impressions, as there is no clear correlation between the observed malformations and the 
severity of hearing loss. Notably, all associated congenital conditions, mild or moderate, 
represent the natural hearing for these patients. Therefore, external interventions (surgery or 
hearing aids) might be considered “artificial” and “unacceptable”. Indeed, experts must 
perform reconstructive surgery on the middle and external ears, and the results in terms of 
auditory function can be extremely disappointing, if not pejorative.  

Genetics in Sensorineural Hearing Loss 
 
781
BOR syndrome primarily reflects mutations in EYA1 (on chromosome 8, BOR type 1) 
SIX 5 (on chromosome 19, BOR type 2) and SIX1 (on chromosome 14, BOR type 3) genes, 
although we cannot exclude the involvement of other genes that play a role in the Tbx1-
Six1/Eya1-Fgf8 genetic pathway, which controls mammalian cardiovascular and craniofacial 
morphogenesis, as demonstrated for other branchial defects, such as Di George syndrome 
(Guo et al. 2011). 
 
 
CHARGE Association (or Overlapping Features with DiGeorge Syndrome 
and Other Branchial Defects Resulting from Genetic Variations in the 
SMAD1/CHD7-FGF8/BMP Family/WNT1-OTX2-FOXA2-TBX1  
Genetic Pathways) 
 
When considering genetic hearing loss, the possibility of sharing new pathways with 
other syndromes should be considered, suggesting that these defects can be surprisingly 
similar (or different) (Corsten-Janssen et al. 2013, Guo et al. 2011, Liu et al. 2014, Payne et 
al. 2015, Schulz et al. 2014).  
CHARGE association or syndrome has a birth prevalence of approximately 0.14 per 
100,000 newborns. The acronym recalls the primary clinical manifestations of this syndrome, 
although the corollary of signs and symptoms are much more vast and complex, including iris 
or retinal colobomas, heart disease, choanal atresia, growth defects and developmental delays, 
genitourinary hypoplasia, external ear abnormalities, brain abnormalities, sensorineural 
hearing loss (up to 90% of cases), respiratory problems and cranial nerve hypoplasia 
(including the seventh and the eighth ones) with important functional deficits. This 
association reflects mutations in the CHD7 gene in approximately two thirds of cases. The 
CHARGE association alone it is not an absolute limit to the rehabilitation program; indeed, 
expectations must be consistent with the clinical conditions, and in cases of cochlear implant, 
the expert medical team will generate nerve stimulation, and carefully evaluate hypoplasia 
and malformations. Bilateral or binaural rehabilitation is desirable. 
 
 
Mutations in the MITF Pathway (Responsible for Waardenburg Syndrome) 
 
The MITF promoter is partially regulated through the transcription factors PAX3, SOX10, 
LEF1/TCF and CREB during melanocyte development. In humans, mutations affecting the 
MITF pathway lead to pigmentary and auditory defects, collectively known as Waardenburg 
Syndrome (WS) (Lin and Fisher 2007). The MITF gene encodes a transcription factor that 
regulates the differentiation and development of melanocytes and the retinal pigment 
epithelium and is also responsible for the pigment cell-specific transcription of melanogenesis 
genes. Hearing deficiency stems from a requirement for melanocytes within the stria 
vascularis of the cochlea (inner ear), a requirement involving the maintenance of 
endolymphatic potassium for auditory nerve action potential. Waardenburg-associated 
mutations represent a striking epistatic series in which essentially every culprit gene is 
mechanistically associated with the regulation of MITF expression or activity. These genes, 
including Pax3, Slug, Sox10, endothelin 1, and endothelin receptor B, are transcriptional 

Alessandro Castiglione 
 
782
regulators of MITF expression (Pax3 and Sox10), transcriptional targets of MITF (Slug), or 
MAPK activators that directly phosphorylate MITF (ET1 and EdnrB) (Steel 1995, Chin, 
Garraway, and Fisher 2006). Mutations in MITF gene are also responsible for melanomas, but 
these mutations typically differ in type and effect from those causing pigmentary defects and 
deafness, thus leading to different phenotypes (Grill et al. 2013). 
 
 
CONCLUSION: PERFORM SIMPLE TASKS  
WITH THE HIGHEST ATTENTION 
 
In 2013, Stamatiou GA and Stankovic KM (Stamatiou and Stankovic 2013) published a 
fine analysis on a new point of view during the present new era of NGS to identify “genetic 
nodes” of several genes. The genes associated with hearing loss and deafness were identified 
through PubMed literature searches and the Hereditary Hearing Loss Homepage. These genes 
were assembled into 3 groups: 63 genes associated with nonsyndromic deafness, 107 genes 
associated with nonsyndromic or syndromic sensorineural deafness, and 112 genes associated 
with otic capsule development and malformations. Each group of genes was analyzed to 
identify the most interconnected nodal molecules. The nodal molecules of these networks 
included transforming growth factor beta1 (TGFB1) for Group 1, MAPK3/MAPK1 MAP 
kinase (ERK 1/2) and the G protein coupled receptors (GPCR) for Group 2, and TGFB1 and 
hepatocyte nuclear factor 4 alpha (HNF4A) for Group 3. These results were confirmed in 
different analyses, suggesting new investigations and treatments involving glutathione, 
protein kinase B (Akt) and nuclear factor kappa B (NFkB) (Muller and Barr-Gillespie 2015). 
A potential solution for more demanding genetic analyses could involve separating the 
multitude of genes in variously articulated pathways of different lengths, assigning priority 
when possible, and subsequently analyzing these pathways, moving on to the next series 
when a non-conclusive mutation is identified; these analyses must continue until the changes 
that greatly impact pathological pathways are identified. 
Not only wide analyses but also targeted analyses should be performed, and impacted 
pathways should be developed and designed, considering the clinical and diagnostic 
possibilities. At this point the quality of a pathway is fundamental and should be well known 
and defined as the metabolic pathway. Obviously, a long period of study and analysis to 
identify genetic variations (pathological conditions) is needed, as the cause-effect relationship 
does not always exhibit a desirable time of onset, and frequently, only the initial effects 
associated with disease causes are observed. 
However, a genetic pathway is not always as linear as a classical metabolic pathway, 
rather metabolic pathways can be “modified” in different ways, whereas a genetic pathway 
can be “far” from linear, with sequential events, also influenced through time and the 
environment. Thus, the clinical phenotype is markedly helpful in defining the depth of the 
associated analysis. 
 
 
 
 

Genetics in Sensorineural Hearing Loss 
 
783
REFERENCES 
 
2003. “International consortium completes human genome project.” Pharmacogenomics 4 
(3):241. doi: 10.1517/phgs.4.3.241.22688. 
Bartolotta, C., P. Salvago, S. Cocuzza, C. Fabiano, P. Sammarco, and F. Martines. 2014. 
“Identification of D179H, a novel missense GJB2 mutation in a Western Sicily family.” 
European Archives of Oto-Rhino-Laryngology 271 (6):1457-1461. doi: 10.1007/s00405-
013-2613-y. 
Benatti, A., A. Castiglione, P. Trevisi, R. Bovo, M. Rosignoli, R. Manara, and A. Martini. 
2013. “Endocochlear inflammation in cochlear implant users: case report and literature 
review.” Int J Pediatr Otorhinolaryngol 77 (6):885-93. doi: 10.1016/j.ijporl.2013.03.016. 
Busi, M., A. Castiglione, M. Taddei Masieri, A. Ravani, V. Guaran, L. Astolfi, P. Trevisi, A. 
Ferlini, and A. Martini. 2012. “Novel mutations in the SLC26A4 gene.” Int J Pediatr 
Otorhinolaryngol 76 (9):1249-54. doi: 10.1016/j.ijporl.2012.05.014. 
Busi, Micol, Monica Rosignoli, Alessandro Castiglione, Federica Minazzi, Patrizia Trevisi, 
Claudia Aimoni, Ferdinando Calzolari, Enrico Granieri, and Alessandro Martini. 2015. 
“Cochlear Implant Outcomes and Genetic Mutations in Children with Ear and Brain 
Anomalies.” BioMed Research International. 
Castiglione, A., S. Melchionda, M. Carella, P. Trevisi, R. Bovo, R. Manara, and A. Martini. 
2014. “EYA1-related disorders: Two clinical cases and a literature review.” Int J Pediatr 
Otorhinolaryngol. doi: 10.1016/j.ijporl.2014.03.032. 
Castiglione, Alessandro, Micol Busi, and Alessandro Martini. 2013. “Syndromic hearing loss: 
An 
update.” 
Hearing, 
Balance 
and 
Communication 
11 
(3):146-159. 
doi: 
10.3109/21695717.2013.820514. 
Chin, L., L. A. Garraway, and D. E. Fisher. 2006. “Malignant melanoma: genetics and 
therapeutics in the genomic era.” Genes Dev 20 (16):2149-82. doi: 10.1101/gad. 
1437206. 
Corsten-Janssen, N., S. C. Saitta, L. H. Hoefsloot, D. M. McDonald-McGinn, D. A. Driscoll, 
R. Derks, K. A. Dickinson, W. S. Kerstjens-Frederikse, B. S. Emanuel, E. H. Zackai, and 
C. M. van Ravenswaaij-Arts. 2013. “More Clinical Overlap between 22q11.2 Deletion 
Syndrome and CHARGE Syndrome than Often Anticipated.” Mol Syndromol 4 (5):235-
45. doi: 10.1159/000351127. 
De Stefano, A., G. Kulamarva, and F. Dispenza. 2012. “Malignant paroxysmal positional 
vertigo.” Auris Nasus Larynx 39:378-382. 
Dispenza, F, F Cappello, G Kulamarva, and A De Stefano. 2013. “The discovery of the 
stapes.” Acta Otolaryngol Ital 33 (5):357-359. 
Dispenza, F., A. De Stefano, C. Costantino, D. Marchese, and F. Riggio. 2013. “Sudden 
Sensorineural Hearing Loss: Results of intratympanic steroids as salvage treatment.” Am 
J Otolaryngol 34 (4):296-300. 
Dondorp, W. J., and G. M. de Wert. 2013. “The ‘thousand-dollar genome’: an ethical 
exploration.” Eur J Hum Genet 21 Suppl 1:S6-26. doi: 10.1038/ejhg.2013.73. 
Grill, C., K. Bergsteinsdottir, M. H. Ogmundsdottir, V. Pogenberg, A. Schepsky, M. 
Wilmanns, V. Pingault, and E. Steingrimsson. 2013. “MITF mutations associated with 
pigment deficiency syndromes and melanoma have different effects on protein function.” 
Hum Mol Genet 22 (21):4357-67. doi: 10.1093/hmg/ddt285. 

Alessandro Castiglione 
 
784
Guo, C., Y. Sun, B. Zhou, R. M. Adam, X. Li, W. T. Pu, B. E. Morrow, A. Moon, and X. Li. 
2011. “A Tbx1-Six1/Eya1-Fgf8 genetic pathway controls mammalian cardiovascular and 
craniofacial morphogenesis.” J Clin Invest 121 (4):1585-95. doi: 10.1172/JCI44630. 
Lin, J. Y., and D. E. Fisher. 2007. “Melanocyte biology and skin pigmentation.” Nature 445 
(7130):843-50. doi: 10.1038/nature05660. 
Liu, Y., C. Harmelink, Y. Peng, Y. Chen, Q. Wang, and K. Jiao. 2014. “CHD7 interacts with 
BMP R-SMADs to epigenetically regulate cardiogenesis in mice.” Hum Mol Genet 23 
(8):2145-56. doi: 10.1093/hmg/ddt610. 
Mardis, E. R. 2010. “The $1,000 genome, the $100,000 analysis?” Genome Med 2 (11):84. 
doi: 10.1186/gm205. 
Martines, F., P. Salvago, C. Bartolotta, S. Cocuzza, C. Fabiano, S. Ferrara, E. La Mattina, M. 
Mucia, P. Sammarco, F. Sireci, and E. Martines. 2015. “A genotype–phenotype 
correlation in Sicilian patients with GJB2 biallelic mutations.” European Archives of Oto-
Rhino-Laryngology 272 (8):1857-1865. doi: 10.1007/s00405-014-2970-1. 
Muller, U., and P. G. Barr-Gillespie. 2015. “New treatment options for hearing loss.” Nat Rev 
Drug Discov 14 (5):346-65. doi: 10.1038/nrd4533. 
Payne, S., M. J. Burney, K. McCue, N. Popal, S. M. Davidson, R. H. Anderson, and P. J. 
Scambler. 2015. “A critical role for the chromatin remodeller CHD7 in anterior 
mesoderm during cardiovascular development.” Dev Biol 405 (1):82-95. doi: 
10.1016/j.ydbio.2015.06.017. 
Reiners, J., K. Nagel-Wolfrum, K. Jurgens, T. Marker, and U. Wolfrum. 2006. “Molecular 
basis of human Usher syndrome: deciphering the meshes of the Usher protein network 
provides insights into the pathomechanisms of the Usher disease.” Exp Eye Res 83 
(1):97-119. doi: 10.1016/j.exer.2005.11.010. 
Salvago, P., E. Martines, E. La Mattina, M. Mucia, P. Sammarco, F. Sireci, and F. Martines. 
2014. “Distribution and phenotype of GJB2 mutations in 102 Sicilian patients with 
congenital non syndromic sensorineural hearing loss.” International Journal of Audiology 
53 (8):558-563. doi: 10.3109/14992027.2014.905717. 
Schulz, Y., P. Wehner, L. Opitz, G. Salinas-Riester, E. M. Bongers, C. M. van Ravenswaaij-
Arts, J. Wincent, J. Schoumans, J. Kohlhase, A. Borchers, and S. Pauli. 2014. “CHD7, 
the gene mutated in CHARGE syndrome, regulates genes involved in neural crest cell 
guidance.” Hum Genet 133 (8):997-1009. doi: 10.1007/s00439-014-1444-2. 
Schuster, S. C. 2008. “Next-generation sequencing transforms today’s biology.” Nat Methods 
5 (1):16-8. doi: 10.1038/nmeth1156. 
Shaffer, C. 2007. “Next-generation sequencing outpaces expectations.” Nat Biotechnol 25 
(2):149. doi: 10.1038/nbt0207-149. 
Stamatiou, G. A., and K. M. Stankovic. 2013. “A comprehensive network and pathway 
analysis 
of 
human 
deafness 
genes.” 
Otol 
Neurotol 
34 
(5):961-70. 
doi: 
10.1097/MAO.0b013e3182898272. 
Steel, K. P. 1995. “Inherited hearing defects in mice.” Annu Rev Genet 29:675-701. doi: 
10.1146/annurev.ge.29.120195.003331. 
 

In: Encyclopedia of Audiology and Hearing Research 
ISBN: 978-1-53617-702-2 
Editors: Erno Larivaara and Senja Korhola 
© 2020 Nova Science Publishers, Inc. 
 
 
 
 
 
 
 
Chapter 55 
 
 
 
CONGENITAL SENSORINEURAL HEARING LOSS 
 
 
Sara Ghiselli1,2, MD, Bruno Galletti1, MD,  
Francesco Freni1, MD, PhD, Rocco Bruno1, MD  
and Francesco Galletti1, MD 
1University of Messina, Department of Human Pathology of the Adult  
and of the Developmental Age “G. Barresi,” ENT Section, Messina, Italy 
2IRCCS “Burlo Garofalo,” Trieste, Italy 
 
 
ABSTRACT 
 
Congenital hearing loss (CHL) is defined as the hearing loss present at birth and, 
consequently, before speech development. It is one of the prevalent chronic conditions in 
children and the main sensor neural disorder in developed countries. The estimated 
prevalence of permanent bilateral CHL is 1-3 per 1000 live births in developed countries.  
CHL is caused by genetic factors in more than 50% of the cases. Genetic hearing 
loss may be the only clinical feature (non-syndromic or isolated forms) or may be 
associated with other symptoms (syndromic forms).  
Non-syndromic hearing loss is extremely heterogeneous. About 80% of the cases are 
autosomal recessive, 15-24% are autosomal dominant and 1-2% are X-linked. 
Furthermore, less than 1% of CHL resulting from mitochondrial mutations and it presents 
with a characteristic matrilineal pattern of transmission. Typically, autosomal recessive 
hearing loss is congenital whereas autosomal dominant is often progressive. The most 
frequent isolated form of genetic hearing loss in white population of Europe and United 
States is the gap junction protein beta 2 gene (GJB2) mutation that is the gene encoding 
connexin-26.  
Syndromic form represents about the 30% of the cases of CHL and literature reports 
more than 400 syndromes where hearing loss is accompanied with physical or laboratory 
findings. Responsible genes are known for many of these scenarios.  
A genetic diagnosis is required for different reasons, in particular for choosing 
appropriate therapeutic options, for treating associated medical problem (syndromic 
forms) and for predicting the progression of the degree. New treatments and screening 
strategies are available for identifying the responsive gene, e.g., Next Generation DNA 
sequencing that allows the simultaneous analysis of a large number of genes causing 
CHL with a higher probability of gene identification. 

Sara Ghiselli, Bruno Galletti, Francesco Freni et al. 
 
786
This paragraph will describe the different genes and clinical features involved in 
CHL both in isolated and in syndromic form. 
 
Keywords: congenital hearing loss, genetic hearing loss, deafness 
 
 
INTRODUCTION 
 
Congenital hearing loss (CHL) is defined as the hearing loss present at birth and, 
consequently, before speech development.  
It is one of the prevalent chronic conditions in children and the main sensor neural 
disorder in developed countries.  
The estimated prevalence of permanent bilateral CHL is 1-3 per 1000 live births in 
developed countries and it varies between 19-24 newborns in sub-Saharian Africa and South 
Asia respectively.  
The prevalence of the hearing loss increase until 3-4 per live birth [1] during the first 5 
years of life when considering the progressive hearing loss genetically programmed. 
Late diagnosis or treatment has consequences on different child developmental area. CHL 
affect speech development, language acquisition and it has an impact in brain plasticity and 
cognitive development. The hearing impairment, if it is not properly treated, move to isolating 
themselves to society and may decrease work opportunity in adult life.  
For these reasons, it is very important an early diagnosis and an early right treatment of 
the CHL. Universal newborn hearing screening program has allowed a reduction of the time 
of reimbursement of the child with different type and degree of deafness and a consequent 
reduction of the associated disabilities. 
Moreover, different economic studies underline that untreated hearing loss has a high 
social cost during the life (e.g., in the USA amount to $1.1 milion for person) and this cost 
decrease by 75% in case of early intervention and treatment [2]. Schulze-Gattermann showed 
that pediatric cochlear implantation provides positive cost-benefit ratios compared with 
hearing aid users especially if the child is implanted before the age of 2 years [3]. 
The benefits are not only economic but also in quality of life and school cost (moreover 
in country where there are special school for deaf people) [4]. 
Psychological reaction to a cochlear implant (CI) may be influenced by the temperament 
of the implanted subject [5]. 
More than 50% of the CHL is caused by genetic factors but it is difficult found the 
specific etiologic diagnosis. In fact, may be only one mutation in a specific gene or different 
mutations in different genes. Moreover may be an association with environmental prenatal 
factors (e.g., infections, prematurity, neonatal intensive care unit recovery). 
Genetic hearing loss may be the only clinical feature (non-syndromic or isolated forms) 
or may be associated with other symptoms (syndromic forms). 
Approximately 30% of the CHL considered syndromic and the remaining 70% being 
non-syndromic. 
Non-syndromic hearing loss is extremely heterogeneous. About 80% of the cases are 
autosomal recessive, 15-24% are autosomal dominant and 1-2% are X-linked. 
Typically, autosomal recessive hearing loss is congenital whereas autosomal dominant is 
often progressive. 

Congenital Sensorineural Hearing Loss 
 
787
The loci linked to non-syndromic CHL are conventionally named using a prefix followed 
by a suffix integer: DNFA for autosomal dominant loci, DFNB for autosomal recessive loci 
and DFN for X-linked loci. 
The syndromic form can be differentiated from nonsyndromic hearing loss by the 
presence of associated symptoms in other organ systems. Syndrome that involve hearing loss 
are currently more than 400 and in some cases deafness is not present at birth but it appears 
later.  
Know the different gene implicated in hearing loss is very important because it allows to 
give information, at the proband and his family, with specific genetic counselling about 
prognosis and recurrence. A genetic diagnosis is required also for choosing appropriate 
therapeutic options, for treating associated medical problem (in syndromic forms) and for 
predicting the progression of the degree. 
Researcher and clinicians can always be informed about gene implicate in CHL (number, 
mutation 
and 
loci) 
consulting 
the 
Hereditary 
Hearing 
loss 
Homepage 
(http://hereditaryhearingloss.org) or http://ghr.nlm.nih.gov. 
New treatments and screening strategies are available for identifying the responsive gene, 
e.g., Next Generation DNA sequencing and genetic panels that allow the simultaneous 
analysis of a large number of genes causing CHL with a higher probability of gene 
identification. 
This paragraph will describe the different genes and clinical features involved in CHL 
both in isolated and in syndromic form. 
 
 
NON SYNDROMIC CHL 
 
Non Syndromic CHL_Autosomal Recessive Hearing Loss 
 
The loci and genes for non-syndromic, autosomal-recessive deafness are presented in 
Table 1. 
 
Table 1. Genes related with autosomal recessive non-syndromic  
congenital hearing loss 
 
Locus 
Gene 
Chromosomal Location 
Protein 
Function 
DFNB1 
GJB2 
GJB6 
13q11–q12 
Connexin 26 
Connexin 30 
Gap junction (ion haemostasis) 
DFNB2 
MYO7A 
11q13.5 
Myosin VIIa 
Transport 
DFNB3 
MYO15 
17p11.2 
Myosin Xva 
Transport 
DFNB4 
SLC26A4 
7q31 
Pendrin 
Acid-base balance of endolymph 
(ion haemostasis) 
DFNB5 
 
14q12 
 
 
DFNB6 
TMIE 
3p21 
 
 
DFNB7 
TMC1 
9q13–q21 
 
 
DFNB8 
TMPRSS3 
21q22.3 
 
 
DFNB9 
OTOF 
2p23.1 
Otoferlin 
Fusion of synaptic vescicle with 
Ca+2 
DFNB10 
TMPRSS3 
21q22.3 
 
 
DFNB11 
 
9q13–q21 
 
 
 

Sara Ghiselli, Bruno Galletti, Francesco Freni et al. 
 
788
Table 1. (Continued) 
 
Locus 
Gene 
Chromosomal Location 
Protein 
Function 
DFNB12 
CDH23 
10q21–q22 
Cadherin 23 
Lateran and tip links (adhesion) 
DFNB13 
 
7q34–q36 
 
 
DFNB14 
 
7q31 
 
 
DFNB15 
 
3q21.3–q25.2/19p13.3–p13.1 
 
 
DFNB16 
STRC 
15q15 
Stereocilin 
TM attachment links (adhesion) 
DFNB17 
 
7q31 
 
 
DFNB18 
USH1C 
11p15.1 
Harmonin 
Scaffolding protein (adhesion) 
DFNB20 
 
11q25–qter 
 
 
DFNB21 
TECTA 
11q23–q25 
α-tectorin 
Stability and structure of TM 
DFNB22 
OTOA 
16p12.2 
Otoancorin 
TM attachment to nonsensory 
cell (adhesion) 
DFNB23 
PCDH15 
10q21.1 
Protocadherin 15 
Lateran and tip links (adhesion) 
DFNB27 
 
2q23–q31 
 
 
DFNB29 
CLDN14 
21q22.1 
Claudin 14 
Tight junction 
DFNB30 
MYO3A 
10p11.1 
Myosin IIIA 
Transport 
DFNB31 
WHRN 
9q32–q34 
Whirlin 
Scaffolding protein (adhesion) 
DFNB32 
 
1p22.1–p13.3 
 
 
DFNB33 
 
9q34.3 
 
 
DFNB35 
 
14q24.1–q24.3 
 
 
DFNB36 
ESPN 
1p36.3 
Espin 
Actin crosslinking and bundling 
DFNB37 
MYO6 
6q13 
Myosin VI 
Regualtion of exocytosis, 
stereocilia anchoring 
DFNB38 
 
6q26–q27 
 
 
DFNB39 
 
7q11.22–q21.12 
 
 
DFNB40 
 
22q11.21–q12.1 
 
 
DFNB42 
 
3q13.31–q22.3 
 
 
DFNB44 
 
7p14.1–q11.22 
 
 
DFNB46 
 
18p11.32–p11.31 
 
 
DFNB48 
 
15q23–q25.1 
 
 
DFNB49 
TRIC 
5q12.3–q14.1 
Tricellulin 
Tight junction 
DFNB53 
COL11A2 
6p21.3 
Type XI collagene α2 
Stability and structure of TM 
DFNB55 
 
4q12–q13.2 
 
 
DFNB91 
GJB3 
1p35–p33 
Connexin 31 
Gap Junction (ion haemostasis) 
 
 
GJB2 (Connexin 26) – DFNB1A 
 
The most frequent isolated form of genetic hearing loss in white population of Europe 
and United States is the gap junction protein beta 2 gene (GJB2) mutation that is the gene 
encoding connexin 26. Mutations in the GJB2 gene are responsible for as much as 50% of 
pre-lingual, recessive deafness. 
GJB2 gene is located on chromosome 13q11 (DFNB1) and it was described for the first 
time in 1994 but the first mutation in the locus were observed in 1997 [6].  
Connexins are a large family of protein with four transmembrane domains, which have 
been implicated in gap-junctional intercellular communication. Connexins are membrane 
proteins and core components of gap junctions (GJs), which are intercellular communication 
channels that are important for recycling potassium ions from the hair cells to the endolymph 
during auditory transduction. 

Congenital Sensorineural Hearing Loss 
 
789
These proteins are present in the cell membranes of the epithelial cells and connective 
tissue of the cochlea and are responsible for maintaining an electrical potential in the cochlea 
thanks to an exchange of neurotransmitters, metabolites and potassium ions [7]. 
Gene inheritance are autosomal recessive in most cases; however, there are been reported 
forms with a autosomal dominace pattern of inheritance [8].  
More than 300 mutations in the GJB2 gene are reported in the literatures and some of 
these are observed in various population: 35delG mutation in the Caucasian population, 
235delC in the Asian population, 167delT in the Jewish population and p.Trp24 in population 
of India, Bangladesh, Slovenia and Romania.  
Incidence varies in the different European country: it is highest in the Mediterranean 
country and lowest in the north. In fact, c.35delG allele accounted for 65.5% of mutated 
chromosomes in the south of Italy [9-11]. 
The 35delG mutation consists of a deletion of a guanine (G) in a sequence of six Gs 
extending from position 30–35 leading to a frameshift and premature stop codon at nucleotide 
38 [12, 13].  
GJB2 mutations are correlated to a neurosensorineural hearing loss of different degree 
dependent on genotype. It has been show that patients with two truncating mutations have 
significantly more severe hearing impairment than truncating/missense compound 
heterozygotes and that patients with two missense mutations have even less hearing 
impairment [14, 15]. 
 
 
GJB6 (Connexin 30) – DFNB1B 
 
In the same locus of the GJB2 mutation (DFNB1), another gene, related to congenital 
hearing loss, has been found: GJB6. 
Also this gene encoding for a gap-junction protein, connexin 30 (Cx30), that is expressed 
in the same inner-ear structures as connexion 26. In fact, both connexins are functionally 
related and Cx30 is co-expressed with Cx26 in the fibrocytes of the spiral ligament, basal 
cells of stria vascularis, spiral limbus, and supporting cells in the organ of Corti [16-18]. 
Genetic transmission is autosomal recessive and can be connected to either two GJB6 
deletions (rare) or one GJB6 deletion and one GJB2 variant on opposite chromosome [19]. 
Mutation in Connexin 30 is characterized by bilateral and stable prelingual, mild-to-
profound sensorineural hearing impairment and affected individuals have no other associated 
medical findings. 
 
 
MYO7A (Myosin VIIA) – DFNB2 
 
Myosins are a family of actin-based molecular motors that use energy from hydrolysis of 
ATP to generate mechanical force.  
The function of the unconventional myosins is to regulate intracellular membrane traffic. 
The MYO7A gene is a typical unconventional myosin consisting of 48 coding exons that 
is express in cochlea and in the retina of the mammalian. 

Sara Ghiselli, Bruno Galletti, Francesco Freni et al. 
 
790
Phenotype presentation is characterized by both vestibular dysfunction and hearing loss 
because in the inner ear, only the cochlear and vestibular sensory hair cells expressed the 
myosin VIIA gene. 
Deafness is non-syndromic, congenital, profound and it is transmitted in autosomal-
recessive manner [20]. 
 
 
MYO15A (Myosin XV) – DFNB3 
 
MYO15A is a part of myosin family. In the inner ear, it has the function of the 
transportation of different proteins. 
Mutation in this gene leads to a profound congenital hearing loss [21]. 
 
 
SLC26A4 (Pendrin) – DFNB4 
 
Mutations in the SLC26A4 gene are reported to be the most frequent cause of hereditary 
hearing loss in East Asia, and the second most common cause worldwide, after Connexin 26 
(GJB2) gene mutations.  
Mutations in the SLC26A4 gene are associated with two clinical pathway: Pendred 
syndrome or autosomal recessive non-syndromic deafness (DFNB4). Because of the variable 
expressivity and overlap of the clinical features, the two conditions may be considered as 
subsets of the spectrum of clinical manifestations of one single genetic entity. 
Both disorders have similar audiologic characteristics which may be associated with 
abnormalities of the inner ear. In Pendred syndrome besides congenital sensorineural 
deafness, goiter or thyroid dysfunctions are frequently present. 
The temporal bone abnormalities ranging from enlarged vestibular aqueduct (EVA) to 
Mondini dysplasia. To explain these abnormalities, it has been hypothesized that SLC26A4 
controls fluid homeostasis in the membranous labyrinth, which in turn affects development of 
the bony labyrinth. 
Hearing loss is common bilateral, often severe to profound degree with prelingual onset 
but, in some case deafness can arise in late childhood to early adulthood. 
SLC26A4 gene encodes a transmembrane protein, pendrin, which functions as a 
transporter of chloride and iodide. 
The human pendrin is expressed in the inner ear, mainly in endolymphatic sac and hair 
cells, and in the follicular cells of the thyroid.  
Impaired function of pendrin was associated with endolymph acidification, leading to 
auditory sensory transduction defects. It is believed that its function in normal inner ear is 
related to pH homeostasis whereas in the thyroid, have a function in electroneutral 
iodide/chloride exchanger [22, 23]. 
 
 
OTOF (Otoferlin) – DFNB9 
 
Mutations in the OTOF gene cause two disorders: nonsyndromic prelingual deafness and 
less frequently, temperature-sensitive nonsyndromic auditory neuropathy/dys-synchrony. 

Congenital Sensorineural Hearing Loss 
 
791
In auditory neuropathy auditory brain stem responses (ABRs) are absent and otoacoustic 
emissions (OAEs) are present but, however, with time OAEs disappear. 
Deafness is bilateral, prelingual onset and with severe to profound degree and without 
inner-ear anomalies. 
Otoferlin gene encoding for a transmembrane domain at the C-terminus predicted to have 
a cytoplasmic location and three Ca2þ-binding C2 domains. A function in Ca2þ-triggered 
synaptic vesicle membrane fusion was hypothesized [24]. 
 
 
CDH23 (Otocadherin) – DFNB12 
 
The CDH23 gene is a very large gene that encodes for an intercellular adhesion protein 
(Otocadherin). 
The study of Astuto et al. has been show that the DFNB12 phenotype demonstrated a 
large intra- and interfamilial variation, with hearing loss ranging from moderate to profound 
deafness and age at diagnosis between 3 months and 6 years [25]. 
 
 
USH1C (Harmonin) – DFNB18 
 
The USH1C gene encodes a PDZ domain-containing protein, harmonin detecting in the 
sensory areas of the inner ear, especially in the cytoplasm and stereocilia of hair cells. 
Mutations in this gene were described to cause congenital profound, non-syndromic, 
sensorineural deafness and severe balance deficits. 
Alteration in USH1C gene is related to Usher syndrome the most frequent cause of 
combined deaf-blindness in man [26]. 
 
 
TECTA (α-Tectorin) – DFNB21  
 
TECTA encodes α-tectorin, one of the major non-collagenous extracellular matrix 
components of the tectorial membrane that bridges the stereocilia bundles of the sensory hair 
cells. For this reasons, mutations in this gene have a dominant-negative effect that disrupts the 
structure of the tectorial membrane. 
Mutations in the TECTA gene have been shown to be responsible for both autosomal 
dominant nonsyndromic hearing impairment and autosomal recessive sensorineural pre-
lingual non-syndromic deafness [27]. 
 
 
COL11A2 (Collagen 11α2) – DFNB53 
 
COL11A2 protein encodes the collagen type XI alpha-2. Mutations in this gene cause a 
non syndromic profound hearing loss can it be non-syndromic autosomal-dominant or 
autosomal-recessive [28]. 
 

Sara Ghiselli, Bruno Galletti, Francesco Freni et al. 
 
792
Non Syndromic CHL_Autosomal Dominant Hearing Loss 
On the contrary that the autosomal-recessive forms of deafness, autosomal-dominant 
forms are usually post-lingual and progressive [29]. 
The loci and genes for non-syndromic, autosomal-dominant deafness are presented in 
Table 2. 
 
Table 2. Genes related with autosomal dominant non-syndromic  
congenital hearing loss 
 
Locus 
Gene 
Chromosomal 
Location 
Protein 
Function 
DFNA1 
DIAPH1 
5q31 
Diaphanous 1 
Actin polymerisation 
(cytoskeleton) 
DFNA2 
 
KCNQ4 
GJB3 
1p34 
KCNQ4 
Connexin 31 
Voltage-gated K+ channel 
Gap Junction (ion haemostasis) 
DFNA3 
GJB2 
GJB6 
13q12 
Connexin 26 
Connexin 30 
Gap Junction (ion haemostasis) 
DFNA4 
MYH14 
19q13 
Nonmuscle myosin heavy chian 
XIV 
Transport 
DFNA5 
DFNA5 
7p15 
 
 
DFNA6 
WFS1 
4p16.3 
wolframin 
 
DFNA7 
 
1q21-q23 
 
 
DFNA8/12 
TECTA 
11q22-q24 
A-tectorin 
Stability and structure of TM 
DFNA9 
COCH 
14q12-q13 
Cochlin 
Structures of the spiral limbus 
DFNA10 
EYA4 
6q22-q23 
Eyes absent 4 
Regulation of transcription 
DFNA11 
MYO7A 
11q12.3-q21 
Myosin VIIa 
Transport 
DFNA13 
COL11A2 
6p21 
Type XI collagen α2 
Stability and structures of TM 
DFNA14 
WFS1 
4p16.3 
wolframin 
 
DFNA15 
POU4F3 
5q31 
Class 3 POU 
Regulation of transcription 
DFNA16 
 
2q23-q24.3 
 
 
DFNA17 
MYH9 
22q12.2-q13.3 
Non muscle myosin heavy chain 
IX 
transport 
DFNA18 
 
3q22 
 
 
DFNA20/26 
ACTG1 
17q25 
γ-actin 
Building cytoskeleton 
DFNA21 
 
6p21-p22 
 
 
DFNA22 
MYO6 
6q13 
Myosin VI 
Regulation of exocytosis, 
anchoring stereocilia 
DFNA23 
 
14q21-q22 
 
 
DFNA24 
 
4q35-qter 
 
 
DFNA25 
SLC17A8 
12q21-q24 
VGLUT-3 
Regulation of exocytosis and 
endocytosis of glutamate 
DFNA28 
TFCP2L3 
8q22 
Transcription factors CP2-like 3 
Regulation of transcription 
DFNA30 
 
15q25-q26 
 
 
DFNA36 
TMC1 
9q13-q21 
 
 
DFNA38 
WFS1 
4p16 
wolframin 
 
 
 
DIAPH1 (Diaphanous) – DFNA1 
 
Expression of DIAPH1 gene was demonstrated in many tissues including cochlea and 
skeletal muscle.  

Congenital Sensorineural Hearing Loss 
 
793
The gene DIAPH1 is involved in cytokinesis and establishment of cell polarity and the 
regulation of polymerization of actin (major component of the cytoskeleton of the hair Cells) 
is related to the role in hearing impairment [30]. 
 
 
KCNQ4 – DFNA2 
 
Mutation in this gene affect potassium channels also present in the cochlea of mammalian 
provoke an alteration of the ion recycling into the endolymph at the level of the basolateral 
membrane of the outer hair cells. 
Consequently, KCNQ4 gene mutation causes a progressive hearing loss more prominent 
in high frequencies [31]. 
 
 
GJB2 (Connexin 26) – DFNA3  
 
Whereas the GJB2 gene is the major gene responsible for non-syndromic, recessive 
deafnes, there is some controversy as to the role of GJB2 in dominant deafness (DFNA3).  
Autosomal-dominant hearing loss shows a different phenotype, consisting of pre-lingual 
to late-childhood onset, mild to profound, progressive hearing loss [32]. 
Mutations in the GJB2 gene are also responsible for autosomal-dominant syndrome with 
keratoderma and sensorineural deafness (Vohwinkel syndrome) and other forms of 
autosomal-dominant palmoplantar keratoderma with deafness [33]. 
 
 
TECTA (a-Tectorin) – DFNA8/DFNA12 
 
TECTA gene encoding a non-collagenous component of the tectorial membrane in the 
inner ear (a-tectorin). Mutations of this gene disrupt the structure of the tectorial membrane, 
leading to inefficient transmission of sound to the mechanosensitive stereociliary bundles of 
the hair cells [34]. 
The hearing loss was congenital, non-progresive, moderate to severe, involved mainly the 
middle frequencies. 
 
 
EYA4 – DFNA10 
 
EYA4 is part of family transcriptional activators protein (EYA1-4) that facilitate normal 
embryonic development. Mutation in EYA1 causes BOR (Brachio-Oto-Renal) syndrome 
whereas mutation in EYA4 causes isolated hearing loss.  
Deafness is progressive, moderate to profound and bilateral [35]. 
 
 
 
 

Sara Ghiselli, Bruno Galletti, Francesco Freni et al. 
 
794
WFS1 – DFNA 6/14/38 
 
WFS1 encodes a transmembrane protein (wolframin) the function of which is currently 
unknown. 
In the most part of the cases, mutation in WFS1 is responsible for Wolfram syndrome but 
can be, also, a cause of non-syndromic low-frequency sensorineural hearing loss.  
In this non syndromic case deafness is characterized by slowly progressive, low-
frequency (<2000 Hz) sensorineural hearing loss [36]. 
 
 
SYNDROMIC CHL 
 
Syndromic CHL_Autosomal Recesive Hearing Loss 
 
Usher Syndrome 
Usher syndrome prevalence ranging from 1/6000 to 1/10000 and it represent the 3-5% of 
infant hearing loss. 
It is characterised by bilateral hearing loss and visual deficiency (until the blindness). 
There are three subtypes based on severity of the deafness, vestibular dysfunction and the 
onset of visual impairment: USH1, USH2 and USH3. 
Visual deficiency is due to retinitis pigmentosa: a gradual retinal degeneration leading to 
decreased night vision, loss of peripheral vision, and blindness. 
In USH1 subtype can be found severe to profound congenital hearing loss, congenital 
vestibular dysfunction and progressive to severe blindness (started with might blindness in 
childhood). 
 
Table 3. Genes associated with Usher syndrome subtypes 
 
Subtype 
Genes 
Protein 
Protein Function 
USH1B 
MYO7A 
Myosin VIIA 
Actin-based motor protein 
USH1C 
USH1C 
Harmonin 
scaffold protein 
USH1D 
CDH23 
Cadherin23 
Cell adhesion 
USH1F 
PCDH15 
Protocadherin 15 
Cell adhesion 
USH1G 
USH1G 
SANS 
Scaffold protein 
USH1J 
CIB2 
CIB2 
Calcium and integrin binding protein 2 
USH2A 
USH2A 
usherin 
Cell adhesion 
USH2C 
GPR98 
VLGR1 
Adhesion G protein-couple receptor VI 
USH2D 
DFNB31 
whirlin 
scaffold protein 
USH3A 
CLRN1 
Clarin1 
Auxiliary subunit of ion channels 
 
USH2 patients have moderate to severe CHL, no vestibular dysfunction and retinitis 
pigmentosa started between the age 10 to 40. 
In the USH3 subtype there are progressive hearing loss, variable vestibular dysfunction 
and retinitis pigmentosa started from the age of 20.  
The gene and loci associated with Usher syndrome is show in Table 3 [37].  
 
Pendred Syndrome 
Prevalence of Pendred syndrome is 7.5/100.000 newborns. 

Congenital Sensorineural Hearing Loss 
 
795
Pendred syndrome comprises a phenotypic spectrum of sensorineural hearing loss 
(SNHL), vestibular dysfunction and abnormal iodine metabolism.  
SNHL is usually bilateral, progressive, from mild to profound degree and can be 
congenital or with a later onset. 
Frequently there are associated temporal bone abnormalities (enlarged vestibular 
aqueduct with or without cochlear hypoplasia). 
Abnormal iodine metabolism develop euthyroid goiter sometimes detected at birth, but 
often not clinically evident until 8 years of age. Often this patient have thyroid dysfunction, 
ranging from euthyroid to hypothyroidism. 
In at least 50% of patients with Pendred syndrome, the molecular diagnosis is established 
by identification of biallelic pathogenic variants in SLC26A4 or double heterozygosity for 
one pathogenic variant in SLC26A4 and one pathogenic variant in either FOXI1 or KCNJ10 
[38, 39]. 
 
Jervell and Lange-Nielsen Syndrome 
It is estimate that prevalence of Jervell and Lange-Nielsen syndrome is 1.6 to 6 per 
1.000.000 people worldwide. 
This syndrome is characterized by severe-profound hearing loss, prolongation of the QT 
interval at basal ECG and sometimes T-waves abnormalities, and by an increased 
susceptibility to life-threatening ventricular arrhythmias. 
KCNQ1, KCNE1 are the gene associated with the syndrome and they encode potassium 
channels found in the stria vascularis of the cochlea and in the heart [40].  
 
Wolfram Syndrome 
This syndrome is characterized by diabetes mellitus, diabetes insipidus, optic atrophy and 
deafness. 
Often there are progressive neurologic abnormalities (cerebellar ataxia, peripheral 
neuropathy, dementia, psychiatric illness, and urinary tract atony), and other endocrine 
abnormalities 
Sensorineural hearing loss is slow progressive emerging in late childhood. Median age at 
death is 30 years [41]. 
 
Pompe Disease 
Pompe disease is a rare multi-systemic metabolic myopathy associated at conductive or 
sensorineural hearing loss in almost 50% of the cases. 
This syndrome is caused by autosomal recessive mutations in the acidic alpha 
glucosidase (GAA) gene [42]. 
 
 
Syndromic CHL_Autosomal Dominant Hearing Loss 
 
Waardenburg Syndrome 
Prevalence of the Waardenburg syndrome is 1/42.000 and it represents 2-5% of infant 
hearing loss. 
This syndrome is characterized by sensorineural hearing loss, abnormal pigmentation of 
the skin and hair, dystopia canthorum, heterochromia iridis and pinched nose. 

Sara Ghiselli, Bruno Galletti, Francesco Freni et al. 
 
796
There are four subtypes based on the presence or absence of the additional symptoms: 
WS1, WS2, WS3 and WS4. 
WS1 and WS2 are the most frequent and WS1 is characterized by dystopia canthorum, 
wide-set eyes. WS3 is characterized by dystopia canthorum and musculoskeletal 
abnormalities of the upper limbs whereas WS4 is associated with Hirschprung diseases. 
Gene involved in WS1 is PAX3 and MITF in WS2, these genes are involved in the 
regulation of melanocyte [43]. 
 
Brachio-Oto-Renal Syndrome 
Brachio-Oto-Renal (BOR) syndrome is characterized by sensorineural or conductive 
hearing loss, cup-shaped pinnae, preauricular pits, branchial cleft fistulae and bilateral renal 
anomalies. 
Prevalence of this disease is 1/40.000 and it is 2% of infant hearing loss [44]. 
 
Stickler Syndrome 
Stickler syndrome is characterized by progressive sensorineural hearing loss with cleft 
palate, abnormal development of the epiphysis, vertebral abnormalities and osteoarthritis; 
myopathy, retinal detachment and vitreoretinal degeneration (only in Types 1 and 3). 
The prevalence is about 7/7.500 to 1/9.000 newborns. 
There are five subtypes based on the collagene gene involved: in type I COL2A1 is 
involved, COL11A1 in Type II and COL11A2 in Type III. Types IV and V are transmitted in 
recessive autosomal manner [45]. 
 
Treacher Collins Syndrome 
Treacher Collins syndrome is characterized by microtia and malformed ears, midface 
hypoplasia, downslanting palpebral fissures, coloboma of outer 1/3 of lower eyelids, and 
micrognathia. 
TCOF1, POLR1C and POLR1D are the three genes associated to this syndrome [46]. 
 
 
Syndromic CHL_X-Linked Hearing Loss 
 
Alport Syndrome 
Alport syndrome is characterizeb by progressive sensorineural hearing loss, renal 
disorders (glomerulonephritis, haematuria (and renal failure) and ocular abnormalities. 
COL4A3, COL4A4 and COL4A5 are the three genes associated with Alport syndrome. 
All encoding for a collagen protein [47]. 
 
 
CONCLUSION 
 
A genetic diagnosis for congenital hearing loss is required for different reasons, in 
particular for choosing appropriate therapeutic options, for treating associated medical 
problem (syndromic forms) and for predicting the progression of the degree [48]. 

Congenital Sensorineural Hearing Loss 
 
797
New treatments and screening strategies are available for identifying the responsive gene, 
e.g., Next Generation DNA sequencing that allows the simultaneous analysis of a large 
number of genes causing CHL with a higher probability of gene identification. 
 
 
REFERENCES 
 
[1] 
IJA 2012; 51:512-528. 
[2] 
Keren, R., Helfand, M., Homer, C., McPhillips, H., and Lieu, T. A. (2002) Projected 
cost-effectiveness of statewide universal newborn hearing screening. Pediatrics, 110 
(5): 855–864. 
[3] 
Schulze-Gattermann, H., Illg, A., Schoenermark, M., Lenarz, T., Lesinski-Schiedat, A. 
(2002) Cost-benefit analysis of pediatric cochlear implantation: German experience. 
Otol Neurotol., Sep; 23(5):674-81. 
[4] 
Martini, A., Bovo, R., Trevisi, P., Forli, F., Berrettini, S. (2013) Cochlear implant in 
children: rational, indications and cost/efficacy. Minerva Pediatr., Jun; 65(3):325-39. 
[5] 
Mento, C., Galletti, F., Freni, F., Logo, P., Testini, G., Rizzo, A., Settineri, S. (2016) 
The role of temperament in traumatic hearing loss: a single case study of a cochlear-
implanted patient. International journal of adolescent medicine and health. 28 (1): 107-
13. 
[6] 
Guilford, P., Ben Arab, S., Blanchard, S., Levilliers, J., Weissenbach, J., Belkahia, A., 
Petit, C. (1994) A non-syndrome form of neurosensory, recessive deafness maps to the 
pericentromeric region of chromosome 13q. Nat Genet., Jan; 6 (1): 24-8. 
[7] 
Mielczarek, M., Zakrzewska, A., Olszewski, J. (2016) GJB2 sequencing in deaf and 
profound sensorineural hearing loss children. Otolaryngol Pol., Jun 30; 70(3): 21-5. 
[8] 
Kelsell, D. P., Dunlop, J., Stevens, H. P., Lench, N. J., Liang, J. N., Parry, G., Mueller, 
R. F., Leigh, I. M. (1997) Connexin 26 mutations in hereditary non-syndromic 
sensorineural deafness. Nature, May 1; 387(6628): 80-3. 
[9] 
Amorini, M., Romeo, P., Bruno, R., Galletti, F., Di Bella, C., Longo, P., Briuglia, S., 
Salpietro, C., Rigoli, L. (2015) Prevalence of Deafness-Associated Connexin-26 
(GJB2) and Connexin-30 (GJB6) Pathogenic Alleles in a Large Patient Cohort from 
Eastern Sicily. Ann Hum Genet., Sep; 79 (5): 341-349. 
[10] Martines, F., Salvago, P., Bartolotta, C., Cocuzza, S., Fabiano, C., Ferrara, S., La 
Mattina, E., Mucia, M., Sammarco, P., Sireci, F., Martines, E. (2015) A genotype–
phenotype correlation in Sicilian patients with GJB2 biallelic mutations. European 
Archives of Oto-Rhino-Laryngology, 272 (8), pp. 1857-1865. 
[11] Bartolotta, C., Salvago, P., Cocuzza, S., Fabiano, C., Sammarco, P., Martines, F. (2014) 
Identification of D179H, a novel missense GJB2 mutation in a Western Sicily family. 
European Archives of Oto-Rhino-Laryngology, 271 (6), pp. 1457-1461. 
[12] Zelante, L., Gasparini, P., Estivill, X., et al. (1997) Connexin26 mutations associated 
with the most common form of non-syndromic neurosensory autosomal recessive 
deafness (DFNB1) in Mediterraneans. Hum Mol Genet; 6: 1605–1609. 

Sara Ghiselli, Bruno Galletti, Francesco Freni et al. 
 
798
[13] Denoyelle, F., Weil, D., Maw, M. A. et al. (1997) Prelingual deafness: high prevalence 
of a 30delG mutation in the connexin 26 gene. Hum Mol Genet; 6: 2173–2177. 
[14] Snoeckx, R. L., Huygen, P. L., Feldmann, D., Marlin, S., Denoyelle, F., Waligora, J., 
Mueller-Malesinska, M., Pollak, A., Ploski, R., Murgia, A., Orzan, E., Castorina, P., 
Ambrosetti, U., Nowakowska-Szyrwinska, E., Bal, J., Wiszniewski, W., Janecke, A. R., 
Nekahm-Heis, D., Seeman, P., Bendova, O., Kenna, M. A., Frangulov, A., Rehm, H. L., 
Tekin, M., Incesulu, A., Dahl, H. H., du Sart, D., Jenkins, L., Lucas, D., Bitner-
Glindzicz, M., Avraham, K. B., Brownstein, Z., del Castillo, I., Moreno, F., Blin, N., 
Pfister, M., Sziklai, I., Toth, T., Kelley, P. M., Cohn, E. S., Van Maldergem, L., Hilbert, 
P., Roux, A. F., Mondain, M., Hoefsloot, L. H., Cremers, C. W., Löppönen, T., 
Löppönen, H., Parving, A., Gronskov, K., Schrijver, I., Roberson, J., Gualandi, F., 
Martini, A., Lina-Granade, G., Pallares-Ruiz, N., Correia, C., Fialho, G., Cryns, K., 
Hilgert, N., Van de Heyning, P., Nishimura, C. J., Smith, R. J., Van Camp, G. (2005) 
GJB2 mutations and degree of hearing loss: a multicenter study. Am J Hum Genet. Dec; 
77(6): 945-57. 
[15] Salvago, P., Martines, E., La Mattina, E., Mucia, M., Sammarco, P., Sireci, F., 
Martines, F. (2014) Distribution and phenotype of GJB2 mutations in 102 Sicilian 
patients with congenital non syndromic sensorineural hearing loss. International 
Journal of Audiology, 53 (8), pp. 558-563. 
[16] Del Castillo, I., Villamar, M., Moreno-Pelayo, M. A., del Castillo, F. J., Alvarez, A., 
Tellería, D., Menéndez, I., Moreno, F. A. (2002) Deletion involving the connexin 30 
gene in nonsyndromic hearing impairment. N Engl J Med. Jan 24; 346 (4): 243-9. 
[17] J. Sun, S. Ahmad, S. Chen, W. Tang, Y. Zhang, P. Chen, X. Lin. (2005) Cochlear gap 
junctions coassembled from Cx26 and 30 show faster intercellular Ca2+ signaling than 
homomeric counterparts, Am. J. Physiol. Cell Physiol.; 288: C613–C623. 
[18] Oh, S. K., Choi, S. Y., Yu, S. H., Lee, K. Y., Hong, J. H., Hur, S. W., Kim, S. J., Jeon, 
C. J., Kim, U. K. (2013) Valuation of the pathogenicity of GJB3 and GJB6 variants 
associated with nonsyndromic hearing loss. Biochim Biophys Acta. Jan; 1832 (1): 285-
91. 
[19] Petersen, M. B., Willems, P. (2006) Non-syndromic, autosomal-recessive deafness. J 
Clin Genet. May; 69 (5): 371-92. 
[20] Weil, D., Lévy, G., Sahly, I., Lévi-Acobas, F., Blanchard, S., El-Amraoui, A., Crozet, 
F., Philippe, H., Abitbol, M., Petit, C. (1996) Human myosin VIIA responsible for the 
Usher 1B syndrome: a predicted membrane-associated motor protein expressed in 
developing sensory epithelia. Proc Natl Acad Sci USA; 93: 3232–3237. 
[21] Robertson, N. G., Lu, L., Heller, S., Merchant, S. N., Eavey, R. D., McKenna, M., 
Nadol, J. B. Jr, Miyamoto, R. T., Linthicum, F. H. Jr, Lubianca Neto, J. F., Hudspeth, 
A. J., Seidman, C. E., Morton, C. C., Seidman, J. G. (1998) Mutations in a novel 
cochlear gene cause DFNA9, a human nonsyndromic deafness with vestibular 
dysfunction. Nat Genet. Nov; 20 (3): 299-303. 

Congenital Sensorineural Hearing Loss 
 
799
[22] Everett, L. A., Morsli, H., Wu, D. K., Green, E. D. (1999) Expression pattern of the 
mouse ortholog of the Pendred’s syndrome gene (Pds) suggests a key role for pendrin 
in the inner ear. Proc Natl Acad Sci USA. 96: 9727–9732. 
[23] Wémeau, J. L., Kopp, P. (2017) Pendred syndrome. Best Pract Res Clin Endocrinol 
Metab. Mar; 31 (2): 213-224. 
[24] Yasunaga, S., Grati, M., Cohen-Salmon, M., El-Amraoui, A., Mustapha, M., Salem, N., 
El-Zir, E., Loiselet, J., Petit, C. (1999) A mutation in OTOF, encoding otoferlin, a FER-
1-like protein, causes DFNB9, a nonsyndromic form of deafness. Nat Genet; 21: 363–
369. 
[25] Astuto, L. M., Bork, J. M., Weston, M. D., Askew, J. W., Fields, R. R., Orten, D. J., 
Ohliger, S. J., Riazuddin, S., Morell, R. J., Khan, S., Riazuddin, S., Kremer, H., Van 
Hauwe, P., Moller, C. G., Cremers, C. W. R. J., Ayuso, C., Heckenlively, J. R., 
Rohrschneider, K., Spandau, U., Greenberg, J., Ramesar, R., Reardon, W., Bitoun, P., 
Millan, J., Legge, R., Friedman, T. B., Kimberling, W. J. (2002) CDH23 mutation and 
phenotype heterogeneity: a profile of 107 diverse families with Usher syndrome and 
nonsyndromic deafness. Am J Hum Genet; 71: 262–275. 
[26] Reiners, J., van Wijk, E., Märker, T., Zimmermann, U., Jürgens, K., te Brinke, H., 
Overlack, N., Roepman, R., Knipper, M., Kremer, H., Wolfrum, U. (2005) Scaffold 
protein harmonin (USH1C) provides molecular links between Usher syndrome type 1 
and type 2. Hum Mol Genet. Dec 15; 14 (24): 3933-43. 
[27] Legan, P. K., Lukashkina, V. A., Goodyear, R. J., Kössl, M., Russell, I. J., Richardson, 
G. P. (2000) A targeted deletion in alpha-tectorin reveals that the tectorial membrane is 
required for the gain and timing of cochlear feedback. Neuron; 28: 273–285. 
[28] Chen, W., Kahrizi, K., Meyer, N. C., Riazalhosseini, Y., Van Camp, G., Najmabadi, H., 
Smith, R. J. (2005) Mutation of COL11A2 causes autosomal recessive non-syndromic 
hearing loss at the DFNB53 locus. J Med Genet; 42: e61. 
[29] Petersen, M. B. (2002) Non-syndromic autosomal-dominant deafness. Clin Genet; 62: 
1–13 
[30] Lynch, E. D., Lee, M. K., Morrow, J. E., Welcsh, P. L., León, P. E., King, M. C. (1997) 
Nonsyndromic deafness DFNA1 associated with mutation of a human homolog of the 
drosophila gene diaphanous. Science; 278: 1315–1318. 
[31] Kubisch, C., Schroeder, B. C., Friedrich, T., Lütjohann, B., El-Amraoui, A., Marlin, S., 
Petit, C., Jentsch, T .J. (1999) KCNQ4, a novel potassium channel expressed in sensory 
outer hair cells, is mutated in dominant deafness. Cell; 96: 437–446. 
[32] Chaib, H., Lina-Granade, G., Guilford, P., Plauchu, H., Levilliers, J., Morgon, A., Petit, 
C. (1994) A gene responsible for a dominant form of neurosensory nonsyndromic 
deafness maps to the NSRD1 recessive deafness gene interval. Hum Mol Genet. 3: 
2219–2222. 
[33] Kelsell, DPW-L., Houseman, M. J. (2001) Connexin mutations in skin disease and 
hearing loss. Am J Hum Genet; 68: 559–568. 

Sara Ghiselli, Bruno Galletti, Francesco Freni et al. 
 
800
[34] Verhoeven, K., Van Laer, L., Kirschhofer, K., et al., (1998) Mutations in the human a-
tectorin gene cause autosomal dominant non-syndromic hearing impairment. Nat 
Genet; 19: 60–62. 
[35] Hildebrand, M. S., Coman, D., Yang, T., Gardner, R. J., Rose, E., Smith, R. J., Bahlo, 
M., Dahl, H. H. (2007) A novel splice site mutation in EYA4 causes DFNA10 hearing 
loss. Am J Med Genet A. Jul 15; 143A(14): 1599-604. 
[36] Young, T. L., Ives, E., Lynch, E., Person, R., Snook, S., MacLaren, L., Cater, T., 
Griffin, A., Fernandez, B., Lee, M. K., King, M. C. (2001) Non-syndromic progressive 
hearing loss DFNA38 is caused by heterozygous missense mutation in the Wolfram 
syndrome gene WFS1. Hum Mol Genet; 10: 2509–2514. 
[37] Mathur, P., Yang, J. (2015) Usher syndrome: Hearing loss, retinal degeneration and 
associated abnormalities. Biochim Biophys Acta. Mar; 1852 (3): 406-20. 
[38] Reardon, W., Trembath, R. C. (1996) Pendred syndrome. J Med Genet. Dec; 33 
(12):1037-40. 
[39] Bruno, R., Aversa, T., Catena, M., Valenzise, M., Lombardo, F., De Luca, F., 
Wasniewska, M. (2015) Even in the era of congenital hypothyroidism screening mild 
and subclinical sensorineural hearing loss remains a relatively common complication of 
severe congenital hypothyroidism. Hearing Research September; 327: 43-47. 
[40] Martini, A., Volo, T., Ghiselli, S. (2011) Heart problems and deafness: Are they more 
common than supposed? Audiological Medicine; 9 (1): 1-3. 
[41] Karzon, R., Narayanan, A., Chen, L., Lieu, J. E. C., Hershey, T. (2018) Longitudinal 
hearing loss in Wolfram syndrome. Orphanet J Rare Dis. Jun;13(1):102. 
[42] Musumeci, O., Catalano, N., Barca, E., Ravaglia, S., Fiumara, A., Gangemi, G., 
Rodolico, C., Sorge, G., Vita, G., Galletti, F., Toscano, A. (2012) Auditory system 
involvement in late onset Pompe disease: A study of 20 Italian patients. Molecular 
Genetics and Metabolism; 107 (3): 480-484. 
[43] Read, A. P., Newton, V. E. (1997) Waardenburg syndrome. J Med Gen; 34: 656-655. 
[44] Smith, R. J. H. (1993) Branchiootorenal Spectrum Disorders. In: Pagon, R. A.; Adam, 
M. P.; Ardinger, H. H., et al., editors. Gene Reviews (R). Seattle (WA). 
[45] Rose, P. S., Levy, H. P., Liberfarb, R. M., Davis, J., Szymko-Bennett, Y., Rubin, B. I., 
Tsilou, E., Griffith, A. J., Francomano, C. A. (2005) Stickler syndrome: clinical 
characteristics and diagnostic criteria. Am J Med Genet A.; 138A:199–207. 
[46] Kadakia, S., Helman, S. N., Badhey, A. K., Saman, M., Ducic, Y. (2014) Treacher 
Collins Syndrome: the genetics of a craniofacial disease. Int J Pediatr 
Otorhinolaryngol.; 78: 893–898. 
[47] Koffler, T, Ushakov, K., Avraham, K. B. (2015) Genetics of Hearing Loss – 
Syndromic. Otolaryngol Clin North Am.; 48 (6): 1041–1061. 
[48] Martines, F., Maira, E., Ferrara, S. (2011) Age-related hearing impairment (ARHI): A 
common sensory deficit in the elderly. Acta Medica Mediterranea, 27 (1), 47-52. 

In: Encyclopedia of Audiology and Hearing Research 
ISBN: 978-1-53617-702-2 
Editors: Erno Larivaara and Senja Korhola 
© 2020 Nova Science Publishers, Inc. 
 
 
 
 
 
 
 
Chapter 56 
 
 
 
NEUROPLASTICITY AND SENSORINEURAL  
HEARING LOSS 
 
 
Francesco Dispenza1, 2,, MD, PhD, Alessia Maria Battaglia2, MD, 
Gabriele Ebbreo2, MD, Alessia Ceraso2, MD, Vito Pontillo3, MD  
and Antonina Mistretta2, MD 
1Istituto Euromediterraneo di Scienza e Tecnologia – IEMEST, Palermo, Italy 
2U. O. C. Otorinolaringoiatria Azienda Ospedaliera  
Universitaria Policlinico P. Giaccone, Palermo, Italy 
3Otolayngology Unit, Department of Basic Medical Science,  
Neuroscience and Sensory Organs, University of Bari Aldo Moro, Bari, Italy 
 
 
ABSTRACT 
 
Neuroplasticity is the ability of central nervous system to modify his own functions 
based on changes of external or internal factors, and it's the basis for numerous 
physiologic and pathologic events in otology. Sensorineural hearing loss implies a 
cochlear deficit but also modifications from acoustic tract up to auditory cortex. It 
determines morphofunctional changes, through neuroplasticity, that may be influenced by 
cochlear implants and hearing aids. There are many trials that shown a remarkable 
hearing development in deaf infant after cochlear implant or usage of hearing aids. 
However, many questions remain around the right time to act, due to the greatest 
neuronal response in younger children. Animal experimentation has shown also tonotopic 
changes in cortical and subcortical areas after cochlear lesions, that depends upon age and 
damage extension, as neuronal reorganization differ from neonatal and adults. In this 
chapter we'll discuss about central neuronal network modifications, after sensorineural 
hearing loss, emphasizing clinical consequences, in particular the usefulness of early 
diagnosis and rapid treatment. 
 
Keywords: neural plasticity, hearing loss, deafness, neuroplasticity, brain 
 
                                                        
 Corresponding Author’s Email: francesco.dispenza@gmail.com. 

Francesco Dispenza, Alessia Maria Battaglia, Gabriele Ebbreo et al. 
 
802
INTRODUCTION TO NEUROPLASTICITY 
 
Since Rita Levi Montalcini’s studies on anatomic changes to auditory pathways after 
experimental lesions of chick embryo, neuroplasticity has been widely recognized, and with 
that neuronal capacity to change itself in reaction to stimuli and lesions (Levi-Montalcini 
1949). Mechanisms of neural plasticity have been the focus of interest in research for many 
decades. Plasticity is based in part on changes in synaptic function (synaptic plasticity), on 
change in synchronization in the neuronal networks, and on change in inter-neuronal 
connection patterns within neuronal networks (Thomas et al., 2018, Martines et al., 2015). 
This may be associated on synaptic strengthening as postulated by Hebb’s studies. 
Exactly as he said “When an axon of cell A is near enough to excite a cell B and repeatedly or 
persistently takes part in firing it, some growth process or metabolic change takes place in one 
or both cells such that A’s efficiency, as one of the cells firing B, is increased. The synaptic 
strengthen works through changes in pre-synaptic and postsynaptic areas. It could work on 
augmented release probability of neurotransmitters, incremented number of release sites or 
vesicles n the pre-synaptic neuron, while on receptor sensitivity and quantity of elicitable 
receptors in the post-synaptic neuron (Wang, Ko, and Kelly 1997). 
This phenomenon may also explain the way of Central Nervous System (CNS) 
development, through the repeated stimulation of genetically determined neural pathway that 
leads improvement and development of some functions. A neuron is linked to many different 
other neurons but is activated just by some. 
Neuroplasticity may explain the phantom limb’s etiology or in auditory area, tinnitus’s 
etiology. Certain types of tinnitus could arise from auditory neurons that somehow develop 
self-perpetuating activity. With our understanding that the brain is full of networks it is easy 
to conceive of local circuits being reinforced to the point of reverberation that in the auditory 
cortex may determine tinnitus (Eggermont 2012). Also the vestibular compensation after an 
issue involving one of the vestibular organs should be related to the neural plasticity (Lorusso 
et al., 2017, Dispenza et al., 2015, Dispenza, Kulamarva, and De Stefano 2012, Dispenza and 
De Stefano 2012, Dispenza et al., 2011). 
Neuroplasticity is heavily studied on its variability during lifespan. The capacity for 
reorganization of the brain is more extensive during development. Especially in neonatal age 
comes a gargantuan synaptogenesis that last until the five years of age, followed by a 
dendritic pruning. Therefore comes the children ability to learn and grow at wonderful speed. 
An explanation may be that, in developing animals, due to immaturity of neuronal 
membranes and ionic channels, cortical postsynaptic potentials are known to have a longer 
duration. This has the effect of naturally boosting synaptic plasticity, as individual 
postsynaptic potentials can more easily temporally overlap. Temporal summation can by that 
cause a strong depolarization of postsynaptic cells. The eventual consequence of this effect is 
higher plasticity during early development. This phenomenon has a clinical effect, since most 
aspects of learning and intellectual functions may be acquired only in earlier age. 
 
 
NEUROPLASTICITY IN THE AUDITORY SYSTEM 
 
The neuroplasticity of the auditory system was object of study of expert otologists all 
over the world, in order to understand the mechanism and the relationship with different area 

Neuroplasticity and Sensorineural Hearing Loss 
 
803
of CNS (Dispenza et al., 2011, De Stefano et al., 2011, De Stefano, Kulamarva, and Dispenza 
2012).  
It has been shown that a pre-lingual sensorineural hearing loss may cause cognitive and 
relational developmental deficits; while in adults the development of an auditory deficit is 
associated with dementia and decreased attention (Contrera et al., 2017, Salvago et al., 2017). 
Alterations of cerebral white and gray matter have been reported in patients with hearing loss 
(Yang et al., 2014). Focal deficits of the white matter of the superior temporal gyrus for deaf 
children in prelingual age and volumetric decreases in gray matter in areas adjacent to the 
auditory cortex in individuals with bilateral hearing loss were demonstrated (Husain et al., 
2011). Yang compared T1 weighted sequences and task free fMRIs of 14 adult patients with 
hearing impairments of moderate severity and 19 controls: Voxel based morphometry (VBM) 
showed decreased gray matter volume in bilateral posterior cingulate, lingual and the 
amplitude of low frequency fluctuation, calculated to analyze brain activity, was decreased in 
bilateral precuneus, left inferior parietal lobule, right inferior frontal gyrus and insula, and 
increased in right inferior and middle temporal gyrus (Figure 1) (Yang et al., 2014).  
Boyen also applied VBM analyses to MRIs of normal-hearing control subjects, hearing-
impaired subjects without tinnitus and hearing-impaired subjects with tinnitus. The two 
hearing impaired groups had well matched audiograms for frequencies of 8 kHz. VBM 
analyses revealed that both hearing impaired groups, compared to healthy controls, had GM 
volume increased in the superior and middle temporal gyrus and limbic areas and decreased 
in the superior frontal gyrus, frontal areas, occipital lobe and hypothalamus (Boyen et al., 
2013).  
Increased amplitude of low frequency fluctuation may determine a neuroplastic change in 
response to hearing loss. Many reviews showed that hearing loss brain adapt through 
unimodal and cross-modal plasticity (Kral 2007). 
 
 
Figure 1. Brain areas with decreased gray matter. Modified from: Yang et al., Hearing Research 316 
(2014) 37-43. 
 

Francesco Dispenza, Alessia Maria Battaglia, Gabriele Ebbreo et al. 
 
804
UNIMODAL PLASTICITY 
 
Unimodal plasticity is the capacity of changing the neuronal pathway inside a single area; 
in the auditory area it mostly deal with tonotopic modifications and relations between primary 
auditory cortex and higher order cortex. It’s a good idea to propose Merzenich studies on deaf 
cats.  
An experiment studied cats treated shortly after birth with the ototoxic aminoglycoside 
amikacin, which resulted in a basal cochlear hair cells lesion. Though ABR evaluations it was 
assessed that the stimuli for low frequency sounds could still be transmitted, but it was gone 
for high frequency sound. Over time, auditory cortex showed normal representation of low 
frequencies, but the cortical region deprived of normal input by the partial cochlear deaf-
ferentation now contains neurons that are all tuned to 6 to 8 kHz. Thus there was an 
abnormally overrepresentation of the still captable frequency in the auditory cortex. Also, one 
of these subjects however showed an injury both on basal and apical cochlea. This kitten also 
developed a cortical frequency map in which there was a very large iso-frequency area where 
all neurons have a common 6.6-kHz frequency tuning (Kaas, Merzenich, and Killackey 
1983). 
Qualitatively, similar results are also found at the cortical level if the lesions are made in 
an adult animal, as showed by Robertson and Irvine studies and many others. At the level of 
the auditory cortex, after cochlear lesions were induced in the adult animal, the pattern of 
reorganization of tonotopic maps was similar to that of the developing neonate (Rajan and 
Irvine 1998). However, intuitively, considerable differences should be expected in the extent 
of the cortical tonotopic map reorganization in subjects with lesions made in early 
development compared with those made in adulthood since the importance of early sensory 
stimulation in driving the development of the mature brain has already been discussed. In 
fact, if we study the subcortical reorganization in adult and developmental animals many 
differences may be exposed.  
It was showed that determining a cochlear lesion in a developmental animals lead to 
subcortical modifications along the auditory brain steam, with a tonotopic map 
reorganization, at inferiors colliculi and thalamo particularly, in large part reflecting what 
occurs at cortical level. Such subcortical reorganization apparently does not occur for similar 
lesions made in the adult. The age of induction of hearing loss, neonatal, childhood or adult 
does not appear to affect the outcome; increased spontaneous ring rates, increased neural 
synchrony and reorganization of the cortical tonotopic map (Harrison 2001). 
Therefore neonatal induced hearing loss also results in reorganization of the tonotopic 
map in the inferior colliculus, which does not occur after adult acquired hearing loss 
(Eggermont 2017). 
Dealing with neural pathway modifications between higher order auditory cortex and 
primary auditory cortex, we should remember that higher order auditory cortex maturity come 
necessarily from long term hearing experience, especially in developmental subject. We can 
expose Sharma’s studies on prelingual deaf children. It showed in early implanted deaf 
childern an increasing amplitude and decreasing latency of wave P1 and an appearance of 
wave N1 with cochlear implant stimulation, whereas late-implanted children, especially those 
implanted in late teens, do not develop wave N1. Since N1 wave is generated in the higher 
order cortex we can assume that without auditory stimuli in early age, those areas doesn’t 

Neuroplasticity and Sensorineural Hearing Loss 
 
805
develop and become significantly compromised (Sharma et al., 2002). Also, higher order 
cortex tends to reorganize cross-modally, leading to interaction with visual, and possibly 
others areas, in an attempt to compensate through visual and other stimuli to the auditory 
deficit. 
 
 
CROSS-MODAL PLASTICITY 
 
Cross modal plasticity works with connections between different areas. In Bertrand and 
Sharma studies, it was proved an higher order auditory cortex activation in response to a 
radial modulated visual grating stimulus giving the effect of apparent motion, in prelingual 
deaf children with cochlear implants, using CVEP. While normally hearing children show 
cortical activation of areas tipically associated with visual procession, while the CI children 
demonstrated additional activation of right lateral temporal cortex for the higher order N1 and 
P2 CVEP components (e.g., right inferior, middle, and superior temporal gyrus). 
Furthermore, speech perception performance in background noise using a clinical test (BKB 
SIN) was significantly negatively correlated with CVEP latency for CI children, such that 
poorer speech perception was associated with earlier CVEP N1 latency However, it appears 
that auditory reactivity is maintained despite cross-modal re-organization by vision (Bertrand 
et al., 2012). 
Sandamn showed that even in adult crossmodal plasticity happens as well, since its 
studies showed an increased activation in the auditory cortex during CVEP, in both 
prelingually and postlingually deaf adults compared to the normal hearing group. Also 
increased CVEP amplitude over temporal cortex is associated with poor speech perception in 
quiet and noise environment (Chen et al., 2016). 
Currently it is not well defined how long it takes to develop cross-modal plasticity in 
adults. A case report study showed a visual activaction of auditory cortex at least three 
months after sudden hearing loss, which increased over time, up to increasing its efficiency 
up to one year. Interestingly, there was a positive association between N1 amplitude at CVEP 
and speech perception. These findings are from a single case study and they should be 
interpreted cautiously (Glick and Sharma 2017). 
Another area related to higher order cortex of deaf patients in cross modal plasticity it’s 
the post-central gyrus of somatosensory cortex. As in, numerous studies showed a 
simultaneous activation of both somatosensory and auditory area cortical during cortical 
somatosensory evoked potentials (CSSEP) and, when treated with cochlear implants, even in 
cortical auditory evoked potentials (CAEP) In this case, findings of cross modal plasticity are 
related to poor speech perception performance as well (Cardon and Sharma 2018). 
Even if visual cortex may be recruited by higher order auditory cortex, to evolve speech 
and communication by other mean than auditory input in hearing loss, many doubts remain 
over usefulness of somatosensory recruitment and many authors suggest this may happen, 
instead of a functional modification, due to close proximity of somatosensory and auditory 
cortices and the overlapping of somatosensory and auditory neurons subcortically, as a result 
of hearing impairment (Glick and Sharma 2017).  
Cross modal plasticity take part also in relations to contralateral auditory cortex as in 
Khosla et al., study, especially in unilateral hearing loss (Khosla et al., 2003). 

Francesco Dispenza, Alessia Maria Battaglia, Gabriele Ebbreo et al. 
 
806
Normal-hearing subjects show significant latency and amplitude differences between 
ipsilateral and contralateral peaks for all components of the CAEP, with contralateral source 
activities that were typically larger and peaked earlier than the ipsilateral activities. However, 
in unilateral hearing loss, the patients showed a reduction of both amplitude and latency 
differences, when the best hearing ear was stimulated. Thus, unilateral hearing loss leads to a 
more synchronous and symmetrical activation of the auditory cortex (Eggermont 2017). 
All this studies showed the higher order auditory cortex is the main protagonist of cross-
modal plasticity as it’s the one to get in relation both with visual and somatosensory auditory 
cortex, but also with frontal area and controlateral auditory area. It takes parts in language 
development and speech perception, it’s heavely binded to the auditory input in normal 
people, even if it’s relation with the visual and other area it’s already proved by McGurk 
effect. However in absence of hearing experiece, the representation between higher order 
cortex and primary order cortex remain to a rudimentary level, and the higher order cortex 
due to their strong inputs also from nonauditory areas, take-over new functions and undergo 
crossmodal reorganization. 
 
 
NEUROPLASTICITY AND COCHLEAR IMPLANTS 
 
Cochlear implants are surgically implanted hearing aids used on patients with severe to 
profound sensorineural hearing loss in both ears to provides a sense of sound. In cochlear 
implants, cochlear transduction pass through a microphone then comes the spectral analysis 
through a bank of bandpass filters within a speech processor. At the very end, the output of 
each bandpass filter is directed to one for up 24 intra-cochlear electrodes positioned to 
stimulate auditory nerve fibers at tonotopically appropriate position along the cochlear spiral.  
Electrical stimulation of the auditory nerve by cochlear implants evokes a pattern of 
activity, which differs from that evoked by acoustical stimulation in the normal ear. The 
spread of activation in the auditory nerve is much larger with electrical stimulation than with 
acoustical stimulation (Middlebrooks, Bierer, and Snyder 2005). Even the most focused 
stimulation strategies, as with the tripolar electrode configuration (Kral et al., 2002), do not 
come close to the acoustical stimulation and, in addition, are not favorable in cases of patchy 
degeneration of the auditory nerve. Moreover, randomness in the temporal firing pattern with 
electrical stimulation is much less than it is in the normally activated auditory nerve partially 
due to the loss of spontaneous activity in “deaf” auditory nerve fibers. Electrical stimulation 
at a high rate such as used in modern cochlear implants might induce a slight increase in 
randomness of the firing patterns because of refractory periods and sub-threshold electrical 
stimulation. Last but not last, simultaneous activation of several electrodes can lead to 
unwanted current flows between the active electrodes. Therefore, interleaved stimulation is 
used, which further biases the temporal excitation pattern when compared to natural acoustic-
evoked activity. 
Thus, after cochlear implantation, most of the representations of sounds in the nervous 
system have to be rebuilt to fit the characteristics of the new coding of auditory input. 
Without auditory brainstem lesions, the outcome of cochlear implantation depends 
heavily on central factors, that is, its functional status and its plasticity (Kral and Tillein 
2006). 

Neuroplasticity and Sensorineural Hearing Loss 
 
807
 
Figure 2. Cortical tonotopic maps that developed in two cats with neonatal basal cochlear lesions. 
Kittens were treated with the ototoxic aminoglycoside amikacin to produce basal lesions to the cochlea, 
the effects of which are reflected in the auditory brainstem response (ABR)–derived audiograms 
(upper panels). A, In this subject, the cochlear lesion was confined to the basal region. B, In this 
subject, hair cell damage was maximal at the cochlear base, but scattered hair cell loss extended up to 
apical regions. Shading indicates regions in which all neurons have similar tuning properties. AEF, 
anterior ectosylvian fissure; PEF, posterior ectosylvian fissure; SF, sylvian fissure (Modified from: 
Cumming’s Otolaryngology, Head and Neck Surgery, sixth edition, chapter 132 “Neural Plasticity in  
Otology: 2042). 
Many speculations were born about effects of cross modal plasticity in hearing recovery. 
Lee’s studies have shown that delayed hearing-aided subjects presented the signs of cross-
modal plasticity, and were less responsive to cochlear implant with greater difficulty in 
learning language and speech; the subjects who received an early prosthesis were often free of 
signs of cross-modal plasticity and respondent better. 
These studies, however, had the defect of referring to the difference in timing of 
prosthesis, for which an ulterior study was performed on adult subjects suffering from post-
lingual deafness and it was highlighted how the subjects with activation of the auditory cortex 
at CVER responded poorly to the hearing aids (Lee et al., 2001). Therefore it is possible to 
speculate that signs of cross modal plasticity can be exploited to evaluate the expectation of 
response to the cochlear implant. However, another study plasticity showed that cochlear 
implantation progressively regressed to a response only of the visual cortex in response to 
VCER. 
 
 

Francesco Dispenza, Alessia Maria Battaglia, Gabriele Ebbreo et al. 
 
808
 
Figure 3. Schematic sketch illustrating cortical reorganization patterns resulting from sensory 
deprivation and hearing restorationwith a CI. “Cortical reorganization in postlingually deaf cochlear 
implant users: intra-modal and cross-modal considerations.” Modified from: Stropahl et al., Hearing 
Research, Elsevier, 343(2017): 128-137. 
Therefore, the concept remains that cross-modal plasticity is an adaptive response to 
deafness, which acts by potentiating the functioning sensory cortex areas and of the frontal 
cortex for TOP-BOTTOM response mechanisms to compensate for the auditory deficit. It is 
possible that in some subjects this phenomenon happens so well that even after prosthetics 
there is no recovery of the normal function of the auditory cortex, while, paradoxically, those 
who do not effectively highlight spoken language. The results discussed above have relevance 
for decisions regarding cochlear implants in congenitally deaf children (Kral and Tillein 
2006). One question that has often been asked is whether the caretakers of children with 
cochlear implants should keep signing with these children, or if this would be 
counterproductive for learning and maintaining a language through spoken words using the 
cochlear implant? Arguments for both alternatives have been made. Signs accompanying 
spoken language might facilitate learning by appropriately activating the semantic auditory 
system with the associative language networks already established in the brain. On the other 
hand, signing might prevent the reassignment of high order auditory cortex to the auditory 
modality, and thus it may counterproductive in learning spoken language. 
 
 
CONCLUSION 
 
In this chapter we have evidenced how neuroplasticity plays a very important role in the 
regulation of cortical neuronal networks in response to inputs of various kinds, and in 

Neuroplasticity and Sensorineural Hearing Loss 
 
809
different age. In the case of deafness in the prelingual period, an early prosthetic implant 
allows the development of normal and physiological neuronal networks at the level of 
primary auditory cortex and higher order, as well as between areas, and promotes the 
stimulation that the central nervous system needs for development. Otherwise, in working 
between the different areas, in attempt to compensate for function, this can lead to a 
disadvantage in normal recovery after hearing aids. 
 
 
REFERENCES 
 
Bertrand, J. A., M. Lassonde, M. Robert, D. K. Nguyen, A. Bertone, M. E. Doucet, A. 
Bouthillier, and F. Lepore. 2012. “An intracranial event-related potential study on 
transformational apparent motion. Does its neural processing differ from real motion?” 
Exp Brain Res 216 (1):145-53. doi: 10.1007/s00221-011-2920-8. 
Boyen, K., D. R. Langers, E. de Kleine, and P. van Dijk. 2013. “Gray matter in the brain: 
differences associated with tinnitus and hearing loss.” Hear Res 295:67-78. doi: 
10.1016/j.heares.2012.02.010. 
Cardon, G., and A. Sharma. 2018. “Somatosensory Cross-Modal Reorganization in Adults 
With Age-Related, Early-Stage Hearing Loss.” Front Hum Neurosci 12:172. doi: 
10.3389/fnhum.2018.00172. 
Chen, L. C., P. Sandmann, J. D. Thorne, M. G. Bleichner, and S. Debener. 2016. “Cross-
Modal Functional Reorganization of Visual and Auditory Cortex in Adult Cochlear 
Implant 
Users 
Identified 
with 
fNIRS.” 
Neural 
Plast 
2016:4382656. 
doi: 
10.1155/2016/4382656. 
Contrera, K. J., J. Betz, J. Deal, J. S. Choi, H. N. Ayonayon, T. Harris, E. Helzner, K. R. 
Martin, K. Mehta, S. Pratt, S. M. Rubin, S. Satterfield, K. Yaffe, E. M. Simonsick, and F. 
R. Lin. 2017. “Association of Hearing Impairment and Anxiety in Older Adults.” J Aging 
Health 29 (1):172-184. doi: 10.1177/0898264316634571. 
De Stefano, A., F. Dispenza, L. Citraro, A. G. Petrucci, P. Di Giovanni, G. Kulamarva, N. 
Mathur, and A. Croce. 2011. “Are postural restrictions necessary for management of 
posterior canal benign paroxysmal positional vertigo?” Ann Otol Rhinol Laryngol 120 
(7):460-4. 
De Stefano, A., G. Kulamarva, and F. Dispenza. 2012. “Malignant paroxysmal positional 
vertigo.” Auris Nasus Larynx 39:378-382. 
Dispenza, F, and A De Stefano. 2012. “Vertigo in childhood: a methodological approach.” 
Bratisl Med J 113:256-259. 
Dispenza, F, A De Stefano, C Costantino, D Rando, M Giglione, R Stagno, and E Bennici. 
2015. “Canal switch and re-entry phenomenon in benign paroxysmal positional vertigo: 
difference between immediate and delayed occurrence.” Acta Otolaryngol Ital 35:116-
120. 
Dispenza, F, G Kulamarva, and A De Stefano. 2012. “Comparison of repositioning 
maneuvers for benign paroxysmal positional vertigo of posterior semicircular canal: 
advantages of hybrid maneuver.” Am J Otolaryngol 33:528-532. 

Francesco Dispenza, Alessia Maria Battaglia, Gabriele Ebbreo et al. 
 
810
Dispenza, F., R. Gargano, N. Mathur, C. Saraniti, and S. Gallina. 2011. “Analysis of visually 
guided eye movements in subjects after whiplash injury.” Auris Nasus Larynx 38:185-
189. 
Eggermont, J J. 2012. The Neuroscience of Tinnitus: Oxford University Press. 
Eggermont, J. J. 2017. “Acquired hearing loss and brain plasticity.” Hear Res 343:176-190. 
doi: 10.1016/j.heares.2016.05.008. 
Glick, H., and A. Sharma. 2017. “Cross-modal plasticity in developmental and age-related 
hearing 
loss: 
Clinical 
implications.” 
Hear 
Res 
343:191-201. 
doi: 
10.1016/j.heares.2016.08.012. 
Harrison, R. V. 2001. “Age-related tonotopic map plasticity in the central auditory 
pathways.” Scand Audiol Suppl (53):8-14. 
Husain, F. T., R. E. Medina, C. W. Davis, Y. Szymko-Bennett, K. Simonyan, N. M. Pajor, 
and B. Horwitz. 2011. “Neuroanatomical changes due to hearing loss and chronic 
tinnitus: a combined VBM and DTI study.” Brain Res 1369:74-88. doi: 
10.1016/j.brainres.2010.10.095. 
Kaas, J. H., M. M. Merzenich, and H. P. Killackey. 1983. “The reorganization of 
somatosensory cortex following peripheral nerve damage in adult and developing 
mammals.” Annu Rev Neurosci 6:325-56. doi: 10.1146/annurev.ne.06.030183. 
001545. 
Khosla, D., C. W. Ponton, J. J. Eggermont, B. Kwong, M. Don, and J. P. Vasama. 2003. 
“Differential ear effects of profound unilateral deafness on the adult human central 
auditory system.” J Assoc Res Otolaryngol 4 (2):235-49. doi: 10.1007/s10162-002-3014-
x. 
Kral, A. 2007. “Unimodal and cross-modal plasticity in the ‘deaf’ auditory cortex.” Int J 
Audiol 46 (9):479-93. doi: 10.1080/14992020701383027. 
Kral, A., R. Hartmann, J. Tillein, S. Heid, and R. Klinke. 2002. “Hearing after congenital 
deafness: central auditory plasticity and sensory deprivation.” Cereb Cortex 12 (8):797-
807. 
Kral, A., and J. Tillein. 2006. “Brain plasticity under cochlear implant stimulation.” Adv 
Otorhinolaryngol 64:89-108. doi: 10.1159/000094647. 
Lee, D. S., J. S. Lee, S. H. Oh, S. K. Kim, J. W. Kim, J. K. Chung, M. C. Lee, and C. S. Kim. 
2001. “Cross-modal plasticity and cochlear implants.” Nature 409 (6817):149-50. doi: 
10.1038/35051653. 
Levi-Montalcini, R. 1949. “Development of the acoustico-vestibular centers in the chick 
embryo in the absence of the afferent root fibers and of descending fiber tracts.” J Comp 
Neurol 91:209-242. 
Lorusso, F., F. Dispenza, G. Martinciglio, A. Messina, A. Battaglia, and S. Gallina. 2017. 
“Postural changes in patients undergoing hyoid surgery for OSAS.” EuroMediterranean 
Biomedical Journal 12 (29):140-143. doi: 10.3269/1970-5492.2017.12.29. 
Martines, F., P. Salvago, C. Bartolotta, S. Cocuzza, C. Fabiano, S. Ferrara, E. La Mattina, M. 
Mucia, P. Sammarco, F. Sireci, and E. Martines. 2015. “A genotype–phenotype 
correlation in Sicilian patients with GJB2 biallelic mutations.” European Archives of Oto-
Rhino-Laryngology 272 (8):1857-1865. doi: 10.1007/s00405-014-2970-1. 
Middlebrooks, J. C., J. A. Bierer, and R. L. Snyder. 2005. “Cochlear implants: the view from 
the 
brain.” 
Curr 
Opin 
Neurobiol 
15 
(4):488-93. 
doi: 
10.1016/ 
j.conb.2005.06.004. 

Neuroplasticity and Sensorineural Hearing Loss 
 
811
Rajan, R., and D. R. Irvine. 1998. “Absence of plasticity of the frequency map in dorsal 
cochlear nucleus of adult cats after unilateral partial cochlear lesions.” J Comp Neurol 
399 (1):35-46. 
Salvago, P, S Rizzo, A Bianco, and F Martines. 2017. “Sudden sensorineural hearing loss: is 
there a relationship between routine haematological parameters and audiogram shapes?” 
Int J Audiol 56:148-153. 
Sharma, A., M. Dorman, A. Spahr, and N. W. Todd. 2002. “Early cochlear implantation in 
children allows normal development of central auditory pathways.” Ann Otol Rhinol 
Laryngol Suppl 189:38-41. 
Thomas, E, F Martines, A Bianco, G Messina, V Giustino, D Zangla, A Iovane, and A Palma. 
2018. “Decreased postural control in people with moderate hearing loss.” Medicine 
(United States) 97:e0244. doi: 10.1097/MD.0000000000010244. 
Wang, J H, G Y Ko, and P T Kelly. 1997. “Cellular and molecular bases of memory: synaptic 
and neuronal plasticity.” J Clin Neurol Physiol 14:264–293. 
Yang, M., H. J. Chen, B. Liu, Z. C. Huang, Y. Feng, J. Li, J. Y. Chen, L. L. Zhang, H. Ji, X. 
Feng, X. Zhu, and G. J. Teng. 2014. “Brain structural and functional alterations in 
patients with unilateral hearing loss.” Hear Res 316:37-43. doi: 10.1016/ 
j.heares.2014.07.006. 
 
 


In: Encyclopedia of Audiology and Hearing Research 
ISBN: 978-1-53617-702-2 
Editors: Erno Larivaara and Senja Korhola 
© 2020 Nova Science Publishers, Inc. 
 
 
 
 
 
 
 
Chapter 57 
 
 
 
NEURORADIOLOGY OF THE HEARING SYSTEM 
 
 
Cesare Gagliardo1,, MD, PhD, Silvia Piccinini2-3, MD  
and Paola Feraco4-5, MD 
1Section of Radiological Sciences, Department of Biomedicine, Neuroscience and 
Advanced Diagnostic, University of Palermo, Palermo, Italy  
2Department of Neuroradiology,  
University Hospital of Modena, Modena, Italy 
3Audiology and Pediatric Otolaryngology Unit,  
University of Parma, Parma, Italy 
4Department of Radiology, Ospedale S. Chiara,  
Azienda Provinciale per i Servizi Sanitari, Trento, Italy 
5Department of Experimental, Diagnostic and Specialty Medicine,  
University of Bologna, Bologna, Italy 
 
 
ABSTRACT 
 
Hearing loss is one of the most frequent indications for CT and MR examinations of 
the auditory system. Such a symptomatology is becoming increasingly common in 
today’s society and is extremely disturbing for patients. Causes may involve the auditory 
pathway at any level. 
In most cases, neuroradiological examinations represents a mandatory step, within a 
multidisciplinary workup, towards final diagnosis, therapeutic plan and subsequent 
follow-ups. This chapter will introduce this critical topic starting from an imaging-based 
exposition of the anatomy and function of the auditory system. The chapter will include 
some hints on the choice of the best imaging examination to perform on each patient 
since the type of hearing loss determines which imaging study will yield the most 
diagnostic information. Practical coverage of the neuroradiological findings in 
conductive, sensorineural and mixed hearing loss forms will be presented. Ranging from 
congenital to acute and chronic causes, from children to adults, the role of imaging-based 
examinations will be illustrated for both common and uncommon diseases of the hearing 
system. 
                                                        
 Corresponding Author’s Email: cesare.gagliardo@unipa.it; cesare.gagliardo@gmail.com. 

C. Gagliardo, S. Piccinini and P. Feraco 
 
814
To increase reading and review experience, the authors will include concise 
descriptions (in a bullet outline format and/or in tables) of all the discussed key 
information related to anatomy, function and pathology. High-quality CT and MR images 
will support the reader in each paragraph for an optimal learning experience of the 
discussed topics.  
 
 
1. INTRODUCTION TO THE ROLE OF IMAGING 
 
Imaging techniques have historically supported the study of the auditory system which 
always required dedicated and optimized protocols to ensure a good visualization of its 
peculiar anatomy and related pathology. 
Nowadays, Computerized Tomography (CT) and Magnetic Resonance Imaging (MRI) 
are the most used imaging modalities to investigate the auditory pathway at any level.  
Conversely, the role of plain film radiographs has been significantly reduced and limited 
to specific applications over the past years (i.e.: Stenvers’ projection is still routinely used for 
intra- and/or postoperative evaluation of a cochlear implant lead). 
Digital subtraction angiography (DSA) is still used in cases of hypervascular masses and 
vascular malformations involving the temporal bone or the auditory pathway.  
Diagnostic ultrasounds found little use in this context if not for the evaluation of 
periauricular lesions or ultrasound-guided biopsies.  
Nuclear medicine modalities, such as Positron Emission Tomography (PET) may be used 
for the assessment of temporal bone masses and/or nodal metastases.  
Last but not least, dedicated devices such as cone beam CT (CBCT) that are more 
recently spreading worldwide, deserve mention since they have been successfully used for 
middle ear diseases [1], cochlear implants [2-4], cholesteatoma surgery [5-6], guidance of 
temporal bone surgery [7] and other specific pathologies such as otosclerosis [8-9]. 
CBCT equipment uses a rotating gantry on which an x-ray tube and a reciprocating solid 
state flat panel detector is attached [10]. This allows the operator to acquire a full dataset of 
the region of interest with a single 180-360° rotation of the gantry (scanning time varies from 
nearly 5 - using pulsed scans - to about 40 seconds). Because of their high spatial resolution 
(slice thickness could be in the order of some tens of microns), lower radiation dose, lower 
sensitivity to metallic and beam hardening artifacts and their reduced costs, these scanners 
have triggered a lively interest in the scientific community. Furthermore, the production of 
compact CBCT scanners enabled their usage in an office-based setting [10]. On the other 
hand, if compared to conventional CT, CBCT images are noisier because of the large volume 
being irradiated, are more sensitive to movement and distortion artifacts, partial volume 
averaging, undersampling and cone-beam effect. Last but not least, CBCT have a poor soft 
tissue contrast and their usage is substantially limited to oral and maxillofacial radiology [11]. 
 
 
1.1. Computerized Tomography (CT) Study Protocol 
 
CT is the primary imaging modality for evaluating the osseous components of the 
temporal bone region [12-13]. The increasing number of multi-detector CT (MDCT) 
installations has been followed by the wide adoption of helical study protocols dedicated to 

Neuroradiology of the Hearing System 
 
815
high resolution temporal bone imaging. Nowadays, thanks to MDCT scanners, it is no longer 
necessary to ask patients to lay on the gantry in uncomfortable positions to obtain optimal 
study planes as we used to do in the past years with single-row-detector CT equipment using 
sequential study protocols. MDCT protocols (see Table 1) for temporal bone region are based 
on sub-millimetric (slice thickness should never exceed 1.0 mm), usually isotropic datasets 
and related multiplanar reconstructions (MPR). All temporal bone studies should be 
reconstructed using a bone algorithm and each side should be separately reconstructed using a 
magnified small field of view (FOV) for both axial and coronal planes. Reconstruction of the 
posterior fossa using soft-tissue algorithm with a wider FOV is recommended. 
 
Table 1. Example of standard protocols for a 16 detector rows scanner  
(GE Brightspeed 16).  
 
Acquisition parameters (helical scan type) 
Protocol 
<2y 
>2y 
Adults 
Tube voltage (kV) 
120 
120 
140 
Tube current (mAs) 
200 
200 
260 
Axial thickness (mm) 
0.625 
0.625 
0.625 
Scan type 
Helical full (0,7s) 
Helical full (1s) 
Helical full (1s) 
Pitch 
0.562:1 
0.562:1 
0.562:1 
Speed (mm/rot) 
5.62 
5.62 
5.62 
Beam collimation (mm) 
10 
10 
10 
Interval (mm) 
0.625 
0.625 
0.310 
SFOV (cm) 
10 
10 
24 
DFOV (cm) 
6 
6 
10 
Scan durations (s) 
11.44 
16.33 
9.3 
N° of images 
129 
129 
130 
Matrix size 
512 x 512 
512 x 512 
512 x 512 
Maximum estimated CTDIvol (mGy) 
52.04 
74.34 
143.70 
DLP (mGy-cm) 
478.21 
682.93 
750.09 
Reconstruction kernel (window width/level) 
Bone Plus - GE’s hard/sharp kernel (4095/600) 
SFOV: Scan field of view; DFOV: Display field of view; CTDIvol: computed tomography dose index; DLP: 
dose-length product 
 
If a MDCT scanner is not available (or if reformatted coronals from the axial scans are 
not possible/adequate), direct coronal images should be considered. To ensure a direct coronal 
plane, the patient is asked to lay in the prone position with the head tilted back (for patients 
who cannot tolerate this position, supine positioning with a pillow under the shoulders and the 
head tilted posteriorly should be tried). For direct coronal plane imaging, the gantry should be 
perpendicular to the infraorbital-meatal line. The typical planning should be from the level of 
the posterior temporo-mandibular joint anteriorly, through the entire mastoid air cells 
posteriorly. 
 

C. Gagliardo, S. Piccinini and P. Feraco 
 
816
 
 
a 
 
 
b 
Figure 1. a) Axial CT passing through the superior semicircular canal (SSCC) with superimposed 
DICOM references lines for a MultiPlanar Reconstruction (MPR) among Poschl’s plane obtained by 
tilting the MPR plane parallel to the SSCC; b) the whole SSCC is fully exposed on the obtained MPR. 
 
 
a 
 
 
b 
Figure 2. a) Axial CT passing through the superior semicircular canal (SSCC) with superimposed 
DICOM references lines for a MultiPlanar Reconstruction (MPR) among Stenvers’ plane obtained by 
tilting the MPR plane perpendicular to the SSCC; b) the cochlea is exposed from basal turn to apex on 
the resulting MPR plane. 
If a MDCT scanner is available, high resolution temporal bone imaging is obtained with 
the patient placed supine and the head in a neutral position. The gantry of the scanner should 
be angled parallel to the infraorbital-meatal line. Two topograms (one in the anterior-posterior 
projection and one lateral) are usually scanned to plan the study ensuring the full coverage of 
the region of interest. The typical axial planning should start from the arcuate eminence 
superiorly and the mastoid tip inferiorly. The excursion of the scan is planned to avoid 
including the eyes in the pathway of the x-ray beam to reduce the radiation dose to the lens. 
Coronal MPRs are usually obtained tilting the plane perpendicular to the infraorbital-meatal 
line. Considering the three-dimensional (3D) nature of the scanned dataset additional 
reformations, with no compromises in terms of image spatial resolution, are possible and 
could result in being very useful in specific cases. For example, if a superior semicircular 
canal dehiscence is suspected, Poschl plane (Figure 1) among the short temporal bone axis 

Neuroradiology of the Hearing System 
 
817
(obtained by tilting the MPR plane parallel to the superior semicircular canal) should be 
considered [14]. Similarly, Stenvers’ plane (Figure 2) among the long temporal bone axis 
(obtained by tilting the MPR plane perpendicular to the superior semicircular canals) should 
be considered to evaluate a cochlear implant lead [15]. 
Intravenous (i.v.) administration of contrast medium is usually not indicated for temporal 
bone imaging but may be helpful when evaluating patients with acute mastoiditis in order to 
evaluate adjacent vascular structures such as the transverse sinus, to investigate the 
involvement of the mastoid and/or the perimastoid dissemination of a disease, or if a temporal 
bone tumor is suspected. 
 
 
1.2. Magnetic Resonance Imaging (MRI) Study Protocol 
 
MRI is the primary imaging modality for evaluating the non-osseous components of the 
temporal bone region [16-17]. A high field strength MRI scanner (≥1.5T) is typically used 
together with a phased array head coil (8-, 16- or 32-channels). The use of dedicated surface 
coils can improve the signal/noise ratio at the cost of a lower depth and reduced FOV. MRI is 
the first imaging examination requested in case of suspected retrocochlear pathology and 
cranial nerve dysfunction. One of the most common indications for an MRI examination of 
the temporal bone is sensorineural hearing loss [18-19]. MRI is also useful in patients with 
CT-defined infections or neoplasms to determine if there is an involvement of the intracranial 
compartment.  
Even if MDCT is still the preferred modality if a labyrinthine or cochlear lesion is 
suspected or in patients with subjective pulsatile tinnitus, there are specific lesions (such as 
cochlear schwannomas or labyrinthine hemorrhages) and cases (such as patients with 
objective pulsatile tinnitus - audible bruit) that could be better detected and studied by MRI. 
During the MRI examination, the patient lays in the supine head-first position. A fast 
(low resolution) T2-weighted three plane localizer is scanned. Axial sequences are planned 
parallel to the line passing through both internal auditory channels (IACs) and perpendicular 
to the brain stem; the number of slices must be sufficient to cover the ROI from the 
hippocampus up to the line of the first cervical verbal body. Coronal sequences are planned 
parallel to the line passing through both internal auditory channels (IACs) on the coronal 
plane and parallel to the brain stem on the sagittal plane. The number of slices must be 
sufficient to cover the ROI from the posterior border of sphenoid sinus up to the fourth 
ventricle anterior wall. An example of an MRI protocol for the evaluation of the temporal 
bone is reported in Table 2; to ensure a good visualization of the peculiar anatomy and related 
pathology of this region a small FOV is used and slice thickness should not exceed 3 mm 
with no interslice gap. Axial and coronal T1-weighted pulse sequences acquired before and 
after administration of i.v. contrast agent should be included (at least one post-contrast  
T1-weighted sequence with fat saturation should be scanned as well). Nowadays, thin section 
3D constructive interference in steady-state (3D-CISS) T2-weighted sequences are mandatory 
[20]. This technique has different names for each vendor: fast imaging, employing steady-
state acquisition (FIESTA) by GE, true fast imaging with steady-state precession (FISP) by  
 
 

C. Gagliardo, S. Piccinini and P. Feraco 
 
818
Table 2. Example of standard protocols for 1.5T scanners using a  
dedicated 8-channel phased-array head coil 
 
Parameters 
MRI scanner: 1.5T Philips Achieva / 1.5T GE HDxT 
Pulse 
sequence 
2D Ax 
T1w 
TSE / 
FSE 
2D Ax and 
Cor T2w 
TSE SPIR / 
FSE FAT 
SAT 
3D Ax 
B-FFE / 
FIESTA 
2D Cor DWI / 
Ax DWI 
PROPELLER 
(b=0/1000m/s2) 
2D Ax 
T1w (Gd) 
SE 
3D AX 
(Gd) 
FFE SPIR / 
SPGR FAT 
SAT 
FOV (mm) 
150x150 / 
180x180 
180x180 / 
180x180 
180x180 / 
180x180 
220x186 / 
240x240 
150x150 / 
180x180 
150x150 / 
180x180 
Matrix 
224x178 / 
256x224 
256x202 / 
256x256 
308x307 / 
352x320 
124x87 / 
384x384 
208x166 / 
256x224 
208x208 / 
256x256 
N° of slices 
12 /14 
13 /14 
75 / 64 
18 / 22 
11 /14 
50 / 64 
Slice 
thickness 
(gap) mm 
3 (0.3) / 3 
(0.5) 
3 (0.3) / 3 
(0.5) 
1 (-0.5) / 
0.8 
3 (0.3) / 3 (0.5) 
3 (0.3) / 3 
(0.5) 
1.4 (-0.7) / 
0.8 
TE (ms) 
10 / 20 
90 / 85 
3.5 / 2.2 
77 / 93 
15 / 20 
4.6 / 3.4 
TR (ms) 
550 / 580 
3000 / 4733 
7.1 / 6.1 
3713 / 6109 
550 / 580 
25 / 10.1 
Number of 
excitations 
3 / 2 
3 / 4 
2 / 3 
4 / 3 
3 
1 / 1 
Echo train 
length 
3 / 18 
17 / 22 
n.a. 
44 / 28 
n.a. 
n.a. 
Acquisition 
time (m:s) 
3:20 / 
4:28 
3:39 / 3:52 
4:25 / 5:40 
4:57 / 2:33 
4:37 / 
6:33 
4:20 / 2:22 
Ax: axial plane; Cor: coronal plane; T1w: T1 weighted; T2w: T2 weighted; TSE: Turbo Spin Echo; FSE: 
Fast Spin Echo; SPIR: Spectral Presaturation with Inversion Recovery; FAT SAT: Fat Saturation; B-FFE: 
Balanced gradient waveform Fast Field Echo; FIESTA: Fast Imaging Employing STeady-state Acquisition; 
DWI: Diffusion Weighted Imaging; PROPELLER: Periodically Rotated Overlapping ParallEL Lines with 
Enhanced Reconstruction (GE’s radial k-space filling pattern used to reduce the effect of patient voluntary 
and physiologic motion and reduce magnetic susceptibility artifacts); SE: Spin Echo; Gd: sequence acquired 
after i.v. administration of gadolinium based contrast medium; FFE: Fast Field Echo; SPGR: SPoiled 
Gradient echo; m: minutes; s: seconds. 
 
Siemens, balanced fast field echo (FFE) by Philips, and true steady-state free precession 
(SSFP) by Toshiba. 3D CISS sequences are very useful in the assessment of cranial nerves 
anatomical variations, pathologies and vascular conflicts and compressions. To evaluate the 
intracisternal tract of the 7th and 8th cranial nerves (CNs), oblique sagittal reformatted CISS 
images perpendicular the internal auditory channel are highly suggested (Figure 3). Thick 
slab MPRs using a maximum intensity projection (MIP) algorithm obtained from 3D CISS 
sequences are commonly used to visualize internal ear structures such as labyrinthine 
structures, the endolymphatic sac and to evaluate the extent of a cochlear dysplasia in cases of 

Neuroradiology of the Hearing System 
 
819
congenital or developmental hearing loss (Figure 4). Poschl like plane is commonly used in 
pediatric cases when a cranial nerve deficiency is suspected. If a cholesteatoma is suspected, 
non–echo planar (EP) diffusion weighted imaging (DWI) sequence has been demonstrated 
useful in differentiating typical findings of middle ear and/or mastoid infections from 
cholesteatomas larger than 2 mm [21]. Non-EP DWI is also useful in post-surgical 
evaluations. Conventional EP-DWI are more sensitive to susceptibility artifacts which 
typically affect this region with little to no practical applications. Additional dedicated 
sequences should be considered in case of intracranial or nasopharyngeal extensions of a 
disease. 
 
 
a 
 
 
b 
Figure 3. a) Axial 3D FIESTA passing through the left internal auditory channel (IAC) showing the 
intracisternal tract of the 7th (anterior) and 8th (posterior) cranial nerves; superimposed DICOM 
references lines shows the correct oblique orientation of a MultiPlanar Reconstruction (MPR) to 
evaluate the internal auditory channel tracts; b) the resulting MPR plane shows the typical four black 
dots into the IAC: the facial nerve (F) is in an anterior-superior location, the cochlear nerve (C) is in an 
anterior-inferior location, the superior and the inferior vestibular nerves (SVN and IVN respectively) 
are located posteriorly. A: anterior; P: posterior; S: superior; I: inferior. 

C. Gagliardo, S. Piccinini and P. Feraco 
 
820
 
 
a 
 
 
b 
 
 
 
c 
 
 
d 
 
 
e 
 
 
f 
Figure 4. 3D Maximum Intensity Projection (MIP) reconstructions of the internal ear structures: 
anterior (a), posterior (b), inferior (c), superior (d), left (e) and right (f) orientations. 
 
 

Neuroradiology of the Hearing System 
 
821
2. EXTERNAL EAR 
 
Imaging plays a minor role in external ear pathology because it is usually evident at 
clinical evaluation. However, it becomes necessary if the EAC is obstructed or stenotic. 
Aural dysplasia derives from a failure of the first branchial cleft to canalise EAC, 
implicating atresia or dysplasia. Clinical examination reveals a small and abnormal auricle 
(microtia) in association. In such cases, a CT scan is indicated before any surgical 
intervention to delineate the facial nerve canal. Aural dysplasia could be associated with 
congenital cholesteatoma or inner ear abnormalities which are usually minor [22, 23]. 
External otitis do not require imaging studies. If a necrotizing variant is present, imaging 
is recommended to evaluate periauricular involvement of the disease, because it spreads 
rapidly through bone and soft tissues. MRI is preferred if intracranial involvement is 
suspected [24]. 
In conductive deafness, stenotic EAC is sometimes difficult to evaluate, so a CT scan is 
required to exclude bone abnormalities such as fibrous dysplasia [25]. Fibrous dysplasia is a 
disease of young patients, conversely to esostosis that is usually in older people. Esostosis is a 
nodular elevation of bone involving tympanic bone, due to prolonged irritation of EAC 
secondary to cold water (Figure 5). Differential diagnosis includes osteoma that is usually 
seen as a unilateral, pedunculated bony lesion [26]. 
EAC cholesteatoma is rare; it is characterized by bony destruction and it usually has an 
iatrogenic origin after surgery. Trauma, focal osteitis, and cerumen retention are less frequent 
causes [27]. Keratosis obturans is an epidermal keratin plug in the EAC, often bilateral 
(Figure 6). On CT scan, it is a soft tissue mass associated with the widening of EAC, possibly 
with mild erosion of bony margins [28]. 
 
 
Figure 5. Bilateral EAC exostosis in a scuba diver with chronic exposure to cold water; coronal MPR of 
a MDCT scan show broad-based circumferential bony overgrowth of the osseous EAC (arrows) that 
severely reduces the width of the EAC (courtesy of Dr Giuseppe Tagliavia, “Centro di Radiologia 
Diagnostica srl” – Sciacca, Agrigento – Italy). 
External ear cancers are rare; they demonstrate clinical symptoms similar to external 
otitis at the onset. They usually are squamous cell carcinoma or basocellular carcinoma. CT 
are required to evaluate surgical intervention; bone involvement is critical to surgical 
planning, especially when extending to temporomandibular joints or the middle ear. MRI is 
frequently associated in order to exclude perineural, perivascular or intracranial spread of the 
disease (Figure 7) [29, 30]. 

C. Gagliardo, S. Piccinini and P. Feraco 
 
822
 
Figure 6. Bilateral EAC keratosis obturans; axial MDCT scan show bilateral soft tissue mass (arrows) 
within the bony EAC which enlarges the canal with no signs of bony erosion. 
 
Figure 7. External ear cancer; coronal T1-weighted sequence with fat saturation acquired after i.v. 
administration of contrast medium. Contrast enhancing soft tissue mass (black asterisk) with undefined 
edges causing stenosis of right EAC and reaches the bony part of the EAC. Normal appearing 
contralateral EAC shows typical low signal due to its air content (white asterisk). 
 
3. MIDDLE EAR AND MASTOID  
 
The most frequent request for oto-neuroradiological examinations concern the middle 
ear. 
The middle ear (or tympanic cavity), is the small, air-filled cavity, within the temporal 
bone located between the eardrum (tympanic membrane, TM) and the lateral bony wall of the 
internal ear. The tympanic cavity posteriorly communicates, through the aditus ad antrum, 
with the mastoid antrum and cells; anteriorly it communicates with the nasopharynx through 
the auditory tube (also known as Eustachian or pharyngotympanic tube) that allows it to 
equalize the air pressure inside the drum with atmospheric pressure lateral to the drum. 
The tympanic cavity contains the three auditory ossicles (hammer or malleus, anvil or 
incus and stirrup or stapes) which transmit sound vibration from the tympanic membrane to 

Neuroradiology of the Hearing System 
 
823
the inner ear enabling the primary function of the middle ear itself (sound‐conducting 
apparatus). Other components of the tympanic cavity are tendons of the tensor tympani and 
the stapedius muscles, the chorda tympani (branch of the facial nerve) and tympanic plexus 
(branches from facial and glossopharyngeal nerves). 
The tympanic cavity is bounded by six walls which must be carefully evaluated during 
the assessment of oto-neuroradiological examinations: superior (or tegmen tympani or paries 
tegmentalis), inferior (or jugular wall or paries jugularis), anterior (or carotid wall), posterior 
(or mastoid wall), lateral (or paries membranaceus) and medial (or paries labyrinthica). The 
tympanic cavity is also divided into three levels: epitympanum (level above the TM; it houses 
the body of the malleus and the incus), mesotympanum (TM level; is the central and the 
biggest compartment of the middle ear cavity, it houses the long processes of malleus and 
incus, the stapes, oval and round windows, facial nerve and parts of the middle ear muscles 
and tendons) and hypotympanum (level below the TM, it houses no functional elements) [31]. 
In adults the tympanic cavity measures approximately 15 × 15 × 6 mm but the width in the 
center part of the cavity is only 2 mm [32]. 
High resolution CT/MDCT imaging of the temporal bone represent the first line imaging 
modality for middle ear evaluation, surgical treatment planning and post-therapy follow-ups. 
MRI is usually performed as a second level investigation for specific clinical suspects. 
 
 
3.1. Congenital Anomalies of the Middle Ear 
 
Middle ear anomalies can be unilateral or bilateral but they are predominantly unilateral 
(70-90%). The incidence of middle ear malformations is approximately 1 in 3800 newborns. 
The etiopathogenesis of most malformations of the middle ear is still poorly defined. In all 
genetically determined malformations (syndromal and non-syndromal) one can assume a high 
frequency of spontaneous genetic mutations. The acquired ear malformations originate from 
exogenic injury during pregnancy. The noxae could comprise infections, chemical agents, 
malnutrition, radiation exposure, Rh incompatibility, hypoxia, atmospheric pressure changes 
and noise exposure. Deficiency or malfunction of the thyroid hormone can be also associated 
with ear malformations. However, in many cases, the actual cause is unknown [33]. 
Middle ear malformations are a rare cause of conductive hearing loss in children, 
especially when these conditions are not associated with malformations of the external ear. 
These anomalies are usually confused with serous otitis [34]. The clinical and surgical 
relevance of these disorders are strictly related to the associated anatomical development 
anomalies and malfunctions [31]. 
If a congenital conductive hearing loss (CCHL) is suspected, a high-resolution CT 
examination in order to evaluate the bony structures of the middle ear should be considered. 
Congenital anomalies of the middle ear can be classified into major (associated with an 
involvement of the tympanic membrane and external ear) and minor (exclusive involvement 
of the middle ear) [34]. 
Minor middle ear anomalies include a change in the anatomy or size of the tympanic 
cavity or a reduced distance between anatomical structures of the middle ear and fixated 
ossicles (stapes ankylosis). In major anomalies, the ossicles are often involved. The most 
common isolated ossicle deformity involves the stapes suprastructure in terms of aplasia or 
hypoplasia, thickening, thinning or fusion of the stapes crura [33]. The malleus tends to be 

C. Gagliardo, S. Piccinini and P. Feraco 
 
824
rarely involved in isolated middle ear malformations. The most frequent findings are 
deformities and hypoplasia of the head and of the manubrium of the malleus, fixations in the 
epitympanic recess and malleolo-incudal joint abnormality. The malleus can also be absent 
[31]. Incus malformations are dominated by absence or hypoplasia of the long process 
coexisting with incudo-stapedial joint separation. Less frequently, the long process may vary 
in position (horizontal rotation and fixation in the direction of the horizontally running 
tympanic segment of the facial nerve) or complete incus aplasia may be found. In addition, 
synostotic or synchondrotic incudo-malleolar joint abnormalities and epitympanic recess 
fixation have often been found [33]. 
The inner ear windows may be involved in middle ear anomalies in terms of a mobile 
stapes footplate or dysplasia/aplasia of the round or oval window. There may be anomalies of 
the oval window and, rarely, of the round window. Congenital agenesis of the oval window 
involves complete osseous obliteration of the oval window either by a concentric narrowing 
that produces a dimple-like depression along the medial tympanic wall or by a thick bony 
plate [33]. Almost 76% of the patients with congenital absence of the oval window presents 
with associated malformation of the facial nerve canal. The nerve can either limit the 
exposure of the oval window or it can cover the footplate completely. This condition may also 
be associated with conductive hearing loss [35]. 
Malformation and aberrant course of the facial nerve are frequently encountered; the 
common abnormalities include complete dehiscence of the tympanic segment, inferior 
displacement of the tympanic segment, and anterior and lateral displacement of the mastoid 
segment. The latter frequently obscures the round window. 
Other malformations of the middle ear include a missing antrum, a pneumatized mastoid, 
cerebral spinal fluid (CSF) fistulas (indirect translabyrinthine or direct paralabyrinthine), 
congenital cholesteatoma (as known as congenital epidermoid), congenital dermoids, aberrant 
courses of arteries and veins, and malformations of the middle ear muscles. 
The primary (congenital) cholesteatoma (Figure 8) counts as a congenital middle ear 
anomaly; a four-stage classification is used: 
 
 
Stage I: only one quadrant of tympanic membrane is affected with no ossicular 
involvement or mastoid extension; 
 
Stage II: multiple quadrants are affected but no ossicular involvement or mastoid 
extension; 
 
Stage III: ossicular involvement (includes erosion of ossicles and surgical removal 
for eradication of disease); no mastoid extension; 
 
Stage IV: mastoid extension (regardless of findings elsewhere). 
 
Numerous classifications for middle ear malformations have been proposed. The 
classification of the minor malformations, proposed by Teunissen and Cremers [36], is based 
on the surgical aspects of the malformations, and subdivides them into four main groups: 
 
1) Ankylosis or isolated congenital fixation of the stapes (footplate fixation and 
superstructure fixation); 

Neuroradiology of the Hearing System 
 
825
2) Stapes ankylosis associated with other malformations of the ossicular chain 
(deformities of the incus and/or malleus, or aplasia of the long apophysis of the incus 
and bone fixation of malleus and/or incus); 
3) Congenital anomalies of the ossicular chain with mobile stapes footplate (disruption 
of the ossicular chain, epytimpanic fixation or timpanic fixation); 
4) Congenital aplasia or severe dysplasia of the oval and round windows (aplasia, 
dysplasia, prolapse of facial nerve or persistence of stapedial artery). 
 
Kösling [37] described three degrees of severity of isolated middle ear malformations: 
 
1) Mild malformations are those in which normal configuration of the tympanic cavity 
coexists with ossicular dysplasia; 
2) Moderate malformations are characterized by hypoplasia of the tympanic cavity 
along with rudimentary or aplastic ossicles; 
3) Severe malformations show aplastic or cleft-like tympanic cavity. 
 
High-resolution CT is the best diagnostic imaging examination since it allows a correct 
visualization of bony structures. However, exploratory tympanotomy is the method that most 
reliably establishes the definitive diagnosis. All of these anomalies can be surgically corrected 
[31]. 
 
 
Figure 8. Primary (congenital) supralabytinthine cholesteatoma; axial CISS sequence passing through 
the IACs showing the cholesteatoma (black asterisk) with a inhomogeneous low- to high- signal with 
geniculate ganglion impairment (white arrow). 
 
3.2. Acute Infections of Middle Ear 
 
Infection of the middle ear cavity is termed otitis media; it is called otomastoiditis (OM) 
when inflammation process spreads to the mastoid. Otitis media could occur suddenly (acute 
otitis media, AOM) or, if it does not go away or happens repeatedly, could remain over 
months to years (chronic otitis media, COM). 

C. Gagliardo, S. Piccinini and P. Feraco 
 
826
A mixture of factors predisposes to otitis media, but Eustachian tube dysfunction is 
thought to be one of the most important factors. Congenital palate defects, host immunity, and 
viral or bacterial infection may all be contributing factors. 
AOM is commonly seen in children and it is the most common bacterial infection among 
children. 
Although AOM is generally considered a bacterial infection, there is ample evidence that 
respiratory viruses have a crucial role in the etiology and pathogenesis of this disease. 
The presence of viruses in the middle ear fluid is important not only in regard to the 
aetiology and pathogenesis of acute otitis media, but also in regard to the outcome of the 
disease [38]. 
Symptoms include earache, fever, pain, otorrhea, conductive hearing loss (CHL) with a 
bulging and red tympanic membrane at otoscopy [39]. 
Although this infection can be well estimated on otoscopic examination, further questions 
concerning the extent of the disease, exact location, structures involved and possible bone 
erosion, will be addressed in detail only with neuroradiological examinations. CT is the 
imaging modality of choice for the assessment of CHL [40]. 
In AOM, high resolution temporal bone CT is routinely performed and may reveal soft 
tissue in the middle ear cavity (Figure 9), thickened tympanic membrane with bulging. Other 
features that could be seen in AOM include air-fluid level in the middle ear (effusion) and 
bony erosion [39]. MR is indicated when complicated inflammatory lesions are suspected to 
extend into the inner ear or towards the sigmoid sinus or jugular vein. MR is very sensible in 
identifying typical high signals from fluid collections in the middle ear cavity and mastoid 
antrum on T2-weighted pulse sequences. 
 
 
Figure 9. Acute otitis media; axial MDCT scan at the level of the IAC / middle ear showing soft tissue 
density in the middle ear cavity which extends to incorporate the ossicular chain and mastoid antrum 
(asterisk). Patient with a noticeable hypopneumatization of the temporal pyramid. 

Neuroradiology of the Hearing System 
 
827
The clinical course of AOM is generally short: in the vast majority of patients the 
response of the immune system and the sensitivity of the germ to the administered antibiotic 
will be enough. However, acute otitis media can progress to severe complications, including 
acute mastoiditis, meningitis, and intracranial abscess [41]. In these cases contrast enhanced 
CT is useful to evaluate adjacent vascular structures such as the transverse sinus. MRI is 
mandatory if the intra-cranial dissemination of the inflammation process is suspected for a 
prompt diagnosis of cerebritis foci or to better characterize brain abscesses (late cerebritis). 
Acute mastoiditis (AM), even if it could occur as an isolated process, is usually a 
complication of otitis media (Oto-Mastoiditis, OM) in which infection in the middle ear cleft 
involves the muco-periosteum and bony septa of the mastoid air cells. CT is usually the initial 
technique of choice for imaging patients with OM. Typical imaging findings are opacification 
of the tympanic cavity, mastoid antrum and air cells with bone erosion and/or destruction of 
the intramastoid bony septa (Figure 10) [42]. Contrast agent administration is recommended 
for better evaluation of perimastoid soft tissues and to exclude fearsome complications like 
dural venous sinus thrombosis [43]. MRI is mainly reserved for the detection, or detailed 
evaluation, of intracranial complications of OM. Typical MRI findings in patients with 
complicated OM are: 
 
 
opacification of the tympanic cavity and the mastoid with fluid-like signal intensity 
of intramastoid contents on T1- and T2-weighted imaging; 
 
diffusion weighted imaging (DWI) may show variable degrees of signal increase 
within the mastoid effusions; however, DWI is a mandatory sequence to detect 
purulent secretions and brain abscesses that are characterized by a bright signal 
intensity and a low signal on apparent diffusion coefficient (ADC) maps due to a 
restricted diffusion of water molecules movements within purulent collections; 
 
after administration of i.v. contrast, an intense intramastoid enhancement is 
commonly seen among the outer periosteum or the perimastoid dura. 
 
 
Figure 10. Patient with acute otomastoiditis; coronal MPR from a MDCT scan show typical soft tissue 
density into the middle ear cavity (asterisk) and mastoid cells with sign of erosion towards the 
infratemporal fossa (Bezold abscess).  

C. Gagliardo, S. Piccinini and P. Feraco 
 
828
According to Platzek [44], the diagnosis of AM is possible with a sensitivity of 100%, a 
specificity of 66% and an accuracy of 86%, with two of the following intra-mastoid findings 
on CT/MRI examinations: fluid accumulation, enhancement, or diffusion restriction. 
In clinical practice, contrast-enhanced CT is still the preferable, first-line imaging 
technique due to higher accessibility, especially for urgent cases. Thus, MRI is: 
 
 
an alternative diagnostic tool for patients with contraindications to contrast-enhanced 
CT; 
 
a mandatory second level investigation to detect intracranial complications; 
 
recommended for paediatric patients due to its lack of ionizing radiation. 
 
 
3.3. Chronic Otitis Media 
 
The definition of chronic otitis media (COM) is based on clinical and pathological 
features. 
When the inflammation of the middle ear persists at least 6 weeks and is associated with 
otorrhea through a perforated tympanic membrane, the diagnosis of chronic otitis media is 
placed. 
Principal etiopathological factors of COM are infections of the upper respiratory tract, 
insufficiency of ciliary clearance and drainage of the Eustachian tube (Eustachian tube 
dysfunction), allergic history and familial predisposition. Symptoms include conductive 
hearing loss, vertigo, otorrhea and sometimes pain. 
Chronic otitis media are classified in chronic suppurative otitis media (CSOM) and 
chronic otitis media with effusion (COME) [45]. 
CSOM is characterized by recurrent or persistent ear discharge (otorrhea) over 2 to 6 
weeks through a perforation of the tympanic membrane. 
COME is defined as the presence of fluid in the middle ear without symptoms or signs of 
infection and is the most common cause of acquired hearing loss in childhood. 
Enabling an optimal visualization of bony structures and pneumatized spaces, CT is 
therefore the best diagnostic method to evaluate the involvement of temporal bone structures 
in patients with chronic inflammation of the middle ear [46]. 
On CT examination typical radiological signs of chronic otitis media are [39]: 
 
 
opacification or mucosal thickening in the tympanic cavity; 
 
obliteration of the epitympanum or Prussak’s space by fibrous-inflammatory tissue 
(for tubal dysfunction, reduced transmucosal gas exchange, and development of otitis 
media); 
 
bone erosions and/or ossicular disorders; 
 
sclerosis and loss of aeration of the mastoid air cells; 
 
osteolysis of the bony septa and, in severe cases, osteomyelitis of the petrous 
temporal bone. 
 

Neuroradiology of the Hearing System 
 
829
Since some ears with chronic inflammation develop cholesteatoma, chronic otitis media 
may be also classified into two groups: with or without cholesteatoma. Cholesteatoma is a 
well-demarcated non-neoplastic lesion resulting from an abnormal accumulation of squamous 
epithelium usually found in the middle ear cavity and mastoid process of the temporal bone 
[45]. 
 
3.3.1. Chronic Otitis Media without Cholesteatoma 
Post-inflammatory ossicular chain fixation is a common finding in patients with chronic 
otitis media and conductive hearing loss (Figure 11). On CT images, three distinctive forms 
of ossicular chain fixation can be evaluated: 
 
 
presence of fibrous tissue, usually in the niche of oval window, forming a so-called 
“peristapedial tent” (fibrous tissue may also be present anywhere in mesotympanum 
and epitympanum). 
 
tympanosclerosis, which reflects deposits of hyalinised collagen in the tympanic 
cavity. If it occurs in the tympanic membrane, it is called myringosclerosis. In the 
tympanic cavity, it may be present in any location, visible as focal calcified densities 
in the middle ear cavity, along tendons, also in direct apposition to the ossicular 
chain. 
 
formation of new bone, rarely seen in the tympanic cavity, usually in epitympanum. 
Visible as high density lamellar structures. 
 
Post-inflammatory ossicular chain erosion is rather rare in the case of a non 
cholesteatomatous disease but may seldom occur and will affect first the incus long process 
and lenticular process, followed by stapes head [47]. 
For best diagnostic accuracy on CT, images should be viewed using a correct bone 
window setting (large window width, e.g., 4000 HU; low window level, e.g., 0–200 HU). 
Three distinctive signs should be carefully evaluated on axial CT images in order to 
exclude an ossicular erosion [39]: 
 
 
“ice cream cone” visible in the epitympanum, where the anterior ice cream cone 
consists of the malleus head and the posterior cone is made of the incus body and 
short process; 
 
“two parallel lines” visible in the mesotympanum, where the anterior line represents 
the malleus handle and the posterior line represents the incus long process; 
 
“two dots” visible in the mesotympanum where the lateral dot refers to the lenticular 
process and the medial dot to the stapes head; between the two dots the incudo-
stapedial joint is well visible. 
 

C. Gagliardo, S. Piccinini and P. Feraco 
 
830
 
Figure 11. Chronic otomastoiditis with tympanosclerosis; axial MDCT scan showing non 
cholesteatomatous soft tissue density within the middle ear cavity and mastoid opacification. In this 
case calcific middle ear foci (arrow) is causing ossicular fixation resulting in conductive hearing loss; 
non cholesteatomatous ossicular chain erosion findings are present too. 
Post-inflammatory erosion sometimes involves walls of tympanic cavity. Based on CT 
multiplanar images, the following structures should always be carefully evaluated: bony walls 
of the lateral semicircular canal, bony walls of the tympanic segment of the facial nerve 
channel and the roof of the middle ear cavity (tegmen tympani) [39]. 
 
3.3.2. Chronic Otitis Media with Cholesteatoma 
Occasionally, chronic suppurative otitis media is associated with a cholesteatoma within 
the middle ear. Cholesteatoma consists of squamous epithelium that is trapped within the 
middle ear cavity and mastoid process of the temporal bone. Granulation tissue and ear 
discharge are often associated with secondary infection of the desquamating epithelium [48]. 
In the setting of chronic middle ear inflammation, cholesteatomas arise as the result of 
tympanic membrane retraction or perforation [39]. 
Cholesteatoma can be either congenital (behind an intact tympanic membrane) or 
acquired, though the origins are indistinguishable with histology or imaging. Only the 
location of the lesion on CT/MRI, the clinical history of the patient, and the otologic status of 
the tympanic membrane could give some hints for a differential diagnosis [21]. If untreated, a 
cholesteatoma may progressively enlarge and erode the surrounding structures [45]. 
Since congenital cholesteatomas develop from embryonic epithelial rests, they can be 
located everywhere in the temporal bone from the external auditory channel to the middle ear, 
from the mastoid to the petrous apex or even in the squama of the temporal bone or within the 
tympanic membrane. 
Acquired cholesteatomas are classified in primary and secondary but are uniquely 
localized in the middle ear (see Table 3): 
 
 
“Primary acquired cholesteatomas” (80% of all middle ear cholesteatomas) 
usually develop in the region of the pars flaccida behind an apparently intact 
tympanic membrane; 
 
“Secondary acquired cholesteatomas” (18% of all middle ear cholesteatomas) 
usually develop into the middle ear through a perforated tympanic membrane in the 

Neuroradiology of the Hearing System 
 
831
pars tensa region (rarely the pars flaccida); these cholesteatomas arising from the 
posterior tympanic membrane are likely to produce facial nerve exposure eroding the 
bony wall of the facial nerve canal and to destroy the stapedial suprastructure. 
 
Table 3. Pars flaccida and pars tensa cholesteatomas main features 
 
Pars flaccida cholesteatoma 
(attic or posterior epitympanic cholesteatoma) 
Pars tensa cholesteatomas 
(sinus or posterior mesotympanic cholesteatoma) 
Develop from the upper one-third portion of the 
tympanic membrane (pars flaccida or Shrapnell 
membrane). 
Most often origins through a defect of the lower two-thirds 
portion of the tympanic membrane (pars tensa) 
Soft tissue mass fills the Prussak’s space, medial to 
attic wall and lateral to the ossicles (head of malleus 
and body of incus). 
Soft tissue mass localized in the facial recess and sinus 
tympani of the tympanic cavity and in the mastoid region. 
Erosion of the anterior portion of the lateral 
epitympanic wall is very common. 
Extension of the soft tissue mass starts in the epitympanum 
medial to the ossicles 
Initially ossicles are very often displaced medially. 
Initially ossicles are displaced laterally (head of malleus and 
body of incus). 
Ossicles erosion is frequent (most commonly long 
process of incus). 
Ossicle erosion occurs to incus long process, stapedial 
superstructure and manubrium of malleus. 
 
In elderly patients, a third special kind of cholesteatomas could be diagnosed: external 
auditory channel cholesteatomas. These lesions are subdivided into idiopathic and secondary 
[50]. The first are typically bilateral and located in the floor of the external auditory channel. 
The location and occurrence of the latter depends on the site of the inducing factor. 
One last special group of cholesteatomas are the so called “mural cholesteatoma.” These 
could mimic a mastoidectomy cave since they are the result of extensive lesions of the middle 
ear or of the mastoid which drain their fluid contents into the external auditory channel 
through the tympanic cavity leaving a wide empty cave often referred to as 
“automastoidectomy” [21]. 
 
 
Figure 12. Chronic otomastoiditis with cholesteatoma; coronal MPR from a MDCT scan showing soft 
tissue density within the middle ear cavity (asterisk) with severe thinning of the tegmen tympani (black 
arrow), ossicular chain dislocation and severe erosion (white arrow). 

C. Gagliardo, S. Piccinini and P. Feraco 
 
832
When evaluating CT images for the presence of cholesteatoma (Figure 12), the following 
features should be addressed: ossicle erosion and displacement, bony walls of tegmen 
tympani and lateral semicircular canal, bony walls of tympanic segment and anterior genu of 
the facial nerve, possible extension of cholesteatoma towards sinus tympani and possible 
involvement of oval window niche [21]. 
 
 
 
a 
 
 
b 
Figure 13. Chronic otomastoiditis with cholesteatoma (same patient shown in figure 12); coronal T2-
weighted fast spin echo sequence with fast saturation (a) showing unspecific high signal intensity 
inflammatory tissue in the middle ear cavity (white arrow). A coronal non-echo planar DWI sequence 
(b) well demonstrate the cholesteatoma within the unspecific fluid collection as a bright comma shaped 
lesion (white arrow).  
On MR images (Figure 13), typical cholesteatoma features include bright, hyper-intense 
signal on diffusion-weighted MRI images (low signal on apparent diffusion coefficient maps), 
moderate signal intensity on T2-weighted images (lower than the signal that characterize the 
inflammatory tissue) and lack of enhancement on post-gadolinium T1-weighted sequences 
[21,49-50]. 
Chronic otitis media can cause both intracranial and extracranial complications [51,52]. 
 
The most frequent complications of COM with cholesteatoma are [21]: 
 
 
erosion of the tegmen or sinus plate that could be thinned or completely eroded; 
 
erosion of the labyrinth with fistula formation appreciable as a loss of the 
endochondral bone overlying the labyrinth (labyrinthine fistula occurrence is one of 
the most common complications in chronic otitis media with cholesteatoma); 
 
extension of the cholesteatoma into the petrous pyramid; 
 
erosion of the facial nerve canal commonly resulting in a peripheral facial nerve 
paralysis. 
 

Neuroradiology of the Hearing System 
 
833
Sigmoid sinus thrombosis is a severe complication of chronic middle ear infectious 
diseases. In these cases, a contrast enhanced CT scan is mandatory to demonstrate the typical 
“empty triangle” or “delta” sign: the sigmoid sinus will appear surrounded by the normally 
enhancing dura that delimitate the un-enhancing thrombus inside the dural venous sinus [53]. 
MRI is more sensitive to detect thrombosis and assess intraluminal blood flow, and it may 
even show the involvement of adjacent structures. 
In case of suspected infection/inflammation and/or complications (such as lateral 
semicircular canal fistula), an MRI examination including non-echo planar diffusion-
weighted (non-EP DWI) and post-gadolinium T1-weighted sequences is mandatory. These 
will help differentiating the infection/inflammation from the cholesteatoma and it will show 
the status of the membranous labyrinth. 
Since chronic otitis media with cholesteatoma (including precholesteatomatous states) is 
an aggressive form of otitis, surgical treatment is mandatory because of the higher risk for 
labyrinthine or intracranial complications. 
The differential diagnosis checklist in case of suspected cholesteatomas includes: 
cholesterol granulomas, paragangliomas, schwannomas and facial nerve hemangioma (see 
Table 4). 
 
Table 4. Most common pathologic entities to consider for cholesteatomas  
differential diagnosis 
 
Pathologic 
entities 
Cholesterol granulomas Paragangliomas 
Schwannomas 
(facial nerve and 
geniculate ganglion) 
Facial nerve 
hemangiomas 
MRI 
findings 
- High signal on T1-w 
and T2w. 
- No contrast-
enhancement. 
Nodular contrast-
enhancing mass on the 
cochlear promontory. 
Characteristic 
tubular/oval enhancing 
mass along the 
tympanic segment of 
the facial nerve or of 
the geniculate 
ganglion. 
-Mass with irregular 
poorly defined margins 
-Slightly 
hypointense/isointense 
on T1WI and 
hyperintense on T2WI 
-Bright contrast-
enhancing oval lesions 
on postcontrast images. 
CT findings 
Bony erosion. 
No bony erosion. 
Enlarged facial nerve 
canal and/or 
geniculate fossa. 
-Enlarged facial nerve 
canal and geniculate 
fossa. 
-The ossifying subtype 
causes a characteristic 
“honeycomb” 
morphology. 
Others 
-Blue tympanic 
membrane at otoscopic 
examination. 
- History of surgery or 
recurrent otitis media. 
- Usually DWI does not 
show diffusion 
restriction. 
- Pulsatile mass at 
otoscopic examination. 
Common clinical 
symptom is rhythmic 
thumping in the ear. 
Large tumors 
involving the 
tympanic segment of 
the facial nerve may 
be visible on otoscopic 
examination.  
Primary symptoms are 
facial nerve palsy and 
hearing loss. 
 
 
 

C. Gagliardo, S. Piccinini and P. Feraco 
 
834
3.4. Post-Operative Imaging 
 
Surgery is widely used to treat various middle ear disorders such as chronic otitis media, 
cholesteatoma, otosclerosis, congenital malformations, traumas and tumours. The most 
common cause of failure in middle ear surgery include persistent suppurative process in 
middle ear / mastoid and recurrent and/or residual cholesteatoma [54]. Imaging needs to be 
able to differentiate residual or recurrent disease from granulation tissue, inflammatory tissue 
or fluid within the middle ear cavity and mastoid cavity. The examination of choice for a 
post-surgical follow-up is usually a non-contrast high-resolution temporal bone CT which 
provides information on the exact surgical procedure done and related findings [55-56]. The 
main role of CT is to allow a correct analysis of dense structures (bony tympano-mastoid 
walls, ossicular chain, prosthesis) [42]. Furthermore, CT easily detects an intra-tympanic soft 
tissue and its extension and margins within the postoperative middle ear. However, CT is not 
specific and so differentiation of granulation tissue in the middle ear cavity from other 
commonly encountered soft tissue masses such as cholesteatomas usually requires an MRI 
scan [56]. Despite this, CT is of great help for the assessment of the bony labyrinth and the 
facial nerve canal. 
Conventional MRI scans have low specificity when it comes to differentiating 
granulation tissue from relapsing cholesteatoma [57]. As a matter of fact both the granulation 
tissue and the cholesteatoma show hypointense signal on T1 and hyperintense signal on T2 
making the differentiation rather difficult. Many studies reported improved specificity of 
delayed (30-45 minutes) post-contrast T1-weighted sequences since the granulation tissue is 
poorly vascularized and contrast uptake may occur belatedly [55]. Cholesteatomas are not 
vascularized and so do not enhance: they typically appear bordered by a ring enhancement 
attached to the enhancing mucosa [55]. Diffusion-weighted imaging (DWI) is a helpful and 
effective method for distinguishing cholesteatomas from other soft tissues in post-surgical 
follow-ups; in particular, non-echo planar DWI has been shown to have a higher sensitivity 
and specificity in the diagnosis of postoperative chronic otitis media complications 
differentiating recurrent cholesteatoma from granulation tissue [55, 58]. 
However, De Foer [41] reported that MR imaging for detection of middle ear 
cholesteatoma can be performed by using non-EP DW imaging sequences alone since the 
combined use of DWI and delayed gadolinium-enhanced T1-weighted sequence yielded no 
significant increases in terms of sensitivity, specificity, negative and positive predictive 
values.  
Some non-cholesteatoma lesions that show restricted diffusion have been reported in 
English literature and must be taken into account in the differential diagnosis checklist: 
residual haemorrhage after recent surgery, in ear patches containing silastic sheets or bone 
pate, cerumen located in the external ear canal, cholesterol granuloma and middle ear or 
mastoid abscess [55]. 
Pre-contrast T1-weighted sequences are mandatory to detect lesions with spontaneous 
high T1 signal intensity (cholesterol granuloma, fluid with high protein concentration, 
bleeding and fatty tissue) and to get information about the vascularity of the lesion. Fat 
suppression techniques may result useful too if the lesion is close to a fat containing structure. 
A careful analysis of the T1-weighted pre- and delayed post-contrast, T2-weighted images 
and DWI provide a sensitive and accurate method for differentiating soft tissue lesions. The 

Neuroradiology of the Hearing System 
 
835
most informative approach to imaging of post-surgical middle ear patients is the use of both 
CT and MR imaging examinations [55]. 
 
 
3.5. Otosclerosis 
 
Otosclerosis is an autosomal dominant genetic disease with incomplete clinical 
penetrance and variable expression which involves the human otic capsule [59]. The typical 
clinical onset is in the third decade and is characterized with symptoms of conductive hearing 
loss (CHL) due to the impaired movement of the stapes; the disease is bilateral in a majority 
of cases with a female predilection (F:M ratio of ~2:1) [60]. Patients could also present 
sensorineural hearing loss (SNHL) or mixed hearing loss (MHL) and/or tinnitus [61]. 
Pathogenesis of otosclerosis is likely multifactorial and still incompletely understood: even if 
the genetic component is probably the most significant in determining the slowly progressive 
CHL, both viral (measles virus) and autoimmune (collagen auto-immunity) etiopathogenetic 
hypothesis have been investigated and accredited. Whatever the etiopathogenesis, otosclerosis 
is one of the leading causes of nonsyndromic deafness in adults [62-64]. 
Otosclerosis is an otodystrophy characterized by the replacement of the normal ivory-like 
enchondral bone of the otic capsule by immature and spongy vascular new bone; this process 
of remodeling occurs continuously and accounts for the progressive nature of the disease [65]. 
It is categorised into two types, fenestral and retrofenestral (or cochlear) otosclerosis. 
Retrofenestral otosclerosis rarely occurs without fenestral involvement and is considered a 
continuum of the fenestral otosclerotic process rather than a separate one. Imaging plays an 
important role in the diagnosis and management of otosclerosis. 
In fenestral otosclerosis, demineralized foci of spongy bone typically occur in the region 
located anterior to the oval window (fissula ante fenestram) where a cleft of 
fibrocartilagenous tissue between the inner and middle ear is found (Figure 14). These typical 
demineralised foci location should not be confused with the so called “cochlear cleft” [66] 
that is particularly seen in up to 40% of children as a hypodense cleft in the cochlear otic 
capsule in the region anterior to the oval window; this finding has no pathological implication 
in the absence of a clinical evidence for otosclerosis or osteogenesis imperfecta and represent 
a potential imaging pitfall in children. 
In patients with fenestral oteosclerosis, fixation of the stapes by foci located anterior to 
the oval window is found in 96% of cases. In slightly less than half the cases, demineralised 
foci are also present in other locations (oval window niche 30%, cochlear apex 12%, posterior 
to the oval window 12%); in 7% of cases a round window obliteration is found. Other even 
rarer sites of involvement are the promontory, round window niche and tympanic segment of 
the facial nerve [61]. CT is the tool of choice to investigate the eventual presence of 
otosclerotic lesions and its sensitivity to make the diagnosis was recently estimated as high as 
90–95% [66]. Stapedectomy is used to treat fenestral otosclerosis and is commonly combined 
with the insertion of a stapes prosthesis to restore ossicular chain functionality. CT is useful 
to evaluate the position of radiodense prosthesis (dislocation is a common possible 
complication) and the typical findings of other post-surgical common complications. MRI 
will be useful to identify fibrotic changes in cases of labyrinthitis ossificans (Figure 15) [61]. 
 

C. Gagliardo, S. Piccinini and P. Feraco 
 
836
 
Figure 14. Fenestral otosclerosis; axial MPR from a MDCT scan showing an otospongiosis focus 
(arrow) close to the round window (not shown). 
Retrofenestral (or cochlear) otosclerosis, is much less common but nearly always 
associated with fenestral otosclerosis. Primary cochlear otosclerosis is relatively rare. The 
typical clinical presentation is a bilateral symmetrical SNHL or MHL or a pulsatile tinnitus. 
Demineralized foci of spongy bone are typically seen in the cochlear capsule, which may 
extend around the vestibule, semicircular canals and internal auditory canal (Figure 16). The 
classical imaging appearance of cochlear otosclerosis on CT is a distinctive pericochlear 
hypodense double ring sign (which is also known as the “4th ring of Valvassori”) [61]. 
 
 
 
Figure 15. Labyrinthitis ossificans (arrow) could involve any part of the inner ear, in different grade 
(mild, moderate as shown in the figure, and severe). It is a sequela of an inflammatory process 
spreading into the membranous labyrinth through three ways: hematogenic, meningogenic (as shown in 
the figure), and tympanogenic disseminations. Unusual cause of labyrinth ossification are temporal 
trauma, long standing otosclerosis or tumors. It is a relative contraindication for cochlear implant. 
 

Neuroradiology of the Hearing System 
 
837
 
Figure 16. Cochlear otosclerosis; coronal MPR from CBCT scan showing the demineralized foci 
(arrows) around the basal turn of the cochlea in the otic capsule.  
MRI is rarely used in the case of otosclerosis but is useful to demonstrate the osteolytic 
inflammatory process (during the “acute phase” of the disease) that occurs in the otic capsule 
as a consequence of the otospongiotic process. During this phase, the otospongiotic foci will 
show a T1 shortening on MRI pulse sequences acquired after i.v. injection of gadolinium. 
MRI is also useful to investigate post-surgery complications (intravestibular granuloma, 
intralabyrinthine hemorrhage and bacterial labyrinthitis) [68]. 
Fluorides and cochlear implantation (CI) are used to treat retrofenestral otosclerosis. 
Fluoride therapy may limit the growth of active otosclerotic foci and thereby prevent 
progression of SNHL. CI surgery in patients with otosclerosis may be challenging because of 
the high risk of partial insertion and misplacement of electrode arrays due to the ossification 
of the scala tympani in the basal turn of the cochlea [61]. 
 
 
4. INNER EAR 
 
The inner ear is composed of a membranous labyrinth surrounded by a bony labyrinth. 
The membranous labyrinth consists of utricle, saccule, semicircular canals, 
endolymphatic sac and duct, and cochlear duct [69]. CT and MRI may well demonstrate the 
inner ear structures and their abnormalities. CT has always been the preferred imaging 
modality to delineate the intricate osseous anatomy and malformations of the inner ear, but 
high-resolution MR imaging is used with increasing frequency to study the membranous 
labyrinth and eighth cranial nerve (vestibulocochlear nerve) [70–71].  
 
 
4.1. Malformations 
 
Congenital abnormalities of the inner ear are the most common cause of sensorineural 
hearing loss (SNHL). Inner ear malformations (IEMs) occur as a result of an interruption of 
the development of the ear itself during the first trimester of fetal development. The causes 
may be idiopathic, associated with an inborn genetic error or due to a teratogenic agent 
exposure [72]. The findings may be isolated or related to a specific syndrome (Table 5). 
Patients with congenital inner ear malformations often present with a variable degree of 

C. Gagliardo, S. Piccinini and P. Feraco 
 
838
SNHL. Roughly 50% of cases of congenital SNHL can be linked to a genetic cause, with 
approximately 30% of these considered syndromic and the remaining 70% being 
nonsyndromic [73]. The abnormalities are usually bilateral and symmetric; these patients are 
commonly affected by a profound SNHL that could benefit from the use of hearing aids or 
may have an indication for a cochlear implant (CI). 
 
Table 5. Hereditary syndromes commonly associated with SNHL and  
characteristic imaging findings 
 
Hereditary syndrome associated with SNHL 
Related imaging findings 
Alagille syndrome 
absence of the PSCC with normal appearing LSCC 
Branchio-oto-renal syndrome 
Cochlear hypoplasia (apical turn); abnormal course of the facial 
nerve canal; funnel-shaped IAC with large porus acousticus; 
vestibular dysplasia; SCC hypoplasia; enlargement of the vestibular 
aqueduct; cochlear nerve deficiency; stenosis or atresia of the 
external auditory canal; middle ear and ossicular chain abnormalities; 
Eustachian tube dilation; absence of the stapedius muscle. 
CHARGE syndrome 
Small misshaped pinnae; small middle ear cavities; absence of the 
stapedius muscle; absence of the round and oval windows; 
hypoplasia of the incus and stapes; ossicular chain fixation; abnormal 
course of the tympanic facial nerve; SCC aplasia with associated 
vestibular dysplasia; cochlear nerve deficiency with atresia of the 
cochlear aperture; abnormalities of cochlear partitioning. 
Klippel-Feil syndrome 
Small pinnae with stenotic and downward sloping EEC; deformed 
caput mallei; rudimental incus head; shortness or absence of long 
process and absence of the whole incus; missing stapes head; fixed 
footplate; absence of footplate or of the the whole stapes. 
Pendred syndrome 
Modiolar deficiency; vestibular enlargement; absence of the 
interscalar septum between the upper and middle cochlear turn; 
endolymphatic sac enlargement. 
Waardenburg syndrome 
Vestibular aqueduct enlargement; widening of the upper vestibule; 
IAC hypoplasia; decreased modiolus size; aplasia or hypoplasia of 
the PSCC. 
X-linked hearing loss with stapes gusher 
Enlarged bulbous IACs; widened cochlear aperture (appearing as 
wide as communication between the basal turn of the cochlea and the 
IAC) with absence of the lamina cribrosa; cochlear hypoplasia with 
modiolar deficiency; widening of the bony canal for the labyrinthine 
segment of the facial nerve; dilation of the vestibular aqueducts. 
 
Congenital malformations of the inner ear may be considered in two broad categories 
[74]: (a) malformations with pathologic changes that involve only the membranous labyrinth 
and (b) malformations that involve both the osseous and the membranous labyrinth 
(malformed otic capsules). 
The majority of the causes of congenital hearing loss (80%) belong to the first group. 
There is no gross bony abnormality and, therefore, in these cases HRCT and MR imaging of 
the temporal bone reveal normal findings. The remaining 20% have various malformations 
involving the bony labyrinth and can be radiologically demonstrated by CT and MRI. In 
patients who are candidates for CI surgery, imaging provides preoperative information about 
the inner ear, the vestibulocochlear nerve, and the brain. CT and MRI together, can aid 
decision making about the best management strategy by facilitating the identification and 
characterization of inner ear malformations and any associated neurologic abnormalities. 

Neuroradiology of the Hearing System 
 
839
Formerly, the Jackler et al. classification of IEMs was based on the time of 
developmental arrest during embryogenesis and anatomical development [75]. In 2002 
Sennaroglu et al. [76] modified this classification and grouped the inner ear anomalies by 
their decreasing severity; Michel deformity (complete labyrinth aplasia), cochlear aplasia, 
common cavity, incomplete partition type 1 (IP-I or cystic cochleovestibular malformation), 
cochlear hypoplasia and incomplete partition type 2 (IP-II or classic Mondini deformity). 
There are a variety of IEMs and they all present in a different way: each group has different 
radiological findings that are very important in the management of deaf patients. 
 
4.1.1. Complete Labyrinthine Aplasia (Michel deformity) 
Complete Labyrinthine Aplasia (CLA) is a rare malformation resulting in complete 
aplasia of the membranous labyrinth. It is caused by the developmental arrest of otic placode, 
early during the third week of fetal development [77]. It is the most severe among the 
deformities involving the osseous and membranous labyrinth.  
According to radiological findings [78], three subgroups of CLA are present: 
 
1) CLA with hypoplastic or aplastic petrous bone - In these cases CLA is accompanied 
by hypoplasia or aplasia of the petrous bone.  
2) CLA without otic capsule - In this group of CLA, formation of the petrous bone is 
normal, but the otic capsule is hypoplastic or aplastic. 
3) CLA with otic capsule - Formation of the petrous bone and the otic capsule is normal. 
Only in this group of CLA with otic capsule development, the labyrinthine segment 
of the facial canal is in its normal location.  
 
On CT examinations there is a complete absence of inner ear structures (cochlea, 
vestibule and semicircular canals). The external auditory canal and middle ear cavity are 
usually normal because they do not arise from the otic capsule. Vestibulocochlear nerve is 
aplastic in patients with Michel deformity because they have no otic vesicle development. 
Patients present with a complete SNHL [77]. 
 
4.1.2. Cochlear Aplasia  
Cochlear aplasia is the absence of the cochlea with formation of the utricle, saccule and 
semicircular canals. CT demonstrates an absent cochlea with a partially or completely formed 
vestibule and semicircular canals (SCCs) (Figure 17). 
There are two subgroups [79]: 
 
1) Cochlear aplasia with normal labyrinth - Vestibule and SCCs are normally 
developed; 
2) Cochlear aplasia with a dilated vestibule (CADV) - Vestibule and SCCs show 
dilatation. 
 
It is very important to differentiate CADV from a common cavity (CC) deformity. 
Cochlear aplasia with a normal labyrinth is usually symmetric. In CADV, however, 
asymmetric development may be present; pathology may be due to genetic or environmental 
factors. Otic capsule development is always normal. 

C. Gagliardo, S. Piccinini and P. Feraco 
 
840
4.1.3. Common Cavity Deformity 
A common cavity results from a developmental arrest in the 4th week of gestation and 
accounts for about 25% of all cochlear malformations [71]. CC deformity denotes a 
malformed inner ear in which the vestibule and cochlea are confluent with no internal 
architecture. Theoretically, this structure has cochlear and vestibular neural structures. There 
may be accompanying SCCs or their rudimentary parts. 
It is important to differentiate CC from CAVD because CI in a CC may result in acoustic 
stimulation, whereas in CAVD no functional stimulation will occur with CI.  
 
 
Figure 17. Cochlear aplasia associated with aberrant course of facial nerve; axial MDCT scan at the 
level of the IAC (double headed arrow). The cochlea is absent, a dilated vestibule can be identified 
(asterisk) and the intralabyrinthine segment of CN VII is antero-medially displaced (black arrow). 
 
4.1.4. Cochlear Hypoplasia (CH) 
In this deformity, there is a clear differentiation between cochlea and vestibule. In CH the 
dimensions are less than those of a normal cochlea with various internal architecture 
deformities. But the definition “cochlea with one and a half turns” should be used for 
hypoplasia (particularly type III), rather than for IP-II cochlea.  
Patients have variable SNHL depending on the degree of development of the 
membranous labyrinth. CT shows a small cochlear bud, while the vestibule is usually 
enlarged. The SSCs are malformed in 50% of patients. Four different types of CH have been 
defined [80]: (i) CH-I (Bud-like cochlea), (ii) CH-II (Cystic hypoplastic cochlea), (iii) CH-III 
(Cochlea with less than 2 turns), (iiii) CH-IV (Cochlea with hypoplastic middle and apical 
turns) (Figure 20). 
 
4.1.5. Incomplete Partitions 
In incomplete partition (IP) anomalies there is a clear differentiation between cochlea and 
vestibule, with normal external dimensions and various internal architecture defects. 
Incomplete partitions constitute 41% of IEMs [79, 80] There are three different types of 
incomplete partition groups according to the defect in the modiolus and the interscalar septa: 
 

Neuroradiology of the Hearing System 
 
841
1) IP-I (termed as “cystic cochleovestibular malformation” [79]). These represent 
approximately 20% of IEMs. In this anomaly, there is a clear differentiation between 
cochlea and vestibule. The fact that the vestibule is distinguishable from the cochlea 
makes it possible to differentiate an IP-I from a common cavity. Cochlea is 
accompanied by an enlarged, dilated vestibule (Figure 18). The cribriform area 
between the cochlea and IAC is often defective, and all patients have a large IAC, 
predisposing them to increased risks for meningitis. All patients with IP-I and 
recurrent meningitis who have normal tympanic membranes but fluid filling the 
middle ear and mastoid, should have an exploration of the middle ear with special 
attention to the stapes footplate.  
2) IP-II (classic Mondini deformity). In IP-II, the apical part of the modiolus is 
defective (Figure 19). It is the most common type of cochlear malformation, 
accounting for more than 50% of all cochlear deformities [74]. This anomaly was 
originally described by Carlo Mondini, and together with a minimally dilated 
vestibule and an enlarged vestibular aqueduct (EVA) constitute the triad of the 
Mondini deformity. The term “Mondini” should be used only if the above mentioned 
triad of malformations is present [76,81]. The apical part of the modiolus and the 
corresponding interscalar septa are defective, giving the apex of the cochlea a cystic 
appearance due to the confluence of middle and apical turns. The external 
dimensions of the cochlea are similar to that seen in normal cases. Therefore, it is not 
correct to define this anomaly as a cochlea with “one and a half turns” [80]. 
3) IP-III. In IP-III, cochlea has an interscalar septa but the modiolus is completely 
absent. IP-III cochlear malformation is the type of anomaly present in X-linked 
deafness [82]. It is the rarest form of incomplete partition cases, among 2% of all 
IEMs. The external dimensions of the cochlea (height and diameter) were found to be 
similar to the normal cochlea [83]. 
 
 
Figure 18. Incomplete partition type I (IP-1); axial MDCT scan showing typical cystic appearance of 
the cochlea and vestibule (severe case). The cochlea (black arrow) is featureless because of the absence 
of the modiolus and the interscalar septum; coexists vestibular dilatation (dotted arrow) and a wide IAC 
(asterisk). 

C. Gagliardo, S. Piccinini and P. Feraco 
 
842
 
Figure 19. Incomplete partition type II (IP-II); axial MDCT scan. The apical part of the modiolus is 
defective giving the typical cystic appearance of the apex of the cochlea because of coalescent apical 
and middle turn (arrow). The defective modiolus is appreciable only in proximity of the medial side of 
the basal turn (dotted arrow). Coexists vestibule (asterisk) and vestibular aqueduct (white arrow) 
dilatation. 
4.1.6. Enlarged Vestibular Aqueduct (EVA) 
This describes the presence of an enlarged vestibular aqueduct in the presence of a 
normal cochlea, vestibule and SCCs (Figure 20). The difference between EVA and IP-II is 
that cochlea and vestibule are completely normal on HRCT and MRI [80]. Classically EVA is 
described when the midpoint between posterior labyrinth and operculum is larger than 1.5 
mm on axial sections.  
 
 
Figure 20. Patient with congenital sensorineural hearing loss with an enlarged vestibular aqueduct 
syndrome; axial MDCT scan showing bilateral slight enlargement of vestibular aqueduct and its 
operculum (arrows). 
4.1.7. Malformations of the Vestibule and Semicircular Canals 
The malformed canals are usually short and wide but may be narrow. In extensive 
malformations, the vestibule is dilated and forms a common lumen with the lateral canal. This 
type of abnormality, which has been described as “lateral semicircular canal–vestibule 

Neuroradiology of the Hearing System 
 
843
dysplasia,” may be accompanied by a normal or malformed cochlea, depending on the stage 
of inner ear development at the time of embryologic arrest. 
Aplasia of the semicircular canals is far less common than dysplasia. Absence of all 
semicircular ducts occurs frequently in patients with CHARGE syndrome (a combination of 
coloboma, heart anomalies, choanal atresia, retardation of growth and development, and 
genital and ear anomalies) [84, 85]. Isolated aplasia of the posterior semicircular duct has 
been described in patients with Waardenburg syndrome and Alagille syndrome [84].  
It is essential to perform high-resolution CT to confirm the diagnosis of semicircular 
canal aplasia and to differentiate it from fibrous or calcified obliteration of the canals. 
 
4.1.8. Abnormalities of the Vestibulo-Cochlear Nerve 
With current MRI technique, it is possible to visualize the vestibulo-cochlear nerve. It 
may be normal to hypoplastic or absent (Figure 21). The absence of the cochlear nerve is 
definitely found in cochlear aplasia. While in the case of Michel deformity with absent IAC, 
the complete vestibulo-cochlear nerve is also absent and only facial nerve can be identified. 
An hypoplastic vestibulo-cochlear nerve is particularly important in CC. 
The amount of cochlear nerve fibers determines the hearing level and management 
strategy.  
 
 
Figure 21. Cochlear nerve aplasia; axial 3D CISS sequence at the level of IACs showing right cochlear 
nerve aplasia with ipsilateral small bud cochlea (white arrow with empty head) and vestibular and 
lateral semicircular canal malformation (dotted line with empty head); the right facial nerve (white 
arrow) is antero-medially displaced. The left vestibulocochlear nerve (black arrow and white dotted 
arrow) is unremarkable as well as the visualised sections of the cochlea (basal turn, asterisk). 
 
4.2. Infections 
 
The inner ear infections usually refer to an inflammatory process of the membranous 
labyrinth, which typically manifests as an acute SNHL or vertigo. Labyrinthitis can be 
classified on the basis of the causative agent and can be considered infectious (bacterial, viral, 
or luetic) or non-infectious (trauma, autoimmune, or toxic).  
A number of viruses, including measles, mumps, influenza, rubella, cytomegalovirus, and 
herpes are associated with acquired inner ear pathology [86]. CT and MRI are complementary 
in evaluating patients with labyrinthitis. 

C. Gagliardo, S. Piccinini and P. Feraco 
 
844
On the ot-neuroradiological point of view, three stages are described in labyrinthitis:  
 
1) Acute stage: MR imaging demonstrates strong labyrinthine enhancement on 
gadolinium-enhanced T1-wheighted imaging; however, enhancement is not specific 
for an infectious aetiology because similar findings can be seen with non-infectious 
causes of labyrinthitis. On CT, the inner ear appears normal. 
2) Fibrous stage: on CISS sequences is seen as loss of the normal fluid signal intensity 
in the membranous labyrinth [87]. Contrast-enhanced T1WI may demonstrate 
enhancement of the inner ear, not as strong as that in the acute phase. On CT, the 
inner ear will appear normal. 
3) Ossifying stage: it appears on CT as calcification within the inner ear. MR imaging 
will demonstrate loss of normal hyperintense fluid signal intensity on CISS images, 
without enhancement on contrast-enhanced T1WI [88].  
 
Fibrosing and ossifying labyrinthitis may be indistinguishable on MR imaging, and CT is 
necessary to determine the presence of inner ear ossification. This distinction is particularly 
important in candidates for cochlear implantation (CI) because significant ossification of the 
cochlea can make implantation more difficult, if not impossible, and often results in poor 
functional results [89]. 
When ossification of the labyrinth becomes very advanced, there may be no recognizable 
labyrinthine structures, in which case the chief differential consideration is labyrinthine 
aplasia.  
 
 
4.3. Autoimmune Labyrinthitis 
 
The diagnosis of autoimmune labyrinthitis is usually one of exclusion. Patients typically 
present 
with 
rapidly 
progressive 
fluctuating 
bilateral 
SNHL 
that 
responds 
to 
immunosuppressive agents. Usually these patients also have autoimmune disease such as 
Cogan syndrome, systemic lupus erythematosus, juvenile idiopathic arthritis, Wegener 
granulomatosis, Sjogren syndrome or antiphospholipid syndrome.  
Autoimmune labyrinthitis appears similar to infectious forms of labyrinthitis on MR 
imaging and will demonstrate intense labyrinthine enhancement acutely on postcontrast T1WI 
[87, 88]. The imaging abnormalities often resolve with steroid treatment but may occasionally 
progress to fibrosing or ossifying labyrinthitis.  
 
 
4.4. Imaging in Cochlear Implantation 
 
Cochlear implantation (CI) is indicated for some patients with profound SNHL. 
Preoperative knowledge of the anatomic features of temporal bone may be critical for making 
the decision to perform CI. The majority of cases of SNHL result from degeneration of the 
hair cells in the organ of Corti. CI devices bypass the hair cells and directly stimulate the 
spiral ganglion cells. The electrode is inserted into the scala tympani via the round window or 
through an anteroinferior cochleostomy (Figure 22-23). Both MRI and high resolution CT in 

Neuroradiology of the Hearing System 
 
845
combination can provide surgically relevant information [90]. The goal of preoperative 
imaging is primarily to identify cochlear abnormalities, eighth-nerve deficiency, or anatomic 
variations that influence candidacy, ear selection, surgical approach, and prognosis. Special 
attention should be placed on the patency of the round window, size of the facial recess, 
course of the facial nerve, patency of the cochlea and presence of IAC [91]. 
Cochlear anatomy, as well as the degree of residual hearing, may influence a surgeon’s 
choice of electrode.  
 
 
Figure 22. Cochlear implant visualization on plain film radiograph (Stenvers’ view) performed for 
postoperative evaluation of a cochlear implant lead. 
 
Figure 23. Cochlear implant in a patient with IP-II malformation; the image shows an axial thick-slab 
maximum intensity projection (MIP) reconstruction from a MDCT scan. 
Once, evidence of an absent or severely dysplastic cochlear nerve, as in Michel 
deformity, was considered an absolute contraindication to cochlear implantation in any 

C. Gagliardo, S. Piccinini and P. Feraco 
 
846
patient. More recently, implantation in children with an absent or deficient eighth nerve was 
performed with variable results. A potential alternative treatment for children with cochlear 
nerve deficiency is auditory brainstem implantation [92].  
Other conditions that may preclude CI are active otosclerosis and bilateral acoustic 
schwannomas. Of course, active middle ear infections and fluid in the middle ear cavity 
should be noted to delay surgery. 
 
 
5. IMAGING OF CEREBELLOPONTINE ANGLE AND INTERNAL 
AUDITORY CANAL LESIONS 
 
Lesions of the cerebellopontine angle (CPA) and internal auditory canal (IAC) are 
frequent and represent 6%–10% of all intracranial tumors. Vestibular schwannomas and 
meningiomas are the two most frequent lesions and account for approximately 85%–90% of 
all CPA tumors [93, 94]. The other 10%–15% represents a group of lesions arising from the 
different structures found in these anatomical regions.  
The detection of lesions at CPA and IAC is a diagnostic challenge for neuroradiologists. 
The diagnostic study with the greatest sensitivity and specificity in the evaluation of 
asymmetric sensorineural hearing loss (aSNHL) is MRI. 
Currently, the MRI screening protocol for CPA lesions consists of high-resolution T2-
weighted (T2w) sequences (see Paragraph 1.2 for CISS sequences) in combination with 
contrast-enhanced T1-weighted (GdT1w) sequences. 
T2w has a very high diagnostic accuracy for the presence of CPA lesions in patients with 
aSNHL. However, GdT1w remains mandatory in the detection of smallest vestibular 
schwannomas as well as rare differential diagnoses [95]. 
Common lesions of the IAC/CPA include vestibular schwannomas, meningiomas, 
haemangiomas, lipomas, lymphomas, facial nerve tumours, and aneurysms. 
 
 
5.1. Vestibular Schwannoma 
 
Vestibular schwannoma (VS) is the most frequent tumour in the CPA (70-80% of all 
CPA masses). It arises from the Schwann cells that wrap the vestibulocochlear nerve at the 
glial-Schwann cell junction (Obersteiner-Redlich zone). VS are usually unilateral, not 
hereditary and occur sporadically; bilateral vestibular schwannomas are usually associated 
with a genetic disorder (neurofibromatosis type 2, NF2). 
Most vestibular schwannomas develop from the inferior vestibular nerve in the IAC 
where they grow slowly (Figure 24). Then, eroding the posterior edge of the porus acusticus, 
it may give rise to a round component in the CPA cistern, giving the typical “ice cream on 
cone” pattern (Figure 25). Small, purely intracanalicular schwannomas exist, but may also 
present with a dumbbell extension in the cochlea or vestibule [96]. On the other hand, purely 
intracisternal vestibular schwannomas, without IAC involvement, have a large space to grow 
in before becoming symptomatic, and at imaging are always larger and heterogeneous due to 
cystic components or bleeding [97]. 
 

Neuroradiology of the Hearing System 
 
847
 
Figure 24. Intra-canalar vestibular schwannoma; axial CISS at the level of IACs showing a small mass 
which arise from the modiolus region (empty head arrow) and extends up to two/third of the IAC 
(arrow). 
 
Figure 25. Vestibular schwannoma with typical “ice cream on cone” pattern; axial contrast enhanced 
T1-weighted sequence at the level of IACs showing an enhancing solid mass (arrow, the “ice cream”) 
which arise from the IAC (empty head arrow, the “cone”) and extends into the CPA cistern mass. 
 
 
a 
b 
Figure 26. Giant solid vestibular schwannoma; axial T2-weighted turbo spin echo (a) and axial contrast 
enhanced T1-weighted spin echo (b) sequences at the level of left IACs showing a big solid mass 
extending from the IAC to the CPA cistern causing severe mass effect of the pons (P) and on the 
ipsilateral middle cerebellar peduncle (MCP) and cerebellar hemisphere (CH); the fourth ventricle (IV) 
is evidently compressed too. 

C. Gagliardo, S. Piccinini and P. Feraco 
 
848
With CT, schwannomas are usually isodense and enhance after contrast administration. 
On MRI, they show T1 isointensity and T2 high signal intensity (Figure 26), but appear as a 
hypointense filling defect on T2- weighted high-resolution MR cisternography (CISS 
sequences), and enhance strongly on GdT1w. Enhancement of the adjacent meninges is 
possible in vestibular schwannoma and is not specific nor exclusive for meningiomas [98].  
There are three different MRI appearances of the tumor after Gd-administration: 
homogeneous (50–60%), heterogeneous (30–40%), and cystic (5–15%) [99]. 
MRI may also be used to optimize treatment planning with respect to several features of 
the lesion: (i) the size of the tumor; (ii) the distance between the lateral extremity of the 
intracanalicular portion of the tumor and the fundus because it affects the hearing prognosis 
and may modify the surgical approach; (iii) the intralabyrinthine signal intensity: poor hearing 
prognosis may be predicted by a low T2-signal intensity of labyrinth contents compared to the 
unaffected ear; (iv) the identification of the facial nerve and its position relative to the 
vestibular schwannoma [16].  
 
 
5.2. Meningioma 
 
Meningioma represents the second most frequent (10%– 15%) tumor of the CPA after 
VS [94]. Meningioma arises from arachnoid meningothelial cells and grows slowly in the 
CPA, independently from the internal auditory canal. It is usually located at the posterior 
aspect of the temporal bone or at the premeatal area, from where it can easily extend into the 
IAC, but without enlarging the porus [16]. At CT, meningiomas are hyperdense in 70% of the 
cases, calcified in about 20% and show a frequent adjacent bone reaction including 
hyperostosis and enostotic spur.  
 
 
Figure 27. Skull base meningioma with multi-compartmental extension; axial T2-weighted turbo spin 
echo sequence with fat saturation. Heterogeneous mass with multiple intra-tumoral degenerative cysts 
and peritumoral arachnoid cysts (black asterisks). The tumour invades the pituitary fossa (white arrow) 
causing internal carotids arteries encasement (dotted arrows), the anterior cranial temporal fossa floor 
(white arrow with empty head) and orbital region, and the pontine and PCA cisterns extending into the 
right IAC (white asterisk) with basilar artery encasement (black dotted arrow) and mass effect on the 
pons and infratentorial brain structures with severe compression of the IV ventricle. 

Neuroradiology of the Hearing System 
 
849
Meningiomas are isointense with the cortex on all sequences (Figure 27), and are strongly 
enhanced after i.v. contrast medium injection, usually homogeneously. The “dural tail sign,” 
is particularly frequent in association with meningiomas, but not specific [98] and should 
suggest the diagnosis when observed. 
 
 
5.3. Aneurysms 
 
The vertebral and basilar arteries and some of their branches pass through the CPA 
cistern, where a tortuous segment or ectasia or even an aneurysm can develop. They account 
for a substantial part of non-tumoral lesions of the CPA that can lead to cranial nerves or 
brain stem compression [93]. In this location, intracranial aneurysms can arise from the 
postero-inferior cerebellar artery (PICA), the antero-inferior cerebellar artery (AICA), the 
vertebral artery (VA) or the basilar artery (BA) itself [100]. 
They may mimic vestibular schwannomas, especially on CT, because they appear as well 
defined round lesions that enhance after contrast administration. At MRI, aneurysms without 
internal thrombus have flow voids and pulsation artefacts on all spin echo sequences but 
demonstrate iso-to-high signal intensities and variable patterns of gadolinium uptake on T1-
weighted images when intraluminal thrombus is present. MR angiography should then be 
performed to confirm the diagnosis, detect the parent artery and plan the possible therapeutic 
options. 
 
 
5.4. Epidermoid Cyst 
 
The epidermoid cyst is the third most frequent tumor of the CPA [93]. It is a congenital 
lesion arising from normal epithelial cells included during neural tube closure. It grows from 
the slow desquamation of the stratified keratinised epithelium that lines the cyst. 
These tumors grow slowly, encasing nerves and arteries in the cisterns with a specific 
cauliflower-like outer surface [17]. On CT scans, epidermoid cysts appear hypoattenuating to 
CSF, and have characteristic irregular, lobulated margins. As opposed to an arachnoid cyst, 
epidermoid cysts produce no reaction to the adjacent bone structures.  
With MRI, epidermoid cysts have slightly higher signal intensity than CSF on T1w and 
T2w images. However, based on signal intensity alone, it could be difficult to distinguish 
from arachnoid cysts on these sequences. T2-weighted FLuid Attenuated Inversion Recovery 
(FLAIR) and Diffusion Weighted Imaging (DWI) sequences are well known to allow 
differentiation between epidermoid and arachnoid cysts (Figure 28). DWI offers a finding 
specific for epidermoid cysts by showing a very bright signal [101]. DWI is also crucial in the 
postoperative follow-up as it allows confirmation of the presence of a possible residual 
tumour. 
 

C. Gagliardo, S. Piccinini and P. Feraco 
 
850
 
 
a 
b 
 
c 
Figure 28. Epidermoid cyst; axial T2-weighted (a), contrast-enhanced T1-weighted (b) and echo planar 
DWI (c) sequences at the level of the CPA / pontine cistern. A small lesion with CSF like signal on T2 
and T1+Gd in the right CPA / pontine cistern is shown (arrows). DWI highlights the finding which 
show a typical bright signal (black asterisk) if compared to CSF (white asterisk within the IV ventricle). 
 
5.5. Arachnoid Cyst 
 
An arachnoid cyst is a congenital, benign, intra-arachnoid pouch-like lesion filled with 
normal CSF. It is usually supratentorial, with about 70% being in the temporal fossa, mostly 
on the left side [17], anterior to the temporal poles. Only 10% of arachnoid cysts are located 
in the posterior fossa, where they most commonly develop in the CPA.  
Spontaneous or traumatic intracystic haemorrhage can complicate arachnoid cysts, 
though this is uncommon in the posterior fossa [102].  
At neuroimaging, attenuation and signal intensities of uncomplicated arachnoid cysts 
exactly match those of CSF on all sequences (Figure 29), and do not enhance after contrast 
media administration. The typical complete suppression of signal intensity on FLAIR 
sequence and the lack of diffusion restriction of these lesions on DWI easily help in the 
differential diagnosis with epidermoid cysts. 

Neuroradiology of the Hearing System 
 
851
 
 
a 
b 
Figure 29. Arachnoid cyst; axial T2-weighted with fat-saturation (a) and high resolution CISS (b) 
sequences at the level of IACs. A lesion occupying the right CPA with CSF like signal on all pulse 
sequences is shown (asterisk); the cyst causes mild mass effect on the intracisternal tract of the 
vestibulocochlear nerve. 
 
5.6. Lipochoristomas (Lipomatous Tumors) 
 
Lipochoristomas are benign rare tumors (0.1% of all CPA tumours) that were thought to 
arise from cells of the meninx primitive and thus they were referred to as lipomas of the 
IAC/CPA. Nowadays they are more appropriately characterized as “lipomatous choristomas” 
since they arise from mesenchyme endogenous to the vestibulocochlear nerve [103]. They 
typically appear as homogeneous fatty lesions surrounding and encasing normal adjacent 
neurovascular structures with very dense adhesions, usually asymptomatic. Sometimes they 
may produce symptoms by compressing the adjacent cerebral structures, such as the cranial  
 
 
 
a 
b 
Figure 30. Lipochoristoma; axial CISS (a) and axial contrast-enhanced T1-weighted turbo spin echo 
sequence with fat saturation (b). A small lesion with fat-like signal on all pulse sequences is found 
(arrows) deep into the right IAC. 
 

C. Gagliardo, S. Piccinini and P. Feraco 
 
852
nerves [104]. Lipochoristomas typically show as hypoattenuating lesions on CT with a high 
signal on MRI T1-weighted images (promptly suppressed with fat saturations sequences) and 
no contrast enhancement on T1-weighted images acquired after i.v. administration of contrast 
medium (Figure 30). They usually show an indolent slow growth and conservative 
management with periodic imaging follow-ups is thus recommended. Those lesions which 
have a low fat content usually show an iso- or mildly hypo-intense signal on T1-weighted 
pulse sequences with appreciable signs of contrast enhancement after i.v. administration of 
gadolinium chelate [105]. 
 
 
5.7. Dermoid Cyst 
 
Dermoid cysts result from the congenital inclusion of cutaneous ectoderm. Intracranial 
dermoid cysts are usually supratentorial midline lesions containing a mix of fat, hair, 
calcifications and the products of sebaceous glands and desquamation of a keratinized 
epithelium. Dermoid cysts rarely arise in the CPA, and may be secondary to the caudal 
extension of a parasellar lesion [17]. 
At imaging, a dermoid cyst appears as a well-circumscribed fatty round mass with a thick 
peripheral capsule that may enhance. In case of rupture, the visualisation of fatty T1-
hyperintense droplets in the sulci or a fat-fluid level in the ventricles is highly suggestive of 
the diagnosis. 
 
 
5.8. Chordoma 
 
Chordomas develop from remnants of the notochord and are located within the midline, 
near the clivus, from which they can expand into the CPA. Chondroid chordoma is a 
pathological subtype of chordoma that may arise more laterally in the petrous bone and grow 
directly in the CPA [106]. With CT, chordomas appear hypoattenuating soft-tissue mass 
associated with irregular bone erosion of the clivus. At MR imaging, chordomas usually 
appear as lobulated, large, hyperintense masses on T2w images with septa of low signal 
intensity. Slight enhancement is present.  
 
 
5.9. Intra-Axial Tumors with CPA Involvement 
 
Sometimes, an intra-axial or intraventricular tumor can be large enough to invade the 
CPA or to manifest as a CPA mass. In such a case, the intra-axial origin could almost be 
impossible to define (Figure 31). Diagnosis is difficult, but subtle signs like narrowing of the 
cisterns, irregularity of the tumor-brain interface, and edema are helpful. 
In this context, the most frequent diagnosis includes: pedunculated brainstem glioma, 
choroid plexus papilloma, lymphoma, hemangioblastoma, ependymoma, medulloblastoma, 
and dysembryoplastic neuroepithelial tumor (DNET) [17]. 
 

Neuroradiology of the Hearing System 
 
853
 
Figure 31. Glioblastoma; axial contrast-enhanced T1-weighted turbo spin echo sequence with fat 
saturation demonstrating a mostly solid and enhancing lesion (black asterisk) with some cystic / 
necrotic components (white asterisk) occupying the right CPA. In such a challenging case is not easy to 
understand the intra-axial exophytic nature of the tumor. 
 
6. TRAUMATIC LESIONS OF THE TEMPORAL BONE  
 
All the bones in our body are the result of an adaptation process [107]. The skull is no 
exception of what kind of trade-off the evolution process had to face: it must ensure 
maximum bone strength and resistance to protect its precious content from any external agent 
while maintaining a lightweight to ensure ease of head movements. A fracture, even 
considering the age-related physiological variations of our bones, will result when an external 
force hitting the skull will overcome its intrinsic elastic absorption capacity. 
 
 
6.1. Temporal Bone Fractures 
 
Nowadays, motor vehicle accidents are the most common cause of trauma. Almost two-
thirds of road accidents are associated with head trauma even if the number of sports-, 
assault- and falls-related head trauma has increased in recent years [108, 109]. In severe head 
trauma cases, up to 8% of the patients will present a temporal bone fracture; if the patient has 
a skull fracture the probability that there is also a temporal bone fracture rises up to 22% 
[110]. Since many pathologic conditions could be associated with a temporal bone trauma a 
promptly imaging-based diagnosis is mandatory. 
Temporal bone fractures can occur with or without brain injuries and are classified within 
the skull base traumatic lesions as laterobasal fractures. 
Taking as reference the long axis of the temporal bone, they are historically classified as 
longitudinal, transverse (Figure 32) and mixed fractures (Figure 33) [111, 112]. However, this 
classification result was not always well correlated with the severity of clinical signs and 
symptoms. A new classification that distinguishes the temporal bone fractures in “otic capsule 
sparing” and “otic capsule violating” has been proposed (Table 6) [113]. While “otic capsule 
sparing” fractures are the most common (70-90%), the latter are rare (10-30%) and more 

C. Gagliardo, S. Piccinini and P. Feraco 
 
854
frequently associated with complications such as cerebrospinal fluid leak or fistula, facial 
nerve injury, hearing loss and intracranial complication such as subarachnoid hemorrhage, 
epidural hematoma and meningitis [113-116]. A temporal bone fracture can also be classified 
as petrous or non-petrous [112]. The first, extending to the petrous apex or the otic capsule, is 
more frequently associated with cerebrospinal leak and facial nerve injury. The latter doesn’t 
involve the petrous apex nor the otic capsule but may extend into the tympanic cavity or 
mastoid and is more frequently associated with conductive hearing loss [117]. 
Patients with severe head trauma are often unconscious and, after the emergency room 
evaluation, are commonly hospitalized in a neurosurgery unit. As soon as the patient's 
condition allows it, an otological assessment as well as facial nerve evaluation should be 
performed to facilitate the detection and treatment of potentially correctable middle ear and 
facial nerve injuries [116]. 
 
Table 6. Features commonly associated with “otic capsule sparing” and  
“otic capsule violating” temporal bone fractures 
 
Features 
Kind of fracture 
Otic capsule sparing 
Otic capsule violating 
Frequency 
Common (70-90%) 
relatively rare (10-30%) 
Facial nerve injury 
rare 
frequent (2x) 
Risk to develop CSF leak/fistula 
low risk 
high risk (4x) 
Associated profound sensorineural and/or conductive 
hearing loss 
low risk 
high risk (7x) 
Intracranial complications (subarachnoid hemorrhage, 
epidural hematoma) 
rare 
Frequent 
Risk for meningitis 
low 
higher risk throughout life 
 
 
Figure 32. Transverse temporal bone fracture; axial MDCT scan (head trauma spiral CT protocol with 
1mm thick slices) shows a transverse fracture line involving the right superior semicircular canal 
(arrow). 

Neuroradiology of the Hearing System 
 
855
 
Figure 33. Mixed temporal bone fracture; axial MDCT scan (head trauma spiral CT protocol with 1mm 
thick slices) shows a longitudinal fracture line involving the left temporal bone pyramid base (arrow) 
and a transverse fracture line through the ipsilateral inner ear structures (dotted arrow). 
A high-resolution CT scan is the first-line imaging examination in patients with severe 
head trauma with or without suspected temporal bone injuries. On CT images, fracture lines 
must be differentiated from the so called “pseudofractures.” The latter are normal linear 
structures very commonly seen on cross-sectional images and are related to the temporal bone 
anatomy (small canals) and its relationship with adjacent bones (fine sutures) that can mimic 
temporal bone fractures. If a pseudofracture is suspected, a comparison with the unaffected 
contralateral side may be helpful in the differential diagnosis. Identifying a small fracture line 
is not always easy since most polytrauma patients are studied with generic CT trauma 
protocols (thus slice thickness is rarely less than 1mm as for high resolution temporal bone 
imaging). If a patient arrives in the Radiology Department with a presumptive diagnosis of 
temporal bone fracture because of some typical physical findings (i.e., hemotympanum, 
postauricular ecchymosis and periorbital ecchymosis), an attendant sign of a temporal bone 
fracture could be the opacifications of mastoid cells, tympanic cavity and external auditory 
canal with or without blood-fluid levels. More rarely, pneumocephalus as a sign for an open 
skull base fracture or a brain injury or an extra-axial fluid collection or even small air bubbles 
in the glenoid fossa of the temporomandibular joint could be indirect signs of a temporal bone 
fracture [118]. 
 
 
6.2. Ossicular Injuries 
 
Ossicular injuries are usually related to temporal, occipital or parietal region high energy 
trauma. The ossicular chain is more frequently damaged in longitudinal or mixed fractures of 
the temporal bone while it is rarely involved in patients with transverse fractures and other 
kinds of head trauma. 
The most common CT finding is the dislocation of the ossicular chain. If an ossicular 
injury is suspected, multiplanar reconstructions will be helpful to detect the ossicular chain 
complex; the oval window region should always be carefully evaluated. 

C. Gagliardo, S. Piccinini and P. Feraco 
 
856
Incudo-malleolar and incudo-stapedial joint separation are the most common dislocation 
injuries; both are best seen on axial slices, the first as a gap between the body of incus and 
head of malleus and the latter as gap between the body of incus and head of malleus. The 
whole incudo-malleolar complex dislocation is usually due to an incudo-stapedial joint 
rupture. 
Isolated dislocation of the incus is characterized by the “Y” sign on coronal slices [119] 
and is far more common than the isolated dislocation of the malleus because of the weaker 
ligamentary complex. 
More rare are the dislocation of the stapes into the vestibulum (stapedio-vestibular 
dislocation); in these cases, a perilymphatic fistula is often seen and the identification of small 
air bubbles in the labyrinth could be an indirect sign of it. 
Fractures of the single components of the ossicular chain are very rare and hard to 
identify if high-resolution CT protocols and multiplanar reconstructions are not used. 
 
 
6.3. Contusio Labyrinthi (Labyrinthine Concussion) 
 
In patients with a negative CT scan for temporal bone fractures but typical clinical signs 
of inner ear impairment after a head trauma, a traumatic lesion of the inner ear must be 
suspected. This could occasionally be associated with the opacifications of pneumatized areas 
of the middle ear in an otherwise negative CT examination. The only oto-neuroradiological 
examination that could provide a direct demonstration of such an impairment of the inner ear 
is MRI that could reveal an hyperintense intra-labyrinthine bleeding on T1-weighted 
sequences (Figure 34) with enhancement on involved inner ear structures on T1-weighted 
sequences performed after i.v. contrast administration (labyrinthine contusion or concussion). 
In such cases the risk of fibrosis and ossification of the labyrinth is possible but less frequent 
than in cases with transverse fractures of the temporal bone [120]. 
 
 
Figure 34. Labyrinthine concussion; axial T1-weighted spin echo sequence shows a small spot of T1 
shortening (arrow) due to intra-labyrinthine haemorrhage in a patient with unremarkable CT 
examination after a head trauma. 

Neuroradiology of the Hearing System 
 
857
6.4. Post Traumatic Hearing Loss 
 
Sensorineural, conductive, or mixed hearing loss may all occur after a head trauma 
involving the temporal bone. After a trauma, use of a systematic approach to explore the main 
functional components of auditory pathways is highly suggested [121]. Since conductive 
hearing loss (CHL) is caused by the impairment of the ossicular chain, high-resolution CT 
will be the best imaging examination to investigate what part of it has been affected and how 
(dislocation or fracture). In cases of sensorineural hearing loss (SNHL), high resolution CT 
scan is still useful to identify indirect signs of inner ear impairment such as pneumolabyrinth 
and perilymphatic fistula, but it's not useful to detect a labyrinthine haemorrhage (see 
labyrinthine concussion paragraph) or brain axonal shearing injuries along the central 
auditory pathways. In these cases MRI is the more exhaustive neuroradiological examination 
to perform. 
 
 
6.5. Facial Nerve Injury 
 
Trauma (blunt, penetrating and iatrogenic) is the second most frequent cause of facial 
palsy; Bell’s palsy is the most common and is still a diagnosis of exclusion [122, 123]. Most 
of the post-traumatic facial nerve injuries are caused by temporal bone fractures. Even if “otic 
capsule violating” fractures are relatively rare, they are those more commonly associated with 
facial nerve injury. Blunt trauma usually leads to nerve compression and subsequent edema 
and contusion. Post traumatic facial nerve transection is very rare. Even if most temporal 
bone injuries do not require an urgent surgical intervention, it has been demonstrated that in 
cases with a facial nerve injury, the earlier the facial nerve decompression is performed, the 
better the chances of a good recovery since bone fragments can prevent axonal regrowth 
[123]. Brodie and colleagues, analyzing 820 temporal bone fractures, identified the severity 
and the delay of onset as the two most important prognostic factors in recovery of post-
traumatic facial paralysis [124]. 
To identify a facial nerve injury, the whole course of the nerve must be analyzed. On high 
resolution CT images, multiplanar reconstruction (MPR) will be extremely helpful for the 
identification of facial nerve canal post-traumatic lesions. Geniculate ganglion region, either 
in association with a transverse or an anterior longitudinal fracture, is the most common 
localization of traumatic facial nerve injury [124]; coronal is the one best plane to identify 
such a lesion. Lesions of the posterior genu or of the descending branch are commonly 
associated with a posterior longitudinal fracture; sagittal is the best imaging plane for a 
correct diagnosis. MRI is more sensible in investigating soft tissues and so is more useful in 
showing the damaged nerve at any level from the brainstem to the fundus of the internal 
auditory canal. 
 
 
6.6. Vascular Injuries (Carotid Canal and Jugular Gulf Impairment) 
 
The complex anatomy that characterizes the skull base and the temporal bone leads to the 
risk of injury also to vascular structures that pass through and which are in strict contact with 
nerby bony structures. 

C. Gagliardo, S. Piccinini and P. Feraco 
 
858
 
Figure 35. Post-traumatic internal carotid artery impairment; CT angiography (CTA) in a patient with 
multiple facial skeleton and skull base fractures following a severe head trauma. Both ICA canals are 
impaired with inhomogeneous intravascular enhancement and abnormal vessel contour of both ICAs 
(arrows). A brain MRI scan performed a few hours later revealed typical watershed territory stroke 
signs. Note the filling defect of the left jugular gulf (asterisk) as indirect sign of a post-traumatic 
traumatic dural venous sinus thrombosis (see Figure 36). 
 
Figure 36. Post-traumatic dural venous sinus thrombosis; axial contrast enhanced T1-weighted turbo 
field echo sequence (same patient shown in Figure 35) further confirms the left jugular gulf thrombosis: 
normal enhancing vessel wall surrounding the nonenhancing thrombosed lumen (“delta sign”). 
The internal carotid artery (ICA) enters the skull passing through the carotid canal and its 
petrous segment is located in the petrous part of the temporal bone. The carotid canal should 
be always carefully evaluated since patients with fractures that extend to it are at an increased 
risk for carotid artery injury. Complications associated with carotid artery injuries are 
associated with a worse prognosis and include vessel wall damage (Figure 35) such as 
dissection, transection or pseudoaneurysm but also complete occlusion and development of 

Neuroradiology of the Hearing System 
 
859
post-traumatic arteriovenous fistulas. CT angiography should be always performed when 
fractures involving the carotid canal are identified [118]. A brain MRI examination could be 
helpful to identify vascular brain injuries even in hyper acute phase by the use of Diffusion 
Weighted pulse sequences. 
Veins could be injured after a blunt or penetrating head trauma as well. MDCT 
venography allowed the identification of traumatic dural venous sinus thrombosis in more 
than 40% of patients with skull fractures extending to a dural venous sinus or jugular bulb 
(Figure 36) [125]. Dural venous sinus thrombosis is also one of the unsuspected causes of 
delayed intracerebral hemorrhage following head trauma with fractures but delayed sinus 
thrombosis can occur even in the absence of skull fracture [126]. 
 
 
7. PETROUS APEX LESIONS AND OTHER LESIONS OF THE  
TEMPORAL BONE  
 
Petrous apex lesions are usually an incidental finding while scanning the head with other 
indications [127]. However, it isn’t uncommon that petrous apex lesions presented with nerve 
palsy, especially of the abducens nerve (6th cranial nerve) due to its proximity to the Dorello 
canal, next to petroclival fissure. Between the lateral and central skull base, petrous apex is 
located antero-medially to the inner ear with greater wing of the sphenoid and clivus as 
medial margins. It is in close relationship with Meckel cave, cavernous sinus, foramen 
lacerum, Eustachian tube and internal carotid artery (ICA) [128]. CT and MRI are 
complementary for differential diagnosis [129]. 
 
 
7.1. Leave-Me-Alone Lesions 
 
Leave-me-alone lesions are the most frequent incidental findings and they include 
asymmetric pneumatization (Figure 37), asymmetric fatty marrow, trapped fluid effusion and 
variant of petrous apex ossification in the child population. The main imaging characteristic 
of this type of lesion is the preservation of bone margins and intra-lesion osseous septa. They 
usually do not require any imaging follow-ups [128, 130]. 
 
 
Figure 37. Asymmetric petrous apex pneumatization; axial MDCT scan showing a big air filled cell 
within the left petrous apex (asterisk). 

C. Gagliardo, S. Piccinini and P. Feraco 
 
860
7.2. Infections and Inflammatory Diseases 
 
In adulthood, leave-me-alone lesions differential diagnosis is mainly represented by 
cholesterol granuloma (60%). Conversely to asymmetric fatty marrow, cholesterol granuloma 
is not suppressed with fat-saturation sequences, with a persisting hyperintense signal on T1 
and T2 weighted images. Actually, cholesterol crystals are made by hemoglobin catabolism in 
a long course chronic inflammation process. Rarely does trapped fluid of the petrous apex 
effusion show slight hyperintensity on T1-weighted imaging due to proteinaceous material; in 
this case a 2-3 months follow-up imaging is recommended [131]. Mucocele should be also 
mentioned as T1-hyperintense petrous apex lesions in relation to its mucoid content, always 
considering the rarity of the lesions [132]. 
Trapped fluid effusion is a sterile retained fluid collection in a pneumatized petrous apex, 
whereas petrous apicitis is a suppurative infection usually extended from severe 
otomastoiditis or invasive sinusitis (Figure 38). On CT scan, opacification of the petrous air 
cells has blurred margins and could be combined with demineralization or erosion of the 
adjacent bone [128]. On MR imaging, fatty marrow has an inhomogeneous signal on T1 and 
on fat suppressed T2 images. Enhancement is usually intense after i.v. contrast 
administration, differently from trapped fluid effusion which has thin linear peripheral rim 
enhancement. Adjacent structures can be involved in uncontrolled infections leading to 
meningitis, thrombophlebitis or empyema. Nowadays, Gradenigo syndrome (characterized by 
the triad of suppurative otitis media, pain in the distribution of the trigeminal nerve, and 
abducens nerve palsy) or complicated petrous apicitis is extremely rare due to the wide use of 
antibiotics [133]. 
 
 
Figure 38. Petrous apicitis; axial T2-weighted turbo spin echo with fat saturation revealing an 
inhomogeneous fluid collection within the right petrous apex (asterisk). 
Pseudotumor is a rare locally aggressive inflammatory disease of the soft tissues adjacent 
to petrous apex; differential diagnosis based on imaging characteristics is extremely difficult 
because of its intense enhancement after Gd administration that make it prone to be confused 
with tumors or invasive infections. Moreover, sometimes it presents bony erosion. A biopsy 
is necessary for the diagnosis [134]. 
 

Neuroradiology of the Hearing System 
 
861
7.3. Neoplasms 
 
The most frequent neoplastic lesion located at the petrous apex is chondrosarcoma, 
representing 6% of all skull base tumors. It is a well-differentiated tumor arising from the 
cartilaginous remnants of the petro-occipital fissure. It can be associated with Ollier disease 
or Maffucci syndrome and occasionally with Paget disease. A CT scan is extremely useful to 
assess tumor characteristics because more than 50% of them presented calcifications of the 
matrix, usually rounded or curvilinear. The margins are lobulated and the adjacent bone is not 
sclerotic. On MRI, chondrosarcoma enhance avidly, whether homogeneously or not. In the 
differential diagnosis of a lytic enhancing soft-tissue mass centered on petrous apex, it should 
be considered chordoma that is usually more central located, and rhabdomyosarcoma in 
childhood population. Ewing sarcoma should also be included even if it is more rare [128, 
130]. 
 
 
7.4. Non-Neoplastic Lesions 
 
Fibrous-osseous lesions of the petrous apex are usually expressions of a widespread 
disease of the skull. Paget is a disease of the aged population, whereas fibrous dysplasia is 
typical of children and young adults. Fibrous dysplasia can be mono or polyostotic. Even if 
temporal bone is frequently affected, petrous apex involvement is uncommon. On MR 
imaging, monostotic disease can mimic malignancies due to avid enhancement after Gd 
contrast administration. Complications could be caused by foraminal narrowing [130]. 
Aneurysmal bone cyst involving temporal bone is extremely rare. Imaging appearance is 
similar to aneurysmal bone cyst involving any other osseous structures of the body and is 
characterized by bubble and multiloculated appearance, which demonstrates fluid-fluid levels 
and septal contrast enhancement on MR imaging. Histopathological confirmation is needed to 
exclude giant cell tumor of the bone [135]. 
Petrous apex is the election site of meningocele in intracranial idiopathic hypertension 
(IHH), due to chronic increased CSF pulsations. Meningocele area well-defined CSF-filled 
lesions laterally to the Meckel cave, sometimes containing Gassner ganglion. The treatment 
depends essentially on the presence of CSF leaks in relation to an extended scalloping of the 
bone [136]. In children, meningoceles located at the petrous apex combine usually with 
sphenoid wing aplasia in NF1 [137]. 
Petrous internal carotid artery aneurysms are mainly asymptomatic, so they are 
recognized as incidental expanding lesions of the petrous apex with smooth margins and no 
bony erosion. CTA or MRA is required for the diagnosis [128]. 
Cholesteatoma is the second most frequent petrous apex lesion after cholesterol 
granuloma; it can be congenital or acquired, respectively arising from epithelial remnants in 
petrous apex (congenital) or spreading from tympanomastoid region (acquired). Imaging 
characteristics of cholesteatoma are the same all over the temporal bone region (see 
Paragraph 3.3) [138]. 
 
 
 

C. Gagliardo, S. Piccinini and P. Feraco 
 
862
7.5. Other Lesions of the Temporal Bone 
 
There are multiple pathological conditions affecting temporal bone not only at the petrous 
apex but also the temporal squama, the mastoid or the otic capsule. The main differential 
diagnosis is between tumoral or non-tumoral lesions. 
 
7.5.1. Tumor-Like Lesions 
Epidermoid or dermoid cysts are typically located at CPA, as extra-axial intradural 
masses; rarely can they have an intradiploic location all over the skull (0.25% of all 
intracranial tumors), also affecting the temporal squama [139]. 
Acquired cholesteatoma usually affects the structures around the tympanic cavity; 
congenital origin of the lesion should be considered when an isolated mass is noted above the 
labyrinthine compartment or in the mastoid [140]. 
Cavitating otosclerosis could be mentioned as a tumor-like lesion when presenting as a 
focal well-circumscribed mass. Representing an inactive foci of cochlear otosclerosis, it has a 
fluid-filled cystic MR appearance, anteriorly located to the IAC or in the pericochlear region. 
If it is associated with enhancing areas after Gd administration, it should be a mixed active 
and inactive otosclerosis focus and differentiated from more aggressive lytic lesions (i.e.: 
metastasis) [141]. 
 
7.5.2. Tumors 
Temporal bone paragangliomas, Fisch’s classification is based on tumor location and is 
strictly related to surgical management (Table 7) [142]. Paraganglioma is recognized as a 
locally aggressive highly vascular neuroendocrine tumor with bone, soft tissue and nerve 
involvement. They can be solitary or multicentric, sporadic or familial. On CT scan, it is 
usually noted as a lytic lesion near the jugular foramen, except for Class A and B 
paragangliomas that are limited to tympanic cavity [143]. Typical MR appearance is a salt-
and-pepper lesion on T2w sequence, due to intratumoral flow-voids of vascular origin. An 
angiographic study should be always performed; CT angiography (CTA) or contrast enhanced 
- MR angiography (CE-MRA) demonstrate arterial vascularization of the lesion (Figure 39), 
because paragangliomas are also visualized in the early phase of the injection. Time of Flight 
(TOF) imaging is useful to recognize intralesional arterial vessels, if the dimension of the 
tumor are adequate to allow it. Digital Subtraction Angiography (DSA) should be necessary 
only in the presurgical stage. Nevertheless, the real extension of the disease is better 
delineated in the fat sat T1-w imaging acquired after Gd injection; volumetric acquisition is 
recommended in presurgical MR studies. PET/CT remains the gold-standard imaging for non 
invasive diagnosis [144, 145]. 
A differential diagnosis of temporal bone paraganglioma includes other lytic bone 
destructive lesions such as metastasis, plasmocytoma or endolymphatic sac tumor. 
Metastasis can be located everywhere in the temporal bone. Bony destruction and 
multiple locations in the body are the best clues for diagnosis. If the abnormal growing cells 
composing the mass are plasma cells, it is called plasmacytoma. Plasmacytoma can be 
solitary, or as a part of myeloma with different treatment and prognosis. Metastasis and 
plasmacytoma have similar MRI features, showing an intense enhancing mass with irregular 
margins. Histopathological confirmation is needed [127]. 
 

Neuroradiology of the Hearing System 
 
863
Table 7. Fish Classification of temporal bone paragangliomas 
 
Class A (glomus tympanicum) 
Limited to mesotympanum. 
Class B (glomus hypotympanicum) 
Limited to hypotympanum, mesotympanum, and mastoid without erosion of 
jugular bulb. 
Class C 
Involvement and destruction of infralabyrinthine and apical compartments.  
Sub- classification by degree of carotid canal erosion: 
 
C1: no invasion of carotid; destruction of jugular bulb/foramen; 
 
C2: invasion of vertical carotid canal between foramen and bend; 
 
C3: invasion along horizontal carotid canal; 
 
C4: invasion of foramen lacerum and along carotid into cavernous sinus. 
Class D 
Intracranial extension (De, extradural; Di, intradural): 
 
De1: up to 2cm dural displacement; 
 
De2: more than 2cm dural displacement; 
 
Di1: up to 2cm intradural extension; 
 
Di2: more than 2cm intradural extension. 
 
 
Figure 39. Paraganglioma; coronal MPR from a 3D contrast-enhanced T1-weighted turbo filed echo 
with fat saturation sequence revealing a lively enhancing lesion in the infralabyrinthine region of the 
right inner ear (arrow). 
 
Figure 40. Nasopharyngeal squamous cell carcinoma; axial T2-weighted fast spin echo sequence with 
fat saturation showing a solid mass (arrow) extending through the pharyngotympanic tube (auditory 
tube) and infiltrating clivus bone structures with signs of petrous apex involvement (asterisk). 

C. Gagliardo, S. Piccinini and P. Feraco 
 
864
Carcinoma arising from nasopharynx (Figure 40), pinna or EAC could extend into the 
temporal bone; in relation to the original location of the tumor, they could infiltrate the 
temporal bone anteriorly or laterally. Conversely, endolymphatic sac tumor is a rare low-
grade papillary adenocarcinoma centered on the vestibular aqueduct, eroding through the 
posterior limit of the temporal bone; it is characterized by spiculae at the erosion margin on 
CT imaging and T1-shortening areas before Gd administration on MR imaging [145]. 
Intraosseous meningioma, schwannoma and hemangioma are extremely uncommon. 
Intraosseous meningioma has a mixed sclerotic and lytic appearance on CT scan and thick 
meningeal enhancement after Gd administration on MRI. Intraosseous schwannoma are a 
well-defined lytic lesion, homogeneously enhancing after Gd injection on MRI. Intraosseous 
hemangioma could have a trabeculated or honeycomb appearance on CT scan and a 
heterogeneous contrast enhancement, increasing during MRI scanning time [128-131]. 
 
 
8. FACIAL NERVE 
 
The VII cranial nerve (CN VII) contains two distinct roots: a motor root to the muscles of 
the face and scalp (including platysma, buccinator, stapedius, stylohyoid, and posterior belly 
of the digastric), and a mixed motor-sensory root to the salivary glands and to taste receptors 
of the tongue. Facial nerves also carry special visceral efferent motor fibers (SVE). It can be 
divided in multiple segments [146, 147]: 
 
1) Intra-axial segment: the facial nucleus is located antero-laterally in the pontine 
tegmentum and nerve fibers run postero-laterally, turning around abducens nucleus 
to exit at the lateral aspect of the ponto-medullary junction. Facial colliculus is a 
bulge on the IV ventricle floor representing the nerve turn around abducens nucleus, 
and it is clearly visible on MRI except in cases of nerve hypo/aplasia [148]. 
2) Cisternal segment: on MR high resolution T2w imaging (CISS sequences, see 
Paragraph 1.2), the cisternal segment is depicted running from ponto-medullary 
junction to the porus acusticus, crossing CPA anteriorly located to the eighth cranial 
nerve [147, 149]. 
3) Intra-temporal segment: the seventh cranial nerve crosses the petrous bone entering 
the IAC and exiting through stylomastoid foramen in the extra-cranial soft tissues 
[147]. It can be further subdivided in 4 segments: 
a) Intra-canalicular segment: CISS imaging perfectly resolves IAC content (CN 
VII-VIII and their divisions); facial nerve is antero-superiorly located in the IAC. 
At the fundus, it is separated from the inferiorly running cochlear nerve by crista 
falciformis and from the posteriorly running superior vestibular nerve by Bill's 
bar, both visible on HRCT scan [149-151]. 
b) Labyrinthine segment: it is the narrowest (<0.7 mm diameter) and shortest part 
of the bony facial canal running antero-laterally from the fundus to the 
geniculate fossa, superiorly to the cochlea. Great superficial petrosal nerve 
(GSPN) is the first facial branch and it exits from the geniculate ganglion 
carrying the preganglionic parasympathetic fibers of the superior salivary 

Neuroradiology of the Hearing System 
 
865
nucleus through Vidian canal to the pterygopalatine ganglion and then to the 
lacrimal gland [147, 152]. 
c) Tympanic segment: from the geniculate fossa, the nerve makes a 75° turn and 
runs adjacent to the tympanic cavity directing posteriorly to the second (or 
posterior) genu. This segment runs inferiorly to the lateral semicircular canal, 
helpful landmark, and superiorly to the stapes, located immediately before the 
second genu [149, 153]. 
d) Mastoid segment: at the pyramidal process, the nerve makes a 95°-125° turn 
(second genu) directing inferiorly to the stylomastoid foramen. The mastoid 
segment has a vertical orientation, posteriorly to the tympanic cavity. Two 
branches arise from this segment, stapedius nerve superiorly and chorda tympani 
inferiorly, respectively carrying motor and special sensory (taste), and 
parasympathetic (to salivary glands) fibers [147]. 
4) Extracranial segment through the stylomastoid foramen, the nerve enters the parotid 
glands where it divides in many branches to temporofacial and cervicofacial 
territories [147]. 
 
Table 8. Classification of facial nerve lesions 
 
Aetiology 
Lesions 
Preferred imaging 
modality 
Distinguishing features 
Tumours 
Schwannoma 
MRI 
Enhancing lesions extending into the geniculate ganglion (along the 
course of the facial nerve). 
Perineural tumor 
spread 
MRI 
Extension of a known tumor along the course of facial nerve from 
mastoid segment. 
Infectious 
Ramsay Hunt 
Syndrome 
MRI 
Abnormal enhancement of facial nerve with classic clinical features 
(otalgia, vesicles, and facial paralysis). 
Lyme Disease 
MRI 
Abnormal enhancement of facial nerve with white matter lesions, 
meningeal enhancement, and classical clinical symptoms (erythema 
migrans, radiculoneuritis, and arthritis). 
Aetiology 
Lesions 
Preferred imaging 
modality 
Distinguishing features 
 
Otitis media 
CT 
Middle ear opacification causing facial nerve canal erosion. 
Cholesteatoma 
CT 
Middle ear opacification causing facial nerve canal erosion. 
Idiopathic 
Bell palsy 
MRI (atypical cases) 
Abnormal facial nerve enhancement with suggestive clinical 
symptoms. 
Sarcoidosis 
MRI 
Abnormal facial nerve enhancement with basal cisterns 
leptomeningeal and dural enhancement. 
Traumatic 
Temporal bone 
fracture 
CT 
Fracture extending to the facial nerve canal. 
Vascular 
Hemifacial spasm 
MRI 
Vascular loop at the root extizone of the facial nerve. 
Hemangioma or 
venous 
malformations 
MRI/CT 
Enhancing lesion at the geniculate ganglion with bony spicules. 
Congenital 
Moebius 
MRI 
Absent or hypotrophic facial colliculi, cisternal/intra-canalicular 
facial segment hypo/aplasia. 
Aberrant course 
CT 
Variable intra-temporal segments course. 
Pontine 
lesions 
Infarct 
MRI 
Intra-axial T2 hyperintense lesion with diffusion restriction in acute 
phase. 
Multiple sclerosis 
MRI 
Multiple T2 hyperintense lesions satisfying revisited McDonald’s 
criteria. 
Cavernous 
hemangioma 
MRI 
“Popcorn”-like appearance on T2 with susceptibility artefacts on 
T2*. 

C. Gagliardo, S. Piccinini and P. Feraco 
 
866
Sensory and parasympathetic components are provided by nervus intermedius (Wrisberg 
nerve). General visceral efferent parasympathetic motor fibers arise in the superior salivary 
nucleus and emerge from the ponto-medullary junction as a distinct nerve from facial 
division. It joins motor root either as it emerges from the ponto-medullary junction or at the 
meatus of the IAC. Occasionally, it can be depicted by using CISS sequences as a 5th thin 
nerve along the acoustic canal [146, 149-154]. 
A small component of general sensory afferent fibers arise from geniculate ganglion to 
supply trigeminal (CN V3) innervation of the concha, the EAC and the external surface of the 
tympanic membrane [146]. 
The major blood supply of intra-temporal facial nerve is the middle meningeal artery 
(superficial petrosal and stylomastoid branches), except for the intra-canalicular segment 
which is in the anterior-inferior cerebellar artery (AICA) territory (labyrinthine branch) [146]. 
The facial nerve can be affected by many different pathologies (Table 8) [155] resulting 
in weakness or paralysis and dystonias or spasm [156, 157]. 
 
 
8.1. Facial Paralysis 
 
Depending on which facial nerve segment is involved, different clinical manifestations 
are recognized. The most critical step is discerning central to peripheral facial palsy. Timing 
of the onset, patient age and associated symptoms can narrow the differential diagnosis and 
can guide the choice of the imaging modality and treatment [155-157]. 
 
8.1.1. Central Facial Palsy 
Among central processes affecting the seventh cranial nerve, cerebrovascular accidents 
(CVAs) are by far the most frequent [158]. Middle cerebral artery (MCA) or anterior cerebral 
artery (ACA) stroke can cause contralateral facial paralysis, sometimes sparing the forehead 
region, in relation to the mixed contra/ipsilateral innervation. Stroke is a time-critical illness 
and it should be recognized promptly for treatment. Pontine infarcts instead cause an 
ipsilateral paresis of the face; they usually are lacunar infarcts representing approximately 7% 
of all ischemic strokes and caused by basilar perforating arteries occlusion. Depending on the 
blood supplying perforating arteries, pontine infarcts can be distinguished in ventral 
(anteromedial and anterolateral pontine arteries) and tegmental (short circumferential 
arteries), with different associated symptoms [159, 160]. MRI with DWI sequence is the gold-
standard neuroradiological diagnostic tool for stroke imaging [160]. 
Brain tumors (primary or metastatic), multiple sclerosis and tumor-like lesions, as 
cavernous hemangiomas, should be also included as causes of facial central paralysis if 
located in or by the pons. Whole-brain MRI scan is required in central lesions [147]. 
However, lesions affecting the facial nerve distal to the decussation in the caudal pons 
can mimic peripheral facial palsy, despite the lesion etiology [161]. 
 
8.1.2. Peripheral Facial Palsy 
The most common cause of peripheral facial paralysis is Bell's palsy. Imaging studies are 
not indicated in the early phase of the disease. If full recovery does not occur after 9 months 
from the onset, MR imaging is recommended. An earlier imaging study is also indicated if it 
is associated with other neurological signs or a parotid mass. On MR imaging, abnormal 

Neuroradiology of the Hearing System 
 
867
facial nerve enhancement after Gd administration is present; sometimes, mainly during the 
acute phase, the nerve is swollen, and it can mimic a schwannoma [162]. If the patient does 
not progressively recover, follow-up MRI is recommended [163]. 
 
 
Figure 41. Facial nerve neuritis in a patient with varicella zoster virus reactivation; axial MPR from a 
3D T1-weighted fast spoiled gradient echo showing enhancement of the labyrinthine (empty head 
arrow), tympanic/geniculate ganglion (arrow) and mastoid (dotted arrow) segments of the facial nerve. 
Facial nerve enhancement is also present in other inflammatory or infectious diseases that 
should be included in the imaging-based differential diagnosis checklist even if clinical signs 
and symptoms should always guide imaging features [150]. Neurosarcoidosis has many 
different features on a brain MRI, but it is usually characterized by dural and leptomeningeal 
involvement at the level of basal cisterns, showing bright enhancement after contrast 
administration [164]. Ramsay Hunt syndrome and Lyme disease are infections of the CNS, 
respectively caused by Varicella-Zoster virus reactivation (Figure 41) and Borrelia 
burgdorferi. Ramsay Hunt syndrome is usually clinically evident (otalgia, vesicles and facial 
paralysis), but if MR imaging is acquired, enhancement of the facial nucleus could be 
observed in association with facial nerve enhancement. Lyme disease is also usually clinically 
diagnosed, but a whole-brain MRI scan is recommended due to the CNS involvement for that 
meningoencephalitis [165-167]. 
Facial nerve enhancement could even be present in facial nerve involvement by 
pathologies of adjacent structures, such as otitis media, malignant otitis externa, bone 
fractures or cholesteatoma. Considering that these diseases are used to primarily affect the 
temporal bone, a CT scan is adequate for the diagnosis [168, 169]. 
 
8.1.3. Facial Nerve Tumors 
Many different neoplastic processes can affect facial nerves; CN VII schwannomas can 
affect any portion along the course of the nerve. They usually develop at the geniculate 
ganglion, but also along the tympanic or mastoid segment. They are well-circumscribed soft 
tissue masses, scalloping the adjacent bone structure, with avid enhancement after Gd 
administration except for cystic changes [170]. The most frequent site of origin of 
hemangiomas is the perigeniculate region, followed by IAC; this kind of lesions arise from 
the vascular plexus surrounding the facial nerve, and demonstrate a typical CT scan 
appearance with bony spicules and progressive avid Gd enhancement on MRI as for any 
venous malformation [170, 171]. 

C. Gagliardo, S. Piccinini and P. Feraco 
 
868
Most commonly CN VII is infiltrated or compressed by lesions arising in the IAC 
(schwannomas, lipomas, choristomas, hemangiomas), in the middle ear (cholesteatomas, 
adenomas, paragangliomas, paragangliomas), in the parotid (tumors), or in the EAC 
(carcinomas) [168, 169]. 
Parotid tumors, especially adenoid cystic carcinoma (70-75%), frequently shows 
perineural tumoral spread (PTS); on MRI imaging, the facial nerve is swollen, clearly 
hyperintense on T2 fat saturated sequences due to edema, and avidly enhances after Gd 
administration. Conversely to inflammatory disease, PTS starts from extra-temporal segment 
and could eventually cause enlargement of the bony facial canal [172]. 
 
8.1.4. Congenital Malformations 
Congenital malformation of the facial nerve can be clinically asymptomatic, but in some 
cases it determines long-standing facial weakness from childhood [148]. In aural atresia, 
second genu, mastoid segment and stylomastoid foramen can be displaced anteriorly and 
laterally [173]. Congenital inner ear malformation can be associated with an aberrant course 
of facial nerve, most frequently the labyrinthine segment (Figure 17), but also tympanic or 
mastoid depending on the associated malformations, especially of EAC or ossicular chain 
[152]. In congenital malformations of temporal bone, an HRCT scan is actually always 
recommended before surgical intervention [174, 175]. 
Congenital facial paralysis is also caused by abnormalities of facial nucleus in a variety 
of syndromes, including Moebius, DiGeorge, Goldenhar, Charge, trisomy 13, and trisomy 18. 
On MR imaging, CISS sequences (see paragraph 1.2) can easily demonstrate the hypo/aplasia 
of the nerve in the IAC or the brainstem abnormalities [147-150]. 
Bony dehiscence of the facial nerve usually occurs at the tympanic segment at the oval 
window level, predisposing the nerve to damaging from inflammatory processes of the 
middle ear, cholesteatoma or otologic surgery. High resolution CT scan is indicated in these 
cases [176]. 
 
 
8.2. Facial Dystonias 
 
MR imaging is indicated in hemifacial spasm or twitching to exclude vascular 
encroaching of the cisternal segment; when a loop of the AICA, PICA, basilar artery or 
vertebral artery encroaches on the nerve transitional zone (TZ), the result could be an 
involuntary, unilateral, sudden contraction of facial muscles. The CN VII TZ is the zone of 
transition between central and peripheral myelination, which is located at 1-2 mm from the 
brainstem nerve root exit zone (REZ) [1]. Volumetric heavily T2-weighted (CISS) imaging is 
the gold-standard in demonstrating neural-vascular conflicts. MRI is recommended [147, 
170]. 
 
 
REFERENCES 
 
[1] 
Dahmani-Causse, M., Marx, M., Deguine, O., Fraysse, B., Lepage, B. and Escudé, 
B.(2011). Morphologic examination of the temporal bone by cone beam computed 

Neuroradiology of the Hearing System 
 
869
tomography: comparison with multislice helical computed tomography. Eur Ann 
Otorhinolaryngol Head Neck Dis,128(V):230-235. 
[2] 
Ruivo, J., Mermuys, K., Bacher, K., Kuhweide R., Offeciers E. and Casselman, JW. 
(2009). Cone beam computed tomography, a low-dose imaging technique in the 
postoperative assessment of cochlear implantation. Otol Neurotol, 30 (III):299-303.  
[3] 
Kurzweg, T., Dalchow, CV., Bremke, M., Majdani, O., Kureck, I., Knecht, R., Werner, 
J.A. and Teymoortash, A. (2010). The value of digital volume tomography in assessing 
the position of cochlear implant arrays in temporal bone specimens. Ear Hear, 
31(III):413-419. 
[4] 
Zou, J., Koivisto, J., Lähelmä, J., Aarnisalo, A., Wolff, J. and Pyykkö, I. (2015). 
Imaging Optimization of Temporal Bones With Cochlear Implant Using a High-
resolution Cone Beam CT and the Corresponding Effective Dose. Ann Otol Rhinol 
Laryngol, 124(VI):466-473.  
[5] 
Peltonen, L., Aarnisalo, A. A., Käser, Y., Kortesniemi, M. K., Robinson, S., 
Suomalainen, A., Jero, J. (2009). Cone-beam computed tomography: a new method for 
imaging of the temporal bone. Acta Radiol. 50(5):543-8. 
[6] 
Buric, N., Jovanovic, G., and Tijanic, M. (2013). Usefulness of cone-beam CT for 
presurgical assessment of keratoma (cholesteatoma) of the maxillary sinus, Head & 
Neck,; 35(VII), E221-E225. 
[7] 
Rafferty, M.A., Siewerdsen, J.H., Chan, Y., Daly, M.J., Moseley, D.J., Jaffray, D.A. 
and Irish, J.C.(2006). Intraoperative cone-beam CT for guidance of temporal bone 
surgery. Otolaryngol Head Neck Surg,134(V):801-808. 
[8] 
Redfors, Y.D., Gröndahl, H.G., Hellgren, J., Lindfors, N., Nilsson, I., and Möller, C. 
(2012). Otosclerosis: Anatomy and pathology in the temporal bone assessed by multi-
slice and cone-beam CT. Otology & Neurotology, 33:922-927. 
[9] 
Liktor, B., Révész, P., Csomor, P., Gerlinger, I., Sziklai, I. and Karosi, T. (2014). 
Diagnostic value of cone-beam CT in histologically confirmed otosclerosis. Eur Arch 
Otorhinolaryngol, 271:2131-2138. 
[10] Miracle, A.C. and Mukherji, S.K. (2009). Conebeam CT of the head and neck, part 1: 
physical principles. AJNR Am J Neuroradiol, 30(VI):1088-1095.  
[11] Miracle, A.C. and Mukherji, S.K. (2009). Conebeam CT of the head and neck, part 2: 
clinical applications. AJNR Am J Neuroradiol, 30(VII):1285-1292.  
[12] Juliano, A.F., Ginat, D.T. and Moonis, G. (2013). Imaging review of the temporal 
bone: part I. Anatomy and inflammatory and neoplastic processes. Radiology, 
269(I):17-33.  
[13] Juliano, A.F., Ginat, D.T. and Moonis, G.(2015). Imaging Review of the Temporal 
Bone: Part II. Traumatic, Postoperative, and Noninflammatory Nonneoplastic 
Conditions. Radiology, 276(III):655-672. 
[14] Juliano, A.F., Ting, E.Y., Mingkwansook, V., Hamberg, L.M. and Curtin, H.D. (2016). 
Vestibular Aqueduct Measurements in the 45° Oblique (Pöschl) Plane. AJNR Am J 
Neuroradiol, 37(VII):1331-1337.  

C. Gagliardo, S. Piccinini and P. Feraco 
 
870
[15] Marsot-Dupuch K. and Meyer, B. (2001). Cochlear implant assessment: imaging 
issues. Eur J Radiol, 40(II):119-132. 
[16] Bonneville, F., Savatovsky and J., Chiras, J. (2007). Imaging of cerebellopontine angle 
lesions: an update. Part 1: enhancing extra-axial lesions. Eur Radiol, 17(X):2472-2482.  
[17] Bonneville, F., Savatovsky and J., Chiras, J. (2007). Imaging of cerebellopontine angle 
lesions: an update. Part 2: intra-axial lesions, skull base lesions that may invade the 
CPA region, and non-enhancing extra-axial lesions. Eur Radiol, 17(XI):2908-2920.  
[18] Verbist, B.M.(2012). Imaging of sensorineural hearing loss: a pattern-based approach 
to diseases of the inner ear and cerebellopontine angle. Insights Imaging, 3(II):139-53. 
[19] Martines, F., Dispenza, F., Gagliardo, C., Martines, E. and Bentivegna, D. (2011). 
Sudden sensorineural hearing loss as prodromal symptom of anterior inferior 
cerebellar artery infarction. ORL J Otorhinolaryngol Relat Spec, 73(III):137-40.  
[20] Chavhan, G.B., Babyn, P.S., Jankharia, B.G., Cheng, H.L. and Shroff, M.M.(2008). 
Steady-state MR imaging sequences: physics, classification, and clinical applications. 
Radiographics, 28(IV):1147-1160.  
[21] Baráth, K., Huber, A.M., Stämpfli, P., Varga, Z. and Kollias, S. (2011). 
Neuroradiology of cholesteatomas. AJNR Am J Neuroradiol. 32(II):221-229.  
[22] Yeakley, J.W and Jahrsdoerfer, R.A. (1996). CT evaluation of congenital aural atresia: 
what radiologists and surgeons need to know. J Comp Ass Tomogr, 20:724-731. 
[23] Langman, J. (1981). Ear In: Medial Embriology, 4th edn. Williams & Wilkins, 
Baltimore, pp 303-304. 
[24] Grandis, J. R., Curtin, H. D., Yu, V.L. (1995). Necrotizing (malignant) external otitis: 
prospective comparison of CT and MR imaging in diagnosis and follow-up. Radiology, 
196(2):499-504.  
[25] Jee, W.H., Choi, K.H., Choe, B.Y., Park, J.M. and Shinn, K.S. (1996). Fibrous 
dysplasia: MR imaging characteristics with radiopathologic correlation. AJR Am J 
Roentgenol, 167:1523-1527. 
[26] Kemink, J.L. and Gaham, M.D. (1982). Osteomas and esostoses of the external 
auditory canal-medial and surgical manegement. J Otolaryngol, 11:101-106. 
Heilbrun, M. E., Salzman, K. L., Glastonbury, C. M., Harnsberger, H. R., Kennedy, R. J., 
Shelton, C. (2003). External auditory canal cholesteatoma: clinical and imaging 
spectrum. Am J Neuroradiol., Apr;24(4):751-6.  
[27] Persaud, R. A., Hajioff, D., Thevasagayam, M. S., Wareing, M. J., Wright, A. (2004). 
Keratosis obturans and external ear canal cholesteatoma: how and why we should 
distinguish between these conditions. Clin Otolaryngol Allied Sci., 29(6):577-81. 
Gillespie, M.B., Francis, H.W., Chee, N. and Eisele, D.W. (2001). Squamous cell 
carcinoma of the temporal bone: a radiographic-pathologic correlation. Arch 
Otolaryngol head NeckSurg, 127:803-807. 
[28] Breau, R.L., Gardner, E.K. and Dornhoffer, J.L. (2002). Cancer of the external 
auditory canal and temporal bone. Curr Oncol Rep, 4:76-80. 
[29] Luers, J.C. and Hüttenbrink, K.B. (2016). Surgical anatomy and pathology of the 
middle ear. J Anat. 228(II):338-353.  

Neuroradiology of the Hearing System 
 
871
[30] Skrzat, J., Kozerska, M., Wroński, S., Tarasiu, J. and Walocha, J. (2015). Volume 
rendering of the tympanic cavity from micro-CT data. Folia Med Cracov, 55(IV):81-
89. 
[31] Bartel-Friedrich, S. and Wulke, C. (2007). Classification and diagnosis of ear 
malformations. GMS Current Topics in Otorhinolaryngology – Head and Neck 
Surgery, Vol. 6, ISSN 1865-1011. 
[32] Esteves, S.D., Silva, A.P., Coutinho, M.B., Abrunhosa, J.M. and Almeida e Sousa, C. 
(2014). Congenital defects of the middle ear uncommon cause of pediatric hearing 
loss. Braz J Otorhinolaryngol, 80(III):251-256. 
[33] Zeifer, B., Sabini, P. and Sonne, J. (2000). Congenital absence of the oval window: 
radiologic diagnosis and associated anomalies. AJNR Am J Neuroradiol, 21(II):322-
327. 
[34] Teunissen, B. and Cremers, CW. (1991). Surgery for congenital stapes ankylosis with 
an associated congenital ossicular chain anomaly. Int J Pediatr Otorhinolaryngol, 
21(III):217-226. 
[35] Kösling, S., Schneider-Möbius, C., König, E. and Meister, E.F. (1997). 
Computertomographie bei Kindern und Jugendlichen mit Verdacht auf eine 
Felsenbeinmissbildung. Radiologe, 37:971–976. 
[36] Heikkinen, T. and Chonmaitree, T. (2003). Importance of Respiratory Viruses in Acute 
Otitis Media. Clin Microbiol Rev, 16(II): 230–241. 
[37] Trojanowska, A., Drop, A., Trojanowski, P., Rosińska-Bogusiewicz, K., Klatka, J., and 
Bobek-Billewicz, B. (2012). External and middle ear diseases: radiological diagnosis 
based on clinical signs and symptoms. Insights Imaging, 3(I): 33–48. 
[38] Maroldi, R., Farina, D., Palvarini, L., Marconi, A., Gadola, E., Menni, K. and 
Battaglia, G. (2001). Computed tomography and magnetic resonance imaging of 
pathologic conditions of the middle ear. Eur J Radiol,40(II):78-93. 
[39] Rettig, E. and Tunkel, D.E. (2014). Contemporary concepts in management of acute 
otitis media in children. Otolaryngol Clin North Am, 47(V):651-672.  
[40] Anbarasu, A., Chandrasekaran, K. and Balakrishnan, S. (2012). Soft tissue attenuation 
in middle ear on HRCT: Pictorial review. Indian J Radiol Imaging, 22(IV):298-304. 
[41] Saat, R., Laulajainen-Hongisto, A.H., Mahmood, G., Lempinen, L.J., Aarnisalo, A.A., 
Markkola and A.T., Jero, J.P. (2015). MR imaging features of acute mastoiditis and 
their clinical relevance. AJNR Am J Neuroradiol. 36(II):361-7.  
[42] Platzek, I. Kitzler, H. H., Gudziol, V. Laniado, M., Hahn G. (2014). Magnetic 
resonance 
imaging 
in 
acute 
mastoiditis. 
Acta 
Radiol 
Short 
Rep.3(2):2047981614523415.  
[43] Morris, P,. (2012). Chronic suppurative otitis media. BMJ Clin Evid. 6;2012. pii: 0507.  
[44] Silva, M.N., Muller, S., Selaimen, F.A., Oliveira, D.S., Rosito, L.P. and Costa, 
S.S.(2013). Tomographic evaluation of the contralateral ear in patients with severe 
chronic otitis media. Braz J Otorhinolaryngol, 79(IV):475-479.  
[45] Swartz, J.D., Wolfson, R.J., Marlowe, F.I. and Popky, G.L. (1985). Postinflammatory 
ossicular fixation: CT analysis with surgical correlation. Radiology. 154(III):697-700. 

C. Gagliardo, S. Piccinini and P. Feraco 
 
872
[46] Viswanatha, B., Sarojamma and Roopashree T,J. (2013). Mastoid cholesteatoma: a 
result of metaplasia. Indian J Otolaryngol Head Neck Surg. 65(III):665-669.  
[47] Dubach, P. and Häusler, R.(2008). External auditory canal cholesteatoma: 
reassessment of and amendments to its categorization, pathogenesis, and treatment in 
34 patients. Otol Neurotol, 29:941– 948. 
[48] De Foer, B., Vercruysse, J.P., Bernaerts, A., Meersschaert, J., Kenis, C., Pouillon, M., 
De Beuckeleer, L., Michiels, J., Bogaerts, K., Deckers, F., Somers, T., Hermans, R., 
Offeciers, E. and Casselman, J.W. (2010). Middle ear cholesteatoma: non-echo-planar 
diffusion-weighted MR imaging versus delayed gadolinium-enhanced T1-weighted 
MR imaging--value in detection. Radiology. 255(III):866-872.  
[49] Wallis, S., Atkinson, H. and Coatesworth, A.P.(2015). Chronic otitis media. Postgrad 
Med. 127(IV):391-395.  
[50] Smith, J.A. and Danner, C.J. (2006). Complications of chronic otitis media and 
cholesteatoma. Otolaryngol Clin North Am, 39(VI):1237-1255. 
[51] Penido Nde, O., Toledo, R.N., Silveira, P.A., Munhoz, M.S., Testa, J.R. and Cruz, 
O.L.(2007). Sigmoid sinus thrombosis associated to chronic otitis media. Braz J 
Otorhinolaryngol, 73(II):165-170. 
[52] Chatterjee, P., Khanna, S. and Talukdar, R. (2015). Role of High Resolution Computed 
Tomography of Mastoids in Planning Surgery for Chronic Suppurative Otitis Media. 
Indian J Otolaryngol Head Neck Surg, 67(III):275-80. 
[53] Khater, N. H., Fahmy, H. S., El Shahat, H. M., Kater, A. M. (2015). Chronic 
inflammatory middle ear disease: Postoperative CT and MRI findings. The Egyptian 
Journal of Radiology and Nuclear Medicine, 46(III):629-638. 
[54] Williams, M.T. and Ayache, D. (2004). Imaging of the postoperative middle ear. Eur 
Radiol, 14(III):482-495.  
[55] Toyama, C., da Costa-Leite, C., Filho, I.S.B., de Brito-Neto R.V., Bento, R.F., Cerri, 
G.G. and Gebrim, E.M.M.S. (2008). The role of magnetic resonance imaging in the 
postoperative management of cholesteatomas. Braz J Otorhinolaryngol, 74(V):693-
696. 
[56] Dündar, Y., Akcan, F.A., Dilli A, Tatar E, Korkmaz H, Özdek A. (2015). Does 
Diffusion-Weighted MR Imaging Change the Follow-Up Strategy in Cases with 
Residual Cholesteatoma? J Int Adv Otol. 11(1):58-62.  
[57] House, J.W. Otosclerosis. In: Cummings, C.W., Fredickson, J.M., Harker, L.A., 
Krause, C.J., Schuller, D.E., eds. Otolaryngology Head and Neck Surgery. 3rd. ed. St. 
Louis, MO; Mosby: 3126–3135. 
[58] Levin, G., Fabian, P. and Stahle, J. (1988). Incidence of otosclerosis. Am J Otol, 
9(IV):299–301. 
[59] Purohit, B., Hermans, R. and Op de beeck, K.(2014). Imaging in otosclerosis: A 
pictorial review. Insights into Imaging, 5(II):245-252.  
[60] Rudic, M., Keogh, I., Wagner, R., Wilkinson, E., Kiros, N., Ferrary, E., Sterkers, O., 
Bozorg-Grayeli, A., Zarkovic, K. and Zarkovic, N. (2015). The pathophysiology of 
otosclerosis: Review of current research. Hearing research, 330: 51-56. 

Neuroradiology of the Hearing System 
 
873
[61] Chole, R.A. and McKenna, M. Pathophysiology of otosclerosis. Otology & 
neurotology: official publication of the American Otological Society, American 
Neurotology Society [and] European Academy of Otology and Neurotology. 22 (II): 
249-257. 
[62] Niedermeyer, H.P. and Arnold, W. (2002). Etiopathogenesis of otosclerosis. ORL, 
64:114–119. 
[63] Schwartz, J.D. and Mukherji, S.K. (2009): The Inner Ear and Otodystrophies. In: 
Swartz, J.D., Loevner, L.A. (eds.) Imaging of the Temporal Bone, 4th edn. Thieme, 
New York, pp 298. 
[64] Chadwell, J.B., Halsted, M.J., Choo, D.I., Greinwald, J.H. and Benton, C. (2004). The 
cochlear cleft. AJNR Am J Neuroradiol, 25:21–24. 
[65] Lagleyre, S., Sorrentino, T., Calmels, M.N., Shin, Y.J., Escudé, B., Deguine, O. and 
Fraysse, B. (2009). Reliability of high-resolution CT scan in diagnosis of otosclerosis. 
Otol neurotol, 30(VIII):1152–1159. 
[66] Rangheard, A.S., Marsot-Dupuch, K., Mark, A.S., Meyer, B. and Tubiana, J.M. 
(2001). Postoperative complications in otospongiosis: usefulness of MR imaging. 
AJNR Am J Neuroradiol, 22(VI):1171–1178. 
[67] Kenna, M.A. (1990). Embriology and developmental anatomy of the ear. In: 
Bluestone, C.D., Stool, S.E., Scheetz, M.D. (eds.) Pediatric Otolaryngology. 
Philadelphia: WB Saunders: 77-87. 
[68] Parry, D.A., Booth, T. and Roland, P.S. (2005). Advantages of magnetic resonance 
imaging over computed tomography in preoperative evaluation of pediatric cochlear 
implant candidates. Otol Neurotol, 26(V): 976–982. 
[69] Casselman, J.W., Offeciers, E.F., De Foer, B., Govaerts, P., Kuhweide, R. and Somers, 
T. (2001). CT and MR imaging of congenital abnormalities of the inner ear and 
internal auditory canal. Eur J Radiol, 40(II): 94–104. 
[70] Brookhauser PE. (1993). Genetic hearing loss. In: Johnson, J.T., Kohut, R.I., Pillsbury, 
H.C., Tardy, M.E. (eds.) Head and Neck Surgery Otolaringology. Philadelphia: 
Lippicott:1754-1766. 
[71] Lalwani, A.K., Castelein, C.M. (1999). Cracking the auditory genetic code: 
nonsyndromic hereditary hearing impairment. Am J Otol Jan, 20:115–132.  
[72] Varsha, M. J., Shantanu K. G. and Ravi, K. K. (2012). Jitender R, E. C. Vinay Kumar. 
CT and MR Imaging of the Inner Ear and Brain in Children with Congenital 
Sensorineural Hearing Loss. RadioGraphics, 32:683–698. 
[73] Jackler, R.K., Luxford, W.M. and House, W.F. (1987). Congenital malformations of 
the inner ear: a classification based on organogenesis. Laryngoscope, 97: 2-14. 
[74] Sennaroglu, L. and Saatci, I. (2002). A new classification for cochleovestibular 
malformations. Laryngoscope, 112: 2230-41. 
[75] Ozgen, B., Oguz, K.K., Atas, A. and Sennaroglu, L. (2009). Complete labyrinthine 
aplasia: clinical and radiological findings with review of the literature. AJNR Am J 
Neuroradiol, 30: 774-780. 

C. Gagliardo, S. Piccinini and P. Feraco 
 
874
[76] Sennaroglu, L. (2016). Histopathology of inner ear malformations: Do we have enough 
evidence to explain pathophysiology? Cochlear Implants Int; 17:3-20. 
[77] Sennaroğlu, L. and Bajin, M.D. (2017). Classification and Current Management of 
Inner Ear Malformations. Balkan Med J, 34:397-411. 
[78] Sennaroglu, L. and Saatci, I. (2004). Unpartitioned versus incompletely partitioned 
cochleae: radiologic differentiation. Otol Neurotol, 25:520-529. 
[79] Lo, W.W. (1999). What is a 'Mondini' and what difference does a name make? AJNR 
Am J Neuroradiol, 20:1442-1444. 
[80] Nance, W.E., Setleff, R., McLeod, A., Sweeney, A., Cooper, C. and McConnell, F. 
(1971). X-linked mixed deafness with congenital fixation of the stapedial footplate and 
perilymphatic gusher. Birth Defects Orig Artic Ser, 7:64-69. 
[81] Sennaroglu, L., Sarac, S. and Ergin, T. (2006). Surgical results of cochlear 
implantation in malformed cochlea. Otol Neurotol, 27:615-623. 
[82] Huang, B.Y., Zdanski, C. and Castillo, M.(2012). Pediatric Sensorineural Hearing 
Loss, Part 2: Syndromic and Acquired Causes AJNR Am J Neuroradiol, 33:399–406. 
[83] Choo, D.I., Tawfik, K.O., Martin, D.M. and Raphael, Y. (2017). Inner ear 
manifestations in CHARGE: Abnormalities, treatments, animal models, and progress 
toward treatments in auditory and vestibular structures. Am J Med Genet. 175(C):439–
449. 
[84] McKenna, M.J. (1997). Measles, mumps, and sensorineural hearing loss. Ann NY Acad 
Sci, 830:291–298. 
[85] Hegarty, J. L., Patel, S., Fischbein, N., Jackler, R.K., Lalwani, A.K. (2002). The value 
of enhanced magnetic resonance imaging in the evaluation of endocochlear disease. 
Laryngoscope, 112(1):8-17.  
[86] Lemmerling, M. M., De Foer, B., Verbist, B. M., VandeVyver, V. (2009). Imaging of 
inflammatory and infectious diseases in the temporal bone. Neuroimaging Clin N Am, 
19:321–337. 
[87] Waltzman, S. B., Fisher, S. G., Niparko, J. K., Cohen, N. L. (1995). Predictors of 
postoperative performance with cochlear implants. Ann Otol Rhinol Laryngol Suppl, 
165:15–18. 
[88] Digge, P., Solanki, R. N., Shah, D. C., Vishwakarma. R., Kumar, S. (2016). Imaging 
Modality of Choice for Pre-Operative Cochlear Imaging: HRCT vs. MRI Temporal 
Bone. Journal of Clinical and Diagnostic Research. 10(X): TC01-TC04. 
[89] Young, J., Ryan, M,E. and Young, N.M. (2014). Preoperative Imaging of 
Sensorineural Hearing Loss in Pediatric Candidates for Cochlear Implantation. 
RadioGraphics, 34:E133–E149. 
[90] Young, N. M., Kim, F. M., Ryan, M. E., Tournis, E., Yaras, S. (2012). Pediatric 
cochlear implantation of children with eighth nerve deficiency. Int J Pediatr 
Otorhinolaryngol, 76(X):1442–1448. 
[91] Bonneville, F., Sarrazin, J. L., Marsot-Dupuch, K., Iffenecker, C., Cordoliani, Y. S., 
Doyon, D., Bonneville, J. F. (2001). Unusual lesions of the cerebellopontine angle: a 
segmental approach. Radiographics, 21:419–438. 

Neuroradiology of the Hearing System 
 
875
[92] Sarrazin, J.L. (2006). Infratentorial tumors. J Radiol, 87:748–763. 
[93] Hentschel, M.A., Kunst, H.P.M., Rovers, M.M., Steens, S.C.A. (2018). Diagnostic 
accuracy of high-resolution T2-weighted MRI vs contrast-enhanced T1-weighted MRI 
to screen for cerebellopontine angle lesions in symptomatic patients. Clinical 
Otolaryngology, 43:805–811. 
[94] Salzman, K. L., Davidson, H. C., Harnsberger, H. R., Glastonbury, C. M., Wiggins, R. 
H., Ellul, S., Shelton, C. (2001). Dumbbell schwannomas of the internal auditory 
canal. AJNR Am J Neuroradiol, 22:1368–1376. 
[95] Gagliardo, C., Martines, F., Bencivinni, F., La Tona, G., Lo Casto, A. and Midiri, M. 
(2013). Intratumoral haemorrhage causing an unusual clinical presentation of a 
vestibular schwannoma. Neuroradiol J. 26(I):30-34. 
[96] Guermazi, A., Lafitte, F., Miaux, Y., Adem, C., Bonneville, J. F., Chiras, J. (2005). 
The dural tail sign-beyond meningioma. Clin Radiol, 60:171–188. 
[97] Gomez-Brouchet, A., Delisle, M. B., Cognard, C., Bonafe, A., Charlet, J. P., Deguine, 
O., Fraysse, B. (2001). Vestibular schwannomas: correlations between magnetic 
resonance imaging and histopathologic appearance. Otol Neurotol, 22:79–86. 
[98] Papanagiotou, P., Grunwald, I. Q., Politi, M., Struffert, T., Ahlhelm, F., Reith, W. 
(2006).Vascular anomalies of the cerebellopontine angle. Radiologe, 46:216–223. 
[99] Liu, P., Saida, Y., Yoshioka, H. and Itai, Y. (2003). MR imaging of epidermoids at the 
cerebellopontine angle. Magn Reson Med Sci, 2:109–115. 
[100] Ikeda, H., Deinsberger, W. and Boker, D.K. (2000). Petroclival arachnoid cyst 
presenting with spontaneous intracystic haemorrhage-case presentation. Acta 
Neurochir (Wien), 142:1317–1318. 
[101] Scangas, G., Remenschneider, A. and Santos, F. (2015) Lipochoristoma of the Internal 
Auditory Canal. J Neurol Surg Rep, 76(I): e52–e54. 
[102] Sade, B., Mohr, G. and Dufour, J.J.(2005). Cerebellopontine angle lipoma presenting 
with hemifacial spasm: case report and review of the literature. J Otolaryngol, 34:270–
273. 
[103] Wu, S.S., Lo, W.W., Tschirhart, D.L., Slattery, W.H. 3rd, Carberry, J.N. and 
Brackmann, D.E.(2003). Lipochoristomas (lipomatous tumors) of the acoustic nerve. 
Arch Pathol Lab Med, 127(XI):1475-1479. 
[104] Mohanty, P. P., Pasricha, R., Datta, N. R., Jain, M. (2003). Primary chondroid 
chordoma of the petrous part of the temporal bone. Clin Oncol (R Coll Radiol),15:365–
366. 
[105] Currey, J.D. (2003). How well are bones designed to resist fracture? J Bone Miner Res, 
18:591–598. 
[106] Gagliardo, C., La Tona, G., Iovane, A. (2014). “Trauma cranico nello sport” in 
“Principi di diagnostica per immagini in medicina dello sport”; Iovane, A.; Solarino, 
M.; Sutera, R.; Edises, ISBN: 9788879598132 January 2014. 
[107]  Saraiya, P.V. and Aygun, N. (2009) Temporal bone fractures. Emerg Radiol, 16:255–
265. 

C. Gagliardo, S. Piccinini and P. Feraco 
 
876
[108] Zarandy M. M., Rutka, J. (2010). Diseases of the Inner Ear doi: 10.1007/978-3-642-
05058-9_5, © Springer-Verlag Berlin Heidelberg 2010. 
[109] Gurdjian, E.S., Lissner, H.R. (1946). Deformation of the skull in head injury studied 
by “stress coat” technique: quantitative determinations. Surg Gynecol Obstet, 83:219–
233 
[110] Ishman, S.L. and Friedland, D.R. (2004). Temporal bone fractures: traditional 
classification and clinical relevance. Laryngoscope, 114(X):1734-1741. 
[111] Dahiya, R., Keller, J.D., Litofsky, N.S., Bankey, P.E., Bonassar, L.J. and Megerian, 
C.A. (1999). Temporal bone fractures: otic capsule sparing versus otic capsule 
violating clinical and radiographic considerations. J Trauma, 47(VI):1079–1083. 
[112] Sudhoff, H., Linthicum and F.H. Jr. (2003). Temporal bone fracture and latent 
meningitis: temporal bone histopathology study of the month. Otol Neurotol 
24(III):521-522. 
[113] Gross, M., Yaacov, A.B. and Eliashar, R. (2003). Cochlear involvement in a temporal 
bone fracture. Otol Neurotol, 24(VI): 958–959. 
[114] Lancaster, J.L., Alderson, D.J. and Curley, J.W. (1999). Otological complications 
following basal skull fractures. J R Coll Surg Edinb, 44(II):87–90. 
[115] Nosan, D.K., Benecke, J.E. Jr and Murr, A.H.(1997). Current perspective on temporal 
bone trauma. Otolaryngol Head Neck Surg, 117(I):67–71. 
[116] Zayas, J. O., Feliciano, Y. Z., Hadley, C. R., Gomez, A. A., Vidal, J. A. (2011). 
Temporal bone trauma and the role of multidetector CT in the emergency department. 
Radiographics, 31:1741–1755. 
[117]  Lourenco, M.T., Yeakley, J.W. and Ghorayeb, B,Y. (1995). The “Y” sign of lateral 
dislocation of the incus. Am J Otol, 16(III):387-392. 
[118]  Jäger, L., Strupp, M., Brandt, T., Reiser, M. (1997) Imaging of labyrinth and 
vestibular nerve. Nervenarzt, 86:443–458. 
[119] Maillot, O., Attyé, A., Boyer, E., Heck, O., Kastler, A., Grand, S., Schmerber, S. and 
Krainik, A. (2016). Post traumatic deafness: a pictorial review of CT and MRI 
findings. Insights Imaging, 7(III):341-50. 
[120] Holland, N.J. and Weiner, G.M. (2004). Recent developments in Bell’s palsy. BMJ, 
329:553–557. 
[121] Chan, E.H., Tan, H.M., Tan, T.Y. (2005). Facial palsy from temporal bone lesions. 
Ann Acad Med Singapore, 34:322–329. 
[122] Brodie, H.A. and Thompson, T.C. (1997). Management of complications from 820 
temporal bone fractures. Am J Otol, 18:188–197. 
[123] Delgado-Almandoz, J.E., Kelly, H.R., Schaefer, P.W., Lev, M.H., Gonzalez, R.G. and 
Romero, J.M. (2010). Prevalence of traumatic dural venous sinus thrombosis in high-
risk acute blunt head trauma patients evaluated with multidetector CT venography. 
Radiology, 255(II):570-577.  
[124] Ghuman, M.S., Salunke, P., Sahoo, S.K. and Kaur, S. (2016). Cerebral venous sinus 
thrombosis in closed head trauma: A call to look beyond fractures and hematomas! 
Journal of Emergencies, Trauma, and Shock. 9(I):37-38. 

Neuroradiology of the Hearing System 
 
877
[125] Leonetti, J.P., Shownkeen, H. and Marzo, S.J. (2001). Incidental petrous apex findings 
on magnetic resonance imaging. Ear Nose Throat J 80(IV):200-2, 205-6. 
[126] Chapman, P. R., Shah, R., Curé, J. K., Bag, A. K. (2011) Petrous Apex Lesions: 
Pictorial Review, AJR Am J Roentgenol, 196: WS26-WS37. 
[127] Arriaga, M.A. and Brackmann, D.E. (1991) Differential diagnosis of primary petrous 
apex lesions. Am J Otol, 12(VI):470-474 Am J Otol May; 13(III):297. 
[128] Radhakrishnan, R., Son, H.J. and Koch, B.L. (2014). Petrous apex lesions in the 
pediatric population Pediatr Radiol, 44(III):325-339; quiz 323-324. 
[129] Isaacson, B. (2015). Cholesterol granuloma and other petrous apex lesions, 
Otolaryngol Clin N Am, 48(2):361-373. 
[130] Larson, T.L., Wong, M.L. (1992). Primary mucocele of the petrous apex: MR 
appearance. AJNR Am J Neuroradiol, 13(I):203-204. 
[131] Fitzgerald, D.C. (2001). Nasopharyngeal abscess and facial paralysis as complications 
of petrous apicitis: a case report Ear Nose Throat J, 80(V):305-307. 
[132] Nelson, J.J., Goyal, P. (2012). Extraorbital pseudotumor of the petrous apex: biopsy 
via a transnasal endoscopic approach Ear Nose Throat J, 91(IV):E6-9. 
[133] Kim, B. J., Lee, E. J., Chang, H. W., Jung, H. R., Kim, E., Sohn, S. I., Kim, S. P. 
(2014). Aneurysmal bone cyst in the temporal bone and complete resection with 
preoperative embolization. A case report. Interv Neuroradiol, 31; 20(V):609-613. 
[134] Bialer, O. Y., Rueda, M. P., Bruce, B. B., Newman, N. J., Biousse, V., Saindane, A. 
M. (2014). Meningoceles in idiopathic intracranial hypertension AJR Am J Roentgenol, 
202(3):608-613. 
[135] Van Es, S., North, K.N., McHugh, K. and De Silva, M. (1996), MRI findings in 
children with neurofibromatosis type 1: a prospective study Pediatr Radiol, 
26(VII):478-487. 
[136] Mafee, M. F., Kumar, A., Heffner, D.K. (1994). Epidermoid cyst (cholesteatoma) and 
cholesterol granuloma of the temporal bone and epidermoid cysts affecting the brain. 
Neuroimaging Clin N Am, 4(III):561-578. 
[137] Zivković, N., Marković, M., Mihajlović, G., Jovanović, M. (2014). Surgical treatment 
of intradiploic epidermoid cyst treated as depression. Srp Arh Celok Lek, 142(I-II):67-
71. 
[138] Bacciu, A., Di Lella, F., Pasanisi, E., Gambardella, I., Saccardi, M. S., Bacciu, S., 
Vincenti, V. (2014). Open vs closed type congenital cholesteatoma of the middle ear: 
two distinct entities or two aspects of the same phenomenon? Int J Pediatr 
Otorhinolaryngol, 78(XII):2205-2209. 
[139] Makarem, A.O., Hoang, T.A., Lo, W.W., Linthicum F.H. Jr and Fayad, J.N. (2010). 
Cavitating otosclerosis: clinical, radiologic, and histopathologic correlations Otol 
Neurotol, 31(III):381-384. 
[140] Moe, K.S., Li, D., Linder, T.E., Schmid, S. and Fisch, U. (1999), An update on the 
surgical treatment of temporal bone paraganglioma. Skull Base Surg, 9(III):185-194. 
[141] Martucci, V.L., Pacak, K. (2014). Pheochromocytoma and paraganglioma: diagnosis, 
genetics, management, and treatment. Curr Probl Cancer, 38(I):7-41. 

C. Gagliardo, S. Piccinini and P. Feraco 
 
878
[142] Corrales, C. E., Fischbein, N., Jackler R. K. (2015). Imaging innovations in temporal 
bone disorders Otolaryngol Clin North Am, 48(II):263-280. 
[143] Szymańska, A., Szymański, M., Czekajska-Chehab, E., Szczerbo-Trojanowska, M. 
(2015) Non-paraganglioma tumors of the jugular foramen – Growth patterns, 
radiological presentation, differential diagnosis. Neurol Neurochir Pol, 49(III):156-
163. 
[144] Naidich, Th. P., Duvernoy, H. M., Delman, B. N., Sorensen, A. G., Kollias, S. S., 
Haacke, E. M. (2009) Duvernoy's atlas of the brainstem and cerebellum. Springer.  
[145] Borges, A. (2015). Pathology of the facial nerve. In: Lemmerling, M., de Foer, B. 
(eds.), Temporal bone imaging. Medical Radiology (Diagnostic Imaging). p257-306. 
Springer 
[146] Verzijl, H. T., Valk, J., de Vries, R., Padberg, G. W. (2005). Radiologic evidence for 
absence of the facial nerve in Möbius syndrome. Neurology, 64:849-855.  
[147] Veillon, F. Ramos-Taboadaa, L.,Abu-Eida, M., Charpiotb, A. Riehma, S. (2010). 
Imaging of the facial nerve. Eur J Radiol, 74(II):341-348. 
[148] Borges, A., Casselman, J. (2007). Imaging the cranial nerves: Part I: methodology, 
infectious and inflammatory, traumatic and congenital lesions. Eur Radiol, 
17(VIII):2112-2125. 
[149] Ünel, S., Yilmaz, M., Albayram, S., Işık, Z., Ceyhan, E., Isildak, H., Teixido, M., 
Savas, Y. and Kiris, A. (2012). Anastomoses of the Vestibular, Cochlear, and Facial 
Nerves. J Craniofac Surg, 23(V):1358-1361. 
[150] Jin, A., Xu, P., Qu, F. (2018). Variations in the labyrinthine segment of facial nerve 
canal revealed by high-resolution computed tomography. Auris Naus Larynx, 
45(II):261-264.  
[151] Alicandri-Ciufelli, M., Fermi, M., Bonali, M., Presutti, L., Marchioni, D., Todeschini, 
A. and Anschuetz, L. (2018). Facial sinus endoscopic evaluation, radiologic 
assessment, and classification. Laryngoscope, [Epub ahead of print]. 
[152] Burmeister, H. P., Baltzer, P. A., Dietzel, M., Krumbein, I., Bitter, T., Schrott-Fischer, 
A., Guntinas-Lichius, O., Kaiser, W. A. (2001). Identification of the nervus 
intermedius using 3T MR imaging. Am J Neuroradiol, 32(III):460-464. 
[153] Singh, A.K., Bathla, G., Altmeyer, W., Tiwari, R., Valencia, M.P., Bazan, C. and 
Tantiwongkosi, B. (2015). Imaging Spectrum of Facial Nerve Lesions. Current 
Problems in Diagnostic Radiology, 44(I): 60-75. 
[154] Lorch, M., Teach, S.J. (2010). Facial nerve palsy: etiology and approach to diagnosis 
and tratment. Pediatr Emerg Care, 26(X):763-769 quiz 770-773. 
[155] Gupta, S., Mends, F., Hagiwara, M., Fatterpekar, G. and Roehm, P.C. (2013). Imaging 
the Facial Nerve: A Contemporary Review. Radiology research and practice, 2013: 
248039. 
[156] Thömke, F., Urban, P. P., Marx, J. J., Mika-Grüttner, A., Hopf, H. C. (2002). Seventh 
nerve palsies may be the only clinical sign of small pontine infarctions in diabetic and 
hypertensive patients. J Neurol, 249(XI):1556-1562. 

Neuroradiology of the Hearing System 
 
879
[157] Kobayashi, J., Ohara, T., Minematsu, K., Nagatsuka, K. and Toyoda, K. (2014). 
Etiological mechanisms of isolated pontine infarcts based on arterial territory 
involvement J Neurol Sci, 339(I-II):113-117. 
[158] Wilson, L. K., Pearce, L. A., Arauz, A., Anderson, D. C., Tapia, J., Bazan, C., 
Benavente, O. R., Field, T. S., SPS3 Investigators. (2016). Morphological 
classification of penetrating artery pontine infarcts and association with risk factors 
and prognosis: The SPS3 trial. Int J Stroke, 11(IV):412-419. 
[159] Park, J.H., Yoo, H.U. and Shin, H.W. (2008). Peripheral type facial palsy in a patient 
with dorsolateral medullary infarction with infranuclear involvement of the caudal 
pons J Stroke Cerebrovasc Dis 17(V):263-265. 
[160] Lanser, M.J., Jackler, R.K. (1991). Gadolinium magnetic resonance imaging in Bell's 
palsy. Western Journal of Medicine 154(VI):718–719. 
[161] Alaani, A., Hogg, R., Saravanappa, N. and Irbing, R.M. (2005), An analysis of 
diagnostic delay in unilateral facial palsy. J Larungol Otol, 119(III):184-188. 
[162] Smith, J.K., Matheus, M.G. and Castillo, M. (2004). Imaging manifestations of 
neurosarcoidosis. Am J Roentgenol, 182:289-295.  
[163] Kuya, J., Kuya, K., Shinohara, Y., Kunimoto, Y., Yazama, H., Ogawa, T. and 
Takeuchi, H. (2017). Usefulness of high-resolution 3D multi-sequences for peripheral 
facial palsy differentiation between Bell's palsy and Ramsay Hunt syndrome. Otol 
Neurotol, 38(X):1523-1527. 
[164] Labin, E., Tore, H., Alkuwaiti, M. and Streib, C. (2017). Teaching NeuroImages: 
Classic Ramsay Hunt syndrome and associated MRI findings. Neurology, 89(VII):e79-
e80. 
[165] Ebner, D., Smith, K., DeSimone, D. and Sohail, M.R. (2010). Cranial neuropathy and 
severe pain due to early disseminated Borrelia burgdorferi infection. BMJ Case Rep, 
23;2018. 
[166] Burmeister, H. P., Baltzer, P. A., Klingner, C. M., Pantel, M., Kaiser, W.A. (2010). CT 
and MR Imaging of the facial nerve. HNO 58(V):433-442. 
[167] Petrus, L.V., Lo, W.W. (1997) The anterior epitympanic recess: CT anatomy and 
pathology. Am J Neuroradiol, 18(VI):1109-1114. 
[168] Borges, A. and Casselman, J., (2007). Imaging the cranial nerves: Part II: primary and 
secondary neoplastic conditions and neurovascular conflicts. Eur Radiol, 17(IX):2332-
2344. 
[169] Yue, Y., Jin, Y., Yang, B., Yuan, H., Li, J. and Wang, Z. (2015). Retrospective case 
series of the imaging findings of facial nerve hemangioma. Eur Arch 
Otorhinolaryngol, 272(IX):2497-2503. 
[170] Ojiri, H. (2006). Perineural spread in head and neck malignancies. Radiat Med, 24:1-8. 
[171] Zhao, S., Han, D., Wang, Z., Li, J., Qian, Y., Ren, Y., Dong, J. (2015). An imaging 
study of the facial nerve canal in congenital aural atresia. Ear Nose Throat J, 94(X-
XI):E6-13. 

C. Gagliardo, S. Piccinini and P. Feraco 
 
880
[172] Song, J. J., Park, J. H., Jang, J. H., Lee, J. H., Oh, S. H., Chang, S. O., Kim, C. S. 
(2012) Facial nerve aberrations encountered during cochlear implantation. Acta 
Otolaryngol, 132(VII):788-794. 
[173] Vincenti, V., Di Lella, F., Falcioni, M., Negri, M. and Zanetti, D. (2018) Cochlear 
implantation in children with CHARGE syndrome: a report of eight cases. 
275(VIII):1987-1993. 
[174] Kozerska, M., Skrzat, J., Spulber, A., Walocha, J., Wronski, S. and Tarasiuk, J. (2017), 
Micro-CT study of the dehiscences of the tympanic segment of the facial canal. Surg 
Radiol Anat, 39(IV):375-382. 
 
 
ATLAS 
 
Imaging Based Atlas of the Hearing System 
Atlas legend:  
 
1) styloid process 
2) facial nerve (mastoid segment) 
3) condyloid process 
4) hypoglossal canal 
5) mastoid cells 
6) pinna 
7) C1 (atlas) anterior arch 
8) external auditory channel (EAC) 
9) jugular foramen 
10) condylar process 
11) tympanic membrane 
12) internal carotid artery (ICA) 
13) posterior semicircular canal (PSCC) 
14) vestibular aqueduct 
15) sinus tympani 
16) round window niche 
17) cochlear aqueduct 
18) basal turn cochlea 
19) vestibule 
20) lateral semicircular canal (LSCC) 
21) malleus 
22) incus (short process) 
23) stapes 
24) internal auditory channel (IAC) 
25) modiolus 
26) superior semicircular canal (SSCC) 
27) middle turn cochlea 
28) apical turn cochlea 
29) incudomalleolar joint 
30) aditus ad antrum 
31) Eustachian tube entrance 
32) facial nerve (tympanic segment) 
33) geniculate ganglion 
34) facial nerve (labyrinthine segment) 
35) cochlea 
36) hypo tympanum 
37) tegmen tympani 
38) tensor tympani muscle 
39) tensor tympani tendon 
40) Prussak’s space 
41) scutum 
42) jugular bulb 
 
 

Neuroradiology of the Hearing System 
 
881
  
 
  
 
  
 
  
  

C. Gagliardo, S. Piccinini and P. Feraco 
 
882
  
  
  
 
 

In: Encyclopedia of Audiology and Hearing Research 
ISBN: 978-1-53617-702-2 
Editors: Erno Larivaara and Senja Korhola 
© 2020 Nova Science Publishers, Inc. 
 
 
 
 
 
 
 
Chapter 58  
 
 
 
AGE-RELATED HEARING LOSS 
 
 
Rocco Bruno, MD, Bruno Galletti, MD, Pietro Abita, MD,  
Giuseppe Impalà, Francesco Freni, MD, PhD 
and Francesco Galletti, MD, PhD 
University of Messina, Department of Human Pathology,  
Adult and Developmental Age “G. Barresi”, Messina, Italy 
 
 
ABSTRACT 
 
Age-related hearing loss (ARHL, also known as presbycusis) is a hearing loss linked 
to ageing in which there is a typical deterioration in the ability to understand verbal 
messages, caused by physiological ageing processes of the whole auditory system, from 
the peripheral receptors up to the central processing centres (Central Auditory Processing, 
CAP). 
This chronic health condition affects approximately one-third of the population. The 
incidence among the elder patients (over 80 years old) reaches the 80%, and over 90% of 
hearing loss in the elderly is caused by presbycusis. 
ARHL is classicaly defined as a progressive, bilateral and symmetrical hearing loss 
primarily observed in the high frequency region, associated with a deterioration in 
detection, localization of sound and verbal discrimination, especially in a competitive 
environment (for example, in the presence of background noise). 
Four categories of risk factors associated with ARHL were identified in humans: 
genetic predisposition, environment, health co-morbidities and cochlear and CAP ageing. 
For these reasons ARHL can be defined ad a multifactorial disorder. 
By analyzing human temporal bones, it could be distinguished six distinct forms of 
ARHI, with different pathologic changes correlated with a different audiologic pattern. 
According to this classification presbycusis can be divided into: Sensory presbycusis, 
Neural presbycusis, Strial presbycusis, Cochlear conductive presbycusis, Indeterminate 
presbycusis, Mixed presbycusis. 
This chapter aims to give an overview of the scientific findings related to Age-
related hearing impairment that is a complex disorder. 
 
Keywords: age related hearing loss, presbyacusis, hearing impairment 
 

Rocco Bruno, Bruno Galletti, Pietro Abita et al. 
 
884
DEFINITION 
 
Age-related hearing loss (ARHL, also known as presbycusis) is a hearing loss linked to 
ageing in which there is a typical deterioration in the ability to understand verbal messages, 
caused by physiological ageing processes of the whole auditory system, from the peripheral 
receptors up to the central processing centres (Central Auditory Processing, CAP).  
It is defined as a progressive, bilateral and symmetrical hearing loss primarily observed in 
the high frequency region, associated with a deterioration in detection, localization of sound 
and verbal discrimination, especially in a competitive environment (for example, in the 
presence of background noise) [1]. 
 
 
EPIDEMIOLOGY 
 
AHRI is a chronic health condition that affects approximately one-third of the population. 
The incidence among the elder patients (over 80 years old) reaches the 80%, and over 90% of 
hearing loss in the elderly is caused by presbycusis [2]. The alteration in perception of pure 
tones already occurs in younger adults (approx. 30 years old), involving the acute frequencies 
(>10 kHz), which are not commonly examined in the classical tonal audiometric examination. 
This leads to the idea that a damage in perception of high frequency sounds has already taken 
place once the diagnosis of ARHL has been made with a conventional pure tone audiometry 
[3]. 
Epidemiological studies have confirmed two kinds of modifications in the auditory 
thresholds, involving different parts of the spectral frequencies: the decline in the higher 
frequencies (6-12,5 kHz) seems to have an early outset (beginning even at 31 years old) and a 
rapid growth while for the low and middle frequencies (up to 4kHz) the decline seems to have 
a late outset and a slower growth [4, 5]. 
The elaboration of data taken by the National Health and Nutrition Examination Survey 
(NHANES) demonstrates that the prevalence of ARHL is two times higher in men compared 
to women for frequencies between 0,5-8 kHz, especially after 50 years old, probably because 
of the protective role played by female hormones. From the same study emerged that in black 
individuals the prevalence of ARHL is lower than the one registered for white individuals, 
suggesting a protective role played by melanocyte function. Further studies are necessary to 
confirm this link, tough [3, 5]. 
 
 
CAUSES AND RISK FACTORS 
 
ARHL is an inevitable hearing impairment associated with reduction of communicative 
skills related to ageing. Even if the development of this pathology is, as remarked before, 
inevitable, many Authors have found factors that can affect the extent of hearing loss. 
Yamasoba et al. [6] identified four categories of risk factors associated with ARHL in 
humans: genetic predisposition, environment, health co-morbidities and cochlear and CAP 
ageing. For these reasons ARHL can be defined ad a multifactorial disorder. 
 

Age-Related Hearing Loss 
 
885
1. Genetics 
 
Contributions of the genetic factors to ARHL in humans have been well documented, 
despite the genetic mechanisms underlying the development of this pathology are not yet 
fully known. 
Genome wide association studies have reported a strong link between ARHL and single 
nucleotide polymorphisms (SNPs) located in GRM7, a gene encoding metabotropic glutamate 
receptor type 7 protein (mGluR7) [7, 8].  
A number of genes and mutations responsible for monogenic non-syndromic hearing loss 
are linked to ARHL, including: SNPs in 13-kb region in the middle of the KCNQ4, a gene 
which encodes a voltage-gated K-channel found in both outer and inner hair cells of cochlea 
[9]; 35delG heterozygosis mutation of GJB2, a gene that encodes gap junction proteins 
expressed in the inner ear (Connexin 26) [10-14]; mutation in GRHL2, a gene that encodes a 
transcription factor expressed in cells lining cochlear duct [15]; mutation in MYO6, a gene that 
encodes myosin VI found in inner ear hair cells [16]. It is known that genes that are linked to 
oxidative stress such as mutant allele (NAT2∗6A), an isoform of N-acetyltransferases which 
encodes metabolism of reactive oxygen species [17, 18] and Glutathione S-transferases (GSTs) 
which encodes synthesis of glutathione antioxidant enzymes [19] are linked with the 
development of ARHL.  
Furthermore it is necessary to mention, as possible responsible for presbycusis, mutations 
in mitochondrial DNA (deletion of 4,977bp of mitochondrial DNA and haplogroups U and K 
of mitochondrial DNA) [20, 21], and genes coding for Apolipoprotein E [22] and Endothelin-1 
[23]. 
All the findings made on human DNA have been sustained over time by the initial 
discovery of analogous genes and alleles mutated in laboratory animals, especially in mice of 
the “inbred” strain. 
In fact, in some studies on animal models, there have been identified some genes called 
AHL (age-hearing loss) that seems to contribute to the onset of ARHL: AHL2 on 
chromosome 5; AHL1, AHL4 and AHL5 on chromosome 10; AHL8 on chromosome 11; 
AHL3 on chromosome 17; AHL6 on chromosome 18 [24]. 
 
 
2. Environmental Factors 
 
A variety of environmental risk factors such as exposure to industrial chemicals, 
occupational and recreational noise exposure are reported to be associated with ARHL [25-
27]. Synergistic effects of simultaneous exposure to industrial chemicals and noise has a 
greater effect on ARHL than the impact of either one of the agents acting on its own [28-31]. 
 
 
3. Health Co-Morbidities 
 
Several diseases and drugs have been associated over time with an increased probability 
of developing ARHL. The best known associations are between ARHL and type 2 diabetes 
mellitus, cardiovascular diseases, atherosclerosis, smoking, and the use of ototoxic drugs such 

Rocco Bruno, Bruno Galletti, Pietro Abita et al. 
 
886
as platinum-derived chemotherapeutics, loop diuretics, anti-inflammatory drugs and 
aminoglycoside antibiotics [5]. 
 
 
4. Ageing of the Auditory System 
 
The inner ear is more prone to age-related changes than both the external and middle ear 
[32]. 
The first Author who managed to describe the damages caused by ageing on the inner 
hear, basing his discoveries on underlying case history information, audiometric 
configurations, and temporal bone analyses, was Harold Friederick Schuknecht [33-36]. He 
divided ARHL into four distinct classes: 
 
 
Sensory: loss of hair cells - inner (IHCs) and outer (OHCs) - and supporting cells 
- rod cells, Deiters, Hensen and Claudius cells. It is distinguished by a sharp drop 
in the audiometric track on the high frequencies and a bad speech discrimination 
in noisy environment. The otoacoustic emissions are absent. It is the most 
common form, typically linked to exposure to noise and environmental factors. It 
is also called sociocusis; 
 
 
 
 
Neural: linked to the loss of afferent neurons of the spiral ganglion, associated 
with a normal Organ of Corti. The audiogram is distinguished with a falling 
curve on the high frequencies, typically differentiated from the sensory form due 
to the bad speech discrimination; 
 
 
 

Age-Related Hearing Loss 
 
887
 
Metabolic or strial: linked to atrophy of cochlear lateral wall and Stria 
vascularis. The audiogram is characterized by a pantonal hearing loss or with a 
slight fall on the higher frequencies with a good speech discrimination. The 
otoacoustic emissions are present. It is thought to be the form strongly correlated 
to genetic causes, since it is present in about 50% of the sisters, 40% in mother-
daughter and about 30% in the siblings; 
 
 
 
 
Cochlear conductive: linked to atrophy and stiffening of the basilar membrane. 
The audiogram shows a typical and gradual descent on the high frequencies, with 
good verbal discrimination and with present otoacoustic emissions. It seems to be 
the least frequent form of the four, less probable from an etiopathogenetic point 
of view. 
 
 
 
Later Shucknecht added two more categories to the four described above: 
 
 
Mixed: consisting of a mixture of pathological characteristics; 
 
Indeterminate: consisting of none of the aforementioned pathological 
characteristics. 
 
In spite of the valuable contribution of Schuknecht in defining the pathophysiological 
mechanisms underlying ARHL, the above classification has been recently overcome due to 
the difficulties encountered in recognizing the different forms in a strict way. Nowadays it is 

Rocco Bruno, Bruno Galletti, Pietro Abita et al. 
 
888
common to use a much simpler distinction, based on the anatomical region in which the 
damage is established: we, then, recognize a peripheral ARHL (in which the hearing loss is 
caused by damages in the peripheral auditory system) and a central ARHL (in which hearing 
problems originate from a CAP dysfunction). The two nosological entities, however, may not 
present themselves exclusively, acting synergistically in the development of the pathology. 
 
Peripheral ARHL 
Peripheral ARHL includes all those forms characterized by an altered morphology of the 
audiogram with less or none deterioration in speech recognition. These forms are caused by 
damages to the structures of the inner ear, markedly against outer hair cells (progressive 
deterioration and decrease in the number of OHCs), stria vascularis (loss of cells and 
deterioration of its capillaries), spiral ganglion (deterioration of its neurons), lamina spiralis 
(reduction of the number of nerve fibers at this level) and internal auditory artery 
(hypertrophy of its elastic lamina) [34, 37-42]. The cause of all these damages has been 
proven to be oxidative stress: in fact, it has been demonstrated that an increased production of 
toxic catabolites (following, for example, noise exposure, use of ototoxic drugs, etc.) together 
with their inadequate disposal (as a result of mitochondrial dysfunction due to ageing) can 
damage the microstructures of the inner ear causing their death. Even alterations of the 
cochlear vascularization have been proven to be responsible for the damaging of inner ear’s 
structures [43-53].  
As far as we know, there are two different measurable alterations in a cochlea suffering 
from aging processes: the decrease of the electrical potential of endolymph (due to decreased 
expression of specific electrolytes transportation enzymes) and the increase in the threshold of 
the cochlear nerve compound action potential (due to the asynchrony of discharge of the 
single fibers that compose it [38]. 
 
Central ARHL 
Central ARHL includes all those forms in which the main characteristic is an altered 
speech discrimination together with a partially conserved tonal auditory threshold. These 
forms originate from an alteration of the cortical networks and connections, resulting in a 
reduction of cortical plasticity, a physiological phenomenon due to ageing. In central ARHL 
what is typically altered is the Central Auditory Processing (CAP). CAP dysfunction is 
indeed occupying more and more importance in the establishment of the late phases of 
ARHL, while it is thought that the alterations of the peripheral auditory function are the 
primum movens in the development of the initial phases of presbycusis [54-57]. 
The three fundamental key points analyzed in Literature nowadays are: 
 
4. What kind of alterations we find at various levels of the auditory path and how they 
affect the perception of complex stimuli, such as speech; 
5. If and how these alterations are the effect of a peripheral system depletion, or if and 
how they run independently of it; 
6. If and how there are correlations between ARHL, cognitive impairment and 
dementia. 
 

Age-Related Hearing Loss 
 
889
I. The main alterations of central processing found in the latest studies are related to three 
main parameters: deficiency of temporal processing of complex stimuli, lesser ability to 
encode the signal in presence of noise and decline in spectral resolution. The first of the three 
seem to be the parameter that contributes most to the deterioration of all those skills useful to 
understand complex stimuli, such as speech. 
As a consequence of aging, in fact, we can find at various levels of the auditory path: a 
decline in inhibitory neurotransmission mediated by glycine in cochlear nuclei, especially in 
the dorsal portion, as reported in the strain of aged Fischer-344 rats [58]; a marked decline of 
GABA-mediated inhibitory impulses together with a prevalence of the excitatory area over 
the inhibitory one in the inferior colliculus, as reported in various strains of aged rats [59, 60]; 
a 45% reduction of GABA receptors in the medial geniculate nucleus reported in aged rats 
[61]; decline in number of SMI-32-immunoreactive neurons and levels of non-phosphorylated 
neuro-filament proteins [62]. Human studies have found a deterioration in GABA-mediated 
inhibitory neurotransmission (both presynaptic and post-synaptic) in the primary auditory 
cortex and a deterioration of the Startle reflex evaluated through pre-pulse inhibition [63-65]. 
All these changes influence the temporal processing of acoustical stimuli and are reported to 
be contributing to central ARHL. The alterations of the remaining parameters (decline in 
spectral resolution and lesser ability to encode the signal in presence of noise) seems to be 
mainly caused by a deterioration of the capacity of fine tuning of the neuronal populations 
present in the primary auditory cortex (fine-tuned receptive fields) [66-68]. There is therefore 
a lower capacity in the primary auditory cortex to execute a fine spectral processing of 
complex signals, which leads to a lower capacity to encode properly a signal in the presence 
of background noise (poorly-tuned receptive fields). 
It is also thought that age-associated changes in calcium binding proteins (parvalbumin, 
calbindin, calretinin) disrupt the calcium homeostasis and could lead to impaired synaptic 
transmission, reduced neural plasticity, and degeneration of neurons reported in ARHL [69-
73]. Thanks to the advent of new imaging methods (PET and functional MRI) it was possible 
to show as a consequence of aging a reduction in both gray and white matter volumes, 
associated with cortical thinning. Alterations in the above mentioned neural networks are 
implicated in impaired cognitive functions such as verbal recognition memory, episodic 
visuospatial memory, learning and association ability, working memory and executive 
functions as well as attention switching [74-77]. 
II. An alteration of the central auditory system alone is extremely rare, whilst seems 
much more common an alteration of both the peripheral and central auditory system at the 
same time [78]. In addition, it appears that CAP alterations depend also on the reduction of 
peripheral inputs. (e.g., the deterioration of glycine-mediated neurotransmission at the level of 
cochlear nuclei found in the Fischer-344 rats [58], the evidence of a tonotopic reorganization 
of the primary auditory cortex found in animals, which follows the peripheral/cochlear 
hearing loss) [79, 80]. Even peripheral decline (e.g., different kind of glial alteration found in 
the strain of C57BL/6J mice) [81] and aging itself (documented as anatomical modifications 
in the whole brain) have been seen to be responsible for the alterations in CAP [78]. 
III. Increasing evidence has linked ARHL to more rapid progression of cognitive  
decline and incidental dementia, in an escalating form that can lead also to Alzheimer’s 
disease (AD) - the most common form of dementia [2, 3, 57]. As far as we know it has not 
been yet discovered the keystone to explain whether the hearing impairment determines the 
development of dementia (due to the degradation of sensory inputs sent from the periphery to 

Rocco Bruno, Bruno Galletti, Pietro Abita et al. 
 
890
the central nervous system) or if cognitive decline leads to an altered capacity of auditory 
discrimination, especially in noisy environments (leading the elderly to further isolate 
themselves, worsening their dementia).  
From an analysis of epidemiological and clinical evidences, four hypothesis have been 
theorized to explain the link between ARHL and cognitive impairment [2]: 
1. Cognitive load on perception hypothesis: cognitive decline may reduce the cognitive 
resources that are available for auditory perception, increasing the effects of hearing 
loss; 
2. Degradation of audiological information hypothesis: when the inputs are poor, either 
through degraded stimuli (e.g., in noisy environment) or impaired perception, 
additional cognitive resources are required to understand the signal. Therefore, this 
cognitive resources will not be available for cognitive roles. 
3. Sensory deprivation hypothesis: described by Lin and colleagues [82-84], it suggests 
that hearing loss causes a cognitive decline that is permanent or potentially 
remediable after rehabilitation (e.g., with the use of hearing aids). It has been 
theorized that an impaired perception could lead to worsening cognition over time 
and social isolation, which in turn leads to cognitive decline.  
4. Common cause hypothesis: according to this hypothesis numerous factors that act 
synergistically with each other are responsible for cognitive decline in the elderly. 
These include cardiovascular diseases, diabetes and tissue damage caused by 
increased Reactive Oxygen Species (ROS) production. 
 
Although none of the four hypotheses is able to clarify the causal link between ARHL 
and cognitive decline [3], it has emerged that CAP dysfunction can be considered an 
important and early risk factor in determining the future onset of cognitive impairment up to 
Alzheimer's dementia [54]. 
 
 
ARHL AND FRAILTY 
 
In addition to the close connection between ARHL and cognitive impairment, ARHL is 
also considered an important marker for frailty in older age. Frailty reflects a nonspecific state 
of vulnerability and multisystem physiological change that predisposes an individual to 
adverse health outcomes such as disability, falls, institutionalization, hospitalization and death 
[85], and is of high importance in the clinical care of the older population. Thus, 
psychological, cognitive and social factors contribute to define this condition.  
The recruitment of cognitive areas which are not directly responsible for speech encoding 
causes neural resources to be sacrificed. Alterations in the above mentioned neural networks 
are implicated in impaired cognitive functions such as verbal recognition memory, episodic 
visuospatial memory, learning and association ability, working memory and executive 
functions, and attention switching [3, 54]. Moreover, it is thought that hearing loss is 
associated with a 20% increased risk of mortality compared with normal hearing [86]. 
 
 

Age-Related Hearing Loss 
 
891
DIAGNOSIS 
 
The most important part in the diagnosis of ARHL is the anamnesis. Investigating the life 
of the patient, asking if there has ever been a chronic exposition to noise, a genetic 
susceptibility or a history of chronic illnesses linked to presbycusis, associated with tinnitus 
(a condition often related to hearing loss) is the cornerstone for a correct diagnosis. 
After asking for the medical history it is necessary to submit the patient to different kind 
of audiological exams, which often have limitations in implementation due to the reduction of 
the level of attention and cooperation from the patient, which can trigger any anxiety states, 
further affecting the success of the examination. It will be necessary, therefore, to put the 
patient at ease, explaining in a clear and comprehensible way each task and the manner in 
which it must be completed. 
During the course of the examinations it is important to take into account that the laxity 
of the tissues of the auricle and the ear canal, physiological in the elderly, can facilitate, 
collapsing, a reduction of the auditory acuity [1, 2]. 
 
 
Pure Tone Audiometry 
 
It’s the screening test for the evaluation of auditory acuity. It allows to highlight the 
presence of a hearing loss that is characteristically sensorineural, bilateral and symmetrical 
with a typical saving of the lower frequencies and a fall on the medium/higher frequencies. 
The magnitude of this loss depends significantly on the age of the patient and the amount of 
risk factors present in the medical history. 
 
 
Speech Audiometry 
 
Speech audiometry refers to procedures that use speech stimuli to assess auditory 
function. The goal of speech audiometry is to quantify a patient’s ability to understand 
everyday communication. Speech audiometry testing can be done in isolation or with acoustic 
interferences which can be differentiated into two main groups: a kind of background noise 
which is similar to the primary signal (e.g., cocktail party) and another kind constituted by 
pure noise, different from the primary signal (e.g., pink noise). 
Results from speech recognition tests in quiet testing condition and in background noise 
should be evaluated in relation to the pure-tone thresholds. Underperformance in speech 
recognition in comparison with expectations based on peripheral hearing function suggests 
central auditory processing dysfunction [54]. If word-recognition scores equal or exceed those 
that might be expected from the audiogram, then suprathreshold speech recognition ability is 
thought to be normal for the degree of hearing loss. If word recognition scores are poorer than 
would be expected, then suprathreshold ability is abnormal for the degree of hearing loss. 
Abnormal speech recognition is often the result of cochlear distortion or retrocochlear 
disorder. 
The typical pattern of ARHL in speech detection threshold demonstrates what is called 
“rollover”, in which speech recognizing function declines substantially as speech intensity 

Rocco Bruno, Bruno Galletti, Pietro Abita et al. 
 
892
increases beyond the level producing the maximum performance score. In other words, as 
speech intensity level increases, performance rises to a maximum level then declines or “rolls 
over” sharply as intensity increases. This rollover effect is commonly observed when the site 
of hearing loss is retrocochlear, in the auditory nerve or the auditory pathways in the 
brainstem [87]. 
 
 
Redundancy and Sensitized Speech Measures (SSM) 
 
There is a great deal of redundancy associated with our ability to hear and process speech 
communication. Intrinsically, the central auditory nervous system has a rich system of 
anatomic, physiologic, and biochemical overlap. Among other functions, such intrinsic 
redundancy permits multisensory processing and simultaneous processing of different 
auditory signals. Another aspect of intrinsic redundancy is that the nervous system can be 
altered substantially by neurologic disorder and still maintain its ability to process 
information. Extrinsically, speech signals contain a wealth of information due to phonetic, 
phonemic, syntactic, and semantic content and rules. Such extrinsic redundancy allows us to 
hear only part of a speech segment and still understand what is being said. Extrinsic 
redundancy increases as the content of the speech signal increases. 
The issue of redundancy plays a role in the selection of speech materials. If you are trying 
to assess the effects of a cochlear hearing impairment on speech perception, then signals that 
have reduced redundancy should be used. If you are trying to assess the effects of a disorder 
of the central auditory nervous system on speech perception, the situation becomes more 
difficult. The solution to assessing central auditory nervous system disorders is to reduce the 
extrinsic redundancy of the speech information enough to reveal the reduced intrinsic 
redundancy caused by neurologic disorder [87, 88]. 
Thanks to the use of sensitized speech measures it is possible to evaluate CAP and any of 
its dysfunction (CAPD) establishing critical listening conditions, as described above. The 
most diffused SSM tests in the last few years are based on: 
 
 
the administration of phrases with a verbal competitive signal characterized by 
continuous speech, presented ipsilaterally or contralaterally to the primary signal 
(SSI-ICM: synthetic sentence identification with ipsilateral competing message, SSI-
CCM: synthetic sentence identification with contralateral competing message); 
 
the administration of phrases in presence of a competitive noise, generally consisting 
of pink noise (SPIN: speech in noise perception); 
 
the administration of verbal signal idegraded in its spectral component (“distorted 
voice”) or temporal component (by introducing interruptions - “interrupted voice” - 
or compressing the times - “accelerated voice”). 
 
It is not yet clear whether these tests specifically identify CAPD or are significantly 
influenced by alterations in cognitive abilities, often present in several individuals affected by 
ARHL with concomitant cognitive impairment, dementia and/or AD (Alzheimer's disease) 
[89]. 
 

Age-Related Hearing Loss 
 
893
Tympanometry 
 
This test provides a valuable aid in the topodiagnosis of ARHL, excluding a transmission 
deficit in the middle ear (presence of type A tympanograms), and evaluating the presence 
(with recruitment) or absence of the cocleo-stapedial reflexes [1]. 
 
Otoacoustic Emissions 
 
Not necessary for the diagnosis of ARHL in the typical audiological examination. They 
may be useful in objecting a damage of OHCs in case of peripheral receptor damage [1]. 
 
 
PREVENTION AND REHABILITATION 
 
It is impossible to counteract the aging processes which lead to ARHL. As for the 
prevention of the pathology it is therefore important to avoid a rapid progression of the 
deterioration in the auditory system. 
As it could be imagined, the main prevention for ARHL is avoiding all those conditions 
in which the ear can suffer from chronic acoustic stress (e.g., use of headphones and 
earphones at high volume, attendance of discos, lack of soundproofing in the workplace, 
exposition to noise in the city environment, hobbies related to auditory stress such as hunting, 
etc.) and preventing all of those diseases capable of altering the auditory function (ischemic 
heart disease, strokes, hyperlipidemia, diabetes mellitus, etc.). 
The first and fundamental tool of prevention in the diagnosis of ARHL is the periodic 
control of the auditory function, in order to recognize at an early stage the moment in which 
the hearing loss begins to determine a deficit in personal and communicative skills of an 
individual. 
There are conflicting opinions concerning therapeutic strategies for ARHL. On the basis 
of its etiopathogenesis, however, it has been advised the use of substances with antioxidative 
powers (such as A, B, C, E vitamins, selenium, N-acetylcysteine, methionine, etc.) to contrast 
the damages made by ROS in the inner ear. 
Nowadays the pivotal tool for an early diagnosis of ARHL is still the pure tone 
audiometry. Every adult over 65 years old should undergo annually to this exam, especially 
when predisposing factors are documented in his medical history. The mail goal of an early 
diagnosis lies on the possibility to establish a rapid therapeutic-rehabilitative strategy, 
counteracting the evolution of the pathology and the social isolation, which can eventually 
lead to cognitive impairment and dementia. 
Hearing Aids (HAs) are the most valid and effective instrument in the field of auditory 
rehabilitation in ARHL. Different studies, in fact, prove that the use of HAs influence 
significantly in a positive way the quality of life in those who wear them [90]. HAs exploit 
the functional residues of the organ of Corti amplifying, transducing and sending sounds 
directly to the tympanic membrane. They can be useful when the hearing loss is not 
susceptible to medical and/or surgical intervention. For a documentable benefit from the use 
of HAs there must be an average pure tone threshold higher than 55dB SPL on 500, 1000, 
2000 and 4000 frequencies, together with an identification greater than 60% of the words in 

Rocco Bruno, Bruno Galletti, Pietro Abita et al. 
 
894
closed lists and a recognition of more than 40% of the words in open lists without the help of 
labiolecture in speech audiometry with an emission of 65dB SPL. 
HAs are chosen on the basis of the characteristics of each patient (grade of hearing loss, 
expectancies and necessities). These modern digital amplification systems are completely 
innovative and allow, thanks to better sound processing and division of the frequency 
spectrum into multiple channels, to have excellent results in those hearing losses where 
personalization and fine adjustment are fundamental for a good hearing rehabilitation. 
Clinical trials have demonstrated that hearing loss has a negative impact on working 
memory, which is important for speech understanding especially in difficult or noisy 
environments. Other trials proved that the use of hearing aids in the earliest stages of ARHL 
can improve a person's performances on auditory memory tests [90]. 
Conventional HAs come in several styles and with a range of functionality. The most 
common styles of hearing aids are known as behind-the-ear (BTE) and in-the-ear (ITE) 
hearing aids. A radical change in terms of hearing rehabilitation in ARHL was the birth of 
Open Fitting (OF) coupling system. Thanks to the OF system the ear is left open and the snail 
is replaced by a small silicone dome that can be pierced or “tulip-shaped”; it is supported by a 
small tube that can be empty or more frequently traveled by an electric wire if the receiver is 
in the ear canal and not in the body of the HA. This has allowed a greater miniaturization and 
camouflage of the prosthesis, together with a greater tolerability and acceptance by the 
patient, as well as a better hearing quality thanks to the reduced effects of autofonia and 
occlusion of the external auditory canal [88]. 
Despite the high incidence of ARHL, the percentage of hearing impaired elderly who use 
hearing aids is relatively low (it is estimated, in fact, that only 20% of patients who need 
acoustic amplification regularly use HAs). This is mostly due to cultural and mental status, 
degree of socialization, education and/or family situation. In this regard, in the context of 
rehabilitation, a careful counseling activity aimed at patients and their relatives is very 
important, purposing to encourage the acceptance and adaptation of HAs, encouraging their 
use. In fact, elderly patients must be gradually educated to amplified hearing, giving them the 
opportunity to hear again sounds they were no longer used to hear [88]. 
The main limitation of HAs is in all those severe and profound hearing losses whose gain 
from the use of HAs is not able to activate the analyzing processes necessary for speech 
understanding. In these cases, after a careful evaluation of the patient and his life expectancy, 
and if there are no general medical contraindications, it will be possible to restore hearing 
thanks to Cochlear Implantation (CI). While in the past CI was not recommended for older 
patients, to date the outlook has completely changed. In fact, the majority of elderly patients 
using cochlear implants have demonstrated, both through subjective and objective 
assessments, a marked improvement in the ability to discriminate speech versus preoperative 
assessments, as well as an overall satisfaction and better hearing performance even compared 
to patients who have undergone surgery for CI at a younger age [2, 91, 92]. 
Given these considerations, counteracting ATHL since the earliest symptoms is very 
important, both from a prosthetic and an implantological point of view. 
Future perspectives in the field of audiological rehabilitation in the elderly are focusing 
on the possibility of developing a “hybrid” prosthetic system, able to stimulate the ear either 
by direct acoustic stimulation (as with the HA) or by electromagnetic stimulation (CI). This 
solution would be particularly indicated in all patients presenting a pure tone threshold 
rapidly falling on the higher frequencies with partial or total preservation of the lower 

Age-Related Hearing Loss 
 
895
frequencies. Other interesting research cues are oriented towards the discovery of one or more 
drugs able to prevent the death of acoustic receptors, hindering the worsening of ARHL or 
even exploiting stem cells in order to restore a “physiological hearing” [1, 93]. 
 
 
REFERENCES 
 
[1] 
Fortunato, S., Forlì, F., Guglielmi, V., De Corso, E., Paludetti, G., Berrettini, S., Fetoni, 
A.R. (2016) A review of new insights on the association between hearing loss and 
cognitive decline in ageing. Acta Otorhinolaringol Ital; 36: 155-166. 
[2] 
Jayakody, D.M.P., Friedland, P.L., Martins, R.N., Sohrabi, H.R. (2018) Impact of 
aging on the auditory system and related cognitive functions: a narrative review. Front 
Neurosci; 12 (125). 
[3] 
Lee, J., Dhar, S., Abel, R., Banakis, R., Grolley, E., Lee, J. (2012) Behavioral hearing 
thresholds between 0.125 and 20 kHz using depth-compensated ear simulator 
calibration. Ear Hear; 33: 315. 
[4] 
Agrawal, Y., Platz, E.A., Niparko, J.K. (2008) Prevalence of hearing loss and 
differences by demographic characteristics among US adults: data from the National 
Health and Nutrition Examination Survey, 1999-2004. Arch Intern Med; 168: 1522-
1530. 
[5] 
Yamasoba, T., Lin, F.R., Someya, S., Kashio, A., Sakamoto, T., Kondo, K. (2013) 
Current concepts in age-related hearing loss: epidemiology and mechanistic pathways. 
Hear Res; 303: 30-38. 
[6] 
Friedman, R.A., Van Laer, L., Huentelman, M.J., Sheth, S.S., Van Eyken, E., 
Corneveaux, J.J. (2009) GRM7 variants confer susceptibility to age-related hearing 
impairment. Hum Mol Genet; 18: 785-796. 
[7] 
Newman, D.L., Fisher, L.M., Ohmen, J., Parody, R., Fong, C.T., Frisina, S.T. (2012) 
GRM7 variants associated with age-related hearing loss based on auditory perception. 
Hear Res; 294: 125-132. 
[8] 
Van Eyken, E., Van Laer, L., Fransen, E., Topsakal, V., Lemkens, N., Laureys, W. 
(2006) KCNQ4: a gene for age-related hearing impairment? Hum Mutat; 27: 1007-
1016. 
[9] 
Van Eyken, E., Van Laer, L., Fransen, E., Topsakal, V., Hendrickx, J.J., Demeester, K. 
(2007) The contribution of GJB2 (Connexin 26) 35delG to age-related hearing 
impairment and noise-induced hearing loss. Otol Neurotol; 28: 970-975. 
[10] Amorini, M., Romeo, P., Bruno, R., Galletti, F., Di Bella, C., Longo, P., Briuglia, S., 
Salpietro, C., Rigoli, L. (2015) Prevalence of Deafness-Associated Connexin-26 
(GJB2) and Connexin-30 (GJB6) Pathogenic Alleles in a Large Patient Cohort from 
Eastern Sicily. Ann Hum Genet. Jun 19. 
[11] Lin, Y.H., Wu, C.C., Hsu, C.J., Hwang, J.H., Liu, T.C. (2011) The grainyhead-like 2 
gene (GRHL2) single nucleotide polymorphism is not associated with age-related 
hearing impairment in Han Chinese. Laryngoscope; 121: 1303.  

Rocco Bruno, Bruno Galletti, Pietro Abita et al. 
 
896
[12] Martines, F., Salvago, P., Bartolotta, C., Cocuzza, S., Fabiano, C., Ferrara, S., La 
Mattina, E., Mucia, M., Sammarco, P., Sireci, F., Martines, E. (2015) A genotype–
phenotype correlation in Sicilian patients with GJB2 biallelic mutations. European 
Archives of Oto-Rhino-Laryngology, 272 (8), pp. 1857-1865. 
[13] Bartolotta, C., Salvago, P., Cocuzza, S., Fabiano, C., Sammarco, P., Martines, F. 
(2014) Identification of D179H, a novel missense GJB2 mutation in a Western Sicily 
family. European Archives of Oto-Rhino-Laryngology, 271 (6), pp. 1457-1461. 
[14] Salvago, P., Martines, E., La Mattina, E., Mucia, M., Sammarco, P., Sireci, F., 
Martines, F. (2014) Distribution and phenotype of GJB2 mutations in 102 Sicilian 
patients with congenital non syndromic sensorineural hearing loss. International 
Journal of Audiology, 53 (8), pp. 558-563. 
[15] Oonk, A.M.M., Leijendeckers, J.M., Lammers, E.M., Weegerink, N.J.D., Oostik, J., 
Beynon, A.J. (2013) Progressive hereditary hearing impairment caused by aMYO6 
mutations resembles presbyacusis. Hear Res; 299: 88-98. 
[16] Van Eyken, E., Van Camp, G., Fransen, E., Topsakal, V., Hendrickx, J.J., Demeester, 
K. (2017) Contribution of the N-acetyltransferase 2 polymorphism NAT2*6° to age-
related hearing impairment. J Med Genet; 44: 570. 
[17] Ünal, M., Tamer, L., Dogruer, Z.N., Yildirim, H., Vayisoglu, Y., Çamdeviren, H. 
(2005) N-acetyltransferase 2 gene polymorphism and presbycusis. Laryngoscope; 115: 
2238-2241. 
[18] Ates, A., Ünal, M., Tamer, L., Derici, E., Karakas, S., Ercan, B. (2005) Glutathione S-
transferase gene polymorphism in presbycusis. Otol Neurotol; 26: 392-397. 
[19] Bai, U., Seidman, M.D., Hinojosa, R., Quirk, W.S. (1997) Mithochondrial DNA 
deletions associated with aging and possibly presbycusis: a human archival temporal 
bone study. Am J Otol; 18: 449. 
[20] Manwaring, N., Jones, M.M., Wang, J.J., Rochtchina, E., Howard, C., Newall, P. 
(2007) Mitochondrial DNA aplogroups and age-related hearing loss. Arch Otolaryngol 
Head Neck Surg; 133: 929-933. 
[21] O’Grady, G., Boyles, A.L., Speer, M., Deruyter, F., Strittmatter, W., Worley, G. (2007) 
Apolipoprotein E alleles and sensorineural hearing loss. Int J Audiol; 46: 183. 
[22] Uchida, Y., Sugiura, S., Nakashima, T., Ando, F., Shimokata, H. (2009) Endothelin-1 
gene polymorphism and hearing impairment in elderly Japanese. Laryngoscope; 119: 
938-943. 
[23] Fetoni, A.R., Picciotti, P.M., Paludetti, G., Troiani, D. (2011) Pathogenesis of 
presbycusis in animal models: a review. Exp Gerontol; 46(6): 413-425. 
[24] Campo, P., Morata, T.C., Hong, O. (2013) Chemical exposure and hearing loss. Dis 
Month; 59:119. 
[25] Fransen, E., Topsakal, V., Hendrickx, J.J., Van Laer, L., Huyghe, J.R., Van Eyken, E. 
(2008) Occupational noise, smoking and a high body mass index are risk factors for 
age-related hearing imparment and moderate alcohol consumption is protective: a 
European population-based multicenter study. J Assoc Res Otolaryngol; 9: 264-276. 

Age-Related Hearing Loss 
 
897
[26] Clark, W.W. (1991) Noise exposure from leisure activities: a review. J Acoust Soc Am; 
90: 175. 
[27] Sliwinska-Kowalska, M., Zamyslowska-Szmytke, E., Szymczack, W., Kotylo, P., 
Fiszer, M., Wesolowsky, W. (2004) Effects of co-exposure to noise and mixture of 
organic solvents on hearing in dockyard workers. J Occup Environ Med; 46: 30-38.  
[28] Chang, S., Chen, C., Lien, C., Sung, F. (2006) Hearing loss in workers exposed to 
toluene and noise. Environ Health Perspect; 114: 1283. 
[29] Fuente, A., McPherson, B. (2006) Organic solvents and hearing loss: the challenge for 
audiology. Int J Audiol; 45: 367. 
[30] Dispenza, F., De Stefano, A., Costantino, C., Marchese, D., Riggio, F. (2013) Sudden 
sensorineural hearing loss: Results of intratympanic steroids as salvage treatment. 
American Journal of Otol – Head and Neck Medicine and Survey; 34(4), 296-300. 
[31] Dispenza, F., Mazzucco, W., Bianchini, S., Mazzola, S., Bennici, E. (2015) 
Management of labyrinthine fistula in chronic otitis with cholesteatoma: case series; 
Euromediterranean Biomedical Journal 10(21), 255-261.  
[32] Gordon-Salant, S. (2010) The Aging Auditory System, Ed. Springer-Verlag, USA 2010. 
[33] Schuknecht, H.F. (1974) Pathology of the Ear. Cambridge, MA: Harvard University 
Press 1974. 
[34] Schuknecht, H.F., Gacek, M.R. (1993) Cochlear pathology in presbycusis. Ann Otol 
Rhinol Laryngol; 102, 1-16. 
[35] Schuknecht, H.F., Watanuki, K., Takahashi, T., Belal, A.A. Jr., Kimura, R.S., Jones, 
D.D., Ota, C.Y. (1974) Atrophy of the stria vascularis, a common cause for hearing 
loss. Laryngoscope; 84 (10): 1777-1821. 
[36] Schuknecht, H.F. (1964) Further observations on the pathology of presbycusis. Arch 
Otolaryngol; 80: 369-382. 
[37] Buckiova, D., Popelar, J., Syka, J. (2007) Aging cochleas in the F-344 rat: 
morphological and functional changes. Exp Gerontol; 42: 629-638. 
[38] Gates, G.A., Mills, J.H. (2005) Presbycusis. Lancet; 366: 1111-1120. 
[39] Gratton, M.A., Shulte, B.A. (1995) Alterations in microvasculature are associated with 
atrophy of the stria vascularis in quiet-aged gerbils. Hear Res; 82: 44-52. 
[40] Hinojosa, R., Nelson, E.G. (2011) Cochlear nucleus neuron analysis in individuals with 
presbycusis. Laryngoscope; 121: 2641–2648. 
[41] Mills, J.H., Konrad-Martin, D., Leek, M., Hood, L.J. (2006) Roundtable discussion: 
pathophysiology of the aging auditory system. Semin Hear; 27: 237–242. 
[42] Belal, A. (1975) Presbycusis: physiological or pathological. J. Laryngol. Otol; 89: 
1011–1025. 
[43] Henderson, D., Bielefeld, E.C., Harris, K.C., Hu, B.H. (2006) The role of oxidative 
stress in noise-induced hearing loss. Ear Hear; 27: 1-19. 
[44] Tabuki, K., Nishimura, B., Nakamagoe, M., Hayashi, K., Nakayama, M., Hara, A. 
(2011) Ototoxicity: mechanism of cochlear impairment and its prevention. Curr Med 
Chem; 18: 4866-4871.  

Rocco Bruno, Bruno Galletti, Pietro Abita et al. 
 
898
[45] Cannizzaro, E., Cannizzaro, C., Plescia, F., Martines, F., Sole, L., Pira, E., Lo Coco, D. 
(2014) Exposure to ototoxic agents and hearing loss: A review of current knowledge. 
Hearing, Balance and Communication; 12: 166-175. 
[46] Martines, F., Ballacchino, A., Sireci, F., Mucia, M., La Mattina, E., Rizzo, S. (2016) 
Audiologic profile of OSAS and simple snoring patients: the effect of chronic 
nocturnal intermittent hypoxia on auditory function. European Archives of Oto-Rhino-
Laryngology; 273: 1419-1424. 
[47] Martines, F., Messina, G., Patti, A., Battaglia, G., Bellafiore, M., Messina, A., Rizzo, 
S., Salvago, P., Sireci, F., Traina, M., Iovane, A. (2015) Effects of tinnitus on postural 
control and stabilization: A pilot study. Acta Medica Mediterranea; 31: 907-912. 
[48] Ferrara, S., Salvago, P., Mucia, M., Ferrara, P., Sireci, F., Martines, F. (2014) Follow-
up after pediatric myringoplasty: Outcome at 5 years. Otorinolaringologia; 64: 141-
146. 
[49] Rizzo, S., Bentivegna, D., Thomas, E., La Mattina, E., Mucia, M., Salvago, P., Sireci, 
F., Martines, F. (2016) Sudden sensorineural hearing loss, an invisible male: State of 
art. Hearing loss: etiology,management and societal implications, 75-86.  
[50] Cheng, A.G., Cunningham, L.L., Rubel, W.E. (2005) Mechanism of hair cell death and 
protection. Curr Opin Otolaryngol Head Neck Surg; 13: 343-348. 
[51] Someya, S., Prolla, T.A. (2010) Mitochondrial oxidative damage and apoptosis in age-
related hearing loss. Mech Ageing Dev; 131: 480-486. 
[52] Wen, J., Duan, N., Wang, Q., Jing, G.X., Xiao, Y. (2017) Protective effect of propofol 
on noise-induced hearing loss. Brain Res; 1657: 95-100. 
[53] Nomiya, R., Nomiya, S., Kariya, S., Okano, M., Morita, N., Cureoglu, S. (2008) 
Generalized arteriosclerosis and changes of the cochlea in young adults. Otol Neurotol; 
29: 1993-1997. 
[54] Panza, F., Solfrizzi, V., Logroscino, G. (2015) Age-related hearing impairment – a risk 
factor and frailty marker for dementia and AD. Nat Rev Neurol; 11: 166-175. 
[55] Martines, F., Maira, E., Ferrara, S. (2011) Age-related hearing impairment (ARHI): A 
common sensory deficit in the elderly. Acta Medica Mediterranea, 27 (1), 47-52.  
[56] Salvago, P., Rizzo, S., Bianco, A., Martines, F. (2017) Sudden sensorineural hearing 
loss: is there a relationship between routine haematological parameters and audiogram 
shapes? International Journal of Audiology; 56(3): 148-153. 
[57] Ballacchino, A., Salvago, P., Cannizzaro, E., Costanzo, R., Di Marzo, M., Ferrara, S., 
La Mattina, E., Messina, G., Mucia, M., Mulè, A., Plescia, F., Sireci, F., Rizzo, S., 
Martines, F. (2015) Association between sleep-disordered breathing and hearing 
disorders: Clinical observation in Sicilian patients. Acta Medica Mediterranea; 31(3): 
607-614. 
[58] Caspary, D.M. (2005) Age-related changes in the inhibitory response properties of 
dorsal cochlear nucleus output neurons: role of inhibitory inputs. J. Neurosci; 25: 
10952-10959. 
[59] Burianova, J., Ouda, L., Profant, O., Syka, J. (2009) Age-related changes in GAD 
levels in the central auditory system of the rat. Exp. Gerontol; 44: 161–169. 

Age-Related Hearing Loss 
 
899
[60] Simon, H., Frisina, R.D., Walton, J.P. (2004) Age reduces response latency of mouse 
inferior colliculus neurons to AM sounds. J Acoust Soc Am; 116: 469–477. 
[61] Richardson, B.D., Ling, L.L., Uteshev, V.V., Caspary, D.M. (2013) Reduced 
GABA(A) receptor-mediated tonic inhibition in aged rat auditory thalamus. J Neurosci; 
Jan 16;33(3):1218-27a. 
[62] Burianova, J., Ouda, L., Syka, J. (2015) The influence of aging on the number of 
neurons and levels of non-phosporylated neurofilament proteins in the central auditory 
system of rats. Front Aging Neurosci; 7: 27. 
[63] Gao, F., Edden, R.A.E., Li, M., Puts, N.A.J., Wang, G., Liu, C. (2013) Edited magnetic 
resonance spectroscopy detects an age-related decline in brain GABA levels. 
Neuroimage; 78: 75-82. 
[64] Gao, F., Wang, G., Ma, W., Ren, F., Li, M., Dong, Y. (2015) Decreased auditory 
GABA+ concentrations in presbycusis demonstrated by edited magnetic resonance 
spectroscopy. Neuroimage; Feb 1;106:311-6. 
[65] Koch, M. (2005) The neurobiology of startle. Prog Neurobiol; 59: 107-128. 
[66] Turner, J.G. (2005) Effects of aging on receptive fields in rat primary auditory cortex 
layer V neurons. J Neurophysiol; 94: 2738–2747. 
[67] Juarez-Salinas, D.L., Engle, J.R., Navarro, X.O., Recanzone, G.H. (2010) Hierarchical 
and serial processing in the spatial auditory cortical pathway is degraded by natural 
aging. J Neurosci; 30: 14795–14804. 
[68] Hughes, L.F., Turner, J.G., Parrish, J.L., Caspary, D.M. (2010) Processing of 
broadband stimuli across A1 layers in young and aged rats. Hear Res; 264: 79-85. 
[69] Verkhratsky, A., Toescu, E.C. (1998) Calcium and neuronal ageing. Trends Neurosci; 
21: 2–7. 
[70] Idrizbegovic, E., Bogdanovic, N., Willott, J.F., Canlon, B. (2004) Age related increases 
in calcium-binding protein immunoreactivity in the cochlear nucleus of hearing 
impaired C57BL/6J mice. Neurobiol Aging; 25: 1085-1093. 
[71] Ouda, L., Burianova, J., Syka, J. (2012) Age-related changes in calbindin and calretinin 
immunoreactivity in the central auditory system of the rat. Exp Gerontol; 47: 497–506. 
[72] Engle, J.R., Gray, D.T., Turner, H., Udell, J.B., Recanzone, G.H. (2014) Age related 
neurochemical changes in the rhesus macaque inferior colliculus. Front Aging 
Neurosci; 6: 73. 
[73] Gray, D.T., Rudolph, M.L., Engle, J.R., Recanzone, G.H. (2013) Parvalbumin 
increases in the medial and lateral geniculate nuclei of aged rhesus macaques. Front 
Aging Neurosci; 5: 69. 
[74] Husain, F.T., Medina, R.E., Davis, C.W., Szymko-Bennett, Y., Simonyan, K., Pajor, 
N.M. (2011) Neuroanatomical changes due to hearing loss and chronic tinnitus: a 
combined VBM and DTI study. Brain Res; 1369: 74-88. 
[75] Boyen, K., Langers, D.R.M., de Kleine, E., Van Dijk, P. (2013) Gray matter in the 
brain: differences associated with tinnitus and hearing loss. Hear Res; 295: 67-78. 
[76] Eckert, M.A., Cute, S., Vaden, K., Kuchinsky, S., Dunho, J. (2012) Auditory cortex 
signs of age-related hearing loss. J Assoc Res Otolaryngol; 13: 703-713. 

Rocco Bruno, Bruno Galletti, Pietro Abita et al. 
 
900
[77] Chang, Y., Lee, S., Lee, Y., Hwang, M., Bae, S., Kim, M. (2004) Auditory neural 
pathway evaluation on sensorineural hearing loss using diffusion tensor imaging. 
Neuroreport; 15: 1669-1703. 
[78] Ouda, L., Profant, P., Syka, J. (2014) Age-related changes in the central auditory 
system. Springer-Verlag 2014. 
[79] Willott, J.F., Aitkin, L.M., McFadden, S.L. (1993) Plasticity of auditory cortex 
associated with sensorineural hearing loss in adult C57BL/6J mice. J Comp Neurol; 
329: 402-411. 
[80] Robertson, D., Irvine, D.R.F. (1989) Plasticity of frequency organization in auditory 
cortex of guinea pigs with partial unilateral deafness. J Comp Neurol; 282: 456-471. 
[81] Tremblay, K.L., Burkhard, R.F. (2012) Hearing Across the Lifespan - Assessment and 
Disorders. San Diego, CA: Plural Publishing, Inc 2012. 
[82] Lin, F.R., Metter, E.J., O’Brien, R.J. (2011) Hearing loss and incident dementia. Arch 
Neurol; 68: 214-20. 
[83] Lin; F.R. (2011) Hearing loss and cognition among older adults in the United States. J 
Gerontol A Biol Sci Med Sci; 66: 1131-6. 
[84] Lin, F.R., Yaffe, K., Xia, J. (2013) Hearing loss and cognitive decline in older adults. 
Health ABC Study Group. JAMA Intern Med; 173: 293-9. 
[85] Fried, L.P. (2001) Frailty in older adults: evidence for a phenotype. J Gerontol A Biol 
Sci Med Sci; 56: M146–M156. 
[86] Genther, D.J., Betz, J., Pratt, S. (2000) Association of hearing impairment and 
mortality in older adults. J Gerontol A Biol Sci Med Sci; 55: M10-16. 
[87] Stach, B.A. (2010) Clinical Audiology: An Introduction, II Ed. Delmar, Cengage 
Learning; Canada, 2010. 
[88] Prosser, S., Martini, A. (2013) Argomenti di Audiologia. Omega Edizioni, Torino, 
2013. 
[89] Humes, L.E. (2012) Central presbycusis: a review and evaluation of the evidence. J Am 
Acad Audio; 23: 635-666. 
[90] Doherty, K.A. (2015) The benefit of amplification on auditory working memory 
function in middle-aged and young-older hearing impaired adults. Front Psychol 2015. 
[91] Di Nardo, W., Anzivino, R., Giannantonio, S. (2014) The effects of cochlear 
implantation on quality of life in the elderly. Eur Arch Otorhinolaryngol; 271: 65-73. 
[92] Lin, F.R., Albert, M. (2014) Hearing loss and dementia – who is listening? Aging Ment 
Health; 18: 671-673. 
[93] Vaisbuch, Y. (2018) Age-Related Hearing Loss: Innovations in Hearing Augmentation. 
Otolaryngol Clin North Am 2018. 
 

In: Encyclopedia of Audiology and Hearing Research 
ISBN: 978-1-53617-702-2 
Editors: Erno Larivaara and Senja Korhola 
© 2020 Nova Science Publishers, Inc. 
 
 
 
 
 
 
 
Chapter 59 
 
 
 
TRAUMATIC SENSORINEURAL HEARING LOSS 
 
 
Michele Cassano, MD, Valeria Tarantini, MD,  
Eleonora M. C. Trecca, MD, Antonio Moffa, MD  
and Gianluigi Grilli, MD 
Department of Otorhinolaryngology, University of Foggia, 
Foggia, Italy 
 
 
ABSTRACT 
 
Sensorineural hearing loss (SNHL) is a common consequence after head trauma. 
Head injury may cause temporal bone fracture that can result in damage to the otic 
capsule, petrous pyramid, and/or other middle and/or inner ear structures. The 
pathophysiology of hearing loss following temporal bone fractures has been largely 
attributed to the mechanical forces that grossly disrupt the fragile structures of the middle 
and inner ear. Another proposed mechanism is endolymphatic hydrop resulting from 
obstruction of the endolymphatic duct by the temporal bone fracture. 
However, remains a subset of patients who had traumatic brain injury with hearing 
loss without temporal bone fractures. There are different mechanisms that can cause such 
SNHL: disruption of the membranous labyrinth, avulsion or trauma to the cochlear nerve, 
interruption of the cochlear blood supply, hemorrhage into cochlea, and perilymphatic 
fistulae.  
Prompt evaluation of patient, early diagnosis and early treatment improves the 
prognosis. CT can detect pneumolabyrinth and signs of perilymphatic fistulae but fails to 
detect subtle lesions within the inner ear, such as labyrinthine haemorrhage or localized 
brain axonal damage along central auditory pathways, which are better detected by MRI. 
Treatment can be based upon etiology. If no definitive or treatable etiology is found, 
treatment is done as in Ideopathic sudden sensorineural hearing loss. Oral corticosteroid 
therapy is among the few treatment modalities that have gained acceptance. 
Intratympanic injection of dexamethasone is shown to effectively improve hearing in 
patients with severe or profound SNHL after treatment failure with standard therapy. 
Cochlear implants have been demonstrated to be effective in restoring hearing in cases of 
                                                        
 Corresponding Author’s Email: michele.cassano@unifg.it. 

Michele Cassano, Valeria Tarantini, Eleonora M. C. Trecca et al. 
 
902
bilateral profound SNHL after traumatic injury, although traumatic and anatomical 
limitations may make some patients unsuitable for cochlear implantation.  
 
Keywords: sensorineural hearing loss, traumatic sensorineural hearing loss, temporal bone 
fracture 
 
 
INTRODUCTION 
 
Head injuries are sustained by 5% of the population annually. Sensorineural hearing loss 
(SNHL) is very common following traumatic head injury with the incidence ranging from 7% 
to 50% [1]. Hearing impairment can be due to central or peripheral causes with middle ear or 
cochlea being the most common site of peripheral injury. The most pronounced injury is 
fracture of temporal bone but even labyrinthine concussion is frequent [2]. 
Since the injury occurs to the ear that contains both hearing and vestibular apparatus, 
generally SNHL is also associated with tinnitus, dizziness or vertigo [3]. 
In some patients deterioration of hearing and vestibular functions occurs immediately 
after head injury and it may be transient or permanent. In other patients the symptoms may 
not manifest until a few weeks post trauma. In some cases patients can show facial nerve 
palsy or perilymphatic fistula. 
A prompt diagnosis is necessary to establish the best treatment and improve the 
prognosis. 
 
 
PATHOPHYSIOLOGY 
 
Traumatic brain injuries (TBIs) are leading cause of morbidity and mortality worldwide. 
TBI is defined as a disruption in normal brain function caused by external forces, either direct 
or transmitted including falls, motor vehicle collisions, sport-related injuries, abuse/assault, 
and a strike by a blunt object or pressure blasts [4, 5]. Regardless of its cause, brain injury can 
result in physical, cognitive and behavioral impairments, leading to temporary or permanent 
dysfunction [6]. Patients with TBI can appear with significant central and peripheral 
neurological deficits. Auditory dysfunction after TBI has been well described in literature [7]. 
In order to better understand the mechanism underlying the traumatic sensorineural hearing 
loss, TBI can be classified into:  
 
1. TBI with temporal bone fracture 
2. TBI without temporal bone fracture 
 
TBI with Temporal Bone Fracture 
 
The temporal bone forms a part of the lateral skull base and houses the hearing and 
balance organs; it also brings the facial nerve from the brainstem to the facial soft tissues. The 
bone itself is subdivided into four parts: the mastoid process, the tympanic portion, the 
squamous and the petrous apex [8]. Temporal bone fractures have traditionally been classified 

Traumatic Sensorineural Hearing Loss 
 
903
as either longitudinal, transverse, and/or mixed according to the long axis of the fracture line 
considering the long axis of the petrous bone (Table 1) [9]. Longitudinal fractures are 
generally the most common of the two types and result from laterally derived blow. The 
fracture lines run parallel and extend through the petrosquamous suture line and continue 
anteriorly to the otic capsule. This results in a haemotympanum and ossicular disruption 
causing a conductive hearing loss (CHL) in the patient. The facial nerve (FN) could be 
involved in approximately 15%–20% of these fractures. Transverse skull base fractures are 
commonly caused by direct trauma delivered to the back of the head. The fracture line begins 
at the jugular foramen and extends across the petrous pyramid to the area of the foramen 
spinosum and foramen lacerum. Transverse fractures can lead to SNHL and vertigo. 50% of 
patients experience facial nerve palsy 10. Increasing data demonstrate that the majority of 
these fractures do not fit easily into one these categories but have mixed features.2 Moreover, 
this fracture classification does not provide useful prognostic information with regards to 
neurotologic deficits [11]. In 1994, a simpler method of classifying fractures proposed by 
Kelly and Tami [12], is to separate fractures into otic capsule disrupting or otic capsule 
sparing (Table 1). Their classification has proven more predictive of clinical outcomes [13].  
Fractures that disrupt the otic capsule will almost always result in a sensorineural hearing 
loss (SNHL) and are associated with a much higher incidence of facial nerve paralysis, nerve 
disruption, cerebrospinal fluid (CSF) leaks, and intracranial complications as compared with 
otic capsule sparing fractures. Blows to the occipital region usually cause otic capsule 
disrupting fractures. This kind of fractures runs from the foramen magnum across the petrous 
pyramid to the otic capsule. They will commonly pass through the jugular foramen, internal 
auditory canal, and foramen lacerum. These fractures rarely involve the ossicular chain or 
external auditory canal (EAC). 
Otic capsule sparing fractures usually cause a conductive or mixed hearing loss and they 
are normally caused by a blow to the temporoparietal region and involve the squamous 
temporal bone and posterosuperior wall of the EAC. They pass through the mastoid air cells 
and middle ear, fracture the tegmen mastoideum and tegmen tympani, and then continue 
anterolaterally to fracture the tegmen in the region of the facial hiatus [11]. 
 
Table 1. Classification schemes and complications by TBI  
with temporal bone fracture 
 
Classification scheme 
Fracture class 
Complications 
Traditional 
classification 
(In relation to the 
petrous bone axis) 
Longitudinal 
Hemotympanum, ossicular disruption, CHL, FN 
palsy (15-20%) 
Transverse 
SNHL, vertigo, FN palsy reported in 50% of patients 
Mixed 
Mixed features 
Alternative 
classification 
(Kelly and Tami, 1994) 
Otic capsule 
disrupting 
SNHL, higher incidence of facial nerve paralysis, 
nerve disruption, CSF fistula, intracranial 
complications 
Otic capsule 
sparing 
Conductive or mixed hearing loss 
 
There are other pathogenic mechanisms producing SNHL in temporal bone fractures: the 
cochlear nerve may be avulsed or directly injured by fractures that extend across or along the 

Michele Cassano, Valeria Tarantini, Eleonora M. C. Trecca et al. 
 
904
internal auditory canal [14, 15]; vascular vasospasm, thrombosis or hemorrhage into the inner 
ear may result in SNHL [14, 16]; the fracture line may extend across the vestibular acqueduct, 
resulting in occlusion and secondary endolymphatic hydrop [14, 17]. 
 
 
TBI without Temporal Bone Fracture 
 
While hearing loss following temporal bone fracture is common, few data exist on 
auditory dysfunction in patients with TBI without temporal bone fracture. Among possible 
causes are considered trauma to peripheral pathway (labyrinthine concussion) or even direct 
damage to the central auditory system [18, 19]. Labyrinthine concussion may be described as 
perceptive deafness and vertigo resulting from a blow to the head without fracture of bony 
labyrinth capsule. A head injury can lead to either an isolated damage to the otolith organs 
(vestibular labyrinthine concussion) or injuries to the labyrinth of the inner ear without 
damage to the otic capsule or intralabyrinthine limiting membranes (cochlear labyrinthine 
concussion) [20, 21]. The underlying pathology was thought to be due to damage from the 
acceleration/deceleration forces on the inner ear. The nature of the injury is a tearing or 
rupture of the sensory cells from their supporting cell attachments on the basilar membrane 
induced by the excessive displacement of the basilar membrane. In less severe instances, 
separations of the Hensen cell tight cell junctions at the reticular lamina are created which 
also leads to an intermixing of cochlear fluids and the eventual loss of sensory cells [22]. It is 
also speculated that high-pressure waves caused by a blow to the head is directly transmitted 
to the cochlea by bone conduction [23-25]. 
Regarding damage to the central auditory system, there are two primary damage 
categories: injury to the brainstem such as the inferior colliculi [26, 27] and injury to the brain 
such as temporal bone contusion [28]. 
 
 
Perilymphatic Fistula with Pneumolabyrinth 
 
A perilymphatic fistula (PLF) is an abnormal connection between the inner ear and 
middle ear or mastoid cavity secondary to a dehiscence in the otic capsule, oval or round 
window [29]. PLFs typically present with hearing loss and vertigo following head or ear 
trauma that can mimic many other otolaryngologic entities, such as labyrinthine concussion, 
traumatic Meniere’s and cervical vertigo. Trauma is currently the most common cause of 
PLF, and can be associated with blunt or penetrating trauma, with or without associated 
temporal bone fracture [30]. 
Pneumolabyrinth describes a condition of acute inner ear dysfunction associated with 
perilymphatic fistula and the presence of air within the labyrinth. Symptoms associated with 
pneumolabyrinth include acute hearing loss, vertigo and pressure sensation in the affected ear. 
These symptoms presumably reflect changes in resonance of basilar membrane motion, 
impaired transduction, and pressure changes within the labyrinth [31]. The pathophysiology 
of symptoms produced by pneumolabyrinth is due to the presence of air on the ear membrane 
potential generation. This could be due to entry of air through an apical opening thereby 
increasing the threshold of the action potential (CAP) of the auditory nerve [31, 32]; 
perfusion of scala tympani with air causing immediate and drastic decrease of the cochlear 

Traumatic Sensorineural Hearing Loss 
 
905
microphonics (CM) and compound action potential with relatively little effect on 
endocochlear direct current potential (endocochlear potential) [31, 33]; with air perfusion of 
the scala vestibule, CM potentials were more drastically attenuated than with similar air 
applied to the scala tympani, suggesting a poorer prognosis with fistula of the oval window 
compared with that of the round window [31, 34]. 
 
 
DIAGNOSIS 
 
Clinical Evaluation (Table 2) 
 
The otologic evaluation should include inspection of the mastoid prominence for Battle 
sign, which is an ecchymosis over the mastoid prominence related to emissary vein disruption 
seen 
in 
lateral 
skull 
base 
fractures 
and, 
specifically, 
temporal 
bone  
fractures [35]. 
 
Table 2. Diagnostic protocol 
 
Diagnostic levels 
Examination 
Clinical 
assessment 
History 
Past medical history, onset of facial palsy, trauma 
mechanism, audiological and/or neurological symptoms 
Clinical 
examination 
 
Inspection of the mastoid prominence (Battle sign) 
 
Inspection of the ear canal/tympanic membrane 
Cranial nerve 
examination 
 
Functional status of the FN 
Auditory testing 
 
Pure tone and speech audiometry  
 
ABR 
Vestibular 
testing 
 
ENG/VNG 
 
Romberg sign, gait ataxia and moving platform 
posturography 
Radiological 
evaluation 
CT 
 
Temporal bone fractures and ossicular injuries 
 
Perilymphatic fistula 
MRI 
 
Detection of inner ear hemorrhage 
 
Post-traumatic lesions of the brain parenchyma 
 
The ear canal must be inspected and assessed for the most common findings associated 
with traumatic brain injuries including tympanic membrane perforation, bloody otorrhea and 
hemotympanum [9, 35-37]. In temporal bone fractures it is possible to find external ear canal 
stenosis, brain herniation and fracture of the roof of the EAC.  
Traumatic perilymphatic fistula is suspected in cases of cerebrospinal fluid otorrhea. In 
otic capsule-sparing fractures, the CSF usually leaks through a fracture of the tegmen tympani 
or mastoideum into the epitympanum, antrum, and mastoid air cell tract. It can present as 
clear otorrhea if the tympanic membrane is disrupted or as rhinorrhea if the tympanic 
membrane is intact. In otic capsule-disrupting fractures, CSF will flow from the posterior 
fossa into the middle ear through the otic capsule.  

Michele Cassano, Valeria Tarantini, Eleonora M. C. Trecca et al. 
 
906
It is essential that the functional status of the facial nerve have to be recorded as soon as 
possible during the initial general clinical examination because a nerve injury could lead to a 
prompt surgical treatment.  
Early audiometric testing is recommended for evaluating the baseline post-injury hearing 
status [38]. 
TBI can be associated with conductive, sensorineural or mixed hearing loss that can be 
assessed with a pure tone and a speech audiometry. In otic capsule-violating fractures, severe 
to profound SNHL can be immediately apparent. Otic capsule- sparing fractures can manifest 
both sensorineural and conductive hearing loss. Conductive losses are caused by initial 
hemotympanum or effusion, and permanent deficits are caused by disruption of the ossicular 
chain, which occurs in approximately 20% of patients [39]. The most common injuries of the 
ossicular chain include subluxation of the incudo-stapedial (IS) joint (82%), dislocation of the 
incus (57%), and fracture of the stapes crura (30%) [40]. A subsequent full audiological 
examination should be performed three to six weeks post-injury, to allow sufficient time for 
the resolution of haemotympanum, because the presence of middle ear fluid (CSF or blood) 
results in a conductive loss.  
In labyrinthine concussion, sensorineural hearing loss particularly affected high 
frequencies with recruitment [21]. When present, the most common pattern of hearing loss is 
similar to that of a noise-induced hearing loss, with a loss that is most apparent at 4 kHz [41, 
42].  
The use of auditory brain-stem response (ABR) has been reported as the standard to 
evaluate comatose patients [43]. Indeed the ABR grading system is a sensitive index of 
brainstem dysfunction and the presence or prolongation of V wave and I-V interwave latency 
even in one ear is of good prognostic value in the comatosed patient [43]. Also Testing 
DPOAE may help in detecting sub-clinical injuries to cochlea. Distortion product oto-acoustic 
emissions assessment at 3000 and 4000 Hz has a higher predictive value in assessing outer 
hair cell damage [44]. 
The presence and type of nystagmus should be noted. Electronystagmography/video 
nystagmography (ENG/VNG) can aid in categorization of vestibular injury. Romberg sign, 
gait ataxia and moving platform posturography are helpful to quantify balance deficits [45, 
46]. The most common type of vertigo associated with head trauma is benign paroxysmal 
positional vertigo (BPPV). Most post-traumatic vertigo and nystagmus resolve spontaneously 
in the first 4 to 6 weeks after injury.  
 
 
Radiological Evaluation (Table 2) 
 
Radiological evaluation is important in patients with post-traumatic hearing loss. The 
adequacy and selection of the imaging technique with correct interpretation is crucial for 
diagnosis and prognosis, enabling the selection of the appropriate treatment [47].  
Computed Tomography (CT) is the first choice technique and will allow the detection of 
alterations that cause conductive hearing loss. It allows radiologists to examine the complex 
anatomy of the temporal bone with sub-millimetric resolution and it is capable of revealing a 
broad spectrum of ossicular lesions that may not be apparent on clinical findings alone. 
Virtual otoscopy with 3-D reconstructions of CT images can provide a different view on 
ossicular chain anomalies in traumatic conditionsn [48]. In the case of sensorineural hearing 

Traumatic Sensorineural Hearing Loss 
 
907
loss, CT can detect pneumolabyrinth and signs of perilymphatic fistulae but fails to detect 
subtle lesions within the inner ear, such as labyrinthine haemorrhage or localized brain axonal 
damage along central auditory pathways [49] In these cases, Magnetic Resonance Imaging 
(MRI) with 3D-FLAIR acquisition is very important in the detection of inner ear 
haemorrhage and post-traumatic lesions of the brain parenchyma that may lead to auditory 
neuropathy. 
The potential lesions that cause post-traumatic hearing loss are discussed below and the 
most suitable radiological examination will be suggested. 
 
 
Temporal Bone Fractures and Ossicular Injuries 
 
CT is the modality of choice for evaluating temporal bone fractures (Figure 1). The 
fractures investigated include fracture line’s direction (longitudinal, trasverse or mixed), the 
affected portion (fractures that involve the petrous apex and those that spare the petrous 
apex)50 and the otic capsule involvement (otic capsule violating or otic capsule sparing). 
One of the most complex spaces of the temporal bone is the middle ear cavity. Within 
this space resides the ossicular chain constituted by three ossicles - the malleus, the incus, and 
the stapes - linked together by two articulations: the incudo- malleolar joint and the incudo-
stapedial joint. The incus is the heavier ossicle, with a body and two processes of differing 
length. The body articulates with the head of the malleus, and the short process is directed 
posterolaterally while the thin long process runs inferiorly in parallel to the malleus handle. 
Laterally, the tympanic membrane and the malleus handle close the middle ear cavity. The 
head of the malleus is better observed on the upper axial slices at the incudo- malleolar joint. 
The lower slices show the lenticular process of the incus articulating with the head of the 
stapes. This is connected to the footplate via the neck, from which the anterior crus and 
posterior crus emerge [49]. 
Ossicular chain disruption is usually seen with longitudinal fractures or otic capsule–
sparing fractures of the temporal bone. CT findings of ossicular injury may be difficult to 
evaluate due to hemotympanum. Ossicular dislocation is more common than ossicular 
fracture. There are five types of dislocations: incudo-stapedial joint separation, incudo-
malleal joint separation, incus dislocation, incudo-malleal complex dislocation, and stapedio-
vestibular dislocation [48]. 
Stapedio-vestibular dislocation is often associated with cochleovestibular symptoms 
including SNHL, tinnitus and acute vestibulopathy because the injury of the annular ligament 
or stapes footplate may cause a perilymphatic fistula. Transverse reconstruction of CT in the 
plane of the oval window and coronal reconstruction can show the medial displacement of the 
stapes footplate and the distal portion of both stapedial crura within the vestibule due to injury 
to the annular ligament. 
Isolated ossicular fractures are less frequent than joint luxation and may involve any one 
part of the chain. Injuries to the stapes may be difficult to diagnose at the early stages due to 
hemotympanum and they are more frequently associated with severe high frequency hearing 
loss. Fracture of the footplate occurs secondary to a transverse fracture passing through the 
oval window, and may cause a perilymphatic fistula with pneumolabyrinth [49].  

Michele Cassano, Valeria Tarantini, Eleonora M. C. Trecca et al. 
 
908
 
Figure 1.CT scan showing a right temporal bone fracture. 
 
Labyrinthine Concussion 
 
This injury of the membranous labyrinth without bone fracture is difficult to evaluate 
with CT [47]. MRI can demonstrate hemolabyrinth; in the T1-weighted sequences. It presents 
as an intrinsic hyperintensity due to its methaemoglobin content [49-53], although the 3D-
FLAIR sequence is more useful because of its greater sensitivity to detect subtle changes in 
the signal of the lymphatic fluid (blood alters the composition of the perilymph) [54]. Non-
enhanced FLAIR acquisition may reveal a hypersignal inside the cochlea, vestibule or both 
[25]. 
 
 
Perilymphatic Fistula 
 
A perilymphatic fistula is a direct connection between the middle ear and inner ear 
cavities. There are two zones of weakness between these two cavities: the oval window and 
the round window. The oval window is affected either by a footplate fracture or by a lesion to 
the annular ligament, which may be isolated or associated with stapedio-vestibular 
disarticulations or stapes dislocation (external or internal). When the round window is 
affected, the fracture line can be seen around the edges of the window. The radiologist must 

Traumatic Sensorineural Hearing Loss 
 
909
examine CT scan thoroughly to identify the fracture line in the axial and coronal planes [49]. 
A pneumolabyrinth or pneumocochlea can be seen in the absence of temporal bone fracture 
[55]. CT can help identify the possible fracture trace and the pneumolabyrinth. Other possible 
specific signs are the intravestibular displacement of the plate and the presence of opacity at 
the site of the oval window [56]. When the exact site of bony defect is not identified, CT 
cisternography with intrathecal contrast can be used. Intrathecal fluorescein is a highly 
sensitive and specific test used typically when the other methods have failed to locate the 
fistula. There are occasional reports of neurotoxicity, seizures, and paraparesis, but these 
complications are infrequent and occur at higher doses of fluorescein than is recommended 
[11]. MRI can detect perilymph in the middle ear, although it is difficult to differentiate it 
from the hemotympanum. 
 
 
Endolymphatic Hydrops 
 
It is a post-traumatic dilatation of the endolymphatic space. In a normal patient, the 
endolymphatic duct is observed in MRI as a hypointense laminar structure due to its lack of 
contrast uptake, while the perilymphatic space show contrast uptake and is hyperintense. The 
saccule and the utricle are individualized and have a rounded shape. To look for a post-
traumatic endolymphatic hydrops, it is necessary to perform the FLAIR sequence 4 hours 
after contrast media injection, to identify a dilatation of the endolymphatic duct that 
completely obliterates the vestibular ramp and a dilatation of the saccule and the utricle that 
completely fills the vestibule [47]. 
 
 
Injury to the Central Auditory Pathways 
 
The central auditory pathway should be assessed along its whole length: cochlea, 
cochlear nerve, cochlear nucleus, inferior colliculus, medial geniculate body and auditory 
cortex.  
It is important to distinguish injuries that occur along the central auditory pathways 
before the decussation into the superior olivary nucleus that may lead to asymmetrical SNHL, 
from those potentially responsible for associated auditory neuropathy [57]. The lesions that 
may lead to SNHL may be secondary to axonal injury, contusion or hemorrhage. Cochlear 
nerves could be injured by a superficial leptomeningeal hemosiderosis that may be seen after 
head trauma [58]. The diagnosis of hemosiderosis often relies on MRI with susceptibility-
weighted imaging. Theoretically, isolated injury of the thalamus, auditory radiations, or 
auditory cortex could alter auditory function. Isolation of auditory radiations requires 
advanced diffusion techniques, such as MR tractography, while the auditory cortex can be 
visualized with functional MRI [59, 60]. Post-traumatic cerebral contusion located along the 
Heschl’s gyrii may be responsible for SNHL. New MR techniques such as susceptibility-
weighted imaging or track-weighted imaging will likely prove useful in the assessment of 
focal brain lesions after trauma, including mild traumatic brain injury.  
 
 

Michele Cassano, Valeria Tarantini, Eleonora M. C. Trecca et al. 
 
910
Labyrinthitis Ossificans 
 
When a temporal bone fracture involves the inner ear structures (usually an otic capsule–
violating fracture), labyrinthitis ossificans can result, in which the fluid-filled lumen of the 
otic capsule is replaced by bone (or fibrous tissue at the early stages) [61, 62]. Clinically, this 
is associated with profound sensorineural hearing loss and loss of vestibular function. On 
high-spatial-resolution CT images, osseous attenuation is noted within the inner ear. The 
corresponding MR images show loss of fluid signal intensity within the membranous 
labyrinth and enhancement on gadolinium- enhanced images. Heavily T2-weighted high-
spatial-resolution sequences are most sensitive for detection at its earliest (fibrous) stage. MR 
findings precede CT changes by many months, as the earlier fibrous stage prior to ossification 
may not be detectable on CT images but may be seen on MR images as loss of fluid signal 
intensity in the membranous labyrinth [63]. 
 
 
TREATMENT 
 
The prognosis for patients with post-traumatic brain injury SNHL is very poor. Cochlear 
implants (Table 3) have been demonstrated to be effective to restore hearing in cases of 
bilateral profound SNHL after traumatic injury, given that the functions of the cochlear nerve 
and brain are intact [64], although traumatic and anatomical limitations may make some 
patients unsuitable for cochlear implantation.  
There are several factors to be considered before performing cochlear implantation in 
patients with profound hearing loss caused by bilateral temporal bone fractures. The decision 
to proceed with cochlear implantation after trauma is very difficult and the proper timing of 
the operation is still controversial.  
Temporal bone fracture may result in destruction and degeneration of hair cells, 
supporting cells, and ganglion cells [65]. It is intuitive that implantation shortly after trauma 
would provide less time for spiral ganglion cell loss and would increase the chance of 
successful rehabilitation. On the other hand, surgical intervention that is too early can 
preclude the opportunity for natural restoration of hearing. Regular audiometric examination 
must be performed to confirm that the hearing level has been fixed.  
In case of labyrinthine concussion, hemorrhage in the inner ear causes a hyperplastic 
inflammatory response leading to degeneration of neural elements, eventual fibrosis and new 
bone formation [66]. Labyrinthitis ossificans as a result of TB fractures and secondary 
infection may also inhibit successful insertion of the electrode array. The most frequent site of 
ossification appears to be the basal turn of the scala tympani [67, 68]. It is likely that the 
sooner cochlear implantation is performed after injury, the less time there is for cochlear 
osteoneogenesis and, therefore, the greater the likelihood for successful electrode insertion. 
When there is a significant time delay between the initial CT scan and the time of cochlear 
implantation, repeat imaging is beneficial to rule out labyrinthitis ossificans and other 
structural abnormalities that may inhibit successful placement of electrodes. Preoperative CT 
and high-resolution T2 MRI are useful methods to determine the patency of the cochlea [69, 
70]. The possibility of retrocochlear lesions (auditory nerve, brain) should be considered. If a 
patient has bilateral fractures through the internal auditory canal, brain stem implantation 
(Table 3) may be an option for aural rehabilitation instead of cochlear implantation [71]. 

Traumatic Sensorineural Hearing Loss 
 
911
Results of cochlear implantation in patients with auditory cortex injuries are equivocal. 
Cognitive, behavioral and communicative deficits, including aphasia, should all be evaluated 
to determine the aural rehabilitation method. Promontory stimulation testing can be beneficial 
to confirm the presence of functioning eighth nerve. Although unilateral cochlear 
implantation generally provides good speech understanding in quiet conditions, unilateral 
cochlear implantation patients frequently report difficulties in understanding speech and 
localizing sound in noisy environments. Bilateral cochlear implantation has several 
advantages over unilateral implantation including improvement in speech perception in noisy 
environments and improved sound localization by head shadow, binaural squelch and 
binaural summation effects. In patients deafened by bilateral temporal bone fractures, 
bilateral cochlear implantation may be a better method for aural rehabilitation than unilateral 
cochlear implantation [69, 72].  
There is no standard treatment protocol for management of sensorineural hearing loss in 
the immediate post trauma time [73-76]. Treatment options for SNHL depend on the severity 
of hearing loss and presence of associated complications.  
In case of labyrinthine concussion or otic capsule sparing temporal bone fractures with 
mild symptoms associated, conservative treatment with high-dose corticosteroids (Table 3) is 
suggested [9].  
Most cases of CSF leak occur in the first week after trauma and close spontaneously with 
conservative medical management (strict bed rest, elevation of bed by 30°, and avoidance of 
straining) [63]. If the CSF leak fails to respond, exploratory surgery is suggested. Fat and 
perichondrium are commonly used for repair [77]. Also temporalis fascia and muscle are used 
for fistula repair [14]. Repair of the fistula, even if done relatively late, markedly reduces 
vestibular symptoms and improves low and middle frequency sensorineural hearing. 
 
Table 3. Treatment 
 
Treatment 
Indications 
Conservative 
treatment 
High-dose 
corticosteroids 
 
Labyrinthine concussion 
 
Otic capsule sparing temporal bone fractures 
 
Mild symptoms associated 
 
Incomplete FN paralysis 
Early surgical 
intervention 
 
 
FN paralysis 
 
Persisting cerebrospinal fluid leakage  
 
Vestibular symptomatology (with severe symptoms 
such as intractable nausea and vomiting) 
 
Recurrent meningitis 
Aural 
rehabilitation 
 
Cochlear implants 
 
Brainstem 
implantation 
 
Bilateral profound SNHL after traumatic injury 
 
Possibility of retro-cochlear lesions (auditory nerve, 
brain) 
 
The indications for early surgical intervention (Table 3) in patients with TBI include 
facial paralysis, persisting cerebrospinal fluid leakage and vestibular symptomatology (with 
severe symptoms such as intractable nausea and vomiting), recurrent meningitis [9, 29]. 
Observation and high- dose steroids can manage incomplete facial paralysis, with surgical 
exploration considered only if an evident bone fragment is seen impinging the facial nerve 

Michele Cassano, Valeria Tarantini, Eleonora M. C. Trecca et al. 
 
912
canal. Early complete paralysis may predicate the need for urgent surgical exploration. The 
perigeniculate area is more susceptible to injury due to traction from the greater superficial 
petrosal nerve [79-82]. 
 
 
REFERENCES 
 
[1] 
Fitzgerald, D. C. (1996). Head trauma: hearing loss and dizziness. J Trauma 40(3): 
488-496. 
[2] 
Dahiya. R., Keller, J. D., et al. (1999). Temporal bone fractures: otic capsule sparing 
versus otic capsule violating clinical and radiographic considerations. J Trauma; 47: pp 
1079-83. 
[3] 
Folmer, R. L., Griest, S. E. (2003). Chronic tinnitus resulting from head or neck 
injuries. Laryngoscope; 113(5):821-7. 
[4] 
Najem, D., Rennie, K., Ribecco-Lutkiewicz, M., Ly, D., Haukenfrers, J., Liu, Q., Nzau, 
M., Fraser, D., Bani, M. (2018). Traumatic Brain Injury: Classification, Models and 
Markers. Biochem Cell Biol. 25. doi: 10.1139/bcb-2016-0160. 
[5] 
Taylor, C. A., Bell, J. M., Breiding, M. J., Xu, L. (2017). Traumatic brain injury–related 
emergency department visits, hospitalizations, and deaths—United States, 2007 and 
2013. MMWR Surveill Summ; 66(9):1-16. 
[6] 
Reis, C., Wang, Y., Akyol, O., Ho, W. M., Ii, R. A., Stier, G., Martin, R, and Zhang, J. 
H. (2015). What’s new in traumatic brain injury: update on tracking, monitoring and 
treatment. Int. J. Mol. Sci. 16(6): 11903–11965.  
[7] 
Segal, S., Eviatar, E., Berenholz, L., Kessler, A., Shlamkovitch, N. (2002). Dynamics of 
sensorineural 
hearing 
loss 
after 
head 
trauma. 
Otol 
Neurotol; 
23:  
312-5. 
[8] 
Honeybrook, A., Patki, A., Chapurin, N., Woodard, C. (2017). Hearing and Mortality 
Outcomes following Temporal Bone Fractures. Craniomaxillofac Trauma Reconstr; 
10:281–285.  
[9] 
Cannon, C. R., Jahrsdoerfer, R. A. (1983). Temporal bone fractures: review of 90 cases. 
Arch Otolaryngol; 109:285–8. 
[10] Kanavati, O., Salamat, A. A., Tan, T. Y., Hellier, W. (2015). Bilateral temporal bone 
fractures associated with bilateral profound sensorineural hearing loss. Postgrad Med J; 
0:1–2.  
[11] Ghorayeb, B. Y., Yeakley, J. W. (1992). Temporal bone fractures: longitudinal or 
oblique? The case for oblique temporal bone fractures. Laryngoscope; 102(2):129–134.  
[12] Kelly, K. E., Tami, T. A. Temporal bone and skull base trauma. In: Jackler RK, 
Brackmann DE, eds. Neurotology. St Louis: Mosby, 1994;1127–47  
[13] Brodie, H. A., Thompson, T. C. (1997). Management of complications from 820 
temporal bone fractures. Am J Otol; 18(2):188–197. 
[14] Lyos, A. T., Marsh, M. A., Jenkins, H. A., et al. (1995). Progressive hearing loss after 
transverse temporal bone fracture. Arch Otolaryngol Head Neck Surg; 121:795Y9.  

Traumatic Sensorineural Hearing Loss 
 
913
[15] Ward, P. H. (1969). The histopathology of auditory and vestibular disorders in head 
trauma. Ann Otol Rhinol Laryngol.; 78: 227-238. 
[16] Schuknecht, H. F. (1969). Mechanism of inner ear injury from blow to the head. Ann 
Otol Rhinol Laryngol.; 78: 253-262. 
[17] Rizvi, S. S., Gibbin, K. P. (1979). Effect of transverse temporal bone fracture on the 
fluid compartment of the inner ear. Ann Otol Rhinol Laryngol.; 88: 741-748. 
[18] Chen, J. X., Lindeborg, M., Herman, S. D., Ishai, R., Knoll, R. M. et al. (2018). 
Systematic review of hearing loss after traumatic brain injury without associated 
temporal bone fracture. Am J Otolaryngol.; 39 (3): 338-344. 
[19] Makishima, K., Snow, J. B. (1975). Pathogenesis of hearing loss in head injury: Studies 
in man and experimental animals. Arch Otolaryngol; 101:426–432.  
[20] Brusis, T. (2011). Sensorineural hearing loss after dull head injury or concussion 
trauma. Laryngorhinootologie; 90 (2): 73-80. 
[21] Chiaramonte, R., Bonfiglio, M., D’Amore, A., et al. (2013). Traumatic Labyrinthine 
Concussion in a Patient with Sensorineural Hearing Loss. The Neuroradiology 
Journal 26: 52-55.  
[22] Patterson Jr., J. H., Hamernik, R. P. (1997). Blast overpressure induced structural and 
functional changes in the auditory system. Toxicology; 121:29-40. 
[23] Schuknecht, H. F., Davison, R. C. (1956). Deafness and vertigo from head injury. AMA 
Arch Otolaryngol; 63:513–528. 
[24] Choi, M. S., Shin, S. O., Yeon, J. Y., Choi, Y. S., Kim, J., Park, S. K. (2013). Clinical 
Characteristics 
of 
Labyrinthine 
Concussion. 
Korean 
J 
Audiol; 
17:13. 
doi:10.7874/kja.2013.17.1.13. 
[25] Ulug, T., Ulubil, S. A. (2006). Contralateral labyrinthine concussion in temporal bone 
fractures. J Otolaryngol; 35: 380-3. 
[26] Hu, C. J., Chan, K. Y., Lin, T. J., Hsiao, S. H. (1997). Traumatic brainstem deafness 
with normal brainstem auditory evoked potentials. Neurology; 48:1448–51. 
[27] Jani, N. N. (1991). Deafness after bilateral midbrain contusion: a correlation of 
magnetic resonance imaging with auditory brain stem evoked responses. Neurosurgery; 
29:106–9. 
[28] Fujimoto, C., Ito, K., Takano, S., Karino, S. (2007). Successful cochlear implantation in 
a patient with bilateral progressive sensorineural hearing loss after traumatic 
subarachnoid hemorrhage and brain contusion. Ann Otol Rhinol Laryngol; 116:897–
901. 
[29] Prisman E., Ramsden, J. D., et al. (2011). Traumatic Perilymphatic Fistula with 
Pneumolabyrinth: Diagnosis and Management. Laryngoscope, 121:856–859.  
[30] Kim. S. H., Kazahaya, K., Handler, S. D. (2001). Traumatic perilymphatic fistulas in 
children: etiology, diagnosis and management. International Journal of Pediatric 
Otorhinolaryngology; 60.147–153. 
[31] Lao W. W., Niparko, J. K. (2007). Assessment of Changes in Cochlear Function with 
Pneumolabyrinth After Middle Ear Trauma. Otology & Neurotology 28(8):1013-1017.  

Michele Cassano, Valeria Tarantini, Eleonora M. C. Trecca et al. 
 
914
[32] Nishioka, I., Yanagihara, N. (1986). Role of air bubbles in the perilymph as a cause of 
sudden deafness. Am J Otol; 7:430-8.  
[33] Kobayashi, T., Itoh, Z., Sakurada, T., et al. (1990). Effect of perilymphatic air perfusion 
on cochlear potentials. Acta Otolaryngol (Stockh); 110:209-16.  
[34] Kobayashi, T., Sakurada, T., Ohyama, K., et al. (1993). Inner ear injury caused by air 
intrusion to the scala vestibule of the cochlear. Acta Otolaryngol (Stockh); 113:725-30.  
[35] Diaz R. C., Cervenka, B., Brodie, H. A. (2016). Treatment of Temporal Bone Fractures. 
J Neurol Surg B; 77:419–429. 
[36] Ferrara, S., Salvago, P., Mucia, M., Ferrara, P., Sireci, F., Martines, F. (2014). Follow-
up after pediatric myringoplasty: Outcome at 5 years. Otorinolaringologia; 64: 141-
146. 
[37] Martines, F., Bentivegna, D., Maira, E., Marasà, S., Ferrara, S. (2012). Cavernous 
haemangioma of the external auditory canal: Clinical case and review of the literature. 
Acta Otorhinolaryngol Ital; 32(1): 54-57. 
[38] Song, S. W., Jun, B. C., Kim, H. (2017). Clinical features and radiological evaluation of 
otic capsule sparing temporal bone fractures. The Journal of Laryngology & Otology, 
131, 209–214.  
[39] Yoganandan, N., Pintar, F. A., Sances, A. Jr, et al. (1995). Biomechanics of skull 
fracture. J Neurotrauma; 12(4):659–668. 
[40] Hough, J. V. D., Stuart, W. D. (1968). Middle ear injuries in skull trauma. 
Laryngoscope; 78(6):899–937. 
[41] Flint, P., Haughey, B., et al. Etiology of Sensorineural Hearing Loss. In: Cummings 
otolaryngology head & neck surgery. Elsevier; 2004. 5th edition, Chap.149. 
[42] Bamiou, D. E., Davies, R. A., Mckee, M., et al. (1999). The effect of severity of 
unilateral vestibular dysfunction on symptoms, disabilities and handicap in vertiginous 
patients. Clin Otolaryngol Allied Sci.; 24 (1): 31-38.  
[43] Abd al-Hady, M. R., Shehata, O., el-Mously, M., Sallam, F. S. (1990). Audiological 
findings following head trauma. J Laryngol Otol.; 104(12):927-36. 
[44] Emerson, L. P., Mathew, J., Balraj, A., Job, A., Singh, P. R. (2011). Peripheral 
Auditory Assessment in Minor Head Injury: A Prospective Study in Tertiary Hospital. 
Indian J Otolaryngol Head Neck Surg; 63(1):45–49. 
[45] Thomas, E., Martines, F., Bianco, A., Messina, G., Giustino, V., Zangla, D., Iovane, A., 
Palma, A. (2018). Decreased postural control in people with moderate hearing loss. 
Medicine (Baltimore); 97(14): e0244.  
[46] Martines, F., Messina, G., Patti, A., Battaglia, G., Bellafiore, M., Messina, A., Rizzo, 
S., Salvago, P., Sireci, F., Traina, M., Iovane, A. (2015). Effects of tinnitus on postural 
control and stabilization: A pilot study. Acta Medica Mediterranea; 31: 907-912. 
[47] Mazón M., Pont, E., Albertz, N., Carreres-Polo, J., Más-Estellés, F. (2018). Imaging of 
post-traumatic hearing loss. Radiología; 60,(2),119-127.  
[48] Fatterpekar, G. M., Doshi, A. H., Dugar, M. et al. (2006). Role of 3D CT in the 
evaluation of the temporal bone. Radiographics 26(Suppl 1): S117–S132. 

Traumatic Sensorineural Hearing Loss 
 
915
[49] Maillot, O., Attyé, A., Boyer, E., Heck, O., Kastler, A., Grand, S., et al. (2016). Post 
traumatic deafness: a pictorial review of CT and MRI findings. Insights Imaging; 
7:341-50. 
[50] Ishman, S. L., Friedland, D. R. (2004). Temporal bone fractures: traditional 
classification and clinical relevance. Laryngoscope; 114(10): 1734–1741. 
[51] Meriot, P., Veillon, F., Garcia, J.F., et al. (1997). CT appearances of ossicular injuries. 
Radio- Graphics; 17(6):1445–1454.  
[52] Park, G. Y., Choi, J. E., Cho, Y-S. (2014). Traumatic ossicular disruption with isolated 
fracture of the stapes suprastructure: comparison with incudostapedial joint dislocation. 
Acta Otolaryngol 134:1225–1230. 
[53] Petrovic, B. D., Futterer, S. F., Hijaz, T., Russell, E. J., Karagianis, A. G. (2010). 
Frequency and diagnostic utility of intralabyrinthine FLAIR hyperintensity in the 
evaluation of internal auditory canal and inner ear pathology. Acad Radiol.; 17:992-
1000. 
[54] Sugiura, M., Naganawa, S., Sato, E., Nakashima, T. (2006). Visualization of a high 
protein concentration in the cochlea of a patient with a large endolymphatic duct and 
sac, using three-dimensional fluid- attenuated inversion recovery magnetic resonance 
imaging. J Laryngol Otol 120:1084–1086. 
[55] Lee, E. J., Yang, Y. S., Yoon, Y. J. (2012). Case of bilateral pneumolabyrinth 
presenting as sudden, bilateral deafness, without temporal bone fracture, after a fall. J 
Laryngol Otol 126:717–720. 
[56] Herman, P., Guichard, J. P., Van den Abbeele, T., Tan, C. T., Bensimon, J. L., 
Marianowski, R., et al. (1996). Traumatic luxation of the stapes evidenced by high-
resolution CT. AJNR Am J Neuroradiol.;17:1242-4.  
[57] Hattiangadi, N., Pillion, J. P., Slomine, B. et al. (2005). Characteristics of auditory 
agnosia in a child with severe traumatic brain injury: a case report. Brain Lang 92:12–
25. 
[58] Sydlowski, S. A., Levy, M., Hanks, W. D. et al. (2013). Auditory profile in superficial 
siderosis of the central nervous system: a prospective study. Otol Neurotol 34:611–619. 
[59] Javad, F., Warren, J. D., Micallef, C. et al. (2014). Auditory tracts identi- fied with 
combined fMRI and diffusion tractography. Neuroimage 84:562–574. 
[60] Profant, O., Škoch, A., Balogová, Z. et al. (2014). Diffusion tensor imaging and MR 
morphometry of the central auditory pathway and auditory cortex in aging. 
Neuroscience 260:87–97. 
[61] Juliano, A. F., Ginat, D. T., Moonis, G. (2013). Imaging review of the temporal bone: 
part I. anatomy and inflammatory and neoplastic processes. Radiology; 269(1):17–33.  
[62] Aralașmak, A., Dinçer, E., Arslan, G., Cevikol, C., Karaali, K. (2009). Posttraumatic 
labyrinthitis ossificans with perilymphatic fistulization. Diagn Interv Radiol; 
15(4):239–241. 
[63] Juliano, A. F., Ginat, D. T., Moonis, G. (2015). Imaging review of the temporal bone: 
part II. Traumatic, Postoperative, and Noninflammatory Nonneoplastic Conditions. 
Radiology 276(3):655-72. 

Michele Cassano, Valeria Tarantini, Eleonora M. C. Trecca et al. 
 
916
[64] Shin, J. H., Park, S., Baek, S. H., et al. (2008). Cochlear implantation after bilateral 
transverse temporal bone fractures. Clin Exp Otorhinolaryngol; 1:171-3. 
[65] Nadol Jr, J. B., Young, Y. S., Glynn, R. J. (1989). Survival of spiral ganglion cells in 
profound sensorineural hearing loss: implications for cochlear implantation. Ann Otol 
Rhinol Laryngol; 98:411-6. 
[66] Morgan, W. E., Coker, N. J., Jenkins, H. A. (1994). Histopathology of temporal bone 
fracture. Implications for cochlear implantation. Laryngoscope 104(4):426-32. 
[67] Camilleri, A. E., Toner, J. G., Howarth, K. L., Hampton, S., Ramsden, R. T. (1999). 
Cochlear implantation following temporal bone fracture. J Laryngol Otol; 113:454–
457.  
[68] Vermeire, K., Brokx, J. P. L., Dhooge, I., Van de Heyning, P. H. (2012). Cochlear 
implantation in posttraumatic bilateral temporal bone fracture. ORL; 74: 52-56. 
[69] Chung, J. H., Shin M. C., Min H. J., Park C. W., Lee S. H. (2011). Bilateral cochlear 
implantation in a patient with bilateral temporal bone fractures. American Journal of 
Otolaryngology–Head and Neck Medicine and Surgery 32:256–258.  
[70] Seidman, D. A., Chute, P. M., Parisier, S. (1994). Temporal bone imaging for cochlear 
implantation. Laryngoscope; 104:562-5. 
[71] Simons, J. P., Whitaker, M. E., Hirsch, B. E. (2005). Cochlear implantation in a patient 
with bilateral temporal bone fractures. Otolaryngol Head Neck Surg; 132:809-11. 
[72] Brown, K. D., Balkany, T. J. (2007). Benefits of bilateral cochlear implantation: a 
review. Curr Opin Otolaryngol Head Neck Surg; 15:315-8.  
[73] Rizzo, S., Bentivegna, D., Thomas, E., La Mattina, E., Mucia, M., Salvago, P., Sireci, 
F., Martines, F. (2016). Sudden sensorineural hearing loss, an invisible male: State of 
art. Hearing loss: etiology, management and societal implications, 75-86. 
[74] Salvago, P., Rizzo, S., Bianco, A., Martines, F. (2017). Sudden sensorineural hearing 
loss: is there a relationship between routine haematological parameters and audiogram 
shapes? International Journal of Audiology; 56(3): 148-153. 
[75] Martines, F., Salvago, P., Ferrara, S., Mucia, M., Gambino, A., Sireci, F. (2014). 
Parietal subdural empyema as complication of acute odontogenic sinusitis: A case 
report. Journal of Medical Case Reports, 8 (1). 
[76] Dispenza, F., De Stefano, A., Costantino, C., Marchese, D., Riggio, F. (2013). Sudden 
Sensorineural Hearing Loss: results of intratympanic steroids as salvage treatment. Am 
J Otolaryngol; 34:296-300. 
[77] Yanagihara, N., Nishioka, I. (1987). Pneumolabyrinth in perilymphatic fistula: report of 
three cases. Am J Otol; 8:313-8. 
[78] Dispenza, F., Mazzucco, W., Bianchini, S., Mazzola, S., Bennici, E. (2015). 
Management of labyrinthine fistula in chronic otitis with cholesteatoma: case series. 
EuroMediterranean Biomedical Journal 10(21): 255-261. 
[79] Coker, N. J. (1991). Management of traumatic injuries to the facial nerve. Otolaryngol 
Clin North Am; 24(1):215–227. 
[80] Lambert, P. R., Brackmann, D. E. (1984). Facial paralysis in longitudinal temporal 
bone fractures: a review of 26 cases. Laryngoscope; 94(8):1022–1026. 

Traumatic Sensorineural Hearing Loss 
 
917
[81] Saraiya, P. V., Aygun, N. (2009). Temporal bone fractures. Emerg Radiol; 16(4):255–
265. 
[82] Dispenza, F., Battaglia, A. M., Salvago, P., Martines, F. (2018). Determinants of failure 
in the reconstruction of the tympanic membrane: a case-control study. Iranian Journal 
of Otorhinolarhingology, 30(6): 341-346. 
 
 


In: Encyclopedia of Audiology and Hearing Research 
ISBN: 978-1-53617-702-2 
Editors: Erno Larivaara and Senja Korhola 
© 2020 Nova Science Publishers, Inc. 
 
 
 
 
 
 
 
Chapter 60 
 
 
 
ADVANCED OTOSCLEROSIS 
 
 
Nicola Quaranta1, MD, Vito Pontillo1, MD  
and Francesco Dispenza2, MD, PhD 
1Otolayngology Unit, Department of Basic Medical Science,  
Neuroscience and Sensory Organs, University of Bari Aldo Moro, Bari, Italy 
2Istituto Euromediterraneo di Scienza e Tecnologia – IEMEST, Palermo, Italy 
 
 
ABSTRACT 
 
Otosclerosis is characterized by a continuous and aberrant process of osteolysis and 
osteogenesis of the endochondral bone of the otic capsule, most commonly involving the 
fissula ante fenestram (fenestral otosclerosis) and resulting in a conductive hearing loss. 
As it undergoes a maturation process, the sclerotic bone may invade deeper into the 
labyrinth, resulting in retrofenestral otosclerosis and gradually leading to severe mixed 
hearing loss and then to profound sensorineural hearing loss. This cochlear involvement 
of otosclerosis audiologically reflects as advanced otosclerosis (AO) and can be defined 
by audiometric and radiological criteria.  
Treatment for AO has evolved over the past 20 years with the improvement in 
hearing aid devices and the availability of cochlear impants (CI) as an alternative surgical 
option. 
Most authors suggest treating AO with stapes surgery and postoperative 
amplification by hearing aids. 
Cochlear implants have become available in the last 20 years and, since their 
introduction, many otosclerotic patients have undergone implantation with good hearing 
and communicative outcomes. Cochlear Implantation in otosclerosis poses some surgical 
problems, mainly related to cochlear obliteration and facial nerve stimulation. For cases 
of unsuccessful stapedotomy, the results obtained by a salvage CI are as good as those of 
CI when no prior stapedectomy was performed. 
 
Keywords: advanced otosclerosis, stapes surgery, stapedectomy, cochlear implantation, CI 
 
 
 

Nicola Quaranta, Vito Pontillo and Francesco Dispenza 
 
920
INTRODUCTION 
 
Otosclerosis is a rather hereditary disease that usually develops in the post-lingual period, 
specifically between the second and the fifth decade of life [1]. It is characterized by a 
continuous and aberrant process of osteolysis and osteogenesis of the endochondral bone of 
the otic capsule [2, 3]. The most common site of involvement is the fissula ante fenestram 
(fenestral otosclerosis), which results in conductive hearing loss due to stapes footplate 
fixation [4, 5]. Hearing loss is initially observed at low frequencies and later also at higher 
frequencies [6]. As it undergoes a maturation process, the sclerotic bone can increase in size 
and depth and may invade deeper into the labyrinth, resulting in retrofenestral otosclerosis; 
this process gradually leads to severe mixed hearing loss and then to profound sensorineural 
hearing loss (SNHL) [5]. This cochlear involvement of the disease affects about 10% [7] of 
patients with otosclerosis and, from an audiological point of view, is defined as advanced 
otosclerosis (AO). Shea et al. [8] estimated that 1.6% of patients with otosclerosis may then 
evolve to profound SNHL. 
 
 
DEFINITION 
 
There is no universally accepted definition for advanced otosclerosis. “Far-Advanced 
Otosclerosis” (FAO) was first described by House and Sheehy [9] in 1961 and was defined by 
an air conduction (AC) threshold worse than 85 dB and a bone conduction (BC) threshold 
beyond the measurement limits of the standard clinical audiometers available at that time. In 
the modern era, the criteria for diagnosing FAO have considerably changed since the 
availability of more powerful audiometers with higher detection limits. Merkus et al. [10] 
have therefore proposed that speech discrimination scores (SDS) are more likely to be used 
than pure-tone thresholds and the term “far advanced otosclerosis” should be no longer 
applicable. Some Authors prefer to use the term “advanced otosclerosis” instead of far 
advanced otosclerosis, and define it as a SNHL with decreased speech recognition abilities or 
with an AC threshold higher than 85 dB and even a poor/unmeasurable BC threshold [5].  
Iurato et al. [11] in 1992 described very far-advanced otosclerosis (VFAO) in patients 
with undetectable air and bone conduction levels with standard clinical audiometers, resulting 
in a “blank audiogram.” Calmels and colleagues [12] recently described VFAO as a condition 
characterized by dissyllabic word discrimination lower than 30% at 70 dB SPL in the best 
aided condition and a blank audiogram. 
 
 
PATHOGENESIS 
 
The mechanisms leading to SNHL have been widely studied and many theories have 
been proposed: 
 
 
Siebenmann [13] suggested that toxic substance released by the otospongiotic foci 
into the inner ear fluids could impair the function of the cochlea. These hypothesis 

Advanced Otosclerosis 
 
921
has been corroborated by the findings of electron microscopy, that showed the 
presence of lysosomes at the margins of the advancing otospongiotic foci [14, 15]. 
 
Ruedi [16] described venous shunts between the otospongiotic foci and vessels of the 
cochlea. It is suspected that these shunts might produce venous congestion, 
interfering with the normal metabolism of the cochlea, resulting in hypoxia and 
degeneration of the spiral ligament, hence producing hearing loss.  
 
Atrophy and hyalinization of the spiral ligament, and of the stria vascularis have 
been found in patients with advanced otosclerosis, but the mechanism that produces 
them is uncertain [17]. 
 
Linthicum et al. [18, 19] proposed the invasion of the cochlear walls by the 
otospongiotic foci, causing a narrowing of the lumen of the cochlea and a distortion 
of the basilar membrane, with subsequent inhibition of the traveling wave throughout 
the rest of the cochlea. 
 
More recently, some Authors proposed that retrofenestral foci may lead to hearing 
loss through disturbance of the ionic homeostasis of the cochlea by hindering ion 
recycling and reducing the endocochlear potential [20, 21]. 
 
In all probability, more than one of these factors is responsible for the hearing loss in 
each case. The atrophy and hyalinization, which can be determined by both lytic enzymes and 
venous shunts, may lead both to a distortion of the basilar membrane and to an alteration of 
the 
ionic 
homeostasis. 
Detritus 
caused 
by 
the 
aberrant 
osteoclastic/ 
osteoblastic activity may also alter the normal composition of perilymphatic fluids by 
inflammatory reactions mediated by immune complexes or by the sum of several of these 
factors [17, 18]. 
 
 
RADIOLOGIC DIAGNOSIS AND CLASSIFICATION 
 
If it is still debated the utility of imaging in the diagnosis of otosclerosis, there is no 
controversy in stating that it is of essential importance when the disease progresses into AO 
and cochlear implantation is taken into consideration. 
High-resolution CT (HRCT) scanning is the imaging modality of choice for assessing 
cochlear involvement of otosclerosis, characteristically manifesting with irregularities of the 
outline of the otic capsule or with the more specific presence of a lucent area in the normally 
homogeneously dense otic capsule. This lucent area might be presenting as a focal lucency or 
with the characteristic double ring/halo sign (pericochlear lucency) [22, 23, 24], emerging 
when the pericochlear confluent foci surround the cochlear lumen [25, 26]. Besides, HRCT 
can be used to assess the location and extension of hypodense lesions, helping to quantify the 
degree of otospongiosis and the severity of disease, which has been demonstrated to be 
correlated to the degree of sensorineural hearing loss [27]. Finally, HRCT might be used for 
preoperative evaluation of the patency of the cochlear lumen, which can be obstructed in 
cases of AO, and of the risk of facial nerve stimulation (FNS). These findings can help the 
surgeon respectively to be prepared for extra-drilling and to choose a perimodiolar electrode 
rather than straight electrodes in selected patients [26, 28, 29]. 

Nicola Quaranta, Vito Pontillo and Francesco Dispenza 
 
922
In case of intralabyrinthine involvement, also MRI can be performed to explore the 
cochlear status and evaluate the patency of the cochlear lumen [30], particularly on fast-spin 
T2-weighted scans [31], demonstrated to be even superior to CT scans in the assessment of 
luminal patency [32]. In cochlear otosclerosis a ring with an isointense signal is usually 
detected in the peri-cochlear and peri-labyrinthine area on T1-weighted images, with mild to 
moderate enhancement after gadolinium, related to hypervascularity and inflammatory 
response 
in 
cases 
of 
large 
otospongiotic 
peri-cochlear 
foci 
[31].  
T2-weighted images might detect hyperintense signal as well [30, 33]. Lombardo et al. [34] 
demonstrated three-dimensional fluid attenuation inversion recovery sequence using 3T MRI 
to be useful for the demonstration of an alteration in the composition of the endocochlear 
fluid due to inflammation and blood-labyrinth barrier breakdown, which was demonstrated in 
81,8% of their patients. 
Single-photon emission computed tomography (SPECT) using 99-technetium-
diphosphonates was proposed by Berrettini et al. [33] as a diagnostic alternative in difficult 
cases and for medical treatment follow-up, with high sensitivity (95.2%) and specificity 
(96.7%) in identifying otospongiotic foci in the otic capsule. 
Many types of radiographic grading systems were proposed in order to describe the 
location and stage of otosclerosis, often in relationship with audiological findings. Valvassori 
[22] was the first to propose a grading system for advanced otosclerosis based on disease 
progression. In more recent studies, Rotteveel and colleagues [26] (Table 1), Symons and 
Fanning [35] (Table 2) and Kabbara and colleagues [36] (Table 3) described other 
classification systems based on CT evaluation of the otic capsule involvement.  
 
Table 1. Rotteveel et al. imaging-based grading system [26] 
 
 
Otosclerotic Lesions of the Otic Capsule 
Type 1 
Solely fenestral involvement 
Type 2 
Retrofenestral (with or without fenestral involvement) 
a 
Double ring effect 
b 
Narrowed basal turn 
c 
Double ring effect and narrowed basal turn 
Type 3 
Severe retrofenestral involvement (unrecognizable otic capsule), with or without 
fenestral involvement 
 
Table 2. Symons and Fanning's imaging-based grading system [35] 
 
 
Plaques Location 
Grade 1 
Solely fenestral involvement (spongiotic/sclerotic) 
Grade 2 
Patchy localized cochlear disease (with or without fenestral involvement) 
a 
To basal cochlear turn 
b 
To middle/apical turn 
c 
Both 
Grade 3 
Diffuse confluent cochlear involvement (with or without fenestral involvement) 
 
 
 

Advanced Otosclerosis 
 
923
Table 3. Kabbara’s imaging-based grading system [36] 
 
 
Otosclerotic Lesions 
Stage 1 
Limited footplate and pericochlear lesions without endosteum involvement 
Stage 2 
Significant pericochlear and endosteum involvement 
Stage 3 
Full obliteration of the round window and/or basal turn ossification associated with 
pericochlear lesions 
 
Table 4. Diagnostic clues suggested by Sheehy (1978) for advanced otosclerosis [37] 
 
(1) positive family history for otosclerosis 
(2) progressive hearing loss beginning in early adult life 
(3) paracusis during the early stage of the disease 
(4) past use of a bone-conduction hearing aid 
(5) previous audiograms showing an airbone gap 
 
Although the diagnostic clues suggested by Sheehy [37] (Table 4) together with 
instrumental imaging may help, definitive diagnosis often requires exploratory surgery [38]. 
 
 
TREATMENT STRATEGIES 
 
The management of patients with AO is a real challenge. Although various methods have 
been used in recent years, no standard guidelines have been established. The following 
therapeutic options are in common use [10, 39, 40]:  
 
A. No intervention and hearing aids with follow-up; 
B. Stapes surgery and hearing aids; 
C. Cochlear implantation; 
D. Direct acoustic cochlear stimulation implant. 
 
In some cases, choosing between these options can be difficult for two main factors: first, 
with mixed hearing loss it is not easy to predict the success rate of stapedectomy; second, 
otospongiotic foci around the otic capsule can lead to surgical complications and difficulties 
during cochlear implantation. 
 
 
Hearing Aids and Follow-Up 
 
This option can be taken into consideration in case of patients with good audiological 
(SDS >50%) and radiologic (Rotteveel grade 1, 2A or 2B) findings but with an air-bone gap 
lower than 30 dB, in which a stapes surgery would be ineffective, considering the reduced 
conductive component [10]. 
 

Nicola Quaranta, Vito Pontillo and Francesco Dispenza 
 
924
Stapes Surgery and Hearing Aids 
 
Patients with advanced otosclerosis and no benefit from a powerful hearing aid may be 
suitable candidates for stapes surgery. 
This indication was first discussed by House in 1960 [41]. In 1964 Sheehy stated that 
“there is no maximum bone conduction threshold above which stapedectomy is 
contraindicated” [37]. 
Conducting a stapedectomy with subsequent placement of a hearing aid has been widely 
studied, with varying audiological results: 46–100% hearing improvement, 38-75% post-
operative SDS and 17–75% improvement of SDS [8, 10-12, 37, 38] (Table 5). Several 
Authors have stated that there are no contraindications for performing stapedectomy in any 
case of AO and assert that stapes surgery should be considered as first line therapy in these 
patients, especially in countries with limited economic resources, since even though the 
results should be unsatisfactory, a contralateral stapedotomy [42] or a salvage CI [6] can still 
be performed. Abdurehim and colleagues in their meta-analysis [3] revealed that previously 
failed stapedotomy does not affect the outcomes in terms of SDS after salvage CI. 
Complications in patients with advanced otosclerosis are statistically different from those 
in patients withot AO [43]. One of the most feared complications of stapedectomy is the 
deterioration of sensorineural hearing loss, which can be due to several causes (among them 
penetration of the prosthesis into the inner ear, perylimphatic fistula or granuloma) and might 
thus result in a functionally deaf ear. However, the surgeon should not be excessively worried 
about this possibility in case of advanced otosclerosis, because he is dealing with a severe to 
profound HL. Furthermore, the ‘second chance’ of CI is still possible. 
Some of the advantages of stapedotomy are lower cost and difficulties, local anaesthesia, 
fewer risks and postoperative requirements (fitting of a hearing aid) and better natural sound 
and music perception. However, stapedectomy does not treat the sensorineural component of 
mixed hearing loss and does not stop the aberrant maturation process of the otic capsule. 
Moreover, the outcomes are less predictable, especially if compared with CI [38]. Several 
Authors have tried to demonstrate the utility of different prognostic factors: it has been stated 
that patients with severe retrofenestral involvement and speech recognition scores of less than 
30% are associated with poorer results if compared with subjects with less retrofenestral 
involvement and speech recognition scores of more than 50% [5]. For this reason patients 
should be carefully selected and each case must be assessed individually. 
Controversy still exists about the possibility to perform a second stapedectomy on the 
opposite ear [43]. Many Authors believe that there is no real justification for this if the first 
stapedectomy was successful [43]. Others believe that each patient should be offered the 
potential benefit of binaural amplification even for a hearing loss of this severity. In 
conclusion, each decision should be individualized to the single subject and the final decision 
should be left to the patient after fully considering all the risks and benefits. In case of 
contralateral stapes surgery is taken into consideration, the normal protocol of delaying of 1 
year the second operation for fear of SN deterioration has no reason to exist in AO, because, 
as already mentioned, we are dealing with patients with sever to profound HL and no 
apparent cochlear reserve. 
 
 

Advanced Otosclerosis 
 
925
Cochlear Implantation 
 
Cochlear implantation was once considered to be contraindicated in patients affected by 
otosclerosis, because it was generally agreed that the pathologic process led to an inadequate 
number of neural elements with subsequent reduction of the electric stimulation [44]. 
The literature has demonstrated that treating advanced otosclerosis with CIs yield 
satisfactory results. This can be explained by the fact that this pathologic condition mainly 
affects the lateral wall of the cochlea, resulting in a degeneration of the spiral ligament and 
stria vascularis, but leaving the fibres of the auditory nerve uninvolved in a first period [45]; 
even though spiral ganglion cells are involved by the process, they have been demonstrated to 
be present in a sufficient number (40-85% of normal) [46] for successful electrical 
stimulation [47], thus not affecting the performance of the implant [24], but implying the need 
for higher electrical charges [48].  
Several publications have reported hearing improvement in 100% of patients submitted to 
CI [1, 10, 12, 26, 29, 32, 35, 38, 46, 49-51] (Table 5). Moreover, a significant improvement in 
speech perception (34-94%) was reported after CI in studies that compared pre- and post-
operative speech discrimination (SD) scores [1, 12, 29, 38, 50], with an average SDS after 
implantation of 45-98% [10]. In a study conducted in 2005 [49] our group found similar 
results, with an average postoperative SD score of 60% (using two-syllable words test) and 
83% (using sentences test). 
With such a high rate of success (hearing improvement of 100% vs 46-100% of 
stapedectomy; post-operative SD scores of 45-98% vs 38-75% of stapedectomy; 
improvement in SD after surgery of 34-94% vs 17-75% of stapedectomy) [10], CI should be 
considered the treatment of choice for these patients. However, CI undoubtedly present 
negative aspects. Some disadvantages of cochlear implantation include high cost, challenging 
programming/rehabilitation and the high rate of difficulties and complications, thus requiring 
experienced surgeons. Furthermore, because of the progression of otosclerosis, also late 
postoperative failure of the CI must be taken into account [31]: in this case reprogramming 
with higher stimulus levels might be required, although this can increase the risk of facial 
nerve stimulation. 
 
Table 5. Audiological results after stapes surgery and cochlear implantation 
 
 
Patients Hearing 
Improved 
Average SDS after 
surgery 
Improvement SDS after 
surgery 
Stapes surgery 46-100% 
38-75% 
17-75% 
CI 
100% 
45-98% 
34-94% 
CI: cochlear implantation; SDS: Speech Discrimination Score 
 
The surgical technique is the same than in standard non-otosclerosis patients, with 
conventional cortical mastoidectomy and posterior tympanotomy, but continuous and aberrant 
production of bone in the cochlea can determinate several difficulties during the procedure: 
 

Nicola Quaranta, Vito Pontillo and Francesco Dispenza 
 
926
 
The conventional landmarks for CI, such as the promontory and round window 
niche, may be altered due to bony remodelling in otosclerosis patients, thereby 
making the identification of scala tympani difficult.  
 
Round window and basal turn ossification often occur in FAO, with a reported 
incidence of 8-89% and 10-60% respectively [10]. Placing a CI electrode in an 
ossified cochlea is certainly a challenge, however, is not a contraindication and does 
not affect the audiological results [2, 46]. A number of techniques have been 
proposed in order to enable full electrode insertion in these patients: in case of 
fenestral ossification, extra-drilling may be required to detect the lumen of the basal 
turn [44]; alternatively the cochleostomy can be placed 1-2 mm cranially with scala 
vestibuli insertion of the electrode [29, 38, 53].  
 
Partial insertion or misplacement of the electrode has been reported in 19% of 
patients [26, 35, 38]. Partial insertion can be caused by the obliteration of the apical 
regions of the scala tympani [8]. The evolution of otospongiotic lesions can lead to 
the creation of osteolytic cavities surrounding the cochlea, which can be confused 
with the opening of the basal turn, resulting in an electrode misplacement in this false 
lumen [26, 28] It is also possible that an electrode normally inserted in the basal turn 
penetrates the cochlear endosteum and enters this false lumen [54]. 
 
It has been demonstrated that 60% of preoperative CT scans does not reveal findings 
consistent with otosclerosis. Therefore, the surgeon must be prepared for extra-
drilling despite lack of imaging findings [32]. 
 
In otosclerosis patients CI complications have been described more frequently than in 
non-otosclerosis ones: 
 
 
Facial nerve stimulation (FNS) has been reported between 25 and 75% [26, 29, 55] 
of otosclerosis patients versus the 0.9-14.9% of the general CI population [6]. It is 
thought to occur because of an altered electrical impedance of the spongiotic bone: 
this can generate current leaks outside the cochlea, especially in case of partial 
electrode insertion [54-56], thus resulting in an electrical shunt with the facial nerve 
[25]. The bone resorption and the progressive thinning of the bone between the 
electrode and the facial nerve may contribute to this shunt [55, 57]. It has been 
suggested that the electrode design can influence the incidence of FNS, with 
perimodiolar (modiolar hugging) electrodes demonstrated to be a useful strategy for 
preventing this problem [58]. 
 
When it occurs, FNS usually appears with facial twitching, pain and paraesthesia [59] at 
the first connection of the CI or after an average time period of 6.8 months after implant 
activation [60, 61], but an onset as long as 13 years after implantation has been described 
[31]. Some Authors [35] have speculated that the higher incidence of FNS with straight 
electrodes could be explained by the fact that these devices have been in situ longer than the 
newer modiolar hugging electrodes. 

Advanced Otosclerosis 
 
927
It has been also demonstrated that the higher risk of developing FNS interests subjects 
with grade 3 (Rotteveel grading system) advanced otosclerosis [35]. This suggests that 
disease severity on CT scanning may predict cases in which FNS is more likely. 
Once occurred, FNS can usually be resolved by reprogramming or deactivation of the 
involved electrodes [25], that usually are the most distal/apical one, the ones in close 
proximity to the geniculate ganglion and labyrinthine portion of the facial nerve [26, 55]. 
However, when many electrodes require deactivation, the performance of the CI unavoidably 
decreases. The “variable-mode programming,” by leaving normal pulses for non-offending 
electrodes and setting wider pulses for the offending electrodes, may represent the right 
compromise between audiological performance and FNS solving [61]. Another treatment 
modality for refractory FNS is the injection of botulinum toxin [62]. Gold and colleagues [62] 
also reported the benefit of oral fluoride treatment in refractory cases. In some cases, FNS 
cannot be resolved through the aforementioned modalities and reimplantation may be 
necessary [25, 63]. 
 
 
Other non-auditory stimulations were reported in the literature to be more common in 
patients with otosclerosis submitted to cochlear implantation: tympanic plexus 
stimulation (manifesting as otalgia) and vestibular structures stimulation (clinically 
presenting with dizziness) [64]. Other untoward symptoms described in patients with 
advanced otosclerosis after CI are tinnitus, headaches [32, 50] and throat discomfort 
[49]. The treatment in all cases consists in the deactivation of the offending 
electrodes. 
 
As otosclerosis progresses, demineralization can cause the formation of cavitation 
around the cochlea with resultant perilymphatic gusher during cochleostomy [36]. 
 
 
Direct Acoustic Cochlear Implant 
 
The direct acoustic cochlear implant (DACI) is a new type of acoustic hearing implant 
designed for patients with severe to profound mixed hearing loss [65] but not yet approved by 
US Food and Drug Administration.  
DACI transfers acoustic energy directly to the inner ear via an implantable 
electromagnetic transducer introduced into the oval or round window or in a surgically 
created ‘third’ window [40]. As a result, pathological outer and middle ear structures of the 
ear are bypassed and the amplified signal is directly provided to the cochlea. Häusler et al. 
[40] and Bernhard et al. [66] were the first to describe a DACI device called DACS. The 
successor of the DACS, the Codacs investigational device, has been demonstrated to be safe 
and clinically useful in the treatment of patients with severe to profound MHL due to 
advanced otosclerosis [67].  
Several studies have stated that the outcomes in otosclerosis patients with severe to 
profound hearing loss treated with DACI, in terms of hearing improvement and speech 
intelligibility, are significantly better than in case of CI [63] or conventional hearing aids [68]. 
Busch and colleagues [68] defined the indication for DACI as a BC threshold between 40 
and 80 dB hearing loss and AC threshold higher than 60-dB hearing loss. Larger clinic trials 
with this device are however required to reach definitive conclusions [6]. 

Nicola Quaranta, Vito Pontillo and Francesco Dispenza 
 
928
Treatment Strategy and Counselling 
 
Different criteria should be considered when choosing the best treatment strategy, 
including rate of success, economic criteria and potential complications of each option.  
Merkus and colleagues [10] proposed a treatment algorithm that can help the surgeon in 
choosing the best treatment strategy basing on SD rates and CT findings (Figure 1). First, 
patients are divided into 3 main groups according to their maximum SD scores, using 
standard speech audiometry (open-set monosyllables) [69]: group 1 SD scores are less than 
30%; group 2 SD scores are 30% to 50%, and group 3 SD scores are 50% to 70%.  
For group 1 patients (SDS < 30dB), who often suffer from sever SNHL, the most 
effective treatment has been demonstrated to be cochlear implantation, because stapedectomy 
does not act on the sensorineural component. Group 2 patients (SDS between 30 and 50%) 
might be treated with both CI and stapedectomy in relation to their CT scan Rotteveel grade. 
In case of severe retrofenestral otosclerosis with Rotteveel grade 2C or 3, cochlear 
implantation is typically recommended, because of the likely progression of cochlear damage 
that could make CI very difficult in future. In case of less advanced CT lesions (Rotteveel 
grade 1, 2A or 2B) the air-bone gaps should guide the surgeon: if the ABG is equal or greater 
than 30 dB, stapedotomy is recommended; if the ABG is less than 30 dB, CI still remains the 
best option in the Authors’ opinion. Group 3 patients (SD between 50 and 70%) undergo the 
same management as group 2, except that in case of limited CT cochlear involvement and 
ABG less than 30 dB hearing aids and follow-up are recommended rather than CI.  
Despite this interesting algorithm appears to be a useful to help the surgeon choose the 
best treatment to perform, retrospective evidence suggests that CT and audiological findings 
are not sensitive or specific enough to predict the outcomes of stapedotomy [36, 42]. 
Furthermore, it has been demonstrated that even in patients with a “blank” audiogram 
(unmeasurable air and bone conduction thresholds) and 0% SD, stapedectomy with a well-
fitted hearing aid can still lead to acceptable outcomes in up to 30% of patients [12, 36]. 
 
 
Figure 1. Algorithm guideline proposed by Merkus et al. for advanced otosclerosis.  
SD: Speech Discrimination; ABG: air-bone gap; CI: cochlear implantation; STP: stapedectomy. 

Advanced Otosclerosis 
 
929
Because of the advantages listed above, several Authors still recommend to consider 
stapes surgery with hearing aid as a first option [6]. In fact, the results of auditory stimuli 
appears to be better than electrical stimuli in terms of sound quality, musical appreciation and 
speech discrimination in loud environments [70-72]. If stapes surgery does not have a 
successful outcome, a cochlear implantation is still an option [6].  
In addition, multiple factors must be considered in the surgical decision, such as the 
degree of residual hearing in the contralateral ear, the duration of hearing deprivation and the 
patient preference. 
Careful preoperative counselling is extremely important in patients with advanced 
otosclerosis. Especially in cases selected for stapedectomy, patients must be aware of the risk 
of the procedure, of the limited goals and of the possibility, in case of failure, that a CI can be 
carried out in the next future. Failure is normally defined by no improvement of threshold 
levels or speech recognition with well fitted hearing aids at 3 months after the surgery and 
when the patient is not satisfied [73]. Nevertheless, patients should be informed that, since 
cochlear otosclerosis is an evolutive process, the results of a stapedectomy can deteriorate 
with time; in these cases, CI must be proposed.  
Quite recent publications showed promising results with the use of high dose third-
generation bisphosphonates in the treatment of SNHL in otosclerosis, with stabilization and 
up to 68% improvement of SD [74, 75]. The mechanism is thought to be linked to a reduction 
in osteoclast activity and, hence, of TNF-alpha diffusion to the perilymph and hair cells [74, 
75]. Although more studies are necessary, this therapeutic option may decrease the number of 
patients requiring salvage cochlear implantation after stapedotomy and improve the long-term 
stability of the procedure. 
 
 
CONCLUSION 
 
Recent reviews concluded that CI leads to a statistically greater and consistent 
improvement in speech discrimination scores compared with stapes surgery. Stapedotomy is 
not universally effective; however, it yields results comparable to CI in at least half of 
patients.  
In conclusion, stapedectomy with subsequent hearing aid adaptation should not be 
forgotten as a valid procedure for these patients. Each case must be thoroughly analysed and 
the choice of treatment should be individualized for each patient. 
For cases of unsuccessful stapedectomy, the option of CI is still open, and the results 
obtained by a salvage CI are as good as those of CI when no prior stapedotomy was 
performed. 
 
 
REFERENCES 
 
[1] 
Rama-Lopez J, Cervera-Paz FJ, Manrique M. Cochlear implantation of patients with 
far-advanced otosclerosis. Otol Neurotol 2006;27:153-158.  
[2] 
Castillo F, Polo R, Gutiérrez A, et al. Cochlear implantation outcomes in advanced 
otosclerosis. Am J Otolaryngol 2014;35:558-564.  

Nicola Quaranta, Vito Pontillo and Francesco Dispenza 
 
930
[3] 
Dispenza F, Cappello F, Kulamarva G, De Stefano A. The discovery of stapes. Acta 
Otorhinolaryngol Ital, 2013; 33:357-359. 
[4] 
Ferrara S, Di Marzo M, Martines F, Ferrara P. Medical and surgical update on 
“atelectasic - Adhesive – Tympanosclerotic” otitis media. Otorinolaringologia 2011; 
61:11-17. 
[5] 
Abdurehim Y, Lehmann A, Zeitouni AG. Stapedotomy vs cochlear implantation for 
advanced otosclerosis: systematic review and meta-analysis. Otolaryngol Head Neck 
Surg 2016;155:764-770.  
[6] 
Eshraghi AA, Ila K, Ocak E, Telischi FF. Stapes Surgery or Cochlear Implantation? 
Otolaryngol Clin N Am 2018;51:429-440.  
[7] 
Ramsay HA, Linthicum Jr FH. Mixed hearing loss in otosclerosis: indication for long-
term follow-up. Am J Otol 1994;15:536-539.  
[8] 
Shea PF, Ge X, Shea Jr JJ. Stapedectomy for far-advanced otosclerosis. Am J Otol 
1999;20:425-429.  
[9] 
House HP, Sheehy JL. Stapes surgery: selection of the patient. Ann Otol Rhinol 
Laryngol 1961;70:1062-1068.  
[10] Merkus P, van Loon MC, Smit CF, et al. Decision making in advanced otosclerosis: an 
evidence-based strategy. Laryngoscope 2011;121:1935-1941.  
[11] Iurato S, Ettorre GC, Onofri M, et al. Very far-advanced otosclerosis. Am J Otol 
1992;13:482-487.  
[12] Calmels MN, Viana C, Wanna G, Marx M, James C, Deguine O, Fraysse B. Very far-
advanced otosclerosis: stapedotomy or cochlear implantation. Acta Oto-Laryngologica 
2007;127:574-578.  
[13] Siebenmann F. Multiple Spongiosierung der Labyrinthkapsel als Sectionsbefund bei 
einem Fall von progressiver Schwerhorigkeit. Z Ohrenheilk 1899;34:356-374.  
[14] Bretlau P, Causse J, Jorgensen MB, et al. Histiocytic activity in the otosclerotic bone. 
Arch Klin Exp Ohren Nasen Kehlkopfheilkd 1971;198:301-316.  
[15] Chevance LG, Bretlau P, Jorgensen MB, et al: Otosclerosis: An electron microscopic 
and cytochemical study. Acta Otolaryngol [Suppl] (Stockh) 1970;272:1-27.  
[16] Ruedi L. Histopathologic confirmation of labyrinthine otosclerosis. Laryngoscope 
1965;75:1582-1609.  
[17] Linthicum Jr FH, Filipo R, Brody S. Sensorineural hearing loss due to cochlear 
otospongiosis: theoretical considerations of etiology. Ann Otol Rhinol Laryngol 
1975;84:544-551.  
[18] Linthicum Jr FH. Histopathology of otosclerosis. Otolaryngol Clin North Am 
1993;26:335-352.  
[19] Linthicum Jr FH, Filipo R, Brody S. Sensorineural hearing loss due to cochlear 
otospongiosis: theoretic considerations of etiology. Ann Otol Rhinol Laryngol 
1975;84:544-551.  
[20] Cureoglu S, Baylan MY, Paparella MM. Cochlear otosclerosis. Curr Opin Otolaryngol 
Head Neck Surg 2010;18:357-362.  

Advanced Otosclerosis 
 
931
[21] Doherty JK, Linthicum FH. Spiral ligament and stria vascularis. Otol Neurotol 
2004;25:457-464.  
[22] Valvassori GE. Imaging of otosclerosis. Otolaryngol Clin North Am 1993;26:359-371.  
[23] Palacios E, Valvassori G. Cochlear otosclerosis. Ear Nose Throat J 2000;XX:494.  
[24] Marx SV, Langman AW. Cochlear otosclerosis. Am J Otol 1997;18:404.  
[25] Polak M, Ulubil SA, Hodges AV, et al. Revision cochlear implantation for facial nerve 
stimulation in otosclerosis. Arch Otolaryngol Head Neck Surg 2006;132:398-404.  
[26] Rotteveel LJ, Proops DW, Ramsden RT, Saeed SR, van Olphen AF, Mylanus EA. 
Cochlear implantation in 53 patients with otosclerosis: demographics, computed 
tomographic scanning, surgery, and complications. Otol Neurotol 2004;25:943-952.  
[27] Shin YJ, Fraysse B, Deguine O, et al. Sensorineural hearing loss and otosclerosis: a 
clinical and radiological survey of 437 cases. Acta Otolaryngol 2001;121:200-204.  
[28] Lee TC, Aviv RI, Chen JM, Nedzelski JM, Fox AJ, Symons SP. CT grading of 
otosclerosis. AJNR Am J Neuroradiol 2009;30:1435-1439.  
[29] Ruckenstein MJ, Rafter KO, Montes M, Bigelow DC. Management of far advanced 
otosclerosis in the era of cochlear implantation. Otol Neurotol 2001;22:471-474.  
[30] Goh JPN, Chan LL, Tan TY. MRI of cochlear otosclerosis. Br J Radiol 2002:75;502-
505.  
[31] Toung JS, Zwolan T, Spooner TR, et al. Late failure of cochlear implantation resulting 
from advanced cochlear otosclerosis: surgical and programming challenges. Otol 
Neurotol 2004;25:723-726.  
[32] Semaan MT, Gehani NC, Tummala N, et al. Cochlear implantation outcomes in 
patients with far advanced otosclerosis. Am J Otolaryngol 2012;33:608-614.  
[33] Berrettini S, Ravecca F, Volterrani D, et al. Imaging evaluation in otosclerosis: single 
photon emission computed tomography and computed tomography. Ann Otol Rhinol 
Laryngol 2010;119:215-224.  
[34] Lombardo F, De Cori S, Aghakhanyan G, Montanaro D, De Marchi D, Frijia F, 
Fortunato S, Forli F, Chiappino D, Berrettini S, Canapicchi R. 3D-Flair sequence at 3T 
in cochlear otosclerosis. Eur Radiol 2016 Oct;26(10):3744-3751.  
[35] Marshall AH, Fanning N, Symons S, et al. Cochlear implantation in cochlear 
otosclerosis. Laryngoscope 2005;115:1728-1733.  
[36] Kabbara B, Gauche C, Calmels MN, et al. Decisive criteria between stapedotomy and 
cochlear implantation in patients with far advanced otosclerosis. Otol Neurotol 
2015;36:73-78.  
[37] Sheehy JL. Far-advanced otosclerosis. Diagnostic criteria and results of treatment: 
report of 67 cases. Arch Otolaryngol Head Neck Surg 1964;80:244-248.  
[38] Berrettini S, Burdo S, Forli F, et al. Far advanced otosclerosis: stapes surgery or 
cochlear implantation? J Otolaryngol 2004;33:165-171.  
[39] Eshraghi AA, Nazarian R, Telischi FF, et al. The cochlear implant: historical aspects 
and future prospects. Anat Rec (Hoboken) 2012;295:1967-1980.  
[40] Hӓusler R, Stieger C, Bernhard H, et al. A novel implantable hearing system with direct 
acoustic cochlear stimulation. Audiol Neurootol 2008;13:247-256.  

Nicola Quaranta, Vito Pontillo and Francesco Dispenza 
 
932
[41] House WF, Glorig A. Criteria for otosclerosis surgery and further experiences with 
round window surgery. Laryngoscope 1960;70:616-630.  
[42] van Loon MC, Merkus P, Smit CF, et al. Stapedotomy in cochlear implant candidates 
with far advanced otosclerosis: a systematic review of the literature and meta-analysis. 
Otol Neurotol 2014;35:1707-1714.  
[43] Frattali MA, Sataloff RT. Far-advanced otosclerosis. Ann Otol Rhinol Laryngol 
1993;102:433-437.  
[44] Marchioni D, Soloperto D, Bianconi L, et al. Endoscopic approach for cochlear 
implantation in advanced otosclerosis: a case report. Auris Nasus Larynx 2016;43:584-
590.  
[45] Linthicum Jr FH, Galey FR. Histologic evaluation of temporal bones with cochlear 
implants. Ann Otol Rhinol Laryngol 1983;92:610-613.  
[46] Fayad J, Moloy P, Linthicum Jr FH. Cochlear otosclerosis: does bone formation affect 
cochlear implant surgery? Am J Otol 1990;11:196-200.  
[47] Nadol JB Jr, Young YS, Glynn RJ. Survival of spiral ganglion cells in profound 
sensorineural hearing loss: implications for cochlear implantation. Ann Otol Rhinol 
Laryngol 1989;98:411-416.  
[48] Eisenberg LS, Luxford WM, Becker TS, et al. Electrical stimulation of the auditory 
system in children deafened by meningitis. Otolaryngol Head Neck Surg 1984;92:700-
705.  
[49] Quaranta N, Bartoli R, Lopriore A, et al. Cochlear implantation in otosclerosis. Otol 
Neurotol 2005;26:983-987 [Erratum in: Otol Neurotol 2005; 26(6):1264].  
[50] Sainz M, Garcia-Valdecasas J, Ballesteros JM. Complications and pitfalls of cochlear 
implantation in otosclerosis: a 6-year follow-up cohort study. Otol Neurotol 
2009;30:1044-1048.  
[51] Matterson AG, O’Leary S, Pinder D, et al. Otosclerosis: selection of ear for cochlear 
implantation. Otol Neurotol 2007;28:438-446.  
[52] Lenarz T, Lesinski-Schiedat A, Weber BP, et al. The nucleus double array cochlear 
implant: a new concept for the obliterated cochlea. Otol Neurotol 2001;22:24-32.  
[53] Balkany T, Gantz BJ, Steenerson RL, Cohen NL. Systematic approach to electrode 
insertion in the ossified cochlea. Otolaryngol Head Neck Surg 1996;114:4-11.  
[54] Ramsden R, Bance M, Giles E, Mawman D. Cochlear implantation in otosclerosis: a 
unique positioning and programming problem. J Laryngol Otol 1997;111:262-265.  
[55] Muckle RP, Levine SC. Facial nerve stimulation produced by cochlear implants in 
patients with otosclerosis. Am J Otol 1994;15:394-398.  
[56] Weber BP, Lenarz T, Battmer R-D, et al. Otosclerosis and facial nerve stimulation. Ann 
Otol Rhinol Laryngol Suppl 1995;166:445-447.  
[57] Bigelow D, Kay DJ, Rafter KO, Montes M, Knox GW, Yousem DM. Facial nerve 
stimulation from cochlear implants. Am J Otol 1998;19:163-169.  
[58] Flook EP, Broomfield SJ, Saeed S, et al. Cochlear implantation in far advanced 
otosclerosis: a surgical, audiological and quality of life review of 35 cases in a single 
unit. J Int Adv Otol 2010;7:35-40.  

Advanced Otosclerosis 
 
933
[59] Seyyedi M, Herrmann BS, Eddington DK, et al. The pathologic basis of facial nerve 
stimulation in otosclerosis and multi-channel cochlear implantation. Otol Neurotol 
2013;34:1603-1609.  
[60] Rayner MG, King T, Djalilian HR, et al. Resolution of facial stimulation in otosclerotic 
cochlear implants. Otolaryngol Head Neck Surg 2003;129:475-480.  
[61] Kelsall DC, Shallop JK, Brammeier TG, Prenger EC. Facial nerve stimulation after 
nucleus 22-channel cochlear implantation. Am J Otol 1997;18:336-341.  
[62] Gold SR, Miller V, Kamerer DB, et al. Fluoride treatment for facial nerve stimulation 
caused by cochlear implants in otosclerosis. Otolaryngol Head Neck Surg 
1998;119:521-523.  
[63] Fernandez-Vega S, Quaranta N, Bartoli R, et al. Management of facial nerve 
stimulation in otosclerosis by revision cochlear implantation. Audiol Med 2008;6:155-
160. 
[64] Ramsden R, Rotteveel L, Proops D, et al. Cochlear implantation in otosclerotic 
deafness. Adv Otorhinolaryngol 2007;65:328-334.  
[65] Kludt E, Bu¨chner A, Schwab B, et al. Indication of direct acoustical cochlea 
stimulation in comparison to cochlear implants. Hear Res 2016;340:185-190.  
[66] Bernhard H, Stieger C, Perriard Y: New implantable hearing device based on a micro-
actuator that is directly coupled to the inner ear fluid. Conf Proc IEEE Eng Med Biol 
Soc 2006;1:3162-3165.  
[67] Lenarz T, Verhaert N, Desloovere C, et al. A comparative study on speech in noise 
understanding with a direct acoustic cochlear implant in subjects with severe to 
profound mixed hearing loss. Audiol Neurootol 2014;19:164-174.  
[68] Busch S, Kruck S, Spickers D, et al. First clinical experiences with a direct 
acousticcochlear stimulator in comparison to preoperative fitted conventional hearing 
aids. Otol Neurotol 2013;34:1711-1718.  
[69] Bosman AJ, Smoorenburg GF. Intelligibility of Dutch CVC syllables and sentences for 
listeners with normal hearing and with three types of hearing impairment. Audiology 
1995;34:260-284.  
[70] Drennan WR, Rubinstein JT. Music perception in cochlear implant users and its 
relationship with psychophysical capabilities. J Rehabil Res Dev 2008;45:779-789. 
[71] Thomas, E., Martines, F., Bianco, A., Messina, G., Giustino, V., Zangla, D., Iovane, A., 
Palma, A. (2018) Decreased postural control in people with moderate hearing loss 
Medicine (United States), 97 (14), DOI: 10.1097/MD.0000000000010244.  
[72] Thomas, E., Bianco, A., Messina, G., Mucia, M., Rizzo, S., Salvago, P., Sireci, F., 
Palma, A., Martines, F. The influence of sounds in postural control (2017) Hearing 
Loss: Etiology, Management and Societal Implications, pp. 1-11.  
[73] Glasscock ME, Storper IS, Haynes DS, Bohrer PS. Stapedectomy in profound cochlear 
loss. Laryngoscope 1996;106:831-833.  
[74] Quesnel AM, Seton M, Merchant SN, et al. Third-generation bisphosphonates for 
treatment of sensorineural hearing loss in otosclerosis. Otol Neurotol 2012;33:1308-
1314.  

Nicola Quaranta, Vito Pontillo and Francesco Dispenza 
 
934
[75] Brookler KH, Gilston N. Re: Third-generation bisphosphonates for treatment of 
sensorineural hearing loss in otosclerosis, Otology & Neurotology 33:1308Y1314, 
2012. Otol Neurotol 2013;34:778-779. 
 
 

In: Encyclopedia of Audiology and Hearing Research 
ISBN: 978-1-53617-702-2 
Editors: Erno Larivaara and Senja Korhola 
© 2020 Nova Science Publishers, Inc. 
 
 
 
 
 
 
 
Chapter 61 
 
 
 
SUDDEN SENSORINEURAL HEARING LOSS 
 
 
Valerio Giustino1, Francesco Lorusso2, MD,  
Serena Rizzo3, MD, Pietro Salvago4, MD  
and Francesco Martines4,5, MD, PhD 
1Sport and Exercise Sciences Research Unit, University of Palermo, Palermo, Italy 
2A.O.U.P. Paolo Giaccone, Palermo, Italy 
3University of Palermo, Di. Chir.On.S. Department,  
Physical Medicine and Rehabilitation, Palermo, Italy 
4University of Palermo, Bio.Ne.C. Department, Audiology Section, Palermo, Italy 
5Istituto Euromediterraneo di Scienza e Tecnologia – IEMEST, Palermo, Italy 
 
 
ABSTRACT 
 
Sudden sensorineural hearing loss (SSNHL), is an important otological disorder that 
affects up to 5-20 in 100,000 people. It is characterized by a rapid loss of the hearing, 
usually unilateral, with a sensorineural hearing loss greater than 30 dB over three 
consecutive frequencies, in less than 72 hours and can be associated with tinnitus and 
vertigo. It is a real sensorineural emergency that can become a permanent handicap if not 
adequately treated. 
Because of patients recovering rapidly or seeking no medical attention, the true 
figure might be higher, even if delaying SHL diagnosis and treatment may decrease the 
effectiveness of treatment. Sudden Hearing Loss can occur at any age but usually affects 
between 50 and 60 years old and the youngest patients affected are among 20-30 years 
old. There are not significantly differences in the prevalence between men and women[1-
3]. Several pathophysiological mechanisms have been proposed to explain SHL 
(infective, vascular, and immune disease), but only 10 to 15 percent of the people have an 
identifiable cause; the majority of cases in fact remain ‘idiopathic’[4]. 
Because no specific cause is identified, the treatments are heterogeneous and can be 
considered empiric; on one hand therapies’ aim is to correct the primary risk factors 
(smoke, diabetes, hypertension, previous viral or bacterial infections), on the other hand 
the purpose is to act on the main etiopathogenetic hypotheses (viral infection, 
immunologic, vascular compromise). 
 

Valerio Giustino, Francesco Lorusso, Serena Rizzo et al. 
 
936
Keywords: sudden hearing loss, sensorineural hearing loss 
 
 
ETIOLOGY 
 
The etiology of Sudden Hearing Loss (SHL) includes viral/infectious, autoimmune, 
labyrinthine membrane rupture/trauma, vascular, neurological, and neoplastic causes [5, 6]. 
Within these broader categories, there are a host of subtypes associated with SHL. An 
abridged list of recognized causes of SHL is shown in table 1 [7-10]. 
 
 
DIAGNOSTIC EVALUATION 
 
Hearing impairment workup comprehends history, audiometry, tympanometry, including 
stapedial reflex testing, as well as auditory evoked potentials. 
A typical history, per se, often makes for a straightforward diagnosis. In particular, 
clinicians should focus on the accompanying circumstances, symptom onset and temporal 
progression, as well as corroborating audiovestibular features (i.e., tinnitus, vertigo/dizziness, 
aural fullness) [11-13]. Clinically, tinnitus and vertigo affect approximately 77% and 33% of 
cases, respectively [14-16]. Moreover, the history should include inquiry into prior otologic 
surgery, exposure to ototoxic agents, viral infections and systemic disorders, such as 
hypercoagulable states, diabetes and autoimmunity [17-19]. A pure-tone audiometry exam 
that assesses conventional generated tone frequencies (i.e., 125, 250, 500, 1000, 2000, 4000 
and 8000 Hz) is a mainstay of the workup in every patient presenting with SHL, as 
recommended by the “International Organization for Standardization” (ISO). Furthermore, 
the clinical utility of the audiogram, together with its morphological features, is not limited to 
the diagnosis, but rather provides clinician the elements of prognostic value as well  
(Figure 1). 
 
 
Figure 1. Most common types of curve. 

Sudden Sensorineural Hearing Loss 
 
937
As for the tympanogram and stapedial reflexes, the utility of these assessments mainly 
lies in the topographic diagnosis of hearing loss. Finally, via objective estimations of 
electrophysiological hearing thresholds, the hearing impairment workup avails itself of 
recordings of auditory evoked potentials, which aid in assessing the integrity of discrete 
constituents of the acoustic-facial bundle and neural circuitry. 
 
Table 1. Causes of SHL 
 
Infectious 
Meningococcal men 
Herpesvirus (simplex, zoster, varicella, cytomegalovirus) 
Mumps 
Human immunodeficiency virus 
Lassa fever 
Mycoplasma 
Cryptococcal meningitis 
Toxoplasmosis 
Syphilis 
Rubeola 
Rubella 
Human spumaretrovirus 
Autoimmune 
Autoimmune inner ear disease (AIED) 
Ulcerative colitis 
Relapsing polychondritis 
Lupus erythematosus 
Polyarteritis nodosa 
Cogan’s syndrome 
Wegener’s granulomatosis 
Traumatic 
Perilymph fistula 
Inner ear decompression sickness 
Temporal bone fracture 
Inner ear concussion 
Otologic surgery (stapedectomy) 
Surgical complication of nonotologic surgery 
Vascular 
Vascular disease/alteration of microcirculation 
Vascular disease associated with mitochondriopathy 
Vertebrobasilar insufficiency 
Red blood cell deformability 
Sickle cell disease 
Cardiopulmonary bypass 
Neurologic 
Multiple sclerosis 
Focal pontine ischemia 
Migraine 
Neoplastic 
Acoustic neuroma 
Leukemia 
Myeloma 
Metastasis to internal auditory canal 
Meningeal carcinomatosis 
Contralateral deafness after acoustic neuroma surgery 
 

Valerio Giustino, Francesco Lorusso, Serena Rizzo et al. 
 
938
PATHOPHYSIOLOGY OF SUDDEN HEARING LOSS 
 
Although a specific cause may be identified in no more than approximately 10% of cases, 
most available evidence appears to support inflammation and/or hypoxia as the underlying 
condition(s) leading to cell injury or dysfunction. Accordingly, three main theories have been 
advanced to interpret idiopathic Sudden Hearing Loss, all of whose hypotheses regarding the 
pathophysiological mechanisms converge on the common pathway of inflammation and/or 
hypoxia: vascular, viral and autoimmune theories. 
 
 
VASCULAR THEORY 
 
Since the inner ear is supplied by terminal blood vessels, the organ is particularly 
vulnerable to reduced blood flow and/or hypoxic stress. Moreover, the resulting clinical 
picture closely matches the physiology of the affected area. Unsurprisingly, circulation within 
the cochleo-vestibular system can be compromised by conditions such as: increases in 
blood/plasma viscosity; sludging of blood; vasospasm and/or release of vasoactive 
substances; embolism or thrombosis. 
 
 
VIRAL THEORY 
 
In 1957, van Dishoeck first advanced a viral theory to elucidate the onset of Sudden 
Hearing Loss, positing three alternative mechanisms [20] (Figure 2): 
 
1. direct viral invasion of the inner ear or cochlear nerve via the bloodstream, 
cerebrospinal fluid, or middle ear; 
2. reactivation of a latent virus presents in the inner ear: neurotropic viruses sub-
clinically infect cochlear neurons, become latent and subsequently are reactivated 
manifesting as acute cochleitis or neuritis, which lead to sudden deafness; 
3. viral antigens stimulating an immune response during a systemic infection induce 
cross-reacting antibodies (i.e., antigenic mimicry) to antigens of the inner ear. 
 
 
                     (A)                                        (B)                                          (C) 
Figure 2. Occlusion of the cochlear (A), vestibular-cochlear (B) and vestibular arteries (C). (From: 
http://www.orl.uniroma2.it/ischemia.htm). 

Sudden Sensorineural Hearing Loss 
 
939
AUTOIMMUNE THEORY 
 
The first report of an autoimmune inner ear disease (AIED), dates back to McCabe 
(1979) [21]. The autoimmune theory of Sudden Hearing Loss postulates the existence of 
autoantibodies or activated T-cells that directly target constituents of the inner ear. Antigens 
occurring on a variety of host molecules, such as type-II collagen, β-actin, cochlin, β-tectorin, 
cochlear proteins (P30 and P80), cardiolipids, phospholipids, serotonin and gangliosides have 
been singled out as the putative targets. As of yet, however, the most compelling case 
concerns a protein called choline transporter-like protein 2 (CTL2). 
Finally, the higher frequency of specific HLA alleles in patients that respond well to 
corticosteroid therapy has been observed, lending further support to the autoimmune theory 
[22-26]: 
 
(A): Reduced blood flow to the cochlear artery affects the medium and apical parts of the 
cochlea, resulting in audiometric deficit limited to medium - and low frequency tones. 
(B): Reduced blood flow at the level of the vestibular-cochlear artery affects the basal 
part of the cochlea, resulting in audiometric deficit of high-frequency tones associated with 
vertigo. 
(C): Reduced blood flow in vestibular artery manifests clinically as significant vertigo 
due to injury of the three semicircular canals. 
 
 
TREATMENT 
 
As mentioned above, treatment of SHL is a controversial matter and the idiopathic 
category has been treated by a wide range of approaches. Within the various treatments 
proposed, glucocorticoids remain the agents most relied on, although via different routes of 
administration: either oral or intratympanic steroids or their combinations [27, 28]. 
Nonetheless, Table 2 includes a list of therapeutic modalities which have been adopted, some 
of which are currently in use for the treatment of SHL. 
 
Table 2. Therapeutic modalities of SHL 
 
Anti-inflammatory/immunologic agents 
Steroids 
Prostaglandin 
Cyclophosphamide 
Methotrexate 
 
Diuretics  
Hydochlorothiazide/triamterene 
Furosemide 
 
Antiviral agents   
Acyclovir 
Valacyclovir 

Valerio Giustino, Francesco Lorusso, Serena Rizzo et al. 
 
940
Table 2. (Continued) 
 
Vasodilators 
Carbogen 
Papaverine 
Buphenine 
Naftidrofuryl 
Thymoxamine 
Prostacyclin 
Nicotinic acid 
Pentoxifylline 
 
Volume expanders/hemodilutors 
Hydroxyethyl starch 
Low-molecular-weight dextran 
 
Defibrinogenators 
Batroxobin 
 
Calcium antagonists 
Nifedipine 
 
Other agents and procedures 
Amidotrizoate 
Acupunture 
Iron 
Vitamins 
Procaine 
 
 
PROGNOSIS 
 
Statistical data from case series indicate that 25% of cases evolve with full recovery of 
hearing, 50% have only partial recovery, while the remaining 25% of patients experience 
permanent hearing impairment [29-31]. In a study of 270 patients in Sicily, included in one 
review, the following five prognostic factors were identified:  
 
a) Type of Therapy: combined intratympanic and systemic steroids produced more 
favorable results; 
b) Type of Curve: an upward curve increased the margins for improvement; 
c) Hypertension: a hypertensive state reduced the likelihood of recovery; 
d) Vertigo: severe vertigo correlated with significantly worse outcomes than no vertigo; 
e) OAE: presence of OAEs had positive prognostic significance [32]. 
 
 

Sudden Sensorineural Hearing Loss 
 
941
CONCLUSION 
 
Sudden sensorineural hearing loss is an issue of primary concern to otolaryngology, 
given its clinical relevance and potential for disabling outcomes. Arguably, hearing loss 
negatively impacts quality of life, social and work-related relationships, often representing 
not only a communication barrier, but also a disconnect from their surroundings for those 
affected, with the inherent risk of emotional isolation [33]. Despite the advances made, many 
aspects regarding etiology, pathogenesis, diagnosis and therapy remain elusive and/or 
controversial. The recent increase in incidence, reported in the literature, probably due to a 
host of new and widespread pathological noxae, along with the emergence of new therapeutic 
protocols, render the discussion regarding these issues quite timely. Finally, there is 
consensus among authors that Sudden Hearing Loss should not go untreated, because many 
treatments provide at least some margin of benefit and functional recovery, thus improving 
the patient's quality of life [34-36]. 
 
 
REFERENCES 
 
[1] 
Gignoux, M., Martin, H., Cajgfinger, H., (1973) Les surdites brusques [The sudden 
surgeons]. J. Med. Lyon, 44/1043, 1701 - 1718. 
[2] 
Tran Ba Huy, P., Bastian, D., Ohresser, M. (1980) Anatomie de l’oreille interne 
[Anatomy of the inner ear]. Encycl. Med. Chir. Paris, ORL, 20020 A 10. 
[3] 
De Kleyn, A., (1994) Sudden complete or partial loss of function of the octavus-system 
in apprerently normal persons. Acta Otolaryngol. (Stockh), 32: 407 - 429. 
[4] 
Martines, F., Bentivegna, D., Maira, E., Marasà, S., Ferrara, S. (2012) Cavernous 
haemangioma of the external auditory canal: Clinical case and review of the literature. 
Acta Otorhinolaryngol. Ital., 32(1): 54 - 57. 
[5] 
Martines, F., Salvago, P., Bartolotta, C., Cocuzza, S., Fabiano, C., Ferrara, S., La 
Mattina, E., Mucia, M., Sammarco, P., Sireci, F., Martines, E. (2015) A genotype–
phenotype correlation in Sicilian patients with GJB2 biallelic mutations. Eur. Arch. 
Otorhinolaryngol., 272(8): 1857 - 1865. 
[6] 
Gagliardo, C., Martines, F., Bencivinni, F., Latona, G., Lo Casto, A., Midiri, M. (2013) 
Intratumoral Haemorrhage Causing an Unusual Clinical Presentation of a Vestibular 
Schwannoma. Neurualradiology Journal, 26: 30 - 34. 
[7] 
Martines, F., Ballacchino, A., Sireci, F., Mucia, M., La Mattina, E., Rizzo, S. (2016) 
Audiologic profile of OSAS and simple snoring patients: the effect of chronic nocturnal 
intermittent hypoxia on auditory function. European Archives of Oto-Rhino-
Laryngology, 273: 1419 - 1424. 
[8] 
Martines, F., Messina, G., Patti, A., Battaglia, G., Bellafiore, M., Messina, A., Rizzo, 
S., Salvago, P., Sireci, F., Traina, M., Iovane, A. (2015) Effects of tinnitus on postural 
control and stabilization: A pilot study. Acta Medica Mediterranea, 31: 907 - 912. 

Valerio Giustino, Francesco Lorusso, Serena Rizzo et al. 
 
942
[9] 
Ferrara, S., Salvago, P., Mucia, M., Ferrara, P., Sireci, F., Martines, F. (2014) Follow-
up after pediatric myringoplasty: Outcome at 5 years. Otorinolaringologia, 64: 141 - 
146. 
[10] Cannizzaro, E., Cannizzaro, C., Plescia, F., Martines, F., Sole, L., Pira, E., Lo Coco, D. 
(2014) Exposure to ototoxic agents and hearing loss: A review of current knowledge. 
Hearing, Balance and Communication, 12: 166 - 175. 
[11] Rizzo, S., Bentivegna, D., Thomas, E., La Mattina, E., Mucia, M., Salvago, P., Sireci, 
F., Martines, F. (2016) Sudden sensorineural hearing loss, an invisible male: State of 
art. Hearing loss: etiology, management and societal implications, 75 - 86. 
[12] Salvago, P., Rizzo, S., Bianco, A., Martines, F. (2017) Sudden sensorineural hearing 
loss: is there a relationship between routine haematological parameters and audiogram 
shapes? International Journal of Audiology, 56(3): 148 - 153. 
[13] Ballacchino, A., Salvago, P., Cannizzaro, E., Costanzo, R., Di Marzo, M., Ferrara, S., 
La Mattina, E., Messina, G., Mucia, M., Mulè, A., Plescia, F., Sireci, F., Rizzo, S., 
Martines, F. (2015) Association between sleep-disordered breathing and hearing 
disorders: Clinical observation in Sicilian patients. Acta Medica Mediterranea, 31(3): 
607 - 614. 
[14] Kiris, M., Cankaya, H., Icli, M., Kutluhan, A. Retrospective analysis of our cases with 
sudden hearing loss. J. Otolaryngol., 2003; 32: 384 - 7. 
[15] Martines, F., Dispenza, F., Gagliardo, C., Martines, E., Bentivegna, D. (2011) Sudden 
sensorineural hearing loss as prodromal symptom of anterior inferior cerebellar artery 
infarction. ORL, 2011; 73: 137 - 140. 
[16] Plescia, F., Cannizzaro, C., Brancato, A., Sireci, F., Salvago, P., Martines, F. (2016) 
Emerging pharmacological treatments of tinnitus. Tinnitus: Epidemiology, Causes and 
Emerging Therapeutic Treatments. Nova Science Publishers, Inc.; 43 - 64. 
[17] Wilson, W. R., Laird, N., Moo-Young, G., Soeldner, J. S., Kavesh, D. A., MacMeel, J. 
W. (1982) The relationship of idiopathic sudden hearing loss to diabetes mellitus. 
Laryngoscope, 92: 155 - 60. 
[18] Campbell, K. C., Klemens, J. J., (2000) Sudden hearing loss and autoimmune inner ear 
disease. J. Am. Acad. Audiol., 11: 361 - 7. 
[19] Martines, F., Maira, E., Ferrara, S. (2011) Age-related hearing impairment (ARHI): A 
common sensory deficit in the elderly. Acta Medica Mediterranea, 27 (1),  
47 - 52. 
[20] Van Dishoeck, H., Bierman, T. (1957) Sudden perceptive deafness and viral infection 
(report of the first one hundred patients). Ann. Otol. Rhinol. Laryngol., 66: 963 - 980. 
[21] McCabe, Brian F. (1991) Autoimmune inner ear disease: results and therapy. Adv. 
Otorhinolaryngol., 46:78 - 81. 
[22] Boulassel, M. R., Deggouj, N., Tomasi, J. P., Gersdorff, M. (2001) Inner ear 
autoantibodies and their targets in patients with autoimmune inner ear diseases. Acta 
Otolaryngol., 121: 28 - 34. 

Sudden Sensorineural Hearing Loss 
 
943
[23] Solares, C. A., Edling, A. E., Johnson, J. M., Baek, M. J., Hirose, K., Hughes, G. B., 
Tuohy, V. K. (2004) Murine autoimmune hearing loss mediated by CD4+ T cells 
specific for inner ear peptides. J. Clin. Invest., 113: 1210 - 1217. 
[24] Nair, T. S., Kozma, K. E., Hoefling, N. L., Kommareddi, P. K., Ueda, Y., Gong, T. W., 
Lomax, M. I., Lansford, C. D., Telian, S. A., Satar, B., Arts, H. A., EI-Kashlan, H. K., 
Berryhill, W. E., Raphael, Y., Carey, T. E. (2004) Identification and characterization of 
choline transporter-like protein 2, an inner ear glycoprotein of 68 and 72 kDa that is the 
target of antibody induced hearing loss. J. Neurosci., 24: 1772 - 1779. 
[25] Adams, L. E. (2002) Clinical implications of inflammatory cytokines in the cochlea: a 
technical note. Otol. Neurotol., 23:316 - 322. 
[26] Disher, M. J., Ramakrishnan, A., Nair, T. S., Miller, J. M., Telian, S. A., Arts, H. A., 
Sataloff, R. T., Altschuler, R. A., Raphael, Y., Carey, T. E. (1997) Human 
autoantibodies and monoclonal antibody KHRI-3 bind to a phylogenetically conserved 
inner ear supporting cell antigen. Ann. NY Acad. Sci., 830: 253 - 265. 
[27] Wilson, Willimam, R., Byl., Frederick, M. and Laird, Nan. (1980) The efficacy of 
steroids in the treatment of idiopathic sudden hearing loss. Archives of Otolaryngology; 
106:772 - 776 (Dec.). 
[28] Dispenza, F., De Stefano, A., Costantino, C., Marchese, D., Riggio, F. (2013) Sudden 
Sensorineural Hearing Loss: results of intratympanic steroids as salvage treatment. Am. 
J. Otolaryngol., 34:296 – 300. 
[29] Lazarini, P. R., Camargo, A. C. (2006) Idiopathic sudden sensorineural hearing loss: 
etiopathogenic aspects. Braz. J. Otorhinolaryngol., 72:554 - 61. 
[30] O’Malley, M. R., Haynes, D. S. (2008) Sudden hearing loss. Otolaryngol. Clin. North 
Am., 41:633 - 49. 
[31] Rauch, S. D. (2008) Idiopathic sudden sensorineural hearing loss. N. Engl. J. Med., 
359: 833 - 40. 
[32] Schweinfurth, J. M. and others. (1997) Clinical applications of otoacoustic emissions in 
sudden hearing loss. Laryngoscope, 107: 1457 - 1463. 
[33] Thomas, E., Martines, F., Bianco, A., Messina, G., Giustino, V., Zangla, D., Iovane, A., 
Palma, A. (2018) Decreased postural control in people with moderate hearing loss. 
Medicine (Baltimore), 97(14): e0244. 
[34] Dispenza, F., Amodio, E., De Stefano, A., Gallina, S., Marchese, D., Mathur, N., 
Riggio, F. (2011) Treatment of sudden sensorineural hearing loss with transtympanic 
injection of steroids as single therapy: a randomized clinical study. Eur. Arch. 
Otorhinolaryngol., 268:1273 - 1278. 
[35] Dispenza, F., Cappello, F., Kulamarva, G., De Stefano, A. (2013) The discovery of the 
stapes. Acta Otorhinolaryngol. Ital., 33(5): 357 - 359. 
[36] Dispenza, F., Mazzucco, W., Bianchini, S., Mazzola, S., Bennici, E. (2015) 
Management of labyrinthine fistula in chronic otitis with cholesteatoma: case series. 
EuroMediterranean Biomedical Journal, 10(21): 255 - 261. 


In: Encyclopedia of Audiology and Hearing Research 
ISBN: 978-1-53617-702-2 
Editors: Erno Larivaara and Senja Korhola 
© 2020 Nova Science Publishers, Inc. 
 
 
 
 
 
 
 
Chapter 62 
 
 
 
CAUSE, PATHOGENESIS, CLINICAL MANIFESTATIONS 
AND TREATMENT OF MENIERE’S DISEASE AND 
ENDOLYMPHATIC HYDROPS 
 
 
Sergio Ferrara2, MD and Francesco Dispenza1,2, MD, PhD 
1Istituto Euromediterraneo di Scienza e Tecnologia – IEMEST, Palermo, Italy 
2U.O.C. Otorinolaringoiatria Azienda Ospedaliera  
Universitaria Policlinico P. Giaccone, Palermo, Italy 
 
 
ABSTRACT 
 
Meniere’s disease (MD) is characterized by the triad of fluctuating hearing loss, 
episodic vertigo and tinnitus, and by endolymphatic hydrops found on postmortem 
examinations. Since the description of endolymphatic hydrops by Hallpike and Cairns all 
the physiopathology of Meniere’s symptoms have been based on assumption that the 
pathologic lesion was the cause of the symptoms. Paparella came out term and concept 
towards understanding of a disease was, “pathogenesis,” which applies to all otological 
diseases, in general and in particular within this context of MD, which allows us to better 
understand this disease. After Schuknecht proposed the theory of membranous rupture 
causing the mixing up of endo and perilymph leading to the appearance of Meniere’s 
symptoms. Lawrence proved this theory with research on experimental animals. In 1995 
the AAO-HNS criteria defines “Possible MD, Probable MD, Definite MD and Certain 
MD. In 1995 the Committee of Barany Society proposed a classification that is similar to 
the AAO-HNS criteria, it includes only two categories: definite MD and probable MD. A 
variety of medical and surgical treatments have been developed to treat or control the 
symptoms. The treatment can be divided into non-destructive and destructive procedures. 
 
Keywords: Meniere disease, hearing loss, deafness, inner ear, endolymphatic hydrops 
 
 
INTRODUCTION 
 
Endolymphatic hydrops is the increase of fluids in the inner ear. The morphological 
substrate of Meniere’s disease, becomes histomorphologically evident by excavation of the 

Sergio Ferrara and Francesco Dispenza 
 
946
Reissner’s membrane in the paraffin sections of the cochlea. Although, Paparella described 
the cause (multifactorial inheritance, genetic) and pathogenesis (endolymphatic absorption) of 
Meniere’s disease and its symptoms (mechanical and chemical); there are diseases that, 
according to Paparella, can predispose patients to endolymphatic hydrops and Meniere’s 
disease. These diseases include: advanced otosclerosis with otosclerosis obstructing the 
vestibular aqueduct, chronic inactive otitis media and mastoiditis, syphilis, delayed MD 
symptoms, endolymphatic hydrops from childhood measles or mumps and sometimes sudden 
deafness. The latter responded well to medical and surgical therapy. Pathophysiology of 
symptoms of MD (vertigo, deafness, pressure, tinnitus, loudness intolerance) can be assessed 
through animal studies; observations of patients clinically and in sequential histopathological 
studies in patients with MD. Besides hydrops of pars inferior, there are hydrops of the pars 
superior, as well, with utricle enlargement. This would have allowed for potassium rich 
endolymph to bathe the basal surface of hair cells as well as the eighth cranial nerve endings. 
Repeated exposure to toxic potassium levels could cause vertigo episodes and a decline in 
hearing. There is currently no gold standard treatment for MD and endolymphatic hydrops. 
Non-destructive methods aim to reduce the symptoms of MD through dietary restrictions as 
well as through the use of betamethasone, citicoline, cinnarizine and diuretics. Isosorbide, is 
also used for MD to improve the endolymphatic hydrops. As with the cases of destructive 
procedures, surgical decompression of the endolymphatic sac, surgical or chemical 
labyrinthectomy and vestibular nerve section are applied in intractable cases. Recently, in 
research literature about MD, improvement in vertigo and hearing in patients with MD were 
described after application of positive pressure to the middle ear using the Meniett device. 
 
 
CAUSE OF MENIERE’S DISEASE 
 
In the mid- nineteenth century, the classical triad of episodic disabling vertigo (Thomas et 
al. 2018), fluctuating sensorineural hearing loss (Salvago et al. 2017, Martines, Maira, and 
Ferrara 2011), tinnitus (Sireci et al. 2012, Salvago et al. 2012, Neri et al. 2009), and a feeling 
of aural pressure was known as “apoplectic cerebral congestion” and was felt to be a brain 
disorder. Meniere demonstrated that this phenomenon was due to a labyrinthine dysfunction 
rather than a brain disease. After Guild discussed the longitudinal flow of endolymph, leading 
to the knowledge that the endolymphatic sac is the site of the outflow of endolymph in guinea 
pigs (Guild 1927). Numerous histopathological studies have clearly described, the importance 
of endolymphatic hydrops and Meniere’s disease. Hydrops has been demonstrated to involve 
both the scala media and the otolithic organs of the inner ear. Hydrops has rarely been 
associated in only the vestibular portion, but it has been seen to involve only the cochlear 
portion (Dispenza, Cappello, et al. 2013). Traditionally, Meniere’s symptom-complex has 
divided into two categories: the so-called Meniere’s syndrome for which a known cause 
exists, and Meniere’s disease, in which the process appears to be idiopathic (Paparella 1984). 
Subsequently, Paparella proposed a new simpler classification: a Meniere’s disease extrinsic 
and a Meniere’s disease intrinsic. The first is caused by etiological agents that have been 
shown, through histopathological correlations, to lead to hydrops and the symptomatology of 
Meniere’s disease. These include etiological agents such as syphilis (Pulec 1972), trauma 
(Paparella and Mancini 1983), otosclerosis (Yoon, Paparella, and Schachern 1990), chronic 

Cause, Pathogenesis, Clinical Manifestations and Treatment … 
 
947
otitis media (Martines et al. 2016, Ballacchino et al. 2015), allergy, tumors, leukemia and 
autoimmune disorders. The second category to consider is the intrinsic factors leading to 
Meniere’s disease. Intrinsic factors are associated with multifactorial inheritance (Paparella 
1985), as a cause can include extrinsic contributing factors as well as underlying intrinsic 
factors such as genetic predispositions and developmental anomalies (Martines et al. 2015, 
Fung et al. 2002). Of these the most important is genetic. Recently it is been observed the 
phenotypic and molecular changes in the organ of Corti auditory sensory epithelia and an 
increase in the number of hair cells and supporting cells, which suggested proliferation of 
those cells after knockdown of protein Hes 1 (hairy and enhancer of split) and protein COUP- 
TF1 (COUP Transcription Factor 1) using shRNA (short hairpin RNA) in the organ of Corti 
organotypic culture of three-day postnatal mice (Tang, Alger, and Pereira 2006). Multiple 
anomalies were found during endolymphatic sac surgery. These findings were seen in many 
mastoidectomies for chronic mastoiditis. The findings included hypopneumatization of the 
mastoid, a sigmoid sinus that is not lateral, but medial and anterior, hypo-development of the 
aditus and supra pyramidal recess and most importantly Trautmann’s triangle, that plate of 
bone separating the sigmoid sinus from the posterior semi-circular canal which also separates 
the mastoid from the posterior cranial fossa. Trautmann’s triangle may be oriented in a more 
vertical than horizontal orientation, but most importantly Trautmann’s triangle is often 
reduced in size and can be absent in too many cases. In these patients the sigmoid sinus abuts 
against the bony wall of the solid angle containing the posterior semi-circular canal. In these 
cases it can be difficult to gain access to the dura containing the endolymphatic sac beneath 
the solid angle. Meniere’s disease is defined by AAO-HNS as “an idiopathic disease 
involving the inner ear, that is characterized by vertigo, hearing loss and tinnitus. Meniere’s 
disease has become accepted as the name used to describe these symptoms when they are 
presumed to be due to hydrops.  
 
 
PATHOGENESIS OF MENIERE’S SYNDROME 
 
Meniere’s syndrome will be described in a number of proposed pathogenic mechanism. 
These include obstruction of the endolymphatic duct or dysfunction of the endolymphatic sac, 
overproduction (or up-regulation) of endolymphatic volume, infections, either bacterial or 
viral, immune-mediated etiologies, genetic causation or predisposition, and vascular 
disorders. 
Endolymphatic hydrops of the membranous labyrinth was described in the pathogenesis 
of Meniere’s syndrome by experiment of Kimura e Schuknecht (Kimura 1982) by surgical 
obstruction of the endolymphatic duct in the guinea pig. Surgical dissection or cauterization 
of the sac may cause endolymphatic hydrops in the guinea pig. Histological examination in 
several human temporal bones showed the presence of peri saccular fibrosis in the 
endolymphatic duct or sac in patients with Meniere’s disease compared to normal (Ikeda and 
Sando 1984). Hypoplasia of the vestibular aqueduct as a cause of Meniere’s syndrome has 
been suggested by an histological study of the human temporal bone and a difference in the 
radiographic appearance of the posterior fossa dural plate and the position of the lateral 
venous sinus. Also, small anatomical size, non-visualization of the duct using RMN and 
possible obstruction of the vestibular aqueduct by a diverticulum of the jugular bulb, have 

Sergio Ferrara and Francesco Dispenza 
 
948
been described in some patients with Meniere’s syndrome. Common to all of these 
observations is that the size of the duct or its capacity for radiographic visualization is 
correlated in some way with the function of the sac and fluid homeostasis of the inner ear. 
Although obstruction of the endolynphatic duct has been seen in a few human temporal bone 
specimens with endolymphatic hydrops and concomitant otosclerosis, frank obstruction of the 
endolymphatic space has been seen in a minority of temporal bones from patients who in life 
had Meniere’s syndrome. The obstruction of some part of the endolymphatic compartment in 
patients with Meniere’s syndrome may be the result, rather than the cause, of endolymphatic 
hydrops and due to displacement and distortion of limiting membranes of the inner ear (Sando 
and Ikeda 1984) (Masutani et al. 1991). 
As an alternative to defective resorption of the endolymph, it has been suggested that the 
up-regulation, or overproduction, of endolymph could be another cause for the increased 
volume of the endolymphatic space found in temporal bones from patients with Meniere’s 
syndrome. Plasma vasopressin levels and plasma antidiuretic hormone (P-ADH) have been 
demonstrated, by Takumida M. et al, to be elevated in patients with a clinical diagnosis of 
Meniere’s syndrome. Keithley et al. could not demonstrate a significant increase in Na+-K+ 
ATPase in the stria vascularis from patients with Meniere’s syndrome, compared to normal 
patients (Keithley, Horowitz, and Ruckenstein 1995). In fact, degenerative changes in the 
lateral cochlear wall in human Meniere’s syndrome, would imply decreased activity in at least 
some enzymatic systems in endolymphatic hydrops. Sterkers et al. have described two 
osmotic gradients in the cochlea, one between the perilymphatic and endolymphatic spaces, 
and another within the endolymphatic space from apex to base. They concluded that 
interference with either gradient may cause endolymphatic hydrops. Juhn et al. have 
described the possible role of intrinsic metabolites of arachidonic acid in the fluid 
homeostasis of the inner ear and the interaction of external factors as drugs, stress hormones, 
and noise, with intrinsic perilymphatic prostaglandin levels and osmolarity. 
Both bacterial and viral pathogens have been proposed as etiological agents in Meniere’s 
syndrome. The classical example of bacterial causation of endolymphatic hydrops is syphilis, 
involving the endolymphatic duct, which includes generalized mononuclear leukocytic 
inflammatory response and endarteritis, that may also be involved in the pathogenesis of 
hydrops. In addition endolymphatic hydrops may also be caused by acute or chronic otitis 
media secondary to passage of bacterial toxins into the inner ear via the round window 
membrane. A delayed endolymphatic hydrops provides indirect evidence for viral causation 
of Meniere’s syndrome. Endolymphatic hydrops seems to occur months or years following a 
previous damage to the inner ear, which in some cases may have been viral. 
There are a number of known immune-mediated systemic diseases, which also cause 
inner ear symptoms and endolymphatic hydrops such as Cogan’s syndrome and polyarteritis 
nodosa. In a number of studies evidence of immune hyperactivity has been demonstrated in 
patients with Meniere’s syndrome. Circulating immune complexes have been demonstrated in 
the serum of some patients with Meniere’s syndrome. More recently, a number of articles 
have demonstrated that 30% of patients with Meniere’s syndrome have been reported to have 
circulating antibodies that reacted with a 58-kilodalton (kDa) antigen generated from animal 
inner ear protein. Similarly, circulating serum antibodies to a 68-kDa protein were found in 
some patients with Meniere’s syndrome and in some patients with delayed endolymphatic 
hydrops (Rauch et al. 1995). Hydrops has been demonstrated following a Type 3 allergic 
reaction, and immunization against Type II collagen. It is clear that a number of disorders 

Cause, Pathogenesis, Clinical Manifestations and Treatment … 
 
949
known to be immune-mediated may produce hearing loss and also endolymphatic hydrops 
(Fattori et al. 1994). 
It also suggested that disorders of the microcirculation of the inner ear, including the 
venous drainage, may be significant in the pathogenesis of Meniere’s syndrome. In the 
classical model of Meniere’s syndrome, it has been suggested that endolymphatic hydrops 
may not be entirely due to physical obstruction of the endolymphatic duct, but may be 
partially mediated by interference with microcirculation of the endolymphatic sac of the vein 
at the vestibular aqueduct. It is demonstrated that endolymphatic hydrops in disorders of the 
microcirculation of the inner ear is immune-mediated in which a significant perivascular 
inflammatory response is common. 
Genetic predisposition to development of endolymphatic hydrops is based on immune-
regulatory mechanisms. There is an increased prevalence of the haplotype HLA B8/DR3 in 
patients with Meniere’s syndrome. 
Inner ear damage may leads to detachment of the otoliths causing Tumarkin’s crisis with 
drop attack caused by a paroxysmal positional vertigo, which may be treated by maneuvers in 
the non-active phase (Dispenza, Kulamarva, and De Stefano 2012, Dispenza et al. 2011). 
 
 
TREATMENT OF MENIERE’S DISEASE AND  
ENDOLYMPHATIC HYDROPS 
 
The treatment of Meniere’s disease remains one of most controversial areas in the field of 
otolaryngology. The most significant obstacle to define treatment is a lack of understanding 
of its underlying etiology and a variety of therapeutic options have been studied with 
conflicting results. Once an attack is established, vestibular suppressant and antiemetic 
medication have been used to control the vertigo, in association with electrolyte adjustment 
and rehydration. Treatment can be divided into non-destructive and destructive procedures. 
Non-destructive methods aim to reduce the symptoms of Meniere disease through dietary 
restrictions and lifestyle (voluptuary habits, greasy and allergic foods) as well as through the 
use of diuretics, steroids, drugs modulating the cholinergic system (scopolamine, atropine), or 
the histaminergic system (dimenhydrate, promethazine), or GABA system (benzodiazepine). 
On the other hand there are medications acting on voltage-gated ionic channels like the 
calcium channel blockers (nimodipine, flunarizine, cinnarizine). Betahistine is currently used 
in European countries for the management of Meniere disease. Recently, experimental and 
clinical studies on antisecretory system as a clinical innovation in Meniere’s disease have 
been published. As for destructive procedures, surgical decompression of the endolymphatic 
sac, surgical or chemical labyrinthectomy and vestibular nerve section are applied for 
intractable cases. Meniett device is used to reduce vertigo and hearing in patients with 
Meniere disease after application of positive pressure to the middle ear. 
A diet low in salt (<2 g) has been the mainstay of therapy. Sodium retention may result 
from endogenous hormonal responses to stress. No evidence indicates that sodium restriction 
alters the progression of the hearing loss, but it seems to help control symptoms significantly 
in many patients. Next, we suggest that patients avoid consuming caffeine, tobacco, alcohol, 
chocolate and allergens. Those patients who consume these seem to suffer more episodic 
dizziness and aural pressure. 

Sergio Ferrara and Francesco Dispenza 
 
950
We routinely use hydrochlorothiazide/triamterene, starting at a low dose (one 25-mg 
tablet per day for one week, after one 25 mg tablet every other day for two weeks, after one 
25 mg tablet twice a week for two weeks) to control metabolic symptoms and reduce the 
sodium load on the inner ear. With this therapy, there is a need to supplement loss of liquids 
with potassium. Blood pressure can be measured before treatments and a week after; if it is 
low to begin with, we may not use diuretic therapy, and it may stop therapy if pressure drops 
later. It is also described the use of osmotic diuretics (mannitol, glycerol) administered 
intravenously. The rationale for their use is based on the supposition that these drugs can alter 
the fluid balance of inner ear, leading to a depletion of endolymph and a correction of 
hydrops (Stahle 1984). 
Oral corticosteroid use is not advisable in patients with classic Meniere disease, but might 
it be advisable in patients with bilateral Meniere’s symptom complex. Treatment with high 
doses oral of prednisone (1mg/Kg/day for five days and then taper it slowly over a further ten 
days). If patients’ response is significant, we may reinstate the therapy, prolonging the use of 
the steroid until we reach a stable audiogram and symptomatology. The use of oral or 
intratympanic (dexamethasone) corticosteroids has also been proposed both to reduce the 
acuity of the crisis and to promote audio-vestibular recovery (Hargunani et al. 2006, 
Dispenza, De Stefano, et al. 2013). 
In the past many patients used a patch for preventing motion sickness as well as a 
treatment for chronic low- grade dizziness, but manufacturing problems have made this drug 
unavailable. A tablet of 0,6 mg of atropine sublingually is an effective method of stopping an 
attack of vertigo. The atropine is absorbed through the oral mucosa and causes a 
parasympathomimetic blockade. A subcutaneous injection of atropine 0,4 mg is useful in an 
emergency room setting to help arrest an active attack. 
Histaminergic system drugs are often prescribed for patients with dizziness or vertigo. 
The anti-emetic action is associated with a sedative effect, which many patients find intrudes 
on their ability to function during day-to-day. Antihistamines and phenothiazines, strong 
vestibular suppressants, can be used as anti-emetics in the control of vertigo; patients with 
Meniere’s disease are often plagued with nausea and vomiting, as well as dizziness. 
Potentially habit- forming drugs must be used with care so as not to create dependency. They 
must be used only for a few days only because of their side effects (sedation, drowsiness) that 
delay the spontaneous vestibular compensation and slow down the recovery process. 
Benzodiazepines act on the cerebellar GABAergic system that inhibits vestibular nuclei 
response and on glycine receptors of the vestibule-spinal reflex that regulate the postural tone. 
Among this class, diazepam, clonazepam and lorazepam are used the most (Padoan et al. 
1990). 
Calcium channel blockers show vestibular suppressant activity because of their 
anticholinergic and antihistamine properties. They may act on the calcium channel of the 
vestibular dark cells modifying the ionic concentration in the endolymph. Side effects are 
tremors, drowsiness, weight gain and depression. Available in this category are flunarizine, 
cinnarizine, nimodipine and verapamil; these latter have been proposed in treating vertigo of 
vestibular peripheral origin and Meniere’s disease particularly. 
All the molecules described, separately or in combination, constitute a possible treatment 
during a crisis of Meniere’s disease. The method of administration depends on the 
development of vegetative symptoms and the availability in the formulation of each molecule. 
It could be oral, intramuscularly, intravenously or rectally. It is important to remember that, 

Cause, Pathogenesis, Clinical Manifestations and Treatment … 
 
951
because of the action inhibiting the vestibular compensation of most of these drugs, their use 
should be limited to the acute phase and stopped as soon as possible (Martines et al. 2012).  
Betahistine favors vestibular compensation and it may play an important role in helping 
patients to recover more quickly after each episode. Betahistine, an analogue of histamine 
with strong inverse agonistic action on the H3 histamine receptors, is currently used in 
European countries for the management of Meniere’s disease. It significantly reduces the 
incidence and severity of vertigo when compared to cinnarizine, flunarizine or Ginko biloba. 
Betahistine efficacy can be explained by mechanisms targeting the histamine receptors at 
three different levels: the vascular tree, the central nervous system, and the peripheral 
vestibular system. In patients with Meniere’s disease, betahistine reduced the intensity and 
frequency of vertigo significantly. However, the therapeutic effect of betahistine is dose- and 
duration dependent. High doses of betahistine (at least 48 mg/day) and long-term betahistine 
treatment (six to nine months) seem two necessary requirements for the prophylactic 
treatment of Meniere’s disease and the improvement of vestibular compensation. According 
to the new theory of the Meniere attack as an ischemia/reperfusion disorder of inner ear 
sensory tissue, betahistine could therefore regulate and normalize the reduced perfusion 
pressure in the inner ear of patients with endolymphatic hydrops (Lacour 2013).  
The anti-secretory factor (AF) is a 41 Kd protein secreted in plasma and other tissue 
fluids in mammals. This protein provides protection against diarrheal diseases and intestinal 
inflammation. It has been postulated that AF may act as a modulator of water and ions by 
regulating chloride homeostasis through membranes, and an interaction with aquaporins has 
been claimed. The endogenous plasma level of anti-secretory factor is increased by 
enterotoxins and surprisingly also by certain food constituents. Specially Processed Cereals 
(SPC) is an AF-inducing medical food, developed by the Swedish R&D company, as well as 
an AF-rich egg yolk powder, Salovum. SPC-Flakes® are especially processed cereal 
optimized to increase endogenous AF plasma levels. A 14-28 days-long period of intake of 
SPC-Flakes® is necessary to obtain a significant AF plasma concentration, commonly 
followed by a positive clinical outcome. Because of the effects on hypersecretion in the 
gastro-intestinal tract, it was hypothesized that anti-secretory treatment with SPC could be 
valuable in other instances where fluid imbalance is thought to play a role, such as Meniere’s 
disease. In an open pilot study, in some patients, the attacks of rotatory vertigo were reduced 
and hearing was normalized. Studies in rats using immunohistochemistry methods 
demonstrated that AF was localized to the cochlea and the vestibule of the inner ear, which 
led the authors to propose that AF could be a new regulator of endolymph. Recently, various 
authors have reported a significant reduction of vertigo in patients with Meniere’ disease 
treated with SPC-Flakes® ranging between 50% and 60%. Significantly other authors have 
correlated the reduction of episodes of vertigo with an increase of AF plasma levels in 
patients with Meniere’s disease performing the therapy. Today, the antisecretory factor 
protein is recognized as a fundamental regulator of fluid balance in mammals (Leong, 
Narayan, and Lesser 2013). 
When intractable incapacitating vertigo cannot be controlled by other means, surgical 
intervention must be considered. In this situation it is desirable to recommend a procedure 
that offers a high likelihood of vertigo control with maximum hearing preservation.  
We can divide intractable vertigo into conservative (endolymphatic sac surgeries, 
saculotomy, crioterapy, fistulization of the labyrinth) and destructive (vestibular neurectomies 
and labyrintectomies). The first type, conservative surgery for Meniere’s disease had been 

Sergio Ferrara and Francesco Dispenza 
 
952
used relatively infrequently, and reports by otologists were often not enthusiastic about the 
procedure’s value. 
Paparella published very good results of a technique with decompression and drainage. 
He emphasized that the experimental demonstration of the endolymphatic sac’s role has not 
been conclusive, however, it appears that the sac does have a significant function in 
endolymphatic homeostasis. When endolymphatic homeostasis is disturbed and hydrops 
occurs, the sac appears a conceptually excellent site for decompression of the endolymphatic 
space. The sac is relatively distant from the cochlear and vestibular organs. There is also 
some evidence that the direction of the flow within the endolymphatic duct is away from 
these organs toward the sac. The surgical technique is essentially the same as any other trans-
mastoid endolymphatic sac procedure, with the exposure of the endolymphatic sac below the 
lateral sinus. It is important to try to expose as much of the endolymphatic sac as possible. A 
probe is used to locate the endolymphatic duct to measure the amount of endolymphatic sac 
hidden by the posterior semicircular canal. The lateral edge of the endolymphatic sac is gently 
excised and lifted off the underlying dura. A probe can be placed between the endolymphatic 
sac and the dura. Next, the endolymphatic sac is transected inferiorly using a small knife. The 
endolymphatic sac can then be lifted off the dura and dissected superiorly, so the only 
attachment remains at the duct. The duct is then grasped with angled cupped forceps and 
avulsed to try to remove as much of the intraosseous portion as possible. 
Chemical labyrinthectomy consists of instilling into the middle ear streptomycin or 
gentamicin with the intention to reduce or abolish vestibular activity in the afflicted ear whilst 
preserving hearing. Gentamicin is less cochleotoxic than streptomycin when instilled directly 
into the middle ear. The absorption of drugs into the inner ear is via the round window or the 
anular ligament of the oval window. The treatment protocols using intratympanic gentamicin 
can be divided into fixed dose protocols and titration protocols. Fixed dose protocols aim to 
administer a fixed dose of gentamicin over a predetermined interval. The treatment is 
discontinued earlier only if the patient develops symptoms or signs of ototoxicity. Titration 
protocols aim to administer gentamicin until the patient demonstrates evidence of ototoxicity. 
Our protocol consists of instilling gentamicin 40 mg/cc through a single weekly injection 
technique. The solution is introduced into the middle ear with an epidural needle into the 
anterior-inferior quadrant of the eardrum until the middle ear is full. A bone conduction 
audiogram and clinical assessment is performed daily before the next administration. Low 
dose, varying interval, protocols offer the attraction of a reduced incidence of hearing loss 
(De Stefano et al. 2007). However, they require a significant time investment and may require 
multiple treatments for the control of vertigo. Intratympanic gentamicin is an effective 
treatment modality for the control of vertigo in severe unilateral Meniere’s disease. It offers 
an alternative to the traditional surgical procedures of vestibular neurectomy and 
labyrinthectomy. Complete or substantial control of vertigo is noted in 90% of patients. 
Vestibular neurectomy is considered when medical management fails. In the retrolabyrinthine 
approach to the vestibular nerve combined with the retrolabyrinthine-retrosigmoid approach 
to the vestibular nerve, the facial nerve is routinely monitored. In the retrolabyrinthine 
approach an anteriorly based postauricolar flap is elevated with the periosteum and 
postauricular muscles in a single layer. A mastoidectomy is performed and bone is removed 
over and behind the sigmoid sinus. The endolymphatic sac and the surrounding dura are 
widely exposed. The vertical portion of the facial nerve, the posterior wall of the external 
auditory canal, and the posterior semicircular canal are identified and preserved. The sigmoid 

Cause, Pathogenesis, Clinical Manifestations and Treatment … 
 
953
sinus is collapsed and retracted posteriorly using a retractor. The dura anterior to the sigmoid 
sinus is incised, creating an anteriorly based flap around the endolymphatic sac. A 1,5-2 cm 
wide Penrose drain is placed over the cerebellum, which is gently retracted as the arachnoid is 
opened with an arachnoid dissector instrument to allow the cerebrospinal fluid to escape. The 
vestibular nerve section is then performed under high-power magnification. The dura is 
closed using interrupted 4-0 silk sutures. Temporalis fascia is placed over the dura, the 
mastoid cavity is then filled with adipose tissue and the wound closed in layers. However a 
watertight closure is generally not possible and the 10% incidence of cerebrospinal fluid 
leakage has led to an evolution in technique of the retrosigmoid-internal auditory canal 
approach (RSG-IAC) and finally of the combined retrolabyrinthine-retrosigmoid approach 
(RRVN). 
The RSG-IAC approach was developed in an attempt to improve results of the vestibular 
neurectomy near the labyrinth, where the fibers are more clearly delineated and decrease the 
incidence of cerebrospinal fluid leakage. Within the internal auditory canal, the cleavage 
plane between the cochlear and vestibular fibers is more developed near the labyrinth and 
thus a more complete and selective vestibular nerve section can be performed. A posterior 
fossa craniotomy is performed behind the sigmoid sinus. After the cerebrospinal fluid is 
released from the cerebellopontine cistern the cerebellum falls away. The jugular dural fold 
and the VIIIth cranial nerve are identified. The posterior wall of the external auditory canal is 
drilled with a diamond burr to the singular canal. Next, the dura in the internal auditory canal 
is incised. The superior vestibular nerve and the singular nerve, the branch of the inferior 
vestibular nerve to the posterior semicircular superior canal (SSC), are sectioned at this point. 
The branch of the inferior vestibular nerve to the saccule is preserved since the saccule has no 
known vestibular function in man and sectioning it would place the hearing at risk. With this 
procedure, no abdominal fat is needed to fill the defect since this approach does not require a 
mastoidectomy. Also, the dura can be closed in a watertight fashion. The retrosigmoid 
approach solved the cerebrospinal fluid leakage problem, however, because of the frequent 
incidence of severe headaches, this approach was discontinued in1987. The headaches were 
felt to be related drilling the bone over the internal auditory canal, causing a bone dust 
arachnoiditis. 
The combined RRVN approach represents a further evolution in posterior fossa 
approaches to vestibular neurectomy. A limited mastoidectomy is performed, opening a few 
mastoid air cells. The bone over the sigmoid sinus is removed from the transverse sinus to the 
jugular bulb of about 3 cm. The dura posterior to the sigmoid sinus is exposed for 1,5-2 cm. A 
dural incision is made 3 mm behind and parallel to the sigmoid sinus. The sigmoid is 
retracted forward using three stay sutures placed along the dural cuff. This affords 
visualization of the posterior wall of the temporal bone, the jugular dural fold, and allows 
wide exposure of the cerebellopontine angle without retraction of the cerebellum. After the 
cerebellopontine angle cistern is opened and cerebrospinal fluid released, the vestibular nerve 
is identified and sectioned. On occasion when a cleavage plane cannot be visualized, the 
internal auditory canal can be opened and the nerve sectioned, as outlined under the RSG-
IAC approach. The internal auditory canal is no longer opened for vestibular nerve section. In 
cases with a poor cleavage plane, the superior half of the VIIIth nerve is sectioned near the 
brain stem. Once the procedure is completed, the exposed mastoid air cells are sealed with 
bone wax and the dura is closed in a watertight fashion with interrupted silk sutures. 
Abdominal fat is used to fill in the bony defect for cosmetic purposes and to reinforce the 

Sergio Ferrara and Francesco Dispenza 
 
954
dural closure. The skin is closed with staples without a drain. This approach was developed in 
an effort to streamline the procedure further by shortening the operating time, making a 
watertight closure of the dura possible, and allowing exposure for drilling the internal 
auditory canal when necessary. 
Pressure treatment is regarded as one of the therapeutical options to offer to disable 
Meniere’s disease, when the patients are not responding to any medical treatment. The 
Meniett device is a portable instrument that allows a patient to self-administer treatments at 
home, whenever required. The Meniett device has become, at some centers, a conservative 
procedure without risk of additional damage to the inner ear, such as when applying intra-
tympanic gentamicin. This therapy started to be always proposed to those Meniere’s patients 
already selected for vestibular neurectomy surgery. The protocol consisted in insertion of a 
short-term trans-tympanic ventilation tube and in one-month treatment that started the same 
day. Each patient was instructed to use the device five times per day, for three minutes per 
session. During the month of treatment, each patient was asked to fill in a diary, noting any 
symptom related to Meniere’s disease (Gates et al. 2006). 
A simple surgical intervention is performed, under local anesthesia, inserting a short-term 
trans- tympanic ventilation tube, with the aim of reducing intralabyrithine pressure and 
decreasing the potential high pressure of the middle ear. Some patients report an improvement 
or a disappearance of vertigo (Park, Chen, and Westhofen 2009, Dispenza et al. 2015). 
 
 
CONCLUSION 
 
Meniere’s disease raises great interest for many reasons: 
 
 
It is necessary to make a precise clinical analysis to decide the diagnosis; 
 
Specific examinations are available to confirm the diagnosis; 
 
The therapeutic medical or surgical support is various and variable; 
 
Clinical and research pathways are multiple. 
 
Beyond the clinical expressions, Meniere’s disease imposes a better understanding of 
mechanisms involving homeostasis of the inner ear and its troubles. The diversity of clinical 
expression, in particular the variability of the intensity and symptoms, justifies individual care 
to establish appropriate treatment. 
 
 
REFERENCES 
 
Ballacchino, A, P Salvago, E Cannizzaro, R Costanzo, M Di Marzo, S Ferrara, E La Mattina, 
G Messina, M Mucia, A Mulè, F Plescia, F Sireci, S Rizzo, and F Martines. 2015. 
“Association between sleep-disordered breathing and hearing disorders: Clinical 
observation in Sicilian patients.” Acta Medica Mediterranea 31:607-614. 

Cause, Pathogenesis, Clinical Manifestations and Treatment … 
 
955
De Stefano, A, F Dispenza, G De Donato, A Caruso, A Taibah, and M Sanna. 2007. 
“Intratympanic gentamicin: a 1-day protocol treatment for unilateral Meniere's disease.” 
Am J Otolaryngol 28 (5):289-93. 
Dispenza, F, F Cappello, G Kulamarva, and A De Stefano. 2013. “The discovery of the 
stapes.” Acta Otolaryngol Ital 33 (5):357-359. 
Dispenza, F, A De Stefano, C Costantino, D Rando, M Giglione, R Stagno, and E Bennici. 
2015. “Canal switch and re-entry phenomenon in benign paroxysmal positional vertigo: 
difference between immediate and delayed occurrence.” Acta Otolaryngol Ital 35:116-
120. 
Dispenza, F, G Kulamarva, and A De Stefano. 2012. “Comparison of repositioning 
maneuvers for benign paroxysmal positional vertigo of posterior semicircular canal: 
advantages of hybrid maneuver.” Am J Otolaryngol 33:528-532. 
Dispenza, F, A De Stefano, C Costantino, D Marchese, and F Riggio. 2013. “Sudden 
Sensorineural Hearing Loss: Results of intratympanic steroids as salvage treatment.” Am 
J Otolaryngol 34 (4):296-300. 
Dispenza, F, A De Stefano, N Mathur, A Croce, and S Gallina. 2011. “Benign paroxysmal 
positional vertigo following whiplash injury: a myth or a reality?” Am J Otolaryngol 
32:376-380. doi: doi:10.1016/j.amjoto.2010.07.009. 
Fattori, B, P Ghilardi, A Casani, P Migliorini, and L Riente. 1994. “Meniere’s disease: Role 
of antibodies against basement membrane antigens.” Laryngoscope 104:1290-1294. 
Fung, K, Y Xie, S F Hall, D P Lillicrap, and S A M Taylor. 2002. “Genetic basis of familial 
Meniere's disease.” J Otolaryngol 31:1-4. 
Gates, G A, A Verrall, J D Green Jr, D L Tucci, and S A Telian. 2006. “Meniett clinical trial: 
Long-term follow-up.” Arch Otolaryngol Head Neck Surg 132:1311-1316. 
Guild, S, 1927. “The circulation of endolymph.” Am J Anat:39-57. 
Hargunani, C A, J B Kempton, J M De Gagne, and D R Trune. 2006. “Intratympanic 
injection of dexamethasone: Time course of inner ear distribution and conversion to its 
active form.” Otol Neurotol 27:564-569. 
Ikeda, M, and I Sando. 1984. “Endolymphatic duct and sac in patients with Meniere's disease: 
A temporal bone histopathological.” Ann Otol Rhinol Laryngol 93:540-546. 
Keithley, E M, S Horowitz, and M J Ruckenstein. 1995. “Na,K-atpase in the cochlear lateral 
wall of human temporal bones with endolymphatic hydrops.” Ann Otol Rhinol Laryngol 
104:858-863. 
Kimura, R S, 1982. “Animal models of endolymphatic hydrops.” Am J Otolaryngol 3:447-
451. 
Lacour, M, 2013. “Betahistine treatment in managing vertigo and improving vestibular 
compensation: Clarification.” J Vest Res 23:139-151. 
Leong, S C, S Narayan, and T H Lesser. 2013. “Antisecretory factor-inducing therapy 
improves patient-reported functional levels in Meniere's disease.” Ann Otol Rhinol 
Laryngol 122:619-624. 
Martines, F, M Agrifoglio, D Bentivegna, M Mucia, P Salvago, F Sireci, and A Ballacchino. 
2012. “Treatment of tinnitus and dizziness associated vertebrobasilar insufficiency with a 
fixed combination of cinnarizine and dimenhydrinate.” Acta Medica Mediterranea 
28:291-296. 
Martines, F, E Maira, and S Ferrara. 2011. “Age-related hearing impairment (arhi): A 
common sensory deficit in the elderly.” Acta Medica Mediterranea 27:47-52. 

Sergio Ferrara and Francesco Dispenza 
 
956
Martines, F, A Ballacchino, F Sireci, M Mucia, E La Mattina, S Rizzo, and P Salvago. 2016. 
“Audiologic profile of OSAS and simple snoring patients: the effect of chronic nocturnal 
intermittent hypoxia on auditory function.” European Archives of Oto-Rhino-
Laryngology 273 (6):1419-1424. doi: 10.1007/s00405-015-3714-6. 
Martines, F, P Salvago, C Bartolotta, S Cocuzza, C Fabiano, S Ferrara, E La Mattina, M 
Mucia, P Sammarco, F Sireci, and E Martines. 2015. “A genotype–phenotype correlation 
in Sicilian patients with GJB2 biallelic mutations.” European Archives of Oto-Rhino-
Laryngology 272 (8):1857-1865. doi: 10.1007/s00405-014-2970-1. 
Masutani, H, H Takahashi, I Sando, and H Sato. 1991. “Vestibular Aqueduct in Meniere's 
Disease and Non-Meniere's Disease With Endolymphatic Hydrops: A Computer Aided 
Volumetric Study.” Auris Nasus Larynx 18:351-357. 
Neri, G, A De Stefano, C. Baffa, G Kulamarva, P Di Giovanni, G Petrucci, A Poliandri, F 
Dispenza, L Citraro, and A Croce. 2009. “Treatment of central and sensorineural tinnitus 
with orally administred Melatonin and Sulodexide: personal experience from a 
randomized controlled study.” Acta Otolaryngol Ital 29:86-91. 
Padoan, S, K Korttila, M Magnusson, I Pyykkö, and L Schalén. 1990. “Reduction of gain and 
time constant of vestibulo-ocular reflex in man induced by diazepam and thiopental.” J 
Vest Res 1:97-104. 
Paparella, M M, 1984. “Pathogenesis of Meniere's disease and Meniere's syndrome.” Acta 
Otolaryngol 98 (suppl. 406):10-25. 
Paparella, M M, 1985. “The cause (multifactorial inheritance) and pathogenesis 
(endolymphatic malabsorption) of Meniere's disease and its symptoms (mechanical and 
chemical).” Acta Otolaryngol 99:445-451. 
Paparella, M M, and F Mancini. 1983. “Trauma and Meniere’s syndrome.” Laryngoscope 
93:1004-1012. 
Park, J J H, Y S Chen, and M Westhofen. 2009. “Meniere's disease and middle ear pressure - 
Vestibular function after transtympanic tube placement.” Acta Otolaryngol 129:1408-
1413. 
Pulec, J L, 1972. “Symposium on Meniere's disease: I. Meniere’s disease: Results of a two 
and one-halfyear study of etiology, natural history and results of treatment.” 
Laryngoscope 82:1703-1715. 
Rauch, S D, J E San Martin, R A Moscicki, and L J Bloch. 1995. “Serum antibodies against 
heat shock protein 70 in Meniere's disease.” Am J Otol 16:648-652. 
Salvago, P, A Ballacchino, M Agrifoglio, S Ferrara, M Mucia, and F Sireci. 2012. “Tinnitus 
patients: Etiologic, audiologic and psychological profile.” Acta Medica Mediterranea 
28:171-175. 
Salvago, P, S Rizzo, A Bianco, and F Martines. 2017. “Sudden sensorineural hearing loss: is 
there a relationship between routine haematological parameters and audiogram shapes?” 
Int J Audiol 56:148-153. 
Sando, I, and M Ikeda. 1984. “The vestibular aqueduct in patients with Meniere's disease: A 
temporal bone histopathological investigation.” Acta Otolaryngol 97:558-570. 
Sireci, F, A Ballacchino, M Agrifoglio, S Ferrara, M Mucia, and P Salvago. 2012. 
“Psychopathologic diseases in patients with tinnitus: A case-control of an outpatient 
cohort. Acta Medica Mediterranea 2012; 28 (2):167-170.” Acta Medica Mediterranea 
28:167-170. 

Cause, Pathogenesis, Clinical Manifestations and Treatment … 
 
957
Stahle, J, 1984. “Medical treatment of fluctuant hearing loss in Meniere's disease.” Am J Otol 
5:529-533. 
Tang, L S, H M Alger, and F A Pereira. 2006. “COUP-TFI controls Notch regulation of hair 
cell and support cell differentiation.” Development 133:3683-3693. 
Thomas, E, F Martines, A Bianco, G Messina, V Giustino, D Zangla, A Iovane, and A Palma. 
2018. “Decreased postural control in people with moderate hearing loss.” Medicine 
(United States) 97:e0244. doi: 10.1097/MD.0000000000010244. 
Yoon, T H, M M Paparella, and P A Schachern. 1990. “Otosclerosis involving the vestibular 
aqueduct and Meniere's disease.” Otolaryngol Head Neck Surg 103:107-112. 
 
 
 
 
 


In: Encyclopedia of Audiology and Hearing Research 
ISBN: 978-1-53617-702-2 
Editors: Erno Larivaara and Senja Korhola 
© 2020 Nova Science Publishers, Inc. 
 
 
 
 
 
 
 
Chapter 63 
 
 
 
AUTOIMMUNE INNER EAR DISEASE 
 
 
Francesco Dispenza1,2, MD, PhD, Alessia Ceraso2, MD,  
Antonina Mistretta2, MD, Gabriele Ebbreo2, MD,  
Francesco Barbara3, MD and Alessia Maria Battaglia2, MD 
1Istituto Euromediterraneo di Scienza e Tecnologia, IEMEST, Palermo, Italy 
2U.O.C. Otorinolaringoiatria Azienda Ospedaliera Universitaria  
Policlinico P. Giaccone, Palermo, Italy 
3Otolayngology Unit, Department of Basic Medical Science,  
Neuroscience and Sensory Organs, University of Bari Aldo Moro, Bari, Italy 
 
 
ABSTRACT 
 
Nowadays, autoimmune deafness does not appear to be as a well-defined nosological 
entity, although the ability of the inner ear to react to genetic, environmental and 
autoimmune phenomena has been demonstrated. The scientific evidence shows 
sensorineural deafness, usually bilateral, rapidly progressive and debilitating, which 
mostly affects women (from 30 to 50 years) and is associated with vestibular symptoms 
and 30% of autoimmune diseases. The clinical diagnosis, without specific laboratory 
tests, is made most of the time, as exclusion. 
Generally, autoimmune deafness is rapidly progressive and is characterized by a 
reduction of more than 30 db on three adjacent frequencies. It appears over a period of 
weeks or a few months. The best diagnostic test, in general, is the improvement of 
hearing observed after treatment with corticosteroids or immunosuppressants. 
Regarding the onset of autoimmune deafness, it is possible to identify different 
factors: genetic hypothesis with particular HLA suggesting genetic susceptibility to 
pathology and environmental hypotheses, namely exogenous (viral, toxic) factors that 
ease its onset. Otoscopy is usually within limits, audiometry doesn’t show particular 
features and it is possible to observe curves with falling plateaus on acute sounds. The 
differential diagnosis is important with diseases such as carcinosis, ear tumors, 
ototoxicity, syphilis, and Ménière's disease. In absence of specific tests, what is typically 
provided is: a) dosage of inflammation markers (ESR and PCR); b) search for antibodies 
that can be found in autoimmune diseases (ANCA, ANA Cryoglobulins, Anti-endomysial 

Francesco Dispenza, Alessia Ceraso, Antonina Mistretta et al. 
 
960
antibodies, Anti-core, Anti-Mitochondria, Anti-muscle smooth, etc.); c) viral serology; d) 
tests to explore humoral and cellular immunity.  
Therefore, therapy involves not only the use of corticosteroids (oral or 
transtympanic) or immunosuppressants, but also of plasmapheresis, gamma globulin and, 
finally, the installation of a cochlear implant. 
 
Keywords: autoimmune, hearing loss, deafness, immunology, ear 
 
 
INTRODUCTION 
 
Already in 1958, Lehnhardt studied recursive bilateral cases of deafness, attributing them 
to the presence of autoantibodies. The immune system is complex and formed by a series of 
balances that allow to recognize our body the self from non-self. If one of these mechanisms 
that guarantee equilibrium should fail, an autoimmune pathology occurs. 
The Autoimmune Inner Ear Disease (AIED) was first described by McCabe in 1979 as 
Bilateral Sensorineural Hearing Loss (SNHL) that progressed over weeks to months and was 
responsive to immunosuppressive agents; hence he proposed an autoimmune mechanism. 
Since that time, a large body of evidence in support of the immune hypothesis has been 
proposed; however, the underlying pathophysiology remains unknown and is likely to be 
varied. Elucidating the underlying immune mechanism is important, because immune-
mediated hearing loss is one of the few causes of SNHL that is reversible. 
Inner ear, also called labyrinth of the ear, is a part of the ear that contains organs of the 
senses of hearing and equilibrium. The bony labyrinth, a cavity in the temporal bone, is 
divided into three sections: the vestibule, the semicircular canals, and the cochlea. (Dispenza, 
Cappello, et al. 2013). Within the bony labyrinth is a membranous labyrinth, which is also 
divided into three parts: the semicircular ducts; two saclike structures, the saccule and utricle, 
located in the vestibule; and the cochlear duct, which is the only part of the inner ear involved 
in hearing. The cochlear duct forms a shelf across the cochlea dividing it into two sections, 
the scala vestibuli and the scala tympani. The bony labyrinth contains the otic capsule, which 
is denser than the surrounding temporal bone. The entire inner ear is bathed in a cushioning 
fluid, called the endolymph when it lies within the membranous labyrinth and the perilymph 
when it separates the bony and membranous labyrinths (Martines et al. 2015, Rizzo et al. 
2016, Salvago et al. 2017). 
 
 
AUTOIMMUNE INNER EAR DISEASE PATHOLOGY 
 
It is complex to have a precise definition of the pathology known as autoimmune 
deafness, since most of the time the diagnosis is made by exclusion or given by the response 
to the treatment with corticosteroids. 
According to the literature data, autoimmune deafness refers to a rapidly progressive 
bilateral and asymmetric sensorineural deafness, with associated vestibular signs and a slight 
prevalence for women in their middle age (factor in common with all the other autoimmune 

Autoimmune Inner Ear Disease 
 
961
diseases) and with a systemic disease associated with a percentage that is around 25% of 
cases.  
AIED manifests clinically as SNHL that progress over weeks. Most commonly affects 
women between the ages of 20 and 50 years. The inner ear is not an immune-privileged site, 
and the endolymphatic sac is critical for the immune response. 
Sudden autoimmune deafness seems to be very rare, and the self-priming residing in the 
presence of autoimmune agents would destroy or directly affect the inner ear. 
Causes of the pathology can be: environmental factors and genetic factors. 
 
 
Environmental Factors 
 
These are infectious agents (for example, parts of viruses or other infectious agents) that, 
according to a mechanism of molecular mimicry, would be recognized as non-self structures 
of the human organism. 
 
 
Genetic Factors 
 
In the years 2001-2005, 88 patients were recruited and subjected to routine serological 
tests and also tests for the determination of antibodies hsp70. Patients were divided into three 
groups: patients with Autoimmune Sensorineural Hearing Loss (ASNHL), patients with 
idiopathic ASNHL associated with Cogan Syndrome and patients with ASNHL associated 
with Systemic Autoimmune Disease (SAD). The study confirmed the value of the anti-hsp70 
test in the diagnosis of autoimmune deafness, promoting it as a marker capable of identifying 
an autoimmune origin of hearing loss (Boulassel et al. 2001, Bovo, Aimoni, and Martini 
2006). 
MicroRNAs (miRNAs) regulate the differentiation and development of inner ear cells. 
Mutations in miRNAs lead to deafness in humans and mice. Among inner ear pathologies, 
inflammation may lead to structural and neuronal defects and eventually to hearing loss and 
vestibular dysfunction. While the genetic factors of these pathways have not been defined, 
autoimmunity participates in these processes. Is reported that inflammatory stimuli in the 
inner ear induce activation of the innate immune system via miR-224 and pentraxin 3 (Ptx3). 
miR-224 is a transcriptional target of nuclear factor κB, a key mediator of innate immunity. 
Ptx3 is a regulator of the immune response. It is released in response to inflammation and 
regulated by nuclear factor κB. Is shown that miR-224 and Ptx3 are expressed in the inner ear 
and is demonstrated that miR-224 targets Ptx3. As a model for the innate immune response, 
lipopolysaccharide is injected into the scala tympani of mouse inner ears. This resulted in 
changes in the levels of miR-224 and Ptx3, in addition to activation of the complement 
system, as measured by immune cell infiltration and activated C3. This suggests that while 
miR-224 regulates Ptx3 under normal conditions, upon inflammation, both are recruited to 
offer a front line of defense in acting as responders to inflammation in the inner ear. miR-224 
diminishes the innate immune response by downregulating Ptx3 expression, while Ptx3 
stimulates the innate immune response (Rudnicki et al. 2014). 
 

Francesco Dispenza, Alessia Ceraso, Antonina Mistretta et al. 
 
962
Yet a role for development is suggested by intriguing overlaps in particular organs 
targeted in autoimmune diseases, in this case type 1 diabetes and Primary Sjogren's Syndrome 
(PSS). Patients with diabetes type 1 have high rates of concomitant PSS, and both conditions 
are associated with hearing loss and tongue abnormalities. All of these co-occurrences are 
found in organs tracing their lineage to the developmental transcription factor Hox11, which 
is expressed in embryonic cells destined for the pancreas, salivary glands, tongue, cranial 
nerves and cochlea (Lonyai et al. 2008). 
 
 
Diagnosis 
 
Making a diagnosis of ASNHL is not simple; it is necessary to have an accurate 
knowledge of the patient in terms of medical history, collection of instrumental examinations, 
laboratory tests and radiological examinations useful to diagnose any underlying multi-organ 
pathology. 
An interesting retrospective study in which 19 cases of patients with bilateral ASNHL 
were presented, with clinical features, laboratory tests, instrumental examinations, 
audiometric and radiological examinations with relative prognosis for each case described. 
Among these 19 cases, 78.9% of patients presented non-otological diseases with multisystem 
and multi-organ disorders, with diseases of the central nervous system such as viral or 
bacterial meningitis, 5 patients on the other hand had pathologies of the concomitant immune 
system, with characteristic deafness progressive and simultaneous bilateral autoimmune type. 
It is therefore necessary, first of all, to identify the etiology of the underlying disease by 
admitting its treatment to treat and try to resolve the associated deafness (Gao et al. 2015). 
Currently, there is any reliable test in order to detect immunocompetent cells or direct 
and specific circulating antibodies against certain labyrinth structures. 
The sensitivity and the specificity of the various tests proposed in the literature must be 
interpreted with caution, since in the absence of standard comparators, there are numerous 
methodological distortions that can lead astray and therefore towards incorrectly correct 
diagnoses. 
The implementation of the complementary budget, particularly the laboratory one, is a 
function of the anamnesis where previous personal and family history, traumas of long 
standing, recent viral syndrome, recent vaccination or intake of an ototoxic drug, must be 
sought. The otoscopic and vestibular examination with subjective audiometry (audiometry) 
and objective measures (auditory evoked potentials, otoemissions) and instrumental vestibular 
tests, will then be completed (Hervier et al. 2010, Dispenza and De Stefano 2012). 
 
 
Cogan’s Syndrome 
 
Cogan's syndrome (CS) is a rare chronic autoimmune disease, characterized by 
interstitial keratitis and sensorineural hearing loss. It may also be accompanied by systemic 
vasculitis (large vessel vasculitis, aortitis, medium-sized vessel vasculitis) (St Clair and 
McCallum 1999). The etiology of CS is still unknown; environmental exposure to toxic 
substances or pollutants, viral infections, cigarette smoking might be some triggers for the 
disease (Gluth et al. 2006). The pathogenesis is now supposed to be based on circulating 

Autoimmune Inner Ear Disease 
 
963
autoantibodies and endothelial antigens that are found in the inner ear in CS patients, but are 
not found in the sera of patients with other autoimmune diseases. Lunardi et al. identified “the 
Cogan peptide” as an amino acid sequence related to six autoantigens; CD148 (a 
transmembrane protein expressed in the inner ear) and connexine 26 (a gap junction protein 
highly expressed in the inner ear) are two of these six autoantigens that have been studied. 
They might be two inner ear targets for autoantibodies (Lunardi, Bason, and Leandri 2002). 
Crohn's disease, ulcerative colitis, sarcoidosis, hypothyroidism, and interstitial nephritis 
and other autoimmune diseases may present in association with CS. That supports the 
hypothesis that CS is an autoimmune disease too (Grasland et al. 2004). 
Usually, CS initially presents with vestibule-auditory pathologies. The most common 
presenting symptom is sudden bilateral sensory hearing loss. Inner ear manifestations of CS 
are Ménière's-like attacks consisting of vertigo, hearing loss, tinnitus, ataxia, nausea, and 
vomiting. Vestibular and auditory dysfunctions develop quickly, and recurrent episodes of 
inner ear disease result frequently in deafness. Once the hearing loss is deep, vertigo and 
other vestibular symptoms usually disappear. 
According to Oshrat et al. mandatory criteria for CS diagnosis are: sensorineural hearing 
loss, inflammatory ocular disease (classically interstitial keratitis), alternative causes of 
inflammation or infection ruled out. 
Prevalent additional criteria are vertigo and tinnitus, ataxia and dizziness, fever, weight 
loss, fatigue, lymphadenopathy, and headache. Possible additional criteria are vasculitis and 
elevation of systemic inflammatory markers. 
There are basically three therapeutic approaches. Topical steroid to treat mild ocular 
disease without other symptoms. Prednisone (1 mg/kg/day) is prescribed when inner ear, 
ocular and systemic symptoms are present; this treatment should produce a short period of 
intense immunosuppression. If improvement occurs doses can be tapered down after 2 to 4 
weeks. In cases of relapse, corticosteroid dose should be increased again.1 Therapeutic doses 
are chosen according to clinical response, in order to reduce the steroid dosage below 10 
mg/day. 
Additional 
immunosuppressive 
drugs 
are 
methotrexate, 
azathioprine, 
cyclophosphamide, cyclosporine (D’Aguanno et al. 2018). 
A biologic therapy using infliximab (anti-TNF-α) could be considered after treatment 
with steroids if: 
 
1) Lack of response to steroids within 2–3 weeks; 
2) Inability to reduce the steroid dosage below 10 mg/day; 
3) The use of steroids is contraindicated in light of the patient's medical status (e.g., 
diabetes, hypertension, or if there are significant sides effects). 
 
The use of infliximab as first-line therapy could be started in selected patients: 
 
1) Patients with severe ocular involvement, which jeopardizes the patient's eyesight 
(scarring and elevated intraocular pressure); 
2) Rapid hearing loss (hearing level approaching 50 Hz); 
3) When both ears are simultaneously affected; 
4) Evidence of systemic involvement: large vessels vasculitis, involvement of the heart, 
kidneys, and nervous system; 

Francesco Dispenza, Alessia Ceraso, Antonina Mistretta et al. 
 
964
5) The patient's general condition precludes the use of high-dose steroids (severe heart 
failure, uncontrolled diabetes, or hypertension). 
 
 
Vogt-Koyanagi-Harada Syndrome 
 
Vogt-Koyanagi-Harada (VKH) syndrome is an idiopathic, multisystem autoimmune 
disorder characterized by bilateral granulomatous uveitis with neurologic, auditory or 
dermatologic symptoms. 
Otologic complaints are sensorineural hearing loss, tinnitus and/or vertigo that typically 
coincide with the onset of ocular pathology (Ondrey et al. 2006).  
The diagnosis of VKH disease is based on both ocular and extraocular symptoms and 
signs. The current diagnostic criteria only include tinnitus, not hearing loss, as an auditory 
finding (Read et al. 2001).  
Nevertheless, according to Morita et al., 89.4% of the subjects affected by VKH included 
in their study were found to be suffering from hearing loss on the basis of audiometric 
findings, while only 34.1% complained of tinnitus. This might be explained by the mild 
degree of hearing loss that can be noticed easily with audiometry but doesn’t match with 
subjective hearing loss. That’s why they suggest to do auditory examinations to every VKH 
patient, in order to evaluate any degree of hearing loss, whether or not the loss is clinically 
relevant (Morita et al. 2014).  
The diagnosis is clinical; the eye exam is fundamental, looking for iridocyclitis and 
posterior uveitis. 
The cochleo-vestibular involvement appears in 33 to 75% of cases. Evolution in deafness 
is usually progressive; rarely it can be sudden. The severity of this impairment is variable. 
The prognosis is improved by early diagnosis and treatment, and adequate management based 
on prolonged corticosteroid therapy with or without immunosuppressors. 
 
 
Susac’s Syndrome 
 
Susac’s syndrome (SS) classically presents with the clinical triad of sensorineural hearing 
loss, retinal artery occlusion and encephalopathy plus the neuroimaging triad of white matter 
lesions, deep gray matter lesions, and leptomeningeal disease. It’s a rare disease. Initial SS is 
characterised by incomplete clinical or neuroimaging triads; this makes it difficult to be 
diagnosed. 
It is now thought that it is an immune-mediated endotheliopathy that affects the 
microvasculature of the brain, retina, and inner ear. The incidence of SS is higher in females 
than in males (3:1), in fact there is a female predominance in autoimmunity diseases. 
Antiendothelial cell antibodies (AECAs) mediate the endothelial cell injury with consequent 
deposition of thrombotic material in the lumen of the small vessel (Magro et al. 2011). 
Patients with SS must be treated quickly and aggressively. Medical treatments start with a 
pulse of highly dosed methylprednisolone (1000 mg/day for 5 days), tapering it in the 
following weeks, according to the patient condition. It is usually provided also an 
antithrombotic and anticoagulation treatment (García-Carrasco et al. 2011). 

Autoimmune Inner Ear Disease 
 
965
In the worst cases, addition of mycophenolate mofetil or rituximab is required, followed 
by cyclophosphamide when disease is refractory to other medications. 
 
 
Rheumatoid Arthritis  
 
Rheumatoid Arthritis (RA) is a chronic autoimmune inflammatory disorder that can 
affect joints. In some people, the condition also can damage a wide variety of body systems, 
including the skin, eyes, lungs, ear, heart and blood vessels. The initial site of disease is the 
synovial membrane, where swelling and congestion lead to infiltration by immune cells. 
Three phases of progression of RA are an initiation phase (due to non-specific inflammation), 
an amplification phase (due to T cell activation), and chronic inflammatory phase, with tissue 
injury resulting from the cytokines, IL–1, TNF-alpha and IL–6. Patients with RA had a high 
prevalence of sensorineural hearing loss for high and very high frequencies. 
RA is thought to induce conductive hearing loss and/or sensorineural hearing loss. 
Ahmadzadeh et al. evaluated the function of the middle ear and cochlea, and the related 
factors in patients with RA; they detected higher bone conduction thresholds in some 
frequencies of RA patients, but not clinically significant. Otherwise they confirmed that 
sensorineural hearing loss is significantly more prevalent in refractory rheumatoid arthritis 
patients. This study revealed that sensorineural hearing loss is frequently due to medical 
treatment with azathioprine, cyclosporine and etanercept (Ahmadzadeh et al. 2017).  
 
 
Primary Sjögren Syndrome  
 
Primary Sjögren Syndrome (pSS) is a chronic autoimmune disease characterized by 
lymphocyte infiltration of both the salivary and lacrimal glands; its main symptoms are dry 
eyes and a dry mouth. Otologic symptoms may be an early indicator of pSS, but they are also 
a less-common feature of other autoimmune disorders (Tucci, Quatraro, and Silvestris 2005). 
Ziavra et al. founded SNHL in 22.5% (9/40) of pSS patients (Ziavra et al. 2000).  
The most common hearing impairment has cochlear origin; it often involves high 
frequencies. Autoantibodies of both cardiolipin and M3 muscarinic receptors in the sera are 
suspected to play a pathogenetic role in the progressive hearing loss of pSS patients(Tucci, 
Quatraro, and Silvestris 2005).  
The mechanism that leads to sensorineural damage might be vasculitis, neuritis, or an 
ototoxic effect of the drugs used to treat pSS (Tumiati, Casoli, and Parmeggiani 1997). 
 
 
Polyarteritis Nodosa 
 
Polyarteritis nodosa (PAN), also known as panarteritis nodosa, periarteritis nodosa, 
Kussmaul disease, or Kussmaul-Maier disease, is a systemic necrotizing inflammation of 
blood vessels (vasculitis) affecting small- or medium-sized muscular arteries, that typically 
involves the arteries of the kidneys, of lungs and other internal organs. 
According to Wolf et al. the hearing loss that occurs in PAN is due largely to middle ear 
effusion but usually appears as a mixed type. Pure perceptive hearing loss is rare. A profound, 

Francesco Dispenza, Alessia Ceraso, Antonina Mistretta et al. 
 
966
rapidly deteriorating perceptive hearing loss could be the onset and only one symptom of 
PAN (Wolf et al. 1987). 
Gussen detected that the cochlea as well as the vestibular system exhibited ischemic 
necrosis of the soft tissue structures with extensive fibrosis and bone formation; that is 
supposed to be one of the pathogenic mechanism of hearing impairment (Gussen 1977).  
 
 
Systemic Lupus Erythematosus 
 
Systemic Lupus Erythematosus (SLE) is an autoimmune disease with multiorgan 
involvement and an incidence of 12.5–39.0 per 100,000 people in the general population (Di 
Stadio and Ralli 2017). The pathophysiology of SLE is based on the production of 
autoantibodies that react with self-nuclear and cytoplasmic antigens, creating an immunologic 
attack on body organs, resulting in tissue inflammation and multiorgan damage (McCarty et 
al. 1995). 
Di Stadio et al. performed a systematic literature review about hearing loss in patients 
affected by SLE. They assessed that SLE can damage tissues and organs through three 
different mechanisms: antibody/antigen direct reactions, cytotoxic action, and immune 
complex deposition(Di Stadio and Ralli 2017). 
These mechanisms together create hearing impairment: immune complex deposition 
plays a central role in the development of inner ear vasculitis and is associated with atrophy 
of the stria vascularis. Progressive reduction of the vessel caliber increases the resistance in 
the circulatory system, eventually increasing the blood pressure. Oxygen deficit damages 
inner ear cells. 
According to Di Stadio et al., corticosteroids should be considered as the first treatment 
option to restore hearing in patients with sudden hearing loss and prevent worsening of 
progressive hearing loss. If steroid therapy is unsuccessful cyclophosphamide should be used. 
Monoclonal antibodies should be used in patients with proven resistance to other treatments. 
Plasmapheresis and anticoagulant treatments could be a good preventive therapy for sudden 
sensorineural hearing loss (Di Stadio and Ralli 2017).  
 
 
SPECIFIC TESTS OF THE INNER EAR 
 
The Specific tests of the inner ear can be classified as follow: lymphoblastic 
transformation test concerning cellular immunity (TTL), western blot (humoral immunity) 
and indirect immunofluorescence test. 
 
 
Lymphoblastic Transformation Test Concerning Cellular Immunity 
 
The test consists in incubating the lymphocytes of patients stimulated with antigens 
belonging to the inner ear (human). To collect the material needed to perform the test, the 
antigens must be extracted by surgery conducted by translabyrintyne route. During these 
experiments conducted on a small number of patients, given the complexity of finding the 

Autoimmune Inner Ear Disease 
 
967
biological material to perform the study, an increase in gamma interferon by T cells placed in 
the presence of antigens coming from the inner ear, was noted (Lorenz, Solares, and Williams 
2002). 
 
 
Western Blot 
 
The test aims to identify specific circulating autoantibodies with respect to different 
antigens present in the human labyrinth, following their migration on a support according to 
their size and weight. 
On this basis several candidate antigens were studied as targets in autoimmune deafness 
(Suslu, Yilmaz, and Gursel 2009): 
 
 
Type II collagen; 
 
Po-myelin; 
 
Beta-actin; 
 
Beta-tubulin; 
 
Different proteins with a molecular weight of 30, 32, 33, 34, 35, 58, 68, 220 Kda 
 
Also some autoantibodies directed against non-specific inner ear proteins were initially 
attentions, such as the antibodies directed against the 68 proteins found in western blot up to 
60% of cases of isolated developmental sensorineural hearing loss, but also in extra 
pathologies labyrinthine. 
This protein was subsequently identified in the heat shock protein 70, an intracellular 
protein released in the event of thermal stress. For other authors it would be the CTL2 protein, 
fundamental in the role of degeneration of the Corti's cells. However, the distribution of 
CTL2 would not only be limited to Corti's cells, but its molecular similarity to cyclic, 
suspects an important function also in the transport of molecules from the intracellular 
environment to the extra cellular environment of the inner ear. This specific protein of the 
inner ear, however, seems an interesting track even if, to date, a diagnostic test has not yet 
been developed to actively and easily tests this protein in the diagnosis of autoimmune 
deafness. 
 
 
Indirect Immunofluorescence Test 
 
The principle is based on the visualization, starting from human or animal temporal bone 
sections, of human antibodies that are fixed and taken first from the patient's serum, which 
confirms that the serum contains specific proteins of the inner ear or non-specific (Yeom et al. 
2003). 
However, it is possible to simply evaluate that laboratory tests have neither the sensitivity 
nor the specificity sufficient to confirm that this is an autoimmune deafness and are 
nevertheless very expensive. 
 
 

Francesco Dispenza, Alessia Ceraso, Antonina Mistretta et al. 
 
968
OTHER USEFUL TESTS FOR DIAGNOSIS 
 
An examination of the fundus oculi is essential to understand the presence of the signs of 
raisins or episcleritis, always in the context of the systemic autoimmune disease. 
A Magnetic Resonance Imaging (MRI) of the posterior cranial fossa and the inner ear 
would be useful in order to found a retrocochlear pathology in the case of asymmetric 
sensorineural deafness (Piccirillo et al. 2011, De Stefano, Kulamarva, and Dispenza 2012). A 
CT of petrous bone also plays an important role in the diagnosis in order to found 
morphological abnormalities of the labyrinth in children (Dispenza et al. 2015). 
The diagnosis is based on history, on physical examination, on laboratory and 
instrumental tests that lead to a general and global classification (Hervier et al. 2010, De 
Stefano et al. 2011, Dispenza, Gargano, et al. 2011). 
 
 
THERAPY 
 
Therapies 
can be 
classified 
as 
follows: 
corticosteroids, 
immunosuppressive, 
plasmapheresis, gammaglobuline, intratympanic injections, cochlear implants, and new 
frontiers of research. 
 
 
Corticosteroids 
 
Validated treatment that demonstrates efficacy in autoimmune deafness. This treatment 
turns out to be the first therapeutic choice even before the diagnostic phase; in fact it is done 
before having carried out all the investigations of the case. The recommended dose for adults 
is 1-2 mg/kg per day of methylprednisone for 4 weeks. 
The oral delivery route is recommended due intravenous cortisone boluses are considered 
off-label with regard to the occurrence of sudden or autoimmune deafness. More the 
treatment is quickly, the greater the degree of improvement of the symptoms obtained. 
The actual duration of steroid treatment seems rather uncertain. Periods of continuation 
of corticosteroid therapy are recommended for 1-2 months, depending on the response (Harris 
and Ryan 1984). If there is not response within 4 weeks, then the steroid therapy is 
recommended to interrupt over a period of seven days in descending order, again to avoid 
altering the hypothalamic-pituitary axis. 
In patients who respond, the hypothesis of continuing with 20-30 mg/day for several 
weeks can be evaluated. In children up to 14 years of age, must be taken into account all the 
adverse effects that could occur with the introduction of corticosteroid therapy during growth 
and evaluate any risks and benefits. 
 
 
Immunosuppressive 
 
Immunosuppressants drugs may be an alternative treatment to the use of corticosteroids. 
It can be evaluated: 

Autoimmune Inner Ear Disease 
 
969
 
in those patients who cannot assume steroid therapy; 
 
in those patients in whom, side effects due to excessive use of strictures, such as 
myelosuppression or hemorrhagic cystitis, have already occurred; 
 
in those patients in whom, having obtained a good result with corticosteroids, they 
want to maintain and strengthen the therapy and the success of the therapy through 
the use of this class of drugs. 
 
Specifically, the drugs used are methotrexate and cyclophosphamide. Methotrexate is 
prescribed at a dose of 7.5 mg/week as a single dose, given in combination with folio acid 1 
mg/day to minimize the risk of stomatitis. 
It is important to monitor the side effects of methotrexate, which include anemia, 
thrombocytopenia, hepatotoxicity and lung problems. 
The side effects of cyclophosphamide instead include bone marrow suppression, 
infertility, hemorrhagic cystitis, increased risk of prostate cancer and lymphoma. Another 
drug that is used as an immunosuppressant is colchycin, an alkaloid that prevents microtubule 
polymerization by blocking them in metaphase, used in anti-inflammatory gout therapy. In 
animals, its validity in the modification of fluids within the labyrinth seems to be related. The 
recommended dose is 1 mg/day, although at the moment none of these drugs was approved by 
the Food and Drug Administration (FDA) for the treatment of autoimmune sensorineural 
deafness. 
 
 
Plasmapheresis 
 
The blood is purified from all the immunoglobulins with a mechanism very similar to that 
of dialysis. This therapy is invasive, expensive and unapproved in the treatment of sudden 
autoimmune deafness. 
 
 
Gammaglobuline 
 
The intravenous route of administration appears to lead to results similar to 
plasmapheresis, with greater ease of delivery and fewer side effects. The immunoglobulins 
would seem to interact with a series of complement factors, such as cytokines, mediators of 
immunity and cellular fractions, in order to attenuate the autoimmune response in 
autoimmune deafness. 
 
 
Intratympanic Injections 
 
The local injection of drugs such as corticosteroids locally, would seem to avoid the 
series of side effects that lead to suspension of therapy. Even this method of delivery presents 
different disadvantages, e.g., given its proximity to the round window and the Eustachian 
tube, it could lead to a residual perforation of the tympanic membrane, but also a series of 
advantages including an ease delivery of therapy that can be repeated over time e also with 

Francesco Dispenza, Alessia Ceraso, Antonina Mistretta et al. 
 
970
simultaneity between right ear and left ear(De Stefano, Kulamarva, and Dispenza 2010, 
Dispenza, De Stefano, et al. 2013, Dispenza, Amodio, et al. 2011). 
 
 
Cochlear Implants 
 
To be evaluated very carefully and after having tried medical therapy according to the 
various steps. The indication clearly is never given in urgency but assessed over time and 
varies from case to case. 
 
Table 1. Autoimmune investigation: main complementary  
1st-intention examinations 
 
 
EMS-platelets, PCR, blood ionogram, creatinine, liver tests 
CPK, LDH, serum protease electrophoresis, 24-hour proteinuria 
Antinuclear factors, native anti-DNA, anti-ENA 
Latex-Waaler Rose, circulating anticoagulant, anticardiolipin, C3, C4, CH50 
Ophthalmologic examination (including fundus of the eye and research of a sicca syndrome) 
Capillaroscopy 
Biopsy of accessory salivary glands  
X-ray of hands 
 
EMS: blood count; PCR: C reactive protein; CPK: creatine phosphokinase; LDH: lactate dehydrogenase; 
DNA: deoxyribonucleic acid; ENA: extractable nuclear antigen. 
 
Table 2. Autoimmune investigation: main complementary  
2nd-intention examinations 
 
 
Outside specialized laboratories 
HLA typing 
Search for an increase in the HSP-70 
Ac anticollagene II 
Ac antimelin P0 
Specialized laboratories 
Ac directed against proteins present in large quantities in the cochlea, but not only: 
- Ac anti-betatubulin 
- Ac anti-lamanina 
- Ac anti-Raf 1 protein 
Ac directed against proteins present only in the cochlea: 
- Ac anti-betatectorine 
- Ac anti-coclina 
 
HLA: human leucocyte antigen; Ac: antibodies. 
 
 

Autoimmune Inner Ear Disease 
 
971
 
 
Table 3. Systemic autoimmune diseases associated with autoimmune  
inner ear disease 
 
Vogt_Koyanagi_Harada Syndrome 
Cogan Syndrome 
Susac Syndrome 
Antiphospholipid syndrome 
Rheumatoid Arthritis 
Systemic vasculitis 
Panarteritis nodosa 
Granulomatosis with polyangiitis 
Goodpasture Syndrome 
Behcet disease 
Sarcoidosis 
Sjogren Syndrome 
Hashimoto thyroiditis 
Relapsing polychondritis 
Myasthenia gravis 
Polymyositis_dermatomyositis 
Crohn’s disease 
Ulcerative colitis 
Guillain-Barre´ syndrome 
Multiple sclerosis 
 
 
CONCLUSION 
 
ASNHL is a rare kind of sensorineural deafness, difficult to detect and to diagnose 
correctly. In those patients who suffer from a well-known systemic autoimmune disease, 
diagnosis is easier and it is supported sometimes by a regression after corticosteroid or 
immunosuppressive therapies. In patients without a systemic autoimmune disease, the 
diagnosis is often given when other possible causes are excluded. A medical team made by 
ENTs, audiologists, rheumatologists, and ophthalmologists is required to manage as well as 
possible the patient with a suspect of ASNHL. 
In order to increase results especially in those patients who can't be delivered with 
corticosteroid, immunosuppressor and other drugs, local therapies have to be improved. When 
therapies aren't working, the cochlear implant can be alternatively chosen as a good solution. 
 
 
REFERENCES 
 
Ahmadzadeh, A, M Daraei, M Jalessi, A A Peyvandi, E Amini, L A Ranjbar, and A Daneshi. 
2017. “Hearing status in patients with rheumatoid arthritis.” J Laryngol Otol 13:895-899. 

Francesco Dispenza, Alessia Ceraso, Antonina Mistretta et al. 
 
972
Boulassel, M R, N Deggouj, J P Tomasi, and M Gersdorff. 2001. “Inner ear autoantibodies 
and their targets in patients with autoimmune inner ear diseases.” Acta Otolaryngol 
121:28-34. 
Bovo, R, C Aimoni, and A Martini. 2006. “Immune-mediated inner ear disease.” Acta 
Otolaryngol 126:1021. 
D’Aguanno, V., M. Ralli, M. de Vincentiis, and A. Greco. 2018. “Optimal management of 
Cogan’s syndrome: A multidisciplinary approach.” Journal of Multidisciplinary 
Healthcare 11:1-11. doi: 10.2147/JMDH.S150940. 
De Stefano, A., F. Dispenza, L. Citraro, A. G. Petrucci, P. Di Giovanni, G. Kulamarva, N. 
Mathur, and A. Croce. 2011. “Are postural restrictions necessary for management of 
posterior canal benign paroxysmal positional vertigo?” Ann Otol Rhinol Laryngol 120 
(7):460-4. 
De Stefano, A., G Kulamarva, and F Dispenza. 2010. “Intratympanic management for 
autoimmune inner ear disease.” Otorinolaringologia 60 (3):155-163. 
De Stefano, A., G. Kulamarva, and F. Dispenza. 2012. “Malignant paroxysmal positional 
vertigo.” Auris Nasus Larynx 39:378-382. 
Di Stadio, A, and M Ralli. 2017. “Systemic Lupus Erythematosus and hearing disorders: 
Literature review and meta-analysis of clinical and temporal bone findings.” J Int Med 
Res 45:1470-1480. 
Dispenza, F, F Cappello, G Kulamarva, and A De Stefano. 2013. “The discovery of the 
stapes.” Acta Otorhinolaryngol Ital 33 (5):357-359. 
Dispenza, F, and A De Stefano. 2012. “Vertigo in childhood: a methodological approach.” 
Bratisl Med J 113:256-259. 
Dispenza, F., E. Amodio, A. De Stefano, S. Gallina, D. Marchese, N. Mathur, and F. Riggio. 
2011. “Treatment of sudden sensorineural hearing loss with transtympanic injection of 
steroids as single therapy: a randomized clinical study.” Eur Arch Otorhinolaryngol 268 
(9):1273-8. 
Dispenza, F., A. De Stefano, C. Costantino, D. Marchese, and F. Riggio. 2013. “Sudden 
Sensorineural Hearing Loss: Results of intratympanic steroids as salvage treatment.” Am 
J Otolaryngol 34 (4):296-300. 
Dispenza, F., R. Gargano, N. Mathur, C. Saraniti, and S. Gallina. 2011. “Analysis of visually 
guided eye movements in subjects after whiplash injury.” Auris Nasus Larynx 38:185-
189. 
Dispenza, F., W. Mazzucco, S. Bianchini, S. Mazzola, and E. Bennici. 2015. “Management of 
labyrinthine 
fistula 
in 
chronic 
otitis 
with 
cholesteatoma: 
Case 
series.” 
EuroMediterranean 
Biomedical 
Journal 
10 
(21):255-261. 
doi: 
10.3269/1970-
5492.2015.10.21. 
Gao, X, L Liu, Y Huang, H Lu, J Ouyang, and Y Wang. 2015. “Etiologies and clinical 
features of 19 cases with bilateral acute sensorineural hearing loss.” Zhonghua Er Bi Yan 
Hou Tou Jing Wai Ke Za Zhi 50:3-7. 
García-Carrasco, M, C Jiménez-Hernández, M Jiménez-Hernández, S Voorduin-Ramos, C 
Mendoza-Pinto, G Ramos-Alvarez, A Montiel-Jarquin, J Rojas-Rodríguez, and R 
Cervera. 2011. “Susac's syndrome: an update.” Autoimmun Rev 10:548-552. 
Gluth, M B, K H Baratz, E L Matteson, and C L Driscoll. 2006. “Cogan syndrome: a 
retrospective review of 60 patients throughout a half century.” Mayo Clin Proc 81:483-
488. 

Autoimmune Inner Ear Disease 
 
973
Grasland, A, J Pouchot, E Hachulla, O Blétry, T Papo, and P Vinceneux. 2004. “Typical and 
atypical Cogan’s syndrome: 32 cases and review of the literature.” Rheumatology 
43:1007-1015. 
Gussen, P. 1977. “Polyarteritis nodosa and deafness. A human temporal bone study.” Arch 
Otorhinolaryngol 217:263-271. 
Harris, J P, and A F Ryan. 1984. “Immunobiology of the inner ear.” Am J Otolaryngol 5:418-
425. 
Hervier, B, P Bordure, M Audrain, C Calais, A Masseau, and M Hamidou. 2010. “Systematic 
screening for nonspecific autoantibodies in idiopathic sensorineural hearing loss: no 
association with steroid response.” Otol Neurotol 31:687-690. 
Lonyai, A, S Kodama, D Burger, and D L Faustman. 2008. “The promise of Hox11+ stem 
cells of the spleen for treating autoimmune diseases.” Immunol Cell Biol 86:301-309. 
Lorenz, R R, C A Solares, and P Williams. 2002. “Interferon-gamma production to inner ear 
antigens by T cells from patients with autoimmune sensorineural hearing loss.” J 
Neuroimmunol 130:173-178. 
Lunardi, C, C Bason, and M Leandri. 2002. “Autoantibodies to inner ear and endothelial 
antigens in Cogan’s syndrome.” Lancet 360:915-921. 
Magro, C M, J C Poe, M Lubow, and J O Susac. 2011. “Susac syndrome: an organ-specific 
autoimmune endotheliopathy syndrome associated with anti-endothelial cell antibodies. 
2011;136:903–12.” Am J Clin Pathol 136:903-912. 
Martines, F., P. Salvago, C. Bartolotta, S. Cocuzza, C. Fabiano, S. Ferrara, E. La Mattina, M. 
Mucia, P. Sammarco, F. Sireci, and E. Martines. 2015. “A genotype–phenotype 
correlation in Sicilian patients with GJB2 biallelic mutations.” European Archives of Oto-
Rhino-Laryngology 272 (8):1857-1865. doi: 10.1007/s00405-014-2970-1. 
McCarty, D J, S Manzi, T A Jr Medsger, R Ramsey-Goldman, R E LaPorte, and C K Kwoh. 
1995. “Incidence of systemic lupus erythematosus. Race and gender differences.” 
Arthritis Rheum 38:1260-1270. 
Morita, S, Y Nakamaru, N Obara, M Masuya, and S Fukuda. 2014. “Characteristics and 
Prognosis of Hearing Loss Associated with Vogt-Koyanagi-Harada Disease.” Audiol 
Neurotol 19:49-56. 
Ondrey, F G, E Moldestad, M A Mastroianni, A Pikus, D Sklare, E Vernon, R Nusenblatt, 
and J Smith. 2006. “Sensorineural hearing loss in Vogt-KoyanagiHarada syndrome.” 
Laryngoscope 116:1873-1876. 
Piccirillo, E., A. De Stefano, F. Dispenza, G. Kulamarva, G. De Donato, and M. Sanna. 2011. 
“Intermediate nerve schwannoma: a rare tumour.” B-Ent 7 (3):219-23. 
Read, R W, G N Holland, N A Rao, K F Tabbara, S Ohno, L Arellanes-Garcia, P Pivetti-
Pezzi, H H Tessler, and M Usui. 2001. “Revised diagnostic criteria for Vogt-Koyanagi-
Harada disease: report of an international committee on nomenclature.” Am J Ophthalmol 
131:647-652. 
Rizzo, S., Bentivegna, D., Thomas, E., La Mattina, E., Mucia, M., Salvago, P., Sireci, F., 
Martines, F. (2016) Sudden sensorineural hearing loss, an invisible male: State of art. 
Hearing loss: etiology, management and societal implications, 75-86. 
Rudnicki, A, S Shivatzki, L A Beyer, Y Takada, Y Raphael, and K B Avraham. 2014. 
“MicroRNA-224 regulates Pentraxin 3, a component of the humoral arm of innate 
immunity, in inner ear inflammation.” Hum Mol Genet 23:3138-3146. 

Francesco Dispenza, Alessia Ceraso, Antonina Mistretta et al. 
 
974
Salvago, P., S. Rizzo, A. Bianco, and F. Martines. 2017. “Sudden sensorineural hearing loss: 
is there a relationship between routine haematological parameters and audiogram 
shapes?” 
International 
Journal 
of 
Audiology 
56 
(3):148-153. 
doi: 
10.1080/14992027.2016.1236418. 
St Clair, E W, and R M McCallum. 1999. “Cogan’s syndrome.” Curr Opin Rheumatol 11:47–
52. 
Suslu, N, T Yilmaz, and B Gursel. 2009. “Utility of immunologic parameters in the 
evaluation of Meniere's disease.” Acta Otolaryngol 129:1160-1165. 
Tucci, M, C Quatraro, and F Silvestris. 2005. “Sjögren's syndrome: an autoimmune disorder 
with otolaryngological involvement.” Acta Otolaryngol Ital 25:139-144. 
Tumiati, B, P Casoli, and A Parmeggiani. 1997. “Hearing loss in the Sjögren syndrome. Ann 
Intern Med. 1997 Mar 15; 126:450-3.” Ann Intern Med 126:450-453. 
Wolf, M, J Kronenberg, S Engelberg, and G Leventon. 1987. “Rapidly progressive hearing 
loss as a symptom of polyarteritis nodosa.” Am J Otolaryngol 8:105-108. 
Yeom, K, J Gray, T S Nair, H A Arts, and S A Telian. 2003. “Antibodies to HSP-70 in 
normal donors and autoimmune hearing loss patients.” Laryngoscope 113:1770-1776. 
Ziavra, N, E N Politi, I Kastanioudakis, A Skevas, and A A Drosos. 2000. “Hearing loss in 
Sjögren's syndrome patients. A comparative study.” Clin Exp Rheumatol 18:725-728. 
 
 

In: Encyclopedia of Audiology and Hearing Research 
ISBN: 978-1-53617-702-2 
Editors: Erno Larivaara and Senja Korhola 
© 2020 Nova Science Publishers, Inc. 
 
 
 
 
 
 
 
Chapter 64 
 
 
 
OCCUPATIONAL HEARING LOSS 
 
 
Giampietro Ricci1, Egisto Molini1, Mario Faralli1, 
Lucia Calzolaro2 and Luca D’Ascanio3,* 
1Department of Biological and Surgical Sciences, ENT Section,  
University of Perugia, Perugia, Italy 
2Department of Otolaryngology, Civil Hospital Città di Castello, Italy 
3Department of Otolaryngology - Head & Neck Surgery,  
Carlo Poma Civil Hospital – ASST Mantova, Italy 
 
 
ABSTRACT  
 
Occupational hearing loss is a condition that results from exposure to noise (noise 
induced hearing loss, NIHL) or to non-noise agents in a work environment. NIHL is 
usually caused by continuous or intermittent noise exposure which usually develops 
slowly over several years. Hearing loss from non-noise agents results from exposure to 
organic solvents, metals, and carbon monoxide. Occupational hearing loss is a prominent 
global topic affecting individuals, families, businesses and communities, since it is one of 
the major causes of adult-onset hearing loss at different ages all over the world. 
Furthermore, occupational noise may have harmful effects eventually independent or 
associated to hearing loss. Non auditory effects of noise exposure and hearing loss are: 
physical effects (tinnitus, increased cardiovascular disease risk, fatigue and sleeplessness, 
increased accident and injury risk, impaired communication), psychological and social 
effects (annoyance, depression, memory loss, impaired decision making, reduced quality 
of life, lower confidence and self-esteem, social isolation, relational difficulties) and 
economic effects (employment and income disruption, increased work absenteeism, 
increased employee turnover, reduced productivity and performance). Occupational 
NIHL is typically bilateral, with a classical “notch” at the high frequencies (3000, 4000, 
or 6000 Hz) and recovery at 8000 Hz, in contrast to presbycusis, indicating a hearing 
impairment in the middle of the frequency range of human voice. The notch becomes 
deeper and wider and affects adjacent frequencies in case of continued noise exposure, 
with a consequent increased impact on speech communications. Making a diagnosis of 
occupational NIHL is an important step in preventing further hearing loss in the affected 
                                                        
*Corresponding Author’s Email: giampietro.ricci@unipg.it. 

Giampietro Ricci, Egisto Molini, Mario Faralli et al. 
 
976
worker and identifying the potential for NIHL in co-workers. Complete hearing loss 
prevention programs are needed to effectively reduce the global burden of occupational 
hearing loss. 
 
Keywords: occupational hearing loss, noise induced hearing loss 
 
 
INTRODUCTION 
 
Sound is energy in the form of pressure waves that vary rapidly as they move through the 
air and other media. Sound waves enter the cochlea where they stimulate hair cells (HCs). 
Such cells convert the vibratory sound energy into electrical impulses that travel via the 
auditory nerve to the brain, where they are interpreted. In case of HCs destruction, a 
permanent hearing loss will develop. Sound frequency (pitch) is the number of pressure 
variations per second and is measured in hertz (Hz). The magnitude or intensity of a sound 
(loudness) is measured by the sound pressure level in units of decibels (dB). The decibel is 
used to describe both noise exposure and hearing loss. While sound magnitude is measured as 
sound pressure level (dB SPL), hearing threshold is measured as hearing level (dB HL).  
Averaged thresholds at specific tested frequencies are referred as pure tone average 
(PTA). The typical pure tone audiometric test includes frequencies at 0.25, 0.5, 1, 2, 4, and 8 
kHz, which include the speech frequency range of 0.3 – 4 kHz. Many epidemiological and 
population-based studies on occupational noise induced hearing loss focus on PTAs that 
include 0.5, 1, 2, and 4 kHz frequencies. 
The perceived loudness of sounds varies with sound frequency as well as with dB level. 
To account for this, a spectral sensitivity factor (A-filter) is used to weight sound pressure 
levels to de-emphasise lower and higher frequencies and emphasise the mid-range 
frequencies to which the human ear is most sensitive (i.e., around the 1–6 kHz range). These 
A-weighted sound pressure levels are expressed in units of dB(A) [1-3]. 
Long-term exposure to noise levels beyond 80 dB(A) carries an increased risk of hearing 
loss, which increases with noise level. Exposure to loud noise is the most common 
preventable cause of hearing loss and impairment (a weighted average hearing loss at 1, 2, 3, 
and 4 kHz greater than 25 dB) [4]. 
Occupational noise hearing loss in workers at different ages accounts for 7% to 21% 
(mean 16%) of the forms of adult-onset hearing impairment all around the world [5]. Besides 
hearing loss, occupational noise is associated with tinnitus, cardiovascular disease, 
depression, increased risk of accidents, and decreased productivity. Occupational hearing loss 
is a permanent sensorineural hearing loss due to acoustic overstimulation that has the 
potential for damaging cochlear cells (noise induced hearing loss, NIHL). Occupational NIHL 
is caused by continuous or intermittent noise exposure and usually develops slowly over 
several years. However, occupational hearing loss can also result from exposure to non-noise 
agents, such as chemicals (organic solvents, metals, carbon monoxide) and pharmaceuticals 
(ototoxins). In case of contemporary causes (i.e., noise and ototoxic chemicals), the effects on 
hearing loss are usually additive [6]. Many chemicals, either alone or in association with 
noise, may damage hearing organs and nerves after inhalation or dermal exposure. Potential 
ototoxic chemicals in the occupational environment are fuels, carbon monoxide, lead and 
derivatives, toluene, xylene, stoddard solvent, mercury and derivatives, organophosphate 

Occupational Hearing Loss 
 
977
pesticides, chemical warfare nerve agents, perchloro-ethylene, n-hexane, ethyl benzene, 
trichloroethylene, manganese, styrene monomer, cyanide, organic tin, arsenic, carbon 
disulfide, paraquat [7].  
 
 
PATHOPHYSIOLOGY OF OCCUPATIONAL HEARING LOSS 
 
The mechanisms of cochlear damage are mechanical: the exaggerated movements of the 
basilar membrane cause an increase in oxidative metabolism with a consequent production of 
free radicals, glutamatergic excitotoxicity, ionic and ischemic disorders responsible for 
delayed HCs death in the inner ear by necrosis and apoptosis. Increased levels of reactive 
oxygen species (ROS: molecules or ions formed by the incomplete single-electron reduction 
of oxygen, superoxide, peroxides, hydroxyl radicals, and hypochlorous acid) and reactive 
nitrogen species (RNS: nitric oxide-derived compounds that include nitroxyl anion, 
nitrosonium cation, higher oxides of nitrogen, S-nitrosothiols, and dinitrosyl iron complexes) 
play a significant role in noise-induced hair cell death [8-10]. 
Oxidative stress is an imbalance between the production of reactive oxygen species 
(ROS) and antioxidant defences, potentially resulting in oxidative damage [11]. ROS cause 
damage by chemically reacting with DNA, proteins, cytosolic molecules, cell surface 
receptors, and membrane lipids [12] and have been detected in cochlear tissue just after noise 
exposure [13] just before any morphological sign of damage [14]. The initial mechanical HCs 
damage occurs in conjunction with transient intense ROS formation; HCs loss progresses 
over time and stabilizes two or more weeks after the insult when the late formation of free 
radicals of ROS/RNS causes a delayed HCs loss spreading from the basal turn to the apex 
[15]. ROS cause the activation of cellular defence pathways such as autophagy [16], a 
protective process that delivers damaged cellular components to lysosomes for degradation 
[17]. Such procedure attenuates noise-induced hearing loss (NIHL) by reducing the 
consequences of oxidative stress [18]. ROS can also cause the production of pro-
inflammatory cytokines [19] and tumour necrosis factor [20] which can produce cochlear 
damage [21]. Calcium homeostasis plays a significant role in regulating ROS release from 
mitochondria into the cytoplasm [22]. Aminoglycoside antibiotics drastically alter calcium 
homeostasis by increasing cytoplasmic ROS in HCs; free calcium triggers mitogen-activated 
protein kinase (MAPK) responsible of HCs damage [23]. 
Glutamate excitotoxicity is defined as cell death produced by the toxic actions of the 
essential amino-acid glutamate. Neuronal excitotoxicity is the injury and death of neurons 
arising from prolonged exposure to glutamate and the associated excessive calcium overload 
in HCs responsible for the activation of enzymes that degrade proteins, membranes and 
nucleic acids [24]. High-level noise exposure causes the release of a large amount of 
glutamate within inner hair cells (IHCs) that overstimulate NMDA receptors, thus producing 
high intracellular synapses calcium levels. Excessive postsynaptic ion influx into the auditory 
nerve terminals at the IHCs synapse results in dendritic swelling and vacuolization [25].  
In addition, an increased potassium concentration, due to high-level noise exposure, may 
be toxic for HCs [26] since it increases intracellular calcium concentration which activates a 
series of enzymes that degrade proteins, membranes and nucleic acids [27].  

Giampietro Ricci, Egisto Molini, Mario Faralli et al. 
 
978
High-level noise exposure causes cochlear vasoconstriction and reduced inner ear blood 
flow as well, by means of prostaglandins [28]. Noise-induced ischemia and subsequent re-
perfusion further potentiate the generation of ROS [29]. 
Following intense noise exposure activation of ROS, RNS and MAPK stress pathways, 
cochlear HCs can undergo apoptosis and/or necroptosis [30-35]. 
Apoptosis results in the orderly disassembly of cells into membrane-packaged fragments 
that can be eliminated by phagocytes in a non-inflammatory process. Apoptosis appears 
extremely rapidly after noise stresses and has been shown to be the primary cell death 
pathway in the first day following noise exposure [31,32,36]. Necroptosis permeabilizes intra- 
and extracellular membranes, releasing cellular and organelle contents into the extracellular 
medium, where they induce inflammation. 
Noise exposure has been shown to up-regulate cochlear production of cytokines [20,37] 
and chemotactic chemokines that attract inflammatory cells to the cochlea [38]. Another 
potential source of inflammatory mediators is the release of intracellular components into the 
extracellular environment. Such release develops in case of necrosis or necroptosis, both of 
which have been implicated in noise-induced cochlear damage [39]. 
The accumulation of ROS in cells is opposed by the action of native antioxidant enzyme 
systems, and HCs are no exception to this process. Glutathione, superoxide dismutase (SOD), 
catalase (CAT), glutathione peroxidase, glutathione reductase and coenzyme Q10 have all 
been detected in cochlear tissues [40-42]. These natural defences have to be overcome by 
ROS before cell damage develops. The antioxidant glutathione in the organ of Corti is 
distributed in a high-to-low gradient from the apex to the base [43]. This distribution may 
explain the familiar pattern of HCs damage due to several causes, with initial appearance in 
the base and progressive extension towards the apex. 
 
 
CLINICAL AND AUDIOMETRIC CHARACTERISTICS OF NIHL 
 
Occupational NIHL is always sensorineural, typically bilateral. Its first sign is a 
“notching” of the audiogram on high frequencies (3000, 4000, or 6000 Hz) with recovery at 
8000 Hz [44]. This notch typically develops on one of these frequencies and affects adjacent 
frequencies with continued noise exposure. The exact location of the notch depends on 
multiple factors including the frequency of the damaging noise and size of the ear canal. In 
early NIHL, the average hearing thresholds at the lower frequencies (500, 1000, and 2000 Hz) 
are better than the average thresholds at 3000, 4000, and 6000 Hz, and the hearing level at 
8000 Hz is usually better than the deepest part of the notch. Noise exposure alone usually 
does not produce a loss greater than 75 dB at high frequencies and greater than 40 dB at lower 
frequencies. Hearing loss due to noise exposure increases most rapidly during the first 10 to 
15 years of exposure, while the pattern of hearing loss decelerates later on: previously noise-
exposed ears are less sensitive to future noise exposure. Furthermore, it is unlikely that NIHL 
progresses if noise exposure is discontinued. 
The presence of a temporary threshold shift (TTS: the temporary loss of hearing, which 
largely disappears 16–48 hours after exposure to loud noise) with or without tinnitus is a risk 
indicator that permanent threshold shift (PTS) will occur if hazardous noise exposure 
continues. Except for ototraumatic accident, workers always develop TTS before sustaining 
PTS [45].  

Occupational Hearing Loss 
 
979
When evaluating cases of asymmetric loss, a referral to rule out a retrocochlear lesion, 
such as an acoustic neuroma, is required before attributing the loss to noise. The addition of 
very intense and frequent impulse/impact noise to steady-state noise can be more harmful 
than steady-state noise of the same A-weighted energy exposure. There are a number of other 
causes of sensorineural hearing loss besides occupational noise. These include non-
occupational noise exposure (recreational noise), exposure to ototoxic compounds including 
drugs [46,47], mutations in deafness genes [48-51], infections such as labyrinthitis or prenatal 
cytomegalovirus [52-56], aging [57,58], head injury, therapeutic radiation exposure, 
neurologic disorders, cerebral vascular disorders, immune disorders, bone diseases (Paget 
disease), central nervous system neoplasms, and Ménière disease [59].  
NIHL is irreversible. Detection and intervention are critical to prevent this condition 
to develop. A significant threshold shift (STS) of 10-dB from the baseline in PTA at 
2000, 3000, and 4000 Hz is an important early indicator of permanent hearing loss [60]. 
TTS is an important early and reversible indicator that potential cochlea HCs damage can 
progress to a STS. Tinnitus is another early warning symptom for NIHL [61-64]. One of 
the main components of the hearing conservation programme is the annual pure tone 
audiogram (PTA), designed to detect workers with NIHL early and to submit them to 
subsequent interventions that might arrest hearing lossprogression. The use of PTA at 2, 3 
and 4 kHz has shown the highest sensitivity and specificity amongst the other pure tone 
averages [65].  
Otoacoustic Emissions (OAEs) are an important technological advance in audiological 
assessment.OAEs are sounds produced by the cochlea, specifically the outer hair cells 
(OHCs), and measured in the outer ear canal. Transient Otoacoustic Emissions (TEOAEs)are 
evoked responses from stimulating the cochlea with a transient signal such as a click or tone 
burst acoustic signal. TEOAEs are a wide frequency response in 500 to 5000 Hz 
range.Distortion Products (DPOAEs) are evoked response OAEs from stimulating the cochlea 
with two simultaneously presented pure tones of different frequency. This type of OAE can 
be recorded in individuals with a more severe hearing loss, at higher frequencies with more 
frequency specificity. DPOAEs are obtainable in the frequency range of 500 to 8000 Hz. 
They typically do not occur in hearing losses greater than 30 dB.The production of OAEs by 
the OHCs of the cochlea is due to the cochlear active processes. In case of OHCs damage 
producing a mild hearing loss, OAEs are not present. 
OAE testing is twice as sensitive as audiometry to detect a change in hearing threshold 
level and could improve monitoring for noise-induced hearing loss in the workplace [66]. 
Furthermore, OAEs indicate noise-induced changes in the inner ear undetected by 
audiometric tests [67].More studies are needed to show whether OAE testing can replace 
standard audiometry or whether the two techniques have complementary roles. 
 
 
NON AUDITORY EFFECTS OF NOISE EXPOSURE 
 
Occupational and environmental noise exposure may have important non-auditory 
effects, eventually independent or associated to hearing loss. Such effects can be manifold, 
bothersome and, sometimes, serious. 

Giampietro Ricci, Egisto Molini, Mario Faralli et al. 
 
980
Among them, tinnitus is one of the most frequent and annoying. It can have low intensity 
or can be extremely severe, thus causing distress, depression and sleep discomfort [68,69]. 
Environmental or occupational exposure to noise can have effects on the cardiovascular 
system, causing tachycardia and high systolic and diastolic blood pressure, in addition to 
other risk factors such as blood lipid concentration, blood viscosity and blood glucose 
concentration 
[70-74].Chang 
et 
al. 
(2013) 
[75], 
found 
that 
high 
noise 
exposure (≥85 dBA) increased systolic pressure by 3.2 mm Hg and diastolic pressure by 2.5 
mm Hg. Such conditions can increase the risk of severe events such as myocardial infarction 
and stroke (Basner et al., 2014). Potential mechanisms are emotional stress reactions with 
release of catecholamines and glucocorticoids (indirect pathway) and non-conscious 
physiological stress from interactions between the central auditory system and other regions 
of the CNS (direct pathway) [76-78]. 
In 2009, WHO published the Night Noise Guidelines for Europe, an expert consensus 
that mapped four noise exposure groups to negative health outcomes ranging from no 
biological effects to increased risk of cardiovascular disease (below 30 dBaeq,night,outside; 30-40 
dB; 40-55 dB; above 55 dBaeq,night,outside: in this group the situation is considered increasingly 
dangerous for public health [76]. 
Exposure to loud noise has been linked to adverse psychological and social effects. It can 
cause anxiety, depression, annoyance, sleeplessness [79]. Particularly, sleep disturbances are 
thought to be one the most deleterious non-auditory effect of environmental noise exposure, 
since a sufficient undisturbed sleep is considered necessary for a good quality of life [80]. The 
effects of environmental noise exposure depend not only on the acoustical properties of the 
sound [76] but also on the momentary sleep stage [81] and individual noise susceptibility 
[82]. Elderly people, children, shift-workers and people with a pre-existing sleep disorder are 
thought to be the major risk groups for noise induced sleep disturbance [76-78]. 
Other authors reported negative effects of chronic noise exposure on memory (IEH, 
1996) [83], decision-making ability [84] and after-work irritability [85]. Many studies 
demonstrated environmental noise exposure has a negative effect on children’s learning 
outcomes and cognitive performance [86]. Postulated mechanisms for these effects are 
communication difficulties, impaired attention, increased arousal, learned helplessness, 
frustration, noise annoyance and consequences of sleep-disorders [76]. 
Recently, Sorensen et al. (2014) [87] have shown a relation between exposure to traffic 
noise and post-menopausal breast cancer, while some other authors have demonstrated the 
association between noise exposure and obesity [88,89]. 
Many of these conditions seem to be associated with a higher frequency of workplace 
[90,91]. In conclusion, the consequences of chronic noise exposure have a significant social 
cost, since they are associated with a high frequency of working days loss and reduced 
productivity [92, 93]. 
According to the WHO, more than one million healthy life years (disability adjusted life 
years, DALY) are lost annually in the European Union because of community noise exposure. 
Noise-induced sleep disturbance is responsible for about 900.000 DALYs, annoyance for 
650.000, ischemic heart disease for 65.000 and children’s cognitive impairment for 45.000 
DALYs [94]. 
 
 

Occupational Hearing Loss 
 
981
INNER EAR PROTECTION FROM NOISE 
 
Occupational NIHL is permanent. At the moment, no effective treatment to regenerate 
damaged sensory receptors after noise exposure has been reported, leaving amplification as 
the only option. However, the risk of NIHL can be greatly minimized if noise is reduced to 
below 80 dB(A) [95].  
The maximum daily occupational noise exposure level at an eight-hour equivalent 
continuous A-weighted sound pressure level is 85 dB(A). The preferred solution to excessive 
noise exposure is to completely eliminate the source of loud noise. When this is not possible 
or practical, the legal requirement is to minimise exposure through a hierarchy of controls: 
substitute the noise source with quieter machinery or processes, isolate the noise source from 
workers, apply engineering solutions and install noise guards or enclosures, apply 
administrative solutions, provide signs and quiet areas for breaks, and when none of the above 
are reasonably practicable, provide personal hearing protectors (e.g., ear muffs and plugs). 
The high rate of occupational NIHL casts doubts upon the effectiveness of prevention 
programs or people’s compliance to them. The average hearing loss prevention programs 
show the poor effectiveness of non-pharmaceutical interventions for preventing occupational 
noise exposure and occupational NIHL and do not reduce the risk of hearing loss to below a 
level at least equivalent to that of workers who are exposed to 85 dB(A) [96]. 
There are two therapeutic strategies to reduce cochlear damage in NIHL: inhibit 
pathways that lead to the damage of HCs and enhance processes that enable HCs survival. 
Antioxidants protect HCs and hearing from noise induced noise [97-100].  
The antioxidant N-acetyl cysteine (NAC) in military trainees showed some degree of 
protection [101] in contrast to other studies, where no protective effect of NAC was found 
during stapes surgery [102] and on TTS induced by loud music [103].  
Reduction of inflammation also has the potential to protect against NIHL: steroid 
dexamethasone, delivered to the round window membrane, has also been shown to reduce 
hearing loss after noise [104]. The patients suffering from recently NIHL receiving 
intratympanic treatment showed significantly more improvement in thresholds than patients 
receiving systemic steroid alone [105]. Delivery to the inner ear across the round window 
membrane into the perilymph provides the possibility to utilize a wider variety of potential 
therapies for inner ear protection from noise. 
 
 
REFERENCES 
 
[1] 
Pederson, O.J. (1989). Noise and people. Noise Contr Engin J, 32(2), 73–78. 
[2] 
Roeser, R.J., Buckley, K. A. & Stickney, G.S. (2000). Pure tone tests. In: Roeser, R.J., 
Valente, M. and Hosford-Dunn, H. (Eds.). Audiology diagnosis. New York: Thieme 
Medical Publishers. 
[3] 
Gates, G. A. & Hoffman, H.J. (2008). What the numbers mean: an epidemiological 
perspective on hearing. www.nidcd.nih.gov/health/statistics/measuring.htm. 
[4] 
John, A.B., Kreisman, B. M. & Pallett, S. (2012). Validity of hearing impairment 
calculation methods for prediction of self-reported hearing handicap. Noise & Health, 
14, 13–20. 

Giampietro Ricci, Egisto Molini, Mario Faralli et al. 
 
982
[5] 
Occupational noise: assessing the burden of disease from work-related hearing 
impairment at national and local levels. World Health Organization, Series Number 9, 
Geneva 2004. 
[6] 
Tak, S. & Calvert, G.M. (2008). Hearing Difficulty Attributable to Employment by 
Industry and Occupation: An Analysis of the National Health Interview Survey—
United States, 1997 to 2003. J Occup Environ Med, 50(1), 46-56. 
[7] 
Morata, T.C. (2003). Chemical Exposure as a Risk Factor for Hearing Loss. J Occup 
Environ Med, 45(7), 676-682. 
[8] 
Henderson, D., Bielefeld, E.C., Harris, K. C. & Hu, B.H. (2006). The role of oxidative 
stress in noise-induced hearing loss. Ear Hear, 27(1), 1-19. 
[9] 
Fubini, B. & Hubbard, A. (2003). Reactive oxygen species (ROS) and reactive nitrogen 
species (RNS) generation by silica in inflammation and fibrosis. Free Radic Biol Med, 
34, 1507–1516. 
[10] Martinez, M. C. &Andriantsitohaina, R. (2009).Reactive nitrogen species: molecular 
mechanisms and potential significance in health and disease. Antioxid Redox Signal, 
11(3), 669–702. 
[11] Sies, H. (1997). Oxidative stress: oxidants and antioxidants. Exp Physiol, 82, 291–295. 
[12] Dröge, W. (2002). Free radicals in the physiological control of cell function. Physiol 
Rev, 82, 47-95. 
[13] Yamane, H., Nakai, Y., Takayama, M., Iguchi, H., Nakagawa, T. &Kojima, A. 
(1995).Appearance of free radicals in the Guinea pig inner ear after noise-induced 
acoustic trauma. Eur Arch Otorhinolaryngol, 252(8), 504-508. 
[14] Choung, Y.H., Taura, A., Pak, K., Choi, S. J., Masuda, M. & Ryan, A.F.(2009). 
Generation of highly-reactive oxygen species is closely related to hair cell damage in 
rat organ of Corti treated with gentamicin. Neurosci, 161(1), 214-226. 
[15] Yamashita, D., Jiang, H.Y., Schacht, J. & Miller, J.M.(2004). Delayed production of 
free radicals following noise exposure. Brain Res, 1019(1-2), 201-209. 
[16] Vernon, P. J. & Tang, D. (2013).Eat-me: autophagy, phagocytosis, and reactive oxygen 
species signaling. Antioxid Redox Signal,18(6), 677–691. 
[17] Wang, C. W. & Klionsky, D.J. (2003). The molecular mechanism of autophagy. Mol 
Med, 9(3-4), 65–76. 
[18] Yuan, H., Wang, X., Hill, K., Chen, J.,Lemasters, J., Yang, S. M. & Sha, S.H. (2015). 
Autophagy Attenuates Noise-Induced Hearing Loss by Reducing Oxidative Stress. 
Antioxid Redox Signal., 22(15), 1308–1324. 
[19] Wakabayashi, K., Fujioka, M., Kanzaki, S., Okano, H.J., Shibata, S., Yamashita, D., 
Masuda, M., Mihara, M., Ohsugi, Y., Ogawa, K. & Okano, H. (2010). Blockade 
ofinterleukin-6 signaling suppressed cochlear inflammatory response and improved 
hearing impairment in noise-damaged mice cochlea. Neurosci Res, 66(4), 345-35. 
[20] Keithley, E. M., Wang, X. &Barkdull, G.C. (2008).Tumor necrosis factor alpha can 
induce recruitment of inflammat ory cells to the cochlea. OtolNeurotol, 29(6), 854-859. 

Occupational Hearing Loss 
 
983
[21] Tan, W.J., Thorne, P. R. & Vlajkovic, S.M. (2016). Characterization of cochlear 
inflammation in mice following acute and chronic noise exposure. Histochem Cell Biol, 
146(2), 219-230. 
[22] Batandier, C., Leverve, X. & Fontaine, E. (2004). Opening of the mitochondrial 
permeability transition pore induces reactive oxygen species production at the level of 
the respiratory chain complex I. J Biol Chem, 279(17), 17197-17204. 
[23] Maeda, Y., Fukushima, K., Omichi, R., Kariya, S. & Nishizaki, K. (2013). Time 
courses of changes in phospho- and total- MAP kinases in the cochlea after intense 
noise exposure. PLoS One, 8(3), e58775. 
[24] Berliocchi, L., Bano, D. & Nicotera, P. (2005).Ca2+ signals and death programmes in 
neurons. Philos Trans R SocLond B Biol Sci, 360(1464), 2255–2258. 
[25] Pujol, R., Puel, J. L., d’Aldin, C. & Eybalin, M. (1990). Physiopathology of the 
glutamatergic synapses in the cochlea. Acta Oto-Laryngol, 113, 330–334. 
[26] Zenner, H. (1986). K+-induced motility and depolarization of cochlear hair cells. 
Direct evidence for a new pathophysiological mechanism in Meniere’s disease. Arch 
Otorhinolaryngol, 243(2), 108–111. 
[27] Sendowski, I. (2006). Magnesium therapy in acoustic trauma. Magnes Res, 19(4), 244-
254. 
[28] Miller, J.M., Brown, J. N. & Schacht, J. (2003). 8-iso- prostagladin F(2alpha), a 
product noise of exposure, reduces inner ear blood flow. AudiolNeurootol, 8(4), 207–
221. 
[29] Kurabi, A., Keithley, E. M., Housley, G.D., Ryan, A. F. & Wong, A.C. (2017). Cellular 
mechanisms of noise-induced hearing loss. Hearing Research, 349, 129-137. 
[30] Hu, B.H., Guo, W., Wang, P. Y., Henderson, D. & Jiang, S.C. (2000). Intense noise-
induced apoptosis in hair cells of Guinea pig cochleae. Acta Otolaryngol, 120(1), 19-
24. 
[31] Hu, B. H., Henderson, D. & Nicotera, T.M. (2002a). F-actin cleavage in apoptotic outer 
hair cells in chinchilla cochleas exposed to intense noise. Hear Res, 172, 1-9. 
[32] Hu, B. H., Henderson, D. & Nicotera, T.M. (2002b). Involvement of apoptosis in 
progression of cochlear lesion following exposure to intense noise. Hear Res, 166, 62-
71. 
[33] Wang, X., Truong, T., Billings, P.B., Harris, J. P. & Keithley, E.M. (2003). Blockage 
of immune-mediated inner ear damage by etanercept. Oto lNeurotol, 24, 52-57. 
[34] Nicotera, T., Hu, B. & Henderson, D. (2004). The caspase pathway in noise-induced 
apoptosis of the chinchilla cochlea. JARO, 4, 466-477. 
[35] Yang, W.P., Henderson, D., Hu, B. H. & Nicotera, T.M. (2004). Quantitative analysis 
of apoptotic and necrotic outer hair cells after exposure to different levels of continuous 
noise. Hear Res, 196, 69-76. 
[36] Hu, B. H., Henderson, D. & Nicotera, T.M. (2006). Extremely rapid induction of outer 
hair cell apoptosis in the chinchilla cochlea following exposure to impulse noise. Hear 
Res, 211, 16-25. 

Giampietro Ricci, Egisto Molini, Mario Faralli et al. 
 
984
[37] Fujioka, M., Kanzaki, S., Okano, H.J., Masuda, M., Ogawa, K. & Okano, H. 
(2006).Proinflammatory cytokines expression in noise-induced damaged cochlea. J 
Neurosci Res, 83, 575-583. 
[38] Tornabene, S.V., Sato, K., Pham, L., Billings, P. &Keithley, E.M. (2006). Immune cell 
recruitment following acoustic trauma. Hear Res, 222, 115-124. 
[39] Zheng, H. W., Chen, J. & Sha, S.H. (2014). Receptor-interacting protein kinases 
modulate noise-induced sensory hair cell death. Cell Death Dis, 29(5), 1262. 
[40] Jacono, A.A., Hu, B., Kopke, R.D., Henderson, D., Van De Water, T. R. & Steinman, 
H.M. (1998). Changes in cochlear antioxidant enzyme activity after sound conditioning 
and noise exposure in the chinchilla. Hear Res, 117, 31-38. 
[41] McFadden, S.L., Ding, D., Reaume, A.G., Flood, D. G. & Salvi, R.J. (1999). Age-
related cochlear hair cell loss is enhanced in mice lacking copper/zinc superoxide 
dismutase. Neurobiol Aging, 20, 1-8. 
[42] Fetoni, A.R., De Bartolo, P., Eramo, S.L., Rolesi, R., Paciello, F., Bergamini, C., Fato, 
R., Paludetti, G., Petrosini, L. & Troiani, D. (2013).Noise-induced hearing loss (NIHL) 
as a target of oxidative stress-mediated damage: cochlear and cortical responses after 
an increase in antioxidant defense. J Neurosci, 33, 4011-4023. 
[43] Sha, S. H., Taylor, R., Forge, A. & Schacht, J. (2001). Differential vulnerability of 
basal and apical hair cells is based on intrinsic susceptibility to free radicals. Hear Res, 
155, 1-8. 
[44] McBride, D. I. & Williams, S. (2001). Audiometric notch as a sign of noise induced 
hearing loss. Occup Environ Med, 58, 46–51. 
[45] U.S. Department of Health and Human Services.Criteria for a Recommended 
Standard: Occupational Noise Exposure. Publication No. 98–126, 36-60. Cincinnati, 
1998. 
[46] Haynes, D. S., Rutka, J., Hawke, M. & Roland, P.S. (2007). Ototoxicity of ototopical 
drops – an update. Otolaryngol Clin North Am, 40(3), 669-683. 
[47] Cannizzaro, E., Cannizzaro, C., Plescia, F., Martines, F., Sole, L., Pira, E. & Lo Coco, 
D. (2014).Exposure to ototoxic agents and hearing loss: A review of current 
knowledge. Hearing, Balance and Communication,12, 166-175. 
[48] Vona, B. &Haaf, T. (2016). Genetics of deafness. In: Monographs in Human Genetics. 
Karger, Basel, Switzerland. 
[49] Martines, F., Salvago, P., Bartolotta, C., Cocuzza, S., Fabiano, C., Ferrara, S., La 
Mattina, E., Mucia, M., Sammarco, P., Sireci, F. & Martines, E. (2015).A genotype–
phenotype correlation in Sicilian patients with GJB2 biallelic mutations. Eur Arch 
Otorhinolaryngol, 272(8), 1857-1865. 
[50] Bartolotta, C., Salvago, P., Cocuzza, S., Fabiano, C., Sammarco, P. & Martines, F. 
(2014).Identification of D179H, a novel missense GJB2 mutation in a Western Sicily 
family. European Archives of Oto-Rhino-Laryngology, 271 (6), pp. 1457-1461. 
[51] Salvago, P., Martines, E., La Mattina, E., Mucia, M., Sammarco, P., Sireci, F. & 
Martines, F. (2014).Distribution and phenotype of GJB2 mutations in 102 Sicilian 

Occupational Hearing Loss 
 
985
patients with congenital non syndromic sensorineural hearing loss. International 
Journal of Audiology, 53 (8), pp. 558-563. 
[52] Furutate, S., Iwasaki, S., Nishio, S. Y., Moteki, H. & Usami, S. (2011).Clinical profile 
of hearing loss in children with congenital cytomegalovirus (CMV) infection: CMV 
DNA diagnosis using preserved umbilical cord. Acta Otolaryngol, 131, 976-982. 
[53] Ferrara, S., Salvago, P., Mucia, M., Ferrara, P., Sireci, F. & Martines, F. 
(2014).Follow-up 
after 
pediatricmyringoplasty: 
Outcome 
at 
5 
years. 
Otorinolaringologia, 64, 141-146. 
[54] Rizzo, S., Bentivegna, D., Thomas, E., La Mattina, E., Mucia, M., Salvago, P., Sireci, 
F. & Martines, F. (2016).Sudden sensorineural hearing loss, an invisible male: State of 
art. Hearing loss: etiology, management and societal implications, 75-86. 
[55] Salvago, P., Rizzo, S., Bianco, A. & Martines, F. (2017).Sudden sensorineural hearing 
loss: is there a relationship between routine haematological parameters and audiogram 
shapes? International Journal of Audiology, 56(3), 148-153. 
[56] Dispenza, F., De Stefano, A., Costantino, C., Marchese, D. &Riggio, F. (2013).Sudden 
Sensorineural Hearing Loss: results of intratympanic steroids as salvage treatment. Am 
J Otolaryngol, 34, 296-300. 
[57] Zhang, Q., Liu, H., McGee, J., Walsh, E. J., Soukup, G. A. & He, D. Z. (2013). 
Identifying micro RNAs involved in degeneration of the organ of Corti during age-
related hearing loss. PLoS One, 8, e62786. 
[58] Martines, F., Maira, E. & Ferrara, S. (2011).Age-related hearing impairment (ARHI): 
A common sensory deficit in the elderly. Acta Medica Mediterranea, 27 (1), 47-52. 
[59] Kirchner, D.B., Evenson, E., Dobie, R.A., Rabinowitz, P., Crawford, J., Kopke, R. & 
Hudson, T.W. (2012). Occupational Noise-Induced Hearing Loss: ACOEM Task Force 
on Occupational Hearing Loss. J Occup Environ Med, 54(1), 106-108. 
[60] Dobie, R.A. (2005). Audiometric threshold shift definitions: simulations and 
suggestions. Ear Hear, 26, 62–77. 
[61] Dobie, R.A. (2001). Structure and function of the ear. In: Dobie RA, ed. Medical-Legal 
Evaluation of Hearing Loss. 2nd ed. San Diego. 
[62] Plescia, F., Cannizzaro, C., Brancato, A., Sireci, F., Salvago, P. & Martines, F. 
(2016).Emerging pharmacological treatments of tinnitus. Tinnitus: Epidemiology, 
Causes and Emerging Therapeutic Treatments. Nova Science Publishers, Inc., 43-64. 
[63] Cavallaro, A., Martines, F., Cannizzaro, C., Lavanco, G., Brancato, A., Carollo, G., 
Plescia, F., Salvago, P., Cannizzaro, E., Mucia, M., Rizzo, S., Martini, A. &Plescia, F. 
(2016).Role of cannabinoids in the treatment of tinnitus. Acta Medica Mediterranea,32, 
463-469. 
[64] Martines, F., Messina, G., Patti, A., Battaglia, G., Bellafiore, M., Messina, A., Rizzo, 
S., Salvago, P., Sireci, F., Traina, M. &Iovane, A. (2015).Effects of tinnitus on postural 
control and stabilization: A pilot study. Acta Medica Mediterranea,31, 907-912. 
[65] Razali, A. &Rampal, K.G. (2012).Validity of various methods of pure tone audiogram 
averaging in diagnosing hearing impairment in a hearing conservation programme. 

Giampietro Ricci, Egisto Molini, Mario Faralli et al. 
 
986
Kulliyah of Medicine, IIUM Kuantan Perdana University, Graduate School of 
Medicine, Kuala Lumpur. GRF One Health Summit, Davos. 
[66] Hall, A. J. & Lutman, M.E. (2000). Methods for early identification of noise-induced 
hearing loss. Audiol, 38(5), 277-280. 
[67] Lapsley Miller, J.A., Marshall, L., Heller, L. M. & Hughes, L.M. (2006). Low-level 
otoacoustic emissions may predict susceptibility to noise-induced hearing loss. J 
Acoust Soc Am, 120(1), 280–296. 
[68] Axelsson, A. & Prasher, D. (2000). Tinnitus induced by occupational and leisure noise. 
Noise and Health, 2(8), 47–54. 
[69] Stormer, C. C. L., Sorlie, T. & Stenklev, N.C. (2017). Tinnitus, Anxiety, Depression 
and Substance Abuse in Rock Musicians a Norwegian Survey.Int Tinnitus J, 21(1), 50-
57. 
[70] Sbihi, H., Davies, H. W. & Demers, P.A. (2008). Hypertension in noise-exposed 
sawmill workers: a cohort study. J Occup Environ Med, 65, 643–646. 
[71] Babisch, W. (2008). Road traffic noise and cardiovascular risk. Noise and Health, 
10(38), 27–33. 
[72] Goyal, S., Gupta, V. & Walia, L. (2010). Effect of noise stress on autonomic function 
tests.Noise Health, 12(48), 182-186.  
[73] Münzel, T., Knorr, M., Schmidt, F., von Bardeleben, S., Gori, T. & Schulz, E. (2016). 
Airborne disease: a case of a Takotsubocardiomyopathie as a consequence of nighttime 
aircraft noise exposure. Eur Heart J, Oct 1, 37(37), 2844. 
[74] Skogstad, M., Johannessen, H.A., Tynes, T., Mehlum, I.S., Nordby, K. C. & Lie, A. 
(2016). Systematic review of the cardiovascular effects of occupational noise. Occup 
Med (Lond), Jan,66(1), 10-16. 
[75] Chang, T.Y., Hwang, B.F., Liu, C.S., Chen, R.Y., Wang, V.S., Bao, B.Y., et al. (2013). 
Occupational noise exposure and incident hypertension in Men: a prospective 
cohortstudy. Am J Epidemiol, 177(8), 818-825. 
[76] Basner, M., Babisch, W., Davis, A., Brink, M., Clark, C., Janssen, S. & Stansfeld, S. 
(2014). Auditory and non-auditoryeffects of noise on health. Lancet, Apr 12, 
383(9925), 1325-1332. 
[77] Ballacchino, A., Salvago, P., Cannizzaro, E., Costanzo, R., Di Marzo, M., Ferrara, S., 
La Mattina, E., Messina, G., Mucia, M., Mulè, A., Plescia, F., Sireci, F., Rizzo, S. & 
Martines, F. (2015).Association between sleep-disordered breathing and hearing 
disorders: Clinical observation in Sicilian patients. Acta Medica Mediterranea, 31(3), 
607-614. 
[78] Martines, F., Ballacchino, A., Sireci, F., Mucia, M., La Mattina, E. & Rizzo, S. 
(2016).Audiologic profile of OSAS and simple snoring patients: the effect of chronic 
nocturnal intermittent hypoxia on auditory function. European Archives of Oto-Rhino-
Laryngology,273, 1419-1424. 
[79] Raffaello, M. &Maass, A. (2002). Chronicexposure to noise in industry: the effects on 
satisfaction, stress, symptoms, and companyattachment. Environ Behav, 34(5), 651–
671. 

Occupational Hearing Loss 
 
987
[80] Fritschi, L., Brown, A.L., Kim, R., Schwela, D. H. & Kephalopoulos, S. (2011). 
Burden of disease from environmental noise. Bonn: World Health Organization. 
[81] Basner, M., Müller, U. &Griefahn, B. (2010). Practical guidance for riskassessment of 
traffic noise effects on sleep, Appl Acoust, 71, 518–522. 
[82] Dang-Vu, T.T., McKinney, S.M., Buxton, O.M., Solet, J. M. &Ellenbogen, J.M. 
(2010). Spontaneousbrainrhythmspredictsleepstability in the face of noise. Curr Biol, 
20, 626–627. 
[83] IEH (Institute for Environment and Health). (1997). The non-auditoryeffects of noise. 
University of Leicester. 
[84] Siegel, J. M. & Steele, C.M. (1980). Environmental distraction and interpersonal 
judgments. Br J Soc Clin Psyc, 19(1), 23–32. 
[85] Melamed, S. & Bruhis, S. (1996). The effects of chronicindustrial noise exposure on 
urinary cortisol, fatigue, and irritability: a controlled field experiment. J Occup Environ 
Med, 38(3), 252-256. 
[86] Evans, G. & Hygge, S. (2007). Noise and performance in adults and children. In: 
Luxon L, Prasher D, editors. Noise and its effects. London:Whurr Publishers. 
[87] SØrensen, M., Ketzel, M., Overvad, K., TjØnneland, A. &Raaschou-Nielsen, O. 
(2014). 
Exposure 
to 
road 
traffic 
and 
railway 
noise 
and 
postmenopausalbreastcancer:acohortstudy, Int J Cancer, 134(11), 2691-2698. 
[88] Eriksson, C., Hilding, A., Pyko, A., Bluhm, G., Pershagen, G. & Östenson, C.G. 
(2014). Long-term aircraft noise exposure and body mass index, waist circumference 
and type 2 diabetes: a prospective study. Environ Health Perspect, 122(7), 687-694. 
[89] Oftedal, B., Krog, N.H., Pyko, A., Eriksson, C., Graff-Iversen, S., Haugen, M., et al. 
(2015). Road traffic noise and markers of obesity – a population-based study, Environ 
Res, 138C, 144-153. 
[90] Léger, D., Guilleminault, C., Bader, G., Lévy, E. &Paillard, M. (2002). Medical and 
socio-professional impact of insomnia. Sleep, 25(6), 621–625. 
[91] Chau, N., Mur, J.M., Benamghar, L., Siegfried, C., Dangelzer, J.L., Français, M., et al. 
(2004). Relationships between certain individual characteristics and occupational 
injuries for various jobs in the construction industry: a case-control study. Am J Ind 
Med, 45(1), 84–92. 
[92] Fried, Y., Melamed, S. & Ben-David, H.A. (2002). The joint effects of noise, job 
complexity, and gender on employee sickness absence: an exploratory study across 21 
organizations—the CORDIS study. J OccupOrganizPsychol, 75(2), 131–44. 
[93] Thomas, E., Martines, F., Bianco, A., Messina, G., Giustino, V., Zangla, D., Iovane, A. 
& Palma, A. (2018).Decreased postural control in people with moderate hearing loss. 
Medicine (Baltimore),97(14), e0244. 
[94] Belojević, G. &Paunović, K. (2016). Recent advances in research on non-auditory 
effects of community noise. Srp Arh Celok Lek, Jan-Feb, 144(1-2), 94-98. 
[95] International Standard Organisation. ISO (1999). Acoustics – Determination of 
occupational noise exposure and estimation of noise-induced hearing impairment. 
Geneva: ISO, 2013. 

Giampietro Ricci, Egisto Molini, Mario Faralli et al. 
 
988
[96] Verbeek, J.H., Kateman, E.,Morata, T.C., Dreschler, W. A. & Mischke, C. (2014). 
Interventions to prevent occupational noise-induced hearing loss: A Cochrane 
systematic review. Int J Audiol, Mar, 53,Suppl 2, S84-96. 
[97] Bielefeld, E.C., Kopke, R.D., Jackson, R.L., Coleman, J. K., Liu, J. & Henderson, D. 
(2007). Noise protection with N-acetyl-l-cysteine (NAC) using a variety of noise 
exposures, NAC doses, and routes of administration. Acta Otolaryngol, 27, 914-919. 
[98] Fetoni, A.R., Mancuso, C., Eramo, S.L., Ralli, M., Piacentini, R., Barone, E., Paludetti, 
G. &Troiani, D.(2010). In vivo protective effect of ferulic acid against noise-induced 
hearing loss in the Guinea-pig. Neurosci, 169, 1575-1588. 
[99] Fetoni, A. R., Eramo, S., Troiani, D. & Paludetti, G. (2011). Therapeutic window for 
ferulic acid protection against noise-induced hearing loss in the Guinea pig. 
ActaOtolaryngol, 131, 419-427. 
[100] Le Prell, C.G., Gagnon, P.M., Bennett, D. C. &Ohlemiller, K.K. (2011). Nutrient-
enhanced diet reduces noise-induced damage to the inner ear and hearing loss. Transl 
Res, 158, 38-53. 
[101] Lindblad, A. C., Rosenhall, U., Olofsson, A. & Hagerman, B. (2011). The efficacy of 
Nacetylcysteine to protect the human cochlea from subclinical hearing loss caused by 
impulse noise: a controlled trial. Noise Health, 13, 392-401. 
[102] Bagger-Sjöbäck, D., Strömback, K., Hakizimana, P., Plue, J., Larsson, C., Hultcrantz, 
M., Papatziamos, G., Smeds, H., Danckwardt-Lillieström, N., Hellström, S., Johansson, 
A., Tideholm, B. & Fridberger, A. (2015). A randomised, double blind trial of NAC for 
hearing protection during stapes surgery. PLoS One, Mar 12, 10(3), e0115657. 
[103] Kramer, S., Dreisbach, L., Lockwood, J., Baldwin, K., Kopke, R., Scranton, S. & 
O’Leary, M. (2006). Efficacy of the antioxidant N-acetylcysteine (NAC) in protecting 
ears exposed to loud music. J Am Acad Audiol,17, 265-278. 
[104] Harrop-Jones, A., Wang, X., Fernandez, R., Dellamary, L., Ryan, A. F., LeBel, C. & 
Piu, F. (2016). The sustained-exposure dexamethasone formulation OTO-104 offers 
effective protection against noise-induced hearing loss. Audiol Neurotol, 21, 12-21. 
[105] Zhou, Y., Zheng, G., Zheng, H., Zhou, R., Zhu, X. & Zhang, Q. (2013). Primary 
observation of early transtympanic steroid injection in patients with delayed treatment 
of noise-induced hearing loss. Audio lNeurootol, 18, 89-94. 
 
 

In: Encyclopedia of Audiology and Hearing Research 
ISBN: 978-1-53617-702-2 
Editors: Erno Larivaara and Senja Korhola 
© 2020 Nova Science Publishers, Inc. 
 
 
 
 
 
 
 
Chapter 65 
 
 
 
SINGLE SIDE DEAFNESS IN CHILDREN 
 
 
Antonio della Volpe, Arianna Di Stadio, Antonietta De Lucia, 
Valentina Ippolito and Vincenzo Pastore 
Otology and Cochlear Implant Unit,  
Santobono-Posilipon Children’s Hospital, Naples, Italy 
 
 
ABSTRACT  
 
The importance of a good hearing function to preserve memory and cognitive 
abilities has been shown in the adult population but studies on the pediatric population 
are currently lacking. To date we have investigated memory and cognition; Memory was 
studied in children affected from Single Side Deafness (SSD) and treated with Bone 
Anchored Hearing Implant (BAHI) while the cognition was studied in a sample of 
children affected from Unilateral Asymmetric Hearing Loss (UAHL) evaluating the 
effect of Adhesive Anchored Prosthesis (AAP). Both studies aimed evaluating the effects 
of BAHI or AAP on speech perception, speech processing, and memory in children with 
SSD or UAHL. We enrolled in the two studies a total of 35 children (25 with SSD and 10 
with AUHL) and assessed them prior to BAHI implantation or AAP use. In the case 
control study (BAHI) children were evaluated at 1-month and 3-month follow-up using 
tests of perception in silence and perception in phonemic confusion, dictation in silence 
and noise, working memory and short-term memory function in conditions of silence and 
noise. We also enrolled end evaluated N = 15 children with normal hearing. In the AUHL 
study, instead, we evaluated speech perception test, dictation test, working memory and 
short-term memory function tests prior to the intervention (no Hearing Aid (NoHeAi)), 
immediately after the intervention (AAPT0), and 1week post-intervention (AAPT1).  
 
Keywords: single side deafness, hearing loss, bilateral hearing 
 
 
In the BAHI study we found a statistically significant difference in performance between 
healthy children and children with Single Side Deafness (SSD) before BAHI implantation in 
the scores of all tests. After 3 months from BAHI implantation, performance of children with 
SSD was comparable to that of healthy subjects in speech perception, working memory and 

Antonio della Volpe, Arianna Di Stadio, Antonietta De Lucia et al. 
 
990
short-term memory function in silence, while differences persisted in the scores of the 
dictation (both in silence and noise condition) and working memory function test in noise 
condition.  
The AAP study showed at AdHeT1 statistically significant improvement compared to 
their pre-intervention baseline (NoHeAi) in speech perception (p = 0.01) and dictation ability 
both in noise (p = 0.03) and silence (p = 0.02) conditions. Scores of the short-term memory 
test (p = 0.01) and of the working memory test in noise (p = 0.01) and silence (p = 0.01) 
conditions were also improved. Similar results were obtained for subjects with mild and 
severe SSHL. At AdHeT0 subjects showed an improvement in the scores of all tests 
compared to NoHeAi, but the changes were not statistically significant. 
Our data suggests that in children with SSD BAHI improves speech perception and 
memory; the AAP might be helpful in the treatment of AUHL for the same reason of BAHI in 
SSD. Speech rehabilitation may be necessary to further improve speech processing both with 
BAHI that with AAP. 
 
 
INTRODUCTION 
 
The importance of recovery of bilateral hearing function is a widely accepted concept in 
the treatment of patients with bilateral deafness[1]; conversely, single side Hearing Loss 
(SSHL) are rarely treated with hearing aids [2], bone anchored hearing aid [3], or cochlear 
implants (CI) [4]. In patients with SSHL, both adult and pediatric, a good unilateral hearing 
function is typically considered acceptable, and the option of using a hearing aid is often 
underexplored. However, bilateral hearing function is not only important for hearing 
correctly, but it is also necessary for identifying origin and direction of sound [5], perceiving 
nuances of music [6], and improving the hearing ability function in noise situations [3, 4]; in 
children, it is key for developing normal auditory pathways [7]. As it has been shown by 
recent studies, bilateral hearing improves quality of life, social life, speech perception [8], and 
memory function [8-11]. While most studies focus on assessing these outcomes in CIs 
recipients [4, 8, 9], the effects of hearing aids and bone anchored systems are rarely studied 
[14]. 
Recently it was demostred on adult population that working memory performances are 
influenced by hearing function [14-16]. Infact it has been shown that hearing impairments 
affect working memory function in subjects who are asked to identify spoken sentences with 
semantic ambiguity [14, 15]. Increased auditory thresholds decrease scores in the Text 
Reception Threshold test [17, 18] which suggests that hearing impairments also ultimately 
affect reading performance. Finally, in a recent study, Saunders et al. showed that 
improvement in hearing via a personal frequency modulation system led to an enhancement 
of word recognition ability in veterans [19]. 
The link between hearing impairment and working memory shown by the 
aforementioned studies is not surprising. In fact, working memory which is part of the short-
term memory and whose main role is managing the information temporarily stored in the 
short-term memory, is composed of four main parts, one of which (phonological loop) is 
specifically dedicated to storing and manipulating verbal information [20]. The phonological 
loop works in synergy with the central executive (an attentional control system), the episodic 

Single Side Deafness in Children 
 
991
buffer [21], and the visuospatial sketchpad (useful for visual and spatial information) for 
ensuring a correct higher-level processing of verbal data, such as word recognition, reading, 
and speech production.  
While current literature on the relationship between hearing abilities, memory and speech 
processing mainly focuses on adults, studies on the pediatric population are lacking. In 
particular, little is known on how hearing abilities affect memory function in children with 
Single Side Deafness (SSD). Understanding this relationship in this population is particularly 
important as both these functions affect learning, and thus potentially academic performances. 
 
 
HOW TO TEST AUDITORY AND MEMORY  
 
The screening tests for children affected from Single Side Deafness (SSD) includes 
auditory test and study on memory functions. 
During each evaluation session, all subjects undergo tests for evaluating speech 
perception, memory (working memory and short-term memory), and dictation performances. 
Speech perception is evaluated by using the Common Evaluation Protocol in Rehabilitative 
Audiology (CEPRA) [22], where we evaluate Perception in silence (PS) and Perception in 
Phonemic Confusion (PPC), also evaluated in silence condition.  
The PS test allows an integrated evaluation of hearing and brain function (working 
memory), while the PPC test allows a mere evaluation of the actual hearing ability (sounds 
perception) [22].  
Working memory and short-term memory are evaluated respectively with the non-sense 
word repetition test and the verbal span test, both from the PROMEA battery of tests [22]. In 
the non-word repetition task, the assessor read aloud a list of forty non-sense words of 
different length. The subject was asked to listen and repeat each word. The total test score 
was calculated as the number of correct words. The verbal span test included six lists of 
words of different frequency of use, length, and level of similarity. Each list was composed of 
seven blocks of word sequences and each block identifies a different span level (from 2 to 8). 
The subject was asked to repeat the sequences read by the assessor maintaining the same 
words order. The span level corresponded to the highest number of words correctly repeated 
in at least three sequences out of five. Working memory tests were performed in silence 
(WMS) and noise (WMN, cocktail party noise) conditions [23, 24]. Short-term memory (SM) 
tests were performed in silence condition. The dictation tests were taken from DDE-2 test 
[23], and tested overall speech recognition ability including hearing function, short term 
memory, working memory, signal integration, and writing skills; they were performed in 
silence (DS) and noise (DN) conditions. The stimuli included non-sense words. In the tasks 
the examiner read 24 non-sense words, one by one. The subject was asked to repeat each 
word aloud and write it down.  
 
 
STUDIES RESULTS 
 
We completed two different study to investigate the effect of bilateral hearing restoration 
on working memory function by using bone adhesive prosthesis (AAP) and bone anchorage 

Antonio della Volpe, Arianna Di Stadio, Antonietta De Lucia et al. 
 
992
hearing implant (BAHI); the first was a cross-sectional pilot study in which we analyzed 
children without and with AAP for evaluating the variance in working memory performance, 
then in the second one we compared the working memory performance between children with 
SSD with and without BAHI and a group homogeneous for age and sex of healthy children. 
In the first study we observed that all children showed an improvement in speech 
perception and dictation, short term and working memory function tests when we compared 
their performance without hearing aids and with AAP. The study analyzed the use of AAP at 
two different times, when children used AAP for a day only and when they used it for a week 
at least. In all cases (single day and one week) children improved their performance.  
We observed that in single day use of AAP, children improved 15% and 32% their 
dictation performance, respectively in silence and noise. The working memory scores were 
better than without hearing aids both in silence (25% of gain) and in noise (40%). The short 
memory notevolly improved when children used AAP (22% of gain). 
After 1 week of constant use of AAP every day, children improved their performances in 
dictation test of 40.3% when they used AAP, specifically they gained a 31% in silence 
condition until a 51% of improved performance in noise.  
We observed that the working memory scores improved by 33% in silence and 58% in 
noise when children used AAP; short term in particular improved 17%. 
In the second study we compared the performance of children with SSD with a healthy 
group, without and with BAHI; we studied as the first study, the speech perception, the 
dictate ability and the working memory.  
Children with SSD presented statistically significant difference when compared with the 
healthy, in all tests when they did not use the BAHI. These differences completely 
disappeared when children used BAHI and in this way the bilateral hearing function was 
restored. 
The only test in which we did not observe equal performance after use of BAHI was the 
dictation, in fact even the children with BAHI really improved their performance when 
compared with themselves with single hearing function, the recovery was not big enough to 
pair with the healthy children. 
 
 
DISCUSSION 
 
The overall results of our studies, showed that a bilateral hearing function is fundamental 
to reach good performance in speech perception, dictate test and working memory function. 
In fact, both patients with AAP and the ones with BAHI really ameliorated their personal 
performance when the prosthesis was applied on the SSD ear, by supporting the idea that also 
in presence of good function of a single ear the bilateral hearing function have to be always 
searched, in fact authors have been shown that in pediatric subjects even a mild loss of 
hearing function can trigger fatigue and ultimately reduce subjects’ academic performance 
[26], as well as reduce intellectual abilities [27]. 
In our first study patients using AAP showed an overall improvement in speech 
perception, dictation, and working memory tests; improvements tended to increase with 
prolonged use (7 days) of the prosthesis. 

Single Side Deafness in Children 
 
993
In the speech perception test, all subjects displayed an improvement with AAP when 
compared with no use of hearing aids. The improvement in this test was, however, smaller 
compared to the improvements in the other tests. 
The dictation was improved also by analyzing performance after 1-day use of AAP even 
obviously the major increasing of the performances was observed after 1 week of AAP use. 
Memory abilities largely improved with use of AAP, both in terms of working memory 
and short-term memory. The working memory, a part of short- memory, is the cognitive 
function involved in manipulating the information temporarily stored in the short-term 
memory. According to the multi-component model of Baddeley and Hitch [20] working 
memory can be divided into the following components: 1) phonological loop, which stores 
and manipulates verbal information; 2) visuospatial sketchpad, useful for visual and spatial 
information; 3) the central executive, that works as an attentional control system, and at least 
4) the episodic buffer. The episodic buffer component stores information from the subsystems 
in a multimodal code and combines it with information from long-term memory into a unitary 
episodic representation [21]. The fact that subjects improved in both memory and dictation 
tests is not surprising, as a short-term and working memory amelioration not only enhances 
the quantity of storable information, but also facilitates data manipulation and translation 
from the phonological to the graphemic code. 
The biggest gain in working memory function was achieved at after 1 week of use of 
AAP when the children were tested in the noise and silence conditions. The improvement in 
silence condition was smaller than the one in noise. After 1 week of AAP use, short term 
memory function was also greatly improved, and displayed a trend in improvement similar to 
the one observed for working memory.  
These results are on line with the several studies that have shown how the bilateral 
hearing function is fundamental for maintaining good memory function [27-29], verbal 
abilities [30, 31, 32], and word recollection performance [33]; all these functions require the 
ability to identify and recall sounds in the voice frequency band [27].  
In our second study, we reinforced the results obtained in the first one, in fact we 
observed a statistically significant difference between children with SSD without BAHI and 
healthy controls, in speech perception, dictate test and working memory function.  
We chose to measure subjects’ performance in speech perception, dictation, and working 
memory function tests as these skills are known to be related.  
When children with SSD used BAHI, they displayed impaired performance compared to 
healthy subjects only in the dictate and working memory tests in noise, all other scores 
instead were similar to those recorded from the control group. 
The comparison between subjects with SSD using BAHI and healthy controls did not 
show a statistically significant difference for speech perception both in silence and in noise, 
indicating that BAHI improves speech perception ability in terms by improving subjects’ 
ability to perceive sound [25, 34].  
The dictation abilities of children with SSD using BAHI, although improved when 
compared to not use of hearing aids, did not reach results statistically significant enough for 
defining a performance that was the same of the healthy. 
We think that this result may be due to a combination of the complexity of the dictation 
test and the relatively short follow-up we used in this study. Multiple abilities are required to 
reach high scores in a dictation test, including good hearing function, concentration, short-

Antonio della Volpe, Arianna Di Stadio, Antonietta De Lucia et al. 
 
994
term memory, and overall confidence of being able to complete the task. Re-acquiring all 
these skills may take time, possibly longer than the 3 months of our observation period [22]. 
We investigated working memory both in silence and noise condition to assess the effect 
of environmental conditions [35]. Children with SSD using BAHI showed performance 
similar to the healthy for working memory in silence and short memory; the gain that they 
have had in working memory performance in noise comparing SSD without BAHI and with 
BAHI, was not big enough to reach the same performance of the healthy. The difference we 
observed in the working memory in noise scores might be due to the fact that BAHI increases 
sound perception; as previously shown by other authors [9-14, 19], this increase can cause 
difficulty in concentration, especially if subjects perceive the noise as meaningful [36]. 
The key role of bilateral hearing function in preserving good memory function [10, 27, 
37-39], verbal abilities [27, 28], and word recollection performance [29] has been shown by a 
number of studies; all these functions require the ability to identify and recall sounds in the 
audible frequency band [35]. Our results show that even children who preserved good 
unilateral hearing function can benefit from the use of BAHI, and that bilateral hearing 
function positively affects memory function [10, 32, 36, 40]. The bilateral hearing function 
gained through BAHI allowed SSD children to achieve speech perception abilities 
comparable to those from healthy subjects in the same age range as well as similar results in 
terms of short-term memory and working memory function in the noise condition. 
Performance in the dictation and working memory tests of children with BAHI might be 
further improved by speech rehabilitation. 
 
 
CONCLUSION 
 
The results of our studies confirm that bilateral hearing function needs to be achieved 
always, even in case of quite satisfactory quality of life with a single  
The effect of bilateral hearing improves not only the speech perception but also superior 
brain function.  
It is known that in case of deafness there is not a re-organization of brain area, in opposite 
to that happen in blindness, but we still don’t know what happens in SSD 
Our results showed that by using AAP of BAHI the performances of children affected by 
SSD become similar to the heathy ones in the same age range. 
In our opinion SSD or asymmetric hearing loss (HL) should be treated with hearing aids, 
in case of SSD and severe form of HL, BAHI is the more appropriate technology. In case of 
mild and mild to severe HL the AAP is the best solution, because is a minimally invasive 
high-performance system.  
Anyway, speech rehabilitation after BAHI implantation or AAP application might help 
fill the gap in performance between subjects with SSD and healthy controls and help the 
former to achieve full recovery of complex functions such as those required by the dictation 
and working memory tests in noise condition. 
 
 
 

Single Side Deafness in Children 
 
995
REFERENCES 
 
[1] 
Martines, F., Maira, E. & Ferrara, S. (2011). Age-related hearing impairment (ARHI): 
A common sensory deficit in the elderly. Acta Medica Mediterranea, 27 (1), 47-52. 
[2] 
James, R. & Dornhoffer, John L. Dornhoffer. (2016). Pediatric unilateral sensorineural 
hearing loss. Current Opinion in Otolaryngology & Head and Neck Surgery, 24, 6, 
pages 522-528. 
[3] 
Monini, S., Musy, I., Filippi, C., Atturo, F. & Barbara, M. (2015). Bone conductive 
implants in single-sided deafness. Acta Otolaryngol., Apr, 135(4), 381-8. 
[4] 
Arndt, S., Aschendorff, A., Laszig, R., Beck, R., Schild, C., Kroeger, S., Ihorst, G. & 
Wesarg, T. (2011). Comparison of pseudobinaural hearing to real binaural hearing 
rehabilitation after cochlear implantation in patients with unilateral deafness and 
tinnitus. Otol Neurotol., Jan, 32(1), 39-47. 
[5] 
Seeber, B. U., Baumann, U. & Fastl, H. (2004). Localization ability with bimodal 
hearing aids and bilateral cochlear implants. J Acoust Soc Am., Sep, 116 (3), 1698-709. 
[6] 
Polonenko, M. J., Giannantonio, S., Papsin, B. C., Marsella, P. & Gordon, K. A. 
(2017). Music perception improves in children with bilateral cochlear implants or 
bimodal devices. J Acoust Soc Am., Jun, 141 (6), 4494. 
[7] 
Fallon, J. B., Irvine, D. R. & Shepherd, R. K. (2008). Cochlear implants and 231 brain 
plasticity. Hear Res., Apr, 238(1-2), 110-7. 
[8] 
Nahm, E. A., Liberatos, P., Shi, Q., Lai, E. & Kim, A. H. (2017). Quality of Life after 
Sequential Bilateral Cochlear Implantation. Otolaryngol Head Neck Surg., Feb, 156(2), 
334-340. 
[9] 
van Zon, A., Smulders, Y. E., Stegeman, I., Ramakers, G. G., Kraaijenga, V. J., 
Koenraads, S. P., Zanten, G. A., Rinia, A. B., Stokroos, R. J., Free, R. H., Frijns, J. H., 
Huinck, W. J., Mylanus, E. A., Tange, R. A., Smit, A. L., Thomeer, H. G., Topsakal, 
V. & Grolman, W. (2017). Stable benefits of bilateral over unilateral cochlear 
implantation after two years: A randomized controlled trial. Laryngoscope., May, 
127(5), 1161-1168. 
[10] McCoy, S. L., Tun, P. A., Cox, L. C., Colangelo, M., Stewart, R. A. & Wingfield, A. 
(2005). Hearing loss and perceptual effort: downstream effects on older adults’ 
memory for speech. Q J Exp Psychol A., Jan, 58(1), 22-33. 
[11] Salvago, P., Rizzo, S., Bianco, A. & Martines, F. (2017). Sudden sensorineural hearing 
loss: is there a relationship between routine haematological parameters and audiogram 
shapes? International Journal of Audiology, 56 (3), pp. 148-153. 
[12] Rizzo, S., Bentivegna, D., Thomas, E., La Mattina, E., Mucia, M., Salvago, P., Sireci, 
F. & Martines, F. (2016). Sudden sensorineural hearing loss, an invisible male: State of 
art. Hearing loss: etiology, management and societal implications, 75-86. 
[13] Marsella, P., Scorpecci, A., Cartocci, G., Giannantonio, S., Maglione, A. G., Venuti, I., 
Brizi, A. & Babiloni, F. (2017). EEG activity as an objective measure of cognitive load 
during effortful listening: A study on pediatric subjects with bilateral, asymmetric 

Antonio della Volpe, Arianna Di Stadio, Antonietta De Lucia et al. 
 
996
sensorineural hearing loss. International Journal of Pediatric Otorhinolaryngology, 99, 
pp. 1-7. 
[14] Zeitooni, M., Mäki-Torkko, E. & Stenfelt, S. (2016). Binaural Hearing Ability With 
Bilateral Bone Conduction Stimulation in Subjects With Normal Hearing: Implications 
for Bone Conduction Hearing Aids. Ear Hear. Nov/Dec, 37(6), 690-702. 
[15] Koeritzer, M. A., Rogers, C. S., Van Engen, K. J. & Peelle, J. E. (2018). The Impact of 
Age, Background Noise, Semantic Ambiguity, and Hearing Loss on Recognition 
Memory for Spoken Sentences. J Speech Lang Hear Res., Feb 15, 1-12. doi: 
10.1044/2017_JSLHR-H-17-0077. 
[16] Dispenza, F., Cappello, F., Kulamarva, G. & De Stefano, A. (2013). The discovery of 
the stapes. Acta Otorhinolaryngol Ital., 33(5), 357-359. 
[17] Zekveld, A. A., Pronk, M., Danielsson, H. & Rönnberg, J. (2018). Reading Behind the 
Lines: The Factors Affecting the Text Reception Threshold in Hearing Aid Users. J 
Speech Lang Hear Res., Feb 13, 1-14. doi: 10.1044/2017_JSLHR-H-17-0196. 
[18] Besser, J., Zekveld, A. A., Kramer, S. E., Rönnberg, J. & Festen, J. M. (2012). New 
measures of masked text recognition in relation to speech-in-noise perception and their 
associations with age and cognitive abilities. J Speech Lang Hear Res., Feb, 55(1), 
194-209. doi: 10.1044/1092-4388(2011/11-0008).  
[19] Saunders, G. H., Frederick, M. T., Arnold, M. L., Silverman, S. C., Chisolm, T. H. & 
Myers, P. J. (2018). A Randomized Controlled Trial to Evaluate Approaches to 
Auditory Rehabilitation for Blast-Exposed Veterans with Normal or Near-Normal 
Hearing Who Report Hearing Problems in Difficult Listening Situations. J Am Acad 
Audiol., Jan, 29(1), 44-62. doi: 10.3766/jaaa.16143. 
[20] Baddeley, A. D. (2000). The episodic buffer: A new component of working memory? 
Trends in Cognitive Science, 4, 417-423. 
[21] Baddeley, A. D. & Hitch, G. J. (1974). Working 256 memory. In G. A. Bower (Ed.), 
Recent advances in learning and motivation, (Vol. 8, pp. 47-89). New York: Academic 
Press. 
[22] Schindler, A., Vernero, I. & Aimar, E. (2009). Fisiologia della percezione uditiva. In: 
Allenamento della percezione uditiva nei bambini con impianto cocleare. Metodologie 
Riabilitative in Logopedia, vol 16. Springer, Milano. 
[23] Hutcherson, R. W., Dirks, D. D. & Morgan, D. E. (1979). Evaluation of the speech 
perception in noise (SPIN) test. Otolaryngol Head Neck Surg, Mar-Apr, 87(2), 239-45. 
[24] Sartori, G., Job, R. & Tressoldi, P. E. (2007). DDE-2 Batteria per la Valutazione della 
Dislessia e della Disortografia Evolutiva-2 Giunti O.S. 
[25] Sheffield, B. M. & Zeng, F. G. (2012). The relative phonetic contributions of a 
cochlear implant and residual acoustic hearing to bimodal speech perception. J Acoust 
Soc Am., Jan, 131(1), 518-30.  
[26] Hornsby, B. W., Werfel, K., Camarata, S. & Bess, F. H. (2014). Subjective fatigue in 
children with hearing loss: some preliminary findings. Am J Audiol., Mar, 23(1), 129-
34. doi: 10.1044/10590889 (2013/13-0017). 

Single Side Deafness in Children 
 
997
[27] Rabbitt, P. (1990). Mild hearing loss can cause apparent memory failures which 
increase with age and reduce with IQ. Acta Otolaryngol Suppl., 476, 167-75, discussion 
176. 
[28] McCoy, S. L., Tun, P. A., Cox, L. C., Colangelo, M., Stewart, R. A. & Wingfield, A. 
(2005). Hearing loss and perceptual effort: downstream effects on older adults’ 
memory for speech. Q J Exp PsycholA. Jan, 58(1), 22-33. 
[29] EeLynn, Ng. & Kerry, Lee. (2010). Children’s task performance under stress and non-
stress conditions: A test of the processing efficiency theory Cognition and Emotion, 
Vol. 24, Iss. 7. 
[30] Rezai, M., Lofti, G. & Wiesi, F. (2012). Comparison of Working Memory in Hearing 
Loss and Normal Children. Pajouhan Scientific Journal, North America, 11, dec.  
[31] Wong, C. G. (2017). Hearing Loss and Verbal Memory Assessment in Older Adults 
Wayne State University, ProQuest Dissertations Publishing. 10267327. 
[32] Ballacchino, A., Salvago, P., Cannizzaro, E., Costanzo, R., Di Marzo, M., Ferrara, S., 
La Mattina, E., Messina, G., Mucia, M., Mulè, A., Plescia, F., Sireci, F., Rizzo, S. & 
Martines, F. (2015). Association between sleep-disordered breathing and hearing 
disorders: Clinical observation in Sicilian patients, Acta Medica Mediterranea, 31 (3), 
pp. 607-614. 
[33] Skinner, B. F. (1957). Verbal Behavior. Acton, MA: Copley Publishing Group. 
[34] Roman, S., Nicollas, R. & Triglia, J. M. (2011). Practice guidelines for bone-anchored 
hearing aids in children. Eur Ann Otorhinolaryngol Head Neck Dis., Nov, 128 (5), 253-
8. 
[35] Ng, E. H., Rudner, M., Lunner, T., Pedersen, M. S. & Rönnberg, J. (2013). Effects of 
noise and working memory capacity on memory processing of speech for hearing-aid 
users. Int J Audiol., Jul, 52(7), 433-41. 
[36] Lyxell, B. & Rönnberg, J. (1993). The effects of background noise and working 
memory capacity on speechreading performance. Scand Audiol., 22(2), 67-70. 
[37] Ng, EeLynn. & Kerry, Lee. (2010). Children’s task performance under stress and non-
stress conditions: A test of the processing efficiency theory. Cognition and Emotion, 24 
(7), 1229-1238. 
[38] Dispenza, F., Battaglia, A. M., Salvago, P. & Martines, F. (2018). Determinants of 
failure in the reconstruction of the tympanic membrane: A case-control study. Iranian 
Journal of Otorhinolaryngology, 30 (6), pp. 341-346. 
[39] Dispenza, F., De Stefano, A., Costantino, C., Marchese, D. & Riggio, F. (2013). 
Sudden Sensorineural Hearing Loss: results of intratympanic steroids as salvage 
treatment. Am J Otolaryngol, 34, 296-300. 
[40] Dispenza, F., Mazzucco, W., Bianchini, S., Mazzola, S. & Bennici, E. (2015). 
Management of labyrinthine fistula in chronic otitis with cholesteatoma: case series. 
EuroMediterranean Biomedical Journal, 10(21), 255-261. 
 


In: Encyclopedia of Audiology and Hearing Research 
ISBN: 978-1-53617-702-2 
Editors: Erno Larivaara and Senja Korhola 
© 2020 Nova Science Publishers, Inc. 
 
 
 
 
 
 
 
Chapter 66 
 
 
 
PHARMACOLOGICAL TREATMENT  
OF SENSORINEURAL HEARING LOSS 
 
 
Angela Cavallaro1, Carla Cannizzaro1, MD,  
Francesco Martines2, MD, Gianluca Lavanco3,  
Pietro Salvago2, MD, Fabiana Plescia4, PhD,  
Anna Brancato1, PhD and Fulvio Plescia1,, PhD 
1Department of Sciences for Health Promotion and Mother and Child Care  
“Giuseppe D’Alessandro,” University of Palermo, Palermo, Italy 
2Bio. Ne. C. Department, University of Palermo, Palermo, Italy 
3Department of Biomedical and Biotechnological Sciences, 
University of Catania, Catania, Italy 
4 Dipartimento di Scienze e Tecnologie Biologiche, Chimiche e Farmaceutiche,  
Sezione di Chimica e Tecnologie Farmaceutiche,  
Università degli Studi di Palermo, Palermo, Italy 
 
 
ABSTRACT 
 
Sudden sensorineural hearing loss is a common and alarming symptom of about 360 
million people that suffer from hearing impairment worldwide. The sudden sensorineural 
hearing loss usually arises unilaterally and it is habitually described as greater than 30dB 
hearing reduction, attributable to lesions of the cochlea, cranial nerve VIII, brainstem and 
temporal lobe. There are many factor that promote the onset of this lesions such us 
infections, circulatory diseases, inner ear neoplasia and neurological disorders. This 
pathology is characterized by primary symptoms such as the impairment of the 
comprehension of spoken language and the struggling to listen to music. Subsequently, 
secondary symptoms arise as well as anxiety, inadequate coping with illness and 
psychosomatic disturbances that have a negative impact on patients with a significant 
reduction in the quality of life. Treatment of the sudden sensorineural hearing loss 
remains one of the most problematic issues for contemporary otorhinolaryngology, 
                                                        
 Corresponding Author’s Email: fulvio.plescia@unipa.it. 

Angela Cavallaro, Carla Cannizzaro, Francesco Martines et al. 
 
1000
because of the wide array of the presumed mechanisms that underpin this disorder. 
Although the pharmacological treatment remain even now empirical and the management 
is not standardized in term of medical treatment, duration and route of administration, 
different agents are used. In the past, pharmacological approaches have included antiviral 
agents, vitamin, herbal preparations, carbogen inhalations or magnesium, administered on 
either an inpatient or outpatient procedures. Nowadays, the corticosteroids therapy 
remains the mainstay strategy, but considering the multifaceted aspects of this disorder, 
diuretics, anticoagulants, vasodilatators and fibrinolityc agents have also been tried. In 
this chapter, we will focus mainly on the principal pharmacological approaches of the 
sudden sensorineural hearing loss that will be described and examined in terms of 
mechanism of action and effectiveness. 
 
Keywords: sudden sensorineural hearing loss, glucocorticoids, prostaglandine E1 
 
 
INTRODUCTION 
 
Hearing well is synonymous with living well. A high quality of hearing reflects a fully 
participation in everything that happens around us, in fact, hearing is the sense that receives 
sounds which come from outside the human body, transmitting them, through complex 
mechanisms that originates in the auricle, in the temporal cortex, the area of the brain able to 
receive and decode sounds.  
The correct functioning of the hearing system has a positive effect also at cognitive 
levels; in fact, there is a direct correlation between hearing loss and ability of the brain to 
process information and recall memories. 
Given the importance of corret functioning of the hearing system, appear clear how 
troubled and disabililing could be a total or partial perceptual hearing loss. 
The Sudden Sensorineural Hearing Loss (SSHL), defined by US National Institute for 
Deafness and Communication Disorders (NICDC) as an idiopathic loss of hearing of at least 
30 dB, nearly always unilateral, is one of the most common human ailments and the most 
ordinary complaint of patients evaluated by hearing impairment specialists. It occurs at any 
age making verbal communication and comprehension of spoken language more difficult. 
Usually patients notice that the hearing loss appears instantaneously in the morning even if 
others describe that it rapidly developed over a period of hours or days [1].  
The onset of the symptoms is subjective, but generally it occurs over less than a 72-hour 
period and the severity of the harm also varies from patient to patient [2]. 
SSNHL affect the inner ear and the neural pathways to the auditory cortex. Although the 
pathology predominantly affects adults, children also can be affected [3]. 
The diagnosis of deaf patients is difficult and impose a specify analysis of the primary 
symptoms such as impairment of the localization of sound, the difficulty on comprehension 
of spoken language in a noisy environment, and the enjoyment of music. These symptoms are 
frequently associated with secondary symptoms as anxiety, inadequate coping with illness, 
various types of psychosomatic disturbance, and damage quality of life [4]. Considering the 
multifaceted aspects of the SSNHL, such as patient age, presence of vertigo and/or tinnitus at 
onset, exposure to ototoxic agents, degree of hearing loss, audiometric configuration, time 
between onset of hearing loss, and co-morbidities such as hypertension and diabetes, 
treatments have traditionally been empirical [5-9].  

Pharmacological Treatment of Sensorineural Hearing Loss 
 
1001
Corticosteroids, via systemic and/or intratympanic administration, have been the most 
commonly agents used to treat SSNHL, even if a large array of other drugs, such as antivirals, 
antibiotics, diuretics, vasodilators, osmotic agents, plasma expanders, anticoagulants, mineral 
supplements, and hyperbaric oxygen or carbon dioxide rich gases, among others, have been 
used [10]. 
Although the etiopathology of this disease is still unclear, this chapter aims to understand 
the pathophysiology and the appropriate drug therapies, by answering four simple questions: 
What is Sudden Hearing Loss? What Causes Sudden Hearing Loss? How is Sudden Hearing 
Loss Diagnosed? How is Sudden Hearing Loss Treated? 
 
 
SUDDEN SENSORINEURAL HEARING LOSS:  
INTO THE MEDICAL HISTORY 
 
SSNHL, described as a medical emergency in search of appropriate diagnostic techniques 
and treatments, is generally defined as a rapidly developing hearing loss with a threshold 
reduction of ≥30 dB in at least three contiguous audiometric frequencies [11].  
According to the World Health Organization, about 360 million people suffer from 
hearing impairment worldwide and in the European Union, the number is expected to amount 
to 434,000 people suffering from deafness and 44,000,000 people suffering from hearing 
impairment [12, 13].  
All ages and both sexes are affected, with peak ages ranging between 30 and 60 years 
[14, 15]. According to the otolaryngologist guidelines, SSNHL is a suddenly appearing, 
generally as an unilateral hearing loss of cochlear origin with unknown cause (i.e., 
idiopathic), expressing different degrees of severity, up to complete deafness (anacusis), 
sometimes additionally with vertigo and/or tinnitus [16]. 
The SSNHL etiology remains unknown in the most of patients and the causes can be 
numerous and could be congenital or acquired [Table 1]. Although the list of potential 
etiologies is lengthy, the more substantial evidence seems to support that SSNHL is most 
commonly the result of viral infections, vascular disruption, inner ear problems, such as 
Meniere’s disease, neoplastic, traumatic, metabolic, neurologic and cochlear injuries and also 
autoimmune processes, toxic damage and alcohol use. None of these etiologies has 
undisputed evidence supporting its role in the cause of SSNHL, therefore, these cases remain 
idiopathics [17-19].  
Regarding its pathophysiological, still unclear, three major categories of hearing loss 
could be considered to the differential diagnosis: the impeded sound conduction through the 
external ear, middle ear or both; hearing loss that occurs within the cochlea or the neural 
pathway to the auditory cortex; and eventually a mixed hearing loss, concomitant with a 
conductive loss and sensorineural one [20].  
Generally, SSNHL has a rapid onset, occurring over a 72-hour period, of a subjective 
sensation of hearing impairment in one or both ears. It indicates an abnormalities of the 
cochlea and auditory nerve, with negative impact to the central auditory perception or 
processing. The most frequently used audiometric criterion is a decrease in hearing and since 
premorbid audiometry is generally unavailable, hearing loss is defined as related to the 
opposite ear’s thresholds [21]. 

Angela Cavallaro, Carla Cannizzaro, Francesco Martines et al. 
 
1002
But what should we take account of SSNHL? The majority (96–99%) of sudden hearing 
loss is unilateral [22, 23]. Causes of bilateral sudden hearing loss are due to autoimmune 
diseases, syphilis, especially if rapidly progressive, and it occurs commonly in older patients 
with pre-existing diabetes mellitus and lipid abnormalities. Therefore, it is relevant a full 
medical history. Detailed otolaryngological experiences indicate that prognosis for recovery 
is dependent on other factors, including patient age, degree of hearing loss, audiometric 
configuration, time between onset of hearing loss and treatment, and also presence of vertigo 
or tinnitus at onset [24, 25]. 
 
Table 1. Etiological Factors for Hearing Loss 
 
Infection 
Meningitis (bacterial, fungal), labyrinthitis (bacterial, fungal, viral, parasitic, 
spirochaetal), mumps, measles, chicken pox, syphilis. 
Congenital 
Large vestibular aqueduct, Mondini dysplasia. 
Traumatic 
Head injury (with or without fractures), barotrauma (with or without 
perilymphatic fistula), acoustic trauma, iatrogenic injury. 
Neoplastic processes 
Vestibular schwannoma and metastases of the meningeal temporal bone, 
leukemia, multiple myeloma. 
immunological disease 
Systemic lupus erythematosus, Cogan syndrome, Wegener’s granulomatosis. 
Ototoxic agents 
Medical product, drugs, tissue toxins  
Vascular disease 
Hypertensive crisis, hypotonia, AICA (anterior inferior cerebellar artery 
infarct) infarction. 
Neurological diseases 
Neurofibromatosis type II, multiple sclerosis, focal ischemia pontine. 
Metabolic disorder 
Iron metabolic disorder, renal failure/dialysis. 
 
Tinnitus, defined as an abnormal noise perceived in one or both ears or in the head in 
which a patient has a conscious hearing percept in absence of external sound, is usually 
reported in patients with SSNHL [26-28]. Given the considerable correlation between tinnitus 
and sudden hearing loss, studies have been reported that the incidence seems to be 5-30 per 
100,000 persons per year [29, 30] and accounts for 1% of all sensorineural hearing loss cases 
[31].  
SSNHL commonly occurs in patients aged between 25 and 60 years old, with a peak in 
prevalence for patients between 46 and 49 years old with increasing incidence with age and 
male are equally affected as females [32-34].  
Although SSNHL has a greater impact on adults, it also affects children, but it is very 
rare and its cause is still unclear. It has been reported that 6.6% of patients with SSNHL were 
under 18 years of age, 3.5% under 14 years, and only 1.2% under 9 years [35]. Due to the 
rarity of SSNHL in the pediatric population, research regarding etiology, treatment outcomes 
and prognosis of SSNHL in children is limited. 
 
 
SYMPTOMS: FROM THE MECHANISTIC DAMAGE TO  
THE DISTORTED PERCEPTION 
 
Sound waves are conducted via the external ear and the external auditory canal to the 
tympanic membrane. The mechanical vibrations are transmitted by the ossicles way of the 
middle ear to the cochlear perilymph and endolymph. Thus, all the disturbances that arise 

Pharmacological Treatment of Sensorineural Hearing Loss 
 
1003
along the sound conduction pathway, have a mechanical nature that terms into a hearing loss 
[36].  
People who get a hearing loss, usually refer a reduction in hearing ability, describing the 
feeling that have hair in the auricle or a large wool pad into the ear canal.  
The subsequent hypoacusia has also a perceptive nature, since the inner ear (cochlea, 
acoustic nerve) cannot transmit, through the central acoustic way, the correct nervous impulse 
from sound vibrations [37]. This results in a distorted perception of sounds, impairment of the 
comprehension of spoken language and the struggling to listen to music. In fact, people often 
compensate to the hearing impairment by turning up the volume of the radio or television set, 
or (in unilateral hearing impairment) by turning the healthy ear to the sound sources.  
In addition to a great insecurity among people affected, toward the environment, it is very 
common taking advantage from vision to speech recognition with an increasing reliance on 
lip-reading, in order to prevent the consequent inappropriate answers to misheard questions 
and an excessively loud speaking voice.  
But the simultaneous presence of other symptoms, makes the sudden hearing loss even 
more disabling. In fact, patients often report disorders such as vertigo, tinnitus and buzzing 
and just about to the numerous symptoms reported, experts’ opinions about causes and 
therapies are enough controversial [38]. 
 
 
DIAGNOSTIC MEASURES: THE STATE OF THE MULTIPLE EVIDENCES  
 
SSNHL defined as a rapid onset, occurring over a 72-hour period, of a subjective 
sensation of hearing impairment in one or both ears, has a sensorineural nature and meets 
audiometric criteria. The most frequently used audiometric criterion is a decrease in hearing 
of ≥30 decibels (dB), affecting at least 3 consecutive frequencies. Because premorbid 
audiometry is generally unavailable, hearing loss is defined as related to the opposite ear’s 
thresholds. [39] 
Although patients often underestimate a tangible disease, clinical experiences indicate 
that a range from 32% to 65% of cases of SSNHL may recover spontaneously [40, 41].  
Many of the discoverable causes of SSNHL induce permanent hearing loss due to the 
damage to hair cells or other inner ear structures. Prognosis for recovery depend on a several 
number of factors, in fact, the evaluation usually lay the groundwork for a careful history on 
physical examination, beginning to patient age, presence of vertigo or tinnitus at onset, degree 
of hearing loss and time between onset of hearing loss [5,42]. Moreover, it is essential 
looking for potential infectious causes such as otitis media, systemic diseases and exposure to 
known ototoxic medications. 
Given the decline in hearing, the first step to diagnose the SSNHL, usually requires an 
audiogram. 
Instead, blood studies are usually performed to rule out potential systemic causes (i.e., 
syphilis, Lyme disease, metabolic, autoimmune and circulatory disorders) [43]. Moreover, in 
order to investigate the presence of acoustic neuroma, which is reported to be existent up to 
15% of patients with sudden hearing loss, Magnetic Resonance Imaging of the brain is 
frequently recommended [44].  

Angela Cavallaro, Carla Cannizzaro, Francesco Martines et al. 
 
1004
Considering the large amount of etiological causes, the different and usual procedures, 
required in individual cases, are reported in Table 2. 
 
Table 2. Diagnostic Measures 
 
Otoacoustic emissions (OAE) 
Auditory evoked brainstem potentials (ABR) 
Speech audiometry 
Stapedius reflex measurement 
Functional examination of the cervical spine 
Laboratory tests: blood glucose, CRP, procalcitonin, small blood count, differential blood count, 
creatinine, fibrinogen level 
Serologic testing: borreliosis, syphilis, herpes simplex virus type 1, varicella zoster virus, CMV, HIV. 
MRI: exclusion of a tumor of the cerebello pontine angle 
CT scan: skull, temporal bone, cervical spine 
Electrocochleography: coclear damage, exclusion of hydrops 
Auditory steady state responses (ASSR) 
Tympanoscopy 
 
 
PHARMACOLOGICAL MANAGEMENT:  
GLUCOCORTICOIDS MECHANISMS OF ACTION 
 
Numerous agents have been suggested and used to treat of the SSNHL, in concert with 
alternative approaches (i.e., acoustic, electrical, surgical and radiological strategies). A large 
number of different drugs have been investigated for the treatment of idiopathic SSNHL 
including antiinflammatory agents, antimicrobials, calcium antagonists essential minerals, 
vasodilators, volume expanders, defibrinogenators, diuretics and hyperbaric oxygen [41]. On 
the basis of the etiology of this disorder, still unclear, there are insufficient evidences 
supporting the daily application of antiviral, vasodilatory or antioxidant drugs, together with 
alternative therapeutic methods, which also include vitamins or Ginko Biloba [45, 46].  
The most common approach to treatment of SSHL is with glucocorticoids (GC), which 
are considered, around the world, to be the gold standard of therapy, because it is thought the 
disorder might be due to an infectious/inflammatory or autoimmune process [4, 47]. GC act 
on almost all organs, mainly carrying out their effects through a DNA-mediated induction of 
protein biosynthesis after transformation of an intracellular GC receptor (GCR). In the 
cytoplasm, the non-active receptor is present in a complex with chaperones. The GC-activated 
GCR undergoes an initial conformation change, resulting in the dissociation of the 
chaperone–GCR complex. In this way the GC–GCR complex is activated and can translocate 
to the nucleus where it dimerizes. As a homodimer, it can bind to the DNA regulatory 
sequences, called GC response elements (GRE) and found in the promoter regions of 
glucocorticoid-regulated genes. If the GC–GCR complex binding leads to gene activation, the 
GRE sequence termed as ‘positive’ GRE. Negative GRE is also described where GC–GCR 
leads to gene suppression (direct repression) [48, 49]. GCs action includes their influence 
(direct or indirect) on the human genoma (DNA within the nucleus) transcription and 
translation, for many genes encoding inflammatory mediators. Its actions become evident 
within 1 to 2 hours and the cytoplasmatic effects, mostly at very high doses, occur after only a 

Pharmacological Treatment of Sensorineural Hearing Loss 
 
1005
few minutes [50]. Each cell contains 2 classes of GCR, type I (glucocorticoid) and type II 
(mineralocorticoid), both of which are present in the cochlear and vestibular tissues of 
mammals [51, 52]. The activation of cytoplasmatic GCR lead to the triggering of 
transcription processes and also the expression of specific genes, that inhibit the synthesis of 
inflammatory mediators and cytokines, which are responsible for the anti-inflammatory 
effects of GC. GC also affect carbohydrate and protein metabolism and change the 
physicochemical characteristics of cell membranes, promoting their stabilization and reducing 
the permeability of cations (cytoplasmic effect). Finally, they are able to regulate cellular 
osmolarity through the binding of type II mineralocorticoid receptors, which activate the 
enzyme Na,K-ATPase [53]. This enzyme is found at the base of the external and internal hair 
cells, the tympanic nerve fibers and the spiral ganglion cells of mammals [54, 55]. The 
activation of Na, K-ATPase by GC could have positive effects on unbalanced intracellular 
and extracellular osmolarity, electrochemical gradients and neuronal activities, which are 
disturbed by noise-related cellular, functional cochlear damage and autoimmune inner ear 
disease [56, 57]. It is interesting that GC, despite their conventional effects at physiological 
concentrations, have various therapeutic application at higher doses, through different 
mechanisms: immunosuppressive effects (inhibition of the activation of T lymphocytes), anti-
inflammatory (trough blockade of proinflammatory mediators), antiproliferative effect 
(through suppression of collagen synthesis and fibroblast formation) and immunosuppressive 
one (through the inhibition of the activation of T lymphocytes) [58]. The use of GC is 
justified by the fact that steroids are able to reduce inflammation and edema in the inner ear, 
typical in the idiopathic, SSNHL. Despite the numerous clinical trials, the value of steroids in 
the treatment of SSNHL remains unclear, but the administration of high-doses of 
corticosteroids is recommended and primary performed in clinical routine practice [59, 60].  
 
 
PHARMACOLOGICAL MANAGEMENT: ORAL AND INTRATYMPANIC 
CORTICOSTEROID THERAPY 
 
Oral/systemic corticosteroid administration is the most frequent primary pharmacological 
treatment and is widely considered most efficacious for its ability to reduce the inflammation 
and the edema in the inner ear [10]. Although, there aren't many data to support this 
recommendation, in fact, different studies showed that oral steroids administration, such as 
methylprednisolone or dexamethasone, administered over a period of 10 to 12 days, was able 
to induce a significant higher rates of improvement among patients [61]. The efficacy of 
systemic corticosteroid treatment seems directly related to the time between the onset of the 
disease and the start of the pharmacological treatment [62]. Studies taking into account the 
relationship between the duration of SSNHL before pharmacological therapy and outcomes 
have reported the greatest recovery of hearing when corticosteroids were given within the 
first one to two week after symptom onset, and little if any when initiated four weeks or 
longer after the onset of the symptoms [63-65].  
Some clinical studies evaluated the effects of oral corticosteroids vs oral placebo for the 
treatment of SHHL [65]. Wilson et al., [61] showed that dexamethasone (0.75 mg twice daily 
to 4.5 mg twice daily) or metylprednisolone (4 mg/d to 16 mg three times daily) have the 
same anti-inflammatory effects. In particular, these clinical research showed that 

Angela Cavallaro, Carla Cannizzaro, Francesco Martines et al. 
 
1006
corticosteroids was able to reduce the pure-tone average, measured at four and three months 
after the onset of SSNHL, thus bringing to a greater rate of recovery in patients treated with 
steroids than to placebo control group [61]. In contrast with these studies, randomized 
controlled studies conducted by Nostrati-Zerenoe and Cinamon have failed to demonstrate a 
beneficial effect of systemic steroids administration [66, 67]. In particular, Cinamon and 
collegues have find that prednisone (1mg/kg daily) was not able to reduce the pure-tone 
average scores, speech frequency, high tone hearing levels, and discrimination scores at 6 
days and 14 to 90 days (follow-up) after treatment. 
These reports together with the side effects induced by corticosteroid administration 
(mood changes, elevated blood pressure and sugar levels, loss of appetite, weight gain, 
gastritis, sleep disorders and hyperglycemia) ensure that oral therapy is to be considered 
carefully, in particular in patients with other chronic diseases such as sleep disorders or 
diabetes mellitus.  
In alternative of oral corticosteroids, some otolaryngologists recommend local 
corticosteroid therapy for SSNHL. This treatment is based on the local glucocorticoid 
injection, directly into the ear in order to reduce the risk of systemic side effects, typical of 
oral administration, allowing glucocorticoids to penetrate directly into the cochlea and 
achieve a high concentration there even when low doses are used [65-69]. This procedure 
consists in the administration of methylprednisolone, dexamethasone and prednisolone, drugs 
able to affect the immune suppression and the ion homeostasis [70], by intratympanic or as 
eardrops by means of ventilating tube or a ‘wick’ running from a ventilating tube to the round 
window membrane in the medial wall of the middle ears. In this way, corticosteroids are 
available in high concentrations in the target tissue, promoting a reduction of inflammation 
associated with labyrinthitis, an enhancement in cochlear blood flow and improving 
striavascularis functions.  
During the last years, different researches have taken into account the use of 
intratympanic steroid as the primary treatment of idiopathic SSNHL. Two multicenter studies, 
conducted by Battaglia et al., [71, 72], have found that association between intratympanic 
dexamethasone (12 and 10 mg/ml) and hight-dose oral prednisone resulted in a significant 
improvement of hearing, respect to the treatment with oral prednisone alone.  
Two reports about the efficacy of local corticosteroid therapy showed that the association 
between 5 mg/ml dexamethasone with i.v steroid are able to induce an improvement of the 
hearing functions in patients affected by SSNHL [73, 74]. These studies, taking together, 
demonstrated that a combined therapy was more effective for SSNHL in achieving hearing 
gain than corticosteroids alone. Furthermore, when administered alone as primary therapy, 
intratympanic steroids have been shown to be as effective as systemic steroids. An elegant 
research conducted by Rauche and collegues [75] showed that metylprednisolone (40 mg/ml) 
was able to improve the pure tone average when compared to oral corticosteroid treatment, 
rejecting the hypothesis of the inferiority of intratympanic administration with respect oral 
prednisolone. In conclusion intratympanic injection may be an alternative method, 
particularly for patients who have high riskes of complications, due to the oral therapy, 
although the evidences supporting this strategy is even more limited.  
 
 

Pharmacological Treatment of Sensorineural Hearing Loss 
 
1007
PHARMACOLOGICAL MANAGEMENT: VASODILATORS AGENTS 
 
The speculation about the pathogenesis of the SSNHL lead to the investigation of several 
other pharmacological agents to treat this disorder. 
The hypothesis about the involvement of microvascular dysfunction in the cochlea as 
major cause of idiopathic SSNHL, different vasodilators and blood thinners are widely 
suggested as agents able to increase the caliber and blood flow in vessels, in order to rule out 
the problem. 
A research by Zhuo and colleague [76] pointed out the attention on the role played by the 
Prostaglandine E1 (PGE1), a prostanoid with vasodilator properties, in the treatment of 
SSNHL. In this study the author showed that PGE1 might be beneficial, probably due to its 
ability to increase cardiac output, improving cochlear blood flow [77]. Although this study 
appeared to be favorable to the use of PGE1, a prospective, double blind, randomized 
controlled study, showed that either PGE1 or placebo, used in addition to a steroid in each 
experimental condition, do not have a beneficial effect on the treatment of idiopathic SSNHL 
[78].  
Moreover, in order to enhance the microcirculation, other compounds with cerebral 
vasodilator activity have been studied. A prospective, single blind, randomized controlled 
study investigated the efficacy of carbogen, a gaseous mixture of 5% carbon dioxide and 95% 
oxygen, known for its ability to increasing the partial oxygen pressure of perilinfatic fluids, 
on idiopathic SSNHL. This study showed that carbogen treatment was able to increase the 
hearing ability with respect to control group [79].  
 
 
CONCLUSION 
 
Despite specialists are unanimous about the identification of the typical symptoms of the 
SSNHL, the research and the evaluation of the main causes that trigger this auditory disability 
are characterized by contrasting opinions. Nevertheless, different pharmacological treatment 
are known and have been engaged to ameliorate the idiopathic SSNHL. Treatment regimens 
have included minerals, essential minerals, antimicrobials, vitamin, antiviral and diuretics 
agents, in addition to herbal preparations. Although initially promising results are found in 
different case reports and small trials, surprisingly there is a little persuasive evidence that 
supports the efficacy of these pharmacological agents in alleviating the simptomatologycal 
conditions that afflict patients with SSNHL. Among all the different therapies, corticosteroids 
appear the prominent current standard care to improve or restore hearing.  
 
 
REFERENCES 
 
[1] 
O’Connell, B. P., Hunter, J. B., Haynes, D. S. (2016) Current concepts in the 
management of idiopathic sudden sensor neuronal hearing loss. Curr Opin Otolaryngol 
Head Neck Surg, 24:413–419.  
[2] 
National Institute of Health. Sudden Deafness. Bethesda, Md: National Institutes of 
Health; 2000. NIH publication 00-4757. 

Angela Cavallaro, Carla Cannizzaro, Francesco Martines et al. 
 
1008
[3] 
Martines, F., Salvago, P., Ferrara, S., Messina, G., Mucia, M., Plescia, F., Sireci, F. 
(2016) Factors influencing the development of otitis media among Sicilian children 
affected by upper respiratory tract infections. Braz J Otorhinolaryngol, 82(2): 215-222. 
[4] 
Suckfüll, M. (2009) Perspectives on the Pathophysiology and Treatment of Sudden 
Idiopathic Sensorineural Hearing Loss. Dtsch Arztebl Int, 106(41): 669–676.  
[5] 
Conlin, A. E., Parnes, L. S. (2007) Treatment of sudden sensorineural hearing loss, I: a 
systematic review. Arch Otolaryngol Head Neck Surg, 133(6):573–81.  
[6] 
Fetterman, B. L., Saunders, J. E., Luxford, W. M. (1996) Prognosis and treatment of 
sudden sensorineural hearing loss. Am J Otol, 17(4):529–36.  
[7] 
Cannizzaro, E., Cannizzaro, C., Plescia, F., Martines, F., Soleo, L., Pira, E., Lo Coco, 
D. (2014) Exposure to ototoxic agents and hearing loss: A review of current knowledge. 
Hearing, Balance and Communication, 12(4): 166-175. 
[8] 
Plescia, F., Cannizzaro, E., Brancato, A., Martines, F., Di Naro, A., Mucia, M., Plescia, 
F., Vita, C., Salvago, P., Mulè, A., Rizzo, S., Sireci, F., Cannizzaro, C. (2015) 
Acetaldehyde effects in the brain. Acta Med Med, 31 (4): 813-817. 
[9] 
Watford, K., Labadie, R. F. (2007) Intratympanic dexamethasone for sudden 
sensorineural hearing loss after failure of systemic therapy. Laryngoscope, 117(1): 3–
15.  
[10] Wei, B. P. C., Mubiru, S., O’Leary, S. (2006) Steroids for idiopathic sudden 
sensorineural hearing loss. Cochrane Database Syst Rev;(1) Art. No.: CD003998. 
[11] Haberkamp, T. J., Tanyeri, H. M. (1999) Management of idiopathic sudden 
sensorineural hearing loss. Am J Otol, 20:587–95. 
[12] Olzowy, B., Osterkorn, D., Suckfüll, M. (2005) The incidence of sudden hearing loss is 
greater than previously assumed. MMW Fortschr Med, 147(14):37-8. 
[13] Klemm, E., Deutscher, A., Mösges, R. (2009) Aktuelle Stichprobe zur Epidemiologie 
des idiopathischen Hörsturzes [A present 20. investigation of the epidemiology in 
idiopathic suddensensorineural hearing loss]. Laryngo, 88(8):524-7.  
[14] Megighian, D., Bolzan, M., Barion, U., Nicolai, P. (1986) Epidemological 
considerations in sudden hearing loss: a study of 183 cases. Arch Otorhinolaryngol, 
243(4):250–3. 
[15] Ballacchino, A., Salvago, P., Cannizzaro, E., Costanzo, R., Di Marzo, M., Ferrara, S., 
La Mattina, E., Messina, G., Mucia, M., Mulè, A., Plescia, F., Sireci, F., Rizzo, S., 
Martines, F. (2015) Association between sleep-disordered breathing and hearing 
disorders: Clinical observation in Sicilian patients Acta Med Med, 31(3): 607-614. 
[16] Schick, B., Brors, D., Koch, O., Schäfers, M., Kahle, G. (2011) Magnetic resonance 
imaging in patients with sudden hearing loss, tinnitus and vertigo. Otol Neurotol, 
22(6):808-12. 
[17] Hughes, G. B., Freedman, M. A., Haberkamp, T. J., Guay, M. (1996) Sudden 
sensorineural hearing loss. Otolaryngol Clin North Am, 29:393–405. 
[18] Lazarini, P. R., Camargo, A. C. (2006) Idiopathic sudden sensorineural hearing loss: 
etiopathogenic aspects. Rev Bras Otorrinolaringol, 72(4):554–61. 
[19] Rybak, L. P. (1985) Treatable sensorineural hearing loss. Am J Otol, 6(6):482–9. 

Pharmacological Treatment of Sensorineural Hearing Loss 
 
1009
[20] Zahnert, T. (2011) The Differential Diagnosis of Hearing Loss. Dtsch Arztebl Int, 
108(25): 433–444.  
[21] National Institute of Deafness and Communication Disorders. Sudden deafness. 2000. 
http://www.nidcd.nih.gov/health/hear- ing/sudden.htm. 
[22] Burton, M., Harvey, R. (2007) Idiopathic sudden sensorineural hearing loss. In Scott-
Brown’s Otolaryngology, Gleeson, M. Chapter 131. Butterworth-Heinemann, Oxford. 
[23] Oh, J. H., Park, K., Lee, S. J., Shin, Y. R., Choung, Y. H. (2007) Bilateral versus 
unilateral sudden sensorineural hearing loss. Otolaryngol Head Neck Surg, 136:87–91. 
[24] Chiossoine-Kerdel, J. A., Baguley, D. M., Stoddart, R. L., Moffat, D. A. (2000) An 
investigation of the audiologic handicap associated with unilateral sudden sensorineural 
hearing loss. Am J Otol, 21(5):645-651. 
[25] Wie, O. B., Pripp, A. H., Tvete, O. (2010) Unilateral deafness in adults: effects on 
communication and social interaction. Ann Otol Rhinol Laryngol, 119(11):772-781. 
[26] Cavallaro, A., Martines, F., Cannizzaro, C., Lavanco, G., Brancato, A., Carollo, G., 
Plescia, F., Salvago, P., Cannizzaro, E., Mucia, M., Rizzo, S., Martini, A., Plescia, F. 
(2016) Role of cannabinoids in the treatment of tinnitus. Acta Med Med, 32: 463-469. 
[27] Plescia, F., Cannizzaro, C., Brancato, A., Sireci, F., Salvago, P., Martines, F. (2016) 
Emerging pharmacological treatments of tinnitus. Tinnitus: Epidemiology, Causes and 
Emerging Therapeutic Treatments, 43-64.  
[28] Bennett, M., Kertesz, T., Yeung, P. (2005) Hyperbaric oxygen therapy for idiopathic 
sudden sensorineural hearing loss and tinnitus: a systematic review of randomised 
controlled trials. J Laryngol Otol, 119: 791–8. 
[29] Nosrati-Zarenoe, R., Arlinger, S., Hultcrantz, E. (2007) Idiopathic sudden sensorineural 
hearing loss: Results drawn from the Swedish national database. Acta Oto-Laryngol, 
127:1168-1175.  
[30] Wu, C. S., Lin. H. C., Chao. P. Z. (2006) Sudden sensorineural hearing loss: evidence 
from Taiwan. Audiol neuro-otol, 11:151-6. 
[31] Treviño González, J. L., Soto-Galindo, G. A., Moreno Sales, R., Morales Del Ángel, J. 
A. (2018) Sudden sensorineural hearing loss in atypical Cogan's syndrome: A case 
report. Ann Med Surg, 30;30:50-53. 
[32] Byl, F. M. (1984) Jr Sudden hearing loss: Eeight years’ experience and suggested 
prognostic table. Laryngoscope, 94(5 Pt 1):647-661. 
[33] Ottaviani, F., Cadoni, G., Marinelli, L., Fetoni, A.R., De Santis, A., Romito, A., 
Vulpiani, P., Manna, R. (1999) Anti-endothelial autoantibodies in patients with sudden 
hearing loss. Laryngoscope, 109(7):1084–7. 
[34] Li, F. J., Wang, D. Y., Wang, H. Y., Wang, L., Yang, F. B., Lan, L., Guan, J., Yin, Z. 
F., Rosenhall, U., Yu, L., Hellstrom, S., Xue, X. J., Duan, M. L., Wang, Q. J. (2016) 
Clinical Study on 136 Children with Sudden Sensorineural Hearing Loss. Chin Med J, 
20;129(8):946-52. 
[35] Lai, D., Zhao, F., Jalal, N., Zheng, Y. (2017) Intratympanic glucocorticosteroid therapy 
for idiopathic sudden hearing loss: Meta-analysis of randomized controlled trials. 
Medicine, 96(50):e8955. 

Angela Cavallaro, Carla Cannizzaro, Francesco Martines et al. 
 
1010
[36] Areias, B., Santos, C., Natal Jorge, R.M., Gentil, F., Parente, M.P. (2016) Finite 
element modelling of sound transmission from outer to inner ear. Proc Inst Mech Eng 
H, 230(11):999-1007. 
[37] Okamoto, H., Fukushima, M., Teismann, H., Lagemann, L., Kitahara, T., Inohara, H., 
Kakigi, R., Pantev, C. (2014) Constraint-induced sound therapy for sudden 
sensorineural hearing loss--behavioral and neurophysiological outcomes. Sci Rep, 
29:4:3927. 
[38] Kuhn, M., Heman-Ackah, S. E., Shaikh, J. A., Roehm, P. C. (2011) Sudden 
sensorineural hearing loss: a review of diagnosis, treatment, and prognosis. Trends 
Amplif, 15(3):91-105. 
[39] National Institute on Deafness and Other Communication Disorders (NIDCD). 
[40] Mattox, D. E., Simmons, F. B. (1997) Natural history of sudden sensorineural hearing 
loss. Ann Otol Rhinol Laryngol, 86(4, pt 1):463-480.  
[41] Conlin, A. E., Parnes, L. S. (2007) Treatment of sudden sensorineural hear- ing loss, II: 
a meta-analysis. Arch Otolaryngol Head Neck Surg, 133(6):582-586.  
[42] Haynes, D. S., O’Malley, M., Cohen, S., Watford, K., Labadie, R. F. (2007) Intratym- 
panic dexamethasone for sudden sensorineural hearing loss after failure of systemic 
therapy. Laryngoscope, 117(1):3-15. 
[43] Aimoni, C., Bianchini, C., Borin, M., Ciorba, A., Fellin, R., Martini, A., Scanelli, G., 
Volpato, S. (2010) Diabetes, cardiovascular risk factors and idiopathic sudden 
sensorineural hearing loss: a case-control study. Audiol Neurootol, 15(2):111-5. 
[44] Cho, J., Cheon, H., Park, J. H., Lee, H. J., Kim, H. J., Choi, H. G., Koo, J. W., Hong, 
SK. (2017) Sudden sensorineural hearing loss associated with inner ear lesions detected 
by magnetic resonance imaging. PLoS One 12(10): e0186038. 
[45] Plontke, S.K. (2017) Diagnostics and therapy of sudden hearing loss. GMS Current 
Topics in Otorhinolaryngology - Head and Neck Surgery, Vol. 16, ISSN 1865-1011. 
[46] Stachler, R. J., Chandrasekhar, S. S., Archer, S. M., Rosenfeld, R. M., Schwartz, S. R., 
Barrs, D. M., Brown, S. R., Fife, T. D., Ford, P., Ganiats, T. G., Hollingsworth, D.B., 
Lewandowski, C. A., Montano, J. J., Saunders, J. E., Tucci, D. L., Valente, M., Warren, 
B. E., Yaremchuk, K. L., Robertson, P. J. (2012) Clinical practice guideline: sudden 
hearing loss. Otolaryngol Head Neck Surg, 146(3 Suppl):S1-35. 
[47] Chandrasekhar, S.S. (2003) Update son methods to treat sudden hearing loss. Oper 
Tech Otolaryngol Head Neck Surg, 14:288-292. 
[48] Barnes, P. J. (2006) How corticosteroids control inflammation: Quintiles Prize Lecture 
2005. Br J Pharmacol, 148(3):245-54.  
[49] Ito, K., Chung, K. F., Adcock, I. M. (2006) Update on glucocorticoid action and 
resistance. J Allergy Clin Immunol, 117:522–543. 
[50] Kaiser, H., Kley, H. K. (1997) Cortisontherapie. 10th ed. Stuttgart, Germany: Georg 
Thieme Verlag, 19-21.  
[51] Erichsen, S., Bagger-Sjöbäck, D., Curtis, L., Zuo, J., Rarey, K. E., Hultcrantz, M. 
(1996) Appearance of glucocorticoid receptors in the inner ear of the mouse during 
development. Acta Otolaryngol, 116:721-725. 

Pharmacological Treatment of Sensorineural Hearing Loss 
 
1011
[52] Furuta, H., Mori, N., Sato, C., Hoshikawa, H., Sakai, S., Iwakura, S., Doi, K. (1994) 
Mineralocorticoid type I receptor in the rat cochlea: mRNA identification by 
polymerase chain reaction (PCR) and in situ hybridization. Hear Res, 78(2):175-80. 
[53] Pitovski, D. Z., Drescher, M. J., Kerr, T. P., Drescher, D. G. (1993) Aldosterone 
mediates an increase in [3H]ouabain binding at Na,K-ATPase sites in the mammalian 
inner ear. Brain Res, 601:273-278. 
[54] Zuo, J., Curtis, L., Yao Xten Cate, W. J. F., Rarey, K. (1995) Expression of Na,K-
ATPase a- and b-isoforms in the neonatal rat cochlea. Acta Otolaryngol, 115:497-503. 
[55] Erichsen, S., Zuo, J., Curtis, L., Rarey, K., Hultcrantz, M. (1996) Na,K-ATPase a- and 
b-isoforms in the developing cochlea of the mouse. Hear Res; 100:143-149. 
[56] Trune, D. R., Wobig, R. J., Kempton. J. B., Hefeneider, S. H. (1999a) Steroid treatment 
improves cochlear function in the MRL. MpJ-Fas(lpr) autoimmune mouse. Hear Res, 
137:160-166.  
[57] Trune, D. R., Wobig, R. J, Kempton, J. B., Hefeneider, S. H. (1999b) Steroid treatment 
in young MRL. MpJ-Fas(lpr) autoimmune mice prevents cochlear dysfunction. Hear 
Res, 137:167-173.  
[58] Forth, W., Henschler, D., Rummel, W., Förstermann, U., Starke, K. (2001) Allgemeine 
und Spezielle Pharmakologie und Toxikologie. 8. Auflage ed. Urban & Fischer Verlag 
München Jena. 
[59] Merchant, S. N., Durand, M. L., Adams, J. C. (2008) Sudden deafness:is it viral? 
Journal of Oto-rhino-laryngology and its Related Specialities, 70(1), 52-60. 
[60] Wei, B. P., Mubiru, S., O’Leary, S. (2006) Steroids for idiopathic sudden sensorineural 
hearing loss. Cochrane Database of Systemic Review, 1CD003998. 
[61] Wilson, W. R., Byl, F. M., Laird, N. (1980) The efficacy of steroids in the treatment of 
idiopathic sudden hearing loss: a doubleblind clinical study. Arch Otolaryngol, 
106:772-6. 
[62] Mattox, D. E., Simmons, F. B. (1977) Natural history of sudden sensorineural hearing 
loss. Ann Otol Rhinol Laryngol, 86:46380. 
[63] Byl, F. M. Jr. (1984) Sudden hearing loss: eight years’ experience and suggested 
prognostic table. Laryngoscope, 94:647-61. 
[64] Fetterman, B. L., Saunders, J. E., Luxford, W. M. (1996) Prognosis and treatment of 
sudden sensorineural hearing loss. Am J Otol, 17:529-3. 
[65] Parnes, L. S., Sun, A. H., Freeman, D. J. (1999) Corticosteroid pharmacokinetics in the 
inner ear fluids: an animal study followed by clinical application. Laryngoscope, 109:1-
17. 
[66] Cinamon, U., Bendet, E., Kronenberg, J. (2001) Steroids, carbogen or placebo for 
sudden hearing loss: a prospective double-blind study. Eur Arch Otorhinolaryngol, 
258:477-480. 
[67] Nosrati-Zarenoe, R., Hultcrantz, E. (2012) Corticosteroid treatment of idipathic sudden 
sensorineural hearing loss: randomized triple-blind placebo-controlled trial. Otol 
Neurotol, 33:523-531. 

Angela Cavallaro, Carla Cannizzaro, Francesco Martines et al. 
 
1012
[68] Plescia, F., Sardo, P., Rizzo, V., Cacace, S., Marino, R. A., Brancato, A., Ferraro, G., 
Carletti, F., Cannizzaro, C. (2014) Pregnenolone sulphate enhances spatial orientation 
and object discrimination in adult male rats: evidence from a behavioural and 
electrophysiological study. Behav Brain Res 258:193-201.  
[69] Silverstein, H., Choo, D., Rosenberg, S. I., Kuhn, J., Seidman, M., Stein, I. (1996) 
Intratympanic steroid treatment of inner ear disease and tinnitus (preliminary report). 
Ear Nose Throat J, 75(8):468-71. 
[70] Hamid, M., Trune, D. (2008) Issue, indication, and controversies regarding 
intratympanic steroid perfusion. Curr Opin Otolaryngol Head Neck Surg, 16:434-440. 
[71] Battaglia, A., Burchette, R., Cueva, R. (2008) Combination therapy (intratympanic 
dexamethasone + high-dose prednisone taper) for the treatment of idiopathic sudden 
sensorineural hearing loss. Otol Neurotol, 29(4):453-60.  
[72] Battaglia, A., Lualhati, A., Lin, H., Burchette, R., Cueva, R. (2014) A prospective, 
multi-centered study of the treatment of idiopathic sudden sensorineural hearing loss 
with combination therapy versus high-dose prednisone alone: a 139 patient follow-up. 
Otol Neurotol, 35(6):1091-8.  
[73] Jungda, J., Park, J. H., Jang, J. H., Lee, K. Y. (2016) The efficacy of combination 
therapy for idiopathic sudden sensorineural hearing loss. Laryngoscope, 126(8):1871-6.  
[74] Lee, J. B., Choi, SJ. (2016) Potential Benefits of Combination Therapy as Primary 
Treatment for Sudden Sensorineural Hearing Loss. Otolaryngol Head Neck Surg, 
154(2):328-34.  
[75] Rauch, S. D., Halpin, C. F., Antonelli, P. J., Babu, S., Carey, J. P., Gantz, B. J., Goebel, 
J.A., Hammerschlag, P.E., Harris, J.P., Isaacson, B., Lee, D., Linstrom, C. J., Parnes, L. 
S., Shi, H., Slattery, W. H., Telian, S. A., Vrabec, J. T., Reda, D. J. (2011) Oral vs 
intratympanic corticosteroid therapy for idiopathic sudden sensorineural hearing loss: a 
randomized trial. JAMA, 305(20):2071-9.  
[76] Zhuo, X. L., Wang, Y., Zhuo, W. L., Zhang, X. Y. (2008) Is the application of 
prostaglandin E1 effective for the treatment of sudden hearing loss? An evidence-based 
meta-analysis. J Int Med Res, 8;36(3):467-70. 
[77] Nishimura, T., Noario, K., Hosoi, H. (2002) Effects of intravenous administration of 
prostaglandin E1 on cochlear blood flow in guinea pigs. Eur Arch Othorhinolaryngol, 
259:253-256. 
[78] Ogawa, K., Takei, S., Inoue, Y., Kanzaki, J. (2002) Effect of prostaglandin E1 on 
idiopathic sudden sensorineural hearing loss: a double-blinded clinical study. Otology 
and Neurotology, 23:665–8. 
[79] Ni, Y., Zhao, X. (2004) Carbogen combined with drugs in the treatment of sudden 
deafness. Lin Chuang Er Bi Yan Hou Ke Za Zhi,18 (7):414–5. 
 
 

In: Encyclopedia of Audiology and Hearing Research 
ISBN: 978-1-53617-702-2 
Editors: Erno Larivaara and Senja Korhola 
© 2020 Nova Science Publishers, Inc. 
 
 
 
 
 
 
 
Chapter 67 
 
 
 
MANAGEMENT OF SENSORINEURAL HEARING  
LOSS WITH HEARING AIDS 
 
 
Pasquale Marsella, MD, Alessandro Scorpecci*, MD, PhD  
and Sara Giannantonio, MD, PhD 
Audiology and Otosurgery Unit, Cochlear Implant Referral Center,  
“Bambino Gesù” Children’s Hospital and Research Institute, Rome, Italy 
 
 
ABSTRACT 
 
Sensorineural hearing loss (SNHL) is a disease affecting the hair cells of the cochlea. 
Congenital SNHL is mainly due to genetic mutations, infectious agents and hypoxia, 
whereas acquired forms are mostly caused by aging (presbycusis), noise exposure and 
ototoxic drugs, although genetic mutations and infections by neurotropic viral agents are 
recognized etiologic factors in this category, as well. SHL can also be classified 
according to laterality into bilateral and unilateral, and according to the degree of hearing 
loss into mild, moderate, severe and profound.  
Modern hearing aids are digital amplifiers receiving sound energy at their 
microphones, converting it into digital information by means of their processor, and 
transforming it back into an analogue signal for the receiver. Traditionally they are 
divided into behind-the-ear and in-the-ear hearing aids, based on the position.  
Hearing aids represent an effective treatment of SHL when there is a cochlear 
reserve, i.e., in cases where residual hair cells are in a sufficient number to be 
appropriately stimulated. Especially in children affected by prelingual, profound 
deafness, they can still be used in to get the subject trained to acoustic stimulation before 
he/she receives cochlear implantation.  
Whereas hearing aids are the standard treatment of mild, moderate and severe forms 
of bilateral SNHL, their indication in patients with unilateral SNHL is much debated. 
 
Keywords: hearing loss, hearing aids 
 
 
                                                        
* Corresponding Author’s Email: alessandro.scorpecci@opbg.net. 

Pasquale Marsella, Alessandro Scorpecci and Sara Giannantonio 
 
1014
INTRODUCTION 
 
Hearing loss is the most frequent sensory deficit in human populations, affecting more 
than 250 million people in the world [1]. Its causes may be congenital, such as for example 
the 35delG mutation of the connexin 26 gene [2] and intrauterine cytomegalovirus infection, 
or acquired, such as hearing loss determined by noise exposure [3-8]. Consequences of 
hearing impairment include inability to interpret speech sounds, often producing a reduced 
ability to communicate, delay in language acquisition, economic and educational 
disadvantage, social isolation and stigmatization. 
Hearing loss is the most prevalent sensory deficit, and represents a major public health 
issue with substantial economical and societal costs. Untreated, child hearing loss leads to 
significant language delay and impaired auditory-verbal communication, while in adults it 
results in communication difficulties that can lead to social isolation and withdrawal, 
depression and reduced quality of life [9, 10]. Hearing loss is also associated with an 
increased risk of dementia, and this is true especially for older adults [11, 12]. 
So far, it has not been possible to resolve the causes of sensorineural hearing loss, which 
can only be aided by means of sound amplification. Gene therapy, consisting of direct 
administration of genes regenerating the sensory epithelium, or stem cells differentiating into 
mature cells of the organ of Corti have no clinical application at the moment [13]. Although 
causal therapy of sensorineural hearing loss is not to be expected for the near future, there are 
currently several possibilities of hearing aid amplification that can compensate it. 
Shared indications to hearing aid application include the following conditions [14]: 
 
 
surgical hearing improvement is not possible 
 
pure tone audiometric hearing loss in the better ear ≥ 30 dB in at least one of the test 
frequencies in the 500-4000 Hz range 
 
speech recognition in the better ear (tested with headphones at 65 dB) ≤ 80%  
 
sufficient cooperation by the patient 
 
 
FUNCTIONAL PRINCIPLES AND ESSENTIAL COMPONENTS OF 
HEARING AIDS 
 
Modern hearing aids rely on a completely digital signal processing. The sound is first 
received by a microphone, which converts it into an electric signal. Then, the electric signal is 
transformed into a discreet pulse sequence by an analogue-to-digital transducer. Finally, the 
digital sound is again transduced into an electric sound, which is picked up by the receiver 
that converts it into sound waves for the patient’s ear.  
The microphone includes a diaphragm that is set into vibration by the pressure variation 
of sound waves that enter the opening of the microphone itself. The motion of the diaphragm 
transduces the acoustical energy to electrical energy.  
The Digital Sound Processor (DSP) represents the sound by analyzing it at discrete 
intervals and converting it to a series of numbers according to specific algorithms. Typically, 
the sampling rate of modern hearing aids is around 20 kHz. Therefore, a theoretical limit of 

Management of Sensorineural Hearing Loss with Hearing Aids 
 
1015
10 kHz is determined for further signal representation and processing. After digital 
conversion, the discrete signals are separated in the hearing device into several frequency 
bands, corresponding to 4–20 channels. Each channel performs the signal processing, 
including frequency-specific amplification, independent of other channels. The number of 
channels, which sets the number of independently adjustable frequency ranges. This number 
plays a central role in sensorineural hearing losses where only a part of the frequency range is 
affected, such as high-frequency hearing loss. Since typically only 10 different frequency 
values are tested in tone audiometry, the number of channels is no longer a challenge from a 
technical point of view.  
Finally, the separately processed signals are merged, amplified, converted back to 
analogue signals (digital-to-analogue transduction) that are delivered to the ear via a receiver.  
The receiver is also a transducer, transforming electrical signals into acoustic sound 
waves. Like the microphone, it has a diaphragm that is set into vibration, but its movement 
creates the sound waves that travel through the tubing connecting the receiver to the outside.  
 
 
CLASSIFICATION OF HEARING AIDS 
 
According to manner of placement, hearing aids can be classified into: 
 
 
Custom-molded hearing aids, made from an impression of the user’s ear. The 
electronics of these aids are housed in hard plastic, although soft materials are 
sometimes used for the portion located in the auditory canal. Although they offer the 
potential for better quality control, they generally suffer from size and shape 
limitations that adversely impact cosmetics and the functional integration of the 
hearing aid and earmold.  
 
Completely-in-the-canal (CIC) hearing aids, the most cosmetically appealing and 
smallest contemporary hearing aid styles, they often have their electronics 
completely within the cartilaginous segment of the external auditory canal, although 
some extend into the bony portion of the canal, terminating close to the tympanic 
membrane. Despite gain and output of these hearing aids are limited because of small 
transducers, they allow the patient to benefit from improved cosmetics, greater 
overall sound pressure level especially for the high frequencies, reduced occlusion 
effect and feedback and normal telephone use. 
 
In-the-canal (ITC) hearing aids, sized between the CIC and the in-the-ear (ITE) 
hearing aid, they fit within the concha and the cartilaginous portion of the external 
auditory canal, with the microphone opening located at the outer portion of the 
concha. Because of vents, “feedback control” trimmers may be needed, which 
attenuate the high frequencies. Owing to deeper insertion than ITE aids, they often 
require lower gains and provide a better high-frequency response, while size limits 
the number or dimension of circuits and trimmer controls, together with use of the 
large vents that could suppress the occlusion effect. For users, telephone use is much 
easier with this hearing aid type than with a larger ITE device thanks to reduced 

Pasquale Marsella, Alessandro Scorpecci and Sara Giannantonio 
 
1016
feedback, more favorable microphone locations and larger air volume under the 
telephone receiver.  
 
In-the-ear (ITE) hearing aids include “full concha,” “low profile” and “half concha” 
instruments. Full concha ITE aids are the most common, allowing the entire concha 
volume to be filled with electronics and therefore enabling the implementation of 
complex circuit designs, venting and performance control.  
 
Behind the Ear (BTE): the hearing device is above the auricle and the processed 
sound is conducted into the auditory canal either electrically or via a sound tube. 
BTE hearing aids can be divided into the traditional ones, with a receiver within the 
case of the hearing aid, and those with a receiver removed from the case and instead 
located at the end of the tubing and placed inside the auditory canal (receiver-in-the-
canal or RIC). BTE aids can be worn in an “open” configuration, where the coupling 
consists of a tube to the ear and the ear domes do not completely occlude the ear. 
Open fitting is particularly good for subjects with normal hearing in the low 
frequencies and hearing loss in the high frequencies, because the low-frequency 
sound can exit the ear canal as it does for normal-hearing listeners.  
 
 
TYPES OF AMPLIFICATION 
 
The most common ways to provide amplification in a hearing aid are linear and non-
linear amplification. In the context of linear amplification, all input levels are amplified to the 
same extent until the hearing aid reaches output sound pressure level 90. This way, a sound 
entering the hearing aid is increased of a constant decibel value. This type of amplification is 
suitable for low-grade sensory hearing losses or conductive hearing losses. In cases of higher-
grade hearing losses with defined recruitment a lower amplification has to be set for higher 
input levels in order to consider the discomfort limit. This goal is achieved by means of 
amplitude compression. In amplitude compression systems, a linear amplification is typically 
applied up to a certain input level, whereas it is reduced for higher levels. The non-linearity 
can be described by the knee point, i.e., the point where the output curve deviates from linear, 
and the compression ratio, i.e., the degree of such a deviation. There are several compression 
variants that function in a similar way. 
Another type of special, non-linear of amplification is achieved by frequency lowering or 
reduction [15], a function that changes the spectral representation of sound signals and can be 
obtained both as frequency transposition and as frequency compression. The rationale behind 
frequency reduction is that most sensorineural hearing losses are characterized by a 
descending auditory threshold for high-frequencies, for which an amplification is neither 
useful nor possible. By taking high-frequency input signals and presenting these sounds to 
lower-frequency regions, the hearing aid allows the patient to hear otherwise inaudible and 
not amplifiable sounds. Frequency reduction is possible either via frequency transposition, 
whereby the signal is lowered by a fixed frequency value with no alteration of the overall 
bandwidth, or via frequency compression, whereby both frequency and bandwidth are 
reduced by a preset ratio. These procedures are associated with unavoidable signal distortions. 
In many cases, however, a better hearing perception can be achieved after some months of 

Management of Sensorineural Hearing Loss with Hearing Aids 
 
1017
acclimatization. It is important to remind that frequency reduction does not so much lead 
primarily to a better speech understanding than mainly improve sound impression [16]. Since 
frequency reduction algorithms are initially disturbing, the possibilities to implement them in 
commercially available hearing aids are rather limited. 
Up to now, there is no possibility to identify particular subjects who might benefit from 
frequency reduction. In contrast to earlier analogue aids, not only the hardware but also the 
quality of technical components in digital hearing devices is essential. The function of a 
hearing aid is determined by the signal processing defined in the software. Thus, there are 
today technically identical hearing aids that are only different regarding their technical 
features (and price). The software determines for example the feedback suppression, wind 
noise suppression, directional microphones etc. 
 
 
FITTING OF HEARING AIDS 
 
The fitting of a hearing aid is a process of several weeks and months in which the most 
suitable hearing aid is identified and the optimal settings for daily life are established. First, 
the audiological profile is determined by measuring the severity and the type of hearing loss 
and the individual needs are assessed. It is clarified which hearing conditions appear 
frequently and are especially relevant. Patient needs or request to be taken into account at this 
stage are: speech understanding in quiet compared to in noise, telephone use, frequent lecture 
situations (e.g., school children or students), or specific requests for directionality (e.g., taxi 
drivers), or special requirements regarding dirt and water repellency (e.g., pool attendants). 
Additional settings must also be considered: are highly different settings constellations 
necessary? Does switching have to be automatized or at the touch of a button? Those and 
other similar questions lead to a selection of the possible hearing aid. The initial setting of the 
hearing aid is generally performed by means of a software according to audiometric 
parameters such as hearing (air and bone conduction) and discomfort thresholds, even 
loudness scaling if needed. Because of the approximation of measurements, most hearing aid 
fittings are performed only based on tone audiograms and the discomfort thresholds are 
directly estimated by the fitting programs. 
The objective of compensation in cases of sensory hearing losses is never the complete 
amplification of an existing hearing loss, whereas the target amplification is rather at half of 
the hearing loss dynamic range. Most fitting formulas such as the National Acoustics 
Laboratories of Australia (NAL) [17], the Prescription of Gain and Output (POGO) [18] 
generally correct the values, adjusting them downwards for higher frequencies and upwards 
for lower frequencies. Other procedures such as the Desired Sensation Level (DSL) [19] try 
to restore the loudness sensation via the dynamic range and thus require the measurement of 
individual loudness scaling over several frequencies. 
In the practice, hearing aid fitting is completely performed by the software provided by 
the hearing aid manufacturer. Based on the audiometric data, the prescription is calculated 
and the hearing aid is programmed. Additional information such as having to do with an 
inexperienced or with an experienced hearing aid user lead to further automatic adjustments. 
Furthermore, other modifications of the hearing aid settings can be performed after testing the 

Pasquale Marsella, Alessandro Scorpecci and Sara Giannantonio 
 
1018
device in daily routine. Finally, fine tuning must take into account the hearing environment 
and include algorithms to optimize sound quality. 
 
 
TECHNOLOGICAL ADVANCEMENTS AND FUTURE DEVELOPMENTS 
 
Modern hearing aids are miniaturized high-power computers that have to function with 
little energy for a possibly long duration. While formerly hearing aids were limited by the 
components (microphone, amplifier, receiver), the quality of a modern hearing device is 
rather defined by the immanent software. Even if there are permanent improvements of the 
hearing aid technology, exaggerated advertising measures often lead to disappointments 
owing to the fact that the effectiveness of the single improvements is not always noticeable. 
Nonetheless, several improvements could be observed over the past years. 
Directional microphones are useful when the speech signal comes from the front and the 
background noise from other directions. Nowadays, directional microphones cannot only be 
implemented as a fixed part but they can also be digitally added. Adaptive directional 
microphones only switch on when a speech signal is recognized as coming from the front. 
This is possible due to the evaluation of the time delay of the sound input at two different 
microphones. 
Wind noise elimination: the wind reaching a normal hearing ear is mostly well eliminated 
and only rarely leads to noticeable hearing deterioration. Since most of the hearing aid 
microphones are located above the auricle, this natural protection is missing. Furthermore, 
most microphones have a directional effect set to the front. Thus, also low wind velocities 
lead to significant deterioration of the signal quality. In the past, this fact led to dissatisfaction 
in nearly half the hearing aid users [20]. Several algorithms for wind noise reduction were 
thus developed, with the aim to increase the wearing comfort and also to improve speech 
understanding in challenging acoustical environments. 
Binaural coupling: coupling two hearing aids of the same user became possible after the 
development of an appropriate wireless protocol. Initially, binaural coupling was limited to 
the (wireless) transmission of parameter settings of one hearing aid to another. In this context, 
for example, the change of loudness in one hearing aid was also effective in the contralateral 
one. Later, this feature was extended by real time transmission of audiodata. This way, a very 
important directional effect of the microphones can be achieved. Additionally, the hearing aid 
can recognize on which side the speech signal is presented and amplify it. During phone calls, 
such devices can transmit the telephone signal to both ears. It is highly efficient to use 
binaural coupling also to suppress wind noise when they only occur in one ear. 
 
 
HEARING AIDS FOR UNILATERAL HEARING LOSS IN CHILDREN 
 
Although a hearing aid may be a useful intervention option for children with unilateral 
hearing loss (UHL) who have usable residual hearing in the impaired ear, clinicians do not 
appear to be making this recommendation consistently. Only 26% of children with UHL 
received an initial recommendation for amplification [21], whereas across studies 48% of 
children with UHL received a conventional hearing aid [22, 23]. A parental survey indicates 

Management of Sensorineural Hearing Loss with Hearing Aids 
 
1019
similar findings: 42% of families of children with UHL were told that hearing aids would not 
help, although only 8% of the children had no residual hearing [24]. However, evidence 
indicates that a conventional hearing a does provide benefits: 20 parents of children with mild 
to moderate UHL surveyed via a questionnaire reported improved hearing and better 
performance in academic and social situations with a hearing aid and many parents indicated 
that they wished their child had received a hearing aid sooner [25]. Children with UHL who 
used a hearing aid have also reported greater ease of listening in quiet and noise [22]. Even 
with no measurable change in speech perception, subjective reports from parents, teachers, 
and children showed significant aided benefits at home, school and quality of life [26]. 
Younger children with mild to severe UHL have also shown significantly improved 
localization, although children who were fit later showed bilateral interference [27]. Yet only 
about 26% of children with UHL use their hearing aid full-time; compared to 72% of children 
with a moderate bilateral hearing loss. This reduced compliance in children with UHL may be 
because they are often fit with hearing aids later than children with bilateral hearing loss, and 
wearing compliance is typically poorer when children are fitted later [28]. One limitation in 
fitting a hearing aid to children with UHL concerns the prescriptive method used: there is no 
evidence to date to indicate whether children with UHL prefer the gain from prescriptive 
methods designed for bilateral hearing loss [29]. A possible solution to this problem has been 
suggested [30], which is to use a technique to achieve binaural fusion in individuals with 
asymmetric hearing losses [31-32]. However, this method requires patient participation and 
therefore is not useful in fitting infants and young children with UHL. 
Overall, the evidence indicates that children with UHL who have usable residual hearing 
in the affected ear can receive benefits from conventional digital amplification including 
greater ease of listening, better performance in academic and social situations, and improved 
localization if fitted early. 
 
 
HEARING AIDS FOR UNILATERAL HEARING LOSS IN ADULTS 
 
Adults with UHL also have positive outcomes with conventional hearing aid use. Of 119 
adults with UHL who were fit with a conventional hearing aid, 68% continued use 6 months 
post-fitting and the primary predictors for successful hearing aid use were social/work 
activities and digital signal processing [33], suggesting that although individual demands on 
communication may affect use, advanced technology devices may be more appropriate for 
individuals with UHL. 
In adults, unilateral hearing loss is often acquired suddenly and accompanied by tinnitus 
[34-36]. Positive outcomes of hearing aid use in the adult population are reported as well. Of 
119 adults with UHL who were fit with a conventional hearing aid, 68% continued use 6 
months post-fitting and the primary predictors for successful hearing aid use were social/work 
activities and digital signal processing [37], suggesting that although individual demands on 
communication may affect use, advanced technology devices may be more appropriate for 
individuals with UHL. 
Unfortunately, there are only few studies that examine the effectiveness of hearing aids 
on tinnitus alone. With hearing aids, many patients experience effective relief of their tinnitus, 
but studies on hearing aids as solitary therapy do not exist because they are always embedded 

Pasquale Marsella, Alessandro Scorpecci and Sara Giannantonio 
 
1020
in an audio-therapeutic concept. Nonetheless, hearing aids are essential in the tinnitus therapy 
because they nearly always include and compensate the existing hearing loss. In a 
retrospective tinnitus analysis [38-39], 58 tinnitus patients with hearing loss were followed-
up; 29 used hearing aids, 29 did not – both groups had nearly identical audiograms, the same 
duration of tinnitus, and the same age on the average. Only in the group of hearing aid users, 
a significant improvement of the tinnitus could be achieved based on the Tinnitus Handicap 
Questionnaire. 
Another work reported about 74 tinnitus patients who received hearing aids with a linear 
frequency transposition [40-41]. Those hearing aids are especially active in the high 
frequencies and very suitable for patients with a steep drop of the hearing curve. In 60 
patients, the tinnitus could be permanently eliminated. In this study, patients whose hearing 
loss was related to noise exposure had permanent tinnitus suppression a few days after 
starting hearing aid use. A review study from the Netherlands reviewed 10 articles, showing 
improvement 25–72% of the patients and complete tinnitus suppression in 8–45% of the 
patients. Up to 25%, however, even mentioned deterioration, new additional tinnitus 
developed in up to 10% [41]. 
 
 
REFERENCES 
 
[1] 
Heller, A. J. (2003) Classification and epidemiology of tinnitus. Otoryngol Clin North 
Am, 36:2390-2489. 
[2] 
Eggermont, J. J., Roberts, L. E. (2004) The neuroscience of tinnitus. Trends Neurosci, 
27:676-682. 
[3] 
Salvago, P., Rizzo, S., Bianco, A., Martines, F. (2017) Sudden sensorineural hearing 
loss: is there a relationship between routine haematological parameters and audiogram 
shapes?. International Journal of Audiology, 56(3): 148-153. 
[4] 
Ballacchino, A., Salvago, P., Cannizzaro, E., Costanzo, R., Di Marzo, M., Ferrara, S., 
La Mattina, E., Messina, G., Mucia, M., Mulè, A., Plescia, F., Sireci, F., Rizzo, S., 
Martines, F. (2015) Association between sleep-disordered breathing and hearing 
disorders: Clinical observation in Sicilian patients. Acta Medica Mediterranea, 31(3): 
607-614. 
[5] 
Martines, F., Maira, E., Ferrara, S. (2011) Age-related hearing impairment (ARHI): A 
common sensory deficit in the elderly. Acta Medica Mediterranea, 27 (1):47-52.  
[6] 
Martines, F., Salvago, P., Bartolotta, C., Cocuzza, S., Fabiano, C., Ferrara, S. et al. 
(2015) A genotype-phenotype correlation in Sicilian patients with GJB2 biallelic 
mutations. Eur Arch Otorhinolaryngol, 272:1857–1865. 
[7] 
Bartolotta, C., Salvago, P., Cocuzza, S., Fabiano, C., Sammarco, P., Martines, F. (2014) 
Identification of D179H, a novel missense GJB2 mutation in a Western Sicily family. 
European Archives of Oto-Rhino-Laryngology, 271 (6), pp. 1457-1461. 
[8] 
Salvago, P., Martines, E., La Mattina, E., Mucia, M., Sammarco, P., Sireci, F., 
Martines, F. (2014) Distribution and phenotype of GJB2 mutations in 102 Sicilian 

Management of Sensorineural Hearing Loss with Hearing Aids 
 
1021
patients with congenital non syndromic sensorineural hearing loss. International 
Journal of Audiology, 53 (8), pp. 558-563. 
[9] 
Thomas, E., Martines, F., Bianco, A., Messina, G., Giustino, V., Zangla, D., Iovane, A., 
Palma, A. (2018) Decreased postural control in people with moderate hearing loss. 
Medicine (Baltimore); 97(14): e0244. 
[10] Mathers, C., Smith, A., Concha, M. (2000) Global burden of hearing loss in the year 
2000. Global Burden of Disease, 18:1–30. 
[11] Davis, A., Smith, P., Ferguson, M., Stephens, D., Gianopoulos, I. (2007) Acceptability, 
benefit and costs of early screening for hearing disability: a study of potential screening 
tests and models. Health Technology Assessment, 11:1–294. 
[12] Lin, F. R., Metter, E. J., O’Brien, R. J., Resnick, S. M., Zonderman, A.B., Ferrucci, L. 
(2011) Hearing loss and incident dementia. Arch Neurol, 68:214–220. 
[13] Davies, H. R., Cadar, D., Herbert, A., Orrell, M., Steptoe, A. (2017) Hearing 
Impairment and Incident Dementia: Findings from the English Longitudinal Study of 
Ageing. J Am Geriatr Soc; 65: 2074–2081. 
[14] Ibekwe, T. S., Ramma, L., Chindo, B. A. (2012) Potential roles of stem cells in the 
management of sensorineural hearing loss. J Laryngol Otol, 126:653-657. 
[15] Hoppe, U., Hesse, G. (2017) Hearing aids: indications, technology, adaptation, and 
quality control. GMS Curr Top Otorhinolaryngol Head Neck Surg, 18:1-24. 
[16] Simpson, A. (2009) Frequency-lowering devices for managing highfrequency hearing 
loss: a review. Trends Amplif, 13:87-106. 
[17] Miller, C. W., Bates, E., Brennan, M. (2016) The effects of frequency lowering on 
speech perception in noise with adult hearing-aid users. Int J Audiol, 55:305-312. 
[18] Byrne, D., Dillon, H. (1986) The National Acoustic Laboratories' (NAL) new procedure 
for selecting the gain and frequency response of a hearing aid. Ear Hear, 7:257-265. 
[19] McCandless, G., Lyregaard, P. E. (1983) Prescription of gain/output (POGO) for 
hearing aids. Hearing Instruments, 34:16-21. 
[20] Cornelisse, L. E., Seewald, R. C., Jamieson, D. G. (1995) The input/output formula: a 
theoretical approach to the fitting of personal amplification devices. J Acoust Soc Am, 
97:1854-1864.  
[21] Kochkin, S., MarkeTrak VII: Customer satisfaction with hearing instruments in the 
digital age. Hearing Journal 2005; 58: 30, 32-34, 38-40, 42-43. 
[22] Fitzpatrick, E. M., Whittingham, J., Durieux-Smith, A. (2014) Mild bilateral and 
unilateral hearing loss in childhood: a 20-year view of hearing characteristics, and 
audiologic practices before and after newborn hearing screening. Ear Hear, 35:10-18. 
[23] Davis, A., Reeve, K., Hind, S., Bamford, J. (2001) Children with mild and unilateral 
hearing loss, in: R. C. Seewald, J. S. Gravel (Eds.), A Sound Foundation through Early 
Amplification: Proceedings of the Second International Conference, 2001, 179-186. 
[24] English, K., Church, G. (1999) Unilateral hearing loss in children: an update for the 
1990s. Lang Speech Hear Serv Sch., 30:26-31. 

Pasquale Marsella, Alessandro Scorpecci and Sara Giannantonio 
 
1022
[25] Kochkin, S. K., Luxford, W., Northern, J. L., Mason, P., Tharpe, A. M., MarkeTrak, 
VII. (2007) Are 1 million dependents with hearing loss in America being left behind? 
Hear Rev, 14, 1-10. 
[26] McKay, S. To aid or not to aid: children with unilateral hearing loss, Audiol. Online. 
Retrieved from, http://www.audiologyonline.com/articles/to-aid-or-not-children. 2002. 
[27] Briggs, L., Davidson, L., Lieu, J. E. (2011) Outcomes of conventional amplification for 
pediatric unilateral hearing loss. Ann Otol Rhinol Laryngol, 120:448-454. 
[28] Johnstone, P. M., Nabelek, A. K., Robertson, V. S. (2010) Sound localization acuity in 
children with unilateral hearing loss who wear a hearing aid in the impaired ear. J Am 
Acad Audiol, 21:522-534. 
[29] Reeve, K. (2005) Amplification and family factors for children with mild and unilateral 
hearing impairment. In: National Workshop on Mild and Unilateral Hearing Loss: 
Workshop Proceedings, Centers for Disease Control and Prevention, Breckenridge, CO, 
pp. 20-21. 
[30] McKay, S., Gravel, J. S., Tharpe, A. M. (2008) Amplification considerations for 
children with minimal or mild bilateral hearing loss and unilateral hearing loss. Trends 
Amplif, 12:43-54. 
[31] Cui, T. (2014) Monaural hearing aid fitting considerations for Patients with unilateral 
hearing loss: who should receive unilateral fittings, and how should you fit them? Hear 
Rev, 21:32-34. 
[32] McSpaden, J. B., Brethower, L. D. (2007) Achieving binaural fusion in asymmetric 
losses. Hear Rev, 14:5-40.  
[33] Lee, D. H., Noh, H. (2015) Prediction of the use of conventional hearing aids in Korean 
adults with unilateral hearing impairment. Int J Audiol, 54:613-619. 
[34] Rizzo, S., Bentivegna, D., Thomas, E., La Mattina, E., Mucia, M., Salvago, P. et al. 
(2016) Sudden sensorineural hearing loss, an invisible male: State of the art. Hearing 
loss: etiology, management and societal implications, 75-86. 
[35] Dispenza, F., De Stefano, A., Costantino, C., Marchese, D., Riggio, F. (2013) Sudden 
Sensorineural Hearing Loss: results of intratympanic steroids as salvage treatment. Am 
J Otolaryngol, 34:296-300. 
[36] Gagliardo, C., Martines, F., Bencivinni, F., Latona, G., Lo Casto, A., Midiri, M. (2013) 
Intratumoral Haemorrhage Causing an Unusual Clinical Presentation of a Vestibular 
Schwannoma. Neurualradiology Journal, 26: 30-34. 
[37] Moffat, G., Adjout, K., Gallego, S., Thai-Van, H., Collet, L., Noreña, A. J. (2009) 
Effects of hearing aid fitting on the perceptual characteristics of tinnitus. Hear Res, 
254:82-91. 
[38] Dispenza, F., Cappello, F., Kulamarva, G., De Stefano, A. (2013) The discovery of the 
stapes. Acta Otorhinolaryngol Ital. 33(5): 357-359. 
[39] Peltier, E., Peltier, C., Tahar, S., Alliot-Lugaz, E., Cazals, Y. (2012) Long-term tinnitus 
suppression with linear octave frequency transposition hearing aids. PLoS ONE, 
7:e51915. 

Management of Sensorineural Hearing Loss with Hearing Aids 
 
1023
[40] Dispenza, F., Mazzucco, W., Bianchini, S., Mazzola, S., Bennici, E. (2015) 
Management of labyrinthine fistula in chronic otitis with cholesteatoma: case series. 
Euro Mediterranean Biomedical Journal 10(21): 255-261. 
[41] Ramakers, G. G., van Zon, A., Stegeman, I., Grolman, W. (2015) The effect of cochlear 
implantation on tinnitus in patients with bilateral hearing loss: A systematic review. 
Laryngoscope, 125:2584-2492. 
 
 


In: Encyclopedia of Audiology and Hearing Research 
ISBN: 978-1-53617-702-2 
Editors: Erno Larivaara and Senja Korhola 
© 2020 Nova Science Publishers, Inc. 
 
 
 
 
 
 
 
Chapter 68 
 
 
 
COCHLEAR IMPLANT OF SNHL PATIENTS 
 
 
Pasquale Marsella, MD, Sara Giannantonio, MD, PhD  
and Alessandro Scorpecci, MD, PhD 
Audiology and Otosurgery Unit, Cochlear Implant Referral Center,  
“Bambino Gesù” Children’s Hospital and Research Institute, Rome, Italy 
 
 
ABSTRACT 
 
Sensorineural hearing loss (SNHL) is the most common type of hearing loss. The 
key to the optimal management of congenital SHL is early diagnosis (achieved through 
the diffusion of Newborn Hearing Screening programs) and early intervention. Treatment 
for SNHL varies, depending on the severity of the loss itself. Although hearing aids can 
help most people with mild to moderate SNHL, they are often not sufficient for spoken 
language development in more severe hearing losses, where cochlear implants represent 
the gold standard of the treatment. A cochlear implant is a surgically implanted electronic 
device. Unlike hearing aids, which simply amplify sound, cochlear implants pick up 
sound and digitize it, convert that digitized sound into electrical signals, and transmit 
those signals to electrodes embedded in the cochlea. The electrodes electrically stimulate 
the cochlear nerve, causing it to send signals to the brain. There are several systems 
available, but generally they have similar external (speech processor, transmitter, 
microphones) and internal (receiver-stimulator, electrode array) components. The ideal 
timing for cochlear implantation is between 12 and 18 months of age, and it can be done 
simultaneously or sequentially. Results vary from person to person. The main factors that 
can affect the outcomes of cochlear implantation include the age when hearing was lost, 
the length of time between hearing loss and cochlear implantation (hearing deprivation), 
and the timely inclusion in an appropriate speech therapy rehabilitation program. 
Research indicates that children who undergo bilateral (either early sequential or 
simultaneous) cochlear implant surgery at young age develop better hearing and speech 
than similar children with hearing aids or who received one cochlear implant or two 
cochlear implants after longer hearing deprivation. The benefit of cochlear implantation 
in children with single sided deafness is currently under investigation. 
 
 
 
 

Pasquale Marsella, Sara Giannantonio and Alessandro Scorpecci 
 
1026
INTRODUCTION 
 
Sensorineural hearing loss (SNHL) affects 1 to 3 of every 1000 children born in 
developed countries [1, 2]; the rate is probably higher in the developing world [3]. In most 
cases, the hearing loss is nonsyndromic (i.e., it is not associated with other congenital 
features) and the child is otherwise healthy. The lack of auditory input during the child’s 
development has a minimal effect on his or her motor and social development during infancy. 
Thus, if infant hearing screening is not performed, the deafness is often unnoticed during this 
period, resulting in a late diagnosis (at ≥1 year of age) [4]. The deaf child receives little or no 
access to environmental sounds and speech; this lack of access arrests or disrupts normal 
auditory development [5-9]. As the child grows older, auditory deprivation results in cortical 
reorganization, including an expansion of visually driven inputs into the secondary areas of 
the auditory cortex. The duration of deafness before diagnosis and intervention is negatively 
correlated with the child’s ability to perceive and use spoken language after being fitted for an 
auditory prosthesis [10]. Universal newborn hearing screening, which is now available in 
most countries, has markedly improved the early diagnosis of sensorineural hearing loss. 
 
 
Effects of Hearing Loss 
 
It is well documented that childhood deafness can have a severe impact on speech and 
language development, which can result its emotional, social, educational, and vocational 
disruption as the child matures [11]. In our society, oral language is the primary means 
through which socialization and learning occur. Development of speech and language occurs 
rapidly in the first few years of life, primarily through normal family interaction. If the 
communication interaction between child and family is disrupted during these early critical 
years, serious delays are likely to occur. If the deprivation goes on for too long, the child may 
never make up the lost learning, even with extensive rehabilitation. Supporting this claim, the 
average reading level of deaf 18 year old persons is just below the third grade level [12]. 
Adults who have been deaf since childhood tend to be undereducated and earn less money, 
compared with their hearing peers [13]. Severe to profound hearing loss has the potential to 
adversely affect many aspects of development, including social, cognitive, and academic 
abilities, primarily because of language delay [14]. In the long term, deficits in these areas can 
limit vocational and economic potential. Unlike many clinical conditions, the management 
and treatment of SNHL largely involves the social welfare and educational systems rather 
than the medical care system. For a child with congenital severe to profound SNHL, the total 
lifetime cost of hearing loss exceeds US$1000000. Special education costs amount to over 
half of this total, and medical expenses and the purchase of assistive devices add another 
US$100000 [15]. 
Cochlear implants are electronic devices which have been approved as method of treating 
profound, bilateral, sensorineural hearing loss for persons since the mid-1980s [16]. Although 
the original cochlear implants were single channel devices, there are now several 
commercially available, multichannel cochlear implant systems. Additionally, over the course 
of the last two decades, technological developments in cochlear implant design have yielded 
substantial gains in spoken word recognition for the average multichannel cochlear implant 

Cochlear Implant of SNHL Patients 
 
1027
user. Along with advances in engineering and speech processor design have come changes in 
the criteria for cochlear implant candidacy. For example, initially only adults with postlingual 
profound deafness were considered suitable candidates for cochlear implantation; now, 
audiometric thresholds are no longer a primary determinant of cochlear implant candidacy for 
postlingually deafened adults. Similarly, congenitally deaf children initially were not 
considered suitable candidates for multichannel cochlear implantation. When implantation of 
children was approved by the FDA it was limited to children 2 years of age and up; now, the 
FDA has approved the use of multichannel cochlear implants in prelingually deafened 
children as young as 12 months of age, and many children younger than 12 months of age 
have been implanted off protocol. 
 
 
CANDIDACY CRITERIA FOR COCHLEAR IMPLANTATION 
 
FDA Guidelines 
 
The FDA has approved cochlear implants for children with severe-to-profound bilateral 
sensorineural hearing loss (hearing threshold, ≥90 dB in the better ear) who are at least 1 year 
of age and who have not benefited from an adequate trial (typically 4 to 6 months) of hearing-
aid amplification. A similar position was taken in 2000 in a statement of the Joint Committee 
on Infant Hearing [17], which noted that “cochlear implants may be an option for certain 
children age 12 months and older with profound hearing loss who show limited benefit from 
conventional amplification.” Currently, clinical practice in recent years has expanded beyond 
these criteria. Guidelines for cochlear implant candidacy have changed substantially over 
time. For instance, in the 1980's cochlear implants were recommended for post-linguistically 
deafened adults with hearing losses greater than 100 dB and no discernable communication 
benefit from a hearing aid. By the year 2000, FDA approval had extended the implantable age 
down to 12 months and broadened the general hearing criteria. Current guidelines permit 
cochlear implantation in persons age 2 years and older with severe-to-profound deafness (i.e., 
pure tone average thresholds of 70 dB HL or greater), and in children 12 to 23 months of age 
with profound deafness (i.e., pure tone average thresholds of 90 dB HL or greater.) Whenever 
possible, outcomes from word and sentence recognition testing are also used to determine 
candidacy. Current guidelines permit implantation in adults with open-set sentence 
recognition scores of approximately 50% to 60% words correct. As cochlear implant devices 
continue to improve, the criteria regarding the degree of hearing loss and the performance 
with a hearing aid that warrants consideration of a cochlear implant also will continue to 
evolve.  
 
 
Medical Evaluation 
 
The medical evaluation examines the status of the patient's overall health, the history and 
etiology of the patient's hearing loss, and the physical condition of the ear and cochlea. The 
general health of the patient impacts his fitness for general anesthesia and surgery, and his 
ability to complete the necessary post-operative programming of the device. Although general 

Pasquale Marsella, Sara Giannantonio and Alessandro Scorpecci 
 
1028
health status is rarely a contraindication for implantation, it may affect the timing and 
preparation for implantation. 
 
 
Etiology 
 
At present, the etiology and history of a patient's hearing loss cannot accurately predict a 
patient's performance with the cochlear implant. However, some general relationships have 
been reported that can moderate the patient's expectations. For example, persons with 
deafness subsequent to meningitis commonly develop cochlear ossification that can impede 
the insertion of the electrode array. The degree of cochlear ossification may affect the 
prognosis for implant performance and increase the possibility of facial nerve stimulation. 
Individuals with partial insertion of the electrode array perform similarly to those with 
complete insertion as long as a sufficient number of electrodes can be activated to program 
the device [18-20]. Individuals with complete cochlear ossification who require a “drill-out” 
of the bone to provide a space to lay the electrode do not achieve as high a level of auditory 
perception with their implant [20]. They also are more prone to complications of facial nerve 
stimulation and pain associated with implant activation [21]. The possibility of less than 
average performance and a higher incidence of stimulation complications in cases of 
complete ossification needs to be discussed frankly with a patient and can sometimes affect 
the patient's decision to proceed with implantation. 
 
 
History of Hearing Loss 
 
Postlingually deafened adults with a history of progressive hearing loss and a shorter 
duration of deafness tend to achieve higher speech perception scores than those who have 
been deaf for a long period of time prior to implantation [22-25]. Adults with prelingual 
hearing loss generally are not considered good candidates for cochlear implantation, 
especially if they do not use oral/aural communication [26]. Similar relationships exist 
between the history of hearing loss in children and performance with an implant, although 
they are moderated by a child's development. The origins of deafness in children are 
manifold. The difference must be made between congenital and acquired causes as well as the 
time of deafness (pre-, peri-, or postlingual). If the onset is observed before language 
acquisition, the term of pre-lingual deafness is applied, after final language acquisition 
(around the 10th year of life) it is called post-lingual deafness. If hearing loss is detected 
during the phase of language acquisition, it is the case of a peri-lingual deafness. The impact 
of hearing loss on the language development is well-known [27]. It is crucial for the 
therapeutic success of a cochlea implant to possibly early detect, diagnose, and treat hearing 
loss in order to keep the consequences of the auditory deprivation for hearing and language 
development as well as the general mental development on a low level [28]. Hereby, also the 
development of a binaural hearing system as base of directional hearing and speech 
understanding in noise must be mentioned. In cases of congenital deafness, the newborn 
hearing screening is essential for early detection. In contrast to adults, both pre- and 
postlingually deafened children are candidates for cochlear implantation as long as they 
receive little or no benefit from conventional amplification. In some instances, better hearing 

Cochlear Implant of SNHL Patients 
 
1029
sensitivity before implantation and the use of spoken language in a child's communication and 
educational setting have been associated with better speech perception [29, 30]. 
 
 
Radiological Examination 
 
High-resolution imaging (Computerized Tomography, CT and Magnetic Resonance 
Imaging, MRI) is used to estimate the patency of the cochlea and to identify any abnormal 
anatomical variations that may affect insertion of the electrode. Although imaging may miss 
some obstructions preventing electrode insertion, this is rare [31, 32]. Some obstructions can 
be anticipated on the basis of the clinical history of hearing loss. As noted above, clinical 
histories of otosclerosis or meningitis commonly are associated with cochlear ossification. 
 
 
Genetic Diagnostics 
 
One relevant pillar of the etiological clarification is the genetic diagnosis. About 50–60% 
of pediatric hearing impairment are due to a genetic predisposition. They are classified into 
non-syndromic and syndromic types of hearing loss, i.e., generally the hearing loss is a 
symptom in the context of a syndrome. Currently, more than 200 so-called deafness genes are 
known [33]. The most frequent expression is the mutation on the gene locus GJB2 that leads 
to a disorder of the connexin molecule (Connexin 26), a gap junction protein. The 
consequences are disorders of the ionic homeostasis of the hair cells that are irreversibly 
damaged by a potassium intoxication. The difference is made between autosomal recessive, 
autosomal dominant, X-linked, and mitochondrial, genetically caused hearing losses. 
Autosomal recessive types often reveal deafness already at birth and are entitled DFNB (e.g., 
DFNB1 with connexin 26 disorders). Autosomal dominant types often have a postnatal onset 
and are progressive (DFNA) [33]. X-linked hearing losses are located on the X chromosome 
and only appear in males (DFN). Mitochondrial hereditary hearing impairment is passed on 
by maternal genes. 
 
 
Audiologic Evaluation 
 
The purpose of the audiological evaluation is to quantify the candidate's preoperative 
hearing, communicative status, and use of prosthetic devices. The results are useful in 
determining candidacy by comparing the current communicative status to the expected 
outcome of using a cochlear implant. Results also are important as pre-outcome measures to 
quantify the benefit of the cochlear implant after implantation. To this end, the audiologic 
evaluation comprises of a pure-tone audiogram including air and bone-conducted thresholds, 
tests of speech perception such as word and sentence recognition, an evaluation of current 
amplification, and, if appropriate, a trial use of amplification. Speech perception tests are 
most decisive in determining the appropriateness of cochlear implantation. Candidates who 
demonstrate open-set word or sentence recognition performance that is below the average 
scores seen for cochlear implant recipients should be considered for implantation. Indications 
in children – Cochlear implantation in children should be performed immediately after 

Pasquale Marsella, Sara Giannantonio and Alessandro Scorpecci 
 
1030
indication. Bilateral implantation should be performed in cases of bilateral profound deafness, 
if possible simultaneously or otherwise as sequential implantation with a short time interval in 
order to use the sensitive phase for the development of binaural hearing [34, 35]. Hearing aid 
fitting beside unilateral cochlear implantation is indicated in cases of asymmetric hearing with 
unilateral sensory hearing loss and useable hearing ability in the contralateral ear. Narrow 
controls of the residual hearing as well as the hearing success in this ear must be performed so 
that progressive hearing loss or development failure of bilateral hearing are detected in time 
and the point of then necessary sequential cochlear implantation of the second ear may be 
correctly chosen [28-36]. If maturation is delayed, as it may be expected in cases of increased 
hearing thresholds and prolonged inter-peak latencies in brainstem audiometry, control 
examinations in narrow intervals and probatory hearing aid fitting seems to be appropriate.  
Often hearing improvement is observed due to maturation of the peripheral auditory 
system and the central hearing pathway so that a repetition of the examination of the residual 
hearing after some weeks or months is indicated. If no significant improvement of hearing is 
observed, cochlear implantation should be performed in the second year of life at the latest. In 
this context, the so-called perisynaptic audiopathy must be mentioned summarizing disorders 
of the inner hair cells, the synapsis to the afferent nerve fibers as well as true auditory 
neuropathy with damage of the afferent neuron (auditory neuropathy spectrum disorder). This 
term encompasses different pathophysiological disorders of stimulus transmission and 
stimulus forwarding in the peripheral auditory system. Only in the context of true auditory 
neuropathy a relative contraindication for a cochlear implant system exists. In cases of 
particular urgency such as for example threatening cochlear obliteration by labyrinthitis and 
meningitis require immediate, early implantation. 
 
 
Performance Measures in Children 
 
The audiological evaluation of young children for cochlear implantation assesses the ear's 
sensitivity to sound, and, if possible, includes measures of auditory perception. As the age of 
implantation decreases, visual reinforcement audiometry and auditory evoked response 
audiometry are the primary methods of measuring hearing sensitivity. Speech/auditory 
perception testing depends upon the age and linguistic ability of the child. Again, a large 
number of pediatric perception tests exist which vary from open-set word and sentence 
recognition, to closed-set measures of prosodic features, word identification, and speech 
feature identification [37]. For the youngest children, parental reporting scales of auditory 
listening behavior, such as the Infant-Toddler Meaningful Auditory Integration Scale [38] 
frequently have been used to assess auditory skill development. For older children, open-set 
word and sentence tests are employed to determine candidacy. Less difficult tests that include 
closed-set measures of performance, such as the Early Speech Perception Test [39] can be 
included if open-set word recognition is not possible. By using tests appropriate for the age 
and language level of the child, one can scale the child's ability along a continuum and chart a 
child's progress over time. As the age of implantation decreases, candidacy criteria are 
generally determined by a lack of progress noted on parental scales of auditory skill 
development over a given period of time (such as three to six months). In very young 
children, candidacy also may be determined by the child's progress in developing spoken 
language with amplification, based on studies of spoken language acquisition in children with 

Cochlear Implant of SNHL Patients 
 
1031
cochlear implants versus children with different severity of hearing losses and hearing aids 
[40, 41]. 
 
 
Psychological/Rehabilitation Evaluation 
 
An important aspect of cochlear implant candidacy that is much harder to define than the 
audiological or medical evaluation is the assessment of whether the candidate's overall life 
situation is one that will integrate and promote the use of a cochlear implant. The anticipation 
of cochlear implant surgery and the hope for a positive outcome introduces stress into the 
lives of the candidate and his or her family. Evaluation of a patient’s family’s expectations for 
life after implantation can be beneficial in tempering unrealistic expectations and anticipating 
alternative pathways if the postimplant performance is not as expected. In children, the 
psychosocial evaluation is more extensive and includes developmental and educational 
evaluations as well as family assessments. In the pediatric population, the choice of a cochlear 
implant is usually associated with the choice of spoken language as the primary 
communication mode of the deaf child and family. Establishing a plan of rehabilitation and 
education before implantation makes the integration of the implant smoother and reduces the 
likelihood that progress will be hindered by poor follow-through or gaps in rehabilitative 
services. 
 
 
Patient Counseling and Expectations 
 
Candidates for cochlear implantation come for evaluation with all levels of knowledge 
about cochlear implants and need to be informed of the potential risks and benefits of 
cochlear implantation and the impact it may have on their life. The surgical procedure and its 
risks should be described along with a physical description and, preferably demonstration, of 
the internal and external portions of the device. The various cochlear implant systems 
available at the center also should be shown and described to the candidate. The post-surgical 
programming commitment should be described and planned. In addition, potential cochlear 
implant candidates need to be aware of what day-to-day living with the device entails. This is 
best done by contacting other cochlear implant wearers and their families. The most 
important, yet sometimes difficult, aspect of patient counseling is generating realistic 
expectations regarding performance outcome with the implant. Almost all candidates (or their 
families) seek the implant because they want to improve their ability to hear and understand 
speech. Although the mean and range of performance with implants can be described, most 
people will naturally hope for the best of outcomes. Redundantly reviewing the range of 
performance, including the bottom of the range, during the course of the candidacy evaluation 
and discussing post-implant plans in case performance with an implant is poorer than 
anticipated can assist those recipients who obtain minimal postimplant benefit. 
 
 
 
 

Pasquale Marsella, Sara Giannantonio and Alessandro Scorpecci 
 
1032
THE CI TEAM 
 
Minimally, the role of a cochlear implant team is to determine candidacy for cochlear 
implantation, to help prospective recipients make informed decisions about cochlear implant 
surgery and device options, to provide necessary medical care, to carry out the surgical 
implantation, and to provide postimplant device setting and monitoring. Aural rehabilitation 
specialists, speech-language pathologists and educators play an important role in the 
preimplant evaluation and/or postimplant management of children with cochlear implants. 
Prelingually deafened children must learn to use the sound provided by an implant to organize 
and access spoken language and to produce speech that can be understood by others. Aural 
rehabilitation specialists and speech-language pathologists are members of some cochlear 
implant teams. Other teams may not have these professionals on staff; in that case, aural 
rehabilitation and speech-language pathology may be provided by private therapists or by 
school personnel. Because many children with cochlear implants require special classroom 
placement and educational support services, at least during the early years of cochlear implant 
use, it is important for cochlear implant professionals to work closely with educators in 
developing and coordinating appropriate intervention strategies. Larger cochlear implant 
teams may routinely include representatives of multiple disciplines; others may bring in 
additional specialists or refer to outside specialists as needed. Either way, it is important to 
have access to the disciplines required to provide quality health care. Hearing loss impacts not 
only communication and educational development, but also a child's emotional and social 
development. A number of cochlear implant programs have access to the expertise of 
psychologists or social workers who can assist families as needed. Close communication 
among the cochlear implant team and other professionals working with the child is essential 
for children to receive maximum benefit from a cochlear implant.  
 
 
Otologist/Otosurgeon 
 
The core personnel required to carry out these responsibilities include the surgeon 
(otologist/otolaryngologist) and the audiologist. Prior to implantation, the focus of care is 
determining medical and audiological suitability for cochlear implant surgery and managing 
any medical conditions that may prevent surgery. Following cochlear implant surgery and 
postimplant healing, the focus shifts from primarily medical management to primarily 
audiological management. Although the surgeon and audiologist have the principal roles in 
providing services to cochlear implant candidates and recipients, the needs of different 
populations may require the services and expertise of additional professionals, not all of 
whom need be involved with each potential candidate or implantee.  
 
 
Aural Rehabilitation Specialists 
 
The type of intervention provided by an aural rehabilitation specialist depends on his or 
her philosophy of communication development and on the needs of the child. A variety of 
philosophies exist concerning the appropriate communication methods for children with 
hearing impairment or deafness. One philosophy, oralism, promotes the development of 

Cochlear Implant of SNHL Patients 
 
1033
speaking and listening skills for communication. There are several different approaches 
within this philosophy. For example, some oral therapists use both lip-reading and listening as 
a means of learning to speak whereas others follow a more unisensory approach emphasizing 
listening alone without visual cues. An alternative philosophy promotes the use of sign 
language to develop communication skills, either alone or in conjunction with spoken 
language. Signing and speech used together is defined as total communication. In total 
communication, reception of language occurs through listening to speech and watching the 
signs. Expressive language is conveyed via speech and sign. The speech-language pathologist 
may be called upon to carry out evaluations of the child's spoken or signed communication 
abilities and to make recommendations for intervention. Some teams have speech-language 
pathologists who provide ongoing postimplant speech-language therapy to cochlear implant 
recipients. 
 
 
Psychologist 
 
The psychologist provides input related to the level of functioning and mental status of 
the child. The psychologist can also provide intervention when necessary or appropriate. For 
example, if family dynamics or behavioral problems present potential obstacles to success 
with a cochlear implant, the patient and family may be referred for counseling before and/or 
after cochlear implantation. 
 
 
Neuropsychologist 
 
Cochlear implant candidates may be referred for a neuropsychological evaluation if there 
is some concern about their ability to understand and actively participate in the preimplant 
and postimplant processes. 
 
 
Educational Specialists 
 
School personnel such as teachers of the deaf, itinerant teachers of the hearing impaired, 
and mainstream classroom teachers often work closely with the implant team during the 
evaluation and postimplant periods. They provide important information about how the child 
is functioning in his or her daily environment, and implement suggestions given by the team 
for maximizing communication. Sometimes a cochlear implant team includes an educator 
who assists in the planning of the educational placement and protocol. This individual can act 
as a formal liaison between the implant center and the school system. 
 
 
Social Worker 
 
The social worker can provide guidance and support to the child and the family in all 
areas, including financial planning. Social workers also may help to coordinate necessary 
appointments and services and provide counseling for families. 

Pasquale Marsella, Sara Giannantonio and Alessandro Scorpecci 
 
1034
CI COMPONENTS 
 
Cochlear implants are electrical prostheses that trigger auditory sensations via a direct 
electrical stimulation of the hearing nerve. They replace the function of the inner hair cells 
that have the role of biological microphone. Hereby, a technical simulation of the natural 
hearing process is performed with tonotopic presentation of the frequencies along the basilar 
membrane on different parts of the hearing nerve. In comparison to the natural hearing 
process, only a low number of electrically separated channels is available for signal 
transmission. This bottleneck of the electrode-nerve interface becomes especially obvious 
when listening to music or understanding speech in noise.  
The cochlear implant systems of today are generally conceived as two component 
systems. The external speech processor is used for sound recording, sound preprocessing, and 
transformation of the acoustic information into a logical sequence of electrical impulses (so 
called speech processing) and it is the sender of the FM signal for a transcutaneous 
transmission and power supply of the implant per induction by a sending coil. The implant 
that is located under the skin, contains the receiver coil for reception of the FM signal, a 
demodulator for extraction of the electrical pulses, an electrode carrier with different 
intracochlear electrode contacts for transmission of the electrical impulses to the hearing 
nerve and telemetric measurement systems. Current cochlear implant systems dispose of a 
broad spectrum of signal pre-processing including directional microphones, beam former, 
noise elimination, and acoustic scene analysis, and of a mostly wireless interaural connection 
of the systems in cases of bilateral and bimodal treatment. In this way, both speech processors 
can be synchronized. Telemetric measurement systems record electrophysiological data with 
the implant itself such as electrode impedances, measurement of acoustically and electrically 
evoked potentials. Some systems may assess the intracochlear components of 
electrocochleography with Cochlear Microphonics, compound action potential of the hearing 
nerve and summation potential. Additionally, electrically triggered stapedius reflexes can be 
measured. Those objective measurements allow the intra and postoperative functional control 
of the implants and provide support for adjustment, which is a great advantage in children. 
They also allow an indirect control of the position of the implant electrodes. Different 
electrode systems are available for the individual cochlear implantation. Generally, a 
sufficient cochlear coverage should be achieved in order to stimulate possibly all spiral 
ganglia cells. For this purpose, insertion depths of 360° and more are needed. Some 
manufacturers postulate a higher cochlear coverage to reach apical neuronal elements. For 
cochlear implant surgery with hearing preservation, specially designed thin electrodes are 
used that are most frequently placed on the lateral wall and advanced depending on the 
hearing loss. To achieve a possibly selective stimulation with low stimulation current, 
preformed, perimodiolar electrodes are inserted, but generally it is less probable to preserve 
the hearing ability. Special electrodes are available for malformations and for ossified 
cochleas (double or split array. Those arrays distribute the electrode contacts on 2 electrode 
carriers that are inserted into the first and second turns via 2 cochleostomies. Compressed 
arrays are shortened electrode carriers with a normal number of stimulus contacts that are 
placed into the drilled initial part of the basal turn. Both procedures aim at approaching the 
number of intracochlear stimulus contacts as near as possible to the normal cochlear anatomy. 

Cochlear Implant of SNHL Patients 
 
1035
To achieve a secure watertight closure of the cochlea in cases of malformations, special 
electrodes with thickened basal end are applied. 
 
 
THE CI SURGERY 
 
As with many surgical procedures, different surgeons employ different techniques and 
hold different opinions related to cochlear implant surgery. However, there are some basic 
principles that underlie all cochlear implant surgical procedures. The major goals are: (1) to 
insert the electrode array as atraumatically as possible into the scala tympani, (2) to place the 
device on the side of the head in a manner that most protects it from trauma and (3) to ensure 
that the device and electrode array are secure enough to prevent movement. The intent is to 
accomplish these goals without damaging the surrounding tissue, device, and electrode array 
or causing infection and with an acceptable cosmetic result. Modifications in surgical 
technique often are determined by the physical and structural properties of a given device. 
Although the surgical technique is basically the same for both children and adults, some 
modifications may be required due to head size; no increased surgical risks or complications 
have been found in very young children (12 months). Alterations and/or adjustments to the 
surgical technique also may be required for special cases such as a Mondini deformity 
(malformed cochlea) or a hearing loss secondary to meningitis accompanied by ossification. 
Depending on the amount of ossification, the surgeon has choices of technique to maximize 
the possibility of obtaining a full insertion of the electrode array or of using a specially 
designed electrode array for the more heavily ossified cochleas [42]. Cochlear implant 
surgery is performed under general anesthesia, and typically lasts between one and four 
hours. Because of the immaturity of the organs, the implantation should be performed 
generally from the 12h month of age in cases of congenital deafness. Only in cases of 
particular urgency such as the risk of obliteration in the context of labyrinthitis, the 
implantation should be performed earlier. The implantation should include both sides to allow 
the development of binaural hearing with the ability of directional hearing and improved 
speech understanding in noise. Hereby, the simultaneous implantation should be preferred if it 
is possible from an anesthesiologic point of view. Compared to sequential implantation, the 
following advantages should be mentioned: only one hospital stay; only one anesthesia for 
surgery; simultaneous activation of the hearing system for the development of binaural 
hearing. The disadvantage is the prolonged anesthesia and the duration of surgery with the 
associated risk for example of increased blood loss. If sequential bilateral cochlear 
implantation is performed, the interval should be rather short in order to keep the auditive 
deprivation of the second ear as low as possible and thus to achieve a similar hearing ability 
for both ears. If the intervals are longer, poorer hearing results in the later implanted ear and 
poorer bilateral and binaural hearing performance are observed [43]. 
 
 
Standard Surgical Technique 
 
The surgical technique is largely standardized and may be applied in all age groups and 
special cases. Generally a transmastoid surgical approach with posterior tympanostomy is 
performed comprising the following steps [44]: 

Pasquale Marsella, Sara Giannantonio and Alessandro Scorpecci 
 
1036
 
Retroauricular incision 
 
Creation of a periostal pouch in occipital direction to insert the receiving part of the 
implant 
 
Partial mastoidectomy with exposure of the posterior wall of the auditory canal, the 
antrum with the incus, the mastoid course of the facial nerve, and the canal of the 
chorda tympani, the labyrinthine block with the 3 semicircular canals, the sigmoid 
sinus, and the cortex to the middle and posterior cranial fossa as well as the sinus-
dura angle 
 
Creation of a bone bed to insert the implant at 1 cm behind and above the sinus-dura 
angle. Hereby, advancing sometimes onto the dura is necessary, especially in very 
young children. Afterwards careful coagulation is performed 
 
Creation of a connecting canal or tunnel to the mastoid in projection on the sinus-
dura angle to securely insert and fix the electrode 
 
Performance of the posterior tympanostomy by removal of the bone between the 
bone-covered facial nerve and the chorda tympani, in order to visualize the middle 
ear and the relevant structures of the inner ear. Those are the promontory, the round 
and oval windows with stapes and stapedius tendon. In children, revisions, and 
malformations generally intraoperative monitoring of the facial nerve should be 
performed to avoid neural damages and facilitate identification of the nerve 
 
Opening of the cochlea by incision of the round window membrane or cochleostomy 
 
Insertion of the electrode carrier. Generally this should be performed in an atraumatic 
and slow procedure. The selected insertion depths depend on the size of the cochlea 
as well as the dimension of residual hearing. The insertion is performed down to the 
calculated depth. Depending on the electrode type, different insertion techniques, 
possibly using special instruments, are required. Lateral wall electrodes may be 
easily inserted by means of a specially developed insertion forceps in one-hand 
technique. Preformed electrodes require special insertion techniques. In the context 
of advanced-off stylet technique, the electrode is advanced into the cochlea by the 
stylet after partial insertion.  
 
Closure of the cochlea: to avoid perilymph fistula, a secure closure of the cochlea is 
essential. Either a fascia collar may be used that had been created before insertion, or 
muscle pieces that are positioned carefully around the electrode opening 
 
Positioning of the electrode carrier. The electrode carrier has to be securely 
positioned in the mastoid in order to avoid the contact with the covering skin. 
Although there is no absolute indication in children, in some cases a fixation of the 
receiver-stimulator in indicated.  
 
Intraoperative electrophysiology is obligatory for the intraoperative functional 
control of the implant as well as for measuring the stimulus response of the nerve. 
Via an attached coil system the implant can be activated. Then the following 
measurements can be performed: electrode impedances; electrically triggered 
stapedius reflex with determination of the threshold; electrically triggered compound 

Cochlear Implant of SNHL Patients 
 
1037
action potential of the hearing nerve (NRT, neural response telemetry); cochlear 
monitoring. During insertion of the electrode, residual hearing can be monitored by 
measuring cochlear microphone potentials outside and inside the cochlea. Critical 
changes of the Cochlear Microphonics amplitude indicate an impairment of the inner 
ear function. By repositioning the electrode, a permanent hearing loss might be 
avoided [45].  
 
Appropriate wound closure in several layers to securely cover the implant. 
 
The intraoperative control of the electrode position by radiography or cone beam 
tomography is the standard in order to identify insertion failures in time and to 
correct them in the same session. Furthermore, the insertion depth has to be critically 
verified and to be corrected, if necessary. Radiography provides important 
information for the postoperative fitting [46]. The chosen surgical technique is 
associated with a very low complication rate. 
 
Compressive dressing 
 
 
CI COMPLICATIONS 
 
Device Failure (Technical Complications)  
 
Device failure occurs in about 2–4% of the cases. In children they are more frequently 
observed than in adults which is mainly due to a higher incidence of external forces. The 
continuous technical improvement of the implant, in particular since the introduction of 
titanium cases by nearly all manufacturers, a clear reduction of the cumulative failure rate 
(percentage of all implant defects over a defined observation time) could be achieved. Beside 
complete, also partial technical failures may occur, as for example the breakdown of an 
electrode contact. Re-implantation is indicated when the hearing performance is significantly 
impaired. Intermitting failures are difficult to assess technically as well as soft failure, i.e., the 
patient reports convincingly about hearing deterioration but a defect cannot be verified with 
the available technical means. When a device failure is observed and confirmed, re-
implantation should be performed as soon as possible. This is especially true for children with 
implant in only one ear [47]. 
 
 
Medical Complications 
 
Although the rate of complications associated with cochlear implant surgery is very small 
and thus postimplant complications are rare, there are certain risks involved in both the 
surgical procedure and postoperative period.  
 
 
Intraoperative complications – Intraoperative complications mainly occur as damage 
of the facial nerve, the sigmoid sinus, the internal carotid artery, or the ossicular 
chain. Further complications are injuries of the external wall of the auditory canal, 
the tympanic membrane, and the dura. The risk of facial nerve damage is somewhat 

Pasquale Marsella, Sara Giannantonio and Alessandro Scorpecci 
 
1038
greater in those individuals with anatomic malformation of the inner ear such as are 
found with a Mondini deformity. In general, they can be avoided by an adequate 
surgical technique. A low complication rate reflects a high quality standard of 
cochlear implantation and sufficient training due an adequate minimum number of 
surgeries performed per year [48, 49]. 
 
Postoperative complications – The difference is made between severe and mild 
complications. In general, those are either acute complications such as infections, 
postoperative bleedings, vertigo, or inner ear damage in the context of cochlear 
implantation with hearing preservation. In cases of late complications, usually long-
term complications are observed. Those are among others the migration of the 
implant or the electrode when they are insufficiently fixed, e.g., without bone bed or 
without fixation of the electrode, thinning out of the skin covering the implant 
sometimes with perforation of the skin and infection, irritation of the facial nerve in 
the context of advanced ossification, obliteration of the cochlea in the context of 
labyrinthitis, or meningitis occurring after implantation [50]. Mild complications can 
mostly be treated conservatively. Those are also hearing deterioration with increased 
impedance and increased stimulus threshold, e.g., as consequence of labyrinthitis. 
Interestingly, those changes may also be observed in the context of overstimulation 
of the hearing nerve, e.g., with a very short pulse width and high rate of stimuli 
sequences. Hereby, the interruption of stimulation, the administration of 
corticosteroids as well as a careful reactivation of the stimulation are usually suitable 
measures to restore the stimulation capacity. Severe complications require surgical 
revision, for example for re-fixation of the implant and the electrode, dislocation of 
the implant in cases of skin defect and according plastic measures in the sense of e.g., 
local rotation of the temporal muscle. Meningitis is a rare though potentially serious 
complication in those people with inner ear deformities. Leakage of cerebrospinal 
fluid into the ear should be controlled if and when it occurs in order to prevent the 
onset of meningitis. The vestibular portion of the ear, which controls the balance 
mechanism, may have remaining function even when there is little or no residual 
hearing. When this occurs, opening the inner ear to the electrode could cause a 
temporary imbalance. For meningitis prophylaxis, vaccination against Pneumococci 
and Haemophilus influenza is recommended since CI users have an increased risk. In 
children, specific risks must be considered that may have severe consequences. 
Complications require an adequate management that must be controlled by the 
cochlear implant surgeon. Continuous improvement of the surgical technique led to a 
relevant reduction of the complication rates. With 6.9%, the percentage of 
inflammatory complications is clearly higher than in adults as well as the rate of 
electrode migration, which occurs in particular in atraumatic lateral wall electrodes. 
It becomes obvious by hearing loss as well as missing NRT responses to the 
electrode contacts that have left the cochlea. In general, surgical revision with re-
insertion of the electrode and adequate fixation is required. 
 

Cochlear Implant of SNHL Patients 
 
1039
SETTING THE COCHLEAR IMPLANT SPEECH PROCESSOR 
 
Approximately three to five weeks following surgery, recipients return to the cochlear 
implant center to receive their external equipment and to have their speech processor 
programmed. Device programming involves selecting and individually fitting the speech 
processing strategy or strategies the patient will use. Processing strategies are used to translate 
incoming acoustic stimuli into electrical pulses that stimulate auditory nerve fibers. Despite 
the numerous speech encoding strategies implemented in the various cochlear prostheses, the 
basic parameters of programming are neither device nor strategy dependent: the audiologist 
needs to obtain basic psychophysical measures i.e., thresholds and comfort levels on all 
electrodes. Although the basic parameters are the same, the techniques used to obtain these 
measures do depend on individual characteristics such as age, cognitive skills, length of 
deafness, and other potential factors affecting responses the use of both subjective and 
objective techniques. If the recipient is an adult or an older child, the subjective method can 
be used to set the threshold at the lowest level where the patient responds 100% of the time. 
The implant users also can report the level at which the loudness of the stimuli is most 
comfortable. After the thresholds and comfort levels are obtained for all electrodes, the 
computer simulates this information and translates it into an operating program that is 
transferred to the speech processor; live voice stimulation then can begin. Many parameters, 
including global increases in loudness, frequency allocation to electrodes, and speed of 
transmission to name a few, can be manipulated to improve the quality of sound and increase 
open-set speech understanding for a given patient. The precise characteristics that can be 
regulated are dependent on the speech processing strategy used and the manifestation of that 
strategy in a given cochlear implant system. Whether the patient is a child or an adult, 
accurate electrical thresholds and comfort levels are critical contributors to postoperative 
performance. Because of this, it is essential that a comprehensive schedule of programming 
sessions be established. The number of visits required to adequately program and maintain the 
speech processor depends on a number of factors including but not limited to patient age, 
previous auditory experience, and ability to actively participate in the device programming 
tasks. Furthermore, because responses to auditory stimulation from a cochlear implant can 
change over time, long-term audiological follow-up is required. It is recommended that 
cochlear implant recipients contact their cochlear implant center for speech processor 
programming if they or their family notices a decrease in auditory responsiveness, perception, 
discrimination, speech production, or a change in vocal quality in between regularly 
scheduled audiological appointments. 
 
 
Postoperative Fitting and Hearing-Speech Training 
 
In adults and older children, the fitting is performed psycho-acoustically with assessment 
of the co-called T and C levels (threshold and current of comfortable loudness) for every 
single electrode contact. Then the loudness between the contacts is balanced, the dynamic 
range is defined, and the speech processing strategy is selected. The strategy is an algorithm 
according to which the acoustic signal is transformed – completely or partially – into a 
defined sequence of electrical pulses that are then transmitted to the hearing nerve via the 

Pasquale Marsella, Sara Giannantonio and Alessandro Scorpecci 
 
1040
electrode. The aim is a possibly physiological activation pattern of the hearing nerve. The 
single electrode contacts are allotted to different frequency ranges in the form of frequency 
bands. The allocation is made according to the subjective hearing impression and should 
follow the tonotopic order, i.e., high frequencies should be transmitted to the basal electrodes, 
low frequencies to the apical electrode contacts. An anatomically correct depictions is 
generally not possible because the presented frequencies and the position of the electrode 
contact are usually not congruent with the physiological representation on the cochlea (so 
called Greenwood function). In an intraoperative process, an optimized fitting may be 
achieved until the patient reaches an open speech understanding. After longer intervals of 
hearing habituation, further optimizations may follow. Already during fitting, a hearing and 
speech training take place. First, the focus is placed on the recognition of basic auditive 
categories such as loud, quiet/soft, high, low, the recognition of single syllables, of vowels 
and consonants, later it is speech understanding [51]. In children, fitting is performed based 
on objectively assessed parameters. So called NRT based maps allow an approximation of the 
profile over the complete electrode carrier as soon as a T and C level can be psycho-
acoustically determined on an electrode contact. Additionally, electrically evoked brainstem 
potentials and EEG signals are applied [52]. In order to control the usage by means of a so-
called datalogging, the implant registers several parameters such as the daily time of usage. 
This information can be used to support rehabilitation [53]. It is imperative that audiologists 
involved in device programming take the training courses offered by individual device 
manufacturers and avail themselves of the support personnel at each company in order to 
provide the highest quality care to the patient. Because cochlear implant speech processor 
technology and speech programming software constantly evolve, continuing education is a 
necessity. 
 
 
The Use of Objective Measures in Speech Processor Programming 
 
Over the course of the past decade there has been a trend toward implanting children at 
progressively younger ages. Programming the speech processor of the cochlear implant can 
be challenging if the recipient is either very young or has limited response capabilities. It such 
cases, programming techniques that are less dependent on the ability of the child to give a 
behavioral response can prove helpful. While there are several different types of electrically 
evoked potentials that could be used to assist with device programming, most of the attention 
in the literature has focused on the electrically evoked auditory brainstem response (EABR), 
the electrically evoked compound action potential (ECAP) and the electrically evoked 
acoustic reflex threshold (EART). All three measures have acoustic analogs, have been well 
studied and can be recorded in young children. When cochlear implant recipients can actively 
participate in the speech processor programming process, these techniques typically will not 
result in speech processor programs that are superior to those constructed using traditional 
behavioral programming techniques. Additionally, few clinics will use these tools routinely. 
They are typically incorporated into clinical practice in cases where the audiologist has reason 
to question the validity of the behavioral measures that were obtained. However, with the 
decrease in age of implantation and the increase in our understanding about how these tools 
can be used in the clinical management of cochlear implant recipients, the need for 

Cochlear Implant of SNHL Patients 
 
1041
supplemental, non-behaviorally based measures of sensitivity to electrical stimulation 
increasingly has become evident. 
 
 
Electrically Evoked Auditory Brainstem Response (EABR) 
 
The EABR is a recording of the synchronous neural activity in the brainstem that results 
when the auditory nerve is stimulated. It is recorded using commercial evoked potential 
equipment and surface recording electrodes positioned on the head. The EABR can be 
recorded either in the operating room at the time of surgery or during the postoperative 
period. However, obtaining a successful recording does require a very quiet or sleeping 
subject. The stimulus used to evoke the EABR is a biphasic current pulse that is generated by 
the software used to program the speech processor. Studies have shown that the EABR can be 
successfully measured using a variety of different implant types both in congenitally deaf 
children and postlingually deafened adults [54-59]. The EABR is similar in form to the 
acoustically evoked ABR [60] and EABR thresholds have been shown to correlate well with 
behavioral thresholds for the electrical stimulus used to elicit the EABR [54, 61, 62]. From a 
clinical perspective, however, the comparison of interest is between EABR thresholds and the 
levels needed to program the speech processor of the cochlear implant. Research has shown 
that this correlation is significant but not strong [54, 62, 63]. In general, EABR thresholds are 
recorded at levels where the stimulus used to program the speech processor is audible but 
below the maximum level of stimulation that is comfortable for a congenitally deaf child [54, 
62]. This information can be useful in cases where the child is showing little or no reaction to 
electrical stimulation at the initial device stimulation and there is question about whether or 
not he/she hears the programming stimulus. The EABR threshold can provide a point to begin 
conditioning the child to respond to electrical stimulation. EABR thresholds tend to be 
relatively stable over time [64], and therefore this response provides a baseline measure of 
neural responsiveness to electrical stimulation that can be valuable if problems develop at any 
point following the initial device programming session, or hookup [65]. Additionally, in 
children with extremely limited response capabilities, the EABR can allow the audiologist to 
approximate the levels needed to program the speech processor. Few clinics routinely record 
the EABR. The primary reason for this is that recording this particular response requires that 
the subject be sedated or very still during the recording period and the process of establishing 
threshold on an individual electrode is time consuming. Additionally, in most cases, the 
relationship between the EABR threshold and the levels used to program the speech processor 
are not strong enough to warrant routine postoperative sedation. Some clinics do record the 
EABR in the operating room at the end of the surgical procedure to implant the device. 
Unfortunately, time is very limited during surgery and there are data suggesting that the 
threshold measures made in the OR immediately following insertion may change during the 
immediate postoperative period [54]. Nevertheless, the presence of an EABR indicates that 
the device and the auditory nerve are functioning. It is also possible to identify electrodes that 
activate the facial nerve. Because facial nerve stimulation can complicate the process of 
device setting, it can be very helpful to identify electrodes that cause this prior to the initial 
stimulation of the device. Furthermore, the parents of the child and the surgeon often find 
intraoperative EABR results reassuring given the necessary delay between surgery and 
hookup. 

Pasquale Marsella, Sara Giannantonio and Alessandro Scorpecci 
 
1042
Electrically Evoked Compound Action Potential (ECAP) 
 
An alternative auditory evoked potential that can be used in much the same way as the 
EABR is the electrically evoked compound action potential (ECAP). This is a measure of the 
synchronized response of the auditory nerve to electrical stimulation. Rather than being 
measured using surface electrodes like those used to record the EABR, the ECAP typically is 
recorded from an intracochlear electrode. This requires specialized technology. Cochlear 
Corporation was the first company to develop this technology. Since the introduction of the 
Nucleus CI24M device in 1998, it has been possible to measure electrically evoked 
intracochlear potentials in all Nucleus cochlear implant users. Cochlear Corporation refers to 
the software and hardware used to record this response as Neural Response Telemetry (NRT). 
Recently the other manufacturers have also introduced a cochlear implant with neural 
telemetry capabilities and is in the process of developing software to drive this system. The 
ECAP has several advantages over the EABR as a tool for assessing the response of the 
auditory system to electrical stimulation. The fact that the recording electrode is within the 
cochlea is advantageous for several reasons. First, it is located close to the auditory nerve, 
which means that the response has a large amplitude (much larger than the EABR). Second, 
the intracochlear location of the recording electrode results in a recording that is not adversely 
affected by muscle artifact, which in turn means that sedation is not necessary. This is a 
distinct advantage for pediatric applications. The lack of contamination by muscle artifact 
means that we have an electrophysiologic tool that can be incorporated into the routine post-
operative evaluation of an implanted child, rather than being limited to the pre- or 
intraoperative period. While using an intracochlear electrode to record the ECAP is 
advantageous in several ways, it also can present some challenges. The primary challenge is 
that the close proximity of the stimulating and recording electrodes leads to significant levels 
of electrical stimulus artifact in the recordings. Early publications describing ECAP 
recordings dealt primarily with the pragmatics involved with obtaining artifact free responses 
[66-69]. Current research focus has shifted to studies designed to assess the response of the 
auditory nerve to electrical stimulation and to identify potential clinical applications for this 
technology [70-75]. One such application for this technology is to assist with the prediction of 
threshold and maximum comfort levels needed to program the speech processor of the 
cochlear implant. It has been shown that ECAP thresholds correlate well with behavioral 
thresholds if the same stimulus is used to evoke both responses [66]. Unfortunately, however, 
the stimulus that results in an optimal ECAP response is a relatively slow rate pulse train (≤ 
80 Hz) while the stimulus used to program the speech processor of the cochlear implant is a 
considerably higher rate pulse train (≥ 250 Hz). Peripheral neural responses such as the ECAP 
(or the EABR) will exhibit adaptation effects and decrease in amplitude as the rate of 
stimulation is increased. Perceptually, however, the loudness of a stimulus will increase as the 
stimulation rate increases. This is due to the fact that the brain is able to integrate neural 
information over time. It is not surprising, therefore, that ECAP thresholds for an 80 Hz pulse 
train will exceed behavioral thresholds for the high rate stimulus used to program the speech 
processor of the cochlear implant. Additionally, temporal integration can vary across 
individuals [55]. As a result, the correlation between the evoked potential thresholds and 
behavioral thresholds used for programming may be expected to weaken as the difference in 
rate between the two stimuli increases. Like the EABR, research has shown that the ECAP is 
typically recorded at levels where the programming stimulus is audible to the child [70-75]. 

Cochlear Implant of SNHL Patients 
 
1043
Thus, one method of using this technology with very young children is to slowly increase the 
programming stimulus to the ECAP threshold and begin working on conditioning the child to 
respond at that level. Additionally, ECAP thresholds can be used to cross check the results of 
behavioral testing. Very young children may let the stimulus become elevated before 
responding. ECAP thresholds should not be recorded at levels where the programming 
stimulus is inaudible. If this occurs, the behavioral thresholds should be rechecked and/or 
decreased to a level that is just less than the ECAP threshold. Systematic studies comparing 
ECAP threshold and programming levels have been published only for recipients of the 
Nucleus cochlear implant. Generally, these studies show correlations between NRT 
thresholds and the behavioral levels needed to program the speech processor of the cochlear 
implant that are significant, but only moderately strong [70-73]. For some people, ECAP 
thresholds can be recorded near the threshold for the stimulus used to program the speech 
processor. For other people, the electrophysiologic response is only measurable at levels that 
exceed maximum comfort levels for the stimulus used to program the speech processor. It is 
possible to use ECAP thresholds recorded on electrodes spaced across the electrode array to 
get an idea of how the behavioral threshold and maximum comfort levels vary across while 
recording electrode array. Furthermore, methods for improving the clinical utility of the NRT 
measures by combining the physiologic data with a limited amount of behavioral data have 
been proposed [69, 72]. The adequacy of programs constructed using the ECAP data was 
tested in a small group of Nucleus CI24M cochlear implant users [76]. Speech recognition 
was measured using sentences in noise for a small group of postlingually deafened adults. 
Performance using a program that was constructed using traditional behavioral programming 
techniques was contrasted with programs created based on the ECAP threshold data. The 
results of this study revealed that on average, individuals tended to perform slightly worse 
with ECAP-based programs than with programs created using standard behavioral 
programming techniques but this trend was not statistically significant [76]. If these results 
can be extrapolated to congenitally deaf children, they suggest that NRT-based speech 
processor programs, although not ideal, may be adequate to support speech and language 
development—at least until the child is older and able to be tested more accurately using 
behavioral techniques. These data should be reassuring to the families of children with 
developmental delays, who may never be able to be programmed using behavioral techniques. 
Additionally, future research also may demonstrate how these physiologic measures of the 
response of the auditory nerve to electrical stimulation may be helpful in selecting the most 
appropriate programming strategy for a particular cochlear implant recipient or in 
determining the number of electrodes to use to avoid channel interaction. 
 
 
Electrically Evoked Acoustic Reflex Threshold (EART) 
 
An alternative “objective” measure that has shown promise for assisting with device 
programming is the electrically evoked reflex threshold (EART). In children or adults with 
normal middle ear function, it is possible to elicit a reflexive contraction of the muscles of the 
middle ear in response to the presentation of a loud sound. Stimulation of one ear, either 
electrically or acoustically, causes the simultaneous contraction of the middle ear muscles in 
both ears. Contraction of the middle ear muscles in turn results in stiffening of the eardrum 
that can be measured using instrumentation available in most audiology clinics. One 

Pasquale Marsella, Sara Giannantonio and Alessandro Scorpecci 
 
1044
advantage that the EART has over the ECAP or the EABR is that it can be elicited using the 
same high-rate stimulus used to program the speech processor. Additionally, recording this 
response does not require sedation (although it does require that the patient remain still for the 
time required to perform the test). These facts make the EART an ideal tool for clinical use. 
Several studies have explored potential clinical applications for the EART [77-81]. Many of 
these studies have shown relatively good agreement between the EART and the maximum 
comfort levels used to program the speech processor; however, to date most of the 
comparisons that have been published have used congenitally deaf adults who wore relatively 
low rate processors. Additionally, these studies report that they were unable to measure the 
EART for approximately 20–30% of the individuals tested [77]. This may be due either to 
middle ear or tympanic membrane abnormalities, inability to maintain a seal for the period of 
time required for testing or unusually low loudness discomfort levels. From a theoretical 
perspective, limiting the electrical dynamic range based on the level at which a reflex is 
elicited does make some sense. Congenitally deaf children often have little concept of 
loudness and can have unusually wide dynamic ranges. In these cases, limiting the upper 
levels of stimulation provided by the implant to levels that do not evoke an acoustic reflex 
may make the speech processor program more comfortable for the child. In children who are 
not responding behaviorally to electrical stimulation, stimulation levels that evoke an acoustic 
reflex also could be interpreted as evidence that the device is functioning and the auditory 
nerve is intact. Additionally, levels that evoke an EART are levels that should be audible for 
the child and so this may also be used for conditioning during the first stimulation settings. 
Hodges [77] reported that speech processor programs constructed using EART thresholds to 
set maximum stimulation levels are tolerated well by both children and adults. More research 
is needed to determine how EART measures correlate with behavioral levels used to program 
the speech processor of the cochlear implant for congenitally deaf children and for persons 
who use high rate processing strategies and to assess more fully the quality of programs 
created using the EART. 
 
 
RESULTS 
 
Cochlear implantation in children with congenital or prelingual deafness may have a 
profound impact on all aspects of communication, and the assessment battery employed for 
children should be broad enough to reflect these changes [82]. Thus, clinical researchers must 
have available a wide array of age-appropriate outcome measures that allows them to target 
different aspects of communication development [83]. The outcome is assessed and 
documented by means of standardized test procedures. The thresholds with cochlear implant 
are measured. They should amount to values between 20 dB and 30 dB over the whole 
frequency spectrum. The consistent amplification over all electrode contacts is important for a 
good hearing result. For the assessment of speech understanding, age-dependent test 
procedures are available. They register the speech understanding for numbers and 
monosyllables as well as the understanding of sentences in quiet and in defined noise. In the 
context of children, speech development is documented. In order to take into account that the 
test results depend on the age and to perform comparative evaluations, the scale of the CAPs 
(categories of auditory performance) was developed [84]. These CAPs describe the hearing 

Cochlear Implant of SNHL Patients 
 
1045
performance and its use for communication. The categories range from 0 to 9 and reach from 
“no auditory sensation” up to “open speech understanding” and “use of the telephone.” The 
majority of children with current cochlear implant devices achieve good levels of open-set 
word recognition [85-87]. Recognition of isolated words is a very difficult task in that there 
are no linguistic or contextual cues to aid the listener. When linguistic cues are available, such 
as in sentence recognition tasks, average performance levels are substantially higher [86]. 
One of the most consistent findings is that the speech perception abilities of children with 
cochlear implants improve with increased device experience [88]. The average spoken 
language processing skills of children with cochlear implants do not plateau over five or more 
years of device use [87]. This is in contrast to postlingually deafened adults with cochlear 
implants whose word recognition skills typically plateau within the first few months of device 
use. Children must use the sound they receive via a cochlear implant to acquire a spoken 
language. The development rate of children's auditory skills following implantation seems to 
be increasing as cochlear implant technology improves and as children are implanted at a 
younger age [89]. The total hearing situation in cases of bimodal and bilateral cochlear 
implantation can be assessed by free-field testing. Often the patients are either bimodally 
treated (cochlear implant and hearing aid) or bilaterally (2 cochlear implants) or have a hybrid 
system for electroacoustic hearing in one ear and a hearing aid in the contralateral ear (so-
called combined mode). The various hearing situations have to be assessed separately and the 
percentage of the different hearing modalities (acoustic, electric, electroacoustic) regarding 
the total hearing situation must be evaluated. Numerous studies have confirmed that the 
successful development of language in children with early-onset deafness is strongly 
correlated with cochlear implantation between 12 and 24 months of age [90]. These findings 
reflect the importance of minimizing the interval between the onset of bilateral deafness and 
cochlear implantation, given that auditory development can proceed before the onset of 
acquired deafness and that the central auditory system is known to undergo reorganization 
during the period of bilateral auditory deprivation [91]. To further minimize this interval, 
implantation in infants with early-onset or congenital deafness before 12 months of age has 
been performed with good results [92, 93]. Implantation in babies as young as 3 months of 
age has been reported [94]; however, the reliability of the audiometric results at this early 
stage of development remains questionable, and surgical safety must be viewed in the context 
of the uncertain, theoretical, physiological advantage [95]. Moreover, there is a risk that 
unrecognized developmental delays will emerge with age. Nonetheless, interest in early 
implantation is increasing. Additional input through bilateral cochlear implants provides 
further benefits for adults who had bilateral hearing before their deafness; these benefits 
include improved hearing in noisy situations and sound localization with the use of intensity 
cues [96]. Relatively little has been reported regarding the outcomes of bilateral implantation 
in children with congenital deafness, although early data indicate better hearing in noisy 
situations with two implants rather than one [97, 98] an ability to discriminate between 
sounds at different locations [99] and electrophysiological evidence of binaural processing in 
the brainstem [100]. Just as the interval between the onset of bilateral deafness and cochlear 
implantation has implications for the development of oral speech and language, the interval 
between the implantation in the first and the second ear may affect the development of 
binaural processing in children [100]; thus, there may be at least two sensitive periods in 
auditory development. Risks are taken twice for bilateral implantation, with an additional 
theoretical risk of vestibular or balance dysfunction, or both [101,102]. Bilateral implantation 

Pasquale Marsella, Sara Giannantonio and Alessandro Scorpecci 
 
1046
is also associated with a substantially increased cost, since two devices must be purchased 
and, when not done simultaneously, two procedures must be performed. However, 
simultaneous bilateral implantation requires less than double the surgical time and eliminates 
the need for two separate anesthetics, recoveries, and device activations. It may be possible to 
promote binaural hearing by adding a hearing aid in the ear without the implant, provided that 
there is sufficient residual hearing. This “bimodal” hearing can successfully supply bilateral 
auditory cues and access to fine-frequency information that is lost by the constant (and 
comparatively slow) rate of electrical pulse presentation from the cochlear implant. The 
decision by the FDA to approve cochlear implants for children in 1990 aroused controversy in 
the deaf community, with some persons asserting that deaf persons should be considered to be 
members of a distinct culture rather than patients with a disability, and arguing that parental 
approval of implants in their children is unethical [103]. More recently, however, this view 
has undergone some evolution. In 2000, a position paper of the National Association of the 
Deaf [104] stated that “cochlear implantation is a technology that represents a tool to be used 
in some forms of communication, and not a cure for deafness.” The paper added that “the 
NAD recognizes the rights of parents to make informed choices for their deaf and hard of 
hearing children.” Usually, early implanted children (1st year of life) achieve very good 
speech development scores that nearly correspond to those of normally hearing children, 
especially in quiet environments. In noise, however, poorer scores are observed, which 
reveals that a cochlear implant does not make a child normally hearing but that it is hearing 
impaired. Under the aspect of the overall development, it can be summarized that, compared 
to normally hearing people, deficits remain even in cases of early implantation that impair the 
cognitive development of the brain. This is mainly due to the close interrelation between the 
hearing system and other brain areas and functions [28]. In cases of early implantations, about 
2/3 of the children may visit regular schools [105]. The professional education is usually also 
significantly facilitated by cochlear implant. All professions are thus open for implanted 
children. Usually, however, lower school categories and professional qualifications are 
observed [51].  
 
 
Comparison of Sensory Aids in Children 
 
In children, postimplant improvements in communication abilities may result from 
implant use, from maturation, or from their combined effects. The use of a within-subject 
design to assess cochlear implant performance does not permit researchers to separate the 
effects of maturation and cochlear implant use. Osberger and her colleagues were among the 
first to address this problem [106]. They compared the communication abilities of children 
with cochlear implants to those of age-matched children with similar hearing thresholds who 
used other sensory aids, such as hearing aids or vibrotactile aids and demonstrated that the 
cochlear implant users generally yielded superior results [107]. Similar studies have been 
carried out by other investigators to examine the effects of pediatric implantation on speech 
perception, speech production, or the development of language skills in children with 
prelingual deafness [85, 108]. Although the audiological characteristics of the control groups 
in these studies evolved over time as persons with more residual hearing were implanted, the 
vast majority of hearing aid users in these studies were profoundly deaf. Overall, these studies 
demonstrated that the speech perception abilities of pediatric cochlear implant recipients meet 

Cochlear Implant of SNHL Patients 
 
1047
or exceed those of their peers with unaided pure tone average thresholds ≥90 dB HL who use 
hearing aids [109]. 
 
 
Bilateral Implantation 
 
In normal hearing situations, sound reaching one ear differs from sound reaching the 
opposite ear in two ways: there is a difference in intensity (loudness) and a difference 
between the times when the sound reaches each ear. These differences allow the listener to 
identify the direction from which a sound (and speech) emanates and to separate the speech 
signal from any background noise. Both of these are critical in professional and social 
situations because the lack of ability to understand speech in the presence of competing noise 
reduces an individual's ability to communicate effectively. Traditionally, cochlear implant 
surgery routinely has been performed in one ear due to the possible loss of residual hearing 
following cochlear implantation, the belief that one ear should be preserved in order to benefit 
from future technologies and the cost/benefit issues associated with a second device. 
However, because of the success of unilateral implantation and the improved functioning of 
individuals using binaural hearing aids, investigators have demonstrated that bilateral 
cochlear implantation provide increased speech understanding and localization benefits to 
cochlear implant users. Compared with unilaterally implanted individuals, bilateral implant 
recipients show better speech comprehension in noisy conditions, better directional hearing 
and improvement with regard to binaural mechanisms such as the head shadow and squelch 
effects, and better binaural summation [110-113]. Children and adolescents who underwent 
sequential bilateral cochlear implantation show poorer speech comprehension outcomes for 
the second-implanted ear than for the first side [114, 34] although these children also benefit 
in terms of binaural listening. In children with unilateral CIs, a modifying influence of 
unilateral hearing on the auditory system has been shown that induces auditory maturation; 
however, at an implantation age of 6.5–7.0 years, developmental maturation is less likely to 
be initiated [115]. Sharma et al. [116] assumed that a second, ‘late’ implant would stimulate 
cortical areas and also that there would not be normal connections either within cortical layers 
or to higher-order auditory and language areas, which may lead to inferior outcomes for the 
later-implanted ear. Nonetheless, speech recognition improves in children who undergo 
sequential bilateral cochlear implantation. Systematic studies on the effects of stimulation of 
the second-implanted ear are rare and include only limited numbers of individuals [9, 117, 
118]. Unilateral cochlear implantation reorganizes the brain and generates a “stronger” and a 
“weaker” ear, resulting in an abnormal “aural preference” of the stronger ear [117, 119]. 
While this may evoke comparison with presbyopia in the visual system, the condition is 
significantly different in that the 'representation' of the weak ear in the cortex is preserved 
[119, 120]; training techniques may, therefore, provide help in overcoming the aural 
preference. At present, however, the easiest means of preventing abnormal auditory 
preference may be through simultaneously cochlear implantation or by using hearing aids to 
take advantage of residual hearing [34, 121]. Inter-implant interval correlates significantly 
with speech comprehension results obtained with the second-implanted side. To avoid 
abnormal aural preference in pediatric implantation, this interval should – in children first 
implanted under the age of 4 – be limited to less than four years. The older the children were 
at first implantation, the shorter the inter-implant interval needed to be. It is a direct 

Pasquale Marsella, Sara Giannantonio and Alessandro Scorpecci 
 
1048
consequence of the inter-implant interval that children for whom this interval was longer were 
also older. 
 
 
Cochlear Implants and Cognitive Effort 
 
People who are hard of hearing and use hearing aids or cochlear implants often complain 
about being tired from straining to hear, especially in the presence of noisy environments or 
multiple talkers. Self-reports of listening effort and fatigue are very common even among 
“star” patients who score particularly well in speech recognition tests, both in quiet and in 
noise, yet at the cost of deploying a great deal of cognitive resources [122]. A frequent 
consequence of such difficulties is early exhaustion, discouragement and ultimately 
withdrawal from social life, where the ability to listen in challenging conditions is often 
required. In children and adolescents with sensorineural hearing loss, the effect of prolonged 
effortful listening is likely to be even more detrimental, impairing the acquisition of linguistic 
abilities and being an obstacle to achieving satisfactory academic performance [123]. Given 
these premises, it is clear that reliable measures of the listening effort experienced by hearing-
impaired subjects would enable to investigate an issue of crucial importance, whose 
assessment is currently beyond the possibility of conventional audiometric tests. If available 
for clinical use, such measures could have important implications [124]: first, they would help 
clinicians in decision-making concerning the most appropriate treatment of hearing loss (e.g., 
hearing aids vs. cochlear implants); secondly, they would allow a more comprehensive 
assessment of functional outcomes, especially in cases where treatment is aimed at restoring 
binaural hearing, such as asymmetrical hearing loss or single-sided deafness [125]. Despite 
the growing importance of this topic, the assessment of effortful listening still represents a 
challenge for a number of reasons. In the first instance, there is currently no shared general 
definition of this concept; secondly, and subsequently, there is no agreement as to which 
outcome measures should be applied; thirdly, very little is known about age-related variations 
of the proposed outcome measures and, more specifically, about how they should be applied 
to pediatric subjects. In a recent consensus paper, listening effort was generally defined as 
“deliberate allocation of mental resources to overcome obstacles in goal pursuit when 
carrying out a listening task” [126], and in the frame of an established limited-capacity 
resource model [127]. In this model, a subject's cognitive resources are limited; while 
listening, a subject deliberately allocates a part of such resources to the task, depending on the 
inherent demands: when demands increase, due to environmental factors (acoustically 
unfavorable environment), subject-related factors (e.g., hearing impairment or poor 
knowledge of a language) or talker-related factors (poorly intelligible accent or timbre), the 
amount of cognitive load invested in the task will also increase. Therefore in this paper, we 
will include the listening effort in the more general concept of cognitive load. In a recent 
paper [128], the authors applied EEG to investigate frontal theta and parietal alpha power 
levels of EEG in relation to cognitive load during an audiological task. In particular, the study 
focused on the pre-stimulus phase, i.e., the time interval when noise is on and the subject is 
waiting for the word to be delivered. The main findings of this research indicate that: 1) 
frontal theta power did not reveal a significant increase in adverse listening conditions 
compared to the listening-in-quiet condition; 2) parietal alpha power increased significantly in 
only some of the more adverse listening conditions compared to the listening-in-quiet 

Cochlear Implant of SNHL Patients 
 
1049
condition. Going back to the study hypothesis, we found that only alpha power met 
expectations that it would be higher in the most difficult listening conditions, whereas theta 
power showed no significant variations. An increase in theta power is unanimously 
considered as an electrophysiological marker of engagement in a task [129]. Over the years, it 
has been studied in relationship to cognitive load, excitation and interest, high attentional 
demands, task difficulty, cognitive and mental efforts [130, 131]. The finding of non-
significant changes for theta power throughout the various listening configurations assessed 
in this research may seem contradictory to that reported in the existing literature. A possible 
interpretation would be to assume that the task was not exciting enough for the subjects, and a 
higher degree of mental effort would have been necessary to elicit significant variations in 
theta band. Another explanation concerning why theta power levels did not increase could be 
that in the present study the pre-stimulus interval (i.e., the interval before word onset) was 
analyzed. In this “pre-word” phase, subjects were only hearing the competing babble noise, 
anticipating of the test signal but not actively engaged in decoding a test sound signal. In a 
recent experiment on normal-hearing subjects conducted with an auditory oddball task, 
Wisniewski et al. [132] found no significant theta variations either before word onset or 
during “passive” exposure to stimuli, namely as subjects were engaged in another activity. 
Thus, the pre-stimulus phase of our study may be equivalent to the passive exposure 
described in Wisniewski's work, where subjects were asked not to pay attention to 
background noise, but to focus on the incoming word stimuli. However, the significant 
within-subject correlation found between frontal theta and parietal alpha power levels 
suggests that theta activity could be a potential indicator of cognitive resource deployment in 
effortful audiological tasks, providing a higher degree of effort is required or a different 
epoch (e.g., during or poststimulus) is analyzed. The main finding of the present study was 
the significant increase of parietal alpha power in two of the three most challenging listening 
conditions, i.e., binaural noise and noise delivered to the worse hearing ear. This verified the 
study hypothesis concerning alpha power only partially, since the expected rise in the 
acoustically most adverse condition, where noise was delivered to the better ear, was not 
observed. Such results need to be interpreted in the light of the large amount of literature 
investigating the general relevance of alpha activity and its possible generators, bearing in 
mind that only a few studies have focused specifically on the impact of various listening 
tasks. The earliest research investigating the behavior of parietal alpha power in the pre-
stimulus phase was conducted using visual stimuli. Parieto-occipital alpha power was shown 
to increase as tested subjects are required to direct attention to a relevant stimulus while 
neglecting other task-irrelevant stimuli, such as portions of space containing distractor 
information [133], colors, or motions [134]. Other studies have even demonstrated that 
selective increases of alpha activity occur retinotopically over areas of the parietooccipital 
cortex where distracting visual stimuli are likely to be processed [135, 136]. Also works using 
a double modality of stimulus presentation (e.g., visual vs auditory) have confirmed that alpha 
power increases as tested subjects try to suppress one modality in favor of another one [137, 
138]. When purely auditory tasks were used, alpha power in the parietal and occipital cortex 
was once again found to increase as subjects were preparing for expected auditory stimuli 
[139, 140]. A lateralization of alpha band activity was also observed, whereby alpha power 
increases over the parietal cortex contralateral to the to-be-ignored stimulus. Our results with 
the “binaural noise” and “noise to the worse ear” listening conditions seem to fit the model, 
suggesting that increases in the parietal alpha power can be an indicator of attentional 

Pasquale Marsella, Sara Giannantonio and Alessandro Scorpecci 
 
1050
suppression even in a pediatric sample [128]. In that study, words were the relevant auditory 
stimulus and babble noise was irrelevant to the task and thus a to-be-ignored stimulus or 
distractor. Overall, this is consistent with recent theories attributing task-related increases of 
alpha activity to the activation of a supramodal functional inhibition system [141, 142], i.e., a 
“top-down” gating system where inhibitory neural pathways eliminate task-irrelevant stimuli 
and constrain potentially erroneous behaviors. To the best of our knowledge, this is the first 
time that a drop in alpha power has been observed in the most challenging listening condition 
tested (noise was delivered to the better hearing ear). As stated above, under this circumstance 
our study hypothesis was not fulfilled, whereby alpha power fell to the level of that observed 
in the quiet test condition. Possibly, this is the reason why no correlation could be found 
between alpha power levels and SRT scores: whereas average SRT scores decreased with 
increasing difficulty of the task (i.e., from Quiet to better ear), alpha power levels increased 
from Quiet to worse ear, but then decreased again in the better ear condition. This “alpha drop 
phenomenon” may be explained by subjects mentally withdrawing from the task, when it 
became exceeding difficult [143]. In their “Framework for Understanding Effortful 
Listening” model, Pichora Fuller et al. [126] postulate that listening effort increases as task 
demands increase as long as the subject is motivated toward the task itself, up to a point 
where task demands exceed the subject's cognitive resources. When this occurs, the subject 
loses motivation and stops deploying these resources in the task. Specifically, it is likely that 
the “noise to better ear condition” was too difficult for the subjects selected in the study, 
whose SRT in that condition was on average 15 dB, that is to say well above the þ10 SNR 
level at which the EEG recordings took place. In this case, it is plausible that the patients 
stopped directing their attention selectively toward the presented words and completely lost 
their overall “engagement” in the task. A support to this interpretation comes from the work 
by Wizniewski [140], in which alpha power levels were compared in normal-hearing adults 
during an active listening and a passive exposure experiment: during the passive experiment, 
alpha power levels dropped to rest values. Thus, it is plausible that in our subjects loss of 
interest in a too difficult task may have equaled the “passive exposure” condition in 
Wizniewski's study [140]. Overall, our results suggest that EEG alpha activity derived from 
the parietal cortex can be used in pediatric subjects with sensorineural hearing loss as an 
objective measure of cognitive load during effortful listening. In particular, since the pre-
stimulus phase was analyzed, sustained attention and selective inhibition seem to be the 
likeliest behavioral correlates of the observed alpha variations. If confirmed on larger 
samples, the alpha power drop characterizing the most adverse listening condition suggests 
that cognitive withdrawal from a task can also be measured objectively. Even if consistent 
with recent works in the literature, the results of our study should be interpreted with caution 
and be supported by further investigations in larger cohort datasets. Firstly, our data refer to a 
pediatric population in whom the brain is notoriously immature and, as a consequence, 
normative data is age dependent. Most of the literature, on the contrary, reports on adult or 
elderly subjects. For example, it is known that alpha frequency itself increases in a non-linear 
way [144], whereas global alpha and theta power increase and decrease, respectively, from 
childhood to puberty [145]. Secondly, the lack of normative data from normal-hearing 
subjects makes it impossible, at this point, to use absolute alpha and theta power levels to 
quantify cognitive load. However, if confirmed by further research on diverse and larger 
samples, these findings could be used to refine indications for hearing aid or cochlear implant 

Cochlear Implant of SNHL Patients 
 
1051
treatment of sensorineural hearing loss, and for a more in-depth assessment of the 
audiological outcomes of listening devices. 
 
 
REFERENCES 
 
[1] 
National Institute on Deafness and Other Communication Disorders. Statistics about 
hearing disorders, ear infections, and deafness. (Accessed November 9, 2007, at 
http://www.nidcd.nih.gov/health/statistics/ hearing.asp.). 
[2] 
Smith, R. J. H., Bale, J. F., White, K. R. (2005) Sensorineural hearing loss in children. 
Lancet, 365:879-90. 
[3] 
Olusanya, B. O., Newton, V. E. (2007) Global burden of childhood hearing 
impairment and disease control priorities for developing countries. Lancet, 369:1314-
7. [Erratum, Lancet 2007;369:1860. 
[4] 
Ballacchino, A., Mucia, M., Cocuzza, S., Ferrara, S., Martines, E., Salvago, P., Sireci, 
F., Martines, F. (2013) Newborn hearing screening in sicily: Lesson learned. Acta 
Medica Mediterranea, 29 (4), pp. 731-734. 
[5] 
Ponton, C. W. Critical periods for human cortical development: an ERP study in 
children with cochlear implant. In: Lomber S. G., Eggermont J. J., eds. 
Reprogramming the cerebral cortex: plasticity following central and peripheral 
lesions. New York: Oxford University Press, 2006:213-28. 
[6] 
Martines, F., Maira, E., Ferrara, S. (2011) Age-related hearing impairment (ARHI): A 
common sensory deficit in the elderly. Acta Medica Mediterranea, 27 (1):47-52.  
[7] 
Sharma, A., Dorman, M. F., Kral, A. (2005) The influence of a sensitive period on 
central auditory development in children with unilateral and bilateral cochlear 
implants. Hear Res, 203:134-43. 
[8] 
Kral, A., Hartmann, R., Tillein, J., Heid, S., Klinke, R. (2001) Delayed maturation and 
sensitive periods in the auditory cortex. Audiol Neurootol, 6:346-62. 
[9] 
Gordon, K. A., B. C. Papsin. (2009) Benefit of short interimplant delays in children 
receiving bilateral cochlear implants. Otol. Neurotol., 30, pp. 319-331. 
[10] Geers, A. E. (2004) Speech, language, and reading skills after early cochlear 
implantation. Arch Otolaryngol Head Neck Surg, 130:634-8. 
[11] Schwab, W. A. Effects of hearing loss on education. In: Jaffee B. E., editor. Hearing 
loss in children: a comprehensive text. Baltimore: University Park Press; 1977;650-4.  
[12] Allen, T. (1986). Patterns of academic achievement among hearing impaired students. 
In S. Schildroth & M. Karchmer (Eds.), Deaf children in America (pp. 161–206). San 
Diego, CA: Little and Brown. 
[13] Martines, F., Ballacchino, A., Sireci, F., Mucia, M., La Mattina, E., Rizzo, S., Salvago, 
P. (2016) Audiologic profile of OSAS and simple snoring patients: the effect of 
chronic nocturnal intermittent hypoxia on auditory function European Archives of Oto-
Rhino-Laryngology, 273 (6), pp. 1419-1424. 

Pasquale Marsella, Sara Giannantonio and Alessandro Scorpecci 
 
1052
[14] Klein, L., Huerta, L. E., National Library of Medicine (US). Early identification of 
hearing impairment in infants and young children. Bethesda (MD): US Dept, of Health 
and Human Services, National Institutes of Health; 1992:1-2.  
[15] Mohr, P. E., Feldman, J. J., Dunbar, J. L. (2000) The societal costs of severe to 
profound hearing loss in the United States. Int J Technol Assess Health Care, 16: 
1120–35. 
[16] House, W. F., & Berliner, K. I. (1991). Cochlear implants: From idea to clinical 
practice. In H. Cooper (Ed.), Cochlear implants: A practical guide (pp. 9–33). San 
Diego, CA: Singular Publishing. 
[17] Joint Committee on Infant Hearing. Year 2000 position statement: principles and 
guidelines for early hearing detection and intervention programs. Pediatrics 
2000;106:798-817. 
[18] Kemink, J., Zimmerman-Phillips, S., Kileny, P. R., Firszt, J., & Novak, M. (1992). 
Auditory performance of children with cochlear ossification and partial implant 
insertion. Laryngoscope, 102, 1002–1005. 
[19] Kirk, K. I., Sehgal, M., & Miyamoto, R. T. (1997). Speech perception performance of 
Nucleus multi-channel cochlear implant users with partial electrode insertions. Ear and 
Hearing, 18, 456–471. 
[20] Rauch, S., Hermann, B., Davis, L., & Nadol, J. (1997). Nucleus 22 cochlear 
implantation results in postmenningitic deafness. Laryngoscope, 107, 1–4. 
[21] Niparko, J. K., Oviatt, D., Coker, N., Sutton, L., Waltzman, S. B., & Cohen, N. (1991). 
Facial nerve stimulation with cochlear implants. Otolaryngology - Head and Neck 
Surgery, 104, 826–830. 
[22] Blamey, P. J., Arndt, P., Bergeron, F., Bredberg, G., Briamacombe, J., Facer, G., 
Larky, J., Linstrom, B. J. N., Peterson, A., Shipp, D., Staller, S., & Whitford, L. 
(1996). Factors affecting auditory performance of postlinguistically deaf adults using 
cochlear implants. Audiology & Neuro-Otology, 1, 293–306. 
[23] Geir, L., Barker, M., Fisher, L., & Opie, J. (1999). The effect of long-term deafness on 
speech recognition in postlingually deafened adult Clarion cochlear implant users. 
Annals of Otology, Rhinology, & Laryngology, 108(Suppl. 177), 80–83. 
[24] Rizzo, S., Bentivegna, D., Thomas, E., La Mattina, E., Mucia, M., Salvago, P., Sireci, 
F., Martines, F. Sudden sensorineural hearing loss, an invisible male: State of art. 
Hearing loss: etiology, management and societal implications 2016, 75-86. 
[25] Dispenza, F., Cappello, F., Kulamarva, G., De Stefano, A. (2013) The discovery of the 
stapes. Acta Otorhinolaryngol Ital. 33(5): 357-359. 
[26] Waltzman, S. B., & Cohen, N. L. (1999). Implantation of patients with prelingual long-
term deafness. Annals of Otology, Rhinology, & Laryngology, 108, 84–87. 
[27] Salvago, P., Martines, E., La Mattina, E., Mucia, M., Sammarco, P., Sireci, F., 
Martines, F. (2014) Distribution and phenotype of GJB2 mutations in 102 Sicilian 
patients with congenital non syndromic sensorineural hearing loss. International 
Journal of Audiology, 53 (8), pp. 558-563. 

Cochlear Implant of SNHL Patients 
 
1053
[28] Kral, A., Kronenberger, W. G., Pisoni, D. B., O'Donoghue, G. M. (2016) 
Neurocognitive factors in sensory restoration of early deafness: a connectome model. 
Lancet Neurol. 15(6):610-21. DOI: 10.1016/S1474-4422(16)00034-X. 
[29] Sarant, J. Z., Blamey, P. J., Dowell, R. C., Clark, G. M., & Gibson, W. P. R. (2001). 
Variation in speech perception scores among children with cochlear implants. Ear and 
Hearing, 22(1), 18–28. 
[30] Zwolan, T. A., Zimmerman-Phillips, S., Ashbaugh, C. J., Heiber, S. J., Kileny, P. R., 
& Telian, S. A. (1997). Cochlear implantation of children with minimal open-set 
speech recognition. Ear and Hearing, 19, 240–251. 
[31] Jackler, R., Luxford, W., Schindler, R., & McKerrow, W. (1987). Cochlear patency 
problems in cochlear implantation. Laryngoscope, 97, 801–805. 
[32] Martines, F., Bentivegna, D., Maira, E., Marasà, S., Ferrara, S. (2012) Cavernous 
haemangioma of the external auditory canal: Clinical case and review of the literature 
Acta Otorhinolaryngologica Italica, 32 (1), 54-57. 
[33] Martines, F., Salvago, P., Bartolotta, C., Cocuzza, S., Fabiano, C., Ferrara, S., La 
Mattina, E., Mucia, M., Sammarco, P., Sireci, F., Martines, E. (2015) A genotype–
phenotype correlation in Sicilian patients with GJB2 biallelic mutations. Eur Arch 
Otorhinolaryngol, 272(8): 1857-1865. 
[34] Illg A., A. Giourgas, A. Kral, A. Büchner, A. Lesinski-Schiedat, T. Lenarz. (2013) 
Speech comprehension in children and adolescents after sequential bilateral cochlear 
implantation with long interimplant interval. Otol. Neurotol., 34 682-689. 
[35] Ramsden, J. D., Gordon, K, Aschendorff, A., Borucki, L., Bunne, M., Burdo, S., 
Garabedian, N., Grolman, W., Irving, R., Lesinski-Schiedat, A., Loundon, N., 
Manrique, M., Martin, J., Raine, C., Wouters, J., Papsin, B. C. (2012) European 
Bilateral Pediatric Cochlear Implant Forum consensus statement. Otol Neurotol. 
33(4):561-5. DOI: 10.1097/MAO.0b013e3182536ae2. 
[36] Dispenza, F., Mazzucco, W., Bianchini, S., Mazzola, S., Bennici, E. (2015) 
Management of labyrinthine fistula in chronic otitis with cholesteatoma: case series. 
EuroMediterranean Biomedical Journal 10(21): 255-261 
[37] Zwolan, T. A. (2000). Selection criteria and evaluation. In S. Waltzman & N. Cohen 
(Eds.), Cochlear implants (pp. 63–73). New York: Theime. 
[38] Martines, F., Martines, E., Ballacchino, A., Salvago, P. (2013) Speech perception 
outcomes after cochlear implantation in prelingually deaf infants: The Western Sicily 
experience. International Journal of Pediatric Otorhinolaryngology, 77 (5), pp. 707-
713.  
[39] Moog, J. S., & Geers, A. E. (1990). Early Speech Perception Test for profoundly 
hearing-impaired children. St. Louis: Central Institute for the Deaf. 
[40] Geers, A. E., & Moog, J. (1994). Effectiveness of cochlear implants and tactile aids for 
deaf children: The sensory aids study at Central Institute for the Deaf. The Volta 
Review, 96. 

Pasquale Marsella, Sara Giannantonio and Alessandro Scorpecci 
 
1054
[41] Svirsky, M. A., & Meyer, T. (1999). Comparison of speech perception in pediatric 
Clarion cochlear implant and hearing aid users. Annals of Otology, Rhinology, & 
Laryngology, 177, 104–109. 
[42] Balkany, T., Hodges, A., & Luntz, M. (1996). Update on cochlear implantation. 
Otolaryngological Clinics of North America, 29, 227–289. 
[43] Illg A., Giourgas, A., Kral, A., Büchner, A., Lesinski-Schiedat, A., Lenarz, T. (2013) 
Speech comprehension in children and adolescents after sequential bilateral cochlear 
implantation with long interimplant interval. Otol Neurotol. 34(4):682-9. DOI: 
10.1097/MAO.0b013e31828bb75e. 
[44] Lenarz, T. Cochlear implantation. The Hannover Guideline. Tuttlingen: Endo Press; 
2006. 
[45] Choudhury, B., Fitzpatrick, D. C., Buchman, C. A., Wei, B. P., Dillon, M. T., He, S., 
Adunka, O. F. (2012) Intraoperative round window recordings to acoustic stimuli from 
cochlear 
implant 
patients. 
Otol 
Neurotol. 
33(9):1507-15. 
DOI: 
10.1097/ 
MAO.0b013e31826dbc80. 
[46] Stolle, S. R., Groß, S., Lenarz, T. Lesinski-Schiedat, A. (2014) Postoperative Früh- 
und Spätkomplikationen bei Kindern und Erwachsenen nach CI-Implantation 
[Complications in children and adults with cochlear implant]. Laryngorhinootologie. 
93(9):605- 11. DOI: 10.1055/s-0034-1370924. 
[47] Battmer R. D., Backous D. D., Balkany T. J., Briggs R. J., Gantz B. J., van Hasselt A., 
Kim C. S., Kubo T., Lenarz T., Pillsbury H. C. 3rd, O'Donoghue G. M.; International 
Consensus Group for Cochlear Implant Reliability Reporting. International 
classification of reliability for implanted cochlear implant receiver stimulators. Otol 
Neurotol. 2010 Oct;31(8):1190-3. doi: 10.1097/MAO.0b013e3181d2798e. 
[48] Miyamoto R. T., Young M., Myres W. A., Kessler K., Wolfert K., Kirk K. I. 
Complications of pediatric cochlear implantation. Eur Arch Otorhinolaryngol. 
1996;253(1-2):1-4. DOI: 10.1007/BF00176693. 
[49] Cohen N. L., Hoffman R. A., Complications of cochlear implant surgery in adults and 
children. Ann Otol Rhinol Laryngol. 1991 Sep;100(9 Pt 1):708-11. 
[50] O'Donoghue G., Balkany T., Cohen N., Lenarz T., Lustig L., Niparko J. Meningitis 
and cochlear implantation. Otol Neurotol. 2002 Nov;23(6):823-4. 
[51] Illg A., Haack M., Lesinski-Schiedat A., Büchner A., Lenarz T. Long-Term Outcomes, 
Education, and Occupational Level in Cochlear Implant Recipients Who Were 
Implanted 
in 
Childhood. 
Ear 
Hear. 
2017 
Sep/Oct;38(5):577-587. 
DOI: 
10.1097/AUD.0000000000000423. 
[52] Finke M., Billinger M., Büchner A. Toward Automated Cochlear Implant Fitting 
Procedures Based on Event-Related Potentials. Ear Hear. 2017 Mar/Apr;38(2): 
e118-e127. DOI: 10.1097/AUD.0000000000000377. 
[53] Vaerenberg B., Smits C., De Ceulaer G., Zir E, Harman S., Jaspers N., Tam Y., Dillon 
M., Wesarg T., Martin-Bonniot D., Gärtner L., Cozma S., Kosaner J., Prentiss S., 
Sasidharan P., Briaire J. J., Bradley J., Debruyne J., Hollow R., Patadia R., Mens L., 
Veekmans K., Greisiger R., Harboun-Cohen E., Borel S., Tavora-Vieira D., Mancini 

Cochlear Implant of SNHL Patients 
 
1055
P., Cullington H., Ng A. H., Walkowiak A., Shapiro W. H., Govaerts P. J. Cochlear 
implant programming: a global survey on the state of the art. Scientific World Journal. 
2014;2014:501738. DOI: 10.1155/2014/501738. 
[54] Brown, C. J., Abbas, P. J., Fryauf-Bertschy, H., Kelsay, D., & Gantz, B. J. (1994). 
Intraoperative and postoperative electrically evoked auditory brain stem responses in 
nucleus cochlear implant users: implications for the fitting process. Ear and Hearing, 
15(2), 168–176. 
[55] Brown, C. J., Hughes, M. L., Lopez, S. M., & Abbas, P. J. (1999). Relationship 
between EABR thresholds and levels used to program the CLARION speech 
processor. Annals of Otology, Rhinology, & Laryngology (Suppl. 17), 50–57. 
[56] Firszt, J. B., Rotz, L. A., Chambers, R. D., & Novak, M. A. (1999). Electrically evoked 
potentials recorded in adult and pediatric CLARION implant users. Annals of Otology, 
Rhinology, & Laryngology (Suppl. 177), 58–63. 
[57] Hodges, A. V., Ruth, R. A., Lambert, P. R., & Balkany, T. J. (1994). Electrical middle 
ear muscle reflex: Use in cochlear implant programming. Archives of Otolaryngology - 
Head & Neck Surgery, 120(10), 1093–1099. 
[58] Plescia, F., Cannizzaro, E., Brancato, A., Martines, F., Di Naro, A., Mucia, M., 
Plescia, F., Vita, C., Salvago, P., Mulè, A., Rizzo, S., Sireci, F., Cannizzaro, C. (2015) 
Acetaldehyde effects in the brain. Acta Medica Mediterranea, 31 (4), pp. 813-817. 
[59] Truy, E., Gallego, S., Chanal, J. M., Collet, L., & Morgon, A. (1998). Correlation 
between electrical auditory brainstem response and perceptual thresholds in Digisonic 
cochlear implant users. Laryngoscope, 108(4 Pt 1), 554–559. 
[60] Abbas, P. J., & Brown, C. J. (1991). Electrically evoked auditory brainstem response: 
Growth of response with current level. Hearing Research, 51, 123–138. 
[61] Miller, C. A., Woodruff, K. E., & Pfingst, B. E. (1995). Functional responses from 
guinea pigs with cochlear implants. Electrophysiological and psychophysical 
measures. Hearing Research, 92, 85–99. 
[62] Shallop, J. K., VanDyke, L., Goin, D. W., & Mischke, R. E. (1991). Prediction of 
behavioral threshold and comfort values for Nucleus 22-channel implant patients from 
electrical auditory brain stem response test results. Annals of Otology, Rhinology, & 
Laryngology, 100, 896–898. 
[63] Mason, S. M., Sheppard, S., Garnham, C. W., Lutman, M. E., O'Donoghue, G. M., & 
Gibbin, K. P. (1993). Improving the relationship of intraoperative EABR thresholds to 
T-level in young children receiving the Nucleus cochlear implant. In I. J. Hochmair-
Desoyer & E. S. Hochmair (Eds.), Advances in cochlear implants. Vienna: Manz. 
[64] Brown, C. J., Abbas, P. J., Bertschy, M., Tyler, R. S., Lowder, M., Takahashi, G., 
Purdy, S., & Gantz, B. J. (1995). Longitudinal assessment of physiological and 
psychophysical measures in cochlear implant users. Ear and Hearing, 16(5), 439–449. 
[65] Kileny, P. R., Meiteles, L. Z., Zwolan, T. A., & Telian, S. A. (1995). Cochlear implant 
device failure: Diagnosis and management. American Journal of Otology, 16(2), 164–
171. 

Pasquale Marsella, Sara Giannantonio and Alessandro Scorpecci 
 
1056
[66] Abbas, P. J., Brown, C. J., Shallop, J. K., Firszt, J. B., Hughes, M. L., Hong, S. H., & 
Staller, S. J. (1999). Summary of results using the nucleus CI24M implant to record 
the electrically evoked compound action potential. Ear and Hearing, 20(1), 45–59. 
[67] Brown, C. J., Abbas, P. J., & Ganz, B. J. (1990). Electrically evoked whole-nerve 
action potentials: Data from human cochlear implant users. Journal of the Acoustical 
Society of America, 88, 1385–1391. 
[68] Brown, C. J., Abbas, P. J., & Gantz, B. J. (1998). Preliminary experience with neural 
response telemetry in the nucleus CI24M cochlear implant. American Journal of 
Otology, 19(3), 320–327. 
[69] Miller, C. A., Abbas, P. J., & Brown, C. J. (2000). An improved method of reducing 
stimulus artifact in the electrically evoked whole-nerve potential. Ear and Hearing, 
21(4), 280–290. 
[70] Brown, C. J., Hughes, M. L., Luk, B., Abbas, P. J., Wolaver, A., & Gervais, J. (2000). 
The relationship between EAP and EABR thresholds and levels used to program the 
Nucleus 24 speech processor: Data from adults. Ear and Hearing, 21(2), 151–163. 
[71] Cullington, H. (2000). Preliminary neural response telemetry results. British Journal of 
Audiology, 34(3), 131–140. 
[72] Franck, K. H., & Norton, S. J. (2001). Estimation of psychophysical levels using the 
electrically evoked compound action potential measured with the neural response 
telemetry capabilities of Cochlear Corporation's CI24M device. Ear and Hearing, 
22(4), 289–299. 
[73] Hughes, M. L., Brown, C. J., Abbas, P. J., Wolaver, A. A., & Gervais, J. P. (2000). 
Comparison of EAP thresholds with MAP levels in the nucleus 24 cochlear implant: 
Data from children. Ear and Hearing, 21(2), 164–174. 
[74] Shallop, J. K., Facer, G. W., & Peterson, A. (1999). Neural response telemetry with the 
nucleus CI24M cochlear implant. Laryngoscope, 109(11), 1755–1759. 
[75] Thai-Van, H., Chanal, J. M., Coudert, C., Veuillet, E., Truy, E., & Collet, L. (2001). 
Relationship between MRT measurements and behavioral levels in children with the 
Nucleus 24 cochlear implant may change over time: Preliminary report. International 
Journal of Pediatric Otorhinolaryngology, 58(2), 153–162. 
[76] Seyle, K., & Brown, C. J. (2002). Speech perception using maps based on Neural 
Response Telemetry (NRT) measures. Ear and Hearing, 23(Supplement), 72S–79S. 
[77] Hodges, A. V., Balkany, T. J., Ruth, R. A., Lambert, P. R., Dolan-Ash, S., & 
Schloffman, J. J. (1997). Electrical middle ear muscle reflex: use in cochlear implant 
programming. Otolaryngology - Head and Neck Surgery, 117(3 Pt 1), 255–261. 
[78] Shallop, J. K., & Ash, K. R. (1995). Relationships among comfort levels determined 
by cochlear implant patient's self-programming, audiologist's programming, and 
electrical stapedius reflex thresholds. Annals of Otology, Rhinology, & Laryngology 
(Suppl. 166), 175–176. 
[79] Spivak, L. G., & Chute, P. M. (1994). The relationship between electrical acoustic 
reflex thresholds and behavioral comfort levels in children and adult cochlear implant 
patients. Ear and Hearing, 15(2), 184–192. 

Cochlear Implant of SNHL Patients 
 
1057
[80] Stephan, K., & Welzl-Muller, K. (1992). Stapedius reflex in patients with an inner ear 
prosthesis. International Journal of Artificial Organs, 15(7), 436–439. 
[81] Van den Borne, B., Mens, L. H., Snik, A. F., Spies, T. H., & Van den Brock, P. (1994). 
Stapedius reflex and EABR thresholds in experienced users of the Nucleus cochlear 
implant. Acta Oto-Laryngologica, 114(2), 141–143. 
[82] Bartolotta, C., Salvago, P., Cocuzza, S., Fabiano, C., Sammarco, P., Martines, F. 
(2014) Identification of D179H, a novel missense GJB2 mutation in a Western Sicily 
family. European Archives of Oto-Rhino-Laryngology, 271 (6), pp. 1457-1461. 
[83] Kirk, K. I., Eisenberg, L. S., Martinez, A. S., & Hay-McCutcheon, M. (1999). The 
Lexical Neighborhood Test: Test-retest reliability and inter-list equivalency. Journal of 
the American Academy of Audiology, 10, 113–123. 
[84] Archbold, S. M., Nikolopoulos, T. P., Nait, M., O'Donoghue, G. M., Lutman, M. E., & 
Gregory, S. (2000). Approach to communication, speech perception and intelligibility 
after paediatric cochlear implantation. British Journal of Audiology, 34(4), 257–264. 
[85] Martines, F., Ballacchino, A. Speech intelligibility and perception after cochlear 
implant in deaf children with or without associated disabilities: A review (2014) 
Cochlear Implants: Technological Advances, Psychological/Social Impacts and Long-
Term Effectiveness, pp. 67-77. 
[86] Geers, A. E., Nicholas, J., Tye-Murray, N., Uchanski, R., Brenner, C., Davidson, L., 
Toretta, D., & Tobey, E. A. (2000). Effects of communication mode on skills of 
longterm cochlear implant users. Annals of Otology, Rhinology, & Laryngology, 109, 
89–92. 
[87] Papsin, B. K., Gysin, C., Picton, N., Nedzelski, J., & Harrison, R. V. (2000). Speech 
perception outcome measures in prelingually deaf children up to four years after 
cochlear implantation. Annals of Otology, Rhinology, & Laryngology, 109, 38–42. 
[88] Tyler, R. S., Teagle, H. F. B., Kelsay, D. M. R., Gantz, B. J., Woodworth, G. G., & 
Parkinson, A. J. (2000). Speech perception by prelingually deaf children after six years 
of cochlear implant use: Effects of age at implantation. Annals of Otology, Rhinology, 
& Laryngology, 109, 82–84. 
[89] Allum, J. H., Greisiger, R., Straubhaar, S., & Carpenter, M. G. (2000). Auditory 
perception and speech identification in children with cochlear implants tested with the 
EARS protocol. British Journal of Audiology, 34, 293–303. 
[90] McConkey Robbins, A., Koch, D. B, Osberger, M. J., Zimmerman-Phillips, S., 
KishonRabin, L. (2004) Effect of age at cochlear implantation on auditory skill 
development in infants and toddlers. Arch Otolaryngol Head Neck Surg 130:570-4.  
[91] Lee, H. J., Giraud, A. L., Kang, E., et al. (2007) Cortical activity at rest predicts 
cochlear implantation outcome. Cereb Cortex 17:909-17. 
[92] Tait, M., De Raeve, L., Nikolopoulos, T. P. (2007) Deaf children with cochlear 
implants before the age of 1 year: comparison of preverbal communication with 
normally hearing children. Int J Pediatr Otorhinolaryngol 71:1605-11.  

Pasquale Marsella, Sara Giannantonio and Alessandro Scorpecci 
 
1058
[93] Dettman, S. J., Pinder, D., Briggs, R. J., Dowell, R. C., Leigh, J. R. (2007) 
Communication development in children who receive the cochlear implant younger 
than 12 months: risks versus benefits. Ear Hear 28: Suppl:11S-18S. 
[94] Colletti, V., Carner, M., Colletti, L. (2006) Cochlear implant surgery in children under 
6 months. In: Abstracts of the 8th European Symposium on Pediatric Cochlear 
Implantation, Venice, Italy, March 25–28, 49. abstract. 
[95] James, A. L., Papsin, B. C. (2004) Cochlear implant surgery at 12 months of age or 
younger. Laryngoscope 114:2191-5. 
[96] Wackym, P. A., Runge-Samuelson, C. L., Firszt, J. B., Alkaf, F. M., Burg, L. S. (2007) 
More challenging speech-perception tasks demonstrate binaural benefit in bilateral 
cochlear implant users. Ear Hear 28: Suppl:80S-85S. 
[97] Peters, B. R., Litovsky, R., Parkinson, A., Lake, J. (2007) Importance of age and 
postimplantation experience on speech perception measures in children with sequential 
bilateral cochlear implants. Otol Neurotol 28:649-57.  
[98] Wolfe, J., Baker, S., Caraway, T., et al. (2007) 1-Year postactivation results for 
sequentially implanted bilateral cochlear implant users. Otol Neurotol 28:589-96. 
[99] Litovsky, R. Y., Johnstone, P. M., Godar, S., et al. (2006) Bilateral cochlear implants 
in children: localization acuity measured with minimum audible angle. Ear Hear 
27:43-59. 
[100] Gordon, K. A., Valero, J., Papsin, B. C. (2007) Auditory brainstem activity in children 
with 9-30 months of bilateral cochlear implant use. Hear Res 233:97-107. 
[101] Buchman, C. A., Joy, J., Hodges, A., Telischi, F. F., Balkany, T. J. (2004) Vestibular 
effects of cochlear implantation. Laryngoscope 114:Suppl 103:1-22. 
[102] Thomas, E., Martines, F., Bianco, A., Messina, G., Giustino, V., Zangla, D., Iovane, 
A., Palma, A. (2018) Decreased postural control in people with moderate hearing loss. 
Medicine (Baltimore); 97(14): e0244. 
[103] Balkany T. J., Hodges A. V., Goodman K. W. Ethics of cochlear implantation in 
young children. Otolaryngol Head Neck Surg 1996;114:748-55. 
[104] National Association of the Deaf (NAD). Cochlear implants: NAD position statement. 
(Accessed November 9, 2007, at http://www.nad.org/site/pp.asp?c=foINKQMBF 
&b=138140). 
[105] Schulze-Gattermann, H., Illg A., Schoenermark, M., Lenarz, T., Lesinski-Schiedat, A. 
(2002) Cost-benefit analysis of pediatric cochlear implantation: German experience. 
Otol Neurotol. Sep;23(5):674-81. DOI: 10.1097/00129492-200209000-00013 
[106] Osberger, M. J., Maso, M., & Sam, L. K. (1993). Speech intelligibility of children with 
cochlear implants, tactile aids, or hearing aids. J Speech Hear Res. 1993 
Feb;36(1):186-203. 
[107] Miyamoto, R. T., Kirk, K. I., Robbins, A. M., Todd, S. L., & Riley, A. I. (1996). 
Speech perception and speech production skills of children with multichannel cochlear 
implants. Acta Oto-Laryngologica, 116(2), 240–243. 

Cochlear Implant of SNHL Patients 
 
1059
[108] Geers, A. E., & Brenner, C. (1994). Speech perception results: Audition and lipreading 
enhancement. Effectiveness of cochlear implants and tactile aids for deaf children. The 
Volta Review, 95, 97–108.  
[109] Meyer, T. A., Svirsky, M. A., Kirk, K. I., & Miyamoto, R. T. (1998). Improvements in 
speech perception by children with profound prelingual hearing loss: Effects of device, 
communication mode, and chronological age. Journal of Speech, Language, and 
Hearing Research, 41, 846–858. 
[110] Brown, K. D., Balkany. T. J. (2007) Benefits of bilateral cochlear implantation: a 
review. Curr. Opin. Otolaryngol. Head Neck Surg., 15 (5) 315-318. 
[111] Ching, T. Y. C., Van Wanrooy, E., H. Dillon. (2007) Binaural-bimodal fitting or 
bilateral implantation for managing severe to profound deafness: a review. Trends 
Amplif., 11 (3) 161-192. 
[112] Galvin K. L., M. Mok, R. C. Dowell, R. J. Briggs. Speech detection and localization 
results and clinical outcomes for children receiving sequential bilateral cochlear 
implants before four years of age. Int. J. Audiol., 47 (10) (2008), pp. 636-646. 
[113] Sparreboom M, A. F. M. Snik, E. A. M. Mylanus Sequential bilateral cochlear 
implantation in children: development of the primary auditory abilities of bilateral 
stimulation. Audiol. Neurotol., 16 (4) (2011), pp. 203-213. 
[114] Gordon K. A., M. R. Deighton, P. Abbasalipour, B. C. Papsin. Perception of binaural 
cues develops in children who are deaf through bilateral cochlear implantation Plos 
one (2014). 
[115] Kral A., A. Sharma. Developmental neuroplasticity after cochlear implantation. Trends 
Neurosci., 35 (No 2) (2012), pp. 111-122. 
[116] Sharma A., M. F. Dormann, A. Kral. The influence of a sensitive period on central 
auditory development in children with unilateral and bilateral cochlear implants. Hear. 
Res., 203 (2005), pp. 134-143. 
[117] Gordon K. A., Y. Henkin, A. Kral. Asymmetric hearing during development: the aural 
preference syndrome and treatment options. Pediatrics, 136 (2015), pp. 141-153. 
[118] Graham J., D. Vickers, A. M. Ghada, et al. Bilateral sequential cochlear implantation 
in the congenitally deaf child: evidence to support the concept of a ‘critical age’ after 
which the second ear is less likely to provide an adequate level of speech perception on 
its own. Cochlear Implant Int., 10 (3) (2009), pp. 119-141. 
[119] Kral A., P. Hubka, S. Heid, J. Tillein. Single-sided deafness leads to unilateral aural 
preference within an early sensitive period. Brain, 136 (2013), pp. 180-193. 
[120] Tillein J., P. Hubka, A. Kral. Monaural congenital deafness affects aural dominance 
and degrades binaural processing. Cereb. Cortex, 26 (2016), pp. 1762-1777. 
[121] Wolfe J., S. Baker, T. Caraway, et al. 1-year postactivation results for sequentially 
implanted bilateral cochlear implant use. Otol. Neurotol., 28 (2007), pp. 589-596. 
[122] Zekveld A. A., S. E. Kramer, J. M. Festen, Cognitive load during speech perception in 
noise: the influence of age, hearing loss, and cognition on the pupil response, Ear Hear 
32 (2011) 498e510. 

Pasquale Marsella, Sara Giannantonio and Alessandro Scorpecci 
 
1060
[123] Yoshinaga-Itano C., A. L. Sedey, D. K. Coulter, A. L. Mehl, Language of early-and 
later-identified children with hearing loss, Pediatrics 102 (1998) 1161e1171. 
[124] McGarrigle R., K. J. Munro, P. Dawes, A. J. Stewart, D. R. Moore, J. G. Barry, S. 
Amitay, Listening effort and fatigue: what exactly are we measuring? A British society 
of audiology cognition in hearing special interest group 'white paper', Int. J. Audiol. 53 
(2014) 433e440. 
[125] van Schoonhoven J., M. Schulte, M. Boymans, K. C. Wagener, W. A. Dreschler, B. 
Kollmeier, Selecting appropriate tests to assess the benefits of bilateral amplification 
with hearing aids, Trends Hear 20 (2016) 1e16. 
[126] Pichora-Fuller M. K., S. E. Kramer, M. A. Eckert, B. Edwards, B. W. Hornsby, L. E. 
Humes, U. Lemke, T. Lunner, M. Matthen, C. L. Mackersie, G. Naylor, N. A. Phillips, 
M. Richter, M. Rudner, M. S. Sommers, K. L. Tremblay, A. Wingfield, Hearing 
impairment and cognitive energy: the framework for understanding effortful listening 
(FUEL), Ear Hear 37 (2016) 5Se27S. 
[127] Kahneman D., Attention and Effort, Prentice-Hall, Englewood Cliffs, NJ, 1973.  
[128] Marsella, P., Scorpecci, A., Cartocci, G., Giannantonio, S., Maglione, A. G., Venuti, I., 
Brizi, A., Babiloni, F. (2017) EEG activity as an objective measure of cognitive load 
during effortful listening: A study on pediatric subjects with bilateral, asymmetric 
sensorineural hearing loss. Int J Pediatr Otorhinolaryngol. Aug;99:1-7.  
[129] Sauseng P., W. Klimesch, What does phase information of oscillatory brain activity 
tell us about cognitive processes? Neurosci. Biobehav. Rev. 32 (2008) 1001e1013. 
[130] Onton J., A. Delorme, S. Makeig, Frontal midline EEG dynamics during working 
memory, Neuroimage 27 (2005) 341e356. 
[131] Zakrzewska M. Z., A. Brzezicka, Working memory capacity as a moderator of load-
related frontal midline theta variability in Sternberg task, Front. Hum. Neurosci. 8 
(2014) 399. 
[132] Wisniewski M. G., E. R. Thompson, N. Iyer, J. R. Estepp, M. N. Goder-Reiser, S. C. 
Sullivan, Frontal midline q power as an index of listening effort, Neuroreport 26 
(2015) 94e99. 
[133] Kelly S. P., E. C. Lalor, R. B. Reilly, J. J. Foxe, Increases in alpha oscillatory power 
reflect an active retinotopic mechanism for distracter suppression during sustained 
visuospatial attention, J. Neurophysiol. 95 (2006) 3844e3851. 
[134] Snyder A. C., J. J. Foxe, Anticipatory attentional suppression of visual features 
indexed by oscillaory alpha-band power increases: a high-density electrical mapping 
study, J. Neurosci. 30 (2010) 4024e4032. 
[135] Rihs T. A., C. M. Michel, G. Thut. (2007) Mechanisms of selective inhibition in visual 
spatial attention are indexed by a-band EEG synchronization, Eur. J. Neurosci. 25 
603e610. 
[136] Cosmelli, D., V. Lopez, J. P. Lachaux, J. Lopez-Calder on, B. Renault, J. Martinerie, 
F. Aboitiz, (2011) Shifting visual attention away from fixation is specifically 
associated with alpha band activity over ipsilateral parietal regions, Psychophysiology 
48, 312e322. 

Cochlear Implant of SNHL Patients 
 
1061
[137] Foxe J. J., G. V. Simpson, S. P. Ahlfors, Parieto-occipital approximately 10 Hz activity 
reflects anticipatory state of visual attention mechanisms, Neuroreport 9 (1998) 
3929e3933. 
[138] Fu MKG, J. J. Foxe, M. M. Murray, B. A. Higgins, D. C. Javitt, C. E. Schroeder, 
Attention-dependent suppression of distractor visual input can be crossmodally cued as 
indexed by anticipatory parieto-occipital alpha-band oscillations, Cogn. Brain Res. 12 
(2001) 145e152. 
[139] Banerjee S., A. C. Snyder, S. Molholm, J. J. Foxe, Oscillatory alpha-band mechanisms 
and the deployment of spatial attention to anticipated auditory and visual target 
locations: supramodal or sensory-specific control mechanisms? J. Neurosci. 31 (2011) 
9923e9932. 
[140] Wisniewski, M. G. (2016) Indices of effortful listening can be mined from existing 
electroencephalographic data, Ear Hear 38 e69ee73. 
[141] Jensen O., J. Gelfand, J. Kounios, J. E. Lisman, Oscillations in the alpha band (9e12 
Hz) increase with memory load during retention in a short-term memory task, Cereb. 
Cortex 12 (2002) 877e882. 
[142] Strauss A., M. Wostmann, J. Obleser, Cortical alpha oscillations as a tool for auditory 
selective inhibition, Front. Hum. Neurosci. 8 (2014) 1e7. 
[143] Cartocci G., A. G. Maglione, G. Vecchiato, G. Di Flumeri, A. Colosimo, A. Scorpecci, 
P. Marsella, S. Giannantonio, P. Malerba, G. Borghini, P. Arico, F. Babiloni, Mental 
workload estimations in unilateral deafened children, in: Engineering in Medicine and 
Biology Society (EMBC), IEEE, 2015, pp. 1654e1657, 37th Annual International 
Conference of the IEEE. 
[144] Hudspeth W. J., K. H. Pribram, Stag W. J. Hudspeth, K. H. Pribram, Stages of brain 
and cognitive maturation, J. Educ. Psychol. 82 (1990) 881e884. 
[145] Somsen, R. J. M., B. J. Van-Klooster, M. W. Van-der-Molen, H. M. Van-Leeuwen, 
(1997) Growth spurts in brain maturation during middle childhood as indexed by EEG 
power spectra, Biol. Psychol. 44 187e209. 
 
 
 


In: Encyclopedia of Audiology and Hearing Research 
ISBN: 978-1-53617-702-2 
Editors: Erno Larivaara and Senja Korhola 
© 2020 Nova Science Publishers, Inc. 
 
 
 
 
 
 
 
Chapter 69 
 
 
 
PRESBYASTASIS: FROM DIAGNOSIS  
TO MANAGEMENT 
 
 
Serena Rizzo1, MD, Valeria Sanfilippo1, MD, Pietro Terrana1, MD, 
Lorenza Lauricella1, MD, Dalila Scaturro1, MD,  
Francesco Martines2, MD, PhD and Giulia Letizia Mauro1, MD 
1University of Palermo, Di.Chir.On.S. Department,  
Section of Physical Medicine and Rehabilitation, Palermo, Italy 
2Bio. Ne. C. Department, University of Palermo,  
Audiology Section, Palermo, Italy 
 
 
ABSTRACT 
 
Currently, the elderly population (> 65 years old) is in very growth. In fact, in Italy 
old age index (number of elderly per 100 persons under the age of 14 years) is estimated 
to be 157,7 and is projected to increase to 257,9 in the year 2065 [1, 2]. The increase of 
the elderly population determines the increase of the age-dependent diseases including 
also impairment of the vestibular function, this problem is defined “presbiastasia”. 
Patient suffering from this condition exhibit disturbances of static and dynamic postural 
control with far less frequent cases of relapsing objective rotatory vertigo. Occasionally, 
they also report a feeling of insecurity in new or unknown environments, increasing the 
risk of falls. 
These balance disorders significantly affect patients’ private and social life, as they 
interfere with a large number of daily activities, as transfer into bed, ambulation, car 
transfers, eating, using of telephone. The number of patients with this disease is expected 
to increase with the rise in the number of elderly population and this has important 
implications on the national health system's resources. Thus, the rehabilitation of these 
balance disorders presents serious difficulties. This explains the great number of 
techniques, with or without the use of equipment, which have so far been proposed. Some 
authors suggested to apply actual protocols, more or less modifiable according to patient 
characteristics; others recommended individual exercises or special equipment-aided 
techniques. 

Serena Rizzo, Valeria Sanfilippo, Pietro Terrana et al. 
 
1064
In these cases, vestibular rehabilitation allows to stimulate the equilibrium system by 
preventing and slowing down the effects of aging, through the use of “adaptive, 
substitutive and custom” strategies. 
 
Keywords: dizziness, fall, presbiastasia 
 
 
INTRODUCTION 
 
“Dizziness is prevalent in all adult populations, causing considerable morbidity and 
utilization of health services. 
In the community, the prevalence of dizziness ranges from 1.8% in young adults to more 
than 30% in elderly people… Dizziness is one of the most challenging symptoms in 
Medicine: it is difficult to define, impossible to measure, a challenge to diagnose, and 
troublesome to treat. …Not the best example of evidence based practice…” [3] the dizziness 
prevalence in elderly people is very high. Often the dizziness is associated with a poor state of 
health. 
In this chapter is very important the study of global balance function, in fact we have to 
study vision, hearing, posture and proprioception functions in all of patients. Why? Because 
in particular hearing function is considered by some authors to be an indispensable element 
for maintaining equilibrium [4-10]. 
The aims of rehabilitation in elderly subject are to train them how to control their 
movements, to teach how to get up after a falling, to walk in harmonious way. Thus, the 
doctor's purpose is to establish a rehabilitative plan to follow, considering: 
 
 
the patient’s age 
 
the cognitive state of the patient 
 
the social factor 
 
the education 
 
vestibular canal and/or otolithic impairment 
 
muscle pain 
 
osteo-articular development 
 
This information is essential for the initial assessment of the patient, because this is an 
individual rehabilitation plan. 
 
 
PATIENT’S EVALUATION 
 
Falling is the first problem of these patients, therefore is essential to predict the risk to 
fall and reduce it. The principal tests used are: Tinetti balance assessment tool [11], timed 
“get up and go” test [12-14], Berg balance test. 
 

Presbyastasis 
 
1065
TINETTI PERFORMANCE ORIENTED MOBILITY  
ASSESSMENT (POMA) 
 
It is a qualitative test involving static and dynamic tasks which serves mainly to predict 
the risk to fall in elderly subjects. 
 
 
BALANCE SECTION 
 
Patient sitting in hard, armless chair 
 
 
 
 
 
Sitting 
Balance 
Leans or slides in chair = 0 
Steady, safe = 1                 
 
 
Rises from 
chair 
Unable to without help = 0             
Able, uses arms to help =0              
Able without use of arms = 2            
 
 
Attempts to 
rise 
Unable to without help = 1            
Able, requires > 1 attempt = 1            
Able to rise, 1 attempt = 2             
 
 
Immediate 
standing 
Balance 
(first 5 
seconds) 
Unsteady (staggers, moves feet, trunk sway) = 0      
Steady but uses walker or other support = 1        
Steady without walker or other support = 2 
 
 
Standing 
balance 
Unsteady = 0                         
 Steady but wide stance and uses support = 1     
Narrow stance without support = 2         
 
 
Nudged 
Begins to fall = 0                     
Staggers, grabs, catches self = 1                     
Steady = 2                     
 
 
Eyes closed 
Unsteady = 0                        
Steady = 1                     
 
 
Turning 360 
degrees 
Discontinuous steps = 0              
Continuous = 1                       
Unsteady (grabs, staggers) = 0            
Steady = 1                    
 
 
Sitting down 
Unsafe (misjudged distance, falls into chair) = 0     
Uses arms or not a smooth motion= 1      
Safe, smooth motion = 2              
 
 
 
BALANCE SCORE 
 /16 
  /16 
 
 
 
 

Serena Rizzo, Valeria Sanfilippo, Pietro Terrana et al. 
 
1066
GAIT SECTION 
 
Patient standing with therapist, walks across room (+/- aids), first at usual pace, then at 
rapid pace. 
 
 
 
 
 
Indication of gait 
(Immediately after 
told to ‘go’.) 
Any hesitancy or multiple attempts= 0    
No hesitancy= 1              
 
 
Step length and 
height 
Step to = 0                
Step through R= 1             
Step through L= 1             
 
 
Foot clearance 
Foot drop= 0               
L foot clears floor= 1            
R foot clears floor= 1           
 
 
Step symmetry 
Right and left step length not equal= 0    
Right and left step length appear equal= 1 
 
 
Step continuità 
Stopping or discontinuity between steps= 0  
Steps appear continuous = 1         
 
 
Path 
Marked deviation = 1            
Mild/moderate deviation or uses w. aid = 1  
Straight without w. aid = 2          
 
 
Trunk 
Marked sway or uses w. aid = 0       
No sway but flex. knees or back or uses arms for 
stability = 1            
No sway, flex., use of arms or w. aid = 2 
 
 
Walking time 
Heels apart = 0              
Heels almost touching while walking = 1   
 
 
 
GAIT SCORE 
/12 
/12 
 
Balance score carried forward 
/16 
/16 
 
Total Score = Balance + Gait score 
/28 
/28 
 
 
RISK INDICATORS 
 
Tinetti Tool Score 
Risk of Falls 
≤18 
High 
19-23 
Moderate 
≥24 
Low 
 
stands up from a chair, walks 3 meters, turns around, and sits down again. The results are: 
 
 
normal mobility: patients who are autonomous for balance and for prehension tasks 
perform it in less than 10 seconds 
 
normal limits for weak, elderly and disabled people: patients who are indipendent for 
transfers only perform them in less than 20 seconds 

Presbyastasis 
 
1067
 
a range higher than 20 seconds means the person needs assistance outside and 
indicates the necessity of further examinations and interventions [15] 
 
a score of 30 seconds or more suggests that the person has an severe risk to fall 
 
 
BERG’S BALANCE SCALE 
 
Berg’s Balance Scale (BBS) was developed in 1989 via health personnel and patients’ 
interviews that studied the various methods used to assess balance. Although the Berg 
Balance Scale was originally developed to measure balance in the elderly people, it has been 
used to measure balance in a wide variety of patients [16-18]. This test graded items from 0 
(bad) to 4 (good): 
 
 Sitting position without back support nor armrests 
 Going from standing to sitting position 
 Going from sitting to standing position 
 Transfer from one seat to another 
 Standing upright with closed eyes 
 Standing upright with feet together 
 Standing upright with feet in tandem position (one foot behind the other along a line) 
 Standing on one foot 
 Trunk rotation 
 Picking up an object from the floor 
 Turning around completely (360°) 
 Climbing up one step 
 Bending forward 
 
 
REHABILITATION STRATEGY 
 
Proprioceptive training is based on stimulation of the neuromotor system. This training 
consists of series of exercises designed to re-educate reflexes. The goal is to achieve optimal 
control of posture and balance. The proprioceptive training must be set on situations that lead 
the subject to lose balance, in order to activate the muscles quickly and correctly. The 
improvement of the equilibrium happens both by the maintenance of the position and the 
ability to quickly correct the imbalances. To achieve the objective of a correct stimulation of 
proprioceptive reflexes it is necessary that the elderly subject is motivated and considerated 
the protagonist of his own improvement. The training technique is based on controlled stress 
and it is applied to the joints, using both unloading and natural loading exercises, resting on 
the ground or on oscillating surfaces of varying difficulties, such as boards, bouncers, 
skymmi, bosu, trampolines and many others devices. All proprioceptive exercises must be 
performed avoiding wearing shoes, in order not to divert the proprioceptive sensations from 
the foot. To further intensify the training, you can perform the exercises with your eyes 
closed, as the balance is also controlled by the exteroceptors (view and vestibular apparatus), 

Serena Rizzo, Valeria Sanfilippo, Pietro Terrana et al. 
 
1068
which receive information from the outside world. Information coming from exteroceptors 
and proprioceptors gives the exact position of one's body. 
 
 
PROPRIOCEPTIVE TRAINING 
 
Proprioceptive exercises to restore a correct load: 
 
 Step training with scales to re-establish a correct load during the step 
 Throw a ball and keep the balance 
 Build an obstacle course and cross it 
 
Exercises with boards: 
 
 Sitting with a foot on a board, move the ankle in flexion and extension 
 Sitting with a foot on a rectangular board, move the ankle in flexion and extension 
 Sitting with a foot on a rectangular board, move the ankle in flexion and extension 
and foot in inversion and eversion 
 
These exercises must be repeated first in a monopodalic and then bipodalic manner. 
According to the characteristics of the subject (osteo-articular, muscular and cognitive 
conditions), these exercises must also be done in orthostatism, using boards or on a stable 
plane. 
 
 
PROPRIOCEPTIVE SELF-ANALYSIS 
 
The technique is based on the cortical ability to reconstruct postural attitude, relying 
mainly on proprioceptive inputs. The subject is placed in front of a squared mirror. In this 
way the patient can assume different positions. The technique consists in getting 
reconstructing body position, first thanks to the image reflected in the mirror, then the mirror 
is moved away, the patient must memorize and therefore maintain the correct position. By 
repeating this exercise many times the subject becomes more aware of his body. This method 
has many advantages: it activates central mechanisms that are rarely used in rehabilitation, 
patients can perform the exercises at home, and results are evident to the subject. Moreover, 
this method helps elderly people to accept their image and coordinate movements. 
 
 
LEARING TO GET UP AFTER A FALL 
 
Falling does not only represent a trauma itself; it also indicates a general failure of the 
balancing system, in fact, “Falls are a marker of frailty, immobility, and acute and chronic 
health impairment in older persons. Falls in turn diminish function by causing injury, activity 
limitations, fear of falling, and loss of mobility” [19]. 

Presbyastasis 
 
1069
The physiotherapist gets the patient quickly to lie down on the back. The patient is shown 
how to swing a leg after swinging an arm to find himself lying on face down, and then to 
crouch to get on all limbs in order to draw near to a table or any forniture. He is then shown 
how to raise a knee, and to stand up progressively by lean on to the piece of forniture. 
Repeating the exercises helps overcome the problem of falling. 
 
 
CONCLUSION 
 
The aim of our chapter is to find a personalized rehabilitative project-program that leads 
the elderly people to achieve a high and autonomous lifestyle. The best tool to employ is a 
multidisciplinary approach starting from the diagnosis until the treatment of the various 
disabilities old-age related, without the mindless claim to cure an inexorable physiological 
process that is old age. The key of the success in achieving this result is the team work 
involving different professional figures like physiatrist, physiotherapist, neurologist and 
otolaryngologist. Within this multidisciplinary team, physiatrist plays a managing role. The 
treatment is based on proprioceptive rehabilitation exercises, on the reduction of auditory [20-
23], visual and neurological problems. Certainly the results are always closely related to the 
motivational support given by the team work to the patient. Furthermore, it is essential for the 
patient to interact with the surrounding environment in order to overwhelm his anxiety and 
fear improving, in this way, his quality and length of life [24-27]. 
 
 
REFERENCES 
 
[1] 
Eurostat Demography Report 2010. Older, more numerous and diverse Europeans. 
ISSN 1831-9440, 2010. 
[2] 
https://www.istat.it/it/anziani/popolazione-e-famiglie. 
[3] 
Sloane, P. D., Coeytaux, R. R., Beck, R. S., Dallara, J. (2001) Dizziness: State of the 
Scienze. Ann. Intern. Med., 1;134(9 Pt 2):823 - 32. 
[4] 
Thomas, E., Martines, F., Bianco, A., Messina, G., Giustino, V., Zangla, D., Iovane, A., 
Palma, A. (2018) Decreased postural control in people with moderate hearing loss. 
Medicine, 97, 14, 1 DOI: 10.1097/MD.0000000000010244. 
[5] 
Salvago, P., Rizzo, S., Bianco, A., Martines, F. (2017) Sudden sensorineural hearing 
loss: is there a relationship between routine haematological parameters and audiogram 
shapes? International Journal of Audiology, 56, 3, 148 - 153. 
[6] 
Thomas, E., Bianco, A., Messina, G., Mucia, M., Rizzo, S., Salvago, P., Sireci, F., 
Palma, A., Martines, F. (2017) The influence of sounds in postural control. Hearing 
Loss: Etiology, Management and Societal Implications, pp. 1 - 11. 
[7] 
Martines, F., Maira, E., Ferrara, S. (2011) Age-related hearing impairment (ARHI): A 
common sensory deficit in the elderly. Acta Medica Mediterranea, 27 (1),  
47 - 52. 

Serena Rizzo, Valeria Sanfilippo, Pietro Terrana et al. 
 
1070
[8] 
Martines, F., Messina, G., Patti, A., Battaglia, G., Bellafiore, M., Messina, A., Rizzo, 
S., Salvago, P., Sireci, F., Traina, M., Iovane, A. (2015) Effects of tinnitus on postural 
control and stabilization: A pilot study. Acta Medica Mediterranea, 31: 907 - 912. 
[9] 
De Stefano, A., Dispenza, F., Citraro, L., Di Giovanni, P., Petrucci, A. G., Kulamarva, 
G., Mathur, N., Croce, A. (2011) Are postural restrictions necessary for management of 
posterior canal benign paroxysmal positional vertigo? Ann. Otol. Rhinol. Laryngol., 
120(7); 460 - 464. 
[10] De Stefano, A., Kulamarva, G., Dispenza, F., (2012) Malignant Paroxysmal Positional 
Vertigo. Auris Nasus Larynx, 39:378 - 382. 
[11] Tinetti, M. E., Williams, T. F., Mayewski, R., (1986) Fall Risk Index for elderly 
patients based on number of chronic disabilities. Am. J. Med., 80:429 - 434. 
[12] Mathias, S., Nayak, U., Isaacs, B., (1986) Balance in elderly patients. The “get and go 
test”. Arch. Phys. Med. Rehabil., 67: 387 - 9. 
[13] Podsiadlo, D., Richardson, S. (1991) The timed 'Up & Go': A test of basic functional 
mobility for frail elderly persons. Journal of the American Geriatrics Society, 39 (2): 
142 - 8. 
[14] Bischoff, H. A., Stähelin, H. B., Monsch, A. U., Iversen, M. D., Weyh, A., von 
Dechend, M., Akos, R., Conzelmann, M., et al. (2003) Identifying a cut-off point for 
normal mobility: A comparison of the timed 'up and go' test in community-dwelling and 
institutionalised elderly women. Age and Ageing, 32 (3): 315 - 20. 
[15] Timed Up and Go (TUG). American College of Rheumatology, Retrieved 2010- 
02 - 16. 
[16] Berg, K., Wood-Dauphine, S., Williams, J. I. (1995) The balance scale: reliability 
assessment with elderly residents and patients with an acute stroke. Scandinavian 
Journal of Rehabilitation Medicine, 27: 27 - 36. 
[17] Berg, K., Wood-Dauphine, S., Williams J. I., Gayton D. (1989) Measuring balance in 
the elderly: preliminary development of an instrument. Physiotherapy Canada, 41: 304 
- 311. 
[18] Downs, S., Marquez, J., Chiarelli, P., (2013) The Berg Balance Scale has high intra- 
and inter-rater reliability but absolute reliability varies across the scale: a systematic 
review. J. Physiother., 59(2):93-9. doi: 10.1016/S1836-9553(13)70161-9. 
[19] Institute of Medicine (US) Division of Health Promotion and Disease Prevention. Berg, 
R. L., Cassells, J. S., editors. The Second Fifty Years: Promoting Health and Preventing 
Disability. Washington (DC): National Academies Press (US); 1992. 15, Falls in Older 
Persons: Risk Factors and Prevention. 
[20] Plescia, F., Cannizzaro, C., Brancato, A., Sireci, F., Salvago, P., Martines, F. (2016) 
Emerging pharmacological treatments of tinnitus. Tinnitus: Epidemiology, Causes and 
Emerging Therapeutic Treatments, p. 43 - 64. 
[21] Martines, F., Agrifoglio, M., Bentivegna, D., Mucia, M., Salvago, P., Sireci, F., 
Ballacchino, A. (2012) Treatment of tinnitus and dizziness associated vertebrobasilar 
insufficiency with a fixed combination of cinnarizine and dimenhydrinate. Acta Medica 
Mediterranea, 28 (3), 291 - 296. 

Presbyastasis 
 
1071
[22] Martines, F., Ballacchino, A., Sireci, F., Mucia, M., La Mattina, E., Rizzo, S., Salvago, 
P. (2016) Audiologic profile of OSAS and simple snoring patients: the effect of chronic 
nocturnal intermittent hypoxia on auditory function. European Archives of Oto-Rhino-
Laryngology, 273, 6, 1419 - 1424. 
[23] Ballacchino, A., Salvago, P., Cannizzaro, E., Costanzo, R., Di Marzo, M., Ferrara, S., 
La Mattina, E., Messina, G., Mucia, M., Mulè, A., Plescia, F., Sireci, F., Rizzo, S., 
Martines, F. (2015) Association between sleep-disordered breathing and hearing 
disorders: Clinical observation in Sicilian patients, Acta Medica Mediterranea, 31 (3), 
pp. 607 - 614. 
[24] Canal switch and re-entry phenomenon in benign paroxysmal positional vertigo: 
difference between immediate and delayed occurrence. (2015) Dispenza, F., De 
Stefano, A., Costantino, C., Rando, D., Giglione, M., Stagno, R., Bennici, E. Acta 
Otorhinolaryngol. Ital., 35: 116 - 120. 
[25] Analysis of visually guided eye movements in subjects after whiplash injury. (2011) 
Dispenza, F., Gargano, R., Mathur, N., Saraniti, C., Gallina, S. Auris Nasus Larynx, 
38(2):185 - 9. 
[26] The discovery of stapes (2103) Dispenza, F., Cappello, F., Kulamarva, G., De Stefano, 
A. Acta Otorhinolaryngol. Ital., 33:357 - 359. 
[27] Dispenza, F., Mazzucco, W., Bianchini, S., Mazzola, S., Bennici, E. (2015) 
Management of labyrinthine fistula in chronic otitis with cholesteatoma: case series. 
Euro Mediterranean Biomedical Journal, 10(21): 255 - 261. 


 
 
 
 
 
 
 
 
 
 
 
 
INDEX 
 
 
# 
12SrRNA, 661, 662 
5As model, vi, 111, 112, 135, 137 
A 
academic performance, 8, 991, 992, 1048 
accountability, viii, 12, 13, 543 
accuracy, 19, 23, 30, 32, 146, 155, 156, 158, 183, 
191, 192, 253, 288, 554, 555, 561, 562, 564, 574, 
768, 776, 828, 829, 846, 875 
acoustic reflex testing, 22 
acquired hearing loss, 8, 641, 804, 828 
action research, 111, 115, 120, 121, 122, 128, 132, 
137, 138, 139, 140, 141, 142, 143 
acupoint, 278, 283 
acute mastoiditis (AM), 73, 106, 107, 186, 502, 641, 
642, 712, 817, 827, 828, 871, 899, 933 
acute otitis media (AOM), 243, 588, 589, 590, 593, 
595, 596, 597, 598, 700, 701, 704, 825, 826, 827, 
871 
aditus ad antrum, 822, 880 
advanced driver assistance system (ADAS), 386, 
403, 404, 432 
advanced otosclerosis, x, 919, 920, 921, 922, 923, 
924, 925, 927, 928, 929, 930, 931, 932, 946 
age related hearing loss, 142, 203, 652, 883 
air conduction, 223, 327, 391, 591, 604, 920 
alleles, 442, 446, 448, 678, 797, 885, 895, 896, 939 
Alport, 240, 457, 483, 623, 624, 625, 626, 627, 632, 
640, 778, 796 
Alport syndrome, 240, 457, 483, 623, 624, 625, 626, 
627, 632, 640, 796 
alternative screening methods, 13 
ambient noise, 9, 12, 18, 19, 32, 85, 87, 323 
American Academy of Audiology (AAA), 9, 10, 11, 
12, 14, 15, 16, 18, 19, 20, 22, 23, 24, 27, 31, 33, 
35, 142, 185, 430, 437, 716, 720, 1057 
American Association for Speech and Hearing 
(ASHA), 9, 10, 11, 12, 18, 21, 22, 23, 24, 25, 32, 
33, 38, 165, 480 
aneurysms, 846, 849, 861 
Apert syndrome, 454, 482, 637 
apical turn cochlea, 880 
arachnoid cyst, 848, 849, 850, 875 
array CGH (comparative genomic hybridization), 
464, 468, 477 
audiologist, 11, 12, 13, 22, 25, 29, 152, 154, 160, 
215, 472, 637, 638, 639, 640, 701, 1032, 1039, 
1040, 1041, 1056 
audiometry, 7, 8, 9, 10, 11, 21, 22, 29, 32, 34, 36, 53, 
59, 61, 66, 70, 71, 95, 155, 156, 157, 185, 191, 
278, 279, 314, 325, 330, 332, 375, 376, 390, 521, 
523, 529, 533, 591, 592, 599, 604, 626, 627, 630, 
638, 646, 647, 648, 649, 651, 683, 701, 703, 705, 
706, 884, 891, 893, 894, 905, 906, 928, 936, 959, 
962, 964, 979, 1001, 1003, 1004, 1015, 1030 
auditory brainstem response (ABR), viii, xiii, 105, 
106, 108, 157, 181, 188, 191, 205, 229, 242, 277, 
300, 301, 309, 311, 312, 323, 327, 334, 521, 522, 
523, 524, 526, 527, 528, 529, 615, 616, 617, 618, 
620, 626, 635, 637, 638, 702, 804, 807, 905, 906, 
1004, 1040, 1041, 1055 
auditory cortex, 148, 616, 740, 747, 749, 750, 751, 
756, 759, 760, 768, 770, 771, 772, 801, 802, 803, 
804, 805, 806, 807, 808, 809, 810, 889, 899, 900, 
909, 911, 915, 1000, 1001, 1026, 1051 
auditory evaluation, 522 
auditory evoked potentials, 93, 94, 106, 336, 376, 
522, 527, 530, 615, 683, 701, 805, 913, 936, 937, 
962 
auditory function, 25, 106, 196, 277, 278, 324, 326, 
335, 338, 390, 395, 528, 590, 666, 670, 687, 688, 

Index 
 
1074
698, 705, 747, 780, 888, 891, 893, 898, 909, 941, 
956, 986, 1051, 1071 
auditory hair cells, 276, 763 
auditory neuropathy spectrum disorder, viii, 104, 
107, 148, 615, 616, 617, 620, 621, 1030 
auditory neuropathy spectrum disorder (ANSD), viii, 
104, 107, 148, 615, 616, 617, 620, 621, 1030 
auditory neuropathy/dys-synchrony (AN/AD), 19, 
20, 620, 790 
auditory performance, 24, 26, 38, 53, 57, 490, 495, 
503, 620, 721, 1044, 1052 
auricular point sticking, 278 
Australian, 8, 35, 49, 68, 339, 359, 432 
autism spectrum disorder, vi, 247, 258, 259, 260, 
261, 262, 263, 264, 701 
autoimmune, x, xiii, 198, 201, 212, 241, 242, 266, 
366, 599, 600, 602, 604, 605, 609, 612, 655, 656, 
682, 683, 685, 688, 835, 843, 844, 936, 937, 938, 
939, 942, 943, 947, 959, 960, 961, 962, 963, 964, 
965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 
1001, 1002, 1003, 1004, 1011 
autoimmune deafness, 959, 960, 961, 967, 968, 969 
autoimmune inner ear disease, x, xiii, 201, 685, 688, 
939, 942, 959, 960, 972, 1005 
autosomal dominant, 239, 240, 291, 294, 306, 307, 
442, 443, 445, 446, 449, 451, 452, 453, 454, 457, 
459, 460, 461, 462, 476, 486, 616, 618, 621, 623, 
624, 626, 627, 632, 636, 664, 665, 667, 780, 785, 
786, 787, 791, 792, 795, 800, 835, 1029 
autosomal recessive, 239, 240, 291, 306, 307, 310, 
439, 442, 443, 446, 447, 451, 453, 454, 455, 456, 
457, 459, 460, 461, 462, 470, 473, 475, 476, 485, 
616, 618, 623, 624, 626, 636, 639, 641, 664, 667, 
675, 676, 677, 779, 785, 786, 787, 789, 790, 791, 
795, 797, 799, 1029 
B 
basal turn cochlea, 880 
basilar membrane, 198, 223, 228, 229, 277, 282, 495, 
496, 625, 626, 695, 755, 758, 762, 764, 765, 767, 
768, 887, 904, 921, 977, 1034 
behavioural techniques, 247, 248 
Bi-CROS, 232 
bilateral hearing, 9, 12, 50, 51, 160, 242, 538, 599, 
615, 624, 626, 627, 699, 710, 712, 715, 717, 777, 
794, 803, 989, 990, 991, 992, 993, 994, 1019, 
1022, 1023, 1030, 1045 
body balance, 506, 507, 509, 514, 515, 517 
bone conduction, 61, 66, 223, 224, 225, 232, 233, 
376, 390, 591, 651, 705, 706, 710, 779, 904, 920, 
924, 928, 952, 965, 996, 1017 
bone-anchored hearing aids (BAHA), 232, 233, 245, 
709, 710, 713, 997 
brain, 3, 98, 104, 106, 107, 108, 109, 148, 156, 193, 
209, 223, 224, 249, 258, 260, 307, 310, 327, 362, 
367, 370, 371, 380, 381, 383, 434, 452, 458, 519, 
526, 527, 587, 589, 604, 610, 616, 618, 621, 639, 
645, 646, 662, 693, 694, 695, 697, 698, 718, 730, 
739, 740, 741, 744, 746, 747, 749, 751, 752, 753, 
755, 757, 758, 760, 765, 766, 768, 769, 771, 781, 
783, 786, 791, 801, 802, 803, 804, 808, 809, 810, 
811, 817, 827, 838, 848, 849, 852, 853, 855, 857, 
858, 859, 866, 867, 873, 877, 889, 898, 899, 901, 
902, 904, 905, 906, 907, 909, 910, 911, 912, 913, 
915, 946, 953, 964, 976, 982, 991, 994, 995, 
1000, 1003, 1008, 1011, 1012, 1025, 1042, 1046, 
1047, 1050, 1055, 1059, 1060, 1061 
branchio-oto-renal syndrome, 239, 453, 480 
C 
C1 (atlas) anterior arch, 880 
cardiovascular risk factors, vi, viii, 52, 197, 198, 
199, 202, 211, 212, 213, 214, 215, 216, 217, 218, 
313, 369, 604, 655, 656, 657, 658, 1010 
caregiver, 11, 112, 114, 117, 119, 120, 121, 124, 
127, 128, 129, 130, 131, 132, 134, 136, 137, 254 
central auditory processing disorder (CAPD), 24, 25, 
26, 27, 31, 32, 33, 526, 527, 892 
cerebellopontine angle (CPA), 599, 604, 755, 758, 
759, 846, 847, 848, 849, 850, 851, 852, 853, 862, 
864, 870, 874, 875, 953 
Cervantes, vi, 167, 168, 169, 171, 173, 175, 176, 177 
CHARGE syndrome, 149, 451, 452, 479, 783, 784, 
838, 843, 880 
child development, 15, 259, 262, 333, 359, 362, 710, 
786 
Children’s Auditory Performance Scale (CHAPS), 
26, 38 
Chinese Hearing Questionnaire for School Children, 
21, 193 
cholesteatoma, 243, 244, 497, 592, 637, 639, 699, 
700, 704, 705, 706, 707, 708, 709, 710, 712, 713, 
714, 732, 734, 814, 819, 821, 824, 825, 829, 830, 
831, 832, 833, 834, 861, 862, 865, 867, 868, 869, 
870, 872, 877, 897, 916, 943, 972, 997, 1023, 
1053, 1071 
Chordoma, 852 
CHQS-II, 21 
chromosomes, 441, 442, 448, 449, 450, 458, 464, 
465, 669, 672, 777, 789 
chronic otitis media (COM), ix, 243, 454, 458, 587, 
588, 589, 590, 592, 593, 594, 595, 596, 598, 699, 
700, 704, 705, 706, 708, 709, 710, 712, 713, 714, 

Index 
 
1075
734, 825, 828, 829, 830, 832, 833, 834, 871, 872, 
947, 948 
chronic otitis media with effusion (COME), 454, 
458, 700, 701, 702, 703, 828 
chronic suppurative otitis media (CSOM), 588, 596, 
712, 713, 828, 830, 872 
CISS, 817, 818, 825, 843, 844, 846, 847, 848, 851, 
864, 866, 868 
clock-drawing test (CDT), 386, 394 
cochlear aplasia, 717, 839, 843 
cochlear aqueduct, 242, 493, 603, 880 
cochlear function, 101, 102, 103, 104, 105, 148, 196, 
229, 276, 278, 322, 328, 331, 334, 716, 913, 1011 
cochlear gene therapy, 280, 281 
cochlear hypoplasia (CH), 282, 370, 612, 795, 838, 
839, 840, 847 
cochlear implant failure, 490 
cochlear implantation (CI), v, xiii, 27, 51, 52, 53, 54, 
56, 57, 108, 233, 234, 235, 242, 314, 329, 422, 
489, 490, 492, 493, 494, 497, 500, 502, 503, 592, 
616, 619, 630, 642, 715, 716, 717, 718, 719, 720, 
721, 723, 724, 727, 729, 730, 734, 735, 737, 739, 
740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 
750, 751, 778, 786, 797, 805, 806, 807, 808, 811, 
837, 838, 840, 844, 845, 846, 869, 874, 880, 894, 
900, 902, 910, 913, 916, 919, 921, 923, 924, 925, 
926, 927, 928, 929, 930, 931, 932, 933, 990, 995, 
1013, 1023, 1025, 1027, 1028, 1029, 1030, 1031, 
1032, 1033, 1034, 1035, 1037, 1038, 1045, 1047, 
1051, 1052, 1053, 1054, 1057, 1058, 1059 
cochlear implants, vi, ix, 2, 47, 57, 221, 233, 235, 
344, 359, 433, 495, 496, 498, 499, 500, 501, 502, 
515, 518, 519, 619, 621, 715, 716, 717, 719, 720, 
721, 722, 739, 740, 750, 751, 752, 779, 801, 805, 
806, 808, 810, 814, 874, 894, 932, 933, 968, 970, 
990, 995, 1025, 1026, 1027, 1031, 1032, 1045, 
1046, 1048, 1051, 1052, 1053, 1055, 1057, 1058, 
1059 
cochleovestibular disorders, 278, 283 
Cogan’s syndrome, 242, 844, 961, 971, 972, 1002 
cognitive deterioration, 52 
common cavity, 718, 839, 840, 841 
compensatory strategies, 385, 402, 405, 413, 415, 
416, 417, 418, 422 
Complete Labyrinthine Aplasia (CLA), 839 
computerized tomography (CT), 193, 242, 244, 261, 
295, 493, 639, 642, 652, 713, 717, 721, 730, 732, 
735, 776, 813, 814, 816, 817, 821, 823, 825, 826, 
827, 828, 829, 830, 832, 833, 834, 835, 836, 837, 
838, 839, 840, 843, 844, 848, 849, 852, 854, 855, 
856, 857, 858, 859, 860, 861, 862,864, 865, 867, 
868, 869, 870, 871, 872, 873, 876, 879, 880, 901, 
905, 906, 907, 908, 909, 910, 914, 915, 921, 922, 
926, 927, 928, 931, 968, 1004, 1029 
conduct disorder, vii, 341, 342, 343, 345, 346, 347, 
348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 
358, 359, 360, 361, 362 
conductive hearing loss (CHL), 11, 13, 14, 36, 147, 
148, 225, 229, 232, 233, 240, 243, 244, 245, 246, 
388, 454, 458, 588, 591, 592, 637, 639, 641, 645, 
648, 650, 652, 662, 701, 705, 706, 709, 713, 780, 
785, 786, 787, 792, 794, 795, 796, 797, 823, 824, 
826, 828, 829, 830, 835, 854, 857, 903, 906, 919, 
920, 965, 1016 
condylar process, 880 
condyloid process, 880 
cone beam CT (CBCT), 639, 814, 837, 869 
congenital conductive hearing loss, 823 
congenital hearing loss (CHL), 8, 225, 229, 232, 233, 
239, 240, 243, 244, 245, 246, 453, 482, 636, 637, 
639, 643, 664, 778, 779, 785, 786, 787, 789, 790, 
792, 794, 795, 796, 797, 823, 826, 835, 838, 903 
connexin 26, 239, 460, 462, 475, 484, 618, 620, 636, 
639, 643, 665, 668, 674, 675, 676, 677, 678, 778, 
787, 788, 790, 792, 793, 797, 798, 885, 895, 
1014, 1029 
constructive interference in steady-state, 817 
contralateral routing of signal (CROS), 232 
Contusio Labyrinthi (Labyrinthine Concussion), 856, 
908, 913 
coping strategies, 386, 402, 415, 418, 421 
Cornelia de Lange syndrome, 452, 479, 480 
corticosteroids, 242, 266, 502, 599, 605, 686, 911, 
950, 959, 960, 966, 968, 969, 1000, 1001, 1005, 
1006, 1007, 1010, 1038 
cranial nerve, 240, 765, 781, 817, 818, 819, 837, 
849, 859, 864, 866, 878, 879, 946, 953, 962, 999 
craniofacial anomalies, 11, 21 
cross-modal plasticity, ix, 739, 740, 741, 742, 746, 
747, 749, 750, 752, 803, 805, 806, 807, 808, 810 
Crouzon syndrome, 454, 481, 482 
cytogenetics, 463, 464, 467, 468 
D 
data management system, 29, 181 
datalogging, 160, 531, 532, 533, 534, 535, 536, 537, 
539, 542, 1040 
deaf children with visual-impairment, 739, 740, 741, 
742, 743, 744, 745, 746, 747, 749 
delayed onset hearing loss, 8 
deletion, 209, 465, 466, 468, 668, 669, 676, 783, 
789, 798, 799, 885 
deoxyribonucleic acid (DNA), 1, 197, 204, 209, 273, 
286, 290, 295, 296, 309, 370, 440, 441, 450, 458, 

Index 
 
1076
464, 465, 466, 467, 468, 469, 470, 471, 473, 484, 
485, 593, 621, 638, 639, 642, 657, 666, 667, 673, 
678, 775, 776, 780, 785, 787, 797, 885, 896, 970, 
977, 985, 1004 
depression, 51, 52, 53, 56, 65, 78, 95, 108, 149, 151, 
223, 224, 225, 279, 358, 374, 375, 380, 381, 532, 
756, 824, 877, 950, 975, 976, 980, 986, 1014 
Dermoid cyst, 852 
developing countries, 8, 36, 38, 180, 183, 1051 
diabetes mellitus, 195, 197, 198, 199, 200, 211, 212, 
213, 214, 216, 462, 602, 637, 655, 656, 688, 795, 
885, 893, 942, 1002, 1006 
diffusion weighted imaging (DWI), 818, 819, 827, 
832, 833, 834, 849, 850, 866 
digital subtraction angiography (DSA), 814, 862 
disabling hearing loss, 146, 275, 276, 320 
dissection, 281, 494, 497, 726, 727, 728, 729, 730, 
732, 736, 737, 858, 947 
distortion product evoked otoacoustic emissions 
(DPOAEs)/ distortion product OAEs (DPOAEs), 
3, 16, 18, 19, 20, 66, 73, 93, 94, 101, 102, 103, 
104, 106, 107, 108, 236, 277, 376, 611, 979 
dizziness, 56, 65, 153, 315, 502, 507, 515, 518, 519, 
610, 645, 646, 648, 649, 652, 683, 694, 695, 902, 
912, 927, 936, 949, 950, 955, 963, 1064, 1069, 
1070 
DNA sequencing, 309, 470, 485, 785, 787, 797 
Down syndrome, 146, 148, 149, 150, 151, 159, 160, 
165, 262, 458, 459, 483, 484, 700, 701 
dural venous sinus thrombosis, 827, 858, 859, 876 
E 
ear canal, 11, 14, 16, 84, 91, 147, 148, 157, 159, 223, 
224, 226, 228, 231, 232, 281, 388, 458, 593, 662, 
694, 891, 894, 905, 978, 979, 1003, 1016 
early intervention, 24, 39, 40, 42, 43, 47, 104, 179, 
182, 183, 185, 249, 259, 273, 786, 1025 
earphones, 9, 10, 22, 235, 893 
earwax, 139, 147, 149, 154, 159 
efficiency, 19, 21, 27, 66, 92, 191, 385, 393, 405, 
406, 526, 549, 557, 564, 802, 805, 997 
elderly, vii, 51, 52, 53, 54, 56, 57, 115, 165, 197, 
213, 216, 241, 315, 373, 374, 378, 381, 386, 387, 
395, 401, 404, 415, 419, 425, 427, 428, 430, 431, 
432, 433, 434, 435, 436, 514, 515, 520, 531, 532, 
533, 534, 535, 536, 537, 538, 539, 540, 541, 588, 
602, 604, 607, 630, 631, 697, 698, 800, 831, 883, 
884, 890, 891, 894, 896, 898, 900, 942, 955, 980, 
985, 995, 1020, 1050, 1051, 1063, 1064, 1065, 
1066, 1067, 1068, 1069, 1070 
electric acoustic stimulation CI’s, 234 
electrocochleography, 229, 529, 659, 1004, 1034 
electrophysiology, 158, 522, 530, 749, 1036 
emotion, 48, 122, 167, 172, 176, 344, 361, 997 
endolymphatic hydrops, x, 196, 909, 945, 946, 947, 
948, 949, 951, 955, 956 
endothelial dysfunction, v, vi, 1, 2, 3, 4, 5, 195, 196, 
197, 198, 199, 200, 201, 204, 208, 211, 212, 214, 
218, 311, 656, 657, 658 
enlarged vestibular aqueduct (EVA), 245, 461, 482, 
637, 639, 776, 778, 790, 795, 841, 842 
epidermoid cyst, 849, 850, 877 
equivalent ear canal volume (Vea), 13, 16, 226 
European consensus statement, 10, 38 
eustachian tube dysfunction, 267 
exome sequencing, 286, 287, 288, 290, 291, 293, 
296, 308, 439, 471, 472, 477 
exons, 288, 300, 307, 471, 628, 677, 789 
exostosis, 821 
external auditory canal, 13, 278, 452, 497, 590, 651, 
756, 761, 838, 839, 855, 870, 894, 903, 914, 941, 
952, 953, 1002, 1015, 1053 
external auditory channel (EAC), 243, 821, 822, 830, 
831, 864, 866, 868, 880, 903, 905 
external ear, 159, 160, 222, 223, 281, 454, 640, 662, 
756, 780, 781, 821, 823, 834, 870, 905, 1001, 
1002 
eyes, vi, 167, 168, 169, 172, 173, 174, 177, 408, 414, 
420, 453, 454, 509, 510, 637, 640, 692, 693, 694, 
696, 756, 759, 792, 796, 816, 965, 1065, 1067 
F 
facial nerve (labyrinthine segment), 880 
facial nerve (mastoid segment), 880 
facial nerve (tympanic segment), 880 
facial nerve injury, 245, 496, 854, 857 
facial palsy, 451, 646, 857, 866, 879, 905 
failure, 2, 10, 16, 18, 19, 20, 23, 28, 41, 54, 100, 234, 
245, 246, 267, 297, 299, 313, 314, 316, 361, 362, 
489, 490, 491, 492, 493, 494, 495, 499, 500, 502, 
560, 606, 623, 624, 626, 627, 633, 637, 648, 718, 
796, 821, 834, 901, 917, 925, 929, 931, 964, 997, 
1002,1008, 1010, 1030, 1037, 1055, 1068 
false-negative, 22, 30, 187 
false-positive, 9, 12, 22, 29, 30 
feasibility, 29, 34, 181, 282, 288, 732 
fenestral otosclerosis, 835, 836, 919, 920 
fibrous dysplasia, 821, 861 
Fisher’s auditory problems checklist (FAPC), 26 
fluorescence in situ hybridization (FISH), 464, 466, 
467, 468 
founder effect, 456, 672, 673, 674, 678 
frequency following response (FFR), viii, 521, 522, 
523, 525, 526, 527 

Index 
 
1077
G 
gel electrophoresis, 468, 469, 470 
genes GJB2, 661, 662, 669, 673 
genetic hearing loss, 188, 285, 440, 447, 459, 472, 
475, 477, 478, 775, 781, 785, 786, 788 
genetic mutations, 280, 783, 823, 1013 
genetic screening, 7, 30, 31 
genetic testing, 30, 31, 32, 33, 183, 186, 288, 291, 
439, 445, 463, 472, 473, 474, 475, 477, 482, 487, 
663, 675 
genetics, vii, ix, 30, 32, 33, 146, 165, 179, 180, 182, 
184, 271, 286, 287, 289, 315, 369, 371, 439, 440, 
442, 454, 463, 466, 468, 470, 472, 473, 474, 475, 
477, 478, 481, 482, 483, 484, 487, 615, 639, 641, 
661, 666, 674, 675, 676, 677, 678, 775, 776, 777, 
779, 783, 800, 877, 885, 984 
geniculate ganglion, 825, 833, 864, 865, 866, 867, 
880, 927 
genotype, 296, 298, 307, 442, 447, 450, 470, 482, 
485, 486, 630, 633, 674, 784, 789, 797, 810, 896, 
941, 956, 973, 984, 1020, 1053 
gentamicin-induced, 273, 274, 281, 282 
gesture, 168, 247, 251, 252, 261, 262, 263 
GJB3, 661, 662, 665, 669, 673, 788, 792, 798 
GJB6, 462, 639, 661, 662, 665, 669, 673, 676, 677, 
787, 789, 792, 797, 798, 895 
glioma, 852 
glucocorticoids, 681, 687, 939, 980, 1000, 1004, 
1006 
glue ear, 147, 148 
gold standard, 9, 15, 19, 21, 24, 599, 604, 638, 719, 
946, 1004, 1025 
H 
head trauma, 11, 21, 28, 189, 193, 320, 490, 500, 
646, 649, 650, 853, 854, 855, 856, 857, 858, 859, 
876, 901, 906, 909, 912, 913, 914 
headphones, 11, 22, 28, 29, 66, 85, 86, 155, 156, 
157, 161, 223, 630, 893, 1014 
hearing disorders, 2, 7, 8, 49, 106, 107, 139, 192, 
199, 202, 215, 217, 278, 279, 313, 314, 357, 596, 
610, 620, 635, 637, 639, 642, 664, 898, 942, 954, 
972, 986, 997, 1008, 1020, 1051, 1071 
hearing loss counseling, 439 
hearing loss in children, 31, 192, 478, 484, 618, 636, 
637, 639, 640, 641, 677, 699, 700, 701, 712, 715, 
777, 985, 1021, 1028, 1051 
hearing scale test (HST), 21, 35 
hearing screening, v, 7, 8, 9, 10, 11, 12, 13, 15, 16, 
20, 21, 22, 23, 28, 29, 30, 31, 32, 34, 35, 36, 37, 
38, 105, 107, 108, 109, 139, 146, 150, 163, 164, 
165, 181, 182, 183, 184, 185, 186, 189, 190, 191, 
192, 193, 373, 478, 635, 637, 641, 643, 652, 676, 
678, 716, 720, 1026, 1051 
hemoglobinopathy, 521, 522 
high-risk, 11, 15, 105, 108, 264, 641, 876 
Hong Kong, 7, 8, 33, 35 
human machine interaction (HMI), 386, 404, 420 
hybrid CI’s, 234 
hyperbaric oxygen therapy, vi, 265, 266, 269, 612 
hypertension, 53, 65, 94, 107, 195, 197, 198, 199, 
211, 212, 230, 268, 313, 314, 315, 457, 631, 655, 
656, 681, 687, 861, 877, 935, 940, 963, 964, 986, 
1000 
hypo tympanum, 880 
hypoglossal canal, 880 
hypoxia, 93, 94, 95, 96, 98, 100, 101, 104, 105, 106, 
107, 108, 109, 197, 266, 311, 312, 314, 315, 316, 
607, 637, 659, 688, 698, 823, 898, 921, 938, 941, 
956, 986, 1013, 1051, 1071 
I 
iconicity, 247, 251, 261 
immittance, 226, 227, 330 
immunology, 661, 960 
imperfecta, 239, 835 
implantable hearing aids, 233 
incomplete partition (IP), 545, 548, 549, 550, 552, 
553, 554, 559, 560, 563, 564, 566, 569, 571, 573, 
574, 575, 718, 839, 840, 841, 842, 845 
incudomalleolar joint, 652, 880 
incus (short process), 880 
infections, 112, 147, 149, 187, 188, 190, 196, 241, 
271, 272, 273, 280, 366, 440, 473, 588, 590, 595, 
600, 601, 616, 618, 636, 637, 638, 640, 655, 683, 
786, 817, 819, 823, 825, 828, 843, 846, 860, 867, 
935, 936, 947, 962, 979, 999, 1001, 1008, 1013, 
1038, 1051 
inner ear malformations (IEMs), 717, 718, 721, 778, 
780, 837, 838, 839, 840, 841, 874 
intensity, 9, 10, 16, 53, 62, 67, 72, 85, 95, 99, 100, 
106, 175, 225, 229, 279, 280, 305, 327, 349, 355, 
376, 517, 523, 604, 616, 694, 695, 696, 701, 760, 
766, 767, 818, 820, 827, 832, 834, 844, 845, 848, 
849, 850, 852, 891, 910, 951, 954, 976, 980, 
1045, 1047 
interaction, vi, 119, 139, 167, 168, 173, 174, 175, 
213, 228, 255, 256, 259, 273, 320, 323, 326, 329, 
332, 335, 360, 386, 390, 397, 410, 418, 487, 611, 
692, 710, 740, 749, 750, 770, 805, 948, 951, 
1009, 1026, 1043 

Index 
 
1078
internal auditory canal, 382, 454, 493, 599, 683, 717, 
836, 846, 848, 857, 873, 875, 903, 904, 910, 915, 
937, 953 
internal auditory channel (IAC), 649, 817, 818, 819, 
825, 826, 838, 840, 841, 843, 845, 846, 847, 848, 
851, 862, 864, 866, 867, 868, 880, 953 
internal carotid artery (ICA), 858, 859, 861, 880, 
1037 
International Classification of Functioning Disability 
and Health (ICF), 386, 389, 390, 401, 418, 435, 
437 
intervention, 8, 15, 23, 25, 33, 42, 43, 47, 49, 50, 71, 
81, 101, 105, 107, 137, 142, 165, 175, 180, 181, 
182, 183, 184, 185, 193, 239, 247, 250, 252, 254, 
255, 256, 257, 260, 262, 263, 279, 285, 347, 357, 
403, 433, 439, 487, 509, 517, 630, 635, 640, 641, 
708, 715, 716, 719, 720, 740, 749, 764, 821, 857, 
868, 893, 910, 911, 923, 951, 954, 979, 989, 990, 
1018, 1026, 1032, 1033, 1052 
introns, 471, 476 
inversion, 465, 468, 818, 849, 915, 922, 1068 
irritability, 81, 279, 590, 710, 980, 987 
J 
Jacobsen syndrome, 461 
Jervell, 240, 457, 474, 483, 779, 795 
Jervell and Lange-Nielsen syndrome, 457, 474, 483, 
779, 780, 795 
jugular bulb, 245, 859, 863, 880, 947, 953 
jugular foramen, 245, 862, 878, 880, 903 
K 
karyotype, 442, 464, 465, 467, 468 
keratosis obturans, 822 
L 
labyrinthine concussion, 646, 857, 902, 904, 906, 
908, 910, 911, 913 
labyrinthine hydropsis, 278 
labyrinthitis, 242, 497, 498, 587, 589, 591, 594, 596, 
598, 601, 604, 835, 836, 837, 843, 844, 910, 915, 
979, 1002, 1006, 1030, 1035, 1038 
Lange, 149, 164, 240, 452, 457, 483, 780 
language, 9, 11, 21, 23, 24, 25, 28, 32, 33, 34, 35, 37, 
38, 42, 43, 45, 47, 48, 49, 50, 102, 104, 126, 134, 
142, 151, 162, 168, 171, 176, 181, 183, 185, 187, 
190, 248, 249, 250, 252, 253, 254, 255, 258, 259, 
260, 261, 262, 263, 264, 294, 342, 343, 344, 356, 
358, 366, 375, 382, 390, 392, 395, 407, 424, 426, 
429, 433, 435, 437, 478, 491, 526, 529, 532, 533, 
534, 545, 550, 568, 573, 577, 578, 579, 616, 635, 
637, 638, 640, 643, 668, 701, 702, 704, 710, 711, 
713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 
740, 742, 745, 746, 747, 748, 749, 750, 751, 752, 
778, 786, 806, 807, 808, 1014, 1026, 1028, 1030, 
1032, 1033, 1043, 1045, 1046, 1047, 1048, 1051, 
1059, 1060 
language development, 28, 43, 47, 49, 102, 104, 190, 
252, 254, 255, 259, 261, 344, 638, 701, 702, 710, 
713, 714, 715, 718, 721, 722, 742, 751, 806, 
1026, 1028, 1043 
lateral semicircular canal (LSCC), 493, 830, 832, 
833, 838, 842, 843, 865, 880 
lipochoristomas, 851, 852, 875 
lipomas, 846, 851, 868 
Listening Inventory For Education–Revised (LIFE-
R), 26 
locus, 456, 460, 618, 787, 788, 789, 792, 799, 1029 
long-term memory (LTM), 386, 391, 392, 395, 396, 
397, 435, 527, 993 
loss of concentration, 279 
low-resolution brain electromagnetic tomography 
(LORETA), 740, 742, 743, 744, 752 
M 
Magnetic Resonance Imaging (MRI), 295, 494, 602, 
604, 639, 718, 732, 741, 752, 771, 776, 814, 817, 
818, 821, 823, 827, 828, 830, 832, 833, 834, 835, 
837, 838, 842, 843, 844, 846, 848, 849, 852, 856, 
857, 858, 859, 861, 862, 864, 865, 866, 867, 868, 
872, 874, 875, 876, 877, 879, 889, 901,905, 907, 
908, 909, 910, 915, 922, 931, 968, 1003, 1004, 
1029 
malleus, 646, 649, 650, 695, 709, 755, 757, 761, 762, 
822, 823, 825, 829, 831, 856, 880, 907 
mass screening, 18, 19 
mastoid cells, 827, 855, 880 
meiosis, 441, 458, 459 
MELAS, 457, 483 
Meniere disease, 945, 949, 950 
meningioma, 242, 848, 864, 875 
MERRF, 457, 483 
methylprednisone, 968 
Michel deformity, 839, 843, 845 
microvascluar disease., 195 
middle ear, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 23, 
31, 34, 36, 37, 38, 94, 96, 98, 102, 103, 147, 149, 
222, 223, 225, 226, 227, 228, 233, 242, 243, 244, 
245, 246, 267, 269, 388, 451, 452, 493, 587, 588, 
589, 590, 591, 592, 593, 597, 601, 605, 612, 617, 

Index 
 
1079
637, 638, 639, 647, 648, 649, 650, 651, 653, 662, 
685, 694, 695, 699, 700, 701, 702, 703, 704, 705, 
706, 708, 709, 712, 713, 727, 730, 755, 756, 757, 
761, 762, 814, 819, 821, 822, 823, 824, 825, 826, 
827, 828, 829, 830, 831, 832, 833, 834, 835, 838, 
839, 841, 846, 854, 856, 868, 870, 871, 872, 877, 
886, 893, 902, 903, 904, 905, 906, 907, 908, 913, 
927, 938, 946, 949, 952, 954, 956, 965, 1001, 
1002, 1006, 1036, 1043, 1055, 1056 
middle ear disorders, 11, 15, 36, 37, 38, 94, 96, 98, 
102, 103, 834 
middle turn cochlea, 880 
mitochondrial, 149, 189, 197, 200, 202, 205, 207, 
272, 313, 442, 445, 449, 450, 457, 459, 463, 483, 
487, 616, 618, 621, 636, 664, 666, 667, 674, 675, 
677, 777, 785, 885, 888, 896, 898, 983, 1029 
mitosis, 441, 458, 459, 464 
mixed hearing loss (MHL), 189, 233, 243, 451, 588, 
637, 639, 813, 835, 836, 857, 903, 906, 919, 920, 
923, 924, 927, 933, 1001 
mobility, vii, 13, 82, 226, 227, 385, 386, 387, 388, 
389, 396, 397, 400, 401, 402, 404, 405, 411, 417, 
418, 421, 422, 428, 430, 431, 432, 434, 436, 512, 
519, 590, 1065, 1066, 1068, 1070 
modiolus, 492, 838, 840, 841, 842, 847, 880 
mosaicism, 306, 458, 465 
multi-detector CT (MDCT), 814, 815, 816, 817, 821, 
822, 823, 826, 827, 830, 831, 836, 840, 841, 842, 
845, 854, 855, 859 
multidisciplinary Team (MDT), 133, 134, 135, 136 
multiplanar reconstructions (MPR), 815, 816, 818, 
819, 821, 827, 831, 836, 837, 855, 856, 857, 863, 
867 
multiple comfort zone model (MCZ), 386, 399 
mutations, vii, 104, 183, 189, 192, 197, 206, 239, 
272, 285, 287, 288, 290, 291, 294, 307, 309, 310, 
442, 445, 447, 450, 451, 452, 453, 454, 455, 456, 
457, 460, 461, 462, 463, 464, 471, 472, 475, 476, 
479, 480, 481, 482, 483, 484, 485, 486, 615, 618, 
620, 621, 623,624, 626, 628, 630, 632, 639, 641, 
643, 661, 665, 666, 667, 668, 669, 670, 671, 673, 
674, 675, 676, 677, 678, 777, 778, 779, 780, 781, 
783, 784, 785, 786, 788, 789, 790, 791, 793, 795, 
797, 798, 799, 800, 810, 885, 896, 941, 956, 961, 
973, 979, 984, 1013, 1020, 1052, 1053 
myringotomy, 15, 727, 736 
N 
neural pathway, 94, 320, 802, 804, 900, 1000, 1001, 
1050 
neural plasticity, 381, 801, 802, 807, 889 
neurofibromatosis type 1, 453, 877 
neurofibromatosis type 2, 452, 846 
neuroplasticity, x, 741, 746, 747, 749, 752, 801, 802, 
806, 808, 1059 
newborn hearing screening, 7, 8, 36, 165, 179, 180, 
181, 183, 184, 185, 186, 191, 476, 487, 716, 786, 
1021, 1025, 1026, 1028 
Nielsen, 240, 283, 404, 434, 457, 479, 483, 675, 780, 
987 
noise induced hearing loss (NIHL), 27, 28, 29, 63, 
68, 72, 74, 86, 203, 207, 222, 225, 242, 277, 279, 
975, 976, 977, 978, 979, 981, 984 
non-compliance rate, 8 
nondisjunction, 458, 459, 465 
nonsyndromic hearing loss, 290, 291, 294, 439, 455, 
459, 460, 462, 463, 472, 473, 475, 476, 484, 486, 
787, 798 
normal hearing (NH), 12, 18, 22, 157, 164, 213, 214, 
224, 225, 227, 229, 230, 232, 233, 293, 297, 302, 
307, 313, 324, 345, 346, 349, 356, 358, 382, 386, 
394, 395, 399, 400, 404, 408, 409, 410, 411, 412, 
413, 414, 415, 416, 417, 419, 420, 421, 453, 518, 
637, 659, 701, 702, 710, 714, 742, 744, 751, 761, 
778, 805, 890, 933, 989, 996, 1016, 1018, 1047 
O 
Obstructive Sleep Apnea Hypopnea Syndrome 
(OSAHS), 206, 311, 312, 313, 314 
occupational hearing loss, x, 70, 71, 74, 335, 975, 
976, 977, 985 
odds ratio (OR), 314, 324, 329, 386, 410, 432, 1041 
older adults, 51, 56, 57, 165, 217, 230, 236, 237, 
246, 395, 396, 401, 405, 408, 426, 427, 428, 429, 
431, 434, 435, 510, 519, 646, 652, 696, 809, 900, 
995, 997, 1014 
osseointegrated devices (OID), 233 
ossicles, 243, 244, 452, 454, 662, 695, 707, 730, 731, 
755, 757, 758, 761, 822, 823, 824, 825, 831, 907, 
1002 
osteogenesis, 239, 835, 919, 920 
otic capsule sparing, 853, 854, 876, 903, 907, 911, 
912, 914 
otic capsule violating, 853, 854, 857, 876, 907, 912 
otitis media, viii, 11, 21, 36, 37, 38, 222, 243, 452, 
454, 587, 588, 589, 590, 591, 592, 593, 595, 596, 
597, 598, 604, 609, 637, 641, 653, 699, 700, 702, 
704, 708, 709, 711, 712, 713, 714, 825, 826, 827, 
828, 832, 833, 860, 867, 871, 872, 930, 946, 947, 
1003, 1008 
otitis media with effusion (OME), 11, 14, 15, 16, 18, 
21, 36, 38, 243, 452, 590, 598, 699, 700, 701, 
702, 703, 704, 710, 711, 712 

Index 
 
1080
otoacoustic emissions, 7, 16, 18, 29, 34, 35, 36, 37, 
59, 66, 71, 73, 74, 75, 93, 105, 107, 108, 109, 
157, 188, 189, 228, 236, 278, 311, 312, 321, 336, 
390, 521, 523, 527, 530, 615, 616, 617, 618, 626, 
635, 637, 689, 764, 791, 886, 887, 893, 943, 979, 
986 
oto-acoustic emissions, 906 
otolaryngology, 35, 36, 37, 163, 182, 217, 221, 239, 
246, 266, 271, 283, 285, 289, 293, 315, 369, 489, 
501, 528, 587, 598, 599, 641, 653, 659, 687, 689, 
699, 701, 704, 705, 706, 707, 711, 713, 719, 723, 
727, 728, 780, 807, 813, 872, 873, 875, 914, 916, 
941, 943, 949, 975, 995, 1009, 1052, 1055, 1056 
otomastoiditis (OM), 236, 237, 243, 590, 699, 700, 
701, 704, 711, 825, 827, 830, 831, 832, 860 
otosclerosis, 54, 223, 240, 243, 244, 662, 709, 814, 
834, 835, 836, 837, 846, 862, 869, 872, 873, 877, 
919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 
929, 930, 931, 932, 933, 934, 946, 948, 957, 1029 
otoscopy, 16, 19, 21, 29, 30, 147, 154, 245, 375, 604, 
617, 639, 711, 826, 906, 959 
Outcome Inventory for Hearing Aids (IOI-HA), 531, 
533, 534, 535, 536, 537, 539, 540, 541 
outer hair cells, 3, 16, 19, 28, 70, 104, 204, 206, 213, 
224, 228, 273, 327, 331, 594, 601, 616, 657, 758, 
762, 763, 764, 765, 766, 767, 773, 793, 799, 888, 
979, 983 
oxidative stress, v, 1, 2, 3, 4, 5, 197, 200, 201, 203, 
204, 205, 207, 208, 209, 210, 213, 273, 311, 312, 
313, 330, 366, 369, 372, 655, 657, 658, 885, 888, 
897, 977, 982, 984 
P 
pass/fail criterion, 9 
patterns of inheritance, 442, 624 
peak compensated static acoustic admittance, 13, 226 
pediatric neuroradiology, 715 
pedigree, 294, 295, 296, 443, 444, 445, 662 
Pendred, 240, 370, 455, 460, 482, 637, 639, 642, 
675, 778, 779, 790, 794, 795, 799, 800, 838 
Pendred syndrome, 240, 370, 455, 460, 482, 637, 
639, 642, 778, 779, 790, 794, 795, 799, 800, 838 
penetrance, 244, 296, 445, 453, 481, 835 
perception, 9, 20, 56, 63, 77, 86, 87, 118, 119, 122, 
133, 134, 136, 142, 143, 160, 167, 168, 169, 171, 
173, 174, 176, 190, 280, 390, 391, 392, 399, 400, 
401, 404, 419, 422, 428, 432, 434, 436, 497, 514, 
526, 529, 533, 536, 539, 626, 664, 665, 666, 669, 
694, 698, 702, 712, 718, 719, 732, 751, 760, 761, 
771, 805, 884, 888, 890, 892, 895, 924, 933, 989, 
991, 993, 994, 995, 996, 1001, 1002, 1003, 1016, 
1028, 1029, 1030, 1039, 1046, 1052, 1053, 1056, 
1057, 1058, 1059 
permanent childhood hearing loss, 28, 440 
personnel, 11, 12, 22, 23, 25, 59, 60, 61, 62, 63, 64, 
65, 66, 68, 71, 72, 73, 74, 77, 86, 182, 183, 1032, 
1033, 1040, 1067 
phenotype, 192, 290, 295, 296, 302, 307, 442, 479, 
482, 483, 485, 486, 628, 630, 633, 643, 674, 780, 
782, 784, 790, 791, 793, 797, 798, 799, 810, 896, 
900, 941, 956, 973, 984, 1020, 1052, 1053 
Picture Exchange System (PECS), 154, 247, 255, 
256, 257, 258, 260 
pinna, 11, 223, 232, 451, 662, 756, 761, 864, 880 
plain film radiographs, 814 
planning, 31, 46, 48, 81, 132, 134, 137, 141, 160, 
181, 254, 350, 393, 423, 474, 573, 723, 724, 731, 
732, 778, 815, 816, 821, 823, 848, 872, 1033 
pneumatic otoscopy, 15, 590 
polyarteritis nodosa, 948, 965, 974 
polymerase chain reaction, 300, 466, 468, 469, 618, 
667, 1011 
polymorphisms, vii, 203, 205, 206, 209, 365, 368, 
369, 371, 442, 478, 485, 885 
positive predictive values, 19, 834 
Positron Emission Tomography (PET), 747, 814, 
862, 889 
post traumatic hearing loss, 857 
posterior semicircular canal (PSCC), 809, 838, 880, 
952, 955 
postnatal hearing loss, 20, 191, 193 
posture, vii, 253, 505, 506, 507, 508, 509, 510, 511, 
512, 513, 514, 517, 519, 691, 693, 695, 697, 698, 
1064, 1067 
practice of working, 342 
pre-lingual, 637, 788, 791, 793, 803, 1028 
presbiastasia, 1063, 1064 
presbyacusis, 148, 221, 225, 241, 427, 435, 883, 896 
presbycusis, 3, 4, 52, 57, 151, 197, 203, 204, 205, 
213, 217, 379, 387, 388, 428, 477, 883, 884, 885, 
888, 891, 896, 897, 899, 900, 975, 1013 
primary care, 112, 113, 114, 125, 127, 128, 129, 131, 
132, 133, 134, 135, 139, 141, 472, 712 
prostaglandine E1, 1000, 1007 
pseudoaneurysm, 858 
pseudofractures, 855 
public health, 38, 179, 180, 181, 182, 183, 184, 247, 
273, 275, 276, 331, 335, 339, 430, 436, 539, 541, 
735, 980, 1014 
pure tone average (PTA), 51, 52, 53, 54, 55, 56, 155, 
224, 241, 268, 386, 390, 391, 702, 706, 976, 979, 
1006, 1027, 1047 
pure-tone audiometry screening, 8 

Index 
 
1081
Q 
questionnaires, 7, 20, 21, 26, 27, 87, 139, 191, 330, 
375, 381, 406, 431, 531, 532, 533, 534, 535, 536, 
537, 539, 540 
R 
reactive oxygen species (ROS), 1, 2, 3, 4, 195, 197, 
198, 199, 203, 204, 205, 206, 208, 272, 282, 368, 
372, 655, 657, 885, 890, 893, 977, 978, 982, 983 
referral rates, 23 
restriction in social participation, 531, 532, 533, 534, 
535, 536, 537, 539, 540 
retrofenestral (or cochlear) otosclerosis, 835 
Rett syndrome, 449 
revision surgery, vii, 489, 490, 492, 495, 496, 497, 
499, 503 
rheumatoid arthritis (RA), 282, 283, 500, 501, 602, 
612, 642, 965, 971, 985 
risk allostasis theory (RAT), 386, 398, 399 
risk homeostasis model (RHM), 387, 398 
risk management, 12, 64, 560 
risk monitor model (RMM), 387, 399 
round window niche, 593, 594, 835, 880, 926 
S 
satisfaction/benefit, viii, 531, 532, 533, 534, 535, 
537, 539 
school entry, 8, 32, 34, 35, 182 
screening, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 
20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 
33, 34, 35, 36, 37, 38, 106, 107, 150, 157, 164, 
179, 181, 182, 183, 184, 185, 186, 187, 188, 190, 
191, 274, 291, 382, 476, 483, 487, 518, 531, 533, 
536, 537, 605, 632, 638, 641, 663, 664, 668, 676, 
677, 678, 716, 720, 721, 778, 785, 787, 797, 800, 
846, 891, 973, 991, 1021 
screening audiometry, 8, 9, 10, 22 
Screening Instrument for Targeting Educational Risk 
(SIFTER), 26, 38 
scutum, 880 
second stage screening, 16 
senses, 167, 168, 169, 170, 171, 172, 173, 174, 176, 
177, 398, 960 
sensitivity, 9, 14, 15, 18, 19, 20, 21, 22, 30, 42, 81, 
95, 188, 191, 212, 214, 273, 300, 338, 343, 400, 
408, 427, 434, 435, 437, 477, 516, 519, 589, 626, 
694, 702, 751, 763, 764, 765, 766, 768, 769, 772, 
773, 802, 814, 827, 828, 834, 835, 846, 908, 922, 
962, 967, 976, 979, 1029, 1030, 1041 
sequencing, vii, 285, 286, 287, 288, 290, 291, 296, 
297, 309, 370, 439, 470, 471, 472, 476, 477, 665, 
670, 775, 776, 784, 797 
Shakespeare, vi, 167, 168, 169, 170, 171, 172, 173, 
174, 175, 176, 177 
sickle cell disease, viii, 521, 522, 528, 530 
signal-to-noise ratio (SNR), 16, 20, 235, 1050 
signing, 138, 247, 249, 253, 256, 257, 263, 534, 808, 
1033 
simplified sign system, 247, 254, 255 
single side deafness, x, 511, 519, 989, 991 
sinus tympani, 831, 832, 880 
Sjögren Syndrome, 965 
SLC26A4 and SLC26A5, 661, 662 
sleep disordered breathing (SDB), 311, 312, 313, 
314 
sleep disorders, 279, 374, 381, 1006 
smoking, 78, 120, 211, 212, 214, 217, 320, 339, 589, 
602, 655, 656, 885, 896, 962 
somatosensory evoked potentials, 739, 740, 750, 
751, 805 
specificity, 9, 14, 15, 18, 19, 20, 22, 27, 30, 101, 
188, 191, 358, 396, 397, 516, 519, 604, 828, 834, 
846, 922, 962, 967, 979 
speech detection threshold, 52, 53, 55, 224, 891 
speech perception, 9, 34, 51, 53, 56, 224, 242, 294, 
433, 490, 491, 492, 499, 747, 748, 749, 751, 805, 
806, 892, 911, 925, 989, 990, 991, 992, 993, 994, 
996, 1019, 1021, 1028, 1029, 1030, 1045, 1046, 
1053, 1054, 1057, 1058, 1059 
speech reception threshold, 224 
speech stimuli tests, 22 
speech-language pathologists, 11, 12, 1032, 1033 
spiral ganglion cells, 101, 206, 277, 323, 327, 495, 
496, 601, 844, 916, 925, 932, 1005 
spoken language, 25, 47, 247, 248, 249, 250, 252, 
255, 263, 436, 722, 747, 751, 752, 808, 999, 
1000, 1003, 1025, 1026, 1029, 1030, 1031, 1032, 
1033, 1045 
stability, 264, 435, 468, 506, 507, 509, 510, 511, 
512, 517, 518, 519, 520, 692, 694, 697, 698, 788, 
792, 929, 1066 
stapedectomy, 245, 463, 682, 835, 919, 923, 924, 
925, 928, 929, 930, 933, 937 
stapes surgery, 245, 919, 923, 924, 925, 929, 930, 
931, 981, 988 
Stenger test, 228 
Stickler syndrome, 239, 451, 478, 479, 796, 800 
styloid process, 880 
sudden hearing loss, 4, 200, 201, 206, 214, 215, 218, 
246, 268, 269, 313, 315, 365, 366, 369, 370, 371, 
372, 604, 609, 610, 611, 612, 659, 682, 684, 685, 
687, 688, 689, 805, 935, 936, 938, 939, 941, 942, 

Index 
 
1082
943, 966, 1001, 1002, 1003, 1008, 1009, 1010, 
1011, 1012 
sudden sensorineural hearing loss, vi, vii, viii, ix, x, 
3, 4, 195, 198, 200, 201, 202, 203, 206, 209, 211, 
213, 215, 217, 218, 219, 246, 265, 268, 269, 312, 
315, 316, 365, 366, 368, 369, 371, 592, 596, 599, 
600, 601, 609, 610, 611, 612, 613, 655, 656, 658, 
659, 681, 689, 783, 901, 916, 935, 943, 955, 966, 
972, 985, 997, 999, 1000, 1001, 1008, 1009, 
1010, 1011, 1012, 1022 
superior semicircular canal (SSCC), 245, 650, 695, 
698, 816, 854, 880 
superoxide dismutase, vi, 3, 203, 204, 205, 206, 207, 
208, 209, 210, 273, 978, 984 
supporting cells, 206, 276, 657, 789, 886, 910, 947 
surgery, ix, 36, 53, 56, 147, 162, 163, 233, 244, 245, 
246, 265, 282, 285, 315, 316, 369, 370, 453, 463, 
489, 490, 493, 494, 496, 497, 498, 499, 500, 501, 
503, 515, 587, 599, 615, 630, 631, 639, 641, 645, 
652, 653, 659, 682, 683, 699, 703, 704, 705, 706, 
707, 708, 709, 710, 713, 716, 717, 719, 721, 723, 
724, 727, 728, 730, 732, 733, 734, 735, 736, 737, 
741, 780, 807, 810, 814, 821, 833, 834, 837, 838, 
846, 868, 869, 871, 872, 873, 894, 911, 914, 916, 
923, 925, 929, 930, 931, 932, 936, 937, 947, 951, 
954, 966, 975, 995, 1010, 1025, 1027, 1031, 
1032, 1034, 1035, 1037, 1039, 1041, 1047, 1052, 
1054, 1055, 1056, 1058 
surgical outcome, vii, 489, 490, 495, 724, 725 
Swedish Association for Hard of Hearing People 
(HRF), 386, 411, 424 
symbolic interactionism, 119, 120, 128, 130, 138 
syndrome, vii, 3, 6, 11, 112, 147, 148, 150, 159, 163, 
164, 165, 206, 214, 218, 239, 240, 241, 247, 253, 
291, 293, 294, 296, 306, 307, 308, 309, 310, 311, 
312, 314, 315, 316, 342, 449, 451, 452, 453, 454, 
455, 456, 457, 458, 460, 462, 468, 470, 472, 473, 
474, 477,480, 481, 482, 483, 511, 618, 623, 627, 
628, 629, 632, 633, 637, 639, 640, 646, 663, 675, 
682, 776, 777, 779, 780, 781, 783, 787, 793, 795, 
796, 797, 798, 799, 837, 838, 842, 843, 844, 860, 
861, 865, 867, 878, 879, 937, 946, 947, 948, 949, 
956, 962, 964, 970, 971, 972, 973, 974, 1009, 
1029, 1059 
syndromic hearing loss, 240, 286, 287, 288, 289, 
439, 451, 474, 475, 487, 618, 641, 675, 676, 776, 
777, 778, 780, 785, 786, 799, 885 
systemic lupus erythematosus, 844, 966, 972, 973 
T 
task difficult homeostasis (TDH), 387, 398, 399 
technology, 7, 8, 12, 15, 20, 22, 29, 32, 36, 39, 40, 
44, 45, 47, 48, 49, 112, 133, 158, 162, 164, 180, 
231, 234, 235, 247, 256, 257, 259, 272, 404, 427, 
431, 432, 433, 477, 490, 550, 565, 575, 578, 579, 
581, 582, 584, 716, 726, 730, 732, 736, 775, 776, 
994, 1018, 1019, 1021, 1040, 1042, 1045 
tegmen tympani, 823, 830, 831, 832, 880, 903, 905 
tele-audiology, 29, 30, 34 
telehealth, 7, 29, 35, 38 
temporal bone fracture, 189, 193, 639, 642, 650, 853, 
854, 855, 856, 857, 876, 901, 902, 903, 904, 905, 
907, 908, 909, 910, 911, 912, 913, 914, 915, 916 
tensor tympani muscle, 650, 880 
tensor tympani tendon, 880 
test battery, 13, 15, 21, 151, 234, 408, 430 
test performance, 19, 20, 21, 29, 107 
test protocol, 16 
text information processing system (TIPS), 387, 394, 
425 
threshold, 9, 11, 27, 29, 34, 36, 51, 52, 53, 55, 56, 
62, 78, 83, 93, 94, 95, 96, 97, 98, 99, 100, 101, 
102, 105, 106, 108, 129, 188, 190, 192, 199, 202, 
214, 218, 221, 222, 224, 228, 229, 230, 241, 277, 
321, 325, 328, 376, 397, 398, 399, 400, 408, 419, 
499, 523, 608, 617, 637, 638, 652, 658, 677, 683, 
701, 703, 711, 760, 761, 766, 806, 888, 893, 894, 
904, 920, 924, 927, 929, 976, 978, 979, 985, 990, 
996, 1001, 1016, 1027, 1036, 1038, 1039, 1040, 
1041, 1042, 1043, 1055 
tinnitus, vii, xiii, 3, 5, 21, 53, 57, 65, 66, 71, 72, 73, 
137, 147, 164, 216, 241, 242, 245, 266, 269, 275, 
276, 278, 279, 281, 282, 283, 311, 312, 315, 373, 
374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 
452, 462, 491, 507, 510, 515, 517, 518, 519, 520, 
592, 596, 600, 604, 606, 646, 648, 649, 683, 688, 
694, 697, 698, 802, 803, 809, 810, 817, 835, 836, 
891, 898, 899, 902, 907, 912, 914, 927, 935, 936, 
941, 942, 945, 946, 955, 956, 963, 964, 975, 976, 
978, 979, 980, 985, 986, 995, 1000, 1001, 1002, 
1003, 1008, 1009, 1012, 1019, 1020, 1022, 1023, 
1070 
tinnitus evaluation test, 279 
tinnitus handicap inventory, 279, 375, 382 
tinnitus loudness, 279, 373, 376, 378, 379, 380, 383 
tinnitus severity index, 279 
trail making test (TMT), 387, 394, 408, 436 
training, 12, 20, 22, 30, 37, 38, 43, 46, 47, 57, 59, 60, 
61, 62, 63, 71, 72, 73, 79, 83, 84, 86, 89, 90, 111, 
112, 114, 115, 117, 118, 120, 122, 123, 124, 125, 
126, 127, 130, 131, 132, 133, 137, 138, 140, 141, 
142, 143, 150, 151, 161, 164, 182, 248, 249, 250, 
251, 252, 255, 256, 259, 261, 263, 294, 333, 349, 
350, 356, 404, 430, 510, 512, 520, 616, 620, 724, 

Index 
 
1083
725, 726, 727, 729, 730, 735, 736, 747, 778, 
1038, 1039, 1040, 1047, 1067, 1068 
trans-differentiation, 276 
transection, 857, 858 
transient evoked otoacoustic emissions 
(TEOAEs)/transient evoked OAEs (TEOAEs), 16, 
18, 19, 34, 38, 68, 69, 75, 107, 190, 228, 229, 
236, 325, 376, 635, 637, 979 
translocation, 307, 465, 468, 493, 628 
trauma, 3, 4, 54, 189, 190, 198, 245, 266, 277, 282, 
374, 489, 494, 495, 496, 497, 507, 511, 592, 599, 
603, 605, 608, 611, 616, 639, 641, 645, 646, 650, 
651, 652, 695, 696, 730, 821, 836, 843, 853, 855, 
857, 859, 875, 876, 901, 902, 903, 904, 905, 909, 
910, 911,912, 913, 914, 936, 946, 956, 982, 983, 
984, 1002, 1035, 1068 
traumatic conditions, viii, 645, 906 
traumatic sensorineural hearing loss, x, 901, 902 
Treacher, 240, 454, 481, 780, 796, 800 
Treacher Collins syndrome, 454, 481, 780, 796, 800 
trisomy 21, 458, 459 
tRNASer(UCN), 661, 662, 670 
two-stage screening, 20, 22 
tympanic membrane, 13, 14, 16, 223, 226, 243, 277, 
281, 590, 592, 638, 648, 650, 651, 652, 694, 699, 
700, 703, 704, 708, 755, 756, 757, 758, 761, 822, 
823, 824, 826, 828, 829, 830, 831, 833, 841, 866, 
880, 893, 905, 907, 917, 969, 997, 1002, 1015, 
1037, 1044 
tympanogram, 13, 14, 15, 16, 102, 227, 244, 683, 
703, 937 
tympanometer, 16 
tympanometric peak pressure, 13, 226 
tympanometric width, 13, 226 
tympanometry, 7, 13, 14, 15, 16, 19, 20, 21, 29, 30, 
34, 35, 103, 191, 226, 227, 236, 279, 376, 521, 
523, 590, 604, 638, 651, 652, 683, 893, 936 
U 
universal newborn hearing screening, vi, 8, 13, 18, 
36, 50, 150, 165, 179, 180, 181, 183, 184, 185, 
797 
useful field of view (UFOV), 387, 394, 408 
Usher syndrome, 240, 455, 456, 461, 470, 474, 482, 
483, 485, 637, 663, 779, 784, 791, 794, 799, 800 
V 
variable expressivity, 453, 790 
vestibular aqueduct, 455, 639, 642, 838, 842, 864, 
869, 880, 946, 947, 949, 956, 957, 1002 
vestibular disorders, 512, 513, 514, 515, 516, 517, 
519, 602, 604, 913 
vestibular dysfunction, vi, 242, 245, 275, 276, 280, 
281, 284, 455, 519, 779, 790, 794, 795, 798, 914, 
961 
vestibular schwannoma (VS), 225, 242, 315, 452, 
688, 846, 847, 848, 849, 875, 941, 1022 
vestibular toxicity, 280 
vestibule, 493, 509, 514, 603, 618, 649, 692, 693, 
694, 696, 757, 836, 838, 839, 840, 841, 842, 846, 
880, 905, 907, 908, 909, 914, 950, 951, 960, 963 
vestibulo-cochlear nerve, 843 
virtual reality, ix, 723, 724, 725, 726, 727, 728, 729, 
730, 732, 733, 734, 735, 736, 737 
visual analog scale, 279 
Vogt-Koyanagi-Harada (VKH) syndrome, 964 
W 
Waardenburg syndrome, 240, 453, 481, 637, 663, 
781, 795, 800, 838, 843 
whisper test, 22 
whole genome sequencing, 286, 470, 471, 472 
Wolfram syndrome, 462, 486, 794, 795, 800 
word recognition, 56, 224, 225, 241, 427, 499, 891, 
990, 991, 1026, 1030, 1045 
working memory (WM), 274, 387, 391, 392, 393, 
394, 395, 396, 397, 404, 424, 425, 426, 433, 435, 
437, 502, 511, 518, 611, 889, 890, 894, 900, 932, 
989, 990, 991, 992, 993, 994, 996, 997, 1060 
World Health Organization (WHO), 11, 27, 38, 77, 
81, 146, 147, 165, 179, 184, 221, 237, 320, 331, 
339, 341, 343, 387, 389, 390, 395, 400, 408, 418, 
432, 437, 522, 528, 590, 595, 663, 697, 980, 982, 
987, 1001 
X 
X-linked, 239, 240, 442, 444, 448, 449, 452, 457, 
459, 463, 486, 616, 623, 632, 636, 664, 785, 786, 
787, 796, 838, 841, 874, 1029 
 

