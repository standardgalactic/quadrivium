
Formal Models of Operating System Kernels

Iain D. Craig
Formal Models of 
Operating System 
Kernels

Iain D. Craig, MA, PhD, FBCF, CITP
British Library Cataloguing in Publication Data
A catalogue record for this book is available from the British Library
Library of Congress Control Number: 2006928728
ISBN-10: 1-84628-375-2
Printed on acid-free paper
ISBN-13: 978-1-84628-375-8
© Springer-Verlag London Limited 2007
Apart from any fair dealing for the purposes of research or private study, or criticism or review, as
permitted under the Copyright, Designs and Patents Act 1988, this publication may only be
reproduced, stored or transmitted, in any form or by any means, with the prior permission in writing
of the publishers, or in the case of reprographic reproduction in accordance with the terms of
licences issued by the Copyright Licensing Agency. Enquiries concerning reproduction outside those
terms should be sent to the publishers.
The use of registered names, trademarks, etc. in this publication does not imply, even in the absence
of a specific statement, that such names are exempt from the relevant laws and regulations and
therefore free for general use.
The publisher makes no representation, express or implied, with regard to the accuracy of the
information contained in this book and cannot accept any legal responsibility or liability for any
errors or omissions that may be made.
9 8 7 6 5 4 3 2 1
Springer Science+Business Media
springer.com

To a very special friend—
Eheu fugaces labuntur anni

Preface
The work that this book represents is something I have wanted to do since
1979. While in Ireland, probably in 2001, I sketched some parts of a small
operating system speciﬁcation in Z but left it because of other duties. In
2002, I worked on the sketches again but was interrupted. Finally, in April,
2005, I decided to devote some time to it and produced what amounted to
a ﬁrst version of the kernel to be found in Chapter 3 of this book. I even
produced a few proofs, just to show that I was not on a completely insane
tack.
I decided to suggest the material as the subject of a book to Beverley
Ford. The material was sent on a Thursday (I think). The following Monday,
I received an email from her saying that it had gone out for review. The
review process took less than 2 weeks; the response was as surprising as it
was encouraging: a deﬁnite acceptance. So I got on with it.
This book is intended as a new way to approach operating systems de-
sign in general, and kernel design in particular. It was partly driven by the
old ambition mentioned above, by the need for greater clarity where it comes
to kernels and by the need, as I see it, for a better foundation for operating
systems design. Security aspects, too, played a part—as noted in the introduc-
tory chapter, if a system’s kernel is insecure or unreliable, it will undermine
attempts to construct secure software on top of it. Security does not otherwise
play a part in this book.
As Pike notes in [24], operating systems has become a rather boring area.
The fact that two systems dominate the world is a stultifying problem. There
are good ideas around and there is always new hardware that needs control-
ling. The advent of ubiquitous computing is also a challenge. I would be very
pleased if formal models helped people deﬁne new models for operating sys-
tems (the lack of implementation problems is a real help—I have used formal
models as a way of trying out new software ideas since the late 1980s).
Of course, I hope that people from formal methods and operating systems,
as well as computer science more generally, will read this book. I would like

viii
Preface
to think that it is a demonstration that system software can be modelled and
speciﬁed formally, endowing it with all the beneﬁts of formal methods.
What makes this book diﬀerent are the facts that it contains proofs of
properties and that it is broader in scope. The majority of the studies in the
literature omit proofs ([14] discusses proof but includes none). It seems to me
that proof is necessary for, otherwise, one is just describing systems in just
another fancy notation.
This book was written in a relatively short period of time (May–December,
2005). Every eﬀort has been made to ensure that it is error-free. The way I
approached the process of writing it was intended to reduce errors. Steve
Schuman has also read the entire text and the proofs. However, I cannot
say that the text does not contain any errors. For the mistakes that occur, I
apologise in advance.
Acknowledgements
First of all, I would like to thank Beverley Ford. Next, I would like to thank
Helen Desmond for running the project so smoothly. Steve Schuman promoted
the project, gave extremely useful advice on how to pitch it and read the
various intermediate versions of the manuscript (some a little chaotic) and
checked the proofs. My brother, Adam, once again produced the artwork
with remarkable speed and accuracy. For those who are not mentioned above
and who helped, my apologies for omitting to mention you. Your help was
appreciated.
Iain Craig
North Warwickshire,
January, 2006

Contents
Preface . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . vii
1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1
1.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1
1.2
Feasibility . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2
1.3
Why Build Models?. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4
1.4
Classical Kernels and Reﬁnement . . . . . . . . . . . . . . . . . . . . . . . . . .
5
1.5
Hardware and Its Role in Models . . . . . . . . . . . . . . . . . . . . . . . . . . 11
1.6
Organisation of this Book . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13
1.7
Choices and Their Justiﬁcations . . . . . . . . . . . . . . . . . . . . . . . . . . . 14
2
Standard and Generic Components . . . . . . . . . . . . . . . . . . . . . . . . 17
2.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17
2.2
Generic Tables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17
2.3
Queues and Their Properties . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21
2.4
Hardware Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27
2.4.1
CCS Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27
2.4.2
Registers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29
2.4.3
Interrupt Flag . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31
2.4.4
Timer Interrupts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32
2.4.5
Process Time Quanta . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36
2.5
Processes and the Process Table . . . . . . . . . . . . . . . . . . . . . . . . . . . 39
2.6
Context Switch . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51
2.7
Current Process and Ready Queue . . . . . . . . . . . . . . . . . . . . . . . . . 52
3
A Simple Kernel . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55
3.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55
3.2
Requirements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55
3.3
Primary Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56
3.4
Basic Abstractions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58
3.5
Priority Queue . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 71

x
Contents
3.6
Current Process and Prioritised Ready Queue . . . . . . . . . . . . . . . 77
3.7
Messages and Semaphore Tables . . . . . . . . . . . . . . . . . . . . . . . . . . . 81
3.8
Process Creation and Destruction . . . . . . . . . . . . . . . . . . . . . . . . . 84
3.9
Concluding Remarks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 85
4
A Swapping Kernel . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87
4.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87
4.2
Requirements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87
4.3
Common Structures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 88
4.3.1
Hardware . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 88
4.3.2
Queues. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 93
4.3.3
Process Queue . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 94
4.3.4
Synchronisation and IPC . . . . . . . . . . . . . . . . . . . . . . . . . . . 97
4.4
Process Management. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103
4.5
The Scheduler . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 126
4.6
Storage Management. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 144
4.6.1
Swap Disk . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 158
4.6.2
Swapper . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 163
4.6.3
Clock Process . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 173
4.6.4
Process Swapping . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 186
4.7
Process Creation and Termination . . . . . . . . . . . . . . . . . . . . . . . . . 191
4.8
General Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 198
5
Using Messages in the Swapping Kernel . . . . . . . . . . . . . . . . . . . 203
5.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 203
5.2
Requirements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 204
5.3
Message-Passing Primitives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 205
5.4
Drivers Using Messages . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 224
5.4.1
The Clock . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 225
5.5
Swapping Using Messages . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 228
5.6
Kernel Interface . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231
6
Virtual Storage . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 239
6.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 239
6.2
Outline . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 239
6.3
Virtual Storage . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 240
6.3.1
The Paging Disk Process . . . . . . . . . . . . . . . . . . . . . . . . . . . 263
6.3.2
Placement: Demand Paging and LRU . . . . . . . . . . . . . . . . 267
6.3.3
On Page Fault . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 268
6.3.4
Extending Process Storage . . . . . . . . . . . . . . . . . . . . . . . . . 288
6.4
Using Virtual Storage . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 299
6.4.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 299
6.4.2
Virtual Addresses . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 300
6.4.3
Mapping Pages to Disk (and Vice Versa) . . . . . . . . . . . . . 305
6.4.4
New (User) Process Allocation and Deallocation. . . . . . . 306

Contents
xi
6.5
Real and Virtual Devices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 309
6.6
Message Passing in Virtual Store . . . . . . . . . . . . . . . . . . . . . . . . . . 310
6.7
Process Creation and Termination; Swapping . . . . . . . . . . . . . . . 311
7
Final Remarks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 313
7.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 313
7.2
Review . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 313
7.3
Future Prospects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 316
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 319
List of Deﬁnitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 321
Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 331

List of Figures
1.1
The layers of the classical kernel model. . . . . . . . . . . . . . . . . . . . . .
7
4.1
The layer-by-layer organisation of the kernel. . . . . . . . . . . . . . . . . 89
4.2
The clock process in relation to its interrupt and alarm requests. 174
4.3
Interaction between clock and swapper processes. . . . . . . . . . . . . . 186
4.4
Interaction between clock, swap and dezombiﬁer processes. . . . . . 191
6.1
The layer-by-layer organisation of the kernel, including virtual
storage-management modules. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 241
6.2
Interactions between virtual storage components. . . . . . . . . . . . . . . 264
6.3
Process organisation for handling page faults. . . . . . . . . . . . . . . . . 268
6.4
The actual speciﬁcation. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 281
6.5
The speciﬁcation using a queue. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 282
6.6
The ideal speciﬁcation. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 284

1
Introduction
Dimidium facti qui coepit habet; sapere aude.
– Horace, Epistles, I, ii, 40
1.1 Introduction
Operating systems are, arguably, the most critical part of any computer sys-
tem. The kernel manages the computational resources used by applications.
Recent episodes have shown that the operating system is a signiﬁcant thorn
in the side of those desiring secure systems. The reliability of the entire op-
erating system, as well as its performance, depends upon having a reliable
kernel. The kernel is therefore not only a signiﬁcant piece of software in its
own right, but also a critical module.
Formal methods have been used in connection with operating systems for
a long time. The most obvious place for the application of mathematics is
in modelling operating system queues. There has been previous work in this
area, for example:
•
the UCLA Security Kernel [32];
•
the work by Bevier [2] on formal models of kernels;
•
Horning’s papers on OS speciﬁcation [3]
•
the NICTA Workshop in 2004 on operating systems veriﬁcation [23];
•
Zhou and Black’s work [37].
Much of the formal work on operating systems has been veriﬁcational in
nature. That is, given some working software, an attempt is made to justify
that software by constructing a formal model. This is clearly in evidence in the
NICTA Workshop [23] papers about the L4 kernel [13, 31]. Formal methods
in this case are used in a descriptive fashion. Certainly, if the model is good
enough, it can be used to reason about the reliability of the implemented
software; it can also be used to clarify the relationships between the modules in

2
1 Introduction
that software. However, the descriptive approach requires an adequate model,
and that can be hard to obtain.
What is proposed in this book is a prescriptive approach. The formal
model should be constructed before code is written. The formal model is then
used in reasoning about the system as an abstract, mathematical entity. Fur-
thermore, a formal model can be used for other purposes (e.g., teaching kernel
design, training in the use and conﬁguration of the kernel). C. A. R. Hoare has
complained that there are too many books on operating systems that just go
through the concepts and present a few case studies—there are a great many
examples from which to choose; what is required, he has repeatedly argued,
is detailed descriptions of new systems1.
The formal speciﬁcation and derivation of operating system kernels is also
of clear beneﬁt to the real-time/embedded systems community. Here, the ker-
nels tend to be quite simple and their storage management requirements less
complex than in general-purpose systems like Linux, Solaris and Windows
NT. Embedded systems must be as reliable as possible, fault tolerant and
small. However, a kernel designed for an embedded application often contains
most of the major abstractions employed by a large multiprogramming sys-
tem; from this, it is clear that the lessons learned in specifying a small kernel
can be generalised and transferred to the process of specifying a kernel for
a larger system. Given the networking of most systems today, some of the
distinctions between real-time and general-purpose systems are, in any case,
disappearing (network events must be handled in real time, after all).
For the reasons given in the last paragraph, the ﬁrst speciﬁcation in this
book is of a kernel that could be used in an embedded or real-time system. It
exports a process abstraction and a rich set of inter-process communication
methods (semaphores, shared buﬀers and mailboxes or message queues). This
kernel is of about the same complexity as µC/OS [18], a small kernel for
embedded and real-time applications.
1.2 Feasibility
It is often argued that there are limits to what can be formally speciﬁed. There
are two parts to this argument:
•
limits to what can proﬁtably be speciﬁed formally.
•
a priori limits on what can be formally speciﬁed.
The ﬁrst is either a philosophical, pragmatic or economic issue. As a philo-
sophical argument, there is G¨odel’s (second) theorem. As an economic ar-
gument, the fact that formal speciﬁcation and derivation take longer than
1 This is not to denigrate any of them. Most contain lucid explanations of the
concepts. The point is that they tend only to repeat the principles and sketch
well-known systems.

1.2 Feasibility
3
traditional design and construction methods is usually taken as an argument
that they are only of “academic interest”. This argument ignores the fact that
the testing phase can be reduced or almost entirely omitted because code is
correct with respect to the speciﬁcation. (Actually, a good testing schedule
can be used to increase conﬁdence in the software.) In the author’s experi-
ence, formally speciﬁed code (and by this is meant speciﬁcation supported by
proofs) works ﬁrst time and works according to speciﬁcation.
The existence of a formal model also has implications for maintenance
and modiﬁcation. The consequences of a “small patch” are often impossible
to predict. With a formal model, the implications can be drawn out and
consequences derived. With informal methods, this cannot be done and users
are disappointed and inconvenienced (or worse).
As to what can proﬁtably be speciﬁed, it would appear that just about
any formal speciﬁcation can be proﬁtable, even the swap program. There was
a notion a few years ago that only safety-critical components should be for-
mally speciﬁed; the rest could be left to informal methods. This might be
possible if the dependencies between safety-critical and noncritical compo-
nents can be identiﬁed with 100% accuracy. The problem is that this is not
often undertaken. Again, formal methods reveal the dependencies.
So what about the argument that programmers cannot do formal speciﬁ-
cation, that only mathematicians can do it? One argument is that we should
be teaching our people rather more than how to read syntax and hack code;
they should be taught abstractions right from the start. This is not something
one readily learns from lectures on syntax and coding methods; it is not even
something that can be learned from lectures on design using informal tools
or methods (waterfalls, ‘extreme’ programming, etc.). Much of the mathe-
matics used in formal speciﬁcations is quite simple and its use requires and
induces clearer thinking about what one is doing and why. There is a clear
problem with the way in which computer scientists are trained and with the
perceptions, abilities and knowledge of many of those who train them.
The second argument is that it is just impossible to specify everything
in a formal way. Programs, and processes for that matter, are structured
entities that can be described in formal ways. This is admitted by the other
side, but there are things like compilers, operating systems, command and
control systems and a whole list of other kinds of systems that simply cannot
be formally speciﬁed. The reason usually given is that they are too complex
or complicated. Operating systems have the additional problem that they
deal with hardware and “you can’t specify that”. There are many possible
answers; for example, to point to hardware speciﬁcation languages, to point
to speciﬁcations of hardware or to point out that a piece of hardware can
be modelled in an abstract fashion. Critics object that the speciﬁcation will
be too abstract to be of use—it cannot capture every aspect of the hardware
device. This is true: abstractions do not capture every detail, only the relevant
ones.

4
1 Introduction
For example, a model of a disk drive might include read and write opera-
tions and might contain a mapping from disk locations to data. Such a model
would be of considerable use. The objection from the doubter is that such a
model does not include disk-head seek time. Of course, seek times are relevant
at low levels (and temporal logic can help—the speciﬁcation says “eventually
the disk returns a buﬀer of data or a failure report”).
The next objection is that it is impossible to model those aspects of the
processor required to specify a kernel. And so it goes on.
The only way to silence such objections is to go ahead and engage in the
exercise. That is one reason for writing this book: it is an existence proof.
1.3 Why Build Models?
It has always been clear to the author that a formal speciﬁcation could serve
as more than a basis for reﬁnement to code. A formal speciﬁcation constitutes
a formal model; important properties can be proved before any code is written.
This was one of the reasons for writing [10]. In addition to that book, formal
models and proofs were used by the author as a way of exploring a number of
new systems during the 1990s without having to implement them (they were
later implemented using the formal models). The approach has the beneﬁt
that a system’s design or, indeed, an entire approach to a system, can be
explored thoroughly without the need for implementation. The cost (and risk)
of implementation can thereby be avoided.
In the case of operating systems, implementation can be lengthy (and
therefore costly) and require the construction of drivers and other “messy”
parts2. The conventional approach to OS (and other software) design requires
an implementation so that properties can be determined empirically. Deter-
mining properties of all software at present is a wholly empirical exercise; not
all consequences of a given collection of design decisions are made apparent
without prolonged experience with the software. The formal approach will
never (and should never) obviate empirical methods; instead, it allows the
designer to determine properties of the system a priori and to justify them in
unambiguous terms.
The production of a formal model of a system poses the same problems
as does a conventional design and implementation. Interfaces have to be de-
ﬁned, as must behaviours. However, a formal model aﬀords the opportunity
to state the design in an unambiguous form in which properties can be stated
2 OS Kit from the University of Utah—see the Computer Science Department’s
Web site—is a considerable aid in constructing new systems by providing Inter-
rupt Service Routines (ISRs), drivers and other basic components that can be
slotted together to form a substrate upon which to build the upper layers of an
operating system. OS Kit is a software kit, not a formal speciﬁcation or modelling
tool.

1.4 Classical Kernels and Reﬁnement
5
as propositions to be proved. The proof of such properties makes an essen-
tial contribution to the exercise by justifying the claims. Proofs provide more
insight into the design, even if they seem to be proofs of obvious properties
(there are lots of examples above). The point is that the statement of a prop-
erty as a proposition to be proved makes that property explicit; otherwise, it
will remain implicit or just another line in the formal statement of the model.
The properties proved as part of formal modelling reveal characteristics
of the software in a way that cannot be obtained by implementation—it can
be construed as an exploration without the expense (and frustration) of im-
plementation. This is, of course, not to deny implementation: the goal of all
software projects is the production of working code. The point is that formal
models provide a level of exploration that is not obtained by a purely em-
pirical approach. Furthermore, formal models document the system and its
properties: they can serve as information, inspiration or warnings to others.
A further advantage of the formal approach is that it always leaves imple-
mentation as an option. With the conventional approach, implementation is
a necessity.
1.4 Classical Kernels and Reﬁnement
The focus in this book is on what might be called the “classical” operating
system kernel. This is the kind of kernel that is amply documented in the
literature (the books and papers cited in this paragraph are all good exam-
ples). It is the approach to kernel design that has evolved since the early
days of computers through such systems as the TITAN Supervisor [34], the
the operating system [19] and Brinch Hansen’s RC4000 supervisor [5]; it is
the approach to kernels described in standard texts on operating systems (for
example, [29, 11, 26] to cite but three from the past twenty years).
The classical operating system kernel is to be found in most of the systems
today: Unix, POSIX and Linux, Microsoft’s NT, IBM’s mainframe operating
systems and many real-time kernels. In days of greater diversity, it was the
approach adopted in the design of Digital Equipment’s operating systems:
RSTS, RSX11/M, TOPS10, TOPS20, VMS and others. Other, now defunct
manufacturers also employed it for their product ranges, each with a diﬀerent
choice of primitives and interfaces depending upon system purpose, scope and
hardware characteristics. Such richness was then perceived as a nuisance, not
a reservoir of ideas.
The classical approach regards operating system kernels as layered enti-
ties: a layer of primitives must be deﬁned to execute above the hardware,
providing a collection of abstractions to be employed by the remainder of the
system. Above this layer are arranged layers of increasing abstraction, includ-
ing storage management, various clocks and alarms. Finally, there comes the
layer in which ﬁle management, database interfaces and interfaces to network

6
1 Introduction
services appear. At the very top of the hierarchy, there is usually a mecha-
nism that permits user code to invoke system services; this mechanism has
been variously called SVCs, Supervisor Calls, System Calls, or, sometimes,
Extracodes.
This approach to the design of operating systems can be traced back at
least to the the operating system of Dijkstra et al. [19]. (It could be argued
that the the system took many current ideas and welded them into a coher-
ent and elegant whole.) The layered approach makes for easier analysis and
design, as well as for a more orderly construction process. (It also assists in the
organisation of the work of teams constructing such software, once interfaces
have been deﬁned.) It is sometimes claimed that layered designs are inherently
slower than other approaches, but with the kernel some amount of layering is
required; raw hardware provides only electrical, not software, interfaces.
The classical approach has been well-explored as a space within which
to design operating system kernels, as the list of examples above indicates.
This implies that the approach is relatively stable and comparatively well-
understood; this does not mean, of course, that every design is identical or
that all properties are completely determined by the approach.
The classical model assumes that interacting processes, each with their own
store, are executed. Execution is the operation of selecting the next process
that is ready to run. The selection might be on the basis of which process
has the highest priority, which process ran last (e.g., round-robin) or on some
other criterion. Interaction between processes can take the form of shared
storage areas (such as critical sections or monitors), messages or events. Each
process is associated with its own private storage area or areas. Processes
can be interrupted when devices are ready to perform input/output (I/O)
operations. This roughly deﬁnes the layering shown in Figure 1.1.
At the very bottom are located the ISRs (Interrupt Service Routines).
Much of the work of an ISR is based on the interface presented by the device.
Consequently, there is little room in an ISR for very much abstraction (al-
though we have done our best below): ideally, an ISR does as little as possible
so that it terminates as soon as possible.
One layer above ISRs come the primitive structures required by the rest
of the kernel. The structures deﬁned at this level are exported in various ways
to the layers above. In particular, primitives representing processes are imple-
mented. The process representation includes storage for state information (for
storage of registers and each process’ instruction pointer) and a representation
of the process’ priority (which must also be stored when not required by the
scheduling subsystem). Other information, such as message queues and stor-
age descriptors, are also associated with each process and stored by operations
deﬁned in this layer.
Immediately above this there is the scheduler. The scheduler determines
which process is next to run. It also holds objects representing processes that
are ready to execute; they are held in some form of queue structure, which
will be referred to as the ready queue. There are other operations exported by

1.4 Classical Kernels and Reﬁnement
7
IPC
Process Abstraction
i/o r/gs
System
Calls
User
Processes
alarms
Context
Switch
Device
Software
Hardware
Device
H/W 
Clock
Device
Process
Table
Device
Processes
(drivers)
Swap
Tables
Swap
Disk
Kernel Interface Routines
Swapper
Process
Clock
Process
Low-Level
Scheduler
ISRs
Kernel
Primitive
System
Processes
ISR
ISR
ISR
Clock
Fig. 1.1. The layers of the classical kernel model.
the scheduler, for example, removal of a ready or running process from the
ready queue or an operation for the self-termination of the current process.
Context switches are called from this layer (as well as others).
Above the process representation and the scheduler comes the IPC layer.
It usually requires access not only to
the process representation (and the
process-describing tables) but also to the scheduler so that the currently exe-
cuting process can be altered and processes entered into or removed from the
ready queue. There are many diﬀerent types of IPC, including:
•
semaphores and shared memory;
•
asynchronous message exchange;
•
synchronous message exchange (e.g., rendezvous);

8
1 Introduction
•
monitors;
•
events and Signals.
Synchronisation as well as communication must be implemented within this
layer. As is well-documented in the literature, all of the methods listed above
can perform both functions.
Some classical kernels provide only one kind of IPC mechanism (e.g., the
[19], solo [6]). Others (e.g., Linux, Microsoft’s NT, Unix System V) provide
more than one. System V provides, inter alia, semaphores, shared memory and
shared queues, as well as signals and pipes, which are, admittedly, intended for
user processes. The essential point is that there is provision for inter-process
synchronisation and communication.
With these primitive structures in place, the kernel can then be extended
to a collection of system operations implemented as processes. In particular,
processes to handle storage management and the current time are required.
The reasons for storage management provision clear; those for a clock are,
perhaps, less so.
Among other things, the clock process has the following uses:
•
It can record the current time of day in a way that can be used by processes
either to display it to the user or employ it in processing of some kind or
another.
•
It can record the time elapsed since some event.
•
It can provide a sleep mechanism for processes. That is, processes can
block on a request to be unblocked after a speciﬁed period of time has
elapsed.
•
It can determine when the current process should be pre-empted (if it is a
pre-emptable process—some processes are not pre-emptable, for example,
some or all system processes).
In addition to a storage manager and a clock, device drivers are often
described as occurring in this layer. The primary reason for this is that pro-
cesses require the mechanisms deﬁned in the layers below this one—it is the
ﬁrst layer at which processes are possible.
The processes deﬁned in this layer are often treated diﬀerently from those
above. They can be assigned ﬁxed priorities and permitted either to run to
completion or until they suspend themselves. For example, device drivers are
often activated by the ISR performing a V (Signal) operation on a semaphore.
The driver then executes for a while, processing one or more requests until
it performs a P operation on the semaphore (an equivalent with messages is
also used, as is one based on signals).
The characteristics of the processes in this layer are that:
•
They are trusted.
•
Their behaviour is entirely predictable (they complete or block).
•
They run for relatively short periods of time when executed.

1.4 Classical Kernels and Reﬁnement
9
The only exception is the storage manager, which might have to perform
a search for unallocated blocks of store. (The storage manager speciﬁed in
Chapter 4 does exactly this.) However, free store is represented in a form that
facilitates the search.
Above this layer, there comes the interface to the kernel. This consists
of a library of system calls and a mechanism for executing them inside the
kernel. Some kernels are protected by a binary semaphore, while others (Mach
is a good, clear example) implement this interface using messages. Above this
layer come user processes.
Some readers will now be asking: what about the ﬁle system and other
kinds of persistent, structured storage? This point will be addressed below
when deﬁning the scope of the kernels modelled in this book (Section 1.7).
The classical model can therefore be considered as a relatively high-level
speciﬁcation of the operating system kernel. It is possible to take the position
that all designs, whether actual or imagined, are reﬁnements of this speciﬁca-
tion.
As a high-level speciﬁcation, the approach has its own invariants that must
be respected by these reﬁnements. The invariants are general in nature, for
example:
•
Each process has a state that can be uniquely represented as a set of
registers and storage descriptors.
•
Each process is in exactly one state at any time. One possible set of states
of a process is: ready (i.e., ready to execute), running (executing), waiting
or (blocked) and terminated.
•
Each process resides in at most one queue at any time3.
•
Each process can request at most one device at any one time. This is a
corollary to the queues invariant.
•
Each process owns one or more regions of storage that are disjoint from
each other and from all others. (This has to be relaxed slightly for virtual
store: each process owns a set of pages that is disjoint from all others.)
•
There is exactly one process executing at any one time. (This clearly needs
generalising for multi-processor machines; however, this book deals only
with uni-processors.)
•
When a process is not executing, it does nothing. This implies that pro-
cesses cannot make requests to devices when they are not running, nor can
they engage in inter-process communications or any other operations that
might change their state.
•
An idle process is often employed to soak up processor cycles when there
are no other processes ready to execute. The idle process is pre-empted as
soon as a “real” process enters the scheduler.
3 It might be thought that each process must be on exactly one queue. There are
designs, such as the message-passing kernel of Chapter 5, in which processes do
not reside in queues—in this case, when waiting to receive a message.

10
1 Introduction
•
The kernel has a single mechanism that shares the processor fairly between
all processes according to need (by dint of being the unique running pro-
cess) or current importance (priority).
•
Processes can synchronise and communicate with each other;
•
Storage is ﬂat (i.e., it is a contiguous sequence of bytes or words); it is
randomly addressed (like an array).
•
Only one user process can be in the kernel at any one time.
These invariants and the structres to which they relate can be reﬁned in
various ways. For example:
•
Each process can share a region of its private storage with another process
in order to share information with that other process.
•
User processes may not occupy the processor for more than n µseconds
before blocking. (n is a parameter that can be set to 1 or can vary with
load.)
•
A process executes until either it has exceeded its allocated time or a
process of higher priority becomes ready to execute.
Multi-processor systems also require that some invariants be altered or re-
laxed. The focus in this book is on single-processor systems.
It is sometimes claimed that modern operating systems are interrupt-
driven (that is, nothing happens until an interrupt occurs). This is explained
by the fact that many systems perform a reschedule and a context switch
at the end of their ISRs. A context switch is always guaranteed to occur be-
cause the hardware clock periodically interrupts the system. While this is true
for many systems, it is false for many others. For example, if a system uses
semaphores as the basis for its IPC, a context switch occurs at the end of the
P (Wait) operation if there is already a process inside the critical section. A
similar argument applies to signal-based systems such as the original Unix.
Because this book concentrates on classical kernel designs and attempts
to model them in abstract terms, each model can be seen as a reﬁnement of
the more abstract classical kernel model. Such a reﬁnement might be partial
in the sense that not all aspects of the classical model are included (this is
exempliﬁed by the tiny kernel modelled as the ﬁrst example) or of a greater or
total coverage (as exempliﬁed by the second and third models, which contain
all aspects of the classical design in slightly diﬀerent ways).
Virtual store causes a slight problem for the classical model. The layers of
the classical organisation remain the same, as do their invariants. The princi-
ples underlying storage and the invariants stated above also remain invariant.
However, the exact location of the storage management structures is slightly
diﬀerent.
The storage management of a classical kernel is a relatively simple matter:
the tables are of ﬁxed size, as are queue lengths (the maximum possible queue
length is just the number of processes that can be supported by the kernel).
The kernel stack (if used) will tend to be small (it must be allocated in a

1.5 Hardware and Its Role in Models
11
ﬁxed-size region of store, in any case). The basics of virtual storage allocation
and deallocation are simple: allocation and deallocation are in multiples of
ﬁxed-sized pages.
The problem is the following: the kernel must contain a page-fault handler
and support for virtual storage. Page tables tend to be relatively large, so it
makes sense to use virtual store to allocate them. This implies that virtual
storage must be in place in order to implement virtual storage. The problem
is solved by bootstrapping virtual storage into the kernel; the kernel is then
allocated in pages that are locked into main store. The bootstrapping process
is outside the layered architecture of the classical kernel, so descriptions in
the literature of virtual storage tend to omit the messy details. Once a virtual
store has been booted, the storage manager process can operate in the same
place as in real-store kernels.
Virtual storage introduces a number of simpliﬁcations into a kernel but at
the expense of a more complex bootstrap and a more involved storage man-
ager (in particular, it needs to be optimised more carefully, a point discussed
in some detail in Chapter 6). Virtual machines also introduce a cleaner sepa-
ration between the kernel and the rest of the system but imposes the need to
switch data between virtual machines (an issue that is omitted from Chapter
6 because there are many solutions).
The introduction of virtual storage and the consequent abstraction of vir-
tual machines appears at ﬁrst to move away from the classical kernel model.
However, as the argument above and the model of Chapter 6 indicate, there
is, in fact, no conﬂict and the classical model can be adapted easily to the
virtual storage case. A richer and more radical virtual machine model, say
Iliﬀe’s Basic Language Machine [17], might turn out to be a diﬀerent story
but one that is outside the scope of the present book and its models.
1.5 Hardware and Its Role in Models
Hardware is one of the reasons for the existence of the kernel. Kernels ab-
stract from the details of individual items of hardware, even processors in the
case of portable kernels. Kernels also deal directly with hardware by saving
and restoring general-purpose registers on context switches, setting ﬂags and
executing ISRs.
The kernel is also where interrupts are handled by ISRs and devices han-
dled by their speciﬁc drivers. No model of an operating system kernel is com-
plete without a model (at some level of abstraction) of the hardware on which
it is assumed to execute.
In the models below, there is only relatively little material devoted to
hardware. Most of this is general and included in Chapter 2. This must be
accounted for.
First, consider interrupts. Each processor type has its own way of dealing
with interrupts. First, there is the question of vectored or non-vectored inter-

12
1 Introduction
rupts: some processors (the majority) oﬀer vectored interrupts, while others
do not. Next, what are the actions performed by the processor when an in-
terrupt occurs? Some processors do very little other than indicate that the
interrupt has actually occurred. If the processor uses vectored interrupts, it
will execute the code each interrupt vector element associates with its inter-
rupt. Although not modelled below, an interrupt vector would be a mapping
between the interrupt number, say, and the code to be executed, and some
entries in the vector might be left empty. Some processors save the contents
of the general-purpose registers (or a subset of them) in a speciﬁc location.
This location might be a ﬁxed area of store, an area of store pointed to by a
register that is set by the hardware interrupt or it might be on the top of the
current stack (it might be none of these).
After the code of an ISR has executed, there must be a return to normal
processing. Some processors are designed so that this is implemented as a
jump, some implement it as a normal subroutine return, while still others
implement it as a special instruction that performs some kind of subroutine
return and also sets ﬂags. The advantage of the subroutine return approach is
that the saved registers are restored when the ISR terminates—this is a little
awkward if a reschedule occurs and a context switch is required, but that is a
detail.
There are other properties of interrupts that diﬀerentiate processors, the
most important of which the prioritised interrupts. It is not possible to con-
sider all the variations. Instead, it is necessary to take an abstract view, as
abstract as is consistent with the remainder of the model. The most abstract
view is that processors have a way of indicating that an asynchronous hard-
ware event has occurred.
Interrupts are only one aspect of the hardware considerations. The number
of general-purpose registers provided by a processor is another. Kernels do
not, at least do not typically, alter the values in particular registers belonging
to the processes it executes (e.g., to return values, as, e.g., in a subroutine
call). For this reason, the register set can be modelled as an abstract entity;
it consists of a set of registers (the maximum number is assumed known, and
it might be 0 as in a stack machine, but not used anywhere other than in
the deﬁnition of the abstractions) and a pair of operations, one to obtain the
registers’ values from the hardware and one to set hardware register values
from the abstraction.
There is also the issue of whether the processor must be in a special ker-
nel mode when executing the kernel. Kernel mode often enables additional
instructions that are not available to user-mode processes.
There are many such issues pertaining to hardware. Most of the time,
they are of no interest when engaging in a modelling or high-level speciﬁcation
exercise; they become an issue when reﬁnement is underway. The speciﬁcation
of a low-level scheduler has precious little to do with the exact details of the
rti instruction’s operation. What is required is that the speciﬁcation or model

1.6 Organisation of this Book
13
be structured in such a way that, when these details become signiﬁcant, they
can be handled in the most appropriate or convenient way.
The diversity of individual devices connected to a processor also provides
a source either of richness or frustration. Where there are no standards, device
manufacturers are free to construct the interfaces that are most appropriate
to their needs. Where there are standards, there can be more uniformity but
there can also be details like requiring a driver to wait n µs before performing
the next instruction or to wait m µs before testing a pin again to conﬁrm that
it has changed its state.
Again, the precise details of devices are considered a matter of reﬁnement
and abstract interfaces are assumed or modelled if required. (The hardware
clock and the page-fault mechanism are two cases that are considered in de-
tail below.) In these cases, the reﬁnement argument is supported by device-
independent I/O, portable operating systems work over many years and by
driver construction techniques such as that used in Linux [25]. The reﬁnement
argument is, though, strengthened by the fact that the details of how a device
interface operates are only the concern to the driver, not to the rest of the
kernel; only when reﬁning the driver do the details become important.
Nevertheless, the hardware and its gross behaviour are important to the
models. For this reason, a small model of an ideal processor is deﬁned and
included in the common structures chapter (Chapter 2). The hardware model
includes a single-level interrupt mechanism and the necessary interactions be-
tween hardware and kernel software are represented. The real purpose of this
model is to capture the interactions between hardware and software; this is an
aspect of the models that we consider of some importance (indeed, as impor-
tant as making explicit the above assumptions about hardware abstraction).
1.6 Organisation of this Book
The organisation of this book is summarised in this section. Chapters 2 to 6
contain the main technical material, and the last chapter (Chapter 7) contains
a summary of what has been done. It also contains some suggestions about
where to go next.
Very brieﬂy, the technical chapters are as follows.
Chapter 2. Common structures. This chapter contains the Z speciﬁcation
of a number of structures that are common to most kernels. These struc-
tures include FIFO queues, process tables and semaphores. Also included is a
hardware model. This is very simple and quite general and is included just to
orient the reader as well as to render explicit our assumptions about the hard-
ware. CCS [21] is used for the operational part of this model. Some relevant
propositions are proved in this chapter.
Chapter 3. A simple kernel. This kernel is of the type often found in real-
time and embedded systems. It is relatively simple and open. It serves as an
introduction to the process of modelling kernels. The focus, as far as formally

14
1 Introduction
proved properties are concerned, is the priority queue that is used by this
kernel’s scheduler.
Chapter 4. The swapping kernel. This is a kernel of the kind often found
in mini-computers such as the PDP-11/40 and 44 that did not have virtual
storage. It includes IPC (using semaphores), process management and stor-
age management. The system includes a process-swapping mechanism that
periodically swaps processes to backing store. The kernel uses interrupts for
system calls, as is exempliﬁed by the clock process (the sole example of a
device driver). The chapter contains proofs of many properties.
Chapter 5. This is a variation on the kernel modelled in Chapter 4. The
diﬀerence is that IPC is now implemented as message passing. This requires
changes to the system processes, as well as the addition of generic structures
for handling interrupts and the context switch. The kernel interface is imple-
mented using message passing. A number of properties are proved.
Chapter 6. The main purpose of this chapter is to show that virtual storage
can be included in a kernel model. Virtual storage is today too important to
ignore; in the future, it is to be expected that embedded processors will include
virtual storage4. Many properties are proved.
1.7 Choices and Their Justiﬁcations
It is worth explaining some of the choices made in this book.
Originally, the models were written in Z [28]. Unfortunately, a considerable
amount of promotion was required. The presence of framing schemata in the
speciﬁcation tended, in our belief, to obscure the details of the models. Object-
Z [12, 27] uses a reference-based model that makes promotion a transparent
operation.
Chapter 2 still contains a fair amount of pure Z: this is to orient readers
who are more familiar with Z than Object-Z and give them some idea of the
structures used in the rest of the book. The chapter contains some framing
schemata and promoted operations. The reader should be able to see how
framing gets in the way of a clear presentation. Chapter 2 also contains some
CCS.
Object-Z is an object-oriented speciﬁcation language. Although the models
in this book in no way demand object-oriented speciﬁcation or implementa-
tion, the modularity of Object-Z again seems to make each model’s structure
clearer since operations can be directly related to the modular structure to
which they naturally belong. During the speciﬁcation in Object-Z, objects
were considered more in the light of modules (as in Modula2) or Ada packages.
Every eﬀort, however, has been made to conform to Object-Z’s semantics, so
it could be argued that the speciﬁcations are genuinely object-oriented; this
is an issue we prefer to ignore.
4 The StrongArm processor has, for example, included virtual storage support
since before the year 2000.

1.7 Choices and Their Justiﬁcations
15
As can be inferred from the comment above, CCS [21] is used in a few
places. CCS was chosen over CSP [16], π-calculus [22, 33] or some other process
algebra (e.g., [1]) because it expresses everything required of it here in a
compact fashion. The Concurrency Workbench [8] is available to support work
in CCS, as will be seen in Chapter 6. Use of CCS is limited to those places
where interactions between component processes must be emphasised or where
interactions are the primary issue.
The use of Woodcock et al.’s Circus speciﬁcation [7] language was con-
sidered and some considerable work was done in that language. In order to
integrate a Circus model with the remainder of the models and to model a
full kernel in Circus, it would have been necessary to model message pass-
ing and the proof that the model coincided with the one assumed by Circus
would have to have been included. Another notation would have tended to
distract readers from the main theme of this book, as would the additional
equivalence proofs.
It was originally intended to include a chapter on a monitor-based kernel.
The use of monitors makes for a clearly structured kernel, but this structure
only appears above the IPC layer. Eventually, it turned out that:
1. the chapter added little or nothing to the general argument; and
2. Inclusion of the chapter would have made an already somewhat long book
even longer.
For this reason, the chapter was omitted. This is a pity because, as just noted,
monitors make for nicely structured concurrent programs and the speciﬁca-
tion of monitors and monitor-using processes in Object-Z is in itself a rather
pleasing entity.
Some readers will be wondering why there are no reﬁnements included
in this book. Is this because there have been none completed (for whatever
reason, for example because they do not result in appropriate software) or for
some other reason? We have almost completed the reﬁnement of two diﬀerent
kernels similar to the swapping kernel (but without the swap space), one
based on semaphores and one based on messages. The target for reﬁnement
is Ada. These reﬁnements will have been completed by the time this book
is published. The reasons for omitting them are that there was no time to
include them in this book and that they are rather long (the completed one
is more than 100 A4 pages of handwritten notes). It is hoped that the details
of these reﬁnements, as well as the code, will be published in due course.
It cannot be stressed enough times that the models presented in this book
are logical models. The intention is that they should be the subject of reason-
ing. In order to reﬁne the models to code, some extra work has to be done;
for example, some sequential compositions will have to be introduced and
predicates rearranged or regrouped. The aim here is to make the constructs
as clear as possible, even if this means that the grouping of predicates is not
optimal for a reﬁnement attempt.

16
1 Introduction
It is a natural question to ask why temporal logic has not been used in this
book. The work by Bevier [2] uses temporal logic. Temporal logic is a natural
system for specifying concurrent and parallel programs and systems. The an-
swer is that temporal logic is simply not necessary. Everything can be done
in Z or Object-Z. A process algebra (CCS [21]) is used in a few cases to de-
scribe interactions between components and to prove behavioural equivalence
between interacting processes. The approach adopted here is directly analo-
gous to the use of a sequential programming language to program a kernel:
the result might be parallel but the means of achieving it are sequential.
This book concentrates on what is referred to as the “classical” kernel
paradigm. The reason for excluding other kernel designs, say those based on
events, is that they are not as widely known. In order to demonstrate that
formal models are possible for kernels, it would appear wiser to attempt the
most widely known paradigm. The classical kernel comes in many diﬀerent
ﬂavours, so the scope for diﬀerent models is relatively broad.

2
Standard and Generic Components
2.1 Introduction
In this chapter, we introduce some of the more common structures encoun-
tered in operating system kernels. Each structure is speciﬁed and, frequently,
properties of that structure are proved. This provides a formal basis upon
which to construct the kernels of this book. Some of the structures are used
with minor variations (for example, semaphores will be redeﬁned in the next
two chapters), while others are not explicitly used at all (for example, tables).
The reason for explicitly specifying and proving properties of such struc-
tures is that they will usually appear as components of other structures. For
example, the generic table structure, GENTBL[K,D], appears as the process
table in all of the following models, with or without some extra components.
There are instances of semaphore and message queue tables. As a consequence,
properties of these supporting structures might be omitted by accident, even
though they are of considerable importance to the overall speciﬁcation of the
system. The purpose of this chapter is to supply those additional proofs.
2.2 Generic Tables
Tables appear in a number of places in the speciﬁcations to follow. The process
table is one example, as is the queue of alarm requests in the clock driver.
Tables are mappings of some kind from a set of keys (e.g., process references)
to a set of data items (for example, process descriptors). The state is deﬁned
(in Z) as:
GENTBL [K, D]
tbl : K  →D
keys : F K
keys = dom tbl

18
2 Standard and Generic Components
This is a generic schema for obvious reasons. The variable keys is the set of
domain elements of the mapping tbl (i.e., the keys of the table).
The table is initialised by the following operation:
InitGENTBL [K, D]
GENTBL[K, D]′
keys′ = ∅
The set of keys is initialised to empty.
Sometimes, it is useful to determine which keys are in the table. The
following schema deﬁnes that operation:
TBLContainsKey [K, D]
ΞGENTBL[K, D]
k? : K
k? ∈keys
If a table has been initialised and no other update operations have been
performed, then that table contains no keys. This is the point of the following
proposition.
Proposition 1.
InitGENTBL[K, D] ⇒¬ ∃k : K • TBLContainsKey′[K, D][k/k?]
Proof.
The predicate of InitGENTBL is keys′ = ∅. The predicate of
TBLContainsKey′ is: k? ∈keys′. If keys = ∅, there can be no k? such that
is an element of keys.
2
The following operation adds a key-datum pair to a table. Strictly speak-
ing, if the key is already in the table, an error should be raised. Here, we are
just deﬁning the operations, so the error condition is ignored. In any case,
a user of this component might want to report a more relevant error than a
simple “duplicate key”.
AddTBLEntry [K, D]
∆GENTBL[K, D]
k? : K
d? : D
tbl ′ = tbl ∪{k? →d?}
Since the key, k?, is assumed not to be in the table, set union can be used
rather than domain override (⊕).

2.2 Generic Tables
19
Proposition 2. The conjunction
¬ TBLContainsKey ∧AddTBLEntry[K, D][k/k?, d/d?]
implies TBLContainsKey[K, D][k/k?].
Proof. The predicate of TBLContainsKey side is:
k? ̸∈keys ∧
tbl ′ = tbl ∪{k? →d?}
Since keys = dom tbl, by taking domains:
dom tbl ′
= dom(tbl ∪{k? →d?})
= (dom tbl) ∪dom({k? →d?})
= keys ∪{k?}
= keys′
So k? ∈keys′
2
The next operation is the one that retrieves the datum corresponding to
a key. If the key is not present, an error should be raised (or some default
value returned); this is ignored for the same reason that was given above. The
schema is:
GetTBLEntry [K, D]
GENTBL[K, D]
k? : K
d! : D
d! = tbl(k?)
The operation to remove a key-datum pair from a table is deﬁned by the
following schema. If the key is not present, the table is invariant. This is the
point of the second proposition after the schema.
DelTBLEntry [K, D]
GENTBL[K, D]
k? : K
tbl ′ = {k?} −◁tbl
The domain subtraction operator, −◁, is used to remove k? from tbl’s domain.
Proposition 3. DelTBLEntry[K, D] ⇒¬ TBLContainsKey′[K, D].

20
2 Standard and Generic Components
Proof. The right-hand side is k? ̸∈keys′. Since keys = dom tbl, the result
can be obtained by taking domains:
dom tbl ′
= dom({k?} −◁tbl)
= dom(tbl \ {k?})
= (dom tbl) \ {k?}
= keys \ {k?}
= keys′
Therefore k? ̸∈keys′.
2
Proposition 4. If k ∈K is not in keys, DelTBLEntry[K, D][k/k?] leaves tbl
invariant.
Proof. By deﬁnition of −◁.
2
Another common operation is overwriting the datum corresponding to a
key that is already present in a table. The operation is deﬁned by the following
schema:
OverwriteTBLEntry [K, D]
GENTBL[K, D]
k? : K
d? : D
tbl ′ = tbl ⊕{k? →d?}
The following proposition shows that overwriting is the same as a deletion
followed by an addition.
Proposition 5. If k ∈keys,
OverwriteTBLEntry[K, D][k/k?, d/d?] =
(DelTBLEntry[K, D] o
9 AddTBLEntry[K, D])[k/k?, d/d?]
Proof. The composition of DelTBLEntry o
9 AddTBLEntry, when expanded,
is:
∃tbl ′′ : K  →D •
tbl ′′ = {k} −◁tbl ∧
tbl ′ = tbl ′′ ∪{k? →d?}
Clearly, k? ̸∈dom({k} −◁tbl). Equally clearly, k? ∈dom{k? →d?} and is
therefore in dom tbl′, so tbl′(k?) = d?.
The deﬁnition of f ⊕g is:

2.3 Queues and Their Properties
21
(f ⊕g)(x) =

g(x)
:
if x ̸∈dom f
f (x)
:
otherwise.
Setting f = tbl′′ and g = {k? →d?}, it is obvious that:
(tbl′′ ⊕{k? →d?})(x) =

tbl′′(x)
:
if x ̸= k?
k? →d?(x)
:
if x = k?
The two predicates coincide.
2
2.3 Queues and Their Properties
Queues are one of the primary data types used in the speciﬁcation and imple-
mentation of operating system kernels. For this reason, this section contains
the basic speciﬁcation of the queue type, as well as a collection of proofs. The
queue type is quite general and is of a FIFO (First-In, First-Out) queue. It is
essential that a type as important as the FIFO queue is completely understood
and supported by proofs of its major properties.
The queue is generic so it can be instantiated to any element type. The
operations speciﬁed for this type are the ones that will usually occur in the
speciﬁcations that follow.
The type that is deﬁned by the following schema is intended to be used for
a good many data types within the kernel. After presenting this speciﬁcation,
a version is deﬁned and justiﬁed that contains process references (speciﬁcally
elements of the type APREF which is deﬁned below in Sections 3.3 and 4.4)
is deﬁned and justiﬁed. As will be seen, it has the same operations as the
generic queue type that is deﬁned here.
This is the generic FIFO queue type:
QUEUE [X ]
elts : seq X
The queue is represented quite naturally in Z by a sequence of elements of
some type (here, the generic type X ). Sequences in Z are just partial functions
from a subset of N to another set, here X .
The initialisation operation for QUEUE[X ] (recall that the name includes
the generic parameter) is as follows:
InitQUEUE [X ]
QUEUE[X ]′
elts′ = ⟨⟩
The schema deﬁnes the after state of the operation only. The sequence is set
to the empty sequence, ⟨⟩.

22
2 Standard and Generic Components
The length of the queue is the number of elements it contains:
LengthOfQUEUE [X ]
ΞQUEUE[X ]
len! : N
len! = #elts
It is necessary to determine whether a queue contains elements (for ex-
ample, when removing or dequeuing the ﬁrst element). The following schema
deﬁnes this test:
EmptyQUEUE [X ]
ΞQUEUE[X ]
elts = ⟨⟩
The Enqueue[X ] operation adds an element to the end of the queue. It is
naturally modelled in Z by the following schema:
Enqueue [X ]
∆QUEUE[X ]
x? : X
elts′ = elts ⌢⟨x?⟩
To dequeue an element from a queue according to the FIFO scheme, the
ﬁrst element is removed, provided that the queue is not empty. The following
schema deﬁnes the removal operation only:
RemoveFirst [X ]
∆QUEUE[X ]
x! : X
⟨x!⟩⌢elts′ = elts
Equivalently, the RemoveFirst operation could be written as:
∆QUEUE[X ]
x! : X
x! = head elts
elts′ = tail elts
This form is one that will often be used in proofs below.
Sometimes, it is necessary to test whether an element is present in a queue.
The following schema models this test:

2.3 Queues and Their Properties
23
IsInQueue [X ]
ΞQUEUE
x? : X
x? ∈ran elts
Occasionally, the index of an element in the queue is required. This oper-
ation is modelled by the following schema:
QueueEltIndex [X ]
ΞQUEUE[X ]
x? : X
n! : N1
(∃n : N1 | n ∈1..#elts •
elts(n) = x? ∧n = n!)
or elts(n!) = x? for some n (both versions are non-deterministic).
It will frequently be necessary to remove queue elements that are not at
the head of the queue. This is modelled by the following schema:
RemoveQueueElt [X ]
∆QUEUE[X ]
x? : X
∃s, t : seq X | elts = s ⌢⟨x?⟩⌢t •
elts′ = s ⌢t
This operation is a necessary one. In the kernels that appear in this book,
the unready operation is frequently used. The unready operation removes a
process from the queue in which it resides. The element to be removed is
not, however, the head of the queue. The unready operation’s core is the
RemoveQueueElt operation just deﬁned.
Just for completeness, a collection of error types is deﬁned for the generic
QUEUE[X ] type and the operations deﬁned over it.
QERROR ::= emptyqerr | okq
EmptyQError
qerr! : QERROR
qerr! = emptyqerr
QOk
qerr! : QERROR
qerr! = okq

24
2 Standard and Generic Components
Traditionally, the FIFO queue is equipped with a Dequeue operation. This
operation would be deﬁned as follows:
Dequeuea[X ] =
(¬ EmptyQUEUE[X ] ∧RemoveFirst[z])
∨EmptyQError
The operation must ﬁrst test the queue to determine that it contains at least
one element. If the queue is empty, an error is usually raised. If the queue is
not empty, the ﬁrst element is removed and all is well (denoted by the QOk
operation).
Meanwhile, for the propositions that follow, the following deﬁnition is quite
satisfactory:
Dequeue[X ] = RemoveFirst[X ]
Indeed, this deﬁnition permits reasoning about empty queues that would oth-
erwise be complicated by the error schemata (EmptyQError).
This is the way in which removal of the queue head is treated in the
models that follow. The reason for this is that the emptiness test is performed
somewhere else, somewhere that makes better sense for the operation in which
RemoveFirst occurs. It is, in any case, something of an inconvenience to use
the error schemata deﬁned above.
A number of fairly obvious propositions are now proved about QUEUE[X ].
This ﬁrst proposition shows that an enqueue followed immediately by a
dequeue produces a queue that is diﬀerent from the one prior to the operation.
Proposition 6. If Enqueue[X ] o
9 Dequeue[X ], then elts ̸= elts′.
Proof. The predicate of operation Enqueue is:
elts′ = elts ⌢⟨x?⟩
While the predicate of operation Dequeue is:
elts = ⟨x!⟩⌢elts′
By the deﬁnition of sequential composition (and changing output variable
name to avoid confusion):
Enqueue o
9 Dequeue ≡
∃elts′′ : seq X •
elts′′ = elts ⌢⟨x?⟩∧
elts′′ = ⟨y!⟩⌢elts′
The second conjunct can be re-written as:
elts′ = tail elts′′
y! = head elts′′

2.3 Queues and Their Properties
25
So,
y! ⌢((tail elts) ⌢⟨x?⟩)
= (head elts) ⌢(tail elts) ⌢⟨x?⟩
= (head elts) ⌢((tail elts) ⌢⟨x?⟩)
which implies that:
elts′ = (tail elts) ⌢⟨x?⟩
̸= elts
2
Proposition 7. If #elts ≥2, RemoveFirst[X ] implies that tail(tail elts) =
tail elts′
Proof. The predicate of the RemoveFirst[X ] schema is:
x! = head elts
elts′ = tail elts
For some y:
tail tail elts
= tail(tail⟨x!⟩⌢⟨y⟩⌢elts′′)
= tail(⟨y⟩⌢elts′′)
= elts′′
2
Proposition 8. If elts ̸= ⟨⟩, RemoveFirst[X ] implies that:
head elts ̸= head elts′
Proof. Let elts = ⟨x⟩⌢⟨y⟩⌢elts′′.
elts′
= tail elts
= tail(⟨x!⟩⌢⟨y⟩⌢elts′′)
= ⟨y⟩⌢elts′′
Note that, even if x! = y, we can consider them to be diﬀerent instances of
x!.
2

26
2 Standard and Generic Components
Proposition 9. If, for some element, x, of elts, if elts(n) = x for some n,
such that 1 ≤n ≤#elts, then RemoveNextn[X ] removes x from the queue,
where:
RemoveNextn ≡



(RemoveNext
o
9 . . .
o
9 RemoveNext) n times
Proof. The proof is by induction on the length of the preﬁx (i.e., the elements
elts(1) . . . elts(n −1)). The length is denoted by k.
The predicate of RemoveNext is (changing the name of the output vari-
able):
elts = ⟨y!⟩⌢elts′
Case k = 0, then x = head elts, so RemoveNext removes it from the queue.
Case k = n −1. So, there are n −1 elements ahead of x in elts. By deﬁnition
of RemoveNext, RemoveNextn−1 removes them, so x = head elts. Therefore,
RemoveNextn removes x from elts.
2
Proposition 10. If x is an element of elts, and, for some m, such that
1 ≤m ≤#elts, elts(m) = x, then, assuming no removals from the queue,
Enqueuen, for all n, leaves x at the same index.
Proof. Enqueuen is deﬁned as:



Enqueue
o
9 . . .
o
9 Enqueue n times
If n = 0, Enqueue0 can be deﬁned as elts′ = elts ⌢⟨⟩.
It can be assumed without loss of generality that, for some i, i > 0,
elts(i) = x and #elts = i.
The proof proceeds by induction that Enqueuen, n ≥0, leaves elts(i) = x.
Case n = 0, so elts(i) = elts′(i) = x.This is for the reason that Enqueue0
implies that elts′ = elts ⌢⟨⟩= elts.
Case n = k −1, then #elts′ = (#elts) + k −1 since
Enqueuek−1 = elts ⌢⟨x1, . . . , xk−1⟩
where the elements xj, 1 ≤j ≤k −1 occur after x in elts′. The elements
in the sequence (λ j : m + 1 . . m + k −1 • elts(j)) clearly appear at indices
greater than m, so elts′(m) = elts(m) = x.
2
Corollary 1. If #elts = n and n > 0, Dequeue[X ]m ⇒elts′ ̸= ⟨⟩, if and
only if m < n.
Proof. Immediate from Proposition 9.
2

2.4 Hardware Model
27
Corollary 2. If #elts = n, Dequeue[X ]n ⇒elts′ = ⟨⟩
Proof. Immediate from Proposition 9.
2
Corollary 3. If elts = ⟨⟩, then, for all n and m,
Enqueue[X ]n o
9 Dequeue[X ]m ⇒elts′ = ⟨⟩
if and only if n = m.
Proof. Immediate from Propositions 9 and 10.
2
2.4 Hardware Model
As stated above, a hardware model is required. In this section, a simple model
is deﬁned. The purpose of this section is to make clear the assumptions about
the hardware that are made for the remainder of this book. The section re-
mains somewhat outside the rest of the models because the hardware is rather
outside the kernels modelled here.
In this section, the use of Z is replaced by the use of CCS, which is used to
model the fundamental behaviour of the hardware, in particular the interrupt
structure. There are no proofs to be undertaken: the material is suggestive of
a general architecture, not a model of a speciﬁc one.
2.4.1 CCS Model
CCS [21] is used to model the hardware. CCS is a well-known process algebra
with a small set of operations. It is well-suited to describing the hardware’s
operations.
The hardware is modelled by a CCS process, HW . The model is not com-
plete and is intended merely to be suggestive of the actions taken by the
hardware in response to various signals.
The ﬁrst action of this process is start, which starts the hardware (ini-
tialises it, etc.). The hardware then behaves as if it were process HW1. This
process waits for a message. If the message is an interrupt, ii, it saves the
register set (by a hidden action, saveregs) and then waits for the signal to
restore it; after the restoreregs signal has been received, the process iterates.
If the message is setregs, the hardware loads values (unspeciﬁed) into the
general-purpose (i.e., programmable) registers; if the message is getregs, the
hardware returns the register set (by performing an action not shown in the
deﬁnition of HW1).
The process is arranged so that neither a setregs nor a getregs action can
be performed while the register set is saved.

28
2 Standard and Generic Components
The hardware process is deﬁned as:
HW = start.HW1
HW1 = (i1.saveregs + HW1
+setregs.HW1
+getregs.HW1
+restoreregs.HW1) \ saveregs
The following pair of processes are intended to model the behaviour of
hardware when an interrupt occurs. The process Inti represents the ith in-
terrupt. When it receives its internal interrupt signal, ii, it signals that the
Interrupt Service Routine (ISR) corresponding to this interrupt should be ex-
ecuted; this is done by sending the runisr i message. The interrupt process
then recurs, ready to accept another interrupt signal. The second process,
ISRi, is intended roughly to model the actions of the ISR corresponding to
interrupt i. When the ISR receives the signal to execute (runisri), it performs
the service action and then instructs the hardware to restore the register set
to the way it was before the interrupt occurred. The ISR process then recurs,
so that it can accept another interrupt.
Inti = i1.runisr 1.Inti
ISRi = runisr.service.restoreregs.ISRi
The hardware and interrupt subsystem can be thought of as the following
(parallel) composition of processes:
H = HW | Πi∈I (Inti | ISRi)
The next process models the interrupt mask. The interrupt mask deter-
mines whether interrupts are signalled or not (it is modelled in this book by
the Lock Object-Z class).
IntMask = on.IntMask(1)
IntMask(v) = oﬀ.IntMask(0)
+on.IntMask(1)
+stat.istat(n).IntMask(n)
The interrupt mask enables the hardware model to be extended so that inter-
rupts can be enabled and disabled under programmer control. Integration of
the interrupt mask and the process P is left as an exercise for the interested
reader.
The model works as follows. Initially, the IntMask accepts an on event to
initialise the mask. Initialisation enables interrupts and takes the state of the
mask as its parameter (the value in parentheses). After this, the mask oﬀers
three possible actions: oﬀto disable interrupts, on to enable them and stat to
enquire about the state of the mask. When IntMask engages in an oﬀaction, it
disables interrupts (denoted by the 0 parameter). Alternatively, it can engage
in an on action. If interrupts are currently disabled, the on action re-enables

2.4 Hardware Model
29
them; otherwise, it does nothing. Finally, some other component (say, some
software) can enquire as to the state of the interrupt mask by engaging in
the third possible action, stat (status). The IntMask process then returns the
current status (denoted by n) via an istat (interrupt status) action; enquiry
does not aﬀect the state of the mask. This is indicated by the recursion on
the same value as that communicated by the istat action.
This is a single-level interrupt scheme. Some processors have a multi-level
one. At the level of detail required in this book, the diﬀerences between single-
and multi-level interrupt schemes are not signiﬁcant, so a single-level scheme
is assumed for simplicity.
Purely for interest, a multi-level interrupt mask, MLIMask, can be deﬁned
as follows. First, the mask is initialised by participating in an allon (all on)
action:
MLIMask = allon.MLIMask(S)
Here, the parameter S denotes the set of all interrupt levels. The mask now
behaves as follows:
MLIMask(S) = oﬀ(i).MLIMask(S \ {i})
+on(i).MLIMask(S ∪{i})
+ison(i).istat(i ∈S).MLIMask(S)
+oﬀm(I ).MLIMask(S \ I )
+onm(I ).MLIMask(S ∪I )
where I denotes a set of interrupt levels and i is an individual level.
2.4.2 Registers
The processor contains a set of general-purpose registersas well as a set of
more specialised ones: stack register, instruction pointer and status register
(sometimes called the “status word”). It is assumed that each register is one
PSU wide.
The model of the registers is rather minimal. There is not a lot that can
be proved about it.
It is assumed that the hardware is not a stack machine (i.e., a single-
address machine, that is). If a stack machine were the target, the registers
would not strictly be required. Actually, many stack machines do have the
odd oﬀ-stack register just as an optimisation.
The number of general-purpose registers is given by:
numregs : N1
Note that no value is given. This is a partial speciﬁcation (it is, in any case,
impossible to assign a value to numregs without knowing which processor is
being used).
The register names form the following set:

30
2 Standard and Generic Components
GENREG == {r0, . . . , rnumregs−1}
The contents of this set are of no further interest to us because the register
set will be manipulated as a complete entity.
The register set is deﬁned as a function from register (index) to the value
it contains:
GENREGSET == GENREG →PSU
The status register contains a value. That value is of the following type.
It is assumed to be of the same size (in bits) as an element of PSU .
[STATUSWD]
This will be an enumeration, for example: overﬂow, division by zero, carry set.
The register state is deﬁned by the following schema:
HWREGISTERS
hwregset : GENREGSET
hwstack : PSTACK
hwip : N
hwstatwd : STATUSWD
The general register set is hwregset, the stack is in hwstack, the instruction
pointer (program counter) is hwip and the status word is denoted by hwstatwd.
The following deﬁnes the zero elements for PSU and STATUSWD:
0PSU : PSU
clear : STATUSWD
The registers are initialised when the hardware starts up. This initialisation
is modelled by the following operation:
InitHWREGISTERS
HWREGISTERS ′
(∀r : GENREGSET •
r ∈hwregset′ ⇒hwregset′(r) = 0PSU)
hwip′ = 0
hwstack ′ = EmptyStack
hwstatwd ′ = clear
This schema does not appear in any of the kernels because it will have been
referenced (executed) before any kernel initialisation operations are executed.
It is included for completeness.

2.4 Hardware Model
31
2.4.3 Interrupt Flag
The interrupt ﬂag is of crucial importance in the models that follow. The
ﬂag is of a type containing two values (they could be true and false or 0 and
1—symbolic values are used instead for easier interpretation of often complex
schemata):
INTERRUPTSTATUS ::= inton | intoﬀ
The value inton represents the hardware state in which interrupts are enabled.
The value intoﬀdenotes the fact that interrupts have been disabled.
The interrupt ﬂag itself is deﬁned as:
INTERRUPTFLAG
iﬂag : INTERRUPTSTATUS
When the hardware starts up, it will execute an operation similar to that
denoted by the following schema:
InitINTERRUPTFLAG
INTERRUPTFLAG′
iﬂag′ = inton
This schema is similar to the register-initialisation schema. It is assumed that
the hardware executes it before the kernel bootstrap starts executing. This
will be the only time we see this schema.
There are three operations associated with the interrupt ﬂag. Two are
under program control: one disables and one enables interrupts. The remaining
operation raises the interrupt and performs operations such as saving the
current register state and transferring control to an ISR.
The operation to disable interrupts is modelled here as:
DisableInterrupts
∆INTERRUPTFLAG
iﬂag′ = intoﬀ
The operation to enable interrupts is:
EnableInterrupts
∆INTERRUPTFLAG
iﬂag′ = inton
Interrupts are disabled and then enabled again to ensure that no interrupts
occur during the execution of a piece of code. They are used as a kind of low-
level mutual exclusion mechanism.

32
2 Standard and Generic Components
It is usual to deﬁne a couple of operations, named Lock and Unlock, to
perform the disabling and enabling of interrupts. These operations are usually
deﬁned as assembly language macros. The names are used because they are
better mnemonics. They are deﬁned as:
Lock = DisableInterrupts
and:
Unlock = EnableInterrupts
2.4.4 Timer Interrupts
Most processors have a hardware clock that generates interrupts at a regular
rate (e.g., typically 60Hz, the US mains supply frequency). Timer interrupts
are used to implement process alarms (sleep periods—the term “alarm” is used
in this book by analogy with “alarm clock”). A process suspends itself for a
speciﬁed period of time. When that time, as measured by the hardware clock,
has expired, the process is resumed (by giving it an “alarm call”). A piece
of code, which will be called the clock driver in this book, is responsible for
(among other things) suspending processes requesting alarms and for resuming
them when the timer has expired.
This subsection is concerned with the general operation of the clock driver
and with clock interrupts. The clock will be used in a number of places in the
kernels that follow and it will be re-modelled in various forms. The purpose
of the current section is just to orient the reader and to show that such a
low-level model can be produced in Z (later in Object-Z) in a fashion that is
relatively clear and, what is more, in a form that allows a number of properties
to be proved.
The hardware clock is associated with the interrupt number:
clockintno : INTNO
Time is modelled as a subset of the naturals:
TIMEVAL == N
Here, time is expressed in terms of uninterpreted units called “ticks” (assumed
to occur at regular intervals, say every 1/60 second).
The clock is just a register that contains the current time, expressed in
some units:
CLOCK
timenow : TIMEVAL
The hardware initialises the clock on startup. (The clock can also be reset
on some processors.)

2.4 Hardware Model
33
InitCLOCK
CLOCK ′
timenow ′ = 0
The length of the clock tick often needs to be converted into some other
unit. For example, a 60Hz “tick” might be converted into seconds.
ticklength : TIMEVAL
The clock updates itself on every hardware “tick”:
UpdateCLOCKOnTick
∆CLOCK
timenow ′ = timenow + ticklength
When the current time is required, the following operation is used:
TimeNow
ΞCLOCK
now! : TIMEVAL
now! = timenow
When a process needs to set an alarm, it sends the clock driver a message
of the following type:
TIMERRQ == PREF × TIMEVAL
The message contains the identiﬁer of the requesting process (here, of type
PREF, the most general process reference type) plus the time by which it
expects to receive the alarm.
The following axioms deﬁne functions to access elements of TIMERRQ
(which are obvious and merit no comment):
timerrq pid : TIMERRQ →PREF
timerrq time : TIMERRQ →TIMEVAL
∀t : TIMERRQ •
timerrq pid(t) = fst t
timerrq time(t) = snd t
The queue is represented as a ﬁnite set of requests. An instance of
QUEUE[X ] could be used but, as will be seen, searching might have to be
performed to ﬁnd the process to wake and the actual arrival time of requests
in the queue is not of any particular importance, so a more abstract view of
the queue, as a collection, is used instead.

34
2 Standard and Generic Components
The request queue is deﬁned as:
TIMERRQQUEUE
telts : F TIMERRQ
The request queue is initialised by the following operation. It can be called
at any time the kernel is running, say on a warm reboot.
InitTIMERRQQUEUE
TIMERRQQUEUE ′
telts′ = ∅
The following schema deﬁnes a predicate that is true when the request
queue is empty:
EmptyTIMERRQQUEUE
ΞTIMERRQQUEUE
telts = ∅
The following three schemata deﬁne operations that add and remove re-
quests:
EnqueueTIMERRQ
∆TIMERRQQUEUE
tr? : TIMERRQ
telts′ = telts ∪{tr?}
RemoveFirstTIMERRQ
∆TIMERRQQUEUE
tr! : TIMERRQ
{tr!} ∪telts′ = telts
This operation removes the ﬁrst element of the queue. It is a non-deterministic
operation.
RemoveTIMERRQQueueElt
∆TIMERRQQUEUE
tr? : TIMERRQ
tr? ∈telts
telts′ = telts \ {tr?}

2.4 Hardware Model
35
This schema deﬁnes an operation that removes an arbitrary element of the
request queue.
The following schema deﬁnes a combination of a clock and a request queue.
The instance of CLOCK is intended to be a register holding a copy of the
hardware clock’s current value. The idea is that the clock driver copies the
hardware clock’s value so that the driver can refer to it without needing to
access the hardware.
TIMER = TIMERRQQUEUE ∧CLOCK
This expands into:
telts : F TIMERRQ
timenow : TIMEVAL
The timer is initialised by the obvious operation:
TIMERInit =
InitCLOCK ∧
TIMERInit
This expands into:
TIMER′
CLOCK ′
timenow ′ = 0
telts′ = ∅
The following condition must always hold:
Proposition 11. At any time, now:
∀tr : TIMERRQ •
tr ∈telts ⇒timerrq time(tr) > now
Proposition 12. At any time, now:
¬ ∃tr : TIMERRQ •
tr ∈telts ∧timerrq time(tr) ≤now
Both of these propositions are consequences of Proposition 92 (p. 173).
Their proofs are omitted.
In order to unblock those processes whose alarms have gone oﬀ, the follow-
ing schema is used. It returns a set of requests whose time component speciﬁes
a time that is now in the past:

36
2 Standard and Generic Components
TimerRequestsNowActive
∆TIMER
trqset! : F TIMERRQ
trqset! = {trq : TIMERRQ | trq ∈telts ∧timerrq time(trq) ≤timenow • trq}
telts′ = telts \ trqset!
This is the basis of a CLOCK process:
OnTimerInterrupt =
(UpdateCLOCKOnTick o
9
((TimerRequestsNowActive[trqset/trqset!] ∧
(∀trq : TIMERRQ | trq ∈trqset ∧timerrq pid(trq) ∈known procs •
(∃p : PREF; | p = timerrq pid(trq) •
MakeReadypq[p/pid?]))) \ {trqset}))
The operation works as follows. First, the clock is updated by one tick. Then,
those processes whose alarms have gone oﬀ(expired) are found in and removed
from the set of waiting processes. Each one of these processes is put into the
ready queue (MakeReadypq[p/pid?]).
The basic operation executed by a process when requesting an alarm is
the following:
WaitForTimerInterrupt =
(([CURRENTPROCESS; time? : TIMEVAL; trq : TIMERRQ |
trq = (currentp, time?)] ∧
Lock ∧EnqueueTIMERRQ[trq/tr?]) \ {trq} ∧
MakeUnready[currentp/pid?] ∧
SwitchFullContextOut[currentp/pid?] ∧
SCHEDULENEXT)o
9
Unlock
In Chapter 4, some properties of the clock process and its alarm mechanism
will be proved.
2.4.5 Process Time Quanta
In some of the kernels to follow, user processes are scheduled using a pre-
emptive method. Pre-emption is implemented in part using time quanta. Each
user process (system processes are not allocated time quanta and cannot be
pre-empted) is allocated a time quantum, a value of type TIMEVAL. On
each hardware clock “tick”, the time quantum is decremented. When the
quantum reaches some threshold value, the process is suspended. When that
same process is executed the next time, it is assigned a new quantum.
To begin, the type of time quantum is deﬁned:
time quantum : TIMEVAL

2.4 Hardware Model
37
For the purpose of this book, every user process uses the same values for
initialisation and threshold.
The following schema retrieves the value of a process’ time quantum from
the process table.
ProcessQuantum
ΞPROCESSES
pid? : PREF
timeq! : TIMEVAL
timeq! = pquants(pid?)
The next schema deﬁnes an operation that sets the initial value for its
time quantum:
SetInitialProcessQuantum
∆PROCESSES
pid? : PREF
time quant? : TIMEVAL
pquants′ = pquants ∪{pid? →time quant?}
When a process’ time quantum is to be reset, the following operation does
the work:
ResetProcessTimeQuantum =
(∃q : TIMEVAL | q = time quantum •
UpdateProcessQuantum[time quantum/timeq?])
The following schema models an operation that sets the current value of
its time quantum in its process descriptor:
UpdateProcessQuantum
∆PROCESSES
pid? : PREF
timeq? : TIMEVAL
pquants′ = pquants ⊕{pid? →timeq?}
This operation can be used when the process is interrupted or when a higher-
priority process must be scheduled.
There is a storage location that holds the current process’ time quantum
while it executes:
SetCurrentProcessQuantum
∆CURRENTPROCESSpq
timequant? : TIMEVAL
tq′ = timequant?

38
2 Standard and Generic Components
The quantum is updated by:
UpdateCurrentProcessQuantum
∆CURRENTPROCESSpq
now? : TIMEVAL
tq′ = tq −now?
This schema deﬁnes a predicate that is satisﬁed when the current process’
time quantum has expired:
CurrentProcessQuantumHasExpired
ΞCURRENTPROCESSpq
tq ≤0
The current process quantum is read from the storage location by the next
schema:
CurrentProcessQuantum
ΞCURRENTPROCESSpq
tquant! : TIMEVAL
tquant! = tq
On each hardware clock tick, the current process’ time quantum is updated
by the following operation:
UpdateCurrentQuantumOnTimerClick =
(TimeNow[now/now!] ∧
UpdateCurrentProcessQuantum[now/now?]) \ {now}
This operation is already represented in the last line of OnTimerInterrupt.
When a process is blocked, the following are required:
SaveCurrentProcessQuantum =
(CurrentProcessQuantum[tquant/tquant!] ∧
UpdateProcessQuantum[tquant/timeq?]) \ {tquant}
This expands into:
ΞCURRENTPROCESSpq
∆PROCESSES
(∃tquant : TIMEVAL •
tquant = tq ∧
pquants′ = pquants ⊕{pid? →tquant?})

2.5 Processes and the Process Table
39
On each clock tick, the CLOCK process executes the following operation:
SuspendOnExhaustedQuantum =
(CurrentProcessQuantumHasExpired ∧
ResetProcessTimeQuantum ∧
(SuspendCurrent o
9 SCHEDULENEXTn))
∨(UpdateCurrentProcessQuantum ∧
ContinueCurrent)
SetNewCurrentProcessQuantum =
(ProcessQuantum[tquant/timeq!] ∧
SetCurrentProcessQuantum[tquant/timequant?]) \ {tquant}
This expands into:
ΞPROCESSES
∆CURRENTPROCESSpq
pid? : PREF
(∃tquant : TIMEVAL •
tquant = pquants(pid?) ∧
tq′ = tquant)
It simpliﬁes to tq′ = pquants(pid?).
2.5 Processes and the Process Table
This section deals with a representation of processes and the process table.
Each process is represented by an entry in the process table; the entry is a
process descriptor. The process descriptor contains a large amount of infor-
mation about the state of the process it represents; the actual contents of the
process descriptor depend upon the kernel, its design and its purpose (e.g.,
a real-time kernel might contain more information about priorities and time
than one for an interactive system as well as the hardware).
The purpose of this section is not to deﬁne the canonical process descriptor
and process table for the kernels in this book (which, in any case, diﬀer among
themselves), nor to deﬁne the canonical structure for the process table (the one
here is somewhat diﬀerent from those that follow). Instead, it is intended as a
general deﬁnition of these structures and as a place where general properties
can be identiﬁed and proved.
As will become clear from the kernel models that follow, the process table
in this section diﬀers somewhat from the others in this book. In particular, the
process table here is modelled as a collection of mappings, while the others
are more obviously “tables”. The reasons for this diﬀerence are many. The
most important, for present purposes, are:

40
2 Standard and Generic Components
•
The current model is at a higher level than the others.
•
The current model separates the diﬀerent attributes of the process descrip-
tor into individual mappings.
Some kernels (e.g., some versions of Unix) use the representation used here.
The representation of this section has a slight advantage over the standard
table representation: for fast real time, it is possible to access components of
the process descriptor simultaneously—this might also be of utility in a kernel
running on a multi-processor system.
The section begins with a set of deﬁnitions required to support the deﬁni-
tion of the process descriptor and the process table.
In particular, there is a limit to the number of processes that can be
present in the system. There is one process descriptor for each process, so this
represents the size of the process table.
maxprocs : N1
A type for referring to processes must be deﬁned:
PREF == 0 . . maxprocs
The null and idle processes must be deﬁned:
IdleProcRef : PREF
NullProcRef : PREF
NullProcRef = 0
IdleProcRef = maxprocs
where NullProcRef is the “name” of no process and IdleProcRef is the “name”
of the idle process.
It is possible to deﬁne a set of “real” process names, that is process iden-
tiﬁers that represent actual processes. An “actual” process can be deﬁned as
a process associated with code that does something useful. The null process
has no code. The idle process consists of a empty inﬁnite loop.
Given this deﬁnition, the set, REALPROCS can be deﬁned as:
REALPROCS == PREF \ {NullProcRef , IdleProcRef }
That is, REALPROCS == 1 . . (maxprocs −1). Another, but less useful, set
of identiﬁers can also be deﬁned:
IREALPROCS == PREF \ {NullProcRef }
Writing out the deﬁnitions, this is IREALPROCS == 1 . . maxprocs. These
additional types will not be used in this speciﬁcation but might be of some
use in reﬁnement.
Hardware devices are assigned an identifying number:

2.5 Processes and the Process Table
41
DEVICEID == N
Each process has a state in addition to that denoted by the PSW.
PROCSTATUS ::= pstnew
|
pstrunning
|
pstready
|
pstwaiting
|
pstswappedout
|
pstzombie
|
pstterm
Processes come in three kinds:
PROCESSKIND ::= ptsysproc
|
ptuserproc
|
ptdevproc
These kinds are system, user and device processes.
The code and data areas of a process’ main-store image need to be repre-
sented:
[PCODE, PDATA]
For the time being, we can ignore PCODE and PDATA. Their elements are
structured in a way that will only be relevant during reﬁnement; similarly, the
PSTACK type also has elements whose structures can, for the most part, be
ignored. (The structure of elements of type PSTACK is only really of relevance
to interrupt service routines and the mechanisms that invoke them—typically
they push a subset of the current register set onto the stack.)
The process descriptor (sometimes called the process record) is deﬁned
by the following schema; together all process descriptors in the system form
the process table. It is the primary data structure for recording important
information about processes. The information includes a representation of
the process’ state, which is retained while the process is not executing. On
a context switch, the state (primarily, hardware registers, IP and stack) is
copied into the process descriptor for storage until the process is next ex-
ecuted. When next selected to run, the state is copied back into registers.
The process descriptor does hold other information about the process: data
about the storage areas it occupies, message queues, priority information and
a symbolic representation of its current state (in this book, an element of type
PROCSTATUS).
In this chapter, process descriptors are represented as sets of mappings
from process identiﬁers to the various attribute types. This representation
ﬁnds a natural representation as a collection of arrays. An alternative that
is commonly encountered in working systems, is to collect the information

42
2 Standard and Generic Components
about each process into a record or structure; all process descriptors are then
implemented as an array of these records. The record implementation has the
advantage that all relevant information about a process is held in one data
structure. The main disadvantage is that the record has to be accessed as an
entity. In the array-based implementation (the one adopted in this chapter,
i.e.), individual components are accessed separately. The advantage to the
separate-access approach is seen when locking is considered: when one com-
ponent array is being accessed under a lock, the others remain available to be
locked.
In this representation, the process table is implicitly deﬁned as the map-
ping from process reference (PREF) to attribute value:
PROCESSES
pstatus : PREF  →PROCSTATUS
pkinds : PREF  →PROCESSKIND
pprios : PREF  →PRIO
pregs : PREF  →GENREGSET
pstacks : PREF  →PSTACK
pstatwds : PREF  →STATUSWD
pcode : PREF  →PCODE
pdata : PREF  →PDATA
pips : PREF  →N
known procs : F PREF
NullProcRef ̸∈known procs
known procs = dom pstatus
dom pstatus = dom pkinds
dom pkinds = dom pprios
dom pprios = dom pregs
dom pregs = dom pstacks
dom pstacks = dom pstackwds
dom pstackwds = dom pcode
dom pcode = dom pdata
dom pdata = dom pips
known uids = ran pips
The conjunct, NullProcRef , is added to the predicate because it is required
that NullProcRef actually refer to the null process. It should never be the
case that the null process appears in the process table.
It is possible to exclude IdleProcRef from the process table in a manner
identical to NullProcRef . In the case of IdleProcRef , matters are less clear.
The idle process is a real process: it has code but probably no data or stack
areas. It is quite possible to have an idle process without representing it in
the process table. The idle process is only executed whenever the ready queue
is empty, so a small piece of code can do all the necessary work. To some,
this will appear an ad hoc solution; to others, it will appear totally natural.

2.5 Processes and the Process Table
43
At the moment, the idle process will be represented in the process table, even
though it requires an additional slot (this is, after all, a speciﬁcation, not an
implementation).
When reﬁnement is performed, the inclusion of IdleProcRef and the ex-
clusion of NullProcRef are of some importance. They determine the range of
possible values for the domains of the components of process descriptors. In
other words, their inclusion and exclusion determine what a “real process”
can be; this is reﬂected in the type to which PREF reﬁnes: REALPROCS
or IREALPROCS. (A hidden goal of the reﬁnement process is to represent
NullProcRef as, for example, a null pointer.)
Proposition 13. NullProcRef does not refer to a “real” process.
Deﬁnition 1 . A “real” process must be interpreted as one that has code and
other attributes (stack, data, status, instruction pointer and so on). Alterna-
tively, a “real” process is one that can be allocated either by the kernel or as
a user process.
More technically, a “real” process is one whose parameters are represented
in the process table and, hence, whose identiﬁer is an element of known procs.
Note that this deﬁnition is neutral with respect to the idle process. Some
systems might regard it as “real” and include an operation to create the idle
process. Other systems, MINIX [30] for example, regard the idle process as
a pseudo-process that is implemented as just a piece of kernel code that is
executed when there is nothing else to do; as in other systems built using
this assumption, the idle process is not represented by an entry in the process
table.
The above deﬁnition could be extended to include the idle process, of
course.
Proof.
The components of the process description, pstate, pkind, pstack,
pregs, etc., all have identical domains by the ﬁrst part of the invariant of
PROCESSES. That is:
dom pstatus = dom pkind ∧
dom pkinds = dom pprios ∧
dom pprios = dom pregs ∧
dom pregs = dom pstacks ∧
dom pstacks = dom pips ∧
dom pcode = dom pstacks ∧
dom pdata = dom pcode ∧
dom pips = dom pstatus
Furthermore, the domains are all identical to known procs since dom pstatus =
known procs. Since NullProcRef ̸∈known procs, it follows that NullProcRef ̸∈
dom pregs (for example). By Deﬁnition 1, the null process is not a “real” pro-
cess.
2

44
2 Standard and Generic Components
The process table is initialised by the following operation:
InitPROCESSES
PROCESSES ′
known procs′ = ∅
A process is removed from the process table by the operation modelled by
the following schema:
DelProcess
∆PROCESSES
pid? : PREF
pstatus′ = {pid?} −◁pstatus
pkinds′ = {pid?} −◁pkinds
pprios′ = {pid?} −◁pprios
pregs′ = {pid?} −◁pregs
pstacks′ = {pid?} −◁pstacks
pips′ = {pid?} −◁pips
or, more simply: pid? ̸∈known procs′.
Proposition 14. DelProcess[p/pid?] implies that p ̸∈known prcs′.
Proof. Since all domains are identical, take, for example, the case of pregs:
pregs′ = {p} −◁pregs
Taking domains and using the identity dom pregs = known procs:
dom pregs′
= known procs′
= dom({p} −◁pregs)
= dom(pregs \ {p})
Therefore, p ̸∈known procs′.
The same reasoning can be applied to all similar functions in PROCESSES. 2
A process is added to the process table by the AddProcess operation:
AddProcess
∆PROCESSES
pid? : PREF
knd? : PROCESSKIND
status? : PROCSTATUS
stat? : STATUSWD
regs? : GENREGSET

2.5 Processes and the Process Table
45
stk? : PSTACK
prio? : PRIO
ip? : N
pstatus′ = pstatus ∪{pid? →status?}
pkinds′ = pkinds ∪{pid? →knd?}
pprios′ = pprios ∪{pid? →prio?}
pregs′ = pregs ∪{pid? →regs?}
pstatwds′ = pstatwds ∪{pid? →stat?}
pips′ = pips ∪{pid? →ip?}
pstacks′ = pstacks ∪{pid? →stk?}
Proposition 15. (AddProcess[p/pid?, . . .] o
9 DelProcess[p/pid?]) is the iden-
tity on the process table.
Proof. This proposition states that the eﬀect of adding a process and im-
mediately deleting it leaves the process table invariant.
Since PROCESSES is rather large, only a part will be considered in detail.
The composition can be written as:
∃pstacks′′ : PREF  →PSTACK •
pstacks′′ = pstacks ∪{p? →stk} ∧
pstacks′ = {p?} −◁pstacks′′
which simpliﬁes to:
pstacks′ = {p?} −◁(pstacks ∪{p? →stk})
So:
dom({p?} −◁(pstacks ∪{p? →stk}))
= (dom pstacks ∪dom{p? →stk}) \ {p?}
= ((dom pstacks) ∪{p?}) \ {p?}
Therefore:
dom pstacks′ = dom(pstacks ∪{p?}) \ {p?}
= dom pstacks
2
The priority of a process is returned by the following operation:
ProcessPriority
ΞPROCESSES
pid? : PREF
prio! : PRIO
prio! = pprios(pid?)

46
2 Standard and Generic Components
The kind of process is returned by:
KindOfProcess
ΞPROCESSES
pid? : PREF
knd! : PROCESSKIND
knd! = pkinds(pid?)
A process’ current status is retrieved from the process table by the follow-
ing operation:
StatusOfProcess
PROCESSES
pid? : PREF
ps! : PROCSTATUS
ps! = pstatus(pid?)
InitialiseProcessStatus
∆PROCESSES
pid? : PREF
pstat? : PROCSTATUS
pstatus′ = pstatus ∪{pid? →pstat?}
Process status changes frequently during its execution. The following op-
eration alters the status:
UpdateProcessStatus
∆PROCESSES
pid? : PREF
pstat? : PROCSTATUS
pstatus′ = pstatus ⊕{pid? →pstat}
The following operations set the process status to designated values as and
when required:
SetProcessStatusToNew =
([pstat : PROCSTATUS | pstat = pstnew] ∧
UpdateProcessStatus[pstat/pstat?]) \ {pstat}
This operation is called when a process has been created but not added to
the ready queue.
When a process enters the ready queue, the following operation changes
its status to reﬂect the fact:

2.5 Processes and the Process Table
47
SetProcessStatusToReady =
([pstat : PROCSTATUS | pstat = pstready] ∧
UpdateProcessStatus[pstat/pstat?]) \ {pstat}
The SetProcessStatusToRunning operation should be called when a pro-
cess begins execution:
SetProcessStatusToRunning =
([pstat : PROCSTATUS | pstat = pstrunning] ∧
UpdateProcessStatus[pstat/pstat?]) \ {pstat}
When a process is suspended for whatever reason, the following operation
is called to set its status to pstwaiting:
SetProcessStatusToWaiting =
([pstat : PROCSTATUS | pstat = pstwaiting] ∧
UpdateProcessStatus[pstat/pstat?]) \ {pstat}
In the second kernel below (Chapter 4), processes can be swapped out to
disk space. The status of such a process is set by the following schema. As
with all of these schemata, the variable pstat represents the new state.
SetProcessStatusToZombie =
([pstat : PROCSTATUS | pstat = pstzombie] ∧
UpdateProcessStatus[pstat/pstat?]) \ {pstat}
This schema is used when a process terminates but has not yet released
its resources:
SetProcessStatusToTerminated =
([pstat : PROCSTATUS | pstat = pstterm] ∧
UpdateProcessStatus[pstat/pstat?]) \ {pstat}
For many purposes, it is necessary to know whether a given process ref-
erence denotes a process that is in the process table. The following schema
deﬁnes that test:
KnownProcess
ΞPROCESSES
pid? : PREF
pid? ∈known procs
It is not possible to allocate processes indeﬁnitely. The following operation
determines whether new processes can be allocated.
CanAllocateProcess
PROCESSES
known procs ⊂PREF

48
2 Standard and Generic Components
The identiﬁer of the next new process is generated by the following (rela-
tively abstract) schema.
NextPREF
PROCESSES
pid! : PREF
(∃p : PREF | p ∈(PREF \ known procs) •
p ̸= NullProcRef ∧p ̸= IdleProcRef ∧
pid! = p)
or:
pid! ∈{p : PREF • p ̸∈known procs}
The way names are allocated to new processes is as follows. There is a set
of all possible process references, PREF. If a process’ identiﬁer is not in
known procs, the set of known processes (i.e., the names of all processes
that are currently in the system—the domain of all attribute mappings), it
can be allocated. Allocation is, here, the addition of a process reference to
known procs.
If all processes have been allocated, the following schema’s predicate is
satisﬁed.
ProcessesFullyAllocated
PROCESSES
known procs = PREF \ {NullProcRef , IdleProcRef }
Note that neither IdleProcRef, nor NullProcRef represent real processes that
can be allocated and deallocated in the usual way. Indeed, IdleProcRef denotes
the idle process that runs whenever there is nothing else to do; it is already
deﬁned within the kernel. The constant NullProcRef denotes the null process
and is only used for initialisation or in cases of error.
The following is just a useful synonym:
CannotAllocateProcess = ProcessesFullyAllocated
Proposition 16. For any process, p, such that p ∈known procs:
DelProcess ⇒¬ ProcessesFullyAllocated ′
Proof.
By Proposition 14, the operation DelProcess applied to a process,
p, implies that p ̸∈known procs′.
Note, ﬁrst of all, that p cannot be one of NullProcRef or IdleProcRef.
The deﬁnition of CanAllocatePREF is known procs ⊂PREF, which im-
plies that there is some subset S : F PREF s.t., known procs ∪S = PREF;
(strictly speaking:

2.5 Processes and the Process Table
49
known procs ∪S = PREF \ {NullProcRef , IdleProcRef }
so CanAllocatePREF implies that if S ̸= ∅, then p ∈S will be the next
PREF to be allocated, so known procs ∪{p} ∪(S \ {p}) = PREF. If S = ∅,
clearly known procs = PREF. Therefore PREF \ S = known procs.
In the case of deletion, known procs′ = known procs \ {p?}, so:
known procs′
= known procs \ {p}
= (PREF \ S) ∪{p}
= PREF \ (S ∪{p})
For PREF = known procs, it is impossible that p ∈S. Therefore, it can be
concluded that the predicate of ¬ ProcessesFullyAllocated′ does not hold.
2
It might be useful to know whether there are any processes in the system.
The following schema provides that ability:
NoProcessesInSystem
ΞPROCESSES
known procs = ∅
Proposition 17. AddProcess ⇒pid ∈known procs′.
Proof. For AddProcess, consider the case pstacks′ = pstacks ∪{p? →stk}.
Since dom pstacks = known procs and dom pstacks′ = known procs′, it fol-
lows that: dom pstacks = known procs and:
dom pstacs = dom(pstacks ∪{p? →stk})
= (dom pstacks) ∪(dom{p? →stk})
= dom pstacks ∪{p?}
= known procs′
2
Proposition 18.
¬ NoProcessesInSystem ∧(NextPREF ∧AddProcess)n ∧0 < n ≤maxprocs ⇒
¬ ProcessesFullyAllocated
Proof. The proposition statement expands to:
known procs = ∅∧
(NextPref ∧AddProcess)n ∧
0 < n ≤maxprocs

50
2 Standard and Generic Components
It has already been established (Proposition 17) that
AddProcess[p/pid?, . . .] ⇒p ∈known procs′
(2.1)
so:
(NextPref [p/pid!] ∧AddProcess[p/pid?]) ⇒p ∈known procs
Writing the available identiﬁers as:
A = (PREF \ {NullProcRef , IdleProcRef }) \ known procs
We write A for the set of available identiﬁers before NextPREF ∧AddProcess and
A′ for that afterwards. Then #A is the cardinality of A, and so #A′ = #A−1. This
is justiﬁed by:
A′
= (PREF \ {NullProcRef , IdleProcRef }) \ known procs′
= (PREF \ {NullProcRef , IdleProcRef }) \ (known procs ∪{p})
where p is the newly allocated identiﬁer.
Consequently, for (NextPREF[pm] ∧AddProcess[pm/pid?, . . .])m and for some
m, 0 < m < maxprocs −1
A′
= (PREF \ {NullProcRef , IdleProcRef }) \ known procs′
= (PREF \ {NullProcRef , IdleProcRef }) \ (known procs ∪{p1, . . . , pm−1})
Therefore, for m = maxprocs,
A′
= (PREF \ {NullProcRef , IdleProcRef }) \ known procs′
= (PREF \ {NullProcRef , IdleProcRef }) \ known procs ∪{p1, . . . , pm}
Since the interval 1 . . maxprocs contains exactly m elements:
(PREF \ {NullProcRef , IdleProcRef }) \ known procs′ = ∅
2
It should be noted that if the idle process is not regarded as a “real” process,
the statement of the proposition should be restricted to ∧0 < n < maxprocs.
Proposition 19. The operations AddProcess and DelProcess are inverse op-
erations. That is, for any p, AddProcess[p/pid?] o
9 DelProcess[p/pid?] implies
that #known procs = #known procs′.
Proof. This follows immediately by induction from Proposition 15.
2

2.6 Context Switch
51
2.6 Context Switch
Context switches occur when a process is swapped on or oﬀthe processor.
This section outlines a scheme for modelling context switching.
Basically, a context switch involves the transfer of hardware and other state
information from or to the process descriptor. Of the registers, the most impor-
tant is the instruction pointer. Context switches are expensive because they
copy the contents of all hardware registers into the current process descrip-
tor. They occur when the scheduler determines that another process should
be allocated to the processor. They are also required for the speciﬁcation of
semaphores.
There are two main operations involved in context switching: one to copy
state data from the process descriptor to the hardware and one to copy data
in the opposite direction. The schemata deﬁned in this section are included as
an illustration. They will be redeﬁned with slight variations when required.
The SaveAllHWRegisters operation copies the contents of the registers
used by a process into its process descriptor. The operation is complemented
by RestoreAllHWRegisters, which reads the process descriptor and copies
items from it to the hardware’s general-purpose registers. In the represen-
tation below, the instruction pointer is the last register to be set from the
process descriptor.
SaveAllHWRegisters
∆PROCESSES
HWREGISTERS
pid? : PREF
(∀r : GENREG •
pregs′(pid?)(r) = hwregset(r))
pstacks′(pid?) = hwstack
pstatwds′(pid?) = hwstatwd
pips′(pid?) = hwip
SwitchContextOut = SaveAllHWRegisters
RestoreAllHWRegisters
PROCESSES
HWREGISTERS ′
pid? : PREF
hwstack ′ = pstacks(pid?)
hwstatwd ′ = pstatwds(pid?)
hwip′ = pips(pid?)
(∀r : GENREG •
hwregset′(r) = pregs(pid?)(r))

52
2 Standard and Generic Components
SwitchContextIn = RestoreAllHWRegisters
Sometimes, for example when an interrupt occurs, a partial context switch
can occur. Partial context switches only save part of the data normally
switched by a context switch. Although the detailed workings of the hard-
ware interrupt subsystem are mostly ignored in this book, it is interesting,
just as an orienting exercise, to include the following schemata.
A partial context switch is described by the following two schemata:
SaveHWGeneralRegisters
∆PROCESSES
HWREGISTERS
pid? : PREF
(∀r : GENREG •
pregs′(pid?)(r) = hwregset(r))
SavePartialContext = SaveHWGeneralRegisters
RestoreHWGeneralRegisters
∆PROCESSES
ΞHWREGISTERS
pid? : PREF
∀r : GENREG •
hwregset(r) = pregs′(pid?)(r)
RestorePartialContext = RestoreHWGeneralRegisters
2.7 Current Process and Ready Queue
This section presents a simple model of the operation of the kernel’s scheduler.
It uses a simple FIFO queue to hold the processes that are ready to execute;
this is readyq. The identiﬁer of the process currently executing is stored in
currentp.
CURRENTPROCESS
currentp : PREF
readyq : ProcQueue
Here, ProcQueue can either be regarded as an instantiation of the generic
QUEUE type or of a new type.

2.7 Current Process and Ready Queue
53
MakeCurrent
∆CURRENTPROCESS
pid? : PREF
currentp′ = pid?
Because this is Z, a framing schema is used to promote operations on the
process queue:
ΦCURRENTPROCESSq
∆CURRENTPROCESS
∆ProcQUEUE
readyq = θProcQUEUE
readyq′ = θProcQUEUE ′
ΨCURRENTPROCESSq
CURRENTPROCESS ′
ProcQUEUE ′
readyq′ = θProcQUEUE ′
The scheduler is initialised by the following operation:
InitCURRENTPROCESS =
ΨCURRENTPROCESSq ∧
InitProcQueue ∧
[CURRENTPROCESS ′ | currentp′ = NullProcRef ]
A process is added to readyq, the queue of processes ready to execute, by
the MakeReady operation. It is deﬁned as:
MakeReady =
ΦCURRENTPROCESSq ∧
EnqueueProc[readyq/procs, readyq′/procs′]
It is often necessary for a process whose execution was interrupted or
blocked by some operation, immediately to be resumed. The following does
this:
ContinueCurrent
ΞCURRENTPROCESS
currentp′ = currentp
readyq′ = readyq
We can now prove some propositions about the scheduler.

54
2 Standard and Generic Components
Proposition 20. p = currentp ∧RunNext ⇒currentp′ ̸= p.
The currently executing process can suspend itself by a call to the following
operation:
SuspendCurrent =
SwitchContextOut[currentp/pid?]o
9
(ΦCURRENTPROCESSq ∧
EnqueueProc[currentp/p?])
DequeueProc =
(¬ EmptyProcQueue[PREF] ∧RemoveFirst[PREF] ∧ProcQOk)
∨EmptyProcQueue[PREF]
There is no need for a dequeue operation that raises an error: should the
process queue ever become empty, the idle process will be executed. Therefore,
the following will be adequate for current needs:
DequeueProc =
(EmptyQueue[PREF] ∧MakeNextIdle)
∨RemoveFirst[PREF]
where:
MakeNextIdle = [x! : PREF | x! = IdleProcRef ]
The core of this little scheduler is the SCHEDULENEXT operation. It is
deﬁned as:
SCHEDULENEXT =
((ΦCURRENTPROCESSq ∧
DequeueProc[p/x!] ∧
SetProcessStatusToRunning[p/pid?] ∧
MakeCurrent[p/pid?])o
9
SwitchContextIn[p/pid?]) \ {p}

4
A Swapping Kernel
4.1 Introduction
The last chapter presented the model of a simple kernel. The kernel is similar
to those found in embedded and small real-time systems such as µC/OS [18].
The model of the last chapter serves as an existence proof : the formal mod-
elling of an operating system can be performed. The purpose of this chapter
is to expand upon this by presenting a model of the kernel with much more
functionality. It is a kernel of about the same complexity as minicomputer
(and some mainframe) operating systems of the 1970s and 1980s, and a large
proportion of its functionality can be found in present-day kernels.
Since the requirements for this kernel are listed in Section 4.2, they will
not be repeated here. Instead, it will be noted that the kernel was greatly
inﬂuenced by the Linux [4] and, particularly, Minix [30] kernels. Some might
object that this kernel is really too simple and that it is a poor example. To
this, it must be replied that the model presented below is a high-level de-
scription of the functions and interactions of the kernel, a kernel that does
not contain ﬁle systems or browsers as integral components1. The lack of com-
plexity is merely superﬁcial, as the kernel contains models of all the operations
required of it in Section 4.2.
4.2 Requirements
The kernel speciﬁed in this chapter should have a layered design. In order,
the layers should be:
1. the hardware;
2. Interrupt Service Routines;
3. the process abstraction;
1 As far as the author is concerned, feature creep leading to kernel bloat!

88
4 A Swapping Kernel
4. Inter-Process Communications;
5. system processes;
6. a scheduler to be based on a priority scheme. Instead of arranging matters
as in the previous kernel, three broad bands are to be used: one each for
device processes, one for system processes and one for user processes.
User processes have the lowest priority; device processes have the highest.
Within each priority band, a round-robin scheme should be used.
The system processes should include, at a minimum, the following:
•
a clock to support alarms of various kinds;
•
a storage-management mechanism. Each process should be composed of
a contiguous segment of main store that is allocated when the process is
created.
In addition, a swapping mechanism for storing active processes in a re-
served disk space is to be used. When a process has been swapped out for
a suﬃciently long time, it should be returned to main store so that it can
continue execution. If there is insuﬃcient store free when a process is created,
it should be allocated on disk, later to be swapped into main store. These
mechanisms apply only to user-level processes.
The organisation of the kernel is shown in Figure 4.1. This ﬁgure, which
ﬁrst appeared as Figure 1.1, shows the organisation of the kernel in terms of
layers: hardware appears at the bottom and the user’s programs at the top.
The model displays all the characteristics of the classical operating system
kernel, hence the duplication of the ﬁgure2.
4.3 Common Structures
In this section, some structures common to many of the models in this book are
deﬁned. With the exception of the hardware model that immediately follows
(Section 4.3.1), the deﬁnitions are in Z rather than Object-Z. This is because
many readers will be more familiar with Z, so this chapter serves as a gentle
introduction to the remainder of this book. The use of Z in some cases leads to
framing and promotion. It was decided to include these so that the reader can
gain some idea of what a full speciﬁcation in Z might look like (and, thereby,
see why Object-Z was eventually preferred).
4.3.1 Hardware
Operating system kernels operate the system’s hardware. This subsection con-
tains a number of deﬁnitions that will be used when deﬁning the rest of the
kernel. The speciﬁcations of this subsection are loose for the reason that it
2 This is certainly not to claim that this kernel is the paradigm upon which all
should follow.

4.3 Common Structures
89
IPC
Process Abstraction
i/o r/gs
System
Calls
User
Processes
alarms
Context
Switch
Device
Software
Hardware
Device
H/W 
Clock
Device
Process
Table
Device
Processes
(drivers)
Swap
Tables
Swap
Disk
Kernel Interface Routines
Swapper
Process
Clock
Process
Low-Level
Scheduler
ISRs
Kernel
Primitive
System
Processes
ISR
ISR
ISR
Clock
Fig. 4.1. The layer-by-layer organisation of the kernel.
is not possible, a priori, to determine anything other than the most general
properties of the actual hardware upon which a kernel runs. If the kernel spec-
iﬁed in this chapter were reﬁned to code, the hardware-related parts would, at
some stage, need to be made more precise. Without target hardware in mind,
this cannot be done. On the other hand, the looseness of the speciﬁcation
of this subsection shows how little one need assume about the hardware in
order to construct a working kernel; this is good news for portability and for
abstraction.
The speciﬁcations begin with a type that represents time. Time is im-
portant to the hardware and, although this chapter is not about a real-time
kernel, the current time is important to a number of kernel components: for

90
4 A Swapping Kernel
example, the swapper process and the scheduler. The scheduler uses time
slicing to implement pre-emption on user processes.
TIME == N
Time is deﬁned as an inﬁnite, discrete type of atomic elements. The elements
(in one-one correspondence with the naturals) can be events or arbitrary ticks
of the hardware. For the purposes of this speciﬁcation, the actual denotation
of elements of this type is left unspeciﬁed.
Next, there is the runtime stack. Each process maintains a stack and there
is a slot in the process descriptor of each process for a stack. The type is
deﬁned as:
[PSTACK]
For the time being, there is no need to ask what constitutes a stack. It is,
therefore, left as an atomic type. (A reﬁnement of this speciﬁcation would
add structure to this type; for example, a pointer to the start of the storage
area reserved for the stack, the size of the reserved area and a pointer to
the top of the stack.) In order to initialise various data structures, as well as
the (model of the) hardware registers, a null value is needed for stacks. It is
deﬁned as:
NullStack : PSTACK
It is assumed that the kernel will run on hardware with one or more reg-
isters. The actual number of registers is deﬁned by the following constant:
maxgreg : N
There are no assumptions made about the value of maxgreg. For the purposes
of the next deﬁnition, it can be said that maxgreg should be assigned to a
value that is one less than the actual number of registers:
GENREG == 0 . . maxgreg
This is the type deﬁning the indices used to refer to the actual hardware
registers that appear in the register set. The register set is deﬁned as the
following Object-Z class:
GENREGSET
↾(regs)
regs : GENREG →PSU
INIT
∀i : GENREG •
regs′(i) = 0

4.3 Common Structures
91
The general registers are modelled as a function from the index set to the
value in each register. Another way to view this deﬁnition is as an array—
this is what is really wanted. This speciﬁcation does not include operations
to access and update individual registers. At present, there is no need for
individual register access in the more general kernel speciﬁcation, so they are
not included (they are simple enough to deﬁne, in any case).
The general registers that are accessible to programmers come next. This
is what is usually known as the processor’s register set. The registers include
the general registers, the stack register, the program counter and the status
register; a ﬂag controlling interrupts is also included.
HardwareRegisters
↾(SetGPRegs, GetGPRegs, GetStackReg, SetStackReg,
SetIntsOﬀ, SetIntsOn, GetIP, SetIP,
GetStatWd, SetStatWd)
hwgenregs : GENREGSET
hwstack : PSTACK
hwstatwd : STATUSWD
hwip : N
INIT
hwgenregs.INIT
hwstack ′ = 0
hwstatwd ′ = 0S
hwip′ = 0
SetGPRegs = . . .
GetGPRegs = . . .
GetStackReg = . . .
SetStackReg = . . .
GetIP = . . .
SetIP = . . .
GetStatWd = . . .
SetIntsOﬀ= . . .
SetIntsOn
Operations to read and set each register are deﬁned now.
SetGPRegs
∆(hwgenregs)
regs? : GENREGSET
hwgenregs′ = regs?

92
4 A Swapping Kernel
GetGPRegs
regs! : GENREGSET
regs! = hwgenregs
GetStackReg
stk! : PSTACK
stk = hwstack
SetStackReg
stk? : PSTACK
hwstack ′ = stk?
The program counter or instruction pointer can be read and set. The
operations now follow.
GetIP
ip! : N
ip! = hwip
SetIP
ip? : N
hwip′ = ip?
There is usually a status register provided by the processor. This register
contains a collection of ﬂags representing conditions such as result non-zero,
result zero and so on. The operation to read the contents of this register is
deﬁned by the next schema:
GetStatWd
stwd! : STATUSWD
hwstatwd ′ = stwd?
The initialisation operation uses the constant value 0S as a means to ensure
that it is well-typed. The status register is always initialised by the hardware,
not the software.
Interrupts play a large part in the current kernel. They are used as the
basic mechanism for mutual exclusion. At the bottom of the kernel, they are
used for this purpose, as well as in the deﬁnition of semaphores. There are two

4.3 Common Structures
93
operations: one to switch oﬀand one to switch on the interrupt notiﬁcation
mechanism. It is assumed that all interrupts can be disabled by the following
schema:
SetIntsOﬀ
intﬂg′ = intoﬀ
Interrupts can be enabled by the following operation:
SetIntsOn
intﬂg′ = inton
Below, these operations will be aliased and referred to as the “locking” oper-
ations.
The following is left undeﬁned. It is only included for reasons of complete-
ness. The swapping procedure can involve the relocation of code and data;
without relocation registers, it would not be possible to access and update
data or to access code properly. The details of the relocation mechanism are
of no interest to us in this speciﬁcation.
UpdateRelocationRegisters
· · ·
4.3.2 Queues
Queues are ubiquitous. In this speciﬁcation, a distinction is made between
general queues (of messages, requests and so on) and queues of process refer-
ences. The former type is modelled using the generic QUEUE[X] type, while
the other is modelled using the ProcessQueue type.
Type QUEUE[X] is the generic type encountered in Chapter 2. It is exactly
the same as the queue used to deﬁne semaphores there.
QUEUE [X ]
↾(INIT, IsEmpty, Enqueue, RemoveNext, QueueFront, RemoveElement)
elts : seq X
INIT
elts′ = ⟨⟩
IsEmpty = . . .
Enqueue = . . .
RemoveNext = . . .
QueueFront = . . .
RemoveElement = . . .

94
4 A Swapping Kernel
Enqueue
∆(elts)
x? : X
elts′ = elts ⌢⟨x?⟩
IsEmpty
elts = ⟨⟩
RemoveNext
∆(elts)x! : X
elts = ⟨x!⟩⌢elts′
QueueFront
x! : X
x! = head elts
RemoveElement
∆(elts)
x? : X
(∃s1, s2 : seq X •
elts = s1 ⌢⟨x?⟩⌢s2
∧elts′ = s1 ⌢s2)
4.3.3 Process Queue
The ProcessQueue type is used to model queues of processes. This type diﬀers
from the QUEUE[X] type in one critical respect: it is deﬁned in terms of an
injective sequence and not a simple sequence. Semantically, the distinction is
that the range of an injective sequence can contain no duplicates (an injective
sequence is an injective mapping from a subset of the naturals to the range
set).
The reason for adopting an injective sequence is that if a process occurs
in a queue, it can only occur once. It would have been tiresome to prove this
invariant each time an enqueue operation was performed.
The actual details of the type deﬁnition are given immediately below. The
class has the same operations as that of QUEUE[X]; in fact, it deﬁnes an extra
one, which will be discussed after all the operations have been deﬁned. The

4.3 Common Structures
95
only signiﬁcant diﬀerence between the two (apart from the fact that one is
generic and the other is not) is that the underlying sequence type is diﬀerent.
ProcessQueue
↾(INIT, IsEmpty, Enqueue, RemoveNext, QueueFront, Catenate, RemoveFirst)
⊗
: ProcessQueue × ProcessQueue →ProcessQueue
∀q1, q2 : ProcessQueue •
q1 ⊗q2 = q1.elts ⌢q2.elts
elts : iseq X
INIT
elts′ = ⟨⟩
IsEmpty = . . .
Enqueue = . . .
RemoveNext = . . .
QueueFront = . . .
RemoveFirst = . . .
Catenate = . . .
As can be seen from the class deﬁnition, the methods are the same as for
QUEUE[X]. The operations that follow are also the same. The properties of
this type are the same as those proved in Chapter 2 for the general queue
type; they are not repeated here.
It should be noted that the operation, ⊗, deﬁned at the start of this
class, cannot be exported. In order for the operation to be performed as an
exportable operation, it has to be implemented as an operation, here with the
rather unpleasant name Catenate. This restriction must be imposed because
the ⊗operation acts upon the internal representation of the queue, which is
assumed hidden by the class construct.
Enqueue
∆(elts)
x? : X
elts′ = elts ⌢⟨x?⟩
IsEmpty
elts = ⟨⟩

96
4 A Swapping Kernel
RemoveNext
∆(elts)x! : X
elts = ⟨x!⟩⌢elts′
QueueFront
x! : X
x! = head elts
RemoveFirst
∆(elts)
elts′ = tail elts
RemoveElement
∆(elts)
x? : X
(∃s1, s2 : iseq X •
elts = s1 ⌢⟨x?⟩⌢s2
∧elts′ = s1 ⌢s2)
The extra operation added to ProcessQueue is the Catenate (concatenate)
operation. It is deﬁned in terms of the operation ⊗deﬁned at the start of the
ProcessQueue class. It is deﬁned in order to export ⊗.
Catenate
q1?, q2? : ProcessQueue
q! : ProcessQueue
q! = q1? ⊗q2?
The operation concatenates two instances of ProcessQueue to produce another
instance.
Because ProcessQueue is based on injective sequences, the following prop-
erty is immediate (the proof is omitted):
Proposition 32. The formulæ:
∀q1, q2 : ProcessQueue • q1 ⊗q2
or:
∀q1, q2 : ProcessQueue • Catenate[q1/q1?, q2/q2?]
yield a queue with no duplicate elements.
In addition to this property, ⊗(and, hence, Catenate) has the same prop-
erties as ⌢, the concatenation operation for ﬁnite sequences.

4.3 Common Structures
97
4.3.4 Synchronisation and IPC
In this subsection, the synchronisation and Inter-Process Communication
primitives employed by this kernel are speciﬁed.
The primary synchronisation primitive is the lock. There are two opera-
tions: Lock and Unlock. The requirement is that the operations between a
Lock and the corresponding Unlock cannot be interrupted; in any case, they
are executed by a single thread of control. The critical issue is that execu-
tion of the locked code cannot be interrupted. Locks will be used in deﬁning
semaphores below.
Locks are deﬁned in terms of interrupts. This is a standard technique for
implementing critical regions in OS kernels. It is quick to apply and easy to
implement. The only problem is that the programmer has to remember to
unlock a lock. (This can be solved by the judicious deﬁnition of a macro.)
Locks must be used to implement other, higher-level synchronisation and IPC
primitives if the hardware does not support a mutual-exclusion instruction
like test-and-set; even when the hardware does support such an instruction,
locks are often more appropriate for the reasons just given.
Lock
↾(Init, Lock, Unlock)
hw : HardwareRegisters
Assume that registers have been initialised.
INIT
hwrgs? : HardwareRegisters
hw ′ = hw?
Lock = hw.SetIntsOﬀ
Unlock = hw.SetIntsOn
Because this is an object-oriented speciﬁcation, an instance of the hard-
ware has to be passed to the Lock class. This is the purpose of the INIT oper-
ation. The other two operations perform locking and unlocking. The locking
operation disables interrupts, while the unlocking one enables them again.
Clearly, when interrupts are disabled, the thread of control executing the lock
operation has sole access to the hardware and to the contents of the store;
it cannot be interrupted. This permits the safe manipulation of shared data
structures without the use of higher-level operations such as semaphore oper-
ations.
The reader should be aware that the locking method suﬀers from the
problem that any process manipulation must be done by hand. Semaphores
and messages are implemented in such a way that processes are automatically

98
4 A Swapping Kernel
handled in the correct ways. Locks are deﬁned at a lower level in the kernel
(at a level below that at which the process abstraction has been deﬁned).
Next, we come to the semaphores. The semaphore abstraction is deﬁned
in exactly the same way as in Chapter 2. As was noted there, the semaphore
deﬁned in this book can be used as a binary as well as a counting semaphore.
The class is as follows.
Semaphore
↾(Init, Wait, Signal)
waiters : ProcessQueue⃝
C
scnt, initval : Z
ptab : ProcessTable
sched : LowLevelScheduler
ctxt : Context
lck : Lock
INIT
iv? : Z
pt? : ProcessTable
sch? : LowLevelScheduler
ct? : Context
lk? : Lock
initval ′ = iv? ∧scnt′ = iv? ∧ptab′ = pt?
sched ′ = sch? ∧ctxt′ = ct? ∧lck ′ = lk?
waiters.Init
NegativeSemaCount = scnt < 0
NonPositiveSemaCount = scnt ≤0
IncSemaCount = scnt′ = scnt + 1
DecSemaCount = scnt′ = scnt −1
Wait = . . .
Signal = . . .
The Wait (or P) operation is deﬁned ﬁrst (some results will be proved
before Signal is deﬁned):
Wait =
lck.Lock o
9
(DecSemaCnt o
9
(NegativeSemaCount ∧ctxt.SaveState
∧waiters.Enqueue[currentp/x?] ∧

4.3 Common Structures
99
(∃cpd : ProcessDescr •
ptab.DescrOfProcess[currentp/pid?, cpd/pd!] ∧
cpd.SetProcessStatusToWaiting) ∧
sched.MakeUnready[currentp/pid?] ∧sched.ScheduleNext)
∨sched.ContinueCurrent)o
9
lck.Unlock
(This is exactly the same as in Chapter 2 but is now written in Object-Z.)
Assuming a fair scheduling mechanism (e.g., round-robin) and the fairness
of the queue abstraction, the major properties of the semaphore can be proved.
The properties of Wait and Signal are almost symmetrical but the diﬀerences
between them mean that properties of Wait cannot be used in the reverse
direction to prove properties of Signal.
Lemma 1. scnt < 0 ⇒elts′ = elts ⌢⟨caller?⟩.
Proof. Writing out the deﬁnition of Wait:
scnt′ = scnt −1 ∧
(scnt′ < 0 ∧
waiters.Enqueue[caller?/x?] ∧. . .
This expands into:
scnt′ = scnt −1 ∧
scnt′ < 0 ∧
elts′ = elts ⌢⟨caller?⟩∧. . .
Clearly, the caller’s process is enqueued on the semaphore’s queue of waiting
processes.
2
Lemma 2. scnt < 0 ⇒currentp ̸= currentp′.
Proof. The proof of this reduces to the proof that ScheduleNext o
9 RunNext
implies currentp ̸= currentp′.
2
Lemma 3. scnt ≥0 ⇒currentp = currentp′.
Proof. scnt′ ≥0 implies that the caller is resumed.
2
Lemma 4. scnt ≥0 ⇒elts′ = elts
Proof. scnt ≥0 implies ¬ NegativeSemaCount (i.e., scnt ≥0 ⇒¬ (scnt <
0), so currentp = currentp′. Furthermore, waiters.elts = waiters.elts′.
2

100
4 A Swapping Kernel
Lemma 5. | scnt | −initval = #elts
Proof.
A semaphore can be initialised with an arbitrary integral value
denoting the number of processes that can be simultaneously in the critical
section. If this number is k, if there are more than k calls on Wait, say l calls,
then l −k of those calls will be blocked.
For the time being, and without loss of generality, let k = 1. By the
deﬁnition of the semaphore type, scnt′ = k upon initialisation. (This is a
binary semaphore.) Let this be denoted by scntI .
If m processes simultaneously wait on the same semaphore before the orig-
inal process has performed a Signal operation and leave the critical section, by
deﬁnition of Wait, for each process, scnt will be decremented by 1. The value
of scnt will therefore be decremented by m. Therefore, Waitm ⇒scnt′ =
scntI −(m + 1). Meanwhile, let eltsI = ⟨⟩(the initialisation value of elts). It
is clear that Wait ⊢scnt′ = scnt −1, so Wait ⊢scnt = 0. The enqueue op-
eration is performed only when scnt < 0, and Waitm ⊢#elts′ = #eltsI + m,
while scnt = scntI + m = 1 + m, so #elts = | m | + 1 −1 = m = #elts.
2
The last proof was written in terms of the initialisation values scntI and
eltsI . These are values that the semaphore attains whenever there are no pro-
cesses in its waiting queues and no processes in its critical section—a quiesence
or inactive semaphore; it is also the state of a semaphore immediately prior
to use.
Lemma 6. Wait implies:
Wait ⊢∀p : APREF | p ∈ran elts •
∃pd : ProcessDescr; s : PROCSTATUS •
ptab.DescrOfProcess[p/pid?, pd/pd!]
∧pd.ProcessStatus[s/stat!]
∧s = pstwaiting
if scnt′ < 0.
Proof. The inner existential simpliﬁes to:
ptab.procs(p).status = pstwaiting
By the deﬁnition of Wait, if scnt′ < 0, Enqueue is applied. By the deﬁnition
of Enqueue, elts′ = elts ⌢⟨p⟩, so last elts′ = ⟨p⟩. SetProcessStatus sets p’s
status to pstwaiting.
However, the only way in which processes can enter waiters.elts is via a
call to Enqueue, so every process in waiters.elts is in the pstwaiting state. 2
Lemma 7. If scnt ≤0, then there are scnt elements in the semaphore’s wait-
ing queue. The status of each such element is pstwaiting.

4.3 Common Structures
101
Proof. By a previous Lemma (Lemma 5), | scnt| = #elts. By Lemma 6 and
induction, the result is immediate.
2
The Signal (or V ) operation is deﬁned as:
Signal =
lck.Lock o
9
(IncSemaCnt o
9
(NonPositiveSemaCount ∧
waiters.RemoveFirst[cand/x!] ∧
(∃cpd : ProcessDescr •
ptab.DescrOfProcess[cand/pid?, cpd/pd!] ∧
cpd.SetProcessStatusToReady) ∧
sched.MakeReady[cand/pid?]) \ {cand}
∨sched.ContinueCurrent)o
9
lck.Unlock
Lemma 8. scnt ≤0 ⇒elts = ⟨p⟩⌢elts′
Proof. By the predicate of Signal:
waiters.RemoveFirst[cand/x!]
= waiters.elts = ⟨cand⟩⌢waiters.elts′
That is, elts = ⟨cand⟩⌢elts′.
2
Lemma 9. scnt ≤0 ⇒#elts′ < #elts
Proof. Again, if scnt < 0, waiters.elts = ⟨cand⟩⌢waiters.elts′. Rewriting
(omitting class names), elts = ⟨cand⟩⌢elts′ is obtained. Taking sizes on both
sides yields:
#elts = #(⟨cand⟩⌢elts′)
= #⟨cand⟩+ #elts′
= 1 + #elts′
2
Lemma 10. scnt ≤0 ⇒MakeReady.
Proof. By the predicate, scnt ≤0 implies MakeReady.
2
Lemma 11. scnt ≤0 ⇒currentp′ ̸= currentp

102
4 A Swapping Kernel
Proof. In this case, MakeReady is the only operation related to scheduling.
The eﬀects of MakeReady do not include updating currentp, because nothing
else in the predicate of Signal aﬀects the scheduler’s data variables.
2
Lemma 12. scnt > 0 ⇒currentp′ = currentp.
Proof. scnt ≤0 is true when NonPositiveSemaCount is not true. From this,
it can be inferred that sched.ContinueCurrent ⊢currentp = currentp′.
2
Proposition 33. Waitn o
9 Signalm ⊢elts = ⟨⟩iﬀn = m.
Proof.
Assume that scnt was initialised to 1. Assume that exactly one
process is already in the critical section.
By Lemma 5, the next n callers to Wait extend elts by n elements. Con-
versely, by another lemma (Lemma 9), a call on Signal removes one ele-
ment from elts, so n calls remove n elements. It is the case that Dequeuem o
9
Enqueuen ⊢elts′ = ⟨⟩iﬀn = m (by Corollary 3). The process tha initially
entered the critical region (calling Wait, therefore) must eventually exit it (as-
suming that meanwhile the process does not terminate abnormally). There-
fore, while one process is inside the critical section, and there are n processes
waiting to enter it, there must be m calls to Signal to restore the semaphore
to its initial state; alternatively, for all processes to exit the critical section. 2
Corollary 4. If a semaphore is initialised to k and elts = ⟨⟩,
Waitn+k o
9 Signal m+k ⊢elts′ = ⟨⟩iﬀn = m
Proof. Immediate from previous results.
2
Corollary 5. Wait o
9 Signal pairs are fair in the sense that any process per-
forming a Wait operation will eventually enter the critical section and, by
performing a Signal, will exit it also. When all Waits are matched by corre-
sponding Signals, it is the case that #elts = #elts′.
Proof. For this proof, it is important to observe that the semaphore’s oper-
ations are deﬁned in terms of sequential compositions. The intermediate state
of elts is denoted elts′′, and the before and after states are written using the
normal Z convention.
For #elts′′ = #elts +1, scnt < 0, so a process is in the critical section and
the callers must have been enqueued.
Conversely, for #elts′′ = #elts′ + 1, scnt ≤0, so a process must already
have been made ready and, therefore, removed from elts′′.

4.4 Process Management
103
If scnt = −k when a process is enqueued by Wait, there must be exactly
k calls to Signal before the process can next be made ready.
2
These results establish the correctness of the semaphore speciﬁcation.
By the assumption that the underlying scheduler is fair, the fairness of the
semaphore is also established.
In fact, the scheduler used by this kernel is slightly more complex than a
simple round-robin one. It is organised as a priority queue with three priorities,
the lowest of which employs timesliced pre-emption. The lower two priorities
use what amounts to a round-robin scheme (they contain system processes
that either run to completion or suspend in a natural fashion—when they are
readied, they are enqueued in FIFO fashion). This structure complicates the
proof of fairness; because it is a fair scheme, by assumption the results above
remain valid.
4.4 Process Management
This section contains the speciﬁcation of those kernel components that imple-
ment the process abstraction.
It is ﬁrst necessary to have some way of designating or referring to pro-
cesses. With this deﬁned, it will be possible to refer to individual processes
without having to introduce references to all of the apparatus that implements
the process abstraction. To do this, three types and two constants are deﬁned.
The ﬁrst type is:
[PREF]
This is the basic Process Reference type. There are two constants of this type:
NullProcRef , IdleProcRef : PREF
The constant NullProcRef denotes the null process. Normally, the null process
should never appear in any data structure; when it does, a signiﬁcant error has
occurred and the system should halt. For the reason that this model is typed,
it is possible to prove that the null process has this property. This fact reduces
the occurrence of the null process to an error in reﬁnement and/or transcrip-
tion or to some unforeseen event that should cause immediate termination of
the kernel.
The second constant, IdleProcRef, denotes the idle process. This is the
process that should be run when there is nothing else to do; it merely exe-
cutes an inﬁnite loop containing no instructions, absorbing cpu cycles until
an external interrupt occurs or a new process is created and made ready for
execution. It might be encoded in a programming language as:
while true do skip od;

104
4 A Swapping Kernel
If the scheduler’s queue (queues in the present case) ever become empty (i.e.,
there are no processes ready to execute), the idle process is executed. This
process is a way of ensuring that the scheduler always has something to do.
With these constants and PREF deﬁned, it is possible to deﬁne two more
types:
IPREF == PREF \ {NullProcRef }
APREF == IPREF \ {IdleProcRef }
The type IPREF is the type of all process references except the null process
reference (NullProcRef ). It is a type used by the scheduler. (It is also a useful
type to have when reﬁning the process management and scheduler speciﬁ-
cations.) The type APREF is the type of actual processes. Type APREF
contains the identiﬁers of all those processes that actually exist. (The idle
process is, in some systems, a virtual process in the sense that it is imple-
mented as a piece of kernel code.) In any case, the idle process cannot appear
in semaphore or device queues; it can only appear in the scheduler and in
a few other special places, as will be seen. The APREF type is used, then,
to denote processes that can wait for devices, wait on semaphores, request
alarms from the clock, and so on. System processes, except the idle process,
and all user processes are denoted by an element of APREF.
Without loss of generality, the types PREF, IPREF and APREF can be
given a more concrete representation:
maxprocs : N
There must be an a priori limit to the number of processes that the system
can handle. This constant denotes that limit. The constant is used to limit
the number of entries in the process table.
The constants NullProcRef and IdleProcRef can be deﬁned (again) as
constants:
NullProcRef : PREF
IdleProcRef : IPREF
NullProcRef = 0
IdleProcRef = maxprocs
This representation is intended to bracket the actual process references so
that simple tests can be performed to determine legality.
The following deﬁnitions are of the two other process reference types in
view of the values denoting the null and idle processes:
IPREF == 1 . . maxprocs
APREF == 1 . . maxprocs −1
These deﬁnitions will, in addition, make process identiﬁer generation sim-
pler and easier to understand.

4.4 Process Management
105
The state of each process must be recorded in the corresponding process
table entry. The next type denotes the possible states a process can be in.
It contains designations for the obvious states (the preﬁx pst denotes Process
STate; constants will usually be printed in sans serif font):
•
pstnew: the state of a newly created process that has not yet been readied
(not all of its necessary resources have yet been allocated);
•
pstrunning: the state of a process that is currently executing;
•
pstready: the state of a process that can run but is not currently executing;
•
pstwaiting: the state of a process that is waiting for a device, semaphore,
etc.
•
pstterm: the state of a process that has terminated and is waiting to be
deleted (it might still own resources that are to be deallocated).
In addition, processes can have the following additional states:
•
pstswappedout: the state of a process whose stored image (code, data and
stack) is currently on the swapper disk and not in main store;
•
pstzombie: the state of a process that is waiting to terminate but is pre-
vented from doing so because not all its children have terminated, (The
children still require at least the code segment of the parent to remain
accessible so that they can continue execution.)
(The use of these last two states will become clearer when the swapper and
the zombie scheme are modelled in Section 4.4 of this chapter.)
It is an invariant of this kernel that each process can be in exactly one of
the above states at any one time.
The type representing process states is Z free type and is deﬁned as follows:
PROCSTATUS ::= pstnew
|
pstrunning
|
pstready
|
pstwaiting
|
pstswappedout
|
pstzombie
|
pstterm
Processes fall into natural kinds: system, user and device processes. The
kind of process matters as far as resource allocation, scheduling and swapping
are concerned. The process kind is an attribute that is set when each process
is created; it is constant thereafter. In the type declaration that follows, the
pt preﬁx is denotes Process Table:
PROCESSKIND ::= ptsysproc
|
ptuserproc
|
ptdevproc

106
4 A Swapping Kernel
In this kernel, all device drivers are assigned a kind of ptdevproc.
Processes have various data areas associated with them. In the kernel
modelled in this chapter, a process can have a stack, a data area and a code
area; other kernels might allow a separate heap area. The store allocated to
each of these areas is modelled as a storage descriptor.
The types PSTACK, PCODE and PDATA are required by the kernel
modelled in this chapter. They are deﬁned as synonym types as follows:
PSTACK == MEMDESC
PCODE == MEMDESC
PDATA == MEMDESC
The descriptor types are deﬁned as synonyms for the MEMDESC type, a type
describing regions of store (it is deﬁned as an address-limit pair in Section 4.6
of this chapter). For the time being, these three types can be considered to
have values that are atomic.
Next, there is the type modelling the process descriptor. In this chapter,
the process descriptor is an extension of that deﬁned in the previous chapter.
As is standard, there is one process descriptor per actual process in the system
and, possibly, as the idle process, as well.
The process descriptor, in this model, contains a representation of the
hardware state (general registers, status word, instruction pointer, stack de-
scriptor), as well as a descriptor for each of its code and data areas; the
memsize slot is a descriptor holding the base address and size of the storage
area allocated to this process. (It is assumed that the storage is allocated in
one contiguous segment—this makes storage management much easier than
allocating in discontinuous regions.) It also has a slot for the process status
at the last transition and one for its kind (system, device or user process). In
addition, the process descriptor has slots for the process’ time quantum and
scheduling level (in eﬀect, its priority).
The operations deﬁned for this type are basically concerned with setting
and accessing the values stored in its slots. There is little need to comment
on them. The two interesting operations deal with the process context and
comments will be made after their deﬁnition.
ProcessDescr
↾(INIT, ProcessStatus, SetProcessStatusToNew,
SetProcessStatusToTerminated, SetProcessStatusToReady,
SetProcessStatusToRunning, SetProcessStatusToWaiting,
SetProcessStatusToSwappedOut, SetProcessStatusToZombie,
ProcessKind, SetProcessKindToDevice,
SetProcessKindToSystem, SetProcessKindToUserProc,
WaitingFor, SetWaitingType, SchedulingLevel,
BlocksProcesses, AddBlockedProcesses,
RemoveBlockedProcess, ClearBlockedProcesses,

4.4 Process Management
107
TimeQuantum, SetTimeQuantum,
StoreSize, StoreDescr, SetStoreDescr, FullContext,
SetFullContext)
status : PROCSTATUS
kind : PROCESSKIND
schedlev : SCHDLVL
regs : GENREGSET
time quantum : TIME
statwd : STATUSWD
ip : N
stack : PSTACK
data : PDATA
code : PCODE
mem : MEMDESC
memsize : N
INIT
stat? : PROCSTATUS
knd? : PROCESSKIND
slev? : SCHDLVL
tq? : TIME
pstack? : PSTACK
pdata? : PDATA
pcode? : PCODE
mem? : MEMDESC
msz? : N
status′ = stat?
kind ′ = knd?
schedlev ′ = slev?
regs.INIT
time quantum′ = tq?
statwd ′ = 0S
ip′ = 0
data′ = pdata?
code′ = pcode?
stack ′ = pstack?
mem′ = mem?
memsize′ = msz?
ProcessStatus = . . .
SetProcessStatusToNew = . . .
SetProcessStatusToTerminated = . . .

108
4 A Swapping Kernel
SetProcessStatusToReady = . . .
SetProcessStatusToRunning = . . .
SetProcessStatusToWaiting = . . .
SetProcessStatusToSwappedOut = . . .
SetProcessStatusToZombie = . . .
ProcessKind = . . .
SetProcessKindToDevice = . . .
SetProcessKindToSystem = . . .
SetProcessKindToUserProc = . . .
WaitingFor = . . .
SetWaitingType = . . .
SchedulingLevel = . . .
BlocksProcesses = . . .
AddBlockedProcesses = . . .
AddBlockedProcess = . . .
RemoveBlockedProcess = . . .
ClearBlockedProcesses = . . .
TimeQuantum = . . .
SetTimeQuantum = . . .
StoreSize = . . .
StoreDescr = . . .
SetStoreDescr = . . .
FullContext = . . .
SetFullContext = . . .
ProcessStatus
st! : PROCSTATUS
st! = status
SetProcessStatusToNew
∆(status)
status′ = pstnew

4.4 Process Management
109
SetProcessStatusToTerminated
∆(status)
status′ = pstterm
SetProcessStatusToReady
∆(status)
status′ = pstready
SetProcessStatusToRunning
∆(status)
status′ = pstrunning
SetProcessStatusToWaiting
∆(status)
status′ = pstwaiting
SetProcessStatusToSwappedOut
∆(status)
status′ = pstswappedout
SetProcessStatusToZombie
∆(status)
status′ = pstzombie
ProcessKind
knd! : PROCESSKIND
knd! = kind
SetProcessKindToDevProc
∆(pkind)
kind ′ = ptdevproc

110
4 A Swapping Kernel
SetProcessKindToSysProc
∆(pkind)
kind ′ = ptsysproc
SetProcessKindToUserProc
∆(pkind)
kind ′ = ptuserproc
SchedulingLevel
sl! : SCHDLVL
sl! = schedlev
BlocksProcesses
bw! : F APREF
bw! = blockswaiting
AddBlockedProcesses
∆(blockswaiting)
bs? : F APREF
blockswaiting′ = blockswaiting ∪bs?
AddBlockedProcess
∆(blockswaiting)
b? : APREF
blockswaiting′ = blockswaiting ∪{b?}
RemoveBlockedProcess
∆(blockswaiting)
b? : APREF
blockswaiting′ = blockswaiting \ {b?}
ClearBlockedProcesses
∆(blockswaiting)
blockswaiting′ = ∅

4.4 Process Management
111
TimeQuantum
tq! : TIME
tq! = time quantum
SetTimeQuantum
tq? : TIME
time quantum′ = tq?
StoreSize
memsz! : N
memsize = memsz!
StoreDescr
memdescr! : MEMDESC
memdescr! = mem
This is the descriptor containing the base address of the process’ storage area,
together with its length. It is set (by the next operation) when the process is
ﬁrst allocated and reset whenever it is swapped out and back in again.
SetStoreDescr
∆(pmem, pmemsize)
newmem? : MEMDESC
mem′ = newmem?
memsize′ = hole size(newmem?)
The next two operations are worthy of comment. The ﬁrst is used to store
the current hardware context (general registers, instruction pointer, status
word and stack pointer—here modelled simply as the entire descriptor) when
the process is suspended by an interrupt or by pre-emption. In addition to
the hardware context, the operation also stores the value of the current time
quantum from the scheduler if the process is at user priority.
FullContext
pregs! : GENREGSET
pip! : N
ptq! : TIME
pstatwd! : STATUSWD
pstack! : PSTACK
pregs! = regs

112
4 A Swapping Kernel
pip! = ip
ptq! = time quantum
pstatwd! = statwd
pstack! = stack
The SetFullContext operation is used to restore the process’ context to
the hardware and also the time quantum value. It is called when a process is
executed.
SetFullContext
pregs? : GENREGSET
pip? : N
ptq? : TIME
pstatwd? : STATUSWD
pstack? : PSTACK
regs′ = pregs?
ip′ = pip?
time quantum′ = ptq?
statwd ′ = pstatwd?
stack ′ = pstack?
The two context-manipulating operations are used to suspend and restore the
process. Suspension can be performed by an ISR or by waiting on a semaphore.
Resumption occurs when the scheduler selects the process as the one to run
next.
It should be noted that these schemata operate only on the process de-
scriptor. The actual context switch is performed by generic ISR code or by
semaphores.
Next comes the process table. This is basically a table of process descrip-
tors. When a process is created, a new entry in the process table is allocated
if possible; if it is not possible, creation of the process fails. The AddProcess
operation sets a new process’ data in the table. When a process is to be re-
moved (when it has terminated), it is removed from the table by DelProcess.
The descriptor of a process is obtained from the table by the DescrOfProcess
operation. (In a full model, if the designated process does not exist, an error
would be signalled.)
The remaining operations included in the table fall into three categories:
1. The creation of the idle process. In this model, the idle process has an
entry in the process table. Its descriptor can be used to store hardware
context not otherwise catered for (e.g., the context of the kernel itself).
2. Handling of child processes.
3. Handling of zombie processes.

4.4 Process Management
113
The last two classes of operation will be described in more detail when the pro-
cess hierarchy is described and modelled and when termination is considered
in detail.
The reason for including the last two classes of information in the process
table is that they relate processes rather than describing individual processes;
the process table collects all the necessary information in one place and this
seemed rather better than scattering it in diﬀerent places in the model. In
any case, the process table deals with sets of processes, not single ones; child
processes and zombies clearly deal with sets of processes, so there is a real
semantic reason for the inclusion of this information here.
The organisation of the table is similar to the generic one presented in
Chapter 2. There are slight diﬀerences between the structures; for example,
the generic table is organised around a partial mapping, →, while the process
table uses a partial injection ( ↣). The appropriate results proved for the
generic table transfer with only minor changes to the case of the process
table.
In addition, it is worth pointing out that eac process descriptor in the
process table is annotated with ⃝
C. This is an Object-Z symbol denoting the
fact that the annotated entity (here the process descriptors in the table) is
private to the class containing it. (This has the implication that there are no
reference relations to be taken into account when manipulating or reasoning
about process descriptors.)
The class exports the operations that are to be used by other components
of the kernel. Of particular interest is the operation to retrieve a process de-
scriptor for a given process (DescrOfProcess—this is an operation that will
be particularly common. There are also operations that do not relate to single
processes but to collections of related processes, for example those operating
on descendant processes. The class exports a number of operations for the
association (and disassociation) of child processes with their parents. For ex-
ample, AddChildOfProcess adds a child process’ identiﬁer to a structure that
relates it to its parent. The existence of child processes also requires the estab-
lishment of who owns the code of any particular process. If a process has no
children, it owns its code. If, on the other hand, a process has created a child
process, the child then shares its parent’s code; this fact must be recorded.
There are also operations dealing with so-called zombies. These are pro-
cesses that have almost terminated but cannot release their storage because
they have children that have not yet terminated.
ProcessTable
↾(INIT, CreateIdleProcess, IsKnownProcess, AddProcess, DelProcess,
DescrOfProcess, AddCodeOwner, DelCodeOwner, ProcessHasChildren,
AddChildOfProcess, DelChildOfProcess, AllDescendants, IsCodeOwner,
AddProcessToZombies, MakeZombieProcess, ProcessIsZombie,
RemoveAllZombies, KillAllZombies, ProcessHasParent, ParentOfProcess,
AddProcessToTable, CanGenPId, NewPId, RemoveProcessFromParent)

114
4 A Swapping Kernel
procs : IPREF
↣ProcessDescr⃝
C
known procs : F IPREF
freeids, zombies, code owners : F APREF
parent : APREF  →APREF
children, blockswaiting : APREF  →F APREF
childof , parentof , share code : APREF ↔APREF
(∀p : APREF • p ∈freeids ⇔p ̸∈known procs)
known procs = dom procs ∧zombies ⊂known procs
dom children ⊆known procs ∧dom childof ⊆known procs
ran childof ⊆known procs ∧ran childof = ran parent
childof ∼= parentof ∧code owners ⊆dom parentof
(∀p1, p2 : APREF •
p1 ∈dom blockswaiting ∧
p2 ∈blockswaiting(p1) ⇒
(p1 ∈code owners ∨parentof +(p1, p2)))
INIT
known procs′ = {IdleProcRef }
freeids′ = 1 . . maxprocs −1
code owners′ = {IdleProcRef }
dom shares code′ = ∅
dom childof ′ = ∅
dom blockswaiting′ = ∅
zombies′ = ∅
CreateIdleProcess = . . .
IsKnownProcess = . . .
AddProcess = . . .
DelProcess = . . .
DescrOfProcess = . . .
AddCodeOwner = . . .
DelCodeOwner = . . .
ProcessHasChildren = . . .
AddChildOfProcess = . . .
DelChildOfProcess = . . .
IsCodeOwner = . . .
AddProcessToZombies = . . .
MakeZombieProcess = . . .
ProcessIsZombie = . . .

4.4 Process Management
115
RemoveAllZombies = . . .
KillAllZombies = . . .
GotZombies = . . .
ProcessHasParent = . . .
RemoveProcessFromParent = . . .
ParentOfProcess = . . .
CanGenPId = . . .
NewPId = . . .
releasePId = . . .
AddProcessToTable = . . .
deleteProcessFromTable = . . .
The following operation creates the idle process. The operation sets up
basic data about the idle process, including the status (it will be a ready
process, so can be immediately considered by the scheduler) and process kind
(it is a system process); the operation assigns an arbitrary time quantum
to the process (∞) and its status word is cleared to 0s. Next, the storage
areas are created; the idle process does not have any storage (since it does
nothing other than loop), so anything can be assigned (here, empty storage
descriptors are assigned). Then, the idle process’ process descriptor is created
by calling the Init method belonging to its type and the descriptor is stored
in the process table.
CreateIdleProcess
(∃stat : PROCSTATUS; knd : PROCESSKIND; schdlv : SCHEDLVL;
tq : TIME; stwd : STATUSWD; emptymem : MEMDESC;
stkdesc : MEMDESC; memsz : N; ipd : ProcessDescr •
stat = pstready
∧knd = ptuserproc ∧schdlv = userq
∧tq = ∞∧stwd = 0s ∧emptymem = (0, 0)
∧stkdesc = (0, 0) ∧memsz = 0
∧ipd.INIT[stat/stat?, knd/knd?, schdlv/slev?, tq/tq?,
stkdesc/pstack?, emptymem/pdata?,
emptymem/pcode?, emptymem/mem?, memsz/msz?]
procs′ = procs ⊕{IdleProcRef →ipd})
It is necessary to generate new process identiﬁers. The following three
operations are for this purpose. There is a maximum size associated with the
process table: there can, at any time, be a maximum of maxprocs processes in
the table. This is done in this model by manipulating a set of identiﬁers, as
follows. When an identiﬁer is in this set, it is considered available for use by

116
4 A Swapping Kernel
a new process; when it is not in this set, it is considered to be the identiﬁer
of a process in the process table.
The following schema deﬁnes a predicate determining whether there are
any process names that are free. The set freeids contains all those identiﬁers
that have not been assigned to a process.
CanGenPId
freeids ̸= ∅
NewPId
∆(freeids)
p! : APREF
(∃p : APREF •
p ∈freeids
∧p! = p
∧freeids′ = freeids \ {p})
The NewPId operation returns a new process identiﬁer. The predicate can be
simpliﬁed, obtaining:
NewPId
∆(freeids)p! : APREF
p! ∈freeids
freeids′ = freeids \ {p!}
The operation selects an element of freeids at random, removes it from freeids
and returns it as the next process identiﬁer for use.
releasePId
∆(freeids)
p? : APREF
freeids′ = freeids ∪{p?}
This operation returns an identiﬁer to the free pool of identiﬁers. The identi-
ﬁer, denoted by p?, is added to freeids and, therefore, can no longer be used
as the identiﬁer of a process in the process table, as the class invariant states.
The IsKnownProcess operation is a predicate which tests whether a given
identiﬁer (pid?) is in the set known procs, the set of known process identiﬁers.
By the invariant of the class, an identiﬁer is an element of known procs if and
only if it is not a member of freeids. Therefore, every member of known procs
is the identiﬁer of a process in the process table.

4.4 Process Management
117
IsKnownProcess
pid? : APREF
pid? ∈known procs
Process descriptors are added to the process table by the following opera-
tion. In a full model, it would be an error to attempt to add a descriptor that
is already present in the table or to use an identiﬁer that is in freeids. For
present purposes, the following suﬃces:
AddProcessToTable
∆(procs)
pid? : APREF
pd? : ProcessDescr
procs′ = procs ⊕{pid? →pd?}
This is an operation local to the ProcessTable. The public operation is the
following:
AddProcess =
newPId o
9 addProcessToTable
The addition of the identiﬁer generator implies that there is no need to check
the validity of the new process’ identiﬁer (the fact that identiﬁers are unique
and not in the table should be proved as a property of the model, as is done
below, after the process table’s operations have been deﬁned).
Removal of a process descriptor from the process table is performed by
the following local operation:
deleteProcessFromTable
∆(procs)
pid? : APREF
procs′ = {pid?} −◁procs
The deleted process’ identiﬁer is removed from the domain of the procs map-
ping using the domain subtraction operator −◁.
DelProcess = deleteProcessFromTable o
9 releasePId
The public deletion operation also needs to ensure that the identiﬁer of the
deleted process is released (i.e., is added to freeids).
Throughout the model, access to each process’ process descriptor is re-
quired. The following schema deﬁnes this operation. A fuller model, partic-
ularly one intended for reﬁnement, would include an error schema to handle
the case in which the process identiﬁer, pid?, does not denote a value element
of the procs domain (i.e., is not a member of known procs).

118
4 A Swapping Kernel
DescrOfProcess
pid? : IPREF
pd! : ProcessDescr
pd! = procs(pid?)
Methods for children and zombies now follow.
The owner of a code segment is recorded here. This allows the system to
determine which process owns any segment of code when swapping occurs.
AddCodeOwner
∆(code owners)
p? : APREF
code owners′ = code owners ∪{p?}
DelCodeOwner
∆(code owners)
p? : APREF
code owners′ = code owners \ {p?}
Shared code is important when swapping is concerned.
Since there can
be many sharers of any particular process’ code, it appears best to represent
code sharing as a relation.
The following operation declares the process owner? as the owner of a
code segment, while sharer? denotes a process that shares owner?’s code. For
every such relation, there must be an instance in the code owners relation in
the process table.
AddCodeSharer
∆(code owners)
owner?, sharer? : APREF
code owners′ = code owners ∪{(owner?, sharer?)}
DelCodeSharer
∆(code owners)
owner?, sharer? : APREF
code owners′ = code owners \ {(owner?, sharer?)}
Zombies and sharing depend upon the process hierarchy. This is expressed
in terms of parent and child processes.
The hierarchy is most easily repre-
sented as a relation that associates a parent with its children. The following

4.4 Process Management
119
few operations handle the childof relation, which represents the process hier-
archy in this model.
ProcessHasChildren
p? : APREF
∃c : APREF •
childof (c, p?)
AddChildOfProcess
∆(childof )
parent?, child? : APREF
childof ′ = childof ∪(child?, parent?)
DelChildOfProcess
∆(childof )
parent?, child? : APREF
childof ′ = childof \ (child?, parent?)
AllDescendants
descs! : F APREF
parent? : APREF
descs! = childof +(| {p?} |)
When a process has children in this model, the children processes all share
the parent’s code. If the parent is swapped out, its code segment is transferred
to backing store and, as a consequence, is no longer addressable by the child
processes. Because of this, it is necessary to block (i.e., suspend) all child
processes when their parent is swapped out.
The following schema is satisﬁed when the process, p?, owns the code it ex-
ecutes. Code-owning processes tend not to be descendants of other processes.
IsCodeOwner
p? : APREF
p? ∈code owners
The operations for handling zombie processes now follow. Zombies are
relatively easy to represent and manipulate in this model.

120
4 A Swapping Kernel
AddProcessToZombies
∆(zombies)
pid? : APREF
zombies′ = zombies ∪{pid?}
MakeZombieProcess =
AddProcessToZombies ∧
SetProcessStatusToZombie
ProcessIsZombie
pid? : APREF
pid? ∈zombies
Operation RemoveAllZombies removes those processes from the children
relation that are related to the zombie process zmb.
RemoveAllZombies
∆(parent, children, zombies)
deadzombs! : F APREF
∃zmbs : F APREF | zmbs ⊆zombies ∧deadzombs! = zmbs •
zombies′ = zombies \ zmbs
∧(∀zmb : APREF | zmb ∈zombies ∧children(zmb) = ∅•
parent′ = {zmb} −◁parent
∧(∃p : APREF; descs : F APREF |
p = parent(zmb) ∧descs = children(p) •
children′ = children ⊕{p →descs \ {zmb}))
When this operation is used, each zmb has no children. It must be removed
from the parent table and it has to be removed as a child of its parent.
The KillAllZombies operation is deﬁned as follows:
KillAllZombies =
(RemoveAllZombies[dzombs/deadzombies!] ∧
(∀zmb : APREF | zmb ∈dzombs •
DelProcess[zmb/p?])) \ {dzombs}
This operation is performed on a periodic basic. It is called from the clock
process.
The following schema deﬁnes a predicate that is true if the set of zombies
contains at least one element. This operation is used in the clock driver.
GotZombies
zombies ̸= ∅

4.4 Process Management
121
ProcessHasParent
p? : APREF
(∃p1 : APREF •
parentof (p1, p?))
RemoveProcessFromParent
∆(parentof )
parent?, child? : APREF
parentof ′ = parentof \ {(parent?, child?)}
ParentOfProcess
p? : APREF
parent! : APREF
(∃p1 : APREF •
parentof (p1, p?) ∧parent! = p1)
Note that the initialisation of the system should include a call to the
operation that creates the idle process.
The deﬁnition of the ProcessTable class is now complete. It is now possible
to state and prove some properties of this class.
Proposition 34. The identiﬁer of (reference to) the idle process, IdleProcRef,
is unique.
Proof.
IdleProcRef = maxprocs. The result follows by the uniqueness of
natural numbers.
2
Proposition 35. The idle process is unique.
Proof. Each process is represented by:
(i) a unique identiﬁer (its reference);
(ii) a single entry in the process table.
For (ii), procs : IPREF  →PD since procs is a function:
procs(x) = procs(y) ⇒x = y
Therefore, by Proposition 48, the idle process descriptor is unique.
2
Proposition 36. The identiﬁer NullProcRef never appears in the process ta-
ble.

122
4 A Swapping Kernel
Proof. The domain of procs is IPREF and IPREF ⊂PREF. NullProcRef ∈
PREF = 0. .maxprocs, while IPREF = 1. .maxprocs. Since NullProcRef = 0,
it is an element of PREF but not of IPREF.
2
Proposition 37. ∀p : APREF • p ∈freeids ⇔p ̸∈known procs.
Proof. This is a conjunct of the invariant.
2
Proposition 38. NewPId[p/p!] ⇒p ∈known procs′.
Proof.
NewPId
∆(freeids)
p! : APREF
p! ∈freeids
freeids′ = freeids \ {p!}
By the invariant:
p ∈freeids ⇔p ̸∈known procs
By propositional calculus:
p ̸∈freeids ⇔p ∈known procs
So, if p ∈freeids ⇔p ̸∈known procs,
freeids′
= freeids \ {p}
= known procs ∪{p}
= known procs′
Therefore, p ∈known procs′.
2
Proposition 39. NewPIdn ⇒freeids′ = ∅if n = maxprocs −1.
Proof. The NewPId operation is:
NewPId
∆(freeids)
p! : APREF
p! ∈freeids
freeids′ = freeids \ {p!}

4.4 Process Management
123
Initially, freeids = 1 . . maxprocs −1, so #freeids = maxprocs −1.
Now, NewPIdn =
n times



(NewPId o
9 . . . NewPId). From the deﬁnition of NewPId,
it can be seen that #freeids′ = #freeids −1. Therefore, newPIdn
⇒
#freeids′ = #freeids −n.
If n = maxprocs −1, it is clear that NewPIdn implies that:
#freeids′
= #freeids −(maxprocs −1)
= (maxprocs −1) −(maxprocs −1)
= 0
So freeids′ = ∅.
2
Proposition 40. NewPId ⊢#freeids′ = #freeids −1.
Proof. By the deﬁnition of NewPId, p! ∈freeids ∧freeids′ = freeids \ {p!}.
Therefore:
#freeids′
= #(freeids \ {p!}
= #freeids −#{p!}
= #freeids −1
2
Proposition 41. DelProcess ⊢#freeids′ = #freeids + 1.
Proof. The deﬁnition of DelProcess is:
deleteProcessFromTable o
9 releasePId
The important conjunct is releasePId, whose predicate is:
freeids′ = freeids ∪{p?}
The result is immediate:
#freeids′
= #(freeids ∪{p?})
= #freeids + #{p?}
= #freeids + 1
2
Corollary 6. deleteProcessFromTable ⊢p ̸∈known procs′.

124
4 A Swapping Kernel
Proof. By the deﬁnition of deleteProcessFromTable, procs′ = {pid?}−◁procs
and known procs = dom procs. The predicate implies that pid? ̸∈dom procs′,
which, in turn, implies that pid? ̸∈known procs.
2
Proposition 42. If p ∈known procs and p1 ̸= p, the substitution instance
of schema deleteProcessFromTable[p1/pid?] implies that p ∈known procs′.
Proof. By the deﬁnition of deleteProcessFromTable:
procs′ = {p1} −◁procs
The invariant states that dom procs = known procs. Therefore:
dom procs′
= dom({p1} −◁procs)
= (dom procs) \ {p1}
= known procs \ {p1}
= known procs′
However, by assumption, p ̸= p1, so p ∈known procs.
2
Proposition 43. Using the deﬁnition of NewPIdn above, the composition
NewPIdn o
9 DelProcessm implies #freeids = #freeids′ iﬀn = m.
Proof. The proof of this proposition requires the following (obvious) lem-
mata.
Lemma 13. If #freeids = n, NewPIdn implies #freeids = 0.
Proof. Since NewPId ⇒#freeids′ = #freeids −1, then, by induction, for
all n, n ≥#freeids, NewPIdn implies that #freeids′ = #freeids −n.
2
Lemma 14. If #freeids = n, DelProcess implies that #freeids′ = n + 1.
Proof.
Immediate from the fact that releasePId implies that #freeids′ =
#freeids + 1.
2
Lemma 15. If #freeids = 0, then DelProcessn implies that #freeids′ = n.
Proof. By induction, using Proposition 14.
2
The proof of Proposition 43 follows immediately from the three lemmata. 2
Proposition 44. ¬ CanGenPId ⇒¬ NewPId.

4.4 Process Management
125
Proof. The operations are deﬁned by the following schemata:
CanGenPId
freeids ̸= ∅
and:
NewPId
∆(freeids)
p! : APREF
p! ∈freeids
freeids′ = freeids \ {p!}
Given
¬ canGenPId
freeids = ∅
it is clear that there can be no p s.t. p! ∈freeds.
2
Proposition 45. NewPIdn o
9 releasePIdm ⇒freeids′ = ∅iﬀm = n.
Proof. Immediate consequence of Proposition 43.
2
Proposition 46. There can be no p ∈APREF such that p ∈freeids and
p ∈known procs.
Proof.
By the invariant, p ∈freeids ⇔p ̸∈known procs, for all p. Using
propositional calculus, the following can be derived:
1. If p ∈freeids, then p ̸∈known procs.
2. If p ∈known procs, then p ̸∈freeids.
Therefore, ¬ ∃p : PREF • p ∈freeids ∧p ∈known procs.
2
Proposition 47. NewPId[p1/p!] o
9 NewPId[p2/p!] ⇒p1 ̸= p2.
Proof. The schema for NewPId is:
NewPId
∆(freeids)
p! : APREF
p! ∈freeids
freeids′ = freeids \ {p!}

126
4 A Swapping Kernel
By the deﬁnition of o
9, NewPId[p1/p!] o
9 NewPId[p2/p!] is:
∃freeids′′ : F APREF •
p1 ∈freeids ∧freeids′′ = freeids \ {p1}
∧p2 ∈freeids′′ ∧freeids′ = freeids′′ \ {p2}
This simpliﬁes to:
p1 ∈freeids ∧p2 ∈freeids \ {p1}
∧freeids′ = (freeids \ {p1}) \ {p2}
This is clearly equivalent to:
p1 ∈freeids ∧p2 ∈freeids \ {p1}
∧freeids′ = freeids \ {p1, p2}
For p2 ∈freeids \ {p1} to be the case, p1 ̸= p2, for the reason that
p ̸∈freeids{p} for any p.
2
Proposition 48.
deleteProcessFromTable ⇒known procs′ = known procs \ {pid?}
Proof.
deleteProcessFromTable
∆(procs)
pid? : AREF
procs′ = {pid?} −◁procs
By the invariant, known procs = dom procs, so:
dom procs′
= dom({pid?} −◁procs)
= (dom procs) \ {pid?}
= known procs \ {pid?}
= known procs′
2
4.5 The Scheduler
The scheduler is based on a three-level priority scheme. The basic type is:
SCHDLVL == 1 . . 3

4.5 The Scheduler
127
This type is used to identify queues of waiting processes. The queues are
identiﬁed by the following constants:
userqueue, sysprocqueue, devprocqueue : SCHDLVL
userqueue = 3
sysprocqueue = 2
devprocqueue = 1
The ﬁrst constant, userqueue, denotes the queue of user processes; the second
constant, sysprocqueue, denotes the queue of system processes; and the third,
devprocqueue, denotes the queue of device processes.
Device processes must always be preferred to other processes, so the con-
stant devprocqueue denotes the queue of highest-priority processes. System
processes must be preferred by the scheduler to user processes but should be
pre-empted by device processes, so sysprocqueue denotes the next highest pri-
ority. The constant userqueue denotes the queue of user processes; they have
lowest priority.
In addition, there is the idle process (denoted by the constant IdleProcRef )
which runs when there is nothing else to do. Strictly speaking, the idle process
has the lowest priority but is considered a special case by the scheduler (see the
schema for ScheduleNext), so it appears in none of the scheduler’s queues. (In
the process table, the idle process is assigned to the user-process priority—this
is just a value that is assigned to avoid an unassigned attribute in its process
descriptor.)
The ordering on the priorities is:
devprocqueue < sysprocqueue < userqueue
This property will be exploited in the deﬁnition of the scheduler.
queuelevel : PROCESSKIND →SCHDLVL
∀pt : PROCESSKIND •
(∃l : SCHDLVL •
queuelevel(pt) =
(pt = ptdevdrvr ∧l = devprocqueue)
∨(pt = ptsysproc ∧l = sysprocqueue)
∨(pt = ptuserproc ∧l = userqueue))
As noted above, type ProcessQueue is not deﬁned in terms of QUEUE[X ]
but deﬁned separately. This is because all elements of a process queue are
unique (i.e., there are no duplicates), so the basic type iseq is used rather
than seq.
The class Context is deﬁned so that process context manipulation can
be made simpler. The class accesses the process table, the scheduler (to be
deﬁned shortly) and the hardware registers. The class deﬁnes ﬁve operations.

128
4 A Swapping Kernel
Context
↾(INIT, SaveState, RestoreState, SwapIn, SwapOut, SwitchContext)
ptab : ProcessTable
sched : LowLevelScheduler
hw : HardwareRegisters
INIT
ptb? : ProcessTable
shd? : LowLevelScheduler
hwregs? : HardwareRegisters
ptab′ = ProcessTable
sched ′ = LowLevelScheduler
hw ′ = hwregs?
SaveState = . . .
RestoreState = . . .
SwapIn = . . .
SwapOut = . . .
SwitchContext = . . .
When an interrupt occurs, SaveState is called to save the state. Then, the
device-speciﬁc stuﬀis executed (this might involve calling SendInterruptMsg).
Finally, the RestoreState method is called to perform a context switch.
SaveState
(∃cp : IPREF •
sched.CurrentProcess[cp/cp!]
(∃pd : ProcessDescr •
ptab.DescrOfProcess[cp/pid?, pd/pd!]
∧(∃regs : GENREGSET; stk : PSTACK; ip : N;
stat : STATUSWD; tq : TIME •
hw.GetGPRegs[regs/regs!]
∧hw.GetStackReg[stk/stk!]
∧hw.GetIP[ip/ip!]
∧hw.GetStatWd[stat/stwd!]
∧sched.GetTimeQuantum[tq/tquant!]
∧pd.SetFullContext[regs/pregs?, ip/pip?,
stat/pstatwd?, stk/pstack?, tq/ptq?])))
The current process referred to here is not necessarily the same as the one
referred to above. Basically, whatever is in (bound to) currentp runs next.

4.5 The Scheduler
129
RestoreState
(∃cp : IPREF •
sched.CurrentProcess[cp/cp!]
∧(∃pd : ProcessDescr •
ptab.DescrOfProcess[cp/pid?, pd/pd!]
∧(∃regs : GENREGSET; stk : PSTACK; ip : N;
stat : STATUSWD; tq : TIME •
pd.FullContext[regs/pregs!, ip/pip!, stat/pstatwd!,
stk/pstack!, tq/ptq!]
∧hw.SetGPRegs[regs/regs?]
∧hw.SetStackReg[stk/stk?]
∧hw.SetStatWd[stat/stwd?]
∧sched.SetTimeQuantum[tq/tquant?]
∧hw.SetIP[ip/ip?])))
For completeness, we deﬁne the SwapOut and SwapIn operations (al-
though they are not used in this book): they are intended to be mutually
inverse.
SwapOut =
(∃cp : IPREF; pd : ProcessDescr •
sched.CurrentProcess[cp/cp!]
∧ptab.DescrOfProcess[pd/pd!] ∧pd.SetProcessStatusToWaiting)
∧SaveStateo
9
(sched.MakeUnready[currentp/pid?] ∧sched.ScheduleNext)
The SwapOut operation uses SaveState and alters the status of the process
concerned. The process is removed from the ready queue and a reschedule is
performed, altering the current process.
SwapIn =
(∃cp : IPREF; pd : ProcessDescr •
sched.CurrentProcess[cp/cp!] ∧pd.SetProcessStatusToRunning
RestoreState)
The SwapIn operation just performs simple operations on the process’ descrip-
tor and then switches the process’ registers onto the hardware and makes it
the current process (i.e., the currently running process).
SwitchContext = SwapOut o
9 SwapIn
This is a combination operation that swaps out the current process, schedules
and executes the next one.
The organisation of the scheduler implies that the idle process must be
represented by a descriptor in the process table. This is for a number of
reasons, including the need for somewhere to store the kernel’s context.

130
4 A Swapping Kernel
The kernel’s scheduler is called the LowLevelScheduler. It is deﬁned as
follows.
The scheduler has three queues (readyqs), one each for device, system and
user process (in that order). It is worth noting that the process queues are all
contained in the class. This scheme is a multi-level priority queue.
The currently executing process is represented by currentp. The time quan-
tum of the current process is represented by currentquant (if it is a user-level
process). For all processes, the priority is represented by currentplev.
The component prevp refers to the process that executed immediately
before the one currently denoted by currentp.
As already observed, readyqs is an array of queues (represented by a bi-
jection) and nqueues is the number of queues in readyqs (is the cardinality of
readyqs’ domain).
The scheduler is deﬁned at a level in the kernel that is below that at which
semaphores are deﬁned. For this reason, it is important to ﬁnd another way
to obtain exclusive access to various data structures (e.g., the process table,
a particular process descriptor, the hardware registers or the scheduler’s own
queues). At the level at which the scheduler is deﬁned, the only way to do this
in the present kernel is to employ locking. For this reason, the class initialises
itself with an instance of Lock.
LowLevelScheduler
↾(INIT, GetTimeQuantum,
SetTimeQuantum, RunIdleProcess,
CurrentProcess, MakeReady,
UpdateProcessQuantum, MakeUnready,
ContinueCurrent,
ScheduleNext)
currentp : IPREF
currentquant : TIME
currentplev : SCHDLVL
prevp : IPREF
nqueues : N1
readyqs : SCHDLVL ↣
→ProcessQueue⃝
C
lck : Lock
ctxt : Context
proctab : ProcessTable
hw : HardwareRegisters
nqueues = 3
#readyqs = nqueues

4.5 The Scheduler
131
INIT
lk? : Lock
ptb? : ProcessTable
hwrs? : HardwareRegisters
lck ′ = lk?
proctab′ = ptb?
currentp′ = NullProcRef
currentquant′ = 0
currentplev ′ = userqueue
prevp′ = NullProcRef
prevplev ′ = 1 ∧hw ′ = hwregs?
GetTimeQuantum = . . .
SetTimeQuantum = . . .
RunIdleProcess = . . .
CurrentProcess = . . .
MakeReady = . . .
UpdateProcessQuantum = . . .
MakeUnready = . . .
reloadCurrent = . . .
ContinueCurrent = . . .
ScheduleNext = . . .
runTooLong = . . .
allEmptyQueues = . . .
selectNext = . . .
The operations deﬁned for the scheduler can now be described.
User processes are associated with a time quantum. This is used to de-
termine when a user process should be removed from the processor if it has
not been blocked by other means. The current time quantum must be copied
to and from the current process’ descriptor in the process table. It must be
possible to assign currentquant to a value. The following pair of operations
specify these operations.
The ﬁrst returns the value stored in the time quantum variable. This value
represents the time quantum that remains for the current process.
GetTimeQuantum
tquant! : TIME
currentquant = tquant!

132
4 A Swapping Kernel
The second operation sets the value of the current process’ time quantum;
this operation is only used when the current process is a user-deﬁned one.
When a user process is not executing, its time quantum for a process is stored
in its process descriptor.
SetTimeQuantum
tquant? : TIME
(∃pd : ProcessDescr; lv : SCHDLVL •
proctab.DescrOfProcess[currentp/pid?, pd/pd!]
∧pd.ProcessLevel[lv/lev!]
∧((lv = userqueue ∧currentquant′ = currentquant −tquant?)
∨currentquant′ = 0))
When there are no other processes to execute, the idle process is run.
RunIdleProcess
∆(currentp)
currentp′ = IdleProcRef
billp′ = IdleProcRef
This schema deﬁnes the operation to select the idle process as the next process
to run. Note that it does not switch to the idle process’ context because the
code that calls this will perform that operation by default.
When a process is swapped oﬀthe processor, its identiﬁer must be retrieved
from currentp. The following schema deﬁnes that operation:
CurrentProcess
cp! : IPREF
cp! = currentp
With the MakeReady, we have come to the core set of scheduler operations.
This operation adds the process named by pid? to the ready queue at the
appropriate priority level.
The MakeReady operation ﬁrst locks everything else out of the processor.
It then obtains the process descriptor for the process referred to by pid?. The
priority of this process is extracted from its process descriptor and the process
is enqueued on the appropriate queue. (Actually, the pid?—a reference to the
process—is enqueued.) Finally, the operation unlocks the processor.

4.5 The Scheduler
133
MakeReady
∆(readyqueues)
pid? : IPREF
lck.Lock o
9
(∃pd : ProcessDescr; lv : SCHDLVL •
proctab.DescrOfProcess[pd/pd!]
∧pd.ProcessLevel[lv/lev!]
∧pd.SetProcessStatusToReady
∧(readyqueues(lv).Enqueue[pid?/x?]
∧lck.Unlock)
Proposition 49. For any process, p, at priority level, l, MakeReady[p/pid?]
implies that:
#readyqueues′(l) = #readyqueues(l) + 1
Proof. The critical line in the predicate is:
readyqueue(l).Enqueue[p/x?]
The deﬁnition of Enqueue, after substituting p for x?, is:
elts′ = elts ⌢⟨p⟩
So:
#elts′ =
#(elts ⌢⟨p⟩) =
#elts + #⟨p⟩=
#elts + 1
2
Operation UpdateProcessQuantum updates the time quantum in a process
descriptor, provided that the process is a user-level one. The quantum (stored
in currentquant) is decremented by one to denote the fact that the process
has just executed.
UpdateProcessQuantum
(∃pd : ProcessDescr; lv : SCHDLVL •
proctab.DescrOfProcess[currentp/pid?, pd/pd!]
∧pd.ProcessLevel[lv/lev!]
∧((lv = userqueue
∧currentquant′ = currentquant −1
∧((currentquant′ ≤minpquantum ∧runTooLong)
∨(currentquant′ > minpquantum ∧ContinueCurrent)))
∨Skip))

134
4 A Swapping Kernel
This operation deals with the case in which a user process has run for too
long a period. Its operation is very much as one might expect.
runTooLong
(∃p : APREF •
readyqueues(userqueue).RemoveFirst[p/x!]o
9
(readyqueues(userqueue).Enqueue[p/x?]o
9
(prevp′ = currentp ∧ScheduleNext)))
This is called by the clock driver (Section 4.6.4) to cause pre-emption of the
current user process.
Proposition 50. UpdateProcessQuantum implies that if currentp’s priority
is userqueue and currentquant > minpquantum, then currentp′ = currentp.
Proof. By the predicate, if currentquant′ > minpquantum, ContinueCurrent
is executed. The predicate of ContinueCurrent contains currentp′ = currentp
as a conjunct.
2
Proposition 51. If there are no processes of higher priority in the scheduler’s
ready queue, UpdateProcessQuantum implies that currentp′ = currentp if the
user-level queue only contains process p.
Proof. Let readyqueues(userqueue) = ⟨p⟩. The predicate of runTooLong is
(in shortened form): RemoveFirst o
9 Enqueue. This implies that elts = elts′ if
elts = ⟨p⟩.
The sequential composition expands into:
∃elts′′ : iseqAPREF; x! : APREF •
x! = head elts
∧elts′′ = tail elts
∧elts′ = elts′′ ⌢⟨x!⟩
This simpliﬁes to elts′ = (tail elts) ⌢⟨head elts⟩. If elts = ⟨p⟩, tail elts = ⟨⟩,
and:
elts′
= (tail elts) ⌢⟨head elts⟩
= ⟨⟩⌢⟨head elts⟩
= ⟨⟩⌢(head⟨x⟩)
= ⟨⟩⌢⟨x⟩
= ⟨x⟩
= elts
By selectNext, currentp′ = p since selectNext contains QueueFront as a con-
junct and QueueFront is deﬁned in terms of head elts.
2

4.5 The Scheduler
135
Proposition 52. Assuming there are no processes of higher priority in the
ready queue, if the level of the executing process is userqueue and
currentquant ≤minpquantum
then
currentp′ ̸= head readyqueues(userqueue)
if #readyqueues(userqueue) > 1.
Proof. Assume that the queue readyqueues(userqueue) is of length greater
than 1. Then head elts = currentp and head tail elts ̸= currentp. By the com-
position RemoveFirst o
9Enqueue, elts′ = (tail elts)⌢⟨currentp⟩. Since there are
no duplicates in elts, this implies that currentp′ = head tail elts′ ̸= currentp. 2
The MakeUnready operation is another key operation. Its intent is to re-
move the process denoted by pid? from the ready queue. What happens to the
process thereafter is a matter for the caller of MakeUnready. The MakeUn-
ready operation does not manipulate the context of the victim process because
it is not clear what that state is; instead, it just removes the process from the
queue. If the process is the head of its queue, it is removed and a rescheduling
operation occurs; otherwise, the process is just removed.
The operation removes any process reference that is in the queue. The
reference can be the head of the queue or somewhere inside the queue. What
happens to the reference that is removed is a matter for the user of this
operation. Typically, the process reference is enqueued on another queue (e.g.,
a device queue or the clock). Because what is to happen to the removed
process cannot be determined, the MakeUnready schema contains no reference
to operations manipulating the representation of the process’ state in the
process descriptor. (The reader should note that RemoveElement will also
remove the head of the queue—the schema is written to be as clear as possible.)
MakeUnready
pid? : APREF
(∃q : ProcessQueue; pd : ProcessDescr; lv : SCHDLVL •
proctab.DescrOfProcess[pd/pd!]
∧pd.ProcessLevel[lv/lev!] ∧q = readyqueues(lv)
∧(¬ q.IsEmpty
∧(∃f : APREF •
q.QueueFront[f /x!]
∧(f = pid? ∧(q.RemoveFirst o
9
q.selectNext[q/q?, lv/lev?]))
∨q.RemoveElement[pid?/x?])))

136
4 A Swapping Kernel
Proposition 53. If a process, p, has priority l, and is in the ready queue,
then MakeUnready[p/pid?] implies that:
#readyqueues′(l) = #readyqueues(l) −1
Proof. There are two cases to consider: in the ﬁrst, p is at the head of the
queue and in the other, p is not at the head.
In both cases, let readyqueues(l) = elts.
Case 1. In the predicate, f = p or p = head elts, so elts = ⟨p⟩⌢elts′. Then:
#elts =
#(⟨p⟩⌢elts′) =
#⟨p⟩+ #elts′ =
1 + #elts′
So #elts′ = #elts −1.
Case 2. p ̸= head elts. Therefore:
∃s1, s2 : iseq APREF •
elts = s1 ⌢⟨p⟩⌢s2 ∧
elts′ = s1 ⌢s2
Therefore:
#elts =
#(s1 ⌢⟨p⟩⌢s2) =
#s1 + #⟨p⟩+ #s2 =
#s1 + 1 + #s2 =
1 + #s1 + #s2 =
1 + #elts′
2
Proposition 54. Let q be readyqueues(pr), where pr is the priority of process,
p. If p is an element of q, then MakeUnready[p/pid?] implies that p is not
an element of q′.
Proof. There are two cases to consider:
Case 1. Process p is the head of q. The appropriate conjunct of MakeUnready
is:
q.QueueFront[f /x!]
∧(f = pid? ∧q.RemoveFirst)
The predicate of RemoveFirst is:

4.5 The Scheduler
137
elts′ = tail elts
which is equivalent to:
elts = ⟨p⟩⌢elts′
from which it is clear that p is not an element of elts′; hence, p cannot be an
element of q′.
Case 2. Process p is not the head element of q. Therefore, in MakeUnready,
f ̸= pid?, so q.RemoveElement[pid?/x?] is required. The RemoveElement’s
predicate is:
∃s1, s2 : iseq APREF •
s1 ⌢⟨pid?⟩⌢s2 = elts
∧s1 ⌢s2 = elts′
It is again immediate that p cannot be an element of elts′ and, hence, not of
q′.
2
reloadCurrent
∆(currentp, prevp)
currentp′ = currentp
prevp′ = prevp
ContinueCurrent =
reloadCurrent ∧ctxt.RestoreState
This operation is really just the identity on the scheduler’s state. The intent is
that the current process’ execution is continued after a possible rescheduling
operation. If the rescheduling operation determines that the same process be
continued, the operation speciﬁed by this schema is performed.
The scheduler needs to determine whether all of its queues are empty. The
following schema deﬁnes this test:
allEmptyQueues
∀i : SCHDLVL •
readyqueues(i).IsEmpty
If all the queues are empty, the idle process must be run.
The selectNext operation is a central part of the scheduler.

138
4 A Swapping Kernel
selectNext
(∃q : ProcessQueue •
q = readyqueues(devprocqueue)
⊗readyqueues(sysprocqueue)
⊗readyqueues(userqueue)
∧(∃p : APREF; l : SCHDLVL; pd : ProcessDescr •
q.QueueFront[p/x!]
∧proctab.DescrOfProcess[p/pid?, pd/pd!]
∧pd.SchedulingLevel[l/sl!]
∧prevp′ = currentp
∧currentp′ = p
∧currentplev ′ = l))
The schema ﬁrst concatenates the three queues so that the head can be de-
termined. This is licensed by the fact that, for any sequence, injective or not,
⟨⟩⌢q = q. The process at the head of the queue is determined and its prior-
ity is obtained from the process descriptor. The current and previous process
variables are updated, as is the record of the current process’ priority. The
priority, currentplev, is only of signiﬁcance when it is userqueue: in this case,
pre-emption using time quanta is employed.
Proposition 55. If:
q = readyqueues(devprocqueue)
⊗readyqueues(sysprocqueue)
⊗readyqueues(userqueue)
then 0 ≤#q ≤maxprocs −1.
Proof. The element type of readyqueue(i), i : SCHDLVL, is APREF. There
can be a maximum of maxprocs −1 elements in APREF. If all processes in
the system are readied, they will be in exactly one of the queues, depending
upon priority. Since q is the concatenation of all priority queues, its maximum
length is therefore maxprocs −1.
If, on the other hand, there are no ready processes (and the idle process
is the next to run), readyqueues is empty for all i : SCHDLVL, so #q = 0. 2
Finally, we reach ScheduleNext. This is the scheduling operation.
ScheduleNext =
(allEmptyQueues ∧RunIdleProcess)
∨selectNext
If all scheduler queues are empty, the idle process is executed; otherwise,
another process is selected for execution. It should be noted that this operation
must always be executed in a locked context: it is called either in an ISR or
in the body of a semaphore.

4.5 The Scheduler
139
Time quantum manipulation and pre-emption are performed by the clock
process. The appropriate operations are deﬁned there (see Section 4.6.3).
The scheduler’s data structures and operations have now been deﬁned. It
is now time to prove some of the more important properties of the scheduler
as deﬁned above.
Proposition 56. If a process, p, is of priority l, operation MakeReady[p/pid?]
enqueues p on the queue for level l.
Proof. Expanding MakeReady[p/pid?], we obtain:
pd.procs(p)
∧pd.SchedulingLevel[l/sl!]
∧q = readyqueues(l)
∧q.elts′ = q.elts ⌢⟨p⟩
This is equivalent to:
readyqueues(procs(p).lev).elts′ = elts ⌢⟨p⟩
The mapping readyqueues is a bijection, so its range elements are uniquely
determined by those of its domain.
2
Proposition 57. If a process, p, is of priority l, all other queues are unaf-
fected by the execution of MakeReady[p/pid?].
Proof. In the schema for MakeReady, the important conjunct is:
readyqueues(lv).Enqueue[pid?/x?]
where lv is the priority of the process and pid? its identiﬁer. This expands
into:
readyqueues(lv).elts′ = readyqueues(lv).elts ⌢⟨pid⟩
Since readyqueues is a bijection, readyqueues(lv) uniquely determines elts.
Therefore, only one queue is aﬀected by MakeReady.
2
Proposition 58. If a process, p, is of priority l, all other queues are unaf-
fected by the execution of MakeUnready[p/pid?].
Proof. This follows from the fact that readyqueues is a bijection. The core
is:
q = readyqueues(lv)
∧q.QueueFront[f /x!]
∧((f = pid? ∧q.RemoveFirst[f /x!])
∨(f ̸= pid? ∧q.RemoveElement[f /x?]))
Since readyqueues(lv) is uniquely determined, only one queue can be the re-
sult.
2

140
4 A Swapping Kernel
Proposition 59. runTooLong implements a round-robin r´egime on the user
queue.
Proof. The core is:
∃p : AREF •
readyqueues(userqueue).RemoveFirst[p/x?]o
9
readyqueues(userqueue).Enqueue[p/x?]
This expands into:
∃elts′′ : iseq APREF •
elts′′ = tail elts
∧p = head elts
∧elts′ = elts′′ ⌢⟨p⟩
which simpliﬁes to:
elts′ = (tail elts) ⌢⟨head elts⟩
That is, the ﬁrst element becomes the last. This is exactly the round-robin
scheme.
It has already been established that the queue is uniquely determined by
readyqueues(userqueue).
2
Proposition 60. ScheduleNext ∧allEmptyQueues implies that the idle pro-
cess is the current process; that is, currentp′ = IdleProcRef .
Proof. This is an or-elimination proof, so there are two cases.
Case 1: allEmptyQueues ∧runIdleProcess. By propositional calculus:
p ∧q ⇒q
so allEmptyQueues ⇒runIdleProcess, or (just taking the most relevant com-
ponents):
(∀q : ProcessQueue.q.IsEmpty) ⇒currentp′ = IdleProcRef
by MP, currentp′ = IdleProcRef follows.
Case 2: selectNext.
First, assume that currentp′ ̸= IdleProcRef .
Now, the essential part of ScheduleNext is:
(∃q : ProcessQueue •
q = readyqueues(devprocqueue)
⊗readyqueues(sysprocqueue)
⊗readyqueues(userqueue)
∧(∃p : APREF; l : SCHDLVL; pd : ProcessDescr •
q.QueueFront[p/x!]
∧currentp′ = p))

4.5 The Scheduler
141
This simpliﬁes to:
q = readyqueues(devprocqueue)
⊗readyqueues(sysprocqueue)
⊗readyqueues(userqueue)
∧currentp′ = head q.elts
The fact about queues (and sequences more generally) that:
∀q • q.elts ̸= ⟨⟩⇔∃h • h = head q.elts
can be used to show that q.elts ̸= ⟨⟩because currentp′ = head q.elts. This
contradicts the assumption that allEmptyQueues.
2
Proposition 61. If ¬ allEmptyQueues, then the predicate of ScheduleNext
implies that currentp′ ̸= IdleProcRef .
Proof. Again, this is an or-elimination proof.
Case 1: The property of queue heads:
∀q • q ̸= ⟨⟩⇔∃h • h = head q.elts
⇔∀q • q = ⟨⟩⇔¬ ∃h • h = head q.elts
Assuming that currentp′ ̸= IdleProcRef , q.elts = ⟨⟩. This contradicts the
assumption that ¬ allEmptyQueues. Therefore currentp′ ̸= IdleProcRef .
Case 2: ¬ allEmptyQueues ∧selectNext ⇒currentp′ ̸= IdleProcRef . Using
the property of queues and sequences:
∀q • q ̸= ⟨⟩⇔∃h • h = head q.elts
and applying MP, ¬ allEmptyQueues implies that there is a head of q.elts.
By the deﬁnition of selectNext, currentp′ = head q.elts and currentp′ ̸=
IdleProcRef .
2
Proposition 62. If the device-level queue is not empty, then ScheduleNext
implies that the priority of currentp′ is the device level (i.e., the highest pri-
ority).
Proof. Let dq denote the device process queue, readyqueues(devprocqueue),
let wq denote the other system process queue, readyqueues(sysprocqueue),
and, ﬁnally, let uq denote the queue of user processes, readyqueues(userqueue).
Then, by the deﬁnition of selectNext, the queue from which the next process
is chosen is:
q.elts = dq.elts ⌢sq.elts ⌢uq.elts
By assumption, dq.elts ̸= ⟨⟩. By the existential quantiﬁcation,

142
4 A Swapping Kernel
p = head q.elts
= head(dq.elts ⌢sq.elts ⌢uq.elts)
= head dq.elts since head q = q(1)
= currentp′
The element that is selected from the queue is an element of the device queue,
and so must have the highest (device) priority.
2
Proposition 63. If the device queue is empty and the queue of system pro-
cesses is not empty, ScheduleNext will select a system process as the next value
of currentp.
Proof. This proof is similar to the immediately preceding one. The details,
though, are given.
Using the same abbreviations as in the last proof and expanding the deﬁ-
nition of q, we have:
q.elts = dq.elts ⌢sq.elts ⌢uq.elts
By assumption, sq.elts ̸= ⟨⟩, while dq.elts = ⟨⟩, so:
q.elts
= ⟨⟩⌢sq.elts ⌢uq.elts
= sq.elts ⌢uq.elts (since ⟨⟩⌢q = q, for all q)
Therefore:
head q.elts
= head⟨⟩⌢sq.elts ⌢uq.elts
= head sq.elts ⌢uq.elts (since ⟨⟩⌢q = q)
= head sq.elts since head q = q(1)
= currentp′
Therefore, currentp′ = head sq.elts and currentp′ is bound to a reference to a
system process; that process must have system-process priority (middle pri-
ority).
2
Proposition 64. If both the device queue and the system-process queue are
empty and the user-process queue is not empty, ScheduleNext selects a user
process as the next value of currentp.
Proof. Again, using the same abbreviations as above, the queue from which
the next value of currentp is taken is:
q.elts
= dq.elts ⌢sq.elts ⌢uq.elts
= ⟨⟩⌢⟨⟩⌢uq.elts
= ⟨⟩⌢uq.elts
= uq.elts

4.5 The Scheduler
143
Following the usual reasoning:
head q.elts
= head(dq.elts ⌢sq.elts ⌢uq.elts)
= head(⟨⟩⌢⟨⟩⌢uq.elts)
= head(⟨⟩⌢uq.elts)
= head uq.elts
= currentp′
Therefore, a user process is selected.
2
Proposition 65. If ¬ allEmptyQueues, then ScheduleNext implies that the
highest-priority process is referred to by currentp′.
Proof. By the three immediately preceding propositions, SelectNext assigns
to currentp processes in the order:
1. device processes;
2. system processes;
3. user processes.
This corresponds to the organisation of priorities deﬁned immediately prior
to the deﬁnition of the scheduler.
2
Proposition 66. After ScheduleNext, the current process, currentp, is bound
either to the identiﬁer of the idle process or to the identiﬁer of a process that
resides in one of the three scheduling queues. It is not possible for any other
process identiﬁer to be bound by ScheduleNext to currentp.
Proof. By examination of the predicate of ScheduleNext, there are two cases
to consider.
Case 1: All the process queues are empty (i.e., allEmptyQueues). In this case,
currentp′ = IdleProcRef .
Case 2: At least one of the scheduler’s three queues is not empty. By the
preceding results, currentp′ can only be the head of one of these queues. Fur-
thermore, there is no operation deﬁned by the scheduler for setting the value
of currentp from an external source.
2
Proposition 67. It is always the case that currentp′ after ScheduleNext is
not identical to NullProcRef .
Proof.
The type of currentp is IPREF. The constant NullProcRef is of
type PREF. However, IPREF ⊂IPREF, so NullProcRef is not an element
of IPREF and cannot be bound to currentp without a type-assignment error.

144
4 A Swapping Kernel
2
The basic policy is that the scheduler is called quite frequently, so de-
cisions can change. The current process is, therefore, left on the head of its
queue. When a user-level process has run out of time, it is pre-empted and the
runTooLong method is executed, removing the current head and placing it at
the end (provided, that is, that the user-level queue is not empty). When a
user-level process terminates, it is removed from the queue, in any case. Oth-
erwise, currentp always points to the head of the system or device queue. It is
occasionally necessary to remove these processes. Device processes must end
by waiting on the corresponding device semaphore. System processes either
suspend themselves (by making a call to the self-suspend primitive) or they
wait on a semaphore.
4.6 Storage Management
This kernel performs a certain amount of storage management. The manage-
ment scheme is relatively simple but still more complex than the one employed
in the last chapter (which, the reader will recall, employed a totally static al-
location method).
This section begins with a relatively long series of deﬁnitions. Most of the
deﬁnitions are of axiomatically deﬁned functions. A number of proofs appear
among the deﬁnitions. The reader will note that not all of the functions deﬁned
below are used in the model that follows; some are introduced because they can
be used in an alternative version of this model. Furthermore, some functions
have interesting consequences or properties that are included just for their
interest value.
It is assumed that the store is not inﬁnite in size. The limit is:
memlim : N1
This is assumed to be the maximum address for the storage conﬁguration.
In deﬁning the ADDRESS type, address 0 is omitted (it makes little dif-
ference).
ADDRESS == 1 . . memlim
MEMDESC == ADDRESS × N
The second type is the storage descriptor encountered towards the start of this
chapter. The intention is that an element of MEMDESC describes a region
of store whose address is given by the ﬁrst component and whose size is given
by the second. These memory descriptors are constructed by the following
function:
mkrmemspec : ADDRESS × N →MEMDESC
∀a : ADDRESS; s : N •
mkrmemspec(a, s) = (a, s)

4.6 Storage Management
145
As a pair, there are naturally two selector (projection) functions:
memstart : MEMDESC →ADDRESS
memsize : MEMDESC →ADDRESS
∀r : MEMDESC •
memstart(r) = fst r
memsize(r) = snd r
Of utility are the following:
memend : MEMDESC →ADDRESS
nextblock : MEMDESC →ADDRESS
∀s : MEMDESC •
memend(s) = (memstart(s) + memsize(s))
nextblock(s) = memstart(s) + memsize(s) + 1
Next, it is necessary to deﬁne a type for whatever is stored. The type PSU
is the type of the contents of each cell in the store
[PSU ]
This is the type of the Primary Storage Unit and it can be a word or byte.
We assume a byte.
We can also assume:
NullVal : PSU
The entire store is a sequence of content type, i.e.:
MEM == seq PSU
Below, it will be assumed that each process has one storage area.
As far as processes and the storage manager are concerned, the store is
represented by collections of objects of type MEMDESC.
It is necessary to determine a few properties about storage. More speciﬁ-
cally, we need to know the properties of storage descriptors.
There is the case of overlap.
memsegoverlap : MEMDESC ↔MEMDESC
∀ms1, ms2 : MEMDESC •
memsegoverlap(ms1, ms2) ⇔
(memstart(ms1) ≤memstart(ms2) ∧
nextblock(ms1) ≤nextblock(ms2)) ∨
(memstart(ms1) > memstart(ms2) ∧
nextblock(ms1) ≥nextblock(ms2))
A symmetric version of this predicate can be deﬁned as follows:

146
4 A Swapping Kernel
memsegsymoverlap : MEMDESC ↔MEMDESC
∀ms1, ms2 : MEMDESC •
memsegsymoverlap(ms1, ms2) ⇔
memsegoverlap(ms1, ms2) ∨memsegoverlap(ms2, ms1)
Proposition 68. memsegsymoverlap is symmetric.
Proof. Obvious from the deﬁnition and the fact that p ∨q ⇔q ∨p.
2
It is necessary that all holes be disjoint. This is expressed in the third
conjunct of the invariant.
The following function returns a subsequence of a sequence m, starting at
element oﬀset and running to the end of m (the deﬁnition being taken from
[15]):
after
: seq X × N →seq X
∀m : seq X ; oﬀset : N •
dom(m after oﬀset) = (1 . . #m −oﬀset) ∧
(∀n : N •
(n + oﬀset) ∈dom m ⇒(m after oﬀset)(n) = m(n + oﬀset))
The store is considered to be two sets of segments. The segments used by
processes are, in eﬀect, invisible to the operating system. The segments that
are not used by any processes constitute the free store; free store is represented
by a sequence of zero or more segments described by MEMDESCs. Initially,
the free store consists of exactly one segment: it is the entire store.
For fairly obvious reasons, regions in free store are called “holes”.
lower hole addr : MEMDESC × MEMDESC →ADDRESS
upper hole addr : MEMDESC × MEMDESC →ADDRESS
∀h1, h2 : MEMDESC •
lower hole addr(h1, h2) =

memstart(h1), if memstart(h1) < memstart(h2)
memstart(h2), otherwise
upper hole addr(h1, h2) =

memstart(h1), if memstart(h1) > memstart(h2)
memstart(h2), otherwise
These two functions return the lower of the start addresses of the arguments.
The holes in the free store need to be merged to form larger blocks when
a compaction is performed. The merge function can be deﬁned as:
mergememholes : MEMDESC × MEMDESC →MEMDESC
∀h1, h2 : MEMDESC •
(lower hole addr(h1, h2), upper hole addr(h1, h2))

4.6 Storage Management
147
hole size : MEMDESC →N
∀h : MEMDESC •
hole size(h) = memsize(h)
This function merely returns the size of a hole.
room in hole : MEMDESC →N
room left in hole : N × MEMDESC →N1
∀n : N, h : MEMDESC •
room in hole(n, h) ⇔n ≤hole size(h)
room left in hole(n, h) = hole size(h) −n
The function room in hole returns the size of the hole supplied as its argu-
ment. The second function returns the amount of space left in the hole after
the ﬁrst argument has been removed.
Finally, it is assumed that the store in which allocations are made starts at
some address that is suﬃciently far away from the kernel to avoid problems.
This address is:
startaddr : ADDRESS
The main store is modelled as a description. The class is as follows:
REALMAINSTORE
↾(INIT, RSCanAllocateInStore, RSAllocateFromHole,
MergeAdjacentHoles, FreeMainstoreBlock,
RSFreeMainstore, RSAllocateFromUsed,
RSCopyMainStoreSegment, RSWriteMainStoreSegment,
CreateProcessImage)
mem : seq PSU
holes : seq MEMDESC
usermem : seq MEMDESC
#mem = memlim
#holes ≤memlim
((hole size(holes(1)) = #mem)
∨(i=#holes
i=1
hole size(holes(i)) + j=#usermem
j=1
hole size(usermem(j))
= #mem))
(∀h : MEMDESC | h ∈ran holes •
¬ (∃h1 : MEMDESC | h1 ∈ran holes •
h ̸= h1 ∧memsegsymoverlap(h, h1)))
(∀h : MEMDESC | h ∈ran holes •
¬ (∃m : MEMDESC | m ∈usermem •
memsegsymoverlap(m, h)))

148
4 A Swapping Kernel
INIT
holes′ = ⟨(startmem, memlim)⟩
usermem′ = ⟨⟩
RSCanAllocateInStore = . . .
RSAllocateFromHole = . . .
MergeAdjacentHoles = . . .
FreeMainstoreBlock = . . .
RSFreeMainstore = . . .
RSAllocateFromUsed = . . .
RSCopyMainStoreSegment = . . .
RSWriteMainStoreSegment = . . .
CreateProcessImage = . . .
The class divides the store into two main areas. The ﬁrst is composed of all
the store currently allocated to user processes. This is called usermem in the
class. The second area is the free space, or all the store that is not currently
allocated to processes. The free space is called holes for the reason that there
can be free areas within allocated ones—such areas of unallocated store are
often called “holes”.
The usermem sequence is required only because the store of processes that
are currently swapped out must be able to be recycled for use by other pro-
cesses. This (perhaps extreme) requirement forces the recording of allocated
store. In other kernels, such as those that only allocate once or do not recycle
storage in the same way as this one, it is only necessary to record the descrip-
tors to unallocated store. The descriptors for allocated store are never passed
to user processes: instead, the base address and size of the storage block are
passed instead. This makes descriptor management somewhat easier.
The rather convoluted allocation and recycling approach has been chosen
because it introduces a way of handling store that is implied by much of the
literature but not explicitly described. In a swapping system without virtual
store, how does the storage manager handle store? One simple way is to swap
a process back to the storage area it originally occupied (Minix [30] does this);
this means that one or more processes might need to then be relocated and/or
swapped out. There are clearly other strategies that could be adopted; the
one adopted here was chosen because it does recycle storage and it relocates
processes when they are swapped back into store. It also enables the question
of the integration of heap storage with main storage design. (The strategy
modelled here is distantly related to heap storage methods.) This remains an
open problem, one that is worth some consideration in our opinion.
The mem variable could also be replaced by two variables: one denoting
the start of the available store, the other denoting its size. This would provide

4.6 Storage Management
149
all the information required to check allocations. The mem variable is included
just for those readers who wonder “where” the store to be allocated is.
It should be noted that various operations over holes are also used on
allocated storage chunks. The reason for this is that holes and chunks of user
store are deﬁned in terms of the same mathematical structures. (In any case,
there is a duality: a “hole” is free space inside a region of allocated store and
it can also be a piece of allocated store inside a region of free store.)
The invariant of this class is somewhat complex. It ﬁrst states that memlim
speciﬁes the size of the store and that the limit to the number of holes is the
size of the store itself (in the worst case, all holes will be of unit size). The next
conjunct states that the store is as large as the sum of the sizes of all holes plus
the size of all allocated store. (This is a way of stating that all storage can be
accounted for in this model—memory leaks are not permitted.) Finally, the
two quantiﬁed formulæ state that all holes are disjoint, as are all allocated
regions.
The following schema is used as a predicate. It is true iﬀthere is a hole
of suﬃcient size to satisfy the request for storage. The request requires rqsz?
units for satisfaction.
RSCanAllocateInStore
rqsz? : N
(∃h : MEMDESC | h ∈ran holes •
hole size(h) > 0 ∧
room in hole(rqsz?, h))
Clearly, store can be allocated iﬀthere is a hole of at least the requested
size. The operation RSAllocateFromHole performs storage allocation from free
store. It is expected that allocation from the holes will be the norm. However,
if there is insuﬃcient free store, the storage manager can also reallocate user
storage (using the swapping mechanisms).
The RSAllocateFromHole operation’s deﬁnition naturally falls into two
cases:
1. The chosen hole is exactly of rqsz? units (bytes).
2. The chosen hole is larger than rqsz? units (bytes).
In the ﬁrst case, the hole is removed from the free list (holes) and added to
allocated store (usermem). In the second case, the hole is split into two parts
with the one of rqsz? bytes being transferred to usermem and the remainder
allocated in a new hole in holes.
RSAllocateFromHole
∆(holes, usermem)
rqsz? : N
mspec! : MEMDESC
(∃h : MEMDESC; n : N | n ∈dom holes ∧h = holes(n) •

150
4 A Swapping Kernel
room in hole(rqsz?, h) ∧
((room left in hole(rqsz?, h) = 0 ∧
mspec! = h ∧usermem′ = usermem ⌢⟨mspec!⟩∧
holes′ = holes −▷{h})
∨(room left in hole(rqsz?, h) > 0 ∧
(∃la : ADDRESS; hsz : N •
la = memstart(h) ∧hsz = memsize(h) −rqsz? ∧
mspec! = (la, rqsz?) ∧
usermem′ = usermem ⌢⟨mspec!⟩∧
holes′ = (holes −▷{h})⌢
⟨mkrmemspec(nextblock(mspec!), hsz)⟩))))
Every so often (actually when a used block is freed by a process), the free
store in holes is scanned and adjacent holes merged to form larger ones. This
is deﬁned by the following operation:
MergeAdjacentHoles
∆(holes)
(∀h1, h2 : MEMDESC | h1 ∈ran holes ∧h2 ∈ran holes ∧
(memstart(h1) + memsize(h1) + 1) = memstart(h2) •
holes′ = ((holes −▷{h1}) −▷{h2}) ⌢⟨mergememholes(h1, h2)⟩)
The freeing of an allocated block is achieved by the next operation:
FreeMainstoreBlock
∆(holes, usermem)
start? : ADDRESS
sz? : N
holes′ = holes ⌢⟨mkrmemspec(start?, sz?)⟩
usermem′ = usermem −▷{mkrmemspec(start?, sz?)}
The operation just adds the block (region) to holes (rendering it a free block)
and removes the block from user storage in usermem; this operation is mod-
elled by a range subtraction (−▷).
Proposition 69. FreeMainstoreBlock increases the length of the free list by
1.
Proof.
The free list is called holes in this class. The predicate of schema
FreeMainstoreBlock contains the following identity:
holes′ = holes ⌢⟨mkrmemspec(start?, sz?)⟩
From this, the following calculation establishes the result.

4.6 Storage Management
151
#holes′
= #(holes ⌢⟨mkrmemspec(start?, sz?)⟩)
= #holes + #⟨mkrmemspec(start?, sz?)⟩
= #holes + 1
2
Proposition 70. FreeMainstoreBlock removes one block from user store.
Proof.
The predicate of the schema states that: usermem′ = usermem −▷
{mkrmemspec(start?, sz?)}.
There are two ways (at least) to prove this proposition.
(1) By taking ranges:
ran usermem′ = (ran usermem) \ {mkrmemspec(start?, sz?)}
so:
# ran usermem′ = #((ran usermem) \ {mkrmemspec(start?, sz?)})
= # ran usermem −#{mkrmemspec(start?, sz?)}
= # ran usermem −1
(2) By writing the deletion in the equivalent form,
∃s1, s2 : seq MEMDESC •
usermem = s1 ⌢⟨mkrmemspec(start?, sz?)⟩⌢s2 ∧
usermem′ = s1 ⌢s2
it is clear that:
#usermem
= #s1 + #⟨mkrmemspec(start?, sz?)⟩+ #s2
= #s1 + #s2
= #usermem′
Therefore #usermem′ = #usermem −1.
2
The combined operation that frees an allocated block and merges all ad-
jacent blocks in holes is the following:
RSFreeMainStore = FreeMainstoreBlock o
9 MergeAdjacentHoles
Sometimes, a process will require storage that is already allocated. This
happens, in particular, when holes is empty and a new process is created. In
this case, the resident process is swapped out to disk and its storage reallocated
to the new process. The operation to perform the basic reallocation is as
follows:

152
4 A Swapping Kernel
RSAllocateFromUsed
∆(holes, usermem)
rqsz? : N
n? : N1
start! : ADDRESS
∃h : MEMDESC | h = usermem(n?) •
(room left in hole(rqsz?, h) = 0 ∧start! = memstart(h))
∨(room left in hole(rqsz?, h) ≥0 ∧
start! = memstart(h) ∧
holes′ =
holes ⌢⟨mkrmemspec((start! + rqsz? + 1),
memsize(h) −rqsz?)⟩∧
usermem′(n?) = mkrmemspec(start!, rqsz?)
Again, this operation is deﬁned in terms of two cases: where the hole is of the
exact size and where the hole is of greater size.
The swapping process requires store segments to be written to and read
from disk. The ﬁrst of the next two operations returns a segment of store that
is a copy of the one designated by the pair (start?, end?).
RSCopyMainStoreSegment
start?, end? : ADDRESS
mseg! : MEM
mseg! = (λ i : start? . . end? • mem(i))
The second is an operation that overwrites a segment of store. The overwriting
starts at the location speciﬁed by loadpoint. The input mseg? contains the
piece of store that is to be written to main store.
RSWriteMainStoreSegment
∆(mem)loadpoint? : N
mseg? : MEM
∃size : N | size = #mseg? •
mem′ = (λ i : 1 . . (loadpoint −1) • mem(i))
⌢mseg? ⌢(mem after ((loadpoint + size) −1))
If there is just no space in store, write a new process to disk, setting store
to zero as required.
The following is used to convert an object of type PCODE to a segment
of store. It is a loose deﬁnition (even though, given the equivalences at the
start of this chapter, it could be completed). The function is included so that
the speciﬁcation remains well-typed. (The constructs in the next two chapters
are under-speciﬁed and will not typecheck correctly—more on this in the next
chapter.)

4.6 Storage Management
153
codeToPSUs : PCODE →MEM
The next operation creates the sequence of bytes that will actually be
copied to disk on a swap. It uses codeToPSUs as well as two λ expressions
that operate more as one would ﬁnd in a complete model. (When this schema
is used, that use will be a little incorrect because the extraction of start and
size from data and stack segments is ignored.)
CreateProcessImage
code? : PCODE
stkstrt?, datastrt? : ADDRESS
stksz?, datasz? : N1; image! : MEM
image! = codeToPSUs(code?) ⌢(λ i : datastrt? . . datasz? • 0)⌢
(λ i : stkstrt? . . stksz? • 0)
It is now possible to prove a few propositions about the main store and its
operations.
Proposition 71. RSCanAllocateStore is false iﬀthere are no holes of positive
size.
Proof. By the predicate, hole size(h) > 0 for some hole, h, in ran holes. 2
Proposition 72. Each use of RSAllocateFromHole monotonically decreases
available free storage.
Proof. Assume there have already been allocations. Then, by the invariant:
i=#holes
i=1
hole size(holes(i)) + j=#usermem
j=1
hole size(usermem(j))
= #mem
There are two cases.
Case 1. rqsz? = hole size. Then the number of holes decreases by one. The
sum decreases by the corresponding amount.
Case 2. rqsz? < hole size. The hole is split into two blocks, one of size rqsz?
and the other of size memsize(h) −rqsz?. The size of this new hole is neces-
sarily less than memsize(h). Therefore, the available storage decreases.
2
The following two propositions establish the fact that free store decreases
by the action of RSAllocateFromHole (when it is applicable) and the action
of RSFreeMainstore increases the amount of free store.
Proposition 73. The action of RSAllocateFromHole[k/rqsz?] decreases the
available free store by k units.

154
4 A Swapping Kernel
Proof.
Again, without loss of generality, assume there have already been
allocations. Then, by the invariant:
i=#holes
i=1
hole size(holes(i)) + j=#usermem
j=1
hole size(usermem(j)) = #mem
If k units are allocated from free store, it follows that #mem′ is given by:
i=#holes

i=1
hole size(holes(i)) −k +
j=#usermem

j=1
hole size(usermem(j)) + k =
i=#holes′

i=1
hole size(holes′(i)) +
j=#usermem′

j=1
hole size(usermem′(j))
2
Proposition 74. The action of RSFreeMainstore[k/sz?] increases the avail-
able free store by k units.
Proof. This is the converse of the last proposition.
Again, we use the same conjunct of the invariant:
i=#holes
i=1
hole size(holes(i)) + j=#usermem
j=1
hole size(usermem(j)) = #mem
If k units are returned to free store, it follows that #mem′ is given by:
i=#holes

i=1
hole size(holes(i)) + k +
j=#usermem

j=1
hole size(usermem(j)) −k =
i=#holes′

i=1
hole size(holes′(i)) +
j=#usermem′

j=1
hole size(usermem′(j))
2
Proposition 75. If a hole is exactly the size of a request, it disappears from
the free list.
Proof. The predicate of RSAllocateFromHole states that
room left in hole(rqsz?, h) = 0 ∧
ran usermem′ = ran usermem \ {mspec!}
Since h = mspec!, ran usermem′ = ran usermem\{h}, so h ̸∈ran usermem′. 2
Proposition 76. If a hole is larger than that requested, it is split into two
and the smaller block is returned to the free list.

4.6 Storage Management
155
Proof. The predicate of RSAllocateFromHole states that:
mspec! = (la, rqsz!) ∧
holes′ = (holes −▷{h}) ⌢⟨mkrmemspec(nextblock(mspec!), hsz)⟩
where hsz = memsize(h) −rqsz? and nextblock yields the index of the start
of the next block: nextblock(mkrmemspec(strt, sz)) = strt + sz.
Since hsz is the size of the block added to holes and hsz = memsize(h) −
rqsz? and hsz > 0 (by the predicate), it follows that:
memsize(mkrmemspec(nextblock(mspec!), hsz)) < memsize(h)
2
Proposition 77. If all holes have size < rqsz?, RSAllocateFromHole cannot
allocate any store.
Proof. Let rqsz? = n and let n be larger than the greatest block size. Then
room left in hole(rqsz?, h) < 0 for all h. This falsiﬁes the predicate of the
schema.
2
Proposition 78. If the allocating hole is ≥rqsz?, the hole is split into two
parts: one of size = rqsz?, the other of size, s, s ≥0.
Proof. There are two cases to consider, given RSAllocateFromHole’s predi-
cate:
1. memsize(h) = rqsz?, and mspec is of size rqsz?, so s = 0 (the smaller part
is of zero length);
2. memsize(h) = rqsz? and mspec is of size rqsz?, so memsize(h) −rqsz? is
the size of one part and s > 0 is the size of the other.
2
The next proposition establishes the fact that merging adjacent free blocks
(holes) decreases the number of blocks in free store.
Proposition 79. MergeAdjacentBlocks ⇒# ran holes′ < # ran holes.
Proof. For the purposes of this proposition, the critical line is:
holes′ = [((holes −▷{h1}) −▷{h2}) ⌢⟨mergememholes(h1, h2)⟩]
So:

156
4 A Swapping Kernel
# ran holes′
= # ran[((holes −▷{h1}) −▷{h2}) ⌢⟨mergememholes(h1, h2)⟩]
= # ran((holes −▷{h1}) −▷{h2}) + # ran⟨mergememholes(h1, h2)⟩
= # ran((holes \ {h1}) \ {h2}) + # ran⟨mergememholes(h1, h2)⟩
= # ran((holes \ {h1}) \ {h2}) + 1
= (#(ran holes \ {h1}) −1) + 1
= (#(ran holes) −2) + 1
= # ran holes −1
≤# ran holes
2
If the free blocks are reduced in number, what happens to their size? The
following proposition establishes the fact that the merging of adjacent free
blocks creates a single new block whose size is the sum of all of the merged
blocks.
Proposition 80. If h1 and h2 are adjacent holes in the store of size n1 and
n2, respectively, then MergeAdjacentHoles implies that there exists a hole of
size n1 + n2.
Proof. Since h1 and h2 are adjacent, they can be merged. The deﬁnition of
mergememholes is:
∀h1, h2 : MEMDESC •
(lower hole addr(h1, h2), memsize(h1) + memsize(h2))
The size of the merged hole is therefore memsize(h1) + memsize(h2). Letting
memsize(h1) = n1 and memsize(h2) = n2, it is clear, by the deﬁnition of
mergememholes, that:
memsize(h1) + memsize(h2) = n1 + n2
2
It is clear that we do not want operations on the free store to aﬀect the
store allocated to processes. The following proposition assures us that nothing
happens to user store when adjacent blocks of free store are merged.
Proposition 81. MergeAdjacentHoles leaves user store invariant.
Proof. The predicate does not alter usermem.
2
Proposition 82. If h1 and h2 are adjacent holes and MergeAdjacentHoles is
applied to merge them, then # ran holes′ = # ran holes −1.
Proof. By Proposition 79.
2

4.6 Storage Management
157
Proposition 83. The predicate of schema FreeMainstoreBlock implies that
# ran holes′ > # ran holes and that # ran usermem′ < # ran usermem.
Proof. By the deﬁnition of FreeMainstoreBlock:
holes′ = holes ⌢⟨mkrmemspec(start, sz?)⟩
so:
# ran holes
= # ran(holes ⌢⟨mkrmemspec(start, sz?)⟩)
= # ran holes + # ran(⟨mkrmemspec(start, sz?)⟩)
= # ran holes + 1
and so, # ran holes′ > ran holes.
Now,
# ran usermem′
= # ran(usermem −▷{⟨mkrmemspec(start, sz?)⟩})
= #(ran usermem \ {⟨mkrmemspec(start, sz?)⟩})
= # ran usermem −1
Therefore # ran usermem′ < # ran usermem.
2
Proposition 84. If n calls to the allocator request k units of store, followed
immediately by n calls to RSFreeMainStore, each returning k units of store,
return the store to its original state.
Proof. We need to show that the sizes of usermem and holes are unchanged.
By Proposition 73, the size of the store after the n allocations is:
i=#holes
i=1
hole size(holes(i)) −nk+
j=#usermem
j=1
hole size(usermem(j)) + nk =
i=#holes′′
i=1
hole size(holes′′(i))+
j=#usermem′′
j=1
hole size(usermem′′(j))
while that after the n deallocations is, by Proposition 74:
i=#holes′′
i=1
hole size(holes′′(i)) + nk+
j=#usermem′′
j=1
hole size(usermem′′(j)) −nk =
i=#holes′
i=1
hole size(holes′(i))+
j=#usermem′
j=1
hole size(usermem′(j)) =
i=#holes
i=1
hole size(holes(i))+
j=#usermem
j=1
hole size(usermem(j))
2

158
4 A Swapping Kernel
Proposition 85. #image! = #code + stksz? + datasz?.
Proof.
Note that codeToPSUs is of type PCODE →MEM , so #code =
#codeToPSUs since MEM = seq PSU .
Now
#image! =
#(codeToPSU (code?) ⌢(λ i : 1 . . datasz? • 0) ⌢(λ i : 1 . . stksz? • 0))
= #(codeToPSU (code?) + #(λ i : 1 . . datasz? • 0) + #(λ i : 1 . . stksz? • 0))
= #code + #datasz? + #stksz?
2
The real store on the hardware is represented by a unique instance of
SharedMainStore. This is a store that refers to the real store but whose op-
erations are protected by locks. All that is required is that the operations be
indivisible. The class is deﬁned as follows:
SharedMainStore
↾(INIT, CanAllocateInStore, AllocateFromHole,
AllocateFromUsed, FreeMainStore, CopyMainStore, WriteMainStore)
lms : LINERAMAINSTORE
lck : Lock
INIT
lms.INIT
CanAllocateInStore =
lck.Lock o
9 lms.RSCanAllocateInStore o
9 lms.Unlock
AllocateFromHole =
lck.Lock o
9 RSAllocateFromHole o
9 lck.Unlock
AllocateFromUsed =
lck.Lock o
9 RMAllocateFromUsed o
9 lck.Unlock
FreeMainStore =
lck.Lock o
9 RSFreeMainStore o
9 lck.Unlock
CopyMainStore =
lck.Lock o
9 RSCopyMainStoreSegment o
9 lck.Unlock
WriteMainStore =
lck.Lock o
9 RSWriteMainStoreSegment o
9 lck.Unlock
4.6.1 Swap Disk
This section contains a high-level model of the swap disk. The swap disk is
where swapped process images are stored. It is assumed to be more or less
inﬁnite in size.

4.6 Storage Management
159
Communication with the swap disk is in terms of a buﬀer containing an
operation code. The codes are deﬁned as:
SWAPRQMSG ::= NULLSWAP
|
SWAPOUT⟨⟨PREF × ADDRESS × ADDRESS⟩⟩
|
SWAPIN ⟨⟨PREF × ADDRESS⟩⟩
|
NEWSPROC⟨⟨PREF × MEM ⟩⟩
|
DELSPROC⟨⟨PREF⟩⟩
The NULLSWAP operation is a no-operation: if the opcode is this value, the
swap disk should do nothing. A SWAPOUT code speciﬁes the identiﬁer of the
process whose store is to be swapped out and the start and end addresses of
the segment to be written to disk. A SWAPIN code requests the disk to read
a segment and transfer it to main store. A NEWSPROC speciﬁes that the
store represented by MEM is to be stored on disk and that PREF denotes
a newly created process that cannot be allocated in store at present. Finally,
the DELSPROC code indicates that the named process is to be removed
completely from the disk (it should be removed from the swap disk’s index).
The buﬀer that supplies information to the swap disk is SwapRQBuﬀer.
A semaphore is used to provide synchronisation between the swapper process
and the swap disk process.
The buﬀer is modelled by a class and is deﬁned as follows:
SwapRQBuﬀer
↾(INIT, Write, Read)
mutex, msgsema : Semaphore
buﬀ: SWAPRQMSG
INIT
mt? : Semaphore
ptab? : ProcessTable
sched? : LowLevelScheduler
lck? : Lock
mutex ′ = mt?
(∃iv : Z | iv = 1 •
msgsema′ = Semaphore.Init[iv/iv?, ptab?/pt?,
sched?/sch?, lck?/lk?])
buﬀ′ = NULLSWAP
Write = . . .
Read = . . .
This class has two main operations, one for reading a request buﬀer and one for
writing a reply buﬀer. The buﬀers are protected by semaphores. Semaphores

160
4 A Swapping Kernel
are correct at this level because the code that calls Read and Write is executed
by system processes, not by kernel primitives.
The Write operation is simple and deﬁned as:
Write
∆(buﬀ)
rq? : SWAPRQMSG
msgsema.Wait ∧buﬀ′ = rq? ∧msgsema.Signal
The Read operation is also simple:
Read
rq! : SWAPRQMSG
mutex.Wait
msgsema.Wait
mutex.Signal
rq! = buﬀ
buﬀ′ = NULLSWAP
mutex.Wait
msgsema.Signal
mutex.Signal
Readers should note that the above buﬀer protocol is asymmetric. If a
reader is already reading and a writer is waiting to write, the code will permit
other readers to perform reads before the writer is permitted to write new
data. In this particular case, this is permissible because there is exactly one
reader, the swap-disk driver, and two writers, the swapper and store manager
processes.
The driver process for the swap disk is relatively simple. Its basic tasks
are to store process images and to retrieve them again when required. The
images are indexed by process reference or identiﬁer (APREF). Only “gen-
uine” processes can have their images swapped out, and thus only processes
whose reference is an element of APREF. The image stored on the swap disk
is a copy of a contiguous segment of main store, so the objects stored on the
swap disk are elements of type MEM (sequences of PSU ).
The swap-disk model uses a ﬁnite partial map to represent the disk storage
and index. Two semaphores are used, one to synchronise with the device
driver that passes requests to the disk-controller process and a semaphore to
synchronise with the storage management module. The second semaphore is
used to signal the fact that the transfer has been completed; if this semaphore
were not included, there is the risk that the storage management module
would assume that a transaction had been completed, while, in fact, it had
not.

4.6 Storage Management
161
Requests to the swap disk process are placed in the SwapRQBuﬀer. This
is a piece of shared storage and is guarded by its own semaphore.
The read and write operations are to main store. Main store is, of course,
shared, so locking is used to prevent interrupts from occurring while read and
write operations are under way. It would be natural to assume that, since
this is the only process running at the time reads and writes are performed,
main store would, in eﬀect, belong to this process. However, an interrupt
could cause another process to be resumed and that process might interact
with this one. This is, it must be admitted, a bit unlikely, but it is safer to
use the scheme employed here. The alternative is to guard main store with
a semaphore. This is not an option here because the storage-management
software is implemented as a module, not a process.
The driver uses a semaphore to synchronise with the swapper process
for reading the SwapRQBuﬀer. This is the semaphore called devsema in the
deﬁnition of the class. It also uses a second semaphore, called donesema, which
is used to indicate the fact that the disk read has been completed (the reason
for this will become clear below).
The class that follows is, in fact, a combination of the process that performs
the copy to and from disk and the disk itself. The reason for this is that the
disk image is as important a part of the model as the operations to read and
write the byte sequences and process references.
The swap disk’s driver process is deﬁned as:
SWAPDISKDriverProcess
↾(INIT, RunProcess)
devsema : Semaphore
donesema : Semaphore
dmem : APREF  →MEM
sms : SharedMainStore
rqs : SwapRqBuﬀer
INIT
dsma? : Semaphore
devsemaphore? : Semaphore
rqbuﬀ? : SwapRqBuﬀer
store? : SharedMainStore
donesema′ = dsma?
devsema′ = devsemaphore?
dom dmem′ = ∅
rqs′ = rqbuﬀ?
sms′ = store?

162
4 A Swapping Kernel
writeProcessStoreToDisk = . . .
readProcessStoreFromDisk = . . .
deleteProcessFromDisk = . . .
sleepDriver = . . .
handleRequest = . . .
RunProcess = . . .
Even though this is a system process, the main store is locked when read and
write operations are performed. This is because arbitrary interrupts might
occur when these operations are performed; even though it is controlled by
a semaphore (so processes cannot interfere with any operation inside it), the
body of critical regions is still open to interrupts. The lock is used as an
additional safety measure, even though it is not particularly likely that an
interrupt would interfere with the store in question.
writeProcessStoreToDisk
∆(dmem)
p? : APREF
ms? : MEM
dmem′ = dmem ⊕{p? →ms?}
readProcessStoreFromDisk
p? : APREF
ms! : MEM
ms! = dmem(p?)
deleteProcessFromDisk
∆(dmem)
p? : APREF
dmem′ = {p?} −◁dmem
When the driver is not performing any operations, it waits on its devsema.
The driver is awakened up by a Signal on devsema. When the request has been
handled, the Wait operation is performed to block the driver. This is a safe
and somewhat standard way to suspend a device process.
sleepDriver = devsema.Wait
The remaining operation is the one that handles requests. When the device
process has the semaphore, it reads the data in the request block; in particular,

4.6 Storage Management
163
it examines the operation. The operation requested is used to perform the
appropriate operation. The schema modelling this is:
handleRequest
rq? : SWAPRQMSG
(∃p : APREF; start, end : ADDRESS; mem : MEM •
rq? = SWAPOUT⟨⟨p, start, end⟩⟩
∧sms.CopyMainStore[start/start?, end/end?, mem/mseg!]
∧writeProcessStoreToDisk[p/p?, mem/ms?])
∨(∃p : APREF; ldpt : ADDRESS; mem : MEM •
rq? = SWAPIN ⟨⟨p, ldpt⟩⟩
∧readProcessStoreFromDisk[p/p?, mem/ms!]
∧sms.WriteMainStore[ldpt/loadpoint?, mem/mseg?]
∧donesema.Signal)
∨(∃p : APREF •
rq? = DELSPROC⟨⟨p⟩⟩∧deleteProcessFromDisk[p/p?])
∨(∃p : APREF; img : MEM •
rq? = NEWSPROC⟨⟨p, img⟩⟩
∧writeProcessStoreToDisk[p/p?, img/img?])
The semaphore, donesema, is used to synchronise with the swapper process
directly. It is used to ensure that the write request has completed before the
swapper process updates the storage tables associated with the process that
is being swapped. This is to ensure consistency.
The main loop for the swap disk process is as follows. The reader should
note the ad hoc use of a universal quantiﬁer to model an inﬁnite loop:
RunProcess =
∀i : 1 . . ∞•
sleepDriver o
9
(∃rq : SWAPRQMSG •
rqs.ReadRequest[rq/rq!]
∧(rq = NULLSWAP ∧sleepDriver)
∨(handleRequest ∧sleepDriver))
Proposition 86. p? ̸∈dom dmem and dmem′ = dmem = ⊕{p? →ms?}
implies that p? ∈dom dmem′. In addition, if p? ∈dom dmem and dmem′ =
dmem ⊕{p? →ms?}, this implies that p? ∈dom dmem′.
Proof.
Both parts are a consequence of the deﬁnition of ⊕: f ⊕g(x) =
g(x) if x ∈dom g and f (x) otherwise.
2
4.6.2 Swapper
This subsection is about the process swapper. In fact, the swapper is better
described as a storage-management module. The software is a module because

164
4 A Swapping Kernel
it implements a set of tables describing the state of each user process’ storage.
In particular, the module contains tables recording the identiﬁers of those pro-
cesses that are currently swapped out to disk (swapped out) and the time that
each process has spent out of main store on the swap disk (swappedout time).
Swapping, in this kernel, is based on the time processes have spent swapped
out, so these two tables are of particular importance. However, the time a
process has been resident in main store is signiﬁcant and is used to determine
which process to swap out when its store is required to hold a process that
is being swapped in from disk. The time each process resides in main store is
recorded in the residency time table.
The operations on the class ProcessStorageDescr are composed of struc-
tures that record the time each (user) process has resided in main store and
the time it has resided on disk. Marking operations are also provided so that
the system can keep track of which processes are in store and which are not.
The remaining operations are concerned with housekeeping and which deter-
mining which processes to swap in and out of main store.
It was decided (somewhat unfairly) that main-store residency time would
include the time processes spend in queues of various sorts. This has the
unfortunate consequence that a process could be swapped in, immediately
make a device request and block; as soon as the request is serviced and the
process is readied, it is swapped out again. However, other schemes are very
much more complicated to model and therefore to implement.
The class is deﬁned as follows:
ProcessStorageDescrs
↾(INIT, MakeInStoreProcessSwappable, MakeProcessOnDiskSwappable,
UpdateAllStorageTimes, MarkAsSwappedOut, MarkAsInStore,
ClearProcessResidencyTime,
ClearSwappedOutTime, IsSwappedOut, SetProcessStartResidencyTime,
SetProcessStartSwappedOutTime, UpdateProcessStoreInfo,
RemoveProcessStoreInfo,
AddProcessStoreInfo,
ProcessStoreSize, ReadyProcessChildren,
CodeOwnerSwappedIn, ReadyProcessChildren, NextProcessToSwapIn,
BlockProcessChildren, HaveSwapoutCandidate, FindSwapoutCandidate)
proctab : ProcessTable
sched : LowLevelScheduler
swapped out : F APREF
residencytime : APREF  →TIME
swappedout time : APREF  →TIME
swapped out ⊆dom pmem ∧swapped out ⊆dom pmemsize
dom swappedout time = swapped out
dom residencytime ∩swapped out = ∅

4.6 Storage Management
165
INIT
pt? : ProcessTable
sch? : LowLevelScheduler
proctab′ = pt? ∧sched ′ = sch?
swapped out′ = ∅∧dom residencytime′ = ∅
dom swappedout time′ = ∅
MakeInStoreProcessSwappable = . . .
MakeProcessOnDiskSwappable = . . .
UpdateAllStorageTimes = . . .
MarkAsSwappedOut = . . .
MarkAsInStore = . . .
ClearProcessResidencyTime = . . .
ClearSwappedOutTime = . . .
IsSwappedOut = . . .
SetProcessStartResidencyTime = . . .
SetProcessStartSwappedOutTime = . . .
AddProcessStoreInfo = . . .
UpdateProcessStoreInfo = . . .
RemoveProcessStoreInfo = . . .
ProcessStoreSize = . . .
CodeOwnerSwappedIn = . . .
BlockProcessChildren = . . .
ReadyProcessChildren = . . .
NextProcessToSwapIn = . . .
HaveSwapoutCandidate = . . .
FindSwapoutCandidate = . . .
As can be seen, the class has a rather large number of operations.
The following schema deﬁnes the operation that makes a process swap-
pable. It does this by setting its main-store residency time to 0.
MakeInStoreProcessSwappable
pid? : APREF
residencytime′ = residencytime ⊕{pid? →0}
Processes can be created on disk when there is insuﬃcient main store avail-
able. As user processes, they can be made swappable. The following operation

166
4 A Swapping Kernel
does this. It just sets the swapped-out time to 0 and adds the process reference
to the set of swapped-out processes.
MakeProcessOnDiskSwappable
pid? : AREF
swappedout time′ = swappedout time ⊕{pid? →0}
swapped out′ = swapped out ∪{pid?}
The management module interacts with the clock. On every clock tick,
the time that each process has been main-store and swap-disk resident is
incremented by one tick (actually by the amount of time represented by a
single tick). The following schema deﬁnes this operation:
UpdateAllStorageTimes
∆(swappedout time, residencytime)
(∀p : APREF | p ∈dom residencytime •
residencytime′ = residencytime ⊕{p →residencytime(p) + 1})
(∀p : APREF | p ∈dom swappedout time •
swappedout time′ = swappedout time⊕
{p →swappedout time(p) + 1})
When a process is swapped out to disk, it must be marked as being no
longer in main store. The following schema deﬁnes this operation:
MarkAsSwappedOut
∆(swapped out)
p? : APREF
swapped out′ = swapped out ∪{p?}
Conversely, when a process is copied into main store, the management
software needs to make a record of this fact. The operation MarkAsInStore
performs this marking and is deﬁned as:
MarkAsInStore
∆(swapped out)
p? : APREF
swapped out′ = swapped out \ {p?}
Note that the marking is modelled as a simple set operation. The assumption
is that a process that is not marked as swapped out is resident in main store.
When a process enters main store, or terminates, its residency time has to
be cleared:

4.6 Storage Management
167
ClearProcessResidencyTime
∆(residencytime)
p? : APREF
residencytime′ = residencytime ⊕{p? →0}
Similarly, when a process is swapped out, or terminates, the time that it
has spent on disk has to be set to zero:
ClearSwappedOutTime
∆(swappedout time)
p? : APREF
swappedout time′ = swappedout time ⊕{p? →0}
The following pair of schemata deﬁne operations to set the start times for
main-store and swap-disk residency. The idea is that the actual time is set,
rather than some number of clock ticks.
SetProcessStartResidencyTime
∆(residencytime)
p? : APREF
t? : TIME
residencytime′ = residencytime ⊕{p? →t?}
SetProcessStartSwappedOutTime
∆(swappedout time)
p? : APREF
t? : TIME
swappedout time′ = swappedout time ⊕{p? →t?}
The following predicate is used to determine whether a process is on disk.
IsSwappedOut
p? : APREF
p? ∈swapped out
When a process is created, entries in the storage-management tables must
be created. The storage descriptor describing the process’ main-store region
is set in the process’ descriptor.
AddProcessStoreInfo =
(∃pd : ProcessDescr •
proctab.DescrOfProcess[p?/pid?, pd/pd!]
∧pd.SetStoreDescr[mdesc?/newmem?])

168
4 A Swapping Kernel
The following operation updates the storage descriptor should a process
be relocated when swapped into main store. The storage descriptor input to
this operation (mdesc?) need not be the same as the one already stored. This
is because the swap-in operation stores the process image in the ﬁrst available
hole in main store that is of suﬃcient size.
UpdateProcessStoreInfo =
(∃pd : ProcessDescr •
proctab.DescrOfProcess[p?/pid?, pd/pd!]
pd.SetStoreDescr[mdesc?/newmem?])
The following operation removes a process from the storage-management
module’s tables. It also removes the storage descriptor from the process’ de-
scriptor in the process table.
RemoveProcessStoreInfo
∆(residencytime, swappedout time)
p? : APREF
residencytime′ = {p?} −◁residencytime
swappedout time′ = {p?} −◁swappedout time
(∃md : MEMDESC; pd : ProcessDescr •
md = (0, 0)
∧proctab.DescrOfProcess[p?/pid?, pd/pd!]
∧pd.SetStoreDescr[md/newmem?])
The next schema deﬁnes an operation that computes the size of the storage
occupied by a process:
ProcessStoreSize =
(∃pd : ProcessDescr •
proctab.DescrOfProcess[p?/pid?, pd/pd!]
pd.StoreSize)
The next few schemata operate on the children of a process. When a pro-
cess blocks, its children, according to this process model, must also be blocked.
The reason for this is that the children of a process share its code. Child pro-
cesses do not copy their parent’s code and become a totally independent unit.
The reason for this is clear: if child processes were to copy their parent’s code,
the demand upon store would increase and this would decrease the number
of processes that could be maintained in main store at any one time. The
advantage to independent storage of code is that processes can be swapped
out more easily. However, the consumption of main store is considered, in this
design at least, to be more important than the ease of swapping. Therefore,
the swapping rules for this kernel are somewhat more complex than for some
other possible designs.
The process model (such as it is) for this kernel is somewhat similar to
that used by Unix: processes can create child processes (and child processes

4.6 Storage Management
169
can create child processes up to some limit on depth3. Child processes share
their parent’s code but have their own private stack and data storage. When
a parent is swapped out, its code is also swapped out (which makes an already
complex swapping mechanism a little simpler). Because the parent process’
code is swapped out, child processes have no code to execute. It is, therefore,
necessary to unready the children of a swapped-out parent. The following
schema deﬁnes this operation.
The schema named BlockProcessChildren blocks the descendant processes
of a given parent. The complete set of descendants is represented by the
transitive closure of the childof relation; the complete set of descendants of
a given process are represented by childof +(| {p?} |) for any process identiﬁer
p?. In BlockProcessChildren, ps is the set of descendants of p? (should they
exist). The operation then adds the processes in ps to the blockswaiting set
(which is used to denote those processes that are blocked because the code
they execute has been swapped out); and it sets their status to pstwaiting.
BlockProcessChildren
p? : APREF
∃ps, oﬀspring : F APREF; pd : ProcessDescr •
proctab.DescrOfProcess[p?/pid?, pd/pd!]
∧proctab.AllDescendants[p?/parent, oﬀspring/descs!]
∧pd.BlocksProcesses[ps/bw!]
∧(∀p : APREF | p ∈ps ∪oﬀspring •
(∃pd1 : ProcessDescr •
proctab.DescrOfProcess[p/pid?, pd1/pd!]
∧pd1.SetProcessStatusToWaiting)
∧sched.MakeUnready[p/pid?])
The schema could be simpliﬁed.
When a parent is returned to main store, its children can be readied (i.e.,
added to the ready queue). The following schema deﬁnes this operation in a
fairly obvious fashion.
First, the identiﬁers of all processes that become blocked when the pro-
cess denoted by parent? is blocked are determined by pd.BlocksProcesses.
Next, identiﬁers of all the descendants of the process are determined by
AlDescendants. Next, each of the identiﬁers in the union of these two sets
is marked as being present in store and then added to the ready queue so that
it can be scheduled.
3 The actual limit is imposed by the maximum number of entries in the process
table. This fact is a clear problem for a kernel’s security: a malicious process could
deliberately create child processes.

170
4 A Swapping Kernel
ReadyProcessChildren
∆(swapped out)
parent? : APREF
∃pd : ProcessDescr; bw, oﬀspring : F APREF •
proctab.DescrOfProcess[parent?/pid?, pd/pd!]
∧pd.BlocksProcesses[bw/bw!]
∧proctab.AllDescendants[oﬀspring/descs!]
∧(∀c : APREF | c ∈bw ∪oﬀspring •
(∃cdesc : ProcessDescr •
proctab.DescrOfProcess[c/pid?, cdesc/pd!]
∧MarkAsInStore[c/p?] ∧sched.MakeReady[c/pid?]))
What if a child is waiting for a device request completion? It cannot sud-
denly be stopped. A quick and totally horrid solution is to require that all
children be in the ready queue when the swap occurs.
The reader is invited to ﬁnd better alternatives and to specify them in an
appropriate notation.
Proposition 87. For any parent process, p,
BlockProcessChildren ⇒(∀p1 : APREF | childof (p1, p) • p ̸∈ran userqueue)
Proof.
The predicate of BlockProcessChildren contains an instance of
MakeUnready inside the scope of the universal quantiﬁer. The universal
quantiﬁer ranges over all possible descendants of input process p?. Since
MakeUnready removes its argument from the ready queue, the result is proved.
2
Proposition 88. If there are n processes in the ready queue at the user level
and process ϕ has p descendants, then after BlockProcessChildren, the length
of the user-level queue will be n −1.
Proof. Without loss of generality, it can be assumed that all descendants of
process ϕ, and all processes that it blocks, have user-level priority. Let blocks =
ps ∪oﬀspring and #blocks = p. By the predicate of the schema, it follows
that ∀p ∈blocks • MakeUnready[p/pid?], so there must be p applications of
MakeUnready to blocks. By Proposition 53:
#readyqueues′(userqueue) = #readyqueues(userqueue) −p
2
Proposition 89. If there are n processes in the ready queue at the user level
and process ϕ has p descendants, then after ReadyProcessChildren, the length
of the user-level queue will be n + p.

4.6 Storage Management
171
Proof. Again, without loss of generality, it can be assumed that all descen-
dants of process ϕ, and all processes that it blocks, have user-level priority.
Again, let blocks = bw ∪oﬀspring and let #blocks = p. By reasoning similar
to that in the last proposition:
#readyqueues′(userqueue) = #readyqueues(userqueue) + p
2
The following is an immediate consequence of the last proposition.
Corollary 7. Operation ReadyProcessChildren changes the state of all pro-
cesses aﬀected by it to pstready.
Proposition 90. BlockProcessChildren o
9 ScheduleNext implies that currentp′
is not a descendant of the ancestor of the process just blocked.
Proof. This requires the proof of the following lemma.
Lemma 16. For any process, p, BlockProcessChildren implies that there are
no children of p in the ready queue after the operation completes.
Proof. In the predicate of schema BlockProcessChildren, ps represents the
descendants of process p. From this, using the predicate, it can be seen that
MakeUnready[p/pid?] for all p ∈ps implies p ̸∈ran userqueue. In other
words, the process, p, is removed from the ready queue by the operation
MakeUnready. Therefore, there are no children of p in the ready queue.
2
By Lemma 16, no child of p can be in the ready queue. More speciﬁcally,
that head(tail userqueue) cannot be a child of p. This establishes the desired
result.
2
The following schema deﬁnes a predicate that is true when a process that
owns its code is swapped into main store. Code owners are either independent
processes or are parents.
CodeOwnerSwappedIn
p? : APREF
(∃p1 : APREF; pd : ProcessDescr •
proctab.DescrOfProcess[p1/pid?, pd/pd!]
∧(pd.SharesCodeWith[p1/pid?]
∨pd.HasChild[p1/ch?])
∧pd.IsCodeOwner
∧p1 ̸∈swapped out)
The next schema is another predicate. This time, it is one that determines
which process next to swap into main store. The candidate is the process that

172
4 A Swapping Kernel
has been swapped out for the longest time. The identiﬁer of the process (pid!),
together with the amount of store it requires (sz!), is returned.
NextProcessToSwapIn
pid! : APREF
sz! : N
(∃p : APREF | p ∈swapped out •
swappedout time(p) = max(ran swappedout time) ∧
pid! = p ∧
sz! = pmemsize(p))
Only user processes in the ready state can be swapped out. It is essential
that this condition be recorded in the model. Instead of stating it directly, a
less direct way is preferred. It is expressed by the following constant deﬁnition:
illegalswapstatus : PROCSTATUS
illegalswapstatus = {pstrunning, pstwaiting, pstswappedout,
pstnew, pstterm, pstzombie}
Again, the following schema deﬁnes a predicate. This predicate is true
when the storage-management module has a candidate process to swap out
to disk.
HaveSwapoutCandidate
rqsz? : N
(∃pd : ProcessDescr; st : PROCSTATUS; k : PROCESSKIND; sz : N;
tm : TIME; tms : F TIME •
proctab.DescrOfProcess[p1/pid?, pd/pd!]
∧pd.ProcessKind[k/knd!] ∧k ̸= ptsysproc ∧k ̸= ptdevproc
∧pd.ProcessStatus[st/st!] ∧st ̸∈illegalswapstatus
∧pd.StoreSize[sz/memsz!] ∧sz ≥rqsz?
∧pdescrs.ResidencyTime[tm/tm!] ∧pdescrs.AllResidencyTimes[tms/tms!]
∧tm = max tms
The swapout candidate is a user process that is in the ready queue (illegalstatus
is a set of state names that excludes pstready). The amount of store the can-
didate occupies must be at least the same as that requested for the incoming
process (this is represented by rqsz?). The candidate must also have the great-
est main-store residency time. System and device processes do not appear in
any of the storage-management tables, so it is not possible for an attempt to
be made to swap one of them out.

4.6 Storage Management
173
The candidate process to be swapped out is located by the following op-
eration. It is, again, fairly straightforward. It locates a process that is not in
one of the “banned” states deﬁned by illegalswapstatus. The process must not
be a device or system process; that is, it must be a user process. The victim
process must also occupy a storage region whose size is at least that required
(rqsz?) to ﬁt the incoming process.
FindSwapoutCandidate
p? : APREF
cand! : APREF
rqsz? : N
slot! : MEMDESC
(∃p : APREF; t : TIME | residencytime(p) = t •
p ̸= p? ∧
pstatus(p) ̸∈illegalswapstatus ∧
pkind(p) ̸= ptsysproc ∧
pkind(p) ̸= ptdevproc ∧
pmemsize(p) ≥rqsz? ∧
(∀p1 : APREF •
(p1 ̸= p ∧p1 ̸= p?
∧p1 ∈dom residencytime ∧t ≥residencytime(p1))
⇒p = cand! ∧pmem(p) = slot!))
A proposition can now be proved about the priority of swap-out candi-
dates.
Proposition 91. Only user-level processes that are ready to run can be
swapped out.
Proof.
By the predicate of HaveSwapoutCandidate, the kind of process is
k, and k ̸= sysproc ∧k ̸= devproc implies that k = userproc, so the process is
at the user level. By the condition that st ̸∈illegalswapstatus, and
illegalswapstatus = {pstrunning, pstwaiting, pstswappedout, pstnew, pstterm}
it follows that the process can only be in the ready state (pstready).
2
4.6.3 Clock Process
The clock process is an extremely important component of the system. As
has been seen, the clock is used to pre-empt user-level processes. In addition,
processes of all kinds can use the clock to suspend themselves for a speciﬁed
period of time; when that time has expired, the processes receive an “alarm”
call which wakes them up and places them on the ready queue. This ﬁrst
organisation for the clock process is shown in Figure 4.2.

174
4 A Swapping Kernel
Clock
Process
Alarms
etc.
Processes waiting 
for alarms
Clock
ISR
H/W Clock 
Signal
 Signal
Fig. 4.2. The clock process in relation to its interrupt and alarm requests.
ticklength : TIME
GenericISR
↾(INIT,
OnInterrupt,
AfterProcessingInterrupt,
WakeDriver)
hw : HardwareRegisters
ptab : ProcessTable
driversema : Semaphore
sched : LowLevelScheduler
INIT
sema? : Semaphore
schd? : LowLevelScheduler
hwregs? : HardwareRegisters
proctb? : ProcessTable
ptab′ = proctb?driversema′ = sema?
hw ′ = hwregs?
sched ′ = schd?
OnInterrupt = . . .
AfterProcessingInterrupt = . . .
WakeDriver = . . .
saveState = . . .
restoreState = . . .

4.6 Storage Management
175
WakeDriver
driversema.Signal
When an interrupt occurs, SaveState is called to save the state. The schema
deﬁnes an operation that retrieves the current process’ descriptor from the
process table. Then, the contents of the hardware’s general registers are copied
from the hardware, as are the contents of the stack register, the instruction
pointer and the status word. The time quantum value is also copied and the
values set in the appropriate slots in the process descriptor.
The reader should note that there is a slight ﬁction in the saveState op-
eration. It concerns the instruction pointer. Clearly, as saveState executes,
the IP register will point to instructions in saveState, not in the code of the
current process (the process pointed to by currentp). The saveState operation
is called from ISRs. This implies that an interrupt has occurred and that the
hardware state has already been stored somewhere (certainly, the instruction
pointer must have been stored somewhere so that the ISR could execute). Be-
cause this model is at a relatively high level and because we are not assuming
any speciﬁc hardware, we can only assume that operations such as GetGPRegs
and GetIP can retrieve the general-purpose and instruction registers’ contents
from somewhere.
What has been done in the model is to abstract from all hardware. The
necessary operations have been provided, even though we are unable to deﬁne
anything other than the name and signature of the operations at this stage.
(In a reﬁnement, these issues would, of necessity, be confronted and resolved.)
Once saveState has terminated, device-speciﬁc code is executed. Finally,
the operation to restore the hardware state is called to perform a context
switch.
The ﬁrst part of the context switch is performed by saveState. This opera-
tion copies the hardware state, as represented by the programmable registers,
the instruction pointer and the status word, as well as the variable contain-
ing the process’ time quantum. (Non-user processes just have an arbitrary
value stored.) The state information is then copied into the outgoing process’
process descriptor.
saveState
(∃cp : IPREF •
sched.CurrentProcess[cp/cp!]
(∃pd : ProcessDescr •
ptab.DescrOfProcess[cp/pid?, pd/pd!]
∧(∃regs : GENREGSET; stk : PSTACK; ip : N;
stat : STATUSWD; tq : TIME •
hw.GetGPRegs[regs/regs!]
∧hw.GetStackReg[stk/stk!]
∧hw.GetIP[ip/ip!]

176
4 A Swapping Kernel
∧hw.GetStatWd[stat/stwd!]
∧sched.GetTimeQuantum[tq/tquant!]
∧pd.SetFullContext
[regs/pregs?, ip/pip?, stat/pstatwd?,
stk/pstack?, tq/ptq?])))
The current process referred to here is not necessarily the same as the one
referred to above. Basically, whatever is in currentp runs next. The reason for
this is that the scheduler might be called by the device-speciﬁc code that is
not deﬁned here.
The code supplied for each speciﬁc device should be as short as possible.
It is a general principle that ISRs should be as fast as possible, preferably just
handing data to the associated driver process.
Once the device-speciﬁc code has been run, the state is restored. As noted
above, the actual state might be that of a process diﬀerent from the one bound
to currentp when saveState executed. This is because the low-level scheduler
might have been called and currentp’s contents replaced by another value. The
operation for restoring state (of whatever process) is deﬁned by the following
schema:
restoreState
(∃cp : IPREF •
sched.CurrentProcess[cp/cp!]
∧(∃pd : ProcessDescr •
ptab.DescrOfProcess[cp/pid?, pd/pd!]
∧(∃regs : GENREGSET; stk : PSTACK;
ip : N; stat : STATUSWD; tq : TIME •
pd.FullContext[regs/pregs!, ip/pip!, stat/pstatwd!,
stk/pstack!, tq/ptq!]
∧hw.SetGPRegs[regs/regs?]
∧hw.SetStackReg[stk/stk?]
∧hw.SetStatWd[stat/stwd?]
∧sched.SetTimeQuantum[tq/tquant?]
∧hw.SetIP[ip/ip?])))
In this case, the various registers are all stored in known locations inside the
kernel (in the descriptor of the process that is to run next). The transfers are
moves to the hardware’s registers. The instruction pointer is the last to be set
(for obvious reasons).
These are the generic interrupt service routines. The ﬁrst is called before
performing the interrupt-speciﬁc operations:

4.6 Storage Management
177
OnInterrupt =
(saveStateo
9
(∃p : IPREF •
sched.CurrentProcess[p/cp!] ∧sched.MakeReady[p/pid?]))
o
9WakeDriver
The second operation is called when the ISR is about to terminate:
AfterProcessingInterrupt =
(sched.ScheduleNext o
9 restoreState)
It is assumed that the clock interrupt does just that—raise an interrupt. A
shared variable, encapsulated in TimeNow, stores the current time. The actual
value passed to TimeNow is the length of one tick (expressed in arbitrary
units here). The shared variable is only updated by CLOCKISR, so there is
no contention problem because all other accesses are reads that are protected
by locking. The update of the clock is atomic because it is performed within
an ISR; the reads are also atomic because they are performed inside locks.
This mechanism is quite suﬃcient.
The clock’s ISR now follows, presented as a class. Note that it notionally
inherits methods from a GenericISR.
CLOCKISR
↾(INIT, ServiceISR)
GenericISR
zsema : Semaphore
tmnow : TimeNow
INIT
tn? : TimeNow
zs? : Semaphore
tmnow ′ = tn?
zsema′ = zs?
setTime =
(∃tn : TIME | tn = ticklength •
tmnow.SetTime[tn/t?])
ServiceISR =
OnInterrupt o
9
setTime
∧zsema.Signal
o
9AfterProcessingInterrupt

178
4 A Swapping Kernel
The ISR uses a semaphore to wake the driver when an interrupt occurs. It is
assumed that the semaphore is initialised by some kernel start-up operation
before it is passed to the ISR. The main operation of the ISR is ServiceISR.
This is the TimeNow shared variable. It has two operations: SetTime and
CurrentTime. The CurrentTime operation retrieves the current value of the
time now variable.
TimeNow
↾(INIT, SetTime, CurrentTime)
time now : TIME
INIT
sttm? : TIME
time now ′ = sttm?
SetTime
∆(time now)
t? : TIME
time now ′ = t? + time now
CurrentTime
t! : TIME
t! = time now
The process that removes zombies is now speciﬁed so that it is out of the
way. It is encapsulated as a class, as follows:
DeZombiﬁer
↾(INIT, RunProcess)
zsema : Semaphore
lck : Lock
proctab : ProcessTable
INIT
zs? : Semaphore
lk? : Lock
pt? : ProcessTable
zsema′ = zs?
lck ′ = lk?
proctab′ = pt?

4.6 Storage Management
179
RunProcess =
∀i : 1 . . ∞•
zsema.Wait o
9
lck.Lock o
9
((proctab.GotZombies ∧proctab.KillAllZombies ∧lck.Unlock)
∨lck.Unlock)
The main entry point, RunProcess, is readied by the zsema.Wait opera-
tion, as is standard for this kind of process (it counts as a driver process).
The main routine then disables interrupts with a lck.Lock. Next, it deter-
mines whether there are any zombies (proctab.GotZombies); if there are, it
kills them and unlocks. Otherwise, there are no zombies, so interrupts are
re-enabled (lck.Unlock on the last line).
Immediately, a couple of results can be proved about the de-zombiﬁer.
Lemma 17. Operation KillAllZombies removes all zombies from the system.
Proof.
Zombies are only stored in the zombies list. The KillAllZombies
operation is deﬁned as the conjunction of two operations. The crucial parts
of the deﬁnition (after simpliﬁcation and substitution) are:
deadzombs! ⊆zombies
∧zombies′ = zombies \ deadzombs!
∧procs′ = deadzombies! −◁procs
where deadzombs! is a set composed of the identiﬁers of those zombies whose
children have all been deleted from the process table.
2
Proposition 92. DeZombiﬁer.RunProcess removes all childless zombies from
the system if any exist.
Proof. If there are any such zombies, the KillAllZombies operation is exe-
cuted. The result follows from Lemma 17 that KillAllZombies removes zombies
from everything except the scheduling queues and the process table, and from
Proposition 14 (DelProcess removes a process from the process table).
2
The clock and alarms raise an interesting question: how do user programs
communicate with the kernel. A way of performing system calls must be de-
ﬁned. Immediately, there are two alternatives:
•
a semaphore to ensure mutual exclusion between user processes, ;
•
an interrupt.

180
4 A Swapping Kernel
The ﬁrst alternative requires that all user processes signal on a semaphore
when they are required to perform an SVC (system call). When inside the
critical region, the user process can call system-interface functions.
The second alternative is to use an interrupt. In this case, an interrupt not
expected to be used by hardware is reserved. When a user process needs to
perform an SVC, it calls an interface routine that raises that interrupt. The
user process passes parameters to the SVC either on its stack or in predeﬁned
locations (both pose problems of crossing address-space boundaries but the
stack option generally appears the better). The parameters must include an
operation code denoting the operation to be performed. ISR picks up the
SVC’s parameters and opcode, places them in appropriate locations within
the kernel and then wakes a driver process. At this point, there are choices to
be made.
The ﬁrst option is for the SVC ISR to wake up a special driver and pass all
the parameters to it. The driver then passes the opcode and associated data to
the necessary processes (e.g., allocate store, add a request to the clock’s alarm
queue, or, in bulkier kernels, perform an I/O request); should the operation
not involve a kernel process, the driver performs the operation directly. The
ISR must unready the calling process and pass its identiﬁer to the driver
process which readies it again after the request has been serviced. The ISR
wakes up the driver using a Signal operation on a semaphore they share. It
also unreadies the calling process by a call to MakeUnready (the driver will
ready it at a later time).
The second option is for the SVC ISR to perform as many of the requests
itself as it possibly can. This means that the ISR has to inspect the opcode to
determine what to do. For example, if the SVC is to request a period of sleep,
it will add the identiﬁer of the calling process (always currentp), together with
the requested sleep period, to the alarm queue in the clock driver.
The second alternative appears attractive but suﬀers from some problems.
First, it might easily violate the principle that ISRs do only as much as they
absolutely must—ISRs should be as fast as possible. Second, it could entail
signiﬁcant periods during which interrupts are disabled—this is clearly not a
good idea. Third, the operation of the SVC ISR might interfere with other
interrupts (e.g., the system clock).
For these reasons, the ﬁrst alternative is adopted here. The ISR has a
structure roughly as follows:
SVCISR
↾(INIT, HandleSVC)
GenericISR

4.6 Storage Management
181
proctab : ProcessTable
sched : LowLevelScheduler
ctxt : Context
alarmrqs : AlarmRQBuﬀer
. . .
INIT
. . .
HandleSVC = . . . . . .
The SVC ISR must place clock-related requests in a buﬀer. To this end,
it needs to inspect the opcode associated with each SVC. The following is a
fragment of the speciﬁcation of the ISR:
HandleSVC
opcode? : N
params? :
∃cp : IPREF •
sched.CurrentProcess[cp/cp!] ∧ctxt.SaveStateo
9
(sched.MakeUnready[currentp/pid?]
∧(∃pd : ProcessDescr •
proctab.DescrOfProcess[cp/pid?, pd/pd!]
∧pd.SetProcessStatusToWaiting) ∧. . .)
∨(∃tm : TIME •
opcode? = SLEEP⟨⟨tm⟩⟩
∧alarmrqs.AddAlarm[cp/p?, tm/t?] ∧WakeDriver)
sched.ScheduleNext o
9 ctxt.RestoreState
In this system, the user can request to sleep for a period, denoted
SLEEP⟨⟨tm⟩⟩above, where tm denotes the period of sleep. The handler sets
the sleep period and the process identiﬁer of the caller in the request buﬀer
using AddAlarm. The current process is the caller (it is the process that raised
the interrupt) and the period of sleep is speciﬁed as a parameter to the SVC
(passed on the stack or in another known location).
It should be noted that the type used to represent requests (of which
SLEEP is one component) is omitted. The reason for this is that the remainder
of the range of SVCs is only partially deﬁned in this chapter.
The request buﬀer is just a shared variable. There is no need for the request
buﬀer to be protected by a semaphore because, as noted above, the only writer
of requests is the SVC ISR. The alarm buﬀer also contains a variable denoting
the current time. This variable is also updated only within an ISR, this time
the one associated with the hardware clock. These two updates cannot occur at

182
4 A Swapping Kernel
the same time because they are performed by ISRs. All reads to the variables
inside the request buﬀer are protected by locks, so there can be no contention
there, either.
The request buﬀer has three visible operations. The ﬁrst (AddAlarm) adds
a sleep request to the internal queue held in the buﬀer (the queue is represented
by the ﬁnite partial function alarms); here, sleeping is interpreted as the
time before the process is to be resumed (called an “alarm”). The second,
CancelAlarm, is used to remove an alarm request from the buﬀer; its use, in
this kernel, is restricted to tidying up when processes are killed (not covered
here). The third, HaveAlarms, is a predicate used to determine whether there
are any alarm requests in the queue; it only reads alarms. The ﬁnal operation
is CallAlarms, which runs over the queue determining which processes are
ready to wake.
It should be noted that the use of the ﬁnite partial function from process
identiﬁers (APREF) to time values (TIME) to represent the queue of sleeping
processes (or, alternatively, those processes waiting for an alarm call), alarms,
ensures that a process can only make one sleep request at any time. This does
not appear to be a restriction. It should also be noted that, because of alarm’s
domain type, the idle process cannot sleep:
Proposition 93. The idle process cannot sleep.
Proof.
Immediate from the deﬁnition of APREF, the domain type of
alarms.
2
The buﬀer is called AlarmRQBuﬀer and is deﬁned as follows (the identiﬁer
“AlarmRQQueue” was resisted on the grounds of euphony):
AlarmRQBuﬀer
↾(INIT, AddAlarm, CancelAlarm, HaveAlarms, CallAlarms)
sched : LowLevelScheduler
alarms : APREF  →TIME
timenow : TimeNow
INIT
tn? : TimeNow
sch? : LowLevelScheduler
timenow ′ = tn?
sched ′ = sch?
dom alarms′ = ∅

4.6 Storage Management
183
AddAlarm
∆(alarms)
p? : APREF
t? : TIME
∃tm : TIME •
timenow.CurrentTime[tm/t!] ∧alarms′ = alarms ⊕{p? →t? + tm}
CancelAlarm
∆(alarms)
p? : APREF
alarms′ = {p?} −◁alarms
HaveAlarms
∃tm : TIME •
timenow.CurrentTime[tm/t!]
∧{p : APREF | p ∈dom alarms ∧alarms(p) ≤tm •
(p, alarms(p))} ̸= ∅
CallAlarms
∃tm : TIME •
timenow.CurrentTime[tm/t1]
∧(∃pairs : F APREF × Time; pids : F APREF •
pairs = {p : APREF | p ∈dom alarms ∧alarms(p) ≤tm •
(p, alarms(p))}
∧alarms′ = alarms \ pairs
∧pids = {p : APREF; tm : TIME | (p, tm) ∈pairs • p}
∧(∀p : APREF | p ∈pids •
∧sched.MakeReady[p/p?]))
The model of the driver process now follows. The process is represented
by a class that exports two operations: its initialisation operation and the
RunProcess operation. The RunProcess operation is an inﬁnite loop that
merely updates the swap times in the swapper process and determines whether
there are any alarms to be called. All alarm operations are performed by the
CallAlarms operation inside the request buﬀer, so the driver does not see the
structure of alarm requests. The driver also does not see the structures inside
the swapper process. These encapsulations ensure that the clock driver’s op-
erations are simple and easy to understand; they also localise any problems
with timing.
The deﬁnition of the ClockDriver process now follows.

184
4 A Swapping Kernel
ClockDriver
↾(INIT, RunProcess)
lck : Lock; devsema : Semaphore; swaptabs : ProcessStorageDescrs
swappersema : Semaphore; timenow : TimeNopw; alarms : AlarmRQBuﬀer
INIT
lk? : Lock; alarms? : AlarmRQBuﬀer
swaptb? : ProcessStorageDescrs; swapsema? : Semaphore
tn? : TimeNow
lck ′ = lk? ∧alarms′ = alarms?
tiemnow ′ = tn? ∧swaptabs′ = swaptb?
swappersema′ = swapsema?
putDriverToSleep = . . .
updateSwapperTimes = . . .
RunProcess = . . .
The operation of the driver is relatively simple, as will be seen from the
description of its component routines.
The driver is made to wait for the next interrupt by the following opera-
tion. It waits on the devsema, the device semaphore:
putDriverToSleep
devsema.Wait
The swapper uses time to determine which is to be swapped out. This
requires updating swapper tables at every clock tick. The operation called by
the clock driver is the following.
updateSwapperTimes =
swaptabs.UpdateAllStorageTimes o
9 swappersema.Signal
The main clock-driver routine is as follows. Its basic operation is to update
the swapper’s timers and call alarms:
RunProcess =
putDriverToSleepo
9
∧(∀i : 1 . . ∞•
lck.Lock o
9
(∃tm : TIME •
timenow.CurrentTime[tm/t!]
∧updateSwapperTimes[tm/tm?]
∧sched.UpdateProcessQuantum)
∧((alarms.HaveAlarms ∧alarms.CallAlarms)
∨Skip)

4.6 Storage Management
185
∧lck.Unlock
∧putDriverToSleep)
Proposition 94. The operation alarmsToCall implies that, if alarms ̸= ∅,
∀p : APREF | p ∈domalarms′ • alarms′(p) > now.
Proof. By the predicate, alarms′ = alarms \ pairs, where:
pairs = {p : APREF | p ∈dom alarms ∧alarms(p) ≤now • (p, alarms(p))}
Therefore, on each call to alarmsToCall, it is true that:
∀p : APREF | p ∈domalarms′ • alarms′(p) > now
(since this is just alarms′).
2
Proposition 95. All swapped-out processes age by one tick when the clock
driver is executed.
Proof. The critical schema is UpdateAllStorageTimes. This is a component
of updateSwapperTimes.
The schema UpdateAllStorageTimes contains the identity
swappedout time′ = swappedout time ⊕{p →swappedout time(p) −1}
2
Proposition 96. All resident processes age by one tick when the clock driver
is executed.
Proof. Similar to the above but replacing swappedout time′ by residencytime′.
2
Proposition 97. The current process’ time quantum is reduced by one unit (if
the current process is at the user level) each time the clock driver is executed.
Proof.
The body of the RunProcess operation in the clock driver con-
tains, as a conjunct, a reference to the schema sched.UpdateProcessQuantum.
The predicate of this last schema contains the identity currentquant′ =
currentquant −1.
2
Proposition 98. If, in alarmsToCall, #pairs > 0, the ready queue grows by
#pairs.
Proof. By induction using Proposition 49.
2

186
4 A Swapping Kernel
Clock
Process
Swapper
Process
Alarms
etc.
Clock
ISR
 Signal
Fig. 4.3. Interaction between clock and swapper processes.
4.6.4 Process Swapping
In this kernel, user processes are swapped in and out of main store. This
mechanism is introduced so that there can be more processes in the system
than main store could support. It is a simple storage-management principle
that pre-dates virtual store and requires less hardware support. In our scheme,
processes are swapped after they have been resident in main store for a given
amount of time. When a process is swapped, its entire image is copied to disk,
thus freeing a region of main store for another user process to be swapped in.
The relationship between this process, the Swapper process, and the clock
process is depicted in Figure 4.3
Swapping is performed by two main processes: one to select victims and
another to copy process images to and from a swapping disk.
The swapper process is modelled by the following class. The main routine
is RunProcess.
SwapperProcess
↾(INIT, swapProcessOut, swapCandidateOut, swapProcessIn,
swapProcessIntoStore, DoDiskSwap, RunProcess)
donesema : Semaphore;
swapsema : Semaphore;
pdescrs : ProcessStorageDescrs;
proctab : ProcessTable;
sched : LowLevelScheduler;
sms : SharedMainStore;
hw : HardwareRegisters;
diskrqbuﬀ: SwapRQBuﬀer;
realmem : SharedMainStore

4.6 Storage Management
187
INIT
dsma? : Semaphore
pdescs? : ProcessStorageDescrs
sched? : LowLevelScheduler
pt? : ProcessTable
store? : SharedMainStore
hwr? : HardwareRegisters
dskrq? : SwapRQBuﬀer
swpsema? : Semaphore
ms? : SharedMainStore
donesema′ = dsma?
swapsema′ = swpsema?
pdescrs′ = pdescr?
sched ′ = sched?
proctab′ = pt?
sms′ = store?
hw ′ = hwr?
diskrqbuﬀ′ = dskrq?
realmem′ = ms?
requestWriteoutSegment = . . .
requestReadinSegment = . . .
swapProcessOut = . . .
swapCandidateOut = . . .
swapProcessIn = . . .
swapProcessIntoStore = . . .
doDiskSwap = . . .
waitForNextSwap = . . .
RunProcess = . . .
The following operation requests that a segment of main store be written
to disk. It supplies the start and end addresses of the segment to be copied:
requestWriteoutSegment
p? : APREF
start?, end? : ADDRESS
(∃rq : SWAPRQMSG •
rq = SWAPOUT⟨⟨p?, start?, end?⟩⟩
∧diskrqbuﬀ.SetRequest[rq/rq?])

188
4 A Swapping Kernel
The next operation models the operation to read a segment into main
store. The name of the process to which the image belongs, as well as the
address at which to start copying, are supplied as parameters. The disk image
contains the length of the segment.
requestReadinSegment
p? : APREF
loadpoint? : ADDRESS
(∃rq : SWAPRQMSG •
rq = SWAPIN ⟨⟨p?, loadpoint?⟩⟩
∧diskrqbuﬀ.SetRequest[rq/rq?])
The operation that actually swaps process images out is given by the
following schema. The operation, like many of those that follow, is deceptively
simple when written in this form. It should be noted that it is disk residency
time that determines when swapping occurs; the basic principle on which the
swapper operates is that processes compete for main store, not disk residency.
swapProcessOut =
(∃pd : ProcessDescr •
proctab.DescrOfProc[p?/pid?, pd/pd!]
∧requestWriteoutSegment
∧sched.MakeUnready[p?/pid?]
∧realmem.FreeMainStore
∧pdescr.ClearProcessResidencyTime
∧pdescr.SetProcessStartSwappedOutTime
∧pdescr.BlockProcessChildren
∧pd.SetStatusToSwappedOut
∧pdescr.MarkAsSwappedOut)
A high-level description is relatively easy. The process descriptor of the pro-
cess to be swapped out is retrieved from the process table. The segment cor-
responding to the selected process is determined (and copied) and the process
is unreadied. The residency and start of swapout times for the process are
then cleared and the children of the selected process are then blocked. The
status of the selected process is set to swappedout.
Processes have to be swapped into store. This operation is deﬁned as:
swapCandidateOut =
(∃pd : ProcessDescr •
proctab.DescrOfProcess[p?/pid?, pd/pd!]
∧(proctab.ProcessHasChildren
∧((proctab.IsCodeOwner
∧swapProcessOut
∧proctab.BlockProcessChildren)
∨swapProcessOut))

4.6 Storage Management
189
∨((proctab.IsCodeOwner ∧swapProcessOut)
∨swapProcessOut))
When a process is to be swapped into main store, the following operation
is employed. It determines whether the process has any child processes. If
it has, it swaps the process into store and readies its children. If the newly
swapped-in process owns the code it executes, it marks its code as in store and
then performs the swap-in operation. If the process has no children, there is
no need to ready them; the rest of the operation is the same as just described.
swapProcessIn =
(proctab.ProcessHasChildren
∧((proctab.IsCodeOwner
∧swapProcessIntoStore
∧pdescr.ReadyProcessChildren)
∨(pdescr.CodeOwnerSwappedIn ∧swapProcessIntoStore)))
∨((proctab.IsCodeOwner ∧swapProcessIntoStore)
∨pdescr.CodeOwnerSwappedIn)
∧swapProcessIntoStore
The following operation performs the swap-in operation. It allocates store
and reads in the process image. It then updates the storage descriptors as-
sociated with the newly swapped-in process and then updates the relocation
registers so that the image can be accessed correctly at its new address. The
process is marked as in store and its status set to pstready; the swap param-
eters are then updated. Finally, the newly swapped-in process is readied and
a reschedule occurs.
swapProcessIntoStore =
(sms.AllocateFromHole[mspec/mspec!]
∧([mspec : MEMDESC; ldpt : N; sz : N |
∧ldpt = memstart(mspec)
∧sz = memsize(mspec)]
∧requestReadinSegment[ldpt/loadpoint?]
∧donesema.Wait
∧pdescrs.UpdateProcessStoreInfo[sz/sz?, mspec/mdesc?])
\{ldpt, sz, mspec}
∧hw.UpdateRelocationRegisters
∧pdescrs.MarkAsInStore
∧pd.SetStatusToReady[p?/pid?]
∧pdescrs.SetProcessStartResidencyTime
∧pdescrs.ClearSwappedOutTime
∧(sched.MakeReady[p?/pid?] o
9 sched.ScheduleNext)
The doDiskSwap operation is the main swapper routine. It determines the
process to swap in and then ﬁnds out whether it can allocate its image in free

190
4 A Swapping Kernel
store. If it can, it just performs the swap. If not, it determines whether it can
swap some process out of store—that process should have an image size that
is at least as big as that of the process to be swapped in. Once that candidate
has been found, the image size is determined and the swap-out operation is
performed; when the victim has been swapped out, the disk process is swapped
into store.
doDiskSwap =
(pdescrs.NextProcessToSwapIn[p?/pid!, rqsz?/sz!]
∧(sms.CanAllocateInStore ∧swapProcessIntoStore)
∨(pdescrs.HaveSwapoutCandidate
∧(pdescrs.FindSwapoutCandidate[outcand/cand!, mspec/slot!]
∧[mspec : MEMDESC; start, end : ADDRESS; sz : N |
start = memstart(mspec) ∧sz = memsize(mspec)
∧end = (start + sz) −1]
∧(swapCandidateOut[outcand/p?, start/start?,
end/end?, sz/sz?]o
9
swapProcessIn))) \ {outcand, start, end, sz, mspec})
\{p?, rqsz?}
As can be seen, this swapper is based upon disk residency time to determine
whether swapping should occur. Clearly, if there are no processes on disk,
no swapping will occur; only when there are more processes than can be
simultaneously maintained in main store does swapping begin. This seems
a reasonable way of arranging matters: when there is nothing to swap, the
swapper does nothing.
waitForNextSwap = swapsema.Wait
RunProcess =
WaitForNextSwapo
9
(∀i : 1 . . ∞•
doDiskSwapo
9
waitForNextSwap)
Proposition 99. If the owner of a process’ code is swapped out, that process
cannot proceed.
Proof. By Proposition 54, since MakeUnready removes the process from the
ready queue and alters its state to pstwaiting.
2
Proposition 100. When a parent process is swapped out, all of its children
are blocked.
Proof.
This is an immediate consequence of the BlockProcessChildren
propositions.
2
The ﬁnal organisation of this subsystem is shown in Figure 4.4.

4.7 Process Creation and Termination
191
Clock
Process
Disk
Handler
Swap
Disk
Process
Swapper
Process
Dezombifier
ISR
ISR
Fig. 4.4. Interaction between clock, swap and dezombiﬁer processes.
4.7 Process Creation and Termination
A major issue to be addressed is the following: how are processes created
within a system such as this? The answer is that some processes are created
at boot time, others when the system is running. Among the latter class are
user processes. In this section, mechanisms are deﬁned for creating system
and user processes. System processes come in two varieties, so two operations
are deﬁned for their creation.
Most system processes never terminate but user processes do, so a primi-
tive is deﬁned to release resources when a user process ends; resource release
includes the handling of zombies. For all of the system processes deﬁned in
this chapter, termination is an exceptional behaviour.
The operations required to create processes (of all kinds) and to handle
the termination of user processes are all collected in the following class.
ProcessCreation
↾(INIT,
CreateUserProcess,
CreateChildUserProcess,
CreateSystemProcess,
CreateDeviceProcess,
TerminateProcess)

192
4 A Swapping Kernel
proctab : ProcessTable
pdescrs : ProcessStorageDescrs
diskrqbuﬀ: SwapRQBuﬀ
realstore : REALMAINSTORE
lck : Lock
INIT
ptab? : ProcessTable
dskbf ? : SwapRQBuﬀ
pdescr? : ProcessStorageDescrs
store? : REALMAINSTORE
lk? : Lock
proctab′ = ptab?
diskrqbuﬀ′ = dskbf ?
pdescrs′ = pdescr?
realstore′ = store?
lck ′ = lk?
createNewPDescr . . .
createAUserProcess . . .
CreateUserProcess . . .
CreateChildUserProcess . . .
CreateSystemProcess . . .
CreateDeviceProcess . . .
writeImageToDisk = . . .
deleteProcessFromDisk = . . .
freeProcessStore = . . .
deleteSKProcess = . . .
TerminateProcess = . . .
The ﬁrst operation to deﬁne creates a new process descriptor and adds it
to the process table. In order to deﬁne this operation, the following functions
are required:
mkpstack : N1 →PSTACK
mpdata : N1 →PDATA
These functions are intended to simulate the allocation of storage for the
classes of structure. A reﬁned speciﬁcation would ﬁll in these details—for the
present, the axiomatic deﬁnitions will suﬃce.
The CreateNewPDescr operation just creates a new process descriptor.
It is supplied with the basic information required to create one through its

4.7 Process Creation and Termination
193
arguments. The predicate creates descriptors for the new process’ stack and
data areas (using the above-declared functions). The identiﬁer of the new
process is also supplied as an argument. The schema is somewhat uninteresting
from the operating systems viewpoint; however, it does show how an Object-Z
entity is dynamically created.
The operation CreateNewPDescr is, therefore, as follows:
createNewPDescr
pid? : APREF
kind? : PROCESSKIND
prio? : SCHDLVL
timequant? : TIME
stacksize?, datasize? : N
code? : PCODE
mspec? : MEMDESC
rqsz? : N
∃pd : ProcessDescr; stat : PROCSTATUS; stk : PSTACK; data : PDATA •
stat = pstnew
∧stk = mkpstack(stacksize?)
∧data = mkpdata(datasize?)
pd.Init[stat/stat?, kind?/knd?, prio/slev?, timequant?/tq?,
stk/pstack?, data/pdata?, mspec?/mem?, rqsz?/msz?]
∧proctab.AddProcessToTable[pd/pd?]
(The AddProcessToTable operation requires no substitution because it expects
the process to be identiﬁed by a variable pid?.)
The user-process creation operation proper is as follows. It creates a pro-
cess descriptor for the new process, thus enabling it to be represented within
the system. As part of this, a test (proctab.CanGenPId) is made as to whether
the system has reached its maximum number of processes. The schema is com-
plicated by the fact that allocation might have to take place on disk and not in
main store. It should be noted that the identiﬁer of the newly created process
is returned by this operation; this will be of some importance, as will be seen.
createAUserProcess
code? : PCODE
stacksize?, datasize? : N
prio? : SCHDLVL
timequant? : TIME
newpid! : APREF
∃p : APREF; rqsz : N; prio : SCHDLVL;
mspec : MEMDESC; kind : PROCESSKIND; qimage : MEM |
kind = ptuserproc ∧prio = userqueue •
proctab.CanGenPId ∧(proctab.NewPId[p/p!] ∧p = newpid!

194
4 A Swapping Kernel
∧rqsz = #code? + stacksize? + datasize?
∧((realstore.RSCanAllocateInStore[rqsz/rqsz?]
∧realstore.RSAllocateFromHole[rqsz/rqsz?, mspec/mspec!]
∧createNewPDesc[rqsz/rqsz?, mspec/mspec?]
∧pdescrs.MakeInStoreProcessSwappable[p/pid?])
∨(∧mspec = mkmspec(0, rqsz)
∧createNewPDesc[rqsz/rqsz?, mspec/mspec?]
∧realstore.CreateProcessImage[stacksize?/stksz?,
datasize?/datasz?, image/image!]
∧writeImageToDisk[p/pid?, image/image?]
∧pdescrs.MakeProcessOnDiskSwappable[p/pid?]))
∧pdescrs.AddProcessStoreInfo[p/p?, mspec/mdesc?, rqsz/sz?])
If there are no free process identiﬁers and CanGenPId fails, an error should
be raised. However, for the purposes of clarity, errors are ignored in this book.
The case should be noted, however.
In a similar fashion, a creation operation for system and device processes
needs to be deﬁned. There are some diﬀerences between it and the user-
process creation operation. In particular, all system-process identiﬁers and
storage areas can be predeﬁned, so they can be supplied as conﬁguration-time
or boot-time parameters. The schema deﬁning the operation is as follows:
createASystemProcess
kind? : PROCESSKIND
pid? : APREF
code? : PCODE
stacksize?, datasize? : N
prio? : SCHDLVL
mspec? : MEMDESC
∃rqsz : N; tquant : TIME |
tquant = ∞∧rqsz = #code? + stacksize? + datasize? •
realstore.RSAllocateInSTore[rqsz/rqsz?]
∧createNewPDEsc[rqsz/rqsz?, tquant/timequant?]
There should be no errors raised by calls to this operation.
The following operation writes a new process image to disk. It will be
loaded into main store by the swapper at some later stage. This is the opera-
tion used above in the deﬁnition of the createAUserProcess schema.
writeImageToDisk
pid? : APREF
image? : MEM
(∃rq : SWAPRQMSG •
rq = NEWSPROC⟨⟨pid?, image?⟩⟩∧diskrqbuﬀ.Write[rq/rq?])

4.7 Process Creation and Termination
195
It is now possible to continue with the deﬁnition of the interface operations
for the creation of all three kinds of process. The ﬁrst operation is the one
that creates user processes. This diﬀers from the other two schemata in that
it requires locking and that it returns a new process identiﬁer.
CreateUserProcess =
∃pprio : PRIO; tquant : TIME |
pprio = userqueue ∧tquant = minpquantum •
lck.Lock
o
9(createAUserProcess[pprio/prio?, tquant/timequant?] o
9 lck.Unlock)
The lock is required because:
•
This is an operation that is called when other processes are executing.
•
This is an operation that is intended to be called from user processes.
So, it is reasonable to ask, how are processes actually created? In particular,
how is the ﬁrst user process created? Without an initial user process, a process
outside the kernel that can call this primitive, how are user processes created?
The answer is simple: there is a kernel call that creates the initial user process.
The initial process is called the UrProcess and is created when the kernel
ﬁnishes its initialisation. What is required is, then, the following:
CreateUrProcess =
∃pprio : PRIO; tquant : TIME |
pprio = userqueue ∧tquant = minpquantum •
createAUserProcess[pprio/prio?, tquant/timequant?]
This operation requires stack and data region sizes to be created: they will
be zero or very small. They are not speciﬁed because the UrProcess might
be used for purposes other than simply creating user processes (e.g., it could
count them, exchange messages with them, and so on). For this reason, the
storage areas are not speciﬁed by the existential. The operation also returns a
new process identiﬁer (element of APREF): it can be stored within the kernel
or just ignored.
Child processes are created by the operation that is deﬁned next. It should
be noted that the basic operation is still createAUserProcess.
CreateChildUserProcess =
(∃pprio : PRIO; tquant : TIME |
pprio = userqueue ∧tquant = minpquantum •
lck.Lock
o
9(createAUserProcess[pprio/prio?, tquant/timequant?]
∧proctab.AddChildOfProcess[rqprocid?/parent?, newpid!/child?])
o
9lck.Unlock)
Now come the two operations to create the two kinds of system processes.
Both operations are based on the createASystemProcess operation. This op-
eration performs the same role in the creation of system and device processes
as createAUserProcess does in the creation of user processes.

196
4 A Swapping Kernel
A diﬀerence between the two following operations and the ones for user
processes is that the priorities are diﬀerent. System and device processes each
have their own priority level. They are assigned the appropriate priority by
the creation operation.
First, there is the system-process creation operation:
CreateSystemProcess =
(∃kind : PROCESSKIND; prio : SCHDLVL |
kind = ptsysproc ∧prio = sysprocqueue •
createASystemProcess[kind/kind?, prio/prio?])
Next, there is the operation to create device processes:
CreateDriverProcess =
(∃kind : PROCESSKIND; prio : SCHDLVL |
kind = ptsysproc ∧prio = sysprocqueue •
createASystemProcess[kind/kind?, prio/prio?])
The storage areas are deﬁned by the kernel-conﬁguration operation, and the
code is statically deﬁned as part of the kernel code. The following operations
are for use when processes terminate. In the present kernel, user processes
are the only ones that can terminate; all the other processes must continue
running until the system shuts down.
As noted above, the identiﬁer of the process is also statically allocated.
This allows, inter alia, the identiﬁers to be hard-coded into all communica-
tions. (This will be of great convenience when IPC is deﬁned in terms of
messages, as they are in the next chapter, where a full interface to the entire
kernel is deﬁned.)
Next, it is necessary to handle process termination. Processes cannot sim-
ply be left to terminate. The resources belonging to a terminating process
must be released in an orderly fashion. For this kernel, as it stands, processes
can only hold storage as a resource, so this must be released before the process
descriptor representing the process is deleted. In addition to releasing store,
a process might have unterminated children and must, therefore, become a
zombie before it can be killed oﬀcompletely. The following operations imple-
ment the basics (and add a few extra operations to give the reader an idea of
some of the other things that might need to be handled during termination).
If a process is on disk when it is terminated (say, because of system ter-
mination or because of some error that we have not speciﬁed in this chapter),
its image must be erased. The operation whose schema follows performs that
operation.
deleteProcessFromDisk
p? : APREF
(∃rq : SWAPRQMSG •
rq = DELSPROC⟨⟨p?⟩⟩
∧diskrqbuﬀ.Write[rq/rq?])

4.7 Process Creation and Termination
197
When a process terminates, its storage must be freed. The following
schema deﬁnes what happens. It is really just an interface to FreeMainstore-
Block:
freeProcessStore
p? : APREF
descr? : MEMDESC
(∃start : ADDRESS; sz : N |
start = memstart(descr?) ∧sz = memsize(descr?) •
realstore.FreeMainstoreBlock[start/start?, sz/sz?])
Finally, the full operation for releasing process storage is deﬁned. The way
in which storage is released will, at some point, depend upon whether the ter-
minating process owns its code or shares it with some other process. Clearly, if
the process owns its code, the store for the code can just be deleted—provided,
that is, the process has only terminated children. The basic operation for re-
leasing storage is as follows. It should be noted that there will be some extra
work for handling zombie processes.
releaseProcessStorage =
deleteProcessFromDisk
∧((proctab.IsCodeOwner ∧proctab.DelCodeOwner)
∨(∃owner : APREF •
proctab.DelCodeSharer[owner/owner?, p?/sharer?]))
∧(∃pd : ProcessDescr; md : MEMDESC •
proctab.DescrOfProcess[p?/pid?, pd/pd!]
∧pd.StoreDescr[md/descr!]
∧freeProcessStore[md/descr?])
∧pdescrs.RemoveProcessStoreInfo
System and device processes are easier to handle. Their storage can just be
deleted. In this system, there are no hierarchical relationships between system
and driver processes. The schema deﬁning the operation that releases kernel
process storage is the following:
deleteSKProcess =
releaseProcessStorage
∧proctab.DelProcess[p?/pid?]
It can be argued that a system shutdown can be performed without freeing
the storage that system and device processes occupy. This is messy, so the
operation just deﬁned frees the process’ space and then deletes its process
descriptor. This choice has the consequence that any process in this kernel
can execute the operation just deﬁned when it terminates.
The operations just deﬁned can be used to deﬁne the TerminateProcess
operation. This operation is deﬁned below.

198
4 A Swapping Kernel
TerminateProcess =
lck.Lock o
9
((∃pd : ProcessDescr •
proctab.DescrOfProcess[p?/pid?]
∧(¬ proctab.ProcessHasChildren
∧((proctab.ProcessHasParent
∧proctab.ParentOfProcess[parent/parent!]
∧proctab.RemoveProcessFromParent
[parent/parent?, p?/child?]
∧pd.SetStatusToTerminated
∧deleteSKProcess) \ {parent}
∨(pd.SetStatusToTerminated
∧deleteSKProcess))
∨(proctab.ProcessHasChildren
∧proctab.MakeZombieProcess[p?/pid?])))
∧lck.Unlock)
The operation uses a lock instead of a semaphore because, strictly speaking,
it belongs to the layer implementing the process abstraction.
The termination operation also has to handle the case in which a par-
ent process terminates before any of its children do. If a parent terminates,
its storage will be deallocated but this will also remove its code from main
store. Without code, the children cannot execute, so a mechanism must be
implemented to prevent the parent’s code from being deleted. (If parents and
children share data storage, it, too, must be prevented from deallocation.) The
zombie mechanism whose operations were deﬁned together with the process
table is used to do this.
Basically, when a parent process terminates, a check is made to see if there
are any active child processes. If there are no active children, the parent is
allowed to terminate normally. Otherwise, the parent is unreadied and placed
in a special waiting state (which we refer to, here, as the “zombie” state).
When all the children of a zombie parent have terminated, the parent can be
deallocated (properly terminated). The deallocation is the same as for normal
processes; each zombie must have a process descriptor, at least to record the
locations and sizes of its storage areas. The only problem is that children can
create children: in the model, this requires that the transitive closure of the
child relation be used to determine all the children of a parent process.
4.8 General Results
This ﬁnal section contains the proof of a number of propositions that deal
with properties of the kernel.
The propositions stated and proved in this section are collected here for
convenience.

4.8 General Results
199
Proposition 101. When a process is swapped in, it enters the ready queue.
Proof. The predicate of schema swapProcessIn contains MakeReady[p?/pid?]
as a conjunct in an unconditional location.
2
Proposition 102. When a parent process is swapped out, none of its children
appear in the ready queue.
Proof. By Proposition 89.
2
Proposition 103. When a parent process is swapped in, its children change
state and appear in the ready queue.
Proof. The appropriate schema contains an instance of MakeReady.
2
Proposition 104. When a device request is made, the current process enters
a waiting state and is no longer in the ready queue.
Proof.
In this kernel, there is really only one good case upon which to
make an argument: clock alarms. When a process makes an alarm request,
has its context swapped out by the SVC ISR and its state is set to pstwaiting.
Furthermore, the ISR calls MakeUnready on the requesting process to remove
it from the scheduler. The process is held by the clock driver.
Device requests are made via SVCs, so the above will always hold.
2
Proposition 105. When a device completes, the requesting process is re-
turned to the ready queue.
Proof.
Again, the clock driver is the only example but it is normative.
When each process is awakened from its sleeping state (when its alarm clock
“rings”), MakeReady is called to return the process to the ready queue. The
MakeReady operation changes the status attribute in the process’ descriptor
to reﬂect the fact that it is ready (sets the status to pstready, that is).
2
Proposition 106. While a process is waiting for a device request to complete,
it is in neither the ready nor the running state. It is in the waiting state.
Proof.
Proposition 104 states that the requesting process is unreadied by
the SVC ISR. Therefore, it cannot be in the ready state. The ISR also calls
the scheduler to execute another process, so the requesting process cannot be
executing.
2
Proposition 107. Processes marked as zombie cannot be swapped out.

200
4 A Swapping Kernel
Proof. By the schema, FindSwapoutCandidate:
FindSwapoutCandidate
p? : APREF
cand! : APREF
rqsz? : N
slot! : MEMDESC
(∃p : APREF; t : TIME | residencytime(p) = t •
p ̸= p? ∧
pstatus(p) ̸∈illegalswapstatus ∧
pkind(p) ̸= ptsysproc ∧
pkind(p) ̸= ptdevproc ∧
pmemsize(p) ≥rqsz? ∧
(∀p1 : APREF •
(p1 ̸= p ∧p1 ̸= p?
∧p1 ∈dom residencytime ∧t ≥residencytime(p1))
⇒p = cand! ∧pmem(p) = slot!))
The critical line is pstatus(p) ̸∈illegalswapstatus, where:
illegalswapstatus = {pstrunning, pstwaiting, pstswappedout,
pstnew, pstterm, pstzombie}
Since this line appears as a conjunct, if it is false, it will invalidate the entire
predicate.
2
Proposition 108. Processes marked as zombie cannot make device requests.
Proof. To make a device request, a process must be ready. Processes marked
as zombie are not active and are about to terminate. Therefore, they cannot
make any requests apart from those that release resources.
2
Corollary 8. Processes marked as zombie cannot be present in device queues.
Proof. This follows from the immediately preceding proposition.
2
Proposition 109. Each process is resident in at most one queue at any time.
Proof. The possible queues in which a process can reside are:
•
one of the ready queue components;
•
a device request queue (if appropriate);
•
a semaphore queue; or

4.8 General Results
201
•
the clock’s waiting sets.
In the deﬁnition of the semaphore Wait operation, there is an instance
of MakeUnready. This operation removes the caller from the ready queue.
Furthermore, the operation applies Enqueue to the caller to place it in the
local queue of processes waiting on the semaphore. Therefore, any process
performing a Wait operation cannot simultaneously be in a ready queue and
the semaphore’s queue of waiting processes.
When a process is ready, it is not waiting on the clock or a device or
semaphore (by deﬁnition). When a process is waiting on a device, it cannot
be marked as ready.
2
Proposition 110. Each process is in exactly one state at any time.
This is the analogue of the informal property that a process is resident in
at most one queue at any time.
Proof.
The state of each process (with the exception of the idle process,
which is a special case) is represented by its status attribute. Inspection of the
operations reveals that the value of this attribute is modiﬁed appropriately.
2
Proposition 111. The scheduling r´egime employed by this kernel is fair.
Proof.
The fairness property is interpreted as: no process waits inﬁnitely
long before executing. Therefore, it must be shown that the scheduler does
not require processes to wait for inﬁnite periods of time.
First, if there are only user-level processes, by Propositions 59 and 64, the
user-level queue implements a fair policy.
Clearly, by Proposition 62, all device processes execute as soon as possible.
Similarly, by Proposition 63, all system processes are executed before user-
level ones and after all device processes. Indeed, if there are no device processes
in the scheduler, system processes are executed in preference to user-level ones.
It can be observed that device and system processes are guaranteed by
design either:
•
to terminate in a ﬁnite time; or
•
to block after a relatively short period of execution.
Either way, device and system processes do not execute for inﬁnite periods of
time before either terminating or blocking.
The next case to consider is that in which an inﬁnite number of device pro-
cesses are executed on an inﬁnite number of occasions between the execution
of user processes.
The clock process is driven by a periodic interrupt. The handler processes
are guaranteed to terminate promptly. However, the swapper processes might

202
4 A Swapping Kernel
have to wait for an inﬁnite time because of a disk fault; when waiting, processes
are not in the scheduler’s ready queues.
To have a suﬃcient number of device processes in the scheduler, a user
process would have to make repeated requests. This implies that at least one
user process is executing inﬁnitely often because device and system processes
do not usually make device requests (the swapper process can be discounted
because of its structure). However, user processes exhaust their time quantum
after a ﬁnite period of activity and are returned to the back of the user-level
ready queue, thus permitting rescheduling. If a process is waiting on a device,
it is not in the scheduler’s queues.
Finally, there is the case of inﬁnite execution of the idle process. The idle
process is only executed when there are no other processes available in the
scheduler to execute. Therefore, if the idle process is executing and another
process becomes ready, the scheduler will block the idle process in favour of
the other process.
In the sense of fairness enunciated at the start, the scheduler is fair.
2
Ich weiß nicht, was soll bedeuten,
Daß ich so traurig bin,
Ein M¨archen aus alten Zeiten,
Daß kommt mir nicht aus dem Sinn
– Heinrich Heine, Die Lorelei

3
A Simple Kernel
Scimus, et veniam petimusque damusque vicissim.
– Horace, Ars Poetica, 9
3.1 Introduction
This chapter contains the ﬁrst of the kernel models in this book. The kernel
modelled here is deliberately simple but is still useful. It is intended to be a
kernel for an embedded or small real-time system and to be a speciﬁcation
of a workable system—one aim of the exercise is to produce a speciﬁcation
that could be reﬁned to working code. (As noted in Chapter 1, the kernels
in this book have been revised somewhat and are being reﬁned to code as a
concurrent activity by the author.)
The model deﬁned in this chapter is intended as an existence proof. It
is intended to show that it is possible to model an operating system kernel,
albeit a small one, using purely formal models. The model is simple, as is the
kernel—more extensive kernels will be modelled in the next two chapters, so
readers will ﬁnd increasingly complex kernels that deal with some of the issues
left unresolved by the current one (for example, properties of semaphores in
the next chapter).
The current eﬀort is also intended as an orienting exercise for the reader.
The style of the models is the same in this chapter as in the following ones.
As will be seen, there are structures that are common (at least in high-level
terms) and this chapter introduces them in their actual context.
This chapter uses Object-Z rather than Z.
3.2 Requirements
The operating system to be modelled in this chapter is intended to be suitable
for real-time processing, possibly in an embedded context. The kernel should

56
3 A Simple Kernel
be as small. The kernel should also be portable and, as such, there is no need
to specify any ISRs or the clock and associated driver and ISR. Devices and
the uses to which the clock is to be put are considered matters that depend
upon the particular instantiation of the kernel (e.g., some kernels might not
use drivers, or the clock might do more than just record the time and wake
sleeping processes).
The kernel must implement a priority-based scheduler. Initially, all prior-
ities are to be ﬁxed. The priority of a process is deﬁned before it is loaded
and assigned to it via a parameter; that parameter is to be used to set the
process’ priority in the scheduler.
The kernel is not to contain any storage-management modules. All storage
is to be allocated statically, oﬄine, as part of the kernel conﬁguration process.
The kernel is, basically, to implement the process abstraction, a scheduler
and IPC. The IPC is to be relatively rich and must include:
•
semaphores (and shared memory);
•
mailboxes and asynchronous messages.
All shared memory must be allocated statically when process storage is allo-
cated.
The kernel is to be statically linked with the user processes that run on it.
The memory map of the system is used to deﬁne where the various processes
reside and where the shared storage is. Primitives are to be provided to:
•
create processes and enter them into the scheduler’s queue;
•
terminate a process and release its process descriptor, together with any
semaphores and message queues that it owns.
There are operations, moreover, to perform the following operations:
•
suspend a running process;
•
create and dispose of IPC structures;
•
perform IPC operations.
In addition, the kernel will support an operation that permits a process to
alter its priority.
3.3 Primary Types
This section contains the deﬁnitions of the basic types used by this model.
Processes must be referenced. The basic reference type is the following:
[PREF]
As noted elsewhere, it is necessary to deﬁne constants to denote the null and
idle processes. The types are:
NullProcRef , IdleProcRef : PREF

3.3 Primary Types
57
Two more process reference types can now be deﬁned. The ﬁrst excludes the
null process reference, while the second excludes both the null and idle process
references:
IPREF == PREF \ {NullProcRef }
APREF == IPREF \ {IdleProcRef }
Without loss of generality, these types can be given a more concrete represen-
tation. First, it is necessary to deﬁne the maximum number of processes that
the kernel can contain:
maxprocs : N
(This is, in fact, the size of the process table or the number of process de-
scriptors in the table.)
Next, the types and values of the constants denoting the null and idle
processes are deﬁned:
NullProcRef : PREF
IdleProcRef : IPREF
NullProcRef = 0
IdleProcRef = maxprocs
They are deﬁned so that they form the extrema of the IPREF type.
The PREF type can now be deﬁned as:
PREF == NullProcRef . . IdleProcRef
The above deﬁnitions of IPREF and APREF still hold. For example, writing
constants out:
APREF == 1 . . maxprocs −1
These deﬁnitions will, inter alia, make process identiﬁer generation simpler
and easier to understand.
Each process is in one and exactly one state at any time during its exis-
tence. The following type deﬁnes the names of these states (the pst preﬁx just
denotes “process table”):
PROCSTATUS ::= pstnew
|
pstrunning
|
pstready
|
pstwaiting
|
pstterm
The states can be understood as follows. When a process is newly created but
not added to the ready queue, it has state pstnew. When a process is ready to

58
3 A Simple Kernel
execute (is resident in the ready queue), it has state pstready. When a process
is executed, its state is pstrunning. Processes block or are suspended for a
variety of reasons (e.g., when they are waiting for a device). While a process
is waiting (for whatever reason), it is in state pstwaiting. Finally, when a
process terminates, it enters the pstterm state.
In this kernel, each process has a stack and code and data areas. The
process descriptor records the address and size of each of these areas. In
addition, the process descriptor records the pointer to the top of the stack.
The relevant types are deﬁned as the following atomic types:
[PSTACK, PCODE, PDATA]
Of these, PSTACK is the only one that is used much in this model. It is
assumed that the process state consists partly of the state of its current stack
and that there is hardware support for the stack, so there is a stack register.
For the purposes of this model, it is assumed that values of type PSTACK
are atomic values that can be assigned to registers.
The other types, PCODE and PDATA, are only used in the current model
to represent values stored in each process’ process descriptor. If they were
expanded, they could be used for error checking; we ignore this possibility,
however.
Finally, the type representing process priorities is deﬁned:
PRIO == Z
The interpretation is that the higher the priority, the greater the magnitude.
Therefore, the priorities −1, 20 and 0 are ordered (highest to lowest) as: −1,
0 and 20. There are no bounds placed on priorities, so it is always possible to
produce a priority that is lower than any other. In an implementation, there
would be a minimum priority equal to the greatest integer representable by
the hardware (232 −1 on a 32-bit machine); conversely, the highest possible
priority would be the most negative integer representable by the hardware
(−232 on a 32-bit machine).
3.4 Basic Abstractions
This section is concerned with the deﬁnition of the basic constructs used to de-
ﬁne the kernel. Three of these abstractions, ProcessQueue, HardwareRegisters
and Lock have appeared before, so they will be presented without comment.
The reader is warned again that the model in this chapter is written in Object-
Z and not in Z. For this reason, the constructs just listed are represented as
Object-Z classes and methods.
The Object-Z version of the ProcessQueue is modelled as follows. With
the exception of the constructs required for Object-Z, the model is exactly
the same as the Z version:

3.4 Basic Abstractions
59
ProcessQueue
↾(INIT, IsEmpty, Enqueue, RemoveFirst,
QueueFront, RemoveElement)
elts : iseq APREF
INIT
elts′ = ⟨⟩
IsEmpty
elts = ⟨⟩
Enqueue
∆(elts)
x? : APREF
elts′ = elts ⌢⟨x?⟩
RemoveFirst
∆(elts)
x! : APREF
x! = head elts
elts′ = tail elts
QueueFront
x! : APREF
x! = head elts
RemoveElement
∆(elts)
x? : APREF
(∃s1, s2 : iseq APREF •
s1 ⌢⟨x?⟩⌢s2 = elts
∧s1 ⌢s2 = elts′)
The class exports the following operations, in addition to the initialisa-
tion (Init) operation: IsEmpty, Enqueue, RemoveFirst, QueueFront and Re-
moveElement.
In a similar fashion, the hardware register class is composed of operations
that are identical to those deﬁned in the last chapter.

60
3 A Simple Kernel
HardwareRegisters
↾(SetGPRegs, GetGPRegs, GetStackReg, SetStackReg,
SetIntsOﬀ, SetIntsOn, GetIP, SetIP
GetStatWd, SetStatWd)
hwgenregs : GENREGSET
hwstack : PSTACK
hwstatwd : STATUSWD
hwip : N
INIT
hwgenregs.INIT
hwstack ′ = 0
hwstatwd ′ = 0S
hwip′ = 0
SetGPRegs
∆(hwgenregs)
regs? : GENREGSET
hwgenregs′ = regs?
GetGPRegs
regs! : GENREGSET
regs! = hwgenregs
GetStackReg
stk! : PSTACK
stk = hwstack
SetStackReg
stk? : PSTACK
hwstack ′ = stk?
GetIP
ip! : N
ip! = hwip
SetIP
ip? : N
hwip′ = ip?

3.4 Basic Abstractions
61
GetStatWd
stwd! : STATUSWD
hwstatwd ′ = stwd?
SetStatWd
stwd? : STATUSWD
stwd! = hwstatwd
SetIntsOﬀ
intﬂg′ = intoﬀ
SetIntsOn
intﬂg′ = inton
The lock class is as follows. It exports the Lock and Unlock operations,
as well as an initialisation operation. The class diﬀers very slightly from the
speciﬁcation of the previous chapter. In the Z speciﬁcation, the operations
worked directly on the interrupt able/disable ﬂag. Here, the class takes a ref-
erence to the hardware registers as its only initialisation parameter. The Lock
and Unlock operations are deﬁned in terms of the reference to the hardware.
The net eﬀect is that the Lock class must be instantiated before it is used.
Lock
↾(INIT, Lock, Unlock)
hw : HardwareRegisters
Assume that registers have been initialised.
INIT
hwrgs? : HardwareRegisters
hw ′ = hw?
Lock = hw.SetIntsOﬀ
Unlock = hw.SetIntsOn
The lowest level of the kernel uses locking to ensure mutual exclusion.
Above this, semaphores are used. Semaphores are modelled by the following
class, which exports an initialisation operation (INIT), Wait (P in Dijkstra’s
terminology) and Signal (V ). The class contains a process queue (waiters)
to hold its waiting processes; the waiters queue is unrelated to any other

62
3 A Simple Kernel
queue, a fact denoted by the ⃝
C subscript. The other semaphore component is
the counter, scnt, which has type Z. (The initialisation value, initval, is also
retained.)
The semaphore has to cause processes to be scheduled and suspended. It
needs to access the scheduler (via the reference sched) and to the process table
(via ptab). Semaphores also need to switch contexts when they block waiting
processes, so a reference to the Context class is required to provide access to
the context-switching operations.
Semaphores work by updating the counter (scnt) as an atomic operation.
To do this, the semaphore uses the Lock class to exclude all processes except
the calling one from the counter. In the model, the lock operations are placed
around more operations than simply the counter update. This is to make the
speciﬁcation easier to read.
Here, the decrement-based model for semaphores is adopted (see, for ex-
ample, [26]). The decrement-based model has certain advantages from the
implementation viewpoint. In particular, the sign of the counter is used as
the basis for the major decisions in the two operations.
Although semaphores are of considerable interest, the reader will see that
we do not prove any of their properties in this chapter. Indeed, the only proofs
in this chapter relate to priority queues, because priority queues in this form
do not appear in any of the following chapters—semaphores are used in the
next chapter. The interested reader will have to wait until the next chapter
for proofs of the basic properties of semaphores.
Semaphore
↾(INIT, Wait, Signal)
waiters : ProcessQueue⃝
C
scnt, initval : Z
ptab : ProcessTable
sched : LowLevelScheduler
ctxt : Context
lck : Lock
INIT
iv? : Z
pt? : ProcessTable
sch? : LowLevelScheduler
ct? : Context
lk? : Lock
initval ′ = iv? ∧scnt′ = iv? ∧ptab′ = pt?
sched ′ = sch? ∧ctxt′ = ct? ∧lck ′ = lk?
waiters.Init

3.4 Basic Abstractions
63
NegativeSemaCount = scnt < 0
NonPositiveSemaCount = scnt ≤0
IncSemaCount = scnt′ = scnt + 1
DecSemaCount = scnt′ = scnt −1
Wait =
lck.Lock o
9
(DecSEMACnt o
9
(NegativeSEMACount ∧
waiters.Enqueue[currentp/x?] ∧
(∃cpd : ProcessDescr •
ptab.DescrOfProcess[currentp/pid?, cpd/pd!] ∧
cpd.SetProcessStatusToWaiting ∧
ctxt.SwitchContextOut) ∧shed.MakeUnready[currentp/pid?]
∧sched.RunNextProcess)
∨sched.ContinueCurrent)o
9
lck.Unlock
Signal =
lck.Lock o
9
(IncSEMACnt o
9
(NonPositiveSEMACount ∧
waiters.RemoveFirstProc[cand/x!] ∧
(∃cpd : ProcessDescr •
ptab.DescrOfProcess[cand/pid?, cpd/pd!] ∧
cpd.SetProcessStatusToReady) ∧
sched.MakeReady[cand/pid?]) \ {cand}
∨sched.ContinueCurrent)o
9
lck.Unlock
At this point, it is worth making an observation or two about the use of
locks in this book. When writing code that manipulates the interrupt ﬂag, it is
always wise to make the period during which interrupts are disabled as short
as possible so that new interrupts are not missed. In the models in this book,
there are operations entirely bracketed by locking and unlocking operations,
thus giving the impression that interrupts must be disabled for relatively long
periods of time: these operations are high-level speciﬁcations that have been
written with clarity as a goal. When reﬁning the speciﬁcations, use should be
made of the two following propositional calculus theorems:
p ∧q ⇔q ∧p
and:
p ∧q ⇔p ∧q ∧p

64
3 A Simple Kernel
These theorems (and their corollaries) are of use in distributing the lock/unlock
conjuncts through the rest of the operation, thus adjusting the regions over
which interrupts are disabled.
In this model, the process descriptor is a record-like structure stored in a
table (an array of records). The process descriptor stores the priority (prio),
registers (regs), status word (statwd) and the instruction pointer (ip), as well
as the process’ current state (status). Furthermore, it also contains a pointer
to the process’ stack (stack) and to its data and code areas (data and code,
respectively). It is assumed that the stack, code and data are stored in one
contiguous region of main store of size memsize and pointed to by mem. The
type MEMDESC can be considered, for the time being, as simply a pointer
into main store.
The process descriptor is modelled by the next class. It exports an initial-
isation operation (INIT), together with the following operations: FullContext
(to extract the process’ context from the record) and SetFullContext (to save
the context in the descriptor). In addition, there are operations to store and
update the process’ priority and to update its state record (status) and re-
turn and set its storage descriptor (this is required by the storage-allocation
operations). Operations are also provided to read and set the process’ priority.
The reader might care to compare this deﬁnition with the much more
complex one required in the next chapter (Section 4.4). Although the record-
based approach to process descriptors is common and easy to work with (it
turns the process table into an array of records), the approach has some
disadvantages, the most interesting of which relates to contention. If more
than one process needs to access a process descriptor at the same time, it
is necessary to protect it in some way, by a lock in the uni-processor case.
However, locking prevents access to all of the components of the descriptor
(and possibly all of the process table). An alternative implementation must
therefore be sought; for example, representing the components of the records
by mappings from IPREF to their type (e.g., the process’ stack by IPREF  →
PSTACK).
ProcessDescr
↾(INIT, FullContext, SetFullContext, Priority, SetPriority,
SetProcessStatusToNew, SetProcessStatusToTerminated,
SetProcessStatusToReady, SetProcessStatusToWaiting,
StoreSize, SetStoreDescr)
prio : PRIO; status : PROCSTATUS; regs : GENREGSET
statwd : STATUSWD; ip : N; stack : PSTACK
data : PDATA; code : PCODE; mem : MEMDESC
memsize : N

3.4 Basic Abstractions
65
INIT = . . .
Priority = . . .
SetPriority = . . .
ProcessStatus = . . .
SetProcessStatusToNew = . . .
SetProcessStatusToTerminate = . . .
SetProcessStatusToReady = . . .
SetProcessStatusToRunning = . . .
SetProcessStatusToWaiting = . . .
StoreSize = . . .
StoreDescr = . . .
SetStoreDescr = . . .
FullContext = . . .
SetFullContex = . . .
INIT
pr? : PRIO
stat? : PROCSTATUS
pstack? : PSTACK
pdata? : PDATA
pcode? : PCODE
mem? : MEMDESC
msz? : N
prio′ = pr?
status′ = stat?
waitingtype′ = none
kind ′ = knd?
regs.INIT
statwd ′ = 0S
ip′ = 0
data′ = pdata?
code′ = pcode?
stack ′ = pstack?
mem′ = mem?
memsize′ = msz?

66
3 A Simple Kernel
Priority
pr! : PRIO
pr! = prio
SetPriority
∆(prio)
pr? : PRIO
prio′ = pr?
ProcessStatus
st! : PROCSTATUS
st! = status
SetProcessStatusToNew
∆(status)
status′ = pstnew
SetProcessStatusToTerminated
∆(status)
status′ = pstterm
SetProcessStatusToReady
∆(status)
status′ = pstready
SetProcessStatusToRunning
∆(status)
status′ = pstrunning
SetProcessStatusToWaiting
∆(status)
status′ = pstwaiting

3.4 Basic Abstractions
67
StoreSize
memsz! : N
memsize = memsz!
StoreDescr
memdescr! : MEMDESC
memdescr! = mem
SetStoreDescr
∆(pmem, pmemsize)
newmem? : MEMDESC
mem′ = newmem?
memsize′ = hole size(newmem?)
FullContext
pregs! : GENREGSET
pip! : N
ptq! : TIME
pstatwd! : STATUSWD
pstack! : PSTACK
pregs! = regs
pip! = ip
pstatwd! = statwd
pstack! = stack
SetFullContext
pregs? : GENREGSET
pip? : N
pstatwd? : STATUSWD
pstack? : PSTACK
regs′ = pregs?
ip′ = pip?
statwd ′ = pstatwd?
stack ′ = pstack?
The process table is deﬁned next. Its main structure, procs, is a ﬁnite
mapping between IPREF and ProcessDescr. It is a table or array indexed

68
3 A Simple Kernel
by elements of IPREF and whose elements are objects of type ProcessDescr.
The class also has state variable known procs to record the elements in the
domain of procs; it is a record of the identiﬁers of those processes currently
in the system. The variable freeids is a set of actual process identiﬁers that
represent those process references not currently referring to processes in the
system. The idea is that the identiﬁer of a process is its index in the process
table.
The kernel only allocates “actual” processes; that is, processes other than
the null and idle processes. For this reason, freeids is a set of type APREF.
The procs mapping (table) is of type IPREF, the reason for this being that
the idle process is represented by a process descriptor that is allocated in the
process table when the kernel is initialised.
Apart from its initialisation operation (again, INIT), the process table
exports operations to create the idle process (CreateIdleProcess) and to add
and delete process descriptors (AddProcess and DelProcess, respectively), as
well as an operation to return the descriptor of a process (DescrOfProcess).
The operation to create the idle process could be deﬁned in a higher layer
of the model. Since the idle process owns no resources and executes a piece of
code that will be supplied with the kernel (and whose address can, therefore,
be made available at kernel initialisation time), it seems reasonable to make
idle process creation a process table operation.
ProcessTable
↾(INIT, CreateIdleProcess, AddProcess, DelProcess, DescrOfProcess)
procs : IPREF  →ProcessDescr
known procs : F IPREF
freeids : F APREF
INIT
known procs′ = {IdleProcRef }
freeids′ = 1 . . maxprocs −1
(∃ipd : ProcessDescr • createIdleProcess)
CreateIdleProcess
(∃pr : PRIO; stat : PROCSTATUS; stwd : STATUSWD;
emptymem : MEMDESC; stkdesc : MEMDESC;
memsz : N; ipd : ProcessDescr •
stat = pstready ∧prio = pr ∧stwd = 0s
∧emptymem = (0, 0) ∧stkdesc = (0, 20) ∧memsz = 0
∧ipd.INIT[stat/stat?, knd/knd?, schdlv/slev?, tq/tq?,
stkdesc/pstack?, emptymem/pdata?,
emptymem/pcode?, emptymem/mem?, memsz/msz?]
procs′ = procs ⊕{IdleProcRef →ipd})

3.4 Basic Abstractions
69
AddProcess
∆(procs)
pid? : APREF
pd? : ProcessDescr
procs′ = procs ⊕{pid? →pd?}
DelProcess
∆(procs)
pid? : APREF
procs′ = {pid?} −◁procs
DescrOfProcess
pid? : IPREF
pd! : ProcessDescr
pd! = procs(pid?)
The Context class implements the context-switching operations. It is just
an encapsulation of the operations described in the previous chapter. It is, in
any case, relatively simple. The reader should note the comments in the class
deﬁnition. The operations deﬁned in this class are extended by SwapIn and
SwapOut—they are deﬁned for convenience.
Context
↾(INIT, SaveState, RestoreState, SwapIn, SwapOut)
ptab : ProcessTable
sched : LowLevelScheduler
hw : HardwareRegisters
INIT
ptb? : ProcessTable
shd? : LowLevelScheduler
hwregs? : HardwareRegisters
ptab′ = ProcessTable
sched ′ = LowLevelScheduler
hw ′ = hwregs?

70
3 A Simple Kernel
SaveState
(∃cp : IPREF •
sched.CurrentProcess[cp/cp!]
(∃pd : ProcessDescr •
ptab.DescrOfProcess[cp/pid?, pd/pd!]
∧(∃regs : GENREGSET; stk : PSTACK; ip : N;
stat : STATUSWD •
hw.GetGPRegs[regs/regs!]
∧hw.GetStackReg[stk/stk!]
∧hw.GetIP[ip/ip!]
∧hw.GetStatWd[stat/stwd!]
∧pd.SetFullContext[regs/pregs?, ip/pip?, stat/pstatwd?,
stk/pstack?])))
RestoreState
(∃cp : IPREF •
sched.CurrentProcess[cp/cp!]
∧(∃pd : ProcessDescr •
ptab.DescrOfProcess[cp/pid?, pd/pd!]
∧(∃regs : GENREGSET; stk : PSTACK; ip : N;
stat : STATUSWD •
pd.FullContext[regs/pregs!, ip/pip!, stat/pstatwd!,
stk/pstack!]
∧hw.SetGPRegs[regs/regs?]
∧hw.SetStackReg[stk/stk?]
∧hw.SetStatWd[stat/stwd?]
∧hw.SetIP[ip/ip?])))
SwapOut =
(∃cp : IPREF; pd : ProcessDescr •
sched.CurrentProcess[cp/cp!]
∧ptab.DescrOfProcess[pd/pd!]
∧pd.SetProcessStatusToWaiting
∧SaveState o
9 sched.MakeUnready[currentp/pid?]
∧sched.ScheduleNext)
SwapIn =
(∃cp : IPREF; pd : ProcessDescr •
sched.CurrentProcess[cp/cp!]
∧pd.SetProcessStatusToRunning
∧RestoreState)
SwitchContext = SwapOut o
9 SwapIn

3.5 Priority Queue
71
3.5 Priority Queue
This kernel uses a priority queue as the core of its scheduler. The PRIO type
is equivalent to the integers, so the priorities cannot be arranged as broad
classes as they are in the kernel modelled in the next chapter (where there
are three priority classes, each modelled by a separate queue). This kernel
does not make assumptions about how the priority bands are deﬁned, so
a representation has to be chosen to reﬂects this. The representation is a
sequence of process references.
Three relations are required for the deﬁnition of priorities. They are the
usual ≤, ≥and = operations. The subscript is used just to diﬀerentiate them
from the corresponding relations over the integers.
≤P
: PRIO ↔PRIO
=P
: PRIO ↔PRIO
≥P
: PRIO ↔PRIO
∀p1, p2 : PRIO •
p1 ≤P p2 ⇔p1 ≤p2
p1 =P p2 ⇔p1 = p2
p1 ≥P p2 ⇔p1 ≥p2
The following derived relations are deﬁned in the obvious fashion:
<P
: PRIO ↔PRIO
>P
: PRIO ↔PRIO
∀p1, p2 : PRIO •
p1 <P p2 ⇔(p1 ≤P p2) ∧¬ (p1 =P p2)
p1 >P p2 ⇔(p1 ≥P p2) ∧¬ (p1 =P p2)
For completeness, the deﬁnitions of these relations are given, even though they
should be obvious. Moreover, the <P relation is not used in this book.
A class deﬁning the process priority queue (or queue of processes ordered
by priority) is as follows:
PROCPRIOQUEUE
↾(INIT, EnqueuePROCPRIOQUEUE,
NextFromPROCPRIOQUEUE, IsInPROCPRIOQUEUE,
IsEmptyPROCPRIOQUEUE, PrioOfProcInPROCPRIOQUEUE,
RemoveProcPrioQueueElem)
qprio : PREF  →PRIO
procs : iseq PREF
dom qprio = ran procs
∀p1, p2 : PREF •
p1 ∈ran procs ∧p2 ∈ran procs ∧qprio(p1) ≤P qprio(p2) ⇒
(∃i1, i2 : 1 . . #procs • i1 ≤i2 ∧procs(i1) = p1 ∧procs(i2) = p2)

72
3 A Simple Kernel
INIT
PROCPRIOQUEUE ′
procs′ = ⟨⟩
EnqueuePROCPRIOQUEUE = . . .
NextFromPROCPRIOQUEUE = . . .
IsInPROCPRIOQUEUE = . . .
IsEmptyPROCPRIOQUEUE = . . .
PrioOfProcInPROCPRIOQUEUE = . . .
RemovePrioQueueElem = . . .
reorderProcPrioQueue = . . .
The queue’s state consists of a ﬁnite mapping from process identiﬁers to their
associated priority (the priority mapping) and a queue of processes. The in-
variant states that if the priority of one process is less than that of another,
the ﬁrst process should precede the second.
The class exports an initialisation operation (INIT), an enqueue and re-
moval operations. There is an emptiness test and a test to determine whether
a given process is in the queue. A removal operation, as well as a reordering
operation, is also provided (the removal operation is used when re-prioritising
processes). The ﬁnal operation that is exported returns the priority of a pro-
cess that is in the queue.
The reader will have noted that the priority record in the priority queue
duplicates that in the process table. What would happen in reﬁnement is that
the two would be identiﬁed.
The enqueue operation is:
EnqueuePROCPRIOQUEUE
∆(qprio, procs)
pid? : PREF
pprio? : PRIO
qprio′ = qprio ∪{pid? →pprio?}
(procs = ⟨⟩∧procs′ = ⟨pid?⟩)
∨(procs ̸= ⟨⟩
∧((qprio(pid?) ≤P qprio(head procs)) ∧procs′ = ⟨pid?⟩⌢procs)
∨((qprio(pid?) >P qprio(last procs)) ∧procs′ = procs ⌢⟨pid?⟩)
∨(∃s1, s2 : iseq PREF | s1 ⌢s2 = procs •
((qprio(last s1) ≤P qprio(head s2)) ∧
procs′ = s1 ⌢⟨pid?⟩⌢s2)))

3.5 Priority Queue
73
The operation uses the priority of the process in determining where the process
is to be inserted in the queue. If the new process’ priority is greater (has a lower
value) than the ﬁrst element of the queue, the new process is prepended to the
queue; conversely, if the priority is lower (has a greater value) than the last
element, it is appended to the queue. Otherwise, the priority is somewhere
between these two values and a search of the queue is performed (by the
existential quantiﬁer) for the insertion point.
Proposition 21. The predicate of the EnqueuePROCPRIOQUEUE schema
satisﬁes the invariant of the PROCPRIOQUEUE schema that deﬁnes the
state.
Proof. Let I denote the invariant:
dom qprio = ran procs
∀p1, p2 : PREF •
p1 ∈ran procs ∧p2 ∈ran procs ∧qprio(p1) ≤P qprio(p2) ⇒
(∃i1, i2 : 1 . . #procs •
i1 ≤i2 ∧procs(i1) = p1 ∧procs(i2) = p2)
Case 1. procs = ⟨⟩∧proc′ = ⟨p⟩⇒I . Since qprio(p) ≤P qpiro(p), for all p.
Clearly, in the case of procs′, i1 ≤i2 (since i1 = i2).
Case 2. procs ̸= ⟨⟩. Let ps = {p : PREF | p ∈ran procs′ • qprio(p)}. There
are three cases to consider:
i. p is at the head of procs′—qprio(p) ≤P min ps;
ii. p is the last of procs′—qprio(p) >P max ps;
iii. p appears in the middle of the sequence—i.e., min ps ≤P (pqprio(p) ≤P
max ps.
Case 2i. Immediate.
Case 2ii. Immediate.
Case 2iii. Assume that there are two increasing sequences, s1 and s2, of PREFs
s.t. s1 ⌢s2 = procs. Then, if qprio(last s1) ≤P qprio(p) ≤P qprio(head s2),
procs′ = s1 ⌢⟨p⟩⌢s2. By induction, s1 and s2 satisfy I , therefore s1 ⌢⟨p⟩⌢s2
satisﬁes I .
2
Proposition 22. If a process, p, has a priority, pr, such that, for any priority
queue, the value of pr is less than all of its elements, then p is the head of the
queue.
Proof.
By the ordering ≤P, pr is less than all the elements of procs, i.e.,
pr ≤P min ps, where ps = {p : PREF | p ∈ran procs • qprio(p)}, as above.
By the invariant, ⟨pr⟩⌢procs = procs′.
2

74
3 A Simple Kernel
Proposition 23. If a process, p, has a priority, pr, such that, for any priority
queue, the value of pr is greater than all of its elements, then p is the last
element of the queue.
When a process has executed, the next element has to be selected from
the priority queue. The operation to do this is:
NextFromPROCPRIOQUEUE
∆(procs, qprio)
pid! : PREF
procs = ⟨pid!⟩⌢procs′
qprio′ = {pid!} −◁qprio
The priority is updated as well as the sequence of queues.
Proposition 24. If an element, p, has been removed from a priority queue
and the priority of p is pr, then pr ≤head procs′.
Proof. If ⟨pr⟩⌢procs = procs′, then pr > ps (where ps is as in Proposition
22). By the invariant, I ,
qprio(head procs) ≤P qprio(head(tail procs))
⇒qprio(head(tail procs)) = min ps
Therefore, qprio(head(tail procs)) ≥P qprio(head procs).
2
The following pair of schemata deﬁne predicates. The ﬁrst, IsInPROCPRI-
OQUEUE, determines whether the process, pid?, is in the queue of processes.
The second is true when the process queue is empty.
IsInPROCPRIOQUEUE
pid? : PREF
pid? ∈ran procs
IsEmptyPROCPRIOQUEUE
procs = ⟨⟩
The following schema deﬁnes an operation to return the priority of the
process denoted by pid?:
PrioOfProcInPROCPRIOQUEUE
pid? : PREF
pprio! : PRIO
pprio! = qprio(pid?)

3.5 Priority Queue
75
Proposition 25. For any pair of processes, p1 and p2, that are both in the
same priority queue, if pr,1 < pr,2 (where pr,i denotes the priority of process
1 or 2), then p1 occurs before p2 in the queue; otherwise, the order in which
they occur is reversed.
Proof. This proposition is an immediate consequence of I .
2
The unready operation, among others, requires that processes be removed
from the priority queue. The operation to do this is modelled by the following
schema:
RemovePrioQueueElem
∆(procs, qprio)
pid? : PREF
procs′ = procs −▷{pid?}
qprio′ = {pid?} −◁qprio
There is the case in which a process’ priority is re-calculated at some time.
Such a re-evaluation will aﬀect the order in which the processes occur in the
queue. For the following, as for all process priority queue operations, it is
assumed that the priority value is established by a mechanism that is not
described by schemata in this section and that it is supplied to the operation
reordering the queue upon re-calculation.
It should be noted that the case in which more than one process’ priority is
re-calculated at a time does not cause any problems: if n processes have their
priority re-calculated, n iterations of the reorderProcPrioQueue are required.
Usually, however, re-calculations occur one at a time.
The following schema represents the desired operation:
reorderProcPrioQueue =
RemovePrioQueueElem o
9 EnqueuePROCPRIOQUEUE[newprio?/pprio?]
After substituting qprio′ for qprio′′ in the appropriate places, this expands
into:
reorderProcPrioQueue
∆(procs, qprio)
pid? : PREF
newprio? : PRIO
∃procs′′ : iseq PREF; qprio′′ : PREF  →PRIO •
procs′′ = procs −▷{pid?}
∧qprio′′ = {pid?} −◁qprio
∧qprio′ = qprio′′ ∪{pid? →newprio?}

76
3 A Simple Kernel
∧((procs′′ = ⟨⟩∧procs′ = ⟨pid?⟩) ∨(procs′′ = ⟨⟩
∧((qprio′(pid?) ≤P qprio′(head procs′′))
∧procs′ = ⟨pid?⟩⌢procs′′)
∨((qprio′(pid?) >P qprio′(last procs′′))
∧procs′ = procs′′ ⌢⟨pid⟩)
∨(∃s1, s2 : iseq PREF | s1 ⌢s2 = procs′′ •
(qprio′(last s1) ≤P qprio′(pid?) ≤P qprio′(head s2))
∧procs′ = s1 ⌢⟨pid?⟩⌢s2)))
This operation must, clearly, respect PROCPRIOQUEUE’s invariant, so
we have the following:
Proposition 26. ReorderProcPrioQueue respects PROCPRIOQUEUE’s in-
variant.
Proof. By Proposition 21, EnqueuePROCPRIOQUEUE respects the invari-
ant. It remains, therefore, to show that ReorderProcPrioQueue does.
Recall that ReorderProcPrioQueue is deﬁned as:
∆(procs, qprio)
p? : PREF
procs′ = procs −▷{p?}
qprio′ = {p?} −◁qprio
There are three cases to consider:
i. p? = head procs: this is clear;
ii. p? = last procs: this is clear;
iii. procs = s1 ⌢⟨p?⟩⌢s2: this is proved by induction.
It is clear that the composition implies the invariant.
2
Proposition 27. If a process, p, is removed from a priority queue, P, its
priority, pr, recalculated, and returned to P to form P′, then:
1. If the length of P is exactly 1, P′ = P.
2. If the length of P is exactly 2, then p is either the ﬁrst or last element of
P′.
Proof. There are two cases.
1. If p ∈P and #P = 1, then P = ⟨p⟩. This case is covered by Proposition
37 (ﬁrst case).
2. If P = ⟨p1, p2⟩, then it follows that if p = p1, p ≤P p2; otherwise, if p = p2,
p1 ≤P p. The result then follows by Proposition 21.
2

3.6 Current Process and Prioritised Ready Queue
77
Proposition 28. If a process, p, is removed from a priority queue, P, its
priority, pr, recalculated and is reinserted into P to form P′, provided that P
has more than one element, exactly one of the following holds:
1. If the new value of pr is less than the old one, p will appear closer to the
head of P′ than in P.
2. If the new value of pr is greater than the old one, p will appear closer to
the end of P′ than P.
3. If the new value of pr is the same as the old one, one of the two previous
conditions will hold.
Proof. By Proposition 21. The interesting case is case 3, whose proof follows
from ≤P.
2
Proposition 29. If a process, p, has priority, pr, is in a priority queue at
the nth position, if there are no processes of higher priority inserted into that
queue, and if the priority of p is not recomputed, process p will have the highest
priority after n processes have been removed from the queue.
Proof. This is just an instance of the corresponding proposition for FIFO
queues.
2
Proposition 30. If a process, p, is at the nth position in a priority queue
and if m processes, each with priority higher than p, are added to the queue,
p will then occupy position n + m in the queue, provided that the priority of
p is not recomputed.
Proof. Let procs = s1⌢⟨p⟩⌢s2 with #s1 = n. By Proposition 21 (case 2iii),
s′
1 = s1,1 ⌢sm ⌢s1,2, where #sm = m, and sn are sequences of new processes,
where s=s1,1 ⌢s1,2. (More simply but less generally assume s′
1 = s1 ⌢sm.)
If #s1 = n and #sm = m, and s1 = s1,1 ⌢s1,2 and #s1,1 +#s1,2 = n, then
#(s1,1 ⌢sm ⌢s1,2) = n + m. Since qprio(p) remains constant, the proposition
is proved.
2
3.6 Current Process and Prioritised Ready Queue
This is just a redeﬁnition of CURRENTPROCESS so that the ready is re-
placed by a priority queue. The result is still called CURRENTPROCESS.
Structural theorems carry over from PROCPRIOQUEUE.
The class CURRENTPROCESS represents the scheduler in this ker-
nel. The class contains a variable holding the currently executing process,
currentp, as well as the queue of ready processes (readyq, an instance of the

78
3 A Simple Kernel
PROCPRIOQUEUE class). The class exports two schemata that manipulate
currentp: CurrentProcess (which returns the value of currentp) and Make-
Current (which sets the value of currentp). The operation MakeReady adds a
process to the scheduler’s queue; to do this, the priority of the process must be
supplied. The ContinueCurrent is deﬁned: it is, in fact, the identity relation
and serves only to continue the execution of the current process. The Suspend-
Current operation removes the currently executing process but does not swap
in another process. The schema for RunNextProcess deﬁnes an operation that
takes the next element from the ready queue, ready, and sets currentp so that
the new process can be executed. The operation deﬁned by the schema called
SCHEDULENEXT is the primary interface to the scheduler.
Clearly, the scheduler needs to perform context operations. It is also clear
that it should use locking to ensure exclusive access to data structures.
CURRENTPROCESS
↾(INIT, CurrentProcess, MakeCurrent,
MakeReady, ContinueCurrent, SuspendCurrent,
RunNextProcess, SCHEDULENEXT)
currentp : PREF
readyqp : PROCPRIOQUEUE
ctxt : Context
lck : Lock
INIT
ct? : Context
lk? : Lock
readyqp.INIT
currentp′ = NullProcRef
lck ′ = lk?
ctxt′ = ct?
CurrentProcess = . . .
MakeCurrent = . . .
MakeReady = . . .
MakeUnready = . . .
isCurrentProc = . . .
reloadCurrent = . . .
ContinueCurrent = . . .
SuspendCurrent = . . .
RunNextProcess = . . .
selectIdleProcess = . . .

3.6 Current Process and Prioritised Ready Queue
79
SCHEDULENEXT = . . .
CurrentProcess
cp! : PREF
cp! = currentp
MakeCurrent
∆(currentp)
pid? : PREF
currentp′ = pid?
The MakeReady schema is deﬁned as follows:
MakeReady =
(∃pd : ProcessDescr •
ptab.DescrOfProcess[pd/pd!]
∧pd.ProcessPriority[prio/prio!]
∧pd.SetProcessStatusToReady
∧readyq.EnqueuePROCPRIOQUEUE[prio/pprio?]) \ {prio}
The MakeReady operation inserts a new process into the queue. As can be
seen, the priority of the process must be used to compute the point where the
process is to be inserted.
As can be seen, ContinueCurrent is the identity:
reloadCurrent
currentp′ = currentp
readyqp′ = readyqp
ContinueCurrent =
reloadCurrent
∧ctxt.RestoreState
The MakeUnready operation is deﬁned as:
MakeUnready =
lck.Lock o
9
((IsCurrentProc ∧
(ctxt.SaveState o
9 RunNextProcess)o
9
lck.Unlock)
∨RemovePrioQueueElem)o
9
lck.Unlock

80
3 A Simple Kernel
where:
isCurrentProc
ΞCURRENTPROCESS
p? : PREF
p? = currentp
This operation is used to remove a process from the readyq. It can be used,
for example, when a process has to wait on a device queue.
In this kernel, it is possible for a process to suspend itself. It does so by
calling the following operation:
SuspendCurrent =
lck.Lock o
9
((ctxt.SaveState
∧(∃pd : ProcessDescr •
ptab.DesrcOfProcess[currentp/pid?, pd/pd!]
∧((pd.ProcessPriority[prio/prio!]
∧pd.SetProcessStatusToWaiting)
∧readyqp.EnqueuePROCPRIOQUEUE[currentp/x?, prio/prio?])
\{prio}))o
9
RunNextProcess)o
9
lck.Unlock
The RunNextProcess operation calls the scheduler and executes the next
process. Note that it assumes that the context of the previously executing
process has been saved before this operation executes.
RunNextProcess =
SCHEDULENEXT o
9 ctxt.RestoreState
The primary interface to the scheduler is the following operation:
SCHEDULENEXT =
lck.Lock o
9
((∃pd : ProcessDescr •
ptab.DescrOfProcess[p/pid?, pd/pd!]
∧(¬ readyqp.IsEmptyPROCPRIOQUEUE
∧readyqp.NextFromPROCPRIOQUEUE[p/pid!]
∧readyqp.MakeCurrent[p/pid?]
∧pd.SetProcessStatusToRunning[p/pid?])
∨selectIdleProcess))o
9
lck.Unlock
The auxiliary operation, selectIdleProcess, is deﬁned as follows:

3.7 Messages and Semaphore Tables
81
selectIdleProcess
∆(currentp)
currentp′ = IdleProcRef
This operation is required to ensure that the idle process runs when there is
nothing to execute in readyq.
Proposition 31. If currentp = p, for some process reference, p : APREF,
then RunNextProcess implies that currentp′ ̸= p.
Proof. The proof divides into two cases.
Case 1. The ready queue is empty. Therefore, by SCHEDULENEXT:
readyqp.IsEmptyPROCPRIOQUEUE ∧selectIdleProcess
and currentp′ = IdleProcRef follows immediately.
Case 2. The ready queue is not empty. The following conjunction occurs in
the predicate of schema SCHEDULENEXT:
readyqp.NextFromPROCPRIOQUEUE ∧readyqp.MakeCurrent[p/pid?]
The operation NextFromPROCPRIOQUEUE removes the ﬁrst element from
the ready queue. This will, in general, be diﬀerent from the current value of
currentp.
2
3.7 Messages and Semaphore Tables
Semaphores have already been deﬁned. This kernel also requires asynchronous
message queues (mailboxes), according to the requirements. This section con-
tains the outline speciﬁcation for mailboxes.
First, the message type is deﬁned. Messages are composed of data (mod-
elled by the atomic type MSGDATA) and a record of the message’s source
(MSGSRC).
[MSGDATA]
A message can be sent by any “actual” process or by a hardware device.
MSGSRC == APREF ∪{hardware}
Putting these components together, we obtain MBOXMSG, the type of mes-
sages:
MBOXMSG == MSGSRC × MSGDATA

82
3 A Simple Kernel
The following (obvious) functions are deﬁned to assist in manipulating mes-
sages:
msgsender : MBOXMSG →MSGSRC
msgdata : MBOXMSG →MSGDATA
∀m : MBOXMSG •
msgsender(m) = fst m
msgdata(m) = snd m
The class that actually deﬁnes the mailbox type is as follows. The mailbox
is deﬁned in the obvious way as a queue of messages.
The class exports operations to add a message (PostMessage) and obtain
the next message from the mailbox (NextMessage) and an operation that
determines whether there are messages in the mailbox (HaveMessages). The
initialisation operation just clears the queue of messages.
Mailbox
↾(INIT, PostMessage, HaveMessages, NextMessage)
msgs : QUEUE[MBOXMSG]
lck : Lock
INIT
l? : LOCK
msgs.INIT
lck ′ = l?
PostMessage
m? : MBOXMSG
lck.Lock o
9 (msgs.Enqueue[m?/x?] o
9 lck.Unlock)
HaveMessages
lck.Lock o
9 ¬ msgs.IsEmpty o
9 lck.Unlock
NextMessage
m! : MBOXMSG
lck.Lock o
9 msgs.RemoveFirst[m!/x!] o
9 lck.Unlock
Each process can have no more than one mailbox in this kernel (it does not
need more than one). This suggests that:
•
An instance of GENTBL can be used to deﬁne and implement a central
table of mailboxes.

3.7 Messages and Semaphore Tables
83
•
APREF can be used for the key type in this table.
The table type requires the following operations: initialise, create a mailbox
for a process, delete a process’ mailbox and retrieve the mailbox upon demand.
The type will have, in addition, to ensure mutual exclusion so that, should
two processes attempt, say, to create a mailbox at the same time, only one
will succeed.
The deﬁnition of the mailbox table is relatively simple and is, in any case,
similar to the SemaphoreTable type, which will be deﬁned next.
Processes can also have one or more semaphores to provide synchronisation
on their shared data. The semaphore table contains all the semaphores in the
system that are available for use by processes. The table is an instance of the
generic GENTBL[K, D] class. Locking is used to ensure mutual exclusion.
The index type, SEMAID, is of little relevance. Processes will use values
of this type to refer to semaphores. It is deﬁned as an atomic type:
[SEMAID]
Semaphore identiﬁers can be assumed to be generated by:
GenSemaId
sid! : SEMAID
. . .
An inﬁnite number of semaphore identiﬁers is assumed. It is also assumed
that no identiﬁer is generated twice.
SemaphoreTable
↾(INIT, NewSemaphore, DelSemaphore, GetSemaphore)
lck : Lock
stbl : GENTBL[SEMAID, Semaphore]
INIT
l? : Lock
lck ′ = l? ∧stbl.INIT
NewSemaphore =
lck.Lock o
9
(∃s : Semaphore; sid : SEMAID •
s.INIT
∧GenSemaId[sid/sid!]
∧stbl.AddTBLEntry[sid/k?, s/d?]
o
9lck.Unlock

84
3 A Simple Kernel
DelSemaphore = lck.Lock o
9 stbl.DelTBLEntry[sid?/k?] o
9 lck.Unlock
GetSemaphore = lck.Lock o
9 stbl.GetTBLEntry[sid/k?, s!/d!] o
9 lck.Unlock
3.8 Process Creation and Destruction
In this kernel, processes are created statically, assigned a static priority and
linked to the kernel. This has the implication that process creation and termi-
nation primitives are not really required. However, it is necessary to commu-
nicate some basic parameters about each process to the kernel. This can be
done using the following operations (deﬁned, for convenience, inside an object
called UserLibrary).
The operations deﬁned below should be easily understood: their names
state what they should do.
UserLibrary
↾(INIT, CreateProcess, TerminateProcess, Suspend)
procid : IPREF
ptab : ProcessTable
sched : Scheduler
INIT
ptb? : ProcessTable
schd? : Scheduler
ptab′ = ptb?
sched ′ = schd?
CreateProcess
pprio? : PRIO
stkd? : PSTACK
datad? : PDATA
cdd? : PCODE
allocin? : MEMDESC
totmemsz? : N
pid! : PREF
∃pd : ProcessDescr; stat : PROCSTATUS | stat = pstnew •
pd.INIT[pprio?/pr?, stat/stat?, stkd?/pstack?,
datad?/pdata?, cdd?/pcode?, allocin?/mem?,
totmemsz?/msz?]
∧ptab.AddProcess[pd/pd?, pid!/p!] ∧sched.MakeReady[pid!/pid?]
∧procid ′ = pid!

3.9 Concluding Remarks
85
TerminateProcess =
sched.MakeUnready[procid/pid?] ∧
ptab.DelProcess[procid/pid?]
Suspend = sched.SuspendCurrent
3.9 Concluding Remarks
The kernel modelled in this chapter is extremely simple. It is not so simple
that it cannot be used. Indeed, it is of a complexity not far from that of the
tiny kernels used for embedded and some real-time systems. The µC/OS [18]
is a good example of such a kernel.
The kernel is minimal in the sense that it contains no facilities for per-
forming device-speciﬁc operations and contains no clock process. If the kernel
were to be used in reality, these operations would have to be modelled and
implemented. This would not be a particularly diﬃcult operation, for all the
necessary operations have been provided by the above model.
The kernel is also open as far as security is concerned. This is an area that
requires further development.
The above kernel is also a fairly static aﬀair. Processes are statically linked
to the kernel via a library of routines (basically the interface routines and the
small library deﬁned at the end of the last section). Processes are free to
change their priority and to create new processes when they are running but
this is subject to the constraint that all processes must always be resident in
main store.
Main store itself is partitioned statically as a conﬁguration operation when
user code is linked to the kernel. There are no storage-management operations
in this kernel, so the process creation primitives are, really, of limited use.
Even though the kernel is so limited, it is reasonable useful. In the next
chapter, a larger kernel, one that can perform storage management (it per-
forms process swapping) is presented and discussed.
Perhaps the most signiﬁcant aspect of this chapter’s model is that it acts
as an existence proof. It is possible to deﬁne a formal model of an operating
system kernel and to prove some of its properties. In the next chapter, the
model becomes more involved and more properties are proved. As noted in
the introduction, the general method of this book is to increase complexity
and to prove more properties (when appropriate) as the book progresses.

5
Using Messages in the Swapping Kernel
Hoc volo, sic iubeo, sit pro ratione voluntas
– Juvenal, Satires, 223
5.1 Introduction
The kernel that was the topic of the last chapter employed semaphores as
its inter-process communication primitive. In that kernel, semaphores were
used both to synchronise processes, as in the case of driver processes being
awakened by a semaphore shared with the corresponding ISR. Semaphores
were also used to synchronise processes that shared data; for example, the
clock driver and alarm requests.
Semaphores have, of course, a long and distinguished history, but they are
open to abuse. One must (almost) always ensure that the Wait and Signal
operations come in pairs. Sometimes, as was the case in the last chapter, the
two operations are applied to a single semaphore in two processes (as in the
driver wake-up method). It is all too easy to make mistakes in their use.
It was decided to base this chapter on a message-passing model. The model
adopted is synchronous message passing. The reason for using messages is
that they make inter-process interaction more explicit; this is reﬂected in the
organisation of the model. The presence of operations that send or receive
messages is much clearer, it seems to us, than the use of semaphores. Message
passing can also be integrated more easily with networked services than can
a semaphore-based scheme. The choice of synchronous message passing is
motivated by two facts:
•
It is easier to prove synchronous message-passing systems.
•
Synchronous message passing is often assumed by process algebras (of
particular relevance to this book is CCS [21]).
As is well known, message passing can be deﬁned in terms of semaphores
and semaphores can be implemented using messages. The two mechanisms are,

204
5 Using Messages in the Swapping Kernel
then, of equal power. However, as indicated in the last paragraph, spotting a
misuse of message-passing primitives is much easier than with semaphores.
The system modelled in this chapter is similar in many respects to Tan-
nenbaum’s Minix system [30], the precursor of Linux. The reason for this is
that we believe that Minix is one of the superior examples of the method.
(Xinu [9] is another clear example but one that does not draw as much from
message passing as does Minix). We are, in any case, more familiar with the
Minix kernel, another contributing reason for using it.
Although this chapter purports to contain the model of a kernel, it actually
does rather less. The primitive structures required to support a message-
passing model are presented. This model is interrupt-driven, so the model
of a generic ISR is also presented. The kernel in full is not modelled because
so much of it can be constructed with relative ease. Instead of showing every
single case of the use of messages, critical examples (e.g., the clock driver
process) are included. The chapter also includes essential modiﬁcations to
other structures required to model message passing.
The kernel is organised in a way identical to the kernel of the previous
chapter (Chapter 4). The only diﬀerence between the two is that, whereas the
kernel of Chapter 4 used semaphores, the current one uses messages. Figure
4.1 is therefore an adequate depiction of the current kernel.
5.2 Requirements
The requirement is to model an operating system kernel that is based upon
the exchange of messages between processes. The kernel should be an example
of the interrupt-driven variety. In this class of kernel, all context switches are
performed within ISRs and scheduling decisions only take eﬀect, therefore,
when the next interrupt is serviced. The scheduler can be called at many
places in the system so that the current needs are taken into account; however,
any scheduling decision taken outside of an ISR will, quite probably, be over-
ridden by the one made during the activation of the next ISR.
When a process sends a message, it raises an interrupt and uses the ISR
associated with it to perform the send operation. This provides a clear in-
terface and usage protocol for messages. It also ﬁts in well with the general
requirement that the kernel be interrupt-driven.
The kernel should include a clock process. The periodic nature of the clock
will ensure that some scheduling decisions take place; if there is no peripheral
activity, kernels such as this will do nothing. The clock should allow user and
other processes to request alarm calls.
The kernel should also support low-level storage management, very much
as did the kernel in the last chapter. Swapping, in the sense of the last chapter’s
kernel, can be included if desired.

5.3 Message-Passing Primitives
205
5.3 Message-Passing Primitives
The model begins with the speciﬁcation of the message-passing primitives and
their support in the kernel.
A type representing all messages is required. It is an atomic type and
deﬁned as:
[MSG]
It is necessary to determine the source of each message. Processes can receive
messages from ISRs and from other processes. The idle process can never
originate messages. Therefore, the message source type, MSGSRC, is deﬁned
as follows:
MSGSRC == {hardware, any} ∪APREF
The element any above is important because processes can state the identity
of the process from which they wish to receive their next message. There must
be a way to denote the fact that a process can state that it does not care where
the next message comes from: this is the role of any. This value is of some
importance when specifying the send and receive operations.
The attentive reader will observe that the model that follows does not, as
a matter of fact, type check as Z or Object-Z. The reason for this is that the
message operators are heavily overloaded; in order not to clutter the model,
the type MSG is deﬁned at the start and assumed for the message operators.
The overloading could have been handled in a variety of ways. It was decided
not to clutter the model with such details (they can be added with relative
ease). The use of overloading is, we believe, akin to the omission of errors in
the previous models (and, for that matter, in this one), something that can
be added later. For the present, the structures that model message passing
are the centre of interest, not the mechanisms of overloading.
The process descriptor structure must be modiﬁed to hold messages. It
is assumed that messages are stored in some kind of structure before they
are read; also, because it is a synchronous message-passing model, sending
processes must be suspended if the destination is not ready to receive from
them. There is a number of places where the message and the process queues
can be located within the kernel. However, it is clear that, wherever they are
stored, they should be somewhere that makes their association with source
and destination processes clear. The queue structures will, clearly, be shared
between every process in the system and must be protected in some fashion.
Locks will be used below because:
•
The message primitives are implemented at a level below that at which
full process abstraction is available (message passing is, in any case, a part
of the process abstraction in this kernel).
•
Messages are used to wake driver processes. They must be available to
ISRs.

206
5 Using Messages in the Swapping Kernel
•
The code segments implementing the message primitives are all relatively
short, so locking should not interfere too much with the overall perfor-
mance of the system. Moreover, messages are, themselves, passed via an
interrupt, so interrupts are disabled in any case.
For these reasons, it was decided to place the message structures in the process
descriptor of each process. This requires slight modiﬁcations to the process
descriptor object. The modiﬁcations are additions rather than deletions.
The ProcessDescr structure is deﬁned as follows. Rather than give the
entire class deﬁnition again, only those additions are shown below. The vari-
ables and operations omitted from the new ProcessDescr class deﬁnition are
denoted by . . .. The remainder of the class remains the same as it was in the
previous chapter. The reader can ﬁnd the assumed structure in Section 4.4.
The types used in the omitted parts of the class are exactly the same as in
Section 4.4.
ProcessDescr
↾(INIT, . . . ,
SetInMsg, InMsg, SetOutMsg, OutMsg, SetNextMsgSrc, NextMsgSrc,
WaitingSenders, AddWaitingSenders)
status : PROCSTATUS
kind : PROCESSKIND
schedlev : SCHDLVL
regs : GENREGSET
time quantum : TIME
statwd : STATUSWD
ip, memsize : N
stack : PSTACK
data : PDATA
code : PCODE
mem : MEMDESC
qinmsgbuﬀ, myoutmsgbuﬀ: MSG
nextmsgsrc : MSGSRC
waitingsenders : seq MSGSRC
INIT
. . . nextmsgsrc′ = any
waitingsenders′ = ⟨⟩
· · ·
SetInMsg = . . .
InMsg = . . .
SetOutMsg = . . .

5.3 Message-Passing Primitives
207
OutMsg = . . .
SetNextMsgSrc = . . .
NextMsgSrc = . . .
WaitingSenders = . . .
AddWaitingSenders = . . .
The class adds four variables to its state: inmsgbuﬀ, myoutmsgbuﬀ, nextmsgsrc
and waitingsenders, respectively. These components are interpreted, infor-
mally, as:
•
inmsgbuﬀ: A one-element buﬀer containing the most recently read mes-
sage; the process will copy the message into local store when it reads it.
Sender processes deposit their messages into this slot when message ex-
change occurs.
•
myoutmsgbuﬀ: A one-element buﬀer containing the next message this pro-
cess is to send.
•
nextmsgsrc: The identiﬁer of the process from which this process wants
next to receive a message. If this process is prepared to accept a message
from any source, this component has the value any.
•
waitingsenders: A sequence of elements of MSGSRC; that is, a queue
containing the identiﬁers of processes that are waiting to send a message
to this process.
The PROCSTATUS type needs to be extended:
PROCSTATUS ::= pstnew
|
pstrunning
|
pstready
|
pstwaiting
|
pstwaitingmsg
|
pstswappedout
|
pstzombie
|
pstterm
The additional state, pstwaitingmsg, is added. This is the state of a process
that is waiting to receive a message.
The operations required to support these additional components are now
deﬁned. They are all quite straightforward.
SetInMsg
∆(inmsgbuﬀ)
m? : MSG
inmsgbuﬀ′ = m?

208
5 Using Messages in the Swapping Kernel
This operation is to be executed when a sending process synchronises with
this process. By setting inmsgbuﬀto a message, this process has received the
message.
The receiving process executes the InMsg operation when it wants to read
the current message.
InMsg
m! : MSG
m! = inmsg
A sending process places the message it is trying to send in this compo-
nent of its process table. This component represents a standard location for
outbound messages; it is copied by the primitives to the inmsgbuﬀcomponent
of the receiver when the message is sent.
SetOutMsg
∆(outmsgbuﬀ)
m? : MSG
outmsgbuﬀ′ = m?
The following operation retrieves the contents of the outmsgbuﬀcompo-
nent of the process descriptor.
OutMsg
m! : MSG
m! = outmsgbuﬀ
This operation is called by a process when it advertises the identiﬁer of
the next process from which it wishes to receive a message. If the process is
willing to accept a message from any process or ISR, it supplies the value
any. If the process wishes to receive from some piece of hardware, it supplies
the value hardware (in general, a process will receive only from one piece of
hardware, e.g., the clock or a disk driver).
SetNextMsgSrc
msrc? : MSGSRC
nextmsgsrc′ = msrc?
This operation retrieves the value stored in nextmsgsrc. This is used to
determine which process to resume when waitingsenders is not empty.
NextMsgSrc
msrc! : MSGSRC
msrc! = nextmsgsrc

5.3 Message-Passing Primitives
209
As indicated before the schema, a search is made when waitingsenders is non-
empty to determine whether a process is to send its message to this process.
This operation returns the queue of the identiﬁers of those processes wait-
ing to send a message to this process.
WaitingSenders
sndrs! : seq MSGSRC
waitingsenders = sndrs!
When a process is sending a message to this process and this process is
unable to accept it, the sender is enqueued here.
AddWaitingSenders
∆(waitingsenders)
sndr? : MSGSRC
waitingsenders′ = waitingsenders ⌢⟨sndr?⟩
The ProcessTable is also the same except for some minor additions. As with
the ProcessDescr class, the class is presented below in outline form only and
shows only those components that are required to support message passing.
The rest of the deﬁnition can be found in Section 4.4 of Chapter 4.
The diﬀerences between the ProcessTable required by the previous ker-
nel and the present one consist in two operations—MessageForDriver and
AddDriverMessage, which manipulate messages whose destination is a driver
process—and in a new table, drivermsgs, which maps the identiﬁer of the
destination process (which should be the identiﬁer of a driver process) to the
next message it is intended to receive.
ProcessTable
↾(INIT,
. . .
MessageForDriver,
AddDriverMessage)
. . .
drivermsgs : APREF  →MSG
. . .
(∀p : APREF | p ∈dom drivermsgs •
(∃pd : ProcessDescr; k : PROCESSKIND •
DescrOfProcess[p/pid?, pd/pd!]
∧pd.ProcessKind[k/knd!]
∧k = ptdevproc))
. . .

210
5 Using Messages in the Swapping Kernel
INIT
. . .
dom drivermsgs′ = ∅
MessageForDriver = . . .
AddDriverMessage = . . .
Messages for drivers are handled slightly diﬀerently. The support for them
is provided by the following pair of operations.
MessageForDriver
pid? : APREF
dmsg! : MSG
dmsg! = drivermsgs(pid?)
AddDriverMessage
∆(drivermsgs)
pid? : APREF
dmsg? : MSG
drivermsgs′ = drivermsgs ⊕{pid? →dmsg?}
Driver messages must be treated diﬀerently because the driver might be
busy when the message is sent. Messages to drivers are of high priority and
must be delivered. Therefore, any messages with a driver as destination are
temporarily stored if the driver cannot immediately receive them.
There is a generic message-based ISR that responds to interrupts by cre-
ating and sending messages from hardware.
Process context manipulation must be redeﬁned to account for messages.
This is an interrupt-driven kernel, so the context switch is a logical place to
insert message-handling code.
The Context structure is the same as that deﬁned in the last chapter.
It is repeated here because it plays a central role in the modelling of the
message-passing subsystem. The class is
Context
↾(INIT, SaveState, RestoreState,
SwapOut, SwapIn, SwitchContext)
ptab : ProcessTable
sched : LowLevelScheduler
hw : HardwareRegisters

5.3 Message-Passing Primitives
211
INIT
ptb? : ProcessTable
shd? : LowLevelScheduler
hwregs? : HardwareRegisters
ptab′ = ProcessTable
sched ′ = LowLevelScheduler
hw ′ = hwregs?
SaveState = . . .
RestoreState = . . .
SwapOut = . . .
SwapIn = . . .
SwitchContext = . . .
The SaveState operation’s schema is very much as in the previous kernel.
Since it is relatively short, it is repeated here.
The SaveState and RestoreState operations are intended to be called from
within an ISR. The SaveState stores the contents of the hardware register in
the descriptor of the process referred to by currentp. The scheduler, just like
the one in Chapter 4, can then be called to select another process to execute
(if there are none, the idle process is run); as a part of this selection operation,
currentp becomes bound to the identiﬁer of the selected process. At the end,
RestoreState should be called to copy the newly selected process’ state to the
hardware.
SaveState
(∃cp : IPREF •
sched.CurrentProcess[cp/cp!]
(∃pd : ProcessDescr •
ptab.DescrOfProcess[cp/pid?, pd/pd!]
∧(∃regs : GENREGSET; stk : PSTACK;
ip : N; stat : STATUSWD; tq : TIME •
hw.GetGPRegs[regs/regs!] ∧hw.GetStackReg[stk/stk!]
∧hw.GetIP[ip/ip!] ∧hw.GetStatWd[stat/stwd!]
∧sched.GetTimeQuantum[tq/tquant!]
∧pd.SetFullContext[regs/pregs?, ip/pip?,
stat/pstatwd?, stk/pstack?, tq/ptq?])))
The current process referred to in the following schema is not necessarily
the same as the one referred to in the previous schema. Basically, whichever
process is referred to by currentp is the next to run and its context is switched
onto the processor. It should be noticed that the instruction pointer is the last

212
5 Using Messages in the Swapping Kernel
register to be set. This is because it hands the processor to the process that
owns it.
RestoreState
(∃cp : IPREF •
sched.CurrentProcess[cp/cp!]
∧(∃pd : ProcessDescr •
ptab.DescrOfProcess[cp/pid?, pd/pd!]
∧(∃regs : GENREGSET; stk : PSTACK; ip : N;
stat : STATUSWD; tq : TIME •
pd.FullContext[regs/pregs!, ip/pip!, stat/pstatwd!,
stk/pstack!, tq/ptq!]
∧hw.SetGPRegs[regs/regs?]
∧hw.SetStackReg[stk/stk?]
∧hw.SetStatWd[stat/stwd?]
∧sched.SetTimeQuantum[tq/tquant?]
∧hw.SetIP[ip/ip?])))
The general operation for swapping out a context is deﬁned by the next
operation:
SwapOut =
(∃cp : IPREF; pd : ProcessDescr •
sched.CurrentProcess[cp/cp!]
∧ptab.DescrOfProcess[pd/pd!]
∧pd.SetProcessStatusToWaiting
∧SaveStateo
9
sched.MakeUnready[currentp/pid?])
The operation calls SaveState and then unreadies the process referred to by
currentp.
Similarly, SwapIn is the general interface to the operation that swaps a
context onto the processor.
SwapIn =
(∃cp : IPREF; pd : ProcessDescr •
sched.CurrentProcess[cp/cp!]
∧pd.SetProcessStatusToRunning
RestoreState)
SwitchContext = SwapOut o
9 SwapIn
The low-level scheduler is identical to the one deﬁned in the last chapter
(Section 4.5).
This kernel requires a global variable to store clock ticks that might have
been missed by drivers that are not waiting when the clock interrupt arrives.
This variable is not protected by a lock. It is assumed that there is no need

5.3 Message-Passing Primitives
213
because it can only be accessed and updated under strict conditions (there can
be no other process active when update and read occur—this is guaranteed by
the fact that this kernel executes on a uni-processor; if the kernel were ported
to a multi-processor, matters might be a little diﬀerent).
GlobalVariables
↾(INIT, missed ticks)
missed ticks : N
INIT
missed ticks′ = 0
Finally, we come to the core of the model of message passing. This is the
generic ISR that sends messages to devices to wake them up. This is the most
detailed speciﬁcation of an ISR that has been given so far in this book. The
reason for this is that it is central to the operation of the message-passing
mechanism.
The generic ISR is modelled by the GenericMsgISR class as follows:
GenericMsgISR
↾(INIT, SendInterruptMsg)
did : APREF
mm : MsgMgr
ctxt : Context
busydds : F APREF
glovars : GlobalVariables
INIT
isrname? : APREF
msgmgr? : MsgMgr
ctxtops? : Context
gvs? : GlobalVariables
ctxt′ = ctxtops?
did ′ = isrname?
mm′ = msgmgr?
busydds′ = ∅
glovars′ = gvs?
saveState = . . .
restoreState = . . .
shouldRunDriver = . . .
SendInterruptMsg = . . .

214
5 Using Messages in the Swapping Kernel
Before discussing the more interesting points about this ISR, it is worth
pointing out that this model, like the others in this book, makes only minimal
assumptions about the hardware on which the kernel runs. In particular, it
is assumed that ISRs do not dump the hardware registers anywhere when an
interrupt occurs. It is merely assumed that, when the interrupt does occur,
a context will be current; that context is the interrupted one. It is also the
context that might be switched out, should the scheduler so determine.
It is worth remembering that the interrupt mechanisms of any particular
processor could diﬀer considerably from this one; it is a reliable assumption
that the contents of currentp will be unaﬀected by any interrupt. Where the
context is deposited by a particular cpu is a detail that cannot be accounted
for by this model. In what follows, it should be assumed that the state save
and restore operations are able to locate the registers belonging to the current
process; that is, to the process referred to by currentp.
saveState = ctxt.SaveState
This operation saves the current context in the descriptor of the process re-
ferred to by currentp when the interrupt occurs.
restoreState = ctxt.RestoreState
This is the operation that installs a context in the cpu. The process might be
diﬀerent from the one current when the interrupt occurred.
shouldRunDriver = sched.IsEmptyDriverQueue ∧sched.IdleIsCurrent
This operation forces the execution of the driver associated with this ISR if
the scheduler’s queues are empty and the idle process is currently running.
The driver will always have a higher priority than the idle process, so the net
eﬀect of this operation is to pre-empt the idle process’ execution. It is called
from the next operation.
The usual form of an ISR using messages is:
(* Current process is running. *)
SaveStateo
9
(* Do some processing and create message. *)
SendInterruptMsg o
9
(* A new process might be in currentp. *)
RestoreState
(* Possible new process executing. *)
The following operation sends a message to a process when the interrupt
occurs. The process will usually be the driver associated with the interrupt.
At the end of the operation, the shouldRunDriver operation is executed,
followed by a call to the scheduler.

5.3 Message-Passing Primitives
215
There is one more operation deﬁned in the class. It is the one deﬁned
next. This operation sends messages generated by ISRs. These messages are
used to wake the driver process that corresponds to a driver. The problem is
that the driver might have been interrupted or could even be blocked when
the message is to be sent. For that reason, the schema records the identiﬁer
of the destination driver when it is busy. In addition, the operation is used
by the clock ISR to send a message to the clock process. Given the above,
it is possible that some clock ticks might be missed, so each invocation of
the SendInterruptMsg operation adds 1 to a “missed tick” counter (called
missed ticks and deﬁned in the global variables class, GlobalVariables, deﬁned
immediately before the GenericMsgISR class).
SendInterruptMsg
∆(missedclicks, busydds)
driver? : APREF
m? : MSG
(∃dpd : ProcessDescr •
ptab.DescrOfProcess[did/pid?, dpd/pd!]
∧(¬ mm.IsWaitingToReceive[dpd/pd?]
∧((driver? = CLOCKISR
∧glovars.missed ticks′ = glovars.missed ticks + 1)
∨(busydds′ = busydds ∪{driver?}
∧ptab.AddDriverMessage[driver?/pid?, m?/dmsg?]))))
∧(∀p : APREF | p ∈busydds •
(∃pd : ProcessDescr •
∧ptab.DescrOfProcess[p/pid?, pd/pd!]
∧(mm.IsWaitingToReceive[pd/pd?]
∧(∃hwid : MSGSRC | hwid = hardware •
∧msgmgr.SendMessage[hwid/src?, p/dest?])))
⇒p ̸∈busydds′)
∧(shouldRunDriver ∧sched.ScheduleNext)
We are now in a position to prove some fairly general properties of the
message-passing system.
Proposition 112. The message-passing mechanism is synchronous.
Proof. By the predicates of SendMessage and RcvMessage.
If the destination is already waiting when the source sends a message, the
message is immediately received. Otherwise, the destination eventually enters
a waiting state, during which the message is exchanged.
2
Proposition 113. Unless the destination process terminates (or the system
is shut down), every message is delivered to its destination.

216
5 Using Messages in the Swapping Kernel
Proof. There are two cases to consider.
Case 1. If the destination is waiting to receive from either the sender or any
process (IsWaitingToReceive), the message is immediately copied to the des-
tination (SetInMsg). The sender is the current process and continues. The
message has been delivered.
Case 2. If the destination is not waiting, or waiting for a message from a
source other than the current process or the default source, any, the sender is
enqueued onto the destination’s queue (list) of processes that are waiting to
send a message to it; the sender is unreadied so that it cannot be scheduled.
When the destination is ready to receive a message, it selects a process
from its waiting list and adds it to the ready queue after the message has been
copied from the sender to the destination.
A receivers can specify the source of the message it wants to recevie next
(this is the sender’s process identiﬁer) or the special value any. If any is
speciﬁed, the receiver is willing to accept a message from any process that
wishes to send to it.
Provided that the receiver lives long enough and provided that the receiver
issues enough requests for any sender, all of the messages sent to the receiver
are received.
2
Proposition 114. Every device process receives its interrupt messages in the
correct order.
Proof.
This follows from the previous result. The diﬀerence is that In-
terrupt Service Routines (ISRs) are not processes and cannot, therefore, be
suspended. If the associated driver process is not yet ready to receive from
the ISR, the message is stored in a special location until it can be delivered
when a subsequent interrupt occurs.
2
Proposition 115. Every message sent is received in the correct order.
Proof. This follows from the behaviour of synchronous messages. Consider
two processes, S and D. Each time S sends a message, m, to D, either S
is suspended or the message is delivered; when S is resumed, the message
is delivered. If S sends two messages to D, say m1 and m2, in that order,
then S ﬁrst attempts to send m1. If D is waiting to receive, the message is
delivered and S continues; if D is not waiting to receive, S is suspended until
D is ready. In either case, message m1 is delivered. Next, S tries to send m2
and goes through the same sequence of operations and state transitions; m2
is delivered, however. The order in which the messages are delivered is m1
followed by m2. By induction, the order in which messages are received is the
same as the order in which they are sent.
2

5.3 Message-Passing Primitives
217
Proposition 116. Nothing happens in the system unless an interrupt occurs.
Proof. The critical part of this is: when do context switches occur?
In this kernel, a context switch occurs in the general ISR code. (In the
previous kernel, context switches occurred in ISR code and in the semaphore’s
Wait operation.)
When the generic ISR code runs, the actual context changes. First, the
register set is switched out; these registers belong to the process named by
the current value of currentp. The scheduler then executes and changes the
value of currentp; there can be more than one scheduling decision in this ker-
nel before the ISR exits, but the important fact is that these intermediate
scheduling decisions do not aﬀect the context. Indeed, only the last schedul-
ing decision (assignment to currentp) occurring before the ISR terminates is
switched onto the processor.
Since context switches change the state of the system and cause diﬀer-
ent processes to execute, and since context switches occur only in ISRs, the
proposition has been proved.
2
Proposition 117. Each interrupt causes a context switch. This alters the
currently running process.
Proof. The reasoning is similar to that of the previous proposition.
2
Finally, there are the operations to support message passing at the level
of the process. They are collected into the following object (module). This
is really more a matter of convenience than of anything else. The module is
called MsgMgr, the Message Manager.
As far as processes are concerned, this module contains the most important
operations. It is also a relatively complex module whose workings are, at ﬁrst
sight, somewhat obscure. Because of this, the operations deﬁned below are
described (perhaps painfully) in more detail.
MsgMgr
↾(INIT, IsWaitingToReceive, SendMessage, RcvMessage)
ptab : ProcessTable
sched : LowLevelScheduler
INIT
pt? : ProcessTable
schd? : LowLevelScheduler
ptab′ = pt?
sched ′ = schd?

218
5 Using Messages in the Swapping Kernel
IsWaitingToReceive = . . .
SendMessage = . . .
RcvMessage = . . .
isWaitingForSender = . . .
enqueueSender = . . .
canReady = . . .
haveMsgsWithAppropriateSrc = . . .
copyMessageToDest = . . .
RcvMessage = . . .
It must be remembered that the operations deﬁned by the MsgMgr class
are always called from inside an ISR. This has implications for the use of
context switches and the identity of callers and destinations.
IsWaitingToReceive
pd? : ProcessDescr
(∃stat : PROCSTATUS; wtgfor : PROCWAITINGON •
pd.ProcessStatus[stat/st!]
∧stat = pstwaitingmsg)
isWaitingForSender
pd? : ProcessDescr
sender? : APREF
(∃nxtsrc : MSGSRC •
pd?.NextMsgSrc[nxtsrc/msrc!]
∧(nxtsrc = any ∨nxtsrc = sender?))
enqueueSender
pd? : ProcessDescr
sender? : APREF
pd?.addWaitingSender[sender?/sndr?]
If a receiver is waiting for a message from a process and that process is
not in its waiters queue, it will be placed in “limbo”, i.e., removed from all
queues. When the message eventually arrives, it is put onto its ready queue
by SendMessage.

5.3 Message-Passing Primitives
219
SendMessage
dest?, src? : APREF
m? : MSG
(∃pd : ProcessDescr •
ptab.DescrOfProcess[dest?/pid?, pd/pd!]
(∃stat : PROCSTATUS; wtgfor : PROCWAITINGON •
pd.ProcessStatus[stat/st!]
∧((IsWaitingToReceive[pd/pd?]
∧isWaitingForSender
∧pd.SetInMsg
∧sched.MakeReady[dest?/pid?])
∨((pd.addWaitingSender[pd/pd?, src?/sender?]
∧sched.MakeUnready[src?/pid?])))))
The next operation to be deﬁned determines whether the process described
by the process descriptor bound to pd? can be moved to a pstready state.
canReady
pd? : ProcessDescr
(∃stat : PROCSTATUS •
pd?.ProcessStatus[stat/st!]
∧(stat ̸= pstterm
stat ̸= zombie))
haveMsgsWithAppropriateSrc
pd? : ProcessDescr
src? : MSGSRC
(∃waiters : seq APREF •
pd?.WaitingSenders[waiters/sndrs!]
∧waiters ̸= ⟨⟩
∧src? ∈ran waiters)
copyMessageToDest
cpd?, spd? : ProcessDescr
(∃m : MSG •
spd?.OutMsg[m/m!]
∧cpd?.SetInMsg[m/m?])
Note that if the receiver doesn’t have any appropriate senders, it is removed
from all queues.

220
5 Using Messages in the Swapping Kernel
RcvMessage
caller? : APREF
src? : APREF
m! : MSG
(∃cpd : ProcessDescr •
ptab.DescrOfProcess[caller?/pid?, cpd/pd!]
∧(∃waiters : seq APREF •
cpd.WaitingSenders[waiters/sndrs!]
∧((haveMsgsWithAppropriateSrc
∧(∀p : APREF | p ∈ran waiters •
(∃spd : ProcessDescr •
ptab.DescrOfProcess[p/pid?, spd/pd!]
∧(src? = any ∨src? = caller?
∧copyMessageToDest[cpd/cpd?, spd/spd?]
∧((canReady[spd/pd?] ∧MakeReady[p/pid?])
∨Skip)))))
∨sched.ScheduleNext)))
The operations deﬁned in this class are not designed to be executed di-
rectly. It is intended that they be executed by raising an interrupt. Therefore,
any user process must raise an interrupt to send a message and raise another
to read a message. When sending the message, the ISR has to retrieve the
message and the destination address from somewhere (say, some ﬁxed oﬀset
from the top of the calling process’ stack). In a similar fashion, when a process
performs a receive operation, the parameters must be in a standard location.
In order to make this clear (and to permit the proof of one or two relevant
propositions), the two interrupt-handling classes are deﬁned, one each for send
and receive. The reader should be aware that they are only deﬁned in outline
(this is, in any case, in line with our general policy on hardware matters). In
order to deﬁne them, it will be necessary to assume an operation:
RaiseInterrupt
ino? : N
. . .
This can be assumed to be a hardware operation (i.e., it can be modelled
as an operation provided by the HardwareRegisters class. The input to the
operation, ino?, is the number of the interrupt.
Both classes are subclasses of GenericISR, thus permitting the save and
restore operations on contexts.
The ﬁrst class is the one that implements the interface for sending mes-
sages. Its main operation, ServiceInterrupt handles the message by calling the
SendMessage operation deﬁned in the MsgMgr class.

5.3 Message-Passing Primitives
221
SendISR
↾(INIT, ServiceInterrupt)
GenericISR
mmgr : MsgMgr
sched : LowLevelScheduler
INIT
mm? : MsgMgr
sch? : LowLevelScheduler
mmgr ′ = mm?
sched ′ = sch?
ServiceInterrupt =
. . .
∧sched.CurrentProcess[mypid/cp!]
∧mmgr.SendMessage[mypid/src?, . . .]
. . .
The second class is the one that implements the interface for receiving mes-
sages. Its main operation, ServiceInterrupt, handles the message by calling the
RcvMessage operation deﬁned in the MsgMgr class. When a process is ready
to receive a message, it raises an interrupt, thus invoking the ServiceInterrupt
operation.
ReceiveISR
↾(INIT, ServiceInterrupt)
GenericISR
mmgr : MsgMgr
INIT
mm? : MsgMgr
mmgr ′ = mm?
ServiceInterrupt =
. . .
∧sched.CurrentProcess[mypid/cp!]
∧mmgr.RcvMessage[mypid/caller?, . . .]
. . .
It will be assumed that there is a mechanism by which kernel processes
can send and receive messages. Rather than performing a full system call, this

222
5 Using Messages in the Swapping Kernel
alternative mechanism will be used (it still performs a RaiseInterrupt). It will
be denoted by KMsgMgr.
Proposition 118. The sender of a message is always the current process.
Proof.
In order to send a message, the sending process must execute a
call that involves RaiseInterrupt in order to raise the interrupt associated
with message sending. However, the only process that can do this is the one
currently referenced by currentp since it denotes the only executing process
at any time.
Furthermore, the sender, src?, for the message to be sent is bound to the
value of currentp by sched.CurrentProcess.
2
Proposition 119. The receiver of a message is always the current process.
Proof. By reasoning similar to the ﬁrst paragraph of the previous proposi-
tion (the caller can be the only executing process on a uni-processor machine).
In this case, the caller? of the receive operation, mmgr.RcvMessage, is
bound to the value of currentp by sched.CurrentProcess.
2
Proposition 120. If a sending process is not one for which the destination
is waiting, the sender is removed from the ready queue.
Proof. The relevent class is MsgMgr and the relevant operation is, clearly,
SendMessage. The second disjunct of SendMessage’s predicate is as follows:
(¬ isWaitingToReceive[pd/pd?]
∨¬ isWaitingForSender)
∧pd.addWaitingSender[pd/pd?, src?/sender?]
∧sched.MakeUnready[src?/pid?]
This conjunct deals with the case in which the destination is either not in
the special waiting-for-message state or it is not waiting to receive from the
current process (that is, the process referred to by currentp). As can be seen,
the sender is made unready by the second conjunct. This removes it from the
head of the ready queue so that it cannot be rescheduled until the receiver is
ready for it.
2
Corollary 9. The sending process is always referred to by currentp.
Proof. By Proposition 118.
2
Proposition 121. When a process, d, receives a message, m, from a process,
s, m is placed into d’s incoming message slot.

5.3 Message-Passing Primitives
223
Proof. The signiﬁcant line of mmgr.RcvMessage is copyMessageToDest[. . .],
which expands into:
∃m : MSG •
spd?.OutMsg[m/m!]
∧cpd?.SetInMsg[m/m?]
where both cpd? and spd are process descriptors. With one more level of
expansion and simpliﬁcation, this becomes:
cpd.inmsgbuﬀ′ = spd?.outmsgbuﬀ
This is clearly the operation required in the statement of the proposition. 2
Proposition 122. If a process, d, is waiting for a message from any process
and there is a waiting sending process, s, the process s will be readied.
Proof. By the predicate of mmgr.RcvMessage, having copied the message
over, if the waiting process can be readied, it is placed in the ready queue by
MakeReady:
copyMessageToDest
∧((canReady[spd/pd?] ∧MakeReady[p/pid?] . . .
where spd is the process descriptor of the message source (sender process
descriptor) and p is its process identiﬁer.
2
It is necessary to make message passing easier to use in user-level processes.
In support of this, a new class is deﬁned. This new class, called UserMessages,
exports two operations, Send and Receive. The exported operations are in-
tended to place the parameters required by the send and receive operations
in an easily accessible place and raises the necessary interrupts. The class is
deﬁned in outline as:
UserMessages
↾(INIT, Send, Receive)
sendintno, recvintno : N
INIT
sendno?, recvno? : N
sendintno′ = sendno?
recvintno′ = recvno?
raiseSendInterrupt = RaiseInterrupt[sendintno/intno?, . . .]
raiseRcvInterrupt = RaiseInterrupt[recvintno/recvno?, . . .]
Send = raiseSendInterrupt[m?/msg?, . . .]
Receive = raiseRcvInterrupt[m!/msg!, . . .]

224
5 Using Messages in the Swapping Kernel
This deﬁnition is intended merely to give the reader an idea of what it should
look like. The state variables, sendinto and recvintno, denote the number
of the send and receive interrupts, respectively. The second argument to the
message-passing operations is the message being sent or received, respectively.
In both cases, there will be other parameters (e.g., for receiving, the origin of
the message can be speciﬁed).
The UserMessages class will be instantiated once in the kernel interface
library.
Before moving on, it is worth pausing to reﬂect at a high level on what
has been presented so far. The reader should note that the above model is
not the only one. The Xinu operating system [9] is also based on message
passing but does not integrate messages with interrupts and is, therefore, in
our opinion, a somewhat cleaner kernel design. However, many readers will, as
a result of reading standard texts, be of the (false) opinion that kernels must
be interrupt-driven. The kernel of the last chapter was driven, in part, by in-
terrupts and, in part, by semaphores (recall that semaphores cause a context
switch and a reschedule); many real-time kernels are also driven only partially
by interrupts. Nevertheless, many kernels are organised entirely around inter-
rupts. This approach has merits (uniformity and simplicity) when there are
interactive users hammering away at keyboards and torturing hapless mice!
The current kernel was intended to show how such kernels can be structured,
even if that structure becomes somewhat opaque in places; it is not intended
as a statement that this is how they must be organised. (For a completely
diﬀerent approach, Wirth et al.’s fascinating and elegant Oberon system
[35, 36] is recommended).
With these points noted, it is possible to move on to the use of the message-
passing subsystem as deﬁned above. The reader will be relieved to learn that
what follows is far less convoluted than that which has gone before. Indeed, it
is believed that the following models are cleaner and easier to construct and
understand than those deﬁned using semaphores.
5.4 Drivers Using Messages
In this section, the semaphore-based drivers from the swapping kernel are
presented in an altered form: they now use message passing. Because of its
centrality, the clock is the ﬁrst to be considered. This will be followed by the
swapper process, a process that turned out to be quite complex when deﬁned
in the last chapter.
Because these driver processes have already been presented in detail in the
last chapter, it is only necessary to cover those parts that diﬀer as a result of
the use of message passing. This will allow us to ignore the common parts,
thus simplifying the exposition.

5.4 Drivers Using Messages
225
5.4.1 The Clock
To begin the discussion, the constant ticklength is repeated. It is the amount
of time represented by a single tick of the clock:
ticklength : TIME
Next, a message type is deﬁned:
CLOCKMSG ::= CLKTICK⟨⟨TIME⟩⟩
CLOCKISR
↾(INIT, ServiceISR)
GenericISR
time : TIME
msgs : KMsgMgr
INIT
tm? : TIME
msgman? : MsgMgr
msgs′ = msgman?time′ = tm?
ServiceISR =
time′ = time + ticklengtho
9
(∃dest : APREF; m : CLOCKMSG |
dest = clock ∧m = CLOCKTICK⟨⟨time⟩⟩•
SendInterruptMsg[dest/driver?, m/m?])
Although logically correct, there are pragmatic issues that need to be
discussed. There are similar issues with the page-fault mechanism, which is
addressed in some detail in the next chapter. Meanwhile, the clock driver
process is presented.
The process is essentially the same as the one speciﬁed in the last chapter
(Section 4.6.3). The diﬀerence, of course, is that the process uses message
passing to communicate the current time and to record requests for alarms.
Alarms themselves are implemented in the same way as in the last chapter.
In order to implement message passing, it is necessary to provide an inter-
face to the internal kernel message manager, KMsgMgr, to the clock driver.
ClockDriver
↾(INIT, RunProcess)

226
5 Using Messages in the Swapping Kernel
swaptabs : ProcessStorageDescrs
msgman : KMsgMgr
lk : Lock
now : TIME
missing : TIME
alarms : APREF  →TIME
INIT = . . .
addAlarm = . . .
cancelAlarm = . . .
processRequests = . . .
alarmsToCall = . . .
updateSwapperTimes = . . .
getNextTick = . . .
RunProcess = . . .
The initialisation operation is basically the same as in the last chapter. It is
necessary, of course, to initialise the reference to the message manager.
The operation to inform the swapper process of the current time is now
implemented as a message-passing method. It is deﬁned as follows:
updateSwapperTimes =
swaptabs.UpdateAllStorageTimeso
9
(∃src, dest : APREF; m : MSG | src = clock ∧dest = swapper •
m = SWAPTIME⟨⟨now⟩⟩
∧msgman.SendMessage[dest/dest?, src/src, m/m?])
The main point about this operation is that it now constructs a message of
type SWAPTIME that contains the current time as its payload. The destina-
tion to which the message is to be sent is the swapper process.
As noted above, the SendMessage operation is implicitly overloaded.
The clock driver obtains the current time from the hardware clock via the
clock ISR, which sends a CLKTICK message to the driver process. Sending
this message is the main point of the ISR.
It should be noted that the entire clock could be implemented within
the ISR. This would lead to an implementation that could place reasonable
guarantees on alarms and on the time displayed by the clock. The clock in this
model, as in the last, is really organised to display the various interactions
between components and how they can be modelled formally. For this reason,
the optimisation remark below is of importance.
The CLKTICK message contains the current time in an appropriate form
(probably in terms of milliseconds). The missed ticks global variable is up-
dated just in case any drivers are unable to synchronise.

5.4 Drivers Using Messages
227
getNextTick =
(∃src, dest : APREF; cm : MSG; tm : TIME |
src = hardware ∧dest = clock •
msgmgr.RcvMessage[src/src?, dest/dest?, cm/m!]
∧cm = CLKTICK⟨⟨tm⟩⟩
∧missing = glovars.missed ticks
∧now ′ = now + missed ticks + tm
∧glovars.missed ticks′ = glovars.missed ticks −missing
This operation is another example of how the receiving process can request
the next message from a speciﬁc source, in this case from the clock (which
happens to be the clock ISR).
The main routine of this process is RunProcess. It implements an inﬁnite
loop (modelled by quantiﬁcation over an inﬁnite domain). The main routine
is resumed when the ISR sends it a message containing the current time. The
routine then disables interrupts and sends a message to update the swapper’s
tables; it also updates the current process quantum (this is a shared variable
in the scheduler, so access needs to be locked). The driver then decodes other
messages. If the message is of type NULLCLKRQ, it checks the alarms that
it needs to call and readies the processes that are waiting for them. Because
readying waiting processes alters the scheduler’s queues, the scheduler is called
to select a process to run after the driver suspends. If the message is an alarm
request (denoted by a message of type AT), the requesting process is added to
the alarm queue in the driver. Otherwise, the message is a NOTAT message;
this message type is used to cancel a previously requested alarm. In both
cases, processes waiting for alarms are readied and the scheduler is called.
Since these operations are within the scope of the universal quantiﬁer, the
process then waits for the next message from the ISR.
RunProcess =
(∀i : 1 . . ∞•
(getNextTick o
9
(lk.Lock o
9
(ptab.UpdateCurrentProcessQuanta[now ′/tm?]
∧updateSwapperTimes[now/tm?] ∧sched.UpdateProcessQuantum
∧lk.Unlock)))
∨((rq? = NULLCLKRQ ∧alarmsToCall ∧sched.ScheduleNext)
∨((rq? = AT⟨⟨p, t⟩⟩∧addAlarm[p/p?, t/tm?])
∨(rq? = NOTAT⟨⟨p, t⟩⟩∧cancelAlarm[p/p?, t/tm?])
∧alarmsToCall ∧sched.ScheduleNext)))
The main routine is organised as a three-way branch, or as three disjuncts:
1. The ﬁrst case handles messages from the clock ISR. This causes swapper
and quantum updates inside a lock.
2. The second case receives requests from processes needing an alarm.
3. The ﬁnal case receives requests from processes wanting to cancel previ-
ously requested alarms.

228
5 Using Messages in the Swapping Kernel
This organisation imposes no priorities on the messages. It is essential for the
clock to be able to respond to ISR messages but it must also be available
to handle alarm requests and cancellations. If the process waited for clock
ticks and then waited for requests and cancellations, it would only be able
to respond to the latter when a clock tick had awakened the process. It is
expected that alarms (and cancellations) will be comparatively rare and that
the probability that they will occur at the same time as a clock tick is low. It
is also expected that the time taken to execute the clock driver is very much
less than the time between clock ticks (if this turns out to be false, the driver
can be optimised by splitting it into two processes).
5.5 Swapping Using Messages
In this section, the various processes implementing the swapping process are
presented in an altered form: they now use message passing.
The swapper processes deﬁned in this chapter use message passing in-
stead of semaphores and shared variables. It is, therefore, necessary to deﬁne
message types.
The message types contain information required by the desired operation.
The request type (which is assumed to be a sub-type of MSG, so over-loading
is, again, implicit) is as follows:
SWAPRQMSG ::= NULLSWAP
|
SWAPOUT⟨⟨PREF × ADDRESS × ADDRESS⟩⟩
|
SWAPIN ⟨⟨PREF × ADDRESS⟩⟩
|
NEWSPROC⟨⟨PREF × RMEM ⟩⟩
|
DELSPROC⟨⟨PREF⟩⟩
An extra message type is required to replace the semaphore that indicated
that the image-copy operation has been completed (Section 4.6.1). Instead of
signalling on a semaphore, the disk process sends a message of the following
type to the swapper:
SDRPYMSG ::= DONE
SWAPDISKDriverProcess
↾(INIT, SwapDriver)
dmem : APREF  →RMEM
sms : SharedMainStore
msgmgr : KMsgMgr

5.5 Swapping Using Messages
229
INIT
store? : SharedMainStore
mm? : KMsgMgr
dom dmem′ = ∅
sms′ = store?
msgmgr ′ = mm?
writeProcessStoreToDisk = . . .
readProcessStoreFromDisk = . . .
deleteProcessFromDisk = . . .
handleRequest = . . .
SwapDriver = . . .
The SwapDriver operation is the main one of the process. It is deﬁned as
an inﬁnite loop whose body receives messages from swapdisk:
SwapDriver =
∀i : 1 . . ∞•
(∃src, dest : APREF; rq : SWAPRQMSG |
src = swapper ∧dest = swapdisk •
msgmgr.RcvMessage[src/src?, dest/dest?, rq/m!]
∧(rq ̸= NULLSWAP ∧handleRequest
∧(∃SDRPYMSG •
msgmgr.SendMessage[dest/src?, src/dest?, rpy/m?])))
As is common with such processes, the real work is performed by an op-
eration that is not the main entry point. In this case, it is handleRequest:
handleRequest
rq? : SWAPRQMSG
(∃p : APREF; start, end : ADDRESS; mem : RMEM •
rq? = SWAPOUT⟨⟨p, start, end⟩⟩
∧sms.CopyMainStore[start/start?, end/end?, mem/mseg!]
∧writeProcessStoreToDisk[p/p?, mem/ms?])
∨(∃p : APREF; ldpt : ADDRESS; mem : RMEM •
rq? = SWAPIN ⟨⟨p, ldpt⟩⟩
∧readProcessStoreFromDisk[p/p?, mem/ms!]
∧sms.WriteMainStore[ldpt/loadpoint?, mem/mseg?])
∨(∃p : APREF •
rq? = DELSPROC⟨⟨p⟩⟩∧deleteProcessFromDisk[p/p?])
∨(∃p : APREF; img : RMEM •
rq? = NEWSPROC⟨⟨p, img⟩⟩
∧writeProcessStoreToDisk[p/p?, img/img?])

230
5 Using Messages in the Swapping Kernel
The operation uses the type of the latest message to determine which action to
take (dispatches, that is, according to message type). Its deﬁnition is similar
to that in the previous chapter.
The swapper process is now as follows:
SwapperProcess
↾(INIT, SwapperProcess)
pdescrs : ProcessStorageDescrs
proctab : ProcessTable
sms : SharedMainStore
hw : HardwareRegisters
realmem : SharedMainStore
msgmgr : KMemMgr
INIT = . . .
requestWriteoutSegment = . . .
requestReadinSegment = . . .
SwapperProcess = . . .
SwapProcessOut = . . .
SwapCandidateOut = . . .
SwapProcessIn = . . .
SwapProcessIntoStore = . . .
DoDiskSwap = . . .
The operations of this process are similar to those in the semaphore-based
one. The primary diﬀerence is that messages are used instead of the semaphore
and shared variable.
The following operation is dispatched when a SWAPRQMSG is received.
It sends a SWAPOUT message to the swap-disk process and waits for the
SDRPYMSG to synchronise.
requestWriteoutSegment
p? : APREF
start?, end? : ADDRESS
(∃rq : SWAPRQMSG; src, dest : APREF |
src = swapper ∧dest = swapdisk •
rq = SWAPOUT⟨⟨p?, start?, end?⟩⟩
∧msgmgr.SendMessage[src/src?, dest/dest?, rq/m?]
∧(∃rpy : SDRPYMSG •
msgmgr.RcvMessage[dest/src?, src/dest?, rpy/m!]
∧rpy = DONE))

5.6 Kernel Interface
231
Operation requestReadinSegment is, again, a message-dispatched one that
sends a message to the swap-disk process.
requestReadinSegment
p? : APREF
loadpoint? : ADDRESS
(∃rq : SWAPRQMSG; src, dest : APREF |
src = swapper ∧dest = swapdisk •
rq = SWAPIN ⟨⟨p?, loadpoint?⟩⟩
∧msgmgr.SendMessage[src/src?, dest/dest?, rq/m?]
∧(∃rpy : SDRPYMSG •
msgmgr.RcvMessage[dest/src?, src/dest?, rpy/m!]
∧rpy = DONE))
This operation, like the previous one, shows how much can be done just by
exchanging messages. It also demonstrates how much clearer message-based
code is than that based on semaphores.
The ﬁnal operation of this subsection is the main one of the process. It
loops forever waiting for messages to arrive. It then calls DoDiskSwap to do
the real work.
SwapperProcess =
∀i : 1 . . ∞•
(∃src, dest : APREF; m : MSG |
m = dest = swapper ∧src = clock •
msgmgr.RcvMessage[/src?, /dest?, m/m!]
∧DoDiskSwap)
5.6 Kernel Interface
Some readers will have been wondering why a proper system interface has
not been deﬁned in any of the models so far. The ﬁrst kernel merits no such
interface: it is completely open (and, therefore, somewhat unsafe) so that it
can be as fast as possible. The second kernel is based on semaphores and
semaphores, as has been noted (probably too) often, are vital but low-level
primitives. A semaphore-based kernel interface was considered to be less clear
than one based on messages. It falls to this kernel to deﬁne a kernel interface
(much as it fell to the one in the last chapter to prove that semaphores behave
properly) because it can be deﬁned in a relatively clean fashion.
In order to deﬁne the kernel interface, it is necessary to be clear as to its
purpose. The interface provides those operations that can be executed by user
processes when they require kernel operations to be performed for them. The
operations that can be performed generally include such things as:
•
i.o operations, traditionally ﬁle operations.

232
5 Using Messages in the Swapping Kernel
•
read/write requests to communications networks (often expressed in terms
of protocol-speciﬁc operations).
•
requests to alter process priority (e.g., nice and renice in some versions
of Unix.
•
process creation and termination—creation requests can also create child
processes.
•
storage allocation and deallocation requests.
The kernel of this chapter, like the previous one, contains no ﬁle system
(for reasons given in Chapter 1) and contains no network interface (for reasons
of space1). Like the last kernel, all that the interface has to support is process
creation and termination. In both cases, there is no way to alter the priority
of a user process: it just remains a user-level process. The nice operation
is easy to implement: it is merely the inclusion of a lower-priority queue in
the scheduler. There is plenty, in any case, to do with process creation and
termination.
The operations to be included in the system calls for this kernel are the
ones that mostly constitute the process abstraction as far as user processes
are concerned. The primary operations are:
•
Create a new process.
•
Terminate a process.
The kinds of process that can be created are:
•
Create a process that can potentially have children (the usual case).
•
Create a child process.
These operations are immediately supported by the primitives deﬁned in the
last chapter. This is a process model that is supported by Unix and its deriva-
tives. When creating a child process, a ﬂag must be passed to the parent and
child processes so that they can determine the role they play. This is a simple
fork-join model. It is worth noting that message passing between processes in
this model is relatively simple: it can be arranged for the parent to receive
the identiﬁer of the child process (the child can also be passed the identiﬁer of
the parent so that two-way communication can be immediately established).
In addition, some systems (e.g., Windows) support a kind of process cre-
ation in which the newly created processes do not share code or data; they
are autonomous processes. In this kind of process model, the sub-processes
are able to communicate with their creator and with each other. To do this, it
is necessary to pass process identiﬁers between the processes so that messages
can be exchanged. The management of such matters as termination among
autonomous communicating processes is usually left to the programmer. This
is what will be done in this chapter.
1 It would be extremely interesting to model one, but that is for another day.

5.6 Kernel Interface
233
In order to provide these operations, a set of parameters must be deﬁned
for each operation. In each case, the identiﬁer of the newly created process is
returned.
It is easy enough to arrange for processes to create other processes. The
question arises as to how a completely new process is created (i.e., a process
that is not created by another). One way to do this is to have a general root
process that receives creation messages; another is to introduce a command
interface. Here, the nature of the process is ignored. It is just a process that
calls the necessary library routines; no urprocess is, therefore, deﬁned. What-
ever approach is adopted, a library of operations must be provided to perform
all interface operations. A call to a library operation will actually cause the
requesting messages to be sent to the kernel (this is, in essence, what the
Mach kernel does). The library is the real focus of attention in this section.
The basis of the library is a set of message types. Each type represents an
operation to be performed by the kernel. In addition to these messages, there
must be one or more processes that are able to receive and interpret these
messages. The library will have to access the storage on which each process’
code is stored. Since this store is outside the scope of this model, it must be
assumed that the library has already accessed this store and obtained basic
parameters from it before the following messages are sent to the kernel. (It
should be noted that obtaining this data might also involve kernel operations
that are not deﬁned here.)
The messages contain the parameters for the operations to be performed.
In each case, the message contains the identiﬁer of the sending process. It
also contains two natural numbers (elements of N). They denote the size of
the data area and the size of the stack area that are, respectively, required
by the new process. The last message type just has a process reference as its
payload: it is the identiﬁer of the process that is to terminate. The creation
message types also contain a ﬁrst component of type PCODE: this is the code
of the process that is to be created. The reader should note that what is going
on is actually a conﬂation of the process-creation and code-loading functions.
Since no loading operation is speciﬁed here (because no external storage media
have been speciﬁed), it is not possible to specify something like a ﬁle name
instead of a complete chunk of code2. Alternatively, the operations provided
here could be seen as being at a level that is lower than the one called by
user processes. The purpose of the speciﬁcation presented here is to show the
reader how it can be done in principle, not to give the exact details—given
message passing, it is a relatively easy process to deﬁne an interface between,
2 In any case, kernels might vary in the way in which code is stored. Some might
store it in FLASH; others might, for instance, use a network interface to a SAN.
The conventional method is to employ a ﬁle store but a database is equally
possible. For present purposes—the modelling of kernels that are free from things
like ﬁle systems—the approach adopted here seems quite reasonable.

234
5 Using Messages in the Swapping Kernel
say, a ﬁle system and the creation operation. This is not done for the reasons
given here and elsewhere in this book.
SYSCALLMSG ::= CRTPROC⟨⟨APREF × PCODE × N × N⟩⟩
|
CRTCHLD⟨⟨APREF × PCODE × N × N × N⟩⟩
|
TERMPROC⟨⟨APREF⟩⟩
. . .
These messages will generate reply messages. In most cases, if the oper-
ation succeeds, the identiﬁer (of type APREF) of the newly created process
will be returned, together with other information.
SYSRPY ::= NEWPROC⟨⟨APREF × APREF⟩⟩
|
NEWCHLDPROC⟨⟨APREF × APREF⟩⟩
. . .
The messages contain the identiﬁer of the newly created process and the
identiﬁer of the process that made the creation request; in addition, they
contain a natural number that is a code returned by the operation.
When creating processes, it is important for the creating process to have
the identiﬁer of the process just created. This enables the two processes to
communicate using messages; it also allows the creating process to communi-
cate the identiﬁer of the newly created process to other processes; and ﬁnally,
the newly created process’ identiﬁer can be stored in a table by its creating
process.
User interface operations are all collected into a single library. As usual,
this library will be represented as a class. The class takes as initialisation
parameters the following: the identiﬁer of the process to which it is linked
(mypid), a pointer to the message manager module (msgman), and the iden-
tiﬁer of the process handling system calls (kernitﬁd).
SysCallLib
↾(INIT, UserCreateProcess, UserCreateChildProcess, TerminateProcess, . . .)
mypid : APREF
msgman : UserMsgMgr
kernintﬁd : APREF
INIT
me? : APREF
mm? : UserMsgMgr
intﬁd? : APREF
mypid ′ = me?
msgman′ = mm?
kernintﬁd ′ = intﬁd?

5.6 Kernel Interface
235
UserCreateProcess = . . .
UserCreateChildProcess = . . .
TerminateProcess = . . .
. . .
The class seems a little impoverished, dealing, as it does, only with pro-
cess creation and termination. In most systems, the kernel also handles I/O
requests, often at the level of the ﬁle system. The above class is included as
an illustration of what can be done and could, without too much eﬀort, be
immediately extended to include calls that perform I/O operations at a level
just above the drivers; indeed, I/O operations of considerable sophistication
could be provided, as well as operations, say, on streams (i.e., sequences of
messages). This whole issue has been ignored because we still have not settled
the question of which devices are being managed by this system.
In each case, the creation operations just create a message and send it to
the kernel. They then wait for a reply that contains the identiﬁer of the newly
created process. The operations are deﬁned as follows.
The ﬁrst operation is the user-level process-creation operation. It requests
the creation of a separate process, requiring the code (code?), size of data
(datasize?) and stack (stacksize?) areas, respectively, and returns the identiﬁer
of the newly created process (newpid!).
UserCreateProcess
code? : PCODE
datasize?, stacksize? : N
newpid! : APREF
(∃m : SYSCALLMSGm = CRTPROC⟨⟨code?, stacksize?, datasize?⟩⟩•
msgman.SendMessage[mypid/src?, kernintﬁd/dest?, m/m?])
o
9(∃rpmsg : SYSRPY ; newid : APREF •
msgman.RcvMessage[kernintﬁd/src!, mypid/dest?, rpmsg/m!]
∧rpmsg = NEWPROC⟨⟨newid⟩⟩
∧newpid! = newid)
The second operation creates a child process. It requests the creation of a
process that will share code with the calling process (which should supply a
pointer to its own code segment as code?); the remainder of the arguments are
the same. The identiﬁer of the newly created process is returned as newpid!.

236
5 Using Messages in the Swapping Kernel
UserCreateChildProcess
code? : PCODE
datasize?, stacksize? : N
newpid! : APREF
(∃m : SYSCALLMSG | m = CRTCHLD⟨⟨code?, stacksize?, datasize?⟩⟩•
msgman.SendMessage[mypid/src?, kernintﬁd/dest?, m/m?])
o
9(∃rpmsg : SYSRPY ; newid : APREF •
msgman.RcvMessage[kernintﬁd/src!, mypid/dest?, rpmsg/m!]
∧rpmsg = NEWCHLDPROC⟨⟨newid⟩⟩
∧newpid! = newid)
The termination message is sent by the following operation:
TerminateProcess
mypid? : APREF
(∃m : SYSCALLMSG | m = TERMPROC⟨⟨mypid?⟩⟩•
msgman.SendMessage[mypid/src?, kernintﬁd/dest?, m/m?])
The caller does not wait for a reply. When this message is sent, it is all over
as far as the caller is concerned!
The kernel supports a single process that receives the requests sent by
SysCallLib’s operations. In the version presented here, it is just a loop that
receives messages and performs the appropriate operations. This is very sim-
ple, of course, and no checking is performed; the process could do other things
and engage in message exchange with processes inside the kernel in a more
sophisticated version. Again, the point, here, is to demonstrate the principles.
The process is called KernIntf. It is deﬁned by the following class:
KernIntf
↾(INIT, RunProcess)
mypid : APREF; msgman : UserMessages; procmgr : ProcessCreation
INIT
me? : APREF
mm? : UserMessages
pcr? : ProcessCreation
mypid ′ = me?
msgman′ = mm?
procmgr ′ = pcr?

5.6 Kernel Interface
237
RunProcess =
∀i : 1 . . ∞•
(∃m : SYSCALLMSG •
msgmgr.RcvMessage[mypid/caller?, src/src?, m/m!]
∧((∃src : APREF; stcksz, datasz : N;
code : MEM ; newpid : APREF •
m = CRTPROC⟨⟨src, code, stcksz, datasz⟩⟩
∧procmgr.CreateUserProcess
[code/code?, stcksz/stacksize?,
datasz/datasize?, newpid/newpid!]
∧(∃crmsg : SYSRPY | crmsg = NEWPROC⟨⟨newpid⟩⟩•
msgmgr.SendMsg[mypid/src?, src/dest?, crmsg/m?]))
∨(∃src : APREF; stcksz, datasz : N;
code : MEM ; newpid : APREF •
m = CRTCHLD⟨⟨src, code, stcksz, datasz⟩⟩
∧procmgr.CreateChildUserProcess
[code/code?, stcksz/stacksize?, datasz/datasize?,
src/rqprocid?, newpid/newpid!]
∧(∃retmsg : SYSRPY |
retmsg = NEWCHLDPROC⟨⟨newpid⟩⟩•
msgmgr.SendMsg[mypid/src?, src/dest?, retmsg/m?]))
∨(∃tpid : APREF •
m = TERMPROC⟨⟨tpidsrc⟩⟩
procmgr.TerminateProcess[tpid/p?])
∨. . .))
The class is incomplete because it does not handle any requests other than
user-process creation and termination. With the exception of sending and
receiving messages, the kernel does not contain any other services that would
be useful to user processes. The message-passing operations are not included
because they are obvious given the above deﬁnitions.
It is now possible to state an important proposition about the kernel.
Proposition 123. Only one user process can be in the kernel at any one time.
Proof. First, it is necessary to clarify what is meant by the statement of the
proposition. What is intended by the proposition is the following: at any one
time, it is possible for at least one and at most one system call to be processed.
Since system calls are: (i) procedure calls and (ii) requests for the kernel to
perform some action (as deﬁned by the system call library, SysCallLib, as the
sketch-form adopted here is called).
As a procedure call, any system call can belong to a single thread of exe-
cution only. This implies that exactly one process at a time can be performing
the system call.

238
5 Using Messages in the Swapping Kernel
The procedures comprising the system-call library all send and receive
messages. Therefore, the rest of the proof must be in terms of the properties
of the message-passing subsystem.
The message-passing subsystem is driven by interrupts (Proposition 116)
and only one interrupt can be serviced at any time (this is an informal property
of interrupts). Therefore, while any user process is sending (or receiving) a
message, there can be no other process performing the same operation (more
generally, there can be no other process performing any operation).
By Proposition 114, messages are processed in the order in which they are
received. By inspection of the system-call operations, each is structured as a
message send followed by a message receive. Furthermore, message passing is
synchronous by Proposition 112.
The system calls are implemented by a process that just waits for messages,
services them and returns the reply. Therefore, until a system call has been
completed, it is not possible for the caller to proceed. Furthermore, by the
organisation of the message-passing subsystem, it is not possible for another
user process to proceed until the KernIntf process has replied to a message.
The remainder of the kernel will have its operations hidden by syntactic
methods and only imported by the KernIntf process.
2
Corollary 10. Message passing can be used to implement mutual exclusion.
Proof. By Propositions 112 and 114.
2

6
Virtual Storage
Nil posse creari de nilo
– Lucretius, De Rerum Natura, I, 155
6.1 Introduction
In this chapter, mechanisms to support virtual storage will be modelled. Vir-
tual storage aﬀords a considerable number of advantages to the operating
system designer and user. Virtual storage is allocated in units of a page and
pages can be collected into independent segments; virtual storage deﬁnes clear
boundaries between address spaces so that each process can maintain its own
address space. This clearly provides a measure of protection between processes
but requires additional methods for exchanging data between processes.
In virtual storage systems, main store is shared between processes in the
usual way but is deﬁned as a sequence of page frames, each a block of store
one page long. The storage belonging to each process is swapped into main
store when required and copied to a paging disk (or some other mass-storage
device) when not required. Strategies for selecting pages to copy to the paging
disk and for determining which page to bring into main store must be deﬁned.
6.2 Outline
The storage system to be designed is to have the following features:
•
The virtual store should have four segments: one each for code, data, stack
and heap.
•
The system uses demand paging with reference counting for victim selec-
tion.
•
Pages can be shared (and unshared) between processes.
•
Segments can be shared (and unshared) between processes;

240
6 Virtual Storage
•
Storage should be mapped in the sense that disk blocks can be directly
mapped to main-store pages and vice versa.
•
Message passing will be used for IPC.
The virtual storage system is composed of:
•
A page-fault handler. This is invoked when a page fault occurs. It deter-
mines the identity of the logical page that caused the page fault. It invokes
the page-fault driver process and passes to it the identiﬁer of the faulting
process and the page number. It unreadies the faulting process.
•
A page-fault driver. This takes a message from the page-fault ISR and
sends a message to the paging disk to retrieve the page whose reference
caused the fault. If there are no free page frames in (main) physical store,
it selects a victim page in physical store and sends it to the paging disk.
When the faulting page is received from the paging disk, it is copied into a
main store page whose physical address is identiﬁed with the logical page
number in the faulting process. The faulting process is then readied and
the driver waits for the next page fault.
The above scheme is sub-optimal. As part of the model, optimisations
are suggested, particularly for the interactions between the driver and paging
disk.
Even though it is sub-optimal, the above scheme is logically suﬃcient. It is,
therefore, appropriate to concentrate on it as the model for this chapter. This
exempliﬁes the method adopted in this book: capturing the logical functioning
of the model is much more important than optimisation. The optimisation
included here is introduced as an example of how it can be done without too
much of a compromise to the model.
The structure of this kernel is shown in Figure 6.1. Comparison of this
ﬁgure with the corresponding one in Chapter 4 (Figure 4.1) reveals their
similarities. In the current kernel, virtual and not real storage forms the basis
of the system. Apart from the need for structures and operations to support
virtual storage (the subject of this chapter), the main diﬀerence lies in the
kernel bootstrapping operations (which are not considered in this book).
6.3 Virtual Storage
In this section, the basic structures required to model a virtual store are
introduced.
The following axiomatic deﬁnition deﬁnes the number of real pages (pages
in real store or physical pages) and the size of the page frame. Neither constant
is assigned a value, so the speciﬁcation is of the loose variety.
numrealpages : N
framesize : N
The basic virtual address is represented by an atomic type:

6.3 Virtual Storage
241
ISR
ISR
TLB
Clock
IPC
Process Abstraction
V-Store Manager
i/o r/gs
System
Calls
User
Processes
alarms
Context
Switch
Process
Table
Device
Processor
Page
Tables
Physical
Store Mgr.
Kernel Interface
Routines
Paging
Disk
Process
Page
Placement
Clock
Process
Low-Level
Scheduler
Page Fault
ISRs
Kernel
Primitive
System
Processes
Pages locked in store
(Always resident)
Pages not locked in store
(Temporarily resident)
…
…
Fig. 6.1. The layer-by-layer organisation of the kernel, including virtual storage-
management modules.

242
6 Virtual Storage
[VIRTUALADDRESS]
maxvirtpagespersegment : N
This is the maximum number of virtual pages that a process can own.
PAGEOFFSET == 1 . . framesize
PHYSICALPAGENO == 1 . . numrealpages
LOGICALPAGENO == N
where:
•
PAGEOFFSET denotes the oﬀsets into a page;
•
PHYSICALPAGENO denotes the indices of pages in the main-store page
frame;
•
LOGICALPAGENO denotes the indices of logical pages (pages belonging
to a process).
Note that LOGICALPAGENO is not bounded above. The reason for this is
that the actual number of logical pages that a process can have is a hardware-
dependent factor and is not relevant to the current exercise.
For every virtual address, the hardware performs an address translation
that maps the virtual address to a logical frame number and an oﬀset into
that frame. The signature of this function, addresstrans, is:
addresstrans : VIRTUALADDRESS →DECODEDADDRESS
The deﬁnition of this function is hardware-speciﬁc and is, in any case, not
particularly relevant to the current exercise.
The type DECODEDADDRESS is deﬁned as:
DECODEDADDRESS == LOGICALPAGENO × FRAMEOFFSET
and has the following projections:
dlogicalpage : DECODEDADDRESS →LOGICALPAGENO
dpageoﬀset : DECODEDADDRESS →PAGEOFFSET
∀addr : DECODEDADDRESS •
dlogicalpage(addr) = fst addr
dpageoﬀset(addr) = snd addr
For a segmented, paged architecture, the address-decoding function can
be deﬁned as:
saddresstrans : VIRTUALADDRESS →SDECODEDADDRESS
where:

6.3 Virtual Storage
243
SDECODEDADDRESS == SEGMENT × LOGICALPAGENO × PAGEOFFSET
and:
saddrseg : SDECODEDADDRESS →SEGMENT
spageno : SDECODEDADDRESS →LOGICALPAGENO
spagoﬀset : SDECODEDADDRESS →PAGEOFFSET
∀saddr : SDECODEDADDRESS •
saddrseg(saddr) = fst saddr
spageno(saddr) = fst(snd saddr)
spagoﬀset(saddr) = snd 2 saddr
The PAGEMAP translates logical to physical page numbers. PAGE-
FRAME translates physical page numbers to the actual pages in store. Finally,
PAGE deﬁnes a storage page as a vector of PSU ; the vector has PAGEOFF-
SET elements. (PSU is, it will be recalled, the Primary Storage Unit, which
is assumed to be a byte.)
PAGEMAP == LOGICALPAGENO  →PHYSICALPAGENO
PAGEFRAME == PHYSICALPAGENO →PAGE
PAGE == PAGEOFFSET →PSU
The empty page is deﬁned as follows:
NullPage : PAGE
NullPage = (λ i : PAGEOFFSET • 0)
It is a page (vector of bytes), PAGEOFFSET bytes long, with each byte set
to zero.
Pages are associated with a number of ﬂags, including, among others:
•
in core (i.e., in main store);
•
locked In (i.e., must always remain in main store);
•
shared (i.e., shared between at least two processes).
For each process, these properties can be represented by sets (thus simplifying
the modelling of pages).
For the remainder of this section, a segmented virtual store will be mod-
elled. The hardware nearest to the model presented here is the Intel X86
series. The reader is warned that this is a logical model of segmented, paged
storage, not an exact rendition of any existing hardware implementations.
Furthermore, details such as the Translation Lookaside Buﬀer, or TLB, (the
associative store that typically holds a few entries from the current process’
page table) are not modelled in detail, the reason being that, as usual, hard-
ware diﬀers considerably in implementation and, in particular, the size of the
TLB can vary considerably among MMUs1.
1 Memory Management Unit.

244
6 Virtual Storage
Although most segmented hardware supports more than four segments
per process, for the present, only three segments will be considered. Linux on
X86 requires three segments: one each for code, stack and data, although the
hardware permits a maximum of 16 segments (the virtual address size is 32
bits). The segment names are as follows:
SEGMENT == {code, data, stack, heap, . . .}
A great many programming languages now require heap (dynamic) storage.
A problem for dynamic store, as with stacks, is that, quite frequently, it has
to be expanded. Within a three-segment organisation, the heap is part of
either the stack or data segment; this can limit the maximum size of the
heap somewhat on 32-bit machines. To simplify manipulation, it is assumed
here that the data segment contains static data (global variables, literal pools,
ﬁxed-length buﬀers and so on) and the heap is given its own segment. The
heap can, therefore, grow to the maximum segment size at runtime, as can
the stack segment.
usedsegment : SEGMENT
∀s : SEGMENT •
usedsegment(s) ⇔s ∈{code, data, stack, heap}
It is now possible to deﬁne per-process page tables.
Each segment is composed of a number of pages. The following function
translates a physical address and segment into a logical page number:
pages in segment : APREF × SEGMENT ×
(APREF  →SEGMENT  →F LOGICALPAGENO) →
F LOGICALPAGENO
∀p : APREF; sg : SEGMENT; f : APREF  →SEGMENT  →
F LOGICALPAGENO •
pages in segment(p, sg, f ) = f (p)(sg)
The following (inverse) functions mark and unmark pages. They
are
higher-order functions that take the speciﬁcation of a page and a page at-
tribute map as arguments and return the modiﬁed page attribute map.
mark page : APREF × SEGMENT × LOGICALPAGENO×
(APREF  →SEGMENT  →F LOGICALPAGENO) →
(APREF  →SEGMENT  →F LOGICALPAGENO)
unmark page : APREF × SEGMENT × LOGICALPAGENO×
(APREF  →SEGMENT  →F LOGICALPAGENO) →
(APREF  →SEGMENT  →F LOGICALPAGENO)
∀p : APREF; sg : SEGMENT; lpno : LOGICALPAGENO;
f : APREF  →SEGMENT  →F LOGICALPAGENO •
mark page(p, sg, lpno, f ) = f (p) ⊕{sg →(f (p)(sg) ∪{lpno})}
unmark page(p, sg, lpno, f ) = f (p) ⊕{sg →(f (p)(sg) \ {lpno})}

6.3 Virtual Storage
245
It is now proved that these two functions are mutual inverses.
Proposition 124. mark page and unmark page−1 are mutually inverse.
Proof. Write f (p)(sg) = h, then:
mark
= f (p) ⊕{sg →(h ∪{lpno})}
unmark = f (p) ⊕{sg →(h \ {lpno})}
Calculating the value of unmark ◦mark, we obtain:
(f (p) ⊕{sg →(h ∪{lpno})}) ⊕{sg →(h \ {lpno})}
Writing f (p)(sg) = s, then mark = s ∪{lpno} and unmark = s \ {lpno}, so:
unmark ◦mark
= (s \ {lpno}) ◦(s ∪{lpno})
= (s ∪{lpno}) \ {lpno}
= s
Conversely:
mark ◦unmark
= (s ∪{lpno}) ◦(s \ {lpno})
= (s \ {lpno}) \ {lpno}
= s
Therefore, mark and unmark are mutual inverses and the proposition is
proved.
2
The page table abstraction can be modelled as follows. The variable free-
pages represents those pages in main store that are not allocated to any
process. The page table proper is pagetable. The variables executablepages,
writablepages and readablepages are intended to refer to pages the owner has
marked executable (i.e., code pages), read-only (e.g., a constant data seg-
ment) and read-write (e.g., a stack). Pages can be shared between processes
and some are locked into main store. When a page is locked, it cannot be
removed from main store. The kernel’s own storage is often marked as locked
into main store. It is so locked because a page fault could prevent the kernel
from responding in time to a circumstance. It is also necessary to keep track
of those pages that are currently in main store: these are referred to as being
“in core”, hence the name of the variable, incore. The pagecount counts the
number of pages in each segment of each process. There is an a priori limit to
the number of pages in a segment and pagecount is intended to keep track of
this and to provide a mechanism for raising an error condition if this limit is
exceeded. The ﬁnal variable, smap, is a relation between elements of PAGE-
SPEC; it denotes those pages that are shared and it will be explained in more
detail below.

246
6 Virtual Storage
There are diﬀerent ways to organise page tables. The simplest is a linear
sequence of page references. As virtual storage sizes increase, simple linear
structures do not perform well, so tree-like structures are to be preferred.
These trees can be arranged to perform mapping on two or three levels. The
model deﬁned here is intended to be suggestive of a tree structure, even though
it can also be implemented as a table.
The class that follows deﬁnes an abstract data type. It represents the page
table type. The type exports a large number of operations and has the most
complex invariant in this book.
PageTables
↾(INIT, HaveFreePages, NumberOfFreePages, AllocateFreePage,
MakePageFree, PhysicalPageNo, InitNewProcessPageTable,
RemoveProcessFromPageTable, AddPageToProcess, HasPageInStore,
IncProcessPageCount, DecProcessPageCount,
LatestPageCount, UpdateMainstorePage,
RemovePageFromProcessTable, RemovePageProperties,
RemovePageFromProcess, IsPageInMainStore, MarkPageAsIn,
MarkPageAsOut, IsSharedPage, MarkPageAsShared,
UnsharePage, IsLockedPage, LockPage, UnlockPage,
MakePageReadable, MakePageNotReadable, MakePageExecutable,
IsPageExecutable, MakePageNotExecutable, MakePageWritable,
IsPageWritable, MakePageNotWritable)
freepages : F PHYSICALPAGENO
pagetable : APREF  →SEGMENT  →PAGEMAP
executablepages, writablepages, readablepages,
sharedpages, lockedpages,
incore : APREF  →SEGMENT  →F LOGICALPAGENO
pagecount : APREF  →SEGMENT  →N
smap : PAGESPEC ↔PAGESPEC
InvPageTables
0 ≤#freepages ≤numrealpages
dom incore ⊆dom pagetable
dom sharedpages ⊆dom pagetable
dom lockedpages ⊆dom pagetable
dom pagecount = dom pagetable
dom executablepages = dom pagetable
dom writablepages = dom pagetable
dom readablepages = dom pagetable

6.3 Virtual Storage
247
INIT
freepages′ = ∅
dom pagetable′ = ∅
dom sharedpages′ = ∅
dom lockedpages′ = ∅
dom incore′ = ∅
dom pagecount′ = ∅
dom executablepages′ = ∅
dom writablepages′ = ∅
dom readablepages′ = ∅
dom smap = ∅
HaveFreePages = . . .
NumberOfFreePages = . . .
AllocateFreePage = . . .
MakePageFree = . . .
PhysicalPageNo = . . .
InitNewProcessPageTable = . . .
RemoveProcessFromPageTable = . . .
AddPageToProcess = . . .
HasPageInStore = . . . IncProcessPageCount = . . .
DecProcessPageCount = . . .
LatestPageCount = . . .
UpdateMainstorePage = . . .
RemovePageFromPageTable = . . .
RemovePageProperties = . . .
RemovePageFromProcess = . . .
IsPageInMainStore = . . .
MarkPageAsIn = . . .
MarkPageAsOut = . . .
IsSharedPage = . . .
MarkPageAsShared = . . .
UnsharePage = . . .
IsLockedPage = . . .
LockPage = . . .
UnlockPage = . . .

248
6 Virtual Storage
MakePageReadable = . . .
MakePageNotReadable = . . .
MakePageExecutable = . . .
IsPageExecutable = . . .
MakePageNotExecutable = . . .
MakePageWritable = . . .
IsPageWritable = . . .
MakePageNotWritable = . . .
It will be noted that the invariant is partially stated in the class deﬁnition.
The remainder is speciﬁed by the InvPageTables schema deﬁned below after
the other operations have been deﬁned. This will bring the invariant closer to
some of the proofs in which it is required.
The following schema represents the test that there are pages in main store
(physical pages) that are free.
HaveFreePages
freepages ̸= ∅
NumberOfFreePages
np! : N
np! = #freepages
The following operation models the allocation of a free page to a process.
It removes the page denoted by ppno! from the set of free pages, freepages.
AllocateFreePage
∆(freepages)
ppno! : PHYSICALPAGENO
ppno! ∈freepages
freepages′ = freepages \ {ppno!}
Proposition 125. AllocateFreePage implies that #freepages′ = freepages+1.
Proof.
#freepages′
= #(freepages \ {ppno?})
= #freepages −#{ppno?}
= #freepages −1
2

6.3 Virtual Storage
249
Proposition 126. If freepages = n, AllocateFreePagen implies freepages′ =
0.
Proof. By induction, using the last proposition.
2
The next operation returns a page to the set of free pages.
MakePageFree
∆(freepages)
ppno? : PHYSICALPAGENO
freepages′ = freepages ∪{ppno?}
Proposition 127. MakePageFree implies that #freepages′ = #freepages −1.
Proof.
#freepages′
= #(freepages ∪{ppno?})
= #freepages + #{ppno?}
= #freepages + 1
2
Proposition 128. AllocateFreePage[p/ppno!] o
9 MakePageFree[p/ppnp?] im-
plies that freepages′ = freepages.
Proof. The sequential composition can be written as:
∃freepages′′ : F PHYSICALPAGENO | freepages′′ = freepages \ {ppno!} •
freepages′ = freepages ∪{ppno?}
Renaming and simplifying:
freepages′ = (freepages \ {p}) ∪{p}
Then:
(freepages \ {p}) ∪{p}
= (freepages \ {p}) ∪{p}
= freepages ∪({p} \ {p})
= freepages ∪∅
= freepages
2
The PhysicalPageNo operation contains a use of the pagetable variable.
This variable is a higher-order function. Its use might appear a little odd.

250
6 Virtual Storage
Essentially, to obtain the physical page number corresponding to a logical
page number, the process has to locate the segment in which the page occurs
and then translate the logical page number.
PhysicalPageNo
p? : APREF
sg? : SEGMENT
lpno? : LOGICALPAGENO
ppgno! : PHYSICALPAGENO
ppgno! = pagetable(p?)(sg?)(lpno?)
When a process is allocated, it is given an entry in the page table. The
following schema models this operation. It just adds the process’ identiﬁer as
a key in the subtables and sets everything to zero (empty or ∅).
InitNewProcessPageTable
∆(incore, sharedpages, lockedpages)
p? : APREF
pagetable′ = pagetable ∪{p? →code →∅} ∪{p? →data →∅}
∪{p? →stack →∅} ∪{p? →heap →∅}
incore′ = (incore ∪{p? →code →∅}) ∪({p? →data →∅}
(∪{p? →stack →∅}(∪{p? →heap →∅})))
sharedpages′ = (sharedpages ∪{p? →code →∅}) ∪({p? →data →∅}
(∪{p? →stack →∅}(∪{p? →heap →∅})))
lockedpages′ = (lockedpages ∪{p? →code →∅}) ∪({p? →data →∅}
(∪{p? →stack →∅}(∪{p? →heap →∅})))
Proposition 129. InitNewProcessPageTable implies that the new process has
no pages.
Proof.
For a process to have pages, it must have at least one page
in at least one segment. However, for a process, p, and all segments, sg,
pagetable′(p)(sg) = ∅.
2
Corollary 11. InitNewProcessPageTable implies that the new process has no
in-core pages.
Proof. Similar to the above.
2
Similar results can be proved for all other page attributes, e.g., locked
pages.
Conversely, when a process terminates or is killed, its storage is returned
to the free pool and all of the information associated with it in the page tables
is removed. The following schema models this operation:

6.3 Virtual Storage
251
RemoveProcessFromPageTable
∆(pagetable, incore, sharedpages, lockedpages)
p? : APREF
pagetable′ = {p?} −◁pagetable
incore′ = {p?} −◁incore
sharedpages′ = {p?} −◁sharedpages
lockedpages′ = {p?} −◁lockedpages
Proposition 130. The predicate of RemoveProcessFromPageTable implies
that p ̸∈dom pagetable.
Proof. The ﬁrst line of the predicate is pagetable′ = {p?}−◁pagetable. Taking
domains:
dom pagetable′ = dom({p?} −◁pagetable)
= (dom pagetable) \ {p?}
2
Proposition 131. For any p : APREF, RemoveProcessFromPageTable[p/p?]
implies that the process:
1. is no longer incore, swappable, etc.; and
2. is no longer in the page table for its owning process.
Proof. Each conjunct of the predicate employs the domain subtraction op-
eration (−◁) to remove p from the domain of each function. This implies that
p is removed from each table.
2
Propositions about page attributes can be proved. They follow the pattern
of the last proposition.
When the storage image of a process is augmented by the addition of fresh
pages, the following operation is the basic one used to extend the process’
page table entry. Each page is speciﬁed as a process reference, a segment and
a logical page number; in addition, the physical page number of the page to be
added is also included. Since the process and segment are already present in
the table, the logical to physical page number mapping is added to the table
at the speciﬁed point.
AddPageToProcess
∆(pagetable)
p? : APREF
sg? : SEGMENT
lpno? : LOGICALPAGENO
ppno? : PHYSICALPAGENO
pagetable′ = pagetable(p?)(sg?) ∪{lpno? →ppno?}

252
6 Virtual Storage
There now follows a predicate that returns true when the process speciﬁed
by p? has at least one page in main store:
HasPageInStore
p? : APREF
p? ∈dom incore
The per-segment page count is incremented by the following schema:
IncProcessPageCount
∆(pagecount)
p? : APREF
sg? : SEGMENT
pagecount′ = pagecount(p?) ⊕{sg? →pagecount(p?)(sg?) + 1}
The counter is decremented by the following schema:
DecProcessPageCount
∆(pagecount)
p? : APREF
pagecount′ = pagecount(p?) ⊕{p? →pagecount(p?)(sg?) −1}
When a page is added to a segment, the page count is incremented. When a
page is removed from a segment, the page count is decremented. The current
value of the page count is obtained by the following schema:
LatestPageCount
p? : APREF
sg? : SEGMENT
lpno! : LOGICALPAGENO
lpno! = pagecount(p?)(sg?)
If the logical to physical page mapping is changed, the following schema
performs the update in the page table.
UpdateMainStorePage
∆(pagetable)
p? : APREF
sg? : SEGMENT
lpno? : LOGICALPAGENO
ppno? : PHYSICALPAGENO
pagetable′ = pagetable(p?)(sg?) ⊕{lpno? →ppno?}

6.3 Virtual Storage
253
When a page is removed from the page table, the entry representing it
must be removed. The removal operation is deﬁned as follows:
RemovePageFromPageTable
∆(pagetable)
p? : APREF
sg? : SEGMENT
lpno? : LOGICALPAGENO
(∃pmap : PAGEMAP | pmap = pagetable(p?)(sg?) •
pagetable′ = pagetable(p?) ⊕{sg? →({lpno?} −◁pmap)})
The removal of a page also requires the removal of the attributes of that
page. The attributes are removed using the unmark page function (when a
page is allocated, the attributes it possesses are marked using the mark page
function).
RemovePageProperties
∆(executablepages, readablepages, writablepages, sharedpages,
lockedpages, incore)
p? : APREF
sg? : SEGMENT
lpno? : LOGICALPAGENO
executablepages′ = unmark page(p?, sg?, lpno?, executablepages)
readablepages′ = unmark page(p?, sg?, lpno?, readablepages)
writablepages′ = unmark page(p?, sg?, lpno?, writablepages)
sharedpages′ = unmark page(p?, sg?, lpno?, sharedpages)
lockedpages′ = unmark page(p?, sg?, lpno?, lockedpages)
incore′ = unmark page(p?, sg?, lpno?, incore)
Finally, the high-level operation to remove a page from a process is deﬁned
as follows:
RemovePageFromProcess =
RemovePageFromProcessTableo
9
MakePageFreeo
9
RemovePageProperties
It is possible to determine whether a page is in main store by determin-
ing whether it is in the incore attribute. The following schema deﬁnes this
predicate. Note that it uses the pages in segment function.
IsPageInMainStore
p? : APREF
sg? : SEGMENT
lpno? : LOGICALPAGENO
lpno? ∈pages in segment(p?, sg?, incore)

254
6 Virtual Storage
Proposition 132. IsPageInMainStore iﬀlpno? is an in-core page.
Proof. The predicate states that lpno? ∈pages in segment(p?, sg?, incore).
By the deﬁnition of pages in segment,
lpno? ∈incore(p?)(sg?)
2
Proposition 133. IsSharedPage iﬀlpno? is a shared page; that is, iﬀlpno?
is an element of sharedpages(p)(sg), for some p and sg.
Proof. Similar to the previous proof.
2
Proposition 134. IsLockedPage iﬀlpno? is a locked page; that is, iﬀlpno?
is an element of lockedpages.
Proof. Similar to the previous proof.
2
When a page is swapped into main store, it is marked as being “in”. The
following schema performs this marking. The schema that immediately follows
marks pages as “out” (i.e., as not being main-store resident).
MarkPageAsIn
∆(incore)
p? : APREF
sg? : SEGMENT
lpno? : LOGICALPAGENO
incore′ = mark page(p?, sg?, lpno?, incore)
Proposition 135. MarkPageAsIn implies that lpno? is an element of incore′.
Proof.
As can be seen from the schema, the predicate is incore′ =
mark page(p?, sg?, lpno?, incore). Substituting the deﬁnition of mark page:
incore′ = mark page(p?, sg?, lpno?, incore)
= incore(p?) ⊕{sg →(incore(p?)(sg) ∪{lpno?})}
2
Proposition 136. For ﬁxed arguments, p : APREF, s : SEGMENT and
l : LOGICALPAGENO, MarkPageAsIn[p/p?, s/sg?, l/lpno?]n has the same
eﬀect as MarkPageAsIn[p/p?, s/sg?, l/lpno?].

6.3 Virtual Storage
255
Proof. This proposition is to be taken as:
MarkPageAsInn ⇔MarkPageAsIn
The proposition is proved by substitution from the following general property
of sets:
(S ∪{x}) ∪{x} = S ∪{x}
(i.e., the absorbtive law of set union).
2
MarkPageAsOut
∆(incore)
p? : APREF
sg? : SEGMENT
lpno? : LOGICALPAGENO
incore′ = unmark page(p?, sg?, lpno?, incore)
Proposition 137. MarkPageAsOut is satisﬁed iﬀlpno? is not an element of
incore.
Proof. Substituting the deﬁnition of unmark page into the predicate of the
schema MarkPageAsOut:
incore′ = unmark page(p?, sg?, lpno?, incore)
= incore(p?) ⊕{sg? →(incore(p?)(sg?) \ {lpno?})}
2
Proposition 138. For ﬁxed arguments, p : APREF, s : SEGMENT and
l : LOGICALPAGENO, MarkPageAsOut[p/p?, s/sg?, l/lpno?]n has the same
eﬀect as MarkPageAsOut[p/p?, s/sg?, l/lpno?].
Proof. The statement of the proposition is to be taken as:
MarkPageAsOutn ⇔MarkPageAsOut
The proposition is proved by substitution from the following general property
of sets:
(S \ {x}) \ {x} = S \ {x}
2
Proposition 139. MarkPageAsIn[l/lpno?]o
9MarkPageAsOut[l/lpno?] implies
that incore′ = incore.

256
6 Virtual Storage
Proof. Writing out the predicates and performing the obvious substitutions:
unmark page(p?, sg?, lpno?, mark page(p?, sg?, lpno?, incore))
The result follows from the fact that unmark page and mark page are mutu-
ally inverse.
2
Proposition 140. MarkPageAsOut[l/lpno?]o
9MarkPageAsIn[l/lpno?] implies
that incore = incore′.
Proof. Writing out the predicates and performing the obvious substitutions:
mark page(p?, sg?, lpno?, unmark page(p?, sg?, lpno?, incore))
The result follows from the fact that unmark page and mark page are mutu-
ally inverse.
2
The next few schemata set and unset attributes in pages. The attributes
are represented by the various tables in the PageTables class, such as shared-
pages, readable and locked. The schemata naturally fall into three sets: one to
perform a test and one to set the attribute and one to unset it. The schemata
in each of these sets have the same structure. That structure is the obvious
one and is quite simple. For these reasons, the schemata will not be described
in English: the formal notation can stand on its own.
IsSharedPage
p? : APREF
sg? : SEGMENT
lpno? : LOGICALPAGENO
lpno? ∈pages in segment(p?, sg?, sharedpages)
MarkPageAsShared
∆(sharedpages)
p? : APREF
sg? : SEGMENT
lpno? : LOGICALPAGENO
sharedpages′ = mark page(p?, sg?, lpno?, sharedpages)
UnsharePage
∆(sharedpages)
p? : APREF
sg? : SEGMENT
lpno? : LOGICALPAGENO
sharedpages′ = unmark page(p?, sg?, lpno?, sharedpages)

6.3 Virtual Storage
257
IsLockedPage
p? : APREF
sg? : SEGMENT
lpno? : LOGICALPAGENO
lpno? ∈pages in segment(p?, sg?, lockedpages)
LockPage
∆(lockedpages)
p? : APREF
sg? : SEGMENT
lpno? : LOGICALPAGENO
lockedpages′ = mark page(p?, sg?, lpno?, lockedpages)
UnlockPage
∆(lockedpages)
p? : APREF
sg? : SEGMENT
lpno? : LOGICALPAGENO
lockedpages′ = unmark page(p?, sg?, lpno?, lockedpages)
MakePageReadable
∆(readablepages)
p? : APREF
sg? : SEGMENT
lpno? : LOGICALPAGENO
readablepages′ = mark page(p?, sg?, lpno?, readablepages)
IsPageReadable
p? : APREF
sg? : SEGMENT
lpno? : LOGICALPAGENO
lpno? ∈readablepages(p?)(sg?)
MakePageNotReadable
∆(readablepages)
p? : APREF
sg? : SEGMENT
lpno? : LOGICALPAGENO
readablepages′ = unmark page(p?, sg?, lpno?, readablepages)

258
6 Virtual Storage
MakePageExecutable
∆(executablepages)
p? : APREF
sg? : SEGMENT
lpno? : LOGICALPAGENO
executablepages′ = mark page(p?, sg?, lpno, executablepages)
IsPageExecutable
p? : APREF
sg? : SEGMENT
lpno? : LOGICALPAGENO
lpno? ∈executablepages(p?)(sg?)
MakePageNotExecutable
∆(executablepages)
p? : APREF
sg? : SEGMENT
lpno? : LOGICALPAGENO
executablepages′ = unmark page(p?, sg?, lpno, executablepages)
MakePageWritable
∆(writablepages)
p? : APREF
sg? : SEGMENT
lpno? : LOGICALPAGENO
writablepages′ = mark page(p?, sg?, lpno, writablepages)
IsPageWritable
p? : APREF
sg? : SEGMENT
lpno? : LOGICALPAGENO
lpno? ∈writablepages(p?)(sg?)
MakePageNotWritable
∆(writablepages)
p? : APREF
sg? : SEGMENT
lpno? : LOGICALPAGENO
writablepages′ = unmark page(p?, sg?, lpno, writablepages)

6.3 Virtual Storage
259
Finally, we come to InvPageTables, the page table invariant. As can be
seen, this is quite an invariant. Because of its length, it was not possible to
make it ﬁt within the Object-Z class box without obfuscating the speciﬁcation
even more. The invariant is mostly concerned with ensuring that each page
is represented correctly. For example, no free page has a corresponding page-
table entry; all locked pages are always in main store, and so on. Readers can
inspect the various clauses of the invariant for themselves.
This invariant clearly demonstrates the need for higher-order logics!
InvPageTables =
(∀ppno : PHYSICALPAGENO •
ppno ∈freepages ⇔
¬ (∃p : APREF; sg : SEGMENT; lpno : LOGICALPAGENO •
ppno = pagetables(p)(sg)(lpno)))
(∀p : APREF; sg : SEGMENT •
p ∈dom lockedpages ∧sg ∈dom lockedpages(p) ⇒
lockedpages(p)(sg) ⊆incore(p)(sg))
(∀p : APREF; sg : SEGMENT •
p ∈dom incore ∧sg ∈dom incore(p) ⇒
incore(p)(sg) ⊆dom pagetable(p)(sg))
(∀p : APREF; sg : SEGMENT •
p ∈dom sharedpages ∧sg ∈dom sharedpages(p) ⇒
sharedpages(p)(sg) ⊆dom pagetable(p)(sg))
(∀p : APREF; sg : SEGMENT •
p ∈dom lockedpages ∧sg ∈dom lockedpages(p) ⇒
lockedpages(p)(sg) ⊆dom pagetable(p)(sg))
These clauses are intended to represent the disjointness of segments.
(∀p : APREF | p ∈dom pagetable •
(∀sg1, sg2 : SEGMENT •
(sg1 ̸= sg2 ∧
sg1 ∈dom pagetable(p) ∧sg2 ∈dom pagetable(p)) ⇒
dom pagetable(p)(sg1) ∩dom pagetable(p)(sg2) = ∅))
(∀p : APREF | p ∈dom pagetable •
(∀sg1, sg2 : SEGMENT •
(sg1 ̸= sg2 ∧
sg1 ∈dom pagetable(p) ∧sg2 ∈dom pagetable(p)) ⇒
ran pagetable(p)(sg1) ∩ran pagetable(p)(sg2) = ∅))
(∀p : APREF; sg : SEGMENT •
p ∈dom executablepages ∧sg ∈executablepages(p) ⇒
executablepages(p)(sg) ⊆dom pagetable(p)(sg))
(∀p : APREF; sg : SEGMENT •
p ∈dom readablepages ∧sg ∈readtablepages(p) ⇒
readablepages(p)(sg) ⊆dom pagetable(p)(sg))

260
6 Virtual Storage
(∀p : APREF; sg : SEGMENT •
p ∈dom writablepages ∧sg ∈writablepages(p) ⇒
writablepages(p)(sg) ⊆dom pagetable(p)(sg))
(∀pg : PAGESPEC | pg ∈dom pmap •
(∃p : APREF; sg : SEGMENT; lpno : LOGICALPAGENO •
(p = pgspecpref (pg) ∧
sg = pgspecseg(pg) ∧
lpno = pgspeclpno(pg)) ⇒
(p ∈dom pagetable ∧sg ∈dom pagetable(p) ∧
lpno ∈dom pagetable(p)(sg))))
(∀pg : PAGESPEC | pg ∈ran pmap •
(∃p : APREF; sg : SEGMENT; lpno : LOGICALPAGENO •
(p = pgspecpref (pg) ∧
sg = pgspecseg(pg) ∧
lpno = pgspeclpno(pg)) ⇒
(p ∈dom pagetable ∧sg ∈dom pagetable(p) ∧
lpno ∈dom pagetable(p)(sg))))
Proposition 141.
InitNewProcessPageTable ⇒
(∀s : SEGMENT •
incore = ∅
∧sharedpages = ∅
∧lockedpages = ∅)
Proof. By the predicate of the InitNewProcessPageTable predicate.
2
Proposition 142. ∀p : PAGE • locked(p) ⇔¬ swappable(p)
Proof.
The class invariant states that dom lockedpages ⊆dom pagetables.
This permits us to infer that:
∀p : LOGICALPAGENO •
p ∈lockedpages(p)(sg)
⇒p ∈(dom pagetable(p)(sg))
for all p ∈IPREF and sg ∈SEGMENT.
Again, by the same invariant:
lockedpages(p)(sg) ⊆incore(p)(sg)
(again, for all p and sg as above).
These two formulæ ensure that every locked page exists in store.
⇒: By the predicate of PageFaultDriver.ﬁndVictimLogicalPage (q.v.):

6.3 Virtual Storage
261
pagetable(p)(sg)(l) = v! ∧l ̸∈lockedpage
First, applying the substitutions [p/p!, sg/sg!, l/l!], then simplifying and re-
arranging the predicate of ﬁndVictimLogicalPage, we obtain:
p ∈dom pagetable
∧sg ∈dom pagetable(p)
∧l ∈dom pagetable(p)(sg)
∧l ̸∈lockedpages(p)(sg)
∧pagetable(p)(sg)(l) = v
where v is the page to be swapped.
From this, it can be concluded that v cannot be a locked page.
⇐. If a page is not swappable, it is locked. Consider the set of swappable pages,
S, by the deﬁnition of ﬁndVictimLogicalPage in the substitution instance
above, any logical page, l, cannot be in S because l ̸∈lockedpages(p)(sg). 2
Proposition 143. For all processes, lockedpages ∩swappablepages = ∅.
Proof. This follows immediately from the previous proposition.
2
Proposition 144. If a page, p, is in main store, IsPageInMainStore[p/...] is
satisﬁed.
Proof. By the predicate of IsPageInMainStore, it is clear that
lpno? ∈pages in segment(p, s, incore)
and that: pages in segment(x, y, f ) = f (x)(y); its range is a set.
For a page actually to be in store, the following must be satisﬁed:
IsPageInMainstore implies that:
(∃p : IPREF; sg : SEGMENT; pp : PHYSICALPAGENO •
pagetable(p)(sg)(lpno) = pp
∧pp ̸∈freepages)
By the invariant:
∀pp : PHYSICALPAGENO •
pp ∈freepages ⇒
¬ (∃p : IPREF; sg : SEGMENT; l : LOGICALPAGENO •
pp = pagetables(p)(sg)(l)
By the application of contraposition (p ⇒q ⇔q ⇒p), the result is obtained.
It is now necessary to show that
l ∈incore(p)(sg) ⇒
(∃pp1 : PHYSICALPAGENO • pagetables(p)(sg)(l) = pp)
This can be done using the invariant.
2

262
6 Virtual Storage
Proposition 145. If a page, p, is locked, IsPageInMainStore[p/...] is satis-
ﬁed.
Proof. Similar to that of the last proof.
2
Proposition 146. A locked page can never be swapped out.
Proof. By Propositions 142 and 144.
2
Proposition 147. A free page is in the process table of no process.
Proof.
Assume that process, p, has segment, s, in which the logical page
number, l is mapped to physical page, n. In this case, n = pagetable(p)(s)(l).
By the class invariant,
∀ppno : PHYSICALPAGENO •
ppno ∈freepages ⇔
¬ (∃pid : APREF; sg : SEGMENT; lpn : LOGICALPAGENO •
ppno = pagetable(pid)(sg)(lpn))
By Universal Instantiation:
n ∈freepages ⇔
¬ (∃pid : APREF; sg : SEGMENT; lpn : LOGICALPAGENO •
n = pagetable(pid)(sg)(lpn))
From the assumption that n ∈freepages, a contradiction ensues. Therefore,
n ̸∈freepages
as required.
2
Proposition 148. A free page is not incore.
Proof. The invariant states that:
∀ppno : PHYSICALPAGENO •
ppno ∈freepages ⇔
¬ (∃pid : APREF; sg : SEGMENT; lpn : LOGICALPAGENO •
ppno = pagetable(pid)(sg)(lpn))
This implies that:
freepages ∩pagetable(p)(sg) = ∅
(6.1)
The class invariant also states that:

6.3 Virtual Storage
263
p ∈dom incore ∧sg ∈dom incore(p) ⇒
incore(p)(sg) ⊆dom pagetable(p)(sg)
This and equation (6.1) above imply that pg ∈freepages ⇔¬ incore(p)(sg)(l)
for all values of p, sg and l.
2
Proposition 149. A free page is not:
1. executable;
2. readable; or
3. writable.
Proof. Since a free page is not in the page table, it follows from the invariant
that it cannot have any of these attributes.
2
6.3.1 The Paging Disk Process
The paging disk holds pages while they are not in main store. The virtual store
software copies pages to and from the paging disk to implement the swapping
process that underlies the huge address space illusion. Pages are swapped out
of store when they are not required and swapped back in when their owning
process (or one of them, if the page is shared) refers to them.
The paging disk is part of the subsystem whose design will be discussed in
the next few subsections. The subsystem’s organisation and interactions are
shown in Figure 6.2. It consists of an ISR, a handler or driver process and the
paging disk proper.
The paging disk is assumed to be inﬁnite in size. It is represented by a
mapping from logical to physical pages (pagemap). In addition, the disk has an
interface to the message-passing system (msgmgr) so that it can communicate
with the other processes in the storage-management subsystem. For most of
the time, pagemap will be the focus of attention.
The class deﬁning the paging disk process is now deﬁned.
PagingDiskProcess
↾(INIT, PageIsOnDisk, StorePageOnDisk, RetrievePageFromDisk,
RemoveProcessFromPagingDisk, OnPageRequest)
pagemap : APREF  →SEGMENT  →LOGICALPAGENO  →PAGE
msgmgr : MsgMgr

264
6 Virtual Storage
allocate
delete
expand
mark
…
Virtual 
Store Mgr.
Physical
Store
Page
Tables
Paging
Disk
Page Fault 
Handler
Process
ISR
H/W Page
Fault Signal
Fig. 6.2. Interactions between virtual storage components.
INIT
msgs? : MsgMgr
msgmgr ′ = msgs?
dom pagemap′ = ∅
PageIsOnDisk = . . .
StorePageOnDisk = . . .
RetrievePageFromDisk = . . .
RemoveProcessFromPagingDisk = . . .
OnPageRequest = . . .

6.3 Virtual Storage
265
The following schema is a predicate that is true when the speciﬁed page
of the speciﬁed process is present on the paging disk.
PageIsOnDisk
p? : APREF
sg? : SEGMENT
lpno? : LOGICALPAGENO
p? ∈dom pagemap
sg? ∈dom pagemap(p?)
lpno? ∈dom pagemap(p?)(sg?)
Pages are stored on the paging disk when they are swapped out of main
store. In order for a page to be stored on the paging disk, it must be placed
there and indexed properly. The StorePageOnDisk operation does this:
StorePageOnDisk
∆(pagemap)
p? : APREF
sg? : SEGMENT
lpno? : LOGICALPAGENO
pg? : PAGE
pagemap′ = pagemap ⊕{p? →{sg? →{lpno? →pg?}}}
Proposition 150. If a logical page image is already on disk and that page is
swapped out again, that page image is overwritten.
Proof. Let p = pagemap(p?)(sg?)(lpno?) and let pg? be pagemap′(p?)(sg?)
(lpno?), so {p? →{sg? →{lpno? →p}}} ∈pagemap and {p? →{sg? →
{lpno? →pg?}}} ∈pagemap′. Therefore, pagemap′ = pagemap ⊕{p? →
{sg? →{lpno? →pg?}}}.
2
When its owning process references a page that is not in main store, the
paging disk is instructed to retrieve it from the paging disk. The following
schema models the basics of this operation:
RetrievePageFromDisk
p? : APREF
sg? : SEGMENT
lpno? : LOGICALPAGENO
pg! : PAGE
pg! = pagemap(p?)(sg?)(lpno?)
When a process terminates (or is terminated), all of its pages must be
removed from the paging disk. In our model, this can be done very easily by

266
6 Virtual Storage
removing the process’ identiﬁer from the domain of the pagemap. This removes
all references to the process from the map—hence, removes the process from
the disk, thus:
RemoveProcessFromPagingDisk
∆(pagemap)
p? : APREF
pagemap′ = {p?} −◁pagemap
Proposition 151. The predicate of RemoveProcessFromPagingDisk implies
that p ̸∈dom pagemap′.
Proof.
dom pagemap′
= dom({p?} −◁pagemap)
= (dom pagemap) \ {p?}
Therefore, p ̸∈dom pagemap′.
2
The paging disk has an operation that handles requests for operations.
The operations it can perform are:
•
store a page (STOPG);
•
retrieve a page (GTPG), and
•
delete a process from the paging disk (DELPROCPG).
The following schema deﬁnes this operation. The schema uses overloaded calls
to the RcvMessage primitive provided by the message-handling subsystem.
The operation is really just a large “or” based on the type of message that
has just been received. The inﬁnite loop is modelled by the exterior universal
quantiﬁer. While the operation has nothing to do, it waits for the next message
to arrive.
OnPageRequest
∀i : 1 . . ∞•
(∃pdsk, fhandler : APREF; msg : MSG |
pdsk = pagedisk ∧fhandler = faultdrvr •
msgmgr.RcvMessage[pdsk/caller?, fhandler/src?, msg/m!]
∧(∃p : APREF; sg : SEGMENT;
lpno : LOGICALPAGENO; pg : PAGE •
(msg = STOPG⟨⟨p, sg, lpno, pg⟩⟩
∧storePageOnDisk[p/p?, sg/sg?, lpno/lpno?, pg/pg?])

6.3 Virtual Storage
267
∨(msg = GTPG⟨⟨p, sg, lpno⟩⟩
∧retrievePageFromDisk[p/p?, sg/sg?, lpno/lpno?, pg/pg!]
∧(∃rpmsg : MSG | rpmsg = ISPG⟨⟨p, sg, lpno, pg⟩⟩•
msgmgr.SendMessage
[fhandler/dest?, pdsk/src?, rpmsg/m?]))
∨(msg = DELPROCPG⟨⟨p⟩⟩
∧removeProcessFromPagingDisk[p/p?])))
Proposition 152. OnPageRequest does what it should.
Proof. The proof is by cases on message type. It is assumed that all domains
are correct so the error cases ignored in the schema need not be introduced
here.
Case 1. m = STOPG, a request to store a page on disk. The predicate of
storePageOnDisk[p/p?, sg/sg?, lpno/lpno?, pg/pg?] states:
pagemap′ = pagemap ⊕{p →{sg →{lpno →pg}}}
so pg? = pagemap′(p)(sg)(lpno).
Case 2. m = GTPG, a request to retrieve a page. This follows from the fact
that retrievePageOnDisk is a function: pg? = pagemap(p?)(sg?)(lpno?).
Case 3. m = DELPROCPG. By the last proposition.
2
6.3.2 Placement: Demand Paging and LRU
There are signiﬁcant issues to be resolved in the design of the virtual storage
mechanism. This section deals with the general area of placement. Placement
is concerned with where pages are to be removed and included in main store.
When a process refers to a page that is not currently in main store, it generates
a page fault,
an asynchronous signal that interrupts the process and leads
to the satisfaction of the reference. To do this, the support software has to
identify the page that is being referenced and then identify a page in physical
store that can be swapped out to the paging disk, thus making space for the
referenced page to be copied into main store. The issue is slightly complicated
by the fact that the system might have some free physical pages in main store
(indeed, it might be a policy to keep a block of such pages in reserve). For
present purposes, it is assumed that all physical pages are allocated and that
there is no pool of free pages kept in reserve.
The placement algorithm just outlined is demand paging. This is the most
common approach. It is documented, like many other possible approaches, in
most textbooks on operating systems (e.g., [26, 11, 29, 5]). Demand paging is
the most commonly used approach and makes reasonable assumptions about
the hardware and the software. It just assumes that the hardware can detect

268
6 Virtual Storage
a page fault and that the software can ﬁnd the referenced page and locate the
page in main store where it can be stored; if there is no free page, demand
paging assumes that there is a way to ﬁnd a victim page that can be swapped
out to make space.
ISR
Page
Fault
Handler
Physical
Store
Paging
Disk
Process
Hardware Page
Fault (signal)
process Id
page
request
replacement
page
+ faulting
address
Fig. 6.3. Process organisation for handling page faults.
The placement algorithm used in this model has two identiﬁable aspects:
1. ﬁnding pages to remove;
2. pages to include.
The second aspect is solved for us: the pages to include are always those that
cause a page fault when referenced by a process.
The general organisation of the processes that handle page faults is shown
in Figure 6.3.
6.3.3 On Page Fault
A page fault occurs when a virtual address refers to a page that is not in
physical store.
When such a fault occurs, it is assumed that the address causing the
fault is available to the operating system. From this address, it is assumed
that the following parameters can be computed: segment number, logical page
number and the oﬀset into the logical page. In addition, it is assumed that the

6.3 Virtual Storage
269
identity of the process causing the page fault can be determined (it should be
the currently running process on a uni-processor; in the terms of this book,
the value of currentp).
The case in which a page is shared is identical. The important thing to
remember is that the owning process causes the page fault. If a page is shared,
the important thing is for the page not to be swapped in (or out) more than
once. That is why the smap is included in PageTables. When a shared page is
to be swapped, this map is consulted. If the page is shared, it should already
be in store. Conversely, if a page is to be swapped in, the smap should be
consulted for the same reason.
In this section, a page that is to be removed from main store in order to
free a page frame will be called a victim or candidate. It is always a restriction
on victim page selection that victim pages are never locked into main store.
To deﬁne a relatively simple candidate-ﬁnding algorithm, it is necessary
to associate page frames in main store with a bit that is set by the hardware
whenever a page is referenced and a counter. The counter is a single byte
whose value is computed by rotating the reference bit into the top bit of the
counter byte and or-ing the counter with the contents of the counter shifted
down one bit (ignoring the bottom bit). The types of the reference bit and
the counter are:
BIT == {0, 1}
N256 == 0 . . 255
(N256 is just the naturals 0 . . 216 −1—i.e., a 16-bit unsigned.)
The computation of the counter value forms part of the predicate of schema
ComputeHitCounts. To deﬁne a swap-out procedure, it is necessary to extend
PageFrames a little so that information on page usage is represented.
The class and its operations are relatively straightforward.
PageFrames
↾(INIT, GetPage, OverwritePhysicalPage, ClearRefBitsAndCounter,
ComputeHitCounts, IsVictim, VictimPhysicalPageNo)
frames : PAGEFRAME
refbit : PHYSICALPAGENO  →BIT
count : PHYSICALPAGENO  →N256
dom count = dom refbit
dom count ⊆dom frames
# dom refbit = numrealpages

270
6 Virtual Storage
INIT
(∀i : 1 . . numrealpages •
frames′(i) = NullPage)
dom refbit′ = ∅
dom count′ = ∅
GetPage = . . .
OverwritePhysicalPage = . . .
ClearRefBitsAndCounter = . . .
ComputeHitCounts = . . .
IsVictim = . . .
VictimPhysicalPageNo = . . .
GetPage
pageno? : PHYSICALPAGENO
fr! : PAGE
1 ≤pageno? ≤numrealpages
fr! = frames(pageno?)
This operation retrieves a page.
The inﬁx function after is required by the next schema. Its deﬁnition is
repeated for convenience:
after
: seq X × N →seq X
∀m : seq X ; oﬀset : N •
dom(m after oﬀset) = (1 . . #m −oﬀset) ∧
(∀n : N •
(n + oﬀset) ∈dom m ⇒(m after oﬀset)(n) = m(n + oﬀset))
OverwritePhysicalPage
∆(frames)
pageno? : PHYSICALPAGENO
pg? : PAGE
frames′ = frames ⊕{pageno? →pg?}
This operation overwrites a page in main store. The input pageno? is the index
of the page frame in main store and pg? is a page full of data.
Proposition 153. The predicate of the substitution instance of the predicate
OverwritePhysicalPage[p/pageno?, pg/pg?] replaces the page indexed by p in
frames by the page, pg and only that page.

6.3 Virtual Storage
271
Proof. The ⊕operation can be deﬁned as:
(f ⊕g)(x) =

f (x), x ∈dom f
g(x), otherwise.
Then, for the predicate of the schema:
(frames ⊕{pageno? →pg?})(x) =

frames(x), x ∈dom frames
{pageno? →pg?}, x = pageno?
2
The clearing of the reference bits and reference counter in a physical page
is deﬁned as follows:
ClearRefBitsAndCounter
∆(refbit, count)
ppno? : PHYSICALPAGENO
refbit′ = refbit ⊕{ppno? →0}
count′ = count ⊕{ppno? →0}
The following operation computes the hit count for each page. That is, it
computes the number of times the page has been referenced since it was copied
into main store. It must be performed on a cyclic basis but this model does
not specify how the cycle is implemented—hardware is the optimal way to
compute such counts because the counter must be updated on each reference.
The computation operation is deﬁned by the following schema:
ComputeHitCounts
∆(pcount, count)
(∀i : PHYSICALPAGENO | i ∈dom frames •
(∃pcount : N265 •
pcount = (count(i)/2)mod 256 + refbit(i) ∗27 ∧
count′ = count ⊕{i →pcount}))
The lowest count value is chosen as the victim:
IsVictim
(∃j : PHYSICALPAGENO | j ∈dom count •
count(j) = min(ran count))
The physical page of the victim must be obtained:
VictimPhysicalPageNo
victim! : PHYSICALPAGENO
(∃: PHYSICALPAGENO | i ∈dom count •
∧count(i) = min(ran count)
∧i = victim!)

272
6 Virtual Storage
This algorithm is not foolproof but is a reasonable, hardware-independent
choice. There are many alternative algorithms in the literature (see, for ex-
ample, [26] or [29]) but the best will always be determined by the hardware
on which the operating system runs. The assumption made here is a mini-
mal one (because many processors implement reference bits in page frames);
some machines might provide reference counters directly, while others might
record the time of the last reference to each page. It is to be hoped that,
in the future, victim determination will be considerably simpliﬁed by more
co-operative hardware.
The FindVictim operation is “safe” in the sense that it will always ﬁnd
an in-core page. The reason for this is that the pageout operation deﬁned
above requires that ¬ HaveFreePages be true before FindVictim is called.
This ensures that none of the candidate pages is in freepages.
PGMSG ::= DELPROCPG⟨⟨AREF⟩⟩
|
GETPG⟨⟨AREF × SEGMENT × LOGICALPAGENO⟩⟩
|
STOPG⟨⟨AREF × SEGMENT × LOGICALPAGENO × PAGE⟩⟩
|
ISPG⟨⟨AREF × SEGMENT × LOGICALPAGENO × PAGE⟩⟩
FMSG ::= BADADDR⟨⟨APREF × SEGMENT × LOGICALPAGENO⟩⟩
The ISR handling page faults can be deﬁned as the following class. It is a
subclass of the message-based ISR deﬁned in the last chapter.
PageFaultISR
↾(INIT,
OnPageInterrupt)
GenericMsgISR
sched : LowLevelScheduler
ptab : ProcessTable
INIT
schd? : LowLevelScheduler
pt? : ProcessTable
sched ′ = schd? ∧ptab′ = pt?

6.3 Virtual Storage
273
OnPageInterrupt
intaddr? : VIRTUALADDRESS
∃fmsg : FMSG; cp : APREF; sg : SEGMENT;
lpno : LOGICALPAGENO; oﬀset : N •
saddrseq(saddresstrans(intaddr?)) = sg
∧spageno(saddresstrans(intaddr?)) = lpno
∧sched.CurrentProcess[cp/cp!] ∧sched.MakeUnready[cp/pid?]
∧ptab.DescrOfProcess[cp/pid?, pd/pd!]
∧ctxt.SwapOut ∧fmsg = BADADDR⟨⟨cp, sg, lpno⟩⟩
∧(∃isrid, fdvrid : APREF | fdrvrd = faultdrvr •
SendInterruptMsg[fdrvrid/driver?, fmsg/m?])
o
9ctxt.SwapIn
When a page fault occurs, the ISR sends a message to the PageFault-
Driver. The page-fault handler or driver is deﬁned by the following class. As
is usual with classes that represent processes, it exports only one operation,
here DoOnPageFault. The driver also contains routines that access page ta-
bles but they are not exported. The idea is that once the driver starts, it has
exclusive access to these data structures. The data structures, however, still
need to be protected by locks.
PageFaultDriver
↾(INIT, DoOnPageFault)
sched : LowLevelScheduler; ptab : ProcessTable; pts : PageTables;
vsm : VStoreManager; pfs : PageFrames; msgman : MsgMgr
lck : Lock
INIT
mmgr? : MsgMgr; sch? : LowLevelScheduler
ptb? : ProcessTable; pgtabs? : PageTables
vstoreman? : VStoreManager
pgfrms? : PageFrames; lk? : Lock
msgman′ = mmgr? ∧sched ′ = sch? ∧ptab′ = ptb? ∧pts′ = pgtabs?
vsm′ = VStoreManager ∧pfs′ = PageFrames ∧lck ′ = lk?

274
6 Virtual Storage
ﬁndVictimLogicalPage = . . .
haveVictim = . . .
ﬁndVictimPage = . . .
swapPageToDisk = . . .
retrievePageFromDisk = . . .
storePageOnDisk = . . .
genOnPageFault = . . .
onPageFault = . . .
DoOnPageFault = . . .
The driver has to ﬁnd a victim page to swap out when there is no free
store. The following schema deﬁnes this operation. The page to be swapped
out is a logical one at this point. The schema maps the logical page to a
physical page by another operation.
ﬁndVictimLogicalPage
p! : APREF
sg! : SEGMENT
lpno! : LOGICALPAGENO
victim! : PHYSICALPAGENO
(∃p : APREF; s : SEGMENT; l : LOGICALPAGENO |
p ∈dom pagetable ∧sg ∈dom pagetable(p)
∧l ∈dom pagetable(p)(sg) •
pagetable(p)(sg)(l) = victim!
∧l ̸∈lockedpages(p)(sg)
∧p! = p ∧sg! = s ∧lpno! = l)
The schema simpliﬁes to:
p! : APREF
sg! : SEGMENT
lpno! : LOGICALPAGENO
victim! : PHYSICALPAGENO
p! ∈dom pagetable ∧sg! ∈dom pagetable(p!)
∧lpno! ∈dom pagetable(p!)(sg!)
∧pagetable(p!)(sg!)(lpno!) = victim!
∧lpno! ≠∈lockedpages(p!)(sg!)
The following deﬁnition is a synonym. It tests the reference count of the
victim physical page.

6.3 Virtual Storage
275
haveVictim = pfs.IsVictim
The ﬁnal operation to locate a victim page is the following:
ﬁndVictimPage =
pfs.VictimPhysicalPageNo[victim/victim!]
∧ﬁndVictimLogicalPage[victim/victim!]
It is possible to put a few properties of pages on a more formal basis.
Proposition 154. Locked pages can never be victims.
Proof.
The predicate of ﬁndVictimLogicalPage contains the conjunct l ̸∈
lockedpages(p)(sg), where l is the logical page number, p the process identiﬁer
and sg the segment.
2
Proposition 155. Free pages can never be victims.
Proof. Since free pages do not belong to any process (by Proposition 147),
they do not appear in pagetable, so they cannot be victims because the quan-
tiﬁer in ﬁndVictimLogicalPage ranges over pagetable.
2
Proposition 156. Faulting processes are not ready.
Proof.
The predicate of PageFaultISR.OnPageInterrupt contains a refer-
ence to the schema MakeUnready[cp/pid?], where cp is the current process
(i.e., cp = currentp), so it is the process that caused the page fault. The action
of MakeUnready is to remove the process from the ready queue.
2
Proposition 157. A faulting process cannot be executed.
Proof. By the previous proposition, MakeUnready implies that cp cannot
be scheduled until it is returned to the ready queue. Furthermore, cp cannot
continue because OnPageInterrupt calls sched.ScheduleNext to select the next
process to run; this process will not be cp.
2
Corollary 12. A faulting process is blocked.
Proof. This is a consequence of the previous proposition.
2
The operation that actually swaps a page from main store to the paging
disk is the following:

276
6 Virtual Storage
swapPageToDisk =
(ﬁndVictimPage[p/p!, sg/sg!, lpno/lpno!]
∧vsm.MarkSharedLogicalPageAsOut[p/p?, sg/sg?, lpno/lpno?]
∧pfs.GetPage[pg/fr!, victim!/pageno?]
∧storePageOnDisk[p/p?, sg/sg?, lpno/lpno?, pg/pg?]
∧pfs.ClearRefBitsAndCounter[victim!/ppno?]
∧storePageOnDisk[p/p?, sg/sg?, lpno/lpno?, pg/pg?])
\{pg, p, sg, lpno}
∨Skip
First, a victim is located and then marked as being not in store (MarkShared-
LogicalPageAsOut). The page causing the page fault is then demanded from
the paging disk and the victim is sent to the disk for temporary storage. The
reference bits of the victim are then cleared so that the referenced page (the
one causing the page fault) can be written to it by storePageOnDisk.
The next operation to be deﬁned is retrievePageFromDisk. This operation,
as its name suggests, communicates with the paging disk process to locate the
page that is to be brought into main store as a consequence of the last page
fault. The reference to this page is, in fact, the one that caused the page fault
that resulted in the current execution of the PageFaultDriver. It is deﬁned by
the following schema:
retrievePageFromDisk
p? : APREF
sg? : SEGMENT
lpno? : LOGICALPAGENO
pg! : PAGE
(∃msgo, msgr : PGMSG; src, dest : APREF; pg : PAGE |
msgo = GETPG⟨⟨p?, sg?, lpno?⟩⟩
∧src = faultdrvr ∧dest = pagedsk •
msgman.SendMsg[src/src?, dest/dest?, msgo/m?]o
9
(msgman.RcvMsg[src/caller?, dest/src?, msgr/m!]
∧msgr = ISPG⟨⟨p?, sg?, lpno?, pg!⟩⟩))
As can be seen, this operation mostly handles messages. First, the operation
sends a message requesting that the paging disk retrieve the page speciﬁed by
the parameters p?, sg? and lpno?; the page is represented by pg!. The page,
pg!, is returned by the paging disk in the ISPG message.
The operation to store a page on disk is similar to the last one.

6.3 Virtual Storage
277
storePageOnDisk
p? : APREF
sg? : SEGMENT
lpno? : LOGICALPAGENO
pg? : PAGE
(∃msg : PGMSG; src, dest : APREF |
msg = STOPG⟨⟨p?, sg?, lpno?, pg?⟩⟩
∧src = faultdrvr ∧dest = pagedsk •
mgman.SendMsg[src/src?, dest/dest?, msg/m?])
Again, this operation mostly deals with messages. In this case, it contains just
one send operation. Messages of type STOPG request the paging disk to store
the page speciﬁed by p?, sg?, lpno?; the page is denoted by pg?.
The next operation schema deﬁnes the operation performed whenever a
page fault occurs. This is a complex operation and its deﬁnition reﬂects this
complexity. The operation receives a message containing a speciﬁcation of the
page that was referenced and determined (by the hardware) not to be in main
store (it is on the paging disk).
The operation determines whether there are any page frames free in main
store. If there are, the page is located on the disk and copied into a free
page. To do this, the operation sends a message to the paging-disk process
requesting the page.
If there are no page frames free in main store, a page that is currently
resident in main store must be placed on the paging disk in order to make
space for the one that caused the page fault. A suitable resident page must
have a low frequency of reference in the near future and the reference-count
mechanism speciﬁed above is used to determine which it is. This page is
referred to as the victim in the following schema and the schemata deﬁning
the selection operations. It should be noted that the victim can belong to any
process whatsoever but cannot be a page that is locked into main store. The
victim is swapped to the paging disk and the one causing the page fault is
retrieved and copied into the newly vacated page frame in main store. The
process that caused the page fault is then returned to the ready queue and
the ISR waits for the next page fault.
It should be noted that the victim can never be a locked page (i.e., a page
locked into main store). This condition is imposed so that, in particular, pages
locked into main store by the kernel (typically pages containing kernel code
and data structures) cannot be swapped out. It is undesirable to swap kernel
pages out of store because they might be involved in the operation currently
being performed or they might be ISRs and the scheduler.
In some kernel designs, it is possible for kernel processes to be stored in
swappable pages. In such a case, the pages would contain data or processes
that are considered to be of lower importance, implementing operations that
the kernel can aﬀord to have blocked while some of their store is paged out.

278
6 Virtual Storage
The kernel assumed here is the one modelled in Chapter 4 and extended
in Chapter 5. It is assumed that all of its components (data structures and
processes) must be stored in pages that are locked into main store (and hence
are stored in pages with the locked attribute). (The schemata deﬁned above
for victim selection, it should be noted, depend on the commutativity of con-
junction.)
genOnPageFault =
∃fmsg : FMSG; me, src : APREF | me = faultdrvr ∧src = hardware •
msgman.RcvMessage[me/dest?, src/src?, fmsg/m!]
∧(∃fpid : APREF; fs : SEGMENT;
ﬂpno : LOGICALPAGENO;
destpg : PHYSICALPAGENO •
fmsg = BADADDR⟨⟨fpid, fs, ﬂpno⟩⟩
((lck.Lock o
9
((pts.HaveFreePages ∧pts.AllocateFreePage[destpg/ppno!])
∨(haveVictim
∧swapPageToDisk[destpg/victim!])) ∧lck.Unlock)o
9
(lck.Lock o
9
(retrievePageFromDisk[fpid/p?, fs/sg?, ﬂpno/lpno?, page/pg!]
∧pfs.ClearRefBitsAndCounter[destpg/ppno?]
∧pfs.OverwritePhysicalPage[page/pg?, destpg/pageno?]
∧vsm.MarkSharedLogicalPageAsIn
[fpid/p?, fs/sg?, ﬂpno/lpno?]
∧lck.Unlock)))
o
9(lck.Lock ∧sched.MakeReady[fpid/pid?])
o
9(sched.ScheduleNext ∧lck.Unlock))
onPageFault = (sched.CurrentProcess[p/cp!] ∧genOnPageFault[p/p?]) \ {p}
DoOnPageFault =
(∀i : 1 . . ∞• onPageFault)
Proposition 158. If there are free pages, no page is swapped out.
Proof. The ﬁrst component of the sequential composition in the predicate
of genOnPageFault contains the disjunction:
(pts.HaveFreePages ∧pts.AllocateFreePage[destpg/ppno!])
∨(haveVictim ∧swapPageToDisk[destpg/victim!])
If there are free pages, pts.HaveFreePages is satisﬁed.
2
Proposition 159. If there are no free pages in main store, a page is swapped
out.

6.3 Virtual Storage
279
Proof. There is a disjunction in the composition forming genOnPageFault’s
predicate:
(pts.HaveFreePages ∧pts.AllocateFreePage[destpg/ppno!])
∨(haveVictim ∧swapPageToDisk[destpg/victim!])
In this case, if HaveFreePages is not satisﬁed, ¬ HaveFreePages must be sat-
isﬁed and the swap is performed by swapPageToDisk.
2
Proposition 160. If a process fault occurs, the referenced page overwrites a
page frame freed by swapping out.
Proof.
In the previous proposition, the page destpg was swapped out to
disk. In the second component of genOnPageFault’s predicate, the operation
overWritePhysicalPage occurs as a conjunct. By p ∧q ⊢p, the result follows.
2
Proposition 161. If a process faults, the referenced page is brought into store.
Proof. The operation retrievePageFromDisk[page/pg] is a conjunct in the
second component of the sequential composition in genOnPageFault.
2
Proposition 162. If there are free pages, only a free page is written when a
page is swapped in.
Proof.
The predicate of schema genOnPageFault contains the following
references:
pts.AllocateFreePage[destpg/ppno!] . . . o
9 . . .
retrievePageFromDisk[. . . , page/pg!]
pts.OverwritePhysicalPage[page/pg?, destpg/pageno?]
The physical page, destpg, is the one overwritten by page in the operation
deﬁned by the schema OverwritePhysicalPage. The physical page destpg is
allocated by AllocateFreePage. The page retrieved from disk is page; it is re-
trieved by retrievePageFromDisk (the omitted arguments refer to the faulting
process).
2
Proposition 163. Newly swapped pages have a zero reference count.
Proof. Reference bits are cleared in the newly swapped page by genOnPage-
Fault. The second component of this schema’s predicate contains, as one of its
conjuncts, a reference to pfs.ClearRefBitsAndCounter[destpg/ppno?]—this is
a reference to a page frame in physical store, not to the contents (which is
denoted by page in this predicate).
2

280
6 Virtual Storage
Proposition 164. Newly swapped pages cannot be victims unless all pages
are victims.
Proof. By the victim-ﬁnding operation, the victim has the minimum refer-
ence count:
IsVictim
(∃j : PHYSICALPAGENO | j ∈dom count •
count(j) = min(ran count))
A newly swapped-in page—one that has not yet been referenced—has a
reference count of 0. To become a victim, there must be no page with reference
count > 0.
2
A process can be waiting on a device when one of its pages is chosen
to swap out. If the driver copies data and puts it into buﬀers associated
with the waiting process’ PCBs, there is only the issue of swapping out the
page. However, there is no way a priori of knowing whether the page just
swapped out will cause a page fault when its owning process next executes.
Since swapping out does not aﬀect the operations of the device upon which
the victim is waiting, it would appear valid just to pick any process that is
not locked into main store.
The reader should note that, logically, this is perfectly adequate. As a
proposed implementation, this is unlikely to work well. It is to be expected
that page faults will be relatively frequent. The paging disk has a latency time
that must be taken into account. When a user process causes a page fault,
it must be blocked. Clearly, processes ought to be blocked for the shortest
possible time. The paging disk, however, serialises requests. All of this suggests
that the swapin/swapout operations should be as fast as possible.
Moreover, the speciﬁcation, as it stands, allows the ISR to respond to as
many interrupts as it can but it must also wait for the driver. The driver’s
message input is restricted to one immediate and one outstanding message.
This suggests that the ISR should enqueue messages on the driver and imme-
diately halt.
Furthermore, the context of the faulting process must be swapped immedi-
ately. This is because it cannot progress and must be taken oﬀthe processor:
alternatives are hard to discern. Removal of the current process’ registers from
the processor by the ISR is, therefore, justiﬁed.
Similarly, the page disk can lose requests if it just hangs between instruct-
ing a disk search and reading the result.
This subsystem also shows limitations with the message-passing r´egime.
Because a synchronous method has been adopted, the sender must wait if the
receiver is not in a state to receive. This has the implication that, should the
page disk process not be ready to accept another request (either because it is
waiting for the disk or because it is processing another request), the page-fault

6.3 Virtual Storage
281
handler will have to wait. This has the implication that the page-fault handler
might miss an interrupt.
The presence of operations to add and remove process data from the paging
disk complicates matters also. Luckily, these requests will be less common than
simple page faults.
PD
PFH
Dsk
Store
i
s
fault
ok
get
done
ISR
Fig. 6.4. The actual speciﬁcation.
The question for us is the following. Even though the classes and operations
presented above provide an adequate logical model, they do not take into
consideration all of the pragmatic issues. Should the speciﬁcation be altered
to reﬂect these pragmatic issues?
The speciﬁcation presented above can be represented diagrammatically
as in Figure 6.4. As can be seen, the virtual-storage management subsystem
consists of the ISR (denoted by ISR in the ﬁgure), the page-fault driver process
(denoted by PFH in the ﬁgure) and the disk driver process (denoted by PD).
The ﬁgure also includes the disk itself (denoted by DSK) and main store
(denoted by STORE).
The arrows in Figure 6.4 denote the messages or interactions between
processes. The arrow labelled i denotes the message sent by the ISR to the
page-fault handling process (PFH ). This message contains the speciﬁcation
of the page that was referenced (in terms of the segment and logical page
numbers) and the process (its APREF). The page-fault handler sends a fault
message containing the same information to the paging-disk process, which in
turn sends a request (as a get message) to the disk proper (actually, to the
disk driver). The disk driver retrieves the page and sends a done message to
the paging-disk handler. The done message denotes the fact that the retrieval
has been successfully completed.
Once the page has been written to main store, process PD sends an ok
message to the page-fault handler process, PFH . On reception of the ok, the
page-fault handler can wait for another page fault.

282
6 Virtual Storage
It is clearly a highly desirable property for any optimisations of the basic
(logical) speciﬁcation to behave in the same way as the speciﬁcation. It is
also highly desirable, given the present context, to be able to demonstrate
this in a formal way. In order to achieve this, the proposed optimisations are
formalised as CCS [21] processes so that they can be manipulated in formally
sound ways. CCS is chosen as the representation because we are interested
in the interactions between the component processes of the subsystem, not
in the speciﬁcation of the components. The processes to be modelled do not
have properties suggestive of the use of the π-calculus (e.g., mobility), so CCS
appears suﬃcient.
The subsystem can be represented in CCS as the following set of equations:
ISR = ¯i.ISR
PFH = i.fault.ok.PFH
PD = fault.get.done.¯s.ok.PD
DSK = get.done.DSK
STORE = s.STORE
The overall arrangement is represented in CCS as:
VM1 = (ISR | PFH | PD | DSK | STORE) \ {i, fault, ok, get, done, s}
(Note that actions are hidden using the \ operation.)
PD
Q
PFH
Dsk
Store
i
s
enq
deq
ok
get
done
ISR
Fig. 6.5. The speciﬁcation using a queue.
As noted above, the design depicted in Figure 6.4 and represented by the
above set of CCS process deﬁnitions can be optimised. An obvious optimisa-

6.3 Virtual Storage
283
tion is to introduce a queue of requests between the page-fault handler (PFH )
and paging-disk process (PD). This is the arrangement shown in Figure 6.5.
In the arrangement shown in Figure 6.5, the PFH process places new requests
into the queue. The queue is represented by the process named Q in the ﬁgure,
and the operation of sending a request (really, just an enqueuing of the re-
quest) is represented by the enq arrow. Requests are removed from the queue
process by the paging-disk process, PD, in exactly the same way they are in
the ﬁrst case. When the page has been copied to main store, the paging-disk
process, PD sends the page-fault handling process an ok to inform it that: (i)
the copy has been performed and that (ii) the process that caused the fault
just rectiﬁed can now be unblocked.
The argument is that this second version can process more page faults
per unit time. In this case, PFH does not now wait for the page fault to be
rectiﬁed before it can wait for a new fault. Instead, it passes the request to
the rest of the subsystem and then immediately blocks on the page-fault ISR.
This second arrangement can be represented by CCS processes as follows:
VM2 = init.(ISR | PFH2 | Q | PD2 | DSK | STORE)
\{i, enq, deq, ok, done, get, init, s}
For the deﬁnition of this subsystem, processes ISR, DSK and STORE remain
as in the ﬁrst case. The remaining processes must be redeﬁned as follows (the
subscripts will be explained below).
PFH2 = i.enq.ok.PFH2
Q = init.enq.Q1
Q1 = enq.Q1 + deq.Q1
PD2 = deq.get.done.¯s.ok.PD2
It is clearly necessary to distinguish between the two versions of PFH that
have been deﬁned at this point (a third version will be added shortly). For
this reason, subscripts were introduced into the speciﬁcations.
It would be useful for these two speciﬁcations (models) to be equivalent
in some sense. One important sense is that they should be observationally
equivalent; another is that they should be bisimilar.
The property of observational equivalence of two processes is very much the
intuitive one: two processes are observationally equivalent when they cannot
be distinguished by an external observer. In other words, the externally visible
events that can be perceived by an external observer are determined by the
observer to be the same in content and in order, no matter which process is
observed. In the cases of VM1 and VM2, the externally observable events are
restricted by the hiding operator (\, as in Z).
Bisimilarity is an equivalence that also takes hidden actions into account.
(Those readers unfamiliar with the concept should consult [21], Chapter 4,
for an extended treatment.)
It is now possible to engage in formal reasoning about processes VM1
and VM2 and to prove two important propositions about them. Rather than

284
6 Virtual Storage
engaging in a hand proof, it was considered interesting to employ automation.
To this end, the Concurrency Workbench of the New Century [8] was employed
as a tool. The Concurrency Workbench can be used to determine a number of
properties of CCS and CSP processes, including observational equivalence and
bisimilarity. The propositions concerning equivalence of the various versions
of the subsystem were all proved using the Concurrency Workbench.
Proposition 165. Processes VM1 and VM2 are observationally equivalent.
Proof. Both VM1 and VM2 were encoded in the input format required by
the CWB and tested using the eq -S obseq command. The CWB system
determined that VM1 and VM2 are observationally equivalent.
2
Matters are diﬀerent when it comes to bisimilarity. Processes VM1 and
VM2 are quite dissimilar in internal structure, and process VM2 oﬀers an
initial event, init, which initialises the process Q, so it does not appear, at
ﬁrst sight, that VM1 and VM2 will be bisimilar. Indeed, this is the case.
Proposition 166. Processes VM1 and VM2 are not bisimilar.
Proof. Both VM1 and VM2 were encoded in the input format required by
the CWB and tested using the eq -S bisim command. The CWB system
determined that VM1 and VM2 are not bisimilar.
2
PD
Q
PFH
PFH
Dsk
Store
i
s
enq
deq
ok
get
done
ISR
Fig. 6.6. The ideal speciﬁcation.

6.3 Virtual Storage
285
Finally, a second speciﬁcation can be considered as an optimisation. This
version retains the queue of requests. It diﬀers from the second version by
creating a new instance of the PFH process whenever an interrupt occurs.
This instance performs the same operations as in the second version but im-
mediately terminates (denoted by the 0 process). The CCS speciﬁcation is
(again, subscripts are used to diﬀerentiate between versions):
VM3 = init.(ISR | PFH3 | Q | PD2 | DSK | STORE)
\{i, enq, deq, ok, done, get, init, s}
where:
PFH3 = i.(enq.ok.0 | PFH3)
Proposition 167. VM3 is observationally equivalent to VM2.
Proof. The models for VM2 and VM3 were encoded in the input format re-
quired by the CWB and tested using the eq -S obseq command. The CWB
system determined that the two are observationally equivalent.
2
Proposition 168. VM3 is bisimilar to VM2.
Proof. The models for VM2 and VM3 were encoded in the input format re-
quired by the CWB and tested using the eq -S obseq command. The CWB
system determined that the two are bisimilar.
2
From the ﬁrst of these two results, we have the next proposition:
Proposition 169. Process VM1 is observationally equivalent to VM3.
Proof. By transitivity of the equivalence relation.
(In addition, the encoded models were tested using the eq -S obseq com-
mand and the result was supported by the CWB system.)
2
We also have the following negative result:
Proposition 170. Processes VM1 and VM3 are not bisimilar.
Proof. Again, by transitivity of the equivalence relation, this result would
be expected.
(In addition, the CWB supported the claim.)
2
The last result is not as bad as it sounds. All that is required, here, is that
the processes appear the same as far as an external observer is concerned.
This property is suﬃcient for the optimisations to be considered equivalent
to the original. However, as far as this chapter is concerned, the ﬁrst version
(the one referred to as the “logical” one) is the one that will be adopted.
With this discussion of optimisation out of the way, it is possible to return
to the main theme. There follow some propositions dealing with the properties
of the logical (Z) model of page faults.

286
6 Virtual Storage
Proposition 171. Page faults are serviced in the order in which they occur.
Proof. There are two senses:
1. Each page fault is an interrupt. In this sense, page faults are all processed
in order.
2. In this sense, page faults are serviced by the handler process which services
messages sent to it by the page-fault ISR. These messages are sent in
temporal (sequence) order. That the handler process operates upon these
messages in the correct order is a consequence of the correctness of the
message-passing operations.
Each sense implies the statement of the proposition.
2
Proposition 172. Every page fault is serviced eventually (i.e., the page-fault
mechanism is fair).
Proof. This proof follows from the correctness and fairness of the message-
passing operations.
2
Proposition 173. The process causing a page fault has status pstrunning
when the fault occurs.
Proof. Only a running process can cause a page fault.
ISRs cannot cause faults and are not processes.
Drivers are processes. They are locked into main store and, by hypothesis,
have all the necessary pages locked in as well.
Only user processes have pages that can be swapped into and out of store.
The fact that a fault occurs implies that the process causing it is executing.
There can only be one process that is executing at any one time (i.e., is the
current value of currentp and has a status of pstrunnning).
This is a property of the scheduler.
2
Proposition 174. A faulting process is not unblocked until the replacement
page has been swapped into physical store.
Proof. The service operation onPageFault ﬁrst blocks the faulting process by
setting its state to pstwaiting and by removing it from the processor. Therefore
blockFaultingProcess implies that currentp ̸= currentp′ ∧regs′ ̸= regs, where
regs are hardware registers.
The onPageFault operation takes the form of a sequential composition.
There are three operations, thus forming a composition of the form S1
o
9 S2
o
9
S3. The second operation is itself a sequential composition; it is this part
that performs the swapping operation. The operations are, therefore, totally
ordered and the order can be directly related to temporal succession.

6.3 Virtual Storage
287
Let p denote the faulting process and let the composition be written as
above. Then post S1 ⇒status(p) = pstwaiting and currentp′ ̸= p.
Throughout S2, status(p) = pstwaiting.
Finally, pre S3 ⇒status(p) = pstwaiting, while post S3 ⇒status(p) =
pstready but p ̸= currentp—the last being a property of MakeReady. It can-
not be true because the service process is currently executing.
2
Proposition 175. If a process, p, causes a page fault, that process is not
marked ready until the faulting page has been replaced.
Proof. This follows immediately from the previous proposition.
2
Proposition 176. After execution of onPageFault, there is exactly one phys-
ical page in physical store such that its logical page number in the faulting
process maps to the physical page number.
Proof. The proposition implies that exactly one page is mapped into store
by the page-fault mechanism.
Inspection of the predicate of genOnPageFault shows that only one page
is introduced into store.
2
Proposition 177. If a process, p, causes a page fault, after that page fault
has been serviced, the process is in the ready state.
Proof.
That the process is blocked follows immediately from Proposition
174. The predicate of genOnPageFault contains an instance of MakeReady
with the faulting process’ identiﬁer substituted for the formal parameter.
2
Proposition 178. If a page fault occurs and a page has to be swapped out,
that page can be a page belonging to the faulting process or to another process.
Proof. There are two cases to consider.
Case 1: If there are free pages, they are consumed. Only the faulting process
is aﬀected.
Case 2: HaveVictim is called. The victim page is found in physical store by
pfs.IsVictim:
ﬁndVictimPage =
pfs.VictimPhysicalPageNo
∧ﬁndVictimLogicalPage
The value returned by pfs.VictimPhysicalPageNo is just a physical page
number with the minimum reference count. The schema does not mention
processes. Similarly, ﬁndVictimLogicalPage in this class merely looks up the

288
6 Virtual Storage
owning process’ identiﬁer and the segment in which the page occurs, as well
as the logical page number of the victim page. Therefore, the page can belong
to any process in the system except those that lock it into main store (i.e.,
driver and system processes).
2
Proposition 179. If a page fault occurs and there are free pages in physical
store, physical store is updated; only one process is aﬀected.
Proof. By the deﬁnition of onPageFault:
pts.HaveFreePages ∧pts.AllocateFreePages
implies that the physical page to which the swapped-in page is to be written
is a free page in physical store.
In this case, only the faulting process is aﬀected. This is because the allo-
cation of a free page relates only to a single process (the process to which the
allocation is made).
2
Corollary 13. If a page fault occurs within process, p, and if a page has to
be swapped out, only a maximum of two processes are aﬀected by the page-
swapping operation.
Proof. Immediate from the two preceding propositions.
2
Proposition 180. No pages are swapped unless a page fault occurs.
Proof. Inspection reveals that only the schema genOnPageFault references
the relevant operations.
2
6.3.4 Extending Process Storage
Processes very often make requests to increase the amount of store they use.
In a paged system, this allocates more pages to the process. This subsection
contains a model of the operations. It is rarer for processes to release store but
operations to perform this task are deﬁned as well. Pages can also be shared
between processes. Sharing can be used, for example, to implement message
passing in virtual storage.
First, there is a problem with allocating pages. The problem is that there
might not be a physical page free when the request is made. The system could
block the requesting process until there is a free page in the page frame. This
solution does not ﬁt well with the aims of virtual storage. Furthermore, when
a new process is created, it will request a set of pages to hold code, data, stack,

6.3 Virtual Storage
289
etc. It would not be acceptable to block the creation of the process until main
store becomes free.
A solution more in keeping with the purpose of virtual store is the fol-
lowing. When a request is made to allocate a new page and there is no free
physical store, an empty page is allocated on disk. The new page is allocated
to the requesting process and can be written to by the requesting process.
This mechanism can be used when allocating extra pages to a new page.
Therefore, it is necessary to begin with the deﬁnition of the empty page:
pageofzeroes : PAGE
∀pg : PAGE •
pageofzeroes = λ i : 1 . . framesize • 0
This structure need not be held in a page; it can be produced in a loop and
then set into a buﬀer of smaller size. Ideally, it should be packed into a single
disk block and then handed to the paging disk. This needs to be iterated n
times, where n is the number of disk blocks per page.
Pages must be speciﬁed when allocating, deallocating and sharing. A
method for specifying them is required. Here, we deﬁne a structure for this
purpose:
PAGESPEC == APREF × SEGMENT × LOGICALPAGENO
The following axiomatic deﬁnitions are required to manipulate objects of type
PAGESPEC. The relation that comes ﬁrst will be discussed below. The rest
of the deﬁnitions are: the constructor function (mkpgspec) and the accessor
functions (pgspecpref to obtain the process reference, pgspecseg to obtain the
segment name and pgspeclpno to obtain the logical page number).
smap : PAGESPEC ↔PAGESPEC
mkpgspec : APREF × SEGMENT × LOGICALPAGENO →PAGESPEC
pgspecpref : PAGESPEC →APREF
pgspecseg : PAGESPEC →SEGMENT
pgspeclpno : PAGESPEC →LOGICALPAGENO
∀p : APREF; sg : SEGMENT; lpno : LOGICALPAGENO •
mkpgspec(p, sg, lpno) = (p, sg, lpno)
∀ps : PAGESPEC •
pgspecpref (ps) = fst ps
pgspecseg(ps) = fst(snd ps)
pgspeclpno(ps) = snd 2 ps
The type PAGESPEC could have been deﬁned earlier in this chapter. If it had
been used there, it would have been necessary to represent and manipulate
all virtual addresses and page references in terms of PAGESPEC. Although
this seems attractive, we believe, it would have complicated the speciﬁcations
somewhat.

290
6 Virtual Storage
The axiomatic deﬁnitions begin with smap, a relationship between el-
ements of PAGESPEC. This is the sharing map. When two elements of
PAGESPEC are in the relation, the processes mentioned as the ﬁrst com-
ponent of PAGESPEC share the page referred to by the two PAGESPECs.
The operations to allocate, deallocate and share pages are collected into a
(somewhat ad hoc) class called VStoreManager. The class is intended to act
as a component in an interface library. It exports most of its operations so
that a wide variety of combined operations can be deﬁned elsewhere.
VStoreManager
↾(INIT, AddNewMainStorePageToProcess, AddNewVirtualPageToProcess,
CanAddPageToProcess, MarkLogicalPageAsShared, UnshareLogicalPage,
WithdrawLogicalPage, SharedLogicalPageSharers, IsSharedLogicalPage,
RemoveSharedLogicalPageOwner, RemoveLogicalPageSharer,
RawShareLogicalPageBetweenProcesses, ShareLogicalPageBetweenProcesses,
ReturnSharedLogicalPageToOwner, MarkSharedLogicalPageAsIn,
MarkSharedLogicalPageAsOut, ShareLogicalSegment,
ReleaseSharedSegment, ReleaseSegmentPagesExcept,
CanReleaseSegment, SharedPagesInSegment, CanReleaseProcessVStore)
pts : PageTables
pfs : PageFrames
INIT
pgtabs? : PageTables
pfrms? : PageFrames
pts′ = pgtabs?
pfs′ = pfrms?
makeEmptyPage = . . .
AddNewMainStorePageToProcess = . . .
AddNewVirtualPageToProcess = . . .
CanAddPageToProcess = . . .
MarkLogicalPageAsShared = . . .
UnshareLogicalPage = . . .
WithdrawLogicalPage = . . .
SharedLogicalPageSharers = . . .
IsSharedLogicalPage = . . .
RemoveSharedLogicalPageOwner = . . .
RemoveLogicalPageSharer = . . .
RawShareLogicalPageBetweenProcesses = . . .

6.3 Virtual Storage
291
ShareLogicalPageBetweenProcesses = . . .
ReturnSharedLogicalPageToOwner = . . .
MarkSharedLogicalPageAsIn = . . .
MarkSharedLogicalPageAsOut = . . .
ShareLogicalSegment = . . .
ReleaseSharedSegment = . . .
ReleaseSegmentPagesExcept = . . .
CanReleaseSegment = . . .
SharedPagesInSegment = . . .
CanReleaseProcessVStore = . . .
First, there is the hidden operation that creates an empty page:
makeEmptyPage
pg! : PAGE
pg! = pageofzeroes
This operation is hidden because it is somewhat undesirable for everyone to
manipulate the buﬀers in which new pages are created.
The operation to add a new page to a process using a free-store page is
the following. It allocates the page frame, adds the page to the process and
clears the page (this is not really necessary but is a nice feature2).
AddNewMainStorePageToProcess =
(pts.HaveFreePages
∧((pts.IncProcessPageCount o
9 (pts.LatestPageCount)
∧pts.AllocateFreePage[ppno/ppno!]
∧pts.AddPageToProcess[ppno/ppno?, lpno!/lpno?]
∧makeEmptyPage[pg/pg?]
∧pts.OverwritePhysicalPage[ppno/pageno?, pg/pg?]) \ {ppno}))
Note that an alternative is to swap out a process’ page. The approach here is
simpler but much more proﬂigate.
The next operation uses the prceding one and then stores the page that it
has created on the paging disk. Note that the operation requires there to be
at least one page-sized buﬀer in the kernel.
AddNewVirtualPageToProcess =
(¬ pts.HaveFreePages
∧(pts.IncProcessPageCount o
9 pts.LatestPageCount)
2 Some (civilised?) operating systems perform this operation on allocating new
store.

292
6 Virtual Storage
∧(∃ppno : PHYSICALPAGENO | ppno = 1 •
(makeEmptyPage[pg/pg!]
∧pts.AddPageToProcess[lpno!/lpno?, ppno/ppno?]
∧StorePageOnDisk[lpno!/lpno?, pg/pg?])) \ {pg})
The value assigned to ppno is purely arbitrary. The physical page number
of any page on disk has no relevance because it will be mapped to another
physical page when swapped into main store.
The following is a predicate. It is true if the process denoted by p? can
add at least one page to its sg? segment.
CanAddPageToSegment
p? : APREF
sg? : SEGMENT
pagecount(p?)(sg?) < maxvirtpagespersegment
The actual operation to add a new page to a process is the following.
Depending upon the state of main store, it adds the page directly or stores it
on the paging disk:
AddNewPageToProcess =
AddNewMainStorePageToProcess
∨AddNewVirtualPageToProcess
Proposition 181. If there are no free pages in main store, a zero page is
created for it and written to disk.
Proof. The schema AddNewPageToProcess is a disjunction:
AddNewMainStorePageToProcess
∨AddNewVirtualPageToProcess
Each disjunct is a conjunction, with mutually exclusive ﬁrst conjuncts.
In particular, AddNewVirtualPageToProcess has a predicate containing
the following:
makeEmptyPage[pg/pg!]
∧
. . .
∧StorePageOnDisk[. . . , pg/pg?]
The existential quantiﬁer can be removed by the one-point rule, and the result
follows from the fact that p ∧q ⇒p.
2
Proposition 182. If there are free pages, one is allocated for the newly cre-
ated page.

6.3 Virtual Storage
293
Proof.
Similar to the above, concentrating on AddNewMainStorePage.
Again, p ∧q ⊢p allows the conclusion to be drawn.
2
The only thing that needs to be done when a page is shared between
processes is to mark it. This is actually done by adding PAGESPECs to the
sharing map, smap:
MarkLogicalPageAsShared
∆(smap)
ownproc?, shareproc? : APREF
ownseg?, shareseg? : SEGMENT
ownlp?, sharelp? : LOGICALPAGENO
(∃atrip1, atrip2 : PAGESPEC •
atrip1 = mkpgspec(ownproc?, ownseg?, ownlp?) ∧
atrip2 = mkpgspec(shareproc?, shareseg?, sharelp?) ∧
smap′ = smap ∪{(atrip1, atrip2)})
Unsharing, conversely, removes a pair of PAGESPECs from the sharing
map:
UnshareLogicalPage
∆(smap)
p? : APREF
sg? : SEGMENT
lpno? : LOGICALPAGENO
smap′ = smap −▷{mkpgspec(p?, sg?, lpno?)}
If a page is to be reallocated or removed from store completely, it must be
totally removed from the sharing map:
WithdrawLogicalPage
∆(smap)
owner? : APREF
sg? : SEGMENT
lpno? : LOGICALPAGENO
smap′ = {mkpgspec(p?, sg?, lpno?)} −◁smap
In later operations, it is necessary to determine which processes share a
given page. The page is speciﬁed by the sg? and lpno? inputs and is shared
by (at least) p?. The relational image is used to determine all the sharing
PAGESPECs and, hence, the sharing processes:

294
6 Virtual Storage
SharedLogicalPageSharers
p? : APREF
sg? : SEGMENT
lpno? : LOGICALPAGENO
srs! : F PAGESPEC
smap(| {mkpgspec(p?, sg?, lpno?)} |) = srs!
The following predicate is true when the page is shared:
IsSharedLogicalPage
p? : APREF
sg? : SEGMENT
lpno? : LOGICALPAGENO
mkpgspec(p?, sg?, lpno?) ∈dom smap
When, say, a process terminates or when a shared page used to contain a
message is withdrawn, the entry for the page must also be removed from the
smap:
RemoveSharedLogicalPageOwner
∆(smap)
p? : APREF
sg? : SEGMENT
lpno? : LOGICALPAGENO
smap′ = {mkpgspec(p?, sg?, lpno?)} −◁smap
All the sharers of a page can be removed from the smap by the following
operation:
RemoveLogicalPageSharers
∆(smap)
p? : APREF
sg? : SEGMENT
lpno? : LOGICALPAGENO
(∃pg : PAGESPEC | pg = mkpgspec(p?, sg?, lpno?) •
smap′ = smap −▷{pg})
The following pair of schemata deﬁne the operation of sharing a page
between two processes. The ﬁrst schema deﬁnes the actual operation, while
the second hides the logical page number. The ﬁrst operation returns the
logical page number of the shared page. Sometimes, this is something of a
nuisance, so the second operation hides it. The ﬁrst operation returns the
page number so that it can be referenced, while the second hides the page

6.3 Virtual Storage
295
number—approximately, it states that a page is shared but does not say which
it is.
RawShareLogicalPageBetweenProcesses =
((pts.IsLockedPage[owner?/p?, ownseg?/sg?, ownlpno?/lpno?]
∧pts.LockPage[sharer?/p?, shareseg?/sg?, sharelpno!/lpno?])
∨Skip)
∧NextNewLogicalPageNo[sharer?/p?, shareseg?/sg?, sharelpno!/lpno!]
∧(pts.PhysicalPageNo[owner?/p?, ownseg?/sg?, ownlpno?/lpno?, ppno/ppno!]
∧pts.AddPageToProcess[sharer?/p?, shareseg?/sg?, sharelpno!/lpno?]
∧MarkLogicalPageAsShared[owner?/ownproc?, sharer?/shareproc?,
ownlpno?/ownlp?, sharelpno!/sharelp?]
∧pts.MarkPageAsShared[owner?/p?, ownseg?/sg?, ownlpno?/lpno?]
∧pts.MarkPageAsShared[sharer?/p?, shareseg?/sg?, sharelpno!/lpno?])
\{ppno}
ShareLogicalPageBetweenProcesses =
RawShareLogicalPageBetweenProcesses \ {sharelpno!}
Proposition 183. If two processes share a page, pg, that page will appear in
the page tables of both processes.
Proof.
The page, pg?, is already assumed to be in the page table of
its owning process. The predicate of RawShareLogicalPageBetweenProcesses
contains, AddPageToProcess[sharer?/p?, shareseg?/sg?, sharelpno!/lpno?] as
a conjunct. The arguments to the substitution refer to the process that is
receiving the page.
2
Proposition 184. Schema RawShareLogicalPageBetweenProcesses makes the
speciﬁed page shared by both processes.
Proof. The predicate of RawShareLogicalPageBetweenProcesses contains an
instance of MarkPageAsShared, which simpliﬁes to smap′ = smap ∪{(s1, s2)},
where:
s1 = mkpgspec(ownproc?, ownseg?, ownlp?)
and
s2 = mkpgspec(sharer?, shareseg?, sharelp?)
and where ownproc? is the owning process identiﬁer and sharer? is the iden-
tiﬁer of the process being granted the right to share the page; ownseg? and
shareseg? denote the segments in the owner and sharer’s spaces; ownlp? is the
owning process’ logical page number and sharelp? is the logical page number
in the sharer’s segment.
2

296
6 Virtual Storage
The only point to note about the following is that it unshares the page in
question.
ReturnSharedLogicalPageToOwner =
pts.IsSharedPage[sharer?/p?, shareseg?/sg/, sharelpno?/lpno?]
∧pts.UnsharePage[sharer?/p?, shareseg?/sg/, sharelpno?/lpno?]
∧pts.RemovePageProperties[sharer?/p?, shareseg?/sg/, sharelpno?/lpno?]
∧pts.RemovePageFromPageTable[sharer?/p?, shareseg?/sg/,
sharelpno?/lpno?]
∧UnshareLogicalPage[sharer?/p?, shareseg?/sg/, sharelpno?/lpno?]
Proposition 185. When a page is unshared, it is removed from one of the
page tables.
Proof. The operation ReturnSharedLogicalPageToOwner removes the spec-
iﬁed page from one of the processes that share it. This is done by removing
the page from the sharer’s page table by means of the conjunct:
RemovePageFromPageTable[sharer?/p?, shareseg?/sg/, sharelpno?/lpno?]
The other conjuncts cancel various attributes, in particular:
RemovePageProperties[sharer?/p?, shareseg?/sg/, sharelpno?/lpno?]
as well as removing the information that this page is shared by process sharer?
by
UnsharePage[sharer?/p?, shareseg?/sg/, sharelpno?/lpno?]
and
UnshareLogicalPage[sharer?/p?, shareseg?/sg/, sharelpno?/lpno?]
.
2
Shared pages need to be marked as in-store or out-of-store. The following
pair of schemata deﬁne these operations. They will be used below.
MarkSharedLogicalPageAsIn =
(pts.IsSharedPage ∧pts.MarkPageAsIn ∧
(SharedLogicalPageSharers[srs/srs!] ∧
(∀pg : PAGESPEC | pg ∈srs •
(∃p : APREF; sg : SEGMENT;
lpno : LOGICALPAGENO •
pg = mkpgspec(p, sg, lpno)
∧pts.MarkPageAsIn[p/p?, sg/sg?, lpno/lpno?])) \ {srs}))
∨pts.MarkPageAsIn
Proposition 186. When a shared page is swapped in, it is swapped in in all
sharing processes.

6.3 Virtual Storage
297
Proof. The operation MarkPageAsIn occurs within the scope of the univer-
sal quantiﬁer which ranges over elements of PAGESPEC. These elements are
exactly those describing the shared page in processes other than its owner.
The operation MarkPageAsIn is applied to each descriptor (rather, to its com-
ponents) and records the fact that the page has entered main store in each of
the processes that share it.
2
MarkSharedLogicalPageAsOut =
(pts.IsSharedPage ∧pts.MarkPageAsOut ∧
(SharedLogicalPageSharers[srs/srs!] ∧
(∀pg : PAGESPEC | pg ∈srs •
(∃p : APREF; sg : SEGMENT;
lpno : LOGICALPAGENO •
mkpgspec(p, sg, lpno) = pg ∧
pts.MarkPageAsOut[p/p?, sg/sg?, lpno/lpno?]))) \ {srs})
∨pts.MarkPageAsOut
Proposition 187. When a shared page is swapped out, it is swapped out in
all sharing processes.
Proof. The operation deﬁned by MarkPageAsOut occurs inside the univer-
sal quantiﬁer in the predicate of MarkSharedLogicalPageAsOut. The universal
quantiﬁer ranges over all PAGESPEC elements that are related to the pro-
cess in which the page is being swapped. Each element of type PAGESPEC
records the process identiﬁer, segment identiﬁer and logical page number of
the page in the sharing processes. Therefore, the quantiﬁer ranges over all de-
scriptions of the page in the sharing process. The MarkPageAsOut operation
is applied to each of these descriptions, thus recording the fact that the page
is swapped out.
2
Proposition 188. The operation MarkSharedLogicalPageAsOut can never
mark a locked page as swapped out.
Proof. By Proposition 154.
2
The next schema deﬁnes the operation to return the next logical page
number available in the segment, sg?, of process p? (both sg? and p? are
inputs to the schema):
NextNewLogicalPageNo =
pts.IncProcessPageCount o
9 pts.LatestPageCount
Segments, too, can be shared and unshared. This is not obviously useful
but it turns out to be. When a process spawns a copy of itself or creates a child
process that shares its code, the code segment can be shared if it is read-only
(executable is a page attribute deﬁned at the start of this chapter).

298
6 Virtual Storage
ShareLogicalSegment
ownerp?, sharerp? : APREF
ownerseg?, sharerseg? : SEGMENT
(∀lpno : LOGICALPAGENO |
lpno ∈dom pagetable(ownerp?)(sharerp?) •
(∃ps1, ps2 : PAGESPEC; nxtlpno : LOGICALPAGENO •
ps1 = mkpgspec(ownerp?, ownerseg?, lpno) ∧
NextNewLogicalPageNo[nxtlpno/lpno!] ∧
ps2 = mkpgspec(sharerp?, sharerseg?, nxtlpno) ∧
pts.MarkPageAsShared
[ownerp?/p?, ownerseg?/sg?, lpno/lpno?] ∧
MarkLogicalPageAsShared[lpno/ownlp?, nxtlpno/sharelp?]))
ReleaseSharedSegment
∆(pagetable)
p? : APREF
sg? : SEGMENT
pagetable′ = {sg?} −◁pagetable(p?)
ReleaseSegmentPagesExcept
∆(pagetable)
p? : APREF
sg? : SEGMENT
except? : F LOGICALPAGENO
pagetable′ = ((dom pagetable(p?)(sg?)) \ except?) −◁pagetable(p?)(sg?)
Proposition 189. If except? = ∅, ReleaseSegmentPagesExcept implies that
the predicate of CanReleaseSegment is satisﬁed.
Proof. The predicate of CanReleaseSegment is:
dom pagetable(p?)(sg?) = ∅
The predicate of ReleaseSegmentPagesExcept is:
pagetable′ = ((dom pagetable(p?)(sg?)) \ except?) −◁pagetable(p?)(sg?)
Clearly (substituting ∅for except?):
((dom pagetable(p?)(sg?)) \ ∅) = dom pagetable(p?)(sg?)
Now,

6.4 Using Virtual Storage
299
(dom pagetable(p?)(sg?)) −◁pagetable(p?)(sg?)
implies that dom pagetable(p?)(sg?) = ∅. This is the predicate of the schema
CanReleaseSegment, so we are done.
2
Proposition 190. A process whose entire virtual store has been released has
no pages.
Proof. Obvious given the last proposition and the appropriate schema def-
initions.
2
The following predicate is true if and only if all the pages in the segment,
sg?, have been deallocated:
CanReleaseSegment
p? : APREF
sg? : SEGMENT
dom pagetable(p?)(sg?) = ∅
The pages in the segment sg? of process p? are output by this operation.
They constitute the set sps!.
SharedPagesInSegment
p? : APREF
sg? : SEGMENT
sps! : F LOGICALPAGENO
(∃psg : F PAGESPEC •
psg = smap(| {pg : PAGESPEC; lpn : LOGICALPAGENO |
pg = mkpgspec(p?, sg?, lpn) • pg} |) ∧
sps! = {pg : PAGESPEC; lpno : LOGICALPAGENO | pg ∈pgs •
pgspeclpno(pg)})
If a process has no pages and no segments (i.e., they have never been
allocated or all have been released), its page-table entry can be released. The
following schema is a predicate deﬁning this case.
CanReleaseProcessVStore
p? : APREF
dom pagetable(p?) = ∅
6.4 Using Virtual Storage
6.4.1 Introduction
This section is a rather looser model than the above model. It deals with the
user-level interfaces. The view of virtual store is that much more akin to real

300
6 Virtual Storage
store: a linear sequence of locations that can be addressed sequentially. The
concept of the virtual address is also diﬀerent in this section. Instead of a
complex structure, virtual addresses are considered atomic, in eﬀect a subset
of N.
6.4.2 Virtual Addresses
From this point on, the speciﬁcation will deal with virtual addresses, not with
logical and physical pages. This amounts to the user process’ perspective
on virtual storage. Hitherto, all the perspective has been that of the virtual
storage constructor, so virtual address spaces and virtual addresses have been
seen in terms of their components.
For this reason, the following is required:
AllocatePageReturningStartVAddress =
AddNewPageToProcess ∧ComputePageVAddress[lpno!/lpno?]
This operation, as its name suggests, allocates a page and returns the virtual
address of its start. (Note that the logical page number is not hidden; there
are reasons for this, as will be seen.)
The following operation computes a virtual address from its components.
ComputePageVAddress
lpno? : LOGICALPAGENO
vaddr! : N
vaddr! = (lpno? −pgallocstart) ∗framesize
Here, pgallocstart is a constant. It is deﬁned as:
pgallocstart : N
pgallocstart = 0
The value of 0 is completely arbitrary, as is now explained.
Some systems map a virtual copy of the operating system onto the vir-
tual address space of each user space (and some privileged processes, too).
The virtual copy can be allocated at the start or at the end of virtual store.
The allocation of user-process pages has to respect this. Furthermore, there
are special addresses that are reserved by the hardware; for example, inter-
rupt vectors, device buﬀers and status words. These, too, must be allocated
somewhere that cannot be directly accessed by untrusted user processes.
The pgallocstrt represents the logical page number of the ﬁrst page in a
segment that can be allocated.
For clarity and simplicity, it will be assumed here that the operating system
virtual copy is located entirely in its own space. Transfer to the operating

6.4 Using Virtual Storage
301
system from user space is achieved by a “mode switch”. The mode switch
activates additional instructions, for example those manipulating interrupts
and the translation lookaside buﬀer. How the mode switch is performed is
outside the scope of this book for reasons already given. Mode switches are,
though, very common on hardware that supports virtual store.
In some systems, there are parts of the kernel space that are shared be-
tween all processes in the system. These pages are pre-allocated and added
to the process image when it is created. Because they are pre-allocated, the
allocation of user pages in that process must be allocated at some page whose
logical page number is greater than zero. The constant pgallocstart denotes
this oﬀset.
Usually, the oﬀset is used in the data segment only. For simplicity, the
oﬀset is here set to 0. Moreover, it is uniformly applied to all segments (since
it is 0, this does not hurt).
The one hard constraint on virtual store is that some physical pages must
never be allocated to user space. These are the pages that hold the device
registers and other special addresses just mentioned.
Virtual-store pages are frequently marked as:
•
execute only (which implies read-only);
•
read-only;
•
read-write.
Sometimes, pages are marked write-only. This is unusual for user pages but
could be common if device buﬀers are mapped to virtual store pages.
The operations required to mark pages alter the attributes deﬁned at the
start of this chapter. The operations are relatively simple to deﬁne and are
also intuitively clear. They are operations belonging to the class deﬁned below
in Section 6.5.2; in the meanwhile, they are presented without comment.
MarkPageAsReadOnly =
MakePageReadable ∧
((IsPageWritable ∧MakePageNotWritable) ∨
((IsPageExecutable ∧MakePageNotExecutable)))
MarkPageAsReadWrite =
(MakePageReadable o
9 MakePageWritable) ∧
(IsPageExecutable ∧MakePageNotExecutable)
MarkPageAsCode =
(MakePageExecutable o
9 MakePageReadable) ∧
(IsPageExecutable ∧MakePageNotExecutable)
An extremely useful, but generic, operation is the following. It allocates n
pages at the same time:

302
6 Virtual Storage
AllocateNPages =
(∀p : 1 . . numpages? •
(p = 1 ∧AllocatePageReturningStartVAddress[startaddr?/vaddr!])
∨(p > 1 ∧
(∃vaddr : VADDR •
AllocatePageReturningStartVAddress[vaddr/vaddr!])))
As it stands, this operation is not of much use in this model. The reason for
this is that it does not set page attributes, in particular the read-only, execute-
only and the read-write attributes. For this reason the following operations are
deﬁned. The collection starts with the operation for allocating n executable
pages.
The following allocation operation is used when code is marked as exe-
cutable and read-only. This is how Unix and a number of other systems treat
code.
AllocateNExecutablePages =
(∀p : 1 . . numpages? •
(p = 1 ∧AllocatePageReturningStartVAddress[startaddr?/vaddr!]
∧MarkPageAsCode)
∨(p > 1 ∧
(∃vaddr : VADDR •
AllocatePageReturningStartVAddress[vaddr/vaddr!] ∧
MarkPageAsCode)))
Similarly, the following operations allocate n pages for the requesting pro-
cess. It should be remembered that the pages might be allocated on the paging
disk and not in main store.
AllocateNReadWritePages =
(∀p : 1 . . numpages? •
(p = 1 ∧AllocatePageReturningStartVAddress[startaddr?/vaddr!]
∧MarkPageAsReadWrite)
∨(p > 1 ∧
(∃vaddr : VADDR •
AllocatePageReturningStartVAddress[vaddr/vaddr!] ∧
MarkPageAsReadWrite)))
AllocateNReadOnlyPages =
(∀p : 1 . . numpages? •
(p = 1 ∧AllocatePageReturningStartVAddress[startaddr?/vaddr!]
∧MarkPageAsReadOnly)
∨(p > 1 ∧
(∃vaddr : VADDR •
AllocatePageReturningStartVAddress[vaddr/vaddr!] ∧
MarkPageAsReadOnly)))

6.4 Using Virtual Storage
303
To support the illusion of virtual storage, virtual addresses can be thought
of as just natural numbers (including 0):
VADDR == N
and the virtual store for each process can be considered a potentially inﬁnite
sequence of equal-sized locations:
VirtualStore
vlocs : seq PSU
maxaddr : N
#locs = maxaddr
It must be emphasised that each virtual address space has its own copy of
the VirtualStore schema. Page and segment sharing, of course, make regions
of store belonging to one virtual address space appear (by magic?) as part of
another.
The usual operations (read and write) will be supported. However, when
the relevant address is not present in real store, a page fault occurs and the
OnPageFault driver is invoked with the address to bring the required page
into store.
For much of the remainder, a block-copy operation is required. This is
used to copy data into pages based on addresses. For the time being, it can
be assumed that every address is valid (the hardware should trap this, in any
case).
CopyVStoreBlock
∆VirtualStore
data? : seq PSU
numelts? : N
destaddr? : VADDR
vlocs′ = (λ i : 1 . . (destaddr? −1) • vlocs(i))
⌢⟨data?⟩⌢(vlocs after (destaddr? + numelts?))
If any of the addresses used in this schema are not in main store, the page-
faulting mechanism will ensure that it is loaded.
Operations deﬁning the user’s view of virtual store are collected into the
following class. It is deﬁned just to collect the operations in one place. (In the
next section, the operations are not so collected—they are just assumed to be
part of a library and are, therefore, deﬁned in Z.)
The class is deﬁned as follows. The deﬁnition is somewhat sparse and con-
tains only two operations, CopyVStoreBlock and CopyVStoreFromVStore. In
a full implementation, this class could be extended considerably. The point,
here, though, is merely to indicate that operations similar to those often im-
plemented for real store can be implemented in virtual storage systems at

304
6 Virtual Storage
a level above that at which virtual addresses are manipulated as complex
entities.
UsersVStore
↾(INIT, CopyVStoreBlock, CopyVStoreFromVStore)
vlocs : seq PSU
maxaddr : N
#locs = maxaddr
INIT
maxaddress? : N
maxaddr ′ = maxaddress?
CopyVStoreBlock = . . .
CopyVStoreFromVStore = . . .
Data can be copied into a virtual-store page (by a user process) by the
following operation:
CopyVStoreBlock
∆VirtualStore
data? : seq PSU
numelts? : N
destaddr? : VADDR
vlocs′ = (λ i : 1 . . (destaddr? −1) • vlocs(i))
⌢⟨data?⟩⌢(vlocs after (destaddr? + numelts?))
A similar operation is the following. It copies one piece of virtual store
to another. It is useful when using pages as inter-process messages: the data
comprising the message’s payload can be copied into the destination (which
might be a shared page in the case of a message) from the page in which it
was assembled by this operation:
CopyVStoreFromVStore
∆VirtualStore
fromaddr? : VADDR
toaddr? : VADDR
numunits? : N1
(∃endaddr : VADDR | endaddr = fromaddr? + numunits? −1 •
vlocs′ = (λ i : 1 . . (toaddr? −1) • vlocs(i))
⌢(λ j : fromaddr? . . endaddr • vlocs(j))
⌢(vlocs after endaddr + 1))

6.4 Using Virtual Storage
305
6.4.3 Mapping Pages to Disk (and Vice Versa)
Linux contains an operation called memmap in its library. This maps virtual
store to disk store and is rather useful (it could be used to implement persistent
store as well as other things, heaps for instance).
A class is deﬁned to collect the operations together. Again, this class is
intended only as an indication of what is possible. In a real system, it could
be extended considerably; for example, permitting the controlled mapping of
pages between processes, archiving of pages, and so on.
PageMapping
↾(INIT, MapPageToDisk, MapPageFromDiskExtendingStore)
usrvm : UserVStore
pfr : PageFrames
INIT
uvm? : UserVStore
pgfrm? : PageFrames
usrvm′ = uvm?
pfr ′ = pgfrm?
MapPageToDisk = . . .
MapPageFromDiskExtendingStore = . . .
writePageToDisk = . . .
readPageFromDisk = . . .
The operations in this class are all fairly obvious, as is their operation.
Commentary is, therefore, omitted.
writePageToDisk
. . .
diskparams? : . . .
pg? : PAGE
. . .
MapPageToDisk =
(pgt.PhysicalPageNo[ppno/ppgno!] ∧
pfr.GetPage[ppno/pageno?, pg/fr!] ∧
writePageToDisk[pg/pg?]) \ {ppno, pg}

306
6 Virtual Storage
readPageFromDisk
. . .
diskparams? : . . .
pg! : PAGE
. . .
This operation extends the store of the requesting process. It is used when
reading pages from disk. The disk page is added to the process’ virtual storage
image.
MapPageFromDiskExtendingStore =
usrvm.AllocatePageReturningStartVAddress[pageaddr!/vaddr!]o
9
(readPageFromDisk[pg/pg!] ∧
(∃sz : N | sz = framesize •
usrvm.CopyVStoreBlock
[sz/numelts?, pg/data?, pageaddr!/destaddr?]))
\{pg}
There ought to be an operation to delete the page from the image. However,
only the most careful programmers will ever use it, so the operation is omitted.
It is, in any case, fairly easy to deﬁne.
Note that there is no operation to map a disk page onto an existing virtual-
store page. This is because it will probably be used extremely rarely.
The operations in this class could be extended so that the speciﬁed disk as
well as the paging disk get updated when the frame’s counter is incremented.
This would automatically extend the disk image. A justiﬁcation for this is
that it implements a way of protecting executing processes from hardware
and software failure. It can be used as a form of journalling.
This scheme can also be used on disk ﬁles. More generally, it can also
work on arbitrary devices. This could be an interesting mechanism to explore
when considering virtual machines of greater scope (it is an idea suggested by
VME/B). Since this is just speculation, no more will be said on it.
6.4.4 New (User) Process Allocation and Deallocation
This section deals only with user-process allocation and deallocation. The
general principles are the same for system processes but the details might
diﬀer slighty (in particular, the default marking of pages as read-only, etc.).
When a new process is created, the following schema is used. In addition,
the virtual-store-management pages must be set up for the process. This will
be added to the following schema in a compound deﬁnition.

6.4 Using Virtual Storage
307
UserStoreMgr
↾(INIT, MarkPageAsReadOnly, MarkPageAsReadWrite, MarkPageAsCode,
AllocateNPages, AllocateNExecutablePages, AllocateNReadWritePages,
AllocateNReadOnlyPages, CopyVStoreBlock, CopyVStoreFromVStore,
AllocateNewProcessStorage, ReleaseSharedPages,
FinalizeProcessPages, AllocateCloneProcessStorage)
usrvm : UserVStore
pgt : PageTables
INIT
uvm? : UserVStore
ptbl? : PageTables
usrvm′ = uvm?
pgt′ = ptbl?
MarkPageAsReadOnly = . . .
MarkPageAsReadWrite = . . .
MarkPageAsCode = . . .
AllocateNPages = . . .
AllocateNExecutablePages = . . .
AllocateNReadWritePages = . . .
AllocateNReadOnlyPages = . . .
CopyVStoreBlock = . . .
CopyVStoreFromVStore = . . .
AllocateNewProcessStorage = . . .
ReleaseSharedPages = . . .
FinalizeProcessPages = . . .
AllocateCloneProcessStorage = . . .
AllocateNewProcessStorage
p? : APREF
codepages? : seq PSU
codesz?, stacksz?, datasz?, heapsz? : N
(∃sg : SEGMENT; codeszunits : N |
sg = code ∧codeszunits = #codepages? •

308
6 Virtual Storage
AllocateNExecutablePages
[codesz?/numpages?, addr/startaddr!]o
9
usrvm.CopyVStoreBlock
[codepages?/data?, codeszunits/numelts?,
addr/destaddr?])
(∃sg : SEGMENT | sg = data •
AllocateNReadOnlyPages[datasz?/numpages?])
(∃sg : SEGMENT | sg = stack •
AllocateNReadWritePages[stacksz?/numpages?])
(∃sg : SEGMENT | sg = heap •
AllocateNReadWritePages[heapsz?/numpages?])
ReleaseSharedPages
∆(smap)
p? : APREF
(∀ps : PAGESPEC | ps ∈dom smap ∧pgspecpref (ps) = p? •
(∃s : PAGESPEC | (ps, s) ∈smap •
smap′ = smap \ {(ps, s)}))
∧(∀ps : PAGESPEC | ps ∈ran smap ∧psgpecpref (ps) = p? •
(∃s : PAGESPEC | (s, ps) ∈smap •
smap′ = smap \ {(s, ps)}))
Once this schema has been executed, the process can release all of its
pages:
FinalizeProcessPages =
pgt.RemovePageProperties ∧pgt.RemoveProcessFromPageTable
AllocateCloneProcessStorage
p? : APREF
clonedfrom? : APREF
stacksz?, datasz?, heapsz? : N
(∃sg : SEGMENT | sg = code •
ShareLogicalSegment[clonedfrom?/ownerp?, p?/sharerp?,
sg/ownerseg?, sg/sharerseg?])
(∃sg : SEGMENT | sg = data •
AllocateNReadOnlyPages[datasz?/numpages?])
(∃sg : SEGMENT | sg = stack •
AllocateNReadWritePages[stacksz?/numpages?])
(∃sg : SEGMENT | sg = heap •
AllocateNReadWritePages[heapsz?/numpages?])

6.5 Real and Virtual Devices
309
This works because of the following argument. The ﬁrst of the two
schemata (ReleaseSharedPages) above ﬁrst removes the process from all of
the pages that it shares but does not own. Then it removes itself from all of
those shared pages that it does own. This leaves it with only those pages that
belong to it and are not shared with any other process.
If a child process performs the ﬁrst operation, it will remove itself from
all of the pages it shares with its parents; it will also delete all of the pages
it owns. The parent is still in possession of the formerly shared pages, which
might be shared with other processes. As long as the parent is blocked until
all of its children have terminated, it cannot delete a page that at least one of
its children uses. Thus, when all of a process’ children have terminated, the
parent can terminate, too. Termination involves execution of the operations
deﬁned by ReleaseSharedPages and FinalizeProcessPages.
The only problem comes with clones. If the clone terminates before the
original, all is well. Should the original terminate, it will delete pages still
in use by the clone. Therefore, the original must also wait for the clone to
terminate.
An alternative—one that is possible—is for the owner to “give” its shared
pages to the clone. Typically, the clone will only require the code segment and
have an empty code segment of its own. If the code segment can be handed
over to the clone in one operation (or an atomic operation), the original can
terminate without waiting for the clone or clones. Either is possible.
The allocation of child processes is exactly the same as cloning. The dif-
ference is in the treatment of the process: is it marked as a child or as a
completely independent process? Depending upon the details of the process
model, a child process might share code with its parent (as it does in Unix
systems), whereas an independent process will tend to have its own code (or
maybe a copy of its creator’s code). In all cases, the data segment of the new
process, as well as its stack, will be allocated in a newly allocated set of pages.
In this chapter’s model, data and stack will be allocated in newly allocated
segments. The mechanisms for sharing segments of all kinds have been mod-
elled in this chapter, as have those for the allocation of new segments (and
pages). The storage model presented in this chapter can, therefore, support
many diﬀerent process models.
6.5 Real and Virtual Devices
There is often confusion between real and virtual devices. It is sometimes
thought that the use of virtual store implies the use of virtual devices. This is
not so. In most operating systems with virtual store, the devices remain real,
while in some real-store operating systems, devices are virtual.
Virtual devices are really interfaces to actual, real ones. Virtual devices
can be allocated on the basis of one virtual device to each process. The virtual
device sends messages to and receives them from the device process. Messages

310
6 Virtual Storage
are used to implement requests and replies in the obvious fashion. Messages
to the real device from the virtual devices are just enqueued by the device
process and serviced in some order (say, FIFO).
The interface to the virtual device can also abstract further from the real
device. This is because virtual devices are just pieces of software. For example,
a virtual disk could just deﬁne read and write operations, together with return
codes denoting the success of the operation. Underneath this simple interface,
the virtual device can implement more complex interfaces, thus absolving the
higher levels of software from the need to deal with them. This comes at the
cost of inﬂexibility.
This model can be implemented quite easily using the operations already
deﬁned in this book. Using message passing, it can be quite nicely structured.
There is another sense in which devices can be virtualised. Each device
interface consists of one or more addresses. Physical device interfaces also in-
clude interrupts. Operations performed on these addresses control the device
and exchange data between device and software. The addresses at which the
device interface is located are invariably ﬁxed in the address map. However,
in a virtual system, there is the opportunity to map the pages containing
device interfaces are mapped into the address space of each process. (This
can be done, of course, using the sharing mechanism deﬁned in this chapter.)
This allows processes directly to address devices. However, some form of syn-
chronisation must be included so that the devices are fairly shared between
processes (or virtual address spaces). Such synchronisation would have to be
included within the software interface to each device and this software can be
at as low a level as desired.
A higher-level approach is to map standard addresses (by sharing pages)
into each address space but to include a more easily programmed interface.
Again, the mechanisms deﬁned in this book can be used as the basis for this
scheme.
6.6 Message Passing in Virtual Store
At a number of points in this chapter, the idea of using shared pages (or sets
of shared pages) to pass messages between processes has been raised. The
basic mechanisms for implementing message passing have also been deﬁned.
When one process needs to send a message to another, it will allocate
a page and mark it as shared with the other process. Data will typically be
placed in the page before sharing has been performed. The data copy operation
can be performed by one of the block-copy operations, CopyVStoreBlock or
CopyVStoreFromVStore (Section 6.5.1).
The receiving process must be notiﬁed of the existence of the new page
in its address space. This can be achieved as either a synchronous or an
asynchronous event—the storage model is completely neutral with respect to

6.7 Process Creation and Termination; Swapping
311
this. In a system with virtual storage, message passing will be implemented as
system calls, so notiﬁcation can be handled by kernel operations. For example,
the synchronous message-passing primitives deﬁned in Chapter 5 can easily be
modiﬁed to do this. What is required is that the message call point to a page
and not to a small block of storage. Equally, the asynchronous mechanism
outlined in Chapter 3 can be modiﬁed in a similar fashion.
Message passing based on shared pages will be somewhat slower at runtime
than a scheme based upon passing pointers to shared storage blocks (buﬀers),
even when copying buﬀers between processes is required. The reason for this
is clear from an inspection of the virtual storage mechanisms. For this reason,
it would probably be best to implement two message-passing schemes: one
for kernel and one for user messages. The kernel message scheme would be
based on shared buﬀers within kernel space; user messages would use the
shared-page mechanism outlined above.
In some cases, additional system processes are required in addition to those
executing inside the kernel address space and they will be allocated their own
virtual store. In order to optimise message passing between these processes
and the kernel, a set of pages can be declared as shared but not incore (i.e.,
not locked into main store). The set of pages can be pre-allocated by the
kernel at initialisation time, so no new pages need to be allocated. All that
remains is for the pages to be given to the processes. This can be achieved
using the primitives deﬁned in this chapter.
6.7 Process Creation and Termination; Swapping
Process creation, activation and termination are unaﬀected by the virtual
storage mechanisms. The virtual storage subsystem must be booted before
any processes are created, so all processes, even those inside the kernel, are
created in virtual address space. The primitives to allocate and deallocate
storage have been deﬁned above (Sections 6.5.1 and 6.5.3). The operations
to create and delete processes can be implemented in a way analogous to
those deﬁned in Chapter 4 (and assumed in Chapter 5), with the virtual-store
primitives replacing those handling real store. The most signiﬁcant diﬀerence
between the two schemes is that the virtual-store allocation operations are
not as limited in the amount of store they can allocate. The virtual storage
operations are only limited by the number of pages permitted in a segment
and not be the size of main store.
Virtual store also has advantages where swapping is concerned. It is possi-
ble to include a swapping system in a virtual-store-based system. As with the
scheme deﬁned in detail in Chapter 4, the swapper will transfer entire process
images between main store and the swap disk (or swap ﬁle). Under virtual
storage, the swapper treats the page as the basic unit for transfer. The swap-
per reads the page table and swaps physical pages to disk. Not all segments
need be swapped to disk; code segments might be retained in main store while

312
6 Virtual Storage
there are active child processes. The process is, however, complicated by the
fact that a process image is likely to be shared between the paging disk and
main store.

7
Final Remarks
Sic transit Gloria Swanson
– Anon.
7.1 Introduction
Rather than just end the book with the virtual storage model, it seems ap-
propriate to add a few concluding remarks.
The chapter is organised as follows. In the next section, the models of this
book are reviewed and some omissions mentioned. In Section 7.3, the whole
idea of engaging in the formal modelling activity is reviewed. Finally, Section
7.4 contains some thoughts about what to do in the future.
7.2 Review
The formal models of three operating systems have been presented. All three
kernels are intended for use on uni-processor systems. They are also examples
of how the classical kernel model described in Chapter 1 can be interpreted;
it should be clear that the invariants stated in Chapter 1 are maintained by
the three kernels.
The ﬁrst model (Chapter 3) is of a simple kernel of the kind often encoun-
tered in real-time and embedded systems. The system has no kernel interface
and does not include such things as ISRs and device drivers. The user of
this kernel is expected to provide these components on a per-application ba-
sis. This is common for such systems because the devices to which they are
connected are not speciﬁed and are expected to vary among applications.
The ﬁrst kernel can be viewed as a kind of existence proof. It shows that it
is possible to produce a formal model of an operating system kernel. However,
the kernel of Chapter 3 should not be considered a toy, for it can be reﬁned
to real working code.

314
7 Final Remarks
The second kernel is for a general-purpose system. The model includes a
number of device drivers, in particular a clock process that is central to the
process-swapping mechanism. The kernel uses semaphores for synchronisation
and as the basic inter-process communication mechanism (here, shared mem-
ory). The kernel uses a time-based mechanism for multiplexing main store
between processes; the kernel supports more processes than can be simulta-
neously maintained in main store. A storage-management subsystem is also
provided to manage main store. It does so in a fairly rudimentary fashion,
based upon the allocation of relatively large chunks of store for each process
(the actual division of process store is left undeﬁned because it is often deter-
mined by the compiler—GNU C’s approach was at the back of the author’s
mind while producing this model). The chapter contains the proofs of many
kernel properties, and includes a proof of the correctness of the model for
semaphores.
The second kernel is of approximately the complexity of kernels such as
those built by Digital Equipment for the excellent operating systems running
its PDP-11 series of minicomputers in the 1970s. It is of approximately the
complexity of the kernel of Tannenbaum’s Minix [30] system (minus signals,
ﬁle system and terminal interface). Indeed, Minix was a signiﬁcant inﬂuence
on the models in Chapters 4 and 5.
The third kernel is not presented in its entirety. It is a variation on the
second one. The two diﬀer in that the third uses message passing for IPC.
The message-passing primitives are modelled, as is a generic ISR based on
the use of messages for the unblocking of drivers. All communication and
synchronisation in this kernel is based upon synchronous message exchange.
The various device drivers and the process-swapping subsystem are outlined
as message-passing processes. A kernel interface is also outlined. The interface
implements system calls as messages and a library of system calls is presented.
The chapter contains a number of proofs of properties of the message-passing
mechanisms and also contains a proof that only one process can be in the
kernel at any one time.
The ﬁnal exercise is in the modelling of virtual storage. This was included
because many systems today use virtual store for system and user processes.
There are issues in the construction of virtual storage systems that are not
covered in detail in standard textbooks (they must be confronted without
much support from the literature). In a sense, it is necessary to have virtual
store in order to construct it. Virtual storage aﬀords a number of beneﬁts
including automatic storage management at the page level, management of
large address spaces and support for more processes than will simultaneously
ﬁt into main store without having to resort to the all-or-nothing techniques
exempliﬁed by the swapping mechanisms in the previous kernels. Message
passing is also assisted by virtual storage, as is device-independent I/O (al-
though it is not considered in detail in Chapter 6)—more will be said on these
matters in the last section of this chapter (Section 7.4).

7.2 Review
315
It has been pointed out (in Chapter 1) that ﬁle systems are not considered
part of the kernel. File systems are certainly part of the operating system but
not part of the kernel. They are considered privileged code that can directly
access kernel services such as device drivers, but they are not considered by
the author to be kernel components—they rely upon the abstractions and
services provided by the kernel. File systems do provide an abstraction: the
abstractions of the ﬁle and the directory. However, it is not necessary for
a system to have a ﬁle system, even in general-purpose systems—consider
diskless nodes in distributed systems and, of course, real-time systems, and
there have been a number of attempts to replace ﬁle systems with databases;
Mach, famously, relegates the ﬁle system to a trusted process outside the
kernel. In keeping with the designers of Mach, the author believes that the
inclusion of ﬁle systems in kernels should be resisted as an example of “kernel
bloat” (the tendency to include all OS modules inside the protected walls of
the kernel, as is witnessed by many familiar kernels).
It can be argued that this approach to ﬁle systems restricts the task of
the kernel. This cannot be denied. It also restricts the services expected of
the kernel. This, again, cannot be denied. Indeed, the author considers both
points to be positive: the kernel should be kept as small as possible so that
its performance can be maximised. Furthermore, by restricting the kernel in
this way, it is easier to produce formal kernel models and to perform the kind
of modelling activity that has been the subject of this book. This has the
side-eﬀect that, should the kernel be implemented, it can be supported by
correctness arguments of the kind included above and its implementation can
be justiﬁed by formal reﬁnement.
As far as the author is concerned, the most signiﬁcant omissions are:
•
initialisation;
•
asynchronous signals.
The initialisation operations for each kernel can be inferred from remarks
in the models as well as the formal structure of the classes (modules) that
comprise them. The modelling of the initialisation routines for each kernel
should be a matter of reading through the models; the idle process and the
basic processes of the kernels must be created and started at the appropriate
time. Initialisation, even of virtual store, poses no new problems as far as
formal models are concerned.
Asynchronous signals should be taken as including such things as the ac-
tions taken by the system when the user types control-c, control-d, etc., at a
Unix (POSIX) console. From experience with Unix, it is clear that there is
not much of an in-principle diﬃculty, just a practical one of including it in
the models1. Asynchronous signals need to be integrated with ISRs and with
the interrupt scheme for the system (it can be done in a device-independent
1 For this book, there were time and length constraints that mitigated against the
inclusion of such a component.

316
7 Final Remarks
fashion, as the Unix and Linux kernels show). It is just a matter of producing
the models and showing that they are correct (the latter is a little more of a
challenge, of course).
A more detailed model of a complex interrupt structure would also be of
considerable interest. This should be taken as an initial step in the formal
modelling of the lowest level of the kernel. Such a model would have to be
hardware speciﬁc and would have to be undertaken during the reﬁnement to
code of a model of a kernel at the level of this book.
7.3 Future Prospects
In this section, a number of possible projects are suggested. The author is al-
ready reﬁning two formal models to implementation, so the issue of reﬁnement
is being attempted.
The ﬁrst area is to employ formal models in the deﬁnition and exploration
of non-classical kernel models. For example, some embedded systems are event
driven. This has implications for IPC, device handling and process structur-
ing. As a ﬁrst step, the author is working on a tiny event-based kernel but
more work is required. It is clear that the beneﬁts of formal models can be
demonstrated most graphically in the embedded and real-time areas, areas in
which the highest reliability and integrity are required.
In a similar fashion, the formal approach can assist in the production of
more secure systems. After all, if hackers can gain unauthorised access to
a kernel, they can control the entire system (as tools such as Back Oriﬁce
demonstrate). There are many areas in the kernels modelled in this book
that need attention as far as security is concerned. Many of these areas were
identiﬁed during the modelling process but nothing has been done to plug the
holes.
The extension of formal techniques to multi-processor systems is clearly
of importance, particularly with the advent of multicore processor chips. It
is natural, then, also to consider distributed operating systems from a formal
viewpoint, at kernel and higher levels. Within the area of distributed systems,
there are systems that support code and component mobility. The classical
position is that the kernel must support a basic set of features and that the rest
can be relegated to servers; this needs to be questioned, particularly because
the basic set of features can look like a speciﬁcation of a rather large classical
kernel. There is a need for IPC and networking, as well as storage management
but what else should be supported, particularly when components are mobile?
As Pike [24] has pointed out, there is very little new in operating systems
research these days. Most “new” systems look like Unix or Windows. Pike
makes the point that the domination of these systems serves to reduce the
level of innovation in operating systems in particular and systems research
in general. The two major systems have their own ways of doing things and
there is a tendency to believe that they will be there for all time. This leads to

7.3 Future Prospects
317
a reluctance to think of genuinely new ways of doing things. In addition, the
existence of such giants and their established user communities implies that
the cost and risk of developing new system concepts are just not worthwhile.
There is, though, a need to look for new approaches to operating system
design. New concepts are appearing in other areas that will impact upon
operating systems (mobility is a case in point, as is ubiquitous computing)
and it is unlikely that systems designed in the 1960s, 1980s or 1990s will be
able to form an adequate basis for their full exploitation. The whole area of
computing is changing: networks are established as a structure and are always
becoming cheaper. Networks suggest distributed applications, mobility and
ubiquity.
There are also hardware developments (multicore processors have already
been mentioned—they will oﬀer genuine parallel processing within a single
box). Prompted by the appearance of 64-bit processors (and why not have 128-
or even 1024-bit address spaces), there has been some work on systems with
very large address spaces. In these systems, persistence can become a reality,
not an add-on. The idea is that, with a suﬃciently large address space, there
is never any need to delete or destroy anything. The use of storage networks
is another development in support of this, as is the idea that storage devices
autonomously handle all storage and retrieval. The interfaces to such devices
deal mostly with naming. If objects are never deleted, there is not only a
naming problem, but the problem of determining which object to retrieve—it
will hardly be possible to remember the names of all the objects stored in a
space that can potentially hold 2128 objects. It will be necessary to introduce
new ways to access these objects and in reasonable time, too.
The classical models have served us well, but it is not necessarily the case
that they will do so in the future, given the demands of huge address spaces,
large networks and mobility. Formal techniques can help in these research
areas for reasons stated earlier in this chapter: they constitute a method by
which systems can be designed and experimented with without implemen-
tation. Promising ideas can be explored in a real scientiﬁc and engineering
manner, and with less ambiguity.

References
1. Baseten, J. C. M., Applications of Process Algebra, Tracts in Theoretical Com-
puter Science, No. 17, Cambridge University Press, Cambridge, England, 1990.
2. Bevier,
W.,
A
Veriﬁed
Operating
System
Kernel,
Ph.
D.
Dis-
sertation,
University
of
Texas,
Austin,
1987.
(Ftp:
ftp.cs.utexas.edu/pub/boyer/diss/bevier.pdf.)
3. Birrell, A. D., Guttag, J. V., Horning, J. J. and Levin, R., Synchronistaion
Primitives for a Multiprocessor: A Formal Speciﬁcation, ACM Operating Sys-
tems Review, 1987.
4. Boret, Daniel P. and Cesati, Marco, Understanding the Linux Kernel, O’Reilly
and Associates, Sebastopol, CA, 2001.
5. Brinch Hansen, Per, Operating Systems Principles, Prentice-Hall, Englewood
Cliﬀ, NJ, 1973.
6. Brinch Hansen, Per, The Architecture of Concurrent Programs, Prentice-Hall,
Englewood Cliﬀs, NJ, 1977.
7. Cavalcanti, Ana, Sampaio, Augusto and Woodcock, Jim, A Reﬁnement Strategy
for Circus, Formal Aspects of Computing, Vol. 15, Nos. 2 and 3, pp. 146–181,
2003.
8. Cleveland, Rance, Li, Tan and Sims, Steve, The Concurrency Workbench of
the New Century, North Carolina State University and SUNY, 2000. (Available
from http://www.cs.sunysb.edu/˜ cwb)
9. Comer, Douglas, Operating Systems Design, The Xinu Approach, Prentice-Hall,
Upper Saddle River, NJ, 1984.
10. Craig, I. D., Formal Models of Advanced AI Architectures, Ellis Horwood, Chich-
ester, England, 1991.
11. Deitel, H. M., Operating Systems, 2nd ed., Addison-Wesley, Reading, MA, 1990.
12. Duke, Roger and Rose, Gordon, Formal Object-Oriented Speciﬁcations using
Object-Z, Macmillan, Basingstoke, England, 2000.
13. Elphinstone, Kevin, Future Directions in the Evolution of the L4 Microkernel,
in [23], 2004.
14. Fowler, S., Formal Analysis of a Real-Time Kernel Speciﬁcation, Real-Time
Systems Research Group, Dept. of Computer Science, University of York, York,
UK, February, 1996.
15. Hayes, I., ed., Speciﬁcation Case Studies, Prentice-Hall, Hemel Hempstead, Eng-
land, 1987.

320
References
16. Hoare, C.A.R., Communicating Sequential Processes, Prentice-Hall, Hemel
Hempstead, England, 1985.
17. Iliﬀe, J. K., Basic Machine Principles, 2nd ed., MacDonald/American Elsevier
Computer Monographs, London, 1972.
18. Labrosse, Jean J., MicroC/OS-II, The Real-Time Kernel, Miller Freeman Inc.,
Lawrence, KS, 1999.
19. McKeag, R. M., T. H. E. Multiprogramming System, in [20], pp. 145–184.
20. McKeag, R. M. and Wilson, R., Studies in Operating Systems, Academic Press,
New York, 1976.
21. Milner, R., Communication and Concurrency, Prentice-Hall, Hemel Hempstead,
England, 1989.
22. Milner, R., Communicating and Mobile Systems: The π-calculus, Cambridge
University Press, Cambridge, England, 1999.
23. NICTA OS Veriﬁcation Workshop, 2004, NICTA, Canberra, Australia, 2004.
24. Pike,
Rob,
Systems
Software
Research
Is
Irrelevant,
2000.
(http:
//herpolhode.com/rob/utah2000.pdf.)
25. Rubini, A., Linux Device Drivers, O’Reilly and Associates, Sebastopol, CA,
1998.
26. Silberschatz, A., Galvin, P. and Gagne, G., Applied Operating System Concepts,
John Wiley, New York, 2000.
27. Smith, Graeme, The Object-Z Speciﬁcation Language, Kluwer Academic Publi-
cations, Boston, MA, 2000.
28. Spivey, J. M., The Z Notation: A Reference Manual, 2nd ed., Prentice-Hall,
Hemel Hempstead, England, 1992.
29. Tannenbaum, A., Modern Operating Systems, Prentice-Hall, Englewood Cliﬀs,
NJ, 1992.
30. Tannenbaum, A., Operating Systems: Design and Implementation, Prentice-
Hall, Englewood Cliﬀs, NJ, 1987.
31. Tuch, Harvey and Klein, Gerwin, Verifying the L4 Virtual Memory System, in
[23], 2004.
32. Walker, B. J., Kemmerer R. A. and Popek, L., Speciﬁcation and Veriﬁcation of
the UCLA Unix Security Kernel, Communications of the ACM, Vol. 23, No. 2,
pp. 118–131, 1980.
33. Walker, D. and Sangiorgi, D., The pi-calculus, Cambridge University Press,
Cambridge, England, 2001.
34. Wilson, R., The TITAN Supervisor, in [20], pp. 185–263.
35. Wirth N. and Gutknecht, J., Project Oberon, Addison-Wesley, Reading, MA,
1989.
36. Wirth N. and Gutknecht, J., The Oberon System, Software Practice and Expe-
rience, Vol. 19, No. 9, 1989.
37. Zhou, D. and Black, Paul E., Formal Speciﬁcation of Operating Systems Oper-
ation, Proc. IEEE TC-ECBS Working Group WG10.1, pp. 69–73, IEEE, Wash-
ington, DC, 2001.

List of Deﬁnitions
Type:
ADDRESS 144
APREF 57, 104
BIT 269
CLOCKMSG 225
DECODEDADDRESS 242
FMSG 272
GENREG 29, 90
GENREGSET 30
INTERRUPTSTATUS 31
IPREF 57, 104
IREALPROCS 40
LOGICALPAGENO 242
MBOXMSG 81
MEM 145
MEMDESC 144
MSG 205
MSGDATA 81
MSGSRC 81, 205
N256 269
PAGE 243
PAGEFRAME 243
PAGEMAP 243
PAGEOFFSET 242
PAGESPEC 289
PCODE 41, 58, 106
PDATA 41, 58, 106
PGMSG 272
PHYSICALPAGENO 242
PREF 40, 56, 57, 103
PRIO 58
PROCESSKIND 41, 105
PROCSTATUS 41, 57, 105, 207
PSTACK 58, 90, 106
PSU 145
REALPROCS 40
SCHDLVL 126
SDECODEDADDRESS 242
SDRPYMSG 228
SEGMENT 244
SEMAID 83
STATUSWD 30
SWAPRQMSG 159, 228
SYSCALLMSG 234
SYSRPY 234
TIME 90
TIMERRQ 33
TIMEVAL 32
VADDR 303
VIRTUALADDRESS 240
Constant:
0PSU 30
clockintno 32
DEVICEID 40
devprocqueue 127
IdleProcRef 40, 56, 57, 103, 104
illegalswapstatus 172
maxgreg 90
maxprocs 40, 57, 104
maxvirtpagespersegment 242

322
List of Deﬁnitions
memlim 144
NullPage 243
NullProcRef 40, 56, 57, 103, 104
numregs 29
NullStack 90
NullVal 145
pageofzeroes 289
sysprocqueue 127
ticklength 33, 173, 225
time quantum 36
usedsegment 244
userqueue 127
Function:
addresstrans 242
after 146, 270
codeToPSUs 152
dlogicalpage 242
dpageoﬀset 242
hole size 146
lower addr 146
mark page 244
memend 145
memsegoverlap 145
memsegsymoverlap 145
memsize 145
memstart 145
mergmemholes 146
mkpgspec 289
mkpstack 192
mkrmemspec 144
mpdata 192
msgdata 82
msgsender 82
nextblock 145
pages in segment 244
pgspeclpno 289
pgspecpref 289
psgspecseg 289
queuelevel 127
room in hole 147
room left in hole 147
saddresstrans 242
saddrseg 243
spageno 243
spagoﬀset 243
timerrq pid 33
timerrq time 33
unmark page 244
upper hole addr 146
Relation:
<P 71
=P 71
>P 71
≥P 71
≤P 71
smap 289
Class:
AlarmRQBuﬀer 182
CLOCKISR 177, 225
CURRENTPROCESS 78
ClockDriver 183, 225
Context 69, 127, 210
DeZombiﬁer 178
GenericISR 174
GenericMsgISR 213
GENREGSET 90
GlobalVariables 213
HardwareRegisters 59, 91
KernIntf 236
Lock 61, 97
LowLevelScheduler 130
Mailbox 82
MsgMgr 217
PageFaultDriver 273
PageFaultISR 272
PageFrames 269
PageMapping 305
PageTables 246
PagingDiskProcess 263
ProcessCreation 191
ProcessDescr 64, 58, 95, 106, 206
ProcessStorageDescrs 164
ProcessTable 68, 113, 209
PROCPRIOQUEUE 71
QUEUE[X ] 93
REALMAINSTORE 147
ReceiveISR 221

List of Deﬁnitions
323
SVCISR 180
SWAPDISKDriverProcess 161, 228
Semaphore 62, 98
SemaphoreTable 83
SendISR 220
SharedMainStore 158
SwapRQBuﬀer 159
SwapperProcess 186, 230
SysCallLib 234
TimeNow 178
UserLibrary 84
UserMessages 223
UserStoreMgr 306
UsersVStore 304
VStoreManager 290
Operation:
AlarmRQBuﬀer:
AddAlarm 182
CallAlarms 182
CancelAlarm 182
HaveAlarms 182
INIT 182
ClockDriver:
INIT 183, 225
RunProcess 227
genNextTick 226
putDriverToSleep 184
updateSwapperTimes 184, 226
CLOCKISR:
INIT 177, 225
ServiceISR 177, 225
Context:
INIT 69, 127, 210
RestoreState 69, 128, 212
SaveState 69, 128, 211
SwapIn 69, 129, 212
SwapOut 69,129, 212
SwitchContext 129, 212
CURRENTPROCESS:
ContinueCurrent 79
CurrentProcess 79
INIT 78
MakeCurrent 79
MakeReady 79
MakeUnready 79
RunNextProcess 80
SCHEDULENEXT 80
SuspendCurrent 80
isCurrentProc 80
reloadCurrent 79
selectIdleProcess 80
DeZombiﬁer:
INIT 178
RunProcess 178
GenericISR:
INIT 174
OnInterrupt 176
WakeDriver 174
restoreState 176
saveState 175
GenericMsgISR:
INIT 213
SendInterruptMsg 215
restoreState 214
saveState 214
shouldRunDriver 214
GENREGSET:
INIT 90
GlobalVariables:
INIT 213
missed ticks 213
HardwareRegisters:
GetGPRegs 59, 92
GetIP 59, 92
GetStackReg 59, 92
GetStatWd 59, 92
INIT 91
SetGPRegs 59, 91
SetIP 59, 92

324
List of Deﬁnitions
SetIntsOﬀ59, 93
SetIntsOn 59
SetStackReg 59, 92
SetStatWd 59
KernIntf :
INIT 236
RunProcess 236
Lock:
INIT 97
Lock 61, 97
Unlock 61, 97
LowLevelScheduler:
allEmptyQueues 137
ContinueCurrent 137
CurrentProcess 132
GetTimeQuantum 131
INIT 130
MakeReady 132
MakeUnready 135
reloadCurrent 137
RunIdleProcess 132
runTooLong 134
ScheduleNext 138
selectNext 137
SetTimeQuantum 132
UpdateProcessQuantum 133
Mailbox:
HaveMessages 82
INIT 82
NextMessage 82
PostMessage 82
MsgMgr:
canReady 219
copyMessageToDest 219
enqueueSender 218
haveMsgsWithAppropriateSrc 219
INIT 217
isWaitingForSender 218
IsWaitingToReceive 218
RcvMessage 219
SendMessage 218
PageFaultDriver:
DoOnPageFault 278
INIT 273
ﬁndVictimLogicalPage 274
ﬁndVictimPage 275
genOnPageFault 278
haveVictim 274
onPageFault 278
retrievePageFromDisk 276
storePageOnDisk 276
swapPageToDisk 275
PageFaultISR:
INIT 272
OnPageInterrupt 272
PageFrames:
ClearRefBitsAndCounter 271
ComputeHitCounts 271
GetPage 270
INIT 269
IsVictim 271
OverwritePhysicalPage 270
VictimPhysicalPageNo 271
PageMapping:
INIT 305
MapPageFromDiskExtendingStore
306
MapPageToDisk 305
readPageFromDisk 305
writePageToDisk 305
PageTables:
AddPageToProcess 251
AllocateFreePage 248
DecProcessPageCount 252
HasPageInStore 252
HaveFreePages 248
INIT 246
IncProcessPageCount 252
InitNewProcessPageTable 250
InvPageTables 259

List of Deﬁnitions
325
IsLockedPage 257
IsPageExecutable 258
IsPageInMainStore 253
IsPageReadable 257
IsPageWritable 258
IsSharedPage 256
LatestPageCount 252
LockPage 257
MakePageExecutable 258
MakePageFree 249
MakePageNotExecutable 258
MakePageNotReadable 257
MakePageNotWritable 258
MakePageReadable 257
MakePageWritable 258
MarkPageAsIn 254
MarkPageAsOut 255
MarkPageAsShared 256
NumberOfFreePages 248
PhysicalPageNo 250
RemovePageFromPageTable 253
RemovePageFromProcess 253
RemovePageProperties 253
RemoveProcessFromPageTable 250
UnlockPage 257
UnsharePage 256
UpdateMainStorePage 252
PagingDiskProcess
INIT 263
OnPageRequest 266
PageIsOnDisk 265
RemoveProcessFromPagingDisk 266
RetrievePageFromDisk 265
StorePageOnDisk 265
ProcessCreation:
createASystemProcess 194
createAUserProcess 193
createNewPDescr 193
CreateChildUserProcess 195
CreateDriverProcess 196
CreateSystemProcess 196
CreateUrProcess 195
CreateUserProcess 195
deleteProcessFromDisk 196
deleteSKProcess 197
freeProcessStore 197
INIT 191
releaseProcessStorage 197
TerminateProcess 197
writeImageToDisk 194
ProcessDescr:
AddBlockedProcess 110
AddBlockedProcesses 110
AddWaitingSenders 209
BlocksProcesses 110
ClearBlockedProcesses 110
FullContext 67, 111
INIT 65, 106, 206
InMsg 208
NextMsgSrc 208
OutMsg 208
Priority 65
ProcessKind 109
ProcessStatus 66, 108
RemoveBlockedProcess 110
SchedulingLevel 110
SetFullContext 67, 112
SetInMsg 207
SetNextMsgSrc 208
SetOutMsg 208
SetPriority 66
SetProcessKindToDevProc 109
SetProcessKindToSysProc 109
SetProcessKindToUserProc 110
SetProcessStatusToNew 66, 108
SetProcessStatusToReady 66, 109
SetProcessStatusToRunning 66, 109
SetProcessStatusToSwappedOut 109
SetProcessStatusToTerminated
66,
108
SetProcessStatusToWaiting 66, 109
SetProcessStatusToZombie 109
SetStoreDescr 67, 111
SetTimeQuantum 111
StoreDescr 67, 111
StoreSize 67, 111
TimeQuantum 111

326
List of Deﬁnitions
WaitingSenders 209
ProcessQueue:
Catenate 96
Enqueue 58, 95
INIT 58, 95
IsEmpty 58, 95
QueueFront 58, 96
RemoveElement 58, 96
RemoveFirst 58, 96
RemoveNext 96
ProcessStorageDescrs:
AddProcessStoreInfo 167
BlockProcessChildren 169
ClearProcessResidencyTime 166
ClearSwappedOutTime 167
CodeOwnerSwappedIn 171
FindSwapoutCandidate 173
HaveSwapoutCandidate 172
INIT 164
IsSwappedOut 167
MakeInStoreProcessSwappable 165
MakeProcessOnDiskSwappable 166
MarkAsInStore 166
MarkAsSwappedOut 166
NextProcessToSwapIn 172
ProcessStoreSize 168
ReadyProcessChildren 169
RemoveProcessStoreInfo 168
SetProcessStartResidencyTime 167
SetProcessStartSwappedOutTime 167
UpdateAllStorageTimes 166
UpdateProcessStoreInfo 168
ProcessTable:
AddChildOfProcess 119
AddCodeOwner 118
AddCodeSharer 118
AddDriverMessage 210
AddProcess 68, 117
AddProcessToTable 117
AddProcessToZombies 119
AllDescendants 119
CanGenPId 116
CreateIdleProcess 68, 115
DelChildOfProcess 119
DelCodeOwner 118
DelCodeSharer 118
deleteProcessFromTable 117
DelProcess 68, 117
DescrOfProcess 68, 117
GotZombies 120
INIT 69, 113, 209
IsCodeOwner 119
IsKnownProcess 116
KillAllZombies 120
MakeZombieProcess 120
MessageForDriver 210
NewPId 116
ParentOfProcess 121
ProcessHasChildren 119
ProcessHasParent 121
ProcessIsZombie 120
releasePId 116
RemoveAllZombies 120
RemoveProcessFromParent 121
PROCPRIOQUEUE:
EnqueuePROCPRIOQUEUE 72
INIT 71
IsEmptyPROCPRIOQUEUE 74
NextFromPROCPRIOQUEUE 74
RemovePrioQueueElem 75
reorderProcPrioQueue 75
QUEUE[X ]:
Enqueue 94
INIT 93
IsEmpty 94
QueueFront 94
RemoveElement 94
RemoveNext 94
REALMAINSTORE:
CreateProcessImage 153
FreeMainstoreBlock 150
INIT 147
MergeAdjacentHoles 150
RSAllocateFromHole 149

List of Deﬁnitions
327
RSAllocateFromUsed 151
RSCanAllocateInStore 149
RSCopyMainStoreSegment 152
RSWriteMainStoreSegment 152
ReceiveISR:
INIT 221
ServiceInterrupt 221
Semaphore:
DecSemaCount 62, 98
INIT 62, 98
IncSemaCount 62, 98
NegativeSemaCount 62, 98
NonPositiveSemaCount 62,98
Signal 62, 101
Wait 62, 98
SemaphoreTable:
DelSemaphore 83
GetSemaphore 83
INIT 83
NewSemaphore 83
SendISR:
INIT 220
ServiceInterrupt 220
SharedMainStore:
AllocateFromHole 158
AllocateFromUsed 158
CanAllocateInStore 158
CopyMainStore 158
FreeMainStore 158
INIT 158
WriteMainStore 158
SVCISR:
HandleSVC 181
SWAPDISKDriverProcess:
INIT 161
INIT 228
RunProcess 163
SwapDriver 229
deleteProcessFromDisk 162
handleRequest 163, 229
readProcessStoreFromDisk 162
writeProcessStoreToDisk 162
SwapRQBuﬀer:
INIT 159
Read 160
Write 160
SwapperProcess:
INIT 186, 230
RunProcess 190
SwapperProcess 231
doDiskSwap 190
requestReadinSegment 188, 231
requestWriteoutSegment 187, 230
swapCandidateOut 188
swapProcessIn 189
swapProcessIntoStore 189
swapProcessOut 188
waitForNextSwap 190
SysCallLib:
INIT 234
TerminateProcess 236
UserCreateChildProcess 235
UserCreateProcess 235
TimeNow:
CurrentTime 178
Init 178
SetTime 178
UserLibrary:
CreateProcess 84
INIT 84
Suspend 84
TerminateProcess 84
UserMessages:
INIT 223
Receive 223
Send 223
UserStoreMgr:

328
List of Deﬁnitions
AllocateCloneProcessStorage 308
AllocateNewProcessStorage 307
FinalizeProcessPages 308
INIT 306
ReleaseSharedPages 308
UsersVStore:
CopyVStoreBlock 304
CopyVStoreFromVStore 304
INIT 304
VStoreManager:
AddNewMainStorePageToProcess
291, 292
AddNewPageToProcess 292
AddNewVirtualPageToProcess 291
CanAddPageToSegment 292
CanReleaseProcessVStore 299
CanReleaseSegment 299
INIT 290
IsSharedLogicalPage 294
makeEmptyPage 291
MarkLogicalPageAsShared 293
MarkSharedLogicalPageAsIn 296
MarkSharedLogicalPageAsOut 297
NextNewLogicalPageNo 297
RawShareLogicalPageBetweenProcesses
295
ReleaseSegmentPagesExcept 298
ReleaseSharedSegment 298
RemoveLogicalPageSharers 294
RemoveSharedLogicalPage 294
ReturnSharedLogicalPageToOwner
296
ShareLogicalPageBetweenProcesses
295
ShareLogicalSegment 297
SharedLogicalPageSharers 293
SharedPagesInSegment 299
UnshareLogicalPage 293
WithdrawLogicalPage 293
Schema:
AddProcess 44
AddTBLEntry[K, D] 18
AllocateNExecutablePages 302
AllocateNPages 301
AllocateNReadOnlyPages 302
AllocateNReadWritePages 302
AllocatePageReturningStartVAddress
300
CLOCK 32
CURRENTPROCESS 52
CanAllocateProcess 47
CannotAllocateProcess 48
ComputePageVAddress 300
ContinueCurrent 53
CopyVStoreBlock 303
CurrentProcessQuantum 38
CurrentProcessQuantumHasExpired
38
DelProcess 44
DelTBLEntry[K, D] 19
DequeueProc 54
Dequeue[X ] 24
Dequeuea[X ] 24
DisableInterrupts 31
EmptyQError 23
EmptyQUEUE[X ] 22
EmptyTIMERRQQUEUE 34
EnableInterrupts 31
EnqueueTIMERRQ 34
GENTBL[K, D] 17
GenSemaId 83
GetTBLEntry[K, D] 19
HWREGISTERS 30
INTERRUPTFLAG 31
InitCLOCK 32
InitCURRENTPROCESS 53
InitGENTBL[K, D] 18
InitHWREGISTERS 30
InitINTERRUPTFLAG 31
InitPROCESSES 44
InitQUEUE[X ] 21
InitTIMERRQQUEUE 34
InitialiseProcessStatus 46
KindOfProcess 46
KnownProcess 47
LengthOfQUEUE[X ] 22
Lock 32

List of Deﬁnitions
329
MakeCurrent 52
MakeNextIdle 54
MakeReady 53
MarkPageAsCode 301
MarkPageAsReadOnly 301
MarkPageAsReadWrite 301
NextPREF 48
NoProcessesInSystem 49
OnTimerInterrupt 36
OverwriteTBLEntry[K, D] 20
PROCESSES 42
ProcessPriority 45
ProcessQuantum 37
ProcessesFullyAllocated 48
QOk 23
QUEUE[X ] 21
QueueEltIndex[X ] 23
RaiseInterrupt 220
RemoveFirstTIMERRQ 34
RemoveFirst[X ] 22
RemoveQueueElt[X ] 23
RemoveTIMERRQQueueElt 34
ResetProcessTimeQuantum 37
RestoreAllHWRegisters 51
RestoreHWGeneralRegisters 52
RestorePartialContext 52
SaveAllHWRegisters 51
SaveCurrentProcessQuantum 38
SaveHWGeneralRegisters 52
SavePartialContext 52
SCHEDULENEXT 54
SetCurrentProcessQuantum 37
SetInitialProcessQuantum 37
SetNewCurrentProcessQuantum 39
SetProcessStatusToNew 46
SetProcessStatusToReady 46
SetProcessStatusToRunning 47
SetProcessStatusToTerminated 47
SetProcessStatusToWaiting 47
SetProcessStatusToZombie 47
StatusOfProcess 46
SuspendCurrent 54
SuspendOnExhaustedQuantum 39
SwitchContextIn 52
SwitchContextOut 51
TBLContainsKey[K, D] 18
TIMER 35
TIMERInit 35
TIMERRQQUEUE 34
TimeNow 33
TimerRequestsNowActive 35
Unlock 32
UpdateCLOCKOnTick 33
UpdateCurrentProcessQuantum 38
UpdateCurrentQuantumOnTimerClick
38
UpdateProcessQuantum 37
UpdateProcessStatus 46
VirtualStore 303
WaitForTimerInterrupt 36
ΦCURRENTPROCESSq 53
ΨCURRENTPROCESSq 53

Index
Address
translation, 242
virtual, 240, 303
virtual using, 300
Address Space
large, 317
Clock, 32, 56, 88, 173, 203, 204
alarm, 204
message-based, 225
system, 8
tick, 36, 212
Code
owner, 118
shared, 118
sharer, 118
Context switch, 10, 11, 51, 69, 175, 204
Demand paging, 267
Device, 9, 56
real, 309
virtual, 309
Device driver, 8, 56, 106, 127, 214, 273
message-based, 224
Disk
swap, 158
Event, 8, 316
I/O, 231
Inter-Process Communication, 7
Interface
kernel, 231
Interrupt, 11, 31, 175, 267
clock, 212
disable, 31
driven, 204
enable, 31
page fault, 240, 267
Interrupt Service Routine, 6
IPC, 7, 56, 81, 88, 203, 240, 314
ISR, 6, 10, 11, 56, 87, 203, 204, 240
Generic message-passing, 213
Kernel
L4, 1
locked pages, 300
mode switch, 300
UCLA Security, 1
virtual pages, 300
Linux, 2, 5, 8, 204, 316
Lock, 97, 212
Lock operation, 32
LRU, 267
Mach, 9, 233
Mailbox, 56, 81
Memory
shared, 7
Memory Management Unit, 243
Message, 81, 204
asynchronous, 7, 56
synchronous, 7, 203
Message passing, 203, 240, 310
and virtual store, 310
MINIX, 43, 204, 314
MMU, 243

332
Index
Monitors, 8
Multi-Core CPU, 316
Multi-Processor System, 316
multiprogramming, 2
Page, 239
addition, 251
allocation, 301
attribute, 243
setting, 301
counter, 252
disk mapping, 305
executable, 245
fault, 240, 267
driver process, 273
handling, 273
frames, 269
free, 248
hit count, 269
least recently used, 267
locked, 11, 245, 257
logical page number, 242, 297
mainstore attribute, 253
map, 243
mapping, 240
marking, 244
null, 243
page fault driver, 240
page number
logical, 242
physical, 242
paging disk, 263
placement, 267
readable, 245
real, 240
reference count, 269
shared, 239, 245, 256, 289
attributes, 296
sharing, 294
swapping, 254
optimisation, 280
swapping in, 276
swapping out, 275
table, 11, 244, 245
allocation, 250
deallocation, 250
organisation, 246
unmarking, 244
unsharing, 296
writable, 245
Paging
demand, 239
Paging disk, 263
Paging process, 263
POSIX, 5
Priority, 77, 88, 106
scheme, 126
static assignment, 84
Process, 39, 87
allocation, 306
child, 112, 118, 197, 232, 309
clock, 88, 173
clone, 309
cloning, 309
context, 69, 106, 111, 127
creation, 84, 191, 232, 311
child process, 235
fork-join model, 232
user process, 235
current, 8, 52, 77, 176, 211
deallocation, 306
descriptor, 39, 51, 67, 106
destruction, 84
device, 106, 127
idle, 40, 68, 103, 127
reference, 42, 56, 103
management, 103
null, 40, 68, 103
reference, 42, 56, 103
page allocation, 301
parent, 118
priority, 106
reference, 21, 103
APREF, 57, 104
IPREF, 57, 104
PREF, 56, 103
sleep, 8
state, 9, 57, 105
storage
extension, 288
storage area
base address, 111
storage descriptor, 111
swap, 51, 118, 158, 204, 228
in virtual store, 311
swapper, 163
swapping, 314
system, 88, 106, 127

Index
333
table, 39, 67
termination, 191, 232, 311
user, 106, 127
zombie, 112, 118, 119, 197
PSU, 145
Queue, 93
FIFO, 21, 103
Priority, 77
priority, 71
multi-level, 88, 130
process, 58, 94, 127
ready, 6, 52
RC4000, 5
Reference counting, 239
Register, 9, 11, 29
general-purpose, 29
instruction pointer, 29, 51
program counter, 29
stack, 29
status, 29, 92
Registers
general, 90
RSTS, 5
RSX11/M, 5
Scheduler, 6, 77, 88, 126, 204, 212
fair policy, 99
policy
round robin, 99, 103
Security, 316
Segment, 239, 244, 297
code, 118
shared, 239, 297
unshared, 297
Semaphore, 7, 51, 56, 61, 81, 97, 203,
314
counter, 62
P operation, 8, 61, 98
properties proved, 99
queue, 61
Signal, 8
Signal operation, 61, 101
V operation, 8, 61, 101
Wait operation, 61, 98
Signal, 8
asynchronous, 315
Solaris, 2
Solo, 8
Storage
allocation, 232
deallocation, 232
descriptor, 144
descriptors, 9
management, 8, 88, 144, 204
segment, 239
unit
primary, 145
Storage manager, 9
Store
real, 240
virtual, 10, 11, 239
System call, 6
message, 234
response message, 234
THE, 5, 6, 8
Time, 90
quantum, 36, 131
Time slicing, 90
Timer, 32
TITAN, 5
TLB, 243
TOPS10, 5
TOPS20, 5
Translation lookaside buﬀer, 243
Unix, 5, 232, 316
System V, 8
Unlock, 97
Unlock operation, 32
Virtual storage, 239, 313
segment, 239
Virtual store, 314
and message passing, 310
block copy, 303
copy, 304
extending, 288
VMS, 5
Windows NT, 2, 5, 8, 232

