
Information Security
Management Handbook
Sixth Edition
VOLUME 2

AUERBACH PUBLICATIONS
www.auerbach-publications.com
To Order Call: 1-800-272-7737    Fax: 1-800-374-3401
E-mail: orders@crcpress.com
802.1X Port-Based Authentication
Edwin Lyle Brown
ISBN: 1-4200-4464-8
Approach to Security in the Organization,
Second Edition
Jan Killmeyer
ISBN: 0-8493-1549-2
Audit and Trace Log Management:
Consolidation and Analysis
Phillip Q. Maier
ISBN: 0-8493-2725-3
The CISO Handbook: A Practical Guide to
Securing Your Company
Michael Gentile, Ron Collette and Tom August
ISBN: 0-8493-7943-1
CISO Leadership: Essential Principles for Success
Todd Fitzgerald adn Micki Krause
ISBN: 0-8493-1952-8
Complete Guide to CISM Certification
Thomas R. Peltier and Justin Peltier
ISBN: 0-849-35356-4
Complete Guide to Security and Privacy
Metrics: Measuring Regulatory Compliance,
Operational Resilience, and ROI
Debra S. Herrmann
ISBN: 0-8493-5402-1
Computer Forensics: Evidence Collection
and Management
Robert C. Newman
ISBN: 0-8493-0561-6
Cyber Crime Investigator s Field Guide,
Second Edition
Bruce Middleton
ISBN: 0-8493-2768-7
Cyber Forensics: A Field Manual for Collecting,
Examining, and Preserving Evidence of Computer
Crimes, Second Edtion
Albert J. Marcella, Jr. and Doug Menendez
ISBN: 0-8493-8328-5
Database and Applications Security: Integrating
Information Security and Data Management
Bhavani Thuraisingham
ISBN: 0-8493-2224-3
Digital Privacy: Theory, Technologies, and Practices
Alessandro Acquisti, Stefanos Grizallis,
Costos Lambrinoudakis, Sabrina di Vimercati
ISBN: 1-4200-5217-9
How to Achieve 27001 Certification: An Example
of Applied Compliance Management
Sigurjon Thor Armason and Keith D. Willett
ISBN: 0-8493-3648-1
Information Security: Design, Implementation,
Measurement, and Compliance
Timothy P. Layton
ISBN: 0-8493-7087-6
Information Security Architecture: An Integrated
Information Security Cost Management
Ioana V. Bazavan and Ian Lim
ISBN: 0-8493-9275-6
Information Security Fundamentals
Thomas R. Peltier, Justin Peltier and John A. Blackley
ISBN: 0-8493-1957-9
Information Security Management Handbook,
Sixth Edition
Harold F. Tipton and Micki Krause
ISBN: 0-8493-7495-2
Information Security Risk Analysis,
Second Edition
Thomas R. Peltier
ISBN: 0-8493-3346-6
Insider Computer Fraud: An In-Depth Framework
for Detecting and Defending against Insider IT
Attacks
Kenneth Brancik
ISBN: 1-4200-4659-4
Investigations in the Workplace
Eugene F. Ferraro
ISBN: 0-8493-1648-0
Managing an Information Security and Privacy
Awareness and Training Program
Rebecca Herold
ISBN: 0-8493-2963-9
A Practical Guide to Security Assessments
Sudhanshu Kairab
ISBN: 0-8493-1706-1
Practical Hacking Techniques and
Countermeasures
Mark D. Spivey
ISBN: 0-8493-7057-4
Securing Converged IP Networks
Tyson Macaulay
ISBN: 0-8493-7580-0
The Security Risk Assessment Handbook:
A Complete Guide for Performing Security
Risk Assessments
Douglas J. Landoll
ISBN: 0-8493-2998-1
Wireless Crime and Forensic Investigation
Gregory Kipper
ISBN: 0-8493-3188-9
OTHER INFORMATION SECURITY BOOKS FROM AUERBACH

Information Security
Management Handbook
Sixth Edition
Edited by
Harold F. Tipton, CISSP . Micki Krause, CISSP
Boca Raton   New York
Auerbach Publications is an imprint of the
Taylor & Francis Group, an informa business
VOLUME 2

Auerbach Publications
Taylor & Francis Group
6000 Broken Sound Parkway NW, Suite 300
Boca Raton, FL 33487-2742
© 2008 by Taylor & Francis Group, LLC 
Auerbach is an imprint of Taylor & Francis Group, an Informa business
No claim to original U.S. Government works
Printed in the United States of America on acid-free paper
10 9 8 7 6 5 4 3 2 1
International Standard Book Number-13: 978-1-4200-6708-8 (Hardcover)
This book contains information obtained from authentic and highly regarded sources. Reprinted material is quoted 
with permission, and sources are indicated. A wide variety of references are listed. Reasonable efforts have been made to 
publish reliable data and information, but the author and the publisher cannot assume responsibility for the validity of 
all materials or for the consequences of their use. 
Except as permitted under U.S. Copyright Law, no part of this book may be reprinted, reproduced, transmitted, or uti-
lized in any form by any electronic, mechanical, or other means, now known or hereafter invented, including photocopy-
ing, microfilming, and recording, or in any information storage or retrieval system, without written permission from the 
publishers.
For permission to photocopy or use material electronically from this work, please access www.copyright.com (http://
www.copyright.com/) or contact the Copyright Clearance Center, Inc. (CCC) 222 Rosewood Drive, Danvers, MA 01923, 
978-750-8400. CCC is a not-for-profit organization that provides licenses and registration for a variety of users. For orga-
nizations that have been granted a photocopy license by the CCC, a separate system of payment has been arranged.
Trademark Notice: Product or corporate names may be trademarks or registered trademarks, and are used only for 
identification and explanation without intent to infringe.
Library of Congress Cataloging-in-Publication Data
Tipton, Harold F.
Information security management handbook / Harold F. Tipton, Micki Krause. -- 6th ed.
p. cm. ((ISC) 2 Press ; 27)
Includes bibliographical references and index.
ISBN 1-4200-6708-7
1. Computer security--Management--Handbooks, manuals, etc. 2. Data protection--Handbooks, 
manuals, etc. I. Krause, Micki. II. Title.
QA76.9.A25154165 2006
005.8--dc22 
2006048504
Visit the Taylor & Francis Web site at
http://www.taylorandfrancis.com
and the Auerbach Web site at
http://www.auerbach-publications.com

v
Contents
Preface ..................................................................................................................................ix
Editors ..................................................................................................................................xi
Contributors ...................................................................................................................... xiii
DOMAIN 1: INFORMATION SECURITY AND RISK MANAGEMENT 
Security Management Concepts and Principles
 1 Integrated Th reat Management ....................................................................................3
GEORGE G. McBRIDE
 2 Understanding Information Security Management Systems .....................................15
TOM CARLSON
Policies, Standards, Procedures, and Guidelines
 3 Planning for a Privacy Breach ....................................................................................29
REBECCA HEROLD
Risk Management
 4 Using Quasi-Intelligence Resources to Protect the Enterprise ...................................47
CRAIG A. SCHILLER
 5 Information Risk Management: A Process Approach
to Risk Diagnosis and Treatment ...............................................................................71
NICK HALVORSON
 6 Department-Level Transformation ............................................................................83
R. SCOTT McCOY
 7 Setting Priorities in Your Security Program ..............................................................93
DEREK SCHATZ
 8 Why and How Assessment of Organization Culture Shapes
Security Strategies ....................................................................................................109
DON SARACCO
 9 A Look Ahead ...........................................................................................................135
SAMANTHA THOMAS

vi  Contents
DOMAIN 2: ACCESS CONTROL
Access Control Techniques
10 Authentication Tokens .............................................................................................145
PAUL A. HENRY
11 Authentication and the Role of Tokens ....................................................................153
JEFF DAVIS
Access Control Administration
12 Accountability ..........................................................................................................163
DEAN R. BUSHMILLER
Methods of Attack
13 Rootkits: Th e Ultimate Malware Th reat ..................................................................175
E. EUGENE SCHULTZ AND EDWARD RAY
DOMAIN 3: CRYPTOGRAPHY
14 Encryption Key Management in Large-Scale Network Deployments .....................191
FRANJO MAJSTOR AND GUY VANCOLLIE
DOMAIN 4: PHYSICAL SECURITY
Elements of Physical Security
15 Mantraps and Turnstiles ..........................................................................................201
R. SCOTT McCOY
DOMAIN 5: SECURITY ARCHITECTURE AND DESIGN
Principles of Computer and Network Organizations, Architectures, 
and Designs
16 Service-Oriented Architecture and Web Services Security ..................................... 209
GLENN J. CATER
17 Analysis of Covert Channels ....................................................................................229
RALPH SPENCER POORE
18 Security Architecture of Biological Cells: An Example of Defense in Depth...........237
KENNETH J. KNAPP AND R. FRANKLIN MORRIS, JR.
19 ISO Standards Draft Content ..................................................................................245
SCOTT ERKONEN
20 Security Frameworks ................................................................................................253
ROBERT M. SLADE

Contents  vii
DOMAIN 6: TELECOMMUNICATIONS AND NETWORK SECURITY
Communications and Network Security
21 Facsimile Security ....................................................................................................273
BEN ROTHKE
Internet, Intranet, and Extranet Security
22 Network Content Filtering and Leak Prevention .....................................................289
GEORGE J. JAHCHAN
Network Attacks and Countermeasures
23 Th e Ocean Is Full of Phish .......................................................................................295
TODD FITZGERALD
DOMAIN 7: APPLICATION SECURITY
Application Issues
24 Neural Networks and Information Assurance Uses ................................................ 307
SEAN M. PRICE
25 Information Technology Infrastructure Library
and Security Management Overview .......................................................................333
DAVID McPHEE
26 Adaptation: A Concept for Next-Generation Security 
Application Development .........................................................................................349
ROBBY S. FUSSELL
27 Quantum Computing: Implications for Security .....................................................361
ROBERT M. SLADE
DOMAIN 8:  LEGAL, REGULATIONS, COMPLIANCE,
AND INVESTIGATION
Information Law
28 Compliance Assurance: Taming the Beast ...............................................................377
TODD FITZGERALD
Incident Handling
29 Enterprise Incident Response and Digital Evidence 
Management and Handling .....................................................................................391
MARCUS K. ROGERS
30 Security Information Management Myths and Facts .............................................. 405
SASAN HAMIDI
Index .................................................................................................................................415


ix
Preface
Traditionally, the preface for this handbook focuses on the evolving landscape of the security 
profession, highlighting industry trends such as the burgeoning impact of privacy laws and regu-
lations, emerging technologies that challenge de facto security, or any of the other various and 
sundry topics du jour. Th is time, we shift the focus.
Information security is an interesting, many times frustrating discipline to institutionalize. 
Th e commonly accepted triad—people, process, technology—trips easily oﬀ  the tongue. How-
ever, breaking down the threesome into its subcomponents gives one pause. Information security 
truly is a complex composite of many ﬁ elds of study, including sociology, psychology, anthropol-
ogy, virology, criminology, cryptology, etiology, and technology.
Th us, we give tribute here to those who willingly choose to slay the dragons, oftentimes ﬁ nding 
themselves tilting at windmills instead.
Further, and importantly, we want to give tribute to, and underscore the contributions of, our 
authors.
We can only speculate on what compels an individual to take keyboard in hand in an eﬀ ort to 
share information and experiences that will beneﬁ t others. And yet, year after year, we have a select 
community of practitioners and professionals who give their all for the good of the industry.
Th is volume of the handbook is no exception. Th e topics featured encompass a broad spectrum 
of areas, ranging from the fundamentals of access control, malicious software, and network secu-
rity to more esoteric, but equally important, organizational culture and governance framework 
discussions. All of the chapters share a common property—they contain gems of information that 
aﬀ ord the readers a leg up in their individual eﬀ orts to instill adequate and appropriate levels of 
security within their organizations.
To our readers, Don Quixotes that you are, we wish you good luck and good reading.
And to our authors, we sincerely thank you for your valuable and valued contributions.
Hal Tipton
Micki Krause


xi
Editors
Harold F. Tipton, currently an independent consultant and past president of the (ISC)2, was 
director of computer security for Rockwell International Corporation for about 15 years. He initi-
ated the Rockwell computer and data security program in 1977 and then continued to administer, 
develop, enhance, and expand the program to accommodate the control needs produced by tech-
nological advances until his retirement from Rockwell in 1994.
He has been a member of the ISSA since 1982, was president of the Los Angeles chapter in 
1984, and was president of the national organization of ISSA (1987–1989). He was added to the 
ISSA Hall of Fame and the ISSA Honor Role in 2000.
He was a member of the National Institute for Standards and Technology, Computer and 
Telecommunications Security Council, and National Research Council Secure Systems Study 
Committee (for the National Academy of Science).
He has a B.S. in engineering from the U.S. Naval Academy, an M.A. in personnel admin-
istration from George Washington University, and a certiﬁ cate in computer science from the 
University of California at Irvine. He is a CISSP®, an Information System Security Architecture 
Professional (ISSAP® ), and an Information System Security Management Professional.
He has published several papers on information security issues with Auerbach Publishers 
(Handbook of Information Security Management, Data Security Management, and Information Secu-
rity Journal ); National Academy of Sciences (Computers at Risk); Data Pro Reports; Elsevier; and 
ISSA Access magazine.
He has been a speaker at all the major information security conferences, including Computer 
Security Institute, the ISSA Annual Working Conference, the Computer Security Workshop, MIS 
conferences, AIS Security for Space Operations, DOE Computer Security Conference, National 
Computer Security Conference, IIA Security Conference, EDPAA, UCCEL Security & Audit 
Users Conference, and Industrial Security Awareness Conference.
He has conducted/participated in information security seminars for (ISC)2, Frost & Sullivan, 
UCI, CSULB, System Exchange seminars, and the Institute for International Research. He partici-
pated in the Ernst & Young video “Protecting Information Assets.” He is currently serving as editor 
of the Auerbach Handbook of Information Security publications. He received the Computer Security 
Institute Lifetime Achievement Award in 1994 and the (ISC)2 Hal Tipton Award in 2001.
Micki Krause, M.B.A., CISSP, has held positions in the information security profession for the 
past 20 years. She is currently the chief information security oﬃ  cer at Paciﬁ c Life Insurance 
 Company in Newport Beach, California, where she is accountable for directing the information 
protection and security program for the enterprise. Paciﬁ c Life is the 15th largest life insurance 

xii  Editors
company in the nation and provides life and health insurance products, individual annuities, 
mutual funds, group employee beneﬁ ts, and a variety of investment products and services.
Krause was named one of the 25 most inﬂ uential women in the ﬁ eld of information security by 
industry peers and Information Security magazine as part of their recognition of Women of Vision 
in the information technology (IT) security ﬁ eld and received the Harold F. Tipton Award in 
recognition of sustained career excellence and outstanding contributions to the profession.
Micki has held several leadership roles in industry-inﬂ uential groups including the Information 
Systems Security Information (ISSA) and the International Information Systems Security Certiﬁ -
cation Consortium (ISC)2® and is a passionate advocate for professional security leadership.
She is a reputed speaker, published author, and coeditor of the Information Security Manage-
ment Handbook series.

xiii
Contributors
Dean R. Bushmiller has had fun for the past 20 years learning and teaching everything he can 
in technology and security. His consulting experience in accounting systems, inventory control, 
migrations, and patch management has breathed life into his 12 years in the classroom. Dean is a 
courseware developer who specializes in CISSP and patch management. He is a member of (ISC)2, 
the Information Systems Audit and Control Association (ISACA), and the Center for Internet 
Security. He is proud to be a recipient of both the DISA/FSO and the Air Force 92IOS mission 
coins. Very little of this would have been possible without Helaine— a partner, friend, and wife.
Tom Carlson is a certiﬁ ed ISO 27001 auditor and a recognized expert on information security stan-
dards and programs. His background spans diverse environments, including national security, aca-
demia, private enterprise, and Antarctic research, encompassing design, development, deployment, 
operations, and knowledge transfer. Th roughout his career, Tom has worked with multiple govern-
ment agencies on a variety of mission critical projects, as well as security solutions for the private sec-
tor. His area of expertise is in information security management systems and risk management. Tom 
holds a BS in electrical engineering as well as various education and industry certiﬁ cations.
Glenn J. Cater has over 14 years experience in IT covering information security, software devel-
opment, and IT management. Glenn currently holds the position of director of IT risk consulting 
at Aon Consulting. In this role, Glenn supports Aon’s electronic discovery services, high-tech 
investigations, and IT security consulting practices. Glenn joined Aon from Lucent Technologies, 
where he held management positions in Lucent’s internal IT security team and Lucent Worldwide 
Services consulting group. Before joining Lucent, Glenn had begun his career as a software engi-
neer at British Aerospace working on military systems.
Jeﬀ  Davis, CISSP, CISM, has been working in the information security area for the past
15 years. He is currently a senior manager for IT global security operations at Alcatel–Lucent. He 
is responsible for IT security architecture as well as operations of network intrusion detection and 
prevention, security compliance, and threat evaluation. He also consults on risk assessment and 
security governance and has worked with Bell Labs on evaluating and implementing new security 
initiatives. He holds a bachelor’s degree in electrical engineering and a master’s degree in computer 
science from Stevens Institute of Technology.
Scott Erkonen is principal and director of client relationships for Hot Skills, Inc. He is the U.S. 
International Representative to ISO JTC1/SC27 INCITS CS/1 Cyber Security. He successfully led 
one of the ﬁ rst ISO 27001 certiﬁ cations in the U.S.

xiv  Contributors
Todd Fitzgerald, CISSP, CISA, CISM, serves as a Medicare systems security oﬃ  cer for National 
Government Services, LLC (NGS), Milwaukee, Wisconsin, which is the nation’s largest processor 
of Medicare claims and a subsidiary of WellPoint, Inc., the nation’s largest health insurer.
Todd was named as a ﬁ nalist for the 2005 Midwest Information Security Executive (ISE) of the 
Year Award, nominee for the national award, and judge for the 2006 central region awards and has 
moderated several ISE Executive Roundtables in 2006. Todd is the co-author of CISO Leadership: 
Essential Principles for Success, and has authored articles on information security for Th e 2007  Oﬃ  cial 
(ISC)2 Guide to the CISSP Exam, Information Security Magazine, Th e Information Security Hand-
book, Th e HIPAA Program Reference Book, Managing an Information Security and Privacy Awareness 
and Training Program, and several other security-related publications. Todd is also a member of the 
editorial board for (ISC) 2 Journal, Information Systems Security Magazine, and the Darkreading.com 
security publication and is frequently called upon to present at international, national, and local 
conferences. Todd serves on the board of directors for the Health Insurance Portability and Account-
ability Act (HIPAA) Collaborative of Wisconsin and is an active leader, participant, and presenter in 
multiple industry associations such as ISSA, Blue Cross Blue Shield Information Security Advisory 
Group, CMS/Gartner Security Best Practices Group, Workgroup for Electronic Data Interchange, 
ISACA, Executive Alliance Information Security Executive Roundtables, and others.
Todd has 28 years of IT experience, including 20 years of management. Prior to joining NGS, 
Todd held various broad-based senior IT management positions for Fortune 500 organizations 
such as American Airlines, IMS Health, Zeneca (subsidiary of AstraZeneca Pharmaceuticals), and 
Syngenta as well as prior positions with Blue Cross Blue Shield of Wisconsin.
Todd holds a BS in business administration from the University of Wisconsin at LaCrosse and 
an MBA with highest honors from Oklahoma State University.
Robby S. Fussell, MS, CISSP, GSEC, CCSE, NSA IAM, is an information security/assurance 
manager for AT&T Government Solutions. Robby has been working in the IT/Security ﬁ eld for 
the past 13 years and has authored numerous topics in the security realm. His career has taken 
him through the areas of security in both the public and private sectors. Robby is currently com-
pleting his PhD in the area of cascading failures within scale-free networks.
Nick Halvorson is recognized for his expertise in information security, risk assessment, and 
management consulting. Currently, Nick is a senior consultant for Hotskills, Inc., specializing in 
information security and management consulting.
His experience includes the development of risk management strategies, process implementa-
tion, and security management solutions. His eﬀ orts have led directly to the creation of several 
information security management systems and formal certiﬁ cation under ISO 27001:2005.
Nick holds a bachelor of science in computer information systems from Dakota State Uni-
versity, Madison. His professional certiﬁ cations include CISSP and ISO 27001 Certiﬁ ed Lead 
Auditor among others. He is considered an expert in ISO 17799, ISO 27001, and various other 
technical disciplines. He currently resides in South Dakota.
Sasan Hamidi, PhD, CISSP, CISA, CISM, has been involved with information security for the 
past 20 years. He is currently the chief information security oﬃ  cer for Interval International, Inc., 
the leading global timeshare exchange company, where he is also involved with electronic privacy 
matters. Prior to joining Interval, Sasan was the director of enterprise architecture and security at 
General Electric Power Systems and senior project manager for IBM Network Security Services, 
where he was involved with the overall security assessment of IBM’s global networks.

Contributors  xv
Sasan’s area of interest and research is steganography, emergence, chaos, and complexity as 
they apply to network security. It is on these topics that he regularly speaks and has published 
several articles.
Paul A. Henry, MCP+I, MCSE, CCSA, CCSE, CFSA, CFSO, CISSP, CISM, CISA, ISSAP, 
CIFI, is one of the world’s foremost global information security experts, with more than 20 years 
of experience managing security initiatives for Global 2000 enterprises and government organiza-
tions worldwide.
At Secure Computing®, Henry plays a key strategic role in launching new products and 
retooling existing product lines. In his role as vice president of technology evangelism, Henry 
also advises and consults on some of the world’s most challenging and high-risk information 
security projects, including the National Banking System in Saudi Arabia; the U.S. Depart-
ment of Defense’s Satellite Data Project; and both government and telecommunications projects 
throughout Japan.
Henry is frequently cited by major and trade print publications as an expert on both technical 
security topics and general security trends and serves as an expert commentator for network broad-
cast outlets such as NBC and CNBC. In addition, Henry regularly authors thought leadership 
articles on technical security issues, and his expertise and insight help shape the editorial direction 
of key security publications such as the Information Security Management Handbook, for which he 
is a regular contributor.
Paul serves as a featured and keynote speaker at network security seminars and conferences 
worldwide, delivering presentations on diverse topics including network access control, cyber-
crime, distributed denial-of-service attack risk mitigation, ﬁ rewall architectures, computer and 
network forensics, enterprise security architectures, and managed security services.
Rebecca Herold, CIPP, CISSP, CISA, CISM, FLMI, is an information privacy, security and 
compliance consultant, author, and instructor with her own company since mid-2004, Rebecca 
Herold, LLC. She has over 16 years of privacy and information security experience, and assists 
organizations in various industries throughout the world with all aspects of their information 
privacy, security, and regulatory compliance programs. Rebecca was instrumental in building 
the information security and privacy program while at Principal Financial Group, which was 
recognized as the 1998 CSI Information Security Program of the Year. In October 2007, Rebecca 
was named one of the “Best Privacy Advisers” in two of the three categories by Computerworld 
magazine. Rebecca was also named one of the “Top 59 Inﬂ uencers in IT Security” for 2007 by IT 
Security magazine. Rebecca is an adjunct professor for the Norwich University master of science 
in information assurance program.
Rebecca has authored or coauthored many books and is currently authoring her eleventh. 
Some of them include Th e Privacy Papers (Auerbach, 2001), Th e Practical Guide to HIPAA Pri-
vacy and Security Compliance (Auerbach, 2003), Managing an Information Security and Privacy 
Awareness and Training Program (Auerbach, 2005), the Privacy Management Toolkit (Informa-
tion Shield, 2006), and coauthored Say What You Do (2007). Rebecca is the editor and primary 
contributing author for Protecting Information, which is a quarterly security and privacy aware-
ness multimedia publication by Information Shield. She has also authored chapters for dozens of 
books along with over 100 other published articles. She has been writing a monthly information 
privacy column for the CSI Alert newsletter since 2001, and regularly contributes articles to other 
publications as well. Rebecca has a BS in math and computer science and an MA in computer 
science and education.

xvi  Contributors
George J. Jahchan graduated in 1980 as an electrical engineer from McGill University in Montreal, 
Canada. He has been in various personal-computer-related positions for over 25 years, of which six 
related to gateway security and three were as a security oﬃ  cer in a university. He currently works 
as a senior security and enterprise systems management consultant in the Levant, North Africa, 
and Pakistan with CA. He holds CISA, CISM, and BS7799-2 Lead Auditor certiﬁ cations.
Kenneth J. Knapp is an assistant professor of management at the U.S. Air Force Academy. He 
received his PhD in 2005 from Auburn University, Auburn, Alabama. His research focuses on 
topics related to information security eﬀ ectiveness and has been published in numerous outlets 
including Information Systems Management, Information Systems Security, Communications of the 
AIS, Information Management & Computer Security, International Journal of Information Security 
and Privacy, Journal of Digital Forensics, Security, and Law, as well as the 2007 edition of the Infor-
mation Security Management Handbook edited by Tipton and Krause.
Franjo Majstor holds an electrical engineering degree from the Faculty of Electrical Engineering 
and Computing, University of Zagreb, Croatia, and a master of science degree from the Depart-
ment of Computer Sciences, Faculty of Science, University of Leuven, Belgium. He started his 
career in the IT industry in 1989 at Iskra Computers and NIL Ltd. in Slovenia. He was with Cisco 
Systems, Inc., in Belgium from 1995 to 2004, and Fortinet, Inc., until 2005; since 2006 he has 
been with CipherOptics, Inc.
As EMEA senior technical director at CipherOptics, Inc., he is responsible for driving to mar-
ket the latest generation of data-protection solutions. Previously, as technical director at Fortinet, 
Inc., he was responsible for security products and solutions based on the modern perimeter secu-
rity architecture, whereas at Cisco Systems, Inc., he was recognized as a trusted advisor through-
out the EMEA for the leading security projects. He achieved a CCIE certiﬁ cation from Cisco 
Systems, Inc., in 1995 and CISSP certiﬁ cation from (ISC)2 in 2000. Franjo is also an external 
CISSP instructor at the (ISC)2 international vendor neutral nonproﬁ t organization for certiﬁ ca-
tion of information security professionals and is a mentor and recognized lecturer of an ICT Audit 
and Security postgraduate study joint program between ULB, UCL, and Solvay Business School 
in Brussels, Belgium.
As a recognized security professional, Franjo is also a frequent speaker at worldwide confer-
ences on network security topics. Most relevant so far were NetSec (New Orleans, 2001), IPSec 
Summit and IPv6 Global Summit (Paris, 2002), ISSE (Vienna, 2003), IEEE (Bonn, 2003), RSA 
Security (Paris, 2002; Amsterdam, 2003; Barcelona, 2004; San Francisco, 2005; San Jose, 2006; 
Nice, 2006), and IDC (London, 2004; Prague, 2005). For the RSA Security 2005 conference, he 
was invited as an independent judge for the Perimeter Defense Track paper selections.
George G. McBride, CISSP, CISM, is a senior manager in the Enterprise Risk Services group at 
Deloitte & Touche, LLP, in New York City and has worked in the network security industry for 
more than 14 years. Before joining Deloitte, George was with Aon Consulting, Lucent Technolo-
gies, and Global Integrity. George has focused on the ﬁ nancial and telecommunications industry 
and has supported risk management, secure network architecture development, technology risk 
assessments, and more. He has spoken at MIS, RSA, (ISC)2, and other conferences worldwide on 
a wide variety of topics such as penetration testing, risk assessments, Voice-over-IP and telephony 
security, and mobile data security. He has contributed to Th e Black Book on Corporate Security and 
Securing IP Converged Networks, hosted several Webcasts, and contributed to several editions of 
the Information Security Management Handbook.

Contributors  xvii
R. Scott McCoy, CPP, CISSP, CBCP, is the chief security oﬃ  cer for Alliant Techsystems. He has 
23 years of security experience, starting as an Army explosive ordnance disposal technician. He 
also has 12 years of security management experience in ﬁ ve critical infrastructures.
David McPhee is an information security manager for a ﬁ nancial services provider in Milwau-
kee, Wisconsin. He has over 18 years experience in the information security profession, with an 
extensive background in such diverse security issues as risk assessment and management, security 
policy development, security architecture, infrastructure and perimeter security design, outsource 
relationship security, business continuity, and information technology auditing. David began his 
career in Canada, as a senior security analyst for eight years with the Atlantic Lottery Corporation, 
in Moncton, New Brunswick. He moved to the United States in 1998, working as a ﬁ rewall con-
sultant in St. Louis, Missouri. He joined his current employer in 1998 as a senior UNIX security 
analyst. Since 2000, he has held a management role within information security, and is currently 
managing the infrastructure support team.
R. Franklin Morris, Jr., is an assistant professor of management information systems at Th e 
Citadel in Charleston, South Carolina. He received his PhD in management information systems 
from Auburn University, Auburn, Alabama. He holds an MBA from Georgia Southern University 
and a bachelor of science in aerospace engineering from Georgia Institute of Technology. Morris 
has more than 20 years of experience working in private industry and has published his work in 
Communications of the AIS.
Ralph Spencer Poore is chief scientist and principal for Innové Labs LP. He has over 30 years 
of information technology experience with emphasis on high-assurance systems, applied cryp-
tography, ﬁ nancial and fusion intelligence, information forensic investigations, cyber-terrorism, 
transnational border data ﬂ ows, information assurance, audit and control, and enabling technolo-
gies. He was cited for his major contribution to the Guideline for Information Valuation and for his 
service as president of (ISC)2. Poore is an inventor, author, and frequent speaker on topics ranging 
from privacy in electronic commerce to transnational border data ﬂ ows. Poore worked closely with 
the GLBA, HIPAA, and Sarbanes–Oxley rollouts for a Fortune 400 company.
Poore is a Certiﬁ ed Fraud Examiner, Certiﬁ ed Information Systems Auditor, CISSP, Qualiﬁ ed 
Security Assessor, and is certiﬁ ed in Homeland Security-Level III.
Sean M. Price, CISA, CISSP, is an independent information security consultant residing in 
Northern Virginia. He provides security consulting and architecture services to commercial and 
government entities. Price has more than 12 years of information security experience, which con-
sists of system security administration, user information assurance training, policy and procedure 
development, security plan development, security testing and evaluation, and security architect 
activities. His academic background includes a bachelor’s degree in accounting and business, a 
master’s degree in information systems, and he is currently pursuing doctoral studies in com-
puter information systems. He has previously contributed to the Information Security Management 
Handbook, the Oﬃ  cial (ISC)2 Guide to the CISSP CBK, and the IEEE Computer magazine. His 
areas of interest in security research include access control, information ﬂ ow, insider threat, and 
machine learning.
Edward Ray is president of NetSec Design & Consulting, Inc., which specializes in computer, data, 
and network security and secure network design. Speciﬁ c areas of expertise include  implementation 

xviii  Contributors
of defense in-depth layered security solutions utilizing Cisco, Juniper, Tipping Point, Windows, 
UNIX, Linux, Free/OpenBSD, Novell, and Mac-based hardware and software; PKI/Kerberos/
LDAP implementation on Windows 2003/XP/Linux; intrusion detection and analysis; wired and 
wireless penetration testing and vulnerability analysis; HIPAA security and privacy rule implemen-
tation; and wired and wireless PC & network security design (802.11 a/b/g/i). Ray has an MS in 
electrical engineering from the University of California at Los Angeles (1997) and a BS in electri-
cal engineering from Rutgers University (1990) and holds the CISSP, GCIA, GCIH, and MCSE 
professional certiﬁ cations.
Marcus K. Rogers, PhD, CISSP, CCCI, is the head of the Cyber Forensics Program in the 
Department of Computer and Information Technology at Purdue University. He is a professor 
and a research faculty member at the Center for Education and Research in Information Assur-
ance and Security. Dr. Rogers was a senior instructor for (ISC)2, the international body that 
certiﬁ es information system security professionals (CISSP), is a member of the quality assurance 
board for (ISC)2’s SCCP designation, and is international chair of the Law, Compliance, and 
Investigation Domain of the Common Body of Knowledge Committee. He is a former police 
detective who worked in the area of fraud and computer crime investigations. Dr. Rogers is the 
editor-in-chief of the Journal of Digital Forensic Practice and sits on the editorial board for several 
other professional journals. He is also a member of various national and international committees 
focusing on digital forensic science and digital evidence. Dr. Rogers is the author of numerous 
book chapters and journal publications in the ﬁ elds of digital forensics and applied psychological 
analysis. His research interests include applied cyber-forensics, psychological digital crime scene 
analysis, and cyber-terrorism.
Ben Rothke, CISSP, CISM, is a New York City–based senior security consultant with BT INS 
and has over 15 years of industry experience in information systems security and privacy.
His areas of expertise are in risk management and mitigation, public key infrastructure (PKI), 
security and privacy regulatory issues, design and implementation of systems security, encryp-
tion, cryptography, and security policy development. Prior to joining INS, Ben was with AXA, 
 Baltimore Technologies, Ernst & Young, and Citicorp and has provided security solutions to 
many Fortune 500 companies.
Ben is the author of Computer Security: 20 Th ings Every Employee Should Know (McGraw-Hill) 
and a contributing author to Network Security: Th e Complete Reference (Osborne), and Th e Hand-
book of Information Security Management (Auerbach). He writes a monthly security book review 
for Security Management and is a former columnist for Information Security, Unix Review, and 
Solutions Integrator magazines.
Ben is also a frequent speaker at industry conferences such as the Computer Security Institute 
(CSI), RSA, MISTI, NetSec, and ISACA and is a CISSP and Certiﬁ ed Information Security 
Manager (CISM). He is a member of HTCIA, ISSA, ISACA, ASIS, CSI, and InfraGard.
Don Saracco, Ed.D., joined MLC & Associates, Inc., in 1997 with over 25 years experience in 
human resource and organizational development in manufacturing, health care, and government 
organizations as a manager and consultant. His background includes the design and delivery 
of corporate education and training as well as executive coaching, facilitation of organizational 
change, and process improvement. In addition, he has served as an adjunct faculty member for a 
state university and a private business school.

Contributors  xix
Don served for several years as a faculty member of the Business Recovery Managers Sympo-
sium presented by the MIS Institute. His speaking credits include Business Continuity Planning 
and Y2K Preparedness workshops for the International Quality & Productivity Center in Atlanta, 
Georgia; Orlando, Florida; and Las Vegas, Nevada; and the 4th International  Conference on 
Corporate Earthquake Programs in Shizuoka, Japan, as well as the annual Contingency Planning 
and Management Magazine Conference and Exposition. In addition, Don has presented papers at 
national and international conferences sponsored by the International Society for  Performance 
Improvement, the Association for Quality and Participation, RIMS, and  Continuity Insights. He 
has also worked as an adjunct faculty member in graduate business programs at two accredited 
universities.
Derek Schatz, CISSP, is currently the lead security architect for network systems at Boeing Com-
mercial Airplanes. He has been in information security for over 10 years in both enterprise and 
consulting roles, including a stint in the Big 5. He has spoken at a number of conferences besides 
teaching information security. He holds a bachelor’s degree in economics from the University of 
California at Irvine.
Craig A. Schiller CISSP-ISSMP, ISSAP serves as chief information security oﬃ  cer of Portland 
State University and as the president of Hawkeye Security Training, LLC.
He has worked in the computer industry for the past 27 years. For 17 of those years, he worked 
as an information security professional.
Craig is the primary author of Botnets: Th e Killer Web App, which is the ﬁ rst book published on 
the subject of botnets. He is known and respected in the security industry as the primary author of 
the ﬁ rst publicly distributed version of the GSSP, now known as the Generally Accepted Informa-
tion Security Principles. He has published 12 chapters in various security books, including several 
previous editions of the Information Security Management Handbook.
Craig is a volunteer police reserve specialist for the Hillsboro Police Department. He is the 
organizer of volunteers for their Police to Business Program.
Craig led the development of the NASA Mission Operations AIS Security Engineering team 
and founded NASA’s Technology for Information Security conference. He is a cofounder of two 
ISSA chapters.
E. Eugene Schultz, PhD, CISM, CISSP, is the chief technology oﬃ  cer and chief information 
security oﬃ  cer at High Tower Software, a company that develops security event management 
 software. He is the author/coauthor of ﬁ ve books: the ﬁ rst on UNIX security, the second on Inter-
net security, the third on Windows NT/2000 security, the fourth on incident response, and the 
latest on intrusion detection and prevention. He has also published over 110 papers. Dr. Schultz is 
the editor-in-chief of Computers and Security and is an associate editor of Network Security and the 
Information Security Bulletin. He is also a member of the editorial board for the SANS NewsBites, 
a weekly information security-related news update, and is on the technical advisory board of two 
companies. He has been professor of computer science at various universities and is retired from 
the University of California at Berkeley. He has received the NASA Technical Excellence Award, 
the Department of Energy Excellence Award, the ISSA Professional Achievement and Honor Roll 
Awards, the ISACA John Kuyers Best Speaker/Best Conference Contributor Award, the Vanguard 
Conference Top Gun Award (for best presenter) twice, the Vanguard Chairman’s Award, and the 
National Information Systems Security Conference Best Paper Award. Additionally, Eugene has 

xx  Contributors
been elected to the ISSA Hall of Fame. While at Lawrence Livermore National Laboratory he 
founded and managed the U.S. Department of Energy’s Computer Incident Advisory Capability. 
He is also one of the founders of the Forum of Incident Response and Security Teams. Dr. Schultz 
has provided expert testimony before committees within the U.S. Senate and House of Represen-
tatives on various security-related issues and has served as an expert witness in legal cases.
Robert M. Slade is an information security and management consultant from North Vancouver, 
British Columbia, Canada.
His initial research into computer viral programs developed into the writing and reviewing 
of security books and eventually into conducting review seminars for CISSP candidates. He also 
promotes the Community Security Education project, attempting to promote security awareness 
for the general public as a means of reducing overall information security threats.
Samantha Th omas is the CSO at a $290-billion ﬁ nancial regulatory organization in the United 
States. Th omas is a founding board member of the University of California at Davis Network 
Security Certiﬁ cation Program, and she has developed curricula for universities, institutes, and 
private industries. She is a regularly requested international keynote and think tank facilitator. 
Th omas has been a featured speaker in ﬁ ve European Union countries, South Africa, Austra-
lia, Mexico, and Papua New Guinea. Her writings, interviews, and quotations are published in 
international newspapers, magazines, and books. Th omas creates and provides “online safety” for 
K–8 children, parents, and school administrators. She is a U.S. Executive Alliance Information 
Security Executive of the Year (Western Region) nominee.
Guy Vancollie is the MD EMEA for CipherOptics, leading provider of data protection solutions. 
Prior to joining CipherOptics, Guy was the CMO for Ubizen and an evangelist in the emerging 
space of managed security services. Earlier in his career, he managed both U.S. ﬁ eld marketing 
and international marketing for RSA Security, was director of EMEA marketing for AltaVista 
Internet Software, and held several positions with Digital Equipment Corp.
Vancollie has spoken on Internet and security topics at conferences such as IT Asia and 
 CommunicAsia, EEMA, and IMC, as well as Gartner Sector 5, Infosecurity Europe, and the 
RSA Conference.
Vancollie earned an MS degree in electrical engineering magna cum laude from the State Uni-
versity of Ghent in Belgium, a degree in management from the Vlerick School of Management, 
and an MBA from the MIT Sloan School.

DOMAIN
  
1
INFORMATION 
SECURITY AND 
RISK MANAGEMENT
Security Management 
Concepts and Principles


3
Chapter 1
Integrated Threat Management
George G. McBride
Contents
Introduction ................................................................................................................................ 3
What Is an ITM? ........................................................................................................................ 4
Pros and Cons of an ITM Solution ............................................................................................. 9
Evaluating an ITM Solution ......................................................................................................11
Conclusion and Lessons Learned .............................................................................................. 13
Integrated threat management (ITM) is the evolution of stand-alone security products into a 
single, uniﬁ ed solution that is generally cheaper and easier to implement and maintain. Combine 
a single console for management, updates, reports, and metrics, and you will wonder why you do 
not have one at home too. Th is chapter will introduce what an ITM solution is, the beneﬁ ts and 
drawbacks of the solution, what to look for, and how to select a solution. Finally, the chapter will 
wrap up with some lessons learned to help avoid some of the common pitfalls and gaps in a typical 
ITM solution.
Introduction
One cannot read an information security magazine or attend a trade show without hearing about 
ITM. Within the same magazine or across the aisle, the next vendor may be advertising “uniﬁ ed 
threat management” or even perhaps “universal threat management.” What these are, what the 
beneﬁ ts to an organization are, what to look for when evaluating solutions, and lessons learned are 
discussed in this chapter. Even if you have no intention today of deploying an integrated or uniﬁ ed 

4  Information Security Management Handbook
solution, this chapter provides you with a solid background to understand thoroughly and leverage 
this emerging technology in the future.
Integrated, uniﬁ ed, and universal threat management all have much the same implementa-
tions and goals; their names are diﬀ erent only because they were chosen by diﬀ erent vendors. For 
the sake of consistency within this chapter, we will choose to use the phrase “integrated threat 
management.”
To start, let us examine the deﬁ nition of ITM and what it brings to the enterprise. First, ITM 
is focused on threats that may aﬀ ect an organization. A threat is deﬁ ned as some entity that may 
be capable of attacking or aﬀ ecting the organization’s infrastructure. When used in a quantitative 
manner, the threat component also includes likelihood and impact considerations as well. Perhaps 
it is a malicious payload carried via Hypertext Transfer Protocol or via e-mail, or perhaps it is a 
“0-day” virus not yet seen by an antivirus software manufacturer. It may be a phishing site and 
the accompanying e-mails inviting users to visit the site to verify their account information or it 
may be a polymorphic worm whose purpose is to evade ﬁ rewalls while continuously morphing its 
signature as it attacks the next target.
An ITM platform should, by deﬁ nition, protect an enterprise against all of these threats and 
provide a platform to monitor and manage the ITM. To address these threats, the platform may 
include the following functions:
An intrusion detection system (IDS) or an intrusion prevention system (IPS)
Antivirus solution
Antispyware solution
Unsolicited commercial e-mail ﬁ ltering
Content ﬁ ltering that includes e-mail and instant messenger content management
Uniform resource locator (URL) ﬁ ltering, which may include serving as a Web cache proxy
Firewalls
Virtual private network (VPN) connectivity
It is important to note that in the absence of a deﬁ ned standard for ITM, almost any product with 
an integrated (uniﬁ ed) combination of functions listed here can and likely has been called an ITM 
solution. Fortunately, if you follow the steps identiﬁ ed under “Evaluating an ITM Solution,” you 
will learn how to identify and include the components that are important and relevant to your 
ITM requirements.
What Is an ITM?
Th e ITM platform is an extension to the information security life cycle within a typical orga-
nization. As you may recall, a number of organizations typically started with very rudimentary 
(compared to today’s standards) IDS capabilities that complemented an existing ﬁ rewall solution 
at the perimeter. Some number of IDS personnel actively monitored a number of consoles for 
anomalies and reacted accordingly based on the alarms produced by the consoles. As the technol-
ogy matured, a more eﬀ ective and valuable event correlation function developed that allowed us 
to see longer term, more sophisticated and professional style attacks. Somewhat concurrent with 
the advancements in event correlation came IPSs, which allowed connections that either the user 
or the system determined to be a threat to the system’s environment to be actively shut down. 
Th e ITM platform is the next stage of evolution, by which one can monitor and manage not only 
ﬁ rewall and IDS data, but all security appliances.









Integrated Threat Management  5
It is important to note the similarities, as well as the functional diﬀ erences, between an ITM 
program and an eﬀ ective enterprise risk management (ERM) program, which are diﬀ erent, but 
complementary, programs. Recall that the function to calculate risk can be deﬁ ned as
C
Risk (asset) =
T     V
where T is the threat, V the vulnerability, and C the control or safeguard employed to protect the 
asset. Th e asset need not be a single system, but can be a collection of systems grouped by function 
(such as the Human Resources systems or all e-mail servers), by physical or logical location (such 
as New Jersey or systems in the corporate demilitarized zone), or even by system administrators 
or groups of users.
An ERM program is a continuously measured enterprisewide view of the risks aﬀ ecting an 
organization. A properly implemented ERM program identiﬁ es and measures the risks from 
perspectives such as ﬁ nancial, operational, reputational, and strategy. One of the most dynamic 
aspects of enterprise risk is the operational component, as it includes the logical and physical 
security risks of an organization. Having an eﬀ ective ITM program provides a component of the 
many inputs required to support a successful ERM program. Although it is quite possible to have 
a successful ERM program without an ITM program, it signiﬁ cantly simpliﬁ es the collection and 
management of data to support one aspect of the program.
Returning to the ITM discussion, the platform as such does not require that all components 
be manufactured by the same company, but rather the components have their life-cycle activities 
consolidated. Th ese activities include the following:
Implementation and deployment
Management
Reporting
Maintenance
Updates
Rarely does a single manufacturer produce a best-in-class product in each area that it attempts. As we 
will see, an ITM solution may include components from several manufacturers utilizing a completely 
separate third-party integration tool or it may include using the management of several components 
to serve as its integrated solution. Alternatively, an organization may choose to develop its own inte-
grated solution, relying on the framework of the individual components to satisfy its needs.
As has been presented here, an ITM solution typically integrates several IT security compo-
nents within the infrastructure. Consider the simpliﬁ ed network diagram shown in Figure 1.1, 
which highlights the IT security components of a typical organization.
Th ere are equally viable architectures that could support an ITM program. In this situation, 
the ﬁ rewall, VPN, antispyware, antivirus software, and IDS solution are individual solutions and 
are managed individually. One typical solution is shown in Figure 1.2.
As a typical ITM solution, the functions identiﬁ ed in the traditional solution in Figure 1.2 
are combined into a single, integrated solution. It is quite possible, and in fact quite likely, that 
a typical ITM architecture may include two ITM devices to support high availability and load-
 balancing requirements. Th e primary components of an ITM solution are the management func-
tions, the individual engines, event data, and conﬁ guration data of the ITM solution.






6  Information Security Management Handbook
Th e management of an ITM solution is one of the most critical functions of the solution, as IT 
support personnel will need to manage and maintain the system. Th e ITM management functions 
should be a cohesive and tightly integrated module that includes the following:
A dashboard that clearly shows the overall operating eﬃ  ciency, critical events, and ITM 
functions that require attention and action and can be customized to the individual con-
ducting the monitoring
Th e ability to run queries that may be predeﬁ ned by the vendor or ad hoc queries deﬁ ned 
by the organization
Th e ability to throttle traﬃ  c or reallocate processing capability to prioritize traﬃ  c or 
functions
Th e ability to assign and manage user accounts and roles and responsibilities
Th e ability to support multiple concurrent sessions to manage and monitor the device and 
events
Th e maintenance and update functions within the management component should focus on the 
maintenance of the ITM platform, including interfaces to the database backups, restoration, and 
repair. Th is is quite important and should also include provisions for archiving of data, and more 
importantly, an eﬀ ective method of recalling and viewing the archived data. For example, if we 
need to recall the data from four months ago that has been archived to tape and stored oﬀ -site, 
a valuable feature of the ITM platform would be the identiﬁ cation of which particular tapes we 
need to recall and then an easy way to view the data once it has been recalled.





Internet
Firewall
IDS/IPS
system
URL
filtering
Antivirus
E-mail and
UCE filtering
Corporate
network
Figure 1.1 Traditional IT security components.
ITM
appliance
Internet
Corporate
network
Figure 1.2 Typical ITM solution.

Integrated Threat Management  7
Th e core of an ITM solution is the processing engines that do the work. Th e antivirus engine, 
the ﬁ rewall engine, and perhaps the reporting engine are the foundation of the solution and are 
utilized by the management function to provide an integrated solution. Whether the engines are 
single or multiple processors, shared or independent, commercial or proprietary; the customer is 
typically concerned about making sure that his or her requirements are satisﬁ ed during regular 
and peak periods.
One of the most useful and desirable beneﬁ ts of an integrated solution is the correlation of the 
data collected and analyzed across the engines. Consider an innocent-looking e-mail message that 
would typically pass through an antivirus server. If the message has an HTML-based attachment 
that includes a Trojan or other malicious payload, an integrated solution can utilize a combination 
of antivirus, antispyware, unsolicited commercial e-mail ﬁ ltering, and other security engines to 
detect the blended threat and block it from entering the network.
As part of the correlation functionality of an ITM, the management console can typically 
identify threats across a wider range of types of attacks, which can result in a more eﬃ  cient 
response and can also look at the destination of more than one type of attack (such as ﬁ rewall and 
antivirus messages) to develop an appropriate response to ensure that the organization’s assets are 
appropriately protected.
In both examples, it is the combination of data from multiple sources that allows the analysis 
of aggregated data typically not detectable from a single vantage point. It is important to note, 
however, that most ITM solutions focus on the active protection of the organization rather than 
serving as a complete security event management (SEM) system. For those organizations, the 
adoption of a more robust SEM solution that takes input from the ITM may be preferable, as its 
core strength is the correlation and analysis of the data.
Th ere is typically a database engine that focuses on maintaining the events that are detected 
and generated by the ITM solution. Depending on user preferences stored in the conﬁ guration 
database, an almost unlimited combination of events may be logged, stored, or analyzed. Some 
examples include
Packets dropped by the ﬁ rewall
VPN users that were successfully authenticated and connected to the intranet
Messages sent via e-mail that contained a predeﬁ ned pattern and were logged in accordance 
with the requirements
Sources of unsolicited commercial e-mail messages
Th e database may be a proprietary solution that can be accessed only through interfaces provided 
by the vendor or may not be directly accessible at all. Some vendors utilize commercially available 
databases on separate systems for scalability and ﬂ exibility issues that also may come with or with-
out appropriate interfaces and may or may not require additional tuning and maintenance.
Th e engines and management console typically rely on a conﬁ guration database that main-
tains user preferences, user accounts and roles and responsibilities, and other system conﬁ guration 
information. Th is is the information that maintains the current state (and sometimes past state 
for rollback) of the system. Depending on the level of integration by the vendor, the ITM solution 
may provide a uniﬁ ed console to manage the conﬁ guration information but may utilize one or 
more databases to store the information.
It should be extensible. An ITM platform should include functions to support the imple-
mentation and deployment of additional components. For example, the inclusion of data and 
metrics from the desktop antivirus solution should not require a complete rewrite of the code, but 





8  Information Security Management Handbook
perhaps an incremental additional licensing cost. A well-designed ITM console should provide a 
documented and supported interface to devices and other platforms and be capable of accepting, 
correlating, and analyzing the data that they provide.
Th e extensibility of the ITM solution should not be exclusive to the front-end or “input” side, 
but should also include the back-end or “output” side. Many organizations may utilize the ITM 
solution and the built-in tools to generate alerts to appropriate persons that will conduct further 
investigations or obtain additional data. Some organizations may wish to use the ITM solution as 
an input to their dispatching or trouble ticket system. Depending on the organization’s require-
ments, how and what the ITM solution produces may need to be evaluated and be part of the 
decision-making criteria.
One of the most important functions of an ITM platform from a senior management perspec-
tive will be the development of metrics and reports that highlight the overall eﬀ ectiveness (or inef-
fectiveness) of the ITM platform. Typical metrics include the following:
New threats identiﬁ ed
Total threats encountered
Eﬀ ectiveness of managing new threats
Trouble tickets generated
Trouble tickets closed
Coﬀ ees consumed while troubleshooting the ITM appliance
Well, OK, the last one was thrown in as a joke, but it should be realized that although metrics are 
important to the ITM platform and the organization, one should not get carried away in creating 
numbers for the sake of creating numbers. Metrics and reports should be generated to identify 
areas of the ITM program that need improvement or require some additional action to support, 
to measure progress, and, very important, to measure compliance to existing corporate policies 
and regulations.
An eﬀ ective ITM solution is more than just the box and some tools to manage it. Although 
a separate IT security program focused on the ITM solution may not be necessary (but quite 
helpful), integration of the ITM solution into the existing security program is necessary. An 
eﬀ ective program should address the following areas:
Responsibilities of the various roles required to support and monitor the solution.
Appropriate training and required qualiﬁ cations for the various roles.
How the system is updated (including testing) with patches, dataﬁ le updates, operating 
system updates, etc.
Processes to request, review, approve, and implement changes, such as ﬁ rewall rule changes 
and content monitoring criteria.
All required policies, practices, standards, and procedures to support and monitor the solu-
tion. It is very important that the implementation of an ITM solution include a review or 
creation of a policy so that associates know what activities are monitored and logged.
What system parameters and characteristics are monitored and included in the metrics and 
reports. How the metrics and reporting data are used to drive eﬃ  ciency and eﬀ ectiveness 
into the ITM solution should be addressed.
How reports and alerts are reacted to, managed, and ultimately closed after being resolved. 
Th e ITM program should address the interface, if any is required, between the ITM solution 
and any system used to facilitate a response to a threat that is detected.














Integrated Threat Management  9
Th is is not an inclusive list of the components of an ITM solution but serves as a foundation to 
develop a program that can grow and adapt as necessary. Finally, the program also serves to help 
drive and support IT governance by ensuring that the ITM program (including all required docu-
mentation, monitoring, reaction to events, etc.) is fully operational and receiving the required 
support by upper management.
Th e ITM program should also include an IT security assessment of the implementation to 
measure the compliance with industry best practices and organizational policies. Th e assessment 
should review the ITM appliance or infrastructure to identify any vulnerabilities introduced, it 
should review the rules implemented within the ITM, and it should validate that the rules are 
being properly evaluated and processed by the ITM device. Finally, as part of the ITM program, 
assessments and audits of the ITM infrastructure should be scheduled on a regular basis.
Pros and Cons of an ITM Solution
Th ere are a number of beneﬁ ts to the deployment and implementation of a successful ITM pro-
gram. Th ose beneﬁ ts include consolidation, which typically drives cost and complexity, ease of 
management, and integrated reporting. Th e beneﬁ ts of an ITM solution are not without a few 
drawbacks, which may include a lack of ﬂ exibility and potential performance issues if not scaled 
properly.
One of the most obvious and visible beneﬁ ts of an ITM solution, and one of the most prevalent 
arguments made by ITM vendors, is the consolidation of a number of components and functions 
into a single, uniﬁ ed solution. Combining multiple functions into a single solution, and poten-
tially a single appliance, will likely provide initial and ongoing cost savings.
Initial “capital” costs of an ITM solution are traditionally less than the costs of the individ-
ual components that comprise the ITM solution. Costs associated with vendor negotiations and 
licensing can be reduced from ﬁ ve or six vendors to a single ITM vendor. Additionally, the price of 
the appliance is typically substantially less than the sum of the components, through economies of 
scale and the use of common hardware and software. Likewise, the maintenance costs of a single 
appliance or solution are generally less than those of the separate components, which increases cost 
savings continuously over the product’s life.
In the future, when the company needs another function provided by the ITM solution, it can 
be as simple as generating a purchase order and installing a license key that was received via e-mail. 
Th at alone often saves weeks of time and quite a bit of money for the organization. Although new 
policies and inputs may be needed, rearchitecting the network and lengthy vendor evaluation and 
negotiations will likely not be needed.
An often overlooked factor in cost savings is the cost to house the components in the data 
center. Just like traditional real estate costs, some organizations bill back data center costs to the 
business. Consider the signiﬁ cant reduction in costs, moving from several boxes consuming rack 
space to a single unit with comparable functions. Additionally, overall power consumption will 
be reduced, as will the cooling costs, two important factors today in data center costs. To a data 
center that is already at maximum capacity with existing equipment, being able to retroﬁ t several 
devices to a single solution or the addition of a single box that previously would have needed half 
of a rack is a tremendous advantage. Adding an additional equipment rack or maintaining equip-
ment in multiple locations adds additional costs, complexity, and overhead.
Having a single console to manage will reduce the amount of time required to maintain and 
manage the infrastructure. Although it is imperative to ensure that all components are regularly 

10  Information Security Management Handbook
updated with any appropriate signatures such as antivirus and antispyware data ﬁ les, equally 
important are the updates at the system level. Maintaining the operating system and application 
updates on one system will require less time and money than maintaining the updates on several 
systems.
Consider the beneﬁ ts of deploying an ITM solution at each branch oﬃ  ce or location when the 
equipment, maintenance, and management costs are multiplied across the organization. Additionally,
whether conducting an audit or an assessment at one location or each of the branch oﬃ  ces, having one 
console to measure compliance and conduct audits and assessments will be tremendously useful and 
beneﬁ cial to the organization.
A uniﬁ ed console to manage the ITM components also requires less training and shorter 
timeframes for employees to learn and understand. Many ITM solutions also provide for granular 
user-account provisioning (including roles and responsibilities) that allows individuals to have 
access to maintaining or monitoring their respective components. Depending on the conﬁ gura-
tion of the ITM infrastructure, logging and alerting may be “uniﬁ ed” as well or at least pro-
vide for a consistent and uniform notiﬁ cation process that can be easily integrated into an SEM 
architecture. Likewise, the management of the ITM infrastructure from a single console allows 
an administrator to view all aspects and parameters of the system without needing to hop from 
system to system. Th e beneﬁ ts of an integrated ITM reporting system can help with metrics, 
troubleshooting, return on investment studies and compliance, audits, and assessments (as noted 
earlier).
Some organizations consider the lack of ﬂ exibility of an ITM solution to be a signiﬁ cant 
drawback. For example, consider the ITM solutions that are available today. Although most 
vendors often do not attempt to develop their own solutions for all ITM functions, they partner 
or form alliances to deliver that integrated solution. If you are an organization moving toward 
an ITM infrastructure, are you willing to use the antivirus software that the vendor has chosen 
versus the one that you have or want to have? What about the ﬁ rewall or the VPN connectiv-
ity solution? Although you do not have to license and use all of the components oﬀ ered within 
an ITM solution, the cost savings, management, and beneﬁ ts of an integrated solution may 
outweigh the inconveniences. It is unlikely that each component of the ITM will have been 
voted “best in class,” but it is likely that the overall beneﬁ ts of a well-integrated solution have
that vote.
Some organizations are concerned with performance issues with available ITM solutions and 
feel that a single appliance cannot eﬃ  ciently handle all functions without signiﬁ cant trade-oﬀ s. 
Just like any other solution, corresponding requirements need to be developed individually for 
each function. Once those requirements are developed, ITM solutions can be evaluated. Design 
and architecture of the ITM solution can be evaluated. Questions such as whether speciﬁ c func-
tions are sandboxed and managed to ensure that the required memory and processing power are 
provided should be answered. Having a signiﬁ cant peak in messages with large attachments that 
need to be scanned should not cause the ﬁ rewall to block traﬃ  c or, worse yet, allow traﬃ  c to pass 
without the deﬁ ned screening.
Although many of the ITM solutions today are appliances, there are some software-only plat-
forms that operate on top of hardware and operating system platforms provided by the user. 
Although the vendor typically provides the speciﬁ cations of those systems, it may or may not 
deﬁ ne security requirements to help ensure that the platform itself is secure. Customers should 
understand that if a system is an appliance, they may be prohibited by licensing or may not even 
have access to perform security updates to the core operating system.

Integrated Threat Management  11
Evaluating an ITM Solution
One of the most important aspects of the ITM life cycle is the development of the evaluation 
criteria so that the available products can be reviewed and assessed against standard criteria. With 
more than a single person conducting the assessment process, this is critical to help ensure a 
consistent approach to the process. Th is section will discuss the development of selection criteria, 
scoring of solutions, and selection of the product.
Th e development of the selection criteria should be based on what is expected from each of 
the individual components as well as what the requirements are from the consolidated reporting, 
management, and maintenance functions. First, develop a list of the functions that are critical 
to being part of the ITM solution. Although ﬁ rewall, VPN, and antivirus are the most common 
functions of an ITM solution, other functions discussed in the introduction may be considered 
mandatory or optional to the organization. It is important to note that many vendors market their 
ITM products to small to medium business enterprises. Th ese are the organizations that may not 
have extensive and complex ﬁ rewall, content monitoring, logging, etc., requirements. For those 
ﬁ rms that require complex rules, have extremely heavy bandwidth requirements, or have very spe-
ciﬁ c needs, an ITM solution may not ﬁ t their needs. Following the process provided here should 
help determine the answer for you.
Once those components are identiﬁ ed, individual requirements should be developed and 
labeled as mandatory or optional. For example, consider the ﬁ rewall component and ask whether 
you have or expect to have Voice-over-IP (VoIP) traﬃ  c passing through your ﬁ rewall. If so, Session 
Initiation Protocol application inspection capabilities may be a requirement to support the VoIP 
traﬃ  c and may be heavily weighted as such. If VoIP traﬃ  c requirements are still under review, it 
may be considered mandatory, with a lighter weighting according to the relative importance to the 
organization, or even labeled as optional.
Once the individual components have been identiﬁ ed and their respective requirements 
deﬁ ned, the requirements of the uniﬁ ed solution should be identiﬁ ed and weighted. Requirements 
in these areas typically include
Ability to deﬁ ne user roles and responsibilities that meet the organization’s security needs
Reports and metrics that support compliance, auditing, and any required return on invest-
ment information
Extensibility and ease of access to the database engine to extract custom reports or feed to 
any other system
Appliance and component updates including dataﬁ les (such as antivirus or antispyware) and 
system-level updates including ease of installation, frequency of updates, and reliability of 
updates
Space, size, power, and cooling requirements for integration into the data center
Th e vendor road map: with appropriate consideration, the product road map including addi-
tional features and integration opportunities
Ability to add increased capacity such as storage and bandwidth processing through systems 
in parallel or upgrades
Ability to support the device, such as on-site support, 24/7 telephone service, and same-day 
or next-day replacement options
Correlation features that allow one to look at data across a longer time range by threat, by 
asset, by physical location, etc.










12  Information Security Management Handbook
When all of the requirements have been considered, a table should be developed that includes all 
of the requirements and their respective weighting that can be utilized to evaluate the products.
A sample table is shown in Figure 1.3.
In addition to the myriad of technology-based evaluation criteria, the ITM manufacturer 
should also be evaluated. Moving toward an ITM solution is a diﬃ  cult choice. Although the risk 
of going out of business may be marginal, it is a risk, as is perhaps the greater risk of a product line 
being dropped as a result of an acquisition or merger. When you are putting the protection of your 
entire infrastructure into the hands of a single organization, the company itself should be evalu-
ated. Is the vendor venture capital ﬁ nanced, public, or private? What is the direction of the com-
pany? What is the reputation of the company in the industry? Is the ITM solution the main focus 
of the company or just a small part? Although there may not be a wrong or right answer to any of 
these questions, understanding the company is part of the informed decision-making process.
Many organizations follow a two-phased approach to evaluate solutions. In any event, it is 
important to understand and follow the product or solution evaluation methodology for your orga-
nization. Th e ﬁ rst phase is a non-technology-based review, which may consist of discussions with 
vendors, reading of white papers, reading of independent evaluations, and discussions with peer 
and industry groups. Rather than evaluating 20 or 30 ITM solutions that may satisfy your require-
ments, the ﬁ rst phase is intended to narrow the list down to a smaller, manageable list of vendors 
that require a more thorough evaluation. By eliminating solutions that do not meet your require-
ments up front, the selection pool is reduced. Solutions that marginally meet your requirements or 
have additional beneﬁ ts and features should be noted and marked for further evaluation.
Th e second phase is one of further discussions with vendors and a further review of white 
papers, product speciﬁ cation sheets, and manuals and documentation. For those systems that 
make the short list (typically two to three systems), a “try before you buy” program may exist that 
allows you to implement the product in an environment that you maintain. Some organizations 
may have a test lab in which products are evaluated, some may choose to run the ITM solution 
under evaluation in parallel with preexisting solutions, and some may wish to evaluate the ITM 
solution operating in lieu of the preexisting solutions. Th e merits of each solution are varied, but 
the reader is warned not to test an unproven security solution in a production environment as the 
sole line of defense.
Vendor A
Vendor B
Vendor C
Vendor D
Vendor E
Vendor F
Vendor G
Vendor H
Vendor I
Criteria
High
availability
Customizable
URL filtering
FW supports
100 MB/s
SSL VPN
FW supports
VoIP
Accepts alerts from
other devices
Figure 1.3 Sample evaluation table.

Integrated Threat Management  13
Conclusion and Lessons Learned
Th e selection, implementation, and maintenance of an ITM solution should follow the life cycle 
of any other IT security product deployed within an organization’s infrastructure. However, given 
that any ITM solution typically encompasses several critical security and control components of 
an organization, any mistake is often ampliﬁ ed due to its criticality and function. Make an error 
on the selection of an ITM solution and ﬁ ve diﬀ erent components may not perform as expected. 
Realize the diﬃ  culty of developing a business case to implement an ITM solution and then realize 
how diﬃ  cult it will be to develop a business case to implement a second, better performing, ITM 
solution.
To avoid these errors, during the selection phase, you must deﬁ ne your selection criteria accu-
rately. It makes no diﬀ erence whether an ITM solution has the best e-mail ﬁ ltering if that is not 
nearly as important as having a ﬁ rewall that serves as a VoIP gateway. Many organizations have 
suﬀ ered because they decided to move toward a solution that oﬀ ered great and wonderful features 
and functionality in areas that were not part of their mandatory requirements and were perhaps 
actually lacking in those areas that were part of their requirements.
Th e development of an eﬀ ective program including the ITM solution is imperative to ensure 
that it is properly used, monitored, and reacted to. Too many companies focus on the IT aspects 
of a deployment and fail to include any of the requisite training, awareness, documentation, and 
integration into the existing infrastructure. Without a program that addresses those areas, an 
organization will, at best, not fully utilize the solution. At worst, the security posture of the orga-
nization will be signiﬁ cantly reduced below an acceptable level if alerts are missed, personnel are 
not trained, parameters are not properly conﬁ gured, etc.
In addition, organizations habitually neglect to plan for growth in terms of size and bandwidth 
within their network. Many of the ITM solutions are geared toward small- to medium-sized busi-
nesses and have plenty of room to grow and add capacity as the organization grows. However, 
many organizations fail to plan far enough into the future and at some point the chosen ITM 
solution may no longer scale to support the business needs. Be sure to look far enough into the 
future and be sure that the solution meets your needs today and tomorrow.
Th e ITM market continues to grow in terms of both number of features within each solu-
tion and number of vendors that are marketing solutions. Whether it is a single appliance or an 
integrated solution and whether it is from one vendor or many, you will ﬁ nd that there are both 
extremely stellar and extremely inferior products available. Understanding what your require-
ments are and evaluating the available products to ﬁ nd a viable and eﬀ ective solution that meets 
your requirement are half of the solution. Developing and implementing a robust ITM program 
that supports, governs, and sustains the ITM infrastructure completes the solution and serves as 
the remaining foundation to a successful ITM implementation that helps reduce risk posture, 
saves costs, and increases management and insight into the threats aﬀ ecting the organization.


15
Chapter 2
Understanding Information 
Security Management Systems
Tom Carlson
Contents
What Is an Information Security Management System? ............................................................16
Deﬁ nitions ........................................................................................................................16
History and Background...................................................................................................16
Concept ............................................................................................................................16
Why Is an ISMS Beneﬁ cial? .......................................................................................................17
Defensible .........................................................................................................................17
Diﬀ erentiator ....................................................................................................................17
Business Enabler ...............................................................................................................18
Structure ...........................................................................................................................18
Who Participates in an ISMS? ...................................................................................................19
Board ................................................................................................................................19
Executive Staﬀ  ..................................................................................................................19
Management .....................................................................................................................19
Operations ........................................................................................................................19
Where Does an ISMS Live? ...................................................................................................... 20
Enterprise ........................................................................................................................ 20
Information Security Domains ........................................................................................ 20
How Is an ISMS Built? ............................................................................................................. 20
Understand the Environment ...........................................................................................21
Assess Enterprise Risk .......................................................................................................21
Charter Information Security Program .............................................................................21
Assess Program Risk ........................................................................................................ 22

16  Information Security Management Handbook
Create Enterprise Information Security Baseline .............................................................. 22
Directives................................................................................................................ 22
Methodologies ........................................................................................................ 22
Responsibilities ....................................................................................................... 23
Create Domain-Speciﬁ c Implementations ....................................................................... 23
Speciﬁ cations .......................................................................................................... 23
Procedures .............................................................................................................. 23
Tasks....................................................................................................................... 23
Assess Operational Risk ................................................................................................... 23
Measure and Monitor ...................................................................................................... 24
Environmental Metrics ........................................................................................... 24
Program Metrics ..................................................................................................... 24
Process Metrics ....................................................................................................... 24
When Does an ISMS Protect? ................................................................................................... 24
Degree of Assurance .........................................................................................................25
Degree of Maturity ...........................................................................................................25
Degree of Implementation ................................................................................................25
Summary ...................................................................................................................................25
What Is an Information Security Management System?
Deﬁ nitions
Information security: Preservation of conﬁ dentiality, integrity, and availability of information.
Management system: Coordinated activities to direct and control an organization.
Information security management system (ISMS): Coordinated activities to direct and control 
the preservation of conﬁ dentiality, integrity, and availability of information.
History and Background
Th e current process-based approach to management systems is derived from the work of  W. Edwards 
Deming and the world of Total Quality Management (TQM). His holistic and process-based 
approach to the manufacturing sector was initially ignored but eventually embraced after the rapid 
rise in quality of Japanese products in the 1960s. Although initially viewed as relevant only to a 
production-line environment, the concepts of TQM have since been successfully applied to many 
other environments.
Concept
ISMS is an example of applying the management system conceptual model to the discipline of infor-
mation security. Unique attributes to this instance of a management system include the following:
Risk management applied to information and based upon metrics of conﬁ dentiality, integ-
rity, and availability
TQM applied to information security processes and based upon metrics of eﬃ  ciency and 
eﬀ ectiveness



Understanding Information Security Management Systems  17
A monitoring and reporting model based upon abstraction layers that ﬁ lter and aggregate 
operational details for management presentation
A structured approach toward integrating people, process, and technology to furnish enter-
prise information security services
An extensible framework from which to manage information security compliance
INFOSEC program
Program
services
Compliance
TQM
Enterprise
process
Enterprise
process
Enterprise
process
People
Risk management
Procedure
Technology
Program
services
Program
services
Reporting
Why Is an ISMS Beneﬁ cial?
On the surface, ISMS may appear to be a paperwork exercise. Although this may be true, the ben-
eﬁ t of ISMS far outweighs the resultant documentation. Of equal or greater value is the resultant 
thought processes, awareness, and informed-choice decision making.
Defensible
Th e structure inherent to an ISMS shows clear direction and authorization. Executive management 
direction is linked to operational detail. Details are derived from documented informed-choice 
decision making. Measuring and monitoring ensure reasonable awareness of the information secu-
rity environment. Th is documented due diligence provides a defensible posture.
A standards-based ISMS allows extra defensibility through third-party validation such as cer-
tiﬁ cation to the ISO27001 information security management standard. Th is defensibility works 
whether one is a consumer or a source of information. Choosing to do business with an externally 
validated partner is a defensible decision.
Differentiator
An ISMS may serve as a market diﬀ erentiator, as well as enhancing perception and image. Market-
ing your information services to external information-sharing partners or clients requires a degree 
of conﬁ dence from all parties. Th e extra eﬀ ort of information security certiﬁ cation makes their 
decision defensible.




18  Information Security Management Handbook
Business Enabler
An ISMS may serve as an umbrella to cover several regulatory components simultaneously. Most 
relevant regulations deal with very speciﬁ c data types such as health or ﬁ nancial information. 
Controls deployed for one regulation, and managed by an overarching or blanket ISMS, typically 
meet the requirements of multiple regulations simultaneously. Most legal regulations also require 
demonstrable management of information security, something inherent in an ISMS. Th e potential 
legal and regulatory cost savings of an overarching ISMS are obvious.
An ISMS allows for, and generally is based upon, risk. Risk analysis and risk rating may 
serve as a fundamental justiﬁ cation for the selection and deployment of controls that populate 
the ISMS. A risk-based ISMS, such as required by the ISO27001 standard, allows for business to 
accept risk based upon informed-choice decision making. Th is ability to accept risk enables busi-
nesses to react to their environment, not someone else’s interpretation of their environment.
A standards-based ISMS oﬀ ers the basis for enhanced interoperability with information trad-
ing partners. Th e ISMS framework eases interfacing and is extensible to absorb future expansion 
or change. Standardized terminology facilitates communication.
Corporate policy
INFOSEC program
Infosec
service
Infosec
service
Infosec
service
Other programs
Other programs
Structure
An ISMS brings structure to the Information Security Program. With clear direction and autho-
rization, roles are understood. Deﬁ ned functions or services allow derivation of tasks that can be 
delegated. Metrics can be collected and analyzed, producing feedback for “continuous process 
improvement.”
In many situations, creation of an ISMS inspires and spawns complementary management 
systems in other disciplines such as human resources, physical security, business continuity, 
and more. Th e framework and management system principles transcend disciplines and tend to 
enhance multidisciplinary interoperation.
Board
Executive staff
Management
Operations
Vision
Strategy
Tactics
Detail

Understanding Information Security Management Systems  19
Who Participates in an ISMS?
An ISMS transcends an organization from the board room to the data center. Th ere are typically 
three organizational layers with four very distinct audiences.
Board
Th e board of directors typically provides the organizational vision and guiding principles in 
response to managing risk on multiple fronts, from regulatory compliance to ﬁ duciary responsi-
bility. Th e board of directors participates in the ISMS through empowerment. Th is empowerment 
or authorization is a strategic control in response to risks such as regulatory noncompliance and 
ﬁ duciary irresponsibility.
Executive Staff
Senior executives are the typical owners of programs that would be managed by a management 
system. Management systems enhance an organization’s horizontal and vertical integration and 
visibility. Senior executives participate in the ISMS through deﬁ nition and provision of services to 
the enterprise by the program, such as incident management.
Management
Directors manage the tactics required to provide the program services. In a process-based ISMS, 
program services are provided by a collection of complementary and integrated processes. Directors 
participate in the ISMS through the deﬁ nition, execution, and ongoing improvement of these 
relevant information security processes, such as contain, eradicate, restore.
Operations
Managers implement the program on an operational level. Th e ISMS will generate standardized 
methodologies and requirements, codiﬁ ed in organizational process and standards. Managers par-
ticipate in the ISMS through integration of people, procedure, and technology in response to these 
organizational directives.
Domain
implementation
Domain
implementation
Corporate policy
INFOSEC program
Enterprise baseline
controls
Domain
implementation

20  Information Security Management Handbook
Where Does an ISMS Live?
An ISMS lives within an organization from the board room to the production ﬂ oor, each strata 
addressing a diﬀ erent need.
Enterprise
At the enterprise level the ISMS lives in the form of a minimum enterprise information secu-
rity baseline created in direct response to the enterprise information security risk addressed by 
upper management. Th e enterprise information security baseline typically consists of enterprise 
information security standards, processes, and roles or responsibilities. Risk acceptance for 
nonconformance to the information security baseline has enterprisewide information security 
signiﬁ cance.
Information Security Domains
At the operational level, an ISMS lives in multiple places and instances, based upon functional 
areas, or information security domains. A typical information security domain may be a data 
center, oﬃ  ce area, or reception area, each with a unique security proﬁ le. Information security 
domains serve as the basis for enterprise information security baseline implementation. Each 
domain is autonomous in how it tailors the enterprise information security baseline requirements 
to its unique environment.
How Is an ISMS Built?
An ISMS is typically risk based and process oriented. Th ere may be multiple layers of abstraction 
to accommodate the distinct audiences whose concerns must be addressed. Th e ISO27001 stan-
dard recommends a Plan, Do, Check, Act process-based approach deﬁ ned as
Plan. Establish the ISMS
Understand the environment
Assess enterprise risk
Charter Information Security Program
Assess program risk
Do. Implement and operate the ISMS
Create enterprise information security baseline
Create domain-speciﬁ c implementations
Check. Monitor and review the ISMS
Assess operational risk
Act. Maintain and improve the ISMS
Measure and monitor

Understanding Information Security Management Systems  21
Quantified risk
Control objective
Enterprise    controls
Directive
Process
Responsibility
Domain    controls
Specification
SOP
Duty
Do
Plan
Metrics
Reports
Act
Check
Understand the Environment
Th e structure and the content of the ISMS must take into account the management environment 
to be successful. Organizational considerations will inﬂ uence the ISMS framework. Cultural 
sensitivities may change usage of terminology. Regulatory requirements will certainly inﬂ uence 
approach, contents, and packaging.
Assess Enterprise Risk
Enterprise risk is usually assessed and addressed through upper management directives such as cor-
porate policies. Th e assessment of high-level enterprise risk, such as regulatory compliance and ﬁ du-
ciary responsibility, is inherently understood and intuitively addressed. Upper management directives 
serve as the authorization and empowerment of the supporting enterprise risk-mitigating programs.
For example,
A corporate behavioral or acceptable-use policy empowers proactive behavioral training as 
well as reactive behavioral detection mechanisms.
Corporate administrative policy empowers eﬃ  ciency initiatives supported by operational 
metrics and continuous process improvement.
Corporate legal or regulatory policy establishes nonnegotiable requirements embedded as 
controls within the ISMS.
Charter Information Security Program
Th e Information Security Program is the organizational entity authorized and empowered to create 
and maintain the ISMS to oﬀ er the enterprise the services required to meet corporate policy goals. 




22  Information Security Management Handbook
Th e Information Security Program not only oﬀ ers services, but also requires externally provided 
services to maintain program eﬀ ectiveness. An example program dependency may be a human 
resource department that performs background checks for the Information Security Program. 
A program charter may serve as a vehicle to document the authorization and empowerment, as 
well as documenting and acknowledging the mutually recognized program dependencies.
Assess Program Risk
Program risk serves as the basis to select controls managed by the ISMS. Some program risk has 
been analyzed and addressed by others who believe they know the practitioner’s environment 
better than the practitioner, resulting in binding regulations. Some program risk is obvious and 
intuitive, such as the risk of unpatched information processing systems. Other program risk is 
more insidious, such as aggregation, when individual inconsequential risks combine to produce 
risk disproportionate to the sum. For example,
Th ere is no ﬁ rewall between Department A and Department B. Th is is rated a minor risk 
and has been accepted by both departments.
Department B then deploys a Web server. Th e risk of opening Hypertext Transfer Protocol 
port 80 through the Department B external (Internet facing) ﬁ rewall is deemed a minor risk 
and has been accepted by Department B.
Department A’s previously isolated network segment is now no longer isolated.
A minor risk accepted by Department B caused an unknown risk acceptance by Department A. 
Th ere is now an unrecognized major enterprise risk.
An ISMS serves as the vehicle to coordinate the management of risk and risk-mitigating controls. 
Identiﬁ ed risks are quantiﬁ ed and control objectives assigned. Control objectives serve as the glue 
that justiﬁ es and binds each risk to its respective control. Th e satisfaction of control objectives is 
prioritized by the risk quantiﬁ cation.
Create Enterprise Information Security Baseline
An enterprise information security baseline serves as a common minimum information security pos-
ture for the enterprise. Th is in turn serves as the basis for trust between operational areas or domains 
because they all are required to meet this minimum baseline, which may be exceeded as required.
Directives
Directives are controls that deﬁ ne hard and measurable requirements. Directives may be derived 
from legislation, from industry standards and practices, or in response to risk. Directive controls 
are typically codiﬁ ed in a suite of standards, with the content based upon informed-choice deci-
sion making. Care must be taken in the crafting of the directives because informed-choice decision 
making implies a degree of risk acceptance. Th at which is not addressed is by default accepted.
Methodologies
Methodologies are controls that deﬁ ne measurable and repeatable processes. Methodologies may 
be derived to meet the requirements of directives or may be part of a suite of processes that provide 
a program service. Methodologies are typically codiﬁ ed as a process ﬂ ow. Care must be taken in 





Understanding Information Security Management Systems  23
crafting process ﬂ ows to ensure that the process can be measured and monitored. Th at which can-
not be measured cannot be improved.
Responsibilities
Clear assignment of responsibilities is a control that binds a role to an activity. Activities may be 
derived to meet the requirements of directives and may be performed by executing a methodol-
ogy. Responsibilities are typically codiﬁ ed via functional role deﬁ nitions. Care must be taken 
when deﬁ ning functional roles to ensure that role-assigned responsibilities are supported by role-
required authorizations and qualiﬁ cations. Th ose assigned responsibility must have the requisite 
authorization, qualiﬁ cations, and resources.
Create Domain-Speciﬁ c Implementations
Speciﬁ cations
Speciﬁ cations are domain-speciﬁ c operational controls that deﬁ ne hard and measurable details 
such as conﬁ gurations or attributes. Speciﬁ cations are derived from enterprise information secu-
rity standards, with each domain potentially deriving unique interpretations for a common stan-
dard, dependent on each unique environment. Th is allows a degree of autonomy in execution. 
Care must be taken when deriving speciﬁ cations to ensure domain-speciﬁ c interpretations; while 
meeting the spirit and intent of the parent standards, do not cause interdomain incompatibility. 
To preclude introduction of unidentiﬁ ed risk, speciﬁ cations must meet the spirit and intent of the 
parent standard.
Procedures
Standard operating procedures are controls that deﬁ ne measurable and repeatable work instruc-
tions. Standard operating procedures are derived from enterprise information security processes, 
with each domain potentially deriving unique interpretations dependent on each unique environ-
ment. Th is allows a degree of autonomy in execution. Care must be taken in deriving standard 
operating procedures to ensure parent process attributes are preserved. Th e execution of domain 
standard operating procedures is the basis of enterprise information security services.
Tasks
Tasks are activities assigned a functional role executing a standard operating procedure. Tasks are 
domain-speciﬁ c and schedule-driven, with frequency of execution based upon risk. Individuals 
executing tasks while ﬁ lling a role are performing their employment duties. Performance of duty is 
an employee metric. Care must be taken when scheduling tasks and assigning duties to ensure the 
schedule is defensible and the individual competent. Tasking is an employee performance metric.
Assess Operational Risk
Operational risk is based upon the risk that a domain will not be able to meet its enterprise 
information security baseline-derived obligations, such as speciﬁ cations, procedures, and sched-
uled tasks. Th is risk is many times resource-driven, putting a risk justiﬁ cation to budgeting. 

24  Information Security Management Handbook
Acceptance of operational risk may change residual program risk, and aggregation may cause this 
program risk to rise to an unacceptable level.
Measure and Monitor
Measuring and monitoring are the feedback mechanism required for continuous process improve-
ment. What to monitor and how to measure require well-deﬁ ned metrics. Typical domains will 
obtain multiple varieties of metrics.
Environmental Metrics
Environmental metrics are based upon the surroundings. Th e focus is on identifying the enter-
prise’s risk proﬁ le. Industry groups are a consideration. Banking and ﬁ nancial services may, for 
example, attract highly motivated attackers. Level of organizational sophistication may inﬂ uence 
the risk level. An ISO27001-certiﬁ ed domain may, for example, have a lower perceived risk level. 
Location may become a factor inﬂ uenced by crime rates or ﬁ re response times. Risk proﬁ les aﬀ ect 
probability. Th is can be utilized to inﬂ uence risk ratings in the vulnerability management process. 
For example, the probability of a speciﬁ c vulnerability being exploited at a bank is perhaps higher 
than at a home user site because of attacker motivation and targeting. Consideration should be 
taken to weighting risk and response based upon these environmental metrics. Another focus for 
environmental metrics is to establish an information security frame of reference or threshold. 
Intrusion sensors, for example, utilize environmental metrics to establish detection noise baselines 
and thresholds.
Program Metrics
Program metrics are based upon eﬀ ectiveness. Th e focus is on validating that the ISMS is success-
fully providing the services that justify its existence. Consider vulnerability management. Th is 
ISMS service measures eﬀ ectiveness, for example, not by how rapidly a vulnerability can be identi-
ﬁ ed and processed (eﬃ  ciency). Vulnerability management eﬀ ectiveness is measured by how many 
vulnerabilities were never identiﬁ ed or fully processed.
Process Metrics
Process metrics are based upon eﬃ  ciency. Th e focus is on ﬁ ne-tuning procedures to maximize 
performance. Consider a vulnerability tracking process. Th e acquisition of new software may, for 
example, decrease the “time to resolve,” thus improving metrics eﬃ  ciency.
When Does an ISMS Protect?
An ISMS protects by degrees.
Responsibility
Owner
Focus
Degree of assurance
Program management
Program risk
Degree of maturity
ISMS management
ISMS process
Degree of implementation
Project management
People, procedure, and technology

Understanding Information Security Management Systems  25
Degree of Assurance
In a risk-based ISMS, the risk assessment process is an integral part of the feedback loop that pro-
vides continuous process improvement. Because risk can never be completely eliminated, a com-
promise is sought by which residual risk has been reduced to an acceptable level. Th is is known 
as degree of assurance. Th e Information Security Program is a risk management tool. From the 
program perspective, the ISMS protects when risk has been reduced to an acceptable level.
Th e important question is how to deﬁ ne this “acceptable level” threshold. Degree of assur-
ance implies a level of risk acceptance, but risk may be scattered throughout the ISMS. Th is may 
preclude a straightforward assignment of risk acceptance authorization. An ISMS, by nature of 
its structure, recognizes the need to delegate risk acceptance as well as taking into consideration 
aggregate risk.
Degree of Maturity
A process-based ISMS is conducive to maturity modeling, because processes by deﬁ nition should 
produce feedback metrics that enhance the maturation of the process. Maturity modeling scales, 
such as seen in the Capability Maturity Model schemas and others, serve as a common language 
with consistent deﬁ nition of scale. Th e desired degree of maturity is hence bound to the maturity 
scale selected, as well as to the speciﬁ c process under evaluation. A defensible degree of maturity is 
based upon informed choice. Processes may vary in their acceptable degree of maturity, dependent 
on external factors such as risk. Nevertheless, the ISMS protects as its processes reach the desired 
degree of maturity.
Degree of Implementation
Degree of implementation is tied to operations and project management. Information security 
projects at the operational level are tied to speciﬁ c operational areas, or security domains. Th ese 
projects deploy domain-speciﬁ c controls in response to domain-speciﬁ c risk, aggregating to raise 
the enterprise degree of assurance. On project completion, degree of implementation is complete, 
and the control is now bound to degree of maturity. Th e ISMS protects as people, procedure, and 
product integrate into process.
Summary
Th e management system concept is being applied across many new disciplines. With the ratiﬁ ca-
tion of the ISO27001 standard, ISMS have achieved new prominence, in some arenas becoming 
a de facto requirement.
In conclusion, an ISMS
Integrates information security risk into enterprise risk management
Documents informed-choice decision making and due diligence
Provides a framework for regulatory compliance
Oﬀ ers a structure to integrate people, process, and technology eﬃ  ciently and eﬀ ectively
Furnishes a mechanism for monitoring and reporting
Is business friendly and a market diﬀ erentiator








Policies, Standards, 
Procedures, and Guidelines


29
Chapter 3
Planning for a Privacy Breach
Rebecca Herold
Contents
All Organizations Must Address Privacy Issues ......................................................................... 29
Incidents Occur Many Diﬀ erent Ways ...................................................................................... 30
Increasingly More Breaches Are Occurring ................................................................................31
Prevention Is Much Less Expensive Th an Response and Recovery ............................................ 32
Deﬁ ne Possible Privacy Breaches ............................................................................................... 32
Create Your Privacy Breach Response Plans ...............................................................................33
Deﬁ ne PII .........................................................................................................................33
Locate the PII ............................................................................................................................33
Create the Breach Response Plan .............................................................................................. 39
Plan Eﬀ ectively ................................................................................................................ 40
Know When a Privacy Breach Has Occurred ............................................................................41
Breach Notiﬁ cation ................................................................................................................... 42
Recovery ................................................................................................................................... 44
All Organizations Must Address Privacy Issues
Privacy is considered a basic human right in many parts of the world. Take, for instance, the EU 
Data Protection Directive (95/46/EC) requirements, “for the protection of the private lives and 
basic freedoms and rights of individuals.” Although privacy principles and laws have been around 
for well over a decade, it has been only in the past few years, as breaches have become an almost 
daily event, that organizations have started noticeably to address privacy challenges and dedicate 
the resources necessary to deal eﬀ ectively with the myriad of issues and requirements.

30  Information Security Management Handbook
Th e public is savvy with regard to privacy, much more now than it has ever been before in his-
tory. Organizations must address privacy, not only because they are legally required to do so, but 
also because customers demand it and it is just the right thing to do. Organizations must maintain 
privacy to maintain customer trust, maintain customer loyalty and support, and even improve 
corporate brand.
Organizations are starting to address some privacy issues, but there are still signiﬁ cant privacy 
breaches that increasingly more organizations experience. Organizations must prepare for addressing 
these privacy breaches so they can respond to them in the most eﬀ ective and eﬃ  cient way possible, 
minimizing not only negative business impact but also negative personal impacts to customers.
Incidents Occur Many Different Ways
Incidents can, do, and will continue to occur in a wide variety of ways. Th ese are not just the 
results of hackers or stolen computers, which are most widely reported, but also the results of mali-
cious intent from outsiders or insiders, mistakes made by those who handle personally identiﬁ able 
information (PII), and simple lack of awareness of what should be done to protect PII, along with 
other unique ways.
As examples, each of the following represents a unique type of privacy incident:
Canadian airline refuses customer access. In January 2007, the Canadian Privacy Commis-
sioner ﬁ led charges against a Canadian airline that refused to give a customer access to his 
personal information.
Cleveland clinic hospital employee theft. In September 2006, a former employee of Cleveland 
Clinic Hospital in North Naples and a relative who worked for a Naples-based health insur-
ance claims company were arrested and charged with stealing records of more than 1100 
patients.
Connecticut technical high school e-mail error. In March 2006, the Social Security num-
bers (SSNs) of the 1250 teachers and school administrators in the Connecticut Technical 
High School System were mistakenly sent via e-mail to staﬀ . Th e e-mail was sent to the 
system’s 17 principals to inform them about a coming workshop. Th e ﬁ le with the SSNs 
was attached to the e-mail by mistake. At least one principal then forwarded the e-mail to 
77 staﬀ  members without opening the attachment containing the SSNs.
DoubleClick cookie use. In 2000, a series of class action lawsuits were brought against Double-
Click for violation of privacy relating to the company’s cookie-tracking practices. In January 
2000, the stock for DoubleClick, Inc., was at about $135 per share. Following the privacy 
lawsuits around six months later, DoubleClick’s share price dropped to the mid-30s. On 
top of this was the settlement, which included implementing privacy protections, paying all 
legal fees, and paying up to $1.8 million.
Eckerd pharmacy use of PII for marketing. In July 2002, Eckerd had a practice of having cus-
tomers sign a form that not only acknowledged receipt of a prescription but also authorized 
the store to release prescription information to Eckerd Corp. for future marketing purposes. 
Th e court determined the form did not adequately inform customers that they were autho-
rizing the commercial use of their personal medical information.
Eli Lilly Prozac e-mail incident. In June 2001, Eli Lilly sent a message to 669 Prozac users 
who had voluntarily signed up for a prescription reminder service. Th e message header inad-
vertently contained visible e-mail addresses for all the recipients.







Planning for a Privacy Breach  31
Ernst & Young stolen laptop. In January 2006, a laptop was stolen from an Ernst & Young 
employee’s car. As a result of the theft, the names, dates of birth, genders, family sizes, SSNs, 
and tax identiﬁ ers for IBM employees were exposed.
Microsoft passport security. In August 2002, Microsoft agreed to settle Federal Trade Com-
mission (FTC) charges regarding the privacy and security of personal information collected 
from consumers through its “Passport” Web services. As part of the settlement, Microsoft 
had to implement a comprehensive information security program for Passport and similar 
services. Each subsequent violation of the order could result in a civil penalty of $11,000.
University of San Diego computer network hack. In November 2005, the University of San 
Diego notiﬁ ed almost 7800 individuals that hackers had gained illicit access to computers 
containing their personal income tax data. Th e compromised data included names, SSNs, 
and addresses.
University of Southern California programming error. In July 2005, a programming error 
in the University of Southern California’s online system for accepting applications left the 
personal information of as many as 280,000 users publicly accessible.
Ziﬀ  Davis Web site error. Because of how one of their Web pages was designed, a computer 
ﬁ le of approximately 12,000 subscription requests could be accessed by anyone on the Inter-
net. As a result, some subscribers incurred fraudulent credit card charges.
To plan eﬀ ectively to prevent, as well as respond to, privacy incidents, organizations must identify 
their potential privacy incidents and then address each of them individually.
Increasingly More Breaches Are Occurring
Th e more mobile PII becomes, being stored upon personal digital assistants (PDAs), laptops, and 
mobile storage devices and being accessed by people who work from home, work while traveling, 
or work for other companies, the more risk there is that the PII will fall victim to an incident.
Th e Privacy Rights Clearinghouse (PRC) logged 705 breaches that they had found reported 
in the news within the United States between February 15, 2005, and October 25, 2007. Th ese 
breaches cumulatively involved the information of over 168 million people. Attrition.org also keeps 
track of breaches, many of which are not on the PRC list. Th e author has also found many more 
breaches not on either list, and a very large number of incidents do not get reported in the news.
According to a Ponemon privacy breach study released in October 2006,* losses involving PII 
cost U.S. companies approximately $182 per compromised individual’s record. Th is was up from 
$138 per individual’s record in 2005. Considering that most breaches impact thousands of indi-
viduals, this is signiﬁ cant. Each of the 56 companies surveyed had $2.5 million in lost business as 
a result of each incident.
Privacy incidents involve much more than just the immediate cost of the incident. Th rough 
research with organizations that have experienced privacy incidents the author has found the 
subsequent and ongoing actual costs of internal investigations, external legal advice, notiﬁ cation 
and call center costs, investor relations, promotions such as discounted services and products, lost 
personnel productivity, lost customers, travel and lodging costs to bring business clients on site 
for assurance meetings, notiﬁ cations to individuals in other countries, increasing staﬀ , ongoing 
* http://www.computerworld.com/pdfs/PGP_Annual_Study_PDF.pdf






32  Information Security Management Handbook
auditing and documentation requirements, installing new systems and ﬁ xing old ones, and so on 
have a huge impact on an organization.
Prevention Is Much Less Expensive Than Response and Recovery
All organizations, of all sizes, in all industries, in all parts of the world, that handle PII are vulner-
able to experiencing a privacy breach. No organization is immune.
Organizations must be prepared to respond to privacy-related incidents. Information security 
and privacy areas must work together following a comprehensive well-thought-out and tested 
breach response plan to be eﬀ ective.
Your organization must understand when you are required to notify the aﬀ ected individuals. As 
of October 2007 there were 40 states including the District of Columbia with privacy breach notice 
laws. Th ere are pending U.S. federal breach notice bills. Th ere are pending proposed laws throughout 
the world, such as in Canada and the European Union. If you live in some remote part of the world 
where there is no breach notice law protecting your customers, do not wait until you legally must 
address privacy and how to respond to breaches. You will have to address this issue sooner or later.
When planning for a privacy breach:
 
1. Deﬁ ne the possible privacy breaches
 
2. Create plans for the privacy breach
 
3. Know when a privacy breach has occurred
 
4. Know when notiﬁ cation is necessary
 
5. Continue recovery activities following a breach
Deﬁ ne Possible Privacy Breaches
You must know what a privacy breach is before you can plan how to identify when a privacy 
breach has occurred and how best to respond to it. Th ere are many diﬀ erent kinds of potential 
privacy breaches. Most of these overlap with and are part of information security incidents, high-
lighting the need for privacy and information security practitioners to work together to address 
privacy breaches.
Some of the types of privacy breaches that organizations have experienced include, but are not 
limited to, the following:
Unauthorized access to e-mails and voicemails
Receipt of unsolicited e-mails that can be considered spam
Unauthorized access on borrowed or loaned computers
Unauthorized access to work areas
Illegal use of SSNs
Inappropriate access to the network or computer systems
Lost or stolen computers, such as laptops, PDAs, and so on
Lost or stolen computer storage media
Mistakes that leave information vulnerable
Dishonest authorized insiders inappropriately using PII
E-mail messages with conﬁ dential information sent or forwarded inappropriately












Planning for a Privacy Breach  33
Fraud activities perpetrated by outsiders, insiders, or both
Hackers gaining unauthorized access to the information
Information exposed online because of inadequate controls
Conﬁ dential paper documents not being shredded and being given to people outside the 
organization (e.g., recycled)
Improper disposal
Password compromise
Customer or employee angry with privacy practices
Create Your Privacy Breach Response Plans
Now that you have identiﬁ ed the situations through which privacy can be breached, you need to 
create your privacy breach response plans. Th e ﬁ rst, fundamental, action in creating your plan is 
to identify the PII items that your organization handles. You cannot know if a privacy breach has 
occurred unless you know what PII exists and where it is located.
Deﬁ ne PII
Th ere is no one universal deﬁ nition for what constitutes PII. Th e author has analyzed over 90 
worldwide laws and found at least 47 diﬀ erent and uniquely named items that are considered PII 
as indicated in Table 3.1. Identify the data protection and privacy laws that apply to your organi-
zation and document the PII items.
Locate the PII
You cannot know if PII has been breached if you do not know where it is located. A critical com-
ponent of privacy breach prevention and incident response is locating and documenting where PII 
exists throughout your organization.
In the course of a business day, organizations collect PII in many diﬀ erent ways. Much of this 
information is in the form of unstructured data (generally data under the control of end users, 
such as within Word ﬁ les, Excel ﬁ les, e-mail messages, and so on). Be comprehensive in your 
identiﬁ cation of PII storage locations. Do not forget about those often overlooked and seemingly 
innocent storage areas where massive amounts of PII could be hiding. Map out how the PII ﬂ ows 
throughout the organization.
Following are some high-level steps for locating PII:
 
1. Identify all applicable laws and regulations
 
2. Identify and document all types of PII referenced within the laws and regulations
 
3. Document all types of PII within contracts and Web site privacy policies
 
4. Create an inventory of all PII used within the organization
 
5. Identify and document where PII is collected throughout the organization
 
6. Identify and document where PII is stored and accessed throughout the organization
 
7. Identify and document all points at which PII leaves the organization
Th ere are many diﬀ erent ways in which you can document your PII data ﬂ ow. For example, the 
U.S. Transportation Security Authority (TSA) represented their PII data ﬂ ow with a somewhat 








34  Information Security Management Handbook
Table 3.1 Laws Deﬁ ning PII
Personal Information Item
Law or Regulation
HIPAA
COPPA
SB 1386
GLBA
EU 
Directive
Privacy Act 
of 1974
Drivers
FOIA
PIPEDA
Misc.
First name or initial
X
X
X
X
X
X
X
X
Xa
X
Last name
X
X
X
X
X
X
X
X
Xa
X
Geographic subdivisions 
smaller than a state 
(mailing address)
X
X
X
X
X
Xb
X
Xa
X
Dates (excluding year 
for HIPAA)
X
X
X
X
X
 Birth
X
X
X
X
X
X
X
 Admission
X
X
X
X
 Discharge
X
X
X
X
 Death
X
X
X
X
X
Telephone number
X
X
X
X
X
X
X
Xc
X
Fax number
X
Xb
X
X
X
X
Xc
X
E-mail address
X
X
X
X
X
X
Xc
X
SSN
X
X
X
X
X
X
X
X
X
Medical records numbers
X
X
X
X
X
X
X
Health plan beneﬁ ciary 
numbers
X
X
X
X
X
X
Account numbers
X
X
X
X
X
License and certiﬁ cate 
numbers
X
X
X
X
X
X
Vehicle identiﬁ ers (such as 
license plate number)
X
X
X
X
X
X
X
Credit card number
X
X
X
X
X
Debit card number
X
X
X
X
X
California ID number
X
X
X
X
Device identiﬁ ers (such as 
serial numbers)
X
X
X

Planning for a Privacy Breach  35
Universal resource locaters 
X
X
X
Internet Protocol address
X
X
X
Biometric identiﬁ ers (such 
as DNA, iris-, ﬁ nger-, and 
voiceprints)
X
X
X
X
X
X
Full-face photographic 
images (and any 
comparable images)
X
X
X
X
X
X
X
Other unique identiﬁ ers 
that can be attributed to
a speciﬁ c individual
X
X
X
X
X
X
Medical care information, 
such as organ donations, 
medications, and disability 
information
X
X
X
X
X
X
Any other identiﬁ er that the 
FTC determines permits 
the physical or online 
contacting of a speciﬁ c 
individual
X
X
X
Information concerning
a child or parents of that 
child that a Web site 
collects online from the 
child and combines with 
one of the above 
identiﬁ ers
X
X
Body identiﬁ ers 
(tattoos, scars)
X
Xb
X
X
Employment history
X
X
X
X
(continued )

36  Information Security Management Handbook
Table 3.1 (continued)
Personal Information Item
Law or Regulation
HIPAA
COPPA
SB 1386
GLBA
EU 
Directive
Privacy Act 
of 1974
Drivers
FOIA
PIPEDA
Misc.
Income
X
X
X
X
Payment history
X
X
X
Loan or deposit balances
X
X
X
Credit card purchases
X
X
X
Criminal charges, 
convictions, and court 
records
X
X
X
X
Military history
X
X
X
Credit reports and credit 
scores
X
X
X
Existence of customer 
relationship
X
X
Financial transaction 
information
X
X
X
Merchandise and product 
order history
Xb
X
X
Service subscription history
X
Fraud alerts
X
X
X
“Black box” data
X
Video programming activity 
information
X
Voting history
X
X
X
Conversations (recorded or 
overheard)
X
X
Xb
X

Planning for a Privacy Breach  37
Descriptive listings of 
consumers
X
X
Education records
X
X
X
Personnel ﬁ les
X
X
Often, combinations of more than one piece of information create PII. The following, typically when combined with an element from the 
above list, are also considered PII. Additionally, these are often considered “sensitive,” “protected,” or “conﬁ dential” information.
 Racial or ethnic origin
 Political opinions
 Religious or philosophical beliefs
 Trade-union membership
 Health or sexual activity information
 Marital status
 Security code
 Access code
 Password
a Does not include the name, title, business address, or telephone number of an employee of an organization.
b Although this law does not explicitly list this item, it is possible that using this item could be considered a violation of the law because the law 
is written in such a way that it is vague or leaves things open to interpretation. It could depend upon the judge or jury and the other policies, 
contracts, and documents the organization has published or provided.
c But not the ﬁ ve-digit ZIP code.
Note: HIPAA, Health Insurance Portability and Accountability Act; COPPA, Children’s Online Privacy Protection Act; California SB 1386; GLBA, 
Gramm– Leach– Bliley Act; EU Data Protection Directive (Personal data is deﬁ ned very broadly as any “information relating to an identi-
ﬁ ed or identiﬁ able natural person [data subject]. An identiﬁ able person is one who can be identiﬁ ed, directly or indirectly, in particular 
by reference to an identiﬁ cation number, or to one or more factors speciﬁ c to his physical, physiological, mental, economic, cultural or 
social identity.”); The Privacy Act of 1974 (amended); Drivers Privacy Protection Act; FOIA, Freedom of Information Act; Canada’s Personal 
Information Protection and Electronic Documents Act (PIPEDA); Miscellaneous other laws.

38  Information Security Management Handbook
Figure 3.1  TSA PII data ﬂ ow diagram (http://www.dhs.gov/xoig/assets/mgmtrpts/Privacy_
pia_afs.pdf).
TSA performs preliminary adjudication using government
databases.
Candidate submits biographical data to TSA and TSA assigns a unique identification number via
www.flightschoolcandidates.gov. If data is incomplete candidate receives instructional email. Flight
Training Provider (FTP) verifies candidates training request via Web site.
TSA forwards data to Clearinghouse along with
candidate unique identification number.
Candidate and FTP receive email notification of
approval. Candidate may apply for new or
change current visa. Candidate locates
fingerprint collection location via direction from
Web site.
Appropriate governmental, law enforcement, and intelligence
agencies notified.
Candidate submits fingerprints at U.S. or overseas collection
location. Collection expenses paid by candidate.
Clearinghouse processes fingerprints and forwards to TSA.
TSA receives fingerprints and forwards notification email to FTP and training provider or receipt.
TSA performs final adjudication using outside agency provided data.
Candidate and FTP receive electronic notification email. Candidate
begins training.
Appropriate government, law enforcement, and intelligence
agencies notified
approval
approval
denial
denial
AFSP DATA Flow*
*This chart accurately reflects the data flow for all categories of candidates with the following exceptions:  
There is no preliminary approval for Category lll Candidates, and Category IV Candidates receive only  
notification of application receipt and will not undergo a security threat assessment.

Planning for a Privacy Breach  39
unusual ﬂ owchart as shown in Figure 3.1. However, it provides the documentation to show where 
PII is collected, where it goes, and where it is stored.
Another type of PII data ﬂ ow that provides more meaningful information is shown in 
Figure 3.2. Th is is from Miami–Dade Transit.*
Use the method for documenting your PII data ﬂ ow that works best for your organization.
Create the Breach Response Plan
Now that you know the types of breaches possible, the PII you handle, and all the locations for the 
PII, create the incident identiﬁ cation and response plans. Coordinate with and incorporate plan 
actions with the information security incident response plan. If you do not, you will either have 
gaps that can defeat your response eﬀ orts or have conﬂ icting activities occurring within diﬀ erent 
parts of your organization that will likely lead to unsatisfactory response results.
Ensure your plan takes into consideration intrusion detection systems (IDSs). Ensure the IDSs 
are used and conﬁ gured in the most eﬀ ective way so that as many of the types of privacy breaches 
that you have identiﬁ ed as possible will be ﬂ agged.
* http://www.miamidade.gov/transit/library/pdfs/reports/MDTFinalReportTechnicalAppendixA_1.19.2004_
jfmB2.pdf.
Figure 3.2 TSA PII data ﬂ ow diagram.
Safety & security
Safety & security
Metrobus,
metrorail,
metromover
Metrobus,
metrorail,
metromover
Core data
Service
implementation
Internal
infrastructure
SC_and_Employee_Id
Employee_job_category
Actual_operator_time;
Workforce_performance
Pick, roster, vacation, extra boards
Actual_operator_assignment
Scheduled_roster
Scheduled_operator_assignment
Actual_roster
Actual_vehicle_assignment
(end to end control)
Pre-Inspection_form
Incident_report
Actual_operator_vehicle_assignment
Lookup
(e.g., vehicle history)
Vehicle_availability
Vehicle_availability_with_APC
(End to end control)
Work_order_request
Orboard_msg (Location_msg
Incident_msg
AVM_msg
RTT, PRTT, Alarm)
Work_order_report_for_corrective_maint;
Work_order_report_for_scheduled_maint;
Hierarchy_configuration;
AVM_data
Special_events_schedule
Pickup_and_dropoff_stops
Transit_vehicle_location_data
Transit_vehicle_schedule_performance
Workforce management
Bus dispatch
Bus operations
−CAD
Supervisor tools
Communications
Mover operations
Track and vehicle
sensors
(SCADA and automated
system control)
Load_archive_data
Archive
Rail dispatch
Rail operations
Garage (parking)
management
Maintenance
management (bus, rail,
mover, facilities)
Customer information
Asset management
Service management
To specific functions
(End to end control)

40  Information Security Management Handbook
Plan Effectively
Th e basic components of your privacy breach response plan include:
 
1. Receive notiﬁ cation of a potential privacy breach incident.
 
2. Information security and privacy oﬃ  ces work together to determine at the onset.
 
a. Th e type of incident, location, and people involved.
 
b. If PII is involved or likely to be involved.
 
c. Th e systems and other components involved.
 
d. Th e timeframe for when the incident occurred.
 
3. Notify the incident response team.
 
4. Determine whether the breach is ongoing, for example if a hacker is still accessing the data 
or systems. If so, determine whether the systems should be shut down or if activity should 
be logged and watched closely.
 
5. Determine if your organization has primary responsibility for the data (it is for your 
clients or customers) or if you obtained it from another company to perform services for 
them, for example, if you were contracted by another company to process or otherwise 
handle the data.
 
6. Immediately inform the owner of the aﬀ ected data about the breach.
 
7. Identify the obligations your organization has under its contract with the owner.
 
8. Fulﬁ ll those obligations.
 
9. Determine if you need to inform any law enforcement agency and, if so, determine which 
one(s).
 10. If your organization is the primary custodian of the data, determine the speciﬁ c types of 
data aﬀ ected and the associated individuals. Th is may require sophisticated forensics and 
could take a signiﬁ cant amount of time, but planning ahead for who will perform these 
actions will keep that time to a minimum.
 11. Determine the jurisdictions within which all impacted individuals reside.
 12. Identify the notiﬁ cation requirements for each of the jurisdictions.
 13. If just one of the notiﬁ cation requirements is met, plan to notify all impacted individuals. 
Even if you are not legally obligated to notify beyond those in the jurisdictions with the 
legal requirements, it is a best practice, and it is best for all your customers to do so.
 14. Determine the obligations and responsibilities your organization will have to the impacted 
individuals for such activities as credit monitoring, toll-free information lines, dedicated 
incident Web sites, expense reimbursement, and so on.
 15. Determine the content of the breach notiﬁ cations.
 16. Determine whether the associated state attorneys general or country privacy commissioner 
must be notiﬁ ed.
 17. Determine how to send and communicate any necessary notiﬁ cations and whether to use 
in-house personnel or to engage a third party to send notiﬁ cations.
 18. Send the notiﬁ cations.
 19. Remediate and update processes and procedures to help prevent the incident from occurring 
again.
 20. Monitor the ongoing impact of the breach and continue to answer impacted individuals’ 
questions and address concerns.

Planning for a Privacy Breach  41
As you create your breach response plans, keep in mind that the primary goals of incident han-
dling are to
Quickly control and minimize damage
Preserve evidence
Notify individuals if appropriate
Recover as soon as possible
Continue monitoring for downstream impact
Learn from the incident and make changes to help prevent similar incidents from occurring 
again
Do your documented plans support these goals?
Once you create the breach response plan, eﬀ ectively communicate it throughout your enter-
prise. Provide initial and ongoing training for the personnel who will actively be involved with 
breach response. Test the plans at least annually and whenever major changes are made within the 
organization.
Know When a Privacy Breach Has Occurred
Incidents may be reported from many diﬀ erent sources, such as
Personnel
Customers
Th e general public
Business partners
News media
Automated systems
Reports of a privacy breach can be made to many diﬀ erent areas, such as
Information security
Privacy
Human resources
Call centers
Technical support
Ensure your plan clearly speciﬁ es where privacy breach reports need to be routed and the posi-
tions responsible for privacy breach response coordination. Communicate this throughout your 
enterprise often and in various ways.
When a privacy breach is reported, it is critical to follow your documented breach response 
plans to ensure that they are addressed in the most eﬃ  cient and eﬀ ective manner, that those ﬁ ll-
ing breach response roles fulﬁ ll their speciﬁ c responsibilities, and that the response activities are 
followed consistently.


















42  Information Security Management Handbook
Breach Notiﬁ cation
Typically you will need to notify others when a breach occurs that involved PII. Within the 
United States as of March 1, 2007, there were 35 states with privacy breach notice laws as indicated 
in Table 3.2.
Table 3.2 U.S. Privacy Breach Notice Laws as of March 1, 2007
State Breach Notiﬁ cation Law
Effective Date
Arizona SB 1338
12/31/06
Arkansas SB 1167
8/12/05
California SB 1386
7/1/03
Colorado HB 1119
9/1/06
Connecticut SB 650
1/1/06
Delaware HB 116
6/28/05
District of Columbia 28-3852
7/1/07
Florida HB 481
7/1/05
Georgia SB 230
5/5/05
Hawaii SB 2290
1/1/07
Idaho SB 1374
7/1/06
Illinois HB 1633
1/1/06
Indiana HB 1101
7/1/06
Kansas SB 196
7/1/06
Louisiana SB 205
1/1/06
Maine LD 1671 
1/31/06
Maryland HB208 and SB194
1/1/08
Massachusetts HB4144
2/3/08
Michigan SB 309
6/29/07
Minnesota HF 2121
1/1/06
Montana HB 732
3/1/06
Nebraska LB 876
4/6/06
Nevada SB 347
1/1/06 (10/1/08 for
 mandatory encryption)
New Hampshire HB 1660
1/1/07
New Jersey A4001
1/1/06
New York S 3492, S 5827, and AB 4254
12/7/05
North Carolina SB 1048
12/1/05
North Dakota SB 2251
6/1/05
Ohio HB 104
2/17/06
Oklahoma HB 2357
6/08/06
Oregon SB583
10/1/07
Pennsylvania SB 712
6/20/06
Rhode Island HB 6191
3/1/06
Tennessee HB 2170
7/1/05
Texas SB 122
9/1/05
Utah SB 69
1/1/07
Vermont SB 284
1/1/07 
Washington SB 6043
7/24/05
Wisconsin SB 164
3/31/06
Wyoming SF53
7/1/07

Planning for a Privacy Breach  43
Some of those you may need to notify could include the following:
Customers
Business partners
Telecommunications providers
State attorneys general
Regulatory oversight agencies, such as the FTC
Law enforcement
Software vendors
Internet Service Providers (ISPs)
News media
Other incident response teams
Owners of the source of the incident (such as if a network attack was launched from another 
company’s network)
Lawyers
Incidents can occur that do not involve an actual compromise of, or inappropriate access to, PII. 
However, if there is reasonable belief, as deﬁ ned by the multiple breach notice laws, that PII has 
been inappropriately accessed or compromised, you will need to notify the impacted  individuals. 
Create documented procedures to determine how to make these notiﬁ cations. Consider the 
 following notiﬁ cation methods.
Written notice. Send via postal mail or other similar delivery method considered dependable. 
Send to the individuals’ permanent home addresses. Include the cost of postage, envelopes, 
paper, and staﬀ  to assemble the letters within your overall breach response plans to ensure 
you have suﬃ  ciently budgeted for this activity.
Telephone notice. Individuals will appreciate and respond best to news of a breach using this 
method. However, this will also be one of the most time- and money-consuming methods of 
notiﬁ cation. Include the cost of staﬀ , phone charges, and varying times on the phone within 
your overall breach response plan.
Conspicuous posting of the breach notice on your Internet Web site. Th is should not be your 
primary means of notiﬁ cation, but it is certainly a great supplemental notiﬁ cation method.
E-mail notice. Even though some state-level laws list this as an acceptable notiﬁ cation method, 
avoid it if at all possible. Among the many reasons not to use e-mail notiﬁ cation are
Recipients may view it as another phishing message.
Spam ﬁ lters may delete it before it gets to the recipient.
If it is a shared e-mail address, as many family e-mails are, it is possible the message will 
never make it to the intended individual if another family member deletes it ﬁ rst.
E-mail addresses often are checked or used for a very short period of time; you may have 
many e-mail addresses that are no longer used.
Notiﬁ cation to major statewide or nationwide media. Th is is another method to use as a 
supplement to a method that contacts each individual directly.
Within your breach response plan, document the type of information to include within the noti-
ﬁ cation message. Also document how quickly notiﬁ cation needs to be made following discovery 
of the breach.
Generally if notiﬁ cation is necessary it should occur as quickly as possible and account for the 
time necessary to determine the scope of the breach and restore the security and integrity of the 
















−
−
−
−


44  Information Security Management Handbook
data system, along with provisions for potential law enforcement, investigation, and homeland 
security-related delays. A suggested best practice is to provide notiﬁ cation no later than 45 days 
after the date on which the privacy breach was discovered. Not only do many privacy lawyers 
recommend this timeframe, but at least two state-level breach notice laws (Ohio and Florida) 
speciﬁ cally require notiﬁ cations to occur within this timeframe.
It is important you create your breach response plans with all the state breach notice laws in 
mind; they are all diﬀ erent. For example, the Illinois law does not allow any extra notiﬁ cation 
delays for law enforcement purposes.
Recovery
Continue breach recovery activities following your immediate breach response activities. If sys-
tems were compromised and led to the breach, eliminate all means of continued intruder access.
 Do such things as follows:
Restore programs from trusted vendor-supplied media
Restore data from trusted backups
Install appropriate patches or ﬁ xes
Modify accounts and passwords as needed
Monitor systems for further attacks
Modify systems and procedures to prevent subsequent incidents
Identify lessons learned and implement improvements. To do this eﬀ ectively you must carefully 
document response actions and track certain metrics. For example,
Assess time and resources used and damage incurred. Th e author has identiﬁ ed at least 40 
diﬀ erent types of costs involved with privacy breaches.*
Document commands, code, and procedures used in response activities. Update your 
response plan documentation as necessary.
Conduct a postmortem review and investigation to prevent a similar incident from recurring 
if at all possible.
Document all ﬁ ndings and lessons learned and incorporate into a privacy breach report for 
your executive business leaders.
Do not stop responding to the incident once you have determined the incident has been resolved.
Continue postincident monitoring and updating your personnel, business partners, and cus-
tomers as appropriate about the incident.
Continue monitoring inquiries, and ensure the responses are handled consistently.
Handle returned breach notiﬁ cation letters appropriately and consistently. Determine what 
actions to take for those individuals whose letters were returned.
Modify incident response plans as needed, including the portions of the information secu-
rity incident response plans.
Implement improvements to information security policies, procedures, and measures.
Modify applications and systems as needed. Provide targeted training and ongoing awareness.
* See the author’s Privacy Management Toolkit: http://www.informationshield.com/privacy_main.html.

















Risk Management


47
Chapter 4
Using Quasi-Intelligence 
Resources to Protect 
the Enterprise
Craig A. Schiller
Contents
Background .............................................................................................................................. 48
Identifying the Kinds of Information an Enterprise or University Should Try to Gather ...........52
External Sources ........................................................................................................................52
Places or Organizations Where Public Information Can Be Found ..................................52
Research and Education Networking–Information Sharing
and Analysis Center .................................................................................................53
Shadowserver ...........................................................................................................53
Bleeding Th reat ...................................................................................................... 54
Castlecops.com or Phishing Incident Response and Termination ........................... 54
CYMRU ..................................................................................................................55
Inﬁ ltrated.net ......................................................................................................... 56
Spamhaus ............................................................................................................... 56
Internet Crime Complaint Center .......................................................................... 56
National Cyber-Forensics and Training Alliance .................................................... 57
Internet Security Operations Task Force ................................................................. 57
Membership Organizations ............................................................................................. 57
Conﬁ dentiality Agreements ............................................................................................. 58
Th e Role of Intelligence Sources in Aggregating Enough Information
to Make Law Enforcement Involvement Practical ............................................................ 58

48  Information Security Management Handbook
Internal Sources .........................................................................................................................59
What Do You Do with the Information When You Get It? .......................................................59
Counterintelligence: Th e Next Step ...........................................................................................65
Summary .................................................................................................................................. 66
Th e times they are a changing
Bob Dylan
Background
Enterprises used to be able to handle the threats themselves. As the threats have grown in scope, 
they have grown beyond the boundaries of the enterprise.
In the beginning, battling malicious code was a desktop-only concern. Th e viruses attacked a 
single computer, our tools defended individual computers. Th e targets of viruses were ﬁ les or boot 
sectors of disks. At ﬁ rst our tools were integrity checkers that conﬁ rmed known goodness. Later 
we began to recognize bad code and created small signatures that we could count on to discrimi-
nate bad code from good. Th e use of antivirus programs was not widespread. During the time that 
signatures were being developed, several private databases (like Patricia Huﬀ man’s VSum) were 
used by information security professionals to recognize the signs of a virus infection.
Information security professionals compared observed behavior and characteristics with the 
database entries to determine if they matched a known virus. Using this method, the individual 
information security professional could ﬁ nd viruses for which no signatures had been developed. 
Information security professionals would use the database to search for entries that included the 
behavior or ﬁ les that they had observed. In this way they might recognize a virus even if no signa-
ture had been developed for this particular strain. Th e behavior was recognizable even if bits had 
been twiddled to avoid matching an existing signature. It was a heuristic process that was later 
emulated in antivirus products.
As computers shifted from stand-alone systems to networked workstations, the primary mode of 
infection shifted as well, from ﬁ les, to e-mails, and then to network exploits against vulnerabilities. 
Th e number of viruses climbed, making it diﬃ  cult for individuals to keep up without the help of 
vendors.
Until the 1990s, enterprise security was largely performed in-house, with little apparent reliance 
on outside resources. Th at is, most threats of the day could be detected and responded to, in their 
entirety, within the boundaries of the company using packaged security products. With sensors 
(e.g., ﬁ rewalls) along the edge and antivirus (A/V) on the servers and desktops a company stood a 
pretty good chance of protecting itself from the threats. Even so, the Department of Energy and the 
Department of Defense realized as early as 1988 that some aggregation and distribution of threat 
information was needed and thus founded the computer incident advisory capability (CIAC) and 
Computer Emergency Response/Team Coordination Center (CERT/CC), respectively.
In the late 1990s, enterprise protection was extended through the use of intrusion detec-
tion and intrusion prevention tools. Th e image of self-reliance was an illusion. Th e threat of 
these early days was simple enough that intelligence gathering and aggregation of data could 
be packaged and delivered as commodities. Behind the antivirus software and intrusion detec-
tion system/intrusion prevention system (IDS/IPS) packages stood as an intelligence apparatus, 
harvesting security reports and converting them into neatly wrapped signatures and proﬁ les. 

Using Quasi-Intelligence Resources to Protect the Enterprise  49
Managed security services (MSS) began to appear. Soon after the introduction of MSS, vendors 
of these services began to oﬀ er the use of their aggregated clients’ experiences as an early warning 
to other enterprise customers. Th e products oﬀ ered alerts as well as IDS/IPS and ﬁ rewall rules 
created in response to new threats.
With the advent of malware driven by organized crime, the threat has evolved past three points 
of detection by signature or even single perspective heuristics.
Here is what Gartner’s Magic Quadrant recently said on the subject:
Traditional signature-based antivirus products can no longer protect companies from 
malicious code attacks. Vendors must execute product and business strategies to meet 
the new market requirements for broader malicious code protection.
Arabella Hallawell*
Even A/V vendors have come to the same conclusion, as evidenced by “New approaches to 
malware detection,” an article by Ellen Messmer in the April 30, 2007, issue of Network World. 
Th e article quotes Brian Foster, Symantec’s Senior Director for Product Management, as saying 
“Everyone agrees signature-based defense is not enough.” In the same article, Paul Moriarty, 
director of Internet Content Security for Trend Micro, said they were looking beyond the signature-
based approach, which “has utility but some limitations.” Trend Micro hopes to augment traditional 
signature-based technology with analysis of patterns of traﬃ  c to desktops or servers. Further, 
Trend Micro is looking at promising research regarding blocking traﬃ  c to Web sites whose 
domain names have existed for fewer than ﬁ ve days.
Th is is not to say that existing antivirus products should no longer be used. On the contrary, 
it is saying that existing A/V products must be augmented with information and products that 
address diﬀ erent aspects of the threat to be eﬀ ective. Increasingly malicious code authors are 
employing encryption, polymorphism, hide tools, and rootkits to avoid detection. If the attack 
vector is password guessing or brute force, then the bot-herder takes actions as a legitimate user. 
Th e ﬁ rst action one takes is to run a batch ﬁ le that turns oﬀ  antivirus products. In addition, more 
and more code is coordinated and controlled across the network.
All this adds up to a move toward the inclusion of intelligence information and the network 
perspective in detection. Table 4.1 provides a list of sources of malware information, a description 
of the data provided, and the security goal to which the information applies.
Th ere are now some attacks that involve no malicious code on the victim’s computer (man in the 
middle, pharming using domain name system [DNS] spooﬁ ng). Recently there have been signs of 
some botnet agents being controlled via terminal services or other remote control technologies rather 
than by a resident botnet client. Th ese may be using existing remote control software where avail-
able (Carbon Copy, virtual network computing [VNC], remote desktop protocol [RDP] terminal 
services, etc.). Th is has the advantage of creating botnet clients without the presence of betraying 
malware. If the bot-herder needs special code for a task, the code need exist only when it is needed 
(just-in-time malware). Th is reduces the detectable footprint both in size and in temporal range.
Sometimes the only evidence that a system is owned is data that is collected somewhere else. 
Sometimes the data is located on other systems owned by your organization. Other times the data 
is found on systems outside the organization.
* From Magic Quadrant for enterprise antivirus, January 2005: Vendors must address new malicious code threats, 
Feb. 22, 2005. www.gartner.com.

50  Information Security Management Handbook
Table 4.1 Categories of Intelligence Data Used against Malware
Type
Description
Security Goal
Community virus 
database
9/1/1998 (last known version); Patricia Hoffman’s 
VSum hypertext listing of viruses. Virus-L, 
virus.comp, Computer Virus Catalog; published 
by the Virus Test Center in Hamburg. The Wild 
List (http://www.wildlist.org/WildList/), vendor 
tables of virus information available from most 
A/V vendors.
Originally a database to help users ﬁ gure out which 
virus they had by comparing symptoms to the list of 
known virus characteristics. Today’s lists are merely a 
cross-reference of the polyphony of A/V vendor’s 
names for the same instance of a virus. Some vendor 
lists provide a fair amount of information. The 
vendor lists usually have limited search capability.
Speciﬁ c virus removal 
tools
1987; Two tools (immune and unvirus) created by 
Hebrew University, one to detect whether a 
computer had the Jerusalem virus, the other to 
remove it; more recently A/V companies have 
produced virus removal tools in response to 
speciﬁ c viruses, like Blaster.
Incident response to a virus attack, defensive, no 
intelligence value.
Integrity checkers
System ﬁ le checker (SFC), Tripwire
A method or tool for ensuring that static ﬁ les remain 
veriﬁ ably unchanged since their creation or 
installation. Similar technology is used today in 
communications protocols to ensure that messages 
received are unchanged during transmission.
Virus signature/proﬁ le 
checkers
Most A/V and IDS/IPS tools. A method for detecting 
and identifying a known virus that uses a small, 
unique pattern that is present in the virus. Issues 
occur when a pattern is discovered to be 
nonunique.
Contributes the identity of many viruses to the total 
intelligence picture.
Heuristics/anomaly 
detection
Most A/V and IDS/IPS tools. Heuristic methods ﬂ ag 
deviations from a model of acceptable behavior as 
anomalies. False-positives occur when acceptable 
anomalous behavior is not understood. False-
negatives occur when the model of acceptable 
behavior is ﬂ awed. An alternative to this approach 
is to catalog known unacceptable behavior.
Heuristic detection has the potential to detect 
previously unknown viruses.

Using Quasi-Intelligence Resources to Protect the Enterprise  51
Organic communication 
channels for notiﬁ cation 
of exploits
Abuse e-mail—e-mails sent to the organization’s 
published abuse e-mail address. Help desk trouble 
tickets informing IT of compromised hosts, reports 
of abuses, etc.
Identiﬁ es compromised hosts, Digital Millenium 
Copyright Act (DMCA) violations, spam relays, and 
failures of spam engines; collects miscellaneous 
abuse complaints from users. Systems identiﬁ ed 
here can be a potential source of intelligence 
information.
Enterprise A/V 
management tools
Central quarantine, central reporting.
Identiﬁ es compromised hosts.
External group 
notiﬁ cations
Network for Education and Research in Oregon, 
Recording Industry Association of America (RIAA), 
Home Box Ofﬁ ce (HBO). 
Identiﬁ es compromised hosts, DMCA violations, 
spam relays, and phishing Web sites.
Receiving intel from 
aggregating groups
Information Sharing and Analysis Centers (ISACs), 
Shadowserver.
Identiﬁ es C&C servers; alerts about near-time attacks, 
new vulnerabilities, technical and operational 
discussions from peers.
Gathering local 
intelligence
Workstation and server audit logs, ﬁ rewall logs, 
forensic examinations, Ourmon, Snort, CWSandbox, 
Fiddler, Google searches, darknets.
Identiﬁ es compromised hosts that are quiet or use 
undetectable communications techniques. Identiﬁ es 
intermediate participants in phishing attacks; 
discovers C&C servers and drop sites; discovers 
exploited Web sites used for spam, phishing, botnet 
activity. Discovers attack vectors and local botnet 
members. Detects and prevents botnets that others 
have seen. Interrupts communication with known 
C&C servers.
Sharing intel with 
aggregating groups
Phishing Incident Response and Termination, 
Internet Security Operations Task Force, 
Anti-Phishing Working Group, Research 
and Education Networking–ISAC
Community aggregation of reports, creating enough 
of a body of evidence that makes law enforcement 
participation worthwhile. Letting other companies 
and organizations leverage what you know. Greater 
effectiveness in taking down bad sites.

52  Information Security Management Handbook
Th e information in Table 4.1 can lead you to explore new sources of information, which may 
improve your ability to detect and respond to malware.
Identifying the Kinds of Information an Enterprise 
or University Should Try to Gather
Organizations need tools that can help detect or reveal botnets and other malicious code even 
when A/V tools report nothing. Th ey need insights into behaviors and components that can be 
used to conﬁ rm the presence, activity, or eﬀ ects of malware.
Th e value of these intelligence sources is that they may reveal botnet, phishing, or spam activity 
that local network sensors (collection eﬀ orts) may not see or do not report. Using these resources 
you can gain:
Knowledge of attacks by your own organization’s resources on others
Knowledge of attacks by other systems on your resources
Knowledge of attacks on other organizations similar to yours
Knowledge of attempts by your assets to communicate with known C&C servers
Lists of known C&C servers, ports, and channels
Results of aggregate data from honeynets, honeypots, and darknets across the Internet
Access to analysis reports on current threats
Access to analysis of individual instances of malware
Access to special tools or special collections of data
Access to detailed discussions of real uncensored events
Access to a professional community with similar security concerns
Access to bleeding edge IDS signatures
External Sources
Th ere are a myriad of sources of information on the various threats, so that it is necessary to choose 
the most relevant and applicable source.
Places or Organizations Where Public Information Can Be Found
Th ere are many organizations online where quasi-intelligence can be found. Unfortunately, there 
is no room to cover them all. Th e author has selected a representative sample of useful organiza-
tions. In your sector of the economy there will likely be similar organizations that will provide 
similar intelligence information.
In response to 9/11, the United States created several Information Sharing and Analysis Centers 
(ISACs), organized along critical infrastructure boundaries. Th e umbrella for these centers is called 
the ISAC Council (http://www.isaccouncil.org/). Th ere are ISACs that serve the communications, 
electricity, emergency management and response, ﬁ nancial services, highways, information tech-
nology, multistate, public transit, surface transportation, supply chain, water, and worldwide sec-
tors. Th ere is also an ISAC dedicated to Research and Education Networking (REN), with which 
the author is most familiar and which will be described more fully.













Using Quasi-Intelligence Resources to Protect the Enterprise  53
Research and Education Networking–Information 
Sharing and Analysis Center
REN–ISAC (http://www.ren-isac.net) is a cooperative organization for higher education and 
research institutes that was formally established in February 2003. REN–ISAC is one of many ISACs 
that were created in response to the needs of the Department of Homeland Security (DHS).
Th e goal of REN–ISAC (from the REN–ISAC Web page) is to
Develop a trusted community for sharing information regarding cybersecurity threat, 
incidents, response, and protection, speciﬁ cally designed to support the unique envi-
ronment and needs of higher education and research organizations. Th e trust com-
munity will provide a forum for sharing sensitive information, a source for trusted 
contact information, a meeting point for peers, a means to facilitate communications, 
and methods for improving cybersecurity awareness and response.
In addition to sharing information among members, REN–ISAC also has established sharing 
relationships with DHS, U.S.-CERT, other ISACs, private network security collaborations, and 
others. It also has relationships with Educause and Internet2. From the REN–ISAC Web site:
Th e REN-ISAC receives, analyzes and acts on operational, threat, warning and actual 
attack information derived from network instrumentation and information sharing rela-
tionships. Instrumentation data include netﬂ ow, router ACL counters, darknet monitor-
ing, and Global Network Operations Center operational monitoring systems.
REN–ISAC is a membership organization that requires vetting before access to forums and shared 
data is granted.
Shadowserver
Shadowserver is an organization of volunteers established in 2004. Th e mission of the Shadowserver 
Foundation is to “improve the security of the Internet by raising awareness of the presence of 
 compromised servers, malicious attackers, and the spread of malware” (from the Shadowserver 
Web site). From the Shadowserver Web site, the foundation meets its mission by
Capturing and receiving malicious software or information related to compromised 
devices
Disassembling, sandboxing, and analyzing viruses and Trojans
Monitoring and reporting on malicious attackers
Tracking and reporting on botnet activities
Disseminating cyber threat information
Coordinating incident response
Shadowserver Foundation is well organized, with teams established to focus on botnets, E-fraud, 
honeypots, malware, and tools (toyshop), as well as a management team. Criminal activity is 
reported to the appropriate authority.
Shadowserver provides a mailing list (http://www.shadowserver.org/mailman/listinfo/
shadowserver) that will send you a monthly update of the top command and control (C2) 







54  Information Security Management Handbook
servers sorted in various ways. Th ere are valuable white papers, a knowledge base, graphs, and 
links on the Web page. You can also report botnets directly on the Web page (http://www.
shadowserver.org/wiki/pmwiki.php?n=Involve.SubmitABotnet).
Until recently, the Shadowserver Web site provided a list of C&C IP addresses. Th is list has 
been taken down to prevent its use for malicious purposes. You can request access to the list by 
providing your full contact information as well as the purposes for which you require access to the 
data. Send the request to admin@shadowserver.org. If you do not have access to one of the vetting 
quasi-intelligence organizations, then this list is essential. You can use this list at the ﬁ rewall to 
detect internal botclients trying to communicate to their C&C servers or in your DNS to notify 
you of queries while preventing communication.
Th is list, formatted for use in Snort, can be found on http://www.bleedingthreats.net/index.
php/about-bleeding-edge-threats/all-bleeding-edge-threats-signatures/.
Bleeding Threat
Bleeding Th reat (www.bleedingthreats.net) was founded in 2003 by Matt Jonkman and James 
Ashton. At that time there was no central repository of open-source IDS proﬁ les. Security professionals 
had to subscribe to a number of mailing lists and make regular visits to several Web sites to ﬁ nd the lat-
est and best IDS signatures. To address that need, the primary project at Bleeding Th reat is the Bleed-
ing Edge Th reats Snort Ruleset. Th is project is staﬀ ed by expert information security volunteers.
Castlecops.com or Phishing Incident Response and Termination
CastleCops® is an essential resource in every security professional’s tool chest. Here is the mission 
statement from their Web site:
CastleCops® is a volunteer security community focused on making the Internet a 
safer place. All services to the public are free, including malware and rootkit cleanup 
of infected computers, malware and phish investigations and terminations, and search-
able database lists of malware and ﬁ le hashes.
Education and collaborative information sharing are among CastleCops high-
est priorities. Th ey are achieved by training our volunteer staﬀ  in our anti-malware, 
phishing, and rootkit academies and through additional services including Castle-
Cops forums, news, reviews, and continuing education.
CastleCops consistently works with industry experts and law enforcement to reach our 
ultimate goal in securing a safe and smart computing experience for everyone online.
Th e Web site has essential information for anyone trying to interpret the log ﬁ les of Hijack Th is 
(http://www.castlecops.com/HijackTh is.html). On the main Web page, the index items beginning 
with “O” and a number refer to a speciﬁ c section of the Hijack Th is log. Th e author has found 
forum participants on CastleCops to be very knowledgeable. Th e PIRT database is a primary intel-
ligence resource. Individuals can contribute suspected phishing e-mails to the database. Th e phish-
ing incident response and termination (PIRT) team is a community of volunteers dedicated to 
taking down phishing sites (as originally conceived by Robin Laudanski). An overview of the PIRT 
team can be found at http://wiki.castlecops.com/PIRT. Individuals who wish to report phishing 
e-mails or Web sites can e-mail the information to pirt@castlecops.com or the information can be 
entered directly into the Fried Phish tool.

Using Quasi-Intelligence Resources to Protect the Enterprise  55
PIRT handlers are selected based on an appropriate background. Th ey are trained in the 
use of the Fried Phish tools. New handlers work with mentors until the mentor is satisﬁ ed with 
the  quality of reports generated by the new handler. Reports from individuals are placed into a 
 suspected phish queue. Handlers conﬁ rm the report by gathering data about the reported phish, 
including retrieving the code from the suspected phishing Web site. Th ose that are validated are 
moved into a “conﬁ rmed phish” queue. Next, handlers attempt to contact either the server owner 
or the Internet Service Provider (ISP) in an eﬀ ort to terminate the phishing site. Successfully ter-
minated phishing sites are added to the “terminated phish” database. Th ere is very little chance of 
a false-positive surviving this process.
Veriﬁ ed phishing sites are shared with a long list of organizations. As of April 30, 2007, the 
list included the following:
1&1 Internet AG, 8e6 Technologies, Alice’s Registry, Anti-Phishing Working Group, 
APACS Security Unit, Arbor Networks, Australian Computer Emergency Response 
Team (AusCERT), Authentium, Blue Coat, Brand Dimensions, CERT/Software 
Engineering Institute/Carnegie Mellon University, ClamAV, Compete, Co-Logic, Con-
tentKeeper Technologies, CyberDefender, Cyveillance, EveryDNS, Federal Bureau of 
Investigation (FBI), Firetrust, For Critical Software Ltd., Fortinet, Forum of Inci-
dent Response and Security Teams (FIRST), FraudWatch International, IronPort, 
Infotex, Internet Crime Complaint Center (IC3), Internet Identity, Intellectual Prop-
erty Services, Korea Information Security Agency (KISA), Korea Internet Security 
Center (KrCERT/CC), Laboratoire d’Expertise en Securite Informatique (LEXSI), 
Malware Block List, National Cyber-Forensics and Training Alliance (NCFTA), 
Netcraft, NYSERNet, Okie Island Trading Company, OpenDNS, Pipex, Research 
and Education Networking Information Sharing and Analysis Center (REN-ISAC), 
Rede Nacional de Ensino e Pesquisa (RNP), SonicWALL, Sunbelt-Software, Support 
Intelligence, SURBL, Symantec, Team Cymru, Th omas Jeﬀ erson National Accelerator 
Facility (JLab), TrustDefender, United Online, United States Computer Emergency 
Readiness Team (DHS US-CERT), Websense, Webwasher, XBlock, Yahoo!
CastleCops provides a free XML feed service into the phish database. Th e feed is a 30-day rolling 
window showing both the terminated and the conﬁ rmed URLs, their associated Autonomous 
System Numbers (ASNs), and the PIRT database reference ID number. To request the feed, send 
an e-mail to Paul Laudanski (paul@castlecops.com) for authorization.
CYMRU
According to the CYMRU Web site (www.cymru.com), Team CYMRU is
a corporation of technologists interested in making the Internet more secure. We are 
a group of geeks who are passionate about network security and in helping the com-
munity identify and eradicate problems within their networks.
Team CYMRU was founded in 1998 by Rob Th omas as an Internet security think tank. Team 
CYMRU works with over 700 vendors, researchers, and providers. Team CYMRU provides lists 
of bogons (Internet Protocol [IP] ranges that should never appear in the Internet, e.g., 127.0.x.x; 
blocks of IP addresses that have not been allocated to any regional Internet registry; etc.) in a 

56  Information Security Management Handbook
“plethora of formats.” Rob Th omas documented the use of bogons against a frequently attacked 
site in a paper titled “60 Days of Naughtiness.” Sixty percent of the attacks used obvious bogons. 
Th eir database is updated daily with changes from the Internet Assigned Numbers Authority. Th e 
associated Web pages also provide assistance for those wanting to start ﬁ ltering bogons.
Once you have begun to look for intelligence sources you will run into tables that provide only 
the ASN or that provide only the IP address for sites. Team CYMRU provides a conversion utility 
in the form of an IP-to-ASN “whois” page (https://asn.cymru.com/). Th e ASN is used in Border 
Gateway Protocol (BGP), which exists at the same network layer as IP. BGP is designed for passing 
traﬃ  c between networks as opposed to within them. A single ASN is used to represent all of the 
blocks of IP addresses associated with a single organization. When you retrieve whois information 
about an ASN you can get information about all of the IP blocks belonging to the organization 
with that ASN. Th is may help you get to someone who can help shut down a rogue site.
Th e CYMRU Web site also provides a valuable library of expert papers, presentations, and 
tools, many of them dealing with BGP security. Th ere is also a section devoted to darknets and 
how to create your own.
Inﬁ ltrated.net
Inﬁ ltrated.net is a list of IP addresses that have attempted brute-force password attacks against 
machines administered by the Web site owner (http://www.inﬁ ltrated.net/bforcers/masterlist.txt).
Spamhaus
Spamhaus (www.spamhaus.org) provides a wealth of information useful to spam ﬁ ghters. Th ey 
also provide the Spamhaus DROP (do not route or peer) list (http://www.spamhaus.org/drop/
index.lasso). Th is list is a small subset of the larger Spamhaus block list (SBL) list provided for 
ﬁ rewall and routing equipment. According to the Spamhaus Web site:
Th e DROP list will NEVER include any IP space “owned” by any legitimate network 
and reassigned—even if reassigned to the “spammers from hell.” It will ONLY include 
IP space totally controlled by spammers or 100% spam hosting operations. Th ese are 
“direct allocations” from ARIN, RIPE, APNIC, LACNIC, and others to known spam-
mers, and the troubling run of “hijacked zombie” IP blocks that have been snatched 
away from their original owners (which in most cases are long dead corporations) and 
are now controlled by spammers or netblock thieves who resell the space to spammers.
Both the DROP list and the SBL list can be used to alert you to any communications between 
hosts in your organization and known spammer’s assets.
Internet Crime Complaint Center
Internet Crime Complaint Center (IC3) is a partnership of the FBI and the National White 
Collar Crime Center (NWC3). From the IC3 Web site:
IC3’s mission is to serve as a vehicle to receive, develop, and refer criminal complaints 
regarding the rapidly expanding arena of cyber crime. Th e IC3 gives the victims of 

Using Quasi-Intelligence Resources to Protect the Enterprise  57
cyber crime a convenient and easy-to-use reporting mechanism that alerts authorities 
of suspected criminal or civil violations. For law enforcement and regulatory agen-
cies at the federal, state, local and international level, IC3 provides a central referral 
mechanism for complaints involving Internet related crimes.
National Cyber-Forensics and Training Alliance
National Cyber-Forensics and Training Alliance (NCFTA) is a partnership of industry, academia, 
and law enforcement. From the NCFTA Web site, NCFTA
provides a neutral collaborative venue where critical conﬁ dential information about 
cyber incidents can be shared discreetly, and where resources can be shared among 
industry, academia and law enforcement.
Th e Alliance facilitates advanced training, promotes security awareness to reduce 
cyber-vulnerability, and conducts forensic and predictive analysis and lab simulations.
Th ese activities are intended to educate organizations and enhance their abilities to 
manage risk and develop security strategies and best practices.
NCFTA participants receive the beneﬁ ts of cyber-forensic analysis, tactical response develop-
ment, technological simulation or modeling analysis, and the development of advanced training. 
NCFTA provides the FBI and Postal Inspection Service with expertise and a place for collabora-
tion with industry and academia.
Internet Security Operations Task Force
Internet Security Operations Task Force (ISOTF) is an anti-cyber-crime group focused on 
uncovering new trends and tactics to combat phishing, botnets, and other types of online scams. 
ISOTF is led by Gadi Evron, a security researcher at Israeli-based Beyond Security. In addition 
to Zero Day Emergency Response Team alerts, ISOTF also publishes member-only mailing 
lists focused on botnets (http://www.whitestar.linuxbox.org/mailman/listinfo/botnets),  phishing 
attacks (http://www.whitestar.linuxbox.org/mailman/listinfo/phishing), ISP-centric security 
(Drone Army), malware vendor and security researchers (malicious Web sites and phishing), and 
registrar operators (Reg-Ops). Th e last three mailing lists require vetting before you can join. For 
consideration, contact Gadi Evron at ge@linuxbox.org.
Membership Organizations
Th e simplest and most direct organization that can provide some intelligence is your ISP. Although 
ISPs are not traditional membership organizations, you are a member of the ISP community as 
a customer. Th e services available vary from ISP to ISP. At a minimum, you should be receiving 
information from your ISP related to complaints against your organization that they receive. Th ey 
might also provide you with information they receive about attacks against your organization that 
they see or are told about.
Quasi-intelligence organizations have varying qualiﬁ cation requirements. Some organiza-
tions, like Shadowserver, do not require membership. Most of their information is made freely 

58  Information Security Management Handbook
 available to all. Other organizations, like the REN–ISAC, have strict membership and conﬁ den-
tiality requirements. REN–ISAC acquires some of its information from sources that will provide 
information only on the condition that all who receive it pass a vetting check and agree to abide 
by tough conﬁ dentiality guidelines. Th is is to prevent the data from getting into the wrong 
hands. In addition, the conﬁ dentiality guidelines create an environment in which members 
are comfortable discussing sensitive cases because they know the information will not become 
public.
Each membership organization establishes its own qualiﬁ cations. For example PIRT shares the 
information it collects with anyone that wants it. All handlers are volunteers, but to be a handler 
you must apply and have your resume and experiences evaluated. All newly admitted handlers 
must go through some mandatory training and a period of time spent working with a mentor. 
Clearly the focus of handler screening is to ensure the integrity of the analysis process, but the 
resume review also attempts to identify and block potential bad guys from getting inside, again 
for integrity reasons.
Another class of quasi-intelligence organization is the paid membership consortium. Th is 
includes organizations like the Internet Security Alliance and Red Siren. Th ese organizations tend 
to be more general in focus, digging into an issue when their constituency expresses a need. Th is 
chapter focuses on the free organizations.
Conﬁ dentiality Agreements
Some quasi-intelligence organizations are bound to conﬁ dentiality agreements by original sources. 
By agreeing to keep the data or the source conﬁ dential, they are able to get quality intelligence that 
would otherwise be unobtainable.
In some cases, the information cannot be shared with anyone outside your institution. In other 
cases, you are permitted to share the information only with other individuals that have been vet-
ted by the quasi-intelligence organization. Each cache of intelligence information may carry its 
own provisions for conﬁ dentiality. Here, caches are sets of information from diﬀ erent sources. You 
need to ensure that each person that might have access to this kind of data understands and agrees 
to abide by the provisions of each conﬁ dentiality agreement.
The Role of Intelligence Sources in Aggregating Enough Information 
to Make Law Enforcement Involvement Practical
Quasi-intelligence sources provide a valuable service to the Internet community in that they 
are able to take individual cases that law enforcement would never prosecute and aggregate 
them with thousands of other related cases. Law enforcement is justiﬁ ed in taking a case with 
thousands of instances. Organizations like PIRT (Castlecops.com), the Anti-Phishing Work-
ing Group (APWG), REN–ISAC, the IC3, and the NCFTA bundle and report cases to the 
NWC3, which delivers them to the FBI and Secret Service. PIRT and APWG also report the 
same cases to anti-phishing and antivirus vendors. Sites like Shadowserver make lists of known 
C&C servers publicly available. Some law enforcement sites like NCFTA are known to use 
their data.
Without these aggregating organizations, law enforcement would be buried in thousands of 
individual cases that could not easily be pursued. Th e aggregating organizations, in addition to 
collecting and collating the data, bring a great amount of expertise to the task of analyzing and 

Using Quasi-Intelligence Resources to Protect the Enterprise  59
interpreting the information. It is inconceivable that law enforcement would be funded to hire all 
the expertise provided to them for free by these groups.
Internal Sources
You should not overlook the many internal sources of intelligence information available to you. 
Th e most obvious sources are log ﬁ les of every size, shape, and color. Firewall logs, system logs, and 
application logs from both servers and workstations. Centralizing your logs can make this data 
more accessible and can let you develop tools for real- or near-real-time analysis.
For many organizations, Windows workstation logs are not turned on by default. To ensure  useful 
data is being collected the local security policy should include the audit policy settings as follows:
Audit account log-on events
Success, Failure
Audit account management
Success, Failure
Audit log-on events
Success, Failure
Audit policy change
Success, Failure
Audit privilege use
Success, Failure
Th ese settings should be enabled on all Windows workstations. In addition the Windows ﬁ rewall 
for all workstations should enable logging and you should ensure that the options “Enable log 
dropped packets” and “Enable log successful connections” are both checked. Th is should be done 
even if you do not intend to use the ﬁ rewall for ﬁ ltering traﬃ  c.
Table 4.2 lists the potential internal sources of intelligence, a description of the nature of the 
intelligence, and the security goals addressed by each source.
One fundamental change is necessary in the way help desk teams respond to virus-infected 
systems that are brought in to be scanned or reimaged. Performing a quick forensic prior to virus 
scanning or reimaging has proven to be yield valuable information about other infected hosts, 
C&C servers, payload structures, and more. (See a sample quick forensic procedure at the end of 
this chapter.) Note that the quick forensic procedure as described here is not intended to support a 
case for involving law enforcement. Th e intent of the quick forensic is to expand your knowledge 
of the breadth of the botnet infection or its links to the outside. If the quick forensic yields infor-
mation that would indicate law enforcement should be involved (e.g., the presence of child por-
nography), then the quick forensic should be suspended and a full forensic exam, beginning with 
taking a forensically sound image, should be performed. As you can see from the sample quick 
forensic, the procedure will be unique to each organization and to each wave of infected botclients. 
Th is sample is version 5. As more information was learned about the nature of botclients infected 
by this bot-herder, the procedure was modiﬁ ed to gather better information.
What Do You Do with the Information When You Get It?
Organizations need a process for ﬁ nding candidates (which I call potential intelligence markers) 
and evaluating them for their suitability. In law enforcement, an intelligence marker may sometimes 
be placed on an individual’s or asset’s record to indicate there may be some interest in the indi-
vidual. An intelligence organization may need to know about activities that are not crimes in and of 

60  Information Security Management Handbook
Table 4.2 Internal Intelligence Sources
Security audit logs
Check the security logs for failed and successful log-ons. This 
may provide evidence of password guessing or brute force. 
Some are obvious, page after page of failed attempts starting 
with administrator and then changing to different spellings 
(administrador, etc.). The successful logs that occur during 
these attempts are likely compromised accounts, particularly 
if the attempts occur during hours when your company does 
not usually work. Sometimes it is less obvious, a handful of 
failed log-in attempts from many machines spread out over 
time. Have the logs forwarded to a central log server and 
process them daily using Structure Query Language queries 
to ﬁ lter out most normal behavior.
Discover other infected systems by making 
a list of the machines involved in the failed 
log-ins. Useful to convince the user who 
says, “My machine is not infected. I ran a 
virus scan and it came up clean.”
Network ﬁ rewall, 
IDS/IPS logs
Traditional security, understand what normal looks like, 
investigate abnormal entries, look for known attack trafﬁ c 
patterns. Develop rules to block newly discovered attack 
trafﬁ c.
Detect, log, and block trafﬁ c at the 
perimeter. Identify IP addresses 
transmitting trafﬁ c associated with security 
alerts. Keep logs for analysis after the fact, 
when intelligence reports identify a 
problem.
Host ﬁ rewall logs
Check the host ﬁ rewall logs for successful inbound 
connections. Validate that inbound connections are 
reasonable for that workstation. Check outbound connections 
on unusual ports, particularly ports for which alerts have 
recently been issued. Check for communications with known 
C&C servers.
Evidence of participation in botnet activity. 
Identify attack vectors, hosts providing 
botnet updates, spam templates, C&C, etc.
Network trafﬁ c 
anomaly detection
Using Net ﬂ ow analysis or tools like Ourmon, analyze network 
trafﬁ c for behavioral evidence of botnet or scanning activity. 
Monitor and report more detailed trafﬁ c from suspected 
botnet clients and servers.
Identify botnet clients and their C&C 
servers, along with their IRC channel, user 
ID, and password. Identify malware 
downloaded by botclients.
IDS/IPS
Snort, Real Secure, etc.—analyze network trafﬁ c in near-real-
time to spot patterns or anomalies associated with malicious 
activity.
Signatures come from outside organizations 
(vendors or open-source organizations like 
Bleeding Snort).

Using Quasi-Intelligence Resources to Protect the Enterprise  61
(continued )
Darknets
A darknet is a reserved portion of your IP space that is not 
assigned to any system. Any attempt to communicate with 
systems in darknet space is evidence of scanning.
Identify systems that are scanning your 
network. Feed this information to your 
network trafﬁ c anomaly detection systems 
to further corroborate bot-like activity.
Honeypots, honeynets
An instrumented system set up so that would-be attackers give 
themselves away. Honeypots and honeynets can be set up to 
respond to attackers to make them believe they have 
encountered a new potential host to infect.
Placing a honeypot or honeynet in darknet 
space permits you to gather information 
about the scanners and their intentions. 
Honeypots and honeynets can give you 
detailed information about attack vectors, 
C&C servers, location of botnet 
component storage servers, bot 
commands, and functionality.
Forensic examinations
A major operations change for most IT shops when 
remediating virus-infected systems is to perform a quick 
forensic examination before scanning for viruses or 
reimaging. Scanning for viruses with an independent virus 
scanner or reimaging destroys evidence that can help you 
identify the C&C server and other botclients. Creating a quick 
forensic checklist can preserve essential intelligence 
information, even evidence.
Examine the security and ﬁ rewall logs on 
suspected virus-infected systems. If you 
know the time of a suspicious event 
involving the host, search the computer for 
ﬁ les that were modiﬁ ed around the time of 
the event. If you ﬁ nd malware, look for 
conﬁ guration ﬁ les associated with the 
malware. The conﬁ guration ﬁ les may tell 
you ports used, C&C IP addresses, 
usernames, passwords, and other infected 
ﬁ les.
Sandbox technology
CWSandbox from Sunbelt Software and the Norman Sandbox. 
Both the CWSandbox and the Norman Sandbox offer a free 
Web site for organizations to submit individual samples. 
Submitted samples are analyzed in their respective sandboxes 
and the results are e-mailed back to the submitter. The sample 
is placed in the sandbox, in a virtual environment, and 
executed. The sandbox records all ﬁ les opened, all 
connections attempted, all ﬁ les that the malware attempts to 
download.
Sandbox analysis can provide C&C server 
IP addresses or DS names, bot channel 
names, user IDs and passwords, download 
sites for malware, scanning software, spam 
templates, lists of e-mails, and download 
package names.

62  Information Security Management Handbook
Table 4.2 (Continued)
Fiddler
Developed by Microsoft as part of the Strider project. Fiddler is
a Web browser proxy that records, for analysis, the Web sites 
through which a browser is redirected when a site is visited 
and the actions taken during each visit.
Can reveal Web sites that upload malware as 
well as the structure of sites involved in 
search engine spam.
Google searches
A method for discovering Web vulnerabilities using search 
engines. It was popularized by the book Google Hacking for 
Penetration Testers, by Johnny Long. Two useful examples: 
(1) Use the search phrase “phpbb site:<your URL>” to ﬁ nd 
phpBB sites. Check these sites for evidence that they have 
been abandoned by users and taken over by spammers. 
(2) Use the search phrase “phentermine site:<your URL>” 
to locate Web sites that may have been co-opted by 
spammers to sell the popular diet pill.
PhpBB sites that have been misconﬁ gured to 
permit users to post without being 
approved by a moderator are often taken 
over by spammers. Finding Web sites in 
your domain that are offering phentermine 
will permit you to take these compromised 
Web sites ofﬂ ine. If you happen to have 
Web statistics being gathered about 
these Web pages, they can yield valuable 
information about the spammer’s 
infrastructure. Look at referrer sites and the 
search engine strings used to ﬁ nd the site.
Asset inventory 
searches
Using tools like LANDesk Manager or Altiris search-managed 
systems for deﬁ nition indications of bot control. File names or 
hashes found on other local botclients, directory structures 
used by the bot-herder.
Use your knowledge of organic bot 
information found on local clients to ﬁ nd 
other members of the botnet. Ourmon 
snagged Internet trafﬁ c containing the 
name of a ﬁ le being downloaded by 
infected botclients. Using Altiris to search 
for the ﬁ le, about 40 other infected hosts 
were located.

Using Quasi-Intelligence Resources to Protect the Enterprise  63
themselves but may link an individual to criminal activity or organizations. Sometimes the behav-
ior indicated by the marker is enough to conﬁ rm maliciousness without any other  conﬁ rmation 
(e.g., a password guessing using the list of default accounts associated with Rbot), but not always.
Other intelligence markers may require a second or third marker to be sure. For example, a work-
station scanning your network may be a botclient, but it could also be a bored employee. However, 
a workstation that scans your network and communicates with a known C&C server has a higher 
probability of being a member of a botnet. Intel markers can be used to identify infected systems in 
your enterprise or to let the infected systems ID themselves as in the case of a darknet or honeynet. 
In this way intelligence markers can contribute to both prevention and recovery strategies.
What makes a good intelligence marker? Intelligence markers that we are interested in consist 
of data or information that aid in conﬁ rming or denying the nature of a workstation or Internet 
site as malicious. Th e best markers are unambiguous and deﬁ ning. Th at is, by their presence or 
absence they can conﬁ rm or deny maliciousness. For example, network traﬃ  c that contains con-
ﬁ rmed malicious code retrieved by several sites from the suspect workstation would be an unam-
biguous and deﬁ ning intelligence marker.
Th e usual intelligence marker is less deﬁ nitive or more ambiguous in isolation. However, 
aggregating this data can often raise your conﬁ dence in a determination. Th e best markers are 
well understood, particularly the circumstances under which the marker would mean malicious or 
nonmalicious use. For example, the Symantec Anti-Virus (SAV) server transmitting to destination 
Transmission Control Protocol (TCP) port 2967 to several workstations is likely nonmalicious. In 
contrast, a workstation (not a SAV server) transmitting to several workstations using destination 
TCP port 2967 is likely malicious and is trying to exploit a Symantec vulnerability.
Evaluation of what makes a good Intel marker will vary with the experience of the evaluator. 
It takes a skilled evaluator to analyze and vet new intelligence markers. Once vetted, the markers 
can be described to less-skilled observers so that they may monitor for the presence of the vetted 
markers. A record should be kept of the vetting process, in case anyone (e.g., a defense attorney) 
should later question its validity.
Here, for example, is the conﬁ dence rating system provided by the Network for Education 
and Research in Oregon, the author’s ISP, for abuse reports related to hosts infected with the 
Storm Worm.
Th e conﬁ dence value associated with an entry indicates how likely the host is infected 
with Storm-Worm and ranges between 1 and 5. A value of 1 means medium conﬁ dence: 
a suspect host connected to a Storm-Worm C&C network but a monitor system could 
not establish a return connection to verify the suspect host is infected. A value of 5 
means very high conﬁ dence: a suspect host connected to a Storm-Worm C&C network, 
searched for strings known to be associated with Storm-Worm, and a monitor system 
was able to establish a return connection and verify the suspect host’s behavior is con-
sistent with Storm-Worm. Values between 1 and 5 suggest that either the suspect host 
connected to a Storm-Worm C&C network and searched for strings associated with 
Storm-Worm or a monitor system was able to establish a return connection to the sus-
pect host. When available, the UDP port used to connect to the monitor is provided.
In some cases, markers only add weight to a decision that must ultimately be made by a human. 
In the bot-detection algorithms found in Ourmon, developed by Jim Binkley of Portland State 
University (PSU), several markers are monitored and evaluated. Each marker is assigned a letter, 
which is printed in reports whenever that condition is detected (Table 4.3).

64  Information Security Management Handbook
If only one marker’s letter shows up, then the system may not be part of a botnet. If several let-
ters are printed, then the likelihood of the system being part of a botnet is increased. In Ourmon, 
a busy botnet will light up the letters, spelling out EWORM. Ourmon adds other intelligence 
markers to increase conﬁ dence. One indicator shows whether the system is communicating with 
a known C&C server. Another indicator displays whether a system is acting in isolation or is part 
of a communicating network of some kind (IRC, P2P, etc.). An intelligence marker displays the 
ratio of unique IP addresses to destination ports. If you see a host that talks to few IP addresses 
with many destination ports, you may have a scanner looking for active ports, particularly if the 
one-way ﬂ ag is set. If you see a host that talks to many IP addresses with a few unique destination 
ports, you may be seeing a typical fan-out pattern for a bot that is recruiting. Most bots have tools 
that scan only a limited number of vulnerabilities.
To reduce the number of false intelligence markers, Ourmon also keeps track of protocols that 
exhibit botlike characteristics but may actually be legitimate. Similar to our intelligence markers, 
identifying a host as one that uses a protocol with wormlike characteristics does not discount the 
fact that it might still be a bot. Instead, it says that worminess alone is not suﬃ  cient to conclude 
that it is part of a botnet (Table 4.4).
You will notice that some of the ﬂ ags indicate potential good, whereas some indicate potential 
bad (honeypot or darknet violation, e-mail source port seen, User Datagram Protocol (UDP) 
only—a spam using Internet messenger indicator).
For a more detailed look at Ourmon, check out Chapters 6–9 of Botnets—Th e Killer Web App, 
published by Syngress, or go to http://ourmon.sourceforge.net/. To see Ourmon in action go to 
http://ourmon.cat.pdx.edu/ourmon.
Ourmon also uses data from other intelligence sources to corroborate its suspicions. Several 
sources, like Shadowserver provide lists of known C2 servers. Ourmon checks the IP addresses asso-
ciated with a suspected botclient to see if any of them are known C&C servers. Th e combination of 
communication with a known C&C server and botlike activity is usually enough to conclude this 
is a positive determination of a botnet.
Table 4.3 Intelligence Markers Used in Ourmon
E
Presence of Internet Control Messaging Protocol errors
W
Work weight—essentially the ratio of content to control data
O
One-way or two-way trafﬁ c
R
Presence of RESETs
M
Lack of FINS
Table 4.4 Application Flags
B
BitTorrent Protocol
G
Gnutella Protocol
K
Kazaa Protocol
M
Morpheus Protocol (P2P too)
P
Honeypot (darknet) violation
E
E-mail source port (e.g., port 25) seen
H
Web source port (e.g., port 80 or 443) seen
I
IRC messages seen
S
User Datagram Protocol only; indicates spam for Internet messenger

Using Quasi-Intelligence Resources to Protect the Enterprise  65
PSU obtains this ﬂ ag by using the list of known C&C servers in our internal DNS server. 
Any host that queries one of the known DNS servers is returned a special address. Th e system at 
this address records the IP address and port number for any system that contacts it. Th is informa-
tion is fed into Ourmon and correlated with other intelligence markers for the same IP address. 
Another approach would be just to return a blackhole address for any queries made to known C&C 
servers. Similarly, some organizations use BGP to the same eﬀ ect (turning oﬀ  routes instead of 
giving ﬁ ctitious DNS entries).
Some intelligence you receive from external sources (e.g., from your ISP or from your abuse e-mail 
address) is about the activity of systems in your IP space. If the intelligence indicates the likelihood 
of an infected host, you should activate your response process. In the case of PSU, our networking 
team quarantines the suspected infected host, restricting its access and referring the user to the help 
desk. Our computer support analysts identify the location of the computer and the user to whom 
the computer is assigned. Th e desktop support team retrieves the computer and performs the quick 
forensic exam. If anything extraordinary or illegal is seen during the forensic exam, an image is taken 
and information security is notiﬁ ed for a more complete forensic exam. In the course of examining 
the system, any new intelligence that is uncovered is fed back to Ourmon or other sensors.
Counterintelligence: The Next Step
Security professionals are now beginning to look at these threats in a new light. Th is chapter urges 
organizational security oﬃ  cers to begin to look beyond their own boundaries for information to 
combat the growing darkness. As we have begun to learn more about the threat, a few have made 
forays into the realm of counterintelligence. Th e white paper “Revealing Botnet Membership Using 
DNSBL Counter-Intelligence,” by Anirudh Ramachandran, Nick Feamster, and David Dagon from 
the College of Computing, Georgia Institute of Technology, is one of these. By  analyzing the eﬀ orts 
of bot-herders to market their spamming bot activities as free of blacklisting, Mr. Dagon et al. noticed 
that they made DNS blacklist queries in a manner that could identify them as spamming bots. Th eir 
method uses heuristics to distinguish between legitimate and bot-related queries. Th eir study suggests 
that bot-herders perform reconnaissance to ensure their bots are not blacklisted prior to conducting 
attacks. Using techniques described in this paper could yield an early warning capability.
Recent work in the area of passive DNS analysis has yielded great insights into the working of 
fast ﬂ ux DNS related to phishing sites. You can see a visual representation of fast ﬂ ux DNS used in 
a persistent phishing cluster located at http://www.internetperils.com/perilwatch/20060928.php. 
Th is animated .gif was created by taking 20 dumps of the APWG database, gathered from May 17 
through September 20, 2006, and combining them with ongoing network performance and 
topology data collected directly by Internet Perils. Th e result is a view that no individual target 
of phishing could have provided. Law enforcement and anti-phishing groups can now see the big 
picture of systems involved in phishing attacks. In addition they see the eﬀ ects of fast ﬂ ux DNS 
in a striking graphic presentation.
More analysis of the aggregated data collected by these quasi-intelligence organizations is 
needed. It is here that we will ﬁ nd the weapons to begin to ﬁ ght the ﬁ re currently fueled by 
organized crime. Th ere are reports that spammers using botnet technology are making incredible 
amounts of money. One court document says that Jeremy Jaynes was making $750,000 a month 
from his spamming activities. Rumor has it that Pharmamaster, the Russian spammer that brought 
down Blue Security, was making $3 million a month from spam. With this kind of money, they 
can fund signiﬁ cant research to keep their enterprises operational. As evidenced by Blue Security’s 

66  Information Security Management Handbook
fate, they can also bring tremendous resources to bear on anyone or any company that begins to 
impact that income. Governments must begin to recognize this and respond accordingly. At pres-
ent, there is no concerted eﬀ ort to ensure that research is being done in all areas that might yield 
productive results. More important than the technical issues, there is little being done in the realm 
of law and law enforcement that will eﬀ ectively meet this global threat.
Summary
A/V products must be augmented to protect your organization against today’s threat. Intelligence 
information from both internal and external sources is needed to address new threats that are not 
handled by A/V products. Each intelligence source is diﬀ erent. Information security professionals 
should review the objectives addressed by each intelligence source to determine those that will 
enhance your organization’s ability to detect botnets and other malicious activity.
A rating system should be associated with each intelligence source. Th e rating should indicate 
the level of conﬁ dence that the organization should place on the information. Information from 
diﬀ erent sources should be gathered and correlated to raise the conﬁ dence level in a determination 
that a suspicious host may be part of a botnet or other malicious activity.
Organizations should change their process for handling virus-infected systems to require the 
collection of intelligence data prior to clean scanning or host reimaging. Ensure your workstations 
are conﬁ gured to gather useful log information.
Using these intelligence resources to augment your existing security measures you can gain:
Knowledge of attacks by your own organization’s resources on others
Knowledge of attacks by other systems on your resources
Knowledge of attempts by your assets to communicate with known C&C servers
Lists of known C&C servers, ports, and channels
Results of aggregate data from honeynets, honeypots, and darknets across the Internet
Access to analysis reports on current threats
Access to analysis of individual instances of malware
Access to special tools
Access to detailed discussions of real uncensored events
Access to a professional community with similar security concerns
Access to bleeding edge IDS signatures
Arrange to use this intelligence data with your DNS system, your wide area networks routers, your 
network monitoring systems, and your IDS/IPS systems.
Finally, ﬁ nd aggregating organizations in your sector and become a contributing member. As a 
profession, we cannot win the war against bots and other malware unless we work together.
Th e sample First Responder procedure
Version 5
12/14/06
First Responder Examination of Compromised Machines
Read each section before beginning.
Do not scan the computer for viruses before taking these steps. Th e scan may delete useful ﬁ les.
Do not edit, view, sort, or otherwise manipulate the event ﬁ les before saving them.












Using Quasi-Intelligence Resources to Protect the Enterprise  67
First, copy the Event Viewer logs to a universal serial bus (USB) drive.
Go to Control Panel > Administrative Tools > Event Viewer
Right click on each log, and click on “Save As.”
– 
When saving the ﬁ rst ﬁ le, create a directory with today’s date (YYMMDD) and the 
name of the computer being examined and the help desk ticket number (e.g., 061102 
CAMPUSREC-04 RT2349).
– 
Save each log to this folder on the USB drive, using the naming scheme [computer 
name] [log description] [six-character date, YYMMDD] (e.g., “CAMPUSREC-04 
Security 061102”).
Keep Event Viewer open, as the logs will be useful later in locating entry events and helping to 
locate corrupted ﬁ les. Th e other logs to export are the antivirus (SAV or McAfee) logs. Th e McAfee 
logs are located at:
%DEFLOGDIR%\AccessProtectionLog.txt
%DEFLOGDIR%\Buﬀ erOverﬂ owProtectionLog.txt
%DEFLOGDIR%\EmailOnDeliveryLog.txt
%DEFLOGDIR%\OnAccessScanLog.txt
%DEFLOGDIR%\OnDemandScanLog.txt
%DEFLOGDIR%\UpdateLog.txt
On the author’s system %DEFLOGDIR% translates to C:\Documents and Settings\All Users\Application 
Data\McAfee\DesktopProtection
Th e SAV logs are SAV risk, scan, tamper, and event histories and can be exported by running 
the SAV graphical user interface.
If the log is empty, disregard.
If the log has items in it, select the log, then click “Save” on the toolbar.
– 
Save them to the USB drive
– 
Use the same naming scheme as for the Event Viewer logs
– 
Th ese are saved as comma-delimited ﬁ les
Once the logs have been saved, the next step is to locate any corrupted ﬁ les or ﬁ les of copyrighted 
information (movies, games, etc.) as well as any other unusual ﬁ les.
At this point you can use the SAV logs to see if they identify any folders that may have infected 
ﬁ les. Th e risk history ﬁ le will identify folders that contained infected ﬁ les. Th ese folders should be 
examined for other potential evidence. Th e SAV event history may identify folders that contained 
ﬁ les that could not be examined, called scan omissions. Th ese folders are good places to look for the 
bot-herder’s payload. Note that saving the SAV logs does not save the individual entry detail. If there 
is an interesting individual entry, you can copy the text from the entry into a notepad text ﬁ le.
In the current set of infections, one place commonly used to store stolen intellectual property 
is in the recycle bin. Looking at hidden ﬁ les in the recycle bin is tricky. Open Windows Explorer 
and click on Tools and Options. Change setting on Tools options so that hidden ﬁ les and folders 
are visible (enable Show Hidden Files and Folders). Change the settings (disable) for the attributes 
“Hide Extensions for Known File Types” and “Hide Protected OS ﬁ les.”
Using Windows Explorer, go to C:\ and locate the ﬁ le C:\Recycler\. If you list the ﬁ les, you 
may see a directory that begins with .bin{SID}. Th is is the directory in which we have found stolen 
intellectual property. However, the ﬁ les in this directory do not show up in Windows. To see the 





68  Information Security Management Handbook
ﬁ les, ﬁ rst double-click on the directory that begins with .bin. Th is will place a copy of the path in 
the address bar. Highlight the path in the address bar, then press Ctrl C. Th is will place a copy of 
the path on the clipboard.
Next, open a Disk Operating System (DOS) window. Switch to the C: drive if it is not already 
there. Type cd followed by a quote mark. Right click on the top blue bar of the DOS window. In 
the drop-down menu locate the Edit selection. Left click on Edit to bring up another menu. In the 
Edit menu select Paste. Add the closing quotation mark (”), then press Enter.
To check if ﬁ les are there, you can type the dir command. If there are ﬁ les, then you will want 
to type the command again with the forward slash (“/”) s option (list subdirectories) and redirect 
the output to the USB memory stick into a ﬁ le with a name that includes the name of the com-
puter, the phrase “Hidden Directories,” and the date in YYMMDD format, for example:
C:\RECYCLER\bin.{645ff040-5081-101b-9f08-00aa002f954e} > dir /s > e:“{computername} Hidden 
Directories 061103.txt”
Th e easiest way to locate ﬁ les associated with the break-in or the data collected by the hacker is to 
ﬁ nd the dates of intrusion. Go back to the security log.
Sort by date and scroll through the log looking at the “Failure Audits.”
Th ese indicate failed log-ins, and the most suspicious of these are when there are several 
failures within a second. However, it is best to open up the properties of the ﬁ rst few and 
look at them in turn.
On the properties page, there are several items of interest that indicate break-in attempts.
Make note if the domain ﬁ eld of the Event Properties entry contains anything other than 
your domain name or the name of the workstation being examined. Also make note if 
the Workstation Name ﬁ eld contains the name of anything other than the name of the 
workstation being examined.
When you ﬁ nd a record like this, record the date and time of the ﬁ rst failed attempt, then move 
on to another date.



−

Using Quasi-Intelligence Resources to Protect the Enterprise  69
You will use the dates and times of the break-ins to search the ﬁ le system for other evidence. If 
the security log is empty or contains only successes, use the dates from the Symantec risk history 
or event log. If Symantec has also has no logs, check for activity on a recent common break-in date 
(from other intelligence) or the date the suspicion of infection was raised. For each date you found 
you can search the ﬁ les and folders with the options mentioned earlier for showing hidden ﬁ les 
and folders and not hiding the system ﬁ les. Once the search has been completed, sort the ﬁ les by 
the date/time ﬁ eld. Look for ﬁ les that were modiﬁ ed around the time of the break-ins. Th ere may 
be some normal ﬁ les at the same time but after a few machines you will be able to recognize most 
of them. If you want to look at some to check them out, use Notepad. You should not execute any 
of the ﬁ les you ﬁ nd. In these ﬁ les you are looking for things that may tell you how they got in or 
user IDs and passwords they may have collected or broken. Any hacker tools and the conﬁ guration 
ﬁ les associated with them can provide valuable insights.
One ﬁ le that we found on several systems that was worth looking for was a set of ﬁ ve ﬁ les 
starting with JAs.
JAsfv.dll
JAsfv.ini
JAstat.dll
JAstat.ini
JAstat.stats
In the request tracker (RT) ticket you should also locate any ﬁ les that are listed that were detected 
by an Altiris scan. Th ese ﬁ les and ﬁ les either near them or with the same date and time as them 
may be of interest.
If you ﬁ nd any ﬁ le with credit card numbers, Social Security numbers (SSNs), or other data 
that might be personally identiﬁ able information, stop the investigation and contact the security 
oﬃ  cer. A computer with this kind of data in proximity to hacker data will need to have an image 
taken and a more thorough forensic examination performed by security.
In the Windows directory (WinNT for Win2K) copy to the memory stick any ﬁ les that have 
the word “ﬁ rewall” in them (Firewall_Zone_A.log, Firewall_Zone_A.log.old, pﬁ rewall.log, etc.)
Open a command window. Change to the drive on which the memory stick is located. Change 
the directory to the folder for this computer. Change the drive to the C: drive. Change the direc-
tory to the root “\” directory. List the directory ﬁ rst with the “/s” parameter, then with both “/s” 
and “/ah” parameters and redirect the output to the drive with the memory stick. If the memory 
stick is on drive E: the commands would look like this.
C:\Documents and Settings\comp$admin> e: 
E:\>dir 
Volume in drive E has no label. 
Volume Serial Number is 05D1-4545 
Directory of E: 
11/02/2006  01:46 PM    <DIR>          061117 ESL-TECH 
11/17/2006  05:13 PM    <DIR>          061117 ATH-PSC167-XRAY 
               0 File(s)              0 bytes 
               2 Dir(s)     876,937,216 bytes free 
If the computer you were working with was the ESL-TECH computer,
 you would change the directory to 06117 ESL-TECH. 
E:\< cd “061117 ESL-TECH” 
E:\061117 ESL-TECH> c: 
C:\Documents and Settings\comp$admin>cd \ 
C:\>dir /s >”e:061117 ESL-TECH directories.txt” 
C:\>dir /s /ah >”e:061117 ESL-TECH hidden directories.txt”

70  Information Security Management Handbook
In the root directory (C:\) you will ﬁ nd a directory called “System Volume Information.” To look 
at this directory you will add the account you are using to the security tab of the folders Proper-
ties; the default access that it gives you is OK, you will need only to read the ﬁ les. After applying 
the change, click OK.
Open the system volume information folder. Th ere may be a folder that looks something like 
the following (the numbers in the braces will be diﬀ erent):
_restore{FABD0D3E-B186-4217-A903-D6F355385163}
Double-click on this folder. Here do a search for *.old. Copy any ﬁ le it ﬁ nds to the memory stick 
and place in a folder called <machine name> Firewall logs.
Execute system internals Process Explorer and save the results to the memory stick.
Execute system internals TCPView and save the results to the memory stick.
Execute system internals Autoruns and save the results to the memory stick.
When you are done, bring the memory stick and any notes you took to information security and 
note in the RT ticket that the system is ready to be reimaged.

71
Chapter 5
Information Risk Management: 
A Process Approach to Risk 
Diagnosis and Treatment
Nick Halvorson
Contents
Introduction .............................................................................................................................. 72
Th e Nature of Risk .................................................................................................................... 72
Strategic Risk ................................................................................................................... 72
Tactical Risk .................................................................................................................... 73
Operational Risk ............................................................................................................. 73
Th e Process of Risk Management .............................................................................................. 73
Information Security Program ......................................................................................... 73
Th reat Forecasting ............................................................................................................74
Incident Evaluation .......................................................................................................... 75
Risk Assessment ............................................................................................................... 75
Assessment Scope.................................................................................................... 75
Assessment Framework ............................................................................................76
Risk Quantum .........................................................................................................76
Raw Risk ................................................................................................................ 77
Risk Tolerance ................................................................................................................. 77
Avoid Risk .............................................................................................................. 77
Transfer Risk .......................................................................................................... 77

72  Information Security Management Handbook
Accept Risk............................................................................................................. 77
Mitigate Risk .......................................................................................................... 78
Control Objectives ........................................................................................................... 78
Selection of Controls ........................................................................................................ 78
Discretionary Controls ........................................................................................... 78
Mandatory Controls ............................................................................................... 78
Risk Treatment ................................................................................................................ 78
Development of Action Plan ................................................................................... 78
Approval of Action Plan ......................................................................................... 79
Implementation of Action Plan ............................................................................... 79
Risk Metrics .................................................................................................................... 79
Process Metrics ....................................................................................................... 79
Program Metrics ..................................................................................................... 80
Environmental Metrics ........................................................................................... 80
Control Attributes ........................................................................................................... 80
Maturity ................................................................................................................. 80
Weight .................................................................................................................... 80
Residual Risk ................................................................................................................... 80
Summary ...................................................................................................................................81
Introduction
Information security, as a subset of an organization’s overall risk management strategy, is a focused 
initiative to manage risk to information in any form. Risk management concepts, when applied to 
information risk, are readily managed within the context of an information security management 
system (ISMS). An ISMS is a process-based management approach and furnishes a framework to 
administer risk management processes.
Robust risk management processes identify and quantify areas of information risk and allow 
for development of a comprehensive and focused risk treatment plan.
A clearly deﬁ ned risk assessment methodology is a mandatory component in legal or regula-
tory compliance.
Th e corresponding risk treatment plan documents informed-choice decision making and 
organizational due diligence.
The Nature of Risk
Risk may be strategic, tactical, or operational.
Strategic Risk
Strategic risk is risk to the existence or proﬁ t of the organization and may or may not have infor-
mation security signiﬁ cance. Such risk includes regulatory compliance and ﬁ duciary responsibil-
ity, as well as risk to the revenue and reputation of the organization.



 Information Risk Management  73
Tactical Risk
Tactical risk is risk to the information security program’s ability to mitigate relevant strategic risk 
to information. Such program risk includes the ability to identify relevant regulations, identify 
and justify control objectives, and justify information security initiatives.
Operational Risk
Operational risk is concerned with the ability to implement the tactical risk-based control objec-
tives. Such risk includes budget, timelines, and technologies.
The Process of Risk Management
In its most basic form, the risk management process is closed loop, or iterative, providing a feed-
back mechanism for continuous process improvement (Figure 5.1).
Th e current ISO17799-3 standard addresses the application of this process as an information 
security technique. A process-based ISMS provides the framework within which to implement 
this technique.
Information Security Program
A comprehensive information security program should address strategic, tactical, and operational 
risk (Figure 5.2). An information security program is a strategic risk initiative, managed by a tacti-
cal risk-based ISMS. Th is structure allows ready identiﬁ cation and mitigation of operational risk. 
For example,
Th e scope of strategic risk is enterprisewide and focused on the risk-mitigating services 
required by the enterprise.
Th e scope of tactical risk is programwide and focused on the risk-mitigating processes 
required by the strategic services.
Th e scope of operational risk is based upon a discrete domain that stores, transmits, or 
processes information in any form. Th is domain-speciﬁ c risk is focused on the people, pro-
cedure, and products that integrate into the risk-mitigating process.



Figure 5.1 Risk management process.
Identify risk
Quantify
risk
Set scope
Address
risk
Mitigate
risk
Measure
performance
Figure 5.2 Step 1: Set scope.
Identify risk
Quantify
risk
Set scope
Address
risk
Mitigate
risk
Measure
performance

74  Information Security Management Handbook
An ISMS-based information security program is conducive to scoping and managing multiple risk 
domains while simultaneously identifying and maintaining both vertical alignment and horizon-
tal dependencies (Figure 5.3).
Threat Forecasting
Th reats are negative events that occur when a vulnerability or weakness is exploited. Th reat fore-
casting is a proactive process to predict future risk based upon identiﬁ ed or perceived vulnerability 
(Figure 5.4).
Th reats span the organization at all levels.
Th reats may be strategic, or enterprisewide, such as regulatory noncompliance.
Th reats may be tactical, based upon organizational vulnerabilities, such as ineﬀ ective programs.
Th reats may be operational, based upon technical vulnerabilities.
Th reat forecasting examines multiple information sources or sensors. Th reat sensors may include
Legal or regulatory analysts
Program reviews
Technical bulletins from vendors or analysts






Risk management policy
Information security program
Domain specific ISMS
Managed domains
Supporting security services
vision
Strategic risk
Tactical risk
Operational risk
Service 1
Service 2
Service 3
Service 4
Service 5
Call center
Server
room
Collection 
center
Server
room 2
Collection
center 2
Figure 5.3 ISMS-based information security program.
Figure 5.4 Step 2: Identify risk.
Identify risk
Quantify
risk
Set scope
Address
risk
Mitigate
risk
Measure
performance

 Information Risk Management  75
Th e potential rate of change to the threat environment must be considered and may drive the 
frequency of triggering the threat forecasting processes. For example, a strategic threat such as 
noncompliance with emerging regulations typically has a longer tolerable reaction time than an 
operational threat such as emerging technical vulnerabilities.
Incident Evaluation
Incidents are threats that have taken eﬀ ect, or in other words, a vulnerability has been exploited 
to cause an event resulting in an incident. Incident evaluation, although triggered reactively, is 
proactive because of the “lessons learned” that can be utilized to both identify the underlying vul-
nerabilities and predict the future probability of reoccurrence. Forensic, or “root cause,” analysis 
will illuminate technical and procedural weaknesses, and performance analysis will illuminate 
strengths and weaknesses.
Risk Assessment
Th e processes of threat forecasting and incident evaluation identify relevant threats and vulner-
abilities; however, relevant threats and vulnerabilities are not necessarily risks. Identiﬁ ed threats 
and vulnerabilities must be quantiﬁ ed to determine the existence and magnitude of risk within 
the applicable environment (Figure 5.5). Quantiﬁ ed risk allows for defensible prioritization of 
remediation eﬀ orts as well as informed-choice (defensible) decision making.
Assessment Scope
Strategic Assessment
Strategic risk assessments look at enterprise business processes that span multiple domains. Not all 
assessed business processes have information risk.
Tactical Assessment
Tactical risk assessments look at the ability of the information security program to identify and 
mitigate relevant strategic risk to information.
Operational Assessment
Operational risk assessments look at a domain’s ability to meet tactical control objectives in pro-
tecting speciﬁ c information assets. Technical vulnerability assessments are an example of a speciﬁ -
cally focused type of operational risk assessment.
Identify risk
Quantify
risk
Set scope
Address
risk
Mitigate
risk
Measure
performance
Figure 5.5 Step 3: Quantify risk.

76  Information Security Management Handbook
Assessment Framework
A risk assessment framework assists in maintaining structure during the risk assessment process, 
because it may be diﬃ  cult to make sense of the diverse collection of threats and vulnerabilities 
that ﬂ ows from “worst case” scenario brainstorming. A risk assessment framework allows both 
organization of thought and recognition of relationships among this diverse collection of threats 
and vulnerabilities. Starting with the premise that information risk is based upon breaches of con-
ﬁ dentiality, integrity, and availability, a risk assessment framework can be further subdivided into, 
for example, intentional and accidental components. Further subdivisions result in creation of a 
“threat tree” that allows organized “cataloging” of risk and enhances the ability to ask and analyze 
appropriate risk questions. For example
Th reat: Breach of conﬁ dentiality
Intentional disclosure
Vulnerability: Unvetted employees
Unintentional disclosure
Vulnerability: Unencrypted information
Vulnerability: Ineﬀ ective media disposal
Note the structured thought process resulting in discrete vulnerabilities being mapped to a com-
mon threat.
Risk Quantum
Risk quantiﬁ cation is based upon identiﬁ cation of relevant variables that are then incorpo-
rated into a risk-rating algorithm. A quantitative assessment requires much more eﬀ ort than a 
qualitative assessment, but may be necessary when, for example, using the resultant risk rating 
to make ﬁ nancial (quantitative) decisions. Typical qualitative risk quantiﬁ cation utilizes two 
independent variables, probability (likelihood) and harm (impact). Risk-rating algorithms vary 
in sophistication depending on the level of detail and accuracy required to be furnished by the 
assessment.
Probability
Probability may be seen as having three attributes. Total probability must take into consideration 
all aspects:
Frequency: How often the scenario can be expected to occur
Simplicity: Th e level of eﬀ ort required to create the scenario
Motive: Th e determination of the attacker
Frequency and simplicity are relevant for each vulnerability, whereas motive is relevant to the 
organization. For example, an externally facing ﬁ rewall has a high probability of penetra-
tion attempts (frequency) but a low probability of success (simplicity). A defense contractor or 
ﬁ nancial institution may generate more focused attention than a home personal computer user 
(motive).

−

−
−




 Information Risk Management  77
Harm
Harm is the impact successful execution of the event would cause the organization. Because harm 
is many times aligned to a particular tangible asset, another view sometimes used in risk assess-
ment is value, where value is perceived in terms of availability and harm perceived as absence. Th is 
view is more common in enterprise business process risk assessment.
Raw Risk
Th e identiﬁ ed vulnerabilities quantiﬁ ed through an algorithm (of your choice) utilizing the inde-
pendent variables of probability and harm constitute raw risk, or risk before the application of 
controls. Raw risk serves as a baseline for threat exposure, or risk environment. Raw risk also acts 
as the basis of “before and after” views, modiﬁ ed as controls are factored in to calculate residual 
(postcontrol) risk. An unacceptable level of raw risk serves as the justiﬁ cation for implementing 
mitigating controls.
Risk Tolerance
Having identiﬁ ed and evaluated the risks attached to speciﬁ c vulnerabilities, the risks must 
be addressed (Figure 5.6). Decisions on risk are based upon the organization’s risk tolerance
thresholds and include the following options.
Avoid Risk
Risk may possibly be avoided, for example, by relocating a data center.
Transfer Risk
Risk may be transferred to someone with a higher risk tolerance, for example, an insurance 
company.
Accept Risk
Risk may be accepted, although diligence requires care regarding
Who is authorized to accept what level of risk
How is risk acceptance based upon informed-choice decision making
Whether the aggregation of accepted risk remains tolerable



Identify risk
Quantify
risk
Set scope
Address
risk
Mitigate
risk
Measure
performance
Figure 5.6 Step 4: Address risk.

78  Information Security Management Handbook
Mitigate Risk
Risk may be mitigated to an acceptable level through the application of compensating controls.
It is not practical to eliminate risk completely, only to reduce risk to an acceptable level.
Control Objectives
Control objectives serve as the glue to bind speciﬁ c vulnerabilities to speciﬁ c controls. Deﬁ ning 
control objectives is the ﬁ rst step in deriving the corresponding control requirements to mitigate 
the risk associated with the vulnerability (Figure 5.7). Control objectives give a risk-based justiﬁ ca-
tion to allocation of resources.
Selection of Controls
Once control requirements have been derived from control objectives, tangible controls may be 
selected.
Discretionary Controls
Discretionary controls are controls that can weigh cost versus beneﬁ ts. In general, the cost of 
mitigating a risk needs to be balanced by the beneﬁ ts obtained. Th is is essentially a cost–beneﬁ t 
analysis on “at what cost” the risk is acceptable. It is important to consider all direct and indirect 
costs and beneﬁ ts, whether tangible or intangible and measured in ﬁ nancial or other terms. More 
than one option can be considered and adopted either separately or in combination. For example, 
mitigating controls such as support contracts may reduce risk to a certain degree, with residual risk 
transferred via appropriate insurance or risk ﬁ nancing.
Mandatory Controls
Mandatory controls diﬀ er from discretionary controls in that cost has no bearing on the selection 
of mandatory controls. Th ese are controls that must be implemented to mitigate speciﬁ c risks. 
Th ere may be no risk acceptance option due to legal and regulatory requirements, for example.
Risk Treatment
Development of Action Plan
Th e organization requires a treatment plan to describe how the chosen controls will be imple-
mented. Th e treatment plan should be comprehensive and should document all necessary infor-
mation about
Proposed actions, priorities, or time plans
Resource requirements


Identify risk
Quantify
risk
Set scope
Address
risk
Mitigate
risk
Measure
performance
Figure 5.7 Step 5: Mitigate risk.

 Information Risk Management  79
Roles and responsibilities of all parties involved in the proposed actions
Performance measures
Reporting and monitoring requirements
Action plans may have strategic, tactical, and operational components and should be in line with 
the culture, values, and perceptions of all stakeholders.
Approval of Action Plan
As with all management plans, initial approval is not suﬃ  cient to ensure the eﬀ ective implementa-
tion of the action plan. Senior management support is critical throughout the entire life cycle of 
the plan. By its nature, an ISMS is an empowerment vehicle for risk treatment, with clear trickle-
down authority documenting management support and authorization to the highest levels.
Implementation of Action Plan
An important responsibility of the action plan owner is to identify requirements and procure nec-
essary resources to implement the plan. Th is may include such tangibles as people, process, and 
products; the component parts selected to meet the required control objectives. In the event that 
available resources such as budgets are not suﬃ  cient, the risk of not implementing the action plan 
must ultimately be accepted by someone. Th e risk management model allows transference of risk to 
a willing risk acceptor, and the ISMS framework provides the means of transference.
A critical success factor (CSF) for the risk management process is to strategically reduce risk 
to an acceptable level. A key performance indicator is the tactical ability to reach this steady state, 
or equilibrium, through the judicious selection and deployment of eﬃ  cient and eﬀ ective controls. 
Operational metrics can be used to evaluate control eﬃ  ciency and eﬀ ectiveness.
Risk Metrics
Th ere are various types of risk metrics that may beneﬁ t the information security program
(Figure 5.8).
Process Metrics
A process by deﬁ nition has a CSF deﬁ ning the successful execution of the process. Th e CSF is 
evaluated via process key performance indicators. Key performance indicators are evaluated via 
process metrics. Whereas process design deals with process eﬀ ectiveness, process execution deals 
with process eﬃ  ciency. For example, a risk-mitigating operational “incident response” process 
(a reactive control) has been designed to be tactically eﬀ ective, but the performance indicators look 
at operational eﬃ  ciency factors such as “time to respond.”



Figure 5.8 Step 6: Measure performance.
Identify risk
Quantify
risk
Set scope
Address
risk
Mitigate
risk
Measure
performance

80  Information Security Management Handbook
Program Metrics
Program metrics typically measure process eﬀ ectiveness. Th ese tactical process eﬀ ectiveness met-
rics require a “history” against which to measure, with value being enhanced by history length. 
Th is type of evaluation is synergistic with maturity modeling, because maturity modeling is by 
nature history-based.
Environmental Metrics
Environmental metrics are of value when trying to evaluate an organization’s risk proﬁ le and resul-
tant risk strategy. For example, a response process (reactive control) may be triggered frequently, 
giving insight into the external environment. Th is metric says nothing about the eﬃ  ciency or eﬀ ec-
tiveness of the information security program, but may add justiﬁ cation to its existence or tactics.
Control Attributes
Controls in this context may be seen to have two independent attributes, maturity and weight.
Maturity
As risk treatment progresses, controls remain in varying degrees of maturity. Factoring in the 
maturity level of the various types of controls on a standardized scale allows one to quantify eﬀ ec-
tiveness in progress toward meeting control objectives and the resultant reduction of risk.
Weight
Th e following controls may be considered:
Directive
Preventive
Detective
Reactive
In some environments there is merit in weighting the value of a speciﬁ c category of control. For 
example, in a risk-intolerant environment such as the nuclear industry, a preventive control may be 
far more valued than detective and reactive controls and should be weighted accordingly.
Residual Risk
Residual risk is the risk that remains after risk treatment. Residual risk is derived from raw risk, 
with an algorithm typically utilizing risk-mitigating control attributes to modify the raw risk 
environment. Untreated residual risk is essentially de facto accepted risk. Because the objective 
of the iterative risk management process is to reduce residual risk to an acceptable level, the risk 
management process may require multiple passes to reach this goal. For example, a vulnerability 
management process that tracks the system patching life cycle may require multiple iterations 
before an acceptable residual risk of 5 percent unpatched (95 percent patched) is achieved.





 Information Risk Management  81
Summary
Information security is a focused application of risk management, managing risk to information in 
any form based upon the risk criteria of conﬁ dentiality, integrity, and availability. An information 
security program is hence a subset of an organization’s risk management program and is readily 
managed within the context of a process-based ISMS. ISMS and risk assessment frameworks add 
structure to the information security program, clearly delineating risk roles and responsibilities. 
A process-based approach is repeatable, defensible, and extensible, oﬀ ering metrics to optimize 
eﬃ  ciency and eﬀ ectiveness while reducing risk to an acceptable level.


83
Chapter 6
Department-Level 
Transformation
R. Scott McCoy
Contents
Introduction .............................................................................................................................. 83
Th e Strategic Vision .................................................................................................................. 84
Current State ....................................................................................................................85
Future Desired State .........................................................................................................85
Detailed Program Description ......................................................................................... 86
Guard Force ............................................................................................................ 86
Gap Analysis ............................................................................................................................. 87
Th e Business Case ..................................................................................................................... 88
Implementation ......................................................................................................................... 89
Measuring Department Performance ........................................................................................ 89
Budget ............................................................................................................................. 89
Customer Satisfaction ...................................................................................................... 90
Cycle Times ..................................................................................................................... 90
Worker Engagement ................................................................................................................. 90
Conclusion .................................................................................................................................91
Introduction
Th e main complaint among security professionals is that they lack the resources they need to do their 
job. Th ere are classes on metrics, strategy, how to sell a program to upper management, and even how 
to write a business case. What seems to be missing is a concise explanation on how all there ﬁ t together 

84  Information Security Management Handbook
with a step-by-step “how to.” Th is is an attempt to do just that, by fully explaining how the process 
works in detail and the pieces necessary to transform a department so that it can meet the particular 
requirements of an industry and company. Every day security managers, be they information technol-
ogy (IT) or corporate, are torn between conducting their daily work and trying to improve their pro-
grams. Time must be taken for the latter, or the former will never get better and may get a lot worse.
To change the current state of a department, there must be an honest and complete view 
of the department’s scope and its performance in accomplishing that scope. Th ere must be an 
understanding of what the current challenges are, whether they are threat-based or competition 
or regulatory, and an educated guess as to what the challenges will be in the next three to ﬁ ve 
years. Th e security professional must understand his or her own organization, from an operational 
detail level down to the internal politics and key players. Finally, security managers must know 
themselves and their staﬀ s’ strengths and weaknesses.
In 500 BC, Sun Tzu wrote, “If you know the enemy and know yourself, you need not fear 
the result of a hundred battles.” Some people ﬁ nd it odd to think of people in their own company 
as the enemy. Perhaps opponents would be better, but because there will always be fewer budget 
dollars than requested and because that budget is distributed between all departments, if one 
department’s budget is raised by even 5 percent, some other department is going to get less. Before 
going down the path to growing their department, security professionals need ﬁ rst to understand 
themselves, their department, and, at a minimum, the other departments that report to their boss. 
If there is time or if the security professional has been in place long enough, a thorough analysis of 
all noncore departments should be made. In this way, the outcome of a thousand budget battles, 
and make no mistake, they are battles, should not be in question.
Th e goal of this evaluation should not be to increase budget, because it is possible that, once 
complete, the analysis may point to either doing less or doing the current workload diﬀ erently, 
which may actually reduce spending. Th e odds are that few security departments overspend, but the 
point is not just to seek more money, because money without a plan is not a recipe for success.
Th e goal is to build a department that has a well-deﬁ ned scope of responsibility that will miti-
gate risk at the level the company is comfortable with and use the smallest amount of resources 
to accomplish that objective. It is hoped that these objectives will include things like recruiting, 
developing, and retaining qualiﬁ ed personnel. Th ere are several ways to approach this, including 
just throwing money at the situation, but good managers ﬁ nd ways to supplement the money (and 
it does take some money) and to motivate and engage workers without relying solely on a bunch of 
conferences, but this will be covered in more detail under Worker engagement.
Th ere are six steps in department transformation:
Strategic vision
Gap analysis
Th e business case
Implementation
Department performance
Worker engagement
The Strategic Vision
Th e strategic vision document should have three components: current state, future state, and a detailed 
description. Most departments have been around for a while and have some historical reasons for why 
they are conﬁ gured the way they are and how they do certain pieces of the job. Th ose reasons and 







Department-Level Transformation  85
origins may or may not be known by those currently in the department, but it is actually better if they 
are not. With knowledge comes emotion, especially if a well-liked current or former employee created 
a process that is still in use. In tackling the ﬁ rst step, creating a strategic vision for a department, it 
is essential to have a complete and realistic understanding of its current state. To accomplish this, 
break down the pieces of the department into functional areas and write down a few statements that 
describe them. Th e goal is not to be all negative or all positive, but describe each segment honestly. 
Th is may be diﬃ  cult, and if so, an outside consultant may be able to help. Outside perspective does 
not have to cost a lot of money; it could be an auditor from your own company or even a peer from 
another company, especially if they are willing to go through this same process.
It is important to stay current and to help explain things in a way upper management can 
quickly grasp. In a paper by Booz, Allen, and Hamilton titled Convergence of Enterprise Security 
Organizations, http://www.boozallen.com/publications/article/1439866, dated September 8, 2005, 
the areas in a converged department were broken into the functional areas of physical security 
(access control), corporate security (investigations), and IT security (network). Upper management 
has an easier time understanding the security areas when they are broken down into these major 
headings and all of the applicable components are listed under them with a bullet for each. It is also 
important to get input from department staﬀ , but it may help to complete a ﬁ rst draft. Th is will 
focus the input on the content and not waste time on format.
Th e next piece of the paper should be identical to the ﬁ rst (the current state) in format, but be 
called future state and have bullets that describe how you want the functional areas to either per-
form or be viewed. Th e last piece is a detailed description of your department scope. Th is section 
goes into a lot of detail that no one may read completely, especially your boss, but it is more for you 
or whoever has your job in the future. It is important to remember the drivers and the conditions 
under which you made your decisions. Th is section goes into a more detailed description of each 
program and has three or, depending on the industry, possibly four parts. Th ose parts are
Scope
Trends
Future plans
Regulatory considerations
Here is a generic example for reference only; any real description would be more detailed.
Current State
Guard force
High turnover (90 percent)
Minimal training
Poorly educated oﬃ  cers
Customer complaints
Existing coverage has no risk-based justiﬁ cation
Future Desired State
Guard force
Low turnover
First-responder training with continuing education





−
−
−
−
−

−
−

86  Information Security Management Handbook
Minimum requirements
Sites with coverage are determined by a risk-based assessment
Detailed Program Description
Guard Force
Scope
Th ere is security oﬃ  cer coverage at ﬁ ve locations. All oﬃ  cers are contracted with the Really Good 
Oﬃ  cer Co. and as of December 2007 the contract is in its third year of a four-year contract with a 
one-year extension clause. Security oﬃ  cers are unarmed and trained as ﬁ rst responders. Turnover 
is at 80 percent and a recent survey showed the oﬃ  cers are paid an average of $2 per hour less than 
at other companies in the area.
Trends
Current trends still show a preference for contract security oﬃ  cer coverage, though the quality of 
oﬃ  cers and corresponding increase in pay suggest that many companies are expecting more from 
their oﬃ  cers in education, training, and professionalism.
Future Plans
Assess the current level of coverage, both for where oﬃ  cers are posted and for what else we may 
require of them. Send out a request for proposal (RFP) when the contract expires and put forth a 
scope that will meet the evolving needs of the company.
Regulatory Considerations
Although there are currently no regulations requiring security oﬃ  cer coverage at critical sites, add-
ing such coverage may either help avoid or minimize the intensity of new regulation.
A ﬁ ve-year plan is common because it is far enough into the future that there is time to make 
changes but not so far out that your plans could fall apart due to too much change. Th is is a good 
time to get some perspective from both upper management and direct reports. Th ink about all of 
the issues that are currently impacting the department and try to put the issues in perspective.
Th is is a golden opportunity for security professionals to prove they are business managers 
ﬁ rst and security professionals second. It is the security practitioner’s responsibility to protect the 
company, but it is not possible or cost-eﬀ ective to attempt to mitigate all risk. Some risk, especially 
with lower impact, must be accepted.
When going through this exercise, try not to limit the analysis within the conﬁ nes of the 
department’s current scope. Ask the tough questions, like whether the security department would 
be the best place to perform other tasks currently provided by another department, and the con-
verse, whether another department would be the best place for some work currently being done 
by the security department. Not everyone believes in the convergence of IT security and more 
traditional security roles. Look beyond preference and bias and determine if the company would 
beneﬁ t before ignoring it outright. As an example, what about background checks? A survey 
in the Institute of Management and Administration’s July 2006 edition of Security Director’s 
Report showed that 89 percent of companies responding had background screening conducted by 
−
−

Department-Level Transformation  87
Human Resources (HR) and not Security. One of HR’s main functions is to bring people in, not 
to keep people out. Keeping people out is something Security excels at, so which department is 
better equipped to perform background screening?
Every company’s experience will be diﬀ erent and it may take several drafts and about three 
months, with about two to four hours of work a week, to complete. Th e time spent will be worth 
it, because it will be the basis for the transformation.
Once completed, remember that this is only the ﬁ rst step. Th e next step is to complete a gap 
analysis between current and future desired state. Th is analysis will determine what will be done 
diﬀ erently, how it will be done, what staﬀ  will be needed, and what skills the staﬀ  will need to be 
successful. Th is may include new policies, new products, new people, and new partners. Try not 
to rush toward a solution at this point, stay focused on identifying the gaps for now.
Using the previous guard force example, the gap analysis between current and future state 
might be
Last RFP lacked minimum requirements for oﬃ  cers or performance measures for the 
contract
Low pay for oﬃ  cers compared the rest of the region
Lack of companywide business impact analysis or enterprisewide risk assessment to identify 
critical sites
Be careful not to try to solve the problems in the gap analysis as it is created. Th e way to get bet-
ter qualiﬁ ed and better skilled oﬃ  cers is a more obvious problem to solve than most people will 
ﬁ nd, but none of the problems should be diﬃ  cult to solve. Without this exercise, you may be able 
to come up with solutions to individual problems, but without the discipline the exercise requires 
you may not capture everything that needs to be improved. You may also not get wholesale sup-
port from your management if you bring items to them piecemeal. Department heads should be 
able to think strategically, and even if it is easy for you to see the total picture, as with algebra, it is 
important to show your work to get credit or, in this case, buy-in from upper management.
Th e solution to guard oﬃ  cer coverage is deﬁ nitely not complex, but in the course of gather-
ing data there will be a need to put together something more than opinion. Gather the facts that 
will help put together the business case, and bring upper management along the way during the 
process so the business case will not be new to them when it is presented.
Gap Analysis
Now that there is a strategic vision with buy-in from upper management, it is time to determine 
how to get from point A to point B.
Th e ﬁ rst step is to complete a gap analysis between the current and the future. Once the gaps 
are described, ask some questions:
Do I have all the programs that I need?
Do the programs I currently have in place meet the objectives?
What are the outcomes or work products that need to be routinely produced by my depart-
ment in the future scope and how many hours does it take to accomplish them?
Risk assessments
Giving security awareness training
Background investigations






−
−
−

88  Information Security Management Handbook
Creating or revising site-speciﬁ c security plans
Conducting penetration tests
Auditing security settings
What is the average number of unscheduled items per year and how many hours does it take 
complete them?
Investigations
New application assessments
Computer incident response team events
Supporting audits
Do I have the right position descriptions to get the work done?
Do the current staﬀ  have the right skill sets?
Do I have the right number of people?
Is there a way other than traditional staﬃ  ng to accomplish my objectives?
Th is takes a lot of analysis, but it is worth the work, because only by doing this level of analysis 
can someone fully understand what a speciﬁ c company needs from its security department. Th ere 
is nothing wrong with ﬁ nding a consultant to help with this process.
Th e outcome of the gap analysis will be a work plan, which can be as simple as a table that 
shows the milestone dates and success measures. Th e ﬁ nal step will be to prioritize the work plan 
into a multiyear format that organizes the steps in the order necessary to execute.
When this process is started, it is impossible not to have certain preconceptions, but realize 
that the ﬁ nal result may be diﬀ erent. Also remember that this is a living document; when things 
change it is important to reevaluate the portion aﬀ ected by that change and perform a new gap 
analysis. Th e gap analysis may identify the need for several things or potentially nothing if there 
is no need for change. If any of the things needed require more money, it will most likely require 
a business case to get.
The Business Case
All of the documentation that was created during the process of ﬁ guring everything out needs 
to be kept, but this documentation is not the business case. Th ese are documents that the data is 
drawn from. Every company does things diﬀ erently and business cases are no exception. Some 
companies have elaborate formats that resemble novellas, some have only one page, and most 
have no format at all. Th e one-page business case has a lot of appeal, but it can be a challenge to 
articulate all of the justiﬁ cation with so few words. Breaking down all of the pieces needed for a 
department transformation into separate cases, like guard force management as one and depart-
ment reorganization as another, is recommended over trying to change it all at one time. Also try 
not to present more than two business cases a year that have a signiﬁ cant ﬁ nancial impact.
Th e relationship between a department head and the next level of management will determine 
how much prep work and socializing for the business case are necessary. Th is is the most diﬃ  cult 
area to give advice on, because every situation is so diﬀ erent. If the relationship between depart-
ment head and upper management is new or in question, seek advice from a trusted mentor in the 
organization. Whether advice is available or not, it is important to determine what motivates the 
next two people in the chain of command. Th is is critical when communication of the change is 
created. In some cases power points and a high-level executive summary will do the trick; in others, 
more detail is required. Th e higher up the case goes the less detail should be needed if there is trust 
in the chain of command. Usually the next level is the hardest audience, but this is not always so.
−
−
−

−
−
−
−





Department-Level Transformation  89
Implementation
Th e implementation plan will most likely be a multiyear prioritized work plan that is broken down 
into logical and measurable milestones. Because there could be many steps between the current 
state and the ﬁ nal desired state, it is important to lay out all of the steps for all of the initiatives 
and spread them out over a few years, especially where budget dollars will be required. Some of 
the initiatives must be done ﬁ rst, so the order in which the work is laid out is important, both 
within each initiative and between the initiatives. Some actions can and should be done in paral-
lel, whereas others are by their nature linear and dependent on others to be completed ﬁ rst. Make 
sure not to take on too much in any given year, because the departmental workload must also be 
completed during the transformation; this is the most common mistake made by any team.
Measuring Department Performance
Most companies run their businesses by facts: What services do they provide or what products do 
they make? How much can they charge for their product or service? Can they make new products 
or perform new services? Should they do it better or cheaper than the competition? Every bit of 
spending in a company is broken down into two categories: cost of goods (COGs) and overhead. If 
it is a manufacturing company, then all the raw materials, the electricity to run the machines, and 
the salaries for the labor to produce the product are COGs. Everything that does not contribute 
directly to the creation, storage, distribution, and sale of the product is overhead. Security is not a 
core part of any business except a security business. Security is overhead. Th is does not mean that 
it is not important, but being important also does not make security core. Th e loss of an IT or 
corporate security department to a business would exceed the cost of that department, but because 
most companies already have these departments and have had them for some time, it is very dif-
ﬁ cult to prove. So, security is seen as a necessary evil at worst and a valuable asset at best. Th e 
best way to move toward the perception as a valuable asset is to show the value in business terms. 
Retail companies have loss prevention departments that measure the percentage of shrinkage and 
can show the eﬀ ectiveness of their programs by how they can reduce the amount of shrinkage. 
A combination of preventative and reactive programs must be in place and deployed with skill. 
Other companies that have more traditional security departments have programs that are more 
diﬃ  cult to quantify. All of these programs, as well as all other work products and services, should 
be measured.
Th ere are two types of measures: those that you can set performance targets to and those that 
you cannot. Th e measures you should not set targets on are things like number of thefts per year. 
Th is is work volume and should be tracked, but speciﬁ c targets on metrics you cannot predict 
or directly aﬀ ect are demotivating and counterproductive. Even if a company does not require 
measuring the performance of its security department, that department should at a minimum 
keep track of workload like how many investigations were conducted, alarms monitored, people 
escorted, guard tours conducted, etc. Th is data will be invaluable in building a case to increase 
staﬀ  or to defend existing levels.
Budget
Th e measure of successful budget performance is not simply to avoid spending more than the bud-
geted amount by the end of the year. You must also be able to forecast your spending accurately 

90  Information Security Management Handbook
from month to month. A valid measure for operating expense is to be able to forecast one month 
in advance, within ±5 percent, what the actual spend of operating dollars will be. Capital projects 
are more dynamic and may have a forecast target of ±10 percent. Th e second measure might be 
not to exceed the budgeted amount by the end of the year, because this also has a direct impact 
on earnings for the company.
Customer Satisfaction
Measuring the satisfaction of customers, or even the idea that security departments have custom-
ers, may be a foreign concept to some security professionals. Security departments are internal 
service providers who directly and indirectly support the core operation of their company in doz-
ens of ways. Th e key is to identify these services and then to gauge the satisfaction of, at least, 
supervisors and above with the delivery of those services. Doing a survey around investigations 
is not recommended, but granting access control or completing a background check or issuing a 
badge all take time and cost money, so most likely the customers want these things to be done 
more quickly or cheaper or possibly more accurately.
Th e ﬁ rst step is to issue an annual survey asking for overall satisfaction and speciﬁ c 
satisfaction around key services. Make sure it is anonymous and that there is a space for 
comments. Be warned, if this is the ﬁ rst time customers are asked for feedback, the ﬁ rst survey 
results and comments may be a little hard to read. Th e results of this survey can be used as sup-
porting documentation for your business case and even to spark ideas for the ﬁ ve-year strategy.
Cycle Times
How fast services are provided can be a large source of dissatisfaction if the perception is that 
they should be faster. Time to issue a company ID, time to complete a background check, time 
to issue a new laptop, time to grant logical access, or time to roll out a new application—all of 
these things frustrate customers and damage credibility when the perception is that the services 
provided take too long. Sometimes this is because the services are too slow, but other times it is 
a matter of adjusting the expectation of the customer through honest and open communication. 
To be successful and get voluntary cooperation with security policies, a security department must 
have credibility at a minimum, and treating customers with respect and meeting performance 
commitments is a large step toward gaining that credibility.
Worker Engagement
Th e fact is, the employees are the ones that get the work done and can either make or break the 
strategic initiatives that have been agreed upon. Every manager should devote the appropriate 
amount of time to employee engagement for the culture of his or her company and department, 
which varies greatly by industry and country. Th e ﬁ rst thing to do is to determine the current level 
of engagement. Th ere is a standardized survey provided by Gallup that many companies use to 
measure the level of engagement of a company’s workforce. It is backed up by years of research 
that shows a direct correlation between an increase in engagement scores over time with a decrease 
in workplace injuries and an increase in productivity and earnings. It is possible to come up with 
a company-speciﬁ c survey, but regardless of how it is done, there should be some way to measure 
engagement to track if actions taken to aﬀ ect it positively are working.

Department-Level Transformation  91
Areas that should be given focus are
Having a formal development plan for all workers
Continuing education
Cross training for advancement or to build depth
Development of management skills where appropriate
Giving recognition when it is earned (it is not recommended to mandate a program as that 
seems to take the value out of it)
Inclusion of workers in strategic and annual planning
Team building events, if appropriate
Having at least two levels for individual contributor positions so workers have a path for 
advancement
What employee engagement boils down to is caring about the well-being of the workers and 
expressing it professionally through word and deed. It is also about having an atmosphere of trust, 
in which people know they can survive a mistake and they are not afraid to express their opinion. 
As with all things, the ﬁ rst time an opinion is measured, be it on this or customer satisfaction, 
the scores are artiﬁ cially low. If this is the ﬁ rst time a group is asked, they have years of issues that 
come boiling out. Th e key is to know this going in and be prepared for it. Th e most important 
thing that to do once something is measured is to take action on the outcome of the survey. If no 
actions are taken, it is worse than if there had never been a survey, because there is an expectation 
of potential change associated with being asked an opinion in such a formal way. It is not practical 
to ﬁ x everything, but it is important to put forth eﬀ ort and take reasonable steps to improve one 
or two of the highest priority issues as ranked by the workers. Th e action planning from the sur-
vey data is best accomplished with an outside facilitator and the workers for the surveyed group 
(no more than 20; if larger break the group up). Th e “boss” should not be in the room, because 
even bosses are human and have a hard time not being defensive, whereas workers have a hard 
time opening up in the presence of their boss.
Conclusion
It is extremely helpful to have someone in the department with project management experience. If 
no such person exists, it may be necessary to get someone on board or use the services of a consul-
tant. Because every department will have completely diﬀ erent gaps and challenges, it is impossible 
to give a more detailed description, other than to say that it may take less or more time than ﬁ ve 
years to get from point A to point B, especially with course corrections along the way as things 
within the environment change. Once started, the journey is not meant to be locked on cruise 
control; remember that the destination itself may look completely diﬀ erent from that originally 
envisioned and that the destination is not ﬁ nal. Once the original transformation has been com-
pleted, it is likely time to begin the process all over again.
Th e things that deﬁ ne a security department as successful or unsuccessful are department’s 
capacity to prevent where possible, respond eﬀ ectively when required, and aid recovery to nor-
mal operations as quickly as is practical. Th is is the same whether there is a denial service attack, 
the intrusion of malware, or an actual disaster. To accomplish these goals, the people in the 
department must know the security requirements that are unique to their industry and design a 
department that is appropriately organized, staﬀ ed, and funded to meet the evolving challenges 
that are speciﬁ c to that organization. Even within the same industry, with similar threats, there 

−
−
−





92  Information Security Management Handbook
are diﬀ erences that must be accounted for. Th is can be done eﬀ ectively only if the people in that 
organization take the time and eﬀ ort to perform the detailed analysis that is required for strategic 
planning. Once this is accomplished, the department members must also have the skills and abili-
ties needed to execute those plans. A department should not ask for more dollars than is required 
to accomplish the mission, and if it is accomplished for less, then the sum must be returned. Th ese 
are security departments, whether they are IT or corporate, and as such will always be seen as cost 
centers ﬁ rst. Only by building a reputation of integrity and competency in business can a depart-
ment rise to its full potential.

93
Chapter 7
Setting Priorities in Your 
Security Program
Derek Schatz
Contents
Introduction .............................................................................................................................. 93
Levels of Maturity of a Security Program .................................................................................. 94
Key Questions to Help Assess Security Maturity ...................................................................... 95
Characteristics of Security Program Maturity ........................................................................... 97
Maturity Level 1 .............................................................................................................. 97
Maturity Level 2 .............................................................................................................. 98
Maturity Level 3 ............................................................................................................ 100
Maturity Level 4 .............................................................................................................101
Setting the Right Priorities ......................................................................................................103
Maturity Level 1 .............................................................................................................103
Maturity Level 2 .............................................................................................................104
Maturity Level 3 .............................................................................................................105
Maturity Level 4 .............................................................................................................107
Conclusion ...............................................................................................................................107
Introduction
A well-run information security program provides a structured approach to the management of 
risk to an organization’s information technology (IT) infrastructure and the information that it 
handles. In a typical business that continually faces new threats, the information security  managers 
must ensure that they focus their eﬀ orts and budget money on the right initiatives and tools to 

94  Information Security Management Handbook
gain the greatest risk reduction for the business at the least cost. Th is is not an easy task, as these 
decisions must be made in the face of a number of signiﬁ cant challenges.
Security spending is continually scrutinized by an organization’s management for business 
value, requiring the security manager to become adept at justifying spending in business-
relevant terms.
Certain risks may increase rapidly in importance in the middle of a budget cycle, requir-
ing reallocation of funds. An example of this may be an important new R&D project that 
requires extra protections against industrial espionage and the resultant loss of highly sensi-
tive intellectual property.
Security must overcome the reputation of being the group that says “No” and acting as a 
roadblock to new IT initiatives and instead be the group that says, “Yes, but let’s do it this 
way so risk is reduced.”
Increasing regulatory compliance requirements threaten to absorb the entire security budget.
Diﬃ  culty in attracting and retaining skilled information security personnel can introduce 
risk that security projects will not be completed as planned or with adequate quality.
Internal political issues and turf battles may hinder the implementation of new processes 
and tools.
A major security breach may call the eﬀ ectiveness of the entire security program, and even 
the competence of the security manager, into doubt.
For many information security professionals, one of the greatest attractions to the ﬁ eld is that there 
is always something new going on: new threats, new technologies, new business initiatives, new 
regulations. Th is is often one of its greatest frustrations also, as it is impossible to ever achieve a 
state of perfect security in which all risks are mitigated to a level that is acceptable to the business. 
After all, “security is a process, not a product.” Th e security manager must constantly reevaluate 
the risk environment, gain agreement from the business side on risk prioritization, and adjust the 
focus of his or her program as needed to address new threats and requirements as they arise. But 
the end objective should not simply be to reduce information risk in the organization—this is 
the objective of a merely good security program. Rather, it should go beyond that, enabling the 
business to take on new ventures to increase revenue and shareholder value that would be too 
risky without an eﬀ ective security program in place. It is this that makes a security program great, 
makes it invaluable to the business, and earns it a place at the big table.
Th is chapter looks at some guiding principles for security managers to follow when deciding 
on priorities for their organization’s security program. As will be seen in the following section, 
however, priorities depend on the program’s maturity.
Levels of Maturity of a Security Program
As with Carnegie Mellon’s Capability Maturity Model Integration (CMMI®) for process improve-
ment in software engineering, security programs go through phases of maturity that are based on 
how well policies and processes are documented, how broadly they are adhered to across the busi-
ness, how well their eﬀ ectiveness is measured, the level of support from senior management, and 
how developed the security infrastructure is. Th e IT Governance Institute® and the Information 
Systems Audit and Control Association also publish a security governance maturity model as part 
of the Control Objectives for Information and Related Technology (COBIT®). Understanding 








Setting Priorities in Your Security Program  95
where an organization stands on such a scale is important for a security manager new to the job, 
because initiatives that would be successful in a more mature program would likely fail in one 
that is less mature. For example, developing a strategic plan for security is more likely a fruitless 
eﬀ ort in an organization that suﬀ ers regular security breaches because of inadequate infrastruc-
ture protections. Th e focus in such a situation must be to stabilize the environment so that the 
security manager can begin to look beyond the purely tactical responses, becoming proactive and 
not purely reactive. It should be clear that an organization at the lower levels of security program 
maturity will be challenged to manage risks to its information assets eﬀ ectively and will therefore 
have a hard time demonstrating business value. But achieving and maintaining the highest levels of 
maturity are very diﬃ  cult and require substantial dedication on the part of the security team and 
very strong support by the organization’s leadership.
CMMI uses ﬁ ve levels, and COBIT uses six, but for purposes of this chapter, a simpliﬁ ed 
model with four levels is presented. For each level, 12 major areas of concern that are good indica-
tors of an organization’s security program maturity are used as the basis for assessment. Note that 
there is some correlation between an organization’s size and its maturity level—as an organization 
grows, ignoring or simply underfunding security becomes increasingly perilous as information 
risks become unmanageable. In addition, there are few large companies that are not publicly 
traded and therefore subject to Sarbanes–Oxley (and likely a raft of other regulations), which 
requires implementation of a solid security program and system of internal controls. Yet on the ﬂ ip 
side, there are many smaller privately held companies that face signiﬁ cant risks due to the nature 
of their business but lack a more mature program to manage them eﬀ ectively.
Before looking at the characteristics of the maturity levels, a sampling of key questions that can 
help in an assessment of maturity is provided in the following section. In general, the hallmarks of 
a mature program are strong management support earned through credible activity, adherence to 
repeatable processes with measurable feedback loops, and the ability to respond and adapt rapidly 
to a changing risk environment.
Key Questions to Help Assess Security Maturity
 
1. Security policies
 
1.1. Has the organization created and published security policies, standards, guidelines, 
processes, and rules?
 
1.2. Has a control framework been deﬁ ned and implemented for regulatory compliance 
(or other) purposes?
 
1.3. Is the organization’s information labeled as to its sensitivity and criticality to the busi-
ness, and do policies clearly state the roles and responsibilities for its protection?
 
2. Management support
 
2.1. Does senior management recognize the importance of information security and com-
municate this to the rest of the company, perhaps based on a communications plan 
created with the security department?
 
2.2. Are budget requests for security given due consideration when funds are being allocated?
 
2.3. Does the security function report into an appropriate place in the organizational 
hierarchy?
 
3. Security integration into the system development life cycle (SDLC)
 
3.1. Are security experts involved in new system development or implementation projects 
from the beginning?

96  Information Security Management Handbook
 
3.2. Are design reviews conducted on security features of new systems?
 
3.3. Are new systems and applications tested for security standards compliance before being 
released into production?
 
3.4. Are programmers trained in secure coding practices?
 
4. Security personnel
 
4.1. Do dedicated information security staﬀ  positions exist, and are the people in those 
roles adequately skilled?
 
4.2. Are training funds allocated to training to keep those skills current?
 
4.3. In a distributed/federated environment, does security management exert suﬃ  cient 
inﬂ uence over personnel in other areas who perform security functions?
 
4.4. Are security experts sought out by others in the organization for advice and counsel?
 
5. Security infrastructure and tools
 
5.1. Are the right tools in place to perform functions such as malware detection and removal, 
ﬁ rewalling, intrusion detection, encryption of data at rest and in transit, identity man-
agement, strong authentication, spam ﬁ ltering, and patch management?
 
5.2. Do security personnel have the time and skills to conﬁ gure and operate these tools 
properly?
 
5.3. Is the organization’s network designed for security?
 
5.4. Has a reference architecture for security been deﬁ ned and documented?
 
6. Th reat and vulnerability management
 
6.1. Is a comprehensive view maintained of the organization’s vulnerabilities?
 
6.2. Are discovered vulnerabilities prioritized, tracked, and ﬁ xed?
 
6.3. Are patches quickly tested and applied to the organization’s systems after they are 
released by the vendor?
 
7. Conﬁ guration management
 
7.1. Are system conﬁ gurations change-controlled?
 
7.2. Is a limited group of speciﬁ c individuals authorized to make changes to production 
systems?
 
8. Access control
 
8.1. Is network and system access strictly limited to only those with a business need for it?
 
8.2. Are user accounts disabled or deleted immediately after employees leave the organization?
 
8.3. Are standards for password strength enforced?
 
8.4. Are strong authentication mechanisms used on the most sensitive and critical systems?
 
8.5. Are system access logs regularly monitored for unusual activity?
 
9. Audits and assessments
 
9.1. Are outside ﬁ rms hired to conduct security assessments on at least an annual basis, and 
are the ﬁ ndings from those assessments acted upon?
 
9.2. Is there a close working relationship between the internal audit and the information 
security departments?
 
9.3. Do audits incorporate requirements for regulatory compliance?
 10. Business continuity
 
10.1. Have business impact assessments (BIAs) been conducted?
 
10.2. Does a comprehensive documented business continuity and disaster recovery plan 
(DRP) exist?
 
10.3. Is the plan exercised annually for training and test purposes?

Setting Priorities in Your Security Program  97
 11. Incident handling
 
11.1. Has an incident response (IR) process been documented?
 
11.2. Have key personnel been trained on this process?
 
11.3. Are there regular drills to reinforce the training?
 
11.4. Are outcomes and lessons learned from previous incidents used to improve the process?
 
11.5. Has management provided clear direction as to involvement of law enforcement on 
incidents?
 
11.6. Is there adequate technical expertise available either in-house or on contract for foren-
sic analysis?
 12. Training and awareness
 
12.1. Is there an employee security awareness program in place?
 
12.2. Do employees understand their roles and responsibilities in helping to maintain the 
security of the organization and protect its information assets?
Characteristics of Security Program Maturity
Th e following sections describe characteristics of security programs at each of the four levels of 
maturity deﬁ ned in this chapter. Note that organizations will not typically exhibit all of the char-
acteristics within a given level. Instead, they may be more advanced in some, less in others. It of 
course depends on what areas have been emphasized to that point in time.
Maturity Level 1
At this level, there is really no security “program” to speak of. Organization management has paid 
little to no attention to information security matters, and information protection activities are 
conducted in an entirely ad hoc manner. Note that in today’s environment of pervasive threats and 
ever-expanding regulatory requirements, there are fewer and fewer organizations still operating 
primarily at this level. Characteristics of the following categories include
Security policies. No documented policies exist, and procedures for security tasks are entirely 
ad hoc and nonrepeatable. Security failures reoccur due to lack of understanding of the 
security impact of staﬀ  activities. No distinctions are made in the value of the organization’s 
information assets.
Management support. Management pays little or no attention to the subject of information secu-
rity, and there is no separate budget for security activities apart from general IT (because there 
is no separate manager for such a budget). Staﬀ  performing security functions are buried at 
the lowest levels of the IT hierarchy, exhibit little to no understanding of what is important 
to the business, and are focused solely on technical matters such as ﬁ rewall conﬁ guration 
and user account management. Business management views information security as a cost of 
doing business that does not produce measurable beneﬁ t. Note, however, that this situation is 
increasingly rare and approaching nonexistence in large or publicly traded companies due to 
regulatory requirements for security that have visibility at the level of the board of directors.
Security integration into the SDLC. Information security is not involved in the development of 
new systems and at most is asked to rubber stamp the move of new systems into production. 
Systems developers and programmers are unfamiliar with the concepts of secure program-
ming and therefore produce applications rife with security vulnerabilities.

98  Information Security Management Handbook
Security personnel. Th ere are no personnel dedicated to information security in the organiza-
tion. Security functions are performed as just another “hat” worn by someone in the lower 
levels of the IT systems administration staﬀ . Lack of training means these individuals are 
unfamiliar with the key requirements of these functions.
Security infrastructure and tools. Only the bare minimum of tools is deployed on the organiza-
tion’s network, typically a ﬁ rewall and some antivirus, that is not updated regularly. Perhaps 
the ﬁ rewall has been conﬁ gured by someone untrained in its operation, leaving holes open 
for exploitation from the Internet. Lack of thought about security in the network design cre-
ates yet more holes from branch oﬃ  ces or connected business partners. Wireless local area 
network (LAN), if used, is uncontrolled and unsecured.
Th reat and vulnerability management. Because there is little common understanding of where 
the organization’s critical assets are housed, vulnerability information cannot be prioritized 
and therefore patches cannot be, either. Application of patches to systems is irregular and 
in many instances is far behind. Th is allows further exploitation and damage to systems by 
hackers and malware, thus causing additional downtime as systems must be cleaned up and 
restored to operational status.
Conﬁ guration management. Developers have unfettered and unmonitored access to produc-
tion systems, and the ﬂ ow and control of systems from development to test to production 
are uncontrolled and unstructured. Changes to systems are ad hoc and untracked, and 
downtime results from unauthorized and untested changes.
Access control. More active user accounts exist on systems for past employees than for current 
ones. Authentication mechanisms are weak, and employees are uneducated about using good 
passwords. No password policy exists to force regular changes to passwords, and employees 
often write their passwords on a sticky note left on their monitor. No monitoring of access 
logs is performed.
Audits and assessments. No outside assessments of the organization’s security posture are per-
formed, and ﬁ nancial audits pay little attention to information security issues.
Business continuity. No business continuity plan or DRP exists. Little attention has been paid 
by management to the possibility of a business-ending catastrophe. No BIA has been con-
ducted to identify the critical information assets of the organization.
Incident handling. Response to security incidents is entirely ad hoc and inadequate and is con-
ducted by untrained staﬀ . Unfortunately for a level 1 organization, incidents are frequent, so 
staﬀ  spend a great deal of time cleaning up malware outbreaks and system intrusions.
Training and awareness. No security awareness program has been created, and therefore 
employees are unfamiliar with what is expected of them in protecting the organization’s 
information assets.
Maturity Level 2
At this level, a basic security program has been established. Management has some awareness of 
security issues, but mostly in a reactive sense, for example, a virus outbreak has underscored the 
need to keep the desktop antivirus software current. Characteristics include the following:
Security policies. Some basic policies have been created, such as for employee e-mail use. Key 
systems containing business-critical data have been identiﬁ ed but not fully documented; 
they receive more protection attention than other systems.

Setting Priorities in Your Security Program  99
Management support. Management is aware of security issues and views some level of security con-
trol as desirable to reduce downtime and protect company information assets, although security 
spending as a percentage of the IT budget still trails industry norms. Management does not 
lead by example, nor does it communicate its support broadly across the organization. Th is is 
primarily due to security personnel having diﬃ  culty framing security issues in business terms.
Security integration into the SDLC. Security is involved in the test phase of system development 
and has some opportunity to require ﬁ xes before systems go into production. Some devel-
opers have had training on secure programming methods, but are not consistently held to 
documented security standards.
Security personnel. Management has funded at most a few full-time security staﬀ  positions in 
the IT organization to focus on security issues. Key IT personnel have had some security 
training and understand the implications of some key risk areas.
Security infrastructure and tools. A set of tools has been implemented in the organization’s 
network and computer systems, although some gaps still exist that could allow signiﬁ cant 
damage from an attack. Antivirus is updated automatically, and network intrusion detection 
sensors have been deployed on some key segments, although they are not tuned well and 
the alerts generated are often ignored due to administrators’ experiences with high levels of 
false-positives. Filtering of traﬃ  c has been implemented on business partner connections.
Th reat and vulnerability management. Th e identiﬁ cation of the organization’s key systems has 
enabled some rudimentary prioritization of patching activity, although it often happens that 
Web servers on the perimeter get less attention than an internal database server despite the 
fact that they are exposed to greater threats. Critical patches get applied, albeit too slowly 
because of continued use of manual processes.
Conﬁ guration management. Developers still have access to production systems because they 
are the only ones who understand how to ﬁ x the applications those systems are running, but 
at least they have to ﬁ rst get approval to do so from the IT operations manager. Downtime 
is reduced but still happens due to incomplete testing, perhaps because of a lack of good 
integration testing.
Access control. User log-in accounts are somewhat better controlled, but many accounts are still 
not deactivated in a timely manner, perhaps only monthly or quarterly. Some guidance on 
selection of good passwords and protection of them has been given to employees, but enforce-
ment of password quality is spotty across systems. Some key systems use strong authentication 
for administrative access. Access logs on critical systems are monitored manually.
Audits and assessments. An outside ﬁ rm is brought in to conduct annual security audits and 
assessments, but the report never makes it above the IT manager or director level, as the 
security holes it enumerates would be too embarrassing. Some signiﬁ cant issues remain still 
unﬁ xed on subsequent reports.
Business continuity. A basic DRP for IT systems has been created, but never tested. Perhaps a 
recovery center contract has been signed with a vendor. But senior management has not paid 
much attention to the issues involved with business recovery. Data backup tapes are rarely 
tested for restorability, if ever.
Incident handling. A basic process for incident handling has been documented and a few key 
team members have received some training. But no formalized team has been created, and 
frequent security incidents often result in ad hoc panic-driven responses.
Training and awareness. Security awareness eﬀ orts are rudimentary and infrequent. Many 
employees are still unaware of key safe computing behaviors, which means that malware 
outbreaks still happen with some regularity.

100  Information Security Management Handbook
Maturity Level 3
At this level, the security program is running fairly well and has the support of the organiza-
tion’s management. Tactical response is mostly under control, allowing the security manager to 
focus more on strategic eﬀ orts. Areas where initial capital expenditures will result in ongoing 
reduction in operating costs are identiﬁ ed. However, gaps still exist and some processes are still 
too labor intensive because of the lack of good tools to automate them further. Characteristics 
include the following:
Security policies. A comprehensive set of policies, standards, and guidelines has been developed 
and promulgated across the organization. Compliance is monitored in some areas but not 
in others, resulting in increased risk (as well as increased scrutiny by auditors). Some areas 
could use more eﬀ ective enforcement tools, perhaps a Web-traﬃ  c monitoring tool to detect 
users violating a policy against sharing of copyrighted media.
Management support. Th e security budget is within industry norms. Management has a good 
understanding of the information risks that face the business and therefore fully supports 
a solid security program. Management also takes many opportunities to voice support for 
security to the rank and ﬁ le. Security management provides regular reports of metrics and 
status to the chief information oﬃ  cer (CIO) or other senior management.
Security integration into the SDLC. Security is regularly involved in the development of 
new systems from the beginning, and has the ability to escalate security issues prior 
to production deployment. A process for risk acceptance of noncompliant systems has 
been implemented. Most developers have received some training in secure development 
methods.
Security personnel. A dedicated security team of multiple experienced and certiﬁ ed individuals 
exists, led by a senior manager or even a chief information security oﬃ  cer. To attract and 
retain talent, compensation is on the upside of industry averages. Achievement of security 
objectives is assisted by key people in other departments.
Security infrastructure and tools. Tools have been deployed throughout the network that provide 
a comprehensive set of preventive and detective controls to prevent, monitor, and report on 
things like malware activity, network intrusion attempts, attacks against the wireless LAN, 
and Web application attacks. However, this has resulted in a plenitude of point solutions 
that require signiﬁ cant operational attention and a complexity that increases risk of errors 
or failures. A security event management (SEM) tool set and process are used to normalize 
and correlate alerts from log feeds from the intrusion detection system (IDS), ﬁ rewalls, and 
critical systems. But some areas could still beneﬁ t from greater automation, such as central-
ized identity management. A basic reference architecture for security functionality may have 
been developed.
Th reat and vulnerability management. Most critical systems are patched within a week, using 
a specialized patch deployment tool. Challenges may still exist—for example, an enterprise 
resource planning or customer relationship management system may get delayed patches 
due to heavy customization, increasing the risk of patches breaking the application. Also, 
there may not yet be good correlation between speciﬁ c threats and the systems on the net-
work of varying criticality.
Conﬁ guration management. Access to production systems is restricted to operations personnel 
only, and all ﬁ xes are ﬁ rst tested in the development environment. System conﬁ guration data 
is stored manually in federated repositories.

Setting Priorities in Your Security Program  101
Access control. User log-in accounts are fairly well-controlled, albeit still mostly manually. An 
enterprisewide identity management system has not been deployed. Some key application 
systems, as well as superuser-level administrative access to network infrastructure and host 
systems, require strong two-factor authentication. Th e data center is in a secured facility 
with tightly controlled access. Th e concept of data ownership with owners being responsible 
for access decisions has taken root.
Audits and assessments. Audits and assessments occur on a regular basis, with results commu-
nicated to key stakeholders who collectively respond with corrective action plans. High-risk 
ﬁ ndings are addressed fairly promptly, and the loop is closed on the reporting to senior 
management. Security is also somewhat involved in the due-diligence process when sig-
niﬁ cant new business partnerships are initiated, establishing requirements for third-party 
security evaluation of the business partner’s security practices. Th ere is a good partnership 
with the organization’s internal audit department. However, audit and assessment eﬀ orts are 
not always well coordinated, causing duplication of work, particularly in the area of audits 
for regulatory compliance.
Business continuity. A reasonably complete plan exists and has been tested at least once in the 
past year. But it may not have been updated to reﬂ ect new business initiatives or new sites 
performing critical IT functions. Upper management supports the plan, however, and has 
allocated adequate funding for it. Backup media for some of the key systems are tested for 
restorability as part of the regular rotation.
Incident handling. A virtual incident response (IR) team that consists of trained people from 
key departments has been identiﬁ ed. Th e IR plan is tested at least once a year, and the team 
is able to respond reasonably well to the security incidents that occur. However, there is a 
lack of coordination with other key departments in the organization such as legal, commu-
nications, and, most importantly, senior business management.
Training and awareness. New employees are briefed on security policies, and there is an annual 
eﬀ ort to remind the employees of the importance of certain security practices. Malware 
incidents have been reduced in frequency due to employees’ improved practices. Protection 
of intellectual property has likewise improved.
Maturity Level 4
At this, the highest, level the security program is operating in an optimized and very eﬀ ective 
manner and has support up to the board level, creating a risk-aware organization that does not rely 
only on the security team to keep things secure. Security is regarded as integral to the business and 
enables the business to proceed into areas that would otherwise be too risky. A comprehensive set 
of security controls, both technical and procedural, is in place and employees participate in pro-
tecting the company’s information assets. Automation of key processes and reporting mechanisms 
ensures that the security team is able to respond quickly to new threats.
Security policies. Comprehensive policies and standards are reviewed and updated annually, and 
compliance is monitored in a number of ways. Deﬁ cient areas of compliance are responded 
to with additional technical controls or increased training as needed.
Management support. Senior business management evinces full support for security objec-
tives and has included information risk in the business’s overall risk management  planning. 

102  Information Security Management Handbook
Th e chief security oﬃ  cer has established signiﬁ cant credibility and regularly solicits time 
to brief senior business management on the status of and plans for information protection 
in the company.
Security integration into the SDLC. Security has been baked into all phases of the SDLC. Secu-
rity requirements are deﬁ ned before any development on a new system commences. Most or 
all developers are trained on and follow the company’s secure system development practices, 
and functional security testing is performed on all applications prior to going live.
Security personnel. Excellent compensation and a stimulating environment attract top-notch 
talent to the security team. Th ey are not focused solely on technical matters, but instead 
work to understand the business and speak its language to frame risks in a way that is rel-
evant to business decision makers. Team members have access to all the training needed to 
be successful and are rotated through diﬀ erent positions to round out their skill set.
Security infrastructure and tools. Automation of security tasks has been implemented where 
possible for labor savings and reduction of errors, and the security infrastructure is man-
aged centrally in a dedicated security operations center. Suites of tools provide an inte-
grated operational capability. Tools generate comprehensive metrics that enable pinpoint 
identiﬁ cation of areas that need additional attention and enable better quantiﬁ cation of risk 
reduction.
Th reat and vulnerability management (TVM). A comprehensive and regularly updated conﬁ gu-
ration database of all critical systems enables rapid patch deployment across the enterprise. 
Patches are prioritized according to risk exposure.
Conﬁ guration management (CM). Evidencing the close relationship between CM and TVM, 
automated feeds of conﬁ guration data is stored in a centralized database that serves as a 
powerful tool to manage the organization’s overall security posture.
Access control. An enterprisewide identity management system is used to manage user and sys-
tem credentials and ensure that they are added and deleted in a timely manner. Self-service 
password reset has reduced the burden on the help desk (enabling it to spend time on higher-
value activities), and two-factor authentication for sensitive systems has likewise reduced the 
need for frequent password changes. Superuser access is tightly controlled to protect against 
insider sabotage and other malicious acts. All application systems have documented owners 
that make access decisions.
Audits and assessments. Activities are well coordinated across the business, with security, com-
pliance, and audit working in sync to continually improve the system of controls. Reporting 
enables a clear path to industry certiﬁ cation such as ISO27001.
Business continuity (BC). A comprehensive cross-team plan that enables rapid resumption of 
key business activities at an alternate site is in place and is rehearsed at least annually. It is 
baked into the development process and developers help identify critical business processes 
that need recovery plans. Th e BC/DR function is led by a dedicated, experienced manager 
and staﬀ  who ensure that the plan is regularly updated to reﬂ ect new sites and initiatives.
Incident handling. An enterprise-level IR plan is in place that has been coordinated across 
all key departments. Scenario planning ensures that the highly trained IR team is able to 
respond to almost any situation in a rapid and eﬀ ective manner.
Training and awareness. A broad-spectrum awareness program ensures that employees are con-
tinually educated about and reminded of their responsibilities to maintain the organization’s 
security. Metrics for awareness program eﬀ ectiveness are used to tune the messages and 
identify areas that need more attention. Data custodians and IT personnel receive special-
ized training.

Setting Priorities in Your Security Program  103
Setting the Right Priorities
For the security manager new to an organization, or an existing one working to achieve maxi-
mum leverage with his or her limited budget, focusing on the right issues is critical to success. For 
example, in a less mature program it may be folly to spend time and money on advanced projects 
like identity management when much more fundamental things are broken. Some activities, 
however, are de rigueur for the security professional entering an organization at any maturity 
level: understand the business, understand the culture, understand the IT infrastructure, and 
win allies in key areas of the organization.
Now let us take a look at each maturity level and the prioritized areas that the security manager 
should focus eﬀ orts on. Consider these priorities to be cumulative—as the security program gains 
resources, skills, and maturity it will be able to take on more advanced initiatives while continuing 
to maintain existing tools and processes. Th ese existing activities must continue to evolve toward 
greater automation and deﬁ nition of repeatable processes. For brevity, the activity descriptions are 
kept to a high level—consult other chapters in this book for more details. Of course, diﬀ erences 
in organizations may require adaptation of these recommendations to ﬁ t the speciﬁ c environment 
and culture.
Maturity Level 1
At this level, it is entirely likely that the ﬁ rst full-time security professional hired is for a staﬀ -level 
position, reporting to a manager in IT or perhaps audit or ﬁ nance. Such a hiring represents the 
ﬁ rst signiﬁ cant indication of management support for information security.
Th e security practitioners in an organization with an immature program at this level will be 
primarily in tactical mode, performing triage and ﬁ reﬁ ghting on an almost daily basis. Because 
of this, they will be unable to focus on any more strategically focused work because of time 
constraints and the simple fact that management and the organization are not yet ready for such 
thinking from the security function. Nor should the security practitioner yet attempt to create a 
complete security policy—policy is not very eﬀ ective at stopping bleeding. Instead, they should 
focus on the following areas.
Build relationships with key managers and staﬀ . In an immature security program, it is essential 
to gain allies in other parts of the organization for maximum leverage of very limited secu-
rity resources. Ideally, these allies will buy into the security eﬀ ort and help create a federated 
type of security team.
Implement comprehensive malware detection. Antivirus and spyware-detection tools must be 
installed and regularly updated on desktops, laptops, servers, and mail gateways. A 2007 report 
by Webroot Software found that 43 percent of ﬁ rms they surveyed had been hit by malware 
that caused disruption to their business. Although a growing percentage of malware is rapidly 
evolving and not detected by many of the tools out there, detection tools remain a critical line 
of defense that must be deployed as eﬀ ectively as possible.
Shore up the network perimeter. Assess the network’s ﬁ rewall defenses at all entry points into 
the network. Review the ﬁ lter conﬁ gurations and ensure that each permission is fully justi-
ﬁ ed by business need. For environments with complex yet porous ﬁ rewall conﬁ gurations, it 
may be most eﬀ ective to examine logs of traﬃ  c ﬂ ows over a couple of weeks and then start 
with a clean “deny-all” slate and build it back up by soliciting input on needs. Conduct a 
survey to track down wireless LAN access points and begin securing them.

104  Information Security Management Handbook
Develop a patch management process. Keeping desktop and server systems up to date on patches 
is a critical ongoing task. At this maturity level, however, patch deployment is likely a man-
ual process, so concentrate on Internet-facing systems ﬁ rst, then user desktops, and then 
key internal servers. For Microsoft Windows desktops, just set them up to use Windows 
Update—at this stage the risk of a bad patch is far outweighed by the risk of remaining 
unpatched. Th is goes for Windows servers as well.
Delete or lock dormant user log-in accounts. Inactive log-in accounts are a common avenue of 
compromise by disgruntled ex-employees. Review key systems to get a list of accounts that 
are no longer authorized and accounts that have not been accessed in 90 days by existing 
employees, then get them deleted or locked.
Begin identifying critical application systems. Although simply identifying critical systems does 
not improve a security posture by itself, it will help focus future protection activities on what 
is important to the business.
Conduct a security vulnerability assessment. If funding can be secured to hire a third party to 
conduct an assessment, then the objectivity of an outside entity will be worth it. It will be a 
challenge to ﬁ x all of the vulnerabilities that will be found, so ﬁ rst obtaining support for the 
eﬀ ort from system owners and management is important. Gain consensus on a timetable to 
ﬁ x the worst problems by a target date. Refer to best practices documents for guidance to 
point to when justifying how the vulnerabilities should be ﬁ xed—the National Institute of 
Standards and Technology (NIST) is a good source for this (see Special Publications 800-30 
and 800-53 in particular).
Because the security practitioner’s time is limited and the organization is not ready yet, some areas 
that should be avoided at this stage include anything more than basic policies, security awareness 
training, insertion of security into the SDLC, and disaster recovery planning. Looking for quick 
wins to show management will build credibility for the program and lay the groundwork for fur-
ther eﬀ orts. Security metrics will be hard to come by at this point, so focus should be on the rapid 
reduction in risk to the network that has been achieved.
Maturity Level 2
At this level, a basic security infrastructure is in place and functioning, and primary focus can be 
shifted to somewhat more evolved security activities. Remember that activities are  cumulative—
priorities at level 1 must continue to be worked, as they will need ongoing support and improve-
ment to reduce risk further.
Policies, standards, procedures, and guidelines. Begin developing a set of security policies that 
take into account the business’s culture, relevant laws and regulations, and the company’s 
appetite for risk. Having the chief executive oﬃ  cer sign oﬀ  on the policies will demonstrate 
to the organization that senior management takes security seriously. Policies also carry legal 
weight and help reduce liability—something the general counsel will appreciate. Once high-
level policies are published, develop standards that spell out speciﬁ c, measurable technical 
controls that can be veriﬁ ed for compliance. Documented procedures that detail for users and 
systems administrators the steps needed to implement the policies and standards may then 
be created. Last, guidelines that provide recommendations for action may be generated.
Understand the business. Seek out the key players in areas such as sales, marketing, opera-
tions, legal, human resources, and audit to build knowledge of how the business operates, 
what the key objectives and strategies are, where management sees areas of risk, what the 

Setting Priorities in Your Security Program  105
perception of security’s role is, and who the key players are (they are not always in manage-
ment roles—the senior UNIX guru who has been at the company for 20 years may be one 
of the most important people to make friends with).
Vulnerability assessments. Assessments and audits should be planned to take into account 
multiple reporting requirements for compliance, internal tactical planning, and metrics. 
Otherwise, signiﬁ cant time and eﬀ ort may be wasted redoing the same assessments for 
diﬀ erent recipients.
Security monitoring. Ensure that ﬁ rewalls, virtual private network (VPN) concentrators, and 
critical server systems are generating useful logs. Begin centralizing the log output to a main 
log server. Deploy IDS on key network segments, using a limited set of alerts focused on 
major threats. Otherwise, IDS alert output will easily overrun the time and capabilities of 
the security team at level 2.
Incident response. Th e annual Computer Security Institute/Federal Bureau of Investigation 
security survey has found that more than 70 percent of organizations have had at least one 
security incident. Th e rest probably just did not know it. It is therefore very important to 
deﬁ ne and document an IR process and identify the key personnel that would be needed to 
respond to a breach of security. Ensure that everyone involved is trained on the process and 
knows how to respond in an organized and eﬃ  cient manner. Rehearse the process every six 
months if there are not enough actual incidents to practice on.
Disaster recovery planning. Having identiﬁ ed the critical IT systems and developed an under-
standing of the business and its recovery time objectives, and the major business- interrupting 
threats it faces, develop a recovery plan that will help get critical IT systems back up and 
running in the event of a disaster.
Continued eﬀ ort and focus at this level will help move the organization up the maturity scale. At 
this stage, avoid complex tool deployments like SEM and identity management and directory ser-
vices, any large security awareness programs, and data classiﬁ cation eﬀ orts. Getting the infrastruc-
ture secured to a basic level will free more time to work on building support and relationships and 
developing better processes around the tools that have been deployed. Management should be aware 
of the work that the security team is doing and understand the value it brings to the organization.
Maturity Level 3
Organizations at this level of security maturity are doing the basic blocking and tackling well and 
can devote resources to more advanced eﬀ orts. However, the security manager should be careful 
not to shortchange the fundamentals while working on these more advanced projects. Continuing 
to do that well helps ensure that management will appreciate the security team’s value and fund 
additional projects. Th e manager must not underestimate the skills and resources that advanced 
projects like these require. Nothing will destroy security’s credibility faster than spending a large 
amount of money and having only a broken, half-functional tool to show for it. Bring in consult-
ing expertise as needed to ensure success, and break down the project into manageable chunks that 
each has a strong chance of success. Project failure is one of the major reasons that many organiza-
tions cannot get their security program up to a higher level of maturity. At this level of maturity, 
the following areas deserve attention:
Security tool integration. Once an organization has deployed a plethora of security point solu-
tions, the new challenge is to integrate them into a cohesive whole that enhances security 

106  Information Security Management Handbook
visibility across the enterprise while reducing the eﬀ ort needed to manage the tools and the 
huge amount of data they generate. Security information management tools, sometimes also 
called SEM, enable this by pulling in the myriad sources of security monitoring data like 
ﬁ rewalls, IDSs/intrusion prevention systems, VPN servers, routers and switches, servers and 
desktops, vulnerability scanners, and antivirus gateways.
Secure application development training. To achieve stronger integration of security into the 
SDLC, the software developers should be trained in secure coding practices, especially for 
Web applications—a major source of risk. Seek out one of the training consultancies that 
specialize in this. Also refer to NIST Special Publication 800-64 for more information on 
integrating security into the SDLC.
Awareness training. Once the infrastructure is reasonably well secured, focus on getting 
employees familiar with the current security threats, their responsibilities for keeping infor-
mation secure, who to call to report incidents, and proper behavior when using e-mail and 
the Internet. Use multiple media that continuously reinforce the security message.
Strong authentication for critical data. Passwords are not enough for strong access control. 
 Having identiﬁ ed the systems that hold and process critically sensitive data, implement two-
factor authentication for those systems and ensure that there are no privileged accounts left 
out from under that umbrella. Pilot the project with a small group of systems and users ﬁ rst 
to avoid any problems later.
Data classiﬁ cation. Th is is perhaps one of the most challenging security projects, taking years to 
implement as the culture and awareness of the organization changes. But it is very important, 
as it helps legally protect the company’s trade secrets and ensures that access to sensitive doc-
uments and data can be properly restricted. Work with the legal department and begin with 
a classiﬁ cation policy, educate users, and begin labeling documents as they are newly created. 
As existing documents and applications are updated, they should be labeled as well.
Compliance tools. Th e ever-growing raft of regulations that companies, especially public com-
panies, must comply with has resulted in a very diﬃ  cult environment. Many companies 
deal with new compliance reporting or audit requests on at least a monthly basis and ﬁ nd 
themselves repeating the same work over and over. Th is is a big drain on resources and often 
does not make the company measurably more secure. Evaluate and implement tools to help 
streamline compliance reporting and avoid duplicated eﬀ ort. Also, pursuing certiﬁ cation 
against ISO27001 can help in this area.
Security strategy. A 2004 study by PricewaterhouseCooper and CIO Magazine found that 
50 percent of security managers do not have a security strategy. But once the security pro-
gram has matured to this level, the security manager must start building a strategic plan to 
ﬁ t the business and provide a framework for all of the security eﬀ orts. To do this eﬀ ectively, 
however, requires that they are closely aligned with the business and involved in the overall 
strategic business planning process. Th e security strategic plan should be revisited every year 
and adjusted as needed.
Business continuity. Although DRP focuses on restoration of the company’s IT infrastructure, 
business continuity planning focuses on restoration of business operations when the avail-
ability of supporting resources like the network and facilities is lost. Although this planning 
function is not purely security, it is a key part of enterprise risk management and the security 
manager will play a key role in this eﬀ ort.
Maturity level 3 is the highest that many organizations get before plateauing. Th is is due to 
many factors, but discontinuity of security program management is one, overall lack of rigor 

Setting Priorities in Your Security Program  107
in the organization’s processes and risk management approach is another. To reach the highest 
level of maturity requires substantial discipline and expertise, and a great deal of eﬀ ort to stay 
there. But there are more and more companies that achieve this as best practice are shared and 
institutionalized.
Maturity Level 4
Th e most mature security programs are fully optimized and have well-documented (and used) pro-
cesses that provide a feedback loop to continually improve security. Although tools are still impor-
tant, the greater focus at this level is on business alignment and standardization of processes.
Identity management and public key infrastructure. As the numbers of systems and users in an 
organization grow, the eﬀ ort required to manage user accounts eﬀ ectively and access privi-
leges quickly becomes overwhelming. Build and deploy an enterprisewide identity manage-
ment system to centralize user accounts and privileges and reduce the risk of overassignment 
of access and of incomplete termination of access when an employee leaves the company.
Comprehensive metrics reporting. To continue building management support for new security 
initiatives and ensure that security is baked into the business, develop a suite of metrics that 
enable tracking of security spending eﬀ ectiveness and that can help to identify problem 
areas that need more attention. Ensure the metrics are properly tuned to the audience.
Enterprise risk management. Th e manager of a mature security program should be fully involved 
in the organization’s overall enterprise risk management program. Th e top-performing secu-
rity oﬃ  cers have created a risk-aware culture in their companies in which employees fully 
understand their role in protecting information and management evaluates all decisions in 
terms of risk (and therefore cost to the business).
Formalized security governance. IT governance is a topic on more and more CIO’s minds, and 
prominent resources like the IT Infrastructure Library are available to help establish and 
maintain a governance structure. Establish a security governance structure that includes key 
stakeholder representatives to ensure that security is continually aligned with the business 
and responsibilities are clearly deﬁ ned. Governance eﬀ orts will also help the security depart-
ment position itself as an internal service resource for the rest of the business.
Another tool that top-performing organizations use to ensure they are moving in the right direc-
tion is industry benchmarking. By leveraging contacts in the industry, a group of security manag-
ers can build oﬀ  of one another’s successes to achieve higher levels in their security program—“steel 
sharpening steel.”
A security manager that has built or manages a program at a high level of maturity is a very 
valuable asset to his or her organization and will be frequently sought out by others looking to 
leverage their expertise.
Conclusion
Th e reader should now be familiar with the characteristics of security programs of diﬀ ering levels 
of maturity and what the security managers need to focus on when starting in an organization 
at each level. It is important that they are able to evaluate program maturity objectively so that 
eﬀ ort and resources can be assigned to the most appropriate activities that result in the most risk 
reduction for the business.


109
Chapter 8
Why and How Assessment 
of Organization Culture 
Shapes Security Strategies
Don Saracco
Contents
Why Be Concerned with Organization Culture? .....................................................................110
Learning to Be Secure .....................................................................................................110
So What? ........................................................................................................................111
Th e Requirements of Assessment..............................................................................................113
Selling Assessment ...................................................................................................................113
Selling Yourself ...............................................................................................................113
Selling the Assessment ....................................................................................................114
Choosing Assessment Methods ................................................................................................116
Interviews .......................................................................................................................116
Interview Protocol .................................................................................................117
Selecting Interview Subjects ...................................................................................117
Interview Structure ................................................................................................118
Interpreting Results ...............................................................................................118
Surveys ...........................................................................................................................118
Th e Instrument ......................................................................................................119
Developing Your Own Instrument ........................................................................119
Th e Survey Protocol .............................................................................................. 120
A Classiﬁ cation System for Organizational Cultures ............................................................... 120
Th e Organization Imperative ...................................................................................................121

110  Information Security Management Handbook
Th e Psychological Contract: Th e Heart of the Culture .............................................................121
Th e Formal Organization ........................................................................................................ 122
Informal Organization ............................................................................................................ 122
Vertical, Horizontal, and Blended Cultural Archetypes .......................................................... 123
Th e Vertical Archetype .................................................................................................. 123
Th e Horizontal Archetype ............................................................................................. 124
Archetypes in the Middle ...............................................................................................125
Not Only What but How Well ............................................................................................... 126
Linking Strategy to Culture .................................................................................................... 127
Presenting Assessment Results ................................................................................................ 130
Focus on Strategy........................................................................................................... 130
If Th ey Really Need to Know ........................................................................................ 130
Some Final Th oughts on Culture ............................................................................................ 130
References ................................................................................................................................132
Why Be Concerned with Organization Culture?
To answer this question we must ﬁ rst answer the question, “How are security and culture linked?” 
Th e answer to that question lies not in what we know but in what we do not know. Although we take 
it for granted that security is an indelible part of individual and organizational life, the deﬁ nition 
and extent of its need vary greatly across any population of people and organizations. After all, if it 
is simply “common sense” to ensure security, of what use is the answer to the question? We should 
simply implement as much security as we possibly can and consider the job done. Of course, such 
a simplistic application of common sense could lead an organization into excessive spending and 
crippling constraints on employee productivity.
As it turns out, every management practice in an organization will support or inhibit that 
organization in proportion to the extent that the practice is aligned with the culture. Failure to 
align with culture is the hallmark of “programs of the month” that come and go and end up on 
the trash heap of good intentions badly executed.
Effective alignment of practice with culture enables security man-
agers to design and implement necessary and sufﬁ cient security, 
and the provision of no more and no less than that is the security 
manager’s job.
Th e purpose of this chapter is twofold. First it will explain why you must understand the link 
between culture and security practices. Second it will describe how you can go about assessing 
your organization’s culture and linking that assessment to security strategies.
Learning to Be Secure
Security needs in people begin with what are apparently instinctive reactions to perceived threats. 
Humans seem to have a survival instinct hardwired into the organism. It is initially visible in the 

Security Strategies  111
form of reﬂ exes and later becomes more sophisticated. An infant reacts to loud noises or jerky 
motions with alarm. As the child grows and develops more sophisticated perceptions, reﬂ exes are 
augmented by thinking processes. Reactions to threats include not only simple perception but also 
analysis of the threat and the choice of an appropriate response.
As sophistication grows even further people become able to develop actions based on an assess-
ment of the probability that a threat might exist. Our personal security becomes more proactive and 
less reactive. A person walking down a dark street in an unfamiliar neighborhood hearing footsteps 
approaching from the rear is likely to experience an elevated heart rate and other physical signs of 
psychological arousal. Th ere is no clear and present danger but the person makes an analysis of 
the facts listed earlier, blends it with past experiences as well as stories heard, and reaches instant 
conclusions regarding the presence of threat. Th ese conclusions produce the physical feelings with 
which we are all familiar when danger is sensed. Th e default response for people is to prepare to ﬂ ee 
or ﬁ ght. It seems that the very design of the organism is toward protection and survival. It is impor-
tant to note that reﬂ exive reactions never completely disappear. Th ey have always been necessary for 
the survival of the organism and are not likely to evolve out of existence any time soon.
A truly interesting thing about this process is that as learning continues, the proactive process 
can come to appear reﬂ exive as the processing of information regarding familiar stimuli becomes 
“automated” in the brain. Familiar threats begin to produce what appear to be reﬂ exive reactions, 
which are actually learned responses that bypass conscious analysis as an unnecessary step in deal-
ing with that stimulus. Essentially, a person forms an “association macro” that runs an automatic 
analysis of the stimulus and then runs a programmed response. Th e person walking down the dark 
street did not think about the danger. In fact the physical feelings were probably felt before any 
conscious thought occurred. Th us the foundation for the person’s tendencies throughout life to 
approach or avoid various stimuli is laid.
In a sense the processes come full circle from reﬂ ex to conscious thought and back to what 
appears as reﬂ ex again (see Figure 8.1).
Such learned automatic behavior is even called “knee jerk” in popular literature. Th e allusion 
to what happens when the doctor taps a person’s knee to test reﬂ exes is not without foundation. 
For all intents and purposes it is the same thing. Th e only meaningful diﬀ erence between the two 
responses is that the latter, learned response can be altered by conscious cognitive intervention.
As cognitive mechanisms continue to develop automated responses can become incorporated 
into larger schemes of thought such that the person anticipates discomfort and avoids walking 
unaccompanied in unfamiliar neighborhoods at night. After all, would not a reasonable person 
avoid perceived danger? You can probably see how this process proceeding out of control can also 
produce “unreasonable” patterns of behavior that we might call paranoid or otherwise excessive.
So What?
By now you are probably asking yourself why this discussion of assessing culture began with a walk 
through Developmental Psych 101. It is important because this “biological inertia” to survive and 
to use programmed responses is also true for other organic forms in our world, including human 
organizations, and it ﬁ nds its expression in the patterns that we call organization culture. Th at 
which is born does not normally want to die and there is a will to live apparent in all viable 
organizations as well as in viable people. In fact managers in organizations accept their account-
ability for the protection of the organization’s continued growth and survival unquestioningly. 
I have not seen a position description (except at the chief executive oﬃ  cer level) that spells out this 

112  Information Security Management Handbook
accountability for managers but I doubt that any would deny that it exists. It could be argued that 
this reﬂ exive will to survive is hardwired into the organization or is at least automated in manage-
ment practices (Rousseau, 1995).
Th e problem is that reﬂ exes are not enough and reactions to risk must become thoughtful antici-
pation of risk. Rapid discovery of a security breach must be secondary to eﬀ ective reduction of a 
security risk. Th e design of the process of reducing risk is the point at which all organisms and 
organizations diﬀ er and that diﬀ erence follows from either personality in the individual or culture 
in an organization.
So, just as we would need to understand the personality of an 
individual to understand his or her needs for security, so must we 
understand the culture of an organization to design an appropriate 
security program.
Diﬀ erent personalities are likely to perceive personal risk diﬀ erently and diﬀ erent organizational 
cultures will also diﬀ er in their perceptions of what is most important to their survival. As will be 
Stimulus
At rest
Analysis
Response
Response
effect 
Figure 8.1 Response learning process.

Security Strategies  113
discussed later, culture can trump good common sense when it comes to management and secu-
rity practices and this is the compelling driver for including a useful assessment of culture in the 
development of a security program. After all, eﬀ ective management is doing the right things right, 
not just doing everything that can be done.
The Requirements of Assessment
Th e ﬁ rst requirement of cultural assessment is support from the most senior levels of management 
for the conduct of such an assessment. It cannot be assumed that owners and other top manag-
ers of organizations want any such assessment to be performed, so portion of this treatise will be 
devoted to selling the idea of assessment.
Th ere are a number of deﬁ nitions of assessment. For our purposes we will use the one that 
refers to assessment as a categorization, sorting, or classiﬁ cation. If we can provide a useful clas-
siﬁ cation system for organization cultures, we can identify security strategies most appropriate 
for each class. So, the next requirement for assessment of organization culture is a classiﬁ cation 
system. We will use a fairly simple system that provides adequate direction without unnecessarily 
complicating the work.
Th e next requirement is a method of assessment. Th e method must provide suﬃ  cient informa-
tion to diﬀ erentiate among organizations and be compatible with practices in the organization. 
Both survey and interview methods may be used. Both can be valid and can be used indepen-
dently or together.
Th e next requirement is a logical connection between the classiﬁ cation and the speciﬁ c secu-
rity strategies. Th is requirement is partially met by the use of a robust classiﬁ cation system that 
is founded in valid and reliable principles of human and organizational behavior. It also calls for 
openness to changes in management practices where such changes will enable or enhance the 
eﬀ ectiveness of strategies.
Th e ﬁ nal requirement is eﬀ ective presentation of the assessment results and recommenda-
tions to organization decision makers, without whose support no eﬀ ective program can be imple-
mented. Both new and enhanced security strategies and changes to management practices are 
likely to include costs of some kind, so this step is crucial to getting the right program in place. 
Without appropriate management support, many security personnel are relegated to the role of 
“virus and porn police” with no strategic impact on the business.
Selling Assessment
Selling the assessment may be the most important part of the entire process, for without it the 
assessment is not likely to move forward. Th e process is fairly simple, as shown in Figure 8.2.
Selling Yourself
It all begins with the ability of security professionals to be perceived as competent and trustworthy 
partners in the pursuit of business goals. If you do not really know how you are perceived you will 
have to ﬁ nd a way to ask people. Th is is the ﬁ rst necessary step toward ensuring the value of your 
security program as well as your own inﬂ uence in the organization.

114  Information Security Management Handbook
Of course the ﬁ rst source to use should be your direct supervisors. Th ey may be willing to give 
you some unvarnished feedback about your perceived eﬀ ectiveness and can also help you to plan 
the reinvention of yourself in your role. If your supervisor lacks the skills or willingness to give 
you useful feedback and developmental support you will have to go to your peers and customers. 
Frankly, you should never spend any signiﬁ cant length of time in a staﬀ  position without getting 
feedback from your customers anyway.
Soliciting feedback can be a risky process. People who are asked face to face to assess your 
eﬀ ectiveness are just as likely to tell you what they think you want to hear as to give you an hon-
est appraisal of your relationship with them. An anonymous method is probably better. Th ere 
are two ways to get anonymous feedback. You can develop a valid questionnaire and distribute it 
to a sample of your peers and your customers at every level of the organization that is as large as 
possible or you can have a surrogate interview people on your behalf using a structured interview 
protocol that you have helped to design. Th e former is faster and probably less expensive. It will 
also be statistically defensible. Th e latter method will get you nuances of perception and a richer 
pool of information but will take longer, cost more, and lack statistical power. In either case you 
should enlist the aid of a skilled assessment professional to help interpret the results of your data 
collection and help you to make speciﬁ c plans for improvement.
If the current security staﬀ  already enjoys the conﬁ dence of peer and superior customers, selling 
the idea of culture assessment should be relatively easy, but it will not necessarily be a “slam dunk.” In 
the past years when my colleagues and I at MLC & Associates, Inc., were ﬁ rst developing our assess-
ment methods, we had the experience of getting agreement from a senior management sponsor to do 
the assessment only to ﬁ nd that when we tried to roll out the method, there were others who objected 
to it. We quickly learned that an assessment of culture will succeed only if there is broad manage-
ment support for doing it. At a minimum, this support should include the senior business operations 
managers, human resources, risk management, audit, the chief information oﬃ  cer, the chief admin-
istrative oﬃ  cer, and a signiﬁ cant sample of middle managers throughout the organization.
Selling the Assessment
We and our clients have found that a well-designed and planned “road show” can be a very eﬀ ec-
tive method of gaining the broad base of support that you will need. A road show has two central 
Obtain sr. support for
assessment 
Obtain broad 
support for 
assessment
Choose method
for assessment 
Interpret data
Link to strategy
Present results
Figure 8.2 Assessment process.

Security Strategies  115
elements. It contains factual information and it succeeds in generating dialogue. Th e factual infor-
mation is necessary because people want to know exactly what they are being asked to support 
(or at least not object to) and how it will help them to reach their goals. Th e dialogue is necessary 
because you will need to know what those goals are before you can position the assessment as 
helpful.
In most cases, this selling process involves multiple iterations of face-to-face meetings with key 
people. Initial meetings can be exploratory for the purpose of exchanging general security program 
and business unit goals. One of the most common mistakes that we have seen people make is to assume 
that they have the support or agreement of someone as a result of a single conversation.  Support and 
agreement must be treated like living things that require constant nurturing and renewal. Organiza-
tion life today is much too dynamic to assume that any relationship is permanent.
Skilled security managers will do much more listening in these meetings than talking. Th ey  
should be certain about the strategic goals that provide the direction for the program in case peers 
and superiors want to know, but there is little or no value in long-winded speeches ﬁ lled with tech-
nical jargon intended to impress people with your brilliance. Th ere is tremendous value in sincere 
inquiry about the things that are important to business operations. So, if you are asked to describe 
your program respond with a brief but complete statement of your strategic goals followed by a 
question such as, “What can we do that will best support your business goals?”
Of course the people with whom you are meeting will be curious and perhaps even suspicious 
about what you want from them. We have found that it is always best to be brief and honest about 
that. You will be asking for support in the conduct of an assessment of the organization’s culture. 
It is important to formulate a succinct statement that says what you want and what it is likely to 
cost the other person, if anything.
Your purpose in assessing the culture is not to try to change it or be 
critical of it, but to understand it, so that your program will be appro-
priately aligned with it.
You should operate under the assumption that the culture is what it is and represents part of what 
makes the company successful. Unless the company is in serious trouble, this is usually a safe 
assumption.
If you are asked for details, focus on providing “minimal truth.” Avoid technical jargon and 
be prepared to give a simple example of how you will use the information. Such an example might 
be that you need to develop security policies that are consistent with the culture, because to do 
otherwise puts you in danger of being either overly restrictive or not suﬃ  ciently diligent. Security 
policies and practices must blend with the culture rather than attempt to change it—unless such 
a change is necessary to reduce or eliminate a legitimate risk.
Some security chiefs ﬁ nd it useful to assemble a steering committee or program management 
oﬃ  ce involving key personnel from around the organization willing to serve. If you choose this 
management strategy, it should be the ﬁ rst thing that you do before framing any initiatives. Such 
an advisory group can be a powerful ally but it will take some time to get it up and running. 
A key to success for a steering committee or advisory board is to ensure that they have real work 
to do and real decisions to make. For example, you can use such a body to bless your drafts of 
organization security policies, thus ensuring that your policy framework is both widely accepted 

116  Information Security Management Handbook
and aligned with the interests of key players in the organization. A steering or advisory committee 
is a double-edged sword that can hurt your eﬀ orts as well as help them. If you choose to use one, 
assemble and nurture it with great care. Communicate often and eﬀ ectively with its members and 
never assume that everyone is automatically on the same page with you or that you can use the 
committee to “rubber stamp” anything.
Choosing Assessment Methods
Th e choice of assessment methods is critical to the success of the process. Organizational activities 
associated with programs and initiatives must gain fairly wide acceptance not to be disruptive or 
face resistance.
Disruption can come from poor understanding of the motives for the assessment. In these 
times when people are increasingly likely to distrust an employer’s actions, any assessment may be 
viewed as a step toward restructuring or right-sizing, with the consequences of reduced productiv-
ity and malicious compliance.
Resistance, both open and passive, can also derail an assessment. As people become success-
fully socialized into their organizations, they learn how not to do things as well as how to get 
things done. Research tells us that when they are threatened, people will often plead lack of time 
or insuﬃ  cient priority to avoid engaging in a mandated activity without clear purpose. Passive 
resistance is very diﬃ  cult to identify as people will invoke reasons for not doing their part appar-
ently rooted in a focus on central organizational goals. Senior managers are unlikely to be critical 
of people who appear to be supporting management’s primary reasons for being.
You might be persuaded to think that obtaining senior management support for an assessment 
would be suﬃ  cient to overcome resistance, and for some percentage of the population in some 
organizations that would be true. Th ere is, however, no substitute for gaining broad support from 
all levels of management as well as from the rank and ﬁ le of employees.
If by now you are becoming discouraged by all that must be done to get this right, do not 
worry. Th ere is also good news, and that is a little truth telling works wonders. Th e most important 
truths to tell are about how the assessment information will be used without hiding any secondary 
purpose and that individual inputs from people will remain anonymous.
For example, you may see that an assessment of the culture can be incorporated into any analy-
sis of readiness for organizational change as well as into actual change initiatives. If the organiza-
tion plans to leverage the cost of the assessment by using the information for more than security 
program development, that fact must be shared with people in the beginning.
It is also necessary to guarantee anonymity for individuals. Th ere will always be those who 
suspect the information will be somehow used against them in administrative proceedings. Of 
course to do so would be both unethical and in some states illegal. Verbal assurances may not be 
enough to support a guarantee of anonymity. You may need to share an explicit description of how 
that anonymity is going to be protected and make the process open to inspection.
Well, that’s enough discussion of things about which you should be concerned. Let us get to 
the “how to do it” parts.
Interviews
Eﬀ ective interviewing is an art. It requires both discipline and sensitivity to what is not being said. 
Th e discipline can be rooted in the interview protocol but even skilled interviewers can succumb 

Security Strategies  117
to the temptation to stray from the protocol just for the sake of variety. Reliance on the protocol 
should be absolute as a consistent framework for interviews. Properly done interviews can provide 
a very rich body of data from a relatively small sample of subjects but interpretation must be done 
with the highest standards of professional discipline to avoid overly subjective interpretation of 
results. Having the data collection and the interpretation done by diﬀ erent people can overcome 
this pitfall and help to ensure that conclusions about the culture can be supported.
Sensitivity to what is not being said enables interviewers to demonstrate that they are sincerely 
listening, makes the interview more conversational, and allows the interviewer to probe beneath 
the surface for foundation beliefs about the culture and experiences within it. Th is is the part 
of interviewing that is the most artful and that takes signiﬁ cant experience to learn. We do not 
recommend that inexperienced people use interview methods. An unskilled interviewer can come 
across as an interrogator and that will do nothing less than conﬁ rming any negative suspicions 
about the purpose of the interview that the subjects may have had at the outset. We do recommend 
that anyone hoping to be successful in staﬀ  roles learn eﬀ ective interviewing skills. Th ey will serve 
you well throughout your career.
Interview Protocol
Th e interview protocol is the essential structure of the interview process as well as the list of ques-
tions you intend to ask. Th e core questions of all subjects must be asked to ensure accurate inter-
pretation of results. Th e core should consist of enough questions to develop suﬃ  cient information 
for analysis but not so many as to cause you be rushed near the end of the scheduled time. We 
have found that somewhere in the neighborhood of 10 to 15 open-ended questions ﬁ ts fairly well 
into a one-hour time slot. Th is allows you to get enough information to contribute to a classiﬁ ca-
tion of the culture archetype and enough time to maintain a friendly, conversational tone to the 
interview.
Selecting Interview Subjects
Th e selection of interview subjects should be done with input from stakeholders or neutral par-
ties. We have found input from senior managers as well as from senior administrative assistants 
to be very useful in selecting a good cross section of the population. Th e subjects should include 
managers at several levels as well as rank and ﬁ le staﬀ  of all types (e.g., exempt and nonexempt). 
Include both people with signiﬁ cant tenure and those who have fewer than 18 months with the 
organization. Most people should be able to provide enough information to help with classiﬁ ca-
tion of the culture after they have been on board for about 90 days, but a little longer is probably 
better. Frankly, it depends on things like the actual age of the organization. It is important to get 
a good cross-sectional representation of organizational functions to ensure that you account for 
internal diﬀ erences in departments. A large organization with rigid “silos” can have important 
diﬀ erences across departments and these diﬀ erences can inﬂ uence how you implement security 
measures.
We have done an analysis in an organization in which more than half the personnel had been 
with the organization for less than a year and were still able to make an accurate assessment. 
Th e rapid growth of the company called for people to truly “hit the ground running” and the 
 recruitment process aimed at fully informing new hires about how things were done in the com-
pany. We were able to get a very good representative sample of the various functions and thus to 
understand the diﬀ erences with which the program would have to cope.

118  Information Security Management Handbook
Interview Structure
Th e overall structure of the interview should help to ensure an appropriate tone and that you 
get the information you need. Th e general process structure should look something like the 
following:
Introduction
 
— Purpose and aﬃ  rmation of anonymity
 
— Process description
 
— Check for understanding
Opening questions (ask about the subject’s role in the organization, tenure with the organi-
zation, experience with security, etc., to establish a conversational tone)
Core questions (start with the most general and unrelated to the person’s own experience 
and work toward more speciﬁ c examples of the subject’s personal experiences)
Finish by giving the subject an opportunity to ask questions of you, oﬀ ering thanks, and by 
sharing what the next steps in the process will be
Interpreting Results
Interpretation of interview results calls for intimate familiarity with the culture classiﬁ cation sys-
tem that you use and the implications of each class for security strategies. Th e process for draw-
ing information from interview data is called “thematic analysis” because what you are doing 
is identifying relevant themes that appear across interviews. Th ese themes lend support to your 
conclusions about the classiﬁ cation of the culture and subsequent application to your program. 
A theme is a response to your core interview questions that appears more than two or three times 
in as many separate interviews. We have found that in an organization of medium to large size 
between 20 and 40 interviews should be suﬃ  cient.
In a land development organization in which we conducted an assessment, we repeatedly heard 
that decisions were seldom made below the executive level. In our classiﬁ cation system this theme 
clearly points to a vertical archetype. Other information that supported this conclusion appeared 
in stories of a sort of “bipolar” way of doing things. It either took “forever” to get anything done 
or things had to be done immediately so as to not suﬀ er the disfavor of a senior manager. Th is is 
another clear indication of the vertical archetype that will be described under “A Classiﬁ cation 
System for Organizational Cultures.”
Surveys
Assessment by survey is more about science than about art, although the artful preparation of 
the survey is still necessary. You may even ﬁ nd that some people are more suspicious of a survey 
than of interviews. Any survey that smacks of psychology or social research can provoke hostile 
reactions in some people. People sometimes have bad experiences with surveys badly done, so that 
they will never greet one without deep suspicion or resentment. You can protect against hostile 
reactions by suﬃ  ciently and honestly communicating the purpose of the survey, aﬃ  rming the 
anonymity of respondents, and fully describing how the data will be handled and processed.
A survey is more science than art because it can avoid any tendencies for the data-collection 
process to be biased by subjective interpretation of data. It provides an objective measure of opin-
ions and usually allows for a much larger sample of organization members to be included in the 





Security Strategies  119
data-collection process. However, science calls for a certain level of rigor in the creation of the 
survey instrument and the treatment of results.
The Instrument
Th ere are two major concerns when it comes to using survey instruments: validity and reliability. 
In the simplest terms, the instrument must measure what it intends to measure (validity) and 
produce similar results with repeated use (reliability). At the time of publication, we have not been 
able to ﬁ nd a standard instrument that can be used in the design of a security program. Th ere are 
several instruments that have been developed to assess cultures with regard to safety issues as well 
as tools intended for use in general assessment of organizational climate. Th ere are apparently none 
based on a classiﬁ cation system that can be related to security strategies.
This is not particularly surprising when one considers the fact that 
most security experts avoid the subject of culture as a factor in pro-
gram implementation, preferring to focus on the power of technol-
ogy and policy to achieve security program goals.
Developing Your Own Instrument
We have been using a survey instrument of our own design for culture assessment for the past 
decade. It is based on a classiﬁ cation system that readily provides guidance for a wide variety 
of organizational development activities and initiatives. Although the instrument has not yet 
been statistically validated, it consistently returns internal reliability coeﬃ  cients above 0.90 
(above 0.80 is considered fairly reliable and above 0.60 is often considered acceptable in social 
research). Th is suggests that the instrument is essentially coherent and is measuring something 
consistently. We believe that it is measuring the factors that we assume characterize the major 
archetypes of culture that we believe exist, but we have not yet secured a research partner to help 
us to validate our assumption.
Th e foregoing information is not included as an advertisement but to demonstrate that devel-
oping your own instrument can be diﬃ  cult and requires adherence to rigorous research rules. We 
are neither willing to oﬀ er our tool on the market nor do we suggest to clients that it is more than 
it is, because it does not yet meet the standard for a research tool. Neither should you pretend that 
your homegrown survey is valid and reliable without appropriate statistical evidence. Question-
naires are fairly easy to write, but scientiﬁ c instruments take years to develop and require a solid 
theoretical basis. Perhaps some of the purveyors of security technology and program support will 
become willing to invest in the development of useful culture assessment tools as they learn about 
the need to align programs and technology with culture.
Th is does not mean that you cannot design your own survey instrument and use it. It means 
only that you will need a robust classiﬁ cation model upon which to base your questionnaire and 
that you must include the limitations of your tool in any report of results that you produce.
Th e following is oﬀ ered as basic information relative to developing survey items.
Th e instrument items are usually written in the form of statements with which people are 
asked to agree or disagree on a scale from “strongly disagree” to “strongly agree,” because what 

120  Information Security Management Handbook
we are looking for is where the person’s perception falls on a continuous scale. For example, if, as 
the ﬁ rst item in the following list states, leadership is emphasized more than control, we get an 
indication that the organization culture archetype is more horizontal than vertical. Th ere must be 
multiple items in the instrument that seek the same determination until a single item is validated 
statistically to provide the information alone. In our instrument we use 36 items to identify place-
ment in three categories. Th at gives us 12 items for each archetype looking at six diﬀ erent factors, 
so each factor is measured two times.
 
1. Leadership (inspiration) is emphasized and rewarded much more than is management 
(control).
 
2. My primary customer (the person I must please) is my supervisor.
 
3. People are rewarded and recognized primarily because of their individual accomplishments.
 
4. Th ere are things that are not “discussable,” that is, things that everyone knows, but it is not 
OK to talk about.
 
5. Innovation is highly valued despite the risk of failure.
 
6. People must get permission to do anything new or diﬀ erent.
The Survey Protocol
Th ere is a standard general protocol for the use of social research tools. It is designed to avoid 
contamination of survey results that can come from conscious or unconscious bias. Th e following 
steps are an adaptation of the protocol for the use of individual assessment instruments:
 
1. Administer the instrument
 
2. Score the instrument and collect relevant statistical results
 
3. Interpret the results in terms of the classiﬁ cation system and implications for strategy
 
4. Report the results to stakeholders, including implications for security strategies
Th e critical part of this protocol is administration before the classiﬁ cation system model is dis-
cussed with any of the participants in the survey. Results can be skewed by knowledge of the 
model unless the survey includes enough items of the right kind to identify deliberate bias in the 
responses. For custom-designed tools and most others that are commercially available this kind of 
robust instrument design is seldom available.
A Classiﬁ cation System for Organizational Cultures
Cultural analysis is deﬁ ned in the organizational psychology literature as a stream of investiga-
tion that seeks to understand and map trends, inﬂ uences, eﬀ ects, and aﬀ ects within cultures 
( Aronson, 1995). Standard analysis of culture is based upon an idiosyncratic array of symbols, 
norms, myths, legends, and character archetypes. Th e analysis and classiﬁ cation framework that 
we use is derived from research and practice concerned with psychological contracts and core 
relationship dynamics within organizations (Rousseau, 1989; Rousseau, 1990; Rousseau and 
McLean, 1993). Psychological contracts are the operant agreements regarding the understood 
exchange of value between employees and their organizations. Th e exchange of value generally 
calls for employees to give things like their attendance, best eﬀ orts, loyalty, and adherence to 
organization values in exchange for adequate compensation, beneﬁ ts, opportunity, and quality 
of relationships. Th ese contracts tend to be unique on an individual level owing to the unique 

Security Strategies  121
 psychology of  individual people. At the level of organization archetype, the contract is a normative 
one that is shared by all employees with the organization. Th e research of MLC & Associates has 
identiﬁ ed organizational archetypes that are characterized by certain underlying beliefs, practices, 
and elements of the psychosocial contract that are common across the vast majority of relation-
ships between the organization and its members. Th ese archetypes can be described as analogous 
to fundamental models of governance ranging from absolute control by an individual to widely 
distributed control as may be seen in a community (Figure 8.3).
The Organization Imperative
Humans will organize. Whenever people commit to work toward shared goals, they will organize 
to reach those goals (Biddle, 1979). Granted the organization may not always be elegant or func-
tionally eﬀ ective but it will exist. It appears that people will organize because there is a need to 
know how we relate to others with whom we work and an organization can deﬁ ne relationships 
according to commonly accepted deﬁ nitions of roles.
Organization relationships are most signiﬁ cantly inﬂ uenced by the distribution of authority 
and accountability (A&A). Th is distribution informs people about how they can learn what is 
important and how things get done in the organization. It also deﬁ nes formal freedom to act, 
which is a de facto control on the extent to which people can be creative.
The Psychological Contract: The Heart of the Culture
Psychological contracts are both individual and collective (normative). Each organization has a 
normative contract in place that can serve as a basis for the classiﬁ cation of the culture. Many 
elements or clauses are included in the contract (see Figure 8.4) but there are some that repre-
sent a core of critical factors. Th ese revolve around the distribution of A&A and include how 
information is managed and how much dependence is expected from people. Such a classiﬁ ca-
tion system allows us to make the connection between the culture and how we must design 
the organization’s policies and practices, because each archetype calls for speciﬁ c patterns of 
behavior and belief.
Absolute
monarchy 
Feudal
monarchy 
Republic
Democracy
Community
Vertical
Blended
Horizontal
Dependence
Interdependence
Top-down accountability or authority
Distributed accountability or authority
Need-to-know information
Good-to-know information
Archetypes
Figure 8.3 Archetypes governance model. 

122  Information Security Management Handbook
The Formal Organization
In most organizations the formal distribution of A&A is shown in organizational charts that are 
drawn in the form of pyramids with the least of both authority and accountability at the bottom. 
Th e more layers in the pyramid the less A&A is vested in the lowest rungs of the ladder. Pure forms 
of this distribution are somewhat confounded by the existence of unions in the workforce. In 
those cases  certain forms of power exist in the collective bargaining unit that no individual would 
have. Th ere is also a lack of some forms of individual power that are co-opted by the union. In no 
case does the existence of a collective bargaining unit change the fundamental characteristics of a 
cultural archetype. Th e impact of collective bargaining is primarily to remove management power 
to abuse and exploit and to remove individual power to excel by exceeding performance standards. 
Th e fundamental distribution of A&A remains aligned with the extent and depth of the verticality 
in the formal organization.
Informal Organization
Where formal organizations reﬂ ect the intentions of their designers, informal organizations reﬂ ect 
how things actually get done and relate to one another. Where formal organizations tend to be  stable 
and unchanging in their basic design, the informal organization is more ﬂ uid (Aronson, 1995).
Figure 8.4 Inputs to the psychological contract.
Compensation
Benefits
Authority
Accountability
Social
cues 
Occupational
predispositions 
Advancement
Consistent
organizational
messages  
Shared
values 
The total
psychological contract 

Security Strategies  123
Th e dynamics of the informal organization are driven by the inﬂ uence of politics and personalities as 
well as by people with leadership ability that exceeds what is formally expected from their roles.
In every one of the hundreds of organizations with which we have worked over the past two 
decades, there have been people whose inﬂ uence far outstripped their formal authority. Sometimes 
that inﬂ uence has positive eﬀ ects on policies and practices and sometimes not. One example can be 
seen in a client of ours. Th is manufacturing organization implemented a wireless radio frequency sys-
tem in support of its logistics control and communication functions. A single individual from outside 
the information technology (IT) department held sway over what was done with the system including 
the extent to which it was made secure—or not secure. Despite our urging that the system “owner-
ship” be shifted to IT to ensure adequate support and security, management was unwilling to confront 
the current owner to eﬀ ect the change because it might call into question the need for his role and 
pay grade. We had to resort to having one of our consultants gain access to the organization’s network 
from a laptop in a car in the headquarters parking lot to demonstrate the extent to which the organiza-
tion was in jeopardy. Remember this story as we look at the vertical archetype in the following section; 
we will return to it as an example of the predictable patterns of behavior in the archetypes.
Vertical, Horizontal, and Blended Cultural Archetypes
Generally an archetype is deﬁ ned as “the original model of which all other similar persons, objects, 
or concepts are merely derivative, copied, patterned, or emulated.” In psychology, it is often described 
as an unconscious predisposition to perceive in categories, though not to be confused with stereo-
types. Archetypes are more fundamental and tend to endure over time and social system changes. 
Th e archetypes in our model reﬂ ect commonly understood models of relationship that can be traced 
to the beginnings of human organization such as families and military or religious organizations 
(Aronson, 1995).
The Vertical Archetype
Th e vertical archetype is based on a fundamental model for organization relationships—the hier-
archy. Although it may be arguable that there is some degree of hierarchy in all organizations, 
there are signiﬁ cant diﬀ erences in culture tied to the depth and rigidity of that hierarchy.
Deep and rigid hierarchy is visible in the earliest models of organization. Whether it is in a 
family, an army, or a church, position in the hierarchy deﬁ nes formal A&A. Of course there are 
those in the lower levels of the hierarchy that wield power beyond that vested in their formal roles; 
but that is a subject for another treatise. Here we are concerned with the expected characteristics 
of the formal organization.
Let us look at the characteristics of a well-run vertical organization:
Membership comes from actual or virtual belonging to a familial system. For example, the 
owner’s relatives may be employed by the company and others are told that they are joining 
a virtual family when they are recruited or interviewed for employment. In most cases this 
promise of work life analogous to family life is presented as a positive aspect of the culture. 
Th is promise will become a key feature of the individual psychological contracts of employ-
ees and unless what it means is made very speciﬁ c, it is subject to wide variance in individual 
interpretation. Some people grew up in loving extended families with strong rituals and 
close relationships. Others grew up in families that provided identity and economic support 
but little in the way of togetherness and aﬀ ection.


124  Information Security Management Handbook
Continuation of membership is dependent upon compliance and loyalty to leaders. More than 
a few people have been let go from organizations for violating the expectation of loyalty.
Ideal leader is a strong, caring parent. Deeply vertical organizations led by cold and distant 
parents tend to be dysfunctional in the same way that families would be. Th at is to say that 
behavior of subordinates is driven more by fear than by desire to please a loved and respected 
leader. Remember our gentleman with control of the radio frequency identiﬁ cation system in 
our manufacturing client. He had managed to create an aura of fear around himself such that 
people were unwilling to confront his clearly dysfunctional behavior. Th e fear probably had its 
origins in his own fear of being perceived as redundant. If he owned something both mysterious 
and important his personal job security could be enhanced. His “crime” was compounded by a 
largely disinterested senior management that the IT staﬀ  were sure would not intervene in the 
name of a more secure network. Of course there was no truth to the belief that management did 
not care; they were merely ignorant and no one was willing to risk being the whistle-blower. It 
took an outside agent to raise awareness and change the dysfunctional dynamic. Th is was clearly 
an example of poorly executed senior management because in any vertical system the parent 
ﬁ gures have to express caring or concern before people will believe that they have it.
Leadership role is assigned along with legitimate status and authority. Th e extent to which 
a person is expected to be a leader is determined by whether there are subordinates to his or 
her position.
Ideal member is a dependent, well-adjusted child. Th is contract for dependency is a critical 
part of the psychological contract in vertical organizations.
Authority and accountability are distributed in direct proportion to vertical position.
Superiors are the primary source of direction, feedback, and recognition or reward. It is com-
mon for leaders to tell subordinates that their job is to “make me look good” in exchange for 
benevolent treatment.
Information is handled on a strict need-to-know basis. Th is is obviously crucial in the shap-
ing of security policy and practices.
Permission is generally required before acting. Th is is also especially important to security 
programs.
Members relate to one another as parent to child (leader to follower) or as siblings (peers). 
Th is is a more subtle but nonetheless important feature when we look to align security policy 
and practices with the culture.
Work and people are organized along department or functional lines. Th e good (or bad 
depending upon how you view it) news here is that a signiﬁ cant amount of organizational 
behavior is fairly predictable.
Change initiatives such as program or system implementations can be propelled to success 
by directives from respected (or feared) senior people who can compel compliance.
The Horizontal Archetype
Still fairly rare but visible on the horizon of organizational evolution is the horizontal organiza-
tion, which claims maximum versatility, resilience, and speed of both operations and adaptation. 
A well-run horizontal culture looks like the following:
Based upon a “community of well-adjusted adults” with minimal hierarchy as the model for 
organization (ﬂ at structure).













Security Strategies  125
Emerging as an organizational model along with the spread of technology. Th e nature of 
technology urges the work surrounding it to be more team-based and customer-driven. Th us 
the inﬂ uence of technology on the design and conduct of organized work is to ﬂ atten orga-
nizations to enable faster processes and increased throughput.
Membership hinges on eﬀ ectiveness in adult-to-adult relationships. Single superior–subordinate 
relationships are not the key to personal eﬀ ectiveness. People must be able to function eﬀ ectively 
in teams and often in multiple teams.
People are organized in teams responsible for projects (long and short term).
With the exception of a team or person at the top with responsibility for strategic plans and 
noncustomer external relations, leadership is a more distributed function.
Information is handled on a good-to-know basis. Th e default position is for information to 
be pushed at people rather than held from them. Selecting the important from the unim-
portant becomes a core human competency.
Permission from superiors before acting is seldom required though assent from aﬀ ected 
members may be commonly required. Getting the team or the customer on board before 
acting is the ongoing challenge. Highly conﬁ dent people will take risks when time does not 
allow for consensus building.
Direction is primarily informed by customer’s needs and team culture. Th e assumption is 
that meeting customer needs in a fashion consistent with healthy team norms is the path to 
eﬀ ectiveness.
Feedback comes from customers and teammates as well as directly from the work. Th e now 
familiar 360-degree feedback does not have to be solicited because it is frequently available.
Authority and accountability are widely distributed and sought by those in a position to 
impact customer satisfaction, revenue, and organizational continuity. Acquiring more 
authority, which is often a goal of politically active people in more vertical organizations, is 
of little value in a ﬂ at organization where the structure of work is more dynamic.
Change initiatives such as program or system implementations will normally require sig-
niﬁ cant investments of time, eﬀ ort, and materials to educate and enlist the cooperation 
of organization members. Such investments are returned in the speed with which actual 
implementation can be achieved.
Archetypes in the Middle
Th e vast majority of organizations today have a culture that is a blend of vertical and horizontal ele-
ments in the contract. It could be said that such an organization is “neither ﬁ sh nor fowl” and unsure 
of its own identity, but that is not really the case. As it turns out, an organization culture can have 
elements of both vertical and horizontal archetypes. Such an organization may be more complex to 
manage but it can run well so long as everyone is aware of the contract requirements such as:
Fundamental hierarchy that includes elements of a horizontal archetype. People are  primarily 
accountable to a superior but get signiﬁ cant direction from customer needs.
Probably the most common type found today. As organizations evolve along with the spread 
and development of technology pure verticality is disappearing. Th is is even true for military 
organizations that are now considering the combat team as their primary unit rather than a 
large organization of soldiers.













126  Information Security Management Handbook
People are organized by function, and work may be organized by function or by project. 
Th e value of projects is understood but eﬀ ectiveness in project and portfolio management is 
often confounded by behavior driven by hierarchy.
Direction may come from superiors or customers but evaluation of performance is primarily 
by superiors.
Authority and accountability tend to ﬂ ow upward but may be temporarily distributed to 
teams working on key projects. High-proﬁ le projects are often a path to recognition and 
advancement.
Management is signiﬁ cantly more complex owing to the blending of vertical and horizontal 
archetype characteristics. As an organization becomes more horizontal, managers must be 
eﬀ ective in all directions. Professional staﬀ  members are often more comfortable working 
directly with customers than they are taking direction from functional superiors.
Permission to act is generally necessary but successful risk-taking will be rewarded.
Leadership in functions is vertical and in project teams may be distributed.
Accommodates the widest variety of psychosocial contracts because messages about organi-
zational expectations will contain emphasis from both ends of the continuum, from vertical 
to horizontal.
Reference to both vertical and horizontal systems produces a highly political climate in 
which power, the trappings of power, and pursuit of power are constantly visible as features 
in day-to-day dynamics.
Both formal/public and behind-closed-doors are important methods of communication.
Change initiatives such as program or system implementations are dependent upon top-
management commitment and support as well as successful engagement of aﬀ ected organi-
zation members.
Th e key feature that changes among archetypes across the continuum is the distribution of owner-
ship, both felt and actual. It is this feature that most strongly inﬂ uences the array of characteristics 
in any organization culture. In recent history, monarchy has all but disappeared as a governance 
model for nations, and community has been successful only in small experiments for relatively 
short periods of time. Th us, the most frequently appearing archetype will be a blended one pos-
sessing characteristics of both vertical and horizontal archetypes. IT organizations are urged by 
the nature of their work (often complex and requiring team eﬀ ort) to be more horizontal than 
vertical and to organize in teams rather than functions. Th is is a key factor in complicating change 
initiatives in mature organizations.
Not Only What but How Well
Th e key reason it takes some skill to interpret the results of an assessment of culture is that it is 
not quite enough to know what archetype is operant in an organization. It is also necessary to 
have some insights into how well that archetype is being expressed. For example, a purely vertical 
organization can be very eﬀ ective but only if there is strong, competent, and caring leadership at 
the top as the model for other leaders in the organization. We have worked with a privately held 
company that is managed at the top by an owner/manager whose lack of leadership is reﬂ ected in a 
poverty of leadership throughout the organization. Political inﬁ ghting, poorly founded decisions, 
wasted resources, and fearful people are the inevitable results. For reasons not discussable here, the 
company is successful but not because it is a well-run vertical archetype. In fact there is tremendous 











Security Strategies  127
potential in the company that is unlikely to be realized so long as the present leadership is in place. 
Its security policies and practices reﬂ ect this lack of leadership. Security policy is unclear and there 
is no coherent strategy driving security practices. Talented security professionals are relegated to 
policing functions and are not invited into the design stages of new systems and processes. Security 
is treated largely as a necessary but not particularly welcome afterthought. Morale in the security 
oﬃ  ce is low and turnover exceeds normal expectations. All in all and despite excellent cutting-edge 
technology this is a security function without a positive impact on the business (Figure 8.5).
To understand the impact of management eﬀ ectiveness, it is necessary to look at the stable 
characteristics of the organization and make an educated assessment as to how well they are being 
expressed. For example, in a blended archetype organization, information will be managed essen-
tially on a need-to-know basis, but there must also be a strong internal communications function 
that can push necessary and suﬃ  cient information out to the population so that the employees can 
adequately serve customers and represent the organization to them and other outsiders. Drawing 
the links between culture and strategy demands a proﬁ le that identiﬁ es the archetype and assesses 
its eﬀ ectiveness, but of the two factors the archetype will always be the more powerful.
Linking Strategy to Culture
By now you may have begun to see how the classiﬁ cation system based on vertical, horizontal, and 
blended archetypes can inform the design and implementation of security policies and practices. 
Th e linking process is shown in Figure 8.6.
Th e more vertical the organization, the more top–down its dynamics and the more employee 
behavior can be inﬂ uenced by demands for compliance.
As organizations become more ﬂ at and horizontal, the drivers of behavior are more varied and 
include customer and peer inﬂ uences. Th e business case for behavior becomes more important than 
compliance when change is implemented in ﬂ atter organizations. How people deﬁ ne value is driven 
more by customer needs and actual impact on operations than by how much superiors approve.
Management effectiveness
Low
High
Suboptimal
organization effectiveness
Optimal organization
effectiveness 
High
Suboptimal
 organization effectiveness
Suboptimal
organization effectiveness
Alignment
Figure 8.5  Optimal culture—Management alignment.

128  Information Security Management Handbook
A characteristic of ﬂ at organizations that ﬂ ies in the face of many people’s fundamental 
assumptions about the workplace is that the most knowledge about what must be done to meet 
customer needs and advance business objectives resides in the lower levels of the company rather 
than only at the top. Many in the workplace are comfortable with the assumption that the more 
senior the persons are the more they know. Of course, when information is managed on a very 
strict need-to-know basis this is often true, because low-level people are not asked to clutter their 
thinking with real business knowledge, so it is kept from them.
If the contract that an individual accepted along with employment calls for appropriate depen-
dence (vertical archetype), people are less likely to resist security controls. If the vertical organi-
zation is led by a truly caring leader, resistance is even less likely because such a person will be 
assumed to have the best interests of the business and of the people in mind when creating and 
applying policy.
In vertical organizations people feel powerful because they hold titles, have inside information, 
and have strong relationships with others who also hold titled positions. In ﬂ atter organizations 
people feel powerful because the feedback they get tells them that they are having the desired 
impact on customer satisfaction and are working well with teammates. Th ese are nothing more 
or less than diﬀ erent deﬁ nitions of competence. Th e strategies that a security program chooses 
must recognize this sort of fact. Consider this example of how diﬀ erent types of organizations can 
respond to a common threat to security—social engineering.
Recognition of the social engineering threat includes acceptance of the fact that this is one of the 
most diﬃ  cult threats to reduce, because both the threat and the solution involve inﬂ uencing human 
behavior. Let us assume that the cultural archetype in this organization is blended, so we may infer 
that behavior is inﬂ uenced both by strong leadership and by customer needs. Th e archetype also 
suggests that our eﬀ orts will be positively inﬂ uenced by eﬀ ective performance management and 
employee relations practices. Let us say that our organization is fairly typical in that performance 
evaluations are done on an annual basis by direct supervisors who may or may not have input from 
customers and peers of subordinates. Further let us assume that our employee-relations practices are 
focused on reducing risk to the organization, as is the case in most organizations today. Of course 
there are likely to be other factors, but let us focus on these for purposes of explanation.
Formal written policy is organization law. For our security policy with regard to social engi-
neering to have weight it will have to be visibly blessed by top management. Th e policy should 
also deﬁ ne infractions as well as including a general description of administrative consequences 
for violations of the policy, so its language must be coordinated with the human resources oﬃ  ce 
as well as legal counsel.
If there are administrative consequences for infractions, there must be some method of enforce-
ment implemented and publicized to deter policy violations. If we believe that our perimeter 
Threat
Archetype
Analysis of salient 
factors
Vertical
Blended
Horizontal
Top management decree + training + punishment
Top management decree + training + punishment + communication
Idea mining + education + high touch communication   
Options
Figure 8.6  Linking culture to strategy.

Security Strategies  129
security is weak because people are frequently allowing “tailgating” by strangers, we might install 
video surveillance at the entrances both as a deterrent and to capture a record of infractions.
We might also implement training to ensure that everyone in the organization understands 
both the nature and the threat of social engineering, because the phrase is not self-explanatory. 
Initially this training will have to be done across the population and the best method might be 
a video- or computer-based approach that ensures access to the information but does not place 
great demand on people’s time. Media materials in support of this policy should include the 
image and voice of top management to lend credibility to the messages. In our organization, 
policy and training language should also include information about impact on the customer 
experience and company proﬁ tability (especially important if employees have an ownership stake 
in the company). For ongoing training the introduction to security policy and practices should 
be a part of formal and informal new-hire orientation.
If we were addressing this threat in a horizontal organization, our approach would be diﬀ erent. 
Our focus at the outset would be on developing ideas from among the employee population about 
how the threat can be addressed by policy and practices. Th e responsibility for enforcement would 
be distributed among the population and education about this part of role expectations would be 
“high touch” rather than “high tech” and directly involve the most senior managers in the orga-
nization. Discussion of security threats of all kinds would include metrics that describe the impact 
of breaches in business terms. Th e extent to which people at various levels in the organization are 
directly involved in strategy and program development varies with cultural archetype as is shown 
in Figure 8.7.
You may be able to see from our example that understanding the culture in terms of the 
most positive aspects of the archetype logically leads to workable strategy. Th e archetype 
also discourages the endless analysis of culture that can come from inclusion of every idio-
syncrasy of a physical or social behavioral nature in a description of culture. Th e principles 
underlying the archetypes give you a solid foundation upon which to base policy and practice 
recommendations.
Direct Employee Involvement
A
r
c
h
e
t
y
p
e
Vertical
High
Horizontal
Low
Figure 8.7 Employee involvement by archetype.

130  Information Security Management Handbook
Presenting Assessment Results
Focus on Strategy
It is not necessarily required that the results of an assessment of culture per se be presented to 
anyone. Th is is truer if the organization is more vertical. It is the strategies that matter to people 
because the strategies will impact operations and behavior. So, it can be enough to say that an 
assessment of organization needs with regard to security policies and practices has led to a set of 
strategies that are aligned with the current culture and business needs. Th us it is the strategies that 
are presented and not the direct results of the assessment.
If They Really Need to Know
If there is an organizational interest in what drove the creation of strategies, choose the briefest 
description of the assessment process that you can. You may want to dazzle people with your 
brilliance but we have learned that there is little value in overinforming senior people. Th ey have 
neither the time nor the patience to wade through a lengthy dissertation on the theory behind 
your conclusions. Lead with results (strategies suggested or implemented), even if you have been 
asked to talk about methods, and then describe methods brieﬂ y. Finish with how the strategies 
are expected to support organizational goals. Remember to give credit to your steering committee 
or your program management team or whoever supported your eﬀ orts in developing the strategic 
direction of the security program.
It is generally a good idea to make presentations to management as if what you have done has 
been a roaring success. If you have botched the job badly nothing you say is going to help. If there 
is any kind of case to be made for a positive view it may have the eﬀ ect of mitigating a negative 
minority opinion.
Some Final Thoughts on Culture
Is there an ideal culture for optimal security? Given the conventional wisdom about what culture 
is and how to understand it, this could be a reasonable question. Actually the answer is “no,” if 
we are talking about an ideal archetype. Th ere certainly can be a well-executed cultural archetype 
combined with strategies that are appropriately aligned with that archetype.
A basic assumption behind the existence of security programs and practices is that there are 
limits to the extent to which people can be trusted. Th ese limits are drawn by our inability to 
predict perfectly what any individual person will do in a given situation. Although we can and 
do know a fair amount about the general processes of individual motivation and social interac-
tion, there is at least an equal amount that we cannot and do not know about what an individual 
is likely to do in a given situation. Th us we are driven to make ourselves and our property secure 
from human mischief and malevolence in that realm of uncertainty.
Human behavior is driven by both individual and social inﬂ uences. Organization leaders 
shape the attitudes and behavior of the people within their sphere of inﬂ uence by the policies and 
practices they promulgate and the behavioral models they present (social inﬂ uence). Managing 
well, which to us means managing in positive alignment with the cultural archetype in place, is 
the path to reducing the likelihood that your security program will have to focus most on protect-
ing the organization from its own people.

Security Strategies  131
Th e social inﬂ uence of leadership is one of the most powerful forces available to ensure the 
security of people and property.
As a security professional you have an obligation to provide lead-
ership by aligning your program with the cultural reality in your 
organization.
If it looks like a duck and it quacks like a duck and it waddles like a duck, there is a fairly good 
chance that it is a duck. Your job is to help it be the absolute best duck that it can be.
Excellent alignment of programs with culture fosters faith in leaders.
Faith in leaders encourages trust in policies and practices. Faith and trust within the organization 
makes your job much simpler in that you can focus on the threats from outside and on helping 
business operations to have necessary and suﬃ  cient security without it having to be an inhibiting 
inﬂ uence. Rest assured that if your security measures are not aligned with the culture and with the 
needs of business units they will be ignored eventually by your own people. As a staﬀ  professional, 
you do not want enemies within the management ranks of your organization.
You want to be perceived as an ally in reaching the business goals of 
the organization and it is your job to align your program with those 
goals, not the other way around.
Can culture be changed? Most certainly culture can be changed. Th ere are numerous examples 
of cultural change in management history. Most rapid and dramatic changes, though, have come 
about because organizations are in serious trouble. Under these conditions, change is both pos-
sible and relatively easy, though not painless. A much more productive path to change is found 
in accepting the archetype for what it is and optimizing the way that it works. For example, if 
the culture is vertical, then strong, caring leadership is necessary. If the culture is horizontal, then 
team performance metrics and frequent customer feedback must be in place. For a blended culture 
to work well, there must be strong, caring leadership and very eﬀ ective project management. Of 
course there are numerous other management practices in all cases that can be optimized. Th e key 
is to accurately assess those that are out of alignment in any way and change them.
In one organization with which we have worked there was a deep crisis period that caused 
extensive force reduction and broad ﬁ nancial restructuring. One of the most powerful changes 

132  Information Security Management Handbook
that helped the company to bounce back was to change the work schedule. Th ey lengthened the 
workday slightly Monday through Th ursday and ended the formal workweek at noon on Friday. 
Th e culture in this consumer products company was a blended one that had grown up from an 
owner-managed family business to a billion-dollar giant in its industry. Both product develop-
ment and technology projects were in need of vastly improved management. Th e changes that 
the remaining people were being asked to accept would certainly have been resisted more if not 
for the enormous morale boost that came from giving employees Friday afternoons oﬀ . In fact, 
informal measures of attendance some months after the change showed that a signiﬁ cant number 
of employees were working into Friday afternoon anyway.
In this company, the transition from pure verticality to the blended archetype took place over a 
period of 40 years and change was still under way at a glacial pace. Some might say that the culture 
changed when emphasis was placed on improved project management and support for employee 
morale. In fact the changes did nothing more or less than bring policy and practices more into 
alignment with the blended archetype.
Real culture change can be seen in other companies. Jack Welch took a very large mono-
lithic company with a very vertical culture and broke it into smaller business units with increased 
accountability for performance. Th is forced the company to move toward a more horizontal arche-
type that was more nimble and competitive in the changing markets in which General Electric 
(GE) operated. Th is example of deliberate change for the purpose of improving a company that 
was generally proﬁ table and healthy is signiﬁ cant in part because it shows how long it takes for 
change in a cultural archetype to take place. Mr. Welch spent the better part of 20 years achiev-
ing the changes he set out to implement and there were many instances in which there was a 
temporary misalignment of practices with the emerging culture. Both people and processes had to 
change and change generally brings some measure of discomfort along with its beneﬁ ts.
Should culture be changed? Just because a thing can be done does not mean that it should be 
done. In the case of GE the change was led by a visionary manager who could see decades into 
the future and was willing to do the hard work of sticking to the path that he set. He was a strong 
leader and opened up opportunities for people to become more accountable and able to have more 
direct impact on how things got done within GE divisions. Th e growth that the company experi-
enced during his tenure is testimony to the wisdom of his leadership.
By contrast during the late 20th century a number of companies quickly embraced the bright 
promise of Total Quality Management (TQM) without understanding that full implementation 
would require changes in culture to accompany the implementation of quality tools. Essentially the 
full value of TQM required that work become designed around teams, that structures become ﬂ at-
ter, and that more information be made available to more people. Organizations that were unwilling 
or unable to make that sort of radical change got little beneﬁ t from quality tools and practices.
Th is treatise was intended to provide some practical instruction as well as to demystify the 
question of aligning culture with security program design. Our experience tells us that if you apply 
the information thoughtfully, you will increase the likelihood of your program being successful. 
And if you apply this knowledge, let us know how it worked for you.
References
Aronson, E. (1995). Th e Social Animal, New York: W. H. Freeman.
Biddle, B. J. (1979). Role Th eory: Expectations, Identities and Behaviors. New York: Academic Press.
Chilton, K., and Orlando, M. (1996). A new social contract for the American worker. Business and Society 
Review, 96(Winter), 23–26.

Security Strategies  133
Laker, D. R., and Steﬀ y, B. D. (1995). Th e impact of alternative socialization tactics on self managing 
behavior and organizational commitment. Journal of Social Behavior and Personality, 10(September), 
645–660.
Morrison, E. W., and Robinson, S. L. (1997). When employees feel betrayed: a model of how psychological 
contract violation develops. Academy of Management Review, 22(1), 226–256.
Nelson, D. L., Quick, J. C., and Joplin, J. R. (1991). Psychological contracting and newcomer socialization: 
an attachment theory foundation. Special issue: Handbook on job stress. Journal of Social Behavior 
and Personality, 6, 55–72.
Rousseau, D. M. (1989). Psychological and implied contracts in organizations. Employee Responsibilities and 
Rights Journal, 2, 121–139.
Rousseau, D. M. (1990). New hire perceptions of their own and their employer’s obligations: a study of 
psychological contracts. Journal of Organizational Behavior, 11, 389–400.
Rousseau, D. M. (1995). Psychological Contracts in Organizations: Understanding Written and  Unwritten 
Agreements. Th ousand Oaks, CA: Sage Publications.
Rousseau, D. M., and McLean, P. J. (1993). Th e contracts of individuals and organizations. In L. L. 
 Cummings and B. M. Stow (Eds.), Research in Organizational Behavior, Vol. 15, Greenwich, CT: JAI 
Press, pp. 1–47.


135
Chapter 9
A Look Ahead
Samantha Thomas
Contents
Opening Remarks ....................................................................................................................135
Future Challenges ................................................................................................................... 136
Policy ............................................................................................................................. 136
Workforce .......................................................................................................................137
External Customers ........................................................................................................138
Information Technology .................................................................................................139
Footing for the Future: Buy-In and Communication ...............................................................140
Acquiring Buy-In ............................................................................................................140
Communication .............................................................................................................141
Conclusion ...............................................................................................................................142
Th is chapter is meant to provide the information security professional an awareness of the coming 
years’ information security challenges. Th ere are a variety of observations oﬀ ered with suggested 
solutions. Th is chapter should leave the reader armed with the readiness to solicit thoughtful 
questions from and oﬀ er solutions to his or her organization, business partners, and customers for 
planning of and success with their information security eﬀ orts.
Opening Remarks
It is a necessary and diﬃ  cult challenge to plan deliberately for information security. Short-term, 
one-year-ahead planning tends to be tactical in nature and ﬁ reﬁ ghting in reality. Strategically, orga-
nizations are charged with attempting to plan two to four years ahead, as most chief  information 

136  Information Security Management Handbook
security oﬃ  cers (CISOs) are required to provide strategic plans to chief ﬁ nancial oﬃ  cers for bud-
get purposes, for direct reporting to executives and directors for cultural support, and to internal 
business partners for stratifying relationships. Both areas of tactical and strategic planning require 
CISOs continually meet multiple challenges. Consistently certain challenges have reoccurred over 
the past 20 years: a signiﬁ cant shift in the manner in which society views privacy, a multigen-
erational workforce, and the rapid evolution of technology. Th ese challenges embrace all areas of 
business, be they academia, medicine, government, environmental science, manufacturing, etc. 
Although these challenges will likely not change in the coming few years, the nuances within each 
will continue to evolve.
Future Challenges
Policy
As the security of critical infrastructure for most countries continues to be a priority for top 
leadership, there will be consistent and continual growth of national policy (e.g., law, regulations, 
and civil codes) related to privacy and conﬁ dentiality of information. Certain speciﬁ c informa-
tion security policy and standards, including ISO17799 and BS7799, have experienced multiple 
updates, and there will be continued iterations and amendments. Th e European Union, Canada, 
and Australia already feel the tug of their constituents’ sensitivity to privacy and data protection 
in privatized corporations. Th ese three collectives will continue to have parliamentary struggles in 
maintaining the balance of previously published privacy regulations and the future needs of their 
constituency for privacy. Th e Organization for Economic Cooperation and Development and aﬃ  l-
iated countries will be creating more deﬁ ned speciﬁ cations, particularly in the areas of Computer 
Emergency Response Teams. Picking up the pace in this area we may also see an active increase in 
information security eﬀ orts in Turkey and several South American countries and related regula-
tions in Poland. Th e creation of a Basel III Capitol Accord may also include more input from U.S. 
ﬁ nancial ﬁ rms. In the United States the Real ID Act requirements may not be reinstated in 2009, 
whereas Patriot Act controls continue to cause controversy. With these far-reaching changes in 
policy, CISOs should develop a plan to work among and regularly meet with their risk managers 
and privacy oﬃ  cers. Awareness of the level of information security risk the company is willing to 
assume, and privacy and compliance concerns of these two key business partners, will be essential 
for CISOs to assist in maintaining the appropriate balance of risk tolerance of the organization 
and proper information protection controls. Th is is the perfect opportunity for information secu-
rity professionals to stand out as valued partners by demonstrating the ability to be an advocate in 
these areas, and by acting as a bridge for these partners to connect with the key program areas of 
a company by way of building risk reduction and compliance measures within business processes. 
It is also important to point out in the midst of continued conﬁ dential and sensitive information 
disclosures, that working with risk managers and privacy oﬃ  cers provides an opportunity to make 
clear that security breaches of all types will most certainly continue, to accept this reality as a risk 
of doing business, and to ensure the organization has a plan to handle them. Th is point cannot be 
stressed enough, as in this regard the information security professional position evolves into that of 
trusted guide and ﬁ rst responder. Popular media will continue to dote on ﬁ nding organizations to 
blame for breaches and repeat that blame time and again for months or even years. For the CISO to 
ensure that his or her leadership has a plan to respond that complements compliance with current 
and impeding policy, without taking blame but by accepting  responsibility, the  partnerships with 
chief legal counsel and public aﬀ airs will continue to be as critical as ever. To support decisions in 

A Look Ahead  137
this area, CISOs should also maintain consistent relationships with their legislative oﬃ  ces, policy 
committees, and research and development bureaus to stay abreast of policy and strategic business 
developments that will aﬀ ect the tactical and strategic planning of the information security pro-
gram. Th e CISO should keep those areas of business appraised of information security concerns, 
make recommendations of issues to be “on watch for,” and suggest changes or modiﬁ cations in 
current business practices to support the standard of due care set forth by the organization.
Workforce
Th e end of the ﬁ rst decade of the 21st century brings companies worldwide to a very signiﬁ -
cant turning point regarding the generations of their workplace. Th e majority of the “Greatest 
Generation” World Wars I/II-era workers in most countries will be leaving the workforce from 
what were the “second” jobs acquired after oﬃ  cially retiring from their pre-65-years-of-age 
company jobs (Table 9.1). Th eir ﬁ rst children, the leading cusp of the “baby boomers,” will 
be eligible for what many developed countries oﬀ er those citizens: pensions after 60 years of 
age. To this end there will be an enormous impact within the internal culture of all organiza-
tions. Not only will companies ill prepared for this exodus of knowledge come face-to-face with 
high personnel turnover rates, but also the information protection implications will be grave as 
company histories, intelligence, wisdom, and in-mind undocumented business processes leave 
factory ﬂ oors, hospitals, laboratories, data centers, government entities, technology companies, 
utilities, and universities.
Many information security challenges lie immediately ahead for those left to pick up the 
pieces—the tail end of the Baby Boomer Generation and early Generation X. Not only will these 
people be charged with leading organizations without the knowledge of the early edge baby boom-
ers and the (work) ethics of the World War II generation, they will also be the upcoming driving 
leadership in most worldwide organizations. Th ese workers will also be managing very diﬀ er-
ent generations: the ending cusp of the baby boomers, their fellow Generation X-ers, and all of 
Generation Y. While the tail-end Baby Boomer Generation prepares for retirement and “second-
career” pursuits, the early cusp Generation X leaders have many slippery slopes to overcome with 
information security, most notably the internal management of how the three generations work-
ing together perceive and manage information security. Th e issue is not so much the end result 
of compliance with policy and company regulations to protect people, information, and assets; 
more so it is the diﬀ erent pathway each generation feels is appropriate to use to get there. To this 
end, CISOs should work closely with their privacy representatives and human resources/personnel 
departments and stay acutely abreast of organizational change management eﬀ orts.
Another key issue in the area of workforce will be secure communication. Although the exit-
ing generations previously mentioned prefer communication by personal contact, live telephone 
conversation, and, to some extent, e-mail, the incoming leadership has used and will continue 
to use e-mail heavily and prefers employment as independent contributors by telecommuting, 
Table 9.1 Description of Generations
Greatest generation
Late 1900s–mid-1930s
Baby boomer generation
Late 1940s–early 1960s
Generation X
Mid-1960s–early 1980s
Generation Y
Late 1970s–early 1990s

138  Information Security Management Handbook
push-button technologies (e.g., interactive voice-response systems), and to some extent text mes-
saging on handheld devices. Following this will be the work(ing)force majority Generation Y. Th is 
generation is most at ease and even demanding of a work environment that uses Web-based soft-
ware applications, instant messaging, text messaging, and Webcam interfaces and desires a variety 
of these communication avenues available for them to pick and choose as they deem appropriate. 
Conversely this generation does not aspire to scheduling face-to-face meetings or using “regular 
oﬃ  ce” e-mail to conduct business, as they feel this takes away from their ability to multitask and 
provides for an unproductive work environment. Along with the observation that the communica-
tion preferences of Generation Y and those of the incoming leadership generation directly conﬂ ict 
with each other, the information security implications open up extensively in obtaining and main-
taining a high variety of communication avenues. Although secure communication challenges 
have always existed, the extent to which information is used, maintained, transmitted, shared, and 
disposed of increases many fold to accommodate this varied workforce. Also of note: the internal 
pressures of the workforce will increase due to the lack of Generations X and Y entering the typical 
corporate and government environment, as trends continually indicate these generations opting to 
pursue small businesses and entrepreneurial opportunities of their own. CISOs should continue 
building relationships with their Web-application developers, telecommunication specialists, and 
human resources/personnel staﬀ  and maintain heightened awareness of communication trends in 
their global and satellite oﬃ  ces. Th ese relationships will continue to be critical for assurance of 
properly implemented information security architecture methods and controls, meeting evolving 
compliance concerns, and having staﬀ  “separation and transfer” plans in place.
External Customers
In many instances the same information security concerns in the workforce will be mirrored in 
serving a similar demographic of the outside customer. To expand on the observations made ear-
lier, in many instances the customer base will be more youthful or aged than a standard workforce 
age base. Th e same theory mentioned above of oﬀ ering a variety of communication vehicles in 
the workplace to attract top personnel in many cases also applies to obtaining, maintaining, and 
enhancing the external customer experience, as well as making those oﬀ erings palatable to a cus-
tomer base that is a larger span in age. With a majority of business and government services oﬀ ered 
with continued global focus, the demand for secure computerized data and paper information 
has never before been such a signiﬁ cant factor in the company-to-customer interface. Beyond the 
eﬀ ects of security for conducting international business, customer expectations of organizations 
to have knowledge of, abide by, and have business and system processes that allow for compliance 
with regulations and policy will be met with little or zero fault tolerance. As the public continues to 
hear and understand that information security breaches (continue to) occur, their lenience toward 
an organization’s lack of proper processes will wane. Th is means an increase in constituency calls 
to government leaders to create and modify policy, letters to board members, pressure from stock 
holders, and waves of turnover rates in customer loyalty. It also means that the role of information 
security will grow from merely an integral program inside a company’s overall strategic direction 
to a more signiﬁ cant public relations issue and transparent role within and outside of an organiza-
tion. Th e challenge will be for CISOs to determine when and how to include their media relations 
staﬀ  and legal counsel when making decisions for what may not be obvious information security 
risks and what the company deems appropriate mitigation measures and controls related to public 
interpretation and trust. Further, these decisions are complicated by the globalization of business, 

A Look Ahead  139
the extreme variety of cultural expectations, and the continual changes in an individual nation’s 
information security and privacy policy.
Information Technology
Today the majority of an organization’s critical information has been converted into or originally 
developed within an electronic medium using computer systems. Th is fact brings signiﬁ cant chal-
lenges to both an organization’s CISO and its information technology business areas. Th e work 
plan developments for technology staﬀ  charged with managing enterprise architecture and business 
continuity programs rose high in 2002–2004, then dipped down after 2006. Attention to these 
plans, and their security, will rise again in the next few years. With technology and related disas-
ter recovery processes too quickly executed in response to the events on and after September 11, 
2001, the time is ripe, nearly ten years later, to revisit and revise business methods for the upcom-
ing decade. For this revision, the enterprise architect and chief information oﬃ  cer (CIO) (or 
chief technology oﬃ  cer, CTO) play pivotal roles in laying the foundation of success for the CISO 
to ensure that modiﬁ cations to an organization’s business continuity planning have at the forefront 
the secure availability of assets and information. Other aﬀ ected areas of information security related 
to information technology will be an increase in the use of smart-card and biometric technologies. 
Although the United States diﬀ ers from most other countries, with heavy use of the magnetic 
strip for various ﬁ nancial and identiﬁ cation card uses, the overall use of smart cards and radiofre-
quency identiﬁ cation will increase and continue to evolve. To this end the hiring of telecommuni-
cations specialists and outsourced telecommunications consulting services will rise as the demand 
for mobility, connectedness, and secure responsiveness increases. Th is also comes at a time when, 
along with using smart cards, the individual consumer (staﬀ  and customers) can aﬀ ord to purchase 
his or her own personal satellite telephone. Th e increased purchases of these phones bring about the 
evolution of handheld services to a highly integrated technology space—palmtops with rich data-
center-type capabilities. Th is convergence of connectedness gives leeway for mind-bending types 
of new communication vehicles, including not only the sharing of text and attachments from one 
handheld satellite device to another, but also packets of reduced video ﬁ les that may be transported 
via satellite and, when uplinked by the receiver, viewed as a holographic display (à la Star Wars) 
with several people simultaneously interconnected. As these evolutionary communication vehicles 
continue to push the envelope of technology and consumers’ demand for connectedness increases, 
the upcoming 2010 decade will see dramatic discoveries in these areas. For the organization’s inter-
nal technology administrators these quickly evolving changes mean a continual update of security 
parameters, notably the security aspects of a company’s system development life cycle. Another 
interesting side eﬀ ect of a company continuing to meet the secure communications demands of its 
staﬀ  and customers is a stronger push for vendors and product developers to resolve the ever-present 
security issues of bugs that continue to plague operating systems and commercial software applica-
tions. Depending on the severity of the issues this push may ascend to the regulatory level. Until 
then, certain information technology security-speciﬁ c software, such as vulnerability prevention, 
detection, and correction applications, will likely maintain its slow but steady climb. Also related 
to communication, there will be continued growth in both breadth and depth of search engines for 
use inside the organization. CISOs may thus see an increase in enterprise document management, 
digital rights management, and challenges in electronic discovery and forensic issues as they relate 
to access, appropriate use, and log monitoring. Related to all of these future areas of information 
security and information technology lies a responsibility of the CISO to partner with his or her 

140  Information Security Management Handbook
CIO, CTO, enterprise architect, and Web-application developers and ensure collective agreement 
on and diligently search for the most secure and least intrusive communication vehicles for staﬀ  
and customers.
Footing for the Future: Buy-In and Communication
For many CISOs gone are the days of “selling” the idea of information security to their executive 
leadership. Now are the days in which information security professionals must consistently and 
concisely show their value in the organization. Rubbing directly against this eﬀ ort is the accept-
able tolerance of time required for securing the physical, administrative, and technical areas of 
information and assets. In the past decade tolerance for a business’s downtime has been reduced 
from days to hours to minutes to eﬀ ectively nothing. As CISOs have moved from concentrating 
on detecting an event to event-driven planning, there has been an immense push on prevention 
since 2000. Th is push has led to an increase in work for the information security professional to be 
involved with much of the execution in front-end engineering and testing of business processes in 
attempts not only to prevent incidents but also to decrease business disruptions from downtime.
Acquiring Buy-In
CISOs must directly express to leadership the idea that information security not only is the 
responsibility of the organization for ensuring controls but also could and should be a realized 
ﬁ nancial opportunity from which every area of a business can reap beneﬁ ts. To do this, informa-
tion security professionals must not only advise, but also roll up their sleeves to assist colleagues 
when they need to integrate information security and privacy strategies into their own areas of 
business. Th is work moves beyond setting oversight policy and monitoring. It means making 
available the opportunity for other leadership in your organization to achieve measurements and 
milestones and to show innovation and creativity in information security within their own areas of 
business—notably strategic outcomes to report to executive staﬀ  and the board of directors as well 
as tactical outputs for internal business partners and other advocate areas. Key areas for acquiring 
buy-in include business resilience, competition, regulations, and legal constraints.
Business resilience. Th is topic is often the most diﬃ  cult area in which to acquire buy-in. Often 
there is a complacency among other areas of business that information security issues are 
by and large the sole responsibility of the CISO and there tends to be a quick forgetfulness 
of incidents as we become more agile with quick recovery that allows business to swiftly 
move forward. Th is is particularly obvious in regions where organizations are keenly aware 
of disruptions caused by natural disasters and power outages. Within the past decade there 
has grown a stronger interest in issues surrounding terrorism and personal safety for which 
tactics have greatly changed. For physical security there are fringe concerns, like climate 
inﬂ uences such as gas emissions and mismanagement of toxic waste and how these two areas 
aﬀ ect environmental factors, which in turn aﬀ ect the physical security of our information, 
assets, and employees.
Competition. An area often overlooked by CISOs is the information security implications of 
research and development, sales, and marketing on meeting their goals for being a lead-
ing contender in their market space. CISOs need to be continually diligent in examining 

A Look Ahead  141
how information security will aﬀ ect an organization’s ability to communicate worldwide 
and increase or reduce market shares, particularly after stocks dipped in the earlier part of 
the 1990s. Th is, along with the qualitative nuances surrounding international public image 
(which due to the Internet and media can be argued as all inclusive), demonstrate how the 
consequences of a poor image aﬀ ect an organization’s ability to be more agile and innovative 
than its competitors. If not carefully examined and executed, information security eﬀ orts in 
this space will continually place constraints in these competition-type arenas.
Regulations. Policy has received much attention in since 2005. Many countries—Taiwan, Tunisia,
Uruguay, Argentina, Hungary, Ireland, Canada, Australia, Turkey, Brazil, Pakistan, 
Cambodia, Philippines, the list goes on—continue a hard line striving to improve their 
security infrastructure and increase privacy directives. Th ird- and even fourth-party caveats 
written into comprehensive information security programs and business contracts will be 
looked upon to decrease risks by allowing examination of authorized access, use, etc., by 
a network of business partners who in turn have their own service provider and business 
partner agreements and controls that require agreement on how information security and 
privacy directives will be met.
Legal constraints. Simply put, ﬁ nancial obligations to protect company information and assets, 
and to keep liability to a minimum through risk management, must be ﬁ nite. Allowing lead-
ership to have the legal discussion of risk, budget, and strategic goals allows the organization 
as a whole to mitigate and accept certain risks while setting a standard by which the CISO 
can follow and adhere. Interestingly this also allows for an often-overlooked opportunity 
in the return on investment in information security, or better put, an area of cost savings 
overall in an organization. Th ese savings may be found in the examination of risk reduction 
as it applies to a company’s ability to negotiate a reduction in the amount of premiums and 
insurance coverage requirements.
Th is overview of key areas leaves CISOs with two inescapable truths for acquiring buy-in: 
(1) Although information security issues continue to be a heightened consideration for the man-
ner in which an organization conducts its business, the security professional will still be required 
to continue focusing on the narrow areas of protection, detection, and correction of breaches, 
while at the same time be challenged with the broader aspects of “the business” of its organiza-
tion. However, today and in the near future, security-related incidents that aﬀ ect public image 
and unauthorized releases of information come in hundreds of diﬀ erent forms and severity, and 
their eﬀ ects can be more crippling than ever. As an added concern, with help from the Internet 
and mass media, security-related indiscretions are reported worldwide when organizations do not 
respond well to these incidents. (2) Succinctly put, an organization employs a CISO to engage 
in securing information, as unplanned incidents—be they unauthorized access, modiﬁ cation, or 
destruction—are guaranteed.
Communication
To assist in addressing these two truths, the foremost advantage will be with those organiza-
tions that fervently integrate and weave more than just information security controls into an 
 organization. A successful CISO must communicate intent and build partnerships to create the 
vision one desires for their organization’s information security program. Th is obligates the CISO 
to create and lead a strategic and continuously evolving communication plan for the organization’s 

142  Information Security Management Handbook
information security program and must include educating customers, dispelling myths with inter-
nal business partners, and relating truths to leadership. For a communication plan to be strategic 
and for each information security eﬀ ort to be in alignment with that strategy, CISOs must ensure 
that leadership is aware that although the information security program is facilitated by the CISO, 
it is owned by the business—it is their program to support, nurture, ﬁ nesse, and continually 
improve upon as their own business areas grow and evolve. Another, sometimes diﬃ  cult, part of a 
communication strategy is the security professionals must acknowledge to internal staﬀ  and man-
agement that they realize the business staﬀ  understand their speciﬁ c program areas better than the 
information security staﬀ . Th is simple yet possibly ego-swallowing statement assists in establish-
ing a partnership between a security team and a business area because it moves a usually precon-
ceived group dynamic from that of a fault-ﬁ nding mission to a mutual respect for each program’s 
range of expertise. Another important success factor for the CISO to communicate to business 
areas that as their own business processes become more secure, logically they (the business areas) 
reap the beneﬁ ts of the information security successes. Further, the CISO should explain that the 
purpose of the information security program is not only to ensure programs and processes are in 
compliance with information security policy and standards, it is also to create a consultative rela-
tionship that allows business areas the opportunity to confer with their information security staﬀ  
so as to execute risk-mitigating decisions for their own business area. Th is provides an avenue for 
shifting business areas from simply trying to be in compliance with policy to actively engaging to 
make security-minded decisions about their programs. Th at said, certain business areas may still 
be resistant to this type of involvement and it will continue to be the CISO’s responsibility to con-
sistently and diplomatically remind business areas that by not being an active part of the informa-
tion security program, they accept the risks of not being fully engaged. Th is message should also 
be reiterated to an organization’s councils, committees, etc., whose members often make sweeping 
project and program decisions. Th e dynamics in those cross-functional groups are diﬀ erent from 
those of groups in similar working types collectively employed in the same area of business.
Conclusion
Th e pace at which business in today’s world moves will continue to be faster than we have ever 
experienced, and there will be continual gaps in the ebb and ﬂ ow of eﬀ ective communication of 
information security. In the workplace, technology upgrades and the diversity of how staﬀ  interact 
within a business are more prevalent than ever before. Th e way an organization conducts busi-
ness today is diﬀ erent from what it was as little as two years ago and will be diﬀ erent two years 
from now. In the years ahead the information security professional will continue dealing with the 
challenges of creating customer-centric information, security-sensitive leadership, and a security-
minded culture among its internal staﬀ , business partners, and customers. Taking time to examine 
the future and being mindful of what lies ahead will assist organizations in eﬀ ectively recognizing 
areas for success with their information security eﬀ orts.

DOMAIN
  
2
ACCESS CONTROL
Access Control Techniques


145
Chapter 10
Authentication Tokens
Paul A. Henry
Contents
Evolution of the Need for Authentication Tokens ....................................................................145
Password-Cracking Tools Have Also Evolved...........................................................................146
Strong Authentication Mitigates the Risks of Weak Passwords ................................................147
Tokens as a Candidate for Strong Authentication ....................................................................147
Common Types of Tokens .......................................................................................................148
Asynchronous Tokens .....................................................................................................148
Synchronous Tokens .......................................................................................................148
Tokens under Attack ................................................................................................................149
Evolution of the Need for Authentication Tokens
Remote access has opened up a new world of possibilities for the Internet-connected enterprise. 
Today, users can access their corporate network from a hotel room or coﬀ ee shop in nearly any 
city in the world. Network administrators can now manage the entire enterprise network from the 
comfort of their home, no longer needing to drive back to the oﬃ  ce at 3:00  to address a criti-
cal issue. Th in client technology and virtual private network access have made it possible to gain 
access to the enterprise network anytime from anywhere.
With the convenience and additional productivity aﬀ orded by remote access comes an enor-
mous amount of risk: Keylogger malware surreptitiously installed at 14 public Internet terminals 
in Manhattan allowed an attacker to compromise the personal information and network access of 
dozens of people and organizations. One Silicon Valley company endured months of unauthorized 
access by a competitor before they discovered the breach. In 2006, a well-organized identity theft 
ring victimized over 300 customers of a well-known ﬁ nancial institution, costing the  ﬁ nancial 
institution over $3 million in direct losses. Phishers plague the Internet on a daily basis, using 

146  Information Security Management Handbook
their social engineering ploys to harvest user credentials for banking and E-commerce customers, 
allowing them to quickly and quietly drain the customers’ accounts.
At the root of all of these exploits and, indeed, the cause of hun-
dreds of corporate breeches, countless identity thefts, and millions 
of dollars lost every year is the traditional password.
Th e average computer user has dozens of accounts online and at their job. Access to nearly all of 
these systems requires a password. Most people cannot memorize a diﬀ erent password for each of 
their accounts, particularly if they access certain applications only once a month. Here are some 
ways average users combat their memory problems:
 
1. Th ey choose one password for everything. Of course, if their password for their personal 
Web mail is compromised, chances are good that their company network password is com-
promised as well.
 
2. Th ey write their passwords down. One online study revealed that over 30 percent of people 
surveyed wrote their passwords down and “hid” them under their keyboards, on their sta-
plers, or in their desk drawers.
 
3. Th ey choose information they can easily remember. Many people—up to 35 percent, 
according to some experts—choose some piece of personal information: a name of a family 
member or pet or a birth date. Th e problem is such information is often common knowl-
edge. A potential hacker can make small talk in the lobby with an employee—and come 
away with dozens of passwords to try.
 
4. Th ey get clever. In one company’s password audit, 10 percent of passwords were “stud,” 
“goddess,” “cutiepie,” or some other vanity password. Even more disturbing, 12 percent of 
passwords were “password”—and most of the users who chose it thought that it was a clever 
choice. Th e problem is that hackers know all of this. Before they attempt personal informa-
tion to crack a password, the ﬁ rst thing they try is “password.” Hackers will also pretend 
to work at a company, striding conﬁ dently into the front doors with a nod of the head to 
the security desk or the receptionist. Any passwords on monitors or under keyboards are 
fair game. Once a hacker has cracked a password, they can view conﬁ dential documents or 
e-mails without the organization ever knowing about it.
Password-Cracking Tools Have Also Evolved
Traditional brute-force password-cracking tools grinding through lists of known passwords or 
automatically trying each and every letter, number, and symbol in machine-generated password 
guesses are no longer the primary tool for cracking user passwords to gain privileged access. Th e 
traditional brute-force password cracker has evolved to include the use of precomputed password 
hashes. Rainbow tables—a set of downloadable algorithms—allows a malicious hacker to precal-
culate each and every combination of letters, numbers, and symbols in various password lengths. 
Once a set of tables is calculated, guessing the password is no longer necessary; it is simply looked 
up in the precomputed hash database.

Authentication Tokens  147
Instead of the time-consuming task of guessing passwords, precom-
puted hashes allow the password-cracking tool simply to look up 
the password hash in the precomputed hash database and return 
the password.
Strong Authentication Mitigates the Risks of Weak Passwords
Th e answer to this huge problem is strong authentication. Th is refers to factors that work in combi-
nation to protect a resource. Automatic teller machines (ATMs) are the most common example of 
this: to access their checking account, customers must use two factors to be authorized. First, they 
must have their physical bank card (one factor: what you have), and second, they must know their 
personal identiﬁ cation number (PIN) (second factor: what you know). Most people would not want 
their checking account guarded with just a PIN or just the card—yet companies use password-only 
protection to guard resources that are many times more valuable than the average person’s checking 
account. Government standards are now making it imperative to protect consumer information. 
Health care agencies and ﬁ nancial institutions in particular are ﬁ nding that implementing strong 
authentication is a step toward complying with recent legislation to protect patients and customers.
Without realizing it, many organizations had been using strong authentication for years: 
employees had to know passwords to access the company network (one factor: what you know), 
but also needed to be inside the building (second factor: where you are). But remote access has 
taken away the location requirement, as demanded by today’s business environment, and 
authentication has become vulnerable as a result.
Tokens as a Candidate for Strong Authentication
Tokens are small pieces of hardware, about half the size of a credit card (but a bit thicker), that 
often ﬁ t on a key chain (Figure 10.1). Like an ATM card, this factor is a “what you have.” Th ey 
often have liquid-crystal displays and give the user a onetime passcode for each log-in. Instead 
Figure 10.1 Token form factors.

148  Information Security Management Handbook
of logging in with a password, the user activates the token and types in the characters from 
the token display into the password ﬁ eld. Tokens usually require a piece of server software that 
allows or denies access to the user. Th e big advantage for most information technology depart-
ments is that token solutions do not require a piece of client software on the user’s machine. 
Tokens, therefore, can be used anywhere: on public Internet terminals, on the Web, from any 
laptop, desktop, or palmtop. Some users resist tokens initially, and some companies are con-
cerned about price: in excess of $70 per user as an initial cost for many solutions. But the solu-
tion is cost-competitive, highly reliable, and portable and is one of the simplest options available 
to deploy.
Common Types of Tokens
Current-generation tokens are available in form factors that are much less intrusive to users than 
previous-generation tokens. Nearly all token implementations today use onetime-password meth-
odologies. In eﬀ ect, the password is changed after each authentication session. Th is eﬃ  ciently 
mitigates the risk of shoulder surﬁ ng or password sniﬃ  ng, as the password is valid only for one 
session and cannot be reused.
Asynchronous Tokens
Th e asynchronous token, also called an event-based token or challenge–response, provides a new 
onetime password with each use of the token. Although it can be conﬁ gured to expire on a spe-
ciﬁ c date, its lifetime depends on the frequency of its use. Th e token can last from ﬁ ve to ten 
years and eﬀ ectively extend the time typically used in calculating the total cost of ownership in 
a multifactor authentication deployment. When using an asynchronous onetime-password token 
the access control subject typically executes a ﬁ ve-step process to authenticate identity and have 
access granted:
 
1. Th e authentication server presents a challenge request to the access control subject.
 
2. Th e access control subject enters the challenge into his or her token device.
 
3. Th e token device mathematically calculates a correct response to the authentication server 
challenge.
 
4. Th e access control subject enters the response to the challenge along with a password
or PIN.
 
5. Th e response and password or PIN are veriﬁ ed by the authentication server and, if correct, 
access is granted.
Synchronous Tokens
Th e synchronous token, also known as a time-based token, uses time in the computation of the 
onetime password. Time is synchronized between the token device and the authentication server. 
Th e current time value is enciphered along with a secret key on the token device and is presented to 
the access control subject for authentication. A typical synchronous token provides for a new six- 
to eight-digit code every 60 seconds; it can operate for up to four years and can be programmed to 

Authentication Tokens  149
cease operation on a predetermined date. Th e synchronous token requires fewer steps by the access 
control subject to authenticate the following successfully:
 
1. Th e access control subject reads the value from his or her token device.
 
2. Th e access control subject enters the value from the token device into the log-in window 
along with his or her PIN.
 
3. Th e authentication server calculates its own comparative value based on the synchronized time 
value and the access control subject’s PIN. If the compared values match, access is granted.
The use of a PIN together with the value provided from the token helps 
to mitigate the risk of a stolen or lost token being used by an unau-
thorized person to gain access through the access control system.
Tokens under Attack
Since tokens became the most popular alternative to traditional passwords only one attack meth-
odology has been successful in actually cracking them, and it was used successfully against only 
a single token vendor. Hackers reverse-engineered the methodology used in the calculation of the 
onetime password and using that, in combination with the token serial number and the token acti-
vation key, they were able to calculate the next eight onetime passwords that would be calculated 
by the token. Th is methodology was implemented in the popular Cain & Abel password-cracking 
tool v2.5 beta 21 (Figure 10.2) found at http://www.oxid.it/ and was mitigated by storing the 
activation key separately and securely until the vendor introduced a new version of the token using 
a diﬀ erent onetime-password computing methodology.
Figure 10.2 Cain & Abel password cracking.

150  Information Security Management Handbook
Tokens are inherently resilient to attack, but poor token implementations can provide weak-
nesses that can be taken advantage of by hackers. As recently as 2006 a man-in-the-middle 
(MITM) attack (Figure 10.3) was successful in compromising a token implementation for a popu-
lar bank. Although the attack relied solely on social engineering and did not exploit a weakness 
in the token itself it is important to consider this attack methodology in the deployment of any 
token implementation. One methodology of risk mitigation for this attack that is gaining popular-
ity is the consideration of the reputation (Figure 10.4) of the Internet Protocol address, network, 
or domain from which the authentication is being requested. By denying authentication from a 
source that has a “bad reputation” signiﬁ cant risk mitigation can be aﬀ orded in consideration of 
a MITM attack.
Current developments in identity and access management (IAM) solutions are also providing 
stronger token implementations by taking into consideration the security of the endpoint from 
which the user is authenticating. It is common in current-generation IAM product oﬀ erings to 
validate that
Th e endpoint is running the required antivirus software and the signatures are up to date.
Th e endpoint is running the required ﬁ rewall and the conﬁ guration matches the require-
ments of the enterprise endpoint security conﬁ guration.
Th e endpoint operating system is patched to current levels.
Th e endpoint applications are patched to current levels.




Figure 10.3 Man in the middle attack.
Attacker
Attacker
Customer
Attacker
Man in the middle
Http://www.phisher.com/fake.mybank.com
Http://www.phisher.com/fake.mybank.com
Http://www.phisher.com/fake.mybank.com
Https://www.phisher.com/fake.mybank.com
Https://www.phisher.com/fake.mybank.com
Https://www.phisher.com/fake.mybank.com
Https://www.mybank.com
Https://www.mybank.com
Https://www.mybank.com
Http://www.mybank.com
Http://www.mybank.com
Http://www.mybank.com
Real bank
Real bank
Real bank
Customer
Customer
2
1
3

Authentication Tokens  151
If the endpoint is found not to be compliant, access is denied and the user is constrained to an area 
of the network where the failures can be corrected prior to allowing the user to authenticate again 
to the enterprise network for permitted privileged access.
In closing, current-generation onetime-password authentication tokens by and of themselves 
can go a long way toward mitigating the risks associated with traditional passwords. However, to 
aﬀ ord maximum risk mitigation to the enterprise, authentication tokens combined with access 
control systems that use endpoint reputation scoring or security validation of the endpoint from 
which the user is authenticating should be considered.
Figure 10.4 Reputation defenses.
Computing
credit
Track
Compile
Compute
Use
Business transactions
Businesses and individuals
Physical world
Cyber world
IPs, domains, content, etc.
Cyber communication
Reputation score
• E-mail exchanges
• Web transaction
• URLs, images
• Good IPs, domains
• Bad
• Grey-marketing, adware
Allow/deny communication
• Stop at FW, Web proxy, mail gateway
• Allow
• Quarantine
• Purchases
• Mortgage, leases
• Payment transactions
• Timely payment
•  Late payment
• Transaction size
• Loan
• LOC
• Credit terms
Credit score
Allow/deny credit


153
Chapter 11
Authentication and 
the Role of Tokens
Jeff Davis
Contents
Overview of Authentication Factors .........................................................................................154
Types of Tokens and How Th ey Work .....................................................................................157
Token Management .................................................................................................................159
Conclusion ...............................................................................................................................160
References ................................................................................................................................160
Authentication is an important part of any system or application security. It is the basis for any 
access control that is needed over information that is in the system or authorization for any trans-
actions that could be carried out. To provide stronger authentication, tokens are increasingly being 
used to add an additional dimension or factor of authentication and to reduce the risk of an 
attacker impersonating a user.
Th ere are in general three diﬀ erent factors that are used in authenticating a user. Th ese factors 
are something you know, such as a password; something you have, which could be a token device; 
and something you are, which may be implemented through biometrics such as ﬁ ngerprints or 
other physical characteristics. Th is chapter will give an overview of authentication, the use of 
diﬀ erent factors of authentication to establish an identity, and some of the risks associated with 
the use of the diﬀ erent factors of authentication and how tokens can be used to mitigate some 
of them.

154  Information Security Management Handbook
Overview of Authentication Factors
Authentication is the act of someone establishing an identity that they have declared them to be. 
In the world of computers the most prevalent example is when the users authenticate to prove that 
they are the persons assigned to a speciﬁ c ID that is used to control access to a system. Th ere are 
three diﬀ erent types or factors of authentication. Th ese three factors are something you know, 
something you have, and something you are. Th ese can be used individually or together to authen-
ticate an identity.
Th e ﬁ rst factor, “something you know,” also called a shared secret, is generally implemented as 
a static password that is shared between the person needing to be authenticated and the server that 
authenticates the access (Figure 11.1). Th e process of authentication usually starts with the user 
typing in the password at the client. Th e password is then sent to the authenticating server and is 
put through a one-way hash algorithm to generate a hash for the password. Th e hash algorithm 
has the property that it will generate a unique hash for diﬀ erent passwords, but it is not possible to 
reconstruct the password from the hash value. Th is hash is then compared to the hash that is stored 
on the authenticating server to see if they match. In some implementations the hash is generated 
on the client before it is sent to the server. Th ere are a number of ways to attack this method of 
authentication, one of which is to intercept the password by monitoring or “sniﬃ  ng” the network. 
Encryption can be used to help prevent the interception of the password when it is passed over the 
network. Most Web portals utilize a secure channel implemented by the Hypertext Transfer Pro-
tocol when accepting authentication information to mitigate this risk. Another method of attack 
is through the use of a keystroke logger program that may be present on the end user’s device. 
Th ese programs can record everything that is typed at a keyboard, including passwords, and send 
it to a third party. Keystroke loggers are used in many computer viruses to collect passwords that 
can be used for further compromises or actual theft from online banking. Installing and keeping 
Figure 11.1 Example of client–server password authentication.
Authenticating
client
Authenticating
server
Password hash
match?
Password hashing
function (if not
performed on
client)
Yes
No
Password
data store
User supplies
password
Authentication success
Authentication failed 
Example of client−server
password authentication
Client
accesses
authorized
resources
Client denied
access
Password (or hash) 

Authentication and the Role of Tokens  155
up-to-date antivirus software will help prevent these viruses from installing the software. Th is risk 
can also be reduced by not using an account with administrative privileges for Internet browsing 
or reading e-mail. Th ese two activities are the most prevalent vectors used by viruses to infect 
machines. Typically if a virus is attempting to infect a machine via one of these vectors, it will run 
in the context of the user who is performing the action. If the user does not have administrative 
access to the machine then most viruses will not be able to install a keystroke logger. A third type 
of attack is one that uses social engineering to trick an end user into providing the credentials to 
a system that is owned or monitored by the attacker. Th is is commonly done through the use of 
phishing e-mails. A phishing e-mail is a fake e-mail that appears to come from an oﬃ  cial source. 
Th e fake e-mail prompts the user to supply their credentials via a Web link that is contained in the 
e-mail. Th e Web link appears to connect to the authentic system but actually points to a system 
that has been made to look like the real system but is owned or monitored by the attacker. Th ese 
attacks have become more and more sophisticated and can be successful even if a small percent-
age of users respond to the e-mail because of the volume of e-mails that are sent. Mitigating these 
attacks is very diﬃ  cult as it depends on modifying the users’ behavior so that they do not trust the 
links sent via e-mail. Because these attacks depend on user awareness of them they will continue to 
be successful in gathering passwords from users who are unaware of these types of attacks.
Another attack method against static passwords is to try every possible combination of pass-
words to determine the correct password. Th is is commonly referred to as a password-guessing 
attack or brute-force attack. Th is is generally done by capturing the computed hash of the  password, 
either through network sniﬃ  ng or from the server it is stored on, and then running a program to 
generate every possible combination of passwords, calculate their hashes, and then compare the 
hashes to the captured hash until one matches it. Th ese attacks can be time-consuming depend-
ing on the length and complexity of the password. For example, a password that is made up of six 
numeric digits ranging from 0 to 9 will have 1 million combinations that will have to be tried, 
whereas a password that is made up of six upper- and lowercase alphanumeric characters will have 
over 56 billion combinations. However, with the advances in processing speed, using a computer 
to generate all 56 billion combinations would still take only a couple of hours. To shorten the time 
even further, especially for longer password implementations, a brute-force attack can be sped 
up through the use of precomputed tables of passwords and their associated hashes, which are 
commonly called rainbow tables. If the hash of a password can be obtained from the authenticat-
ing server or intercepted on a network, then its corresponding password can be looked up in the 
rainbow table in a much shorter time frame. One protection against the use of rainbow tables is 
through the use of a “salt” as part of the hash algorithm. A salt is a number of bits that are added 
to the password before it is run through the algorithm. Th is eﬀ ectively lengthens the password and 
makes any brute-force attack more diﬃ  cult. Also the bits used in the salt may not correspond to 
any characters used to generate the rainbow table as they may be unprintable and usually not used 
in a password. Th is would make a rainbow table generated with printable characters ineﬀ ective.
Another implementation of the “something you know” factor is through the use of security 
questions and user-supplied answers. Th ese are questions and answers that have been registered 
between the user and the authenticating authority. Th ey are usually established as part of the 
registration process for establishing the ID for that system. Th eir most prevalent use is as a way to 
identify a user who has lost or forgotten his or her password and needs to reset it. Th is process is 
threatened if the questions use information that may be obtainable through public records, like 
mother’s maiden name or place of birth. Th e best implementations of this process utilize questions 
and answers that are selected by the user from a pool of questions and do not contain informa-
tion that can be easily obtained by third parties. Questions like “What is your favorite color?” or 

156  Information Security Management Handbook
“What is your favorite sports team?” are examples of questions that could be used. In practice, 
more than one question is usually used to verify the individual’s identity before any actions are 
performed.
Th e next type of factor is “something you have” or something you possess. Th is is usually 
implemented through the use of a device or token that the end user carries with him or her. Th is 
device or token will provide an authentication code that will be used to validate a user. In some 
implementations, this authentication code is combined with a personal identiﬁ cation number 
(PIN) or other password that the user knows to ensure that the device cannot be used by another 
person. In other implementations, the PIN or password is used to lock the device and prevent it 
from producing valid authentication codes until it is supplied. When the PIN or password and 
the device are used together, this is known as two-factor authentication. Th e devices mitigate the 
threat to the single-factor implementation of passwords by generating authentication codes that 
are onetime-use passwords. Th ese password are able to be used only once to authenticate and 
will be rejected if attempted to be reused. Th is negates attacks involving network interception or 
keylogging because of the dynamic nature of the password. Attacks against these devices usually 
involve the compromising of the communications channel from the end user to the server or are 
actual physical attacks against the devices themselves in an attempt to copy the device or deter-
mine some of its characteristics. Th ese systems involve increased costs for both the device and the 
people to manage them.
Th e third factor, “something you are,” is usually implemented via a biometric measurement. 
Th e most popular implemented biometric today is ﬁ ngerprint matching. Other biometrics that 
have been explored and have some limited implementations include iris recognition, hand geom-
etry, and voice recognition. Th is factor has the advantage of being extremely hard to steal and, as 
with a token, is usually combined with one of the other factors to increase its eﬀ ectiveness. Th ere 
are drawbacks to implementation of this factor as these systems do produce higher rates of false-
positives and false-negatives. Th ere is also some reluctance to use some of these implementations 
because of concerns that the measurement method may cause some harm. Many of these imple-
mentations are expensive but ﬁ ngerprint readers and facial recognition systems have been coming 
down in price as they become more widely available and are starting to be included as part of 
standard system conﬁ gurations. In general, the attacks against this factor usually are attempts to 
spoof the reader of the biometrics and take advantage of any weakness it has in properly measur-
ing the biometric. Th is has been especially true of some ﬁ ngerprint scanners being susceptible to 
fake ﬁ ngers molded out of plastic or gelatin.1 Th e technology of biometrics scanners in general 
is still being perfected and until the errors are worked out there will be a risk that they will be 
able to be bypassed by allowing false-positives or not allowing authorized users by generating a 
false-negative.
One other area of biometrics that is worth mentioning is a category called dynamic biometrics. 
Th is is a technology that attempts to use the action of doing something to identify a person. Th e 
two most prevalent are signature biometrics, which measures the pressure and dynamics of someone 
signing his or her name, and keyboard dynamics, which uses the speed, length of key presses, and 
rhythm of a user typing at a keyboard. Th is technology is in the very early stages of development 
and it has not had very many implementations so very little data is available about its eﬀ ectiveness.
One growing trend in the area of authentication is to use more then one shared secret factor 
(something you know) to authenticate an individual. Th is is done by requiring not only a pass-
word but also, in some cases, answers to predetermined questions. Another example may be the 
need to supply a password and select a previously agreed upon picture from a group of pictures to 
authenticate. Th is is done to try to provide additional authentication information that may not be 

Authentication and the Role of Tokens  157
in the possession of a potential attacker. In some of these implementations, this multiple authenti-
cation is done when something out of the ordinary occurs. Th is may be when the users log in from 
a workstation that they usually do not log in from or if they request to perform an unusual action 
like transferring an entire balance out of a bank account.
All in all, good authentication is important as the basis for access control to systems and appli-
cations. Authentication using shared secrets is coming under constant attack through the use of 
keyboard loggers and network monitoring that can record the information and make it available 
to a third party. Biometric authentication is becoming more widely available but still faces some 
usability hurdles and cannot be readily adapted to most current applications. Authentication using 
a token device that produces dynamic passwords is readily adaptable to most existing system that 
accept a password, it is cheaper than most biometrics systems and can be implemented with a 
PIN to provide two factors of authentication. Of the current methods available for authentication, 
tokens that are used to implement two-factor authentication seem the best solution for providing 
strong authentication, reducing the risk of compromise through interception.
Types of Tokens and How They Work
Devices or tokens that can be used to implement two-factor authentication can be grouped into a 
couple of diﬀ erent types or classes. Th ese types are time-synced devices that produce authentica-
tion codes at predetermined intervals, on-demand or asynchronous devices that produce codes 
when needed, and cryptographic devices.2 Th ese tokens use diﬀ erent methods to provide dynamic 
authentication information. Each of these types of tokens has advantages and disadvantages in the 
methods that they employ.
Th e ﬁ rst type is a time-synced token. Th ese tokens use synchronized clocks between the token 
device and the authenticating server to generate codes that can be used to authenticate. Th e token 
uses the time on the clock as part of the algorithm to generate a code that changes periodically. 
Th is code is then displayed to the user and is either used as the authentication code or combined 
with a PIN to form the authentication code that authenticates the user. In some implementations 
the PIN is entered into the device and is used as part of the algorithm to generate the authentica-
tion code. Th is method has the advantage that it will work with most applications with minimal 
change as the authentication code just replaces the password that would have been supplied by 
the user. One drawback that these types of tokens have is that the clocks will drift over time and 
will eventually become out of sync between the servers and the device. Th is may require that the 
tokens be resynced periodically with the servers if the drift becomes too large. It is important that 
the server maintain accurate time as well. Usually, this is done by using the network time protocol 
that uses a consistent time server to ensure that it keeps accurate time. Th e authentication process 
on the server will also attempt to measure the time drift between its clock and the token clock and 
adjust its authentication process accordingly. In some implementations the authentication process 
will use an authentication window, which will accept a range of authentication codes that are 
good over a predeﬁ ned time period. Th is will prevent an excess of rejected authentications due to 
clock drift between the authentication server and the token but also increase the number of valid 
authentication codes that will be accepted. Depending on how large a window is used, this may 
increase the risk that an attacker may be able to guess an authentication code, but the quantity of 
possible codes is usually so large that this risk is pretty low. Th ese tokens may also present some 
usability challenges as the code will be displayed for only a short time and may change while the 
user is reading it, requiring the user to start over.

158  Information Security Management Handbook
Th e next type of token is one that generates authentication codes on demand. Th ese devices 
use a counter that is incremented every time a code is generated and is used as an input into the 
algorithm that is used to generate the code. Th is counter is synchronized with the authentication 
server, which enables it to verify that the correct code has been presented. Th e authentication 
codes are onetime passwords and cannot be reused as the server will reject them. If the end user 
skips over a code without using it, the server will accept it as valid as long as it falls within a prede-
termined window of valid codes. Th e server does this by computing all of the valid codes starting 
with the current value it has of the counter up to the size of the window and comparing them to 
the presented code. If the code matches any of the computed codes in the window, the user will 
be authenticated and the server will resync the counter to the value used for that code and then 
increment it to match the value on the token. Th is allows the users to authenticate even if they 
inadvertently request a new code without using the current one. As with the time-synced tokens, 
this does increase the risk of an attacker guessing the password depending on the window size but 
the quantity of possible codes is usually so large that this risk is pretty low. One advantage of this 
type of device is that they are generally lower cost and last for a longer period of time than time-
synced tokens because they are not always producing codes. Th ey also do not experience any of 
the clock drift issues as they do not utilize clocks as part of their process. One drawback of using 
this type of device is that authenticating codes can be pregenerated and written down, and as long 
as they are used in order they will be valid. Th is would negate the need to have the token present 
while authenticating. Th is is a serious risk and can be prevented only through end-user awareness 
so that the codes are kept secure.
A third type of token device is a cryptographic smart card. Th is is generally implemented as 
a card about the size and thickness of a credit card that holds a small amount of secure storage 
and a processor that is capable of some cryptographic functions. Th e card is inserted into a reader 
that powers the card and provides the interface to the system. Smart-card tokens have also been 
implemented using devices that utilize USB connectors that are available on most newer comput-
ers. Th is is an advantage over the card implementation as a separate reader is not needed to be con-
nected to the system. Th ese devices perform authentication by relying on a type of cryptographic 
algorithm called public or private key. Th ese algorithms use two diﬀ erent keys, a private key, 
which is kept secret and stored on the device, and a public key. To ensure that the correct public 
key is associated with a user, the key and the identiﬁ er of the user are stored together in an object 
called a certiﬁ cate. Th e certiﬁ cate will then be veriﬁ ed cryptographically by a trusted certiﬁ cate 
authority to ensure that it is not altered. Th is certiﬁ cate is then stored in a directory as part of 
a public key infrastructure (PKI). Th e public or private key algorithm has the property that data 
encrypted using the private key is able to be decrypted only using the public key and that data 
encrypted by the public key can be decrypted only by the private key. Th e most widely used public 
or private key algorithm is the RSA algorithm, which is named for its creators—Rivest, Shamir, 
and Adleman. Th is algorithm is used by the devices to authenticate a user by having the device 
encrypt a challenge string that has been supplied by the system the user is trying to authenticate 
to. Th is data is then decrypted with the user’s public key by the authenticating server to verify that 
it has been encrypted by that user’s private key. Most implementations of these devices will use a 
PIN to unlock the card before it will perform any functions. Th e use of smart cards and public or 
private key authentication will also require the use of a PKI and associated certiﬁ cate authorities 
to manage and verify the public and private keys used in the authentication.
All physical tokens possess some safeguards to prevent physical attacks. If a token can be 
physically compromised and then reverse-engineered or if the appropriate secret information can 
be copied from it, then it can be duplicated without the user’s knowledge. Th is would compromise 

Authentication and the Role of Tokens  159
the token as it would no longer be unique to the individual who possessed it. Tokens are usually 
in form factors that are diﬃ  cult to break into without damaging the token to the point that it 
will not function and any secret key information cannot be read. Th ere have been some attacks 
against smart cards that involve manipulating data that is input into the card to be encrypted and 
timing the amount of time it takes to encrypt it to reveal information about the secret private key. 
Th ese attacks are time consuming in nature and require special equipment to enact. Th ere have 
also been adjustments made on the smart-card architectures and processing to thwart these types 
of attacks. Th ese kinds of attacks continue to be an area of ongoing concern as token device use 
becomes more widespread.
Token Management
Regardless of the type of token that is employed, there needs to be a process to manage it over its 
lifetime. Th is would include the initial distribution of tokens, replacing lost or expired tokens, and 
collecting tokens from employees who are leaving the enterprise. Th ese processes generally make 
use of a database to manage the tokens during their life cycle. It is also important that the distribu-
tion and replacement processes use appropriate authentication methods to verify that the correct 
person is receiving the token. If these processes can be subverted then any subsequent authentica-
tions will be compromised, as someone other than the appropriate person may be able to obtain a 
token in his or her name. Th ese processes may use trusted security oﬃ  cers to verify an identity or 
may be tied into the methods used to issue credentials for physical access to the enterprise. As a 
part of the procedure for issuing the token an alternate method of identiﬁ cation can and should be 
established. One method is to set up a series of challenge-and-response questions that can be used 
over the phone or through a self-service Web site to request actions like replacements or resets. It is 
important that these questions do not ask for easily obtainable information and are diverse enough 
not to be easily guessed. In general three to ﬁ ve questions chosen out of a pool of twenty are suﬃ  -
cient for this purpose. Th ese questions should be used only for this purpose and should not be used 
for day-to-day authentication. Th is will reduce the likelihood that they could be intercepted.
Th e distribution and management of tokens can add a lot of overhead to the total cost of own-
ership of the token. Th is is especially true if tokens need to be shipped individually to end users. 
If they are handled via a centralized process, people would need to be paid to assign the tokens 
and actually pack them individually for shipping. Th e method of shipping would also need to give 
reasonable assurance that the token is delivered only to the person to whom it is assigned. Th is 
can add cost to the process especially if the enterprise is at multiple geographic sites. Th is cost can 
be reduced by using automation that will assign tokens from a pool of unassigned tokens that is 
kept at various sites within the enterprise and distributed as needed. A Web portal can be used by 
individuals to assign themselves a token, provided that they can be authenticated in a satisfactory 
manner. In enterprises that require more assurance that tokens are assigned to the appropriate 
individuals, on-site security oﬃ  cers or other trusted individuals can verify the identity of a person 
before assigning him or her a token. In all cases, detailed audit trails should be kept to document 
the process in case there is any question in the future about who was assigned the token.
Th ere is also the potential to combine the physical access control of an employee badge with 
that of the smart card by using the same form factor. Th is is done by printing the badge informa-
tion, usually a name, photograph, and, possibly, some other enterprise information, on the smart 
card itself. Th is gives the enterprise the option of using the smart card authentication information 
to control building access. Th is also makes it easier to remove access; when an employee leaves an 

160  Information Security Management Handbook
organization and the badge or smart card is turned in, it will not only prevent them from entering 
the building but also prevent them from accessing any electronic systems or applications utilizing 
the smart card.
Conclusion
Authentication schemes that use static passwords are increasingly being compromised by attackers 
using network monitoring, viruses that install keyloggers on workstations, password guessing, and 
phishing that spoofs the end user into supplying the credentials to a third party. Th ese attacks are 
becoming more and more common. Other methods of authentication need to be implemented to 
reduce the ability of attackers to compromise those systems and applications that use static pass-
words. Biometric schemes that implement the authentication factor “what you are” would also be 
eﬀ ective but solutions are still somewhat immature and remain diﬃ  cult to implement, especially 
with legacy systems. Token authentication schemes that implement two of the three factors of 
authentication, “something you know” (a PIN) and “something you have” (the token device), seem 
to be the best solution to prevent these types of attacks. Token authentication would be easier for 
an enterprise to implement and would greatly reduce the risk of the authentication scheme being 
compromised within the enterprise.
References
1. Schuckers, S. (2002). Spooﬁ ng and Anti-Spooﬁ ng Measures, Clarkson and West Virginia University. http://
citer.wvu.edu/members/publications/ﬁ les/15-SSchuckers-Elsevior02.pdf
2. Tipton, H. F., and Krause, M. (2004). Information Security Handbook, Fifth Edition, Boca Raton, FL, 
CRC Press LLC.

Access Control Administration


163
Chapter 12
Accountability
Dean R. Bushmiller
Contents
Introduction .............................................................................................................................163
Assumptions ........................................................................................................................... 164
Deﬁ nition and Need ............................................................................................................... 164
Requirements Overview ...........................................................................................................165
Business Process Details ...........................................................................................................165
Technical Process Details .........................................................................................................166
Technical Process Implementation ...........................................................................................167
Th reats .....................................................................................................................................172
Who Needs to Be Involved? .....................................................................................................172
Summary .................................................................................................................................172
Introduction
What is accountability and why is no one willing to implement sound accountability mea-
sures? Accountability is neither popular with business nor is attractive enough for technolo-
gists to implement, and ﬁ nally, security professionals can barely keep up with audit. You heard 
it here ﬁ rst: Accountability will be the next version of audit, identity management, and systems 
administration.
Accountability is about as opposite to “set it and forget it” as you can get. Everyone is look-
ing for a silver bullet to kill the specter of compliance and regulation. But no silver bullet exists. 
Th e strength of our audit holy water gets dangerously diluted by the “turn it on when the auditor 
comes” attitude. It is time for the technical and business process of accountability.

164  Information Security Management Handbook 
Assumptions
To have a clear discussion on accountability, this chapter will be limited to the access control 
domain. In the access control domain, unique identiﬁ cation is assumed; without it, none of this 
concept or any access control methodology will be successful.
Discretionary access control (DAC) system failures are a reason for the need for accountability; 
therefore, DAC is the second assumption of this chapter. It is possible to adjust accountability 
concepts to ﬁ t role-based and mandatory access control systems.
Keep in mind, the author comes from a Windows background. Th e second section of this
chapter discusses Windows ﬁ le systems and tools to address logging “Windows style.” Technologies
discussed in this chapter can be abstracted to ﬁ t other situations such as implementations and rela-
tional database (UNIX-like) systems.
Th e information security management domain overlaps this topic speciﬁ cally in the area of 
policy. Policy on consent to monitor, escalation procedures, and audit are assumed for the success 
of any level of accountability. Physical security is assumed to be robust.
Th e basic assumptions of unique identiﬁ cation, DAC, and Windows will help narrow the 
scope of this topic into a chapter instead of an entire book.
Deﬁ nition and Need
Th e formal deﬁ nition of accountability is as follows: Th e principle that individuals, organizations, 
and the community are responsible for their actions and may be required to explain those actions 
to others. In CISSP® terms, the organization will expect its constituents to conform to the policy 
or rules and, if there is a failure in compliance, the governing body will have knowledge of the 
infraction(s) and take action. Each of these components requires scrutiny for a CISSP to apply 
them to its business.
Who governs actions? What are the repercussions? Th e individual is a constituent of many 
groups or sets. For example: you are a member of a family, a community, an organization, and a 
business. If you do something wrong at the family holiday celebration (yes, everyone saw what 
you did), one or more family members will call you the next day and let you have it. If you do 
something wrong as a CISSP (not again?), the (ISC)2® Ethics Review Board will be sending you 
a nasty e-mail and perhaps revoking your membership. If you do something unacceptable on the 
ﬁ le server at work, you should get an automated message explaining the policy violation, and your 
organization’s counselor will expect you to set up a meeting to discuss the situation. Th is perfect 
world of repercussions for improper actions can be achieved via a mix of technical and administra-
tive controls focused on accountability.
In the perfect world, everyone would understand the intent of the rules and follow them. With 
an approach that people are basically good, training would be the answer to setting clear expecta-
tions and preventing inappropriate interpretations of the rules. However, in an imperfect world, 
people are in a continuous state of change. In most cases, the way information is presented will 
have a bearing on how well it is received and acted upon. For example, the chief executive oﬃ  cer 
(CEO) of a health club says, “We are instituting a new system of accountability. Drug testing will 
be done every day. We will know what you are drinking, eating, and doing the night before. If you 
do anything wrong, you are ﬁ red!” What will the staﬀ  be feeling at this point?
Let us start over. Th e CEO believes they want to improve the health of the staﬀ  by showing 
them how to improve diet, exercise, and vitamin balance. What would be the feeling now? Th e 

Accountability  165
same implementation of accountability can be perceived diﬀ erently. Successful  implementation of 
accountability strategies requires a smooth delivery of expectations and an accurate technology.
Regrettably, organizations break regulations, people break laws and policies; the ones who get 
caught get punished. So when does this happen? Auditors schedule appointments with organiza-
tions to review their activity either because of a complaint or as a part of a periodic inspection. It is 
rare that a surprise or random inspection occurs without some warning. Before the auditor arrives, 
everyone scurries around turning on the controls. Th e auditor checks the policy against the con-
trols, looking for gaps. Auditors will dig until they have a ﬁ nding and then submit the report to 
the governing body. Th e governing body hands out ﬁ nes or, in most cases, warnings. After the 
auditor leaves, the controls are turned oﬀ , life goes on.
What should have happened? When the controls were turned oﬀ , the governing body and 
the responsible party at the organization should have been notiﬁ ed automatically, the summons 
should have arrived in the mail, and the controls would then be turned back on or the ﬁ ne would 
be paid. Th e next time you drive down the road and you see a police car pulling someone over, will 
you slow down? Th e next time a red light camera catches you, will you pay the ﬁ ne or go to court? 
Th e next time you see the camera, will you stop? How about following the law all the time?
Th at is what accountability is all about; it is a business and technical process that changes 
everyone’s behavior to follow policy at all times.
For example, suppose you do something unacceptable. You would then get an e-mail from the 
system and a copy would go to your boss. You would be required to show up at his or her desk ready 
to explain. As a responsible member of the organization and a mature adult, you would not make 
excuses: you would apologize and not do it again. It would not be a fun part of the day. If employees 
know that inappropriate actions have repercussions, they learn quickly not to do those actions.
We need an accountability system that addresses the world we live in. We need a business pro-
cess and a technical tool set that report all inappropriate activity so that self-corrective measures 
are applied.
Requirements Overview
Accountability requires a balance between the implementation and the business process. Relying on 
either one too much will reduce the accountability. If we have a poorly automated way to deliver the 
data, the business process cannot apply the rules and remediation equally. Once we have inequitable 
application of policy, it will lead to decision reversals either by human resources or, worse yet, by a 
court of law. We have all heard stories of courts ordering organizations to reinstate employees.
Administratively there must be clear, accurate policy and a remedy for noncompliance. 
 Technically there must be well-deﬁ ned, accurate permission systems, consolidated logging, and 
timely e-mail communications for all parties involved.
Business Process Details
Before we address the technical processes we need to get the business processes in place. We must 
deﬁ ne the actions, and then we can deﬁ ne the inappropriate actions. We must choose a  governing 
body from the population for escalation and remediation. We must deﬁ ne the repercussions.
A well-deﬁ ned business has its functions and ﬂ ows documented. Th is data is currently in most 
organizations. It could be in the risk management documents, the business impact assessment, the 
business plan, or the management framework.

166  Information Security Management Handbook 
Th e data we need for deﬁ ning the actions includes all of the job descriptions, roles, and respon-
sibilities in the organization. Th is cannot be done in the vacuum of a single department. If we 
examine the roles and an overlap occurs we need to ﬁ nd out why and make adjustments, if pos-
sible. Each position or role will have a deﬁ ned set of resources that is not appropriate for others 
to access. Further, in a mature deﬁ nition the access to resources would be as granular as possible. 
Our goal is to answer the questions, what are the least privileges, what are the groups, and what 
are the resources? In a large organization this data may be in ﬁ le systems, directories, or identity 
management systems.
If the data is present, it most likely needs consolidation. Th e maximum number of groups 
should be less than 25 for an organization or a large, segregated department. Th e maximum 
number of resources should be 25. Th e reason for these numbers is that the possible number of 
permutations of groups and resources could be so high that administrators could not diagram 
or conceptualize it. It is possible to exceed these maximums, but in most cases consolidation is 
called for. Th e diﬃ  culty with this step is as follows: administrative overhead changes over the life 
of a business, a position, and a set of resources. Th e output of this step will be used to deﬁ ne your 
functional policies.
Consent to monitoring, acceptable use of resources, remediation, self-governance, and escala-
tion are the functional policies that must be deﬁ ned for use in the technical implementation of 
accountability. As always, policy must be communicated to staﬀ  before, during, and after employ-
ment. Consent to monitoring must detail the level of activity tracking and give clear examples. 
Acceptable use of resources must include a statement that speciﬁ cally points to not using named 
ﬁ les or databases that are not part of the scope of that role or group; further, personnel must be 
warned to protect the user account as an asset of the organization. Acceptable use must reference 
the other three policies listed. Th e remediation policy must explain the  following: steps to be taken 
in the event the acceptable use policy is broken, who will be contacted if a violation occurs, excep-
tions, typical punishments, and the number of violations before escalation occurs. Self-governance 
policy (also called ethics handbook), if present, should explain acceptable and unacceptable behav-
ior as it pertains to accountability. Th e escalation policy must name or address parties such as union 
representation, legal counsel, employee review boards, and human resources.
Employee review boards are a group of peers who listen to exceptions and make recommen-
dations to the violator. Th is group should be a mix of all departments, with a variety of tenure, 
and should change frequently. It may have more impact than management. Depending on the 
culture of the organization, review boards may even make recommendations for termination or 
punishment. Just the thought of disappointing peers in certain organizations will be a deterrent 
to further inappropriate actions.
Technical Process Details
All businesses can implement accountability; however, the technical house must be in order. 
Th e minimum requirements are unique identity; properly named resources and groups; accurate 
permissions; accurate, continuous, concise, logging; automated reporting of relevant logging; and 
good maintenance of all of the above.
Identity management strategies include consolidation or synchronization of authentication 
databases, grouping of functional or departmental staﬀ , and grouping of resources. A more 
 organized group management strategy of tying groups of owners to their named resources using 
a clear naming convention will increase the clarity of accountability. If the resource is clearly 

Accountability  167
marked or named and organized for the users’ department or function, the users will be more 
likely to access the correct resources. Conversely, it will be clear to the users that the inappropriate 
action is not a part of their security domain. Th e example in the implementation section of this 
chapter will make this easier to understand.
In most enterprise permissions systems, administrators either are confused about the eﬀ ective 
permissions or use a “most privilege” strategy, rather than least privilege. Resource users should 
be in as few conﬂ icting permissions groups as possible. Permissions should be applied as close to 
the resource as possible, and grouping should be abstracted on the local resource.
Th e “antigroup” consists of a group of all personnel that should not have access to a speciﬁ c 
resource, that is, the antipermission group. Antigroup is a term that the author has created because 
the concept is paramount to successful accountability. Th e antigroup should speciﬁ cally be denied 
access to the resource by technical means. If this occurs and overall group management is accurate 
and automated, it will be easier to implement accountability.
Accurate logging is the last key piece of the accountability puzzle. Traditionally, logging levels 
have been either too high or too low. Trapping all events causes poor performance, storage issues, 
and log consolidation errors. Trapping too few log entries misses key events. Logging all types 
of access (success and failure) by the antigroup communicates all that is needed for accountabil-
ity. Successful access by the antigroup indicates failed permissions settings and requires immedi-
ate action by administrators. Failed access by the antigroup indicates accountability issues to be 
reported as directed by the policies. If group consolidation is coupled with antigroup strategies, 
logging can be nearly perfect.
Indirectly related to accountability is the act of tuning the logging system itself. Changes to 
logging facilities indicate a policy change. Technical or administrative policy change should be 
carefully reviewed before implemented; accountability’s assurance depends on it.
Automated reporting of accountability infractions is the ﬁ nal step in the set of technical pro-
cesses. To limit collusion, reduce tension between employees, and provide immediate feedback 
to transgressors, all reporting and escalation must not have human intervention until after the 
oﬀ ender has had a chance to review his or her own actions.
Adjustments to the technical and business processes surrounding accountability are essential 
to business. As infractions are recorded, the metadata will indicate gaps between what is reason-
able to achieve business goals and what is written in the policy. Accountability strategies will take 
at least three iterations to become stable and reliable.
Technical Process Implementation
Th e second part of this chapter is a description of an implementation of accountability. We will 
use the technical implementation norms for organizations of the most prevalent operating system 
and typical setup to build an accountability implementation. Microsoft’s Active Directory for 
version 2000 or better with Global Groups enabled has the widest audience. With some adjust-
ments, this system could work for other operating systems and atypical designs.
Assumptions for this implementation of accountability are as follows: a Windows domain 
structure under a single forest, universal groups, permissions applied to groups only, a universal 
naming convention for both groups and shared resources, permissions set on every accessible 
resource, event logging for security and system events, and Logcaster (a log consolidation tool).
Large Windows domain structures prior to Windows 2000 were typically set up as resource 
domains trusting accounts domains to overcome limitations in the sizes of databases. Th is is no longer 

168  Information Security Management Handbook 
necessary, but the concept and a diagram will help to illustrate a domain that is complex enough to be 
applied to most enterprises (see Exhibit 12.1). In this domain structure, the user account is located in 
the a.com domain, and the ﬁ le server is located in a separate domain, r.com. Both domains are located 
in a single forest so that database replication may occur.
Universal groups are found only in a forest where the functional level has been raised to a mini-
mum of Windows 2000 native mode for all domains in the forest. Th is cannot be undone unless you 
restore all domain controllers from backup. (A strong warning: if you raise the functional level and 
if you have any NT 4.0 domains, you will lose replication capability.) Raising the functional level 
can be accomplished in the microsoft management console (MMC) for Active Directory Domains 
and Trust by right-clicking each of the domain objects and choosing from the context menu.
From Windows 2003 server Help ﬁ le: Th e concept of enabling additional functional-
ity in Active Directory exists in Windows 2000 with mixed and native modes. Mixed-
mode domains can contain Windows NT 4.0 backup domain controllers and cannot 
use Universal security groups, group nesting, and security ID (SID) history capabili-
ties. When the domain is set to native mode, Universal security groups, group nest-
ing, and SID history capabilities are available. Domain controllers running Windows 
2000 Server are not aware of domain and forest functionality.
It is possible to achieve accountability in separate forests by using a centralized logging facility, but 
the level of complexity increases.
Permissions need to be set on resources at the group level in a nested fashion to reduce permis-
sions conﬂ icts and confusion. An informal polling of hundreds of systems administrators over 
seven years indicates three things: Th ere is an overwhelming attitude of confusion on how to set 
permissions correctly, what the eﬀ ective cumulative permissions are on a share, and how to clean 
up the permissions creep that occurs over the life of an account.
Permissions administrators should use a practical approach to permissions systems. Th e prac-
tical approach from Discretionary Access Control Knowledge, a Practical System oﬀ ers a new solu-
tion for administrators to reduce abuse of access controls and simplify permissions management. 
Forest root
Accounts domain
a.com 
domain controller
Resource domain
r.com
domain controller
User account 
File server resource
Exhibit 12.1 Example forest and domain structure.

Accountability  169
“If the concepts of ‘THE SNAIL’ and the best practices are followed, administrators will be able 
to reduce the confusion of calculating the eﬀ ective cumulative permissions. Using THE GRID 
and THE FIVE RULES allow administrators to quickly identify and reduce vulnerabilities….”*
Th is paper also details naming conventions for groups. When inappropriate actions are logged, 
there needs to be a clear understanding of who did what and when. By implementing standard 
naming of groups, we know the “who.” By implementing standard naming of resources, we know 
the “what.” If we have time synchronization with external timeservers, we know the “when.”
Th e organization of groups should follow “Th e Snail” concept of placing users only in global 
groups, placing global groups in universal groups, and placing universal groups in domain local 
groups (see Exhibit 12.2). Th is organization of groups allows for slow migration to a mature 
accountability posture. Th e naming conventions should support a clear path from the user account 
to the resource and its permissions. Th e following is an example naming convention:
Domain local groups
LgDepartmentFoldernamePermission
If there is a deny permission, precede it with “x”
Universal groups
UgDepartmentFoldernamePermission
If there is a deny permission, precede it with “x”
Global groups
GgDepartment
Th e antigroup concept that is critical for accountability implementations to work is employed by 
assigning all global groups who do not have permission to the resource to the xUg group. Th is may 
have a high administrative cost if scripts are not employed.
* http://www.sans.org/reading_room/whitepapers/windows/1165.php.
Global group 
Domain local group
Users
Universal group
Exhibit 12.2 Nesting groups.

170  Information Security Management Handbook 
Th is naming convention will allow for fast identiﬁ cation of administrative error and the ability 
to track down accountability issues. Naming and organizing groups will support accountability if 
owners are assigned in Active Directory under the “Managed By” tab of the group.
Naming conventions and group responsibilities will help with separation of duties. Server 
operators who are responsible for ﬁ le and print servers can limit their activities to creating shares, 
setting permissions for domain local groups, and setting auditing for the same groups. Domain 
administrators for resource domains can limit their activities to creating domain local groups and 
assigning domain local groups to universal groups. Domain administrators for accounts domains 
can limit their activities to creating and assigning users to global groups and creating and assign-
ing global groups to universal groups. It is possible in a very mature accountability structure to 
identify inappropriate group creation.
Permissions can be set at three levels within the Windows operating system: share, NTFS 
(NT File System) folder, and NTFS ﬁ le. To reduce confusion, set share permissions to full con-
trol for everyone. Many administrators get upset with this suggestion. Share permissions, if left 
to stand alone, are never a good access control strategy. Th ey must be supported by NTFS folder 
permissions that maintain least privilege. Th ere should not be any need for NTFS ﬁ le permissions. 
Administratively, this should be the only permissions; this can be achieved only by changing the 
advanced settings to remove inheritance of permissions. Th is is accomplished by removing the 
check in the “Allow inheritable permissions from parent” box.
At this point, the administrator’s group still maintains full control. Th is group contains the local 
administrator account of the ﬁ ler and by default contains the domain administrators of the local 
domain as one of its members. If administrators cannot adjust permissions, they cannot do their 
job. Th is permission should be left alone so we can see when the administrator makes changes.
When building or adjusting group membership, an organization might want to put all groups 
in a single active directory container to prevent domain policy inheritance from changing conﬁ gu-
ration rights. Th is strategy also increases the speed of searching the directory.
By executing the administrative tasks mentioned, the users are in the correct groups, nesting 
of group types for the organization has been achieved, eﬀ ective permissions can be set, antigroups 
are in place, and it is possible to achieve accountability via event logging. Th e result should look 
like Exhibit 12.3. Th ere should be two to four permissions set on the resource: local administrator 
with full control, antigroup with deny full control, and the one or two departments with their 
least privileges set.
Event logging is the core tracking mechanism for accountability. It should be conﬁ gured at the 
domain policy level and not at the local policy level. For ﬁ lers, audit should be set to success and 
failure for object access and success and failure for policy change. If additional auditing is turned 
on, extra events that do not pertain to accountability will be recorded.
Once auditing is turned on at the server and conﬁ gured at the domain level, the objects or 
resources can be successfully tracked. Th e audit tab on the advanced security settings for the 
resource should audit for the two groups who do not need access on a regular basis: the adminis-
trators and the antigroup. Keep in mind, the antigroup is everyone who does not have permission. 
Th e antigroup was deﬁ ned by the accounts domain administrator at the universal group level by 
adding the global groups who do not need access to the resources of the department. If the per-
missions administrator failed to set the deny all permission and did set the audit for both success 
and failure, the inappropriate access would still be logged. Th is is possible only for the antigroup 
and not the built-in “everyone group.” Th e “everyone group” includes everyone who has access 
to the network, which includes the people with permissions. If everyone is audited, both inap-
propriate access and correct access will be logged. Th e goal is to log only inappropriate access. 

Accountability  171
Th e administrator must see both success and failure audit events at accessing resources by the 
antigroup.  Success audit events indicate incorrectly set permissions. Failure audit events indicate 
inappropriate attempts. By using the antigroup as the group for logging events, the ﬁ rst part of 
accountability has been achieved.
Activity of both end-user violation and administrative maintenance must be collected, stored, 
and used. Th e use of the data for our initial purpose is accountability. Policy will need to be 
adjusted to ﬁ t the real working conditions, because the accountability data will indicate gaps. 
Because only inappropriate activity is being collected, collection and storage of logging data will 
be reduced to a manageable level for review. Using an event log aggregation tool such as Logcaster 
by Rippletech will allow us to trap critical events as they occur, rather than at the point of oﬄ  ine 
storage. Critical events such as accountability violations, policy changes, audit changes, and per-
missions changes should be submitted for immediate review by department managers, account-
ability committees, and the end user. Immediate review ties actions to consequences. Automated 
output allows for immediate review without judgment calls by security teams or administrators. 
Critical events can be done via e-mail.
Caution should be used when ﬁ rst implementing e-mail notiﬁ cation due to a potential denial 
of service. Summarization is the best strategy for automation until false-positives are reduced to 
a manageable level. Any noncritical events such as administrator access should be collected, sum-
marized, and reviewed in a reasonable time period.
Exhibit 12.3 Complete diagram of accountability implementation.
Forest 
Account domain 
UgDeptAFolderFc
xUgDeptAFolder
Resource domain 
LgDeptAFolderFc
xLgDeptAFolder
Filer in resource domain with folder 
SharePerm = FC everyone
NTFS      =  FC LgDeptAFolderFc
           =  Deny FC xLgDeptAFolder
Audit      =  Succ & Fail 
xLgDeptAFolder
           =  Succ & Fail Admin 
GgDeptA 
User
GgDeptB 
GgDeptC 
GgDeptD

172  Information Security Management Handbook 
Threats
Accountability has many administrative threats. Th ey include prerequisite failures,  implementation 
failures, maintenance failures, and mislabeling. Th e prerequisites of unique identiﬁ cation and 
identity management are diﬃ  cult to achieve and maintain. To hold people accountable, admin-
istrators need to be sure the account is used by one and only one person. It would be bad form to 
punish someone for another’s actions. Shared accounts of administrators will be most troublesome 
if the intention is to apply accountability to technical administrative functions.
Initial implementation failures can include a high number of false-positives if the accountabil-
ity systems are not installed in stages.
To address maintenance failures, keep in mind that permissions change. It is tempting to 
leave the past set of permissions in place and add new permissions. Th is violation of least privilege 
should be addressed by conducting regular reviews. Additional maintenance failures can be caused 
by staﬀ  changes on the administrative side, uncontrolled growth of staﬀ , and lack of automation.
Organizations are likely to mislabel accountability as audit. But audit is a periodic third-party 
evaluation of gaps between policy and implementation. Accountability is immediate gap notiﬁ ca-
tion and correction by the parties involved.
Th ere are a few technical threats, including logging costs, lack of education, and requirement 
of centralization. Th e act of logging has a dollar value. Some organizations already have logging 
in place; those that do not have will be starting from scratch and, therefore, spending more. Lack 
of education on permissions and logging consolidation cause a great deal of unnecessary overhead 
on accountability systems. Centralization of logging, authentication, and policy are required for 
most organizations to achieve accountability.
Who Needs to Be Involved?
Th e easy answer is everyone needs to be involved. Policy makers, technologists, employees, and 
auditors all need to be a part of the accountability program. Enforcement by policy makers needs 
to be deﬁ ned and implemented by the technologists in a hands-oﬀ  manner. Policy makers should 
make the rules and deﬁ ne the repercussions so that the employees take it upon themselves to 
self-correct. If the rules are not followed in a reasonable amount of time, human resources or 
an employee council should step in. Auditors should take the metadata from the accountability 
system and adjust policy or work habits. If everyone gets involved, accountability will change the 
culture of the organization for the better.
Summary
Security is not “set it and forget it”; accountability keeps this uppermost in our minds. Account-
ability achieves awareness by verifying every action deﬁ ned in the policy. When everyone is aware, 
our risks to our resources decrease. Assurance is increased by an order of magnitude when security 
is moved from the responsibility of a few to that of the entire organization.
Do not try to go after every inappropriate action at once. Start with simple, easy-to-be-right 
actions. For example, only the accounting department should be in the payroll ﬁ les. Work your 
way up to the more diﬃ  cult decisions. Accountability is possible.

Methods of Attack


175
Chapter 13
Rootkits: The Ultimate 
Malware Threat
E. Eugene Schultz and Edward Ray
Contents
Introduction .............................................................................................................................176
About Rootkits ........................................................................................................................177
Deﬁ nition of Rootkit ......................................................................................................177
Characteristics of Rootkits ..............................................................................................177
How Rootkits Work........................................................................................................177
Hiding Mechanisms ..............................................................................................177
Backdoor Mechanisms ...........................................................................................178
Types of Rootkits ............................................................................................................178
User-Mode Rootkits ..............................................................................................178
Kernel-Mode Rootkits ...........................................................................................179
How Rootkits and Other Types of Malware Diﬀ er .........................................................179
How Rootkits Are Installed ............................................................................................180
Rootkits and Security-Related Risk .........................................................................................181
Escalation of Security Breach-Related Costs ...................................................................181
Increased Likelihood of Backdoor Access........................................................................181
Rootkits Often Run in Connection with Botnets ...........................................................181
Rootkits Often Include Keystroke and Terminal Loggers ...............................................182
Rootkit Prevention ...................................................................................................................182
Prophylactic Measures ....................................................................................................182
Patch Management .........................................................................................................182

176   Information Security Management Handbook
Conﬁ guring Systems Appropriately and Limiting Services
Th at Run on Systems ......................................................................................................183
Adhering to the Least Privilege Principle ........................................................................183
Deploying Firewalls ........................................................................................................183
Using Strong Authentication ..........................................................................................184
Performing Security Maintenance on Systems ................................................................184
Limiting the Availability of Compilers ............................................................................185
Incident Response Considerations ............................................................................................185
Detection ........................................................................................................................185
Change Detection ..................................................................................................185
Running Tools Designed to Detect Rootkits .........................................................186
Analyzing Output of Network Monitoring Tools ..................................................187
Eradication .....................................................................................................................187
Recovery .........................................................................................................................188
Conclusion ...............................................................................................................................188
References ................................................................................................................................188
Introduction
Of all the things that occur in the information security arena, few are more interesting (and also 
more troublesome) than malicious code (“malware”) incidents. Over the years we have seen mal-
ware evolve from simple viruses written in assembly language to complex programs that deliver 
advanced functionality that greatly facilitates the ability of perpetrators to accomplish their sordid 
purposes. In this chapter we have termed rootkits “the ultimate malware threat,” something that 
is no embellishment whatsoever. When it comes to sophistication and potential for damage, loss, 
and destruction, few, if any, types of malware can compare to rootkits. With the constant news 
about viruses, worms, and Trojan horse programs, however, rootkits have somehow gotten “lost 
in the fog.” Th is chapter is intended to serve as a wake-up call—it is time for information security 
professionals to become aware of exactly what rootkits are, what they can do, what risks they pose, 
and possible solutions for countering them.
Information security professionals are constantly concerned about a wide variety of security-
related threats. Some of these threats pose considerably higher levels of risk than others and thus 
require more resources to counter. Furthermore, risks and their potential impact change over 
time. In the 1990s, for example, risks resulting from the activity of external attackers were some of 
the most serious. Attackers often launched brute-force password-guessing attacks or, if they were 
more sophisticated, password-cracking attacks using dictionary-based password-cracking tools 
that are by today’s standards rather crude. During that time, damage and disruption due to virus 
and worm infections also comprised one of the most serious types of security risks. Th ings have 
changed considerably since then; certain types of malware other than viruses and worms have 
moved to the forefront of risks that organizations currently face. Rootkits in particular now repre-
sent what might safely be called the ultimate malware threat. Th is chapter covers the ins and outs 
of rootkits, the relationship between rootkits and security-related risk, how to prevent rootkits 
from being installed in the ﬁ rst place, and how to detect them and recover when rootkits have 
been installed in victim systems.

Rootkits: The Ultimate Malware Threat  177
About Rootkits
What exactly is a rootkit? Th e following section deﬁ nes what rootkits are, describes their charac-
teristics, explains how rootkits and Trojan horse programs diﬀ er, and describes how rootkits work.
Deﬁ nition of Rootkit
Th e term “rootkit” refers to a type of Trojan horse program that if installed on a victim system 
changes its operating system software such that: (1) evidence of the attackers’ activities (including 
any changes to the system that have been made in installing the rootkit) is hidden and (2) the 
attackers can gain remote backdoor access to the system at will. Rootkits replace normal programs 
and system libraries that are part of the operating system on victim machines with versions that 
superﬁ cially appear to be normal, but that in reality subvert the security of the machine and cause 
malicious functions to be executed.
Characteristics of Rootkits
Rootkits almost without exception run with superuser privileges, the full set of system privileges 
intended only for system administrators and system programmers, so that they can readily perform 
virtually any task at will. In UNIX and Linux, this translates to root-level privileges; in Windows, 
this means Administrator- and SYSTEM-level privileges. Without superuser privileges, rootkits 
would not be very eﬀ ective in accomplishing the malicious functions they support. It is important 
to realize, however, that attackers need to gain superuser-level access before installing and run-
ning rootkits. Rootkits are not exploit tools that raise the privilege level of those who install them. 
Attackers must thus ﬁ rst exploit one or more vulnerabilities independent of the functionality of 
any rootkit to gain superuser privileges on victim systems if they are going be able to install and 
run a rootkit on these systems.
Additionally, the majority of rootkits are “persistent,” whereas others are not. Persistent root-
kits stay installed regardless of how many times the systems on which they are installed are booted. 
Nonpersistent rootkits (also called “memory-resident” rootkits) reside only in memory; no ﬁ le in 
the compromised system contains their code. Th ey thus remain on a victim system only until the 
next time the system boots, at which time they are deleted.
How Rootkits Work
Rootkits work using two basic types of mechanisms, those that enable them to avoid detection and 
those that set up backdoors, as explained in this section.
Hiding Mechanisms
Attackers know that discovery of their unauthorized activity on a victim system almost invari-
ably leads to investigations that result in the system being patched or rebuilt, thereby eﬀ ectively 
forcing them to “start from scratch” in their eﬀ orts to gain unauthorized access to and control a 
target system or, in a worst case scenario for attackers, giving investigators clues that can be used in 
 identifying and ultimately convicting the attackers of wrongdoing. It is to the attackers’ advantage , 

178   Information Security Management Handbook
therefore, to hide all indications of their presence on victim systems. Most rootkits incorporate 
one or more hiding mechanisms—as a rule, the more sophisticated the rootkit, the more of these 
mechanisms are part of the rootkit and the more proﬁ cient these mechanisms are.
Th e most basic type of hiding mechanism is one in which log data pertaining to an attacker’s 
log-ins and log-outs on the victim system are erased so that when system administrators inspect 
the system’s audit logs, they do not see any entries that report the attacker’s having logged in or 
out or having done anything else on the system. Additionally, many rootkits delete any evidence 
of processes generated by the attacker and the rootkit itself. When system administrators enter 
commands or use system utilities that display the processes that are running, the names of pro-
cesses started in connection with all facets of the attack (including the presence of a rootkit) are 
omitted from the output. Rootkits may also hide ﬁ les and directories that the attacker has created 
in a number of ways, including changing commands used to list directory contents to have them 
exclude ﬁ les that the attacker has created or (as explained in more detail shortly) making changes 
to the kernel of the operating system itself to cause it to provide false information about the pres-
ence and function of certain ﬁ les and executables. To allow backdoor access by attackers, rootkits 
almost always open one or more network ports on the victim system. To preclude the possibility of 
discovering rootkits when system administrators examine open (“listening”) ports, many rootkits 
thus also hide information about certain ports’ status. Additionally, some rootkits change what 
happens when certain executables are invoked by legitimate users (e.g., system administrators) 
such that malicious executables that superﬁ cially appear to work like the original executables 
are run instead. Finally, some rootkits (e.g., those with keystroke logging capability) capture or 
change information sent to or from hardware devices that interface with victim systems.
Backdoor Mechanisms
Rootkits almost without exception also provide attackers with remote backdoor access to com-
promised systems. One of the most common ways of providing this kind of access is creating 
encrypted connections such as secure shell (SSH) connections that not only give attackers remote 
control over compromised systems, but also encrypt information to prevent it from being avail-
able for analysis by network-based intrusion detection systems (IDSs) and intrusion prevention 
systems (IPSs) as well as network monitoring tools. Additionally, SSH implementations used in 
connection with rootkits require entering a username and password, thereby also helping prevent 
individuals other than the individual or individuals who installed the rootkit from being able to 
use the backdoor.
Types of Rootkits
Two fundamental types of rootkits, user-mode rootkits and kernel-mode rootkits, exist. Th e dif-
ference is based on the levels at which they operate and the type of software they change or replace. 
Th is section describes both types and explains how each works.
User-Mode Rootkits
User-mode rootkits replace executables and system libraries that system administrators and users 
use. Th e SSH program and the C library in UNIX and Linux systems are two of the most common 
targets. Windows Explorer (the default shell in Windows systems) is often targeted by user-mode 

Rootkits: The Ultimate Malware Threat  179
rootkits. Authors of user-mode rootkits take great care to hide the fact that targeted executables 
and system libraries have been changed. For example, if a rootkit has replaced the SSH program, 
both the last date of modiﬁ cation and the ﬁ le length will be what they were when the SSH was 
originally installed when system administrators enter commands to query for this information. 
Additionally, most rootkits target only a few executables and system libraries (often only one); the 
fewer executables and system libraries targeted, the less likely system administrators and users are 
to notice that something is wrong.
Kernel-Mode Rootkits
As their name implies, kernel-mode rootkits change components within the kernel of the operat-
ing system on the victim machine or sometimes even completely replace the kernel. Th e kernel is 
the heart of an operating system; it provides fundamental services (e.g., input and output control) 
for every part of the operating system.
Kernel-mode rootkits hide the presence of attackers better than do user-mode rootkits. System 
administrators and system programmers trust kernel-level processes implicitly, but anything that 
has control of the kernel can cause kernel processes to produce bogus information about their 
status. System administrators and system programmers are not likely to have any reason to believe 
that this information is specious. Additionally, detecting changes in the kernel is generally very 
diﬃ  cult, especially if kernel-mode rootkits have been developed by individuals with extremely high 
levels of technical expertise. Kernel-mode rootkits are thus even deadlier than user-mode rootkits.
Kernel-mode rootkits invariably change process listings to exclude processes that run in con-
nection with the rootkits. Th e kernel is aware of all processes that are running, but when system 
administrators enter a command to list all processes, certain ones (the ones that the rootkit author 
wants to hide) are omitted when the kernel processes provide information to the command. Addi-
tionally, kernel-mode rootkits often redirect the execution of programs such that when system 
administrators and users invoke a certain program, a completely diﬀ erent program is run, some-
thing that is called “redirection.” Redirection is an especially eﬀ ective hiding technique because 
the original program remains intact; no changes in this program can thus be discovered.
How Rootkits and Other Types of Malware Differ
As stated in the deﬁ nition at the start of this chapter, a rootkit is a type of Trojan horse program. 
Th e term “Trojan horse program” actually refers to a wide range of hidden malicious programs; 
rootkits are thus one kind of Trojan program. Rootkits, however, go further than conventional 
Trojans in that the latter are designed to go unnoticed, but do not incorporate active mechanisms 
that prevent them from being noticed. In general, the primary method of hiding Trojan horse 
programs is assigning an innocuous name (e.g., “dataﬁ le” or “misc”) to them. In contrast, rootkits 
have mechanisms that actively hide their presence from antivirus and antispyware programs, sys-
tem management utilities, and system and network administrators. Additionally, Trojan programs 
are generally created within systems that have been compromised, that is, they do not replace 
existing programs and ﬁ les, but are instead new programs that are installed. As mentioned previ-
ously, in contrast, rootkits actually replace operating system programs and system libraries.
It is also important to understand that rootkits are not tools that exploit vulnerabilities. Root-
kit installation instead requires that one or more vulnerabilities ﬁ rst be exploited. Additionally, 
rootkits are not viruses or worms, both of which are self-reproducing programs. If rootkits were 

180   Information Security Management Handbook
self-reproducing, detecting and deleting them would be considerably easier; rootkit authors thus 
avoid incorporating self-reproducing functionality in the code they write. At the same time, how-
ever, it is important for information security professionals to realize that in some instances viruses 
or worms have installed rootkits in systems that they have infected.
How Rootkits Are Installed
One of the most common ways that rootkits are installed includes having someone download 
what appears to be a patch or legitimate freeware or shareware program, but which is in reality a 
rootkit. Software is sometimes modiﬁ ed at the source; programmers can insert malicious lines of 
code into programs that they write. A recent example of this is the Sony BMG Music Entertain-
ment copy-protection scheme, which came with music compact disks (CDs) that secretly installed 
a rootkit on computers (see the following vignette). Additionally, malicious Web servers often 
install rootkits into systems by exploiting vulnerabilities in browsers such as Internet Explorer 
and Mozilla Firefox that allow malicious Web pages to download ﬁ les of a perpetrator’s choice or 
possibly by giving processes on the malicious Web server superuser privileges on the systems that 
run these browsers.
A relatively new attack vector for installing rootkits is spyware. A recent example of this is a vari-
ant of the VX2.Look2Me Spyware Trojan released in November 2005 (see http://www.f-secure.
com/sw-desc/look2me.shtml). Rootkits enable spyware authors to hide conﬁ guration settings and 
program ﬁ les, enabling the rootkits themselves to be installed in alternate data streams—features 
associated with ﬁ les and directories in the Windows NT File System that provide compatibil-
ity with the Macintosh File System—to disguise their presence. Spyware and rootkit combina-
tions are typically installed on victim computers via malicious Web pages or e-mail messages that 
exploit Web browser vulnerabilities or use “social engineering” tricks to get users to install the 
code unknowingly.
A ﬁ nal rootkit vector discussed here is viruses and worms. Although most viruses and worms 
usually do not install rootkits, a few of them do.
Vendor-Installed Rootkits: More Reason to Worry
The information security community in general and security ven-
dors in particular have been slow to react to rootkit-related risks. 
More recently, however, a few vendors have installed monitoring 
software that uses stealthy, rootkit-style techniques to hide itself. 
Long before Mark Russinovich blew the whistle on Sony BMG’s use 
of such software to cloak its digital rights management scheme, 
spyware researchers had seen traces of Sony BMG’s controversial 
technology on personal computers without knowing what it was. 
As Russinovich explained, the detection of the Sony BMG rootkit 
was not a straightforward task. New techniques and products are 
emerging to make it easier for technical staff to identify rootkits on 
compromised machines, but identifying such machines in the ﬁ rst 
place and then removing the malicious software remain frustratingly 

Rootkits: The Ultimate Malware Threat  181
difﬁ cult. Everyone expects the perpetrator community to write and 
deploy rootkits—according to McAfee, the use of stealth techniques 
in malware has increased by over 600 percent since 2004. At the 
same time, who would expect vendors to write and install rootkits in 
their products? Vendors such as Sony BMG have thus added another 
layer of complexity to the already too complex rootkit problem.
Rootkits and Security-Related Risk
Rootkits considerably raise the level of security-related risk that organizations face, namely by 
increasing the cost of incidents, increasing the probability of backdoor access, putting organiza-
tions’ machines at risk of becoming part of a botnet, and exposing organizations to the risk of 
conﬁ dentiality infractions because of unauthorized capture of information, as explained in the 
following sections.
Escalation of Security Breach-Related Costs
Although rootkits do not break into systems per se, once they are installed on systems they are 
(unless they are poorly designed or written) usually extremely diﬃ  cult to identify. Th ey can reside 
on compromised systems for months without anyone, the most experienced system administrators 
included, suspecting that anything is wrong. Th e cost of security breaches is proportionate to their 
duration; anything that increases duration escalates incident-related costs.
Increased Likelihood of Backdoor Access
Because rootkits usually include backdoors, they substantially raise the probability that even if 
eﬀ ective security measures are in place, attackers will gain unauthorized remote access to systems. 
Because rootkits are so diﬃ  cult to discover, whoever gains such access can rummage through the 
contents of ﬁ les within the compromised system to glean sensitive and other information. Th e fact 
that access of this nature is normally with superuser-level privileges means not only that attackers 
can remotely access systems any time they wish, but also that they have complete control to do 
anything they want with each system that they access in this manner.
Rootkits Often Run in Connection with Botnets
A bot is a malicious executable that is under the control of a master program used by an attacker 
to achieve a variety of malicious goals. A botnet comprises multiple bots that respond to a central 
source of control. Botnets may be used for numerous sordid purposes; one of the worst is dis-
tributed denial-of-service attacks. Some rootkits function as bots within massive botnets that, if 
not detected, can produce deleterious outcomes. If bots are discovered early enough, they can be 
eradicated without providing suﬃ  cient time to accomplish their goals, but rootkits are normally 
extremely hard to ﬁ nd, reducing the probability of discovering and deleting bots before they can 
do their sordid deeds.

182   Information Security Management Handbook
Rootkits Often Include Keystroke and Terminal Loggers
Another area of risk that rootkits can introduce is having sensitive information such as credit card 
numbers and personal identiﬁ cation numbers used in banking transactions captured by keystroke 
and terminal loggers that are part of the rootkit. Keystroke loggers capture every character entered 
on a system, whereas terminal loggers (which pose even greater risk than do keystroke loggers) 
capture all input and output, not just keystrokes. Keystroke and terminal loggers are often used in 
connection with identity theft. Additionally, keystroke and terminal loggers are frequently used to 
steal log-on credentials, thereby enabling successful attacks on systems on which the credentials 
are used. Keystroke and terminal loggers can also glean encryption keys, thereby enabling success-
ful cryptanalysis attacks that result in the ability to decrypt encrypted information.
Rootkit Prevention
Prevention is the best cure; adopting measures that prevent rootkits from being installed is far 
better than having to detect and eradicate them after they are installed. In a way the term “rootkit 
prevention” does not make sense, however, because rootkit installation is something that occurs 
after a system is compromised at the superuser level. Th e one essential element in preventing root-
kits from being installed, therefore, is keeping systems from being compromised in the ﬁ rst place. 
Some measures that accomplish this goal include using prophylactic measures, running software 
that detects and eradicates rootkits, patch management, conﬁ guring systems appropriately, adher-
ing to the least privilege principle, using ﬁ rewalls, using strong authentication, practicing good 
security maintenance, and limiting compilers.
Prophylactic Measures
Prophylactic measures are measures that prevent rootkits from being installed, even if an attacker 
has superuser privileges. Th e challenge of creating prophylactic measures that work reliably despite 
the fact that an attacker has control of the operating system on a compromised system is great; 
it should thus come as no surprise that few such measures currently exist. Intrusion prevention 
is a promising prophylactic measure. Host-based intrusion prevention systems, IPSs that run on 
individual systems, can keep rootkits from being installed through policy ﬁ les that allow or pro-
hibit the execution of certain commands and prevent service requests from being processed if 
they potentially lead to rootkit installation as well as other undesirable outcomes. Additionally, 
operating system vendors are starting to incorporate prophylactic measures into their products. 
Microsoft, for example, has introduced a security feature called “Kernel Patch Protection,” or 
“PatchGuard,” in the 64-bit versions of its Windows operating systems. PatchGuard monitors the 
kernel and detects and stops attempts by code that is not part of the operating system to intercept 
and modify kernel code. IPSs can keep rootkits from being installed in the ﬁ rst place, provided, of 
course, that each IPS has an updated policy ﬁ le that enables the system on which it resides to deny 
certain kinds of incoming service requests that lead to rootkit installation.
Patch Management
Applying patches that close vulnerabilities is one of the most important measures in preventing 
rootkits from being installed. As mentioned previously, attackers need to exploit vulnerabilities 

Rootkits: The Ultimate Malware Threat  183
to install rootkits and run them with superuser-level privileges. If systems and network devices 
are up to date with respect to patches, attackers will be unable to exploit vulnerabilities and thus 
will not be able to install rootkits. Patch management tools that automate the patching process 
generally provide the most eﬃ  cient way to patch systems. It is also imperative that all patches come 
from known, trusted sources and that the hash value for each downloaded patch matches the value 
provided by the developer.
Conﬁ guring Systems Appropriately and Limiting 
Services That Run on Systems
To prevent attackers from installing system administrator-mode rootkits on a system, the user 
must harden each system by conﬁ guring it in accordance with security conﬁ guration guidelines. 
Vendors such as Microsoft and Sun Microsystems publish such guidelines for each version of 
operating system that they make, and sites such as the Center for Internet Security oﬀ er guide-
lines as well as automated tools to “grade” a computer to see how well it is secured based on their 
guidelines. Many types of malware take advantage of services and software running on client or 
server machines. Th ese services are sometimes turned on by default and run without the user’s 
knowledge, or are left on because of poor security policy, or are turned on later. Organizations 
should have a default conﬁ guration for their clients and servers that speciﬁ es the services and 
software that are and are not needed and ensure not only that these services are turned oﬀ  when 
they are not needed, but also that the executables for all unneeded services are uninstalled, if at all 
possible. By ensuring that machines are running only the services and software that are essential 
for job-related tasks, organizations can reduce the rootkit threat.
Adhering to the Least Privilege Principle
Assigning individuals the minimum level of privileges they need to get their jobs done helps 
reduce the likelihood that attackers will gain superuser privileges, which in turn reduces the like-
lihood that attackers will be able to install rootkits. For example, kernel-level rootkits almost 
always require drivers that run in kernel mode. In Windows operating systems, these drivers can 
be loaded and unloaded into memory using techniques similar to those necessary to create, enable, 
or terminate services. Only users with administrator or system rights (privileges) are allowed to 
install programs (including rootkits) that run in connection with drivers or that create services. If 
an attacker intent on installing a rootkit does not have at least one of these two types of privileges, 
therefore, the rootkit cannot start and hence cannot hide itself.
Deploying Firewalls
Firewalls can also provide some measure of proactive defense against rootkit installation. Root-
kits are special applications used by perpetrators. Because ﬁ rewalls are increasingly performing 
analysis of network traﬃ  c at the application layer (network layer 7) instead of at the network layer 
(network layer 3), ﬁ rewalls can improve the ability to identify and intercept malicious traﬃ  c in 
connection with rootkits. Many perimeter-based ﬁ rewalls now include application-layer signatures 
for known malware and scan traﬃ  c as it enters the perimeter from the edge, looking for suspicious 
ﬁ les downloaded by users before these ﬁ les are executed on the user’s machines. Many proxy-based 

184   Information Security Management Handbook
ﬁ rewalls (ﬁ rewalls that terminate each incoming connection and then create a new outbound 
connection with the same connection characteristics if the connection meets one or more secu-
rity criteria)  now incorporate scanning engines that increase the likelihood that content associ-
ated with rootkit traﬃ  c will be intercepted before it is downloaded and executed. At the same 
time, however, this added ﬁ rewall functionality has the potentially deleterious eﬀ ect of harming 
network performance. Information security professionals must thus balance the use of real-time 
network scanning for malicious traﬃ  c with network performance considerations.
Using Strong Authentication
Th e widespread use of static passwords in authentication constitutes a serious vulnerability, one 
that attackers and malicious code often exploit to install rootkits in systems. Strong authentica-
tion means using authentication methods that are considerably more diﬃ  cult to defeat. Examples 
of strong authentication methods include using one time passwords, authentication tokens, and 
biometric authentication. Th e strength of authentication in both clients and servers can also be 
improved by requiring authentication on commonly open services and ports. Using open standards 
such as the IPSec protocol (which deﬁ nes an authenticating header for packets sent over the net-
work to guard against spooﬁ ng and an encapsulated security payload to help ensure conﬁ dentiality 
of packet contents) also substantially decreases the likelihood of compromise. IPSec is available 
on Windows, Linux, and UNIX platforms; multiple approaches to credential management such 
as shared key, Kerberos, and public key infrastructure (PKI) can be implemented. A shared-key 
scheme is the simplest, but the most easily compromised. Kerberos, a very strong method of net-
work authentication, is more secure than the shared-key scheme, but is challenging to deploy in 
heterogeneous environments. PKI works the best in heterogeneous environments and is the most 
secure authentication method, but it also requires the most time and eﬀ ort. Th e particular IPSec 
approach that is best depends on speciﬁ c needs and business drivers within each organization.
Performing Security Maintenance on Systems
All the measures previously mentioned will do no good unless systems are kept up to date and prop-
erly maintained. A large part of system maintenance thus involves ensuring that system security 
does not erode over time. Patch management, discussed earlier in this section, is an important part 
of security maintenance, but security maintenance also requires many activities in addition to patch 
management. Organizations should, for example, have a centralized audit policy that mandates that 
system administrators regularly inspect and analyze the logs of each and every computer in their 
network.* Equally important is regularly inspecting systems to ensure that critical settings that 
aﬀ ect security have not been modiﬁ ed without authorization and also that no new unauthorized 
accounts (regardless of whether they are privileged or unprivileged) have been created. It is also a 
good practice to perform regular security audits to see which machines are most vulnerable to attack 
and compromise. Additionally, for critical systems, deploying tools such as Tripwire that regularly 
* Inspecting audit log output is essential in maintaining security, although such output is not likely to be useful 
in ﬁ nding rootkits because hiding mechanisms in rootkits almost always delete or suppress any audit log entries 
that would indicate the presence of the attacker. Inspecting the output of security event management (SEM) 
tools that collect a wide variety of output from many sources and then apply event correlation algorithms to 
identify suspicious events such as rootkit-related activities is thus much more expedient.

Rootkits: The Ultimate Malware Threat  185
check for possible unauthorized changes to ﬁ le and directory integrity is an important piece of secu-
rity maintenance. Performing vulnerability assessments, including periodic internal and external 
penetration testing, is yet another component of security maintenance. Regularly implementing all 
of these measures will substantially reduce the likelihood that rootkits will be installed.
Limiting the Availability of Compilers
Rootkits have become more complex over time. Although increased complexity has resulted in 
many advantages for attackers, it has also made installing rootkits considerably more complicated. 
Many rootkits now consist of many components that need to be compiled and installed, steps that 
if performed manually require considerable time and also thus increase the likelihood of detec-
tion. An increasing number of rootkits thus now contain easy-to-use installation scripts called 
“makeﬁ les,” instructions for compiling and installing programs. Makeﬁ les specify program mod-
ules and libraries to be linked in and also include special directives that allow certain modules to 
be compiled diﬀ erently should doing so be necessary. Makeﬁ les require that compilers be installed 
on systems; if compilers are absent from systems that have been successfully attacked, the attack-
ers must ﬁ rst install them, something that increases the time needed to install rootkits. Limiting 
compilers such that they are installed only on systems for which they are necessary for job-related 
functions is thus another eﬀ ective measure against rootkit installation.
Incident Response Considerations
Responding to security-related incidents is often complicated, but the presence of a rootkit makes 
responding to incidents even more diﬃ  cult. Incident response includes six stages: preparation, detec-
tion, containment, eradication, recovery, and follow-up [1]. Several of these stages, detection, eradica-
tion, and recovery, become particularly complex when rootkits have been installed in victim systems.
Detection
As stated previously, discovering most rootkits is diﬃ  cult because so much information about the 
attacks that led to the deletion or suppression of their installation; considerable time, eﬀ ort, and 
technical prowess are thus likely to be necessary. Th ere is one comforting thought, however—no 
attacker or rootkit, no matter how proﬁ cient, is capable of hiding all the information about an 
attack, including the presence of a rootkit that has been installed. One or more clues, no mat-
ter how small, will be available if proﬁ cient investigators and suitable analysis tools are available. 
Among the clues that are likely to be available are subtle changes in systems, the output of rootkit 
detection tools, and the output of network monitoring tools.
Change Detection
Unexplained changes in systems are excellent potential indicators of the presence of rootkits. 
Changes in the number of bytes in ﬁ les and directories from one point in time to another can, for 
example, indicate the presence of a rootkit. Almost every rootkit, however, tries to suppress any 
indication of such changes such that when a command to list directory contents is issued, the size 
of a ﬁ le that now contains the rootkit appears to be the same. Suppose that a rootkit has changed 

186   Information Security Management Handbook
the size of an executable in a UNIX system, but has also altered the ls –al command (a command 
used to list all ﬁ les within a directory, their length, their owner, and so on) so that the output of 
this command falsely shows that the contents of the ﬁ le containing the executable was unchanged. 
Th e solution for information security professionals is to obtain the output of hashing algorithms 
such as Secure Hash Algorithm version 1 (SHA1) from one point in time to another. If there is 
any change in ﬁ le contents, the computed hash will change. With a reasonably strong hashing 
algorithm, there is little chance that someone could make changes in the ﬁ le without the hash for 
the changed ﬁ le being diﬀ erent. If a rootkit somehow masqueraded SHA1 hash-value changes that 
resulted from changing an executable, the change would certainly be detected by comparing the 
before- and after-change hash values of another hashing algorithm, such as the Message Digest 
algorithm version 5 (MD5). It is virtually impossible to deceive multiple hashing algorithms by 
changing the content of a single ﬁ le, provided that the algorithms are suﬃ  ciently strong against 
cryptanalytic attacks. Using tools such as Tripwire that compute multiple hash values as well as 
several crypto checksums and other values to detect changes in ﬁ les and directories is thus one of 
the most powerful ways to detect the presence of rootkits.
It is unlikely but not impossible for experienced system administrators and system program-
mers to spot rootkit-caused changes without using special tools, of which Tripwire is only one. 
Host-based IDSs can also spot suspicious changes that could indicate the presence of rootkits, 
as can system administration tools such as Tivoli and Unicenter TNG. Th e lsof command, in 
UNIX and Linux, and fport, a Windows tool, both list open ports and the processes that have 
opened them, although as mentioned before many rootkits change such commands to suppress 
information about port activity. Forensics software may also be useful in detecting changes in 
systems. Finally, it is essential that any detection or forensics tools and outputs from such tools 
be kept oﬄ  ine (e.g., on a CD) and in a physically secure location until they are used; if left on 
a system, either could be modiﬁ ed by attackers who have compromised the system on which 
they reside.
Running Tools Designed to Detect Rootkits
Running tools that are speciﬁ cally designed to ﬁ nd and eradicate rootkits is another possible 
approach. Free tools such as chkrootkit (for Linux systems) and Rootkit Revealer (for Windows 
systems) generally use a variety of detection mechanisms to achieve their goals. Th ese tools con-
stantly need to be updated if they are to have a chance of being eﬀ ective. It is important, however, 
for information security professionals to realize that these tools are far from perfect; many rootkits’ 
hiding mechanisms are more advanced than rootkit detector and eradication tools’ capabilities.
Unfortunately, antivirus and antispyware tools are currently not up to par in detecting Trojan 
horses, let alone rootkits, for a variety of reasons. First, rootkit writers are aware that their tools 
must evade detection by antivirus and antispyware software and thus include mechanisms within 
the rootkit code that enable them to do so. Additionally, antivirus and antispyware software 
largely relies on malicious code signatures, binary or character strings that distinguish one piece of 
malicious code from the others, for detection. Much of today’s malicious code, rootkits included, 
uses a variety of signature detection evasion techniques, however. Additionally, signatures, even 
if they were to work in detecting rootkits, are invariably post hoc in nature; signatures thus can-
not be used to recognize malicious code that is used in zero-day exploits. At the same time, 
however, a growing number of antivirus software vendors are incorporating the ability to scan 
kernel or user-mode memory for known rootkits. Th e bottom line is that currently, information  
security professionals should not rely on antivirus and antispyware software to detect rootkits. 

Rootkits: The Ultimate Malware Threat  187
If tools designed speciﬁ cally for rootkit detection are not all that proﬁ cient in detecting rootkits 
(as mentioned previously), it should be little surprise to realize that antivirus and antispyware 
software does even worse.
Analyzing Output of Network Monitoring Tools
Monitoring network activity is an eﬀ ective method for detecting rootkits. Finding connections 
that make little sense, for example, connections between a billing server of a large corporation and 
a machine with a domain name that ostensibly belongs to a university, can lead system and net-
work administrators to investigate what has happened to the billing server. If an investigation of 
a system that has had suspicious connections leads to the discovery that information about other 
connections, but not the suspicious ones, is available in audit log data, the presence of a rootkit 
would be a very possible explanation. Activity on certain ports is another possible rootkit indica-
tor. Although evidence of such activity is likely to be hidden on any machine on which a rootkit 
has been installed, network-based IDSs, IPSs, SEM tools, and ﬁ rewalls will nevertheless detect 
port-related activity that may indicate the presence of a rootkit on such a machine. Both network- 
and host-based IDSs and IPSs can provide information about attempts to install rootkits as well 
as the presence of rootkits on systems. Aggregating the output of IDSs, IPSs, ﬁ rewalls, routers, 
individual systems, and other sources of log data and then correlating it using event correlation 
software also increases the probability of detecting rootkits on systems. Eﬀ ective rootkits do not 
leave obvious indicators of their existence, so correlated clues (no matter how obscure) about the 
existence of rootkits from multiple sources are in fact often the best way to discover them.
Eradication
Eradication involves eliminating the cause of any incident. If a rootkit is discovered on a system, 
the ﬁ rst impulse on the part of investigators is normally to delete the rootkit as soon as possible. 
Doing so is usually not the proper course of action, however. In most cases it is far better to 
make an image backup, a backup of virtually everything on the compromised system’s hard drive 
(including information that is carefully hidden in places other than in ﬁ les), as soon as possible. 
Doing this will enable forensics experts to perform a thorough forensics analysis that will enable 
them to: (1) preserve evidence to potentially be used in subsequent legal action, (2) analyze the mech-
anisms used by the rootkit and any other malicious tools that were installed, and (3) use the infor-
mation to identify other machines that may be compromised on the basis of evidence within the 
compromised system. Remember—some rootkits are nonpersistent, so making an image backup 
right away is all the more critical if obtaining a copy of a rootkit is necessary.
And now the bad news—unlike viruses, worms, and most types of Trojan horse programs, root-
kits often cannot be surgically deleted. Programs such as chkrootkit (see http://www.chkrootkit.org/) 
and Rootkit Revealer (see http://www.microsoft.com/technet/sysinternals/utilities/RootkitRevealer.
mspx) may be able to delete rootkits, but considerations related to eradicating rootkits are diﬀ erent 
from those for other types of malware. Rootkits, almost without exception, run with superuser privi-
leges. Any time a system has been compromised at the superuser level, the rootkit and the attacker 
who installed it could have done almost anything to that system. Discovering all the changes and 
software replacements is likely to be an almost impossible task, and if forensics experts overlook 
even one change that has been made, the attacker and the rootkit could regain control of the system 
shortly afterward. Th e best thing to do, therefore, is to take no chances—rebuild the system entirely 

188   Information Security Management Handbook
using original installation media. Failure to do so could result in malicious code or unauthorized 
changes remaining in the compromised system.
Recovery
Recovery means returning compromised systems to their normal mission status. Again, if a rootkit 
has been installed in a compromised system, rebuilding the system is almost always the best course 
of action. To ensure that rootkits and other malware do not reappear once a recovered system is 
up and running again, the system must be rebuilt using original installation media, and data and 
programs must be as they were before the attack occurred. Additionally, any patches need to be 
installed to help make sure that the system will not succumb to the same attack(s) that was previ-
ously launched against it. Finally, before recovery can be considered complete, a vulnerability scan 
of the compromised system should be performed to verify that no unpatched vulnerabilities exist.
Conclusion
Rootkits pose a very high level of risk to information and information systems. Information secu-
rity professionals need to learn about and analyze rootkit-related risk thoroughly and then select, 
implement, and test appropriate security control measures. A successful risk management strat-
egy includes ensuring that multiple system and network-based security control measures, such as 
conﬁ guring systems appropriately, ensuring that systems are patched, using strong authentication, 
and other measures, are in place. Because rootkits are so proﬁ cient in hiding themselves, extremely 
strong monitoring and intrusion detection and prevention eﬀ orts also need to be implemented. 
Furthermore, appropriate, eﬃ  cient incident response procedures and methods serve as another 
cornerstone in the battle to minimize the damage and disruption caused by rootkits.
In closing, information security professionals need to put the problem of rootkits in proper 
perspective. Rootkits were ﬁ rst discovered in 1994 [2]; even at that time they were remarkably pro-
ﬁ cient in hiding themselves and creating backdoor access mechanisms. Since that time, rootkits 
have improved immensely to the point that many of them are now almost impossible to detect. 
Some of them are in reality “all-in-one” malware—a complete arsenal of weapons for attackers. 
Additionally, many current rootkits capture sensitive information and are capable of being part of 
gigantic botnets that can create massive damage and disruption. Th e bottom line is that dealing 
with rootkit-related risk should be at the forefront of the proverbial radar of information security 
professionals.
References
1. Skoudis, E., Malware: Fighting Malicious Code. Upper Saddle River, NJ: Prentice Hall, 2004.
2.  Van Wyk, K., Th reats to DoD computer systems. Paper presented at 23rd International Information 
Integrity Institute Forum, Whitehouse Station, New Jersey, October, 1994.

DOMAIN
  
3
CRYPTOGRAPHY


191
Chapter 14
Encryption Key Management 
in Large-Scale Network 
Deployments
Franjo Majstor and Guy Vancollie
Contents
Introduction .............................................................................................................................192
Large-Scale Network Issues ......................................................................................................192
Performance ....................................................................................................................192
Redundancy ....................................................................................................................192
Load Balancing ...............................................................................................................192
Multicast ........................................................................................................................193
Multi-Protocol Label Switching ......................................................................................193
Encryption Options .................................................................................................................193
Link-Level Encryption ....................................................................................................193
Application-Level Encryption .........................................................................................194
Network-Level Encryption .............................................................................................194
Limitations of the IPSec Encryption ........................................................................................194
Separation of the Key Management Solution ...........................................................................195
Summary .................................................................................................................................197
Further Reading .......................................................................................................................198

192  Information Security Management Handbook
Introduction
All corporations need to protect their business transactions, customer data, and intellectual prop-
erty. At a minimum, data loss or compromise can create public relations nightmares and even 
seriously hurt market reputation. In the long run, it can impact customer relationships or create 
serious ﬁ nancial damage from fraud, information theft, or public disclosure of intellectual proper-
ties. Th is problem has presented information technology with a technological challenge because 
the ideal network data protection solution should require no change to network infrastructure, 
should not impact network performance, must work over any network topology, and must secure 
any type of traﬃ  c. Th e challenge facing information security professionals is to secure data in 
motion as has never been possible before. It is obvious that encryption is the solution to addressing 
conﬁ dentiality and integrity of the data while it transits lines that we have no control over; how-
ever, its limitations have hampered its deployment, especially on large-scale networks. Standards 
are normally present when interoperability among diﬀ erent vendor solutions should take place, 
and multiple good ones have been used, for example, the Internet Protocol security (IPSec) stan-
dard framework. Although IPSec delivered a portion of the solution, it also introduced its own 
limitations and unnecessary overlay to an existing network infrastructure, making it even more 
diﬃ  cult to manage, maintain, and operate.
Large-Scale Network Issues
Performance
Not so long ago data network infrastructures were used only for the bulk transfer of data over slow 
links of various, mostly unreliable, quality. Th e data carried over those network infrastructures 
was less important and, even if stolen, modiﬁ ed, or lost, there were always multiple paper copies 
and forms in existence to replace the data when needed. Nowadays a modern high-speed network 
infrastructure carries the most crucial pieces of information as well as multiple crucial applications 
that companies depend upon for their existence. Adding encryption to the communication paths, 
unless assisted with specialized hardware, typically slows down the overall communication speed 
and, therefore, impacts the usability of the high-speed communication paths.
Redundancy
High-speed, high-performance networks are required to stay up all the time, no matter what hap-
pens with individual communication components. Th erefore, modern network design includes 
multiple redundant devices as well as multiple available paths built into the network itself. Redun-
dancy built into the network keeps the availability of the communication paths between multiple 
points in the network; however, it often causes diﬃ  culty for security mechanisms.
Load Balancing
Multiple redundant paths do not necessarily have to work in a master–slave or active–standby 
mode, but could be active and used simultaneously to do load balancing and share the traﬃ  c load 
across the multiple links. Th is is the preferred way for eﬃ  cient networks to use multiple available 

Encryption Key Management in Large-Scale Network Deployments  193
links, but it also has, unfortunately, some security implications. Security relationships are typically 
ﬁ xed between peers and are in trouble when they lose peer relationships that have to be dynami-
cally established when network traﬃ  c chooses another path to the same destination.
Multicast
Any kind of group communication—multicast is just one of them—requires group security 
member relationships as well as group member control if any of the communication peers leaves 
or joins the group. Th at makes the encrypted group communication extremely diﬃ  cult, with a 
heavy overlay of the peer-to-peer relationships that grows exponentially with the number of peers 
communicating. It is a known mathematical fact that for “n” number of peers it is required to 
have “n × (n − 1)” peer-to-peer relationships and that times 2 if each direction has to be secured 
separately.
Multi-Protocol Label Switching
Multi-Protocol Label Switching (MPLS) wide area networks provide most of the long-distance 
connectivity today and as such are replacing multiple older technologies such as Frame Relay, 
X.25, or leased lines. MPLS provides quite similar functionality compared to its predecessors 
through the creation of separate, isolated communication paths based on diﬀ erent labels. Traﬃ  c 
isolation, however, provides neither conﬁ dentiality nor authentication of the data traveling via the 
MPLS network and opens the data to multiple risks when traveling over a shared infrastructure, 
such as a possible data leakage due to conﬁ guration errors or even illegal tapping.
Encryption Options
It has been obvious throughout the history of communication protocols that protection of data 
while it travels over unsecured data channels could be achieved with encryption. However, encryp-
tion has proven to be a diﬃ  cult task as it requires multiple other elements to be done correctly as 
well, so as not to impact modern data communication networks. As mentioned earlier, encryption 
impacts the performance, redundancy, and load balancing of modern-day networks, and also 
the requirement for any type of group communication makes the use of encryption problematic. 
Furthermore, there have been several options of where to implement encryption: on the link level, 
network level, or application level. Let us browse through them brieﬂ y to see the pros and cons 
of each.
Link-Level Encryption
Link-level encryption was one of the earliest types available and had no demand for standardization 
as there always was a product of the same vendor on both sides of the link. Key management pro-
tocols were often also proprietary and built-in as part of the solution. Th erefore, the price of such 
devices was high and when a device failed in a point-to-point topology both had to be replaced. 
Th e problems for link-level encryption came with new network media connectivity options, such 
as mesh topologies as well as multiple diﬀ erent paths through the same media. Th is led to the 
option of developing encryption on other levels, such as at the application or network level.

194  Information Security Management Handbook
Application-Level Encryption
Application-level encryption is, from a security standpoint, the highest level—as the application 
that produces the data has the best visibility on how to protect it. It would be great if each and 
every application had the encryption possibility built-in; however, as security was in the past often 
not the issue, many legacy applications remained without it and have no option to turn it on. 
Newer applications mostly have the option to protect the data via encryption; however, each and 
every one of them has its own diﬀ erent way of how to do it, and that makes scalability as well as 
intra-application data protection transfer impossible or nonscalable.
Network-Level Encryption
Owing to the limitations and drawbacks of the other earlier mentioned options and levels to 
encrypt the data, the network layer has ended up as the most frequent choice. Network-level 
encryption provides for equal protection to legacy applications as well as new applications travers-
ing the same network protocol and requires no other application changes. As Internet Protocol 
(IP) has become the most dominant network communication protocol today, we will narrow our 
discussion on the encryption features to within IP with its security protocol framework, IPSec. 
Th e IPSec protocol got standardized in the late 1990s and through numerous interoperable imple-
mentations, IPSec-based equipment has become much more aﬀ ordable than link-level encryption 
devices used to be, but as usual it has its advantages as well as its limitations, which we will focus 
on going forward.
Limitations of the IPSec Encryption
Th e IPSec set of request for comment (RFC) standards deﬁ ned the authentication as well as the 
encryption of the IP packet. It also deﬁ ned diﬀ erent modes of operation as well as the Internet key 
exchange (IKE) automated key-derivation protocol that helps with exchanging the keys based on 
a predeﬁ ned time interval or amount of transferred data. Together, IKE and IPSec got wide imple-
mentation on routers, layer-three switches, and edge devices such as ﬁ rewalls, as well as end nodes 
running on diﬀ erent operating systems. With wide implementation, however, IPSec and IKE have 
also introduced new limitations. IPSec and IKE are by deﬁ nition a peer-to-peer protocol that 
impacts network communications if there are redundant paths or if load balancing is involved. 
Peer-to-peer trusted relationships also make encrypted group communication very diﬃ  cult. Th is 
is illustrated in Exhibits 14.1 and 14.2. Last but not least, if not implemented in hardware, certain 
encryption processes also impact the performance of the communication on any higher-speed 
network connections.
A
C
D
B
Exhibit 14.1 Redundant network architecture.

Encryption Key Management in Large-Scale Network Deployments  195
Separation of the Key Management Solution
IPSec and IKE together represent three main functions most often implemented together in the very 
same, single running platform. Th ese three functions are security policy deﬁ nition, key exchange, 
and encryption. Th e most common implementation for all three functions as one IPSec/IKE 
architecture is illustrated in Exhibit 14.3. Implementation of all three of the main encryption 
components on the same physical platform seems to be an obvious choice; however, it brings with 
it its limitations of peer-to-peer relationships and, therefore, impacts modern network communi-
cations. To be able to achieve resilient and redundant network designs, the encryption security 
architecture should have its components designed the same way. Th e three main components 
in essence represent three individual roles: bulk encryption, which could be done on the policy 
enforcement point (PEP); key management, which a key authority point could take care of; and 
security policies, which could be done on a management and policy server. Th is distributed model 
represented by the three individual layers, management, distribution, and encryption, is illustrated 
Branch
office
Central data center
Branch
office
Branch
office
Branch
office
Exhibit 14.2 Group (multicast or broadcast) network architecture.
Policy definition
Key exchange
Encryption
•Policy definition
•Elements defined by standards
•Facilitates interoperability
•Key exchange protocol
•IKE is standard for IPSEC
•Use of Diffie−Hellman
•Encryption algorithm
•AES is the current standard (also 3 Data Encryption Standard [DES]/DES)
•Supports tunnel and transport mode
Exhibit 14.3 IPSec/IKE common architecture.

196  Information Security Management Handbook
Key authority point 
(KAP)
Policy enforcement
point
(PEP)
Management and
policy server
(MAP)
Open API
Distributed
or
Centralized
Exhibit 14.4 Distributed policy and key management architecture.
MAP
KAP
KAP
PEP
PEP
Management
layer
Distribution
layer
Encryption
layer
Exhibit 14.5 Three-tier encryption security architecture.
in Exhibit 14.4. Each of the main functional components could hence fulﬁ ll its job when imple-
mented on individual platforms, thereby also bringing additional beneﬁ ts such as scalability. Each 
of the layers in the three-tier model could be replicated up to the necessary service-scale level and 
support growth as required for large-scale network designs. Th e three-tier security architecture 
is illustrated in Exhibit 14.5. Th e key distribution layer and policy distribution layer have to be 
designed with redundancy and failover mechanisms as well as incorporating hardware security 

Encryption Key Management in Large-Scale Network Deployments  197
modules for key generations. Th e key storage has to be a “hack-proof” system with no backdoor 
and no possible traﬃ  c-probing vulnerabilities. An additional problem to solve is security of the 
traﬃ  c between the layers. Th at could be resolved by utilizing either IKE or other secure but less 
heavy protocols, such as the Transport Layer Security protocol. Scaling in such a distributed 
model is built-in from the ground up by design. Th e three-layer architecture allows scalability of 
security policies never before possible using IPSec. Grouping networks and network device units 
together through group policy deﬁ nitions dramatically simpliﬁ es policy generations. Th erefore, 
the layered encryption security architecture can serve many thousands of end-node PEPs in the 
network and, as well, through the open application programming interface provide access to hun-
dreds of thousands of multivendor devices, such as desktops, notebooks, cell phones, personal 
digital assistants, and printers.
An additional element that helps break the point-to-point relationship is that PEPs responsible 
for the bulk encryption doing IPSec maintain the original IP address header, as is illustrated in 
Exhibit 14.6.
With the original IP header preserved, there is no additional need to create any point-to-point 
relationships and, even more important, no need to create any overlay network on top of the exist-
ing infrastructure. Th at simpliﬁ es the encryption function on the existing modern networks to 
the maximum possible and as such only adds ﬂ exibility to enabling redundancy, load balancing, 
as well as group broadcast or multicast communication.
Summary
Th e challenge in front of the information security professional is to secure data in motion like 
never before. Encryption is the obvious choice for the solution but the solution must work over any 
network topology and must secure any type of traﬃ  c. All of that is to be done preferably without 
requiring changes to the network infrastructure or impacting the network performance. Th e IPSec 
protocol provides part of the solution but is also part of the problem, with its point-to-point nature 
as well as the network overlay model. A layered encryption security architecture brings a solution 
IP header
IP payload
Original IP packet
IPsec tunnel mode
New header with 
original IP header
encapsulated
Original header
preserved*
ESP header
Original source and destination IP address 
encapsulated in tunnel mode
IP header preservation = Tunnel-less VPN
IP
IP payload
*only the next protocol field is changed (to ESP).
Exhibit 14.6 IPSec tunnel-mode header preservation.

198  Information Security Management Handbook
to the requirements of modern data protection through the separation of the main roles and func-
tions of encryption into three individual layers. Such a three-tier encryption security architecture 
brings inherited scalability and no longer requires a network overlay for the generation and dis-
tribution of policies and encryption keys. It provides data protection but does not require any 
changes to network infrastructure, does not impact network performance, and works over any 
network topology. It is a concept that should, once widely implemented, solve the problem of data 
protection through encryption in large-scale network deployments.
Further Reading
 
1. Bauger, M., Weis, B., Hardjono, T., and Harney, H., Th e Group Domain of Interpretation, RFC 3547, 
IETF Standard, July 2003.
 
2. Davis, C. R., IPSec: Securing VPNs, McGraw-Hill, 2001.
 
3. Doraswamy, N., and Harkins, D., IPSec: Th e New Security Standard for the Internet, Intranets and 
Virtual Private Networks, Prentice-Hall PTR, 1999.
 
4. Ferguson, N., and Schneier, B., A Cryptographic Evaluation of IPSec, www.counterpane.com/ipsec.
html, April. 1999.
 
5. Frankel, S., Demystifying the IPSec Puzzle, Artech House Inc., 2001.
 
6. Harkins, D., and Carrel, D., Th e Internet Key Exchange (IKE), RFC 2409, November 1998.
 
7. Kent, S., and Atkinson, R., Security Architecture for the Internet Protocol, RFC 2401, November 
1998.
 
8. Kent, S., and Atkinson, R., IP Authentication Header, RFC 2402, November 1998.
 
9. Kent, S., and Atkinson, R., IP Encapsulating Security Payload (ESP), RFC 2406, November 1998.
 10. Kosiur, D., Building and Managing Virtual Private Networks, Wiley Computer Publishing, 1998.
 11. Maughan, D., Schertler, M., Schneider, M., and Turner, J., Internet Security Association and Key Man-
agement Protocol (ISAKMP), RFC 2408, November 1998.
 12. Perlman, R., and Kaufman, C., Key exchange in IPSec: Analysis of IKE, IEEE Internet Computing, 
4(6), pp. 50–56, 2000.
 13. Perlman, R., and Kaufman, C., Analysis of the IPSec Key Exchange Standard, WET-ICE Security Con-
ference, MIT, sec.femto.org/wetice-2001/papers/radia-paper.pdf, 2001.
 14. Weis, B., Gross, G., and Ignjatic, D., Multicast Extensions to the Security Architecture for the Internet 
Protocol, IETF draft RFC, draft-ietf-msec-ipsec-extensions-04.txt.
 15. Weis, B., Hardjono, T., and Harney, H., Th e Multicast Group Security Architecture, RFC 3740, IETF 
Standard, July 2004.

DOMAIN
  
4
PHYSICAL SECURITY
Elements of Physical 
Security


201
Chapter 15
Mantraps and Turnstiles
R. Scott McCoy
Contents
Introduction .............................................................................................................................201
Mantraps ................................................................................................................................ 202
Turnstiles ................................................................................................................................ 202
Optical Turnstiles .......................................................................................................... 204
Revolving Doors ............................................................................................................ 205
Traditional Turnstiles .................................................................................................... 205
Conclusion .............................................................................................................................. 206
Introduction
Th e challenge with most card systems is tailgating. Th is is when one person unlocks a door using 
a security credential and three people walk into a secured room. Depending on the criticality of 
the secured space, this may not be acceptable.
Th ere are many levels of access control, ranging from none to total. Total control implies that 
every person who enters and leaves a space is authorized, has been granted entry and exit, and that 
any violation of these rules is identiﬁ ed by an alarm condition. Most facilities focus on controlling 
who can enter a space through the use of one or more levels of authentication: something someone 
has, which could be as simple as a key or a company-issued access control token (proximity, con-
tactless smart card, etc.); something someone knows, which could be as simple as a four-digit pin 
number entered into a keypad (usually integrated into the card reader); or something someone is, 
such as a ﬁ ngerprint or retinal scan. For highly restricted areas, a combination of two or even all 
three may be warranted.

202  Information Security Management Handbook
Th e level of access should correspond to the criticality of the workspace. Although these tech-
nologies can be used eﬀ ectively to ensure with a high degree of conﬁ dence that only persons 
authorized may open a door, they do nothing to ensure that unauthorized persons do not tag along 
before the door shuts. Mantraps and turnstiles can be used to increase the level of control and 
reduce or eliminate tailgating.
Mantraps
A mantrap is used when more control on access is desired, but there is no need for total con-
trol. One reason may be that it is an entry into a clean room environment where containment 
is required. Th e mantrap is accomplished by having two sets of doors, both with access control 
equipment. Th e doors are spaced some distance apart, usually in excess of 15 ft, so that it takes the 
time of the ﬁ rst door to shut before you reach the second door. Th e idea is that neither door can 
be opened while the other door is in an open state, thereby making it impossible for someone to 
piggyback in or rush inside to the secured area unchecked. Mantraps usually have cameras at both 
the outer and the inner door and are connected by a hallway, so no one can hide their presence 
when they are being granted access and no one can allow more people in than authorized.
Many states have ﬁ re codes that require that free access be allowed from any secured space, 
usually requiring what is called “no special knowledge” to get out. Th is means when someone 
needs to get out due to a ﬁ re, they need only push on some easy-to-use latch or crash bar to exit. 
Because of this, most doors that use an electric strike have free egress by pushing down on a lever 
to retract the strike and do not require the release of the electric strike for exiting. Th is would not 
give the positive control a mantrap requires, so it is better either to keep the door hardware locked 
or to use a magnetic lock, which holds the door secure until activated by a touch sense bar for exit. 
With this form of egress, the circuit can be interrupted every time the other door is open, detected 
by a door contact mounted at each door. In this way, access to the other door is not allowed, 
thereby providing a mantrap.
If a person does tailgate an authorized worker past the ﬁ rst door, they can be refused entry to 
the secure area and would need to exit the outer door. No one is actually trapped in a mantrap, 
because ﬁ re codes now prohibit this, but the setup described does protect against a rush of people 
gaining access into a secured space by tailgating a worker through one open door directly into the 
restricted space.
A variation of this is used to control vehicle traﬃ  c into a secured space. Th e setup is similar 
to what is described above, but with more control, because the lanes can be broken down into 
entrance and exit, eliminating the chance of someone gaining entry while someone else exits. Two 
gates are spaced a reasonable distance apart to allow only one of whichever type of vehicle uses 
the site. Th is can be done to mandate vehicle inspections or to eliminate the possibility of tailgat-
ing. For extremely critical areas, vehicle barriers could be used in conjunction with or instead of 
traditional gates to ensure no vehicle could force its way in.
Turnstiles
Total control may be required for entrance into an area for audit purposes, even for data centers 
with Sarbanes–Oxley requirements, but usually it is not required for exit. A turnstile can be set 

Mantraps and Turnstiles  203
to allow free-wheeling exit. Turnstiles are an access control product whose purpose is to ensure 
positive access control. Only one person per transaction is allowed entry, whether using a subway 
station token or a security credential to enter a building.
Th ere are three main types of turnstiles: First is the optical turnstile, which does not oﬀ er the 
same level of access control as would be required in some settings and is often accompanied by a 
security oﬃ  cer (see Figure 15.1).
Th e second is an enhanced revolving door that is created with a mechanism that will allow 
only one section of the door to rotate into the secured space at a time (see Figure 15.2).
Th e last is the traditional type seen in most industrial settings and primarily used for outdoor 
applications (see Figure 15.3).
 Figure 15.1 Optical turnstile with barrier.
 Figure 15.2 Revolving door.

204  Information Security Management Handbook
Optical Turnstiles
Security oﬃ  cers have been used for access control in many companies for years, but even if every 
security oﬃ  cer were perfect and never missed a person or mistook another card for a badge during 
high traﬃ  c times, there is no way for the oﬃ  cer to know if all of those people are still employed, 
only that they possess a badge and it is their face on the badge. Optical turnstiles are designed 
to house diﬀ erent types of credential or biometric readers to ensure that everyone entering is still 
active in the system. Of course, there is still human error, if someone forgets to turn a record inac-
tive in the card access system, but the chance for error is less than relying on visual inspection. 
Practices should be in place that requires managers to submit a form to remove workers from 
databases when their employment ends, and emergency practices should be in place for removal 
of logical and physical access immediately when there is a termination for cause. Th en if either 
the person does not have his or her badge or the manager or human resource personnel forgets to 
collect it, it will not register as an active card and an alarm should sound. In this way as with all 
alarms, security professionals should spend their time responding to exceptions and not monitor-
ing normal or authorized transactions.
 Figure 15.3 Traditional turnstile.

Mantraps and Turnstiles  205
Optical turnstiles do not provide an actual barrier, with most being at the height of 36 in. and 
some having small wing barriers or bars to impede entry, whereas others simply alarm. Th ey are 
designed for high traﬃ  c areas usually in corporate oﬃ  ces, where it is impractical to depend on 
security oﬃ  cers to inspect every badge visually. Th ey are traditionally set up to alarm only when 
motion is detected moving in one direction for entry without a valid card read and to ignore 
motion when exiting, but they can be set up to require carding out if desired.
Revolving Doors
Revolving doors can also be set up for either entry only or both entry and exit control. Th e beneﬁ t 
of a revolving door is that, unlike an optical turnstile, it can be set up to allow only one person at 
a time entry or exit into a space and cannot be circumvented. Th e drawback of a revolving door is 
that because of the tight control, the doors move slowly and are not recommended for high traﬃ  c 
areas. Th ey are best suited for highly restricted areas where tailgating is unacceptable. Exit from 
such an area can also be completely controlled and therefore tracked, but due to ﬁ re codes in most 
countries, these revolving doors are designed with a breakout feature that collapses the sections of 
the door to allow for emergency exit. An alarm should be connected to the door in case someone 
crashes out to avoid recording his or her exit.
Traditional Turnstiles
Th ese are the turnstiles that most people envision when they hear the word. Th ey are metal and 
are most commonly found in sporting arenas and parking lots. Th e newer models function like the 
revolving doors described earlier, but are designed for outdoor applications.
Because all types of turnstiles can record all entry to a controlled space, there are safety ben-
eﬁ ts that can be used when tied into most card access systems. A common feature that is mostly 
unused is the muster feature of card access systems. Th e muster feature keeps track of whoever 
enters and exits a speciﬁ c space. For the feature to work, everyone who enters or exits must register 
his or her token for both entry and exit. If this does not happen, the software will think that some-
one is still in the space although it is actually empty or never record that they were in the space 
even if they are actually inside. Th is feature is beneﬁ cial during an evacuation for ﬁ re or chemical 
release, when it is critical to get a positive count of who is left inside a building or industrial com-
plex. Fire ﬁ ghters will be risking their lives entering these dangerous areas, and it is important for 
them to know if there are two or ten people left inside or if there are none, so there may not be a 
reason to enter at all.
If a muster feature is desired, then the location of exit readers is very important and may 
require additional readers at more remote locations to ensure a safe and speedy exit. So, for normal 
daily operations, there may be a row of two or three turnstiles at every main entry point with card 
readers on the inside and outside of a fence or perimeter wall, which require one card read per 
entry and exit request. For emergencies, there can be additional readers mounted at muster points 
a safe distance from the building, and the turnstiles can both be connected to the ﬁ re system and 
have a manual override to allow free-wheeling exit so as not to slow evacuation. Th en at the muster 
point the workers can each run their card to register an exit. Most card access features run a report 
every so many minutes based on preference during an event, each showing fewer and fewer names 
until the site is empty or only the last few people left inside are listed.

206  Information Security Management Handbook
If the same muster feature were used in a more limited way at, say, a lab inside a larger com-
plex, a revolving door could be used instead of a more traditional turnstile. Normal operation 
can also require some form of granted access using a credential or biometric for entry and egress 
with a remote muster reader at a safe distance, if muster is required, or just entry if muster is not 
required.
Conclusion
Th ere are many types of access control methodologies and technologies. As with most solutions 
related to security, a risk assessment should be done and a description of what is trying to be 
accomplished written. A security professional should never lose sight of the original goal, though 
in the quest for a solution it is easy to do so. If such an assessment indicates that there must be 
protection from tailgating above what a single door can provide, then a mantrap or some form 
of turnstile may be the answer. If positive control of entry for audit or life safety reasons is called 
for, then either a traditional turnstile or a revolving door (for oﬃ  ce applications) may be required. 
Regardless of the access control product selected, solutions requiring this level of control should 
always be accompanied with video surveillance. Any camera covering higher level access control 
should be recorded at all times and with enough deﬁ nition and number of frames so that a positive 
identiﬁ cation can be made.
Whatever level of control is required; there are a variety of access control products available 
to meet the need. Make sure before a solution is selected that it meets the requirements of the 
restricted area.

DOMAIN
  
5
SECURITY 
ARCHITECTURE 
AND DESIGN
Principles of Computer and 
Network Organizations, 
Architectures, and Designs


209
Chapter 16
Service-Oriented Architecture 
and Web Services Security
Glenn J. Cater
Contents
Introduction .............................................................................................................................210
Foundations for Web Services and Web Services-Security .......................................................211
eXtensible Markup Language .........................................................................................211
XML Extensions ....................................................................................................212
Simple Object Access Protocol ........................................................................................212
WSDL and UDDI ..........................................................................................................213
XML Signature ...............................................................................................................213
XML Encryption ............................................................................................................215
Security Assertion Markup Language ......................................................................................217
Web Services Security Standards..............................................................................................218
WS-Security ...................................................................................................................219
WS-Policy and WS-SecurityPolicy ................................................................................ 220
WS-Trust ........................................................................................................................221
WS-SecureConversation ................................................................................................ 222
WS-Federation ............................................................................................................... 222
WS-Authorization and WS-Privacy (Proposed Standards) ............................................. 224
WS-I Basic Security Proﬁ le 1.0 ...................................................................................... 224
Putting It All Together ............................................................................................................ 224
Conclusion .............................................................................................................................. 227
Further Readings .................................................................................................................... 227

210  Information Security Management Handbook
Th e concept of service-oriented architecture (SOA) has been around in various forms for some 
time, but the SOA model has really become popular of late because of advances in Web technol-
ogy, Web services, and standards. Although the concept of an SOA is not tied to a speciﬁ c technol-
ogy, in most cases SOA now refers to a distributed system using Web services for communication. 
Other examples of SOA architectures are primarily based upon remote procedure calls, which use 
binary or proprietary standards that cause challenges with interoperability. Web services solve the 
problems of interoperability because they are based upon eXtensible Markup Language (XML), by 
nature an interoperable standard. Signiﬁ cant eﬀ ort is being put into developing security standards 
for Web services to provide integrity, conﬁ dentiality, authentication, trust, federated identities, 
and more. Th ose security standards will be the focus of this chapter, which will cover XML, XML 
encryption, XML signature, Simple Object Access Protocol (SOAP), Security Assertion Markup 
Language (SAML), WS-Security, and other standards within the WS-Security family.
Introduction
So what is an SOA? SOA is an architectural model based upon independent (or loosely cou-
pled) services, with well-deﬁ ned interfaces designed in such a way as to promote reuse. SOA ﬁ ts 
extremely well with an architecture based on Web services, which by nature meet the deﬁ nition 
of loose coupling and well-deﬁ ned interfaces. For instance, as an example of a service in SOA, 
imagine a user directory that is accessible via Web services. In this example, the interface may 
specify functions, or methods, that include searching the directory (searchDirectory), password 
resets (resetPassword), updating user information (updateUser), and adding and removing users 
(addUser, removeUser). As long as the interface is adequately deﬁ ned, the consumer of the service 
does not need to know how the service is implemented to use it. Figure 16.1 illustrates a simpliﬁ ed 
SOA.
Company A
Intranet
Web site
Public
Web site
SOA
based on Web
services
Employee
User
identity
Inventory
Shipping/
receving
Order
processing
Accounting
Payment
provider
Credit card
processing
Shipping
provider
Shipping
service
Customer or
business partner
Figure 16.1 Simpliﬁ ed SOA example.

Service-Oriented Architecture and Web Services Security  211
Figure 16.1 shows that each service is reasonably independent and has a well-deﬁ ned purpose. 
Th e idea behind SOA is that, provided the services and their interfaces are designed well, they can 
be combined together in diﬀ erent ways to build diﬀ erent types of applications. For example, the 
order-processing service may be accessible from both the public Web site for placing orders and the 
internal Web site for sales and marketing purposes. Services expose their functionality through 
industry standard Web service interfaces described using the Web Services Description Language 
(WSDL), which is discussed later in this chapter.
In the simple example mentioned earlier, there is no security shown on Figure 16.1. To add 
security to this picture some of the following need to be addressed:
Network security, operating system security (server hardening), application security, and 
physical security
Transport security, typically via the use of Secure Sockets Layer (SSL)
Web service security, through the use of the Web Service-Security family (WS-*) of stan-
dards for securing Web services messages
Utilizing other WS-Security extensions to provide trust relationships between the company, 
the payment provider, and the shipping provider
Web services and Web Services Security standards make heavy use of XML. XML has revolu-
tionized data exchange because of its simplicity and power. As a simple, human-readable, text 
format XML has facilitated data exchange between applications and businesses even across dis-
similar systems.
Th e remainder of this chapter discusses Web services and the methods used to secure applica-
tions and data in an SOA environment. XML, XML encryption, XML signature, SOAP, SAML, 
and Web Services Security standards will also be covered as part of this chapter.
Foundations for Web Services and Web Services-Security
Web services and Web Services Security are based upon a number of standards that should be 
understood to some extent by a security practitioner. Th e idea is to provide an overview of the 
relevant standards here and how they ﬁ t together. Th en for some of the more complex standards 
we will delve into more detail in later sections.
eXtensible Markup Language
XML is the basic building block upon which all the other Web services standards and Web 
 Services Security standards are built. XML is a free, open standard recommended by the World 
Wide Web Consortium (W3C) as a method of exchanging data using a simple text-based format. 
Th e fact that XML is a simple, human-readable format and works across heterogeneous systems 
makes it perfect for Web services and SOAs for which the service and the consumer (client) may 
be on diﬀ erent platforms.
Th e example in Figure 16.2 is a snippet of XML describing a person. Th is simple example 
shows how XML can be easily read by a human being. Th e structure of the XML clearly identiﬁ es 
this as data related to a person (see the Person element in Figure 16.2). So in addition to exchange 
of data, the XML gives some understanding of what the data represents.





212  Information Security Management Handbook
XML Extensions
Although not really important for the understanding of how XML relates to Web Services  Security, 
there are some extensions to XML that should be included for completeness.
XML Schema is an important extension that allows the structure of XML to be deﬁ ned simi-
lar to the way in which a SQL database schema is deﬁ ned. Among other things, XML Schema 
speciﬁ es what the structure of the XML should be, such as the order in which elements appear, 
how many of each element is allowed, and the data types. XML Schema is useful for creating 
speciﬁ cations and for automatically validating the correctness of XML.
XML also has the concept of “XML namespaces.” XML namespaces provide a way to avoid 
naming conﬂ icts. For example, imagine that there are two diﬀ erent deﬁ nitions of an employee in 
XML; to diﬀ erentiate them XML namespaces can be used. Th e way this is done is by preﬁ xing the 
name with a namespace preﬁ x, for example <abc:Employee>, where abc is the namespace preﬁ x 
that contains a deﬁ nition of the employee type.
Other extensions exist that provide powerful ways to extract and query data in an XML mes-
sage. Th ese extensions are called XPath and XQuery. XPath provides a way to reference parts of 
the XML structure, whereas XQuery is a powerful query language that allows queries to be writ-
ten against the XML data, similar to SQL, which is the query language for relational databases.
Simple Object Access Protocol
SOAP is an important messaging protocol that forms the basis for the Web services protocol stack. 
SOAP messages are designed to be independent of a transport protocol, but are most often trans-
mitted via HTTP or HTTPS when used with Web services. SOAP messages are not tied to the 
HTTP protocol, however, and may also be used in message queuing systems, sent through e-mail, 
or via other transport mechanisms.
Th e SOAP standard is based upon XML and deﬁ nes the structure of messages that can be 
passed between systems. Messages deﬁ ned in SOAP have an envelope, a header, and a body as 
shown in Figure 16.3. Th e SOAP header allows for the inclusion of security elements such as digi-
tal signatures and encryption within the message. Although security elements are not restricted 
only to the header, it is used heavily with WS-S standards to transmit security information with 
the message.
Th ere are two primary messaging modes used by SOAP—“document” mode and remote 
procedure call (RPC) mode. Document mode is good for one-way transmission of messages, in 
which the sender submits the SOAP message but does not expect a response. RPC mode is more 
 commonly used and is a request–response model in which the sender submits the SOAP request 
and then waits for a SOAP response.
Figure 16.2 Simple XML example.

Service-Oriented Architecture and Web Services Security  213
WSDL and UDDI
Th e Web Services Description Language (WSDL) and Universal Description, Discovery, and 
Integration (UDDI) standards allow a consumer of a Web service to understand how to ﬁ nd a 
Web service and how to use that service. Th is includes the following:
 
a. Discovery of basic information about the service such as the service name
 
b. Where to ﬁ nd the service, including network endpoints and protocol used
 
c. How to call the service (the service contract)
WSDL is essentially metadata in the form of XML that describes how to call a Web service. Th ere 
is a security concern with the protection of the WSDL data, because if it falls into the wrong 
hands it can expose information about your network. Th e WSDL metadata may be stored as an 
XML ﬁ le, but is often available via a URL on the same application server where the Web service is 
hosted. Th e WSDL should be made available only to authorized users of the service. Later in this 
chapter, we will discuss how security policy requirements are included in WSDL.
UDDI is diﬀ erent in that it deﬁ nes a standard for a directory of Web services. Th is allows 
other applications or organizations to discover the WSDL for a Web service that meets their need. 
Businesses publish the WSDL for their Web service in the directory so that  it can be easily dis-
covered by others. UDDI directories can be hosted publicly on the Internet or internally within 
corporations to allow services to be discovered dynamically. Security of UDDI directories must 
be maintained to prevent man-in-the-middle attacks, by which a fake Web service could be pub-
lished in place of a real one. UDDI builds upon other Web Services Security standards to ensure 
integrity and trust for the data within the directory, which is particularly important for publicly 
accessible directories.
XML Signature
XML signature provides for integrity and authentication of XML data through the use of digital 
signatures and can be applied not only to XML but to any digital content. Th e primary use within 
Web Services Security is to sign XML messages to ensure integrity and to prove the identity of 
SOAP envelope
SOAP header
(XML)
SOAP body
(XML)
<Envelope>
<Header>
</Header>
<Body>
</Body>
</Envelope>
... Header XML ...
... Body XML ...
Figure 16.3 An SOAP message.

214  Information Security Management Handbook
the signer. Figure 16.4 shows an informal representation of the XML signature syntax. Th e details 
are removed to simplify explanation of the structure. Unfortunately, a more complete explanation 
of how digital signatures work is beyond the scope of this discussion.
XML signature is itself represented as XML, as Figure 16.4 shows. Th e structure contains the 
following elements:
Signature is the containing element that identiﬁ es that this is a digital signature.
SignedInfo contains the references to, and digests of, the data that is digitally signed.
CanonicalizationMethod refers to the way the SignedInfo element is prepared before the 
signature is calculated. Th e reason for this is because diﬀ erent platforms may interpret data 
slightly diﬀ erently (e.g., carriage returns <CR> versus carriage return/line feeds <CRLF>), 
which would cause signatures to compute diﬀ erently on diﬀ erent platforms.
SignatureMethod refers to the algorithm used for signature generation or validation, for 
example dsa-sha1, which refers to the use of the DSA algorithm with the SHA-1 hashing 
function.
Th e Reference element is complex, but in a nutshell it refers to the data being signed, which 
is either part of the same XML data, or a uniform resource identiﬁ er (URI) that refers to 
external data, such as a document, Web page, or other digital content. In addition, the 
reference element deﬁ nes transforms that will aﬀ ect the content prior to being passed to 
the digest for computing the hash (via DigestMethod). Th e resultant hash value is stored as 
DigestValue.
SignatureValue is the actual computed signature value. Rather than digitally signing 
the actual content, the signature is computed over SignedInfo so that all the references, 
 algorithms, and digest values are digitally signed together, which ensures the integrity of the 
data being signed.
KeyInfo enables the recipient to obtain the key needed to validate the signature, if necessary. 
Th is structure is fairly complex and is described in more detail under XML Encryption.
Th e Object element contains arbitrary XML data that can be referenced within SignedInfo. 
It can also include a Manifest element, which provides an alternate list of references, where 








Figure 16.4 Informal XML signature syntax.

Service-Oriented Architecture and Web Services Security  215
the integrity of the list itself is validated, but the integrity of the actual items will not invali-
date the signature. Th e purpose of such a list might be to include an inventory of items that 
should accompany the manifest. It also deﬁ nes a SignatureProperties element by which other 
properties of the signature are stored such as the date and time the signature was created.
Th e XML signature standard deﬁ nes three types of digital signatures, which are enveloped, envel-
oping, and detached. Enveloped signature refers to a signature on XML data, whereby the Signa-
ture element is contained within the body of the XML. Enveloping signatures contain the XML 
content that is being signed, and this is where the Object element is used to contain the data that 
is signed. Finally the detached signature type signs content that is external to the XML signature, 
deﬁ ned by an URI, which may be external digital content, but can also include elements within 
the same XML data such as sibling elements. Figure 16.5 provides an example of a detached 
signature.
As discussed earlier, XML signature allows any type of digital content to be signed, and there 
are uses for XML signature that go beyond the scope of Web Services Security. However, this 
overview of XML signature is intended to provide a foundation for understanding how it relates 
to Web Services Security.
XML Encryption
By design, XML is a plain text format with no security built in. XML encryption provides data 
conﬁ dentiality through a mechanism for encrypting XML content that relies on the use of shared 
Figure 16.5 XML signature example.

216  Information Security Management Handbook
symmetric encryption keys. Standard key exchange techniques based on public-key cryptography 
provide secrecy for the shared key. Typically the shared key is included within the XML message 
in an encrypted form, is referenced by name or URI, or is derived from some key exchange data. 
Symmetric encryption keys are used to encrypt data for performance reasons because public-key 
encryption can be very slow in comparison.
Figure 16.6 shows an informal representation of the XML encryption syntax. Th e details are 
removed to simplify explanation of the structure.
Like XML signature, XML encryption is itself represented as XML, as Figure 16.6 shows. Th e 
structure contains the following elements:
EncryptedData is the containing element that identiﬁ es that this is encrypted data.
EncryptionMethod deﬁ nes the encryption algorithm that is used to encrypt the data, such 
as Triple-DES (3DES). Th is is an optional element and if it is not present, then the recipient 
must know what algorithm to use to decrypt the data.
ds:KeyInfo contains information about the encryption key that was used to encrypt the 
message. Either the actual key is embedded in encrypted form or there is some information 
that allows the key to be located or derived.
EncryptedKey contains an encrypted form of the shared key. As mentioned previously this 
key will typically be encrypted using public-key cryptography. Th ere may be multiple recipi-
ents of a message, each with their own encrypted key element.
AgreementMethod is an alternate way of deriving a shared key by using a method such as 
Diﬃ  e–Hellman. Providing key agreement methods means that the key does not need to be 
previously shared or embedded within the EncryptedKey element.
ds:KeyName provides another way of identifying the shared encryption key by name.
ds:RetrievalMethod provides a way to retrieve the encryption key from a URI reference, 
either contained within the XML or external to it.
ds:* refers to the fact that there is other key information, such as X.509v3 keys, PGP keys, 
and SPKI keys that can be included.








Figure 16.6 Informal XML encryption syntax.

Service-Oriented Architecture and Web Services Security  217
CipherData is the element that contains the actual encrypted data, either with CypherValue 
as the encrypted data encoded as base64 text or by using CypherReference to refer to the 
location of the encrypted data, in the XML or otherwise.
EncryptionProperties contains additional properties such as the date and time the data was 
encrypted.
Figure 16.7 shows an example of an XML-encrypted message. Th e encrypted data is clearly visible 
in the CipherValue element.
Th is basic overview of the XML encryption standard helps to give some background on how 
data conﬁ dentiality can be achieved with XML; however, there is much more detail than can be 
covered here.
Th e XML signature and XML encryption standards together form the basic security building 
blocks upon which the rest of the WSS standards rely.
Security Assertion Markup Language
SAML is a standard framework based upon XML for communicating user identity, user entitle-
ments, and user attributes between organizations or entities in separate security domains. SAML 
builds upon XML signature and XML encryption to provide integrity, conﬁ dentiality, and authen-
tication of SAML assertions. 
SAML allows an entity or organization to vouch for the identity of an individual, via a SAML 
assertion (a portable XML authentication token). Th e SAML assertion can be presented as proof 
of identity to another entity provided a trust relationship has been established between the two 
parties. Th is can be important for SOAs for which services are located within separate companies 
or security domains. Th is concept is really the basis of federated identity, which insulates organiza-
tions from the details of authentication and identity management within other organizations.
SAML attempts to solve several problems:
Web single sign-on—by which a user can sign into one Web site and then later sign into a 
second related Web site using the credentials (a SAML assertion) provided by the ﬁ rst site.
Delegated identity—by which credentials supplied to an initial Web site or service can be 
utilized by that service to perform actions on behalf of the user. An example is a travel Web 
site, which can pass the user identity to other services to perform airline, hotel, and car rental 
reservations.




Figure 16.7 Example of an XML-encrypted message.

218  Information Security Management Handbook
Brokered single sign-on—by which a third-party security service authenticates the user. Th e 
credentials provided by the third-party security service can then be used to authenticate to 
multiple Web sites.
Attribute-based authorization—by which attributes about the user are placed into the SAML 
assertion. Th ese attributes are then used to make authorization decisions. For example, user 
“John Doe” has level “director” in the “human resources” department; based upon these 
attributes he is allowed certain access to the human resources systems.
Within the SAML assertion will be some information about a user’s identity, such as the user’s 
e-mail address, X.509 subject name, Kerberos principal name, or an attribute such as employee 
identiﬁ cation number. For privacy purposes, SAML 2.0 introduced the concept of pseudonyms 
(or pseudorandom identiﬁ ers), which can be used in place of other types of identiﬁ ers, thereby hid-
ing personal identiﬁ cation information such as an e-mail address. SAML provides two main ways 
to conﬁ rm the subject’s identity. One way is referred to as “holder of key,” where the sender of the 
message (the subject) typically holds the key that was used to digitally sign the message. Th e other 
conﬁ rmation method is referred to as “sender vouches,” which means that the digital signature on 
the message was created by a trusted third party.
Th is description of SAML is intended to provide some understanding of where it ﬁ ts within 
SOAs. By leveraging trust relationships between service providers, SAML provides loose coupling 
and independence with respect to user identity. SAML is also referenced by the WS-S standards 
as a type of security token.
Web Services Security Standards
To gain an understanding of how all the Web Services Security protocols ﬁ t together, refer to the 
illustration in Figure 16.8. Th is diagram shows how XML signature, XML encryption, and SOAP 
form the foundation of the stack, with the other Web Services Security standards building upon 
them. Other standards, such as WSDL, UDDI, SAML, WS-Policy, and WS-PolicyAttachment 


Figure 16.8 WS-S standards.
WS-Federation
WS-Authorization 
(proposed)
WS-Privacy
(proposed)
WS-Trust
WS-PolicyAttachment
WS-SecurityPolicy
WS-Security (WSS)
WS-SecureConversation
SAML
WS-Policy
Related
Related
WSDL
UDDI
Web Services & security foundation
Web Services Security standards
SOAP
XML encryption
XML signature

Service-Oriented Architecture and Web Services Security  219
are listed down the right-hand side of the Figure 16.8 that have relationships to the security stan-
dards, but are not speciﬁ cally security standards themselves.
It is clear from  Figure 16.8 that the WS-Security protocol suite is complex, which can serve to 
discourage adoption of these standards into an SOA, particularly for application developers whose 
job is complicated by these security protocols. Th is complexity can lead to a reliance on SSL and 
ﬁ rewall policies to provide point-to-point security for SOAP messages. Fortunately, tools are avail-
able to simplify integration of security into Web services and SOA.
WS-Security
Th e WS-Security standard, also referred to as WSS: SOAP Message Security, speciﬁ es extensions 
to SOAP that provide message integrity, message conﬁ dentiality, and message authentication. 
WS-Security leverages XML signature to ensure that the integrity of the message is maintained 
and XML encryption to provide conﬁ dentiality of the message. Security tokens are supported for 
authentication purposes to provide assurance that the message originated from the sender identi-
ﬁ ed in the message.
Th ere are three categories of security tokens that are deﬁ ned by WS-Security: username 
tokens, binary security tokens, and XML tokens. Each of the security tokens supported by 
WS-Security ﬁ ts within one of these categories. Examples of security tokens are usernames and 
passwords  (UsernameToken),  Kerberos tickets (BinarySecurityToken), X.509v3 certiﬁ cates (Binary-
SecurityToken), and SAML (XML Token). Th e WS-Security header is designed to be extensible to 
add additional security token types.
Figure 16.9 shows where the WS-Security SOAP extensions appear within the header of the 
SOAP message.
Figure 16.9 An SOAP message with WS-S extensions.

220  Information Security Management Handbook
Th e example in Figure 16.9 shows that the structure of a SOAP message is altered when 
WS-Security extensions are added. It also shows how the security tokens, XML signature, 
and XML encryption ﬁ t within the WS-Security (wsse) header. Th e receiver of a message with 
WS-Security extensions processes the extensions in the order they appear in the header, so in this 
case the signature is veriﬁ ed on the message body and then the message is decrypted.
Th e following ﬁ ve types of tokens are discussed in version 1.1 of the standard:
Username token, which is the most basic type of token. A UsernameToken contains a user-
name to identify the sender and it can also contain a password as plain text, a hashed pass-
word, a derived password, or an S/KEY password. Obviously, the use of plain-text passwords 
is strongly discouraged.
X.509 token, which is a BinarySecurityToken, identiﬁ es an X.509v3 certiﬁ cate that is used 
to digitally sign or encrypt the SOAP message through the use of XML signature or XML 
encryption.
Kerberos token, which is also a BinarySecurityToken, includes a Kerberos ticket used to provide 
authentication. Ticket granting tickets (TGT) and service tickets (ST) are supported.
SAML token, which is an XML token, provides a SAML assertion as part of the SOAP 
security header.
Rights expression language (REL) token, which is an XML token, provides an ISO/IEC 
21000 or MPEG-21 license for digital content. Th is type of token is used for communicat-
ing the license to access, consume, exchange, or manipulate digital content.
WS-Security allows for the inclusion of time stamps within the SOAP security header. Time 
stamps can be required (see WS-Policy and WS-SecurityPolicy) to determine the time of creation 
or expiration of SOAP messages. 
In addition, WS-Security deﬁ nes how to add attachments to SOAP messages in a secure man-
ner by providing conﬁ dentiality and integrity for attachments. Support for both multipurpose 
Internet mail extensions (MIME) attachments and XML attachments is provided.
SOAP messages and attachments may be processed by diﬀ erent intermediaries along the route 
to the ﬁ nal recipient, and WS-Security allows parts of messages to be targeted to diﬀ erent recipients 
to provide true end-to-end security. Th ere is an important distinction between point-to-point secu-
rity technologies such as SSL and end-to-end security in which there are multiple intermediaries. 
A possible scenario is that one intermediary might need to perform some processing on a message 
before passing the message along; however, some parts of the message are conﬁ dential and intended 
only for the ﬁ nal recipient. SSL would not provide the necessary security in this scenario.
WS-Policy and WS-SecurityPolicy
Th e WS-Policy standard by itself is not directly related to security. Its purpose is to provide a 
framework for describing policy requirements in a machine-readable way. A policy might describe 
communication protocols, privacy requirements, security requirements, or any other type of 
requirement. WS-SecurityPolicy builds upon the WS-Policy framework to deﬁ ne security policies 
for WS-Security, WS-Trust, and WS-SecureConversation.
Th e following types of assertions are available within WS-SecurityPolicy:
Protection assertions (integrity, conﬁ dentiality, and required elements), which deﬁ ne which por-
tions of a message should be signed or encrypted and which header elements must be present.







Service-Oriented Architecture and Web Services Security  221
Token assertions, which specify the types of security token that must be included (or not 
included), such as UsernameToken, IssuedToken (third-party-issued token, e.g., SAML), 
X509Token, KerberosToken, SpnegoContextToken (used with WS-Trust), SecurityContext-
Token  (external), SecureConversationToken (used with WS-SecureConversation), SamlToken, 
 RelToken,  HttpsToken (requires use of HTTPS).
Security-binding assertions, which deﬁ ne requirements for cryptographic algorithms, time 
stamps, and the order of signing and encrypting; whether the signature must be encrypted 
or protected; and whether signatures must cover the entire SOAP header and body.
WS-Security assertions, which indicate which aspects of WS-Security must be supported 
within the message.
WS-Trust assertions, which deﬁ ne policy assertions related to WS-Trust.
Th ere is a related standard, called WS-PolicyAttachment, that deﬁ nes attachment points within 
WSDL at which security policies can be deﬁ ned. Th is provides a mechanism for describing the 
security policy associated with a Web service along with the Web service interface deﬁ nition.
WS-Trust
WS-Trust builds upon WS-Security and WS-Policy to deﬁ ne mechanisms for issuing, renewing, 
and validating security tokens. Th e WS-Trust model has many similarities to Kerberos, and there 
are direct analogies such as delegation and forwarding of security tokens. Of course WS-Trust 
is designed to work over Web services and with many types of security tokens, such as X.509, 
 Kerberos, XML tokens, and password digests. WS-Trust can also extend to trust relationships over 
the Internet, whereas Kerberos is more suited to providing trust within intranet-type scenarios. 
WS-Federation, discussed later in this chapter, builds upon these principles and adds mechanisms 
to provide a framework for implementing identity federation services.
In the WS-Trust model shown in Figure 16.10, the Web service has a policy that deﬁ nes 
what security tokens are required to use the service (via WSDL). To access the Web service, the 
requester needs a valid security token that the Web service understands. To obtain a valid secu-
rity token, the requester may directly request a token from the security token service (STS), via 
a RequestSecurityToken request. Assuming the requester adequately proves its claims (via digital 




Requester
Security token
service (STS)
Web service
Claims
Claims
Claims
Security
token
Security
token
Policy
Security
token
Policy
Policy
Figure 16.10 WS-Trust security model.

222  Information Security Management Handbook
signatures) to the STS and meets the STS policy, the STS will respond with a RequestSecurity-
TokenResponse containing a new token signed by the STS. Th is new token will be in a format 
the Web service understands, even if the client and Web service support diﬀ erent authentication 
mechanisms. For example, say the client understands X.509 certiﬁ cates only and the Web service 
understands SAML only, then the STS can issue a SAML token for the requester to present to the 
Web service.
WS-Trust addresses the issue of trust in the security tokens by providing mechanisms for 
brokering trust relationships through the use of one or more STSs. Trust is established through 
relationships between the requester and an STS, between the Web service and an STS, and 
between STSs. So the Web service need not directly trust the requester or the STS it uses to 
accept security tokens, as long as there is a trust relationship between the requester’s STS and the 
Web service’s STS.
WS-SecureConversation
Th e WS-SecureConversation standard builds upon WS-S and WS-Trust to deﬁ ne the concept of 
a security context, or session between services. Establishing a security context aims to alleviate 
some of the potential security problems with WS-S, such as message replay attacks and support 
for challenge–response security protocols.
Th ere are three diﬀ erent ways to establish the security context.
An STS (see WS-Trust) is used, whereby the initiator requests the STS to create a new 
 security context token.
Th e initiator is trusted to create the security context itself and sends it along with a message.
A new security context is created via a negotiation between participants, typically using the 
WS-Trust model.
An advantage of WS-SecureConversation is that it optimizes multiple secure Web service calls 
between services by performing the authentication step only once for the conversation, by reduc-
ing message size with the use of a small context identiﬁ er, and by performing only fast symmetric 
cryptography (using the shared secret keys). WS-SecureConversation uses public-key cryptogra-
phy to derive shared secret keys for use with the conversation.
WS-Federation
WS-Federation builds upon WS-Security, WS-Policy, WS-SecurityPolicy, WS-Trust, and  WS- Secure 
Conversation to allow security identity and attributes to be shared across security boundaries. 
As its name suggests, WS-Federation provides a framework for implementing federated identity 
services.
WS-Federation deﬁ nes certain entities.
Principal is an end user, an application, a machine, or another type of entity that can act as 
a requester.
STS, as deﬁ ned in WS-Trust, issues and manages security tokens such as identity tokens and 
cryptographic tokens. Th e STS is often combined with an identity provider role as STS/IP.






Service-Oriented Architecture and Web Services Security  223
Identity provider is a special type of STS that performs authentication and makes claims 
about identities via security tokens.
Attribute service provides additional information about the identity of the requester to 
authorize, process, or personalize a request.
Pseudonym service allows a requester (a principal) to have diﬀ erent aliases for diﬀ erent 
 services and optionally to have the pseudonym change per service or per log-in.  Pseudonym 
services provide identity mapping services and can optionally provide privacy for the 
requester, by utilizing diﬀ erent identities across providers.
Validation service is a special type of STS that uses WS-Trust mechanisms to validate 
 provided tokens and determine the level of trust in the provided tokens.
Trust domain or realm is an independently administered security space, such as a  company 
or organization. Passing from one trust domain to another involves crossing a trust 
boundary.
Th ese services can be arranged in diﬀ erent ways to meet diﬀ erent requirements for trust, from 
simple trust scenarios through to quite complex trust scenarios. Th e example in Figure 16.11 
illustrates a fairly complex scenario in which the requester ﬁ rst requests a token from the STS/IP 
it trusts. (1) Th e security token is then presented to the resource’s STS to request a token to access 
the resource. (2) Assuming the requester’s token is valid, the resource’s STS will issue a new token, 
which is then presented to the Web resource to request access. (3) Th e Web service resource at 
some point needs to perform work on behalf of the principal, so it queries another STS/IP in 
a separate security domain to obtain a delegated security token. (4) Assuming the Web service 
has the appropriate proof that it is allowed to perform delegation, the STS/IP will issue a security 
token. (5) Th is delegated security token is then presented to the resource on behalf of the principal. 
Th e chain of trust between the requester and the resource in trust domain C can be followed in 
the Figure 16.11.





Trust domain A
Trust domain B
Trust domain C
STS
IP
Trust
Trust
Trust
Trust
STS
STS
IP
IP
P
P
Trust
STS
IP
(1)
(2)
(3)
(4)
(5)
Resource 
(service)
Resource 
(service)
Requester
Identity provider
Principal (requester)
Security token service
Figure 16.11 WS-Federation example.

224  Information Security Management Handbook
WS-Federation introduces models for direct trust, direct brokered trust, indirect brokered trust, 
delegated trust, and federated trust relationships. Other services can be added to the picture, such 
as attribute and pseudonym services for attribute-based authorization, role-based authorization, 
membership, and personalization. Pseudonym services store alternate identity information, which 
can be used in cross-trust domain scenarios to support identity aliases and identity mapping.
WS-Federation also describes a way for participants to exchange metadata such as the capabili-
ties, security requirements, and characteristics of the Web services that form the federation. Th is 
exchange of metadata is achieved through the use of another standard called WS-MetadataExchange, 
which builds primarily upon WSDL and WS-Policy.
WS-Authorization and WS-Privacy (Proposed Standards)
As these standards are not yet published, they are mentioned here just for completeness. 
WS- Privacy is a proposed standard language for describing privacy policies for use with Web 
services. Th e standard is intended for use by organizations to state their privacy policies and to 
indicate their conformance with those policies. WS-Authorization is a proposed standard for how 
to describe authorization policies for Web services using a ﬂ exible authorization language. Th e 
standard will describe how authorization claims may be speciﬁ ed in a security token and validated 
at the endpoint.
WS-I Basic Security Proﬁ le 1.0
With the large number of WS-* security standards, vendors are implementing them at diﬀ erent 
times, and not all of the options are common from one vendor’s system to the next. WS-I Basic 
Security Proﬁ le 1.0 is intended to provide a baseline for WS-Security interoperability among dif-
ferent vendor’s products. Th e idea is that if the products conform to the Basic Security Proﬁ le 1.0, 
then they should be interoperable at least to some level. Th is can be important when implement-
ing SOAs with products from diﬀ erent vendors, such as Sun’s Java J2EE, BEA Weblogic, and 
Microsoft’s .NET platform.
Th e Basic Security Proﬁ le 1.0 supports a good number of security extensions, including 
 Kerberos, SAML, X.509, and username tokens and support for SSL transport-layer security 
(HTTPS).
Putting It All Together
Now that we have covered the suite of Web Services Security standards, we can apply this knowl-
edge to the problem of securing an SOA based upon Web services.
It is important to note that traditional security principles should form the basis of a secure SOA. 
Th e environment in which the systems are running should be managed appropriately to ensure 
that the organization’s security policies are satisﬁ ed and that regulatory requirements placed upon 
the organization are being met. Th is includes attention to network security, operating system secu-
rity, application security (including the Web services infrastructure), and physical security. Secu-
rity risk assessments, threat analysis, vulnerability scanning, and penetration testing techniques 
should be used to validate the security of the SOA services, platforms, and related systems.

Service-Oriented Architecture and Web Services Security  225
To perform a thorough security assessment, the following types of questions should be asked:
What does the overall SOA look like?
Who are the intended consumers of the service(s)?
How are the services discovered by consumers? Is WSDL or UDDI used?
What interactions occur between consumers and services and between services?
Are any of the services or consumers on untrusted networks?
What types of data are passed between consumers and services at various points?
Is data integrity or conﬁ dentiality required at any point within the SOA?
Does data ﬂ ow through multiple intermediaries?
Is there a need to provide end-to-end security for certain types of data?
What are the authentication and authorization requirements for each of the services?
Is the authorization based upon roles or attributes?
Is data privacy a concern?
What security technologies, such as X.509, Kerberos, or SAML, are available?
Are multiple security domains involved? Is there a need for cross-domain trust relationships?
Are there diﬀ erent Web services technologies, such as J2EE, Weblogic, or .NET, in use that 
might cause issues with protocol support or interoperability? If so, is the WS-I Basic Security 
Proﬁ le 1.0 supported?
Th reat analysis—what potential threats are there to the infrastructure, such as malicious 
attacks, insider threats, information disclosure, disasters, message replay attacks, or denial-
of-service (DoS)?
Th e following summarizes the types of threats that apply to SOA and mechanisms to mitigate the 
threats:
Information disclosure (conﬁ dentiality)—Use of XML encryption within WS-Security can 
provide data conﬁ dentiality. End-to-end message conﬁ dentiality can also be handled with 
XML encryption.
Message tampering—Message tampering could be used to remove XML, add XML, or oth-
erwise alter data or cause some unintended behavior within the application. XML signatures 
can be used to ensure the integrity of messages.
Message injection—Message injection may be used to cause some unintended behavior 
within the application. Authentication mechanisms and input validation within the service 
can help to mitigate this issue.
Message replay—WS-SecureConversation provides mechanisms to prevent this kind of 
attack, but otherwise, message identiﬁ ers or time stamps can be used to prevent message 
replay.
Authentication—Authentication is provided by XML signatures and security tokens such 
as Kerberos, X.509 certiﬁ cates, and SAML, or even username tokens. Th ese methods are 
supported by WS-Security and WS-Trust.
Authorization—Authorization can be role based or attribute based. Th e Web services plat-
form will typically provide some form of authorization capability, but for more advanced 
authorization needs, the application will have to include explicit authorization checks.
Service availability—Disasters, whether natural or human-made, need to be planned for by 
ensuring that an adequate disaster recovery strategy is in place. Other malicious attacks such 
























226  Information Security Management Handbook
as DoS can aﬀ ect the network, operating system, or application. Dealing with DoS attacks 
is beyond the scope of this chapter, however.
Token substitution—Attempts to substitute one security token for another can be prevented 
by ensuring that digital signatures provide integrity over all the security critical portions of 
the message, including security tokens.
Once a risk assessment is completed, and the security requirements are understood, decisions 
need to be made about how to secure the SOA environment. Risks are normally rated in terms of 
impact and likelihood and should be prioritized—for example into high-risk, medium-risk, and 
low-risk categories. Security measures can then be chosen to mitigate the risks and meet security 
requirements, based on a cost–beneﬁ t analysis.
General security principles should be followed when choosing security measures, such as:
Ensuring the conﬁ dentiality, integrity, and availability of data and services
Defense in depth
Principle of least privilege
Minimizing the attack surface
Promoting simplicity rather than complexity
At the network level, ﬁ rewall policies can be applied to limit access to Web services, because 
SOAP messages are transmitted via HTTP, typically on Transmission Control Protocol (TCP) 
port 80, or via HTTPS on TCP port 443. Internet-facing servers should have access restricted just 
to the port that the service is listening on. Firewall policies can form the ﬁ rst line of defense by 
reducing the available attack surface. Other standard techniques, including DMZ  architecture, 
 security zones, and intrusion detection/prevention, can reduce risk at the network level and pro-
vide defense in depth.
At the transport level, Web services are often secured through the use of SSL, via the HTTPS 
protocol, and policies can be applied through WSDL to ensure that Web services are secured with 
SSL. Th e use of SSL should deﬁ nitely be considered, particularly because it is a well-understood 
protocol, although it is important to understand that SSL provides only point-to-point encryption 
and that other techniques need to be applied if the security of the SOAP messages is to be main-
tained beyond the SSL session.
At the message level, XML is by nature a text-based standard, so data conﬁ dentiality and 
integrity are not built in. SOAP messages and attachments may be processed by diﬀ erent inter-
mediaries along the route to the ﬁ nal recipient, and WS-Security allows parts of messages to be 
targeted to diﬀ erent recipients. Th is is an important distinction between point-to-point secu-
rity technologies, such as SSL, and end-to-end security, which WS-Security supports. XML 
encryption can provide end-to-end data conﬁ dentiality via public-key cryptography and shared 
symmetric-key cryptography, whereas XML signature can meet data integrity and message 
authentication needs.
Other issues exist when dealing with trust relationships and cross-domain authentication. 
Th e WS-Trust and WS-Federation standards provide a technical foundation for establishing trust 
for SOAs. Organizational security policies and regulatory requirements should deﬁ ne the secu-
rity requirements that need to be placed on interactions with customers and business partners. 
Th ese security requirements can be used as a basis for determining the security mechanisms that 
need to be used to provide an appropriate level of trust, such as encryption strength or method 







Service-Oriented Architecture and Web Services Security  227
of  authentication (X.509 digital certiﬁ cates, SAML, Kerberos, etc.). However, trust between 
 organizations goes beyond technical implementation details and also needs to be addressed by 
contractual obligations and business discussions.
Conclusion
Th e WS-S family provides an essential set of standards for securing SOAs; however, the number 
and complexity of the standards is a deﬁ nite problem. Th is complexity can serve to discourage 
the adoption of these standards into an SOA, particularly for application developers, whose job is 
complicated by security needs. Th ese standards are also evolving and new security standards are 
being developed, so expect the SOA security landscape to evolve over time.
Fortunately vendors are providing new tools to simplify integration of WS-Security standards 
into Web services. Th ese tools can help by hiding many of the lower-level details from security 
practitioners and architects. Expect these tools to evolve over time as SOA and Web services 
become more mature. At this time, however, it is still not an easy task to integrate WS-Security 
standards into Web services.
For the security practitioner, standard security principles can be leveraged to assist in guiding 
architects and developers in selecting appropriate mechanisms to secure SOAs.
Further Readings
IBM developerWorks Web Services Standards Documentation, http://www.ibm.com/developerworks/ 
webservices/standards.
Microsoft MSDN Documentation on WSE Security and WCF Security, http://msdn2.microsoft.com/ 
en-us/library/default.aspx.
OASIS Standards for WS-Security, WS-Trust, WS-SecureConversation, WS-Federation, UDDI and 
SAML, http://www.oasisopen.org/specs/index.php.
Security in a Web Services World: A Proposed Architecture and Roadmap, http://msdn2.microsoft.com/
enus/library/ms977312.aspx.
W3C Standards for XML, XML Encryption, XML Signature, SOAP, WSDL, WS-Policy and WS-
PolicyAttachment, http://www.w3.org/.


229
Chapter 17
Analysis of Covert Channels
Ralph Spencer Poore
Contents
What Is a Covert Channel? ..................................................................................................... 229
How Is a Covert Channel Exploited? ...................................................................................... 230
How Much Information Can Flow over a Covert Channel? .....................................................231
Example of a Covert Channel ................................................................................................. 232
Overview of the Analysis Process ............................................................................................ 232
Protecting against Covert Channels ........................................................................................ 234
Steganography as a Special Case ............................................................................................. 234
Recommendations ...................................................................................................................235
Further Readings .....................................................................................................................235
Technology—suﬃ  ciently advanced—is indistinguishable from magic.
attributed to Arthur C. Clarke 
Complex systems often have paths for information that were not intended by their designers. Th ese 
paths or channels may exist at any layer within the open systems interconnection (OSI) model and 
may cross  layers. Th rough these channels information may escape to unauthorized recipients. To 
the unwary, these covert channels transport information as if by magic.
What Is a Covert Channel?
Th e security and academic literature deﬁ ne the term “covert channel” in several ways. Th e notion of 
covert communication was introduced in a paper by Lampson (1973), in which he deﬁ ned the term 
by stating that “A communication channel is covert if it is neither designed nor intended to trans-
fer information at all.” Other deﬁ nitions tend to focus on the diﬀ erent means that result in such a 

230  Information Security Management Handbook
communication channel (the references for this chapter include a wealth of publications discussing 
this). However, a covert channel becomes especially important when it can result in the leakage of sen-
sitive information either from a more-sensitive process (e.g., one that is classiﬁ ed as top secret) to a less-
sensitive process (e.g., one that is classiﬁ ed as conﬁ dential) or from one compartment (e.g., medical 
records) to another (e.g., oﬃ  ce equipment inventory). Th is unintended path moves data from access 
by authorized users to access by unauthorized users. Because the covert channel is neither designed 
nor intended to transfer data, access control mechanisms generally cannot address the leakage.
A covert channel exists when two (or more) processes operating at diﬀ erent levels of sensitiv-
ity share a resource, whereby the less-sensitive process cannot read the information written to it 
by the more highly sensitive process, but can measure the eﬀ ect on its own performance of the 
resource’s use by the more-sensitive process. For example, if a nonsensitive ﬁ le, such as a zip codes 
ﬁ le, were accessible to both a highly sensitive process (e.g., a human immunodeﬁ ciency virus 
research program) and a less sensitive process (e.g., a general market mailing program), a path for 
information leakage (i.e., a covert channel) would exist if, by analyzing the performance of the 
less-sensitive process as it opens, reads, and closes the zip codes ﬁ le, information could be obtained 
about the highly sensitive process that also opens, reads, and closes the zip codes ﬁ le.
In practice, when covert channel use scenarios are constructed, a distinction between covert 
storage channels and covert timing channels is made, even though theoretically no fundamental 
distinction exists between them. A potential covert channel is a storage channel if its use scenario 
“involves the direct or indirect writing of a storage location by one process and the direct or indirect 
reading of the storage location by another process” (National Computer Security Center, 1985). 
A potential covert channel is a timing channel if its use scenario involves a process that “signals 
information to another by modulating its own use of system resources (e.g., CPU time) in such a 
way that this manipulation aﬀ ects the real response time observed by the second process” (National 
Computer Security Center, 1985).
How Is a Covert Channel Exploited?
To exploit a covert channel, the perpetrators need to identify it and need to capture the  performance 
data of the less-sensitive process to which they presumably have access. Th e required  analysis is not 
trivial. However, if the sensitive information is of suﬃ  cient value and alternative means eﬀ ectively 
prevented, then even the diﬃ  cult analysis may become attractive.
Once the perpetrators have identiﬁ ed the covert channel, they may be able to exploit it more 
directly if they can create and execute a process of his or her own. An even worse situation is 
one in which an authorized user with access to highly sensitive data conspires with someone 
who does not have access to such data. Th e authorized user cannot just copy the data to a lower 
classiﬁ cation (as this violates access control policy). Instead, the authorized user (whom we will 
call “Adam”) creates a program that will signal the information via a covert channel to a pro-
gram created by the unauthorized user (whom we will call “Ulysses”). In this scenario,* Ulysses 
creates three ﬁ les: synch, bit_1, and bit_0. Ulysses opens synch for writing, writes “Begin” 
in the ﬁ le, and then closes it. Adam opens synch for reading, reads it, and closes it; this he repeats 
* Th is scenario is based on a widely followed security policy of allowing high-security processes to read low-
 security ﬁ les, but preventing low-security processes from reading high-security ﬁ les. In the Bell-La Padula 
Model, this is the star (*) property, sometimes called the “write up, read down” policy.

Analysis of Covert Channels  231
until he reads “Begin” in the ﬁ le. At this point, Adam and Ulysses may begin exploiting the covert 
channel through the following loop of steps:
 
1. Adam opens bit_1 for reading when he intends to send a “1”; he opens bit_0 for reading 
when he intends to send a “0”.
 
2. Adam also continues to open synch for reading, reads it, and closes it, repeating this until 
he reads “Next” in the ﬁ le.
 
3. Ulysses repeatedly attempts to open both bit_1 and bit_0 for writing. If this succeeds for 
both, they are closed, and this step is repeated. If Ulysses succeeds for one but not for the 
other, than a bit has been sent (i.e., a “1” if he failed to open bit_1 and a “0” if he failed to 
open bit_0).
 
4. Adam closes the open ﬁ le bit_1 or bit_0.
 
5. Ulysses repeatedly attempts to open the ﬁ le he failed to get in step 3 until he succeeds.
 
6. Ulysses then signals his success (indicating receiving of the bit) by writing a message (i.e., 
“Next”) to the synch ﬁ le.
 
7. Th is loop continues until all the bits are transferred from Adam to Ulysses.
Given machine speeds, this prearranged exploitation of a covert channel could have a very high 
bandwidth.
How Much Information Can Flow over a Covert Channel?
Th e amount of information communicated over a covert channel in a given period is called its 
bandwidth or capacity. Very low bandwidths, for example, 1 bit per hour, may make exploitation 
impractical and alleviate the need for remediation (but not always). High bandwidths, however, 
invite discovery and exploitation. Information theory as described by Shannon and Weaver (1964) 
provides a mathematical basis for determining bandwidth. Th e interested reader with extensive 
background in advanced mathematics is invited to review their paper. An additional source with 
somewhat simpliﬁ ed mathematics (but still requiring more than college algebra) is well pre-
sented in Section 4.0 of A Guide to Understanding Covert Channel Analysis of Trusted Systems 
(NCSC-TG-30). Th e information security practitioner, however, may need only a general 
understanding. To that end, here is a substantial oversimpliﬁ cation: the bandwidth is a function 
of the number of possible states available to the channel and the speed at which the states can be 
changed by one process and evaluated by another. For example, if the high-sensitivity process can 
cause four detectable independent events each millisecond, that would be equivalent to passing a 
4-bit value every millisecond for a bandwidth of 4000 bps. Th e Handbook for the Computer Secu-
rity Certiﬁ cation of Trusted Systems * contains in Chapter 8, “Covert Channel Analysis,” a discus-
sion of channel capacity that concludes that the trend toward faster systems in shared memory 
multiprocessors makes fast covert channels much more likely. Th is conforms to Moore’s Law,† 
which portends serious consequences if we ignore covert channel analysis.
* Prepared by the University of North Carolina for the Naval Research Laboratory under contract N00014-91-
K-2032 (NRL Technical Memorandum 5540:062A, February 12, 1996).
† Th e term Moore’s Law was coined by Carver Mead (ca. 1970) and is named after Gordon E. Moore (a cofounder 
of Intel). He determined that the number of transistor counts for the same component costs doubled every two 
years. Th is proportional “law” has been generalized to information processing advances. Although such dou-
bling cannot continue indeﬁ nitely, it has largely held to date.

232  Information Security Management Handbook
Although much of the literature focuses on covert channels in software, the electronics of an 
information processing device may provide unintended communication paths that result in the leak-
age of sensitive data. A simple discrete circuit used to illuminate a status lamp, for example, might 
be manipulated to provide information to an unauthorized person through Morse code. It may also 
be possible to determine critical bits of information by examining power ﬂ uctuations, changes in 
temperature, or acoustic vibrations depending on the nature of the information processing device. 
Because the unintended communication paths were neither clearly designed nor intended to be 
information communication paths, when they exist, they qualify as covert channels.
Example of a Covert Channel
For this example, we deﬁ ne three domains of diﬀ ering sensitivity classiﬁ cations: Red, Green, and 
Blue. Red will be the most sensitive and act as a security gateway between Green and Blue. By 
security policy, no Green data should ever get to Blue. Th e Red process transforms Green data to 
Blue data (or blocks it entirely depending on security policy). Blue data may freely ﬂ ow through 
Red to Green, that is, the Green domain may read Blue domain data, but the Blue domain may 
never read Green domain data. With this simple example, we have a security policy and a design 
that makes any channel that can transfer Green domain data to the Blue domain a covert channel. 
Because the Red domain is eﬀ ectively a shared resource, we may have the potential for a process in 
the Blue domain to detect a performance impact by a process in the Green domain by its interac-
tion with the Red domain. Th is could allow a covert timing channel through Red manipulated 
by Green. Blue can easily establish a semaphore for synchronization because the security policy 
allows Blue to send to Green.
If Green can signal Red to set a condition that should prevent Red from processing something 
sent by Blue, then Green can establish a covert storage channel with Blue through which Blue 
continuously queries Red and checks for a response. Th is would be analogous to Green setting a 
ﬂ ag in storage, which Blue could check. Th e bandwidth or capacity of this covert channel would 
depend on machine speeds and the number of possible distinguishable states. However, even a 
simple binary, if it could be tested every 100 ms (a rather slow machine rate), would transfer 100 bps. 
If those were eight-character passwords, this would expose more than 90 passwords per minute. Or, 
if this were a banking system relying on cryptographic keys (e.g., two-key Triple-Data Encryption 
Standard, which would be 112 bits of key plus 16 bits of parity for a total of 128 bits), the key 
would be compromised in less than two seconds.
If Green, Red, and Blue shared a power supply, a display, or error-handling processes, addi-
tional covert channels may exist. As previously suggested, the criticality of the information poten-
tially released determines what may constitute a suﬃ  ciently stringent constraint on information 
leakage. If only the compromise of gigabytes of data is of concern, then a 100-bps covert channel 
might not warrant countermeasures. However, if national security, life safety, or billions of dol-
lars are at stake over the loss of a password or cryptographic key, then even 1 bps may demand 
remediation.
Overview of the Analysis Process
Before the investigators can identify covert channels, they must have an understanding of the 
overt, that is, intended or legal, channels and their associated information ﬂ ow security poli-
cies. Th ese channels may support a covert channel if an information ﬂ ow contrary to policy is 

Analysis of Covert Channels  233
possible. Otherwise, the investigator documents these for use later in the analysis. Next, the 
investigator documents all shared resources, including storage locations, devices, CPU, power 
supplies, and system resources (e.g., error routines, common libraries, and system calls). Th ese 
are all potential covert channels. Developing a matrix for this analysis is one practical approach 
(see Kemmerer, 2002).
Th e investigator must then determine whether each shared resource qualiﬁ es for further analy-
sis as a potential covert channel. Any of the following three situations would be documented, but 
would end the analysis for a candidate covert channel.
 
1. If another channel already exists between the processes that share the resource and if that 
channel is one that would permit the same communication without violating the informa-
tion ﬂ ow security policies (i.e., it is a legal or overt channel), then the potential covert channel 
is not of consequence. Th is may be determined by comparing the potentially illicit informa-
tion ﬂ ow with the ones previously documented as legal. Where a legal channel accomplishes 
the same result as the potentially illicit one, then the covert channel is discounted and no 
further analysis is needed for that channel.
 
2. If the potential covert channel cannot be controlled suﬃ  ciently to signal useful informa-
tion, than it is also of no consequence. For example, a state variable that is changed by the 
trusted computing base but does not identify the process that caused the change and can be 
changed by any arbitrary process may be useless as a signal to another process because it is 
too unreliable.
 
3. If the shared resource can signal to each process only information the respective process 
would already know, then it is, again, not worthy of further analysis. An example of this is a 
ﬁ le attribute that states who locked a ﬁ le. If it can be read only by the process that locked the 
ﬁ le—a process that already knows it did so—then no useful information via that attribute 
is sent.
Th e remaining candidates for covert channels require more detailed analysis. Although additional 
analysis techniques exist, including covert ﬂ ow trees (see Kemmerer and Porra, 1991) and nonin-
terference modeling (see Goguen and Meseguer, 1982), the ﬁ nal determination remains one based 
on the experience and skill of the investigator.
For each channel identiﬁ ed as a covert channel, an assessment of its bandwidth or capacity is 
needed. Th is information is important in determining the risk–beneﬁ t associated with making 
the changes necessary to eliminate or limit the eﬀ ectiveness of the covert channel. In many com-
mercial situations, a qualitative approach using “high, medium, and low” may prove suﬃ  cient. 
In more formal situations, quantitative measurements or mathematical modeling may be required 
(some of which we discussed earlier). Once the investigators have assessed the potential  capacity, 
they then need to identify any existing countermeasures that would further limit either the 
capacity or the utility of the covert channel. For example, an error condition discrete has the 
potential of sending one bit of information each time it is set and reset. If the processor can do this 
at machine speed, gigabits of information could ﬂ ow within minutes—an enormous  capacity. 
However, if a change in this register results in an interruption that shuts the system down, then 
the capacity is, at most, one bit. Documenting this is an important step in the  analysis of covert 
channels.
At the end of the analysis, the investigator will probably have covert channels for which addi-
tional remediation is warranted. Th e next section provides some insight into protecting against 
covert channels. Th e investigator has, however, not completed the work. At each stage in the devel-
opment or remediation process, additional analysis will be needed.

234  Information Security Management Handbook
Protecting against Covert Channels
Good architecture and design practices that clearly identify the intended security policies for the 
 system form the foundation for any countermeasures. Th e system designer can include speciﬁ c coun-
termeasures in the design, including the use of “fuzzy time” (see Hu), heuristic measure of  regularity 
(see Cabuk et al., 2004a, b), and formal information ﬂ ows. In addition, the developer can run tools 
against the formal design (or in some instances against the source code). Tools include the following:
 
1. Buﬀ er Overrun Detection (BOON) (refer to http://www.cs.berkeley.edu/∼daw/boon/)
 
2. Cqual (refer to http://www.cs.umd.edu/∼jfoster/cqual/)
 
3. Flawﬁ nder (open source; refer to http://www.dwheeler.com/ﬂ awﬁ nder/)
 
4. Modelchecking Programs for Security Properties (MOPS) (refer to http://www.cs.berkeley.
edu/∼daw/mops/)
 
5. Rough Auditing Tool for Security (RATS) (open source; refer to http://www.fortifysoftware.
com/security-resources/rats.jsp)
 
6. ITS4 (open source [but not supported]; refer to http://www.cigital.com/its4/)
 
7. Secure Programming Lint (SPLINT) (refer to http://www.splint.org/)
 
8. Stanford Checker (now known as “MC”) (refer to http://metacomp.stanford.edu/)
Although each tool can provide valuable assistance in identifying problems in the design or source 
code, each tool has its limitations. Using more than one increases the likelihood of discovering 
potential problems that could support covert channels. Even with the use of tools, formal analysis 
by a computer scientist or engineer with experience in covert channel analysis is recommended.
Steganography as a Special Case
Steganography, from the Greek meaning covered writing, covertly encodes a message in benign 
data. Steganographic techniques consist of altering bytes in predominantly lossy protocols, that is, 
protocols that use a compression technique that does not decompress data back to 100 percent of 
the original (e.g., AAC, JPEG, MP3, and Motion Picture Experts Group [MPEG]) and that does 
not lead to a perceivable change in data quality but does allow information to be embedded with-
out being identiﬁ ed. Although steganography has ancient roots, its widespread use in information 
processing is primarily a result of the Internet and laws against the transmission of pornographic 
materials. Th e information is encoded into a benign data stream or object and transmitted.  Persons 
with the proper decoding software can then retrieve the original materials.
Although modern researchers often include this special case in papers that discuss covert chan-
nel analysis (see, e.g., Van Horenbeeck), this illicit information ﬂ ow has not become a common 
component of traditional covert channel analysis. First, processes in systems that prevent higher-
sensitivity processes from writing to lower-sensitivity processes—a rather standard security policy 
in systems that process multiple levels of sensitive information—cannot exploit this, as the overt 
message from the higher-sensitivity category would not be transported to the lower-sensitivity 
category. Second, any otherwise covert channel that might subvert the security policy would have 
a higher capacity for illicit information ﬂ ows without recourse to steganography. Nonetheless, 
systems that rely on object labeling programmatically assigned by a process (as opposed to labels 
assigned by the trusted computing base) may need to address this threat. Th is situation exists 
when a higher-sensitivity process can label its outputs at lower levels of sensitivity either by design 
or by a process that does not conform to data labeling, for example, messages to a system operator 
and error or diagnostic messages.

Analysis of Covert Channels  235
Recommendations
Systems that use high-security components or warrant high-assurance application development 
should include an analysis of covert channels. Such an analysis should follow a formal process, 
for example, as described in NCSC-TG-30 or in A Foundation for Covert Channel Analysis (see 
References). Th e Common Criteria* requires a formal covert channel analysis only for Evaluation 
Assurance Level (EAL) 7—the highest level of assurance. However, as early as EAL 3, covert 
channels (aka “illicit information ﬂ ows”) must be addressed.
As systems become more complex and processing becomes faster, the potential for covert chan-
nels with dangerously high bandwidths increases. Although it may seem counterintuitive, improve-
ments in application and system security may increase the risk of covert channel exploitation. When 
a simple password hack gains access, a perpetrator need not invest in more sophisticated attacks. 
As security improves, the more easily exploited holes close. Covert channels are generally not easily 
exploited, but when other doors close, they may prove to be the window that remains open.
Further Readings
Fine, T. A Foundation for Covert Channel Analysis, Proceedings of the 15th National Computer Security 
Conference, 1992, pp. 204–212, Baltimore, Maryland.
Gligor, V. D., Millen, J. K., Goldston, J. K., and Muysenberg, J. A. A Guide to Understanding Covert 
 Channel Analysis of Trusted Systems (NCSC-TG-30), National Computer Security Center (NCSC), 
November 1993 (available at stinet.dtic.mil).
Gray, J. W., III. On Introducing Noise into the Bus-Contention Channel, Proceedings of the IEEE Sympo-
sium on Security and Privacy, 1993, pp. 90–98. Oakland: IEEE.
Haigh, J. T., Kemmerer, R. A., McHugh, J., and Young, D. W. An Experience Using Two Covert Channel 
Analysis Techniques on a Real System Design, Proceedings of the IEEE Symposium on Security and 
Privacy, 1986, pp. 14–24. Oakland: IEEE.
International Standard ISO/IEC 15408:2005—Th e Common Criteria for Information Technology Security 
Evaluation (available from www.niap-ccevs.org/cc-scheme/cc_docs/).
Karger, P. A., and Wray, J. C. Storage Channels in Disk Arm Optimization, Proceedings of the 1991 IEEE 
Computer Society Symposium on Research in Security and Privacy, 1991, pp. 52–61. Oakland: IEEE.
Kemmerer, R. A. Shared Resource Matrix Methodology: An Approach to Identifying Storage and 
Timing Channels, ACM Transactions on Computer Systems, Vol. 1, No. 3, August 1983, pp. 256–277, 
 Washington: ACM Press.
Levin T., Tao, A., and Padilla, S. J. Covert Storage Channel Analysis: A Worked Example, Proceedings of the 
13th National Computer Security Conference, 1990, pp. 10–19, Washington, D.C.
Melliar-Smith, P. M., and Moser, L. E. Protection against Covert Storage and Timing Channels, 1991, 
Proceedings of the 4th IEEE Computer Security Foundations Workshop—CSFW’91, Franconia, N H, 
June 18–20, 1991, pp. 209–214, IEEE Computer Society, 1991.
Millen, J. K. 20 Years of Covert Channel Modeling and Analysis, Proceedings of the 1999 IEEE Symposium 
on Security and Privacy, 1999, pp. 113–114. Oakland: IEEE.
Millen, J. K. Covert Channel Capacity, 1987 IEEE Symposium on Security and Privacy, 1987, sp, p. 60. 
Oakland: IEEE.
Minutes of the First Workshop on Covert Channel Analysis, Cipher, Newsletter of the Technical Commit-
tee on Security and Privacy, IEEE Computer Society, Special Issue, July 1990.
Moskowitz, I. S., and Miller, A. R. Th e Inﬂ uence of Delay upon an Idealized Channel’s Bandwidth, 
 Proceedings of the IEEE Symposium on Security and Privacy, 1992, pp. 62–67. Oakland: IEEE.
* ISO/IEC15408:1999.

236  Information Security Management Handbook
Moskowitz, I. S., and Miller, A. R. Simple Timing Channels, IEEE Symposium on Research in Security and 
Privacy, 1994, pp. 56–64. Oakland: IEEE.
National Computer Security Center, Department of Defense Trusted Computer System Evaluation Crite-
ria, DoD 5200.28-STD, December 1985.
Oblitey, W., Wolfe, J. L., and Ezekiel, S. Covert Channels: Th e State of the Practice. Department of Computer 
Science, Indiana University of Pennsylvania, Indiana, PA, August 24, 2005.
Proctor, N. E., and Neumann, P. G. Architectural Implications of Covert Channels, Proceedings of the 15th 
National Computer Security Conference, 1992, pp. 28–43.
Siponen, M. T., and Oinas-Kukkonen, H. A Review of Information Security Issues and Respective Research 
Contributions, Th e DATABASE for Advances in Information Systems, Vol. 38, No. 1, February 2007. 
Washington: ACM Press.
Tsai, C.-R., and Gligor, V. D. A Bandwidth Computation Model for Covert Storage Channels and 
its Applications, Proceedings of the IEEE Symposium on Security and Privacy, 1988, pp. 108–121. 
Oakland: IEEE.
Tsai, C.-R., Gligor, V. D., and Chandersekaran, C. S. A Formal Method for the Identiﬁ cation of Covert 
Storage Channels in Source Code, Proceedings of the IEEE Symposium on Security and Privacy, 1987, 
pp. 74–86. Oakland: IEEE.
Willcox, D. A., and Bunch, S. R. A Tool for Covert Storage Channel Analysis of the UNIX Kernel, Proceed-
ings of the 15th National Computer Security Conference, 1992, pp. 697–706, Baltimore, Maryland.
Wray, J. C. An Analysis of Covert Timing Channels, Proceedings of the 1991 IEEE Computer Society Sympo-
sium on Research in Security and Privacy, May 20–22, 1991, pp. 2–7. Oakland: IEEE.

237
Chapter 18
Security Architecture of 
Biological Cells: An Example 
of Defense in Depth*
Kenneth J. Knapp and R. Franklin Morris, Jr.
Contents
Four Analogies ........................................................................................................................ 238
Barrier Defense .............................................................................................................. 238
Barrier Transmission and Communication .................................................................... 240
Membrane Channels ............................................................................................ 240
Gap Junctions ........................................................................................................241
Cell-to-Cell Communications via the Extracellular Matrix ...................................241
Internal Organization .....................................................................................................241
Internal Routing and Communication .......................................................................... 242
Five Valuable Lessons from Cells ............................................................................................ 243
Summary ................................................................................................................................ 244
* Th e idea for this chapter came from a reading of Peter Checkland’s book, Systems Th inking, Systems Practice 
(Wiley, 1999). An academic version of this chapter with full references appeared in Communications of the 
Association for Information Systems, volume 12 (December 2003), titled, “Defense Mechanisms of Biological 
Cells: A Framework for Network Security Th inking,” by Knapp, Morris, Rainer, and Byrd. Opinions, conclu-
sions, and recommendations expressed or implied within are solely those of the authors and do not necessarily 
represent the views of the USAF Academy, Th e Citadel, the USAF, the Department of Defense, or any other 
government agency.

238  Information Security Management Handbook
Examining the similarities between biological cells and networked 
computer systems reveals valuable lessons for the security profes-
sional. In summary, the security approach in cells is consistent with 
the defense-in-depth notion that multiple techniques and layers 
help to mitigate the risk of one layer being compromised.
Today, networks are essential tools for business survival. Typically, the more employees use a 
network, the more valuable it becomes. Th e challenge is daunting: security must protect busi-
ness information while allowing for open communication and commerce. Looking to nature for 
security approaches can yield insights into how we can better meet this challenge. In this regard, 
biological cells oﬀ er a security strategy that is interesting and worth emulating.
After studying security mechanisms in cells, we found that security mechanisms are present in 
nearly every cell component. Cells follow a multilayered, defense-in-depth approach to security. In 
this chapter, we oﬀ er a framework that examines the similarities between cell security and network 
security. In today’s high-technology environment, in which security is increasingly important, this 
framework can help us by stimulating thinking about security while oﬀ ering a model about how 
to design secure systems.
Before we discuss the various analogies between cells and networks, we will brieﬂ y mention 
what biologists call “cell theory.” Understanding the basics of cell theory helps explain why cells 
are useful to study as a security framework. Th e premise of cell theory states that all living things 
are made up of cells—it is the fundamental unit of structure in all life. A single cell can be a 
complete organism in itself or cells can work together to become the building blocks of large 
multicellular organisms such as a human being. Although diﬀ erences exist between plant and 
animal cells or blood and skin cells, the similarities are substantial. Because cells are considered 
the fundamental structure of life, we argue that it is worth examining cells because they highlight 
important principles valuable to today’s security professional.
Figure 18.1 illustrates the fundamental architecture of a cell. For each identiﬁ ed cell compo-
nent in the ﬁ gure, we name an analogous computer network counterpart. In the following section, 
we will brieﬂ y examine the key aspects of this ﬁ gure while providing four analogies that highlight 
similarities between cells and networks. As a conclusion, we oﬀ er ﬁ ve valuable principles based on 
cell security that are useful to the information security professional.
Four Analogies
Table 18.1 provides a framework of the four analogies by comparing cell biology and computer 
networks. Th e left column lists a phrase that accurately describes the functions common to both. 
Th e center column provides the computer network term with the analogous cell biology term to 
the right. We discuss each analogy in the following paragraphs.
Barrier Defense
After studying cells, we quickly noticed just how essential perimeter defenses are to cell security. Th e 
ﬁ rst line of defense is the plasma membrane, which encloses and protects the cell. Th e  membrane 

Security Architecture of Biological Cells  239
Table 18.1 Computer Network and Biological Cell Comparison
Analogous Function
Computer Network Examples
Cell Biology Examples
Barrier defense
Exterior router
Firewall
Intrusion detection system (IDS)
Plasma membrane/cell wall 
oligosaccharides
Barrier transmission 
and communication
Tunneling protocols
Secure Sockets Layer (SSL)
Virtual private networks (VPNs)
Network ports
Variety of membrane channels
Gap junctions
Facilitated diffusion
Extracellular matrix signaling 
(e.g., receptors)
Internal organization
Internal ﬁ rewalls
Network demilitarized zone (DMZ)
Membrane-bound organelles
Nucleolus double-membrane 
envelope
Internal routing 
and communication
E-mail
Instant messaging
Routers
Internet Protocol version 6 (IPv6)
Routing tables
Endocytosis
Exocytosis
Golgi apparatus
Cell nucleus
Figure 18.1 Cell components and computer network counterparts.
Organelle membrane
(internal firewalls)
Vesicles (data storage)
Vacuoles (data storage)
Nucleus envelope (DMZ)
Nucleus (routing tables)
Endocytosis/Exocytosis
(IPv6, wrappers)
Gap junctions (VPN)
Golgi apparatus (router)
Plasma membrane (firewall)
Signal receptors (IDS)
Extracellular matrix (Internet)
Cytoplasm (Intranet)

240  Information Security Management Handbook
forms a selective barrier allowing nutrients to enter and waste products to leave. Th is membrane 
is the primary divider between the cell and its external environment. Some plant cells have a rigid 
cell wall in addition to the plasma membrane. For this chapter, however, we discuss cells in general 
without distinguishing between the diﬀ erent types of cells. In sum, cell membranes allow the entry 
of wanted elements while ﬁ ltering out unwanted elements.
In comparison, network perimeters include routers, IDSs, and ﬁ rewalls. Together, these 
devices demark an internal network from the public Internet. Like cell membranes, ﬁ rewalls ﬁ lter 
out unwanted data while permitting wanted data to enter. Furthermore, threat analogies exist 
between ﬁ rewalls and cell membranes. A transport channel that circumvents the cell membrane 
can endanger the cell just as an unauthorized modem or a faulty ﬁ rewall rule can endanger an 
entire network.
In general, membranes provide perimeter defense for the cell through three main functions: 
(1) mechanical protection and a chemically buﬀ ered environment, (2) a porous medium for the 
distribution of water and other small molecules, and (3) a storage site of regulatory molecules that 
sense the presence of pathogenic threats. Interestingly, devices such as a ﬁ rewall and IDS together 
provide similar functions: (1) electronic protection through a buﬀ ered environment, (2) a “porous” 
medium for the distribution of packets, and (3) a regulatory listing to detect the presence of elec-
tronic intrusions.
One of the more versatile cell barrier defenses involves oligosaccharins. Th ese fragments in the 
cell wall become active in an attack against the cell. Among their multiple roles, oligosaccharides 
perform an important signaling function that can initiate when a pathogen that threatens a cell 
is detected. An attack can then trigger an “oxidative burst” near the cell membrane that serves 
two functions relating to cell defense. First, this burst releases hydrogen peroxide, superoxide, and 
other active oxygen types that directly attack the pathogen in an attempt to destroy it. Second, the 
burst prompts a hardening of the cell membrane, making it harder for the pathogen to penetrate 
the membrane.
A desired quality of networks is an active defense against attacks rather than a passive, reac-
tive one. Th e multiple roles of oligosaccharides serve as a model of how cells provide an “active 
defense.” For example, the hardening of the cell membrane upon detection of a threat is like 
switching a ﬁ rewall’s rule base to a stricter conﬁ guration, thus making the ﬁ rewall more diﬃ  cult 
to penetrate under high threat conditions.
Barrier Transmission and Communication
Today, numerous cyber and privacy threats force businesses to use secure network communica-
tions. To meet this need, numerous services such as VPNs, SSL, and other tunneling protocols 
have emerged. Comparatively, cells have a very rich variety of specialized communication mecha-
nisms. Intriguingly, these mechanisms all inherently incorporate security. In this section, we limit 
our discussion to three such cell mechanisms: membrane channels, gap junctions, and communi-
cation via the extracellular matrix.
Membrane Channels
Firewalls and routers manage communications by opening and closing thousands of ports that 
allow or block data. At the biological level, a similar structure exists. Cells can communicate with 
other cells via electrical current ﬂ owing across the cell’s membrane. Th is current appears as bursts 

Security Architecture of Biological Cells  241
traveling through open channels, or holes, formed by proteins built into the membrane. If no hole 
is open, no signiﬁ cant current ﬂ ows.
Signals from external substances such as calcium wanting to enter the cell can cause the open-
ing of membrane channels. Like some network ﬁ rewalls that can restrict the passage of certain 
protocols, cell membrane channels permit passage of selected substances while denying others.
Gap Junctions
Th e cytoplasm is the material that ﬁ lls the inside of a cell between the plasma membrane and the 
membrane of the nucleus. In this sense, the cytoplasm is like an internal network within the cell. 
Connecting the cytoplasm between cells, channels called gap junctions allow the secure passage 
of molecules through the cell’s membrane. Gap junctions provide a secure tunnel to allow the pas-
sage of molecules and ions between cells. In essence, gap junctions are similar to VPNs that safely 
link outside users (or external organizations) to an organization’s internal network.
Cell-to-Cell Communications via the Extracellular Matrix
One way that cells communicate with other cells is by employing receptors that detect outside ele-
ments friendly to the cell. Receptors recognize foreign objects and then convey the message to the 
nucleus to induce a response. Receptors also have an important security function.
In multicellular organisms, communications that occur outside the cell do so in extracellular 
space, which consists of a gel material known as the extracellular matrix. Th e gel is composed of sugar 
molecules in a water-based solution ﬁ lled with salts, proteins, other nutrients, and waste products.
Receptors that are associated with the cell’s membrane provide communication links from 
the cell to this extracellular matrix. Th ese receptors interact with protein ﬁ bers that inﬂ uence cell 
behaviors, often leading to changes in cell shape, movement, and development.
In networks, an IDS protects a network from intrusions by ﬂ agging suspicious communica-
tions. Cells take a proactive approach to intrusion detection by deploying an array of diﬀ erent 
receptors that respond to extracellular signals in a type of signal detection system. Once detected 
by an associated receptor, an “approved” chemical signal triggers an event that changes a cell’s 
behavior. Depending on the type of cell with which it is communicating, a particular chemical 
signal can cause diﬀ erent cellular reactions. In one example, a receptor will trigger the opening of 
a membrane channel, allowing a ﬂ ow of ions into the cell, which can aﬀ ect the electrical properties 
of the cell’s membrane or cytoplasm.
Internal Organization
In recent years, some network devices have integrated ﬁ rewall functionality into their services. 
One example is a ﬁ rewall switch. In addition to these hybrid devices, organizations are making 
more frequent use of internal or application ﬁ rewalls for use inside an organization’s network. 
Internal ﬁ rewalls can electronically segment departmental networks within an organization. 
Th ey also can provide dedicated protection for high-value resources such as a ﬁ nancial data store. 
 Internal ﬁ rewalls not only provide a layer of protection from external cyber threats, but also can 
protect from internal threats.
Comparatively, cells are segmented into organelles. A dedicated protective membrane sur-
rounds these specialized compartments. Th e internal membranes act as an additional layer of 

242  Information Security Management Handbook
 cellular defense for the organelle. Each organelle membrane has its own distinct composition. Like 
the external plasma membrane, internal membranes contain barrier transmission mechanisms 
that facilitate communication between organelles.
Th e most prominent organelle, the nucleus, is a highly protected resource. A double- membrane 
envelope separated by a perinuclear space encloses the nucleus. Th e perinuclear space is like a  buﬀ er 
zone or network DMZ, which forms nuclear pores through which the nucleus and  cytoplasm 
communicate. Protein granules often guard these pores to help regulate the passage of small ions 
and larger macromolecules into the nucleus.
Other organelles called mitochondria are responsible for the energy transactions necessary 
for cell survival. Like the nucleus, mitochondria are a high-value resource and have a double 
 membrane. Other organelles include membrane-protected vacuoles, which are sacs within the cell 
that store food particles, water, and other substances. Vesicles are simply very small vacuoles.
Cells teach that security is a multilayered process. Whereas the plasma membrane provides the 
initial protection, the organelles provide their own protection with specialized membranes. Th e 
more valuable the organelle is to the cell, the more robust its membrane seems to be.
Similarly, based on the increased use of hybrid and internal ﬁ rewalls, it appears that net-
work security is beginning to resemble cell security. Th e defense-in-depth approach stipulates that 
security should be multilayered and that processes should penetrate deep into an organization. 
For example, defense in depth has been a key element of the U.S. Nuclear Commission’s safety 
philosophy. It employs a framework of successive and redundant measures to prevent accidents at 
nuclear facilities. Th is philosophy has served the nuclear power industry well and is being used as 
an eﬀ ective architectural model for securing industry cyber defenses. Defense in depth is receiving 
greater acceptance as a model for information technology security. It is also consistent with the 
multilayered approach of biological cells.
Internal Routing and Communication
Organizations today use a variety of communication systems such as e-mail, instant messaging, 
and Web conferencing. Cells too have what we can call communication systems. Endo- and exo-
cytosis is one such system. Th is “full service” system facilitates cell transport, communication, and 
routing between organelles. It is also inherently secure.
In the process of endocytosis, cells—and even some organelles—engulf material by forming 
an inward depression in their outer plasma membrane. Th e depression continues to bulge further 
into the cell’s cytoplasm until it ﬁ nally pinches oﬀ  as a vesicle. Later, a transport process called 
exocytosis discharges unwanted materials by performing endocytosis in reverse. Together, the 
endo- and exocytosis mechanisms serve as reliable security escorts. Th ey direct material to the 
place it needs to go within the cell while safely escorting waste out of the cell.
Some of the newer Internet standards appear to integrate security and routing like those found 
in endo- and exocytosis. Th e IPv6 adds values into a packet’s header ﬁ eld to help ensure security 
and privacy. IPv6 also requires the use of certain security protocols in the IP Security framework 
that enhance security at the packet level. Wrappers are another network technology with simi-
larities to endo- and exocytosis. Various wrappers exist, but generally, wrappers can be placed in 
front of or around a data transmission and can encapsulate it from view to anyone other than the 
intended recipient. Such technologies can make the Internet inherently more secure if its core 
functionality has security designed into it.
Like large networks, cells have an extensive routing system that moves macromolecules to 
their destination organelle. Th ese “routers” are systems devoted to keeping intracellular order 

Security Architecture of Biological Cells  243
by delivering newly synthesized macromolecules to their proper home. Th ese routers also have 
built-in security in that they are membrane-protected. Although not well understood, the Golgi 
apparatus is one such system. It handles many of these operations as the primary router of protein 
traﬃ  c in the cell.
Th e internal “routing tables” in a cell are contained in the nucleus. As the highly protected 
information hub of the cell, the nucleus provides details about the transportation of proteins into 
diﬀ erent compartments. It contains most of the cell’s genetic information and houses the DNA 
molecules, which contain the information a cell needs to retain its unique character.
Routing and sorting in cells is not unlike that in computer networks. Although developments 
such as IPv6 and hybrid ﬁ rewalls are improving security, the advanced level of encapsulated pro-
tection demonstrated in cell processes such as endo- and exocytosis serves as a model for network 
security. Beyond the scope of this chapter, a more detailed study of the advanced cell function of 
endo- and exocytosis may yield insight and ideas for improved network security.
Five Valuable Lessons from Cells
After a study of cell security, ﬁ ve principles emerged. Each of these represents a stratagem that is 
applicable to information security.
 
1. Seamless integration of communication and security functionality. Security functionality is 
highly integrated into cellular mechanisms. Th at is, security is not separate from the com-
munication mechanism, but is rather an integral part of the system itself. In general, we do 
not see dedicated security mechanisms or organelles in cells. For example, we do not see any 
single or dedicated cell organelle in charge of cell security. What we do see is security as a 
shared responsibility built directly into the various mechanisms and organelles. Examples 
include membrane channels and gap junctions, all of which are inherently secure communi-
cation mechanisms.
 
2. Proactive approach to membrane defense and crossing. Cells take a proactive approach to 
the passage of items through the outer cell membrane. Instead of taking the approach of 
identifying unwanted elements, which is a common IDS method, cells generally take the 
opposite approach. By focusing on the “friendly” chemical or electrical signals provided 
by a visitor at the outer membrane, cells provide an active defense. Hence, cells identify 
desired elements prior to allowing their passage through the external membrane. Undesired 
or unidentiﬁ ed elements are blocked.
 
3. High level of specialization of communication methods. Cells have a rich variety of highly 
specialized mechanisms for moving molecules through the outer membrane. Th ere seems to 
be a tailored communication mechanism for each type of molecule that a cell needs to cross 
its membrane. Th e cell perimeter is not a simple wall blocking out unwanted or dangerous 
elements. Instead, the cell perimeter works as a complex system containing numerous trans-
porters and channels, each designed to allow speciﬁ c molecules to pass.
 
4. Standard use of internal membrane protection for high-value resources. Cells make liberal 
use of internal membranes. Mitochondria, vacuoles, and the nucleus, for example, all have 
their own protective membrane—or multiple membranes—in addition to the cell’s outer 
membrane. Th e more important the organelle’s function, the more robust the internal mem-
brane seems to be.
 
5. Overall, security is integrated, ubiquitous, and continuous. Considering the full range of 
 mechanisms that inherently provide cellular security, we conclude that cells maintain a 

244  Information Security Management Handbook
high-security orientation. Defensive measures are present at the membrane, within organ-
elles,  during internal routing, and throughout the entire cell. In addition, the security 
 mechanisms of a cell are not intermittently active, but rather are continuously active, or 
always on. Overall, we recognize that cell security is integrated, ubiquitous, and  continuous. 
Th at is, in biological cells, security is a part of everything, security is everywhere, and 
 security is always functioning.
Th ese ﬁ ve principles also suggest general implications for network security design. Although such 
detailed recommendations are beyond the scope of this chapter, we trust that enough detail has been 
provided to gain a practical understanding of the general security architecture of biological cells and 
how such an understanding can potentially beneﬁ t thinking about network security design.
Summary
Th e analogies in this chapter suggest similarities between cellular functions that defend an 
 organism compared to network systems that defend an organization. In summary, the security 
approach in cells is consistent with the defense-in-depth notion that multiple techniques and 
layers help to mitigate the risk of one layer of defense being compromised. Although we just 
scratched the surface of the cell analogy, we hope this discussion stimulates one’s thinking about 
network security. Such thinking can generate ideas and insights, which, in turn, lead to security 
improvements.

245
Chapter 19
ISO Standards Draft Content
Scott Erkonen
Contents
Introduction .............................................................................................................................245
ISO 27001, ISO 27002, and the ISO 27000 Series ................................................................. 246
Th e 27000 Series of ISO Standards ......................................................................................... 249
Relationships to Other Standards ............................................................................................250
Why Do People Look to Implement an ISO 27001 ISMS? ......................................................251
How Does One Become Certiﬁ ed? ..........................................................................................251
What Is the Future? .................................................................................................................252
Introduction
Th e development of information security standards on an international level involves the Interna-
tional Organization for Standardization (ISO) and the International Electronics Consortium (IEC). 
Although other bodies provide sector-speciﬁ c standards, they are often derived from or refer to the 
“ISO” standards (commonly referred to as ISO/IEC). In the United States, this work is managed 
through the American National Standards Institute and the International Committee for Informa-
tion Technology Standards (INCITS). Th e group directly responsible for developing, contributing 
to, and managing this work is INCITS CS/1, cyber security. Th is group, CS/1, is also  responsible 
for standards work in the areas of information technology (IT) security, privacy, identity manage-
ment, and biometric security. One major area of focus for CS/1 involves the information security 
 standards known as ISO/IEC 27001: 2005 (information security–information security manage-
ment system (ISMS) requirements) and ISO/IEC 17799: 2005 (speciﬁ cation for information 
 security management). For the sake of keeping things simpliﬁ ed as much as possible, these will be 
referred to as “ISO 17799” and “ISO 27001,” respectively. It is also important to note that eﬀ ective 
April 2007, ISO 17799 has undergone a numbering change and is renumbered to ISO 27002.

246  Information Security Management Handbook
ISO 27001, ISO 27002, and the ISO 27000 Series
So what are these standards, and what are the diﬀ erences between them? ISO 27001 is the standard 
for ISMS. Most people are more familiar with ISO 17799 (now ISO 27002), which is the code of 
practice for information security. Although it may seem confusing at ﬁ rst, the relationship is not 
diﬃ  cult to understand. Many people confuse ISO 27001 and ISO 27002 with British Standard 
(BS) 7799, but although they are similar, they are not 100 percent equal. It is important to acknowl-
edge that much of the work in this area was initiated by, and developed from, BS 7799 prior to it 
being modiﬁ ed and approved as an ISO standard, ISO 17799. What we have today is the result of 
that initial work combined with the input and participation of multiple nations. Th is chapter is not 
designed to serve as implementation guidance, but to educate you on the topic of ISMS, speciﬁ cally 
as it pertains to ISO 27001. Implementation guidance is best left where it belongs, in ISO 27003.
ISO/IEC 27001 is the international standard that provides requirements for the creation, struc-
ture, and management of an ISMS. It contains ﬁ ve major areas, often referred to as “Sections 4 
through 8.” Th ese areas are ISMS, management responsibility, internal ISMS audits, management 
review of the ISMS, and ISMS improvement. Th ese four sections are what allow an organization 
to create a program structure, or ISMS. Most information security practitioners are familiar with 
or have heard of ISO 9001, which deals with quality management systems. Th ink of ISO 27001 
as having similar structure, but dealing with this in the context of information security. One way 
to visualize this is as an umbrella. ISO 27001 provides the top layer deﬁ ning how you document, 
organize, empower, audit, manage, and improve your information security program. In other 
words, an ISMS is an organization’s structure for managing its people, processes, and technology. 
Th is chapter will provide you with information about the standards, but will not go into line-by-
line descriptions or list the control objectives. It is highly recommended, if you are considering 
going down this path or would like to learn more, that you pick up a copy of the ISO standards.
ISO/IEC 17799 provides the control objectives, along with the legal, regulatory, or business require-
ments, that are relevant to an information security practitioner’s organization. Th ere are ten  diﬀ erent 
areas that are covered in ISO 17799. Th ese should look familiar as you are reading this book:
 
1. Security policy
 
2. Security organization
 
3. Asset classiﬁ cation and control
 
4. Personnel security
 
5. Physical and environmental security
 
6. Communications and operations management
 
7. Access control
 
8. Systems development and maintenance
 
9. Business continuity management
 10. Compliance
Together with an organization’s legal, regulatory, and business requirements, these control objec-
tives provide the foundation of an ISO 27001 ISMS. Examine Annex A of ISO 27001, and you 
will notice that the control objectives in ISO 17799 are replicated there. When a security manager 
or practitioner wants to certify his or her organization’s program as conforming to ISO 17799, 
it is actually done through certifying against the criteria deﬁ ned in ISO 27001. Th is could seem 
confusing, but understand that the objective is to prove implementation of applicable controls 
from ISO 17799 (also Annex A of ISO 27001), and the ISMS developed from ISO 27001 (general 
requirements) provides the method by which this is accomplished.

ISO Standards Draft Content  247
So what are the requirements of ISO 27001? Sections 4 through 8 are often referred to as 
“general requirements.”
Section 4 covers the requirements for development, implementation, management, and 
improvement of an ISMS. One of the ﬁ rst steps in the development of an ISMS is to deﬁ ne the 
scope. Th is scope can be based upon physical location, function, organizational culture, envi-
ronment, or logical boundaries. Many organizations use physical or logical boundaries to sim-
plify things. A scope includes physical, technical, information, and program elements and human 
assets. We will go a little deeper than normal regarding the concept of scoping, as it is a critical 
concept in information security and audit.
When you are developing an information security program based on ISO 27001, without 
the goal of certiﬁ cation, your scope would be where you have determined that your information 
security program is applicable. For example, you may work for a company with multiple divi-
sions. Your scope may include the division that you are responsible for, but not the others or the 
overlying corporate structure. Th ink of scope in terms of span of control, which is critical for any 
program to be successful. You may choose to leverage building a program based upon ISO 27001 
to expand span of control to drive consistency or manage risk.
If creating a scope for certiﬁ cation purposes, there are several important things to consider.
 
1. What is the value of the contents of the domain deﬁ ned by the scope of the organization?
 
2. Do you have span of control over the domain?
 
3. What roles and responsibilities are performed by the people associated with the domain?
 
4. What are the logical or physical boundaries that can be used to deﬁ ne the domain?
 
5. What exceptions exist?
 
6. Is the desired scope reasonable for a certiﬁ cation eﬀ ort?
When determining the value of the contents, there are many formulas that are available for you 
to use. Some are based on tangible values such as the dollar value of equipment. Others are based 
upon risk or business impact (potential for major disruption to the business caused by lack of 
availability, etc.). Oftentimes, a combination of these approaches proves to be the most successful. 
Th is chapter does not go into risk-management approaches, but will discuss the ISO risk require-
ments later.
Span of control is a critical concept in regard to successful scoping. You need to analyze what 
you have direct control over, can inﬂ uence, or have no say in. Certiﬁ cation scopes typically deal 
with these areas of no control or limited inﬂ uence through service-level agreements, memoran-
dums of understanding, responsibility documents, or other methods. Trying to create a scope with 
little or no span of control may not be a wise idea and may end in the frustration of an ineﬀ ective 
program or failed certiﬁ cation attempt.
Roles and responsibilities exist within the scope and should be deﬁ ned and understood so as 
to eliminate overlap and duplication. Responsibility for the management of the ISMS needs to be 
deﬁ ned as well as the responsibility for those activities that make up the day-to-day operations of 
the system. A great way to keep all this information straight is through the use of RACI diagrams 
(in which tasks are split into four types of roles: Responsible, Accountable, Consulted, Informed), 
or responsibility matrices.
Physical and logical boundaries can be used to help deﬁ ne where a scope exists and can also 
help clarify span of control. Th ese boundaries can be walls, ﬂ oors, fences, etc., for the physical and 
virtual local area networks, segments, or even ﬁ ltered ports for the logical boundaries. Th is is par-
ticularly valuable when preparing a scope for a data center, for example. Ingress and egress points, 
both physical and logical, can be identiﬁ ed and should be examined and documented.

248  Information Security Management Handbook
Another important step in creating a scope is documenting exceptions. Exceptions are 
 anything that is not applicable from the control objectives in Annex A. Th e requirements in 
Sections 4 through 8 are just that, required. You cannot document exceptions to those areas. 
One way to handle this is to create a list as you go or utilize a process that keeps these exceptions 
organized. You may need to defend your rationale for exceptions during an audit.
OK, so we have covered most of the items to be considered (granted, at a high level) when creat-
ing a scope. Th e most important question that needs to be answered is the last question that was 
asked earlier. Is the scope reasonable for attempting a certiﬁ cation audit? Many organizations, when 
ﬁ rst deciding whether to go down this road, choose to certify an entire organization (often referred to 
by consultants as “boiling the ocean”). Although this may be successful in smaller organizations with 
strong span of control, it may not be reasonable for most. Experience has shown that successful certi-
ﬁ cation is based upon a program that is designed and implemented enterprisewide, but in which cer-
tiﬁ cation speciﬁ cs are applied to the assets that are of the highest value to the organization. What you 
end up with is a situation in which the organization is able to beneﬁ t from the information security 
program that you developed (your ISMS) and from a certiﬁ cation that is internationally recognized 
and applied to your highest-value assets or services. My advice to you would be not to try to boil 
the ocean, but to look at a certiﬁ cation scope that makes sense for you. Are you a service provider? 
Consider certifying the portions of your organization that provide those services for your custom-
ers. Are you a ﬁ nancial institution? Consider certifying the services or centers where your customer 
information is stored, used, and retained. If you have a desire for enterprisewide certiﬁ cation, break 
your eﬀ orts up into manageable domains and apply the same scoping process to those domains.
Getting back to the rest of this section, deﬁ ning an ISMS policy is just what it sounds like, 
writing a policy. Policy templates are popular starting points, but beware trying to use a canned 
document if you are going for certiﬁ cation or trying to build a truly eﬀ ective program. Any good 
policy should be well thought out and be exactly that—a policy. Too often people put components 
of speciﬁ cations (i.e., 128-bit encryption minimums) into policy. Th is prevents you from exercis-
ing span of control. Who wants to go to the board of directors every time you need to update a 
technical setting? Th e best advice to give here is to make sure that your “policy” ﬁ ts the culture 
and environment of your organization. Take the time to be sure that you are not setting yourself 
up for failure by creating an unrealistic policy that you cannot live up to.
Risk management means diﬀ erent things to diﬀ erent people, but anyone should like the ﬂ exibil-
ity and business-friendly approach that the ISO standards take. If you are looking for a “how to” doc-
ument, you will be disappointed. From the ISO standard perspective, they are more concerned that 
you have an organizational approach to risk, criteria or thresholds, and a repeatable methodology.
Informative references (optional, informational) exist that are directly applicable. Two of them 
are the following:
ISO/IEC 27005 Information Technology—Security Techniques—Information Security Risk 
Management.
ISO/IEC TR 13335-3, Information Technology—Guidelines for the Management of IT 
 Security—Techniques for the Management of IT Security.
I strongly recommend using these documents as resources. At the end of performing a solid risk 
assessment, you should have a very good idea where your risks exist, what controls are there, and 
what your residual risk is. Remember, acceptance or transference are also approved methods for 
dealing with risk.
Monitoring and reviewing the ISMS—these requirements ensure that you are actively “man-
aging” the ISMS. You not only have to understand what you have, but you need to be reviewing 



ISO Standards Draft Content  249
for errors or security events, reviewing eﬀ ectiveness, and checking to see if you are still on track 
with your objectives. Time should be spent on looking forward to improve the ISMS, while mak-
ing sure that any identiﬁ ed problems or observations are acted upon.
Documents and records need to be maintained, as the remainder of the Section 4 requirements 
discuss. For this, certain types of documents and document control requirements are outlined. 
Keep all the applicable documentation in an environment that is easy to access and work with and 
that maintains the integrity of this information. Oftentimes, people have a content management 
system, portal, or Web server that can serve this purpose. However, there is no requirement that 
says these records need to be electronic. Pay attention to Section 4.3.1 if you are going for certiﬁ ca-
tion, as you will need to have those items on hand and ready for the auditors. Th ese are the core 
categories of the actual documents that make up an ISMS.
Section 5 is the area of the ISMS requirements that talks about management involvement and 
responsibility. Th e support of management is critical to any program, not just an ISMS. Proof of 
this commitment comes in many ways, including documented responsibilities, approval of policy, 
funding, and active involvement with the appropriate levels of ISMS activities. Other examples of 
management’s commitment are the hiring, training, and empowerment of staﬀ .
Internal audits are another required function, and the requirements are described in Section 6. 
Internal audit is the function that reviews whether your ISMS is meeting your requirements and 
functioning properly. What is covered here is what you would expect regarding audit considerations, 
including scheduling, performance, and remediation requirements. Internal audit is an important 
process, as it allows for identiﬁ cation and resolution of issues between registrar audit cycles. If you ﬁ nd 
a problem, you can ﬁ x it—but be aware that major problems or “nonconformities” must be reported.
Management review is the subject of Section 7. Th is section correlates directly with the PDCA 
(Plan, Do, Check, Act) model, which is a foundation for all the ISO ISMS standards. Here, you 
review your actions, changes in the environment, and measurements among other things. Th ere 
are two parts, one that deals with “inputs” and one that deals with “outputs.” Th e “outputs” 
 portion helps you document your actions, considerations, and outcomes. Th ese types of records 
are important to show the active management of the ISMS.
Th e last section, Section 8, deals with ISMS improvement. Th is is often compared to con-
tinuous process improvement, which, in eﬀ ect, it is. Section 8 can be simpliﬁ ed in the following 
 manner: “corrective” actions, which focus on problems that have been identiﬁ ed, and “preventa-
tive” actions taken to avoid negative events and impacts. Oftentimes, these preventative actions 
are the result of a review of corrective actions.
Th at should give you a basic understanding of what is covered in the general requirements of 
ISO 27001. As you can see, there are various other standards and documents that work together 
to make an ISMS eﬀ ective.
The 27000 Series of ISO Standards
Currently under development are various other documents in the 27000 series. Th e main purpose 
of these developing standards is to support organizations in their eﬀ orts to implement an ISMS 
based on ISO 27001.
ISO 27000 is a standard designed to educate and inform people of what the 27000 series of 
documents is and how they interrelate. It will also contain vocabulary and concepts that are 
not speciﬁ cally contained in the other 27000 series of documents.


250  Information Security Management Handbook
ISO 27002 (eﬀ ective April 2007) is what is currently known as ISO 17799.
ISO 27003 is implementation guidance for ISO 27001, focusing on the general require-
ments (Sections 4 through 8).
ISO 27004 deals with how to gather measurements and metrics from an ISMS.
ISO 27005 covers risk management in regard to ISO 27001 and ISMS.
ISO 27006 deals with the requirements for accreditation bodies (the people who actually 
perform the registration audits).
Additional standards in the 27000 series will be added as needed, in support of the overall ISMS 
standards.
Figure 19.1 explains the relationships and functions of these standards.
Relationships to Other Standards
Although these standards focus on information security, they do not exist in a vacuum. Th ere are 
various other standards, such as ISO 20000 (IT service management) that complement and inter-
face with ISO 27001 and ISO 17799. Consider ISO 20000 as the mechanism to deal with the IT 
infrastructure and ISO 27001 as the mechanism to deal with the information security program 
and requirements. IT service management can help organizations deﬁ ne how to deal with areas 





Enterprise management
Program elements
Empowerment and authorization 
Program services
Program standards
Plans
Processes
Controls
Figure 19.1 Information security management reference model.

ISO Standards Draft Content  251
such as change management and release management, which are both important from an infor-
mation security standpoint as well.
Security managers often ask how standards such as COBIT (Control Objectives for Information 
and related Technology) and the National Institute of Standards and Technology standards relate to 
ISO standards. Although ISO 27001 will not direct someone to block a certain port on a ﬁ rewall, 
it will require an understanding of the risk environment and the application of what is determined 
to be an appropriate control—that is, blocking that port. Th e important thing to understand is 
that where other standards are more operational, ISO standards deal with the issues of how secu-
rity managers actually manage information security. Th is assists at a tactical and strategic level, 
while forming the processes for “informed decision,” which impacts the operational level. Th ese 
operational requirements are derived from legal, regulatory, or business requirements. When these 
elements are combined correctly, the result is a comprehensive information security program.
Why Do People Look to Implement an ISO 27001 ISMS?
Th ere are many reasons information security practitioners and organizations are looking to imple-
ment or have implemented ISO 27001 ISMS. Th ese reasons include looking for a way to provide 
proof of activities, due care, due diligence, and regulatory compliance. An ISO 27001 ISMS 
clearly meets the rigors of the Sarbanes-Oxley Act and other similar legislation in the United 
States or worldwide through the process of identifying and meeting requirements. Others see this 
as a road map into the future, understanding where future requirements may be met more easily 
by having a proven, ﬂ exible structure in place. Clear demonstration of industry leadership drives 
some, such as Fujitsu,  PREMIER Bankcard, and the Federal Reserve Bank of New York, who 
were among the ﬁ rst worldwide to certify to ISO 27001 when it was published in November of 
2005. Various  organizations have leveraged ISMS eﬀ orts to accelerate maturity in their organiza-
tion while maintaining ﬂ exibility.
One diﬀ erentiator with the ISO 27001 standard is that it is risk based and, therefore, “business 
friendly.” Security managers get to choose which control objectives apply to them based on their 
risk, legal, regulatory, and business requirements. Th ere are many additional beneﬁ ts that have 
been experienced ﬁ rsthand, but to list them all here would be too lengthy.
How Does One Become Certiﬁ ed?
One potential advantage of building an information security program based on ISO 27001 is that 
you can achieve certiﬁ cation. Although there are many industry- or technology-speciﬁ c certiﬁ ca-
tion schemes, none oﬀ er the level of international recognition that the ISO ISMS  certiﬁ cation 
does. Th e actual certiﬁ cation audit is performed by an accredited registrar, working with a cer-
tiﬁ cation body (CB). Several of the best-known registrars include British Standards Institution 
(BSI) and Bureau Veritas Certiﬁ cation (BVQI), but recently American-based companies such 
as SRI Quality System Registrar and Cotecna are now beginning to oﬀ er services in this area. 
Globally, there are many CBs (also known as accreditation services). Several have been very active 
in ISMS activities. Th e best known of these is the United Kingdom Accreditation Service. In 
America, the American National Accreditation Body has expanded its existing quality manage-
ment systems oﬀ erings to include ISO 27001. Th is is an important step toward increased adop-
tion of the ISO standards in the United States. If someone is looking to become certiﬁ ed, or is 

252  Information Security Management Handbook
interested, a  program analysis is a good way to start. Th ese can either be performed internally 
or with the help of an experienced partner. Following this, you should be able to have a good 
feel for where you sit, and what it will take to achieve your goal. Even if you are not interested 
in certiﬁ cation, the ISO standards provide a sound, accepted measuring stick against which you 
can examine your  information security program. One last word of assistance to those who seek 
certiﬁ cation—train and educate those involved with the process. Th ere are lead auditor and 
implementer courses available that should be considered. Th ese can shorten your learning curve 
and bring better results in the long run.
What Is the Future?
Th e use of the ISO standards continues to grow in the United States. Many private and pub-
lic sector organizations have information security programs built on components of ISO 17799. 
Although there were under 25 organizations certiﬁ ed to BS 7799 (in the United States), this num-
ber has already nearly doubled since the publication of ISO 27001. As awareness of the standards 
and the beneﬁ ts of implementing ISMS continues to grow, it is estimated that the United States 
will begin to surpass many countries and become more on the level of the United Kingdom, Japan, 
and India, countries with registrations numbering in the hundreds. Security managers should 
take the time to explore ISO 27001 and the ISO 27000 series as important tools that can help 
strengthen their ability to manage information security.

253
Chapter 20
Security Frameworks
Robert M. Slade
Contents
Introduction ............................................................................................................................ 254
General Types and Diﬀ erences ...................................................................................... 254
Governance............................................................................................................255
Checklist ...............................................................................................................255
Risk Management and Assessment ........................................................................257
Audit and Assurance ..............................................................................................257
Taxonomy .......................................................................................................................257
Weaknesses .....................................................................................................................258
Content Limitations ..............................................................................................258
Deﬁ ne Secure ........................................................................................................258
Description of Frameworks ......................................................................................................258
BS 7799 and ISO 27000 Family .....................................................................................259
BS 7799-1, ISO 17799, and ISO 27002 ................................................................259
BS 7799-2 and ISO 27001.....................................................................................259
ISO 27000 ............................................................................................................ 260
Control Objectives for Information and Related Technology ........................................ 260
Common Criteria ...........................................................................................................261
Federal Information Systems Management Act ...............................................................261
Information Security Forum .......................................................................................... 262
Information Technology Infrastructure Library ............................................................. 263
Management Frameworks .............................................................................................. 263
Zachman Framework............................................................................................ 263
Calder–Moir IT Governance Framework ............................................................. 263
Balanced Scorecard ................................................................................................265

254  Information Security Management Handbook
National Institute of Standards and Technology .............................................................265
800-26 .................................................................................................................. 266
Operationally Critical Th reat, Asset, and Vulnerability Evaluation................................ 266
Securities and Financial Industry Frameworks ............................................................... 266
Basel II ................................................................................................................. 266
Committee of Sponsoring Organizations of the Treadway Commission ............... 267
Sarbanes–Oxley Law ............................................................................................ 267
Security Governance ...................................................................................................... 267
Systems Security Engineering-Capability Maturity Model ............................................ 268
Summary ................................................................................................................................ 269
Introduction
Th e term “security framework” has been used in a variety of ways in the security literature over the 
years, but in 2006 it came to be used as an aggregate term for various documents (and some pieces 
of software), from a variety of sources, that give advice on topics related to information systems 
security, with particular regard to the planning, managing, or auditing of overall information 
security practices for a given institution.
Some of these texts are guidelines speciﬁ cally addressed toward information security such as 
British Standard (BS) 7799 and its descendants, particularly the International Standards Organi-
zation (ISO) 27000 family of standards. In this category are also items such as the (free, regarding 
both charge and access) “self-assessment questionnaire” prepared by the U.S. National Institute 
of Standards and Technology (NIST) (identiﬁ ed among their publications as 800-26). Th ere have 
been a number of projects that attempted to produce similar sets of standards or practice lists, such 
as the now-moribund Commonly Accepted Security Practices and Recommendations and two 
versions of Generally Accepted System Security Principles: these listed undertakings have been 
amalgamated into Generally Accepted Information Security Principles. Other frameworks are 
peripherally related, but have come to be seen as having a bearing on system security. Probably the 
most widely known are the auditing standards and outlines such as Control Objectives for Infor-
mation and Related Technology (COBIT) and the variety of supporting documents and processes 
that have grown up around the U.S. Federal Information Systems Management Act (FISMA). 
Others are more distantly associated, such as the Common Criteria (CC) on speciﬁ cations and 
evaluation. Still others are even more tenuously connected, such as the advice on fraudulent ﬁ nan-
cial reporting from the Committee of Sponsoring Organizations of the Treadway Commission 
(COSO). (Th e various ﬁ nancial instructions are generally concerned with the accuracy and reli-
ability of reported earnings and the ﬁ nancial health of a company: this is felt to have implications 
for the management and controls on information systems, which are the primary source of all 
corporate data, including that related to ﬁ nance.)
General Types and Differences
As can be seen, security frameworks come from a variety of sources and are intended to address a 
number of diﬀ erent ends. How relevant a speciﬁ c framework will be to your operations and situa-
tion will partly depend upon the aim and objective of the framework.
Th is is not to say that a speciﬁ c framework may not have relevance to your enterprise. All frame-
works will give you diﬀ erent pieces of information about your systems, and all information can be 

Security Frameworks  255
valuable. In some cases, the initial intent of the framework may be irrelevant. For example, most of 
the ﬁ nancial frameworks and instructions are expected to address the issue of fraudulent reporting 
of the ﬁ nancial status of the company. To this end, they generally concentrate on requiring the 
disclosure of the availability of internal controls within the company. Internal controls are part 
and parcel of information system security, and so these frameworks can provide useful guidance, 
although their original purpose is outside the information security (InfoSec) realm. (It is rather 
ironic to note that if corporate oﬃ  cers are willing to lie about their ﬁ nances, they would probably 
have no compunction in regard to lying about the state of internal controls. Th erefore, ﬁ nancial 
frameworks may have more relevance to information security than to their original aim.)
Nevertheless, there are certain characteristics that tend to be consistent across frameworks 
from similar backgrounds.
Governance
Th ere is frequent confusion in regard to the term governance and what diﬀ erentiates it from 
management. Some note that management might be said to increase direct performance, 
whereas governance may, through analysis, redirect activities to greater eﬀ ect. (In a sense this 
only moves the question back one level: this simply seems to be the distinction between strate-
gic and operational management.) Some texts also note that ﬁ ve basic classes of decisions must 
be made in information technology (IT), over principles, architecture, infrastructure, business 
application needs, and the prioritizing of investment, and that these constitute the areas of 
governance.
Again, this outline does not get us much closer to a useful or functional deﬁ nition.  Architecture, 
to take a closer look at one aspect, is stated to be a level of abstraction above design, but this deﬁ ni-
tion is not very helpful. A more functional description may be that architecture involves integra-
tion and standardization, but even this does not give us an awful lot of help in deciding what an 
IT architecture is, nor what the governance of it may be.
Security frameworks that stress “governance” tend to a management and overview perspective. 
Frequently they provide only a very generic structure for examining the macro levels of a very large 
enterprise, leaving the details to be dealt with elsewhere. Such tools are valuable for ensuring that 
security is assessed in a holistic manner, and that large areas are not missed in the pursuit of small 
details, but they will not be of much use to those who need to start on the securing of particular 
systems.
Breakdown Framework
A number of the governance-related security frameworks are primarily sets of divisions of activi-
ties and functions. Th ese types of security frameworks are, in fact, the most likely to use the 
word “framework” in the title or description of the process. Th e entities provide structures 
that provide for the breaking down of the overall organization and operations of an institu-
tion into smaller areas that may aid in the analysis of speciﬁ c risks, security requirements, and 
weaknesses.
Checklist
A signiﬁ cant number of security frameworks are presented in checklist form. Th is preference for 
the checklist format is hardly surprising: security is not a single function, but a compilation of a 

256  Information Security Management Handbook
number of functions. Indeed, it is frequently pointed out that tremendous expenditures on secu-
rity may be entirely obviated by the lack of a single control, and, therefore, a checklist of functions 
to be covered makes a great deal of sense.
Checklists, however, can vary in both content and intent. One checklist may be based on 
functional security, another may deal with audit and assurance mechanisms, whereas yet a third 
proceeds from an examination of business functions. Th e level of detail can also ﬂ uctuate from 
framework to framework.
When using checklist-type frameworks it is probably best to use more than one and to choose 
complementary documents that approach security from diﬀ erent perspectives. Th e use of multiple 
resources is probably more important with checklist frameworks than with other types, because 
there would be a psychological expectation of being “ﬁ nished” once one had completed such a list.
Controls
Most security workers would probably see checklists in terms of lists of controls, but few formal 
security frameworks deal with speciﬁ c controls. A great number of security frameworks, particu-
larly those from the ﬁ nancial industry, stress “internal controls.” Th is term is basically identical 
to the meaning of controls in security: it simply refers to the controls that a company imple-
ments on its own, rather than those that are required from external sources such as legislation or 
regulations.
Controls may be administrative, physical, or technical/logical. In planning for and consider-
ing the types of controls that we have, their eﬀ ectiveness, and new ones we may need, it may be 
helpful to categorize controls into these diﬀ erent types, developed from the normal divisions of 
responsibility in business: management, physical plant, and operations. We divide controls into 
other classes as well. Corrective controls are applied when others have failed, directive controls 
provide guidance, deterrent controls use social pressures to reduce threats from human attackers, 
detective controls determine that a breach has taken place, preventive controls reduce our vulner-
ability to threats, recovery controls assist us to resume operations after an incident, and compen-
sating controls provide coverage where others have been insuﬃ  cient. Th is partition of security 
actions has its roots in military and law enforcement studies.
Th e ﬁ ner the grading and codifying of controls that we can do, the better our analysis of our 
total security posture, and the two classiﬁ cations are orthogonal. Th erefore, the two divisions can 
be used as the basis for a matrix of controls, which can be used to assess the completeness of pro-
tection for a given system. Details of the process may be found in volume 3 of the ﬁ fth edition of 
Information Security Management Handbook (pp. 179–182).
For any given system, a wide variety of controls can be used. Indeed, a conglomeration of safe-
guards may be needed for a single process or structure. At some point it may become diﬃ  cult to 
see the forest for the trees: having established a number of countermeasures, the practitioner may 
wonder at the necessity for ensuring against further vulnerabilities.
Th ere are, of course, a number of tools for establishing the completeness of a risk management 
strategy, primarily involved with identifying speciﬁ c risks, threats, or vulnerabilities. Th e controls 
matrix oﬀ ers a slightly diﬀ erent kind of assessment of overall protections, noting broad classes of 
coverage and potential blind spots. Th e controls matrix is, therefore, a kind of breakdown frame-
work (as noted earlier) directed at controls themselves.

Security Frameworks  257
Risk Management and Assessment
Th ere are numerous products, procedures, outlines, and systems dedicated to the assessment, anal-
ysis, and management of risks. Th ese tend to fall into three categories: those speciﬁ c to informa-
tion systems and security, those dealing with general business risk, and those from the ﬁ nancial 
(and particularly banking) community. Systems for information security and business risks tend 
to be similar in structure and general outline, with some minor variations in terms of speciﬁ cs to 
be addressed. Th e banking world looks at risk management in a very diﬀ erent way: there is a great 
emphasis on the single issue of solvency and capital reserves, with everything else (pretty much 
what information systems and business people would know as the entire ﬁ eld of risk management) 
being relegated to a separate category of operational risk.
Risk management frameworks are very much process-oriented. Structures of committees, 
information gathering, and documentation are major aspects of these entities. If you are aware of 
deﬁ ciencies in regard to management structures and reporting in your own security environment, 
using a risk management framework will likely be of beneﬁ t.
Audit and Assurance
A signiﬁ cant number of frameworks are concerned with audit measures. Th ese documents stress 
points that can be measured and demonstrated and may have little to do with the actual security 
environment or situation. Most of the emphasis in these frameworks is on what can be proven 
to others or documented. It is always a good idea to pay attention to what can be measured and 
documented. It is very easy to say that you know you are secure but just have not bothered to write 
it down. If you cannot document it, you really do not have a good idea of your situation.
At the same time, be careful of systems that require a lot of documentation that may not be 
relevant to your situation. You may commit a lot of resources to proving rather than doing. Th is 
is currently the situation with the Sarbanes–Oxley law in the United States: a number of smaller 
companies are noting that the cost of documenting internal controls is draining budgets for secu-
rity operations.
Taxonomy
It would be handy to have a taxonomy of diﬀ erent types of security frameworks. Unfortunately, 
despite the proliferation of frameworks documents, there are so many diﬀ erent approaches and 
categories that it is questionable how useful such an exercise would be. In attempting to struc-
ture this chapter, and the list of frameworks to be covered, I attempted a structure of security, 
management, and ﬁ nancial orientation, as well as divisions along the lines of the characteris-
tics noted earlier. Th ere were, unfortunately, still a number of exceptions that did not ﬁ t well 
under any category, and the categories tended to group frameworks together in artiﬁ cial ways. 
(I ﬁ nally decided just to list the frameworks in alphabetical order and even that did not work 
too well.)
In a sense, this points out the value that using a variety of frameworks can have for you. Th ere 
are a great many diﬀ erent viewpoints and perspectives, and the more positions you bring to a 
security plan, the better the result will be.

258  Information Security Management Handbook
Weaknesses
Unfortunately, although security frameworks can provide some help and value, all of them do 
have weaknesses, and the weaknesses tend to be the same across all the systems and processes.
Content Limitations
One weakness that is very common across all the security frameworks is a narrow focus on a particular 
area, topic, or approach. Security should be a holistic practice, with input from a variety of ﬁ elds and a 
wide-ranging overview of the problem, as well as details suitable to the situation or environment. Some 
frameworks focus on the details and do not care about an overview. Some take a management view 
and neglect the speciﬁ cs. Some focus on functional security, others on the assurance mechanisms. 
Everyone has a ﬁ eld of expertise, and that is emphasized to the exclusion of some other aspects.
Deﬁ ne Secure
As Eugene Spaﬀ ord has famously said, a secure system is one that does what it is supposed to. 
Th erefore, it is impossible to deﬁ ne a state of security that is applicable to all computers, because 
not all computers are, in the minds of the users, supposed to do the same thing. In fact, secu-
rity conﬂ icts with itself. Factors promoting availability generally work against conﬁ dentiality. 
 Controls enhancing conﬁ dentiality do not always support integrity. If we want to take the time to 
ensure that we can conﬁ rm integrity, that delays availability.
It should, therefore, come as no surprise that one size does not ﬁ t all when it comes to security. 
It is inherently impossible to create a checklist of items that, when implemented, will guarantee 
“security.”
Best Practice
In the security ﬁ eld and industry, we are extremely fond of the term “best practice.” It sounds quite 
reasonable: it does not imply that something is perfect, but it does support the idea that we are 
doing the ﬁ nest job we can in a real (and, therefore, ﬂ awed) world. Unfortunately, we do not stop 
to think what that really means.
Does best practice mean something that will work for everyone in all situations? We have 
already determined that there is very little (possibly nothing) that will be “secure” in any and 
every environment. Does best practice mean a minimum level of security required by all? Does it 
mean an optimal balance? We do not know. Th ere is no agreed-upon deﬁ nition of “best practice.” 
Although it sounds great, the term is close to meaningless. Probably the closest we can come to 
deﬁ ning the term in any useful way is to say that it refers to activities or processes that a number of 
experienced people agree are useful or helpful in improving security in most common situations.
Description of Frameworks
As noted earlier, there is no particular taxonomy to this list. Th e items are generally in alphabetical 
order, although some entities (particularly those with limited relation to security as such) will be 
included with more general or derivative frameworks.

Security Frameworks  259
BS 7799 and ISO 27000 Family
Starting with BS 7799, a number of diﬀ erent security frameworks have been created. Th ese have 
also become ISO standards and have created a family that is being expanded into specialty areas.
BS 7799-1, ISO 17799, and ISO 27002
BS 7799 Part 1 is one of the earliest frameworks speciﬁ cally addressing information security and 
is currently probably the most important and widely used. Subsequent to its adoption as BS 7799-1 
it became of signiﬁ cant interest to the information security community worldwide. Th e ISO used 
BS 7799-1 as a model for developing multiple versions of ISO 17799: the current standard is 
ISO 17799:2005. To promote consistency of numbering in the 27000 family of security stan-
dards, ISO 17799 is being redeveloped as ISO 27002.
Th is framework does not provide technical or implementation details, nor does it give a meth-
odology or a complete list of controls or safeguards. In its ISO 17799 version, it structures a bit of 
a taxonomy (eleven “clauses” that are surprisingly similar to the ten domains of the (ISC)2® Com-
mon Body of Knowledge), some policy (30 “objectives”), and a number of controls (133 “controls” 
and more than 500 “detailed controls”).
135 Items
There seems to be something magical about 135 in relation to secu-
rity. An astounding number of the security frameworks have roughly 
135 controls, or objectives, or questions. Of course, an intriguing 
count of the security frameworks also seems to gravitate to 150. Not 
as a number of items of any kind, though. When you go to purchase 
the various documents, U.S. $150 seems to have become a very com-
mon price point, regardless of the size or complexity of the guide-
line in question.
BS 7799-1 is essentially a code of practice, and it is the closest, of all the frameworks, to a list of 
speciﬁ c security activities to perform. In the new ISO 27000 family, the updated version is to be 
ISO 27002.
BS 7799-2 and ISO 27001
BS 7799 seems to have promoted the use of the phrase “Information Security Management 
 System” and the use of the acronym “ISMS” is an indicator of a BS 7799 inﬂ uence. BS 7799-2 
deals with ISMS requirements and is used within companies to create security requirements and 
objectives. Th is framework provides a process for implementation and management of controls 
and safeguards, ensuring that they meet speciﬁ c security goals. Enterprises can deﬁ ne new (and 
document existing) information security management processes and determine the status of Info-
Sec management activities.

260  Information Security Management Handbook
ISO 27000
As noted, the ISO standards related to security are being renumbered (as they are updated) and 
new standards are being added in the 27000 range. ISO 27000 itself will be about ISMS funda-
mentals and vocabulary and will essentially be the introduction to (and umbrella for) the whole 
group of standards. ISO 27003 will be ISMS implementation guidance, 27004 talks about Info-
Sec management measurements and metrics, 27005 is InfoSec risk management, 27006 is for 
accreditation of certiﬁ cation agencies, and 27007 will deal with audit guidelines.
Control Objectives for Information and Related Technology
Widely used and, until the rise of BS 7799-1, probably the most recognized of the security frame-
works, COBIT is directed at information security. However, it should be noted that COBIT was 
created by a speciﬁ c group and intended for a speciﬁ c purpose.
COBIT was created by ISACA (which used to be known as the Information Systems Audit 
and Control Association). Auditability is key to the COBIT, and the accounting and manage-
ment background deﬁ nitely shows in the choice of items in the COBIT list. Much of the activity 
suggested relates to measurement, performance, and reporting. Th us, in a sense, most of COBIT 
concentrates on what can be counted and demonstrated, sometimes disregarding what might 
actually be eﬀ ective.
You will ﬁ nd all kinds of variations on the capitalization of COBIT. 
There are references to COBiT, CObIT, and CobiT in the security 
literature, and ISACA prefers to print it out with the C and T in large 
capital letters and the OBI in small caps. In fact, you will ﬁ nd varia-
tions on the expansion of the acronym. In the same way that the 
parent organization now prefers to be known by its initials and 
the original name has been discarded, COBIT itself was originally 
Control Objectives for Information Technology, and has now been 
expanded to include “and related,” and ISACA’s literature seldom 
spells out the expansion at all.
COBIT breaks the list of suggested controls into four phases or domains, dealing with “planning 
and organization,” “acquisition and implementation,” “delivery and support,” and “monitoring.” 
(It is not too much of a stretch to see the Deming Plan/Do/Check/Act (PDCA) cycle in this 
structure. In fact, a great many process-based frameworks demonstrate the inﬂ uence of Deming’s 
PDCA.) Th e checklist of controls is extensive, and it is a valuable tool to ensure that no major area 
is neglected. COBIT also ﬁ ts very well for organizations that are primarily concerned about issues 
of compliance (e.g., in terms of the U.S. Sarbanes–Oxley law): the emphasis on audit provides a 
good utility for demonstrating the existence of controls of many types.
COBIT is not, however, conﬁ ned to information security and addresses a large number of 
other areas. Th erefore, basing a security review on COBIT may require extensive resources and 
will deﬁ nitely demand activity from areas of the enterprise outside of the information security 
department.

Security Frameworks  261
Common Criteria
Contrary to much mistaken opinion, the CC (more properly the Common Criteria for informa-
tion technology security evaluation, and also ISO 15408) is not a security framework or standard 
of practice. It is not even a standard for evaluating security products or systems. Th e CC is a struc-
ture for specifying product and product evaluation standards.
Th e basic result of following the CC structure is the production of a protection proﬁ le (PP). 
A PP outlines a general class of security devices or products, describing the environment within 
which such an entity is expected to work and the security functions that should be implemented. 
Th e part of the PP that can be used to evaluate a speciﬁ c device is known as the security target 
(ST). Evaluations are done on the basis of seven levels of increasing conﬁ dence in the assessment, 
the evaluation assurance levels (EALs).
It is not enough to know that a product has “passed” the CC. To 
understand what that might imply, the details of the PP, ST, and EAL 
must be known as well. As those who have dealt with ISO 9000, the 
standard on quality, are aware, it is perfectly possible to document 
your quality standards and procedures in a manner consistent with 
the ISO 9000 requirements and still have them say no more than 
“we make lousy products, and we do not care.” In the same way, it 
is possible to be CC “compliant” with a certiﬁ cation that says “the 
product provides almost no protection, and we are only judging that 
based on hearsay.”
Sources of information about the CC have tended to bounce around. For a while you could go 
to www.commoncriteria.org, then that disappeared, and the best place to get an idea of how it 
worked was at the NIST Web site. At the moment the site http://www.commoncriteriaportal.
org/public/expert/index.php?menu=2 seems to be working.
Th ere are generally three parts, or documents, related to the CC overall. Part 1 is a general intro-
duction, outlining the basic ideas and major terminology used. Th e Part 1 document is not hard 
to read, and probably every security professional should have read through it at least once. Part 2 
addresses functional security, the aspects that we normally consider to be security technologies 
and activities. Th is document stipulates how to express the requirements for functional security 
for a particular device. Outside of developers or evaluators working with or toward an evaluation, 
Part 2 is not something you will want to plow through, unless you have serious problems with 
insomnia. Part 3 deals with assurance: the question of how we know that the functional security is 
actually providing the protection that we want it to provide. Like Part 2, it sets forth the language 
and format for requirements and speciﬁ cations, and the document is even longer. However, this 
part also contains an overview of the seven EALs. Although the text is not easy to work through, 
this section of the CC is one with which more security professionals should be familiar.
Federal Information Systems Management Act
Th e U.S. FISMA mandates certain standards of information security and controls for U.S. federal 
agencies. It extends to contractors and other sources that support the assets of federal government 

262  Information Security Management Handbook
departments. However, it may have wider application yet, because it provides a solid basis for 
security management, assessment, and assurance for large corporations as well.
Speciﬁ cs on the implementation of FISMA vary somewhat. Th e legislation states that standards 
must be applied, but the standards are diﬀ erent for diﬀ erent agencies and applications. Detailed 
instructions can be found in directives for the military (Defense Information Technology Systems 
Certiﬁ cation and Accreditation Process), the intelligence community (Director of Central Intel-
ligence Directive 6/3), and more generally the National Information Assurance Certiﬁ cation and 
Accreditation Process. Th e NIST also has outlines (see National Institute of Standards and Tech-
nology for details of this and other documents).
Information Security Forum
Th e Information Security Forum (ISF) Standard of Good Practice for information security is 
a guideline forming a checklist of policies (or even attitudes) that the company or employees 
should have. It is structured in ﬁ ve “aspects” of security management: critical business applica-
tions,  computer installations, networks, systems, and development. Th ese aspects are broken out 
into 30 “areas” and the areas into 135 “sections.”
Th e areas of security management are high-level direction, security organization, security 
requirements, secure environment, malicious attack, special topics, and management review. For 
critical business applications there are security requirements, application management, user envi-
ronment, system management, local security management, and special topics. Computer instal-
lations involve installation management, live environment, system operation, access control, local 
security management, and service continuity. Networks require network management, traﬃ  c 
management, network operations, local security management, and voice networks. For systems 
development pay attention to development management, local security management, business 
requirements, design and build, testing, and implementation. Not all the 135 sections do have 
equal levels of detail. Management, for example, gets much more attention and material. Th e ﬁ rst 
section (of three) from “high-level direction” (section SM1.1) deals with management commit-
ment. It sets out the principle that senior management’s direction on information security should 
be established and commitment demonstrated. Th e objective is to establish top management’s 
direction on, and commitment to, information security. It goes on to note that board-level execu-
tives or the equivalent should have a high level of commitment to achieving high standards of 
corporate governance, such as those required by various national standards, treating information 
security as a critical business issue, creating a security-positive environment, and demonstrating 
to third parties that the enterprise deals with information security in a professional manner. Top 
management should have a high level of commitment to applying fundamental principles, for 
example, assuming ultimate responsibility for the internal controls of the enterprise; ensuring 
that controls over information and systems are proportional to risk assessed; assigning respon-
sibility for identifying, classifying, and safeguarding information and systems to system own-
ers; and granting access to information and systems in accordance with explicit criteria (policy). 
 Management should demonstrate their commitment to information security by setting direction 
for information security (in policy), assigning overall responsibility for information security to a 
top-level director or equivalent, chairing key information security working groups, monitoring the 
security condition of the enterprise, and allocating suﬃ  cient resources to information security.
Unfortunately, a later section on malicious mobile code simply states that there should be a 
means of dealing with it and lists some risk factors.

Security Frameworks  263
Th e ISF standard is, however, one of the few frameworks available without charge. Th e 247-page 
document (currently the 2005 version) does provide useful advice in a number of areas (although 
the early material is primarily promotional in nature). It can be downloaded from the ISF Web site 
at www.securityforum.org or http://www.isfsecuritystandard.com/pdf/standard.pdf.
Information Technology Infrastructure Library
Th e Information Technology Infrastructure Library (ITIL®) is a massive (and expensive) set of 
documentation aimed at improving IT service management. Although ITIL does not address 
security speciﬁ cally (any more: an original security section has been removed to be dealt with 
separately), proper management generally leads to better security, so it fairly naturally follows that 
this library of practices would be of interest to information security.
Th e areas addressed by the library include incident response, problems, change, release, con-
ﬁ guration, service desk, service levels, availability, capacity, service continuity, IT ﬁ nancials, and 
the IT workforce.
A standard for IT service management, closely following the principles and activities described 
in ITIL, will shortly be available as ISO 20000 (and the related BS 15000).
Management Frameworks
Although some of the entities noted earlier have a deﬁ nite background in the management arena, 
there are some additional frameworks that tend to be used in security planning.
Zachman Framework
Th e Zachman Framework is a two-dimensional model used to analyze an organization or process 
by breaking it down into smaller characteristics or considerations. Instead of trying to look at the 
entire enterprise at once, you break it down into a grid of perspectives and viewpoints. Th e “col-
umns” of the framework are the standard W5 “ﬁ ve good serving men” (plus one) of “what” (enti-
ties or data), “how” (function), “where” (network), “who” (people or organization) “when” (time 
or schedule), and “why” (motivation). Th e rows of the model structure diﬀ ering levels of scope and 
detail for various viewpoints: overall scope and context (or ballpark view), business unit (system or 
process owner’s view), system level (architect’s view), technology level (designer’s view), and detail 
level (subcontractor or implementer’s view) (Figure 20.1).
Th e Zachman Framework is presented as a tool for analyzing architectural conditions and 
operations in business. However, the original intent was to address issues in regard to sharing data 
and the structuring of relationships in data warehouses. Th erefore, although the tool would likely 
identify a number of important factors in regard to information ﬂ ow, direct application to security 
will likely require some application on the part of the analyst.
Calder–Moir IT Governance Framework
Supposedly to help you get the various security frameworks to work together harmoniously, the 
Calder–Moir IT Governance Framework is really only a graphical classiﬁ cation of the various 
frameworks in terms of whether they address the topics of business strategy, business and risk 
environment, IT strategy, operations, capabilities, and change management. You can see it at 
http://www.itgovernance.co.uk/calder_moir.aspx (Figure 20.2).

264  Information Security Management Handbook
Figure 20.1 Graphical display of the Zachman Framework. (From http://www.zifa.com/ 
framework.html. With permission).
Figure 20.2 Graphical display of the Calder–Moir IT Governance Framework. (From http://
www.itgovernance.co.uk/page.framework. With permission).
COSO; CoBIT; SOX; ISO17799;
Balanced Scorecard;
Baldridge et al.
Governance;
Compliance;
Enterprise Risk Mgmt;
Controls;
Audit
Strategic
Plans;
Business
Model;
Business
Environment;
Business
Strategies
Business
Strategy
Operations
Business
Operations;
IT Operations;
IT Asset Mgmt;
Security
ITPO
TCO/ROI;
ISO 17799;
CoBIT;
ITIL:
Business
Plans;
Balanced
Scorecard
Business & Risk
Environment
Information
Strategy;
Zachman
Framework;
Balanced
Scorecard
PRINCE2;
CMMI;
OPM3;
CoBIT
Zachman Framework;
Balanced Scorecard;
AS8015-2005
Capabilities
Human, Structural
and Market Capital;
Organization; Data;
Applications; Business & IT
Processes; Technologies
Change
Benefits
Business/IT
Architectures;
IT Principles
IT
Strategy
Readiness;
Projects;
Programs;
Methods;
Alignment;
The IT governance framework

Security Frameworks  265
Balanced Scorecard
Th e “balanced” part of balanced scorecard is a reminder to view business processes from multiple 
perspectives and not to neglect any. Speciﬁ cally, the process recommends setting objectives, and 
measuring performance, for the learning and growth (employee training), (internal) business pro-
cesses, customer (satisfaction), and ﬁ nancial perspectives. It is very concerned with metrics and 
measurement-based management.
Th e balanced scorecard is a good approach to take when there is a concern for the establish-
ment of security metrics. Generally, this would mitigate some of the risks of creating biased and 
unrealistic measurement baselines (Figure 20.3).
National Institute of Standards and Technology
It really is not fair to compare the Computer Security Resource Center of the U.S. NIST with the 
security frameworks we have been discussing. Th e center (which, although it is only one oﬃ  ce of 
the institute, is generally known simply as NIST in the security community) provides a wealth of 
security information and resources, which are freely available from their Web site at http://csrc.nist.
gov. Th e publications section is particularly useful, with a constantly updated stream of guidelines 
and aids, particularly the 800-series documents. Notable among these are the Information Security 
Figure 20.3 Graphical display of the balanced scorecard. (From http://www.balancedscorecard.
org/basics/bsc1.html. With permission).
Financial
Internal business
processes
“To succeed
financially, how
should we
appear to our
shareholders?”
Objectives
Measures
Targets
Initiatives
Objectives
Measures
Targets
Initiatives
Objectives
Measures
Targets
Initiatives
Objectives
Measures
Targets
Initiatives
Vision
and
strategy
“To satisfy our
shareholders
and customers,
what business
processes must
we excel at?”
Customer
Learning and
growth
“To achieve our
vision, how
should we
appear to our
customers?”
“To achieve our
vision, how will
we sustain our
ability to
change and
improve?”

266  Information Security Management Handbook
Handbook: A Guide for Managers (800-100), Recommended Security Controls for Federal Informa-
tion Systems (800-53), Guide to Information Technology Security Services (800-35), Risk Management 
Guide for Information Technology Systems (800-30), Engineering Principles for Information Technol-
ogy Security (800-27), Guide for Developing Security Plans for Federal Information Systems (800-18), 
Generally Accepted Principles and Practices for Securing Information Technology Systems (800-14), 
and An Introduction to Computer Security: Th e NIST Handbook (800-12).
800-26
Th e NIST publications provide an embarrassment of riches, and no security professional worth 
his or her salt has a bookmark ﬁ le that does not contain this site. However, to avoid extending the 
number of pages in this chapter I shall note only one.
Th e original Security Self-Assessment Guide for Information Technology Systems (800-26) was 
formalized in November 2001. It is a checklist of 137 questions to ask yourself about your own 
system. Th e signiﬁ cance and analysis of your answers are left up to you, but this work has been 
a tremendously valuable self-audit resource. More recently a version has been revised with NIST 
SP 800-53 (Recommended Security Controls for Federal Information Systems) references and map-
pings for the associated security controls, although this is, of course, more directly useful for 
the running the U.S. government systems. 800-26 is undergoing another revision, and this will 
involve a change of format to the Guide for Information Security Program Assessments and System 
Reporting Form. Th is new guide will be broader, and will deal with more extensive aspects of 
systems and protection, but it will also be more demanding of the user. Th ose dealing with small 
systems may wish to ensure that they have a copy of the original version of 800-26 before it is 
withdrawn in favor of the update.
Operationally Critical Threat, Asset, and Vulnerability Evaluation
Th e Operationally Critical Th reat, Asset, and Vulnerability Evaluation (OCTAVE) process is a 
risk management method from Carnegie Mellon University. It is a formal and detailed set of 
processes and will assist in ensuring that risks are identiﬁ ed and properly analyzed, following the 
standard techniques used in most risk analysis procedures. However, due to the level of activity 
and overhead involved in OCTAVE, it is probably best suited to large organizations or projects.
Securities and Financial Industry Frameworks
As should be clear to everyone in both ﬁ elds, the ﬁ nancial securities industry has very little to 
do with computer or information security, despite a heavy reliance on the technology. However, 
recent concerns in that community have concentrated on the area of internal controls, which have 
application in reviewing controls and safeguards, particularly in regard to insider attacks.
Basel II
Th is reference is shorthand for the Second Report from the Basel Committee on Banking Supervi-
sion, Risk Management Principles for Electronic Banking. Th e banking community has its own 
ideas about what risk management entails. One of the areas they are most concerned with involves 

Security Frameworks  267
having suﬃ  cient capital reserves to weather a storm, which generally is not something information 
security people tend to worry much about. However, the Basel II Accord also looks at operational 
risk, which is more in line with the risk management that InfoSec people know and love.
Committee of Sponsoring Organizations of the Treadway Commission
Th is title is shorthand for the Committee of Sponsoring Organizations of the Treadway Commis-
sion, Enterprise Risk Management Integrated Framework. Th e Treadway Commission was estab-
lished, in the United States, to address a fear (subsequent to some major ﬁ nancial failures) that 
small investors would lose faith in the stock markets and, in particular, in the ﬁ nancial reports 
from publicly traded companies. As such, COSO seeks to ensure that there are internal controls 
to enhance the reliability of public disclosures. Like COBIT, COSO is primarily concerned with 
internal controls, and with audit. (In opposition to COBIT, which concentrates on IT, COSO is 
concerned with business risk.)
COSO outlines a three-dimensional framework for examining controls. On one axis are four 
categories of objectives: strategic, operations, reporting, and compliance. A second axis lists four 
unit levels of an enterprise: entity level, division, business unit, and subsidiary. Finally, there are eight 
components of risk management: internal environment, objective setting, event identiﬁ cation, risk 
assessment, risk response, control activities, information and communication, and monitoring.
Again, although COSO provides a framework for examining a number of aspects of the busi-
ness, it does not provide any list of controls, practices, or methodologies.
Sarbanes–Oxley Law
Th e U.S. Sarbanes–Oxley law (frequently referred to as Sarbox or SOX) emphasizes that corporate 
management is responsible for the reliability of ﬁ nancial reports about publicly traded companies. 
It extends beyond that, touching on private companies doing business with other companies that 
do provide public reports and even on entities outside U.S. jurisdiction. Section 404 (and also 
302, in a marvelous confusion with Web result codes) notes that the integrity of information 
systems supporting these ﬁ nancial reports must also be managed. (Note: Th is basically repeats 
the concepts established in 1977 by the Foreign Corrupt Practices Act. Th e big diﬀ erence is in the 
compliance requirements.)
Security Governance
Many of the security frameworks available are in the form of a checklist, so why should not the 
Security Governance list-in-book-form for Fred Cohen’s CISO Toolkit be included?
In fact, Cohen’s version may be considerably easier to understand and use, particularly for 
those with a business, rather than a security, background. Although most security frameworks 
are structured according to a taxonomy of security concepts, the checklist in Security Governance 
is based on business models and concepts. For example, the four major divisions are made on the 
basis of business functions and modeling, oversight, business risk management, and enterprise 
security management. Th erefore, the businessperson working through the points will start with 
the familiar and only later have to face items directly discussing security. (Even then, the security 
issues are those regarding the position and management of security within the organization.)

268  Information Security Management Handbook
Regardless of other security frameworks that you may use, Cohen’s checklist will be of value. 
Although many items will have relations to details in other indices, the articles and entities in 
Security Governance address a number of issues that are not found in most security frameworks. 
Let’s face it: regardless of the emphasis or perspective, security frameworks tend to follow the same 
general outline. Cohen’s work is idiosyncratic and, in this case, that is a useful characteristic.
Also, most security frameworks give you a checklist of about 135 items for roughly U.S. $150. 
Cohen gives you over 900 points for U.S. $49.
Systems Security Engineering-Capability Maturity Model
Th e Systems Security Engineering-Capability Maturity Model (SSE-CMM), more generally 
known as the Capability Maturity Model (CMM), is an attempt to apply standards of engineering 
rigor to information systems technology development. Researchers at Carnegie Mellon University 
noted that many technology products and applications succeed based primarily upon being the 
ﬁ rst to address a need, even if it is addressed very poorly. (Many more programs and systems fail 
along the way.) Th e model identiﬁ ed diﬀ erent levels of maturity of organizations, in terms of pro-
cesses, documentation, and discipline, in an approach to development and change. Th e original 
model identiﬁ ed levels starting at informal or chaotic, through repeatable, documented, managed, 
and ﬁ nally ending at continually improving. Th ese structures and observations have been modi-
ﬁ ed and applied to more specialized ﬁ elds.
Th e SSE-CMM addresses the planning, development, and management of security and secu-
rity architecture for an enterprise. Th e levels in security are basic, planned and veriﬁ ed, well-
deﬁ ned and coordinated, measurable and quantitatively controlled, and constantly improving. 
Within these levels, sublevels are identiﬁ ed. In general, SSE-CMM recommends determining the 
institution’s performance level (in a number of security engineering and process areas) and then 
addressing individual areas to improve overall maturity.
SSE-CMM brings a good deal of discipline to management and process areas. Any large orga-
nization that has addressed basic areas of security, but wishes to formalize the process and develop a 
more architectural and broader outlook, can beneﬁ t from the assessment and recommended activities. 
However, the model does not, strictly speaking, advise on security activities and protections as such.
There is some controversy about the value of the CMM itself. Neither 
the “informal” nor the “continually optimizing” endpoint of the con-
tinuum is particularly well deﬁ ned, and some management special-
ists see very little difference between them. It should also be noted 
that some enterprises seem to perform very well, and for a very long 
time, at the basic “repeatable” level, although such organizations do 
not tend to deal well with change. However, companies nominally at 
the higher “managed” level may struggle with processes that are not 
truly repeatable or have been improperly documented. Therefore, 
placing an institution on the continuum is somewhat subjective.
Most management specialists would agree that the CMM is a 
valuable analytical tool. It may not work as well in terms of prescrip-
tions for action.

Security Frameworks  269
Summary
Although this chapter can only be the merest introduction to the security frameworks themselves, 
it should provide a general idea of the types of frameworks that are available and the relative areas 
of relevance and application for speciﬁ c frameworks. It is hoped that the reader will also have 
noted that just as no one security framework is suitable for all situations and applications, so no 
single framework should be relied upon as the sole guide for any enterprise. Multiple perspectives 
are necessary to provide for realistic security, and multiple documents have additional viewpoints 
to add to the construction of a security architecture. Each folio should be considered to see if it has 
something to add to your security program.


DOMAIN
  
6
TELECOMMUNI-
CATIONS AND 
NETWORK SECURITY
Communications and 
Network Security


273
Chapter 21
Facsimile Security
Ben Rothke
Contents
Group 3 Fax Protocols .............................................................................................................274
Secure Faxing ...........................................................................................................................275
Fax Advantages and Security Issues .........................................................................................275
Secure Fax Designation ............................................................................................................275
Creating a Secure Fax Infrastructure ..............................................................................276
Cover Sheets ...................................................................................................................276
Receiving Misdirected Faxes ...........................................................................................276
Number Conﬁ rmation ....................................................................................................276
Secure Fax Locations ..................................................................................................... 277
Conﬁ rmation Page ......................................................................................................... 277
Secure Fax Hardware ..................................................................................................... 277
Conclusion .............................................................................................................................. 278
Exhibit A: Secure Fax Hardware and Software ....................................................................... 278
Exhibit B: Policy ..................................................................................................................... 278
Most companies do not lack for information security products. Th eir data centers are likely full 
of ﬁ rewalls, virtual private networks, security appliances, and much more. Yet there is a device, 
hundreds of them perhaps, in many organizations, that lacks any sort of security. Th is is the lowly 
fax machine.

274  Information Security Management Handbook
Th e fax machine poses serious potential security issues and risks to every company that uses it. 
Th e good news is that most of these risks can easily be mitigated. Th e issue is that most companies 
are oblivious to these threats and do not take the appropriate countermeasures.
Group 3 Fax Protocols
An introduction to basic fax operations is in order. Th e reason faxing is so seamless is that all 
modern fax machines operate using the same protocol, namely the Group 3 Facsimile Protocol 
(G3). Th e G3 was ﬁ rst published in 1980 by the ITU (International Telecommunications Union: 
http://www.itu.int).
Th e G3 standard for facsimile communications over analog telephone lines was originally 
approved by the Consultative Committee for International Telegraphy and Telephony (CCITT) 
in its T.4 and T.30 recommendations in 1980. Th is standard is supported by nearly every fax 
machine in use today and continues to be updated.
G3 is speciﬁ ed in two standards:
T.4—image-transfer protocol
T.30—session-management procedures that support the establishment of a fax transmission
T.30 allows the two endpoints to agree on such things as transmission speed and page size. Because 
G3 is speciﬁ ed for switched analog networks, and it is an all-digital procedure, it must use modems 
or a fax relay. Th ey are also speciﬁ ed in ITU standards:
V.21 (300 bps) for the T.30 procedures and for image transfer
V.27ter (2400/4800 bps)
V.29 (7.2k, 9.6k)
V.17 (7.2k, 9.6k, 12k, 14.4k)
Real-time Internet Protocol fax transport is speciﬁ ed in T.38 and replaces modems
Th ere is a G4 standard, but this is for digital telephone networks and was approved in 1984 
and updated in 1988. Th is standard has found greater acceptance in Europe and Japan 
than in the United States and is predominately used for ﬁ xed point-to-point high-volume 
communications.
Th e T.30 speciﬁ cation divides a call into ﬁ ve phases:
Phase A—call setup
Phase B—premessage procedures
Phase C—image transfer
Phase D—postmessage procedures including multipage and end of procedure signals
Phase E—call release
Th ese ﬁ ve phases are detailed in the following ﬁ gure:*
* http://www.commetrex.com/whitepapers/FaxTech.html.













Facsimile Security  275
Activity progress
Message
transmission
Facsimile procedure
Facsimile call
In-message
procedure
Phase
A
Phase
B
Phase
C
Phase
D
Phase
E
Secure Faxing
One of the important works on fax security was Guidelines on Facsimile Transmission Security, 
issued by the Information and Privacy Commissioner of Ontario, Canada, back in 1989. Th is 
document was one of the ﬁ rst to bring to light the need to deal with fax security. Th e document 
was updated in 2003,* and it sets out guidelines for government organizations to consider when 
developing systems and procedures to maintain the conﬁ dentiality and integrity of information 
transmitted by fax. Although the paper was written for government  organizations, most of the 
issues and guidelines are relevant for nongovernment organizations also.
According to Ontario, Canada-based Natural Data, Inc., there are over 100 million fax 
machines in use worldwide today. Almost all of these fax machines are unable to connect to 
the Internet and as a result can send and receive faxes using only the unsecured public fax line 
services.
Fax Advantages and Security Issues
Th e fax machine, like all technologies, has security risks. Th e most notable fax issues are that the 
faxed document will sometimes not reach its intended destination. Th is is due to both human 
error (wrong number dialed) and technical issues (poor communication lines, incompatible equip-
ment, and more).
Although there are fax security issues, one of the main beneﬁ ts of a fax is that unlike an e-mail 
attachment, a fax document is an image ﬁ le and, therefore, is inherently not an editable ﬁ le. Th at 
means that no one can alter the original itself to embed another program within it, meaning a fax 
can never cause a computer virus or worm to invade one’s network.
Secure Fax Designation
It is important to note that in a perfect world, every fax machine will be deployed with the highest 
levels of security. In the real world, such an approach is not practical.
* http://www.ipc.on.ca/index.asp?navid=46&ﬁ d1=413.

276  Information Security Management Handbook
Creating a Secure Fax Infrastructure
Computer security is simply attention to detail and good design, and eﬀ ective information secu-
rity is built on risk management, good business practices, and project management. Creating a 
secure fax infrastructure is no diﬀ erent.
Th e initial step in this infrastructure is to establish policies around the use of fax machines. 
Th e ultimate level of fax security is built on this foundation of eﬀ ective policies and procedures 
that govern their use. At the end of this chapter is a set of core policies around fax security that 
can be used.
Although the basic use of a fax machine is often intuitive, the secure use of a fax machine is 
often not so intuitive. By creating a set of standard operating procedures (SOPs) around the use of 
secure faxes, you can mitigate most of the threats involved.
Some of the basic procedures around fax security include ensuring that the number of pages 
received for the fax is the same as that being sent, reassembling the received document, distribut-
ing it appropriately, conﬁ rming receipt, and more.
Cover Sheets
As part of the SOPs, all faxes sent should have a standardized cover sheet containing the name, 
title, and company name of both the sender and the recipient and the total number of pages 
faxed.
Some organizations request that the recipient conﬁ rm successful receipt of the fax, but 
such a request should be used with caution, as such a request can be onerous to the receiving 
party.
Many companies include disclaimers on their fax cover sheets stating that the information in 
the fax is conﬁ dential and that the information should not be distributed, copied, or disclosed to 
any unauthorized persons without prior approval of the sender.
Receiving Misdirected Faxes
Just as your users will eventually and invariably send a fax to the wrong number, you will also 
invariably be on the receiving end of an errant fax. Your SOPs should deal with such scenarios and 
detail to employees what they should do when an errant fax is received.
Th e ﬁ rst thing to do is to notify the sender that a fax was received in error. It is assumed that 
the sender followed guidelines and used a cover sheet.
Your users should be instructed that incorrectly sent faxes should never be forwarded to the 
recipient. Th ey should either be returned to the sender or shredded.
Number Conﬁ rmation
Many organizations have master lists of fax numbers. Th e challenge with such master lists is that 
fax numbers are often changed. If such lists are used, they should be audited regularly to ensure 
that the numbers are indeed current and accurate.

Facsimile Security  277
Secure Fax Locations
A key point to realize about security is that nearly every operating system, from UNIX to Linux, 
NetWare, Windows, and more, places the foundation of its security architecture at the physical 
server level. Unfortunately, physical security is often an afterthought when deciding where to 
place a fax machine. Such consequences can leave fax machines open to a security breach.
To create a secure fax infrastructure, fax machines must be isolated in a secure area. Th is area 
must be restricted to only authorized employees. Th ese secure fax machines should be placed in 
locations that are not accessible to the general populace. Given that faxes can come in at any time, 
24/7/365, this level of segregation ensures that conﬁ dential information sent during oﬀ -hours is 
not compromised.
Conﬁ rmation Page
Even with the advent of e-mail, one signiﬁ cant advantage the fax has over other forms of data 
exchange is that the sender immediately knows if the transmission was successful. When it comes 
to e-mail, it can often take hours or days for the information to actually appear on the recipient’s 
desktop.
With that, all fax machines have the capability to print a fax conﬁ rmation sheet after each fax 
sent. Th is sheet conﬁ rms if the fax has been successfully transmitted, the destination fax number, 
and the number of pages transmitted. Th e sender of each fax should conﬁ rm the success of a trans-
mission by checking this log after each secure fax message is sent.
Similarly, recipients should be trained to match the number of pages received against the 
transmitted fax cover sheet. In the event that pages are missing, the recipient should contact the 
sender and request a retransmission.
Secure Fax Hardware
To use fax encryption technology, both senders and recipients must have the same type of fax 
encrypting hardware. Most secure fax machines are identical in appearance to a typical fax machine, 
built on a standard commercial-based platform of product sold for general use. For secure fax 
machines, most of the functionality is transparent to the end user.
Th ere are various standards for secure fax machines, including:
MIL-STD-188-161D
NATO STANAG 5000
NSA NSTISSAM 1-92 TEMPEST Level 1
NATO AMSG720B
TEMPEST models are internally shielded to prevent electromagnetic emissions from escaping, 
preventing interception of transmitted data signals. Th is is needed as anyone with the proper 
equipment can monitor, intercept, and reconstruct those signals, possibly while parked outside a 
corporate headquarters or military base. Th e downside is that TEMPEST capabilities can increase 
the price of a standard fax machine to well over $2000.





278  Information Security Management Handbook
When communicating in a secure mode, a fax uses an RS-232C connection to cryptographic 
equipment, such as an STE (secure terminal equipment), a device that looks much like a telephone 
and utilizes digital signaling.
Conclusion
Creating a secure fax infrastructure does not take a lot. Th e function of this chapter was to raise 
the issue and be a starting point for companies in creating their secure fax plan.
Exhibit A: Secure Fax Hardware and Software
Th e following is a starters list of secure fax vendors. A Google search on secure fax will provide a 
much more deﬁ nitive list of the various vendors.
Ricoh SecureFax
www.ricoh-usa.com/products/category_main.asp?pCategoryId=17&pCatName= 
SecureFax
Cryptek Secure Fax
http://www.cryptek.com/fax/default.asp
Gateway Fax Systems
http://www.gwfs.com/JITCCertiﬁ cation/JITCcert.html
Venali
http://www.venali.com/solutions/index.php
Business Security AB SecuriFax
www.bsecurity.se
TCC CSD 3700
http://www.tccsecure.com/products/voice-fax-data-encryption/CSD3700-summary.html
Exhibit B: Policy
Policy is critical to the eﬀ ective deployment of a secure fax infrastructure. A comprehensive secu-
rity policy is required to map abstract security concepts to the real world implementation of secu-
rity products. It is the policy that deﬁ nes the aims and goals of the business. It comes down to the 
fact that if you have no policies, you have no information security.
After policy comes the need for SOPs. Organizations that take the time and eﬀ ort to cre-
ate formal information security SOPs demonstrate their commitment to security. By creating 
SOPs, they drastically lower their costs (greater return on investment [ROI]) and drastically 
increase their level of security.
Th e following policies are from Information Security Policies Made Easy, version 10,* which is 
the deﬁ nitive information security policy resource.
* https://www.informationshield.com/ispmemain.htm—Used with permission from Information Shield, Inc.

Facsimile Security  279
Title
Policy
Commentary
Machine repair staff 
conﬁ dentiality agreements
Prior to beginning their work, all 
external ofﬁ ce equipment repair staff 
must have signed a Company X 
conﬁ dentiality agreement.
This policy prevents industrial or military espionage. Recent 
models of ordinary ofﬁ ce equipment such as copiers and fax 
machines now have up to 5 MB of recent information stored in 
them. If repairpersons were to swap the chip that contains this 
information, they could walk away with signiﬁ cant intellectual 
property without detection. If there is a paper jam, some 
sensitive information may have been printed on that paper but 
it may not have been removed from the machine.
The policy is written with a broad scope, and general-purpose 
computers, including handhelds, would be included within its 
purview. Some organizations refer to conﬁ dentiality 
agreements as nondisclosure agreements.
Maintaining classiﬁ cation 
labels
Workers in possession of any 
information containing a Company X 
data classiﬁ cation sensitivity label must 
maintain, propagate, and if need be, 
reestablish this same label whenever 
the information changes form, format, 
or handling technology.
This policy tells users that they must be diligent when they 
change the form, format, or technology used to handle sensitive 
information.
For example, assume that information labeled as “conﬁ dential” 
was sent by fax to a remote location. The recipient could then 
extract certain details from the fax and include these details in 
an e-mail message. This policy would require that the 
“conﬁ dential” label be included in the e-mail message. Because 
users are in control of many of the changes in form, format, and 
handling technology that occur, they must be the ones to ensure 
that a label continues to be attached to sensitive information. 
This policy could be expanded to include labels and restrictions 
provided by third parties, such as copyright notices.
The words “any information containing a Company X data 
classiﬁ cation sensitivity label” may be too stringent for some 
organizations; they may prefer to use the words “any 
information with a secret classiﬁ cation label” (and thus save 
some money).
(continued)

280  Information Security Management Handbook
Title
Policy
Commentary
Equipment in secret 
information areas
Printers, copiers, and fax machines 
must not be located in the physically 
isolated zones within Company X 
ofﬁ ces that contain secret information.
This policy prevents people from making paper copies, from 
printing computer-resident information, and from otherwise 
removing hard-copy versions of secret information. If the devices 
to perform this process are not provided within a secured area 
no one will be able to make unauthorized copies of the 
information contained therein. All other avenues through which 
secret information could ﬂ ow must also be blocked. For example, 
an isolated local area network could be used to prevent users 
from sending the secret information out over the Internet as part 
of an e-mail message. The very high security approach reﬂ ected 
in this policy works best if the movement of paper-resident 
secret information is strictly controlled, perhaps with sensors 
that detect that it has been removed from an isolated area.
This policy also creates a paperless ofﬁ ce that, when deployed in 
high security areas, has the potential to be more secure than 
any paper-based ofﬁ ce could ever be. Diskless workstations 
could be employed in such an environment to increase the 
level of security.
Fax logs
Logs reﬂ ecting the involved phone 
numbers and the number of pages
for all inbound and outbound fax 
transmissions must be retained
for one year.
This policy provides a legal record of the faxes that were sent 
and received. This is important in business environments where 
contracts, purchase orders, invoices, and other legally binding 
promises are handled by fax. The maintenance and retention of 
a fax log can help resolve day-to-day operational problems. 
Such fax logs may additionally be useful for the preparation of 
expense reports and internal charge-back system reports. 
Many new personal computer software packages that support 
faxing come with their own logs, which, according to this policy, 
should be turned on. Fax servers also support extensive 
logging. Modern versions of more expensive fax machines
also keep their own logs. This policy can be carried out 
automatically by the involved equipment as well as manually
by the involved operators.

Facsimile Security  281
Faxing sensitive
information—
notiﬁ cation
If secret information is to be sent by fax, 
the recipient must have been notiﬁ ed 
of the time when it will be transmitted 
and also have agreed that an 
authorized person will be present at 
the destination machine when the 
material is sent. An exception to this 
policy is permitted when the 
destination fax machine is physically or 
logically restricted such that persons 
who are not authorized to see the 
material being faxed may not enter the 
immediate area or otherwise gain 
access to faxes received.
One scenario for inadvertent disclosure involves sensitive 
materials that have been sent by fax but not yet picked up by 
the intended recipient. This policy ensures that no 
unauthorized person examines sensitive faxed materials sitting 
in a fax machine. If the recipient knows a fax is coming, he or 
she will also be concerned if it does not arrive when expected. 
The policy presumes the existence of another policy that 
deﬁ nes the term “secret.” This term may be readily replaced 
with the comparable label used within the organization in 
question. Note that the policy recognizes the reality of modern 
fax servers that can restrict access to faxes received using 
recipient passwords.
Faxing sensitive 
information—human
presence
Sensitive materials must not be faxed 
unless the sender has immediately 
beforehand conﬁ rmed that an 
authorized staff member is on hand to 
handle the materials at the receiving 
machine properly. 
When the transmission is complete, the 
staff member at the receiving end 
must conﬁ rm to the sender that a 
certain number of pages were 
received. An exception is allowed if 
the receiving machine is in a locked 
room accessible only to authorized 
personnel or if a password-protected 
fax mailbox is used to restrict 
unauthorized release of faxed 
materials.
One common scenario for inadvertent disclosure of faxed 
materials involves faxes that have been sent but not yet picked 
up by the intended recipient. This policy requires an authorized 
staff member to be present throughout the entire faxing 
process and to conﬁ rm that the faxing process was completed 
successfully. In addition to the exception noted in the third 
sentence of the policy, another exception may be permitted in 
those situations in which two fax machines support encryption.
A higher security approach would be to prohibit the faxing of 
any sensitive information unless both the sending and the 
receiving machines employ encryption. Only with encryption 
can the sender and recipient be reasonably assured that a fax 
was not intercepted in transit. This policy assumes that the 
word “sensitive” has been deﬁ ned elsewhere.
(continued)

282  Information Security Management Handbook
Title
Policy
Commentary
Faxing sensitive
information—
intermediaries
Sensitive Company X information must 
not be faxed through untrusted 
intermediaries including, but not 
limited to, hotel staff, airport ofﬁ ce 
services staff, and rented mailbox store 
staff.
Workers may be traveling for business, pressed for time, and not 
thinking about the people who may be exposed to sensitive 
information. The policy could be expanded to include preferred 
methods for sending the information, for example, by bonded 
courier.
The use of encryption is irrelevant here because the issue is 
whether intermediaries can examine the information in hard-
copy form. The policy requires senders to do the faxing 
personally to help assure that unauthorized parties are not 
exposed to the information in question. The word “sensitive” 
should have been deﬁ ned in another policy.
Faxing sensitive 
information—cover sheet
When sensitive information must be 
faxed, a cover sheet must be sent and 
acknowledged by the recipient, after 
which the sensitive information may 
be sent through a second call.
This policy ensures that sensitive information is being faxed to 
the correct fax machine and that the sender is using the correct 
phone number. The policy prevents unauthorized call 
forwarding from interfering with the intended fax 
communication path. With so many fax machines in use these 
days, the chance that a wrong number would make connection 
with another fax machine is quite high. This policy prevents that 
type of error from causing unauthorized disclosure of the 
material on the involved fax. Another intention of this policy is 
to ensure that an authorized party is on hand and actually 
watching the destination fax machine. This prevents 
unauthorized parties from viewing the sensitive faxed material.
Conﬁ rming that an authorized recipient is on hand is also 
desirable in case the second call is unsuccessful. Thus the 
recipient would call the sender and ask for a retransmission if 
some of the pages were missing, if there was a paper jam, etc. 
This policy could be augmented with another sentence requiring 
the recipient to conﬁ rm receipt of the second transmission. The 
policy does not specify how the destination party acknowledges 
receipt. This would most often occur on a separate voice line or 
by other means such as a pager or instant messaging.

Facsimile Security  283
Faxing sensitive
information—
unencrypted
Sensitive information may be faxed over 
unencrypted lines only when time is of 
the essence, no alternative or higher-
security transmission methods are 
available, and voice contact with the 
receiving party is established 
immediately prior to transmission.
This policy notiﬁ es staff that sensitive information should not be 
faxed over unencrypted lines on a regular basis. If there is a need 
for regular transmission of sensitive information, then workers 
should request encrypting fax machines. Some international 
export restrictions may apply to encryption technology so check 
with legal counsel if establishing encrypting fax machines for 
international transmissions. The policy shown here may also 
include words requiring conﬁ rmation of receipt of a fax that 
includes sensitive information. Transmission to an attended 
stand-alone fax machine may be preferable to transmission to a 
fax server, if that server does not have adequate access controls 
and if it may be readily accessed by a number of people. This 
distinction may be stated explicitly in the policy. The word 
“sensitive” should have been deﬁ ned in another policy.
Faxing sensitive 
information—physical 
security
Secret or conﬁ dential information must 
not be sent to an unattended fax 
machine unless the destination 
machine is in a locked room for which 
the keys are possessed only by people 
authorized to receive the information. 
This policy ensures that no unauthorized person examines 
sensitive faxed materials. By physically restricting access, 
unauthorized persons are prevented from seeing secret or 
conﬁ dential faxes. This policy says nothing about notiﬁ cation of 
the recipient.
The policy can be implemented by placing a special fax machine 
in a locked closet. Some organizations may wish to eliminate the 
reference to physical keys because there are other technologies 
that might be used, such as magnetic card access control 
systems. The policy presumes the existence of another policy 
that deﬁ nes the terms “secret” and “conﬁ dential.”
(continued)

284  Information Security Management Handbook
Title
Policy
Commentary
Faxing secret
information—
encryption
Secret information must not be sent by 
fax unless the transmission is 
encrypted using methods approved by 
the Company X Information Security 
Department.
Encryption prevents sensitive information from being revealed 
to wiretappers and others who may have access to it as it travels 
by common carriers. At the destination, the information can be 
decrypted, or recovered by reversing the encryption process. 
Even though the transmission is encrypted, the information 
coming out of a destination fax machine will be readable to any 
person who happens to be present when the fax is received. To 
prevent this, other controls such as a password to print a fax will 
be required. This policy thwarts fax transmission wiretapping. It 
is relatively easy to place a wiretap, record an unencrypted fax 
transmission, and later play it back into another fax machine to 
generate readable hardcopy. If this were done, neither the 
sender nor the recipient would ordinarily be aware that a 
wiretap has taken place. This comment is equally true of the 
new faxing services that use the Internet rather than dial-up 
lines. They too can be tapped unless the transmission is 
encrypted. The policy presumes the existence of a policy that 
deﬁ nes the term “secret.”
Faxing conﬁ dential 
information—speed dial
When conﬁ dential information is sent 
by fax, the operator must not use 
preset destination telephone numbers, 
but must instead manually enter the 
destination number.
This policy prevents the misdirection of faxes because of a 
mistaken entry of a speed-dial number. These types of errors 
can result in embarrassing situations in which, for example, one 
important customer sees that another important customer has a 
different price for the same product they bought yesterday. A 
high-visibility case involved the misdirection of a conﬁ dential 
merger contract to a business newspaper.

Facsimile Security  285
If fax operators manually key in the phone number, they may 
make an error, but the error is likely to be a single digit. This will 
often cause the fax not to go through because a voice line or a 
modem line will be reached instead of another fax line. There 
is, however, no such automatic safety net when preset fax 
numbers are employed. This policy also helps to prevent the 
scenario in which some unauthorized person with access to the 
sending machine changes a previously selected speed-dial fax 
number, such that a sensitive fax is misdirected to an 
unauthorized recipient.
Faxing secret
information—
passwords
Secret information must not be sent by 
fax unless the receiving machine, prior 
to the initiation of a transmission, 
successfully receives a correct 
password from an authorized person 
at the receiving end of the 
transmission.
This policy helps to ensure that the correct fax machine has been 
reached. Only when a correct password is entered is this 
connection conﬁ rmed. There have been many reported cases in 
which sensitive faxes were sent to the wrong machine, and this 
policy helps to prevent additional problems of this nature. Two 
compatible machines, each supporting passwords, are likely to 
be required for this policy to work. This will reduce the number 
of machines to which secret faxes can be sent. This may also 
require that certain fax machines throughout an organization, 
machines that were manufactured by various vendors, be 
replaced with fax machines from a single vendor. Other 
passwords for printing faxes also may be required. The policy 
presumes the existence of a policy that deﬁ nes the term 
“secret.” The restriction of the scope of this policy to secret 
information means that normal (less sensitive) faxes need not 
bother with this process.
(continued)

286  Information Security Management Handbook
Title
Policy
Commentary
Fax cover sheet notice
All outgoing Company X faxes must 
include a cover sheet that includes 
wording approved by the legal 
department.
This policy is intended to be responsive to the signiﬁ cant 
number of faxes that are mistakenly sent to the wrong 
number. Not only can this involve entering the wrong 
telephone number on the fax machine, it may also involve 
telephone system malfunctions, internal mail systems that 
incorrectly deliver faxes to the wrong person, or monitoring of 
transmissions by telephone company technicians. A standard 
cover sheet will ensure that certain legal words precede all 
outbound faxes. Typically such a cover sheet includes a notice 
that the transmission is for use only by the intended individual 
or entity. This notice may also state that if the reader of the fax 
is not the intended recipient, then the reader must not use, 
disseminate, distribute, or copy the information. The notice 
may request that the sender be notiﬁ ed if the fax has been 
sent someplace other than the intended destination.
The notice can be supplemented with words requesting the 
destruction of a misdirected fax and that no action be taken 
relying on the information contained in the fax itself. The 
policy discussed gives the greatest ﬂ exibility in that the words 
on the cover can be changed without the need to change the 
policy itself. Changes in the words on the cover will be 
necessary as the legal and business status of faxes evolves 
over time.

Internet, Intranet, and 
Extranet Security


289
Chapter 22
Network Content Filtering 
and Leak Prevention
George J. Jahchan
Contents
Conclusion ...............................................................................................................................291
Organizations today depend heavily on the Internet, intranets, and their network infrastructures 
to conduct business. Ensuring the security and integrity of data shared across networks is essential, 
especially in light of the various regulatory and legislative mandates they must comply with. At 
the same time, the enforcement challenges facing them are on the rise, and the need for eﬀ ective 
security controls is greater than ever. Organizations strive to implement technical controls to assist 
in enforcing their security policies; however, under certain circumstances some organizations need 
to monitor the content of packets entering and leaving their network to ensure they detect leaks 
of conﬁ dential information.
Signature- or behavior-based detection and prevention technologies depend on the auto-
mated recognition of anomalous conditions: in the ﬁ rst case through signatures and in the sec-
ond through exceeding a set threshold of deviation from known normal conditions (or baseline). 
Th e  prevention of unauthorized disclosure of proprietary or conﬁ dential data (information leaks) 
through conventional technologies (such as intrusion detection or prevention) is diﬃ  cult to man-
age. Signature-based intrusion detection and prevention relies on attack signatures (bit patterns in 
packet streams); extending that to include words or word patterns that are contained in applica-
tion ﬁ les (databases, oﬃ  ce productivity documents, portable document ﬁ les, or any of the numer-
ous ﬁ le formats in use today) that would be indicative of a leak of information is diﬃ  cult.
Conventional technology solutions such as identity and access management, security informa-
tion management, content management systems, and digital rights management—individually 

290  Information Security Management Handbook
or in combination—help organizations control who has access to sensitive data; however, once 
authorized access is granted, they have little control over how that data is utilized.
In this chapter, we look at controls that can help organizations mitigate the risk of information 
leaks through networks.
Information-handling security policy should have teeth: a strong policy that clearly outlines 
the information-handling requirements of the organization and mandates disciplinary measures 
for policy violations is the ﬁ rst step in controlling information leaks through networks. But a 
policy without the means to enforce it remains ineﬀ ective.
Limiting the protocols or applications that can be utilized by network users in connections 
to foreign networks helps organizations reduce the vectors through which sensitive information 
could be leaked. Placing too many restrictions will, however, impede the business, and organiza-
tions need to compromise between security and usability.
Once this exercise is complete, and a clear picture of the traﬃ  c to be allowed is established, the 
attention can turn to the mitigation methods for permitted traﬃ  c. Th is chapter covers the most 
common vectors through which information can be leaked and suggests mitigating controls.
HTTP/FTP. Any document types can be uploaded to a Web site that is designed to “accept” 
attachments (Web-based e-mail, bulletin boards, etc.). Universal resource locater (URL) 
ﬁ ltering—which is typically part of the defense arsenal of companies—can help mitigate 
this risk. Free Web-based e-mail services are typically classiﬁ ed in the “Web mail” category 
of URL ﬁ ltering solutions; thus access to these services can be curtailed by implementing 
appropriate security controls over Web access (a functionality that is available either in a 
stand-alone solution or as an add-on to the existing Web caching servers from several ven-
dors). Th e residual risk will come from uncategorized sites. Denying access to such sites can 
further reduce the residual risk, but may be deemed unacceptable to the business. Either 
way, insofar as leak control is concerned, the URL ﬁ ltering method is binary and lacks 
granularity.
HTTP/SFTP/SSH and other encrypted traﬃ  c. Th e scenario is similar to the preceding one. 
Control is binary and lacks granularity. Once access is granted, no further control is possible 
over content.
Peer-to-peer applications. Risk is best mitigated by preventing the use of such applications.
A combination of controls at diﬀ erent layers can be used for maximum eﬀ ectiveness.
On desktops in Active Directory (AD) environments, group policies can prevent users from install-
ing or running unauthorized applications, including peer-to-peer.
On desktops in all Windows environments, desktop security solutions available from several 
vendors help organizations control desktop usage and prevent the installation or execution of 
peer-to-peer applications. Th ese can be used stand-alone or in combination with AD group poli-
cies in AD environments.
At the network layer, periphery defenses can be conﬁ gured to block peer-to-peer traﬃ  c, with 
varying degrees of eﬀ ectiveness.
Electronic mail (corporate mail systems). Technical solutions exist to (i) inspect the content 
of messages and attachments (speciﬁ c ﬁ le formats) or (ii) archive all or selected mailboxes. 
Encrypted e-mails or attachments would, however, be diﬃ  cult to inspect with either of these 





Network Content Filtering and Leak Prevention  291
solutions. In the ﬁ rst case, if the business allows it, rules can specify that unrecognized or 
encrypted ﬁ le formats be automatically blocked.
General controls. Network forensics solutions that capture and store all (or ﬁ ltered) traﬃ  c 
(see simpliﬁ ed network diagram) enable the reconstruction and replay of sessions that were 
previously “recorded,” enabling organizations to spot security policy violations. Th e technol-
ogy does have limitations though it is expensive and requires expertise to operate eﬀ ectively. 
Furthermore, though encrypted traﬃ  c can be recorded “as is,” its clear-text content cannot 
be visualized unless the organization has prior knowledge of the encryption algorithms and 
associated keys, which is rarely the case. HTTPs and SSH are common methods of transfer-
ring data in encrypted form.
In addition, archive tools (such as WinZip) now oﬀ er built-in strong symmetrical encryption 
capabilities (up to 256-bit advanced encryption standard [AES]). Any documents encrypted with 
a strong key that is transferred to the addressee out-of-band cannot be visualized unless the sender 
discloses (or is forced to disclose) the encryption method and key used. Th ings are even more 
diﬃ  cult in the case of symmetrical keys that are negotiated online through an asymmetrical key 
exchange (such as during a Secure Sockets Layer session establishment).
Traffic collector
Loader
Database
Content
management
system 
Mail
gateway
Network forensics
DMZ
LAN
Proxy
servers
Mail
gateway
AD group
policies
Desktop
security
solutions
Analysis
workstation
SQL
DRM
Conclusion
Th e technology designed to protect highly sensitive data from leaks through networks is complex 
and expensive in terms of acquisition and ongoing operation costs, and its eﬀ ectiveness is depen-
dent upon what type of traﬃ  c an organization allows to permeate through its periphery.


292  Information Security Management Handbook
Encryption is a double-edged sword: it helps in ensuring the conﬁ dentiality of information 
traveling across networks, but it also prevents organizations from maintaining the visibility of 
what sort of information is leaving their networks.
To combat information leaks eﬀ ectively through networks, organizations must follow the con-
tinuous information security plan cycle: assess, design, implement, educate, monitor, and correct. 
Th e security personnel’s awareness and understanding of vectors that could be used by ill-intentioned 
persons to sneak sensitive or conﬁ dential information out of a network is key to mitigating its risk.

Network Attacks and 
Countermeasures


295
Chapter 23
The Ocean Is Full of Phish
Todd Fitzgerald
Contents
Phishing Deﬁ nition ................................................................................................................ 296
Evolution of Phishing .............................................................................................................. 297
Today’s Phishing Activity ........................................................................................................ 297
Phishing Delivery Mechanisms ............................................................................................... 298
E-Mail and Spam Delivery Method ............................................................................... 298
Web-Based Delivery Method ......................................................................................... 299
IRC and Instant Messaging Delivery Method ............................................................... 299
Trojaned Host Delivery Method .................................................................................... 299
Phishing Attacks ..................................................................................................................... 299
Man in the Middle ........................................................................................................ 299
URL Obfuscation Attacks ...................................................................................................... 300
Other Attacks ..........................................................................................................................301
Educating Consumers ..............................................................................................................301
Technical Approaches to the Problem ..................................................................................... 302
Inbound Spam Filters .................................................................................................... 302
Protect the Desktop ....................................................................................................... 302
Removal of HTML E-Mail ........................................................................................... 302
Browser Enhancements .................................................................................................. 302
Stronger Password Log-Ons ........................................................................................... 303
Final Th oughts ........................................................................................................................ 303
Further Readings .................................................................................................................... 303

296  Information Security Management Handbook
It was only a little more than a decade ago when “the Internet” was not part of most individual’s 
daily vocabulary. Today, the use of the Internet, e-mail, and text messaging is ubiquitous through-
out coﬀ ee shops, cities, cell phone communications, and the workplace. Th is medium, despite 
the lack of inherent security at the network level, has become “trusted” by many to perform daily 
personal and business operations. As with everything that is “trusted” in our society, a criminal 
element is also invited to the party to penetrate that trust for personal satisfaction or ﬁ nancial 
gain. Enter the latest lucrative criminal element poised to diminish the trust that companies have 
built up—phishing.
Phishing Deﬁ nition
Wikipedia deﬁ nes phishing as “a criminal activity using social engineering techniques.  Phishers 
attempt to fraudulently acquire sensitive information, such as usernames, passwords and credit 
card details, by masquerading as a trustworthy entity in an electronic communication.” Th e 
Anti-Phishing Working Group (APWG) deﬁ nes phishing as a form of identity theft that 
employs both social engineering and technical subterfuge to steal consumer’s personal identity 
data and ﬁ nancial account credentials. Th ey further deﬁ ne technical subterfuge as “a scheme 
to plant crimeware onto PCs to steal credentials directly, often using key logging systems to 
intercept consumers’ online account user names and passwords, and to corrupt local and remote 
navigational infrastructures to misdirect consumers to counterfeit Web sites and to authentic 
Web sites through phisher-controlled proxies that can be used to monitor and intercept con-
sumers’ keystrokes.”
Th e term “phishing” was ﬁ rst mentioned in the America Online (AOL) Usenet newsgroup 
in January 1996 and may have been used in the earlier hacker “2600” newsletter. Phishing is a 
variant of the word “ﬁ shing,” describing the use of sophisticated techniques to “ﬁ sh” for ﬁ nancial 
information by casting lures into the mouths of unsuspecting users. AOL was a large target, and 
many passwords, known as “phish,” to AOL accounts were obtained by phishing and subsequently 
traded for other pieces of stolen software, such as games and copyrighted software.
Companies work very hard to protect their brand and establish trust in the presence of their 
brand with the consumer. When an individual goes to a McDonald’s for example, he or she 
expects to get a consistent level of service and product and pay a price similar to that of their last 
experience. Th e transactional trust, which is built over time, causes people to have faith in obtain-
ing products from the company. Th e cleanliness and safe handling of the hamburger, fries, equip-
ment, etc., are also expected to be the same each time the consumer visits the store. All of these 
thoughts come to the surface when the “Golden Arches” brand is presented, and people’s trust in 
future purchases is based upon their last interaction with the brand. Similarly, many banks have 
established trust over time with consumers to protect their funds and oﬀ er online banking ser-
vices. When notices appear to come from the bank, complete with its logo, the individual percep-
tion of trusting the message is based upon the last interaction with the bank.  Criminal phishing 
activity disrupts the trust model by masquerading as the “trusted brand” to gain the consumer’s 
conﬁ dence. Consumers are left confused in many cases as to whom they should trust. Th is creates 
a very diﬃ  cult problem for companies to educate the workforce as to what is and what is not a 
phishing attempt.
Th e subsequent sections describe how to identify phishing attempts, methods used to deliver 
phishing by the attackers, attack methods, and approaches being used to minimize the threat.

The Ocean Is Full of Phish  297
Evolution of Phishing
Originally, phishing attempts obtained passwords by tricking users into supplying the passwords 
in response to an e-mail request. Although this method is still prevalent today, with ﬁ rms such as 
the major banks, EBay, and PayPal being among the largest targets, more complex and creative 
methods have been developed to attempt to fool the end user. Th ese include such methods as 
directing users to fake Web sites that appear as if they are issued by the same company (i.e., EBay, 
Chase, U.S. Bank), man-in-the-middle proxies to capture data, Trojan-horse keyloggers, and 
screen captures. Early attempts utilized requests from individuals posing as AOL support staﬀ  
asking the subscriber to “verify your account” or “conﬁ rm billing information.” Th is resulted in 
AOL issuing the ﬁ rst statements that “no one from AOL will ask for your password or billing 
information.” Now, these statements are prevalent across banks, online payment services, and 
organizations providing E-commerce activity. E-mails have been made to look like they were 
coming from the Internal Revenue Service (IRS) to obtain tax information to be used in identity 
theft criminal activities. Th ere is typically an increase in fake IRS e-mails around April 15 ﬁ ling 
deadline, as consumers are more vulnerable due to the short time left to ﬁ le taxes. Fake job sites 
have been erected to entice individuals to reveal personal information. MySpace was the subject 
of a worm in 2006 to direct users to diﬀ erent Web sites to obtain their log-in credentials.
Today’s Phishing Activity
Phishing activity has been increasing dramatically over the past few years. Th e APWG identiﬁ es 
itself as “an industry association focused on eliminating the identity theft and fraud that result 
from the growing problem of phishing and email spooﬁ ng.” For the past several years they have 
been tracking trends in phishing activity.
Unique phishing attacks are deﬁ ned by the APWG as unique Uniform Resource Locators 
(URLs) of the Web sites that the users are directed to. In January 2004, they tracked 176. 
Just nine months later, in October 2004, the number had risen to 1142, and by October 
2005 the number was 3367. An explosion of phishing Web sites subsequently occurred, with 
27,221 unique sites in January 2007.
Th e AWPG deﬁ nes a phishing report as the instance of a unique e-mail sent to multiple users, 
directing them to a speciﬁ c phishing Web site. Th e number of e-mails increased substantially, 
from 6957 in October 2004 to 15,820 in October 2005 and 29,930 in January 2007.
Th e number of brands attacked is also increasing, with 28 brands attacked in November 
2003, 44 brands in October 2004, 96 brands in October 2005, and 135 brands attacked in 
January 2007.
Th e average time for a phishing site to be online has been steadily decreasing, making it dif-
ﬁ cult to identify and deal with the spoofed sites in a timely manner. Th e average time online 
was ﬁ ve and a half days in October 2005, compared with four days in January 2007. Th e 
longest time online for a site was 30 days.
Almost 97 percent of the ports used at the Web sites were port 80, with the other 3 percent 
made up of ports 84, 82, 81, and other ports.
Th e United States leads as the country hosting the most phishing sites, with 24.27 percent. 
Th e other top countries are China (17.23 percent), Republic of Korea (11 percent), and 
Canada, with 4.05 percent.







298  Information Security Management Handbook
Th ese statistics point out that this is a growing activity and increasingly used as a criminal activ-
ity to open an account, make an unauthorized transaction, obtain log-in credentials, or perform 
some other kind of identity theft. A First Data survey in 2005 revealed that over 60 percent of 
online users had inadvertently visited a spoofed site. A Consumer Reports survey indicated that 
30 percent of users had reduced their overall use of the Internet and 25 percent had discontinued 
online shopping. Where once there was trust in the major brands, as indicated earlier, this trust 
is eroding with respect to online transactions, in large part due to a lack of trust in Web sites and 
fear of identity theft.
Phishing Delivery Mechanisms
Simple Mail Transfer Protocol (SMTP) is the primary avenue of vulnerability exploitation by 
phishers due to failures within the protocol. In addition to the e-mail communication channel, 
other methods such as Web pages, messaging services, and Internet Relay Chat (IRC) are increas-
ingly being used to extract personal information. As vulnerabilities are plugged within SMTP over 
time, other methods of exploitation will emerge, because of the lucrative ﬁ nancial opportunity 
presented by phishing. Th erefore, it is critical that organizations take a proactive stance to reduce 
consumer fears that their information may be compromised. Organizations whose primary liveli-
hood depends upon the Internet for E-commerce and large banking institutions have been imple-
menting proactive education for consumers and implementing tighter controls for the past several 
years. Obviously, with the increasing number of phishing attempts previously noted, the breadth 
of organizations being phished and the type of delivery are expanding.
E-Mail and Spam Delivery Method
Th is is the most common method of delivery, by which the end user is tricked into clicking on a 
link or an attachment. Th e e-mails are meant to look legitimate, complete with the logos of the 
company and an oﬃ  cial looking e-mail address in the “Mail From:” ﬁ eld of the e-mail. Flaws in 
SMTP permit the “From” address to be spoofed, and the phisher may also put an address in the 
“RCPT To:” ﬁ eld to direct any responses to the spoofer. When the recipients of the e-mail click 
on the link included in the e-mail, they are directed to a fraudulent Web site set up by the phisher. 
Personal information is collected at the Web site to be used in further the criminal activity.
Th ese e-mails look oﬃ  cial and use language to sound like they could come from the company. 
In fact, the e-mail may be a replica of a similar notice from the organization. Th ere is usually a 
sense of urgency stated in the e-mail request for a quick response to the e-mail. Some of the e-mails 
are Hypertext Markup Language (HTML) based to hide the target URL information using diﬀ er-
ent color schemes and substituting letters, such as an I for an L, to direct the user to diﬀ erent sites. 
Th ese e-mails are often constructed in an attempt to defeat the antispam ﬁ lters by inserting ran-
dom words in a color to match the background of the e-mail so that they would not appear to the 
end user. Open e-mail relays are also utilized to hide the real source of the e-mail. Th e URL may 
point to a diﬀ erent Web site through the use of an escape coded into the HTML. Nonstandard 
ports speciﬁ ed in the URL may be clues that the phisher’s Web site is being hosted on a personal 
computer (PC) exploited by the hacker earlier.
Although most of the e-mails would direct the unsuspecting end users to a fraudulent site after 
clicking on the link, some may actually direct them to a real site. In this case, a JavaScript pop-up 

The Ocean Is Full of Phish  299
containing a fake log-in page could be used to store the credentials. Subsequently, the application 
could forward the credentials to the real application, and the user would be none the wiser.
Although most of the attacks have been through random e-mails sent to people that may or 
may not have a relationship with the company, some phishers are getting smarter and are perform-
ing spear-phishing, which is targeted phishing. In the case of spear-phishing, a group is targeted 
for their relationship. For example, employee names listed in a Web site directory may be sent a 
notice from the company’s health insurance company or credit union or another ﬁ rm known to 
provide services for the company. Additionally, as companies become larger in size and have mil-
lions of customers, there is a greater chance that their Web sites contain more information about 
their organizations in the name of customer service, as well as a greater likelihood that even a 
random e-mail will connect with someone who has a relationship with the organization.
Web-Based Delivery Method
Web sites are constructed to contain HTML links that are disguised such as in the e-mail scenarios 
noted earlier. Fake advertising banners with diﬀ erent URLs may be posted to legitimate Web sites, 
directing traﬃ  c to the phisher’s Web site. Malicious content embedded within the Web site may 
then exploit a known vulnerability within the user’s browser software and then be used to install a 
keylogger (monitors keystrokes), screen-grabber (monitors portions of the user’s input screen), back-
door (to gain control of the computer for later remote or botnet access), or other Trojan program. 
Keyloggers may be coded to intercept speciﬁ c credential information, such as the log-in information 
for certain banks. Phishers may establish an online account, use a fake banner pointing to a fake 
Web site, all with a stolen credit card and other bank information obtained to cover their tracks.
IRC and Instant Messaging Delivery Method
Communication in the instant messaging area makes it possible for the end user to fall victim to 
the same techniques used in other delivery methods. Embedded dynamic content is permitted in 
these clients, which can also point to other links that would point to ﬁ ctitious Web sites.
Trojaned Host Delivery Method
PCs that have been previously compromised may act as a delivery mechanism for sending out 
phishing e-mails, which makes tracking the originators of the phishing scams very diﬃ  cult. 
Although antivirus software can help with the reduction of the risk of Trojans, it is becoming 
increasingly diﬃ  cult. Home users are often tricked into installing software as an upgrade that 
provides the ability for the PC to be controlled at a later date.
Phishing Attacks
Man in the Middle
In this type of attack, the attackers insert themselves in between the consumer and the real appli-
cation, capturing the credentials along the way. Th e end user may have a false sense of security 
by relying on the HTTPs, as the man-in-the-middle attack could set up a secure communication 

300  Information Security Management Handbook
path between the hacker’s server and the customer and subsequently pass the information to the 
real Web site. While the phisher remains in the middle, all transactions can be monitored. Th is 
can be accomplished by multiple methods, including transparent proxies, Domain Name System 
(DNS) compromises, URL obfuscation, and changing the browser proxy conﬁ guration. Trans-
parent proxies reside on the network segment on the way to the real Web site, such as a corporate 
gateway or an intermediary Internet Service Provider (ISP). Outbound traﬃ  c can then be forced 
through the proxies, which would deliver the information back to the consumer unnoticed. DNS 
caches can also be poisoned to point certain domain names to diﬀ erent Internet Protocol (IP) 
addresses controlled by the phisher. Th e cache within a network ﬁ rewall could redirect the pack-
ets bound for the real Web site to that of the attackers. Th e DNS server itself could also be com-
promised, as well as the local host’s ﬁ le on the user’s PC ahead of receipt of the phishing e-mail. 
Th e browser proxy can also be overridden to proxy the traﬃ  c for, say, the HTTP port, to a proxy 
server. Th is involves changes on the client side and may be noticed by the end user by reviewing 
the setup. Many users, however, would not be actively looking at those controls and there is a 
high likelihood that the controls would be named something that would sound technical, making 
noticing them diﬃ  cult.
Man-in-the-middle attacks are particularly troublesome, as the end users think they are inter-
acting with a trusted entity when executing transactions with a trusted bank, online shopping 
storefront, or service provider; meanwhile, their identity is being captured for later exploitation.
URL Obfuscation Attacks
URL obfuscation involves minor changes to the URL and directing the consumer to a diﬀ erent 
Web site. Th ere are multiple techniques for changing the URL to make it appear as though the 
user is being directed to a normal Web site.
Th e ﬁ rst technique leverages bad domain names to appear like the real host, although in real-
ity these are domain names that are registered by the phisher. For example, a ﬁ rm with the name 
Mybrokerage.com may have a transaction site named http://onlinetrading.mybrokerage.com. Th e 
phisher could set up a fraudulent server using one of the following names:
http://mybrokerage.onlinetrading.com
http://onlinetrading.mybrokerage.com.ch
http://onlinetrading.mybrokerage.securesite.com
http://onlinetrading.mybrokerage.com
http://onlinetrading.mybrokeráge.com
In the foregoing examples, the name was varied, extensions were added, words were misspelled, or 
diﬀ erent character sets were used. To the average user, the URL looks like a valid site.
Th ere are also third-party services that shorten URLs to make entry easier. Th ese sites map 
other URLs to their shorter ones to make entry by the user easier. Th ese sites can also be utilized 
by phishers to hide the real site.
Friendly log-in URLs are another method by which the user can be deceived. URLs can include 
authentication information, in the format of URL://username:password@hostname/path. To trick 
the end user, information would be placed in the username and password ﬁ elds to resemble the 
company Web site while directing the user to the host-name Web site, which is managed by the 
phisher. In the preceding example, the URL may look like http://mybrokerage.com:etransaction






The Ocean Is Full of Phish  301
@fakephishersite.com/fagephisherpage.htm. Several browsers have dropped support of this 
method of authentication due to the success it has had in the past with phishers.
Th e host name can also be obfuscated by replacing it with the IP address of the fraudulent Web 
site. Another technique is the use of alternate character set support, which is supported by many 
browsers and e-mail clients. Escape encoding, Unicode encoding, inappropriate UTF-8 (8-bit 
UCS/Unicode Transformation Format or variable length encoding for unicode) encoding, and 
multiple encoding are all techniques for representing the characters in diﬀ erent ways.
Other Attacks
Cross-site scripting attacks are another method by which the attacker can utilize poorly written 
company Web site code to insert an arbitrary URL in the returned page. Instead of returning the 
expected page for the application, the attacker returns a page that is under the control of their 
external server.
Preset session attacks make use of a preset session ID, which is delivered in the phishing 
e-mail. Th e attacker then polls the server continuously, failing as the session ID is not valid. When 
the end user authenticates using the session ID, the application Web server will allow any connec-
tion using the session ID to access the restricted content, including the attempts by the attacker.
Each of these methods for obfuscation can be combined with others, making it even more dif-
ﬁ cult to identify when the URL is being used to direct traﬃ  c to a fraudulent Web site.
Educating Consumers
Educating consumers about the dangers of phishing is a delicate balance. On the one hand, con-
sumers need to be vigilant in not responding to e-mails with links to sites requesting their personal 
information; on the other hand, consumers should not be afraid to participate in online com-
merce and use e-mail wisely. Many banking and E-commerce sites have included information on 
phishing on their Web sites in an eﬀ ort to reduce the risks. According to the National Consumers 
League Anti-Phishing Retreat conducted in 2006, there should be more consumer education, pos-
sibly included with new PCs, and ISP-supported pop-ups to warn users of risky URLs. Th ey also 
proposed that technical staﬀ  should be made better aware of the legal and law enforcement sides 
of the issue, as well as law enforcement and legal staﬀ s understanding the technical side.
Phishing has become so prevalent that the Federal Trade Commission (FTC) issued a con-
sumer alert in late 2006 advising consumers how not to get hooked by a phishing scam. Th e key 
points from the FTC included the following:
If you get an e-mail or pop-up message that asks for personal or ﬁ nancial information, do 
not reply. And do not click on the link in the message, either.
Area codes can mislead (and may not be in your area due to Voice-over-IP technology).
Use antivirus and antispyware softwares, as well as a ﬁ rewall, and update them all.
Do not e-mail personal or ﬁ nancial information.
Review credit card and bank account statements as soon as you receive them.
Be cautious about opening any attachment or downloading any ﬁ le from e-mails.
Forward spam that is phishing for information to spam@uce.gov and to the bank or com-
pany that was impersonated with the e-mail.
If you believe you have been scammed, ﬁ le a complaint at www.ftc.gov.









302  Information Security Management Handbook
Technical Approaches to the Problem
Educating consumers is one avenue to combat the growing problem; however, the entire burden 
cannot be on the consumer. Several technical approaches are in process to address the issue.
Inbound Spam Filters
Th e most common method of assisting the end user is to restrict the e-mail that is coming in 
through the ISP or the organization through anti-phishing or antispam ﬁ lters. Th ese ﬁ lters uti-
lize IP address blacklists, Bayesian content ﬁ lters (examining the semantic diﬀ erences between 
legitimate messages and spam messages), heuristics (examining the ways that the URL may be 
incorporating the names of the institution), and URL list ﬁ ltering. Each of these techniques needs 
to be consistently evaluated to determine the success rate, as the hosts are constantly changing, as 
are the URL speciﬁ cations.
Protect the Desktop
Implementation and maintaining currency of antivirus protection, spyware detection, antispam 
ﬁ ltering, and personal ﬁ rewalls or intrusion detection systems are essential in protecting the desk-
top from unwanted changes. Products by the major desktop security vendors typically support 
one or more of these functions. Speciﬁ cally, the desktop software must be able to block attempts 
to install malicious software; identify and quarantine spam; update the latest antivirus, antispam, 
and antispyware signatures and apply from the Internet; block unauthorized outbound connec-
tions from installed software; identify anomalies in network traﬃ  c; and block outbound connec-
tions to suspected fraudulent sites.
Although multiple products provide a defense-in-depth strategy for the desktop, they can also 
become quite expensive and complex for the typical end user. Th ere is usually a subscription fee 
after the initial implementation and a reliance on the end user to renew the subscription. In orga-
nizations, the desktops are managed and this is not a consideration for internal users; however, 
with trust in the organization resting with the end-user experience, these costs and approaches 
must be understood.
Removal of HTML E-Mail
Plain-text e-mail communications could be utilized to reduce the ability to hide the actual URL 
the user is directed to in the e-mail. Th ese e-mails would not look nice; however, the security 
would be improved.
Browser Enhancements
Enhancements have been placed into the browser software to check against a list of known phish-
ing sites. Microsoft’s Internet Explorer version 7 browser and Mozilla Firefox 2.0 contain this 
functionality. Users can also take further actions such as disabling window pop-up functionality, 
Java runtime support, ActiveX support, and multimedia and autoplay or autoexecute extensions 
and preventing storage of nonsecure cookies. However, these actions may increase security, but 
may degrade the online experience for the end user as well. Other approaches permit the user to 

The Ocean Is Full of Phish  303
create a label for a Web site that they recognize, so they have a reliable method of returning to the 
Web site (Firefox petname extension).
Stronger Password Log-Ons
Several banking Web sites have implemented the showing of a user-selected image (animal, scenery, 
hobby) prior to the entry of the password. In the event the end user does not recognize the image, 
they are not to provide the password. Th is is an attempt to assure the end user, by presenting them 
with the image they selected, that they are on the correct Web site. Th e phisher would not have 
knowledge of the appropriate image to show the consumer.
Stronger authentication may be necessary to positively identify the users to the real Web site, 
so that retrieval of the username or password information has limited value. Some of these solu-
tions can be expensive, such as issuing two-factor authentication tokens to millions of consumers 
for an organization. Th is approach introduces added complexities by the fact that individuals have 
relationships with multiple organizations and would potentially be carrying multiple devices.
Final Thoughts
Th ere is no silver bullet to resolve the phishing criminal activity. Th ere is much ﬁ nancial gain to be 
made without needing to use physical force, making this an attractive option for criminals. Th ere 
are multiple known delivery methods, attack vectors, and solutions to help minimize the risk. 
Organizations must be vigilant in their education of internal and external customers, the design 
of secure software, the maintenance of appropriate patch levels, and providing a phishing report-
ing and remediation capability and must remain continuously aware of the techniques and threats 
related to this type of attack. As consumer conﬁ dence decreases through personal experiences of 
identity theft, excessive e-mails impersonating the company, or a perceived lack of attention to the 
issue, they will stop doing business with the organization. Th e ocean is full of phish, some bite, 
some do not, but it only takes a few to take the bait to disrupt the ecology. Our organizations must 
educate and implement the technical approaches necessary to protect the ecology of our business. 
Further Readings
Anti-Phishing Working Group, Phishing Activity Trends Report for the Month of January, 2007, http://www.
antiphishing.org.
Anti-Phishing Working Group (APWG)/Messaging Anti-Abuse Working Group (MAAWG), Anti- Phishing 
Best Practices for ISPs and Mailbox Providers, July 2006, Washington, D.C.
Federal Trade Commission, Consumer Alert: How Not to Get Hooked by a “Phishing” Scam, October 2006, 
Washington, D.C.
National Consumers League, A Call for Action—Report from the National Consumers League Anti-Phishing 
Retreat, March 2006, http://www.nclnet.org.
NGS Software Security Insight Research, Th e Phishing Guide, Understanding and Preventing Phishing 
Attacks, 2004, http://ngsconsulting.com.
PayPal, Recognizing Phishing, http://www.paypal.com.
U.S. Department of Homeland Security/SRI International Identity Th eft Technology Council/Anti-
 Phishing Working Group, Th e Crimeware Landscape: Malware, Phishing, Identity Th eft and Beyond, 
October 2006, Washington, D.C.
Wikipedia, Phishing, http://en.wikipedia.org/wiki/Phishing.


DOMAIN
  
7
APPLICATION 
SECURITY
Application Issues


307
Chapter 24
Neural Networks and 
Information Assurance Uses
Sean M. Price
Contents
Introduction ............................................................................................................................ 308
Inspiration .............................................................................................................................. 309
Architectures ............................................................................................................................311
Algorithms ...............................................................................................................................313
Functional Characteristics .......................................................................................................314
Th e Concept of Learning .........................................................................................................315
Capabilities ..............................................................................................................................317
Training Considerations ..........................................................................................................318
Data Features ..................................................................................................................318
Data Cleanliness and Accuracy .......................................................................................318
Over- and Undertraining ................................................................................................319
Local Minima ................................................................................................................ 320
Typical Application Controls ...................................................................................................321
Training Sets...................................................................................................................321
Validation Sets ................................................................................................................321
Test Sets ..........................................................................................................................321
Learning Rate ................................................................................................................ 322
Momentum .................................................................................................................... 322
Bias ................................................................................................................................ 322
Learning Stop Points ..................................................................................................... 322
Demonstrated Usage ............................................................................................................... 322
Security-Relevant Applications ............................................................................................... 328

308  Information Security Management Handbook
Potential Applications ............................................................................................................. 330
Conclusion .............................................................................................................................. 330
References ................................................................................................................................331
Introduction
Computers are wonderful tools that can be used to automate numerous manual processes. Large 
and complex calculations that could take an individual a lifetime to solve are trivial for a machine 
with suﬃ  cient memory and processing speed. In this respect, the eﬀ ort of one superhuman task is 
easily accomplished in a reasonable amount of time by a computer. However, this vast processing 
capability does not easily give rise to the ability of a machine to learn, think, or reason. Human 
tasks involving intelligence, such as the ability to diﬀ erentiate or identify complex patterns, are 
not easily accomplished with computers. Th e eﬀ orts of security practitioners could be reduced or 
simpliﬁ ed through the automation of activities that require intelligent thought. Machines with 
the ability to learn about simple problems and identify correct solutions could allow the security 
practitioner to focus on more complicated security issues. Th e ability of a machine to display intel-
ligent behavior is commonly known as artiﬁ cial intelligence.
A large body of research currently exists for artiﬁ cial intelligence. Th is ﬁ eld has several cat-
egories that describe the specialized techniques for achieving machine intelligence. Major divi-
sions within the ﬁ eld of artiﬁ cial intelligence include expert systems, fuzzy logic, evolutionary 
algorithms, emergent behavior, and artiﬁ cial neural networks. Expert systems provide users with 
answers or options to domain-speciﬁ c problems. Th ese systems usually contain a database of 
knowledge obtained from human experts. Fuzzy logic makes judgments on imprecise information 
to derive an appropriate solution. Th is type of artiﬁ cial intelligence can be found in control systems 
and robotics. Evolutionary algorithms employ mutations within a computation to discover the best 
or most ﬁ t solution to a problem. Th ese types of algorithms are typically based on concepts found 
in genetics and are used for optimization problems. Emergent behavior, also known as swarm 
intelligence, occurs when communities of autonomous entities, such as ants, bees, schools of ﬁ sh, 
or ﬂ ocks of birds, discover solutions to problems through cooperation. Th e application of emergent 
behavior is useful for solving optimization problems such as ﬁ nding the shortest path between two 
points. Artiﬁ cial neural networks (or simply neural networks) are a biologically inspired technique 
used to solve a host of problems. Th is aspect of artiﬁ cial intelligence has the capability to learn, 
memorize, and predict patterns. Neural networks are designed, in principle, to emulate the func-
tionality of the human brain. In this respect, neural networks have the potential to provide the 
security practitioner with an artiﬁ cially intelligent application that could handle simplistic and 
recurring activities that might normally require the decision process of a human.
Th ere are several characteristics about neural networks that make them strong candidate 
implementations for security practitioners. First, neural networks are adaptable. By deﬁ nition neu-
ral networks have a capability to learn. Th is means that they can change their behavior to match 
an environment during the learning process. Th is is very helpful in a constantly changing threat 
environment. Second, most neural network implementations have a nonlinear analysis capability. 
Th is strength allows a neural network to ﬁ nd solutions to problems without reliance on a known 
algorithm. In essence, it can discover a solution to a problem that might require a complex algo-
rithm. Th is implies that a security problem might be solved without the need to wait for a vendor 
update. Neural networks are also noise tolerant. Th ey can learn or discern answers in the presence 
of noise. A neural network has the ability to sort through ordinary noise and ﬁ nd patterns related 

Neural Networks and Information Assurance Uses  309
to security issues. Last, they are fault tolerant. If a portion of a neural network becomes corrupt it 
can still manage to perform the necessary tasks. Fault tolerance is a desirable property for distrib-
uted security implementations.
Fundamentally, neural networks are a collection of algorithms. Implementations of these spe-
cialized algorithms can be found in software packages as well as hardware (Gadea et al., 2000). 
Conceptually, neural networks comprise an architecture and algorithms. Th e architecture refers 
to how the input data is transformed through interconnections to derive an output. From a more 
simplistic viewpoint, the architecture is a map or graph of data ﬂ ow through the network. A neu-
ral network is ﬁ rst and foremost a mathematical graph (Jordan and Bishop, 1996). Th e structure 
of the graph deﬁ nes data-ﬂ ow direction and transformation. Th ere are two principle algorithms 
used in neural networks. First, an algorithm is used to apply weights between nodes, which are 
transformed by an activation function resulting in a subsequent output. Th e activation function 
is the key feature of the logical operations within the architecture. Th e second algorithm, called 
the learning algorithm, gives rise to the network’s ability to adapt to the input and resolve a 
desired output. Whereas the activation function simply transforms an input into an output, the 
learning algorithm evaluates the output according to the input and makes appropriate changes 
to the internal weights in an eﬀ ort to derive a better or more correct output. Th e architecture, 
activation function, and learning algorithms are the main features of neural networks that dic-
tate their implementations and capabilities.
Inspiration
Neural networks are designed to mimic the structure and operations of neurons within the human 
brain. Scientists continue to learn new aspects about the operation and functions of the human 
brain. Neural networks represent an approximation of functional activity of the human brain. 
Some physical characteristics and theorized operational aspects of the brain are implemented in 
neural networks. Th e outer layer of the brain, known as the cortex, is made up of billions of 
specialized cells known as neurons. Th ese cells form complex networks that give rise to thought, 
reason, and, arguably, consciousness in humans. Th e cells communicate with one another through 
biochemical reactions. Th e interactions and individual neuron processing of these communica-
tions occur through small.
A neural network represents a computation method. It should not be confused with an infor-
mation technology (IT) network. Whereas an IT system consists of devices and applications com-
municating over a medium, a neural network is a method of combining discrete computations. 
Although a neural network might take advantage of distributed computing, it is not predicated 
upon it. Typically, a neural network is implemented within a single machine.
A biological neuron is composed of three principle parts known as dendrites, soma, and axon. 
Figure 24.1 provides a rough drawing of what a human neuron looks like. Dendrites receive chem-
ical stimuli from the axons of hundreds or thousands of other neurons. Signals received by the 
dendrites are then propagated to the soma or neural cell body. Th e soma reacts to the level of input 
received by summing all the stimuli received. Insuﬃ  cient stimulus causes no change in the state 
of the soma. However, if the stimulus received is high enough the soma will create a small electric 
discharge of pulses down the axon. Th is discharge results in a biochemical reaction between the 
axon and other dendrites in close proximity to it. Th e space between the axon and an associated 
dendrite is called the synapse. Essentially, dendrites act as input to a processing center, the soma, 
which provides an output through the axon depending on the total stimulus received. Th ese are 
the basic properties of a human neuron.

310  Information Security Management Handbook
Artiﬁ cial neurons capitalize on the basic aspects of the biological neurons. Th e artiﬁ cial neuron 
contains a number of inputs, a summation point, and an output. Figure 24.2 shows an example of a 
basic artiﬁ cial neuron. From this ﬁ gure we can see that a number of inputs are connected to a central 
node that provides an output. Each of the links between the input and the node are weighted. Indi-
vidually, the weights on each link are used to identify the importance of a given input. Larger weights 
signify an input that is more signiﬁ cant in determining the output. Th e input values and the weights 
are combined at the node and fed into an activation function. Th is function compares the weighted 
input with a predetermined threshold and outputs a value according to the speciﬁ cs of the function. 
Soma
Dendrites
Axon
Figure 24.1 Biological neuron.
Summing point
Input
Output
Activation function
f
Figure 24.2 Artiﬁ cial neuron.

Neural Networks and Information Assurance Uses  311
Typically, this value will be 0, negative 1, positive 1, or some other real number. In general a value 
of 0 or less indicates that the weighted input did not meet a particular threshold, whereas a value of 
1 or more signiﬁ es a properly weighted input.
Architectures
Th e architecture of a neural network refers to the actual method by which nodes are connected.
A network comprises nodes and links. Nodes can be inputs, computation points, or outputs. 
 Usually, inputs simply introduce the data to the network. Computation points summarize the 
value of the input combined with any weights associated with a given link. Th ese points also 
contain an activation function that determines their output. A computation point can act as the 
output for the network or feed the results into another layer of nodes performing computations. 
Output nodes can also perform some computations. Usually, they only combine the results passed 
to them by the computation nodes in the preceding layer. Links between nodes provide logical 
connectivity between nodes and also hold the weight values used for network learning. It is impor-
tant to note that interconnection of nodes and links inﬂ uences the function of the network and 
how it learns.
Th e artiﬁ cial neuron in Figure 24.2 is also referred to as a single-layer neural network. Th is 
type of network simply connects inputs to a layer of outputs after the application of weights and 
the activation function (Russell and Norvig, 2003). An example of a more extensive single-layer 
neural network is seen in Figure 24.3. Th is ﬁ gure also shows that a neural network can have mul-
tiple outputs. Each output could be any real number. It is important to remember that the output 
is a mathematical representation of the input combined with a set of weights.
Generally, neural networks are designed such that they are fully connected. Th is means that 
each node at a given layer has a link with each node at the subsequent layer. Computations propa-
gate from one layer to the next until they reach an output. Th is concept is known as feedforward. 
Input
Neuron
Output
Figure 24.3 Single-layer neural network.

312  Information Security Management Handbook
Most neural network implementations are feedforward multilayer networks similar to the one 
depicted in Figure 24.4. In this conﬁ guration each layer of nodes between the input and the output 
is known as a hidden layer. Figure 24.4 has one hidden layer, whereas Figure 24.5 has two.
Multilayer neural networks are capable of modeling nonlinear data. Th us, they can ﬁ nd solu-
tions that produce complex curves. Multilayer networks are perhaps the most common type of 
neural network implementations. Increasing the number of hidden layers allows the network to 
model more complex data. However, this also greatly increases the computation cost with respect 
to time. In most cases, not more than three layers are used in practice (Negnevitsky, 2005).
Input
Hidden layer
Output
Figure 24.4 Multilayer neural network.
Input
First hidden layer
Second hidden layer
Output
Figure 24.5 Neural network with two hidden layers.

Neural Networks and Information Assurance Uses  313
Th e number of nodes in a layer also aﬀ ects the ability of the network to approximate a solution. 
If there are not enough nodes then the solution is likely to be too general and misclassiﬁ cation will 
occur. If there are too many nodes in a given layer then overgeneralization may occur, which can 
cause the network to respond strongly to test data points and too weakly to other inputs.
Some types of neural networks have the ability to reproduce patterns from a given classiﬁ ca-
tion. In other words, the neural network has the ability to recall a pattern as opposed to simply rec-
ognizing it. Th ese types of neural networks are known as recurrent networks. Th e distinguishing 
feature of recurrent networks is their feedback mechanism. Th is requires a specialized algorithm 
that is diﬀ erent from those associated with the previous ﬁ gures. Generally speaking, a recurrent 
network is said to possess an autoassociative memory or pattern storage capability.
Algorithms
Th e architectures from the earlier section provide a graphical representation of how a neural net-
work can be connected. However, this is only half of the story. An algorithm is needed to direct 
how the values and weights are computed and propagated within the architecture. Some of the 
more common algorithms include back propagation, support vector machines, radial basis func-
tions, and self-organizing maps.
Back propagation is perhaps the most popular neural network algorithm. Th e algorithm begins 
with initializing the weights with random values. Th en training data is applied to the input. For 
each input node a computation is made forward through the network to each succeeding node. 
Once the output is reached, the diﬀ erence between the computed and the desired values is com-
puted as the error. Th is error is then propagated back through the network, changing the weight 
values according to the learning rate and momentum constants. New iterations are conducted for 
subsequent training data and the process continues with forward computations and backward 
error corrections.
Radial basis functions are limited to three layers architecturally. Th e hidden layer of the net-
work utilizes a nonlinear function, but the output layer is linear. Th e activation function computes 
the Euclidean distance between input vectors as the means of learning.
In contrast to the nonlinear nature of the back-propagation algorithm, the support vector 
machine makes use of hyperplanes to categorize data and is, therefore, a linear machine. Essen-
tially, a nonlinear feature space is created from the original data with multiple dimensions in 
which a hyperplane can be drawn to separate the data.
In a self-organized map, neurons are organized in a one- or two-dimensional architecture. 
Learning occurs as a competition between neurons as opposed to an assignment of weights. 
 Neurons compete with each other to be activated. Th ose that are activated and their associated 
neighbors are ordered to create a type of topographical map, which reveals patterns in the data.
Numerous specialized algorithms exist. Many of these are simply variations of the previously 
mentioned algorithms. It is important to note that the algorithm is designed to support the archi-
tecture implemented. Th us, we would not see a back-propagation algorithm-supporting recur-
rent network because it does not support the structure. Indeed, the converse is true with respect 
to algorithms designed to support recurrent networks. Neural network algorithms supporting 
the same type of architecture are usually diﬀ erentiated by their learning abilities or convergence 
speed.
Th e remainder of this chapter focuses primarily on the general multilayer feedforward archi-
tecture using the back-propagation algorithm.

314  Information Security Management Handbook
Functional Characteristics
Neural networks are essentially specialized statistical models. Th ey take a numeric input and 
produce a numeric output. Th e output will depend on the type of activation function used as 
well as the intended properties of the output. Many diﬀ erent types of activation functions have 
been proposed but, in practice, the most popular are the step, sign, sigmoid, and linear functions 
(Negnevitsky, 2005). Th e step, sign, and linear functions are used to ﬁ nd solutions to problems 
that can be bound by a region. Sigmoid functions are used to ﬁ nd nonlinear solutions.
As an example, Figure 24.6 shows a solution to a categorization problem that divides the data 
into two regions using a single line. Th is means that for any input into the neural network, the 
output will be within one of the two regions.
Figure 24.7 is an example of a solution to a bound-region problem. A neural network can be 
trained to identify a bounded region of data. It is not always possible to identify the data fully 
with the appropriate category. Substandard categorization or classiﬁ cation results in errors in the 
network.
In some instances the separations between data categories are not easily obtained with a straight 
line. In this case the neural network used must have a nonlinear capability to ﬁ nd the solution. 
Figure 24.8 shows a categorization problem with a nonlinear solution. It is important to note that 
a nonlinear solution is just as susceptible to errors as  is a linear solution.
Each connection between the inputs, the hidden layers, and the output has an associated 
weight. Th e weight is used to indicate the importance of an individual link. Essentially, links that 
are the least important have smaller weights, whereas those that contribute more signiﬁ cantly to a 
desired outcome are more heavily weighted. Th e values of each input are multiplied by their associ-
ated weights with the results from all the inputs being summed together. Th is total amount is then 
processed by the transfer function and compared to a threshold value. Any diﬀ erence between the 
threshold and the value computed by the transfer function produces an error value. Any error at 
the output node is used to adjust the internal weights in an attempt to reduce the error. Th e neural 
network algorithm implemented speciﬁ es how weights are to be adjusted to reduce this error dur-
ing the learning process.
Figure 24.6 Linear categorization.

Neural Networks and Information Assurance Uses  315
Th e numbers of inputs, hidden layers, and outputs, as well as their connectivity, are selected to 
solve a speciﬁ c type of problem. How these components are connected represents the architecture 
of the network.
The Concept of Learning
Biological organisms can learn a task or concept by observation and experimentation. Learning 
through observation means that an entity watches something with the explicit purpose of repeating 
the task or identifying with the concept. An example is a student in a class. Th e instructor explains 
Figure 24.7 Linear bound region.
Figure 24.8 Nonlinear categorization.

316  Information Security Management Handbook
a concept and the student learns by internalizing it. Young creatures learn from adults by watching 
them perform a task. In this way knowledge is transferred from a teacher to the learner. We can 
consider this form of learning as supervised learning. Learning through experimentation involves 
a biological entity that attempts to approach a problem or situation through trial and error. Th e 
organism tries diﬀ erent strategies until the solution materializes. In the human realm many of us 
have experienced this with the famed Rubik’s cube puzzle. Aside from reading a manual, a person 
can learn tricks or strategies on his or her own to ﬁ nd the best solutions for rotating the puzzle to 
get the same colored blocks on the appropriate side. Th is form of learning is considered unsuper-
vised. In this respect there is no teacher available to specify a strategy for solving the puzzle, as it 
is learned independently and based on trial and error.
Learning within a neural network is not exact. Th is means that the process of learning takes 
much iteration and yet might not result in a perfect answer or solution. Some amount of error 
is still likely to exist because of the statistical nature of the neural network algorithm employed. 
Neural networks learn by adjusting their weighted links. However, inexactness and errors are 
advantages for neural networks. In this sense inexactness means the network has learned a gener-
alized answer to a problem. A network that is properly generalized will provide more consistent 
responses to input data than one that is over generalized or too speciﬁ c.
Neural networks learn through supervised and unsupervised means. With supervised training 
the network learns through examples. Th e examples teach the network about the input and the 
expected output. In this respect the learning is considered to be controlled or supervised, similar to 
a student in a class. In contrast, with unsupervised learning the network independently attempts 
to discover patterns or features in the data introduced. Th e network looks for features in the data 
and then attempts to organize them, much like an individual solves a Rubik’s cube. Unsupervised 
networks tend to learn more quickly than those that are supervised (Negnevitsky, 2005).
Supervised training speciﬁ es the input data and the desired output for the network. Under this 
type of training a portion of the data to be tested is set aside to train the network. Th e data set 
aside is further subdivided into two groups. One group is referred to as training data and the other 
is called validation data. Training data is used to teach the network about the entire data popula-
tion. It should be a representative sample of all of the patterns or classes desired to be learned. 
Validation data is used to ensure that the error threshold is not exceeded when nontraining data 
is evaluated by the neural network. Validation errors exceeding an established threshold typically 
result in subsequent retraining of the network.
Th e neural network learns by adjusting the internal weights on the links between the input, 
the nodes, and the output until the diﬀ erence between the training data values and the outputs is 
suﬃ  ciently low. Th e aggregate of the squared errors, known as the sum of the squared errors, is the 
criterion implemented for evaluating the learning error, especially with the back-propagation 
training algorithm (Negnevitsky, 2005). Th e network is said to have converged when the sum 
of the squared error for the training data is equal to or less than the predetermined threshold set 
by the analyst. Th e back-propagation algorithm is the most popular supervised training algorithm 
used with feedforward multilayer networks (Negnevitsky, 2005). Th e algorithm takes the error at 
the output and adjusts the weights between each node from the output back through the hidden 
layers to the input.
Unsupervised learning, also known as self-organized learning, utilizes rules on how to evaluate 
the input data to discover unique features. Th ese features comprise the classiﬁ cations that arise 
from the data. One of the strengths of unsupervised learning networks is the ability to learn in real 
time (Negnevitsky, 2005). Two examples of unsupervised learning techniques include  Hebbian 
and competitive learning. With Hebbian, learning weights into a particular node are adjusted 

Neural Networks and Information Assurance Uses  317
based on their associations with other nodes that result in the activation of the immediate node. 
Synchronous activations cause an increase in the weights, whereas asynchronous activities result 
in a decrease. In contrast, competitive learning allows only one node to be active, which is why it 
is referred to as the winner-takes-all neuron (Negnevitsky, 2005).
Capabilities
Th e central property of neural networks is their ability to learn. Th is capability distinguishes them 
from the other forms of artiﬁ cial intelligence. Th is ability gives rise to other useful aspects due to 
their statistical strengths, which include pattern matching, prediction, and memory.
Pattern recognition, also known as pattern classiﬁ cation, is perhaps the most common imple-
mentation of neural networks. A neural network can be trained to remember multiple patterns. 
Pattern recognition is also called pattern matching. Th e true nature of a neural network with 
 pattern-recognition capability is not to identify discrete patterns, but to make approximations 
of the input and produce an output classiﬁ cation. Each pattern learned is identiﬁ ed as belong-
ing to a particular class. A neural network produces a unique output for a known pattern. 
A pattern- classiﬁ cation neural network will usually produce one of the following outputs from 
an input pattern:
 
1. Th e input pattern is recognized as belonging to a previously trained class.
 
2. Th e input does not match any previously known class.
 
3. Th e input is too diﬃ  cult to recognize.
Consider a network that is trained to recognize circles, triangles, and squares. Each shape repre-
sents a unique class to be learned by the network. Prior to training, unique features about each 
shape would be selected and used to train the network. Assume that the training features selected 
for the network recognize each shape regardless of its size. For any input the neural network will 
either identify the input as belonging to one of the previously trained classes (shapes) or return 
an output that says it is not one of the known classes. Suppose that an oval and a rectangle are 
introduced to the network as input at diﬀ erent times. Although an oval is a type of circle and a 
rectangle is very similar to a square, the network might not recognize either shape as belonging to 
a previously trained class. Although the shapes have similarities to the known classiﬁ cations, they 
might be too diﬀ erent for the neural network to recognize. If it was necessary to include either of 
these objects as one of the known shapes to be recognized, then a new set of features would need 
to be considered for training. Th is illustrates the point that feature selection is the ﬁ rst and the 
most important step in pattern matching (Haykin, 1999). Selecting the wrong amount or type of 
feature to train a network will yield less than optimal results.
Function approximation is an important capability of neural networks. Appropriately trained 
neural networks are capable of estimating an output based on a given input. Th is capability is 
possible due to the inherent statistical capabilities of neural networks, but is strongly inﬂ uenced 
by the architecture and training methods employed. Function approximation is most readily 
seen by training a network to associate numerical input with a numerical output. In this respect 
the network statistically infers a formula (function) whereby a given input results in a particular 
output. Th e inferred formula represents a particular class that the neural network is trained to 
recognize. Feedforward neural networks are commonly used for this purpose. Given this use and 
capability it is easy to understand why such neural networks are recognized as universal approxi-
mators (Haykin, 1999).

318  Information Security Management Handbook
Neural networks can also be used to make predictions or forecasts. Predictions can be a par-
ticular value, class, or pattern depending on the trained inputs and outputs. Th is capability is 
closely related to function approximations. A prediction is an output based on a previously untried 
input. To make a prediction the input data would need to fall into a previously trained classiﬁ ca-
tion. Approximate predictions are possible as long as the response of the neural network is well 
generalized. Th is means that the trained network should make smooth transitions from one train-
ing point to another. A neural network that is well generalized will make valid predictions within 
a margin of error close to the data used to train the network.
Training Considerations
Preparing for a neural network implementation requires some level of planning with respect to 
training. Important points of consideration include aspects of the data and the training process 
itself. Although selecting the right data might seem obvious, it should not be considered a trivial 
task. Likewise there are several aspects to actual training that also need to be considered.
Data Features
Given that neural networks are statistical models the data processed must be in a numerical form. 
Some software packages will transform text or other types of data automatically, but this might not 
be the most optimal for a given problem. Th e analyst must decide how best to represent the data. 
Arguably, if the data can be decomposed into a binary representation, that is 1’s and 0’s, this would 
potentially provide the best responses for pattern-matching problems. It is not always possible to 
use binary representations, in which case any real number could potentially be used to represent 
the input data item or feature. However, this can prove problematic. Th e analyst could inadver-
tently select numerical representations that accidentally teach the neural network something that 
was not intended. Th erefore, nonnumeric feature substitution must be done carefully and subject 
to retraining to ensure that the network does not learn something unintentionally. Ideally, select-
ing the smallest number of features that discriminate one data class or pattern from another while 
allowing overall generalization and noncontradicting is the best approach (Pendharkar, 2005). 
A small set of features allows the network to train faster. Likewise, dissimilar features also help the 
neural network to recognize distinct patterns more readily. Th e farther apart training data points 
are from one class to the next, the better the network will learn the distinction between them.
Data Cleanliness and Accuracy
Only data that is known or intended to represent a particular feature for classiﬁ cation should be 
learned by the network. Neural networks possess a keen ability to discern patterns in the presence 
of noise (Padhy, 2005). However, too much noise in the data can unintentionally cause the network 
to learn aspects of the noise instead of the actual data. Th erefore, it is important to reduce or remove 
noise from the training data where possible (Yu et al., 2006). Likewise, it is imperative in the case of 
pattern matching that classiﬁ cation identiﬁ cations are valid. For instance, if a network is trained to 
recognize a known vulnerability as something that is allowed or valid, then the network will con-
tinually misclassify the item. Furthermore, any new vulnerabilities emerging based on the original 
miscategorization will probably also be identiﬁ ed by the neural network as valid. Th erefore, it is criti-
cal that training and validation data be properly categorized and as free from noise as possible.

Neural Networks and Information Assurance Uses  319
Over- and Undertraining
A well-trained neural network is said to generalize well. Th is means that for any input within a known 
classiﬁ cation an output is reproduced that closely represents a function ﬁ tting the data. Th e amount 
of training aﬀ ects the generalization of the network. With too little training the output will not 
closely represent the desired results. In the case of overtraining, the network learns too closely train-
ing data that might cause it to not respond well to the validation or test data. Consider the example 
classiﬁ cation shown in Figure 24.9. Here we see two classes separated by a function that curves.
Suppose that an insuﬃ  cient number of training epochs are conducted. Th is might result in an 
output similar to Figure 24.10. Th is can be easily seen by an analyst if a graphical representation of 
Figure 24.9 Desired output.
Figure 24.10 Undertraining.

320  Information Security Management Handbook
the desired output is known. From the ﬁ gure we can see that the shape of the function separating 
the two classiﬁ cations is not well formed. In this case the network is too general and needs more 
speciﬁ c training.
Sometimes a network can undergo too many training epochs. In this case the output 
could be similar to that seen in Figure 24.11. Note that the network has very closely matched 
the test points and the output is very jagged. Th e function output is not smooth and is not 
generalized.
In either case of over- or undertraining it is possible for misclassiﬁ cations or poor predictions 
to occur. Additionally, the function represented by the output will not be a good approximation 
of the underlying formula. Th erefore, the amount of training can signiﬁ cantly aﬀ ect the perfor-
mance of a neural network. When we consider the analyst’s involvement with training neural 
networks, it is helpful to represent the desired output and the actual outputs graphically to ensure 
that under- or overtraining has not occurred.
Local Minima
Th e learning process for neural networks involves the determination of the best values for weights 
applied to the input that will most closely ﬁ t the desired output. Weights are adjusted to reduce 
the output error of estimating the input. Th e weights, individually as well as collectively, are the 
representative statistical functions used to reduce error. Essentially, a neural network strives to 
adjust the weights to ﬁ nd the lowest possible error. An example relationship between the output 
error and the weight values can be seen in Figure 24.12.
Note that relationship has low and high points. Th e high points are called maxima and the low 
points minima. Th e lowest point is known as the global minimum, whereas other low points are 
called local minima. Neural networks attempt to ﬁ nd the lowest point in their area of the graph. 
When a neural network begins to learn it will start at a random point on the graph. As learning 
occurs the network will move down a slope until it reaches a bottom. Th is bottom might be local 
Figure 24.11 Overtraining.

Neural Networks and Information Assurance Uses  321
minima or the global minimum. Typically, the analyst will not know if the global or a local mini-
mum is reached unless the network is retrained a number of times.
Typical Application Controls
Analysts using neural network software packages will be given a certain amount of ﬂ exibility with 
respect to training a network. Some of the more common controls likely to be encountered when 
using a back-propagation algorithm include training set speciﬁ cations, learning rates, momentum, 
and bias.
Training Sets
Th is is a subset of the initial data that is used to teach the neural network. At a minimum a 
representative selection of each class or feature to be learned must be included. Likewise, the set 
should be a suﬃ  cient representation of each feature such that most of the nuances of the data can 
be learned.
Validation Sets
A sample of the training set is used to conﬁ rm the accuracy of the neural network. In most 
instances validation sets are a randomly selected small percentage of the training set. Th is special 
set is necessary to ensure that the neural network is properly learning the appropriate features or 
classiﬁ cations about the data.
Test Sets
Th is is the actual data used to ﬁ nd the desired classiﬁ cations or features.
Error
Local minima
Global minima
Weights
Local minima
Figure 24.12 Local minima.

322  Information Security Management Handbook
Learning Rate
Th is constant is used to control the speed of change with respect to weights used. Th us, a large 
learning rate allows large changes in the weights, whereas a small value minimizes weight changes. 
Th is constant has a signiﬁ cant eﬀ ect on neural network convergence.
Momentum
Th is necessary constant provides a level of stability in the learning process. It also aﬀ ects the 
amount of change in weights. Th is constant is particularly important when the neural network 
encounters training data that signiﬁ cantly diverges from other training points learned.
Bias
Th is is an oﬀ set value used to aﬀ ect the activation function of each neuron, which essentially 
adjusts the threshold value.
Learning Stop Points
Some tools allow the user to specify stop points during the learning process. Common stop points 
include the number of epochs, amount of time, total, and average error amounts. A well-generalized 
neural network will not likely be perfect, but close enough is often good enough.
Demonstrated Usage
In this section, a simple demonstration of neural network classiﬁ cation and prediction capabilities 
is presented. An inexpensive commercial neural network tool called EasyNN-Plus was used for this 
purpose. Th is tool implements a back-propagation algorithm that relies on sigmoid transfer func-
tions. Additionally, the tool provides the user with a variety of parameters to control learning, such as 
learning rates, momentum, number of hidden layers, and validation parameters. Th e data inputs and 
outputs will be diﬀ erent for each of these scenarios. Th is also necessitates that two diﬀ erent types of 
networks be created. Th is is necessary because a neural network is created for a particular purpose.
In the classiﬁ cation scenario we will observe the ability of a neural network to diﬀ erentiate 
between a sine wave, a sawtooth wave, and a Gaussian pulse pattern. All three waveform param-
eters can be contained in a single graph with vertical (  y) values of ±1 and horizontal (x) values 
from 1 to 360. Because we are interested in training the neural network to recognize a pattern it 
is necessary to assign a value representing each waveform type. For this exercise we assign the sine, 
sawtooth, and Gaussian waveforms the values of 1, 2, and 3, respectively. Th e input parameters for 
the pattern classiﬁ cation are the x and y coordinates associated with the pattern. Th e pattern value 
associated with the input coordinates is the output. Th e neural network is trained by introducing 
training data that states the input and output parameters.
Each pattern in our exercise consists of the integer x values from 1 to 360 and the associated
y values. Th e training set consists of a series of coordinate values starting at 1 and then every ninth 
after that. So we have for our x values 1, 9, 18, 27, …, 360. Th is gives us 41 elements or approxi-
mately 11 percent of the total possible coordinates in our example. Th ese 41 coordinates represent 
our sample for training the neural network.

Neural Networks and Information Assurance Uses  323
Figure 24.13 shows a sine-wave plot, which is identiﬁ ed as classiﬁ cation number 1. Note that 
a sine wave is a nonlinear function. Th is necessitates the creation of a neural network that has at 
least one hidden layer to approximate the sine wave function.
A sawtooth waveform is shown in Figure 24.14 and is designated as classiﬁ cation item
number 2. Th e sharp transitions (angles) at the top and bottom of the waveform can be a challenge 
for neural networks to learn. Th is is due in part to the transformation function used.
1
0
1
51
101
151
201
251
301
351
Figure 24.13 Sine waveform.
1
1
51
101
151
201
251
301
351
0
Figure 24.14 Sawtooth waveform.

324  Information Security Management Handbook
A plot of a Gaussian waveform is seen in Figure 24.15 and represents the third classiﬁ cation 
item. Th is waveform should be no more challenging for the neural network to learn than the sine 
waveform.
An overlay of all of the waveforms is seen in Figure 24.16. Note that only the sine waveform 
has values less than 0.
As mentioned earlier, the ﬁ rst and every ninth coordinate in each waveform were used as the 
inputs for training the neural network. If we use each coordinate in the series as an input we would 
have a network with 41 inputs. Given this scenario we might not be able to train the neural network 
properly to generalize the waveforms. Th erefore, it is prudent to introduce smaller chunks of the data 
to the neural network for learning purposes. It was decided that ﬁ ve coordinates would be used for 
input purposes. Now it is evident that 41 elements are not evenly divided by 5. Indeed, 41 is a prime 
number and is only divisible by 1 and itself. However, this is not a problem. In fact, it is irrelevant 
1
0
1
51
101
151
201
251
301
351
Figure 24.15 Gaussian waveform.
1
1
51
101
151
201
251
301
351
0
Figure 24.16 Combined waveforms.

Neural Networks and Information Assurance Uses  325
because we will use a sliding window technique to help the neural network learn each waveform. 
What we will do is introduce the ﬁ rst ﬁ ve coordinates as one training element. For the next element 
we use the last three coordinates of the prior element combined with the next two coordinates in 
the series. Th e sliding window method results in 19 elements to be used for training. Table 24.1 
shows the ﬁ rst two and last two rows of the actual sine data used to train the network. Each row 
in Table 24.1 is an element used for training. Th e columns seen in Table 24.1 represent the input 
coordinates and output classiﬁ cation for each training element. Th e columns x1, y1; x2, y2; …; x5, y5 
are the coordinate pairs to be trained. Th e last column, C, is the classiﬁ cation or output associated 
with the input coordinates.
Th e neural network tool generates a neural network based on the training data and parameters 
provided by the end user. Training parameters included a momentum of 0.8 and a learning rate 
of 0.6. A total of 57 training elements were introduced to the neural network. From this initial 
amount eight were set aside for validation, whereas the remaining 49 were used to train the  neural 
network. Figure 24.17 is a graphical representation of the neural network created by the tool. 
Table 24.1 Abbreviated Training Data
x1
y1
x2
y2
x3
y3
x4
y4
x5
y5
C
1
0.017452
9
0.156434
18
0.309017
27
0.45399
36
0.587785
1
18
0.309017
27
0.45399
36
0.587785
45
0.707107
54
0.809017
1
…
…
…
…
…
…
…
…
…
…
…
306
−0.80902
315
−0.70711
324
−0.58779
333
−0.45399
342
−0.30902
1
324
−0.58779
333
−0.45399
342
−0.30902
351
−0.15643
360
0
1
X1
X2
X3
X4
X5
Y5
Y1
Y2
Y3
Y4
Input
Hidden layer
Output
1 = Sine
2 = Sawtooth
3 = Gaussian
Figure 24.17 Generated neural network.

326  Information Security Management Handbook
1
0
0
45
90
135
180
225
270
315
360
Sine 1
Sine 2
Sine 3
Sine 4
Sine 5
Figure 24.18 Sine test sets.
Note that the inputs match the x and y coordinates seen in Table 24.1, whereas the output is a 
single node. Th is follows the structure of the data used to train the neural network. Th e number 
of neurons in the hidden layer was generated automatically by the tool itself.
Only a few minutes of training was needed for the neural network to learn the three diﬀ erent 
classiﬁ cations suﬃ  ciently. A total of 21,464 epochs were conducted prior to halting the train-
ing. At this point, the average training error was 0.16 percent, whereas the maximum error was 
1.47 percent. Th e trained neural network was then given ﬁ ve elements of x and y coordinates 
from each of the waveforms exclusive of those elements identiﬁ ed in the training set. Th us, the 
trained network was queried to identify which waveform the element belonged to, representing 
the rudimentary act of classifying or categorizing the data. Th e element groupings were selected 
in series, but somewhat arbitrarily, while excluding points previously included in the training 
set. Some of the elements were purposely chosen across waveform transitions to determine if the 
neural network in fact learned the transition for a particular waveform and could correctly clas-
sify the input data.
Figure 24.18 shows the sine test sets introduced to the trained network. Most of the groupings 
are close together with the exception of sine 3.
In Figure 24.19, we can see that sawtooth 2 consists of points on two diﬀ erent slopes of the 
waveform, whereas sawtooth 5 was used on a steep and negative slope.
With the exception of Gaussian 4, most of the test sets seen in Figure 24.20 are kept close 
together. Th e exception element is spread out over most of the waveform.
Th e trained neural network successfully classiﬁ ed each of the input elements introduced. 
Although every coordinate was not tested, we might assume that in this case the neural network 
is suﬃ  ciently generalized to recognize a series of ﬁ ve consecutive coordinates as belonging to one 
of the previously learned classiﬁ cations.
Neural networks can also be used to make predictions. Th is ability is demonstrated for the 
sine waveform. In the case for prediction we want the neural network to predict a y value given the
x value. Th e training set consists of the x value as the input and the associated y value as the output. 

Neural Networks and Information Assurance Uses  327
1
0
0
50
100
150
200
250
300
350
Sawtooth 1
Sawtooth 2
Sawtooth 3
Sawtooth 4
Sawtooth 5
Figure 24.19 Sawtooth test sets.
1
Gaussian 1
Gaussian 2
Gaussian 3
Gaussian 4
Gaussian 5
360
315
270
225
180
135
90
45
0
0
Figure 24.20 Gaussian test sets.
Each training element consists of only two values. Th e previously identiﬁ ed 41 data points for the 
sine waveform are used to train the neural network.
It took less than two minutes for 57,639 training epochs to be completed. Once again the 
learning rate and momentum were set to 0.6 and 0.8, respectively. From the 41 training examples 
nine were selected for validation. At the training termination, the average error was 0.0275 per-
cent, whereas the maximum error was less than 0.095 percent. Figure 24.21 shows a representa-
tion of the generated neural network.
Th e neural network was queried to predict the y values for each x integer between 1 and 360, 
excluding those found in the training set. Th e prediction results can be seen in Figure 24.22. Note 
that the predicted results, identiﬁ ed as the dashed line, are very close to the actual results to be 
obtained. Th is demonstrates the ability of a neural network to generalize a function well enough 
to be able to predict an outcome with a fair degree of accuracy.

328  Information Security Management Handbook
1
y Predict
y Actual
0
1
51
101
151
201
251
301
−1
Figure 24.22 Prediction results.
Security-Relevant Applications
Perhaps the most prominent use of neural networks in security applications involves pattern clas-
siﬁ cation. Th ere exist a multitude of security technologies of which pattern classiﬁ cation is an 
essential aspect of the application. Some of the more well-known implementations are in the areas 
of biometrics, intrusion detection, and spam detection.
Data features form the basis by which a neural network learns a pattern. Some process is used 
to extract the features from the data for neural network processing. Sometimes the data features 
extracted are not clean. Th e features could be obscured, distorted, or missing. For instance, 
biometric data can be obscured through a variety of means. Facial recognition techniques must 
learn to accept diﬀ erent lighting situations, facial hair, and accessories such as eyeglasses that 
can obscure the pattern. Likewise, ﬁ ngerprint recognition must be robust enough to success-
fully  identify individuals with dirty ﬁ ngers or scars that might cover up some of the minutia. 
Input
Hidden layer
Output
Figure 24.21 Prediction neural network.

Neural Networks and Information Assurance Uses  329
 Fortunately, dirty or missing data is not always a problem for neural networks because one of 
their strengths is the ability to generalize. Given this characteristic, neural networks are a tech-
nology that can be very useful to the security practitioner in situations in which accurate or 
consistent data collection is not ensured.
A biometric is a measurable characteristic that can be used to identify an individual uniquely. 
Measurements can comprise angles and distances between feature points. Th e unique features 
of a biometric can be used to represent the “something a person is” aspect of an authentication 
scheme. Neural networks have been successfully used for pattern classiﬁ cation of individual 
physical characteristics of ﬁ ngerprints (Cappelli et al., 2003), irises (Chu and Chen, 2005), faces 
(Zhao et al., 2003), hand geometry and palm prints (Ong et al., 2003), and voices (Quixtiano-
Xicohtencatl et al., 2006) and in thermal face imaging (Bauer and Mazurkiewicz, 2005).
Other interesting types of biometrics that are not physical characteristics, but rather man-
ifestations of an individual, for which neural networks have been used include authorship 
(Li et al., 2006), handwritten signatures (Al-Shoshan, 2006), and typing patterns (Peacock 
et al., 2005). Handwritten signatures, perhaps the most well-known form of authentication, 
have been evaluated with neural networks that look for unique aspects of a signature shape 
to classify it as belonging to a particular individual or not. Authorship is a way of identifying 
an individual based on their writing style. People tend to write certain ways when they conduct 
correspondence or formal writing, and these unique aspects can be used to identify patterns of 
how a person writes a message. Some of the usable feature points extracted can include grammar, 
punctuation, case, and word usage in a typical sentence. Likewise, the way a person types can also 
be considered a biometric. Aspects such as typing speed and rhythm as well as spelling can be used 
to actively authenticate the individual entering information into a system.
An intrusion detection system (IDS) is categorized as signature or anomaly based. A signature-
based IDS, also referred to as misuse detection, relies on a database of signatures to detect attacks. 
In contrast, an IDS performing anomaly detection looks for abnormal activity. Th e generalization 
capabilities of neural networks make them an ideal evaluation mechanism for an anomaly-based 
IDS (Cannady, 1998). Neural networks have been implemented for both host- and network-based 
IDS applications. In network-based anomaly detectors the neural network is used to identify 
traﬃ  c patterns that deviate from what is considered normal (McHugh et al., 2000). Host-based 
anomaly detection neural networks have been used to identify abnormal events in audit logs 
(Endler, 1998) as well as system calls (Cha et al., 2005).
Spam ﬁ ltering is another area in which neural networks are beginning to emerge. A variety of 
ﬁ ltering techniques based on text classiﬁ cation are used in antispam ﬁ lters. Th ese ﬁ lters range from 
simple keyword searches to more complex implementations of Bayesian analysis. At least one ven-
dor has used a neural network as a means to classify an e-mail as spam or not spam (Goth, 2003). 
Attributes of an e-mail that can be used to identify it as spam include e-mail header information, 
types of words and phrases, and the existence of Hypertext Markup Language content (Clark 
et al., 2003). It is reasonable to assume that a human can readily classify an e-mail as spam or 
not spam. Given this situation it would be better for a machine to learn to handle this redundant 
task. In this regard neural networks are an ideal candidate for the task. Indeed, the generaliza-
tion capabilities of a neural network are likely to be more eﬀ ective at identifying spam than static 
techniques such as keyword searches given the constant change in spam content. More recently, 
spammers have evolved their tactics so that words that make up a spam message are embedded in 
a graphic image. Most spam ﬁ lters are not able to cope up with this new tactic because they rely 
on words within the body of the e-mail to make a classiﬁ cation decision. However, researchers 
have started exploring the use of neural networks for spam image analysis (Aradhye et al., 2005). 

330  Information Security Management Handbook
Certainly more work is needed in this area, but neural networks appear to be an ideal tool for 
identifying image-based spam.
Potential Applications
Pattern classiﬁ cation is clearly a strength of neural networks. It is this ability that could possibly 
be used to further information security activities. Given this strength new applications of neural 
networks to security problems can be envisioned. Th ere are many information security areas where 
neural networks could be used simply to diﬀ erentiate between normal and abnormal activities. 
For example, a neural network could be used to identify system processes that are not normal for 
a network or user. Th is is closely related to the idea of secure state processing (Price, 2006), which 
involves knowing those processes, and their loaded libraries, that are authorized or not regarding 
a security policy. A neural network could be used to categorize processes by user name or group. 
Th is would result in an application that acts like a type of host-based IDS with respect to run-
ning processes. Neural networks might also be used to assist with the task of audit log reduction 
and analysis. Although Endler (1998) used neural networks to analyze audit logs, his approach 
primarily focused on IDS activities. If we consider a neural network that is trained to recognize 
approved patterns of activities in audit logs then it might be able to identify deviations from what 
is acceptable. Indeed, the neural network could potentially identify unimportant events to aid in 
audit reduction. Neural networks could also be used to identify attempts to steal sensitive infor-
mation. Th is concept involves a method of tracking the ﬂ ows of information on a system to iden-
tify those ﬂ ows that are anomalous or not authorized. For instance, if a policy exists prohibiting 
users from saving sensitive information to removable media, then it may be possible to construct 
a neural network that could identify the occurrence of the violation. Th is might require that the 
neural network is trained to identify either information ﬂ ows that are authorized or those that are 
not authorized. Although neural networks have been used to diﬀ erentiate between possible spam-
based images (Aradhye et al., 2005), more work could be done in this area. A neural network 
could be trained to recognize persistent aspects of an image that are common to a particular type 
of spam. Suppose that certain words or pictures persist in a certain type of spam. It would not be 
necessary for the neural network to distinguish the word or picture per se, but rather recognize 
that the particular aspect of an image received represents a type of spam. Th us, a neural network 
could be trained to identify an aspect within an image that represents spam.
Conclusion
Neural networks are an aspect of artiﬁ cial intelligence that has a special ability to learn. Th e feed-
forward neural network architecture used with the back-propagation algorithm is one the most 
popular neural network implementations. Security practitioners can beneﬁ t from the learning 
capabilities of neural networks that are taught to recognize features or patterns in data. Some of 
the more common neural network implementations include biometrics, intrusion detection, and 
spam classiﬁ cation. Commercial tools that exist allow the security analysts to discover new ways 
to use this powerful technology. Although neural networks can learn interesting things from data, 
it is important to ensure that applicable, clean, and accurate data features are used. Otherwise, the 
neural network might learn and report irrelevant results.

Neural Networks and Information Assurance Uses  331
References
Al-Shoshan, A. I. (2006). Handwritten signature veriﬁ cation using image invariants and dynamic  features. 
Proceedings of the International Conference on Computer Graphics, Imaging, and Visualization, 
173–176.
Aradhye, H. B., Meyers, G. K., and Herson, J. A. (2005). Image analysis for eﬃ  cient categorization of 
image-based spam. Proceedings of the 2005 Eighth International Conference on Document Analysis and 
Recognition, 914–918.
Bauer, J., and Mazurkiewicz, J. (2005). Neural network and optical correlators for infrared imaging based 
face recognition. Proceedings of the 5th International Conference on Intelligent Systems Design and Appli-
cations, 234–238.
Cannady, J. (1998). Artiﬁ cial neural networks for misuse detection. Proceedings of the 1998 National Infor-
mation Systems Security Conference, 443–456.
Cappelli, R., Maio, D., Maltoni, D., and Nanni, L. (2003). A two-stage ﬁ ngerprint classiﬁ cation system. 
Proceedings of the 2003 ACM SIGMM Workshop on Biometrics Methods and Applications, 95–99.
Cha, B., Vaidya, B., and Han, S. (2005). Anomaly intrusion detection for system call using the soundex 
algorithm and neural networks. Proceedings of the 10th IEEE Symposium on Computers and Commu-
nications, 427–433.
Chu, C. T., and Chen, C. (2005). High performance iris recognition based on LDA and LPCC. Proceedings 
of the 17th IEEE International Conference on Tools with Artiﬁ cial Intelligence, 417–421.
Clark, J., Koprinska, I., and Poon, J. (2003). A neural network based approach to automated e-mail clas-
siﬁ cation. Proceedings of the IEEE/WIC International Conference on Web Intelligence, 702–705.
Endler, D. (1998). Intrusion detection applying machine learning to Solaris audit data. Proceedings of the 
1998 Annual Computer Security Applications Conference, 268–279.
Gadea, R., Cerda, J., Ballester, F., and Mocholi, A. (2000). Artiﬁ cial neural network implementation on a 
single FPGA of a pipelined on-line back propagation. Proceedings of the 13th International Symposium 
on System Synthesis, 225–230.
Goth, G. (2003). Much ado about spamming. IEEE Internet Computing, 7(4), 7–9.
Haykin, S. (1999). Neural Networks: A Comprehensive Foundation (2nd ed.). Upper Saddle River, NJ: 
 Prentice Hall.
Jordan, M. I., and Bishop, C. M. (1996). Neural networks. ACM Computing Surveys, 28(1), 73–75.
Li, J., Zheng, R., and Chen, H. (2006). From ﬁ ngerprint to writeprint. Communications of the ACM, 49(4), 
76–82.
McHugh, J., Christie, A., and Allan, J. (2000). Defending yourself: the role of intrusion detection systems. 
IEEE Software, 17(5), 42–51.
Negnevitsky, M. (2005). Artiﬁ cial Intelligence: A Guide to Intelligent Systems (2nd ed.). Essex, UK: Pearson 
Educational Limited.
Ong, M. G., Connie, T., Jin, A. T., and Ling, D. N. (2003). A single-sensor hand geometry and palmprint 
veriﬁ cation system. Proceedings of the 2003 ACM SIGMM Workshop on Biometrics Methods and Appli-
cations, 100–106.
Padhy, N. P. (2005). Artiﬁ cial Intelligence and Intelligent Systems. Oxford, UK: Oxford University Press.
Peacock, A., Ke, X., and Wilkerson, M. (2005). Typing patterns: a key to user identiﬁ cation. IEEE Security 
and Privacy, 2(5), 40–47.
Pendharkar, P. C. (2005). A data envelopment analysis-based approach for data preprocessing. IEEE Trans-
actions on Knowledge and Data Engineering, 17(10), 1379–1388.
Price, S. M. (2006). Secure state processing. Proceedings of the 2006 IEEE Information Assurance Workshop, 
380–381.
Quixtiano-Xicohtencatl, R., Flores-Pulido, L., and Reyes-Galaviz, O. F. (2006). Feature selection for a fast 
speaker detection system with neural networks and genetic algorithms. Proceedings of the 15th Inter-
national Conference on Computing, 126–134.

332  Information Security Management Handbook
Russell, S., and Norvig, P. (2003). Artiﬁ cial Intelligence: A Modern Approach (2nd ed.). Upper Saddle River, 
NJ: Pearson Education.
Yu, L., Wang, S., and Lai, K. K. (2006). An integrated data preparation scheme for neural network data 
analysis. IEEE Transactions on Knowledge and Data Engineering, 18(2), 217–230.
Zhao, W., Chellappa, R., Phillips, P. J., and Rosenfeld, A. (2003). Face recognition: a literature survey. 
ACM Computing Surveys, 35(4), 399–458.

333
Chapter 25
Information Technology 
Infrastructure Library and 
Security Management 
Overview
David McPhee
Contents
Introduction ............................................................................................................................ 334
What Is the Information Technology Infrastructure Library? ................................................. 334
History of ITIL ....................................................................................................................... 334
What Is Security Management? ...............................................................................................335
Descriptions ............................................................................................................................ 336
Service Support Overview .............................................................................................. 336
Service Support Details .................................................................................................. 336
Service Desk ......................................................................................................... 336
Incident Management .....................................................................................................337
Beneﬁ ts of Incident Management Process ..............................................................337
Problem Management .....................................................................................................337
Incident Management and Problem Management: What Is the Diﬀ erence? .................. 340
Change Management ..................................................................................................... 340
Beneﬁ ts of Change Management .......................................................................... 340
Conﬁ guration Management .......................................................................................... 340
Conﬁ guration Management and Information Security .................................................. 341
Beneﬁ ts of Conﬁ guration Management ................................................................ 341

334  Information Security Management Handbook
Release Management ..................................................................................................... 341
Beneﬁ ts of Release Management ........................................................................... 341
Release Categories ................................................................................................ 342
Service Delivery Overview ...................................................................................................... 343
Service Level Management ............................................................................................ 343
Beneﬁ ts of Implementing SLM ............................................................................. 344
Capacity Management ................................................................................................... 344
Capacity Management Processes .......................................................................... 344
Availability Management ................................................................................................345
Availability Management and Information Security .......................................................345
Financial Management ...................................................................................................345
Service Continuity Management ................................................................................... 346
Th e Security Management Process .......................................................................................... 346
Control .......................................................................................................................... 347
Plan ............................................................................................................................... 347
Implementation ............................................................................................................. 347
Evaluation ...................................................................................................................... 347
Maintenance .................................................................................................................. 348
References ............................................................................................................................... 348
Introduction
For the purpose of this chapter, the focus will be on how information security management works 
within the Information Technology Infrastructure Library (ITIL®).
What Is the Information Technology Infrastructure Library?
Th e ITIL is a framework of best practices. Th e concepts within ITIL support information 
 technology (IT) services delivery organizations with the planning of consistent, documented, and 
repeatable or customized processes that improve service delivery to the business. Th e ITIL frame-
work consists of the following IT processes: service support (service desk, incident management, 
problem management, change management, conﬁ guration management, and release manage-
ment) and services delivery [service-level management (SLM), capacity management, availability 
management, ﬁ nancial management, and IT service continuity management (SCM)].
History of ITIL
Th e ITIL concept emerged in the 1980s, when the British government determined that the level of  
IT service quality provided to them was not suﬃ  cient. Th e Central Computer and Telecommuni-
cations Agency, now called the Oﬃ  ce of Government Commerce, was tasked with developing a 
framework for eﬃ  cient and ﬁ nancially responsible use of IT resources within the British govern-
ment and the private sector.
Th e earliest version of ITIL was called Government Information Technology Infrastructure 
Management. Obviously this was very diﬀ erent from the current ITIL, but conceptually very 
similar, focusing around service support and delivery.

ITIL and Security Management Overview  335
Large companies and government agencies in Europe adopted the framework very quickly in 
the early 1990s. ITIL was spreading far and wide and was used in both government and nongov-
ernmental organizations. As it grew in popularity, both in the United Kingdom and across the 
world, IT itself changed and evolved, and so did ITIL (http://itsm.fwtk.org/History.htm).
What Is Security Management?
Security management details the process of planning and managing a deﬁ ned level of security for 
information and IT services, including all aspects associated with reaction to security incidents. It 
also includes the assessment and management of risks and vulnerabilities and the implementation 
of cost-justiﬁ able countermeasures.
Security management is the process of managing a deﬁ ned level of security on information and 
IT services. Included is managing the reaction to security incidents. Th e importance of informa-
tion security has increased dramatically because of the move to open internal networks to custom-
ers and business partners, the move toward electronic commerce, and the increasing use of public 
networks like the Internet and intranets. Th e widespread use of information and information 
processing as well as the increasing dependency on information process results requires structural 
and organized protection of information (Figure 25.1).
Service delivery
Service-level
management
IT service
continuity
management
Availability
management
Service
desk
Financial
management
Capacity
management
Problem
management
Incident 
management
Configuration 
management
Change 
management
Service support
Release 
management
Figure 25.1 ITIL overview.

336  Information Security Management Handbook
Descriptions
Service Support Overview
Service support describes the processes associated with the day-to-day support and maintenance 
activities associated with the provision of IT services (service desk, incident management, problem 
management, change management, conﬁ guration management, and release management).
Service desk. Th is function is the single point of contact between the end users and IT service 
management.
Incident management. Best practices for resolving incidents (any event that causes an interrup-
tion to, or a reduction in, the quality of an IT service) and quickly restoring IT services.
Problem management. Best practices for identifying the underlying cause(s) of IT incidents to 
 prevent future recurrences. Th ese practices seek to proactively prevent incidents and problems.
Change management. Best practices for standardizing and authorizing the controlled imple-
mentation of IT changes. Th ese practices ensure that changes are implemented with mini-
mum adverse impact on IT services and that they are traceable.
Conﬁ guration management. Best practices for controlling production conﬁ gurations (for exam-
ple, standardization, status monitoring, and asset identiﬁ cation). By identifying, control-
ling, maintaining, and verifying the items that make up an organization’s IT infrastructure, 
these practices ensure that there is a logical model of the infrastructure.
Release management. Best practices for the release of hardware and software. Th ese practices 
ensure that only tested and correct versions of authorized software and hardware are pro-
vided to IT customers.
Service Support Details
Service Desk
Th e objective of the service desk is to be a single point of contact for customers who need assistance 
with incidents, problems, and questions and to provide an interface for other activities related to 
IT and ITIL services (Figure 25.2).
Beneﬁ ts of Implementing a Service Desk
Increased ﬁ rst-call resolution
Skill-based support
Rapid restoration of service
Improved incident response time
Improved tracking of service quality
Improved recognition of trends and incidents
Improved employee satisfaction
Processes Utilized by the Service Desk
Workﬂ ow and procedures diagrams
Roles and responsibilities
Training evaluation sheets and skill set assessments
Implemented metrics and continuous improvement procedures












ITIL and Security Management Overview  337
Incident Management
Th e objective of incident management (http://www.itilpeople.com/) is to minimize disruption to 
the business by restoring service operations to agreed levels as quickly as possible and to ensure 
that the availability of IT services is maximized. It can also protect the integrity and conﬁ dential-
ity of information by identifying the root cause of a problem.
Beneﬁ ts of Incident Management Process
Incident detection and recording
Classiﬁ cation and initial support
Investigation and diagnosis
Resolution and recovery
Incident closure
Incident ownership, monitoring, tracking, and communication
Repeatable process
With a formal incident management practice, IT quality will improve through ensuring ticket 
quality, standardizing ticket ownership, and providing a clear understanding of ticket types while 
decreasing the number of unreported or misreported incidents (Figure 25.3).
Problem Management
Th e object of problem management (http://www.itilpeople.com/) is to resolve the root cause of 
incidents to minimize the adverse impact of incidents and problems on the business and, second, 
to prevent recurrence of incidents related to these errors. A “problem” is an unknown underly-
ing cause of one or more incidents, and a “known error” is a problem that has been successfully 
 diagnosed and for which a workaround has been identiﬁ ed. Th e outcome of a known error is a 
request for change (RFC).







Service desk
Service-level
management
Availability
management
Service
delivery
Financial management 
for IT services
IT service
continuity management
Capacity
management
Release
management
Configuration 
management
Service
support
Incident
management
Problem
management
Change 
management
Figure 25.2 Service desk diagram (Securityfocus.com/infocus/1815).

338  Information Security Management Handbook
A problem is a condition often identiﬁ ed as a result of multiple incidents that exhibit common 
symptoms. Problems can also be identiﬁ ed from a single signiﬁ cant incident, indicative of a single 
error, for which the cause is unknown, but for which the impact is signiﬁ cant.
A known error is a condition identiﬁ ed by successful diagnosis of the root cause of a problem 
and the subsequent development of a work-around.
An RFC is a proposal to IT infrastructure for a change to the environment (Figure 25.4).
Incident owner completes an
incident template with as
much information as  
possible.
Incident owners identify
where they should go
to obtain all necessary
data.
(a)
(b)
Incident owner must
ensure that there is
a timely update.
Incident owner must
repeat last step, until
issue is resolved.
Process definition
Incident management will lead or support activities related to these steps.
Incident owner 
completes an incident
template with as much 
information as possible.
•
Initially, the incident owner must provide as much information as  possible.  The 
owners must also establish the initial timeframe when they will update the 
template next (whether negotiated or preestablished service-level agreement 
 [SLA]).
Incident owners 
identify where they
should go to obtain all 
necessary data.
•
Every data point on the appended templates will have a group accountable.  
This means, that the incident owners must ensure the template is complete, they
are not responsible for being able to complete the template on their own.  
Identified resources will exist which are responsible for knowing the information 
that should go into the template. That resource is to provide the technical data 
to the incident owner.
Incident owner must 
ensure that there is a 
timely update.
•
Part of the update process is that the next point of contact be established with 
the customer. Whether this is an operational-level agreement (OLA)/SLA, or a 
time negotiated and agreed upon at the time of the call, that time is when the 
incident owners owe another update to the customer, and is when they
should have a fresh update in the incident.
. 
Incident owner must 
repeat last step, until 
issue is resolved.
•
All subsequent updates in the incident must be by or prior to the agreed upon 
SLA/OLA.
Figure 25.3 Incident management ticket owner workﬂ ow diagram.

ITIL and Security Management Overview  339
Figure 25.4 Problem management diagram overview.
Escalation to next 
level of support
Publish as known 
error
Root cause 
identified
Work-around 
available?
Publish and 
communication
Define solution
Is a change 
required?
Change 
process
Apply solution
Problem 
task
assigned 
Root-cause 
analysis
Item closed
No
Yes
Yes
No
Yes
No

340  Information Security Management Handbook
Incident Management and Problem Management: 
What Is the Difference?
Incidents and service requests are formally managed through a staged process to conclusion. 
Th is process is referred to as the “incident management life cycle.” Th e objective of the incident 
 management life cycle is to restore the service as quickly as possible to meet SLAs. Th e process is 
 primarily aimed at the user level.
Problem management deals with resolving the underlying cause of one or more incidents. Th e 
focus of problem management is to resolve the root cause of errors and to ﬁ nd permanent solu-
tions. Although every eﬀ ort will be made to resolve the problem as quickly as possible, this process 
is focused on the resolution of the problem rather than the speed of the resolution. Th is process 
deals at the enterprise level.
Change Management
Change management (http://www.itilpeople.com/) ensures that all areas follow a standardized 
process when implementing change into a production environment. Change is deﬁ ned as any 
adjustment, enhancement, or maintenance to a production business application, system software, 
system hardware, communications network, or operational facility.
Beneﬁ ts of Change Management
Planning change
Impact analysis
Change approval
Managing and implementing change
Increase formalization and compliance
Postchange review
Better alignment of IT infrastructure to business requirements
Eﬃ  cient and prompt handling of all changes
Fewer changes to be backed out
Greater ability to handle a large volume of change
Increased user productivity
Conﬁ guration Management
Conﬁ guration management is the implementation of a database (conﬁ guration management 
 database [CMDB]) that contains details of the organization’s elements that are used in the provi-
sion and management of its IT services. Th e main activities of conﬁ guration management are
Planning. Planning and deﬁ ning the scope, objectives, policy, and processes of the CMDB
Identiﬁ cation. Selecting and identifying the conﬁ guration structures and items within the 
scope of your IT infrastructure
Conﬁ guration control. Ensuring that only authorized and identiﬁ able conﬁ guration items are 
accepted and recorded in the CMDB throughout its lifecycle.
Status accounting. Keeping track of the status of components throughout the entire lifecycle 
of conﬁ guration items
















ITIL and Security Management Overview  341
Veriﬁ cation and audit. Auditing after the implementation of conﬁ guration management to 
verify that the correct information is recorded in the CMDB, followed by scheduled audits 
to ensure the CMDB is kept up-to-date
Conﬁ guration Management and Information Security
Without the deﬁ nition of all conﬁ guration items that are used to provide an organization’s IT 
services, it can be very diﬃ  cult to identify which items are used for which services. Th is could 
result in critical conﬁ guration items being stolen, moved, or misplaced, aﬀ ecting the availability 
of the services dependent on them. It could also result in unauthorized items being used in the 
provision of IT services.
Beneﬁ ts of Conﬁ guration Management
Reduced cost to implement, manage, and support the infrastructure
Decreased incident and problem resolution times
Improved management of software licensing and compliance
Consistent, automated processes for infrastructure mapping
Increased ability to identify and comply with architecture and standards requirements
Incident troubleshooting
Usage trending
Change evaluation
Financial chargeback and asset life-cycle management
SLA and software license negotiations
Release Management
Release management (http://www.itilpeople.com) is used for platform-independent and auto-
mated distribution of software and hardware, including license controls across the entire IT infra-
structure. Proper software and hardware control ensures the availability of licensed, tested, and 
version-certiﬁ ed software and hardware, which will function correctly and respectively with the 
available hardware. Quality control during the development and implementation of new hardware 
and software is also the responsibility of release management. Th is guarantees that all software can 
be conceptually optimized to meet the demands of the business processes.
Beneﬁ ts of Release Management
Ability to plan resource requirements in advance
Provides a structured approach, leading to an eﬃ  cient and eﬀ ective process
Changes are bundled together in a release, minimizing the impact on the user
Helps to verify correct usability and functionality before release by testing
Controls the distribution and installation of changes to IT systems
Designs and implements procedures for the distribution and installation of changes to IT 
systems
Eﬀ ectively communicates and manages expectations of the customer during the planning 
and rollout of new releases



















342  Information Security Management Handbook
Th e focus of release management is the protection of the live environment and its services through 
the use of formal procedures and checks.
Release Categories
A release consists of the new or changed software or hardware required to implement the approved 
change (Figure 25.5).
Major software releases and hardware upgrades, normally containing large areas of new 
functionality, some of which may make intervening ﬁ xes to problems redundant. A major 
upgrade or release usually supersedes all preceding minor upgrades, releases, and emergency 
ﬁ xes.
Minor software releases and hardware upgrades, normally containing small enhancements 
and ﬁ xes, some of which may have already been issued as emergency ﬁ xes. A minor upgrade 
or release usually supersedes all preceding emergency ﬁ xes.
Emergency software and hardware ﬁ xes, normally containing the corrections to a small 
number of known problems.



User request
Service desk 
Configuration 
management
Change 
management
Release 
management
Change requests are directed 
to the service desk
Service desk provides 
effective support to 
customers
Change requests are 
directed to the change 
process
CMDB is consulted to 
assess the impact  of 
a proposed change
CMDB is updated to  
reflect the changes 
after the release
Knowledge is transferred to 
the service desk
Approved changes are
made through release 
management process
Figure 25.5 Release management overview.

ITIL and Security Management Overview  343
Releases can be divided based on the release unit into the following:
Delta release is a release of only that part of the software that has been changed (e.g., security 
patches to plug bugs in a software).
Full release means that the entire software program will be released again (e.g., an entire 
version of an application).
Packaged release is a combination of many changes (e.g., an operating system image con-
taining the applications as well).
Service Delivery Overview
Service delivery is the discipline that ensures IT infrastructure is provided at the right time in 
the right volume at the right price and ensures that IT is used in the most eﬃ  cient manner. 
Th is involves analysis and decisions to balance capacity at a production or service point with 
demand from customers; it also covers the processes required for the planning and delivery of 
 quality IT services and looks at the longer-term processes associated with improving the quality of 
IT services delivered.
SLM. Service-level management is responsible for negotiating and agreeing to service require-
ments and expected service characteristics with the customer.
Capacity management. Th is is responsible for ensuring that IT processing and storage capacity 
provision match the evolving demands of the business in a cost-eﬀ ective and timely manner.
Availability management. Th is is responsible for optimizing availability.
Financial management. Th e object of ﬁ nancial management for IT services is to provide cost-eﬀ ec-
tive stewardship of the IT assets and the ﬁ nancial resources used in providing IT services.
IT SCM. Service continuity is responsible for ensuring that the available IT service continu-
ity options are understood and the most appropriate solution is chosen in support of the 
 business requirements.
Service Level Management
Th e object of SLM is to maintain and gradually improve business-aligned IT service quality, 
through a constant cycle of agreeing, monitoring, reporting, and reviewing IT service achieve-
ments and through instigating actions to eradicate unacceptable levels of service.
SLM is responsible for ensuring that the service targets are documented and agreed in SLAs 
and monitoring and reviewing the actual service levels achieved against their SLA targets. SLM 
should also be trying to improve all service levels proactively within the imposed cost constraints. 
SLM is the process that manages and improves agreed level of service between two parties, the 
provider and the receiver of a service.
SLM is responsible for negotiating and agreeing to service requirements and expected service 
characteristics with the customer, measuring and reporting service levels actually being achieved 
against target, resources required, and cost of service provision. SLM is also responsible for contin-
uously improving service levels in line with business processes, with a Session Initiation  Protocol; 
co-coordinating other service management and support functions, including third-party suppli-
ers; reviewing SLAs to meet changed business needs; or resolving major service issues and produc-
ing, reviewing, and maintaining the service catalog.




344  Information Security Management Handbook
Beneﬁ ts of Implementing SLM
Implementing the SLM process enables both the customer and the IT services provider to 
have a clear understanding of the expected level of delivered services and their associated 
costs for the organization, by documenting these goals in formal agreements.
SLM can be used as a basis for charging for services and can demonstrate to customers the 
value they are receiving from the service desk.
It also assists the service desk with managing external supplier relationships and introduces 
the possibility of negotiating improved services or reduced costs.
Capacity Management
Capacity management is responsible for ensuring that IT processing and storage capacity provi-
sioning match the evolving demands of the business in a cost-eﬀ ective and timely manner. Th e 
process includes monitoring the performance and the throughput of the IT services and support-
ing IT components, tuning activities to make eﬃ  cient use of resources, understanding the current 
demands for IT resources and deriving forecasts for future requirements, inﬂ uencing the demand 
for resource in conjunction with other service management processes, and producing a capacity 
plan predicting the IT resources needed to achieve agreed service levels.
Capacity management has three main areas of responsibility. Th e ﬁ rst of these is business con-
tinuity management (BCM), which is responsible for ensuring that the future business require-
ments for IT services are considered, planned, and implemented in a timely fashion. Th ese future 
requirements will come from business plans outlining new services, improvements and growth in 
existing services, development plans, etc. Th is requires knowledge of existing service levels and 
SLAs, future service levels and service level requirements (SLRs), the business and capacity plans, 
modeling techniques  (analytical, simulation, trending, and baselining), and application sizing 
methods.
Th e second main area of responsibility is SCM, which focuses on managing the performance 
of the IT services provided to the customers and is responsible for monitoring and measuring 
services, as detailed in SLAs, and collecting, recording, analyzing, and reporting on data. Th is 
requires knowledge of service levels and SLAs, systems, networks, service throughput and perfor-
mance, monitoring, measurement, analysis, tuning, and demand management.
Th e third and ﬁ nal main area of responsibility is resource capacity management (RCM), 
which focuses on management of the components of the IT infrastructure and ensuring that all 
ﬁ nite resources within the IT infrastructure are monitored and measured and that collected data 
is recorded, analyzed, and reported. Th is requires knowledge of the current technology and its 
utilization, future or  alternative  technologies, and the resilience of systems and services.
Capacity Management Processes
Performance monitoring
Workload monitoring
Application sizing
Resource forecasting
Demand forecasting
Modeling










ITIL and Security Management Overview  345
From these processes come the results of capacity management, these being the capacity plan 
itself, forecasts, tuning data, and SLM guidelines.
Availability Management
Availability management is concerned with design, implementation, measurement, and manage-
ment of IT services to ensure the stated business requirements for availability are  consistently 
met.  Availability management requires an understanding of the reasons why IT service failures 
occur and the time taken to resume this service. Incident management and problem management 
 provide a key input to ensure the appropriate corrective actions are being implemented.
Availability management. Th e ability of an IT component to perform at an agreed level over 
a period of time.
Reliability. Th e ability of an IT component to perform at an agreed level under described 
conditions.
Maintainability. Th e ability of an IT component to remain in, or be restored to, an opera-
tional state.
Serviceability. Th e ability of an external supplier to maintain the availability of a component 
or function under a third-party contract.
Resilience. A measure of freedom from operational failure and a method of keeping services 
reliable. One popular method of resilience is redundancy.
Security. A service has associated data. Security refers to the conﬁ dentiality, integrity, and 
availability of that data.
Availability Management and Information Security
Security is an essential part of availability management, this being the primary focus of ensuring 
IT infrastructure continues to be available for the provision of IT services.
Some of the elements mentioned earlier are the products of performing risk analysis to identify 
how reliable elements are and how many problems have been caused as a result of system failure.
Th e risk analysis also recommends controls to improve availability of IT infrastructure such 
as development standards, testing, physical security, and the right skills in the right place at the 
right time.
Financial Management
Financial management (www.securityfocus.com/infocus/1815) for IT services is an integral part of 
service management. It provides the essential management information to ensure that services are 
run eﬃ  ciently, economically, and cost eﬀ ectively. An eﬀ ective ﬁ nancial management system will 
assist in the management and reduction of overall long-term costs and identify the actual cost of 
services. Th is provisioning provides accurate and vital ﬁ nancial information to assist in decision mak-
ing, identify the value of IT services, and enable the calculation of total cost of ownership and ROI.
Th e practice of ﬁ nancial management enables the service manager to identify the amount 
being spent on security countermeasures in the provision of the IT services. Th e amount being 
spent on these countermeasures needs to be balanced with the risks and the potential losses that 
the service could incur as identiﬁ ed during business impact and risk assessments. Management of 
these costs will ultimately reﬂ ect on the cost of providing the IT services and potentially what is 
charged in the recovery of those costs.







346  Information Security Management Handbook
Service Continuity Management
SCM supports the overall BCM process by ensuring that the required IT technical and services 
facilities can be recovered within required and agreed business timescales.
IT SCM is concerned with managing an organization’s ability to continue to provide a prede-
termined and agreed level of IT services to support the minimum business requirements following 
an interruption to the business. Th is includes ensuring business survival by reducing the impact of a 
disaster or major failure, reducing the vulnerability and risk to the business by eﬀ ective risk analysis 
and risk management, preventing the loss of customer and user conﬁ dence, and producing IT recovery 
plans that are integrated with and fully support the organization’s overall business continuity plan.
IT service continuity is responsible for ensuring that the available IT service continuity options 
are understood and the most appropriate solution is chosen in support of the business require-
ments. It is also responsible for identifying roles and responsibilities and making sure that these 
are endorsed and communicated from a senior level to ensure respect and commitment for the 
process. Finally, IT service continuity is responsible for guaranteeing that the IT recovery plans 
and the business continuity plans are aligned and are regularly reviewed, revised, and tested.
The Security Management Process
Security management provides a framework to capture the occurrence of security-related  incidents 
and limit the impact of security breaches. Th e activities within the security  management process must 
be revised continuously, to stay up to date and eﬀ ective. Security management is a  continuous process 
and it can be compared to the Quality Circle of Deming (Plan, Do, Check, and Act).
Th e inputs are the requirements formed by the clients. Th e requirements are translated into 
security services, security quality that needs to be provided in the security section of the SLAs. As 
you can see in Figure 25.6, there are arrows going both ways: from the client to the SLA and from 
Figure 25.6 Security image diagram.

ITIL and Security Management Overview  347
the SLA to the client, and from the SLA to the plan subprocess and from the plan  subprocess to 
the SLA. Th is means that both the client and the plan subprocess have inputs to the SLA and the 
SLA is an input for both the client and the process. Th e provider then develops the security plans 
for their organization. Th ese security plans contain the security policies and the OLAs. Th e secu-
rity plans (Plan) are then implemented (Do) and the implementation is then evaluated (Check). 
After the evaluation both the plans and the implementation of the plan are maintained (Act).
Control
Th e ﬁ rst activity in the security management process is the “control” subprocess. Th e control 
subprocess organizes and manages the security management process itself. Th e control subprocess 
deﬁ nes the processes, the allocation of responsibility, the policy statements, and the management 
framework.
Th e security management framework deﬁ nes the subprocesses for the development of security 
plans, the implementation of the security plans, the evaluation, and how the results of the evalua-
tions are translated into action plans.
Plan
Th e plan subprocess contains activities that in cooperation with the SLM lead to the information 
security section in the SLA. Th e plan subprocess contains activities that are related to the under-
pinning contracts, which are speciﬁ c for information security.
In the plan subprocess the goals formulated in the SLA are speciﬁ ed in the form of OLAs. 
Th ese OLAs can be deﬁ ned as security plans for a speciﬁ c internal organization entity of the 
 service provider.
In addition to the input of the SLA, the plan subprocess works with the policy statements of 
the service provider itself. As mentioned earlier these policy statements are deﬁ ned in the control 
subprocess.
Th e OLAs for information security are set up and implemented based on the ITIL process. 
Th is means that there has to be cooperation with other ITIL processes. For example, if the security 
management wishes to change the IT infrastructure to achieve maximum security, these changes 
will be done only through the change management process. Th e security management will deliver 
the input (RFC) for this change. Th e change manager is responsible for the change management 
process itself.
Implementation
Th e implementation subprocess makes sure that all measures, as speciﬁ ed in the plans, are properly 
implemented. During the implementation subprocess no (new) measures are deﬁ ned or changed. 
Th e deﬁ nition or change of measures will take place in the plan subprocess in cooperation with 
the change management process.
Evaluation
Th e evaluation of the implementation and the plans is very important. Th e evaluation is necessary 
to measure the success of the implementation and the security plans. Th e evaluation is also very 
important for the clients and possibly for third parties. Th e results of the evaluation subprocess are 

348  Information Security Management Handbook
used to maintain the agreed measures and the implementation itself. Evaluation results can lead 
to new requirements and so lead to an RFC. Th e RFC is then deﬁ ned and it is sent to the change 
management process.
Maintenance
It is necessary for security to be maintained. Because of changes in the IT infrastructure and 
changes in the organization itself, security risks are bound to change over time. Th e maintenance 
of security concerns the maintenance of both the security section of the SLAs and the more 
detailed security plans.
Maintenance is based on the results of the evaluation subprocess and insight into the changing 
risks. Th ese activities will only produce proposals. Th e proposals serve as inputs for the plan sub-
process and will go through the whole cycle, or the proposals can be taken in the maintenance of 
the SLAs. In both cases the proposals could lead to activities in the action plan. Th e actual changes 
will be carried out by the change management process.
Th e maintenance subprocess starts with the maintenance of the SLAs and the operation level 
arrangements (OLAs). After these activities take place, in no particular order, and when there is a 
request for a change, the RFC activity will take place, and after the RFC activity is concluded the 
reporting activity will start. If there is no request for a change then the reporting activity will start 
directly after the ﬁ rst two activities.
References
http://itsm.fwtk.org/.
http://www.itilpeople.com/.
http://www.itlibrary.org/.
ITIL—Security Management.
http://www.securityfocus.com/infocus/1815.

349
Chapter 26
Adaptation: A Concept for 
Next-Generation Security 
Application Development
Robby S. Fussell
Contents
Introduction .............................................................................................................................350
Background of Complex Adaptive Systems ..............................................................................350
Diversity and Mimicry ....................................................................................................351
Learning through Embodied Internal Models ................................................................352
Adaptive Agent Construction...................................................................................................353
Agent Rule Set: Performance System ..............................................................................353
Value/Credit Assignment ................................................................................................353
Discovery of Rules ..........................................................................................................354
Crossover, Mutation, and Genetic Algorithms ................................................................354
Current and Future Trends ......................................................................................................355
Artiﬁ cial Intelligence ......................................................................................................356
Adaptive Protocol for Streaming Video Real-Time Transmission Protocol .....................356
Other Areas of Research ..........................................................................................................357
Conclusion ...............................................................................................................................357
Acknowledgments ....................................................................................................................358
References ................................................................................................................................358

350  Information Security Management Handbook
Introduction
Security applications are constantly managing changes in their environment. Antivirus applica-
tions, ﬁ rewall programs, network components, intrusion detection systems, and various other 
types of functions that are involved with security are continuously confronted with change. Th e 
next phase of security application development is to introduce adaptation mechanisms within the 
application. Th is will provide the application with the ability to adapt to changes in its environ-
ment to provide enhanced security measures. However, to provide adaptation methods, adapta-
tion must be explained.
Adaptation is a characteristic of complex adaptive systems (CAS) that assists in causing a 
system’s evolution. CAS have the innate ability to conform and optimize based on their current 
environment [20]. CAS achieve this conformity or optimization via the feedback of agents within 
the system [8,13,16,19]. Agents are also known as the components that comprise a system. For 
example, the network devices within a local area network or the people of a speciﬁ c social network 
can be deﬁ ned as agents or components. Th e agents within complex systems contain a set of rules 
[19] that instruct the agents on how to behave based on their interactions with other agents and 
their environment.
Th erefore, complex systems that exist in unpredictable environments are constantly striving 
to adapt and conform to their surroundings. However, the deﬁ ned rules present within the agents 
must also change to make the system as a whole adapt to the change in the environment [13]. Th is 
process of the agents changing their set of rules is called learning [8]. Th e learning process can be 
viewed as the central function that propels the overall complex system to adapt. Th erefore, adap-
tation can be deﬁ ned as the process by which a system changes its goals and behavior due to the 
alterations in its surrounding environment to survive [15]. According to Ashby, “another way to 
understand adaptation is to think of it as behavior by organisms in order to support the stability of 
their internal environment, or homeostasis” [1]. Adaptation emerges through the learning process 
within the complex system. Th e system agents constantly interact with the environment and other 
agents based on a rule set or stimuli–response framework as illustrated by Holland [13].
Holland [13] illustrates this in his book by describing how the immune system adapts [10]. 
Holland [13] states that there are “lever points” in CAS. For example, a characteristic of CAS is 
chaos. By adding a small change to the system, diverse results can be observed. In the immune 
system example, if a small amount of an antigen, such as the measles virus, is introduced into the 
body, the immune system will react and create antibodies for the measles virus to protect the entire 
body from the disease [13]. Th e lever point has caused the immune system to learn about the virus 
and produce antibodies to protect the body. Th e immune system adapted to its new environment, 
the measles-induced environment, by producing antibodies to preserve the system.
Background of Complex Adaptive Systems
Cybernetics [5] is focused on how systems change in response to their current environment. 
Cybernetics is demonstrated by an entity outside a target system, which controls the target system 
based on changes in the surrounding environment. A concern with this theory is that it prevents 
the system from adapting spontaneously due to ﬂ uctuations in the environment. Th e outside 
mediator provides the input for the system it change based on which or adapts; therefore, cyber-
netics can also be deﬁ ned as a self-regulating system. An example of cybernetics is climate control 
inside a building. Based on the comfort of an individual, the climate ﬂ uctuates. Th e thermostat 

Adaptation  351
is a contained system and can adapt only by the predetermination of an agent outside the system, 
which is the individual. Th ere is another type of adaptation, which involves complex systems that 
perform adaptation within the system itself, without an outside controlling agent. Th is theory of 
adaptation is the focus of this chapter.
CAS are structured to adapt to their changing environment. Th ey perform this function 
without a ﬁ xation on control. Th e complex system is not controlled or modiﬁ ed by an objective 
observer outside the system. Th e agents who comprise the structure are responsible for its change 
[13,19]. Th erefore, for adaptation to occur, the following two elements are required:
Th e complex system must be placed in a state of diversity [16] or constant ﬂ uctuation for 
adaptation to emerge.
Agents within the system must modify the way they interact and process feedback informa-
tion, known as learning [8], which includes the use of embodied internal models.
Examining these two elements, which cause adaptation to occur, prompts the question, why 
does a system adapt? Complex systems adapt to optimize the system as a whole to the current 
 environmental conditions, and because the environment is always changing, open complex sys-
tems never cease adapting. If they do cease adapting, they will become extinct. A main element of 
CAS is the property of diversity.
Diversity and Mimicry
Holland [13] illustrates this diversity property by explaining that if an agent within the system is 
removed, the system will respond with a surge of adaptations that will ﬁ ll the role of the removed 
agent, also known as convergence [5]. One system that explains this diversity property is the 
biological phenomenon called mimicry [13]. Mimicry is the process of one species adapting the 
behavior or “likeness” of another species to obtain the other species’ beneﬁ ts [25]. An example 
illustrated in Ref. [13] is that of the monarch and viceroy butterﬂ ies. Th e monarch butterﬂ y 
digests the milkweed plant for food, which produces an alkaloid chemical inside the butterﬂ y. 
Birds that have eaten the monarch butterﬂ y over time continually regurgitated the ingested but-
terﬂ y. Birds now recognize the patterns of the monarch butterﬂ y and avoid it as a potential prey. 
Th is could possibly be explained as an adaptation process within the bird society, through which 
birds have learned not to prey on the monarch butterﬂ y by recognizing the monarch’s wing 
markings. Th is learning process, called “learned avoidance” [13], is also explained as a tagging 
mechanism [13], in which a tag is used by the bird to identify the wing pattern on the monarch 
butterﬂ y.
Back to the monarch butterﬂ y: there is another butterﬂ y called the viceroy butterﬂ y that has 
used mimicry to imitate the monarch butterﬂ y. Th e viceroy butterﬂ y is considered a prey to birds; 
however, because the viceroy butterﬂ y has adapted a wing pattern similar to that of the monarch 
butterﬂ y, birds using their tagging mechanism decline to consume the viceroy due to the possible 
negative outcomes. Mimicry can be viewed as a type of adaptation and diversity can be seen as a 
result of progressive adaptations. Th is mimicry is also seen in other species, like lizards and the 
chameleon that change their skin color to resemble that of the environment on which they cur-
rently reside to avoid being prey.
In the computer network environment, honeypots and honeynets can be seen as a means 
of mimicry. Some companies utilize honeypots and honeynets to mimic an attractive  hacking 



352  Information Security Management Handbook
 environment for potential malicious behavior to deter this behavior from the company’s legitimate 
computer infrastructure. In addition, routing protocols have adopted the diversity principle. For 
example, when a router is removed from the network, the routing protocol becomes aware of this 
removal and will send routing table updates to neighboring routers to route traﬃ  c correctly. By 
observing CAS, these systems contain another property element termed ﬂ ows [13].
Th e ﬂ ows property can be visualized as resources that are transferred between agents within 
a system. Based on these resources and the agent’s set of rules, feedback is produced. However, 
Holland [13] explains that ﬂ ows contain a property called the recycling eﬀ ect. Th e recycling eﬀ ect 
is based on the reuse of resource inputs in a system. Th is recycling eﬀ ect is explained by the rain-
forest example, in which continuous rainfalls wash the resources out of the soil and into the river 
system quickly, providing poor soil. However, the trees in the rainforest have adapted and they 
reuse the input resources from the soil that is retained to support over 10,000 possible distinct 
species of insects per tree [13]. According to Holland [13], systems like these that recycle their 
resources to exploit new niches for new agents will continue to thrive while other systems become 
extinct. Holland [13] states, “It is a process that leads to increasing diversity through increasing 
recycling …” also known in general as natural selection.
Learning through Embodied Internal Models
Th e next element in the study of adaptation is the process of learning [5]. For complex systems to 
adapt to their environment, the system must learn the optimal pattern of change to implement. 
To facilitate learning, the complex system’s agents must have a model in which anticipation and 
prediction can be generated. Th e internal model has two types:
Tacit—recommends a current action based on understood predictions of a desired future 
state [13].
Overt—a “look-ahead” process in which the model is used as a basis for explicit searching 
of options [13].
An example of prediction using a tacit internal model is that of Escherichia coli searching for food 
based on a chemical gradient [11,13]. An example of prediction utilizing an overt internal model 
is that of a computer chess game predicting possible case scenarios of diﬀ erent moves before it 
makes an actual move in the game. Th e underlying principle for the model is that it permits us to 
understand that which is being modeled.
Th e internal model is based upon the building blocks mechanism. Building blocks make mod-
els eﬀ ective. Building blocks can be viewed as various components that can be arranged to create 
a particular environment. For example, using the chess scenario, the chess program can create an 
internal model comprising a chessboard and various chess pieces. Based on the current location of 
the chess pieces, its environment, it can use its overt internal model to predict the best next move 
for an optimal outcome. Playing the diﬀ erent scenarios with the various building blocks, chess 
pieces and board, the chess program can learn how diﬀ erent interactions result and can predict its 
next move based on the forecasted results. Th is is also observed in game theory and in the use of 
genetic algorithms, to be discussed in the next section. Holland [13] eﬀ ectively states, “I cannot 
have a prepared list of rules for all possible situations, for the same reason that the immune system 
cannot keep a list of all possible invaders” [10]. Given our immune system, it would be impractical 
for it to store a blueprint of all possible viruses and process its reaction to a particular virus within 
a suitable amount of time.



Adaptation  353
Adaptive Agent Construction
To understand how agents within a CAS exhibit adaptation, their internal operations must be 
examined. Agents, as noted earlier, contain a set of rules that deﬁ ne how an agent behaves. Th is 
behavior output is utilized by other agents to mold the complex system into its optimal form based 
on its surrounding environment. Adaptive agents typically comprise the following three identiﬁ -
able characteristics:
Th e performance system—a rule base that processes input information and produces an 
output result [13].
Th e value/credit assignment—the process of applying positive and negative values to various 
parts of the performance system based on its success and failure [13].
Th e discovery of rules—the process of instantiating changes to the agent’s potential by 
replacing the negative-value parts with new alternatives [13].
Agent Rule Set: Performance System
Th e performance system is basically a set of rules on how the agent will respond to various inputs 
from the environment or other agents. Based on the processed rules for the input message, the 
agent will send output in the form of a message. Th e agent’s set of rules can be illustrated by a set of
IF/THEN or CONDITION/ACTION statements [6]. Whichever terminology is applied, the 
 functions are the same. Th e IF/THEN statement terminology will be used in this discussion for the 
agent performance system. First, the agent employs various stimuli to obtain the input message from 
the environment [13]. An example would be the senses used by the human body, a video camera used by 
various robots, or a network interface card for computer network devices. Normally, the environment 
will produce many messages that will be observed by the complex system; therefore, the system must 
ﬁ lter the input. Th e environment produces various detectors [13] that are noticed by the agent. If the 
agent has a rule for that detector, it will process it. Otherwise, the agent will ignore the detector.
For example, using the chess game scenario and algebraic chess notation, the opposing player’s 
queen is moved to cell c4. Based on this movement, the artiﬁ cial intelligence (AI) chess system 
will have an environment identiﬁ er for “move,” “queen,” and “position.” Each one of these identiﬁ -
ers will have a corresponding IF/THEN statement and the agent will process the rules and provide 
a response. Two actions will occur within the agent. Th e agent will process the input from the 
environment and it will also process input within the system based on actions provided by other 
internal rules. A series of “what if” scenarios [19] will be performed. Th is gives the agent the ability 
to produce the most optimal response to an environment input. If the agent was based on a single-
rule situation, it would need a rule for every possible environmental condition. Th is would not 
be feasible, as shown by the aforementioned immune system example. As noted by Holland [13], 
“With simultaneously active rules, the agent can combine tested rules to describe a novel  situation. 
Th e rules become building blocks” [19]. Th ese building blocks [19] contribute to the internal 
model of the agent. Th e novel situation that is created here can be obtained using the processes of 
mutation and crossover in genetic algorithms discussed under Crossover, Mutation, and Genetic 
Algorithms. Th e use of rules working in parallel can also be seen in behavior-based robots [21].
Value/Credit Assignment
Th is process will assist in providing a solution to how systems adapt. Credit assignment [13] is the 
process of assigning a value to various rules based on their eﬀ ectiveness. Agents will assign weights 




354  Information Security Management Handbook
or values corresponding to a rule’s helpfulness or unhelpfulness [13]. Th is process enables an agent 
and the overall complex system to adapt to environmental ﬂ ux. Th is process is based on competi-
tion. When a rule is selected, it gives its predecessor rule an increase in value. If the selected rule 
produces output, then its value will increase based on its future bids. Th erefore, reinforcement in 
rule eﬀ ectiveness is substantiated, with helpful rules getting higher precedence over less helpful or 
unhelpful rules.
Th e rule selection is based on competition. Th e more a rule is selected and outcome is produced, 
the higher its value will become. Th erefore, higher value rules are selected in time of competition 
among other rules. Th en, the rules that make the ﬁ nal direct contribution to the environment are 
rewarded. Th e overall concept of the credit assignment process is “to strengthen rules that belong 
to chains of action terminating into environmental rewards” [13]. Over time, default hierarchies 
are created as internal models. For example, a general rule that can typically satisfy any input from 
the environment can be executed. However, what if a more speciﬁ c rule exists that can satisfy the 
majority of conditions inputted from the environment? Th e process will construct internal models 
that consist of hierarchies or subsets, which can otherwise be seen as nesting.
Discovery of Rules
Th e next process in how agents adapt is in regard to rule discovery. How agents adapt with preex-
isting rules has been discussed earlier. Th is process will examine how agents adapt by the creation 
of new rules to manage new environmental conditions.
Th ere is one method by which new rules can be created and tested and that method is trial 
and error. Random trial and error states that what might have happened before has no eﬀ ect on 
what happens next. Th is method is not a feasible approach to rule discovery. Th e method that is 
employed is one of plausibility [13]. Holland [13] explains this by stating, “a component that con-
sistently appears in strong rules should be a likely candidate for use in new rules.” By choosing a 
number of strong rules and extracting the components within these rules to create new rules, the 
agent builds new rules on tested components, which is a more eﬃ  cient approach than random trial 
and error. Holland [13] demonstrates this by providing the example of the digital computer. Th e 
use of building blocks provided innovation that brought about the digital computer. Components 
such as Geiger’s particle counter, cathode ray tube images, wires for electrical current, and others 
were combined to create the digital computer. Th erefore, the agent not only processes rules based 
on environmental input but also constantly attempts to discover new rules that will assist it in 
optimizing its behavior.
Crossover, Mutation, and Genetic Algorithms
Crossover is a genetic operation by which two messages are used to generate a new message for 
testing [13]. Th e process of selecting the rules to be crossed over is based on their values or credit 
assigned. Th is process is called reproduction based on ﬁ tness [2,8,24] ranking. For example, the 
following are two diﬀ erent messages:
M1 = 100#101
M2 = #00####
M1 and M2 compose a message string based on a particular binary sequence used for conditional 
rule–based testing. Th e # symbol denotes either a 1 or a 0.



Adaptation  355
Example of rule:
R1 = IF (100#101) THEN (do_this_action)
R2 = IF (#00####) THEN (do_this_action)
Th e two rules, R1 and R2, have the highest values assigned compared to any other rule within a 
particular agent. Th e crossover process then selects a crossover point to generate a new message 
for implementation into a new rule for testing. For example, if the crossover point selected were 
position 5, with the ﬁ rst position being counted as 0, the new message for testing in a new rule 
would be the following:
M1^ = 100#1##
M2^ = #00##01
Example of rule:
R1^ = IF (100#1##) THEN (do_this_action)
R2^ = IF (#00##01) THEN (do_this_action)
Th e crossover process provides means for evolution through adaptation to ever-changing envi-
ronmental conditions. Th is is an overt process that creates internal models with novel building 
blocks.
According to Foster, “Adaptive mutation is deﬁ ned as a process that, during non-lethal selec-
tions, produces mutations that relieve the selective pressure whether or not other, non-selected 
mutations are also produced” [11]. Mutation is rather simple in that a 1, 0, or # in the above rules 
R1 and R2 is arbitrarily changed in the message rule. Th is mutation will yield another hypothesis 
for testing that includes plausibility as opposed to random trial and error. One might think, why 
does crossover or mutation need to be executed? If crossover or mutation does not occur, the same 
rules will just be copied to the next generation. Doing this only allows the existing generation to 
thrive; however, because CAS exist in continuously changing environments, permitting crossover 
and mutation allows for new hypotheses to be tested.
Last is the replacement of rules or strings in the new-generation agent over the current rules.
Th e process discussed here is a genetic algorithm [7,22,26] or genetic process for agents of 
CAS. Th e ﬁ rst step was to select the best ﬁ t set of rules and the strings or messages contained in 
those rules. Th e second step was to use the crossover and mutation procedures to generate new 
strings for testing. Th e third and ﬁ nal step was to replace the new strings in the next generation 
of the agent. Th e genetic algorithm is used to provide the agent with the most optimal set of rules 
for producing the most advantageous set of responses to environmental input, in other words, 
enabling the agent to adapt to changes in its environment.
Current and Future Trends
Th e understanding of adaptation in complex systems is essential. By attempting to discover the 
processes and components needed to explain adaptation, CAS can then be modeled. How can 
the framework of an adaptive agent as previously discussed be applied to current and future 
developments?



356  Information Security Management Handbook
Artiﬁ cial Intelligence
AI is a popular computer science discipline that scientists are continuously attempting to develop. 
AI has a component that is being researched constantly, which is adaptation [26]. AI is concerned 
with attempting to manufacture intelligence by human means. As stated by Bredeweg and Struss 
[4], “Reasoning about, and solving problems in, the physical world is one of the most fundamen-
tal capabilities of human intelligence and a fundamental subject for AI.” An example is that of a 
robot that can function in an  ever-changing environment. Th e goal sought after is to provide the 
machine the correct model to solve problems with ﬂ uctuating input, in other words, to exhibit 
intelligence [5,22]. For example, people exhibit intelligence by being able to solve problems they 
have never actually encountered. A person can be given an algebraic model such as:
x = 2y + z
Next, that same person can be confronted by various situations that call for solving a quantity 
given two distinct inputs. Th e inputs encountered and situations containing those inputs can 
always be changing; however, because the persons know the algebraic algorithm or model, they 
can always produce a correct solution. Simply trying to provide the person all the solutions for all 
possible inputs would be infeasible. Th is is the process of adaptation, and a framework for how 
agents adapt was discussed earlier. Th at framework is the type of model that is being applied to 
AI systems.
As stated by Sharkey and Ziemke [21], “Intelligence is found in the interaction of the robot 
with its environment.” Th e framework discussed here is based on this statement by providing a 
way for an agent to learn, which provides a means for the agent to adapt. However, when dealing 
with AI and robots, interaction with the environment provides cognition and this cognition can 
be embodied using two diﬀ erent views: Loebian and Uexküllian (see Ref. [21]). Th e objective with 
allopoietic machines is to make them into autopoietic (living) systems. Scientists are trying to 
use the two diﬀ erent views to accomplish this; however, more research must be performed on the 
behavior of agent-based systems [15].
Adaptive Protocol for Streaming Video Real-Time Transmission Protocol
Th e Internet provides a communication structure of which many people are taking advantage. 
Streaming video has become a popular means of delivering information to the consumer based on 
human cognition studies. However, protocols developed to allow for the transmission of informa-
tion across the network factored in the idea that all routers had the same amount of connections. 
According to Ottino [19], “it was shown recently that the real Internet has a scale-free structure, 
i.e., the distribution of the number of connections decays as a power law” [12]. It has now been 
shown that a few speciﬁ c routers employ the most connections and this is changing how commu-
nication protocols are being developed.
Th ere are diﬀ erent protocols being developed to provide an adaptive means for delivering video 
media data [14,23]. Th e Real-Time Transmission Protocol (RTP) [3] was developed to  provide a 
quality-of-service means for streaming video data across the Internet. In this situation, the ﬂ uctu-
ating environment is the data connection rate between the client and the server. Th e architecture 
of the RTP contains certain modules that perform certain functions such as delivery of the video 
data; however, the quality-adaptation module performs the calculations needed to adapt to the 
ﬂ uctuations in the data connection rate so that the streaming video will be delivered on a timely basis. 


Adaptation  357
Th e quality-adaptation module receives feedback information between the client and the server 
regarding data rates, and adapts the server based on the information analysis calculated by the 
quality-adaptation module.
Other Areas of Research
Th ere are other areas that are exploring agent-based models and the characteristic of adaptation. 
One area would be adaptation in computer security [9,10]. Some researchers are studying this area 
using the idea of having agents modeled after the immune system [10,27]. Corporations today 
have their own internal networks that provide internal communication among diﬀ erent depart-
ments and functions. Th is internal network also provides access for remote users and the ability 
for new systems to be directly attached to the internal network. Research is attempting to discover 
a way to permit authorized and nonintrusive systems on the network without infecting other sys-
tems or accessing restricted areas. Researchers have seen that this scenario resembles the immune 
system. Th e immune system’s function is to protect the human body from any chemical intrud-
ers. Th e immune system, as discussed, does not keep a list of all viruses but employs an adaptive 
framework for detection and deletion of the virus. Researchers are striving to utilize this concept 
and apply it to a model for computer network systems.
Other areas in which researchers are aiming to employ agent-based models are the stock mar-
ket and economic sectors. Th is research has been undertaken by John Holland [6,13] and some of 
his colleagues at the Santa Fe Institute and by Epstein and Axtell [19] in economics. Holland and 
his colleagues have attempted to use the agent-based framework along with genetic algorithms [7] 
to have their agents mimic the stock market based on a speciﬁ c company’s stock prices and other 
market indicators. One ﬁ nal area would be an adaptive protocol for wireless local area networks 
(LANs) [18] and other quality-of-service issues with network or system load [17]. Wireless LANs 
continuously encounter ﬂ uctuations to their environment and would beneﬁ t from the ability to 
adapt to those changes.
Conclusion
CAS can be termed as nonlinear structures that contain agents that interact and have the ability 
to adapt to a ﬂ uctuating environment. Th ese systems can also be characterized by their ability to 
self-organize. CAS evolve by performing random mutation, crossover, self-organization, alteration 
of their internal models, and natural selection. Examples of CAS range from organisms to societ-
ies and the nervous system to the immune system. Th e complex systems contain agents that have 
internal rules of behavior to solve input conditions from the environment or other agents. Th e 
agents are diverse, evolve, and adapt by assigning ﬁ tness values to their internal rules. Th ose rules 
with the lowest ﬁ tness rating eventually die out, whereas new rules are created by evolving the 
stronger rules through mutation and crossover. Th is process of evolution demonstrates the creative 
ability of CAS. One of the main elements in adaptation is diversity. For CAS to be creative, the 
following conditions must be satisﬁ ed:
Nonaverage behavior must be encountered
Agents in the system must not be identical and must interact with one another in various ways
Environmental ﬂ uctuations or “noise” must be propagated into the system




358  Information Security Management Handbook
For complex systems to adapt, they must learn. Th is learning process is shown by the system 
receiving a favorable response from the environment when the system produces output pertain-
ing to some input from the environment. According to Murray Gell-Mann, “Complex adaptive 
systems are pattern seekers. Th ey interact with the environment, ‘learn’ from the experience, and 
adapt as a result.” Th is can be seen in the operational states of various corporations across the 
world. By examining the corporate structure as a complex system in which the corporation has 
many interactions with customers, suppliers, employees, and so on, if the environment that the 
corporation operates in suddenly changes, the corporation must adapt or it will become extinct. 
If the corporation learns from the environmental changes and constructs internal models that 
produce favorable responses, it can survive.
Acknowledgments
I would like to thank the true complexity factor, God; Dr. Jim Cannady; the speakers; and the 
authors for their presentations and insights on the topics concerning CAS, AI, and adaptation.
References
 
1. Ashby, W.R., Design for a Brain. Chapman & Hall, London, 1960.
 
2. Boettcher, S., and Percus, A.G., Optimization with extremal dynamics. Complexity, 2003, 57–62.
 
3. Bouras, C., and Gkamas, A., Multimedia transmission with adaptive QoS based on real-time proto-
cols. International Journal of Communication Systems, 2003, 16, 225–248.
 
4. Bredeweg, B., and Struss, P., Current topics in qualitative reasoning. AI Magazine, 2004, 13–16.
 
5. Brooks, R.A., Intelligence without reason. Computers and Th ought, IJCAI-91, 1991, 1–28.
 
6. Casazza, D., Th e eﬀ ects of violence on the evolution of a simple society. Consortium for Computing in 
Small Colleges, 2002, 243–245.
 
7. Chalmers, D.J., Th e evolution of learning: An experiment in genetic connectionism. In D.S. Touretzky, 
J. Elman, T.J. Sejnowski, and G.E. Hinton, editors, Proceedings of the 1990 Connectionist Models 
 Summer School. Morgan Kaufmann, San Mateo, CA, 1990.
 
8. Chiva-Gomez, R., Th e facilitating factors for organizational learning: Bringing ideas from complex 
adaptive systems. Knowledge and Process Management, 2003, 99–114.
 
9. Dandalis, A., Prasanna, V.K., and Rolim, J.D.P., An adaptive cryptographic engine for IPSec 
 architectures. In Proceedings of the 2000 IEEE Symposium on Field-Programmable Custom Computing 
Machines, IEEE, 2000.
 10. Forrest, S., Hofmeyr, S.A., and Somayaji, A., Computer immunology. Communications of the ACM, 
1997, 88–96.
 11. Foster, P.L., Adaptive mutation: Implications for evolution. BioEssays, 2000, 1067–1074.
 12. Gong, P., and van Leeuwen, C., Emergence of scale-free network with chaotic units. Physica A, 2003, 
679–688.
 13. Holland, J.H., Hidden Order: How Adaptation Builds Complexity. Perseus Books, Reading, MA, 1995.
 14. Kasiolas, A., Nait-Abdesselam, F., and Makrakis, D., Cooperative Adaptation to Quality of Service 
Using Distributed Agents. IEEE, 1999, pp. 502–507.
 15. Lerman, K., and Galstyan, A., Agent memory and adaptation in multi-agent systems. In AAMAS 2003. 
ACM New York Press, Melbourne, Australia, 2003, pp. 797–803.
 16. Levin, S.A., Complex adaptive systems: Exploring the known, the unknown, and the unknowable. 
Bulletin of the American Mathematical Society, 2002, 3–19.

Adaptation  359
 17. Michiels, S., Desmet, L., Janssens, N., Mahieu, T., and Verbaeten, P., Self-adapting concurrency: Th e 
DMonA architecture. In WOSS ’02, ACM New York Press, Charleston, SC, 2002.
 18. Obaidat, M.S., and Green, D.G., An adaptive protocol model for IEEE 802.11 wireless LANs. Com-
puter Communications, 2004, 1131–1136.
 19. Ottino, J.M., Complex systems. AIChE, 2003, 292–299.
 20. Raz, O., Koopman, P., and Shaw, M., Enabling automatic adaptation in systems with under-speciﬁ ed 
elements. In WOSS ‘02, ACM New York Press, Charleston, SC, 2002, pp. 55–61.
 21. Sharkey, N., and Ziemke, T., Life, mind and robots: Th e ins and outs of embodied cognition, 2000.
 22. Sipper, M., On the origin of environments by means of natural selection. American Association for 
Artiﬁ cial Intelligence, 2001, 133–142.
 23. Striegel, A., and Manimaran, G., A scalable QoS adaptation scheme for media servers. In Proceedings 
of the 15th International Parallel and Distributed Processing Symposium (IPDPS’01). IEEE, 2001.
 24. Venkatasubramanian, V., Katare, S., Patkar, P.R., and Mu, F.-p., Spontaneous emergence of com-
plex optimal networks through evolutionary adaptation. Computers and Chemical Engineering, 2004, 
1789–1798.
 25. Wagner, D., and Soto, P., Mimicry attacks on host-based intrusion detection systems. In CCS ’02. 
ACM New York Press, Washington, DC, 2002.
 26. Wildberger, A.M., Introduction and overview of artiﬁ cial life: Evolving intelligent agents for model-
ing and simulation. In Proceedings of the 1996 Winter Simulation Conference, ACM New York Press, 
1996.
 27. Williams, J., Just sick about security. In ACM New Security Paradigm Workshop. ACM Press, New 
York, NY, 1996, pp. 139–146.


361
Chapter 27
Quantum Computing: 
Implications for Security
Robert M. Slade
Contents
Introduction ............................................................................................................................ 362
Quantum Introduction ........................................................................................................... 362
Quantum Concepts ....................................................................................................... 362
Superposition ........................................................................................................ 363
Entanglement ....................................................................................................... 363
Diﬃ  cult Problems .......................................................................................................... 363
Quantum Computing and Encryption ................................................................................... 364
Quantum Computers .....................................................................................................365
Quantum Encryption .................................................................................................... 366
Quantum Computing .....................................................................................................367
Analog Computing ................................................................................................367
Quantum Analog Computing .............................................................................. 368
Applications and Implications in Security ............................................................................... 368
Security Management .................................................................................................... 368
Security Architecture ..................................................................................................... 369
Access Control ................................................................................................................370
Cryptography ..................................................................................................................370
Physical Security .............................................................................................................371
Business Continuity Planning ........................................................................................ 372
Applications Security ..................................................................................................... 372

362  Information Security Management Handbook
Operations Security ........................................................................................................374
Telecommunications and Networking ............................................................................374
Law and Investigation .....................................................................................................374
Summary .................................................................................................................................374
Introduction
Th ere have been numerous mentions of quantum computing in the security trade press over the 
years. Generally, these concentrate on aspects of cryptography. However, our view of quantum 
computing tends to be contaminated by our knowledge of, and familiarity with, traditional digital 
computing. Quantum computers, as they have been developed, are based on architectures that 
are not the same as those in digital computers. Th erefore, it is probable, and even desirable, that 
quantum computers will not simply be “faster” versions of what we have now.
Quantum computing will probably make possible certain types of calculations and analyses 
that have been diﬃ  cult or impossible to do with traditional digital computers. Th ese new opera-
tions will, like every new development in information technology, have implications for security. 
New means of analysis and detection will be possible. At the same time, new vulnerabilities and 
methods of attack will be developed.
Quantum Introduction
If someone says that he can think or talk about quantum physics without becoming 
dizzy, that shows only that he has not understood anything whatever about it.
Niels Bohr
I use that section title deliberately and with two meanings attached. Yes, it is necessary to intro-
duce some basic concepts in quantum physics and mechanics, to proceed with a discussion of the 
possibilities of quantum computing. However, it should also be noted that quantum physics, as 
most people understand it, involves very small things.
Th erefore, I want to stress that quantum mechanics, and even the ﬁ eld of quantum comput-
ing, covers an enormous range. Th is introduction can be only the most cursory review of the topic, 
and, necessarily, not only will it lack scientiﬁ c rigor, but also it cannot address the full spectrum of 
technologies being pursued in regard to quantum technologies that may be of use to information 
technology.
Quantum Concepts
Quantum theory has been developed to explain and examine the state (particularly energy 
states) in regard to entities at very small size ranges, typically atomic and smaller. Although 
it is frequently stated that quantum mechanics explains operations at small sizes and classical 
mechanics applies to larger sizes, quantum mechanics is necessary to explain a number of char-
acteristics of the larger world, such as superconductivity. Because we are much more familiar 
with the operations of classical mechanics, many aspects of quantum mechanics contain appar-
ent paradoxes, such as the fact that the only way to specify exact energy states of small items 

Quantum Computing: Implications for Security  363
is with quantum mechanics, but these precise measurements can often only be expressed as 
probability clouds.
Superposition
One of the concepts of quantum mechanics is that of superposition. One of the aspects of superpo-
sition is that a given entity may have multiple possible states at the same time. In traditional digital 
computing, a bit (binary digit) has two possible states, on or oﬀ  (representing data states of 1 or 0, 
respectively). Quantum computing is based upon qubits (pronounced cuebits), which may be in 
a state representing both 1 and 0 at the same time and which may, in fact, represent many more 
than two distinct states. Qubits can, therefore, potentially carry much more information than 
traditional binary digits. Computing devices built using qubits may (and, in research situations, 
seemingly do) process multiple pieces of data at the same time.
Single photons are frequently seen and used as carriers of single bits of information, but they 
are also subject to quantum eﬀ ects. Recently, photons have been made to carry suﬃ  cient informa-
tion as to re-create entire (if somewhat simple) images and graphics are very data-intensive entities. 
Th e capacity to carry a good deal of information in a single photon may have additional implica-
tions for superposition and quantum computing overall.
Entanglement
If two objects (such as subatomic particles or photons) are created together, or become entangled, 
then certain properties are related (generally as opposites). Even when the objects are spatially 
separated there will be correlations between certain observable physical properties. Owing to the 
nature of quantum mechanics, when a property of one object is observed, it becomes ﬁ xed and 
the measurement of the other object will show an opposite property. Th e properties may be in 
an indeterminate state until they are observed, and, therefore, the ﬁ xing of state in an entangled 
object may indicate observation by an outside party—however, observation of the state will also 
determine it. Th is is known as the observer eﬀ ect, applicable to all quantum objects and not just 
those that are entangled.
Difﬁ cult Problems
Digital computers are a wonder and have allowed us to do so many things that we could not 
before they existed. Digital computers are getting better and faster every year. Still, there are 
certain types of problems that classical computer architectures solve poorly, if at all. Many of 
these restrictions are not simply limitations that will be overcome as computers get faster, but are 
inherent in the way traditional computers work.
People are very good at ﬁ nding and recognizing patterns. Computers do this poorly. Given 
an object, a computer can be taught to recognize it—if it is the same distance from the camera, 
if it is placed in the same orientation, and if the background has not changed. It is very dif-
ﬁ cult to get computers to take all these factors into account, compare two objects, and reliably 
decide that they are the same, because “same,” to a computer, means identical. It is, therefore, 
even more diﬃ  cult to get a digital computer to look at a number of diﬀ erent objects and decide 
which two, of all of them, are closest to being the same. All kinds of calculations have to be 

364  Information Security Management Handbook
done, and then redone, and then redone again, as each aspect of each item is compared against 
every other aspect of every other item. Th e more items are presented, the more work the com-
puter has to do.
Some problems are just generally hard. Th ere is, for example, the traveling salesman problem. 
A salesman has a territory and a number of cities to visit. What is the best route to be taken to visit 
them all, minimizing the distance and time to cover the circuit? If there are only two cities, the 
answer is obvious. Th ree is still obvious. Four might be harder, and you might have to calculate a 
couple of paths before you ﬁ nd the best. In fact, if the answer does not jump right out at you (and, as 
good pattern matchers, people generally can take a good stab at creating a reasonably good itinerary 
without doing much calculation), there is no algorithm for ﬁ nding the very best route other than 
creating each possible course, calculating the distance or time, and then comparing the courses until 
the shortest is found. Every city that you add does not just add to the complexity of the calculation: 
it compounds it exponentially. Other examples of this level of diﬃ  culty are problems that are NP-
complete, nonconvergent problems, and the Ising model (which is, itself, related to some quantum 
technologies in that it has implications for materials science and possibly superconductivity).
Th is “least path” problem turns up surprisingly often in all kinds of situations. It relates to staﬀ  
scheduling and to eﬃ  ciency studies. (Th ose who have had to deal with seating plans for a wedding 
or other special event will have encountered it: what is the best seating plan, given all the factors 
of who will speak to whom, which pairs cannot be seated together, and all kinds of preferences 
and social obligations.)
Weather forecasting and climate prediction are other applications that are extremely diﬃ  cult. 
Simulations of all kinds require the processing of a great deal of data. With digital computers we 
have to break the problem up into small boxes, and then process each box, and then ﬁ gure out how 
the change in box A aﬀ ects boxes B, C, and D, and then recalculate how the change in box B caused 
by the change in box A aﬀ ects boxes C and D. And then we have to recalculate how the change in 
box C caused by the change in box B caused by the change in box A will, in fact, change box A, 
and so forth.
It is felt that quantum computers will be able to deal more eﬀ ectively with a number of these 
diﬃ  cult problems. Superposition will allow for the processing of vast numbers of possibilities 
simultaneously, so that a “best” answer, of a number of potential answers, can be arrived at quickly. 
Entanglement may be able to allow us to impose additional conditions on calculations, beyond 
straightforward computation. Other aspects of quantum physics and mechanics may allow us to 
build computing devices that can perform calculations that are completely beyond our current 
capabilities and those of the projected developments in digital information technologies.
Quantum Computing and Encryption
A good deal of confusion exists about the possibility and capability of quantum computing, par-
ticularly in regard to the ﬁ eld of cryptography. Th ere are those who say that quantum computers 
will destroy the possibility of strong encryption and others who assert that quantum computing 
will make decryption by an outside party impossible. Proponents of both positions will state their 
cases ﬁ rmly and generally without ever coming to agreement.
Th is is because there are multiple aspects of quantum mechanics that are applicable to infor-
mation processing and many possible types of quantum computing. Th e following are three broad 
categories, which, although do not exhaust the possibilities, comprise the major areas of current 
research into the ﬁ eld.

Quantum Computing: Implications for Security  365
Quantum Computers
A great deal of the research into quantum computing has, in fact, been based on traditional digital 
architectures. Th e idea is intriguing: if you create a register that can hold two states at the same 
time, what kind of operations can you perform with it? Can you create basic logic circuits, the 
Boolean algebra of AND and OR? If so, can these basic logic circuits be combined into processing 
functions to create arithmetic or control circuits? Can those processing circuits be linked into pro-
grams? And, if you do create programs, can you process all possible initial inputs simultaneously 
and still come out with a meaningful answer?
You can create quantum registers. In fact, you can create them in a variety of ways. Unfortu-
nately, the means of creating quantum registers that have been found so far tend to involve rather 
specialized environments. You can trap atoms using crossed beams of coherent light (lasers). You 
can use electrons ﬂ oating on liquid helium. You can use the molecules of a liquid and process them 
with nuclear magnetic resonance. Th ere are a number of other possibilities. Unfortunately, all of 
them demonstrate a number of problems with control, measurement of results, and noise.
With all the diﬃ  culties, why create devices that do what we already do? In part this is because 
the reduction in size of computing circuitry (at the chip level) is starting to reach the size at which 
quantum eﬀ ects would become a problem. To keep Moore’s Law going, and create ever-smaller 
circuitry (and thus more capable and faster computers), we have to start changing the structure of 
transistors and logic circuits at that level. Th is is sometimes referred to as nanometer-scale classical 
computing and may be seen as a branch of nanotechnology.
It is, in fact, now felt that Turing’s “universal” computers are not completely universal. For 
one thing, the classical computer architectures are irreversible (a given process will give you a 
result starting from known values, but knowledge of the result and the process will not necessar-
ily tell you what the initial values were), and the laws of thermodynamics, therefore, require that 
a certain minimum dissipation of energy takes place during each computation. Th is means that 
we cannot keep making computers faster and faster by cramming more and more components 
into a smaller and smaller space: at some point we simply will not be able to get rid of the waste 
heat, and the processor will start to melt. Th eoretically, quantum computing can be made to be 
reversible, and so computations can take place with arbitrarily small heat dissipation. As well as 
keeping the computer from burning up, this also allows you to create computers with very small 
power requirements.
Owing to somewhat diﬀ erent restrictions of physics, it is also felt that simulations run on com-
puters with traditional architectures can be only approximations and that as you try to make the 
approximation more exact, the attempt very quickly makes the processing requirements excessive. 
Once again, theory holds that quantum simulations are exact and that the accuracy of the results 
we obtain from such simulations is simply dependent upon the care used to obtain the answer. 
Turning back to Turing, it is also felt that we may be able to reformulate the attempt to create a 
universal computational device with quantum theory and that this time it will work.
However, much research is looking toward a diﬀ erent kind of computational device, one that 
is based on classical digital architecture, but processes qubits with superpositioned data in a mas-
sively parallel way. Although there are experiments that have demonstrated the operation of this 
type of computing at a single gate level, and with limited numbers of qubits, at present most are 
conﬁ ned to very basic functions. In addition, most results have been concerned with single state 
changes and, therefore, single operations. It is not clear that operations can be strung together into 
a program. Th is may even be inherently impossible: because of the observer eﬀ ect, the beneﬁ ts of 
superposition may frequently be restricted to a single operation.

366  Information Security Management Handbook
Quantum Encryption
Although there are many possibilities for the use of quantum technologies in regard to cryptogra-
phy, so far the ﬁ eld has concentrated on quantum communication channels. Th rough the use of 
single photons as data carriers, a system may be devised so that secret keys may be derived despite 
communications being observable by all parties or such that the two communicating parties can 
determine whether any eavesdropping is taking place, or both.
Key negotiations can be determined using polarizations of photons. Single photons may be 
polarized in two ways and each type of polarization can result in one of two values. Th e values 
can be determined if the right detector is used, but the same detector cannot detect both types 
of polarization. (In fact this does not exhaust the possibilities: there can be linear and circular 
polarizations or polarizations at multiple angles for which the detectable values require the correct 
orientation of the detector. However, for the purposes of the negotiation the simplest level will suf-
ﬁ ce.) Th e initiator of the negotiation (“Alice,” in all the crypto literature) sends a string of photons, 
each of which is randomly polarized using one of the two ways and to one of the two values. Th e 
receiver (“Bob”) measures each photon, randomly picking one of the two detection methods and 
records his results. If he chooses the wrong detection method he will get the wrong answer, but, 
statistically, he is going to get about half of the answers correctly. Bob then publishes, publicly, the 
type of detector he used to measure each photon, but not what value he got. Alice can, publicly, 
tell him which photons he measured correctly. An eavesdropper (“Eve”) can try and measure the 
photon stream, but, even using the publicly declared information, will obtain only about half the 
data necessary to determine the key being used.
If Eve is eavesdropping on the line while the key negotiation is going on, she can, like Bob, 
guess correctly about half of the time. But roughly half of the photons will be polarized such 
that she cannot measure them. For certain types of detectors, if she makes a mistake in guessing 
the type of polarization, her detector will randomize the value of the photon passing through. 
Th erefore, even if Eve re-creates the photons that she did measure correctly, her eavesdropping 
will generate errors in about one-quarter of the data. Th erefore, Alice and Bob can take a random 
subset of the data and publicly compare it (and discard it). Th e comparison will make it obvious 
that someone is listening in.
Th e previous key negotiation and eavesdropping detection measures are based on the “BB84” 
algorithm by Charles H. Bennett and Gilles Brassard. Artur Eckert later proposed a detection 
scheme using the fact of entanglement. If entangled pairs of photons are created and submitted to 
Alice and Bob, then Alice can make measurements and determine, with above average probability, 
what Bob has measured. If Eve attempts to measure the photons, her measurements will weaken 
the correlations and this fact can be determined by Alice and Bob.
Although these systems are strong, they are not perfect, and Eve may have some information 
about the key being used and, therefore, some information about the communication going on. 
However, using other cryptographic functions, we can create privacy ampliﬁ cation starting with 
the key that Eve knows something about and creating a key that she knows very little about. 
Entanglement-based cryptography can do this at the quantum level, and this shows promise for 
the future of quantum encryption.
All traditional forms of encryption are subject to the man-in-the-middle attack, in which a 
malicious observer (Eve gets a break here: this one is generally referred to as “Mallory”) reads the 
message and modiﬁ es it to insert her own key. In the case of quantum encryption this becomes 
much more diﬃ  cult, because Alice and Bob have so many means of detecting whether someone is 
listening in and so much redundant data that Mallory cannot fully determine.

Quantum Computing: Implications for Security  367
At the moment, quantum encryption requires a dedicated ﬁ ber-optic connection, thus limit-
ing its use in general communications.
The concept of superposition is one of the reasons quantum com-
puting is so tied, in the mind of the security professional, to cryp-
tography. The application is obvious: build a quantum computer 
with a thousand qubits, and you will be instantly able to decrypt an 
encrypted message with every possible thousand-bit key, because all 
possible keys can be simultaneously represented in the machine.
This idea is not only generally attractive, it has, in fact, been for-
malized, in an algorithm by Peter W. Shor, as far back as 1994.
And, of course, there are certain large governmental bodies with 
large research budgets that are very interested in any paper that 
mentions the possibility of using quantum computing for decryp-
tion purposes. Therefore, a great many research papers mention this 
possibility.
However, although the possibility exists and research has been 
done in this area, the technical details of creating such a computer 
on a usable level have not yet been completely worked out. It is 
likely that other applications for quantum computing hold greater 
promise in the near future.
Quantum Computing
We have already discussed quantum computers: why are we now talking about quantum comput-
ing? Isn’t it the same thing?
Th ere are a great many computing devices that are not traditional digital computers. In fact, 
we use many of these devices to assist computers. Th ere are a number of proposals to use quantum 
devices to perform certain calculations as coprocessors to digital computers, rather than replacing 
them entirely. Quantum computing devices may not use traditional digital architectures.
Analog Computing
Aren’t all computers digital? No, not by a long shot. Th ere are a number of computers, or comput-
ing devices, that are analog.
One example is the spaghetti computer. Sorting is a rather time-consuming process in a digital 
computer. We have numerous sorting algorithms, and some of them are astonishingly eﬃ  cient 
(compared to the good old Bubble Sort), but all of them require that each entry in a list be com-
pared multiple times before everything is complete. (And the longer the list, the more times each 
entry gets compared.)
Take a bunch of spaghetti. Cut a piece to length for each number you want to sort. Holding 
the bunch of spaghetti ﬁ rmly enough to keep it under control, but loosely enough that the pieces 
slide against each other without jamming, bring one end of the bundle down against a ﬂ at surface. 
Instant sorting of the whole bunch with completely parallel processing. Th e spaghetti computer is 

368  Information Security Management Handbook
rather restricted to one application, and the data entry and output are somewhat tedious, but the 
processing itself is faster than any digital computer could accomplish: a single step.
Slightly more useful than the spaghetti computer is the slide rule. A slide rule gives completely 
precise calculations of certain multiplicative and logarithmic functions. Any imprecision results 
from our inability to be exact in either machining the device or setting the inputs and reading 
the output. And, once again, the processing is instant: as soon as you set the inputs, the result is 
available.
Analog computers have also been used in conjunction with digital computers. In the early 
days of digital computing, multiplication was a very time-consuming operation. Th erefore, some 
computers had analog multipliers that used ampliﬁ ers to speed up the process.
Quantum Analog Computing
Not all quantum computers are based on a digital model. An adiabatic quantum computer looks 
at energy states in the system. By ﬁ nding the lowest energy state we also ﬁ nd the best answer 
to a speciﬁ c problem. Using superconducting adiabatic quantum computers application-speciﬁ c 
processors can be created that are very much faster than normal digital computers and also use 
very little power for the processing itself. (If certain theories of information are correct, it may 
be possible that such computers are inherently the best at solving those speciﬁ c problems: that 
no possible computer that obeys the law of physics could do a better job. However, we are, at the 
moment, a long way from being able to take full advantage of these hypotheses.)
Th e best answer (and lowest energy state) turns out to ﬁ t very nicely with a number of the dif-
ﬁ cult problems noted earlier. Th e correspondence to the minimization problem would seem to be 
obvious, but the ability also relates to pattern matching and to simulation.
Applications and Implications in Security
Herewith is an overview of possibilities and problems raised by quantum computing as we exam-
ine the various domains of security. In terms of applications we cannot yet be completely certain 
of the actual operations and power of quantum computers, but this listing and examination con-
centrates on the three functions that are typically seen as areas where quantum computers have a 
decided advantage over classical digital computers. Th ese are calculations of selection of least path 
or least state, simulation, and pattern recognition.
Security Management
In security, we are all familiar with the importance of risk assessment, analysis, and management. 
Assessment and analysis are probably still diﬃ  cult and time-consuming, but we do have software 
tools that help us with the management aspect.
Typically, these utilities have to be loaded with all the risk assessments and analysis that have 
been done, the calculations of annualized loss expectancies for each risk, the various countermea-
sures, factors by which the safeguards will reduce the risks, and the cost of running the counter-
measures. (Among other things.) Once all of this data is loaded, the program will operate as a 
spreadsheet, allowing you to play “what if” games, in which you reduce or increase your expendi-
ture on the various controls and see what impact that has on the bottom line. Th e intent, of course, 

Quantum Computing: Implications for Security  369
is to try to ﬁ nd the greatest total cost savings given the set and (usually inadequate, but we will 
ignore that for now) budget that you have for security.
What these programs will not do is to tell you what that most desirable state is. To ﬁ nd it, you 
would have to create every possible combination of spending on controls, calculate the savings cre-
ated by each blend, and then determine which one gives you the greatest reduction in risk. Sound 
familiar? It is our old least path problem. Th erefore, a quantum computer may be able to do that 
last risk management step for us (as long as we have done the assessment and analysis properly in 
the ﬁ rst place).
Information classiﬁ cation is a diﬃ  cult and time-consuming task and one that is hard for 
people to do in a consistent manner. Th ere are very few software tools that can assist us with the 
classiﬁ cation process. A good deal of the inconsistency results from not recognizing patterns that 
indicate this information is of the same sensitivity as that data. Th erefore, a system that can match 
patterns may be able to do a good deal toward helping us with this particular problem.
Quantum computing is a new technology. Any new technology will require a new risk assess-
ment: part of the following sections of this chapter note areas where the existence of the new 
technology may create new vulnerabilities or require greater vigilance on our part. Th ere is one risk 
assessment that management should probably be looking into: what, for our particular industry 
and company, is the risk of investing, or failing to invest, in quantum technologies?
Security Architecture
Computer and system architectures have security implications. Any new technology needs to be 
assessed in terms of the risk it may present. A completely new architecture means that there will 
be new vulnerabilities. We would be remiss in implementing any such novel technology without 
understanding potential security issues.
However, we have great diﬃ  culty in analyzing our current architectures, and security architec-
tures, to determine whether they are eﬀ ective. Th e standard practice tends to create and implement 
an architecture, using experience and shared wisdom (such as security guidelines and frameworks), 
and then see how eﬀ ective it is (or whether it is eﬀ ective at all). It would be very helpful to have a 
simulation of vulnerabilities and protections driven by a given architecture and to be able to evalu-
ate diﬀ erent architectures in terms of which one gives the best result. Simulation is, however, very 
diﬃ  cult and time-consuming—with traditional systems. If quantum computing allows for more 
eﬀ ective simulation we may be able to do better than trial and error.
One aspect of a quantum architecture is in regard to integrity. Quantum devices are highly 
susceptible to noise of all types, thermal, electromagnetic, and radio frequency. Some have to 
operate at temperatures close to absolute zero, others need to be in a vacuum, most need to be 
shielded from radio transmitters (including wireless local area networks and cell phones) and vari-
ous electrical devices. All quantum equipment needs careful handling of input and output, and 
an analog apparatus in particular requires input/output ﬁ ltering. Even with all this care there still 
seems to be just a bit of indeterminacy in the results.
At the moment, and with the fairly rudimentary computing mechanisms developed, “voting” 
(comparison of multiple devices or multiple runs) and checking of errors against other standards 
is suﬃ  cient. However, as applications become more complex, these measures may no longer be 
suﬃ  cient.
Fortunately, quantum error correction is a recently determined general outline, which indi-
cates that, using a concept of entanglement transfer, quantum information processing can be used 

370  Information Security Management Handbook
to correct a wide range of noise in a properly designed quantum system. It has been demonstrated 
that rectiﬁ cation can be achieved even when the remedial operations are faulty. Th is may have 
ramiﬁ cations for fault-tolerant computing.
Access Control
Th e posited pattern-matching capabilities of quantum computing may have a couple of diﬀ erent 
applications in access control. Biometrics would likely beneﬁ t from improved abilities to match 
and compare. At the moment biometric matching must be done on the basis of constructs and 
representations of biometric data that lose a great deal of information in the symbolization pro-
cess. In addition, the stored data may be fairly arbitrary, and, therefore, real similarities between 
samples and stored data may not be as evident. Th e ability to do more direct comparisons may 
have implications for accuracy, as well as speed and new forms of data representation.
Intrusion detection relies on two major forms of analysis: the matching of patterns of known 
attacks and the noting of deviations from normal operations. In both cases the ability to identify 
patterns would be of beneﬁ t. Quantum computing support for anomaly-based intrusion detection 
would be able to picture, more accurately, the normal state of aﬀ airs, as well as determining which 
deviations are signiﬁ cant. Signature-based systems would be able to use a baseline to identify new 
attack signatures and also to note attacks that are similar to those already in the database.
Information ﬂ ow analysis is a useful exercise for determining possibilities for improper infor-
mation disclosure. It is, however, a tedious and time-consuming business. Th e processing involved 
in ﬁ nding potential ﬂ ow paths requires the investigation of many possibilities and is, therefore, 
quite similar to our least path problem. In addition, simulation-type activity is involved. Th erefore, 
on two counts, the analysis of ﬂ ow paths and determination of covert channels could likely beneﬁ t 
from quantum computing.
Cryptography
I have already discussed, in some detail, quantum communications and encryption, as well as key 
negotiation and eavesdropping detection, and have noted that parallel factorization, processing, 
and decryption activities have been much explored in the popular literature. Th ere are, however, 
additional areas and topics to consider in regard to cryptography.
Given the feeling that current encryption algorithms may be susceptible to attack by quantum 
methods, work on new algorithms tractable by neither classical nor quantum computing would 
be indicated as a useful ﬁ eld of study. Indeed, although the prime factorization of large numbers 
is seen as a threat to the Rivest–Shamir–Adleman algorithm, it is by no means obvious that other 
currently used algorithms are equally at risk. Th e need for assessment of nonfactoring algorithms, 
and the development of new algorithms, is manifest.
We are all aware of the importance of randomness in using and operating cryptographic sys-
tems. Quantum devices may be of beneﬁ t to cryptography in terms of generation of randomness. 
As previously noted, most quantum machinery is delicate and subject to signiﬁ cant issues of noise. 
We can turn this to our advance by capturing and processing that noise. In addition, numerous 
quantum structures can be established with indeterminate outcomes and can be used as auto-
mated “coin-ﬂ ipping” devices. (Using these structures is not always easy: care should be taken to 
ensure that the devices are not somehow biased because of careless construction. Even this can be 
used to advantage: we may be able to use a biased, but random, keystream in certain situations 

Quantum Computing: Implications for Security  371
in which we may be either correcting for biased data or attempting to disguise the nature of the 
traﬃ  c or the type of encryption. We can, of course, bias pseudorandom streams, but a biased but 
still random stream may be an advantage.)
Implementation has always been the greatest source of problems and weaknesses in crypto-
graphic systems. Analysis of implementation vulnerabilities is not a straightforward task. Th e use 
of quantum computing to improve simulation of a system may be able to identify these types of 
ﬂ aws in operation.
Physical Security
Th ere is probably not a great deal that quantum computing can do to beneﬁ t physical security. As 
previously noted, biometrics may be improved and are being increasingly used for physical access 
control. Th ose charged with physical security should, however, be aware of the new demands and 
requirements that quantum computing will place on the plant environment.
As has also been mentioned in prior discussions, a number of proposed quantum devices 
are highly susceptible to radio frequency and electromagnetic interference. Specially constructed 
computer rooms will probably return as some of these computing systems are introduced. Faraday 
cages and other TEMPEST measures may also come back into prominence. Th ese elements would 
not be used to preclude emanations from disclosing information, but to prevent noise from cor-
rupting data and processing.
We have always had to pay attention to air conditioning and refrigeration requirements for 
computers, but quantum computers have entirely diﬀ erent needs in this realm. Many quantum 
devices require operating temperatures near absolute zero, either for superconductivity or for other 
physical eﬀ ects. Room temperature, which is quite suitable for normal computer equipment, is 
about a hundred times greater than the temperature in interstellar space. Interstellar space, as 
cold as it is, is a thousand times too hot for the proper operation of the D-Wave Systems Orion 
computer, for example.
There is some irony in the fact that these computers may have 
extremely small power requirements in terms of the information pro-
cessing itself, but will demand huge refrigerators to keep operating 
near absolute zero. However, when ENIAC was built, it was famous 
in business and academic circles for being the largest computer con-
structed up to that time—and in physical plant communities for hav-
ing the largest refrigeration system ever put in one place.
In the near term, as quantum devices begin to come onstream, they will be extremely expensive 
pieces of equipment, with special requirements that are poorly understood. (For example, the gate-
level operations of these devices are poorly understood even by their designers, and undoubtedly 
we will discover failure modes under unusual conditions.) Initially, the advantages to a company 
that is running an application supported by quantum processing will make it distinctive in the 
marketplace. However, the failure of that device will also jeopardize the special place of the com-
pany and will create yet another possible point of failure. Th erefore, special attention must be paid 

372  Information Security Management Handbook
to the creation of deﬁ nite controls and protections that will guard the devices, not only against 
attacks, but also against carelessness and ignorant usage.
Business Continuity Planning
As with risk analysis and management, so business impact analysis is a diﬃ  cult and laborious 
aspect of business continuity and disaster recovery studies. Th e same type of least path calculation 
that can aid risk and safeguard analysis will assist in this area as well. Both least path and simula-
tion analyses can be used to ﬁ nd functions with a high concentration of business dependence as 
well as single points of failure.
Simulation will also assist with the testing of business continuity plans. We already use simula-
tion tests, but on a very limited level. Quantum simulations will be able to assess a very wide range 
of conditions and possibilities and to determine combinations of events and situations that may 
overwhelm our prepared plans.
In the medium term, quantum computing applications, along with various forms of artiﬁ -
cial intelligence, will likely be able to guide and assist decisions about the optimal assignment 
of resources to address disasters. Th is will probably be initially used by governmental agencies 
in managing large-scale disasters, with capabilities and systems being made available to regional 
governments as the technology develops. Very soon thereafter the costs and capabilities will be 
within the range of large corporations (initially possibly on a contract or service basis) for the 
management of disaster recovery and response, and the beneﬁ ts, in terms of damage mitigation 
and recovery speed, will probably be immediate.
For those companies using quantum computing, there will be considerations for continuity of 
operations for these special devices. For example, given the nature and operating environment of 
the equipment created to date, damage may result if the power or cooling fails. In the near term, 
it is probable that a mere loss of power will result in damage to, or loss of, the computing elements 
themselves and a requirement to re-create sections of the environment.
Applications Security
Th ere are many applications for quantum computing in the ﬁ eld of application security; these 
examples are only a few.
Testing of software is necessary, but problematic. Although much work is being done in the 
ﬁ eld, it is still the case that testing of applications and systems is more of an art than a science.
Testing involves a kind of simulation, and test inputs are generally submitted for processing based 
on a “best guess” of which combinations might present a potential diﬃ  culty for the program. 
Quantum simulations should be much more accurate in identifying problems and should be able 
to test a much wider range of inputs and combinations.
A great deal of security work involves database analysis, such as the pattern-matching require-
ment mentioned earlier in regard to biometrics. Th erefore, a number of new security applications 
themselves are likely to result from the capability. Th is, of course, raises both beneﬁ ts (in regard to 
safety) and concerns (in regard to privacy).
In terms of database security itself, two long-standing and intractable problems have been data 
aggregation attacks and inference attacks. Although it is unlikely that any speciﬁ c protections 
against database aggregation will result from quantum computing, the problem analysis, using 
pattern matching and simulation, will be useful in determining the extent of the problem, the 

Quantum Computing: Implications for Security  373
information classiﬁ cation level appropriate to a given collection, and probably the eﬀ ectiveness of 
controls applied in a given situation.
In attempting to extract useful information out of ever-larger databases we have turned to artiﬁ cial 
intelligence methods. Part of this research involves creating applications that learn how to ﬁ nd “inter-
esting” results for themselves. Th is requires the ability to determine and match patterns, and we have 
previously noted the suitability of quantum computing in this regard. In terms of traditional comput-
ing, the most eﬀ ective programs have used the neural network model, based on what we know about 
the formation of neurons in the brain and the strengthening of links as they are used and encountered 
in new situations. Quantum computing can be used to support neural net analysis with faster pattern 
matching. In addition, quantum computing can do direct pattern matching, ﬁ nding the same pat-
terns in diﬀ erent ways. Similarly, cross-supporting assistance can be applied to fuzzy logic.
Neural nets are subject to speciﬁ c and systematic types of errors, known as superstitious learn-
ing. A pattern may appear randomly and, due to chance associations, become learned and then 
strengthened over time, even though there is no real relation. We have previously noted that noise 
and errors are a problem for quantum computers. However, because of the diﬀ erent architectures and 
approaches, neural net superstitious learning will result in errors that are diﬀ erent from the random 
errors generated out of quantum equipment. Th erefore, the two types of processing can act as checks 
on each other’s errors: mistakes may arise, but they will be diﬀ erent types of miscalculations.
Th e ability to assess errors will be a major consideration. A standard approach, when testing 
new systems, is to check results computed against those that are expected. Given the new capa-
bilities of quantum computing technologies this becomes problematic: how do you check on the 
results when the question you are processing is impossible to compute by classical methods?
As previously noted in relation to intrusion detection, the pattern-matching capabilities of 
quantum computing can be applied to malware detection and the assessment of botnet operation, 
control, and ownership. Th ese questions have become extremely complex and new approaches and 
tools are needed badly.
The question of malware analysis relates to an earlier point in regard 
to the universality of Turing machines. Fred Cohen’s determination 
of the “undecidability” of computer viruses is based on analysis 
using the Turing machine model. Cohen found that there cannot be 
a “perfect” antivirus program: any detection program will err either 
by failing to ﬁ nd a virus or by raising a false alarm over an innocent 
program, or both. Given that Turing machines are not truly universal, 
does this result hold?
In the case of virus detection, it appears that the original result is 
valid. However, there are many theories in security that have been 
assessed based upon the initial Turing model. Academic research 
into security architecture models should be checked for additional 
implications of quantum models.
As stated earlier, these notes are the merest beginning of the implications of quantum comput-
ing for the security of applications. Quantum methods will result in completely new paradigms in 
programming, and the changes will be even greater than those that accompanied the introduction 
of object-oriented or functional programming to the original procedural archetype.

374  Information Security Management Handbook
Operations Security
As if securing computer operations was not hard enough, combinations of classical and quantum 
devices and functions will vastly increase the complexity of the situation. Troubleshooting of 
problems will become even more diﬃ  cult. At the same time, quantum simulations can greatly 
assist in troubleshooting of intricate dilemmas.
An ongoing and intractable problem in operations is the detection of insider attacks or misuse. 
More sophisticated pattern matching and recognition, made possible by quantum computing, 
may be able to assist in catching such activity in the planning or setup stages rather than long after 
the damage has been done.
Telecommunications and Networking
In terms of network security, it is likely that quantum technology will be more of an additional 
demand than an assist. As noted, quantum encryption will require special channels and those 
of special types. In addition, given their cost and special environmental requirements, quantum 
devices are likely to be remotely accessible for some years to come. Th erefore, data and results of a 
highly sensitive nature will have to be protected during communication.
However, as with intrusion and malware detection, network attack analysis using pattern-
matching capabilities may be greatly enhanced. Proper large-scale network simulation may also be 
able to assist with network architectures and provisioning that is more resistant to failure.
Law and Investigation
Taking advantage of quantum capabilities in pattern matching and simulation, new forensic anal-
ysis tools may be able to speed the time-consuming task of ﬁ nding relevant evidence in computer 
systems and data. However, even our current forensic ﬁ ndings make presentation and acceptance 
of the implication problematic in court situations. Th e often counterintuitive nature of quantum 
technologies will make the educational and explanatory problems all the greater.
As noted in regard to business continuity planning, incident response will likely beneﬁ t from 
guidance systems based upon quantum computing and artiﬁ cial intelligence. In the long term, 
similar systems will likely be available to guide response to even minor incidents, ensuring that 
covert attacks are not able to masquerade as minor glitches or annoyances and that the best com-
bination of attack restriction and evidence collection allows for both protection and investigation, 
without one activity compromising the other.
Summary
Quantum computing is a ﬁ eld that is only just starting to move out of the arena of research and 
into real application. However, the implications for security indicate that attention should be paid 
to developments to be able to take the earliest opportunity to address a number of diﬃ  cult tasks 
and problems.

DOMAIN
  
8
LEGAL, REGULATIONS, 
COMPLIANCE, AND 
INVESTIGATION
Information Law


377
Chapter 28
Compliance Assurance: 
Taming the Beast
Todd Fitzgerald
Contents
What Is Compliance? ...............................................................................................................378
Th e Regulations Are Coming, the Regulations Are Coming! ...................................................378
Control Frameworks and Standards ........................................................................................ 380
Let’s Name a Few Control Frameworks and Security Standards ..............................................381
Committee of Sponsoring Organizations of the Treadway Commission .........................381
Information Technology Infrastructure Library ..............................................................381
Control Objectives for Information and Related Technology ........................................ 382
International Organization for Standardization (ISO) 17799 ........................................ 382
Federal Information System Controls Audit Manual ..................................................... 383
National Institute of Standards and Technology 800-53 Controls ................................. 383
Technical Control Standards ......................................................................................... 384
Penalties for Noncompliance ................................................................................................... 384
Enter Best Practices ..................................................................................................................385
Th e 11-Factor Security Compliance Assurance Manifesto........................................................385
Final Th oughts ........................................................................................................................ 388
Further Readings .................................................................................................................... 388
As children we are taught by our parents to behave ourselves, obey their instructions, and be kind 
to others. As we go to school, teachers tell us to sit at our desks, follow the rules, learn the material, 
and prepare for the exams. As teenagers, we test the rules, bending the edges, seeing what we can 
“get away with” to deﬁ ne our own independence. Parents understand that we are “just growing up” 

378  Information Security Management Handbook
and this is part of the process of becoming an adult, so they are tolerant within reasonable limits. 
As children graduate high school and move on to college or other life experiences, more rules are 
learned, yet this time they do not come from our parents, they are society’s rules and breaking them 
has deﬁ ned civil, criminal, and societal consequences. Frequent speeding tickets, drunk driving, 
and large numbers of accidents equal increased insurance rates or loss of driving privilege. Studying 
hard and getting good grades in school equal graduation and increased job opportunities. Learning 
the sales techniques on that ﬁ rst sales job combined with hard work equals increased income.
Rules. Regulations. Policies. Standards. Just as we learn as we grow from being children to 
adults that there are rules that must be followed, so too have organizations “grown up” in an 
environment of increasing rules and regulations. Th e increasing number of similar but diﬀ erent 
regulations makes achieving compliance a very time-consuming activity.
What Is Compliance?
Answers.com provides a deﬁ nition for compliance as “the act of complying with a wish, request, 
or demand; acquiescence.” It further provides a deﬁ nition, which may resonate with how many 
companies feel about the plethora of government regulations, “a disposition or tendency to yield 
to the will of others”! Compliance with security regulations is no trivial task; in fact, in a survey 
conducted by the Security Compliance Council, as much as 34 percent of information technology 
resources were being consumed to demonstrate compliance. Th ese are valuable, technical resources 
that could be deployed to other high-value, new development eﬀ orts or to improving the eﬃ  ciency 
of operations, but rather are being utilized to ensure that the regulations are being followed. Th is is 
a signiﬁ cant burden for large businesses; however, in smaller businesses the resources dedicated may 
be smaller in numbers, except that the hidden costs must be considered, such as burnout of the one 
or two information technology (IT) people who are working many hours of overtime to comply.
Compliance ensures that due diligence has been exercised within the organization to meet the 
government regulations for security practices. Compliance can be achieved in many ways, as many 
of these regulations provide a higher level deﬁ nition of the requirement of “what” must be done; 
however, the lower level, platform-speciﬁ c details of how the solution is implemented are typically 
not stated in the regulation itself. Th e regulation’s primary task is to ensure that the appropriate 
processes are in place, people are aware of their responsibilities, and technical issues are appro-
priately managed. Th e regulations are drafted at a policy level and, as such, it would be diﬃ  cult 
to mandate the selection of a speciﬁ c platform from a particular vendor, as this would provide an 
undue advantage for that vendor. Furthermore, because technology changes at a pace faster than 
the policy-making process, by the time new legislation was enacted, the legislation would most 
likely be out of date. Th is approach would also stiﬂ e innovation by mandating the use of speciﬁ c, 
recent technology to address security challenges.
Th e landscape of government regulations and security control frameworks covered in the sub-
sequent sections is shown in Exhibit 28.1.
The Regulations Are Coming, the Regulations Are Coming!
Over the past several years, an increasing number of regulations that focus on providing adequate 
security have appeared. Th ese regulations are typically focused on a vertical industry or segment 
of the economy, in an attempt to mitigate known issues within an industry.

Compliance Assurance: Taming the Beast  379
One of the earlier U.S. government regulations that provided broad public coverage of informa-
tion security issues was the Gramm–Leach–Bliley Act (GLBA) of 1999. GLBA was also known as 
the Financial Services Moderation Act of 1999 and was aimed at ﬁ nancial institutions that maintain, 
process, and collect ﬁ nancial information. Th e Sarbanes–Oxley Act of 2002 was enacted following 
the inaccurate accounting practices of organizations such as Enron/Arthur Andersen and WorldCom 
and to fulﬁ ll a need to have adequate internal audit controls for ﬁ nancial reporting. Organizations are 
required under this act to have the controls independently audited and attested to. In addition to these 
regulations targeted at ﬁ nancial transactions, the Payment Card Industry (PCI) Data Security Stan-
dard, ﬁ rst released in 2005, establishes extensive requirements for payment card security. Th e major 
credit card companies, in an eﬀ ort to help ensure the implementation of consistent global security 
measures for payment processing, formed the PCI Data Standards Council.
Exhibit 28.1 Regulations, control frameworks, standards, and implementation landscape.
Regulations 
Compliance assurance 
Health Insurance Portability and Accountability 
Act (HIPAA) 
Gramm−Leach−Bliley Act (GLBA) 
Sarbanes−Oxley Act (SOX) 
Federal Information Security Management Act 
(FISMA) 
U.K. Data Protection Act 
Payment Card Industry Data Security Standard 
(PCI) 
 
Control Objectives for Information and 
Related Technology (COBIT) 
ISO17799:2005 
NIST Recommended Controls (800-53) 
Committee of Sponsoring Organizations 
of the Treadway Commission (COSO) 
IT Infrastructure Library (ITIL) 
Control frameworks and standards 
Control frameworks and standards demonstrate compliance of regulations  
supported by technical implementations 
Technical implementations 
Vendor-specific platform controls 
Defense Information Systems Agency Security Technical Implementation Guides 
SANS Institute Top 20 vulnerabilities  
National Institute of Standards and Technology Special Publications 
NIST National Vulnerability Database 
Managerial 
processes 
Operational 
processes 

380  Information Security Management Handbook
Th e Health Insurance Portability and Accountability Act (HIPAA) was enacted in 1996; how-
ever, the Privacy Rule was not in eﬀ ect until April 2003, and the compliance for the ﬁ nal security 
rule was eﬀ ective April 21, 2005, following a two-year period subsequent to the publishing of the 
rule for implementation. Th e ﬁ nal security rule was rewritten based on many public comments 
and reoriented to align better with and support the privacy rule. Th e intent of the HIPAA ﬁ nal 
security rule is to ensure that adequate security protections are created to protect the security and 
privacy of healthcare information maintained by healthcare providers, health insurance plans, 
employers, and those handling healthcare electronic transactions. Congress recognized that as 
eﬃ  ciencies are gained through the implementation of electronic transactions, individual privacy 
rights need to be protected by the application of appropriate security safeguards.
Security breach notiﬁ cation laws are appearing in many states (34 states had adopted legisla-
tion by late 2006), with the most noteworthy being California Senate Bill 1386, which went 
into eﬀ ect July 1, 2003. Th e laws generally require the prompt notiﬁ cation to each individual of 
disclosure of their personal information. Th e laws vary on the deﬁ nition of what is considered 
personal and the timeframes; however, the intent is consistent that companies have an obligation 
to consumers to protect their information and when these protections are compromised, there is a 
corporate responsibility to “make it right.” Identity theft has become a front-and-center issue over 
the past several years, receiving increased media attention.
For those organizations involved in international business, country-speciﬁ c laws and regulations 
need to be researched as well. Th e U.K. Data Protection Act of 1998 has requirements for the privacy 
of information with respect to what can be maintained, processed, used, and disclosed. Th e European 
Union Data Retention Laws passed in 2005 place requirements on Internet service providers and 
phone companies to maintain phone and electronic messages for a period of six months to two years.
Th e Federal Information Security Management Act (FISMA) of 2002 was formulated to 
ensure that adequate information security practices were being performed across the large, dispa-
rate computing infrastructures of the U.S. government. FISMA is applicable to all U.S. govern-
ment agencies and their contractors, whereby the security program is evaluated in a report card 
style, with letters A, B, C, D, and F. Th e results are reported annually to Congress for each of the 
government agencies. For most agencies, the average was a D to D+ score (2003–2005), with 
these scores increasing in some government agencies to bring the total average score to a C− in 
2006. Th ere is still much to be done and the measurement is providing a barometer to gauge the 
improvement. FISMA represents the government’s eﬀ orts to perform the due diligence necessary 
for information security and sets the expectations.
Th ere are more regulations and security policy guidance, such as Oﬃ  ce of Management and 
Budget Circular A-123; Homeland Security Presidential Directive HSPD-7, for critical infrastruc-
ture protection plans to protect federal critical infrastructures and key resources; IRS Publication 
1075; tax information security guidelines for federal, state, and local agencies; the list goes on.
Control Frameworks and Standards
If a person wants to build a new house, he or she cannot just put the house anywhere. Th e land 
must be approved by the city for development, the appropriate building permits must be obtained, 
and there are certain rules for connecting to services such as water, electricity, and roads. Th ese are 
the regulations, or policies, that the homeowner and builder must comply with. Once the expecta-
tions of these regulations are understood, the builder can utilize many diﬀ erent processes to build 
the house for the homeowner. Maybe he builds 10–15 homes at once, rotating the electricians, 

Compliance Assurance: Taming the Beast  381
plumbers, and carpenters from one house to the next. Alternatively, he may be a small builder, 
doing much of the work with jack-of-all-tradesmen. Th e houses may have diﬀ erent solutions for 
the exterior, such as brick, wood, vinyl siding, and stone. To implement the architecture, each role 
has a diﬀ erent function and a diﬀ erent set of supporting procedures. Th e electrician’s tasks are 
much diﬀ erent from the plumber’s; however, they both contribute to the same big-picture goal, 
to build a house.
Building the “security house” starts with understanding the policies, or regulations, noted ear-
lier. From there, control frameworks are decided upon to establish the next level of requirements 
or the approach to demonstrating that compliance is being achieved. In the housing example, this 
would provide the framework for how the electricians, plumbers, and carpenters are governed, or 
supervised; the identiﬁ cation of the tasks that must be performed; and a way of measuring and 
monitoring the results. Th e detailed procedures or speciﬁ cations for how an electrician performs 
job are analogous to the lower-level, detailed technical, platform-speciﬁ c standards that support 
the overall framework. For example, the secure settings for mobile code and active content controls 
(i.e., ActiveX, Java, and VBscript) may be deﬁ ned in a technical standard, just as the electrician’s 
procedures would specify the correct wiring required for a 220 V dryer circuit in the house. Th e 
control framework deﬁ ning the requirement to identify if a dryer is needed, and to implement the 
circuit, would typically not contain this level of details.
Let’s Name a Few Control Frameworks and Security Standards
Multiple frameworks have been created to support the auditing of the implemented security con-
trols. Th ese resources are valuable to assist in the design of a security program, as they deﬁ ne 
the necessary controls to provide secure information systems. Th e following frameworks have 
each gained a degree of acceptance within the auditing or information security community and 
add value to the information security investment delivery. Although several of the frameworks/
best practices were not speciﬁ cally designed originally to support information security, many of 
the processes within these practices support diﬀ erent aspects of conﬁ dentiality, integrity, and 
availability.
Committee of Sponsoring Organizations of the Treadway Commission
Th e Committee of Sponsoring Organizations (COSO) of the Treadway Commission was formed 
in 1985 to sponsor the National Commission on Fraudulent Financial Reporting, which stud-
ied factors that lead to fraudulent ﬁ nancial reporting and produced recommendations for public 
companies, their auditors, the Securities Exchange Commission, and other regulators. COSO 
identiﬁ es ﬁ ve areas of internal control necessary to meet the ﬁ nancial reporting and disclosure 
objectives. Th ese areas are (1) control environment, (2) risk assessment, (3) control activities, 
(4) information and communication, and (5) monitoring. Th e COSO internal control model has 
been adopted as a framework by some organizations working toward Sarbanes–Oxley Section 404 
compliance.
Information Technology Infrastructure Library
Th e IT Infrastructure Library (ITIL) is a set of 44 books published by the British Government’s 
Stationary Oﬃ  ce between 1989 and 1992 to improve IT service management. Th e framework 

382  Information Security Management Handbook
contains a set of best practices for IT core operational processes such as change, release, and con-
ﬁ guration management; incident and problem management; capacity and availability manage-
ment; and IT ﬁ nancial management. ITIL’s primary contribution is showing how the controls can 
be implemented for the service management IT processes. Th ese practices are useful as a start-
ing point for tailoring to the speciﬁ c needs of the organization, and the success of the practices 
depends upon the degree to which they are kept up to date and implemented on a daily basis. 
Achievement of these standards is an ongoing process, whereby the implementations need to be 
planned, supported by management, prioritized, and implemented in a phased approach.
Control Objectives for Information and Related Technology
Control Objectives for Information and Related Technology (COBIT) is published by the IT 
Governance Institute and contains a set of 34 high-level control objectives, one for each of the 
IT processes, such as deﬁ ne a strategic IT plan, deﬁ ne the information architecture, manage the 
conﬁ guration, manage facilities, and ensure systems security. Ensure systems security has been 
broken down further into control objectives such as manage security measures, identiﬁ cation, 
authentication and access, user account management, data classiﬁ cation, and ﬁ rewall architec-
tures. Th e COBIT framework examines the eﬀ ectiveness, eﬃ  ciency, conﬁ dentiality, integrity, 
availability, compliance, and reliability aspects of the high-level control objectives. Th e model 
deﬁ nes four domains for governance, namely planning and organization, acquisition and imple-
mentation, delivery and support, and monitoring. Processes and IT activities and tasks are then 
deﬁ ned within these domains. Th e framework provides an overall structure for IT control and 
includes control objectives, which can be utilized to determine eﬀ ective security control objectives 
that are driven from the business needs.
International Organization for Standardization (ISO) 17799
Th e ISO 17799 standards can be used as a basis for developing security standards and secu-
rity management practices within an organization. Th e U.K. Department of Trade and Industry 
Code of Practice (CoP) for information security, which was developed from support of industry 
in 1993, became British Standard (BS) 7799 in 1995. Th e BS 7799 standard was subsequently 
revised in 1999 to add certiﬁ cation and accreditation components, which became Part 2 of the 
BS 7799 standard. Part 1 of the BS 7799 standard became ISO 17799 and was published as ISO
17799:2000, the ﬁ rst international information security management standard by the ISO and 
International Electrotechnical Commission (IEC).
Th e ISO 17799 standard was modiﬁ ed in June 2005 as ISO/IEC 17799:2005 and contains 
134 detailed information security controls based upon the following 11 areas:
Information security policy
Organizing information security
Asset management
Human resources security
Physical and environmental security
Communications and operations management







Compliance Assurance: Taming the Beast  383
Access control
Information systems acquisition, development, and maintenance
Information security incident management
Business continuity management
Compliance
Th e ISO standards are grouped together by topic areas and the ISO/IEC 27000 series has been 
designated as the information security management series. For example, the 27002 CoP will 
replace the current ISO/IEC 17799:2005 Information Technology—Security Techniques—Code 
of Practice for Information Security Management document. Th is is consistent with how ISO has 
named other topic areas, such as the ISO 9000 series for quality management.
ISO/IEC 27001:2005 was released in October 2005 and speciﬁ es the requirements for 
establishing, implementing, operating, monitoring, reviewing, maintaining, and improving a 
documented information security management system taking into consideration the company’s 
business risks. Th is management standard was based on the BS 7799 Part 2 standard and pro-
vides information on building information security management systems and guidelines for 
auditing the system.
Federal Information System Controls Audit Manual
Although the Federal Information System Controls Audit Manual (FISCAM) was not designed 
speciﬁ cally as a security control framework or standard and was created to assist auditors of federal 
government systems to evaluate the general and application controls over ﬁ nancial systems, it can 
be a useful guide in developing a security program. From a compliance perspective, government 
auditors needing to evaluate whether controls are in place for government agencies utilize the 
FISCAM controls. Th e General Accounting Oﬃ  ce reports on the security of government agencies 
utilizing FISCAM as the basis.
National Institute of Standards and Technology 800-53 Controls
Th e National Institute of Standards and Technology (NIST) was granted $20 million to cre-
ate security-related documents to support FISMA. Although these documents were created to 
support the federal agencies, the documents are very well written and can be utilized by private 
industry free of charge with no copyright restrictions. Many man-hours of government resources 
and public comments have gone into the construction of the control framework and supporting 
documents.
Special Publication 800-53, Recommended Security Controls for Federal Information Systems, is 
an excellent document, which describes 17 control families, such as access control, awareness and 
training, audit and accountability, risk assessment, personnel security, and contingency planning. 
Th e families are broken down into speciﬁ c controls, along with supplemental guidance, which 
typically refers to other more detailed NIST documents, and control enhancements that desig-
nate increasing levels of control required depending upon the security level of the system (low, 
medium, and high). Th e set of controls represents the minimum assurance requirements to be 
compliant with the control.






384  Information Security Management Handbook
Technical Control Standards
Th ere are many sources of speciﬁ c technical control standards, including vendor documentation, 
the SANS Institute’s Top 20 vulnerability list, NIST special publications, Defense Information 
Systems Agency (DISA) Security Technical Implementation Guides (STIGs), National Security 
Agency Security Conﬁ guration Guides, and others. Th ese standards are increasingly being uti-
lized by auditors, as well as being integrated into or used as the basis for vendor security products 
to demonstrate compliance with the higher level security control frameworks. NIST was also 
funded by the Department of Homeland Security to create a “National Vulnerability Database,” 
which combines the vulnerabilities from multiple sources in an eﬀ ort to automate compliance 
assurance of the technical controls. Vendor products are starting to incorporate the database into 
their product sets. If the eﬀ ort is successful, this could provide a standardized mechanism for 
reporting assurance of compliance with the FISMA requirements, which could be leveraged by 
private industry as a method of demonstrating compliance to a standard.
Penalties for Noncompliance
Th e laws have done an excellent job at creating visibility of the need for stronger information security 
controls. However, compliance with many of these regulations is still lagging. According to a 2006 
Global Information Security survey, 35 percent of U.S. respondents indicated they were not com-
pliant with Sarbanes–Oxley legislation, and 40 percent were not compliant with HIPAA security 
regulations, although they were aware the laws pertained to them and they should be compliant.
Th ere appears to be a lack of enforcement and penalties with some of the regulations. For 
example, the HIPAA security rule enforcement is “complaint driven,” whereby claims that dam-
age has occurred due to a perceived lack of security are reported and addressed. Th e concept of 
proactive HIPAA enforcement monitoring does not exist, lessening the attention some organiza-
tions place on the HIPAA rule. Th is may help explain why 40 percent of respondents still report 
they are not compliant, several years after the regulation came into eﬀ ect.
Th ere is also the viewpoint that compliance with government regulations is very, very expen-
sive and organizations may make a risk-based decision not to implement the controls. In a lawsuit-
driven society, this could be a recipe for disaster, not to mention the risks that would be taken 
with the public perception of the brand by the consumer. In the early 1970s, Ford became aware 
that if the Ford Pinto automobile was hit from behind, the car would explode and cause death or 
injury. Ford performed a cost–beneﬁ t analysis and determined that approximately 2100 burned 
vehicles, 180 serious burn injuries, and 180 deaths would most likely occur. Considering jury 
awards of $200,000 per death and $67,000 per injury and the cost of replacing the cars, they ﬁ g-
ured the “beneﬁ t” was $49.5 million versus a cost of $137 million ($11 per car) to ﬁ x the problem. 
Ford seriously erred in their judgment, as they put a price on human life and inﬂ icting pain on 
individuals versus “doing the right thing.” As a result, juries awarded millions in compensatory 
damages through lawsuits.
Although security issues may or may not impact life and death, depending upon the industry 
and the environment, organizations need to consider whether it is worth the risk not to comply with 
the standards that are practiced by other organizations within the industry. Subsequent juries hear-
ing these cases in court, whether criminal convictions, civil monetary penalties, or civil suits are at 
stake, may view the organization as not performing the standard of due care necessary to operate its 
business. Just one of these lawsuits in which someone is victimized through identity theft, a violent 

Compliance Assurance: Taming the Beast  385
attack due to lack of physical security controls, or the disclosure of personal information or a con-
viction due to lack of compliance could pay for the implementation of many security controls.
Enter Best Practices
Today’s risk and real cost from a lack of compliance assurance appears to be related more to bad 
publicity from the lack of security. Th is may be a reﬂ ection of the fact that security has only begun 
to receive increased attention, in large part due to the recent regulations, over the past several years. 
However, as leading organizations and government agencies place increased focus on their informa-
tion security programs, the bar becomes higher for their peer companies. Control frameworks and 
detailed technical standards are being increasingly applied within organizations. Th e vendor tool 
sets to assess compliance to support this activity are becoming richer. Besides, who wants to be the 
lone sheep, standing in the wilderness trying to defend its own wooly hide, when the herd is some-
where else working together on protecting themselves from the big bad wolf? Th e herd sets the stan-
dard and it is important to pay attention to where the herd is going. Th e notion of “best practices” 
today is an elusive one; the best approach is to grab onto a framework that is suitable for the business 
vertical and the culture and work diligently toward implementation of the strategy.
The 11-Factor Security Compliance Assurance Manifesto
Th e regulations, control frameworks, standards, technical implementation guides, and penalties 
for noncompliance provide insight into “what” needs to be achieved to provide the organizational 
compliance assurance to the various security-related regulations. Now, this begs the next ques-
tion, what actions need to be taken to achieve and maintain compliance with the regulations? 
To answer that question, the 11-Factor Security Compliance Assurance Manifesto, as shown in 
Exhibit 28.2, sets out the principles by which compliance assurance may be achieved.
 
1. Designate an individual responsible for compliance assurance oversight. Whereas many of 
the policy-type regulations may not appear to change on a frequent basis, the supporting 
documents, technical speciﬁ cations, and current areas of concern do change over time. 
New laws are also created, such as the incident breach reporting laws mentioned, where 
Exhibit 28.2 The 11-factor security compliance assurance manifesto.
1.  Designate an individual responsible for compliance assurance oversight 
2.  Establish a security management governing body 
3.  Select control frameworks and standards 
4.  Research and apply technical controls 
5.  Conduct awareness and training 
6.  Verify compliance 
7.  Implement formal remediation process 
8.  Dedicate staff, automate compliance tasks 
9.  Report on compliance metrics 
10.  Enforce penalties for noncompliance to policy 
11.  Collaborate and network externally 

386  Information Security Management Handbook
state-by-state adoption of some form of the law is enacted. Similarly, when the HIPAA Pri-
vacy Rule was being made eﬀ ective, each state had groups that were focused on creating a 
preemption analysis. Staying on top of these changes and ensuring that someone is directing 
the security compliance eﬀ orts is essential. In medium-sized organizations, this is likely to 
be the manager or director of security, whereas in larger organizations the chief information 
security oﬃ  cer, chief security oﬃ  cer, or security oﬃ  cer is likely to be responsible for ensuring 
that the security compliance assurance activities are performed. Th e chief information oﬃ  -
cer’s organization and the other business units carry out the mitigation work as appropriate.
 
2. Establish a security management governing body. To achieve support for the implementa-
tion of security policies throughout the organization and to ensure that the security poli-
cies do not disrupt the business, it is advisable to establish an information security council. 
Councils made up of representatives from IT, business units, human resources, legal depart-
ments, physical security, internal audit, ethics and compliance, and information security can 
be eﬀ ective in achieving compliance with the regulations. Th eir oversight and interaction 
provide feedback as to whether the security activities planned are feasible and whether there 
is a high probability of compliance success.
 
3. Select control framework and standards. Th e frameworks mentioned, such as COSO, ITIL, 
ISO 17799, COBIT, NIST, and FISCAM, oﬀ er an excellent place to map the security con-
trols that are in place to the framework, uncover the gaps in compliance, and create action 
plans to increase the security assurance with these objectives. Multiple control frameworks 
can be selected for diﬀ erent levels of detail. For example, COBIT may be selected to provide 
a governing framework, whereas ISO 17799 controls may be mapped to the framework 
(already available from the IT governance institute) and then linked to the NIST control 
objective families and supported by the DISA STIGs. Th e mapping provides a mechanism 
to review how a set of technical controls supports the higher level statements in the other 
frameworks. Th e same controls serve multiple purposes. Comprehensive frameworks are 
created through this process, enabling the other compliance assurance activities.
 
4. Research and apply technical controls. Th ere are many approaches at the technical level for 
being compliant with the control objectives. Analysis must be performed to determine the 
best control based upon the risk proﬁ le of the organization. For example, achieving compli-
ance with a requirement to provide adequate oﬀ -site backups of information in the event of 
a disaster could be achieved in a small regional oﬃ  ce by placing a daily tape in a ﬁ reproof 
safe and rotating the weekly tape oﬀ -site. Alternatively, a small oﬃ  ce may decide to store the 
backup tapes remotely with a tape storage facility, transmit the backup information securely 
over the Internet for backups, or assign an individual to take home the backup tape nightly. 
Each of the scenarios has their own costs and risks inherent in the control selection.
 
5. Conduct awareness and training. Th e documented security policies and procedures are 
 necessary; however, if individuals do not truly understand their responsibilities to comply 
with the security controls, the likelihood that the appropriate processes will be followed is 
greatly diminished.
 
6. Verify compliance. Vulnerability assessments, penetration testing, and internal audit reviews 
of the security controls ensure that the policies and procedures that were created are being 
followed. Implemented security on the computing platform can be tested and compared 
with the documented baselines, conﬁ gurations, and change control records to provide assur-
ance that the security controls are being maintained as per the requirements implemented 
through the control frameworks.

Compliance Assurance: Taming the Beast  387
 
7. Implement a formal remediation process. When weaknesses in the security controls are dis-
covered, through internal audits, external audits, vulnerability assessments, risk assessments, 
or other internal reviews, the issue must be logged and tracked to completion. Accountabil-
ity should be placed at a middle management or senior management level to ensure that the 
appropriate attention and priority are placed on remedying the issue. Completion dates must 
be assigned (preferably no later than 90 days after creation of the action plan). Documenta-
tion of the remediation (evidence) must be provided when the issue has been resolved. Th e 
existence of a formal tracking of the security issues provides the assurance that security is an 
ongoing, management-supported process.
 
8. Dedicate staﬀ , automate compliance tasks. Compliance initiatives are very time-consuming 
and drain the organization of resources to collect evidence, provide explanations, partici-
pate in interviews, and locate the policies and procedures that support the regulations. 
Without an organized automated process, this activity becomes even more challenging and 
time is wasted on ineﬃ  ciencies. Th e same information may be requested multiple times 
to answer similar questions, where one report may have provided a reasonable answer. 
Initially, more staﬀ  should be allocated to the compliance eﬀ orts to provide a focus to the 
activity. When the compliance tasks are added to the regular jobs of  predominant IT 
staﬀ , they may be given lower priority and resources. As automation increases, the staﬀ  
required to support the compliance eﬀ orts should either remain constant or decrease. 
A constant staﬀ  may be needed to ensure that the new regulations and changes are ade-
quately addressed.
 
9. Report on compliance metrics. Dashboards of red, yellow, and green or heat maps are useful 
tools to demonstrate where security is weak within the organization and where more focus 
should be placed. Th ese metrics should be reported in a manner that is meaningful to the 
business, such as unavailability issues, which could impact major, mission critical applica-
tions, or conﬁ dentiality concerns that may aﬀ ect the consumer trust in the brand.
 10. Enforce penalties for noncompliance to policy. Does one grin and bear it when the secu-
rity control objectives are not followed or grit one’s teeth? Th is is one area that needs … 
teeth! Th ere must be sanctions in place for those that do not follow the security poli-
cies. Associates must also be trained that compliance with the security controls is part of 
their job responsibilities. Th e individual responsible for compliance assurance must ensure 
that the guidelines are established for sanctions and that the appropriate parties follow 
through with the sanction (who may be the manager and legal and human resources 
representatives).
 11. Collaborate and network externally. Many organizations must comply with the same regula-
tions, why not leverage that experience? Working with peers, within the industry vertical 
for dealing with industry-speciﬁ c regulations, and across industries for understanding vari-
ous methods to implement the control frameworks, standards, and technical controls can 
be invaluable. For example, nonproﬁ t organizations such as the HIPAA Collaborative of 
Wisconsin were formed to bring together healthcare providers, payers, and clearinghouses 
to discuss approaches to implementing HIPAA. Th e presentations, network contacts, and 
information sharing that happen are phenomenal. Attending conferences and industry asso-
ciations such as the Information Systems Security Association and Information Systems 
Audit and Control Association helps to gain a common understanding of the regulation and 
implementation approaches. Th is also provides input as to what the “herd” is doing to be 
compliant with the regulation.

388  Information Security Management Handbook
Final Thoughts
Compliance assurance seeks to demonstrate that the organization has implemented adequate secu-
rity controls to satisfy the many government regulations. Control frameworks, standards, and 
technical implementation guides are selected to provide more detailed frameworks to assess and 
implement the controls necessary. Ongoing monitoring of the frameworks increases the probabil-
ity that security controls are in operation and that unnecessary risks to availability, conﬁ dentiality, 
and integrity are not being taken. Compliance assurance can have a positive impact on business 
by being more proactive versus reactive, providing better, more thought-out strategies to mitigate 
threats and risks, increase visibility of senior management, and align the security program better 
with the rest of the organization. Compliance assurance should be regarded as more than a paper-
work exercise and viewed as a method by which the overall security of the environment can be 
improved. Owing to the criticality of the need to establish due diligence required for the function, 
it should be recognized as an ongoing, funded, integral business activity and provided the neces-
sary ongoing business support, time allocation, and resources.
Further Readings
 
1. Federal Information Security Management Act of 2002, November 27, 2002, http://csrc.nist.gov/
policies/FISMA-ﬁ nal.pdf.
 
2. GAO/AIMB-12.19.6, Federal Information Systems Controls Audit Manual, January 1999, http://
gao.gov/special.pubs/ai12.19.6.pdf.
 
3. Cobit 4.0, IT Governance Institute, http://www.itgi.org.
 
4. Th e CSO’s Security Compliance Agenda: Benchmark Research Report, CSI Computer Security Jour-
nal, XXII, November, 2006.
 
5. Wikipedia, http://www.wikipedia.com.
 
6. Answers.com, http://www.answers.com.
 
7. National Institute of Standards and Technology, Special Publications, http://csrc.nist.gov/
publications/nistpubs.
 
8. Defense Information Systems Agency Security Technical Implementation Guides, http://iase.disa.
mil/stigs/stig.
 
9. National Security Agency, Security Conﬁ guration Guides, http://www.nsa.gov/snac.
 10. ISO/IEC 17799:2005 Information Technology Security Techniques—Code of Practice for Infor-
mation Security Management, International Standards Organization, http://www.iso.org/iso/en/
prods-services/popstds/informationsecurity.html.
 11. HIPAA Collaborative of Wisconsin, www.hipaacow.org.
 12. Th e Global State of Information Security 2006, PricewaterhouseCooper, CIO, CSO Magazine, www.
pwc.com.
 13. SANS Institute Top 20, www.sans.org/top20.
 14. NIST National Vulnerability Database, http://nvd.nist.gov.
 15. Seventh Report Card on Computer Security, http://republicans.oversight.house.gov/media/pdfs/
FY06FISMA.PDF.

Incident Handling


391
Chapter 29
Enterprise Incident Response 
and Digital Evidence 
Management and Handling
Marcus K. Rogers
Contents
Introduction ............................................................................................................................ 392
Misperceptions .........................................................................................................................393
Incident Response Process Model ............................................................................................393
Cyber-Forensics Process Model ................................................................................................395
Incident Response versus Cyber-Forensics ............................................................................... 396
Digital Evidence ...................................................................................................................... 397
Evidence Management and Handling ..................................................................................... 398
Reasonable Expectation of Privacy ................................................................................. 398
Volatility ........................................................................................................................ 398
Volume and Commingling ............................................................................................ 399
Integrity ......................................................................................................................... 399
Chain of Custody .......................................................................................................... 399
Digital Evidence Life Cycle ............................................................................................ 399
Forensic Readiness .................................................................................................................. 400
Summary ................................................................................................................................ 402
References ............................................................................................................................... 403

392  Information Security Management Handbook
Introduction
Terms like “incident response” (IR) and “computer forensics” have become all too familiar in our 
modern technology-dependent society. Few if any organizations can claim immunity from the 
possible negative side eﬀ ects of this dependence, namely misuse and abuse and other criminal 
behavior. Organizations today are paying more attention to protecting their information tech-
nology (IT) assets and the sensitive information that may be contained therein. Th e attention is 
directly translated into increased budgets, reallocation of resources (both personnel and equip-
ment), and in some cases increased complexity of the enterprise-computing environment.
Regardless of the industry, there seems to be increasing statutory and regulatory compliance 
issues related to ﬁ nancial reporting controls (e.g., Sarbanes–Oxley, United States; CEO/CFO 
Certiﬁ cation, Canada), private information (e.g., Health Insurance Portability and Accountability 
Act), and ﬁ nancial information (e.g., Gramm–Leach–Bliley Act), to name just a few. Th e common 
element with these requirements is the ability to detect when a problem has occurred and the abil-
ity to respond in an eﬀ ective and eﬃ  cient manner. Th e consequence of not having these abilities is 
not only the danger of being in noncompliance and suﬀ ering ﬁ nancial or criminal consequences, 
but also includes the very real danger of never recovering and going out of business in less than a 
noble fashion. Th e risks faced today, other than regulatory compliance, stem from the increased 
frequency and prevalence of external and internal criminal activities. For various reasons that are 
beyond the scope of this chapter, deviant computer behavior is on the rise and shows no sign of 
abating. Reported losses due to insider misuse and abuse have been estimated annually to be mil-
lions of dollar. Errors and omissions also account for a signiﬁ cant ﬁ nancial drain on organizations; 
these events can prove more costly than intentional abuse and misuse and often much harder to 
deal with, as the root cause can be diﬃ  cult to ascertain. Wrongly conﬁ gured systems can also 
endanger our personal safety (e.g., air traﬃ  c control systems and power grids) or create a very large 
national security risk.
Th ere are other business considerations apart from the traditional information assurance and 
security risks. As the corporate world becomes increasingly more litigious, there is a correspond-
ing increase in responding to requests for discovery for electronically stored information (ESI). An 
organization may have its house in order regarding compliance, information assurance, errors, and 
omissions and still be required to investigate, collect evidence, and provide reports in response to 
a request for discovery by another party who has or is anticipating ﬁ ling a legal action against the 
organization (Rowlingson, 2004). Th e ﬂ ip side is applicable as well. An organization may be in a 
position to initiate an action against another party and thereby be making the request for ESI in 
support of that action.
Th ose of us who have been in the information assurance and security ﬁ eld for a while recog-
nize that incident management and response is the primary control strategy that organizations 
implement to meet the various risks that they face on a daily basis. However, what might not be 
readily apparent is the fact that the IR has evolved into a fairly mature systemic (enterprisewide) 
process. Owing to increased demand, organizations are becoming more comfortable in dealing 
with IT-related security incidents and the need to investigate negative events. Th e corollary to this 
increased need to respond to incidents in a formal manner is the requirement to collect digital evi-
dence during the course of these incidents and investigations. Unfortunately the management and 
handling of digital evidence are not a process that most organizations are knowledgeable about or 
necessarily comfortable in dealing with. Digital evidence and how to deal with it appropriately is 
an extremely immature concept or process in most organizations.

Incident Response, and Evidence Management and Handling  393
Th e purpose of this chapter is to assist with the understanding and comfort in dealing with 
digital evidence in the context of dealing with an incident. We begin by discussing some of the 
misperceptions surrounding the collection of digital evidence during an IR situation and then 
continue on by exploring the IR model. We will then look at the digital evidence management and 
handling methodology and focus on the similarities and diﬀ erences between the two models. Th e 
chapter concludes with an examination of how to combine the two process models to accentuate 
the strengths and reduce the inherent weaknesses and shortcomings of both.
Misperceptions
Most discussions on digital evidence and IR ultimately touch on the perceived issues in combining 
these two models. Many business managers are very concerned with the possible negative impact 
that collecting evidence will have on the pressing need for business resumption (Rowlingson, 
2004). Recall that one of the primary goals of IR is the timely resumption of business to mini-
mize the economic impact of the event. In some industries, every minute that an organization is 
unable to use its information system translates into hundreds if not thousands of dollars of lost 
revenue (e.g., stock exchanges and e-commerce) or penalties (e.g., application service providers and 
telecommunications). Obviously, the loss of consumer or shareholder conﬁ dence has an economic 
impact as well.
Th e proper handling and management of digital evidence are commonly thought of as a pro-
cess that interferes with or at the very least slows down the recovery and resumption of business 
operations. Th is is not necessarily the case. Even if it were, the failure to act in a reasonable man-
ner that demonstrates due diligence may result in a larger impact than the cost of losing an hour 
or two. Businesses operating in an industry that falls under the various regulatory compliance 
requirements may face criminal or civil sanctions for failing to conduct a proper investigation that 
includes the proper handling of digital evidence.
A properly implemented and planned-out approach to combining digital evidence and IR 
should function in a manner that allows the two activities to occur in parallel, thus resulting in 
a minimal slowdown in time needed to recover (see Forensic Readiness). It also ensures that the 
resumption of business (recovery phase) is handled in a manner that does not place the organiza-
tion in a more vulnerable position by rushing the recovery and placing the systems back online 
without being properly secured. Looking at the digital evidence allows the investigators and IR 
personnel to understand the full impact of the event and conduct a proper root-cause analysis. 
Th ere are several documented cases in which businesses rushed the process and came back online 
only to be attacked again in the same or a similar manner. Th ese businesses learned the hard way 
that patience really is a virtue.
Incident Response Process Model
Th e term “IR” can be deﬁ ned in many ways. Several authors have focused on the incident han-
dling aspect of the process, whereas others have dealt with the management and response capa-
bility (Rogers, 2007). Regardless of how we formally deﬁ ne the process, the ultimate goal is to 
respond in a manner that reduces the impact of the incident and allows the organization to recover 

394  Information Security Management Handbook
appropriately so as not to be vulnerable to the same incident in the future. Speciﬁ c goals of IR 
can be summed up as follows:
Provide an eﬀ ective and eﬃ  cient means of dealing with the situation in a manner that 
reduces the potential impact to the organization.
Provide management with suﬃ  cient information to decide on an appropriate course of 
action.
Maintain or restore business continuity.
Defend against future attacks.
Deter attacks through investigation and prosecution.
Th e process assumes that prior planning has occurred, in the form of policies and procedures 
speciﬁ c to IR management and handling, and that proactive (e.g., intrusion detection systems and 
intrusion prevention systems) as well as reactive controls (e.g., logs and monitoring) are in place.
Th e actual model used to conduct or implement an enterprisewide IR capability may vary 
from organization to organization in regard to minute details. However, at the conceptual level, 
the framework is usually based on a multiphase formal/methodical approach (Rogers, 2007; 
Rowlingson, 2004) (see Figure 29.1).
Limitations on the size of this chapter prohibit a detailed discussion of each phase, but readers 
interested in more details can refer to Schultz and Shumway (2002) or Rogers (2007).
It should be recognized that IR is a vital component of any organization’s IT security pos-
ture. With the move toward a systemic or enterprise approach to information assurance and 
security, IR has now become part of the information security life cycle (Schultz and Shumway, 
2002) (see Figure 29.2). Th e information security life cycle begins with the detection of an 
event (incident) and encompasses the response to the incident and any countermeasures that are 
identiﬁ ed and implemented. Th e life cycle is dynamic and is a circular process that feeds back 
into itself.





Preparation
Detection
Containment
Analysis
Eradication
Recovery
Follow-up
Feedback
Digital forensics/Evidence management
Digital forensics/Evidence management
Digital forensics/Evidence management
Figure 29.1 Incident response process model.

Incident Response, and Evidence Management and Handling  395
Figure 29.2 Information security life cycle.
Countermeasures
Detection
Incident response
Th is approach also places IR into the system development life cycle and thus IR considerations 
should be part of every project undertaken. Th e inclusion of IR in the system development life 
cycle allows IR to become a systemwide or enterprise-level event. Although there are numerous 
usages for the term “enterprise,” for this discussion enterprise will refer to large-scale implemen-
tation across all business units and inclusive of all IT assets. It is important to have as broad a 
coverage as possible given that systemwide (enterprise) vulnerabilities and threats are a very real 
occurrence, thus risk must be dealt with at the enterprise level as opposed to the more “siloed” 
approach of dealing with business units as unrelated entities. Th e days of IT risk management 
being purely a technology or an IT business unit problem are long gone.
Cyber-Forensics Process Model
Let us turn our attention to cyber-forensics and digital evidence and examine a common approach 
or model. Before we jump into the model it is important that we properly deﬁ ne what is meant by 
“cyber-forensics” or “computer forensics.” Cyber-forensics can be deﬁ ned as follows (from Mandia 
and Prosise, 2001; Rogers, 2007):
Th e scientiﬁ c examination and analysis of digital data in such a way that the informa-
tion can be used as evidence in a court of law.
At ﬁ rst glance this deﬁ nition appears somewhat simplistic, but upon deeper examination it 
becomes clear that by focusing on the modality of the evidence (digital), the deﬁ nition overcomes 
the tendency to have multiple diﬀ erent terms depending upon the location of the evidence. In the 
past there have been many a heated debate regarding network forensics versus computer forensics, 
or small-scale versus large-scale device forensics. Th e common element in all these is in fact the 
nature of the evidence—it is digital.*
* One could argue for the inclusion of an electronic evidence as well as a digital, but most electronic or analog 
materials are converted to digital for the analysis phase, so the argument is considered moot.

396  Information Security Management Handbook
Although it is apparent that currently there are only emerging standards and protocols related 
to cyber-forensics, the underlying framework is rather generic and is derived from the fundamen-
tals of forensic science or criminalistics. Th e framework focuses on the investigative nature of the 
activity and can be broken down into the following phases or steps (Rogers, 2007; Rowlingson, 
2004; Taylor et al., 2006):
Identiﬁ cation
Collection
Preservation
Examination
Analysis
Documentation and report
Like the IR process model the cyber-forensics process model is an iterative process that follows a 
logical approach to dealing with both the crime scene and the durative evidence that is digital in 
nature.
Incident Response versus Cyber-Forensics
Th ere have been numerous discussions and articles published on the topic of IR and cyber-
 forensics. Some authors take the view that these two terms are analogous, but this is incorrect. 
Granted, both IR and cyber-forensics are investigative in nature and both tend to deal with 
incidents in a reactive manner. However, the major diﬀ erence lies in the standard of proof that is 
required. Cyber-forensics is a forensic science and by deﬁ nition the admissibility of evidence is a 
major consideration with every task or phase. However, IR is concerned with the resumption of 
business and the return to a steady state—which, it is hoped, will be less vulnerable than before. 
IR does not by deﬁ nition or convention deal with admissibility of evidence concerns, nor does 
it treat each event as having the potential to end in litigation (Kent et al., 2006; Mandia and 
Prosise, 2001).
Although the objectives and standards of proof for IR and cyber-forensics are somewhat 
 diﬀ erent, they are not mutually exclusive or contradictory activities; they are very complementary. 
In fact, exemplary IR programs integrate cyber-forensics into their response capacity. When an 
event triggers the IR process, care is taken to ensure that the admissibility of evidence, chain of 
custody of evidence, and ability to reproduce the “scene” are taken into consideration. In most 
cases, the IR and the cyber-forensics teams work in parallel and each team coordinates its actions 
with those of the other to ensure that nothing is overlooked. Th is symbiotic relationship has been 
recognized by the courts in many countries (e.g., United States, Canada), with the passing of 
guidelines for determining the cost to the victim of the attack in criminal and civil cases. Here 
the value of the information and the cost to the organization to recover from and investigate the 
attack (e.g., prorated system administrator and IR team salary costs) are combined to arrive at an 
aggregate total loss for the victim (exceeding, it is hoped, the magic $5000 mark that has been 
established for some jurisdictions).
As indicated in Figure 29.1, the introduction of cyber-forensics and the collection and preser-
vation of digital evidence logically occur during diﬀ erent phases of the IR process model. What is 
very important to understand is that with digital evidence and cyber-forensics, once the evidence 







Incident Response, and Evidence Management and Handling  397
or scene has been contaminated, it cannot be decontaminated; there is no “do over” or “undo” 
button. Digital evidence and digital scenes are extremely fragile and volatile, and in some cases the 
evidence has a very short life span.
Digital Evidence
As was stated previously, when dealing with forensic investigations the primary concern is with 
evidence. Although the focus of this chapter is on digital evidence, we cannot ignore physical 
evidence or physical crime scenes. In most instances, the digital evidence exists within a physi-
cal crime scene. Although we might be looking for spreadsheets, log ﬁ les, pictures, etc. that are 
stored on a device, these devices exist in a physical space. Th e location of the system in a room, 
how the system or device was physically connected to the network, and what physical access 
points there were to the room may all be crucial to determining the context of what happened 
or who had or did not have exclusive opportunity. Although a majority of the incidents inves-
tigated are assumed to be the result of external attackers, the reality is that internal attacks are 
still the most predominant and costly events. With internal attacks, proving unauthorized access 
or exceeding account privileges may hinge on the physical evidence (e.g., closed-circuit TV and 
building access logs).
To truly integrate IR and cyber-forensics, it is necessary to reduce the process to its most basic 
element(s). In our case it is really all about digital evidence management and handling. If we 
assume that the IR process is fairly well understood and make an even larger assumption that the 
IR process is reasonably implemented and supported across the organization (i.e., enterprisewide), 
then the focus needs to be on the digital evidence.
Before moving on to a more detailed discussion of digital evidence management and handling, 
let us quickly discuss what digital evidence really is and place it within the context of the business 
environment. So what is really meant by the term digital evidence? One would think that deﬁ ning 
digital evidence would be fairly straightforward, yet here again there has been some debate. Rather 
than getting caught up in semantics, let us turn to the physical domain and criminalistics, which 
has proﬁ ted from its history of case law. Saferstein (2004) deﬁ nes physical evidence as follows:
Physical objects that establish that a crime has been committed, can provide a link 
between a crime and its victim, or can provide a link between a crime and the perpe-
trator (p. 34).
Using this well-established and accepted deﬁ nition as a foundation, Carrier and Spaﬀ ord (2003) 
deﬁ ne digital evidence as follows:
Digital data that establish that a crime has been committed, can provide a link between 
a crime and its victim, or can provide a link between a crime and the perpetrator (p. 6).
Within a business environment the digital evidence can encompass the actual data itself, con-
traband images, rootkits, log ﬁ les, e-mails, etc. It is obvious that to list all possible examples or 
sources of digital evidence would be extremely time consuming. However, one of the most com-
mon sources or types of digital evidence is based on the concept of records (Ghosh, 2004). As a 
quick aside, businesses now produce more electronic records than paper records. Records in our 

398  Information Security Management Handbook
context can be subclassiﬁ ed into (a) computer stored, (b) computer generated, and (c) computer 
generated and stored (Ghosh, 2004).
 
a. Computer stored pertains to such items as documents, e-mails, chat logs, and other “records” 
that capture or record what has been created by a person. Here the technology is not an 
active entity in the creation of the content but is merely a passive receptacle.
 
b. Computer generated refers to records created without human intervention (nonhuman 
generated). Th ese records rely on an automated process (this category is important when 
addressing the business exception to the hearsay problem). Examples here include output 
from computer programs, log ﬁ les, event logs, and transaction records.
 
c. Computer generated and stored covers records that combine automated process and program 
outputs with human-generated input. Spreadsheets that contain calculations and formulas 
(computer) and manually entered data (human) are a good example.
Evidence Management and Handling
Regardless of whether the evidence is record based or not, there are some special considerations 
that one must be aware of when dealing with digital-based evidence. One of the most important 
considerations is the legal authority to actually collect the evidence. A number of countries are strug-
gling with the balance between protecting the privacy of the individual, while at the same time 
allowing private organization and government entities to conduct investigations. Cyberspace has 
drastically changed the notion of what constitutes a reasonable expectation of privacy (REP); 
when does one’s private space overlap with the public domain?
Reasonable Expectation of Privacy
Th e concept of REP is fundamental to most countries when deﬁ ning what is an acceptable or 
unacceptable search and seizure of information/evidence. Businesses are not immune from these 
issues, as several jurisdictions have codiﬁ ed rules relating to the monitoring of employees and 
their activities, even when these individuals are using the technology belonging to the business. 
Investigators must be extremely careful to ensure that they both have a policy-based authority to 
take action and are legally allowed to. Corporate counsel should be consulted before taking any 
action. As a rule of thumb it is usually not a good idea to run afoul of the law when conducting an 
investigation! Even the most noble of intentions is not an excuse here and places the organization 
in the uncomfortable position of being open to criminal or civil redress.
Volatility
Digital evidence is very fragile (volatile) and in some cases has a very short life span (e.g., data in cache 
memory and random-access memory [RAM]). Digital evidence can easily be modiﬁ ed or overwritten 
either as part of the normal system operation or during the identiﬁ cation and collection phase. Care 
must be taken to ensure that the evidence is handled in such a manner that any modiﬁ cations are 
avoided or at least minimized. In the event that modiﬁ cations occur (e.g., running programs for live 
memory analysis), detailed documentation must be made to explain the changes in the state of the 
scene or the evidence from its original state (state at which it was found by the investigator) and what 
impact this might have on evidence (Casey, 2006; Mandia and Prosise, 2001; Rogers, 2007).

Incident Response, and Evidence Management and Handling  399
Volume and Commingling
Given the sheer volume of data these days it should come as no surprise that often the data we are 
interested in (evidence) is commingled with other data that is of no evidentiary value or, in some 
cases, mixed in with information that is protected (e.g., lawyer–client and trade secret). Most 
desktop workstations these days have hard drives in excess of 300 GB and some are now being 
bundled with 1 terabyte (TB) of storage capacity. Business-class server farms routinely exceed 
1 TB of data spread across several drives that may or may not reside in the same geographical 
 loca tion (e.g., grid computing). It is vital that an investigator be sensitive to potential commin-
gling and be aware that it is functionally infeasible to expect to search every possible sector of 
storage for potential evidence. In response to these issues several jurisdictions have deﬁ ned speciﬁ c 
criteria for determining the scope of “discovery” and usually require a detailed investigative plan 
to ensure that the investigations are conducted in an eﬃ  cient and eﬀ ective manner. In an IR situ-
ation in which the authority to search is based on the ownership of the technology, commingling 
and volume of data are no less of a problem.
Integrity
Maintaining and demonstrating the integrity of the digital evidence is one of the integral in the 
consideration of admissibility of the evidence. Although the ultimate decision of what is admissible 
and what will be suppressed is up to a judge, precedent has provided guidance on the criteria that 
provide for the best chance of the evidence being admissible. Th e main method for demonstrating 
or proving that the evidence is an exact copy of the original, in the case of creating forensic cop-
ies, or that the data/evidence has not been altered from the original time of collection is through 
hash functions. Th ese hash functions create a digital ﬁ ngerprint of the data (128 bits in the case of 
MD5). Th e hash totals are extremely sensitive to bitwise changes. Most courts have accepted that 
if the hash totals match, the data has suﬃ  cient integrity.
Chain of Custody
Th e second most important consideration for evidence in general is the chain of custody. Simply 
put, the chain of custody deals with the who, what, when, where, and how of the collected evi-
dence over its entire life span, from identiﬁ cation and collection to ﬁ nal disposition. If any part of 
the chain is broken or is doubtful, the evidence in question may be suppressed. At the very least 
a break in the chain of custody creates doubt in the minds of a judge, jury, arbitrator, etc., which 
can have serious ramiﬁ cations if the evidence or its integrity is disputed.
Digital Evidence Life Cycle
Digital evidence management has a life cycle of its own. Th is life cycle starts with the initial 
design of systems to capture evidence and ends with determining the evidentiary “weight” of the 
data (Ghosh, 2004). In between we have the production of records, the collection of evidence, 
the  analysis and examination of the evidence, and the report or presentation (Ghosh, 2004). 
Th is model highlights a key component for integrating computer forensics with IR, “design 
evidence.” Design for evidence literally means that those individuals developing and design-
ing systems and applications must understand digital evidence, its business life cycle, and the 

400  Information Security Management Handbook
process model. Here again digital evidence management and handling, like IR, should be part 
of the system and software development life cycle. Systems across the enterprise must be forensi-
cally aware or, as Rowlingson (2004) termed it, have forensic readiness. History has shown us 
that trying to retroﬁ t something onto an already in production system or process is costly and 
usually ineﬀ ective.
Forensic Readiness
As was mentioned earlier, the forensic process needs to be conducted in parallel with any IR 
actions. To facilitate this, the typical approach of being reactive needs to be modiﬁ ed. Organiza-
tions need to be proactive and develop and implement policies, guidelines, and procedures that 
clearly articulate how the two processes will interact and who will be responsible for overseeing 
the combined approach and clearly deﬁ ne the so-called rules of engagement (Kent et al., 2006; 
Rowlingson, 2004). Waiting until one is engaged in the chaos of dealing with an incident is not a 
good time to start trying to institute this combined model or create policies, etc., literally on the 
ﬂ y; this ad hoc approach is doomed to failure for obvious reasons (numerous organizations bear 
witness to this fact).
Although it is beyond the scope of this chapter to go into great detail as to how to prepare 
properly, it is necessary to at least touch on the higher-level concepts that must be considered. 
Apart from having policies and procedures in place as the National Institute of Standards and 
Technology (NIST) (Kent et al., 2006) recommends, it is actually necessary to have personnel 
trained in cyber-forensics. Remember, the skill sets for cyber-forensics are similar to, yet diﬀ erent 
from, IR skills. It is acceptable to have individuals cross-trained, but do not assume someone with 
IR training can perform an acceptable cyber-forensics investigation and vice versa. Th e cyber-
forensics training, education, and ongoing skill development will have costs associated with them. 
But, just as with the IR teams, these costs are marginal compared to the cost of properly dealing 
with an incident.
An excellent primer on considerations for implementing forensic readiness into the IR process 
is the NIST-SP800/86 Guideline (Kent et al., 2006). In a nutshell the guideline recommends that 
organizations:
Have a capability to perform cyber-forensics,
Determine a priori who is responsible for cyber-forensics,
Have incident handling teams with robust forensics capabilities,
Have many teams that can participate in forensics,
Have forensic considerations clearly addressed in policies, and
Create and maintain guidelines and procedures for performing forensic tasks.
Rowlingson (2004) also provides a framework for implementing a “forensic readiness program” 
that is more focused on the private sector and corporate entities. Th e ten tasks he lists are similar 
to the recommendations by NIST but predate the formal publication of the NIST document:
Deﬁ ne the business scenarios that require digital evidence.
Identify available sources and diﬀ erent types of potential evidence.
Determine the evidence collection requirement.
Establish a capability for securely gathering legally admissible evidence to meet the 
requirement.











Incident Response, and Evidence Management and Handling  401
Establish a policy for secure storage and handling of potential evidence.
Ensure monitoring is targeted to detect and deter major incidents.
Specify circumstances in which escalation to a full formal investigation (which may use the 
digital evidence) should be launched.
Train staﬀ  in incident awareness, so that all those involved understand their role in the digi-
tal evidence process and the legal sensitivities of evidence.
Document an evidence-based case describing the incident and its impact.
Ensure legal review to facilitate action in response to the incident.
Although policy and procedures are important to ensure that IR and the management and han-
dling of digital evidence interact properly, there are also some technical considerations to forensic 
readiness (Kent et al., 2006; Mandia and Prosise, 2001; Rogers, 2007; Rowlingson, 2004). Th ese 
considerations build on the technical capacity to collect meaningful and trustworthy digital evi-
dence. Log and event ﬁ les are probably the most common sources of information and evidence. 
But, if the system or network has been completely compromised, then how do we trust these 
sources of information? If proper care is not taken, then the data collected or the record is not 
trustworthy enough to be used as evidence, even if it can be trusted to help recover systems and 
resume business operations.
Given that there has not been a considerable amount of applied testing or implementation of 
forensic-ready technology at the enterprise network level, it is prudent to discuss this only at the 
research level. As NIST and Rowlingson (2004) have indicated, the actual design and develop-
ment of this technology stem from a thorough understanding of IR requirements and sound 
 digital evidence or forensic practices. Th e current research in the area of forensic readiness of 
enterprise systems shows promise in several general areas:
Kernel-level forensic capacity
Distributed authenticated logging
Digitally signed and encrypted logs
Automated live forensic imaging of all aﬀ ected systems
Hooking into the actual kernel level of an operating system to obtain valid and reliable informa-
tion on what is being executed and by which process is extremely important. Th ose working in 
antivirus research have recognized the need to operate at the kernel level as opposed to any of the 
higher layers of abstraction; the same holds for obtaining information to be used as evidence.
Logs are a vital and rich source of information and potential evidence as to what transpired and 
the approximate timeline of events. However, we need to be able to trust the logs from these sys-
tems. Th is can lead to a conundrum: how do we trust logs from systems that we assume have been 
compromised and thus are now untrustworthy? A possible solution is to distribute the appropriate 
security and event logs to other systems not part of the primary network. Th ese systems would 
require proper authentication not tied to any information that may be present on the potentially 
compromised systems. Although not foolproof, distributed authenticated logging would deﬁ nitely 
increase the cost of the attack to the attacker and allow for greater trust of these logs.
Tied to the notion of distributed and authenticated logs is the integrity of the logs themselves. 
Even if we can show that the logs are trustworthy we need to demonstrate not only that they are a 
true and accurate recording of the events at the time of recording, but also that they have not been 
altered at any time from their creation to their presentation or use as evidence in a legal proceed-
ing. A process that automatically signs the logs with a hash total that is stored in a trusted database 











402  Information Security Management Handbook
and then encrypts the logs that are then stored in an authenticated and distributed manner would 
be beneﬁ cial.*
Th e ability to collect and analyze live systems and running memory is becoming increasingly 
more important. Large enterprise systems cannot be taken oﬄ  ine or shut down during the investi-
gative process for business or technical reasons. Likewise, shutting down a system with 1–16 GB of 
RAM results in the loss of a great deal of potential evidence. However, how to collect the evidence 
with a live system in a forensically sound matter is diﬃ  cult. To perform the collection one must 
load code or execute an operation on the suspected system, thus changing the state of the system 
and potentially overwriting evidence that may have been in memory. Th is is not a comfortable 
situation considering that forensics is concerned about the admissibility of any derived evidence. 
Th e ability to analyze the content of memory, etc., once collected is beyond the scope of this dis-
cussion but suﬃ  ce to say it is rather diﬃ  cult. Th e reality is that live system and memory collection 
and analysis will soon surpass the current approach of dealing with a powered-oﬀ  (in a forensically 
sound manner, it is hoped) or “dead” analysis.
Summary
Th e business environment is a seemingly constantly changing landscape. Th e demands placed 
on information security professionals is also changing to meet the new demands of business and 
technology. Th e ability to conduct eﬀ ective and proper investigations is now a standard require-
ment for most organizations. Th is requirement has arisen due to various forces such as regulatory 
compliance, requests for discovery that include ESI, and the almost ubiquitous use of technology 
by businesses in general.
We are in a similar position today with cyber-forensics (digital evidence management and 
handling) that we were in about ﬁ ve years ago with IR. Organizations today are struggling with 
implementing digital forensic capabilities into their enterprise-level response processes and many 
are taking shortcuts and liberties with the management and handling of digital evidence. Th is is 
an extremely slippery slope that has some very serious and tangible consequences to businesses. 
Dealing with digital evidence occurs within the context of a forensic event and by its very nature 
carries the requirements and obligations related to the admissibility of evidence into a legal or 
quasi-legal arena. Criminal and civil liability considerations must be taken into account; this 
illustrates the fact that although cyber-forensics and IR are related processes they are not identical 
and must be treated as such.
Digital evidence has its unique characteristics and considerations that traditional physical evi-
dence does not necessarily have, yet at the same time digital evidence resides in physical space. It 
is, therefore, important to understand the life cycle of digital evidence, its uniqueness, and where 
digital evidence management and handling ﬁ t into the IR process. IR and digital evidence man-
agement and handling are not mutually exclusive processes. Both models have considerable over-
lap and in some cases are mutually dependent upon each other. Th e key to combining these two 
investigative models or tools successfully is prior planning, such as developing policies, guidelines, 
and procedures that address both. IR and cyber-forensics teams as well as managers need to be 
* One could argue that the database hash totals could be altered and thus they must be signed, etc., until we col-
lapse under the weight of the inﬁ nite loop of signing the signer. Fortunately, the courts have recognized that at 
some point it is necessary to trust a person unless evidence exists to the contrary. Th us, unless proved otherwise, 
the database administrator could testify that nothing was altered.

Incident Response, and Evidence Management and Handling  403
properly cross-trained for everyone involved to understand the dependencies that each process has 
and the eﬀ ect, if any, that certain actions may have on the other’s primary goal.
Management needs to abandon the outdated notion that dealing with digital evidence will 
slow down or impair the time of recovery. With increased public and government scrutiny, speedy 
business resumption must be tempered with the proper mix of patience and strategic thinking. 
Knee-jerk reactions to incidents are no longer appropriate and are actually more costly in the long 
run. It seems plausible that attacks against our enterprise IT infrastructures from both external 
and internal sources will continue to grow before any type of plateau occurs. Th us, we must use 
and adapt security controls and tools to aid us in our eﬀ ort to protect our systems and our infor-
mation. Th e combining of process models and tools such as IR and digital evidence management 
and handling is a prime example of the synergistic activities that must continue if we are to deal 
eﬀ ectively with the risk that we face today and will face tomorrow.
References
Carrier, B., and Spaﬀ ord, E. (2003). Getting physical with the digital investigation process. International 
Journal of Digital Evidence, 2(2).
Casey, E. (2006). Investigating sophisticated security breaches. Communications of the ACM, 49(2), 48–54.
Ghosh, A. (2004). Guidelines for the Management of IT Evidence. Paper presented at the APEC Telecom-
munications and Information Working Group: 29th Meeting. Retrieved November 1, 2006, from 
http://unpan1.un.org/intradoc/groups/public/documents/APCITY/UNPAN016411.pdf.
Kent, K., Chevalier, S., Grance, T., and Dang, H. (2006). NIST SP800-86: Guide to Integrating 
Forensic Techniques into Incident Response. Retrieved January 5, 2007, from http://csrc.nist.gov/ 
publications/nistpubs/800-86/SP800-86.pdf.
Mandia, K., and Prosise, C. (2001). Incident Response: Investigating Computer Crime. New York: 
McGraw-Hill.
Rogers, M. (2007). Law, regulations, investigations and compliance. In H. Tipton and K. Henry (Eds.), 
Oﬃ  cial (ISC)2 Guide to CISSP CBK (pp. 683–718). Boca Raton, FL: Auerbach.
Rowlingson, R. (2004). A ten step process for forensic readiness. International Journal of Digital Evidence, 2(3).
Saferstein, R. (2004). Criminalistics: An Introduction to Forensic Science. Upper Saddle River: Pearson 
Education.
Schultz, E., and Shumway, R. (2002). Incident Response: A Strategic Guide to Handling System and Network 
Security Breaches. Indianapolis, IN: New Riders.
Taylor, R., Caeti, T., Loper, D. K., Fritsch, E., and Leiderbach, J. (2006). Digital Crime and Digital Terrorism. 
Upper Saddle River, NJ: Pearson Prentice Hall.


405
Chapter 30
Security Information 
Management Myths and Facts
Sasan Hamidi
Contents
Introduction ............................................................................................................................ 406
Motivation .............................................................................................................................. 406
Background ............................................................................................................................ 406
Clariﬁ cation of Terms—Technology Deﬁ ned ......................................................................... 407
Log Aggregation ..................................................................................................................... 407
Centralized Management ........................................................................................................ 408
Real-Time Analysis ................................................................................................................. 408
Correlation of Events .............................................................................................................. 408
Forensics Analysis ................................................................................................................... 409
Incident Response Handling ................................................................................................... 409
Challenges ...............................................................................................................................410
Deployment ....................................................................................................................410
Conﬁ guration .................................................................................................................410
Agent Coverage ...............................................................................................................411
Rules ...............................................................................................................................411
Event Filtering ................................................................................................................411
Deployment Tips .....................................................................................................................412
Conclusion ...............................................................................................................................413

406  Information Security Management Handbook
Introduction
In February 2007, I was part of a panel at the RSA Conference addressing the subject of security 
information management or SIM. Th e panel consisted of industry practitioners, speciﬁ cally those 
who had implemented this somewhat new and complex technology. It was intended to serve as a 
“lessons learned.” However, I soon realized that the one hour dedicated to this issue was not even 
a particle of dust in the vast space of this subject. First of all, there seems to be a great deal of con-
fusion regarding the nomenclature itself. So, if SIM stands for security information management, 
then what is SEM (security event management)? Are the technologies the same? If yes, why the dif-
ferent acronyms, and if no, what are the similarities and diﬀ erences? I was besieged after the panel 
by attendees and those who could not attend for the lack of space in the massive room. Th e ques-
tions were mostly about fundamentals and how this technology could be smoothly implemented 
(normally SIM is not synonymous with words such as “smooth,” “easy,” “eventless,” etc.).
Motivation
Originally, when I was asked to write about this subject, I thought that it would be appropriate to 
dedicate the entire paper to the fundamentals. However, I realized that by having implemented 
this technology (pardon the use of the word “technology” as it is a loose ﬁ t—I will explain later) 
two years earlier, the experience gained was not only very relevant, but also incredibly valuable. 
One can Google the vast databases of the Internet and ﬁ nd hundreds of hits on this subject but 
it would be extremely diﬃ  cult to ﬁ nd an actual implementation case, from beginning to the end 
(the word “end” does not really apply in this context because the implementation and operation 
of a SIM resemble the mathematical equivalent of the old classic “Gideon’s Trumpet,” where the 
issue at hand does not have an end or a “limit”). I should mention that I am a big advocate of the 
“Socrates” method of teaching and presentation, in which the subject is explained using actual 
“cases” and real-world examples, rather than merely deﬁ ning the terms and implementation con-
ditions. (Th is method of teaching is utilized by many law schools as cases are studied and adjudi-
cations analyzed to  understand their relevance to laws).
Background
In the mid-1990s, it became apparent that manual analysis of logs belonging to critical systems 
(UNIX in particular) was not practical. Systems administrators began to write “scripts” that would 
search through megabytes of data for certain events. For example, if the number of unsuccessful 
log-in attempts exceeded a certain threshold, the script would make a note. Other searches looked 
for direct “root” access and guest accounts. Th e practice became standard mainly in the UNIX 
community. Th e problems with this method were multifold:
 
1. Th e Windows operating system did not have the ﬂ exibility of UNIX; scripts could not be 
easily written and did not extend to many events.
 
2. Th e strength of this method was only as good as the script including many of the common 
events (and even then, there were always some that were missed or overlooked).
 
3. Th e results would be dumped into a ﬁ le, which would then be reviewed by an administrator 
or security personnel. In almost all cases, the results were not available until the next day or 
days later.

Security Information Management Myths and Facts  407
All of the above issues would then render the script method ineﬀ ective. It was not until a 
few years later that vendors used this methodology and designed software to address some of its 
 shortcomings. However, it took a few more years before these products matured.
In addition to the obvious security advantages, the new generation of SEM tools (as they were 
referred to in the early 2000s) addressed another much needed issue, compliance. Section 404 of 
the Sarbanes–Oxley Act of 2002 required publicly held  companies to review ﬁ nancially relevant 
systems’ security events (in-scope systems) and document them for internal and external auditors’ 
inspection. Th ese “controls” (as they are referred to by the Act) required that organizations devise 
policies and procedures to retain and review logs of in-scope systems.
Clariﬁ cation of Terms—Technology Deﬁ ned
Earlier I mentioned the use of SIM and SEM. To add to the confusion, there are other terms such 
as “log management,” “event funneling,” “log aggregation,” and a few others that are less com-
mon. It would not be prudent to deﬁ ne and analyze all these terms, as they are all so very loosely 
or, in some cases, tightly coupled. Instead, the clariﬁ cation will consist of explaining what the 
technology is intended to address, and it would be up to the reader to use an  appropriate term to 
frame it. For the purposes of this discussion and simplicity, we will refer to this “technology” as 
SIM. SIM also happens to be the word chosen by the information security industry today.
In a way, SIM brought together all of the areas mentioned earlier. It incorporated all of the 
concepts mentioned and more.
 
1. It made it possible to aggregate logs of many diﬀ erent systems with various formats 
( normalization of logs).
 
2. It centralized the management of security events (or security information), making it  possible 
to build sophisticated and eﬀ ective security operation centers (SOCs).
 
3. It allowed real-time analysis of events, which previously was not possible. Th e term “real 
time” is somewhat misleading, however, because network and system delays do not make 
alerting available instantaneously.
 
4. It provided correlation and intelligence; perhaps the most important and notable character-
istic of SIMs. Without “C&I” these systems would be just gloriﬁ ed log aggregators.
 
5. It improved forensics analysis of events.
 
6. It improved incident response handling.
Log Aggregation
Linux, Solaris, Windows, Cisco IOS, mainframes, ﬁ rewalls, intrusion detection and prevention 
 systems with proprietary operating systems (IDS/IPS), and other platforms make it impossible to feed 
events directly to a correlation engine (CE; explained later). If all these platforms employed the UNIX 
“syslog” format, it would make it much easier for the SIM’s CE to understand and decipher the mes-
sages; but, clearly, that is not the case. Checkpoint uses its own proprietary format, and then there are 
SNMP traps. In this case, “normalization” of logs is an absolute requirement. Normalization is the 
process of reducing the complex structure of data into a simple form  without losing all its  attributes 

408  Information Security Management Handbook
and characteristics. Once the data is normalized it is then fed into the correlation engine (SIM  vendors 
employ many diﬀ erent architectures; however, the underlying premise remains constant).
Centralized Management
With today’s complex networks, multiple data centers, global hubs, disaster recovery sites, and 
many ﬂ avors of platforms, the information security well-being of organizations depends on how 
well the millions of events generated by these systems are collected and analyzed. Centralization of 
data allows the otherwise disparate and seemingly unrelated information to be gathered,  analyzed, 
and presented as a single source. Th is is crucial in building a successful SOC. An organization 
with a well-designed and deployed SIM funnels events from everywhere in the network into a 
central console that is being monitored by level I or level II support personnel. Th e advantage 
is that information sharing becomes much more robust and the speed by which incidents are 
responded to is improved. Add this to the capability of many SIMs with built-in IPSs and one can 
have instantaneous shunning of attacks. Of course, a great deal more thought should be given to 
activating the IPS capabilities of SIMs as they can block legitimate production traﬃ  c as well.
Real-Time Analysis
Earlier I mentioned the archaic practice of writing scripts to search system logs for security events. 
I also wrote that it could be days before the results would be available for review by system admin-
istrators. In some cases, this delayed reaction could cost companies hundreds and even millions 
of dollars. A brute force attack would have bells ringing through a SIM-based solution. Alerts can 
be routed to the Help Desk, the SOC, the enterprise operation center (EOC), e-mail accounts, 
cell phones, pagers, and PDAs. Th e delay in response would be reduced from days to minutes 
practically. Th is improvement would have a direct impact in terms of not only reducing the risk 
of ﬁ nancial loss but also avoiding embarrassing and negative media coverage. In essence, real-time 
analysis closes the gap between incident and response.
Correlation of Events
Th ere are many catchy words and phrases in today’s IT world—words designed to make a 
 technology sexy and slick. In my 20 years of experience in this industry I have heard it all; and 
frankly, I have never been a fan of using such terminology. From time to time, a word comes along 
that perfectly describes the underlying premise, theory, or technology. I believe “correlation” is one 
of those words. One does not have to dig deep to ﬁ gure out what correlation means when it is put 
in the context of security events. Sure, there may be some confusion as to its true beneﬁ ts, or how 
it actually works, but there is never a doubt as to its meaning.
In a typical network, there are routers, switches, ﬁ rewalls, Web servers, Web applications, etc. 
Each component generates messages either because of its own internal design or as it processes data. 
Th e components communicate with one another and in doing so generate more messages. Th ere 
are interactions between E-Commerce systems, Web application servers, databases (more likely 
placed inside the network segmented by ﬁ rewalls), and other pieces of the infrastructure spread 
out through the entire enterprise. It would be nearly impossible for typical human resources to sift 
through and decipher all these messages and even more challenging to make sense of events that 

Security Information Management Myths and Facts  409
happen separately but almost simultaneously in diﬀ erent areas of the network. Th is is certainly a 
daunting task. Event correlation provides the following:
 
1. It reduces the amount of traﬃ  c by setting thresholds for certain alerts—for example, instead 
of generating thousands of alerts “root log in” the threshold is set to three messages per 
minute.
 
2. It makes sense of seemingly unrelated anomalies and tries to establish a relationship among 
them—for example, a Domain Name System (DNS) poisoning attack launched simultane-
ously in diﬀ erent parts of the network. Th e event correlator determines that the attacks have 
the same source IP and orders boundary routers and ﬁ rewalls to modify their ACL and rule 
sets to block the address.
 
3. It translates complex data to detect whether traﬃ  c is safe.
Forensics Analysis
Th e term real-time forensics is new; the concept, however, is not. Th e technology has been on 
the wish list of many security personnel. In the traditional forensics world, after an incident has 
occurred, one would gather logs and events, collect hard drives, bring production systems to a halt, 
freeze applications, interview employees, call in the experts to tear apart TCP/UDP packets, and 
perform a slew of other dizzying tasks that could take up tremendous human and ﬁ nancial resources. 
Th is linear approach to forensics analysis could take days or even weeks to complete the analysis; by 
then, the organization may have lost valuable proprietary data and the perpetrator would have been 
able to clean up their footprints. Th e new “parallel forensics processing” is a combination of intel-
ligence, correlation, and real-time processing of security events that do not take place sequentially. 
It is important to note that, even with the sophistication of SIMs today, a comprehensive and robust 
incident response policy is absolutely critical to the overall eﬀ ectiveness of incident handling.
Correlation is an integral part of modern SIM systems. As a matter of fact, one of the most 
important criteria that I recommend for the evaluation of an eﬀ ective SIM is how well the CE 
responds to disparate attacks, which can be simulated using common tools (such as Nmap).
Incident Response Handling
One of the very ﬁ rst tasks that I undertook as the chief information security oﬃ  cer of my 
 company was to write a comprehensive and robust incident response policy (IRP). I cannot stress 
the importance of a well-written and practical IRP. Aside from the obvious beneﬁ ts of having an 
IRP (I will not go into explaining the typical beneﬁ ts, as it is one of the most saturated subjects 
of information security), it is mandated by legislative and regulatory statutes, such as Sarbanes–
Oxley, Section 404. And for those organizations that process credit cards, the Payment Card 
Industry Data Security Standards compel them to have one as well. However, having been the 
author and implementer of many IRPs, I have learned that even the best documents can suﬀ er 
from what I refer to as “ﬁ eld challenges.” Field challenges consist of the following:
 
1. Th e time that it takes to collect forensics information.
 
a. Determining which systems/applications have been compromised.
 
b. Preserving the evidence according to the “chain of custody” rules.
 
c. Traveling to multiple locations to do (a) and (b).

410  Information Security Management Handbook
 
d. Halting systems that may have been compromised but are not yet determined as such 
(sometimes infected systems do not exhibit abnormal behavior and time is needed to 
search through system and application logs to make this determination).
 
e. Interviewing systems administrators, developers, security staﬀ , etc.
 
2. Examination of information collected.
 
a. Look through hard drives and system and application logs. If forensics tools and in-
house expertise are not available, media and logs must be sent oﬀ -site for analysis.
 
b. Look though hand-written notes collected from interviews and other observations.
 
3. Reporting: Place all ﬁ ndings in a manner understandable for management and law 
enforcement.
For the sake of simplicity I have kept the above to only three items; a more detailed and 
 comprehensive list could include more than ten items. What does this all mean? All of the above 
eﬀ orts translate into time—time that a security oﬃ  cer does not have. A typical  information secu-
rity incident could sometimes take up to 30 days to investigate. A well-designed and  conﬁ gured 
SIM with detailed forensics capabilities, such as “deep packet inspection,” could reduce the inci-
dent response time to hours, even minutes, versus days or maybe even months. In cases in which 
deep packet inspection is required to determine the type of attack, source or destination spooﬁ ng, 
and payload changes, manual examination of these packets is nearly impossible. Even if there is 
resource constraint, time is a factor. SIMs equipped with this type of analysis will take the exam-
iner directly to the infected packet and by clicking through hyperlinked areas show the exact 
bit impacted. Th is is a tremendous gain in terms of time and resources. Almost all SIMs come 
equipped with reporting capabilities that enable the user to generate incident reports in a matter 
of minutes. Canned and custom reports provide ﬂ exibility and ease for security oﬃ  cers.
Challenges
As most technologies make certain tasks not only possible but more eﬃ  cient and accurate (like sifting 
through gigabytes of log data), they also present unintended challenges that in some cases, at least 
initially, require tremendous resources and expertise to overcome. SIMs are not immune to this “side 
eﬀ ect.” In this case, however, the eﬀ orts are well worth it; the end result could be a state-of-the-art 
SOC with the SIM as its core component. Th is is an important point, because the investment in a 
typical SIM is so high that tearing it down and starting over would not be practical in most cases.
In the following, I have highlighted several challenges based on personal experience, although 
I must confess that there may be other challenges that others may have faced that are not well 
publicized.
Deployment
A badly deployed SIM could have grave consequences. A false sense of security is perhaps the most 
prevalent. I have explained in more detail deployment strategies, again, based on my personal 
experience. Although I had researched SIMs for years and have written extensively about them, 
the practical experience of deploying one is invaluable.
Conﬁ guration
Th ere are many checks and balances to consider when conﬁ guring a SIM; for example, checking 
“agents” for reporting and database issues. A misconﬁ gured SIM will not be eﬀ ective.

Security Information Management Myths and Facts  411
Agent Coverage
To maximize the eﬀ ectiveness of SIMs one must make sure that all platforms are covered. At the 
time of my evaluation (early 2004), no vendor provided support for all the platforms spelled out 
in my request for proposal, and only one was willing to develop one for a particular platform. For 
proprietary platforms and applications, one must consider SIM vendors who are willing to work 
with their clients to develop the right agents. Make sure that your contract includes service level 
agreements with regard to this issue.
Rules
Many SIMs employ a combination of behavior-based modeling and rules to catch  anomalies. Th e 
systems are generally shipped with a set of canned rules, signatures designed to catch many of 
the common forms of attacks. Some SIMs, such as netForensics, oﬀ er a set of rich graphical tools 
that allow the user to devise new rules without the use of complicated script languages. As SOC 
personnel and security engineers become familiar with the system and the environment that it 
monitors, they can build custom rules targeting a set of speciﬁ c events. However, even with the 
existence of these tools, writing eﬀ ective correlation rules is very challenging. I would recommend 
attending the SIM’s technical training (almost all SIM vendors oﬀ er extensive oﬀ -site training that 
includes a day or two on the subject of rules).
Event Filtering
Perhaps the most complex and challenging of all implementation tasks; as I have mentioned  several 
times, network components generate gigabytes of data that funnel into the SIM’s databases. Th e 
correlation and rules engines pour through this data attempting to make sense of them. In the 
process, thousands of alarms are generated that include “false positives” and “false negatives.” 
False positives are alerts that indicate a potential issue when in fact there is none. A false negative 
(which happens to be an even bigger concern) is when an anomaly is missed by the SIM. Initially, 
after deployment, it would be safe to assume that at least 50% of the generated alerts are false 
positives. Th ese could be normal chatter among various network components such as the Virtual 
Router Redundancy Protocol between ﬁ rewalls for failover. It takes weeks, if not months, for 
dedicated and knowledgeable security staﬀ  to pore over these messages, identify their sources and 
destination, perform research, contact the SIM vendor, and work with system administrators to 
eliminate them.
Below are some guidelines for message ﬁ ltering:
 
1. Stop message ﬂ ow from the source—a responsible system administrator will turn oﬀ  
 messaging for a speciﬁ c event at the source.
 
2. Stop message ﬂ ow at SIM—rules can be written to ignore the message. Action can be “drop,” 
which eliminates the message altogether from the database, or “store,” which means ignore 
the message but keep it in the database for future use. Future use could include forensics 
and compliance.
 
3. Examine the “canned” rules and write rules customized for your environment (please see 
more on this topic later).
I found that in the process of message ﬁ ltering, ﬁ nding systems that are misconﬁ gured is not uncom-
mon. During the 16 weeks of intense alert ﬁ ltering, we discovered several UNIX and Windows 

412  Information Security Management Handbook
Figure 30.1 Graph indicating the number of reductions before and after even ﬁ ltering. 
Note: Operating system-speciﬁ c information has been removed from this graph for security 
purposes.
53,000
15,050
2525
50,000
32,767
14,712
568
5000
100
150
25
0
10,000
20,000
30,000
40,000
50,000
60,000
Number of events
Before filtering
53,000
150
25
50,000
32,767
14,712
568
After filtering
5000
150
25
500
100
150
25
Sourcefire
As400
500
servers that had not been conﬁ gured correctly. For example, a DNS server was generating 443 and 
80 traﬃ  c, which indicated that the Internet Information Server was running and the system was 
functioning as a Web server as well (although the system administrator had not intended as such).
Figure 30.1 depicts a graph showing the number of alerts before and after alert ﬁ ltering eﬀ orts 
at my organization.
Deployment Tips
 
1. A sound architecture is priceless. Let us not forget the fact that SIM is an expensive and 
 complex technology. Regardless of what the vendor claims, rest assured that deployment 
is not going to be easy. With fragmented LANs, ensure that your SIM, whether appliance 
based or not, has a view into every segment of the network that you intend to monitor. 
Virtual LANs can obstruct the ﬂ ow of information into the SIM’s database. Obtain an 
up-to-date copy of your organization’s network topology and identify all critical areas.

Security Information Management Myths and Facts  413
 
2. Ensure the collection of data from all sources—by correctly conﬁ guring and architecting 
the SIM one can ensure that all network segments are covered.
 
3. Devise controls and policies—how do you ensure that all your devices are pointing their 
logs to the database of your SIM? Th e ﬁ rst step is to write policies and procedures in 
 support of this item. In my organization, we require two sets of documentation with every 
new device: one is a Change Control Form (CCF), which is part of Change Manage-
ment, the other is a form called a New Device Certiﬁ cation Form (NDCF). Th e CCF is 
required because a change in production is about to occur; a new device is being added to 
the  environment. Th is is required even if the system is a developing one, because it is not 
known whether it will be running production data. Th e purpose of an NDCF is to allow 
the Oﬃ  ce of Information Security (OIS) to perform a thorough vulnerability scan of the 
platform and applications for the new system. It also allows the OIS to ensure that this 
device is properly conﬁ gured to send its logs to the SIM database. Th e OIS logs device 
information into a database for future checks. Additionally, there is a control written to 
oversee this entire process. Th e control is tested monthly by the OIS and internal audit.
 
4. Th ere is, of course, technology to support the procedures above. Your SIM may come 
equipped with technology that can detect new devices as they are plugged into the net-
work or removed from it. Th is would make it easy to pinpoint such devices and alert the 
 appropriate department. In many cases, however, this technology is supplied by a third 
party (Sourceﬁ re’s RNA is such an example). In either case, it is invaluable to have such a 
 technology to support all policies, procedures, and manual audits.
 
5. Staﬀ , staﬀ , and then staﬀ —I cannot begin to stress this point enough, that the most success-
ful SIM deployment is not the one that is well designed and implemented, but the one that 
is well managed. Th ere is no sense in deploying a technology like this if the organization 
does not have the human resources dedicated to its management and maintenance. SIM 
requires minute-by-minute attendance. Whether it is the daily update of signature ﬁ les, 
watching critical alerts ﬂ ow into the console, looking for false positives and negatives, or 
merely checking the overall health of the systems, it is extremely demanding and unforgiv-
ing. When planning for a SIM the budget must allow for resources in addition to EOC and 
Help Desk personnel.
Conclusion
It took nearly one year and the eﬀ orts of two people dedicated to the evaluation and testing of 
SIMs before we were ready to announce the product that best ﬁ t our environment. Choosing a 
SIM is not easy; but it is not magic either. Th ere are many considerations and issues that must 
be well studied. I found that developing a “matrix” with our requirements seemed to work best. 
For example, we wanted a system that supported all of our platforms. In the end, although such a 
product did not exist, we found a vendor who was willing to develop an agent needed to support 
the platform.
Th is was indeed one of the most challenging deployments I had been personally involved with. 
But, it is never over; once you make a commitment to a SIM, your job never ends.


415
A
AAC, 234
access
authorization of, 141
control, see access control
denial of, 151
logs, 98–9
management, 289
overassignment of, 107 
unauthorized as privacy breach incidents, 32
access control
administration, accountability, 163–72
attack methods, rootkits, 175–88 
covert channels, 230
frameworks, 382
importance of, 30, 90, 370 
levels of, 201–2 
mature security programs, 96, 98–9, 101
methodologies, 206
techniques, authentication tokens, 145–60
account management, 6–7, 97, 104, 382
accountability, see authority and 
accountability (A&A)
assumptions, 164
business process details, 165–6
deﬁ ned, 164
enforcement participants, 172
need for, 111, 164–5 
remediation and, 387
requirements overview, 165
technical process details, 166–7
technical process implementation, 167–71
threats, 172
accreditation services, 251
Act, PDCA model, 20, 249, 260, 346
action plan
approval of, 79
development of, 78–9
implementation of, 79
active content controls, 381
Active Directory (AD), 290
ActiveX, 6, 302
Adam, covert channel example, 230–1
adaptation
adaptive agent construction, 353–5
complex adaptive systems (CAS), 350–3, 355, 357–8
learning process, 350–1, 358
research directions, 357
trends, current and future, 355–7
ad hoc queries, 6
administrator
accountability strategies, 168–71
roles of, 10, 99, 177–84
advanced encryption standard (AES), 291
advisory board, functions of, 115–6
agent performance system, 353
aggregate risk, 25
aggregation attacks, 372
AgreementMethod, XML encryption, 216
alerts, 8, 10, 100
aliases, 224
Altiris scan, 62, 69
American National Standards Institute (ANSI), 245
analog computing, 367–8
antigroup, accountability strategies, 167, 169
anti-phishing, 65, 302
Anti-Phishing Working Group (APWG), 51, 58, 65, 
296–7
antispam ﬁ lters, 298, 302
antispyware software, 4–5, 7, 11, 186–7, 301
antivirus (A/V) products
applications, 4–5, 7, 10–1, 48–9, 51, 66–70, 98, 
150, 186–7, 301, 350
gateways, 106
research, 401
up-to-date, 99, 155
APNIC, 56
application controls
bias, 322
learning rate, 322
momentum, 322
stop points, 322
test sets, 321
training sets, 321
validation sets, 321
Index

416  Index
application
controls, see application controls
ﬂ ags, 63
security strategies, see application security
sizing, 344
updates, 10
application security
adaptation, next-generation security application 
development, 349–58
information technology infrastructure library, 
333–48
neural networks, information assurance, 307–30
quantum computing, 361–74
architecture
integrated threat management (ITM), 5
mature security programs, 100
quantum computing, 365, 367, 369–70
archiving, 6, 291
ARIN, 56
Arthur Andersen, 379
artiﬁ cial intelligence (AI), 308, 356, 372–4
assembly language, 176
asset inventory searches, 62
association macro, 111
assurance, degree of, 24–5, 257. See also compliance 
assurance
asymmetrical key exchange, 291
asynchronous authentication tokens, 148
attachments, 7, 30, 301
attack(s), see speciﬁ c types of attacks 
monitoring for, 44
surface, minimization of, 226
traﬃ  c, 60 
types of, 100
vectors, 51
atribute-based authorization, 218, 224
Attrition.org, 31
audit(s)
accountability strategies, 170–2
components of, 10, 206, 257 
conﬁ guration management, 341
internal reviews, 386
logs, 51, 60, 330
mature security programs, 96, 98–9, 101
policies, 59, 184
requirements, 32
types of, 114
auditors, roles of, 165
Australia, security policy, 136
authentication
biometric technologies, 156–7, 160
client-server password, 154 
control frameworks, 382
day-to-day, 159
logging, 401 
mature security programs, 106
multiple, 157
need for, 99, 160, 217 
passwords, 154, 303
process overview, 154–7 
strong, 182, 184, 188
tokens, role of, see authentication tokens
two-factor, 101, 156–7, 303
web services security, 225
WS-Federation, 223
WS-Security, 220
authentication tokens
attack methodologies, 149–51
asynchronous, 148
candidates for, 147–8
clock drift, 157
expired, 159
form factors, 147–8
how they work, 157–9
management, 159–60
need for, 145–6
passwords, 146–9, 151, 158
risk mitigation, 147, 153–4
role of, 145–7, 153
synchronous, 148–9
time-synced, 158
authority and accountability (A&A), 121–6
authorization, 17–8, 225. See also access control
authorship, 329
autoassociative memory, 313
automated security processes, 101, 387
automatic teller machines (ATMs), 147
Autonomous System Numbers (ASN), 55–6
availability management, 335, 337, 345
B
baby boomer generation, 137
backdoor
access, 177–8, 181, 188
vulnerabilities, 197
background checks, 90
back propagation, 313, 330
backup(s) 
data restoration, 44
ﬁ les, 6
importance of, 99, 187
media, 101
oﬀ -site, 386
balanced scorecard, 263
bandwidths, implications of, 11, 231–3
bank account statements, 301
banking industry, 257
barrier defense, cell biology vs. computer 
networks, 239

Index  417
barrier transmission/communication, cell biology vs. 
computer networks, 239–41
Basel II Accord, 266–7
Basel III Capital Accord, 136
Bayesian content ﬁ lters, 302
BB84 algorithm, 366
Bennett, Charles H., 366
best-in-class products, 5, 10
best practices, 9, 57, 169, 258, 334, 336, 385
bias
application controls, 322
in culture assessment, 120
neural networks, 322
quantum computing, 370–1
binary security tokens, 219–20 
.bin directory, 67–8
biometrics
neural networks, 328–9
quantum computing applications, 370
types of, 139, 156, 160, 201, 204, 245, 330
blanket ISMS, 18
Bleeding Snort, 60
Bleeding Th reat, 54
Blue Security, 65
board of directors, functions of, 19, 140
Boolean algebra, 365
border gateway protocol (BGP), 56
botclients, 60–1, 64
botnets, 51, 57, 61–4, 66, 181, 299
brainstorming, 76
branch oﬃ  ces, 10
Brassard, Gilles, 366
breach notiﬁ cation laws, 380
British Standard (BS) 7799, 136, 252, 254, 259–60, 383
British Standards Institution (BSI), 251
broadcast architecture, 195, 197
brokered single sign-on, 218
brute-force attack, 155
budget/budgeting, signiﬁ cance of, 23, 89–90, 
94, 99, 136, 141
Buﬀ er Overrun Detection (BOON), 234
bulk encryption, 195
Bureau Veritas Certiﬁ cation (BVQI), 251 
business-class server farms, 399
business continuity
management (BCM), 344, 346
mature security programs, 96, 98–9, 101
planning, 18, 372, 374
business disruptions, 140
business enabler, 18
business impact statement, 165
business initiatives, 94
business interruption assessment (BIA), 98
business partners, 140–1
business plan, 165
business resilience, buy-ins, 140
business risks, 257
Business Security AB SecuriFax, 278
business unit goals, culture assessment, 113, 115
buy-in, acquisition of, 140–2
C
Cain & Abel password-cracking tool, 149
Calder–Moir IT Governance Framework, 263–4
Canada
incident notice laws, 32
laws deﬁ ning PII, 34–7
security policy, 136
C&C servers, 51–2, 54, 58, 60, 63–4
Canonicalization Method, XML signature, 214
Capability Maturity Model (CMM), 25, 268
Capability Maturity Model Integration (CMMI®), 94
capacity management, 335, 337, 343–5
capital
costs, 9
expenditures, 100
projects, 90
CastleCops®, 54–5, 58
cell biology, defense-in-depth approach
analogies with computer networks, 238, 240–4
components of compared with computer network 
counterparts, 239
information security principles from, 243–4
cell phones, 197
cell theory, 238
Center for Internet Security, 183
Central Computer and Telecommunications 
Agency, 334
centralized management, 408
certiﬁ cates, 158
certiﬁ cation
CEO/CFO, 392
ISO, 102, 106
chain of command, 88
chain of custody, 399
challenge-and-response questions, 159
change
deﬁ ned, 340
detection, rootkit attacks, 185–6
initiatives, 125–6
management, 113, 116, 137, 334–6, 340
patterns, 352
Change Control Form (CCF), 413
chargebacks, 341
charter information security program, 21–2
Check, PDCA model, 20, 249, 260, 346
checklists, 255–6
chief administrative oﬃ  cer, 114
chief executive oﬃ  cer (CEO), 111, 164–5, 392

418  Index
chief ﬁ nancial oﬃ  cer (CFO), 413
chief information oﬃ  cer (CIO), 100, 107, 114, 386
chief information security oﬃ  cers (CISOs), 100, 102, 
135–142
chief security oﬃ  cer, 386
chief technology oﬃ  cer (CTO), 139
children, protective legislation, 34–7
chkrootkit, 186–7
CipherData, XML encryption, 217
CISO Toolkit, 267–8
CISSP®, 164
classical computing, nanometer-scale, 365
client-server password authentication, 154
climate predictions, 364
closure, 337
Cohen, Fred, 267–8, 373
coin ﬂ ipping, 370
collaboration, 387
collective bargaining, 122
command and control servers, 53–4
commercial e-mail messages, 7
Committee of Sponsoring Organizations of the 
Treadway Commission (COSO), 254, 267, 
379, 381, 386
Common Criteria (CC), 254, 261
communication
cell biology vs. computer networks, 239, 242–3 
department-level transformation, 88
future challenges of, 140–2
incident management process, 337 
organizational culture, 126–7
privacy breach plans, 40–1
signiﬁ cance of, 90, 239
specialized mechanisms, 243
community virus database, 50
company ID, 90
competition, 140–1, 354
compilers, rootkits, 185
complex adaptive systems (CAS), 350–3, 355, 357
complexity, 226
complex systems, 229
compliance assurance
best practices, 385
compliance, deﬁ ned, 378
control frameworks, 380–2
11-factor manifesto, 385–7
noncompliance penalties, 384–5, 387
signiﬁ cance of, 378, 388
sources of regulations, 378–80
standards, 380–4
Computer Emergency Response/Team Coordination 
Center (CERT/CC), 48
computer forensics, 395
computer incident advisory capability (CIAC), 48
Computer Security Institute/Federal Bureau of 
Investigation security survey, 105
Computer Security Resource Center, NIST, 265
Computer Virus Catalog, 50
CONDITION/ACTION statements, 353
conﬁ dence rating system, 63
conﬁ dentiality
agreements, 58, 279
guidelines, 58
signiﬁ cance of, 136, 181, 217, 220, 225–6, 
258, 275, 292, 345, 387
conﬁ guration ﬁ les, 61
conﬁ guration management
components of, 334–6, 340–1
database (CMDB), 7, 340–2
mature security programs, 96, 98–100
conﬁ rmed phish queue, 55
connectedness, future challenges of, 139
consensus building, 125
console management, 10
Consultative Committee for International Telegraphy 
and Telephony (CCITT), 274
consumer education, importance of, 301–2
contactless smart cards, 201
content ﬁ ltering, 4, 289–92
content management system, 289
continuous improvement, 336
continuous process improvement, 18, 24
contraband, 397
contracts, availability management, 345
control
access, see access control
conﬁ guration management, 340
content ﬁ ltering, 291
matrices, 256
signiﬁ cance of, 347
span of, 247
Control Objectives for Information and Related 
Technology (COBIT ®), 94, 260, 267, 379, 386
cookies, 30, 302
copyrights, 100, 279
corporate structure, 358. See also organizational structure
correlations, types of, 7, 11
cost(s), see ﬁ nancial considerations
of breach, 31, 181
of goods (COGs), 89
cost-beneﬁ t analysis, 78
Cotecna, 251
counterintelligence, 65–6
covert channels
analysis process, 232–4
deﬁ ned, 229–30
example of, 232
exploitation of, 230–1
information ﬂ ow, 231, 234–5
information resources, 231, 235
potential, 230, 233
protection against, 234 

Index  419
quantum computing, 370
steganography, 234
covert ﬂ ow trees, 233
Cqual, 234
credibility, inﬂ uential factors, 90, 102, 104, 129
credit
assignment, 353–4
monitoring, 40
credit cards
card statements, 301
fraud, 31
criminalistics, 397
criminality, prevalence of, 392
critical application systems, mature security 
programs, 104
critical business issues, 262
critical events, accountability strategies, 170
critical success factor (CSF), 79
critical systems, mature security programs, 100
crossover process, 352, 354–5
cross-site scripting attacks, 301
cross-training, 403
cryptanalysis, 182
Cryptek Secure Fax, 278
cryptography, 191–8, 367, 370–1
C2 servers, 64
culture assessment
beneﬁ ts of, 118–9
importance of, 113–5
instrumentation, 119–20
managerial support, 115–6
meeting guidelines, 115
methodologies, 116
participants in, 114–5
resistance to, 116
customer
needs, 127
satisfaction, inﬂ uential factors, 90, 125
CWSandbox, 51, 61
cyber-forensics
applications, 400
incident response compared with, 396–7
process model, 393–6, 402–3
cybernetics, 350
cycle times, 90
CYMRU, 55–6
CyperReference, XML encryption, 217
CypherValue, XML encryption, 217
D
darknets, 52, 56, 61, 63–4, 66
data
analysis, 7
archiving, 6
classiﬁ cation, 106
collection methodologies, 7, 114, 118–20, 170
ownership, 101
storage, 6, 33, 170
databases
access to, 11
authentication, 159, 166
backups, 6
conﬁ guration management, 340–2
National Vulnerability, 379, 384
SQL, 212
data centers, 9, 11, 22–3, 101, 202
day-to-day operations, 247, 280
decision making
informed-choice, 17–8, 25
process, inﬂ uential factors, 8, 12
decryption, 158, 182, 216, 364, 367
deep packet inspection, 410
default conﬁ guration, 183
defense-in-depth strategy, 302
Defense Information Systems Agency (DISA), Security 
Technical Implementation Guides (STIGs), 379, 
384, 386
delegated identity, 217
delegated trust model, 224
delegation, 25
delta release, 343
demand forecasting, 344
demilitarized zones (DMZ), 226, 239, 242
Deming, W. Edwards, 16
denial-of-service (DoS) attack, 91, 170, 181, 225–6
Department of Defense, 48
Department of Energy, 48
Department of Homeland Security (DHS), 53
desktop, protection guidelines, 197, 302
diﬀ erentiator, 17–8, 25
Diﬃ  e–Hellman encryption method, 216
DigestValue, XML signature, 214
digital computers, 363
digital evidence handling
chain of custody, 399
commingling, 399
characteristics of, 392
digital evidence deﬁ ned, 397–8
importance of, 393
integrity, 399
life cycle of digital evidence, 399–400
misperceptions, 393
preservation strategies, 396
reasonable expectation of privacy, 398
types of evidence, 397
volatility, 398
volume, 399
digital forensics, 402 
Digital Millenium Copyright Act (DMCA), 51

420  Index
digital rights management, 139, 289
digital signatures, 213–4, 220–2
direct brokered trust model, 224
direct trust model, 224
direction
in organizational culture, 124
signiﬁ cance of, 17–8
directives, 23–4, 29, 34–7, 141, 262, 380
directors, roles of, 19
disaster recovery plan (DRP), 98–9, 
105–6, 225
disclosure, 289. See also information disclosure
discretionary access control (DAC) system, 164
Discretionary Access Control Knowledge, a Practical 
System, 168–9
discretionary controls, 78
distributed policy and key management 
architecture, 196
distribution layer, encryption security 
architecture, 195–6
diversity principle, 351–2
Do, PDCA model, 20, 249, 260, 346
documentation
business process details, 165–6
covert channel analysis, 233
department-level transformation, 88
importance of, 8–9, 13, 17, 25
incident management process, 337
ISO standards, 248
mature security programs, 104
privacy breach incidents, 33
privacy breach plan, 44
requirements, 32
service agreements, 344
domain names, phishing process, 300
Domain Name System (DNS), 300, 409, 412. 
See also domain name system 
(DNS) servers
domain name system (DNS) servers
analysis, 65
characteristics of, 49, 54
fast ﬂ ux, 65
DoubleClick, Inc., 30
downloads/downloading, 60, 301
downtime, 98–9, 140
Drone Army, 57
DROP list, Spamhaus, 56
ds:*, XML encryption, 216
ds:KeyInfo, XML encryption, 216
ds:KeyName, XML encyrption, 216
dsa-sha1, 214
due care, 251
due diligence, 17, 25, 101, 251, 378, 393
D-Wave Systems Orion, 371
dynamic biometrics, 156
dysfunctional organizations, 124
E
EasyNN-Plus, 322
eavesdroppers, 366
Ebay, 297
Eckert, Artur, 366
egress points, 247
electronically stored information (ESI), 392, 402
electronic commerce (e-commerce), 298, 335, 408
electronic discovery, 139
electronic mail, see e-mail
11-Factor Security Compliance Assurance 
Manifesto, 385–7
e-mail
abuse, 51
breach notiﬁ cation, 43
content ﬁ ltering, 290–1
delivery method, 242, 298–9
denial of service notiﬁ cation, 170
digital evidence, 397–8
ﬁ ltering, 7
future security challenges, 137
HTML, 302
integrated threat management (ITM), 4
messages sent, 7
phishing, 155, 160
privacy breach, 30, 32
spooﬁ ng, 297
unsolicited, 7, 32
Web-based, 290
emergent behavior, 308
employee(s)
accountability policy, 166
badges, 90, 159–60, 204
burnout, 378 
engagement strategies, 90–1
involvement in organizational culture, 129 
-managerial relationship, 128
morale, 127 
rank and ﬁ le, 116–7
relationship with organization, 121
satisfaction, 336 
scheduling, 364
security awareness program, mature security 
programs, 97–9, 101 
termination of, 204
theft, 30
value exchange with organization, 120
encoding, 301
EncryptedData, XML encryption, 216
EncryptedKey, XML encryption, 216
encryption
characteristics of, 154, 158–9, 182, 291–2
faxes, 281, 284
key management, see encryption key management 
layer, 195–6 

Index  421
quantum computing, 364–7, 374
XML, 211
encryption key management, large-scale networks
application-level encryption, 194
challenges of, 197–8
IPSec encryption, limitations of, 194–5, 197
link-level encryption, 193
network-level encryption, 194 
separation of solution, 195–7
EncryptionMethod, XML encryption, 216
EncryptionProperties, XML encryption, 217
endpoint security conﬁ guration, 150
ENIAC, 371
Enron, 379
entanglement, 363, 369
enterprise A/V management tools, 51
enterprise document management, 139
enterprise incident response, components of, 392. 
See also incident response
enterprise information security baseline, 20, 22–3
enterprise risk assessment, 21
enterprise risk management (ERM)
integrated threat management (ITM) compared 
with, 5
mature security programs, 107
environmental changes, impact of, 357–8, 402
environmental metrics, 80
errors and omissions, 392
escalation, 166
espionage, industrial, 94
ethics handbook, 166
Ethics Review Board, 164
European Union (EU)
Data Protection Directives, 29, 34–7
Data Retention Laws, 380
incident notice laws, 32
security policy, 136
evaluation
importance of, 347–8
selection of integrated threat 
management (ITM), 11–3
sheets, 336
evaluation assurance levels (EALs), 235, 261
event, generally
correlation software, 187, 409
funneling, 407
logs/logging, 170–1, 398, 401
event-based authentication tokens, 148
evolutionary algorithms, 308
Evron, Gadi, 57
EWORM, 63
Excel ﬁ les, 33
executive management, 17
executive staﬀ , roles of, 19, 140
expert systems, 308
exploitation, 230–1
extensibility, 11, 17–8, 81
eXtensible Markup Language (XML)
applications, 213, 226
characteristics of, 210–1
encryption, 211, 215–8, 220, 225
extensions, 212
namespaces, 212
signature, 211, 213–6, 218, 220, 225
simple example, 211
tokens, 219–21
external customers, future challenges, 138–9
external groups, 52–9, 63–5
external information resources
conﬁ dentiality agreements, 58
law enforcement and, 58–9
membership organizations, 57–8
for public information, 52–7
extracellular matrix, 241
F
face-to-face meetings, 138
facsimile security
advantages of faxes, 275
classiﬁ cation labels, 279
conﬁ dential information, 284–5
conﬁ rmation page, 277
cover sheets, 276, 282, 286
designation, 275–6
encryption, 281, 284
fax logs, 280
Group 3 (G3) Facsimile Protocols, 274
hardware, 277–8
information resources, 275, 278
locations, 277, 280
machine repair, 2
misdirected faxes, 276
number conﬁ rmation, 276
passwords, 285
physical security, 283
policies, 278–86
RS-232 C connection, 278
secret information, 284–5
sensitive information, 281–2
software, 278
terminal equipment, 278
unencrypted lines, 283
vendors, listing of, 278
Faraday cages, 371
fault-tolerant computing, 370
faxes, see facsimile security
Federal Information System Controls Audit Manual 
(FISCAM), 383, 386
Federal Trade Commission (FTC), 31, 43, 301

422  Index
federated trust relationship, 224
feedback
importance of, 18, 114, 124–5, 351
loops, 107
strategies, 90
Fiddler, 51, 62
ﬁ eld challenges, 409–10
File Transfer Protocol (FTP) ﬁ les, 290
ﬁ ltering
conﬁ gurations, 103
information security management system, 17
integrated threat management (ITM), 4, 7
myths and facts, 411
spam, 302, 329
ﬁ nancial considerations
breach-related costs, 31, 181
capital costs, 9 
conﬁ guration costs, 341
cost of goods (COGs), 89
maintenance costs, 9 
operating costs, 100
privacy breach costs, 31–2, 44
ﬁ nancial industry, 266–7
ﬁ nancial management, 335, 337, 343, 345
ﬁ nancial reports, 254–5
ﬁ ngerprints, biometric technologies
matching, 156
recognition, 328
scans, 201
ﬁ rewalls
characteristics of, 4–5, 7–8, 10–1, 48, 97–8, 106, 
150, 182–4, 187–8, 239–41, 350, 407–8
logs, 51, 60–1
mature security programs, 100, 105
Microsoft Windows, 59
First Responder Examination of Compromised 
Machines, sample procedures, 66–70
ﬂ at organizations, 127–8
Flawﬁ nder, 234
ﬂ ee or ﬂ ight response, 111
ﬂ ow paths, 370
ﬂ ows property, 352
forecasting strategies, 74–5, 344
forensic(s)
analysis, 187, 291, 407, 409
applications, 40, 51, 139, 186
examinations, 59, 61, 65
forest and domain structure, accountability 
example, 168
formal organizations, 122
Foundation for Covert Channel Analysis, A, 234
fport, 186
fragmented local area networks (LANs), 412
fraud
ﬁ nancial reporting, 254–5, 381
privacy breach incidents, 33
Freedom of Information Act (FOIA), 34–7
front-end engineering, 140
function approximation, neural networks, 317–8
fuzzy logic, 308
fuzzy time, 234
G
Gallup surveys, 90
gap analysis, 87–8
gap junctions, 241, 243
Gateway Fax Systems, 27879
Gaussian waveform, 324
Gell-Mann, Murray, 358
general business risk, 257
General Electric (GE), 132
Generally Accepted Information Security 
Principles, 254
Generation X, 137–8
Generation Y, 137–8
genetic algorithms, 352, 354–5
Global Groups, 167
globalization, 138–9
Google, as information resource, 51, 62, 278
Google Hacking for Penetration Testers (Long), 62
governance
mature security programs, 107
organizational culture, 121, 126
types of, 255
Government Information Technology Infrastructure 
Management, 334
Gramm–Leach–Bliley Act (GLBA), 34–7, 
379, 392
Greatest generation, 137
group management strategies, 166
group network architecture, 195, 197
Group 3 (G3) Facsimile Protocols, 274
guard force
future plans, 85
regulatory considerations, 85–6
scope, 85
trends, 85
Guide to Understanding Covert Channel Analysis 
of Trusted Systems, A (NCSC-TG-30), 231, 234
H
hacker data, 68–9
hackers, strategies of, 30–1, 33, 98, 146, 149
hack-proof systems, 197
Handbook for the Computer Security Certiﬁ cation of 
Trusted Systems, 231
handler screening, 58

Index  423
hardware
characteristics of, 10
release management, 336
upgrades, 342
harm, 77–8
hash functions, 399
Health Insurance Portability and Accountability Act 
(HIPAA), 34–7, 379–80, 384, 386–7, 392
Hebbian, 316
Help Desk, 51, 408
heuristics/anomaly detection, 50
“holder of key,” 218
Holland, John, 357
Home Box Oﬃ  ce (HBO), 51
Homeland Security Presidential Directive HSPD-7, 380
homeland-security delays, privacy breach, 44
home oﬃ  ces, privacy incidents, 31
honeynets, 52, 61, 63, 66, 351
honeypots, 52, 61, 64, 66, 351
horizontal organizations, 120, 124–5, 127
host ﬁ rewall logs, 60
host systems, access to, 101
HttpsToken, 221
human resources, functions of, 18, 114, 413
Hypertext Markup Language (HTML), 298–9, 302
hypertext transfer protocol (HTTP/HTTPS), 4, 154, 
212, 226, 290–1, 300
I
identiﬁ cation
conﬁ guration management, 340
control frameworks, 382 
identity
federation, 221
management, 100, 107, 166–7, 245, 289
mapping, 224
theft, 146, 296–8, 303, 384–5
identity and access management (IAM), 150–1
IF/THEN statements, 353
impact analysis, 340
implementation
degree of, 24–5
domain-speciﬁ c, 23
enterprise security baseline, 20
information security life-cycle, 5
strategies, see implementation strategies
implementation strategies
department-level transformation, 89
roadblocks to, 17, 81
types of, 347
incident detection, 337
incident evaluation, 75
incident handling
enterprise incident response and digital evidence 
management, 391–403
goals, 41
mature security programs, 97–9, 101
incident management
characteristics of, 334–7, 340
life cycle, 340
privacy-related incidents, 30–3
incident response (IR)
applications, 105
cyber-forensics vs., 396–7
forensic readiness, 400–2
goals, 393
handling, 409–10
process model, 393–5, 402–3
incident response team, 40, 43, 101, 392
indirect brokered trust model, 224
inference attacks, 372
inﬁ ltrated.net, 56
informal organizations, 122–3
information
analysis, 357
classiﬁ cation, 369
disclosure, 225, 371
ﬂ ow, 231–4, 330
gathering, see data, collection methodologies; 
information gathering
legislation, see information law
processing, 74–5, 335
risk, 76, 94
information gathering
guidelines for, 66
strategies, 52
information law
compliance assurance, 377–88
incident handling, enterprise response and digital 
evidence management and handling, 391–403
security information management myths and facts, 
405–13
information security domains, 20
Information Security Forum (ISF), 262–3
information security life cycle, 4–5, 11, 13, 394–5
information security management system (ISMS)
beneﬁ ts of, 17 
characteristics of, 245–9
development of, 20–4
focus of, 24
historical perspectives, 16
location of, 20
participants in, 19
protection, degrees of, 24–5 
reference model, 250
Information Security Program, 25 
information sharing and analysis centers 
(ISACs), 51–2
information-sharing partners, 17

424  Index
Information Systems Audit and Control Association 
(ISACA), 94, 260, 387
information technology (IT)
future challenges, 139–140
governance, 9, 255, 267–8
hierarchy, 97
infrastructure, 93
ISO standards, 245
neural network distinguished from, 309
organizational culture and, 126
personnel training, 102
service management, 250
support personnel, 6 
Information Technology Infrastructure Library (ITIL®)
applications, 263
deﬁ ned, 334, 379, 381–2, 386
history of, 334–5
InfoSec management, 19, 255, 259
infrastructure mapping, 341
ingress points, 247
insider attacks, 374
installation, ease of, 11
instant messaging, 4, 239, 241
insurance coverage, 141
integrated threat management (ITM)
architectures, 5
characteristics of, 4–9
console components, 7–10
deﬁ ned, 3–4, 16
evaluation of solution, 11–2
life cycle, 5, 11, 13
network diagram, 5–6
pros and cons of solutions, 9–11
size of business, signiﬁ cance of, 13
software-only platform, 10
system selection, inﬂ uential factors, 8, 10–3
typical solution, 6–7
integrity, 217, 220, 225–6, 258, 275, 345, 399
intel markers, 51, 63
intellectual property, 101
intelligence
artiﬁ cial, see artiﬁ cial intelligence (AI)
community, Direction of Central Intelligence 
Directive 6/3, 262
gathering, 51
markers, 59, 63–5
internal audit, 101
internal information sources
applications for information, 59, 63–5
log ﬁ les, 59
internal organization, cell biology vs. computer 
networks, 239, 241–2
Internal Revenue Service (IRS), 297, 380
International Committee for Information Technology 
Standards (ICITS), 245
International Electronics Consortium (IEC), 245
International Electrotechnical Commission (IEC), 382
International Organization for Standarization (ISO)
certiﬁ cation, 251–2
functions of, 245
see also speciﬁ c ISO standards
Internet Crime Complaint Center (IC3), 56–8
Internet key exchange (IKE), 194, 197
Internet messenger, 64
Internet Perils, 65
Internet Protocol (IP), 150, 197
Internet Protocol version 6 (IPv6), 239, 242–3
Internet Security Alliance, 58
Internet Security Operations Task Force 
(ISOTF), 51, 57
Internet Service Provider (ISP), 43, 55, 57, 60, 
65, 300, 302
interviews, cultural assessment
beneﬁ ts of, 114
guidelines for, 116
results interpretation, 118–9
structure of, 118
subjects, selection factors, 117
intrusion detection system (IDS)
anomaly-based, 370
characteristics of, 4, 39, 239–41, 243, 289, 328, 350
host-based, 186–7 
mature security programs, 100
network-based, 178, 187
neural networks, 329–30
intrusion detection system (IDS)/intrusion prevention 
system (IPS) packages
characteristics of, 60
historical perspectives, 48
logs, 60, 407
mature security programs, 106
intrusion prevention system (IPS), 4, 178, 187, 289. See 
also intrusion detection system (IDS)/intrusion 
prevention system (IPS) packages
investigation, privacy breach, 44
IOS (Cisco), 407
IPSec 
network overlay, 197
protocol, 184 
IPSec/IKE architecture, 195, 197
iris recognition, 156, 329
Ising model, 364
ISO standards
15408, 261
17799, 136, 245–6, 252, 379, 382, 386
ISO 2000, 250
27000 series standards, 249–52, 260
27001, 251
27002, 245–50
27003, 246, 250
27004, 250
27005, 250

Index  425
27006, 250
9000, 261
9001, 246
ISO/IEC
17799, 245, 382–3
21000, 220
27000, 383
27001, 245–6
ISO 27001
Annex A, 246, 248
certiﬁ cation, 17–8, 25
content of, 102, 106, 245–9, 251
IssuedToken, 221
IT Governance Institute®, 94
ITS4, 234
ITU (International Telecommunications Union), 274
J
Java, 381
Java J2EE, 224–5
JavaScript, 298–9
Jaynes, Jeremy, 65
Jerusalem virus, 50
job descriptions, 166
JPEG format, 234
jurisdiction, 40
K
Kerberos, 184, 218–9, 221, 224–5, 227
KerberosToken, 221
kernel-mode rootkits, 178–9, 183
key authority point (KAP), 196
keyboard dynamics, 156
key exchange techniques, 216
keylogging, 154–6, 160
key management, encryption security 
architecture, 195–6
keystroke loggers, 178, 182, 299
knee jerk reactions, 111
L
LACNIC, 56
LANDesk Manager, 62
language, organizational culture and, 129
laptop computers, privacy breach, 31
large-scale networks
deployment of encryption key management, 193–8
load balancing, 192–3
multicast, 193
multi-protocol label switching, 193
performance, 192
redundancy, 192, 194–5, 197
simulations, 374
large-sized businesses, 13
Laudanski, Paul, 55
law enforcement, 44, 59
lawyer-client conﬁ dentiality, 399
leadership
future challenges for, 140
organizational culture and, 124–6, 128, 131
perceptions of, 120
security policies and, 136–7
leak prevention, 289–92
learned avoidance, 351
learned responses, 111–2
learning 
algorithm, 309
competitive, 316–7
process, 350–1, 358
rate, neural networks, 322, 327
through internal models, 352
least path problem, 364
least privilege principle, 182–3, 226
legal action, 187. See also litigation
legal constraints, buy-ins, 140–1
legal regulations, 18. See legislation; regulatory 
compliance
legislation
Children’s Online Privacy Protection Act 
(COPPA), 34–7
Drivers Privacy Protection Act, 34–7
Federal Information Systems Management Act 
(FISMA), 261–2, 379–80, 384
Financial Services Moderation Act of 1999, 379
Foreign Corrupt Practices Act, 267
Freedom of Information Act (FOIA), 34–7
Gramm–Leach–Bliley Act (GLBA), 34–7, 379, 392
Health Insurance Portability and Accountability Act 
(HIPAA), 34–7, 379–80, 384, 386–7, 392
Patriot Act, 136
Privacy Act of 1974, 34–7
Real ID Act, 136
Sarbanes–Oxley Act, 202, 251, 257, 260, 267, 379, 
381, 384, 392, 407
security breach notiﬁ cation, 380
licensing, 8–10, 341
life-cycle management, 341
Linux systems, 177–8, 184, 186, 277, 407
litigation, 384–5, 392
load balancing, 197
local area networks, 280
log aggregation, 407–8
Logcaster, 170
log data sources, 187

426  Index
log ﬁ les, digital evidence, 397–8
logging, 10, 167, 172
logical boundaries, 247
log-ins, 104, 299–300, 303
log management, see speciﬁ c types of logs
evidence handling, 401
importance of, 394, 407
normalization of, 407
lossy protocols, 234
loyalty, in organizational culture, 122, 124
M
Macintosh File System, 180
mainframes, 407
maintenance
costs, 9
information security life-cycle, 5–6
signiﬁ cance of, 348
makeﬁ les, 185
malicious code, 48, 63, 186, 188
malware
“all-in-one,” 188
analysis of, 52, 373
characteristics of, 98
comparison of, 179
detection, mature security programs, 103
identiﬁ cation of, 60
impact of, 91
intelligence data categories used against, 49–51
outbreaks, 99
managed security services (MSS), historical 
perspectives, 49
management
information security life-cycle, 5
layer, encryption security architecture, 195–6
support from, 95, 97, 99–100
management and policy server (MAP), 196
managerial commitment, signiﬁ cance of, 262
managerial roles and responsibilities, 88, 247. 
See also speciﬁ c levels of management
mandatory controls, 78
Manifest, XML signature, 214 
man-in-the-middle (MITM) attack, 150, 213, 297, 
299–300, 366
mantraps, 201–2
maturity
degree of, 24–5
levels of, see maturity levels of security program 
modeling, 80
risk treatment, 80
maturity levels of security program
assessment questions, 95–7
characteristics of, 97–102
level 1, 97–8, 103–4
level 2, 98–9, 104–5
level 3, 100–1, 105–7
level 4, 101–2, 107
signiﬁ cance of, 94–5, 107
McAfee, 181
measuring, see metrics
media, security breaches, 136
medical information/records, 30, 230
medium-sized businesses, 13
memory-resident rootkits, 177
message
ﬁ ltering, 411
injection, 225
queuing systems, 212
replay, 225
tampering, 225
Message Digest algorithm version 5 (MD5), 186
metadata analysis, 213, 224
methodologies, overview of, 22–3
metrics
collection and analysis of, 18
compliance, 387
development of, 8
environmental, 24
implementation of, 336
mature security programs, 107
operational, 79
privacy breach, 44
process, 24
program, 24
risk, 79–80
Microsoft 
Internet Explorer, 180, 302
“Kernel Patch Protection/PatchGuard,” 182
management console (MMC), Active Directory 
Domains and Trust, 168
.NET platform, 224–5
Passport, 31
PatchGuard, 182
Strider program, 62
Windows, 104, 164, 167–8, 170, 177, 180, 184, 186, 
277, 290, 406–7, 411
Word ﬁ les, 33
middle management, roles of, 114, 387
military
Defense Information Technology Systems 
Certiﬁ cation and Accreditation Process, 262
organizational structure, 125, 262 
MIL-STD-188–161D, 277
mimicry, 351–2
MLC & Associates, 121
mobile code, 381
mobile storage devices, privacy breach, 31
Modelchecking Programs for Security Properties 
(MOPS), 234
momentum, neural networks, 327

Index  427
monitoring
capacity management, 344
compliance, 100
consent to, 166
digital evidence, 401
documentation of, 8–9
mature security programs, 100
rootkit attacks, 187–8
signiﬁ cance of, 24–5, 337, 394
Moore’s Law, 231, 365
“most privilege” strategy, 167
Motion Picture Experts Group (MPEG), 234
Mozilla Firefox, 180
MP3 technology, 234
MPEG-21 license, 220
multicast architecture, 195, 197
multilayered security, 242
multivendor devices, 197
multiyear work plan, 89
muster feature, turnstile systems, 205–6
mutation, 352, 354–5
MySpace, 297
N
naming conventions, accountability strategies, 169–70
National Committee on Fraudulent Financial 
Reporting, 381
National Consumers League Anti-Phishing 
Retreat, 301
National Cyber-Forensics and Training Alliance 
(NCFTA), 57–8
National Information Assurance Certiﬁ cation and 
Accreditation Process, 262
National Institute of Standards and Technology (NIST)
functions of, 104, 254, 261, 265–6, 379, 386, 400–1
NIST 800–26, 254, 266
NIST 800–53, 379
NIST-SP800/86 Guideline, 400
national policy, 136
National Security Agency Security Conﬁ guration 
Guides, 384
National White Collar Crime Center (NVW3), 56
NATO AMSG720B, 277
NATO STANAG 5000, 277
natural disasters, 140, 225, 352
negotiations, types of, 9, 141, 341, 343, 366
nesting groups, accountability strategies, 169
NetWare, 277
network(s)
design, 98
forensics, 291, 395
internal, 357
intrusion attempts, 100
layer, 290
monitoring, rootkit detection, 187–8
topology, 412
traﬃ  c, anomaly detection, 60
Network for Education and Research in Oregon, 51
networking quantum computing, 374
neural nets, 373
neural network analysis, quantum computing, 373
neural networks, artiﬁ cial
algorithms, 313
application controls, 321–2
architectures, 309, 311–3
capabilities, 317–8
characterized, 308–9, 330
classiﬁ cation, 317, 322, 326, 329
demonstrated usage, 322–8
functional characteristics, 314–5, 317
Gaussian test sets, 327
generated, 325–6
hidden layers, 312
implementation planning, 318
inspiration for, 309–11
learning concept, 313, 315–7, 322
linear categorization, 314–5
local minima, 320–1
multilayer, 312–3
neurons, biological vs. artiﬁ cial, 310
nonlinear categorization, 315
potential applications, 330
prediction, 328
sawtooth test sets, 327
security-relevant applications, 328–30
sine test sets, 326
single-layer, 310–1
training, 316, 318–21
vulnerabilities, 318
neurons, biological, 310
New Device Certiﬁ cation Form (NDCF), 413
news media, breach notiﬁ cation, 43
noise, quantum computing, 368, 370
nonpersistent rootkits, 177, 187
notebooks, 197
notiﬁ cations
external group, 51
legislation, 380
privacy breach, 41–4
NSA NSTISSAM 1–92 TEMPEST Level 1, 277
nuclear power industry, 242
O
Object, XML signature, 214–5
Oﬃ  ce of Government Commerce, 334
Oﬃ  ce of Management and Budget Circular A-123, 380

428  Index
onetime-password authentication token, 148–9, 151, 
156, 158
online banking, 154–5
open-source organizations, 60
open systems interconnection (OSI), 229
operating costs, 100
operating system 
proprietary, 407 
release management, 343
rootkit attacks, 178–9, 182
types of, 10
updates to, 8, 10
Operationally Critical Th reat, Asset, and Vulnerability 
Evaluation (OCTAVE), 266
operational metrics, 79
operational risk
assessment, 23–4, 75
deﬁ ned, 73
operation level arrangements (OLAs), 348
operations management, 19 
operations security, 374
optical turnstiles, 203–5
organic communication channels, 51
organizational challenges
buy-in, 140–2
communications, 140–2
external customers, 136, 138–9
security policy, 136–7
workforce, 136–8
organizational change, see change management
organizational culture
alignment with, 110, 124, 127, 130–1
archetypes, deﬁ ned, 123
assessment methodologies, 116–20
assessment of, 113
blended archetypes, 125–8
changes in, 131–2
classiﬁ cation system for, 113, 120–1
ﬂ at organizations, 127–8
formal organization, 122
horizontal archetype, 120, 124–5, 127
informal organization, 122–3
managerial eﬀ ectiveness, 127
organizational imperative, 121
organizational policies, enforcement of, 128–9
psychological contract, 120–2, 126
response learning process, 111–2
selling assessment, 113–6
signiﬁ cance of, 110, 126–7, 130–2
strategy development, 130
strategy linked to, 127–9
vertical archetype, 118, 120, 123–4, 
126–8, 132
organizational hierarchy, 125–6
organizational law, formal written policy, 128
organizational policies, contents of, 128
Organization for Economic Cooperation and 
Development (OECD), 136
Ourmon, 51, 63–4
overarching ISMS, 18
overgeneralization, 313
oversight policy, 140
overt internal model, 352, 355
overtraining, neural networks, 319–21
ownership, 123, 148, 159, 337, 345
P
packets, 7, 240, 242, 409
palmtops, 139
panic-driven responses, 99
parallel forensics processing, 409
partnerships, 17, 140–2
password(s)
compromise of, 33
covert channels, 232
hash, 147, 154–5
importance of, 61, 63, 98, 146
log-ons, 303 
WS-Security, 219
password-cracking
attacks, 176
tools, 146–7
password-guessing attack, 155, 160
patch management, 8, 80, 98–9, 104, 150, 182–4, 
303, 343
Patriot Act, 136
pattern matching and recognition, 317, 373–4
Payment Card Industry Data Security 
Standard (PCI), 379
PayPal, 297
PCI Data Standards Council, 379
PDCA (Plan, Do, Check, Act) cycle, 20, 249, 
260, 346
peer-to-peer relationships, 195, 290
penalties, for noncompliance, 384–5, 387
penetration testing, 185, 224, 386
perceived threats, 110
performance analysis, 10, 75
performance measurement, 89–91
permissions systems, accountability, 166–70, 172
perpetrators, 176, 230. See also hackers
persistent rootkits, 177
personal digital assistants (PDAs), 31, 197
personal identiﬁ cation number (PIN), 147–9, 
156–7, 160
Personal Information Protection and Electronic 
Documents Act (PIPEDA), 34–7
personally identiﬁ able information (PII)
deﬁ ned, 30

Index  429
determination of, 33
inventory of, 33
laws deﬁ ning, 34–7
location of, 33, 39
privacy breach incidents, 30–1
unauthorized use of, 32
PGP keys, 216
Pharmamaster, 65
phentermine site, 62
phishing
attacks, types of, 57, 299–300
cluster, 65
consumer education, 301
current activities, 297–8
deﬁ ned, 296
delivery mechanisms, 298–9
evolution of, 297
impact of, 4, 51, 54, 155, 160
information resources, 303
sites, listing of, 55
technical approaches to, 302–3
URL obfuscation attacks, 300–1
phishing incident response and 
termination (PIRT) 
database, 51, 54–5, 57
phpBB sites, 62
physical attacks, impact of, 156, 158
physical boundaries, 247
physical evidence, 397
physical security 
facsimiles, 283
importance of, 18
mantraps, 201–2
quantum computing, 371–2
turnstiles, 202–6
types of, 140
physical tokens, 158–9
Plan, PDCA model, 20, 249, 
260, 346–7
planning, conﬁ guration management, 340
policing functions, 113, 127
policy, enforcement point (PEP), 195–7. 
See also security policies
political climate, organizational culture, 126
pop-ups, 298–9, 302
postchange review, 340
potential intelligence markers, 59
power, signiﬁ cance of, 126
power law, 356
power outages, 140
prediction neural network, 327–8
printers, 197
priority-setting in security program, 93–108
privacy
breach of, see privacy breach; privacy breach plan
directives, 141
signiﬁ cance of, 245
privacy breach 
breach notiﬁ cation, 41–4 
cost of incidents, 31
importance of, 29–30
incident handling goals, 41
location of PII, 33, 39
notice laws, 32, 42, 44
notiﬁ cation, 42–4
plan, see privacy breach plan
prevalence of, 31–2 
types of incidents, 30–3
privacy breach plan
as preventive strategy, 32
components of, 32
creation strategies, 33, 39–41
determination of PII, 33
eﬀ ective planning, 40–1
recovery, 44
testing, 41
Privacy Rights Clearinghouse (PRC), 31
private key authentication, 158
private network security collaborations, 53
proactive approach, 239, 243
problem
analysis, quantum computing, 372
management, 334–40
procedures 
creation of, 23
diagrams, 336
requirements, 8
process-based ISMS system, 19–20, 81
process improvement strategies, 94
processing capability, 6
process metrics, 79
productivity, 340
product road map, 11
program management team, 115, 130
program metrics, 80
programming, secure methods, 99
program risk, assessment of, 22
prophylactic measure, 182
propietary data, 409
proprietary solutions, 7
protection assertions, 220
protection proﬁ le (PP), 261
proximity, 201
proxy-based ﬁ rewalls, 183–4
pseudonyms, 218, 223–4
pseudorandom identiﬁ ers, 218
psychological assessment, 113–6
psychological contracts, 120–2, 126
public image, 141
public information resources, 52–7
public-key cryptography, 216, 226
public key infrastructure (PKI), 107, 158, 184

430  Index
Q
qualitative risk quantiﬁ cation, 76
Quality Circle of Deming, 346
quality management, 383
quality of service, 336
quality standards, 261. See also International 
Organization for Standardization (ISO)
quantiﬁ ed risk, 75
quantum computing
access control, 370
analog, 367–8
applications security, 372–3
business continuity planning, 372, 374
characteristics of, 362
concepts, 362–3
cryptography, 370–1
diﬃ  cult problems, 363–4
encryption, 364–7
investigation, 374
law and, 374
operations security, 374
physical security, 371–2
security architecture applications, 369–70
security management applications, 368–9
telecommunications and networking, 374
quantum mechanics, 362–3
quantum registers, 365
quarantine, 51
quasi-intelligence organizations
antivirus (A/V) products, 48–9, 51, 66–70
counterintelligence, 65–6
external groups, 52–9, 63–5
internal sources, 59–62
information gathering strategies, 52
queries, types of, 6, 54
query language, XML, 212
questionnaires, 114, 119
R
RACI (Responsible, Accountable, Consulted, 
Informed) diagrams, 247
radiofrequency identiﬁ cation, 139
rainbow tables, 146, 155
random-access memory (RAM), 398, 402
raw risk, 77
Rbot, 63
Real Secure, 60
real-time
analysis, 407–8
network scanning, 184
transmission protocol (RTP), 356–7
rearchitecting, 9
reasonable expectation of privacy (REP), 398
Recording Industry Association of America (RIAA), 51
recordkeeping, ISO standards, 249
recovery
incident management process, 337
plans, 102, 346
quantum computing applications, 372
rootkits, 188
recycling eﬀ ects, 352
redirection, 179
Red Siren, 58
redundant network architecture, 192, 194–5, 
197, 342, 345
reﬂ exive reactions, 111
registrar operators (Reg-Ops), 57
regulations
buy-ins, 140–1
compliance with, see regulatory compliance
requirements, 21
regulatory compliance
importance of, 17, 25, 74, 101, 136, 138, 
251, 341, 392
mature security programs, 106
requirements, 94
re-imaging, 66
relationship-building, 103
release management, 334–7, 341–3
RelToken, 221
remediation, 166, 387
remote access, 147–8, 181
remote desktop protocol (RDP), 49
remote procedure call (RPC), 212
repeatability, 81, 337
reporting
accountability infractions, 167
automated, 101
central, 51
ﬁ nancial, 254–5, 381
information security life-cycle, 5
information security management 
system (ISMS), 17
mature security programs, 107
privacy breaches, 41
types of, 25
reports
community, 51
contents of, 8
custom, 11
fraudulent, 254–5, 381
generation of, 8
sources of, 41
types of, 7
repositories, 100
reproduction process, 355
request for change (RFC), 337–8, 348
RequestSecurityToken, 221

Index  431
Research and Education Networking-Information 
Sharing and Analysis Center (REN-ISAC), 
51–3, 58
residual risk, 78, 80
resolution, see solution
ﬁ rst-call, 336
incident management process, 337
resource capacity management (RCM), 344
resource-driven risk, 23
resources, acceptable uses of, 166
response time, improvement strategies, 336. 
See also incident response
responsibility matrices, 247
restorability, 99
restoration of service, 44, 337
restructuring, 131–2
retail industry, loss prevention departments, 89
retinal scans, 201
return on investment (ROI), 278, 345
reverse engineering, 149, 158
revolving doors, 203, 205–6
Ricoh SecureFax, 278
rights expression language (REL) token , 220
RIPE, 56
risk
acceptance, 20, 25, 77, 100
analysis, 18, 345–6
assessment, see risk assessment 
avoidance, 77
environment, evaluation of, 94
management of, see risk management
mitigation, 73, 78, 94, 150, 154, 226, 292
nature of, 72–3
perceptions of, 112–3
quantum, 76
rating, 18
reduction strategies, 136, 141
tolerance, 77, 136
transfer, 77
risk assessment
components of, 20, 206, 224, 368
harm, 77–81
probability, 76
scope, 75–6
risk-based ISMS, 18, 25
risk-beneﬁ t analysis, 233
risk management
characteristics of, 16, 114, 395
control objectives, 78
department-level transformation, 83–93
future challenges in, 135–42
organizational culture, impact of, 109–32
priority-setting, 93–108
risk treatment, 78–9
security framework, 257
using process approach, 71–83
using quasi-intelligence resources, 47–70
risk metrics
environmental metrics, 80
process metrics, 79
program metrics, 80
risk-taking behavior, 126
Rivest–Shamir–Adleman (RSA) algorithm, 158, 370
robotics, 308
role-based authorization, 224
Rootkit Revealer, 186–7
rootkits
authentication, 182, 184
backdoor access, 177, 181, 188
backdoor mechanisms, 178
botnets and, 181
breach-related costs, 181
characteristics of, 177, 397
compared with malware, 179
compilers, limitations on, 182, 185
deﬁ ned, 177
detection of, 185–7
eradication of, 187–8
ﬁ rewalls, 182–4
hiding mechanisms, 177–8
historical perspective, 188
incident responses, 185–8
installation of, 180
least privilege principle, 182–3
loggers, keystroke and terminal, 178, 182
mechanics of, 177–8
overview of, 176
prevention strategies, 182–5, 188
recovery, 188
security maintenance, 182, 184–5
self-reproducing, 179–80
system conﬁ guration, 183
types of, 178–9
vendor-installed, 180–1
victim systems, 177–8
Rough Auditing Tool for Security (RATS), 234
routers, 106, 187, 239–40, 242–3, 408
routing
cell biology vs. computer networks, 239, 242–3
protocols, 352
rule discovery, 354
S
SamlToken, 221
sandbox technology, 61
SANS Institute, 379, 384
Sarbanes–Oxley Act, 202, 251, 257, 260, 267, 379, 381, 
384, 392, 407
sawtooth waveform, 323

432  Index
SB 1386, 34–7
scalability, 197–8
scanners, types of, 106, 156
scanning protocols, 61, 66
scenario planning, 102
scoring
organizational culture surveys, 120
reputation, 151
screening process, 10
Second Report from the Basel Committee on Banking 
Supervision, Risk Management Principles for 
Electronic Banking, see Basel II
SecureConversationToken, 221
Secure Hash Algorithm version 1 (SHA1), 186
Secure Programming Lint (SPLINT), 234
secure shell (SSH) connection programs, 178–9, 291
Secure Sockets Layer (SSL), 211, 224, 226, 240, 291
Securities Exchange Commission, 382
securities industry, 266–7
security architecture and design
covert channels, analysis of, 229–35
defense-in-depth example, biological cells compared 
with computer networks, 237–44
ISO standards draft content, 245–52
security frameworks, 253–69
service-oriented architecture (SOA), 209–11, 225–7
web services-security, 211–27
security assertion markup language (SAML), 217–8, 
222, 224–5, 227
security audit logs, 60
security-binding assertions, 221
security breach, discovery of, 112
Security Compliance Council, 378
SecurityContextToken, 221
security event management (SEM) system, 7, 100, 106, 
184, 187, 406
security frameworks
breakdown framework, 255–6
British Standard (BS) 7799, 254, 259–60, 383
checklist format, 255–6
Common Criteria (CC), 254, 261
Control Objectives for Infromation and Related 
Technology (COBIT), 254, 260, 267, 382
controls, 256–7, 262
description of, 258–69
governance, 255, 267–8
information resources, 256, 265–6
Information Security Forum (ISF), 262–3
Information Technology Infrastructure Library 
(ITIL®), 263
ISO 17799, 259, 379
ISO 27000, 254, 260
ISO 27001, 259
ISO 27002, 259
legislation, 254, 261–2
management frameworks, 263–265
National Institute of Standards and Technology 
(NIST), 254, 261, 265–6, 400
Operationally Critical Th reat, Asset, and 
Vulnerability Evaluation (OCTAVE), 266
securities and ﬁ nancial industries framework, 266–7
Systems Security Engineering Capability Maturity 
Model (SSE-CMM), 268
taxonomy, 257
types and diﬀ erences, 254–5
weaknesses, types of, 258
security functionality, 243
security information management (SIM)
agent coverage, 411
background, 406–7
challenges of, 410–2
characteristics of, 289, 406
centralized management, 408
correlated events, 408–9
deployment tips, 410, 412–3
event ﬁ ltering, 411–2
forensics analysis, 407, 409
incident response handling, 409–10
log aggregation, 407–8
motivation, 406
real-time analysis, 407–8
rules, 411
terminology, 407
security infrastructure, mature security programs, 96, 
98–100
security integration, mature security programs, 95, 97, 
99–100
security logs, 61
security management
concepts, see security management concepts
deﬁ ned, 335
information technology infrastructure library (ITL), 
333–48
process, see security management process
security management concepts
information security management systems, overview 
of, 15–25
integrated threat management (ITM), 3–14
security management process
control, 347
evaluation, 347–8
framework for, 346–7
implementation, 347
maintenance, 348
plan, 347
security operations center, 102
security personnel
mature security programs, 96, 98–100
perceptions of, 113–4
security policies
future challenges, 136–7
mature security programs, 96, 98, 100

Index  433
requirements, 8–9
violations, 290–1
security proﬁ le, 20
security strategy, mature security programs, 106
security target (ST), 261
security team, mature security programs, 103
security testing, 102
security token service (STS), 221–3
self-governance, 166
self-organized learning, 316
self-reproducing rootkits, 179–80
sender vouches, 218
senior management
mature security programs, 99–102
roles of, 8, 114, 116, 124, 130
service availability, 225–6
service catalog, 343
service continuity management (SCM), 334–5, 337, 
343, 346
service contract, 213
service delivery
availability management, 335, 337, 343, 345
capacity management, 335, 337, 343–5
ﬁ nancial management, 335, 337, 343, 345
service continuity management (SCM), 334–5, 337, 
343, 346
service level management (SLM), 334–5, 337, 343–4
service desk, 335–6, 342, 344
service level arrangements (SLAs), 340, 344, 346–8
service level management (SLM), 334–5, 337, 343–4
service level requirements (SLRs), 344
service-oriented architecture (SOA)
characteristics of, 209–11, 219, 227
threats to, 225–6
service support functions
change management, 334–5, 337, 340
conﬁ guration management, 334–7, 340–1
incident management, 334–7, 340
overview of, 335–6
problem management, 334–40
release management, 334–7, 341–3
service desk, 334–7, 342, 344
service tickets (ST), 220
session ID, 301
session initiation protocol, 11
Shadowserver, 51, 53–54, 57
shared key, XML encryption, 184, 216
shared secret
authentication factor, 154, 156–7
keys, 222
shareholder value, 94
Shor, Peter W., 367
signature
attack, 289
biometrics, 156
detection evasion, 186
digital, 218
handwritten, 329
IDS/IPS packages, 60
incident detection system (IDS), 52, 66 
up-to-date, 150
viruses, 48–50
XML, 211, 213–5
SignatureValue, XML signature, 214
SignedInfo, XML signature, 214
silos, organizational culture, 117
Simple Mail Transfer Protocol (SMTP), 298
simple object access protocol (SOAP), 212–3, 
218–21, 226
simplicity, 226
simulations
business continuity planning, 372
quantum, 374
sine waveform, 323
S/KEY password, 220
skill set assessment, 336
slide rule, 368
sliding window technique, 325
small-sized businesses, 13
smart-card technology, 139, 158–60, 201
“Snail, Th e,” 168–9
Snort, 51, 54, 60
social engineering, 128, 150, 155, 180
Social Security Numbers (SSNs), privacy breach 
incidents, 31–2
software engineering, 94
Solaris, 407
“something you are” authentication factor, 156, 160
“something you have” authentication factor, 156
“something you know” authentication factor, 
154–6, 160
Sony BMG, rootkit case illustration, 180–1
South America, security regulations, 136
Spaﬀ ord, Eugene, 258
spaghetti computer, 367–8
spam
characteristics of, 298–9, 301–2
classiﬁ cation of, 330
detection, 328
ﬁ ltering, 329
neural networks, 330
relays, 51
Spamhaus, 56
spammer, infrastructure of, 62
spear-phishing, 299
speciﬁ cations, creation of, 23
SPKI keys, 216
SpnegoContextToken, 221
spreadsheet applications, 368
spyware, 180. See also antispyware software
SRI Quality System Registrar, 251
staﬃ  ng, 387

434  Index
standard operating procedures (SOPs), 23, 276, 278
standards-based ISMS, 18
standards requirements, 8
Stanford Checker (MC), 234
state attorney general, breach notiﬁ cation, 42–3
state breach notiﬁ cation laws, 42
static passwords, 154–5, 160
status accounting, conﬁ guration management, 340
STE (secure terminal equipment), 278
steering committee, 115–6, 130
steganography, 234
stewardship, 343
stolen computers, incidence of, 30–2
storage capacity, 11
Storm-Worm, 63
strategic goals, 115, 119, 121, 141
strategic planning, importance of, 106, 135–7
strategic risk
assesment, 75
deﬁ ne, 72–3
strategic vision, 84–7
streaming video, real-time transmission protocol, 356–7
structure, information security program, 18–9
Structure Query Language (SQL), 60, 212
STS/IP, 222–3
subscription fee, 302
Sun Microsystems, 183
superconductivity, 362, 364
superposition, 363, 367
superuser privileges, 177, 181–3, 187
supervision, perceptions of, 114
suppliers, service level management, 343
support, types of, 11
surveys 
culture assessment, 118–20
customer service, 90
employee satisfaction, 91
swarm intelligence, 308
switches, 106, 408
Symantec Anti-Virus (SAV), 63
symmetric cryptography, 222
symmetric encryption keys, 216
synchronous authentication tokens, 148–9
system development life cycle (SDLC), mature security 
programs, 95, 97, 99–100, 104, 106
system ﬁ le checker (SFC), 50
system libraries, rootkit attacks, 178–9
Systems Security Engineering Capability Maturity 
Model (SSE-CMM), 268
T
tacit internal model, 352
tactical risk
assessment, 75 
-based ISMS, 73
deﬁ ned, 73
tailgating, 129, 201–2, 206
tasks, creation of, 23
TCC CSD 3700, 278
team-based organizations, 125
Team CYMRU, 55–6
technological advances
impact of, 125, 136
types of, 139
telecommunications
content ﬁ ltering and leak prevention, 289–92
facsimile security, 273–86
network attacks, phishing, 295–303 
quantum computing, 374
telecommuting, 137–8
TEMPEST, 277–8, 371
terabyte (TB), 399
terminal loggers, 178, 182
termination procedures, 204
terminology, standardized, 18, 21
test sets, neural networks, 321, 326
theft, 30–1, 89
thematic analysis, 118
thermal face imaging, 329
third-party integration, 5
third-party-issued tokens, 221
Th omas, Rob, 55–6
threat(s)
accountability strategies, 172
analogies, 240
analysis, 224–5
detection of, 8
forecasting, 74–5 
internal, 241 
perceived, 110
sensors, types of, 74
social engineering, 128
tree, 76
threat and vulnerability management 
(TVM), mature security programs, 
96, 98–100, 102
three-tier encryption security architecture, 196–8
ticket granting tickets (TGT), 220
time stamps, 221
timing channel, 230
Tivoli, 186
token
assertions, 221
authentication, see authentication tokens
substitution, 226
toll-free telephone lines, privacy breach plans, 40
top-down organizations, 127
total control, deﬁ ned, 201
total quality management (TQM), 16, 132
toxic waste management, 140

Index  435
tracking, 336–7
trade secrets, 399
traditional turnstiles, 203–6
traﬃ  c
encrypted, 290
logs, 103
pattern identiﬁ cation, 329
peer-to-peer, 290
prioritizing, 6
screening, 10
Voice-over-IP (VoIP), 11
vulnerabilities, 197
training
conduct, 386
evaluation sheets, 336
integrated security management system, 13
sets, neural networks, 321
transactional trust, 296
transaction records, 398
transformation, department-level
business case, 88
department performance measurement, 89–91
gap analysis, 87–8
implementation, 89
signiﬁ cance of, 83–4, 91–2
strategic vision, 84–7
worker engagement, 90–1 
Transmission Control Protocol (TCP), 63, 226, 409
Transportation Security Authority (TSA)
data ﬂ ow diagrams, 38
privacy breach incidents, 33, 39
Transport Layer Security, 197, 224
traveling salesman problem, 364
travel web sites, 217
Treadway Commission, 254, 267, 379, 381
trend analysis, 336, 341
trial and error, 354–5
Triple-Data Encryption Standard (DES), 216, 232
Tripwire, 50, 184, 186
Trojan horse programs, 7, 176–7, 179–80, 187, 299
troubleshooting, 341, 374
trouble tickets, 8
trust
relationships, 211, 221
scenarios, 223
tunneling protocols, 239–240
Turing model, 373
Turkey, security regulations, 136
turnstiles, 202–6
two-factor authentication, 156–7
U
Ulysses, covert channel example, 230–1
uncensored events, 52
uncertainty, 130
undertraining, neural networks, 319–20
Unicenter TNG, 186
uniform resource identiﬁ er (URI), 214–6
uniform resource locator (URL), 4, 213, 297, 300
United Kingdom
Accreditation Service, 251
Data Protection Act, 335, 379–80
Universal Description, Discovery, and Integration 
(UDDI), 213, 218, 225
universal resource locator (URL)
list ﬁ ltering, 302
obfuscation attacks, 300–1
phishing, 290, 298–9
UNIX systems, 177–8, 184, 186, 277, 406, 411
unstructured data, 33
unsupervised learning, 316
updates
information security life-cycle, 5
importance of, 10
privacy breach plans, 40, 44
system-level, 11
user accounts
centralized, 107
management of, see account management
provisioning, 10
User Datagram Protocol (UDP), 64 
user ID, 61, 217–8
user-mode rootkits, 178–9
username tokens, 219–21, 224
UTF-8, 301
V
validation
authentication tokens, 151
sets, neural networks, 321
third-party, 17
WS-Federation, 223
value assignment, 353–4
vanity passwords, 146
VBscript, 381
Venali, 278
vendor queries, 6
veriﬁ cation, conﬁ guration management, 341
vertical organizations, 118, 120, 123–4, 126–8, 
132, 378
vetting process, 63
video surveillance, 206
virtual local area networks, 247
virtual network computing (VNC), 49
virtual private networks (VPNs), 4–5, 7, 10, 105, 
239–41
Virtual Router Redundancy Protocol, 411

436  Index
virus.comp, 50
viruses
adaptation and, 357
characterized, 48, 176, 187
removal tools, 50
Virus-L, 50
Voice-over-IP (VoIP), 11, 13, 301
vulnerability/vulnerabilities 
assessment, 104–5, 184–5, 386
control frameworks, 384
identiﬁ cation of, 9, 62
management, see threat and vulnerability 
management (TVM)
organizational, 74
prevention, 139
probabilities and, 76
scan, 188, 224
technical, 74–5
types of, 197
VX2.Look2Me Spyware Trojan, 180
W
warning systems, historical perspectives, 49
waveforms, neural networks, 323–4
weather forecasting, 364
Web application attacks, 100
Web browsers
enhancement of, 302–3
vulnerabilities of, 180, 299
web cache proxy, 4
web caching servers, 290
web conferencing, 241
Weblogic, 224–5
Web Services Description Language (WSDL), 211, 213, 
218, 221, 224–5
Web Service-Security 
assessment questions, 225
Basic Security Proﬁ le, 224
deﬁ ned, 211
foundations for, 211–7
service-oriented architecture (SOA), 224–7
standards, 218–24
Web Services Security protocols
standards, 202, 218–9
WS-Authorization, 218, 224
WS-Federation, 218, 222–4
WS-I Basic Security Proﬁ le, 224
WS-MetadataExchange, 224
WS-Policy/WS-Security Policy, 218, 220–1
WS-PolicyAttachment, 218, 221
WS-Privacy, 218, 224
WS-SecureConversation, 218, 221–2, 225
WS-Security, 211, 219–20, 225, 227
WS-Trust, 218, 220–2, 225
web sites
fraudulent, 298, 301
privacy breach notiﬁ cation, 43
privacy breach plans, 40
self-serve authentication tokens, 159
Web-traﬃ  c monitoring, 100
weight, risk treatment, 80
Welch, Jack, 132
“what if” scenarios, 353, 368–9
“what you are” authentication factor, 160
wide area network, 66
WinZip, 291
wireless local area networks (LANs), 98, 100, 
103, 357
work environment, future challenges of, 138
worker engagement, 90–1
workﬂ ow diagram, 336, 338
workforce, future challenges, 137–8
workload, 344
workstation, information gathering guidelines, 66–7
work volume, in performance measurement, 89
WorldCom, 379
World Wide Web Consortium (W3C), 211
worms
characterized, 176, 187
polymorphic, 4
sources of, 297
worst-case scenario, 76
wrappers, 242
written breach notiﬁ cation, 43
X
X.509
certiﬁ cation, 216, 218–20, 222, 
224–5, 227
token, 220–1
Xpath, 212
XQuery, 212
Z
Zachman Framework, 263–4


