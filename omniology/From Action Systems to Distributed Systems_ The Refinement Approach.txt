Free ebooks ==>   www.Ebook777.com
www.Ebook777.com

Free ebooks ==>   www.Ebook777.com
From Action Systems 
to Distributed Systems
The Refinement Approach
www.Ebook777.com

Chapman & Hall/CRC 
Computational Science Series
PUBLISHED TITLES
SERIES EDITOR
Horst Simon
Deputy Director
Lawrence Berkeley National Laboratory
Berkeley, California, U.S.A.
COMBINATORIAL SCIENTIFIC COMPUTING  
Edited by Uwe Naumann and Olaf Schenk
CONTEMPORARY HIGH PERFORMANCE COMPUTING: FROM PETASCALE  
TOWARD EXASCALE 
Edited by Jeffrey S. Vetter
CONTEMPORARY HIGH PERFORMANCE COMPUTING: FROM PETASCALE  
TOWARD EXASCALE, VOLUME TWO 
Edited by Jeffrey S. Vetter
DATA-INTENSIVE SCIENCE  
Edited by Terence Critchlow and Kerstin Kleese van Dam 
THE END OF ERROR: UNUM COMPUTING  
John L. Gustafson 
FROM ACTION SYSTEMS TO DISTRIBUTED SYSTEMS: THE REFINEMENT APPROACH 
Edited by Luigia Petre and Emil Sekerinski
FUNDAMENTALS OF MULTICORE SOFTWARE DEVELOPMENT
Edited by Victor Pankratius, Ali-Reza Adl-Tabatabai, and Walter Tichy
FUNDAMENTALS OF PARALLEL MULTICORE ARCHITECTURE
Yan Solihin
THE GREEN COMPUTING BOOK: TACKLING ENERGY EFFICIENCY AT LARGE SCALE
Edited by Wu-chun Feng
GRID COMPUTING: TECHNIQUES AND APPLICATIONS
Barry Wilkinson
HIGH PERFORMANCE COMPUTING: PROGRAMMING AND APPLICATIONS 
John Levesque with Gene Wagenbreth
HIGH PERFORMANCE PARALLEL I/O 
Prabhat and Quincey Koziol

HIGH PERFORMANCE VISUALIZATION:  
ENABLING EXTREME-SCALE SCIENTIFIC INSIGHT  
Edited by E. Wes Bethel, Hank Childs, and Charles Hansen
INDUSTRIAL APPLICATIONS OF HIGH-PERFORMANCE COMPUTING:  
BEST GLOBAL PRACTICES  
Edited by Anwar Osseyran and Merle Giles
INTRODUCTION TO COMPUTATIONAL MODELING USING C AND  
OPEN-SOURCE TOOLS 
José M Garrido
INTRODUCTION TO CONCURRENCY IN PROGRAMMING LANGUAGES
Matthew J. Sottile, Timothy G. Mattson, and Craig E Rasmussen
INTRODUCTION TO ELEMENTARY COMPUTATIONAL MODELING: ESSENTIAL 
CONCEPTS, PRINCIPLES, AND PROBLEM SOLVING
José M. Garrido
INTRODUCTION TO HIGH PERFORMANCE COMPUTING FOR SCIENTISTS  
AND ENGINEERS 
Georg Hager and Gerhard Wellein
INTRODUCTION TO REVERSIBLE COMPUTING  
Kalyan S. Perumalla
INTRODUCTION TO SCHEDULING 
Yves Robert and Frédéric Vivien
INTRODUCTION TO THE SIMULATION OF DYNAMICS USING SIMULINK®
Michael A. Gray
PEER-TO-PEER COMPUTING: APPLICATIONS, ARCHITECTURE, PROTOCOLS,  
AND CHALLENGES 
Yu-Kwong Ricky Kwok
PERFORMANCE TUNING OF SCIENTIFIC APPLICATIONS 
Edited by David Bailey, Robert Lucas, and Samuel Williams
PETASCALE COMPUTING: ALGORITHMS AND APPLICATIONS
Edited by David A. Bader
PROCESS ALGEBRA FOR PARALLEL AND DISTRIBUTED PROCESSING
Edited by Michael Alexander and William Gardner
PUBLISHED TITLES CONTINUED

Free ebooks ==>   www.Ebook777.com
This page intentionally left blank
This page intentionally left blank
www.Ebook777.com

Edited by
Luigia Petre 
Åbo Akademi University
Turku, Finland
 
Emil Sekerinski
McMaster University
Hamilton, Canada
From Action Systems 
to Distributed Systems
The Refinement Approach

CRC Press
Taylor & Francis Group
6000 Broken Sound Parkway NW, Suite 300
Boca Raton, FL 33487-2742
© 2016 by Taylor & Francis Group, LLC
CRC Press is an imprint of Taylor & Francis Group, an Informa business
No claim to original U.S. Government works
Version Date: 20160323
International Standard Book Number-13: 978-1-4987-0159-4 (eBook - PDF)
This book contains information obtained from authentic and highly regarded sources. Reasonable efforts have been 
made to publish reliable data and information, but the author and publisher cannot assume responsibility for the valid-
ity of all materials or the consequences of their use. The authors and publishers have attempted to trace the copyright 
holders of all material reproduced in this publication and apologize to copyright holders if permission to publish in this 
form has not been obtained. If any copyright material has not been acknowledged please write and let us know so we may 
rectify in any future reprint.
Except as permitted under U.S. Copyright Law, no part of this book may be reprinted, reproduced, transmitted, or uti-
lized in any form by any electronic, mechanical, or other means, now known or hereafter invented, including photocopy-
ing, microfilming, and recording, or in any information storage or retrieval system, without written permission from the 
publishers.
For permission to photocopy or use material electronically from this work, please access www.copyright.com (http://
www.copyright.com/) or contact the Copyright Clearance Center, Inc. (CCC), 222 Rosewood Drive, Danvers, MA 01923, 
978-750-8400. CCC is a not-for-profit organization that provides licenses and registration for a variety of users. For 
organizations that have been granted a photocopy license by the CCC, a separate system of payment has been arranged.
Trademark Notice: Product or corporate names may be trademarks or registered trademarks, and are used only for 
identification and explanation without intent to infringe.
Visit the Taylor & Francis Web site at
http://www.taylorandfrancis.com
and the CRC Press Web site at
http://www.crcpress.com

To Kaisa

This page intentionally left blank
This page intentionally left blank

Free ebooks ==>   www.Ebook777.com
Contents
Preface
xv
Acknowledgements
xvii
List of Figures
xix
List of Tables
xxiii
About the Editors
xxv
List of Contributors
xxvii
I
Modeling
1
1
Modeling Sources for Uncertainty in Environmental Monitoring
3
Mauno Rönkkö
1.1
Introduction
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4
1.2
Hybrid Action Systems
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5
1.2.1
Conventional Actions
. . . . . . . . . . . . . . . . . . . . . . . . . .
5
1.2.2
Diﬀerential Action . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5
1.2.3
Action Systems and Parallel Composition . . . . . . . . . . . . . . .
6
1.2.4
Reﬁnement of Hybrid Action Systems
. . . . . . . . . . . . . . . . .
7
1.3
Environmental Monitoring
. . . . . . . . . . . . . . . . . . . . . . . . . . .
8
1.4
Case Study: Monitoring Room Temperature
. . . . . . . . . . . . . . . . .
9
1.4.1
System Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
9
1.4.2
Environment
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
10
1.4.3
Temperature Sensor . . . . . . . . . . . . . . . . . . . . . . . . . . .
11
1.4.4
Monitoring Logic . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
12
1.4.5
About Validation of Properties of Interest . . . . . . . . . . . . . . .
13
1.5
Conclusion
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
14
2
Mandatory and Potential Choice: Comparing Event-B and STAIRS
15
Atle Refsdal, Ragnhild Kobro Runde, and Ketil Stølen
2.1
Introduction
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
16
2.2
Kinds of Choice
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
17
2.3
Comparing Event-B and STAIRS at the Syntactic Level . . . . . . . . . . .
19
2.4
Interaction-Obligations versus Failure-Divergences
. . . . . . . . . . . . . .
22
2.4.1
Interaction-Obligations
. . . . . . . . . . . . . . . . . . . . . . . . .
23
2.4.2
Failure-Divergences . . . . . . . . . . . . . . . . . . . . . . . . . . . .
24
2.4.3
Relating the Two Models
. . . . . . . . . . . . . . . . . . . . . . . .
25
ix
www.Ebook777.com

x
Contents
2.4.4
Sets of Interaction-Obligations
. . . . . . . . . . . . . . . . . . . . .
25
2.5
Conclusion
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
26
3
Modelling and Reﬁning Hybrid Systems in Event-B and Rodin
29
Michael Butler, Jean-Raymond Abrial, and Richard Banach
3.1
Introduction
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
29
3.2
Reals and Continuous Functions
. . . . . . . . . . . . . . . . . . . . . . . .
31
3.3
Modelling a Continuous Control Goal
. . . . . . . . . . . . . . . . . . . . .
32
3.4
Distinguishing Modes
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
35
3.5
Modelling the Control Strategy . . . . . . . . . . . . . . . . . . . . . . . . .
36
3.6
Merging Big and Small Step Variables . . . . . . . . . . . . . . . . . . . . .
39
3.7
Derivatives
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
40
3.8
Concluding
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
41
II
Analysis
43
4
Modeling and Analysis of Component Faults and Reliability
45
Thibaut Le Guilly, Petur Olsen, Anders P. Ravn, and Arne Skou
4.1
Introduction
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
46
4.1.1
Overview
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
47
4.2
A Development and Analysis Process
. . . . . . . . . . . . . . . . . . . . .
47
4.2.1
Ideal Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
48
4.2.2
Modeling Faults
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
49
4.2.3
Fault Tree Analysis
. . . . . . . . . . . . . . . . . . . . . . . . . . .
49
4.2.4
Reliability Assessment . . . . . . . . . . . . . . . . . . . . . . . . . .
51
4.3
Example
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
51
4.3.1
Ideal Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
52
4.3.2
Modeling Faults
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
55
4.3.3
Fault Tree Analysis
. . . . . . . . . . . . . . . . . . . . . . . . . . .
56
4.3.4
Reliability Assessment . . . . . . . . . . . . . . . . . . . . . . . . . .
56
4.4
Discussion, Conclusion, Related and Further Work . . . . . . . . . . . . . .
58
4.4.1
Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
58
4.4.2
Conclusion
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
58
4.4.3
Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
59
4.4.4
Further Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
59
5
Veriﬁable Programming of Object-Oriented and Distributed Systems
61
Olaf Owe
5.1
Introduction
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
62
5.2
Basic Programming Constructs . . . . . . . . . . . . . . . . . . . . . . . . .
63
5.3
Class Invariants
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
68
5.4
Inheritance
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
71
5.5
Local Reasoning
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
74
5.6
Discussion of Future-Related Mechanisms . . . . . . . . . . . . . . . . . . .
76
5.7
Conclusion
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
78

Contents
xi
6
A Contract-Based Approach to Ensuring Component Interoperability in
Event-B
81
Linas Laibinis and Elena Troubitsyna
6.1
Introduction
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
82
6.2
Background: Event-B
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
83
6.2.1
Modelling and Reﬁnement in Event-B . . . . . . . . . . . . . . . . .
83
6.2.2
Modelling Modular Systems in Event-B . . . . . . . . . . . . . . . .
85
6.3
From Event-B Modelling to Contracts . . . . . . . . . . . . . . . . . . . . .
88
6.3.1
Contracts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
88
6.3.2
From a Module Interface to a Component Contract . . . . . . . . . .
89
6.4
Example: An Auction System
. . . . . . . . . . . . . . . . . . . . . . . . .
90
6.4.1
Initial Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
90
6.5
Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
95
III
Proof
97
7
Meeting Deadlines, Elastically
99
Einar Broch Johnsen, Ka I Pun, Martin Steﬀen, S. Lizeth Tapia
Tarifa, and Ingrid Chieh Yu
7.1
Introduction
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
100
7.2
Service Contracts as Interfaces
. . . . . . . . . . . . . . . . . . . . . . . . .
101
7.3
A Kernel Language for Virtualized Computing
. . . . . . . . . . . . . . . .
102
7.4
Example: A Photo Printing Shop
. . . . . . . . . . . . . . . . . . . . . . .
103
7.5
Proof System . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
105
7.6
Related Work
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
108
7.7
Discussion
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
110
8
Event-B and Linear Temporal Logic
113
Steve Schneider, Helen Treharne and David M. Williams
8.1
Introduction
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
113
8.2
Event-B . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
115
8.2.1
Machines
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
115
8.2.2
Reﬁnement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
116
8.2.3
Development Strategy . . . . . . . . . . . . . . . . . . . . . . . . . .
117
8.2.4
Semantics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
118
8.3
LTL Notation
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
118
8.4
Preserving LTL Properties in Event-B Reﬁnement Chains . . . . . . . . . .
119
8.4.1
Example: Deadlock-Freedom
. . . . . . . . . . . . . . . . . . . . . .
120
8.4.2
Example: Anticipated Events . . . . . . . . . . . . . . . . . . . . . .
121
8.4.3
Example: β-Dependence . . . . . . . . . . . . . . . . . . . . . . . . .
122
8.5
Discussion and Related Work . . . . . . . . . . . . . . . . . . . . . . . . . .
122
8.6
Conclusion
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
123
9
A Provably Correct Resilience Mediator Pattern
125
Mats Neovius, Mauno Rönkkö, and Marina Waldén
9.1
Introduction
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
126
9.2
Provably Correct Stepwise Development with Action Systems . . . . . . . .
127

xii
Contents
9.2.1
Weakest Precondition Predicate Transformers and the Action Systems
Framework
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
127
9.2.2
The Action Systems Framework
. . . . . . . . . . . . . . . . . . . .
128
9.2.3
Reﬁnement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
129
9.2.4
Tool Support . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
130
9.3
Resilience Mediator
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
131
9.4
Formal Development of the Resilience Mediator Pattern . . . . . . . . . . .
132
9.4.1
The First Model - Abstract System . . . . . . . . . . . . . . . . . . .
132
9.4.2
The Second Model - Introduction of the Producer-Consumer Pattern
133
9.4.3
The Third Model - Introduction of the Resilience Mediator
. . . . .
136
9.4.4
Example of a Resilience Mediator . . . . . . . . . . . . . . . . . . . .
137
9.5
Discussion and Conclusion
. . . . . . . . . . . . . . . . . . . . . . . . . . .
138
IV
Reﬁnement
141
10 Relational Concurrent Reﬁnement - Partial and Total Frameworks
143
John Derrick and Eerke Boiten
10.1 Introduction
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
143
10.2 Models of Reﬁnement
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
144
10.3 Using a Partial Framework to Embed Concurrent Reﬁnement Relations
. .
145
10.3.1 Basic Relations without Divergence
. . . . . . . . . . . . . . . . . .
146
10.3.2 Internal Events and Divergence . . . . . . . . . . . . . . . . . . . . .
148
10.4 A Total Relational Framework
. . . . . . . . . . . . . . . . . . . . . . . . .
149
10.5 A General Framework for Simulations - Process Data Types
. . . . . . . .
150
10.6 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
153
11 Reﬁnement of Behavioural Models for Variability Description
155
Alessandro Fantechi and Stefania Gnesi
11.1 Introduction
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
155
11.2
Running Example and Background
. . . . . . . . . . . . . . . . . . . . . .
156
11.2.1 Labelled Transition Systems . . . . . . . . . . . . . . . . . . . . . . .
157
11.3 Behavioural Models and Variability
. . . . . . . . . . . . . . . . . . . . . .
158
11.3.1 MTS: Modal Transition Systems . . . . . . . . . . . . . . . . . . . .
159
11.3.2 DMTS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
161
11.3.3 1MTS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
161
11.3.4 Generalised Extended Modal Transition Systems . . . . . . . . . . .
164
11.4 A Comparison on the Expressiveness
. . . . . . . . . . . . . . . . . . . . .
168
11.5 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
169
11.6 Acknowledgments
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
169
12 Integrating Reﬁnement-Based Methods for Developing Timed Systems
171
Jüri Vain, Leonidas Tsiopoulos, and Pontus Boström
12.1 Introduction
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
172
12.2 Related Work
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
173
12.3 Preliminaries
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
174
12.3.1 Preliminaries of Event-B . . . . . . . . . . . . . . . . . . . . . . . . .
174
12.3.2 Preliminaries of UPTA . . . . . . . . . . . . . . . . . . . . . . . . . .
175
12.4 Mapping from Event-B Models to UPTA
. . . . . . . . . . . . . . . . . . .
175

Contents
xiii
12.5 IEEE 1394 Case Study
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
177
12.5.1 IEEE 1394 in Event-B . . . . . . . . . . . . . . . . . . . . . . . . . .
178
12.5.2 Mapping IEEE 1394 Event-B Model to UPTA
. . . . . . . . . . . .
179
12.6 Reﬁnement of Timed Systems
. . . . . . . . . . . . . . . . . . . . . . . . .
180
12.6.1 Event-B and UPTA Final Reﬁnement of IEEE 1394
. . . . . . . . .
183
12.7 Conclusion and Future Work
. . . . . . . . . . . . . . . . . . . . . . . . . .
184
V
Applications
187
13 Action Systems for Pharmacokinetic Modeling
189
M.M. Bonsangue, M. Helvensteijn, J.N. Kok, and N. Kokash
13.1 Introduction
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
190
13.2 Actions and Action Systems
. . . . . . . . . . . . . . . . . . . . . . . . . .
191
13.2.1 Action Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
193
13.2.2 Hybrid Action Systems
. . . . . . . . . . . . . . . . . . . . . . . . .
193
13.3 Pharmacokinetic Modeling
. . . . . . . . . . . . . . . . . . . . . . . . . . .
194
13.3.1 Absorption
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
196
13.3.2 Elimination . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
198
13.3.3 One-Compartment Model . . . . . . . . . . . . . . . . . . . . . . . .
199
13.3.4 Distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
199
13.4 Conclusions and Future Work
. . . . . . . . . . . . . . . . . . . . . . . . .
200
14 Quantitative Model Reﬁnement in Four Diﬀerent Frameworks
201
Diana-Elena Gratie, Bogdan Iancu, Sepinoud Azimi, and Ion Petre
14.1 Introduction
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
202
14.2 Quantitative Model Reﬁnement
. . . . . . . . . . . . . . . . . . . . . . . .
203
14.3 Case Study: The Heat Shock Response (HSR)
. . . . . . . . . . . . . . . .
205
14.4 Quantitative Reﬁnement for ODE Models . . . . . . . . . . . . . . . . . . .
208
14.5 Quantitative Reﬁnement for Rule-Based Models
. . . . . . . . . . . . . . .
209
14.6 Quantitative Reﬁnement for Petri Net Models
. . . . . . . . . . . . . . . .
210
14.7 Quantitative Reﬁnement for PRISM Models
. . . . . . . . . . . . . . . . .
211
14.8 Discussion
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
213
15 Developing and Verifying User Interface Requirements for
Infusion Pumps: A Reﬁnement Approach
215
Rimvydas Rukš˙enas, Paolo Masci, and Paul Curzon
15.1 Introduction
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
216
15.1.1 Outline of the Approach . . . . . . . . . . . . . . . . . . . . . . . . .
217
15.2 Sample User Interface Requirements from FDA
. . . . . . . . . . . . . . .
217
15.3 Background
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
218
15.3.1 Interface Reﬁnement Approaches . . . . . . . . . . . . . . . . . . . .
218
15.3.2 Event-B/Rodin Framework . . . . . . . . . . . . . . . . . . . . . . .
219
15.4 The Requirement Hierarchies . . . . . . . . . . . . . . . . . . . . . . . . . .
220
15.4.1 Requirements for Data Entry . . . . . . . . . . . . . . . . . . . . . .
220
15.4.1.1 Requirements R1 and R2 . . . . . . . . . . . . . . . . . . .
220
15.4.1.2 Requirements R3 and R4 . . . . . . . . . . . . . . . . . . .
221
15.4.2 Safeguards against Inadvertent Changes or Tampering . . . . . . . .
222
15.4.2.1 Requirement R5 . . . . . . . . . . . . . . . . . . . . . . . .
222

xiv
Contents
15.4.2.2 Requirement R6 . . . . . . . . . . . . . . . . . . . . . . . .
224
15.5 Veriﬁcation of Concrete Interfaces
. . . . . . . . . . . . . . . . . . . . . . .
226
15.5.1 Speciﬁcation of the vtbi Entry in Alaris . . . . . . . . . . . . . . . .
226
15.5.2 Requirement R6
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
227
15.5.3 Requirements R1-R4 . . . . . . . . . . . . . . . . . . . . . . . . . . .
228
15.6 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
229
16 Self-Assembling Interactive Modules: A Research Programme
231
Gheorghe Stefanescu
16.1 Tiling: A Brief Introduction
. . . . . . . . . . . . . . . . . . . . . . . . . .
231
16.2 Two-Dimensional Languages: Local vs. Global Glueing Constraints . . . . .
233
16.2.1 Words and Languages in Two Dimensions . . . . . . . . . . . . . . .
233
16.2.2 Local Constraints: Tiles . . . . . . . . . . . . . . . . . . . . . . . . .
233
16.2.3 Global Constraints: Regular Expressions . . . . . . . . . . . . . . . .
237
16.2.4 Systems of Recursive Equations . . . . . . . . . . . . . . . . . . . . .
237
16.3 Structural Characterisation for Self-Assembling Tiles
. . . . . . . . . . . .
239
16.3.1 From Local to Global Constraints
. . . . . . . . . . . . . . . . . . .
239
16.3.2 Languages Generated by Two-Colors Border Tiles
. . . . . . . . . .
239
16.3.3 A Case Study: F02ac.c
. . . . . . . . . . . . . . . . . . . . . . . . .
240
16.4 Interactive Programs
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
243
16.4.1 Words and Traces in Two Dimensions
. . . . . . . . . . . . . . . . .
243
16.4.2 Interactive Modules and Programs . . . . . . . . . . . . . . . . . . .
243
16.4.3 Reﬁnement of Structured Interactive Programs . . . . . . . . . . . .
245
16.5 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
246
Bibliography
247
Index
273

Preface
From Action Systems to Distributed Systems – the Refinement Approach is a
book dedicated to the memory of Kaisa Sere (1954–2012).
Kaisa lived a scientiﬁcally-intense life. She was a Professor of Computer Science and
Engineering at Åbo Akademi University, Turku, Finland since 1997. Between 1993–1997 she
was an Associate Professor of Computer Science at the University of Kuopio, Finland. She
got her PhD in 1990 on the formal design of parallel algorithms and held a postdoctoral
position at the Utrecht University in The Netherlands during 1991–1992.
She has established and led for more than 10 years the Distributed Systems laboratory at
TUCS – Turku Centre for Computer Science, the graduate research institute in Informatics,
Turku, Finland. She has supervised 20 PhD students and more than 60 MSc students; the
majority of her former students were – some still are – members of the Distributed Systems
laboratory. At the time of her passing away, she still had seven PhD students under co-
supervision: to date, ﬁve of them graduated, one is graduating during the Fall 2015 and one,
who has started in late 2012, is well underway.
Kaisa Sere was extremely experienced as well as very talented at attracting funding for
her Distributed Systems laboratory researchers. She was granted ﬁnancing for an impressive
array of research projects. Some highlights include Desiré, Asynkron and FOSSE projects,
funded by the Academy of Finland; EFFIMA/DiHy and EFFIMA/Digihybrid projects, funded
by Tekes – the Finnish Funding Agency for Technology and Innovation; Matisse, RODIN and
Deploy projects, funded by the European Union during 2000–2012. She was the vice-leader
of CREST, the Finnish national Centre of Excellence for Formal Methods in Programming
Research, during 2002–2007. She led the Nordic education network NODES on depend-
ability, ﬁnanced by NordForsk – the organization funding Nordic research cooperation and
infrastructures.
Kaisa Sere served in numerous research evaluation committees both nationally and inter-
nationally as well as in programme committees. She has organised several summer schools,
conferences and workshops; notably, she was a program chair of the Integrated Formal Meth-
ods conference in 2002 (IFM’2002) and the general chair of the international symposium on
Formal Methods in 2008 (FM’2008) – the ﬂagship conference in the ﬁeld of formal methods.
The most extensive part of Kaisa Sere’s research consisted in developing Action Systems,
a formalism for modeling, analysing, and constructing distributed systems. Together with her
co-authors, she introduced modularisation techniques for distributed systems, correct-by-
construction rules for developing distributed systems, as well as a vast array of case studies
demonstrating the strength of the proposed approach. All these contributions were expressed
through the ﬂexible Action Systems language, in a period when tool support was still in its
infancy. Quite importantly, Action Systems are at the foundation of a current mainstream
formalism called Event-B, which embeds Kaisa Sere’s contributions to modeling, analysing,
and constructing distributed systems in a tool-centred environment, the Rodin platform.
This platform is reliable and consequently, industrial acceptance of these methodologies
xv

xvi
Preface
increases. In fact, the European project Deploy strongly promoted Event-B and the Rodin
platform to industry.
Within the design of distributed systems, Kaisa Sere’s main research focus was on
reﬁnement-based approaches to the construction of systems ranging from pure software to
hardware and digital circuits. The reﬁnement technique ensures, by mathematical proof, that
the ﬁnal system respects its initial requirements. Central to this is the concept of abstrac-
tion, by which an initial model of the system-to-develop only encompasses its fundamental
requirements; such an initial model is consequently very simple. This abstraction mechanism
makes it feasible to prove that the initial model satisﬁes the fundamental requirements as
well as basic properties. Upon proving these for the system, one gradually adds the missing
details in a manner that keeps the proven requirements and properties true and allows the
satisﬁability proof of other requirements and new properties. This correct-by-construction
method for software development complements model checking approaches as well as testing
and simulation approaches for ensuring the quality of systems. When used properly, it can
shorten the development lifecycle of systems, in addition to certifying their quality.
Kaisa Sere was a remarkably positive, energetic, and inspirational researcher, who at-
tracted an impressive number of collaborators. When the generous opportunity of CRC
Press arose, to send a last salute to the colleague, leader, and friend that she was, a large
number of her former collaborators wanted to contribute. The result of their work is the
present book, From Action Systems to Distributed Systems – the Refinement
Approach. We have divided the book into ﬁve parts: I Modeling, II Analysis, III Proof,
IV Reﬁnement, and V Applications. The names of these parts are recurring themes of
Kaisa Sere’s research, celebrated now by her collaborators. Some of the chapters employ the
Action Systems formalism; some employ and further develop its Event-B successor; some
chapters focus on analysis, some on proof, some on reﬁnement, and some on comparing
various semantical models for these; some chapters discuss model checking approaches to
analysis and reﬁnement; some chapters include applications of actions systems or of the
reﬁnement approach in pharmacokinetics, biology, and medicine; and many chapters em-
phasize future research directions including reﬁnement as a central theme. Therefore, we
hope that the book will address a broad audience, from graduate students to researchers
and practitioners interested in applying formal methods to develop distributed systems of
quality.
September 2015
Luigia Petre
Emil Sekerinski

Acknowledgements
From Action Systems to Distributed Systems – the Refinement Approach is an
edited book collecting scientiﬁc contributions mainly on the themes of distributed systems
and reﬁnement. Each chapter was thoroughly reviewed by experts in the ﬁeld, resulting in
16 accepted articles out of the initial 19 submissions.
We would like to warmly thank the anonymous reviewers for their hard work on pro-
moting scientiﬁc excellence. Our gratitude extends to the kind and professional personnel
at CRC Press who helped and supported this long-term project; in particular, warm thanks
to Ms Randi Cohen, Senior Acquisitions Editor and Ms Jennifer Ahringer, Senior Project
Coordinator. We would also like to acknowledge the Easychair support, for handling our
submission and review process; in particular, thanks to Andrei Voronkov, for making this
framework available.
In the end, we would like to acknowledge the collegiality and scholarship of the chapter
authors: it is your work that makes up this book! Thank you!
Luigia Petre
Emil Sekerinski
xvii

This page intentionally left blank
This page intentionally left blank

Free ebooks ==>   www.Ebook777.com
List of Figures
2.1
Two Event-B vending machines as speciﬁed by [71] . . . . . . . . . . . . .
20
2.2
A simple vending machine with potential choice in STAIRS
. . . . . . . .
21
2.3
A simple vending machine with external choice in STAIRS . . . . . . . . .
22
2.4
Mandatory choice in STAIRS
. . . . . . . . . . . . . . . . . . . . . . . . .
23
2.5
External choice represented by a sequence diagram in STAIRS . . . . . . .
26
3.1
Evolution of continuous function during intervals. . . . . . . . . . . . . . .
34
3.2
Small step and big step intervals. . . . . . . . . . . . . . . . . . . . . . . .
37
4.1
The process . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
48
4.2
Example of power set exploration . . . . . . . . . . . . . . . . . . . . . . .
51
4.3
Gas tank example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
53
4.4
Models of the system components . . . . . . . . . . . . . . . . . . . . . . .
54
4.5
Simulation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
54
4.6
Fault-aﬀected component models
. . . . . . . . . . . . . . . . . . . . . . .
55
4.7
Unreliable sensor and associated complex failure observer . . . . . . . . . .
56
4.8
Safety valve . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
57
5.1
Core language syntax.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
65
5.2
A simple bank example.
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
66
5.3
A simple example of multiple inheritance, reusing the bank example. . . .
67
5.4
Hoare style rules for non-standard constructs. . . . . . . . . . . . . . . . .
75
6.1
Event-B machine and context components . . . . . . . . . . . . . . . . . .
83
6.2
Before-after predicates . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
84
6.3
Module interface
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
86
6.4
Component contract
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
88
6.5
Interface component
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
93
6.6
The seller class contract
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
94
7.1
A photo printing shop in µABS. . . . . . . . . . . . . . . . . . . . . . . . .
102
7.2
µABS syntax for the object level. . . . . . . . . . . . . . . . . . . . . . . .
103
7.3
A class diagram for a photo printing shop
. . . . . . . . . . . . . . . . . .
104
7.4
A sequence diagram for a photo printing shop . . . . . . . . . . . . . . . .
105
7.5
A photo printing shop in µABS . . . . . . . . . . . . . . . . . . . . . . . .
106
7.6
Proof system for µABS . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
107
8.1
Lift0
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
115
8.2
Lift1
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
116
xix
www.Ebook777.com

xx
List of Figures
8.3
Lift2
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
117
8.4
Events and their annotations in the Lift development
. . . . . . . . . . .
118
9.1
The resilience mediator as an architectural component. . . . . . . . . . . .
132
9.2
Traditional producer-consumer signaling sequence on the left and signaling
with a mediator on the right.
. . . . . . . . . . . . . . . . . . . . . . . . .
133
9.3
The abstract system as a UML statechart on the left and as an action system,
called AbstractSystem, on the right. . . . . . . . . . . . . . . . . . . . . . .
133
9.4
Statechart diagram of the system with producer-consumer states; hierarchi-
cal statechart on the left and ﬂattened statechart on the right. . . . . . . .
134
9.5
An action system, called PCSystem, with producer and consumer actions
introduced.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
135
9.6
Action systems with merged state variable. . . . . . . . . . . . . . . . . . .
135
9.7
Flattened statechart diagram of the system with the resilience mediator
states.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
136
9.8
An action system representation of the system with the resilience mediator
states.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
137
9.9
The obtained action systems capturing the producer, mediator and con-
sumer actions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
138
10.1
[60] The original Op, and a divergent after-state; with B⊥× {⊥} added;
ﬁnally also with Dω × Stateω ∪{(ω, ⊥)}. . . . . . . . . . . . . . . . . . . .
152
11.1
Modelling a product family with an LTS . . . . . . . . . . . . . . . . . . .
158
11.2
MTS modelling the family of coﬀee machines. . . . . . . . . . . . . . . . .
160
11.3
(a)-(b) LTS modelling some correct products. . . . . . . . . . . . . . . . .
160
11.4
Modelling a product family with an LTS . . . . . . . . . . . . . . . . . . .
162
11.5
An example of DMTS and 1MTS . . . . . . . . . . . . . . . . . . . . . . .
163
11.6
An example of DMTS and its problem with exclusive choices
. . . . . . .
164
11.7
An example of 1MTS and its implementations . . . . . . . . . . . . . . . .
165
11.8
An example of GEMTS and its implementations . . . . . . . . . . . . . . .
166
11.9
Vending machines family as a GEMTS . . . . . . . . . . . . . . . . . . . .
168
11.10 Hierarchy for the modal family
. . . . . . . . . . . . . . . . . . . . . . . .
169
12.1
CCD workﬂow with data and timing reﬁnement steps . . . . . . . . . . . .
172
12.2
UPTA model template of Event-B a) un-timed event, b) skip-event, c) timed
skip-event, and d) timed event.
. . . . . . . . . . . . . . . . . . . . . . . .
177
12.3
Intermediate Event-B reﬁnement of IEEE 1394 protocol
. . . . . . . . . .
178
12.4
UPTA event template transformations: a) timed event, b) non-blocking
event and c) terminal event
. . . . . . . . . . . . . . . . . . . . . . . . . .
180
12.5
a) UPTA model corresponding to Event-B reﬁnement of Figure 12.3, b)
timing reﬁnement, and c) UPTA model corresponding to ﬁnal Event-B re-
ﬁnement of Figure 12.7
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
181
12.6
(a) Edge reﬁnement, (b) location reﬁnement.
. . . . . . . . . . . . . . . .
182
12.7
Event-B ﬁnal reﬁnement of IEEE 1394 tree identify protocol . . . . . . . .
184
13.1
ADME scheme
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
195
13.2
Intravenous administration . . . . . . . . . . . . . . . . . . . . . . . . . . .
197
13.3
Oral administration . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
197

List of Figures
xxi
13.4
First-order elimination process . . . . . . . . . . . . . . . . . . . . . . . . .
198
13.5
Mixed elimination process . . . . . . . . . . . . . . . . . . . . . . . . . . .
198
13.6
Pharmacokinetic modeling . . . . . . . . . . . . . . . . . . . . . . . . . . .
200
14.1
A graphical representation of the species hsf (containing sites ‘s’,‘u’,‘v’,‘w’)
and of the rule showing the dimerization of hsf, illustrated by binding one of
the ‘s’ sites of the hsf species with one of the ‘s’ site of the other hsf species.
Note the two possible states of the site ‘w’, namely ‘a’ and ‘n’, which depict
two possible states of the species, acetylated or non-acetylated respectively.
210
14.2
Representing the dimerization of two diﬀerent proteins, P′ and P′′ with (a)
a transition for each of them, and (b) a single colored transition for both.
In (b) we use a color set with two colors, Prot type = {1, 2}. The choice
between colors 1 and 2 is done by the variable x; when x = 1 the reaction
will consume two proteins with color 1 and produce one dimer with color
1, and when x = 2 the reaction will consume two proteins with color 2 and
produce one dimer with color 2. In the ﬁgure, all places and transitions have
identiﬁers, and in (b) we also list the color set for each place (italic text).
211
14.3
Modeling the hsf dimers using a compound color set Dimer = Monomer ×
Monomer. The regular text next to places and transitions denotes their re-
spective identiﬁer, while the color sets are written in italic font. The hsf
monomers are represented using the color set Monomer = {0, 1}. The pre-
places of the forward reaction are two monomers, with colors m1 and m2.
The result will be the production of one dimer with color (m1,m2). In the re-
verse reaction, one dimer with color (m1, m2) is split into the two monomers
m1 and m2.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
212
16.1
2-dimensional words
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
233
16.2
Scenarios and accepted words . . . . . . . . . . . . . . . . . . . . . . . . .
233
16.3
Scenario composition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
235
16.4
Border agnostic word composition . . . . . . . . . . . . . . . . . . . . . . .
235
16.5
Restricted word composition . . . . . . . . . . . . . . . . . . . . . . . . . .
236
16.6
General restricted composition . . . . . . . . . . . . . . . . . . . . . . . . .
237
16.7
Recursive equations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
238
16.8
Recursive speciﬁcations . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
242
16.9
A scenario for the communication protocol example . . . . . . . . . . . . .
245

This page intentionally left blank
This page intentionally left blank

List of Tables
1.1
Semantics of conventional actions . . . . . . . . . . . . . . . . . . . . . . .
6
2.1
Choice types in CSP and STAIRS . . . . . . . . . . . . . . . . . . . . . . .
17
4.1
Speciﬁcations expressed as Uppaal properties . . . . . . . . . . . . . . . .
54
4.2
Output of the FTA . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
56
9.1
Semantics of conventional actions . . . . . . . . . . . . . . . . . . . . . . .
128
11.1
Meaning of modalities
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
168
14.1
The molecular model of the eukaryotic heat shock response proposed
in [263].
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
205
14.2
The list of reactions for the reﬁned model that includes the acetylation status
of hsf. A reaction (i.j) is a reﬁnement of reaction (i) of the basic model, see
Table 14.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
207
14.3
PRISM code for the dimerization in (a) the basic and (b) the reﬁned HSR
models (Nhsf is the upper bound for hsf and Nhsf2 is the upper bound for
hsf2). . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
212
xxiii

This page intentionally left blank
This page intentionally left blank

About the Editors
Dr. Luigia Petre is Associate Professor of Computer Science in the Faculty of Science and
Engineering at Åbo Akademi University (Turku, Finland). She got her Ph.D. in Computer
Science in 2005 on modelling techniques in formal methods. Her research interests include
formal methods and their integration, wireless sensor networks, network architectures, meta-
modelling, non-functional properties and time-space dependent computing. She has super-
vised 11 Master’s students, three Ph.D. students and currently has one Ph.D. student under
supervision. She was granted funding from the Academy of Finland to lead a consortium
research project named FResCo during 2013-2015 and has been coordinating NODES—the
Nordic Network on Dependable Systems (ﬁnanced by Nordforsk), concerned with deploying
a dependability curriculum for the Nordic countries, during 2007-2012. She has organized
a winter school and several conferences; most notably, she has actively participated in the
International Conference on Integrated Formal Methods, organising it twice in Turku (2002
and 2013), as a program committee member of this conference in 2002, 2004, 2005, 2007,
2012-2014, as a program committee chair in 2013 and as a member of the steering committee
for this conference since 2014. Dr. Petre has edited two books and three special issues of
international journals; she has published about 45 peer-reviewed articles.
Dr. Emil Sekerinski is Associate Professor in the Department of Computing and Soft-
ware at McMaster University (Hamilton, Ontario, Canada). He got his Dr. rer. nat in
1994 from the University of Karlsruhe (Germany) on the formal development of object-
oriented programs by stepwise reﬁnement. His interests include programming languages and
tools, program correctness, concurrency, components, embedded systems. He has super-
vised at McMaster 18 Master’s student, 4 Ph.D. students, and one postdoctoral researchers.
Currently he receives funding through Canada’s National Science and Engineering Research
Council and through the Ontario Research Fund and has received support from IBM through
the Southern Ontario Smart Computing Innovation Platform. He spent sabbaticals at ETH
Zürich, TU München, and TU Dresden. In 2006, he organized the FM Symposium in
Hamilton and was a member of the program committee of a number of conferences, e.g.
Integrated Formal Methods, Reﬁnement Workshop, International Conference on B and Z,
International Colloquium on Theoretical Aspects of Computing, Mathematics of Program
Construction. Dr. Sekerinski has edited three books and published over 50 peer-reviewed
articles.
xxv

This page intentionally left blank
This page intentionally left blank

List of Contributors
Jean-Raymond Abrial
Independent consultant
Marseille, France
Sepinoud Azimi
Turku Centre for Computer Science and
Åbo Akademi University
Turku, Finland
Richard Banach
University of Manchester
Manchester, UK
Eerke Boiten
School of Computing, University of Kent
Canterbury, Kent, UK
Marcello M. Bonsangue
LIACS, Leiden University
Leiden, the Netherlands
Pontus Boström
Åbo Akademi University
Turku, Finland
Michael Butler
University of Southampton
Southampton, UK
Paul Curzon
Queen Mary University of London
London, UK
John Derrick
Department of Computer Science,
University of Sheﬃeld
Sheﬃeld, UK
Alessandro Fantechi
Dipartimento di Ingegneria
dell’Informazione, Università di Firenze
and ISTI–CNR
Florence, Italy
Stefania Gnesi
ISTI–CNR
Pisa, Italy
Diana-Elena Gratie
Turku Centre for Computer Science and
Åbo Akademi University
Turku, Finland
Thibaut Le Guilly
Department of Computer Science, Aalborg
University
Aalborg, Denmark
Michiel Helvensteijn
LIACS, Leiden University
Leiden, the Netherlands
Bogdan Iancu
Turku Centre for Computer Science and
Åbo Akademi University
Turku, Finland
Einar Broch Johnsen
University of Oslo
Oslo, Norway
Joost N. Kok
LIACS, Leiden University
Leiden, the Netherlands
Natalia Kokash
LIACS, Leiden University
Leiden, the Netherlands
Linas Laibinis
Åbo Akademi University
Turku, Finland
Paolo Masci
Queen Mary University of London
London, UK
xxvii

xxviii
List of Contributors
Mats Neovius
Åbo Akademi University
Turku, Finland
Petur Olsen
Department of Computer Science, Aalborg
University
Aalborg, Denmark
Olaf Owe
University of Oslo, Department of
Informatics
Norway, and University of California,
Department of Computer Science
Santa Cruz, USA
Ion Petre
Turku Centre for Computer Science and
Åbo Akademi University
Turku, Finland
Ka I Pun
University of Oslo
Oslo, Norway
Anders P. Ravn
Department of Computer Science, Aalborg
University
Aalborg, Denmark
Atle Refsdal
SINTEF ICT
Oslo, Norway
Mauno Rönkkö
Department of Environmental Science,
University of Eastern Finland
Kuopio, Finland
Rimvydas Rukš˙enas
Queen Mary University of London
London, UK
Ragnhild Kobro Runde
University of Oslo
Oslo, Norway
Steve Schneider
University of Surrey
Surrey, UK
Arne Skou
Department of Computer Science, Aalborg
University
Aalborg, Denmark
Gheorghe Stefanescu
University of Bucharest
Bucharest, Romania
Martin Steﬀen
University of Oslo
Oslo, Norway
Ketil Stølen
SINTEF ICT and University of Oslo
Oslo, Norway
S. Lizeth Tapia Tarifa
University of Oslo
Oslo, Norway
Leonidas Tsiopoulos
Åbo Akademi University
Turku, Finland
Helen Treharne
University of Surrey
Surrey, UK
Elena Troubitsyna
Åbo Akademi University
Turku, Finland
Jüri Vain
Tallinn University of Technology
Tallinn, Estonia
Marina Waldén
Åbo Akademi University
Turku, Finland
David M. Williams
VU University Amsterdam
Amsterdam, the Netherlands
Ingrid Chieh Yu
University of Oslo
Oslo, Norway

Part I
Modeling
1

This page intentionally left blank
This page intentionally left blank

Chapter 1
Modeling Sources for Uncertainty in
Environmental Monitoring
Mauno Rönkkö
Department of Environmental Science, University of Eastern Finland
1.1
Introduction ......................................................
4
1.2
Hybrid Action Systems ..........................................
5
1.2.1
Conventional Actions ....................................
5
1.2.2
Diﬀerential Action .......................................
5
1.2.3
Action Systems and Parallel Composition ..............
6
1.2.4
Reﬁnement of Hybrid Action Systems ..................
7
1.3
Environmental Monitoring .......................................
8
1.4
Case Study: Monitoring Room Temperature ....................
9
1.4.1
System Overview ........................................
9
1.4.2
Environment .............................................
10
1.4.3
Temperature Sensor .....................................
11
1.4.4
Monitoring Logic ........................................
12
1.4.5
About Validation of Properties of Interest ..............
13
1.5
Conclusion ........................................................
14
Abstract. In this chapter we discuss formal modeling of environmental monitoring. Environ-
mental monitoring is needed to study complex environmental processes and to understand
the eﬀects of our actions in those processes. Environmental monitoring, however, is about
measuring, whereby it is prone to measurement errors. When measuring, there are many
sources for uncertainty. This makes it hard to estimate the total uncertainty. As the main
contribution, we investigate the use of action systems in modeling an environmental moni-
toring system together with sources for uncertainty. We use hybrid action systems, that is,
action systems with diﬀerential actions, to model both discrete-time and continuous-time
dynamics. We illustrate the approach by modeling the central function of a home monitor-
ing system, monitoring of room temperature. We also discuss, how properties of interest are
validated from the model.
3

4
From Action Systems to Distributed Systems: The Reﬁnement Approach
1.1
Introduction
Global trends, such as sustainability and cutting greenhouse gas emissions, have con-
tributed to the increasing need for implementing novel environmental measurement and
monitoring systems [278]. As pointed out by Messer et al. [242] “High-resolution, continu-
ous, accurate monitoring of the environment is of great importance for many applications
from weather forecasting to pollution regulation.” In short: what you cannot measure, you
cannot control.
However, as it was pointed out by Ward et al. [344] already in 1980’s, implementing
ever new measurement systems creates a problem. While new systems provide more data
with better accuracy, data is just data unless computational methods are used to obtain
information. In fact, Ward et al. call this the “data-rich but information-poor syndrome”.
The state of environmental monitoring is worse still than described. For instance, accord-
ing to Williams et al. [346], private weather stations produce data without any indication
of measurement errors. As argued by Williams et al. such data is useless, unless advanced
statistical methods are applied to it.
Assigning uncertainty estimates to measurement data is one way to improve the qual-
ity. Perhaps a more fundamental approach would be to model the sources for uncertainty.
However, for low-cost sensor technologies, fault and failure models are hard to come by.
Still, without such models, it is hard to estimate the potential sources for uncertainty for
the measurement devices and, thus, for the measurement data. Therefore, without fault and
failure models, assigning uncertainty estimates is still guesswork.
Having individual fault and failure models for the sensor, however, is not enough, as
an environmental monitoring system forms a complex ensemble. Without a model taking
this into account, assessing the total uncertainty is hard again. Therefore, as the main
contribution, we investigate here the use of hybrid action systems to model the sources for
uncertainty in an environmental monitoring system. With hybrid action systems, we can
model both continuous-time and discrete-time dynamics. Therefore, we can address a whole
range of sources for uncertainty, including non-deterministic dynamics of environmental
variables, variations associated with measurement activities, sporadic device failures, and
inaccuracies introduced by computational methods.
We introduce hybrid action systems in Section 1.2. In Section 1.3, we discuss environ-
mental monitoring and associated sources for uncertainty. In Section 1.4, we present a case
study involving monitoring of built environment. In the case study, we use hybrid action
systems to model room temperature monitoring together with the most central sources for
uncertainty. Room temperature monitoring is the main function in a home monitoring sys-
tem which is becoming ever more popular due to an increasing need for saving energy as
well as costs for heating and cooling. In Section 1.4, we also discuss provability of properties
of interest from the presented hybrid action system model.

Modeling Sources for Uncertainty in Environmental Monitoring
5
1.2
Hybrid Action Systems
Action systems were originally proposed by Back and Kurki-Suonio [27]. They are iter-
ated systems of actions based on Dijkstra’s guarded command language [113]. Action systems
were later used to model control systems [73], and extended with a diﬀerential action [280]
to characterize continuous-time dynamics. The resulting hybrid action systems [281] were
used to develop models of hybrid systems [147] by stepwise reﬁnement.
We shall now introduce hybrid action systems by deﬁning conventional actions and the
diﬀerential action. We then deﬁne action systems with diﬀerential actions, constituting hy-
brid action systems, and a parallel composition for hybrid action systems. Lastly, we deﬁne
stepwise reﬁnement use of action systems which also applies to hybrid action systems.
1.2.1
Conventional Actions
Conventional actions are used for capturing discrete-time dynamics. The meaning of
an action is deﬁned with a weakest precondition predicate transformer [113]. It returns a
predicate, the weakest precondition, for a given action and a postcondition predicate. The
predicate describes the largest set of states from which the execution of the action terminates
in a state satisfying a given postcondition. For a postcondition q, and an action A the weakest
precondition is denoted by wp(A, q).
An action is executed only if it is enabled. Formally, the set of states in which an action is
enabled is given by g(A) b= ¬wp(A, false). An action is said to be disabled in states ¬ g(A).
An executing action may either terminate or continue indeﬁnitely. The set of states from
which an action terminates is given by t(A) b= wp(A, true). An action is said to abort in
all those states from where it does not terminate, i.e., ¬t(A). The execution of an action
is atomic. Therefore, an action is executed to its completion before any other actions are
considered. Consequently, if an action aborts, no other action will be executed.
The weakest precondition semantics of the conventional actions [26, 38, 113] that we
consider here are given in Table 1.1. As for the actions, “Skip” keeps the state unchanged.
“Assignment” sets the values of the variables to the values of given expressions. “Non-
deterministic assignment” changes non-deterministically the values of the variables so that
a given condition holds. “Sequential composition” executes one action after another. “Non-
deterministic choice” selects arbitrarily one enabled action and executes it. “Guarded com-
mand” executes a guarded action, if the guard holds in the current state. “Iteration” executes
repeatedly an action till it becomes disabled.
1.2.2
Diﬀerential Action
The diﬀerential action was introduced by Rönkkö et. al [281]. It captures continuous-time
dynamics that is described as a diﬀerential relation with respect to an evolution guard. To
unfold the dynamics of the diﬀerential action, the diﬀerential relation, often expressed as
a system of diﬀerential equations, needs to be solved. The solution functions describe then
the continuous-time dynamics. In particular, if the solution functions satisfy the evolution
guard forever, the diﬀerential action never terminates. Correspondingly, the diﬀerential ac-
tion terminates, if the solution functions eventually reach a state that does not satisfy the
evolution guard.

Free ebooks ==>   www.Ebook777.com
6
From Action Systems to Distributed Systems: The Reﬁnement Approach
Table 1.1: Semantics of conventional actions
action
notation wp(action, q)
Skip
skip
q
Assignment
X := E
q[E/X]
Non-deterministic assignment X := χ.r ∀χ:r. q[χ/X]
Sequential composition
A;B
wp(A, wp(B, q))
Guarded command
p →A
p ⇒wp(A, q)
Non-deterministic choice
A [] B
wp(A, q) ∧wp(B, q)
Iteration
do A od
wp(µS. g(A)→A;S [] ¬ g(A)→skip, q)
Above, X are the model variables, and χ are bound variables disjoint from X. Also,
there are predicates p, q, and r. Lastly, A and B denote some actions and, in the
iteration, S is an action variable, and µS denotes the least ﬁxed point [38].
Let e, d, and q be predicates denoting an evolution guard, a diﬀerential relation, and a
post condition over variables X, respectively. Also, let φ denote a continuous function over
time. Then, the duration of φ with respect to the evolution guard e is deﬁned as:
∆(φ, e) b= inf{τ:IR ∩[0, ∞) | ¬e[φ(τ)/X]}
Such a φ is a solution function to the diﬀerential relation, only if its initial value equals to
the current values of the variables X and, from the initial state, it satisﬁes the diﬀerential
relation while it satisﬁes the evolution guard. This is captured by the predicate:
SF(φ, e, d) b= φ(0)=X ∧∀τ:IR ∩[0, ∞). (e⇒d)[φ(τ)/X, ˙φ(τ)/ ˙X]
With these two deﬁnitions, we can deﬁne the diﬀerential action, which is of form e : →d,
to have the weakest precondition semantics:
wp(e :→d, q)
b=
∀φ:C 1. SF(φ, e, d) ∧∆(φ, e)>0
⇒∆(φ, e)<∞∧q[φ(∆(φ, e))/X]
As noted by Rönkkö et. al [281], it is important to realize that the diﬀerential action
speaks only about observations of evolutions, not of time. For instance, if x denotes a lo-
cation, 0 ≤x ≤10 : →˙x = 10 speaks only about the location, not of the velocity or of
time. To include an observation of the passage of time we need a clock variable, t. Then,
0 ≤x ≤10 : →˙x = 10 ∧˙t = 1 speaks simultaneous about the location and time. From this
diﬀerential action we may also infer velocity.
1.2.3
Action Systems and Parallel Composition
An action system is an initialized block of the form [25]:
A b= | [ var X:T; X := E; do A1 [] .. [] An od ] | :V
The expression var X:T declares a set of variables X with types T. The variables consist of
local and shared variables. The shared variables are indicated with an asterisk, for instance
y∗. The variables imported from other action systems are listed as variables V . Thus, the
union of variables X and V forms the state space of A.
www.Ebook777.com

Modeling Sources for Uncertainty in Environmental Monitoring
7
The action X := E initializes all the variables X by constants E. Hence, the shared
variables are initialized in the action systems where they are declared. All action systems
initialize synchronously before any other action of A1..An is considered.
As our action systems are hybrid action systems, an action Ai of A1..An is either a
guarded command or a diﬀerential action. After initialization, an enabled action Ai is se-
lected non-deterministically for execution. The execution of Ai is always atomic, even for
composite or diﬀerential actions. Thus, other actions can be considered only after the exe-
cuted action terminates.
The entire action system A terminates, when all actions are disabled, i.e., ¬ g(A1 [] .. [] An).
Similarly, A aborts, if any executed action aborts.
The parallel composition of action systems was originally given by Back [25], and it is
formalized as follows. Consider the two action systems, where X and Y are disjoint variables
that can be either local or shared:
A
b=
| [ var X:T; X := E; do A1 [] .. [] Am od ] | :V
B
b=
| [ var Y :U; Y := I; do B1 [] .. [] Bn od ] | :W
Then, the parallel composition is given as:
A ∥B = | [ var X, Y :T, U;
X, Y := E, I;
do A1 [] .. [] Am [] B1 [] .. [] Bn od
] | :(V ∪W ) −(X ∪Y )
Thus, the parallel composition combines the state spaces of the two action systems, merging
the shared variables, and keeping the local variables distinct. Imported variables in V ∪W ,
that are deﬁned in either of the action systems, i.e., (X ∪Y ), are no longer imported. The
actions from the action systems are merged with a non-deterministic choice, modeling paral-
lelism by interleaving. Note that parallel composition is both associative and commutative.
1.2.4
Reﬁnement of Hybrid Action Systems
As hybrid action systems are action systems with diﬀerential actions, and as the diﬀer-
ential action has weakest precondition semantics, we can apply reﬁnement of action systems
also to hybrid action systems. For the reﬁnement of action systems, we consider a general
development step where an abstract action system A is shown to be weakly simulated [25]
by a concrete action system C. Informally this means that C has the same state changes over
the shared variables as A; however, C may include new intermediate state changes over the
local variables. Furthermore, as aborting is an undesirable behavior in a reactive setting, if
A aborts in a state, C may do anything in that state. Lastly, if A terminates in some state,
so does C.
The reﬁnement of action systems is formalized as data reﬁnement [25, 38] supporting the
use of a reﬁnement relation [25]. A reﬁnement relation is a predicate over all the variables,
and it is used for relating all the states of the concrete model to some states in the abstract
model. A reﬁnement relation r holds between an abstract action A and a concrete action C,
if C can reach the same states, related by r, from at least the same initial states, related by
r, as A. Then, A is reﬁned by C, and it is denoted by A ⊑r C. Data reﬁnement A ⊑r C
over an action A with local variables X and shared variables Z and an action C with local
variables Y and shared variables Z is deﬁned [25] as:
∀q:PRED(X, Z) . r ∧wp(A, q) ⇒wp(C, ∃X. r ∧q)

8
From Action Systems to Distributed Systems: The Reﬁnement Approach
As for the reﬁnement of action systems, consider a reﬁnement relation r, and the two
action systems:
A
b=
| [ var Z ∗, X:V , T • Z, X := O, E; do A od ] |
C
b=
| [ var Z ∗, Y :V , U • Z, Y := O, I; do C [] B od ] |
Then, A is weakly simulated by C, denoted by A ⪯r C, if the following proof obligations
are shown to hold [25]:
1. the initializations do not contradict the reﬁnement relation, i.e.,
r[O/Z, E/X, I/Y ]
2. the abstract actions A are reﬁned by the concrete actions C, i.e., A ⊑r C
3. the introduced intermediate actions B reﬁne stuttering in A, i.e.,
skip ⊑r B
4. the introduced actions are self-disabling, i.e., r ⇒t(do B od )
5. C does not terminate, unless A terminates as well, i.e.,
r ∧g(A) ⇒g(C [] B)
1.3
Environmental Monitoring
As mentioned in the introduction, we are already “ﬂooded” by environmental data due to
an increasing need for monitoring our environment. The data, however, comes mostly from
sensors and measurement systems for which the uncertainties are poorly understood, thus,
making the use of data questionable. Assigning uncertainty estimates, as done by Williams
et al. [346], is one way to improve the quality of environmental data.
The major challenge in environmental monitoring, however, is that the environmental
processes are poorly understood. The biggest reason for this is that the processes are complex
and open, and therefore inﬂuenced by external factors. In fact, the reason for measuring the
environment is to learn more about the processes.
The qualities of environmental processes are also often non-measurable. Therefore, in-
stead of the actual qualities of interest, indicators and other variables are measured. The
measured variables are then assumed to have a causal or statistical relationship to the qual-
ities of interest. Such relations are also often approximations.
In addition, there is often more than one way to measure the environmental variables of
interest. The choice of the measurement method depends on external factors and restrictions
imposed by end-user application or need. Furthermore, even for the same method, there are
typically several measurement devices and device manufacturers. This makes the merging
of data from several data sources challenging, as discussed by Williams et. al [346].
All this is further complicated by the need to measure the environmental variables from a
large spatial area and over a long period of time. Wide and continuous spatial and temporal
coverage, however, is not realistic, whereby sampling is used. There are several sampling
methods to choose from, and incomplete understanding of the environmental processes makes
it hard to choose the “optimal” sampling method.

Modeling Sources for Uncertainty in Environmental Monitoring
9
Lastly, all the measurements are prone to measurement errors. However, because of all
the previous challenges, it is hard to ensure that all measurement errors are accounted for.
In particular, it is very likely that for two diﬀerent measurement settings, two diﬀerent
mechanisms are used to compensate for the measurement errors. Again, this makes the
merging of data from several sources evermore challenging.
With hybrid action systems, we can address these sources for uncertainty by modeling
the monitoring system as a whole. The uncertainties associated with the continuous-time
dynamics can be embedded into diﬀerential actions. The uncertainties, faults, and failures
associated with discrete-time dynamics can be modeled with the conventional actions. In this
way, we can share our understanding of the dependencies formally, to support more accurate
and meaningful treatment of the measurement data. We shall illustrate this approach next.
1.4
Case Study: Monitoring Room Temperature
As the case study, we consider monitoring of room temperature. It is a basic function
of HVAC control system [21]. It is also the main function in a home monitoring system,
such as AsTEKa [308]. Home monitoring, or monitoring of built environment in general, has
recently become popular due to the availability of low-cost sensors and the ever increasing
need to save energy while improving indoor air quality.
We demonstrate here how hybrid action systems are used to model some of the most
prominent sources for uncertainty in a room temperature monitoring system. We start by
giving a system overview. We then present a hybrid action system model for each of the
subsystems. Lastly, we discuss which properties of the model are of interest and subject to
model-checking and rigorous proofs.
1.4.1
System Overview
The model for the room temperature monitoring system is composed of three subsystems:
the environment, the temperature sensor, and the monitoring logic. Each of the subsystems
will be modeled as an action system, and the overall model is then given as a parallel
composition.
The model of the environment, Environment, captures the absolute time, the measured
time, and the absolute room temperature. In particular, the measured time is modeled as
an inaccurate clock.
The model of the temperature sensor, Sensor, captures the measurement of the absolute
room temperature each 10 seconds and the delivering of the measured value to the monitoring
logic. In particular, the model embeds indirect and inaccurate temperature measurement.
Furthermore, the model includes a non-periodic sensor failure typical to low-cost sensor
technology.
The model of the monitoring logic, Monitor, exposes the measured room temperature, for
instance to HVAC control, as a preprocessed value. The value is exposed as an average of the
measured values over a sliding window of 60 seconds. In particular, the model compensates
for the measurement inaccuracies by discarding measurement values that deviate “too much”
from the current average. A counter is used to record the number of discarded measurement
values for potential diagnostic purposes.

10
From Action Systems to Distributed Systems: The Reﬁnement Approach
The overall model of the room temperature monitoring system is given by the parallel
composition:
System b= Environment || Sensor || Monitor
We shall now continue by describing each of the subsystems in more detail.
1.4.2
Environment
The model of the environment captures three continuous-time dynamics: the absolute
time, the measured time, and the absolute room temperature. The absolute time is con-
sidered ideal and accurate. The measured time is considered inaccurate, and it may drift.
The absolute room temperature is also considered as the ideal evolving value. The room
temperature is assumed to be subject to control, where the objective is to keep it within
[20, 23] Celsius. Since we do not explicitly model the control here, we embed its eﬀect to the
model of the environment. We assume a control logic that avoids hysteresis. Thus, we assume
that the control switches on heating, when the room temperature drops below 20 Celsius.
Correspondingly, the control switches on cooling, when the room temperature exceeds 23
Celsius. Furthermore, we assume that the heating and cooling are mutually exclusive, and
that the room temperature can always be maintained within the range of [19, 24] Celsius.
In the model, there are three real valued variables. The absolute time is denoted by a
variable T, and its dynamics is given by ˙T =1. The inaccurate clock measuring the passage of
time is denoted by a variable t. Since t may drift, its dynamics are given by ˙t ∈[0.999, 1.001].
The absolute room temperature is denoted by a variable c. We assume that a room can be
heated by at most 1 Celsius in 100 seconds and cooled by at most 1 Celsius in 1000 seconds.
Then, the dynamics of the room temperature is given by ˙c ∈[−0.001, 0.01].
The model, Environment, is shown below. Initially, the absolute time and the measured
time is set to 0, and the room temperature is set to 20. The dynamics of the environment is
captured by three diﬀerential actions. All the evolutions are limited by the condition t<10.
The reason for this is that the temperature sensor is to measure the room temperature each
10 seconds. The clock t is used to measure this passage of time. The ﬁrst diﬀerential action
captures the dynamics, where the room temperature is free to change within the allowed
range of [19, 24] Celsius. The second diﬀerential action captures the case, where the room
temperature drops below 20 Celsius. Then, the heating is switched on and the dynamics
is given by ˙c ∈(0, 0.01]. The third diﬀerential action captures the case, where the room
temperature exceeds 23 Celsius. Then, the cooling is switched on, and the dynamics are
given by ˙c ∈[−0.001, 0). The (non-deterministically) combined dynamics of these three
diﬀerential actions captures behavior, where room temperature is free evolve within the
range of [19, 24] Celsius, but the measured time t advances always to the value 10. After
that all the diﬀerential actions become disabled allowing the actions of the sensor model
to take place. Note, however, that the measured 10 seconds may not be the “absolute” 10
seconds, as t may drift.

Free ebooks ==>   www.Ebook777.com
Modeling Sources for Uncertainty in Environmental Monitoring
11
Environment b=
| [ var T ∗, t∗, c∗:IR, IR, IR
T, t, c := 0, 0, 20;
do t<10 ∧19<c<24 :→˙T =1 ∧˙t ∈[0.999, 1.001] ∧˙c ∈[−0.001, 0.01]
[] t<10 ∧c<20
:→˙T =1 ∧˙t ∈[0.999, 1.001] ∧˙c ∈(0, 0.01]
[] t<10 ∧23<c
:→˙T =1 ∧˙t ∈[0.999, 1.001] ∧˙c ∈[−0.001, 0)
od
] |
1.4.3
Temperature Sensor
The model of the temperature sensor captures the indirect and inaccurate measurement
of the absolute room temperature. Thus, the measurement is subject to inaccuracies caused
by the indirect measurement method, device dependent static noise and drifting, as well as
environmental disturbances. We assume that the measurement error caused by the indirect
measurement method, the device dependent static noise, and the environmental disturbances
falls within [−1, 1] Celsius. We also assume that the measurement value drifts at most 0.8
Celsius in one year. Moreover, we assume that the drifting aﬀects also the measurement
accuracy so that after one year, the total accuracy of a measurement falls within [−1.8, 1.8]
Celsius. Such a deviation is not uncommon to low-cost sensor devices. Lastly, we assume that
the sensor has a non-periodic failure rate of one failure within [2, 24] hours. Thus, the sensor
is certain to provide an unreliable measurement within 24 hours, but after such failure, it is
certain to provide reliable measurements for at least 2 hours.
In the model, there are three variables. The number of delivered reliable measurements
is denoted by a variable n. It is used to model the sporadic device failure. A ﬂag variable s
is used to indicate that room temperature has been measured, but not read, yet. The actual
measurement value is denoted by a variable m. The model also refers to all environmental
variables, T, t, and c. Lastly, the model refers to a monitor variable in indicating that a
measurement value is available for the monitoring logic for further processing.
The model, Sensor, is shown below. Initially, the number of delivered reliable measure-
ments is set to 0, the reading ﬂag s is set to false, and the measured value is also set to 0.
The value of the monitor variable in is assumed to be false initially. The measurement logic
is then modeled by using three actions. The ﬁrst action captures the actual measurement. It
can occur only 10 seconds after the most recent measurement, as indicated by t. The action
models indirect and inaccurate measurement of the room temperature c with the variable
m. The drifting, ι, of the measurement value over time is captured with a log2(T) term.
As discussed, the drifting also aﬀects the measurement accuracy, ς, whereby the resulting
inaccurate measurement is captured by m := c+ι+ς.(ι=log2(T) ∧ς ∈[−1−ι, 1+ι]).
The ﬁrst action also sets the value of the ﬂag s to true indicating that a measurement is
taken. The second action captures the occurrence of a sporadic failure. As this may occur
2 hours after the most recent failure, and measuring occurs each 10 seconds, the number of
reliable measurements, n, must be at least 720 for the failure to occur. Then, the measured
value is set to any value within the range [−50, 50] Celsius, and the number of reliable
measurements is reset. The third action captures the case, when the measurement is delivered
to the monitoring logic. Since the sensor is certain to fail once in 24 hours, there can be at
most 8640 successive, reliably delivered measurements as indicated by n. The actual delivery
of a measurement is indicated by setting the value of the monitor variable in to true and
the ﬂag variable s to false. Note that the choice between the actions is non-deterministic, so
www.Ebook777.com

12
From Action Systems to Distributed Systems: The Reﬁnement Approach
the second and the third actions together capture the failure dynamics of the sensor. Note
also that once the third action is executed, all the actions of the environment model remain
disabled and all the actions of the sensor model become disabled allowing the actions of the
monitoring logic to take place.
Sensor b=
| [ var n, s, m∗:IN, IB, IR
n, s, m := 0, false, 0;
do t ≥10 ∧¬ s ∧¬ in →m := c+ι+ς.(ι=log2(T) ∧ς ∈[−1−ι, 1+ι]);
s := true
[] s ∧¬ in ∧720<n →m := ς.(ς ∈[−50, 50]);n := 0;
[] s ∧¬ in ∧n<8640 →n := n+1;s,in := false,true
od
] | :T, t, c, in
1.4.4
Monitoring Logic
The model of the monitoring logic captures the exposure of the measured room tem-
perature as an averaged value over a sliding window of 60 seconds. It also captures the
compensation for measurement errors by discarding values that deviate more than 2 Cel-
sius degrees from the computed average. Such values are likely to be measurement errors.
The number of discarded values is also recorded, and exposed, for potential diagnostic pur-
poses. Note that the computation of the average value requires the storing of at most 6
measurement values, because the temperature sensor measures a value each 10 seconds.
In the model, there are ﬁve variables. The variable in indicates that a measurement is
taken by the sensor and that the measurement value is available to the monitoring logic.
The exposed averaged room temperature value is denoted by a variable avg. The number of
discarded measurement values is denoted by a variable dev. The most recent measurement
values for computing the average are kept in a sequence of real valued number denoted by
a variable d. Lastly, the number of measurement values used for computing the exposed
average value is denoted by a variable n. Thus, if the value of n diﬀers from the length of
the sequence d, denoted by #d, there is a new recorded measurement value and the average
value needs to be recomputed. In addition, the model refers to the sensor model variable m,
which is the measured room temperature. The model also refers to the clock variable t of
the environment model.
We use here two sequence operators. Consider a value m and a sequence d consisting
of n values ⟨v1, v2, ...vn⟩, where a value mi in the sequence is referred to as d(i). Then,
the concatenation of a value m to the end of the sequence d, denoted by d ⊕m, is deﬁned
as ⟨v1, v2, ...vn, m⟩. The tail operator, denoted by tail(d) returns a sequence, where the ﬁrst
value in the sequence is omitted. Thus, for the sequence d, the tail operator tail(d) is deﬁned
as the sequence ⟨v2, ...vn⟩.
The model, Monitor, is shown below. Initially, the ﬂag variable in is set to false, the
(computed) average room temperature is set to 20, the number of deviating measurements
is set to 0, the sequence of most recent measurement values is set to contain one value,
20, and the number of measurement values used for computing the average value is set to
1. The ﬁrst action captures the case, where a reliable measurement value is taken by the
sensor and made available to the monitor. Then, the measured value is appended to the
end of the sequence of measurement values, d. This also disables the action, as the equality
n =#d no longer holds. The second actions captures the case, where the sensor provides a

Modeling Sources for Uncertainty in Environmental Monitoring
13
measurement value that is deviating too much from the average. Then, the measured value
is discarded, current average is appended to the end of the sequence of measurement values,
and the number of rejected measurements is incremented. The third action ensures that
the sequence of measured value contains only at most 6 values. This is done by removing
the least recent measurement value from the sequence. Lastly, the fourth action updates
the average, and resets both the clock t and the variable in. Then, all the actions of the
monitoring logic become disabled, and at least one of the actions of the environment model
becomes enabled, allowing the environment model to advance again.
Monitor b=
| [ var in∗, avg∗, dev∗, d, n:IB, IR, IN, ⟨IR⟩, IN
in, avg, dev, d, n := false, 20, 0, ⟨20⟩, 1;
do in ∧n =#d ∧| avg−m | ≤2 →d := d ⊕m
[] in ∧n =#d ∧| avg−m | >2 →d := d ⊕avg;dev := dev+1
[] in ∧n ̸=#d ∧#d>6
→d := tail(d);n := n−1
[] in ∧n ̸=#d ∧#d ≤6
→n := #d;avg := 1
n
Pn
i=1 d(i);
t, in := 0, false
od
] | :m, t
1.4.5
About Validation of Properties of Interest
The most important property in the presented model is the accuracy of the measure-
ment value. The presented model accounts both external and internal sources for uncer-
tainty. Thus, we can use it to study the eﬀect of the accuracy to an application objective,
such as HVAC control objective, by extending the application logic. In an ideal case, such
an analysis could be performed by model-checking [279], for instance, by using statistical
model-checking, such as UPPAAL-SMC [69]. In a generic case, numerical simulation may
be required.
Similar analysis methods could also be used to analyze drifting of the measured time.
The use of an inaccurate clock for measuring the passage of time may not be an issue for a
control application. However, when considering applications that require measurement data
over a long period of time, inaccuracies in the measurement time do cause challenges. For
instance, training of an anomaly detection algorithm may strongly be aﬀected by temporal
deviations in the training data, causing malfunctioning detection or, in the worst case, failing
of the training altogether. For such a case, the presented model could be used to analyze
alternative methods to account for the inaccuracies in the measurement time. For instance,
the presented model could be adjusted by averaging the measurement values over a longer
period of time, to see if such a change compensates for the drifting of the measured time.
Perhaps the biggest advantage of the presented model is that it can be subject to reﬁne-
ment [32, 282, 281]. Then, for instance, prior to system upgrading, the sensor model could be
reﬁned, to account for more advanced sensor technologies. Similarly, the monitoring model
could be reﬁned to account for more detailed and versatile monitoring logic. In case the
reﬁnement proofs succeed, we know that the overall room temperature monitoring system
is still provably correct despite the modeled changes.
Here, however, we explore the opposite of reﬁnement, coarsement [300], in simplifying
the validation task. In case of the room temperature monitoring, the use of the diﬀerential
actions prohibits use of, for instance, theorem provers [340] in the validation. By using

14
From Action Systems to Distributed Systems: The Reﬁnement Approach
coarsement, we can provide a more abstract, provable correct model of the environment,
where the diﬀerential actions are substituted with non-deterministic assignments. Such an
action system can then be analyzed with a theorem prover. The abstract model of the
environment, AnEnvironment , is shown below. For clarity, the relation between absolute
time, T, its update γ, measured time t, and its update τ is given as a relation Γ(T, γ, t, τ)
which is deﬁned as 0.999(τ −t) ≤γ −T ≤1.001(τ −t). It can be proven by using data
reﬁnement that AnEnvironment ⪯true Environment indeed holds. A similar proof was
presented and discussed in an earlier article [281]. In short, the proof relies on the fact that
a diﬀerential action terminates at the boundary of its evolution guard. Hence, the updated
values for the variables must be some of the boundary values.
AnEnvironment b=
| [ var T ∗, t∗, c∗:IR, IR, IR
T, t, c := 0, 0, 20;
do t<10 ∧19<c<24
→T, t, c := γ, τ, ς.
Γ(T, γ, t, τ) ∧t<τ ≤10 ∧19≤ς ≤24 ∧(τ =10 ∨ς =19 ∨ς =24)
[] t<10 ∧c<20
→T, t, c := γ, τ, ς.
Γ(T, γ, t, τ) ∧t<τ ≤10 ∧ς ≤20 ∧(τ =10 ∨ς =20)
[] t<10 ∧23<c
→T, t, c := γ, τ, ς.
Γ(T, γ, t, τ) ∧t<τ ≤10 ∧23≤ς ∧(τ =10 ∨ς =23)
od
] |
1.5
Conclusion
We proposed the use of hybrid action systems to model the sources for uncertainties
in environmental monitoring. We illustrated the approach by modeling a room tempera-
ture monitoring system. In the model, we formally modeled the most prominent sources for
uncertainty, including non-determinism associated with the dynamics of the environmental
variables, external variations associated with measuring temperature, drifting of measure-
ment clocks, sporadic device failures, and inaccuracies introduced by computational meth-
ods. The advantage of modeling environmental monitoring systems by using hybrid action
systems, is the support for rigorous proofs about the properties of the model. Reﬁnement can
be applied to maintain the model with respect to system upgrades and changing end-user
requirements. Alternatively, coarsement can be used to abstract away details to enable use
of validation tools, such as theorem provers.
Acknowledgments. This research is funded by the Academy of Finland project
“FResCo: High-quality Measurement Infrastructure for Future Resilient Control Systems”
(Grant number 264060).

Chapter 2
Mandatory and Potential Choice:
Comparing Event-B and STAIRS
Atle Refsdal
SINTEF ICT, Norway
Ragnhild Kobro Runde
University of Oslo, Norway
Ketil Stølen
SINTEF ICT, Norway and University of Oslo, Norway
2.1
Introduction ......................................................
16
2.2
Kinds of Choice ..................................................
17
2.3
Comparing Event-B and STAIRS at the Syntactic Level .......
19
2.4
Interaction-Obligations versus Failure-Divergences ..............
22
2.4.1
Interaction-Obligations ..................................
23
2.4.2
Failure-Divergences ......................................
24
2.4.3
Relating the Two Models ................................
25
2.4.4
Sets of Interaction-Obligations ..........................
25
2.5
Conclusion ........................................................
26
Abstract. In order to decide whether a software system fulﬁlls a speciﬁcation, or whether
a detailed speciﬁcation preserves the properties of a more abstract speciﬁcation, we need an
understanding of what it means for one speciﬁcation to fulﬁll another speciﬁcation. This is
particularly important when the speciﬁcation contains one or more operators for expressing
choice. Operators for choice have been studied for more than three decades within the ﬁeld
of formal methods in general, and within methods for action-reﬁnement in particular. In
this paper we focus on Event-B, a more recent method for action reﬁnement. The STAIRS
method belongs to another tradition. It originates from the UML community and is designed
to provide an understanding of reﬁnement and fulﬁllment for UML. STAIRS distinguishes
between potential and mandatory choice, where only the latter is required to be preserved
by reﬁnement. This paper investigates the relationship between the operators for choice in
Event-B and STAIRS.
15

Free ebooks ==>   www.Ebook777.com
16
From Action Systems to Distributed Systems: The Reﬁnement Approach
2.1
Introduction
In order to decide whether a software system fulﬁlls a speciﬁcation, we need a clear
understanding of the concept of fulﬁllment. Similarly, when a speciﬁcation is developed
further into a new more detailed (for example, platform-speciﬁc) speciﬁcation, the essential
properties captured by the original speciﬁcation must still be present in the new speciﬁcation.
This requires an understanding of what it means for one speciﬁcation to fulﬁll another
speciﬁcation.
STAIRS [156, 288] was designed to provide the UML community with this kind of un-
derstanding at a level of abstraction that is easily comprehensible for UML practitioners.
STAIRS is inspired by formal methods and reﬁnement theory. However, STAIRS is not really
a formal method in the classical sense, as explained in the following. When formal methods
are combined with more applied methods for software engineering, the resulting approaches
may typically be classiﬁed according to whether:
• Artifacts of the applied method, typically speciﬁcations and models, are translated
into the formal method and used for formal analysis.
• Artifacts of the applied method, again normally speciﬁcations and models, are anno-
tated with formal expressions and used for formal analysis building on some uniﬁed
underlying semantics.
STAIRS does not ﬁt within this classiﬁcation scheme since the emphasis of STAIRS is to
provide a foundation for fulﬁllment within the conceptual universe of UML rather than
supporting formal analysis of UML speciﬁcations and their relationships.
STAIRS addresses primarily sequence diagrams. Implicitely, STAIRS also deﬁnes the
notion of fulﬁllment for the other UML notations for modeling dynamic behavior, where
the behavior may be captured by sets of sequence diagrams. In many respects, sequence
diagrams are more general than other UML notations for dynamic behavior, e.g., state
machines, because sequence diagrams may be used to describe examples of required behavior,
rather than the complete allowed behavior. STAIRS provides this expressiveness by oﬀering
operators for potential as well as mandatory choice.
Operators for choice have been studied for more than three decades within the ﬁeld of
formal methods in general, and within methods for action-reﬁnement in particular [32]. A
prominent example of a method for action-reﬁnement is Event-B [6]. The objective of this
paper is to investigate the relationship between the operators for choice in Event-B and
STAIRS.
A large literature exists on Event-B. There are no ﬁxed semantics for Event-B, instead
the semantics are provided implicitly by proof obligations associated with a model [152].
Nevertheless, several papers have suggested failure-divergences inspired semantics as a for-
mal underpinning [293, 71, 305]. This paper builds on this approach. Failure-divergences
semantics was originally developed for CSP [171]. In Section 2.2 we therefore start our in-
vestigation by comparing choice in CSP to choice in STAIRS. Then we conduct a comparison
of Event-B and STAIRS; ﬁrst at the syntactic level in Section 2.3; then at the semantic level
in Section 2.4. Finally, Section 2.5 provides a summary and draws conclusions.
www.Ebook777.com

Mandatory and Potential Choice: Comparing Event-B and STAIRS
17
Preserved
CSP
STAIRS
by reﬁnement
environment
system
No
Internal choice
Potential choice
Demonic choice
Yes
External choice
Mandatory choice
Angelic choice
Table 2.1: Choice types in CSP and STAIRS
2.2
Kinds of Choice
In this section, we relate the kinds of choice oﬀered by CSP [171] and STAIRS [156].
We also classify the kinds of properties that may or may not be captured depending on the
available choice operators.
In order to understand the choice operators in CSP we need to understand some un-
derlying assumptions about the involved entities, as well as the communication model. As
explained by [284, p. 13], in CSP a system1 is completely described by the way it can com-
municate with its environment. Hence, CSP assumes a black-box view where internal com-
munication within the system itself is hidden. Communication is synchronous (also known
as handshake communication), meaning that “events only happen when both sides agree”
[284, p. 9]. This can be understood as follows: At any given point the system oﬀers a set of
events to the environment. If the environment accepts one of these events then the system
moves on, otherwise a deadlock occurs.
Choices made by the environment between available alternatives are called external
choices and represented by the 2 operator in CSP, while choices made by the system are
called internal2 and represented by the ⊓operator. If one of the alternatives oﬀered to the
environment is removed, a deadlock will be introduced if the environment is willing to syn-
chronize only on the removed alternative. Reﬁnement in CSP therefore requires preservation
of external choice. Internal choice, on the other hand, represents underspeciﬁcation and may
be reduced in a valid reﬁnement step, as motivated by the following quote [171, p. 101–102]:
Sometimes a process has a range of possible behaviours, but the environment of
the process does not have any ability to inﬂuence or even observe the selection
between the alternatives [. . . ] The choice is made, as it were internally, by the
machine itself, in an arbitrary or nondeterministic fashion [. . . ]
There is nothing mysterious about this kind of nondeterminism: it arises from a
deliberate decision to ignore the factor which inﬂuence the selection [. . . ] Thus
nondeterminism is useful for maintaining a high level of abstraction in descrip-
tions of the behaviour of physical systems and machines [. . . ]
A process speciﬁed as (P ⊓Q) can be implemented either by building P or by
building Q. The choice can be made in advance by the implementor on grounds
not relevant (and deliberately ignored) in the speciﬁcation [. . . ]
1The CSP literature typically uses the term “process”.
2Hoare uses the term “nondeterministic or” or just “nondeterminism” for internal choice.

18
From Action Systems to Distributed Systems: The Reﬁnement Approach
The term angelic choice (or angelic nondeterminism) is sometimes used to describe a
choice that will always be made so that an undesirable result (a deadlock) is avoided if
possible. Hoare explains this in terms of an implementation that, when choosing between P
and Q, “minimises the risk of deadlock by delaying the choice until the environment makes it,
and then selecting whichever of P and Q does not deadlock” [171, p. 105]. Similarly, Roscoe
explains angelic choice in terms of an operator that “keeps on giving the environment the
choice of action of P and Q as long as the environment picks an event they both oﬀer” [285,
p. 219]. Hence, angelic choice is a special kind of external choice. Conversely, although not
used in the above references, the term demonic choice can be used to describe an internal
choice that will (or at least can) be made so that a deadlock will occur, if possible. In [248],
Morgan et al. use the terms demonic choice and internal choice interchangeably.
The two middle columns of Table 2.1 summarize the above discussion. The system column
represents choices resolved by the speciﬁed system, while the environment column represents
choices resolved by its environment. The column furthest to the left indicates whether choices
are preserved by reﬁnement.
According to [156], STAIRS is an approach to compositional development of UML in-
teractions that assigns a precise interpretation to the various steps in incremental system
development based on an approach to reﬁnement known from the ﬁeld of formal methods.
There are a couple of ways in which STAIRS diﬀers from CSP of immediate relevance for
our discussion of choice here. First, STAIRS assumes an asynchronous communication model
with inﬁnite buﬀering, and is therefore not concerned with deadlock. Second, in STAIRS
there is no implicit hiding of internal communication when composing speciﬁcations.
STAIRS oﬀers two diﬀerent choice operators: one for potential choice and one for manda-
tory choice. Along the same lines as internal choice in CSP, potential choice is motivated by
the need for abstraction. This is explained by the following requirement to STAIRS stated
in [156]:
Should allow speciﬁcation of potential behavior. Underspeciﬁcation is a well-
known feature of abstraction. In the context of interactions, “under-speciﬁcation”
means specifying several behaviors, each representing a potential alternative serv-
ing the same purpose, and that fulﬁlling only some of them (more than zero but
not all) is acceptable for an implementation to be correct.
Mandatory choice, on the other hand, is motivated as follows:
Should allow speciﬁcation of mandatory behavior [. . . ] Sometimes [. . . ] it is es-
sential to retain non-determinism in the implementation reﬂecting choice. For
example, in a lottery, it is critical that every lottery ticket has the possibility
to win the prizes [. . . ] As a consequence, we need to distinguish explicit non-
determinism capturing mandatory behavior from non-determinism expressing
potential behavior.
Since potential choice facilitates underspeciﬁcation by oﬀering alternatives serving the same
purpose, STAIRS allows potential choice to be reduced or removed by reﬁnement. A manda-
tory choice, on the other hand, needs to be preserved in order to ensure that all intended
behavior will be implemented. This applies regardless of whether the choice is made by the
system or by the environment. The distinction between potential and mandatory choice in
STAIRS is summarized in the right-hand column of Table 2.1.
Another kind of choice is probabilistic choice, meaning that each alternative should be
selected according to a given probability. Probabilistic choice is beyond the scope of this

Mandatory and Potential Choice: Comparing Event-B and STAIRS
19
paper and has therefore not been included in Table 2.1. However, mandatory choice (as
understood in STAIRS) can be understood as probabilistic choice where all of the prob-
abilities should be higher than 0, but where nothing more is known/speciﬁced about the
probabilities.
The constructs for expressing choice oﬀered by a speciﬁcation language and its notion
of reﬁnement restrict the kinds of properties that can be captured. System properties are
typically analyzed on the basis of system traces, each of which characterizes a possible run
or execution. Properties can then be classiﬁed according to their means of falsiﬁcation.
Properties that can be falsiﬁed by a tester on the basis of a single trace are called trace
properties, while properties that can be falsiﬁed on the basis of trace sets are called trace set
properties [241]. The former include safety and liveness as originally investigated by Alpern
and Schneider [14, 292]. The latter include information security ﬂow properties and are what
McLean referred to as possibilistic properties [241].
As an example, assume we want to specify a simulator to simulate user behavior for
automatic testing of vending machines oﬀering tea and coﬀee. The simulator should then be
able to choose both alternatives, and the choice should be made internally by the simulator
(thus reﬂecting a user’s preference) rather than by its environment. Before using the sim-
ulator to automatically test a vending machine, we need to test the simulator itself. When
testing the simulator, if we observe a single trace yielding tea, we cannot deduce that the
simulator is not able to choose coﬀee or vice versa; such falsiﬁcations can only be made by
considering all traces of the system.
Speciﬁcation approaches allowing all choices made internally by the speciﬁed system (as
opposed to its environment) to be reduced by reﬁnement, have no means to ensure that
trace set properties are preserved. This is referred to as the reﬁnement paradox in [198]. In
the following, we discuss the syntax and semantics of choice in Event-B and STAIRS in the
light of trace properties and trace set properties.
2.3
Comparing Event-B and STAIRS at the Syntactic Level
The essence of an Event-B speciﬁcation is a set of guarded events, where an event is
enabled and may be chosen to occur when its guard is true. More than one event may be
enabled at the same time, and the choice between enabled events is an external choice made
by the environment. Internal choice made by the system itself is modeled more indirectly,
using nondeterministic assignment to internal variables in order to inﬂuence the enabledness
of other events.
As an example of how choice is treated in Event-B, in Figure 2.1 we look at the two
vending machine speciﬁcations given by Butler in [71]. An Event-B speciﬁcation consists of
a speciﬁcation name, a declaration and initialization of variables and a set of named events.
Each event is on the form when guard then body end, where the guard is a boolean state-
ment over the variables and the body is a (possibly non-deterministic) variable assignment.
An event is said to be enabled if its guard evaluates to true, otherwise it is disabled.
The diﬀerence between the two speciﬁcations in Figure 2.1 is that in VM1, the internal
variable m1 is set to vend after the Coin event has been executed, thus enabling both the
Tea and the Coffee event, while in VM2, the internal variable m2 is set to either tea or
coﬀee, thus enabling only one of Tea and Coffee. This means that in VM1, the choice

20
From Action Systems to Distributed Systems: The Reﬁnement Approach
machine VM1
variables m1
{idle,vend}
initialisation
m1 := idle
events
Coin ≙
when
m1 = idle
then
m1 := vend
end
Tea ≙
when
m1 = vend
then
m1 := idle
end
Coffee ≙
when
m1 = vend
then
m1 := idle
end
machine VM2
variables m2
{idle,tea,coffee}
initialisation
m2 := idle
events
Coin ≙
when
m2 = idle
then
m2 :
{tea,coffee}
end
Tea ≙
when
m2 = tea
then
m2 := idle
end
Coffee ≙
when
m2 = coffee
then
m2 := idle
end
Figure 2.1: Two Event-B vending machines as speciﬁed by [71]
between Tea and Coffee is to be made by the environment, and is thus an example of
external choice. In [71], it is argued that from a customer’s point of view, this external choice
should be preserved by reﬁnement, meaning that VM2 should not be a valid reﬁnement of
VM1. This could be achieved for instance by requiring that a reﬁnement should preserve
the enabledness of individual events.
In VM2, the choice between Tea and Coffee is made by the machine itself, and this
is an example of internal choice. An internal choice may be reﬁned by an external choice,
as this ensures that all events enabled in the original machine will also be enabled in the
reﬁned one. Consequently, VM1 should be a valid reﬁnement of VM2.
As an example of potential choice in STAIRS, Figure 2.2 gives a sequence diagram
speciﬁcation of a vending machine with messages that correspond to the events in VM1
and VM2 from Figure 2.1. The main ingredients of a sequence diagram are a set of lifelines
(depicted as vertical lines) and a number of messages (arrows) between the lifelines. In
Figure 2.2, the choice operator alt is used to signify that this diagram speciﬁes two example
scenarios, both starting with the vending machine receiving a coin from the environment,
followed by the vending machine providing tea in one scenario, coﬀee in the other. As alt
is used to model potential choice, a sequence diagram where only one of these scenarios is
positive, and the other one is speciﬁed as negative, would be a valid reﬁnement of Vending
Machine 1.
In STAIRS, there is no fundamental distinction between internal and external choice.
The choice between sending Tea or Coffee in Figure 2.2 is an internal choice when seen
from the sending lifeline VM, and an external choice when seen from the receiving lifeline
Env. For a real vending machine, the choice between tea and coﬀee would be made by the

Free ebooks ==>   www.Ebook777.com
Mandatory and Potential Choice: Comparing Event-B and STAIRS
21
Env
VM
Coin
sd Vending Machine 1
alt
Tea
Coffee
Figure 2.2: A simple vending machine with potential choice in STAIRS
user. In STAIRS, this may be modeled for instance by selection messages from Env to VM
as seen in Figure 2.3. Note, however, that the choice between the two alternatives is still
speciﬁed using alt, meaning that in a valid implementation, only one of the tea and coﬀee
scenarios may be present.
Back to Event-B, Butler [71] argues that experience with Event-B modeling has demon-
strated the need to be able to model both internal and external choice between enabled
events more directly, in particular in situations where the guards are equal only as a result
of abstraction. In reality, such a choice is not really external, but rather internal due to some
condition not included in the abstract speciﬁcation.
For instance, the choice between Tea and Coffee in VM1 in Figure 2.1 should in some
cases be seen as internal due to some condition abstracted away in VM1. A reﬁnement may
for instance add internal variables and guards so that coﬀee is always served in the morning,
while tea is always served in the afternoon.
In [71], the main goal is to allow both external and internal choice to be represented
directly. This is achieved by letting the speciﬁer divide the events into groups. The intuitive
interpretation is that a choice between groups of events is external, while a choice between
events within a group is internal. For VM1 in Figure 2.1, the speciﬁer may state that the
choice between Tea and Coffee is internal by grouping them together, giving the following
event groups for VM1: G= {Coin}, G= {Tea, Coffee}.
In [71], the reﬁnement relation is modiﬁed so that preservation of enabledness is pre-
served for event groups rather than for single events, thus ensuring that external choices are
preserved (or increased) through reﬁnement while at the same time allowing the amount of
internal choice to be reduced. With the event groups Gand Ggiven above, this would
mean that a valid reﬁnement of VM1 may choose to oﬀer only Coffee (or Tea).
Mandatory choice is not discussed in [71], and the introduction of event groups is not
suﬃcient to capture system choices that must be preserved by reﬁnement, i.e., trace set
properties. Assume, for illustration purposes, that the speciﬁer wants to model a machine
which arbitrarily chooses between tea and coﬀee at run-time (similar to the user simulator
described in Section 2.2). As putting Tea and Coffee in the same event group might lead
www.Ebook777.com

22
From Action Systems to Distributed Systems: The Reﬁnement Approach
Env
VM
Coin
sd Vending Machine 2
alt
Tea
Coffee
SelectTea
SelectCoffee
Figure 2.3: A simple vending machine with external choice in STAIRS
to an implementation oﬀering only one of them as seen above, the only other possibility is
to put them in separate event groups. However, the semantics of such a speciﬁcation would
allow Tea (and similarly, Coffee) to be refused only when its guard is false, meaning that
neither Tea nor Coffee could be refused after Coin, so that the choice between the two
remains external and not internal.
A vending machine where the internal choice is made arbitrarily as described above,
may be modeled in STAIRS by using the mandatory choice operator xalt as shown in
Figure 2.4. To simplify the main diagram Vending Machine 3, the diagram refers to
two sub-diagrams Provide tea (also provided in Figure 2.4) and Provide coffee (not
shown, but symmetrical to Provide tea). The refuse operator is used to model that a spe-
ciﬁc alternative should be considered negative, e.g., in Provide tea the vending machine
should serve tea and not coﬀee. The main diagram Vending Machine 3 then requires the
vending machine to have two mandatory behaviors, one with tea and not coﬀee, and one
with coﬀee and not tea. Neither of these can be removed by reﬁnement. Also, the manda-
tory choice in Vending Machine 3 in Figure 2.4 is a valid reﬁnement of the potential
choice in Vending Machine 1 in Figure 2.2, as should be expected. Further reﬁnements
may increase the mandatory behavior required by adding more xalt-operands, e.g., a third
alternative providing chocolate but not tea or coﬀee.
2.4
Interaction-Obligations versus Failure-Divergences
In the previous section, we compared Event-B and STAIRS at the syntactic level. Se-
mantically, an Event-B speciﬁcation may be represented by a failure-divergences pair while a

Mandatory and Potential Choice: Comparing Event-B and STAIRS
23
Env
VM
Coin
sd Vending Machine 3
xalt
Env
VM
sd Provide tea
Tea
Coffee
alt
refuse
ref
Provide tea
ref
Provide coffee
Figure 2.4: Mandatory choice in STAIRS
sequence diagram in STAIRS corresponds to a set of interaction-obligations. If the sequence
diagram does not contain mandatory choice, a single interaction-obligation is suﬃcient. In
the following, we outline the intuition behind interaction-obligations and failure-divergences
and how they are related. We also explain how mandatory choice is represented semantically
and discuss the relationship to external choice.
2.4.1
Interaction-Obligations
A trace in STAIRS is a ﬁnite or inﬁnite sequence of events where an event is either the
sending or the reception of a message. A trace is required to fulﬁll certain well-formedness
conditions [287]. Informally, a trace is well-formed if, for each message, the send event is
ordered before the corresponding receive event.
Let H denote the set of all well-formed traces. An interaction-obligation is a pair (p, n)
of trace-sets which classiﬁes the elements of H into three categories: the positive traces p,
the negative traces n, and the inconclusive traces H\(p ∪n). The inconclusive traces are
those traces that are neither speciﬁed as positive nor as negative by the sequence diagram
in question.
A pre-post speciﬁcation (pre, post) in Hoare-logic may be used as a ﬁrst approximation
of the intuition behind an interaction-obligation (p, n). Roughly speaking:
• A positive trace (in p) corresponds to an execution initiated in a state fulﬁlling pre that
if it terminates, does so in state fulﬁlling post (given Hoare-logic for partial correctness).
• An inconclusive trace (in H\(p ∪n)) corresponds to an execution initiated in a state
fulﬁlling ¬pre.
• A negative trace (in n) corresponds to an execution initiated in a state fulﬁlling pre
that terminates in state fulﬁlling ¬post.
It is worth noticing that while the inconclusive behavior corresponding to a pre-post spec-
iﬁcation is chaotic, meaning that anything is allowed, the inconclusive behavior of an

24
From Action Systems to Distributed Systems: The Reﬁnement Approach
interaction-obligation is not necessarily so. For example, if the ﬁnite trace t is inconclusive
then the result t ⌢t′ of extending t with t′ is not necessarily inconclusive; t ⌢t′ may be pos-
itive (t ̸∈p∪n∧t ⌢t′ ∈p) and another extension t′′ may be negative (t ̸∈p∪n∧t ⌢t′′ ∈n).
In fact, an interaction-obligation may for the same environment behavior allow inconclusive,
positive as well as negative behavior. A pre-post speciﬁcation on the other hand, classiﬁes
executions initiated in a state (in a pre-post setting, representing the environment behavior)
as either positive or negative if it fulﬁlls pre and as inconclusive otherwise.
It is also worth mentioning that for interaction-obligations as for pre-post speciﬁcations,
there may be environment behaviors for which no behavior is allowed. An example of a
pre-post speciﬁcation of this kind is
( true , x = 0 ⇒false )
It disallows any behavior for the initial state x = 0. In classical Hoare-logic, such a speciﬁ-
cation is not implementable because any real program has some kind of behavior whatever
the environment does. In other words, no real program is partial. Hence, any implementable
pre-post speciﬁcation is total; it allows at least one system behavior for each possible initial
state. The same is not true for interaction-obligations because sequence diagrams only spec-
ify example runs and not the full behavior of a real program. Hence, a sequence diagram only
considering some input behaviors is unproblematic from a methodological point of view.
In Hoare-logic, reﬁnement corresponds to weakening the pre-condition and strengthening
the post-condition. Reﬁnement of an interaction-obligation corresponds to reducing incon-
clusive behavior and redeﬁning positive behavior as negative. Formally:
Deﬁnition 2.1. An interaction-obligation (p′, n′) reﬁnes an interaction-obligation (p, n) if
p ⊆p′ ∪n′ and n ⊆n′.
Given the mapping to pre-post speciﬁcations outlined above, reducing inconclusive behavior
may be understood as weakening the pre-condition; redeﬁning positive behavior as negative
may be understood as strengthening the post-condition. Hence, reﬁnement of interaction-
obligations reﬂects very well reﬁnement of pre-post speciﬁcations.
2.4.2
Failure-Divergences
In the setting of Event-B, a speciﬁcation may be described by a pair (f , d) of a set of
failures f and a set of divergences d. A failure is a pair (t, X) of a ﬁnite trace t and a
set of events X that the speciﬁed system may refuse after having engaged in the external
interaction corresponding to t. In other words, the speciﬁed system may deadlock after hav-
ing engaged in t if oﬀered only X or a subset of X by the environment. A divergence is a
trace t after which the systems may diverge, meaning that it performs an inﬁnite unbro-
ken sequence of internal (and hence invisible) actions without any external communication
happening at all, also referred to as livelock. Well-formedness constraints [171, p. 130] are
imposed on failure-divergence pairs that imply that any such pair is total; it allows some
behavior (possibly consisting of doing nothing) whatever the environment does.
Failures-divergences reﬁnement corresponds to removing failures and divergences. This
means set inclusion with respect to the failures and the divergences. Formally:
Deﬁnition 2.2. A failures-divergences pair (f ′, d′) reﬁnes a failures-divergences pair (f , d)
iﬀf ′ ⊆f and d′ ⊆d.

Mandatory and Potential Choice: Comparing Event-B and STAIRS
25
External choice cannot be reduced by reﬁnement, as this would imply adding new failures
in order to allow the speciﬁed system to refuse some of the events oﬀered to the environment
according to the more abstract speciﬁcation.
2.4.3
Relating the Two Models
In the case of total correctness the relationship between an Event-B speciﬁcation cap-
tured by (f , d) and a sequence diagram captured by the interaction-obligation (p, n) may be
characterized as follows:
• The positive behavior p corresponds to e\d, where e = {t | (t, ∅) ∈f }.
• The inconclusive behavior H\(p ∪n) corresponds to d.
• The negative behavior n corresponds to H\(e ∪d).
Given the mapping above, reducing inconclusive behavior in STAIRS may be understood
as reducing the set of divergences, while redeﬁning positive behavior as negative in STAIRS
may be understood as reducing the set of traces that are not divergences. This mapping
is not information preserving since semantically diﬀerent failure-divergences are mapped to
the same interaction-obligation. In particular, the semantic diﬀerence between external and
internal choice disappears.
Contrary to a failure-divergences pair, an interaction-obligation may be partial in the
sense that there may exist environment behavior for which no positive system behavior is
deﬁned. It may be argued that a reﬁnement should not impose additional constraints on the
environment behavior and thereby increase partiality. Although this constraint may easily
be imposed, it is not enforced by STAIRS because there are situations where this is not very
practical. We may for example use the operator for potential choice to specify two diﬀerent
protocols for interaction with the environment and then leave it to the implementor to select
which one to use. This choice will also restrict (or impose additional assumptions about)
the behavior of the environment because the speciﬁed system will only work properly if the
environment sticks to the selected protocol.
2.4.4
Sets of Interaction-Obligations
Sequence diagrams with mandatory choice in STAIRS is represented by a set of
interaction-obligations. Informally speaking, each interaction-obligation represents an al-
ternative that must be reﬂected in any correct implementation. In the most general case,
reﬁnement corresponds to:
Deﬁnition 2.3. A set of interaction-obligations o′ reﬁnes a set of interaction-obligations
o if for each interaction-obligation (p, n) ∈o there is an interaction-obligation (p′, n′) ∈o′
such that (p′, n′) reﬁnes (p, n).
Hence, each interaction-obligation at the more abstract level must be reﬁned by at least one
interaction-obligation at the more concrete level. On the other hand, o′ may have interaction-
obligations that do not reﬁne any of those is o. In the STAIRS literature this notion of
reﬁnement is called general reﬁnement. A more restrictive version is limited reﬁnement
which also requires each of the more concrete interaction-obligations to be a reﬁnement of
at least one abstract at the more abstract level.

26
From Action Systems to Distributed Systems: The Reﬁnement Approach
a
b
Env
System
sd external choice
ref
behavior-if-a
assert
ref
behavior-if-b
assert
xalt
Figure 2.5: External choice represented by a sequence diagram in STAIRS
In the mapping from failure-divergences to interaction-obligations deﬁned in the sub-
section above, we lost the distinction between external and internal choice. When mapping
failure-divergences to sets of interaction-obligations we have the expressiveness required to
keep this distinction. Roughly speaking, each external choice alternative corresponds to a
separate interaction-obligation as outlined by the example in Figure 2.5. The assert, which is
a standard UML 2.x operator, makes any inconclusive trace in its body negative. From the
perspective of the System lifeline, the diagram captures an external choice between receiving
either a or b. If neither behavior-if-a nor behavior-if-b contain xalt-operators, the semantics
of the diagram is a pair of two interaction-obligations; one corresponding to receiving a and
one corresponding to receiving b.
2.5
Conclusion
This paper compares Event-B (with a failure-divergences semantics) and STAIRS with
particular focus on mandatory and potential choice. While the failure-divergences semantics
gives a pure black-box interpretation of the speciﬁed system, STAIRS oﬀers a white-box
interpretation in terms of interaction-obligations and sets of interaction-obligations. Sets of
interaction-obligations are required to capture mandatory choice while a single interaction-
obligation is suﬃcient to model potential choice.
The main inspiration for writing this paper was Butler’s proposal to capture external and

Mandatory and Potential Choice: Comparing Event-B and STAIRS
27
internal choice directly by letting the speciﬁer divide the events into groups. The approach
seemed to resemble our proposal to capture mandatory and potential choice by sets of
interaction-obligations.
Our conclusion is that it does. The expressivity oﬀered by Butler’s proposal is also pro-
vided by STAIRS. In the same sense as a single event group captures internal choice, single
interaction-obligations captures potential choice. When potential choice is restricted to the
speciﬁed system, internal and potential choice is the same – both represent underspeciﬁca-
tion. Moreover, in the same sense as sets of event groups capture external choice, sets of
interaction-obligations capture mandatory choice. When mandatory choice is restricted to
the environment, external and mandatory choice is the same – both represent nondetermin-
ism that must be preserved by reﬁnement.
Acknowledgments. This work has been conducted as a part of the DIAMONDS (201579)
project and the AGRA (236657) project, both funded by the Research Council of Norway,
and the CONCERTO (232059) project funded by the Research Council of Norway and by
ARTEMIS Joint Undertaking – a public private partnership in the ﬁeld of embedded systems
supported under the Seventh Framework Programme of the European Commission.

This page intentionally left blank
This page intentionally left blank

Chapter 3
Modelling and Reﬁning Hybrid Systems in
Event-B and Rodin
Michael Butler
University of Southampton, UK
Jean-Raymond Abrial
Independent consultant, Marseille, France
Richard Banach
University of Manchester, UK
3.1
Introduction ......................................................
29
3.2
Reals and Continuous Functions .................................
31
3.3
Modelling a Continuous Control Goal ...........................
32
3.4
Distinguishing Modes ............................................
35
3.5
Modelling the Control Strategy ..................................
36
3.6
Merging Big and Small Step Variables ..........................
39
3.7
Derivatives .......................................................
40
3.8
Concluding .......................................................
41
Abstract. We outline an approach to modelling and reasoning about hybrid systems with
the Event-B method supported by the Rodin toolset. The approach uses continuous functions
over real intervals to model the evolution of continuous values over time. Nondeterministic
interval events are used to specify how continuous variables evolve within an operating
mode. Reﬁnement is used to constrain the choice of continuous functions and to decompose
a non-deterministic interval event into a series of periodic interval events.
3.1
Introduction
Event-B is an established formalism that has been applied to a range of systems especially
control systems and distributed systems [6]. A key feature of Event-B is the use of abstract
modelling to represent the purpose of a system and the use of reﬁnement to demonstrate
conformance between the abstract models and more detailed models representing the designs
that are intended to achieve the desired purpose. An Event-B machine represents a single
level of abstraction and consists of state variables, invariants and events (i.e., parameterised
guarded atomic actions). The application of Event-B is enabled by the Rodin toolset [2]
29

30
From Action Systems to Distributed Systems: The Reﬁnement Approach
which provides capabilities for proof obligations generation and automated and interactive
proof capabilities.
Event-B has largely been used to represent and reason about discrete models. In this
chapter we are interested in hybrid models, that is, models containing a mix of discrete
and continuous behaviour. We focus on one kind of continuous property, namely, bounds on
a continuous function. A common approach in modelling a hybrid system is to identify a
number of discrete modes such that within each mode the evolution of continuous variables is
speciﬁed through dynamic control laws (e.g., diﬀerential equations) [164, 266, 281]. We follow
such an approach here though we abstract away from control equations, instead specifying
assumptions about continuous functions; for example, we might assume that a continuous
function is monotonically increasing over an interval. At the abstract level, an atomic event is
used to specify the continuous behaviour within a mode; such an event nondeterministically
chooses a continuous function over a time interval representing the continuous behaviour
within that mode. We refer to this as an interval event. We use reﬁnement for two purposes.
The ﬁrst is to make the choice of the continuous function more constrained (reduction of
non-determinism). The second use of reﬁnement is to introduce additional discrete steps
within a mode to represent a periodic control strategy that determines, at each period,
whether to remain in a mode or switch to a diﬀerent mode.
We illustrate the approach we have adopted using the classic example of a controller for
a water tank. The purpose of the water tank controller is to maintain the water level in
the tank between a low and a high level. This is speciﬁed through bounds on a continuous
function representing the evolution of the water level within a mode. In a ﬁrst reﬁnement
we constrain the choice of continuous function further, specifying that it is monotonically
increasing (or monotonically decreasing) within a mode. In a second reﬁnement, we introduce
periodic control events within the modes.
One objective of the work outlined here was the desire to follow an abstraction/reﬁnement
approach, starting with a model of the purpose and reﬁning this towards an implementation
strategy. An additional key aim was to understand the extent to which the existing Event-
B reﬁnement concepts and the Rodin toolset could be used to achieve the modelling and
proofs of the hybrid water tank. A key enabler for mechanising the modelling and proofs in
Rodin is the Theory Plug-in for Rodin [72] . The Theory Plug-in allows us to extend the
mathematical language of Event-B with theories of real numbers and continuous functions
over intervals. The Theory Plug-in also allows us to deﬁne new proof rules about reals and
continuous functions that can be used by the Rodin proof manager.
The work presented here uses the standard reﬁnement proof obligations of Event-B so
that no changes where required in the Rodin tool. The Event-B proof rules are deﬁned
in [6]. Proving reﬁnement in Event-B requires gluing invariants that relate abstract and
concrete variables. Each event of a reﬁning machine either reﬁnes an event of the abstract
machine or reﬁnes skip. For an event that reﬁnes an abstract event, the guards of that
reﬁned event must entail the guards of the abstract event under the gluing invariants and
the actions must maintain the gluing invariants. An event reﬁnes skip if it maintains the
gluing invariants when no change occurs in the abstract variables.
The approach presented here was inspired by previous work on reasoning about hy-
brid systems using an abstraction/reﬁnement approach. Continuous Action Systems [30]
are an extension of the classical Action System approach [29] where variables are time de-
pendent functions, that is, variables are functions over non-negative reals. Hybrid Action
Systems [281] provide the ability to specify evolution of continous functions using diﬀer-
ential equations. Inspired by Continuous Action Systems, Su et al [322] have developed an

Free ebooks ==>   www.Ebook777.com
Modelling and Reﬁning Hybrid Systems in Event-B and Rodin
31
approach to modelling hybrid systems in Event-B using a combination of discrete and time
varying variables. The approach followed in [322] is to start with discrete models and intro-
duce continuous behaviour in reﬁnement steps. When mechanising the models and proofs in
Rodin, [322] approximated reals using integers (because of the lack of support for reals in
Rodin at the time that the work was undertaken). Hybrid Event-B is an extension of Event-
B that distinguishes mode variables (discrete) and pliant variables (continuous) [43]. Hybrid
Event-B also distinguishes mode events and pliant events; mode events model instantaneous
discrete changes while pliant events model continuous evolution of pliant variables over time
intervals. The interval events used in this chapter are essentially intended to mimic the pli-
ant events of Hybrid Event-B. At the time of writing there is no tool support for Hybrid
Event-B.
We make a distinction between a control goal and a control strategy. We outline how
both can be modelled and how reﬁnement can be used to prove that a strategy satisﬁes a
goal. In the case of the water tank system the control goal is as follows:
The control goal is to maintain the water level between a high level,
H, and a low level, L.
Water may ﬂow out of the tank according to some known maximum rate. To maintain a
satisfactory water level, the controller can switch on a pump which causes the water level
to increase according to some known maximum rate.
The control strategy is to sense the water level periodically and
switch the pump on or oﬀas appropriate.
We ﬁnd it useful to follow the categorisation of modelling variables given in the Four-
variable model of Parnas and Madey [260]. In this model, there are two main groupings of
variables, environment variables and controller variables. Environment variables represent
quantities in the environment of the controller. Controller variables represent quantities
inside the controller machine. There are two kinds of environment variable as follows:
Monitored variables Environmental quantities whose value is not determined by the con-
troller but that can be monitored. For example, the water level in the tank is a moni-
tored variable.
Controlled variables Environmental quantities whose value is expected to be determined
by the controller. For example the pump status (on or oﬀ) is a controlled variable.
The approach we follow is to start with a model of the control goal expressed in terms
of monitored variables. We then reﬁne this by a model of the strategy which is expressed in
terms of monitored and controlled variables.
3.2
Reals and Continuous Functions
We have deﬁned a theory of real arithmetic using the Rodin Theory feature. This intro-
duces a new basic type, REAL, deﬁnes real versions of the standard arithmetic operators
(addition, subtraction, multiplication and division) and deﬁnes the usual total order on reals.
www.Ebook777.com

32
From Action Systems to Distributed Systems: The Reﬁnement Approach
With the Theory feature, operators may be deﬁned directly (in terms of previously-deﬁned
operators), recursively (for inductive data types) and axiomatically with a collection of ax-
ioms on a group of operators. In our case we deﬁne the arithmetic operators axiomatically
using standard axioms for reals.
We deﬁne an interval between two reals as follows1 :
i..j
=
{ k | k ∈REAL ∧i ≤k ∧k ≤j }
This is an example of a direct deﬁnition in the Rodin Theory feature: the interval operator
is deﬁned using existing operators (set comprehension) for arguments i and j.
We use a standard deﬁnition of continuity. A function f is continuous at point c, written
cts(f , c), when it satisﬁes the following condition:
cts(f , c)
⇔
f ∈REAL 7→REAL ∧
∀ϵ · 0<ϵ
⇒
∃δ · 0<δ
∧
∀x · x ∈dom(f )
∧
c −δ < x < c + δ
⇒
f (c) −ϵ <f (x) < f (c) + ϵ
This states that for every neighbourhood around f (c), deﬁned by f (c) ± ϵ, there exists a δ
that deﬁnes a neighbourhood around c, deﬁned by c ± δ, that yields that neighbourhood
around f (c).
An interval function is continuous if it is continuous at every point in its domain so we
deﬁne the set of continuous functions on the interval i..j, written ctsF(i, j), as follows:
ctsF(i, j)
=
{ f | f ∈i..j →REAL ∧∀c · c ∈i..j ⇒cts(f , c) }
3.3
Modelling a Continuous Control Goal
We specify a continuous control goal in terms of monitored variables represented by
continuous functions on time intervals. We use a simple form of timed automaton, where
the state variables include a clock, clk, and monitored variables, m, speciﬁed as continuous
functions from time zero up to clk (where PosREAL = {r | r ∈REAL ∧r ≥0}):
clk
∈
PosREAL
m
∈
(0..clk) →REAL
This gives us two ways of specifying continuous goals in Event-B:
1For readability, we use the usual symbols for real arithmetic (+, −, ≤, etc.). These symbols are used for
integer arithmetic in Rodin and, since operator overloading is not allowed in Rodin, we use diﬀerent symbols
(plus, sub, leq, etc.) in our REAL theory.

Free ebooks ==>   www.Ebook777.com
Modelling and Reﬁning Hybrid Systems in Event-B and Rodin
33
• Invariants are used to specify a property satisﬁed by the entire evolution of continuous
variables.
• Interval events are used to specify a property on the continuous evolution within a
behaviour mode.
Boundary constraints can be speciﬁed independently of time, that is, the value of a
continuous variable at each point in its interval remains within some ﬁxed boundaries. If we
characterise the boundary as the set of values B within the boundary, then satisfaction of
the boundary by all points of the continuous variable can be speciﬁed by range inclusion:
ran(m) ⊆B
Requiring that the water level is always between the low and high marks is an example of
a boundary constraint deﬁned by the set L..H. Another form of pointwise property could
involve the relationship between several continuous variables. For example, in a cruise control
system for a car, the speed should be close to the target speed. Assuming target and speed
are continuous functions on interval i..j, this can be speciﬁed as a pointwise predicate as
follows:
∀t·t ∈i..j
⇒
target(t) −δ ≤speed(t) ≤target(t) + δ
Other properties, such as monotonicity, smoothness, responsiveness and stability, span an
interval and cannot be speciﬁed on individual time points. We do not consider a full range
of interval properties here, but we do make use of monotonicity. For example, we deﬁne the
set of monotonically increasing interval functions as follows:
mono inc
=
{ f , i, j | f ∈ctsF(i, j) ∧
(∀k, l · i ≤k ≤l ≤j ⇒f (k) ≤f (l)) • f }
The control goal for the water tank is a boundary property (deﬁned by constants H and
L) that should always be true so we use a boundary constraint on the continuous variable
to model this:
inv1 : clk ∈PosREAL
inv2 : wl ∈ctsF(0, clk)
inv3 : ran(wl) ⊆L..H
To model the dynamics within a mode, we use a nondeterministic interval event that
extends the continuous behaviour for an interval of nondeterministic length. Such an event
chooses some future time t and a continuous function f over the future interval and updates
the clock and the continuous variables in a way that satisﬁes a property P. It has the
following form:
Event
UpdateMonitored b=
any
t,f
where
www.Ebook777.com

34
From Action Systems to Distributed Systems: The Reﬁnement Approach
m
Interval 1
Interval 2
Figure 3.1: Evolution of continuous function during intervals.
grd1 : t ≥clk + ϵ
grd2 : f ∈ctsF(clk, t)
grd3 : f (clk) = m(clk)
grd4 : P(f )
then
act1 : m: = m ∪f
act2 : clk: = t
end
Possible continuous behaviour allowed by this event is illustrated by the graph in Figure 3.1.
In the graph, the behaviour within each interval is deﬁned by a continuous function over
that interval and continuity is maintained between intervals. The function is monotonically
increasing in Interval 1 and monotonically decreasing in Interval 2.
Each of the guards in the UpdateMonitored event is essential:
• Guard grd1 requires the next interval to have a duration of at least ϵ where ϵ is a
constant. This is to prevent zeno behaviour where the time interval continually gets
smaller and smaller.
• Guard grd2 requires the next interval function f to be continuous.
• Guard grd3 requires the endpoint of the existing interval function m and the starting
point of the next interval function f to agree. This is to ensure that continuity is
preserved when the interval function m is extended in action act2.
• Guard grd4 requires the next interval function f to satisfy the interval property P.
We require that interval events always preserve continuity of the continuous variables
(so grd2 and grd3 are essential). Some interval properties P are preserved under extension,
that is, if the existing interval function m satisﬁes P and the next interval f satisﬁes P, that
the extended interval function m ∪f also satisﬁes P. It is easy to show that boundary prop-
erties are preserved when extending an interval function since they are time independent.
Monotonicity is also reserved by interval extension, e.g., if m is monotonically increasing
and f is monotonically increasing, then m ∪f is monotonically increasing (provided m ∪f is
continuous). Clearly there are interval extensions that are not property preserving, e.g., ex-
tending a monotonically increasing function with a monotonically decreasing function does
not preserve monotonicity.

Modelling and Reﬁning Hybrid Systems in Event-B and Rodin
35
In the water tank example, we use the following nondeterministic interval event to rep-
resent the required evolution of the water level during a mode:
Event
WaterLevelInterval b=
any
t,f
where
grd1 : t ≥clk + ϵ
grd2 : f ∈ctsF(clk, t)
grd3 : f (clk) = wl(clk)
grd4 : ran(f ) ⊆L..H
then
act1 : wl: = wl ∪f
act2 : clk: = t
end
The interval property (grd4) for this event is a boundary property, and as just discussed,
is preserved by interval extension, i.e., this event preserves the boundary invariant on the
water level.
3.4
Distinguishing Modes
Our simple water tank system has two modes of operation: when the pump is on, the wa-
ter level is monotonically increasing and when the pump is oﬀ, it is monotonically decreasing.
In both cases the boundary property must be maintained. The interval event WaterLevelIn-
terval of the previous section is an abstraction of both of these modes of operation. We
construct a reﬁned model of the water tank machine with two interval events, one for in-
creasing the water level and the other for decreasing the water level. We require both of
these to be reﬁnements of WaterLevelInterval and thus they need to preserve the boundary
property.
The speciﬁcation of the interval event for increasing the water level is as follows:
Event
IncreaseWaterLevelInterval b=
reﬁnes WaterLevelInterval
any
t,f
where
grd1 : t ≥clk + ϵ
grd2 : f ∈ctsF(clk, t)
grd3 : f (clk) = wl(clk)

36
From Action Systems to Distributed Systems: The Reﬁnement Approach
grd4 : f ∈mono inc
grd5 : f (t) ∈L..H
then
act1 : wl: = wl ∪f
act2 : clk: = t
end
Here we replace the abstract interval property (ran(f ) ⊆L..H) with reﬁned interval prop-
erties stating that f is monotonically increasing and that the endpoint of f is within the
boundaries (the start-point is also bounded because of grd3 and the invariants specifying
that wl is bounded). The reﬁnement is valid because, if f is monotonic and its endpoints
are bounded, then f is bounded at all points. This is capture by the following inference rule
(here mono = mono inc ∪mono dec):
f ∈cstF(i, j),
f ∈mono,
f (i) ∈L..H,
f (j) ∈L..H
ran(f ) ⊆L..H
The interval event for decreasing the water level can be deﬁned in a similar way. Note
that we have not yet introduced a controller variable representing the status of the pump.
At this level of reﬁnement we remain focused on the monitored variable representing the
water level.
3.5
Modelling the Control Strategy
To model the control strategy we introduce controlled variables whose value is modiﬁed
at discrete steps. We make the assumption that the value of a controlled variable may
inﬂuence the value of a monitored variable. For example, in the water tank we introduce a
pump variable representing the status of the pump (on or oﬀ). If the pump is on, we assume
that the water level increases monotonically while if the pump is oﬀ, then the water level
decreases monotonically. For the water tank, we assume a periodic controller with a ﬁxed
period of length T that uses the following strategy at each control period:
C1 If the level is below a low threshold LT, the pump is switched on.
C2 If the level is above a high threshold HT, the pump is switched oﬀ.
C2 If the level is between LT and HT, the pump status does not change.
We assume that constants LT and HT lie in between L and T as follows:
axm1 : L<LT<HT<H
Furthermore we assume that the rate of increase in the water level is bounded by constant
RI, that is, the water level can increase by a maximum of RI × T during one ﬁxed-length
period. Similarly we assume the rate of decrease of the water level is bounded by constant

Modelling and Reﬁning Hybrid Systems in Event-B and Rodin
37
Small step intervals
w/m
Big step interval
wl
Figure 3.2: Small step and big step intervals.
RD. The values for LT and HT are chosen such that if the water level is within LT..HT
at a periodic control point, then the water level cannot go outside L..H by the next control
point, i.e.,
axm2 : L ≤LT −(RD × T)
axm3 : HT + (RI × T) ≤H
The interval events introduced in the previous modelling level represent the evolution of a
continuous variable during an entire control mode throughout which the controlled variables
remain unchanged. For example, the IncreaseWaterLevelInterval event represents the water
level increasing while the pump is on. We refer to these as big step events. When introducing
the periodic controller in a reﬁnement, the eﬀect of a single interval event at the abstract
level, e.g., IncreaseWaterLevelInterval, will be achieved by multiple sequential ﬁxed-length
periodic intervals. To model this we represent the evolution of the continuous variables
during a mode using more ﬁne-grained periodic interval events. The periodic events extend
the continuous variables by ﬁxed length intervals, each of size T. We refer to these as small
step events. In addition to the controlled variables, we introduce additional variables in the
reﬁnement to represent the changes made by the periodic controller events: a clock variable
to represent the periodic steps of time during a single mode, and continuous variables to
represent the periodic evolution of the continuous variables during the mode. For the water
tank example, we introduce two variables, one representing the periodic steps in time within
a pump mode (clkm), and another representing the periodic evolution of the water level
during a mode (wlm). This is illustrated in Figure 3.2: the left hand graph represents a series
of periodic evolutions of the newly introduced wlm variable within a mode; once suﬃcient
periodic intervals have been deﬁned by small step events, the big step event extends wl for
a full mode interval using the periodic interval functions accumulated in wlm.
We introduce invariants representing properties of the newly introduced variables in the
reﬁnement. For the water tank example we have the following invariants:
inv11 : clk ≤clkm
inv12 : wlm ∈ctsF(clk, clkm)
inv13 : wlm(clk) = wl(clk)
inv14 : wlm(clkm) ∈L..H
inv15 : pump = on
⇒
wlm ∈mono inc

38
From Action Systems to Distributed Systems: The Reﬁnement Approach
inv16 : pump = oﬀ
⇒
wlm ∈mono dec
In interpreting these invariants, it is important to understand that the new variables
clkm and wlm will be updated within a mode by the periodic controller events (small step
events), while the original variables (which remain part of the reﬁned model) will be updated
by the reﬁnements of the abstract nondeterministic interval events (big step events). The
invariants specify that clkm is never behind clk (inv11) and that wlm is a continuous function
over the interval clk..clkm (inv12) whose start point is ﬁxed (inv13) and whose end point is
bounded (inv14). Depending on whether the pump is on or oﬀ, determines whether wlm is
monotonically increasing or monotonically decreasing (inv15, inv16).
The periodic events for a mode will be continually executed, once per control period,
while it is ok to remain within that mode. For the water tank, the following periodic event
speciﬁes the system behaviour during a single period while the pump is in the on mode:
Event
PeriodicIntervalIncrease b=
any
f
where
grd1 : pump = on
grd2 : wlm(clkm) ≤HT
grd3 : f ∈ctsF(clkm, clkm + T)
grd4 : f (clkm) = wlm(clkm)
grd5 : f (clkm + T) ≤wlm(clkm) + (RI × T)
grd6 : f ∈mono inc
then
act1 : wlm: = wlm ∪f
act2 : clkm: = clkm + T
end
Here the ﬁrst two guards specify an enabling condition for the event, i.e., that the pump
is on and that the current water level has not exceeded HT. The remaining guards specify
constraints on the choice of interval function used to extend wlm, i.e., f is an interval of
length T starting from the current time (grd3), its starting value is the current water level
grd4, its ending value is bounded by the rate of increase (grd5) and it is monotonically
increasing (grd6). As well as extending wlm by f , the actions of the event increase clkm by
a ﬁxed amount T representing the ﬁxed duration of a period.
There are two key reasons why the PeriodicIntervalIncrease event maintains the invari-
ants on wlm:
• The level at the end of the interval, f (clkm + T) is bounded above by HT + (RI × T)
(from grd2, grd5) which means it is bounded above by H (axm3).
• The continuous composition of two monotonically increasing functions is monotonically
increasing:
f ∈cstF(i, j),
f ∈mono inc,
g ∈cstF(j, k),
g ∈mono inc,
f (j) = g(j)
f ∪g ∈mono inc

Modelling and Reﬁning Hybrid Systems in Event-B and Rodin
39
The periodic event for decreasing the water level is deﬁned and veriﬁed in a similar way.
The events that represent the end of a mode are speciﬁed as reﬁnements of the abstract
nondeterministic interval events. The events are made deterministic by providing witness for
the nondeterministic parameters of the abstract events and the witnesses are provided by the
variables introduced to represent the evolution of time and of the continuous variables during
a mode. For example, the nondeterministic interval event representing the monotonically
increasing mode is reﬁned as follows:
Event
IncreaseWaterLevelInterval b=
reﬁnes IncreaseWaterLevelInterval
where
grd1 : pump = on
grd2 : wlm(clkm)>HT
with
t : t = clkm
f : f = wlm
then
act1 : wl: = wl ∪wlm
act2 : clk: = clkm
act3 : wlm: = {clkm}  wlm
act4 : pump: = oﬀ
end
The reﬁned event is enabled when the pump is on (grd1) and the water level exceeds HT
(grd2). In the abstraction of this event, t and f are nondeterministically chosen parameters.
In the reﬁnement they are eliminated as parameters and their values are represented by
deterministic witness predicates (with clause). The invariants of this reﬁned model ensure
that the witness values satisfy the constraints on the choice of values for the parameters
in the more abstract model. The original actions of the abstract event are retained in the
reﬁnement event, and additional actions are added to reset wlm to be a point interval on
the current time and change the pump status to oﬀ.
3.6
Merging Big and Small Step Variables
In the reﬁnement just outlined, we retain the variable updated by the big step events (wl)
and we introduced a new variable that is updated by the small step events (wlm). Variable
wl represents the history of the water level from time zero up to the most recent big step
interval while wlm represents the recent history from the most recent big step interval up
to the most recent small step interval. It is possible in a further reﬁnement to merge the
big step and small step variables into a single variable wls representing the full history from
time zero to the most recent small step interval. This merge means that the big step clock is
not required since it is no longer used in any guards and can be eliminated. The elimination
and merge is characterised by the following simple invariant:

40
From Action Systems to Distributed Systems: The Reﬁnement Approach
inv21 : wls = wl ∪wlm
This merge leads to a simpliﬁcation of the actions of the IncreaseWaterLevelInterval event:
the update of clk is eliminated and the simultaneous update of wl and wlm is realised by
a skip action on wls (thus no change to wls is required). The only remaining action is the
update to the pump status. We also take the opportunity to rename this event to PumpOﬀ
to indicate the control purpose that it now represents. The simpliﬁed event is speciﬁed as
follows:
Event
PumpOﬀb=
reﬁnes IncreaseWaterLevelInterval
where
grd1 : pump = on
grd2 : wls(clkm)>HT
then
act1 : pump: = oﬀ
end
Through this merging of continuous variables, the PumpOﬀevent has become an instan-
taneous event whereas previously it was an interval event. We say it is now instantaneous
since it does not update a clock and it does not extend a continuous variable. We are able
to simplify PumpOﬀto be instantaneous because the overall eﬀect of the abstraction of
this event is achieved by a sequence of periodic interval events. Once suﬃciently many small
step events have been executed to accumulate the recent history of the water level within
the mode, the instantaneous mode change event is enabled and the eﬀect speciﬁed by the
abstraction of that instantaneous event will have been achieved by the accumulation of small
step interval since the most recent big step events.
3.7
Derivatives
In control systems it is common to specify properties of interval functions in terms
of properties of derivatives of those functions. For example, a function is monotonically
increasing if its derivative is always positive, a function is linear if its derivative is a constant.
Rather than deﬁning derivatives exactly, we can characterise them axiomatically. Since not
all functions have a derivative, we capture the set of diﬀerentiable functions over interval
i..j with a set diﬀ(i, j). We write der(f ) for the derivative of f . We assume (axiomatically)
that all diﬀerentiable functions are also continuous and that the derivative of a diﬀerentiable
function f is a continuous interval function over the same interval as f :
axm : ∀i, j · diﬀ(i, j) ⊆ctsF(i, j)
axm : ∀f , i, j · f ∈diﬀ(i, j) ⇒der(f ) ∈ctsF(i, j)
We can capture the property that functions with positive derivatives are monotonically
increasing through the following axiom:

Free ebooks ==>   www.Ebook777.com
Modelling and Reﬁning Hybrid Systems in Event-B and Rodin
41
axm : ∀f , i, j · f ∈diﬀ(i, j) ∧ran(der(f )) ⊆PosREAL
⇒
f ∈mono inc
This axiom allows us to reﬁne an event guard f ∈mono inc by a guard requiring f to be a
diﬀerentiable function with positive derivative.
3.8
Concluding
We summarise our approach as follows: Continuous behaviour is speciﬁed through nonde-
terministic big step interval events that constrain the shape of continuous interval functions
during a mode. We can reﬁne these nondeterministic events by further constraining the shape
of the continuous interval functions, e.g., we reﬁned an interval function, that is bounded at
every point, to a monotonically increasing function, that is bounded at its end points. We
can also introduce periodic small step events within a mode as new events in a reﬁnement
to represent the strategy to be followed by a control system. Preservation of properties of
continuous functions is key to ensuring the correctness of the reﬁnements. For example, the
most abstract interval event for the water tank preserves boundary invariants, the small step
events in the water tank preserve monotonicity.
We need to be very careful in how we allow the clocks and continuous functions to be
modiﬁed in order to reﬂect assumptions about the progression of time: time must move
forwards, not backwards, and zeno behaviour must be avoided; continuous functions are
extended in a forward direction only. It should be possible to enforce these idioms through
a syntactic layer and this is one of the features of Hybrid Event-B [43].
Our approach ﬁts with the abstraction/reﬁnement approach of Event-B and the water
tank development is supported by the Rodin toolset through the use of theories to deﬁne
operators and proof rules for continuous functions. What is less clear is how well the approach
scales to the case of high degrees of concurrency with multiple continuous functions operating
to diﬀerent mode intervals. This is the subject of future work.
The approach outlined here is inﬂuenced by the approach of [73] to the Steam Boiler
Problem. In that paper, action systems (the basis of Event-B) are used to construct a
model of the system that includes the monitored variables and the controlled variables.
Although [73] uses a very simple model of discrete time whereby the environment actions
model the update to monitored variables in one complete control cycle, it does encourage
a system-level approach. By this we mean that rather than modelling the environment
and controller separately, the abstract model captures the overall system and reﬁnement is
used to introduce more distinction between the environment and controller. In fact in our
approach we take the abstraction one level further than in [73] by focusing on monitored
variables (water level) in the abstraction and only introducing the controlled variable (the
pump) through reﬁnement.
Besides monotonicity, we have focused on expression of control goals that refer to in-
dividual time points, i.e., the monitored variables are required to satisfy some property at
each time point. Treatment of properties over time intervals, as expressible in the Duration
Calculus [79] or the approach of Hayes, Jackson and Jones [157], merits further investigation.
We have yet to include the treatment of faults (e.g., pump or sensor failure) and fault tol-
erance in our approach though we believe it is suﬃciently ﬂexible to support instantaneous
www.Ebook777.com

42
From Action Systems to Distributed Systems: The Reﬁnement Approach
(e.g., sensor failure) and continuous faults (e.g., water level is decreasing when it should be
increasing).

Part II
Analysis
43

Free ebooks ==>   www.Ebook777.com
This page intentionally left blank
This page intentionally left blank
www.Ebook777.com

Chapter 4
Modeling and Analysis of Component
Faults and Reliability
Thibaut Le Guilly, Petur Olsen, Anders P. Ravn, and Arne Skou
Department of Computer Science, Aalborg University, Denmark
4.1
Introduction ......................................................
46
4.1.1
Overview .................................................
47
4.2
A Development and Analysis Process ...........................
47
4.2.1
Ideal Model ..............................................
48
4.2.2
Modeling Faults .........................................
48
4.2.3
Fault Tree Analysis ......................................
49
4.2.4
Reliability Assessment ...................................
51
4.3
Example ..........................................................
51
4.3.1
Ideal Model ..............................................
52
4.3.2
Modeling Faults .........................................
55
4.3.3
Fault Tree Analysis ......................................
56
4.3.4
Reliability Assessment ...................................
56
4.4
Discussion, Conclusion, Related and Further Work .............
58
4.4.1
Discussion ................................................
58
4.4.2
Conclusion ...............................................
58
4.4.3
Related Work ............................................
59
4.4.4
Further Work ............................................
59
Abstract. This chapter presents a process to design and validate models of reactive sys-
tems in the form of communicating timed automata. The models are extended with faults
associated with probabilities of occurrence. This enables a fault tree analysis of the system
using minimal cut sets that are automatically generated. The stochastic information on the
faults is used to estimate the reliability of the fault aﬀected system. The reliability is given
with respect to properties of the system state space. We illustrate the process on a concrete
example using the Uppaal model checker for validating the ideal system model and the fault
modeling. Then the statistical version of the tool, Uppaal-SMC, is used to ﬁnd reliability
estimates.
45

46
From Action Systems to Distributed Systems: The Reﬁnement Approach
4.1
Introduction
Dependability of software systems in its widest meaning [22] is an area which calls for
application of rigorous reasoning about programs. This is in particular the case for embed-
ded software, where programs interact closely and continuously with a larger environment.
Therefore, it has been investigated by developers of formal methods through decades. Here,
Kaisa Sere with Elena Troubitsyna [299] have done seminal work which through the passed
years has been continued with integration into development processes [333]. The work pre-
sented here has a similar perspective. It was inspired by model based testing of real-time
systems [256] and analysis of service oriented home automation systems [92]. In these con-
texts, it is interesting to consider how models developed for testing or interaction analysis
can be reused for safety analysis and perhaps even answer questions about the reliability
of the overall system, because models are not inexpensive. It is a major development eﬀort
to build useful models of software and, even more so, of the context in which the software
is embedded. The contribution in this paper is thus a systematic process, where behavior
models are reused in safety analysis and reliability analysis of embedded systems.
The initial models have to describe the dynamics of a system, not only structural proper-
ties. They could come from Model Based Development (MBD) in the form of state charts or
state machines for the software; for the environment there might be some form of tractable
hybrid automata [164], perhaps in the form of timed automata [15] (TA). In other cases
the models could come from model based testing or other analyses. Whatever the origin, we
assume that they describe the behavior of ideal, correct systems which are not aﬀected by
any faults.
Since the software is embedded in physical systems, faults will inevitably occur due to
wear and tear. Software component failures may also be included. Although, they may often
be hidden in electronic components with built-in intelligence. Faults are essentially events
that aﬀect the behavior of the system as a whole; they may be classiﬁed in many ways as
described by Avizienis in particular, see [22] for further work. However, we assume that a
list of likely faults is known for the system under consideration.
In a conventional process faults are used in a safety analysis without considering behav-
iors, but as pointed out in e.g., [154], faults are related to dynamics of a system. A further
step is to integrate the analysis with behavioral models of a system. Here we are fortunate to
be able to build on the work of Shäfer [291] who uses phase automata as the system model
and the duration calculus to assign semantics to fault trees, and Thums et al. [329] who
use TA for modeling and Computational Tree Logic (CTL) [125] for fault tree semantics.
Finally, Bozzano et al. [66] have gone a step further and automated the synthesis of fault
tree from system modeled as Kripke structures, a result we extend to TA. Thus, there is a
solid basis for model based safety analysis.
There is, however, a catch when augmenting an ideal model with faults and thus intro-
ducing failure modes. It should not be the case that faults provide desired functionality!
This issue has been investigated by Liu and Joseph [231], who present suitable healthiness
conditions. They are employed in a TA setting in [352] which is the formulation used here.
A system with failing components may be saved from failure by augmenting it with fault-
tolerance mechanisms as done in [352]. Yet, this is costly, and there is still a probability of
failure. The real question is: how reliable is the system? Here, a stochastic model is needed.
By assigning probabilities to faults, an automata model becomes a Markov process, or if

Modeling and Analysis of Component Faults and Reliability
47
non-determinism is involved, a Markov Decision Process. Both can be handled with model
checking techniques, see for instance [39, 126]. It may not be realistic to model check a larger
model to get a ﬁgure for the reliability; so since the basic fault probabilities are estimates
anyway, it is feasible to use the ideas of statistical hypothesis testing and get an answer with
some chosen degree of likelihood. This is mechanized in Statistical Model Checking (SMC)
[217] which we apply in this paper.
4.1.1
Overview
The systematic approach outlined above is presented succinctly in Section 4.2. In order
to demonstrate the approach, we apply it to a concrete use case using the model checker
Uppaal [47] and its statistical version Uppaal-SMC [69] in Section 4.3. Finally, we discuss
limitations, related work, and provide a conclusion and possible future work in Section 4.4.
4.2
A Development and Analysis Process
The development process motivated in the introduction has as an objective to enable
reliability assessment of reactive systems. The overall process, illustrated in Figure 4.1, is as
follows:
1. Design and verify an ideal model of the system that correctly implements its require-
ments. As in any system modeling process, the models are derived from requirements
and available components. Diﬀerent types of requirements exist, from functional ones,
that express the functionality that the system should provide to extra-functional ones,
which for example constrain the time in which a function of the system should execute.
This kind of model is well known from model based development and forms a basis
for veriﬁcation of correctness of a system design.
2. Augment the ideal model with failure modes to produce a faulty model and verify that
they invalidate some requirements.
This is a novel step. It aims at analyzing requirements which are orthogonal to those
for the ideal model. A borderline case is safety requirements prohibiting states that
can cause harm to the larger environment of the system.
3. From the augmented model a fault tree for safety analysis can be derived. It enables
to detect the weak points of the system and strengthen them if necessary.
4. Associate failure modes with failure rates to obtain a probabilistic model. It allows
an assessment of system reliability. When validation fails, the previously generated
fault tree can be used to determine if the component structure should be updated
or its reliability improved. This is a novel step in conventional software development,
but it is known from safety analysis. Since failures are stochastic in nature, analyzing
them requires an estimate of the probability of their occurrence. Exactly how they are
found is a gray area, ideally they are obtained through statistical experiments; but this
requires testing many similar components. This is hardly feasible for complex compo-
nents, so in practice they are most likely estimates based on experience. Nevertheless,

48
From Action Systems to Distributed Systems: The Reﬁnement Approach
Start
1. Ideal
Model
Functional
Requirements
Satisﬁes?
2. Model
with Faults
Satisﬁes?
4. Prob-
abilistic
Model
Satisﬁes?
Reliability
Requirements
3. Fault
Tree
End






Figure 4.1: The process
it is assumed that Mean Time To Failures (MTTF) and failure rates are known in
advance for both requirements and components.
This process is an iterative one, and failure in one of the validation steps implies a need
to step back and modify the model or the properties speciﬁed, as illustrated by the dashed
lines in Figure 4.1.
4.2.1
Ideal Model
Tractable models are usually ﬁnite state abstractions of the concrete system. Modeling
the behavior of its components involves representation of their states, the transition between
those, and their interactions with other components and possibly global state variables. The
requirements are translated to predicates, usually in some dynamic logic in the case of
reactive systems. The requirements are then checked to hold for the model. In general, two
types of properties can be veriﬁed. Safety properties say that bad states are never entered,
while liveness properties say that the system keeps on moving, in particular that it avoids
deadlocks. Simulation is also of interest in this step, to observe the system evolution for a
given period and ensure that it behaves as expected at least for the observed runs. In our
setting it is an essential step in the process. Fault modeling does not make sense for an
inherently faulty system, or conversely it is hard to inject speciﬁc faults with any eﬀect in
a system that does not have to satisfy any properties.

Modeling and Analysis of Component Faults and Reliability
49
4.2.2
Modeling Faults
We recall that a failure is a transition from the system providing correct service to incor-
rect service. The state of the system when delivering incorrect service is called an error state.
Finally, the cause of an error is called a fault. When the system delivers correct service in the
absence of faults, the model is augmented with component faults, represented as transitions
from normal states to error states. For convenience, error states may be duplicated. The
obtained model is called a Fault-Aﬀected Automaton [352]. We recall its deﬁnition here.
Deﬁnition 4.1. (Fault-Aﬀected Automaton) A fault-aﬀected (or F-aﬀected) automaton is
an automaton with identiﬁed faulty transitions to error locations.
• L ∪ERR is the union of the two ﬁnite and disjoint sets of normal and error locations.
• l0 ∈L is the initial location, it is a normal state, thus the system starts correctly.
Fault transitions in the set F are the only transitions moving to error locations.
In order to ensure the correctness of the fault modeling, one needs to check the following
healthiness condition. Given an F-aﬀected automaton M of a correct automaton model S:
H 4.1. M\F ≈S, meaning that when removing faulty transitions, the obtained model is
bisimilar with the correct model.
Finally, for any f ∈F, each fault-aﬀected model M\{F\{f }}, should invalidate at least
one of the properties of S. This is to ensure that each fault is signiﬁcant in the model.
Insigniﬁcant faults can be ruled out using Fault Tree Analysis, described in Section 4.2.3.
Note that in some cases, a combination of faults leads to an error state, while their individual
occurrence does not. In that case we would consider their combination as a fault in the set F,
and we would need to check that the occurrence of this composite fault leads to a violation
of a system property.
Note that although these conditions are formulated for automata, they can be interpreted
for transition systems in general, see [231].
4.2.3
Fault Tree Analysis
Fault Tree Analysis (FTA) is used to determine the possible causes of a system failure,
and enables one to identify critical components in a system architecture. It is a top down
approach in which a top level event (TLE), representing a failure, is decomposed into simpler
events composed by boolean connectives. These events can be further decomposed until a
level of elementary events is reached. Boolean logic is then used to analyze the possible
combinations of elementary events that can lead to the failure. The basic syntax of fault
trees is composed of event symbols, representing top level-, intermediate-, or basic events,
and logic gates that express boolean relations between events. Research in this area has
provided better semantics for the syntax of fault trees, enabling the speciﬁcation of event
duration and sequencing [154] for example. With advances in modeling formalisms and tools,
it has been made possible to ensure the correctness and completeness of FTA with regards
to models decorated with faults [291, 329]. Recent research has also shown the possibility of
automatic generation of fault trees from fault-aﬀected models [66].
Here we show how to automatically generate fault trees with minimal cut sets using
CTL. In order to generate fault trees we need to compute minimal cut sets. A cut set is a

50
From Action Systems to Distributed Systems: The Reﬁnement Approach
Algorithm 1 Minimal Cut Sets
if IsCutSet(∅) then
return ∅
end if
Waiting: = {FS ∈F | | FS |= 1}
mCS: = ∅
while Waiting ̸= ∅do
for all FS ∈Waiting do
if IsCutSet(FS) then
Waiting: = Waiting\FS
mCS: = mCS ∪FS
end if
end for
Waiting: = PairwiseUnion(Waiting)
end while
return mCS
set of failures that lead to a TLE. A minimal cut set is a cut set reduced to include only
necessary and suﬃcient failures for the TLE to occur.
For systems modeled as state machines, we deﬁne cut sets and minimal cut sets as follows.
Given a set of faults F, an initial state I, and a failure TLE, CS ⊆F is a cut set for TLE
iﬀthere exist a run of the system, starting from I, visiting all faulty states in CS before
the failure state TLE. The cut set CS is minimal, iﬀthere is no cut set CS′ of TLE which
is smaller, CS′ ⊂CS. Given mCS = {mCS1, · · · , mCSn} the set of minimal cut sets for a
failure TLE and a set of faults F, we note that mCS ⊂P(F).
It is possible to check if a set of faults FS is a cut set by checking if there exists a path
where all faults in the cut set are active together with the failure, while faults outside of the
cut set are not:
E3 TLE ∧FS ∧¬(F\FS)
(4.1)
We recall that E3 ϕ means that for some paths in the model, there exists a state where
ϕ holds.
To construct fault trees, Formula 4.1 can be used to decide the set of minimal cut sets
for a given model, by iterating FS through P(F), starting from the sets with the smallest
cardinality to ensure their minimality. This is realized by Algorithm 1.
The function IsCutSet checks if its argument is a cut set using Formula 4.1. The algorithm
starts by checking if the empty set is a cut set. If it is, then either the fault set F is incomplete
or the TLE can be reached without any error being triggered (which probably indicates an
issue with the model or the speciﬁcations). The algorithm explores the power set of F,
checking for each element if it is a cut set. Since the power set is explored from the bottom,
a cut set is minimal, once it is found. When a cut set is found, it is removed from the Waiting
set, as none of its supersets can be a minimal cut set. Once all sets in Waiting have been
checked, the PairwiseUnion function is applied to it to move on to sets of higher cardinality.
Figure 4.2 shows an example exploration of the set of faults {A, B, C}. The algorithm
ﬁnds that C is a minimal cut set in itself, thus no other sets containing C are explored.
A and B are not minimal cut sets. The pairwise union function joins them into the set

Free ebooks ==>   www.Ebook777.com
Modeling and Analysis of Component Faults and Reliability
51
∅
{A}
{B}
{C}
{A, B}
Figure 4.2: Example of power set exploration
{A, B}, which is found to be a minimal cut set. In this case the set of minimal cut sets is
mCS = {{A, B}, {C}}.
In addition to identifying critical components and ruling out insigniﬁcant faults as already
mentioned, FTA can be used to determine if components, or sets of components are in series
or in parallel. Components in parallel will belong to one minimal cut set, while components in
series will belong to separate minimal cut sets. This can be valuable as most representations
of system models do not enable an easy visualization of this information.
4.2.4
Reliability Assessment
This step requires that the stochastic process is formulated with tractable distributions.
The realism can always be discussed; but it is necessary to keep the model simple in order to
get results. A component can fail in two ways, either temporarily (e.g., an unreliable com-
munication channel) or permanently (e.g., a physical component breaking). Transient faults
can be modeled using probabilistic branching, while permanent faults are modeled using
probability distributions. Assuming constant failure rates, permanent failure transitions are
modeled using an exponential distribution with parameter λ = 1/MTTF. This information
is inserted into the model to determine the unreliability of the system — the probability
that it fails after a given period.
Unreliability is expressed as a property over the global state space of the system. The
probability of this property being veriﬁed is then estimated using statistical model check-
ing (SMC), with two diﬀerent possibilities. Firstly using hypothesis testing to validate that
the probability of failure in a given time interval is less than a threshold, the time interval
and threshold being part of the system requirements. Secondly using probability estimation
to obtain an estimation of the system unreliability within a conﬁdence interval.
4.3
Example
To illustrate the process, we apply it on an example system, simple enough so that
models can be shown here and easily understood. We use Uppaal and its statistical version
Uppaal-SMC to verify the model of the system and estimate its reliability. Note that
Uppaal and Uppaal-SMC were chosen because they make it possible to apply the process
www.Ebook777.com

52
From Action Systems to Distributed Systems: The Reﬁnement Approach
on the same model, using model checking for verifying the correct modeling of faults in a
ﬁrst part and then using statistical model checking for evaluating reliability in a second part.
We start by creating an ideal model of the example system.
4.3.1
Ideal Model
The system is a gas tank, shown in Figure 4.3. It is composed of ﬁve components:
• the tank structure,
• an input valve, controlling the incoming ﬂow of gas in the tank,
• an output valve, externally controlled, providing gas,
• a sensor, measuring the level of gas in the tank,
• a controller, controlling the input valve based on the sensor’s output.
Its function is to deliver gas when requested from its output valve. We assume this tank to
have a capacity of 10L. When the gas level drops below 2L, the controller opens the input
valve to reﬁll the tank, until the level reaches 8L. If the level of the tank rises above 10L,
it explodes. Obviously this is an undesirable event. Another requirement is that the tank
should always be able to provide gas from its output valve, therefore it should never be
empty. Now that we have speciﬁed the system and its requirements we continue to model
it.
The ﬁrst thing is to extract the variables from the speciﬁcations. We have:
• the level of the tank,
• the state of the sensor,
• the state of the input valve,
• the state of the output valve.
The declaration of these variables is shown in Listing 4.1. Constants are used to improve
the clarity of the models. Note that the level of the tank and the sensor are initialized to a
value that corresponds to a normal state of the system, where the level of the tank satisﬁes
the requirements and the sensor reports a correct value.

Free ebooks ==>   www.Ebook777.com
Modeling and Analysis of Component Faults and Reliability
53
Output
LOW
HIGH
Input
MAX
Sensor
Figure 4.3: Gas tank example
Listing 4.1: Variable deﬁnitions
const
int MAX
= 10;
const
int HIGH
= 8 ;
const
int LOW
= 2 ;
const
int CLOSED = 0 ;
const
int OPEN
= 1 ;
const
int INIT_LEVEL
const
int MINUTE = 1 ;
const
int HOUR = 60∗MINUTE;
const
int DAY = 24∗HOUR;
const
int YEAR = 365∗DAY;
int
l e v e l
= INIT_LEVEL ;
int
output = CLOSED;
int
input
= OPEN;
int
sensor = INIT_LEVEL ;
Listing 4.2: Channel and time deﬁnition
broadcast chan
l e v e l S y n c ;
broadcast chan
stop ;
broadcast chan open ;
broadcast chan
c l o s e ;
broadcast chan
updateSensor ;
Listing 4.3: Level calculation
void
c a l c L e v e l ( )
{
i f
( input == OPEN){
l e v e l ++;
}
i f
( output == OPEN){
l e v e l −−;
}
i f ( l e v e l < 0){
l e v e l = 0 ;
}
}
We detail the models shown in Figure 4.4. First, we use a ticker (Figure 4.4a) to discretize
time and enforce a time unit among the models. The tank (Figure 4.4c) updates the level
variable through the function calcLevel () shown in Listing 4.3. It also triggers the update
of the sensor value. The sensor reports the level of the tank, and notiﬁes of any changes.
The input valve opens or closes when told to do so. At each time unit, the output valve
can be opened or closed. Since its state is externally controlled, we create two probabilistic
branches with equal weight to indicate that each time the transition is taken, there is an equal
probability the valve is opened or closed. Finally, the controller implements the previously
introduced speciﬁcations.
Note that components can synchronize and exchange information between each other
using the channels listed in Listing 4.2. A “!” indicates that the automaton is initiating
the synchronization, and possibly sending a value, while a “?” indicates that the automaton
is waiting for synchronization, and possibly receiving a value. Note that it is required for
SMC that all channels be broadcast, meaning that more than one automaton can receive
a synchronization, and that a sender can synchronize even when no receiver is waiting for
synchronization.
The model is veriﬁed against the system speciﬁcations; that it should not rupture, and
should never be empty. We verify them with Uppaal using the CTL formulas shown in
Table 4.1. We recall that A2 ϕ means that for all paths and all states of the model, ϕ holds.
P1 ensures that with the given design of the system, the tank cannot rupture. P2 ensures
that the tank cannot be empty. P3 ensures that the control is satisfactory.
Theorem 4.1. The properties P1−3 are satisﬁed by the network of TA in Figure 4.4.
www.Ebook777.com

54
From Action Systems to Distributed Systems: The Reﬁnement Approach
P1:
A2 ¬(level>MAX)

P2:
A2 ¬(level = 0)

P3:
A2 (level ≥LOW ∧level ≤HIGH)

Table 4.1: Speciﬁcations expressed as Uppaal properties
(a) Ticker
(b) Input valve
(c) Tank
(d) Sensor
(e) Output valve
(f) Controller
Figure 4.4: Models of the system components
Figure 4.5: Simulation
Proof
The properties are veriﬁed using Uppaal.
Other features of Uppaal can be used to analyze the model. For instance the simulator
can be used to get an indication of how the model evolves. The veriﬁer can be used to track
certain values for a set of simulations and visualize how they evolve. An example of this can
be seen in Figure 4.5, where the value of level has been tracked for one simulation. This
shows that the system evolves as expected.

Modeling and Analysis of Component Faults and Reliability
55
(a) Input with faulty transition
(b) Input failure
(c) Sensor with faulty transition
(d) Sensor failure
(e) Monitor for tank rupture
Figure 4.6: Fault-aﬀected component models
4.3.2
Modeling Faults
In our example, we assume that only the input valve and the sensor can fail, and that
their respective MTTF is 15 years and 20 years. We also consider that when the input fails,
it stays open, and that when the sensor fails it stops reporting values, in eﬀect stopping the
controller. In order to keep the models clear, we propose to separate the modeling of the
faults from the model of the components, as shown in Figure 4.6. Note that Figure 4.6e is not
a fault model but an observer automaton. This is used to make queries more clear by using
the rupture variable rather than level>MAX. Note also that the use of the id parameter in
the sensorFail[id] synchronization is in anticipation to the instantiation of several sensors
in a later step.
Theorem 4.2. None of the properties P1−3 are satisﬁed by the fault aﬀected model of the
system.
Proof
Counter examples are found using Uppaal.
Note that we have assumed only permanent faults and simple failure models. However,
transient faults can also be modeled using probabilistic branching as in Figure 4.7a which
shows a model of an unreliable sensor. Figure 4.7b shows a complex observer that models a
failure occurring when two out of ten measurements are erroneous. We however do not use
these model in our analysis to keep the example simple.
Having a fault decorated model, we move on to FTA to obtain an overview of the
combinations of faults leading to failure of the system.

56
From Action Systems to Distributed Systems: The Reﬁnement Approach
(a) Unreliable sensor
(b) Complex failure observer
Figure 4.7: Unreliable sensor and associated complex failure observer
E3 rupture ∧¬Input.Fail ∧Sensor.Fail

E3 rupture ∧Input.Fail ∧¬Sensor.Fail

Table 4.2: Output of the FTA
4.3.3
Fault Tree Analysis
We construct the fault tree using the FTA explained in Section 4.2.3. We take as TLE
the rupture of the tank. The queries run by the algorithm are shown in Table 4.2. Using
this analysis, we can observe that both the input valve and the sensor are single points of
failure of the system. Single points of failure are usually not desirable, but can be acceptable
if they are highly reliable. In order to estimate this we assess the reliability of the system.
4.3.4
Reliability Assessment
The example system can fail in two diﬀerent ways. Either the tank ruptures or it becomes
empty. Both are considered reliability issues, since they prevent normal operation. Only tank
rupture is considered a safety issue, considering that it may endanger lives. These two cases
are captured by the speciﬁcations of properties P1 and P2 in Table 4.1. In order to conduct
the analysis, we need to set up reliability and safety requirements. We specify the following:
1. the probability of system failure within one year should be lower than 10%,
2. the probability of catastrophic event within three years should be lower than 5%.
A system failure corresponds to a transition from a state in which the system delivers
correct service to one where it does not. A catastrophic event is a failure of the system
that impacts the system environment, in this case the rupture of the tank. Note that a
catastrophic event implies a system failure, while the opposite is not true.
We start by evaluating unreliability within one year of service. We thus ask the question,
“What is the probability PM(3t≤1year(rupture ∨level = 0))?”,
assuming a time unit in minutes. We consider that we want an uncertainty of ε = 0.03 and
that we want a 95% conﬁdence that the result is correct. Therefore we set the signiﬁcance
level to α = 0.05.

Free ebooks ==>   www.Ebook777.com
Modeling and Analysis of Component Faults and Reliability
57
Tank
y
t
e
f
a
S
t
u
p
n
I
(a) Input pipe upgraded with a safety valve
(b) Safety valve model
(c) Safety valve failure model
Figure 4.8: Safety valve
With a time of 31 minutes1, we obtain an approximation interval of [0.0924592, 0.152456],
which goes above the required 10%. We can therefore not guarantee that the model satisﬁes
the requirements.
We then assess the safety of the system; that the probability of catastrophic event during
a three year period is less than 5%. Given the extended time period, we use hypothesis
testing, that requires a lower number of simulations than probability evaluation. We thus
ask the question, given the fault aﬀected model M of the system,
“is PM(3t≤3yearrupture) ≥0.05?”,
assuming a time unit in minutes. We set probabilistic deviations of δ = ±0.001 and the
probabilities of Type I and II errors of α = β = 0.05. With a veriﬁcation time of 2 hours and
24 minutes we get a positive answer, indicating that the safety requirement of the system is
not met.
Note that we use minutes as the time unit as the number of simulations required using
seconds makes the estimation process excessively long. This is obviously a drawback of SMC,
since the execution time depends heavily on the length of each trace. However, compared
to analytical solutions this is expected to scale better, since the generation of traces can be
parallelized.
The probability of failure is too high w.r.t. the speciﬁcations. We need to strengthen the
critical points of the system revealed by the FTA in order to obtain an acceptable reliability.
To do so, diﬀerent possibilities are available. The easiest would be to increase the reliability
of the individual components. However, this is not always possible, due to cost or physical
constraints. Another is to add additional safety or redundant components to the system. In
this case we add a safety valve to the input and a redundant sensor.
The safety valve closes the input pipes when the tank level exceeds the level HIGH. This
safety valve is directly connected to the sensor, and as it is simpler than the input valve, we
consider its reliability to be higher (MTTF of 50 years). The safety valve, its model, and
failure model are shown in Figure 4.8. The function calcLevel () of Listing 4.3 is updated to
take it into account by constraining the increase of the level of the tank to when the safety
valve is open.
The redundant sensor is introduced in the system by instantiating a new Sensor and
SensorFail process in the model.
1All experiments are run on an i7 quad core 2.10GHz laptop with 8GB of RAM.
www.Ebook777.com

58
From Action Systems to Distributed Systems: The Reﬁnement Approach
After introducing these additional components, the FTA is performed again. Its outputs
indicate that the fault tree is composed of two minimal cut sets, one containing the failures
of the input and safety valves, the other the failures of the two sensors. The absence of
minimal cut set with a single component indicates the absence of single point of failure.
The statistical estimation of system reliability and safety is then performed again. We
ﬁrst obtain an estimation of reliability within the interval [0.0321459, 0.0919823] after 24
minutes. In order to convince ourselves of the results, we use hypothesis testing that, after
39 minutes conﬁrms the result. We are thus 95% conﬁdent that the unreliability of the
system within a 1 year period is less than 10%.
The hypothesis testing for the system testing with the updated model results in a negative
answer after 11 hours and 28 minutes. We thus have obtained a satisfactory model of the
system with regards to its speciﬁcations.
4.4
Discussion, Conclusion, Related and Further Work
4.4.1
Discussion
The process presented in this paper relies on TA and model checking. Model checking
raises the issue of the scalability of the process, due to the state space explosion problem.
This is a well known problem and abstraction and optimization techniques can be used to
reduce the state space and render model checking feasible. The choice of Uppaal as the
tool for model checking also reduces veriﬁcation time as it seems to be the most eﬃcient
tool for model checking TA [343]. The second question regarding scalability is about the sta-
tistical model checking of the TA augmented with probabilistic transitions. The complexity
of statistical model checking depends on the length of the traces to be generated, and the
conﬁdence requested for the statistical results. We have seen this in our experiments, where
the combination of high time granularity and large time intervals make statistical model
checking time consuming.
Regarding the choice of the tool, we note that Uppaal-SMC is said to perform better [69]
than the PRISM [212] tool for statistical model checking. However, PRISM also enables
probabilistic model checking, which can be more eﬃcient than SMC when applicable. We
could thus imagine modeling the system and faults in Uppaal and use model checking
to ensure the correctness of the modeling, and perform probabilistic model checking when
feasible using PRISM.
4.4.2
Conclusion
In this chapter, we presented a process to design and validate systems modeled as network
of TA. The models are extended with fault transitions to error states that can be used in
the application of two novel steps. We ﬁrst showed how to perform an FTA based on these
extended models, that helps identifying single points of failure and ensuring the correctness
of the models. An algorithm to generate complete and correct fault trees with minimal
cut sets was presented to facilitate FTA. The second novel step showed how to augment
the fault decorated models with probabilities to perform reliability analysis of the system.
We ﬁnally illustrated this process on a example, using Uppaal and Uppaal-SMC as tool

Modeling and Analysis of Component Faults and Reliability
59
support. Being based on model checking, the process is inherently limited in terms of the
size of the system to be analyzed. However, this is a well known problem, and techniques
for abstraction, reduction, and simpliﬁcation are available to help reduce it.
4.4.3
Related Work
Reliability and safety are broad areas of research that have focused the attention of many
researchers.
Regarding relation between formal models and FTA, we mention the work of Sere and
Troubitsyna [299] who use FTA to reﬁne formal speciﬁcations written with the action system
formalism [33]. The diﬀerence with our work is that the fault tree is used to reﬁne the system
model, while we derive it from the system model and use it to validate and analyze the
model.
Assessing safety through linking system reliability and components reliability using prob-
abilistic models is also the objective of the work of McIver et al. [240]. The link is made
through establishing probabilistic data reﬁnement by simulation and is limited to sequen-
tial models. Troubitsyna takes this work further by using it in combination with the action
system formalism, enabling its application to reactive systems in [331].
Regarding reliability analysis based on formal stochastic system models, we mention the
work of Kwiatkowska et al. [211] using the PRISM tool [212]. Here our work emphasizes
more the analysis process than the tool usability.
PRISM is also used by Tarasyuk et al. [325] to introduce reliability assessment in the
Event-B reﬁnement process. Here our work diﬀers in that the process emphasizes fault
modeling and incorporates FTA for identifying critical components.
Another use of statistical model checking in the context of reliability and safety analysis
is shown by Arnold et al. [17] with the DFTCalc tool. This tool focuses on FTA to compute
system reliability and MTTF. The diﬀerence in their work is that the fault tree serves as the
basis of the analysis while we derive it from a formal model of the system. The advantage
of DFTCalc is to have a more expressive syntax for fault tree (SPARE and Priority AND
gates), but the correctness and completeness of fault trees cannot be checked. Moreover,
using formal models and Uppaal also allows for checking safety and liveness properties.
Bozzano et al. [66] present a set of algorithmic strategies that enable the generation of a
fault tree with minimal cut sets. The algorithms are designed for systems modeled as Kripke
structures, and are implemented in the FASP/NuSMV-SA safety analysis platform [67]. The
algorithm we propose relies only on the use of reachability queries. We also mention [40, 41]
who propose to use retrenchment techniques for modeling faults. A (concrete) faulty system
is thus related to an (abstract) ideal system via a retrenchment relation. They then present
algorithms for generating resolution trees ﬁrst for timeless acyclic combinational circuits, and
then for cyclic combinational circuits with clocks. Resolution trees can then be transformed
into conventional fault trees, with the advantage that they provide more detailed relations
between the faults, compared to the fault tree generated by our algorithm that only contain
minimal cut sets.
4.4.4
Further Work
To make the process more useful and interesting for safety and reliability analysis, im-
proving the generation of fault trees is an essential point. As already mentioned, the fault
trees generated by our algorithm are ﬂat, in the sense that they only provide minimal cut

60
From Action Systems to Distributed Systems: The Reﬁnement Approach
sets. It is however important to be able to visualize the nested relations between the faults,
and generating nested trees would provide more insights. Generating such trees using a
combinatorial approach is possible, but would not scale well. Applying on-the-ﬂy algorithms
such as the ones used in [66] would improve the performance and should be investigated.
Another challenge is to make the process easier to use for practitioners in the ﬁelds of
reliability and safety analysis. While preparing this paper, we have recognized two direct
enhancements to Uppaal to improve its applicability in this area. The ﬁrst is to enable the
speciﬁcation of faults in the Uppaal GUI and the second is to implement Algorithm 1 in
Uppaal.
Currently, Uppaal does not provide any contextual understanding of TA, their states,
or transitions. Adding such contexts, by for example diﬀerentiating between system and
environment models, normal and erroneous states, could facilitate modeling. Moreover,
adding a notion of faults and fault aﬀected models would enable the automation of several
steps of the process presented here. The tool could for example automatically verify that
requirements are met by the ideal model, and that each speciﬁed fault invalidates at least
one of them.
With a speciﬁed set of faults and failures, Algorithm 1 could be implemented in the
tool and generate a visual representation of the fault tree. The algorithm can currently be
executed using the command-line interface to the Uppaal veriﬁer, but including it in the
GUI would increase its usability. The reliability assessment could also be automated, and
we are working on an extension that calculates the probability for each minimal cut set to
trigger the TLE. This way the most likely path to a failure can be determined.
Adding features such as these will make Uppaal more usable for practitioners and sup-
port the use of formal methods in industrial applications.

Free ebooks ==>   www.Ebook777.com
Chapter 5
Veriﬁable Programming of Object-Oriented
and Distributed Systems
Olaf Owe
University of Oslo, Department of Informatics, Norway, and
University of California, Santa Cruz, Department of Computer Science, USA
5.1
Introduction ......................................................
61
5.2
Basic Programming Constructs ..................................
63
A Core Language .................................................
64
An Example ......................................................
67
5.3
Class Invariants ..................................................
68
Invariant Reﬁnement and Satisfaction ...........................
69
Composition ......................................................
70
5.4
Inheritance .......................................................
71
Inheritance in the Bank Example ................................
73
Multiple Inheritance ..............................................
73
5.5
Local Reasoning ..................................................
74
Veriﬁcation of the Bank Example ................................
76
5.6
Discussion of Future-Related Mechanisms .......................
76
5.7
Conclusion ........................................................
78
Acknowledgments ................................................
79
Abstract Distributed and concurrent object-oriented systems are diﬃcult to analyze due to
the complexity of their concurrency, communication, and synchronization mechanisms. This
paper explores a programming paradigm based on active, concurrent objects communicating
by so-called asynchronous method calls giving rise to eﬃcient interaction by means of non-
blocking method calls, implemented by means of message passing. The paradigm facilitates
invariant speciﬁcations over the locally visible communication history of each class. Com-
positional reasoning is supported by rules comparable to those of sequential programming,
and global properties may be derived from local speciﬁcations. Reasoning about inheritance
is not limited by behavioral subtyping, but allowing free reuse of code, considering also
multiple inheritance. A small, illustrating example is considered.
61
www.Ebook777.com

62
From Action Systems to Distributed Systems: The Reﬁnement Approach
5.1
Introduction
Today distributed systems form an essential basis of modern infrastructure. Object-
oriented programming is a leading programming paradigm for such systems. It is in general
required that object-oriented, distributed systems are of high quality and behave properly.
However, quality assurance of object-oriented, distributed systems is a non-trivial and chal-
lenging topic. There are a number of approaches for diﬀerent kinds of quality assurance. For-
mal methods play an important role in the systematic studies of such systems and in their
semantics. Several formal approaches consider functional or single-assignment languages,
which are semantically simpler than the setting of imperative, object-oriented programs. To
make the result applicable to common imperative object-oriented languages, one may then
consider reﬁnement approaches. The approach considered by Kaisa Sere among others [32]
is based on reﬁnement, starting by programming in the mathematically simpler formalism
of Action Systems [35], based on the paradigms of single assignment and guarded command,
and making a number of reﬁnement steps, ending up with a correct-by-construction dis-
tributed object system. This line of work focuses on reﬁnement theory, including concepts
for increasing concurrency, like superposition [35], rather than reasoning on imperative, dis-
tributed programs.
In this paper we will not consider reﬁnements between designs at diﬀerent abstraction
levels, but rather consider imperative, object-oriented, distributed systems directly; and in
particular formal reasoning and veriﬁcation of such systems, focusing on concurrency aspects
and inheritance aspects. The concurrency model has some similarities to that of Action
Systems. Both are based on an execution model where each concurrent unit handles one
action/process at a time and where guards may lead to several enabled actions/processes,
non-deterministically chosen. Object-oriented Action Systems [62] allow non-terminating
local actions, like active objects of our concurrency model. Incremental development by
reﬁnement in Action Systems has similarities to incremental program design by inheritance
in our work.
The challenges in imperative, object-oriented, concurrent program reasoning are related
to several factors including the programming language and constructs chosen, the speciﬁca-
tion language, and the veriﬁcation system, and last but not least, tool support. The goal of
this paper is to strive for simplicity in reasoning about object-oriented, distributed systems.
In order to approach this goal we will make some recommendations with respect to language
constructs, in particular object-oriented constructs and reasoning techniques. We will keep
tool support in mind by emphasizing reasoning approaches that allow mechanized analysis.
For object-oriented systems the notions of encapsulation, inheritance, late binding, and
object creation, are central, and a proper treatment of these is essential. As class hierarchies
are open-ended, reasoning should be incremental with respect to addition of subclasses,
rather than based on a closed-world assumption. Since distributed systems involve concur-
rency, it is essential to have a reasoning system that can handle concurrent units and to
consider programming constructs that allow eﬃcient interaction of concurrent units.
Simplicity of reasoning does not only concern the choice of speciﬁcation language and
veriﬁcation system, but also the choice of programming language constructs and their seman-
tics. In particular one should choose a programming language with compositional semantics
that allows compositional reasoning. We therefore focus on programming mechanisms that
have semantical advantages and allow eﬃcient interaction. The paper builds on research

Free ebooks ==>   www.Ebook777.com
Veriﬁable Programming of Object-Oriented and Distributed Systems
63
results from the language development and reasoning activity around the paradigm of so-
called active concurrent objects developed through the languages OUN [258, 257], Creol
[188, 192, 191, 189, 186], and partly ABS [187]. The contribution of this paper is to re-
consider relevant results from the work on active concurrent objects, while making further
improvements with respect to simplicity of veriﬁability.
The paper is organized as follows: The next section discusses basic programming con-
structs for concurrent objects, introducing a core language, ending up with an example.
Section 5.3 motivates and explains invariants over communication histories. Section 5.4 dis-
cusses reasoning challenges for single and multiple inheritance. Section 5.5 suggests a Hoare
style veriﬁcation system for classes, based on invariants over communication histories, recon-
sidering the example. Section 5.6 discusses extensions to future and delegation mechanisms.
Finally, Section 5.7 comments on related work and makes a conclusion.
5.2
Basic Programming Constructs
For distributed systems the notion of concurrent unit together with interaction and coop-
eration mechanisms are crucial. The Actor model [8] is semantically appealing giving rise to
compositional semantics, unifying interaction, and cooperation mechanisms through message
passing. It is clearly simpler than the shared variable setting and the general thread-based
model where a thread may execute code on several objects, and where non-trivial interfer-
ence complicates the semantics. For object-oriented systems the natural unit of interaction
is the object; in fact the term “activity” was used before the terms “class” and “object”
appeared in Simula 67 [90]. Concurrent objects extend the Actor paradigm to the object-
oriented setting, allowing two-way interaction by means of remote method calls rather than
one-way interaction by messages. Inheritance of code is meaningful since program code is
organized in methods.
Consider a remote method call, say v: = o.m(e), where the callee o is an external object
supporting a (type-correct) method m, e is the list of actual parameters, and v is the variable
receiving the return value. In the setting of concurrent objects the default way of performing
such a method call is that the calling object blocks while the callee object (o) is executing the
method when free to do so [91]. One may improve eﬃciency by adding a list of statements
s that the caller can do while waiting, say by the syntax v: = o.m(e){s}, where the caller
blocks after performing s and only if the return value has not arrived.
However, eﬃcient interaction of concurrent objects requires some kind of non-blocking
call mechanism allowing the caller object to do something else (like handling another in-
coming call) while waiting for the call to the external object to ﬁnish. With a suspension
mechanism a method invocation can be suspended and placed in a queue of suspended pro-
cesses while another (enabled) process may continue instead. Enabledness can be controlled
by guards, either a Boolean condition b on the state of an object or the presence of a return
value of a call. The guarded await statement await b suspends while waiting for b to become
true. The await statement await v: = o.m(e) initiates the call and suspends while waiting
for the call to complete [188]. This allows an object to handle a number of processes, being
incoming calls or continuations of such calls, or self calls representing self activity. Local
methods intended for non-terminating self activity need to have release points in order to
www.Ebook777.com

64
From Action Systems to Distributed Systems: The Reﬁnement Approach
allow periods with reactive behavior. Method invocations and method results are realized
by message passing between the caller and callee objects in an asynchronous manner.
We consider objects with their own virtual processor; thus at most one process in an
object can be active at a given time. This allows sequential reasoning inside a class, and
suspension control is programmed within each method. Thus neither notiﬁcation nor sig-
naling from other objects or processes is needed, which simpliﬁes reasoning. For instance
in concurrent Java programs, some of the hardest bugs to locate are missing or misplaced
notify statements. The await statement can be eﬃciently implemented since enabledness of
waiting processes is only checked when no other process is active, i.e., at a suspension point
or end of a method invocation. This await mechanism gives rise to passive waiting.
Concurrent objects with suspension control may be reactive, responding to method calls
from the environment, or active, performing their own activity. Initial active behavior is
programmed by the initialization code, for instance by calling a non-terminating local run
method with suspension points allowing reactive behavior to be mixed with active behavior.
By dynamic object creation, new concurrent units can be generated at any time, starting
with their run method, either by themselves or by the parent object. Non-blocking method
calls give independence of objects, however, sometimes synchronization may be desirable, in
which case one may use the default object-oriented mechanism for blocking calls. For the
case that the result of a call is not needed by the caller, we use the syntax o.m(e), letting the
caller continue with the next statement after sending the invocation message to the callee.
Concurrent objects interact by means of remote method calls only, and remote access
to ﬁelds is not allowed. If allowed, this would create aliasing problems in reasoning. An
assignment statement has the form v: = e where v is a simple variable (either a ﬁeld variable
or a local variable of the method) and e is a pure expression. Even though we have aliasing
in the sense that v may refer to the same object as another variable of the same process, the
classical Hoare rule for assignment is satisﬁed, i.e., [Qv
e] v: = e [Q] where the precondition is
obtained by substituting e for v. Assertions are here enclosed in square brackets (while curly
brackets will occur in code). Thus reasoning is not aﬀected by semantic alias considerations,
since the (pointer) value of v is updated and not the object referred to by v.
Object-oriented languages have diﬀerent approaches to class encapsulation and hiding. In
addition, reasoning about object-oriented systems requires some kind of abstraction mech-
anism. Behavioral interfaces provide abstraction as well as encapsulation and hiding [89].
We let behavioral interfaces control which methods are visible, while hiding all ﬁelds, and
let interfaces contain speciﬁcation of the object behavior by means of the local communica-
tion history. Class encapsulation is then enforced by declaring object variables by interfaces,
rather than by classes. Local data structures in an object can be deﬁned by data types.
Thus objects represent independent units, while data types are used for values that can be
copied. A variable declared of a data type represents a value of that type, for instance a list
of object identities can be represented as a data type.
The setting of concurrent objects gives rise to many logical concurrent units. However
they are easily mapped to a given number of physically concurrent CPUs, since they are
working asynchronously. The objects may reﬂect activity on parallel hardware architectures
as well as distributed machines working in parallel.
A Core Language
A core language based on the concurrency model above is given in Figure 5.1. Program
code is organized in classes. Classes and interfaces may include speciﬁcations in the form

Veriﬁable Programming of Object-Oriented and Distributed Systems
65
In
:: =
interface F([T p]∗)
[extends [F(e)]+] ?{S∗I}
interface declaration
Cl
:: =
class C([T cp]∗) [implements [F(e)]+] ?
[extends [C(e)]+] ? [inherits [C(e)]+] ?
{[T w [: = e]?]∗[s] ? M ∗S∗I}
class deﬁnition
M
:: =
T m([T x]∗) B P?
method deﬁnition
S
:: =
T m([T x]∗) P?
method signature
B
:: =
{[[T x [: = e]?]+;]? [s;]? return e}
method blocks
T
:: =
F | Any | Void | Bool | String | Int | Nat | . . .
types
v
:: =
x | w
variables (local or ﬁeld)
e
:: =
null | this | caller | v | cp | f (e) | (e) | h
pure expressions
s
:: =
skip | v: = e | v: = new C(e) | s;s
basic statements
| v: = e.m(e)[{s}]? | v: = [C:]?m(e)
call statements
| await v: = e.m(e) | await e
suspending statements
| if e then s [else s]? fi
if-statements
P
:: =
[A] | [A, A]
pre-/postcondition
I
:: =
[inv A]? [where A+]?
invariant speciﬁcation
Figure 5.1: Core language syntax. We let [ ]∗, [ ]+, and [ ]? denote repeated, repeated at
least once, and optional parts, respectively. F denotes an interface name, C a class name,
m a method name, p a formal interface parameter, cp a formal class parameter, w a ﬁeld, x
a method parameter or local variable, and e a (possibly empty) expression list. Expressions
e are side-eﬀect free. Speciﬁcations are written in blue. The speciﬁcation [A] abbreviates
[true, A]. Assertions A are ﬁrst order formulas and may refer to the local communication
history h.
of invariants and pre/postconditions of methods. To control code and speciﬁcation reuse,
we let the keyword inherits indicate code reuse, while the keyword extends indicate
reuse of both code and speciﬁcation. A class may implement a number of interfaces, speciﬁed
by an implements clause. The code of a class (including inherited code) must satisfy its
speciﬁcations (including inherited speciﬁcations), and must satisfy the implements clauses
(including inherited ones caused by extends clauses). This gives rise to veriﬁcation obliga-
tions. Inheritance between interfaces is controlled by extends clauses. We could also allow
an interface F1 to implement another interface F2, meaning that F1 satisﬁes all the re-
quirements of F2, but without inheriting from F2. Such a clause could even be stated after
both interfaces are declared, for instance connecting interfaces of independently developed
program parts (in a non-cyclic manner), and be exploited in later class deﬁnitions.
Interface and type names are capitalized, while class names are written in capital letters.
The language is strongly typed, but here we omit typing considerations. We use a Java-like
syntax; however, we use : = for assignments to not confuse equations in assertions and
assignments. Assignments (v: = e), return statements (return e), if-statements, sequential
composition, and object creation (v: = new C(e)), are standard. Class parameters are
stored in the created object (following the Simula tradition). We let class, interface, and
method parameters be read-only, as well as this, referring to the current object, and caller,

Free ebooks ==>   www.Ebook777.com
66
From Action Systems to Distributed Systems: The Reﬁnement Approach
1
interface Bank {
2
Bool sub(Nat x)
3
Bool add(Nat x) [return= true]
4
Int bal() [return= sum(h)]
5
where sum(empty) = 0, sum(h· ←add(x;true)= sum(h)+x,
6
sum(h· ←sub(x;true)=sum(h)−x, sum(h·others=sum(h) }
7
interface PerfectBank extends Bank {Bool sub(Nat x) [return= true]}
8
interface BankPlus extends Bank { inv sum(h)>=0 }
9
10
class BANK implements PerfectBank {Int bal=0;
11
Bool upd(Int x) {bal:=bal+x; return true} [inv, bal=sum(h)+x and return=true]
12
Bool add(Nat x) {Bool ok:=upd(x); return ok} [return= true]
13
Bool sub(Nat x) {Bool ok:=upd(−x); return ok} [return= true]
14
Int bal(){return bal} [return= bal]
15
inv bal=sum(h) }
16
17
class BANKPLUS implements BankPlus inherits BANK{
18
Bool upd(Int x) {Bool ok:=(bal+x>=0); if ok then ok:= BANK:upd(x) fi; return ok}
19
[inv, bal>=0 and if return then bal=sum(h)+x else bal=sum(h)]
20
inv BANK:inv and bal >=0 }
21
22
class BANKWAIT implements BankPlus extends BANK {
23
Bool upd(Int x){await bal+x>=0 ;bal:=bal+x; return true} [bal >=0]
24
inv BANKPLUS:inv }
Figure 5.2: A simple bank example. In assertions, inv refers to the current invariant, while
C:inv refers to the invariant of class C. The auxiliary function sum calculates the balance
from the local history h by means of past return events of completed add and sub calls.
referring to the caller of the current method execution. In the initialization code of a class,
caller refers to the parent object.
The language supports the mechanisms for remote calls and suspension described in
Section 5.2, including guarded suspension await b, suspending call await v: = o.m(e),
interleaved call v: = o.m(e){s}, as well as simple call o.m(e). A simple call does not wait for
a result, and is useful when the result is not needed. A blocking call v: = o.m(e) is equivalent
to an interleaved call with an empty statement list. The syntax v: = m(e) represents a late-
bound local call and v: = C:m(e) a static local call, taking the method m of class C. Both
are implemented in the usual stack-based manner. Dot-notation in a call, v: = o.m(e), may
only be used when the declared interface of o supports a (type-correct) method m. It is
possible to make a call to a null object, but no return value will ever be received by the
caller in such a case. A simple call statement to null will terminate, but not a blocking call
to null, while a suspended call to null will never be enabled. (Exceptions are not part of the
core language.)
A class or interface may specify an invariant and add pre/postconditions to method
declarations. Speciﬁcations may refer to the local communication history h, as discussed in
Section 5.3. A pre- and postcondition pair is written [P, Q] where P is the precondition and
www.Ebook777.com

Veriﬁable Programming of Object-Oriented and Distributed Systems
67
1
interface Pin(Text pin) {
2
Bool open(Text code) [return=(user(h)=caller and code=pin)]
3
Bool close() [return=(user(h)=null)]
4
where user(empty)=null, user(h·o←open(code;_))=
5
if code=pin and user(h)=null then o else user(h),
6
user(h·o←close(;_))=if user(h)=o then null else user(h),
7
user(h·others)=user(h) }
8
9
class PIN(Text pin) implements Pin(pin) { Any u=null;
10
Bool open(Text code) {if code=pin and u=null then u:=caller fi;
11
return (u=caller and code=pin)}
12
Bool close() {if u=caller then u:=null fi; return (u=null)}
13
inv u = user(h) }
14
15
class PINBANK(Text pin) implements Bank extends PIN(pin) inherits BANK {
16
Bool sub(Nat x) {Bool ok:=false; if u=caller then ok:=upd(−x) fi; return ok}
17
[return=(u=caller)]
18
inv bal=sum(h) and u=user(h) }
Figure 5.3: A simple example of multiple inheritance, reusing the bank example. The inter-
face Any is the most general interface, supported by any class.
Q the postcondition. The trivial precondition true may be omitted. An inherited method may
be re-speciﬁed by simply adding the method declaration with the added pre/postcondition.
The keyword inv identiﬁes invariants and where identiﬁes auxiliary function deﬁnitions.
Auxiliary functions may be deﬁned inductively, letting others in a left hand side match
any remaining cases, and letting
denote arguments in a left-hand side pattern that are not
needed in the right-hand side.
An Example
Figure 5.2 and Figure 5.3 show a simple bank example illustrating history-based speci-
ﬁcation, suspension, static, and late bound calls, as well as single and multiple inheritance.
The methods add, sub, and upd, return a Boolean value indicating whether the transaction
was successfully performed. Both add and sub are implemented by means of upd. Interface
Bank, exporting methods add, sub, and bal, says that bal returns the sum calculated from
the successful add and sub transactions of the local communication history h. Function sum
is deﬁned inductively over the history, according to the approach in Section 5.3. Intuitively
it says that the sum is the sum of amounts added minus amounts subtracted, counting only
successful method returns (returning true). The Bank interface does not require that sub
always succeeds. There are two subinterfaces of Bank, PerfectBank, which requires that all
transactions succeed, and BankPlus, which requires that the sum is never negative.
All class implementations are based on the BANK invariant expressing that the ﬁeld bal
equals the calculated sum, bal = sum(h). Both subclasses of BANK ensure non-negative
balance, BANKPLUS by letting sub fail (return false) in case of insuﬃcient balance, and
BANKWAIT by reimplementing upd such that it suspends until the balance is large enough.

68
From Action Systems to Distributed Systems: The Reﬁnement Approach
Code reuse here is demonstrated by inhering the bal, add, and sub methods of class
BANK in the two subclasses of BANK, while redeﬁning the upd method. Speciﬁcation reuse is
demonstrated by the class BANKWAIT, in which upd inherits the speciﬁcation of BANK, re-
sulting in the speciﬁcation [bal = sum(h), bal = sum(h) + x ∧bal⟩= 0 ∧return = true].
As discussed below, a challenge with respect to reasoning is that the BANK speciﬁcation
(namely the postcondition of upd and support of PerfectBank) is violated by the subclass
BANKPLUS. We will suggest a way to solve this challenge; and in Section 5.5 we show how
to verify parts of the example.
Class PINBANK in Figure 5.3 demonstrates multiple inheritance. It inherits code from
both class BANK and PIN, and inherits speciﬁcations from class PIN. It implements interface
Bank and also interface Pin (implicitly through the extends clause).
5.3
Class Invariants
Class invariants are commonly used for specifying, and reasoning about, object-oriented
systems, and are especially useful in a distributed setting with non-terminating concurrent
objects [88, 243]. In a global state of such a system, we may assume that each object satis-
ﬁes its invariant. This gives rise to sound compositional reasoning [312]. Interface invariants
reﬂect parts of class invariants that are relevant to the environment. Encapsulation of inner
state means that remote ﬁeld access should not be allowed since several classes may im-
plement the same interface, each with diﬀerent ﬁelds. In order to capture an abstraction of
the object state, one may use model variables [225] or ghost variables such as the commu-
nication history [88]. Communication histories have the advantage that they are expressive,
since they include all visible events, and one need not invent speciﬁc model/ghost variables
for each class. One may deﬁne functions over the history to extract information relevant in
an interface or class speciﬁcation.
History variables give an abstraction of the state in terms of communication events
only, and distinguish diﬀerent sequences of communication events. Class invariants can be
formulated as predicates over the local history of the object as well as ﬁeld variables, this,
and class parameters. Interface invariants can be formulated as predicates over the local
history of the object as well as this and interface parameters, but not ﬁeld variables, since
these are not visible in an interface. Interface invariants are supposed to hold at all times
and should therefore be preﬁx closed with respect to the history, whereas class invariants
need only hold at suspension and method return points.
A history is a sequence of visible events. We consider the following events:
o →o′.new C(e), o creates a new C object o′ with actual class parameters e.
This creation event is visible to o. The events for method interaction are:
o →o′.m(e), denoting a call to method m with actual parameters e, with o as caller and
o′ as callee. This event is caused by o and is visible to o only.
o ↠o′.m(e), denoting start of processing of the call o′.m(e) with o as caller. This event is
caused by the callee and is visible to o′ only.

Veriﬁable Programming of Object-Oriented and Distributed Systems
69
o ←o′.m(e;e), denoting the generation of the return value e resulting from the call o′.m(e).
This event is caused by the callee and visible to o′ only.
o ↞o′.m(e;e), denoting the reception of the return value e by o of the call o′.m(e). This
event is performed by the caller and is visible to o only.
Thus the following events are caused by an object o: o →o′.m(e), o′ ↠o.m(e), o′ ←
o.m(e;e), o ↞o′.m(e;e), and o →o′.new C(e). The events are referred to as call, start,
return, get, and creation events, respectively. All four communication events are needed
since method communication is asynchronous and the events above may happen at diﬀerent
times. However, for each call the events must happen in the order given above. This ordering
is captured by a notion of global wellformedness, formalized in Section 5.3.
Local speciﬁcation and reasoning in a class or interface are done with local histories, i.e.,
the sequence of events visible to this object. In contrast, global speciﬁcation and reasoning
are done in terms of the global history, i.e., the sequence of all events. It follows that the
local histories of distinct objects are disjoint in the sense that they do not share events.
This allows independent reasoning of each class, and compositional reasoning by means of
a simple composition rule stating that the invariant of a global system is the conjunction of
all the invariants of the objects involved, adding wellformedness [115].
In speciﬁcations, auxiliary functions may be deﬁned inductively over the local history
h, using empty and append right (·) as the history constructors. In this way the last event,
which reﬂects the current activity, is explicit. For instance the ends-with predicate (ew ) can
be deﬁned by the two cases (where x and y range over events):
empty ew y = false,
h · x ew y = (x = y)
using inﬁx notation. The history without the last event can be deﬁned for non-empty histories
by old(h · x) = h. Projection of the history by a set of events s, denoted h/s, is deﬁned by
empty/s = empty,
(h · x)/s = if x ∈s then (h/s) · x else h/s
We let h/o denote the projection of h to events caused by o, and we let h/F denote the
projection of h to the alphabet of an interface F, i.e., restricting ↠and ←events to methods
of F. Similarly, h/C denotes the projection of h to the alphabet of a class C, i.e., restricting
↠and ←events to methods of C. And h/(o:F), denoting the history of o as seen through
the interface F, is a shorthand for h/o/F; and h/(o:C), denoting the history of o as seen
through the class C, is a shorthand for h/o/C. In practice, return and get events are essential
in invariant speciﬁcations, describing output and input, respectively, of the speciﬁed object,
while call and start events are often not needed (unless synchronization aspects are speciﬁed),
as in the Bank example. In an interface or class speciﬁcation we may write o ←m(e;e) rather
than o ←this.m(e;e), skipping the redundant this.
Invariant Reﬁnement and Satisfaction
The invariant of a class C is written IC(h, w) where h is the local history and w its
ﬁelds. The invariant of an interface F is written IF(h) where h is the local history. An
interface invariant IF(h) will only restrict events in its own alphabet. In a subinterface or
class with a wider alphabet, the invariant is therefore understood as IF(h/F), which ensures
that the invariant does not restrict events outside its alphabet. Thus the invariant IF(h) of
an interface F is inherited as IF(h/F) in a subinterface of F. For a class C implementing F,

70
From Action Systems to Distributed Systems: The Reﬁnement Approach
one must verify that IC(h, w) ⇒IF(h/F), in which case C is said to satisfy F. Similarly, a
class invariant IC(h, w) is inherited as IC(h/C, w) in a subclass extending C. Furthermore,
for an inductively deﬁned function f (h), the equation f (h · others) = f (h) is added to make
the deﬁnition complete and to adjust for any alphabet extension when the function is used
in a subinterface or subclass.
For each class C one must prove that the class invariant is established by the initializing
code, that it is maintained by each method exported through a C interface, that the invariant
holds at each suspension point, and that the class satisﬁes each interface of the class.
In an interface or class, postconditions can easily be expressed by invariants over the
history. A postcondition [Q(h, return, caller, x)] of a method m(x) abbreviates the invari-
ant h ew (caller ←this.m(x;return)) ⇒Q(h, return, caller, x) where return is a special
variable to be used in postconditions to refer to the returned value of a method. In a class
postconditions may refer to ﬁelds. In an interface, (abstract) ﬁelds may be extracted by
means of auxiliary functions over the history. In the examples we use postconditions as
a notational convenience. Auxiliary function deﬁnitions are inherited downwards in sub-
classes, subinterfaces, and implementing classes, so that they are available for speciﬁcation
and reasoning.
Composition
For simplicity we here ignore interface and class parameters in the discussion. Given an
invariant IF over the local history of an interface F, we deﬁne the object invariant of an
object o as seen through F by
Io:F(H) ≜IF(H/(o:F))this
o
where the projection H/(o:F) denotes the history H reduced to the set of events generated
by o and visible through F. Next the object invariant of an object o of class C is deﬁned as
Io:C(H) ≜
^
F∈C.implements
Io:F(H)
where C.implements is the list of interfaces implemented by C according to the class deﬁni-
tion. Finally the global invariant of a system with dynamically created objects initiated by
an initial object system:System (where the System interface may include minimal require-
ments and primitives of the underlying operating system) is deﬁned by
Iglobal(H) = wf(H) ∧
^
(o:C)∈ob(H)
Io:C(H)
where ob(H) is the set of object identiﬁers created in H by a new event (including the initial
object):
ob(empty)
=
{system:System}
ob(H · (o′ →o.new C(e)))
=
ob(H) ∪(o:C))
ob(H · others)
=
ob(H)
and where wf(H) is the welldeﬁnedness predicate expressing that for each call the communi-
cation events obey the natural order call, start, return, get, that generated object identiﬁers

Free ebooks ==>   www.Ebook777.com
Veriﬁable Programming of Object-Oriented and Distributed Systems
71
are fresh, and that all identiﬁers used by an object o have been seen by the object:
wf(empty)
≜
true
wf(H ·(o →o′.new C(e))
≜
wf(H) ∧o ∈ob(H) ∧id(e) ⊆id(H/o) ∧o′ ̸∈id(H)
wf(H ·(o →o′.m(e))
≜
wf(H) ∧o ∈ob(H) ∧({o′} ∪id(e))⊆id(H/o)
wf(H ·(o′ ↠o.m(e))
≜
wf(H) ∧o ∈ob(H)
∧#H/{o′ ↠o.m(e)}<#H/{o′ →o.m(e)}
wf(H ·(o′ ←o.m(e;e))
≜
wf(H) ∧o ∈ob(H) ∧id(e)⊆id(H/o)
∧#H/{o′ ←o.m(e; )}<#H/{o′ ↠o.m(e)}
wf(H ·(o ↞o′.m(e;e))
≜
wf(H) ∧o ∈ob(H)
∧#H/{o ↞o′.m(e;e)}<#H/{o ←o′.m(e;e)}
where # denotes sequence length and the id function gives the set of all identiﬁers (including
null) appearing in an expression or history. (In the set {o ←o′.m(e; )}
may be any value.)
5.4
Inheritance
The semantics of inheritance and late binding has been a research topic for many years,
with [342] as an early investigation. Class invariants are used to specify the semantics of a
class, and a (logically) strong invariant is usually called for in order to verify that the class
satisﬁes the speciﬁcations of the given interfaces [89]. Inheritance is an essential element
of object-oriented programming, giving ﬂexible reuse of code. Reasoning is often restricted
to a form of behavioral subtyping, implying that a superclass invariant must be respected
and maintained by all subclasses [230]. The advantage is that behavioral subtyping allows
modular reasoning about late bound calls using the speciﬁcation of the class of the callee,
or the enclosing class in case of a local call. However, this severely limits programming; for
instance a perfect bank class, like BANK in Figure 5.2, cannot be used to derive a bank
class with negative balance protection, like BANKPLUS in the example (nor versions with
interest or charges), since this represents a non-conservative extension violating the BANK
invariant. Hence ﬂexibility of code reuse is lost if behavioral subtyping is accepted, unless
class invariants are very weak. Thus behavioral subtyping is not an acceptable form of
reasoning about object-oriented systems in our setting.
The notion of lazy behavioral subtyping [118, 119, 120] allows better ﬂexibility, by talking
about two kinds of properties for each class, S (for speciﬁcations) and R (for requirements),
letting SC denote properties about class C, and RC minimal properties to be respected by
all subclasses of C. And SC is used to verify interface satisfaction as explained. In order to
prove that the class satisﬁes SC, one must in general reason about late-bound local calls in
the method bodies of the class, in which case RC requirements are needed, and RC must
then be enriched with minimal properties of these calls. Lazy behavioral subtyping allows
reasoning support for extensible class hierarchies. Each class can be analyzed separately as
long as its superclasses have been analyzed earlier. The invariant and pre/postconditions in
C form the SC speciﬁcations, while the RC requirements (initially empty) are generated by
adding minimal properties as needed for reasoning about late-bound local calls in the class.
Both SC and RC properties must be veriﬁed in C, and by adding all veriﬁed properties to
SC, the property set RC will be a subset of SC, i.e., RC ⊆SC.
www.Ebook777.com

72
From Action Systems to Distributed Systems: The Reﬁnement Approach
By adding language support for statically bound local calls, which are in general useful
for explicit code reuse, fewer R requirements are needed since reasoning about these can be
done by S speciﬁcations. A static local call, say v: = C:m(e), which binds to the method
m of C, is meaningful in a subclass of C, say C ′. We may reason about this call using
SC, and we may enrich SC if needed. Thus in the presence of statically bound local calls,
there is less need for late-bound local calls. And for programs without late-bound local
calls, there is no longer a need for R requirements, we only need interface speciﬁcations and
class speciﬁcations. Separation logic also oﬀers S- and R-like requirements for the setting
of sequential Java or JML style programs with non-trivial aliasing but without history
speciﬁcations [82, 233, 259]. This approach is not able to handle the challenge of the Bank
example.
For programs with late-bound local calls, we still have a problem with code reuse when a
redeﬁned method violates an R requirement. To solve this problem, we insist that all object
variables are typed by interfaces. At run-time an object variable will refer to an object of a
class implementing its declared interface, when not null [257, 192]. This property, called the
interface substitution principle, is guaranteed by static type checking. Thus a callee is typed
by an interface rather than a class, and reasoning relies on the interface speciﬁcation. We
distinguish reuse of code from reuse of speciﬁcations: Interface speciﬁcations are inherited
by subinterfaces, i.e., IF(h) is inherited as IF(h/F) in a subinterface of F. Class invariants
need not be inherited, and a subclass of a class implementing interface F may violate F. We
let class invariants and interface support be stated independently for each class; however, if
a class implements F, it implicitly implements any superinterface of F.
A subclass class C1 extends C2 inherits all code and speciﬁcations from the class C2
(with the usual projection of histories), thus supporting all interfaces that C2 implements.
This corresponds to (a kind of) behavioral subtyping. A subclass class C1 inherits
C2 inherits all code, but not speciﬁcations, from C2. This allows free code reuse, as long
as one can verify the stated interface clauses of C1. One may inspect the proof outlines of
C2 and see which ones are valid for C1, and the case of lazy behavioral subtyping occurs
when all pre- and postconditions used in a proof outline for a late-bound local call in C2
are supported by any redeﬁned version of the called methods. Moreover, there is no need to
record R requirements, since subclasses no longer need to respect R requirements. Instead of
pushing requirement downwards in the class hierarchy, one needs to look upwards in the class
hierarchy when verifying a class, reconsidering inherited code. Thus we omit the downward
inheritance of requirements and obtain more ﬁne-grained veriﬁcation control. This approach
to reasoning can be called behavioral interface subtyping. The interface substitution principle
is satisﬁed, and our approach is able to handle the challenge of the Bank example.
Lemma 5.1. Our language satisﬁes the interface substitution principle, and reasoning by
means of behavioral interface subtyping is sound, i.e., one may reason about an object
variable v declared of an interface F by means of the F invariant, assuming each class C is
veriﬁed as described above, possibly involving superclasses but not any subclasses of C.
Proof outline. We prove that our language, which includes late binding and free (type-
correct) method redeﬁnition, satisﬁes the interface substitution principle, and that each
object referred to at run-time by a variable v declared of an interface F satisﬁes the F
speciﬁcation. Each object variable v is declared of an interface F. At run-time the initial
value of v is null or the value of an actual parameter, and its value may be changed by new
statements, assignments, and call statements assigning the result of the call to the variable.
Static type checking ensures that all these statements assign to v a value which is of type F

Veriﬁable Programming of Object-Oriented and Distributed Systems
73
or a subinterface of F, or is null, and that each actual object parameter is of the interface
(or a subinterface) of the corresponding formal parameter. Given operational semantics, this
can be proved more formally by means of subject reduction, as in [192] (which also deals
with the complications of call labels). An object variable will therefore at run-time be null
or refer to an object of a class with an interface being F or a subinterface. It remains to
prove that such a class satisﬁes F, and that this involves only C and superclasses.
We may assume that all classes are veriﬁed. For simplicity we assume that all pre/post-
conditions are expressed through the invariant. And we assume a sound reasoning system
for proving class invariants. For each class C it is required to verify that the invariant is
established and maintained, and to verify the interfaces of C, using the invariant. A C object
may at run-time perform methods deﬁned in C or inherited methods, called remotely, and
these may make local calls to methods in C or a superclass, including static calls, which may
only bind to superclass methods, statically known. Also the binding of late-bound method
calls in C or superclass methods are statically known when the executing object is a C
object. Thus C satisfaction of F depends only on methods in C and its superclasses, and
the binding of all local calls can be resolved at veriﬁcation time. It is therefore possible to
prove satisfaction of F by normal static analysis, ensuring that all methods in C as well as
inherited ones maintain the C invariant, and that suspension points in locally called super-
class methods respect the C invariant. If needed any local calls to superclass methods can be
reveriﬁed to deal with these calls. Thus the veriﬁcation depends on C and its superclasses,
and not on any subclass of C. This ensures that any C object will satisfy the interfaces of
C. Since an interface F inherits all requirements of any superinterface, we have that a class
satisfying F also satisﬁes a superinterface of F. We may conclude that at run-time an object
variable v will be null or refer to an object of a class satisfying its declared interfaces.
Inheritance in the Bank Example
In the Bank example, class BANKWAIT extends BANK, while class BANKPLUS inherits
BANK without claiming to respect its speciﬁcations. For class BANKPLUS it is easy to see
that only the postcondition return = true of method sub and that of upd are violated. And
it is easy to see that the veriﬁcation of the invariant bal = sum(h) in BANK is valid in class
BANKPLUS. The new speciﬁcation of upd and the added invariant conjunct bal ≥0 must
be veriﬁed, which is straightforward. Support of interface BankPlus (and thereby interface
Bank) follows from this. Notice that with lazy behavioral subtyping, class BANKPLUS would
not satisfy the RBANK requirement; thus a reasoning approach requiring inheritance of R
requirements would not be able to handle this kind of code reuse. We avoid veriﬁcation
problems in this case, as opposed to the case of previous work on lazy behavioral subtyping
as well as the work on separation logic.
Multiple Inheritance
The notion of multiple inheritance has been an ideal in object-oriented programming
due to its expressive power with respect to code reuse. However, programming with multiple
inheritance can be confusing [238], and reasoning about multiple inheritance is challenging,
especially if not restricted. In order to control programming with multiple inheritance and
late binding, binding healthiness [120] ensures that a call textually occurring in a given
class C may only bind to a class related to C, either below C or above C. To solve the
diamond binding problem, i.e., to bind a method in case of several alternative deﬁnitions,

74
From Action Systems to Distributed Systems: The Reﬁnement Approach
we use the ordering given by the order of the inheritance list. In addition, explicit class
qualiﬁcation of late-bound local calls, similar to that for static binding, allows ﬁne-grained
control. Synchronization interference between multiple superclasses is avoided, due to local
concurrency control. With healthiness, lazy behavioral subtyping extends to the case of
multiple inheritance. When analyzing a given class C, added R speciﬁcations concern C
and future subclasses of C, whereas S speciﬁcations may be added to C or some superclass
of C. Classes are analyzed in some order consistent with the subclass order, typically the
order in which they are deﬁned. As before, R speciﬁcations are not needed when restricting
local calls to static ones, and in this case healthiness is guaranteed.
Reasoning with behavioral interface subtyping also extends to multiple inheritance.
Healthiness is not required, since reasoning is done for the case that the executing object
is of the class considered. Any subclass must be considered separately, reusing reasoning
results when possible, as in the case of single inheritance. Figure 5.3 gives an example where
class PINBANK inherits both class PIN and BANK, not respecting the speciﬁcations of the
latter, since interface PerfectBank is violated. Thus the challenge of Figure 5.2 reappears.
5.5
Local Reasoning
The disjointness of local histories of distinct objects allows sequential style local reasoning
inside a class, while global reasoning is possible with the composition rule. In particular,
the Hoare rules for basic statements are standard, including assignment, if-statements
and skip, assuming expressions are side-eﬀect free and well deﬁned. Standard consequence,
conjunction, and adaptation rules apply. The consequence rule may be adjusted to assume
local wellformedness of local histories, which implies that any caller and this are non-null.
One may reason about local calls as normal, using the relevant class speciﬁcations. Thus for
a local static call we have
[x′ = e ∧L ∧Px,caller,h
e,this,h·(this→this.m(e))] v: = C:m(e) [L ∧∃v′ . Qx,caller,v,return,h
x′,this,v′,v,h·(this ↞this.m(x′;v))]
where L is a predicate not referring to ﬁelds of C, h, nor v, and given that method m(x)
of C (possibly inherited) satisﬁes the pre- and postcondition pair [P, Q] in the current class
(using the current invariant for release points). The quantiﬁer on v′ is only needed if Q refers
to v. Handling of recursive calls can be done as usual. For a late-bound local call occurring
in a class C reasoning can be done in the same manner, i.e., a call v: = m(e) (as well as
v: = this.m(e)) is treated as the static call v: = C:m(e). And the same rule applies to a
remote call v: = o.m(e) given that the pre/post pair [P, Q] follows from the speciﬁcation of
the interface of o, and that [P, Q] does not refer to the (disjoint) history of that interface.
Note that all methods exported through an interface must maintain the invariant. Dot-
notation is not allowed on non-exported methods; and these need not satisfy the invariant.
Note that this means that suspending calls (which require the invariant) are not available
for non-exported methods.
Rule history in Figure 5.4 expresses that the local history is monotonic, i.e., the past can
never change. Rule await guard expresses that the statement await b will not change local
variables (but during suspension ﬁelds may be updated by other processes), and when it
terminates the waiting condition is satisﬁed and the invariant has been reestablished pro-
vided it held before. The rule for simple call expresses that the partial correctness semantics

Veriﬁable Programming of Object-Oriented and Distributed Systems
75
history
[h0 = h] s [h0 ≤h]
await guard
[I ∧L] await b [b ∧I ∧L]
simple call
[Qh
h·(this→o.m(e))] o.m(e) [Q]
call-while
[o′ = o ∧e′ = e ∧P] s [∀v′ . Qv ,h
v′,h·(this↞o′.m(e′;v′))]
[o ̸= this ∧Ph
h·(this→o.m(e))] v: = o.m(e){s} [Q]
await call
[o′ = o ∧e′ = e ∧L ∧I h
h·(this→o.m(e))] await v: = o.m(e)
[L ∧h ew (this ↞o′.m(e′;v)) ∧∃v . I h
old(h)]
new
[∀v′ . fresh(v′, h) ⇒Qv ,h
v′,h·(this→v′.new C(e))] v: = new C(e) [Q]
method
[Py
y′ ∧y = Udefault] s [Qy,return,h
y′,e, h·(caller←this.m(x;e))]
[Ph
h·(caller↠this.m(x))] T m(T x){U y;s;return e} [Q]
Figure 5.4: Hoare style rules for non-standard constructs. Primed variables represent fresh
logical variables, and fresh(v′, h) expresses that v′ does not occur in h. L denotes a condition
on local variables. For each class one must verify that the class invariant I holds after
initialization and is maintained by all methods exported through an interface. The await
rules ensure that it holds upon suspension.
of the call o.m(e) is equivalent to that of the assignment h: = h · (this→o.m(e)). The rule
call-while expresses that the partial correctness semantics of a non-local call v: = o.m(e){s}
is equivalent to that of the statements
h: = h · (this→o.m(e));s;v′: = some;h: = h · (this ↞o.m(e;v′));v: = v′
where v′ is a fresh variable representing the locally unknown result, letting v′: = some denote
a non-deterministic assignment. The call-while rule may be derived from this using the rule
[∀v . Q] v: = some [Q]. The blocking call v: = o.m(e) is equivalent to v: = o.m(e){skip}.
Thus we may derive the rule
[∀v′ . o ̸= this ∧Qv, h
v′,h·(this→o.m(e))·(this↞o.m(e;v′))] v: = o.m(e) [Q]
With respect to partial correctness, the suspending call await v: = o.m(e) is equivalent to
calling while suspending, i.e., v: = o.m(e){await true}, and the await call rule can be derived
from this. The method rule expresses that the body of a method T m(T x){T y;s;return e}
can be seen as the statements
h: = h · (caller↠this.m(x));{U y;s;return: = e};h: = h · (caller ←this.m(x;return))
(with return and caller as local variables). In the rule, y′ is a list of logical variables used
to handle possible name clashes between local variables y and variables occurring in P or
Q, and uninitialized local variables are initialized by default values of the respective types

76
From Action Systems to Distributed Systems: The Reﬁnement Approach
(Udefault). The rule for object creation expresses the obvious extension of the local history
and (local) freshness of the identity of the new object (and v′ is needed if v occurs in e).
Veriﬁcation of the Bank Example
Consider the inherited method sub of class BANKWAIT. We need to verify the invariant
and the postcondition:
[I(h)] Bool ok: = upd(−x);return ok [I(h) ∧return = true]
where I(h) is the class invariant (bal = sum(h) ∧bal ≥0). Left-constructive reasoning
according to the method rule gives
[I(h)] ok: = upd(−x) [I(h · (this ←this.sub(x;ok))) ∧ok = true]
which by deﬁnition of sum reduces to
[I(h)] ok: = upd(−x) [bal = sum(h) −x ∧bal ≥0 ∧ok = true]
It suﬃces that upd(x) satisﬁes the speciﬁcation
[bal = sum(h), return = true ∧bal = sum(h) + x ∧bal ≥0]
which is easily veriﬁed by the rule for local calls, using the redeﬁned upd (with ok receiving
the method result). Moreover, these veriﬁcation tasks could easily be automated by a tool.
A client object may call methods on a bank object b. If b is declared to be of interface
PerfectBank, we obtain [true] ok: = b.sub(a) [ok = true], and [true] v: = b.bal() [v ≥0] if b
is of interface BankPlus. Reasoning with the compositional rule is required to obtain further
information about the calls.
Veriﬁcation of the PinBank Example. For class PIN it is straightforward to verify that
the invariant is maintained by each method, and that it holds initially. We may also show
that the postcondition given in interface Pin for close is established by the implementation
of close in PIN, given the invariant as precondition. And the one for open is trivial to verify.
Consider the method sub of class PINBANK. We need to verify that the body of sub
satisﬁes its postcondition and that it maintains the given invariant. In the ﬁrst veriﬁcation
task we rely on the postcondition return = true of upd from BANK. The invariance proof
of bal = sum(h) reduces to the one in BANK, and the conjunct u = user(h) is maintained
since it is not aﬀected by sub.
5.6
Discussion of Future-Related Mechanisms
The notion of future has been suggested as a mechanism to increase concurrency and
reduce waiting in method bodies [351, 229]. A future may be seen as a reference to a location
where a method result will be stored when available. Futures may be ﬁrst-order in the sense
that they may be passed as parameters. Thereby information sharing is possible and one
may return a future rather than waiting for the result itself. Reasoning about ABS with
ﬁrst-order futures is studied in [114, 116]. Futures are in particular useful when a callee
depends on remote calls to other objects. However, there is a cost of using futures, both
at the programming level and at the speciﬁcation and reasoning level. At the programming

Veriﬁable Programming of Object-Oriented and Distributed Systems
77
level, an interface must decide if and where to use futures, since this aﬀects the signatures
of the interface methods. These decisions are not easy to make at an early stage, and it
is diﬃcult to change these decisions at a later stage in the programming, since they aﬀect
other classes as well. At the speciﬁcation and reasoning level, one will need to talk about
future identities and it is in general not trivial to make the connection between a call event
and the corresponding get event with the result of the call. Thus the simple call-response
paradigm is no longer syntactically reﬂected in the histories. Reasoning rules must deal with
future identities. And as seen in [116] there is a cost with respect to compositional reasoning,
related to the “get” rule for accessing a future value.
Our experience is that ﬁrst-order futures are often not needed, and therefore the draw-
backs mentioned are quite expensive in a reasoning perspective since futures appear in the
communication events even when not used in the program. The mechanism of delegation
is in several ways similar to futures. In the body of a method m(x) one may delegate the
rest of the method body to another call (possibly remote), letting for instance the state-
ment delegate o.n(e) mean that the current call terminates without producing a result,
while delegating to the remote call o.n(e) to send a result back to the caller of m. Type
checking must ensure that the result type of n is the same, or better (i.e., a subinterface or
subtype), than that of m. However, interface declarations are not aﬀected by issues related
to delegation. Thus delegation may be used in code when suitable without prior planning
in interfaces.
Our current setting may accommodate delegation with some adjustments of the commu-
nication events, adding more information to global events, and strengthening the notion of
wellformedness to make up for the diﬀerence in local and global events. In local reasoning,
events may be as before, except that a delegation call must be indexed with the current call,
and in this case no return event should occur. In global reasoning, all communication events
could be indexed with the initial call, starting with a call event (o →o1.m(e))(o→o1.m(e))
and ending with a get event (o ↞o1.m(e;r))(o→o1.m(e)). Thus (o →o1.m(e))c may be fol-
lowed by (o↠o1.m(e))c, and (o↠o1.m(e))c may be followed by either a delegation event
(o1→o2.n(t))c or a return event (o ←o1.m(e;r))c. The delegation event is like a call event
and may be followed by (o1↠o2.n(t))c, while a return event (o′ ←o1′.m′(e′;r))(o→o1.m(e))
may be followed by (o ↞o1.m(e;r))(o→o1.m(e)), closing the cycle. A normal 4 event call cycle
is now generalized to a call cycle of length 4 + 2n where n is the number of delegations in
the cycle. If the initial call is redundant (i.e., the caller, callee, method, and actual input
parameters are given by the main event), the index may be omitted. Thus if delegation is
not used, events are written as in the setting without delegation. We conclude that the cost
of delegation is less than that of the future mechanism.
A simpler approach is to simulate delegation by the statements await dummy: =
o.n(e);return dummy, where dummy is a fresh local variable, not used in the invari-
ant I nor postcondition Q. This is like a delegation except that the delegating object
needs to pass on the result. However, this may be eﬃciently implemented. We denote these
statements delegate o.n(e), whereas the statements dummy: = o.n(e);return dummy,
denoted return o.n(e), represent a blocking version of delegation. Return may also
be generalized to local calls. For ﬂexible programming, we modify our language so
that the last statement in a method body is either a return or delegation statement,
or a (nested) if construct where each branch ends with a return or delegation state-
ment. For instance, method upd of class BANKPLUS can be written {if bal + x⟩=
0 then return BANK:upd(x) else return false fi}. Reasoning rules can be derived

78
From Action Systems to Distributed Systems: The Reﬁnement Approach
from the deﬁnition above:
delegation
h ew (this→o.n(e)) ∧I ⇒∀return . Qh
h·(this↞o.n(e;return))·(caller←this.m(x;return))
[I h
h·(this→o.n(e))] delegate o.n(e) [Q]
where m is the enclosing method and x the formal parameters. For return-call we obtain
[o ̸= this ∧Qh
h·(this→o.n(e))·(this↞o.n(e;return))·(caller←this.m(x;return))] return o.n(e) [Q]
for remote calls (local calls are similar to earlier). This allows reasoning with a delegation-like
construct without changing the structure of events nor the notion of wellformedness.
5.7
Conclusion
We have motivated and presented the main elements of a concurrency model and rea-
soning framework based on active, concurrent objects. From a programming point of view
the model allows eﬃcient and simple programming of distributed and multi-core systems,
resulting in a high degree of parallelism, and with semantically simple synchronization mech-
anisms, allowing local synchronization control within each method. Reasoning about such
systems has been studied in [98, 264, 119, 9, 115, 117, 114]; [224, 9] survey research out-
side this framework. The current work makes several improvements on this setting: In the
compositional reasoning our treatment is based on interface invariants rather than directly
on class invariants, simplifying the treatment of preﬁx closure of class invariants. Secondly,
the axiomatic semantics is simpliﬁed by the statement for interleaved call introduced here.
Finally, we have shown how lazy behavioral subtyping can be replaced by what we call
behavioral interface subtyping, avoiding inheritance of requirements to subclasses, thereby
allowing free code reuse (as long as the speciﬁed interfaces are supported by each class). As
seen in the example, this makes a signiﬁcant diﬀerence in practice.
The approach is modular since each class can be analyzed separately, verifying the given
speciﬁcations and implements-claims, and subclasses can be added incrementally. In a sub-
class one may need to verify new properties of inherited or statically called methods of
a superclass C. By separating code inheritance from speciﬁcation inheritance we obtain
control of code reuse. Behavioral subtyping corresponds to inheriting while respecting su-
perclass speciﬁcations, lazy behavioral subtyping corresponds to inheriting while respecting
only pre/postconditions of redeﬁned methods, and free code reuse corresponds to inheriting
without respecting superclass speciﬁcation.
We have avoided the use of futures/call labels in order to make the language more high-
level. This has the advantage that the connection between postconditions and history-based
invariants is direct, not depending on future identities. The interleaved call statement has
allowed us to present a label-free version of the language with the expressiveness of normal
(i.e., pair-wise) use of call labels. The presented rules for the diﬀerent call mechanisms are
simpler than in earlier work on future/label-free communication [119], due to the treatment
of interleaved call and guarded suspension. Reasoning is as for sequential programs, apart
from side-eﬀects on the local history. Some topics have not been considered, like typing
considerations, dynamic class updates [258, 191] and constructs for object grouping, which
allow clusters of concurrent objects to be seen as a single object from the outside [190].

Veriﬁable Programming of Object-Oriented and Distributed Systems
79
We have not included soundness and completeness of the Hoare style reasoning sys-
tem, but the basic primitives are modeled by (partly non-executable) assignments where all
updates on the history are explicit. The given rules can be derived from this model.
A number of tools have been developed for the presented concurrency model, mainly
under the HATS project, including compilers and a reasoning framework in KeY [7]. In
order to exploit the paradigm presented here in Java, a Java library has been developed
allowing Java programming with the described communication primitives and concurrency
model [239].
Acknowledgments
The author has known Kaisa Sere since the late 80ies and is indebted to her for many
years of discussions on Action Systems and the concurrency model of this paper, and its
predecessors, especially through the yearly NWPT workshops.
The reviewers and Charlie McDowell have contributed constructively to the presentation
and discussions of the paper. This work relates to the EU projects FP7-610582 Envisage:
Engineering Virtualized Services (http://www.envisage-project.eu) and FP7-ICT-
2013-X UpScale: From Inherent Concurrency to Massive Parallelism through Type-based
Optimizations (http://www.upscale-project.eu).

This page intentionally left blank
This page intentionally left blank

Chapter 6
A Contract-Based Approach to Ensuring
Component Interoperability in Event-B
Linas Laibinis
Åbo Akademi University, Turku, Finland
Elena Troubitsyna
Åbo Akademi University, Turku, Finland
6.1
Introduction ......................................................
82
6.2
Background: Event-B ............................................
83
6.2.1
Modelling and Reﬁnement in Event-B ..................
83
6.2.2
Modelling Modular Systems in Event-B ................
85
6.3
From Event-B Modelling to Contracts ...........................
88
6.3.1
Contracts ................................................
88
6.3.2
From a Module Interface to a Component Contract ....
89
6.4
Example: An Auction System ....................................
90
6.4.1
Initial Model .............................................
90
6.5
Conclusions .......................................................
95
Abstract. The design by contract approach enables rigorous development of component-
based software systems. In particular, it allows us to ensure component interoperability.
However, deﬁning the contracts themselves is often a challenging task, especially in the
development of decentralised systems with complex component interdependencies. In this
paper, we propose a reﬁnement-based approach facilitating deﬁnition of contracts and en-
suring component interoperability. The approach is based on the Event-B formalism and
its modularisation extension. In the Event-B reﬁnement process, we gradually introduce a
representation of inter-component communication, distribute the global state space between
the components, and decouple them. Finally, we decompose the resulting system speciﬁ-
cation into independent modules by formally deﬁning module interfaces, obtaining at the
same time component contracts. This allows us to propagate the system level properties into
the component contracts and ensure component interoperability. The proposed approach is
illustrated by an example – an auction system.
81

82
From Action Systems to Distributed Systems: The Reﬁnement Approach
6.1
Introduction
Ensuring component interoperability constitutes one of the main challenges in the
component-based development approach [161]. The approach relies on a composition of
reusable software components (or services) to implement a desired functionality [323]. While
composing them, we should ensure that the components are compatible not only at the in-
terface but also at the semantic level. Essentially, it requires for the components to share
the knowledge about their globally observable behaviour and properties. The most popular
approach to representing such knowledge is by deﬁning component contracts.
Usually a contract is expressed as an assumption-guarantee pair [170]. The assumption
part postulates the properties that the component’s environment should satisfy, while the
guarantee part deﬁnes the properties that must be satisﬁed by the component itself.
The design by contract approach proposed by Meyer [244] facilitates structuring of soft-
ware into encapsulated modules with contracts regulating component interactions. While
the beneﬁts of the contract-based approach are evident, deﬁning the contracts themselves is
often a challenging task, especially in the development of decentralised systems with com-
plex component interdependencies. In this paper, we propose a reﬁnement-based approach
facilitating deﬁnition of contracts and ensuring component interoperability.
The formal basis of the proposed approach is within Event-B [6] and its modularisa-
tion extension [182]. Event-B is a formal approach for designing correct-by-construction
distributed systems. The main development technique of Event-B – reﬁnement – allows
the designers to transform an abstract speciﬁcation into a detailed model through a chain
of correctness-preserving model transformations. Each reﬁnement step is veriﬁed by proofs
guaranteeing that the reﬁned model preserves the externally observable behaviour and does
not introduce new deadlocks. Modelling and veriﬁcation in Event-B is automated by an
industrial-strength tool – the Rodin platform [327].
Reﬁnement allows us to formally deﬁne relations between models representing the system
behaviour at diﬀerent levels of abstraction. Hence it constitutes a suitable mechanism for
establishing relationships between the system-level properties and the behaviour of system
components.
The main idea behind our approach is to derive component contracts from a formal
Event-B speciﬁcation of the overall system. We start from an abstract centralised speci-
ﬁcation of the system. The initial model relies on the shared global state and abstracts
away the communication between the components. The interoperability properties are fairly
transparent at this level and easy to deﬁne. In the reﬁnement process, while elaborating
on the system behaviour and properties, we introduce a representation of inter-component
communication, distribute the global state space between the components, and decouple
them. Finally, we decompose the obtained system speciﬁcation into independent modules.
While deriving the module interfaces, we at the same time deﬁne their contracts. Since de-
composition is a special kind of reﬁnement step, we guarantee that the components remain
interoperable under the derived contracts.
We believe that the proposed approach facilitates the rigorous development of complex
component-based systems and enhances conﬁdence in the correctness of the overall system
design. It allows us to propagate the system level properties into the component contracts
and ensure component interoperability.
The paper is structured as follows: in Section 6.2, we present our main modelling frame-

A Contract-Based Approach to Ensuring Component Interoperability in Event-B
83
Machine M
Variables v
Invariants I
Events
Init
evt1
· · ·
evtN
−→
Context C
Carrier Sets s
Constants c
Axioms A
Figure 6.1: Event-B machine and context components
work – Event-B and its modularisation extension. In Section 6.3, we demonstrate how to
derive contracts from Event-B models using the modularisation extension. In Section 6.4,
we give a small illustrative example – an auction system. Finally, in Section 6.5, we overview
the proposed approach and discuss the related work.
6.2
Background: Event-B
In this section, we overview our modelling framework – Event-B. The Event-B formal-
ism [6] is a state-based formal approach that promotes the correct-by-construction develop-
ment paradigm and formal veriﬁcation by theorem proving. Event-B is a specialisation of
the B Method that facilitates modelling of event-based (reactive) systems by incorporating
the ideas of the Action Systems formalism [35] into the B Method.
6.2.1
Modelling and Reﬁnement in Event-B
In Event-B, a system speciﬁcation (model) is deﬁned using the notion of an abstract
state machine [6]. An abstract state machine encapsulates the model state, represented as a
collection of model variables, and deﬁnes operations on this state. Therefore, it describes the
dynamic part (behaviour) of the modelled system. Usually a machine also has the accompa-
nying component, called context, which contains the static part of the model. In particular,
a context can include user-deﬁned carrier sets, constants and their properties, which are
given as a list of model axioms. A general form of Event-B models is given in Figure 6.1.
The machine is uniquely identiﬁed by its name M. The state variables, v, are declared
in the Variables clause and initialised in the Init event. The variables are strongly typed
by the constraining predicates I given in the Invariants clause. The invariant clause might
also contain other predicates deﬁning properties that should be preserved during system
execution.
The dynamic behaviour of the system is deﬁned by the set of atomic events speciﬁed in
the Events clause. Generally, an event can be deﬁned as follows:
any lv where g then S end,
where lv is a list of new local variables (parameters), the guard g is a state predicate, and

84
From Action Systems to Distributed Systems: The Reﬁnement Approach
Statement (S)
BAS(s, c, lv, x, y, x′)
skip
x′ = x ∧y′ = y
x: = E(s, c, lv, x, y)
x′ = E(s, c, lv, x, y) ∧y′ = y
x: ∈Set
x′ ∈Set ∧y′ = y
x: | P(s, c, lv, x, y, x′)
P(s, c, lv, x, y, x′) ∧y′ = y
S1 ∥S2
BAS1 ∧BAS2
Figure 6.2: Before-after predicates
the action S is a statement (assignment). In the case when lv is empty, the event syntax
becomes when g then S end. If g is always true, the syntax can be further simpliﬁed to
begin S end.
The occurrence of events represents the observable behaviour of the system. The guard
deﬁnes the conditions under which the action can be executed, i.e., when the event is enabled.
If several events are enabled at the same time, any of them can be chosen for execution
nondeterministically. If none of the events is enabled then the system deadlocks.
In general, the action of an event is a parallel composition of statements (assignments).
The statements can be either deterministic or non-deterministic. A deterministic assign-
ment, x: = E(x, y), has the standard syntax and meaning. A nondeterministic assignment
is denoted either as x: ∈Set, where Set is a set of values, or x: | P(x, y, x′), where P is a
predicate relating initial values of x and y to some ﬁnal value of x′. As a result of such an
assignment, x can get any value belonging to Set or according to P.
Semantics of an Abstract Model. The semantics of Event-B actions is deﬁned using
before-after (BA) predicates [6]. A before-after predicate describes a relationship between
the system states before and after an execution of an event action. The deﬁnitions of a BA for
diﬀerent action statements are shown in Figure 6.2. Here x and y are disjoint lists (partitions)
of state variables, and x′, y′ represent their values in the state after the action execution.
Moreover, lv refers to the local event variables, where s and c stand for respectively the sets
and constants deﬁned in the model context.
The notion of a BA predicate can be easily generalised to formally deﬁne model events.
For an event e of the form any lv where g then S end, its BA predicate is as follows:
BAe(s, c, x, y, x′)
=
∃lv. g(s, c, lv, x, y) ∧BAS(s, c, lv, x, y, x′)
The semantics of a whole Event-B model is formulated as a number of proof obligations,
expressed in the form of logical sequents. Below we present only the most important proof
obligations that should be veriﬁed for the initial and reﬁned models. The full list of proof
obligations can be found in [6].
An initial Event-B model should satisfy the event feasibility and invariant preservation
properties. For each event of the model – ei – its feasibility means that, whenever the event
ei is enabled, its before-after predicate (BA) is well-deﬁned, i.e., there exists some reachable
after-state:
A(s, c), I(s, c, v), gei(s, c, lv, v) ⊢∃v′· BAei(s, c, lv, v, v′)
(FIS)
where A are the model axioms, I is the model invariant, gei is the event guard, d are the
model sets, c are the model constants, lv are the local event variables, and v, v′ are the
variable values before and after event execution.

A Contract-Based Approach to Ensuring Component Interoperability in Event-B
85
Each event ei of an initial Event-B model should also preserve the given model invariant:
A(s, c), I(s, c, v), gei(s, c, lv, v), BAei(s, c, lv, v, v′) ⊢I(s, c, v′)
(INV)
Since the initialisation event Init has no initial state, local variables, and guard, its proof
obligation is simpler:
A(s, c), BAInit(s, c, v′) ⊢I(s, c, v′)
(INIT)
Semantics of a Reﬁned Model. Event-B employs a top-down reﬁnement-based approach
to system development. Development starts from an abstract system speciﬁcation that mod-
els the most essential functional requirements. While capturing more detailed requirements,
each reﬁnement step typically introduces new events and variables into the abstract model.
These new events correspond to stuttering steps that are not visible at the abstract level.
To verify the correctness of a reﬁnement step, we need to prove a number of proof
obligations for the reﬁned model. Intuitively, those proof obligations allow us to demonstrate
that the reﬁned machine does not introduce new observable behaviour, more speciﬁcally, that
concrete states are linked to the abstract ones via the given (gluing) invariant of the reﬁned
model. All proved properties of the abstract model are automatically "inherited" by the
reﬁned one. For brevity, we omit here discussion of these proof obligations. They can be
found in [6].
The Event-B reﬁnement process allows us to gradually introduce implementation details,
while preserving functional correctness during stepwise model transformation. The model
veriﬁcation eﬀort, in particular, automatic generation and proving of the required proof obli-
gations, is signiﬁcantly facilitated by the provided tool support – the Rodin platform [327].
6.2.2
Modelling Modular Systems in Event-B
Recently the Event-B language and tool support have been extended with a possibility
to deﬁne modules [182, 277] – components containing groups of callable operations. Modules
can have their own (external and internal) state and the invariant properties. The important
characteristic of modules is that they can be developed separately and then composed with
the main system.
Module Structure. A module description consists of two parts – module interface and
module body. Let M be a module. The module interface is a separate Event-B component. It
allows the user of the module M to invoke its operations and observe the external variables
of M without having to inspect the module implementation details. The module interface
consists of the module interface description MI and its context MI Context. The context
deﬁnes the required constants c and sets s. The interface description consists, respectively,
of the external module variables w, the external module invariant M Inv(s, c, w), and a
collection of module operations, characterised by their pre- and postconditions, as shown in
Figure 6.3. The primed variables in the operation postcondition stand for the variable values
after operation execution, while the predeﬁned variable res refers to the operation result to
be returned.
In addition, a module interface description may contain a group of standard Event-B
events under the PROCESS clause. These events model the autonomous module thread of con-
trol, expressed in terms of their eﬀect on the external module variables. In other words, the
module process describes how the module external variables may change between operation
calls.

86
From Action Systems to Distributed Systems: The Reﬁnement Approach
INTERFACE MI(id)
SEES MI Context
VARIABLES w
INVARIANT M Inv(s, c, w)
INITIALISATION . . .
PROCESS
PE
=
any vl where g1(s, c, vl, w) then S1(s, c, vl, w, w′) end
. . .
OPERATIONS
O
=
any p pre Pre1(s, c, p, w) post Post1(s, c, p, w, w′, res) end
. . .
END
Figure 6.3: Module interface
A module development always starts with the design of an interface. After an interface is
formulated, it cannot be altered in any manner. This ensures correct relationships between a
module interface and its body, i.e., that the speciﬁcation of an operation call is recomposable
with an operation implementation. A module body is an Event-B machine. It implements
each operation described in the module interface by a separate group of events. Additional
proof obligations are generated to verify the correctness of a module. They guarantee that
each event group faithfully satisﬁes the given pre- and postconditions of the corresponding
interface operation.
Importing of a Module. When the module M is imported into another Event-B machine,
this is speciﬁed by a special clause USES in the importing machine, N. As a result, the
machine N can invoke the operations of M as well as read the external variables of M listed
in the interface MI.
To make a module interface generic, in MI Context we can deﬁne some abstract constants
and sets (types). Moreover, the interface MI itself may be parameterised with the constant
id, which is used as a unique identiﬁer for a module instance within the interface. All
such data structures become module parameters that can be instantiated when a module is
imported. The concrete values or constraints needed for module instantiation are supplied
within the USES clause of the importing machine. Alternatively, the module interface can be
extended with new sets, constants, and the properties that deﬁne new data structures and/or
constrain the old ones. Such an extension produces a new, more concrete module interface.
Via diﬀerent instantiation of generic parameters the designers can easily accommodate the
required variations when developing components with similar functionality. Hence module
instantiation provides us with a powerful mechanism for reuse.
We can create several instances of a given module and import them into the same ma-
chine. Diﬀerent instances of a module operate on disjoint state spaces. Identiﬁer preﬁxes
can be supplied in the USES clause to distinguish the variables and operations of diﬀerent
module instances or those of the importing machine and the imported module. Alternatively,
the pre-deﬁned set can be supplied as an additional parameter. In the latter case, module
instances are created for each element of the given set. The syntax of USES then becomes
as follows:
USES ⟨module interface⟩as ⟨preﬁx ⟩
or
USES ⟨module interface⟩[⟨constant set⟩].

A Contract-Based Approach to Ensuring Component Interoperability in Event-B
87
Semantics of a Module Interface. Similarly to a machine component, the semantics of an
interface component is deﬁned by a number of proof obligations. The module initialisation
must establish the module invariant M Inv:
M Init(s, c, mv′) ⊢M Inv(s, c, mv′)
(MOD INIT)
Let us assume Operi, i ∈1..N, is one of module operations. The module invariant M Inv
should be preserved by each operation execution:
M Inv(s, c, mv), Prei(s, c, p, mv), Posti(s, c, p, mv, mv′, res) ⊢M Inv(s, c, mv′)
(MOD INV1)
where Prei and Posti are respectively the precondition and postcondition of Operi.
Let us assume Evj, j ∈1..K, is one of module process events. The module invariant
M Inv should be also preserved by each such event:
M Inv(s, c, mv), BAj(s, c, lv, mv, mv′) ⊢M Inv(s, c, mv′)
(MOD INV2)
where BAj is the before-after predicate of Evj.
Finally, there is a couple of feasibility proof obligations for each Operi, i ∈1..N. Firstly,
the operation precondition should be true for at least some of the parameter values:
M Inv(s, c, mv) ⊢∃p. Prei(s, c, p, mv)
(MOD PARS)
Secondly, at least some operation post-state containing the required result must be reachable:
M Inv(mv), Prei(p, mv) ⊢∃(mv′, res). Posti(p, mv, mv′, res)
(MOD RES)
Semantics of an Operation Call. A machine importing a module instance operates on
the extended state consisting of its own variables v and the module variables mv. The module
state can be updated in event actions only via operations calls. The semantics of an event
containing an operation call is as follows.
Let us consider the model event Ec that contains a call to the module operation Op with
the given arguments args, i.e., it is of the form
any lv where g then S[Op(args)] end.
The BA predicate of such an event can be deﬁned as follows:
BAEc(s, c, v, mv, v′, mv′)
=
∃(lv, res, new mv). g(s, c, lv, v, mv) ∧
Post(sMI, cMI, args, mv, new mv, res) ∧
BAS∗(s, c, lv, v, mv, res, v′) ∧(mv′ = new mv),
where S∗is S with all the occurrences of Op(args) replaced by res, while sMI and cMI are
respectively the sets and constants deﬁned in the module interface context. Once this is
done, we can rely on the existing proof semantics to verify the invariant preservation, event
simulation, and other required properties.
Moreover, we need an additional proof obligation to ensure call correctness by checking
that the operation precondition holds at the place of an operation call:
g(s, c, lv, v, mv), Inv(s, c, v, mv), M Inv(sMI, cMI, mv) ⊢Pre(sMI, cMI, args, mv)
(CALL CORR)
The modularisation extension of Event-B facilitates formal development of complex sys-
tems by allowing the designers to decompose large speciﬁcations into separate components
and verify system-level properties at the architectural level. Next we demonstrate how to
deﬁne contracts based on the modularisation extension of Event-B.

88
From Action Systems to Distributed Systems: The Reﬁnement Approach
COMPONENT CLASS C(id)
EXTERNAL VARIABLES v
INVARIANT Inv(v)
INITIALISATION Init(v)
ACTIONS
A1 = params w pre Pre1(v, w) post Post1(v, w, v′)
A2 = params w pre Pre2(v, w) post Post2(v, w, v′)
...
An = params w pre Pren(v, w) post Postn(v, w, v′)
END
Figure 6.4: Component contract
6.3
From Event-B Modelling to Contracts
6.3.1
Contracts
Contracts constitute a widely-used approach to ensuring component interoperabil-
ity [161, 244]. Via their contracts, the components share the knowledge about their globally
observable behaviour and properties. In the component-based frameworks, a contract is usu-
ally deﬁned as an assume-guarantee pair [170]. The assumption part deﬁnes the properties
that the environment must satisfy, while the guarantee part expresses the properties that
should be satisﬁed by the component itself.
The development methodology based on reﬁnement allows us to express system-wide
properties, which can signiﬁcantly facilitate deﬁnition of component contracts. These prop-
erties are deﬁned as model invariants. Our goal is to ﬁnd a mechanism for propagating the
relevant system-level properties into the component contracts.
To ensure component interoperability, in our deﬁnition of a contract, we will describe
the component interface, interactions between the component and its environment, as well
as abstractions for the expected autonomous behaviour of a component. The generic form
of a contract for a class of components C is presented in Figure 6.4.
Since one of the strengths of the component-based development is the support for com-
ponent reuse, a single contract can represent a family (class) of components that might diﬀer
by their implementations, internal behaviour, etc. Hence, in our deﬁnition of a component
contract given in Figure 6.4, we explicitly state that the contract is deﬁned for a class of
components.
The EXTERNAL VARIABLES clause deﬁnes the globally observable state of com-
ponents (represented by a collection of variables v). The INVARIANT clause deﬁnes the
types of the external variables as well as the properties always maintained over them. The
initial state of a component is constructed according to the state predicate deﬁned in the
INITIALISATION clause. The ACTIONS part of the contract regulates the dynamic
behaviour of the component. It is deﬁned as a pre- and post-condition pair for each oper-
ation of the component that changes its externally observable state. The operations might

A Contract-Based Approach to Ensuring Component Interoperability in Event-B
89
have parameters that are deﬁned in the params clause. Finally, the class itself may be
parameterised with the constant id to be used as a unique identiﬁer for class instances.
It is easy to note, that the deﬁnition of a contract closely resembles the deﬁnition of
a module interface given in Figure 6.3. Indeed, a module interface deﬁnes the globally ob-
servable state of the component, its properties in the INVARIANT clause and callable
operations as pre- and postcondition pairs. The only diﬀerence is in representing the internal
(autonomous) component behaviour deﬁned in the PROCESS clause. Next we will address
this issue and establish a correspondence between the deﬁnitions of a module interface and
a contract.
6.3.2
From a Module Interface to a Component Contract
In our deﬁnition of the module, the PROCESS clause deﬁnes the autonomous internal
behaviour of the component, i.e., speciﬁes how the external component state may change
between operation calls. The behaviour is modelled by a set of events. To transform this
representation into the pre-postcondition format, let us give an alternative deﬁnition of an
Event-B event.
Essentially, an event e of the form any a where Ge then BAe end is a relation de-
scribing the corresponding state transformation from σ to σ′, such that
e(σ, σ′) = ∃ρ· I(s, c, σ) ∧Ge(s, c, ρ, σ) ∧BAe(s, c, ρ, σ, σ′),
where ρ represents the local event state. Here we treat the model invariant I as an implicit
event guard. Note that, due to the possible presence of nondeterminism, the successor state
σ′ is not necessarily unique.
In other words, the semantics of a single model event is given as a binary relation between
pre- and post-states of the event. To represent this relationship, we deﬁne two functions
before and after in a way similar to [179, 326]:
before(e) = {(ρ, σ) | I(s, c, σ) ∧Ge(s, c, ρ, σ)}
and
after(e) = {σ′ | ∃ρ, σ· I(s, c, σ) ∧Ge(s, c, ρ, σ) ∧BAe(s, c, ρ, σ, σ′)}.
One can see that, for a given event e and any state σ ∈Σ, e is enabled in σ if and only if
(ρ, σ) ∈before(e) for some possible value of the local variables ρ. Essentially, the functions
before and after deﬁne the domain and range of the underlying semantic event deﬁnition as
a before-after relation between the states.1
The alternative representation of an event allows us to express both externally callable
operations and autonomic component behaviour in the pre- and postcondition form. To be
more precise, each callable interface operation
Opi
=
any pi pre Prei(...) post Posti(...) end
is directly translated into the action
Ai = params pi pre Prei post Posti,
while each event in the PROCESS clause
1We slightly modiﬁed the before deﬁnition comparing to its original one, where before(e)
=
{σ |
∃ρ · I(s, c, σ) ∧Ge(s, c, ρ, σ)}, to make it more suitable for deﬁning component contracts.

90
From Action Systems to Distributed Systems: The Reﬁnement Approach
Evj
=
any lvj where Gj(...) then BAj(...) end
is mapped into the following action:
Aj = params lvj pre before(Evj) post after(Evj),
where before and after are the functions deﬁned above.
We have established the correspondence between the deﬁnitions of a module interface
and a contract. We believe that the modularisation extension of Event-B has provided us
with a suitable basis for deriving component contracts. Indeed, it allows us to easily derive
the deﬁnitions of all parts of a contract from the corresponding deﬁnition of a module inter-
face. Since the component contracts are derived from a speciﬁcation of the overall system,
our approach supports “interoperability by construction”. It ensures that the components
composed to achieve the speciﬁed system functionality are interoperable provided they com-
ply with the derived contracts. In the next section, we illustrate the proposed approach by
an example – an auction system.
6.4
Example: An Auction System
In this section, we illustrate the proposed approach by an example – a simple electronic
auction. We start from a centralised abstract system model of an auction, then introduce an
abstract model of the communication mechanism for sending and receiving diﬀerent types of
requests, and, ﬁnally, decompose the model into speciﬁcations of the interfaces (contracts)
of the involved components.
6.4.1
Initial Model
The initial auction speciﬁcation describes the activities of components of three diﬀerent
types: a seller, a buyer, and a manager. There could be any number of sellers and buyers
participating in the system. However, there should be only one manager, which keeps the
information about the current auction state and controls validity of the auction operations.
The auction speciﬁcation describes the following allowed scenario for a seller, a buyer,
and a manager. The scenario is initiated by a seller, who announces an item to be sold at
the auction. Once the item announcement is received by the manager, the bidding process
for this particular item starts. Any active buyer can make its bid. However, only higher bids
(for a particular item) are accepted by the manager. After a predeﬁned number of bids, the
bidding process is stopped and the winner (i.e., a bidder with the highest bid) is decided by
the manager. Once the payment from the winner is received, the item is declared oﬃcially
sold, and the corresponding seller and buyer are notiﬁed about the transaction.
We can depict the scenario as the following chain of operations (events) involving a seller,
a buyer, and the manager:

A Contract-Based Approach to Ensuring Component Interoperability in Event-B
91
Put new item(Seller) −→Get new item(Manager) −→Make bid(Buyer)
−→Take bid(Manager) · · · −→Make bid(Manager) −→Take bid(Manager)
−→Declare winner(Manager) −→Make payment(Buyer)
−→Receive payment(Manager) −→Item sold(Manager)
−→Selling confirmed(Seller) −→Buying confirmed(Buyer)
We specify all these steps as the corresponding events in our Event-B model of the auc-
tion system. Each event also has an annotation indicating to which component it belongs.
Moreover, we distribute the program variables among the involved components as well. Most
variables are associated with the manager, except for buyer log and seller log, which be-
long to a (collective) seller and a (collective) buyer respectively.
SYSTEM Auction
SEES Auction Context
VARIABLES
bids, bids left, winner, paid items, item seller, buyer log, seller log, done
INVARIANT ... buyer log ⊆paid items ∧seller log ⊆paid items ∧
∀ii. ii ∈ITEM ∧done(ii) = TRUE ⇒(ii ∈buyer log ⇔ii ∈seller log)
INITIALISATION ...
EVENTS
Put new item = .../* seller */
Get new item = .../*manager */
Make bid = ../* buyer */
Take bid = /* manager */
Declare winner = /* manager */
END
Make payment = /* buyer */
Receive payment = .../* manager */
Item sold = · · · /* manager */
Selling conﬁrmed = .../* seller */
Buying conﬁrmed = /* buyer */
For brevity, in the invariant part, we show only a couple of the most important correctness
properties of the auction system: (i) all bought and sold items should be paid for, and (ii)
once the auction is done for a particular item, it should be recorded in both buyer’s and
seller’s logs.
Below, we show two auction events in detail.
Get new item =
any ss, ii where
ss ∈SELLER
ii ∈ITEM
done(ii) = FALSE
then
bids(ii): = (NO BUYER 7→0)
bids left(ii): = MAX BIDS
item seller(ii): = ss
end
Receive payment =
any bb, ii where
bb ∈BUYER
ii ∈ITEM
bb = winner(ii)
ii ̸∈paid items
then
paid items: = paid items ∪{ii}
end
The event Get new item speciﬁes the manager’s reaction after getting a new item to sell.
As a result, the bidding process is initiated. The event Receive payment models recording
of the received buyer payment by the manager.
In the initial model, the involved components can directly read each other’s state in
the event guards. In the ﬁrst reﬁnement step, we decouple these components by explicitly
introducing communication between them. The components communicate by sending and
receiving requests. The received requests are stored in their input buﬀers, while the requests
to be sent are put in their output buﬀers. The system model becomes more decentralised.

92
From Action Systems to Distributed Systems: The Reﬁnement Approach
However, the buyer and seller buﬀers are still collectively modelled by the corresponding
arrays variables.
After an introduction of communication, the manager events Get new item and
Receive payment receive the following form:
Get new item =
any rr, ss, ii where
rr ∈Selling Req
rr ∈manager input
ss = Seller(rr)
ii = Item(rr)
done(ii) = FALSE
then
...
manager input: =
manager input\{rr}
end
Receive payment =
any bb, ii where
...
then
...
manager output: = manager output
∪{Pay Conﬁrmation(item seller(ii) 7→ii)}
end
The ﬁrst event now models the manager reaction on the received selling request in its
input buﬀer, while the second event creates a payment conﬁrmation request to be sent to
the item seller and places it into the output buﬀer.
In addition, the reﬁned model contains the events, sole purpose of which is to transport
requests from the output buﬀer of one component to the input buﬀer of the recipient com-
ponent. Essentially, these events specify the behaviour of middleware that is responsible for
implementing component communication.
We specify the middleware events that represent communication between the sellers and
the managers as follows:
Seller to Manager =
any ss, rr where
ss ∈SELLER
rr ∈seller output(ss)
rr ̸∈manager input
then
seller output(ss): = seller output(ss)\{rr}
manager input: = manager input ∪{rr}
end
Manager to Seller =
any ss, rr where
ss ∈SELLER
rr ̸∈seller input(ss)
rr ∈manager output
then
seller output(ss): = seller output(ss) ∪{rr}
manager input: = manager input\{rr}
end
The respective events for the buyer-manager communication are added as well.
In the second reﬁnement step, we decompose the system speciﬁcation by explicitly in-
troducing the manager component as well as the buyer and seller components for each
element of the given sets BUYER and SELLER. We will rely on the modularisation exten-
sion of Event-B to decompose the system model. The system model is reﬁned into that of
the middleware, which calls, when needed, operations from the corresponding introduced
components.
To perform such a decomposition reﬁnement step, we need to
1. Deﬁne separate module interfaces for the manager, a buyer, and a seller;
2. Distribute the system state (not belonging to the middleware) among the introduced
components;
3. In each interface, deﬁne the callable operations for accessing the component input and
output buﬀers;

A Contract-Based Approach to Ensuring Component Interoperability in Event-B
93
4. Distribute the events describing the autonomous component behaviour among the
components, deﬁning them as the corresponding module processes;
5. Deﬁne the gluing invariants, relating the array variables modelling the collective knowl-
edge (e.g., buyer and seller logs) with the respective variables belonging to single mod-
ule instances. Essentially, this allows us to propagate system-level properties into the
deﬁnition of the derived module interfaces.
In Figure 6.5, we present the deﬁned interface for the seller component. In a similar way,
the interfaces for the manager, buyer, and seller components are deﬁned. Having the seller
interface deﬁned, it is rather straightforward to obtain the corresponding class contract for
all sellers (see Figure 6.6).
INTERFACE Seller(id)
VARIABLES input, output, log
INVARIANT (∀rr ∈output. Item(rr) ̸∈log) ∧(∀rr ∈input. Id(rr) = id) ∧
(∀rr ∈input ∩Selling Req. Item(rr) ̸∈log) ∧· · ·
INITIALISATION input = ∅∧output = ∅∧log = ∅
PROCESS
Put new item
=
any ii where ii ∈ITEM ∧ii ̸∈log
then output: = output ∪{Sell Request(id 7→ii)} end
Selling confirmed
=
any rr where rr ∈input ∩Pay Conﬁrmation
then log: = log ∪{ii} ∥input: = input\{rr} end
OPERATIONS
Add request
=
any rr pre
rr ∈Pay Conﬁrmation ∧rr ̸∈input ∧Id(rr) = id
post
input′ = input ∪{rr}
end
Take request
=
any rr pre
rr ∈Selling Req ∪Selling Ackn ∧rr ∈output
post
output′ = output\{rr}
end
END
Figure 6.5: Interface component
The core reﬁned model now consists only of the state and events of the system middle-
ware. The additional clause USES creates one instance of the manager component as well
as a number of instances of the seller and buyer components – one per each element of the
given sets SELLER and BUYER.
SYSTEM Auction 2nd reﬁnement
USES Manager as manager, Seller[SELLER], Buyer[BUYER]
VARIABLES ...
INVARIANT ...
INITIALISATION ...
EVENTS
Seller to Manager = .../* middleware */
Manager to Seller = .../*middleware */
Buyer to Manager = ../* middleware */
Manager to Buyer = /* middleware */
END

94
From Action Systems to Distributed Systems: The Reﬁnement Approach
COMPONENT CLASS Seller(id)
VARIABLES input, output, log
INVARIANT (∀rr ∈output. Item(rr) ̸∈log) ∧(∀rr ∈input. Id(rr) = id) ∧
(∀rr ∈input ∩Selling Req. Item(rr) ̸∈log) ∧· · ·
INITIALISATION input = ∅∧output = ∅∧log = ∅
ACTIONS
Put new item
=
params ii pre
ii ∈ITEM ∧ii ̸∈log
post
output′ = output ∪{Sell Request(id 7→ii)}
end
Selling confirmed
=
params rr pre
rr ∈input ∩Pay Conﬁrmation ∧
Id(rr) = id ∧Item(rr) ̸∈log
post
log′ = log ∪{ii} ∧input′ = input\{rr}
end
Add request
=
params rr pre
rr ∈Pay Conﬁrmation ∧rr ̸∈input ∧Id(rr) = id
post
input′ = input ∪{rr}
end
Take request
=
params rr pre
rr ∈Selling Req ∪Selling Ackn ∧rr ∈output
post
output′ = output\{rr}
end
END
Figure 6.6: The seller class contract
The invariant clause must also include the gluing invariants between the abstract model
variables and the variables of the decentralised system, e.g.,
∀ss. ss ∈SELLER ⇒input(ss) = seller input(ss)
∀ss. ss ∈SELLER ⇒log(ss) = seller log(ss)
In other words, these invariants relate the array variables of a centralised system before the
reﬁnement step, seller input and seller log, with the corresponding variables, input and log,
of the seller components.
Below we show in detail a couple of middleware events. Note that now they are deﬁned
only in terms of the operation calls to the interface operations of the involved components.
Seller to Manager =
any ss, rr where
ss ∈SELLER
rr ∈output(ss)
rr ̸∈man.input
then
Take request(ss)(rr)
manager Add request(rr)
end
Manager to Seller =
any ss, rr where
ss ∈SELLER
rr ̸∈input(ss)
rr ∈man.output
then
manager Take request(rr)
Add request(ss)(rr)
end
The derived interfaces of the buyer and the seller modules represent their contracts.
The auction system can be developed by composing the seller, buyer, and middleware

A Contract-Based Approach to Ensuring Component Interoperability in Event-B
95
components. To ensure interoperability of the implemented components, the designers need
to verify that the components comply to the contracts deﬁned above.
While developing the auction system, we have employed the strategy that is usually
used for the development of distributed systems by reﬁnement [184, 181, 183]. Namely,
we start from an abstract centralised system model. In such a model, components can
directly access each other’s state. This allows us to simplify deﬁnition of the system-level
invariant properties, including the ones that express interoperability conditions. In a number
of reﬁnement steps, we introduce a representation of the detailed functional requirements
as well as communication mechanisms between the components. Finally, we perform model
decomposition and arrive at a decentralised system model. Such a model typically consists of
the components that communicate with each other via the communication support provided
by the introduced middleware component. The decomposition reﬁnement step also allows
us to derive the corresponding contracts of the system components.
6.5
Conclusions
In this paper, we have presented a rigorous approach to ensuring component interoper-
ability. The main idea of the approach was to derive contracts of the constituting components
from the overall system speciﬁcation in Event-B. The modularisation extension of Event-B
allowed us to decompose the system speciﬁcation into the independent components – mod-
ules. A module interface deﬁnes a family of components that might vary in implementation
and the internal behaviour but nevertheless comply to the contract deﬁned by the module
interface. As a next step, we have demonstrated how to transform such a module interface
into the corresponding contract of a component.
Our ideas were illustrated by an example – an auction system. An application of the
proposed approach allowed us to formally deﬁne interoperability of the buyer, seller, and
middleware components, i.e., ensure their correct interactions during the auction activities.
Our approach has been inspired by the seminal works of Kaisa Sere and her group on
reﬁnement, modularisation, and decomposition in the action systems formalism. The fun-
damental theoretical aspects of the reﬁnement approach to the development of distributed
systems were presented by Back and Sere in [32]. The modularisation idea for the action sys-
tems framework was proposed in [33]. The systems approach to development by reﬁnement
that enables propagation of the system-level properties into the models of components have
been proposed in [73]. Since Event-B has adopted many aspects of the theoretical founda-
tions of the action systems framework, in our approach we followed the decomposition-based
development approach deﬁned by the action systems framework. We extended the original
ideas by the notions of module interface and component contracts.
The concept of contracts has been exploited in various domains and development ap-
proaches. Majority of the approaches aim at facilitating compositional component-based de-
velopment. A foundational work on rigorous aspects of such development was done within the
EU FP6 SPEEDS project [313]. The project studied theoretical aspects of formal component-
based design. It proposed a component-based framework that deﬁnes component properties
as extended transition systems and diﬀerent compositional approaches associated with it.
A contract-based top-down design methodology was proposed by Quinton and Graf [272].
This work explored diﬀerent forms of conformance of a component to a contract that is

96
From Action Systems to Distributed Systems: The Reﬁnement Approach
deﬁned by corresponding notions of reﬁnement. The authors also deﬁne reﬁnement relation
between contracts. There is also a vast body of research on contracts that is based on
behavioural typing, where a contract is an abstraction of the component behaviour as a
transition system, see, e.g., [68, 78]. As a result of this research, many contract languages
were proposed, which deﬁne various ways contracts can be composed and compared, while
the behavioural subtyping relation, which can be seen as reﬁnement, is used for compliance
of the component behaviour to a contract.
In our work, we pursued another goal – we aimed at deriving contracts from a reﬁned and
decomposed system speciﬁcation in Event-B. The reﬁnement process allows us to preserve
the global system properties, while gradually decoupling the components and formally deﬁn-
ing their interfaces. As a result, the derived contracts ensure that any component conforming
to its contract is interoperable with the other components of the system.
Deﬁning contracts for complex component-based systems is still a challenging problem.
We believe that the proposed approach helps to alleviate it. Indeed, it allows us to derive
component contracts from a speciﬁcation that rigorously deﬁnes the overall interoperability
conditions for components and their environments. As a future work, we are planning to
experiment with the notion of probabilistic contracts, in particular, in the domain of fault
tolerant systems.

Part III
Proof
97

This page intentionally left blank
This page intentionally left blank

Chapter 7
Meeting Deadlines, Elastically
Einar Broch Johnsen
University of Oslo
Ka I Pun
University of Oslo
Martin Steﬀen
University of Oslo
S. Lizeth Tapia Tarifa
University of Oslo
Ingrid Chieh Yu
University of Oslo
7.1
Introduction ......................................................
100
7.2
Service Contracts as Interfaces ..................................
101
7.3
A Kernel Language for Virtualized Computing .................
102
7.4
Example: A Photo Printing Shop ................................
103
7.5
Proof System .....................................................
105
7.6
Related Work ....................................................
108
7.7
Discussion ........................................................
110
Abstract.
Cloud computing oﬀers a pay-on-demand scalable infrastructure for data processing.
Resource-aware services can exploit this infrastructure to elastically adapt to client traﬃc
according to internal resource policies which balance provided QoS with the accrued costs
of deployment. This paper presents initial work on worst-case response time analysis for ser-
vices which distribute tasks to virtual machine instances with diﬀerent processing speeds.
We extend JML-like interfaces with response time annotations and develop a Hoare-style
proof system to reason about response time guarantees for services expressed in a simple
object-oriented language in which dynamically created objects diﬀer in processing capac-
ity. The simpliﬁed setting considered in this paper does not consider loops, concurrency, or
reﬂection; we brieﬂy discuss how these restrictions could be lifted.
99

100
From Action Systems to Distributed Systems: The Reﬁnement Approach
7.1
Introduction
A cloud consists of virtual computers that are accessed remotely for data storage and
processing. The cloud is emerging as an economically interesting model for enterprises of all
sizes, due to an undeniable added value and compelling business drivers [74]. One such driver
is elasticity: businesses pay for computing resources when needed, instead of provisioning in
advance with huge upfront investments. New resources such as processing power or memory
can be added to a virtual computer on the ﬂy, or an additional virtual computer can be
provided to the client application. Going beyond shared storage, the main potential in cloud
computing lies in its scalable virtualized framework for data processing. If a service uses
cloud-based processing, its capacity can be automatically adjusted when new users arrive or
depending on the input size and required response time of diﬀerent jobs. Another driver is
agility: new services can be deployed on the market quickly and ﬂexibly at limited cost. This
allows a service to handle its users in a ﬂexible manner without requiring initial investments
in hardware before the service can be launched.
Today, software is often designed while completely ignoring deployment or based on
very speciﬁc assumptions, e.g., the size of data structures, the amount of random access
memory, and the number of processors. For the software developer, cloud computing brings
new challenges and opportunities [151]:
• Empowering the Designer. The elasticity of software executed in the cloud gives
designers far reaching control over the execution environment’s resource parameters,
e.g., the number and kind of processors, the amount of memory and storage capacity,
and the bandwidth. In principle, these parameters can even be adjusted at runtime.
The owner of a cloud service cannot only deploy and run software, but also control
trade-oﬀs between the incurred cost and the delivered quality-of-service.
• Deployment Aspects at Design Time. The impact of cloud computing on software
design goes beyond scalability. Deployment decisions are traditionally made at the
end of a software development process: the developers ﬁrst design the functionality
of a service, then the required resources are determined, and ﬁnally a service level
agreement regulates the provisioning of these resources. In cloud computing, this can
have severe consequences: a program which does not scale usually requires extensive
design changes when scalability was not considered a priori.
To realize cloud computing’s potential, software must be designed for scalability. This leads
to a new software engineering challenge: how can the validation of deployment decisions be
pushed up to the modeling phase of the software development chain without convoluting
the design with deployment details?
The EU project Envisage addresses this challenge by extending a design by contract
approach to service-level agreements for resource-aware virtualized services. The function-
ality is represented in a client layer. A provisioning layer makes resources available to the
client layer and determines how much memory, processing power, and bandwidth can be
used. A service level agreement (SLA) is a legal document that clariﬁes what resources the
provisioning layer should make available to the client service, what they will cost, and the
penalties for breach of agreement. A typical SLA covers two diﬀerent aspects: (i) the mutual
legal obligations and consequences in case of a breach of contract, which we call the legal

Meeting Deadlines, Elastically
101
contract; (ii) the technical parameters and cost ﬁgures of the oﬀered services, which we call
the service contract.
This paper discusses some initial ideas about applying program veriﬁcation techniques
to models of virtualized services. We consider response time aspects of service contracts
and extend JML-like interfaces with response time annotations. This is formalized using
µABS; µABS is a restricted version of ABS [187], an executable object-oriented modeling
language developed in the Envisage project to specify resource-aware virtualized services
[13, 195, 194]. Whereas ABS is based on concurrent objects and asynchronous method calls,
the work discussed in this paper is restricted to sequential computation and synchronous
method calls. In future work, we plan to alleviate these restrictions.
Paper organization. Section 7.2 introduces service interfaces with response-time annota-
tions; Section 7.3 introduces the syntax of µABS, the modeling language considered in this
paper; Section 7.4 demonstrates the approach on an example; Section 7.5 develops a Hoare-
style proof system for µABS; Section 7.6 discusses related work; and Section 7.7 concludes
the paper by a discussion of the limitations and possible extensions of the current work.
7.2
Service Contracts as Interfaces
Service level agreements express non-functional properties of services (service contracts),
and their associated penalties (legal contracts). Examples are high water marks (e.g., number
of users), system availability, and service response time. Our focus is on service contract
aspects of client-level SLAs, and on how these can be integrated in models of virtualized
services. Such an integration would enable a formal understanding of service contracts and of
their relationship to the performance metrics and conﬁguration parameters of the deployed
services. Today, client-level SLAs do not allow the potential resource usage of a service
to be determined or adapted when unforeseen changes to resources occur. This is because
user-level SLAs are not explicitly related to actual performance metrics and conﬁguration
parameters of the services; for example, the user-level SLAs may be concerned with end-
user response times but not about the number of virtual machine instances on which the
service is deployed. The integration of service contracts and conﬁguration parameters in
service models enables the design of resource-aware services which embody application-
speciﬁc resource management strategies [151].
The term design by contract was coined by Bertrand Meyer referring to the contractual
obligations that arise when objects invoke methods [244]: only if a caller can ensure that
certain behavioral conditions hold before the method is activated (the precondition), it is
ensured that the method results in a speciﬁed state when it completes (the postcondition).
Design by contract enables software to be organized as encapsulated services with inter-
faces specifying the contract between the service and its clients. Clients can “program to
interfaces”; they can use a service without knowing its implementation. We aim at a de-
sign by contract methodology for SLA-aware virtualized services, which incorporates SLA
requirements in the interfaces at the application-level to ensure the QoS expectations of
clients.
We consider an object-oriented setting with service-level interfaces given in a style akin to
JML [70] and Fresco [347]; requires- and ensures-clauses express each method’s functional
pre- and postconditions. In addition, a response time guarantee is expressed in a within-

102
From Action Systems to Distributed Systems: The Reﬁnement Approach
type Photo = Rat; // size of the ﬁle
interface PhotoService {
@requires ∀p:Photo · p ∈ﬁlm && p < 4000;
@ensures reply == True;
@within 4∗length(ﬁlm) + 10;
Bool request(List<Photo> ﬁlm);
}
Figure 7.1: A photo printing shop in µABS.
clause associated with the method. The speciﬁcation of methods in interfaces is illustrated
in Figure 7.1.
7.3
A Kernel Language for Virtualized Computing
ABS supports modeling the deployment of objects on virtual machines with diﬀerent
processing capacities [187, 13, 195]. The µABS language simpliﬁes ABS by letting each
object have a dedicated processor with a given processing capacity. Thus, objects are dy-
namically created instances of classes such that the resource capacity of each object reﬂects
the provisioning contract between that object and its resource provider. In contrast to ABS,
communication between named objects is synchronous, which means that a method call
blocks the caller until execution has ﬁnished. For simplicity in this paper, the objects share
a thread of execution where at most one task is active and the others are waiting to be
executed on the task stack. Although µABS is currently restricted to sequential execution,
execution is elastic in the sense that several objects may provide instances of the same service
at diﬀerent speeds (and diﬀerent associated costs for the service provider) and the choice
of service instance for a task can be dynamically decided by the service based on, e.g., the
deadline of the task and the accumulated cost of running the service.
µABS is strongly typed: for well-typed programs, invoked methods are understood by
the called object. µABS includes the types Capacity, Cost, and Duration which all extend
Rat with an element inﬁnite: Capacity captures the processing capacity of virtual machines
per time interval, Cost the processing cost of executions, and Duration time intervals.
Figure 7.2 presents the syntax of µABS. A program P consists of interface and class
deﬁnitions, and a main block {T x; sr}. Interfaces IF have a name I and method signatures
Sg. Classes CL have a name C, optional formal parameters T x, and methods M. A method
signature Sg has a list of speciﬁcations Spec, a return type T, a method name m, and formal
parameters x of types T. In speciﬁcations (see Section 7.2), assertions φ express properties
of local variables in an assertion language extending the expressions e with logical variables
and operators in a standard way; a reserved variable reply captures the method’s return
value. A method M has a signature Sg, a list of local variable declarations x of types T,
and statements sr. Statements may access local variables and the formal parameters of the
class and the method.
Statements are standard, except job(e) which captures an execution requiring e process-
ing cycles. A job abstracts from actual computations but may depend on state variables.

Meeting Deadlines, Elastically
103
Syntactic categories
C, I, m in Names
s in Statement
x in Variables
k in Capacity
c in Cost
d in Duration
b in Bool
i in Rat
Deﬁnitions
P
:: =
IF CL {T x; sr}
T
:: =
C | I | Capacity | Cost | Duration | Bool | Rat
IF
:: =
interface I { Sg }
Sg
:: =
Spec T m (T x)
Spec
:: =
@requires φ; | @ensures φ; | @within φ;
CL
:: =
class C (T x) { M}
M
:: =
Sg { T x; sr }
sr
:: =
s;return e | return e
s
:: =
s;s | x = rhs | job(e) | if e {s} else {s}
rhs
:: =
e | new C (e) with e | e.m(x)
e
:: =
this | capacity | deadline | x | v | e op e
Figure 7.2: µABS syntax for the object level. Terms e and x denote possibly empty lists
over the corresponding syntactic categories.
Right-hand sides rhs include expressions e, object creation new C (e) with e and syn-
chronous method calls e.m(x). Objects are created with a given capacity, which expresses
the processing cycles available to the object per time interval when executing its methods.
Thus, diﬀerent instances may have diﬀerent capacities (and consequently, their usage may
have diﬀerent costs in the metered setting of elastic computing). Method calls in µABS are
blocking. Expressions e include operations over declared variables x and values v. Among
values, b has type Bool, i has type Rat (e.g., 5/7), k has type Capacity, c has type Cost, and
d has type Duration. Among binary operators op on expressions, note that division c/k has
type Duration. Expressions also include the following reserved read-only variables: this refers
to the object identiﬁer, capacity refers to the processing speed (amount of resources per time
interval) of the object, and deadline refers to the local deadline of the current method. (We
assume that all programs are well-typed and include further functional expressions and data
types when needed in the example.)
Time. µABS has a dense time model, captured by the type Duration. The language
is not based on a (global) clock, instead each method activation has an associated local
counter deadline, which decreases when time passes. Time passes when a statement job(e)
is executed on top of the task stack. The eﬀect of executing this statement on an object
with capacity k, is that the local deadline of every task on the stack decreases by c/k, where
c is the value resulting from evaluating e. The initial value of the deadline counter stems
from the service contract; thus, a local counter which becomes negative represents a breach
of the local service contract. For brevity, we do not present the formal semantics.
7.4
Example: A Photo Printing Shop
Let us consider a photo shop service which retouches and prints photos. It is cheaper for
the photo shop service to retouch and print photos locally, but it can only deal with low
resolution photos in time. For larger photos, the photo shop service relies on using a faster

104
From Action Systems to Distributed Systems: The Reﬁnement Approach
<<can realize>>
<<uses>>
<<can realize>>
<<can realize>>
<<uses>>
@requires  p:Photo, p  ﬁlm && p < 4000;
@ensures reply == True;
@within 4 length(ﬁlm) + 10;                       
Bool request(List<Photo> ﬁlm)
<<interface>>
PhotoService
@requires p < 4000 && capacity>=250;         
@ensures reply == p + p/10;
@within 2;
Photo retouch(Photo p)
<<interface>>
FastEdit
@requires p < 5000 && capacity>=300;         
@within 2;
Unit print(Photo p)
<<interface>>
FastPrint
PhotoServiceImp
PhotoServiceImp
PhotoServiceImp
PhotoServiceImp
PhotoServiceImp
@…; Bool request(List<Photo> ﬁlm)
@…; Photo retouch(Photo p)             
@…; Unit  print(Photo p)
PhotoServiceImp
FastPrintImp
FastPrintImp
FastPrintImp
FastPrintImp
FastPrintImp
@…; Unit print(Photo p)
FastPrintImp
FastPrintImp
FastPrintImp
FastPrintImp
FastPrintImp
FastPrintImp
@…; Photo retouch(Photo p)
FastEditImp
Figure 7.3: A class diagram for a photo printing shop
and more expensive laboratory in order to guarantee that all processing deadlines are met
successfully.
In this example, a ﬁlm is represented as a list of photos and, for simplicity, a photo by
the size of the corresponding ﬁle. As shown in the class diagram of Figure 7.3, an interface
PhotoService provides a single method request which handles customer requests to the photo
shop service. The interface is implemented by a class PhotoServiceImp, which has methods
retouch for retouching and print for printing a photo, in addition to the request method of
the interface. For faster processing, two interfaces FastEdit and FastPrint, which also provide
the methods retouch and print, may be used by PhotoServiceImp. The sequence diagram in
Figure 7.4 shows how a photo is ﬁrst retouched, then printed. The services of retouching
and printing are done locally if possible, otherwise they are forwarded to and executed by
objects with higher capacities.
The µABS model of the example (Figure 7.5) follows the design by contract approach
and provides a contract for every method declaration in an interface and method deﬁnition
in a class. These speciﬁcations are intended to guarantee that a request to a PhotoService
object will not break the speciﬁed contract. If we consider the contract for request in more
detail, we see that the response time of a request(ﬁlm) call depends on the length of the
ﬁlm and assumes that the size of every photo contained in the ﬁlm is smaller than 4000.
The implementation of the request method is as follows: Take the ﬁrst photo in the ﬁlm (by
applying the function head(ﬁlm)) and check if this photo is low resolution compared to the
capacity of the PhotoService object, represented by a size smaller than 500 and a capacity of
at least 100, respectively. In this case, the retouch can be done locally, otherwise retouch is
done by an auxiliary FastEdit object. A similar procedure applies to printing the retouched
photos. Thus, photos of small sizes are retouched and printed locally, while photos with
bigger sizes are sent to be retouched and printed externally. The ability to send tasks to the
laboratory which meets the deadline at the lowest cost, expresses elasticity in the setting of

Meeting Deadlines, Elastically
105
Main
PhotoService
FastEdit
FastPrint
request(ﬁlm)
if possible 
    retouch(photo)
    locally
if possible
    print(photo)
    locally
if ﬁlm is not 
empty
else
    retouch(photo)
    somewhere else
else
    print(photo) 
    somewhere else 
Capacity = 100
Capacity = 280
Capacity = 320
Main
PhotoService
FastEdit
FastPrint
request(ﬁlm)
if possible 
    retouch(photo)
    locally
if possible
    print(photo)
    locally
if ﬁlm is not 
empty
else
    retouch(photo)
    somewhere else
else
    print(photo) 
    somewhere else 
Capacity = 100
Capacity = 280
Capacity = 320
Figure 7.4: A sequence diagram for a photo printing shop
this example. The implementations of the diﬀerent methods are abstractly captured using
job statements. The expressions e inside the job statements, could be further reﬁned or
calibrated using SACO [11].
7.5
Proof System
Virtual machines are subject to failures. We interpret non-termination of a job statement
as an underlying failure and restrict our analysis to partial correctness. The proof system
for µABS is formalized as Hoare triples [170, 16] {φ} s {ψ} with a standard partial cor-
rectness semantics: if the execution of s starts in a state satisfying the precondition φ and
the execution terminates, the result will be a state satisfying the postcondition ψ. In this
paper, we are particularly interested in assertions about the deadline variables of method
activations.
The reasoning rules for µABS are presented in Figure 7.6. Reasoning about sequential
composition, conditional, and assignment statements is standard, and captured by the rules
Comp, Cond, and Assign, respectively. Time only passes when job(e) is executed; job(e)
has a duration e/cap when executed on an object with capacity cap. The assertion in Rule
Job ensures that this duration is included in the response time after executing job(e). The
subsumption rule allows to strengthen the precondition and weaken the postcondition. For
method deﬁnitions, the premise of Rule Method assumes that the execution of sr starts in a

106
From Action Systems to Distributed Systems: The Reﬁnement Approach
type Photo = Rat; // size of the ﬁle
interface FastEdit {
@requires p < 4000 && capacity>=250; @ensures reply == p + p/10; @within 2;
Photo retouch(Photo p);}
class FastEditImp {
@requires p < 4000 && capacity>=200; @ensures reply == p + p/10; @within 2;
Photo retouch(Photo p) {job(200); return (p + p/10)}}
interface FastPrint {
@requires p < 5000 && capacity>=300; @within 2;
Unit print(Photo p);}
class FastPrintImp {
@requires p < 5000 && capacity>=250; @within 2
Unit print(Photo p) {job(250);return unit}}
interface PhotoService {
@requires ∀p:Photo, p ∈ﬁlm && p < 4000;
@ensures reply == True; @within 4∗length(ﬁlm) + 10;
Bool request(List<Photo> ﬁlm);}
class PhotoServiceImp(FastEdit edit,FastPrint print) {
@requires ∀p:Photo, p ∈ﬁlm && p < 4000;
@ensures reply == True; @within 4∗length(ﬁlm)+1;
Bool request(List<Photo> ﬁlm) {
Photo p = 0;
if (ﬁlm != Nil){
p = head(ﬁlm);
if (p < 500 && capacity>=100){ p = this.retouch(p);}
else{p = edit.retouch(p);}
if ( p < 600 && capacity>=100){this.print(p);}
else{print.print(p);}
this.request(tail(ﬁlm));}
else{ job(1);}
return (deadline >= 0) }
@requires p < 500 && capacity>=100; @ensures reply == p + p/20; @within 1;
Photo retouch(Photo p) {job(100); return (p + p/20)}
@requires p < 600 && capacity()>=100; @within 1;
Unit print(Photo p) { job(100); return unit}}
Figure 7.5: A photo printing shop in µABS
state where the requires-clause φ is satisﬁed and that the expected response time (deadline)
is larger than expression e, where e is the speciﬁed response time guarantee from the within-
clause. When the execution of sr terminates, the result will satisfy the ensures-clause ψ and
the expected response time remains non-negative. For method invocations in Rule Call,
the speciﬁcation of the method is updated by substituting the formal parameters fp by the
input expressions e. The logical variables for the return value of the method (reply) and
of the expected response time are renamed with fresh variables α and β, respectively. To
avoid name clashes between scopes, we assume renaming of other variables as necessary.
Object creation (in Rule New) is handled similarly to assignment. The precondition ensures
that the newly created object of a class C with capacity e correctly implements interface
T, where T is the type of x. (Note that the class instance may or may not implement an
interface, depending on its capacity.) If a method has a return value, expression e in the
return statement will be assigned to the logical variable reply in Rule Return, and can be
handled by the standard assignment axiom in Rule Assign.
Although µABS does not currently include loops, the language supports recursion

Meeting Deadlines, Elastically
107
(Method)
{φ ∧deadline ≥e} sr {ψ ∧deadline ≥0}
@requires φ; @ensures ψ; @within e;
T′′ m (T x) {T′ x′;sr}
(Return)
{φ} s;reply = e {ψ}
{φ} s;return e {ψ}
(Comp)
{φ}s1{ψ′}
{ψ′}s2{ψ}
{φ}s1;s2{ψ}
(Cond)
{φ ∧b}s1{ψ}
{φ ∧¬b}s2{ψ}
{φ} if b {s1} else {s2} {ψ}
(Subsumption)
{φ′} s {ψ′}
φ ⇒φ′
ψ′ ⇒ψ
{φ} s {ψ}
(Assign)
{φ[x 7→e]} x = e {φ}
(Job)
{φ[deadline 7→deadline −(e/cap)]} job(e) {φ}
(New)
fresh(α)
φ′ = φ[x 7→α]
T = typeOf(x)
φ′ ⇒implements(C, T, e)
{φ′} x = new C(e) with e {φ}
(Call)
fresh(α, β)
T = typeOf(e)
φ′ = φ[x 7→α, deadline 7→deadline −β]
φ′ ⇒requires(T, m)[fp 7→e]
φ1 = ensures(T, m)[fp 7→e, reply 7→α]
φ2 = within(T, m)[fp 7→e, deadline 7→β]
{φ′ ∧φ1 ∧φ2} x = e.m(e) {φ}
Figure 7.6: Proof system for µABS
through interfaces with associated contracts. This suggests how loops can be handled in
the proof system, in terms of loop invariants which express execution time for the remaining
iterations of the loop.
Example 7.1. We show in Equation 7.3 the skeleton of the proof for the method request
in Figure 7.5 by using the proof system presented in Figure 7.6. Let sr refer to the method
body of request and let s denote sr without the return statement. In addition, we introduce
the following abbreviations for formulas:
ψ = reply == True,
ψ1 = ψ ∧deadline ≥0,
φ = ∀p:Photo, p ∈film ∧p<4000, and
e = 4 ∗length(film) + 10
(7.1)
and assume that
ψ2 = reply == deadline ≥0 ∧deadline ≥0
(7.2)
is the postcondition of the assignment reply = deadline ≥0.
By Rule Method, the assertions φ and deadline>e serve as precondition to the whole
method body sr, where φ and e are given in the requires- and within-clauses associated
with the deﬁnition of the method request in Figure 7.5. The postcondition of the method

108
From Action Systems to Distributed Systems: The Reﬁnement Approach
body consists of ψ, which is speciﬁed in the ensures-clause as reply == True, and the
expression deadline ≥0. Rule Return converts the return-statement into a statement
where the expression deadline ≥0 is assigned to the logical variable reply. Then, by the
assignment axiom Assign, and with the postcondition ψ2 assumed in Equation 7.2, the
precondition ψ3 is the postcondition with the logical variable reply substituted with the
expression deadline ≥0, and thus ψ3 = True ∧deadline ≥0. By using Rule Subsumption,
the postcondition ψ2 is weakened to the given postcondition ψ1. By Rule Comp, the assertion
ψ3 is also the postcondition of the statement s.
...
{φ ∧deadline>e} s {ψ3}
{ψ3} reply = deadline ≥0 {ψ2}
ψ2 ⇒ψ1
{ψ3} reply = deadline ≥0 {ψ1}
{φ ∧deadline>e} s;reply = deadline ≥0 {ψ1}
{φ ∧deadline>e} s;return(deadline ≥0) {ψ1}
@requires φ; @ensures ψ; @within e;
Bool request(List⟨Photo⟩film){sr}
(7.3)
For brevity, the rest of the proof is omitted. The proof can be completed by repeatedly
applying the corresponding rules from the presented proof system.
7.6
Related Work
The work presented in this paper is related to the ABS modeling language and its exten-
sion to virtualized computing on the cloud, developed in the Envisage project [12]. ABS [187]
and its extensions with time [56], deployment component and resource-awareness [195] pro-
vide a formal basis for modeling virtualized computing. ABS has been used in two larger
case studies addressing resource management in the cloud by combining simulation tech-
niques and cost analysis, but not by means of deductive veriﬁcation techniques; a model of
the Montage case study [103] is presented in [194] and compared to results from specialized
simulation tools and a large ABS model of the Fredhopper Replication Server has been
calibrated using SACO [11] (a cost analysis tool for ABS) and compared to measurements
on the deployed system in [99, 13]. The main diﬀerence between resource-aware models in
ABS [195] and the work presented in this paper, is an elimination of non-determinism; in
addition to the restriction to sequential programs discussed above, µABS uniﬁes objects and
deployment components, such that objects cannot compete for the resources on a server.
As we extend µABS towards ABS in future work, this seems like a reasonable restriction to
enable more precise reasoning, but it could mean that object creation could fail if the tar-
geted deployment component lacks resources! Related techniques for modeling deployment
in embedded real-time systems may be found in an extension of VDM++ [339]. In this
extension, static architectures are explicitly modeled using CPUs and buses. The approach
uses ﬁxed resources targeting the embedded domain. Whereas ABS has been designed to
support compositional veriﬁcation based on traces [115], neither ABS nor VDM++ supports
deductive veriﬁcation of non-functional properties today.

Meeting Deadlines, Elastically
109
Assertional proof systems addressing timed properties, and in particular upper bounds on
execution times of systems, have been developed, the earliest example perhaps being [303].
Another early example of reasoning about real-time is Nielson’s extension of classical Hoare-
style veriﬁcation to timed properties of a given program’s execution [253, 252]. Soundness and
(relative) completeness of the proof rules of a simple while-language are shown. Shaw [302]
presents Hoare logic rules to reason about the passage of time, in particular to obtain upper
and lower bounds on the execution times of sequential, but also of concurrent programs.
Hooman’s work on assertional reasoning and Hoare logic [172] for concurrent programs
covers diﬀerent communication and synchronization patterns, including shared-variable con-
currency and message passing using asynchronous channels. The logic introduces a dense
time domain (i.e., the non-negative reals, including ∞) and conceptually assumes a single,
global clock for the purpose of reasoning. The proof system is developed for a small calculus
focussing on time and concurrency, where a delay-statement can be used to let time pass.
This is comparable to the job-expression in our paper, but directly associates a duration
with the job. In contrast, we associate a cost with the job, and the duration depends on the
execution capacity of the deployed object where the statement is executed. Timed reasoning
using Dijkstra’s weakest-precondition formulation of Hoare logic can be found in [149]. Lam-
port’s temporal logic of actions TLA [214, 1] has likewise been extended with the ability to
reason about time [213]. Similar to the presentation here, the logical systems are generally
given by a set of derivation rules in a pre-/post-condition style. Similar to our work, these
approaches are compositional in that timing information for composed programs, including
procedure calls, is derived from that of more basic statements. While being structural in al-
lowing syntax-directed reasoning, these formalisms do not explore timed interfaces as part of
the programming calculus as we have done here. Thus, these approaches do not support the
notion of design-by-contract compositionality for non-functional properties that has been
suggested in this paper.
Complementing the theoretical development of proof systems for real-time properties,
corresponding reasoning support has been implemented within theorem provers and proof-
assistants, for instance for PVS in [134] (using the duration calculus), and HOL [142]. An
interesting approach to compositional reasoning about timed system is developed in [135].
As its logical foundation, the methodology uses TRIO [139], a general-purpose speciﬁcation
language based on ﬁrst-order linear temporal logic. In addition, TRIO supports object-
oriented structuring mechanisms such as classes and interfaces, inheritance, and encapsula-
tion. To reason about open systems, i.e., to support modular or compositional reasoning,
the methodology is based on a rely/guarantee formalization and corresponding proof rules
are implemented within PVS. Similarly, a rely/guarantee approach for compositional ver-
iﬁcation in linear-time temporal logics is developed in [334, 196]. A further compositional
approach for the veriﬁcation of real-time systems is reported in [173], but without making
use of a rely/guarantee framework.
Reﬁnement-based frameworks constitue another successful design methodology for com-
plex system, orthogonal to compositional approaches. Aiming at a correct-by-construction
methodology, their formal underpinning often rests on various reﬁnement calculi [23, 250,
249]. Reﬁnement-based frameworks have also been developed for timed systems. In partic-
ular, Kaisa Sere and her co-authors [54] extended the well-known formal modeling, veriﬁ-
cation, and reﬁnement framework Event-B [6] with a notion of time, resulting in a formal
transformational design approach where the proof-obligations resulting from the timing part
in the reﬁnement steps are captured by timed automata and veriﬁed by the Uppaal tool
[52].

110
From Action Systems to Distributed Systems: The Reﬁnement Approach
The Java modeling language JML [70] is an interface speciﬁcation language for Java
which was used as the basis for the interface speciﬁcation of service contracts in our pa-
per. Extensions of JML have been proposed to capture timed properties and to support
component-based reasoning about temporal properties [207, 208]. These extensions have
been used to modularly verify so-called performance correctness [307, 306]). For this pur-
pose, JML’s interface speciﬁcation language is extended with a special duration-clause, to
express timing constraints. The JML-based treatment of time is abstract insofar as it for-
malizes the temporal behavior of programs in terms of abstract “JVM cycles”. Targeting
speciﬁcally safety critical systems programmed in SCJ (Safety-critical Java), SafeJML [150]
re-interprets the duration-clause to mean the worst-case execution time of methods con-
cretely in terms of absolute time units. For a speciﬁc hardware implementation for the JVM
for real-time applications, [296] presents a diﬀerent WCET analysis [271] for Java. The ap-
proach does not use full-ﬂedged logical reasoning or theorem proving, but is a static analysis
based on integer linear programming and works at the byte-code level. We are not aware of
work relating real-time proof systems to virtualized software, as addressed in this paper.
7.7
Discussion
Cloud computing provides an elastic but metered execution environment for virtualized
services. Services pay for the resources they lease on the cloud, and new resources can be
dynamically added as required to oﬀer the service to a varying number of end users at an
appropriate service quality. In order to make use of the elasticity of the cloud, the services
need to be scalable. A service which does not scale well may require a complete redesign
of its business code. A virtualized service is able to adapt to the elasticity provided by the
cloud. We believe that the deployment strategy of virtualized services and the assessment of
their scalability should form an integral part of the service design phase, and not be assessed
a posteriori after the development of the business code as it is done today. The design of
virtualized services provides new challenges for software engineering and formal methods.
Virtualization empowers the designer by providing far-reaching control over the resource
parameters of the execution environment. By incorporating a resource management strategy
which fully exploits the elasticity of the cloud into the service, resource-aware virtualized
services are able to balance the service contracts that they oﬀer to their end users, to the
metered cost of deploying the services. For resource-aware virtualized services, the integra-
tion of resource management policies in the design of the service at an early development
stage seems even more important.
This paper pursues a line of research addressing the formal veriﬁcation of service con-
tracts for virtualized services. We have considered a very simple setting with an interface
language which speciﬁes services, including their service contracts in the form of response
time guarantees, and a simple object-oriented language for realizing these services. To sup-
port non-functional behavior, the language is based on a real-time semantics and associates
deadlines with method calls. Virtualization is captured by the fact that objects are dynam-
ically created with associated execution capacities. Thus, the time required to execute a
method activation depends not only on the actual parameters to the method call, but also
on the execution capacity of the called object. This execution capacity reﬂects the process-
ing power of virtual machine instances, which are created from within the service itself.

Meeting Deadlines, Elastically
111
The objective of the proof system proposed in this paper is to apply deductive veriﬁcation
techniques to ensure that all local deadlines are met during the execution of a virtualized
service. This proof system builds on previous work for real-time systems, and recasts the
deductive veriﬁcation of timing properties to a setting of virtualized programs. The exten-
sion of service interfaces with response-time guarantees, as proposed in this paper, allows a
compositional design-by-contract approach to service contracts for virtualized systems.
Whereas our work goes in the direction of worst-case cost analysis, it would also be in-
teresting to consider soft real-time requirements as typically encountered in service-oriented
computing. This could in principle be done by incorporating probabilistic information about
response times and execution cost into the models. As such, the approach taken in this pa-
per could be complemented by simulations and statistical techniques (e.g., Monte Carlo
simulations have been applied in the context of ABS [193]). However, as cloud computing is
increasingly used for critical services in domains such as health and banking, we believe that
there is a need for analysis techniques for hard deadlines also in the context of virtualized
services.
Several challenges to the proposed approach are left for future work, in particular the
extension to concurrency and asynchronous method calls. Currently we plan to address this
challenge in terms of proof rules which make use of explicit assumptions about the size of
the queues for concurrent ABS objects. The size of the queues can be statically detected;
e.g., the size may be approximated by techniques such as may-happen-in-parallel analysis
[133]. Furthermore, in the concurrent setting, it is interesting to work with reﬂection; e.g., an
object may query the current load of its virtual machine and use this as a basis for resource
management. In this paper, we have considered the explicit allocation of resources for each
object. In future work, it would be advantageous to lift the bounded queue length from indi-
vidual objects to groups of objects, and work with the deployment of such groups. Another
challenge is the incorporation of code which reﬂects the actual computations (replacing the
job-statements of this paper). In this case, the abstraction to job-statements could be done
by incorporating a worst-case cost analysis [11] into the proof system. Another interesting
challenge, which remains to be investigated, is how to incorporate the global requirements
which we ﬁnd in many service-level agreements into a compositional proof system, such as
the maximum number of end users.

This page intentionally left blank
This page intentionally left blank

Chapter 8
Event-B and Linear Temporal Logic
Steve Schneider, Helen Treharne
University of Surrey
David M. Williams
VU University Amsterdam
8.1
Introduction ......................................................
113
8.2
Event-B ..........................................................
115
8.2.1
Machines .................................................
115
8.2.2
Reﬁnement ...............................................
116
8.2.3
Development Strategy ...................................
117
8.2.4
Semantics ................................................
118
8.3
LTL Notation ....................................................
118
8.4
Preserving LTL Properties in Event-B Reﬁnement Chains .....
119
8.4.1
Example: Deadlock-Freedom ............................
120
8.4.2
Example: Anticipated Events ...........................
121
8.4.3
Example: β-Dependence .................................
122
8.5
Discussion and Related Work ....................................
122
8.6
Conclusion ........................................................
123
Abstract. In this chapter we consider when temporal logic properties can be carried through
Event-B reﬁnement chains. We also identify conditions on temporal logic properties that
make them suitable for use in a reﬁnement chain, since not all properties are preserved by
Event-B reﬁnement. In particular we identify the particular notion of β-dependence for an
LTL property: that only the events in the set β need to be checked to determine whether an
execution meets the property. Such properties are not aﬀected by the introduction of new
events in a reﬁnement step, which means they will carry through a reﬁnement chain and will
hold for any resulting reﬁnement which is deadlock-free and does not contain anticipated
events. The chapter presents a Lift example reﬁnement chain to illustrate the results and
how they are applied.
8.1
Introduction
Event-B [6] is a step-wise development method with excellent tools: the Rodin plat-
form [2] providing proof support and ProB [226] providing model checking. As Hoang and
Abrial [168] clearly state, the focus of veriﬁcation within Event-B has been on the safety
113

114
From Action Systems to Distributed Systems: The Reﬁnement Approach
properties of a system to ensure that “something (bad) never happens”. Typically, this has
been done via the discharging of proof obligations. Nonetheless, the use of linear temporal
logic (LTL) to specify temporal liveness properties has also been prevalant, for example in its
application within the ProB tool [227]. The challenge is to identify more natural ways of in-
tegrating Event-B and LTL, so that LTL properties can be preserved by Event-B reﬁnement,
which is not currently the case in general.
Event-B describes systems in terms of machines with state, and events which are used to
update the state. Events also have guards, which are conditions for the event to be enabled.
One (abstract) machine may be reﬁned by another (concrete) machine, using a reﬁnement
step. A linking invariant captures how the abstract and concrete states are related, and each
abstract event must be reﬁned by one or more concrete events whose state transformations
match the abstract one in the sense of preserving the linking invariant. Reﬁnement is transi-
tive, so a sequence of reﬁnement steps, known as a reﬁnement chain, will result in a concrete
machine which is a reﬁnement of the original abstract one.
A particular feature provided by Event-B is the introduction of new events in a reﬁnement
step—events which do not reﬁne any abstract event. This allows for reﬁnements to add ﬁner
levels of granularity and concretisation as the design develops; there are many examples
in [6]. These new events are invisible at the abstract level (they correspond to the abstract
state not changing), and we generally need to verify that they cannot occur forever. Event-B
makes use of labels to keep track of the status of events as a reﬁnement chain progresses.
Event-B labels are anticipated, convergent and ordinary. The labelling of events in Event-B
form part of the core of a system description but their inclusion is primarily to support the
proof of safety properties and ensuring that events cannot occur forever: convergent events
must decrease a variant and anticipated events cannot increase it. The result described in
this chapter is applicable when all newly introduced events are convergent or anticipated,
and all anticipated events become convergent at some stage in the reﬁnement chain. As
an initial example, consider a machine Lift0 (Figure 8.1) with two events top and ground,
representing movement to the top and to the ground ﬂoor. This can be reﬁned by a machine
Lift1 (Figure 8.2) introducing a new anticipated event mid corresponding to movement to
one of the intermediate ﬂoors.
Linear temporal logic provides a speciﬁcation language for capturing properties of exe-
cutions of systems and is appropriate for reasoning about liveness and fairness. For example,
we might verify for Lift0 that whenever top occurs, then eventually ground will occur. How-
ever, this is not guaranteed for its reﬁnement Lift1: it may be that the intermediate ﬂoors
are visited repeatedly forever following the top event, thus never reaching the next ground
event. Alternatively it may be that some reﬁnement system deadlocks, again preventing
ground from occurring. Hence we see that LTL properties are not automatically preserved
by Event-B reﬁnement.
In this chapter we consider when temporal logic properties can be carried through Event-
B reﬁnement chains. We also identify conditions on temporal logic properties that make them
suitable for use in a reﬁnement chain, since some properties are not preserved by Event-B
reﬁnement (for example, the property “mid never occurs” holds for Lift0 but not for its
reﬁnement Lift1). The approach is underpinned by our process algebra understanding of the
Event-B semantics, in particular the traces, divergences and inﬁnite traces semantics used
for CSP (Communicating Sequential Processes) and applied to Event-B in [294]. We do not
present the proof of the main result here; it is provided in [295]. In this chapter we give the
intuition of why it holds and in order to aid the reader to develop an understanding of why
the conditions of the result are required.

Event-B and Linear Temporal Logic
115
machine Lift0
variables ﬂr0
invariant ﬂr0 ∈{0, 102}
events
init b= ﬂr0: = 0
top b= status: ordinary
when ﬂr0<102 then ﬂr0: = 102 end
ground b= status: ordinary
when true then ﬂr0: = 0 end
end
Figure 8.1: Lift0
8.2
Event-B
8.2.1
Machines
An Event-B development is deﬁned using machines. A machine M contains a vector of
variables and a set of events. The alphabet of M, αM, is the set of events deﬁned in M. Each
event evti has the general form evti b= any x where Gi(x, v) then v :| BAi(v, x, v′) end,
where x represents the parameters of the event, and the guard Gi(x, v) is the condition for
the event to be enabled. The body is given by v :| BAi(v, x, v′) whose execution assigns to
v any value v′ which makes the before-after predicate BAi(v, x, v′) true. This simpliﬁes to
evti b= when Gi(v) then v :| BAi(v, v′) end when there are no parameters, since the guard
and the before-after predicate do not refer to the parameters x. Such state transformations
can also be expressed in terms of abstract assignments using the Generalised Substitution
Language.
Variables of a machine are initialised in an initialisation event init and are constrained
by an invariant I(v). The Event-B approach to semantics is to associate proof obligations
with machines. The key proof obligation, INV, is that all events must preserve the invariant.
There is also an optional proof obligation on a machine with respect to deadlock freedom
which means that a guard of at least one event in M is always enabled. When this obligation
holds M is deadlock free.
Figure 8.1 gives an example machine Lift0 which describes the behaviour of a lift that
can move to the top ﬂoor or the ground ﬂoor. It contains one variable, ﬂr0, which can take
the values 0 or 102. The initialisation init starts the machine at ﬂoor 0. The event top has a
guard ﬂr0<102 such that it is only enabled, and hence can only occur, when the lift is not
at the top ﬂoor. This event will be blocked when the lift is at the top ﬂoor. The body of the
event, ﬂoor0: = 102, sets the variable to the value 102. On the other hand, the event ground
has a guard of true, so it is always enabled. Its eﬀect is to set the variable to the value 0.
This event is not blocked when the lift is already at the ground.

116
From Action Systems to Distributed Systems: The Reﬁnement Approach
machine Lift1
reﬁnes Lift0
variables ﬂr1
invariant ﬂr1 = ﬂr0 ∨ﬂr1 ∈{1..101}
variant 0
events
init b= ﬂr1: = 0
top b= status: ordinary
when ﬂr1 = 101 then ﬂr1: = 102 end
ground b= status: ordinary
when ﬂr1>0 then ﬂr1: = 0 end
mid b= status: anticipated
when true then ﬂr1: ∈1..101 end
end
Figure 8.2: Lift1
8.2.2
Reﬁnement
An Event-B development is a sequence of B machines M0, . . . , Mi, . . . , Mn each related
to the next by a reﬁnement relationship, and n>0.
A reﬁnement step can introduce new events and split and merge existing events1. In any
particular step, new events are considered as reﬁnements of skip: the event that is always
enabled and makes no change to the state. Their introduction is to provide more detail to
a speciﬁcation.
A machine Mi is considered to be reﬁned by Mi+1 if the given linking invariant Ji+1 on
the variables between the two machines is established by their initialisation, and preserved by
all events. Formally, we denote the reﬁnement relation between two machines, written Mi ≼
Mi+1, when all of the following proof obligations hold: (1) feasibility, (2) guard strengthening
and (3) simulation. Feasibility of an event is the property that, if the event is enabled (i.e.,
the guard is true), then there is some after-state. Guard strengthening requires that when a
concrete event is enabled, then so is the abstract one. Finally, simulation requires that the
occurrence of events in the concrete machine can be matched in the abstract one (including
the initialization event). Formal details of these proof obligations can be found in [6].
There are three kinds of labelling of events in Event-B: anticipated (a), convergent (c) and
ordinary (o), where convergent events are those which must not execute forever, whereas
anticipated events provide a means of deferring consideration of divergence-freedom until
later reﬁnement steps. The proof obligation which deals with divergences requires that the
proposed variant v of a reﬁnement machine satisﬁes the appropriate properties: that it is
a natural number that decreases on occurrence of any convergent event, and that does not
increase on occurrence of any anticipated event. We augment the previous reﬁnement relation
to include this additional requirement, and write Mi ≼W Mi+1 when it holds between Mi and
1For simplicity we omit the treatment of splitting and merging events in this chapter.

Event-B and Linear Temporal Logic
117
machine Lift2
reﬁnes Lift1
variables ﬂr2
invariant ﬂr2 = ﬂr1
variant 101 −ﬂr2
events
init b= ﬂr2: = 0
top b= status: ordinary
when ﬂr2 = 101 then ﬂr2: = 102 end
ground b= status: ordinary
when ﬂr2 = 102 then ﬂr2: = 0 end
mid b= status: convergent
when ﬂr2<101 then ﬂr2: = ﬂr2 + 1 end
end
Figure 8.3: Lift2
Mi+1. Ordinary events can occur forever and therefore this requirement is not mandatory
for such events.
As an example, Figure 8.2 gives Lift1, a reﬁnement of Lift0. It introduces a new variable
ﬂr1 and gives a linking invariant which relates ﬂr1 to the state ﬂr0 of Lift0. Any occurrence
of an event in Lift1 must be matched by some performance of the event in Lift0, in the
sense that it must be enabled in Lift0 and the linking invariant must be preserved. The new
event mid must reﬁne skip, thus the linking invariant must be preserved. Observe that mid
is nondeterministic, and can result in ﬂr1 being set to any value between 1 and 101. Observe
also that the guard of ground is stronger in Lift1, and that it will be blocked in Lift1 when
the lift is already on the ground. The variant is simply a constant, since anticipated events
are only required not to increase the variant, and there are no convergent events.
Figure 8.3 gives Lift2, a reﬁnement of Lift1. Observe that the nondeterminism in mid has
been resolved so that it moves the lift up one ﬂoor. Furthermore, mid is now convergent,
and the variant has been set so that it is strictly decreased by mid.
8.2.3
Development Strategy
Event-B has a strong but ﬂexible reﬁnement strategy which is described in [153]. In [294],
we also discussed diﬀerent Event-B reﬁnement strategies and characterised them with respect
to the approaches documented by Abrial in [6] and supported by the Rodin tool. In this
chapter, we focus on the simplest strategy, and the one most commonly used. The strategy
has the following set of restrictions on a reﬁnement chain M0 ≼W M1 ≼W . . . ≼W Mn:
1. each new event in Mi is either anticipated or convergent, where i>0;
2. reﬁnements of anticipated event of Mi are either convergent or anticipated in Mi+1;
3. reﬁnements of convergent or ordinary events of Mi are ordinary in Mi+1;
4. no anticipated events remain in the ﬁnal machine Mn.

118
From Action Systems to Distributed Systems: The Reﬁnement Approach
top (o)
top (o)
top (o)
ground (o)
text>ground (o)
text>ground (o)
text>mid (a)
text>mid (c)
Lift0
text>Lift1
text>Lift2
Figure 8.4: Events and their annotations in the Lift development
Figure 8.4 illustrates the treatment of events in this development strategy for the reﬁne-
ment sequence Lift0 ≼W Lift1 ≼W Lift2. The event mid is introduced by Lift1 and hence
must be anticipated or convergent—in this case it is anticipated. It will need to reﬁne skip
within Lift0. In the step from Lift1 to Lift2, it must again be anticipated or convergent—in
this case it is convergent. Finally, we observe that there are no anticipated events in the
ﬁnal machine Lift2.
This strategy ensures that all new events introduced along a reﬁnement chain must at
some stage be convergent. This means that no execution of Mn can end with an inﬁnite
sequence of new events not already in M0.
8.2.4
Semantics
We deﬁne a trace of M to be either an inﬁnite sequence of events (a,c or o), i.e.,
⟨e0, e1, . . .⟩or a ﬁnite sequence of events, i.e., ⟨e0, . . . , ek−1⟩where the machine M dead-
locks after the occurrence of the ﬁnal event. Traces correspond to maximal executions of
machines. Plagge and Leuschel in [265] provided a deﬁnition of an inﬁnite or ﬁnite path π
of M in terms of a sequence of events and their intermediate states. In order to distinguish
notation, we use u to represent a trace without the intermediate states. We need not con-
sider the particular states within a trace in our reasoning which is based on inﬁnite traces.
When a machine M is deadlock free all of its traces are inﬁnite. We use the functions of
concatenation (⌢) and projection (↾).
8.3
LTL Notation
We use the grammar for the LTL operators presented by Plagge and Leuschel [265]:
φ
:: =
true | [x] | ¬φ | φ1 ∨φ2 | φ1 U φ2

Event-B and Linear Temporal Logic
119
A machine M satiﬁes φ, denoted M |= φ, if all traces u of M satisfy φ. The deﬁnition for u
to satisfy φ is deﬁned by induction over φ as follows:
u |= true
u |= [x]
⇔
u = ⟨x⟩⌢u1
u |= ¬φ
⇔
it is not the case that u |= φ
u |= φ1 ∨φ2
⇔
u |= φ1 or u |= φ2
u |= φ1Uφ2
⇔
∃k ≥0. ∀i<k.ui |= φ1 and uk |= φ2
where un is u with the ﬁrst n elements removed, i.e., u = ⟨x0, . . . , xn−1⟩⌢un.
From these operators Plagge and Leuschel derived several additional operators, including:
conjunction (φ1 ∧φ2), ﬁnally (or eventually) (Fφ), and globally (or always) (Gφ), in the
usual way; for explicitness we also provide direct deﬁnitions for them:
u |= φ1 ∧φ2
⇔
u |= φ1 and u |= φ2
u |= Fφ
⇔
∃i ≥0.ui |= φ
u |= Gφ
⇔
∀i ≥0.ui |= φ
For example, the informal speciﬁcation for the Lift0 given in Section 8.1, that whenever
top happens then eventually ground will happen, could be written as
φ0
=
G([top] ⇒F[ground])
and so
Lift0 |= φ0
Conversely, we have that Lift0 ̸|= G([ground] ⇒F[top]), since Lift0 has the execution
⟨ground, ground, ground . . .⟩for which the predicate G([ground ⇒F[top]) does not hold.
It will also be useful to identify the events mentioned explicitly in an LTL formula φ.
This set is called the alphabet of φ, and is written α(φ), similar to the use of αM for the
alphabet of machine M. For example, we have α(φ0) = {top, ground}.
8.4
Preserving LTL Properties in Event-B Reﬁnement Chains
The main result when temporal logic properties are preserved by reﬁnement chains is
given in Lemma 8.1 below. We have already observed that new events can be introduced
during a reﬁnement, e.g., mid. We aim for such properties to be preserved even in the
presence of new anticipated and convergent events.
We ﬁrst identify a key property used in Lemma 8.1 below, which enables us to gain
insights into the kinds of temporal properties that are appropriate to be proposed and
have the potential of being preserved through a reﬁnement chain. Deﬁnition 8.1 describes a
maximal execution satisfying a property φ. The execution may include some events which
do not have an impact on whether the property holds or not; therefore we can restrict the
maximal execution to include only those events that impact on the property.

120
From Action Systems to Distributed Systems: The Reﬁnement Approach
Deﬁnition 8.1. Let β be a set of events. Then φ is β-dependent if α(φ) ⊆β and u |= φ ⇔
(u ↾β) |= φ.
An example of a β-dependent property is GF[ground] with β = {ground}. For any
execution u, u |= GF[ground] ⇔u ↾{ground} |= GF[ground]. Conversely, ¬G(ground) is
not {ground}-dependent. For example, if u = ⟨ground, mid, top, ground, ground, . . .⟩then
u |= ¬G(ground) but u ↾{ground} ̸|= ¬G(ground).
As another example, G(top∨ground) is not {top, ground}-dependent. This is exempliﬁed
by any trace u which contains events other than those in {top, ground}. In this case u ↾
{top, ground} |= G(top ∨ground) but u ̸|= G(top ∨ground). Observe that this property
holds for Lift0 but not for Lift2: it is not preserved by reﬁnement. Since it is not {top, ground}-
dependent Lemma 8.1 below is not applicable for this property.
Lemma 8.1 identiﬁes conditions under which an LTL property φ will be preserved in a
reﬁnement chain. The conditions are as follows:
• by the end of the reﬁnement chain there should be no outstanding anticipated events
(and so all newly introduced events have been shown to be convergent), as given by
restriction 4 of the development strategy;
• the ﬁnal machine in the reﬁnement chain must be deadlock-free; and
• all of the events that have an eﬀect on whether or not φ is true are already present in
M0 (φ is β-dependent for some β ⊆αM0).
These conditions are enough to ensure that φ is preserved through reﬁnement chains. This
means that M0 can be checked for φ, and we can be sure that the resulting system Mn will
also satisfy it.
The lemma is formally expressed as follows:
Lemma 8.1. If M0 |= φ and M0 ≼W . . . ≼W Mn and:
1. Mn is deadlock free;
2. Mn does not contain any anticipated events; and
3. φ is β-dependent for some β ⊆αM0
then Mn |= φ.
The proof of this lemma is given in [295] and we do not repeat it here. Instead it gives
more insight to consider the role played by each of the conditions. One would normally
hope that M0 ≼W Mn and M0 |= φ would imply Mn |= φ without the need for additional
conditions, however in the context of Event-B machines and LTL properties we do have the
need for additional conditions. Thus, consideration of how the lemma fails in the absence of
the conditions provides insight into why they are necessary.
8.4.1
Example: Deadlock-Freedom
Our ﬁrst example illustrates the need for deadlock-freedom:
Observe that Lift0 |= F[ground]. We now consider Example0 which is a reﬁnement of
Lift0:

Free ebooks ==>   www.Ebook777.com
Event-B and Linear Temporal Logic
121
machine Example0
reﬁnes Lift0
variables ﬂr
invariant ﬂr = ﬂr0 ∨ﬂr ∈{1..101}
events
init b= ﬂr: = 0
top b= status: ordinary
when ﬂr = 101 then ﬂr: = 102 end
ground b= status: ordinary
when ﬂr = 102 then ﬂr0: = 0 end
end
This is a reﬁnement because the eﬀects of the events remain the same, but they now have
stronger guards, thus whenever an event from Example0 is enabled then it can be matched by
the same event in Lift0. Furthermore, Example0 has no anticipated events, and F[ground]
is {ground}-dependent. Hence, the only condition of Lemma 8.1 which does not hold is
requirement (1): for Example0 to be deadlock-free. Example0 can in fact deadlock, because
the guards have been strengthened to the point where none of the events can occur.
We also have that Example0 ̸|= F[ground]. The execution consisting of initialisation
followed by deadlock is a maximal execution, and it is not the case that ground will eventually
occur for that execution.
Thus we have Lift0 ≼W Example0 and Lift0 |= F[ground] but Example0 ̸|= F[ground].
The possibility of deadlock in the reﬁnement machine means that the property is not pre-
served.
This arises because strengthening guards can introduce new deadlocks, and so new max-
imal executions can be introduced into the reﬁnement machine that were not present in the
abstract machine. Hence even if all maximal executions of the abstract machine model the
property, it need not be the case that all maximal executions of the reﬁnement machine will
do so.
8.4.2
Example: Anticipated Events
Our second example illustrates the need for there to be no anticipated events:
Consider the reﬁnement relationship Lift0 ≼W Lift1, and the property φ = F[ground].
We have that Lift1 is deadlock-free. We also have that Lift0 |= φ, and that φ is {ground}-
dependent. Hence the only condition of Lemma 8.1 which does not hold is requirement (2):
for Lift1 to contain no anticipated events.
One
possible
execution
of Lift1
is
an
inﬁnite
sequence
of mid
events:
u
=
⟨mid, mid, mid, . . .⟩. For this execution, there is no occurrence of ground, and hence u ̸|=
F[ground]. This means that Lift1 ̸|= F[ground].
Thus we have Lift0 ≼W Lift1 and Lift0 |= F[ground] but Lift1 ̸|= F[ground]. The presence
of anticipated events in the reﬁnement machine means that the property is not preserved.
This arises because anticipated events can occur repeatedly, and hence can provide a
maximal execution that corresponds to a ﬁnite sequence of events from the abstract machine,
which is not necessarily a maximal execution in the abstract machine, but only a ﬁnite preﬁx
of one. Even if the maximal executions of the abstract machine all satisfy an LTL formula
www.Ebook777.com

122
From Action Systems to Distributed Systems: The Reﬁnement Approach
φ, this does not mean that all their ﬁnite preﬁxes will do so. The performance of anticipated
events in a reﬁnement might prevent the progress speciﬁed by φ.
8.4.3
Example: β-Dependence
Finally, we consider an example which illustrates the need for β-dependence:
We have that Lift0 ≼W Lift1 ≼W Lift2 and Lift0 |= G([ground] ∨[top]) but Lift2 ̸|=
G([ground] ∨[top]). This is because the reﬁnement step has introduced a new event mid,
and the possibility of this event invalidates the LTL speciﬁcation. All of the conditions
hold except for requirement (3): that the predicate G([ground] ∨[top]) be {ground, top}-
dependent. The absence of {ground, top}-dependence means that the introduction of new
events such as mid into the execution may not preserve the predicate.
8.5
Discussion and Related Work
One of the few papers to discuss LTL preservation in Event-B reﬁnement is Groslam-
bert [146]. The LTL properties were deﬁned in terms of predicates on system states rather
than our paper’s formulation in terms of the occurrence of events. His paper focused only
on the introduction of new convergent events. It did not include a treatment of anticipated
events but this is unsurprising since the paper was published before their inclusion in Event-
B. Our results are more general in two ways. Firstly, the results support the treatment of
anticipated events. Secondly, we allow more ﬂexibility in the development methodology. A
condition of Groslambert’s results was that all the machines in the reﬁnement chain needed
to be deadlock free. The main lemma, Lemma 8.1, does not require each machine in a re-
ﬁnement chain to be deadlock free, only the ﬁnal machine. It is irrelevant if intermediate
Mis deadlock as long as the deadlock is eventually reﬁned away.
Groslambert deals with new events via stuttering and leaves them as visible events in a
trace. This is why the LTL operators used by the author do not include the next operator
(X). As new events may happen this may violate the X property to be checked. Plagge and
Leuschel in [265] permit the use of the X operator since they treat the inclusion of new
events as internal events which are not visible, and hence do not appear in the trace. Since
we deal with new events as visible events we also lose the ability to reason about a temporal
property using the typical X operator. Our reasoning is simpler than both Groslambert and
Plagge and Leuschel since we only focus on events but this means we cannot have atomic
propositions in our LTL, whereas they can.
The notion of veriﬁcation of temporal properties of both classical and Event-B systems
using proof obligations has been considered in many research papers. Abrial and Mussat in an
early paper, [4], introduced proof obligations to deal with dynamic constraints in classical
B. In [168], Hoang and Abrial have also proposed new proof obligations for dealing with
liveness properties in Event-B. They focus on three classes of properties: existence, progress
and persistence, with a view to implementing them in Rodin. A recent paper by Hudon and
Hoang [175] also introduces new proof obligations to deal with liveness properties in Event-
B based on Unity. They propose a new language referred to as Unity-B so that reﬁnement
chains are guided by both safety and liveness requirements. It is a more comprehensive
treatment than [168] since an event explicitly contains guards and ﬁne and coarse grained

Event-B and Linear Temporal Logic
123
scheduling assumptions. They demonstrate the preservation of these scheduling assumptions
through reﬁnement chains. This is an exciting development since their future work will focus
on decomposition and composition of liveness properties. Bicarregui et al. in [55] introduced
a temporal concept into events using the guard in the when clause and the additional labels of
within and next so that the enabling conditions are captured clearly and separately. However,
these concepts are not aligned with the standard Event-B labelling.
The interest of LTL preservation through reﬁnement is wider than simply Event-B. Der-
rick and Smith [108] discuss the preservation of LTL properties in the context of Z reﬁnement
but the authors extend their results to other logics such as CTL and the µ-calculus. They
focus on discussing the restrictions that are needed on temporal-logic properties and retrieve
relations to enable the model checking of such properties. Their reﬁnements are restricted to
data reﬁnement and do not permit the introduction of new events in the reﬁnement steps.
Our approach does permit new events to be introduced during reﬁnement steps; the con-
tribution is in identifying conditions for LTL properties to hold even in the context of such
new events.
8.6
Conclusion
In this chapter we have considered when temporal logic properties can be carried through
Event-B reﬁnement chains. We have also identiﬁed conditions on temporal logic properties
that make them suitable for use in a reﬁnement chain, since not all properties are preserved
by Event-B reﬁnement. In particular we identiﬁed the notion of β-dependence for an LTL
property: that only the events in the set β need to be checked to determine whether an
execution meets the property. Such properties are not aﬀected by the introduction of new
events in a reﬁnement step, which means they will carry through a reﬁnement chain and will
hold for any resulting reﬁnement which is deadlock-free and does not contain anticipated
events. This main result is expressed in Lemma 8.1. The chapter presented a Lift example
reﬁnement chain to illustrate the results and how they are applied.

This page intentionally left blank
This page intentionally left blank

Chapter 9
A Provably Correct Resilience Mediator
Pattern
Mats Neovius
Åbo Akademi University, Turku, Finland
Mauno Rönkkö
Department of Environmental Science, University of Eastern Finland
Marina Waldén
Åbo Akademi University, Turku, Finland
9.1
Introduction ......................................................
126
9.2
Provably Correct Stepwise Development with Action Systems ..
127
9.2.1
Weakest Precondition Predicate Transformers and the
Action Systems Framework ..............................
127
9.2.2
The Action Systems Framework .........................
128
9.2.3
Reﬁnement ...............................................
129
9.2.4
Tool Support .............................................
130
9.3
Resilience Mediator ..............................................
131
9.4
Formal Development of the Resilience Mediator Pattern .......
132
9.4.1
The First Model - Abstract System .....................
132
9.4.2
The Second Model - Introduction of the
Producer-Consumer Pattern .............................
133
9.4.3
The Third Model - Introduction of the Resilience
Mediator .................................................
136
9.4.4
Example of a Resilience Mediator .......................
137
9.5
Discussion and Conclusion .......................................
138
Abstract. The computational processes that manifest as systems are getting ever more
complex. Interconnecting several similar autonomous systems to a system of systems is
frequent, e.g. manufacturers’ autonomous products are integrated to a home automation
system. Traditionally, the approach for this problem has been abstraction of the details and
thus, chiseling and gluing the bits and pieces together. This has been done by declaring
interfaces or by using formal methods. The former declares accessibility whereas the latter
may be used to gain a rigorous mathematical-logical view on the complexity and for the
ability to reason on this with a set of logical rules. On top of these views, the mediator pattern
is deﬁned to provide a reusable solution for a recurring general problem. The mediator
pattern encapsulates interaction between a set of autonomous systems with the intension to
ease maintenance and refactoring. In this chapter, we formally integrate the mediator pattern
in a correct-by-construction manner in the Action Systems formalism. The contribution is
125

126
From Action Systems to Distributed Systems: The Reﬁnement Approach
in introducing the mediator on an abstract level to a contemporary distributed system as
a correctness preserving reﬁnement step. In this setting, the mediator may then be further
reﬁned to provide an isolated placeholder for introduction of domain speciﬁc intelligent
resilience addressing possible issues of inconsistency.
9.1
Introduction
Software engineering is a rather new engineering discipline. It diﬀers from the more
traditional disciplines in nearly all aspects; as a bridge is built to serve a function in a speciﬁc
environment, the contemporary software is expected to operate in a magnitude of possibly
changing deployment environments. This requires the software to adapt its functionality
deﬁned by the input correctness. As a result, the development of contemporary software is
not only complex, but often also complicated. To structure the development and to have a
toolbox of solutions for recurring problems, design patterns are deﬁned; and to make this
in a rigorous manner a formal description of it may be devised. The design pattern that we
formally integrate to a speciﬁcation is the mediator pattern that may be used to provide
resilience.
The mediator pattern describes the well-known producer-consumer relationship, also
known as publisher-subscriber or sender-receiver. The purpose is for a group of autonomous
agents to communicate with each other through a mediator. The frequent example is a mail-
box to which a set of producers (senders) may put a message intended only for a designated
subscriber (receiver) that receives this message the next time they connect. As this is a good
explanatory example, we note that introducing simple logic to the mediator is possible, e.g.
majority voting in terms of fault tolerance. Related to fault tolerance, resilience introduces
a sense of intelligence [216, 321] in case of unexpected changes. “Resilience thus deals with
conditions that are outside the design envelope whereas other dependability metrics deal
with conditions within the design envelope” [330]. Hence, environmental issues and inter-
action in multi-agent systems are most deﬁnitely subject to resilience where optimally, in
addition to correcting predeﬁned faulty inputs, a sense of learning is implemented. This
learning including means of adaption is outside the envelope and constitutes a critical func-
tionality of the system at hand. However, as the learning and response are implementation
and deployment specifc issues, we limit ourselves to introduce the mediator as a placeholder
to which this domain speciﬁc knowledge may be added.
Evidently, the critical parts of a system are those on which applying formal methods
with the purpose of proving correctness is motivated. Formal languages for specifying design
patterns include BPSL [324] and LePUS [138]. As these languages do provide the basis for
formalizing the pattern itself, they do not treat the pattern in context of some formal method
that would provide the tools of formal correctness to the engineer’s toolbox. Moreover, as
the design envelope of the formal method is the requirements manifested as a speciﬁcation,
a mediator pattern featuring resilience in this context is outside the envelope. This outlines
the contribution of this chapter; we show how to introduce a mediator as a correctness
preserving reﬁnement step in the Action Systems framework [27].
Action Systems enable a rigorous stepwise development that follows the rules of reﬁne-
ment calculus by Back [24]. We show how to introduce the mediator pattern to a speciﬁcation
consisting of sets of producer and consumer systems while preserving correctness without

A Provably Correct Resilience Mediator Pattern
127
changing the producers or consumers. Moreover, we consider the producers and consumers
to be autonomous, i.e. their service logic and interfaces are subject to change without notice.
We do not restrict the mediator pattern’s functionality by any means, hence allowing its
further development according to the domain speciﬁc requirements. This implies that reuse
of proof of introducing the mediator is reusable, but reuse of domain speciﬁc resilience logic
is impossible or very diﬃcult; an issue not considered in this chapter.
The structure of this chapter is as follows. Section 9.2 outlines the Action Systems
framework and the related reﬁnement calculus framework. Section 9.3 discusses previously
published work on the resilience mediator pattern. Section 9.4 discusses how a resilience
mediator pattern is introduced in a correct manner using the Action Systems formalism. In
Section 9.5, we conclude and discuss the application of the resilience mediator pattern and
its further development.
9.2
Provably Correct Stepwise Development with Action Systems
The Action Systems formalism [27, 33] is a rich formal language that is well suited for
modelling critical systems in a correct-by-construction manner. It was further developed
for specifying distributed systems by Sere [31, 298]. The Action Systems formalism relies
on Hoare logic [170] and the weakest precondition predicate transformer (wp) semantics of
Dijkstra [112]. The abstract action systems can be developed via stepwise reﬁnement [23, 249]
adding more details to the speciﬁcation while preserving its mathematical correctness within
the reﬁnement calculus framework [38].
9.2.1
Weakest Precondition Predicate Transformers and the Action
Systems Framework
The weakest precondition predicate transformer semantics is deﬁned on the language
of guarded commands [112, 113] for assigning meanings to programs. A wp is deﬁned on a
statement s and postcondition q as wp(s, q). It is a Boolean function wp(s, q):(Σ →Bool) →
(Γ →Bool) where Σ and Γ denote the before and after state space [38] on a set of states
Σwp(s,q) ⊆Σ for which executing s guarantees q, i.e. Γq ⊆Γ. The wp semantics assume
monotonicity, conjunctivity, continuity and that wp(s, false) = false, i.e. the law of the
excluded miracle. The semantics allow nested loops.
For the Action Systems framework used in this chapter, the properties of the wp seman-
tics have been revised. For example, the continuity condition is violated by non-determinism
and the law of the excluded miracle by angelic behavior. The predicate transformer semantics
used in this chapter is deﬁned in Table 9.1.
Of these statements, magic always establishes q. Disallowed behaviour is captured by
abort statement, whereas skip does nothing. If a evaluates to false for assumption [a], the
statement behaves miraculously while for assertion {a}, the statement aborts. In both cases,
if a evaluates to true the statement behaves as skip. We say that a statement is enabled iﬀ
executing the statement establishes q, i.e. deﬁnes the guard predicate gd on statement s as
gd(s) = ¬wp(s, false). Thus, statements abort, skip, x := E and {a} are always enabled.
On these fundaments, we deﬁne the Action Systems framework.

128
From Action Systems to Distributed Systems: The Reﬁnement Approach
Table 9.1: Semantics of conventional actions
action
notation wp(action, q)
Miraculous statement
magic
true
Aborting statement
abort
false
Stuttering statement
skip
q
Multiple assignment
x := E
q[E/x]
Non-deterministic assignment X: ∈S
∀x′.x′ ∈S ⇒q[x′/x]
Sequential composition
sA;sB
wp(sA, wp(sB, q))
Non-deterministic choice
sA [] sB
wp(sA, q) ∧wp(sB, q)
Assumption
[a]
a ⇒q
Assertion
{a}
a ∧q
9.2.2
The Action Systems Framework
The semantics of the Action Systems framework is based on the wp semantics with a
basic building block of an action. An action is deﬁned as a guarded statement denoted by
gA →sA with the meaning of [gA];sA. For action A the gA is commonly called the guard
whereas the action’s body is sA. Thus, the enabledness gd(A) of an action is deﬁned gd(A) =
gA ∧¬wp(sA, false). Consequently, the wp of an action on some q is wp([gA];sA, q) = gA ⇒
wp(sA, q). Moreover, the actions are ﬁnitely conjunctive implying demonic non-determinism,
i.e. wp(A, q ∧r) ⇒wp(A, q) ∧wp(A, r). This also implies monotonicity, i.e. that (q ⇒
r) ⇒(wp(A, q) ⇒wp(A, r)). On these actions, the repetitive construct may be deﬁned:
wp(do A od , q) = (∀n.wp(An, gA ∨q)) ∧(∃n.¬gAn) where A0 = skip and An+1 = An;A.
Thus, the repetitive construct deﬁnes that after each action some other action is enabled
or the postcondition q is satisﬁed, that the number of actions is ﬁnite and that there is a
termination state (total correctness).
An action system A is a composition of an initialization statement a0 and a repetitive
construct of actions separated by non-deterministic choice. The outline is thereby as follows:
A = | [ var x, y∗; a0;do A1 [] ... [] An od ] | :z
In A the variables are x, y and z. More speciﬁcally, x are local variables, y are exported
variables denoted by asterisk ∗and z are imported variables declared in some other action
system. Statement a0 initialises x and y followed sequentially by the repetitive construct of
actions Ai.
The execution model of an action system does not provide fairness. The action system ter-
minates when no action is enabled in the repetitive construct, i.e. when q of wp(do A od , q)
is established. Moreover, parallel execution of actions is possible when the actions operate
on disjoint sets of variables [31, 298].
Features of the Action Systems framework include parallel composition and prioritised
execution. Parallel composition of action systems is denoted by “ || ” [25]. Thus, for action
systems
A = | [ var x, y∗; a0;do A1 [] ... [] An od ] | :z
and
B = | [ var u, v∗; b0;do B1 [] ... [] Bn od ] | :w

A Provably Correct Resilience Mediator Pattern
129
the parallel composition is
A || B = | [ var x, u, y∗, v∗;a0;b0;
do A1 [] ... [] An [] B1 [] ... [] Bn od
] | : (z ∪w) −(v ∪y)
Overlapping variable names are solved by renaming before composition. Composition is as-
sociative and commutative, but irreversible. Therefore, it is used frequently only for analysis
purposes.
9.2.3
Reﬁnement
Reﬁnement of Action Systems is based on work by Back et al. [38]. Fundamentally,
reﬁnement is a collection of conditions for unidirectional stepwise concretisation from a more
abstract set of actions to a more concrete set while preserving the mathematical properties.
Typically, reﬁnement reduces non-determinism or adds functionality. Reﬁnement is denoted
by ⊑and if A ⊑A′ we say that A′ reﬁnes A. A statement S is reﬁned by S′ if and only if
∀q:wp(S, q) ⇒wp(S′, q), i.e. if a postcondition is established by S then the same condition
should be satisﬁed by S′ as well. By transitivity it holds that if S ⊑S′ and S′ ⊑S′′ we
have that S ⊑S′′. As an action is a sequential composition of two statements, reﬁnement
of an action follows the same structure. The conditions to prove are (i) {gA};sA ⊑sA′ and
(ii) gA′ ⇒gA, i.e. to show that if gA holds then sA is reﬁned by sA′ and that A is enabled
whenever A′ is enabled. An abstraction relation R mapping variables from A to A′ is deﬁned
for data reﬁnement. In relation R(x, x′, u), x denotes the abstract variables, x′ the concrete
variables and u the global variables. The reﬁnement considering R is then denoted by ⊑R,
and the conditions to prove are (i) {gA};sA ⊑R sA′ and (ii) R ∧gA′ ⇒gA. Intuitively, this
means that (i) the action A′ behaves in the same way as A and (ii) that the guard of A′ is
strengthened.
A powerful kind of data reﬁnement is superposition reﬁnement [35]. Fundamentally,
superposition introduces new functionality to the action system. The new functionality must
not interfere with the old one. Consider
A = | [ var x, y∗; a0;do A od ] | :z
and
A′ = | [ var x′, y′∗; a0;do A′ [] W ′ od ] | :z′
Then A ⊑R A′ holds only if the following conditions hold:
1. Initialisation:
(a) a′
0 has the same eﬀect on the old variables as a0 when R(x, x′, u) holds;
(b) a′
0 establishes R(x0, x′
0, u)
2. Old actions:
(a) Each old action A′ has the same eﬀect on the old variables as A when R(x, x′, u)
holds;
(b) The old actions A′ will preserve R(x, x′, u);

130
From Action Systems to Distributed Systems: The Reﬁnement Approach
(c) The guards of the old actions are strengthened, gA′ ⇒gA, whenever R(x, x′, u)
holds
3. Auxiliary actions:
(a) W ′ has no eﬀect on x and u;
(b) Each W ′ preserves R(x, x′, u)
4. Termination of auxiliary actions: The auxiliary actions W ′ must not compute forever
if R(x, x′, u) holds, i.e. R ⇒wp(do W ′ od , true)
5. Exit condition: R ∧¬gA′ ∧¬gW ′ ⇒¬gA
6. Non-interference: Execution of an external action belonging to an environment action
system, E , where R(x, x′, u) holds, preserves R(x, x′, u)
The three ﬁrst conditions guarantee that the initialisation and the actions are correct
reﬁnements. The auxiliary actions W ′ must, for example, only assign the new variables x′
such that relation R holds. The fourth condition stipulates that each auxiliary action must
terminate if R(x, x′, u) holds. Finally, the ﬁfth condition states that whenever R(x, x′, u)
holds and no action is enabled in the reﬁned system A′, then no action is enabled in the old
system A. As we do not specify the environment here, we simply assume that condition 6
holds throughout the rest of this chapter.
9.2.4
Tool Support
We have chosen the Action Systems formalism in this chapter, since it is a very pow-
erful and ﬂexible modelling framework. However, in order to be able to develop complex
systems that are correct-by-construction we need to be able to rely on tool support for the
reﬁnement proofs. The Action Systems formalism lacks direct tool support. However, via
the Event-B formalism developed by Abrial [6] we can consider to have tool support also for
Action Systems. Event-B originates from the B-Method [5], but has been heavily inspired
by Action Systems. Moreover, the correspondence between Action Systems and Event-B is
underpinned by the B-Action Systems formalism [341] that can represent Action Systems
using the B-Method. System development in Event-B is based on set theory and atomic-
ity for the events in the same way as for Action Systems. Moreover, abstract models are
developed into concrete ones by stepwise reﬁnement in both formalisms.
The Rodin Platform1 is an Eclipse based tool that provides tool support for stepwise
development of Event-B models. The tool generates proof obligations for the abstract as well
as the concrete model to be able to show that they are consistent and correct with respect
to the abstract model. These proof obligations correspond to the ones shown in Section
9.2.3. The tool tries to prove the proof obligation automatically. The ones that cannot be
proved automatically can be discharged interactively by the user. The interactive proving
process is facilitated by a number of Eclipse plug-ins. Also the development process is well
supported by tools. Notable in the context of this chapter are ProB2 that help to visualise
the development and UML-B [310] translating UML diagrams3 to Event-B models. A later
1http://rodin.cs.ncl.ac.uk/
2http://www.stups.uni-duesseldorf.de/ProB/index.php5/Main Page
3http://www.uml.org/

Free ebooks ==>   www.Ebook777.com
A Provably Correct Resilience Mediator Pattern
131
version of the tool iUML-B4 even allows a more integrated development between UML and
Event-B.
In this chapter we rely on UML statechart diagrams when modeling our systems. Due
to the tight correspondence between Action Systems and Event-B we can rely on the prin-
ciple for translation of UML to Event-B when creating action systems from our statechart
diagrams. State changes in a UML diagram are represented by a variable state in the ac-
tion system. The transitions in UML are modeled by actions. The guards on the transitions
have a one-to-one correspondence to the guards in the action systems. Moreover, the initial
transition in UML is modeled by the initialisation statement in the action systems and the
abort transition by the abort statement.
9.3
Resilience Mediator
As previously explained, our environment has become populated with autonomous sys-
tems, many of which are provided as “black boxes”. Therefore, improving the resilience of
an aggregated system is by no means trivial, as the sub-systems and services cannot be en-
hanced or reﬁned in any way. Furthermore, the service interfaces and the service logic may
change without notice, leading to faulty messaging and unpredictable system’s dynamics.
Also, as the number of connected components change, it becomes harder to track the cause
of a fault. A fault may then propagate over communication from one component to another,
causing the connected components to enter faulty states one by one. This cascading eﬀect
has been studied, for instance, by Zhu et al. [353].
With this problem setting in mind, a method for designing resilience mediators was pro-
posed in an earlier article [283]. A resilience mediator is a data mediator [345]. It is placed in
between the set of producer and consumer components of a system relaying their messages,
as depicted in Figure 9.1. Based on the messages, the mediator detects and stores events.
Stored events are inspected by a monitor that notiﬁes the mediator about state changes.
Hence, the resilience mediator can maintain state awareness [276] and correct or reﬁne a
message between the producers and consumer components accordingly. In this way, propa-
gation of faults becomes restricted while requiring no changes to the original components.
Consequently, a resilience mediator can address faulty dynamics that can be identiﬁed from
the communication and that can also be mediated by enhancing the communication between
the connected components. From a maintenance point of view, the use of resilience media-
tors ensures that all resilience improvements are localized to the mediators that coordinate
the resilience actions, improving the management of later resilience extensions.
An earlier article [283] proposed an analysis and design process for the resilience me-
diators to uncover desired resilience actions. The process includes four steps: 1) behavioral
analysis with sequence diagrams is used to uncover critical messaging; 2) deviation analysis
with HAZOP tables [274] is used to identify all potential deviations; 3) mediation analysis
is used to identify deviations that can be identiﬁed in communication and corrected during
messaging; 4) fault state analysis is used to verify improved resilience and signiﬁcance of
remaining fault propagation.
Although the analysis and design process proposed in [283] is needed to understand the
4http://wiki.event-b.org/index.php/IUML-B
www.Ebook777.com

132
From Action Systems to Distributed Systems: The Reﬁnement Approach
Figure 9.1: The resilience mediator as an architectural component.
potential deviations and their eﬀect on the system as a whole, the process does not address
the implementation or its correctness. In particular, the design process does not address the
implementation phase at all. Because of this, the design process does not provide a provably
correct design pattern that can be applied to improve the resilience of an aggregated system
in a reliable manner. For this reason, we will show below how to introduce a resilience
mediator to an aggregated system in a provable correct manner by using the Action Systems
formalism.
9.4
Formal Development of the Resilience Mediator Pattern
With devices being connected all the time everywhere providing possibly faulty informa-
tion to some consumers, the mediator acts as a relay of this information. Because of this, a
mediator may introduce intelligent inspection of the information by applying ﬁltering and
reacting on controversial inputs. Such a mediator is then an instance of a resilience mediator.
The purpose of the resilience mediator is to prevent the escalation of a faulty input to a
system wide faulty state.
The abstract sequence diagram before applying the mediator pattern is depicted in Figure
9.2. The producer ﬁrst produces data, and then signals the consumer to start consuming
the data. After consuming the data, the consumer signals about the end of the consumption
to the producer. When the resilience mediator pattern has been applied, the mediator acts
as a relay, as depicted in Figure 9.2. The diﬀerence with the mediator is that it brings in
intelligence via an additional preprocessing phase that allows to determine potential faults
and anomalies in the signaling, thus giving the opportunity for the mediator to intervene and
correct the signaling before passing it on. We shall now show how such a resilience mediator
is introduced in a stepwise, provably correct manner in the Action Systems framework.
9.4.1
The First Model - Abstract System
Using Action Systems, we start the development with the most abstract system descrip-
tion that exhibits provably correct and desired dynamics. Such a system typically has only
a few states and a predeﬁned sequence of state transitions. All the details are then intro-
duced to the abstract system step by step. During each step, the correctness is preserved by
proving the reﬁnement proof obligations as stated earlier.

A Provably Correct Resilience Mediator Pattern
133
Figure 9.2: Traditional producer-consumer signaling sequence on the left and signaling with
a mediator on the right.
Figure 9.3: The abstract system as a UML statechart on the left and as an action system,
called AbstractSystem, on the right.
In our case, the abstract system captures overall systems dynamics, as depicted in Figure
9.3 as a UML statechart. The abstract system has two states: a correct state and a faulty
state. The system is initialized to the correct state. The system can do processing in both
states; however, the processing in the faulty state is faulty processing. The system may
change between the correct and faulty state. In particular, if the processing fails in the
correct state, the system state changes to the faulty state. Correspondingly, the system may
recover from the faulty state back to the correct state. There is also a possibility that the
faulty state processing is unmanageable. Then the system aborts. The corresponding action
system is also presented in Figure 9.3. In the action system, there is only one variable,
state, capturing the two states depicted in the UML statechart. As mentioned earlier, each
transition in the statechart corresponds to an action in an action system. The correspondence
is indicated by referring to the name of the transition in the corresponding action.
9.4.2
The Second Model - Introduction of the Producer-Consumer
Pattern
In the ﬁrst reﬁnement step, we introduce the traditional producer-consumer pattern, as
depicted in Figure 9.2, to the abstract system. In terms of the statechart, this is done by
reﬁning the self-referential transitions “processing” and “faulty processing”. For the transition
“processing” this is done by:
1. splitting the state “Correct state” into two states “Correct state produce” and “Correct
state consume”
2. adding transitions “start” and “end” between the two states

134
From Action Systems to Distributed Systems: The Reﬁnement Approach
Figure 9.4: Statechart diagram of the system with producer-consumer states; hierarchical
statechart on the left and ﬂattened statechart on the right.
3. adding self-referential transition “producing” to the state “Correct state produce”
4. adding self-referential transition “consuming” to the state “Correct state consume”
5. assigning the transitions “fail” and “recover” from and to the state “Correct state
consume”
The same is then repeated for the transition “faulty processing” with respect to the state
“Faulty state”. The resulting statechart is shown in Figure 9.4. Note that the transitions
“fail” and “recover” were purposefully assigned to the consumption states only. The reason
for this is that we aim at introducing a resilience mediator that is able to detect and correct
faults and anomalies occurring in the producer component. However, as the resilience medi-
ator may not always be able to correct faulty dynamics, the failure may still take place on
the consumer side. This is why the failure and recovery is considered only for the consumer
states. Figure 9.4 also shows a statechart, where the hierarchical (inner) states are ﬂattened
into single level diagram. The resulting statechart also indicates which states belong to the
producer and consumer components.
To prove that this reﬁnement strategy is correct, we use the Action Systems formalism.
This is done by using the superposition reﬁnement. With respect to the abstract system
shown above, we introduce two new variables cState and fState to describe the changes in the
new statechart with four states. We then add new actions to capture how the values of these
variables change with respect to the abstract state variable, state. Lastly, the existing actions
are bound to the new variables by strengthening their guards and adding the appropriate
assignments to the new variables. The resulting action system is shown in Figure 9.5. The
names of the actions indicate which original action of the abstract system they reﬁne. The
names of the actions also indicate which transitions the actions capture in the new statechart.
The abstraction relation between AbstractSystem and PCSystem is as follows:
(state = correct ⇒fState = consume) ∧(state = faulty ⇒cState = consume)
Hence, the communication between the correct and the faulty states takes place via state
consume.
To prove that the reﬁned system PCSystem is a correct reﬁnement of AbstractSystem,
we need to show that all the reﬁnement proof obligations in Section 9.2.3 are satisﬁed.
First, in PCSystem, the state is initialized to correct and is hence a correct simulation of
AbstractSystem. The relation (invariant) is established since variable fState is assigned to
value consume. Hence, proof obligation 1 is satisﬁed. In the reﬁned actions “fail” and “re-
cover” we strengthen the guards and only add new assignments to the substate variables

A Provably Correct Resilience Mediator Pattern
135
Figure 9.5: An action system, called PCSystem, with producer and consumer actions intro-
duced.
Figure 9.6: Action systems with merged state variable.
cState and fState according to the abstraction relation, respectively. In addition, the actions
“processing.2” and “processing.4” reﬁne the original stuttering action “processing”. Simi-
larly, the actions “faulty processing.2” and “faulty processing.4” reﬁne the original stuttering
action “faulty processing”. This also holds for the actions “processing.3” and “faulty process-
ing.3”. Hence, proof obligation 2 is fulﬁlled. The auxiliary actions “processing.1” and “faulty
processing.1” assign the new variables cState and fState, respectively, in a manner that pre-
serves the abstraction relation. Since they only assign the new variables and their guards are
strengthened, proof obligation 3 is satisﬁed. The auxiliary actions disable themselves and
hence they fulﬁll proof obligation 4. Both systems terminate only by abort, fulﬁlling proof
obligation 5. Proof obligation 6 holds as there are no parallel composed environment action
systems present.
For clarity, we shall next reorganize PCSystem by representing the original state-space
involving three variables with a single variable state-space of all reachable states. As a re-
sult, we obtain an action system called SystemIntegrated as shown in Figure 9.6. As there

136
From Action Systems to Distributed Systems: The Reﬁnement Approach
Figure 9.7: Flattened statechart diagram of the system with the resilience mediator states.
is a one-to-one correspondence between the actions of PCSystem and SystemIntegrated, the
reﬁnement invariant is the equivalence relation between the guards of the actions. Conse-
quently, the reﬁnement proof obligations are satisﬁed.
9.4.3
The Third Model - Introduction of the Resilience Mediator
In the second reﬁnement step, we introduce to the action system SystemIntegrated the
resilience mediator to the statechart with the producer-consumer pattern. We apply the
exact same reﬁnement strategy as in the ﬁrst reﬁnement step. This time, we reﬁne the
self-referential transition “consuming” for both of the states “Correct state consume” and
“Faulty state consume” in Figure 9.4. For the transition “consuming” and the state “Correct
state consume” this is done by:
1. splitting the state “Correct state consume” into two states “Correct state preprocess”
and “Correct state consumption”
2. adding transitions “succeed” from the state “Correct state preprocess” to the state
“Correct state consumption”
3. assigning the “start” transition to the state “Correct state preprocess”
4. assigning the “end” transition to the state “Correct state consumption”
5. assigning the transitions “fail” and “recover” to the state “Correct state preprocess”
only
The same is then repeated for the transition “consuming” with respect to the state
“Faulty state consume”. The resulting ﬂattened statechart is shown in Figure 9.7. Note
that the transitions “fail” and “recover” were purposefully assigned to the preprocessing
states only. This is a design choice, whereby we delegate the responsibility of detecting
a faulty operational state to the resilience mediator. Consequently, we may introduce the
resilience mediator without changing the producer and consumer components. The cor-
rectness of the second reﬁnement step is proven with Action Systems in the same way as
for the ﬁrst reﬁnement step. By this reﬁnement strategy, we arrive at an action system
MediatorSystemIntegrated as shown in Figure 9.8. The resulting action system has, thus,
a single variable for capturing the state change and transitions between the producer, the
mediator and the consumer.
By reverse application of the parallel composition rule, we can decompose an action
system into distributed sub-systems that operate in parallel by their shared pmc state. By

A Provably Correct Resilience Mediator Pattern
137
Figure 9.8: An action system representation of the system with the resilience mediator
states.
applying this technique to MediatorSystemIntegrated, we can obtain action systems that
capture the behavior of the individual components, the producer, the mediator and the
consumer. The resulting action systems are shown in Figure 9.9. For clarity, we have declared
the global, shared variable pmc state in an action system of its own to emphasize that the
variable is a global state variable that is not owned by any of the components.
9.4.4
Example of a Resilience Mediator
As an example of adding a resilience mediator to a model, we can consider an adaptive
house with components and activities [283]. More speciﬁcally, we focus on the adaptation
of home automation to the occupants’ vacation. During their vacation, the occupants are
assumed to be away from home. Technically, the event starts when the occupants enter
their vacation to a calendar. The adaptive house uses the entry for instance to plan heating,
cooling and ventilation of an empty house. Its objective is to save energy during the vacation
while maintaining nominal living conditions. The living conditions are restored at the end
of the vacation, so that when the occupants arrive, the house has optimal living conditions.
In order to do this, the adaptive house accesses not only the calendar, but also a weather
forecast service as well as relevant pricing services regarding electricity used for HVAC.
For clarity, we focus here on the activity of scheduling the vacation and the timing of the
home automation in the adaptive house example. Following the resilience mediator pattern
introduced in this chapter we start with a very abstract model as in the pattern. Hence, we
only state that we have a correct state and a faulty state. Then following the pattern, we
introduce a producer and a consumer in the model. The producer corresponds to the calendar
that takes care of scheduling the functions in the house, and the consumer corresponds to
the adaptive controller that processes the scheduled data. The resilience mediator pattern
allows us to add a mediator to the producer-consumer model as a reﬁnement step. Here
we introduce a mediator to handle the preprocessing of the scheduled data. The producer,

138
From Action Systems to Distributed Systems: The Reﬁnement Approach
Figure 9.9: The obtained action systems capturing the producer, mediator and consumer
actions.
consumer and mediator can subsequently be reﬁned to capture more details in scheduling
the adaptation of the home automation.
As an example of the role of the mediator, we can consider the case for detecting when
the end of a scheduled event was not correctly given in the system [283]. A mediator can
detect the mismatch by having external contextual information, for instance, by monitoring
use of water, energy and appliances or movement. Due to the calendar information, the
adaptive control will start to adjust the house for an arriving occupant. After some time,
however, the mediator can detect that the house is adjusted for occupants, but there is no-
one there. Then, the mediator can contact the occupant for conﬁrmation, and depending on
occupants estimated arrival time, reschedule arrival or ask the occupant to reschedule the
vacation duration. As a consequence, some intelligence has been brought to the adjustment
via the mediator.
9.5
Discussion and Conclusion
Patterns in software design have an established meaning while pattern in formal methods
are sometimes mixed with reuse. The reason is the objective. Patterns in formal methods

A Provably Correct Resilience Mediator Pattern
139
have been used to facilitate proof reuse [136] as a model transformation that adds or modiﬁes
certain elements of the speciﬁcation [232] given that the pattern speciﬁcation matches the
problem [169]. This view omits the generality of the design pattern as intended in software
engineering, i.e. that a pattern is an unﬁnished product; which is the approach taken by this
chapter on a system level.
Resilience and fault tolerance are sometimes used interchangeable. Fault tolerance on a
priori known faulty behavior, sometimes called resilience, takes a slightly diﬀerent approach
as of the uniform recovery strategy. This fault tolerance has been extensively studied by
Troubitsyna [332] and later, as resilience [262] However, with respect to the deﬁnition of
resilience, a resilient entity is intelligent that we consider being more than sets of logical
rules.
The resilience mediator as introduced in this chapter is valid regardless of the level of
abstraction, whether this is a component or a system. The common denominator that the
resilience mediator considers on systems, components, system of systems and multi-agent
systems is the distance of the speciﬁcation from reality. In the considered setting, the real-
ity changes and thus, the distance varies. Hence, a valid formal approach cannot be ﬁxed,
but needs to adapt. This adaption is the point of introducing intelligence, i.e. the point of
resilience acting as the motivation of this chapter. Thus, a formal speciﬁcation with the me-
diator pattern implemented is always at least as close to the reality as without the mediator.
We have shown in this chapter that the mediator pattern can be introduced as a reﬁnement
step to a formal producer-consumer speciﬁcation in the Action Systems formal framework.
This is the main contribution of this chapter.
Acknowledgments. This research is funded by the Academy of Finland project
“FResCo: High-quality Measurement Infrastructure for Future Resilient Control Systems”
(Grant numbers 264060 and 263925).

This page intentionally left blank
This page intentionally left blank

Part IV
Reﬁnement
141

This page intentionally left blank
This page intentionally left blank

Chapter 10
Relational Concurrent Reﬁnement - Partial
and Total Frameworks
John Derrick
Department of Computer Science, University of Sheﬃeld, Sheﬃeld, S1 4DP, UK
Eerke Boiten
School of Computing, University of Kent, Canterbury, Kent, CT2 7NF, UK
10.1
Introduction ......................................................
143
10.2
Models of Reﬁnement ............................................
144
10.3
Using a Partial Framework to Embed Concurrent Reﬁnement
Relations .........................................................
145
10.3.1
Basic Relations without Divergence .....................
146
10.3.2
Internal Events and Divergence .........................
148
10.4
A Total Relational Framework ...................................
149
10.5
A General Framework for Simulations - Process Data Types ...
150
10.6
Conclusions .......................................................
153
10.1
Introduction
Data reﬁnement as found in a state-based language such as Z or B, and reﬁnement
as deﬁned in a process algebra may appear as very diﬀerent notions. Data reﬁnement is
deﬁned using a relational model in terms of the behaviour of abstract programs, whereas
in models of concurrency, reﬁnement is often deﬁned in terms of sets of observations. The
methodologies used to verify them are also diﬀerent: downward and upward simulations for
data-reﬁnement, whereas calculation of traces, refusals etc. from the semantics is prevalent
in a process algebra.
In this chapter we discuss work undertaken to reconcile the two approaches. Speciﬁcally,
we show how one can embed concurrent semantics into a relational framework. This not only
articulates the relationship between the two, but allows event-wise veriﬁcation methods for
concurrent reﬁnement relations to be derived. We discuss how this can be achieved below,
with particular emphasis on the type of relational model used - speciﬁcally whether one uses
a model containing total relations, or one in which relations may be partial. Both are shown
to have limits in expressiveness, and because of this we introduce a more general framework
for simulations, called process data types.
143

144
From Action Systems to Distributed Systems: The Reﬁnement Approach
10.2
Models of Reﬁnement
This chapter starts out from a standard theory of reﬁnement for abstract data types
(ADTs) using relational models. The seminal paper on this topic was by He, Hoare and
Sanders [159]. It uses what we would now call the total relational model: all operations are
total relations, and it has been used in a number of contexts. For example, the standard
reﬁnement theory of Z [348, 105], is based on this version of the theory. However, it is equally
feasible to use a model where the relations can be partial, and after the original framework
was introduced the restriction to total relations was dropped (see [158]). The key result that
makes the partial framework useable is that it is equally possible to prove soundness and
joint completeness of the same set of simulation rules in the partial framework.
In this model, a program (deﬁned here as a sequence of operations) is given a semantics
as a relation over a global state G. The global state G is deﬁned such that values in G, or
more generally: relations on G form the observations that we wish to make of programs. The
operations of the ADT, however, are concerned with a local state State. In order to make
observations on global states from these, any sequence of operations is bracketed between
an initialisation and a ﬁnalisation which translate between global and local state.
The following deﬁnes our notion of relational abstract data type.
Deﬁnition 10.1 (Data type; Total data type).
A (partial) data type is a tuple (State, Init, {Opi}i∈J, Fin). In this tuple, State is its local state,
and operations {Opi}, indexed by i ∈J, are relations on this local state. The initialisation
Init is a total relation from G to State, and the ﬁnalisation Fin is a total relation from State
to G.
For a total data type, we impose the additional constraint that all operations are total
on State.
2
For now we require that Init and Fin are total; this is not a signiﬁcant restriction of
expressiveness, and it could be relaxed if needed. We use it as a view that it is always
possible to start a program sequence, and that it is always possible to make an observation.
We can then deﬁne programs, and hence data reﬁnement as follows.
Deﬁnition 10.2 (Program; Data reﬁnement).
Given a data type D = (State, Init, {Opi}i∈J, Fin) a program is a sequence over J. For a
program p = ⟨p1, ..., pn⟩over D, its meaning is deﬁned as pD = Init o
9 Opp1
o
9 ... o
9 Oppn
o
9 Fin.
Given data types A and C, C is a data reﬁnement of A, denoted A ⊑data C, iﬀfor every
sequence p over J, pC ⊆pA.
2
The standard way to verify a reﬁnement is to use simulations, of which there are two
varieties: downward and upward.
Deﬁnition 10.3 (Downward and upward simulations).
A relation R ⊆AState × CState is a downward simulation between data types A =
(AState, AInit, {AOpi}i∈J, AFin) and C = (CState, CInit, {COpi}i∈J, CFin) if and only if the
following conditions hold:
CInit ⊆AInit o
9 R
R o
9 CFin ⊆AFin
∀i:J • R o
9 COpi ⊆AOpi
o
9 R

Relational Concurrent Reﬁnement - Partial and Total Frameworks
145
A relation T ⊆CState × AState is an upward simulation between A and C as above if and
only if:
CInit o
9 T ⊆AInit
CFin ⊆T o
9 AFin
∀i:J • COpi
o
9 T ⊆T o
9 AOpi
2
They are sound (every simulation establishes data reﬁnement) and jointly complete (ev-
ery data reﬁnement can be proved by a sequence of simulations) [159, 102].
An alternative view of reﬁnement is that used for a behavioural notation such as a process
algebra [171, 246, 53]. In a process algebra, such as CSP, CCS, ACP, LOTOS, reﬁnement
is deﬁned over the semantics of the language, which is often given by labelled transition
systems (LTS) and sets derived from these. For example, for CSP or CCS the language is
modelled as an LTS where the state space is the set of terms in the language.
Reﬁnement preorders and notions of equivalence are deﬁned using the semantics with
the same principle as in a relational model, that is, that two terms are identiﬁed whenever
no observer can notice any diﬀerence between their external behaviours. Varying how the
environment interacts with a process leads to a multitude of potential reﬁnement relations,
e.g., traces, failures, readiness, failure traces; an overview is provided by van Glabbeek in
[338, 337]. Here we will just consider a small number of the possible relations. To begin we
use the usual notation for labelled transition systems:
Deﬁnition 10.4 (Labelled Transition System).
A labelled transition system (LTS) is a tuple (States, Act, T, Init) where States is a non-
empty set of states, such that Init ⊆States is the set of initial states, Act is a set of
action(-label)s, and T ⊆States × Act × States is called the transition relation.
2
Additional notation needed includes the usual one for transitions: p
a
−→q for (p, a, q) ∈T
and the extension of this to traces (written p
tr
−→q) and the set of enabled actions of a
process which is deﬁned as: next(p) = {a ∈Act | ∃q • p
a
−→q}. Further, σ ∈Act∗is a
trace of a process p if ∃q • p
σ
−→q, which we also write as p
σ
−→. The set of traces of p is
denoted T (p). Finally, (σ, X) ∈Act∗× P(Act) is a failure of a process p if there is a process
q such that p
σ
−→q, and next(q) ∩X = ∅. The set of failures of p is denoted F(p).
10.3
Using a Partial Framework to Embed Concurrent Reﬁnement
Relations
Given two frameworks such as the partial relational model and the process algebraic
semantics, and the variety of reﬁnement relations that follow, the natural question to ask is
how do they relate? To answer that, the work initiated in [104], and followed on in [60, 106],
described a methodology to relate the two approaches. That work used the total and partial
frameworks to embed each reﬁnement relation and derive corresponding simulation rules.
In this set-up, we consider original data types (e.g., using Z data types to specify LTSs in
an obvious way) to which we give a concurrency reﬁnement semantics – but we then aim to
check this reﬁnement relation within the relational framework. This works in a number of
steps:

146
From Action Systems to Distributed Systems: The Reﬁnement Approach
1. Deﬁne a relational data type with a state that contains suﬃcient information to encode
the data type’s subsequent behaviours (enabled operations), as well as any observations
that may need to be made, through its ﬁnalisation operation. The choice of ﬁnalisation
(and its target type, i.e., the global state) is taken so that we observe the characteristics
of interest.
2. Describe how the relevant LTS observation is made directly from the original data
type and its programs. For example, for trace reﬁnement what denotes traces in the
data type.
3. Prove that the induced notion of reﬁnement from inclusion between sets of these
observations is equivalent to data reﬁnement on the relational embedding constructed
in step 1.
4. Extract a characterisation of this particular reﬁnement relation as simulation rules on
the operations (etc.) of the data type.
The simulation conditions that are derived are, by construction, guaranteed to provide
a sound proof method for the given notion of reﬁnement; however, their joint completeness
in general requires a separate proof – see [59] for a detailed discussion and an example.
In general there are two parameters that one can use to vary the embedding. First, there
is the framework itself, does one use partial or total relations, and if the latter how are
partial operations (e.g., a Z operation with a precondition that is not total) embedded as
total relations? In particular, this gives rise to diﬀering encodings. Second, what observa-
tions are made, and in a relational framework this is given by the choice of ﬁnalisation.
In previous work we have considered both questions together, and encoded each process
algebraic relation in an appropriate framework. Sometimes, however, multiple choices are
appropriate, and here we are particularly interested in the tension between using a partial
and total framework. We begin by illustrating the approach with two reﬁnement relations,
trace and failure preorder, in a setup that does not consider divergence.
10.3.1
Basic Relations without Divergence
The simplest reﬁnement relation of interest is the trace preorder:
Deﬁnition 10.5 (Trace preorder). The trace preorder is deﬁned by p ⊑tr q iﬀT (q) ⊆T (p).
2
As observed in [104] the partial relations model records exactly trace information for
the embedding with a trivial ﬁnalisation: possible traces lead to the single global value;
impossible traces have no relational image. Thus in a partial model there is no need to
record additional observations, and we can use the following embedding. Detail on Z data
types is omitted here (see [105]), note that their initialisations are sets of initial states rather
than relations, and they have no explicit ﬁnalisations. In the deﬁnition below, θState returns
the bindings of State, i.e., the elements of the relevant schema type, see [105].
Deﬁnition 10.6 (Trace embedding).
The trace embedding of a Z data type (State, Init, {Opi}i∈J) is given by (State, Init, {Opi}i∈J,
Fin), where G == {∗} and State == State:
Init == G × {Init • θState′}
Op == {Op • θState 7→θState′}
Fin == State × G

Relational Concurrent Reﬁnement - Partial and Total Frameworks
147
We denote the trace embedding of a Z data type A by A |tr.
2
The second step in the process is to deﬁne the traces of a Z abstract data type. This is
simply each sequence of operations (each program) which does not have an empty semantics.
Then we need to prove that inclusion on these corresponds exactly on data reﬁnement on
the trace embedding.
Deﬁnition 10.7. For a Z data type A = (State, Init, {Opi}i∈J) its set of traces T (A) is
deﬁned as all sequences ⟨i1, . . . , in⟩such that ∃State′ • Init o
9 Opi1
o
9 . . . o
9 Opin.
2
Theorem 10.1. For Z data types A and C , A |tr⊑data C |tr iﬀT (C) ⊆T (A).
2
Using this embedding one can then derive simulation rules that correspond to this re-
ﬁnement notion (here: traces), see [106]. We give them as they would appear written in the
Z schema calculus. They are, in fact, the standard rules for Z reﬁnement but without the
constraint on applicability of operations. These are used also in Event-B [6], based on ideas
from action systems [37].
Deﬁnition 10.8 (Trace simulations).
Given Z data types A and C, the relation R on AState∧CState is a trace downward simulation
from A to C if
∀CState′ • CInit ⇒∃AState′ • AInit ∧R′
∀i ∈J • ∀AState;CState;CState′ • R ∧COpi ⇒∃AState′ • R′ ∧AOpi
The total relation T on AState ∧CState is a trace upward simulation from A to C if
∀AState′;CState′ • CInit ∧T ′ ⇒AInit
∀i:J • ∀AState′;CState;CState′ •
(COpi ∧T ′) ⇒(∃AState • T ∧AOpi)
2
The trace embedding needed a trivial ﬁnalisation in the partial framework. For a reﬁne-
ment relation such as the failure preorder, one needs to observe more and hence needs a
more complex ﬁnalisation. First the deﬁnition of the preorder itself:
Deﬁnition 10.9. The failures preorder, ⊑f , is deﬁned by p ⊑f q iﬀF(q) ⊆F(p).
2
The embedding into the partial relations model is still fairly simple, we take the ﬁnalisation
to observe a set E which is (any subset of) the set of all refused events {i:J | ¬ pre Opi}:
Deﬁnition 10.10 (Failures embedding).
The failures embedding of a Z data type (State, Init, {Opi}i∈J), is A |f = (State, Init, {Opi}i∈J,
Fin), where G == P J and State == State, and
Init == G × {Init • θState′}
Op == {Op • θState 7→θState′}
Fin == {State;E: P J | (∀i ∈E • ¬ pre Opi) • θState 7→E}
2
In the relational embedding failures are pairs (tr, X), where tr is a trace, and there exists
states (State, State′) ∈tr (with State being initial) such that ∀i:X • State′ ̸∈dom Opi.
Theorem 10.2. With the failures embedding, data reﬁnement corresponds to the failures
preorder: A |f ⊑C |f iﬀF(C) ⊆F(A).
2

148
From Action Systems to Distributed Systems: The Reﬁnement Approach
Given the failures embedding the changes to the simulation conditions are as follows (see
[106]):
Downward simulations: R o
9 CFin ⊆AFin is equivalent to
∀i:J;AState;CState • R ∧pre AOpi ⇒pre COpi
Upward simulations: CFin ⊆T o
9 AFin is equivalent to
∀CState • ∃AState • ∀i:J • T ∧(pre AOpi ⇒pre COpi)
In the ﬁrst work on relating concurrent and relational reﬁnement relations [104, 60], this
preorder was embedded into the total relational model. Lemma 3 in [60] suggested this was
not necessary. Hence in later work a partial relations model was used.
10.3.2
Internal Events and Divergence
So far the partial relational framework has been suﬃcient to model our diﬀerent con-
current reﬁnement relations. However, when we extend the framework to model aspects of
internal events, one naturally needs to consider divergence, and this is where totalisations
(and other encodings) start to be necessary.
First, there is an easy extension of the trace reﬁnement embedding to one that in-
cludes internal events, but does not consider inﬁnitely enabled internal behaviour (livelock)
a problem. We deﬁne a data type extended to include an internal operation, and give a ﬁrst
interpretation of that as a standard data type; reﬁnement is then inherited through that
interpretation.
Deﬁnition 10.11 (i-data type; embedding as a data type (no livelock)). An i-data
type is an extension of the data type of Deﬁnition 10.1 with an additional component
i ⊆State × State. The i-data type D = (State, G, Init, {Opk}k∈J, i, Fin) is embedded as the
data type bD = (State, G, c
Init, {d
Opk}k∈J, Fin) where c
Op = Op o
9 i∗and c
Init = Init o
9 i∗.
2
The simulation rules deriving from this are those of Deﬁnition 10.3 with ﬁnite internal
behaviour inserted after all occurrences of operations and initialisation. In the absence of
(observed) divergence, joint completeness of the simulations follows from joint completeness
of the partial relations simulations, plus the fact that the data type with internal operations
is reﬁnement equivalent to its embedding as in Deﬁnition 10.11, see also [105] for the latter
point.
However, for a reﬁnement relation that does not ignore divergence, the interpretation
of the i-data type needs to ensure the correct observations are made when the ﬁnal state
records diverge. In the case of catastrophic interpretations (i.e., ones where divergence is
propagated to all further behaviours) the embeddings need to generate arbitrary behaviour
from the point of divergence onwards, and propagate this into all subsequent operations.
As usual in such encodings, we use an additional value, assumed not to be included in
any local or global state space. For any set S, let Sω = S ∪{ω}.
The trace reﬁnement relation just given ignores divergence, and thus is diﬀerent from
trace inclusion in the CSP failures-divergences model. An interpretation of i-data types to
encode CSP trace reﬁnement is a simpliﬁcation of the failures-divergences embedding [60],
as follows.

Relational Concurrent Reﬁnement - Partial and Total Frameworks
149
Deﬁnition 10.12 (Embedding trace reﬁnement (CSP model)).
An i-data type D = (State, G, Init, {Opk}k∈J, i, Fin) is embedded as the data type bD =
(Stateω, G, c
Init, {d
Opk}k∈J}, c
Fin) where
c
Init = Init o
9 i∗∪if divi Init then G × Stateω
c
Op = Op o
9 i∗∪divOp × Stateω
c
Fin = Fin ∪{ω} × G
divOp =def {s:State | ∃s′:State • (s, s′) ∈Op ∧s′
i∞
−→}
divi Init =def ∃s: ran Init • s
i∞
−→
2
Using this interpretation we can once again derive simulation rules, which do contain
some modiﬁcations to account for potential divergence including at initialisation.
Deﬁnition 10.13 (Simulation for trace reﬁnement (CSP model)).
The relation R between AState and CState is a downward simulation between i-data types
A and C iﬀ∀k:J:
if divi CInit then divi AInit else CInit o
9 i∗
C ⊆AInit o
9 i∗
A
o
9 R
R o
9 CFin ⊆AFin
(divAOpk) −◁R o
9 COpk
o
9 i∗
C ⊆AOpk
o
9 i∗
A
o
9 R
dom(R ▷divCOpk) ⊆divAOpk
2
10.4
A Total Relational Framework
So far our relational framework has been one of partial relations. However, the last section
is moving us towards a total framework, where additional values are used to represent aspects
that one wants to additionally observe. So why not go the whole way? Indeed in a partial
model the natural encoding of particular programmes being “impossible”, e.g., leading to a
deadlock, is through the empty relation. If non-deterministic choice is represented as union of
relations, the choice ends up hiding the possibility of a deadlock. This may not be desirable,
e.g., for a ﬁnal implementation.
Of course the partial relational model can solve this by making more detailed observations
at the end of a program, but it may be simpler to use a total relational framework. In this
model error behaviour is now encoded explicitly in operations. Many such encodings increase
operations’ domains to become total, however sometimes we also use them just to augment
partial relations.
When turning a partial model into a total one, there are two types of totalising encodings
used: the blocking (or strict) totalisation maps error behaviour only to a “sink” state; the
non-blocking (or non-strict, or chaotic) totalisation in addition maps it to all possible normal
outcomes.
These totalisations use the distinguished value ⊥not in S, and the extended state is
denoted S⊥.

150
From Action Systems to Distributed Systems: The Reﬁnement Approach
Deﬁnition 10.14 (Totalisation).
Let
Op
be
a
partial
relation
on
State.
Its
non-blocking
and
blocking
totalisa-
tions
are
total
relations
on
State⊥,
denoted
c
Op
nb
and
c
Op
b
respectively,
where
c
Op
nb == Op ∪{x, y:State⊥| x ̸∈dom Op • (x, y)}, and
c
Op
b == Op ∪{x:State⊥| x ̸∈dom Op • (x, ⊥)}.
2
With totalisations like these, a similar procedure to that described above can be used to
extract simulation rules on the underlying data type. Indeed, although most embedding of
concurrent reﬁnement relations can be made directly into the partial relation model, histor-
ically, the work on embedding concurrent reﬁnement relations began by using a framework
of total relations.
At ﬁrst sight, the total relational framework looks strictly more expressive than the
partial model. However, the partial framework turns out to be necessary to embed concurrent
reﬁnement relations based on ready sets.
The readiness model, as proposed by Olderog and Hoare [255], does not record the failures
of a process but its “ready sets” which contain events that the process is able to engage in.
Thus (t, Y ) is a ready set of a process P if t is a trace of P and ∃Q • P
t
−→Q ∧∀e ∈Y •
Q
e
−→. Readiness reﬁnement is taken to be inclusion of the ready sets.
The readiness model can be coded in the relational context by taking the set of events
observed at ﬁnalisation E to be the set of events that are enabled instead of refused. However,
to do it is necessary to use the partial relational framework as the readiness model deals not
with events that can be refused, as did the failures model, but with events that are enabled.
Thus the aspects we wish to make observable in the ﬁnalisation must be concerned with
just the enabled events. Taking E to be the set of events that are enabled instead of refused
seems to achieve this. However, the totalisation of a partial relation (in the blocking model)
maps the areas where operations were refused to ⊥, and this gets percolated through to the
ﬁnalisation. That is, the outcome of a program run will sometimes be ⊥which represents
the observation of a certain amount of refusals.
This observation is suﬃcient to deny the correspondence between readiness reﬁnement
and the total relational embedding. It is worth noting that this is due to the artiﬁcial
nature of the totalisation: it has included observations that are simply not observed via a
ﬁnalisation that really only looks at enabled events. However, in a partial model there is no
issue in setting the ﬁnalisation to be the set of events that are enabled, and [104] details the
simulation rules that are derived.
So, should one always use the partial relational framework? Well, no, as we have seen the
totalised framework is useful (and sometimes needed!) when incorporating divergence into
the model. Although we extended the partial framework with divergence in Section 10.3.2,
in some cases we need even more information in the model than that described above.
10.5
A General Framework for Simulations - Process Data Types
Indeed, the two approaches of partial or totalised relations are not exclusive. Languages
such as B [5] have both preconditions and guards, and some speciﬁcation languages include
both situations that lead to divergence and situations that lead to deadlock. For example, in

Free ebooks ==>   www.Ebook777.com
Relational Concurrent Reﬁnement - Partial and Total Frameworks
151
our treatment of internal operations in [107], and in process algebraic contexts, both occur
– livelock causes divergence, and deadlocks may arise from synchronising actions that are
not enabled.
Representing two kinds of exceptional situations cannot be done using only relations of
the kinds described so far. Alternative approaches might be through predicate transform-
ers, relations over sets, or by including extra sets alongside relations. Here we consider an
approach, called process data types which essentially applies two encodings in sequence: one
to account for deadlock, and another to account for livelock.
Such a model contains essential design decisions on the relative ordering of the diﬀerent
kinds of erroneous behaviours: what observations should be possible when the semantics
leads to a non-deterministic choice between normal, divergent, and blocking behaviour?
If our encodings lead to potentially partial relations, a fairly natural choice in this con-
tains three kinds of non-standard behaviour. One of them is a zero of non-deterministic
choice, one of them is a unit of choice, and the third is neither. The zero represents an
“error” whose possible occurrence hides all other behaviour; the unit represents an “error”
whose possible occurrence is hidden by other behaviour, and only for the third type we can
identify both possible and certain occurrence of it.
The “zero” is “chaotic” divergence as in CSP: it can also be viewed as representing the
union of all possible behaviour with something even worse. The unit of non-deterministic
choice is empty behaviour – this then also allows us to model choice as union of relations.
The ﬁnal kind of error is “deadlock” or “blocking”, as an explicitly observed behaviour,
consistent with CSP’s observation of refusals. This set up allows us to record what happens
to operations outside their domain in each of the three possible ways: blocking, non-blocking
divergent, or absent behaviour.
Together this ﬁxes the outcomes of choice between the diﬀerent types of behaviour. The
choice between divergence and anything else (including blocking) is divergence – as it is a
zero. The choice between a behaviour and empty is that behaviour – as it is a unit. The
choice between any type of behaviour and itself is that behaviour too. An extra category is
then “possible deadlock”.
These decisions are summarised in the table below; as before, ⊥represents blocking, and
ω represents divergence. Choice is modelled as union of sets.
Choice
n
ω
⊥
p⊥
∅
model
normal
n
n
ω
p⊥
p⊥
n
subsets of State
divergence
ω
ω
ω
ω
ω
ω
State ∪{⊥, ω}
deadlock
⊥
p⊥
ω
⊥
p⊥
⊥
{⊥}
possible deadlock
p⊥
p⊥
ω
p⊥
p⊥
p⊥
subsets of State⊥
empty
∅
n
ω
⊥
p⊥
∅
∅
Process data types, discussed below, allow us to derive reﬁnement rules directly for any
formalism which gives rise to both kinds of errors once the areas of divergence and blocking
have been made explicit. The area of empty behaviour is implicitly characterised.
Deﬁnition 10.15 (Process data type).
A process data type is a tuple (State, Inits, {Opi}i∈J, Fin) such that Inits is a subset of State;
every operation {Opi} is a triple (N, B, D) such that dom N, D, and B are disjoint subsets of
State; Fin is a relation from State to G.
2
Operations are split into three parts. When Op = (N, B, D) the normal eﬀect of Op is
www.Ebook777.com

152
From Action Systems to Distributed Systems: The Reﬁnement Approach
q
q
q
-
PPPPPP
q
PPPPPP
q q
q


τ
6
q
q
q
q
q
-
PPPPPP
q
PPPPPP
q
p p p p p p p p p p p p p p p p p p
-
p p p p p p p p p p p p p p p p p p
P
q q
⊥
⊥
⊥
⊥
ω
ω
q
q
q


τ
6
q
q
q
q
q
p p p p p p p p p p p p p p p p p p
-
p p p p p p p p p p p p p p p p p p
P
q
-
PPPPPP
q
PPPPPP
q


τ
6
q
q
q
q
q
p p p p p p p p p p p p p p p p p p p
p p p p p p p p p p p p p p p p p p p
p p p p p p p p p p p p p p p p p p p
p p p p p p p p p p p p p p p p p p p
p p p p p p p p p p p p p p p p p p p
p p p p p p p p p p p p p p p p p p p
p p p p p p p p p p p p p p p p p p p
p p p p p p p p p p p p p p p p p p p
Figure 10.1: [60] The original Op, and a divergent after-state; with B⊥× {⊥} added; ﬁnally
also with Dω × Stateω ∪{(ω, ⊥)}.
given by the relation N. The sets B and D describe areas from where the operation would
lead to blocking and divergence, respectively. If the three sets form a partition, that excludes
certain situations, such as miracles and possible (as opposed to certain) deadlock from a given
state. This also ensures that (using ⊥and ω) it can be represented by a total data type. It
is still possible for a trace to lead to possible deadlock, namely when some but not all of the
states it leads to exhibit a deadlock.
This properly generalises the blocking and non-blocking totalisations, namely:
• the blocking operation Op is represented by (Op, dom Op, ∅), i.e., it never diverges,
and blocks in the complement of the operation’s domain;
• the non-blocking operation Op is represented by (Op, ∅, dom Op), i.e., it diverges in
the complement of the operation’s domain, but never blocks.
In the embedding below, which translates process data types into total data types, we
will use state spaces enhanced with special values as before – now also using a third value
“no” to represent the impossibility of making an observation in a ﬁnal state.
Deﬁnition 10.16 (Embedding process data types).
For any set State, let State⊥,ω,no == State ∪{⊥, ω, no}, and similarly for sets subscripted
with subsets of these special values.
A process data type (State, Inits, {(Ni, Bi, Di)}i∈J, Fin) with global state G is embedded
into the total data type (State⊥,ω, Init, {[[Op]]i}i∈J, [[Fin]]) where
Init == G⊥,ω,no × Inits
[[(N, B, D)]] == N ∪(B⊥,ω × {⊥}) ∪(Dω × Stateω)
[[Fin]] == Fin ∪(dom Fin × {no}) ∪{(⊥, ⊥)} ∪{ω} × Gω,no
2
The process data type has a set of initial states, each of which gets related to every global
state. Operations are embedded in line with the explanation above: as a union of normal
behaviour and behaviour representing blocking and divergence from the respective sets.
Finalisation makes both blocking and divergence visible globally. Figure 10.1 [60] illustrates
this operation embedding.
Now we can turn the handle on the reﬁnement derivation machine again. Given two
process data types, we construct their total data type embeddings, apply the simulation
rules for total data types, and then simplify. In particular, any reference to the artiﬁcial

Relational Concurrent Reﬁnement - Partial and Total Frameworks
153
values should be eliminated in this simpliﬁcation step. This then leads to sound simulation
rules for process data types.
Those for downward simulation on process data types come out as follows. The relation
R between AState and CState is a downward simulation between the process data types
(AState, AInits, {AOpi}i∈J, AFin) and (CState, CInits, {COpi}i∈J, CFin), iﬀ
CInits ⊆ran(AInits ◁R)
R o
9 CFin ⊆AFin
(dom AFin) ◁R = R ▷(dom CFin)
and ∀i:J, for AOpi = (AN, AB, AD), COpi = (CN, CB, CD)
AD −◁R o
9 CN ⊆AN o
9 R
dom(R ▷CB) ⊆AB
dom(R ▷CD) ⊆AD
As one might have expected, there are no changes in the initialisation and ﬁnalisation
rules. For operation, “correctness” is modiﬁed only to constrain to non-divergent abstract
states. The other two rules are reﬂections of “applicability”, generalising it separately for
blocking and non-blocking interpretations of partial operations.
Second, the conditions for upward simulation for process data types. The relation T is
an upward simulation between the process data types (AState, AInits, {AOpi}i∈J, AFin) and
(CState, CInits, {COpi}i∈J, CFin), iﬀ
ran(CInits ◁T) ⊆AInits
CFin ⊆T o
9 AFin
dom CFin ⊆dom(T −▷dom AFin)
and ∀i:J, for AOpi = (AN, AB, AD), COpi = (CN, CB, CD)
dom(T ▷AD) −◁CN o
9 T ⊆T o
9 AN
CB ⊆dom(T ▷AB)
CD ⊆dom(T ▷AD)
The comparison with “normal” rules is similar here to the downward simulation sce-
nario. Initialisation is essentially the same, apart from describing sets rather than relations.
Finalisation conditions account for partiality of ﬁnalisation. If we used process data types
to embed a refusal semantics [60], correctness of ﬁnalisation (“are we making the correct
observations at the end?") is the only rule signiﬁcantly aﬀected. The property (see [105])
that ﬁnalisation conditions resulting from an output embedding are trivially satisﬁed for
downward simulation (and thus Z rules do not need to mention it) also transfers across.
10.6
Conclusions
As we have seen, it is possible to embed concurrent reﬁnement relations into relational
models in a natural fashion, and derive simulation rules for those reﬁnement relations as a

154
From Action Systems to Distributed Systems: The Reﬁnement Approach
consequence. The two parameters that we varied in the embeddings used were the observa-
tions made by a ﬁnalisation, and the relational model – speciﬁcally additional values used
in encodings.
The technical details of the deﬁnitions and results of some of the above work is given in
more detail in [104, 60, 106]. Our focus here in this chapter though has been the relationship
between the two relational models, and we have discussed how in general aspects of both
are needed. This resulted in the deﬁnition of a process data type. Of particular relevance to
our discussion here is the use of the partial model, and [106] contains further applications
of this to, for example, notions of reﬁnement in automata. A fuller discussion on modelling
divergence is given in [58].
A notable absence in our discussion given above is the modelling of input and output.
Surprisingly they (or more speciﬁcally the inclusion of outputs) add considerable complexity
to the embeddings used in relational reﬁnement modelling – and the full simulation rules
are consequently complex depending on the exact model of outputs used. Further details of
the subtleties involved are given in [60].

Chapter 11
Reﬁnement of Behavioural Models for
Variability Description
Alessandro Fantechi
Dipartimento di Ingegneria dell’Informazione, Università di Firenze, and ISTI–CNR
Stefania Gnesi
ISTI–CNR
11.1
Introduction ......................................................
155
11.2
Running Example and Background .............................
156
11.2.1
Labelled Transition Systems ............................
157
11.3
Behavioural Models and Variability .............................
158
11.3.1
MTS: Modal Transition Systems ........................
159
11.3.2
DMTS ...................................................
160
11.3.3
1MTS ....................................................
161
11.3.4
Generalised Extended Modal Transition Systems .......
164
11.4
A Comparison on the Expressiveness ............................
168
11.5
Conclusions .......................................................
169
11.6
Acknowledgments ................................................
169
Abstract. In Product Lines Engineering many studies are focused on the research of the
best behavioural model useful to describe a product family and to reason about properties
of the family itself. In addition the model must allow to describe in a simple way diﬀerent
types of variability needed to characterize several products of the family. Modal Transi-
tion System (MTS) is one of the more relevant behavioural models that has been broadly
studied in literature and several extensions have been also described to more ﬁnely address
behavioural variability. Furthermore MTS and its extensions deﬁne a concept of reﬁnement
which represents a step of design process, namely a step where some allowed requirements
are discarded and other ones become necessary. In this chapter we present a bunch of vari-
ants of the classic MTS deﬁnition with the associated reﬁnement deﬁnitions and a discussion
on their expressive power.
11.1
Introduction
Product Lines or Families represent a new paradigm widely used to collectively describe
products of a company that share similar functionality and requirements, in order to im-
155

156
From Action Systems to Distributed Systems: The Reﬁnement Approach
prove development eﬃciency and productivity [84, 267]. In this context many studies are
focused on the search of the best behavioural models useful to describe a product family
and to reason about properties of the family itself. In addition the model must allow to de-
scribe in a simple way diﬀerent types of variability, needed to characterize several products
of the family. One of these models are the Modal Transition Systems (MTSs) introduced
by Larsen and Thomsen in [219]. They are an extension of the Labelled Transition Systems
(LTSs) [200], and introduce two types of transitions useful to describe the necessary and al-
lowed requirements, typical of product lines speciﬁcations, by distinguishing transitions that
must (mandatory transitions) be done from those that may (optional transitions) be done.
These models have been broadly studied as a possible means to express behavioural vari-
ability [132, 218, 130, 19, 20], and several extensions have been described. These extensions
follow diﬀerent approaches which entail the introduction of more complex and expressive
requirements.
In this paper we review a bunch of variants of the classic MTSs deﬁnition, that have
been proposed in the literature to more ﬁnely address behavioural variability discussing
their expressive power. The discussed variants include Disjunctive Modal Transition Sys-
tems (DMTS) [220], where a must transition can be substituted by a must hypertransition,
that is a set of transitions, and its semantics requires that at least one of these transitions
has to be present in any element of the family. Another variant is 1-selecting modal transi-
tion system (1MTS) deﬁned in [131] which modiﬁes the semantics of must hypertransition
transforming the disjunctive choice in an exclusive choice: for every set of transitions related
to a hypertransition one and only one transition has to be present in any element of the
family. In [130] a generalization of DMTS and 1MTS was deﬁned as Generalized Extension
Modal Transition System (GEMTS), which introduces two new types of hypertransitions,
described by means of 3 and 2 , which allow to choose among "at most k of n" transitions
for 3 and "at least k of n" transitions for 2.
Furthermore MTS and its extensions allow a concept of reﬁnement to be deﬁned. It repre-
sents a step of design process, namely a step where some allowed requirements are discarded
and other ones become necessary. In this way when we say N is a reﬁnement of M, we mean
that N is a model derived by M removing some optional transitions and/or changing some
optional transitions into mandatory ones. A reﬁnement step therefore models the decision
of ﬁxing some optionality in the family description. Hence reﬁnement can be used to restrict
the variability exhibited by a family in order to derive from it subfamilies or products. When
no more variability remains we call the model an implementation.
The paper is organized as follows. In Section 11.2 we introduce a running example and
some preliminary deﬁnitions. In Section 11.3 we present the variants of MTSs together with
the associated reﬁnements relations, while in Section 11.4 we compare their expressiveness.
Our conclusions are presented in Section 11.5.
11.2
Running Example and Background
We will use in this paper the running example from [19, 20]. It describes a family of
(simpliﬁed) coﬀee machines through the following list of requirements:
1. A vending machine is activated by a coin. The only accepted coins are the one euro

Reﬁnement of Behavioural Models for Variability Description
157
coin for European products and the one dollar coin for Canadian products. Only one
kind of coin is accepted.
2. After inserting a coin, the user has to choose whether (s)he wants sugar, after which
(s)he may select a beverage;
3. The choice of beverage (coﬀee, tea, cappuccino) varies, but coﬀee must be oﬀered by
all products of the family;
4. Optionally, a ringtone may be rung after delivering a beverage;
5. After the beverage is taken, the machine returns idle.
As we can see, these requirements describe a set of possible, partially diﬀerent products
and we can divide them in two large categories: Canadian products and European products.
Moreover each category has several possible products choosing the diﬀerent alternatives.
11.2.1
Labelled Transition Systems
Deﬁnition 11.1 (LTS). A Labelled Transition System (LTS) is a 4-tuple (Q, A, q, δ), with
set Q of states, set A of actions, initial state q ∈Q, and transition relation δ ⊆Q × A × Q.
If (q, a, q′) ∈δ, then we also write q
a−→q′.
When modelling the behaviour of a product as an LTS, products of a family are consid-
ered to diﬀer for the actions that they are able to perform at any given state; this means that
the deﬁnition of a family has to accommodate all the possibilities desired for each derivable
product, predicating on the choices that keep a product belonging to the family.
We can build an LTS representing all the possible behaviours conceived for the family
of our running example as that represented in Figure 11.1.
We can notice that the given LTS cannot distinguish mandatory transitions from optional
ones since variation points in the family deﬁnition are modeled as nondeterministic choices
(i.e., alternative branches) independently from the type of variability.
The proposed example has indeed three variation points (namely, the choice of the coins,
the choice among provided drinks, and the optional alert tone) which are:
- the ﬁrst, alternative, that is, the two coin transitions cannot be present together in any
product, but one should be present;
- the second and third optional, that is, the transitions may or may not be present in any
product.
Starting from the LTS describing the family, a set of LTSs representing possible products
may be derived. The derivation of a product will amount to choose some alternative branches
from any node of an LTS, while removing the others. Removing branches from an LTS L
produces an LTS L′ such that L simulates L′, according to the following deﬁnition [245].
Deﬁnition 11.2. Let L = (Q, A, q, δ) and L′ = (Q′, A, q′, δ′) We say that q ∈Q simulates
q′ ∈Q′ if there exists a simulation that relates q and q′.
R ⊆Q × Q′ is a simulation if ∀(q, q′) ∈R
• (q, a, q1) ∈δ implies ∃q′
1:(q′, a, q′
1) ∈δ′ and (q1, q′
1) ∈R.
The above deﬁnition is naturally extended to LTSs by considering their initial states: an LTS
L simulates L′ iﬀq simulates q′.

158
From Action Systems to Distributed Systems: The Reﬁnement Approach
Figure 11.1: Modelling a product family with an LTS
Since an LTS cannot distinguish required transitions from optional ones not all LTS sim-
ulated by the one expressing the family are correct products of the family. Hence simulation
between LTSs is a too coarse relation to express the reﬁnement of a family in a subfamily.
11.3
Behavioural Models and Variability
In this section we introduce several frameworks developed to describe a speciﬁcation with
variability, more expressive than the LTSs seen in Section 11.2.1, so that they can properly
distinguish mandatory from optional transitions. The models diﬀer for their expressive power
with respect to the type of variation points, that is, to their ability of expressing alterna-
tive transitions or more complex schemes of variability. Even though a categorization of
these models has never been made, we can see easily some common characteristic in their
deﬁnition:
1. every model is a particular type or an extension of transition systems.
2. some models adopt the modal operators 2 "necessity" and 3 "possibility": we could
call the set of these models as Modal Family.
3. some models in the Modal Family introduce the hypertransition concept, that is a
transition described by a pair (q, T) where q is a source state and T is a set of pairs
(l, q′) where l is a label and q′ is a possible target state.

Reﬁnement of Behavioural Models for Variability Description
159
11.3.1
MTS: Modal Transition Systems
In [219] Larsen and Thomsen introduced a new formalism: the Modal Transition System.
They noted that the LTS formalism is expressively too poor in order to provide a convenient
speciﬁcation. In eﬀect, any speciﬁcation deﬁned through an LTS will limit the possible
implementations to a single (behavioural) equivalence class. We would like to describe by
a speciﬁcation a wide collection of (possibly inequivalent) implementations and, exploiting
some suitable techniques, this collection should be constantly reduced during the design
process, in order to eventually determine a single implementation. It becomes clear that
LTSs are not expressive enough for this task.
Deﬁnition
11.3
(MTS
[219]). A
Modal
Transition
System
(MTS)
is
a
5-tuple
(Q, A, q, δ3, δ2), with underlying LTS (Q, A, q, δ3∪δ2). An MTS has two distinct transition
relations: δ3 ⊆Q × A × Q is the may transition relation, expressing possible transitions,
while δ2 ⊆Q × A × Q is the must transition relation, expressing mandatory transitions. By
deﬁnition, δ2 ⊆δ3.
If (q, a, q′) ∈δ3, then we also write q
a−→3 q′ and likewise we also write q
a−→2 q′ for
(q, a, q′) ∈δ2.
Note that an LTS is an MTS where the two transition relations δ2 and δ3 coincide.
An MTS provides an abstract description of a product family’s set of products [132,
218, 130, 19, 20]. The products diﬀer w.r.t. the actions they can perform in any given state:
the MTS must allow all possibilities desired for each derivable valid product, aﬃrming the
choices that make a product belong to the family.
The MTS depicted in Figure 11.2, in which dashed arcs are used for the may transitions
that are not must transitions (δ3\δ2) and solid ones for must transitions (δ2), is an attempt
to model all possible behaviours conceived for the family of coﬀee machines described in
Section 11.2.
Note that an MTS is thus able to model the constraints concerning optional and manda-
tory features (by means of may and must transitions). However, no MTS is able to model
the constraint that 1e and 1$ are exclusive nor that a cappuccino is not oﬀered in Canadian
products. We now make this claim somewhat clearer by deﬁning how to generate products
(LTSs) from a product family (MTS). This concept is formalized by the notion of reﬁnement:
Deﬁnition 11.4 (Reﬁnement [219]). An MTS Fp = (Qp, A, qp, δ3
p , δ2
p ) is a reﬁnement of
an MTS F = (Q, A, q, δ3, δ2), denoted by F ⪯Fp, if and only if there exists a reﬁnement
relation R ⊆Q × Qp such that (q, qp) ∈R and for any a ∈A and for all (q, qp) ∈R, the
following holds:
1. whenever q
a−→2 q′, for some q′ ∈Q, then ∃q′
p ∈Qp:qp
a−→2 q′
p and (q′, q′
p) ∈R, and
2. whenever qp
a−→3 q′
p, for some q′
p ∈Qp, then ∃q′ ∈Q:q
a−→3 q′ and (q′, q′
p) ∈R.
Of course a straightforward generalization allows us to compare states from diﬀerent
MTSs.
Moreover if q ⪯q′, where q and q′ are the initial states of L and M respectively and L
is an LTS and M is an MTS then we will say that L is an implementation (or a product)
of M.
From the MTS in Figure 11.2, the derivation of products (LTSs), including the Euro-
pean and Canadian coﬀee machines of Figures 11.3(a) and 11.3(b), is possible using Deﬁni-
tion 11.4. Note, however, that also the derivation of the LTS of Figure 11.1 is possible by

160
From Action Systems to Distributed Systems: The Reﬁnement Approach
Figure 11.2: MTS modelling the family of coﬀee machines.
Deﬁnition 11.4, but the product it models violates the constraints of requirements 1 and 3
(cf. Section 11.2) by allowing the insertion of 1e and 1$ and oﬀering cappuccino.
(a) LTS modelling a European coﬀee machine.
(b) LTS modelling a Canadian coﬀee machine.
Figure 11.3: (a)-(b) LTS modelling some correct products.

Reﬁnement of Behavioural Models for Variability Description
161
11.3.2
DMTS
Sometimes in the modelling of a product-line we would like to say "taken a set of possible
features, at least one of them must be present in our products". Unfortunately, we cannot
handle this situation using MTSs but the DMTS formalism resolves this problem. The
DMTS, introduced in [220, 51], extends the MTS formalism: the type of must transition is
modiﬁed from transition to hypertransition, whereas the may transitions are unchanged.
Deﬁnition 11.5 (DMTS [220]). A Disjunctive Modal Transition System (DMTS) is a 5-
tuple (Q, A, q, δ3, δ2), with set Q of states, set A of actions, initial state q ∈Q, and two
distinct transition relations: δ3 ⊆Q × A × Q is the may transition relation and δ2 ⊆
Q × P(A × Q) is the must hypertransition relation.
Intuitively, q −→2 U, with U ⊆A × Q may be understood as W
(a,q′)∈U q
a−→2 q′.
In contrast to MTS, DMTS allows us to deﬁne an inconsistent speciﬁcation by the expression
q −→2 ∅. From now on we implicitly rule out this situation, by assuming that no transition
of the form q −→2 ∅is allowed.
The next step is to introduce the reﬁnement relation for DMTS:
Deﬁnition 11.6 (DMTS reﬁnement). A DMTS Fp = (Qp, A, qp, δ3
p , δ2
p ) is a reﬁnement of
a DMTS F = (Q, A, q, δ3, δ2), denoted by F ⪯Fp, if and only if there exists a reﬁnement
relation R ⊆Q × Qp such that (q, qp) ∈R and for any a ∈A and for all (q, qp) ∈R, the
following holds:
1. whenever q −→2 V , for some V ⊆A×Q, then ∃U ⊆A×Q: ∀(a, q′) ∈V , ∃(a, q′
p) ∈U
and (q′, q′
p) ∈R, and
2. whenever qp
a−→3 q′
p, for some q′
p ∈Qp, then ∃q′ ∈Q:q
a−→3 q′ and (q′, q′
p) ∈R.
As in the MTS case, a straightforward generalization allows us to compare states from
diﬀerent DMTSs, moreover if q ⪯q′, where q and q′ are respectively the initial states of an
LTS L and of a DMTS M, then we may say that L is an implementation of M.
Example 11.1. Suppose that our vending machine has this requirement: "The choice of
drinks (coﬀee, tea, cappuccino) varies between the products. However, every product of the
family delivers at least one diﬀerent drink". Then we can model it using the DMTS as de-
scribed in the Figure 11.4. Note that, for convenience, may transitions are not described.
This is not an error since must hypertransitions guarantee us the presence of may transi-
tions implicitly. Moreover, as we can see, the LTSs L, M and N are some of the possible
implementations of our DMTS.
11.3.3
1MTS
As we said in the DMTS section, taken a set of possible features, the DMTS allows
us to choose among these features in a disjunctive way, that is for every set we can make
a disjunctive choice. A simple extension may be to change the choice type. Using 1MTS,
introduced in [131], we can choose in an exclusive way and, from the modelling point of view,
the exclusive choice is equivalent to say "taken a set of possible features, one and only one of
them must be present in our products". The 1MTS takes advantage of the hypertransition
concept and in addition it introduces a new concept: the choice function.

162
From Action Systems to Distributed Systems: The Reﬁnement Approach
Figure 11.4: Modelling a product family with an LTS
Deﬁnition 11.7 (Choice function). Let S be a set, PS ⊆P(S) and γ:PS →S. Then γ is
a choice function if ∀B ∈PS, γ(B) ∈B. We denote the set of all choice functions on PS by
choice(PS).
In our context S will be the set of all possible transitions of the entire speciﬁcation,
P(S) will be the set of all possible hypertransitions that can be built over S, PS will be
the set of all possible hypertransitions present in our speciﬁcation, T will be a particular
hypertransition and a function γ, taken a hypertransition T, will return one and only one
element of T, that is a transition. Moreover, in order to handle the hypertransition in a
simpler way, we introduce the following notation:
Let →⊆S × A × S be a generic relation. If s ∈S we write:
(s
a−→) for {t ∈S | (s, a, t) ∈→} and
(s →) for {(a, t) ∈A × S | (s, a, t) ∈→}.
Deﬁnition 11.8 (1MTS [131]). A 1-selecting Modal Transition System (1MTS) is a 5-
tuple (Q, A, q, δ3, δ2), with set Q of states, set A of actions, initial state q ∈Q, and two
distinct transition relations: δ3 ⊆Q × (P(A × Q)\∅) is the may hypertransition relation
and δ2 ⊆Q × (P(A × Q)\∅) is the must hypertransition relation.
Moreover, δ2 ⊆δ3 (consistency requirement).
With respect to DMTSs, the may transition relation also uses hypertransitions and both
may relation and must relation cannot include the "inconsistent" hypertransition, that is the
hypertransition (s, T) where T = ∅. The reason for the introduction of may hypertransition
is simple. Consider the system in Figure 11.5(a). It may be either interpreted as a DMTS
(Figure 11.5(b)) or as a 1MTS (Figure 11.5(c)) and for a better understanding we draw the

Reﬁnement of Behavioural Models for Variability Description
163
must hypertransition and the may transitions explicitly.
As we can see in Figure 11.6 LTSs L and I are two possible implementations of M, further-
more the DMTS N is a reﬁnement of M. If we consider the system (b) in Figure 11.5 with the
exclusive interpretation of must hypertransitions, we can easily note that this system fails,
in eﬀect the LTS I in Figure 11.6 is an implementation of this system but does not satisfy
the exclusive interpretation. The 1MTS described in Figure 11.5(c) solves this problem.
Figure 11.5: An example of DMTS and 1MTS
In order to deﬁne reﬁnement over 1MTSs we need a novel concept: if R ⊆S × S is a
generic relation between states, then the extension of R to (A × S) × (A × S) is: (θ, θ1) ∈
R ⇔a = a1 ∧(q′, q′
1) ∈R, where (a, q′), (a1, q′
1) ∈A × S.
Deﬁnition 11.9 (1MTS reﬁnement). A 1MTS Fp = (Qp, A, qp, δ3
p , δ2
p ) is a reﬁnement of
a 1MTS F = (Q, A, q, δ3, δ2), denoted by F ⪯Fp, if and only if there exists a reﬁnement
relation R ⊆Q × Qp such that (q, qp) ∈R and for any a ∈A and for all (q, qp) ∈R and
∀γ ∈choice(qp →3). ∃γ′ ∈choice(q →3) such that the following holds:
1. ∀Θp ∈(qp →3). ∃Θq ∈(q →3):(γ(Θp), γ′(Θq)) ∈R
2. ∀Θq ∈(q →2). ∃Θp ∈(qp →2):(γ(Θp), γ′(Θq)) ∈R
Example 11.2. Suppose that our vending machine has this requirement: "The choice of
drinks (coﬀee, tea, cappuccino) varies between the products. However, every product of the
family delivers one and only one diﬀerent drink". Then we can model this request using the
1MTS as described in the Figure 11.7. As we can see the LTSs L, M, and N are all possible
implementations of our 1MTS.

164
From Action Systems to Distributed Systems: The Reﬁnement Approach
Figure 11.6: An example of DMTS and its problem with exclusive choices
11.3.4
Generalised Extended Modal Transition Systems
A more general notion is actually needed if we want to model multiple optionality, that
is, the fact that a product may have (at least, at most, exactly) k of the n choices proposed
by the family.
It is a matter of discussion whether multiple optionality is really useful in family engi-
neering. Actually, it is rarely the case that a functional requirement on the products of a
family gives bounds on the number of the possible features present in a product. However,
nonfunctional requirements may do: for example, energy consumption or budget consid-
erations may give an upper bound to the number of provided features, while marketing
strategies may suggest a lower bound, under which the product loses its market. Also, up-
per and lower bounds may be used to deﬁne subfamilies on the basis of nonfunctional aspects.
We will introduce the notion of multiple optionality in our running example by adding the
requirement:
- “every product of the family delivers at least two diﬀerent drinks”.
This requirement could be dictated not by functional needs, but by marketing strategies.
In order to give a full range of behavioural models for variability types, the concept of
Generalised Extended Modal Transition Systems, which is able to model multiple optionality
has been introduced [130].
Deﬁnition 11.10 (GEMTS [129]). A Generalised Extended Modal Transition System
(GEMTS) is a quintuple (Q, A, q0, 2, 3), where Q is a set of states, A is a set of actions,

Reﬁnement of Behavioural Models for Variability Description
165
Figure 11.7: An example of 1MTS and its implementations
q0 ∈Q is the initial state, 2 ⊆Q × 2A×Q × N is the at least k-of-n transition relation, and
3 ⊆Q × 2A×Q × N is the at most k-of-n transition relation.
We write respectively: q
a1,a2,...,an
−−−−−−−→2k q1, q2 . . . , qn and q
a1,a2,...,an
−−−−−−−→3k q1, q2 . . . , qn to denote
elements of the two relations, meaning that in the ﬁrst case any product of the family should
have at least k of the n transitions q
ai
−→qi, while in the second case any product of the
family should have at most k of the n transitions (that is, it can also have no transition from
this set). Again, the number of the actions on the arrow must coincide with that of target
states, and order counts as well, since each action is paired to the corresponding state. Note
that 0<k ≤n should always hold, otherwise the relation is meaningless.
The two deﬁned transition relations have the following properties, that derive straight-
forwardly from the interpretation of a GEMTS as model of a family of LTSs:
• q
a1,a2,...,an
−−−−−−−→2k q1, q2 . . . , qn ⇒q
a2,...,an
−−−−−→2k−1 q2 . . . , qn
• q
a1,a2,...,an
−−−−−−−→2k q1, q2 . . . , qn and q
a1,a2,...,an
−−−−−−−→3k q1, q2 . . . , qn
means: any product of the family should have exactly k of the n transitions q
ai
−→qi;
this deﬁnes the relation 2 ∩3 as the relation exactly k of n.
• If we let k to be equal to n, the may relation includes the must relation:
q
a1,a2,...,an
−−−−−−−→2n q1, q2 . . . , qn ⇒q
a1,a2,...,an
−−−−−−−→3n q1, q2 . . . , qn. Inclusion does not hold if
k ̸= n.
Note that the “at least 1-of-1” transitions coincide with the “exactly 1-of-1” ones and

166
From Action Systems to Distributed Systems: The Reﬁnement Approach
can be considered as the usual LTS transitions. For this reason, in the graphical notation
we adopt for GEMTSs, in order to avoid notation overloading, we use the box and diamond
symbols only in states corresponding to variation points: other states in the GEMTS with
only “exactly 1-of-1” outgoing transitions are drawn as usual in LTS. This limited usage
of the modality notation helps the reader to concentrate on variation points. For more
simplicity, box and diamond symbols will be used without the number suﬃx when n = 1.
In our example, the added requirement that "every product of the family delivers at least
two diﬀerent drinks" can be modelled using the GEMTS shown in Figure 11.8.
Figure 11.8: An example of GEMTS and its implementations
From the deﬁnition of GEMTS we can derive the deﬁnition of Extended Modal Transition
Systems [129], in which at any state of the system, it can be deﬁned whether to choose at
least (or at most) one from a subset of the outgoing transitions.
Deﬁnition 11.11 (EMTS [129]). An Extended Modal Transition System (EMTS) is a
quintuple (Q, A, q0, 2, 3), where Q is a set of states, A is a set of actions, q0 ∈Q is the
initial state, 2 ⊆Q × 2A×Q is the at least 1-of-n transition relation, and 3 ⊆Q × 2A×Q is
the at most 1-of-n transition relation.
An EMTS can be deﬁned as a GEMTS in which the relations 2 and 3 are restricted
to the constant value k = 1: this is obvious considering that the two relations can be read
“at least 1-of-n” and “at most 1-of-n”. Consequently, an MTS can be deﬁned as a GEMTS
in which the relations 2 and 3 are restricted to the constant value k = 1, and where only
singleton pairs from A × Q appear (that is, n = 1).

Reﬁnement of Behavioural Models for Variability Description
167
Note therefore that s
a−→21 s′ ⇒s
a−→31 s′ (if a transition is required is also possible,
consistently with the deﬁnition of MTSs).
Deﬁning a reﬁnement relation on GEMTS is not immediate, due to the complex structure
of hypertransitions. A convenient way is by recurring to the notion of product, that parallels
on GEMTS the notion of implementation given for MTSs.
A GEMTS deﬁnes a family of LTSs according to the following deﬁnition:
Deﬁnition 11.12 (GEMTS products). An LTS P = (QP, A, p0, −→) belongs to the family
described by the GEMTS F = (QF, A, f0, 2, 3) (we say also P is a product of F, or P
conforms to F, written P |−F) if and only if p0 |−f0, where:
p |−f if and only if
• f
a1,a2,...,an
−−−−−−−→2k f1, f2 . . . , fn ⇒
∃I ⊆{1, . . . , n}, k ≤| I |≤n: ∀i ∈I, p
ai
−→pi and pi |−fi
• f
a1,a2,...,an
−−−−−−−→3k f1, f2 . . . , qn ⇒
̸ ∃I ⊆{1, . . . , n}, k< | I |≤n: ∀i ∈I, p
ai
−→pi and pi |−fi
• p
a−→p′ ⇒∃k, A′ ⊆A, Q ⊆QF, f ′ ∈QF:(a, f ′) ∈A×QF, (f , A′ ×Q, k) ∈2 or (f , A′ ×
Q, k) ∈3, and p′ |−f ′
We can read the previous clauses as saying: a product of a family has at least (at most)
k of the n transitions speciﬁed in the family; moreover, if a product performs an action, this
should be found among the n transitions speciﬁed for the family. The reﬁnement relation
deﬁned in 11.3.4 is a restriction of a generic reﬁnement relation, in eﬀect it describes only the
connection between a product (or LTS) and a speciﬁcation (or GEMTS), all intermediate
steps of the reﬁnement process are ignored. In Figure 11.8, we can see that the LTSs L, M,
and N are all possible implementations of the shown GEMTS.
According to the deﬁnition of thorough reﬁnement proposed in [50], we give the following
deﬁnition that is based on comparing the sets of products of two GEMTSs:
Deﬁnition 11.13 (GEMTS reﬁnement). Given two GEMTS F and G, we say that F reﬁnes
G if {PF | PF |−F} ⊆{PG | PG |−G}.
The requirements given in Section 11.2 plus the one added above for the multiple op-
tionality can be now fully expressed by the GEMTS shown in Figure 11.9.
The LTS of a product can be obtained from the family GEMTS by applying Deﬁnition
11.12. Hence, the set of products derivable are, again, a subset of those derivable by the
family LTS (note that the family LTS can be obtained from the family GEMTS by just
removing the modality notations in the graphical syntax). Therefore, any derivable product
is still simulated by the family LTS.
The European vending machines of Figure 11.3a is derivable from the family GEMTS
of Figure 11.9. Notice that now it is no more possible to derive the machine accepting both
euro and dollar coins.

168
From Action Systems to Distributed Systems: The Reﬁnement Approach
Figure 11.9: Vending machines family as a GEMTS
11.4
A Comparison on the Expressiveness
Table 11.1 shows the meaning of the modalities of the diﬀerent variants of MTSs that
have been proposed to model variability. DMTSs and 1-MTSs are analogous to GEMTSs
for the fact that they all use hyper-transitions, that is, transition relations where the target
is a set of states, in contrast with MTSs, in which the modal transition relations have only
one target state. This allows modalities to predicate on a particular choice of a subset of
transitions, rather than just on a single transition: note anyway that the possibility to have
diﬀerent (hyper)transitions from the same state is maintained in all the models.
Table 11.1: Meaning of modalities
modality
MTS
DMTS
1-MTS
EMTS
GEMTS
3 (may)
at most 1-of-1
at most n-of-n
at most 1-of-n
at most 1-of-n
at most k-of-n
2 (must)
at least 1-of-1
at least 1-of-n
exactly 1-of-n
at least 1-of-n
at least k-of-n
In [145] it has been shown that it is possible to determine a hierarchy comparing expres-
sivity among all models of the Modal Family. The hierarchy, shown in Figure 11.10 has been
deﬁned under the assumption that all the considered models are action-deterministic, that
is, a restriction is requested on the transition relation: the target state of any transition is
univocally determined by its source state and its label.

Reﬁnement of Behavioural Models for Variability Description
169
Figure 11.10: Hierarchy for the modal family
11.5
Conclusions
Reﬁnement has traditionally been applied to the process of stepwise implementing an
abstract speciﬁcation through successive reﬁnements adding implementation details. The
seminal work of Kaisa Sere and her group has applied reﬁnement to the action systems
formalism according to this trend. [32]. We have indeed presented a diﬀerent application of
reﬁnement, in which the abstract speciﬁcation represents a family of diﬀerent systems and
each of them can be obtained by applying reﬁnement steps, each of those ﬁxes some variable
aspect of the speciﬁcation. We have reviewed some variants of Modal Transition Systems
that are suitable to express behavioural variability in a family of systems. The concept of
reﬁnement in this context amounts to restricting the variability in order to deﬁne a subfam-
ily of systems or a single system (product).
We have left out a few other more elaborate variants that have been proposed in the litera-
ture. In particular, other models, such as the OTS [48] (Transition System with Obligations)
and the PMTS [49] (Parametric Modal Transition System), introduce the obligation con-
cept, using logic formulae related to states. Every formula represents features requested.
In [145] these models have been compared with the MTS variants discussed above and the
appropriate deﬁnitions of reﬁnement are given.
11.6
Acknowledgments
We wish to thank Christian Grioli for the work done on this subject during his master
thesis [145].

This page intentionally left blank
This page intentionally left blank

Free ebooks ==>   www.Ebook777.com
Chapter 12
Integrating Reﬁnement-Based Methods for
Developing Timed Systems
Jüri Vain
Tallinn University of Technology
Leonidas Tsiopoulos
Åbo Akademi University
Pontus Boström
Åbo Akademi University
12.1
Introduction ......................................................
172
12.2
Related Work ....................................................
173
12.3
Preliminaries .....................................................
174
12.3.1
Preliminaries of Event-B ................................
174
12.3.2
Preliminaries of UPTA ..................................
175
12.4
Mapping from Event-B Models to UPTA .......................
175
12.5
IEEE 1394 Case Study ...........................................
177
12.5.1
IEEE 1394 in Event-B ...................................
178
12.5.2
Mapping IEEE 1394 Event-B Model to UPTA .........
179
12.6
Reﬁnement of Timed Systems ...................................
180
12.6.1
Event-B and UPTA Final Reﬁnement of IEEE 1394 ...
183
12.7
Conclusion and Future Work ....................................
184
Abstract. Reﬁnement-based development supported by Event-B has been extensively used
in the domain of embedded and distributed systems design. For these domains timing anal-
ysis is of great importance. However, in its present form, Event-B does not have a built-in
notion of time. The theory of reﬁnement of timed transition systems has been studied, but
a reﬁnement-based design ﬂow of these systems is weakly supported by industrial strength
tools. In this paper, we focus on the reﬁnement relation in the class of Uppaal Timed
Automata and show how this relation is interrelated with the data reﬁnement relation in
Event-B. Using this interrelation we present how the Event-B and Uppaal tools can com-
plement each other in a reﬁnement-based design ﬂow. The approach is demonstrated on a
well-studied case-study, namelly the IEEE 1394 tree identify protocol.
171
www.Ebook777.com

172
From Action Systems to Distributed Systems: The Reﬁnement Approach
correctness check
Refinement step
Event-B
Uppaal
Event-B
UPTA
Functional
requirements
Timing
requirements
ok
nok
Design spec n
(implementable)
ok
nok
Design of functional
aspects
Design of timing
aspects
Refinement
Event-B
UPTA
Event-B
UPTA
ok
nok
nok
ok
Design spec 1
Design spec 2
ok
nok
ok
nok
...
Figure 12.1: CCD workﬂow with data and timing reﬁnement steps
12.1
Introduction
The Correct-by-Construction Design (CCD) workﬂow has proven itself in recent indus-
trial practice. Peugeot Automobiles has developed a model of the car subsystems (lightings,
airbags, engine, etc.) for Peugeot aftersales service; RATP (Paris Transportation) used to
verify automatic doors for an existing metro line. Event-B [6] as one such CCD support-
ing formalism has proven its relevance in data intensive development while lacking suf-
ﬁcient support for timing analysis and reﬁnement of timed speciﬁcations. Uppaal Timed
Automata (UPTA) [47] address timing aspects of systems providing eﬃcient data structures
and algorithms for their representation and analysis but are less focused on supporting the
reﬁnement-based development, especially data reﬁnement. The goal of this paper is to advo-
cate the model-based design method where these two approaches are combined to mutually
complement each other.
The design ﬂow discussed in the paper comprises alternating steps of data and timing
reﬁnement (see Figure 12.1). The process starts with data reﬁnement of requirements spec-
iﬁcation and proving reﬁnement correctness within Event-B. The result of data reﬁnement
is input for timing reﬁnement step performed using an UPTA model. The timing model is
created as a result of mapping a reﬁned Event-B model to an UPTA model that is then
complemented with speciﬁc timing attributes. These attributes are initialized typically with
values deﬁned in the timing requirements speciﬁcation. Further, the timing reﬁnement step
concerns the UPTA attributes that are not instantiated yet and/or those that are already
instantiated but need to be modiﬁed to reduce timing non-determinism.
In the design workﬂow timing reﬁnement steps are performed incrementally. If the UPTA
model (the result of earlier transformation step), already exists, then it is reused for current
Event-B to UPTA mapping. Only the new fragment of Event-B model that is introduced by
current data reﬁnement step needs to be mapped to UPTA and composed with the existing
UPTA model. The resulting composition is subject to timing reﬁnement.
Once speciﬁed, the timing reﬁnement is veriﬁed using Uppaal [47] tool. The result of
timing reﬁnement step is also veriﬁed for consistency, i.e., against the properties such as
deadlocks, non-Zenoness, connectedness, etc.
A ﬁrst result for this approach was presented by Berthing et al. [54] where a part of

Integrating Reﬁnement-Based Methods for Developing Timed Systems
173
an industrial safety critical system was abstractly speciﬁed and then reﬁned to model the
required redundancy. The reﬁnement step was simple in the sense that it did not introduce
new events to the reﬁned model and used very simple data structures. This paper addresses
introduction of new events and reﬁnement of more complex data. The approach is applied to
the IEEE 1394 case study, which is well-studied with both formalisms. The reﬁnement cases
concern incremental unfolding of details at each step with new variables and events. The
tree identify process of IEEE 1394 is a leader election protocol which takes place after a bus
reset in a network. The development steps are shown at ﬁrst within Event-B and mapped
then to UPTA for performing timing reﬁnement and checking their correctness thereafter
following the design workﬂow of Figure 12.1.
12.2
Related Work
An extensive study of automata models for timed systems is presented in [234] where a
general model is deﬁned for developing a variety of simulation proof techniques for timed
systems. To improve model checking performance of timed systems timing constraint re-
ﬁnement methods such as the forward algorithm based on zones for checking reachability
[63] and the counter example guided automatic timing reﬁnement technique [111] have been
studied. The reﬁnement of timing has been addressed also as part of the speciﬁcation tech-
nique in [97] where the constructs for reﬁnement of Timed I/O speciﬁcations were deﬁned
for development of compositional design methodology. In [163] the authors propose a design
approach where diﬀerent forms of reﬁnements are used to enhance model checking TCTL
properties and preservation of these properties by reﬁnements.
The motivation behind timing reﬁnement in all these works has been rather model check-
ing or automated design veriﬁcation than reﬁnement-based development. The way timing
reﬁnement steps are constructed in the course of practical design ﬂow has deserved relatively
little attention because the proof techniques rely rather on semantic models of reﬁnement
transformations than on syntactic ones the developer works with. The design transforma-
tions to be human comprehensible need to be speciﬁed in terms of high level modelling
language and, thus, the reﬁnement transformations need to be deﬁned explicitly in terms of
syntactic constructs of that language.
In [75, 215, 290] attempts have been made to incorporate discrete time directly into
design description formalisms without native notion of time. Continuous time has been
investigated also with a similar approach [322]. However, the clocks are not an integrated
part, they are modelled as ordinary variables. Hence, continuous time speciﬁc problems
such as Zeno behaviour cannot be addressed directly in, for example, the Event-B proof
system. Modelling timed behaviour manually in Event-B is error prone and makes the model
cluttered with timing properties, which also makes proofs harder to automate. Attempts to
remedy this have been made with Hybrid Event-B [42]. An earlier attempt to integrate
stepwise development in Event-B with model checking in Uppaal is given in [180] where
events are grouped into more coarse grained processes with timing properties.
We aim to provide an integrated approach without deforming the underlying formalisms.
Then the timing reﬁnements can be addressed by reusing the model constructs of Event-B
mapped to UPTA by keeping the event structure of the model as much as possible untouched.
This allows verifying the data reﬁnement steps also from the timing feasibility point of view.

174
From Action Systems to Distributed Systems: The Reﬁnement Approach
The IEEE1394 example was studied earlier by following mostly a reﬁnement and proof-
based approach in [3] or by verifying the timing properties of the protocol for solving leader
election contentions with timed automata speciﬁcations in [320]. Abrial et al. [3] presented an
incremental speciﬁcation of the protocol aiming at a generic speciﬁcation without restrictions
on the total number of nodes on the tree. The Event-B model was constructed in a usual,
reﬁnement-based manner where more details are unfolded at each reﬁnement step with new
variables and events. Probabilistic conﬂict resolving was applied for nodes choosing long or
short waiting times. Thus, actual modeling of time was not concerned. On the other hand,
Timed Automata applications to the protocol [320] reduced the timing correctness analysis
of the protocol only on a pair of nodes contesting for network leadership. This approach
helped in avoiding state explosion in the model checkers but ignored the aspects of data
reﬁnement outlined by Abrial et al.
For our proposed CCD methodology it is crucial to keep the Event-B and timing models
in synchrony by mapping the Event-B speciﬁcation to UPTA. Thus, it is of high interest
to investigate to what extent UPTA can follow, as well as complement, the usual Event-
B development and expose the timing related design faults that otherwise may remain
undiscovered by the Event-B proof system.
12.3
Preliminaries
12.3.1
Preliminaries of Event-B
Consider an Event-B model M with variables v, invariant I(v), and events E1, . . . , Em.
All events can be written in the form
Ei = any x where Gi(v, x) then v :| Si(v, x, v′) end
where x are parameters, Gi(v, x) is a predicate called the guard, and v : | Si(v, x, v′) is a
statement that describes a (nondeterministic) relationship between variable valuations before
and after executing the event. The parameters can be omitted and the keyword when is then
used instead of where. Event-B models do not have ﬁxed semantics [6], but correctness of a
model is deﬁned by a set of proof obligations. We can use these proof obligations to prove
correctness of many transition systems. In order to guarantee that Ei preserves invariant
I(v) we prove [6]:
I(v) ∧Gi(v, x) ∧Si(v, x, v′) ⇒I(v′)
(INV)
In order to be able to relate Event-B with UPTA in the following sections we interpret an
Event-B model as a Labelled Transition System (LTS) (Σ, init, T, i), where Σ is the set of
states, init is the set of initial states, T ⊆Σ×Σ is the set of transitions, and i is the set of legal
states i ⊆Σ. The set of states gi where the guard of a transition σi holds is given as gi = {v |
∃x ·Gi(v, x)} and the relation si describing the before-after relation for states corresponding
to the update statement v : | Si(v, x, v′) is given as si = {v 7→v′ | ∃x · Si(v, x, v′)}. The
relation describing the before-after states for each transition Ti is then given as1 gi ◁si.
1The domain restriction operator ◁is deﬁned as: g ◁s = {σ 7→σ′ ∈s | σ ∈g}.

Integrating Reﬁnement-Based Methods for Developing Timed Systems
175
We can now describe the Event-B model as a transition system (Σ, init, T, i) where the
state space Σ is formed from the variables v1, . . . , vn, Σ = Σ1 × . . . × Σn , Σi is the type
of vi. The initial states are formed as init = {v | Init(v)}. The transitions Ti are given
as Ti = g1 ◁s1 ∪. . . ∪gm ◁sm. The set of legal states are the ones where the invariant
i = {v | I(v)} holds.
12.3.2
Preliminaries of UPTA
An UPTA is given as the tuple (L, E, V , CL, Init, Inv, TL), where L is a ﬁnite set of
locations, E is the set of edges deﬁned by E ⊆L × G(CL, V ) × Sync × Act × L, where
G(CL, V ) is the set of constraints allowed in guards. Sync is a set of synchronisation actions
over channels. An action send over a channel h is denoted by h! and its co-action receive is
denoted by h?. Act is a set of sequences of assignment actions as well as with clock resets.
V denotes the set of data variables. CL denotes the set of real-valued clocks (CL ∩V = ∅).
Init ⊆Act is a set of assignments that assigns the initial values to variables and clocks.
Inv : L →I(CL, V ) is a function that assigns an invariant to each location, I(CL, V ) is the
set of invariants over clocks CL and variables V . TL: L →{ordinary, urgent, committed} is
the function that assigns the type to each location of the automaton.
We introduce the semantics of UPTA as deﬁned in [47]. A clock valuation is a function
valcl : CL →R≥0 from the set of clocks to the non-negative reals. A variable valuation is a
function valv : V →D from the set of variables to values. Let RCL and DV be the sets of all
clock and variable valuations, respectively. The semantics of an UPTA is deﬁned as an LTS
(Σ, init, →), where Σ ⊆L × RCL × DV is the set of states, the initial state init = Init(cl, v)
for all cl ∈CL and for all v ∈V , with cl = 0, and →⊆Σ×{R≥0 ∪Act}×Σ is the transition
relation such that:
1. (l, valcl, valv) d−→(l, valcl + d, valv) if ∀d′:0 ≤d′ ≤d ⇒valcl + d′ |= Inv(l),
2. (l, valcl, valv) act
−−→(l′, val′
cl, val′
v) if ∃e = (l, act, G(cl, v), r, l′) ∈E s.t. valcl, valv |=
G(cl, v), val′
cl = [re 7→0]valcl, and val′
cl, val′
v |= Inv(l′),
where for delay d ∈R≥0, valcl + d maps each clock cl in CL to the value valcl + d, and
[re 7→0]valcl denotes the clock valuation which maps (resets) each clock in re to 0 and agrees
with valcl over CL\re.
12.4
Mapping from Event-B Models to UPTA
As demonstrated in Sections 12.3.1 and 12.3.2 both Event-B and UPTA have common
semantic ground deﬁned as LTS. Though, for eﬃcient mapping of Event-B to UPTA the
mapping rules need to be deﬁned on a syntactic level because the semantic mapping via
LTS may cause huge models when having parallel composition and many data variables.
Also mapping from LTS to UPTA may produce syntactically diﬀerent (though semantically
equivalent) results that are expensive to compare. Therefore, the goal in this paper is to
deﬁne a syntactic level mapping between Event-B and UPTA and in that way to extend
the Event-B based stepwise CCD to timed systems. Due to the incrementality of CCD the

176
From Action Systems to Distributed Systems: The Reﬁnement Approach
Event-B to UPTA mappings depicted in Figure 12.1 preserve the locality of model changes
introduced by Event-B reﬁnements, i.e., only those model fragments that are introduced by
Event-B reﬁnements need to be mapped to the corresponding UPTA fragments. The rest of
the UPTA model remains untouched by the Event-B reﬁnement step.
In the following we progressively arrive to the mapping of models after we ﬁrst discuss
the syntax correspondence between Event-B and UPTA and the mapping of events using as
a running example the development of IEEE 1394 tree identify protocol.
Mapping of functions and predicates. Integers and enumerated types in Event-B
become integers, while ﬁnite sets and relations in Event-B are mapped to (multidimensional)
arrays in UPTA. We can then implement the set and relational operators as C-functions
in UPTA. For instance, guards of events stating that an element belongs to the domain of
a function or a pair of mapped elements is present in a function. An example is the guard
send req grd in UPTA shown in Figure 12.5a that is speciﬁed as a boolean function:
bool send req grd(id t x, id t y) {
return forall (i : int [0, N]) (REQ [x] [i] == 0) ;}
returning false if the element REQ (x, i) of two-dimensional boolean array REQ is 0 and
true otherwise. In other words, when this guard is true it means that node x has not yet sent
a parent request to node y. Generally, the functions are used in UPTA for encoding complex
predicates and calculations to avoid visual overhead in the model graphical representation.
Mapping of events. Let
Ei = when Gi(v) then v :| Si(v, v′) end
be an event speciﬁcation in Event-B, then UPTA model template shown in Figure 12.2a
is direct mapping of the event in UPTA where the occurrence of event Ei is simulated by
executing the edge that has attributes: i) when Gi(V) is the mapping of the event guard
Gi, ii) V′ = then Si(V, U′) is assignment statement that corresponds to the deterministic
assignments of v : | Si(v, v′), iii) U′:dom U is an assignment statement that corresponds to
non-deterministic assignments of v :| Si(v, v′), and iv) location PrePost Ei models pre- and
post-control states of event Ei.
Meaning of skip in Event-B. Assuming the skip-event in Event-B: i) does not have
eﬀect on the system state, ii) can be executed in any state at any time moment, iii) can
interleave with all other events, iv) the number of skip events is unbounded, and v) it is
not speciﬁed explicitly, we interpret the skip-event in UPTA as an abstraction of the event
template depicted in Figure 12.2a and we present its model in Figure 12.2b. Due to i) and
ii) the guard in skip-template is always true and the update statement keeps the variables
unchanged. Like in Event-B the skip-events need not be speciﬁed explicitly in UPTA.
Timing of events. When adding in UPTA explicit timing constraint to events it is
assumed that the occurrence of an event is instantaneous. An event takes place within some
time interval [lb, ub] provided it is enabled by guard Gi. For speciﬁcation of these constraints
new variables, namely set CL of clocks is added to the template of Figure 12.2a. The subject
of weakest timing speciﬁcation is the skip-event (Figure 12.2c) where the event occurrence
is not restricted in time (time interval is [inf dom(cl), supr dom(cl)]). We usually assume
the continuous interval [lb, ub] where lb = inf dom(cl) = 0 and ub = supr dom(cl) =

Integrating Reﬁnement-Based Methods for Developing Timed Systems
177
a) 
b) 
c) 
d) 
PrePost_Ei
U’ : dom_U
when_Gi(V)
V’ = then_Si(V,U’)
PrePost
U’ = U
true
V’ = V
PrePost
cl< sup_dom_cl
U’ = U
true &&
cl>=inf_dom_cl
V’ = V,
cl’= inf_dom_cl
PrePost_Ei
inv(CL)
U’ : dom_U
when_Gi(V) &&
when_Gi(CL)
V’ = then_Si(V,U’),
CL’=then_Si(CL)
Figure 12.2: UPTA model template of Event-B a) un-timed event, b) skip-event, c) timed
skip-event, and d) timed event.
+∞. In UPTA syntactic notation the upper bound ub of the skip-event occurrence interval
(see Figure 12.2c) is speciﬁed by the invariant of location PrePost, i.e., inv (PrePost) ≡
cl<supr dom (cl) and lower bound lb by the guard of edge ⟨PrePost, PrePost⟩. The same
unbounded interval is assumed by default if the invariant of the location and the guard of
the edge are left unspeciﬁed. Note that having inf dom(cl) = 0 and guard cl ≥inf may
introduce Zeno computations if there is a loop in the model that has maximum of lower
bounds equal to 0.
In general, the timing speciﬁcation of events, as illustrated in Figure 12.2d, introduces
bounded intervals of occurrence that are speciﬁed as location invariant inv(CL) ≡∧i cli ≤
ubi and the guard when Gi(CL) ≡∧j clj ≥lbj of edge ⟨PrePost, PrePost⟩over a set of clocks
cli ∈CL.
Modelling of system of events and ANY-construct. The translation of a set of
Event-B events such as the ones in Figure 12.3 results in a parallel composition of UPTA
processes that are instances of the template of Figure 12.2a above. The template may have
parameters of the type bounded integer. That allows modelling of ANY-construct of Event-
B, where the choice is ﬁnite. The parameter of template speciﬁed by its type deﬁnes the
instances (processes) of the template, one for each value in the parameter type.
12.5
IEEE 1394 Case Study
The IEEE 1394 tree identify protocol case study will act as a running example through-
out the paper. Before we proceed with the actual Event-B system model and its mapping
to UPTA we ﬁrst introduce shortly the idea of the protocol. The tree identify process of
IEEE 1394 is a leader election protocol which takes place after a bus reset in the network.
Immediately after a bus reset all nodes in the network have equal status, and know only
to which nodes they are directly connected. A leader (root of the tree) needs to be elected
as the manager of the bus. The protocol is designed for use in connected networks and
will correctly elect a leader if the network is acyclic. Speciﬁcally, each node has two phases
based on the number of children and the number of neighbours. If there are more than one
neighbour, the node waits for requests from its neighbours to become their parent. If there is
only one neighbour (and this neighbour is not a child), then the node sends a request to the

178
From Action Systems to Distributed Systems: The Reﬁnement Approach
Figure 12.3: Intermediate Event-B reﬁnement of IEEE 1394 protocol
neighbour to become its parent. This implies that leaf nodes are the ﬁrst to communicate
with their neighbours, and that the spanning tree is built from the leaves.
Furthermore, the protocol may not proceed this straightforwardly because the parent
requests are not atomic and contention may arise (two nodes simultaneously send the parent
requests to each other). Since only one node can be the leader, contention must be resolved.
This is achieved by timing. The standard speciﬁes that each node chooses randomly whether
to wait for a long or short time. If, after the wait period is over, there is a parent request
from the other node, then the node becomes the root. If there is no such request, then the
node resends its own parent request and contention may result again.
12.5.1
IEEE 1394 in Event-B
The deployment of our CCD methodology starts with a speciﬁcation which captures an
abstract behaviour of the whole system using the modelling approach by Abrial et al. [3].
For the purposes of this paper we do not present the very abstract speciﬁcation and its
ﬁrst reﬁnement since they do not contain essential timing information except the total time
bound requirement for the protocol converging. The creation of the tree and the election
of the leader node are supposed to be performed in “one shot” (abstract case of event elect
in Figure 12.3). For the ﬁrst reﬁnement the authors gave the essence of the distributed
algorithm with the tree being constructed in a step by step manner (addition of abstract
case of event progress in Figure 12.3).
For the second reﬁnement the communication mechanism has been introduced between
the nodes. We start our case study from this point. The model is shown in Figure 12.3. In this
reﬁnement step the contention problem between two nodes is addressed. Let us ﬁrst explain
the main functionality regarding the construction of the tree. Two variables, req and ack,
are used to handle the requests and the acknowledgements, respectively. When a pair x7→y
belongs to req (guard of event send ack) it means that node x has sent a request to node y
asking it to become its parent (if this is the only one neighbour node not yet connected with
node x - last guard of event send req). Then node y can send an acknowledgement back to
node x if node y has not already sent an acknowledgement to node x (second guard of event
send ack), nor has it sent a request to any node (guard y ̸∈dom(req)). Event progress is
enabled when a node x receives an acknowledgement from node y (x7→y ∈ack) and it has
not yet established any parent connection (x ̸∈dom(tr)). When these conditions are fullﬁlled
the connection is established; the pair x7→y is added to tr, tr representing a sub-graph of
graph g which gradually converges with event progress to the ﬁnal tree.

Integrating Reﬁnement-Based Methods for Developing Timed Systems
179
The discovery and solving of contentions is handled by events discover cnt and solve cnt
shown in Figure 12.3. If node y has also sent a request to node x at the same time, this
means that event send ack is not enabled because its third guard (y ̸∈dom(req)) does not
hold while the ﬁrst two guards hold. On the other hand, the enabling conditions for event
discover cnt state that node x has sent a parent request to node y and has not yet received
an acknowledgement, while node y has also sent a request. As stated earlier, in the actual
protocol speciﬁcation the problem is solved by timers. In the Event-B case, for solving the
contention problem, a new variable cnt for contention was introduced. The action of event
discover cnt adds the pair x7→y to cnt. Event solve cnt is enabled when both pairs x7→y
and y7→x are present in cnt and it removes these pairs from req and resets cnt, formalizing
what happens after the short delay.
12.5.2
Mapping IEEE 1394 Event-B Model to UPTA
The resulting UPTA model corresponding to Event-B speciﬁcation of Figure 12.3 is
illustrated in Figure 12.5a. In order to arrive to this model several optimisations are per-
formed allowing to reduce the global state-space by factor n and keep the structure of the
model relatively compact. Speciﬁcally, the mapping of Event-B events, each to an individual
UPTA process of template demonstrated in Figure 12.2d, produces a very high degree of
parallelism of UPTA models. This is not feasible from the model checking point of view
(the set of global states grows exponentially in the number of processes). Though there is
not general minimization theory for the network of non-deterministic timed automata the
deterministic fragments of the model can be minimized by applying bisimulation quotient
method [165] and the classical Hopcroft minimization algorithm [174]. This allows merging
the non-distinguishable (from trace semantics point of view) locations and edges in templates
separately and in the product automaton of the parallel composition of templates.
The direct mapping of the speciﬁcation of Figure 12.3 using template of Figure 12.2a
provides a process network consisting of m ∗n processes were m is the number of events
and n the size of the template parameter domain. In this case study it is feasible to choose
the id of a node as a template parameter since the set of events of nodes is uniform modulo
the id of the node. In order to further reduce the size of the model we introduce a few more
simpliﬁcations.
1. Non-interference of local events. We assume that once a guard component Gi (V ) of
an event Ei becomes true it remains true until the guard component Gi (CL) becomes
true due to the progress of clocks and event Ei occurs within time interval satisfying
inv(CL) ∧when Gi(CL).
2. Mutually exclusive and non-blocking events. The events of a node are assumed to be
consecutive, i.e., mutually exclusive, non-blocking, and conspiracy-free which implies
that exactly one of these events is enabled at a time till the ﬁnal state (after progress
or elect) will be reached.
3. Terminal events. It is assumed that events progress and elect of a node may occur at
most once after which no other event of the node can be enabled anymore, i.e., the
protocol terminates in the node either after progress or elect event. So the self-loop
pattern of these events (template in Figure 12.4a) can be substituted without side
eﬀects with the one of Figure 12.4b.
Simpliﬁcation 1. above allows substituting the general event template of Figure 12.4a

180
From Action Systems to Distributed Systems: The Reﬁnement Approach
a) 
b) 
c) 
PrePost
inv(CL)
U’ : dom_U
when_Gi(V)&&
when_Gi(CL)
V’ = then_Si(V,U’),
CL’=then_Si(CL)
Terminal
PrePost’
PrePost’’
inv(CL)
U’ : dom U
when_Gi(CL)
V’ = then_Si(V,U’),
CL’=then_Si(CL)
when_Gi(V)
PrePost’
PrePost’’
inv(CL)
U’ : dom U
when_Gi(CL)
V’ = then_Si(V,U’),
CL’=then_Si(CL)
when_Gi(V)
Figure 12.4: UPTA event template transformations: a) timed event, b) non-blocking event
and c) terminal event
with the one depicted in Figure 12.4b. Here the location PrePost is split to sub-locations
PrePost′ and PrePost′′ connected with a new edge that has guard component Gi (V ). Urgent
location PrePost′ represents the control state where the guard component Gi (V ) is supposed
to become true and sub-location PrePost′′ with invariant inv(CL) models the waiting state
for Gi (CL) becomes true. Thus, inv(CL) together with guard Gi (CL) specify the time
interval from the moment when Gi became true till some time instant that satisﬁes inv(CL)∧
when Gi(CL) and ﬁnally enables event Ei.
Due to simpliﬁcation 2. the parallel composition of event automata can be replaced with
one automaton by merging locations PrePost′ of individual events of a node. It means that
while one event is in the location PrePost′′, there should not be any other event of that node
progressing at the same time. The location merging of our IEEE1394 model events results
in the model of Figure 12.5a.
12.6
Reﬁnement of Timed Systems
Assuming the Event-B models are mapped to corresponding UPTA models the next goal
in the CCD workﬂow is to apply timing reﬁnement and ensure its correctness. Let us ﬁrst
introduce the very generic reﬁnement deﬁnition for timed systems presented by Lynch and
Vaandrager [234]. We adapt this deﬁnition in order to correspond to the UPTA semantics
of Section 12.3.2. Let clc and cla be the concrete and abstract clocks of reﬁnement and
speciﬁcation models N and M respectively.
Deﬁnition 12.1. A speciﬁcation M is reﬁned by a speciﬁcation N, written M ⊑N, iﬀthere
exists a binary relation R ⊆ΣN × ΣM such that for each pair of states (n, m) ∈R we have:
1. whenever n(lref ,valclc ,valw) actN
−−−→n′
(l′
ref ,val′
clc ,val′
w) for some n′ ∈ΣN then m(labs,valcla ,valv)
actM
−−−→m′
(l′
abs,val′
cla ,val′
v)and (n′, m′) ∈R for some m′ ∈ΣM
2. whenever n(lref ,valclc ,valw) dN
−−→n′
(lref ,valclc +d,valw) for d ∈R≥0 then m(labs,valcla ,valv)
dM
−−→m′
(labs,valcla +d,valv) and (n′, m′) ∈R for some m′ ∈ΣM
The conditions in Deﬁnition 12.1 state that all concrete transitions are also possible in
the abstract model. Reﬁnement of timing (condition 2), is here simpliﬁed by the restriction
that all abstract clocks are also present in the concrete model, only new clocks are added.

Free ebooks ==>   www.Ebook777.com
Integrating Reﬁnement-Based Methods for Developing Timed Systems
181
II 
a) 
b) 
c) 
Subtree_done
Progress
cl<=d52
Solve_cnt
cl<=d42
Discover_cnt
cl<=d32
Send_ack
cl <=d22
Send_req
cl<=d12
Elect
cl<= d61
Elected
cl>=d51
TR[x][y]=1
ACK[x][y]&&
   not domTR(x)
cl=0
cl>=d41
ch?
REQ[x][y]=0,
REQ[y][x]=0,
CNT[x][y]=0
CNT[x][y]&&
CNT[y][x]
ch!
cl=0
cl>=d31
CNT[x][y]= 1
cnt_grd(x)
cl=0
cl>=d21
z=child(x),
ACK[z][x]=1
REQ[x][y] &&
 not ACK[x][y]&&
  not domREQ(y)
cl=0
cl>=d11
REQ[x][y]=1
send_req_grd(x,y)
cl=0
elect_grd(x) cl=0
cl>=d61
ld=x,unify(sp,TR)
solve_cnt_long
cl<=d42
solve_cnt_short
cl<=d41
cl==d42
ch!
cl==d41
ch!
ch?
cl=0
ch?
cl=0
Receive_cnf
cl<=d62
Solve_cnt_short
cl<=d41
Subtree_done
Progress
cl<=d52
Solve_cnt_long
cl<=d42
Discover_cnt
cl<=d32
Send_ack
cl <=d22
Post
Send_req
cl<=d12
Elect
cl<= sup
Elected
Pre
cl>=d61
add(CH[y],x)
TR[x][y]&&
not in(x,ch[y])
cl==d41
cl==d42
cl>=d51
TR[x][y]=1,
add(dt,x)
ACK[x][y]&&
not in(x,dt)
REQ[x][y]=0,
REQ[y][x]=0,
CNT[x][y]=0
CNT[x][y]&&
CNT[y][x]
cl>=d31
CNT[x][y]= 1
cnt_grd(x)
cl>=d21
y=child(x),
ACK[y][x]=1,
add(AC[y],x)
REQ[x][y] &&
not in(x,AC[y])&&
not in(y,DR)
cl=0
cl>=d11
REQ[x][y]=1,
DR[y]=x
send_req_grd1(x,y)
elect_grd1(x)
cl>=sup
ld=x
Figure 12.5: a) UPTA model corresponding to Event-B reﬁnement of Figure 12.3, b) timing
reﬁnement, and c) UPTA model corresponding to ﬁnal Event-B reﬁnement of Figure 12.7
Hence, old clock guards and invariants can be strengthened. Clock resets must be preserved.
All data invariants can be checked by the proof rules for reﬁnement in Event-B. We have
shown in our previous work [54] how to extend the Event-B proof obligations to check the
timing properties of all conditions of Deﬁnition 12.1. The extended proof obligations could
be added to the proof system for Event-B if development of timed systems is to be addressed
solely within Event-B. The reader is referred to [54] for a detailed view. Here we focus on
veriﬁcation of reﬁnement of timing by model checking in Uppaal after the corresponding
data reﬁnement step has been veriﬁed in Event-B.
In UPTA, we use an approach where the reﬁnements are added to the abstract model
incrementally to support compositional veriﬁcation of reﬁnement steps. To keep the clear
correspondence between syntactic units of the abstract model and their reﬁnement we deﬁne
the reﬁnement transformations syntactically by elements that are reﬁned, i.e., by locations
and edges of UPTA calling them location and edge reﬁnements respectively. The model
fragments introduced by reﬁnement are composed with the abstract model by means of a
wrapping construct “context frame”. Technically, it means that without changing the se-
mantics of the abstract model we add the reﬁnement of the syntactic element el as new
automaton M el that is composed with the original model M via synchronized parallel com-
position ∥sync, s.t. M ⊑M ∥sync M el. This synchronization is needed to preserve the contract
of el with its context after reﬁnement. It requires decorating automaton M with auxiliary
channel labels to synchronize the entry and leave points to/from element el of M.
A representation of the model fragments that schematically represent location and edge
reﬁnement is depicted in Figure 12.6. The context frame for constructing ⊑l consists of the
www.Ebook777.com

182
From Action Systems to Distributed Systems: The Reﬁnement Approach
Figure 12.6: (a) Edge reﬁnement, (b) location reﬁnement.
following elements: a) synchronizing channel ch is needed to synchronize the executions of
entering to and departing from location li transitions with those entering and departing
to and from reﬁning model M li and b) auxiliary initial location l′
0 and ﬁnal location l
′
F
of M li are introduced to model waiting before the synchronization via channel ch arrives
and after the execution of M li terminates respectively. Location reﬁnement is applied when
reﬁnement M li speciﬁes non-instantaneous time bounded behaviours that are represented in
abstract model by location li. The event guard and update reﬁnement introduced in Event-
B [6] can be considered as un-timed case of edge reﬁnement where the guards of edges are
strengthened and new updates are added respectively in the reﬁning model M e consisting
of exactly one edge.
Purely timing reﬁnement without introducing new model elements means reducing the
non-determinism of time intervals between the occurrence of events (events themselves are
instantaneous). The bounds of event occurrence interval [lb, ub] are speciﬁed according to
the timed event template (Figure 12.2d) by clock constraints when Gi(CL) and inv(CL)
respectively. Thus increasing the time constants in when Gi(CL) and reducing constants in
inv(CL) are the simplest forms of respective edge and location reﬁnement.
In general, edge and location reﬁnements introduce new structural elements that require
stating their correctness conditions formally:
Edge reﬁnement. We say that a synchronous parallel composition of automata M and
M ei is an edge reﬁnement for edge ei of M, (M ⊑e M ∥M ei) iﬀei ∈E(M), and there exists
M ei s.t. P1 ∧P2 ∧P3 ∧P4, where:
• P1(interference free new updates): No variable of M is updated in M ei.
• P2(guard splitting): Let ⟨l
′
0, l
′
F⟩denote a set of all feasible paths from the initial location
l
′
0 to ﬁnal location l
′
F in M ei and ⟨l
′
0, l
′
F⟩k ∈⟨l
′
0, l
′
F⟩be kth path in that set. Then,
– ∀k ∈[1, |⟨l
′
0, l
′
F⟩|]. ∨j∈[1,Length(k)] G(e
′
j) ⇒G(ei),
i.e., the disjunction of edge guards of any path in ⟨l
′
0, l
′
F⟩is not weaker than the guard of
edge ei.
• P3(0-duration unwinding): ∀l
′
i ∈(LMei \l
′
0). T(l
′
i) ∈{committed, urgent},
i.e., all locations in the reﬁnement M ei must be either urgent or committed.

Integrating Reﬁnement-Based Methods for Developing Timed Systems
183
• P4(non-divergency): G(ei) ⇒[M e, l
′
0 |= A♦l
′
F],
i.e., validity of G(ei) implies the existence of a feasible path in M ei.
Location reﬁnement. We say that a synchronous parallel composition of automata M
and M li is a location reﬁnement for location li of M, (M ⊑l M ∥M li) iﬀli ∈L(M), and
exists M li s.t. P1 ∧P2 ∧P3, where:
• P1 (interference free new updates): No variable of M is updated in M li.
• P2 (preservation of non-blocking invariant):
[(M ∥M li),(l0, l’
0) |=E♦deadlock]⇒[M, l0 |=E♦deadlock].
• P3 (non-divergency): inv(li) ≡x ≤d for x ∈CLM, d<∞⇒[M li, l
′
0 |= l
′
0 ⇝d l
′
F],
where “⇝d” denotes bounded ‘leads to’ operator with non-negative integer time bound,
CLM is the set of clocks of M, locations l
′
0 and l
′
F denote respectively auxiliary pre- and
post-locations in the context frame of the reﬁnement.
P2 and P3 are speciﬁed as model checking queries expressed in TCTL. “deadlock”
denotes a standard predicate in Uppaal about the existence of deadlocks in the model. P3
requires that the invariant of li is not violated due to accumulated delays of M li runs.
The practical use of location reﬁnement followed with later minimization steps is demon-
strated on event solve cnt in our running example. Design requirements for solving the
contention situation state that the contention is resolved by choosing diﬀerent waiting
times after the contention situation has been detected. The minimum and maximum of
non-deterministic waiting time is speciﬁed in the UPTA model in Figure 12.5a as d41 and
d42 respectively. In the given level of abstraction we leave this timing speciﬁcation loose
intentionally not to restrict the forthcoming design decisions that can determine exact time
delays due to practical engineering considerations. Since the choice of waiting time is left
to be arbitrary within the interval [d41, d42] it can be proved by model checking that both
nodes can choose the delay that diﬀers too little and leads to the next contention. In Figure
12.5b this condition is reﬁned by applying location reﬁnement. Location Solve cnt is reﬁned
to solve cnt short and solve cnt long that results in two exact waiting times d41 and d42 that
excludes intermediate values as required by the protocol speciﬁcation.
12.6.1
Event-B and UPTA Final Reﬁnement of IEEE 1394
The ﬁnal Event-B reﬁnement of our running example is shown in Figure 12.7. It is
concerned with data reﬁnement for the localisation of the global constants and variables.
Variables nb (for neighbours), ch (for children), ac (for acknowledged), dr (for domain of
req), and dt (for domain of tr) are declared and their connection to the variables of the
previous models is shown in the invariant clause in Figure 12.7. For a node x, the sets for
neighbours (nb(x)), children (ch(x)), and acknowledged nodes (ac(x)) are supposed to be
stored locally within the node. The deﬁnition of variable ch above is not given in terms of an
equality, rather in terms of an inclusion due to the fact that the set ch(y) cannot be updated
while event progress takes place. This is because this event can only act on its local data. A
new event receive cnf for receiving conﬁrmation is thus necessary to update the set ch(y).
This new event reﬁnes skip. Events discover cnt and solve cnt remain unchanged. Events
send req, send ack, progress, and elect are reﬁned with the new variables.
Applying the mapping and optimization steps described in Section 12.4 to the ﬁnal
reﬁnement of Figure 12.7 results in the UPTA model of Figure 12.5c. At ﬁrst, the new

184
From Action Systems to Distributed Systems: The Reﬁnement Approach
Figure 12.7: Event-B ﬁnal reﬁnement of IEEE 1394 tree identify protocol
event receive cnf is introduced by instantiating the template of Figure 12.4b. By applying
the minimization step 2 described in Section 12.5.2, the PrePost′ location of receive cnf is
merged with the one of the model in Figure 12.5a. Thereafter, the ⟨PrePost′′, PrePost′⟩edges
of all events are reﬁned so that the clock resets and data variable assignments remain on
consecutive edges separated by committed location Post. Finally, since ⟨Post, Pre⟩edges
of all nonterminating events have identical clock resets and destination location, they are
merged into one ⟨Post, Pre⟩edge as shown in Figure 12.5c.
Though the ﬁnal reﬁnement by Abrial et al. refers to timing constraint related to con-
tention resolving and message transmission delays, practical implementation of the protocol
may introduce much more complex timing constraints and that is not only for single events
in isolation but also for those that depend on the ordering and timing of other events. For
instance buﬀering time may depend on the arrival rate of messages sent by other nodes.
This information cannot be introduced in un-timed models. Similarly, as our model check-
ing experiments revealed, simple timing errors may remain unnoticed when introducing
timing constraints for events progress and elect (the protocol total convergence time bound
requirements were violated if the occurrence interval of events was speciﬁed too loose).
12.7
Conclusion and Future Work
We propose a correct-by-construction design workﬂow where model-based design trans-
formations combine alternating data and timing constraints reﬁnement steps. The goal is to
beneﬁt from mutually complementing formalisms Event-B and Uppaal automata and related
veriﬁcation techniques. For bridging the data and timing reﬁnement steps the Event-B to
UPTA map and its timing reﬁnement transformations have been deﬁned and their relevance
discussed. As an advantage of integrating theses two it allows to verify the data reﬁnement
correctness also from its timing feasibility point of view. The approach is demonstrated on
the development case study of the IEEE 1394 tree identify protocol. The automation of
the proposed design transformations as plug-in either for Rodin or Uppaal tool remains for
future work. Still, the results are encouraging from the usability point of view due to the

Integrating Reﬁnement-Based Methods for Developing Timed Systems
185
simplicity of transformations and the locality of proof obligations to be discharged for timing
reﬁnement veriﬁcation.

This page intentionally left blank
This page intentionally left blank

Part V
Applications
187

This page intentionally left blank
This page intentionally left blank

Chapter 13
Action Systems for Pharmacokinetic
Modeling
M.M. Bonsangue
LIACS, Leiden University, The Netherlands
M. Helvensteijn
LIACS, Leiden University, The Netherlands
J.N. Kok
LIACS, Leiden University, The Netherlands
N. Kokash
LIACS, Leiden University, The Netherlands
13.1
Introduction ......................................................
190
13.2
Actions and Action Systems .....................................
191
13.2.1
Action Systems ..........................................
193
13.2.2
Hybrid Action Systems ..................................
193
13.3
Pharmacokinetic Modeling .......................................
194
13.3.1
Absorption ...............................................
196
13.3.2
Elimination ..............................................
198
13.3.3
One-Compartment Model ...............................
199
13.3.4
Distribution ..............................................
199
13.4
Conclusions and Future Work ...................................
200
Abstract. In system biology, models play a crucial role to understand, communicate, and
analyze a system. Such models are often the result of complex interactions between contin-
uous and discrete logics. In this chapter we give a short introduction to pharmacokinetics,
the biological study of the process interactions between a drug and the human body. We
show how action systems with continuous behaviour can be used as a precise model for
pharmacokinetics processes. The support of action systems for stepwise reﬁnement open the
doors to new analysis and prediction tools for better understanding what happens between
an administration of a drug dose and the body response.
Kaisa, in this paper we use "your" action systems in a ﬁeld you would have never pre-
dicted: pharmacokinetics. We miss you!
189

190
From Action Systems to Distributed Systems: The Reﬁnement Approach
13.1
Introduction
Pharmacokinetics is a branch of pharmacology that studies processes caused by sub-
stances (such as drugs, hormones, nutrients, or toxins) administered to a living organism,
from the moment of substance administration to the point of its complete elimination from
the body. Pharmacokinetics describes how the body aﬀects a speciﬁc drug after administra-
tion through the mechanisms of absorption and distribution, as well as the chemical changes
of the substance in the body, and the eﬀects and routes of its excretion.
Compartment models are typically used as mathematical models to describe level changes
of the drug concentration in our bodies [301]. Compartments are used to model drug con-
centration in body tissues by using diﬀerential equations for absorption, distribution, and
elimination rates. Compartment models exist for many types of drugs, absorption methods
(e.g. oral, intramuscular, intravenous), and elimination methods.
Compartment models are continuous-value models, based on systems of ordinary dif-
ferential equations that can be analyzed by examining a graph with compartments as node
and in-ﬂow/out-ﬂow rates labeling the arcs. However, pharmacokinetic models are not purely
continuous. They also use a ﬁnite state logic to decide, for example, when absorption stops,
when elimination starts, or when a process is triggered by cell death or division. As such
they involve continuous states and dynamics, as well as some discrete logic corresponding
to discrete states and dynamics. Because existing pharmacokinetic models often represent a
tradeoﬀamong accurately describing the data, having conﬁdence in the results, and math-
ematical tractability, the discrete logic of the system is often ignored.
In this paper we use hybrid action systems as a model of pharmacokinetics. Action
systems were originally proposed as a formalism for developing parallel and distributed sys-
tems [28]. They are based on a predicate transformer semantics for discrete computation,
where parallel composition is described by interleaving of atomic actions. In hybrid action
systems, computations may also continuously evolve over time [280, 281], and parallel com-
position is deﬁned by interleaving discrete actions and combining continuous ones.
While it appears useful to be able to describe and reason about properties of pharma-
cokinetic models using hybrid systems, we are not aware of any existing consistent attempts
to do so. In the last decade, there has been an increasing interest in quantitative and hybrid
models of computation based on systems of ordinary diﬀerential equations. However, all
models that we are aware of are concentrating on biological, bio-chemical, or bio-medical
processes. Examples of successful approaches in these areas include several process algebraic
languages [269, 166, 275, 95, 76, 83]. In this paper we take a novel alternative approach and
use hybrid action systems for a compositional construction of pharmacokinetic models. We
concentrate on the modelling aspects, but our framework allows properties of the systems
to be proven formally within the reﬁnement calculus [34, 281]. For example, in pharmacoki-
netics we deal with models for the study of a drug’s pharmacological eﬀect on the body.
Understanding what happens between the administration of a drug and the body’s response
could help in recommending a proper dosing regimen for that drug (how much, how often,
under what assumptions) with regard to a population, a subpopulation, or an individual
patient. Drug concentrations must be kept high enough to produce a desirable response,
but not so high that they produce toxic eﬀects. The problem is that current models are
so complex that it is diﬃcult to extract useful predictions from them. However, since the

Free ebooks ==>   www.Ebook777.com
Action Systems for Pharmacokinetic Modeling
191
magnitude of an eﬀect is proportional to the concentration of the drug, our action system
model could be used to prove that concentration always remain below the toxic level.
13.2
Actions and Action Systems
Let V ar be a countable set of variables and assume that each variable in V ar is associated
with a nonempty set of values. A state is a function mapping variables to values in their
respective associated set of values. We denote by true the predicate on V ar which holds for
every state, and by false the predicate on V ar which holds for no state. Given a predicate P
over V ar, a list of variables x and a list of values v, we denote by P[x/v] the predicate that
holds for those states s such that P holds for s[x/v], where s[x/v] is the state that maps the
variables x to the values v, but otherwise behaves as s.
A conjunctive predicate transformer is a function π mapping predicates to predicates
such that, for every nonempty index set I,
π
^
{Pi | i ∈I}

=
^
{π(Pi) | i ∈I} .
Conjunctive predicate transformers form the semantic domains for a class of statements,
called actions, interpreted by means of a weakest precondition semantics [113]. These should
be considered speciﬁcation statements rather than actual programs, as they need not be
strict, disjunctive, or preserving of directed disjunctions [36].
More syntactically we consider actions denoting conjunctive predicate transformers. We
deﬁne ordinary actions by the grammar
a
::=
abort | skip | x := v | b→a | p | a1 ; a2 | []Iai .
Here, x is a list of variables, v is a list of values (possibly resulting from the evaluation of
a list of expressions), b is a predicate over V ar, p is a procedure name, and I is an index
set ranged over by i. Intuitively, ‘abort’ is the action which models unwanted or disallowed
behaviour, ‘skip’ is a stuttering action (i.e. not changing the state), ‘x:=v’ represents multiple
assignment, ‘b→a’ is a guarded action that executes a only when the guard b holds, ‘p’ is a
procedure call, ‘a1 ; a2’ is the sequential composition of two actions ‘a1’ and ‘a2’, and ‘[]Iai’
is the nondeterministic choice among actions ‘ai’ for i ∈I.
A procedure declaration p = P consists of a header p and an action P—the body of
the procedure. Given a declaration for each procedure, we deﬁne the weakest precondition
semantics of the above language in a standard way [113, 36], as the least conjunctive predicate
transformer wp such that, for any predicate P,
wp(abort, P)
=
false
wp(skip, P)
=
P
wp(x := v, P)
=
P[x/v]
wp(b→a, P)
=
b ⇒wp(a, P)
wp(p, P)
=
wp(P, P)
wp(a1 ; a2, P)
=
wp(a1, wp(a2, P))
wp([]Iai, P)
=
∀i ∈I.wp(ai, P) ,
where P is the action denoting the body of the procedure p. The greatest conjunctive pred-
icate transformer satisfying the above is the weakest liberal precondition wlp(a, P) of an
action a with respect to the post-condition P. Various form of iterations and other simple
www.Ebook777.com

192
From Action Systems to Distributed Systems: The Reﬁnement Approach
statements can be encoded in the above language. For example, assertions {b} can be en-
coded as b →skip [] ¬b →abort: if the condition b does not hold in a given state, then the
assertion aborts, otherwise has no eﬀect. The details of the deﬁnition of the above functions
is studied elsewhere [61].
Further on we will need the following notions. An action a is enabled in a given state if
its guard
gd(a)
=
¬ wp(a, false)
holds in that state. For example, gd(b→x := v) = b. An action a terminates in a given state
if t(a) = wp(a, true) holds in that state. An action a1 cannot enable another action a2 if
t(a1) = true
and
¬ gd(a2) ⇒wp(a1, ¬ gd(a2)) .
Moreover, a1 cannot disable a2 whenever
t(a1) = true
and
gd(a2) ⇒wp(a1, gd(a2)) .
Actions that capture continuous-time dynamics are called diﬀerential actions [281]. They
act not only on ordinary variables, but also on some evolution variables in EV ar. Evolution
variables describe the observation of an evolution but not its relation with respect to time. As
such, they take values in the set of real numbers R. A diﬀerential action, written as e :→d,
describes the evolution in time according to the predicate d of both evolution and ordinary
variables from their initial value (as given by a state) to the values they reach when the
guard e does not hold. The evolution guard e is a predicate over V ar and a list X = x1 · · · xn
of evolution variables. In this paper we consider the predicate d to be a partially deﬁned
system of diﬀerential equations of the form ˙X = F(X), where ˙X is a syntactic variant used
to denote the component-wise ﬁrst derivative of the variables in X.
A continuous function f :R →Rn with a continuous ﬁrst derivative ˙f is a solution for
e :→d, denoted by SF(f , e :→d), if f (0) = X (the current value of the variables) and for
every positive r ∈R, if the guard e is true then it satisﬁes the system of diﬀerential equations
d. More formally
SF(f , e :→d) ≡f (0) = X ∧∀r ∈[0, ∞). (e ⇒d)[f (r)/X, ˙f (r)/ ˙X]
The ﬁrst point in time, if any, when the guard e does not hold, give the duration ∆(f , e)
of a diﬀerential action. In other words, ∆(f , e) = inf{r ∈[0, ∞) | ¬e[f (r)/X]}.
For a postcondition P over X and V ar, the weakest precondition of a diﬀerential action
is the smallest set of states (assignments to X and V ar) for which the evolution of e :→d
is guaranteed to terminate in a state satisfying P. More formally,
wp(e :→d, P) ≡∀f .(SF(f , e :→d) ∧∆(f , e) > 0 ⇒
∆(f , e) < ∞∧P[f (∆(f , e))/X] )
As for ordinary action, we say that a diﬀerential action e :→d is enabled if gd(e :→d) =
¬ wp(e :→d, false) holds, and that it terminates if t(e :→d) = wp(e :→d, true) holds. En-
abledness holds in states where there is evolution (i.e. gd(e :→d) ⇒e) and termination holds
exactly when all evolutions terminate. Since wp(e :→d, P) = wp(gd(e :→d) :→d, P) [281],
we will only consider stutter free diﬀerential actions [280], that is, diﬀerential actions e :→d
that are enabled exactly when there is evolution (i.e. gd(e :→d) = e). Finally, the weakest
precondition of a diﬀerential action is a conjunctive predicate transformer. These and other
interesting results on diﬀerential actions are studied in, e.g. [281].

Action Systems for Pharmacokinetic Modeling
193
13.2.1
Action Systems
Action systems are a formalism for developing parallel and distributed systems originally
proposed in [28]. We will consider here hybrid action systems [281]. They consist of a set of
ordinary and diﬀerential actions operating on local and global (evolution) variables. First,
the variables are created and initialized. Then, repeatedly, enabled actions are chosen and
executed. Actions operating on disjoint sets of variables can be executed in any order. The
execution terminates if no action is enabled, otherwise it continues inﬁnitely.
Syntactically, an action system A is a statement of the form
A
=
|[
var
Y ∗:= V ; X := U
proc
p1 = P1 ; . . . ; pm = Pm
do A1 [] . . . [] An od
]|
: Z
An action system provides a declaration section for variables and one for procedures. Here Y
is a list of global (evolution) variables, marked with an asterisk ∗, that can be used locally by
A and also by other action systems when put in parallel with A. The (evolution) variables
in the list X are local to A. The global variables Y get initial values componentwise from
the list V and the local variables x get initial values componentwise from the list U. Finally,
Z is the list of imported variables, i.e. global variables declared in action systems that can
be put in parallel with A. We assume that X, Y , and Z are disjoint.
A procedure declared as pi = Pi is local and can be called only by the ordinary actions
of A which can thus enable or disable the body Pi. Actions of the action system A are the
actions A1, . . . An and the bodies of all procedures declared in A. Each action Ai can be
either an ordinary action a as deﬁned above, or a diﬀerential action e :→d. All actions of
A can refer to (evolving) variables which are in X, Y , or Z. Actions are atomic, meaning
that if an action Ak is chosen for execution, then it is executed to completion.
Action systems are models of reactive systems. The behaviour of an action system is
described by the set of all its computations. A computation here is a ﬁnite or inﬁnite sequence
of states (i.e. maps of global variables to values), without ﬁnite repetition (i.e. no ﬁnite
stuttering), possibly terminating with a special symbol to denote abortion [25].
To model the dynamics of a system consisting of several reactive components, action
systems are equipped with a parallel composition operation: global variables are merged
together, local variables are kept separate, and the imported variables will consist of all
variables imported by one component that are not declared as global in the other. Procedures
are local, and thus kept separate, whereas actions are combined non-deterministically, thus
modelling parallelism by interleaving [25].
13.2.2
Hybrid Action Systems
While parallel composition of action systems works ﬁne with ordinary actions that have
no duration in time, interleaving of diﬀerential actions does not model true concurrent
evolution. Parallel composition of diﬀerential actions can be deﬁned as the linear composition
‘⊕’ of two partially deﬁned functions [280]: their values are added together on their common
domain, and remain unchanged on the remaining domains.
e1 :→˙X = F(X) ⊕e2 :→˙X = G(X)
=
e1 ∧
e2 :→˙X = F(X) + G(X)
[]
e1 ∧¬e2 :→˙X = F(X)
[] ¬e1 ∧
e2 :→˙X = G(X)

194
From Action Systems to Distributed Systems: The Reﬁnement Approach
We want the dynamics of a hybrid action system to be an alternation between ordinary
actions and diﬀerential ones, so that in a parallel composition we can linearly compose
the continuous-time diﬀerential actions and interleave the discrete-time ordinary actions. A
hybrid action system A is a statement of the form
A
=
|[
var
Y ∗:= V ; X := U
proc
p1 = P1 ; · · · ; pn = Pn
alt A with D
]|
: Z
where A is a non-deterministic composition of ordinary actions a1 [] . . . [] an, D is the non-
deterministic composition of diﬀerential actions e1 :→d1 [] . . . [] en :→dn, and alt A with D
is their alternation, deﬁned as
do A [] ¬gd(A)→D od
When gd(D) is false we just write ‘alt A’, and when gd(A) is false we just write ‘with A’.
A computation of a hybrid action system is, a ﬁnite or inﬁnite sequences of evolution states
(mapping evolution variables to R), interleaved with ordinary states (mapping of evolution
variables to values).
We conclude by recalling the deﬁnition of parallel composition of hybrid action sys-
tems [280, 281]. Consider the action systems Ai for i = 1, 2:
Ai
=
|[
var
Y ∗
i := Vi ; Xi := Ui
proc
pi,1 = Pi,1 ; . . . ; pi,ni = Pi,ni
alt Ai with Di
]|
: Zi
where the global variables, local variables, and the local procedure headers declared in each
action system Ai are required to be distinct. The parallel composition A1 || A2 is deﬁned as
the action system
|[
var
(Y ∗
1 := V1 ; Y ∗
2 := V2 ; X1 := U1 ; X2 := U2)
proc
p1,1 = P1,1 ; . . . ; p1,n1 = P1,n1 ; p2,1 = P2,1 ; . . . ; p2,n2 = P2,n2
alt A1 [] A2 with D1 ⊕D2
]|
: (Z1 ∪Z2)\(Y1 ∪Y2)
13.3
Pharmacokinetic Modeling
The pharmacokinetics of a drug is a very complex biological process and there are no
exact mathematical models for describing the concentration of a drug at any time in any part
of the body. Pharmacometricians approximate the physiological process of the interactions
between an organism and a drug by a compartmental model. Compartments represent the
ﬂuids and tissues of the human body, and each of them is assigned with input and output
rates modeling the process of absorption and removal of the drug with regard to the tissues.
This method is known as the ADME modeling scheme [223]:

Action Systems for Pharmacokinetic Modeling
195
(a) Absorption
(b) Distribution
(c) Elimination
Figure 13.1: ADME scheme
• Absorption - the process of a substance movement to the blood stream.
• Distribution - the dispersion or dissemination of substances throughout the ﬂuids and
tissues of the body.
• Metabolization - the recognition by the organism that a foreign substance is present
and the irreversible transformation of parent compounds into daughter metabolites.
• Excretion (or elimination) - the removal of the drug from the body. In rare cases, some
drugs irreversibly accumulate in body tissue.
A drug can be given to a patient in several ways, e.g. intravenously, orally, subcuta-
neously, intramuscularly, with a skin patch, or by inhalation. Intravenous administration
does not involve absorption and, hence, there is no loss of the drug. On the other hand, with
oral administration, several factors aﬀect the absorption of a drug: solubility and permeabil-
ity, gastrointestinal pH, gastric emptying time, small intestinal transit time, etc. [311]
The fraction of an administered dose of unchanged drug that reaches the systemic circu-
lation is known as bioavailability and is one of the principal pharmacokinetic properties of
a drug. After absorption, most of the drug is distributed via the blood to the body tissues.
Distribution describes the reversable transfer of the drug between blood, tissues, and organs.
The drug is more easily distributed in highly perfused organs such as heart, brain, lungs,
liver, and kidney than in poorly perfused tissues such as fat, skin, and muscles.
Metabolization refers to the bio-transformation of the drug to other molecules—called
metabolites—inside the body. Metabolites are normally pharmacologically inactive, but they
can be active or toxic. Some drugs remain inactive until metabolized. The principal organ
involved in excretion of a drug is the kidney, which eliminates water soluble drugs with
urine. Bio-ﬂow from the liver is also an important route for the elimination of a drug. Drugs
also leave the body via other natural routes: breath, tears, sweat, and saliva.
About half of the human body weight is water. Water is eliminated from the body in
urine, with about 6 liters of water passing through the kidney ﬁlter per hour. Thus, we
can model this process as a ﬁlled up tank with a tap and an open plug where the ﬂow
through the tap equals the ﬂow through the plug hole. We can think of water ﬂowing in the
blood-stream through the kidneys as water in the tap. Now imagine adding some drug to
the water. The speed with which the drug distributes through the tank can represent the
process of drug absorption (Figure 13.1a). How the drug penetrates to the peripheral tanks
can represent the distribution process (Figure 13.1b). Finally, the elimination process can
be represented by the ﬂow out of the tank through the plug hole (Figure 13.1c).

196
From Action Systems to Distributed Systems: The Reﬁnement Approach
The pharmacokinetics compartment model assumes that the drug concentration is per-
fectly homogenous in each compartment of the body at all times. Thus, we also assume
that the drug concentration is homogenous at each time in each tank. This is a strong as-
sumption but it allows a quantitative description of the pharmacokinetics processes. The
quantitative pharmacokinetic model describes how the drug amount varies in each compart-
ment, or equivalently, how the drug amount varies in each water tank. Such a description
mainly reduces to three main components:
• Rate in describes how the drug moves to the blood stream (or how the drug moves to
the main tank)
• Rate of distribution describes the movement of a drug between the compartments (or
the distribution of the drug between tanks)
• Rate out describes how the drug is eliminated from the body (or how the drug ﬂows
out of the main tank)
Absorption, distribution, and elimination are continuous processes limited by the physio-
logical limitation of the tank, and the administered dose of the drug. Using the chemical
balance law
rate of change = input rates - output rates
distribution can be described in terms of the other two components of each compartment.
The pharmakinetics model of the system combines all these rates for each compartment into
a single large system of diﬀerential equations. Next we describe in more detail the absorption
and elimination processes, and give an example of their models as action systems.
13.3.1
Absorption
Absorption starts right from the beginning and stops when the amount of drug in the
entire system is a bioavailability fraction 0 ≤f ≤1 of the administered dose (denoted dose).
We use the local Boolean variable abs to record whether absorption takes place or not,
and the global variable dose to record the amount of administered dose of the drug. The
global evolution variable x describes the amount of drug present in the tissue modeled by a
compartment (here, for example, blood), and it is dependent on time t.
Intravenous administration bypasses the absorption phase: the entire drug dose enters
the general circulation (bioavailability fraction f = 1). We distinguish intravenous bolus
administration and intravenous infusion. In the ﬁrst case, the drug is administrated through
the intravenous route in a negligible time and achieves instantaneous distribution throughout
the central compartment. Thus, just before the administration, the amount of drug is 0, and
just after administration the amount equals the administered dose (Figure 13.2a). In the
case of intravenous infusion, the dose is administered with a constant rate during some time
of infusion T (Figure 13.2b).
With oral administration of a drug (e.g. in tablet, capsule, or liquid form), the entire
dose does not reach the systemic circulation (f < 1) due to factors such as breakdown in the
intestine, poor absorption, and pre-systemic extraction. When swallowed, the drug enters the
gastrointestinal tract and is then absorbed to the blood stream. The simple pharmacokinetic
model considers the gut as a depot compartment that receives the dose. Describing the
absorption process then reduces to describing how the dose is transferred from the depot

Action Systems for Pharmacokinetic Modeling
197
(a) Bolus
(b) Infusion
Figure 13.2: Intravenous administration
(a) Zero-order absorption
(b) First-order absorption
Figure 13.3: Oral administration
compartment to the central blood compartment. In a zero-order absorption process (see
Figure 13.3a), a drug is absorbed over time-period T with a constant rate k0 = dose/T. In
a ﬁrst-order absorption process (see Figure 13.3b), the absorption rate is proportional to the
amount of drug in the depot compartment. The proportionality constant is usually denoted
ka.
For example, let us consider oral administration of a drug, assuming the mono-
exponential rate of transfer to the blood circulation given by dx/dt = f · dose · kae−ka·t,
where f is the fraction of bioavailability and ka is the proportionality constant. Absorption
into the blood can then be modeled as the following hybrid action system:
Absorption
=
|[
var
abs∗:= true
alt abs ∧x ≥f · dose→abs := false
with abs ∧x < f · dose :→˙x = f · dose · kae−ka·t
]|
: dose, x
According to the above diﬀerential equation, the amount of drug in the blood stream at
time t is given by x(t) = ef ·dose·kat. Here t ranges from 0 to the ﬁrst point in time when x(t)
is not smaller than the bioavailability fraction of the administered dose.

198
From Action Systems to Distributed Systems: The Reﬁnement Approach
(a) Linear elimination rate
(b) Drug concentration
Figure 13.4: First-order elimination process
(a) Saturable elimination rate
(b) Drug concentration
Figure 13.5: Mixed elimination process
13.3.2
Elimination
As soon as drug concentration is above a certain threshold, the elimination process
starts. Elimination is modeled by opening the plug of a water tank. We assume that the
concentration of the drug that comes out of the tank at any time equals the concentration
of the drug in the tank. There are several mathematical models to describe the elimination
process. With ﬁrst-order (linear) elimination, the elimination rate is directly proportional to
the plasma concentration (Figure 13.4a). Thus, the amount of the drug in the tank decreases
with a decreasing rate (Figure 13.4b).
With saturable elimination, the elimination rate increases with the increase in the concen-
tration until a certain concentration is reached, after that the elimination rate stays constant
(Figure 13.5a). Such capacity-limited elimination is known as a mixed-order process. The
corresponding drug amount over time is shown in Figure 13.5b: the amount decreases with
a rate which, at ﬁrst, is almost constant and then slows down to resemble linear elimination.
For example, in a zero-order one-compartment model, let us assume that the drug elimi-
nation rate is dx/dt = kx, for some constant k>0. An action system modeling the elimination
processes is as follows:
Elimination
=
|[
var
x∗:= 0
with x > min :→˙x := −k · x
]|
:
where min is a threshold of minimal amount of drugs in the blood-stream before starting,
so that the amount of drugs at time t is deﬁned by the function x(t) = x0e−kt in terms of
the initial amount x0 at time 0.

Action Systems for Pharmacokinetic Modeling
199
13.3.3
One-Compartment Model
The overall rate of change of the amount of drugs in a single compartment over time is
the combination of the rate in and the rate out. In this simpliﬁed model, distribution does
not play a role.
The overall pharmacokinetic model is obtained through the parallel composition of the
hybrid action systems modeling absorption and elimination of that compartment. Continuing
our example we have
BloodTank = Absorption || Elimination
Unfolding the deﬁnition we obtain the following one-compartment model of drug concentra-
tion in blood from an oral administration:
BloodTank = |[var
abs∗:= true, x∗:= 0
alt abs ∧x ≥f · dose→abs := false
with abs ∧min < x < f · dose :→˙x = f · dose · kae−ka·t −k · x
[]abs ∧x ≤min ∧x < f · dose :→˙x = f · dose · kae−ka·t
[](¬abs ∨x ≥f · dose) ∧x > min :→˙x = −k · x
]|: dose
The ﬁrst diﬀerential equation gives the concentration of drug in the blood-stream when
the drug is absorbed and eliminated at the same time. Until the minimal concentration is
reached, only absorption takes place (as we see in the second diﬀerential equation). The
third diﬀerential action represents elimination when absorption is terminated.
13.3.4
Distribution
The above standard pharmacokinetics equations for one-compartment models are rather
simple. Many categories of drugs, however, cannot be accurately characterized by one-
compartment models. For example, the eﬀects of anesthetic drugs greatly depend on distri-
bution of the active substance into and out of peripheral tissues. To reﬂect the diﬀerences in
perfusion of tissues, several compartments are used in the pharmacokinetic model. In this
case, the construction of a certain pharmacokinetic model consists of choosing a model for
absorption (or distribution) and elimination for each compartment from the current models
pharmacometricians have developed (Figure 13.6a), and which have already been validated
against observations in clinical studies (Figure 13.6). For example, the DDMoRe model
repository1 is a place where pharmacokinetic models can be stored, retrieved, and shared
with the community.
A multi-compartment model can be translated into the parallel composition of hybrid
action systems, each modeling a single compartment. Using one global evolution variable for
each compartment, we can describe the amount of a drug present, assuming circular drug
distribution among compartments, e.g. as in the case when drug metabolites are reabsorbed
from kidneys along with water before they are excreted in the urine.
The overall rate of change of the amount of a drug in the body over time is the combi-
nation of the rate in, in, the rate of distribution, and the rate out.
1http://repository.ddmore.eu

200
From Action Systems to Distributed Systems: The Reﬁnement Approach
(a) ADME model
(b) Predictions vs. observations
Figure 13.6: Pharmacokinetic modeling
13.4
Conclusions and Future Work
In this paper, we propose action systems as precise models of the compositional seman-
tics of pharmacokinetic processes. For simple compartmental models, we found no need to
develop new extensions for action systems, as existing work on continuous and hybrid ac-
tions ﬁt perfectly. However, we have not fully explored the potential of action systems for
reasoning about pharmacokinetic (and pharmacodynamic) processes. In particular, it will
be interesting to prove properties of such systems formally within the reﬁnement calcu-
lus [34, 281].
We are planning to use hybrid action systems in the context of the ApiNATOMY project2
to automatically combine and formally analyze quantitative descriptions of physiological pro-
cesses across multiple scales. A method central to the ApiNATOMY eﬀort is the visualiza-
tion of ontology terms as tiles in a treemap, which allows us to automatically generate body
plans from given ontologies, preserving spatial relations among selected components [100].
Metadata related to ontology terms is represented in the form of objects associated with
tiles as well as visual connections between tiles and their associated objects. To be able
to generate views which are of interest to a user, we need to employ compositional formal
models of related processes. Action systems represent a promising framework for our goal.
As future work, we will employ action systems to model and control heterogeneous sets
of independently developed pharmacokinetic and pharmacodynamic models, e.g. as in the
alcohol consumption process described by de Bono and Hunter [101]. Each of the individual
models can be represented by a separate hybrid action system combining both discrete and
continuous logic, which are then assembled into a complete process using sequential, parallel,
or guarded choice composition operators deﬁned for action systems.
2http://www.apinatomy.org

Free ebooks ==>   www.Ebook777.com
Chapter 14
Quantitative Model Reﬁnement in Four
Diﬀerent Frameworks, with Applications to
the Heat Shock Response
Diana-Elena Gratie
Turku Centre for Computer Science and Åbo Akademi University, Turku, Finland
Bogdan Iancu
Turku Centre for Computer Science and Åbo Akademi University, Turku, Finland
Sepinoud Azimi
Turku Centre for Computer Science and Åbo Akademi University, Turku, Finland
Ion Petre
Turku Centre for Computer Science and Åbo Akademi University, Turku, Finland
14.1
Introduction ......................................................
202
14.2
Quantitative Model Reﬁnement .................................
203
14.3
Case Study: The Heat Shock Response (HSR) ..................
205
14.4
Quantitative Reﬁnement for ODE Models .......................
208
14.5
Quantitative Reﬁnement for Rule-Based Models ................
209
A BioNetGen Implementation of the HSR Model ...............
209
14.6
Quantitative Reﬁnement for Petri Net Models ..................
210
The Basic HSR Model as a Petri Net ............................
210
The Reﬁned HSR Model as a Colored Petri Net ................
210
14.7
Quantitative Reﬁnement for PRISM Models ....................
211
The HSR Models as PRISM Implementations ...................
212
Stochastic Model Checking of the PRISM HSR Models .........
212
14.8
Discussion ........................................................
213
Acknowledgments ...................................................
214
Abstract. Quantitative model reﬁnement is an essential step in the model development
cycle. Starting with a high level, abstract representation of a biological system, one often
needs to add details to this representation to reﬂect changes in its constituent elements. Any
such reﬁnement step has two aspects: one structural and one quantitative. The structural
aspect of the reﬁnement deﬁnes an increase in the resolution of its representation, while
the quantitative one speciﬁes a numerical setup for the model that ensures its ﬁt preserva-
tion at every reﬁnement step. We discuss in this paper the implementation of quantitative
model reﬁnement in four extensively used biomodeling frameworks: ODE-based models,
201
www.Ebook777.com

202
From Action Systems to Distributed Systems: The Reﬁnement Approach
rule-based models, Petri net models, and guarded command language models, emphasizing
the speciﬁcity for every model implementation. We argue that quantitative model reﬁne-
ment is framework-independent, being implementable in all chosen frameworks despite their
diﬀerent underlying modeling paradigms.
14.1
Introduction
Research in molecular biology has been traditionally conducted targeting individual
molecular entities of a biological system. Discovery of the functional speciﬁcity of these
molecular entities has brought about tremendous progress in the understanding of biolog-
ical systems. However, the understanding of individual molecules alone does not suﬃce to
tackle complex biological phenomena, such as those involved in diseases. Systems biology
promotes precisely an integrative bottom-up approach for the analysis of such systems,
which takes advantage of previous knowledge about individual proteins, but which is essen-
tially concerned with a holistic analysis of the system: understanding the structure and the
dynamics of the system, see [273, 201]. Moreover, in the past decades, we have witnessed
a convergence of the ﬁelds of computer science and biology towards a new ﬁeld that is
expanding evermore, bioinformatics, see [270].
At the core of systems biology lies the concept of computational modeling, driven by
the production of massive sets of experimental data which necessitate computer analysis,
see [237]. In this context, formal frameworks prove to be essential in the synthesis and
analysis of large biological models as an eﬀort to predict the system-level behavior of such
systems. This approach commences with an abstraction of the biological phenomena, which
is ultimately converted into a model derived through an iterative process of model building
involving system design, model analysis, hypothesis generation, hypothesis testing, experi-
mental veriﬁcation, and model reﬁnement, see [273]. The model obtained as such very often
needs to be reﬁned to include more details regarding some of its biological processes, encap-
sulating presumably new experimental data over a number of new parameters. A reiteration
of the whole process of quantitative model ﬁtting and validation is, however, unfeasible
for a large model. The alternative we discuss in this paper is that of quantitative model
reﬁnement.
Quantitative model reﬁnement focuses on the step-wise construction of models, from
small abstract models to large, detailed ones. Each reﬁnement step consists of two parts.
The structural part of the reﬁnement consists of ﬁxing the details to add to the model
(e.g., new attributes in existing species, new species, new interactions, new modules, etc.)
and identifying the new set of species and interactions yielded by adding these details. The
quantitative part of the reﬁnement consists in ﬁxing the numerical setup of the reﬁned model
(kinetic parameters and initial values) in such a way that the quantitative behavior of the
model, in particular its experimental ﬁt, remains unchanged.
The goal of this paper is to give an overview of our approach to quantitative model
reﬁnement. We introduce ﬁrst the main mathematical concepts we use in our framework:
reaction-based model, reﬁnement relation, structural reﬁnement, and quantitative reﬁne-
ment. We then discuss the implementation of model reﬁnement in four of the most widely
used approaches in biomodeling: ODE-based models, rule-based models, Petri net models,
and guarded command models. The structural part of the reﬁnement has a diﬀerent solution

Quantitative Model Reﬁnement in Four Diﬀerent Frameworks
203
in each approach, in some cases leading to a compact representation of the reﬁned models.
The quantitative part of the reﬁnement aims to avoid the computationally expensive pro-
cedure of parameter estimation (especially since the models get larger in each reﬁnement
step); instead, we apply in each approach the suﬃcient condition recently proposed in [143].
As a case study, we consider the heat shock response in eukaryotes. We refer to the model
in [263] as the basic heat shock response model and to the model in [176] as its reﬁned model.
A short version of this paper was presented in [178].
The paper is organized as follows: we discuss the concept of ﬁt-preserving reﬁnement in
Section 14.2. We succinctly describe in Section 14.3 the heat shock response and its underly-
ing reaction-based model. We focus in Section 14.4 on the reﬁnement of ODE-based models.
In Section 14.5, we present rule-based modeling and the rule-based implementation of the
heat shock response and of its corresponding reﬁnement. In Section 14.6, we discuss Petri
nets and their capabilities with regards to the implementation of the heat shock response and
its reﬁnement to include acetylation using colored Petri nets. Section 14.7 comprises a brief
description of guarded command languages, focusing on PRISM, and a discussion regarding
the implementation of the basic and the reﬁned model for the heat shock response. We
conclude the paper with a discussion in Section 14.8. All models developed in this chapter
can be downloaded at [177].
14.2
Quantitative Model Reﬁnement
Model reﬁnement has been extensively investigated in the ﬁeld of software engineering,
especially in connection to parallel computing. For example, among other approaches, such
studies brought about a logical framework for the construction of computer programs, called
reﬁnement calculus. This framework tackles the derivation of computer programs correct
by construction and reﬁnement of computer programs ensuring correctness preservation,
see [38].
Quantitative model reﬁnement is a concept introduced in systems biology as an approach
to step-wise construction of biomodels. It focuses on preserving the quantitative behavior of
such models, especially their model ﬁt, while avoiding parameter estimation in the context
of the combinatorial explosion in the size of the models. Quantitative model reﬁnement was
introduced for rule-based models in [251, 94] and for reaction-based models in [247, 176].
We introduce in the following the quantitative reﬁnement of reaction-based models following
the approach of [143] based on reﬁnement relations.
A model M comprises species Σ = {A1, . . .,Am} and reactions R = {r1, . . . , rn}, where
reaction rj ∈R can be expressed as a rewriting rule of the form:
rj : s1,jA1 + . . . + sm,jAm
krj
−−→s′
1,jA1 + . . . + s′
m,jAm,
(14.1)
where s1,j, . . . , sm,j, s′
1,j, . . . , s′
m,j ∈N are the stoichiometric coeﬃcients of rj and krj ≥0 is
the kinetic rate constant of reaction rj. We denote by r(1)
j
= [s1,j, . . . , sm,j] the vector of
stoichiometric coeﬃcients on the left hand side of reaction rj and by r(2)
j
= [s′
1,j, . . . , s′
m,j]
the vector of stoichiometric coeﬃcients on its right hand side. We also denote reaction rj as
r(1)
j
krj
−−→r(2)
j
.

204
From Action Systems to Distributed Systems: The Reﬁnement Approach
The goal of the reﬁnement is to introduce details into the model, in the form of dis-
tinguishing several subspecies of a given species. The distinction between subspecies may
represent post-translational modiﬁcations such as phosphorylation, acetylation, etc., but it
could also account for diﬀerent possible types of a particular trait (e.g., fur color of animals
in a breeding experiment).
We consider that all species are reﬁned at once. Thus, each species in some initial model
M will be replaced by a non-empty set of species in its reﬁned model MR, according to a
species reﬁnement relation ρ. The reﬁnement of a set of species to a new set of [sub]species
is formalized in Deﬁnition 14.1.
Deﬁnition 14.1 ([143]). Given two sets of species Σ and Σ′, and a relation ρ ⊆Σ × Σ′, we
say that ρ is a species reﬁnement relation iﬀit satisﬁes the following conditions:
1. for each A ∈Σ there exists A′ ∈Σ′ such that (A, A′) ∈ρ;
2. for each A′ ∈Σ′ there exists exactly one A ∈Σ such that (A, A′) ∈ρ.
We denote ρ(A) = {A′ ∈Σ′ | (A, A′) ∈ρ}. We say that all species A′ ∈ρ(A) are siblings.
Intuitively, each species A ∈Σ is reﬁned to the set of species ρ(A), and replaced in the
reﬁned model with its reﬁnements. Each species must be reﬁned to at least a singleton set
(and in the singleton case one may say that the reﬁnement is trivial and the species does
not change, although it may be denoted by a diﬀerent symbol in Σ′), and no two species in
Σ can be reﬁned to the same species A′ ∈Σ′.
We introduce in the following deﬁnition the reﬁnement of a vector (of stoichiometric
coeﬃcients), of a reaction, and of a reaction-based model.
Deﬁnition 14.2 ([143]). Let Σ = {A1, . . . , Am} and Σ′ = {A′
1, . . . , A′
p} be two sets of
species, and ρ ⊆Σ × Σ′ a species reﬁnement relation.
1. Let α = (α1, . . . , αm) ∈NΣ and α′ = (α′
1, . . . , α′
p) ∈NΣ′. We say that α′ is a ρ-
reﬁnement of α, denoted α′ ∈ρ(α), if
P
1≤j≤p
A′
j∈ρ(Ai)
α′
j = αi, for all 1 ≤i ≤m.
2. Let r and r′ be two reactions over Σ and Σ′, resp.:
r : s1A1 + . . . + smAm
kr
−→s′
1A1 + . . . + s′
mAm;
r′:t1A′
1 + . . . + tpA′
p
k′
r
−→t′
1A′
1 + . . . + t′
pA′
p.
We say that r′ is a ρ-reﬁnement of r, denoted r′ ∈ρ(r), if
r′
j
(1) ∈ρ(r(1)
j
) and r′
j
(2) ∈ρ(r(2)
j
).
3. Let M = (Σ, R) and M ′ = (Σ′, R′) be two reaction-based models, and ρ ⊆Σ × Σ′ a
species reﬁnement relation. We say that M ′ is a ρ-structural reﬁnement of M, denoted
M ′ ∈ρ(M), if
R′ ⊆S
r∈R ρ(r) and ρ(r) ∩R′ ̸= ∅, ∀r ∈R.
In case R′ = S
r∈R ρ(r), we say M ′ is the full structural ρ-reﬁnement of M.

Quantitative Model Reﬁnement in Four Diﬀerent Frameworks
205
Let A be a species with stoichiometry coeﬃcient s in a reaction r, that is reﬁned to a set
of species ρ(A). There are
| ρ(A) |
s

ways of choosing s species (not necessarily distinct)
from the reﬁned set ρ(A), where
n
k

=
 n+k−1
k

is the multiset coeﬃcient, denoting the
number of multisets of cardinality k taken from a set of cardinality n. It follows that the
number of all possible ρ-reﬁnements of a reaction r of the form (14.1) is
m
Y
i=1
| ρ(Ai) |
si

·
| ρ(Ai) |
s′
i

.
(14.2)
We introduce in the following deﬁnition the notion of quantitative reﬁnement of a model.
We denote by [A](t) the concentration of species A at time t. Associating time-dependent
concentration functions to the variables of a model can be done either directly from the
reaction model by choosing a kinetic law for each reaction, see, eg., [204], or by translating
the reaction model to another modeling framework, such as Petri nets, rule-based model, or
guarded command language, and using a suitable semantic for that translation.
Deﬁnition 14.3 ([176, 143]). Given two reaction-based models M = (Σ, R) and M ′ =
(Σ′, R′) and a species reﬁnement relation ρ ⊆Σ × Σ′ such that M ′ is a ρ-reﬁnement of M,
we say that M ′ is a quantitative ρ-reﬁnement of M if the following condition holds:
[A](t) =
X
B∈ρ(A)
[B](t), for all A ∈Σ, t ≥0.
(14.3)
A simple suﬃcient condition for a model M ′ to be a quantitative reﬁnement of a model
M is given in [143].
14.3
Case Study: The Heat Shock Response (HSR)
The heat shock response is a cellular defence mechanism against stress (high tempera-
tures, toxins, bacterial infection, etc.) that is highly conserved among eukaryotes. We con-
sider here the heat shock response model proposed in [263], consisting of the set of reactions
listed in Table 14.1.
Upon exposure to stress, proteins misfold (reaction (10) in Table 14.1) or aggregate
into multi-protein complexes that impair cellular functions up to cell death; the ﬂux of the
misfolding reaction depends exponentially on the temperature. To counter these proteotoxic
eﬀects of thermal stress the expression of a special family of molecular chaperones, called
heat shock proteins (hsp’s), increases. The chaperone role of hsp’s is to bind to misfolded
proteins and assist them in their correct refolding (reactions (11),(12) in Table 14.1) thus
preventing multi-protein aggregation and cell death.
Table 14.1: The molecular model of the eukaryotic heat shock response proposed in [263].
No. Reaction
No. Reaction
(1) 2 hsf ⇄hsf2
(7)
hsp + hsf3 →hsp:hsf +2 hsf

206
From Action Systems to Distributed Systems: The Reﬁnement Approach
Table 14.1: The molecular model of the eukaryotic heat shock response proposed in [263] -
Continued
(2) hsf + hsf2 ⇄hsf3
(8)
hsp + hsf3:hse →hsp:hsf +2 hsf + hse
(3) hsf3 + hse ⇄hsf3:hse
(9)
hsp →∅
(4) hsf3:hse →hsf3:hse + hsp
(10) prot →mfp
(5) hsp + hsf ⇄hsp:hsf
(11) hsp + mfp ⇄hsp:mfp
(6) hsp + hsf2 →hsp:hsf + hsf
(12) hsp:mfp →hsp + prot
The expression of hsp’s is regulated by a family of proteins called heat shock transcription
factors (hsf’s). In a trimeric state (hsf3) they bind to heat shock elements (hse’s - the hsp-
encoding gene promoter regions), forming hsf3:hse complexes, and activate the transcription
of hsp’s, process modeled through reactions (1)-(4) in Table 14.1. The concentration levels
of hsf3:hse measure the DNA binding activity. Reaction (4) implies that with a higher level
of DNA binding we get a faster transcription/synthesis of hsp. The hsp’s downregulate their
expression levels by binding to hsf3:hse’s, hsf3’s, hsf2’s, and hsf’s and breaking down the
complexes, thus stopping the expression activity (reactions (5)-(8)). The degradation of hsp
molecules is modeled in reaction (9).
The hsf protein can undergo post-translational modiﬁcations (phosphorylation, acetyla-
tion, sumoylation), some of which inﬂuence hsf binding activity, see [10]. In particular, the
acetylation of hsf’s plays a role in the attenuation of the heat shock response. We consider in
this paper the reﬁnement of hsf molecules as described in [176]. The reﬁnement considers the
acetylation status (ON/OFF) of hsf proteins. The order of acetylated sites is not important
in a compound with two or more hsf molecules, only their count. Thus,
• hsf is reﬁned to {rhsf(0), rhsf(1)},
• a dimer molecule hsf2 is reﬁned to {rhsf2
(0), rhsf2
(1), rhsf2
(2)},
• and a trimer molecule hsf3 is reﬁned to {rhsf3
(0), rhsf3
(1), rhsf3
(2), rhsf3
(3)},
where the superscript denotes the number of acetylated sites. This leads to an expansion
of the model from 10 species and 17 irreversible reactions to 20 species and 55 irreversible
reactions.
This reﬁnement can be described via the following species reﬁnement relation:
ρ ={(hse, rhse), (hsp, rhsp), (prot, rprot), (mfp, rmfp), (hsp:mfp, rhsp:rmfp),
(hsf, rhsf(0)), (hsf, rhsf(1)),
(hsf2, rhsf2
(0)), (hsf2, rhsf2
(1)), (hsf2, rhsf2
(2)),
(hsf3, rhsf3
(0)), (hsf3, rhsf3
(1)), (hsf3, rhsf3
(2)), (hsf3, rhsf3
(3)),
(hsp:hsf, rhsp:rhsf(0)), (hsp:hsf, rhsp:rhsf(1)),
(hsf3:hse, rhsf(0)
3 :rhse), (hsf3:hse, rhsf3
(1):rhse), (hsf3:hse, rhsf3
(2):rhse),
(hsf3:hse, rhsf3
(3):rhse)}.
The full set of the reﬁned reactions is given in Table 14.2.

Quantitative Model Reﬁnement in Four Diﬀerent Frameworks
207
Table 14.2: The list of reactions for the reﬁned model that includes the acetylation status
of hsf. A reaction (i.j) is a reﬁnement of reaction (i) of the basic model, see Table 14.1
No.
Reaction
(1.1)
2 rhsf(0) ⇄rhsf2
(0)
(1.2)
rhsf(0) + rhsf(1) ⇄rhsf2
(1)
(1.3)
2 rhsf(1) ⇄rhsf2
(2)
(2.1)
rhsf(0) + rhsf2
(0) ⇄rhsf3
(0)
(2.2)
rhsf(1) + rhsf2
(0) ⇄rhsf3
(1)
(2.3)
rhsf(0) + rhsf2
(1) ⇄rhsf3
(1)
(2.4)
rhsf(1) + rhsf2
(1) ⇄rhsf3
(2)
(2.5)
rhsf(0) + rhsf2
(2) ⇄rhsf3
(2)
(2.6)
rhsf(1) + rhsf2
(2) ⇄rhsf3
(3)
(3.1)
rhsf3
(0) + rhse ⇄rhsf(0)
3 :rhse
(3.2)
rhsf3
(1) + rhse ⇄rhsf3
(1):rhse
(3.3)
rhsf3
(2) + rhse ⇄rhsf3
(2):rhse
(3.4)
rhsf3
(3) + rhse ⇄rhsf3
(3):rhse
(4.1)
rhsf(0)
3 :rhse →rhsf(0)
3 :rhse + rhsp
(4.2)
rhsf3
(1):rhse →rhsf3
(1):rhse + rhsp
(4.3)
rhsf3
(2):rhse →rhsf3
(2):rhse + rhsp
(4.4)
rhsf3
(3):rhse →rhsf3
(3):rhse + rhsp
(5.1)
rhsp + rhsf(0) ⇄rhsp: rhsf(0)
(5.2)
rhsp + rhsf(1) ⇄rhsp: rhsf(1)
(6.1)
rhsp + rhsf2
(0) →rhsp: rhsf(0) + rhsf(0)
(6.2)
rhsp + rhsf2
(1) →rhsp: rhsf(0) + rhsf(1)
(6.3)
rhsp + rhsf2
(1) →rhsp: rhsf(1) + rhsf(0)
(6.4)
rhsp + rhsf2
(2) →rhsp: rhsf(1) + rhsf(1)
(7.1)
rhsp + rhsf3
(0) →rhsp: rhsf(0) +2 ∗rhsf(0)
(7.2)
rhsp + rhsf3
(1) →rhsp: rhsf(0) + rhsf(1) + rhsf(0)
(7.3)
rhsp + rhsf3
(1) →rhsp:rhsf(1) +2 ∗rhsf(0)
(7.4)
rhsp + rhsf3
(2) →rhsp: rhsf(0) +2 rhsf(1)
(7.5)
rhsp + rhsf3
(2) →rhsp:rhsf(1) + rhsf(1) + rhsf(0)
(7.6)
rhsp + rhsf3
(3) →rhsp:rhsf(1) +2 rhsf(1)
(8.1)
rhsp + rhsf(0)
3 :rhse →rhsp: rhsf(0) +2 rhsf(0) + rhse
(8.2)
rhsp + rhsf3
(1):rhse →rhsp:rhsf(1) +2 rhsf(0) + rhse
(8.3)
rhsp + rhsf3
(1):rhse →rhsp: rhsf(0) + rhsf(1) + rhsf(0) + rhse
(8.4)
rhsp + rhsf3
(2):rhse →rhsp:rhsf(1) + rhsf(1) + rhsf(0) + rhse
(8.5)
rhsp + rhsf3
(2):rhse →rhsp: rhsf(0) +2 rhsf(1) + rhse
(8.6)
rhsp + rhsf3
(3):rhse →rhsp:rhsf(1) +2 rhsf(1) + rhse
(9.1)
rhsp →∅
(10.1)
rprot →rmfp
(11.1)
rhsp + rmfp ⇄rhsp:rmfp

208
From Action Systems to Distributed Systems: The Reﬁnement Approach
Table 14.2: The list of reactions for the reﬁned model - Continued
(12.1)
rhsp:rmfp →rhsp + rprot
An ODE-based model for the basic HSR model was introduced and analyzed in [263]. A
similar model for the reﬁned HSR model was introduced in [176].
14.4
Quantitative Reﬁnement for ODE Models
The main problem quantitative model reﬁnement of ODE-based models tackles is to
identify the kinetic rate constants of the reﬁned model that lead to a solution of the reﬁne-
ment condition (14.3). An attempt to obtain all solutions of (14.3) would require solving
the system of ODEs corresponding to the mass-action model for the basic and the reﬁned
models; in general, this cannot be done analytically because the ODEs can be non-linear. An
alternative was proposed in the form of a suﬃcient condition in [143]. We recall that result in
the following. For two vectors of nonnegative integers α = (α1, . . . , αm), α′ = (α′
1, . . . , α′
m′),
we denote
α
α′

=
Qm
i=1 αi!
Qm′
j=1 α′
j!
.
Theorem 14.1 ([143]). Let Σ and Σ′ be two sets of species and ρ ⊆Σ × Σ′ a species
reﬁnement relation. Let M = (Σ, R) be a reaction-based model and M ′ = (Σ′, R′) be the
full structural ρ-reﬁnement of M; we use letters k (indexed with the reaction name) to
indicate the kinetic rate constants of M and letters k′ those of M ′. If for every α →β ∈R
and for any α′ ∈ρ(α) we have that
X
β′∈ρ(β)
k′
α′→β′ =
α
α′

kα→β,
(14.4)
then M ′ is a ﬁt-preserving data reﬁnement of M.
The solution thus obtained is evidently not unique. For example, in the heat shock
response reﬁned model the kinetic rate constants of all reactions involving at least one
form of acetylated hsf could be set to zero; such a choice would cancel the reﬁnement
since the inﬂuence of all acetylated variables would be ignored in the model. Theorem
14.1 allows one to choose a multitude of diﬀerent solutions. One can, for example, include
in the solution some parameter values that were obtained from experiments or literature,
while using condition (14.4) to choose suitable values for the remaining parameters. In
fact, condition (14.4) can also be used to check if a set of given parameter values (for all
parameters) leads to a ﬁt-preserving reﬁned model.
The main disadvantage of ODE-based models is that each species gets its own variable
and then its own ODE. The framework does not allow for the implicit speciﬁcation of some
of its variables, even when the semantic diﬀerence between them is minor (as it could be
between sibling subspecies). This leads to an explosion in the size of the reﬁned ODE-based

Quantitative Model Reﬁnement in Four Diﬀerent Frameworks
209
model with respect to the size of the basic ODE-based model. We discuss in the following
sections the model reﬁnement approach in three other widely used modeling frameworks. In
each case, we focus on whether a more compact speciﬁcation of the reﬁned model is possible.
14.5
Quantitative Reﬁnement for Rule-Based Models
Rule-based modeling is an approach for tackling the combinatorial explosion induced
by expanding reaction-based models. The key feature is that rules only specify those as-
pects of the input species that are critical for that interaction, while omitting all their other
attributes. The rules can be translated either into a set of ODEs, following a continuous,
deterministic interpretation, or into a stochastic process, following a stochastic, discrete in-
terpretation of the biological phenomena. Two description languages for the implementation
of such models are BioNetGen, see [57], and Kappa, see [93]. We use BioNetGen in the
following. We refer to [127, 128] for details on how models are represented in BioNetGen.
A BioNetGen input ﬁle, for instance, is essentially a description of the molecular species
and their components, reaction rules, kinetic rate constants, initial concentrations, and sim-
ulation commands. The reaction network generated by BioNetGen can be used to emulate
system’s dynamics deterministically or stochastically, see [309]. RuleBender is an open source
editor for rule-based models which allows for the construction of large models. The simula-
tion, based on a BioNetGen simulator, see [349], generates the reaction network, in SBML
and NET format, corresponding to the given rule-based model. Simulations can run either
deterministically, using ODEs, or stochastically, using SSA algorithms, see [309, 349].
A BioNetGen Implementation of the HSR Model
We discussed in [178] the implementation of the basic heat shock response model of [263]
with BioNetGen and RuleBender. The model can be found in [177]. All reactions in our
implementation follow the principle of mass action. The BioNetGen model consists of 12
rules, which produce 17 irreversible reactions; kinetic rate constants and initial values are
set according to [263]. For example, the RuleBender implementation of the dimerization of
hsf is illustrated in Figure 14.1. A deterministic simulation for the BioNetGen model revealed
identical simulation results for DNA binding for a temperature of 42◦C as the ODE-based
model in [263].
To implement in BioNetGen the reﬁnement described in Section 14.3 required only
one change: the addition of a site to hsf, having two possible states: acetylated and non-
acetylated. The initial concentrations were set conforming to [176]. For more details regard-
ing the implementation, we refer the reader to [178].

210
From Action Systems to Distributed Systems: The Reﬁnement Approach
Figure 14.1: A graphical representation of the species hsf (containing sites ‘s’,‘u’,‘v’,‘w’) and
of the rule showing the dimerization of hsf, illustrated by binding one of the ‘s’ sites of the
hsf species with one of the ‘s’ site of the other hsf species. Note the two possible states of
the site ‘w’, namely ‘a’ and ‘n’, which depict two possible states of the species, acetylated
or non-acetylated respectively.
14.6
Quantitative Reﬁnement for Petri Net Models
In this section we model the heat shock response and its reﬁnement using the framework
of Petri nets. We implemented our models using Snoopy, a visualization, modeling, and
simulation tool with support for many types of Petri nets, see [162].
The Basic HSR Model as a Petri Net
For the general method of building a (standard) Petri net model from a given set of
biochemical reactions we refer to [205]. We built our implementation of the heat shock re-
sponse following the standard procedure: each species is represented as a place, and each
irreversible reaction is represented as a transition having as pre-places the places correspond-
ing to species on the left hand side of the reaction, and as post-places the places representing
species on the right hand side of the reaction; arc multiplicities denote the stoichiometric
coeﬃcients of the species involved in the reaction.
We checked several properties of the model to ensure that our implementation is correct.
For example, the P-invariants of the Petri net encode the three mass conservation relations
of the biological model, as described in [263]. The net is covered by T-invariants, and all
places except for the place representing species hsp are covered by P-invariants, which means
they are bounded. Our PRISM implementation uses as bounds for the species (except hsp)
the constants from the three mass conservation relations, namely the total amount of hsf,
hse, and prot. We also simulated the model with the numerical setup of [263] and obtained
the same DNA binding curve for a heat shock of 42◦C as that shown in [263] for the
corresponding ODE-based model. We refer to [178] for details.
The Reﬁned HSR Model as a Colored Petri Net
Implementing a model as a (standard) Petri net means that each reaction is represented
as a transition. In doing so, the reﬁned model is inevitably larger than the initial model,
similarly as in the case of ODE-based models. However, the framework of colored Petri nets
allows for stacking more than one species in a colored place, and for identifying each species
via a color, see Figure 14.2 for an example.

Quantitative Model Reﬁnement in Four Diﬀerent Frameworks
211
P′
P′
2
P′′
2
P′′
dimerization′
dimerization′′
2
2
P
Prot type
P2
Prot type
dimerization
x
2 ∗x
(a)
(b)
Figure 14.2: Representing the dimerization of two diﬀerent proteins, P′ and P′′ with (a) a
transition for each of them, and (b) a single colored transition for both. In (b) we use a
color set with two colors, Prot type = {1, 2}. The choice between colors 1 and 2 is done by
the variable x; when x = 1 the reaction will consume two proteins with color 1 and produce
one dimer with color 1, and when x = 2 the reaction will consume two proteins with color 2
and produce one dimer with color 2. In the ﬁgure, all places and transitions have identiﬁers,
and in (b) we also list the color set for each place (italic text).
We implemented the reﬁnement of the heat shock response model as a colored contin-
uous Petri net, in order to maintain a compact representation. Multiple coloring strategies
are possible; we considered two. One of them aimed at using as few colors as possible. In
this approach, trimers are represented with four colors 0, 1, 2, 3, denoting the number of
acetylated sites. A possible reﬁnement of reaction (7) with a single-acetylated trimer is
rhsp + rhsf3
(1) →rhsp: rhsf(0) + rhsf(0) + rhsf(1),
and another one is
rhsp + rhsf3
(1) →rhsp: rhsf(1) +2 rhsf(0) .
In order to diﬀerentiate between the two reﬁned reactions, we had to use two transitions,
thus increasing the number of transitions compared to that of the basic model. The sec-
ond strategy was to preserve the structure of the network in terms of number of places,
transitions, and the connections between them. We were able to do so by considering the
color sets of places denoting some of the species (e.g., hsf2, hsf3, hsf3:hse, hsp:hsf) as Carte-
sian products of the color sets of the places corresponding to the species they consist of.
This corresponds to a reﬁnement where the order of the acetylated monomers in a trimer
is explicitly described. An example of the reversible dimerization reaction using the second
coloring approach is presented in Figure 14.3. We refer to [144] for more details about the
two modeling strategies based on colored Petri nets.
14.7
Quantitative Reﬁnement for PRISM Models
PRISM is a free and open source guarded command language and probabilistic model
checker. It can be used to model and analyze a wide range of probabilistic systems. PRISM
supports various types of probabilistic models: probabilistic automata (PAs), probabilistic
timed automata (PTAs), discrete-time Markov chains (DTMCs), continuous-time Markov
chains (CTMCs), Markov decision processes (MDPs). A PRISM model consists of a keyword

212
From Action Systems to Distributed Systems: The Reﬁnement Approach
hsf2
Dimer
hsf
Monomer
Dimerization f
Dimerization b
(m1, m2)
m1 + +m2
(m1, m2)
m1 + +m2
Figure 14.3: Modeling the hsf dimers using a compound color set Dimer = Monomer ×
Monomer. The regular text next to places and transitions denotes their respective identiﬁer,
while the color sets are written in italic font. The hsf monomers are represented using the
color set Monomer = {0, 1}. The preplaces of the forward reaction are two monomers, with
colors m1 and m2. The result will be the production of one dimer with color (m1,m2). In the
reverse reaction, one dimer with color (m1, m2) is split into the two monomers m1 and m2.
Table 14.3: PRISM code for the dimerization in (a) the basic and (b) the reﬁned HSR models
(Nhsf is the upper bound for hsf and Nhsf2 is the upper bound for hsf2).
(a) Dimerization in the basic HSR model
[]2 ≤hsf ≤Nhsf ∧0 ≤hsf2 ≤Nhsf2 −1 →hsf ∗hsf ∗0.5 ∗k1:
(hsf′ = hsf −2) ∧(hsf2
′ = hsf2 +1);
(b) Dimerization in the reﬁned HSR model
[]2 ≤rhsf(0) ≤Nhsf ∧0 ≤rhsf2
(0) ≤Nhsf2 −1 →rhsf(0) ∗rhsf(0) ∗0.5 ∗k1:
(rhsf(0)′ = rhsf(0) −2) ∧(rhsf2
(0)′ = rhsf2
(0) +1);
[]1 ≤rhsf(0) ≤Nhsf ∧1 ≤rhsf(1) ≤Nhsf ∧0 ≤rhsf2
(1) ≤Nhsf2 −1 →
rhsf(0) ∗rhsf(1) ∗k1:(rhsf(0)′ = rhsf(0) −1) ∧(rhsf(1)′ = rhsf(1) −1)
∧(rhsf2
(1)′ = rhsf2
(1) +1);
[]2 ≤rhsf(1) ≤Nhsf ∧0 ≤rhsf2
(2) ≤Nhsf2 −1 →rhsf(1) ∗rhsf(1) ∗0.5 ∗k1:
(rhsf(1)′ = rhsf(1) −2) ∧(rhsf2
(2)′ = rhsf2
(2) +1);
which describes the model type (e.g., CTMC) and a set of modules whose states are deﬁned
by the state of their ﬁnite range variables (e.g., hsf). The state of the variables in each module
is speciﬁed by some commands including a guard and one or more updates, see [212].
The HSR Models as PRISM Implementations
We implemented the basic heat shock response as a CTMC model within a single module.
The PRISM model consists of 10 variables, each of them corresponding to one of the reactants
in the model, and 17 guards representing the 17 irreversible reactions of the system. For
example, the guard corresponding to dimerization, reaction (1) in Table 14.1, is expressed
in Table 14.3(a).
For the reﬁned heat shock response model, the corresponding PRISM model was built in
a similar way, following its reactions in Table 14.2. For example, the guards corresponding
to dimerization are presented in Table 14.3(b). The complete models can be found at [177]
and more details on how we built them can be found in [178].

Quantitative Model Reﬁnement in Four Diﬀerent Frameworks
213
Stochastic Model Checking of the PRISM HSR Models
The maximum number of states that PRISM can handle for CTMCs does not exceed
1010, see [210], which leads to diﬃculties in handling the state space explosion problem,
see [160]. To avoid this problem, we used approximate veriﬁcation, see [221, 167, 160], to
verify our two PRISM models.
We are interested in verifying two properties discussed in [263]: (i) the existence of three
mass-conservation relations, and (ii) the level of DNA binding eventually returns to the
basal values, both at 37◦C and at 42◦C.
The following three properties are used to check whether the mass-conservation relations,
corresponding to the level of hsf, hse, and prot, are valid in all states along the path:
• p =? [G hsf +2 hsf2 +3 hsf3 +3 hsf3:hse + hsp:hsf = hsfconst ],
• p =? [G hse + hsf3:hse = hseconst],
• p =? [G prot + mfp + hsp:mfp = protconst].
As expected, the value of p was conﬁrmed to be 1 in all cases, with conﬁdence level 95%,
i.e., the three mass conservation relations are respected in the model.
We veriﬁed in PRISM that for time points larger than 14400, the value of hsf3:hse complex
returns to the initial value by formulating the property, p =?
[F ≥14400
hsf3:hse = 3].
We chose 14400 as a time point reference to correspond to the upper limit of the simulation
time for the model in [263]. The probability value calculated by PRISM was 1 for this
property as well, with conﬁdence level 95%.
Finally, we also checked if the model conﬁrms the experimental data of [203] on DNA
binding. Due to the memory issues of PRISM, it was not possible to run the simulation
many times and use the average run plot to verify the experimental data. Therefore, as an
alternative approach, we checked the probability of having a data point within the interval
[0.9 · d, 1.1 · d] in the time period [0.9 · t, 1.1 · t], where d is the experimental data point at
time t. The results in both cases show high value probabilities, which conﬁrms that our two
PRISM models are in accordance with the experimental data of [203]; we refer to [144] for
the numerical results.
14.8
Discussion
We discussed in this paper quantitative model reﬁnement, an approach to step-wise
construction of biological models. Preserving the quantitative behavior of models throughout
the model construction process is at the forefront of this approach. This allows the modeler to
avoid repeating the computationally expensive process of parameter estimation at every step
of the process, thus avoiding the need of collecting larger and larger sets of high-quality time
data. Quantitative reﬁnement also allows the modeler to deal with partial and incomplete
information about some of the parameters of the model-to-build, including such information
when available, checking its consistency with the other parameters and with the data, and
compensating for lack of information about parameters with an algorithmic solution.
We investigated in this paper the versatility of the ﬁt-preserving reﬁnement method with

214
From Action Systems to Distributed Systems: The Reﬁnement Approach
respect to four broadly used frameworks: reaction models (with ODEs), rule-based models
(with BioNetGen), Petri net models (with Snoopy), and guarded command language models
(with PRISM). Dealing with the combinatorial explosion to account for post-translational
modiﬁcations was considerably diﬀerent from one framework to another. We conclude that
the method is cross-platform: it is implementable in all chosen frameworks, despite their
distinct underlying modeling paradigms.
In our case study based on the heat shock response, the data structure provided by
BioNetGen proves to be suitable for modeling the reﬁnement of biological systems. One
could eﬀectively employ species, sites, links, etc., to produce a compact representation of the
reﬁned model. On the other hand, using the colored version of Petri nets provides the modeler
with appropriate tools to introduce data types into the places of the network. The modeling
choices in the deﬁnition of the new data types and associating biological meanings to them
directly aﬀect the compactness of the representation as well as the corresponding model’s
complexity. In contrast, PRISM supports only elementary data types for the variables in the
model, which leads to an explicit detailing of all elements of the reﬁned model, similarly as
in the case of ODE-based models.
We show that our approach toward quantitative model reﬁnement is a potentially suitable
one to build a large biomodel which can be implemented within a wide spectrum of modeling
frameworks. In this method the modeler is able to easily modify the level of details in the
model in an algorithmic fashion, while ensuring that the model ﬁt is preserved from one
level of detail to another. It should also be noted that one can switch from one modeling
framework to another in order to use the advantages that each model formulation oﬀers in
terms of fast simulations, model checking, or compact model representation.
Acknowledgments
The authors thank Monika Heiner for help on Snoopy and Charlie, James Faeder and
Leonard Harris for advice on the BioNetGen implementation of the heat shock response,
and Adam Smith for technical support regarding RuleBender. We gratefully acknowledge
support from Academy of Finland through project 267915.

Chapter 15
Developing and Verifying User Interface
Requirements for Infusion Pumps: A
Reﬁnement Approach
Rimvydas Rukš˙enas
Queen Mary University of London
Paolo Masci
Queen Mary University of London
Paul Curzon
Queen Mary University of London
15.1
Introduction ......................................................
216
15.1.1
Outline of the Approach .................................
217
15.2
Sample User Interface Requirements from FDA .................
217
15.3
Background ......................................................
218
15.3.1
Interface Reﬁnement Approaches .......................
218
15.3.2
Event-B/Rodin Framework ..............................
219
15.4
The Requirement Hierarchies ....................................
220
15.4.1
Requirements for Data Entry ...........................
220
15.4.1.1
Requirements R1 and R2 ..................
220
15.4.1.2
Requirements R3 and R4 ..................
221
15.4.2
Safeguards against Inadvertent Changes or Tampering .
222
15.4.2.1
Requirement R5 ............................
222
15.4.2.2
Requirement R6 ............................
224
15.5
Veriﬁcation of Concrete Interfaces ...............................
226
15.5.1
Speciﬁcation of the vtbi Entry in Alaris ................
226
15.5.2
Requirement R6 .........................................
227
15.5.3
Requirements R1-R4
....................................
228
15.6
Conclusions .......................................................
229
Acknowledgments ................................................
230
Abstract. When describing criteria for the acceptable safety of systems, it is common prac-
tice for the regulator to provide safety requirements that should be satisﬁed by the system.
These requirements are typically described precisely but in natural language and it is often
unclear how the regulator can be assured that the given requirements are satisﬁed. This
chapter applies a rigorous reﬁnement process to demonstrate that a precise requirement is
satisﬁed by the speciﬁcation of a given medical device. It focuses on a particular class of
requirements that relate to the user interface of the device. For user interface requirements,
215

216
From Action Systems to Distributed Systems: The Reﬁnement Approach
reﬁnement is made more complex by the fact that systems can use diﬀerent interaction tech-
nologies that have very diﬀerent characteristics. The described reﬁnement process recognises
the variety of interaction technologies and models them as an interface hierarchy.
15.1
Introduction
Demonstrating that interactive devices are acceptably safe is a signiﬁcant and important
element in their development in various domains. For example, interaction design errors in
medical devices have an impact on patient safety and contribute to health-care costs. Because
of this, medical device regulators require manufacturers to provide suﬃcient evidence that
the risks associated with the device are “as low as reasonably practicable” as well as being
ﬁt for purpose before entering the market. This process is known as the premarket review
process. For the majority of medical devices, the premarket approval relies on manufacturers
demonstrating that the new device is as safe and eﬀective as an already legally marketed
device [336], or that it has been developed in accordance with recognised international
standards [86].
In its current form, the premarket approval process involves the analysis of tens of thou-
sands of printed pages [235] rather than a direct evaluation of the product. To reduce the
amount of paperwork and enable the submission of more succinct and rigorous evidence, the
use of formal methods is being promoted by the US Food and Drug Administration (FDA),
the regulator for medical devices in the US. Their approach relies on usage models for the
veriﬁcation of software [185]. A usage model is a formal representation that describes the
common characteristics and behaviour of software for broad classes of devices. The approach
is based on the idea of developing usage models that satisfy core sets of safety requirements
that are designed to mitigate typical hazards. This way, usage models can be used as a ref-
erence by manufacturers – if they are able to show that their product is compliant with the
behaviours of the usage models, then regulators have evidence that the manufacturer’s de-
vice meets minimum safety conditions. These models are developed manually starting from
safety requirements, verifying the models against these requirements using model checking
techniques.
Our approach shows how stepwise reﬁnement and the Event-B/Rodin platform can be
conveniently used to develop correct-by-construction usage models that are related to the
interactive aspects of medical devices. It addresses two key points of the FDA’s approach.
The ﬁrst is how to design safety requirements so that they are suﬃciently precise to be
eﬀectively operationalised. The second is to provide, by operationalising requirements, the
means for encompassing the range of input/output technologies that are likely to be encoun-
tered in interacting with the systems. Event-B is initially used here to express the high level
requirements such as those proposed by the FDA. Stepwise reﬁnement is then used both to
make those high level requirements more precise and to demonstrate that the requirement
can be cascaded into a hierarchy that encompasses potential input/output technologies.
To illustrate the approach, we focus speciﬁcally on infusion pumps. We take as a starting
point a particular sample set of user related requirements speciﬁed by the FDA. The original
FDA speciﬁcations are in natural language. We give abstract formal speciﬁcations of these
requirements. We then show how they can be reﬁned to more concrete versions. These

Developing and Verifying User Interface Requirements for Infusion Pumps
217
versions can be veriﬁed against the formal speciﬁcation of speciﬁc pump designs. Here we
concentrate on a particular infusion pump design based on a commercially available pump.
This paper is based on and extends our earlier work [286] on user interface requirements
for infusion pumps. In particular, it formally develops and veriﬁes new requirements related
to the safeguards against accidental tampering with infusion settings. Also, the speciﬁc pump
design is modelled in more detail which reﬂects the actual device more truthfully.
15.1.1
Outline of the Approach
The proposed approach is based on three layers: requirements hierarchies, interface hi-
erarchies, and concrete interfaces, each described below.
The requirements hierarchies layer, which is directly relevant to regulators, concerns the
development of user interface requirements. The regulator will be interested in the satis-
faction of these requirements to assure them of the device’s safety. A minimal set of such
requirements, relevant to some usability aspect of device interfaces, is developed. The aim is
that these requirements should be suﬃciently abstract to encapsulate the behaviour of the
largest class of possible devices. Reﬁnements are then used to detail these requirements in a
sequence of steps. It is also possible that reﬁnement can lead to alternative interface require-
ments that also provide assurance of the safety of the device. These modiﬁed requirements
would be developed as a contract between regulator and manufacturer. The development of
the requirements hierarchy layer is discussed in Section 15.4.
The concrete interface layer focuses on the user interfaces of speciﬁc devices. This layer is
most relevant to manufacturers as they demonstrate that the user interfaces of their devices
satisfy the requirements developed in the requirements hierarchy layer. There are several
possible approaches when trying to produce such a demonstration.
The ﬁrst is to verify a speciﬁc interface against the safety requirements directly. How
complicated this is will depend on the extent the requirements were operationalised. An
example of this approach is discussed in Section 15.5.2.
The second approach aims to simplify the process of demonstrating that a speciﬁc user
interface adheres to the relevant set of user requirements. It facilitates the dialogue between
regulators and manufacturers by means of an intermediate layer, the interface hierarchies.
This layer essentially develops a reﬁnement based hierarchy (classiﬁcation) of user interfaces.
The idea is that user requirements are veriﬁed once for most abstract classes of interfaces.
More concrete classes of interfaces at the lower levels of this hierarchy are then guaranteed
to satisfy the requirements by construction. Now, instead of directly verifying a speciﬁc
interface against the requirements it suﬃces to demonstrate that it is an instance of some
concrete class of user interfaces. This approach, brieﬂy discussed in Section 15.5.3, correlates
with the current FDA pre-market review process which involves providing evidence that a
new device is ‘substantially equivalent’ to already approved and legally marketed medical
devices.
15.2
Sample User Interface Requirements from FDA
The regulator’s aim is to be assured that risks associated with the use of a device are
as low as reasonably practicable. As previously discussed part of this assurance is achieved

218
From Action Systems to Distributed Systems: The Reﬁnement Approach
through a credible demonstration that safety requirements are true of the device. Before
showing how this demonstration can be achieved in the proposed framework, we describe a
subset of user related safety requirements developed by the FDA.
These requirements relate to two aspects of infusion pump designs: the usability of their
data entry systems and the safeguards against inadvertent changes of or tampering with
infusion settings. The subset considered is relevant to the volumetric infusion pump used by
clinicians that forms the basis of the example contained in this paper. The safety require-
ments are taken from a larger set produced by the FDA [335]. This larger set is intended
speciﬁcally for PCA (Patient Controlled Analgesic) pumps. As a result it has more em-
phasis on patient tampering than clinician errors, and therefore the overall focus is slightly
diﬀerent than is relevant to the volumetric infusion pump. The aim is to show how these
independently determined properties can be framed in our framework.
The requirements from the FDA document, considered in the subsequent sections, are
listed below:
R1 The ﬂow rate and vtbi (volume to be infused) for the pump shall be programmable.
This safety requirement aims to mitigate hazards due to incorrectly speciﬁed infusion
parameters (e.g., ﬂow rate is too high or low).
R2 The vtbi settings shall cover the range from vmin to vmax ml.
R3 The user (clinician) shall be able to set the vtbi in j ml increments for volumes below x
ml.
R4 The user (clinician) shall be able to set the vtbi in k ml increments for volumes above
x ml.
R5 Clearing of the pump settings and resetting of the pump shall require conﬁrmation. This
requirement aims to safeguard against clinicians changing infusion settings inadver-
tently.
R6 To avoid accidental tampering of the infusion pump’s settings such as ﬂow rate/vtbi, at
least two steps should be required to change the setting.
15.3
Background
This section brieﬂy discusses approaches to interface reﬁnement and introduces the
Event-B formalism used in our approach.
15.3.1
Interface Reﬁnement Approaches
Several previous projects on formal reﬁnement for user interface design had diﬀerent foci
to our work. For example, the main focus of Bowen and Reeves [64, 65] is on a description
of the actions that the user can engage with and how these actions can be reﬁned. The
reﬁnement process involves actions being replaced by more concrete actions in terms of
more concrete structures. The reﬁnement described by them is more akin to trace reﬁnement.

Developing and Verifying User Interface Requirements for Infusion Pumps
219
Although they argue that their interest is in ensuring that requirements are true of the more
reﬁned system, there is less concern with how the requirements are transformed through the
levels of reﬁnement. Duke and Harrison [123] are concerned with data reﬁnement. They
note that abstract representations of objects can be reﬁned in two directions, into what is
perceivable and into the architecture of the device. Darimont and van Lamsweerde [96] are
concerned with requirements described in terms of the reﬁnement of goals using the KAOS
language. The interesting innovation in their proposal is that the formal reﬁnement process
may be achieved through a set of patterns.
The approach we take here has most in common with the work of Yeganefard and
Butler [350] who demonstrate a similar reﬁnement process, in this case for control sys-
tems, using Event-B. They describe an approach to requirements structuring to facilitate
reﬁnement-based formalisation. Their work considers control systems consisting of plants,
controllers and operators. In these terms, our focus is narrower, encompassing phenomena
shared between controller and the operator. Also, we emphasise the formalisation of high
level requirements and their clariﬁcation through reﬁnement, whereas Yeganefard and But-
ler focus attention on requirements structuring. The structure developed is then mapped to
a formal model in the stepwise reﬁnement process. Moreover, their work is yet to address
non-functional requirements, considered here.
In our previous work [235, 155], we explored a diﬀerent approach to formalisation and
reﬁnement of user-related requirements. First, an abstract logic model is created that encap-
sulates key notions and relationships presented in the textual description of the requirements.
Second, a mapping relation is established between the abstract logic model and a concrete
model of a device being veriﬁed. This mapping relation is used as a basis to instantiate re-
quirements for the concrete device model. The concrete model is then mechanically veriﬁed
against the instantiated requirements.
15.3.2
Event-B/Rodin Framework
Event-B speciﬁcations are discrete models that consist of a state space and state tran-
sitions. A state includes constants and variables that describe the system. State transitions
are speciﬁed as events. A speciﬁcation of an event consists of two parts as seen in the ex-
ample below. The ﬁrst is a list of guards. Each guard is a predicate over the state variables
and constants. All the guards are combined using logical conjunction which is implicit in
the Event-B syntax. These guards together deﬁne the necessary conditions for the event
to occur. The second part is a list of actions which describe how the state variables are
modiﬁed as a result of event execution.
Speciﬁcations are structured in terms of machines and contexts. Machines specify the
dynamic aspects of a system, whereas contexts specify its static aspects. A machine includes
state variables and events. Invariant properties are expressed as machine invariants, i.e.,
predicates that must hold in all machine states. A context includes constants deﬁned by a
set of axioms. A machine may reference constants from the contexts it ‘sees’.
Intuitively, machine execution means that one of the events, with all guards being true,
is chosen. The machine variables are modiﬁed as speciﬁed by the actions of that event. The
basic syntactic form of an event is given below, other features of Event-B are introduced
when needed.
Event
E
b=
when G(v) then T(v) end
Here v is a list of variables. G(v) denotes the guards of E and T(v) denotes the actions

220
From Action Systems to Distributed Systems: The Reﬁnement Approach
associated with E. The formal semantics of events is given using before-after predicates that
encode the relation between the machine variables before and after an event occurrence. A
detailed description of Event-B can be found in [6].
15.4
The Requirement Hierarchies
In this section, the informal requirements from Section 15.2 are ﬁrst formalised in Event-
B then made more precise through gradual reﬁnement. The requirements R1–R4 related to
data entry interfaces are considered ﬁrst.
15.4.1
Requirements for Data Entry
The informal requirements R1 and R2 provide a basis for the abstract speciﬁcation of
user requirements relevant to data entry. R3 and R4 are introduced in a later reﬁnement.
15.4.1.1
Requirements R1 and R2
The requirement R1 (The vtbi/ﬂow rate for the pump shall be programmable) is expressed
as the following machine in Event-B. This abstract description simply requires that a variable
called data has the attribute that it is programmable. The requirement asserts that data
commences with a value named source and describes the event programmable as changing
the value to target. The possible values of data are given as the set Numbers. All three
constants, Numbers, source, and target, are deﬁned in the context ReqParams1 below.
MACHINE
Reqs1
SEES ReqParams1
VARIABLES
data
INVARIANTS
data ∈Numbers
EVENTS
Initialisation begin data: = source end
Event
programmable b= begin data: = target end
END
The invariant of Reqs1 simply gives typing of data. The initialisation event assigns the
source value to it. Since the programmable event expresses an abstract requirement, its guard
is assumed to be always true, and the when clause is omitted in the above speciﬁcation.
The requirement R2 (The vtbi settings shall cover the range from vmin to vmax ml) is
speciﬁed in the context ReqParams1 which deﬁnes the corresponding constants Min, Max.
It is assumed that Max exceeds Min and that Min is non-negative. The set constant (type)
Numbers is assumed to be the interval 0 . . Max. The context deﬁnes a number of other
constants: RefValues, source, and target. It is assumed that the source value belongs to the
interval Numbers and it is assumed that target is a member of the set of reference values
(RefValues) that covers the required range of settings. At this stage, no other assumptions
are made as to what these values are.

Free ebooks ==>   www.Ebook777.com
Developing and Verifying User Interface Requirements for Infusion Pumps
221
CONTEXT
ReqParams1
CONSTANTS
Min
Max
Numbers
RefValues
source
target
AXIOMS
Min ≥0
Max>Min
Numbers = 0 . . Max
RefValues ⊆Numbers ∩{x | x ≥Min}
source ∈Numbers
target ∈RefValues
END
Because the R1 requirement is speciﬁed in a non-operational form it is necessary to
reﬁne the machine. Informally, machine reﬁnement means verifying three constraints. The
ﬁrst concerns event reﬁnement: a concrete event must reﬁne the corresponding abstract one
(new events must reﬁne an implicit event that does nothing). The second constrains new
events: they must ‘converge’ (i.e., not run forever on their own). The third states that the
concrete machine must not deadlock before the machine it reﬁnes.
The following reﬁnement of Reqs1 provides guidance about how R1 can be implemented.
The operational version of R1 has a number of new characteristics. Two new variables are
introduced: entry and disp. Whether a number is being entered is indicated by entry, whereas
disp gives the displayed value of the number entered. The initial state requires that data and
disp are both initialised to the source value and entry is false, indicating that entry of the
target number has not commenced. The new requirement decomposes the event representing
R1 into three events. The ﬁrst one (choose) is used to elect to enter the target value, while
the second one models the modiﬁcation of the display value (this is not necessarily the data
value). The ﬁnal event is triggered when the display and target values are equal. At this
step the data value is set to be equal to the display value and entry becomes false. This
operational requirement indicates more about the programming process but says little about
how the value is entered.
MACHINE
Reqs11
REFINES Reqs1
SEES ReqParams1
VARIABLES
data
disp
entry
INVARIANTS
disp ∈Numbers
entry ∈BOOL
EVENTS
Initialisation
begin
data: = source
disp: = source
entry: = FALSE
end
Event
choose b=
Status anticipated
when
entry = FALSE
then
disp: = data
entry: = TRUE
end
Event
modify b=
Status anticipated
when
entry = TRUE
then
disp: ∈Numbers
end
Event
set b=
reﬁnes programmable
when
disp = target
entry = TRUE
then
data: = disp
entry: = FALSE
end
END
The machine Reqs11 speciﬁes that set reﬁnes the abstract event programmable (intu-
itively, both events assign target to data). The other two events, choose and modify, are new.
For the machine Reqs11 to reﬁne Reqs1 these newly introduced events must ‘converge’ (i.e.,
they must not execute forever). The speciﬁcation does not attempt to prove that. Rather
than requiring their convergence, the speciﬁcation assumes, as indicated by the keyword
‘anticipated’, that choose and modify will not run forever. If necessary, this assumption can
be proven later.
15.4.1.2
Requirements R3 and R4
In the case of R3 (The user shall be able to set the VTBI in j ml increments for volumes
below x ml) and, similarly, R4, the requirements are expressed in a suﬃciently concrete
www.Ebook777.com

222
From Action Systems to Distributed Systems: The Reﬁnement Approach
form to proceed directly to their operationalised versions. They are captured in the follow-
ing context ReqParams11 which extends ReqParams1 by adding three relevant constants—
Threshold (x in R3 and R4), j, and k—with three associated axioms:
CONTEXT
ReqParams11
EXTENDS ReqParams1
CONSTANTS
Threshold
j
k
AXIOMS
Threshold ∈Min + 1 . . Max −1
j<Threshold
k ≤Threshold
RefValues ⊆{x·x>0 ∧j ∗x ≤Threshold | j ∗x} ∪{x·x>0 | Threshold + k ∗x}
END
The fourth axiom restricts the reference set (RefValues) to the values obtained using the
increments j and k. This context is used by Reqs111 which is the same machine as Reqs11
otherwise:
MACHINE
Reqs111
REFINES Reqs11
SEES ReqParams11 ....
The last step in the reﬁnement of requirements has a more technical nature. It decom-
poses Reqs111 so that the assumptions about the user behaviour are removed from the
requirements for the pump interfaces. In particular, one guard (disp = target) in the event
set encompasses the notion of a target. Though the latter is relevant to the user behaviour,
it would be meaningless to apply it to the pump interface. The decomposition introduces
a machine that replaces the constant target by a variable that represents the display value
‘passed’ to the user. The details are omitted here, since this does not aﬀect the actual data
entry.
15.4.2
Safeguards against Inadvertent Changes or Tampering
In this section, the requirements R5 and R6 are formally developed.
15.4.2.1
Requirement R5
The informal requirement R5 (Clearing of the pump settings and resetting of the pump
shall require conﬁrmation) simply states that an attempt to clear the pump settings (such
as vtbi and ﬂow rate) cannot take its eﬀect immediately but should result in a request
for conﬁrmation. The requirement is captured by the event clear in the following Event-B
machine Reqs5. The variable require set to true represents a request for the conﬁrmation of
the clearing action. The event clear is enabled when the clearing action has not already been
attempted (require = FALSE). In that case, it initiates a request to conﬁrm the clearing
action (require := TRUE). Note that this speciﬁcation, faithful to the informal requirement,
says nothing about the eﬀect of the clearing action on the pump settings:
MACHINE
Reqs5
VARIABLES
require
INVARIANTS
require ∈Bool
EVENTS
Initialisation begin require: = FALSE end
Event
clear b=
when
require = FALSE
then
require: = TRUE
end
END

Developing and Verifying User Interface Requirements for Infusion Pumps
223
Though it is not stipulated explicitly, the requirement R5 also implies that there should
be some kind of acknowledgement for the clearing request. By making this assumption
explicit in the following reﬁnement of the machine Reqs5, the requirement becomes more
precise and rigorous. In the reﬁnement Reqs51, the acknowledgement is modelled as a new
event, acknowledge. Reqs51 also introduces a new variable, ack. When set to true, this
variable represents an acknowledgement of the clearing action:
MACHINE
Reqs51
REFINES Reqs5
VARIABLES
require
ack
INVARIANTS
ack ∈BOOL
EVENTS
Event
Initialisation
extends Initialisation
then
ack: = FALSE
end
Event
clear
extends clear
end
Event
acknowledge b=
Status anticipated
when
ack = FALSE
require = TRUE
then
ack: = TRUE
end
END
The event acknowledge is enabled when there is an unacknowledged request for conﬁrma-
tion and sets ack to true. For the remaining events, the keyword extends indicates that the
event in question incorporates (and reﬁnes) the corresponding event in Reqs5. In addition,
the reﬁned initialisation event sets ack to false.
The requirement as modelled by Reqs51 captures mode transitions in the pump be-
haviour. However, it puts no constraints on the changes to the pump settings associated
with those transitions. The need to be more rigorous about that is addressed in the next
reﬁnement of Reqs51. Not to be bound by any speciﬁc interpretation of the concept of pump
settings, we assume that they are expressed as an abstract type (set), Settings. Constant
blank from Settings represents the pump settings being cleared. These assumptions are
modelled as the following context:
CONTEXT
ReqParams5
SETS
Settings
CONSTANTS
blank
AXIOMS
blank ∈Settings
END
The reﬁnement Reqs511 introduces new variable data. It is an abstract representation of
the pump settings. The requirement R5 is once again made more precise by distinguishing
two possibilities associated with the acknowledgement event. The ﬁrst one is that the clearing
request is actually conﬁrmed by the pump user. This is modelled by the event conﬁrm which
extends acknowledge by updating data to blank (the pump settings are cleared). The second
possibility is that the user changes their mind and cancels the clearing request. This is
modelled by the event quit which leaves data unchanged:

224
From Action Systems to Distributed Systems: The Reﬁnement Approach
MACHINE
Reqs511
REFINES Reqs51
SEES ReqParams5
VARIABLES
require
ack
data
INVARIANTS
data ∈Settings
EVENTS
Event
Initialisation
extends Initialisation
then
data: ∈Settings
end
Event
clear
extends clear
end
Event
conﬁrm
extends acknowledge
then
data: = blank
end
Event
quit
extends acknowledge
end
Event
other b=
Status anticipated
when
require = FALSE
then
data: ∈Settings
end
END
A new event (other) is added to Reqs511 to avoid constraining changes to the pump
settings when there is no request to clear them. In such states (require = FALSE), event
other allows the pump settings to be updated in an arbitrary way (data: ∈Settings).
15.4.2.2
Requirement R6
Expressed in natural language, the requirement R6 (To avoid accidental tampering of
the infusion pump’s settings such as ﬂow rate / vtbi, at least two steps should be required to
change the setting) is open to several interpretations. For example, the ‘two step’ condition
can be interpreted as one change of the setting followed by another. However, in the context
of safeguarding against accidental tampering, a more plausible interpretation of R6 seems
to be that any attempt to change a setting like vtbi should require a separate conﬁrmation
step. Such an interpretation relates R6 to R5. Therefore, it would be plausible to view R6
as a part of the requirements hierarchy formally developed for the requirement R5, since a
two step (request - acknowledgement) structure has already been speciﬁed in the machine
Reqs51. In particular, R6 can be formally introduced as a reﬁnement of Reqs51.
At the same time, there are several aspects in which R6 is diﬀerent from R5. Firstly,
it applies to any change to a particular pump’s setting, not just clearing of that setting.
Secondly, R6 refers to the changes to a particular setting as opposed to the simultaneous
clearing of all settings as stated in R5. Though, due to the abstract nature, the type Settings
in our speciﬁcation can be interpreted as both, a particular pump’s setting and all the
settings combined, it is not obvious what advantages a formal linkage of R6 and R5 would
provide.
Taking these considerations into account, the requirement R6 is formalised in a separate
development. Its starting point captures the ‘two step’ condition, modelled as the following
Event-B machine:
MACHINE
Reqs6
VARIABLES
change
INVARIANTS
change ∈Bool
EVENTS
Initialisation begin change: ∈Bool end
Event
update b=
when
change = TRUE
then
change: = change
end
Event
acknowledge b=
when
change = TRUE
then
change: = FALSE
end
END
The variable change represents the mode of pump operation where changes to a particular
pump’s setting can be made. When the pump is in such a mode, the event update (ﬁrst
step) stands for all the possible updates to that setting. These updates leave the mode

Developing and Verifying User Interface Requirements for Infusion Pumps
225
of pump operation unchanged (change: = change). The event acknowledge (second step)
stands for the conﬁrmation of changes, which results in the pump exiting the change mode
(change: = FALSE).
Next, we look in more detail at how the two steps speciﬁed in Reqs6 relate to the
actual changes to the pump’s setting considered. The informal requirement R6 suggests
that any changes to the relevant setting are ‘provisional’. In that respect, however, R6 can
be interpreted in two ways at least. The ﬁrst interpretation is that the changes, before
they are conﬁrmed, do not aﬀect the actual pump’s setting. Instead, they are recorded in a
temporary pump’s parameter. Only the conﬁrmation step updates the relevant setting with
the new value from the temporary parameter. The second interpretation is that the changes
are applied to the relevant setting immediately. However, they still have to be conﬁrmed in
the conﬁrmation step. Otherwise, the setting is restored to its old value. Both interpretations
are below formalised as reﬁnements of Reqs6. Both reﬁnements introduce a new variable,
param, that represents the relevant pump’s setting. We start with the ﬁrst interpretation.
In addition to param, the reﬁnement Reqs61 introduces another variable, new, that mod-
els provisional changes to param. This variable is initialised to the value of param:
MACHINE
Reqs61
REFINES Reqs6
SEES ReqParams5
VARIABLES
change
param
new
INVARIANTS
param ∈Settings
new ∈Settings
EVENTS
Event
Initialisation
extends Initialisation
then
param: ∈Settings
new: = param
end
Event
update
extends update
then
new: ∈Settings
end
Event
conﬁrm
extends acknowledge
then
param: = new
end
Event
cancel
extends acknowledge
end
END
The event update extends the same event from Reqs6. It guarantees that any changes
to the setting are provisional and temporarily recorded in the variable new. Both events
conﬁrm and cancel reﬁne the old event acknowledge. The conﬁrmation of the changes to the
setting is modelled by conﬁrm. It extends acknowledge by updating param with the new
value for this setting (new). Any changes are cancelled by the event cancel.
The second, perhaps less natural, interpretation of R6 is formalised as the following
reﬁnement Reqs62. In addition to param, it introduces another variable, old. This variable
stores the old setting and is initialised to param:
MACHINE
Reqs62
REFINES Reqs6
SEES ReqParams5
VARIABLES
change
param
old
INVARIANTS
param ∈Settings
old ∈Settings
EVENTS
Event
Initialisation
extends Initialisation
then
param: ∈Settings
old: = param
end
Event
update
extends update
then
param: ∈Settings
end
Event
conﬁrm
extends acknowledge
end
Event
cancel
extends acknowledge
then
param: = old
end
END
According to this speciﬁcation, the setting param is changed with each update event.
However, the changes are disregarded by the event cancel, if this option is selected instead
of conﬁrm.
The diﬀerence between these formal interpretations of the requirement R6 is quite sub-
tle. If the changes to the setting are ﬁnished in a normal way by conﬁrming or cancelling

226
From Action Systems to Distributed Systems: The Reﬁnement Approach
them, the two formal requirements make no diﬀerence. Only when the changes are abruptly
interrupted (e.g., the pump is switched oﬀbefore the conﬁrmation step), Reqs61 and Reqs62
will result in diﬀerent requirements for the pump design. It is up to the regulators of medical
devices to decide which version of the requirement R6 is preferable, or whether they both
are equally acceptable. Formalising several alternative interpretations highlights the issue
but also raises the possibility of exploring the consequences for safety of each choice formally.
15.5
Veriﬁcation of Concrete Interfaces
Having produced an operational but abstract deﬁnition of the requirements, the next
stage is to make sense of the requirement in terms of the particular device that the developer
wishes to certify. The aim of this section is to show how an interface speciﬁcation of a speciﬁc
device can be shown to satisfy user related requirements. Ideally, such a speciﬁcation would
be provided by the device manufacturer. Alternatively, it can be reverse engineered by
interactively exploring the actual device [328, 155].
To illustrate our approach, we consider the number entry module of the Alaris GP
Volumetric Pump [77]. A speciﬁcation of this module has been reverse engineered in PVS and
SAL [236]. The speciﬁcation given below is its direct translation to Event-B. The purpose of
using this translation is to demonstrate two ways of verifying the relevant user requirements
for the independently developed speciﬁcations of concrete interfaces.
15.5.1
Speciﬁcation of the vtbi Entry in Alaris
The Alaris pump uses a chevron based number entry interface. In this type of interface,
the current data value is updated by pressing the ‘up’ (increase) and ‘down’ (decrease)
chevron keys. The fast versions of these keys are used to speed up data entry. For example,
a fast ‘up’ chevron increases the current value by a larger amount compared to a slow ‘up’
one.
In the PVS and SAL versions, the behaviour of the Alaris chevrons (slow and fast up-
/down keys) is captured using functions that specify how the current value is modiﬁed
by pressing each chevron. In Event-B, the corresponding functions, alaris up, alaris dn,
alaris UP, and alaris DN, are deﬁned in the following context. It extends RealDeﬁnitions
which provides an Event-B model for the real numbers supported by the Alaris pump.
The deﬁnitions of alaris dn, alaris UP, and alaris DN (omitted here) are similar to that of
alaris up:

Developing and Verifying User Interface Requirements for Infusion Pumps
227
CONTEXT
AlarisDeﬁnitions
EXTENDS RealDeﬁnitions
CONSTANTS
trim
alaris up
alaris dn
alaris UP
alaris DN
init
...
AXIOMS
trim ∈Z →real
alaris up ∈real →real
init ∈real
∀x·(x<minAlaris ⇒trim(x) = minAlaris) ∧
(x>maxAlaris ⇒trim(x) = maxAlaris) ∧
(x ≥minAlaris ∧x ≤maxAlaris ⇒trim(x) = x)
∀x·x ∈real ⇒(x<r100 ⇒alaris up(x) = trim((ﬂoor(x ∗10) + r1)/10)) ∧
(x ≥r100 ∧x<r1000 ⇒alaris up(x) = trim(x + r1)) ∧
(x ≥r1000 ⇒alaris up(x) = trim((ﬂoor(x/10) + r1) ∗10))
...
END
The behaviour of the four chevrons when entering vtbi values is described by the events
up, dn, UP, and DN, e.g., up is speciﬁed below:
Event
up b=
Status anticipated
when
topline = dispvtbi
entrymode = vtmode then display: = alaris up(display) end
Here the condition topline = dispvtbi indicates that the pump is in the mode where the vtbi
value can be changed, whereas entrymode = vtmode says that the changes are performed by
updating the vtbi value with the chevron keys. The display variable represents the displayed
value of vtbi. This event does not change the actual vtbi setting represented by the variable
vtbi. The speciﬁcations of the remaining chevrons are similar.
The machine Alaris vtbi1 includes these four chevron events and two events that model
the acknowledgement (conﬁrmation and cancellation) of the changes made to the vtbi value
using the chevrons. The conﬁrmation case is speciﬁed as follows:
Event
conﬁrm b=
when
topline = dispvtbi
entrymode = vtmode
then
vtbi: = display
topline: =
ptop(infstate)
entrymode: = pentry(infstate) end
This event updates the vtbi setting with the entered value recorded by display. The
mode of pump operation (topline) and the data entry mode (entrymode) go back to their
previous values. These are given as the values of functions ptop and pentry, respectively. They
depend on whether the pump is in the infusing state or not, which is modelled as the boolean
variable infstate. The functions ptop and pentry are deﬁned in the context AlarisDeﬁnitions.
The cancellation case is modelled similarly.
Now we illustrate two ways of verifying that the Alaris vtbi entry module satisﬁes the
requirements formalised in Section 15.4. First, the requirement R6 is veriﬁed directly for
the machine Alaris vtbi1.
15.5.2
Requirement R6
In this illustration, our ﬁrst interpretation (machine Reqs61) is used for the informal
requirement R6.
Since the structure of Alaris vtbi1 is not that diﬀerent from Reqs61, it is feasible to
demonstrate the reﬁnement relation between them directly. However, as a preparatory step,
the abstract set Settings and constant blank used in Reqs61 must be instantiated to the

228
From Action Systems to Distributed Systems: The Reﬁnement Approach
concrete set Numbers and value 0, respectively, used in Alaris vtbi1. In Event-B, this is
automatically done by applying the generic instantiation plugin to Reqs61 (we will use the
same name for the instantiated machine).
To establish reﬁnement between the instantiated machine Reqs61 and Alaris vtbi1, one
has to provide a ‘glueing’ invariant that relates the concrete variables in Alaris vtbi1 and
the abstract variables they replace in Reqs61. The abstract variables in question are change,
param, and new. As discussed earlier, change = TRUE models the mode where a relevant
pump’s setting can be changed. In Alaris vtbi1, the corresponding mode for the vtbi entry
is deﬁned by the condition topline = dispvtbi ∧entrymode = vtmode. Assuming this condi-
tion is true, the vtbi setting vtbi and its provisional value display are identiﬁed with their
counterparts in Reqs61. The resulting glueing invariant allows one to prove the following
reﬁnement:
MACHINE
Alaris vtbi1
REFINES Reqs61
SEES AlarisDeﬁnitions
...
INVARIANTS
(change = TRUE) ⇔(topline = dispvtbi ∧entrymode = vtmode)
(topline = dispvtbi ∧entrymode = vtmode) ⇒(vtbi = param ∧display = new) ...
EVENTS
Event
up b=
Status anticipated
reﬁnes update
when
topline = dispvtbi
entrymode = vtmode
with
new′:new′ = display′
then
display: = alaris up(display)
end
...
END
Similarly to up, the remaining chevron events (dn, UP, and DN) in Alaris vtbi1 reﬁne
the requirement event update. Finally, the acknowledgement events conﬁrm and cancel reﬁne
their counterparts in Reqs61.
15.5.3
Requirements R1-R4
This section illustrates an alternative approach for demonstrating that the data entry
systems in infusion pumps satisfy relevant safety requirements. A number of such systems
are already used in infusion pumps [254] and there is future scope for many more. The
approach presumes that a reﬁnement-based hierarchy of user interfaces has been previously
developed that is relevant for various modes of data entry in infusion pumps [286]. It is also
assumed that the relevant requirements have been veriﬁed for the classes at the top of the
hierarchy. If so, then the interface classes at the lower levels are guaranteed to preserve them
by construction. To verify a speciﬁc interface against those requirements, it then suﬃces
to show that the interface is an instance of some class in the hierarchy. This principle is
demonstrated for the Alaris vtbi entry system.
We will show that the Alaris vtbi entry is an instance of the class of interfaces with four
chevron keys. This class, represented by the machine Chevron Entry11, has already been
shown to satisfy the formalisation of the requirements R1-R4 [286]. Thus, the demonstra-
tion that the Alaris vtbi entry interface is an instance of that class boils down to proving
reﬁnement between Chevron Entry11 and Alaris vtbi1. For such a proof, the generic pa-
rameters (such as j, k, and Threshold) used by Chevron Entry11 must be instantiated with
the concrete values from the Alaris speciﬁcation (context AlarisDeﬁnitions) as, for example,
shown below:

Developing and Verifying User Interface Requirements for Infusion Pumps
229
CONTEXT
ChevronAlarisParams
EXTENDS ChevronDeﬁnitions11
AlarisDeﬁnitions
AXIOMS
Min = minAlaris
Max = maxAlaris
j = r01
k = r1
Threshold = r100
...
END
To specify the behaviour of four chevron keys, Chevron Entry11 already includes the
events up, revtdn, UP, and DN. These must be reﬁned by the corresponding events in
Alaris vtbi1. Finally, the invariants of Alaris vtbi1 must include a glueing invariant that
speciﬁes the connection between the state spaces of both machines:
MACHINE
Alaris vtbi1
REFINES Chevron Entry11
SEES ChevronAlarisParams
...
INVARIANTS
(entry = TRUE) ⇔(topline = dispvtbi ∧entrymode = vtmode)
(vtbi = data ∧display = disp)
...
EVENTS
Event
up b=
Status anticipated
reﬁnes up
when topline = dispvtbi
entrymode = vtmode
with
disp′:disp′ = display′
then
display: = alaris up(display)
end
...
END
15.6
Conclusions
We have demonstrated how Event-B can be used to support manufacturers as they
aim to demonstrate that the regulator’s requirements are satisﬁed by their products. All the
reﬁnements described have been proven using the Rodin platform. The reﬁnement hierarchies
thus developed for requirements and user interfaces enable developers to trace the regulator
requirements down to the specialised classes that match the physical characterisation of their
device. Such an approach ﬁts well with the FDA pre-market review process which involves
providing evidence that a new device is ‘substantially equivalent’ to already approved and
legally marketed medical devices.
We envisage showing that a device satisﬁes a full set of requirements by developing
speciﬁcation fragments. Each fragment would address one or more requirements and would
provably demonstrate that the requirements in question are satisﬁed. It then remains an
open question as to how one proves that these components are consistent with each other
and how they might ﬁt into a larger speciﬁcation. This is future work. It would explore work
on composition [304] and product lines [141] in Event-B being carried out at Southampton.
The advantage of using Event-B is that the approach is tool supported. It is feasible that
standard reﬁnement processes such as these can be made easier for developers to use.

230
From Action Systems to Distributed Systems: The Reﬁnement Approach
Acknowledgments
This work is supported by EPSRC as part of CHI+MED (Computer-Human Interaction
for Medical Devices, EPSRC research grant [EP/G059063/1]). We are grateful to Michael
Harrison who collaborated in various aspects of the work described.

Free ebooks ==>   www.Ebook777.com
Chapter 16
Self-Assembling Interactive Modules: A
Research Programme
Gheorghe Stefanescu
University of Bucharest
16.1
Tiling: A Brief Introduction .....................................
231
16.2
Two-Dimensional Languages: Local vs. Global Glueing
Constraints ......................................................
233
16.2.1
Words and Languages in Two Dimensions ..............
233
16.2.2
Local Constraints: Tiles .................................
233
16.2.3
Global Constraints: Regular Expressions ...............
237
16.2.4
Systems of Recursive Equations .........................
237
16.3
Structural Characterisation for Self-Assembling Tiles ...........
239
16.3.1
From Local to Global Constraints .......................
239
16.3.2
Languages Generated by Two-Colors Border Tiles .....
239
16.3.3
A Case Study: F02ac.c ..................................
240
16.4
Interactive Programs .............................................
243
16.4.1
Words and Traces in Two Dimensions ..................
243
16.4.2
Interactive Modules and Programs ......................
243
16.4.3
Reﬁnement of Structured Interactive Programs .........
245
16.5
Conclusions .......................................................
246
Abstract. In this paper we propose a research programme for getting structural characteri-
sations for 2-dimensional languages generated by self-assembling tiles. This is part of a larger
programme on getting a formal foundation of parallel, interactive, distributed systems.
16.1
Tiling: A Brief Introduction
Tiling is an old and popular subject [148]. While our focus is on 2-dimensional tiles/tiling
and 2-dimensional regular expressions, the formalism itself can be easily extended to cope
with 3, 4, or more dimensions.
An interesting tiling problem was proposed by Wang in 1961. Wang tiles are: (1) ﬁnite
sets of unit squares, with a color on each side; (2) which cannot be rotated or reﬂected;
and (3) such that there is an inﬁnite number of copies from each tile. A tiling is a side-by-
side arrangement of tiles, such that neighbouring tiles have the same color on the common
231
www.Ebook777.com

232
From Action Systems to Distributed Systems: The Reﬁnement Approach
borders. The main problem of interest here is the following: “Given a set of tiles, is there a
tiling of the whole 2-dimensional plane?” Wang has conjectured that only regular periodic
tilings are possible, but this conjecture was refuted later and aperiodic tilings of the plane
were found; the smallest known set for which an aperiodic tiling does exist consists in 13
tiles [87, 199]. See also [124] for some recent results, seen from a mathematical perspective.
Another interesting model using tiles is the Winfree’s abstract Tile Assembly Model; see
[261] for a recent survey. This is a theoretic model aiming to capture the basic features of self-
assembling systems from physics, chemistry, or biology. The main problem of interest here
is: “Find a set of tiles such that any ﬁnite tiling yields the same speciﬁed ﬁnal conﬁguration.”
Reformulated in rewriting language terms, the problem of interest is to ﬁnd conﬂuent and
terminating sets of tiling rules. The interest in this problem comes from practical reasons:
to use self-assembling for producing complex substances with no errors and in a fast way.
The approach presented in this paper comes from a diﬀerent perspective: how to use tiling
to describe the syntax and the semantics of open, interactive, distributed programs, and
computing systems. The problem of interest here is: “Find all ﬁnite tiling conﬁgurations with
a given color on each west/north/east/south border”. This is an abstract formulation of the
basic fact that we are interested in running scenarios of distributed systems, corresponding
to tiling conﬁgurations, which start from initial states (on north), initial interaction classes
(on west) and, in a ﬁnite number of steps, reach ﬁnal states (on south) and ﬁnal interaction
classes (on east). To conclude, while formally our tiles are somehow similar with Wang or
Winfree tiles, the problem of interest is diﬀerent.
Tiling has also been used for the study of 2-dimensional languages1, a topic closer to
our approach here. The ﬁeld of 2-dimensional languages started in 1960s, mostly related
to “picture languages”. The ﬁeld has got a renewed interest in 1990s, when a robust class
of regular 2-dimensional languages has been identiﬁed; good surveys from that period are
[140, 228]. Comparisons between our approach and some known results in the area of 2-
dimensional languages are included in the text below, as well as in our previous papers on
a new type of 2-dimensional regular expressions to be introduced in the next section, see,
e.g., [44, 46, 45].
We end this brief introduction with a comment on the use of the “self-assembling” term
here. According to some conventions, a (chemical) self-assembling system is an assembling
system with the following distinctive features related to the order, the interactions, and
the used building blocks: (1) usually, the resulting conﬁgurations have higher order; (2)
they use “weak interactions” for coordination; and (3) larger or heterogeneous building
blocks may be used. A property as (1) is present in the statement of the proposed research
programme presented in Section 1.3. Property (3) is a basic ingredient in our new type
of 2-dimensional regular expressions, based on scenario composition. Property (2) is more
related to physical systems - a slightly similar one may be considered in our setting, making
a diﬀerence between computing (on a machine) and coordinating activities. In short, there
are strong enough reasons to use the “self-assembling” term for constructing scenarios in
the current distributed computing formalism. Both, the term and the self-assembling way
of thinking may be useful when considering distributed software services, as well.
1This approach considers an abstract notion of dimension. Nevertheless, our work on tiling originates
from a study of interactive systems (i.e., the register-voice interactive systems model [318, 319]), leading
to a model with 2 dimensions and a particular interpretation of them: the vertical dimension represents
time, while the horizontal dimension is used for space. More on this distinction between abstract tiling and
developing scenarios out of interactive modules is included in the last section.

Self-Assembling Interactive Modules: A Research Programme
233
(a)
(b)
(c)
Figure 16.1: 2-dimensional words
(a)
(b)
Figure 16.2: Scenarios and accepted words
16.2
Two-Dimensional Languages: Local vs. Global Glueing
Constraints
16.2.1
Words and Languages in Two Dimensions
A 2-dimensional word is a ﬁnite area of unit cells, in the lattice Z × Z, labelled with
letters from a ﬁnite alphabet. A 2-dimensional letter is a 2-dimensional word consisting of
a unique cell. A 2-dimensional language is a set of 2-dimensional words.
These 2-dimensional words are invariant with respect to translation by integer oﬀsets, but
not with respect to mirror or rotation. A word may have several disconnected components.
Examples of words are presented in Figure 16.1: in (a) it is a rectangular word; in (b) it is
a word of arbitrary shape having no holes and 1 component; in (c) there is a word with 1
hole and 2 components.
16.2.2
Local Constraints: Tiles
A tile is a letter enriched with additional information on each border. This information is
represented abstractly as an element from a ﬁnite set2 and is called a border label. The role of
border labels is to impose local glueing constraints on self-assembling tiles: two neighbouring
cells, sharing a horizontal or a vertical border, should agree on the label on that border. A
scenario is similar to a 2-dimensional word, but: (1) each letter is replaced by a tile; and
(2) horizontal or vertical neighbouring cells have the same label on the common border.
Examples of tiles and scenarios are presented in Figure 16.2(a).
A self-assembling tile system3 (shortly, SATS) is deﬁned by a ﬁnite set of tiles, together
2Often, we use sets of numbers or sets of colors.
3Tiling is a popular research subject, see e.g. [148]. The model we are using here (with a ﬁnite label set for
borders) was introduced in the context of interactive programming [317, 319] using a diﬀerent terminology.
In that context, the concept is called ﬁnite interactive system (FIS). The vertical dimension represents

234
From Action Systems to Distributed Systems: The Reﬁnement Approach
with a speciﬁcation of what border labels are to be used on the west/north/east/south ex-
ternal borders. An accepting scenario of a SATS F is a scenario, obtained by self-assembling
tiles from F, having the speciﬁed labels on the external borders. Finally, the 2-dimensional
language recognized by a SATS F, denoted L(F), is the set of 2-dimensional words obtained
from the accepting scenarios of F, dropping the border labels.
Example 16.1. An example of a SATS is F deﬁned by:
(1) tiles:
and
(2) labels for external w/n/e/s borders: {7,8}/{1}/{9}/{2}.
All scenarios in Figure 16.2(a) are correct scenarios of F. The ﬁrst two are accepting sce-
narios, while the last one is not (there is a label 4 on the south border). Dropping the
border labels in the accepting scenarios in Figure 16.2(a) we get the recognized words in
Figure 16.2(b).
Tiles constrain the letters of horizontal and vertical neighbouring cells. They control
the letters of those cells in a word laying in a horizontally-vertically connected component
(shortly hv-component)4 of a word and do not aﬀect separated components. Consequently,
our focus below will be on the structure of hv-components of the words.
Projected on one dimension, this model produces classical ﬁnite automata. For instance,
this can be done by considering diﬀerent labels for the west and the east borders of the tiles,
inhibiting horizontal growth of the scenarios. Then each accepted hv-connected scenario is
a 1-column scenario which may be seen as an acceptance witness of a usual 1-dimensional
word by the corresponding ﬁnite automaton.
It is not at all obvious how to deﬁne 2-dimensional word composition, extending usual
1-dimensional word concatenation. We start with the simpler deﬁnition of scenario compo-
sition.
Scenario composition. For two scenarios v and w, the scenario composite v.w consists
of all valid scenarios resulting from putting v and w together, without overlapping. This
actually means that, if v and w share some borders in a particular placement, then the
labels on the shared borders should be the same.
Example 16.2. We consider two scenarios:
v =
w =
The composite v.w has three results, sharing at least one cell border; they are presented in
Figure 16.3.
Word composition, a preliminary solution. The above scenario composition guides
us towards what word composition should be able to achieve.
time, while the horizontal dimension represents space. The labels on the north and south borders represent
(abstract) memory states, while the ones on the west and east borders represents (abstract) interaction
classes. The selected labels on the external borders are called initial for west and north borders, and ﬁnal
for east and south borders.
4The words in Figure 16.1(a),(b),(c) have 1,3,7 hv-components, respectively.

Self-Assembling Interactive Modules: A Research Programme
235
(a)
(b)
(c)
Figure 16.3: Scenario composition
...
Figure 16.4: Border agnostic word composition
One possibility to deﬁne word composition is to mimic scenario composition using en-
riched alphabets and renaming. Notice that tiles may be codiﬁed using letters in appropriate
enriched alphabets - one possibility is presented is the next paragraph. There are three strong
criticisms to this solution. First, composition would depend on the underlying tile system
and we want a word composition deﬁnition depending only on the words themselves. Second,
the use of tiles (border labels) does not scale to large systems5. Finally, and perhaps the most
important reason, renaming does not behave properly in combination with intersection, a
key operation used in classical regular expressions [140, 228]; for instance, by renaming let-
ters in an expression representing square words one gets an expression producing arbitrary
rectangular words - see [44].
The drawbacks of this “word composition via scenario composition” is inherited by “reg-
ular expressions” including renaming operators [140, 228]6. Indeed, with renaming we can
mimic the border labels of the tiles as additional information in the cells letters; e.g., we
can enrich letter a to become a =def (a, 1, 2, 3, 4), including into the cell letter the labels
1,2,3,4 of the side borders. Then, we can use this extra information on neighbouring cells to
control the shape of the words and, ﬁnally, using a renaming, we can remove the additional
information. Actually, with renaming the border labels are reintroduced in the model.
To conclude:
Scenario composition is based on a set of tiles, while word composition (and the asso-
ciated regular expressions) should not have any underlying tile system behind.
Word composition. The solution to the problems identiﬁed in the previous paragraphs
is to deﬁne a restricted composition using relevant information of the contours of the words
[44, 46, 45]. A few elements of interest on the contours are:
5In one particular case, this is a well-known problem. When the tiling is on the vertical direction only, we
get ﬁnite automata with labels for controlling sequential program executions. Large programs are diﬃcult
to cope with using “go-to programs” corresponding to ﬁnite automata. The well-known solution to avoid
using labels in sequential programming is to use “structured programming” based on a particular class of
regular expressions.
6Renaming is also used in getting regular expressions for Petri nets [137] and timed automata [18].

236
From Action Systems to Distributed Systems: The Reﬁnement Approach
(a)
(b)
(c)
Figure 16.5: Restricted word composition
• side borders (w = west, i.e., vertical side border such that the cell at the right is inside
the word; e = east; etc.),
• land corners (nw = north-west corner seen from inside the word, i.e., the cell at the
bottom-right of the point is inside the word, while the other three cells around are not
inside the word; ne = north-east; etc.) and
• golf corners (nw’ = north-west corner seen from outside the word, i.e., the cell at
the bottom-right of the point is outside the word, while those at the top-right and
bottom-left are inside the word; ne’ = north-east golf corner; etc.).
Example 16.3. To get the words corresponding to the scenario composition in Figure 16.3,
we can use compositions based on the following restrictions:
1. v(w=e)w - the west border of v is equal to the east border of w; this yields a result
similar to the one presented in Figure 16.3(a);
2. v(sw’=sw)w - the south-west golf corners of v (there is only one) are identiﬁed
with the south-west land corners of w (there is only one); this restriction is good for
Figure 16.3(b);
3. v(ne>nw)w - the north-east corners of v (there are two) include the north-west corners
of w (there is only one); this is good for Figure 16.3(c).
These restricted compositions are illustrated in Figure 16.5.
Remark: Corner composition should be used with care. For instance, we can constrain
the order of elements on a diagonal as in (a(se=nw)b)(se=nw)c, which is not possible
using tiles alone, as they only constrain horizontally-vertically connected cells. However, it
can be done if we have cells near diagonal to ensure hv-connections between the cells on the
diagonal.
General restricted word composition: A general restricted composition is deﬁned as fol-
lows. Suppose we are given:
1. Two words v, w; a subset Y of elements of the contour of v (emphasized elements
on the contour of v as in Figure 16.6); a subset G of elements of the contour of w
(emphasized elements on the contour of w); the subset B of actual contact elements
after composing v with w via the points indicated by the little arrows (the emphasized
elements in the composed R(Y , G, B) picture in Figure 16.6).

Self-Assembling Interactive Modules: A Research Programme
237
(a) v
(b) w
(c) v R(Y , G, B) w
Figure 16.6: General restricted composition
2. a relation R(Y , G, B) between the above three subsets7.
The resulted restricted composition is denoted by v R(Y , G, B) w. The iterated version of
R(Y , G, B) is denoted by
∗R(Y , G, B).
16.2.3
Global Constraints: Regular Expressions
Regular expressions. A new approach for deﬁning classes of two-dimensional regular
expressions has been introduced in [44, 46, 45]. It is based on words with arbitrary shapes
and classes of restricted composition operators.
The basic class n2RE uses compositions and iterated compositions corresponding to the
following restrictions (see [45] for more details and examples):
1. the selected elements of the word contours are: side borders, land corners, and golf
corners;
2. the atomic comparison operators are: equal-to ‘=’, included-in ‘<’, non-empty intersec-
tion ‘#’;
3. the general comparison formulas are boolean formulas built up from the atomic for-
mulas deﬁned in 2.
An enriched class x2RE [45] is obtained adding “extreme cells” glueing control. A cell
is extreme in a word if it has at most one neighbouring cell in that word, considering all
vertical, horizontal, and diagonal directions. The restricted composition may use elements
of interest of the contours belonging to extreme cells. They are denoted by preﬁxing the
normal n2RE restrictions with an ‘x’; e.g., xw, xse, xnw’, etc. For instance, v(e>xw)w is
true if the west borders of the extreme cells in w are included in the east borders of v.
16.2.4
Systems of Recursive Equations
A system of recursive equations is deﬁned using variables representing sets of (two-
dimensional) words and regular expressions. Formally, a system of recursive equations is
represented by:





X1
=
P
i1=1,k1 E1i1(X1, . . . , Xn)
. . .
Xn
=
P
in=1,kn Enin(X1, . . . , Xn)
7For the example in Figure 16.6, a relation R making the restricted composition valid may be: G ⊆
Y ∧G ⊆B (after composition, all the emphasized elements on the contour of w are on the common border
and included in the set of emphasized elements of v).

238
From Action Systems to Distributed Systems: The Reﬁnement Approach
Figure 16.7: Recursive equations
where Xi are variables (denoting sets of words) and Eij are regular expressions over a given
alphabet, extended with occurrences of variables Xi.
Comments: A basic operation here is the substitution of 2-dimensional word languages for
the variables Xi used in these equations. A similar operation, but restricted to rectangular
words, has been used in [81, 80] to deﬁne tile grammars. Our formalism, using arbitrary
shape words, may be seen as a generalization of this mechanism.
Example 16.4. The language consisting of square words ﬁlled with a, except for the cen-
ter which contains x, may be represented by the following system/equation, illustrated in
Figure 16.7:
(*) X = x + E(X)
where:
Er = (3(1a*(e=w))1(se=ne)(2a*(s=n))2)3
(5(sw=ne))5 (4(1a*(e=w))1(nw=sw)(2a*(s=n))2)4
Erect = (Er(6(nw>ne)&(nw>sw))6a) (7(se>ne)&(se>sw))7 a
E(X) = X(8(n<s)&(e<w)&(s<n)&(w<e))8Erect
The expression within the parentheses with index 1 in Er generates horizontal bars of a’s.
The one in 2 produces vertical bars. The restrictions in 3 and 4 orthogonally glue the bars
in corners, yielding ‘⌝’ and ‘⌞’ shapes, respectively. Finally, 5 constrains these two corners
to produce a rectangle, without the nw and se corners. Then, the constraints 6 and 7 in
Erect ﬁll in a’s in these corners. For E(X), the restriction 8 requires X to have all borders
included in those of Erect, hence X has to be a rectangle itself and to ﬁll the whole interior
part of the rectangle speciﬁed by Erect. Finally, the recursive procedure (*) starts with a
square x, so we get precisely the required square words.
Example 16.5. The example above can be adapted to produce square diamonds of b’s,
having y in the center (Y in Figure 16.7). Indeed, instead of the restrictions (e=w) and
(s=n), used in 1 and 2, one can use (se=nw) and (sw=ne), respectively, to produce
diagonal bars. To produce orthogonal diagonals, as in 3 and 4, is slightly more complicated:
use extreme cells to locate the corners in the heads of the diagonal bars to be connected.
The remaining part is similar. As a last remark, notice that the resulting expression is in
x2RE, not in n2RE.
Example 16.6. Finally, U and V in Figure 16.7 describe a mutually recursive construction
built on top of the languages in the previous examples.

Self-Assembling Interactive Modules: A Research Programme
239
16.3
Structural Characterisation for Self-Assembling Tiles
In this section we present the proposed research plan.
16.3.1
From Local to Global Constraints
A main question in understanding the tiling procedure is the connection between: (1)
the local representation using tiles, scenarios, and labels on borders; and (2) the global
representation making use of regular expressions and systems of recursive equations.
Here, we are particularly interested in one direction:
Q1: Is it possible to get representations by systems of recursive equations for all tile sys-
tems?
Q2: What is a minimal set of regular expressions expressive enough to represent tile sys-
tems?
Q3: Can we ﬁnd a kind of “normal form representation” for these systems of recursive
equations?
And ﬁnally,
Q4: Is it possible to develop a (correct and complete) algebraic approach for modelling tile
systems?
16.3.2
Languages Generated by Two-Colors Border Tiles
A minimal, non-trivial SATS should have at least two labels for each vertical and hor-
izontal dimension. Up to a bijective representation, the tiles of a SATS using two distinct
labels for each vertical and horizontal dimension can be seen as elements in the following set
.
In this representation, the labels for the vertical and the horizontal borders are denoted by
0/1.
The letter associated to a tile is the hexadecimal number obtained from the binary
representation of the sequence of its west-north-east-south 0/1 digits, in this order; for
instance, the label of the tile
is the number represented by 1011, hence b.
Notation: (1) Tiles: If A = {t1, . . . , tk} is a subset of {0, 1, . . . , f }, then a SATS deﬁned
by the tiles in A is denoted by Ft1t2 . . . tk. To have an example, F02ac consists of tiles
.
(2) External labels: A SATS also uses labels for the external borders of its accepting sce-
narios. The recursive speciﬁcations below will use variables Xwnes denoting the set of words
recognised by scenarios with w/n/e/s on their west/north/east/south borders, respectively.
Here, for simplicity, we add the restriction to have only one label for each west/north/east/
south external border. Then, Ft1t2 . . . tk completely deﬁnes a SATS by specifying the labels
used for the external borders. There are at most 16 possibilities, each one denoted by a
hexadecimal number representing the sequence of the west-north-east-south 0/1 labels used
for the external borders.

240
From Action Systems to Distributed Systems: The Reﬁnement Approach
(3) Final notation: To conclude, the SATSs to be investigated are represented as
Ft1t2 . . . tk.z, where t1, t2, . . . , tk are the tiles and the binary digits of z specify the labels
used for the external borders.
As an example, F02ac.c consists of: (1) tiles
and (2) labels for external
borders: 1 on west, 1 on north, 0 on east, and 0 on south.
The research programme: The goal of the proposed research programme is to:
P1 Find representations by systems of recursive equations for the languages generated by
all SATSs Ft1 . . . tk.z (there are 1048576 cases to consider - 216 subsets of tiles and 24
combinations of border labels for each subset);
P2 Extend these representations to SATSs with any number of labels for borders (and any
number of labels for external borders).
16.3.3
A Case Study: F02ac.c
To start the analysis, note that we can construct any shape of
and
, and vertical
bars of
. The last tile
can be composed with itself, in a connected word, only
along the diagonal. There are four possible direction changes for
, denoted by letters
X, Y , Z, T. A direction change in an hv-connected component is possible if: (1) one can
insert one tile in interior, as in X3; or (2) one can insert two tiles on exterior areas as in X1
and X2. Three interior direction changes via Y 3, Z3, T3 are not possible; the last one, X3,
may be ﬁlled with
. On the other hand, via exterior connections only the combination
Z1&Z2 is possible using, say,
and
.
X1
X2
X3
Y 1
T1
Y 3
T3
Y 2
T2
Z3
Z1
Z2
U
To ﬁll in the area U we need a horizontal passing from border 0 to 1, and this may be
done by horizontal words from the expressions 0∗2a∗.

Self-Assembling Interactive Modules: A Research Programme
241
The north selected label is 1, hence the top of each column should start with an c. Hence,
in a ﬁrst approximation, an hv-connected component of an accepted word should have the
hat-form above.
The general format of an hv-component is slightly more complicated: two hat-
forms, as before, can be connected via the cells of their extreme bottom legs as in
.
To get a recursive speciﬁcation for the hat-form we proceed as follows:
1. construct a shape C1 for c’s as two diagonals connected on the top cells;
2. construct horizontal bars with 0’s on the left, a’s on the right, and separated by a 2;
3. iteratively ﬁll with these bars the shape C1, requiring to completely connect their
west, north, and east borders; let C2 be the resulting word;
4. ﬁnally, iteratively connect C2 with horizontal bars of 0’s on west-north and horizon-
tal bars of a’s on north-east, completely connecting their west-north and north-east
borders, respectively.
It is not diﬃcult to see that this procedure may be formalized by a system of recursive
equations using expressions in n2RE. One possibility is X11 deﬁned by the following system
of recursive equations:
X1 = c + c (sw=ne) X1
X2 = X1 (ne=nw) 2
X3 = c + c (se=nw) X3
X4 = X2 (ne=nw) X3
X5 = c (s<n)&!(sw#nw)&!(se#ne) X4
X6 = ((0 *(e=w)) (e=w) 2)(e=w) (a *(e=w))
X7 = (0 *(e=w))
X8 = (a *(e=w))
X9 = X5 + X6 (n<s)&(w<e)&(e<w) X9
X10 = X9 + X7 (n<s)&(w<e) X10
X11 = X10 + X8 (n<s)&(e<w) X11
The patterns deﬁned by X1, . . . , X11 are illustrated in Figure 16.8.
For the general format, consisting in connected hat-forms, one can use an x2RE variation
of the previous system. Use an additional X5′ deﬁned by (!x means non-extreme)
X5′ = X5 + X5((xne<xsw)&!((!x)nw#sw))X5′
and change X9 to
X9 = X5′ + . . .

242
From Action Systems to Distributed Systems: The Reﬁnement Approach
Figure 16.8: Recursive speciﬁcations

Self-Assembling Interactive Modules: A Research Programme
243
16.4
Interactive Programs
A classical slogan states that “program = control + data”. The control part for simple
sequential programs is provided by ﬁnite automata. We can extend this saying that “dis-
tributed program = (control & interaction) + data”. The control & interaction part may be
speciﬁed by SATSs. In this section we brieﬂy show how data can be added to SATSs to get
completely speciﬁed distributed programs. Actually, one can use either SATSs or regular
expressions for specifying the control & interaction part of a distributed program.
16.4.1
Words and Traces in Two Dimensions
Recently, 2-dimensional languages have been used to study parallel, interactive, dis-
tributed systems [319, 122, 121, 45, 110]; we simply call them interactive systems. In these
studies, the approach is less syntactical considering words up to a graph-isomorphism equiv-
alence [109, 110]. This means, one uses two types of letters: connectors in a set C and
(uninterpreted) statements in a set X. Then, two words over C ∪X are considered equiv-
alent if they have the same occurrences of letters in X connected in the same way via the
elements in C. In other words, the placement of the letters in X in the cells of a word does
not matter, as long as elements in C are used to ensure the connecting structure between
the elements in X is the same.
The model of SATSs is not universal. To compare this class with 1-dimensional languages,
one can consider a 1-dimensional projection, for instance considering only the top row of
the accepted rectangular 2-dimensional words. This way one gets a class of usual languages;
by a theorem in [222], this class coincides with the class of context-sensitive languages. A
universal class can be easily obtained putting more information around the letters of the
words. Scenarios for real computations, as the ones used in rv-systems [319] or in Agapia
programming [121, 268], have complex spatial and temporal data attached to the cells. They
are universal.
In most studies on 2-dimensional languages there is no distinction between the vertical
and the horizontal dimension. The interpretation used in interactive systems is somehow dif-
ferent, considering the vertical dimension to represent the temporal evolution of the system,
while the horizontal dimension takes into account the spatial aspects of the system. This
way, a natural notion of 2-dimensional trace occurs: a column represents a process run (in
an interacting environment), while a row describes a “transaction”, i.e., a chain of process
interactions via message passing (in a state dependent processing environment).
A notion of trace-based reﬁnement for (structured) interactive systems has been recently
presented in [110]. Traces represent running scenarios modulo graph-isomorphism, projected
on classes and states. In this interpretation one focuses on data stored in or ﬂowing through
the cells of the interactive system.
16.4.2
Interactive Modules and Programs
In a SATS, a tile
, linearly represented as X:⟨w | n⟩→⟨e | s⟩, uses elements from
an abstract ﬁnite set to label the borders. These labels are used for deﬁning the control and
the interaction used in interactive systems. In concrete, executable interactive systems the

244
From Action Systems to Distributed Systems: The Reﬁnement Approach
control/interaction labels are enriched with data. The data on the north and south borders
are represented as spatial data implemented on memory, while the data on the west and east
borders are temporal data implemented on streams. The former spatial data represent the
states of the interactive processes, while the latter temporal data represents the messages
ﬂowing between processes.
An interactive module is a cell with: (1) control/interaction labels and temporal/spatial
data on its borders, and (2) a speciﬁcation of a relation between border data. The relation
describing the module functionality may be speciﬁed with a program, or in another way.
Example 16.7. We present a distributed program for a communication protocol between
two parties using a channel which, due to time constrains, may decide to drop some data.
During the ﬁrst attempt of sending data, the sender keeps all the messages, while the receiver
keeps two sets: one with received messages and one with the indices of missing ones. Then,
the receiver sends indices of missing elements one by one to the sender waiting to receive
those missing elements.
We use the convention that ⌢separate data on west or east borders coming from diﬀerent
modules, while ⌣is similarly used, but for north or south borders. The overall behaviour of
the protocol, corresponding to the scenario in Figure 16.9, is:
Protocol:⟨a⌢b⌢c | 0, ∅⟩→⟨a⌢b⌢c | ∅⟩
First we give the speciﬁcation of the modules, then we present the scenario.
Modules:
Send-and-Keep:
SK:⟨x | i, Y ⟩→⟨(i, x) | i + 1, Y ∪{(i, x)}⟩;
Communicate-Yes/No:
CY :⟨(i, x) | ⟩→⟨(i, x) | ⟩;
CN:⟨(i, x) | ⟩→⟨(i, ?) | ⟩;
Receive-and-Keep:
RK:⟨(i, x) | U, V ⟩→⟨| U, V ∪{(i, x)}⟩; RK:⟨(i, ?) | U, V ⟩→⟨| U ∪{i}, V ⟩
Send-first-bunch-End:
SEnd:⟨| i, U⟩→⟨(i, end) | U⟩;
Receive-first-bunch-End:
REnd:⟨(n, end) | U, V ⟩→⟨i | U\{i}, V ⟩, for i ∈U
REnd:⟨(n, end) | ∅, V ⟩→⟨OK | V ⟩
Receive-and-Keep-at-Request:
RKR:⟨(i, x) | U, V ⟩→⟨j | U\{i}, V ∪{(i, x)}⟩, for i ∈U and j ∈U\{i};
RKR:⟨(i, x) | U, V ⟩→⟨OK | V ∪{(i, x)}⟩, if U = {i};
RKR:⟨(i, ?) | U, V ⟩→⟨i | U, V ⟩, for i ∈U;
Output-Stream:
OS:⟨| V ⟩→⟨x | V \{(i, x)}⟩, if (i, x) ∈V and i = min{j : (j, y) ∈V };
Scenario: An example of a running scenario8 is presented in Figure 16.9.
Interactive programs may be introduced on top of interactive modules in two ways: (1)
either in an unstructured way using tiles with labels, or (2) in a structured way using (par-
ticular) regular 2-dimensional expressions. The rv-programs in [318, 319] use the ﬁrst option.
8The drawn “back-arrows” represent a short notation for diagonal composition [121, 122]. The ‘0’ cells
may be omitted if we do not stick to rectangular words/scenarios.

Self-Assembling Interactive Modules: A Research Programme
245
0, ∅
∅, ∅
a
SK
(1, a)
CY
(1, a)
RK
1, {(1, a)}
∅, {(1, a)}
b
SK
(2, b)
CN
(2, ?)
RK
2, {(1, a), (2, b)}
{2}, {(1, a)}
c
SK
(3, c)
CY
(3, c)
RK
3, {(1, a), (2, b), (3, c)}
{2}, {(1, a), (3, c)}
SEnd
(3, end) CY (3, end)
REnd
2
{(1, a), (2, b), (3, c)}
∅, {(1, a), (3, c)} 
-
2
SR
(2, b)
CY
(2, b)
RKR
OK
{(1, a), (2, b), (3, c)}
{(1, a), (3, c), (2, b)}
- OK
End
0
OS
a
{(3, c), (2, b)}
0
0
OS
b
{(3, c)}
0
0
OS
c
∅
Figure 16.9: A scenario for the communication protocol example
On the other hand, Agapia structured interactive programming [121, 268] is based on the
second possibility, using rectangular 2-dimensional words/scenarios and three particular
composition operators, together with their iterated versions: horizontal, vertical, and diago-
nal composition.
16.4.3
Reﬁnement of Structured Interactive Programs
The presented formalism, based on self-assembling interactive modules, can be used as
a basis for a reﬁnement-based design. The approach consists of the following steps:
Basic step: A starting simple speciﬁcation S0 may be introduced using independent spec-
iﬁcations for process behaviours (columns) and for transactions (chains of interactions
used in rows). In this step ﬁnite automata are used.
Matching control and interaction: This step reﬁnes S0 to a speciﬁcation S1 using sce-
narios with a ﬁnite number of border labels (i.e., memory states and interaction
classes). For S1 use a SATS9 for control and interaction. Reﬁnement correctness here
requires the rows and the columns of S1 satisfy speciﬁcation S0.
Adding data: In this step, a new speciﬁcation S2 is obtained by adding to the border labels
concrete data for memory states and interaction messages around each scenario cell.
This way one gets running scenarios describing concrete computations. The correctness
criterion in this step is easy to formulate: by dropping the additional data and keeping
the labels only, one must get simple patterns of control and interaction satisfying S1.
Iterated data and computation reﬁnement: Iterated reﬁnement of data and compu-
tation, preserving trace semantics.
9Recall that what we call here a “SATS” was introduced and used under the name “ﬁnite interactive
system” in this context; see [318, 319] and the subsequent papers.

246
From Action Systems to Distributed Systems: The Reﬁnement Approach
This trace-based reﬁnement design is presented in an abstract way here, no programming
language being involved. Actually, it was introduced in combination with the programming
language Agapia for describing running scenarios in structured interactive programs [110].
An open problem is to lift this trace-based reﬁnement deﬁnition to a reﬁnement deﬁnition
on Agapia programs themselves.
16.5
Conclusions
Sequential computation is already a mature research subject. A witness is the rich al-
gebraic theories based on regular expressions and the associated regular algebra [202, 289,
85, 209, 315, 206]. Recent extensions of regular algebra to network algebra [314, 316] show
a broader area of applications and deep connections with classical mathematics, especially
via the particular instance provided by trace monoidal categories [197, 297]. The present ap-
proach is an attempt to extend these formalisms to open, distributed, interactive programs.
There are a few models for parallel/distributed computation based on regular expressions.
We mention two of them: regular expressions for Petri nets [137] and for timed automata
[18]. Both are based on renaming and intersection, two questionable operations.
Our work on this subject started with the exploration of space-time duality and its role in
organizing the space of interactive computation: (1) A space-time invariant model extending
ﬂowcharts was shown in [318, 319]. (2) A space-time invariant extension of (structured)
while programs was presented in [121]. (3) An enriched version supporting recursion was
presented in [268]. (4) Space-time invariant (2-dimensional) regular expressions are presented
in [44, 46, 45] and in the current paper. (5) Veriﬁcation methods lifting Floyd and Hoare
logics to 2-dimensions have been described, too. (6) A notion of reﬁnement, based on this
space-time invariant model, was introduced in [109, 110].
To conclude: the proposed research programme on clarifying the structure of self-
assembling (2-dimensional) tiles is not only of general interest, but it is also very important
in understanding open, distributed, interactive computation.

Bibliography
[1] M. Abadi and L. Lamport. An old-fashioned recipe for real time. In J. W. de Bakker,
C. Huizing, W. P. de Roever, and G. Rozenberg, editors, Real-Time: Theory in Prac-
tice, REX Workshop, Mook, The Netherlands, June 3-7, 1991, Proceedings, volume
600 of Lecture Notes in Computer Science, pages 1–27. Springer, 1991.
[2] J. Abrial, M. J. Butler, S. Hallerstede, T. S. Hoang, F. Mehta, and L. Voisin. Rodin:
an open toolset for modelling and reasoning in event-b. STTT, 12(6):447–466, 2010.
[3] J. Abrial, D. Cansell, and D. Méry. A mechanically proved and incremental develop-
ment of IEEE 1394 tree identify protocol. Formal Aspects of Computing, 14(3):215–227,
2003.
[4] J. Abrial and L. Mussat. Introducing dynamic constraints in B. In D. Bert, editor,
B’98: Recent Advances in the Development and Use of the B Method, Second Inter-
national B Conference, Montpellier, France, April 22-24, 1998, Proceedings, volume
1393 of Lecture Notes in Computer Science, pages 83–128. Springer, 1998.
[5] J.-R. Abrial. The B-Book: Assigning Programs to Meanings. Cambridge University
Press, 1996.
[6] J.-R. Abrial. Modeling in Event-B: System and Software Engineering. Cambridge Uni-
versity Press, 2010.
[7] ABS tools. http://tools.hats-project.eu.
[8] G. A. Agha. ACTORS - A Model of Concurrent Computation in Distributed Systems.
MIT Press series in artiﬁcial intelligence. MIT Press, 1990.
[9] W. Ahrendt and M. Dylla. A system for compositional veriﬁcation of asynchronous
objects. Science of Computer Programming, 77(12):1289–1309, 2012.
[10] M. Åkerfelt, R. I. Morimoto, and L. Sistonen. Heat shock factors: integrators of cell
stress, development, and lifespan. Nature Reviews Molecular Cell Biology, 11(8):545–
555, 2010.
[11] E. Albert, P. Arenas, A. Flores-Montoya, S. Genaim, M. Gómez-Zamalloa, E. Martin-
Martin, G. Puebla, and G. Román-Díez. SACO: static analyzer for concurrent objects.
In E. Ábrahám and K. Havelund, editors, Proc. 20th International Conference on Tools
and Algorithms for the Construction and Analysis of Systems (TACAS’14), volume
8413 of Lecture Notes in Computer Science, pages 562–567. Springer, 2014.
[12] E. Albert, F. S. de Boer, R. Hähnle, E. B. Johnsen, and C. Laneve. Engineering
virtualized services. In M. A. Babar and M. Dumas, editors, 2nd Nordic Symp. Cloud
Computing & Internet Technologies, pages 59–63. ACM, 2013.
247

248
Bibliography
[13] E. Albert, F. S. de Boer, R. Hähnle, E. B. Johnsen, R. Schlatte, S. L. T. Tarifa, and
P. Y. H. Wong. Formal modeling and analysis of resource management for cloud archi-
tectures: an industrial case study using Real-Time ABS. Service Oriented Computing
and Applications, 8(4):323–339, 2014.
[14] B. Alpern and F. B. Schneider. Deﬁning liveness. Information Processing Letters,
21(4):181 – 185, 1985.
[15] R. Alur and D. L. Dill. A theory of timed automata. Theoretical Computer Science,
126(2):183 – 235, 1994.
[16] K. R. Apt, F. S. de Boer, and E.-R. Olderog. Veriﬁcation of Sequential and Concurrent
Systems. Texts and Monographs in Computer Science. Springer, 3rd edition, 2009.
[17] F. Arnold, A. Belinfante, F. Van der Berg, D. Guck, and M. Stoelinga. DFTCalc:
A tool for eﬃcient fault tree analysis. In F. Bitsch, J. Guiochet, and M. Kaaniche,
editors, Computer Safety, Reliability, and Security, volume 8153 of Lecture Notes in
Computer Science, pages 293–301. Springer Berlin Heidelberg, 2013.
[18] E. Asarin, P. Caspi, and O. Maler. Timed regular expressions. Journal of the ACM,
49:172–206, 2002.
[19] P. Asirelli, M. H. ter Beek, A. Fantechi, and S. Gnesi. A logical framework to deal
with variability. In Integrated Formal Methods - 8th International Conference, IFM
2010, Nancy, France, October 11-14, 2010. Proceedings, volume 6396 of Lecture Notes
in Computer Science, pages 43–58. Springer-Verlag, 2010.
[20] P. Asirelli, M. H. ter Beek, S. Gnesi, and A. Fantechi. Formal description of variabil-
ity in product families. In SPLC ’11: Proceedings of the 15th International Software
Product Line Conference, Volume 2, pages 130–139. ACM, 2011.
[21] A. Aswani, N. Master, J. Taneja, D. E. Culler, and C. Tomlin. Reducing transient and
steady state electricity consumption in HVAC using learning-based model-predictive
control. Proceedings of the IEEE, 100(1):240–253, 2012.
[22] A. Avizienis, J.-C. Laprie, B. Randell, and C. Landwehr. Basic concepts and taxonomy
of dependable and secure computing. IEEE Transactions on Dependable and Secure
Computing, 1(1):11–33, 2004.
[23] R. J. Back. On the Correctness of Reﬁnement in Program Development. PhD thesis,
Department of Computer Science, University of Helsinki, 1978.
[24] R. J. Back. Correctness preserving program reﬁnements: Proof theory and applica-
tions. Mathematical Center Tracts, 131, 1980.
[25] R. J. Back. Reﬁnement calculus ii: parallel and reactive programs. In J. de Bakker, W.-
P. de Roever, and G. Rozenberg, editors, Stepwise Reﬁnement of Distributed Systems:
Models, Formalisms, Correctness, volume 430 of Lecture Notes in Computer Science,
pages 67–93. Springer-Verlag, 1990.
[26] R. J. Back. Atomicity reﬁnement in a reﬁnement calculus framework, reports on com-
puter science and mathematics 141. Technical report, Åbo Akademi, 1993.

Bibliography
249
[27] R. J. Back and R. Kurki-Suonio. Decentralization of process nets with centralized.
In Proceedings of the 2nd ACM SIGACT-SIGOPS Symp. on Principles of Distributed
Computing, pages 131–142, 1983.
[28] R. J. Back and R. Kurki-Suonio. Decentralization of process nets with centralized
control. Distributed Computing, 3(2):73–87, 1983.
[29] R. J. Back and R. Kurki-Suonio. Distributed cooperation with action systems. ACM
Transactions on Programming Languages and Systems, 10(4):513–554, 1988.
[30] R. J. Back, L. Petre, and I. Porres. Continuous action systems as a model for hybrid
systems. Nordic Journal of Computing, 8(1):2–21, 2001.
[31] R. J. Back and K. Sere. Stepwise reﬁnement of action systems. In J. L. A. van de
Snepscheut, editor, Mathematics of Program Construction, 375th Anniversary of the
Groningen University, International Conference, Groningen, The Netherlands, June
26-30, 1989, Proceedings, volume 375 of Lecture Notes in Computer Science, pages
115–138. Springer, 1989.
[32] R. J. Back and K. Sere. Stepwise reﬁnement of action systems. Structured Program-
ming, 12(1):17–30, 1991.
[33] R. J. Back and K. Sere. From action systems to modular systems. In M. Naftalin,
T. Denvir, and M. Bertran, editors, FME ’94: Industrial Beneﬁt of Formal Meth-
ods, volume 873 of Lecture Notes in Computer Science, pages 1–25. Springer Berlin
Heidelberg, 1994.
[34] R. J. Back and K. Sere. From action systems to modular systems. Software - Concepts
and Tools, 17:26–39, 1996.
[35] R. J. Back and K. Sere. Superposition reﬁnement of reactive systems. Formal Aspects
of Computing, 8(3):324–346, 1996.
[36] R. J. Back and J. von Wright. Reﬁnement calculus i: Sequential nondeterministic
programs. In J. de Bakker, W.-P. de Roever, and G. Rozenberg, editors, Stepwise
Reﬁnement of Distributed Systems: Models, Formalisms, Correctness, volume 430 of
Lecture Notes in Computer Science, pages 42–66. Springer-Verlag, 1990.
[37] R. J. Back and J. von Wright. Trace reﬁnement of action systems. In B. Jonsson and
J. Parrow, editors, CONCUR-94:Concurrency Theory, volume 836 of Lecture Notes in
Computer Science, pages 367–384, Uppsala, Sweden, Aug 1994. Springer-Verlag.
[38] R. J. Back and J. von Wright. Reﬁnement Calculus: A Systematic Introduction.
Springer-Verlag, 1998.
[39] C. Baier and J. Katoen. Principles of Model Checking. MIT Press, 2008.
[40] R. Banach and M. Bozzano. The mechanical generation of fault trees for reactive
systems via retrenchment I: combinational circuits. Formal Aspects of Computing,
25(4):573–607, 2013.
[41] R. Banach and M. Bozzano. The mechanical generation of fault trees for reactive sys-
tems via retrenchment II: clocked and feedback circuits. Formal Aspects of Computing,
25(4):609–657, 2013.

250
Bibliography
[42] R. Banach and M. Butler. Cruise control in hybrid event-b. In Z. Liu, J. Woodcock,
and H. Zhu, editors, Theoretical Aspects of Computing - ICTAC 2013, volume 8049 of
Lecture Notes in Computer Science, pages 76–93. Springer-Verlag Berlin Heidelberg,
2013.
[43] R. Banach, H. Zhu, W. Su, and R. Huang. Continuous kaos, asm, and formal con-
trol system design across the continuous/discrete modeling interface: a simple train
stopping application. Formal Aspects of Computing, 26(2):319–366, 2014.
[44] I. Banu-Demergian, C. Paduraru, and G. Stefanescu. A new representation of two-
dimensional patterns and applications to interactive programming. In FSEN 2013,
volume 8161 of Lecture Notes in Computer Science, pages 172–206. Springer, 2013.
[45] I. Banu-Demergian and G. Stefanescu. Towards a formal representation of interactive
systems. Fundamenta Informaticae, 131:313–336, 2014.
[46] I. Banu-Demergian and G. Stefanescu. On the contour representation of two-
dimensional patterns. Carpathian Journal Mathematics, 2016. To appear.
[47] G. Behrmann, A. David, and K. G. Larsen. A tutorial on UPPAAL. In M. Bernardo
and F. Corradini, editors, Formal Methods for the Design of Real-Time Systems, vol-
ume 3185 of Lecture Notes in Computer Science, pages 200–237. Springer Verlag, 2004.
[48] N. Benes and J. Kretínský. Process algebra for modal transition systems. In Sixth
Doctoral Workshop on Mathematical and Engineering Methods in Computer Science,
MEMICS 2010, Selected Papers, October 22-24, 2010, Mikulov, Czech Republic, pages
9–18, 2010.
[49] N. Benes, J. Kretínský, K. G. Larsen, M. H. Møller, and J. Srba. Parametric modal
transition systems. In Automated Technology for Veriﬁcation and Analysis, 9th Inter-
national Symposium, ATVA 2011, Taipei, Taiwan, October 11-14, 2011. Proceedings,
pages 275–289, 2011.
[50] N. Benes, J. Kretínský, K. G. Larsen, and J. Srba. Exptime-completeness of thorough
reﬁnement on modal transition systems. Information and Computation, 218:54–68,
2012.
[51] N. Beneš. Disjunctive Modal Transition Systems. PhD thesis, Faculty of Informatics,
Masaryk University, Brno, 2012.
[52] J. Bengtsson, K. G. Larsen, F. Larsson, P. Petterson, and W. Yi. UPPAAL — a tool-
suite for the automatic veriﬁcation of real-time systems. In R. Alur, T. Henzinger, and
E. D. Sontag, editors, Hybrid Systems III, volume 1066 of Lecture Notes in Computer
Science, pages 232–243. Springer, 1996.
[53] J. Bergstra, A. Ponse, and S. Smolka, editors. Handbook of Process Algebra. Elsevier
Science Inc., New York, NY, USA, 2001.
[54] J. Berthing, P. Boström, K. Sere, L. Tsiopoulos, and J. Vain. Reﬁnement-based de-
velopment of timed systems. In J. Derrick, S. Gnesi, D. Latella, and H. Treharne,
editors, Integrated Formal Methods – 9th International Conference, IFM 2012, Pisa,
Italy, June 18-21, 2012. Proceedings, volume 7321 of Lecture Notes in Computer Sci-
ence, pages 69–83. Springer, 2012.

Free ebooks ==>   www.Ebook777.com
Bibliography
251
[55] J. Bicarregui, A. Arenas, B. Aziz, P. Massonet, and C. Ponsard. Towards modelling
obligations in Event-B. In Abstract State Machines, B and Z, volume 5238 of Lecture
Notes in Computer Science, pages 181–194. Springer, 2008.
[56] J. Bjørk, F. S. de Boer, E. B. Johnsen, R. Schlatte, and S. L. Tapia Tarifa. User-deﬁned
schedulers for real-time concurrent objects. Innovations in Systems and Software En-
gineering, 9(1):29–43, 2013.
[57] M. L. Blinov, J. R. Faeder, B. Goldstein, and W. S. Hlavacek. BioNetGen: Software
for rule-based modeling of signal transduction based on the interactions of molecular
domains. Bioinformatics, 20(17):3289–3291, 2004.
[58] E. Boiten and J. Derrick. Modelling divergence in relational concurrent reﬁnement. In
M. Leuschel and H. Wehrheim, editors, IFM 2009: Integrated Formal Methods, volume
5423 of Lecture Notes in Computer Science, pages 183–199. Springer Verlag, February
2009.
[59] E. Boiten and J. Derrick. Incompleteness of relational simulations in the blocking
paradigm. Science of Computer Programming, 75(12):1262–1269, 2010.
[60] E. Boiten, J. Derrick, and G. Schellhorn. Relational concurrent reﬁnement II: internal
operations and outputs. Formal Aspects of Computing, 21(1-2):65–102, 2009.
[61] M. M. Bonsangue and J. N. Kok. The weakest precondition calculus: recursion and
duality. Formal Aspects of Computing, 6A:788–800, 1994.
[62] M. M. Bonsangue, J. N. Kok, and K. Sere. An approach to object-orientation in
action systems. In J. Jeuring, editor, Mathematics of Program Construction (MPC’98),
volume 1422 of Lecture Notes in Computer Science, pages 68–95. Springer, 1998.
[63] P. Bouyer, F. Laroussinie, and P.-A. Reynier. Diagonal constraints in timed automata:
forward analysis of timed systems. In P. Pettersson and W. Yi, editors, FORMATS’05,
volume 3829 of Lecture Notes in Computer Science, pages 112–126. Springer- Heidel-
berg, 2005.
[64] J. Bowen and S. Reeves. Reﬁnement for user interface designs. Formal Aspects of
Computing, 21:589–612, 2009.
[65] J. Bowen and S. Reeves. Modelling safety properties of interactive medical systems.
In Proceedings of the 5th ACM SIGCHI Symposium on Engineering Interactive Com-
puting Systems, pages 91–100. ACM, 2013.
[66] M. Bozzano, A. Cimatti, and F. Tapparo. Symbolic fault tree analysis for reactive sys-
tems. In Automated Technology for Veriﬁcation and Analysis, volume 4762 of Lecture
Notes in Computer Science, pages 162–176. Springer Berlin Heidelberg, 2007.
[67] M. Bozzano and A. Villaﬁorita. The FSAP/NuSMV-SA safety analysis platform. In-
ternational Journal on Software Tools for Technology Transfer, 9(1):5–24, 2007.
[68] M. Bravetti and G. Zavattaro. Towards a Unifying Theory for Choreography Con-
formance and Contract Compliance. In Proceedings of 6th Symposium on Software
Composition, SC 2007, pages 34–50. Springer, 2007.
www.Ebook777.com

252
Bibliography
[69] P. Bulychev, A. David, K. G. Larsen, M. Mikučionis, D. B. Poulsen, A. Legay, and
Z. Wang. UPPAAL-SMC: Statistical model checking for priced timed automata. In
H. Wiklicky and M. Massink, editors, Quantitative Aspects of Programming Languages
and Systems, Proceedings of the 10th Workshop on, volume 85 of Electronic Proceed-
ings in Theoretical Computer Science, pages 1–16. Open Publishing Association, 2012.
[70] L. Burdy, Y. Cheon, D. R. Cok, M. D. Ernst, J. R. Kiniry, G. T. Leavens, K. R. M.
Leino, and E. Poll. An overview of JML tools and applications. International Journal
on Software Tools for Technology Transfer, 7(3):212–232, 2005.
[71] M. Butler. External and internal choice with event groups in Event-B. Formal Aspects
of Computing, 24(4-6):555–567, 2012.
[72] M. Butler and I. Maamria. Practical theory extension in event-b. In Theories of Pro-
gramming and Formal Methods - Essays Dedicated to Jifeng He on the Occasion of
His 70th Birthday, volume 8051 of Lecture Notes in Computer Science, pages 67–81.
Springer, 2013.
[73] M. Butler, E. Sekerinski, and K. Sere. An Action System Approach to the Steam Boiler
Problem. In Formal Methods for Industrial Applications: Specifying and Programming
the Steam Boiler Control, volume 1165 of Lecture Notes in Computer Science, pages
129–148. Springer-Verlag, 1996.
[74] R. Buyya, C. S. Yeo, S. Venugopal, J. Broberg, and I. Brandic. Cloud computing and
emerging IT platforms: Vision, hype, and reality for delivering computing as the 5th
utility. Future Generation Computer Systems, 25(6):599–616, 2009.
[75] D. Cansell, D. Meŕy, and J. Rehm. Time constraint patterns for Event B development.
In B 2007: Formal speciﬁcation and development in B, volume 4355 of Lecture Notes
in Computer Science, pages 140–154. Springer Heidelberg, 2007.
[76] L. Cardelli. On process rate semantics. Theoretical Computer Science, 391(3):190–215,
2008.
[77] Cardinal Health Inc. Alaris GP volumetric pump: directions for use. Technical report,
Cardinal Health, 1180 Rolle, Switzerland, 2006.
[78] G. Castagna, N. Gesbert, and L. Padovani. A Theory of Contracts for Web Services.
ACM Transactions on Programming Languages and Systems, 31(5):19:1–19:61, 2009.
[79] Z. Chaochen and M. Hansen. Duration Calculus: A Formal Approach to Real-Time
Systems. Springer, Heidelberg, 2004.
[80] A. Cherubini and M. Pradella. Picture Languages: From Wang Tiles to 2D Grammars.
In Algebraic Informatics, volume 5725 of Lecture Notes in Computer Science, pages
13–46. Springer-Verlag, 2009.
[81] A. Cherubini, S. C. Reghizzi, M. Pradella, and P. S. Pietro. Picture languages: tiling
systems versus tile rewriting grammars. Theoretical Computer Science, 356:90–103,
2006.
[82] W.-N. Chin, C. David, H.-H. Nguyen, and S. Qin. Enhancing modular OO veriﬁcation
with separation logic. In Proceedings of the 35th annual ACM SIGPLAN-SIGACT
symposium on Principles of programming languages, pages 87–99. ACM, 2008.

Bibliography
253
[83] F. Ciocchetta and J. Hillston. Bio-pepa: A framework for the modelling and analysis
of biological systems. Theoretical Computer Science, 410(33–34):3065–3084, 2009.
[84] P. Clements and L. Northrop. Software Product Lines: Practices and Patterns.
Addison-Wesley Professional, 2001.
[85] J. Conway. Regular Algebra and Finite Machines. Chapman and Hall, 1971.
[86] Council of the European Communities. Council directive 93/42/EEC of 14 June
1993 concerning medical devices. http://eur-lex.europa.eu/LexUriServ/
LexUriServ.do?uri=CONSLEG:1993L0042:20071011:EN:PDF, 2007.
[87] K. Culik II. An Aperiodic Set of 13 Wang Tiles. Discrete Mathematics, 160:245–251,
1996.
[88] O.-J. Dahl. Can program proving be made practical? In M. Amirchahy and D. Néel,
editors, Les Fondements de la Programmation, pages 57–114. Institut de Recherche
d’Informatique et d’Automatique, Toulouse, France, Dec. 1977.
[89] O.-J. Dahl. Veriﬁable Programming. International Series in Computer Science. Prentice
Hall, New York, N.Y., 1992.
[90] O.-J. Dahl. The birth of object orientation: the simula languages. In O. Owe, S. Krog-
dahl, and T. Lyche, editors, From Object-Orientation to Formal Methods, Essays in
Memory of Ole-Johan Dahl, volume 2635 of Lecture Notes in Computer Science, pages
15–25. Springer, 2004.
[91] O.-J. Dahl and O. Owe. Formal development with ABEL. In S. Prehn and H. Toetenel,
editors, Proc. Formal Software Development Methods (VDM’91), volume 552 of Lec-
ture Notes in Computer Science, pages 320–362. Springer, 1991.
[92] P. H. Dalsgaard, T. L. Guilly, D. Middelhede, P. Olsen, T. Pedersen, A. P. Ravn, and
A. Skou. A toolchain for home automation controller development. In 39th Euromicro
Conference on Software Engineering and Advanced Applications, SEAA 2013, pages
122–129. IEEE, 2013.
[93] V. Danos, J. Feret, W. Fontana, R. Harmer, and J. Krivine. Rule-based modelling,
symmetries, reﬁnements. In Formal Methods in Systems Biology, volume 5054 of Lec-
ture Notes in Computer Science, pages 103–122. Springer, 2008.
[94] V. Danos, J. Feret, W. Fontana, R. Harmer, and J. Krivine. Rule-based modelling and
model perturbation. In Transactions on Computational Systems Biology XI, volume
5750 of Lecture Notes in Computer Science, pages 116–137. Springer, 2009.
[95] V. Danos and C. Laneve. Formal molecular biology. Theoretical Computer Science,
325(1):69–110, 2004.
[96] R. Darimont and A. van Lamsweerde. Formal reﬁnement patterns for goal-driven
requirements elaboration. In Proceedings 4th ACM Symposium on the Foundations of
Software Engineering (FSE’03), pages 179–190. ACM Press, 1996.

254
Bibliography
[97] A. David, K. G. Larsen, A. Legay, U. Nyman, and A. Wasowski. Timed I/O Automata:
A complete speciﬁcation theory for real-time systems. In HSCC’10, Proceedings of the
13th ACM International Conference on Hybrid Systems: Computation and Control,
pages 91–100. ACM, 2011.
[98] F. S. de Boer. Reasoning about histories in object-based distributed systems. In
P. Ciancarini, A. Fantechi, and R. Gorrieri, editors, Formal Methods for Open Object-
Based Distributed Systems, volume 10 of IFIP - The International Federation for In-
formation Processing, pages 35–49. Springer US, 1999.
[99] F. S. de Boer, R. Hähnle, E. B. Johnsen, R. Schlatte, and P. Y. H. Wong. Formal
modeling of resource management for cloud architectures: An industrial case study.
In Proc. European Conference on Service-Oriented and Cloud Computing (ESOCC),
volume 7592 of Lecture Notes in Computer Science, pages 91–106. Springer, 2012.
[100] B. de Bono, P. Grenon, M. Helvenstijn, J. Kok, and N. Kokash. ApiNATOMY: To-
wards multiscale views of human anatomy. In Processings of the 13th International
Symposium on Intelligent Data Analysis (IDA), volume 8819 of Lecture Notes in Com-
puter Science, pages 72–83. Springer-Verlag, 2014.
[101] B. de Bono and P. Hunter. Integrating knowledge representation and quantitative
modelling in physiology. Biotechnology Journal, 7(8):958–972, 2012.
[102] W.-P. de Roever and K. Engelhardt. Data Reﬁnement: Model-Oriented Proof Methods
and their Comparison. Cambridge University Press, 2008.
[103] E. Deelman, G. Singh, M. Livny, G. B. Berriman, and J. Good. The cost of doing
science on the cloud: The Montage example. In Proceedings of the Conference on High
Performance Computing (SC’08), pages 1–12. IEEE/ACM, 2008.
[104] J. Derrick and E. Boiten. Relational concurrent reﬁnement. Formal Aspects of Com-
puting, 15(1):182–214, 2003.
[105] J. Derrick and E. Boiten. Reﬁnement in Z and Object-Z. Springer-Verlag, 2nd edition,
2014.
[106] J. Derrick and E. Boiten. Relational concurrent reﬁnement III: traces, partial relations,
and automata. Formal Aspects of Computing, 26(2):407–422, 2014.
[107] J. Derrick and E. A. Boiten. Relational concurrent reﬁnement with internal opera-
tions. In B. Aichernig, E. A. Boiten, J. Derrick, and L. Groves, editors, BCS-FACS
Reﬁnement Workshop, volume 187 of Electronic Notes in Theoretical Computer Sci-
ence, pages 35–53, 2007.
[108] J. Derrick and G. Smith. Temporal-logic property preservation under Z reﬁnement.
Formal Aspects of Computing, 24(3):393–416, 2012.
[109] D. Diaconescu, I. Leustean, L. Petre, K. Sere, and G. Stefanescu. Reﬁnement-
preserving translation from Event-B to register-voice interactive systems. In Proceed-
ings IFM 2012, Integrated Formal Methods, volume 7321 of Lecture Notes in Computer
Science, pages 221–236. Springer-Verlag, 2012.

Bibliography
255
[110] D. Diaconescu, L. Petre, K. Sere, and G. Stefanescu. Reﬁnement of structured inter-
active systems. In Theoretical Aspects of Computing? ICTAC 2014, volume 8687 of
Lecture Notes in Computer Science, pages 133–150. Springer, 2014.
[111] H. Dierks, S. Kupfersmid, and K. G. Larsen. Automatic abstraction reﬁnement for
timed automata. In J.-F. Raskin and P. S. Thiagarajan, editors, FORMATS’07 Pro-
ceedings of the 5th International Conference on Formal Modeling and Analysis of
Timed Systems, volume 4763 of Lecture Notes in Computer Science, pages 114–129,
2007.
[112] E. W. Dijkstra. Guarded commands, nondeterminacy and formal derivation of pro-
grams. Communications of the ACM, 18(8):453–457, 1975.
[113] E. W. Dijkstra. A Discipline of Programming. Prentice–Hall International, 1976.
[114] C. C. Din. Veriﬁcation of Asynchronously Communicating Objects. PhD thesis, De-
partment of Informatics, University of Oslo, Norway, 2014.
[115] C. C. Din, J. Dovland, E. B. Johnsen, and O. Owe. Observable behavior of distributed
systems: component reasoning for concurrent objects. Journal of Logic and Algebraic
Programming, 81(3):227–256, 2012.
[116] C. C. Din and O. Owe. Compositional reasoning about active objects with shared
futures. Formal Aspects of Computing, 27:1–22, 2014.
[117] J. Dovland. Incremental Reasoning about Distributed Object-Oriented Systems. PhD
thesis, University of Oslo, Dept. of Computer Science, 2009.
[118] J. Dovland, E. B. Johnsen, O. Owe, and M. Steﬀen. Lazy behavioral subtyping. Re-
search Report 368, Dept. of Informatics, University of Oslo, Nov. 2007. Available from
heim.ifi.uio.no/creol.
[119] J. Dovland, E. B. Johnsen, O. Owe, and M. Steﬀen. Lazy behavioral subtyping. Journal
of Logic and Algebraic Programming, 79(7):578–607, 2010.
[120] J. Dovland, E. B. Johnsen, O. Owe, and M. Steﬀen. Incremental reasoning with lazy
behavioral subtyping for multiple inheritance. Science of Computer Programming,
76(10):915 – 941, 2011.
[121] C. Dragoi and G. Stefanescu. Agapia v0. 1: a programming language for interactive
systems and its typing system. Electronic Notes in Theoretical Computer Science,
203(3):69–94, 2008.
[122] C. Dragoi and G. Stefanescu. On compiling structured interactive programs with reg-
isters and voices. In Proceedings SOFSEM 2008, volume 4910 of Lecture Notes in
Computer Science, pages 259–270. Springer, 2008.
[123] D. J. Duke and M. D. Harrison. Mapping user requirements to implementations. Soft-
ware Engineering Journal, 10(1):13–20, 1995.
[124] S. Eigen, J. Navarro, and V. S. Prasad. An aperiodic tiling using a dynamical sys-
tem and beatty sequences. In B. Hasselblatt, editor, Dynamics, Ergodic Theory, and
Geometry, volume 54 of Mathematical Sciences Research Institute Publications, pages
223–241. Cambridge University Press, 2007.

256
Bibliography
[125] E. A. Emerson and E. M. Clarke. Using branching time temporal logic to synthesize
synchronization skeletons. Science of Computer Programming, 2(3):241 – 266, 1982.
[126] K. Etessami, M. Z. Kwiatkowska, M. Y. Vardi, and M. Yannakakis. Multi-objective
model checking of Markov decision processes. Logical Methods in Computer Science,
4(4), 2008.
[127] J. R. Faeder, M. L. Blinov, B. Goldstein, and W. S. Hlavacek. Rule-based modeling
of biochemical networks. Complexity, 10(4):22–41, 2005.
[128] J. R. Faeder, M. L. Blinov, and W. S. Hlavacek. Graphical rule-based representation of
signal-transduction networks. In Proceedings of the 2005 ACM Symposium on Applied
Computing, pages 133–140. ACM, 2005.
[129] A. Fantechi and S. Gnesi. A behavioural model for product families. In Proceedings of
the 6th Joint Meeting of the European Software Engineering Conference and the ACM
SIGSOFT International Symposium on Foundations of Software Engineering, pages
521–524, 2007.
[130] A. Fantechi and S. Gnesi. Formal modeling for product families engineering. In Soft-
ware Product Lines, 12th International Conference, SPLC 2008, Proceedings, pages
193–202. IEEE, 2008.
[131] H. Fecher and H. Schmidt. Comparing disjunctive modal transition systems with an
one-selecting variant. Journal of Logic and Algebraic Programming, 77(1-2):20–39,
2008.
[132] D. Fischbein, S. Uchitel, and V. A. Braberman. A foundation for behavioural confor-
mance in software product line architectures. In Proceedings of the 2006 Workshop on
Role of Software Architecture for Testing and Analysis, held in conjunction with the
ACM SIGSOFT International Symposium on Software Testing and Analysis (ISSTA
2006), ROSATEA 2006, Portland, Maine, USA, July 17-20, 2006, pages 39–48, 2006.
[133] A. Flores-Montoya, E. Albert, and S. Genaim. May-happen-in-parallel based deadlock
analysis for concurrent objects. In D. Beyer and M. Boreale, editors, Proc. Interna-
tional Conference on Formal Techniques for Distributed Systems (FMOODS/FORTE
2013), volume 7892 of Lecture Notes in Computer Science, pages 273–288. Springer,
2013.
[134] S. Fowler and A. Wellings. Formal analysis of a real-time kernel speciﬁcation. In B. Jon-
sson and J. Parrow, editors, FTRTFT’96, Proceedings of 4th International Symposium
on Formal Techniques in Real Time and Fault Tolerant Systems, Uppsala, volume 1135
of Lecture Notes in Computer Science, pages 440–458. Springer, 1996.
[135] C. A. Furia, M. Rossi, D. Mandrioli, and A. Morzenti. Automated compositional proofs
for real-time systems. Theoretical Computer Science, 376(3):164–184, 2007.
[136] A. Fürst. Design patterns in Event-B and their tool support. Master’s thesis, ETH,
Eidgenössische Technische Hochschule Zürich, Department of Computer Science, 2009.
[137] V. Garg and M. Ragunath. Concurrent regular expressions and their relationship to
Petri nets. Theoretical Computer Science, 96:285–304, 1992.

Bibliography
257
[138] E. Gasparis. LePUS: A formal language for modeling design patterns. In Design Pat-
tern Formalization Techniques, pages 357–372. IGI Global, 2007.
[139] C. Ghezzi, D. Mandrioli, and A. Morzenti. TRIO, a logic language for executable
speciﬁcations of realtime systems. Journal of Systems and Software, 12(2):255–307,
1990.
[140] D. Giammarresi and A. Restivo. Two-dimensional languages. In Handbook of Formal
Languages, volume 3, pages 215–267. Springer, 1997.
[141] A. Gondal, M. Poppleton, and C. Snook. Feature composition - towards product lines
of Event-B models. In 1st International Workshop on Model-Driven Product Line En-
gineering (MDPLE’09). CTIT Workshop Proceedings, 2009.
[142] M. Gordon. A mechanized Hoare logic of state transitions. In A. W. Roscoe, editor,
A Classical Mind: Essays in Honour of C.A.R. Hoare, pages 143–159. Prentice Hall,
1994.
[143] C. Gratie and I. Petre. Fit-preserving data reﬁnement of mass-action reaction net-
works. In A. Beckmann, E. Csuhaj-Varjú, and K. Meer, editors, Language, Life, Lim-
its, volume 8493 of Lecture Notes in Computer Science, pages 204–213. Springer, 2014.
[144] D.-E. Gratie, B. Iancu, S. Azimi, and I. Petre. Quantitative model reﬁnement in four
diﬀerent frameworks, with applications to the heat shock response. Technical Report
1067, TUCS, 2013.
[145] C. Grioli. Improvement and analysis of behavioural models with variability. Master’s
thesis, University of Pisa, Italy, 2013.
[146] J. Groslambert. Veriﬁcation of LTL on B Event Systems. In B 2007: Formal Speci-
ﬁcation and Development in B, volume 4355 of Lecture Notes in Computer Science,
pages 109–124. Springer, 2006.
[147] R. Grossman, A. Nerode, A. Ravn, and H. Rischel. Hybrid Systems. Springer-Verlag,
1993.
[148] B. Grunbaum and G. Shephard. Tilings and Patterns. W.H. Freeman and Co., 1990.
[149] V. H. Haase. Real-time behavior of programs. IEEE Transactions on Software Engi-
neering, 7(5):594–501, Sept. 1981.
[150] G. Haddad, F. Hussain, and G. T. Leavens. The design of SafeJML, a speciﬁcation
language for SCJ with support for WCET speciﬁcations. In Proceedings of the 8th
International Workshop on Java Technologies for Real-Time and Embedded Systems,
JTRES’10, pages 155–163. ACM, 2010.
[151] R. Hähnle and E. B. Johnsen. Designing resource-aware cloud applications. IEEE
Computer, 48:72–75, 2015.
[152] S. Hallerstede. On the purpose of Event-B proof obligations. Formal Aspects of Com-
puting, 23(1):133–150, 2011.
[153] S. Hallerstede, M. Leuschel, and D. Plagge. Validation of formal models by reﬁnement
animation. Science of Computer Programming, 78(3):272 – 292, 2013.

258
Bibliography
[154] K. M. Hansen, A. P. Ravn, and V. Stavridou. From safety analysis to software require-
ments. Software Engineering, IEEE Transactions on, 24(7):573–584, 1998.
[155] M. D. Harrison, P. Masci, J. C. Campos, and P. Curzon. Demonstrating that medical
devices satisfy user related safety requirements. In 4th International Symposium on
Foundations of Healthcare Information Engineering and Systems (FHIES2014), 2014.
[156] Ø. Haugen, K. E. Husa, R. K. Runde, and K. Stølen. STAIRS towards formal design
with sequence diagrams. Journal of Software and Systems Modeling, 4:355–367, 2005.
[157] I. Hayes, M. Jackson, and C. Jones. Determining the speciﬁcation of a control system
from that of its environment. In K. Araki, S. Gnesi, and D. Mandrioli, editors, FME
2003: Formal Methods, volume 2805 of Lecture Notes in Computer Science. Springer-
Verlag, Berlin, 2003.
[158] He Jifeng and C.A.R. Hoare. Prespeciﬁcation and data reﬁnement. In Data Reﬁnement
in a Categorical Setting, Technical Monograph, number PRG-90. Oxford University
Computing Laboratory, Nov. 1990.
[159] He Jifeng, C.A.R. Hoare, and J. Sanders. Data reﬁnement reﬁned. In B. Robinet and
R. Wilhelm, editors, ESOP 86, European Symposium on Programming, volume 213 of
Lecture Notes in Computer Science, pages 187–196. Springer-Verlag, 1986.
[160] J. Heath, M. Kwiatkowska, G. Norman, D. Parker, and O. Tymchyshyn. Probabilistic
model checking of complex biological pathways. In Computational Methods in Systems
Biology, volume 4210 of Lecture Notes in Computer Science, pages 32–47. Springer,
2006.
[161] G. Heineman and W. Councill (editors). Component-Based Software Engineering:
Putting the Pieces Together. Addison-Wesley, 2001.
[162] M. Heiner, M. Herajy, F. Liu, C. Rohr, and M. Schwarick. Snoopy – a unifying Petri
net tool. In S. Haddad and L. Pomello, editors, Application and Theory of Petri Nets,
volume 7347 of Lecture Notes in Computer Science, pages 398–407. Springer Berlin
Heidelberg, 2012.
[163] C. Heinzemann, C. Brenner, S. Dziwok, and W. Schäfer. Automata-based reﬁnement
checking for real-time systems. Computer Science - Research and Development, 30:255–
283, 2015.
[164] T. A. Henzinger. The theory of hybrid automata. In Proceedings, 11th Annual IEEE
Symposium on Logic in Computer Science, pages 278–292. IEEE Computer Society,
1996.
[165] T. A. Henzinger, R. Majumbar, and J. F. Raskin. A classiﬁcation of symbolic transition
systems. ACM Transactions on Computational Logic, 6(1):1–32, 2005.
[166] J. Hillston. A Compositional Approach to Performance Modelling. Cambridge Univer-
sity Press, 1996.
[167] A. Hinton, M. Kwiatkowska, G. Norman, and D. Parker. PRISM: A tool for auto-
matic veriﬁcation of probabilistic systems. In Proceedings of the 12th International
Conference on Tools and Algorithms for the Construction and Analysis of Systems,
TACAS’06, pages 441–444. Springer, 2006.

Bibliography
259
[168] T. S. Hoang and J.-R. Abrial. Reasoning about liveness properties in Event-B. In
International Conference on Formal Engineering Methods, volume 6991 of Lecture
Notes in Computer Science, pages 456–471. Springer, 2011.
[169] T. S. Hoang, A. Fürst, and J. Abrial. Event-B patterns and their tool support. Software
and Systems Modeling, 12(2):229–244, 2013.
[170] C. A. R. Hoare. An axiomatic basis for computer programming. Communications of
the ACM, 12(10):576-580, 1969.
[171] C. A. R. Hoare. Communicating Sequential Processes. Prentice Hall, 1985.
[172] J. Hooman. Extending Hoare logic to real-time. Formal Aspects of Computing,
6(6A):801–826, 1994.
[173] J. Hooman. Compositional veriﬁcation of real-time applications. In W.-P. de Roever,
H. Langmaack, and A. Pnueli, editors, Compositionality: The Signiﬁcant Diﬀerence
(Compos ’97), volume 1536 of Lecture Notes in Computer Science, pages 276–300.
Springer, 1998.
[174] J. E. Hopcroft. An n log n algorithm for minimizing states in a ﬁnite automaton.
In Z. Kohavi and A. Paz, editors, Proceedings of an International Symposium on the
Theory of Machines and Computations, pages 189–196. Academic Press, 1971.
[175] S. Hudon and T. S. Hoang. Systems design guided by progress concerns. In Integrated
Formal Methods, 10th International Conference, IFM 2013. Proceedings, volume 7940
of Lecture Notes in Computer Science, pages 16–30, 2013.
[176] B. Iancu, E. Czeizler, E. Czeizler, and I. Petre. Quantitative reﬁnement of reaction
models. International Journal of Unconventional Computing, 8(5-6):529–550, 2012.
[177] B.
Iancu,
D.-E.
Gratie,
S.
Azimi,
and
I.
Petre.
Computational
modeling
of
the
eukaryotic
heat
shock
response:
the
BioNetGen
implementation,
the
Petri net implementation and the PRISM implementation, 2013. Available at:
http://combio.abo.ﬁ/research/computational-modeling-of-the-eukaryotic-heat-shock-
response/.
[178] B. Iancu, D.-E. Gratie, S. Azimi, and I. Petre. On the implementation of quantitative
model reﬁnement. In A.-H. Dediu, C. Martín-Vide, and B. Truthe, editors, Algorithms
for Computational Biology, volume 8542 of Lecture Notes in Computer Science, pages
95–106. Springer International Publishing, 2014.
[179] A. Iliasov. Use case scenarios as veriﬁcation conditions: Event-B/ﬂow approach. In
SERENE 2011, Software Engineering for Resilient Systems, volume 6968 of Lecture
Notes in Computer Science, pages 9–23. Springer-Verlag, 2011.
[180] A. Iliasov, L. Laibinis, E. Troubitsyna, A. Romanovsky, and T. Latvala. Augmenting
Event-B modelling with real-time veriﬁcation. Technical Report 1006, TUCS, 2011.
[181] A. Iliasov, E. Troubitsyna, L. Laibinis, A. Romanovsky, K. Varpaaniemi, D. Ilic,
and T. Latvala. Developing mode-rich satellite software by reﬁnement in Event B.
In S. Kowalewski and M. Roveri, editors, Formal Methods for Industrial Critical Sys-
tems - 15th International Workshop, FMICS 2010. Proceedings, volume 6371 of Lecture
Notes in Computer Science, pages 50–66. Springer, 2010.

260
Bibliography
[182] A. Iliasov, E. Troubitsyna, L. Laibinis, A. Romanovsky, K. Varpaaniemi, D. Ilic, and
T. Latvala. Supporting reuse in event b development: modularisation approach. In
M. Frappier, U. Glässer, S. Khurshid, R. Laleau, and S. Reeves, editors, Abstract State
Machines, Alloy, B and Z, Second International Conference, ABZ 2010. Proceedings,
volume 5977 of Lecture Notes in Computer Science, pages 174–188. Springer, 2010.
[183] A. Iliasov, E. Troubitsyna, L. Laibinis, A. Romanovsky, K. Varpaaniemi, D. Ilic, and
T. Latvala. Developing mode-rich satellite software by reﬁnement in Event-B. Science
of Computer Programming, 78(7):884–905, 2013.
[184] A. Iliasov, E. Troubitsyna, L. Laibinis, A. Romanovsky, K. Varpaaniemi, P. Väisänen,
D. Ilic, and T. Latvala. Verifying mode consistency for on-board satellite software.
In E. Schoitsch, editor, Computer Safety, Reliability, and Security, 29th International
Conference, SAFECOMP 2010. Proceedings, volume 6351 of Lecture Notes in Com-
puter Science, pages 126–141. Springer, 2010.
[185] R. Jetley, S. Purushothaman Iyer, and P. L. Jones. A formal methods approach to
medical device review. Computer, 39(4):61–67, 2006.
[186] E. B. Johnsen, J. C. Blanchette, M. Kyas, and O. Owe. Intra-object versus inter-
object: concurrency and reasoning in Creol. Electronic Notes in Theoretical Computer
Science, 243:89–103, July 2009.
[187] E. B. Johnsen, R. Hähnle, J. Schäfer, R. Schlatte, and M. Steﬀen. ABS: a core language
for abstract behavioral speciﬁcation. In B. Aichernig, F. S. de Boer, and M. M. Bon-
sangue, editors, Proc. 9th International Symposium on Formal Methods for Compo-
nents and Objects (FMCO 2010), volume 6957 of Lecture Notes in Computer Science,
pages 142–164. Springer, 2011.
[188] E. B. Johnsen and O. Owe. An asynchronous communication model for distributed
concurrent objects. Software and System Modeling, 6(1):35–58, 2007.
[189] E. B. Johnsen, O. Owe, and E. W. Axelsen. A run-time environment for concur-
rent objects with asynchronous method calls. In Proc. 5th International Workshop on
Rewriting Logic and its Applications (WRLA’04), volume 117 of Electronic Notes in
Computer Science. Elsevier, 2004.
[190] E. B. Johnsen, O. Owe, D. Clarke, and J. Bjørk. A formal model of service-oriented
dynamic object groups. Science of Computer Programming, 115C:3–22, Jan. 2016.
[191] E. B. Johnsen, O. Owe, and I. Simplot-Ryl. A dynamic class construct for asyn-
chronous concurrent objects. In M. Steﬀen and G. Zavattaro, editors, Proc. 7th In-
ternational Conference on Formal Methods for Open Object-Based Distributed Sys-
tems (FMOODS’05), volume 3535 of Lecture Notes in Computer Science, pages 15–30.
Springer, June 2005.
[192] E. B. Johnsen, O. Owe, and I. C. Yu. Creol: a type-safe object-oriented model for
distributed concurrent systems. Theoretical Computer Science, 365(1–2):23–66, Nov.
2006.
[193] E. B. Johnsen, R. Schlatte, and S. L. Tapia Tarifa. A formal model of object mobility
in resource-restricted deployment scenarios. In F. Arbab and P. Ölveczky, editors,

Bibliography
261
Proc. 8th International Symposium on Formal Aspects of Component Software (FACS
2011), volume 7253 of Lecture Notes in Computer Science, pages 185–202. Springer,
2012.
[194] E. B. Johnsen, R. Schlatte, and S. L. Tapia Tarifa. Modeling resource-aware virtual-
ized applications for the cloud in real-time ABS. In Proc. Formal Engineering Meth-
ods (ICFEM’12), volume 7635 of Lecture Notes in Computer Science, pages 71–86.
Springer, Nov. 2012.
[195] E. B. Johnsen, R. Schlatte, and S. L. Tapia Tarifa. Integrating deployment architec-
tures and resource consumption in timed object-oriented models. Journal of Logical
and Algebraic Methods in Programming, 2014. Available online.
[196] B. Jonsson and Y.-K. Tsay. Assumption/guarantee speciﬁcations in linear-time tem-
poral logic. Theoretical Computer Science, 167(2):47–72, 1996.
[197] A. Joyal, R. Street, and D. Verity. Traced monoidal categories. In Proceedings of the
Cambridge Philosophical Society, volume 119, pages 447–468, 1996.
[198] J. Jürjens. Secrecy-preserving reﬁnement. In Proceedings of Formal Methods Eu-
rope (FME’01), volume 2021 of Lecture Notes in Computer Science, pages 135–152.
Springer, 2001.
[199] J. Kari. A small aperiodic set of Wang tiles. Discrete Mathematics, 160:259–264, 1996.
[200] R. M. Keller. Formal veriﬁcation of parallel programs. Commun. ACM, 19(7):371–384,
July 1976.
[201] H. Kitano. Systems biology: a brief overview. Science, 295(5560):1662–1664, 2002.
[202] S. Kleene. Representation of events in nerve nets and ﬁnite automata. Automata Stud-
ies, 1956.
[203] M. P. Kline and R. I. Morimoto. Repression of the heat shock factor 1 transcrip-
tional activation domain is modulated by constitutive phosphorylation. Molecular and
Cellular Biology, 17(4):2107–2115, 1997.
[204] E. Klipp, R. Herwig, A. Kowald, C. Wierling, and H. Lehrach. Systems Biology in
Practice: Concepts, Implementation, and Application. Wiley-VCH, 2005.
[205] I. Koch, W. Reisig, and F. Schreiber. Modeling in Systems Biology: The Petri Net
Approach. Springer, 2010.
[206] D. Kozen. A completeness theorem for Kleene algebras and the algebra of regular
events. In LICS’91, pages 214–225. IEEE, 1991.
[207] J. Krone, W. F. Ogden, and M. Sitaraman. Modular veriﬁcation of performance con-
straints. In ACM OOPSLA Workshop on Speciﬁcation and Veriﬁcation of Component-
Based Systems (SAVCBS), pages 60–67, 2001.
[208] J. Krone, W. F. Ogden, and M. Sitaraman. Proﬁles: a compositional mechanism for
performance speciﬁcation. Technical Report RSRG-04-03, Department of Computer
Science, Clemson University, Clemson, SC 29634-0974, June 2004.

262
Bibliography
[209] W. Kuich and A. Salomaa. Semirings, automata, and languages. Springer-Verlag,
Berlin, 1985.
[210] M. Kwiatkowska, G. Norman, and D. Parker. Quantitative analysis with the prob-
abilistic model checker PRISM. Electronic Notes in Theoretical Computer Science,
153(2):5–31, 2006.
[211] M. Kwiatkowska, G. Norman, and D. Parker. PRISM: probabilistic model checking for
performance and reliability analysis. SIGMETRICS Perform. Eval. Rev., 36(4):40–45,
2009.
[212] M. Kwiatkowska, G. Norman, and D. Parker. PRISM 4.0: Veriﬁcation of probabilistic
real-time systems. In G. Gopalakrishnan and S. Qadeer, editors, Proceedings of the 23rd
International Conference on Computer Aided Veriﬁcation (CAV’11), volume 6806 of
Lecture Notes in Computer Science, pages 585–591. Springer, 2011.
[213] L. Lamport. Hybrid systems in TLA+. In R. L. Grossman, A. Nerode, A. P. Ravn,
and H. Rischel, editors, Workshop on Theory of Hybrid Systems, volume 736 of Lecture
Notes in Computer Science, pages 77–102. LNCS 736, Springer, 1993.
[214] L. Lamport. Introduction to TLA. Technical report, SRC Research Center, Dec. 1994.
Technical Note.
[215] L. Lamport. Real-time model checking is really simple. In D. Borrione and W. Paul,
editors, Correct hardware design and veriﬁcation methods, CHARME2005, volume
3725 of LNCS, 2005.
[216] J. Laprie. Resilience for the scalability of dependability. In Fourth IEEE International
Symposium on Network Computing and Applications, pages 5–6, 2005.
[217] K. G. Larsen and A. Legay. Statistical model checking past, present, and future -
(track introduction). In Leveraging Applications of Formal Methods, Veriﬁcation, and
Validation. Specialized Techniques and Applications - 6th International Symposium,
ISoLA 2014, Imperial, Corfu, Greece, October 8-11, 2014, Proceedings, Part II, pages
135–142, 2014.
[218] K. G. Larsen, U. Nyman, and A. Wasowski. Modal I/O automata for interface and
product line theories. In Programming Languages and Systems, 16th European Sympo-
sium on Programming, ESOP 2007, Held as Part of the Joint European Conferences
on Theory and Practices of Software, ETAPS 2007, Braga, Portugal, March 24 - April
1, 2007, Proceedings, pages 64–79, 2007.
[219] K. G. Larsen and B. Thomsen. A modal process logic. In Proceedings of the Third
Annual Symposium on Logic in Computer Science (LICS ’88), Edinburgh, Scotland,
UK, July 5-8, 1988, pages 203–210, 1988.
[220] K. G. Larsen and L. Xinxin. Equation solving using modal transition systems. In
Proceedings of the Fifth Annual Symposium on Logic in Computer Science (LICS
’90), Philadelphia, Pennsylvania, USA, June 4-7, 1990, pages 108–117, 1990.
[221] R. Lassaigne and S. Peyronnet. Approximate veriﬁcation of probabilistic systems.
Process Algebra and Probabilistic Methods: Performance Modeling and Veriﬁcation,
2399:277–295, 2002.

Bibliography
263
[222] M. Latteux and D. Simplot. Context-sensitive string languages and recognizable pic-
ture languages. Information and Computation, 138:160–169, 1997.
[223] M. Lavielle. Mixed Eﬀects Models for the Population Approach: Models, Tasks, Meth-
ods, and Tools. Chapman and Hall/CRC, 2014.
[224] G. T. Leavens, K. R. M. Leino, and P. Müller. Speciﬁcation and veriﬁcation challenges
for sequential object-oriented programs. Formal Aspects of Computing, 19(2):159–189,
2007.
[225] K. R. M. Leino and P. Müller. A veriﬁcation methodology for model ﬁelds. In P. Ses-
toft, editor, Programming Languages and Systems, volume 3924 of Lecture Notes in
Computer Science, pages 115–130. Springer Berlin Heidelberg, 2006.
[226] M. Leuschel and M. J. Butler. ProB: an automated analysis toolset for the B method.
STTT, 10(2):185–203, 2008.
[227] M. Leuschel, J. Falampin, F. Fritz, and D. Plagge. Automated property veriﬁcation
for large scale B models. In FM, volume 5850 of LNCS, pages 708–723. Springer, 2009.
[228] K. Lindgren, C. Moore, and M. Nordahl. Complexity of two-dimensional patterns.
Journal of Statistical Physics, 91(5-6):909–951, 1998.
[229] B. Liskov and L. Shrira. Promises: linguistic support for eﬃcient asynchronous proce-
dure calls in distributed systems. In D. S. Wise, editor, Proc. SIGPLAN Conference on
Programming Language Design and Implementation (PLDI’88), pages 260–267. ACM
Press, June 1988.
[230] B. Liskov and J. M. Wing. A behavioral notion of subtyping. ACMTransactions on
Programming Languages and Systems, 16(6):1811–1841, Nov. 1994.
[231] Z. Liu and M. Joseph. Speciﬁcation and veriﬁcation of fault-tolerance, timing, and
scheduling. ACM Trans. Program. Lang. Syst., 21(1):46–89, 1999.
[232] I. Lopatkin, A. Iliasov, A. Romanovsky, Y. Prokhorova, and E. Troubitsyna. Patterns
for representing FMEA in formal speciﬁcation of control systems. In IEEE 13th Inter-
national Symposium on High-Assurance Systems Engineering, pages 146–151. IEEE,
2011.
[233] C. Luo and S. Qin. Separation logic for multiple inheritance. Electronic Notes in
Theoretical Computer Science, 212:27–40, 2008.
[234] N. Lynch and F. Vaandrager. Forward and backward simulations - part ii: Timing-
based systems. Information and Computation, 128, 1995.
[235] P. Masci, A. Ayoub, P. Curzon, M. D. Harrison, I. Lee, and H. Thimbleby. Veriﬁcation
of interactive software for medical devices: PCA infusion pumps and FDA regulation
as an example. In EICS 2013, Proceedings of the 5th ACM SIGCHI Symposium on
Engineering Interactive Computing Systems, pages 81–90. ACM New York, NY, USA,
2013.
[236] P. Masci, R. Rukš˙enas, P. Oladimeji, A. Cauchi, A. Gimblett, Y. Li, P. Curzon, and
H. Thimbleby. On formalising interactive number entry on infusion pumps. Electronic
Communications of the EASST, 45, 2011.

264
Bibliography
[237] W. Materi and D. S. Wishart. Computational systems biology in drug discovery and
development: methods and applications. Drug Discovery Today, 12(7):295–303, 2007.
[238] S. Matsuoka and A.Yonezawa. Analysis of inheritance anomaly in object-oriented con-
current programming languages. In G. Agha, P. Wegner, and A. Yonezawa, editors,
Research Directions in Concurrent Object-Oriented Programming, pages 107–150. The
MIT Press, 1993.
[239] C. McDowell and O. Owe. Towards a light-weight approach for concurrent active
objects in java, 2016. Submitted for publication.
[240] A. McIver, C. Morgan, and E. Troubitsyna. The probabilistic steam boiler: a case
study in probabilistic data reﬁnement. In IRW/FMP 98, Proceedings of, 1998.
[241] J. McLean. A general theory of composition for trace sets closed under selective in-
terleaving functions. In Proceedings of the IEEE Symposium on Research in Security
and Privacy, pages 79–93. IEEE Computer Society, 1994.
[242] H. Messer, A. Zinevich, and P. Alpert. Environmental monitoring by wireless commu-
nication networks. Science, 312:713, 2006.
[243] B. Meyer. Object-Oriented Software Construction. Prentice Hall, 1988.
[244] B. Meyer. Design by contract: the Eiﬀel method. In Proceedings of Tools (26), page
446. IEEE Computer Society, 1998.
[245] R. Milner. An algebraic deﬁnition of simulation between programs. In Proceedings of
the 2nd International Joint Conference on Artiﬁcial Intelligence. London, UK, Sep-
tember 1971, pages 481–489, 1971.
[246] R. Milner. Communication and Concurrency. International Series in Computer Sci-
ence. Prentice Hall, 1989.
[247] A. Mizera, E. Czeizler, and I. Petre. Self-assembly models of variable resolution. LNBI
Transactions on Computational Systems Biology, 7625:181–203, 2011.
[248] C. Morgan, A. McIver, K. Seidel, and J. Sanders. Reﬁnement-oriented probability for
CSP. Formal Aspects of Computing, 8(6):617–647, 1996.
[249] C. C. Morgan. Programming from Speciﬁcations. Prentice Hall, 1990.
[250] J. M. Morris. A theoretical basis for stepwise reﬁnement and the programming calculus.
Science of Computer Programming, 9(3):287–306, Dec. 1987.
[251] E. Murphy, V. Danos, J. Feret, J. Krivine, and R. Harmer. Elements of Computational
Systems Biology, chapter Rule Based Modelling and Model Reﬁnement, pages 83–114.
Wiley Book Series on Bioinformatics. John Wiley & Sons, Inc., 2010.
[252] H. R. Nielson. Hoare-Logic for Run-Time Analysis of Programs. PhD thesis, Edinburgh
University, 1984.
[253] H. R. Nielson. A Hoare-like proof-system for run-time analysis of programs. Science
of Computer Programming, 9, 1987.

Bibliography
265
[254] P. Oladimeji, H. Thimbleby, and A. Cox. Number entry and their eﬀects on error
detection. In P. Campos et al., editors, Interact 2011, number 6949 in Lecture Notes
in Computer Science, pages 178–185. Springer Verlag, 2011.
[255] E.-R. Olderog and C. A. R. Hoare. Speciﬁcation-oriented semantics for communicating
processes. Acta Informatica, 23:9–66, 1986.
[256] P. Olsen, J. Foederer, and J. Tretmans. Model-based testing of industrial transforma-
tional systems. In Testing Software and Systems - 23rd IFIP WG 6.1 International
Conference, ICTSS 2011, Paris, France, November 7-10, 2011. Proceedings, pages
131–145, 2011.
[257] O. Owe and I. Ryl. On combining object orientation, openness, and reliability. In Proc.
of the Norwegian Informatics Conference (NIK’99). Tapir, Nov. 1999.
[258] O. Owe and I. Ryl. Reasoning control in presence of dynamic classes. In 12th Nordic
Workshop on Programming Theory, Bergen, 2000. On-line proceedings http://www.
ii.uib.no/~nwpt00.
[259] M. J. Parkinson and G. M. Bierman. Separation logic, abstraction, and inheritance.
SIGPLAN Not., 43(1):75–86, Jan. 2008.
[260] D. L. Parnas and J. Madey. Functional documents for computer systems. Sci. Comput.
Program., 25(1):41–61, 1995.
[261] M. Patitz. An introduction to tile-based self-assembly and a survey of recent results.
Natural Computing, 2014.
[262] I. Pereverzeva, E. Troubitsyna, and L. Laibinis. Formal goal-oriented development of
resilient MAS in event-b. In M. Brorsson and L. M. Pinho, editors, Reliable Software
Technologies - Ada-Europe 2012 - 17th Ada-Europe International Conference on Reli-
able Software Technologies, Stockholm, Sweden, June 11-15, 2012. Proceedings, volume
7308 of Lecture Notes in Computer Science, pages 147–161. Springer, 2012.
[263] I. Petre, A. Mizera, C. L. Hyder, A. Meinander, A. Mikhailov, R. I. Morimoto, L. Sis-
tonen, J. E. Eriksson, and R.-J. Back. A simple mass-action model for the eukaryotic
heat shock response and its mathematical validation. Natural Computing, 10(1):595–
612, 2011.
[264] C. Pierik and F. S. de Boer. A proof outline logic for object-oriented programming.
Theoretical Computer Science, 343(3):413–442, 2005.
[265] D. Plagge and M. Leuschel. Seven at one stroke: LTL model checking for high-level
speciﬁcations in B, Z, CSP, and more. STTT, 12(1):9–21, 2010.
[266] A. Platzer. Logical Analysis of Hybrid Systems: Proving Theorems for Complex Dy-
namics. Springer, Heidelberg, 2010.
[267] K. Pohl, G. Böckle, and F. J. v. d. Linden. Software Product Line Engineering: Foun-
dations, Principles, and Techniques. Springer-Verlag New York, Inc., Secaucus, NJ,
USA, 2005.
[268] A. Popa, A. Sofronia, and G. Stefanescu. High-level structured interactive programs
with registers and voices. J. UCS, 13:1722–1754, 2007.

266
Bibliography
[269] C. Priami. Stochastic pi-calculus. Computer Journal, 38(7):578–589, 1995.
[270] C. Priami. Algorithmic systems biology. Communications of the ACM, 52(5):80–88,
2009.
[271] P. Puschner and A. Burns. A review of worst-case execution time analysis (editorial).
Real-Time Systems, 18(2/3):115–128, 2000.
[272] S. Quinton and S. Graf. Contract-based veriﬁcation of hierarchical systems of compo-
nents. In Proc. of SEFM 08, pages 377–381. IEEE Computer Society, 2008.
[273] K. Raman and N. Chandra. Systems biology. Resonance, 15(2):131–153, 2010.
[274] F. Redmill, M. Chudleigh, and J. Catmur. System Safety: HAZOP and Software HA-
ZOP. Wiley, 1999.
[275] A. Regev and E. Shapiro. Cellular abstractions: cells as computation. Nature,
419(6905), 2002.
[276] C. Rieger, D. Gertman, and M. McQueen. Resilient control systems: next generation
design research. In Proceedings of Human System Interactions, pages 632–636, 2009.
[277] RODIN modularisation plug-in. http://wiki.event-b.org/index.php/Modularisation
Plug-in.
[278] M. Rönkkö, V. Kotovirta, and M. Kolehmainen. Classifying environmental monitor-
ing systems. In J. Hrebícek, G. Schimak, M. Kubásek, and A. E. Rizzoli, editors, En-
vironmental Software Systems. Fostering Information Sharing - 10th IFIP WG 5.11
International Symposium, ISESS 2013, Neusiedl am See, Austria, October 9-11, 2013.
Proceedings, volume 413 of IFIP Advances in Information and Communication Tech-
nology, pages 533–542. Springer, 2013.
[279] M. Rönkkö and X. Li. Linear hybrid action systems. Nordic Journal of Computing,
8(1):159–177, 2001.
[280] M. Rönkkö and A. Ravn. Action systems with continuous behavior. In P. Antsakilis,
W. Kohn, M. Lemmon, A. Nerode, and S. Sastry, editors, Hybrid System V, volume
1567 of Lecture Notes in Computer Science, pages 304–323. Springer, 1999.
[281] M. Rönkkö, A. Ravn, and K. Sere. Hybrid action systems. Theoretical Computer Sci-
ence, 290:937–973, 2003.
[282] M. Rönkkö and K. Sere. Reﬁnement and continuous behaviour. In F. W. Vaandrager
and J. H. van Schuppen, editors, Hybrid Systems: Computation and Control, Sec-
ond International Workshop, HSCC’99, Berg en Dal, The Netherlands, March 29-31,
1999, Proceedings, volume 1569 of Lecture Notes in Computer Science, pages 223–237.
Springer, 1999.
[283] M. Rönkkö, M. Stocker, M. Neovius, L. Petre, and M. Kolehmainen. Designing re-
silience mediators for control systems. In Proceedings of the IASTED International
Conference on Modelling, Identiﬁcation, and Control, pages 147–154. ACTA Press,
2014.
[284] A. W. Roscoe. The Theory and Practice of Concurrency. Prentice Hall, 1998.

Bibliography
267
[285] A. W. Roscoe. Understanding Concurrent Systems. Springer, 2010.
[286] R. Rukš˙enas, P. Masci, M. D. Harrison, and P. Curzon. Developing and verifying user
interface requirements for infusion pumps: a reﬁnement approach. Electronic Commu-
nications of the EASST, 69, 2013.
[287] R. K. Runde, Ø. Haugen, and K. Stølen. Reﬁning UML interactions with explicit and
implicit nondeterminism. Nordic Journal of Computing, 12:157–158, 2005.
[288] R. K. Runde, A. Refsdal, and K. Stølen. Relating computer systems to sequence dia-
grams: the impact of underspeciﬁcation and inherent nondeterminism. Formal Aspects
of Computing, 25(2):159–187, 2013.
[289] A. Salomaa. Two complete axiom systems for the algebra of regular events. Journal
of the ACM (JACM), 13(1):158–169, 1966.
[290] M. R. Sarshogh and M. Butler. Speciﬁcation and reﬁnement of discrete timing prop-
erties in Event-B. Technical report, Electronic and Computer Science, University of
Southampton, 2011.
[291] A. Schäfer. Combining real-time model-checking and fault tree analysis. In FME 2003:
Formal Methods, volume 2805 of Lecture Notes in Computer Science, pages 522–541.
Springer Berlin Heidelberg, 2003.
[292] F. B. Schneider. Enforceable security policies. ACM Transactions on Information and
Systems Security, 3(1):30–50, Feb. 2000.
[293] S. Schneider, H. Treharne, and H. Wehrheim. A CSP account of Event-B reﬁnement. In
Proceedings 15th International Reﬁnement Workshop, Reﬁne 2011, Limerick, Ireland,
20th June 2011, pages 139–154, 2011.
[294] S. Schneider, H. Treharne, and H. Wehrheim. The behavioural semantics of Event-B
reﬁnement. Formal Asp. Comput., 26(2):251–280, 2014.
[295] S. Schneider, H. Treharne, H. Wehrheim, and D. Williams. Managing LTL properties
in Event-B reﬁnement. arXiv:1406:6622, June 2014.
[296] M. Schoeberl and R. Pedersen. WCET analysis for a Java processor. In Proceedings
of the 4th International Workshop on Java Technologies for Real-Time and Embedded
Systems (JTRES’06), pages 202–211, 2006.
[297] P. Selinger. A survey of graphical languages for monoidal categories, volume Lecture
Notes in Physics 813, pages 289–355. Springer, 2011.
[298] K. Sere. Stepwise Derivation of Parallel Algorithms. PhD thesis, Åbo Akademi, De-
partment of Computer Science, 1990.
[299] K. Sere and E. Troubitsyna. Safety analysis in formal specication. In J. M. Wing,
J. Woodcock, and J. Davies, editors, FM 99 – Formal Methods, volume 1709 of Lecture
Notes in Computer Science, pages 1564–1583. Springer Berlin Heidelberg, 1999.
[300] K. Sere and M. Waldén. Reverse engineering distributed algorithms. Journal of Soft-
ware Maintenance: Research and Practice, 8:117–144, 1996.

268
Bibliography
[301] L. Shargel, A. Yu, and S. Wu-Pong. Applied Biopharmaceutics & Pharmacokinetics.
McGraw Hill Professional, 6th edition, 2012.
[302] A. C. Shaw. Reasoning about time in higher-level language software. IEEE Transac-
tions on Software Engineering, 15(7):875–889, 1989.
[303] M. Shaw. A formal system for specifying and verifying program performance. Technical
Report CMU-CS-79-129, Carnegie Mellon University, June 1979.
[304] R. Silva and M. Butler. Supporting reuse mechanisms for developments in event-b:
composition. Technical report, University of Southampton, 2009.
[305] R. Silva and M. Butler. Shared event composition/decomposition in Event-B. In B. K.
Aichernig, F. S. de Boer, and M. M. Bonsangue, editors, Formal Methods for Compo-
nents and Objects, volume 6957 of Lecture Notes in Computer Science, pages 122–141.
Springer, 2012.
[306] M. Sitaraman. Compositional performance reasoning. In Proceedings of the Fourth
ICSE Workshop on Component-Based Software Engineering: Component-Certiﬁcation
and System Prediction, may 2001.
[307] M. Sitaraman, G. Kulczycki, J. Krone, W. F. Ogden, and A. L. N. Reddy. Performance
speciﬁcation of software components. In ACM Sigsoft Symposium on Software Reuse,
2001.
[308] J.
Skön,
M.
Johansson,
O.
Kauhanen,
M.
Raatikainen,
K.
Leiviskä,
and
M. Kolehmainen. Wireless building monitoring and control system. World Academy
of Science, Engineering, and Technology, 65:706–711, 2012.
[309] A. M. Smith, W. Xu, Y. Sun, J. R. Faeder, and G. E. Marai. RuleBender: integrated
modeling, simulation, and visualization for rule-based intracellular biochemistry. BMC
Bioinformatics, 13(Suppl 8):S3, 2012.
[310] C. Snook and M. Butler. UML-B: A plug-in for the Event-B tool set. In Proceedings of
the 1st International Conference on Abstract State Machines, B and Z, ABZ’08, page
344. Springer-Verlag, 2008.
[311] N. Song, S. Zhang, and C. Liu. Overview of factors aﬀecting oral drug absorption.
Asian Journal of Drug Metabolism and Pharmacokinetics, 4:167–176, 2004.
[312] N. Soundararajan. A proof technique for parallel programs. Theoretical Computer
Science, 31(1-2):13–29, May 1984.
[313] FP6 EU project SPEEDS: SPEculative and Exploratory Design in Systems Engineer-
ing. http://www.speeds.eu.com/.
[314] G. Stefanescu. Feedback Theories (A Calculus for Isomorphism Classes of Flowchart
Schemes). Number 24 in Preprint Series in Mathematics. INCREST, 1986. Also in:
Revue Roumaine de Mathematiques Pures et Applique, 35:73–79, 1990.
[315] G. Stefanescu. On ﬂowchart theories: part II. The nondeterministic case. Theoretical
Computer Science, 52(3):307–340, 1987.
[316] G. Stefanescu. Network Algebra. Springer Verlag, 2000.

Bibliography
269
[317] G. Stefanescu. Interactive systems: from folklore to mathematics. In Relmics’01, pages
197–211. LNCS 2561, Springer, 2002.
[318] G. Stefanescu. Interactive systems with registers and voices. Draft, 2004. National
University of Singapore, 2004.
[319] G. Stefanescu. Interactive systems with registers and voices. Fundamenta Informaticae,
73(1):285–305, 2006.
[320] M. Stoelinga and F. Vaandrager. Root contention in IEEE 1394. In J.-P. Katoen,
editor, Formal Methods for Real-Time and Probabilistic Systems, pages 53–74. Springer
Berlin Heidelberg, 1999.
[321] L. Strigini. Resilience assessment and dependability benchmarking: challenges of pre-
diction. In Proceedings of DSN Workshop Resilience Assess. Depend. Benchmarking,
2008.
[322] W. Su, J.-R. Abrial, and H. Zhu. Formalizing hybrid systems with event-b and the
rodin platform. Science of Computer Programming, 94:164–202, 2014.
[323] C. A. Szyperski. Component Software. Addison Wesley, 1998.
[324] T. Taibi and D. Ngo. Information and software technology. Formal Speciﬁcation of
Design Pattern Combination using BPSL, 45(3):157–170, 2003.
[325] A. Tarasyuk, E. Troubitsyna, and L. Laibinis. From formal speciﬁcation in Event-
B to probabilistic reliability assessment. In Dependability (DEPEND), 2010 Third
International Conference on, pages 24–31, July 2010.
[326] A. Tarasyuk, E. Troubitsyna, and L. Laibinis. Formal modelling and veriﬁcation of
service-oriented systems in probabilistic Event-B. In IFM 2012, Integrated Formal
Methods, volume 7321 of Lecture Notes in Computer Science, pages 237–252. Springer,
2012.
[327] The RODIN platform. http://rodin-b-sharp.sourceforge.net/.
[328] H. Thimbleby. Interaction walkthrough: evaluation of safety critical interactive sys-
tems. In G. Doherty and A. Blandford, editors, Interactive Systems: Design, Speciﬁ-
cation, and Veriﬁcation, number 4323 in Lecture Notes in Computer Science, pages
52–66. Springer Verlag, 2007.
[329] A. Thums and G. Schellhorn. Model checking FTA. In FME 2003: Formal Methods,
volume 2805 of Lecture Notes in Computer Science, pages 739–757. Springer Berlin
Heidelberg, 2003.
[330] K. Trivedi, K. Dong Seong, and R. Ghosh. Resilience in computer systems and net-
works. In IEEE International Conference on Computer-Aided Design - Digest of Tech-
nical Papers, pages 74–77. IEEE, 2009.
[331] E. Troubitsyna. Reliability assessment through probabilistic reﬁnement. Nordic Jour-
nal of Computing, 6(3):320–342, 1999.
[332] E. Troubitsyna. Stepwise Development of Dependable Systems. PhD thesis, Ph.D. the-
sis No.29. TUCS - Turku Centre for Computer Science, 2000.

270
Bibliography
[333] E. Troubitsyna. Dependability-explicit engineering with Event-B: overview of recent
achievements. CoRR, abs/1210.7032, 2012.
[334] Y.-K. Tsay. Compositional veriﬁcation in linear-time temporal logic. In J. Tiuryn, edi-
tor, Proceedings of FoSSaCS 2000, volume 1784 of Lecture Notes in Computer Science,
pages 344–358. Springer, 2000.
[335] Safety requirements for the generic PCA pump. http://rtg.cis.upenn.edu/
gip-docs/Safety_Requirements_GPCA.doc. Accessed: 04.04.2013.
[336] US Food and Drug Administration. Guidance for the content of premarket submissions
for software contained in medical devices, May 2005.
[337] R. van Glabbeek. The linear time – branching time spectrum II; the semantics of se-
quential systems with silent moves (extended abstract). In E. Best, editor, Proceedings
CONCUR’93, 4th International Conference on Concurrency Theory, Hildesheim, Ger-
many, August 1993, volume 715 of Lecture Notes in Computer Science, pages 66–81.
Springer, 1993.
[338] R. van Glabbeek. The linear time - branching time spectrum I. The semantics of
concrete sequential processes. In Bergstra et al. [53], pages 3–99.
[339] M. Verhoef, P. G. Larsen, and J. Hooman. Modeling and validating distributed em-
bedded real-time systems with VDM++. In J. Misra, T. Nipkow, and E. Sekerinski,
editors, Proceedings of the 14th International Symposium on Formal Methods (FM’06),
volume 4085 of Lecture Notes in Computer Science, pages 147–162. Springer, 2006.
[340] J. von Wright and K. Sere. Program transformations and reﬁnements in HOL. In
International Workshop on the HOL Theorem Proving System and Its Applications,
pages 231–239. IEEE, 1991.
[341] M. Waldén and K. Sere. Reasoning about action systems using the B-Method. Formal
Methods in System Design, 13:5–35, 1998.
[342] A. Wang. Generalized types in high-level programming languages. Research Report in
Informatics 1, Institute of Mathematics, University of Oslo, 1974. Cand. Real thesis.
[343] F. Wang. Eﬃcient veriﬁcation of timed automata with bdd-like data structures. In-
ternational Journal on Software Tools for Technology Transfer, 6(1):77–97, 2004.
[344] R. Ward, J. Loftis, and G. McBride. The “data-rich but information-poor” syndrome
in water quality monitoring. Environmental Management, 10(3):291–297, 1986.
[345] G. Wiederhold. Mediators in the architecture of future information systems. Computer,
25(3):38–49, 1992.
[346] M. Williams, D. Cornford, L. Bastin, R. Jones, and S. Parker. Automatic processing,
quality assurance and serving of real-time weather data. Computers & Geosciences,
37:351–362, 2011.
[347] A. Wills. Capsules and types in fresco: program veriﬁcation in smalltalk. In P. America,
editor, European Conference on Object-Oriented Programming, volume 512 of Lecture
Notes in Computer Science, pages 59–76. Springer, 1991.

Free ebooks ==>   www.Ebook777.com
Bibliography
271
[348] J. Woodcock and J. Davies. Using Z: Speciﬁcation, Reﬁnement, and Proof. Prentice
Hall, 1996.
[349] W. Xu, A. M. Smith, J. R. Faeder, and G. E. Marai. RuleBender: a visual interface
for rule-based modeling. Bioinformatics, 27(12):1721–1722, 2011.
[350] S. Yeganefard and M. Butler. Structuring functional requirements of control systems
to facilitate reﬁnement-based formalisation. In Proceedings of the 11th International
Workshop on Automated Veriﬁcation of Critical Systems (AVoCS 2011), volume 46.
Electronic Communications of the EASST, 2011.
[351] A. Yonezawa, J.-P. Briot, and E. Shibayama. Object-oriented concurrent programming
in ABCL/1. In Conference on Object-Oriented Programming Systems, Languages, and
Applications (OOPSLA’86). Sigplan Notices, 21(11):258–268, Nov. 1986.
[352] M. Zhang, Z. Liu, C. Morisset, and A. P. Ravn. Design and veriﬁcation of fault-
tolerant components. In Methods, Models, and Tools for Fault Tolerance, volume 5454
of Lecture Notes in Computer Science, pages 57–84. Springer Berlin Heidelberg, 2009.
[353] Q. Zhu and T. Basar. A dynamic game-theoretic approach to resilient control sys-
tem design for cascading failures. In Proceedings of International Conference on High
Conﬁdence Networked Systems, pages 41–46, 2012.
www.Ebook777.com

This page intentionally left blank
This page intentionally left blank

Free ebooks ==>   www.Ebook777.com
www.Ebook777.com

