
Using R at the Bench
Step-by-Step Data Analytics for Biologists
2

OTHER TITLES FROM COLD SPRING HARBOR LABORATORY PRESS
At the Bench: A Laboratory Navigator, Updated Edition
At the Helm: Leading Your Laboratory, Second Edition
Experimental Design for Biologists, Second Edition
Lab Math: A Handbook of Measurements, Calculations, and Other Quantitative Skills
for Use at the Bench, Second Edition
Next-Generation DNA Sequencing Informatics, Second Edition
Statistics at the Bench: A Step-by-Step Handbook for Biologists
3

Using R at the Bench
Step-by-Step Data Analytics for Biologists
M. Bremer
Department of Mathematics
and Statistics
San Jose State University
R.W. Doerge
Department of Statistics
Department of Agronomy
Purdue University
4

Using R at the Bench
Step-by-Step Data Analytics for Biologists
All rights reserved
© 2015 by Cold Spring Harbor Laboratory Press
Printed in China
Publisher and Acquisition Editor
John Inglis
Director of Editorial Services
Jan Argentine
Project Manager
Inez Sialiano
Director Publication Services
Linda Sussman
Assistant Production Editor
Maria Ebbets
Production Manager
Denise Weiss
Cover Designer
Jim Duffy/Denise Weiss
Front cover illustration was created by Jim Duffy.
Library of Congress Cataloging-in-Publication Data
Bremer, M. (Martina)
Using R at the bench : step-by-step data analytics for biologists / M. Bremer, Department of Mathematics and
Statistics, San Jose State University, R.W. Doerge, Department of Statistics, Department of Agronomy, Purdue
University.
   pages cm
Includes bibliographical references and index.
ISBN 978-1-62182-112-0 (hardcover)
1. Bioinformatics. 2. Biology–Data processing. 3. R (Computer program language) I. Doerge, R. W. (Rebecca W.)
II. Title.
QH324.2.B74 2015
570.285–dc23
2015018960
10 9 8 7 6 5 4 3 2 1
All World Wide Web addresses are accurate to the best of our knowledge at the time of printing.
Authorization to photocopy items for internal or personal use, or the internal or personal use of specific clients, is
granted by Cold Spring Harbor Laboratory Press, provided that the appropriate fee is paid directly to the Copyright
Clearance Center (CCC).Write or call CCC at 222 Rosewood Drive, Danvers, MA 01923 (978-750-8400) for
information about fees and regulations. Prior to photocopying items for educational classroom use, contact CCC at the
above address. Additional information on CCC can be obtained at CCC Online at www.copyright.com.
For a complete catalog of all Cold Spring Harbor Laboratory Press publications, visit our website at www.cshlpress.org.
5

Contents
Acknowledgments
1
Introduction
2
Common Pitfalls
2.1
Examples of Common Mistakes
2.2
Defining Your Question
2.3
Working with and Talking to a Statistician
2.4
Exploratory versus Inferential Statistics
2.5
Different Sources of Variation
2.6
The Importance of Checking Assumptions and the Ramifications of Ignoring the
Obvious
2.7
Statistical Software Packages
2.8
Installing and Using R and R Commander
2.8.1
Loading Data
2.8.2
Variable Types
2.8.3
Handling Graphics
2.8.4
Saving Your Work
2.8.5
Getting Help
3
Descriptive Statistics
3.1
Definitions
3.2
Numerical Ways to Describe Data
3.2.1
Categorical Data
3.2.2
Quantitative Data
3.2.3
Determining Outliers
3.2.4
How to Choose a Descriptive Measure
3.3
Graphical Methods to Display Data
6

3.3.1
How to Choose the Appropriate Graphical Display for Your Data
3.4
Probability Distributions
3.4.1
The Binomial Distribution
3.4.2
The Normal Distribution
3.4.3
Assessing Normality in Your Data
3.4.4
Data Transformations
3.5
The Central Limit Theorem
3.5.1
The Central Limit Theorem for Sample Proportions
3.5.2
The Central Limit Theorem for Sample Means
3.6
Standard Deviation versus Standard Error
3.7
Error Bars
3.8
Correlation
3.8.1
Correlation and Causation
4
Design of Experiments
4.1
Mathematical and Statistical Models
4.1.1
Biological Models
4.2
Describing Relationships between Variables
4.3
Choosing a Sample
4.3.1
Problems in Sampling: Bias
4.3.2
Problems in Sampling: Accuracy and Precision
4.4
Choosing a Model
4.5
Sample Size
4.6
Resampling and Replication
5
Confidence Intervals
5.1
Interpretation of Confidence Intervals
5.1.1
Confidence Levels
5.1.2
Precision
5.2
Computing Confidence Intervals
5.2.1
Confidence Intervals for Large Sample Mean
5.2.2
Confidence Interval for Small Sample Mean
5.2.3
Confidence Interval for Population Proportion
5.3
Sample Size Calculations
6
Hypothesis Testing
6.1
The Basic Principle
7

6.1.1
p-values
6.1.2
Errors in Hypothesis Testing
6.1.3
Power of a Test
6.1.4
Interpreting Statistical Significance
6.2
Common Hypothesis Tests
6.2.1
t-test
6.2.2
z-test
6.2.3
F-test
6.2.4
Tukey’s Test and Scheffé’s Test
6.2.5
χ2-test: Goodness-of-Fit or Test of Independence
6.2.6
Likelihood Ratio Test
6.3
Non-parametric Tests
6.3.1
Wilcoxon-Mann-Whitney Rank Sum Test
6.3.2
Fisher’s Exact Test
6.3.3
Permutation Tests
6.4
E-values
7
Regression and ANOVA
7.1
Regression
7.1.1
Correlation and Regression
7.1.2
Parameter Estimation
7.1.3
Hypothesis Testing
7.1.4
Logistic Regression
7.1.5
Multiple Linear Regression
7.1.6
Model Building in Regression: Which Variables to Use?
7.1.7
Verification of Assumptions
7.1.8
Outliers in Regression
7.1.9
A Case Study
7.2
ANOVA
7.2.1
One-Way ANOVA Model
7.2.2
Two-Way ANOVA Model
7.2.3
ANOVA Assumptions
7.2.4
ANOVA Model for Microarray Data
7.3
What ANOVA and Regression Models Have in Common
8
Special Topics
8.1
Classification
8

8.2
Clustering
8.2.1
Hierarchical Clustering
8.2.2
Partitional Clustering
8.3
Principal Component Analysis
8.4
Microarray Data Analysis
8.4.1
The Data
8.4.2
Normalization
8.4.3
Statistical Analysis
8.4.4
The ANOVA Model
8.4.5
Variance Assumptions
8.4.6
Multiple Testing Issues
8.5
Next-Generation Sequencing Analysis
8.5.1
Experimental Overview
8.5.2
Statistical Issues in Next-Generation Sequencing Experiments
8.6
Maximum Likelihood
8.7
Frequentist and Bayesian Statistics
References
Index
Index of Worked Out Examples
Index of R Commander Commands
9

Acknowledgments
We would like to thank the Department of Statistics at Purdue University and ADG for
initiating the serendipitous circumstances that brought us together. We are grateful to our
families and friends for their endless support. We thank Bingrou (Alice) Zhou for
assistance with an early version of this Manual.
MARTINA BREMER
REBECCA W. DOERGE
10

1  Introduction
Biology is becoming increasingly computational. New technologies are producing
massive amounts of data, particularly in molecular biology, and are opening entirely new
avenues of research. However, with these new technologies come new challenges and
needs. Large amounts of quantitative information need to be organized, displayed, and
understood. Even for biologists who are not directly involved in collecting data, thinking
quantitatively and interpreting quantitative results, both in research and in the literature,
are becoming important aspects of daily scientific training and work.
Large-scale sequencing projects are good examples of how science, enabled by
technology, has given rise to massive amounts of data (e.g., genome and protein
sequences) that need to be summarized, investigated, and quantitatively assembled. Case
in point: The simplest software program used for assessing sequencing data is BLAST
(Basic Local Alignment Search Tool), in which every search conducted by the program
returns statistical summaries that describe how well search results “fit” a query.
Understanding what these results are actually telling us is essential to making well-
informed scientific choices.
Having an appreciation for the computer results provided by software applications or
quantitative results from the literature requires a basic understanding of both statistical
thinking and statistical procedures. Likewise, quantitative reasoning as applied to the
design of an experiment and data evaluation are as important as formulating and
answering biological questions based on challenging and complex experimental
situations. With this in mind, this Manual is intended as a resource that provides an
overview of terminology and concepts that occur frequently in quantitative thinking and
in the statistical analysis of biological data. This Manual also explains in the simplest of
terms the underlying principles of the more complex analyses (e.g., microarray
experiments and RNA-Seq).
If you are looking for a one- or two-semester textbook on statistical procedures, you
have the wrong book in hand. This Manual is not intended as a textbook—It is a “bench-
11

side” Manual that is designed and intended to be used by people who are in need of a
quick refresher or a big picture overview of a statistical procedure. Maybe it has been a
long time (if ever) since you last took a course in mathematics or statistics, or even
considered thinking quantitatively about your data. Maybe the amount of quantitative
training you received is lacking or less than desirable. This Manual is aimed at you! The
comprehensive index allows you to quickly access the information you need to think
about your data and interpret your results effectively.
As you will see and read in this Manual, new concepts are illustrated by simple
examples selected from different biological applications. Many of the examples that we
use are accompanied by detailed R Commander instructions and are the same examples
that are used in the earlier Excel version of this book (Bremer and Doerge 2009). We
chose R because it is a powerful and versatile software that is freely available and
widely used by biologists and statisticians today. We chose R Commander because this
easy-to-understand graphical user interface provides easy and intuitive access to R. For
applications that exceed the scope of this text, R programs and packages usually exist,
but they may not be available via R Commander. Of course, there are many other
statistics programs that can also be used instead of R (for a discussion of available
programs, see Section 2.7).
In R Commander: Complete R Commander examples can be found in boxes
throughout the text. For complete instructions on how to install R and R Commander,
refer to Section 2.8.
Today, computationally trained biologists are gaining a competitive edge in science. Not
only can they read the literature, they can also think critically about it and engage in
meaningful scientific conversations rich with quantitative reasoning. Our purpose in
providing this Manual is to assist biologists in becoming fluent and comfortable in the
language of quantitative reasoning and to facilitate open and informed communication
between the biological and the quantitative sciences.
12

2  Common Pitfalls
2.1  Examples of Common Mistakes
The interesting thing about Statistics as a discipline is that it allows anyone to summarize
and analyze data. After loading data into their favorite statistical software package (or at
least the one that is available), nine times out of ten just about anyone can produce some
sort of numbers or answers. Yes, anyone can do a “statistical analysis” of their data,
which is perilous if these analyses are not done correctly. With this in mind, listed below
are a number of common, but unintentional, mistakes that occur either when designing an
experiment or when analyzing the data from an experiment.
No clear statement of the scientific question(s).
Collecting the wrong data.
Lack of randomization.
Ignoring the importance of biological replication.
Making things more complicated than they need to be.
Ignoring obvious components of the experiment.
Using the wrong statistical procedure.
Ignoring the assumptions of the model.
Altering the experimental question, after the fact, to fit the results.
Losing the big picture of the experiment when thinking about the results from the
analyses.
Many of these mistakes result in frustrations that can be avoided simply by being aware
of the importance of good statistical design and analysis.
2.2  Defining Your Question
“Finding the right question is often more important than finding the right answer” (Tukey
13

1980). It seems like an obvious point, but it is important to know what question(s) to ask,
and then devise a plan or sampling design to collect the data that will help answer the
question(s). One common mistake is that the wrong data are often collected to address
the right questions. Thinking about the question and what data need to be collected before
performing a study will save time, money, and frustration. The old adage, consult a
statistician prior to designing the experiment, actually is true. Questions to ask:
What are my questions?
What data do I need to collect? What data am I able to collect?
How do I measure the data accurately?
What external forces are acting on my biological system? Can I measure them?
How does variation affect my data and the results?
How will I report my results in a comprehensive manner?
2.3  Working with and Talking to a Statistician
Vocabulary is the largest divide between the biological sciences and the mathematical
sciences. The second largest issue is communication. Statisticians and biologists
fundamentally communicate very differently. Coupling vocabulary and communication
issues into any human interaction usually results in frustrations.
Statements from statisticians that biologists are tired of hearing: There are a number
of statements that frustrate biologists, and frankly, they are tired of hearing them. Here
are some examples:
Consult a statistician prior to designing your experiment.
What is your null hypothesis?
Your sample size is too small.
You did not replicate.
You did not randomize.
You collected the wrong data.
Equally, there are a number of fundamentally huge issues, at least from a statistician’s
point of view, that biologists tend to sweep under the carpet as unimportant and high-
headed mathematical mumbo-jumbo.
Statements from biologists that statisticians are tired of hearing:
14

If you need statistics, your result is not real.
I did not replicate because the result might change (or, I do not have enough
money).
Is there a difference between a technical replicate and a biological replicate?
I got the answer from my favorite software package, I have no idea what I did.
I just want a small p-value.
The majority of biologists will attempt to design their own experiments and analyze their
own experimental data, and only if a problem arises will they consult a statistician. This
consultation usually takes place after the data are collected, when both frustrations and
anxiety are high. As such, the best way to approach a consultation with a statistician is to
be prepared. If the data are in hand, before the meeting send a brief document to the
statistician that includes the questions you are addressing, a description of the data that
were collected (include pictures), and the conditions under which the data were
collected. If the initial consultation is prior to actually performing the experiment, the
statistician may work with you to create such a document, which will then become your
experimental plan and design.
2.4  Exploratory versus Inferential Statistics
Much of biology can be viewed as observational. Data are collected, summary statistics
calculated, and pictures drawn. From this exploratory information, patterns are often
observed, and it is quite easy to start drawing conclusions prior to actually controlling
for the experimental conditions and sources of variation.
A common mistake is exploring data without incorporating the experimental design,
which in turn may result in observational patterns that are due to external sources
(e.g., dye bias in a microarray experiment that implies differential expression of a
gene or population structure in association mapping). Conclusions drawn from such
experiments may be misleading if the external sources of variation have a
significant effect on the outcome.
Inferential statistics is based on statistical theory, and although it may seem complicated,
it is rather simple. A mathematical model describes the relationship between the
variable(s) of interest (i.e., the dependent variable) and the other variables (i.e., the
independent variables) of the experiment. Using this relationship, questions can be asked
15

of the data. The simplest models are linear in nature, with the most basic being an
equation for a straight line (y = mx + b). Answers are gained by comparing a quantity, or
test statistic, calculated from the experimental data to the situation where there is no
relationship (or a random relationship) between the variable of interest and the
independent variable(s). If the quantity calculated from the experimental data is unlikely
under the assumption of random representation, then the relationship between the
dependent variable and the independent variable(s) is significant in nature.
Some of the most common pitfalls of inferential statistics are to make the initial
relationship between the dependent variable and independent variable too
complicated, to ask an incorrect question (i.e., test the wrong quantity), and to
ignore the assumptions that are required for the data prior to analysis.
2.5  Different Sources of Variation
Variation is not necessarily a bad thing, if it can be understood and dealt with properly.
Every variable in an experiment that is measured quantitatively will have variability
both because no single measuring device is perfect and because many external forces
may be acting on the experimental system under investigation.
A common misconception among biologists is that variation is bad and that if the
experiment is repeated, or if the measurement is taken again, the quantity should be
exactly the same.
–  For example, two technicians scoring quantitative disease resistance will
most likely obtain two different measurements. Certainly, the experimental
unit has not changed, but the variation due to the technicians may cause the
measurements to be different. The good news is that we can control for
this source of variation (i.e., variation due to technician) in the statistical
model and analysis.
Another common mistake is to disregard sources of technical variation and to
concentrate only on the biological variation. In doing so, technical variation is
confounded with, or included in, the variation that is observed biologically, making
it impossible to obtain an accurate assessment of biological variation.
Often, biological variation is considered unimportant, and as such, it is only deemed
necessary to measure the experimental unit once. Because experimental units, especially
in biology, interact differently with the technology, environment, and other influences, it
16

is important to fully understand how much biological variation there is and how it differs
from technical variation. It is worth remembering that the role of statistics is to partition
variation into its assigned components so that the relationship between the (dependent)
variable of interest and the sources of variation is well-defined.
If important variables are left out of both the model and the analysis, then
nonrandom patterns in the remaining variation (i.e., the residuals) may actually
influence the results.
2.6  The Importance of Checking Assumptions and the Ramifications
of Ignoring the Obvious
Anyone who has attempted to perform a statistical analysis may realize that there are
assumptions about the data which should be satisfied prior to performing the analysis.
The most frequent assumption that is required of the data is that they are normally
distributed. In fact, most statistical analysis procedures are based on the assumption that
the data are normally distributed. Ignoring the assumption of normality usually leads to
incorrect conclusions. The most common mistake when performing a statistical analysis
that requires data to be normally distributed is to proceed with the analysis and ignore
the data’s non-normality.
As with most anything in life, if it is ignored, the problem (i.e., violation of assumptions)
may only get bigger. The ramifications of ignoring the basic assumption of how the data
and/or residuals behave, or are distributed, can result in misleading and incorrect results
and conclusions. Below are some of the most common assumptions that are ignored:
Data are normally distributed.
All members of the population have the same variance (i.e., common variance
assumption).
Once the data are fit to a model, residuals are normally distributed.
The residuals are random and pattern free.
Unfortunately, the popularity of point-and-click statistical analysis software has only
compounded the problem of ignoring assumptions because it is possible to jump into the
middle of an analysis without considering assumptions about the data, the general context
of the experiment, or basic questions upon which the study was formulated.
17

2.7  Statistical Software Packages
Personal computing has certainly made our lives more efficient and our work lives more
informed. Statistics, like many disciplines, has greatly benefited from the implementation
of many seemingly complex analyses in software packages ranging from very intuitive
point-and-click packages to extremely powerful, yet harder to use, statistical
programming languages. Most packages come with a full range of summary statistics and
graphics options. To name only a few, below are some of the more popular/powerful
statistical software packages:
R
SAS
Mathematica
Matlab
Although useful to statisticians, these computer packages are sometimes frustrating for
biologists because it may be difficult to load the data into the program, challenging to
understand the code required (because not all packages have pull-down menus), and
frustrating to interpret the output in the context of the problem under investigation. Other
packages provide a more easy-to-use interface to facilitate ease of statistical analysis:
R Commander
SPSS
JMP
Minitab
Even with pull-down menus, statistical analyses are not always straightforward. Some of
the more common pitfalls when using unfamiliar statistical software include the
following:
Data format does not match requirements of software package.
It is unclear what to do with missing data, or how to code it.
The order in which the exploratory investigations, graphics, and analyses should be
performed is not straightforward.
The output of the analysis does not make sense.
The graphics are difficult to use.
18

With these frustrations in mind, and because we desire to assist biologists with their
science at the bench, we are presenting all examples in this Manual using R Commander.
Because it is an easy-to-understand point-and-click interface, R Commander gives the
user access to the powerful computing capabilities of R without the frustration of writing
R code. R Commander allows the user to explore and ask intelligent questions of their
data easily on a laptop or desktop computer—at the bench.
2.8  Installing and Using R and R Commander
R is a free software environment for statistical computing and graphics. Versions are
available for Windows, MacOS, and Unix platforms. Download the most current version
from http://www.r-project.org/ by clicking on the download R link and following
the (default) installation instructions.
Start R by clicking on the R icon. If the R icon cannot be found on your desktop, start R
by selecting the program under “Start” and “Programs” (on Windows) or from the
Applications folder (MacOS). When R opens, you will see the R console window (Fig.
1). If you wish, you can type the commands directly into the console window.
R Commander is a package in R. To utilize the graphical interface of R Commander, first
download and install the package. This is easily done by simply typing the command
install.packages("Rcmdr", dependencies = TRUE) into the R console window
and hitting enter. Please be aware that you need to be connected to the internet to
download any package. Installing the package is only necessary once. To use R
Commander, open the R console window and type library(Rcmdr). This will open the
R Commander interface window (Fig. 2). Troubleshooting information is available on
the R Commander website (http://www.rcommander.com/).
19

FIGURE 1. R Console windows for a Windows platform (left) and for a MacOS platform
(right).
FIGURE 2. R Commander interface window.
To work with R Commander, one primarily relies on the drop-down menu at the very top
20

of the interface (or window). The second row of buttons shows the active data set and
allows direct viewing and editing of the data. The upper white box labeled R Script
will display the R commands, or code, generated as the result of selecting options, or
clicking on options, in the drop-down menu. This option is particularly useful if R
Commander is used as a spring board toward independent R-programming. The R
commands that are generated can be modified and re-executed. Clicking the Submit
button will execute highlighted commands, or in the absence of highlighting, the
commands in the row where the cursor is currently positioned. The Output window will
reiterate the command (in red) and display the results provided by R in blue. Graphics
will appear in a new window.
2.8.1  Loading Data
When R Commander is started, there is no active data set. The first data imported
becomes the active data set. If more than one data set is imported, the “Data set” button
can be used to toggle between different data sets. The most convenient file format to
import data from are text files whose names end with txt, dat, or csv. It is also possible
to import data in SAS xport, SPSS, Minitab, and STATA formats. If the data are not
currently available in either one of these formats, it is usually possible to import the data
into another spreadsheet package (such as Excel) and save it in either tab or comma-
delimited text format.
In R Commander: To import an existing data file in text format (txt, dat, or csv), click
on “Data,” “Import data,” and “from text file, clipboard, or URL....” Enter a name for
the data set and uncheck the box if the data set does not contain variable names in the
first row. Specify the field separator (usually tab for text files and commas for csv
files). Click “OK.” This will create a browser showing your local file system.
Navigate to the data file and click on it.
If the data set is loaded successfully, the message window will report the number of
rows and columns of the data set. The data can be viewed through the “View data set”
button. Viewing the data after importing is strongly recommended. Common problems
when loading data include:
Error message: Line x did not have y elements.
Common reason: Wrong field separator. This happens commonly when variables
21

are words and some values consists of more words than others (e.g., Chicago vs.
San Francisco). Use tab or comma rather than white space as field separator.
Error message: Invalid string.
Common reason: Unrecognizable file format. Save the data in plain text file format
prior to importing into R.
If a data file is very small, it can also be entered manually directly using R Commander.
In R Commander: Click “Data,” “New data set...” and give the data set a name. Click
“OK.” Add rows and columns as necessary and type variable names and data values
directly into the spreadsheet.
2.8.2  Variable Types
In this Manual, we will work with two different types of variables: Numerical variables
always have number values (e.g., 3 or 1.2). Factor variables can be strings (i.e., words),
such as “treatment” or “control” or they can be numbers (e.g., representing treatment
groups 1,2,3, etc.) It is important to make sure that R understands the variables to be
numeric or factor variables. In general, R will import variables that contain only number
values as numeric variables and variables that contain any strings as factor variables.
Strings cannot be converted into numeric variables, but numeric variables can be
converted to factors.
In R Commander: To convert a numerical variable into a factor variable, load the
data set and click “Data,” “Manage variables in active data set,” and “Convert
numeric variables to factors....” Select the variable to be converted and decide
whether to keep the numbers (e.g., groups 1,2,3) or whether to call them by other
names (e.g., drug A, drug B, placebo).
Common problems:
If a numeric variable has a string variable name and if the button “Variables names
in file” is left unchecked while importing the data, then R will understand the
variable as a factor (because the name row contains strings).
Solution: Either reload the data (this time checking the appropriate button) or
22

delete the variable names row in the data editor, enter the names in the variable
name slots/holders, and convert the numerical variables into factors.
If the data contain missing values that are coded through string expressions (e.g.,
NA and N/A), then R may misinterpret these entries as strings.
Solution: Reload the data and specify the appropriate missing data indicator.
2.8.3  Handling Graphics
Throughout this Manual, we provide detailed instructions for creating specific graphical
displays that are suitable for different situations and different types of data using R
Commander. In general, any graph will appear as a separate graph window. If a new
graph is created, it will generally overwrite the graph currently displayed. Graphs can be
resized (by dragging the lower left corner of the graphics window) and saved for future
use. To save a graph, click on the graph window, and then on “File,” “Save as” in the R
menu (not the R Commander menu). Graphs are saved in pdf format.
There are many options in R that control the appearance of graphs. Many of them can be
entered directly into the plot() command. For example, the simple command
plot(x,y)
was used to create the default scatterplot of two numerical variables x and y, as
illustrated in the left panel of Figure 3. Alternatively, the right panel in Figure 3 was
created with the command
plot(x,y, xlab = "predictor x", ylab = "response y", main = "Title",
col = "darkred", pch = 16, cex = 2, cex.lab = 1.5, cex.main = 2)
xlab, ylab and main are the commands that allow labels to be added to the x-
axis, the y-axis, and the main title of the plot, respectively.
col lets the user select a color for the displayed symbols in the plot. R recognizes
more than 500 different colors ranging from run-of-the mill (e.g., red, green, and
blue) to more exotic (e.g., lawngreen and peachpuff). Search online for “R
colorcharts” to find exhaustive lists of available colors.
pch determines the plotted symbols used in the graph.
23

cex is an enlargement factor that can be used for the symbols in the plot (cex), the
axes labels (cex.lab), or the main title (cex.main).
FIGURE 3. R scatterplots with default graphics settings (left) and modified graphics
options (right).
2.8.4  Saving Your Work
When you are finished with data analysis in R Commander, or when you have to interrupt
your work, you may want to save the R commands you have previously run.
In R Commander: Click “File,” “Save Script as...” to save the contents of the “R
Script” window in a file (ending on .R). Upon restarting R Commander, load the file
again and keep working where you left off by clicking “File” and “Open script file....”
The nongraphical output created by R can be saved in a text file.
In R Commander: Click “File,” “Save output as” to save the output.
2.8.5  Getting Help
Although we provide detailed instructions on how to use R Commander to perform
24

various statistical analyses that are detailed in this Manual, users who desire a
exhaustive description of the functionalities of R Commander are referred to Fox (2005).
Any drop-down menu in R Commander contains a “Help” button. The help menu will
open the R-Help page for the command to be carried out. Help pages are all organized in
the same way:
The DESCRIPTION gives an overview of the general purpose of the specific R
function.
The ARGUMENTS section explains the (often optional) arguments to the function and
their possible values.
The EXAMPLES section at the very bottom of the help page provides examples of the
command. Often, the example commands can be cut and pasted directly into the R
script window and executed for the purpose of gaining a better understanding of
what the function does.
25

3  Descriptive Statistics
3.1  Definitions
VARIABLE: A variable is an observed category (label) or quantity (number) in an
experiment. A variable that takes on label values is called a categorical variable or a
factor. A variable that takes on number values is called a quantitative variable.
CATEGORICAL VARIABLE: A categorical variable takes on label values (e.g., red, green,
and blue). It can also take on number values if the numbers are used to code for certain
conditions (e.g., male = 1, female = 2). However, in this case, the numbers should not be
understood as numerical measurements (i.e., male 
 female). In R, categorical
variables are called factors.
QUANTITATIVE VARIABLE: A quantitative variable counts the occurrence of an event or
measures a numerical quantity. This kind of variable only takes on number values. If the
variable is used to measure a count, it is called discrete. If the variable is used to
measure a quantity that may take on any value in an interval (e.g., 0 to 1), it is called
continuous.
ORDINAL VARIABLE: If the possible values of a variable possess a natural logical order
(e.g., 1 < 2 < 3; or strongly disagree < disagree < neutral < agree < strongly agree), the
variable is called ordinal. In general, quantitative variables that measure something are
always ordinal. Categorical variables may or may not be ordinal. Quantitative ordinal
variables are called QUALITATIVE variables.
Example 3.1
To understand the different types of variables involved in biological experiments
consider the following examples:
1. In Gregor Mendel’s experiment, Mendel (1865), he recorded the color and shape
of pea seeds. The possible values for color were yellow and green, and the
26

possible values for shape were smooth and wrinkled, so both of these variables
are categorical. Because there is no logical order in these values (e.g., green ≯
yellow and yellow ≯ green), neither variable is ordinal.
2. If bacteria are grown on a petri dish, then the number of bacteria that are visible in
a randomly chosen 10–4 in2 microscope cross-section is a quantitative random
variable. The possible values are 0, 1, 2, 3, …. Because this variable is
quantitative, it is automatically ordinal (0 < 1 < 2⋯).
3. In spectrophotometry, light is passed through a liquid, and the amount of light
absorption (in %) can be used to deduce the concentration of a substance in the
liquid. Absorption in this case is a continuous variable that takes on values in the
interval [0, 1] or [0, 100], depending on the scale that is used.
RANDOM VARIABLE: A random variable is a placeholder for the outcome of an
experiment that is subject to chance. The value that the variable will take on is unknown
before the experiment is conducted. However, the distribution of the random variable,
which assigns probabilities to specific outcomes, may be known.
OBSERVATION: After an experiment has been conducted and is complete, the values that a
random variable has taken on are recorded. They are referred to as the observations in
the experiment.
Example 3.2
Gene expression is a continuous random variable because it takes on values in an
interval. Even though fold changes are sometimes reported as integers, intermediate
values are possible and can be determined with more precision in the measurements.
Thus, “expression” of a gene is a random variable. A description such as “gene XYZ
underwent a 2.37-fold change between treatment and control sample” is an observation
on the random variable.
When a random variable such as gene expression, or height of a plant, is observed
repeatedly on several subjects (different genes, plants, etc.) it is often convenient to
graphically display the results. For quantitative variables, the most commonly used
graphical display methods are histograms, dot plots, scatter plots, and box plots,
described in Section 3.3.
3.2  Numerical Ways to Describe Data
27

When several observations of the same type are obtained (e.g., gene expression of many
genes in a microarray experiment), then it is often desirable to report the findings in a
summarized way rather than list all individual measurements. This can be done in
different ways. We will next describe the most common numerical measures that
summarize categorical and quantitative data.
3.2.1  Categorical Data
Categorical data are most commonly summarized in tables. The tables contain the labels
or possible categories and COUNTS of how often these labels were observed in the
experiment. If two categorical variables are observed on the same individuals, then the
data can be summarized in the form of a two-dimensional CONTINGENCY TABLE.
Example 3.3
To test the effectiveness of two potential yellow fever vaccines A and B, laboratory mice
are vaccinated with vaccine type A, or vaccine type B. Some mice are left unvaccinated
to function as a control. All mice are infected with the yellow fever virus, and after an
appropriate incubation period, live and dead mice are counted. Thus, data are collected
on two categorical variables per mouse. One variable describes the type of vaccine the
mouse received (A, B, or none) and the other variable states whether the mouse is alive
or dead. The experimental results in form of a contingency table look like this:
A B none
Live
7 5
3
Dead 3 7
12
For example, ten mice were vaccinated with the type A vaccine, and of those, seven
survived.
3.2.2  Quantitative Data
The mean and median are commonly used to describe a typical or center value of a
quantitative variable, respectively. Percentiles can be used to convey information on
both the center and the spread. Variance, standard deviation, range, and interquartile
range are common measures for the spread or variability in the data.
MEAN: The average of all observations:
28

where the observations are denoted x1, x2, … , xn and n is the number of observations
(sample size). Other commonly used terms for the mean are EXPECTED VALUE and
AVERAGE.
MEDIAN: The middle observation, if the number of observations n is odd. If n is even,
then the median is the average of the two middle observations. Half of the observations
are always larger than the median and the other half are smaller.
PERCENTILES: Similar to the median, the pth percentile of the observations is the
observation value such that p% of the observations are smaller than it. Consequently, the
median can also be thought of as the 50th percentile. The 25th and 75th percentiles are
sometimes referred to as the first and third QUARTILES, respectively.
VARIANCE: The variance is the average squared distance (deviation) of observations
from the mean.
29

where x1, … , xn denote the observations and n is the sample size. Variance is used as a
measure of variation in the observations and describes the spread of the distribution.
STANDARD DEVIATION: This is simply the square root of the variance. Unlike the
variance, which has nonsensical units, the units of the standard deviation are the same as
the original observation measurements. Commonly used symbols for standard deviation
(variance) are s, σ (s2, σ2). Standard deviation should not be confused with standard
error (Section 3.6).
RANGE: This is the distance between the largest and smallest observation. The range can
be used as a crude measure of spread in the data, but it is more susceptible than the
variance (standard deviation) to misrepresent the true variation in the data if there are
uncharacteristically large or small observations among the data points.
INTERQUARTILE RANGE: Another measure for variability in the data which is less
dependent on extreme (big or small) data values is the interquartile range (IQR). It is the
distance between the third and first quartile of the data. This unit is sometimes used to
determine whether or not a data point may be considered an OUTLIER.
In R Commander: To compute summary statistics on a quantitative variable, click on
“Statistics,” “Summaries,” and select “Numerical Summaries.” Choose the variable(s)
30

for which to compute summary statistics. Click “OK.” R will report the mean, the
standard deviation (sd), the interquartile range (IQR), and the 0th, 25th, 50th (this is
also the median), 75th, and 100th percentile, respectively. The 0th percentile is the
smallest and the 100th percentile is the largest observation. Therefore, the range can
be obtained by subtracting the smallest from the largest observation. R also reports the
sample size (n).
3.2.3  Determining Outliers
An outlier is a data point whose value is very different from that of the majority of the
data. Outliers can be caused by errors during the measurement process or during the
recording of data. Outliers may also be measurements that differ from the majority of the
data points for legitimate reasons (e.g., one patient with a rare extreme reaction to a
treatment). The decision of whether or not an observation is an outlier is a subjective
one.
A statistical rule of thumb to decide whether or not an observation may be considered an
outlier uses the IQR of the data. Using all data points (including possibly suspected
outliers), compute the first and third quartile Q1 and Q3, as well as the interquartile range
IQR = Q3 – Q1, for the data. An observation can be considered to be an outlier if it is
either larger than Q3 + 1.5× IQR or smaller than Q1 – 1.5× IQR.
If an observation is suspected of being an outlier, double check the recording of the
observation to rule out typographical errors. If the measurement cannot be repeated, a
statistical analysis should be performed with and without the outlier to determine if this
one data point influences the results of the analysis. Because a single data point should
not change the outcome of any statistical analysis, removal of the data point may be
required. If the data point is omitted in the subsequent analysis, then the decision to
remove the data point should be accompanied with an explanation as to why this value is
considered an outlier, and what may have caused it to be so different from the majority of
the observations.
Example 3.4
The iron content of various foods was measured by G. von Bunge (Bunge 1902). In this
experiment, spinach was determined to contain 35 mg of iron per 100 g of spinach. When
this value was used by other scientists later on, an error was made. The scientists used
the value measured by von Bunge, but failed to notice that it was attributed to dried
31

spinach rather than raw leaves. This error gave rise to a campaign for the health benefits
of spinach, as well as a popular comic figure.
The table below lists iron content (in mg) in 100 g of particular foods as reported by the
USDA in the national nutrient database for standard reference; USDA (Release 18).
Food
Iron per 100 g (in mg)
Beef, cooked
6.16
Sunflower seeds, roasted, salted
3.81
Chocolate, semisweet
3.13
Tomato paste, canned
2.98
Kidney beans, boiled
2.94
Spinach, raw
2.70
Brussel sprout, cooked
1.20
Soy milk
1.10
Lettuce, raw
1.00
Broccoli, raw
0.91
Cabbage, red, raw
0.80
Raspberries, raw
0.69
Strawberry, raw
0.42
Potato, baked
0.35
32

Food (von Bunge)
Iron per 100 g (in mg)
Spinach, dried
35.00
If these data values were combined, would the high iron content of dried spinach be
considered a statistical outlier? What about the value for beef? Computing the quartiles
for the above 15 data points yields Q1 = 0.855 and Q3 = 3.055 and hence an interquartile
range of 3.055 – 0.855 = 2.2. Because the value 35 is larger than Q3 + 1.5 × IQR = 3.055
+ 1.5 × 2.2 = 6.355, the dried spinach value would be considered an outlier in these
data. This makes sense, as all other values are taken from fresh or cooked foods, and the
dried spinach is fundamentally different from all other foods listed. The iron value for
beef (6.16 mg) is smaller than Q3 + 1.5 × IQR and hence would not be considered an
outlier.
3.2.4  How to Choose a Descriptive Measure
The mean and median are numerical measures that are used to describe the center of a
distribution, or to find a “typical” value, for a given set of observations. If there are
some atypical values (outliers) among the observations, then the median is a more
reliable measure of center than the mean. On the other hand, if there are no outliers and
especially if the number of observations is large, then the mean is the preferred measure
of center. If the data are to be used to answer a specific question, then working with
means rather than medians will make subsequent statistical analysis much more
straightforward.
Variance, standard deviation, range, and interquartile range are all measures that can be
used to describe the spread or variability in the observations. If the variability in the data
is small, then this means that the observations are all grouped closely together. If, on the
other hand, the observations cover a wide range of values, then the variation measure
will be large. As is the case for the measure of center, the variance and standard
deviation are better suited for situations where there are no extreme outliers among the
observations. The range is very susceptible to outliers because it is based entirely on the
largest and smallest observation values.
33

Data characteristic Statistical measure When to use
Center
mean
median
no outliers, large sample
possible outliers
Variability
standard deviation
interquartile range
range
no outliers, large sample
possible outliers
use with caution
3.3  Graphical Methods to Display Data
BAR PLOT: For categorical data, a common graphical display method is a bar plot. The
number of observations that fall into each category are counted and displayed as bars.
The length of the bars represents the frequency for each category. Because the values of a
categorical variable may not be ordinal, the order of the bars (each labeled by the
category it represents) can be altered without changing the meaning of the plot.
Example 3.5
Suppose the variable recorded is flower color of a plant. In an experiment, 206 progeny
of a certain parental cross of a flowering plant were obtained and categorized by their
flower color. The results may be listed in table form. Figure 4 displays the data in the
form of two bar plots.
Color Count
red
94
white
37
pink
75
PIE CHART: When displaying categorical data, an alternative to the bar plot is a pie chart
(compare Figs. 4 and 5) in which the frequencies (number of observations of a particular
category) are expressed as relative frequencies. To compute relative frequencies (% of
total observations) determine the total number of observations and divide each frequency
by that number. The categories are then represented by “slices of pie” of varying
thicknesses rather than by bars. Together, the slices add up to the “whole pie” (circle)
and represent the total number of observations.
34

FIGURE 4. Observed flower color of 206 plants represented with a bar plot. The bars are
labeled by the colors they represent, and the frequencies are expressed through the height
of the bars. The order of the categories is arbitrary.
FIGURE 5. Pie chart of the flower color data from Example 3.5.
In R Commander: The data should consist of a categorical variable. The values of
the variable are the category labels and each label may appear with different
frequencies (e.g., there may be 94 “red” entries). Click “Graphs” and select either
“Bar Graph” or “Pie Chart.” Click “OK.” The default order for the categories is
alphabetical.
HISTOGRAM: In a histogram, the range of observations is divided into subcategories (most
often of equal size). The frequencies of observations (i.e., number of observations that
fall into a certain subcategory) are plotted as a bar on the y-axis. The bin width and
number of bins that should be used in a histogram depend on the data. Histograms may
35

not be appropriate if the number of observations is small. The larger the number of
observations, the narrower the bins can be chosen while still accurately portraying the
data. Well-constructed histograms allow a quick overview of the data to check it for
center, symmetry, outliers, and general shape.
Example 3.6
In 1846, William A. Guy studied the duration of life among the male English gentry (Guy
1846) . He recorded the life spans of 2455 adults (ages 21 and up) from pedigrees of
country families and from mural tablets. His results are displayed in Figure 6 in the form
of a histogram. Because the number of observations (2455) in this example is very large,
the histogram bin width can be relatively small (e.g., 5 yr or less) to obtain a detailed
impression of the results. If the bin width is larger (e.g., 10 yr) the presentation of the
same data will have less detail in its visual distribution. The size of the bin width should
be determined by the level of detail needed in the study’s conclusions.
FIGURE 6. Life span in years of the male English gentry. The same data from Guy (1846)
are displayed with different bin widths in the form of a histogram. In the histogram on the
left, the bin width is 10 yr and in the histogram on the right the bin width is 5 yr.
In R Commander: To create a histogram for a quantitative variable, click “Graphs”
and “Histogram.” The frequencies displayed are the number of observations greater
than the left bin boundary and less than or equal to the right bin boundary. The number
of bins may be changed by supplying a value for the option “breaks.”
36

DOT PLOT: For quantitative data, especially if the number of observations is moderate to
small (n ≤ 20), a better graphical display method than a histogram is a dot plot,
sometimes called a strip chart. Although in a histogram, the observations are categorized
(placed in bins) and thus summarized, a dot plot displays each data point separately and
conveys more information to the reader. In a dot plot, each data point is represented by a
dot that is placed either vertically or horizontally on an axis representing the
measurement values (Fig. 7).
FIGURE 7. Two dot plots of the same 10 observations plotted horizontally (left) and
vertically (right). Repeated observations of the same value are plotted above or besides
each other.
In R Commander: To create a strip chart (dot plot) for a quantitative variable, click
“Graphs” and “Strip chart.” Select the variable you want to plot. You can select an
additional factor (optional) to create a side-by-side strip chart to compare several
conditions.
SCATTER PLOT: The most convenient graphical display for two quantitative variables is a
scatter plot. In it, one variable is plotted on the horizontal x-axis and the other variable is
plotted on the vertical y-axis. Scatter plots allow a visual overview of center and spread
for each variable while at the same time giving important clues to possible relationships
between the two variables.
In R Commander: To create a scatter plot for two quantitative variables click
“Graphs” and “Scatterplot.” Select the x- and y-variable to plot. You can label the
37

axes, change the plotting characters, and include a regression line under the “Options”
tab.
BOX PLOT: Like histograms, box plots display quantitative data. They make use of
computed quantities that describe the data (such as the median and quartiles) and display
them graphically. Box plots summarize data and are suited to describe outcomes of
experiments in which the number of observations is too large to report each outcome
separately (as is done in a dot plot). Box plots are especially useful if the graph is
intended to compare measurements on several populations or to compare the reaction of
a population to different conditions.
In R Commander: To create a box plot for a quantitative variable, click on “Graphs”
and on “Boxplot.” Select the variable for which you would like to create the box plot.
If the “Plot by groups” option is selected, side-by-side boxplots that compare across
several groups can be created.
In a box plot, the response variable is shown on the vertical axis. The box extends from
the first quartile to the third quartile of the data. The line in the middle of the box
indicates the median data value. The lines on the top and botton extend to the maximum
and minimum observation, respectively.
In a MODIFIED BOX PLOT, outliers are indicated as circles and the lines are only extended
to the largest (smallest) observations that are not outliers.
Example 3.7
For William A. Guy’s data (1846), which contains observations on the life span of the
English upper class in the 19th century, it may be of interest to compare the life spans of
the gentry, aristocracy, and sovereignty. Do sovereigns live longer than aristocrats? To
make this comparison using a graph, we draw a side-by-side box plot for the available
observations on the three groups.
From the box plot, it is possible to observe that the life spans do not differ very much
between the three groups. Overall, sovereigns seem to live a bit shorter lives than the
members of the other two groups.
38

A side-by-side box plot is one example for a graphical display of more than one
variable. In Example 3.7, the variables are LIFE SPAN, which is quantitative, and GROUP,
which is categorical and takes on values aristocracy, gentry, and sovereignty.
3.3.1  How to Choose the Appropriate Graphical Display for Your Data
The purpose of graphically displaying data is to convey information to the reader.
Depending on which aspect of the data the author wishes to focus, different display
methods may be better suited to bring the point across. Generally, it is a good idea to
present a more comprehensive overview of the data unless it makes the display overly
cluttered. For example, if the intent of the author is to compare repeated measurement
values for two groups, a graph that displays not only the means, but also some
measurement of the spread is clearly preferable to one that displays only the means (Fig.
8).
39

FIGURE 8. Comparing graphical representations of measurements on a treatment and a
control population. Although it is possible to graph the two population means as bars (a),
this display method does not convey enough relevant information to decide whether there
is a difference between the two groups. If the same data are displayed in the form of a
side-by-side box plot (b), the difference in center can be related to the spread in the
observations and a decision of whether or not there is a significant difference can be
made.
For very large data sets, some form of summarization is necessary. Quantitative data may
be displayed in histograms or box plots. Both convey a sense of center and spread of the
observations to the reader. If unusual observations (outliers) are important, then a
modified box plot may be the best display. Box plots are better suited than histograms to
visually compare several populations.
Quantitative data can be displayed interchangeably with either a bar graph or a pie chart.
If quantitative measurements for different populations are to be visually compared, then
bar graphs may be plotted side by side with different colors for different populations.
This method is reasonable, as long as the number of populations to be compared is small
(≤3).
3.4  Probability Distributions
Recall that a random variable is a placeholder for the outcome of an experiment that is
subject to chance. Before the experiment is conducted, the value of the random variable
is unknown. However, the probabilities with which the random variable takes on
specific values may be known. Statisticians call this the PROBABILITY DISTRIBUTION of
40

the random variable.
Example 3.8
A cross, or mating, is performed between two individuals who are heterozygous (Aa) for
a particular allele. The genotype of the offspring can be of the form AA, Aa, or aa. Before
the cross is performed, we do not know which genotype the offspring will have.
However, we do know that the probabilities with which these genotypes occur are 0.25,
0.5, and 0.25, respectively.
A number of special probability distributions arise frequently in biological applications.
Two of the most important distributions, the BINOMIAL and the NORMAL distribution, are
discussed below.
3.4.1  The Binomial Distribution
Consider the following situation: A series of n independent trials is conducted. Each trial
will result either in a success (with probability p) or in a failure (with probability 1 – p).
The quantity in which we are interested is the number of trials that will result in a
success.
The quantity, X, is a random variable because the outcomes of the trials are subject to
chance. It may take on values 0 (in the case that no trial results in a success), 1, 2, etc.,
up to n (in the case that every trial results in success). A random variable of this kind is
called a binomial random variable with parameters n and p. The fundamental
assumptions for this kind of random variable are
The n trials are identical and independent (their outcomes do not influence each
other).
The probability p of a success is the same in each trial.
For every possible value (0, 1, …, n) of a binomial random variable, a probability can
be assigned (Fig. 9). For example, the probability of observing zero successes in n trials
is (1 – p)n, which is the probability that all trials result in failures. More generally, the
probability of seeing k successes in n trials can be computed as
41

Here, 
 is a binomial coefficient that may be computed (by hand) as 
, or by using the R command “choose(n, k).” Sometimes it is
valuable to compute probabilities of the form P(X ≤ 3), or “what is the probability of
having at most three successes.” Statisticians call these expressions CUMULATIVE
PROBABILITIES, because probabilities of possible values are accumulated, e.g.,
FIGURE 9. Three probability histograms for binomial distributions with parameters n =
10 and p = 0.3 (a), p = 0.5 (b), and p = 0.9 (c), respectively. The height of a bar
indicates the probability of seeing this many successes in the n = 10 trials.
In R Commander: To compute probabilities or cumulative probabilities for a
binomial random variable click on “Distributions,” “Discrete distributions,”
“Binomial distribution,” and either “Binomial probabilities” or “Binomial tail
probabilities.” Enter the number of Binomial trials n and the success probability p.
For a tail probability, you will also have to enter the variable value k for which you
would like to compute the cumulative probability and indicate whether you need a
lower tail (i.e., P(X ≤ k)) or an upper tail (i.e., P(X > k)).
Example 3.9
If two carriers of the gene for albinism have children, then each of their children has a
probability of 0.25 of being albino. Whether or not subsequent children are albino is
independent of their siblings. The number of children with albinism in this family is thus
a binomial random variable with p = 0.25 and n = number of children in the family.
To find the probability that in a family with three children, in which both parents carry
42

the gene for albinism, there is exactly one child with albinism, we use the binomial
distribution. Our binomial random variable here is X = number of children with
albinism, and we need to compute the probability that X is equal to one.
To find the probability that in the same family there are at most two children with
albinism, we use the cumulative distribution function instead. For the same random
variable X as above, we now want to compute the probability that X is at most 2 (or X ≤
2). We can do this either by computing the probabilities that X is equal to 0, 1, or 2 and
adding them up or by using R Commander to compute the cumulative probability
3.4.2  The Normal Distribution
The distributions of discrete random variables, such as the binomial, may be displayed
in histograms. The height of the bar for each possible value corresponds to the
probability with which this value will occur in the experiment. For continuous random
variables, which may take on any value in an interval, an analogous display method is
used (compare Fig. 10). The most often used continuous distribution in practice is the
normal distribution. It arises naturally (but not automatically) in many situations. It also
has an important role whenever statistics are computed based on a large number of
observations.
FIGURE 10. Discrete probability distributions can be displayed using histograms. The
number of bars in the histogram corresponds to the number of possible values that the
random variable may take on (left and middle). For a continuous random variable, which
can take on infinitely many possible values, the probability distribution is displayed as a
43

density curve (right).
SHAPE: Normal distributions have the characteristic bell shape. They are symmetric and
characterized by their mean μ and standard deviation σ, where μ and σ are called the
parameters of the normal distribution. All normal distributions have essentially the same
shape (Fig. 11), which is described by the function
The mean μ determines the center (position on the x-axis). The standard deviation σ
determines the spread, as well as both the height and width of the curve. Larger standard
deviations (more spread) give rise to flatter, wider curves.
FIGURE 11. The normal distribution is symmetric around its mean μ. Approximately 68%
of the data can be found within one standard deviation of the mean (μ ± σ); 95% of the
data lie within two standard deviations of the mean (μ ± 2σ) and 99.7% lie within three
standard deviations of the mean (μ ± 3σ).
Note: A normal distribution with mean μ = 0 and standard deviation σ = 1 is
44

referred to as a STANDARD NORMAL DISTRIBUTION.
The normal distribution is a continuous distribution, i.e., random variables that are
normally distributed can take on any value in an interval. To compute probabilities for
such a random variable, one needs to look at the area under the normal distribution
curve. The total area under the curve is equal to one. The area under the curve between
two values x1 and x2 corresponds to the probability that the random variable takes on
values between those numbers P(x1 ≤ X ≤ x2) (Fig. 12). In many statistical applications,
we are interested in “tail probabilities” for distributions. This means that we want to
find out how large the area under the distribution curve is to the left (right) of a specific
value x. Alternatively, we might also need to know which x-value corresponds to a
specific (e.g., 0.05) tail probability.
FIGURE 12. (a) Left tail probability for a normal distribution curve. The hatched area
corresponds to the probability that the random variable takes on a value less than or
equal to x. (b) Probability for a normal random variable. The cross-hatched area
corresponds to the probability that the random variable takes on a value between x1 and
x2. It can be computed by subtracting the left tail corresponding to x1 from the left tail
corresponding to x2.
In R Commander: To compute probabilities for random variables with a normal
distribution, click “Distributions,” “Continuous distributions,” “Normal distribution,”
and “Normal probabilities.” Enter a variable value x as well as a mean and standard
deviation to compute, for instance, a lower left tail probability of the form P(X ≤ x).
Click “OK.”
45

Example 3.10
To compute the probability that a normal random variable with mean μ = 10 and standard
deviation σ = 2 takes on values between 9 and 13, follow the instruction above and
obtain
To find P(9 ≤ X ≤ 13), we subtract these two probabilities from each other (the answer is
0.624) because we want the probability of values that are to the left of 13 but not to the
left of 9.
Example 3.11
A normal distribution percentile is the value on the x-axis, such that the tail area under
the normal curve to the left of it contains a specific area. For example, to find the 5th
percentile of a normal distribution with mean μ = 5 and standard deviation σ = 3, click
“Distributions,” “Continuous distributions,” “Normal distribution,” and “Normal
quantiles.” Enter Probabilities: 0.05, Mean: 5, Standard Deviation: 3 (the answer is
0.0654).
3.4.3  Assessing Normality in Your Data
Normally distributed data is a fundamental assumption in many statistical models. How
can an experimenter be convinced that the data collected in an experiment indeed have a
normal distribution? Several methods exist: A statistical hypothesis test can answer the
question “Are my data normal- Yes/No?” at a desired degree of certainty. Easier visual
tools are the so called PROBABILITY (PP) or QUANTILE (QQ) plots. Both plots rely on
comparing the observed behavior (distribution) of the data to values that one would
expect to see if the data were, indeed, normally distributed.
PROBABILITY PLOT: The expected behavior of a normal distribution is compared to the
observed behavior of the data in the form of left tail probabilities. The left tail
probability for an observation is the percentage of observations that are smaller than it.
For example, for the third smallest of 20 observations, this value would be 3/20. This
kind of display is also sometimes referred to as a RANKIT PLOT.
QUANTILE PLOT: The normal percentiles (or quantiles) are compared to those of the
observed data. Recall that the pth percentile of the observations is the value of the
observation such that p% of the observations are smaller than it. We compute the
46

percentiles of a normal distribution with the same mean and standard deviation as the
observed data and compare them to the observations.
QQ-plots are better suited to detect deviation from normality in the tails of data, whereas
PP-plots are better suited to detect deviation from normality around the center of the
distribution. If the sample size n is large (n > 30), there is very little difference between
the two methods.
In R Commander: To create a QQ-plot to check whether a quantitative variable has a
normal distribution, click “Graphs,” and “Quantile-comparison plot.” Select the
variable for which you would like to produce the QQ-plot. Click “OK.” If the points
lie close to the red line, with no discernible nonlinear pattern, then the data are
approximately normal.
Interpreting the plot: If the data have an approximately normal distribution, then the
dots in the scatter plot should lie approximately on the 45° line (see Fig. 13). Slight
deviations from the line are to be expected due to variation in the observations. If the
scatter plot exhibits any kind of systematic shape (e.g., an S-curve), then this is an
indication that the data are not normally distributed.
FIGURE 13. A QQ-plot can be used as a visual tool to determine whether data have a
normal distribution. If the points in the QQ-plot lie close to the red line (left), then this is
an indication that the data are normally distributed. If the points form any other shape
47

(e.g., an S-curve [right]), then this indicates that the data do not have a normal
distribution.
3.4.4  Data Transformations
If data are not normally distributed, but a statistical model is to be used that requires
normality, then sometimes the data can be transformed to satisfy the model assumptions.
In this process, a function is chosen and applied to all observation values. For example,
if one original observation is x = 5 and the transformation function, natural logarithm
(ln), is chosen (e.g., f(x) = lnx), then the value ln 5 = 1.609 is used instead. The
transformed values are tested again for normality. If the transformed data pass a
normality check, a statistical model can be fitted to the transformed data. If the
transformed data fail to meet the normality check, a different transformation may be
attempted.
Popular functions used for transformations include:
Which function is most appropriate for a particular data set is usually determined through
a trial-and-error procedure. Pick a function, transform all data, and check for normality.
Repeat as necessary until the transformed data appear more or less normal.
Whether or not a transformation is appropriate is a subjective decision (not all data
should be transformed). Keep in mind that any transformation makes the statistical model
that explains the observed biological process more complex. Simpler transformations
are usually preferred over more complicated ones, because they are easier to explain in
a biological context. We suggest staying away from convoluted transformations such as 
, even if they produce perfectly normally distributed data. The
goal is to achieve a trade-off between normality of the observations and interpretability
of the resulting model. Read more on statistical models in Section 4.1.
Note: Sometimes it is not possible to find a reasonably simple transformation to
make your data look normal. In these cases, the statistical model needs to be adjusted
instead of transforming the data. Do not try too hard!
3.5  The Central Limit Theorem
48

In many biological applications, it is of interest to learn more about a quantitative
characteristic of a population. Examples include the average lifetime of a certain
organism or the average expression of a particular gene in a plant undergoing a treatment
such as drought stress. Other experiments focus on studying the presence or absence of a
trait in a population. What percentage of human patients carry the gene for cystic
fibrosis?
The number of individuals (bacteria, plants, humans) that can be included in a study is
usually constrained by the time, money, and manpower available. Even though it is the
researcher’s intent to draw conclusions about a general POPULATION (such as all
humans), one is restricted to work with a SAMPLE (such as the limited number of
volunteers in a clinical trial). A different choice of sample will lead to different
observations on the subjects involved in the study and thus may lead to different
conclusions.
Example 3.12
Suppose that in a population of 10,000 individuals, 1% of subjects carry a particular
allele. This particular allele is the focus of study in an experiment. For the experiment,
10 individuals are randomly selected from the population to determine whether or not
they carry the allele. The number
is called a SAMPLE PROPORTION. Because the allele is relatively rare, recall that only 1%
or 100 out of 10,000 individuals carry it. Therefore, most likely, none of the 10 randomly
selected individuals are carriers (most likely 
). Of course, it is possible that one
or even several individuals in the random sample do carry the marker (possibly 
or 
. The quantity  is a random variable (its value depends on the choice of
sample). We can compute its distribution using the binomial distribution (compare
Section 3.4.1). For example, the probability of randomly selecting 10 individuals, none
of which carry the allele ( ), is 0.9043.
Note: When statisticians want to express a quantity as an estimate of a population
parameter that was computed based on sample data, they often use the “hat” notation.
For instance,  denotes the estimate of the population parameter p, where p for the
whole population is unknown, but  can be computed from a set of observations
49

(data).
If we know the true number of individuals in a population who exhibit a characteristic
(such as 1% who carry a gene), we can compute the probability distribution of the
random variable 
. However, most experiments are conducted under circumstances
where the population proportion is unknown. Indeed, estimating this population
proportion is the very intent of many experiments. Is it still possible to make statements
about the statistical distribution of the sample proportion? Yes! The Central Limit
Theorem makes a general statement about the distribution of the random variable SAMPLE
PROPORTION. Details are discussed in Section 3.5.1.
If an experiment is intended to study a quantitative trait in a population, then an often-
reported number is the SAMPLE MEAN. That is, individuals are chosen from the
population, the characteristic is measured on them, and the mean of these measurements
is used as a representative measure for the whole population. Sample means are also
random variables because their values depend on the choice of individuals in the sample.
In other words, a new sample of the same size from the same population will produce a
different sample mean. The Central Limit Theorem may also be used to draw conclusions
about the distributions of sample means (see Section 3.5.2).
3.5.1  The Central Limit Theorem for Sample Proportions
Theorem: Suppose that in a large population, p% of individuals exhibit a certain
characteristic. A sample of size n is chosen at random from the population and the
sample proportion of the characteristic
is determined. Then  is a random variable whose value depends on the choice of the
sample. If the sample size n is sufficiently large (see note below), then the distribution of
 is approximately normal with mean 
 and standard deviation 
.
Note: How large should the sample size n be so that the Central Limit Theorem will
hold? The answer depends on the frequency of the trait in the population. As a rule of
thumb, the sample size n should be large enough so that both np ≥ 10 and n(1 – p) ≥
10. The population from which the sample is chosen at random should be much
50

larger than the sample. This condition is satisfied in most biological applications.
3.5.2  The Central Limit Theorem for Sample Means
Theorem: Suppose that a characteristic has some distribution (not necessarily normal)
in a population with mean μ and standard deviation σ. A sample of size n is chosen at
random from the population and the characteristic is measured on each individual in the
sample: x1, … , xn. The average of these sample values, 
, is a random
variable whose value depends on the choice of the sample. If the sample size n is
sufficiently large (see note below), then the distribution of  is approximately normal
with mean 
 and standard deviation 
.
FIGURE 14. If a characteristic has a normal distribution in a population (a), then the
Central Limit Theorem holds for sample sizes as small as n = 2. If the distribution of the
characteristic in the population is approximately normal (b), then the Central Limit
Theorem holds for small-to-moderate sample sizes n ≈ 5. If the distribution of the
characteristic in the population is very “non-normal” (c), then the sample size should be
large (n ≈ 30) for the Central Limit Theorem to hold.
Note: How large should the sample size n be for the Central Limit Theorem to hold?
In the case of sample means, the answer depends on the distribution of the
characteristic in the population (see Fig. 14). If the distribution is normal, then the
Central Limit Theorem holds for sample sizes as small as n = 2. The less “normal”
the distribution of the characteristic is in the population, the larger the sample size n
should be for the statement to be valid. In general, sample sizes of n = 30 or larger
are considered sufficient regardless of the distribution of the characteristic in the
population.
Example 3.13
The Central Limit Theorem describes the statistical behavior of a sample mean. To better
51

understand the message behind this important statement, consider the scenario presented
in Figure 15. The population here consists of six plants and the characteristic that is
measured on them is number of flower petals. The average number of flower petals in the
population is μ = 4 with a standard deviation of σ = 0.894. From the population, samples
of two flowers are chosen at random (n = 2). Depending on the selection of individuals,
or flowers, the average number of petals 
 in the sample varies from three to five.
However, the mean of the observed petal averages 
 is equal to four, the same as the
true population mean, μ, of petals in the population. The standard deviation of the petal
means is 
.
FIGURE 15. Illustration of the Central Limit Theorem.
In actual biological experiments, the population is likely much larger than the one in
Example 13, e.g., all plants. The sample size in the real experiment is the number of
plants in the laboratory on which the researcher obtains measurements. It may be as
small as the one used here (n = 2) or larger. Most likely, the trait studied is more
complex than simply the number of flower petals. If the trait can be described
numerically, for example, a gene expression value or as the physical reaction of a plant
to a treatment, then the Central Limit Theorem applies. In other words, the researcher
uses the measurements on the individuals in the sample to draw conclusions about the
general population of plants. Knowing the behavior of a sample statistic allows us to
make these generalizations.
3.6  Standard Deviation versus Standard Error
Two quantities that are commonly confused are the STANDARD DEVIATION and the
STANDARD ERROR. They model different phenomena and thus are not interchangeable
quantities.
52

STANDARD DEVIATION: Describes the variation in observed or sampled values within a
population. If all individuals in the population exhibit similar values for a certain trait,
the standard deviation σ of the trait in the population is small (compare Section 3.2.2).
STANDARD ERROR: The standard error 
 is the standard deviation of the sample
statistic . Suppose that a sample of size n is taken from the population and the mean of
that sample is computed. Suppose further that this process is repeated many times with
different samples to yield many sample means of the same quantity. The standard error
represents the variation in mean values around the true population mean resulting from
choice of sample. As the sample size n increases, the accuracy in representation of the
population mean by the sample mean increases and the standard error decreases.
Example 3.14
Suppose the variable of interest is body weight (in grams) of mice on different diets.
Mice on high-fat diets will typically have higher body weights than mice on low-fat
diets. However, due to biological variation, the weights of individual mice will vary
(even if the mice are presented with the same kind and amounts of food). For the mice
receiving the high-fat diets, the weights will vary more than for the mice on low-fat diets.
To obtain accurate measurements of average weight under both diet conditions, more
mice on the high-fat diet should be included in the experiment to make the standard errors
for both groups of comparable magnitude. The standard error, which is the discrepancy
of average weight and average weight observed in the experimental diet group,
decreases with sample size.
3.7  Error Bars
Using the information that the Central Limit Theorem provides about the statistical
behavior of a sample statistic such as the mean or sample proportion, we can draw
conclusions about the reliability of the information gained from a single sample. How
well does the statistic (mean, proportion, etc.) that is computed from the sample data
actually represent the population? Error bars represent the variation in the experiment
due to sampling and convey to the reader how the reported values may change with a
different choice of sample.
53

FIGURE 16. In an experiment, a quantitative response is measured for three groups. In
each group, measurements are taken on four individuals and the observations averaged.
The same results can be presented as bar graphs with error bars representing the
standard error (a) or as a bar graph with error bars that represent the standard deviation
(b). b is more informative because it is independent of the sample size and provides a
more accurate representation of the variation of the measurements among the
observations. The error bars in b are twice as wide (
) as those in a.
Scientists have a choice of how to convey this information to their audience. The two
most popular versions depicted in Figure 16 are as follows:
Standard Deviation: Let the error bars represent the estimated variation in the
population. Even though this quantity is estimated from a particular observed
sample, it is applicable to the general case of samples of any size. The length of the
error bars is equal to the standard deviation s of the observations.
Standard Error: Let the error bars represent the estimated variation in the sample
statistic. The variation in the sample statistic depends (strongly!) on the size of the
sample taken in the experiments. If the experiment were to be repeated with a
different number of observations, the error bars would not be directly comparable.
The length of the error bars is equal to the STANDARD ERROR 
.
3.8  Correlation
If an experiment records data values for two or more random variables, then one may ask
54

whether there is a relationship between pairs of variables. Does the amount of water that
a plant receives influence its height? Or does the amount of light influence height more
than water?
FIGURE 17. The correlation coefficient measures the direction and strength of a linear
association between two variables. It is independent of the units in which the variables
are measured, and hence is not related to the slope of the line that interpolates the data
points.
CORRELATION: The statistical measure that describes the linear relationship between two
random variables. Correlation is unitless. It does not depend on the units in which the
variables are measured. The correlation coefficient
measures the strength and direction of a linear relationship between two variables. It is
also known as Pearson’s product moment correlation measure. Here (xi, yi) are
measurements on n individuals with sample means  and  and standard deviations sx
and sy, respectively. The sign of r describes the direction of the association between the
variables. Positive correlation means that large x-values are associated (on average)
with large y-values. Negative correlation means that large x-values are associated (on
average) with small y-values. The absolute value of the correlation coefficient r
describes the strength of the association. Values close to zero represent weak
55

association, whereas values close to ± 1 represent strong association.
In R Commander: To compute Pearson’s correlation coefficient for two sets of
quantitative observations (x1, …, xn) and (y1, …, yn), import the observations with
values on the same individual in the same row. Click “Statistics,” “Summaries,” and
“Correlation Matrix.” Select the variables for which you would like to compute
correlations. Click “OK.”
Note: The correlation coefficient is only able to measure a linear relationship
between two variables. The variables may have some other relationship (for
example, a perfect quadratic relationship, such that for every measured pair of data
points it is y = –x2). It is important to realize that the value of the correlation
coefficient for X and Y would not reflect this quadratic relationship, as it is not a
linear one.
3.8.1  Correlation and Causation
The goal of an experiment is often to establish proof for some kind of causation. Does
second-hand smoke cause lung cancer? Will a particular fertilizer increase the yield in
corn? Experimental data are collected (e.g., observations on people exposed to various
amounts of second-hand smoke and whether or not they develop lung cancer, or amounts
of fertilizer used on a crop and yield of corn). A correlation between hypothesized cause
(second-hand smoke, fertilizer) and effect (cancer, yield) is computed. If the association
between the variables is high, then causation is often the conclusion. Statistically,
however, this conclusion may not be entirely valid because there can be several reasons
for a high association between variables, only one of which is causation.
56

Suppose two variables (call them X and Y) are studied in an experiment. However, there
is a third variable Z, on which no data are collected. After measuring X and Y on several
subjects, the experimenters find an association (high positive or negative correlation)
between X and Y. This means that subjects who are found to have high X-levels also tend
to have high (or low) Y-levels. How can that be explained?
CAUSATION: One possible explanation for a high correlation between two variables is
causation. Elevated levels of variable X cause elevated (or suppressed) levels of
variable Y in the subjects. Conversely, high levels of Y may cause high (low) levels of X.
The direction of cause and effect cannot be established through statistical correlation.
COMMON RESPONSE: In some cases, an association between two variables X and Y can be
observed, because the variables X and Y are both influenced by the third (possibly
unobserved) variable Z. In this case, statisticians call Z a “lurking” variable.
CONFOUNDING: If the observed variable X is associated with the unobserved variable Z,
and X and Z both influence Y, then it is impossible to tell how much of the observed
correlation between X and Y is caused by X and how much is caused by Z. In this case,
Z is called a “confounding” variable.
Example 3.15
It is known that there is a relationship between mood (X) and health (Y) in human patients
(Vaillant 1998). Optimistic people tend to be in better health than depressed people. It is
unclear whether a good mood directly leads to better health (e.g., X causes Y) or whether
maybe ill health tends to put people in a bad mood (e.g., Y causes X).
It has been speculated that other factors, such as intermarital stress (DeLongis et al.
1988) or exercise habits (Stewart et al. 2003), may be influencing both mood and health.
For example, increased exercise has long been known to lead to better health, but it may
also simultaneously improve a person’s mood.
Both exercise habits and mood may have an influence on a patients health. Unless data
are collected on the exercise habits as well as the mood of patients in the study, it will
not be possible to distinguish between these confounding effects. But even if data are
collected on both effects, this does not rule out the existence of further confounding
variables, such as marital stress.
Example 3.16
Comic Relief: Researchers in Germany have found a high correlation between the
57

number of storks nesting in Brandenburg (the area surrounding the city of Berlin) and
birth rates in the same area (Sies 1988; Höfer et al. 2004). Between 1965 and 1980,
stork nests have become rarer and simultaneously birth rates have become lower. Is this
proof for the “Theory of the Stork” as T. Höfer (humorously) asks?
The answer is “no.” Even though there may be a high statistical correlation between birth
rate and number of stork nests in this area, this is not proof that babies are delivered by
storks. (The authors prefer the more conventional biological explanation.)
An alternative explanation for the high observed correlation lies in environmental
factors. As towns become more urban, wildlife moves to less developed areas with
more greenery and so do families with young children. Statistically, this would be a
“common response” situation. Both stork nests and birth rates are influenced by
environmental factors, such as urbanization of formerly rural areas.
Note: It is a mistaken belief that the choice of statistical method, and not the way in
which the data are collected, determineswhether or not one can conclude causation
from correlation. This is not true. Only a carefully planned experiment, which rules
out lurking variables and/or confounding effects, is able to establish causation. Thus,
establishing high correlation between two variables is necessary but not sufficient to
conclude that one condition causes another.
58

4  Design of Experiments
4.1  Mathematical and Statistical Models
A MATHEMATICAL model is an equation that describes the relationship between two or
more variables. Mathematical models are DETERMINISTIC in the sense that if the values of
all but one of the variables in the model are known, then the value of the remaining
variable can be deduced.
A STATISTICAL model, on the other hand, is not deterministic. If the values of some of the
variables in the model are known, then the values of the other variables cannot be
computed exactly, although they can be estimated using information from a sample (Fig.
18).
PREDICTOR VARIABLE: If the value of a variable can be determined by the experimenter,
this variable is referred to as a predictor variable (e.g., organism type, light level,
temperature, or watering in plant growth experiments). Predictor variables are also
sometimes referred to as independent or explanatory variables.
59

FIGURE 18. The observations are pairs (x, y) where the predictor is denoted x and the
response variable is denoted y. The data are plotted as dots for a mathematical (a) and
statistical (b) model.
RESPONSE VARIABLE: A variable measured in the experiment whose reaction to different
levels of predictor variables is to be studied is called a response variable (e.g., height or
vigor of plants in growth experiment under different conditions). Response variables are
also sometimes referred to as the dependent variables.
Example 4.1
Most experiments collect information on several predictor variables and one or more
response variables. In a plant growth experiment, temperature, soil moisture, and light
conditions could be predictor variables, and plant height or biomass could be measured
as response variables representing vigor.
A statistical model describes the distribution of the response (y) for a particular value of
the predictor (x). The observed and recorded measurements are understood as
observations on a random variable whose distribution may change according to the
external conditions.
Here, the response y is represented as a Normal random variable with mean x2, which
depends on the predictor variable and variance σ2 = 1.
Note: The notation ϵ ~ Normal(0,1) stands for “the random variable ϵ has a Normal
distribution with parameters 0 and 1.” In general, statisticians use the symbol ~ to
express the distribution of a variable. The distribution will be identified by name
(here Normal) and the values of all parameters of the distribution will be identified.
4.1.1  Biological Models
The goal of many biological experiments is to develop an abstract model that explains a
behavior or reaction to external influences. The responses can be as simple as the growth
of plants under different light conditions or as complex as a cell cycle.
Even in very simple experiments, many other factors beyond the predictor and response
variables provide information. Data will not necessarily be collected on all of them. For
60

example, in the plant growth experiment, every plant is a different individual that may
react differently to the same stimulus. It is impossible to keep the experimental
conditions (placement on the lab shelf, soil, etc.) exactly the same. In addition, even if
the experimental conditions can be very well controlled, other variations introduced by
measurement errors or biological differences between individuals will still exist. Thus,
it is not appropriate to use a deterministic mathematical model to describe the
relationship between predictor and response variables. Instead, a statistical model is
used to describe the relationship as precisely as possible, while at the same time
allowing for random fluctuations that may be caused by factors not directly observed in
the experiment.
4.2  Describing Relationships between Variables
The purpose of a statistical model is to understand the fundamental relationship between
variables. This relationship is fundamental in the sense that it is usually not of interest to
study how a particular animal (the mouse in your lab cage) or a plant (in your laboratory)
behaves, but rather to draw conclusions that are generally valid for a particular strain of
mice or a genotype of plant. Because it is not practical or financially feasible to collect
data from all mice or all plants, a sample is randomly selected and studied. Data from
this sample are then used to choose a statistical model that, under certain conditions, is
generally valid for the extended population.
POPULATION: An organism (e.g, mouse) or a group of individuals (e.g., cancer patients)
about which you want to draw conclusions.
SAMPLE: A subset of the population from which data are collected.
61

FIGURE 19. A statistical model is fit based on data obtained from a sample. If the sample
is representative of the population, then the model can be assumed to be valid in general.
In a STATISTICAL MODEL, the response variable is represented as a function of the
predictor variable plus an error term ϵ whose distribution is known.
If the nature of the functional relationship is known, then the observations are used to
“fine-tune” the model. If the functional relationship is unknown, then the observations or
data are used to find a functional relationship that provides a good fit.
FITTING a statistical model means selecting a function that relates the predictors to the
response. This function should achieve a trade-off between being as simple as possible
and biologically meaningful in the context of the experiment while at the same time
explaining as much of the observed variation as possible in the response through the
predictors (compare Fig. 19).
Note: In general, statisticians denote unknown random quantities by uppercase
letters and observations in experiments or measurements that have already been
taken by lowercase letters. The statistical model represents the general population
(not just your measurements) and is thus usually formulated in uppercase letters.
62

Suppose it is known that the predictor variable X and the response variable Y have a
linear relationship such that if X increases by a unit quantity, Y will increase on average
by a fixed (not necessarily whole unit) quantity.
In this case, the data will be used to find the most appropriate values for the model
parameters β0 (intercept) and β1 (slope).
MODEL PARAMETERS: Generally, the function f(X) that is used to model the response Y
will depend on one or more PARAMETERS. In the above example of a linear function, the
model parameters are β0 and β1. These parameters, which describe the general
relationship between predictor and response for the entire population (not just the
sample), are numbers that are generally unknown. However, their values may be
estimated from the sample.
The estimate of a model parameter is called a STATISTIC. The value of the statistic
depends on the selection of the sample, and thus, it is itself a random variable. Usually,
model parameters are denoted by Greek letters (α, β, or σ), and their estimates, obtained
from a sample of data, are denoted by the corresponding alphabetic letters (a, b, or s).
If the functional relationship between a predictor and response is not known, then
observations may be used to decide which of several possible candidate models
provides a better fit, for example,
Once an appropriate model has been chosen, the same data may be used to obtain
estimates for the parameters in this model.
4.3  Choosing a Sample
What are the conditions under which the observations in a sample lead to a model that
can be generalized to the whole population? The general goal is to select a sample that
represents the population in as many aspects as possible. Theoretically, this goal is
achieved if the sample is taken strictly at random. However, technically, this is usually
not feasible because there are many factors that influence a population. For example,
most often, plants to be sampled are grown on the same lot and are not randomly chosen
from all possible lots.
63

RANDOM SAMPLE: Strictly speaking, random sampling means choosing a subset of a
population in such a way that every member in the population has the same chance of
being chosen for the sample. Individuals must be chosen independently of each other.
If strict random sampling is not possible, other sampling strategies exist, but it is
important to understand what the consequences of using those strategies are.
STRATIFIED SAMPLE: If a population consists of subpopulations that fundamentally differ
with respect to one aspect, then individuals can be organized by this aspect into different
STRATA. From each stratum, a sample is now selected at random with the intent of
representing the overall population as closely as possible in all other aspects.
MATCHED SAMPLING: If an experiment is intended to compare individuals which can be
classified into two (or more) distinct groups, then sometimes matched individuals are
chosen to differ in the characteristic to be studied but to be as similar as possible in all
other aspects.
4.3.1  Problems in Sampling: Bias
A BIASED sample is one that systematically over- or underrepresents individuals which
exhibit a particular characteristic of interest. Thus, the sample does not accurately reflect
the population and any estimation based on such a sample would lead to systematic
errors in estimation and erroneous conclusions drawn from the sample.
Example 4.2
Suppose a survey is conducted to determine the prevalence of a particular disease in a
human population. Selection bias would occur if the study participants were randomly
chosen from hospital patients. If an individual with the disease is more likely to be
treated than a healthy individual (for this or some other disease) in a hospital, then
hospital patients are more likely to have the disease than healthy individuals. Because
we restrict our observations to the hospital group alone, we would thus systematically
overestimate the prevalence of the disease.
Selection bias can be corrected if the nature of systematic over- or underestimation is
understood. However, in most applications, this information is not available and requires
forethought when designing an experiment.
Example 4.3
Rumor has it that a study is much more likely to be published if the results are
64

statistically significant (i.e., some effect is concluded to exist) than if the results are not
statistically significant. Despite the fact that nonsignificant results (i.e., studies where we
are reasonably sure that there is no effect) may be just as informative for the scientific
community, a publication bias exists.
Example 4.4
In certain types of microarray experiments, RNA samples are labeled with red (Cy5) and
green (Cy3) fluorescent dyes. It is known that the binding affinity of dyes varies with
genes. Suppose gene A is more likely to bind with red dye than gene B. Then, if a
treatment RNA sample is labeled with red and a control RNA sample is labeled with
green and they are hybridized on an array, the fold-change of gene A (treatment vs.
control) can be much higher than for gene  B. However, we cannot conclusively say that
the treatment is solely responsible for the differential expression of gene A. Because the
binding affinity for the two genes differs, any differential expression may also have been
caused by the dye bias. To resolve this common problem, many microarray experiments
are conducted in the form of a dye swap. A second hybridization to another array is
performed in which treatment is labeled with green and control is labeled with red. Only
the combined data from both arrays in the dye swap experiment make it possible to
separate the dye (bias) effect from the treatment effect.
4.3.2  Problems in Sampling: Accuracy and Precision
The accuracy and precision of an estimate depend on the method by which the sample is
taken. ACCURACY measures bias—unbiased samples are those with the highest accuracy.
PRECISION measures variability in the measurements (Fig. 20). If all the information from
each observation is combined, how well does this combined information reflect the
population? If the variation between observed individuals is large, the estimate will be
less accurate than if the variation is small.
65

FIGURE 20. Accuracy and precision in measuring a characteristic (bulls eye) via sample
data (black dots).
Note: An accuracy problem can be resolved by adjusting the sampling technique to
obtain an unbiased sample or by incorporating bias information (if available) into
the statistical model. A precision problem can usually be resolved by increasing the
sample size. For more information on how to select an appropriate sample size, refer
to Section 4.5.
Many experiments can contain variation, and therefore bias, from several different
sources. Not all variation is undesirable; in fact, the variation between two treatment
conditions is often the “effect” that the experiment is designed to discover. However, it is
extremely important to understand different sources of variation in order to be able to
separate the desired variation (effect) from the undesired variation (noise).
BIOLOGICAL VARIATION: This type of variation is introduced through the use of samples
from different individuals. Biological variation may be intended (differences between
the treatment and control group) or unintended (differences between individuals in the
same treatment group). Variation can only be estimated if there is replication.
BIOLOGICAL REPLICATION is defined as the repeated analysis using the same method of
samples from different individuals (grown and harvested under the same conditions).
TECHNICAL VARIATION: Even if the same material is analyzed using the same principle
method, the results cannot be expected to be exactly the same due to a variety of possible
errors in sample preparation and measurements. Statisticians refer to this as technical
variation in the measurements. TECHNICAL REPLICATION may be used to estimate this
66

variation. A technical replicate is defined as the repeated analysis of the same biological
sample using the same technique.
Example 4.5
In a microarray experiment RNA is extracted from two species/ genotypes of
Arabidopsis. Suppose two plants are selected from each species and the same type of
leaf tissue is taken from each plant under the same conditions (A1, A2 from species A and
B1, B2 from species B). In the experiment, the tissue sample from the first plant in each
species (A1, B1) is color labeled (A1 red, B1 green) and hybridized onto one array. If this
experiment were repeated with the other two plants (A2, B2) using the same color labels
and the same type of array, it would constitute biological replication. A dye swap, in
which the same biological material (A1, B1) is hybridized again onto different arrays with
different dye labels, constitutes technical variation.
If (A1, B1) tissues were, however, labeled red and green, respectively, and (A2, B2)
tissues were labeled green and red, this would constitute neither biological nor technical
variation. Even though there are two observations, we would not be able to separate the
variability introduced through different individuals from the variability introduced
through the technology (in this case, the dye labeling).
4.4  Choosing a Model
The decision of which statistical model is appropriate for a given set of observations
depends largely on the type of data that have been collected. Usually, observations are
collected on one or more predictor variables and one or more response variables per
experiment (Section 4.1). Each of these variables can be either quantitative or
categorical (Section 3.1). Listed below are four types of predictor and response variable
combinations:
QUANTITATIVE RESPONSE WITH QUANTITATIVE PREDICTORS
The statistical model for a quantitative response with one or several quantitative
predictors is called a REGRESSION MODEL (Section 7.1). A regression model can also be
fit if some (but not all) of the predictors are categorical.
CATEGORICAL RESPONSE WITH QUANTITATIVE PREDICTORS
The statistical model for a bivariate categorical response (e.g., Yes/No, dead/alive) and
one or more quantitative predictors is called a LOGISTIC REGRESSION model (Section
67

7.1.3). This model can be extended for situations in which the response variable has
more than two possible values (MULTIVARIATE LOGISTIC REGRESSION).
QUANTITATIVE RESPONSE WITH CATEGORICAL PREDICTORS
The statistical model to compare a quantitative response across several populations
defined by one or more categorical predictor variables is called an ANOVA MODEL
(Section 7.2).
CATEGORICAL RESPONSE WITH CATEGORICAL PREDICTORS
The statistical tool to record observations on categorical predictor and response
variables is called a CONTINGENCY TABLE (Section 6.2.5). It can be used to draw
conclusions about the relationships between variables.
4.5  Sample Size
According to the Central Limit Theorem (Section 3.5), the standard error for the sample
mean statistic based on a sample of size n decreases by a factor of 
 as the sample
size is increased. Larger samples lead to more accurate estimates. But how large should
a sample be in order to detect some existing effect? Although the answer depends very
much on the particular situation, there are several aspects that will influence the choice
of an appropriate sample size:
Effect size
Significance level
Variability in population
FIGURE 21. If the variability within treatment group (red dots) and control groups (white
dots) is small (a), it is easier to detect an effect of fixed size than if the variability within
a group is large. If the variability is high (b), the sample size must be large to distinguish
both groups.
68

EFFECT SIZE: The difference between the control and treatment group that you are trying
to detect. For example, do colds go away faster if you take a daily vitamin C
supplement? In this case, the effect size would be the mean difference in duration of a
cold with and without the supplement. If this difference is small (6 days without
supplement and 5.79 days with supplement), then you will need a large sample to
conclude with high statistical significance that there is a difference. If the effect size is
large (6 days without supplement and only 3 days with supplement on average), then a
much smaller sample size is sufficient to find the existing effect statistically significant.
SIGNIFICANCE LEVEL: Decisions about populations that are based on samples are always
subject to mistakes. To keep the probability of making an erroneous conclusion small,
one must be conservative before declaring an effect significant. Most often, the chance of
making a wrong decision is bounded by the threshold of 5% (even though other
thresholds can and should be used if appropriate). Depending on how certain you want to
be that the conclusion drawn from the sample is actually correct, you will have to adjust
the sample size. More accuracy in the decision requires larger samples.
VARIABILITY IN THE POPULATION: Variability of the trait in the population cannot be
influenced by the experimenter. If you are measuring a trait whose distribution in a
population is very narrow (almost everybody has the same value with very little
variation), then only a few observations are needed to draw meaningful conclusions. If
the variation of a trait in the population is high, then a larger sample size is needed to
draw the equivalent conclusion at the same significance level (Fig. 21).
Calculating exact sample sizes depends on the issues mentioned here, as well as the data
distribution and the scientific question the experiment is designed to answer. For some
examples of sample size calculations, see Chapters 5 and 6.
4.6  Resampling and Replication
We have already discussed the statistical merits of replication (Section 4.3). Replication
means collecting multiple observations under the same experimental circumstances. In a
study that includes replication, it is possible to identify sources of variation, estimate the
magnitude of variation, and include the variation in the statistical model.
Replication allows the experimenter to understand and describe the variation in the
population being studied. The statistical method of RESAMPLING is fundamentally
different from that of replication. Resampling allows one to better understand the
behavior of a statistic that is calculated based on a sample. In resampling, data points are
69

randomly selected from the available data set of size n and a model is fit based on the
selected subset. Observations may be selected with replacement; this means that the
same observation may potentially be selected more than once. This process is repeated
many times, and each time the selected data subset may differ, which will lead to
different estimates for all of the model parameters. This process makes it possible to
study the behavior (statistical distribution) of the model parameters based on only one
data set.
Example 4.6
A study has been conducted to determine the average width of hummingbird eggs. Five
eggs are selected at random and their widths (at the widest part of the egg) are measured
(in mm):
Estimating the average width of the eggs in the population based on this single sample 
 provides some information.
70

FIGURE 22. Histogram of the sample means computed for 1000 randomly resampled
subsets of data from the five original observations.
This one number, however, does not tell us how the statistic (i.e., the “sample average”)
behaves as a random variable. To learn about the distribution of a statistic, we can
resample the data (with replacement) many times to create multiple data sets of the same
size (n = 5). To study the behavior of the sample mean, we compute the estimate “sample
mean” based on each resampled data set and then look at the distribution of those
estimates. For instance, take 1000 resamples of size five from the original five
observations on hummingbird egg width:
71

Resample
Selected values
Mean
1
9.5
9.8
10.2
9.8
9.5
9.76
2
10.1 10.1
9.8
10.2 10.2 10.08
3
10.2
9.6
9.5
10.2
9.8
9.86
⋮
⋮
⋮
1000
9.8
9.6
9.6
10.1 10.1
9.84
The mean of each resample is computed. A histogram of the resulting 1000 sample means
(Fig. 22) shows the distribution of the statistic “sample mean” for these data. As a result,
not only can the average egg width be estimated, but it is also possible to attach a level
of certainty to this information.
Resampling with replacement from the original data is the simplest version of a
statistical method called the BOOTSTRAP. The purpose of the Bootstrap method is to
derive properties of an estimate (such as a sample mean) from a single sample when it is
not possible to take repeated samples from the population.
72

5  Confidence Intervals
Statistical inference means drawing conclusions from data. Confidence intervals are one
important aspect of statistical inference. In general, there is usually a population that we
want to study (e.g., humans, Drosophila, or Arabidopsis) and a sample selected from the
population. Using the sample, we want to learn more about a population parameter (e.g.,
the average reaction of humans to a drug, the average wing span of Drosophila flies, or
the percentage of Arabidopsis plants that exhibit a certain genetic marker).
In an experiment, measurements are taken on the sample (drug reaction, wing span,
genetic marker). These measurements are usually summarized in the form of a statistic
that estimates the population parameter, as well as a confidence interval that expresses
the uncertainty of the estimate.
Recall: Population parameters will in general be denoted by Greek letters (μ for mean, σ
for standard deviation) and the corresponding statistics (calculated from the sample data)
by Arabic letters (  for mean, s for standard deviation).
Due to different sample choices, the value of the statistic calculated from the data may
vary. The goal of statistical inference is to draw conclusions about the population
parameter from statistics calculated from the data. Most statistics (e.g., sample mean 
sample standard deviation s, etc.) are chosen because their values computed from data
are expected to be close to a true but unknown population parameter (e.g., sample mean
μ, standard deviation σ). But how close (Fig. 23)? Statistics can help to answer this
question. Understanding the behavior of sample statistics will allow us to quantify how
far from the true population parameter we would expect a statistic to be.
73

FIGURE 23. In most samples, the calculated value of the sample average  will be close
(but not equal) to the true unknown population mean μ. The behavior of the statistic  is
described by the Central Limit Theorem (Section 3.5).
Example 5.1
Suppose that we make n random observations on a variable that we know has a normal
distribution with unknown mean μ but known standard deviation σ = 2. In real biological
applications, population distributions and population standard deviations are very rarely
known in practice. Other methods exist to compute confidence intervals in those cases
(Section 5.2). However, this simplified example demonstrates the underlying idea behind
a confidence interval.
According to the Central Limit Theorem, the average 
 of the n observations has a
normal distribution with mean μ and standard deviation 
.
This knowledge allows us to compute the typical distance of  from μ. Of course, the
distance of  from μ is the same as the distance of μ from . Very rarely will the sample
average be very far away from the true mean μ. In fact, we can use this property of the
sample mean to conclude that the standardized distance of  and μ has a standard normal
distribution
And, we can use properties of the standard normal distribution to determine that the area
under the standard normal curve between the values -1.96 and 1.96 has area 0.95.
Combining the above two statements
74

leads to a 95% confidence interval for the population mean μ.
In practice, when the population distribution and/or the population standard deviation σ
is unknown, this confidence interval can be modified to allow for estimation of σ.
To be able to draw general conclusions about population parameters, it is necessary to
make assumptions about the data. In the previous example, it was assumed that the data
are normally distributed and that the standard deviation σ is known. Other common
assumptions are random choice of sample and large sample size. Different assumptions
on the population from which data are drawn from will lead to different formulations of
confidence intervals.
5.1  Interpretation of Confidence Intervals
The purpose of a confidence interval is to convey not only an estimate of a population
parameter, but also the quality of the estimate. In this sense, confidence intervals are very
similar to error bars that are typically used in graphical displays of quantitative data
(Section 3.7). However, the interpretation of confidence intervals is a little bit tricky.
The word confidence is not to be confused with probability. The confidence level
(typically 95%) is not a probability and rather should be understood with respect to
repeated sampling. Based on any particular sample, the confidence interval may or may
not contain the true population parameter. If samples were to be taken repeatedly and
95% confidence intervals computed based on every sample (Fig. 24), then on average,
95% of those confidence intervals would contain the population parameter.
75

FIGURE 24. Confidence intervals convey the estimate, as well as the uncertainty, when
estimating a particular population parameter (here the mean μ). The confidence level
describes the proportion of samples for which the interval will contain the true
parameter.
Note: Assume that one sample of data is collected and a 95% confidence interval
for the mean is computed based on  for this sample. It is tempting (but wrong) to
conclude that this confidence interval contains the true population mean μ with
probability 0.95. Since the true mean is an unknown but fixed number, it will be
contained in any interval with probability either 0 or 1. The confidence level (here
95%) refers to the process of repeated sampling.
Example 5.2
Many contraceptive methods are advertised by their “effectiveness.” What exactly does
it mean for a condom, for example, to be 98% effective? It does not mean, of course, that
when a condom is used a woman is 2% pregnant after intercourse. As your mother
probably told you, you cannot be a little bit pregnant! Either you are pregnant or you are
not. In fact, when reading the fine print on a particular condom manufacturer’s website,
76

you will find the definition of effectiveness: Out of 100 couples, who all have
intercourse on average 83 times a year and use condoms correctly each time they have
intercourse, on average, only two will become pregnant over the course of the year.
What does this have to do with confidence intervals? As for a confidence interval, the
effectiveness rate of 98% (confidence level) does not refer to an individual person
(sample). Every time a woman has intercourse and her partner correctly uses a condom,
her chances of pregnancy are either 0 (not pregnant) or 1 (pregnant). A confidence
interval based on a single sample either will or will not contain the true population
parameter. The effectiveness rate or confidence level can only be interpreted as a
probability over the span of many couples or samples. However, in most practical
applications, only one sample will be collected and observed. Thus, if you are a woman
who had intercourse 83 times last year with correct use of a condom every time (and you
do not pay particular attention to drastic changes in your body over the course of the
year) then at the end of the year you can be 98% confident that you are not pregnant.
5.1.1  Confidence Levels
Most confidence intervals are computed at a confidence level of 95%. This means that if
samples are taken repeatedly, then 95% of the confidence intervals based on those
samples would contain the population parameter. However, there is nothing special
about the value 0.95, and confidence intervals may theoretically be computed at any
confidence level between 0 and 1. In practice, confidence levels are typically chosen
77

between 80% and 99%. Generally, confidence levels are denoted as 1 − α. For example,
α = 0.05 for a 95% confidence level. This notation establishes a direct connection to the
significance level α in hypothesis testing (Chapter 6).
In general, a higher confidence level will make the confidence interval wider, and a
lower confidence level will make the confidence interval more narrow. The width of a
confidence interval can always be expressed as
Here, the standard error is the standard deviation of the statistic used to estimate the
population parameter (e.g., 
 for ), and the critical value is a number that depends
on both the distribution of the statistic and the confidence level.
CRITICAL VALUE: In fact, the critical value is the value on the x-axis such that the area
under the distribution between the positive and negative critical value is equal to the
desired confidence level (Fig. 25).
FIGURE 25. A critical value depends on the distribution of the statistic and the confidence
level of the confidence interval. It is the number on the x-axis such that the area under the
distribution curve between the positive and negative critical value is equal to the
confidence level.
In R Commander:  Critical values depend on the distribution of the statistic and the
confidence level 1 − α. For a normal distribution, click Distribution → Continuous
distribution → Normal distribution → Normal quantiles. Enter (1 − α)/2 for
probabilities, Mean = 0, Standard Deviation = 1, click Lower tail, and click Ok. For
t-distribution quantiles, click Distribution → Continuous distribution → t distribution
→ t quantiles. Enter (1 − α)/2 for probabilities and the degree of freedom. Click
“OK.”
The most commonly used confidence levels are 90%, 95%, and 99%. For critical values
78

for normal and t-distributions at selected sample sizes, see Table 1. All critical values
can be computed in R Commander using the commands above.
TABLE 1. Commonly used critical values for normal and t-distributions at selected
sample sizes n.
Confidence level
Distribution
90%
95%
99%
Normal
1.64
1.96
2.58
t-distribution,   n = 5
2.13
2.78
4.60
t-distribution,   n = 10
1.83
2.26
3.25
t-distribution,   n = 20
1.73
2.09
2.86
t-distribution,   n = 50
1.68
2.01
2.68
5.1.2  Precision
Which is better? A 95% confidence interval or a 99% confidence interval? The answer
depends on how much precision is required. Higher confidence level (1 − α) will result
in wider confidence intervals (less precision).
PRECISION corresponds to the width of the confidence interval. Very narrow confidence
intervals at high levels of confidence are the ultimate goal.
There are a number of factors that influence the width of a confidence interval. Their
values are usually chosen to achieve a trade off between confidence (high confidence is
good) and precision (high precision is good).
The confidence level: Making 1 − α larger means making the confidence interval
wider because both zα/2 and tα/2,n−1 increase as α decreases.
The sample size: A larger sample size n decreases the standard error and thus
makes the confidence interval narrower. Notice that increasing the sample size is
the only way to provide more precision while keeping the confidence level fixed.
The variability of the observed variable σ cannot usually be influenced by the
experimenter. Nevertheless, it has an influence on the width of confidence
intervals. Measurements that are highly variable will result in a wider (less
precise) confidence interval.
79

5.2  Computing Confidence Intervals
Theoretically, confidence intervals can be computed for any type of population
parameter as long as there is a statistic with which to estimate the parameter and the
statistical behavior of this statistic is known. By far, the most common cases in practice
are confidence intervals for population means or population proportions. For simplicity,
we focus here entirely on confidence intervals of these types.
5.2.1  Confidence Intervals for Large Sample Mean
If the sample is taken from the population at random and the sample size is large (n ≥
30), then the sample mean has approximately a normal distribution regardless of the
population distribution. The population standard deviation σ may be replaced with the
sample standard deviation s for very large samples (n ≥ 40) without changing the
distribution of .
CONFIDENCE INTERVAL: A 1 − α% confidence interval for the population mean μ is
where  is the sample mean, s is the sample standard deviation, n is the sample size, and
zα/2 is the appropriate critical value for the normal distribution (Section 5.1.1).
ASSUMPTIONS: For the above confidence interval formula to be valid, the following
conditions must hold.
The sample is chosen at random from the population (no bias).
The sample is very large (n ≥ 40).
Example 5.3
Red yeast rice has been used in China for hundreds of years in cooking and as a food
preservative. It contains small amounts of the same substance found in cholesterol-
lowering drugs. Researchers conducted a trial to investigate whether the ingestion of red
yeast rice (in concentrated capsule form) had a significant effect on the subjects’ total
LDL cholesterol levels. Fifty-two patients with slightly elevated blood cholesterol levels
were chosen for the study. None of the patients took any form of cholesterol-lowering
medication (other than the red yeast rice capsules). After a regiment of 15 weeks on the
dietary supplement, researchers observed that the average LDL levels in the 52 subjects
80

was reduced by 0.63 points (with a standard deviation of 0.4 points).
This information allows us to compute a 95% confidence interval for the average
reduction in LDL cholesterol after a 15-week regimen on the red yeast rice supplement.
Thus, we can say that we are 95% confident that a 15-week regiment of red yeast rice
will reduce the average person’s cholesterol level between 0.521 and 0.739 points.
5.2.2  Confidence Interval for Small Sample Mean
Suppose a fairly small sample (n < 40) is taken from a normal distribution. The
population standard deviation σ is generally unknown and thus needs to be estimated by
the sample standard deviation s. In this case, the quantity
no longer has a normal distribution. The additional uncertainty resulting from the
estimation of σ changes the distribution to Student’s t-distribution with n − 1 degrees of
freedom. t-distributions are shaped very similarly to normal distributions but with
slightly thicker tails. Just as the mean and standard deviation determine the exact shape
of a normal distribution (compare Section 3.4.2), the number of degrees of freedom (df)
determines the exact shape of the t-distribution. For infinite degrees of freedom (df = ∞),
the t-distribution is identical to the standard normal distribution.
As in the previous case, confidence intervals for the population mean μ can now be
constructed that rely only on estimable components. A (1 − α)% confidence interval for μ
is
Here,  is the sample mean, s is the sample standard deviation, n is the sample size, and
tα/2,n−1 is the quantile of the t-distribution corresponding to n − 1 degrees of freedom
(computed as shown in Section 5.1.1).
ASSUMPTIONS:
81

The population should be much larger than the sample (rarely a problem in the life
sciences).
The sample must be chosen at random from the population (no bias).
The observations should be taken independently of each other.
The measured trait must have (approximately) a normal distribution in the
population. This assumption can be verified by one of the procedures to check
normality presented in Section 3.4.3.
Example 5.4
Elevated counts of white blood cells in post menopausal women may be an early
warning sign for breast cancer. In a study, white blood cell (WBC) counts were
determined for six menopausal women who had recently received a diagnosis of breast
cancer but had not yet begun any treatment.
A 95% confidence interval for the average WBC count in the population of
postmenopausal women with breast cancer is
The upper range of normal WBC counts is around 7. This study finds that the population
average for postmenopausal cancer patients lies between 6.152 and 9.514 (at confidence
level 95%). This is not enough evidence to conclude that the cancer average is strictly
higher than the normal group’s average (we have no healthy patients to compare to in this
study). It is also not enough to conclude that the cancer group’s average is strictly higher
than 7 WBC counts, because the confidence interval includes that value.
To obtain a positive result, the researchers could increase the sample size in their study.
This would make 
 in the denominator larger and thus the confidence interval
narrower. Alternatively, they could also obtain WBC measurements from healthy women
as a control and compare confidence intervals for the two groups.
What was actually done in this case is that the experimenters focused solely on very high
and very low WBC counts. They obtained counts from both healthy and cancer patients
82

and compared the proportion of cancer patients in the groups with very low and very
high WBC counts. They found that the proportion of cancer cases in the group with a very
high WBC count was significantly higher than in the group with a very low WBC count.
For information on how to compute confidence intervals for proportions, see Section
5.2.3.
In R Commander:  Your data should contain a quantitative variable. Click
“Statistics,” “Means,” “Single sample t-test.” Select your quantitative variable. You
may modify the confidence level (0.95 is the default). Click “OK.”
5.2.3  Confidence Interval for Population Proportion
Consider situations where the response variable that we are interested in is not
quantitative but rather categorical. What we are interested in is the percentage of
individuals in the population who fall into a certain category. (Example: The percentage
of cancer patients in the population of postmenopausal women with very high WBC
count.)
We cannot measure the whole population, but we can take a sample of size n instead and
count the number of individuals in the sample who exhibit the trait of interest. Here, we
will denote the (unobservable) population proportion by p and the corresponding
(measurable) sample proportion by . The sample proportion is computed as
A confidence interval at confidence level (1 − α)% for the population proportion p is
Here, zα/2 is the appropriate critical value of the standard normal distribution (computed
as shown in Section 5.1.1).
ASSUMPTIONS: For the above confidence interval formula to be valid, the following
assumptions must be satisfied:
The sample must be drawn randomly and independently from a population that is
83

much larger than the sample.
The sample size must be reasonably large for the approximation to be valid. As a
rule of thumb, a sample can be considered large if it contains at least 10
individuals with the trait and at least 10 individuals without the trait.
Example 5.5
BRCA1 is a gene that has been linked to breast cancer. Researchers used DNA analysis
to search for BRCA1 mutations in 169 women with family histories of breast cancer. Of
the 169 women tested, 27 had BRCA1 mutations. Let p denote the probability that a
woman with a family history of breast cancer will have a BRCA1 mutation. Find a 95%
confidence interval for p.
Our sample estimate is 
. The standard error for  is
The confidence interval for p then becomes
Therefore, we are 95% confident that the population proportion p is between 10.5% and
21.5%.
In R Commander:  Your data should contain a categorical factor variable. Click
“Statistics,” “Proportions,” “Single sample proportion test.” Select your factor
variable. You may modify the confidence level in the options tab (0.95 is the default).
Click “OK.” The confidence interval produced will be for the population proportion
of the factor level that comes alphabetically first.
5.3  Sample Size Calculations
How large should a sample be so that a study has sufficient precision for its intended
purpose? In general, larger confidence levels lead to wider confidence intervals and
increased sample size leads to narrower confidence intervals. Sometimes it is possible
to compute how large a sample size should be in a study to achieve a confidence interval
of specified length for a specified confidence level.
84

The length of a confidence interval for a population proportion is
Specifying the confidence level fixes zα/2. Specifying the length of the confidence interval
makes it possible to solve the above equation for the sample size n
If an estimate for the population proportion is available (before the study is actually
conducted), then this number may be used for . If this estimate is not available, then the
fact that 
 may be used to choose a sample of size at least
Example 5.6
Suppose we want to conduct a study to estimate the percentage p of left-handed people
within the population of the United States. Assume that we have no preliminary data on
left-handedness and that we would like to produce a 95% confidence interval that
estimates the true population proportion of left handers within 1 percentage point (i.e.,
the length of our confidence interval for p should be no more than 0.02). How many
subjects should we include in our study?
Here, we are looking for the value of n so that 
. We do not have
any information on  from a previous study, so we have to use the approximation
Thus, we should include 9604 subjects. If we cannot afford to include this many subjects
in our study, we have to be more lenient either in the confidence level (smaller
confidence level = fewer subjects) or in our expectations on how narrow we would like
the interval estimate to be (wider interval = fewer subjects).
85

86

6  Hypothesis Testing
6.1  The Basic Principle
Hypothesis testing is an important example of statistical decision making. The goal is to
use data from a sample to investigate a claim about a population parameter. In other
words, we want to use the data to answer specific questions. The claim to be
investigated is phrased in the form of two opposing statements, the null and alternative
hypotheses.
The NULL HYPOTHESIS, usually denoted H0, is a claim about the population parameter. It
must always be formulated as an equality. In the life sciences, the null hypothesis is
usually the less exciting outcome (i.e., nothing interesting is happening). Examples
include:
The treatment has no effect, or effecttrt = 0.
The gene is not differentially expressed, or etreatment = econtrol.
The ALTERNATIVE HYPOTHESIS, denoted Ha, is the opposite of the null hypothesis. This is
usually the statement that the scientist really suspects to be true. Alternative hypotheses
may be phrased in a one-sided (< or >) or a two-sided (≠) form.
Example 6.1
Biologists want to study whether mild drought has an effect on the average height of
tomato plants compared to plant growth under ideal control conditions. They suspect that
plants grown under drought conditions will grow to be shorter than the control plants. In
this case, the null hypothesis is
and the one-sided alternative hypothesis is
87

where the population average plant height is denoted by μ.
Example 6.2
Differential expression of a gene can be tested by considering the gene’s average
expression under control and treatment conditions. The null hypothesis is that the
expression is (on average) the same under both conditions
Assuming there is no prior knowledge of whether the gene is up-regulated or down-
regulated, the alternative hypothesis is two-sided and represented as an inequality
Of course, one cannot expect that two gene expression intensities measured with any
technology will be exactly equal. The purpose of the hypothesis testing procedure is to
decide whether the variation observed in the data is consistent with the null hypothesis
(i.e., randomness) or whether the information in the data favors the alternative
hypothesis. To make this decision, statisticians use what they call a test statistic.
TEST STATISTIC: Any function whose value can be computed from the sample data, and
whose theoretical behavior (distribution) is known when the null hypothesis is true, can
be used as a test statistic. For a collection of common test statistic functions, see Section
6.2. Knowing the distribution, or behavior, of a test statistic function allows us to
determine which values are likely or unlikely in a random situation. If we observe a test
statistic value that is extremely unlikely to occur in a random situation (i.e., if the null
hypothesis is true), then we have observed evidence against the null hypothesis. In this
case, statisticians say they reject the null hypothesis in favor of the alternative.
Note: One can reject the null hypothesis (claim of randomness) in favor of the
alternative (pattern in data). However, one can never “accept” randomness because a
pattern that looks random may also have resulted from simply not searching hard
enough (not collecting enough data). Instead, we say that you “fail to reject” the null
hypothesis when there is insufficient evidence for the alternative.
There are many test statistic functions, each developed for a particular set of
88

experimental conditions and to answer a specific question. Depending on whether the
null hypothesis is based on means (or proportions) of two or more groups, a different
function will be appropriate. Although you can read more about specific testing
procedures in Section 6.2, it is important to realize that every hypothesis test can be
accomplished using five common steps.
THE FIVE STEPS OF A HYPOTHESIS TEST
1. Decide on a significance level α (Section 6.1.4).
2. Formulate the null hypothesis and alternative hypothesis.
3. Choose an appropriate test statistic (Section 6.2).
a. Know the distribution of the test statistic under H0 (common testing
procedures will always tell you what distribution to use).
b. Compute the value of the test statistic from your data.
4. Compute a p-value for your test and compare with α (Section 6.1.1).
5. Formulate a conclusion sentence that you can report in a publication.
6.1.1  p-values
p-VALUE: A number that is often reported with the conclusion of a hypothesis test is the p-
value. A p-value is the probability of observing data that are less compatible with the
null hypothesis by chance than data that are observed if the null hypothesis were true.
Figure 26 illustrates distribution curves for a test statistic under a null hypothesis with
three possible alternative hypotheses. The p-value is the shaded area under the null
hypothesis distribution curve starting at the observed test statistic value and extending in
the direction of the alternative hypothesis. If the alternative is one sided, the p-value is
the area under the curve in one tail of the distribution. If the alternative is two-sided, the
p-value is the area under the curve in both tails of the distribution.
FIGURE 26. Suppose a hypothesis test is designed to test whether some parameter θ is
equal to zero (null hypothesis). There are three possible alternatives: (a) Ha : θ > 0, (b)
89

Ha : θ < 0, and (c) Ha : θ ≠ 0. The p-value is the probability that a test statistic takes on
values less compatible with the null hypothesis than the test statistic value observed from
the data. This probability (p-value) is the shaded area under the test statistic distribution
curve for H0 in the direction of the alternative hypothesis.
The p-value can be used to decide whether or not to reject a given null hypothesis after
viewing the data. If the p-value is small, we conclude that the observed data are unlikely
to have been generated by a mechanism that conforms with the null hypothesis (i.e.,
randomness), and we reject the null hypothesis in favor of the alternative hypothesis. If
the p-value is large, we do not have enough evidence against the null hypothesis. In this
case, statisticians say that they “fail to reject the null hypothesis.” How small is small?
The p-value is compared against the significance level α (Section 6.1.4) of the test. A p-
value is small, if p < α and large if p ≥ α.
6.1.2  Errors in Hypothesis Testing
Two possible mistakes can be made in statistical hypothesis testing. A null hypothesis
may be rejected even though it is true. This is known as a Type I error. In practice, this
kind of error can be interpreted as seeing a significant effect where there is none. A
different kind of mistake is made if a null hypothesis is not rejected even though it is
false. This is known as a Type II error and corresponds to overlooking an existing effect
or missing a significant result.
Truth
Test Decision
H0 true
H0 false
Fail to reject H0 correct decision
Type II error
Reject H0
Type I error
correct decision
The significance level α of a test maintains the chance of a Type I error below a level
acceptable to the experimenter (Section 6.1.4). For example, if a result is declared
statistically significant whenever the p-value is less than α = 0.05, then there is a 5%
chance of committing a Type I error every time a test is conducted. Unfortunately,
lowering the significance level (to make Type I errors less likely) will increase the
probability of committing a Type II error. The only way to lower both Type I and Type II
error probabilities is to increase the number of observations in the sample (yes, collect
more data).
90

6.1.3  Power of a Test
The probability of correctly rejecting a null hypothesis is called the POWER of a test.
Practically, power describes a test’s ability to correctly identify an existing effect.
Because this situation is the opposite of committing a Type II error, the power can also
be expressed as 1 − β where β is the probability of a Type II error.
To compute the power of a test, one has to know the distribution of the test statistic under
an alternative hypothesis. In some testing scenarios, this is easy, but in other situations,
this can be quite complicated because the distribution of the test statistic under an
alternative does not necessarily have the same shape as the distribution of the test
statistic under the null hypothesis. If the distribution were known, then the power could
be computed by integration as the area under the alternative distribution curve beginning
at the quantile corresponding to (1 − α) away from the null hypothesis.
6.1.4  Interpreting Statistical Significance
If the p-value of a statistical hypothesis test is smaller than the significance level α of the
test, the null hypothesis is rejected in favor of the alternative. Some people find this
concept confusing because it does not mean that the alternative actually is true. Similarly,
failing to reject the null hypothesis does not prove that the null hypothesis is true.
Statistical hypothesis tests are not proofs in the mathematical sense; they are simply a
confirmation or contradiction of some prior belief. The evidence supplied via the data
against a null hypothesis needs to be convincing enough (p-value < α) before this prior
belief is abandoned.
Conventionally, the level of statistical significance is chosen to be α = 0.05. However,
there is nothing magical about this 5% number. Other meaningful significance levels may
be α = 0.01 (1%) or even α = 0.1 (10%), depending on the application. Whether or not a
result is “statistically significant” depends not only on the scientific question and the
data, but also on the researcher’s willingness to be incorrect based on a chosen level of
statistical significance. For this reason, it is preferable to publish the results of statistical
hypothesis tests as p-values rather than significant or nonsignificant decisions. p-values
contain more information and allow all readers to draw their own conclusions at a
meaningful level of significance.
6.2  Common Hypothesis Tests
In this section, we present a selection of commonly used hypothesis testing procedures.
91

In each case, the situation for which the test is designed is described and examples of
possible null hypotheses and alternatives are presented. The test statistic is stated
together with its distribution. Furthermore, the possible assumptions that need to be
satisfied for the testing procedure to be valid are listed.
Review the five steps for hypothesis testing outlined in Section 6.1. Begin by choosing a
significance level with which you want to work (Section 6.1.4). Formulate the question
you want to ask and select an appropriate null hypothesis and alternative. Depending on
the parameter in your null hypothesis (mean or proportion) and the number of populations
that you are comparing, identify an appropriate testing procedure (Table 2). The testing
procedure that you choose will tell you which test statistic function to use and what
the distribution of the test statistic function is. Compute the value of the test statistic for
your data set and obtain the p-value for your test. For many tests, there are R commands
that will skip the test statistic computation step and directly output the p-value for you.
Compare the p-value to your chosen significance level and formulate a conclusion in the
context of the question being asked.
TABLE 2. An overview of common testing procedures described in this Manual.
Population parameter of interest
Mean
Section Proportion
Section
One-sample
One-sample t-test
(6.2.1) One-sample z-
test
(6.2.2)
parameter versus a
constant
Fisher’s exact
test
(6.3.2)
Two independent
samples,
Two-independent-sample
t-test
(6.2.1) Two-sample z-
test
(6.2.2)
parameters compared
Wilcoxon-Mann-Whitney
test
(6.3.1) Permutation
test
(6.3.3)
Permutation test
(6.3.3)
Two dependent samples,
Paired-sample t-test
(6.2.1)
parameters compared
Multiple independent
samples
F-test
(6.2.3)
Tukey’s and Scheffé’s
tests
(6.2.4)
92

Permutation test
(6.3.3)
Categorical data
χ2 goodness-of-fit test
(6.2.5)
χ2 test for independence
(6.2.5)
Fisher’s exact test
(6.3.2)
The name of the testing procedure, for both the population mean and the population
proportion, is listed with Section references for easy access.
A final important part of every hypothesis test is to check that your data satisfy the
assumptions for the hypothesis testing procedure you chose. Often, these assumptions
demand a minimum sample size (which is easy to check). Other times, the assumptions
demand normality of the observations which could be checked with a PP-plot or a QQ-
plot (Section 3.4.3).
6.2.1  t-test
t-tests are among the most frequently used testing procedures in the biological sciences.
They are designed for three distinct applications:
Comparing the mean of one single population to a fixed constant.
Comparing the means of two independent populations to each other.
Comparing two dependent measurements (e.g., before and after measurements on
the same individuals).
We consider these three different applications separately.
One-sample t-test
The one-sample t-test provides a test of whether the mean μ of a population is equal to a
prespecified constant value μ0. Most often, this value is μ0 = 0 but not always. Select an
appropriate significance level α for your application. The decision will be based on data
from a single sample of size n, where  denotes the mean of the sample and s denotes the
sample standard deviation.
HYPOTHESES:
93

The null hypothesis is that the population mean μ is equal to μ0. The alternative
hypothesis states that the population mean is either larger, smaller, or generally not equal
to μ0. Which alternative hypothesis should be used depends on the application.
TEST STATISTIC:
Here, the test statistic has a t-distribution with n − 1 degrees of freedom.
In R Commander:  To conduct a one sample t-test, click “Statistics,” “Means,” and
select “Single-sample t-test.” Select the variable for which you would like to conduct
the test, and the form of the alternative hypothesis. Here, μ0 (mu0) is the hypothesized
population mean. You will obtain a p-value for the test, as well as a confidence
interval for the population mean μ.
ASSUMPTIONS:
The sample must represent the population (no bias).
Either the data need to be approximately normally distributed or the sample size
needs to be large (n > 30).
Two-Sample t-test
For two independent populations, the two-sample t-test decides whether or not the
population means μ1 and μ2 are equal. The decision is made by considering data from
samples of size n1 and n2 (not necessarily equal). Let 
 and 
 denote the sample means
and s1 and s2 the sample standard deviations of the two samples, respectively. Choose an
appropriate significance level α for your application.
HYPOTHESES:
TEST STATISTIC: There are two different test statistics that are used to perform a two-
sample t-test depending on whether or not you assume the two population variances to be
equal. If the populations are assumed to have equal variance (homoscedastic), use
94

If, on the other hand, the two samples cannot be assumed to have been taken from
populations with equal variances (heteroscedastic), use the test statistic
In R Commander:  To conduct a two-sample t-test, write your numerical data in one
column and the corresponding group labels in a second column. The group label
variable needs to be a factor (see Section 2.8.2). Click “Statistics,” “Means,” and
“Independent samples t-test.” Select the group label variable and the numerical
response. Under the “Options” tab, the alternative hypothesis, confidence level, and
form of test (homoscedastic or heteroscedastic) may be specified.
ASSUMPTIONS:
The samples must be independent and represent the unique populations from which
they are taken (no bias).
The data need to be normally distributed in both samples or both sample sizes (n1
and n2) must be large. Two-sample t-tests are quite robust, which means that
sample sizes can be as small as n1 ≥ 5 and n2 ≥ 5 if the departure from normality is
not drastic.
For two populations with nonnormally distributed data, but with equal variance, there is
a non-parametric alternative (i.e., no distribution assumptions are placed on the data) to
the homoscedastic two-sample t-test. It is called the Wilcoxon-Mann-Whitney test
(Section 6.3.1). This test can be applied to samples of any size, but it is not very
powerful for extremely small samples. For moderate-sized samples (n ≥ 10) with equal
variances, a two independent sample t-test can also be replaced by a permutation test
(Section 6.3.3).
Paired t-test
95

The two sample t-test relies on data from two independent populations. In many cases,
independence is not a meaningful assumption. For instance, measurements may be taken
repeatedly on the same individuals under different treatment conditions. To test whether
the mean measurements under both conditions are the same, consider the n dependent
pairs of observations and compute differences 
, where 
 is the
observation on individual i under treatment 1 and 
 is the observation on the same
individual under treatment 2. Let d denote the sample mean of the differences and sd the
sample standard deviation of the differences.
HYPOTHESES:
TEST STATISTIC:
ASSUMPTIONS:
Even though the measurements on the same individual are not assumed to be
independent, the n individuals should be chosen independently and represent the
population from which they are chosen.
Either the two repeated measures should be normally distributed or the number of
individuals n must be large (n > 15).
In R Commander:  To conduct a paired t-test, write your numerical data in two
columns with paired observations in the same line. Click “Statistics,” “Means,” and
“Paired t-test.” Select the two variables to compare. Under the “Options” tab, the
form of the alternative hypothesis and the confidence level may be specified.
Example 6.3
Male Drosophila have some of the longest sperm cells among all the organisms on earth
(including humans). However, the length of the sperm varies by breed. Do males of the
species Drosophila melanogaster (the so called fruit fly) and Drosophila simulans
differ significantly with respect to the length of their sperm cells?
96

We follow the five step procedure outlined in Section 6.1. An experiment has produced
n1 = 15 observations on D. melanogaster sperm. The cells have an average length of 
 mm with standard deviation s1 = 0.12 (that is ~300 times the length of human
sperm cells). There are n2 = 16 observations on D. simulans sperm with average length 
 mm and standard deviation s2 = 0.09.
1. Select significance level α = 0.05.
2. Our null hypothesis is that the average sperm lengths for D. melanogaster and D.
simulans are equal. Assuming that we have no prior information about the flies,
we use the alternative hypothesis that the sperm lengths are not equal.
3. Even though the sample standard deviations are not equal (0.12 and 0.09), it is
still reasonable to assume that the population variances are equal (as a rule of
thumb, check whether the larger sample standard deviation is no more than twice
the smaller). Hence, we will use a two-independent-sample t-test with the equal
variance assumption.
4. If you had the complete data set, you could enter it into a text (e.g., “*.txt”) file,
import data, and follow the R Commander instruction above to perform a two-
sample t-test with a two-sided alternative and homoscedastic variance assumption
to directly compute the p-value.
If you do not have the complete data set, but only the summary statistics that are
provided, compute the test statistic value by hand
and then compute the p-value for this test using the R Commander command
The result is p = 1.56 × 10–16.
5. This p-value is much smaller than α (= 0.05); therefore, we reject the null
hypothesis and instead state that the data contain enough evidence (p = 1.56 × 10–
16) to conclude that the average sperm lengths are different.
97

We do not have to check the data for normality (e.g., with a QQ-plot) because both
samples are reasonably large (n > 10).
6.2.2  z-test
The z-test compares one or more population proportions (e.g., the percentage of patients
who experience a heart attack while on an exercise regimen compared to a control
group). To compare one population proportion to a constant, or to compare two
population proportions to each other, a sample is selected from each population, and the
sample proportion  is calculated as the percentage of individuals in the sample who
exhibit the trait. As in the case of the t-test, the z-test exists as a one-sample form and a
two-sample form.
One-sample z-test
The goal of this procedure is to decide whether or not a population proportion p is equal
to a predetermined constant p0. Suppose a sample of size n is selected from a large
population and the sample proportion 
 of individuals that exhibit some trait is
observed.
HYPOTHESES:
TEST STATISTIC:
ASSUMPTIONS:
The population should be much larger than the sample (rarely a problem in the life
sciences) and the sample must represent the population (no bias).
The sample size must be large enough so that np0 ≥ 10 and n(1 – p0) ≥ 10.
Essentially, the sample should contain at least 10 observations of each type (e.g.,
with and without the trait).
For smaller samples, an alternative nonparametric test (i.e., no distribution assumptions
98

are placed on the data) exists. It is called Fisher’s exact test (Section 6.3.2).
In R Commander:  Import your data as a factor variable with exactly two levels
representing successes and failures (see Section 2.8.2). Click “Statistics,”
“Proportions,” and “Single-sample proportion test.” Select the factor of interest.
Under the “Options” tab, the form of the alternative hypothesis may be specified. The
value of p0 that may be entered will be interpreted by R as the hypothesized
proportion of the label that comes alphabetically first. Click “OK.”
Example 6.4
A group of fruit flies is conditioned to associate the color red with food. 42 flies were
exposed to a maze with two possible options: One path is colored red and the other
green. 28 flies chose the red option and the remaining 14 chose green. The hypothesis
under investigation asks whether the conditioning worked. Is the number of flies who
chose the red option larger than we would expect by chance?
1. Select significance level α = 0.05.
2. Let p be the proportion of conditioned flies in the population (not just the flies in
our experiment) who choose red when presented with the two options. If the
conditioning does not work, we would expect half of the flies (p = 0.5) to choose
either option. If the conditioning worked, then more than half of the flies will
choose red.
3. The value of the test statistic for this experiment is
The test statistic has a standard normal distribution, Normal(0,1).
4. Find the p-value of this one-sided test by computing the right tail area under the
standard normal distribution to the right of z = 2.16 using the R Commander
command pnorm(2.16, lower.tail= FALSE). The resulting p-value is p =
0.0154.
99

5. This p-value is small (p < α); therefore, we reject the null hypothesis and conclude
that the conditioning worked on the flies.
The assumptions are satisfied, since (42)(.5) = 21 ≥ 10 and (42) (1 – .5) ≥ 10. There
were at least 10 flies who chose either option in the experiment.
Note: Suppose this same test would have been conducted with R-Commander where
the data were entered as a factor variable with levels “red” and “green.” Because
“green” comes alphabetically before “red,” R Commander will consider the “green”
outcome as the success. That means that the alternative hypothesis must be specified
in the p < p0 form. No change is necessary for the constant p0 since 1 – 0.5 = 0.5. If
p0 would have had some other value, then the entered value should have been
changed accordingly.
Two-sample z-test
Independent samples of size n1 and n2, respectively, are drawn from two populations and
the proportion of successes is determined in each sample. The question of interest is
whether or not the proportions of successes in both populations are the same.
HYPOTHESES:
TEST STATISTIC: Let 
 and 
 denote the sample proportions. Furthermore, let  denote
the combined relative frequency of successes for both samples.
ASSUMPTIONS:
Both samples must be chosen independently of each other and should represent
their respective populations (no bias).
The number of successes and failures in both samples should be at least 5.
100

In R Commander:  Import your data as two factor variables with the same two levels
representing successes and failures (see Section 2.8.2). Click “Statistics,”
“Proportions,” and “Two-sample proportions test.” Select the factors of interest.
Under the “Options” tab, the form of the alternative hypothesis may be specified. Note
that the alternative hypothesis should refer to the “Difference” specified by R. Click
“OK.”
Example 6.5
An experiment is designed to study a candidate gene for alcoholism in mice. 27 field
mice and 25 knockout mice for the candidate gene are both offered spiked and virgin
drinks. 18 of the field mice and 12 of the knockout mice chose the spiked drink. Is this
enough evidence to conclude that the candidate gene is linked to the drink preference of
the mice?
1. Choose significance level α = 0.05.
2. Let p1 be the population proportion of field mice (not only those in our lab) that
would choose the spiked drink and let p2 be the population proportion of knockout
mice that would choose the spiked drink. The null hypothesis and alternative are
3. From the sampled data, the combined success frequency is
The value of the z-test statistic is
The test statistic has a standard normal distribution, Normal(0,1).
4. The p-value is the right tail area of the standard normal distribution (in this case,
the area to the right of z = 1.361). It can be computed using the R command
pnorm(1.361, left.tail = FALSE). The p-value for this example is 0.0867.
101

5. This value is large (compared to α = 0.05). Thus, we fail to reject the null
hypothesis and conclude that these data do not provide enough evidence to state
that the candidate gene is linked to the drinking preference of mice (i.e., there is no
evidence that field mice have a higher population proportion of drinkers than the
knockout mice).
The assumptions are satisfied because there are 18 successes and 9 failures in the field
mouse (control) group and 12 successes and 13 failures in the knockout group.
6.2.3  F-test
Recall that the two-sample t-test is used to decide whether or not the means of two
populations are equal. In some experimental situations, more than two experimental
conditions are considered. The F-test is used to decide whether the means of k
populations are all equal. The opposite of this statement is that at least one of the
populations has a mean different from that of the others.
HYPOTHESES:
TEST STATISTIC: The test statistic used for the F-test compares the variation within the k
groups to the variation among the means of the k groups. Let xij denote the jth observation
from population i (j = 1, 2, …, ni) and let 
 denote the average of the observations from
population i. Let n = n1 + ⋯ + nk denote the total sample size and  the (grand) average
102

of all n observations.
If the variation among the means is large compared to the variation within the groups, the
F-test statistic is large. In this case, the corresponding p-value is small and the null
hypothesis of equal means is rejected.
In R Commander:  An F-test is carried out using a method that is also known as a
one-way analysis of variance (ANOVA) (see Section 7). Import your data in two
columns. One column contains the numerical response observations and the other
column contains a factor variable that labels the populations from which each
observation came (see Section 2.8.2). Click “Statistics,” “Means,” and “One-way
ANOVA.” Identify your group label factor variable and the numerical response. Click
“OK.” The p-value for the F-test will appear in the Pr(>F) column of the output
summary table. R also computes response means, standard deviations, and sample
sizes for the response in each group.
Example 6.6
For examples on the application of the F-test, please see Sections 7.2.1 and 7.2.2.
6.2.4  Tukey’s Test and Scheffé’s Test
Once an F-test provides evidence of a difference among the k population means, it is
desirable to determine which population means actually differ. Two methods, named
after their inventors, Tukey and Scheffé, can be used. Tukey’s test is available via R
Commander. Scheffé’s test is available in R, but not through the commander interface.
Tukey’s method performs pairwise comparisons of the k means (comparing each
population to every other population separately). This method is preferable when only
pairwise comparisons of means are of interest. For each comparison, Tukey’s method
tests whether or not the two population means differ. This may seem similar to
conducting many two-sample t-tests, but it is not the same. Because all possible
comparisons of pairwise means are made, the number of pairwise comparisons is taken
103

into account so that the overall chance of making an error (among all comparisons) is
controlled by the significance level, or the investigator’s willingness to be incorrect.
In R Commander:  If the box labeled “Pairwise comparison of means” is checked in
a “One-way ANOVA” analysis, R will produce results of Tukey’s test. For each pair
of populations, the mean difference in the response is listed together with its standard
error, test statistic, and p-value. The p-values may be used to decide which population
means differ significantly.
Scheffé’s method is designed to draw conclusions about linear combinations of group
means. For example, after the F-test has concluded that three groups do not have equal
means, one could ask whether the means of groups one and two are the same, and
whether the mean of group three is twice as large as those of groups one and two.
Example for Sheffé: H0 : μ1 = μ2 and μ3 = 2μ1 = 2μ2.
6.2.5  χ2-test: Goodness-of-Fit or Test of Independence
The χ2-test is used in two different applications.
A “goodness-of-fit” application tests whether data have been generated by a
specified mechanism.
A “test of independence” application tests whether two observed factors occur
independently of each other.
Data for a goodness-of-fit test are observations on one categorical variable, whereas for
a test of independence data is collected on two categorical variables (Section 3.1). For
two categorical variables, the data are most often organized in the form of a
CONTINGENCY TABLE where the rows and columns are labeled with the values that the
two categorical variables assume. The cells of the table total how many observations of
each particular variable combination were observed in the sample.
In R Commander:  Click “Statistics,” “Contingency tables,” and “Enter and analyze
two-way table” to create a contingency table. Specify the number of rows and columns
of your table, and type in your data. You can change the row and column labels as
appropriate.
104

Example 6.7
Suppose in a population of fruit flies the observed variables are eye color (red or
brown) and gender (male and female). Eye color and gender are recorded for each fly.
The resulting contingency table has two rows and two columns. For example, the cell
corresponding to red eye color and male gender will contain the number of male fruit
flies with red eyes that were observed in the vial.
Goodness-of-fit test
Consider the case where observations on two categorical variables have been recorded
in a contingency table. A model has been formulated for the occurrence of different factor
combinations, and it is of interest to determine whether or not the observed data conform
to the hypothesized model (e.g., segregation of genes).
TEST STATISTIC: The goodness-of-fit χ2-test statistic compares the observed counts to
counts that one expects to see if the hypothesized (or expected) model is indeed correct.
Here, k denotes the number of levels for your categorical variable.
ASSUMPTION:
The distribution of the test statistic is approximately χ2 distributed if the expected
counts are large enough. Use this test only if the expected count for each level is ≥
5.
In R Commander:  The data should be imported in the form of a factor variable (see
Section 2.8.2). Click “Statistics,” “Summaries,” “Frequency distributions....” Select
the variable for which you would like to perform the goodness-of-fit test. Click “OK.”
Enter the hypothesized probabilities for each category (these probabilities need to add
to one). Click “OK.”
Example 6.8
In dihybrid corn, different combinations of genes may lead to the following phenotypes:
purple/smooth, purple/shrunken, yellow/smooth, yellow/shrunken. The four phenotypes
105

are produced by two pairs of heterozygous genes, located on two pairs of homologous
chromosomes. According to Mendelian genetics, one would expect the following ratio of
phenotypes: 9:3:3:1 (i.e., the hypothesized model).
For one ear of corn with 381 kernels, each kernel has been classified as either smooth or
shrunken and as either purple or yellow. The results are listed in the contingency table
below:
Observed Smooth Shrunken Total
Purple
216
79
Yellow
65
21
Total
381
1. Use significance level α = 0.05. Enter the count data directly into R
data <– c(216, 79, 65, 21)
2. Enter the probabilities expected under the Mendelian model
prob <– c(9/16, 3/16, 3/16, 1/16)
3. Conduct the χ2 goodness-of-fit test
chisq.test(data, p=prob)
to obtain a p-value of p = 0.6311.
4. Because the p-value is large (compared to significance level α = 0.05), the data do
not supply evidence to reject the hypothesized Mendelian model. Note that the test
assumptions are satisfied, because all expected counts are ≥ 5.
χ2-test for independence
When working with one population, it may be of interest to ask whether two factors are
independent. Consider observations on two categorical factors that have been recorded
in a contingency table.
HYPOTHESES:
TEST STATISTIC: If the two observed factors are indeed independent, then expected counts
106

for each factor combination can be obtained by considering count totals and multiplying
row and column totals of a contingency table.
The test statistic for independence using a χ2-test is the same as the one for the goodness-
of-fit test.
Here, r stands for the number of rows and c stands for the number of columns in the
contingency table.
ASSUMPTION:
The distribution of the test statistic is approximately χ2 if the expected counts are
large enough. Use this test only if the expected count for each cell is ≥ 5.
For 2 × 2 tables, Fisher’s exact test provides a nonparametric alternative (i.e., no
distribution assumptions are placed on the data) for the case that the sample sizes are
small (see Section 6.3.2).
In R Commander:  If the data are available in the form of two factor variables, click
“Statistics,” “Contingency table,” “Two-way table,” and select the two factor
variables. Click “OK.” If the data are available in already summarized frequency
form, click “Statistics,” “Contingency table,” and “Enter and analyze two-way table”
to enter the data. Under the “Statistics” tab, you may choose whether to conduct the χ2
test for independence (default) or Fisher’s exact test.
Example 6.9
In a vial of 120 fruit flies, an experimenter counts 55 male (and thus 65 female) flies. 24
of the male and 38 of the female flies have red eyes. All other flies have brown eyes.
The question under investigation is whether gender and eye color are genetically linked.
The contingency table for these data is:
107

Observed Red Brown Total
Male
24
31
55
Female
38
27
65
Total
62
58
120
1. Use significance level α = 0.05.
2. The null hypothesis is that the traits for gender and eye color are genetically
unlinked (or, independent) versus the alternative hypothesis that the traits are
linked. The p-value for a χ2 test of independence is 0.1054. (The p-value for
Fisher’s exact test is 0.1424.)
3. Because both of these values are large (compared to α = 0.05), we fail to reject
the null hypothesis and conclude that gender and eye color are independent or
genetically unlinked.
6.2.6  Likelihood Ratio Test
A likelihood ratio test compares two different statistical models to each other for the
purpose of deciding which of the two models better describes the given set of
observations. A likelihood is the chance, or probability, of observing a given set of
observations under a specified probability model.
Example 6.10
Suppose data are generated by crossing two F1 hybrids and phenotyping the F2 offspring.
Among 40 F2 progeny, 25 appear to be wild type (wt) and 15 mutant. Investigators
compared two inheritance models. In one model, they would expect a 3:1 ratio of wild
type to mutant phenotypes, and in the other model, they would expect a 1:1 ratio of
phenotypes. A choice is made by considering the likelihoods of both models given the
information provided by the data. In both cases, the likelihood can be computed by using
a Binomial probability model (Section 3.4.1).
Both of these models have the same structure, but they differ in the value of the parameter
108

p = proportion of wild type. A direct comparison of the likelihoods concludes that it is
more likely that the inheritance model is 1:1 (since 0.0363 > 0.0282).
In many cases, one of the two models to be compared is more complex (i.e., has more
parameters) than the other, and the simpler model is a subset of the complex one. The
models should have the same general structure and differ only through additional
parameters in the more complex model. The model that has more parameters will always
have higher likelihood because it has improved explanatory power over the simpler
model. However, there is a trade-off between simplicity of the model and increasing
likelihood. Specifically, simpler models are generally easier to explain in a biological
background.
TEST STATISTIC: If the sample size is large (n > 30), then the distribution of the likelihood
ratio test (LRT) statistic is approximately a χ2 distribution.
Here, L0 is the likelihood of the observations under the null hypothesis and La is the
likelihood of the observations under the alternative hypothesis. The degrees of freedom
for the χ2-distribution of the test statistic is the difference in parameter number between
the two models.
In R Commander:  To compute a p-value for a likelihood ratio test statistic in R,
type pchisq(LRT, df, lower.tail=FALSE), where LRT is the value of the
likelihood ratio test statistic, and df is the degrees of freedom.
LOD SCORES: When assessing genetic linkage, results are sometimes formulated in the
form of log-odds (LOD) scores. Similar to the LRT statistic, the LOD score compares the
likelihoods L0 of a null hypothesis model (no linkage) with an alternative model La
(linkage).
In general, LOD scores are easier to interpret than likelihood ratio test statistics. For
instance, a LOD score of 2 means that the linkage model is 100 times more likely than the
no-linkage model given the information provided in the data.
109

Note: A LOD score and the LRT statistic for the same null hypothesis and alternative
are closely related. In fact,
6.3  Non-parametric Tests
Many statistical tests are based on assumptions that are placed on the population from
which the sample or data are drawn. For instance, the test statistic function used for a
two-sample t-test (Section 6.2.1) only has a t-distribution if the data from both
populations are normally distributed. If this is not the case, then the sample sizes need to
be large so that the sample means will have at least approximate normal distributions
according to the Central Limit Theorem (Section 3.5).
In many biological applications, the behavior, or distribution, of the observations may be
unknown because there may be little prior knowledge about the populations in an
experiment. Additionally, sample sizes are often not large enough for the Central Limit
Theorem to be effective.
NON-PARAMETRIC TEST: A testing procedure that does not make any distribution
assumptions about the population from which the data are taken is called NON-
PARAMETRIC. Non-parametric tests still make assumptions (such as equal variance
assumptions, for instance), but they do not require knowledge of the distribution of the
population.
Non-parametric alternatives exist for most of the commonly used statistical testing
scenarios that require population distribution assumptions. Although the main advantage
of the non-parametric methods is that their assumptions are less restrictive, the downside
is that they are more tedious to compute when compared with conventional (parametric)
procedures. If the data do satisfy the distribution assumptions of the conventional
procedures, then the conventional procedures have more statistical power (Section
6.1.3) than their non-parametric counterparts. If the sample size is large, then there is
usually little difference in the statistical power between the parametric and
corresponding non-parametric procedure.
6.3.1  Wilcoxon-Mann-Whitney Rank Sum Test
110

This non-parametric alternative to the two-independent sample t-test can be used to
decide whether two population means are equal based on samples from both
populations.
TEST STATISTIC: Suppose that the samples drawn from the two populations have sizes n1
and n2, respectively. The observations in the samples are ranked regardless of the
population to which they belong, and the ranks for each population are added. Let R1
denote the rank sum of observations from population one (you could also use population
two, it does not matter).
In R Commander:  Your data should contain one numeric response variable and a
factor variable containing the group labels. Click “Statistics,” “Nonparametric tests,”
and “Two-sample Wilcoxon test.” Identify your grouping factor and the response. You
can specify the alternative hypothesis under the “Options” tab. Click “OK.”
ASSUMPTIONS:
This test is non-parametric. It makes no assumptions on the distributions of the
populations from which the samples are drawn.
However, to be good representatives of their respective populations, both samples
must be unbiased and have reasonably large sample sizes.
Example 6.11
Two strains of Drosophila, D. melanogaster and D. simulans, are compared with
respect to the number of mature eggs in female ovaries for the purpose of studying
reproductive efforts. Four females from each strain are dissected and mature eggs
counted. The results are:
We want to decide whether or not the number of mature eggs carried by females of the
111

two species are on average the same.
1. Use significance level α = 0.05.
2. The null hypothesis is that the species do not differ in number of eggs (means and
variances are the same) with the two-sided alternative that the species differ.
3. The eight observed egg counts are recorded in one column. Population labels
(melanogaster = m) and (simulans = s) are recorded in a second column.
4. Conduct the Wilcoxon test in R Commander at the default settings with a two-sided
alternative hypothesis. R will report a p-value of 0.3807. There is a warning,
because there were ties in the data (the number 6 appears twice in the D.
melanogaster samples. Instead of an exact p-value, R reports a value based on a
normal approximation instead.
5. The p-value is larger than the significance level α. Hence, we fail to reject the null
hypothesis and conclude that the average egg number for both strains is the same.
6.3.2  Fisher’s Exact Test
Fisher’s exact test is a non-parametric test for independence. It accomplishes the same
thing as the χ2-test for independence in the special case when sample sizes are small and
the contingency table has dimension 2 × 2. The χ2-test for independence itself does not
make any distribution assumptions and is thus a non-parametric test. Because the χ2-test
requires large sample sizes, Fisher’s exact test may be used as a (less powerful)
alternative when sample sizes are small.
For a 2 × 2 contingency table with possibly low observed and/or expected counts, we
want to decide whether one treatment is preferable to another. Note that this is equivalent
to asking whether there is an association between treatment and outcome.
Treatment 1 Treatment 2 Row total
Outcome 1
a
b
a + b
Outcome 2
c
d
c + d
Column total
a + c
b + d
n = a + b + c + d
TEST STATISTIC: Using a combinatorial approach, we compute the probability of
obtaining more extreme data by chance than the data observed if the row and column
totals are held fixed. For example, the probability of randomly observing the same
outcome as the one in the table is
112

Here, 
 for instance, is the binomial coefficient introduced in Section 3.4.1. If we
shift the observations in the table one by one so that they more strongly support the
alternative, while holding the row and column totals fixed, we create a series of new
tables. For each shift in observations, and each new table, the probability of obtaining
more extreme data than by chance can be calculated. If the probabilities for each table
are added, this number is the p-value of the test. If there are too many representations of
the data to consider, an alternative approach to Fisher’s exact test is the permutation test.
ASSUMPTIONS:
Both samples must represent the populations they have been drawn from (no bias).
There are no assumptions on distributions or sample sizes for this test. However, if
the sample sizes are very small, then the power of the test will be very low.
In R Commander:  Your data should contain two categorical variables. Click
“Statistics,” “Contingency tables,” and “Two-Way Table.” Select the row and column
variables for the contingency table; for the test of independence, it does not matter
which one is which. Under the “Statistics” tab, select “Fisher’s exact test” and click
“OK.” Alternatively, you can also directly type in your data into a 2 × 2 contingency
table.
Example 6.12
Root rot is a common disease that befalls trees in the United States. A fungus infects the
trees and rots their roots, eventually killing the tree. In a small urban park, researchers
counted infected and healthy trees. The park has 12 plane trees of which 11 were found
to be infected, and 8 ash trees of which only two were infected. Clearly, plane trees tend
to be more infected than ash trees. But can the relationship between root rot and tree type
be quantified with a p-value?
113

Infected Healthy Total
Plane
11
1
12
Ash
2
6
8
Total
13
7
20
The null hypothesis of Fisher’s exact test is that root rot and tree species are
independent. It is possible that of the 13 infected trees in the park, 11 (or more) were
plane trees (just by random chance), even if the fungus befalls both tree species with
equal probability. In fact, the probability that the infection pattern of the trees is exactly
as observed is
A p-value is the probability of observing extreme data by chance if the null hypothesis
were true. In this example, more extreme data would be considered as even more
infected plane trees and fewer infected ash trees.
Infected Healthy Total
Plane
12
0
12
Ash
1
7
8
Total
13
7
20
The probability of this outcome is
It is not possible to make the data even more extreme while keeping the row and column
totals fixed. Thus, the p-value for the null hypothesis of no association is
Because this value is small (< α = 0.05), we reject the null hypothesis and conclude that
there is an association between fungus infection and tree species.
6.3.3  Permutation Tests
114

If the null hypothesis represents the situation where there is absolutely no difference (in
mean, variance, or distribution) between two populations, then observations from the
two populations are entirely interchangeable. Without making assumptions on what the
distributions are (only assuming that they are the same), the distribution of a test statistic
can be obtained by considering many different permutations of the observed data and
computing a test statistic for each permuted data set. Permuting the observations can also
be thought of as randomly reassigning group identification labels. For example, for
sample size n, there are n labels or indices. If all labels or indices were placed in a hat,
drawn without replacement, and assigned at random to the observations, this would be
one permutation of the data. One can imagine producing many permuted data sets by
repeating this process.
Theoretically, any function that represents the difference in sample means can be
considered for this purpose. However, conventional tests (e.g., the two sample t-test test
statistic) are typically used. For complicated test statistics and large sample sizes,
computations can quickly become very time intensive (millions of possible permutations
must be considered). If the number of possible permutations becomes excessive (there
are already 184,756 ways to permute 10 treatments and 10 controls), a random subset of
possible permutations may be considered instead. Statisticians call this method MONTE
CARLO. The only restriction on permutation tests is that under the null hypothesis, the
distributions (both in location and in shape) of the populations must be equal. If two
populations have unequal variances, for instance, the individuals cannot be randomly
permuted.
Once the permuted data sets are created and a test statistic computed for each data set,
the resulting test statistic values are ordered (or ranked) from smallest to largest, and the
(1 – α)% cutoff value is identified as the (1 – α)th percentile of the ordered permutation
test statistic values. The test statistic value, as calculated from the original data, is
compared to this cutoff value. If the test statistic from the original data is greater than the
cutoff value obtained from permuting the data, then the null hypothesis of no association
(or randomness) is rejected in favor of the alternative hypothesis.
Example 6.13
Cell cultures are grown both in standard medium and in medium supplemented with α-
tocopherol (vitamin E). For each plate, the number of cell divisions is counted after a
predetermined time. To investigate whether the average growth is the same under both
conditions, a permutation test is performed. The data consist of six observations on
115

standard medium and four observations on medium supplemented with vitamin E.
Standard medium
45
110 63 55 67 75
Vitamin E medium 100
60
72 51
Because the null hypothesis is that the means for both treatments are the same and it is
reasonable to assume the distributions to have the same shape and same variance, a
permutation test may be performed. There are 
 different ways to reorder the
ten observations into two groups of size 4 and 6, respectively, and thus 210 resulting test
statistics that represent the distribution of the test statistic under the null hypothesis.
Group 1
Group 2
Original
45 110
63 55 67
75 100
60
72
51 69.167 70.75
Permutation 1
75
67
55 72 45
63 110
60 100
51 62.833 80.25
Permutation 2
72
55
60 51 45 110
63
75
67 100 65.5
76.25
Permutation 3
60
45
63 55 67
51 110 100
72
75 58.833 89.25
⋮
Permutation 210 72 110 100 67 63
45
75
51
55
60 76.167 60.25
To compare the means of the two groups, we use the test statistic function from the two-
independent sample t-test with equal variance assumption.
Unlike in a t-test, however, we will make no prior assumptions on the distribution of this
test statistic. Rather, we compute the 210 test statistic values arising from all possible
permutations of the data and use their distribution (Fig. 27) to derive a p-value for the
original set of observations.
116

FIGURE 27. For each permutation of observations, the group means and standard
deviations are recomputed. Based on these statistics, the test statistic value is
recomputed for each permutation. The permutation test statistics are graphed in the form
of a histogram. The p-value of the test is the percentage of test statistics more extreme
than the one observed in the original data.
For the original set of observations, the value of the test statistic used here is –0.111. The
p-value for the permutation test is the percentage of permuted samples for which the test
statistic value is more extreme (smaller than –0.111 or larger than +0.111). Because this
number (p = 0.914) is large, we fail to reject the null hypothesis that the two treatment
means are equal.
Note: If the number of possible permutations is very large, then it is not necessary to
actually compute all possible permutations. Instead, it is sufficient to compute a large
(≥ 1000) number of random permutations or randomly select a large number of all
possible permutations. This method is commonly referred to as the MONTE CARLO
117

method.
6.4  E-values
Some biological applications, most prominently BLAST, return a quantity called an E-
VALUE in addition to, or instead of, a p-value. What is the difference in meaning between
an E-value and a p-value? “E” in this case stands for “expect” and represents the
average number of hits, or matches, in a given database with a score bigger than or equal
to that of the query. The null hypothesis in a BLAST search is that the query is a random
(DNA) sequence with no match in the database. A score is computed for every pairwise
comparison between the query and candidate sequences from the database. Two
sequences with a high degree of similarity will receive a high score.
A BLAST search returns the top matching sequences from the database together with an
E-value for each match. The E-value counts how many sequences in the database one
would expect to see receive scores exceeding the observed one in a random matching.
This quantity also takes the size of the database into account. It is easier to interpret the
difference between E-values of 5 and 10 (5 or 10 expected random matches in the
database) rather than interpreting the difference between p-values of 0.99326 and
0.99995. Large E-values mean that one would expect to find many random matches in the
database and that it is hence doubtful that the result is a true match.
Note: E-value and p-value are related through the equation
For very small values (E < 0.01) E- or p-values are virtually identical.
118

7  Regression and ANOVA
In many experiments, several variables are observed simultaneously with the goal of
learning more about their relationships. Some of these variables may be specified by the
experimenter (e.g., treatment and control conditions or choice of organisms involved in
the experiment) and some may be observed as reactions. Generally, variables that can be
varied by the experimenter (e.g., strain of organism, growth conditions, treatments, etc.)
are referred to as EXPLANATORY or PREDICTOR variables. Variables that are measured or
observed as reactions are referred to as RESPONSE variables if they are of primary
interest or as explanatory variables if they are measured but are not of primary interest in
the experiment.
Depending on the number and type (categorical or quantitative) of variables, different
statistical models are fit to the observations to draw conclusions about the experiment or
make predictions for future experiments. Generally, models with one quantitative
response variable are called UNIVARIATE and models with two or more response
variables are called MULTIVARIATE. Multivariate models are considerably more
complicated than univariate models because possible associations between response
variables must be taken into account. Up to this point and throughout the rest of this
Manual, we focus only on univariate models in which one response variable is observed
together with one or more predictor variables.
Regression and Analysis of Variance or, ANOVA, are two of the most commonly used
statistical techniques. They have a lot in common (Section 7.3) and differ primarily in the
type of variables observed. In a regression model, a quantitative response variable is
written as a linear function of one or more quantitative predictor variables plus an
independent error term. Statistical inference includes estimating the values of the model
parameters, providing confidence intervals and conducting hypothesis tests. The model
will make assumptions on the distribution of the error terms that need to be verified
before any conclusions are drawn. Data from a regression analysis are most commonly
displayed in scatter plots (Fig. 28, left).
119

FIGURE 28. (Left) In a regression model, a quantitative response is explained through one
or more quantitative predictors. (Right) In an ANOVA model, a quantitative response is
explained through one or more categorical predictors.
If the response variable is quantitative, but the predictor variables are categorical, an
ANOVA MODEL is used. In this setup, the main question is whether or not the levels of the
categorical predictor variables have significant influence on the average response. To
answer this question, the variation among group means will be compared to the variation
within the groups defined by the categorical predictor(s) (Fig. 28, right).
Model
Response
Predictor(s)
one-way ANOVA model one quantitative one categorical
two-way ANOVA model one quantitative two categorical
simple regression
one quantitative one quantitative
logistic regression
one categorical
one (or more) quantitative
multiple regression
one quantitative two (or more) quantitative
If all variables in an experiment are categorical, statistical inference is usually focused
on evaluating associations between variables via χ2-tests (Section 6.2.5).
7.1  Regression
The simplest statistical model is the one in which one quantitative explanatory variable
120

is used to predict one quantitative response variable. This is called a simple linear
regression model. Recall from Section (3.8) that the correlation coefficient r may be
used as a statistical measurement for the strength of linear association between two
quantitative variables. If the association is strong, then in a scatter plot of the two
variables, the data points may be approximated by a straight line. Conventionally,
response variables are plotted on the y-axis and explanatory variables on the x-axis (Fig.
29).
FIGURE 29. In least squares regression, the line is fit to minimize the sum of squared
residuals.
Which straight line approximates the data points best? There are several ways to make
this decision. By far, the most popular method (and the one implemented in R) is LEAST
SQUARES regression. The line is chosen so that the squared vertical distances between
data points and the line are minimized. The distances between observations and their
predicted counterparts are called RESIDUALS (Fig. 29). For a regression model to be
considered good, the residuals should be normally distributed over the predictor
variable range with roughly constant standard deviation σ.
Regression line equation: The mathematical equation for a line is
Here, y and x are the response and predictor variables, respectively, b0 is the INTERCEPT,
and b1 is the SLOPE of the line.
121

Due to experimental error, most observations will not lie directly on the line. Therefore,
the observations yi will be modeled as observations from a normal distribution with
mean μy that depends on x and standard deviation σ. The residual terms ϵi represent the
variation in the observations y around the mean μy. They are assumed to be normally
distributed with mean 0 and constant standard deviation σ.
Estimates for the intercept b0, the slope b1, and the residual standard deviation  can be
computed (in R) by fitting a least squares regression line to the observations.
In R Commander: Your data should contain two numerical variables to be used as the
explanatory variable x and response y. Observations on the same individual need to
appear in the same row. Click “Statistics,” “Fit models,” and “Linear Regression.”
Identify your response and explanatory variable. Click “OK.”
7.1.1  Correlation and Regression
The closer the correlation coefficient of two sets of quantitative measurements is to 1 or
–1, the stronger the association between the two variables. In terms of regression, strong
association means that the data points of the two measurements will lie close to their
least squares regression line. Statistically, the square of the correlation coefficient, r2, is
the percentage of the variation in the response variable y that is explained by the
predictors, x (or, explained by the regression of y on x).
The R Commander output for fitting a simple linear regression model is organized into
three parts. The first part contains summary statistics for the model residuals ϵi. The
second part contains the estimated model coefficients b0 and b1 and hypothesis tests
related to them, and the third part reports the residual standard error, multiple R2,
adjusted R2, and the results of an F-test, which is sometimes referred to as the model
utility test.
The RESIDUAL STANDARD ERROR is the estimate of the standard deviation of the residuals 
. Its degrees of freedom in a simple linear regression model is n – 2. MULTIPLE R-
SQUARED is the square of the correlation coefficient; this number represents the
percentage of variation of the response explained through the predictor. High values of r2
122

(close to 1) mean that the predictor can predict the response very well. ADJUSTED R-
SQUARED is a quantity that is only relevant for multiple linear regression (Section 7.1.5).
7.1.2  Parameter Estimation
The values, b0, b1, and  of the model parameters computed by R Commander obviously
depend on the data. If the experiment was repeated under similar conditions, the
observations could not be expected to be exactly the same. Different measurement errors
will lead to (slightly) different model parameter estimates. In this sense, the model
parameters are random variables and we can ask statistical questions about them. In
particular, we could formulate confidence intervals for the parameters or conduct
hypothesis tests for them.
In R Commander: When a linear regression analysis is performed in R Commander,
the estimates of the model parameters are computed and reported in the “Coefficients”
table. The same table also reports the standard errors (standard deviations of the
estimates).
To obtain a confidence interval for a regression intercept or slope, fit the regression
model as previously described, and then click “Models” and “Confidence intervals.”
Choose the confidence level (usually 0.95) and click “OK.”
How should the slope estimate b1, that is computed in a simple linear regression
analysis, be interpreted? For each unit increase in the predictor variable x, the response
y increases on average by b1 units. If the measurement units of one or more variables in
the regression model are changed (e.g., from inches to centimeters), this will influence
the values of all regression parameters and the analysis should be repeated to obtain new
parameter estimates.
7.1.3  Hypothesis Testing
The most meaningful question to ask of the model parameters in a regression model is
whether or not they are really necessary. A parameter does not need to be included in the
model if its value is zero. The p-values in the coefficients table returned by R
Commander correspond to this null hypothesis. If a p-value is small, its corresponding
slope is significantly different from zero. Thus, the corresponding predictor has a
significant influence on the response. On the other hand, if a slope p-value is large, then
123

the slope is (almost) zero. In this case, the predictor has very little influence on the
response. Predictors with large p-values for their slopes may potentially be excluded
from a regression model (Section 7.1.6).
Example 7.1
Researchers at the University of California, Davis, have studied the link between
flavonoids in organically and conventionally grown tomatoes and the amount of nitrogen
in the fertilizer used on the plants. Organic fertilizer such as manure contains
considerably less nitrogen than commercially produced fertilizers. They measured the
nitrogen application (in kg ha/yr) as well as the flavonoid compound Kaempferol (in
mg/g) over the course of n = 6 years. For comparison, tomatoes were grown on adjacent
plots under the same environmental conditions.
Nitrogen Kaempferol
446
43
347
48
278
56
254
67
248
90
232
86
Using R Commander to fit a simple linear regression model with nitrogen as the
predictor (x) variable and Kaempferol as the response (y) results in the output shown in
Figure 30.
124

FIGURE 30. R Commander output produced for the simple linear regression model fit in
Example 7.1.
To interpret the output, we can say that the nitrogen level in the soil is a significant (p =
0.042) predictor for flavonoid content in the tomato fruit. In fact, 68.4% of the variation
in flavonoid is explained by nitrogen. We can see that the flavonoid content decreases
when more nitrogen is applied to the soil (in commercially grown tomatoes) because the
regression coefficient for nitrogen is negative (b1 = –0.1983). This means that for every
kilogram of nitrogen added to a hectare of soil, the flavonoid content decreases on
average by 0.1983 mg/g of tomato.
In this example, it makes no sense to also interpret the intercept parameter in the context
of the problem. Theoretically, b0 = 124.65 is the amount of flavonoid contained in plants
grown entirely without nitrogen. However, plants would not grow at all under these
conditions which makes interpretation of this number meaningless.
To check whether the assumptions for the statistical model are satisfied, we have to take
a look at the residuals. It is hard to discern a pattern in the residual plot, because the
number of observations (n = 6) is rather small. A QQ-plot of the residuals (Fig. 31) may
be used to check the residuals for normality. Again, because the number of observations
is small, it is difficult to discern a pattern in the residual plot. In this case, there is no
reason to believe the residual assumptions are violated.
125

FIGURE 31. Residual plot produced as part of the R Commander output for Example 7.1.
In R Commander: After a linear regression model has been fit by R Commander, the
assumptions on the residuals can be checked by clicking “Models,” “Graphs,”
“Residual Quantile-Comparison Plots,” and “OK.”
Check whether the dots in the graph lie approximately scattered around the solid line,
or whether they form a pattern that is not linear. The latter would be an indication that
the model assumpations are violated.
7.1.4  Logistic Regression
Consider the case where a bivariate categorical response (e.g., subject lives or dies, or
experiment succeeds or fails) is to be predicted from one (or more) quantitative
predictors. In this case, we are most interested in the probability p of success (subject
lives, experiment succeeds) for a given level of the predictor x. We cannot directly fit a
linear regression model because the response variable takes on only two values. Instead,
126

consider the probability that the response is a success if the experiment is conducted at a
particular predictor level. Fit a linear regression model to the logit function of this
probability:
Here, pi is the proportion of observed successes if the experiment was conducted at
predictor level i. Let xi denote the predictor value for individual or trial i.
In R Commander: Your data should contain at least one quantitative predictor
variable and the response should be coded as a factor variable with exactly two
levels. Click “Statistics,” “Fit models,” and “Multinomial logit model.” Move the
response factor into the box to left of the ~ sign (by double clicking). Move the
quantitative predictor into the box to the right of the ~ sign. Click “OK.”
The R Commander output will provide the estimated values of b0 and b1 in the column
Values.
The success probability for a specific level x of the predictor can then be estimated by
solving the model equation for p:
7.1.5  Multiple Linear Regression
Sometimes more than one predictor variable is used to explain the behavior of one
quantitative response. For example, several genetic markers may be used to predict a
quantitative trait locus (QTL). The statistical model for a multiple regression model with
k predictor variables x1, …, xk and response y becomes
As in the simple linear regression model, the response y is modeled as a normally
distributed random variable with mean μy and constant variance σ2. The mean μy is
expressed as a linear combination of the predictor variables. There is still only one
127

intercept b0, but unlike the linear regression model, there are now k slopes b1, …, bk,
one corresponding to each predictor variable. The ϵi are the residuals, and the model
assumes that they are normally distributed with mean zero and constant standard
deviation σ.
NOTATION for the multiple linear regression model:
yi
ith observation on the response
what we expect the ith observation to be, given its predictors
xij ith observation of predictor variable j
In R Commander: Fitting a multiple linear regression model is very similar to fitting
a simple linear regression model. Click “Statistics,” “Fit models,” and “Linear
regression.” Select your numerical response variable and identify one or more
predictor variables (click them while holding down the shift button). Click “OK.”
Confidence intervals for the model slopes and hypothesis tests for the model slopes
can be obtained in the same way as those in the simple linear regression case.
The output of a multiple linear regression analysis in R Commander contains three
tables. The Residuals table summarizes properties of the model residuals. The
Coefficients table reports the estimated model parameters, and the last part of the
output reports quantities that are useful in judging the overall fit of the regression model.
One (pessimistic) hypothesis test that one can conduct for a multiple regression analysis
is whether or not any of the predictors have an effect on the response. This corresponds
to testing the null hypothesis
This null hypothesis is tested against the alternative that at least one of the predictors has
a nonzero slope. The test statistic and the corresponding p-value for this F-test can be
found in the last line of the multiple regression output. If the p-value is small, then it
means that at least one of the k predictors in the model has an effect on the response. If
this p-value is large (which rarely happens), then it tells you that your experiment was
poorly designed, and none of the observed predictors have any significant influence on
the response. This test is sometimes referred to as the model utility test.
128

The Coefficients table in the R output contains the estimates of the individual slopes
b0, b1, …, bk in the column titled Estimate. The p-values in the same table correspond
to the t-tests that check each slope individually and ask whether or not it is equal to zero.
If a t-test for a slope has a small p-value, then this means that the corresponding
predictor has a significant effect on the response and thus belongs in the regression
model. If, on the other hand, the p-value is large, it means that the slope is (almost) zero
and that the predictor could be excluded from the model.
7.1.6  Model Building in Regression: Which Variables to Use?
A good statistical model is as simple as possible while at the same time achieving high
explanatory power. Simple in the context of regression means using as few predictor
variables as possible. The explanatory power of the model can be measured by the
percentage of variation in the response explained through the predictors (multiple R2).
Including additional predictors in the model will always improve the explanatory power,
but a small increase in R2 may not be worth including another parameter.
The variable ADJUSTED R SQUARE takes the number of variables and the explanatory
power of the model into account. It can be used as one tool in choosing a good regression
model (pick the model with the highest adjusted R2).
GENERAL STRATEGY: Building a good multiple regression model means selecting a
minimal subset of predictors that collectively have good predictory power for the
response. To find the best regression model, begin with all predictor variables on which
you have collected data. Fit a multiple linear regression model, then
1. Look at R2. The full model that uses all available predictors will have the highest
R2.
2. Look at the p-value for the model utility F-test. Proceed only if this p-value is
small (less than 0.05).
3. Look at the p-values for the t-tests for the individual predictors. Variables with
small p-values correspond to good predictors and those with large p-values
correspond to not-so-good predictors.
4. Exclude the worst predictor (largest t-test p-value) and refit the model with the
remaining predictors. Start over at Step 1.
129

Terminate this procedure when all predictors are significant (slopes have p-values less
than 0.05) and when the exclusion of further predictors causes a large decrease in R2. Do
not forget to refit the model for your final choice of predictor variables. Every change in
the set of predictors used will change the estimates for the slopes and the residuals.
Check the model assumptions (normality and constant variance of residuals, Section
7.1.7) on the residuals computed for the final model.
If there are many potential predictors available for a multiple linear regression model,
then the method described above can be tedious. Automated alternatives exist, but they
should be applied with caution. It is good practice to obtain several candidate models
produced with different automated variable selection methods and compare them
manually based on the previously outlined criteria (i.e., high adjusted R2, significant
predictors, model assumptions satisfied).
In R Commander: Fit a multiple linear regression model. To conduct automated
variable selection, click “Models” and “Stepwise model selection.” The method
described in this section is referred to as the backward model selection method. Click
“OK.” The last line of the R-output will contain the predictor variables selected for
inclusion in the final model.
7.1.7  Verification of Assumptions
Every statistical model relies on some kind of distribution assumptions. All inference
drawn from the analysis such as confidence intervals, hypothesis tests, and predictions
for future experiments are only valid if those assumptions are (reasonably) satisfied.
Computations using software can always be performed for a regression analysis
regardless of whether or not the assumptions are satisfied. It is the responsibility of the
investigator to check whether or not the model is actually valid before using (or
publishing) any conclusions.
Note: In regression and ANOVA models, the assumption is that the residual terms ϵi
are normally distributed with mean zero and constant variance σ2.
Because of the way the model is formulated, the residual terms will automatically have
mean zero. This leaves two assumptions to check: normality of the error terms and the
130

constant variance assumption.
NORMALITY ASSUMPTION: As described in Section 3.4.3, a PP-plot or a QQ-plot of the
residuals can be used to assess their normality. Normally distributed residuals should lie
close to the solid line in the plot with no discernible pattern. If there is a strong S-shape
visible, then this is a sign for nonnormally distributed residual terms.
CONSTANT VARIANCE ASSUMPTION: To check whether the residuals have approximately
constant variance, use R Commander to produce a RESIDUAL PLOT. In this type of plot, the
values of the residuals are plotted against the predicted response. Look for any kind of
pattern in the residual plot. V-shapes, U-shapes, or S-shapes are indicators that the
residual variance is not constant (Fig. 32).
In R Commander: To efficiently create both a residual plot and a QQ-plot of the
residuals for a fitted linear model in R Commander, click “Models,” “Graphs,” and
“Basic diagnostic plots.” The plot on the upper left is a residual plot which can be
used to check for equal variance of the residuals, and the plot on the upper right is a
QQ-plot of the residuals.
FIGURE 32. To check the constant variance assumption of the error terms, produce a
residual plot. If there is no pattern in the residual plot (a), the constant variance
assumptions is satisfied. A V-pattern (b) or a U-pattern (c) in a residual plot is an
indication that the model assumptions are not satisfied.
7.1.8  Outliers in Regression
Sometimes, a few observations do not fit into the overall regression scheme that the rest
of the data follow. These points are called outliers (Fig. 33). The decision of whether to
call a point in a regression analysis an outlier is a subjective one. To make this decision,
it is helpful to consider the residual plot (see Section 7.1.7). If one residual falls outside
131

of the pattern exhibited by the rest of the observations, then the observation
corresponding to the residual may be an outlier.
To decide whether to exclude an outlier from the statistical data analysis several points
need to be considered:
1. Is the outlier influential for the statistical model? This means that if the analysis is
conducted twice—once for the whole data set and once for the reduced set in
which the outlier is omitted—do the estimates of the model parameters (R2, σ,
slopes, p-values for slopes, etc.) change very much? If there is not much change,
then it does not matter (much) whether the outlier is included or not. When in
doubt, err on the side of caution and include every observation (even potential
outliers).
2. Is there reason to believe that the observation does not follow the pattern because
of some type of mistake when the measurement was taken? Is it possible to repeat
parts of the experiment to replace this observation (recommended)? If it can be
established that some kind of technical error was made and the outlier is
influential, the point may be excluded from analysis.
3. Is there reason to believe that some biological effect causes this observation to be
very different from the others? If this is the case, then the point should not be
excluded, even if it is influential. Instead, the model needs to be adjusted to
incorporate this biological effect.
FIGURE 33. Data points that do not fit well into the regression model for the rest of the
data are called outliers. These observations can be recognized by the unusual magnitude
of their residuals.
132

In R Commander: There is a statistical measure called LEVERAGE that measures how
much influence each individual observation has on the fitted regression model. Click
“Models,” “Graphs,” and “Basic diagnostic plots” to create diagnostic plots for a
linear regression mode. The plot on the lower right shows the residuals plotted against
their leverage. Dots that lie beyond the dashed lines can be considered numerical
outliers.
7.1.9  A Case Study
A complete multiple regression analysis will likely consist of several steps.
1. Fit a regression model with all available predictor variables.
2. Look at the residuals and verify the model assumptions. Transform variables if
necessary.
3. Once the residuals are normally distributed, look at the predictor variables. If
necessary, remove variables that are not significant for the response. Refit the
model after each variable removal.
4. Choose a final model. Weigh the model fit (high R2 and ad- justed R2) against
simplicity of the model (simpler is better) and significance of predictor variables
in the model (small p-values for the predictors).
5. Once more, verify the assumptions for this final model. If desired, draw plots
showing the regression line. If you are concerned about outliers, identify potential
outliers and repeat the above analysis for the data set with outliers removed.
Example 7.2
Fifty species of oak trees grow in the United States. Researchers studied the relationship
between acorn size and the size of the geographic region in which the trees grew. They
collected data (tree SPECIES, REGION of growth (0 = Atlantic, 1 = California), ACORN size,
tree HEIGHT, and RANGE) from 39 species of oak. Acorn size is expressed as a volume
computed from length and width measurements on the acorns. Parts of the data are shown
in the following table:
133

SPECIES
REGION
RANGE ACORN HEIGHT
Quercus alba L.
Atlantic
24196
1.4
27
Quercus bicolor Willd.
Atlantic
7900
3.4
21
Quercus Laceyi Small.
Atlantic
233
0.3
11
⋮
⋮
Quercus vacc. Engelm.
California 223
0.4
1
Quercus tom. Engelm.
California 13
7.1
18
Quercus Garryana Hook. California 1061
5.5
20
In this example, acorn size is the response, and range, height, and region are the
predictors. Note that tree species is neither a predictor nor a response, as this variable
identifies the individual trees measured in this experiment. The region variable is
categorical (with values Atlantic and California) and it can be recoded by a numeric
“dummy” variable (see Section 7.3). Specifically, Atlantic is coded as 0 and California
is coded as 1.
R Commander is used to fit a multiple linear regression with ACORN as the response and
RANGE, HEIGHT, and REGION (coded by 0 and 1) as the predictors. A QQ-plot of the
residuals for this model shows that the residuals are clearly not normally distributed
based on the nonlinear pattern in the plot (Fig. 34, left). In fact, both the ACORN variable
and the RANGE variable are strongly skewed to the right as histograms of these two
variables reveal (Fig 34, middle and right).
FIGURE 34. QQ-plot of residuals for the inital linear model (left). Histograms of the
skewed variables ACORN and RANGE (middle,right).
134

To fix this problem, both the ACORN variable and the RANGE variable are natural log-
transformed. That means that new variables named LN(ACORN) and LN(RANGE) are
created which contain the natural logarithms of the original ACORN and RANGE
measurements.
In R Commander: To efficiently transform a variable in R Commander, click “Data,”
“Manage variables in active data set,” and “Compute new variable.” Enter the name
of the new variable (e.g., lnAcorn) and the expression to compute (e.g.,
log(Acorn)). Click “OK.”
The transformed multivariate regression model that is fitted next is of the form
R Commander output for the transformed model is shown on the following page.
From the output, we can see that both REGION and the transformed RANGE variable are
significant for the transformed ACORN size. In fact, researchers believe that larger seed
size attracts larger animals which are able to carry the seeds farther. The tree HEIGHT is
not significant for the ACORN size (p-value for HEIGHT is p = 0.2568 > 0.05). Thus, this
variable can be removed from the model yielding the transformed and reduced model:
135

With the HEIGHT variable removed from the model, the R2 decreases to R2 = 0.239
(adjusted R2 = 0.197). From the output shown above, we can see that for the model that
included HEIGHT, we had R2 = 0.267 (adjusted R2 = 0.204). The simplicity of the
reduced model is preferable even with smaller R2 value.
FIGURE 35. Residual plot and Normal quantile plot produced by R Commander for the
Acorn size example with ln(Range) and Region variables in the model.
Finally, the residual plot and normal probability plot of the transformed and reduced
model (Fig. 35) show that the model assumptions are approximately satisfied. In the
residual plot, we see that the variances of the residuals are approximately constant and
independent because there is no (strong) pattern in the plot. The normal quantile plot
shows that the residuals are approximately normally distributed.
There is one potential outlier in this data set (shown in red in Fig. 36). This value
corresponds to individual 39, the oak tree species Quercus tomentella Engelm, which is
the only species in this experiment which grows on an island (Guadalupe). Since this fact
explains the unusual behavior of the data value, we may decide not to remove it from the
data set.
136

FIGURE 36. Residual plot against natural log-transformed RANGE predictor and leverage
plot for the Acorn size example.
Interestingly, if the outlier value were removed from the analysis, it would make a
drastic difference for the R2 value (which increases to R2 = 0.386). The p-values for the
predictors LN(RANGE) and REGION would become smaller if the outlier value were
removed, making a stronger statement about the significance of these factors for ACORN
size.
7.2  ANOVA
Analysis of Variance (ANOVA) models are used to compare the behavior of a
quantitative response for different values of one or more categorical predictors (Section
3.1).
Example 7.3
In microarray experiments, the quantitative response is gene expression or intensity.
Suppose an experiment considers the differential expression of genes between two
strains of mice. Tissue is collected from three male and three female individuals of each
strain. Meaningful questions that can be asked from this experiment are as follows: Are
there genes that are differentially expressed between the two strains? Are there genes
that are differentially expressed between the two genders? Are there genes for which the
expression difference between strains depends on gender? In this experiment, gene
expression is the response and there are two categorical predictors (strain and gender)
each with two levels. The levels of gender, for example, are male and female.
137

Depending on the number of categorical predictors, ANOVA models are called one-way
(or one factor) for one categorical predictor, two-way (or two factor) for two
categorical predictors, etc. In this Manual, we mostly consider one-way and two-way
ANOVA models and briefly discuss the four-way ANOVA model commonly used in the
analysis of microarray data.
7.2.1  One-Way ANOVA Model
Suppose that a categorical predictor variable takes on I different levels (Fig. 37).
Suppose further that the response has mean μi when the experiment is conducted at level
i. For each level i = 1, …, I of the predictor variable, ni observations are collected on a
quantitative response. Let xij denote the jth observation at predictor level i. We assume
that the observations on level i are normally distributed with mean μi and standard
deviation σ. The standard deviation σ is assumed to be the same for all predictor levels.
FIGURE 37. In the one-way ANOVA model, observations at predictor level i (dots) are
modeled as normal random variables with mean μi and standard deviation σ. Notice that
the standard deviation is assumed to be the same for all predictor levels.
The one-way ANOVA model is:
138

The parameters of this model are μ1, …, μI, and σ.
The ANOVA F-test answers the question whether or not the response means are the same
for all levels of the predictor.
Biologically, this null hypothesis corresponds to the pessimistic statement that the
predictor has no influence on the (average) response.
In R Commander: Your data should include a factor variable to be used as the
predictor and a numerical variable to be used as the response. Click “Statistics,”
“Means,” and “One-way ANOVA.” Select the groups (factor variable) and response to
use. Click “OK.” The “Pairwise comparison of means” option will test whether the
mean response differs between any specific two levels of the grouping variable.
The R-output consists of two tables (or three tables if the pairwise comparison of means
option is selected). The first table contains the result of the ANOVA F-test that asks
whether the predictor factor has any effect on the average response. If the p-value (the
number in the column labeled Pr(>F)) of this test is small, we can say that the factor has
a significant effect on the response or that at least one predictor level has a mean
response different from that of the others. The mean squared error in the summary table is
the estimate of the error variance σ2. The second table provides more insight into what
the direction of the effect actually is. It reports response mean, standard deviation, and
sample size in all groups defined by the factor predictor. Take a preliminary look at the
standard deviations. They should not be too different in magnitude from each other to
satisfy the ANOVA model assumptions (Section 7.2.3).
If an ANOVA F-test concludes that the response means are not all equal for different
levels of the predictor, it is often of interest to question which means actually differ. This
can be done with a Tukey’s test (Section 6.2.4). The “Pairwise comparison of means”
option in R Commander will perform this test. Its results are reported in the form of
pairwise tests for equality of group means (with p-values) and in the form of a graph (see
Fig. 38).
TABLE 3. Baby birth weights (in lbs) for mothers who were smoking at the time of birth,
139

for mothers who had smoked previous to pregnancy, and for nonsmoking mothers.
Current smoker
5.7 7.9 6.8 6.1 7.2 6.2 6.9 6.0 8.4 7.9
Previous smoker 7.5 6.8 6.9 5.7 7.9 7.6 8.3
Nonsmoker
7.6 6.9 7.0 6.8 7.8 7.7 6.4 7.4 8.2 8.6 7.5 7.5 7.5 5.6
Example 7.4
Several studies have linked cigarette smoking in pregnant women to lower infant birth
weights. Researchers interviewed 31 women about their smoking behaviors and weighed
their newborn babies. The smoking behavior was classified as currently smoking (i.e.,
smoked during pregnancy), previously smoking (i.e., smoked previously, but quit before
pregnancy), and never smoked. The infant birth weights are reported in pounds in Table
3. Performing a Single Factor ANOVA analysis in R Commander will produce the output
shown in Figure 38.
To interpret the output, look at the average birth weights for the three groups.
140

FIGURE 38. Output produced for the infant birth weight one-factor ANOVA analysis in R
Commander.
Even though the average for currently smoking mothers is ~0.4 lbs less than for
nonsmoking mothers, we cannot conclude that there is a statistically significant (p =
0.485 > 0.05) difference among the average birth weights based on the data in this study.
The reason for this is that the differences are rather subtle and do not show up in a study
141

of this magnitude. Increasing the sample sizes in all three groups would make the study
more powerful and would likely lead to significant p-values if there truly is an effect of
smoking on birth weight.
To check whether our conclusions are justified, check the assumptions of the one-way
ANOVA model. This can be done in the exact same way as for a linear regression model
(see Section 7.1.9). The variance of the response should be of comparable magnitude in
all three groups. Here, the largest variance is 0.87, which is no more than twice the
smallest (0.56). The residual plot (Fig. 39, left) can also be used to visually inspect the
vertical spread of the residuals in the different groups to make sure the magnitude is
similar. In addition, the residuals should be normally distributed. This can be checked
with a QQ-plot of the residuals (Fig. 39, right). Because there is no nonlinear pattern in
the plot, the residuals are approximately normally distributed. Thus, we can conclude the
model assumptions to be satisfied in this case.
FIGURE 39. Residual plot and QQ-plot for the infant birth weight example.
7.2.2  Two-Way ANOVA Model
Assume that there are two categorical predictor variables A and B. Variable A takes on I
different levels and variable B takes on J different levels. Let μij denote the population
mean of the quantitative response for factor combination level i of factor A and j of factor
B. Let xijk denote the kth observation on factor combination ij, where k = 1, …, nij. The
sample sizes nij for different factor level combinations can all be the same or they can be
different.
142

The two-way ANOVA model is
The parameters of this model are the overall mean response μ, the factor effects αi for
factor A, the factor effects βj for factor B, the interaction effects γij of the two factors, and
the common error standard deviation σ.
MEANS PLOT: An effective way to gain information on how the mean response changes if
the factors are varied in a two-way ANOVA model is a means plot. For each of the
possible IJ factor combinations, compute the average response and plot it as in Figure
40. The factor effects α, β, and the interaction effect γ can be seen in a means plot. There
is a factor A effect (some αi ≠ 0) if the mean response changes for different levels of
factor A. In the means plot, this translates to the average response curve not being
horizontal (flat). There is a factor B effect (some βj ≠ 0) if the average responses for the
different curves corresponding to the levels of factor B are not on top of each other. The
interaction effect (γij ≠ 0) can be seen in a means plot whenever the response curves are
not parallel. If the curves are parallel, then factor B influences the response at every
level of factor A in the same way and the interaction effect is γ = 0.
FIGURE 40. In a means plot, the average response values are plotted for all possible
factor level combinations. In this example, factor A is plotted on the x-axis with four
levels, and factor B is plotted as differently colored curves with two levels.
143

In R Commander: To create a means plot, click “Graphs” and “Plot of means.” Select
your factor variables and your response variable. Under the “Options” tab you can
select which type of error bars (if any) are to be added to the graph.
In R Commander: For a two-way ANOVA model, your data should contain at least
one numerical variable to be used as the response and two variables coded as factors
to be used as the predictors. Click “Statistics,” “Means,” and “Multi-way ANOVA.”
Select your factor variables and your response variable. Click “OK.”
Click “Models,” “Graphs,” and “Basic diagnostic plots” to obtain a residual plot and
normal QQ-plot of the residuals.
The R output for a two-way ANOVA model is organized in a manner similar to that for
the one-way ANOVA model. The first output table contains F-test statistics and
corresponding p-values that test whether the main effects α and β and the interaction
effect γ are equal to zero. A small p-value means that the corresponding effect is not
equal to zero and is therefore important in the model. The next three tables list means,
standard deviations, and sample sizes for the treatments defined by different factor level
combinations. The standard deviations should all be of comparable magnitude to satisfy
the assumptions of the ANOVA model (Section 7.2.3).
Example 7.5
Equal amounts from two strains of yeast, Saccharomyces cerevisiae and Saccharomyces
exiguus, are grown under three different temperature settings (25°C, 35°C, 45°C) in a
sugar solutiongrowth medium. Growth is measured as CO2 production (in mL) over a 1-
hour period. For each strain of yeast and at each temperature, the experiment is repeated
three times. The data are shown in Table 4.
TABLE 4. Data for the yeast growth experiment.
25°
35°
45°
S. cerevisiae
12
37
38
12
38
42
11
39
40
S. exiguus
7
19
18
144

8
22
16
8
23
19
This experiment can be described by a two-way ANOVA model in which growth is the
quantitative response and strain and temperature are two categorical predictors with two
and three levels, respectively. The results of a two-way ANOVA analysis performed in R
Commander with three replications can be seen in Figure 41.
FIGURE 41. R output for the two-way ANOVA analysis performed on the yeast data.
Shown are the ANOVA table, the means plot (with standard error bars), and selected
residuals plots.
To interpret the output, first note that the model assumptions of equal variance of the
residuals and normally distributed residuals are mildly violated. In the plot of residuals
versus fitted values, the vertical spread of the residuals increases slightly as the fitted
response increases. However, there are only three observations available in each
treatment group, and thus we cannot expect the residual variance to be absolutely
constant. The normal QQ-plot of the residuals also exhibits some slight departure from
normality as evidenced by the nonlinear pattern in the plot.
Next, look at the p-values in the ANOVA table (column Pr(>F)). All three values are
very small. This lets us conclude that the strain and the temperature both have an effect
on the growth of yeast. In fact, it can be seen in the means plot that S. cerevisiae in
general exhibits more growth and that the average growth increases with temperature.
145

Note that the interaction effect between Strain and Temperature is also significant. In the
means plot, we can see that the two strains react differently to the higher temperatures.
The p-values in this example were very small (< 10–6). Thus, even though the model
assumptions are slightly violated, the effects can still be called significant.
7.2.3  ANOVA Assumptions
The assumptions that are made in every ANOVA model, regardless of how many factors
are included in the model, are that the residual terms ϵ are independent and normally
distributed with mean zero and constant variance σ2.
The best way to test these assumptions is to obtain the residuals and then check them for
normality and equal variance, similar to the procedure described in the regression
analysis section (Section 7.1.7).
An acceptable substitute is to assure that the response measurements are independent
(e.g., they should not be taken on the same subjects) and to compare the magnitudes of the
standard deviations for all IJ possible factor combinations that are computed by R
Commander. Most of the standard deviations should be similar to each other. However,
if the number of replicates per factor level combination is small (≤ 5), it is unavoidable
that some standard deviations will be larger or smaller than the others. The two-way
ANOVA model is relatively robust against mild violation of the assumptions.
7.2.4  ANOVA Model for Microarray Data
In microarray experiments, the quantitative response is gene expression as measured by
the fluorescence of dyes attached to target cDNA molecules. Categorical predictors
commonly used in microarray experiments are
ARRAY: If more than one slide/array/chip is used in the experiment, small
manufacturing differences can have an influence on the response.
DYE: In two-color experiments, the dye color (red or green) may have an influence
on the magnitude of the response.
TREATMENT: If two (or more) conditions are compared in the experiment, then it is
often the intent to discover the effect that the treatment(s) have on the gene
expression response.
GENE: Naturally, different genes have different levels of expression in any given
tissue sample.
146

Using these four factors, a four-way ANOVA model can be built. Typically, the response
Y in this model is the log-transformed background corrected expression.
In this model, Yijkgr is the logarithm of background-corrected intensity for the rth
repetition of gene g under treatment k labeled with dye j on array i (this notation may
look complicated and scary, but the subscripts are just bookkeeping using indexes). The
interaction effects (array-gene, dye-gene, treatment-gene) reflect the possibility that the
gene probes on different slides may differ (AG), that the two dyes have different
affinities to bind to certain sequences (DG), and that genes may be expressed differently
under different treatments (TG). Note that other interaction effects are missing from the
model. For instance, there is no array-dye (AD) interaction effect, as the dyes are
assumed to function the same on each slide.
In the context of the above ANOVA model, the null and alternative hypotheses
corresponding to differential expression of gene g under treatments 1 and 2 become
The majority of all statistical software packages will provide a p-value for this
hypothesis test. In the context of a microarray experiment, there are a large number of
genes and thus a lot of p-values will need to be considered. Because the number of tests
in microarray experiments is often very large (in the thousands), additional
considerations need to be made to control the number of false-positive decisions
(Section 8.4.6). For more detail on the analysis of microarray data, see Section 8.4.
7.3  What ANOVA and Regression Models Have in Common
The distinction that is made between ANOVA and regression models is somewhat
artificial. Technically, these two statistical models are equivalent. They both model a
quantitative response as a linear function of one or more predictor variables. They both
assume that the residuals are independent, normally distributed, and have constant
variance. The only difference between them is the nature of the predictor variables.
However, it is possible to include categorical variables in regression models by coding
the different levels through DUMMY variables. This becomes especially easy if the
categorical predictor variable takes on only two levels (code them 0 and 1, for
example).
147

Example 7.6
If a categorical predictor takes on more than two levels, more care must be taken before
it can be included in a regression model. For instance, if a drug is administered at doses
2, 4, and 8, then the dummy variable representing drug dosage in the regression model
should not be coded 2, 4, and 8 (if it cannot be assumed that the dosage has a linear
influence on the response). Likewise, the drug dosage should also not be coded as 0, 1,
and 2 because this would assume that the change in response is the same when switching
the dosage from 2 to 4 as it is when switching the dosage from 4 to 8. Instead, use two
dummy variables, both coded 0 and 1, to represent the drug dosage.
dosage represented dummy variable x1 dummy variable x2
2
0
0
4
1
0
8
1
1
In this model, the slope associated with the dummy variable x1 describes the change in
response corresponding to a change in dosage from 2 to 4, and the slope associated with
the dummy variable x2 describes the change in response when changing from 4 to 8.
Consequently, the sum of the two slopes describes the change in response when changing
the dose from 2 to 8.
148

8  Special Topics
In this final chapter, we describe special topics in statistics most commonly used in
biology. The first two popular topics are classification and clustering. Both techniques
are used, for example, in evolutionary biology to create phylogenies, to specify
coexpressed genes in molecular biology, or to find functionally related proteins
(Sections 8.1 and 8.2). Another popular technique used in biology that we describe is
principal component analysis (PCA). PCA is a statistical procedure that makes high-
dimensional data (with observations collected on many variables) easier to interpret by
reducing it to fewer dimensions while conserving the most important aspects of the data
(Section 8.3). This procedure is routinely applied in the analysis of microarray data,
where it is common to observe thousands of variables (genes). Microarray data analysis
itself is a special topic in statistics that is described. The high-dimensional nature of
microarray data gives rise to many new statistical challenges, among those described
here is the multiple comparison problem, i.e., the task of statistically addressing many
questions from the same data set (Section 8.4). A more current special topic is the
analysis of next-generation sequencing (NGS) data. It shares many of the same statistical
issues (i.e., high-dimension, multiple testing, etc.) that are found in microarray analysis,
but are inherently different in that the data are discrete, whereas microarray data are
continuous in nature (Section 8.5). Another special topic that touches many statistical
analyses is maximum likelihood estimation. This statistical technique is commonly used
to estimate the values of model parameters from observations or data (Section 8.6), and
it has benefited greatly from the increased computational capacity that is now widely
available. This technique is one of the most common approaches that is used when
dealing with complex biological models (e.g., in computational phylogenetics or
bioinformatics). Finally, we contrast the frequentist procedures described in this book
with alternative Bayesian methods and highlight important differences between the two
approaches (Section 8.7).
149

8.1  Classification
Many large-scale studies on humans have been conducted to better understand what
conditions cause a particular disease, such as cancer or heart disease. Data are collected
from many patients in the form of genetic information (e.g., microarrays), physiological
measurements, and surveys about lifestyle, family history, etc. A typical goal is to predict
the chance that an individual with a particular background (genetic and lifestyle) will
develop the disease under study. The task of separating a set of n-dimensional
observations into different groups (e.g., high risk, medium risk, low risk) or allocating a
new observation into previously defined groups is one of STATISTICAL CLASSIFICATION.
Example 8.1
Indian elephants have smaller ears (on average) than their African cousins. However, ear
size by itself (measured in diameter or area) is not a good classification tool to
determine whether an elephant is of Indian or African origin. If ear size were used as the
single determining factor, then all baby elephants would (naively) be classified as
Indian, and only when they grow up will some of them be classified as African. Instead,
ear size in conjunction with some other variable (such as age or height) would be a much
better tool for classifying the animals.
There are two main goals in statistical classification:
To describe either graphically (in three or fewer dimensions) or algebraically (in
higher dimensions) the differential features of observations from several known
populations. The goal is to find a DISCRIMINANT FUNCTION of the observations that
describes the differences well (Fig. 42a). This task is usually referred to as
150

statistical DISCRIMINATION.
To sort observations into two or more labeled classes. The objective here is to
develop a CLASSIFICATION RULE that can be used to sort observations and that has
minimal misclassification error (Fig. 42b). This is typically referred to as
statistical CLASSIFICATION.
FIGURE 42. The goal of classification is to find a discriminant function that divides
existing data by type while minimizing the percentage of misclassified observations.
New observations can then be allocated to a particular type using this discriminant
function.
All classification problems are based on sets of TRAINING DATA. These are n-dimensional
observations whose types are known. These data may include measurements on patients
with and without a particular disease, ear diameter and height of elephants of Indian and
African origin, or measurements on other populations which are categorized by a
predictor whose value is observed. Based on this set of training data, a classification
rule is developed (often in the form of a discriminant function) according to which new
observations may then be classified into one of the existing categories.
Figure 43a shows a linear discriminant function that adequately separates two types of
two-dimensional observations. Higher-dimensional observations (n > 2) on two different
types may also be separated by a linear discriminant function (a plane in three
dimensions or a hyperplane in higher dimensions). However, in some applications,
nonlinear discriminant functions may be more appropriate than linear ones (Fig. 43b). As
is the case with almost any statistical model, the best discriminant function is the result
of a trade-off between simplicity of the model (linear is simpler than higher degree
polynomials) and low classification error (percentage of misclassified data points from
the training).
151

FIGURE 43. The goal of classification is to minimize classification error using the
simplest possible discriminant function. Here, the data consist of two-dimensional
observations of two types (red and black). (a) A linear discriminant function is
appropriate, even though two observations from the training set are misclassified. (b) A
curvilinear discriminant function separates the data very well and is preferable to the
linear function which has too many misclassified observations (dotted line). Even though
the curvilinear function in c has no classification error on the training set, it is much too
complicated to be preferable to the simpler version from a.
8.2  Clustering
In statistical classification problems, training data are available and the classification
category of the observations is known. In some biological applications, this is not
possible. For example, for gene expression experiments on the yeast cell cycle, the exact
function of a majority of genes is not known. Instead, expression patterns are observed
repeatedly across many organisms such that groups of genes can be formed which exhibit
similar behavior.
Sorting n-dimensional observations into k groups such that the members of each group
are similar to each other and dissimilar from members of other groups is the goal in
statistical CLUSTERING. One challenge is that the number k of groups is not necessarily
known before the experiment is conducted. What “similar” means in a particular
experiment depends on the measurements that were taken.
152

FIGURE 44. Clustering is the statistical task of separating n-dimensional observations into
meaningful subsets. Here, two-dimensional observations of unknown type are separated
into three clusters based on their proximity (Euclidean distance). Distances between
observations in the same cluster are small compared to distances between observations
in different clusters.
A DISTANCE MEASURE is needed that can describe how dissimilar two observations are.
Example 8.2
For n-dimensional quantitative observations, such as gene expression on n observed
genes, a possible distance measure is Euclidean distance in n-dimensional space.
Suppose that 
 are data observed from n genes collected on
individual A and  = (y1, y2, ... , yn) are n observations on the same genes collected from
individual B. Then the Euclidean distance for these two vectors of observations is
If there is prior knowledge about gene expression in the organism of study, then another
sensible distance measure may weigh gene expression differences according to their
variability. An observed difference in genes that typically do not vary much should count
as “more different” than the same observed difference in a highly variable gene. The
corresponding statistical distance measure is called the MAHALANOBIS DISTANCE.
There are many other distance measures that may be used to describe similarities and
dissimilarities between multidimensional observations. They can be based on absolute
values of coordinate differences, maximum coordinate distances, or similar measures. If
153

some of the observations are categorical, other creative measures may need to be used.
All distance measures have two things in common. First, they are equal to zero if the
observations on both individuals are identical. Second, larger distance measures reflect
observations that are less similar to each other.
There are two fundamentally different approaches for statistical clustering of n-
dimensional data:
HIERARCHICAL 
CLUSTERING: 
Starting 
either 
with 
single 
observations
(AGGLOMERATIVE CLUSTERING) or with one big set containing all observations
(DIVISIVE CLUSTERING), the distance measure is used to form or break up groups of
observations. In agglomerative clustering, initially, every observation is its own
cluster. Similar observations (those with the smallest distance measure) are
clustered together (Fig. 45).
The results from clustering can be displayed in the form of a tree diagram.
Depending on when the algorithm is terminated, the results will either be many
small clusters (terminate early) or fewer larger clusters (terminate later).
PARTITIONAL CLUSTERING: With this method, the number, k, of clusters remains
fixed and observations are “shuffled” between clusters until an optimal clustering
configuration has been reached. One challenge of this approach is to determine the
optimal number of clusters that should be used.
FIGURE 45. In agglomerative hierarchical clustering, observations are combined
154

according to degree of similarity (most similar observations get combined first). In the
above example, the similarity between B and C and between D and E is the same. The
DE cluster is most similar to F, etc. The algorithm may be terminated at any time,
yielding the currently existing clusters (A), (BC), and (DEF) as a result.
8.2.1  Hierarchical Clustering
The main decision that must be made in hierarchical clustering is the choice of which
two clusters to “fuse” (or split) at each stage of the developing a diagram. Because the
processes behind agglomerative clustering and divisive clustering are identical apart
from the direction (top-down or bottom-up) in which the tree is developed, we will
concentrate only on agglomerative clustering here.
Suppose the data consist of observations on N individuals. Each observation is recorded
in the form of an n-dimensional vector. At the first stage of the process, each individual
is its own cluster. Pair-wise dissimilarity measures d are computed for all possible pairs
of individuals and recorded in the form of an N × N table. The two individuals with the
smallest distance are merged together into a cluster.
In the next step, we start with N – 1 clusters. Again, we need distances between all
possible pairs of clusters to fuse the most similar clusters together. How should
similarity measures for groups of observations be computed? There are three different
alternatives.
To compare two clusters, we need a measure that compares the elements that are already
in the clusters. Three different methods are commonly used in practice:
SINGLE LINKAGE: Minimum distance, or distance between
nearest neighbors.
COMPLETE LINKAGE: Maximum distance, or distance between
farthest neighbors.
AVERAGE LINKAGE: Average distance, or average of all
pairwise distances.
155

Note: All hierarchical clustering procedures follow essentially the same protocol:
Select a distance measure and a linkage type.
1. Compute the table of pair-wise distances.
2. Fuse the two clusters with highest degree of similarity (smallest distance) and
reduce the number of clusters by 1.
3. Record the identity of all clusters and the levels (distances) at which mergers
take place.
4. Recompute distance table in smaller dimension using appropriate linkage and
repeat.
The result of a hierarchical clustering can be drawn in a tree diagram with subject labels
on one axis and the distance measure d on the other axis.
In R Commander: Your data set should contain one or more quantitative variables. R
will interpret the rows of your data set as individuals and compute distances between
each pair of individuals. Click “Statistics,” “Dimensional analysis,” “Cluster
analysis,” and “Hierarchical cluster analysis.” Select the variables on which you
would like to base the cluster. Click “OK.” You can select the distance measure and
linkage method to be used under the “Options” tab.
Example 8.3
Nei and Roychoudhury (1993) studied evolutionary distance between humans of different
racial origins. They considered 26 human populations and described genetic distance
between pairs of populations via Cavalli-Sforza distance. For a small subset of five
populations under study the genetic distances (multiplied by 100) are:
Ge
It
Ja
Ko
Ir
German
0.6 5.7 5.7 1.8
Italian
0.6
5.5 5.5 5.0
Japanese 5.7 5.5
0.6 5.0
Korean
5.7 5.5 0.6
5.2
Iranian
1.8 1.6 5.0 5.2
156

To create a phylogenetic tree of these populations using single linkage, notice that the
most closely related populations are German and Italian (distance 0.6), as well as
Japanese and Korean (distance also 0.6). Joining these two pairs of populations will
yield three new clusters. Next, the new distances between clusters (using single linkage)
need to be recomputed.
Ge/It Ja/Ko
Ir
German-Italian
5.5
1.6
Japanese-Korean
5.5
5.0
Iranian
1.6
5.0
For example, the new distance between the German-Italian and Japanese-Korean clusters
is 5.5, because this is the shortest distance between any two members of the two clusters.
Next, the Iranian cluster will be joined with the German-Italian cluster, because it has the
smallest dissimilarity measure (d = 1.6). Finally (without table), the single linkage
between the German-Italian-Iranian and Japanese-Korean cluster is d = 5.0. The
resulting tree diagram is shown in Figure 46. The ordering of the populations on the y-
axis of the diagram is arbitrary. Typically, populations are ordered so that the branches
of the tree do not overlap.
FIGURE 46. A tree diagram illustrating the genetic differences between five selected
human populations. The tree is based on the Cavalli-Sforza dissimilarity measure d and
single linkage.
8.2.2  Partitional Clustering
157

One of the most popular methods of partitional clustering for quantitative data is called
K-MEANS CLUSTERING, in which the complete data set is partitioned into k clusters by
shuffling the observations around in a way that will improve the separation between
clusters until a termination criterion is reached.
ALGORITHM:
1. Choose a number of clusters k.
2. Randomly split the data into k (nonempty) clusters. Determine the center of each
cluster by averaging the observations in the cluster.
3. Assign each data point to its nearest cluster center.
4. Compute new cluster centers and repeat.
5. Terminate after convergence (usually when the assignment of individuals to
clusters does not change).
This algorithm is simple to implement, runs reasonably fast even for very large data sets,
and does not require storage of intermediate results. Because the results depend on the
number k of clusters specified in the algorithm and the initial configuration of
observations, it is a good idea to repeat the algorithm with different k and a different
initialization, to determine the robustness of the results.
In R Commander: Your data set should contain one or more quantitative variables. R
will interpret the rows of your data set as individuals. Click “Statistics,”
“Dimensional analysis,” “Cluster analysis,” and “k-means cluster analysis.” Select the
variables on which you would like to base the cluster. Click “OK.” You can select the
number of clusters to be created under the “Options” tab.
Note: Obtaining a reasonable estimate for the number, k, of clusters that should be
created is a challenging problem that is beyond the scope of this Manual. Note that
the k-means clustering algorithm will always return results regardless of whether or
not the specified k is biologically meaningful. However, the resulting clusters and
subsequently their interpretation in a biological context may change dramatically
with a different choice of k.
158

FIGURE 47. Four two-dimensional observations are clustered using the k-means
clustering algorithm. Observations are depicted by red dots and final cluster centers are
depicted by stars.
Example 8.4
Consider the four two-dimensional observations shown in Figure 47:
Observations
Item
x1
x2
A
1
2
B
5
2
C
2
3
D
7
1
k means clustering (with k = 2) will be used to cluster the observations. Initialize the
algorithm by randomly forming two groups of observations. For instance, consider the
initial clusters (AB) and (CD). The numbers of observations in the initial clusters do not
need to be equal, but every cluster must contain at least one observation. Next, compute
the centers of each cluster by averaging coordinates:
Now consider the observations, one by one, and find their nearest cluster center.
Observation A is closest to the (AB) cluster center, so no action is taken. However,
observation B is closer to the (CD) cluster center, rather than the (AB) cluster center.
159

Therefore, we will shift this observation to form new clusters. The cluster centers now
have to be recomputed:
Check distances of observations from centers again. A, B, and D are closest to the cluster
that they are in. But observation C is now closer to the A-cluster center. Therefore, we
have to shift observation C and recompute centers one more time. Now, every
observation is closest to its own cluster center and no more shifts are necessary. The
algorithm is terminated and yields the final clusters (AC) and (BD).
8.3  Principal Component Analysis
When we think about variables (or multiple dimensions), it is very easy to consider a
single variable or dimension (e.g., time) by itself. Thinking about two variables at the
same time, say plant development across time, is not that difficult, nor is it difficult to
represent graphically (i.e., x – y scatter plot). Even though the correlation (or
covariation) between two predictor variables is not captured in a two-dimensional plot,
it is simple to calculate given the tools that have been described in Section 3.8.
However, when the number of variables (e.g., all genes in a genome) in an experiment
becomes large, it is extremely difficult to think about all the relationships among the
variables and how they are correlated. Luckily, there are a number of exploratory
statistical techniques that can be used that both reduce the dimensionality of the data and
allow the visualization of trends. In other words, instead of thinking about, say five
variables at the same time, it is possible to think about these five predictor variables, or
five dimensions, by forming a linear combination of five predictor variables via a
statistical model. The linear combination is chosen to explain as much of the variation in
the response as possible.
Principal component analysis (PCA) is a statistical technique that surveys the
dimensionality of the data space, as defined by the collection of observed variables
centered around their means. It takes advantage of the variation in and between variables
(i.e., correlation) to transform the original (correlated) data into an informative set of
uncorrelated variables that together explain the largest portion of the variation in the
response variable. As it turns out, PCA operates from the covariance matrix by
160

calculating the eigenvectors. Without going into an explanation of linear algebra (i.e.,
projections, eigenvalues, eigenvectors, etc.), PCA is known to be the optimal linear
transformation of the data space and is able to produce the subspace (i.e., representation)
that has the largest variance between components. A linear transformation is presented as
a function of the variables that are each weighted by what is referred to as a “loading.”
The first principal component explains the most variability in the data through its
loadings on the variables in the model. The second principal component explains less
variation in the data space, and the third and remaining principal components explain
less and less of the variation. Typically, in dimension reduction applications, the
majority of the variation in the data are explained by the first few principal components.
PCA is known as a multivariate technique in the field of statistics because it operates on
multiple dimensions (vectors) in the data space.
In R Commander: Your data set should contain more than two quantitative variables.
Click “Statistics,” “Dimensional analysis,” and “Principal-component analysis.”
Select two or more variables and click “OK.”
The R output will contain the “loadings” that are the coefficients for the linear
combinations of the original variables that will lead to the principal components. There
will always be as many principal components as there were variables in the original
data set. To decide how many principal components to retain, it is helpful to consider the
proportion of variance explained through the components. Ideally, one would want to
select principal components that together explain a large proportion of the variance.
8.4  Microarray Data Analysis
From a statistician’s perspective, microarray data or data generated by other high-
throughput sequencing technologies provide a number of new challenges that do not
occur in more conventional biological data sets (Craig et al. 2003). One challenge is that
the number of treatment combinations (different experimental conditions applied to a
large number of genes on physically different arrays, possibly treated with different dyes,
etc.) is typically very large (easily in the thousands, often in the tens of thousands). In
contrast, the number of identical replications in which the experimental conditions stay
exactly the same and are applied to the same biological sample (technical replicates), or
the number of replications in which the experimental conditions stay the same and are
applied to different biological material (biological replicates), is usually very small.
161

Sometimes, there may be as few as two or three biological and/or technical replicates
compared to tens of thousands of experimental conditions. This makes statistical analysis
challenging, because it relies on comparing variation across replications to differences
between experimental conditions (Kerr and Churchill 2001).
8.4.1  The Data
Most biologists receive the data from their microarray experiments in spreadsheet
format. The data files contain details about the information spotted on the arrays and their
physical positions, as well as per spot laser (light) intensities that represent the amount
of corresponding mRNA measured in the sample. Because microarray technologies vary,
the array platform used in the experiment dictates the format of the data and the way that
mRNA quantities are represented.
OLIGONUCLEOTIDE ARRAYS
These commercially available arrays are the most common microarray platform. Probes
on arrays are short oligonucleotide chains (e.g., 25-mer on Affymetrix arrays and 60-mer
on Agilent arrays) that each correspond to a portion of a gene. Several (between 11 and
20) of these probes together identify a gene in a probe set. To identify the degree of
cross-hybridization, the “perfect match” probes on Affymetrix arrays are accompanied
by “mismatch” probes in which the middle of the oligonucleotide is deliberately altered.
The “mismatch” measurement is subtracted from the “perfect match” measurement for
every probe. To obtain an expression measurement for each gene, the mismatch-corrected
intensities for all probes corresponding to a gene may be averaged.
SPOTTED ARRAYS
Spotted arrays are typically customized arrays that are used in smaller research
applications. Every spot on the array is a sequence that corresponds to a specific mRNA.
Typically, two biological samples are mixed together and then hybridized to a single
array. To distinguish between the samples, the biological material is labeled with
different fluorescent dyes (Cy3, green and Cy5, red). A laser is used twice to measure
fluorescence, once for each color using different wavelengths of light. Each laser scan
provides data from a variety of pixels that represent each spot on the array. The data file
usually contains the mean and median intensities for the center (foreground) pixels as
well as the perimeter (background) pixels for both colors. Typically, the file also
contains columns representing the “background corrected” median intensities, which are
the background medians subtracted from the foreground medians for each spot.
162

In almost all microarray experiments, two biological samples are compared to each
other. The two samples may be hybridized to the same spotted array or to two different
oligonucleotide arrays. For simplicity, we will denote the measurements for gene g
(where g ranges over the possibly thousands of probes or genes represented on an array)
by Rg and Gg, where Rg and Gg are the red and green fluorescence, respectively. On a
one-color oligonucleotide chip or array, Rg and Gg should be understood to be the
fluorescence of a probe g for two conditions each on two different chips.
To compare the measurements for two samples across thousands of genes, it is
convenient to first transform the measurements into the following format:
M represents the log-fold change of background-corrected red intensity compared to
green intensity for gene g. The log2 assures that the M-value is equal to 1 if the red
intensity is twice as large as the green. On the other hand, if the green intensity is twice
as large as the red, then the M-value is -1. If there is no difference in expression between
the red and green condition, then the M-value is zero. Where the M-value represents the
relative difference in expression between the two samples, the A-value expresses the
average log-intensity of the two measurements. If gene g is not (or only slightly)
expressed under both experimental conditions, then A will be small. If the gene is highly
expressed under at least one condition, then A will be large.
Before any kind of analysis is conducted, most researchers will plot the M-values for all
genes on an array against the respective A-values in an MA-plot to gain a visual
overview of the data (Fig. 48a).
163

FIGURE 48. MA plots help to visualize the results of a microarray experiment. The genes
that are most likely differentially expressed are those with both large M-values and large
A-values. Large M-values combined with small A-values may be explained through
technical variation rather than actual biological differences. An MA plot may reveal that
there is a dependence of the fold-change (represented by the M-value) on the intensity
(represented by the A-value) (a). A LOESS normalization may be used (b) to resolve this
problem.
8.4.2  Normalization
Before any conclusions can be drawn from microarray data, it is essential to
mathematically remove as much systematic variation not caused by biological effects as
possible. This process is called Normalization. Possible sources of systematic technical
errors in the data may be caused by manufacturing differences in the arrays themselves,
the dyes used to label the samples, the print tips with which the slides were spotted, etc.
Each of these sources may be adressed with different types of Normalization methods.
Methods may be combined and more than one normalization technique can be applied to
the same data (Yang et al. 2002). The most common normalization techniques are
discussed below.
GLOBAL NORMALIZATION: Consider a whole-genome gene expression study that
compares every gene in the genome under a treatment condition and under a control
condition. If it makes biological sense to assume that there should be approximately as
many up-regulated genes as down-regulated genes, then this assumption is equivalent to
the mathematical assumption that the average of all M-values is zero. In an MA-plot, this
means that the point cloud should be centered vertically at zero. In real microarray data,
164

this is sometimes not the case. If, for instance, the expression values of one condition are
systematically inflated (due to a difference in the amount of material hybridized, a
different laser setting, a problem with the dye, etc.), it will lead to the average of the M-
values being nonzero. A global normalization computes the average of all M-values from
the entire array and subtracts this value from each M-value to force the mean to be zero.
In an MA-plot, this corresponds to moving the point cloud up or down to center it at zero,
without changing the shape of the point cloud.
LOESS NORMALIZATION: Loess (or Lowess) stands for locally weighted scatterplot
smoothing. In microarray experiments, it is often the case that the MA-plot exhibits some
sort of shape that is not a random point cloud centered around the M = 0 axis. For
example, in Figure 48a, the point cloud has a U-shape. This phenomenon occurs typically
on two-color arrays if the dye bias is dependent on the fluorescent intensity. Because
such a dependence does not make sense biologically, it is removed by smoothing the
point cloud (via adjusting the M-values) so that the resulting point cloud is centered
around the M = 0 axis (Fig. 48b).
DYE SWAP NORMALIZATION: In two-color arrays, the two dyes that are often used in
microarray experimens (Cy3 and Cy5) have different binding affinities to certain
sequences. This makes interpreting results difficult, because it can be unclear whether
low fluorescence is caused by low amounts of mRNA in the sample or by poor binding
affinity of one of the dyes. To correct this problem, dye swap experiments are often
carried out (see Example 5). The two samples whose expression values are to be
compared are each split in half. One half of the treatment sample is labeled with red dye
and the control with green dye, and for the other sample halves, the dye labeling is
reversed (or swapped). Then, green treatment and red control are hybridized on one
array and red treatment and green control are hybridized to a second array. M-values are
computed for both hybridizations (keeping the order of treatment and control the same).
The M-values for each gene may be averaged across the two arrays to remove the dye
bias.
165

FIGURE 49. Print tip distribution plot. The distribution of M-values are plotted as
differently colored curves, one for each print tip used to spot the array. In this case, the
print tip represented by the red curve exhibits systematic differences from the other print
tips. The curves may be averaged (thicker black line) for Normalization purposes.
PRINT TIP NORMALIZATION: During the manufacturing process of spotted cDNA arrays,
genetic material is collected in well plates and robotically printed (or spotted) onto the
array surface with fine needles. Multiple needles, or print tips, are arranged in a grid-
like format to simultaneously pick up material and print it on the slide. In the printing
process, the print tips may become slightly deformed, resulting in systematic differences
in the shape of the spots printed by damaged print tips. The ramification of nonuniform
spotting during manufacturing of the arrays results in expression values for the genes
printed by the damaged print tip having altered intensity values, i.e., all slightly higher or
smaller than those printed by undamaged print tips. To identify differences between tips
and to correct systematic non-biological differences, one can create a plot of the M-
values for each separate print tip (Fig. 49). If one curve looks very different from the
others, then it stands to reason that this effect is due to a damaged print tip, rather than
any true biological differences. Normalization in this case is used to find the average
print tip distribution and to adjust M-values to all have the same print tip curve pattern.
After normalization, genes can be ranked by the magnitude of their log-fold changes
(absolute M-values), and those with the largest log-fold changes are often declared
differentially expressed. However, this process of normalizing and ranking genes is
somewhat subjective both in the choice of normalization methods to be applied and in the
threshold chosen for normalized log-fold changes. Statistical methods, such as an
ANOVA model (described in the following section) can replace the normalization and
166

ranking process. If replication has been used, and per gene information is available,
statistical methods are useful for testing statistical hypotheses, such as differential
expression, with greater accuracy.
8.4.3  Statistical Analysis
To make sense of the many observations and attribute “effects” to the treatments that
occur in a microarray experiment, an ANOVA model (introduced in Chapter 7) can be
used. In this model, every systematic change in the experiment, such as treatment group
(one or more different treatment[s] and control), different dyes, each different gene on the
array, each physical array used, etc., is enumerated. After enumerating conditions, every
observation is given a label. In microarray experiments, the observations can be absolute
expressions for a one-color chip or the M-values of ratios of expression for a two-color
chip. The technical effects of the experimental conditions and the biological effects of
different samples are estimated and compared. Statistical hypotheses, for instance, the
hypothesis of differential expression of a gene between two conditions, may be tested
using the model (Newton et al. 2001). Several R-packages freely available through
Bioconductor are specifically designed for the analysis of microarray data. For details,
see Gentleman et al. (2005).
In R Commander:  Marray and limma are popular packages used for the analysis of
two-color microarray data. Marray contains many normalization procedures and
limma can be used to fit a linear model to the data to test for differential expression,
for example. Affy is a package specifically designed for the analysis of
oligonucleotide data.
Example 8.5
In every experiment, it is important to keep track of conditions that may be varied by the
experimenter and to carefully organize the resulting data. This is especially important in
microarray experiments because there are so many observations (possibly under many
different treatment combinations) recorded. Consider, for instance, a very simple dye-
swap experiment, in which only two genes are observed. The genes are spotted in
triplicate on two arrays. In this case, the conditions that we need to keep track of and
enumerate are:
Array: Taking on values 1 (for array 1) and 2 (for array 2).
167

Treatment: Taking on values 1 (for treatment) and 2 (for control).
Dye: Taking on values 1 (for red) and 2 (for green).
Gene: Taking on values 1 (for gene 1) and 2 (for gene 2).
Replication: Taking on values 1, 2, and 3, respectively.
Each observation can be identified or indexed by a combination of the above conditions.
For most microarray experiments, the observations themselves are the background-
corrected median intensities of fluorescence for each spot on each array. The
enumeration process is depicted in Figure 50. In reality, this process is, of course, not
carried out by hand but by a statistical software program.
FIGURE 50. Every observation in a microarray experiment is labeled with the treatment
combinations under which it was derived. For instance, the log-corrected intensity value
3 (circled in red) is the observation taken from array 1 under treatment 1 labeled with
dye 1 on gene 2 in repetition 1. Every other observed value is labeled in a similar
manner.
8.4.4  The ANOVA Model
The statistical model used for the analysis of microarray data seeks to explain as much as
possible the “effects” caused by the different experimental conditions. The enumerated
observations Yijkgr are written as a sum of effects plus a random error term.
Here, μ is the overall expression average observed in the experiment. A is the array
effect, T is the treatment effect, D is the dye effect, and G is the gene effect. If, for
example, the treatment on average had no effect on any of the observed genes, then the
168

treatment effect terms would both be zero (T1 = T2 = 0). The terms AG, DG, and TG are
interaction effects. They express the possibility that a particular treatment may have an
effect on some genes, but not on others. Notice that some potential interaction terms (such
as the Array-Dye interaction, AD) are missing from the model. This is because the dyes
are assumed to function the same way regardless of which array is used in the
experiment. ϵ are error terms that cannot be explained through any systematic change in
experimental conditions. They represent the biological variation from individual to
individual, as well as technical variation through measurement error. The ANOVA model
assumes that the errors ϵ are independent and have a Normal distribution.
The next step in the statistical analysis of a microarray experiment is to estimate all
systematic treatment and interaction effects. This is done by simply averaging the
observations. Statisticians use “dot” notation to represent taking averages. For example,
averaging the replicates (r) of gene i’s expression is represented by
The model parameters are all computed by averaging the appropriate set of observations
(Table 5).
TABLE 5. Model parameters in an ANOVA model are obtained by averaging
observations.
Parameter
Estimate
μ
Ai
Dj
Tk
Gg
AGig
DGjg
TGkg
Example 8.6
In the simple dye swap experiment described in Example 8.5, there are two treatments
169

and, subsequently, there are two treatment terms T1 and T2 that can be estimated. The
overall mean μ is computed as the mean of all 24 observations (estimate of μ: 
). The treatment effect is computed by taking the averages of the treatment
(1.9167) and control (2.0833) observations separately, and subtracting the overall mean
from both. Hence,
A statistical hypothesis test can be used to decide whether these treatment effects can be
explained by random error or whether they are due to some biological effect.
A hypothesis test for differential expression may use the null hypothesis
and alternative hypothesis
Notice that for real microarray data, a large number of these tests need to be conducted
—one test for every gene g represented on the array.
8.4.5  Variance Assumptions
The majority of statistical tests, especially the two-sample t-test (Section 6.2.1) and the
ANOVA F-test (Section 6.2.3), used for the analysis of microarray data rely on
comparing the difference in observations between treatment and control to a variation
measure. There are different methods by which to estimate this variation from the gene
expression observations. If each gene is spotted more than once on the array, then it is
possible to compute a statistical “per-gene” variance for each array. Most often,
however, the number of times that genes are spotted on an array are small (usually less
than five). Thus, this variation measure will lack statistical accuracy.
It is possible to “borrow” variation information from other genes. Whether or not this
makes biological sense must be decided on a case-by-case basis. A very broad approach
(which most likely does not make biological sense) is to estimate the gene expression
variance based on all gene observations on the array. This single estimate of variance is
referred to as the “common variance” and is often used to individually test every gene
for differential expression. The approach of using a common variance assumption is
biologically suspect because regardless of what the treatment actually is, some genes
will naturally be highly expressed and others will show almost no expression. The genes
170

with very low expression will likely have very small variation associated with them,
whereas the expression of highly expressed genes may vary greatly across biological
replications or even over technical replications of the same gene on the same array.
Using the same variation measure for all genes will thus inflate the test statistic (and with
it the p-value) for differential expression for some genes while deflating the value for
other genes. A compromise combines variance information only across genes whose
expression values are comparable.
8.4.6  Multiple Testing Issues
In all microarray experiments, and in most other experiments in molecular biology, a
large number of questions may be posed and answered by the same experiment. For
instance, the same question is asked of potentially tens of thousands of genes from the
same microarray experiment, namely, “Is this gene differentially expressed between
treatment and control?” Statistical tests are not infallible. In fact, the significance level α
that we use in a statistical test (usually α = 0.05) represents our willingness to declare an
effect where in reality there is none (see Section 6.1.2). For every test that is conducted,
it is possible that the conclusion drawn is wrong. If thousands upon thousands of tests are
conducted, then there likely will be many wrong conclusions. The problem is that we do
not know which of the many conclusions are faulty.
Example 8.7
Consider a microarray experiment in which the expression values of 1000 genes are
observed for a treatment condition and a control condition. Suppose there is sufficient
replication so that we can conduct 1000 two-sample t-tests to test each gene for
differential expression. Even though we will likely be correct in declaring many genes as
differentially expressed, if we use a significance level of α = 0.05 for each test, then we
expect to incorrectly declare 50 genes (5% of 1000) as differentially expressed. The
problem is that we do not know which genes are correctly declared as differentially
expressed and which genes are “false-positives.”
How can this problem be adressed? Of course, we could drastically lower the
significance level of every test. For instance, if the experimenters in Example 8.7 are
willing to go on one wild goose chase, they could work with an α value of 0.001 (0.1%
of 1000 is 1). However, this would lead to their declaring very few genes as
differentially expressed. In fact, it would make their list of differentially expressed genes
much shorter, because it would remove both the “fake” genes as well as some truly
171

differentially expressed genes.
An alternative approach has been suggested by Benjamini and Hochberg. Instead of
considering the absolute number of false- positives, one can consider the percentage of
false-positives in the list of genes declared as differentially expressed. Methods of
controlling the false discovery rate (FDR) are simple to implement and are available in
many statistical software packages.
8.5  Next-Generation Sequencing Analysis
Although microarray technology (invented in the 1980s) has its place in science, newer
and faster technologies have replaced them, namely, “next-generation sequencing (NGS)
technology.” NGS technology combines the sequencing approach of the traditional
sequencing (i.e., Sanger) methods with the effectiveness of microarrays. It is efficient
enough to allow the number of pieces of RNA (or DNA) with the same sequence to be
counted and thus quantified. Because the approach is based on sequencing, and not on
matching pieces of RNA to predetermined probes (as in microarray technologies), NGS
is more flexible and can be used for measuring gene expression, or sequencing DNA, and
is not limited to genes that are identified a priori. There are several companies that offer
different approaches to NGS. Although the technologies are different, the basic steps in
preparing, processing, and producing NGS data are very similar.
The three most common platforms are the Genome Analyzer (Illumina, formerly known
as Solexa), the 454-FLX (Roche), and SOLiD (Applied Biosystems). For simplicity, and
the fact that all three technologies share commonalities, we outline a standard Genome
Analyzer experiment.
8.5.1  Experimental Overview
SAMPLE PREPARATION: A tissue sample is taken from an organism; either DNA or mRNA
is extracted from the sample. Recall that the amount of mRNA in a tissue sample is
proportional to the amount of protein produced from the mRNA of the corresponding
genes. The mRNA is converted into cDNA. The cDNA is then randomly fragmented
(using sonication) into pieces that are selected by size (~25–100+ bases long). Adapters
are attached to one or both ends of the cDNA fragments that are then denaturated (split
into single strands). The short single strands of cDNA that are obtained are referred to as
the DNA library for the experiment. The number of pieces of cDNA in a library is
referred to as “library size,” differs between samples, and is a source of sampling
172

variation.
FLOW CELL: The single strands of cDNA are randomly loaded onto a flow cell that is
made up of eight separate lanes on which eight different samples (or more) can be
analyzed simultaneously. On average, between 500 million and 1 billion short strands of
cDNA are loaded into the lanes of a flow cell.
AMPLIFICATION: The single pieces of cDNA are amplified by a process called “bridge
amplification.” That is, copies of each single strand are made, and a cluster of about a
million single strands, all with (hopefully) the exact same base sequence, is built.
SEQUENCING: The nucleotide sequence of each cluster of cDNA sequences will be
determined in parallel for hundreds of millions of clusters. Each cluster represents one
short piece of one part of an mRNA (or cDNA) sequence. All four nucleotides are
labeled each with a different dye (e.g., A is labeled red, T is labeled green, C is labeled
blue, and G is labeled yellow). Because each dye-labeled nucleotide has a removable
terminator molecule, the process is controlled and the next nucleotide in the chain is
prohibited from being added on too early (thus, allowing the sequencing to occur one
nucleotide at a time). Using several cycles of this process, nucleotides are attached to the
single strands of cDNA on the flow cell. After the incorporation of a nucleotide, laser
light in the appropriate frequencies (red, green, blue, yellow) is used to excite the dye
molecules, and a color photograph is taken of the random clusters of DNA that now
fluoresce in the color of the last added dye molecule. As mentioned, before the next
cycle, the dye molecule and the terminator molecule are removed and the process is
repeated. That is, another dye labeled terminated nucleotide is allowed to attach (or
read) to each (growing) chain and another picture is taken, etc. Depth of coverage or
“depth” in DNA sequencing is known as the number of times a nucleotide is read during
the sequencing process.
BASE CALLING: The sequence of pictures taken in the sequencing step gives rise to the
nucleotide sequence for each cDNA cluster on the flow cell via image analysis. The
clusters are identified and consecutive pictures of the same cluster have to be
aligned/matched-up. Similar to microarray image analysis, a background correction is
conducted. The color sequence for the same cluster is translated into a nucleotide base
sequence that can now be called a “read.” A single run of a flow cell produces upward
of 500 million short sequence reads. The resulting data are about 50 GB in size. Given
the advances in technologies, the number of reads and the size of the data files continue
to grow. To date (2015), it takes ~ 1d to run an experiment (if all samples are loaded on
the same flow cell); this includes time for library preparation and the sequencing of
173

clusters.
ASSEMBLY AND ALIGNMENT: The constructed nucleotide sequences from the base-calling
step are each ~25–100+ bases long. However, they overlap a great deal. This makes it
possible to reassemble the sequences into a longer genome for DNA experiments where
the goal is to establish a genome sequence. In RNA experiments, the short sequences are
typically matched, or aligned, to a known/existing reference genome for the purpose of
indicating the presence of a gene.
Not only has NGS revolutionized our ability to sequence RNA and DNA, it has also
enabled significant advances in epigenomics (which is beyond the scope of this Manual,
but definitely worth your time to learn more). Although one can certainly see similarities
with microarray technologies, the experimental designs and resulting data are very
different. For example, in an RNA-seq experiment (i.e., an mRNA experiment conducted
with NGS technology), all of the reads are aligned to the reference genome. The reads
that match/align (i.e., many may align to the same and/or overlapping regions of the
reference genome) are “counted.” The gene counts, or counts of exons in a gene, become
the data that are also referred to as digital gene expression (DGE) measures that quantify
gene expression. They are typically used for a differential expression analysis comparing
the DGE of a gene between two conditions. Because the data are counts, and discrete,
one has to rely on a discrete distribution to study the behavior of genes in a population.
In the earliest days of RNA-seq experiments, there was no biological replication (i.e., no
experimental design). Therefore, a simple Fisher’s exact test was typically used to
compare two conditions, with one sample each, and to test for differential expression.
However, when the power of biological replication and the utility of barcoding gained
appreciation (P.L. Auer 2010), modeling NGS data became an area of great interest.
8.5.2  Statistical Issues in Next-Generation Sequencing Experiments
Interestingly, the physical design of a flow cell can be exploited for the purpose of
sequencing multiple samples in one lane. This approach saves resources, time, and
money, but does come at the expense of sequencing depth (i.e., the number of times a
nucleotide is read during the sequencing step). A unique barcode is a known sequence of
four to 12 nucleotides that can be attached to the 3′ end of an adapter sequence (Sample
Preparation Step). Because the barcode is unique, and identifiable, it identifies the
sample. Therefore, multiple samples can be loaded into the same lane of a flow cell. The
limiting factors in using barcodes are the numbers that are unique and the loss of
sequencing depth during the sequencing process. More samples per lane translates to less
174

read depth and a lower overall read count per sample.
Given that a limited number of samples can be barcoded, it is possible to rely on
standard statistical designs not only to preserve flow cell real estate, but to actually
improve the partitioning of variation into appropriate sources (i.e., improve the chances
of significant results). There are three very important issues to consider in experimental
design: specifically, replication, randomization, and blocking. With respect to NGS
experiments, biological replication is essential if one wishes to accurately understand
the behavior of unit of study (e.g., exon, gene, etc.). Without biological replication, it is
impossible to gain the appropriate biological information to statistically test hypotheses
(e.g., differential expression). Randomizing samples to lanes on a flow cell allows
partitioning of variation into identifiable sources that can be added to a statistical model
as factors. In the absence of randomization, it is possible to “confound,” or hide,
important effects. For example, every replicate of say sample 1 is loaded in lane 3 of
multiple flow cells in an experiment. The sample and lane effects are confounded, and
they are unable to be separated, making the data more variable/noisy than they would be
if sample 1 had been randomly assigned to a lane per flow cell. Finally, blocking is
advantageous to NGS experiments that rely on flow cell technology as it allows the
inherent organization of the flow cell, and multiple flow cells, to be exploited for the
purpose of partitioning unwanted variation.
As mentioned previously, data from NGS technologies are counts and thus require a
discrete distribution to describe their long-run behavior. Certainly, it is well accepted
that a Poisson distribution is the simplest distribution to model the number of times a rare
event occurs. In this context, the rare event is the observation that a read aligns to the
reference genome. The only parameter of the Poisson distribution is λ; it describes both
the center (expected value or mean) and the spread (or variance) of the random variable.
When the requirement for the mean and the variance to be equal is violated, this is known
as overdispersion (i.e., the variance of a gene is greater than its mean), and the data
cannot be described using a standard Poisson distribution. Toward this end, an R
package that is freely available via Bioconductor is edgeR; it acknowledges the need to
estimate gene-wise (per gene) overdispersion or common dispersion (all genes) by
modeling the data as negative binomial and moderating dispersion estimates using an
empirical Bayes procedure. Details about the package and examples on how to conduct
statistical analyses can be found in the edgeR user guide (available on the Bioconductor
website).
175

In R Commander: edgeR is a popular package for differential expression analysis of
biologically replicated RNA-seq data. To install 
edgeR within R type:
source("http://bioconductor.org/biocLite.R") biocLite("edgeR")
Finally, the issue of multiple testing (testing the sample hypothesis thousands of times)
becomes worse in applications of whole-genome NGS. Typically, an entire genome is
explored for differential expression, single-nucleotide polymorphisms, histone
modifications, etc. As mentioned previously for the analysis of microarray data, it is
necessary to control the false-positive rate to a level that considers the family of tests
rather than each individual test (see Section 6.1.2). Estimating false discovery rates
(FDR) (Benjamini and Hochberg 1995) is becoming an increasingly important issue
simply because the number of hypotheses being tested in biology is beyond the limits of
current statistical theory.
8.6  Maximum Likelihood
The accuracy of conclusions drawn from a statistical data analysis depends to a large
degree on the quality of the model fitted to the data. The general form of the model (e.g.,
linear regression, phylogenetic tree, etc.) is largely dictated by the experimenter’s prior
knowledge and the scientific question that an experiment is designed to answer.
However, the fine tuning of a model through the appropriate choice of model parameters
may be based on the outcome of the experiment (data).
Example 8.8
Whether or not it is appropriate to model the life span of fruit flies as a linear function of
the thorax size has to be decided by experimenters based on their experience and the fit
of the data to the hypothesized model.
However, the method by which appropriate values for the intercept β0 and the slope β1
are found may be entirely data-driven.
One of the most popular techniques for estimating the parameters of a statistical model
through the observations is called the MAXIMUM LIKELIHOOD method.
GENERAL IDEA: Every statistical model will assign a probability distribution to the
176

possible observed outcomes of an experiment that is conducted at a fixed level of
predictor variables. If the values of the predictor variables change, the distribution of the
response will likely change, too. Knowing this distribution allows one to compute the
theoretical probability of observing any possible set of outcomes (data). The probability
will depend on the parameters of the statistical model as well as the outcomes that were
actually observed. Written as a function of the model parameters θ and possible
observations x1, x2, …, xn, this probability is also called the likelihood function of the
data
Maximum likelihood values of model parameters may be found by maximizing the
likelihood function with respect to θ. In this case, x1, x2, …, xn are the actual observed
data values.
Example 8.9
The sample proportion  is the maximum likelihood estimate of a population proportion
p. Suppose we are interested in the proportion, p, of soil microorganisms that are
resistant to an antibioticum. Instead of accounting for all microorganisms in the soil, we
take n soil samples, apply the antibioticum and count the number, x, of resistant
microorganisms. The sample proportion is defined as
If the true population proportion of microorganisms that are resistant is p, and a sample
of size n represents a large population of microorganisms, then the number of resistant
microorganisms in the sample has a Binomial distribution (see Section 3.4.1). This
means that the probability of observing x-resistant microorganisms in an n sample can be
formulated as
The former is a function of the observation x, as well as the model parameter p. The
177

number n represents the sample size and is known. To find the maximum likelihood
estimate of p, we maximize the likelihood function L(p;x) with respect to p (not shown
here). The result is
where argmax refers to the argument of the maximum. That is, the maximum likelihood
estimate of p is the value for which the function L attains the largest value.
8.7  Frequentist and Bayesian Statistics
As this reference Manual for bench scientists comes to a close, we address a well-
known dichotomy in statistics. There are many who believe the field of statistics is
divided into two camps: the frequentists and the Bayesians. Some of us believe there are
three camps: the frequentists, the Bayesians, and the “if it works, use it” group. Here, we
introduce the concept of Bayesian statistics in contrast to frequentist or classical
statistics, which is the perspective from which this Manual is written. The basic divide
between classical and Bayesian statistics lies in the definition of probability. Even
though their view and understanding of probability defines their view of
classical/frequentist or Bayesian statistics, the overarching goal of statistics remains the
same: Ask questions of the data based on unknown parameters.
A statistician who approaches statistics from a Bayesian perspective has a different view
of probability, and follows the wisdom of Reverend Thomas Bayes (Bayes 1763).
Bayesian statistics is rooted in thinking about uncertainty rather than long-run behaviors
or probability. Statements are made with a level of certainty or belief attached to them,
which in turn allows probability statements to be made about unknown parameters.
Specifically, Bayes rule is a conditional statement, or posterior probability, on the
parameter given the data and depends on prior information about the parameter. This
prior information may be a guess or hunch, it may be theoretically justified, or it may be
based on previous experience. Prior information (known as “a priori”) coupled with the
likelihood of the data given the unknown parameters gives rise to a level of certainty
(known as a “posterior probability”) that can be placed on the results.
Example 8.10
A quantitative trait locus (QTL) is a region of the genome that is associated with a
quantitative trait of interest. It is desirable to locate QTL for the purpose of inferring the
178

genes or controlling elements that may lie within them. QTL are located by taking
advantage of the genetic distance between known genetic markers, and then statistically
testing at known locations in the genome. From a frequentist approach, the null
hypothesis is that there is no QTL located at a particular testing location in the genome.
Data are collected, a test statistic with a known distribution is calculated, and statements
about the probability of observing a result more extreme than the one provided by the
data are made (i.e., p-value). Alternatively, a Bayesian approach to a QTL analysis
calculates the posterior probability of a QTL being located at the testing position in the
genome, based on prior information about QTL location and the likelihood of the data
given the QTL. A level of certainty for a QTL being present at the testing position is
provided as the result.
179

References
Auer PL, Doerge RW. 2010. Statistical design and analysis of RNA sequencing data.
Genetics 185: 405–416.
Bayes T. 1763. An essay towards solving a problem in the doctrine of chances.
Philosophical Transactions.
Benjamini Y, Hochberg Y. 1995. Controlling the false discovery rate: A practical and
powerful approach to multiple testing. J Roy Stat Soc Series B 57: 289–300.
Bremer M, Doerge RW. 2009. Statistics at the bench: A step-by-step handbook for
biologists. Cold Spring Harbor Laboratory Press, Cold Spring Harbor, NY.
Bunge G von. 1902. Textbook of physiological and pathological chemistry. Second ed.
Kegan Paul Trench/Trubner, London.
Craig B, Black M, Doerge RW. 2003. Gene expression data: The technology and
statistical analysis. J Agri Biol Environ Stat 8: 1–28.
DeLongis A, Folkman S, Lazarus RS. 1988. The impact of daily stress on health and
mood: Psychological and social resources as mediators. J Pers Soc Psych 54: 486–
495.
Fox J. 2005. The R Commander: A basic-statistics graphical user interface to R. J Stat
Softw 14: 1–47.
Gentleman R, Carey VJ, Huber W, Irizarry RA, Dudoit S. 2005. Bioinformatics and
computational biology solutions using R and Bioconductor. Springer, New York.
Guy W. 1846. On the duration of life among the English gentry. J Stat Soc London 9: 37–
49.
Höfer T, Przyrembel H, Verleger S. 2004. New evidence for the theory of the stork. Paed
Perin Epidem 18: 88–92.
Kerr M, Churchill G. 2001. Experimental design for gene expression microarrays.
180

Biostatistics 2: 183–201.
Mendel G. 1865. Experiments in plant hybridization. Proc Nat Hist Soc Brunn
Nei M, Roychoudhury AK. 1993. Evolutionary relationships of human populations on a
global scale. Mol Biol Evol 10: 927–943.
Newton M, Kendziorski C, Richmond C, Blattner F, Tsui K. 2001. On differential
variability of expression ratios: Improving statistical inference about gene
expression changes from microarray data. J Comput Biol 8: 37–52.
Sies H. 1988. A new parameter for sex education. Nature 332: 495.
Stewart KJ, Turner KL, Bacher AC, DeRegis JR, Sung J, Tayback M, Ouyang P. 2003.
Are fitness, activity and fatness associated with health-realted quality of life and
mood in older persons? J Cardiopul Rehab 23: 115–121.
Tukey JW. 1980. We need both exploratory and confirmatory. Amer Stat 34: 23–25.
USDA. National Nutrient Database for Standard Reference, release 18. 2005. Iron
content of selected foods per common measure. United States Department of
Agriculture, Washington, D.C.
Vaillant GE. 1998. Natural history of male psychological health, XIV: Relationship of
mood disorder vulnerability to physical health. Amer J Psych 155: 184–191.
Yang Y, Dudoit S, Luu P, Lin D, Peng V, Ngai J, Speed, T. 2002. Normalization for cDNA
microarray data: A robust composite method addressing single and multiple slide
systematic variation. Nucleic Acids Res 30: e15.
181

Index
A-value, 160
Accuracy, 57
Adjusted R2, 117, 123
Agglomerative clustering, 150
Alternative
hypothesis, 79
one-sided, 79
two-sided, 79
Analysis of variance, 131
ANOVA, 113
ANOVA, 113, 131
assumptions, 140
F-test, 133
model, 60
one-way, 132
two-way, 136
Association, 47
Assumption, 7, 67
ANOVA, 140
constant variance, 125
normality, 125
Average, 20
Average linkage, 152
Bar plot, 24
Bayesian statistics, 145, 176
Bell curve, 33
Bias, 56
182

Bin, 26
Binomial
coefficient, 32
distribution, 31
Biological
replication, 59
variation, 58
BLAST, 110
Bootstrap, 64
Box plot, 28
Categorical, 60
data, 19
variable, 113
Causation, 48
Cause and effect, 48
Central Limit Theorem, 39, 66
Checking model assumptions, 124
Chi-square test, 85, 97
goodness-of-fit, 98
independence, 99
Classification, 145–147
error, 147
rule, 147
Clustering, 145, 148
k-means, 153
agglomerative, 150
divisive, 150
hierarchical, 150
partitional, 150, 153
Common response, 48, 49
Complete linkage, 152
Confidence, 72
183

Confidence interval, 65, 113
computing, 72
interpretation, 67
large sample mean, 72
population proportion, 76
small sample mean, 73
Confidence level, 67, 70, 72
Confounding, 48
Constant variance assumption, 125
Contingency table, 19, 60, 98
Continuous variable, 18
Correlation, 46
Correlation coefficient, 115, 116
Critical value, 70
computing, 71
Cumulative probability, 32
Data
categorical, 19, 24, 25
quantitative, 19, 27, 28
transformation, 37
Dependent variable, 51
Descriptive statistics, 17
Design of experiments, 51
Deterministic model, 51
Differential expression, 132
Discrete variable, 17
Discriminant function, 147
Discrimination, 147
Distance measure, 149
Distribution, 18, 31, 52
binomial, 31
center, 23
Normal, 33
Divisive clustering, 150
Dot plot, 27
184

Dummy variable, 142
Dye-swap, 57, 162
E-value, 110
Effect, 58
Effect size, 61
Error
bars, 44
standard, 21
Estimate, 40
Euclidean distance, 149
Expected value, 20
Experimental design, 6
Explanatory variable, 51, 113
Exploratory statistics, 5
F-test, 85, 95, 122
ANOVA, 133
Factor, 53
Factor effect, 137
False discovery rate, 169
Fisher’s exact test, 85, 91, 100, 105
Fitting a model, 54
Fold-change, 160
Frequency, 26
relative, 25
Frequentist statistics, 145, 176
Global normalization, 161
Goodness-of-fit test, 85, 97, 98
Graphs, 24
Heteroscedastic t-test, 88
Hierarchical clustering, 150
Histogram, 26
Homoscedastic t-test, 87
185

Hypothesis
alternative, 79
null, 79
Hypothesis test, 79, 113
assumptions, 86
errors, 82
five step procedure, 81
power, 83
Independence test, 97, 99, 105
Independent variable, 51
Inference, 65
Inferential statistics, 5
Interaction effect, 137
Intercept, 55, 116
Interquartile range, 21, 24
K-means clustering, 153
Least squares regression, 115
Leverage, 127
Likelihood, 101
Likelihood ratio test, 101
Linkage, 152
average, 152
complete, 152
single, 152
Loading, 157
Loess normalization, 161
Log-odds score, 102
Logistic regression, 60, 114, 120
M-value, 160
MA-plot, 160
Mahalanobis distance, 149
Matched sample, 56
Mathematical model, 51
186

Maximum likelihood, 145, 174, 175
Mean, 20, 23
Means plot, 137
Median, 20, 23
Microarray
data analysis, 145, 158, 163
dye-swap, 164
experiment, 132
normalization, 160
Model
deterministic, 51
mathematical, 51
statistical, 51, 53
Model building, 123
Model assumptions, 7
Model parameter, 55, 113
Model selection, 59
Model utility test, 123
Modified box plot, 29
Monte Carlo, 109, 110
Multiple linear regression, 121
Multiple R-squared, 117
Multiple regression, 114
Multiple testing, 168
Multivariate model, 113
187

Next-generation sequencing (NGS), 169
barcoding, 172
base calling, 171
bridge amplification, 170
data analysis, 169
experimental overview, 170
flow cell, 170
library size, 170
sample preparation, 170
sequencing depth, 171
statistical issues, 172
NGS, data analysis, 145
Noise, 58
Non-parametric test, 103
Normal distribution, 33
mean, 34
parameters, 34
percentile, 36
shape, 33
standard, 34
standard deviation, 34
Normality
assumption, 74, 125
checking for, 37
Normalization, 160
dye-swap, 162
global, 161
loess, 161
print-tip, 162
Null hypothesis, 79
Observation, 18
Oligonucleotide array, 159
One-sample t-test, 85, 86
One-sample z-test, 85, 91
One-sided alternative, 79
188

One-way ANOVA, 132
assumptions, 136
model, 114
Ordinal variable, 17
Outlier, 21, 125, 131
p-value, 81, 83, 110
Paired t-test, 85, 88
Parameter, 52, 55
population, 65
Partitional clustering, 150, 153
Pearson’s product moment correlation measure, 46
Percentile, 20, 36
Permutation test, 85, 88, 108
Pie chart, 25
Plot
bar plot, 24, 30
box plot, 28, 30
box plot, modified, 29
dot plot, 27
histogram, 26, 30
pie chart, 25, 30
PP-plot, 36
QQ-plot, 36
rankit, 37
scatter plot, 27
strip chart, 27
Population, 39, 53, 55, 65
parameter, 65
proportion, 91
Post-hoc test, 96
Posterior distribution, 177
Power, 83
Precision, 57, 71
Predictor variable, 51, 113
Principal component analysis, 145, 156
189

Print-tip normalization, 162
Prior distribution, 177
Probability plot, 36
Probability distribution, 31
Probe set, 159
Proportion, 91
QQ-plot, 86
Qualitative variable, 17
Quantile plot, 37
Quantitative, 60
data, 19
variable, 17, 113
Quantitative trait locus, 177
Quartile, 20
Random sample, 56
Random variable, 18, 30
Range, 21, 24
Rankit plot, 37
Regression, 113
assumptions, 124
case study, 127
least squares, 115
logistic, 60, 114, 120
model building, 123
multiple, 114, 121
outliers, 125
simple linear, 115
Regression model, 60
checking assumptions, 119
Regression parameters
hypothesis testing, 118
interpretation, 117
Reject, 80
Relative frequency, 25
190

Replication, 62
biological, 59
technical, 59
Resampling, 62
Residual, 115
Residual standard error, 117
Response variable, 51, 113
Sample, 39, 53, 55, 65
biased, 56
matched, 56
random, 56
stratified, 56
Sample mean, 40, 41
Sample proportion, 39, 40, 91
Sample size, 58, 60, 72
calculation, 77
Sample statistic, 43, 55
Sampling, 55
Scatter plot, 27
Scheffé test, 85, 96
Side-by-side box plot, 29
Significance, 83
Significance level, 61, 70, 81–83
Simple linear regression, 114, 115
Single linkage, 152
Slope, 55, 116
Sources of variation, 6
Spotted array, 159
Spread, 19, 24
Standard deviation, 20, 24, 43, 44
Standard error, 21, 43, 45, 70
Standard normal distribution, 34
Statistic, 55, 65
Statistical classification, 146
Statistical inference, 65, 113
191

Statistical model, 51, 53
Statistical significance, 83, 84
Statistical software, 8
Stratified sample, 56
Stratum, 56
Strip chart, 27
Summary statistics, 21
Symmetry, 26
t-test, 86
Table, contingency, 19
Tail probability, 34, 35
Technical replication, 59
Technical variation, 59
Test statistic, 6, 80, 81
Training data, 147
Transformation, 37
Tree diagram, 150, 154
Tukey’s test, 85, 96
Two-sample t-test, 85, 87
Two-sample z-test, 85, 93
Two-sided alternative, 79
Two-way ANOVA, 136
model, 114
Type I error, 82
Type II error, 82
Uncertainty, 65
Univariate model, 113
Variability, 24, 61, 72
192

Variable, 17
categorical, 97, 113
continuous, 17
dependent, 51
discrete, 17
explanatory, 51, 113
factor, 17
independent, 51
ordinal, 17
predictor, 51, 113
qualitative, 17
quantitative, 113
random, 18, 30
response, 51, 113
selection, 124
transformation, 129
Variance, 20, 24
Variation
biological, 58
sources of, 6
technical, 59
Wilcoxon-Mann-Whitney test, 85, 88, 104
z-test, 91
193

Index of Worked Out Examples
ANOVA in microarray experiment, 132
ANOVA model for analysis of microarray data, 141
Bar plot, 24
Binomial distribution, 31
Biological and technical replication, 59
Categorical variables in regression, 142
Causation, common response, and confounding, 48
Central Limit Theorem, 42
Chi-squared test for goodness-of-fit, 99
Chi-squared test for independence, 99
Classification, 146
Computing normal percentiles, 36
Computing normal probabilities, 35
Confidence interval, 68
Confidence interval for a population proportion, 76
Confidence interval for Normal Data, 66
Contingency table, 19, 98
Correlation and causation, 47
Determining outliers, 21
Differential gene expression, 80
Dissimilarity measure, 149
Dye bias in microarray experiments, 57
F-test, 95
Fisher’s exact test, 107
Frequentist and Bayesian QTL analysis, 177
194

Hierarchical clustering, 150
Histogram, 26
Independent sample t-test, 88
K-means clustering, 156
Large sample confidence interval for mean, 72
Likelihood, 101
Maximum likelihood estimation of a population proportion, 175
Maximum likelihood parameter estimation, 175
Microarray ANOVA enumeration, 165
Multiple linear regression, 127
Multiple testing, 168
One-sample z-test
for a population proportion, 91
One- and two-sided alternatives in hypothesis testing, 79
One-way Anova, 132
Parameter estimation in dye-swap microarray experiment, 166
Permutation test, 108
Predictor and response variables, 51
Probability distribution, 30
Publication bias, 57
Random variable vs. observation, 18
Resampling, 62
Sample proportion, 39
Sample size calculation, 77
Sampling bias, 56
Side-by-side box plot, 29
Simple linear regression, 117
Small sample confidence interval for a mean, 73
Standard deviation vs. standard error, 43
195

Two-sample z-test, 93
Two-Way ANOVA, 136
Variable types, 17
Wilcoxon-Mann-Whitney test, 105
196

Index of R Commander Commands
ANOVA
one-way, 133
two-way, 137
aov, 133
Backward model selection, 124
Bar plot, 26
Binomial
coefficient, 32
probability, 32
tail probability, 32
Box plot, 28
cex, 14
cex.lab, 14
cex.main, 14
Chi-squared
p-value, 102
goodness-of-fit test, 98
test for independence, 100
chisq.test, 98
choose, 32
col, 14
Computing critical values for normal and t-distributions, 70
Confidence interval for a population mean, 75
Confidence interval for a population proportion, 77
Contingency table, 98
Converting numeric variables to factors, 13
197

cor , 46
Correlation coefficient, 46
dbinom , 33
Diagnostic plots, 125, 127
Entering data, 12
F-test, 96
Fisher’s exact test, 107
fisher.test, 107
Forward model selection, 124
Goodness-of-fit test, 98
hclust, 152
Help, 16
Hierarchical clustering, 152
Histogram, 26
Importing data, 12
Interquartile range, 21
k-means clustering, 155
KMeans, 155
Likelihood ratio test, 102
lm, 116
Logistic regression, 121
main, 14
Maximum, 21
Mean, 21
Means plot, 137
Median, 21
Minimum, 21
Missing data identifier, 13
Model selection, 124
198

Multiple linear regression, 122
Normal
percentiles, 36
probabilities, 35
quantiles, 36
One-sample t-test, 87
One-way Anova, 133
Output
save, 15
plot, 14
Paired sample t-test, 89
pbinom, 33
pch, 14
pchisq, 102
Percentile, 21
Pie chart, 26
Plot
bar plot, 26
box plot, 28
dot plot, 27
histogram, 26
pie chart, 26
scatter plot, 28
strip chart, 27
pnorm, 92
Principal component analysis, 157
princomp, 157
pt, 90
qnorm, 70
QQ-plot construction, 37
qt, 70
Range, 21
199

Regression parameters, 117
Residual check for linear model, 120
Residual plot, 125, 127
Save output, 15
Save R script, 15
Scatter plot, 28
Script
save, 15
Simple linear regression, 116
Standard deviation, 21
Strip chart, 27
Summary statistics, 21
t.test, 87–89
Transformation, 129
Tukey’s post hoc test, 97
Two independent sample t-test, 88
Two-way Anova, 137
Variable
convert, 13
Variable selection, 124
Variable transformation, 129
Variance, 21
wilcox.test, 104
Wilcoxon-Mann-Whitney test, 104
xlab, 14
ylab, 14
200

