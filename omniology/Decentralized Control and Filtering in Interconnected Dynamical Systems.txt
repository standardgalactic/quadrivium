Chapter 1
Introduction
The chapter overviews the past and present results pertaining to the area of de-
centralized control of large-scale systems. An emphasis is laid on decentraliza-
tion, decomposition, and robustness. These methodologies serve as effective
tools to overcome speciﬁc difﬁculties arising in large-scale complex systems
such as high dimensionality, information structure constraints, uncertainty, and
delays. The overview is focused on recent decomposition approaches in inter-
connected dynamic systems due to their potential in providing the extension of
decentralized control into networked control systems, switching systems, and
dynamic systems with abrupt-change parameters.
1.1
Overview
Any scholarly account of the history of the general subject area of large-
scale (complex, interconnected) systems would have to span the past sev-
eral decades, as we have witnessed, during this span of time, an increasing
amount of attention paid to problems of modeling, characterization, struc-
tural properties, control analysis, optimization, and feedback design strategies
[136, 164, 303, 306, 323, 324, 335, 337]. This steady growing interest comes
quite naturally from the relatively rapid expansion of our societal needs which
often result in multidimensional, highly interacting, complex systems which
are frequently stochastic in nature. Though the existence of large-scale systems
as objects for understanding and management is repeatedly afﬁrmed, there has
yet been proposed no precise deﬁnition for largeness nor generally acceptable
quantitative measures of scale.
From the viewpoint of developing analytical models, a system is large when
its input-output behavior cannot be understood without curtailing it, partition-
1

2
Chapter 1. Introduction
ing it into modules, and/or aggregating its modularized subsystems. On the
other hand, from a systems viewpoint, a system is large if it exceeds the ca-
pacity of a single control structure. Thus one can enumerate several viewpoints
regarding scale. The class of large-scale systems we will deal with in the subse-
quent chapters is the class of systems that contains a number of interdependent
constituents that serve particular functions, share resources, and are governed
by a set of interrelated goals and constraints [206, 224].
The notion of large-scale systems is therefore adopted when it becomes
clear that one-shot approaches to the associated control problems would not be
appropriate. Therefore, the approach adopted in this book is that a system is
considered large scale if it can be decoupled or partitioned into a number of in-
terconnected subsystems or “small-scale” systems for either computational or
practical reasons [106, 136, 206]. Figure 1.1 displays this approach. Such typ-
ical motivating problems arise in the control of interconnected power systems
with strong interactions, water systems that are widely distributed in space,
trafﬁc systems with many external signals, or large-space ﬂexible structures. It
is quite evident in these cases that the systems to be controlled are too large
and the problems to be solved are computationally demanding or complicated.
New ideas are thought for dividing the analysis and synthesis of the overall
system into almost independent subproblems, for handling the incomplete in-
formation about the system, for dealing treating with the uncertainties, and for
accommodating delays. One prevailing approach has been that the complexity
is an essential and dominating problem in systems theory and practice [106].
Figure 1.1: Large-scale system structure
Among the major difﬁculties that are encountered in the tasks of analyzing,

1.1. Overview
3
designing, and implementing appropriate control strategies and algorithms are:
1. Dimensionality,
2. Information structure constraints,
3. Parameter uncertainty,
4. Delays.
It turns out that the theoretical framework of large-scale systems provides an-
swers to the fundamental question of how to decompose a given control prob-
lem into manageable subproblems that are only weakly related to each other
and can be solved independently. It is observed that the overall system is no
longer controlled by a single controller but by several independent controllers
that all together represent a hierarchical or decentralized controller. This is one
of the fundamental differences between feedback control of small and large
systems. To shed more light on this, we recall the basic centralized system de-
picted in Figure 1.2.
Figure 1.2: Centralized system
1.1.1
Information structure
One of the major issues that manifests large-scale systems is the role governed
by the idea of information structure. Initially, in the case of centralized sys-
tems (refer to Figure 1.2), the basic feedback problem is to ﬁnd control input
vector u(.) on the basis of the a priori knowledge of the plant S described by

4
Chapter 1. Introduction
its design model in the presence of a class of disturbances v(.) and the con-
trol goal given in the form of the design requirements {C} and the a posteriori
information about the outputs y(.) and the command signals r(.). Classical in-
formation structure corresponds to centralized control as illustrated by Figure
1.3. It is important to note that the controller receives all sensor data available
and determines all input signals of the plant. In other words, all information is
assumed to be available for a single unit that designs and applies the controller
to the plant. In present-day technologies where several different units coexist
Figure 1.3: Information structure: centralized control
side by side, neither a complete model (a priori information) nor a complete
set of measurement data (a posteriori information) can be made available for a
centralized decision maker. Instead, the overall design problem has to be bro-
ken down into different, albeit coupled, subproblems. As a result, the overall
plant is no longer controlled by a single controller but by several independent
controllers constituting a decentralized controller structure. Moreover, these
controllers are no longer designed simultaneously on the basis of a complete
knowledge of the plant, but in different design steps by means of models that
describe only the relevant parts of the plant. This amounts to a nonclassical
information structure that arises in decentralized design schemes as shown in
Figure 1.4.
1.1.2
System representation
There are available two main structures of the models of large-scale systems
distinguished by the degree to which they reﬂect the internal structure of the

1.1. Overview
5
Figure 1.4: Information structure: decentralized control
overall dynamic system. These structures are called multichannel systems en-
tailing the presence of multicontrollers and interconnected systems incorporat-
ing coordinated controllers as illustrated in Figures 1.5 and 1.6.
Figure 1.5: Multicontroller structure
In multichannel systems, the associated input and output vectors are de-
composed into subvectors constituting ns channels, while the system is con-
sidered as one whole. More on these types of systems will be mentioned in
later chapters.
Interconnected systems operate with interactions among subsystems. They
are represented by signals through which subsystems interact among them-
selves. These signals are internal signals of the overall system.

6
Chapter 1. Introduction
Figure 1.6: Coordinated control structure
To cope with the aforementioned appearance of the complexity issues, sev-
eral general methodologies have been and are being elaborated. Most of them
belong to one of the following three groups [206, 323, 335, 337]:
1. Model simpliﬁcation,
2. Decomposition,
3. Decentralization.
The idea of model simpliﬁcation is to come up with a reasonable model that
preserves or inherits most of the main trends (features or dominant modes) of
the original large-scale/complex system; see [136, 206] for further elaboration.
The decomposition (tearing) process amounts to generating a group of subsys-
tems (smaller in size) from the original large-scale/complex system. This could
be achieved for numerical purposes or along the boundaries of coupled units. It
turns out that decomposition is only a part of the two-step procedure, the sec-
ond of which is coordination (recomposing) which amounts to synthesizing the
overall solution from the generated solutions of the subsystems (subsolutions).
There are two aspects of decentralization: the ﬁrst issue is concerned with the
information structure inherent in the solution of the given control problem and
refers to the subdivision of the process in terms of the model and the design
goals. The other issue is associated with on-line information about the state
and the command to generate the decentralized control law. The net result is
that a completely independent implementation of the controllers is made vi-
able. There are a variety of different motivating reasons for the decentraliza-
tion of the design process such as weak coupling of subsystems, subsystems
have contradictory goals, subsystems are assigned to different authorities, or

1.1. Overview
7
the high dimensionality of the overall system. Following [192], the principal
ways of decentralizing the design tasks belong to two groups: decentralized
design for strongly coupled subsystems and decentralized design for weakly
coupled subsystems.
The decentralized design for strongly coupled subsystems means that at
least an approximate model of all other subsystems must be considered for the
design of any subsystem under the current design, while the coupling can be
neglected during the design of individual control stations when considering the
decentralized design for weakly coupled subsystems.
1.1.3
Hierarchical systems
One of the fundamental approaches in dealing with large-scale static systems
was the idea of decomposition treated theoretically in mathematical program-
ming by treating large linear programming problems possessing special struc-
tures. The objective was to gain computational efﬁciency and design simpliﬁ-
cation. There are two basic approaches for dealing with such problems:
1. The coupled approach where the problem’s structure kept intact while
taking advantage of the structure to perform efﬁcient computations [106],
and
2. The decoupled approach which divides the original system into a number
of subsystems involving certain values of parameters. Each subsystem
is solved independently for a ﬁxed value of the so-called “decoupling”
parameter, whose value is subsequently adjusted by a coordinator in an
appropriate fashion so that the subsystems resolve their problems and the
solution to the original system is obtained.
Four decades ago, Mesarovic and his coworkers [271] introduced a formal-
ism of hierarchically controlled systems. Out of the many concepts found in
their work, three sets of ideas have subsequently proved useful. The ﬁrst idea
centers on the description of a large system as an interconnected system as a
collection of subsystems coupled by interaction variables in such a way that if
these are considered to be completely ﬁxed or completely free, then the system
decomposes into independent subsystems. By the second idea, this system de-
composition suggests a corresponding division of control into separate lower
level or inﬁmal controllers, one for each subsystem. Through the third idea,
the interaction variables actually present (and ignored in the decomposition)
are taken into account by an upper level or supremal controller whose task is
to coordinate the inﬁmal units. Inspired by results in large-scale mathematical

8
Chapter 1. Introduction
programming. several coordination principles were suggested in [271], notably
the so-called interaction prediction and interaction balance principles. Several
decomposition-coordination approaches have been subsequently elaborated to
simplify the analysis and synthesis tasks for large-scale systems, mainly in the
context of optimal control. The underlying multilevel computation structures
have the following features:
1. The decomposition of systems with ﬁxed designs at one level followed by
coordination at another level is often the only alternative available.
2. In situations where available decision units have limited capabilities, the
associated problem is formulated in a multilayer hierarchy of subprob-
lems.
3. Generally, there will be an increase in system reliability and ﬂexibility.
4. System resources will be better utilized.
5. Systems are commonly described only on a stratiﬁed basis.
A comprehensive application of the hierarchical multilevel approach to water
resources systems has been documented in [97]. Applications to closed-loop
optimal control problems have been reported in [224, 225, 226, 335].
1.1.4
Structure of interconnections
With focus on interconnections, approaches of large-scale systems can be
broadly categorized as follows:
1. Approaches for subsystems with strong interconnections,
2. Approaches for subsystems with weak interconnections.
The ﬁrst category embraces the following classes:
1. Decoupled subsystems,
2. Overlapping subsystems,
3. Symmetric composite systems.
The second category includes the following classes:
1. Multitime scale systems,
2. Hierarchically structured systems.

1.1. Overview
9
More on these methods will be discussed in the subsequent chapters. A com-
mon feature among these approaches is best illustrated by looking at the role
of the interconnections, as depicted in Figures 1.7 through 1.9.
Figure 1.7: Unstructured model
Figure 1.8: Input-output oriented model
Throughout this book, we will take into account the possibility of para-
metric uncertainties and perform robustness analysis to exploit the character of
uncertainties mainly on the bases of the stability analysis of coupled systems.
Another important issue that we will seriously tackle is that of delays since
the incorporation of modern devices and computing facilities eventually incurs
delays in one form or another. This will be a major milestone in the subsequent
analysis. In fact, in some respects we start with large-scale time-delay systems
and after deriving the desired results, we extract the corresponding results for
none-delay systems.
It must be stressed that the origin and the rapid development of decen-
tralized control design methods began more than four decades ago. Various
decentralized control design structures and algorithms have been developed to

10
Chapter 1. Introduction
Figure 1.9: Interaction-oriented model
present the ﬂexibility and superiority of this approach for different classes of
interconnected systems.
1.1.5
Revived challenges
It is well known that feedback control theory does not tackle the problem of
implementing control design algorithms on distributed microprocessor systems
or Transputer. Rather, it promotes the application of such modern hardware fa-
cilities. In fact, it helps to ﬁnd the parallelisms inherent in control problems
and to decompose the overall control task into subproblems that can be imple-
mented on separate computing entities. The resulting control design algorithm
is fault tolerant if the subproblems, which are allocated to the individual pro-
cessors, are sufﬁciently autonomous. We expect that communication delays,
noise, synchronization difﬁculties, or other failures to occur in the processors
or processor links merely degrade the overall system performance but operation
can continue.
In this regard, large-scale systems present feedback control theory with
revived challenges in the following manner:
1. The large dimension of the plant and, thus, the complexity of the plant
model have to be confronted. As a result of restrictions on computer time
and memory space the system cannot be analyzed and controlled as a
whole.
2. Practically speaking, every model of a large-scale system has severe un-
certainties that have to be considered explicitly in all analysis and de-
sign steps. The possible effects of modeling errors cannot be evaluated

1.1. Overview
11
heuristically but necessitate a systematic procedure.
3. The decentralization of both the design and the controller imposes re-
strictions on the model and on the on-line information links introduced
by the controller. This decentralization is crucial because the subsystems
are under the control of different agents, which make their own models
and design their own control stations, or because the design problem has
to be split into independent subproblems to become manageable.
4. The design aims include not only stability or optimality, but also a variety
of properties such as reliability, ﬂexibility, robustness against structural
perturbations of the plant, or restrictions on the interactions between the
subsystems.
Admittedly, the prime objective of decentralized control and ﬁltering is to
get a reasonable solution with reasonable effort in modeling, designing, and
implementing the controller/ﬁlter. To realize this objective, methods for deal-
ing with large-scale systems have to be based on a new methodological back-
ground. The structural properties of the plant have to be exploited in order to
derive suitable design and control structures. A fundamental question concerns
the conditions on the interconnection structure, under which the subsystems are
“weakly coupled” and, thus, can be analyzed separately while ignoring their
interactions. Decomposition and decentralization methods help to answer this
question and lead to new means for testing the stability of interconnected sys-
tems, for analyzing the input-output behavior of a certain subsystem under the
inﬂuence of other subsystems without using a complete model of the overall
plant, and for designing decentralized controllers.
Concerning the interlinks among the theories of large-scale systems and of
small multivariable systems should emphasize this point. Initially, many prob-
lems that can be solved by the methods of multivariable control theory turn
out to be subproblems encountered in large-scale systems theory. This is not
surprising, for here it is a principal aim to break down complex problems into
a combination of easier ones. It is actually the way to reduce the complexity
that needs novel ideas, which then have to be elaborated. These aspects will be
clariﬁed in the subsequent chapters.
Alternatively, large-scale systems give rise to problems that are known in
multivariable systems theory but have not yet been solved satisfactorily. Rig-
orous methods are missing for some multivariable control problems, because
solutions to these small problems could have been found by engineering com-
mon sense rather than by universal algorithms [136, 164, 206, 224, 303, 306,
323, 324, 335, 337].

12
Chapter 1. Introduction
1.2
Outline of the Book
During the past several decades, there have been real world system applications
for which the associated control design problems cannot be solved by using
one-shot approaches. Typical applications arise in the areas of interconnected
power systems with strong coupling ties among network elements, water sys-
tems that are widely distributed in space, trafﬁc systems with many external
signals, or large-space ﬂexible structures with interacting modes. Models of
such systems are frequently complex in nature, multidimensional and/or com-
posed of highly interacting subsystems. Several approaches to deal with these
systems have been developed based on key ideas from economics, management
sciences, and operations research. Over the years, such approaches have been
dynamically evolved into a body of “large-scale systems (LSS) theories.” This
book is written about the wide spectrum of large-scale system theories.
1.2.1
Methodology
Throughout the book, our methodology in each chapter/section is composed of
ﬁve steps:
• Mathematical Modeling
Here we discuss the main ingredients of the state-space model under
consideration.
• Deﬁnitions and/or Assumptions
Here we state the deﬁnitions and/or constraints on the model variables to
pave the way for subsequent analysis.
• Analysis and Examples
This signiﬁes the core of the respective sections and subsections which
contains some solved examples for illustration.
• Results
These are provided most of the time in the form of theorems, lemmas,
and corollaries.
• Remarks
These are given to shed some light of the relevance of the developed
results vis-`a-vis published work.
In the sequel, theorems (lemmas, corollaries) are keyed to chapters and stated
with bold titles, for example, Theorem 3.4 means Theorem 4 in Chapter 3 and

1.2. Outline of the Book
13
so on. For convenience, we have grouped the references in one major bibliog-
raphy cited toward the end of the book. Relevant notes and research issues are
offered at the end of each chapter for the purpose of stimulating the reader. We
hope that this way of articulating the information will attract the attention of a
wide spectrum of readership.
This book aims at providing a rigorous framework for studying analysis,
stability, and control problems of LSS while addressing the dominating sources
of difﬁculties due to dimensionality, information structure constraints, paramet-
ric uncertainty, and time-delays. The primary objective is threefold: to review
past methods and results from a contemporary perspective; to examine present
trends and approaches; and to provide future possibilities, focusing on robust,
reliable, and/or resilient decentralized design methods based on linear matrix
inequalities framework.
In brief, the main features of the book are:
1. It provide an overall assessment of the large-scale systems theories over
the past several decades.
2. It addresses several issues like model-order reduction, parametric un-
certainties, time-delays, control/estimator gain perturbations.
3. It presents key concepts with their proofs followed by efﬁcient computa-
tional methods.
4. It establishes decentralized control and ﬁltering techniques.
5. It treats equally both continuous-time and discrete-time representations.
6. It gives some representative applications and end-of-chapter problems.
1.2.2
Chapter organization
Large-scale systems have been investigated for a long time in the control liter-
ature and have attracted increasingly more attention for more that two decades.
The literature grew progressively and quite a number of fundamental concepts
and powerful tools have been developed from various disciplines. Despite the
rapid progress made so far, many fundamental problems are still either unex-
plored or less well understood. In particular, there still lacks a uniﬁed frame-
work that can cope with the core issues in a systematic way. This motivated us
to write the current book. The book presents theoretical explorations on several
fundamental problems for large-scale systems.

14
Chapter 1. Introduction
The book is primarily intended for researchers and engineers in the sys-
tem and control community. It can also serve as complementary reading for
linear/nonlinear system theory at the postgraduate level.
After the ﬁrst introductory chapter, the core material of the book is divided
into ﬁve parts.
Part 1 is comprised of two chapters: Chapter 2 reviews some basic ele-
ments of mathematical analysis, calculus, and algebra of matrices to build up
the foundations for the remaining topics on stability, stabilization, control, and
ﬁltering of LSS. Chapter 3 introduces different forms of description and mo-
tivation of the study of LSS and presents several analytical tools and theories
that were developed three decades ago.
Part 2 establishes a detailed characterization of the class of LSS with
strongly coupled subsystems and consists of two chapters: Chapter 4 presents
the decentralized stabilization and the robust decentralized servomechanism
problems in order to develop conditions and algorithms for obtaining the de-
centralized controllers. Chapter 5 focuses on LSS where the model structure ad-
mits an overlapping decomposition and addresses the main concepts and ideas
pertaining to system analysis and control synthesis.
Part 3 is devoted to recent developments in decentralized stabilization and
feedback control methods and is subsumed of four chapters: Chapter 6 puts em-
phasis on time-delay LSS and discusses interaction effects, whereas Chapter 7
attends to the actuator/sensor failure issues seeking the design of decentralized
reliable control. Of prime interest is the explanation of new phenomena that
are encountered in interconnected systems and the new ideas that enable the
control engineer to cope with the various problems raised by the need and the
aims of decentralization. In Chapter 8, we examine the implementation issue in
LSS with particular consideration to gain perturbation in feedback gains. Then
in Chapter 9, we deal with LSS under sliding-mode control for both delay-free
and time-delay systems. A complete analysis of static output-feedback sliding-
mode control is provided,
Part 4 provides results on decentralized ﬁltering methods and is summa-
rized in two chapters: Chapter 10 concentrates on decentralized resilient H∞
ﬁlters and Chapter 11 is left to decentralized Kalman ﬁltering and decentralized
fault detection.
In the last chapter “Epilogue,” a concise summary is given to overview the
results on decentralized systems and to furnish a “recipe” to future research. An
appendix containing some relevant mathematical lemmas and basic algebraic
inequalities is provided at the end of the book. Several illustrative numerical
examples are provided throughout the book and relevant questions as well as
problem sets are situated at the end of each chapter.

1.3. Some Notes
15
Throughout the book and seeking computational convenience, all the de-
veloped results are cast in the format of a family of linear matrix inequalities
(LMIs). In writing up the different topics, emphasis is primarily placed on ma-
jor developments attained thus far and then reference is made to other related
work.
1.3
Some Notes
This book covers a wide spectrum of design tools for decentralized control
and ﬁltering in dynamical interconnected systems. For the purpose of unifying
the results, we provide theoretical results of large-scale systems that are devel-
oped for linear, stationary, continuous-time deterministic systems. Afterward,
whenever deemed convenient, we establish the discrete-time counterpart. Some
other extensions to classes of nonlinear systems are also presented.
In most of the recent developments, we start the model description and
analysis for large-scale systems with time-delays within the subsystems and
along the coupling links. We feel that this set-up provides a general framework
from which we can extract several important LSS descriptions of interest. For
example, suppressing the delayed-coupling terms yields a class of LSS with
time-delay subsystems having instantaneous interactions. On the other hand,
deleting the “delay-” terms within the subsystems results in a class of LSS
where the subsystems have delayed communications due to ﬁnite processing
and/or use of networks.
The analytical tools developed in this volume are supplemented with rigor-
ous proofs of closed-loop stability properties and simulation studies. The ma-
terial contained in this book is not only organized to focus on the new devel-
opments in the control methodologies for continuous-time and discrete-time
LSS systems, but it also integrates the impact of the delay factor, complexity,
and uncertainties on important issues like delay-dependent stability and con-
trol design. For the purpose of clarity, it is intended to split the book into self-
contained chapters with each chapter being equipped with illustrative exam-
ples, problems, and questions. The book will be supplemented by an extended
bibliography, appropriate appendices, and indexes. At the end of each chapter,
a summary of the results with the relevant literature is given and pertinent dis-
cussions of future advances and trends are outlined. Some selected problems
are organized for the reader to solve. The bibliographical notes cannot give a
complete review of the literature but indicate the most inﬂuential papers/books
in which the results presented here have been described and provide interested
readers with adequate entry points to the still-growing literature in this ﬁeld.

16
Chapter 1. Introduction
The symbols and conventions used throughout the book are summarized in the
List of Symbols.
It was planned while organizing the material that this book would be ap-
propriate for use as a graduate-level textbook in applied mathematics as well
as different engineering disciplines (electrical, mechanical, civil, chemical, sys-
tems), a good volume for independent study, or a suitable reference for graduate
students, practicing engineers, interested readers, and researchers from a wide
spectrum of engineering disciplines, science, and mathematics.

Chapter 2
Mathematical Foundations
This chapter contains a collection of useful mathematical concepts and tools,
which are useful directly or indirectly, for the subsequent development to be
covered in the main portion of the book. While much of the material is standard
and can be found in classical textbooks, we also present a number of useful
items that are not commonly found elsewhere. Essentially, this chapter serves
as a brief overview and as a convenient reference when necessary.
2.1
Basic Mathematical Concepts
Let xj, yj,
, j = 1, 2, ..., n ∈ℜ(or C). Then the n-dimensional vectors x, y
are deﬁned by x = [x1 x2 ... xn]t, y = [y1 y2 ... yn]t ∈ℜn, respectively.
A nonempty set X of elements x, y, ... is called the real (or complex) vec-
tor space (or real (complex) linear space) by deﬁning two algebraic operations,
vector additions and scalar multiplication, in x = [x1 x2 ... xn]t.
2.1.1
Euclidean space
The n-dimensional Euclidean space, denoted in the sequel by ℜn, is the linear
vector space ℜn equipped by the inner product
⟨x, y⟩= xt y =
n

j=1
xjyj
Let X be a linear space over the ﬁeld F (typically F is the ﬁeld of real numbers
ℜor complex numbers C). Then a function
||.|| : X →ℜ
17

18
Chapter 2. Mathematical Foundations
that maps X into the real numbers ℜis a norm on X iff
1. ||x|| ≥0, ∀x ∈X (nonnegativity)
2. ||x|| = 0, ⇐⇒x = 0 (positive deﬁniteness)
3. ||α x|| = |α|||x||∀x ∈X (homogeneity with respect to |α|)
4. ||x + y|| ≤||x|| + ||y||, ∀x, y ∈X (triangle inequality)
Given a linear space X, there are many possible norms on it. For a given norm
||.|| on X, the pair (X, ||.||) is used to indicate X endowed with the norm ||.||.
2.1.2
Norms of vectors
The class of Lp-norms is deﬁned by
||x||p
=

n

j=1
|xj|p1/p
,
for1 ≤p < ∞
||x||∞
=
max 1 ≤j ≤n |xj|
The three most commonly used norms are ||x||1, ||x||2, and ||x||∞. All p-
norms are equivalent in the sense that if ||x||p1 and ||x||p2 are two different
p-norms, then there exist positive constants c1 and cs such that
c1 ||x||p1 ≤||x||p2 c2 ||x||p1,
∀x ∈ℜn
induced norms of matrices
For a matrix A ∈ℜn×n, the induced p−norm of A is deﬁned by
||A||p := sup
x̸=0
||Ax||p
||x||p
=
sup
||x||p=1
||Ax||p
Obviously, for matrices A ∈ℜm×n and A ∈ℜn×r, we have the triangle
inequality
||A + B||p ≤||A|||p + ||B||p
It is easy to show that the induced norms are also equivalent in the same
sense as for the vector norms, and satisfying
||AB||p ≤||Ax||p ||B||p, ∀A ∈ℜn×m, B ∈ℜm×r
which is known as the submultiplicative property. For p = 1, 2, ∞, we have

2.1. Basic Mathematical Concepts
19
the corresponding induced norms as follows:
||A||1
=
max
j
n

s=1
|asj|,
(column sum)
||A||2
=
max
j

λj(AtA)
||A||∞
=
max
s
n

j=1
|asj|,
(row sum)
2.1.3
Convex sets
A set S ⊂ℜn
is said to be open if every vector x ∈S,
there is an
ϵ−neighborhood of x
N(x, ϵ) = {z ∈ℜn|||z −x|| < ϵ}
such that N(x, ϵ) ⊂S.
A set is closed iff its complement in ℜn is open; bounded if there r > 0
such that ||x|| < r, ∀x ∈S; and compact if it is closed and bounded; convex
if for every x, y ∈S,
and every real number α, 0 < α < 1,
the point
α x + (1 −α) x ∈S.
A set K ⊂ℜn is said to be convex if for any two vectors x and y in K
any vector of the form (1 −λ)x + λy is also in K where 0 ≤λ ≤1. This
simply means that given two points in a convex set, the line segment between
them is also in the set. Note in particular that subspaces and linear varieties (a
linear variety is a translation of linear subspaces) are convex. Also the empty
set is considered convex. The following facts provide important properties for
convex sets.
1. Let Cj, j = 1, ..., m be a family of m convex sets in ℜn. Then the
intersection C1 ∩C2 ∩.... ∩Cm.
2. Let C be a convex set in ℜn and xo ∈ℜn. Then the set {xo + x : x ∈C}
is convex.
3. A set K ⊂ℜn is said to be convex cone with vertex xo if K is convex
and x ∈K implies that xo + λx ∈K for any λ ≥0.
An important class of convex cones is the one deﬁned by the positive semidef-
inite ordering of matrices, that is, A1
≥
A2
≥
A3. Let P ∈ℜn×n be a
positive semideﬁnite matrix. The set of matrices X ∈ℜn×n such that X ≥P
is a convex cone in ℜn×n.

20
Chapter 2. Mathematical Foundations
2.1.4
Continuous functions
A function f : ℜn
−→
ℜm is said to be continuous at a point x if f(x +
δx) −→f(x) whenever δx
−→
0. Equivalently, f is continuous at x if,
given ϵ > 0, there is δ > 0 such that
||x −y|| < ϵ =⇒||f() −f(y)|| < ϵ
A function f is continuous on a set of S if it is continuous at every point of
S, and it is uniformly continuous on S if given ϵ > 0, there is δ(ϵ) > 0
(dependent only on ϵ), such that the inequality holds for all x, y ∈S.
A function f : ℜ−→ℜis said to be differentiable at a point x if the limit
˙f(x) =
lim
δx→0
f(x + δx) −f(x)
δx
exists. A function f : ℜn −→ℜm is continuously differentiable at a point x
(a set S) if the partial derivatives ∂fj/∂xs exist and continuous at x (at every
point of S) for 1
≤
j
≤
m, 1
≤
s
≤
n and the Jacobian matrix is
deﬁned as
J =
∂f
∂x
	
=
⎡
⎢⎣
∂f1/∂x1
· · ·
∂f1/∂xn
...
...
...
∂fm/∂x1
· · ·
∂fm/∂xn
⎤
⎥⎦∈ℜm×n
2.1.5
Function norms
Let f(t) : ℜ+
−→
ℜbe a continuous function or piecewise continuous
function. The p−norm of f is deﬁned by
||f||p
=
  ∞
0
|f(t)|p dt
1/p
,
for p ∈[1, ∞)
||f||∞
=
sup t ∈[0, ∞)|f(t)|,
for p = ∞
By letting p
=
1, 2, ∞,
the corresponding normed spaces are called
L∞, L∈, L∞, respectively. More precisely, let f(t) be a function on [0, ∞)

2.2. Calculus and Algebra of Matrices
21
of the signal spaces; they are deﬁned as
L∞
:=

f(t) : ℜ+ −→ℜ|||f||1 =
 ∞
0
|f(t)| dt < ∞,
convolution kernel

L∈
:=

f(t) : ℜ+ −→ℜ|||f||2 =
 ∞
0
|f(t)|2 dt < ∞,
finite energy

L∞
:=

f(t) : ℜ+ −→ℜ|||f||∞=
sup
t∈[0,∞)
|f(t)| < ∞,
bounded signal

From a signal point of view, the 1-norm, ||x||1 of the signal x(t) is the integral
of its absolute value, the square ||x||2
2 of the 2-norm is often called the energy
of the signal x(t),
and the ∞-norm is its absolute maximum amplitude or
peak value. It must be emphasized that the deﬁnitions of the norms for vector
functions are not unique.
In the case of f(t) : ℜ+ −→ℜn, f(t) = [f1(t) f2(t)...fn(t)]t which
denote a continuous function or piecewise continuous vector function, the cor-
responding p−norm spaces are deﬁned as
Ln
p
:=

f(t) : ℜ+ −→ℜn|||f||p =
 ∞
0
||f(t)||p dt < ∞,
for p ∈[1, ∞)

Ln
∞
:=

f(t) : ℜ+ −→ℜn|||f||∞=
sup
t∈[0,∞)
||f(t)|| < ∞

2.2
Calculus and Algebra of Matrices
In this section, we solicit some basic facts and useful relations from linear
algebra and calculus of matrices. The materials are stated along with some hints
whenever needed but without proofs unless we see the beneﬁt of providing a

22
Chapter 2. Mathematical Foundations
proof. Reference is made to matrix M or matrix function M(t) in the form:
M
=
⎡
⎢⎣
M11
· · ·
M1n
...
...
· · ·
Mm1
· · ·
Mmn
⎤
⎥⎦, or
M(t)
=
⎡
⎢⎣
M11(t)
· · ·
M1n(t)
...
...
· · ·
Mm1(t)
· · ·
Mmn(t)
⎤
⎥⎦
2.2.1
Fundamental subspaces
A nonempty subset G ⊂ℜn is called a linear subspace of ℜn if x + y and
αx are in G whenever x and y are in G for any scalar α. A set of elements
X = {x1, x2, ..., xn} is said to be a spanning set for a linear subspace G of
ℜn if every element g ∈G can be written as a linear combination of the {xj}.
That is, we have
G = {g ∈ℜ: g = α1x1 + α2x2 + ... αnxn
for some scalars α1, α2, . . . , αn. A spanning set X is said to be a basis for G if
no element xj of the spanning set X of G can be written as a linear combination
of the remaining elements x1, x2, ..., xj−1, xj+1, ..., xn, that is, xj, 1 ≤
i ≤n form a linearly independent set. Frequently xj = [0 0 ... 0 1 0 ... 0]t is
used as the kth unit vector.
The geometric ideas of linear vector spaces had led to the concepts of
”spanning a space” and a “basis for a space.” The idea now is to introduce
four important subspaces which are useful. The entire linear vector space of a
speciﬁc problem can be decomposed into the sum of these subspaces.
The column space of a matrix A ∈Ren×m is the space spanned by the
columns of A, also called the range space of A, denoted by R[A]. Similarly,
the row space of A is the space spanned by the rows of A. Since the column
rank of a matrix is the dimension of the space spanned by the columns and the
row rank is the dimension of the space spanned by the rows, it is clear that the
spaces R[A] and R[At] have the same dimension r = rank(A).
The right null space of A ∈Ren×m is the space spanned by all vectors
x that satisfy A x
=
0, and is denoted N[A]. The right null space of A is
also called the kernel of A. The left null space of A is the space spanned by all
vectors y that satisfy yt A = 0. This space is denoted N[At], since it is also
characterized by all vectors y such that At y = 0.

2.2. Calculus and Algebra of Matrices
23
r
:=
rank(A) = dimension of column space R[A]
dim N[A]
:=
dimension of right null space N[A]
n
:=
total number of columns of A
r
:=
rank(At) = dimension of row space R[At]
dim N[At]
:=
dimension of left null space N[At]
m
:=
total number of rows of A
R[At]
:=
row space of A : dimension r
N[A]
:=
right null space of A : dimension n −r
R[A]
:=
column space of A : dimension r
N[At]
:=
left null space of A : dimension n −r
The dimensions of the four spaces R[A], R[At], N[A], and N[At] are to
be determined in the sequel. Since A ∈ℜn×m and the fact that rank(A) =
rank(At), we have the dimension of the null space dim N[A] = n −r
and the dimension of the null space dim N[At] = m −r. The following is a
summary of these results: Note from these facts that the entire n−dimensional
space can be decomposed into the sum of the two subspaces R[At] and N[A].
Alternatively, the entire m−dimensional space can be decomposed into the
sum of the two subspaces R[A] and N[At].
An important property is that N[A] and R[At] are orthogonal subspaces,
that is, R[At]⊥= N[A]. This has the meaning that every vector in N[A] is
orthogonal to every vector in R[At]. In the same manner, R[A] and N[At]
are orthogonal subspaces, that is, R[A]⊥= N[At]. The construction of the
fundamental subspaces is appropriately attained by the singular value decom-
position.
2.2.2
Calculus of vector-matrix functions of a scalar
The differentiation and integration of time functions involving vectors and ma-
trices arises in solving state equations, optimal control, and so on. This section
summarizes the basic deﬁnitions of differentiation and integration on vectors
and matrices. A number of formulas for the derivative of vector-matrix prod-
ucts are also included.
The derivative of a matrix function M(t) of a scalar is the matrix of the
derivatives of each element in the matrix
dM(t)
dt
=
⎡
⎢⎣
dM11(t)
dt
· · ·
dM1n(t)
dt
...
...
· · ·
dMm1(t)
dt
· · ·
dMmn(t)
dt
⎤
⎥⎦

24
Chapter 2. Mathematical Foundations
The integral of a matrix function M(t) of a scalar is the matrix of the integral
of each element in the matrix
 b
a
M(t)dt =
⎡
⎢⎣
 b
a M11(t)dt
· · ·
 b
a M1n(t)dt
...
...
· · ·
 b
a Mm1(t)dt
· · ·
 b
a Mmn(t)dt
⎤
⎥⎦
The Laplace transform of a matrix function M(t) of a scalar is the matrix of
the Laplace transform of each element in the matrix
 b
a
M(t)e−stdt =
⎡
⎢⎣
 b
a M11(t)e−stdt
· · ·
 b
a M1n(t)e−stdt
...
...
· · ·
 b
a Mm1(t)e−stdt
· · ·
 b
a Mmn(t)e−stdt
⎤
⎥⎦
The scalar derivative of the product of two matrix time-functions is
d(A(t)B(t))
dt
= A(t)
dt B(t) + A(t)B(t)
dt
This result is analogous to the derivative of a product of two scalar functions of
a scalar, except caution must be used in reserving the order of the product. An
important special case follows.
The scalar derivative of the inverse of a matrix time-function is
dA−1(t)
dt
= −A−1 A(t)
dt A(t)
2.2.3
Derivatives of vector-matrix products
The derivative of a real scalar-valued function f(x) of a real vector x =
[x1, . . . , xn]t ∈Ren is deﬁned by
∂f(x)
∂x
=
⎡
⎢⎢⎢⎢⎣
∂f(x)
∂x1
∂f(x)
∂x2...
∂f(x)
∂xn
⎤
⎥⎥⎥⎥⎦
where the partial derivative is deﬁned by
∂f(x)
∂xj
:=
lim
Δxj→0
f(x + Δx) −f(x)
Δxj
,
Δx = [0...Δxj...0]t

2.2. Calculus and Algebra of Matrices
25
An important application arises in the Taylor’s series expansion of f(x) about
xo in terms of δx := x −xo. The ﬁrst three terms are
f(x) = f(xo) +
∂f(x)
∂x
t δx + 1
2δxt
∂2f(x)
∂x2

δx
where
∂f(x)
∂x
=
⎡
⎢⎢⎢⎢⎢⎢⎣
∂f(x)
∂x1
...
∂f(x)
∂xn
⎤
⎥⎥⎥⎥⎥⎥⎦
,
∂2f(x)
∂x2
= ∂
∂x
∂f(x)
∂x
t
=
⎡
⎢⎢⎣
∂2f(x)
∂x2
1
· · ·
∂2f(x)
∂x1∂xn
...
...
· · ·
∂2f(x)
∂xn∂x1
· · ·
∂2f(x)
∂x2n
⎤
⎥⎥⎦
The derivative of a real scalar-valued function f(A) with respect to a matrix
A =
⎡
⎢⎣
A11
· · ·
A1n
...
...
· · ·
An1
· · ·
Ann
⎤
⎥⎦∈Ren×n
is given by
∂f(A)
∂A
=
⎡
⎢⎢⎣
∂f(A)
∂A11
· · ·
∂f(A)
∂A1n
...
...
· · ·
∂f(A)
∂An1
· · ·
∂f(A)
∂Ann
⎤
⎥⎥⎦
A vector function of a vector is given by
v(u) =
⎡
⎢⎢⎢⎢⎣
v1(u)
...
...
vn(u)
⎤
⎥⎥⎥⎥⎦
where vj(u) is a function of the vector u. The derivative of a vector function of
a vector (the Jacobian) is deﬁned as follows:
∂v(u)
∂u
=
⎡
⎢⎢⎣
∂v1(u)
∂u1
· · ·
∂v1(u)
∂um
...
...
· · ·
∂vn(u)
∂u1
· · ·
∂vn(u)
∂um
⎤
⎥⎥⎦

26
Chapter 2. Mathematical Foundations
Note that the Jacobian is sometimes deﬁned as the transpose of the foregoing
matrix. A special case is given by
∂(S u)
∂u
= S,
∂(utRu)
∂u
= 2 utR
for arbitrary matrix S and symmetric matrix R.
The following section includes useful relations and results from linear al-
gebra.
2.2.4
Positive deﬁnite and positive semideﬁnite matrices
A matrix P is positive deﬁnite if P is real, symmetric, and xtPx > 0, ∀x ̸= 0;
equivalently, if all the eigenvalues of P have positive real parts. A matrix S is
positive semideﬁnite if S is real, symmetric, and xtPx ≥0, ∀x ̸= 0.
Since the deﬁniteness of the scalar xtPx is a property only of the matrix
P, we need a test for determining deﬁniteness of a constant matrix P. Deﬁne a
principal submatrix of a square matrix P as any square submatrix sharing some
diagonal elements pf P. Thus the constant, real, symmetric matrix (P ∈ℜn×n
is positive deﬁnite (P > 0) if either of these equivalent conditions holds:
1. All eigenvalues of P are positive.
2. The determinant of P is positive.
3. All successive principal submatrices of P (minors of successively increasing
size) have positive determinants.
2.2.5
Trace properties
The trace of a square matrix P, trace (P), equals the sum of its diagonal ele-
ments or equivalently the sum of its eigenvalues. A basic property of the trace
is invariant under cyclic perturbations, that is,
trace(AB) = trace(BA)
where AB is square. Successive applications of the above results yield
trace(ABC) = trace(BCA) = trace(CAB)
where ABC is square. In general, trace(AB) = trace(BtAt). Another result
is that
trace(AtBA) =
p

k=1
at
kBak

2.2. Calculus and Algebra of Matrices
27
where A ∈ℜn×p, B ∈ℜn×n, and {ak} are the columns of A. A list of some
identities of trace derivatives and related results is given below:
∂(trace(AB))
∂A
=
∂(trace(AtBt))
∂A
= ∂(trace(BtAt))
∂A
,
=
∂(trace(BA))
∂A
= Bt,
∂(trace(AB))
∂B
=
∂(trace(AtBt))
∂B
= ∂(trace(BtAt))
∂B
,
=
∂(trace(BA))
∂B
= At,
∂(trace(BAC))
∂A
=
∂(trace(BtCtAt))
∂A
= ∂(trace(CtAtBt))
∂A
,
=
∂(trace(ACB))
∂A
= ∂(trace(CBA))
∂A
,
=
∂(trace(AtBtCt))
∂A
= Bt Ct,
∂(trace(AtBA))
∂A
=
∂(trace(BAAt))
∂A
= ∂(trace(AAtB))
∂A
,
=
(B + Bt)A,
∂(trace(AXt))
∂X
=
A,
∂(trace(AXB))
∂X
= At Bt,
∂(trace(AXtB))
∂X
=
B A,
∂(trace(AX))
∂Xt
= A,
∂(trace(AXt))
∂Xt
=
At,
∂(trace(AXB))
∂Xt
= B A,
∂(trace(AXtB))
∂Xt
=
At Bt,
∂(trace(XX))
∂X
= 2 Xt,
∂(trace(XXt))
∂X
=
2 X,
∂(trace(AXn))
∂X
=
 n−1

j=0
Xj A Xn−j−1
t
,
∂(trace(AXBX))
∂X
=
AtXtBt + BtXtAt,
∂(trace(AXBXt))
∂X
=
AtXBt + AXB,
∂(trace(X−1))
∂X
=
−

X−2t,

28
Chapter 2. Mathematical Foundations
∂(trace(AX−1B))
∂X
=
−

X−1BAX−1
t
,
∂(trace(AB))
∂A
=
Bt + B −diag(B)
2.2.6
Partitioned matrices
Given a partitioned matrix (matrix of matrices) of the form
M =
⎡
⎣
A
B
C
D
⎤
⎦
where A, B, C, and D are of compatible dimensions, then
(1) if A−1 exists, a Schur complement of M is deﬁned as D−CA−1B, and
(2) if D−1 exists, a Schur complement of M is deﬁned as A −BD−1C.
When A, B, C, and D are all n × n matrices, then:
a)
det
⎡
⎣
A
B
C
D
⎤
⎦= det(A)det(D −CA−1B), det(A) ̸= 0
b)
det
⎡
⎣
A
B
C
D
⎤
⎦= det(D)det(A −BD−1C), det(D) ̸= 0
In the special case, we have
det
⎡
⎣
A
B
C
0
⎤
⎦= det(A)det(C)
where A and C are square. Since the determinant is invariant under row, it
follows
det
⎡
⎣
A
B
C
D
⎤
⎦
=
det
⎡
⎣
A
B
C −CA−1A
D −CA−1B
⎤
⎦
=
det
⎡
⎣
A
B
0
D −CA−1B
⎤
⎦
=
det(A)det(D −CA−1B)

2.2. Calculus and Algebra of Matrices
29
which justiﬁes the foregoing result.
Given matrices A ∈ℜm×n and B ∈ℜn×m, then
det(Im −AB) = det(In −BA)
In case that A is invertible, then det(A−1) = det(A)−1.
2.2.7
Matrix inversion lemma
Suppose that A ∈ℜn×n, B ∈ℜn×p, C ∈ℜp×p, and D ∈ℜp×n. Assume
that A−1 and C−1 both exist. Then
(A + BCD)−1 = A−1 −A−1B(DA−1B + C−1)−1DA−1
In the case of partitioned matrices, we have the following result:
⎡
⎣
A
B
C
D
⎤
⎦
−1
=
⎡
⎣
A−1 + A−1BΞ−1CA−1
−A−1BΞ−1
−Ξ−1CA−1
Ξ−1
⎤
⎦
Ξ
=
(D −CA−1B)
provided that A−1 exists. Alternatively,
⎡
⎣
A
B
C
D
⎤
⎦
−1
=
⎡
⎣
Ξ−1
−Ξ−1BD−1
−D−1CΞ−1
D−1 + D−1CΞ−1BD−1
⎤
⎦
Ξ
=
(D −CA−1B)
provided that D−1 exists.
For a square matrix Y , the matrices Y and (I + Y )−1 commute, that is,
given that the inverse exists
Y (I + Y )−1 = (I + Y )−1 Y
Two additional inversion formulas are given below:
Y (I + XY )−1
=
(I + Y X)−1 Y,
(I + Y X)−1
=
I −Y X (I + Y X)−1
The following result provides conditions for the positive deﬁniteness of a par-
titioned matrix in terms of its submatrices. The following three statements are

30
Chapter 2. Mathematical Foundations
equivalent:
1)
⎡
⎣
Ao
Aa
At
a
Ac
⎤
⎦> 0,
2)
Ac > 0,
Ao −AaA−1
c At
a > 0,
3)
Aa > 0,
Ac −At
aA−1
o Aa > 0
2.2.8
Singular value decomposition
The singular value decomposition (SVD) is a matrix factorization that has
found a number of applications to engineering problems. The SVD of a ma-
trix M ∈Ren×m is
M = U S V † =
p

j=1
σj Uj V †
j
where U ∈Reα×α and V ∈Reβ×β are unitary matrices (U† U = U U† = I
and V † V = V V †I); S ∈Reα×β is a real, diagonal (but not necessarily
square); and pmin(α, β). The singular values {σ1, σ2, ..., σβ} of M are deﬁned
as the positive square roots of the diagonal elements of StS, and are ordered
from largest to smallest.
To proceed further, we recall a result on unitary matrices. If U is a unitary
matrix (U† U = I), then the transformation U preserves length, that is:
||U x||
=

(Ux)†(Ux) =
√
x† U† U x,
=
√
x† x = ||x||
As a consequence, we have
||M x||
=
√
x† M† M x =
√
x† V StU† USV † x,
=
√
x† V StSV † x
To evaluate the maximum gain of matrix M, we calculate the maximum norm
of the above equation to yield
max
||x||=1 ||M x||
=
max
||x||=1
√
x† V StSV † x = max
||˜x||=1
√
˜x† V StS ˜x
Note that maximization over ˜x = V x is equivalent to maximizing over x since
V is invertible and preserves the norm (equals 1 in this case). Expanding the

2.3. Directed Graphs
31
norm yields
max
||x||=1 ||M x||
=
max
||˜x||=1
√
˜x† V StS ˜x,
=
max
||˜x||=1

σ2
1|˜x1|2 + σ2
2|˜x2|2 + ... + σ2
β|˜xβ|2
The foregoing expression is maximized, given the constraint ||˜x|| = 1, when
˜x is concentrated at the largest singular value; that is, |˜x| = [1 0 ... 0]t. The
maximum gain is then
max
||x||=1 ||M x||
=

σ2
1|1|2 + σ2
2|0|2 + ... + σ2
β|0|2 = σ1 = σM
In words, this reads The maximum gain of a matrix is given to be the maximum
singular value σM. Following similar lines of development, it is easy to show
that
min
||x||=1 ||M x||
=
σβ = σm,
=
 σp
α ≥β
0
α < β
A property of the singular values is expressed by
σM(M−1)
=
1
σm(M)
2.3
Directed Graphs
A graph G(V, E) is described by a set V = [v1, v2, ...] of vertices and a set
E = [e1, e2, ...] of edges. The edges can be represented by their end points as
ej = (vk, vℓ), which means that the edge ej connects the vertices vk and vℓ
and is directed from vk to vℓ; see Figure 2.1. Considerations concerning graphs
in which for any pair vk and vℓthere is at most one edge (vk
vℓ) and one
edge (vℓ
vk) are presented in the sequel. Associated with graph there is an
(n, n) adjacency matrix A = (ajk) with n being the number of vertices of the
graph to signify which vertices of the graph are connected by an edge
ajk =
 •
if there exists an edge (vk
vj)
0
otherwise
A graph G(V, E) is completely described by the matrix A.

32
Chapter 2. Mathematical Foundations
Figure 2.1: Directed graph
A path is a sequence of edges [(vj1 vj2)(vj2 vj3) · · · (vk vℓ)] such that
the ﬁnal vertex and the initial vertex of succeeding edges are the same. For
example, [(v3
v1)(v1
v2)(v2
v4)] is a path from v3 to v4 in the graph of
Figure 2.1, but there is no path from v5 to v1.
Deﬁnition 2.3.1 Two vertices vk and vℓare said to be strongly connected if
there is a path from vk to vℓas well as a path from vℓto vk. The graph is called
strongly connected if every pair of vertices vk and vℓis strongly connected.
In the graph G(V, E) the subset of vertices that are strongly connected to a
given vertex vj forms an equivalence class K(vj) within the set V. For example,
K(v1) = [v1, v2, v3, v4]; see Figure 2.1. The adjacency matrix A = (ajk) is
given by
A =
⎡
⎢⎢⎢⎢⎢⎢⎣
•
0
•
0
0
0
•
0
0
•
0
•
0
•
•
0
0
0
0
•
•
0
0
0
0
•
0
•
0
•
0
•
0
0
•
0
⎤
⎥⎥⎥⎥⎥⎥⎦
The reachability matrix R = (rjk) describes which pairs of vertices are
connected by a path
rjk =
 •
if there exists a path from vk to vj
0
otherwise

2.4. Notes and References
33
The reachability matrix R and the adjacency matrix A are related by
R =
n−1

j=1
Aj
where the multiplication and addition of the elements of A are carried out
according to the following
ajkakm
=
 •
if ajk = • and akm = •
0
otherwise
ajk + amℓ
=
 0
if ajk = 0 and amℓ= 0
•
otherwise
A cycle is a path with identical initial and ﬁnal vertices. For example in Figure
2.1, [(v3 v1)(v1 v2)(v2 v3)] form a cycle. A set of vertex-disjoint cycles is
said to be a cycle family. The cycle mentioned above represents a cycle family
with only a single cycle. There is also another cycle family consisting of the
cycles [(v3 v4)(v4 v2)(v2 v3)] and indeed the self-cycle [(v1 v1)].
2.4
Notes and References
The topics covered in this chapter are meant to provide the reader with a general
platform containing the basic mathematical information needed for further ex-
amination of switched time-delay systems. These topics are properly selected
from standard books and monographs on mathematical analysis. For further
details, the reader is referred to the standard texts [147, 152, 404] where funda-
mentals of linear algebra and related math facts are provided. Graph search al-
gorithms for determining paths, cycles, reachability matrices, etc. can be found
in [69] .

Chapter 3
Historical Perspective and
Scope
Many real problems are considered to be “large scale” by nature and not by
choice. Some important attributes of large-scale systems are
1. They often represent complex, real-life systems,
2. Their structures follow hierarchical (multilevel) order,
3. Their dynamics involve time-delays and are subject to uncertainties,
4. Decentralized information structures are the rule and not the exception.
These attributes depict systems dealing with societal, business, and manage-
ment organizations, the economy, the environment, data networks, electric
power, transportation, information systems, aerospace (including space struc-
tures), water resources, and, last but not least, energy. Such systems that are
eventually used in support of human life are complex in nature. As a result of
these important properties and potential applications, several researchers have
paid a great deal of attention to various facets of large-scale systems such as
modeling, model reduction, control, stability, controllability, observability, op-
timization, and feedback stabilization. These concepts have been applied to
various problems and have helped with the development of different notions of
systems analysis, design, control, and optimization.
In this chapter, we follow a chronological order in providing a uniﬁed dis-
cussion about the concepts and techniques of large-scale systems with partic-
ular emphasis on fundamental issues, basic deﬁnitions, and main directions of
development. Whenever deemed convenient, we compare among their merits,
features, and computational requirements.
35

36
Chapter 3. Historical Perspective and Scope
3.1
Overview
An integral assumption in almost all of the conventional control theories and
methods, for quite some time, has been “centralization” [307], meaning that
all the computations and measurements based upon system information are lo-
calized at a given center, very often a geographical position. A prime example
of a centralized system is a computer-controlled experimental testbed physi-
cally located in a laboratory setting. This concept becomes unreliable when the
system is composed of several subsystems and/or is geographically distributed
over wide areas. Consider, for example, water systems.
It has been recognized [22, 303, 323] that a notable characteristic of most
large-scale systems is that centrality fails to hold due to either the lack of cen-
tralized computing capability or centralized information. The important points
regarding large-scale systems are that some of these systems are often sep-
arated geographically, and their treatment requires consideration of not only
economic costs, as is common in centralized systems, but also such important
issues as reliability of communication links, value of information, environmen-
tal consciousness, and machine intelligence quotient (MIQ), to name a few. It
is for the decentralized and hierarchical control properties and potential appli-
cations of such exciting areas as intelligent large-scale systems in which fuzzy
logic and neural networks are incorporated within the control architecture that
many researchers have devoted a great deal of effort to large-scale intelligent
systems in recent years.
3.2
Decomposition-Coordination Methods
A fairly general dynamic optimization problem could be described as follows:
xj(k + 1)
=
fj[xj(k), uj(k), k]
xj(0)
=
xj0, j = 1, ..., Nns, k = 0, ..., P −1
(3.1)
where the interconnections and terminal constraints are speciﬁed by
for j = 1, ..., ns,
ns

j=1
hj[xj(k), uj(k), k] ≤0, k = 0, ..., P −1
(3.2)
Rj[xj(k), uj(k), k] ≤0, , k = 0, ..., P −1
(3.3)
Qj[xj(P)] ≤0
(3.4)

3.2. Decomposition-Coordination Methods
37
The performance measure is
J =
ns

j=1
{Sj[xj(P)] +
P −1

k=0
Fj[xj(k), uj(k), k]}
(3.5)
Equations (3.1)-(3.5) represent ns-coupled subsystems in discrete-time format
where xj(k) and uj(k) are the respective state and control vectors. The objec-
tive is to determine the optimal sequences [{xj ∗(k), uj ∗(k)}, j = l, , ns]
which minimize the performance measure (3.5) subject to the constraints (3.1)-
(3.4). This is a fairly general class of constrained optimization problems. It has
been shown in [137, 138, 164] that the introduction of the dual problem re-
sults in a natural two-level formulation of the optimization problem with the
ﬁrst level solving the primal problem and the second level solving the dual
problem. Thus the procedure involves the formulation and solution of the La-
grangian dual of the above problem. The dual problem is
max
λ
Φ(λ),
λ ≥0
(3.6)
where
Φ(λ) := min
x,u L(x, u, λ)
(3.7)
and the Lagrangian functional is
L(x, u, λ)
=
ns

j=1
{Sj[xj(P)] +
P −1

k=0
Fj[xj(k), uj(k), k]
+
λt
jhj[xj(k), uj(k), k]}
(3.8)
Due to the fact that the interconnection constraints (3.2) provide the only
coupling between the subsystems, (3.8) could be separated into additive sub-
Lagrangians, and consequently ns independent minimization problems are de-
ﬁned. These constitute the ﬁrst level, while solution of (3.6) and (3.7) speciﬁes
the second level.
Observe from (3.6)-(3.8), the gradient of the dual problem is exactly the
value of the coupling constraint. While this observation enhances the dual opti-
mization approach, it implies that the overall optimum is reached only when the
second-level solution converges. On the other hand, since the dual function is
concave without any convexity requirements on the original system, the global
optimum is assured. In addition, the computational efforts at the ﬁrst level are
still burdensome, although the dimensions are reduced. However, they can be

38
Chapter 3. Historical Perspective and Scope
implemented by making use of parallel processing capabilities since each sub-
system Lagrangian can be operated from the remainder. Generally, it is imprac-
tical for the ﬁrst level to minimize the Lagrangian as an explicit function of the
multipliers, and therefore it is always desirable to change the problem into a se-
quential search for the optimum. The ﬁrst-level minimization problems can be
further decomposed in time, thereby leading to the development of a three-level
optimization algorithm. This algorithm utilizes the dual concept to parameter-
ize the local problems by the index k, the discrete instant, and the potential of
this algorithm is explained in [331]. Also, it was pointed out in [331, 332] the
fact that most of the available real-time multilevel techniques are best suited
for slow dynamic systems due to the requirement for repeated iterations.
3.2.1
Hierarchical structures
Extending on the ideas of the foregoing section, we must mention that one of
the earlier attempts in dealing with large-scale systems was to “decompose” a
given system into a number of subsystems for computational efﬁciency and de-
sign simpliﬁcation. The “decomposition” approach divides the original system
into a number of subsystems involving certain values of parameters. Each sub-
system is solved independently for a ﬁxed value of the so-called “decoupling”
parameter, whose value is subsequently adjusted by a coordinator in an appro-
priate fashion so that the subsystems resolve their problems and the solution to
the original system is obtained. The goal of the coordinator is to arrange the
activities of the subsystems to provide a feasible solution to the overall system.
This exchange of solution (by the subsystems) and coordination (interaction)
vector (by the coordinator) will continue until convergence has been achieved.
A uniﬁed approach to multilevel control and optimization of dynamic sys-
tems has been developed in [196]-[199] [201] using the generalized gradients
technique. The basic motivations behind this approach were the following:
1. In the context of two-level structures, the ordering of an optimizing level
(control) and a coordination level (supervisory) is immaterial,
2. There is no restriction on the variables to be handled (optimized or ma-
nipulated) on each level,
3. Problems of physical realizability of the generated control actions, sin-
gular arcs, and interaction feasibility are critical in any two-level control
structure,
4. Within the existing capabilities of digital computers, a single processor

3.2. Decomposition-Coordination Methods
39
is always used for problem solution, and hence, the computational effort
should be adequately shared between levels.
Several candidate computation structures have been developed; for a de-
tailed analysis see [194]-[199].
3.2.2
Decentralized control
Most practical large-scale systems are characterized by a great multiplicity of
measured outputs and inputs. For example, an electric power system has several
control substations, each being responsible for the operation of a portion of the
overall system. This situation arising in a control system design is often referred
to as decentralization. The designer for such systems determines a structure for
control that assigns system inputs to a given set of local controllers (stations),
which observe only local system outputs. In other words, this approach, from
now onward called decentralized control, attempts to avoid difﬁculties in data
gathering, storage requirements, computer program debugging, and geograph-
ical separation of system components. A preliminary comparison between de-
centralized and hierarchical control can be given here. In hierarchical control,
a decomposition in system structure will lead to computational efﬁciency. In
decentralized control, on the other hand, a decomposition takes place with the
system’s output information leading to simpler controller structures and com-
putational efﬁciency.
Experience research results have concluded that the application of the hi-
erarchical multilevel structures to systems engineering problems is guaranteed
to yield a “coordinated control” which, iteratively, approach a “decentralized
control.”
A decentralized approach to hierarchical optimization can be made effec-
tive if the large system is composed of weakly coupled subsystems, or a de-
composition and rearrangement of variables are used to achieve weak coupling
as is the case of sparse systems. In situations when the subsystems are strongly
connected and cannot be simply reconstituted to reduce the strength of the cou-
plings, the assumption of weak coupling may produce gross inaccuracies of the
obtained results. Even in cases when the assumption is appropriate, it is often
not clear what roles should be played by the coordinator and the information
structure to achieve the beneﬁts of the decentralized optimization strategies.

40
Chapter 3. Historical Perspective and Scope
3.3
Multilevel Optimization of Nonlinear Systems
In this section, we consider the optimal control of a class of large-scale nonlin-
ear dynamical systems described by
˙x(t)
=
f(t, x, u)
(3.9)
where x(t)
∈ℜn is the state vector and u(t)
∈ℜmj is the control input
at time t ∈ℜ. The function f : ℜ× ℜn × ℜm is continuous on a bounded
region D ∈ℜn+1 and is locally Lipschitzian with respect to x ∈D, so that
for every ﬁxed control function u(t), a unique solution x(t; to, xo) exists for all
initial conditions (to, xo) ∈D and all t ∈[to, t1] and D = {(t, x) : to ≤t ≤
t1, ||x|| ≤ϱ < +∞}.
Now we view (3.9) as a large-scale or interconnected system. In either
case, dynamic optimization by standard methods becomes impractical due
the excessive requirements of computer storage or processing time. Following
[136, 324, 335], the problem becomes tractable by an appropriate decomposi-
tion of the system and optimization of the subsystems. At start, we re-express
(3.9) as a collection of ns coupled subsystems described by
˙xj(t) = gj(t, xj, ujc) + hj(t, x),
j = 1, 2, ..., ns
(3.10)
where xj(t) ∈ℜnj is the state vector of the jth subsystem and ujc(t) ∈ℜnj
is the local control input of the jth subsystem so that
ℜn
=
ℜn1 × ℜn2 × · · · × ℜnns
ℜm
=
ℜm1 × ℜm2 × · · · × ℜmns
n
=
ns

j=1
nj, m =
ns

j=1
mj
(3.11)
In addition, gj : ℜ× ℜnj × ℜmj →ℜnj represents the dynamics of the decou-
pled subsystems
˙xj(t)
=
gj(t, xj, ujc),
j = 1, 2, ..., ns
(3.12)
which are all completely locally controllable about any admissible trajectory
xj(t; to, xjo) and h : ℜ×ℜn →ℜnj is the function that represents the coupling
pattern of the jth subsystem within the overall system (3.9).
3.3.1
Local-level optimization
We now seek local dynamic optimization using the control law
ujc(t) = Kj(t, xj),
j = 1, 2, ..., ns
(3.13)

3.3. Multilevel Optimization of Nonlinear Systems
41
For each isolated subsystem (3.12) is optimized with respect to the local per-
formance index
Jj(to, xjo, ujc) = pj[to, xj(t1)] +
 t1
to
Mj[t, xj(t), ujc(t)]dt
(3.14)
where pj : ℜ× ℜnj →ℜ+, Mj : ℜ× ℜnj × ℜmj →ℜ+ are functions of the
class C2 in all arguments [168], and xj(t) denotes the solution xj(t; to, xjo) of
(3.12) for the local control function ujc(t).
It must be born in mind that the decomposition of (3.9) into (3.12) entails
that the jth subsystem has low order and/or has a simple structure so that it is
a straightforward task to determine the optimal control law
u∗
jc(t) = Kjc(t, xj),
j = 1, 2, ..., ns
(3.15)
which yields the optimal cost
J∗
j (t, xjo) = Jj(t, xjo, K∗
j (t, xjo))
(3.16)
Remark 3.3.1 One should realize that there are two sources of performance
degradation: one is due to the interconnection pattern which imposes com-
putational constraints and the other arises from certain structural considera-
tions that should be taken into account when designing controllers for inter-
connected systems. Generally speaking, a system that is composed of coupled
subsystems may undergo structural perturbations whereby subsystems are dis-
connected (and again connected) in various ways during the operation. Typical
examples are found in power systems, chemical plants, and trafﬁc networks.
Therefore, in order to cope with the participation nature of the subsystems
while guaranteeing a satisfactory performance of the system, we should pre-
serve as much as possible the autonomy of each isolated subsystem (3.12).
This leads to expressing the performance index for the overall system as:
J(t, xo, uc(t))
=
ns

j=1
Jj(t, xo, ujc(t))
uc(t)
=
[ut
1c, ut
2c, · · · , ut
nsc]t, ∈ℜm
(3.17)
This implies that each isolated subsystem (3.12) is optimized with respect to
its own performance index (3.16) regardless of the behavior of the other sub-
systems. In this regard, the couplings among the subsystems are regarded as
perturbation terms.

42
Chapter 3. Historical Perspective and Scope
A crucial point to observe is that maintaining the subsystem autonomy
means ignoring possible beneﬁcial effects of the interconnection patterns. More
about this point will be mentioned in the subsequent sections. For the time be-
ing, we take the view that any use of the beneﬁcial effects of couplings will
naturally increase the dependence among the subsystems and, hence, increase
the liability to malfunctioning under structural perturbations.
In brief, the optimal performance index
J∗(t, xo)
=
ns

j=1
J∗
j (t, xjo)
(3.18)
cannot be achieved by using only the local control uc(t), unless all the subsys-
tems are decoupled (hj ≡0, j = 1, 2, .∗, s). This simply means that uc(t) is
near-optimal. Let ˜xj = ˜xj(t; to, xjo) denote the solution of the coupled system
(3.10), then the value of the associated performance index becomes
˜J(t, xo) =
ns

j=1

pj[to, ˜xj(t1)] +
 t1
to
Mj[t, ˜xj(t), Kjc(t, ˜xj)]dt

(3.19)
Deﬁne the degree of suboptimality as ε. Hence it follows that [322]
˜J(t, xo) ≤(1 + ε) J∗(t, xo),
∀(t, xo) ∈D
(3.20)
It is readily evident that the suboptimality index ε resulting from the optimal
local control
˙xj(t) = gj(t, xj, Kjc(t, xj)) + hj(t, x),
j = 1, 2, ..., ns
(3.21)
depends on the size of the couplings hj(t, x); then it could furnish a measure
of the deterioration of the performance.
In the sequel, we seek to derive conditions on hj(t, x) to guarantee a pre-
scribed value of the suboptimality ε.
Remark 3.3.2 It is signiﬁcant to observe that any procedure to derive the sub-
optimality index ε would involve only bounds on the norms of the coupling func-
tions hj(t, x). The obtained results are naturally valid for a class of hj(t, x)
and, thus, do not depend on the actual form of these nonlinear functions. This
particular aspect is of major importance in the context of modeling uncertain-
ties and possible variations in the shape of nonlinear couplings during opera-
tion. An improvement in the system performance is possible if ||hj(t, x)|| can
be reduced. It was proposed in [322] to accomplish this improvement by us-
ing additional control functions that neutralize the effect of interconnections.
These functions are generated by a global controller on a higher level using
the states of the subsystems.

3.3. Multilevel Optimization of Nonlinear Systems
43
In this regard, the interconnected subsystems are described by
˙xj(t) = gj(t, xj, ujc) + hj(t, x, ujg),
j = 1, 2, ..., ns
(3.22)
where
h
=

ht
1, ht
2, · · · , ht
ns

∈ℜ× ℜn × ℜm →ℜn
ug
=
 ut
1g, ut
2g, · · · , ut
nsg
t ∈ℜm →ℜn
(3.23)
Deﬁne the functions
V : ℜ× ℜn →ℜ+, p : ℜ× ℜn →ℜ+, M : ℜ× ℜn × ℜm →ℜ+
such that
V(t, x)
=
ns

j=1
Vj(t, xj), p(t, x) =
ns

j=1
pj(t, xj),
M(t, x, uc)
=
ns

j=1
Mj(t, xj, ujc)
Kc
=

Kt
1c, Kt
2c, · · · , Kt
nsc
t ∈ℜ× ℜn →ℜm (3.24)
where Vj(t, xj) belongs to the class C2 in both arguments and satisﬁes the
Hamilton-Jacobi equation
∂Vj(t, xj)
∂t
+ ∇Vt
j(t, xj)gj[t, xj, Kjc(t, xj)]
Mj[t, xj, Kjc(t, xj)]
=
0,
j = 1, 2, ..., ns, ∀(t, x) ∈D (3.25)
The following result is established in [322, 324].
Theorem 3.3.3 Consider the subsystem (3.21) and let the couplings hj(t, x)
satisfy the constraint
∇Vt(t, x)h(t, x) ≤
ε
1 + ε M[t, x, Kc(t, x)],
∀(t, x) ∈D
(3.26)
Then the overall system (3.21) is suboptimal with index ε.
Remark 3.3.4 It must be observed that we can view inequality (3.26) as im-
posing constraints on the couplings hj(t, x) so as to guarantee a prescribed
suboptimality index ε. Another view is that, given a particular pattern of cou-
pling hj(t, x), inequality (3.26) provides a way to estimate the suboptimality
index ε.

44
Chapter 3. Historical Perspective and Scope
Building on Remark 3.3.4 and given the global control function ug(t), the fol-
lowing constraint on couplings hj(t, x, ujg) was presented in [322]:
||∇V(t, x)||||h(t, x, ug)|| ≤
ε
1 + ε M[t, x, Kc(t, x)],
∀(t, x) ∈D (3.27)
It is obvious that inequality (3.27) implies inequality (3.26). Interestingly
enough, provided that expressions for the function V and M are available,
inequality (3.27) can then be used to get an explicit relationship between the
index ε and the norm ||h(t, x, ug)||. In turn, this can be used in the course of de-
signing ug(t). One strong candidate for this is the case of local linear quadratic
regulators (where local free subsystems are linear and the optimization cost is
quadratic). We will elaborate more on this case in later sections.
3.4
Decentralized Nonlinear Systems
In this section, we take another direction and look at the control of multi-input
multi-output (MIMO) systems where constraints are placed on the information
ﬂow. In particular we consider the control of decentralized nonlinear systems
(DNS) where there are constraints on information exchange among subsys-
tems. In this context, decentralized control systems often arise from either the
physical inability of subsystem information exchange or the lack of computing
capabilities required by a single central controller. In addition, it is proved more
convenient to design a controller with decentralized structure than a controller
for a composite MIMO system.
Within a decentralized framework, the overall system is broken into ns sub-
systems each with its own inputs and outputs. A decentralized control law is
then deﬁned using local subsystem signals. Thus subsystem j does not have
access to the signals associated with subsystem m, m ̸= j. Figure 3.1 shows
a decentralized system with four subsystems, each inﬂuenced by couplings to
one or more of the other subsystems, where the notation Sj represents the jth
subsystem and cjm is a coupling that deﬁnes how the jth subsystem inﬂuences
the mth subsystem. In this section, we consider a standard MIMO system de-
scribed by
˙η(t)
=
fη(η) + gηu
y
=
hη(η)
(3.28)
where η(t)
∈ℜn is the state vector, u(t)
∈ℜm is the control input, and
y(t) ∈ℜm is the output at time t ∈ℜ. For the purpose of simplicity in ex-
position, we let η := [ηt
1, ηt
2, · · · , ηt
ns]t where ns signiﬁes the number of

3.4. Decentralized Nonlinear Systems
45
Figure 3.1: A decentralized system structure
subsystems. We will assume that the decomposition of (3.28) into subsystems
is achieved by some means. When communication constraints are incorporated
into the design of a control system, the subsystems may be easily deﬁned. Alter-
natively, choosing a decentralized design approach for computational or other
design considerations, the deﬁnition of a subsystem may often be determined
due to physical grounds such as strong input-output pairing relationships. To
illustrate this, consider two bodies are being connected by a spring. Removing
the spring, the subsystems would then be independent from one another. Thus,
the spring acts as an interconnection between the subsystems. Hereafter, we
will assume that the deﬁnition of the subsystems is obvious from the problem
statement.
To identify the subsystems, we let Tj : ℜnj →ℜnj, xj = Tj(ηj) be an
appropriate transformation such that the subsystem Sj has dynamics deﬁned
by:
˙xj(t)
=
fj(xj) + gjuj + cj(t, x)
Sj :
yj
=
hj(xj)
(3.29)
where for j = 1, ..., ns, xj(t) ∈ℜn is the subsystem state vector, uj(t) ∈

46
Chapter 3. Historical Perspective and Scope
ℜm is the subsystem control input, and y(t)
∈ℜm is the subsystem output
at time t ∈ℜ. Also, we let x := [xt
1, xt
2, · · · , xt
ns]t. The vector function
cj(t, x) accounts for the coupling pattern affecting subsystem Tj. For well-
posedeness, only local measurements are used in the transformation Tj. The
procedure underlying the change from (3.28) to (3.29) belongs to the family of
feedback linearization [152].
The goal now is to design a decentralized controller for systems of the
type (3.29) in which the interconnections cj(t, x) do not necessarily satisfy
matching conditions, and the strengths of the connections may be bounded by
arbitrary smooth functions of the subsystem outputs. To simplify the notation,
we consider the subsystem (3.29) transformed into
˙xj,1(t)
=
fj,1(˜xj,1) + ˜xj,1 + cj,1(t, x)
...
Sj :
˙xj,ns−1(t)
=
fj,ns−1(˜xj,ns−1) + ˜xj,ns + cj,ns−1(t, x)
˙xj,ns(t)
=
fj,ns−1(˜xj,ns−1) + uj + cj,ns−1(t, x)
yj
=
xj,1
(3.30)
with ˜xj,k = [xj,1, ..., xj,k]t and cj,m represents the coupling among subsys-
tems. Our immediate task is to design a controller which forces yj →0, j =
1, ..., ns when the couplings cj,m satisfy certain bounding conditions which
will be deﬁned shortly. We observe here that each cj,m is inﬂuenced by sub-
systems S1, ..., Sns. In line of the development of the previous section, we will
consider that the couplings are modeled by
˙ζj(t)
=
qj(t, x)
Cj :
cj(t, x)
=
sj(t, ζj, x)
(3.31)
where ζj(t)
∈ℜmj and cj(t, x)
∈ℜnj. Notice that Cj combines the ef-
fects of the individual couplings Cj,1, Cj,ns. It is obvious that model (3.31)
includes the case of static couplings (cj(t, x) = sj(t, x)) and complete decou-
pling (cj(t, x) ≡0) corresponding to isolated subsystems.
3.4.1
Diagonal dominance condition
In this section, the immediate task is to develop a static controller for decen-
tralized systems of the type (3.30). Our tool is Lyapunov-based design (LBD)

3.4. Decentralized Nonlinear Systems
47
to help in placing bounds on states which may be used as inputs to a ﬁnite
approximator used within the control law. An integral portion of this design is
ﬁnding robust controllers when the interconnections are ignored (case of iso-
lated subsystems). By making each controller “very robust,” the effects of the
couplings are dominated by the inherently robust local controllers. In this re-
gard, a powerful tool often used in the design of decentralized controllers is the
concept of diagonal dominance for which the following theorem provides one
possible application.
Theorem 3.4.1 Given matrices W ∈ℜm×n, S ∈ℜn×n where W = [wj,k]
and S = diag(s1, ..., sn). The inequality
xt(W + S)x ≥0
holds for all x if
sj ≥n(1 +
n

k
wt
k,j)
deﬁned along the columns of W or
sk ≥n(1 +
n

k
wt
k,j)
deﬁned along the rows of W.
The proof of Theorem 3.4.1 can be found in [344].
Remark 3.4.2 The relevance of Theorem 3.4.1 stems from its basic role to de-
termine how to accommodate the couplings while stabilizing each subsystem
individually. That is, the couplings do not cause system instability. It should
be noted that Theorem 3.4.1 only provides sufﬁcient, and not necessary, con-
ditions on the choice of the diagonal terms. This is in fact the case of almost
all decentralized techniques. It simply implies that the results of Theorem 3.4.1
may be rather conservative for certain applications.
3.4.2
Static controller design
A decentralized control design is now developed for the family of subsystems
(3.30) under the coupling dynamics governed by
˙ζj(t)
=
qj(t, ζj, x)
Cj :
cj,k
=
sj,k(t, ζj ˜xj,k, y)
(3.32)

48
Chapter 3. Historical Perspective and Scope
where the coupling is bounded by
|cj,k| = ϱ + ξj,k(˜xj,k)
ns

m=1
ψj,m(|ym|)
(3.33)
where ξj,k : ℜk →ℜ+ and ψj,m : ℜ→ℜ+ are smooth nonnegative functions
which are assumed bounded for all bounded inputs and ϱ ∈ℜ. It must be
asserted that the bound on cj,k is deﬁned in terms of other subsystem outputs
through the elements ψj,m. Additionally, it is required that the Cj-dynamics are
input-to-state stable [152] so that there exists some Vj(t, ζj) such that
κ1j(ζj) ≤Vj(t, ζj) ≤κ2j(ζj)
˙Vj(t, ζj) ≤−κ3j(ζj) + θ(x)
(3.34)
where κ1j(ζj), κ2j(ζj), and κ3j(ζj) are class-K∞. Observe that if the con-
trolled state x is bounded so is the coupling vector ζj. It follows from [152]
that given a nonnegative continuous function ψj,m : ℜ→ℜ+ there exists a
nonnegative continuous function πj,m : ℜ→ℜ+ such that
ψ(|x|) ≤|x|n π(|x|) + e
(3.35)
with n > 0, e ≥0 are ﬁnite constants. Proceeding further, we assume that
there exist known constants ej,k and smooth functions πj,k(|yk|) such that
ψj,k(|yk|) ≤πj,k(|yk|)

|yk| + ej,k,
∀yk ∈ℜ
(3.36)
Our objective now is to design a decentralized controller to render yj →0, j =
1, ..., ns. At this stage, we introduce the subsystem error
εj,k = xj,k −σj,k−1(˜xj,k−1), j = 1, ..., ns, k = 1, ..., nj
(3.37)
where the term σj,k will be deﬁned shortly with σj,0 = 0. On taking the deriva-
tive of (3.37), we get:
˙ε
=
fj,k + xj,k+1 + cj,k
−
k−1

m=1
∂σj,k−1
∂xj,m
[fj,m + xj,m+1 + cj,m]
=
fj,k + εj,k+1 + σj,k −
k−1

m=1
∂σj,k−1
∂xj,m
[fj,m + xj,m+1]
+
cj,m −
k−1

m=1
∂σj,k−1
∂xj,m
cj,m, j = 1, ..., ns, k = 1, ..., nj
(3.38)

3.4. Decentralized Nonlinear Systems
49
Now letting
σj,k
=
−(δj + νj,k(˜xj,k))εj,k −εj,k−1
−
fj,k +
k−1

m=1
∂σj,k−1
∂xj,m
[fj,m + xj,m+1]
(3.39)
we get
˙εj,k
=
−(δj + νj,k)εj,k −εj,k−1 + εj,k+1 + cj,m
−
k−1

m=1
∂σj,k−1
∂xj,m
cj,m
(3.40)
for k = 1, ..., nj −1 where εj,0 = 0 and the terms νj,k will be decided upon
to accommodate the couplings. On deﬁning the feedback control law as
uj
=
−(δj + νj,k(˜xj,k))εj,k −εj,k−1
−
fj,nj +
nj−1

m=1
∂σj,ns−1
∂xj,m
[fj,m + xj,m+1]
(3.41)
we obtain
˙εj,ns
=
−(δj + νj,k)εj,ns −εj,ns−1 + cj,ns
−
ns−1

m=1
∂σj,ns−1
∂xj,m
cj,m
(3.42)
In terms of ε = εj,1, ..., εj,ns]t, we express the subsystem error dynamics
into the form
˙ε
=
Ajεj + Dj
Aj
=
⎡
⎢⎢⎢⎢⎢⎢⎣
−δj
1
0
· · ·
0
−1
−δj
1
...
0
−1
−δj
...
...
1
0
· · ·
−1
−δj
⎤
⎥⎥⎥⎥⎥⎥⎦
,
Dj
=
⎡
⎢⎣
−νj,kεj,1 + cj,1
...
−νj,nsεj,ns + cj,ns −ns−1
m=1
∂σj,ns−1
∂xj,m cj,m
⎤
⎥⎦
(3.43)
The following theorem summarizes the resulting closed-loop stability proper-
ties of the proposed static controller.

50
Chapter 3. Historical Perspective and Scope
Theorem 3.4.3 Given the subsystem (3.30) with interconnections bounded by
(3.33), the decentralized control law (3.41) with
νj,k
=
μjz2
j,k + ζj(yj), μj > 0
zj,k
=
ϱ

1 +
k−1

m=1
|∂σj,k−1
∂xj,m
|

+

ξj,k +
k−1

m=1
ξj,m|∂σj,k−1
∂xj,m
|
ns

r=1
ej,r

+
ns
4√c

ξj,k +
k−1

m=1
ξj,m|∂σj,k−1
∂xj,m
|
2
, c > 0
will ensure that the subsystem error εj (and thus each subsystem output yj) is
uniformly ultimately bounded.
The proof of Theorem 3.4.3 can be found in [344] based on some algebraic
bounding inequalities.
While the results attained guarantee decentralized controlled subsystems,
the price is a residual error of the subsystem output trajectories in the form of
a ball around the origin.
Remark 3.4.4 It is crucial at this stage to mark our position. In the previous
two sections, we focused on decentralized control of nonlinear systems and
showed how difﬁcult the design problem is. We have seen that the chief effort
has to be concentrated on solving a nonlinear Hamilton-Jacobi equation or
estimating bounds on the nonlinearities. To reach at practical results, we will
relax the situation a little bit and start by dealing with a class of dynamical
interconnected systems, which we call “nominally linear uncertain systems.”
Then we end by “linear uncertain systems.” We added uncertainties to obtain
robust design results for the continuous-time and discrete-time cases.
3.4.3
Illustrative example 3.1
Consider the following large-scale system:
A
=
⎡
⎢⎢⎢⎢⎢⎢⎣
0.6
0
0
1
0.2
0
0.2
2.3
0.1
0
0
0.3
0
0
−1.5
0
0
0
0
0
0.7
1.1
0
0
0
0
0
0
−0.8
0
0
0
0
0
0.5
0.8
⎤
⎥⎥⎥⎥⎥⎥⎦

3.5. Nominally Linear Systems—Continuous Case
51
Go
=
[0.1 0.2 0.4 0.3], Gdo = [0.01 0 0.01 0]
Bo
=

0
0.3

, Co =
 1
10
0
0
0
0
10
10

, Cd =
 2
1
0
0
0
0
1
3

,
Do
=

0.4
0.2

, Ψo =

0.01
0.01

, Φ = 0.1
Using the MATLAB R⃝-LMI solver, the feasible solutions of the respective de-
sign methods yield the feedback gain matrices:
Ks
=
 −34.5094
−4.9061
−52.4436
−130.5408
17.5392
−12.7566
79.5070
157.7008

Kd
=
 −34.5094
−4.9061
−52.4436
−130.5408
17.5392
−12.7566
79.5070
157.7008

Ko
=
⎡
⎢⎢⎣
−55.2134
15.8031
69.2668
−18.6633
−18.4083
5.0529
5.2346
−0.5445
⎤
⎥⎥⎦
3.5
Nominally Linear Systems—Continuous Case
Consider a class of continuous nominally linear uncertain systems S composed
of ns subsystems where the jth subsystem is depicted in Figure 3.2 and de-
scribed by
˙xj(t)
=
[Aj + ΔAj(rj(t))]xj(t) + [Bj + ΔBj(sj(t))]uj(t) + Cjvj(t)
+
Zj + hj(t), j = 1, 2, ..., ns, xj(0) = xjo
(3.44)
Zj(t)
=
ns

k̸=j
Ajkxk(t), hj(t) =
ns

k̸=j
Hjk(t, rj(t), xk(t))
yj(t)
=
xj(t) + wj(t)
(3.45)
where for j ∈{1, ..., ns}, xj(t) ∈ℜnj is the state vector, uj(t) ∈ℜmj
is the control input,
yj(t)
∈ℜnj
is the measured output,
vj(t)
∈ℜsj
is the bounded disturbance, wj(t)
∈ℜnj is the measurement error, and
Zj(t)
∈ℜnj is the interconnection vector with other subsystems. The ma-
trices Aj ∈ℜnj×nj, Bj ∈ℜnj×mj,
Cj ∈ℜnj×sj, Ajk ∈ℜnj×nk are
real and constants. The uncertain matrices ΔAj(rj(t)) and ΔBj(sj(t)) de-
pend continuously on the Lebesgue-measurable parameters rj ∈ℑj ⊂ℜpj
and sj ∈℘j ⊂ℜqj, respectively, where ℑj and ℘j are appropriate compact
bounding sets. Also, the term Cjvj(t) accounts for external input uncertainty,

52
Chapter 3. Historical Perspective and Scope
Zj(t) ∈ℜnj is the coupling vector with other subsystems, and hj(t) ∈ℜnj
contains the uncertainties in the interconnections between the jth subsystem
and the other subsystems. This system is depicted in Figure 3.2.
Figure 3.2: Additive-type uncertain subsystem
Assumption 3.1: The pair (Aj, Bj) is stabilizable for all j ∈{1, ..., ns}
Assumption 3.2:
1. There exist matrix functions Dj(.) and Ej(.) of appropriate dimensions
whose entries are continuous on ℜpj and ℜqj, respectively, such that
ΔAj(rj) = BjDj(rj),
ΔBj(sj) = BjEj(sj)
(3.46)
2. There exists a constant matrix function Fj such that
Cj = BjFj
(3.47)
3. ϱsj = maxsj∈℘j ||Ej(sj)|| < 1
Assumption 3.3: The interactions Hjk(t, rj(t), xk(t)) are assumed to be
carathedory functions (see the Appendix). Furthermore, they are bounded in
the form
||Hjk(t, rj(t), xk(t))||
≤
ns

k̸=j
||ΔAjk(t, rj)||||xk||
≤
ns

k̸=j
γjk||xk||, j = 1, ..., ns
∀
(t, rj(t), xk(t)) ∈ℜ× ℜpj × ℜnj (3.48)

3.5. Nominally Linear Systems—Continuous Case
53
where γjk ≥0, j = 1, ..., ns, k = 1, ..., ns are n2
s scalars representing upper
bounds for the uncertainties among the subsystems. The overall system under
consideration can be written as
˙x(t)
=
[A + ΔA(r) + M]x(t) + [B + ΔB(s)]u(t)
+
Cv + H(t, x, r),
x(0) = xo
(3.49)
y(t)
=
x(t) + w(t)
(3.50)
where
x = [xt
1, xt
2, ..., xt
ns]t ∈ℜn, u = [ut
1, ut
2, ..., ut
ns]t ∈ℜm
y = [yt
1, yt
2, ..., yt
ns]t ∈ℜn, v = [vt
1, vt
2, ..., vt
ns]t ∈ℜs
w = [wt
1, wt
2, ..., wt
ns]t ∈ℜn
are the state, control, measured state, disturbance, and measurement error of
the overall system, respectively, with
n =
ns

k=1
nk, m =
ns

k=1
mk, s =
ns

k=1
sk
The vectors M and H denote the couplings and the associated uncertainties
within the overall system. Furthermore, we have
A
=
diag(Aj), B = diag(Bj), C = diag(Cj),
ΔA(.)
=
diag(ΔAj(.)), ΔB(.) = diag(ΔBj(.))
In view of (3.44) and (3.49), it should be observed that both M and H have
zero diagonal elements, that is, (Mjj = 0, Hjj = 0, j = 1, ..., ns).
Remark 3.5.1 In view of the results of Chapter 2, it is emphasized that if the
family of subsystems (3.44)-(3.45) has unstable ﬁxed modes, we resort to the
technique of [370] to ensure that the subsystems (3.44)-(3.45) are amenable
for decentralized control.
In the absence of unstable ﬁxed modes, our objective is to design either a de-
centralized or two-level control strategies to stabilize the class of nominally
linear uncertain systems S where the perturbations are subject to Assumption
3.1 and Assumption 3.2.

54
Chapter 3. Historical Perspective and Scope
3.5.1
Decentralized control
It follows from Assumption 3.1 that there exists a constant matrix Gj ∈
ℜmj×nj, such that the eigenvalues of (Aj + BjGj) or λj(Aj + BjGj) are
strictly in the complex left half plane. Consider the decentralized feedback con-
trol
uj(t)
=
Gjyj(t) + gj(t, yj(t))
(3.51)
gj(t, yj(t))
=
⎧
⎪
⎪
⎨
⎪
⎪
⎩
−Bt
jPjyj
||Bt
jPjyj||σj(yj)
for ||Bt
jPjyj|| > ϵj
−Bt
jPjyj
ϵj
σj(yj)
for ||Bt
jPjyj|| ≤ϵj
(3.52)
where ϵj > 0 is a prespeciﬁed parameter and Pj is a solution of the Lyapunov
equation
Pj(Aj + BjGj) + (Aj + BjGj)tPj = −Qj, 0 < Qj = Qt
j
(3.53)
and σj(yj) : ℜnj →ℜ+ is a nonnegative function chosen to satisfy
σj(yj)
=

1 −ϱsj
−1$
max
rj∈ℑj ||Dj(rj)yj|| +
max
vj(t) ∈ℜsj ||Fjvj||
+
max
wj(t) ∈ℜnj ||Gjwj|| + max
sj∈℘j ||Ej(sj)Gjyj||
+
max
rj∈Imj, wj(t)∈ℜnj ||Dj(rj)wj||
%
(3.54)
where the indicated inverse exists in view of Assumption 3.2. For simplicity
in exposition, we introduce the following norm quantities:
ϱrj
=
||Dj(rj)||, ϱrj =
max
vj(t) ∈ℜsj ||Fjvj||, ϱwj = ||wj||
ϱgj
=
||Gj||, ϱsgj = max
sj∈℘j ||Ej(sj)Gj||
(3.55)
It is evident by simple algebraic manipulations from (3.54) and (3.55) that the
functions σj(yj), j = 1, ..., ns are cone bounded in the sense that
||σj(yj)||
≤
αj + βj ||yj||
(3.56)
Remark 3.5.2 It is important to observe that the controller (3.52) is of switch-
ing type, dependent on the local measured output yj and is independent of the
interactions. In view of (3.54), σj(yj) is formulated based only on the possible
bound of local uncertainties. This paves the way to designing controllers based
on completely decentralized information.

3.5. Nominally Linear Systems—Continuous Case
55
Remark 3.5.3 It should be emphasized that the cone-boundedness form (3.56)
is always satisﬁed because in view of (3.45), (3.55), and (3.56), we can deduce
that
||σj(yj)||
≤
||σj(xj)|| := ˆαj + ˆβj ||xj||
ˆαj
:=
[(2ϱrj + ϱgj + ϱsgj)ϱwj + ϱvj]/(1 −ϱsj)
ˆβj
:=
(ϱrj + ϱsgj)/(1 −ϱsj)
(3.57)
Based on the foregoing remarks and recalling the notion of practically stabiliz-
ability from the Appendix, the following decentralized stabilization results can
now be developed.
Theorem 3.5.4 The overall
system
(3.50)
satisfying
Assumption
3.1-
Assumption 3.3 is practically stabilizable by the decentralized control laws
(3.51)-(3.52) if the test matrix L = [ℓjk] given by
ℓjk =
⎧
⎨
⎩
λm(Qj)
for j = k
−λM(Pj)[||Ajk|| + ||Akj|| + 2 ns
j=1
ns
k=1 γjk]
for j ̸= k
(3.58)
is positive-deﬁnite.
The proof of Theorem 3.5.4 can be found in [10] based on constructive use of
Lyapunov analysis.
3.5.2
Two-level control
We have seen so far that the overall uncertain system can be stabilized using
decentralized controllers which do not need any exchange of state information
among the subsystems. This, in turn, is economical from the point of view of
the control realization. A possible side effect is that a completely decentralized
control methodology implies that the dynamic behavior of interconnections are
completely neglected thereby yielding a loss of information. In the sequel, we
investigate the stabilization problem via a multilevel (hierarchical) technique
[136, 236]. For a comprehensive overview about the hierarchical control the-
ory and applications, the readers are referred to [192, 194]. The principal idea
of a two-level control structure is to deﬁne a set of subproblems that can be
considered independent at a certain level (subsystem level). Through the ma-
nipulation of the interplaying effect at a higher level (coordinator), we obtain
the global solution. Accordingly, the decentralized control (3.51) is modiﬁed
to be in the hierarchical form
u(t)
=
Gdy(t) + g(t, y(t))
(3.59)

56
Chapter 3. Historical Perspective and Scope
where Gd = Blockdiagonal(Gj), and Gj is a stabilizing gain matrix such
that the eigenvalues of (Aj + BjGj) or λj(Aj + BjGj) are strictly in the
complex left half plane and g(., .) : ℜn →ℜm given by
g(t, y(t))
=
⎧
⎪
⎨
⎪
⎩
σ(y) −BtPy
||BtPy||
for ||BtPy|| > ϵ
−σ(y)BtPy
ϵ
for ||BtPy|| ≤ϵ
(3.60)
where ϵ > 0 is a prespeciﬁed parameter, P = diag(P)j is the positive-deﬁnite
solution of (3.53), and σ(y) : ℜn →ℜ+ is a nonnegative function chosen to
satisfy
σ(y)
=
max
j
$
1 −ϱsj
−1
max
rj∈ℑj ||Dj(rj)yj|| +
max
vj(t) ∈ℜsj ||Fjvj||
+
max
wj(t) ∈ℜnj ||Gjwj|| + max
sj∈℘j ||Ej(sj)Gjyj||
+
max
rj∈Imj, wj(t)∈ℜnj ||Dj(rj)wj||
	%
, j = 1, .., ns
(3.61)
where the indicated inverse exists in view of Assumption 3.2. In the same
manner, it is easy to see that
||σ(y)||
≤
||σ(x)|| := ˜α + ˜β ||x||
˜α
:=
max
j [(2ϱrj + ϱgj + ϱsgj)ϱwj + ϱvj]/(1 −ϱsj)
˜β
:=
max
j (ϱrj + ϱsgj)/(1 −ϱsj), j = 1, 2, ..., ns
(3.62)
Following the development of Theorem 3.5.4, we are ready to provide the
following result.
Theorem 3.5.5 The overall
system
(3.50)
satisfying
Assumption
3.1-
Assumption 3.3 is practically stabilizable by the decentralized control laws
(3.59)-(3.60) if the test matrix L = [ℓjk] given by (3.58) is positive-deﬁnite.
Furthermore, the resulting closed-loop state trajectories are bounded in a set
Ωc(˜η), where Ωc(˜η) is the complement of set Ω(˜η), having radius ˜η given by
˜η
=

˜μa +

(˜μ2a + 4˜μcλm(L))

˜μa
=
˜α( ϵ
2 + 4||BtP||ϱw)
˜μc
=
˜β( ϵ
2 + 4||BtP||ϱw)
ϱw
=
max
j {ϱwj},
j = 1, .., ns
(3.63)

3.5. Nominally Linear Systems—Continuous Case
57
The proof of Theorem 3.5.5 can be found in [10] based on constructive use of
Lyapunov analysis.
Remark 3.5.6 We emphasize that the hierarchical control structure outlined
in Theorem 3.5.5 has the following features:
1. The second term of the present control (the coordinator gain) is nonlin-
ear and depends on the initial conditions.
2. Except for the term σ(y), all the computations are on the subsystem level.
In light of (3.62), however, the computation of σ(y) is performed sepa-
rately for each subsystem.
3. The exchange of information, in the present control implementation, be-
tween the coordinator and the subsystems is minimal, and hence the
control is easy to realize, especially for large-scale geographically dis-
tributed systems.
Remark 3.5.7 In the absence of state uncertainty, that is, wj ≡0, and if very
large feedback gains are permitted (ϵj →0), then the nonlinear (switching)
term of the controller (3.51) will render the subsystem asymptotically stable.
Same result holds when using the hierarchical controller.
Remark 3.5.8 The implementation of hierarchical control necessitates the use
of many communication links, to facilitate transmitting pertinent information
and corrective signals. However, in many situations, physical perturbations
took place which tended to modify the data transmission network and caused
information losses. This may affect the stability of the global system and fre-
quently undergoes instability. Extensions of Theorems 3.5.4 and 3.5.5 to deal
with the effects of structural perturbations have been developed in [10] and
will be demonstrated in the numerical example to follow.
3.5.3
Illustrative example 3.2
We consider a gas-absorber system as detailed in [193]. For numerical sim-
ulation we take the case of six plates that we consider to be split into two
subsystems; each is composed of three plates (each subsystem is a 3-plate gas
absorber). The deﬁnitions of the various elements of the model are presented
in Figure 3.3, where the variables x3 and x4 represent the interconnection be-
tween the two subsystems. Using typical data values, the matrices of the model
(3.44)-(3.45) are given by

58
Chapter 3. Historical Perspective and Scope
Figure 3.3: Six-plate gas absorber representation
A
=
⎡
⎢⎢⎢⎢⎢⎢⎣
−1.173
0.634
0
0
0
0
0.538
−1.173
0.634
0
0
0.3
0
0.538
−1.173
0.634
0
0
0
0
0.538
−1.173
0.634
0
0
0
0
0.538
−1.173
0.634
0
0
0
0
0.538
−1.173
⎤
⎥⎥⎥⎥⎥⎥⎦
B
=
⎡
⎢⎢⎢⎢⎢⎢⎣
0.538
0
0
0
0
0
0
0
0
0
0
0.88
⎤
⎥⎥⎥⎥⎥⎥⎦
, ΔA(r) =
 ΔA1(r)
0
0
ΔA2(r)

ΔB(s)
=
 ΔB1(s1)
0
0
ΔB2(s2)

,
H(t, r, x)
=

0
ΔA12(r)
ΔA12(r)
0

ΔA1(r)
=
ΔA2(r) =
⎡
⎣
r1
r2
0
r3
r1
r2
0
r3
r1
⎤
⎦
ΔB1(s1)
=
⎡
⎣
s1
0
0
⎤
⎦, ΔB2(s2) =
⎡
⎣
0
0
s2
⎤
⎦

3.5. Nominally Linear Systems—Continuous Case
59
ΔA12(r)
=
⎡
⎣
0
0
0
0
0
0
r2
0
0
⎤
⎦, ΔA21(r) =
⎡
⎣
0
0
r3
0
0
0
0
0
0
⎤
⎦
where the compact bounding sets ℑj, ℘j, j = 1, 2 are given by
ℑ1
=
ℑ2 = {r ∈ℜ3 : −0.46 ≤r1 ≤0.39,
−0.16 ≤r1 ≤0.16, −0.24 ≤r1 ≤0.30}
℘1
=
{s1 : −0.24 ≤s1 ≤0.30}, ℘2 = {s2 : −0.22 ≤s1 ≤0.22}
Checking on Assumption 3.2-1 and -2, it follows that
D1(r)
=
D2(r) = 1.859

r1
r2
0

E1(s1)
=
1.859s1, E2(s2) = 1.136s2
Simple calculations give
ϱr1 = ϱr2 = 0.904, ϱs1 = 0.563, ϱs2 = 0.251
and hence Assumption 3.2-3 is satisﬁed.
Invoking the linear quadratic regulator theory [3] with unity weighting ma-
trices and degree of stability α = 1.6, computation of the decentralized gains
yields
G1
=

−6.6712
−16.3014
−17.1622

G2
=

−9.2401
−9.9440
−4.4264

Proceeding further to solve (3.53) with Q1 = Q2 = I and then computing the
nonlinear controller (3.52) with ϵ1 = ϵ2 = 0.5, we reach
σ1(x1)
=
33.750 ||x1||, x1 =

x1
x2
x3

σ2(x2)
=
5.991 ||x2||, x2 =

x4
x5
x6

g
=
[g1(x1)
g2(x2)]t
gj(xj)
=
⎧
⎪
⎪
⎨
⎪
⎪
⎩
−σ(x)
Bt
jPjxj
||Bt
jPjxj||
for ||Bt
jPjxj|| > 0.5
−σ(x)
Bt
jPjxj
0.5
for ||Bt
jPjxj|| ≤0.5
,
j = 1, 2
Simulation of the closed-loop system using a decentralized control structure is
shown in Figure 3.4, where the controller’s components were given before for
the following computer runs:

60
Chapter 3. Historical Perspective and Scope
Figure 3.4: Decentralized control (DC) structure
1. r1 = 0.2, r2 = 0.1, r3 = 0.25, s1 = 0.28, s2 = 0.2.
2. r1 = −0.46, r2 = −0.16, r3 = −0.24, s1 = −0.24, s2 = −0.22.
3. r1 = 0.39, r2 = 0.16, r3 = 0.30, s1 = 0.30, s2 = 0.22.
Representative plots are presented in Figures 3.5-3.7 for the three different
runs and markings. On the other hand, simulation of the closed-loop system
Figure 3.5: Trajectories of ﬁrst (left) and second (right) states under DC
using hierarchical control structure, shown in Figure 3.8, was performed. The
ensuing results are depicted in Figures 3.9-3.11 for the three different runs with
the same markings.

3.6. Linear Systems
61
Figure 3.6: Trajectories of third (left) and fourth (right) states under DC
Figure 3.7: Trajectories of ﬁfth (left) and sixth (right) states under DC
3.6
Linear Systems
In this section, we focus on the class of systems composed of ns coupled linear
subsystems with nonlinear interconnections described by
˙xj(t) = Ajxj + Bjujc + hj(t, x),
j = 1, 2, ..., ns
(3.64)
where xj(t) ∈ℜnj is the state vector, ujc(t) ∈ℜnj is the local control input
of the jth subsystem, and the matrices Aj ∈ℜnj×nj, Bj ∈ℜnj×mj are con-
stants. Following the development of Section 3.3, each of the free subsystems
˙xj(t) = Ajxj + Bjujc,
j = 1, 2, ..., ns
(3.65)

62
Chapter 3. Historical Perspective and Scope
Figure 3.8: Hierarchical control (HC) structure
Figure 3.9: Trajectories of ﬁrst (left) and second (right) states under HC
are optimized with respect to the quadratic performance index
Jj(to, xjo, ujc) =
 ∞
to
eπt

xt
j(t)Qjxj(t) + ut
jc(t)Rjujc(t)

dt
(3.66)
where 0 < Qj ∈ℜnj×nj, 0 < Rj ∈ℜmj×mj are weighting matrices and π
is a nonnegative number. Under the standard assumption of complete control-
lability of the subsystem pair (Aj, Bj), there exists a unique linear optimal
control law [3]
u∗
jc(t) = −Kjc xj(t),
Kjc = R−1
j Bt
jPj
(3.67)
where 0 < Pj ∈ℜnj×nj is the solution of the algebraic Riccati equation
Pj(Aj + πIj) + (Aj + πIj)tPj −PjBjR−1
j Bt
jPj + Qj = 0
(3.68)

3.6. Linear Systems
63
Figure 3.10: Trajectories of third (left) and fourth (right) states under HC
Figure 3.11: Trajectories of ﬁfth (left) and sixth (right) states under HC
such that u∗
jc(t) yields the minimum of Jj(to, xjo, ujc) in (3.66) where the
optimal performance index is
J∗
j (to, xjo) = e2πto xt
joPjxjo
(3.69)
When the matrix Qj can be factored as Qj = CjCt
j, where Cj ∈ℜnj×nj is
a constant matrix, so that the subsystem pair (Aj, Cj), is completely observ-
able, it follows [3] that each closed-loop subsystem
˙xj(t) = (Aj −BjR−1
j Bt
jPj)xj,
j = 1, 2, ..., ns
(3.70)
is globally exponentially stable with the degree π. That means that the solution
xj(t; to, xjo) of (3.70) approaches the equilibrium at the origin at least as fast
as e−πt for all (to, xjo) ∈ℜnj+1, t ∈[to, +∞). Introduce the following

64
Chapter 3. Historical Perspective and Scope
quantities:
ξ
=
ns

j=1
ns

k=1
ξjk, P = Blockdiag

P1
P2
· · ·
Pns

,
W
=
Blockdiag

W1
W2
· · ·
Wns

,
Wj
=
PjBjR−1
j Bt
jPj + Qj
(3.71)
The following theorem presented in [322] establishes condition on the interac-
tion hj(t, x) to guarantee a prescribed degree of suboptimality of the intercon-
nected system
˙xj(t) = (Aj −BjR−1
j Bt
jPj)xj + hj(t, x),
j = 1, 2, ..., ns
(3.72)
Theorem 3.6.1 Let there exist nonnegative numbers ξjk so that the interaction
hj(t, x) in (3.72) satisﬁes the constraints
||hj(t, x)||
≤
ns

k=1
ξjk||xk||, ∀(t, x) ∈[to, +∞) × ℜn, ∀j = 1, 2, ..., ns
ξ
≤
ϵ
1 + ϵ
λm(W)
2λM(P)
(3.73)
Then the overall system (3.72) is suboptimal with index ϵ and globally expo-
nentially stable with degree π.
Observe that λM(P) and λm(W) are the maximum and minimum eigenval-
ues of matrices P and W, respectively, with λM(P) = maxj{λM(Pj)} and
λm(W) = minj{λm(Wj)}.
In the case of a linear interaction pattern, the overall system becomes
˙x(t)
=
Ax + Bu + Hx
A
=
Blockdiag

A1
A2
· · ·
Ans

,
B
=
Blockdiag

B1
B2
· · ·
Bns

(3.74)
for which we introduce the two-level control
u(t) = uc(t) + ug(t)
(3.75)
which consists of two components: uc(t) is the subsystem (lower-level) control
as given by (3.67) and ug(t) is the global (higher-level) control chosen linearly
of the form
ug(t) = −Kgx(t)
(3.76)

3.6. Linear Systems
65
where Kg ∈ℜm×n is a constant matrix to be selected such that [322]
inf
Kg ||(H −BKg)x||
is achieved for all x ∈ℜn. Taking into consideration the fact that ||(H −
BKg)x|| ≤||(H −BKg)||||x|| holds for all x ∈ℜn, then the selection of Kg
reduces to ﬁnding minKg ||H −BKg|| for which the solution is known to be
Kg = B† H
where B† is the Moore-Penrose generalized inverse of B [162]. When
rank(B) = m, then B† = (BtB)−1Bt and thus
Kg
=
(BtB)−1BtH
(3.77)
implying that the closed-loop system (3.74) assumes the form
˙x(t)
=

A −BR−1BtP +

I −B(BtB)−1Bt

H

x(t)
(3.78)
which would be exponentially stable with a prescribed degree π.
Remark 3.6.2 It is interesting to observe that when B is a square and non-
singular matrix, the choice (3.77) reduces to Kg = B−1H, which eventually
leads to a perfect neutralization of the interaction effects and hence ϵ = 0.
An important structural property for the two-level control systems is that
suboptimality index is invariant under structural perturbations whereby sub-
systems are disconnected from each other and again connected together in var-
ious ways during operation. The notion of connective suboptimality introduced
here is, therefore, an extension of the connective concept originated in stability
studies [321] of large-scale systems.

66
Chapter 3. Historical Perspective and Scope
3.6.1
Illustrative example 3.3
Consider the following seventh-order system [179], which we treat in the se-
quel as composed of three subsystems:
A
=
⎡
⎣
A1
0
A2
0
A3
A4
A5
A6
A7
⎤
⎦, B =
⎡
⎣
B1
0
0
0
B2
0
0
0
B3
⎤
⎦,
A1
=
 6
−10
10
20

, A2 =
 2.5
−10
1
7.5

, A5 =
 −1
−0.5
0.1
0.3

,
A3
=
⎡
⎣
10
5
8
2
−10
2
10
0
−2.5
⎤
⎦, A4 =
⎡
⎣
−20
−10
5
4
1
−1
⎤
⎦,
A6
=
 −0.3
0.4
0.2
−0.1
0.1
0.1

, A7 =
 −0.8
0.3
−1
0.2

, B2 =
⎡
⎣
2.5
5
10
⎤
⎦,
B1
=
 2
10

, B3 =
 0.1
0.25
−1
1

Applying the linear quadratic regulator theory [3] with weighting matrices R =
Blockdiag[I2 I3 I2], Q = Blockdiag[I2 I3 2I2] where Ij is the j × j unit
matrix for the full system, the two-level system, and the block arrow structure
(BAS) system [179], the ensuing results of the performance indices with xo =
[I2 I3 I2]t are given by
1. The performance index for the full (centralized) system J∗= 5.4231.
2. The performance index for the two-level system J+ = 5.7485.
3. The performance index for the BAS system J−= 6.1285.
We record that the performance degradation afforded by the two-level system is
6%, while that of the BAS system is 13%, an observation that conﬁrms the su-
periority of the two-level with interaction neutralization. Representative plots
are presented in Figures 3.12-3.15. In the following section, we address a per-
turbational approach to large-scale optimization and control of linear systems.
3.7
A Perturbational Approach
Since a large-scale system will invariably be an interconnection of several sub-
units, it has been noted in the foregoing section that one of the important phe-
nomena that must be accounted for in the design controllers is the occurrence of

3.7. A Perturbational Approach
67
Figure 3.12: Trajectories of ﬁrst (left) and second (right) states under different
controls
Figure 3.13: Trajectories of third (left) and fourth (right) states under different
controls
structural perturbations, that is, changes in the interconnection pattern within
the system during operation. It has been recognized [340] that reliability of
system performance in the face of such structural changes is intimately related
to the allowance for the subsystems to perform with as much autonomy as
possible; a typical example occurs in interconnected power systems where the
reliability of operation is of signiﬁcant importance [334].
From the preceding sections, we learned that an interconnected system
composed of ns coupled linear subsystems with linear interconnections can
be described by
˙xj(t) = Ajxj(t) + Bjuj(t) +
ns

k=1
Hjkxk(t)
(3.79)
where for j ∈{1, . . . , ns}, xj(t) ∈ℜnj is the state vector and uj(t) ∈ℜmj
is the control input. The constant matrices Aj ∈ℜnj×nj and Bj ∈ℜnj×mj

68
Chapter 3. Historical Perspective and Scope
Figure 3.14: Trajectories of ﬁfth (left) and sixth (right) states under different
controls
Figure 3.15: Trajectories of seventh state under different controls
describe the dynamics of the isolated subsystem Sj and Hjk ∈ℜnj×nk spec-
iﬁes the interaction from Sk to Sj. The complete controllability of the pairs
(Aj, Bj) is assumed in the sequel. For the purpose of regulation, the perfor-
mance of each subsystem is measured by an associated quadratic cost
Jj(to, xj(to), uj(to))
=
 ∞
to

xt
j(t)Qjxj(t) + ut
j(t)Rjuj(t)

dt,
j ∈{1, ..., ns}
(3.80)
where 0 ≤Qt
j = Qj ∈ℜnj×nj, 0 < Rt
j = Rj ∈ℜmj×mj are weight-
ing matrices. To guarantee a goal harmony among the subsystems, the overall
quadratic cost
J(to, x(to), u(to)) =
ns

j=1
Jj(to, xj(to), uj(to))
(3.81)

3.7. A Perturbational Approach
69
is sought to be optimized where
x(t)
=

xt
1(t)
xt
2(t)
· · ·
xt
ns(t)
t ,
u(t)
=

ut
1(t)
ut
2(t)
· · ·
ut
ns(t)
t
are the overall state and control input vectors.
Our objective in this section is to design a decentralized controller struc-
ture where the local (subsystem) controller uj(t) will be generated from the lo-
cal information only {Aj(t), Bj(t), Qj, Rj} without information exchange
among the local controllers. One must bear in mind that such decentralized
structure with information constraints may lead to performance loss in com-
parison to the centralized optimal controllers, a fact that poses a compromise
between performance versus implementation.
When the subsystems are decoupled, that is, when Hjk ≡0,
j, k ∈
{1, ..., ns}, the decentralized optimal controls u∗
j(t) that minimize Jj in (3.80)
subject to the dynamic constraints
˙xj(t) = Ajxj(t) + Bjuj(t), j ∈{1, ..., ns}
(3.82)
are given by
u∗
j(t) = −K∗
j xj(t),
K∗
j = R−1
j Bt
jPj
(3.83)
where 0 < Pt
j = Pj ∈ℜnj×nj is the solution of the algebraic Riccati equation
Pj(Aj + πIj) + (Aj + πIj)tPj −PjBjR−1
j Bt
jPj + Qj = 0
(3.84)
with the associated optimal costs
J∗
j (to, xj(to)) = xt
j(to)Pjxj(to), j ∈{1, ..., ns}
(3.85)
It is obvious that the decoupled optimal cost
J∗(to, xj(to)) =
ns

j=1
J∗
j (to, xj(to))
(3.86)
would be markedly different from Jo(to, xj(to)) that would result from the
minimization of (3.81) subject to the full dynamics (3.79) depending on the in-
teraction pattern. The real challenge is to seek methods that result in improved
performance whenever possible for the overall system. It must be emphasized
that J∗may in general be less or greater than Jo and the presence of inter-
connections may generally be termed “nonbeneﬁcial” or “beneﬁcial” to the
optimization [205, 354]. The following theorem provides a possible character-
ization of an interconnection pattern [354].

70
Chapter 3. Historical Perspective and Scope
Theorem 3.7.1 Let
P = Blockdiag

P1
P2
· · ·
Pns

where 0 < Pt
j = Pj ∈ℜnj×nj is the solution of (3.84). Then the optimum cost
condition
J∗= Jo
is attained if and only if the interaction matrix H = [Hjk] ≡0, j, k ∈
{1, ..., ns}, can be factorized,
H = S P
(3.87)
where S ∈ℜn×n is an arbitrary skew-symmetric matrix.
Remark 3.7.2 We note that Theorem 3.7.1 identiﬁes a class of interconnection
patterns H that ensure that the overall optimum Jo is attained by the decentral-
ized local controls u∗
j(t). Consequently, the stability of the closed-loop overall
system
˙xj(t) = [Aj −BjK∗
j ]xj(t) +
ns

k=1
Hjkxk(t), j ∈{1, ..., ns}
(3.88)
is also guaranteed since when (3.87) holds, P ∈ℜn×n is the positive deﬁ-
nite solution of the Riccati equation associated with the overall system (3.79)
together with the cost (3.85). It is quite evident that a system equipped with
these controls would perform reliably (without loss of stability and optimality
of performance) when the structural perturbations can be limited to result in
interconnection patterns belonging to the above class.
3.7.1
Multilevel state regulation
In the case of the interconnection pattern H when it does not satisfy the equal-
ity constraint (3.87), the application of the decentralized local controls u∗
j(t)
will result in a performance that deviates from Jo. In the preceding section,
bounds on the resulting suboptimality of performance and the norm of the in-
terconnections have been developed. There multilevel control schemes to im-
prove the performance by neutralizing the interconnection effects have been
designed.
In line of [205, 353, 354], using different ideas to develop an alterna-
tive multilevel scheme does not ignore the possible beneﬁcial aspects of the
interconnections, but exploits them to permit resulting costs less than Jo to

3.7. A Perturbational Approach
71
be attained. We will achieve this within a two-level hierarchical structure in
which an additional control is to be generated by a supervisory coordina-
tor at a higher level, to whom the subsystems agree to submit their states
and, in turn, is capable of assessing the extent of interactions at any instant.
The information structure of this coordinator consists of {xj(t), t ≤to, j =
1, 2, ..., ns}, Hjk, j, k = 1, 2, ..., ns} together with the a priori information
of Aj, Bj, Pj, j = 1, 2, ..., ns.
Remark 3.7.3 Had the subsystem cost matrices {Qj, Rj, j = 1, 2, . . . , ns},
been made available to the supervisory coordinator, he would then have all the
information necessary to compute the centralized optimal control uo(t) and
substitute the local controls u∗
j(t) by the components uc
j(t). Generally, this is
not encouraged for the following reasons:
1. The associated data processing difﬁculties in computing this control,
2. The fact that such a strategy would oppose our desire for keeping the
autonomy of the subsystems. This comes in full support with the results
reported in [322] as a centralized optimal control is often unreliable
when the system is expected to undergo structural perturbations.
As a practical rule (the reader is referred to the foregoing chapter for issues
on decomposition-coordination structures) the supervisory coordinator must
deploy a minimum intervention providing only corrective controls that deal
with the interactions existing at any given period.
Now let the input uj(t) to each subsystem consist of two components
uj(t) = u∗
j(t) + uc
j(t), j ∈{1, ..., ns}
(3.89)
where u∗
j(t) = −K∗
j xj(t) is the subsystem (lower-level) control with K∗
j
being given by (3.83) and uc
j(t) is the component of the coordinator control
chosen linearly of the form [353, 354]
uc
j(t) = −
ns

k=1
Njkxk(t)
(3.90)
where Njk ∈ℜmj×nj is the component of the coordinator control gain matrix.
Using (3.89), the closed-loop subsystem becomes:
˙xj(t) = [Aj −BjK∗
j ]xj(t) +
ns

k=1
[Hjk −BjNjk]xk(t)
(3.91)

72
Chapter 3. Historical Perspective and Scope
By selecting the gains Njk through the equality relation
B N
=
Bc K∗
K∗
=
Blockdiag

K∗
1
K∗
2
· · ·
K∗
ns

,
N
=
[Njk], j, k ∈{1, ..., ns}
(3.92)
and introducing
A
=
Blockdiag

A1
A2
· · ·
Ans

,
B
=
Blockdiag

B1
B2
· · ·
Bns

(3.93)
we express the closed-loop overall system
˙x(t)
=
(A + H)x(t) −(B + Bc)K∗x(t)
(3.94)
where Bc ∈ℜn×m is the coordinator perturbation in matrix B.
Remark 3.7.4 It is signiﬁcant to note that B as in (3.93) is block-diagonal
and hence the components of −BK∗x(t) applied to each subsystem involve
their own state only, which determines the local controls. On the other hand,
the matrix Bc is not block-diagonal and this implies that the components of
−BcK∗x(t) involve the states of the other subsystems thereby characterizing
the global control.
It remains to seek ways to the determination of the global gains Bc that yield
a bounded performance deviation from J∗without causing any change in the
feedback gain matrix K∗. One possible way to solve this problem is attained
by the following theorem [353, 354].
Theorem 3.7.5 Let S ∈ℜn×n be a skew-symmetric solution of the matrix
equation
S(A + H) + (A + H)tS + HtPA −AtPH = 0
(3.95)
and such that
&P = P + (S −PH)(A + H)−1 > 0
(3.96)
The perturbation matrix Bc given by
Bc = −&P−1(S −PH)(A + H)−1B
(3.97)
yields a cost
&J = xt(to) &Px(to)

3.7. A Perturbational Approach
73
for the overall system (3.94). A bound on the suboptimality index is given by
ˆϵ :=
&J −J∗
J∗
≤λM((S −PH)(A + H)−1)
λm(P)
Moreover, the control
u(t) = −(K∗+ N)x(t)
is a stabilizing controller for the overall system.
Remark 3.7.6 We observe that the perturbation matrix Bc helps retain the
unchanged feedback gain matrix K∗while solving the Lyapunov matrix (3.95)
as compared with two-level coordination algorithms [196]-[203]. Observe also
that the suboptimality is assessed with respect to the decoupled optimum J∗,
instead of the overall optimum Jo by virtue of considerations of reliability and
subsystem autonomy. This performance indicator is essentially used to measure
the deviation caused by the beneﬁcial or nonbeneﬁcial effects of interactions.
3.7.2
Generalized scheme
In the sequel, we provide a multicontroller structure to handle the information
ﬂow within hierarchical control systems. Extending on the foregoing section,
we consider here ns linear output regulators of the form
˙xj(t)
=
Ajxj(t) + Bjuj(t) + gj[x(t), u(t)]
(3.98)
gj[x(t), u(t)]
=
ns

k=1
Djkxk(t) + Gjkuk(t)
(3.99)
yj(t)
=
Cjx(t), j ∈{1, ..., ns}
(3.100)
For the decoupled case gj[x(t), u(t)] ≡0, the optimal policy u∗(t) of mini-
mizing the performance index
Jj(to, yj(to), uj(to))
=
 ∞
to

yt
j(t)Qjyj(t) + ut
j(t)Rjuj(t)

dt,
j ∈{1, ..., ns}
(3.101)
and satisfying the isolated dynamics is expressed as [3]:
u∗
j(t) = −K+
j xj(t),
K+
j = R−1
j Bt
jPj
(3.102)
where 0 < Pt
j = Pj ∈ℜnj×nj is the solution of the algebraic Riccati equation
PjAj + At
jPj −PjBjR−1
j Bt
jPj + Ct
jQjCj = 0
(3.103)

74
Chapter 3. Historical Perspective and Scope
In the subsequent analysis, we seek an approach of handling a general form of
interactions considering both undesirable and favorable effects. From an engi-
neering design point of view, these effects are deemed noninteracting although
they might exist simultaneously. Therefore, adding up the extent of the cou-
pling terms eventually implies placing an additional task on the control policies
in order to master the information ﬂow. To preserve the autonomy of the indi-
vidual problems, this task is reﬂected in suitably superimposing further com-
ponents, directly or indirectly, to the control effort. Speciﬁcally, the jth control
policy is ﬁrst written of the form (3.89) where uc(t) is treated hereafter as the
corrective control component responsible for constraining the information ﬂow
against the existing coupling modes. Substituting (3.89), (3.99), and (3.102)
into (3.98) and considering the term uj(t) in (3.99) as an externally applied
signal ue
j(t), thus,
˙xj(t) = [Aj −BjK+
j ]xj(t) + Bjuc
j(t) +
ns

k=1
Djkxk(t) + Gjkue
k(t)(3.104)
Building on the results of the previous section, we select the corrective control
as
uc
j(t) = −
ns

k=1
Mjkxk(t)
(3.105)
which is in agreement with (3.90) with Mjk being the feedback coupling gains.
It is useful at this stage to recognize the role of the various control policies
(controllers) within the context of hierarchically structured multilevel systems.
The group of controllers {u∗
j(t)}, j = 1, ..., ns is performing the basic reg-
ulation task, thus it has a local attribute and it is quite natural to attach these
controllers to the lower hierarchical control level. Alternatively, the function
of {uc
j(t)}, {ue
j(t)}, j = 1, . . . , ns being associated with the intercouplings
among the subsystems has global attributes. This motivates assigning them to
higher hierarchical control levels. Our task now is to derive the global control
policies. The integrated system is considered by summing up equation (3.104)
over the ns subsystems
˙x(t) = [A −BK+]x(t) + [D −BM]x(t) + Gue(t)
(3.106)
where
A
=
Blockdiag[Aj], B = Blockdiag[Bj], K+ = Blockdiag[K+
j ],
ue(t)
=

ue
1(t)
ue
2(t)
· · ·
ue
ns(t)

(3.107)
Some relevant observations that deserve emphasis are:

3.7. A Perturbational Approach
75
1. The term [D−BM] quantiﬁes an effective interconnection matrix whose
structural form and strength, identiﬁed in some sense, depend entirely
on the particular choice of P. Evidently, in order to absorb the undesir-
able information mode without affecting the autonomous behavior of the
subsystems, this term should be kept at minimal strength. This is clas-
sically equivalent to designing the controllers {uc
j(t)} to have compen-
satory features. Our approach to achieving this situation is to take the
norm of the effective matrix as an appropriate quantity for the strength
of information. Then, obviously, the minimum of the norm corresponds
to the least strength. It turns out that the problem at hand reduces to that
of an algebraic minimization problem, whose solution is only unique if
rank[B D] = rank[B] = m and it therefore has the form [87]:
M = (BtB)−1BtD
(3.108)
If the rank condition is met, the strength would be equal to zero, which
ultimately entails that the interconnections among the state variables are
completely absorbed.
2. Some crucial factors such as the inaccessibility of system states and the
difﬁculty involved in data processing may pose real design problems that
may render the rank constraint far reaching. In such case, it is worth-
while to deﬁne an equivalent interconnection matrix E to designate the
capacity of information ﬂow:
E = M −(BtB)−1BtM
(3.109)
The effect of (3.109) converts (3.106) to
˙x(t) = [A + E]x(t) + Gue(t) −BK+x(t)
(3.110)
3. The global control policy ue(t) is now designed based on a different phi-
losophy. The procedure underlying this philosophy stems from utilizing
the favorable attitude of the external signals to produce potentially use-
ful regulatory effects for the overall system. One intuitive way is through
representing the control policy in global feedback form. That is,
Gue(t) = −ZK+x(t)
(3.111)
where Z ∈ℜn×m is an arbitrary gain matrix. Rewriting (3.110) using
(3.111) is the form
˙x(t) = [A + E]x(t) −[B + Z]K+x(t)
(3.112)

76
Chapter 3. Historical Perspective and Scope
Determination of the global gain matrix Z is established by the following the-
orem.
Theorem 3.7.7 If the effective system matrix (A + E) is nonsingular, then the
gain matrix Z satisfying (3.112) while minimizing the performance index is
given by
Z = −(W + P)−1WB
(3.113)
with an improvement in performance index given by
˜J = xt
oWxo
(3.114)
Proof: Rewriting system (3.112) in the form
˙x(t)
=
[A + E]x(t) −[B + Z]u(t),
y(t)
=
Cx(t)
(3.115)
for which the associated the performance index (3.101) becomes
J(to, y(to), u(to))
=
 ∞
to

yt(t)Qy(t) + ut(t)Ru(t)

dt,
C
=
Blockdiag[Cj], Q = Blockdiag[Qj],
R
=
Blockdiag[Rj],
y(t)
=

y1(t)
y2(t)
· · ·
yns(t)

(3.116)
The minimizing feedback control is given by
u(t) = −R−1(B + Z)tGx(t)
(3.117)
where 0 < Gt = G ∈ℜn×n is the solution of the algebraic Riccati equation
G(A + E) + (A + E)tG −G(B + Z)R−1(B + Z)tG + CtQC = 0 (3.118)
Imposing the relation
R−1((B + Z))tG = R−1BtP = K+
(3.119)
where 0 < Pt = P ∈ℜn×n is the solution of
PA + AtP −PBR−1BtP + CtQC = 0
(3.120)
It follows from (3.118)-(3.120) with W = G −P that
W(A + E) + (A + E)tW + PE + EtP = 0
(3.121)
which yields Z in (3.113) and consequently the improvement in the overall
performance is ˜J = xt
oGxo −xt
oPxo from which (3.114) is obtained.

3.7. A Perturbational Approach
77
Remark 3.7.8 We note that the interpretation of (3.121) is simple and inter-
esting. It implies that if the effective interconnection matrix (D - BP) is con-
strained to possess a skew-symmetry proﬁle, then the feedback matrix remains
unchanged and hence the local autonomy is preserved. Under this condition,
the gains P are installed within the local boundaries and this, in turn, simpliﬁes
the design considerations.
3.7.3
Illustrative example 3.4
To demonstrate the application of the above theoretical analysis, a typical sys-
tem problem frequently encountered in power engineering is considered. The
problem represents the optimal design of network frequency and tie-line power
controllers of two coupled steam electric networks sharing the supply of a
group of loads. In modeling the ﬁrst electric network, ﬁve state variables are
considered. They represent the deviations in the network frequency, power gen-
eration, steam valve position, servomotor angular displacement, and angular
velocity. The second network state vector comprises six variables; the ﬁrst ﬁve
of these are similar to those of the ﬁrst network and the sixth component de-
notes the change in the tie-line power level. For both networks, the control
vector signiﬁes the signal command to reset the control unit and the telemetry
signal expresses the change in the load. Reducing these deviations to minimal
is the desired objective of the power optimization problem for balanced and
continuous operation.
Using reasonable data values in per-unit representation, the associated
quantities of the dynamic model (3.98)-(3.100) are deﬁned by
A1
=
⎡
⎢⎢⎣
−0.284
0.227
0
0
0
0
−3.846
3.846
0
0
−19.23
0
−3.846
3.846
0
0
0
0
0
−3.846
⎤
⎥⎥⎦,
A2
=
⎡
⎢⎢⎢⎢⎣
−1.284
0.227
0
0
0
0.227
0
−3.846
3.846
0
0
0
−19.23
0
−3.846
3.846
0
0
0
0
0
0
3.846
0
−0.1
0
0
0
0
0
⎤
⎥⎥⎥⎥⎦
,

78
Chapter 3. Historical Perspective and Scope
B1
=
⎡
⎢⎢⎢⎢⎣
0
−0.227
0
0
0
0
0
0
1
0
⎤
⎥⎥⎥⎥⎦
, B2 =
⎡
⎢⎢⎢⎢⎢⎢⎣
0
0.227
0
0
0
0
0
0
1
0
0
0
⎤
⎥⎥⎥⎥⎥⎥⎦
,
D11
=
[0], D22 = [0], D12 = [0] except d16 = −0.227,
D21
=
[0] except d61 = 0.1,
G11
=
[0], G22 = [0], G12 = [0] except g22 = 0.15,
G21
=
[0] except g22 = 0.12,
Q1
=
Blockdiag[10, 0, 0, 1, 1],
Q2
=
Blockdiag[10, 0, 0, 1, 1, 1],
R1
=
Blockdiag[0.1], R2 = Blockdiag[0.1]
Applying the linear quadratic regulator theory [3] yields the local decoupled
gain matrices
K1
=
⎡
⎢⎢⎢⎢⎣
9.826
0.311
−0.051
−1.512
−0.812
0.311
−0.295
0.029
0.850
0.444
−0.051
0.029
0.347
−0.763
1.045
−1.512
0.850
−0.763
0.428
−0.75
−0.812
0.444
1.045
−0.75
0.49
⎤
⎥⎥⎥⎥⎦
,
K2
=
⎡
⎢⎢⎢⎢⎢⎢⎣
−9.826
−0.205
0.025
0.805
0.544
−0.061
−0.205
0.349
0.423
0.189
−2.105
1.764
0.025
0.423
1.608
0.242
0.195
−0.126
0.805
0.189
0.242
0.794
−0.324
−0.447
0.544
−2.105
0.195
−0.324
2.788
5.243
−0.061
1.764
−0.126
−0.447
5.243
0.425
⎤
⎥⎥⎥⎥⎥⎥⎦
It is easy to check that rank condition is not satisﬁed thereby yielding an equiv-
alent matrix E ∈ℜ11×11 given by
E = [0] except e1,11 = −0.227, e11,1 = 0.1
Algebraic computation of Theorem 3.7.7 yields an overall improvement in the
performance index of 6%.
Remark 3.7.9 The role of interaction patterns in large multilevel control sys-
tems is viewed as representing undesirable (acting against the direct con-
trol policies) and/or favorable (supporting the basic regulation) information

3.8. Observation and Estimation
79
modes. The rationale adopted in the foregoing analysis has been based on
building up hierarchical control structure with the objective of treating a com-
bined form of both modes. Three noninteracting control policies are employed
to implement this structure. The ﬁrst policy provides for a basic regulation task
directly inﬂuencing the decoupled subsystems. The function of the second pol-
icy is to neutralize (completely or partially) the undesirable modes of infor-
mation ﬂow. Assigned to the third policy is the task of exploiting the beneﬁcial
features of information and therefore to establish an improved overall feedback
strategy. It is worth mentioning that the basic regulation job is performed on
a decentralized basis. Although the global policies are implemented in a cen-
tralized manner, the computational load is not a burden since the calculation
is off-line. Also, it has the advantage of adequately making use of the charac-
teristic features of the information pattern.
3.8
Observation and Estimation
In this section, we focus on the dual problem to the foregoing control prob-
lem, that is, we look at the problem of observation and/or estimation in large-
scale systems. An efﬁcient approach to the development of multilevel con-
trol and estimation schemes for large-scale systems with a major emphasis
on the reliability of performance under structural perturbations is described
in the sequel. As we shall see, the study is conducted within a decomposition-
decentralization framework and leads to simple and noniterative control and
estimation schemes. From the previous sections, it turns out that the solution to
the control problem involves the design of a set of locally optimal controllers
for the individual subsystems in a completely decentralized environment and
a global controller on a higher hierarchical level that provides corrective sig-
nals to account for the interconnection effects. Similar principles are employed
hereafter to develop an estimation scheme, which consists of a set of decentral-
ized optimal estimators for the subsystems, together with certain compensating
signals for measurements.

80
Chapter 3. Historical Perspective and Scope
3.8.1
Model set-up
We consider the class of interconnected systems described by
˙x(t)
=
Ax + Bu + h(t, x)
y
=
Cx
(3.122)
A
=
Blockdiag

A1
A2
· · ·
Ans

,
B
=
Blockdiag

B1
B2
· · ·
Bns

C
=
Blockdiag

C1
C2
· · ·
Cns

(3.123)
where x(t) ∈ℜn, u(t) ∈ℜm, y(t) ∈ℜp are the composite state, input and
output vectors at time t ∈ℜgiven by
x
=
Blockdiag

xt
1
xt
2
· · ·
xt
ns
t ,
u
=
Blockdiag

ut
1
ut
2
· · ·
ut
ns
t ,
y
=
Blockdiag

yt
1
yt
2
· · ·
yt
ns
t
(3.124)
and h(t, x) is the overall interaction pattern. In terms of the subsystems, we
express system (3.122) in the form
˙xj(t)
=
Ajxj + Bjuj + hj(t, x),
j = 1, 2, ..., ns
yj
=
Cjxj(t)
(3.125)
where xj(t) ∈ℜnj is the state vector , uj(t) ∈ℜnj is the local control input
of the jth subsystem, and the matrices Aj ∈ℜnj×nj, Bj ∈ℜnj×mj are con-
stants. We shall assume that the ns-pairs {Aj, Cj} are completely observable.
3.8.2
Observation scheme I
When the subsystems (3.125) are decoupled, that is, hj(t, x) ≡0, ∀j =
1, ..., ns, it is a simple design task to construct s independent observers (of
full order for simplicity in the exposition) based only on the dynamics of the
subsystems. Such observers are linear and are of relatively small dimensions.
More precisely, since {Aj, Cj} are completely observable, it is possible to
construct the local observers
˙ˆxj(t) = (Aj −KjCj)ˆxj + Kjyj + Bjuj,
j = 1, 2, ..., ns
(3.126)
where ˆxj(t) ∈ℜnj is the state estimate of xj(t) for the decoupled subsystems
˙xj(t) = Ajxj + Bjuj,
j = 1, 2, ..., ns
yj
=
Cjxj(t)
(3.127)

3.8. Observation and Estimation
81
and Kj
∈ℜnj×pj are the unknown gains to be determined to ensure any
desired degree of convergence of the observation scheme. It is well known
[158] that a convergence at least as fast as an exponential decay e−πt, π > 0
can be achieved, that is, l{xj(t) −ˆx(t)}exp(πt) →0 as t →∞by the
selection
Kj = Gj =j Ct
j,
j = 1, 2, ..., ns
(3.128)
where Gj ∈ℜnj×nj is the symmetric positive deﬁnite solution of the Riccati
equation
Gj(At
j + πIj) + (Aj + πIj)Gj −GjCt
jCjGj + Qj = 0
(3.129)
where Qj ∈ℜnj×nj is an arbitrary symmetric and nonnegative deﬁnite matrix.
Remark 3.8.1 It is readily evident that the observation scheme (3.126) devel-
oped under the decoupling assumption hj(t, x) ≡0, ∀j = 1, ..., ns, will even-
tually be far from satisfactory when used with the composite system (3.122).
This is expected, since no knowledge of the interconnection functions or of the
outputs of the other subsystems is used in constructing the observers for the
subsystems.
Hence, the problem of interest is to seek modiﬁcations of the decentralized
observation scheme (3.126), which would result in the same degree of con-
vergence π when used with the composite system (3.126). This problem of
tailoring the observation scheme for the overall system to attain a speciﬁed de-
gree of convergence is generally more appealing than the intuitively simple and
rather brute force method of choosing arbitrary large gains Kj to locate the lo-
cal observer poles lying quite deep in the left-half complex plane, hoping that
the interconnection effects are suitably swamped. Note that this latter strategy
would make the observer very sensitive to any noise that may be present.
A simple result established in [355] for the case of linear interconnections
hj(t, x) =
ns

k=1
Hjkxk(t), Hjk ∈Renj×nj
is summarized by the following theorem.
Theorem 3.8.2 Let the overall interconnection matrix H = [Hjk], j, k =
1, 2, ..ns satisfy the following rank condition
rank
 C
H

= rank[C] = p =
ns

j=1
pj
(3.130)

82
Chapter 3. Historical Perspective and Scope
Then the modiﬁed observation scheme
˙ˆxj(t)
=
(Aj −KjCj)ˆxj + Kjyj + Bjuj
+
ns

k=1
Kjkyk(t),
j = 1, 2, . . . , ns
(3.131)
where K = [Kjk], Kjk ∈Renj×pj given by
K = HCt(CCt)−1
(3.132)
ensures the degree of convergence π for the observation of the states of the
overall system.
Remark 3.8.3 We notice from Theorem 3.8.2 that the developed decentral-
ized observation scheme incorporates only the outputs of the other subsystems
as additional input signals to each observer with the gains Kjk being deter-
mined by the matrices H, C. The degree of convergence π is dependent only
on spectrum (A −KC) and it is not necessary to design each decentralized
local observer to achieve the same degree of convergence. Rather, each Kj
may be computed corresponding with a desired πj, and the convergence of the
overall scheme is determined by the number π = minj πj.
3.8.3
Observation scheme II
The following theorem established in [355] based on Lyapunov theory provides
an alternative decentralized observation scheme which relies on using the esti-
mated states of the other subsystems in generating the additional inputs to be
applied to each local observer.
Theorem 3.8.4 Consider the linear interconnection pattern
hj(t, x) =
ns

k=1
Hjk(t)xk(t), Hjk(t) ∈Renj×nj
and let the overall interconnection matrix H(t) = [Hjk(t)], j, k = 1, 2, ..ns
satisfy the following rank condition:
H(t) = G[U(t) −S(t)]
(3.133)
where U(.) : ℜ→ℜn×n is an arbitrary skew-symmetric matrix, and S(.) :
ℜ→ℜn×n is an arbitrary symmetric matrix that satisﬁes the condition
Π(t)
=
Qj + GCtCG + 2GS(t)G ≥0,
Π(t)
:
ℜ→ℜn×n
(3.134)

3.8. Observation and Estimation
83
with
G = Blockdiag

G1
G2
· · ·
Gns

and Gj > 0 is the solution of (3.129). Then the modiﬁed observation scheme
˙ˆxj(t)
=
(Aj −KjCj)ˆxj + Kjyj + Bjuj
+
ns

k=1
Kjkˆxk(t),
j = 1, 2, ..., ns
(3.135)
ensures the degree of convergence π for the observation of the states of the
overall system.
Remark 3.8.5 In it readily evident that Theorems 3.8.2 and 3.8.4 identify con-
ditions under which decentralized observation scheme with desired properties
may be designed for large-scale systems with linear interconnection patterns. A
noteworthy feature of the underlying result is that every one of these conditions
as well as the solution of the associated Riccati equations and the calcula-
tion of the required eigenvalues are performed on the subsystem level, which
is of relatively small dimensions thereby rendering minimal computational re-
quirements. In addition, only the observability of the decoupled subsystems
is assumed, and any test for the observability of the overall system is avoided.
The characterization of the interconnections among subsystems as perturbation
terms affecting the satisfactory behavior of the decoupled subsystems helps in
reaching the desired design goal. An alternative read-out of the results is that
if the strength of the interconnections is suitably limited, or the interconnec-
tion pattern satisﬁes suitable symmetry conditions, simple modiﬁcations of the
decentralized observation scheme may be developed for the state observation,
with desired convergence properties, of the composite system.
3.8.4
Estimation scheme
The ideas used for the generation of multilevel control schemes may be ex-
tended by duality to the linear least squares estimation problem. The objective
is the determination of conditions for obtaining optimal or near-optimal esti-
mates of the state of the system by designing locally optimal estimates for the
individual subsystems.
Consider the large-scale system formed by an interconnection of subsys-
tems
˙xj(t)
=
Ajxj(t) + Bjwj(t) +
ns

k=1
Hjkxk(t)
yj(t)
=
Cjxj(t) + vj(t)
(3.136)

84
Chapter 3. Historical Perspective and Scope
where for j ∈{1, ..., ns}, xj(t) ∈ℜnj is the state vector, wj(t) ∈ℜmj
is the input noise, yj(t) ∈ℜpj is the output, and vj(t) ∈ℜpj is the mea-
surement noise. In the sequel, it will be assumed that the stochastic processes
{wj(t); t ≥to, j ∈{1, ..., ns}} and {vj(t); t ≥to, j ∈{1, ..., ns}}
are zero mean Gaussian stationary white noise processes of known covari-
ances 0 ≤Qj ∈ℜmj×mj and 0 < Rj ∈ℜpj×pj, respectively. The pro-
cesses uj(t) and vj(t) are assumed to be independent of each other, that is,
IE[uj(t)vj(τ)] = 0,
∀τ, t ≥to, for all j ∈{1, ..., ns}. The initial states
xj(to) are Gaussian random vectors of known mean and are independent of
uj(t), t ≥to and vt
j(t), t ≥to. Moreover, we assume that the s-pairs
(Aj, Cj) are completely observable.
By similarity to the state-regulation case, when the subsystems are decou-
pled (that is, when Hjk ≡0), independent decentralized optimal estimators
may be designed for the individual subsystems and are given by [305]:
˙ˆxj(t)
=
(Aj −KjCj)ˆxj(t) + Kjyj(t),
j = 1, 2, ..., ns
ˆxj(to)
=
IE[xj(to)]
(3.137)
where Kj ∈ℜnj×pj is given by
Kj = WjCt
jR−1
j
(3.138)
and Wj ∈ℜnj×nj is the covariance of the error process ej(t) = xj(t)−ˆxj(t),
satisfying the Riccati equation
WjAt
j + AjWj −WjCt
jW−1
j
CjGj + BjQjBt
j = 0
(3.139)
We recall that Tr(Wj) serves as a measure of the performance of the estima-
tion scheme (3.139). In line of the regulation case, it is of interest to determine
conditions on the interconnection matrix H such that the decentralized estima-
tors (3.137), or equivalently
˙ˆx(t)
=
(A −KC)ˆx(t) + Ky(t)
(3.140)
remain optimal for the overall system, that is,
˙x(t)
=
(A + H)x(t) + Bw(t)
y(t)
=
Cx(t) + v(t)
(3.141)
where x, ˆx, y, w, and v are composite vectors of xj, ˆxj, yj, wj, and vj,
respectively. Such conditions are given in the following theorem [354].

3.8. Observation and Estimation
85
Theorem 3.8.6 Let
W = Blockdiag

W1
W2
· · ·
Wns

where 0 < Wj is the solution of (3.139). The decentralized estimation scheme
(3.140) gives optimal state estimates of the overall system (3.141) if and only
if the the linear interconnection pattern H admits the factorization
H = WS
(3.142)
where S ∈ℜn×n is an arbitrary skew-symmetric matrix.
Proof: The proof runs parallel to that of Theorem 3.7.1.
Remark 3.8.7 In some relevant classes of the interconnection pattern, condi-
tion (3.142) fails to be satisﬁed. This leads to the conclusion that the decen-
tralized estimators (3.140) no longer generate optimal estimates of the states
of (3.141). This is quite expected since the estimator for any subsystem does
not incorporate the estimates of the states of the rest of the subsystems. This
defect may be remedied by suitably modifying the dynamics of the estimators
and consequently obtaining improved estimates.
Following the approach of decentralized state regulation, our strategy hereafter
involves retaining the gain matrix K unchanged. For this purpose, consider the
new estimators described by
˙ˆxj(t)
=
(Aj −KjCj)j(t) + Kjyj(t)
−
ns

k=1
KjC∗
jkˆxk(t),
j = 1, 2, ..., ns
ˆxj(to)
=
IE[xj(to)]
(3.143)
where C∗
jk ∈ℜpj×nj are the perturbation matrices to be determined. Equiva-
lently (3.143) can be represented by
˙ˆx(t)
=
[A −K(C + C∗)]ˆx(t) + Ky(t)
(3.144)
where C∗= [C∗
jk] ∈ℜpj×nj, j, k = 1, 2, .., s. Assuming that the n × n
matrix (A + H) is nonsingular, a relation among the perturbation matrix C∗,
the interconnection matrix H, and the performance of the estimation scheme
(3.144) compared with that of the decentralized scheme (3.137) is now given
by the following theorem.

86
Chapter 3. Historical Perspective and Scope
Theorem 3.8.8 Let S ∈ℜn×n be an arbitrary skew-symmetric matrix of the
matrix equation
S(A + H)t + (A + H)S + (AWHt −HWA) = 0
(3.145)
and the matrix '
W ∈ℜn×n given by
'
W = (A + H)−1(S −HW)
(3.146)
be such that (W + '
W) is positive deﬁnite. Then the estimation scheme (3.144)
with
C∗= −C '
W(W + '
W)−1
generates suboptimal estimates of the states of the composite system (3.141)
with an index of suboptimality given by
ϵ = Tr('
W)
Tr(W)
Remark 3.8.9 It must be emphasized that Theorem 3.8.8 may be regarded as
the dual of Theorem 3.7.5 and hence the proof proceeds along almost identical
steps to that of Theorem 3.7.5. In addition, all features and remarks made ear-
lier for the regulation hold with appropriate dualizations to the present result.
In essence, subsystem autonomy is a factor of major importance in the design
of controllers and estimators for large-scale systems from considerations of
reliability of performance under structural perturbations.
Remark 3.8.10 It is worthy to note that efﬁcient two-level algorithms based
on the multiple projection approach were developed for the global Kalman ﬁl-
ter in [99] and for parameter estimation in [101]. In both cases, the optimal
minimum variance estimate is achieved using a ﬁxed number of iterations. This
equally applies to both the recursive and nonrecursive versions of the algo-
rithms.
In the remaining part of this chapter, we direst attention to the class of
large-scale discrete-time systems. Given the rationale that continuous-time and
discrete-time systems are equally important, the main reason behind this di-
rection is the fact that there is a little exposition in the literature about this
topic. Virtually almost all of the texts on large-scale systems have focused
on continuous-time systems. Therefore, addressing basic results related to
discrete-time systems deserves special consideration.

3.9. Interconnected Discrete-Time Systems
87
3.9
Interconnected Discrete-Time Systems
A wide class of interconnected discrete-time systems (DTS) Σ composed of ns
coupled subsystems Σj, j = 1, 2, ..., ns is represented by:
Σ :
x(k + 1)
=
Ax(k) + Bu(k) + g(k, x)
y(k)
=
Cx(k)
(3.147)
where for k ∈Z+ := {0, 1, ...} and x = (xt
1, ..., xt
ns)t
∈ℜn,
n =
ns
j=1 nj, u = (ut
1, ..., ut
ns)t
∈ℜp, p = ns
j=1 pj, y = (yt
1, ..., yt
ns)t ∈
ℜq, q = ns
j=1 qj being the state, control, and output vectors of system Σ. The
function g : Z+ × ℜn →ℜn, g(k, x(k)) = (gt
1(k, x(k)), .., gt
ns(k, x(k)))t is a
piecewise-continuous vector function in its arguments. The associated matrices
are real constants and modeled as A = diag{A1, .., AN}, Aj ∈ℜnj×nj, B =
diag{B1, .., BN}, Bj ∈ℜnj×pj , and C = diag{C1, .., CN}, Cj ∈ℜqj×nj.
Exploiting the structural form of system (3.147), a model of the jth subsystem
Σj can be described by
Σj :
xj(k + 1)
=
Ajxj(k) + Bjuj(k) + gj(k, x(k))
yj(k)
=
Cjxj(k)
(3.148)
where xj(k) ∈ℜnj, uj(k) ∈ℜpj, and yj(k) ∈ℜqj are the subsystem state,
control input, and output, respectively.
By similarity to the case of continuous-time systems [155], there are
discrete-time control systems that exhibit singular perturbation or mode-
separation phenomena. Basically, there are two sources of modeling the
discrete-time systems [279, 280]: from pure difference equations or from
discrete-time modeling of continuous-time systems. Regarding the ﬁrst source,
we look at a general linear, time-invariant discrete-time system:
x(k + 1)
=
A11x(k) + ϵ1−jA12z(k) + B1u(k),
ϵ2iz(k + 1)
=
ϵiA21x(k) + ϵA22z(k) + ϵjB2u(k)
(3.149)
where i ∈{0, 1}, j ∈{0, 1}, x(k) ∈ℜn, z(k) ∈ℜm are state-vectors
and u(k) ∈ℜr is the control vector. Depending on the values for i and j, there
are three limiting cases of (3.149) described by [280]:
1. C-model i = 0, j = 0, where the small parameter ϵ appears in the
column of the system matrix,
2. R-model i = 0, j = 1, where we see the small parameter ϵ in the row
of the system matrix, and

88
Chapter 3. Historical Perspective and Scope
3. D-model i = 1, j = 1, where ϵ is positioned in an identical fashion to
that of the continuous-time system described by differential equations.
Turning the second source, either numerical solution or sampling of singularly
perturbed continuous-time systems normally results in discrete-time models.
It is reported in [279] that by applying a block diagonalization transformation
to a continuous-time singularly perturbed system, the original state variables
x(t) and z(t) can be expressed in terms of the decoupled system consisting of
slow and fast variables xs(t) and zf(t), respectively. Using a sampling device
with the decoupled continuous-time system, we get a discrete-time model that
critically depends on the sampling interval T.
Depending on the sampling interval, we get a fast(subscripted by f) or slow
(subscripted by s) sampling model. In a particular case, when Tf = ϵ, we get
the fast sampling model as
x(n + 1)
=
(Is + ϵD11)x(n) + ϵD12z(n) + ϵE1u(n),
z(n + 1)
=
D21x(n) + D22z(n) + E2u(n)
(3.150)
where n denotes the fast sampling instant (not to be confused with the system
order described previously). Similarly, if Ts = 1, we obtain the slow sampling
model as
x(k + 1)
=
E11x(k) + ϵE12z(k) + E1u(k),
z(k + 1)
=
E21x(k) + ϵE22z(k) + E2u(k)
(3.151)
where k represents the slow sampling instant, and n = k[1/ϵ]. Also, the D and
E matrices in (3.150) and (3.151) are related to the matrices A, B, and trans-
formation matrices; see [188]. Note that the fast sampling model (3.150) can be
viewed as the discrete analog (either by exact calculation using the exponential
matrix or by using the Euler approximation) of the continuous-time system
x
τ
=
ϵA11x(τ) + ϵA12z(τ) + ϵB1u(τ),
z
τ
=
A21x(τ) + A22z(τ) + E2u(τ)
(3.152)
which itself is obtained from its continuous-time system counterpart using the
stretching transformation τ = t/ϵ.
In [187], composite control technique and related asymptotic results were
extended from systems described by singularly perturbed differential equations
to systems described by singularly perturbed difference equations. It laid down
a theoretical framework for studying multirate sampling control for systems
having slow and fast modes.

3.9. Interconnected Discrete-Time Systems
89
An alternative modeling formalism is to express system (3.147) into the
form
Σs :
xa(k + 1)
=
Aaxa(k) + Aexm(k) + Bau(k), xa(0) = xao
xm(k + 1)
=
Acxa(k) + Amxm(k) + Bmu(k), xm(0) = xmo
(3.153)
y(k)
=
Caxa(k) + Cmxm(k)
(3.154)
where xa(k)
∈ℜr, xm(k)
∈ℜn−r, u(k) ∈ℜm, and y(k) ∈ℜp. The
vectors x(k) = [xt
a(k)
xt
m(k)]t, u(k), and y(k) are the overall state, control,
and output vectors at the discrete instant k, respectively. The overall systems
matrices are expressed by
A
=
 Aa
Ae
Ac
Am

, B =
 Ba
Bm

, Ct =
 Ct
a
Ct
m

(3.155)
Remark 3.9.1 The material covered in this section constitutes, to a large ex-
tent, a distinct discrete version of the two-time-scale model of continuous-time
systems [155, 280], a simple comparison with models (3.149)-(3.152). In the
subsequent sections, we treat models (3.148) and (3.153) in relation to the orig-
inal model (3.147). We will reveal relevant structural properties and attend to
both regulation and observation (or estimation) problems. As we shall see later,
the dimension r plays a crucial role in the analysis.
3.9.1
Mode separation in discrete systems
Starting from model (3.153), we introduce the following notations,
λ(A)
=

λ1
λ2, · · ·
λn

,
V
=

v1
v2, · · ·
vn

,
W
=

w1
w2, · · ·
wn

(3.156)
to denote the eigen-spectrum of matrix A, the modal matrix and the matrix of
reciprocal basis vectors, respectively. For simplicity in exposition, we assume
that system (3.153) is a well-damped asymptotically stable system and is put
forward such that the n eigenvalues are arranged in the following manner:
1 |λ1| ≥· · · · · · ≥|λr| ≥|λr+1| · · · · · · ≥|λn|
(3.157)
The columns of V and W = V−1 are arranged in the same manner. It is should
be noted the ordering process can be conveniently achieved by standard per-
mutation and/or scaling procedures in numerical analysis [87].

90
Chapter 3. Historical Perspective and Scope
In the literature, system (3.153) is called two-time-scale [206]-[210] if
λ(A) can be separated by absolute values into nonempty sets S and F so that
|sj| >> |fk| ∀sj ∈S, ∀fk ∈F
(3.158)
Let r be the number of eigenvalues in S, then in view of (3.157), we get
|sj+1| ≤|sj|, j = 1, 2, · · · · · · , r −1,
|fk+1| ≤|fk|, k = 1, 2, · · · · · · , n −r −1
(3.159)
It is shown in [209, 210] that for any two-time-scale discrete system, the ratio
μ
=
|λM(F)|
|λm(S)| = |f1
|sr|,
=
|λr+1|
|λr|
<< 1
(3.160)
deﬁnes a measure of the time-separation in discrete systems. It should be em-
phasized that the parameter μ signiﬁes an intrinsic property of system (3.153)
and it does not appear explicitly in the model under consideration.
When discrete system (3.153) possesses the mode-separation property
(3.160), it follows that the eigen-spectrum λ(A) is composed of r large eigen-
values of order 1 and n −r small eigenvalues of order μ within the unit circle.
The small eigenvalues represent a fast subsystem whereas the large eigenvalues
designate a slow subsystem. In an asymptotically stable system, the fast modes
are important only during a short transient period. After that period they are
negligible and the behavior of the system can be described by its slow modes.
It has been reported that the slow and fast subsystems of system (3.153) are
expressed as
Slow subsystem:
xs(k + 1)
=
Asxs(k) + Bsus(k), xs(0) = xao
ys(k)
=
Csxs(k) + Dsus(k)
(3.161)
Fast subsystem:
xf(k + 1)
=
Amxf(k) + Bmuf(k), xf(0) = xmo −¯
xm(0)
yf(k)
=
Cmxf(k)
(3.162)
where
As
=
Aa + Ae(I −Am)−1Ac, Bs = Ba + Ae(I −Am)−1Bm
Cs
=
Ca + Cm(I −Am)−1Ac, Ds = Cm(I −Am)−1Bm (3.163)
¯xm(k)
=
(I −Am)−1[Acxs(k) + Bmus(k)]
(3.164)

3.9. Interconnected Discrete-Time Systems
91
and the matrix (I −Am)−1 ∈ℜn−r×n−r is assumed to exist and the quantity
¯xm(k) represents the quasi-steady state. The following deﬁnition is needed.
Deﬁnition 3.9.2 A vector or matrix function Ψ(μ) of a positive scalar μ is said
to be O(μm) if there exist positive constants c and μ∗such that
|Ψ(μ)| ≤cμ∗,
∀μ ≤μ∗
In view of Deﬁnition 3.9.2, the slow (reduced) subsystem (3.161) together with
the fast (boundary layer) subsystem (3.162) provides O(μ) approximation to
the dynamic behavior of the original system (3.153) and both subsystems are
of low order. This implies that
xa(k)
=
xs(k) + O(μ)
xm(k)
=
xf(k) + O(μ)
(3.165)
The reader is referred to [209, 238]-[241] where alternative procedures and
further details are given.
Our next objective is to improve the accuracy of the derived lower-order
methods. We recall from [280] that the underlying assumption of multitime-
scale theory is that during short-term studies the slow variables remain con-
stant and that by the time their changes become noticeable, the fast transients
have already reached their quasi-steady state. As pointed out in [155], the slow
variables during transients are time-varying quantities, a fact that leads us to
conclude that the true states xa(k) and xm(k) will differ from xs(k) and ¯xm(k)
mainly by their fast parts. A constructive procedure for iterative separation of
time-scales of the class of discrete-time systems (3.153) was reported in [212].
The result after t−L and i−K iterations is summarized by the model
αi(k + 1)
=
Ftiαi(k) + Gtiβt(k) + Rtiu(k),
βt(k + 1)
=
Htαi(k) + Ptiβt(k) + Etu(k)
(3.166)
where
Fti
=
Ft −KtiHt, Gti = Ae −KtiPt + FtiKti,
Pti
=
Pt −HtKti, Rti = (I −KtiLt)Ba −KtiBm,
Ft
=
Aa −AeLt, Ht = Ac −AmLt + LtFt,
Pt
=
Am + LtAe, Et = Bm + LtBa
(3.167)
and
Lt+1
=
Lt + (AmLt −LtAa + LtAe −Ac)(Aa −AeLj)−1,
L1
=
−(I −Am)−1Ac,
Kti+1
=
−F −1
t
Kti(PtHtKti), Kt1 = −F −1
t
Ae
(3.168)

92
Chapter 3. Historical Perspective and Scope
It should be noted that the slow and fast subsystems (3.166) are now very
weakly coupled since Gti is O(μi+t) and Ht is O(μt). It is also evident that Fti
and Pti are O(μi+t) approximations of the slow and fast modes, respectively.
Obviously, setting t = 1 and i = 0 in (3.166)-(3.168) results in the lower-order
models (3.161)-(3.162).
3.10
Feedback Control Design
In view of the mode-separation property, we now proceed to consider the
feedback control design problem with the objective of developing two-stage
schemes based on the dynamics of the slow and the fast subsystems.
3.10.1
State feedback design
A linear state feedback control is sought of the form
us(k) = Ksxs(k),
uf(k) = Kmxf(k)
(3.169)
where the gain matrices Ks ∈ℜm×r and Km ∈ℜm×n−r are to be designed
based on the independent speciﬁcations of the slow and fast dynamics. A com-
posite state feedback control is given by
u(k)
=

[I −Kf(I −Am)−1Bm]Ks −Kf(I −Am)−1Ac

xa(k)
+
Kmxm(k)
(3.170)
The following theorem in [209] establishes the properties of the feedback sys-
tem (3.153).
Theorem 3.10.1 Let the independent controls (3.169) and the composite con-
trol (3.170) be applied to the systems (3.161), (3.162), and (3.153), respec-
tively. If matrix Am + BmKm is asymptotically stable, then
xa(k)
=
xs(k) + O(μ)
xm(k)
=
xf(k) + (I −Am)−1(Ac + BmKs)xs(k) + O(μ)(3.171)
hold for all ﬁnite k ≥0. In addition, if matrix As + BsKs is asymptotically
stable then (3.171) holds for all k ∈[0, ∞).

3.10. Feedback Control Design
93
3.10.2
Design algorithm I
A two-stage eigenvalue assignment algorithm for state feedback design con-
sists of the following steps:
1. Compute Kf to place the eigenvalues of Am + BmKm at n −r desired
locations.
2. Compute Ks to place the eigenvalues of As + BsKs at r desired loca-
tions.
3. Compute Ka using the formula
Ka = [I −Kf(I −Am)−1Bm]Ks −Kf(I −Am)−1Ac
4. Implement the composite control
u(k) = Kaxa(k) + Kmxm(k)
Theorem 3.10.2 If Am has a spectral radius less than 1, then the low-order
control u(k) = Ksxa(k) can be used to stabilize system (3.153).
3.10.3
Illustrative example 3.5
To demonstrate the application of the above theoretical analysis, we consider a
ﬁfth-order discrete model of a steam plant described by
A
=
⎡
⎢⎢⎢⎢⎣
0.915
0.051
0.038
0.015
0.038
−0.031
0.889
−.001
0.046
0.111
−0.006
0.468
0.247
0.014
0.048
−0.715
−0.022
−0.021
0.240
−0.024
−0.148
−0.003
−0.004
0.090
0.026
⎤
⎥⎥⎥⎥⎦
,
Bt
=

0.0098
0.122
0.036
0.562
0.115

The open-loop eigenvalues are {0.8828± j0.0937, 0.2506± j0.0252, 0.295}
which shows internal oscillations. It can be easily checked that this model has
the mode-separation property (3.160) with r = 2, n −r = 3, and μ = 0.2646.

94
Chapter 3. Historical Perspective and Scope
The slow and fast subsystems (3.161) and (3.162) are given by
As
=
 0.8901
0.0727
−0.099
0.8858

, λ(Ao) = {0.8879 ± j0.0848}
Bt
s
=

0.0306
0.1761

,
Am
=
⎡
⎣
0.247
0.014
0.048
−0.021
0.240
−0.024
−0.004
0.090
0.026
⎤
⎦,
λ(Am)
=
{0.2506 ± j0.0252, 0.0295},
Bt
m
=

0.036
0.562
0.115

The pair (As, Bs) is controllable and the desired slow eigenvalues are placed
at {0.893, 0.825} using the gain
Ks = [−0.5465
0.0402]
For the fast subsystem, the desired fast eigenvalues are placed at
{0.251, 0.250, 0.0295}
using the gain
Km = [−0.0365
−0.0195
−0.0509]
This yields
Ka = [−0.5679
0.0432]
The closed-loop eigenvalues of the original ﬁfth-order model using the com-
posite control u(k) = Kaxa(k) + Kmxm(k) are found to be
{0.8891, 0.8890, 0.243, 0.242, 0.0342}
and the original internal oscillations have been eliminated thereby leading to
smooth behavior.
The foregoing design scheme depends on the availability of the state vari-
ables. In what follows, we look at the problem of designing observers in order
to estimate the slow and fast states.

3.10. Feedback Control Design
95
3.10.4
Observer design
By employing the available input and output measurements and assuming one-
step delay between measuring and processing the information records, a full-
order observer for system (3.153) is given by:
ˆxa(k + 1)
=
Aaˆxa(k) + Aeˆxm(k) + Bau(k)
+
Koa[y(k) −Caˆxa(k) + Cmˆxm(k)]
(3.172)
ˆxm(k + 1)
=
Acˆxa(k) + Amˆxm(k) + Bmu(k)
+
Kom[y(k) −Caˆxa(k) + Cmˆxm(k)]
(3.173)
where ˆxa(k) ∈ℜr,
ˆxm(k)ℜn−r are the estimates of xa(k), xm(k), and
Koa ∈ℜr×p and Kom ∈ℜn−r×p are the design parameters that may be prop-
erly selected to ensure any desired degree of convergence of the observation
scheme. Indeed, the design will exploit the mode-separation property.
In terms of the observation error vectors ˜xa(k) = xa(k) −ˆxa(k) and
˜xm(k) = xm(k) −ˆxm(k), it follows from (3.153), (3.154), (3.172), and
(3.173) that
˜xa(k + 1)
=
(Aa −KoaCa)˜xa(k) + (Ae −KoaCm)˜xm(k)
(3.174)
˜xm(k + 1)
=
(Ac −KomCa)˜xa(k) + (Am −KomCm)˜xm(k) (3.175)
Indeed, system (3.174)-(3.175) will function as an observer for system (3.153)
and (3.154) if the matrices can be selected such that system (3.172) and (3.173)
is asymptotically stable. The following theorem in [208] provides the main
results.
Theorem 3.10.3 Suppose that (I −Am)−1 exists. If the (As,
Cs) and
(Am, Cm) are observable pairs, then system (3.174)-(3.175) is asymptotically
stable. The gain matrix Koa is given by
Koa = Kos[I + Cf(I −Am)−1Kom] −Ae(I −Am)−1Kom
(3.176)
where Kos and Kom are any matrices for which As −KosCs and Am −
KomCm, respectively, have spectral norms less than one.
3.10.5
Design algorithm II
A two-stage eigenvalue assignment algorithm for observer design consists of
the following steps:
1. Compute Kom to place the eigenvalues of Am−KomCm at n−r desired
locations.

96
Chapter 3. Historical Perspective and Scope
2. Compute Kos to place the eigenvalues of As −KosCs at n desired loca-
tions.
3. Compute Koa using the formula (3.176).
3.10.6
Observer-based control design
For simplicity, it is assumed that the fast subsystem is asymptotically stable.
This allows us to construct a reduced-order observer of the slow subsystem
(3.161) and (3.163) of the form:
ˆxa(k + 1)
=
Asˆxa(k) + Bsu(k)
+
Kob[y(k) −Csˆxa(k) −Dsu(k)]
(3.177)
An observer-based controller is then described by
u(k) = Gobˆxa(k)
(3.178)
where Kob ∈ℜr×p and Gob ∈ℜm×r are the design parameters. The closed-
loop system can be expressed by
 xa(k + 1)
ˆxa(k + 1)

=

Aa
BaGob
KobCa
Amm
  xa(k)
ˆxa(k)

+

Ae
KobCm

xm(k)
(3.179)
xm(k + 1)
=
[Ac −BmGob]
 xa(k)
ˆxa(k)

+ Amxm(k) (3.180)
where
Amm = As + BsGob −KobCs −KobDsGob
System (3.179)-(3.180) exhibits the time-separation property with fast subsys-
tem described by
xm(k + 1)
=
Amxm(k)
(3.181)
and slow subsystem given by
(xs(k + 1)
=
F(xa(k)
F
=

Aa
BaGob
KobCa
Amm

(3.182)
The following theorem in [208] presents the main result.

3.10. Feedback Control Design
97
Theorem 3.10.4 If
1. Am is a stable matrix,
2. (As, Bs) is a controllable pair,
3. (As, Cs) is an observable pair
then the observer-based control (3.178) is a stabilizing controller. The gains
Kob and Gob are any matrices for which the matrices (As +BsGob) and (As −
KobCs), respectively, are stable matrices.
3.10.7
Design algorithm III
A two-stage eigenvalue assignment algorithm for observer-based feedback de-
sign consists of the following steps:
1. Compute Kob to place the observer eigenvalues of As −KobCs at r
desired locations.
2. Compute Gob to place the controller eigenvalues of As + BsGob at r
desired locations.
Next, we demonstrate the application of the foregoing feedback design.
3.10.8
Illustrative example 3.6
A variety of investigations on internal combustion engines have been carried
out using engine-dynamometer test rigs [276, 277]. Recent concern with pollu-
tion has caused further studies on petrol and diesel engines to become necessary
with a view to reducing their contribution to pollution of the atmosphere. For
this purpose, it is desirable to be able to control the torque and speed developed
by such engines independently so that the engines can be subjected to a test cy-
cle that will simulate typical road driving conditions. The purpose of this sim-
ulation example is to study the design of control schemes for such a system to
see how useful two-stage design methods are in providing independent control
of torque and speed. An existing analogue model of an engine-dynamometer
test rig [276] is used throughout this study, and two different models of the
system are considered [277] having order 3 and S. The engine considered is a
petrol engine representative of the type used to power medium-sized passenger
cars. The energy developed by the engine is controlled by the input voltage to
the throttle servo system used on the test rig. The dynamometer, which acts
as a load for the engine, consumes energy at a rate determined by the input

98
Chapter 3. Historical Perspective and Scope
voltage to the dynamometer ﬁeld-current controller. The engine-dynamometer
conﬁguration is shown schematically in Figures 3.16 and 3.17.
Figure 3.16: Engine-dynamometer schematic
Figure 3.17: Electrical analogue model
By linearizing the whole system model about a typical operating point, an
electrical analogue model [276] is shown in Figure 3.17 with experimental val-
ues for the various elements. The engine is represented as a constant velocity
source VE with internal resistance RE. The inertia of the engine is represented
by the capacitance CE. The dynamometer is represented by the constant cur-
rent source ID with internal resistance RD. The shaft connecting the engine to
the dynamometer is modeled by the combination of the dissipater Rs and the
inductance Ls, where the shaft is essentially considered as a rotational spring.

3.10. Feedback Control Design
99
The dynamics of the dynamometer clamping gear are represented by the dis-
sipater Rw, the capacitance Cw, and the inductance Lw. The control studies to
be described here were carried out on two versions of this basic model by using
a pertinent sampler plus hold units.
1. Third-order model
One model of the test rig considered is for the case where the dynamome-
ter casing was ﬁrmly clamped to the reference frame. This mode of operation
allows the design control systems with a marginally greater bandwidth [276]
and results in a simple third-order model, where the parallel combination of
Rw, Cw, and Lw are replaced by a direct connection. Using a sampling pe-
riod of 0.18s with zero-order hold, the discrete model of the type (3.147) with
g(k, x) ≡0 is given by the following matrices:
A
=
⎡
⎣
0.7189
0.0866
0.0733
0.4312
0.4704
−0.4206
−0.3262
0.1731
0.2027
⎤
⎦
B
=
⎡
⎣
0.1637
−0.2056
0.2010
−0.2155
0.0169
0.0152
⎤
⎦, Ct =
 1
0
0
0
0
1

where the state vector consists of the dynamometer rotor speed, engine
speed, and shaft torque while the control vector is composed of the throttle
servo voltage and dynamometer source current. This model has eigenvalues
{0.8275, 0.2830±j0.3030} which show that by tacking r = 1, n−r = 2 we
have the mode separation ratio μ = 0.5. The slow and fast subsystems (3.161)
and (3.162) are given by
As
=
0.7885, Bs =

0.1970
−0.2411

,
Cs
=

1
1.1982

, Ds =

0
0
0.0884
−0.0591

,
Am
=
 0.4704
−0.4206
0.1731
0.2027

, Bm =
 0.2010
−0.2155
0.0169
0.0152

,
Cm
=

0
1

The pair (As, Bs) is controllable and let the desired slow eigenvalues be placed
at {0.88} using the gain
Ks = [−2.0726
−2.0726]t

100
Chapter 3. Historical Perspective and Scope
For the fast subsystem, the desired fast eigenvalues are placed at {0.2 ± j0.3}
using the gain
Km = [−9.9615
−6.8717]t
This yields the composite control
u(k) =
 −4.652
0.0756
−9.961
−3.852
0.0128
−6.872

x(k)
2. Fifth-order model
This model is an extension of the third-order model by including the dy-
namics of an existing dynamometer ﬁeld-current ampliﬁer. The resulting model
is now of order 5 and has the state variables as the dynamometer rotor speed,
shaft torque, engine speed, and current ampliﬁer states. Using a sampling pe-
riod of 0.1928s and zero-order hold, which is selected to ensure matching the
response of the continuous model, the discrete model of the type (3.147) with
g(k, x) ≡0 is given by the following matrices:
A
=
⎡
⎢⎢⎢⎢⎣
0.8070
0
0
0.0092
0
−0.0267
0.5527
0.0171
−0.0002
0.0012
−0.1998
5.9560
0.1599
−0.0018
−0.2576
−5.0795
0
0
−0.0381
0
0.0243
−7.8493
0.2311
0.0003
−0.3805
⎤
⎥⎥⎥⎥⎦
,
B
=
⎡
⎢⎢⎢⎢⎣
0
0.8511
0.0766
−0.0106
0.7019
−0.0832
0
22.3995
0.1418
0.0257
⎤
⎥⎥⎥⎥⎦
, Ct =
 0
1
0
0
0
0
0
0
0
1

This model has open-loop eigenvalues
{0.7487, 0.7476, −0.2083 ± j0.2274, 0.0213}
which show that the static separation ratio has the value of 0.4125. It is readily
seen that this model has two slow states r = 2 and three fast states n −r = 3.
Direct calculation gives the slow subsystem matrices as
As
=

0.7621
0
−0.0294
0.6885

, Bs =

0
1.0492
0.0899
−0.0179

,
Cs
=

0
1
−0.2213
8.191

, Ds =

0
0
0.7684
−0.1439


3.10. Feedback Control Design
101
and the fast subsystem matrices as
Am
=
⎡
⎣
0.1599
−0.0018
−0.2576
0
−0.0381
0
0.2311
0.0003
−0.3805
⎤
⎦, Bm =
⎡
⎣
0.7019
−0.0832
0
22.3995
0.1418
0.0257
⎤
⎦,
Cm
=

0
0
1

Through the use of auxiliary devices, we can consider that all the state variables
become available for generating feedback signals, and proceed to apply the
state feedback design scheme. The desired eigenvalues are to be placed at
{0.8, 0.7, 0.0999, −0.2026, −0.2173}
to eliminate system oscillation. The slow gain matrix is
Ks =
 0.0076
−0.0913
0.0076
−0.0913

The fast gain matrix is
Km =
 −0.2861
0.0011
−0.0787
−0.2861
0.0011
−0.0787

This yields the composite control
u(k) =
 0.0541
0.0301
−0.2877
0.0012
−0.0784
0.0541
0.0301
−0.2877
0.0012
−0.0784

x(k)
This two-stage feedback control yields the closed-loop eigenvalues as
{0.8, 0.7001, 0.0998, −0.2179, −0.2021}
which are very close to the desired ones.
From the foregoing results, we can draw the following conclusions:
1. The two-stage feedback design schemes, based on the multiple-time-
scale analysis, provide effective methods for separate eigenvalue assign-
ment.
2. Since the output variables of the engine system model have different time
responses, independent control actions can easily be obtained that en-
able the design engineer to improve the performance of the engine sys-
tem.
3. In general, state feedback control provides robust results with respect to
parameter variations on the expense of using more measuring devices.

102
Chapter 3. Historical Perspective and Scope
3.10.9
Decentralized state reconstruction
In this section, we direct attention to large-scale systems with subsystem model
given by (3.148) and consider the problem of decentralized state reconstruc-
tion. Unlike the continuous-time case, we wish to show that depending on the
available observation records for reconstructing the states, two different prob-
lems arise:
1. The observation records consist of the measurements
{yj(k −1), yj(k −2), · · · , yj(0)}, j = 1, 2, ..., ns
2. The observation records consist of the measurements
{yj(k), yj(k −1), · · · , yj(0)}, j = 1, 2, ..., ns
Whereas Problem 1 entails a one-step delay in the measurement pattern on
the subsystem level, Problem 2 considers the situation whereby the subsys-
tem is performing instantaneous measurements. In both problems, the ns pairs
(Aj, Cj) are completely observable.
Considering Problem 1 and letting gj(k, x(k)) ≡0, it is fairly straightfor-
ward to design a state reconstructor for the jth subsystem of the form
ˆxj(k + 1)
=
Aj ˆxj(k) + Bjuj(k) + Kj[yj(k) −Cjˆxj(k)],
j
=
1, 2, ..., ns
(3.183)
where ˆxj(k) ∈ℜnj is the estimate of xj(k) and Kj ∈ℜnj×pj is the design
parameters that may be properly selected to ensure any desired degree of con-
vergence of the observation scheme. In terms of the estimation error vector
˜xj(k) = xj(k) −ˆxj(k), it follows from (3.153), (3.183) that
˜xj(k + 1)
=
(Aj −KjCj)˜xj(k)
(3.184)
It is well known that ˜xj(k) →0 as k →∞provided that the eigenvalues of the
matrix (Aj −KjCj) are located within the unit circle of the complex plane.
Theorem 3.10.5 If the interaction pattern is a linear function of the state vari-
ables, gj(k, x(k)) = ns
k=1 Gjkxk(k), with the matrix G = {Gjk} satisfying
the rank qualiﬁcation
rank
 C
G

= rank[C] = p =
ns

j=1
pj
(3.185)

3.10. Feedback Control Design
103
then the addition of the quantity ns
k=1 Mjkyk(k) to each local state recon-
structor (3.183) with
M = {Mjk} = GCt[CCt]−1
ensures the asymptotic convergence of the integrated state reconstruction
scheme.
The proof of Theorem 3.10.5 can be found in [207].
Remark 3.10.6 It is needless to emphasize that the developed reconstruction
scheme enjoys the merits of decentralized schemes. Only the local observability
condition is required for the present analysis. As mentioned before, the addi-
tional constraint arises from the linear interconnection pattern that identiﬁes
several useful situations in practice.
Next we consider Problem 2. An appropriate state reconstructor for the jth
subsystem would be
&xj(k + 1)
=
Aj&xj(k) + Bjuj(k)
+
Lj[yj(k + 1) −AjCj&xj(k) −CjBjuj(k)], j = 1, 2, ..., ns
=
[Aj −LjCjAj]&xj(k) + [Bj −LjCjBj]uj(k)
+
Ljyj(k + 1), j = 1, 2, ..., ns
(3.186)
where &xj(k) ∈ℜnj is the estimate of xj(k) and Lj ∈ℜnj×pj is the design
parameters that may be properly selected to ensure any desired degree of con-
vergence of the observation scheme. Similarly, in terms of the estimation error
vector (xj(k) = xj(k) −&xj(k), it follows from (3.153), (3.186) that
(xj(k + 1)
=
[Aj −LjCjAj](xj(k)
(3.187)
It is well known that (xj(k) →0 as k →∞provided that the eigenvalues of
the matrix [Aj −LjCjAj] are located within the unit circle of the complex
plane. It should be noted that the possibility of arbitrarily locating these eigen-
values depends on the observability of the pair (Aj, CjAj). If the matrix Aj
is nonsingular, then the observability of the pair (Aj, Cj) is equivalent to the
observability of the pair (Aj, CjAj) [35]. On the other hand, if the matrix Aj
is singular and the pair (Aj, Cj) is observable, then it can be shown that the
pair (Aj, CjAj) is both detectable and reconstructible [158].
The following results can be found in [207].

104
Chapter 3. Historical Perspective and Scope
Theorem 3.10.7 The state reconstruction schemes (3.183) and (3.186) are
identical under the condition
Kj = Aj Lj
(3.188)
Theorem 3.10.8 The modiﬁed state-reconstructor scheme
&xj(k + 1)
=
Aj&xj(k) + Bjuj(k)
+
Lj[yj(k + 1) −AjCj&xj(k) −CjBjuj(k)], j = 1, 2, ..., ns
=
[Aj −LjCjAj]&xj(k) + [Bj −LjCjBj]uj(k)
+
Ljyj(k + 1) +
ns

k=1
Sjkyk(k)
(3.189)
ensures the asymptotic convergence of the integrated state vector if Aj is non-
singular and the condition
rank
 C
G

= rank[C]
is satisﬁed where
S = {Sjk} = GCt[CCt]−1, L = Blockdiag[L1, L2, · · · , Lns]
3.10.10
Illustrative example 3.7
To demonstrate the application of the above theoretical analysis, we consider
three interconnected subsystems described by
A1
=
 0.7
0.2
0.1
0.8

, B1 =
 0
1

, Ct
1 =
 1
1

,
G12
=
 −6
3
0
0

, G13 =

0
0
−3
3

,
A2
=
 0.5
0.25
0
0.4

, B2 =
 1
0

, Ct
2 =

2
−1

,
G21
=

0
0
−2
−2

, G23 =
 2
−2
0
0

,
A3
=
 0.6
0
0.3
0.1

, B3 =
 1
1

, Ct
3 =
 −1
1

,
G31
=
 1
1
0
0

, G32 =
 0
0
4
−2


3.10. Feedback Control Design
105
Observe that matrices A1, A2, A3 are nonsingular, rank[Cj] = 1, j = 1, 2, 3,
and the pairs (A1, C1), (A2, C2), (A3, C3) are all observable. In case of
one-step delay in measurement, three eigenvalues z1 = 0.25, z2 = 0.45, z3 =
0.65 could be assigned. The result of computations give
K1
=
 0.506
0

, K2 =
 0.025
0

, K3 =
 0.11
0

Because the rank qualiﬁcation is met, the additional term for the local state
reconstructors is
M
=
⎡
⎢⎢⎢⎢⎢⎢⎣
0
−3
0
0
0
3
0
0
−2
−2
0
0
1
0
0
0
2
0
⎤
⎥⎥⎥⎥⎥⎥⎦
On the other hand, if the measurement records were instantaneous and because
of the nonsingularity of subsystem matrices, Problem 2 was solved to yield
L1
=

0.749
−0.094

, L2 =
 0.05
0

, L3 =
 0.183
−0.55

3.10.11
Linear quadratic control design
It was shown in the foregoing sections that a systematic procedure for complete
separation of slow and fast regulator designs can be developed by extending
the idea of two-stage eigenvalue assignment [208, 209]. Extending on this, we
show in this section that by recomposing the fast and slow optimal controls
based on the linear quadratic control (LQC) theory [3], an approximate feed-
back control can be readily obtained and subsequently formulated in a standard
form. When the asymptotically stable fast modes are neglected, a reduced-order
control can be derived and again put in a standard form.
Our starting point is the linear discrete system (3.153)-(3.154) and the cor-
responding slow-fast subsystems (3.161) and (3.162). We note from (3.161)
and (3.162) that the slow control us(k) and the fast control um(k) produce the
composite control uc(k) according to uc(k) = us(k) + um(k). In view of the
mode-separation, it has been shown [210] that a linear feedback scheme of the
type
us(k) = Gsxs(k),
um(k) = Gmxm(k)
(3.190)

106
Chapter 3. Historical Perspective and Scope
can be designed using independent gains Gs and Gm.
Hereafter, the optimal state regulator problem is considered which consists
of the linear dynamical system (3.153) and the associated quadratic perfor-
mance measure
J = 1
2
∞

m=0
{yt(m)y(m) + ut(m)Ru(m)},
R > 0
(3.191)
Instead of tackling the regulator problem (3.153) and (3.191) directly, we de-
compose it appropriately into two discrete regulators. The ﬁrst (slow) regulator
consists of the slow subsystem (3.161) and a quadratic performance measure
Js. The second (fast) regulator consists of the fast subsystem (3.162) and a
quadratic performance measure Jf. It must be emphasized that the construc-
tion of the subsystem measures is done such that J = Js + Jm. By solving
the fast and slow regulator problems independently, we obtain the slow control
us(k) and the fast control um(k). Later we recompose these controls, which are
subsystem optimal, to form the control uc(k) to be implemented on the system
(3.153).
Slow regulator
The problem is to ﬁnd us(k) to minimize
Js = 1
2
∞

m=0
{yt
s(m)ys(m) + ut
s(m)Rus(m)},
R > 0
(3.192)
for the slow subsystem (3.161). Manipulating (3.192), we reach
Js
=
1
2
∞

m=0
{xt
s(m)Ct
sCsxs(m) + 2ut
s(m)Dt
sCsxs(m)
+
ut
s(m)Rsus(m)},
R > 0
(3.193)
Rs
=
R + Dt
sDs
(3.194)
Recall from [158] that if the triplet (As, Bs, Cs) is stabilizable-detectable,
then there exists a stabilizing solution Ks ≥0 for the algebraic Riccati equation
Ks
=
(At
sKsAs + Ct
sCs)
−
(Bt
sKsAs + Dt
sCs)t(Rs + Bt
sKsBs)−1
×
(Bt
sKsAs + Dt
sCs)
(3.195)
The optimal slow control law is given by
us(k)
=
−(Rs + Bt
sKsBs)−1(Bt
sKsAs + Dt
sCs)xs(k)
(3.196)

3.10. Feedback Control Design
107
Fast regulator
The problem is to ﬁnd um(k) to minimize
Jm = 1
2
∞

r=0
{yt
m(r)ym(r) + ut
m(r)Rum(r)},
R > 0
(3.197)
for the slow subsystem (3.162). Manipulating (3.197), we reach
Jm
=
1
2
∞

r=0
{xt
m(r)Ct
mCmxm(r) + ut
m(r)Rum(r)}
(3.198)
Recall from [158] that if the triplet (Am, Bm, Cm) is stabilizable-detectable,
then there exists a stabilizing solution Km ≥0 for the algebraic Riccati equa-
tion
Km
=
(At
mKmAm + Ct
mCm)
−
At
mKmBm(R + Bt
mKmBm)−1Bt
mKmAm
(3.199)
The optimal fast control law is given by
um(k)
=
−(R + Bt
mKmBm)−1Bt
mKmAmxm(k)
(3.200)
Remark 3.10.9 The stabilizability-detectability conditions of the triples
(As, Bs, Cs), (Am, Bm, Cm)
are eventually independent. More importantly, it has been established [208,
209, 210] that they are equivalent to the stabilizability-detectability of the triple
(A, B, C) of the original system (3.153), where Bt = [Bt
a Bt
m]. The control
laws us(k) and um(k) given by (3.196) and (3.200) are only subsystem opti-
mal, that is, with respect to the slow and fast subsystem variables. However, it
is much easier and computationally simpler to determine them than the optimal
control for the overall system (3.153).
By comparing (3.196) and (3.200) to (3.190) we can identify the gains
Gs
=
−(Rs + Bt
sKsBs)−1(Bt
sKsAs + Dt
sCs)
Gm
=
−(R + Bt
mKmBm)−1Bt
mKmAmxm(k)
(3.201)
A standard form of the composite control uc(k) is established by the following
theorem which can be found in [223].

108
Chapter 3. Historical Perspective and Scope
Theorem 3.10.10 The composite control uc(k) can be put into the form
uc(k)
=
−(R + BtKcB)−1BtKcAcx(k) = Lx(k)
(3.202)
B
=
 Ba
Bm

, Ac =
 As
Ab
Ad
Am

, Kc =
 Ks
0
Kn
Kb

Ab
=
−BaGm, Kt
n = KsA1(I −Am)−1
S
=
(Bs −Ba)Gs + BaGm(I −Am)−1(BmGs + Ac)
Ad
=
Ac −(I −Am)−1(BmGs + Ac) + Bm(I −Am)−1Bt
aKsS
+
K−1
m [KnS + (I −Am)−1Ct
m(Cs + DsCs)]
(3.203)
We must emphasize that the approximate control (3.202) is in the standard form
of optimal discrete regulator theory [158]. Recall that the exact optimal control
for the complete dynamic problem (3.153) and (3.191) is given by
uc(k)
=
−(R + BtPoB)−1BtPoAx(k) = −Gox(k)
(3.204)
where Po is the stabilizing solution of the algebraic Riccati equation
Po = AtPoA −AtPoB(R + BtPoB)−1BtPoA + CtC
(3.205)
and the associated optimal performance measure is Jo = (1/2)xt
oPoxo with xo
being the initial state. By virtue of (3.202), the approximate closed-loop system
takes the form
x(k + 1)
=
(A −BL)x(k)
(3.206)
We know that minimizing (3.191) subject to (3.206) results in the suboptimal
performance measure Jc = (1/2)xt
oPcxo, where Pc is the positive deﬁnite
solution of the discrete Lyapunov equation
Pc = (A −BL)tPc(A −BL) + CtC + LtRL
(3.207)
Let the suboptimality index be deﬁned by
Pc −Po = εPc
(3.208)
which, in the light of Jo and Jc, expresses the relative performance degradation,
that is, ε = (Jc −Jo)/Jo. The following theorem provides a useful expression
[223].
Theorem 3.10.11 An upper bound on the suboptimality index ε is given by
ε ≤||AtPoA|| + ||Pc||
||CtC||
−1
(3.209)

3.10. Feedback Control Design
109
It is important to observe that the relative performance degradation ε depends
on the subsystem information. When the fast modes are asymptotically stable,
we set Gm = 0 and obtain the reduced control
ur(k)
=
−(Rs + Bt
sKsBs)−1(Bt
sKsAs + Dt
sCs)x1(k)
=
−Lrx(k)
(3.210)
The next theorem gives an important special case.
Theorem 3.10.12 The reduced-order control (3.210) can be expressed as
ur(k)
=
−(R + BtKrB)−1BtKrArx(k),
Kr
=
=
 Ks
Kt
n
Kn
0

, Ar =
 As
0
Aw
0

,
Aw
=
KnBa(Bt
aKt
nKnBa)−1Dt
sCs −WV (Bt
sKsAs + Dt
sCs),
W
=
Dt
sDs + Bt
m(I −Am)−1At
eKt
nBm,
V
=
(Rs + Bt
sKsBs)
(3.211)
which produces performance degradation bounded by
εr ≤||AtPoA|| + ||Pc||
||CtC||
−1
(3.212)
where Pr = Pc + Pd = (εr −ε)Po and
Pr
=
(A −BLr)tPr(A −BLr) + CtC + Lt
rRLr
Lr
=
LT = L

I
0
(I −Am)−1(BmGo + Ac)
0

Pd
=
(A −BLr)tPd(A −BLr) + AtPcBL(I −T)
+
(I −T)tLtBtPcA −LtBtPcBRL
−
LtRL + T tLtBtPcBRLT + T tLtRLT
(3.213)
A detailed treatment of Theorem 3.10.12 can be found in [223].

110
Chapter 3. Historical Perspective and Scope
3.10.12
Illustrative example 3.8
A power system model of the type (3.153) is described by [206].
Aa
=
⎡
⎢⎢⎣
0.928
−0.029
0.028
0.0318
−0.253
0.882
−0.09
−0.0091
0
0
0.861
0.218
0
0
0
0.835
⎤
⎥⎥⎦,
Ae
=
⎡
⎢⎢⎣
0.06
1.073
0
0.04
−0.03
−0.455
0.5467
−0.02
0
0
0
0.29
0
0
0
0
⎤
⎥⎥⎦,
Ac
=
⎡
⎢⎢⎣
0
0
0.1516
0.0218
−0.077
0.0665
−0.003−
0.003
−0.1727
0.152
0.152
−0.0102
0
0
0
0.185
⎤
⎥⎥⎦,
Am
=
⎡
⎢⎢⎣
0.165
0
0
0.046
−0.007
0.156
0.118
0.007
−0.016
−0.31
0.008
−0.012
0
0
0
0.011
⎤
⎥⎥⎦,
Bt
a
=
 −0.038
0.294
0
0
0.01
−0.003
0.076
0.725

,
Bt
m
=

0
0.081
0.207
0
0.006
−0.0008
−0.004
0.124

,
C1
=
⎡
⎢⎢⎣
0
0
0
4.545
0
1
0
0
0
0
0
0
0
0
0
0
⎤
⎥⎥⎦,
C2
=
⎡
⎢⎢⎣
0
0
0
0
0
0
0
0
0
0
13.333
0
0
18.182
0
0
⎤
⎥⎥⎦

3.11. Applications
111
With R = I2, direct computation yields the gain matrices
Go
=

Go
1
Go
2

,
Go
1
=

0.818
−0.744
0.038
0.026
−0.019
0.005
−0.006
−1.061

,
Go
2
=

0.075
0.685
−0.635
0.025
−0.002
−0.037
−0.0014
−0.0031

,
L
=

Go
1
Go
2

,
L1
=

0.813
−0.743
0.039
0.0259
−0.021
0.0061
−0.005
−1.061

,
L2
=

0.072
0.615
−0.608
−0.023
−0.001
−0.075
−0.011
−0.003

,
Lr
=

Lr1
0

,
Lr1
=
 0.806
−0.736
0.523
0.03
−0.02
0.006
−0.006
−1.061

together with
Jo
=
trace(Po) = 567.424, Jc = trace(Pc) = 567.5176,
Jr
=
trace(Pr) = 578.861
The index ε in (3.208) has the values 0.0168, whereas its upper bound in
(3.209) is 0.19845. Also, εr = 0.0202 whereas its upper bound in (3.212)
is 0.22232. It is clearly evident that the developed composite control produces
good performance results.
The net result of this section illuminated the fact that procedures for de-
composition, feedback design, and optimal control of linear discrete regulators
with time-separation property are systematically disclosed and shown to be ef-
fective. The computations are carried out on the subsystem matrices. Bounds
on suboptimality are given to clarify the degree of suboptimality.
3.11
Applications
In this section, we solve some examples that arise in different system applica-
tions.

112
Chapter 3. Historical Perspective and Scope
3.11.1
Serially connected subsystems
A state-space model of four serially connected subsystems considered in [292]
has the following data:
A
=
⎡
⎢⎢⎣
A1
0
0
A2
A2
A3
A4
0
0
A4
A3
0
A4
0
A2
A1
⎤
⎥⎥⎦, B =
⎡
⎢⎢⎣
B1
0
0
0
0
B1
0
0
⎤
⎥⎥⎦,
A1
=
⎡
⎣
0
1
0
0
0
1
−1
−3
−2
⎤
⎦, A2 =
⎡
⎣
0
0
0
0
0
0
1
0
0
⎤
⎦,
A3
=
⎡
⎣
0
1
0
0
0
1
−1
−2
−3
⎤
⎦, A4 =
⎡
⎣
0
0
0
0
0
0
0
1
0
⎤
⎦,
B1
=
⎡
⎣
0
0
1
⎤
⎦, A2 =
⎡
⎣
0
0
0
0
0
0
1
0
0
⎤
⎦,
C
=
Blockdiag

C1
C1
C1
C1

, C1 =
 1
0
0
0
1
0

Simulation results are shown in Figure 3.18.
3.11.2
Liquid-metal cooled reactor
In this section, we introduce the model and some numerical simulation results
of a liquid-metal cooled reactor (LMCR) of a nuclear power system based on
the material reported in [23]. Consider the LMCR module of a nuclear reac-
tor shown in Figure 3.19. Each reactor module consists of an LMCR reactor
with the corresponding primary and intermediate heat transport loops, a recir-
culating steam generator, and steam drum. All the modules are connected to
a common steam heater that feeds the turbine. The equations describing the
dynamic behavior of a reduced model can be cast into the nonlinear form:
˙x1
=
(a1 + a2x3 + a3x4)a4x1 + a4x2 + (a4a5)u1,
˙x2
=
λ(x1 −x2),
˙x3
=
b1x1 + b2(x4 −x3),
˙x4
=
−b3(x4 −x3) + b4(x7 −x4)u2,

3.11. Applications
113
−202
From: In(1)
 
 
To: Out(1)
−0.50
0.5
To: Out(2)
−202
To: Out(3)
−202
To: Out(4)
−202
To: Out(5)
−0.50
0.5
To: Out(6)
012
To: Out(7)
−0.50
0.5
To: Out(8)
−0.50
0.5
To: Out(9)
012
To: Out(10)
−0.50
0.5
To: Out(11)
0
20
40
60
80
−0.10
0.1
To: Out(12)
From: In(2)
0
20
40
60
80
INPUT1
Time (sec)
Amplitude
Open Loop
Closed Loop Q>>R
Closed Loop Q<<R
Figure 3.18: State trajectories
Figure 3.19: A liquid-metal cooled reactor

114
Chapter 3. Historical Perspective and Scope
˙x5
=
b5(x4 −x3)u2,
˙x6
=
b6(c1 + c2 −x6) + c3(x5 −x6)u2,
˙x7
=
c4(x6 −x7)u2
where a1, ..., a5, b1, ..., b5, and c1, ..., c4 are reactor constants deﬁned in
[136] and the respective model variables are deﬁned by
1. x1 is the normalized neutron power,
2. x2 is the normalized delayed neutron precursor concentration,
3. x3 is the ratio of fuel temperature to reference temperature,
4. x4 is the ratio of core coolant outlet temperature to reference tempera-
ture,
5. x5 is the ratio of primary inlet temperature to reference temperature,
6. x6 is the ratio of primary outlet temperature to reference temperature,
7. x7 is the ratio of core inlet temperature to reference temperature,
8. u1 is the control rod position,
9. u2 is the primary pump fractional ﬂow.
The control input signals are scaled so that 0 ≤u1 ≤1 with 0 means inserted
(minimum or closed) and 1 corresponds to withdrawn (maximum or open).
Evaluating the equilibrium operating values xe, ue from the data in [136] and
performing standard linearization, we obtain the linearized model
˙z1
=
Az + Bv, z = x −xe, v = u −ue,
A
=
 A1
A2
A3
A4

, B =
 B1
0
0
B2

,
A1
=
⎡
⎣
−2.4238 × 108
952.38
−6.722 × 107
0.01
−0.01
0
−0.1437
0
−0.4948
⎤
⎦,
A2
=
⎡
⎣
−6.722 × 107
0
0
0
0
0
0
0
0.4948
0
0
0
⎤
⎦,
A3
=
⎡
⎢⎢⎣
0
0
0.3877
0
0
0
0
0
0
0
0
0
⎤
⎥⎥⎦,

3.11. Applications
115
A4
=
⎡
⎢⎢⎣
−0.4101
0
0
0.0224
0.06772
−0.0677
0
0
0
0.0677
−0.1754
0
0
0
0.0224
⎤
⎥⎥⎦,
B1
=
⎡
⎣
3333.3
0
0
⎤
⎦, B2 =
⎡
⎢⎢⎣
−0.0101
0
0.0304
0
⎤
⎥⎥⎦
We solve the problem as a full-order linear-quadratic regulator and the ensu-
ing step response is presented in Figures 3.20 and 3.21 for the respective con-
trol inputs. Alternatively, we apply the decentralized linear-quadratic regulator
Figure 3.20: Step responses of LMCR from input 1
[200] by treating A2, A3 as interaction matrices. The corresponding system
responses are provided in Figures 3.22-3.25, which show the effectiveness of
the decentralized control approach.
3.11.3
Boiler system
The state-, input-, and output-variables of a boiler system comprising a super-
heater and riser in series with each other [284] are

116
Chapter 3. Historical Perspective and Scope
Figure 3.21: Step responses of the LMCR from input 2
• x1 is the density of output steam ﬂow,
• x2 is the temperature of output steam ﬂow,
• x3 is the temperature the superheater,
• x4 is the riser outlet mixture quality,
• x5 is the water ﬂow in riser,
• x6 is the water pressure in riser,
• x7 is the riser tube-wall temperature,
• x8 is the temperature of water in boiler,
• x9 is the level of water in boiler,
• u1 is the input fuel,
• u2 is the input water ﬂow,
• y1 is the temperature of output steam ﬂow,
• y2 is the riser outlet mixture quality,
• y3 is the water ﬂow in riser,

3.11. Applications
117
Figure 3.22: Different responses of the LMCR from input 1-part A
• y4 is the water pressure in riser.
By simulating the ninth-order linear continuous model and its discretized ver-
sion using ﬁrst-order approximation, it is found that a sampling period of 0.5s
yields a discrete model whose response matches very closely that of the con-
tinuous model. The data values use aEx to mean a × 10x.
Using the permutation matrix
P = {e9, e8, e2, e5, e7, e6, e4, e3, e1}
and the scaling matrix
S = Blockdiag[0.015, 0.015, 0.05, 0.1, 2, 0.5E−4, 0.15, 5, 0.2E4}
where ej is the elementary column vector whose jth entry is 1, the transformed
discrete system has the eigenvalues
{1.0, 0.1452 ± j0.0726, 0.2298, 0.89, 0.996, 0.9741 ± j0.0905, 0.8461}

118
Chapter 3. Historical Perspective and Scope
Figure 3.23: Different responses of the LMCR from input 1-part B
It is estimated that the model has six slow and three fast variables. In terms of
system (3.153) and (3.154), the data values are
Aa
=
 Aa1
Aa2
Aa3
Aa4

,
Aa1
=
⎡
⎣
1
−0.1489E−3
0.1050E−3
0
0.9866
−0.3550E−3
0
−0.1389E−3
0.9866
⎤
⎦,
Aa2
=
⎡
⎣
0.1051E−3
0.0289
0.3127E−3
−0.2745E−3
0.9544E−5
−0.0195
0.3156E−3
−0.0391
0.0257
⎤
⎦,
Aa3
=
⎡
⎣
0
0.8048E−2
0.2856E−2
0
−0.2065E−2
0.3328E−2
0
0.7152E−2
0.2589E−1
⎤
⎦,
Aa4
=
⎡
⎣
0.9057
−0.7275E−4
0.1951
0.7091E−3
0.8829
0.1479E−1
0.1980E−1
−0.8358E−3
0.8705
⎤
⎦,
Ae
=
⎡
⎢⎢⎢⎢⎢⎢⎣
−0.2667E−5
−0.5914E−6
−0.3823E−5
−0.1585E−7
0.4712E−2
0.5030E−4
0.8717E−4
0.9676E−5
−0.1144E−5
0.1169E−6
0.3265E−5
0.1673E−4
−0.1071E−4
−0.9028E−5
0.1334E−4
0.1445E−5
0.1345E−4
0.1143E−3
⎤
⎥⎥⎥⎥⎥⎥⎦
,

3.11. Applications
119
Figure 3.24: Different responses of the LMCR from input 2-part A
Ac
=

Ac1
Ac2

,
Ac1
=
⎡
⎣
0
−6.01465
0.3120E2
0
0.2490E3
−0.8749
0
−0.5153E2
6.2408
⎤
⎦,
Ac2
=
⎡
⎣
−0.1336E1
−0.2310E3
−0.1006E3
−0.6724
0.2564E−1
−0.3105E2
0.4815E1
−0.1692
0.3291E3
⎤
⎦,
Am
=
⎡
⎣
0.2375
0.0670
−0.2622E−1
−0.4447E−4
0.1998
0.8275E−1
0.2825E−3
−0.1018
0.1490
⎤
⎦,
Ae
=
⎡
⎢⎢⎢⎢⎢⎢⎣
−0.2667E−5
−0.5914E−6
−0.3823E−5
−0.1585E−7
0.4712E−2
0.5030E−4
0.8717E−4
0.9676E−5
−0.1144E−5
0.1169E−6
0.3265E−5
0.1673E−4
−0.1071E−4
−0.9028E−5
0.1334E−4
0.1445E−5
0.1345E−4
0.1143E−3
⎤
⎥⎥⎥⎥⎥⎥⎦
,

120
Chapter 3. Historical Perspective and Scope
Figure 3.25: Different responses of the LMCR from input 2-part B
Ba
=
⎡
⎢⎢⎢⎢⎢⎢⎣
0.1777E−4
0.4490E−5
−0.3191E−3
0.1159E−1
0.2177E−3
0.3889E−4
−0.6494E−4
0.1109
−0.1159E−3
−0.2689E−4
−0.7698E−3
0.1239E−2
⎤
⎥⎥⎥⎥⎥⎥⎦
,
Bm
=
⎡
⎣
2.3080
0.1651
−0.7292
1.8098
−0.4393
−0.5085E−1
⎤
⎦, Cm =
⎡
⎢⎢⎣
0
0
0
0
0
0
0
0
0
0
1
0
⎤
⎥⎥⎦,
Ca
=
⎡
⎢⎢⎣
1
0
0
0
0
0
0
0
0
0
1
0
0
0
0
0
0
1
0
0
0
0
0
0
⎤
⎥⎥⎦
The slow subsystem is described by the level of water in boiler, temperature
of the superheater, riser tube-wall temperature, riser outlet mixture quality, and
water pressure in riser, in order of dominance. On the other hand, the fast sub-
system is represented by water ﬂow in riser, temperature of output steam ﬂow,
and density of output steam ﬂow.
The numerical solution based on iterative separation of time-scales took
seven-L and one-K iterations to converge to mode-separation ratio μ = 0.2069.

3.11. Applications
121
This yields the fast subsystem as described by the triplet Am, Bm, Cm, while
the slow subsystem is expressed by the matrices
As
=
 As1
As2
As3
As4

,
As1
=
⎡
⎣
1
−0.1334E−3
0.5951E−3
0
0.9959
−0.2997E−6
0
0.3450E−2
0.9721
⎤
⎦,
As2
=
⎡
⎣
0.8872E−4
−0.2813E−1
−0.7785E−3
−0.2274E−6
0.1616E−7
0.6003E−5
0.1350E−3
−0.6551E−1
0.1263E−1
⎤
⎦
As3
=
⎡
⎣
0
0.7419E−2
0.2983E−2
0
−0.6295E−2
0.2994E−2
0
0.1967E−2
0.2697E−1
⎤
⎦,
As4
=
⎡
⎣
0.9058
−0.1132E−3
0.2015
0.8083E−3
0.8862
0.2149E−1
0.2045E−1
−0.1308E−2
0.9145
⎤
⎦
Bs
=
⎡
⎢⎢⎢⎢⎢⎢⎣
0.2953E−3
0.3310E−5
−0.6407E−3
0.1168E−1
0.4760E−3
0.9704E−4
−0.1528E−3
0.1109
−0.2016E−3
−0.2016E−5
−0.1355E−2
0.1232E−2
⎤
⎥⎥⎥⎥⎥⎥⎦
,
Cs
=
⎡
⎢⎢⎣
1
0
0
0
0
0
0
0
0
0
1
0
0
0
0
0
0
1
0
0.3012E3
−0.3318
−0.2520
0.1771E−1
1.1668
⎤
⎥⎥⎦
It is easy to check that both slow and fast subsystems are completely control-
lable and observable. A full-order observer can be designed to reconstruct the
slow and fast states. Assigning three eigenvalues at {0.15, 0.13, 0.11} yields
Kom
=
⎡
⎣
0
0
0
−61.6373
0
0
0
−0.1962
0
0
0
−0.9500
⎤
⎦

122
Chapter 3. Historical Perspective and Scope
Next, assigning six eigenvalues at {0.99, 0.97, 0.95, 0.93, 0.91, 0.98} gives
Kos
=
⎡
⎢⎢⎢⎢⎢⎢⎣
−0.3992E−1
0.8283E−2
−0.7771E−2
0.1253E−4
−0.1301E−2
−0.2002E−3
0.3398E−3
−0.2193E−3
0.4738E−1
−0.1646E−1
−0.3697E−4
0.7003E−2
0.6404
0.1308
−0.2290
0.1758E−3
0.9804E−1
0.1859E−1
−0.2819E−1
0.3910E−4
−0.3736
−0.4547E−1
0.5312E−1
−0.1472E−3
⎤
⎥⎥⎥⎥⎥⎥⎦
From (3.176), we get the slow gain as
Koa
=
⎡
⎢⎢⎢⎢⎢⎢⎣
−0.3992E−1
0.8283E−2
−0.7771E−2
0.1996E−3
−0.1301E−2
−0.2002E−3
0.3398E−3
−0.2585E−3
0.4738E−1
−0.1646E−1
−0.3697E−4
0.7004E−2
0.6404
0.1308
−0.2290
0.2321E−3
0.9804E−1
0.1859E−1
−0.2819E−1
−0.8178E−3
−0.3736
−0.4547E−1
0.5312E−1
0.5173E−4
⎤
⎥⎥⎥⎥⎥⎥⎦
Proceeding further and since Am is a stable matrix, As, Bs is a controllable
pair, and As, Cs is an observable pair, then we employ Theorem 3.10.4 to de-
sign a lower-order observer-based controller. Placing the observer eigenvalues
at
{0.83, 0.82, 0.81, 0.80, 0.79, 0.78}
gives
Kob
=
⎡
⎢⎢⎢⎢⎢⎢⎣
−0.5879
0.2398
−0.2538E−1
0.2100E−4
−0.9063E−1
0.5282E−1
−0.6228E−2
−0.6453E−3
−0.1249E3
0.6905E2
−0.8445E1
0.6829E−2
0.3669E2
−0.1807E2
0.1703E1
−0.18123E−2
0.19324E1
0.19968
−0.1554
0.1285E−3
−0.1232E2
0.7272E1
−0.1058E1
0.7215E−3
⎤
⎥⎥⎥⎥⎥⎥⎦
and selecting the desired closed-loop eigenvalues to be
{0.99, 0.897, 0.95, 0.93, 0.91, 0.89}
results in
Gob
=

Gob1
Gob2

,
Gob1
=
 −0.2035E3
−0.7295E2
0.6145E2
−0.3760E2
−0.8199E1
0.5847E1

,
Gob2
=
 0.6797E1
0.7904E1
0.3152E2
0.8749
0.5298E1
0.6536E1


3.11. Applications
123
The matrices Kob and Gob are then the required gains to implement the
observer-based feedback controller (3.177)-(3.178) to the discrete model of the
boiler system.
3.11.4
Hydraulic system with electronic test gear
In process industry, electronic test gears are usually mounted near large tanks of
liquid gases to help in evaluating the temperature proﬁle. A state model of this
type of hydraulic system equipped with insulation materials has the following
data values:
A
=
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
−5
0
0
1
0.1
−0.5 −0.009
3
0
−2
0
1
−0.29
0
−0.3
0.48
−0.08 −0.11 −3.99 −0.93
0
0.1
0
0
0
0
1.32
−1.39
−1
−0.4
0
0
0
0
−0.1
−0.4
−0.2
0
0
0
0
0
0
0
0
−0.17
0
0
0
0
0
0
0
0
−0.5
0
0
0
0
0
0
0.01
0
−0.11
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
,
Bt
=
 4
0
0
0
0
0
0
0
0
0
0
0
0
0
10
0

, C =
 1
0
0
0
0
0
0
0
0
0
0
0
0
1
0
0

where the states are the internal pressures and heat ﬂow rates and the control
variables are the pressures of the liquid gas and surroundings. We treat the
system under consideration as composed of two-coupled systems: each has
four states, single input and single output. Our purpose is to compare three
coordinated control methods as reported in [200, 322, 354]. Our scheme of
comparison relies on the results of two fourth-order subsystems vis-`a-vis the
eighth-order system. The control gains are given by
Method of [322]
K1
=

K11
K12

,
K11
=
 −0.0098
−0.0685
−0.8308
−0.3792
−0.0037
−0.0261
−0.3159
−0.1442

,
K12
=

0.1283
0.0001
−0.0001
0.0001
−0.1043
−0.0001
0.0001
−0.0001


124
Chapter 3. Historical Perspective and Scope
Method of [354]
K2
=

K21
K22

,
K21
=
 −0.0141
−0.2290
−0.7302
−0.6726
0.0170
1.4904
0.0355
0.3876

,
K22
=

0.2358
0.1156
0.0393
−0.1314
−0.5895
0.0536
0.2157
−0.3400

Method of [200]
K3
=

K31
K32

,
K31
=
 −0.0084
−0.0592
−0.7171
−0.3273
−0.0002
0.0001
−0.025
−0.1001

,
K32
=
 −0.0020
0.0100
−0.0002
0.0001
−0.9512
0.0100
−0.0002
0.0001

,
||K1||
=
0.9835, ||K2|| = 0.9613, ||K3|| = 1.7706
Figure 3.26: Responses of the main pressure using centralized gain and coor-
dinated gain K1
Simulation results are presented in Figures 3.26-3.28. It is noted that the differ-
ence between the centralized method based on the linear-quadratic theory and
the coordinated control methods lies toward the end of the time-span and there
is consistency during most of the trajectories.
3.12
Problem Set I
Problem I.1: Consider a large-scale system of the type (3.125) with linear

3.12. Problem Set I
125
Figure 3.27: Responses of the main pressure using centralized gain and coor-
dinated gain K2
interconnection pattern. Let 0 < Pj = P t
j satisfy the following ARE:
PjAj + At
jPj + Qj −PjBjR−1
j Bt
jPj = 0,
j = 1, 2, ...ns
where 0 < Qj = Qt
j, 0 < Rj = Rt
j. Use Lyapunov theory to show that
there exists a stabilizing decentralized output feedback controller of the form
u(t) = −FCx(t) where
F = Blockdiag[F1, ..., Fns], C = Blockdiag[C1, ..., Cns]
if the following inequalities
P −1
j
QjP −1
j
+ 2BjP −1
j
Bt
j −4AjkQ−1
k At
jk +
2(AjP −1
j
+ P −1
j
At
j) > 0,
j = 1, 2, ...ns, k = 1, 2, ...ns
are satisﬁed.
Problem I.2: Consider the system described by
˙x1
=
x2
1 x2 + u1,
˙x2 = x2
2 x3 + u2,
˙x3
=
x2
3 x1 + u3
where it is desired to develop static controllers in the spirit of Section 3.4.2
such that xj →0, j = 1, 2, 3. Identify the bounding relations on the intercon-
nections. By selecting appropriate controller parameters, simulate the resulting
closed-loop system starting from x1(0) = 1, x2(0) = −2, x3(0) = 2.

126
Chapter 3. Historical Perspective and Scope
Figure 3.28: Responses of the main pressure using centralized gain and coor-
dinated gain K3
Problem I.3: Consider a system composed of two pendulums connected by a
spring. The dynamics for this system are given by
˙θ1
=
ω1 ,
J1 ˙ω1
=
κ (θ2 −θ1) + 1; u1,
˙θ2
=
ω2 ,
J1 ˙ω2
=
κ (θ1 −θ2) + 1; u2
where θj and ωj are the position and angular velocity for the jth pendulum,
respectively. Here κ is an interconnection constant based on the spring stiffness
and lever arm associated with the connection point. Derive decentralized con-
trollers for each torque input uj so that θj →0, j = 1, 2.
Problem I.4: Consider a large-scale discrete-time system of order 6 with sub-
system model given by (3.148) and explicitly consists of three subsystems with
the following data:
A1
=
 0.7
0.2
0.1
0.8

, B1 =
 0
1

, C1 =
 1
0
0
1

,
A2
=
 0.5
0.15
0
0.4

, B2 =
 1
0

, C1 =
 2
0
0
−1

,
A3
=
 0.6
0
0.3
0.1

, B3 =
 1
1

, C1 =
 −1
0
0
1


3.12. Problem Set I
127
along with the interconnection matrix
H
=
⎡
⎢⎢⎢⎢⎢⎢⎣
0
0
−6
0
0
0
0
0
0
0
0
3
0
0
0
0
0
0
0
−2
0
0
2
0
1
0
0
0
0
0
0
0
0
−2
0
0
⎤
⎥⎥⎥⎥⎥⎥⎦
, B1 =
 0
1

, C1 =
 1
0
0
1

It is required to design observers such that the desired eigenvalues for the re-
spective subsystems are {0.1, −0.7}, {0.3, 0.4}, {−0.6, −0.2} using instan-
taneous and one-step delay measurements.
Problem I.5: A fourth-order discrete system of the type (3.153)-(3.154) is de-
scribed by:
Aa
=
 0.9
0
0.1
0.8

, Ae =

0
0.1
0.05
−0.1

, Ac =
 −0.1
0
0.12
0.03

,
Am
=
 0.15
0
0
0.1

, Ba =
 1
0
0
1

, Bm =

1
0.5
0.5
0

,
Ca
=
 0.1
0
0
0.1

, Cm =

0
0.1
0.2
0

Develop a reduced-order model that inherits the slow modes of the system.
Then design a stabilizing dynamic output-feedback controller.
Problem I.6: A large-scale discrete-time system of the form
˙x(t) = Ax(t) + Bu(t)
has the following data:
A
=
⎡
⎢⎢⎢⎢⎢⎢⎣
0
1
0.5
1
0.6
0
−2
−3
1
0
0
1
0.5
1
0
2
1
0.5
0
0.5
1
3
0
−0.5
1
0
0
1
0
1
0
0.5
0.5
0
−3
−4
⎤
⎥⎥⎥⎥⎥⎥⎦
,
Bt
=
⎡
⎢⎢⎣
1
1
0
0
0
0
0
0
3
0
0
0
0
0
0
4
0
0
0
0
0
0
2
3
⎤
⎥⎥⎦

128
Chapter 3. Historical Perspective and Scope
Derive the optimal controller based for the full-order system with weighting
matrices Q = I6, R = I4. Then compare the results with the decentralized
controllers based on three coupled subsystems.
Problem I.7: A linearized model of a two-link manipulator can be put into the
form
˙x(t) = Ax(t) + Bu(t)
with the following data:
A
=
⎡
⎢⎢⎢⎢⎢⎢⎣
−a1
0
0
0
0
0
0
0
1
0
0
0
a2
−a2
a3
0
0
a4
0
0
0
−a5
0
0
0
0
0
0
0
1
0
0
a6
a7
−a7
a8
⎤
⎥⎥⎥⎥⎥⎥⎦
,
Bt
=
 a1
0
0
0
0
0
0
0
0
a5
0
0

Use the following parameter values:
a1 = a5 = 0.1, a2 = a7 = 10, a3 = −1.8, a4 = 0.1, a6 = 0.1, a8 = −2
Develop decentralized and hierarchical controllers with unity weighting matri-
ces and compare between the closed-loop system performance. Then discretize
the model using Δt = 0.05 and generate decentralized and hierarchical con-
trollers with unity weighting matrices. Compare between the closed-loop sys-
tem performance in each case. Would the results be preserved if the parameters
a3, a4, a6 are perturbed by 100%?
Problem I.8: A typical four-stage mixer-settler model [2] can be cast into the
type (3.148) with j = 1, 2 and having the following values:
A1
=
 −0.5672
0.4699
0.1022
−0.5672

, B1 =
 0.0176
0
0.0039
0.1003

,
A2
=
 −0.5672
0
0
−0.5672

, B2 =
 −0.1108
0
−0.1607
0.1022

,
C1
=
 0.0230
0
0.0130
0

, C2 =
 0
0.0130
0
0.0230

,
g1
=

0
0.1022
0.4649
0

x2, g2 =

0
0.1022
0.4649
0

x1

3.13. Notes and References
129
Using unity weighting factors, it is desired to derive a decentralized controller
u(t) = −
 −G1x1
0
0
−G2x2

to achieve exponential decay of α ≥0.4. To cope with a constant disturbance
d applied to both subsystems, extend the developed controller to the form
u(t) = −
)
−G1x1 −
 t
0 L1x1dt
0
0
−G2x2 −
 t
0 L2x2dt
*
and compute the integral gains L1 and L2.
3.13
Notes and References
This section provided an overview to some of the fundamental approaches to
large-scale systems using multilevel optimization (coordinated control) and de-
centralized control. The material covered on multilevel optimization offers ad-
vantages in the following situations:
1. When a large-scale system is subject to structural perturbations [303,
304, 306, 321, 323], whereby subsystems are disconnected and again
connected in various ways during operation, a trade-off between relia-
bility and optimality can be established. A certain level of suboptimality
and exponential stability is assured under arbitrary structural perturba-
tions.
2. In cases when the individual subsystems have no information about the
actual shape of interactions save that they are bounded, suboptimality
and stability of the overall system can be accomplished using local con-
trollers only.
3. When a system is so large that a straightforward optimization is either
uneconomical because of an excessive computer time required, or im-
possible due to excessive computer storage needed to complete the opti-
mization.
4. If the state of the overall system is not accessible for direct measure-
ment, and a single observer is not feasible. The proposed multilevel op-
timization scheme can easily accommodate the use of observers on the
subsystem level.

130
Chapter 3. Historical Perspective and Scope
5. The above situations can be resolved successfully by the proposed mul-
tilevel optimization method at some cost involving the system perfor-
mance.
Therefore, the method should be judged satisfactory to the extent that the bene-
ﬁts of the advantages outlined above outweigh the sacriﬁce in the suboptimality
of the system. Some relevant practical applications of hierarchical control can
be found in [241] for stream water quality, in [218] for synchronous machine
connected to an inﬁnite bus, in [216] for an industrial fermentation process, and
in [239] for freeway trafﬁc control problems.
Decentralized control has long been used in the control of power systems
and spacecraft since the problem may often be viewed as a number of intercon-
nected systems. See [273] for general stability theory related to decentralized
systems. An early form of diagonal dominance led to the concept of an M-
matrix [132, 152, 386]. We have focused on dealing with linear subsystems
with known or uncertain parameters. This has shown to facilitate the design
task. In this chapter, we have allowed interconnections to be linear or bounded.
In some sections, we focused on nonlinear subsystems to identify some struc-
tural features. A distinct feature of this chapter is the presentation of large-
scale discrete-time systems with either bounded interconnections or operating
on time-scale separation.

Chapter 4
Decentralized Servomechanism
System
We initiate our guided tour through the development of control problems of
large-scale systems, where we focus in Chapter 4 on conditions and algorithms
for obtaining the dynamic controllers to solve the decentralized stabilization
and the robust decentralized servomechanism problems (DSMP). The associ-
ated attributes including decentralized ﬁxed modes of interconnected dynami-
cal systems are carefully examined. We recall that in Chapter 3, the fundamen-
tal notion of decentralized control and its associated structures was brieﬂy ad-
dressed. As it was introduced there and will be emphasized again here, the main
motivation behind decentralized control is the limitations and/or failure of con-
ventional methods of centralized control theory. Some basic techniques such
as eigenvalue assignment, state feedback, optimal control, state estimation, and
that similar to the latter (centralized control) theory demand complete informa-
tion ﬂow from all system sensors for the sake of feedback control. Clearly, these
schemes are totally inadequate for feedback control of large-scale systems. Due
to the physical conﬁguration, high dimensionality, and/or interconnection pat-
terns of such systems, a centralized control would be truly complex, which is
neither economically feasible nor even necessary. Therefore, in many applica-
tions of feedback control theory to linear large-scale systems some degree of
restriction is assumed to prevail on the information processing. In some cases
a total decentralization is assumed; that is, every local control uj is obtained
from the local output yj and possible external input wi [307, 337]. In others, an
intermediate restriction on the information is possible. Some related issues and
discussions were reported in [5, 43, 45, 106, 303, 335].
131

132
Chapter 4. Decentralized Servomechanism System
4.1
Introduction
When control theory is applied to solve problems associated with large-scale
systems (LSS), an important feature called decentralization often arises. In this
chapter, three major problems related to decentralized structure of large-scale
systems are addressed. The ﬁrst problem is decentralized stabilization. In cen-
tralized systems, the problem of ﬁnding a state or an output feedback gain
whereby the closed-loop system has all its poles on the left half-plane is com-
monly known as feedback “stabilization.” Alternatively, the closed-loop poles
of a controllable system may be preassigned through the state or output feed-
back. Clearly, the applications of these concepts in a decentralized fashion re-
quire certain extensions which will be discussed in Section 4.3.
The second problem addressed in this chapter is the decentralized “robust”
control of large-scale linear systems with or without a known plant. This prob-
lem, ﬁrst introduced by [45]-[52] and known as “general servomechanism,”
takes advantage of the tuning regulators and dynamic compensators to design a
feedback that both stabilizes and regulates the system in a decentralized mode.
The notion of “robust” feedback control will be deﬁned and discussed in detail
later; however, for the time being a control is said to be robust if it contin-
ues to provide asymptotic stability and regulation under perturbation of plant
parameters and matrices.
The third problem is stochastic decentralized control of continuous and
discrete-time systems. The scheme discussed here is based on the assumption
of one sensor for each controller (channel or node) whose information, pro-
cessed with a local Kalman estimator, is shared with all other controllers.
In Section 4.2, the problem of decentralized stabilization is mathematically
formulated. The section reviews some of the appropriate schemes for decen-
tralized feedback stabilization, including the notions of “ﬁxed modes,” “ﬁxed
polynomials” [45], and their role in dynamic compensation. Also discussed are
the dynamic stabilization of large-scale systems and the notion of “exponential
stability” applied to decentralized systems. The stabilization of linear time-
varying systems [125, 126, 127] and the special case of time-invariant system
stabilization will follow.
4.2
A Class of Large-Scale Systems
In this section we look at a basic mathematical model of large-scale linear
time-invariant (LTI) time-varying systems using multicontroller structure. Then
we move to study the problem of stabilizing this class of systems and present

4.2. A Class of Large-Scale Systems
133
Figure 4.1: Large-scale system with multicontroller structure
conditions under which the overall system with decentralized control can be
stabilized.
A class of large-scale LTI systems with ns local control stations (channels)
can be represented by:
˙x(t)
=
Ax(t) +
ns

j=1
Bjuj(t)
yj(t)
=
Cjx(t),
j = 1, 2, ...., ns
(4.1)
where x ∈ℜn is the state, uj ∈ℜmj are the local control inputs, and yj ∈ℜrj
are the local measurable outputs associated with control channel j. The overall
system control and output orders m and r are given by
m =
ns

j=1
mj,
r =
ns

j=1
rj
(4.2)
This system is depicted in Figure 4.1. Consider now a pj-th order decentralized
dynamic controller of the form
˙ξj(t)
=
Λjξj(t) + Φjyj(t) + Γjωj(t)
uj(t)
=
Kcjξj(t) + Kojyj(t) + Ψjωj(t),
j = 1, 2, ...., ns
(4.3)

134
Chapter 4. Decentralized Servomechanism System
where ξ ∈ℜpj is the controller state vector and ω ∈ℜqj is an external input
vector. In the sequel, system (4.1) is termed decentralized ν control-channel
system. In (4.1) and (4.3), the system matrices are
A ∈ℜn×n, Bj ∈ℜn×mj, Cj ∈ℜrj×n, j = 1, 2, ...., ns
and the controller matrices
Λj ∈ℜpj×pj, Φj ∈ℜpj×rj, Kcj ∈ℜmj×rj, Kcj ∈ℜmj×pj, j = 1, 2, ...., ns
Γj ∈ℜpj×qj, Ψj ∈ℜmj×qj, j = 1, 2, ...., ns
The decentralized stabilization problem of interest is deﬁned as follows: Obtain
ns local output control laws of the type (4.3) so that the resulting closed-loop
system described by (4.1)-(4.3) has its eigenvalues in a set ℵ, where ℵis a
nonempty symmetric open subset of complex s-plane [48]. It is quite evident
that the membership of a closed-loop system eigenvalue λ ∈ℵimplies its
complex conjugate λ∗∈ℵin a prescribed manner.
4.3
Decentralized Stabilization
In this section the problem of stabilizing large-scale LTI and time-varying sys-
tems is presented. Conditions under which the overall system with decentral-
ized control can be stabilized will be given. Decentralized stabilization has
been an active ﬁeld of research for large-scale systems. The discussions on this
topic are restricted to LTI systems for the most part and are based on the works
of [45]-[52], [5, 43, 115, 304], and [323, 324]. Additional works on such sub-
jects as large-scale linear systems with nonlinear interconnections [353] and
the results of [125, 126, 127] for the time-varying systems and the case of
time-invariant systems [4] will also be considered.
4.3.1
Fixed modes
The notions of ﬁxed modes and the associated ﬁxed polynomials are gener-
alizations of the “centralized” systems pole placement problem, in which any
uncontrollable and unobservable mode of the system must be stable [30], to
the decentralized case. The idea of ﬁxed modes for decentralized control was
introduced by [45] which leads to necessary and sufﬁcient conditions for stabi-
lizability of decentralized systems (4.1)-(4.3). A more reﬁned characterization
of ﬁxed modes and the associated decentralized control was presented later on
by [5, 6, 43, 55, 359, 368]. Some of these approaches have led to conditions
which involve difﬁcult rank and eigenvalue computations [324].

4.3. Decentralized Stabilization
135
At this point, the aggregate dynamic controllers can be written as
˙ξ(t)
=
Λξ(t) + Φy(t) + Γω(t)
u(t)
=
Kcξ(t) + Koy(t) + Ψω(t)
(4.4)
where
Λ
=
Block −diag{Λ1, Λ2, ..., Λns},
Φ
=
Block −diag{Φ1, Φ2, ..., Φns}
Γ
=
Block −diag{Γ1, Γ2, ..., Γns},
Ψ
=
Block −diag{Ψ1, Ψ2, ..., Ψns},
Kc
=
Block −diag{Kc1, Kc2, ..., Kcns},
Ko
=
Block −diag{Ko1, Ko2, ..., Kons}
(4.5)
and
u(t)
=
col[u1(t), ..., uns(t)], ξ(t) = col[ξ1(t), ..., ξns(t)],
y(t)
=
col[y1(t), ..., yns(t)], ω(t) = col[ω1(t), ..., ωns(t)] (4.6)
By applying the aggregate controller (4.4) to system (4.1), we obtain the ag-
gregate closed-loop system
˙ζ(t)
=
Πζ(t) + Ωω(t), ζ(t) = col[x(t)
ξ(t)]
Π
=
 A + BKoC
BKc
ΦC
Λ

, Ω =
 BΓ
Ψ

(4.7)
and
B := [B1, B2, ..., Bns], C := col

C1
C2
· · ·
Cns

(4.8)
As mentioned earlier, the decentralized stabilization problem is to ﬁnd the con-
trol laws (4.4) so that the aggregate closed-loop system (4.7) is asymptotically
stable. Equivalently stated, by means of local output feedback, the closed-loop
eigenvalues of the large-scale system are required to lie on the left half of the
complex s-plane C.
An important structural property of the decentralized control system (4.1)-
(4.3) using static output-feedback is disclosed by the following deﬁnition.
Deﬁnition 4.3.1 Given system (4.1), we let
K
=
{K| K = block diag[K1, K2, ..., Ks];
Kjℜmj×rj, j = 1, 2, ...., ns}
(4.9)

136
Chapter 4. Decentralized Servomechanism System
then the decentralized ﬁxed modes of system (4.1) with respect K are given
by
λ(C, A, B, K) =
+
K∈K
spec(A + BKC)
(4.10)
where spec(.) denotes the set of eigenvalues of (.).
Note that the associated “ﬁxed polynomial” of (C, A, B) with respect K is the
greatest common divisor (gcd) of the set of polynomials |λI −A −BKC| for
all K ∈K and is denoted by
φ(λ, C, A, B, K) = gcd{|λI −A −BKC|}
(4.11)
Since K can take on the null matrix, therefore the set of “ﬁxed modes” is con-
tained in spec(A). In view of Deﬁnition 4.3.1, the ﬁxed modes are the roots
of the ﬁxed polynomials in (4.11), that is,
spec(A, B, K, C) = {λ|λ ∈C ⊂C and φ(λ, C, A, B, K) = 0}
where C represents a set of values on the entire complex s-plane C.
The following algorithm reported in [49] shows, in a simple way, how to
calculate the decentralized ﬁxed modes:
1. Compute all the eigenvalues of matrix A, that is, spec(A).
2. Select “arbitrary matrices” Kj, j = 1, 2, ...., ns
3. Compute the eigenvalues of A + ns
j=1 BjKjCj
Then the decentralized ﬁxed modes are contained in those eigenvalues of
A + s
j=1 BjKjCj which are common with the eigenvalues of A.
Simply stated, the decentralized ﬁxed modes are the eigenvalues of A that
cannot be moved, relocated, or assigned to other places, by decentralized con-
trol actions. There have have been numerous efforts to compute the decentral-
ized feedback gains; the reader is referred to [136]. It has been reported in [45]
that the ﬁxed modes of a centralized system (A, B, K, C), K ∈ℜm×r even-
tually correspond to the uncontrollable and unobservable modes of the system.
For the case of decentralized closed-loop system, the following theorem estab-
lishes the necessary and sufﬁcient conditions for stabilizability.
Theorem 4.3.2 Consider system (4.1) and the class of block-diagonal gain
matrices in (4.9). Then the local feedback controllers () would asymptotically
stabilize the system if and only if the set of ﬁxed modes of (A, B, K, C) is
contained in the open left-half s-plane, that is, spec(A, B, K, C) ∈C−.

4.3. Decentralized Stabilization
137
Proof: The details can be found in [45] which is based on Kalman’s canonical
structure [147].
An alternative algebraic characterization of the decentralized ﬁxed modes
is summarized by the following theorem.
Theorem 4.3.3 Consider system (4.1). Then necessary and sufﬁcient condi-
tion for λ ∈spec(A) to be a decentralized ﬁxed mode of (4.1) is that for
some partition of the set {1, 2, ..., s} into disjoint sets {j1, j2, ..., jk} and
{jk+1, jk+2, ..., js} there exists
rank
⎡
⎢⎢⎢⎢⎢⎣
A −λI
Bj1
Bj2
· · ·
Bj2k
Cjk+1
0
0
· · ·
0
Cjk+2
0
0
· · ·
0
...
...
...
...
Cjs
0
0
· · ·
0
⎤
⎥⎥⎥⎥⎥⎦
< 0
(4.12)
Proof: The details can be found in [5].
More work has shown that the existence of decentralized ﬁxed modes in a s
control channel system always reduces to the existence of ﬁxed modes in an s−
1 control channel system. Effectively then, when studying the characterization
of decentralized ﬁxed modes in a s control channel system, it is only necessary
to eventually examine the case of a two-channel system. The following theorem
summarizes a pertinent result.
Theorem 4.3.4 Consider system (4.1) with s ≥3. Then λ ∈spec(A) is not
a decentralized ﬁxed mode of (4.1) and only if λ is not a decentralized ﬁxed
mode of (4.1) of any of the following s −1 control channel systems for (4.1):
1)
⎧
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎩
⎡
⎢⎢⎢⎢⎢⎣
 C1
C2

C3
...
Cs
⎤
⎥⎥⎥⎥⎥⎦
A

(B1, B2)
B3
· · ·
Bs

⎫
⎪
⎪
⎪
⎪
⎪
⎬
⎪
⎪
⎪
⎪
⎪
⎭
< 0 (4.13)
2)
⎧
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎩
⎡
⎢⎢⎢⎢⎢⎣
C1
 C2
C3

...
Cs
⎤
⎥⎥⎥⎥⎥⎦
A

B1
(B2, B3)
· · ·
Bs

⎫
⎪
⎪
⎪
⎪
⎪
⎬
⎪
⎪
⎪
⎪
⎪
⎭
< 0 (4.14)

138
Chapter 4. Decentralized Servomechanism System
...
3)
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎩
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
C1
...
Cs−2
 Cs−1
C2

C3
...
Cs
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
A

B1
· · ·
Bs−2
(Bs−1, Bs)

⎫
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎬
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎭
< 0
(4.15)
4)
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎩
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
C1
...
Cs−3
 Cs−2
Cs

Cs−1
...
Cs
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
A

B1
· · ·
Bs−3
(Bs−2, Bs)
Bs−1

⎫
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎬
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎭
< 0
(4.16)
Proof: The details can be found in [55].
Let us shed some light on the foregoing result. From the conventional the-
ory of centralized systems [147], it is well known that when the system matrix
A is diagonal with distinct eigenvalues then system (4.1) is controllable and
observable if and only if no row of B and no column of C are identically equal
to zero. We can generalize this result to the case of decentralized systems for
the type of (4.1) when ns = 2. Thus, we let
˙x
=
⎡
⎢⎢⎢⎢⎢⎢⎢⎣
λ1
...
· · ·
· · ·
· · ·
· · ·
· · ·
...
λ2
...
...
...
λn
⎤
⎥⎥⎥⎥⎥⎥⎥⎦
x +
⎡
⎣
bt
1
· · ·
B1
⎤
⎦u1 +
⎡
⎣
bt
2
· · ·
B2
⎤
⎦u2(4.17)
y1
=
(c1
C1)x,
y2 = (c2
C2)x
(4.18)
where b1 ∈ℜm1, b2 ∈ℜm2, c1 ∈ℜr1, c2 ∈ℜr2 are prescribed vectors, re-
spectively. We assume that λ1, λ2, ..., λn are all distinct and occur in complex

4.3. Decentralized Stabilization
139
conjugate pairs. For simplicity in exposition, we deﬁne
B1
:=

b11
b12
· · ·
b1m1

,
B2
:=

b21
b22
· · ·
b2m

C1
:=
col

c11
c12
· · ·
c1r1

,
C2
:=
col

c21
c22
· · ·
c2r2

(4.19)
The following result is established.
Theorem 4.3.5 Consider the two-channel decentralized system (4.17)-(4.19).
Then λ1 is not a decentralized ﬁxed mode if and only if the following conditions
hold:
1)

B1
B2

̸= 0 and

Ct
1
Ct
2

̸= 0
(4.20)
2)
The condition:
B1 = 0, and C2 = 0, and λ1 is a transmission zero [47] of
/
c2j
diag

λ1
· · ·
λs

b1k
0
∀j ∈[1, 2, ..., r2], ∀k ∈[1, 2, ..., m1] does not hold
(4.21)
3)
The condition:
B2 = 0, and C1 = 0, and λ1 is a transmission zero of
/
c1j
diag

λ1
· · ·
λs

b2k
0
∀j ∈[1, 2, ..., r1], ∀k ∈[1, 2, ..., m2] does not hold
(4.22)
Proof: The details can be found in [55].
Remark 4.3.6 It is signiﬁcant to note that in centralized systems [147], the
controllability-observability of mode λ1 depends only on b1, b2, c1, c2 as
given by condition 1) and is independent of the values of B1, B2, C1, C2,
λ1, ..., λs. Note that this is no longer the case with decentralized systems.
We are now in a position to extend on the foregoing results and provide condi-
tions for an interconnected system to have no decentralized ﬁxed modes.

140
Chapter 4. Decentralized Servomechanism System
4.3.2
Decentralized ﬁxed modes
In this section, we examine the existence of ﬁxed modes in interconnected sys-
tems described by
˙x(t)
=
⎡
⎢⎢⎢⎣
A11
A12
· · ·
A1ns
A21
A22
· · ·
A2ns
...
...
...
Ans1
Ans2
· · ·
Ansns
⎤
⎥⎥⎥⎦x(t) +
⎡
⎢⎢⎢⎣
B1
0
...
0
⎤
⎥⎥⎥⎦u1(t)
+
⎡
⎢⎢⎢⎣
0
B2
...
0
⎤
⎥⎥⎥⎦u2(t) + .... +
⎡
⎢⎢⎢⎣
0
0
...
Bns
⎤
⎥⎥⎥⎦uns(t)
y1(t)
=

C1
0
· · ·
0

x(t) +

0
C2
· · ·
0

x(t)
+
· · · · · ·

0
0
· · ·
Cns

x(t)
(4.23)
where
Ajk = TjkKjkRjk, j = 1, 2, ..., ns, k = 1, 2, ..., ns, j ̸= k
and Kjk is the interconnection gain matrix and Tjk, Rjk are arbitrary matrices.
The following theorem furnishes the desired results, the proof of which follows
from [48, 52, 304]:
Theorem 4.3.7 Consider the decentralized system (4.23) and assume that the
triplets (Cj, Ajj, Bj), j = 1, 2, ..., ns are all controllable and observable.
Then this implies that system (4.23) has no decentralized ﬁxed modes for almost
all interconnection gains
Kjk, j = 1, 2, ..., ns, k = 1, 2, ..., ns, j ̸= k
Remark 4.3.8 Consider the decentralized system (4.23) with interconnection
structure
Ajk = BjKjkCk, j = 1, 2, ..., ns, k = 1, 2, ..., ns, j ̸= k
Then necessary and sufﬁcient conditions for system (4.23) to have no decen-
tralized ﬁxed modes are that the triplets (Cj, Ajj, Bj), j = 1, 2, ..., ns are
all controllable and observable.
Some pertinent remarks stand out:

4.4. Illustrative Examples
141
Remark 4.3.9 The approach that led to the establishment of Theorems 4.3.2-
4.3.5 can be labeled, from a system theoretic standpoint, as macroscopic view
as they treat the large-scale system as one black box without emphasis on the
internal coupling pattern. Alternatively, the approach that led to the establish-
ment of Theorem 4.3.7 can be labeled as microscopic view as they treat the
large-scale system as interconnections of subsystems in black box without em-
phasis on the internal coupling pattern. This is crucial to understand since
wider applicability and greater beneﬁts could be gained from the implementa-
tion of the latter approach. We will follow such a trend throughout the book.
Remark 4.3.10 It is worth noting extensions of the deﬁnition decentralized
ﬁxed modes to other information structure constraints can be readily made by
modifying the set of controllers (4.9); the reader is referred to [43, 45] for
further accounts.
4.4
Illustrative Examples
Some examples are presented to illustrate the foregoing results.
4.4.1
Illustrative example 4.1
Consider the following large-scale system of the type (4.1) with
A
=
⎡
⎣
A1
A2
0
A3
A4
A5
A6
A7
A8
⎤
⎦, A1 =
⎡
⎣
−3.9
−0.3
0
0.06
−3
3
27
0.8
−0.9
⎤
⎦,
A2
=
⎡
⎣
0
0
4
0
0
−0.3
0
0
−0.8
⎤
⎦, A3 =
⎡
⎣
−0.4
−5.2
0
−38
17
−12
22
18
0
⎤
⎦
A4
=
⎡
⎣
−0.25
−3.35
3.6
−12
−2.9
−0.1
−35
−0.4
−0.4
⎤
⎦, A5 =
⎡
⎣
6.3
0.1
0
12
43
0
90
56
0
⎤
⎦,
A6
=
⎡
⎣
0
0
0.4
0
0
0
−2.2
−0.7
0
⎤
⎦, A7 =
⎡
⎣
0
0
10
−1.2
0
7
−8
0
1.3
⎤
⎦,
A8
=
⎡
⎣
−20
0
0
0
−7
0
0.1
6
−1
⎤
⎦

142
Chapter 4. Decentralized Servomechanism System
B
=
⎡
⎣
B1
B2
B3
B4
B5
B6
B7
B8
B9
⎤
⎦, B1 =
⎡
⎣
−0.1
0
0
0
1
0
0
15.6
0
⎤
⎦,
B2
=
⎡
⎣
0
0
4
0
0
0
0
0
0
⎤
⎦, B3 =
⎡
⎣
0
0
0
1
0
0
0
0
1
⎤
⎦,
B4
=
⎡
⎣
0
0
−5.6
52
8.2
−1.5
0
0
1.7
⎤
⎦, B5 =
⎡
⎣
0
0
0
−0.4
0.9
0
0
0
0
⎤
⎦,
B6
=
⎡
⎣
0
0
1
0
1
0
0
0
0
⎤
⎦, B7 =
⎡
⎣
0
2.9
0
0
0
−0.4
0
0
2.9
⎤
⎦,
B8
=
⎡
⎣
0
0
0
0
0
0
0
0
3
⎤
⎦, B9 =
⎡
⎣
0
0
10
−1.2
0
7
−8
0
1.3
⎤
⎦
C
=
⎡
⎣
I3
0
C1
C2
C3
C4
0
C5
C6
⎤
⎦, C1 =
⎡
⎣
0
1
0
1
0
0
0
0
1
⎤
⎦,
AC2
=
⎡
⎣
0
0
0
0
1
0
0
0
0
⎤
⎦, C3 =
⎡
⎣
1
0
0
0
1
0
0
1
0
⎤
⎦,
C4
=
⎡
⎣
1
0
0
0
0
0
0
0
0
⎤
⎦, C5 =
⎡
⎣
0
0
0
0
0
1
0
0
⎤
⎦,
C6
=
⎡
⎣
0
1
0
0
0
0
0
1
⎤
⎦
Using MATLAB R⃝to perform simulation, it is found that the open-loop eigen-
values are given by
λ(A)
=
{−1.0, −46.37, 26.96, 6.77, −11.55, 0.11,
−3.92 ± 5.64j, −6.54}
By repeating generating a gain matrix K ∈ℜ7×7 of arbitrary form like K =
diag[K1, ..., K7] and evaluating the eigenvalues of A + BKC,
it turns out
that all the open-loop eigenvalues can be relocated. Hence, there are no ﬁxed

4.4. Illustrative Examples
143
modes and, therefore, it is concluded that the system under consideration can
be stabilized by a decentralized control with dynamic compensator.
4.4.2
Illustrative example 4.2
Consider the following large-scale system of the type (4.1) with
Ao
=
⎡
⎢⎢⎢⎢⎢⎢⎣
0
1
0
0
0
0
0
0
0
1
0
0
0
0
−1
−2
−3
1
0
0
0
1
0
0
−1
−1
0
0
0
0
0
0
0
1
0
0
0
0
0
0
0
1
⎤
⎥⎥⎥⎥⎥⎥⎦
Bo
=
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
0
0
0
0
0
0
1
0
0
0
0
0
0
1
0
0
0
0
0
0
1
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
, Co =
⎡
⎢⎢⎢⎢⎣
1
0
0
0
0
0
0
0
1
0
0
0
0
0
0
0
1
0
0
0
0
0
0
0
1
0
0
0
0
0
0
0
1
0
0
⎤
⎥⎥⎥⎥⎦
The open-loop eigenvalues are given by
{−2.472, −0.322 ± 1.43j, −1.0, 0.24, −0.562 ± 0.68j}
Consider two cases of the gain matrices
Kd
=
⎡
⎣
Kd1
0
0
0
0
0
Kd2
0
0
0
0
0
Kd3
Kd4
Kd5
⎤
⎦, Kf =
⎡
⎣
Kf1
Kf2
Kf3
Kf4
Kf5
Kf6
Kf7
Kf8
Kf9
⎤
⎦
By randomly selecting several entries, it is found [136] that a ﬁxed mode λ =
1.0 took place. On attempting other structures of Kd, it is found that a similar
conclusion is reached.

144
Chapter 4. Decentralized Servomechanism System
On the other hand, consider a similar system with
Ac
=
⎡
⎢⎢⎢⎢⎢⎢⎣
0
1
0
0
0
0
0
0
0
1
0
0
0
0
−1
−2
−3
1
0
0
0
1
0
0
−1
−1
0
0
0
0
0
0
0
1
0
0
0
0
0
0
0
1
⎤
⎥⎥⎥⎥⎥⎥⎦
,
Bc
=
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
0
0
0
0
0
0
0
0
0
0
0
0
0
0
1
0
0
1
0
0
1
0
0
0
0
0
0
0
0
1
0
0
1
0
0
0
0
0
0
0
0
0
0
0
1
0
0
1
0
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
,
Cc
=
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
1
0
0
0
0
0
0
0
1
0
0
0
0
0
0
0
1
0
0
0
0
0
0
0
1
0
0
0
0
0
0
0
1
0
0
0
0
0
0
0
1
0
0
0
0
0
0
0
1
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
It is desired of ﬁnd the ﬁxed modes, if any, of this model having open-loop
eigenvalues
λ(A) = {−3.71, −2.45, 0.11, −0.76 + −0.90i, −0.21 + −0.83i}
The result of simulation is that there is no eigenvalue that can be a ﬁxed mode
even though different controller structures are used.
4.4.3
Illustrative example 4.3
Consider a fourth-order, three-input and four-output system described by
Ao =
⎡
⎢⎢⎣
7
0
0
1
3
6
0
3
0
4
2
0
0
0
1
1
⎤
⎥⎥⎦, Bo =
⎡
⎢⎢⎣
1
0
0
0
1
0
0
0
0
0
0
1
⎤
⎥⎥⎦, Co =
⎡
⎢⎢⎣
0
0
0
0
1
0
0
1
0
1
1
0
0
0
0
1
⎤
⎥⎥⎦
The design objective is to investigate the existence of ﬁxed modes and struc-
turally ﬁxed modes. First, we note that the open-loop eigenvalues are
λ(A) = {7.35, 6.0, 1.32 + −1.34j}

4.5. Decentralized Regulators
145
Now, let the controller structure be
K
=
⎡
⎣
K1
0
0
0
0
K2
0
0
0
0
Kd3
Kd4
⎤
⎦
As a result of extensive MATLAB simulations, it is found that λ = 6 is inde-
pendent of the different of the controller. Therefore it represents a ﬁxed mode
and the system cannot be stabilized using decentralized feedback gain. It is im-
portant to note that on changing the element a22 by a small amount, the new
system will not have a ﬁxed mode with respect to decentralized feedback gain.
Next, to ﬁnd the difference between the ﬁxed mode and structurally ﬁxed
mode of the system, we set a11 ≡0, a22 ≡= 0. In this new system, a ﬁxed
mode λ = 0 will remain regardless of the values of all nonzero elements of the
new system. Thus we conclude that λ = 0 is a structurally ﬁxed mode.
4.5
Decentralized Regulators
Thus far, we were concerned with the existence of ﬁxed modes and decen-
tralized ﬁxed modes. In the control literature, an interconnected system is often
referred to as a system with a set of interacting subsystems [342]. Systems with
different types of interaction topologies have been investigated in the literature,
among which the class of hierarchical interconnected systems has drawn spe-
cial attention in recent publications due to its broad applications, that is, in
formation ﬂying, underwater vehicles, automated highway, robotics, satellite
constellation, etc., which have leader-follower structures or structures with vir-
tual leaders [170, 350]. To stabilize such a large-scale system with hierarchical
fashion, one can design a set of stabilizing local controllers for the individual
subsystems. In some cases, it is permissible that these local controllers partially
exchange information [165, 352]. In general, the need for this type of struc-
turally constrained controller can be originated from some practical limitations
concerning, for instance, the geographical distribution of the subsystems or the
computational complexity associated with the centralized controller design for
large-scale systems [169]. The case when these local controllers operate inde-
pendently, that is, they do not interact with each other, is referred to as decen-
tralized feedback control [56, 170, 324]. Various aspects of the decentralized
control theory have been extensively investigated in the past few decades. In
[56, 89, 165, 166] the decentralized stabilizability of a system is studied by
using the notions of decentralized ﬁxed modes and quotient ﬁxed modes.
To elaborate on the different methods, we start by looking at models that
represent large-scale systems with structural information constraints.

146
Chapter 4. Decentralized Servomechanism System
4.5.1
The robust decentralized servomechanism problem
In the following, we present a mathematical model of a large-scale system
which has ns local control stations, each of which has outputs to be regulated,
and in addition has m local control stations in which there are no outputs to be
regulated but in which there do exist outputs that can be measured and utilized
for control purposes. Such a framework is called the decentralized servomech-
anism problem, in which the m control stations can be used to assist in the
control of the outputs of the ns control stations that are to be regulated.
Thus the plant to be controlled, consisting of ns + m local control stations,
is assumed to be described by the following LTI system:
˙xj(t)
=
Ax(t) +
ns+m

k=1
Bkuk(t) + Γw(t)
yj(t)
=
Cjx(t) + Djuj(t) + Φjw(t), j = 1, 2, ..., ns
zj(t)
=
Gjx(t) + Hjuj(t) + Ψjw(t), j = 1, 2, ..., ns + m
ej(t)
=
yj(t) −yrj(t), j = 1, 2, ..., ns
(4.24)
where for x(t)
∈ℜn is the state vector,
uj(t)
∈ℜmj
is the control
input,
zj(t)
∈ℜrj
is the measurable outputs of the jth control station
(j = 1, 2, ..., ns + m),
w(t)
∈ℜk is a disturbance vector, and ej(t)
∈
ℜrj, j = 1, 2, ..., ns is the output error, with the difference between the output
yj(t) to be regulated and the speciﬁed reference input yrj(t), j = 1, 2, ..., ns.
The following matrix notations are introduced:
B
:=

B1
B2
· · ·
Bns

, C := col

C1
C2
...
Cns
	
Φ
:=
col

Φ1
Φ2
...
Φns
	
, ˆB :=

Bns+1
Bns+2
· · ·
Bns+m

yr
:=
col

yr1
yr2
...
yrns
	
, e := col

e1
e2
· · ·
ens

D
:=
Blockdiag

D1,
D2,
· · · ,
Dns

G
:=
col

G1
G2
...
Gns
	
ˆG
:=
col

Gns+1
Gns+2
...
Gns+m
	
(4.25)
In the sequel, we consider that the disturbance inputs
w(t) arise from the
following class of systems:
˙ζj(t) = S ζ(t), w(t) = Wζ(t), ζ(t) ∈ℜgw
(4.26)

4.5. Decentralized Regulators
147
Additionally, for regulation purposes, we introduce the reference output yrj(t)
which is speciﬁed by the model
˙η(t) = R η(t), ξ(t) = Xη(t), yr = Y ξ, zeta(t) ∈ℜgs
(4.27)
Following [51, 119], it is assumed for nontriviality that the spectrum
spec(S) ⊂C+, spec(R) ⊂C+ where C+ denotes the closed right-half com-
plex plane. Without loss of generality, it is also assumed that the pairs (W, S)
and (X, R) are observable and
rank(Γt Φt)t = rank(W) = dim(w), rank(Y ) = rank(X) = dim(ξ)
The underlying objective for system (4.24)-(4.27) amounts to ﬁnding a decen-
tralized LTI controller so that
1. All the resultant closed-loop subsystems are asymptotically stable.
2. Asymptotic tracking is achieved, that is,
lim
t→∞e(t) = 0, ∀x(0) ∈ℜn, ∀ζ(0) ∈ℜgw, ∀ξ(0) ∈ℜgs
and for all controller initial conditions. This also holds for any arbitrary
perturbations in the plant model.
The above problem is frequently termed the robust decentralized servomecha-
nism problem.
The following theorem establishes conditions for the existence of solution
to the robust decentralized servomechanism problem.
Theorem 4.5.1 There exists a solution to the robust decentralized servomech-
anism problem (4.23) if and only if all of the following conditions hold:
1)
  G
ˆG

,
A,

B
ˆB
 
has no unstable decentralized
fixed modes
2)
The decentralized fixed modes of the q systems
  G∗
ˆG∗

,
 A
0
C
λjI

,

B
ˆB
H
0
 
j = 1, 2, ..., q
do not contain λj j = 1, 2, ..., q, respectively.
3)
The outputs yj(t), j = 1, 2, ..., ns are physically measurable, that is,
yj(t) ⊂zj(t), j = 1, 2, ..., ns

148
Chapter 4. Decentralized Servomechanism System
where
G∗
:=
col

G∗
1
G∗
2
...
G∗
ns
	
,
ˆG∗
:=
col

G∗
ns+1
G∗
ns+2
...
G∗
ns+m
	
(4.28)
G∗
1
:=
 G1
0
0
· · ·
0
0
Irj
0
· · ·
0

,
G∗
ns+1
:=
col

Gns+1
0
0
· · ·
0

G∗
2
:=
 G1
0
0
· · ·
0
0
0
Irj
· · ·
0

,
G∗
ns+2
:=
col

Gns+1
0
0
· · ·
0

...
:=
...
G∗
ns
:=
 Gns
0
0
· · ·
0
0
0
0
· · ·
Irj

,
G∗
ns+1
:=
col

Gns+m
0
0
· · ·
0

(4.29)
Proof: The details can be found in [48, 50].
4.5.2
The robust decentralized controller
It is natural now to seek a design procedure for system (4.24). To facili-
tate such a procedure, we introduce the following notations. Let the mini-
mal polynomial of matrices S and R be denoted by min −poly(S)(s) and
min −poly(R)(s), respectively, and we let the zeros of the least common
multiple of min −poly(S)(s) and min −poly(R)(s) including multiplici-
ties be given by
λ1, λ2, ..., λq
(4.30)
Let the coefﬁcients σj, j = 1, 2, ..., q correspond to the coefﬁcients of the
polynomial 1q
k=1(λ −λk) where λk are given by (4.30), that is,
λq + σq λq−1 + σq−1 λq−2 + · · · + σ2 λ + σ1 =
q2
k=1
(λ −λk)
(4.31)

4.5. Decentralized Regulators
149
Finally, let
Υ
:=
⎡
⎢⎢⎢⎣
0
1
0
· · ·
0
0
0
1
· · ·
0
...
...
...
...
−σ1
−σ2
−σ3
· · ·
σq
⎤
⎥⎥⎥⎦, ∈ℜq×q, δ :=
⎡
⎢⎢⎢⎢⎢⎣
0
0
...
0
1
⎤
⎥⎥⎥⎥⎥⎦
(4.32)
Now consider the large-scale system (4.24) with (4.26) and (4.27) and intro-
duce the decentralized compensator with input ej(t) ∈ℜrj, j = 1, 2, ..., ns
and output fj(t) ∈ℜrjq, j = 1, 2, ..., ns:
˙fj(t)
=
Υ∗
j fj(t) + Δ∗
j ej(t), j = 1, 2, ..., ns
(4.33)
Υ∗
j
:=
Blockdiag

Υ,
Υ,
· · · ,
Υ

,
Δ∗
j
:=
Blockdiag

δ,
δ,
· · · ,
δ

(4.34)
From the linear system theory [147] it follows that the decentralized compen-
sator (4.33) is unique within the class of coordinate transformations and non-
singular input transformations. Next, when Theorem 4.5.1 holds, the decen-
tralized controller consists of the following structure [48, 50]:
uj(t)
=
Kj fj(t) + ˆxj(t), j = 1, 2, ..., ns
uj(t)
=
ˆxj(t), j = ns + 1, ns + 2, ..., ns + m
(4.35)
where fj(t)
∈ℜrjq is the output of the decentralized compensator (4.33)
and ˆxj(t),
j = 1, 2, ..., ns + m is the output of a decentralized stabilizing
compensator ℑ∗
j (with inputs yrj, zj, fj, uj, j = 1, 2, ..., ns) and ℑ∗
j (with
inputs zj, uj, j = n + s + 1, ns + 2, ..., ns + m). In addition, ℑ∗
j, j =
1, 2, ..., ns + m and the gain matrices Kj, j = 1, 2, ..., ns are designed to

150
Chapter 4. Decentralized Servomechanism System
guarantee that the following augmented system

˙x(t)
˙f1(t)
· · ·
˙fns(t)

:=
⎡
⎢⎢⎢⎣
A
0
· · ·
0
Δ∗
1C1
Υ∗
1
· · ·
0
...
...
...
Δ∗
nsCns
0
· · ·
Υ∗
ns
⎤
⎥⎥⎥⎦

x(t)
f1(t)
...
fns(t)
	
+

B
ˆB
Blockdiag

Δ∗
1D1,
· · · ,
Δ∗
nsDns

0

⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
u1
...
uns
uns+1
...
uns+m
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
 Gjx(t)
fj(t)

:=
 ˆzj(t)
fj(t)

, j = 1, 2, ..., ns
ˆzj(t) := Gjx(t), j = ns + 1, ns + 2, ..., ns + m
(4.36)
is stabilizable with desired transient behavior, where ˆzj(t)
:=
zj(t) −
Hjuj(t), j = 1, 2, ..., ns +m and system (4.36) has decentralized ﬁxed modes
corresponding to the decentralized ﬁxed modes (if any) of
  G
ˆG

,
A,

B
ˆB
 
4.5.3
Decentralized controller for interconnected systems
We proceed further and extend the results of the decentralized servomechanism
results to the class of interconnected systems
˙xj(t)
=
Ajxj(t) + Bjuj(t) + Γjw(t) +
ns

k=1,k̸=j
Ajkxk(t)
yj(t)
=
Cjxj(t) + Djuj(t) + Φjw(t)
zj(t)
=
Gjxj(t) + Hjuj(t) + Ψjw(t)
(4.37)
where for j ∈{1, ..., ns}, xj(t) ∈ℜnj is the state vector, uj(t) ∈ℜmj is
the control input, yj(t) ∈ℜpj is the output to be regulated, zj(t) ∈ℜqj
is the measurable output. The matrices Aj ∈ℜnj×nj, Bj ∈ℜnj×mj, Dj ∈
ℜqj×mj, Adj ∈ℜnj×nj, Φj ∈ℜqj×qj, Ωj ∈ℜnj×qj, Cj ∈ℜpj×nj, Cdj ∈

4.5. Decentralized Regulators
151
ℜpj×nj, Gj ∈ℜqj×nj, Gdj ∈ℜqj×nj, Ajk ∈ℜnj×nk are real and constants.
In the sequel, we consider that the disturbance input wj(t) ∈ℜqj arise from
the following class of systems:
˙ζj(t) = Sj ζj(t), wj(t) = Wjζj(t), ζj(t) ∈ℜgwj
(4.38)
Additionally, for regulation purposes, we introduce the reference output yrj(t)
which is speciﬁed by the model
˙ηj(t) = Rj ηj(t), ξj(t) = Xjηj(t), yrj = Yjξj, zetaj(t) ∈ℜgsj (4.39)
and deﬁne the tracking error
ej(t) = yj(t) −yrj(t)
(4.40)
At this stage, we let the interconnections among subsystems be characterized
by
Ajk = MjkKjkNjk,
j ∈1, ..., ns, k ∈1, ..., ns, j ̸= k
(4.41)
where Kjk denotes the interconnection gain connecting subsystem j and sub-
system k. The following theorem provides results reported in [48, 52] for the
case when subsystem j has Ajk = 0,
j ∈{1, ..., ns, k ∈1, ..., ns, j ̸= k.
Theorem 4.5.2 Consider the collection of subsystems (4.37) with (4.38)-
(4.41), j ∈{1, ..., ns, k ∈1, ..., ns,
j ̸= k, then the following statements
hold:
1. Assume that there exists a solution to the centralized, robust servomech-
anism problem for each subsystem of the type (4.37), then there exists
a solution to the decentralized robust servomechanism problem for the
interconnected system (4.37) provided the norms of the interconnection
gains Kjk are “small enough.”
2. Assume that there exists a solution to the centralized, robust servomech-
anism problem for each subsystem of the type (4.37) and in addition
assume that the triplets Gj, A, Bj, j ∈1, ..., ns are controllable and
observable, then there exists a solution to the decentralized robust ser-
vomechanism problem for the interconnected system (4.37) for almost all
interconnection gains Kjk.
3. Assume that the interconnections among subsystems are characterized
by (4.41) with Mjk = Bj, Njk = Ck and that Dj = 0, j ∈1, ..., ns,

152
Chapter 4. Decentralized Servomechanism System
then there exists a solution to the decentralized robust servomechanism
problem for the interconnected system (4.37) if and only if there exists
a solution to the centralized robust servomechanism problem for each
subsystem of the type (4.37).
Remark 4.5.3 It is signiﬁcant to observe that the salient feature of the works
reported in [45]-[56] is that it parameterizes all the decentralized controllers
which reject the unmeasurable exogenous disturbances with known dynamics.
In this section we observe the disturbance input generated by model (4.38) rep-
resents one possible approach of dealing with unknown input disturbances. In
several portions throughout the book, there is an alternative approach to treat
the disturbance input as a member of the space L2[0, ∞). The difference be-
tween both representations is signiﬁcant and the subsequent impact on control
design and system performance brings about numerous interesting features. We
will put this into further consideration to disclose the merits and demerits.
4.5.4
Illustrative example 4.4
Consider the following large-scale system of the type (4.1) with
Ao
=
⎡
⎣
3
2
1
0
2
1
0
0
1
⎤
⎦,
Bo
=
⎡
⎣
2
0
0
0
3
0
0
0
1
⎤
⎦, Co =
⎡
⎣
1
0
0
0
1
0
0
0
1
⎤
⎦
For this system, we wish to design a decentralized output feedback controller
of the form
˙z(t)
=
Fz(t) + Sy(t)
u(t)
=
Hz(t) + Ky(t)
such that a prescribed set of eigenvalues is achieved.
Simple calculations show that λ(A) = {3, 2, 1} and by attempting several
controller structures, no ﬁxed mode is found. Now, let nc, no be the smallest
integers such that
rank[Bo, AoBo, ..., Anc
o Bo] = n, rank[Ct
o, At
oCt
o, ..., At
o
ncCo] = n,
η = min(nc, no) = 1

4.5. Decentralized Regulators
153
to get
Aη
=
⎡
⎢⎢⎣
3
2
1
0
0
2
1
0
0
0
1
0
0
0
0
0
⎤
⎥⎥⎦,
Bη
=
⎡
⎢⎢⎣
2
0
0
0
0
3
0
0
0
0
1
0
0
0
0
1
⎤
⎥⎥⎦, Cη =
⎡
⎢⎢⎣
1
0
0
0
0
1
0
0
0
0
1
0
0
0
0
1
⎤
⎥⎥⎦
Let
Kη
=
⎡
⎢⎢⎣
k1
0
0
h1
0
k2
0
0
0
0
1k3
0
s1
0
0
f1
⎤
⎥⎥⎦
which yields
Aη + BηKηCη
=
⎡
⎢⎢⎣
2k1 + 3
2
1
2h1
0
3k2 + 2
1
0
0
0
k3 + 1
0
s1
0
0
f1
⎤
⎥⎥⎦
where the unknown scalars k1,
k2,
k3,
s1,
h1,
f1 are to be deter-
mined such that the closed-loop system has the prescribed set of eigenvalues
{−3, −4, −1, −2}. The solution procedure employs the determinant identity
det
⎡
⎣
M1
M2
M3
M4
⎤
⎦det[M1] det[M4 −M3M−1
1 M2]
such that the greatest common divisor of
det[λI −Ao −BoKoCo] = det[λI −Aη −BηKηCη]
The result is given by
k1 = −3, k2 = −2, k3 = −2, s1 = 1, h1 = 1, f1 = −4

154
Chapter 4. Decentralized Servomechanism System
Figure 4.2: Simulink set-up
The foregoing data yield the dynamic compensator
˙z1(t)
=
−4z1(t) + y1(t)
u1(t)
=
z1(t) −3y1(t)
˙z2(t)
=
0
u2(t)
=
−2y2(t)
˙z3(t)
=
0
u3(t)
=
−2y3(t)
A complete Simulink simulation diagram is depicted in Figure 4.2 for generat-
ing the output response as displayed in Figure 4.3.
4.6
Hierarchically Structured Servomechanism
High-performance decentralized control design techniques have been recently
investigated for classes of interconnected systems with hierarchical structures.
Several real-world systems are frequently subject to external disturbances; the
controller for a hierarchical interconnected system is therefore desired to satisfy
the following properties [168, 169, 171, 301]:
1. The disturbances must be rejected in the steady state.
2. A predeﬁned H2 performance index should be minimized to achieve a
fast transient response with a satisfactorily small control energy.

4.6. Hierarchically Structured Servomechanism
155
Figure 4.3: Output trajectories
3. The structure of the controller to be designed should be decentralized.
We have seen in the preceding sections the problem of designing a controller
satisfying the properties (1) and (3) given above, and the controller obtained is
regarded as decentralized servomechanism controller [48, 52, 54]. The design
of a controller that meets the criteria (2) and (3), however, has been studied in
[309, 343]. For structural convenience, the available techniques often seek a
near-optimal solution, rather than a globally optimal one. The main shortcom-
ing of this approach is that the controller obtained may destabilize the system,
as a result of neglecting the system’s interconnection parameters in the design
procedure. An alternative approach for handling the underlying problem is to
consider only static decentralized controllers [267]. This imposes a stringent
constraint on the controller, which can lead to a poor closed-loop performance.
It is to be noted that once a centralized controller is designed to achieve the
properties (1) and (2), its decentralized version does not necessarily maintain
the same properties. A technique yielding H2 near-optimal is developed in
[169] for decentralization of any given centralized controller of desired per-
formance. The only requirement of this technique is that the nominal model of
the system is known by all control agents, that is, every local controller must
have a belief about the model of the entire system.
In this section, we direct attention to the formalism of decentralized ser-
vomechanism problems of interconnected systems with hierarchical structures.
A centralized controller is designed ﬁrst, which should satisfy certain con-
straints [170]. This control design is then formulated in terms of LMI [171].

156
Chapter 4. Decentralized Servomechanism System
The class of interconnected systems with hierarchical structures considered
hereafter can be cast into the following representation of the family of sub-
systems Sj, j ∈{1, ..., ns} where Sj is modeled by:
˙xj(t)
=
ns

k=1
Ajkxk(t) + Bjuj(t) + Γjw(t)
yj(t)
=
Cjxj(t)
(4.42)
where xj(t)
∈ℜnj is the state vector, uj(t)
∈ℜmj
is the control input,
yj(t) ∈ℜpj is the output to be regulated, and w(t) ∈ℜq is the disturbance
input vector. For the time being, we assume that local state xj(t) is measurable
at the subsystem level and that there is no measurement noise. This means that
the measured output of Sj is equal to xj(t). In the sequel, we consider that the
disturbance input w(t) ∈ℜq is generated by the following class of systems:
˙ζ(t) = S ζ(t), w(t) = W ζ(t), ζ(t) ∈ℜg
(4.43)
where S ∈ℜg×g, the pair W, S is observable with the initial condition ζ(0)
in (4.43), and the matrix Γj in () is arbitrary, nevertheless unknown.
For the purpose of future comparison, we represent the state-space model
of the overall system S as follows:
˙x(t)
=
Ax(t) + Bu(t) + Γw(t)
y(t)
=
Cx(t)
(4.44)
where
x(t)
=

xt
1(t)
xt
2(t)
· · ·
xt
ns(t)
t ∈ℜn,
u(t)
=

ut
1(t)
ut
2(t)
· · ·
ut
ns(t)
t ∈ℜm,
y(t)
=

yt
1(t)
yt
2(t)
· · ·
yt
ns(t)
t ∈ℜp,
B
=
Blockdiag

B1
B2
· · ·
Bns
t ,
Γ
=

Γt
1
Γt
2
· · ·
Γt
ns
t ,
C
=
Blockdiag

C1
C2
· · ·
Cns

,
n
=
ns

j=1
nj, m =
ns

j=1
mj, p =
ns

j=1
pj
(4.45)

4.6. Hierarchically Structured Servomechanism
157
and
A =
⎡
⎢⎢⎢⎣
A11
0
0
· · ·
0
A21
A22
0
· · ·
0
...
...
...
...
A1ns
A2ns
A3ns
· · ·
Ansns
⎤
⎥⎥⎥⎦
(4.46)
having a lower block triangular form reﬂecting the desired hierarchical struc-
ture in (4.44). Moreover, we consider the initial state x(0) as a random variable
with mean xm and covariance Xm which leads to
X0 = IE[x(0)xt(0)] = Xm + xmxt
m
(4.47)
with IE[.] being the expectation operator. The following assumptions are needed
before tackling the desired decentralized control problem.
Assumption 4.1: The matrices Bj, Cj, and W satisfy the following rank
conditions:
rank(W) = q, rank(Bj) = mj, rank(Cj) = pj,
j ∈{1, ..., ns}
(4.48)
Assumption 4.2: The matrices
⎡
⎣
Ajj −sjIj
Bk
Ck
0
⎤
⎦, j ∈{1, ..., ns}, k ∈1, ..., g
(4.49)
are full-rank where s1, s2, ..., sg represents the eigenvalues of S and the in-
equality mj ≥pj holds for all j ∈{1, ..., ns}.
Assumption 4.3: The pair (Ajj, Bj) is stabilizable for all j ∈{1, ..., ns}
Given the foregoing assumptions and model set-up, the decentralized con-
trol problem of interest is phrased below.
Design a decentralized LTI controller Kd with block diagonal information
ﬂow structure such that the following conditions hold:
1. The state x(t) goes to zero as t →0, provided z(0) = 0;
2. The output y(t) approaches zero as t →0 regardless of the initial state
z(0);
3. When z(0) is a zero vector, the following closed-loop performance index
J := IE
  ∞
0

xt(s)Qx(s) + ut(s)Ru(s)

ds

(4.50)
is satisfactorily small, where 0 < Q ∈ℜn×n, 0 ≤R ∈ℜm×m.

158
Chapter 4. Decentralized Servomechanism System
4.6.1
Decentralized controller structure
In preparation of the main results on decentralized gain computation [169],
we consider the case of free disturbance ζ(0) = 0 and deﬁne the following
quantities for j ∈{1, ..., ns}:
xk(t)
=
 xt
1(t)
· · ·
xt
k−1(t)
xt
k+1(t)
· · ·
xt
ns(t) t ,
uk(t)
=

ut
1(t)
· · ·
ut
k−1(t)
ut
k+1(t)
· · ·
ut
ns(t)t t (4.51)
Then we introduce the following centralized dynamic controller Kc:
˙πc(t)
=
Acπc(t) + Ecx(t), πc(t) ∈ℜnc
u(t)
=
Ccπc(t) + Dcx(t)
(4.52)
It was shown in [169] that there exist constant matrices Ec, Fc, Gc, Hc, Ic,
Jc, Mc, Nc such that controller (4.52) can be expressed by the following
block-structure representation:
˙πc(t)
=
Acπc(t) + Ecxk(t) + Fcxk(t)
uk(t)
=
Gcπc(t) + Icxk(t) + Jcxk(t)
uk(t)
=
Hcπc(t) + Mcxk(t) + Ncxk(t)
(4.53)
for any k
∈
{1, ..., ns}. By the same token, there exist matrices
Ak,
Am,
Ak,
Bk derived from A and B in the manner of (4.51) such
that the aggregated system (4.42) admits the following structure for any k ∈
{1, ..., ns}:
˙xk(t)
=
Akxk(t) + Akxk(t) + Bkuk(t)
˙xk(t)
=
Amxk(t) + Akkxk(t) + Bkuk(t)
(4.54)
Now for subsystem Sj, we introduce the following local dynamic controller
Kdj:
˙πdk(t)
=
 Ak + BkIc
BkGc
Ec
Ac

πdk(t) +
 Ak + BkJc
Fc

xk(t),
uk(t)
=

Mc
Hc

πdk(t) + Ncxk(t)
(4.55)
Let Kd be a decentralized controller consisting of the local controllers
Kd1, Kd2, ..., Kdns
In view of the foregoing dynamical representations, the following result was
reported in [169].

4.6. Hierarchically Structured Servomechanism
159
Theorem 4.6.1 Assuming that x(0) is a known vector, then the state and input
patterns of the centralized system S under the centralized controller Kc are the
same as those of system S under the decentralized controller Kd, if the initial
state of the local controller Kdk as selected as
πdk(0) =
 xk(0)
0

(4.56)
This result implies that a centralized controller can be transformed to an equiv-
alent decentralized controller under appropriate choice of the initial state and
the exchange of all local controller initial states amongst dynamic controllers,
which is a quite demanding constraint as it destroyed the desired decentraliza-
tion. One way to remedy this is to recall upon a statistical nature of x(0), which
leads to modifying (4.56) into
πdk(0) =
 xk
m
0

(4.57)
Next, to examine the internal stability of the system S under the decentralized
controller {Kdj}, j ∈{1, ..., ns}, we look at a modiﬁed system Sk generated
from (4.44) with the following state-space representation:
˙x(t)
=
˜Akx(t) + Bu(t) + Γw(t)
y(t)
=
Cx(t)
(4.58)
where ˜Ak is derived from A by replacing the ﬁrst k −1 block entries of its kth
block row with zeros. Intuitively, we note that S1 = S. Deﬁne the decoupled
subsystem Sj, j ∈{1, ..., ns} by eliminating all of its incoming interconnec-
tions. This leads to the following result [170, 171].
Theorem 4.6.2 The centralized system S is internally stable under the decen-
tralized controller {Kdj}, j ∈{1, ..., ns}, if and only if the system Sk is stable
under the centralized controller Kd, for all k ∈{1, ..., ns}.
Considering the centralized dynamic controller Kc (4.52) where the system
matrices have the following properties:
1. Ac := Blockdiag

Λ
Λ
, · · · ,
Λ

;
2. Ec := BcC := Blockdiag

Υ
Υ
, · · · ,
Υ

;
3. The pair (Ac, Bc) is controllable

160
Chapter 4. Decentralized Servomechanism System
where the matrices Ac, Ec, Λ, and Υ are of appropriate dimensions. The
control design problem is summarized by the following:
Determine the matrices Ec, Cc, Dc so that the centralized dynamic con-
troller Kc (4.52) with the foregoing properties guarantees that the following
conditions hold:
1. The state x(t) goes to zero as t →0, provided z(0) = 0;
2. The output y(t) approaches zero as t →0 regardless of the initial state
z(0);
3. It satisﬁes all of the systems S2, · · · , Sns.
It has been shown in [170] that there exists a solution to the above problem if
and only if the matrices Ec, Cc, Dc satisfy a particular matrix inequality. The
result stems from a generalization of [46] as applied to the augmented system
of (4.52) and (4.58). Some appropriate computational procedures are presented,
which will be illustrated by the following examples.
4.6.2
Illustrative example 4.5
Consider the following large-scale system of the type (4.1) with
A
=
⎡
⎢⎢⎢⎢⎢⎢⎣
0.6
0
0
1
0.2
0
0.2
2.3
0.1
0
0
0.3
0
0
−1.5
0
0
0
0
0
0.7
1.1
0
0
0
0
0
0
−0.8
0
0
0
0
0
0.5
0.8
⎤
⎥⎥⎥⎥⎥⎥⎦
Go
=
[0.1 0.2 0.4 0.3], Gdo = [0.01 0 0.01 0]
Bo
=

0
0.3

, Co =
 1
10
0
0
0
0
10
10

, Cd =
 2
1
0
0
0
0
1
3

,
Do
=

0.4
0.2

, Ψo =

0.01
0.01

, Φ = 0.1
Using the MATLAB-LMI solver, the feasible solutions of the respective design
methods yield the feedback gain matrices:
Ks
=
 −34.5094
−4.9061
−52.4436
−130.5408
17.5392
−12.7566
79.5070
157.7008


4.6. Hierarchically Structured Servomechanism
161
Kd
=
 −34.5094
−4.9061
−52.4436
−130.5408
17.5392
−12.7566
79.5070
157.7008

Ko
=
⎡
⎢⎢⎣
−55.2134
15.8031
69.2668
−18.6633
−18.4083
5.0529
5.2346
−0.5445
⎤
⎥⎥⎦
4.6.3
Illustrative example 4.6
Consider the following large-scale system of the type (4.1) with
A
=
⎡
⎢⎢⎢⎢⎢⎢⎣
0.6
0
0
1
0.2
0
0.2
2.3
0.1
0
0
0.3
0
0
−1.5
0
0
0
0
0
0.7
1.1
0
0
0
0
0
0
−0.8
0
0
0
0
0
0.5
0.8
⎤
⎥⎥⎥⎥⎥⎥⎦
Go
=
[0.1 0.2 0.4 0.3], Gdo = [0.01 0 0.01 0]
Bo
=

0
0.3

, Co =
 1
10
0
0
0
0
10
10

, Cd =
 2
1
0
0
0
0
1
3

,
Do
=

0.4
0.2

, Ψo =

0.01
0.01

, Φ = 0.1
Using the MATLAB-LMI solver, the feasible solutions of the respective design
methods yield the feedback gain matrices:
Ks
=
 −34.5094
−4.9061
−52.4436
−130.5408
17.5392
−12.7566
79.5070
157.7008

Kd
=
 −34.5094
−4.9061
−52.4436
−130.5408
17.5392
−12.7566
79.5070
157.7008

Ko
=
⎡
⎢⎢⎣
−55.2134
15.8031
69.2668
−18.6633
−18.4083
5.0529
5.2346
−0.5445
⎤
⎥⎥⎦

162
Chapter 4. Decentralized Servomechanism System
4.7
Problem Set II
Problem II.1: Consider a large-scale system described by:
⎡
⎢⎢⎣
˙x1(t)
˙x2(t)
˙x3(t)
˙x4(t)
⎤
⎥⎥⎦
=
⎡
⎢⎢⎣
−1
2
3
1
α
−2
4
1
0
0
−3
0
0
0
0
−4
⎤
⎥⎥⎦
⎡
⎢⎢⎣
x1
x2
x3
x4
⎤
⎥⎥⎦+
⎡
⎢⎢⎣
1
0
0
0
0
1
0
0
⎤
⎥⎥⎦
 u1
u2

,
 y1
y2

=
 1
0
0
0
0
0
1
0

⎡
⎢⎢⎣
x1
x2
x3
x4
⎤
⎥⎥⎦
Check the controllability and observability of the system and show that it is in-
dependent of the parameter α. Examine the decentralized modes of the system
with respect to α = 0, α ̸= 0. Identify the decentralized ﬁxed modes.
Problem II.2: Consider a parametrized large-scale system described by:
⎡
⎣
˙x1(t)
˙x2(t)
˙x3(t)
⎤
⎦
=
⎡
⎣
0
α
3
0
β
4
0
0
3
⎤
⎦
⎡
⎣
x1
x2
x3
⎤
⎦+
⎡
⎣
1
1
0
⎤
⎦u1 +
⎡
⎣
0
0
1
⎤
⎦u2,
 y1
y2

=
 1
2
0
0
0
1
 ⎡
⎣
x1
x2
x3
⎤
⎦
Analyze the complete controllability and observability of the system with re-
spect to the parameters α, β. Which set of values of α, β yields decentralized
ﬁxed modes?
Problem II.3: A class of models for pollution control studies can be cast into
the form:
˙x(t)
=
⎡
⎣
A1
0
0
A21
A2
0
0
A32
A3
⎤
⎦x +
⎡
⎣
B1
0
0
0
0
B3
⎤
⎦u(t),
y(t)
=
 C1
0
0
0
0
C3

x
Naturally, this model has ﬁxed modes. Use the static decentralized controller
u(t)
=
 K1
0
0
K2

y(t)

4.7. Problem Set II
163
to identify the decentralized ﬁxed modes. Interpret your results.
Problem II.4: Consider the following system:
˙x(t)
=
⎡
⎣
0
0
1
1
−2
1
0
0
−4
⎤
⎦x +
⎡
⎣
0.2
0
0
0.5
0
0
⎤
⎦u(t),
y(t)
=
 0
5
0
2
0
0

x
It is required to examine the stabilizability of this system under decentralized
control by randomly selecting the gain matrix K = diag[k1
k2. Then design
a suitable decentralized dynamic compensator.
Problem II.5: Consider the following system:
˙x1(t)
=
 0
0
1
0.7

x1(t) +
 1
0

u1(t), y1(t) =

1
0

x1(t),
˙x2(t)
=
−0.6x2(t) + u2(t), y2(t) = x2(t),
˙x3(t)
=
 1
−0.2
1
−2

x3(t) +
 1
1

u2(t), y3(t) =

1
1

x3(t)
Develop a decentralized stabilizing control for this system.
Problem II.6: Illustrate the application of Theorem 4.5.1 on the large-scale
system described by:
⎡
⎣
˙x1(t)
˙x2(t)
˙x3(t)
⎤
⎦
=
⎡
⎣
−1
2
3
1
−2
4
0
0
−3
⎤
⎦
⎡
⎣
x1
x2
x3
⎤
⎦+
⎡
⎣
1
0
0
0
0
1
⎤
⎦
 u1
u2

,
 y1
y2

=
 1
0
0
0
0
1
 ⎡
⎣
x1
x2
x3
⎤
⎦
Give a detailed analysis of the results.

164
Chapter 4. Decentralized Servomechanism System
Problem II.7: Consider the large-scale system described by:
⎡
⎣
˙x1(t)
˙x2(t)
˙x3(t)
⎤
⎦
=
⎡
⎣
0
2
3
0
−2
4
0
1
−3
⎤
⎦
⎡
⎣
x1
x2
x3
⎤
⎦+
⎡
⎣
1
0
0
0
0
1
⎤
⎦
 u1
u2

,
 y1
y2

=
 δ1
δ2
0
δ3
0
δ4
 ⎡
⎣
x1
x2
x3
⎤
⎦
For the two distinct cases
1. δ1 = 0, δ2 = 1, δ3 = 1, δ4 = 0
2. δ1 = 1, δ2 = 2, δ3 = 0, δ1 = 1
examine the complete controllability and observability properties as well as the
modes of the system. Check the controllability and observability with respect
to the possible pairs (uj, yj). Then design an appropriate, decentralized static
output feedback controller that yields satisfactory performance and provides an
interpretation of the ensuing results.
4.8
Notes and References
In this chapter, three major problems related to decentralized structure of large-
scale systems were addressed. The ﬁrst problem was that of decentralized sta-
bilization which amounts to ﬁnding a state or an output feedback gain guar-
anteeing that the closed-loop system has all its eigenvalues on the left half-
plane. This is commonly known as feedback “stabilization.” Alternatively, the
closed-loop eigenvalues of a centralized controllable system may be preas-
signed through the state of output feedback. It is readily evident that the ap-
plications of these concepts in a decentralized fashion required certain exten-
sions. In the foregoing sections, the problem of decentralized stabilization was
mathematically formulated and some of the appropriate schemes for decen-
tralized feedback stabilization were reviewed. The notions of “ﬁxed modes,”
“ﬁxed polynomials,” and their role in dynamic compensation were disclosed.
The second problem addressed in this chapter was the decentralized “ro-
bust” control of large-scale linear systems with or without a known plant. The
main thrust was the approach in [45]-[56] frequently known as “general ser-
vomechanism.” The approach took advantage of the tuning regulators and dy-
namic compensators to design a feedback that both stabilized and regulated the
system in a decentralized mode. The notion of “robust” feedback control was

4.8. Notes and References
165
introduced when the control action continued to provide asymptotic stability
and regulation under perturbation of plant parameters and matrices.
By the third problem, a near-optimal decentralized servomechanism con-
troller was designed for a hierarchical interconnected system. The objectives
of control design were to achieve satisfactory performance with respect to a
prescribed linear-quadratic cost function and to be capable of rejecting unmea-
surable external disturbances of known dynamics. The case when the system
is subject to perturbation was explored. By making use of the information of
every individual subsystem about the overall system, the control design was
initialized. Since this information was inexact in practice, a procedure was pre-
sented to assess the degradation of the performance of the decentralized control
system as a result of the erroneous information.
There are ample extensions to the developed approaches. One of these
would be to examine the case of decentralized servomechanism problem for
discrete-time systems. The literature lacks research results on this topic as vir-
tually no publication material is available. Another extension is related to the
tracking problem for exponentially increasing reference signals. Furthermore,
since in practice the delay in the state or the input of the system is variable
(may be uncertain), it would be of interest to ﬁnd a bound on the delay that
guarantees the closed-loop stability under the proposed linear-quadratic sub-
optimal decentralized controller. Finally for the case of arbitrary interaction
topology, it is considered beneﬁcial to develop decentralized control laws that
yield reliable performance.

Chapter 5
Overlapping Control
In this chapter, we continue our evaluation of the development of methods for
tackling large-scale systems (LSS). In particular, the models of LSS summa-
rized in the sequel are distinguished by the degree to which they reﬂect the
internal structure of the overall system. Then we focus on the concept of sys-
tem decomposition and disclose the effective tool of overlapping decomposi-
tion. The process of actual tearing of the system may be performed from either
conceptual or numerical reasons. Conceptual reasons correspond usually with
the boundaries of physical subsystems. Numerical reasons require to develop a
universal decomposition technique.
The units constituting a hierarchical structure are not completely indepen-
dent but have to respond to data delivered by other units. Although this commu-
nication ensures that the global goals will eventually be satisﬁed, it prescribes
the decision makers certain working regimes. Decentralization concerns the in-
formation structure of the decision-making process. In decentralized decision
making the decision units are completely independent or at least almost in-
dependent. That is, the network, which describes the information ﬂow among
the decision makers, can be divided into completely independent parts. The
decision makers belonging to different subnetworks are completely separate
from each other. Since such a complete division is possible only for speciﬁc
problems, the term decentralized will also be used if the decision makers do
communicate but this communication is restricted to certain time intervals or
to a small part of the available information.
The outline of multilevel systems has shown that some coordination and,
therefore, communication among the decision-making units is necessary if the
overall goal is to be reached. In decentralized structures, such a coordination
is impossible or restricted in accordance with the information exchange that
167

168
Chapter 5. Overlapping Control
is permitted. However, because of the simpliﬁcations in the practical imple-
mentation of coupled decision makers, which are gained from the absence of
information links, decentralized structures are often used but reduce the quality
of the solution.
5.1
Decomposition
The foregoing chapters taught us one fundamental lesson. As the number of
computations required to analyze and control a system grows faster than the
size of the system, it is therefore considered beneﬁcial to break down (decom-
pose) the whole problem into smaller subproblems, to solve these subproblems
separately, and then to combine (recompose) their solutions in order to get a
global result for the original task. It must be emphasized that the subproblems
are not independent. Some modiﬁcation or coordination of the solutions of the
subproblems is necessary in order to satisfy the interrelationships between the
subproblems. The effort required to deal with the subproblems and their coor-
dination can be allocated to various processors, which constitute a distributed
computing system. Therefore, the concepts and techniques for reformulating a
control problem as a set of interdependent subproblems and for solving these
subproblems are referred to in this book as coordinated control.
5.1.1
Decoupled subsystems
The basis for the decomposition of the analytical or control problems is often
provided by the internal structure of the process to be controlled. Accordingly,
the process is not considered as a single object but as a compound of different
interacting subsystems. Decomposition methods, generally speaking, exploit
the system structure, which can be obtained from the building blocks of the
process, or have to impose a structure for mathematical reasons. Let us consider
the LSS described by the overall model:
˙x(t)
=
Ax(t) + Bu(t),
x(0) = xo
y(t)
=
Cx(t)
(5.1)
where x(t)
∈ℜn is the overall state vector,
u(t)
∈ℜm
is the control
input, and y(t) ∈ℜp is the overall output vector. The matrices A ∈ℜn×n,
B ∈ℜn×m, and C ∈ℜp×m
are constants. In Chapter 3, we followed an
upward approach and discussed ways to generate an overall system of the form
(5.1) from its subsystem models. In what follows, the downward approach from

5.1. Decomposition
169
the overall system (5.1) to the subsystem models is considered. The partition
of the state vector x(t) into subvectors xj(t), j = 1, ..., ns yields
˙xj(t)
=
Ajxj(t) +
ns

k=1,j̸=k
Ajkxk(t) +
ns

k=1
Bjkuk(t)
yj(t)
=
ns

k=1,j̸=k
Cjkxk(t)
(5.2)
where the matrices B and C have been partitioned into blocks Bjk and
Cjk, j = 1, ..., ns, k = 1, ..., ns according to the partition of x(t), u(t),
and y(t). Obviously, the subsystem state xj(t) depends on all inputs uj(t), and
the subsystem output yj(t) on all states xj(t).
Since the ultimate goal is to get “weakly coupled” subsystems the parti-
tion of x(t) should be done in such a way that the dependencies of yj(t) on
uk(t), j ̸= k are zero or weak. Systems of the form
˙xj(t)
=
Ajxj(t) +
ns

k=1,j̸=k
Ajkxk(t) + Bjuj(t)
yj(t)
=
ns

k=1,j̸=k
Cjkxk(t),
j = 1, ..., ns
(5.3)
are often termed input decentralized and systems
˙xj(t)
=
Ajxj(t) +
ns

k=1,j̸=k
Ajkxk(t) +
ns

k=1
Bjkuk(t)
yj(t)
=
Cjxj(t)
(5.4)
are often termed output decentralized. By similarity,
˙xj(t)
=
Ajxj(t) +
ns

k=1,j̸=k
Ajkxk(t) + Bjuj(t)
yj(t)
=
Cjx(t)
(5.5)
are often termed input-output decentralized.
The disjoint decomposition into input-decentralized, output-decentralized
or input-output decentralized subsystems has been proposed by [196]-[203]
and [323] using different formats. In [310, 311], a decomposition method was

170
Chapter 5. Overlapping Control
given where the interactions of the resulting subsystems are lower than a pre-
scribed threshold. In essence, when considering disjoint subsystems and con-
sidering (5.1)-(5.5), we are led to the notion of ϵ-decomposition. The idea of
ϵ-decomposition can be simply explained on the linear dynamic system (5.1)
by deﬁning
A
=
AD + ϵ AC
AD
=
Blockdiag{A1, A2, · · · , Ans}
(5.6)
The matrix AC has all its elements smaller than one, and ϵ is a prescribed small
number. The choice of ϵ inﬂuences on the strength of interconnections [200]. If
each subsystem Aj is stable, then an appropriate choice of ϵ preserves the weak
coupling property of the system and thereby the stability of the overall system.
The increasing threshold of ϵ leads to the notion of nested ϵ-decomposition
[324, 325].
5.1.2
Overlapping subsystems
The decomposition of the overall system into disjoint subsystems is not ef-
fective in situations where the subsystems are strongly coupled. It means that
a given system has no ϵ-decomposition and one has to attempt an alternative
procedure. One such procedure is the overlapping decomposition in which the
subsystems share some common parts. Basically, the overlapping subsystems
may be weakly coupled although disjoint subsystems are not, that is, they may
have an overlapping ϵ-decomposition [325].
A systematic way of overlapping decomposition means to expand the orig-
inal system with strongly coupled subsystems into a larger dimensional sys-
tems with weakly coupled subsystems. There is a requirement of the relation
between both systems. The solution of a large-dimensional system must in-
clude the solution of a lower dimensional original system. A circle of ideas,
methods, and algorithms devoted to overlapping decompositions has been for-
mulated rigorously into a general mathematical framework called the inclusion
principle [41, 324].
5.1.3
Transformations
Start with the expansion of the original system (5.1) into the system
˙˜x(t)
=
˜A˜x(t) + ˜Bu(t),
˜x(0) = ˜xo
y(t)
=
˜C˜x(t)
(5.7)

5.1. Decomposition
171
Formally, the systems (5.1) and (5.7) are related by some contraction transfor-
mation
x(t)
=
T† ˜x(t)
(5.8)
where
T† T = I
(5.9)
holds with the superscript “†” denoting the pseudo inverse of a rectangular
matrix.
Deﬁnition 5.1.1 A system (5.7) is said to include a system (5.1) if there exists
an ordered pair of matrices (T, T†) such that relations (5.8) and (5.9) hold.
The systems (5.1) or (5.7) are called contraction or expansion, respectively.
It should be observed that the expansion of (5.1) into a new system (5.7) yields
some parts of the original system (5.1) to appear more than once. Obviously
if system (5.7) is decomposed into disjoint subsystems, then these parts of
(5.1) belong simultaneously to two or more subsystems. That is, the subsys-
tems overlap.
An expansion (5.7) can be found by using the matrices
˜A
=
TAT† + M,
˜B = TB + N
˜C
=
CT† + L
(5.10)
and by choosing appropriate matrices M, N, and L. The following theorem
establishes the ﬁrst basic result.
Theorem 5.1.2 The system (5.7) with relations (5.10) is an expansion of (5.1)
if and only if the following conditions are satisﬁed:
T†MℓT
=
0, T†Mℓ−1N = 0,
LMℓ−1T
=
0, LMℓ−1N = 0
ℓ
=
1, 2, ...., dim(˜x)
(5.11)
Proof: The theorem can be readily derived by considering the standard relation
T† exp( ˜At) T = exp(At)
along with the time series expansion of exp( ˜At) and exp(At).
The method of investigating a given system (5.1) by considering the expan-
sion (5.7) and inferring the results to the contraction (5.1) is called the inclusion
principle. An important fact for the application of the inclusion principle is that
the stability property of the system (5.1) is preserved in the expansion.

172
Chapter 5. Overlapping Control
Theorem 5.1.3 If the systems (5.1) and (5.7) are a contraction or an expan-
sion, respectively, then the asymptotic stability of the system (5.7) implies the
asymptotic stability of the system (5.1).
5.1.4
Illustrative example 5.1
Consider the system (5.1) with partitioned state vector x = [xt
1, xt
2, xt
3]t and
structured matrices A = Ajk,
B = Bjk. An overlapping decomposition is
given by ˜x1 = [xt
1, xt
2, ˜x2 = [xt
2, xt
3]t which satisﬁes (5.8) with
T
=
⎡
⎢⎢⎣
I
0
0
0
I
0
0
I
0
0
0
I
⎤
⎥⎥⎦, T† =
⎡
⎣
I
0
0
0
0
0.5I
0.5I
0
0
0
0
I
⎤
⎦
(5.12)
Simple computations using (5.10) yield:
˜A
=
⎡
⎢⎢⎣
A11
A12
0
A13
A21
A22
0
A23
A21
0
A22
A23
A31
0
A32
A33
⎤
⎥⎥⎦, N = 0
˜B
=
⎡
⎢⎢⎣
B11
A12
B21
B22
B21
B22
B31
B32
⎤
⎥⎥⎦, M =
⎡
⎢⎢⎣
0
0.5A12
−0.5A12
0
0
0.5A22
−0.5A22
0
0
0.5A22
−0.5A22
0
0
0.5A32
−0.5A32
0
⎤
⎥⎥⎦
Hence the isolated subsystems of the expansion (5.7) are
˙˜x1(t)
=
 A11
A12
A21
A22

˜x1(t) +
 B11
B21

u1(t)
(5.13)
˙˜x1(t)
=
 A22
A23
A32
A33

˜x2(t) +
 B22
B32

u2(t)
(5.14)
The overall system matrix has the form
A
=
⎡
⎢⎢⎢⎢⎢⎢⎢⎣
A11
A12
...
A13
· · ·
· · ·
· · ·
· · ·
A21
...
A22
...
A23
· · ·
· · ·
· · ·
...
A31
...
A32
A33
⎤
⎥⎥⎥⎥⎥⎥⎥⎦

5.2. Feedback Control Design
173
Little inspection shows that the original system (5.1) has been expanded in
such a way that the state ˜x2 belongs to both new subsystems (5.13) and (5.14).
Consequently, the matrix A22 is used twice. This explains the term overlap-
ping decomposition. The overall system state space is not the direct sum of the
subsystem state spaces. This decomposition is particularly useful for systems
with A31 = 0, A13 = 0, B12 = 0 and B21 = 0, since these matrices are
neglected when considering the decomposition (5.13) and (5.14).
It is fair to record that the inclusion principle was proposed in the early
1980s in the context of analysis and control of large-scale systems [124]-[131]
and [324]. Essentially, this principle establishes a mathematical framework for
two dynamic systems with different dimensions, in which solutions of the sys-
tem with the larger dimension include solutions of the system with smaller
dimension.
5.2
Feedback Control Design
As we have noted earlier, the mathematical framework of the inclusion prin-
ciple relies on the choice of appropriate linear transformations M, N, L be-
tween the inputs, states, and outputs of both systems. These matrices, which
are at the disposal of the designer, are frequently called the complementary
matrices [15]. Based thereon with the context of optimal control, the idea is to
expand a system with overlapped components into a larger-dimensional system
that appears decomposed into a number of disjoint subsystems. Then, decen-
tralized controllers are designed for the expanded system and contracted to be
implemented in the original system [12, 13, 124, 131, 129, 324].
The conditions given in previous works on the complementary matrices
[124]-[130] to ensure the inclusion principle have a fundamental and implicit
nature. Simply stated, they have the form of matrix products from which it
is not easy to select speciﬁc values for the matrices. A few simple standard
choices have been commonly used in practice, while the exploitation of the
degree of freedom offered by the selection of the complementary matrices has
been considered as one of interesting research issues [128]. In this regard, a
new characterization of the complementary matrices was recently presented
in [15], which gave a more explicit way for their selection. It relies on intro-
ducing appropriate changes of basis in the expansion-contraction process as
already suggested in [130]. In the sequel, we proceed along the same direction
to provide results on overlapping decentralized state linear-quadratic optimal
control.

174
Chapter 5. Overlapping Control
5.2.1
Linear-quadratic control
For simplicity in exposition, we consider a pair of optimal control problems
min
u J(u)
=
 ∞
0
(xtQ∗x + utR∗u)dt,
s.t S : ˙x(t)
=
Ax(t) + Bu(t)
(5.15)
min
˜u
˜J(˜u)
=
 ∞
0
(˜xt ˜Q∗˜x + ˜ut ˜R∗˜u)dt,
s.t˜S : ˙˜x(t)
=
˜A˜x(t) + ˜B˜u(t)
(5.16)
where x(t) ∈ℜn, u(t) ∈ℜm are the state and input of S at time t ∈ℜ+ and
˜x(t) ∈ℜ˜n, ˜u(t) ∈ℜ˜m are those ones of ˜S. The matrices A, B, Q∗, R∗
and ˜A,
˜B,
˜Q∗,
˜R∗are constant matrices of dimensions n × n, n × m,
n × n, m × m, and ˜n × ˜n, ˜n × ˜m, ˜n × ˜n, ˜m × ˜m, respectively. Matrices
Q∗≥0, R∗≥0, tildeR∗≥0. Suppose that the dimensions of the state and
input vectors x(t), u(t) of S are smaller than (or at most equal to) those of
˜x, ˜u of ˜S. We use x(t; x0, u) to denote the state behavior of S for a ﬁxed input
u(t) and an initial state x(0) = x0. Similar notation ˜x(t; ˜x0, ˜u) is used for the
state behavior of system ˜S.
In line of the preceding section, we can see that systems S and ˜S are related
by the transformations
˜x(t) = V x(t), x(t) = U ˜x(t), ˜u(t) = Ru(t), u(t) = Q˜u(t)
where V, U, Q, and R are constant matrices of appropriate dimensions and
full rank satisfying
UV = In, QR = Im
where In, Im are identity matrices of indicated dimensions. The following
deﬁnition provides a wide-sense statement of the inclusion principle.
Deﬁnition 5.2.1
1. System ˜S is said to include system S, that is, ˜S ⊃S, if there exists a
triplet (U, V, R) such that, for any initial state x0 and any ﬁxed input
u(t) of S, the choice ˜x0 = V x0 and ˜ut = Ru(t) for all t ≥0 of
the initial state ˜x0 and input ˜u(t) of the system S implies x(t; x0, u) =
U ˜x(t; ˜x0, ˜u) for all t ≥0.
If ˜S ⊃S,
then ˜S is said to be an expansion of S and S is called a
contraction of ˜S.

5.2. Feedback Control Design
175
2. The pair (˜S; ˜J) is said to include the pair (S; J),
that is, (˜S; ˜J) ⊃
(S; J) if
˜S ⊃S,
J(x0; u) = ˜J( ˜x0; ˜u)
The matrices of (˜S; ˜J) and (S; J) can be related via
˜A
=
V AU + M,
˜B = V BQ + N,
˜
Q∗
=
UtQ∗U + MQ∗,
˜
R∗= QtR∗Q + NR∗
where M, N, MQ∗, NR∗are constant complementary matrices of ap-
propriate dimensions.
The following preliminary results can be readily established.
Theorem 5.2.2 System ˜S is an expansion of system S if and only if UMjV = 0
and UMj−1NR = 0 for all j = 1, 2, ....., ˜n.
Theorem 5.2.3 ˜S ⊃S if and only if there exists ¯S such that ˜S ⊃¯S ⊃S, where
¯S is a restriction (aggregation) of ˜S and S is an aggregation (restriction) of ¯S.
The expansion and contraction between systems S and ˜S can be illustrated in
the form
S →˜S →S
ℜn V−→ℜ˜n U−→ℜn
ℜm R
−→ℜ˜m Q
−→ℜm
(5.17)
It follows that for (˜S; ˜J) to be an expansion of (S; J), a proper choice of the
matrices M, N, MQ∗, NR∗is required. The following theorem provides such
a requirement [128].
Theorem 5.2.4 The pair (˜S; ˜J) ⊃(S; J) if either
1. MV = 0, NR = 0, V tMQ∗V = 0, RtNR∗R = 0 or
2. UMjV = 0, UMj−1NR = 0, MQ∗Mj−1V = 0,
MQ∗Mj−1NR = 0, RtNR∗R = 0 ∀j = 1, 2, ....., ˜n
So far, all the statements and the foregoing analysis pertain to uncontrolled
systems. The next deﬁnition and results are related to controlled systems.
Deﬁnition 5.2.5 A control law ˜u = −˜K˜x for ˜S is contractible to the control
law u = −Kx for implementation to S if the choice ˜x0 = V x0 and ˜u = Ru
implies Kx(t; x0, u) = Q ˜Kx(t; x0, u), for all t ̸= 0, for any initial state x0
and any ﬁxed input u(t) of S.

176
Chapter 5. Overlapping Control
Now suppose that ˜K = RKU + F, where F denotes a complementary matrix.
The conditions to satisfy Deﬁnition 5.2.5 are given by the following theorem
whose proof is given in [128].
Theorem 5.2.6 A control law ˜u = −˜K˜x for ˜S is contractible to the control
law u = −Kx for S if and only if QFMj−1V = 0 and QFMj−1NR = 0,
for all j = 1, 2, ...., ˜n.
An equivalent form of Theorem 5.2.6, which gives an explicit expression of
matrix K from matrix ˜K, is summarized by the following theorem.
Theorem 5.2.7 A control law ˜u = −˜K˜x for ˜S is contractible to the control
law ˜u = Ru for S if and only if Q ˜KV = K, Q ˜KMj−1V = 0 for all j =
1, 2, ...., ˜n, and Q ˜KMj−1NR = 0 for all i = 1, 2, ...., ˜n.
5.2.2
Change of basis
Since the Inclusion Principle does not depend on the speciﬁc basis used in the
state, input and output spaces for both systems S and ˜S, we follow [15] and
proceed to introduce convenient changes of basis in ˜S. Thus, scheme (5.17) can
be modiﬁed into the form
S →˜S →˜S →˜S →S
ℜn V−→ℜ˜n T −1
A
−−→ℜ
˜n TA
−−→ℜ˜n U−→ℜn
ℜm R
−→ℜ˜m T −1
B
−−→ℜ
˜m TB
−−→ℜ˜m Q
−→ℜm
(5.18)
where now ˜S denotes the expanded system with the new basis. The idea of
using changes of basis in the expansion-contraction process was already intro-
duced in [130] to represent ˜S in a canonical form. Now given V and R, we
deﬁne U = (V tV )−1V t, Q = (RtR)−1Rt as their pseudo inverses, respec-
tively, and consider
TA = (V WA),
TB = (R WB)
(5.19)
where WA, WB are chosen such that
Im(WA) = Ker(U),
Im(WB) = Ker(Q)
Using these transformations, it is not difﬁcult to verify the following condi-
tions:
3
UV
=
In,
3
V U =
In
0
0
0


5.2. Feedback Control Design
177
and
3
QR
=
Im,
3
RQ =
Im
0
0
0

where
(V
=
T −1
A V =
In
0

(U
=
UTA = (In0)
and
(R
=
T −1
B R =
Im
0

,
(Q = QTB = (Im0)
In fact, these conditions will be crucial to obtain explicit block structures (with
zero blocks) of the complementary matrices and further to give a general strat-
egy for their selection.
5.2.3
Improved expansion-contraction
The expansion-contraction process will be developed for the system S having
the following structure S:
⎡
⎣
˙x1
˙x2
˙x3
⎤
⎦=
⎡
⎣
A11
A12
A13
A21
A22
A23
A31
A32
A33
⎤
⎦
⎡
⎣
x1
x2
x3
⎤
⎦+
⎡
⎣
B11
B12
B13
B21
B22
B23
B31
B32
B33
⎤
⎦
⎡
⎣
u1
u2
u3
⎤
⎦
(5.20)
where Aii, Bii, i = 1, 2, 3 are ni × ni and ni × mi dimensional matrices, re-
spectively. This system is composed of two subsystems with one overlapped
part. This simple structure will help in smoothing the notation. The results ob-
tained can be easily generalized for any number of interconnected overlapping
subsystems. This structure has been extensively adopted as prototype in the lit-
erature within the Inclusion Principle. Consider the optimal control problem in
the system ˜S,
min
eu
(J((x0, (u)
=
 ∞
0
((xt (Q∗(x + (ut (R∗(u)dt
s.t ˜S : ˙˜x
=
˜A(x + ˜B˜u
(5.21)

178
Chapter 5. Overlapping Control
where (x and (u are deﬁned as
(x = T −1
A V x = (V x, (u = T −1
B Ru = (R(u
In addition, (A, (B, 4
Q∗, and 4
R∗are constant matrices of appropriate dimensions
verifying
(A
=
(V A(U + 4
M, (B = (V B (Q + (
N,
4
Q∗
=
(UtQ∗(U + 4
MQ∗, (R∗= (QtR∗(Q + (
NR∗
where the new complementary matrices are expressed as [15]:
4
M = T −1
A MTA, (
N = T −1
A NTB, 4
MQ∗= T t
AMQ∗TA, (
NR∗= T t
BNR∗TB
Using these matrices, the conditions given by the inclusion principle as stated
in Theorem 5.2.2 become
3
UM
j (V = 0, 3
UM
j−1 3
NR = 0, ∀j = 1, 2, ...., ˜n
Our immediate task is to analyze the form of matrices 4
M, (
N, 4
MQ∗, and (
NR∗.
For this purpose, we consider for j, k = 1, .., 4 the complementary matrices
M = (Mij), N = (Nij), MQ∗= (MQ∗
ij), NR∗= (NR∗
ij)
where all submatrices have appropriate dimensions and MQ∗
ij = Mt
Q∗
ji, NR∗
ij =
N t
R∗
ji. To proceed further, we introduce the matrices
4
M
=
)
4
M11
4
M12
4
M21
4
M22
*
, (
N =
)
(
N11
(
N12
(
N21
(
N22
*
,
4
MQ∗
=
)
4
MQ∗
11
4
MQ∗
12
4
MQ∗
21
4
MQ∗
22
*
, (
NR∗=
)
(
NR∗
11
(
NR∗
12
(
NR∗
21
(
NR∗
22
*
where
4
M11
∈
ℜn×n, 4
M22 ∈ℜ˜n−n×˜n−n, (
N11 ∈ℜn×m, (
N22 ∈ℜ˜n−n× ˜m−m,
4
MQ∗
11
∈
ℜn×n, 4
MQ∗
22 ∈ℜ˜n−n×˜n−n, (
NR∗
11 ∈ℜm×m,
(
NR∗
22
∈
ℜ˜m−m× ˜m−m
The following lemmas summarize the main results.

5.2. Feedback Control Design
179
Lemma 5.2.8 Consider system (5.15) and the corresponding expanded system
(5.21) verifying the inclusion principle. It follows that
4
M =
)
0
4
M12
4
M21
4
M22
*
where 4
M12 4
Mj−2
22
4
M21 = 0, ∀j = 2, ..., ˜n.
Lemma 5.2.9 Consider system (5.15) and the corresponding expanded system
(5.21) verifying the inclusion principle. It follows that
(
N =
)
0
(
N12
(
N21
(
N22
*
where 4
M12 4
Mj−2
22
(
N21 = 0, ∀j = 2, ..., ˜n.
The proofs of Lemmas 5.2.8 and 5.2.9 can be established in line of [15]. Based
thereon, we have the following result.
Theorem 5.2.10 Consider the optimal control problems (5.15) and (5.21).
Then the pair ((S, (J) ⊃(S, J) if either of the following conditions hold:
1.
4
M
=
)
0
4
M12
0
4
M22
*
, (
N =
)
0
(
N12
0
(
N22
*
,
4
MQ∗
=
)
0
4
MQ∗
12
4
Mt
Q
∗
12
4
MQ∗
22
*
, (
NR∗=
)
0
(
NR∗
12
(
N t
R
∗
12
(
NR∗
22
*
2.
4
M =
)
0
4
M12
4
M21
4
M22
*
,
(
N =
)
0
(
N12
(
N21
(
N22
*
such that 4
M12 4
Mj−2
22
4
M21 = 0 and 4
M12 4
Mj−2
22
(
N21 = 0, ∀j = 2, ...., ˜n,
4
MQ∗=
 0
0
0
4
MQ∗
22

such that 4
MQ∗
12 4
Mj−2
22
4
M21 = 0, ∀j = 2, ..., ˜n,
4
MQ∗
12 4
Mi−2
22
(
N21 =
0, ∀j = 2, ...., ˜n + 1, and
(
NR∗=
)
0
(
NR∗
12
(
N t
R∗
12
(
NR∗
22
*

180
Chapter 5. Overlapping Control
Theorem 5.2.11 The pair ((S, (J◦) ⊃(S, J◦) if
3
MV = 0, R∗= ( (Q( ˜(R∗)−1 (Qt)−1, (
N = 0, (V t 4
MQ∗(V = 0
Proof: Let the Riccati matrices associated with the solutions of the prob-
lems (5.15) and (5.21) be P and (P, respectively. Then, the optimal costs are
J◦(x0 = xt
0Px0 and (J◦= (xt
0 (P (x0. It follows that the relation P = (V t (PV
results directly from (x0 = (V x0 and J◦(x0) =
(J◦((x0). On substituting
(A = (V A(U + 4
M and (B = (V B (Q + (
N into the corresponding Riccati equation
of problem (5.21) and P = (V t (˜PV into the Riccati equation of problem (5.15)
and comparing both equations, we reach the desired result.
Next, we proceed to determine the conditions under which a control law
designed in the expanded system (S can be contracted to be implemented in the
initial system S. Considering the system (5.20), let K be the associated gain
matrix. Denote F as the corresponding complementary matrix with the form
F = (Fjk), j, k = 1, ..., 4. Further, deﬁne
(F
=
)
(F11
(F12
(F21
(F22
*
where (F11 ∈ℜm×n, (F22 ∈ℜem−m×en−n. It turns out that the gain matrix ˜(K
for the system (S has the form (K = (RK (U + (F, where ˜(K = T −1
B KTA and
(F = T −1
B FTA. By Deﬁnition 5.2.5, we have (u = −(K(x is contractible to the
control law u = −Kx if
Kx(t; x0, u) = 3
QK(x(t; (V x0, (Ru)
Consequently, the following theorem follows from the preceding results.
Theorem 5.2.12 A control law (u = −(K(x designed in the expanded system (S
is contractible to the control law u = −Kx of the system S if and only if
(F
=
)
0
(F12
(F21
(F22
*
and (F12 4
Mj−2
22
4
M21 = 0, (F12 4
Mj−2
22
(
N21 = 0, ∀j = 2, ..., ˜n + 1.

5.2. Feedback Control Design
181
5.2.4
Particular selection
Recalling the results of example 5.1, and to make a practical use of the charac-
terizations of 4
M, 4
M to enable the expansion-contraction process, we proceed
by deﬁning the speciﬁc transformations V and R to expand a given problem
(5.15). Needless to stress that the choice of these expansion matrices is limited
by the information structure constraints as it demands the preservation of the in-
tegrity of the local feedback and subsystems in overlapping decentralized con-
trol. Once V and R are chosen, the corresponding changes of basis TA, TB are
given by (5.19). It is straightforward to obtain the structure of the complemen-
tary matrices M, N, 4
MQ∗, (
NR∗and F from the corresponding expressions
4
M = T −1
A MTA, (
N = T −1
A NTB, 4
MQ∗= T t
AMQ∗TA, NR∗= T t
BNR∗TB,
and (F = T −1
B FTA. In conclusion, from the derived structure, the designer can
select speciﬁc values of the elements of complementary matrices according to
given speciﬁcations.
Let us illustrate this procedure for the following expansion transformation
matrices:
V =
⎡
⎢⎢⎣
In1
0
0
0
In2
0
0
In2
0
0
0
In3
⎤
⎥⎥⎦, R =
⎡
⎢⎢⎣
Im1
0
0
0
Im2
0
0
Im2
0
0
0
Im3
⎤
⎥⎥⎦
(5.22)
These transformations are chosen to help, in the manner of example 5.1, to an
expanded system where state vector x2 and control vector u2 appear repeated in
(xt = (x1t, xt
2, xt
2, xt
3) and (ut = (ut
1, ut
2, ut
2, ut
3), respectively. According
to (5.19), the changes of basis to deﬁne the system (S for matrices (5.22) are
given by
TA =
⎡
⎢⎢⎣
In1
0
0
0
0
In2
0
In2
0
In2
0
−In2
0
0
In3
0
⎤
⎥⎥⎦, T −1
A =
⎡
⎢⎢⎣
In1
0
0
0
0
1
2In2
1
2In2
0
0
0
0
In3
0
1
2In2
−1
2In2
0
⎤
⎥⎥⎦
(5.23)
In a similar way, we get TB, T −1
B . Then, by Lemmas 5.2.8 and 5.2.9 and
using the relations 4
M = T −1
A MTA and (
N = T −1
A NTB, it is easy to obtain
the following structure for complementary matrix M:
M =
⎡
⎢⎢⎣
0
M12
−M12
0
M21
M22
M23
M24
−M21
−(M22 + M23 + M33
M33)
−M24
0
M42
−M42
0
⎤
⎥⎥⎦
(5.24)

182
Chapter 5. Overlapping Control
By the same token, we have a similar one for N, which, for all j = 2, ..., ˜n,
must verify
⎡
⎣
M12
M23 + M33
M42
⎤
⎦(M22 + M32)j−2 
M21
M22 + M23
M24

= 0
⎡
⎣
M12
M23 + M33
M42
⎤
⎦(M22 + M33)j−2 
N21
N22 + N23
N24

= 0 (5.25)
The corresponding expanded system matrix ˜A = V AU + M is then given by
˜A =
⎡
⎢⎢⎣
A11
1
2A21 + M12
1
2A21 −M12
A13
A21 + M21
1
2A22 + M22 1
2A22 + M23
A23 + M24
A21 −M21
1
2A22 −(M22 + M23 + M33)
1
2A22 + M33
A23 −M24
A31
1
2A32 + M42
1
32A21 −M42
A33
⎤
⎥⎥⎦
A similar structure can be written for the expanded control matrix ˜B = V BQ+
N.
Remark 5.2.13 From (5.25), we may identify the following particular cases:
1. When M12 = 0, M23 + M33 = 0 and M42 = 0.
2. When M21 = 0, M22 +M23 = 0, M24 = 0, N21 = 0, N22 +N23 = 0,
and N24 = 0.
From the above remark, the following special case arises:
1. Selecting M22 + M33 = 0, it follows that conditions (5.25) hold for all
j > 2. However, for j = 2, they are
⎡
⎣
M12
M23 + M33
M42
⎤
⎦
M21
M22 + M23
M24

= 0
⎡
⎣
M12
M23 + M33
M42
⎤
⎦
N21
N22 + N23
N24

= 0
(5.26)

5.2. Feedback Control Design
183
2. M23 + M33 = 0 or M22 + M23 = 0; two subcases are obtained:
subcase 1: M23 = −M33. Then, relations (5.26) are
⎡
⎣
M12
0
M42
⎤
⎦
M21
M22
M24

= 0
⎡
⎣
M12
0
M42
⎤
⎦
N21
N22 + N23
N24

= 0
(5.27)
subcase 2: M23 = −M22. Then, relations (5.26) are
⎡
⎣
M12
M22
M42
⎤
⎦
M21
0
M24

= 0
⎡
⎣
M12
M22
M42
⎤
⎦
N21
N22 + N23
N24

= 0
(5.28)
5.2.5
Illustrative example 5.2
The objective is to illustrate the potential advantages of the complementary
matrices for an overlapping decentralized state LQ optimal control design. For
this purpose, we address problem (5.15) for system (5.20) with the following
data:
A
=
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
−2
0
1
...
−2
· · ·
· · ·
· · ·
· · ·
0
...
4
−2
...
−1
0
...
−2
−4
...
0
· · ·
· · ·
· · ·
· · ·
· · ·
1
...
0
0
2
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
,
B
=
⎡
⎢⎢⎢⎢⎢⎢⎢⎣
0
1
...
1
· · ·
· · ·
1
...
0
...
1
1
...
2
...
1
1
...
1
0
⎤
⎥⎥⎥⎥⎥⎥⎥⎦
,
Q∗
=
Blockdiag[1, 1, 1, 1], R∗= Blockdiag[1, 1, 1]
(5.29)

184
Chapter 5. Overlapping Control
The overlapping decomposition is determined by dotted lines and note that
the pair (A, B) is controllable. For the purpose of illustration, the following
procedure is applied:
1. The pair (S, J) is expanded to (˜S, ˜J).
2. A decentralized optimal control is designed for the decoupled expanded
system in the form ˜u = −˜K˜u where ˜K is a block diagonal matrix.
3. The designed control is then contracted to be implemented in the original
system S as u = −Kx, where K = Q ˜KV according to Theorem 5.2.7.
For simplicity, we assume that x0 is a random variable uniformly distributed
over the n-dimensional unit sphere. In this way, the expected value of the per-
formance criterion is ˆJ⊕= trace{H}, where H satisﬁes the Lyapunov equa-
tion (A−BK)tH +H(A−BK)+KtR∗K +Q∗= 0. Four distinct cases will
be treated with M being the design matrix and its suboptimality is analyzed.
The computational results are summarized below:
case 1:
N
= 0. Following [128, 324] in evaluating the overlapping
decomposition by using an Aggregation, we select matrix M as the most com-
monly used in the literature, that is,
M
=
⎡
⎢⎢⎣
0
0
0
0
A21
1
2A22
−1
2A22
−A23
−A21
−1
2A22
1
2A22
A23
0
0
0
0
⎤
⎥⎥⎦
=
⎡
⎢⎢⎢⎢⎢⎢⎣
0
0
0
0
0
0
0
2
−1
−2
1
1
0
−1
−2
1
2
0
0
−2
1
2
−1
−1
0
1
2
−1
−2
0
0
0
0
0
0
0
⎤
⎥⎥⎥⎥⎥⎥⎦
(5.30)

5.2. Feedback Control Design
185
and the corresponding expanded matrix
˜A
=
⎡
⎢⎢⎣
A11
1
2A12
1
2A12
A13
2A21
A22
0
0
0
0
A22
2A23
A31
1
2A32
1
2A32
A33
⎤
⎥⎥⎦
=
⎡
⎢⎢⎢⎢⎢⎢⎣
−2
0
0.5
0
0.5
−2
0
4
−2
0
0
0
0
−2
−4
0
0
0
0
0
0
4
−2
−2
0
0
0
−2
−4
0
1
0
0
0
0
2
⎤
⎥⎥⎥⎥⎥⎥⎦
(5.31)
Simple computation of the suboptimal performance index is ˆJ⊕= 13.63.
case 2:
MQ∗= 0. In this case overlapping decomposition is pursued
by using a restriction. The typical choice of M is
M
=
⎡
⎢⎢⎣
0
1
2A12
−1
2A12
0
0
1
2A22
−1
2A22
0
0
−1
2A22
1
2A22
0
0
−1
2A32
1
2A32
0
⎤
⎥⎥⎦
=
⎡
⎢⎢⎢⎢⎢⎢⎣
0
0
0.5
0
−0.5
0
0
2
−1
−2
1
0
0
−1
−2
1
2
0
0
−2
1
2
−1
0
0
1
2
−1
−2
0
0
0
0
0
0
0
⎤
⎥⎥⎥⎥⎥⎥⎦
(5.32)
and the corresponding expanded matrix
˜A
=
⎡
⎢⎢⎣
A11
A12
0
A13
A21
A22
0
A23
A21
0
A22
A23
A31
0
A32
A33
⎤
⎥⎥⎦
=
⎡
⎢⎢⎢⎢⎢⎢⎣
−2
0
1
0
0
2
0
4
−2
0
0
−1
0
−2
−4
0
0
0
0
0
0
4
−2
−1
0
0
0
−2
−4
0
1
0
0
0
0
2
⎤
⎥⎥⎥⎥⎥⎥⎦
(5.33)

186
Chapter 5. Overlapping Control
This yields the suboptimal performance index as ˆJ⊕= 15.44.
case 3: INR∗
= 0. The overlapping decomposition is implemented by
the procedure of the foregoing sections. To facilitate the procedure, we can
select the complementary submatrices of M as
M12
=
(1/2)A12 = [0, (1/2)], Mt
21 = At
21 = [0, 0],
M24
=
−A23 = [1, 0], M42 = −(1/2)A32 = [0, 0]
If M12M22 = 0 , the relations (5.27) hold. Denote
M22 =
 m22
m23
0
0

which means that we have the degree of freedom to select the values of m22
and m23. To minimize ˆJ⊕with respect to m22 and m23, the standard algorithm
of steepest descent method is used solve the Lyapunov equation. This yields
m22 = −0.22, m23 = −0.82. The complete matrices M and ˜A given by
(5.24) and (5.26), respectively, are the following:
M
=
⎡
⎢⎢⎢⎢⎢⎢⎣
0
0
0.50
0
−0.50
0
0
−0.22
−0.82
−0.22
−0.82
1
0
0
0
0
0
0
0
0.22
0.82
0.22
0.82
−1
0
0
0
0
0
0
0
0
0
0
0
0
⎤
⎥⎥⎥⎥⎥⎥⎦
,
˜A
=
⎡
⎢⎢⎢⎢⎢⎢⎣
−2
0
1
0
0
−2
0
1.78
−1.82
1.78
−1.82
0
0
−1
−2
−1
−2
0
0
2.22
−0.18
2.22
−0.18
−2
0
−1
−2
−1
−2
0
1
0
0
0
0
2
⎤
⎥⎥⎥⎥⎥⎥⎦
(5.34)
The computed suboptimal performance index is ˆJ⊕= 11.02.
case 4:
MQ∗
=
0. By similarity, the overlapping decomposition is
implemented by the procedure of the foregoing sections. In this case, the com-
plementary submatrices M12, M21, M24, and M42 are the same as in case 3.
The submatrix M22 can now be selected in the form
M22 =
 0
m23
0
m33


5.3. LMI-Based Overlapping Control
187
so as to satisfy relations (5.28). In this case, the minimization algorithm gives
m23 = −0.41, m33 = 2.01. In turn, M and ˜A are
M
=
⎡
⎢⎢⎢⎢⎢⎢⎣
0
0
0.50
0
−0.50
0
0
0
−0.41
0
0.41
1
0
0
2.01
0
−2.01
0
0
0
−0.41
0
0.41
−1
0
0
2.01
0
−2.01
0
0
0
0
0
0
0
⎤
⎥⎥⎥⎥⎥⎥⎦
,
˜A
=
⎡
⎢⎢⎢⎢⎢⎢⎣
−2
0
1
0
0
−2
0
2
−1.41
2
−0.59
0
0
−1
0.01
−1
−4.01
0
0
2
−1.41
2
−0.59
−2
0
−1
0.01
−1
−4.01
0
1
0
0
0
0
2
⎤
⎥⎥⎥⎥⎥⎥⎦
(5.35)
The computed suboptimal performance index is ˆJ⊕= 10.48.
It is of interest to note that the centralized optimal control for the initial
system S in (5.15) is given by ˆJ◦= 9.88. The suboptimality measure ranges
from 16.194% to 57.275 %, which is better than those obtained via the usual
aggregations or restrictions [15].
5.3
LMI-Based Overlapping Control
In this section we establish an alternative approach for the design of overlap-
ping control, which avoids the main difﬁculties associated with direct expan-
sion. The new element is to combine system expansion and linear matrix in-
equalities (LMI) in a way that bypasses the ﬁxed mode problem, while placing
only mild restrictions on the Lyapunov function. The material covered in this
section follows the work of [352]. To formally introduce the alternative ap-
proach to overlapping, let us consider a linear system
S :
˙x(t) = Ax(t) + Bu(t)
(5.36)

188
Chapter 5. Overlapping Control
where x ∈ℜn is the state, u ∈ℜm represents the control input, and matrices
A, B have the following structure:
A
=
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
A11
A12
...
0
· · ·
· · ·
...
· · ·
A21
...
A22
...
A23
· · ·
· · ·
· · ·
...
0
...
A32
A33
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
, B =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
B11
...
0
...
· · ·
B21
...
B22
· · ·
...
0
...
B32
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
(5.37)
where the overlapping decomposition is along the dotted lines, which implies
that the state variables associated with A22 are available to both inputs. It is
then natural to consider an overlapping control of the form u(t) = Kx(t)
where
K =
⎡
⎢⎢⎣
K11
K12
...
0
· · ·
· · ·
· · ·
· · ·
· · ·
0
...
K22
K23
⎤
⎥⎥⎦
(5.38)
As we learned from the foregoing sections, overlapping control is not always
related to the matrix structure identiﬁed in (5.37). In some relevant cases it
can arise simply as a result of control information structure constraints, with
no connection to the form of matrix A. To illustrate this point, let us consider
system (5.36) with the input matrix of the form
B =
 B1
0
B2
0

(5.39)
We consider further that x1 and x2 are the components of x1 that are available
to inputs u1 and u2, and that x1 and x2 share a certain subset of state variables.
It can be easily veriﬁed that such a system can always be permuted so that the
new matrix B has the overlapping structure introduced in (5.37).
Remark 5.3.1 At this stage, it is signiﬁcant to distinguish between overlap-
ping control laws that are induced by the structure of matrix A, and those that
are dictated by the availability of state information for control design. This dis-
tinction is essentially physical, and has no direct bearing on the mathematical
treatment of the problem. From the standpoint of design, a more meaningful
classiﬁcation of overlapping control laws would be one that is based on the
structure of matrix A.

5.3. LMI-Based Overlapping Control
189
We recall from the inclusion principle and the overlapping decomposition that
system (5.36) in included in the
(S :
˙(x(t) = (A(x(t) + (Bu(t)
(5.40)
such that
V A
=
(A V, V B = (B
V
=
⎡
⎢⎢⎣
I1
0
0
0
I2
0
0
I2
0
0
0
I3
⎤
⎥⎥⎦
(5.41)
where I1, I2, and I3 represent identity matrices with dimensions correspond-
ing to A11, A22, and A33, respectively.
Now consider that the expanded system (S can be stabilized with a decen-
tralized control u = (Kd(x, where
(Kd =
)
(K11
(K12
0
0
0
0
(K23
(K24
*
(5.42)
It follows that the original system S is stabilized by u = Kx, where
K = (Kd V =
)
(K11
(K12
0
0
(K23
(K24
*
(5.43)
represents an overlapping control law.
Remark 5.3.2 It is easy to realize that the problem of designing overlapping
control can thus be formulated as a decentralized control problem in the ex-
panded space. One of the main difﬁculties that arise in this context results from
the fact that the pair ( (A, (B) is inherently uncontrollable. It can be shown that
the eigenvalues of (A22 represent ﬁxed modes of the expansion (S, so this method
is not directly applicable to cases when matrix (A22 is unstable [324].
5.3.1
Design procedure
In the sequel, we show that LMI provides a natural framework for the design of
overlapping control. To see this, let us assume that there exists a gain matrix K
that conforms to the structural constraint (5.38) such that the resulting closed-
loop system
SK :
˙x(t) = (A + BK)x(t)
(5.44)

190
Chapter 5. Overlapping Control
is guaranteed to be stable. By Lyapunov stability, it follows that there exists a
matrix 0 < Pt = P such that
AtP + PA + PBK + KtBtP < 0
(5.45)
with xtPx being the corresponding Lyapunov function. It is important to rec-
ognize that although (5.45) is actually a nonlinear matrix inequality in P and
K, it can be convexiﬁed by introducing matrices Y = P−1 and L = KY.
Based thereon, we reformulate (5.45) as an LMI problem in Y and L:
Compute matrices Y and L such that
Y > 0,
YAt + AY + BL + LtBt < 0
(5.46)
Then, determine the gain matrix as K = LY−1.
To ensure that the gain matrix K has the desired overlapping structure
(5.38), it is necessary to look for matrices Y and L in the form
L =
 L11
L12
0
0
L22
L23

, Y =
⎡
⎣
Y11
0
0
0
Y22
0
0
0
Y33
⎤
⎦
(5.47)
since evidently this ensures that
K =
 L11Y−1
11
L12Y−1
22
0
0
L22Y−1
22
L23Y−1
33

(5.48)
The LMI design strategy is now illustrated by the following example.
5.3.2
Illustrative example 5.3
Consider the system of the type (5.36) with
A
=
⎡
⎢⎢⎢⎢⎢⎢⎢⎣
1
4
...
0
· · ·
· · ·
· · ·
· · ·
1
...
2
...
2
· · ·
· · ·
· · ·
· · ·
0
...
−2
3
⎤
⎥⎥⎥⎥⎥⎥⎥⎦
, B =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
1
...
0
...
· · ·
1
...
0
· · ·
...
0
...
1
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦

5.4. Application to Unmanned Aerial Vehicles
191
The overlapping decomposition is determined by dotted lines and note that the
open-loop system is unstable with eigenvalues {−0.166, 3.08 ± j1.59}. Our
objective will be to stabilize it using overlapping control. Using
V =
⎡
⎢⎢⎣
1
0
0
0
1
0
0
1
0
0
0
1
⎤
⎥⎥⎦
we get the expanded system (S as
(A
=
⎡
⎢⎢⎢⎢⎢⎢⎢⎣
1
4
...
0
0
1
2
...
0
2
· · ·
· · ·
· · ·
· · ·
· · ·
1
0
...
2
2
0
0
...
−2
3
⎤
⎥⎥⎥⎥⎥⎥⎥⎦
, (B =
⎡
⎢⎢⎢⎢⎢⎢⎢⎣
1
...
0
1
...
0
· · ·
· · ·
· · ·
1
...
0
0...
1
⎤
⎥⎥⎥⎥⎥⎥⎥⎦
which has an unstable ﬁxed mode A22 = 2, so direct decentralized control
design in the expanded space would fail. However, the LMI optimization (5.46)
easily resolves this problem, yielding
K =
⎡
⎣−1.2900
−0.9344
...
0
0
...
0.4819
−1.7227
⎤
⎦
and the corresponding closed-loop state trajectories are displayed in Figure 5.1.
5.4
Application to Unmanned Aerial Vehicles
In what follows, decentralized overlapping feedback laws are designed for a
formation of unmanned aerial vehicles [350, 352]. The dynamic model of the
formation with an information structure constraint in which each vehicle, ex-
cept the leader, only detects the vehicle directly in front of it, is treated as an
interconnected system with overlapping subsystems. Using the mathematical
framework of the inclusion principle, the interconnected system is expanded
into a higher dimensional space in which the subsystems appear to be disjoint.
Then, at each subsystem, a static-state feedback controller is designed to ro-
bustly stabilize the perturbed nominal dynamics of the subsystem.

192
Chapter 5. Overlapping Control
0
200
400
600
800
1000
1200
−2
−1.5
−1
−0.5
0
0.5
1
1.5
2
States Trajectories, using Ac
 
 
x1
x2
x3
Figure 5.1: Closed-loop state trajectories
Let us start with the following planar kinematic model for a single vehicle:
˙X
=
v cos ψ,
˙Y
=
v sin ψ,
˙ψ
=
ω
(5.49)
where X and Y denote rectangular coordinates, and ψ is the heading angle
in the (X, Y ) plane. The speed in the longitudinal direction (in body axes)
υ and angular turn rate ω are assumed to be the control inputs. It can easily
be shown that the decoupling matrix of the input-state feedback linearization
for the kinematic model (5.49) is singular. In order to deal with this problem,
dynamic extension [308] is employed by considering speed v as a new state
variable, and acceleration a as a new input variable. Now, the state and input
variables are deﬁned as
ζ =
⎡
⎢⎢⎣
ζ1
ζ2
ζ3
ζ4
⎤
⎥⎥⎦=
⎡
⎢⎢⎣
X
Y
ψ
υ
⎤
⎥⎥⎦, η =
 η1
η2

=
 a
ω

(5.50)
Using (5.50) the kinematic model (5.49) can be rewritten as follows:
˙ζ
=
∫(ζ) g(ζ)η,
∫(ζ)
=
⎡
⎢⎢⎣
ζ4 cos(ζ3)
ζ4 sin(ζ3)
0
0
⎤
⎥⎥⎦, g(ζ) =
⎡
⎢⎢⎣
0
0
0
0
0
1
1
0
⎤
⎥⎥⎦
(5.51)

5.4. Application to Unmanned Aerial Vehicles
193
At this point to facilitate feedback linearization, a change of state variables is
introduced as
z = T(ζ) −→
⎡
⎢⎢⎣
z1
z2
z3
z4
⎤
⎥⎥⎦=
⎡
⎢⎢⎣
ζ1
ζ2
ζ4 cos(ζ3)
ζ4 sin(ζ3)
⎤
⎥⎥⎦
(5.52)
and change of input variables, to deﬁne the new input u ∈ℜ2, η = M(ζ)u
such that
M(ζ) =

cos(ζ3)
sin(ζ3)
−sin(ζ3)/ζ4
cos(ζ3)/ζ4

(5.53)
It is not difﬁcult to show that the transformations of (5.52) and (5.53) imply the
following exact linearization of the nonlinear model (5.51)
˙z
=
∂T
∂ζ ζ ⇒
˙z
=
⎡
⎢⎢⎣
0
0
1
0
0
0
0
1
0
0
0
0
0
0
0
0
⎤
⎥⎥⎦z +
⎡
⎢⎢⎣
0
0
0
0
1
0
0
1
⎤
⎥⎥⎦z
=
E z + F z
(5.54)
˙z
=
 0
I2
0
0

z +
 0
I2

z
(5.55)
with z ∈ℜ4 and u ∈ℜ2 being the state and input to the system. Our goal
now is to develop a dynamic model for a leader-follower type of formation of
vehicles. Let us introduce the following decomposition for the state variables
of the jth vehicle in the formation of q vehicles,
zj
=
 zA
j
zB
j

∈ℜ4, zA
j =
 zj1
zj2

∈ℜ2, zB
j =
 zj3
zj4

∈ℜ2 (5.56)
We note that
zA
j
 Xj
Yj

, zB
j =
 υj cos ψj
υj sin ψj

, j ∈{1, ..., q}
(5.57)
We observe that zj is split conveniently into two subvectors, where zA
j includes
position coordinates and zB
j includes speed coordinates of the jth vehicle. The

194
Chapter 5. Overlapping Control
beneﬁt gained by this decomposition is to help in controlling the vehicles in
a formation by controlling variables that represent distances between vehicles
(not positions of the vehicles), and variables that represent speed coordinates
for each independent vehicle. The control input for the jth vehicle as deﬁned
by (5.53) will be denoted as uj ∈ℜ2.
In the sequel, we consider a platoon of r vehicles and introduce the change
of variables eB
1 = zB
1 −vd1
for the leading vehicle and
eA
j = zA
j−1 −zA
j −dj−1
eB
j = zB
j −vdj
j ∈{2, ..., r}
(5.58)
where dj−1 ∈ℜ2 is a constant desired Euclidean distance between the (j−1)st
and jth vehicles, j ∈{2, ..., r}, and vdj ∈ℜ2 represents the desired speed for
the jth vehicle, j ∈{1, ..., r}. We note that for controlling distances between
vehicles, position of the leading vehicle, that is, z1
A, is not needed. Since the
desired Euclidean distances between vehicles are assumed to be constant, the
following assumption is necessary:
vdj = vd,
j ∈{1, ..., r}
(5.59)
This means in order to achieve constant desired spacing in the formation, the
desired speed for each vehicle must be the same. Then eB
1 = u1 for the leading
vehicle and
eA
j = eB
j−1 −eB
j
eB
j = uj
j ∈{2, ..., r}
(5.60)
Notice that the goal is for the whole platoon, that is, formation, to ﬂy at constant
desired speed vd with desired spacing between vehicles, uniquely determined
by desired Euclidean distances between successive vehicles equal to dj, j ∈
1, ..., r −1, which is accomplished if the system described by (5.60) is stable
with respect to its zero equilibrium.
Due to symmetry, the procedure does not depend on the size of the platoon
and therefore we take r = 3 and rewrite (5.60) in the compact form:
⎡
⎢⎢⎢⎢⎣
˙eB
1
˙eA
2
˙eB
2
˙eA
3
˙eB
3
⎤
⎥⎥⎥⎥⎦
=
⎡
⎢⎢⎢⎢⎣
0
0
0
0
0
I
0
−I
0
0
0
0
0
0
0
0
0
I
0
−I
0
0
0
0
0
⎤
⎥⎥⎥⎥⎦
⎡
⎢⎢⎢⎢⎣
eII
1
eI
2
eII
2
eI
3
eII
3
⎤
⎥⎥⎥⎥⎦
+
⎡
⎢⎢⎢⎢⎣
I
0
0
0
0
0
0
I
0
0
0
0
0
0
I
⎤
⎥⎥⎥⎥⎦
⎡
⎣
u1
u2
u3
⎤
⎦
˙e
=
Ae + Bu
(5.61)

5.4. Application to Unmanned Aerial Vehicles
195
It is important to observe that system (5.60) or (5.61) can be viewed as an
interconnected system with subsystems having state variables deﬁned
e1 = eB
1 , ej =
 eA
j
eB
j

∀j ∈{1, ..., r}
(5.62)
Applying the inclusion principle, it turns out that the expansion/contraction
matrices for the state are given as
V
=
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
I
0
0
0
0
I
0
0
0
0
0
I
0
0
0
0
0
I
0
0
0
0
I
0
0
0
0
0
I
0
0
0
0
0
I
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
, U =
⎡
⎢⎢⎢⎢⎣
1
2I
1
2I
0
0
0
0
0
0
0
I
0
0
0
0
0
0
0
1
2I
1
2I
0
0
0
0
0
0
0
I
0
0
0
0
0
0
0
I
⎤
⎥⎥⎥⎥⎦
R
=
⎡
⎢⎢⎢⎢⎣
I
0
0
I
0
0
0
I
0
0
I
0
0
0
I
⎤
⎥⎥⎥⎥⎦
, Q =
⎡
⎣
1
2I
1
2I
0
0
0
0
0
1
2I
1
2I
0
0
0
0
0
I
⎤
⎦
and the stabilizing feedback gain matrix has the structure in the original space
˜KM =
⎡
⎣
˜K1
0
0
0
0
˜K2
˜K3
˜K1
0
0
0
0
˜K2
˜K3
˜K1
⎤
⎦
(5.63)
Let us again consider the group of ﬁve vehicles ﬂying in formation as depicted
in Figure 5.2. Assume that the nominal speed vd 5.59 is [300, 0][ft/s], desired
distances between vehicles (in absolute values) are all equal to |dj−1| ≡d =
[400, 400]t[ft] for both platoons and all j in (5.58), and consider external per-
turbations to be of sinusoidal functions with magnitudes equal to 10.
The design procedure is now applied to compute decentralized overlapping
static feedback controllers. It was reported in [352] that typical simulation re-
sults for two different sets of initial conditions using superimposed snapshots
of the formation at representative time instances, which are 40 nonuniform
(depending on the nonuniform step size used in simulations) time intervals be-
tween 0−1.3[s], are reproduced in Figures 5.3 and 5.4. Position coordinates are
given in feet. Horizontal distances between vehicles V1 and V2, and V2 and V3,
corresponding to Figure 5.2, for the set of initial conditions for the simulation
presented in Figure 5.3, are given in Figures 5.5a and 5.5b, respectively. Time
is in seconds and distances are in feet.

196
Chapter 5. Overlapping Control
Figure 5.2: Leader-follower type formation with ﬁve vehicles and two platoons.
Figure 5.3: One possible formation of unmanned aerial vehicles

5.4. Application to Unmanned Aerial Vehicles
197
Figure 5.4: Another possible formation of unmanned aerial vehicles
Figure 5.5: Horizontal distances between: (a) vehicles V1 and V2; (b) vehicles
V2 and V3

198
Chapter 5. Overlapping Control
5.5
Problem Set III
Problem III.1: Consider a mathematical model of a string of ﬁve high-speed
moving vehicles [183]. The motion of each vehicle in the string is represented
by two states: position and velocity. Under normal operating conditions, the
dynamical model of the string can be written in terms of the deviations from a
desired separation distance between adjacent vehicles and the deviations from
a desired nominal string velocity. In view of this, the equilibrium state and
control values are zero. The system matrices have the form:
A =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
−1
0
0...
1
0
−1...
0
0
0
0
0
0
· · ·
· · ·
· · ·
0
0
... −1...
0
0...
· · ·
· · ·
· · ·
...1
0
−1...
· · ·
· · ·
· · ·
...0
0
... −1...
0
0...
· · ·
· · ·
· · ·
...1
0
−1...
· · ·
· · ·
· · ·
0
0
... −1...
0
0
...1
0
−1
...0
0
−1
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
,

5.5. Problem Set III
199
B =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
1
0...
0
0...
0
0
· · ·
0
1...
0...
· · ·
· · ·
...
0...
· · ·
...
1...
0...
...
0...
· · ·
...
1...
0
· · ·
...
0
...
1
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
where the overlapping subsystems are identiﬁed as substrings of two adjacent
vehicles. Choose appropriate transformation matrices to generate the expanded
system. Using suitable weighting matrices, compute the suboptimal control.
Problem III.2: Consider the interconnected system
˙x(t) = Ax(t) + Bu(t),
y = Cx
where system matrices have the values
A
=
⎡
⎢⎢⎢⎢⎢⎢⎢⎣
1
3
...
0
· · ·
· · ·
· · ·
· · ·
0
...
−1
...
0
· · ·
· · ·
· · ·
· · ·
0
...
3
1
⎤
⎥⎥⎥⎥⎥⎥⎥⎦
, B =
⎡
⎢⎢⎢⎢⎢⎣
1
0
...
0
0
...
1
...
0
· · ·
· · ·
· · ·
· · ·
0
...
0
1
⎤
⎥⎥⎥⎥⎥⎦
,
C
=
⎡
⎢⎢⎢⎢⎢⎢⎢⎣
1
0
...
0
· · ·
· · ·
· · ·
· · ·
0
...
1
...
0
· · ·
· · ·
· · ·
· · ·
0
...
0
1
⎤
⎥⎥⎥⎥⎥⎥⎥⎦

200
Chapter 5. Overlapping Control
where the dotted lines separate the overlapping subsystems. Design a decentral-
ized overlapping controller to stabilize the system and to minimize a quadratic
cost with weighting matrices Q = [1 0.5 1] and R = [1 2 1]. Examine the
cases of state and static output feedback cases.
Problem III.3: Consider the interconnected system
˙x(t) = Ax(t) + Bu(t),
y = Cx
where system matrices have the values
A
=
⎡
⎢⎢⎢⎢⎢⎢⎢⎣
1
4
...
0
· · ·
· · ·
· · ·
· · ·
1
...
2
...
2
· · ·
· · ·
· · ·
· · ·
0
...
−2
3
⎤
⎥⎥⎥⎥⎥⎥⎥⎦
, B =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
1
...
0
...
· · ·
0
...
0
· · ·
...
0
...
1
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
where the dotted lines separate the overlapping subsystems. Design a decen-
tralized overlapping controller to stabilize the system.
Problem III.4: Consider the following two linear systems
S
:
˙x(t) = Ax(t) + Bu(t), x(0) = xo,
y
=
Cx,
˜S
:
˙˜x(t) = ˜A˜x(t) + ˜B˜u(t), ˜x(0) = ˜xo,
˜y
=
˜C˜x
where x ∈ℜn, u ∈ℜm, y ∈ℜp, ˜x ∈ℜ˜n, ˜u ∈ℜ˜m, ˜y ∈ℜ˜p are the
state, input, and output vectors for systems S and ˜S, respectively. Consider the
transformations
T
:
ℜn −→ℜ˜n, rank(T) = n,
U
:
ℜ˜m −→ℜm, rank(U) = m,
T†
:
ℜ˜n −→ℜn, T†T = In,
U†
:
ℜm −→ℜ˜m, rank(U) = m
such that ˜xo = Txo, u = U˜u. Based thereon, establish that
TA = ˜AT, TBU = ˜B

5.6. Notes and References
201
In this case, system ˜S is called an extension of system S. Proceed to deduce the
following relations:
˜A = TAT† + E,
˜B = TBU + F
and derive the conditions on the complementary matrices E and F.
5.6
Notes and References
In this chapter, the main concern has been on the decomposition and control of
interconnected systems through coupled subystems. The main approach ad-
dressed has been the overlapping decomposition (OLD) and the associated
overlapping control (OLC). Different types of input-decentralized or output-
decentralized subsystems have been proposed by [128]. Overlapping decom-
position has been treated by [124]-[131] where emphasis has been placed on
theoretical foundations of expansion and contraction relations. An extension of
the inclusion principle to nonlinear systems was given by [286] and general-
izing this approach for overlapping inputs and outputs was reported in [120].
The notion of a nonclassical information pattern has been discussed in connec-
tion with decentralized design in [185] and application of OLD to the power-
frequency behavior of multiarea power systems was illustrated in [192].
A systematic extension to the class of complementary matrices to obtain
a more ﬂexible selection strategy has been developed in [12] where the intro-
duction of appropriate changes of the basis in the expansion contraction pro-
cess has been formalized. Overlapping decomposition and overlapping feed-
back control techniques have been developed in [19] for a cable-stayed bridge
benchmark, in [350] for a platoon of vehicles, and in [352] for a formation of
unmanned aerial vehicles.
Despite the major developments in deploying the concepts of the overlap-
ping and inclusion principle, the issue of computational load and associated
processing requirements has been addressed in comparison with other decen-
tralized control approaches. It is hoped that this issue will attract the attention
of control researchers.

Chapter 6
Interconnected Time-Delay
Systems
In this chapter, we start our examination of the development of decentral-
ized control for a class of interconnected continuous-time and discrete-time
systems. The subsystems are time-delay plants subjected to convex-bounded
parametric uncertainties and the interconnections are time-delay couplings.
The major departure from the previous chapter lies in the analysis of delay-
dependent stability criteria and the synthesis of delay-dependent feedback sta-
bilization methods.
6.1
Introduction
In the sequel, we study the stability, robust stability, and feedback stabilization
problems of a class of interconnected systems. We start with linear continuous-
time systems and then generalize the results to a class of nonlinear systems.
Moreover, we extend the results to discrete-time systems. In all cases under
consideration, the local subsystem has convex-bounded parametric uncertain-
ties and time-varying delays within the local subsystems and across the inter-
connections. On one hand, linear time-delay systems represent a wide class of
inﬁnite-dimensional systems and are frequently encountered to describe prop-
agation, transport phenomena, and population dynamics in various engineering
and physical applications [255]. On the other hand, large-scale interconnected
systems appear in a variety of engineering applications including power sys-
tems, large structures, and manufacturing systems and for those applications,
decentralized control schemes present a practical and effective means for de-
signing control algorithms based on the individual subsystems [324]. Relevant
203

204
Chapter 6. Interconnected Time-Delay Systems
research results on decentralized control of relevance to the present work can
be found in [173, 288, 328].
Stability analysis and control design criteria for state-delay systems, on the
other hand, can be broadly classiﬁed into two categories: delay-independent,
which are applicable to delays of arbitrary size [255], and delay-dependent,
which include information on the size of the delay; see [74]. Improved meth-
ods pertaining to the problems of determining robust stability criteria of uncer-
tain time-delay systems have been recently reported [103] and the references
cited therein. To reduce the level of design conservatism when dealing with
time-varying delays, one has to select appropriate Lyapunov-Krasovskii func-
tional (LKF) with moderate number of terms, avoid bounding methods, and
use parametrized relations and variables effectively to avoid redundancy. It ap-
pears from the existing results that general results pertaining to interconnected
time-delay systems are few and restricted (see [174, 246, 253, 251, 252, 287]),
where most of the efforts were centered on matching conditions and were vir-
tually delay-independent.
6.2
Linear Interconnected Systems: Continuous-Time
We consider a class of linear systems S structurally composed of ns coupled
subsystems Sj and modeled by the state-space model:
˙xj(t)
=
Ajxj(t) + Adjxj(t −τj(t)) + Bjuj(t)
+
ns

k=1,k̸=j
Ejkxk(t −ηjk(t)) + Γjwj(t)
zj(t)
=
Gjx(t) + Gdjx(t −τj(t)) + Dju(t) + Φjwj(t)
(6.1)
where for j ∈{1, ..., ns}, xj(t)
∈ℜnj is the state vector; uj(t)
∈ℜmj
is the control input, wj(t)
∈ℜqj is the disturbance input which belongs
to L2[0, ∞),
zj(t)
∈ℜqj
is the controlled output, and τj, ηjk, j, k ∈
{1, ..., ns} are unknown time-delay factors satisfying
0
≤
τj(t) ≤ϱj,
˙τj(t) ≤μj,
0
≤
ηjk(t) ≤ϱjk,
˙ηjk(t) ≤μjk
(6.2)
where the bounds ϱj, ϱjk, μj, μjk are known constants in order to guaran-
tee smooth growth of the state trajectories. The matrices Aj ∈ℜnj×nj, Bj ∈
ℜnj×mj, Gj ∈ℜqj×nj, Dj ∈ℜqj×mj, Adj ∈ℜnj×nj, Φj ∈ℜqj×qj, Γj ∈
ℜnj×qj, Cj ∈ℜpj×nj, Cdj ∈ℜpj×nj, Fj ∈ℜpj×mj, Ψj ∈ℜpj×qj
are

6.2. Linear Interconnected Systems: Continuous-Time
205
real and uncertain. The initial condition ⟨xj(0), xj(r)⟩= ⟨xoj, φj⟩, j ∈
{1, ..., ns} where φj(.) ∈L2[−τ ∗
j , 0], j ∈{1, ..., ns}. The inclusion of the
term Adjxj(t −τj(t)) is meant to emphasize the delay within the local subsys-
tem.
The class of systems described by (6.1) subject to delay pattern (6.2) is fre-
quently encountered in modeling several physical systems and engineering ap-
plications including large space structures, multimachine power systems, cold
mills, transportation systems, and water pollution management, to name a few
[252, 253, 324].
For the purpose of conducting stability analysis, we employ the Lyapunov-
Krasovskii theory [93] and consider the LKF:
V (t)
=
ns

j=1
Vj(t)
Vj(t)
=

Voj(t) + Vaj(t) + Vmj(t)) + Vnj(t)
	
Voj(t)
=
xt
j(t)Pjxj(t),
Vaj(t)
=
 0
−ϱj
 t
t+s
˙xt
j(α)Wj ˙xj(α)dα ds,
Vmj(t)
=
 t
t−τj(t)
xt
j(s)Qjxj(s) ds,
Vnj(t)
=
ns

k=1,k̸=j
 t
t−ηjk(t)
xt
k(s)Zjkxk(s) ds
(6.3)
where 0 < Pj = Pt
j, 0 < Waj = Wt
aj, 0 < Wcj = Wt
aj, 0 < Qj =
Qt
j, 0 < Rj = Rt
j, 0 < Zjk = Zt
jk, j, k ∈{1, ..., ns} are weighting
matrices of appropriate dimensions.
Remark 6.2.1 The ﬁrst term in (6.3) is standard to nominal systems without
delay while the second and third terms correspond to the delay-dependent con-
ditions since they provide measures of the individual and difference signal en-
ergies during the delay period (recall that
 t
t−ϱj ˙xj(α)dα = xj(t)−xj(t−ϱj)
by Leibniz-Newton formula) and the fourth term corresponds to the intracon-
nection delays. LKF composed of the ﬁrst three terms has been considered in
[74, 103, 261, 290] for single time-delay systems. Unlike the results on inter-
connected systems [251, 283, 287, 288, 328, 371], LKF (6.3) represents a new
effective form and therefore the advantages and reduced conservatism afforded
in [74, 103, 261, 290] are carried over hereafter.

206
Chapter 6. Interconnected Time-Delay Systems
6.2.1
Local delay-dependent analysis
In this section, we develop new criteria for linear matrix inequality (LMI)-
based characterization of delay-dependent asymptotic stability and L2 gain
analysis. The criteria included some parameter matrices aim at expanding the
range of applicability of the developed conditions. The following theorem es-
tablishes the main result subsystem Sj.
Theorem 6.2.2 Given ϱj > 0, μj > 0, ϱjk > 0, and μjk > 0, j, k =
1, ..., ns. The family of subsystems {Sj} with uj(.) ≡0 where Sj is described
by (6.1) is delay-dependent asymptotically stable with L2-performance bound
γj, j = 1, ..., ns if there exist weighting matrices Pj, Qj, Wj, Zkj, k =
1, ..ns, parameter matrices Θj Υj, and a scalar γj > 0, j = 1, ..., ns satisfy-
ing the following LMI:
Ξϱj
=
 Ξϱj1
Ξϱj2
•
Ξϱj3

< 0
(6.4)
Ξϱj1
=
⎡
⎢⎢⎣
Ξoj
Ξaj
−ϱjΘj
0
•
−Ξmj
−ϱjΥj
0
•
•
−ϱjWj
0
•
•
•
−Ξnj
⎤
⎥⎥⎦
Ξϱj2
=
⎡
⎢⎢⎣
PjΓj
Gt
j
ϱkAt
jWk
0
Gt
dj
ϱkAt
djWk
0
0
0
0
0
ϱk
ns
k=1,k̸=j EjkWk
⎤
⎥⎥⎦
Ξϱj3
=
⎡
⎣
−γ2
j I
Φt
j
ϱkΓt
jWk
•
−I
0
•
•
−ϱkWk
⎤
⎦
(6.5)
where
Ξoj
=
PjAj + At
jPt
j + Θj + Θt
j + Qj +
ns

k=1
Zkj + (ns −1)Pj,
Ξaj
=
PjAdj −Θj + Υt
j,
Ξmj
=
Υj + Υt
j + (1 −μj)Qj,
Ξnj
=
ns

k=1
(1 −μkj)Zkj +
ns

k=1,k̸=j
Et
kjPkEkj
(6.6)

6.2. Linear Interconnected Systems: Continuous-Time
207
Proof: It is readily seen from (6.5) using the delay bounds of (6.2) that there
exists a scalar σj > 0 such that
 ˜Ξϱj1
Ξϱj2
•
Ξϱj3

< 0
(6.7)
with
˜Ξϱj1 =
⎡
⎢⎢⎣
Ξoj + σjI
Ξaj
−Θj
0
•
−Ξmj
−Υj
0
•
•
−ϱ−1
j Wj
0
•
•
•
−Ξnj
⎤
⎥⎥⎦
(6.8)
Therefore, for all τj satisfying (6.2) we have
Ξσj
=
 Ξσj1
Ξϱj2
•
Ξϱj3

< 0
(6.9)
Ξσj1
=
⎡
⎢⎢⎣
Ξoj
Ξaj
−τjΘj
0
•
−Ξmj
−τjΥj
0
•
•
−τjWj
0
•
•
•
−Ξnj
⎤
⎥⎥⎦
(6.10)
Now to examine the internal stability, we need to compute the time-derivative
of V (t) along the solutions of (6.1) with w(t) ≡0. In terms of (6.3), we do this
job componentwise as follows:
˙Voj(t)
=
2xt
jPj ˙xj = 2xt
jPj[Ajxj(t) + Adjxj(t −τj(t))]
+
2xt
jPj
ns

k=1
Ejkxk(t −ηjk(t))
(6.11)
Little algebra on (6.11) yields
˙Voj(t)
=
2xt
jP[Aj + Adj]xj(t) −2xt
jPjAdj
 t
t−τj(t)
˙xj(s)ds
+
2xt
jPj
ns

k=1
Ejkxk(t −ηjk(t))
(6.12)

208
Chapter 6. Interconnected Time-Delay Systems
Expanding terms in (6.12) gives
˙Voj(t)
=
2xt
jPj[Aj + Adj]xj(t)
+
2xt
j[Θj −PjAdj]
 t
t−τj(t)
˙xj(s)ds
+
2xt(t −τj(t))Υj
 t
t−τj(t)
˙xj(s)ds −

2xt
jtΘj
 t
t−τj
˙xj(s)ds
+
2xt(t −τj(t))Υj
 t
t−τj(t)
˙xj(s)ds

+
2xt
jPj
ns

k=1
Ejkxk(t −ηjk(t))
(6.13)
Further manipulation of (6.13) yields
˙Voj(t)
=
1
τj(t)
 t
t−τj(t)
)
2xt
j[PjAj + Θj]xj
+
2xt
j[PjAdj −Θj + Υt
j]xj(t −τj(t))
−
2xt
j(t −τj(t))Υx(t −τj) −2xtτjΘ ˙xj(s)
−
2xt
j(t −τj(t))τj(t)Υj ˙xj(s)
+
2xt
jPj
ns

k=1,k̸=j
Ejkxk(t −ηjk(t))
*
ds
(6.14)
where Θj ∈ℜnj×nj and Υj ∈ℜnj×nj are appropriate relaxation matrices
injected to facilitate the delay-dependence analysis. Next we have
˙Vaj(t)
=
 0
−ϱj
[ ˙xt
j(t)Wj ˙xj(t) −˙xt
j(t + s)Wj ˙xj(t + s)]ds
=
 t
t−ϱj
[ ˙xt
j(t)Wj ˙xj(t) −˙xt
j(s)Wj ˙xj(s)]d s
=
ϱj ˙xt
j(t)Wj ˙xj(t) −
 t
t−τj
˙xt
j(s)Wj ˙xj(s)ds
−
 t−τj
t−ϱj
˙xt
j(s)Wj ˙xj(s)
(6.15)

6.2. Linear Interconnected Systems: Continuous-Time
209
Further manipulation of (6.15) yields
˙Vaj(t)
≤
ϱj ˙xt
j(t)Wj ˙xj(t) −
 t
t−τj
˙xt
j(s)Wj ˙xj(s)ds
=
1
τj(t)
 t
t−τj(t)

ϱj ˙xt
j(t)Wj ˙xj(t)
−
τj ˙xt
j(s)Wj ˙xj(s)

ds
(6.16)
Note that the term Tj =
 t−τj
t−ϱj ˙xt
j(s)Wj ˙xj(s) accounts for the enlarged time
interval from t −ϱj →t to t −τj →t. It is obvious that Tj > 0 and hence
expression (6.16) holds true without conservatism. There has been an alterna-
tive route to handle Tj by employing extra parameter matrices and adding more
identities [103]-[146]. Proceeding further, we get
˙Vmj(t)
=
xt
j(t)Qjxj(t)
−
(1 −˙τj(t)) xt(t −τj(t))Qjxj(t −τj(t))
≤
xt
j(t)Qjxj(t)
−
(1 −μj) xt
j(t −τj(t))Qjxj(t −τj(t))
(6.17)
Little algebra on (6.17) yields
˙Vmj(t)
=
1
τj(t)
 t
t−τj(t)

xt
j(t)Qjxj(t)
−
(1 −μj) xt
j(t −τj(t))Qjxj(t −τj(t))

ds
(6.18)
Also, we have
˙Vnj(t)
=
ns

k=1,k̸=j

xt
k(t)Zjkxk(t)
−
(1 −˙ηjk(t))xt
k(t −ηjk(t))Zjkxk(t −ηjk(t))

≤
ns

k=1,k̸=j

xt
k(t)Zjkxk(t)
−
(1 −μjk) xt
k(t −ηjk(t))Zjkxk(t −ηjk(t))

(6.19)

210
Chapter 6. Interconnected Time-Delay Systems
For the class of interconnected systems (6.1), the following structural identity
holds:
ns

j=1
ns

k=1,k̸=j
xt
k(t)Zjkxk(t) =
ns

j=1
ns

k=1,k̸=j
xt
j(t)Zkjxj(t)
(6.20)
Observe that the result of applying Inequality 3 of the Appendix, we have
2xt
jPj
ns

k=1,k̸=j
Ejkxk(t −ηjk(t)) =
ns

k=1,k̸=j
2xt
jPjEjkxk(t −ηjk(t)) =
ns

k=1,k̸=j
2[Pjxj]t[Ejkxk(t −ηjk(t))] ≤
ns

k=1,k̸=j
[Pjxj]tP−1
j
[Pjxj] +
ns

k=1,k̸=j
[Ejkxk(t −ηjk(t))]tPj[Ejkxk(t −ηjk(t))] =
(ns −1)xt
jPjxj +
ns

k=1,k̸=j
xk(t −ηjk(t))Et
jkPjEjkxk(t −ηjk(t))
(6.21)
which when incorporated with (6.19) yields
ns

j=1
ns

k=1,k̸=j
xk(t −ηjk(t))Et
jkPjEjkxk(t −ηjk(t)) =
ns

j=1
xt
j(t −ηkj(t))[
ns

k=1,k̸=j
Et
jkPjEjkxk(t −ηkj(t))]
(6.22)
In addition, the following equality holds:
ns

j=1
{(
ns

k=1,k̸=j
Ejkxk(t −ηjk(t)))tϱjWj(
ns

k=1,k̸=j
Ejkxk(t −ηjk(t)))} =
ns

j=1
{xt
j(t −ηkj(t))(
ns

k=1,k̸=j
Ejk)tϱkWk(
ns

k=1,k̸=j
Ejk)xj(t −ηkj(t))}
(6.23)

6.2. Linear Interconnected Systems: Continuous-Time
211
By combining (6.3)-(6.22) and using (6.23) with Schur complements, we have
˙Vj(t)|(6.1) ≤
ns

j=1
 1
τj
 t
t−τj
χt
j(t, s) Ξj χj(t, s) ds

(6.24)
χj(t, s) =

xt
j(t) xt
j(t −τj) ˙xt
j(s) xt
j(t −ηkj)
t
(6.25)
where ˙Vj(t)|(6.1) deﬁnes the Lyapunov derivative along the solutions of system
(6.1). Note that Ξj corresponds to Ξσj in with Gj ≡0, Gdj ≡0, Φj ≡0. In
view of (6.10), it follows that Ξj < 0 and more importantly
˙Vj(t)|(6.1) <
ns

j=1

1
τj(t)
 t
t−τj
χt
j(t, s)diag[−σj, 0, 0, 0, 0, 0]χ(t, s)j ds

=
−
ns

j=1
σj ||xj||2 < 0
(6.26)
This establishes the internal asymptotic stability.
Now consider the performance measure
J =
ns

j=1
 ∞
0

zt
j(s)zj(s) −γ2
j wt
j(s)wj(s)

ds
For any wj(t) ∈L2(0, ∞) ̸= 0 and zero initial condition xj(0) = 0, we have
J
=
ns

j=1
 ∞
0

zt
j(s)zj(s) −γ2
j wt
j(s)wj(s) + ˙Vj(t)|(6.1)
−
˙Vj(t)|(6.1)

ds
≤
ns

j=1
 ∞
0

zt
j(s)zj(s) −γ2
j wt
j(s)wj(s) + ˙Vj(t)|(6.1)

ds
Proceeding as before, we get
ns

j=1

zt
j(s)zj(s) −γ2
j wt
j(s)wj(s) + ˙Vj(t)|(6.1)

=
ns

j=1
¯χt
j(t, s) &Ξj ¯χj(t, s),
¯χj(t, s)
=
 xt
j(t)
xt
j(t −τj)
˙xt
j(s)
wt
j(s) t

212
Chapter 6. Interconnected Time-Delay Systems
where &Ξj corresponds to Ξϱj in (6.5) by Schur complements. It is readily seen
from (6.5) by Schur complements that
ns

j=1

zt
j(s)zj(s) −γ2
j wt
j(s)wj(s) + ˙Vj(t)|(6.1)

< 0
for arbitrary s ∈[t, ∞), which implies for any wj(t) ∈L2(0, ∞) ̸= 0 that
J < 0 leading to ns
j=1 ||zj(t)||2
<
ns
j=1 γj ||w(t)j||2 and the proof is
completed.
Remark 6.2.3 It is signiﬁcant to recognize that our methodology incorporates
three weighting matrices Pj, Qj, Wj, and two parameter matrices Θj, Υj
at the subsystem level to ensure least conservative delay-dependent stability
results. This will eventually result in reduced computational requirements as
evidenced by a simple comparison with the improved free-weighting matrices
method of [103] in terms of two aspects. One aspect would be due to reduced
computational load as evidenced by less number of manipulated variables and
faster processing. Another aspect arises by noting that LMIs (6.5) subject to
(6.6) theoretically cover the results of [146, 174, 186] as special cases. Fur-
thermore, in the absence of delay (Adj ≡0, Qj ≡0, Wj ≡0), it is easy
to infer that LMIs (6.5) subject to (6.6) will eventually reduce to parametrized
delay-independent criteria.
6.2.2
Linear polytopic systems
Suppose now that system (6.1) has the state-space model
˙xj(t)
=
AjΔxj(t) + AdjΔxj(t −τj) + BjΔuj(t)
+
ns

k=1
EjkΔxk(t −ηjk) + ΓjΔwj(t)
zj(t)
=
GjΔxj(t) + GdjΔx(t −τj) + DjΔuj(t)
+
ΦjΔwj(t)
(6.27)

6.2. Linear Interconnected Systems: Continuous-Time
213
whose matrices contain uncertainties that belong to a real convex bounded
polytopic model of the type
 AjΔ
AdjΔ
BjΔ
EjkΔ
ΓjΔ
GjΔ
GdjΔ
DjΔ
0
ΦjΔ

∈Πλ
:=
5  Ajλ
Adjλ
Bjλ
Ejkλ
Γjλ
Gjλ
Gdjλ
Djλ
0
Φjλ

=
N

s=1
λs
 Ajs
Adjs
Bjs
Ejks
Γjs
Gjs
Gdjs
Djs
0
Φjs

, λs ∈Λ
6
(6.28)
where Λ is the unit simplex
Λ :=

(λ1, · · · , λN) :
N

j=1
λj = 1 , λj ≥0

(6.29)
Deﬁne the vertex set N = {1, ..., N}. We use {Ao, ..., Φo} to imply generic
system matrices and {Aoj, ..., Φoj, j ∈N} to represent the respective values
at the vertices. It is a straightforward task to show that the following result
holds.
Theorem 6.2.4 Given ϱj > 0 and μj > 0. System (6.1) with polytopic
representation (6.28)-(6.29) and uj(.) ≡0 is delay-dependent asymptoti-
cally stable with L2-performance bound γj if there exist weighting matrices
Pj, Qj, Wj, Zkj, k = 1, ..ns, parameter matrices Θj Υj, and a scalar
γj > 0 satisfying the following LMIs for s = 1, ..., N:
Ξϱjs =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
Ξojs
Ξajs
−ϱjΘj
0
PjΓj
Gt
j
ϱjAt
jsWj
•
−Ξmj
−ϱjΥj
0
0
Gt
djs
ϱjAt
djsWk
•
•
−ϱjWk
0
0
0
ϱk
ns
k=1,k̸=j EkjsWk
•
•
•
−Ξnj
0
0
0
•
•
•
•
−γ2
j I
Φt
j
ϱkΓt
jWk
•
•
•
•
•
−I
0
•
•
•
•
•
•
−ϱkWk
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
< 0
(6.30)

214
Chapter 6. Interconnected Time-Delay Systems
where
Ξojs
=
PjAjs + At
jsPt
j + Θj + Θt
j + Qj
+
ns

k=1
Zkj + (ns −1)Pj,
Ξajs
=
PjAdjs −Θj + Υt
j,
Ξmj
=
Υj + Υt
j + (1 −μj)Qj,
Ξnj
=
ns

k=1
(1 −μkj)Zkj +
ns

k=1,k̸=j
Et
kjsPjEkjs
(6.31)
Remark 6.2.5 The optimal performance level γj, j = 1, .., ns can be deter-
mined in the case of decentralized stability by solving the following convex
optimization problems:
Problem C: Stability
For j, k = 1, ..., ns,
Given ϱj, μj, ϱjk, μjk,
min
Pj, Qj, Wj, Zkj, Θj Υj
γj
subject to LMI(6.5)
(6.32)
6.2.3
Illustrative example 6.1
Consider an interconnected system composed of three subsystems, each of the
type (6.1) with the following coefﬁcients:
Subsystem 1 :
A1 =
 −2
0
−2
−1

, Ad1 =
 −1
0
−1
0

, Γ1 =
 0.2
0.2

,
G1 =

0.2
0.1

, Gd1 =

−0.1
0

, Φ1 = 0.5
Subsystem 2 :
A2 =
 −1
0
−1
−4

, Ad2 =

1
0
−2
−1

, Γ2 =
 0.1
0.3

,
G2 =

0.2
0.1

, Gd2 =

0.1
0

, Φ2 = 0.2
Subsystem 3 :
A3 =

0
1
−1
−2

, Ad3 =
 0
0
0
−1

, Γ3 =
 0.1
0.5

,
G3 =

0.1
−0.1

, Gd3 =

−0.1
0

, Φ3 = 0.1

6.2. Linear Interconnected Systems: Continuous-Time
215
Couplings 1 :
E12 =
 1
0
1
0

, E13 =
 0
−1
0
−1

,
Couplings 2 :
E21 =
 −1
−2
3
6

, E23 =
 −1
1
3
−2

,
Couplings 3 :
E31 =
 1
2
1
2

, E32 =
 0
0
0
−1

Considering Problem C, it is found that the feasible solution is attained at
Subsystem 1 :
ϱ1 = 3, μ1 = 1.5, ϱ21 = 2, μ21 = 0.8,
ϱ31 = 2, μ31 = 0.8, γ1 = 2.2817
P1 =
 2.2511
0.0020
•
0.0362

, Q1 =
 1.39501
0.0576
•
20.0181

Subsystem 2 :
ϱ2 = 32.5, μ2 = 1.3, ϱ12 = 1.5, μ12 = 0.9,
ϱ32 = 1.5, μ32 = 0.9, γ2 = 0.9930
P2 =
 0.1386
−0.0152
•
0.0724

, Q2 =
 5.9043
0.3326
•
5.4613

Subsystem 3 :
ϱ3 = 3, μ3 = 1.1, ϱ13 = 1.8, μ13 = 0.75,
ϱ23 = 1.8, μ23 = 0.75, γ3 = 1.7437
P3 =
 1.8296
0.1004
•
0.5422

, Q3 =
 21.3065
−2.5036
•
28.6509

Since Pj, Qj, > 0, j = 1, 2, 3 then the conditions required by Theorem 6.2.2
are satisﬁed.
6.2.4
State feedback stabilization
We now direct attention to decentralized state feedback stabilization schemes.
Apply the state feedback control uj(t) = Kjxj(t) to the linear system (6.1)
and deﬁne Af
= Aj + BjKj and Gf
= Gj + DjKj. It then follows
from Theorem 6.2.2 that the resulting closed-loop system is delay-dependent
asymptotically stable with L2-performance bound γ if there exist matrices

216
Chapter 6. Interconnected Time-Delay Systems
Pj, Qj, Wj, Zkj, k = 1, ..ns,
parameter matrices Θj Υj, and a scalar
γj > 0 satisfying the following LMI:
&Ξϱj =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
Ξsj
Ξaj
−ϱjΘj
0
PjΓj
Gt
f
ϱjAt
fWk
•
−Ξmj
−ϱjΥj
0
0
Gt
dj
ϱjAt
djWk
•
•
−ϱjWk
0
0
0
0
•
•
•
−Ξnj
0
0
ϱk
ns
k=1,k̸=j EkjWk
•
•
•
•
−γ2
j I
Φt
j
ϱkΓt
jWk
•
•
•
•
•
−I
0
•
•
•
•
•
•
−ϱkWk
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
< 0
(6.33)
where
Ξsj = PjAf + At
fPj + Θj + Θt
j + Q +
ns

k=1,k̸=j
Zkj + (ns −1)Pj(6.34)
and Ξaj, Ξcj, Ξmj, Ξnj are given by (6.6). The main decentralized feedback
design results are established by the following theorems.
Theorem 6.2.6 Given the bounds ϱj > 0 and μj > 0, the interconnected
system (6.1) with decentralized controller uj(t) = Kjxj(t) is delay-dependent
asymptotically stable with L2-performance bound γj if there exist weighting
matrices Xj, Yj, Mj, {Λkj}ns
k=1, {Ψrj}3
1, and a scalar γj > 0 satisfying
the following LMI:
Ξϱj =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
Πoj
Πaj
−ϱjΨ1j
0
Γj
Πt
zj
ϱk(XjAt
j + Yt
jBt
j)
•
−Πmj
−ϱkΨ3j
0
0
Gt
dj
ϱkXjAt
dj
•
•
−ϱjΨ4j
0
0
0
0
•
•
•
−Πnj
0
0
ns
k=1,k̸=j ϱkXjEkj
•
•
•
•
−γ2
j I
Φt
j
ϱjΓt
j
•
•
•
•
•
−I
0
•
•
•
•
•
•
−ϱkMk
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
< 0
(6.35)

6.2. Linear Interconnected Systems: Continuous-Time
217
where
Πoj
=
AjXj + BjYj + XjAt
j + Yt
jBt
j + Ψ1j + Ψt
1j
+
Ψ2j +
ns

k=1,k̸=j
Λkj + (ns −1)Pj
Πaj
=
AdjXj −Ψ1j + Ψt
3j,
Πmj
=
Ψ3j + Ψt
3j + (1 −μj)Ψ2j −Ψt
4j,
Πnj
=
ns

k=1,k̸=j
(1 −μkj)Λkj +
ns

k=1,k̸=j
XjEt
kjPkEkjXj
Πzj
=
GjsXj + DjsYj, Mj = W−1
j
(6.36)
Moreover, the local gain matrix is given by Kj = YjX −1
j
.
Proof: Deﬁne Xj = P−1
j
and apply the congruent transformation
diag[Xj, Xj, Xj, Xj, I, I, I]
to LMI (6.33) using the linearizations
Yj
=
KjXj, Ψ1j = XjΘjXj, Ψ2j = XjQjXj,
Ψ3j
=
XjΥjXj, Ωj = αjXjF t
j , Λkj = XjZkjXj,
Ψ4j
=
XjWjXj
We readily obtain LMI (6.35) by Schur complements.
Theorem 6.2.7 Given ϱj > 0 and μj > 0. System (6.1) with decentral-
ized controller uj(t) = Kjxj(t) and polytopic representation (6.28)-(6.29) is
delay-dependent asymptotically stable with L2-performance bound γj if there
exist weighting matrices Xj, Yj, Mj, {Λkj}ns
k=1, {Ψrj}3
1,
and a scalar
γj > 0 satisfying the following LMIs for s = 1, ..., N:
Ξϱjs =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
Πojs
Πajs
−ϱjΨ1j
0
Γj
Πt
zjs
ϱj(XjAt
j + Yt
jBt
j)
•
−Πmj
−ϱjΨ3j
0
0
Gt
dj
ϱkXjAt
djs
•
•
−ϱkΨ4j
0
0
0
0
•
•
•
−Ξnj
0
0
ϱk
ns
k=1,k̸=j ϱkXjEkjs
•
•
•
•
−γ2
j I
Φt
js
ϱkXjΓt
js
•
•
•
•
•
−I
0
•
•
•
•
•
•
−ϱkMk
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
< 0
(6.37)

218
Chapter 6. Interconnected Time-Delay Systems
where
Πojs
=
AjXj + BjYj + XjAt
j + Yt
jBt
j + Ψ1j + Ψt
1j
+
Ψ2j +
ns

k=1,k̸=j
Λkj + (ns −1)Xj
Πajs
=
AdjsXj −Ψ1j + Ψt
3j,
Πmj
=
Ψ3j + Ψt
3j + (1 −μj)Ψ2j,
Πzjs
=
GjsXj + DjsYj +
ns

k=1,k̸=j
XjEt
kjsPkEkjsXj
(6.38)
Moreover, the local gain matrix is given by Kj = YjX −1
j
.
Proof: Follows by parallel development to Theorems 6.2.4 and 6.2.6.
Remark 6.2.8 Similarly, the optimal performance level γj, j = 1, .., ns can
be determined in case of decentralized stabilization by solving the following
convex optimization problems:
Problem D: H∞Stabilization
For j, k = 1, ..., ns,
Given ϱj, μj, ϱjk, μjk,
min
Xj, Yj, Mj, Ωj, {Λrj}ns
r=1, {Ψrj}4
1
γj
subject to LMI(6.35)
(6.39)
6.2.5
Illustrative example 6.2
Consider the interconnected system of Example 6.1 with the additional coefﬁ-
cients
Subsystem
1
:
B1 =
 1
2

, B2 =

1
1
−1
2

, B3 =
 2
1

,
D1 = [0], D2 = [0], D3 = [0]
Considering Problem D, it is found that the feasible solution is attained at
γ1 = 1.8011, K1 =

1.1187
0.8962

,
γ2 = 13.4931, K2 =
 −8.8441
1.3237
−3.9501
−3.3300

,
γ3 = 1.4746, K3 =

0.6289
−0.2550


6.3. Nonlinear Interconnected Systems
219
6.3
Nonlinear Interconnected Systems
Extending on the foregoing section we consider, in this section, a class of in-
terconnected continuous-time systems with Lipschitz-type nonlinearities and
time-varying delays within the local subsystems and across the interconnec-
tions. In our analysis, we consider the time-delay factor as a differentiable
time-varying function satisfying some bounding relations. We construct appro-
priate Lyapunov-Krasovskii functional in order to exhibit the delay-dependent
dynamics. The developed methods for decentralized stability and stabilization
deploy an “injection procedure” within the individual subsystems which elimi-
nates the need for overbounding and utilizes a smaller number of LMI decision
variables. In this way, new and improved solutions are developed in terms of
feasibility testing of new parametrized LMIs.
6.3.1
Problem statement
We consider a class of nonlinear systems S structurally composed of ns cou-
pled subsystems Sj and modeled by the state-space model:
˙xj(t)
=
Ajxj(t) + Adjxj(t −τj) + Bju(t) + fj(xj(t), t)
+
hj(xj(t −τj), t) +
ns

k=1,k̸=j
Ejkxk(t −ηjk) + Γjwj(t)
zj(t)
=
Gjx(t) + Gdjx(t −τj) + Dju(t) + Φjwj(t)
(6.40)
where for j ∈{1, ..., ns}, xj(t)
∈ℜnj is the state vector; uj(t)
∈ℜmj
is the control input, wj(t)
∈ℜqj is the disturbance input which belongs
to L2[0, ∞),
zj(t)
∈ℜqj
is the controlled output, and τj, ηjk, j, k ∈
{1, ..., ns} are unknown time-delay factors satisfying
0 ≤τj ≤ϱj,
˙τj ≤μj, 0 ≤ηjk ≤ϱjk,
˙ηjk ≤μjk
(6.41)
where the bounds ϱj, ϱjk, μj, μjk are known constants in order to guaran-
tee smooth growth of the state trajectories. The matrices Aj ∈ℜnj×nj, Bj ∈
ℜnj×mj, Gj ∈ℜqj×nj, Dj ∈ℜqj×mj, Adj ∈ℜnj×nj, Φj ∈ℜqj×qj, Γj ∈
ℜnj×qj, Cj ∈ℜpj×nj, Cdj ∈ℜpj×nj, Fj ∈ℜpj×mj, Ψj ∈ℜpj×qj
are
real and constants. The initial condition ⟨xj(0), xj(r)⟩= ⟨xoj, φj⟩, j ∈
{1, ..., ns} where φj(.) ∈L2[−τ ∗
j , 0], j ∈{1, ..., ns}. The inclusion of the
term Adjxj(t −τj) is meant to emphasize the delay within the jth subsystem.
The unknown functions fj = fj(xj(t), t) ∈ℜnj, hj = hj(xj(t), t) ∈
ℜnj
are vector-valued time-varying nonlinear perturbations with fj(0, t) =

220
Chapter 6. Interconnected Time-Delay Systems
0, hj(0, t) = 0, ∀t and satisfy the following Lipschitz condition for all
(xj, t), ( ˆxj, t) ∈ℜnj × ℜ:
||fj(xj(t), t) −fj(ˆxj(t), t)|| ≤αj ||Fj(xj −ˆxj)||
||hj(xj(t −τ), t) −hj(ˆxj(t −τ), t)|| ≤
βj ||Hj (xj(t −τ) −ˆxj(t −τ))||
(6.42)
for some constants αj > 0, βj > 0 and Fj ∈ℜnj × ℜnj, Hj ∈ℜnj × ℜnj
are constant matrices. Note as a consequence of (6.42), we have
||fj(xj(t), t)|| ≤αj ||Fj xj||
||hj(xj(t −τ), t)|| ≤βj ||Hj xj(t −τ)||
(6.43)
Equivalently stated, condition (6.42) implies that

f t
j(xj(t), t)fj(xj(t), t) −α2
jxt
j(t)F t
j Fjxj(t)

≤0

ht
j(x(t −τ), t)hj(xj(t −τ), t) −β2
j xt
j(t −τ)Ht
jHjxj(t −τ)

≤0
(6.44)
Remark 6.3.1 It must be observed that system description (6.40) might bear
some resemblance to dynamic models of neural networks in terms of intercon-
nections and delays. However, careful considerations would reveal that system
(6.40) is much more general since it allows delays within the subsystems as
well as across the couping links. Additionally, the performance vector is per-
mitted to depend on delays and both the states as well as output are subject
to ﬁnite-energy disturbances and not constant inputs as in neural networks.
Moreover, stabilization is the ultimate goal for large-scale systems, a feature
that is not shared by neural networks. The tools of system stability are common
and in the sequel we will provide an improved method for stability and state
feedback stabilization.
6.3.2
Local delay-dependent analysis
In this section, we develop new criteria for LMI-based characterization of
delay-dependent asymptotic stability and L2 gain analysis. The criteria include
some parameter matrices aimed at expanding the range of applicability of the
developed conditions. The following theorem establishes the main result for S
with subsystems Sj, j = 1, ..., ns.

6.3. Nonlinear Interconnected Systems
221
Theorem 6.3.2 Given ϱj > 0, μj > 0, ϱjk > 0, and μjk > 0, j, k =
1, ..., ns. The free global system S composed of the family of subsystems {Sj}
with uj(.) ≡0 where Sj is described by (6.40) is delay-dependent asymptoti-
cally stable with L2-performance bound γj, j = 1, ..., ns if there exist weight-
ing matrices Pj, Qj, Wj
Zkj, k = 1, ..ns,
parameter matrices Θj Υj, and scalars γj > 0, σj >
0, κj > 0, j = 1, ..., ns satisfying the following LMI:
Ξϱj =
 Ξϱj1
Ξϱj2
•
Ξϱj3

< 0
(6.45)
with
Ξϱj1 =
⎡
⎢⎢⎢⎢⎢⎢⎣
Ξoj
Ξaj
−ϱjΘj
0
Pj
Pj
•
−Ξmj
−ϱjΥj
0
0
0
•
•
−ϱjWj
0
0
0
•
•
•
−Ξnj
0
0
•
•
•
•
−σjI
0
•
•
•
•
•
−κjI
⎤
⎥⎥⎥⎥⎥⎥⎦
,
Ξϱj2 =
⎡
⎢⎢⎢⎢⎢⎢⎢⎣
PjΓj
Gt
j
ϱjAt
jWk
0
Gt
dj
ϱjAt
djWk
0
0
ϱk
ns
k=1,k̸=j Et
kjWk
0
0
0
0
0
Wk
0
0
Wk
⎤
⎥⎥⎥⎥⎥⎥⎥⎦
,
Ξϱj3 =
⎡
⎣
−γ2
j I
Φt
j
ϱjΓt
jWk
•
−I
0
•
•
−ϱkWk
⎤
⎦
(6.46)
where
Ξoj
=
PjAj + At
jPt
j + Θj + Θt
j + Qj + σjα2
jF t
jFj
+
ns

k=1
Zkj + (ns −1)Pj,
Ξaj
=
PjAdj −Θj + Υt
j,
Ξmj
=
Υj + Υt
j + (1 −μj)Qj −κjβ2
j Ht
jHj,
Ξnj
=
ns

k=1
(1 −μkj)Zkj +
ns

k=1,k̸=j
Et
kjPkEkj
(6.47)

222
Chapter 6. Interconnected Time-Delay Systems
Proof: It is readily seen from (6.46) that there exists a scalar ωj > 0 such that
¯Ξϱj =
 ¯Ξϱj1
Ξϱj2
•
Ξϱj3

< 0
(6.48)
¯Ξϱj1 =
⎡
⎢⎢⎢⎢⎢⎢⎣
Ξoj + ωjI
Ξaj
−Θj
Ξcj
Pj
Pj
•
−Ξmj
−Υj
0
0
0
•
•
−ϱ−1
j Wj
0
0
0
•
•
•
−Ξnj
0
0
•
•
•
•
−σjI
0
•
•
•
•
•
−κjI
⎤
⎥⎥⎥⎥⎥⎥⎦
(6.49)
Therefore, for all τj satisfying (6.41) we have
Ξωj =
 ˜Ξϱj1
Ξϱj2
•
Ξϱj3

< 0
(6.50)
˜Ξϱj1 =
⎡
⎢⎢⎢⎢⎢⎢⎣
Ξoj
Ξaj
−τjΘj
Ξcj
Pj
Pj
•
−Ξmj
−τjΥj
0
0
0
•
•
−τjWj
0
0
0
•
•
•
−Ξnj
0
0
•
•
•
•
−σjI
0
•
•
•
•
•
−κjI
⎤
⎥⎥⎥⎥⎥⎥⎦
(6.51)
Now consider the Lyapunov-Krasovskii functional (LKF) for the global system
S:
V (t)
=
ns

j=1

Voj(t) + Vaj(t) + Vmj(t) + Vnj(t)

,
Voj(t)
=
xt
j(t)Pjxj(t), Vaj(t) =
 0
−ϱj
 t
t+s
˙xt
j(α)Wj ˙xj(α)dα ds,
Vmj(t)
=
 t
t−τj
xt
j(s)Qjxj(s) ds,
Vnj(t)
=
ns

k=1,k̸=j
 t
t−ηjk
xt
k(s)Zjkxk(s) ds
(6.52)
where 0 < Pj = Pt
j, 0 < Wj = Wt
j, 0 < Qj = Qt
j, 0 < Rj = Rt
j, 0 <
Zjk = Zt
jk, j, k ∈{1, ..., ns} are weighting matrices of appropriate dimen-
sions. The ﬁrst term in (6.52) is standard to nominal systems without delay,
while the second and third terms correspond to the delay-dependent conditions
since they provide measures of the individual and difference signal energies

6.3. Nonlinear Interconnected Systems
223
during the delay-period 1 and the fourth term corresponds to the intraconnec-
tion delays. A straightforward computation gives the time derivative of Vj(t)
along the solutions of (6.40) with w(t) ≡0 as:
˙Voj(t)
=
2xt
jPj ˙xj = 2xt
jPj[Ajx(t) + Adjxj(t −τj) + fj + hj]
+
2xt
jPj
ns

k=1
Ejkxk(t −ηjk)
(6.53)
Expanding terms of (6.53) results in
˙Voj(t)
=
2xt
jP[Ajxj(t) + Adj]xj(t) −2xt
jPjAdj
 t
t−τj
˙xj(s)ds
+
2xt
jPj[fj + hj] + 2xt
jPj
ns

k=1
Ejkxk(t −ηjk)
=
2xt
jPj[Ajxj(t) + Adj]xj(t) + 2xt
j[Θj −PjAdj]
 t
t−τj
˙xj(s)ds
+
2xt(t −τj)Υj
 t
t−τj
˙xj(s)ds
−

2xt
jtΘj
 t
t−τj
˙xj(s)ds + 2xt(t −τj)Υj
 t
t−τj
˙xj(s)ds

+
2xt
jPj[fj + hj] + 2xt
jPj
ns

k=1
Ejkxk(t −ηjk)
(6.54)
Little algebra on (6.13) yields
˙Voj(t)
=
1
τj
 t
t−τj

2xt
j[PjAj + Θj]xj + 2xt
j[PjAdj −Θj + Υt
j]xj(t −τj)
−
2xt
j(t −τj)Υjxj(t −τj)
−
2xt
jτjΘj ˙xj(s) −2xt
j(t −τj)τjΥj ˙xj(s) + 2xt
jPj[fj + hj]
+
2xt
jPj
ns

k=1
Ejkxk(t −ηjk)
	
ds
(6.55)
1Recall that
R t
t−ϱj ˙xj(α)dα = xj(t) −xj(t −ϱj) by Leibniz-Newton formula.

224
Chapter 6. Interconnected Time-Delay Systems
where Θj ∈ℜnj×nj and Υj ∈ℜnj×nj are appropriate relaxation matrices
injected to facilitate the delay-dependence analysis. Proceeding further,
˙Vaj(t)
=
 0
−ϱj
[ ˙xt
j(t)Wj ˙xj(t) −˙xt
j(t + s)Wj ˙xj(t + s)]ds
=
 t
t−ϱj
[ ˙xt
j(t)Wj ˙xj(t) −˙xt
j(s)Wj ˙xj(s)]d s
(6.56)
Little algebra on (6.56) yields
˙Vaj(t)
=
ϱj ˙xt
j(t)Wj ˙xj(t) −
 t
t−τj
˙xt
j(s)Wj ˙xj(s)ds −
 t−τj
t−ϱj
˙xt
j(s)Wj ˙xj(s)
≤
ϱj ˙xt
j(t)Wj ˙xj(t) −
 t
t−τj
˙xt
j(s)Wj ˙xj(s)ds
=
1
τj
 t
t−τj

ϱj ˙xt
j(t)Wj ˙xj(t) −τj ˙xt
j(s)Wj ˙xj(s)

(6.57)
Note that the term Tj =
 t−τj
t−ϱj ˙xt
j(s)Wj ˙xj(s) accounts for the enlarged time
interval from t −ϱj →t to t −τj →t. It is readily evident that Tj > 0
and hence expression (6.57) holds true without conservatism. There has been
an alternative route to handle Tj by employing extra parameter matrices and
adding more identities [103]-[146]. Next we have
˙Vmj(t)
=
xt
j(t)Qjxj(t) −(1 −˙τj) xt(t −τj)Qjxj(t −τj)
≤
xt
j(t)Qjxj(t) −(1 −μj) xt
j(t −τj)Qjxj(t −τj)
=
1
τj
 t
t−τj

xt
j(t)Qjxj(t) −(1 −μj) xt
j(t −τj)Qjxj(t −τj)

ds
(6.58)
Also, we obtain
˙Vnj(t)
=
ns

k=1,k̸=j
xt
k(t)Zjkxk(t) −
ns

k=1,k̸=j
(1 −˙ηjk) xt
k(t −ηjk)
Zjkxk(t −ηjk)
≤
ns

k=1,k̸=j
xt
k(t)Zjkxk(t) −
ns

k=1,k̸=j
(1 −μjk) xt
k(t −ηjk)
Zjkxk(t −ηjk)
(6.59)

6.3. Nonlinear Interconnected Systems
225
For the class of interconnected systems (6.40), the following structural identity
holds:
ns

j=1
ns

k=1,k̸=j
xt
k(t)Zjkxk(t) =
ns

j=1
ns

k=1,k̸=j
xt
j(t)Zkjxj(t)
(6.60)
It should be noted that relation (6.60) is employed to preserve the local vari-
ables with subsystem Sj thereby assuring decentralized computation structure.
Taking into account (6.44) via the S-procedure [29], it follows that there ex-
ist scalars σj > 0, κj > 0 such that by combining (6.52)-(6.60) and Schur
complements, we have
˙V (t)|(6.40) ≤
ns

j=1
 1
τj
 t
t−τj
χt
j(t, s) Ξj χj(t, s) ds
	
(6.61)
χj(t, s) =

xt
j(t) xt
j(t −τj) ˙xt
j(s) xt
j(t −ηkj) f t
j ht
j
t (6.62)
where ˙V (t)|(6.40) deﬁnes the Lyapunov derivative along the solutions of the
global system S with subsystem Sj given by (6.40). Note that Ξj corresponds
to Ξωj in (6.51) with Gj ≡0, Gdj ≡0, Γj ≡0, Φj ≡0. In view of (6.51), it
follows that Ξj < 0 and more importantly
˙Vj(t)|(6.40)
<
ns

j=1
 1
τj
 t
t−τj
χt
j(t, s)diag[−ωj, 0, 0, 0, 0, 0]χ(t, s)j ds
	
=
−
ns

j=1
ωj ||xj||2 < 0
(6.63)
This establishes the internal asymptotic stability.
Consider the performance measure for the global system S
J =
ns

j=1
 ∞
0

zt
j(s)zj(s) −γ2
j wt
j(s)wj(s)

ds
For any wj(t) ∈L2(0, ∞) ̸= 0 and zero initial condition xj(0) = 0, we have
J
=
ns

j=1
 ∞
0

zt
j(s)zj(s) −γ2
j wt
j(s)wj(s) + ˙Vj(t)|(6.40) −˙Vj(t)|(6.40)

ds
≤
ns

j=1
 ∞
0

zt
j(s)zj(s) −γ2
j wt
j(s)wj(s) + ˙Vj(t)|(6.40)

ds

226
Chapter 6. Interconnected Time-Delay Systems
Proceeding as before, we get
ns

j=1

zt
j(s)zj(s) −γ2
j wt
j(s)wj(s) + ˙Vj(t)|(6.40)

=
ns

j=1
¯χt
j(t, s) &Ξj ¯χj(t, s),
¯χj(t, s) =
 xt
j(t)
xt
j(t −τj)
˙xt
j(s)
f t
j
ht
j
wt
j(s) t
where &Ξj corresponds to Ξϱj in (6.65) by Schur complements. It is readily seen
from (6.65) by Schur complements that
ns

j=1

zt
j(s)zj(s) −γ2
j wt
j(s)wj(s) + ˙Vj(t)|(6.40)

< 0
for arbitrary s ∈[t, ∞), which implies for any wj(t) ∈L2(0, ∞) ̸= 0 that
J < 0 leading to ns
j=1 ||zj(t)||2
<
ns
j=1 γj ||w(t)j||2 and the proof is
completed.
Remark 6.3.3 It is signiﬁcant to recognize that our methodology incorporates
three weighting matrices Pj, Qj, Wj, and two parameter matrices Θj, Υj
at the subsystem level to ensure least conservative delay-dependent stability
results. This will eventually result in reduced computational requirements as
evidenced by a simple comparison with the improved free-weighting matrices
method of [103]. The performance of the developed stability criteria is assessed
in terms of the number of LMI variables L, the number of other unknown vari-
ables U, and the basic storage requirements S. Based thereon, a comparison
of the computational requirements of different methods is given in Table 6.1. It
is readily evident that the developed method in this chapter requires the least
computational effort on the subsystems level, a signiﬁcant feature that is natu-
rally needed for large-scale interconnected systems.
6.3.3
State feedback stabilization
We now direct attention to decentralized state feedback stabilization schemes.
Apply the state feedback control uj(t) = Kjxj(t) to the nonlinear system
(6.40) and deﬁne Af = Aj + BjKj and Gf = Gj + DjKj. It then follows
from Theorem 6.3.2 that the resulting closed-loop system is delay-dependent
asymptotically stable with L2-performance bound γj if there exist matrices

6.3. Nonlinear Interconnected Systems
227
Method
L
U
S
Ref. [79]
4
4
6n2 + 2n
Ref. [103]
5
9
11.5n2 + 2.5n
Ref. [146]
11
2
7.5n2 + 5.5n
Ref. [186]
7
9
12.5n2 + 3.5n
Ref. [290]
5
6
8.5n2 + 2.5n
Theorem 6.3.2
3
2
3.5n2 + 2n
Table 6.1: Computational Requirements: A Comparison
Pj, Qj, Wj, Zkj, k = 1, ..ns,
parameter matrices Θj Υj, and scalars
γj > 0, σj > 0, κj > 0 satisfying the following LMI:
&Ξϱj =
)
&Ξϱj1
&Ξϱj2
•&Ξϱj3
*
< 0
(6.64)
with
&Ξϱj1 =
⎡
⎢⎢⎢⎢⎢⎢⎣
Ξsj
Ξaj
−ϱjΘj
0
Pj
Pj
•
−Ξmj
−ϱjΥj
0
0
0
•
•
−ϱjWj
0
0
0
•
•
•
−Ξnj
0
0
•
•
•
•
−σjI
0
•
•
•
•
•
−κjI
⎤
⎥⎥⎥⎥⎥⎥⎦
(6.65)
where
Ξsj
=
PjAf + At
fPj + Θj + Θt
j + Q + σjα2
jF t
j Fj
+
ns

k=1,k̸=j
Zkj + (ns −1)Pj
(6.66)
and Ξaj, Ξcj, Ξmj, Ξnj are given by (6.47). The main decentralized feedback
design results are established by the following theorem.
Theorem 6.3.4 Given ϱj > 0 and μj > 0. System (6.40) with decentralized
controller uj(t) = Kjxj(t) is delay-dependent asymptotically stable with L2-
performance bound γj if there exist weighting matrices
Xj, Yj, Mj, Ωj, {Λkj}ns
k=1, {Ψrj}4
1, γj > 0, σj > 0, κj > 0

228
Chapter 6. Interconnected Time-Delay Systems
satisfying the following LMI:
Ξϱj =
 Ξϱj1
Ξϱj2
•
Ξϱj3

< 0
(6.67)
where
Ξϱj1
=
⎡
⎢⎢⎢⎢⎢⎢⎣
Πoj
Πaj
−ϱjΨ1j
0
I
I
•
−Πmj
−ϱjΨ3j
0
0
0
•
•
−ϱjΠwj
0
0
0
•
•
•
−Πnj
0
0
•
•
•
•
−σjI
0
•
•
•
•
•
−κjI
⎤
⎥⎥⎥⎥⎥⎥⎦
Ξϱj2
=
⎡
⎢⎢⎢⎢⎢⎢⎢⎣
Γj
Πt
zj
ϱj(XjAt
j + Yt
jBt
j)
Ωj
0
Gt
dj
ϱkXjAt
dj
0
0
0
0
0
0
0
ns
k=1,k̸=j ϱkXjEt
kj
0
0
0
I
0
0
0
I
0
⎤
⎥⎥⎥⎥⎥⎥⎥⎦
Ξϱj3
=
⎡
⎢⎢⎣
−γ2
j I
Φt
j
ϱkXjΓt
j
0
•
−I
0
0
•
•
−ϱkMk
0
•
•
•
−σjI
⎤
⎥⎥⎦
(6.68)
with
Πoj
=
AjXj + BjYj + XjAt
j + Yt
jBt
j + Ψ1j + Ψt
1j + Ψ2j
+
ns

k=1,k̸=j
Λkj + (ns −1)Xj,
Πaj
=
AdjXj −Ψ1j + Ψt
3j,
Πmj
=
Ψ3j + Ψt
3j + (1 −μj)Ψ2j −Ψt
4j,
Πnj
=
ns

k=1,k̸=j
(1 −μkj)Λkj +
ns

k=1,k̸=j
XjEt
kjPkEkjXj,
Πzj
=
GjsXj + DjsYj, Mj = W−1
j
(6.69)
Moreover, the local gain matrix is given by Kj = YjX −1
j
.
Proof: Deﬁne Xj = P−1
j
and apply the congruent transformation
diag[Xj, Xj, Xj, Xj, I, I, I, I, I]

6.3. Nonlinear Interconnected Systems
229
to LMI (6.64) using the linearizations
Yj
=
KjXj, Ψ1j = XjΘjXj, Ψ2j = XjQjXj, Ψ3j = XjΥjXj,
Ωj
=
αjXjF t
j , Λkj = XjZkjXj, Ψ4j = κjXjβ2
j Ht
jHjXj
We readily obtain LMI (6.67) by Schur complements.
Remark 6.3.5 The optimal performance-level γj, j = 1, .., ns can be de-
termined in case of decentralized stability and stabilization of interconnected
nonlinear systems by solving the following convex optimization problems:
Problem A: Stability
For j, k = 1, ..., ns,
Given ϱj, μj, ϱjk, μjk,
min
Pj, Qj, Wj, Zkj, Θj Υj, σj, κj
γj
subject to LMI(6.65)
(6.70)
Problem B: H∞Stabilization
For j, k = 1, ..., ns,
Given ϱj, μj, ϱjk, μjk,
min
Xj, Yj, Mj, Ωj, {Λrj}ns
r=1, {Ψrj}4
1, σj, κj
γj
subject to LMI(6.67)
(6.71)
6.3.4
Illustrative example 6.3
Consider an interconnected system composed of three subsystems, each is of
the type (6.40) with the following coefﬁcients:
Subsystem
1
:
A1
=
 −2
0
−2
−1

, Γ1 =
 0.2
0.2

, B1 =
 1
1

,
Ad1
=
 −1
0
−1
0

,
G1
=

0.2
0.1

, Φ1 = 0.5, β1 = 2, α1 = 1,
Gd1
=

−0.1
0

,
F t
1F1
=
 0.04
0
0
0.04

, Ht
1H1 =
 0.01
0
0
0.01


230
Chapter 6. Interconnected Time-Delay Systems
Couplings
1
:
E12
=
 1
0
1
1
0
1

, E13 =
 0
−1
0
−1

Subsystem
2
:
A2
=
⎡
⎣
−1
0
0
−1
−4
−1
1
1
0
⎤
⎦, Γ2 =
⎡
⎣
0.1
0.3
0.4
⎤
⎦, Bt
2 =
 1
1
0
−1
2
1

,
G2
=

0.2
0.1
0

, Φ2 = 0.2, , β2 = 1, α2 = 1,
Gd2
=

0.1
0
−0.2

,
F t
2F2
=
 0.09
0
0
0.09

, Ht
2H2 =
 0.01
0
0
0.01

,
Ad2
=
⎡
⎣
1
0
0
−2
−1
0
−1
0
0
⎤
⎦
Couplings
2
:
E21
=
⎡
⎣
−1
−2
3
6
1
2
⎤
⎦, E23 =
⎡
⎣
−1
1
3
−2
1
−1
⎤
⎦
Subsystem
3
:
A3
=

0
1
−1
−2

, Γ3 =
 0.1
0.5

, B3 =
 1
0
0
1

,
Ad3
=
 0
0
0
−1

,
G3
=

0.1
−0.1

, Φ3 = 0.1, β1 = 1, α1 = 2,
Gd3
=

−0.1
0

,
F t
3F3
=
 0.01
0
0
0.01

, Ht
1H1 =
 0.04
0
0
0.04

Couplings
3
:
E31
=
 1
2
1
2

, E32 =
 0
0
−1
0
−1
0

Using the LMI-solver Scilab-5.1, it is found that the feasible solution of
Problem A is attained at μ1 = 1.8455, ϱ1 = 0.895, μ2 = 1.9191, ϱ2 =
0.8333, μ3 = 1.7784, ϱ3 = 0.769, with disturbance attenuation levels γ1 =
3.5115, γ2 = 3.1359, γ3 = 3.6244 thereby validating Theorem 6.3.2. Turning
to Problem B, the feasible solution is summarized below:

6.4. Interconnected Discrete-Time-Delay Systems
231
ϱ1 = 1.154, μ1 = 1.015, K1 =

4.061
1.536

, γ1 = 3.3875,
ϱ2 = 2.063, μ2 = 1.256, K2 =

2.314
1.816
0.957
−0.742
2.314
4.315

,
γ2 = 3.2977,
ϱ3 = 1.225, μ3 = 0.923, K3 =
 4.498
0.155
0.163
3.147

, γ3 = 2.9938
6.4
Interconnected Discrete-Time-Delay Systems
Large-scale interconnected systems can be found in such diverse ﬁelds as elec-
trical power systems, space structures, manufacturing processes, transportation,
and communication. An important motivation for the design of decentralized
feedback control (DFC) schemes is that the information exchange between sub-
systems of a large-scale system is not needed; hence, the individual subsystem
controllers are simple and use only locally available information. In this way,
multiple separate controllers are articulated each of which has access to differ-
ent measured information and has authority over different decision or actuation
variables.
Decentralized control of large-scale systems has received considerable in-
terest in the systems and control literature. It effectively exploits the informa-
tion structure constraint that commonly exists in many practical large-scale sys-
tems. Over the past few decades, a large body of literature has become available
on this subject; see [57]-[406] and the references therein. The computational
advantages of the DFC approach have also recently attracted considerable at-
tention, particularly in the context of parallel processing.
In recent years, a new systematic methodology has been proposed in
[326, 348] based on LMIs [29] and extended to continuous-time interconnected
systems in [326, 327, 348, 398] and to time-delay systems in [28, 260, 261].
The appealing feature of these results is that the underlying problem is for-
mulated as a convex optimization problem, which is designed to maximize the
system robustness with respect to uncertainties.
The main objective of this section is to develop an LMI-based method for
testing robust stability and designing feedback (state and output) schemes for
robust decentralized stabilization of interconnected systems. We deal with sys-
tems composed of linear discrete-time subsystems coupled by static nonlinear
interconnections satisfying quadratic constraints and subject to unknown-but-
bounded state-delays. The developed solution is cast into the framework of

232
Chapter 6. Interconnected Time-Delay Systems
convex optimization problems over LMIs. We then develop delay-dependent
robust stability and feedback stabilization results. Feedback controllers are de-
signed on the subsystem level to guarantee robust stability of the overall system
and, in addition, maximize the bounds of unknown interconnection terms. By
incorporating additive gain perturbations we establish new resilient feedback
stabilization schemes for discrete-time-delay systems.
6.4.1
Model description and preliminaries
A class of nonlinear interconnected discrete-time systems Σ with state-delay
which is composed of N coupled subsystems Σj, j = 1, .., N is represented
by:
Σ :
x(k + 1)
=
Ax(k) + Bu(k) + Dx(k −d(k))
+
g(k, x(k), x(k −d(k)))
y(k)
=
Cx(k) + Hu(k)
(6.72)
where for k ∈Z+ := {0, 1, ...} and x = (xt
1, ..., xt
N)t
∈ℜn,
n =
N
j=1 nj, u = (ut
1, ..., ut
N)t
∈ℜp, p = N
j=1 pj, y = (yt
1, ..., yt
N)t
∈
ℜq,
q
=
N
j=1
qj are the state, control, and output vectors of sys-
tem Σ. The associated matrices are real constants and modeled as A =
diag{A1, .., AN}, Aj ∈ℜnj×nj, B = diag{B1, .., BN}, Bj ∈ℜnj×pj,
D = diag{D1, .., DN}, Dj ∈ℜnj×nj,
C = diag{C1, .., CN}, Cj ∈
ℜqj×nj,
H
=
diag{H1, .., HN},
Hj
∈
ℜqj×pj. The function g
:
Z+ × ℜn × ℜn →ℜnj,
g(k, x(k), x(k −d(k))) = (gt
1(k, x(k), x(k −
d(k))), .., gt
N (k, x(k), x(k−d(k))))t is a vector function piecewise-continuous
in its arguments. In the sequel, we assume that this function is uncertain and the
available information is that, in the domains of continuity G ⊂Z+ ×ℜn ×ℜn,
it satisﬁes the quadratic inequality
gt(k, x(k), x(k −d(k)))g(k, x(k), x(k −d(k))) ≤xt(k) (Gt(Φ−1 (Gx(k)
+
xt(k −d(k)) (Gt
d (Ψ−1 (Gdx(k −d(k))
(6.73)
where (G = [ (Gt
1, .., (Gt
N]t,
(Gj ∈ℜrj×n,
(Gd = [ (Gt
d1, .., (Gt
dN]t,
(Gdj ∈
ℜsj×n, j = 1, .., N are constant matrices such that gj(k, 0, 0)
=
0 and
x = 0 is an equilibrium of system (6.72) for d(k) ≥0. Exploiting the struc-
tural form of system (6.72), a model of the jth subsystem Σj can be described
by
Σj :
xj(k + 1)
=
Ajxj(k) + Bjuj(k) + Djxj(k −dj(k))
+
gj(k, x(k), x(k −d(k)))
yj(k)
=
Cjxj(k) + Hjuj(k)
(6.74)

6.4. Interconnected Discrete-Time-Delay Systems
233
where xj(k) ∈ℜnj, uj(k) ∈ℜpj, and yj(k) ∈ℜqj are the subsystem state,
control input, and measured output, respectively. The scalar 0 < d∗
j ≤dj(k) ≤
d+
j represents the state-delay within subsystem Σj. The function gj : Z+ ×
ℜn × ℜn →ℜnj is a piecewise-continuous vector function in its arguments
and in line of (6.73) it satisﬁes the quadratic inequality
gt
j(k, x(k), x(k −d(k))) gj(k, x(k), x(k −d(k))) ≤φ2
j xt(k) (Gt
j (Gjx(k)
+ψ2
j xt(k −d(k)) (Gt
dj (Gdjx(k −d(k))
(6.75)
where φj > 0, ψj > 0 are bounding parameters such that
(Φ
=
Blockdiag{φ2
1Ir1, .., φ2
rN IrN },
(Ψ
=
Blockdiag{ψ2
1Is1, .., ψ2
sN IsN}
where Imj represents the mj × mj identity matrix. From (6.73) and (6.75), it
is always possible to ﬁnd matrices Φ, Ψ such that
gt(k, x(k), x(k −d(k)))g(k, x(k), x(k −d(k))) ≤xt(k)GtΦ−1Gx(k)
+
xt(k −d(k))Gt
dΨ−1Gdx(k −d(k))
(6.76)
where
G
=
Blockdiag{G1, .., GN}, Gj ∈ℜrj × nj,
Gd
=
Blockdiag{Gd1, .., GdN }, Gdj ∈ℜsj × nj,
Φ
=
Blockdiag{δ1Ir1, .., δNIrN}, , δj = φ−2
j ,
Ψ
=
Blockdiag{ν1Is1, .., νNIsN }, νj = ψ−2
j
Remark 6.4.1 These applications include cold rolling mills, decision-making
processes, and manufacturing systems. Related results for a class of discrete-
time systems with time-varying delays can be found in [28] where delay-
independent stability and stabilization conditions are derived. It should be
stressed that although we consider only the case of single time-delay, extension
to multiple time-delay systems can be easily attained using an augmentation
procedure.
Remark 6.4.2 It should be observed that the interconnected system (6.72) has
a decoupled structure for the individual subsystems and retains all the nonlin-
earities and uncertainties in the global term
g(k, x(k), x(k −d(k))) =
N

j=1
gj(k, x(k), x(k −d(k)))

234
Chapter 6. Interconnected Time-Delay Systems
Following [28], we note that the local nonlinear perturbations gj(., ., .) include
the class of norm-bounded uncertain systems in which
gj(k, x(k), x(k −d(k))) = ΔAj(xj(k), k) xj(k)
+ ΔAj(xj(k −dj(k)), k) xj(k −dj(k))
where ΔAj(xj(k), k), ΔAj(xj(k −dj(k)), k) are norm bounded matrices.
It is readily seen that the class of systems (6.72) casts more general classes
satisfying the quadratic inequality bound (6.73). In addition, we do not impose
any sort of matching conditions. More importantly, by deﬁning x(k −d(k)) =
[xt
1(k −d1(k)), ...., xt
N (k −dN(k))]t, we allow the local subsystems to have
different delay patterns.
In the sequel, we let ξj(k) = [xt
j(k) xt
j(k −dj(k)) gt
j(k, x(k), x(k −d(k)))]t.
Then (6.75) can be conveniently written as
ξt
j
⎡
⎣
−φ2
j Gt
jGj
0
0
•
−ψ2
j Gt
djGdj
0
•
•
Ij
⎤
⎦ξj ≤0
(6.77)
The goal is to develop new tools for the analysis and design of a class of in-
terconnected discrete-time state-delay systems with uncertain function of non-
linear perturbations by exploiting the decentralized information structure con-
straint. We seek to establish complete LMI-based procedures for the robust
delay-dependent stability and feedback (state, output, resilient) stabilization by
basing all the computations at the subsystem level.
6.4.2
Subsystem stability
Our goal is to establish tractable conditions guaranteeing global asymptotic
stability of the origin (x = 0) for all g(k, x(k), x(k −d(k))) ∈G. Let
βj = (d+
j −d∗
j + 1) represent the number of samples within the delay range
d∗
j ≤d(k) ≤d+
j . The main result of subsystem stability is established by the
following theorem.
Theorem 6.4.3 Given the delay sample number βj. System (6.72) with u ≡0
is delay-dependent asymptotically stable for all nonlinear uncertainties satis-
fying (6.73) if there exist matrices 0 < Yt
j = Yj ∈ℜnj×nj, 0 < Wt
j =
Wj ∈ℜnj×nj and scalars δj > 0 and νj > 0 such that the following convex

6.4. Interconnected Discrete-Time-Delay Systems
235
optimization problems for j = 1, .., N are feasible:
min
Yj,Wj,δj,νj δj + νj
subject to :
Yj > 0,
Wj > 0
⎡
⎢⎢⎢⎢⎢⎢⎣
−Yj + βjWj
0
0
YjAt
j
YjAt
j
YjGt
j
•
−Wj
YjGt
dj
YjDt
j
YjDt
j
0
•
•
−νjIj
0
0
0
•
•
•
Ij −Yj
0
0
•
•
•
•
−Yj
0
•
•
•
•
•
−δjIj
⎤
⎥⎥⎥⎥⎥⎥⎦
< 0
(6.78)
Proof: Introduce the local Lyapunov-Krasovskii functional (LKF):
Vj(k)
=
xt
j(k)Pjxj(k) +
k−1

m=k−dj(k)
xt
j(m)Qjxj(m)
+
1−d∗
j

s=2−d+
j
k−1

m=k+s−1
xt
j(m)Qjxj(m)
(6.79)
where 0 < Pt
j = Pj, 0 < Qt
j = Qj are weighting matrices of appro-
priate dimensions. A straightforward computation gives the ﬁrst-difference of
ΔVj(k) = Vj(k + 1) −Vj(k) along the solutions of (6.72) with uj(k) ≡0 as:
ΔVj(k)
=
[Ajxj(k) + Djxj(k −dj(k)) + gj]tPj
×
[Ajxj(k) + Djxj(k −dj(k)) + gj] −xt
j(k)Pjxj(k)
+
+xt
j(k)Qjxj(k) −xt
j(k −dj(k))Qjxj(k −dj(k))
+
k−1

m=k+1−dj(k+1)
xt
j(m)Qjxj(m) −
k−1

m=k+1−dj(k)
xt
j(m)Qjxj(m)
+
(d+
j −d∗
j)xt
j(k)Qjxj(k) −
k−d∗
j

m=k+1−d+
j
xt
j(m)Qjxj(m)
(6.80)

236
Chapter 6. Interconnected Time-Delay Systems
Since
k−1

m=k+1−dj(k+1)
xt
j(m)Qjxj(m) =
k−1

m=k+1−d∗
j
xt
j(m)Qjxj(m)
+
k−d∗
j

m=k+1−dj(k+1)
xt
j(m)Qjxj(m)
≤
k−1

m=k+1−dj(k)
xt
j(m)Qjxj(m) +
k−d∗
j

m=k+1−d+
j
xt
j(m)Qjxj(m)
(6.81)
then using (6.81) into (6.80) and manipulating, we reach
ΔVj(k)
≤
[Ajxj(k) + Djxj(k −dj(k)) + gj]tPj
×
[Ajxj(k) + Djxj(k −dj(k)) + gj]
+
xt
j(k)[(d+
j −d∗
j + 1)Qj −Pj]xj(k)
−
xt
j(k −dj(k))Qjxj(k −dj(k))
=
ξt
j(k) Ξj ξj(k)
(6.82)
where
Ξj
=
⎡
⎣
At
jPjAj + βjQj −Pj
At
jPjDj
At
jPj
•
Dt
jPjDj −Qj
Dt
jPj
•
•
Pj
⎤
⎦,
ξj(k)
=
 xt
j(k)
xt
j(k −d(k))
gt
j(k, x(k), x(k −d(k)))t t(6.83)
The sufﬁcient condition of stability ΔVj(k) < 0 implies that Ξj < 0. By
resorting to the S-procedure [29], inequalities (6.77) and (6.82) can be rewritten
together as
Pj > 0, ωj ≥0,
⎡
⎢⎢⎢⎢⎣
At
jPjAj + βjQj
−Pj + ωjφ2
jGt
jGj
At
jPjDj
At
jPj
•
Dt
jPjDj −Qj
+ωjψ2
j Gt
djGdj
Dt
jPj
•
•
Pj −ωjIj
⎤
⎥⎥⎥⎥⎦
< 0
(6.84)
which describes nonstrict LMIs since ωj ≥0. Recall from [29] that minimiza-
tion under nonstrict LMIs corresponds to the same result as minimization under

6.4. Interconnected Discrete-Time-Delay Systems
237
strict LMIs when both strict and nonstrict LMI constraints are feasible. More-
over, if there is a solution for (6.84) for ωj = 0, there also will be a solution
for some ωj > 0 and sufﬁciently small φj, ψj. Therefore, we safely replace
ωj ≥0 by ωj > 0. Equivalently, we may further rewrite (6.84) in the form
¯Pj > 0,
⎡
⎢⎢⎢⎢⎣
At
j ¯PjAj + βj ¯Qj−
¯Pj + φ2
jGt
jGj
At
j ¯PjDj
At
j ¯Pj
•
Dt
j ¯PjDj −¯Qj
+ψ2
j Gt
djGdj
Dt
j ¯Pj
•
•
¯Pj −Ij
⎤
⎥⎥⎥⎥⎦
< 0
(6.85)
where ¯Pj
=
ω−1
j
Pj,
¯Qj
=
ω−1
j
Qj. Using the linearizations Yj =
¯P−1
j
, Wj = ¯P−1
j
¯Qj ¯P−1
j
with δj = φ−2
j
and νj = ψ−2
j , multiplying by ωj then
pre- and postmultiplying by ¯P−1
j
with some arrangement, we express (6.85) in
the form (6.78). Robust stability of the nonlinear interconnected system (6.72)
under the constraint (6.73) with maximal φj, ψj is thus established.
Remark 6.4.4 Theorem 6.4.3 characterizes the local conditions for delay-
dependent subsystem stability by resorting to a convenient LKF. The delay-
dependence enters through the factor βj for subsystem j. In the literature,
there are more elaborate and efﬁcient LKFs (see [78, 79]), to achieve delay-
dependent stability conditions for discrete-time systems by adding more ap-
propriate terms. However, the selected LKF nicely paves the way to feedback
stabilization by simple convex analysis within the interconnected framework.
In addition, note that for all possible nonlinear perturbations g(k, 0, 0) = 0
and x = 0 is an equilibrium of system (6.72) for d(k) ≥0. Therefore in the
light of [348], the global asymptotic stable is guaranteed.
In the next sections, we consider the decentralized feedback stabilization for in-
terconnected system (6.72) within LMI-based formulation. We will be looking
for a feedback controller that robustly stabilizes Σ. The main trust is to guaran-
tee that local closed-loop subsystems is delay-dependent asymptotically stable
for all possible nonlinear interconnections satisfying (6.75). In this way, the lo-
cal controllers stabilize the linear part of Σ and, at the same time, maximize its
tolerance to uncertain nonlinear interconnections and perturbations. We start
with state feedback stabilization by assuming that all local state variables are
measurable and accessible to the local controllers.

238
Chapter 6. Interconnected Time-Delay Systems
6.4.3
State feedback design
Now, we examine the application of a linear local feedback controller of the
form
uj(k) = Kj xj(k)
(6.86)
to system (6.72), where Kj ∈ℜpj×nj is a constant gain matrix. Substituting
(6.86) into (6.74) yields:
Σs : xj(k + 1) = Ajsxj(k) + Djxj(k −dj(k)) + gj(k, x(k), x(k −d(k)))
yj(k) = Cjsxj(k)
(6.87)
Ajs = Aj + BjKj,
Cjs = Cj + HjKj
(6.88)
A direct application of Theorem 6.4.3 leads to the following optimization
problem:
min
Yj,Wj,δj,νj δj + νj
subject to :
⎡
⎢⎢⎢⎢⎢⎢⎣
−Yj + βjWj
0
0
YjAt
js
YjAt
js
YjGt
j
•
−Wj
YjGt
dj
YjDt
j
YjDt
j
0
•
•
−νjIj
0
0
0
•
•
•
Ij −Yj
0
0
•
•
•
•
−Yj
0
•
•
•
•
•
−δjIj
⎤
⎥⎥⎥⎥⎥⎥⎦
< 0
(6.89)
To put inequality (6.89) in an LMI setting, we introduce the variable KjYj =
Mj. This gives in turn the following LMIs for j = 1, .., N:
min
Yj,Wj,Mj,δj,νj δj + νj
subject to :
⎡
⎢⎢⎢⎢⎢⎢⎣
−Yj + βjWj
0
0
YjAt
j + MjBt
j
YjAt
j + MjBt
j
YjGt
j
•
−Wj
YjGt
dj
YjDt
j
YjDt
j
0
•
•
−νjIj
0
0
0
•
•
•
Ij −Yj
0
0
•
•
•
•
−Yj
0
•
•
•
•
•
−δjIj
⎤
⎥⎥⎥⎥⎥⎥⎦
< 0
(6.90)
and thus the following theorem is established.

6.4. Interconnected Discrete-Time-Delay Systems
239
Theorem 6.4.5 Given the delay sample number βj. System (6.72) is robustly
delay-dependent asymptotically stabilizable by control law (6.86) if there exist
matrices 0 < Yt
j = Yj ∈ℜnj×nj, 0 < Wt
j = Wj ∈ℜnj×nj, Mj, and
scalars δj > 0, νj > 0 such that the convex optimization problem (6.90) has a
feasible solution. The controller gain is given by Kj = MjY−1
j .
6.4.4
Bounded state feedback design
Following the approach of [28, 348], we consider hereafter the case of local
state feedback control with bounded gain matrix Kj of the form Kt
j Kj
<
κj I, with κj > 0. Since Kj = MjY−1
j
this condition corresponds to the
additional constraints on the component matrices Mj and Y−1
j
by setting
Mt
j Mj
<
μjI,
μj > 0,
Y −1
<
σj I,
σj > 0, j = 1, .., N. In
turn, these are equivalent to the LMIs
 −μj Ij
Mt
j
•
−Ij

< 0,
 −σj Ij
Ij
•
−Yj

< 0
(6.91)
In a similar way, in order to guarantee desired values (φj, ψj) of the bounding
factors (δj, νj), we recall that φ−2
j
= δj, ψ−2
j
= νj. Thus we require
δj −
1
φ2
j
< 0 , νj −
1
ψ2
j
< 0
(6.92)
Incorporating the foregoing modiﬁcations into the present analysis leads to es-
tablishing the following convex optimization problem over LMIs for the local
subsystem j:
min
Yj,Wj,Mj,δj,νj,μj,σj δj + νj + μj + σj
subject to :
⎡
⎢⎢⎢⎢⎢⎢⎣
−Yj + βjWj
0
0
YjAt
j + MjBt
j
YjAt
j + MjBt
j
YjGt
j
•
−Wj
YjGt
dj
YjDt
j
YjDt
j
0
•
•
−νjIj
0
0
0
•
•
•
Ij −Yj
0
0
•
•
•
•
−Yj
0
•
•
•
•
•
−δjIj
⎤
⎥⎥⎥⎥⎥⎥⎦
< 0
δj −
1
φ2
j
< 0 , νj −
1
ψ2
j
< 0
 −μj Ij
Mt
j
•
−Ij

< 0,
 −σj Ij
Ij
•
−Yj

< 0
(6.93)

240
Chapter 6. Interconnected Time-Delay Systems
Hence, the following theorem summarizes the main result.
Theorem 6.4.6 Given the delay sample number βj and the bounds φj, ψj.
System (6.72) is robustly delay-dependent asymptotically stabilizable by con-
trol law (6.86) with constrained feedback gains and bounding factors if there
exist matrices 0 < Yt
j = Yj ∈ℜnj×nj, 0 < Wt
j = Wj ∈ℜnj×nj, Mj
and scalars δj > 0, νj > 0, μj > 0, σj > 0 such that the convex opti-
mization problem (6.93) has a feasible solution. The controller gain is given by
Kj = MjY−1
j .
6.4.5
Resilient state feedback design
We now address the performance deterioration issue by considering that the
actual linear local state feedback controller has the following form:
uj(k) = [Kj + ΔKj] xj(k)
(6.94)
where Kj ∈ℜpj×nj is a constant gain matrix and ΔKj is an additive gain
perturbation matrix represented by
ΔKj
=
Mj Δj Nj,
Δj ∈Δ := {Δj : Δt
jΔj ≤I}
(6.95)
The application of control law (6.94) to system (6.74) yields the perturbed
closed-loop system
Σp :
xj(k + 1)
=
(Ajs + BjΔKj)xj(k) + Djxj(k −dj(k))
+
gj(k, x(k), x(k −d(k)))
yj(k)
=
Cjsxj(k)
(6.96)
Ajs
=
Aj + BjKj,
Cjs = Cj + HjKj + Mj Δj Nj
(6.97)
For simplicity in exposition, we let Υj = YjAt
js + Yj(BjΔKj)t. It follows
by applying Theorem 6.4.3 to system (6.97), we obtain the following convex
problem:
min
Yj,Wj,δj,νj
δj + νj
subject to :
⎡
⎢⎢⎢⎢⎢⎢⎣
−Yj + βjWj
0
0
Υj
Υj
YjGt
j
•
−Wj
YjGt
dj
YjDt
j
YjDt
j
0
•
•
−νjIj
0
0
0
•
•
•
Ij −Yj
0
0
•
•
•
•
−Yj
0
•
•
•
•
•
−δjIj
⎤
⎥⎥⎥⎥⎥⎥⎦
< 0 (6.98)

6.4. Interconnected Discrete-Time-Delay Systems
241
which we seek its feasibility over all possible perturbations Δj ∈Δ. In order to
convexify inequality (6.98) and at the same time bypass the exhaustive search
over the perturbation set Δ, we manipulate inequality of (6.98) with the aid of
Inequality 1 in the Appendix to reach
⎡
⎢⎢⎢⎢⎢⎢⎣
−Yj + βjWj
0
0
YjAt
js
YjAt
js
YjGt
j
•
−Wj
YjGt
dj
YjDt
j
YjDt
j
0
•
•
−νjIj
0
0
0
•
•
•
Ij −Yj
0
0
•
•
•
•
−Yj
0
•
•
•
•
•
−δjIj
⎤
⎥⎥⎥⎥⎥⎥⎦
+
⎡
⎢⎢⎢⎢⎢⎢⎣
0
0
0
BjMj
0
0
⎤
⎥⎥⎥⎥⎥⎥⎦
Δj
⎡
⎢⎢⎢⎢⎢⎢⎣
YjN t
j
0
0
0
0
0
⎤
⎥⎥⎥⎥⎥⎥⎦
t
+
⎡
⎢⎢⎢⎢⎢⎢⎣
YjN t
j
0
0
0
0
0
⎤
⎥⎥⎥⎥⎥⎥⎦
Δt
j
⎡
⎢⎢⎢⎢⎢⎢⎣
0
0
0
BjMj
0
0
⎤
⎥⎥⎥⎥⎥⎥⎦
t
+
⎡
⎢⎢⎢⎢⎢⎢⎣
0
0
0
0
BjMj
0
⎤
⎥⎥⎥⎥⎥⎥⎦
Δj
⎡
⎢⎢⎢⎢⎢⎢⎣
YjN t
j
0
0
0
0
0
⎤
⎥⎥⎥⎥⎥⎥⎦
t
+
⎡
⎢⎢⎢⎢⎢⎢⎣
YjN t
j
0
0
0
0
0
⎤
⎥⎥⎥⎥⎥⎥⎦
Δt
j
⎡
⎢⎢⎢⎢⎢⎢⎣
0
0
0
0
BjMj
0
⎤
⎥⎥⎥⎥⎥⎥⎦
t
(6.99)
which can be overbounded as
≤
⎡
⎢⎢⎢⎢⎢⎢⎣
−Yj + Wj
0
0
YjAt
js
YjAt
js
YjGt
j
•
−Wj
YjGt
dj
YjDt
j
YjDt
j
0
•
•
−νjIj
0
0
0
•
•
•
Ij −Yj
0
0
•
•
•
•
−Yj
0
•
•
•
•
•
−δjIj
⎤
⎥⎥⎥⎥⎥⎥⎦

242
Chapter 6. Interconnected Time-Delay Systems
+
ηaj
⎡
⎢⎢⎢⎢⎢⎢⎣
0
0
0
BjMj
0
0
⎤
⎥⎥⎥⎥⎥⎥⎦
⎡
⎢⎢⎢⎢⎢⎢⎣
0
0
0
BjMj
0
0
⎤
⎥⎥⎥⎥⎥⎥⎦
t
+
η−1
aj
⎡
⎢⎢⎢⎢⎢⎢⎣
YjN t
j
0
0
0
0
0
⎤
⎥⎥⎥⎥⎥⎥⎦
⎡
⎢⎢⎢⎢⎢⎢⎣
YjN t
j
0
0
0
0
0
⎤
⎥⎥⎥⎥⎥⎥⎦
t
+ ηcj
⎡
⎢⎢⎢⎢⎢⎢⎣
0
0
0
0
BjMj
0
⎤
⎥⎥⎥⎥⎥⎥⎦
⎡
⎢⎢⎢⎢⎢⎢⎣
0
0
0
0
BjMj
0
⎤
⎥⎥⎥⎥⎥⎥⎦
t
+
η−1
cj
⎡
⎢⎢⎢⎢⎢⎢⎣
YjN t
j
0
0
0
0
0
⎤
⎥⎥⎥⎥⎥⎥⎦
⎡
⎢⎢⎢⎢⎢⎢⎣
YjN t
j
0
0
0
0
0
⎤
⎥⎥⎥⎥⎥⎥⎦
t
:=
 Π1j
Π2j
•
Π3j

<
0
(6.100)
for some scalars ηaj > 0, ηcj > 0, where
Π1j
=
 −Yj + βjWj + η−1
aj YjN t
jNjYj + η−1
cj YjN t
jNjYj
0
•
−Wj

,
Π2j
=

0
YjAt
j + YjKt
jBt
j
YjAt
j + YjKt
jBt
j
YjGt
j
YjGt
dj
YjDt
j
YjDt
j
0

,
Π3j
=
Blockdiag[Π31j, Π32j],
Π31j
=
Blockdiag[−νjIj, Ij −Yj + ηajBjMjMt
jBt
j],
Π32j
=
Blockdiag[−Yj + ηcjBjMjMt
jBt
j, −δjIj]
(6.101)
Introducing the change of variables
KjYj = Lj, Zaj = ηajYjN t
j, Zcj = ηcjYjN t
j, ¯Zj = [Zaj,
Zcj]
This will eventually cast inequalities (6.100)-(6.101) into the following LMI
format:
⎡
⎣
−Yj + βjWj
0
St
j
•
−Wj
0
•
•
−Rj
⎤
⎦
<
0
(6.102)

6.4. Interconnected Discrete-Time-Delay Systems
243
where
Sj
=
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
0
YjGt
dj
YjAt
j + Lt
jBt
j
YjDt
j
0
0
YjAt
j + Lt
jBt
j
YjDt
j
0
0
YjGt
j
0
¯Zt
0
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
,
Rj
=
Blockdiag[R1j
R2j] > 0, ηj = Blockdiag[ηaj
ηcj],
R1j
=
⎡
⎣
−νjIj
0
0
•
Ij −Yj
BjMj
•
•
−ηajIj
⎤
⎦,
R2j
=
⎡
⎢⎢⎣
−Yj
BjMj
0
0
•
−ηcjIj
0
0
•
•
−δjIj
0
•
•
•
−ηj
⎤
⎥⎥⎦
(6.103)
The foregoing analysis has established the following theorem.
Theorem 6.4.7 Given the delay sample number βj. System (6.72) is robustly
delay-dependent asymptotically stabilizable by the actual control law (6.94)
for all possible gain variations (6.95) if there exist matrices 0 < Yt
j = Yj ∈
ℜnj×nj,
0 < Wt
j = Wj ∈ℜnj×nj,
Lj, and scalars δj > 0,
νj >
0, ηaj, ηcj, Zaj, Zcj such that the following convex optimization problem
min
Yj,Wj,Lj,δj,νj,ηaj,ηcj,Zaj,Zcj
δj + νj + ηaj + ηcj
subject to :
Yj > 0, Wj > 0 and (6.102) −(6.103)
has a feasible solution. The controller gain is given by Kj = LjY−1
j .
Had we taken the modiﬁcations made previously to constrain the local state
feedback gains, we would have reached an alternative convex optimization
problem over LMIs summarized by the following theorem.
Theorem 6.4.8 Given the delay sample number βj and the bounds φj, ψj.
System (6.72) is robustly delay-dependent asymptotically stabilizable by the
actual control law (6.94) for all possible gain variations (6.95) if there exist
matrices 0 < Yt
j = Yj ∈ℜnj×nj, 0 < Wt
j = Wj ∈ℜnj×nj, Lj, and scalars

244
Chapter 6. Interconnected Time-Delay Systems
δj > 0, νj > 0, μj > 0, σj > 0, ηaj, ηcj, Zaj, Zcj such that the following
convex optimization problem
min
Yj,Wj,Lj,δj,νj,μj,σj,ηaj,ηcj,Zaj,Zcj
δj + νj + ηaj + ηcj + μj + σj
subject to :
Yj > 0, Wj > 0 and (6.102) −(6.103)
δj −
1
φ2 < 0 , νj −
1
ψ2
j
< 0
 −μj I
Mt
j
•
−Ij

< 0 ,
 −σj Ij
Ij
•
−Yj

< 0
has a feasible solution. The controller gain is given by Kj = LjY−1
j .
Remark 6.4.9 It should be observed that Theorems 6.4.5-6.4.8 provide a
complete decoupled set of LMI-based state feedback design algorithms for a
class of interconnected discrete-time systems with unknown-but-bounded de-
lays and quadratically bounded nonlinearities and perturbations. It is signiﬁ-
cant to record that Theorem 6.4.8 is new addition to the resilient control theory
[258, 389]. Indeed, these algorithms assume the accessibility of local states.
In the next section, we drop the assumption on complete accessibility of local
state-variables and consider the availability of local output measurements. We
focus on the design of a local dynamic output feedback stabilization scheme.
6.4.6
Output feedback stabilization
In this part, we consider the design of a local dynamic output feedback stabi-
lization scheme of the Luenberger-type:
zj(k + 1)
=
Ajzj(k) + Bjuj(k) + Koj[yj(k) −wj(k)]
wj(k)
=
Cjz(k) + Hjuj(k)
uj(k)
=
Kcjzj(k)
(6.104)
where the matrices Koj ∈ℜnj×qj and Kcj ∈ℜpj×nj are the local unknown
observer and state feedback gain matrices to be determined such that the local
closed-loop controlled system achieves delay-dependent asymptotic stability.
We proceed by deﬁning the state error ej(k) = xj(k) −zj(k) and obtain
from (6.72) and (6.104) the local error system
ej(k + 1)
=
[Aj −KjCj]ej(k) + Djxj(k −dj(k))
+
gj(k, x(k), x(k −d(k)))
(6.105)

6.4. Interconnected Discrete-Time-Delay Systems
245
By combining systems (6.72) and (6.105), we get the augmented system
ζj(k + 1)
=
Aj ζj(k) + Dj ζj(k −dj(k)) + ¯gj(k, x(k), x(k −d(k)))
(6.106)
where
ζj(k)
=
 xj(k)
ej(k)

∈ℜ2nj,
¯gj(k, x(k), x(k −d(k)))
=
 gj(k, x(k), x(k −d(k)))
gj(k, x(k), x(k −d(k)))

,
Aj
=
 Aj + BjKcj
−BjKcj
0
Aj −KojCj

,
Dj
=
 Dj
0
Dj
0

(6.107)
Let
¯Gj
=
 2Gj
0
0
0

,
¯Gdj =
 2Gdj
0
0
0

,
¯Yj
=
 Ycj
0
0
Yoj

,
¯
Wj =
 Wcj
0
0
Woj

,
ˆνj
=
Blockdiag[νcj, νoj], ˆδj = Blockdiag[δcj, δoj]
(6.108)
where Ycj, Wcj, Yoj, Woj ∈ℜnj×nj be symmetric and positive-deﬁnite matri-
ces. It follows from Theorem 6.4.3 that the robust delay-dependent asymptotic
stability of the augmented system (6.106) is guaranteed by the solution such
that the following convex optimization problem
min
¯Yj, ¯
Wj,ˆνj,ˆδj
ˆνj + ˆδj
(6.109)
subject to :
Ycj > 0, Yoj > 0, Wcj > 0, Woj > 0
⎡
⎢⎢⎢⎢⎢⎢⎢⎣
−¯Yj + βj ¯
Wj
0
0
¯YjAt
j
¯YjAt
j
¯Yj ¯Gt
j
•
−¯
Wj
¯Yj ¯Gt
dj
¯YjDt
j
¯YjDt
j
0
•
•
−ˆνjIj
0
0
0
•
•
•
Ij −¯Yj
0
0
•
•
•
•
−¯Yj
0
•
•
•
•
•
−ˆδjIj
⎤
⎥⎥⎥⎥⎥⎥⎥⎦
<0
(6.110)
is feasible. Mathematical manipulations of inequality (6.110) using (6.107)-
(6.108) lead to the following theorem.

246
Chapter 6. Interconnected Time-Delay Systems
Theorem 6.4.10 System (6.106) is robustly delay-dependent asymptotically
stable if there exist matrices 0 < Yt
cj = Ycj ∈ℜnj×nj, 0 < Yt
oj = Yoj ∈
ℜnj×nj, 0 < Wt
cj = Wcj ∈ℜnj×nj, 0 < Wt
oj = Woj ∈ℜnj×nj, Scj ∈
ℜpj×nj, Soj ∈ℜnj×nj, Sfj ∈ℜpj×nj and scalars δcj > 0, νcj > 0, δoj >
0, νoj > 0 such that the following convex optimization problem
min
Ycj,Yoj,Wcj,Woj,Scj,Soj,Sfj,δcj,δoj,νcj,νoj
δcj + δoj + νcj + νoj (6.111)
subject to :
Ycj > 0, Yoj > 0, Wcj > 0, Woj > 0,
 Ξcj
Ξdj
•
Ξoj

<
0
Ξcj =

Ξcj1
Ξcj2

Ξcj1 =
⎡
⎢⎢⎢⎢⎢⎢⎣
−Ycj + βjWcj
0
0
•
−Yoj + Woj
0
•
•
−Wcj
•
•
•
•
•
•
•
•
•
⎤
⎥⎥⎥⎥⎥⎥⎦
Ξcj2 =
⎡
⎢⎢⎢⎢⎢⎢⎣
0
0
0
0
0
0
0
2YcjGt
dj
0
−Woj
0
0
•
−νcjIj
0
•
•
−νojIj
⎤
⎥⎥⎥⎥⎥⎥⎦
Ξdj =

Ξdj1
Ξdj2

Ξdj1 =
⎡
⎢⎢⎢⎢⎢⎢⎣
YcjAt
j + St
cjBt
j
0
YcjAt
j + St
cjBt
j
−St
fjBt
j
YojAt
j −St
oj
−St
fjBt
j
YcjDt
j
YcjDt
j
YcjDt
j
0
0
0
0
0
0
0
0
0
⎤
⎥⎥⎥⎥⎥⎥⎦
Ξdj2 =
⎡
⎢⎢⎢⎢⎢⎢⎣
0
2YcjGt
j
0
YojAt
j −St
oj
0
0
YcjDt
j
0
0
0
0
0
0
0
0
0
0
0
⎤
⎥⎥⎥⎥⎥⎥⎦
(6.112)

6.4. Interconnected Discrete-Time-Delay Systems
247
Ξoj = Blockdiag

Ξoj1
Ξoj2

Ξoj1 = Blockdiag

Ij −Ycj
Ij −Yoj
−Ycj

Ξoj2 = Blockdiag

−Yoj
−δcjIj
−δojIj

(6.113)
is feasible. Moreover, the gains are given by Kcj
= ScjY−1
cj ,
Koj
=
SojY−1
oj C†
j, where C†
j = Ct
j(CjCt
j)−1 is the pseudo-inverse of Cj.
Remark 6.4.11 It can be argued that the block-diagonal form of the Lyapunov
matrices (6.108) is not restrictive since it aims at developing a convenient non-
iterative computational algorithm while maintaining all the computations at
the subsystem level. It has been widely used in dynamic output-feedback design
[28, 346]. In the case of static output feedback the problem can be transformed
into an LMI problem by a simple change of variables [82]. In the case of dy-
namic output feedback the problem becomes far more complex and, in addition,
a general dynamic output feedback design will eventually lead to nonlinear ma-
trix inequalities.
6.4.7
Resilient output feedback stabilization
Next we address the resilience problem of output feedback stabilization. For
this purpose, we re-express the controller (6.104) into the form
zj(k + 1)
=
Ajzj(k) + Bjuj(k) + [Koj + ΔKoj][yj(k) −wj(k)]
wj(k)
=
Cjz(k) + Hjuj(k)
uj(k)
=
[Kcj + ΔKcj]zj(k)
(6.114)
where the matrices Koj and Kcj are the local unknown gain parameters to be
determined such that the local closed-loop controlled system achieves delay-
dependent asymptotic stability and ΔKoj, ΔKcj are gain perturbations repre-
sented by
ΔKoj = MojΔfjNoj, ΔKcj = McjΔdjNcj,
Δfj, Δdj, ∈Δ := {Δj : Δt
jΔj ≤I}
(6.115)
Following the analysis above, the augmented system becomes
ζj(k + 1)
=
[Aj + ΔAj] ζj(k) + Dj ζj(k −dj(k))
+ ¯gj(k, x(k), x(k −d(k)))
=
¯
Aj ζj(k) + Dj ζj(k −dj(k)) + ¯gj(k, x(k), x(k −d(k)))
(6.116)

248
Chapter 6. Interconnected Time-Delay Systems
where ζj(k), Aj, Dj, ¯gj(k, x(k), x(k −d(k))) are given by (6.107) and
ΔAj =
 BjΔKcj
−BjΔKcj
0
−ΔKojCj

(6.117)
In light of the foregoing procedures, it follows from Theorem 6.4.3 that the
robust delay-dependent asymptotic stability of the augmented system (6.116)
is guaranteed by the feasible solution of the following convex optimization
problem:
min
¯Yj, ¯
Wj,ˆνj,ˆδj
ˆνj + ˆδj
(6.118)
subject to :
Ycj > 0, Yoj > 0, Wcj > 0, Woj > 0
⎡
⎢⎢⎢⎢⎢⎢⎢⎣
−¯Yj + βj ¯
Wj
0
0
¯Yj ¯
At
j
¯Yj ¯
At
j
¯Yj ¯Gt
j
•
−¯
Wj
¯Yj ¯Gt
dj
¯YjDt
j
¯YjDt
j
0
•
•
−ˆνjIj
0
0
0
•
•
•
Ij −¯Yj
0
0
•
•
•
•
−¯Yj
0
•
•
•
•
•
−ˆδjIj
⎤
⎥⎥⎥⎥⎥⎥⎥⎦
< 0 (6.119)
In order to convexify (6.119) we invoke Inequality 1 in the Appendix and
manipulate using (6.113) to reach
 Ξcj
Ξdj
•
Ξoj

+ Υj1Δt
djΥt
j2 + Υj2ΔdjΥt
j1 +
Υj3Δt
fjΥt
j4 + Υj4ΔfjΥt
j3 ≤
 Ξcj
Ξdj
•
Ξoj

+ ηjgΥj1Υt
j1 + η−1
jg Υj2Υt
j2 +
ηjfΥj3Υt
j3 + η−1
jf Υj4Υt
j4 <
0
(6.120)
for some scalars ηjg > 0, ηjf > 0 and where
Υt
j1 = [NcjYcj, −NcjYoj, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Υt
j2 = [0, 0, 0, 0, 0, 0, Mt
cjBt
j, 0, Mt
cjBt
j, 0, 0, 0]
Υt
j3 = [0, −NojCjYoj, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Υt
j4 = [0, 0, 0, 0, 0, 0, 0, Mt
oj, 0, 0, 0, 0]
(6.121)

6.4. Interconnected Discrete-Time-Delay Systems
249
We introduce the matrix notations
Zmj
=
ηjgYcjN t
cj , Znj = −ηjgYojN t
cj , Zpj = ηjfYcjCt
jN t
oj,
Ξsj
=
⎡
⎢⎢⎢⎢⎢⎢⎣
Zmj
0
0
0
−Znj
0
Zpj
0
0
BjMcj
0
0
0
0
0
0
0
0
0
0
0
0
0
0
⎤
⎥⎥⎥⎥⎥⎥⎦
,
Ξvj
=
Blockdiag [−ηjg, −ηjg, −ηjf, −ηjf]
(6.122)
The following theorem summarizes the main result about resilient output feed-
back stabilization.
Theorem 6.4.12 The augmented system (6.116) is robustly delay-dependent
asymptoticly stable if there exist matrices 0 < Yt
cj = Ycj ∈ℜnj×nj, 0 <
Yt
oj = Yoj ∈ℜnj×nj, 0 < Wt
cj = Wcj ∈ℜnj×nj, 0 < Wt
oj = Woj ∈
ℜnj×nj, Scj ∈ℜpj×nj, Soj ∈ℜnj×nj, Sfj ∈ℜpj×nj, Zmj ∈ℜnj, Zpj ∈
ℜnj, Znj ∈ℜnj and scalars δcj > 0, νcj > 0, δoj > 0, νoj > 0 such that
the following convex optimization problem
min
Ycj,Yoj,Wcj,Woj,Scj,Soj,Sfj,Zmj,Znj,Zpj,δcj,δoj,νcj,νoj δcj + δoj + νcj + νoj
(6.123)
subject to :
Ycj > 0, Yoj > 0, Wcj > 0, Woj > 0,
⎡
⎣
Ξcj
Ξdj
Ξsj
•
Ξoj
0
•
•
Ξvj
⎤
⎦< 0
(6.124)
is feasible. Moreover, the gains are given by Kcj
= ScjY−1
cj ,
Koj
=
SojY−1
oj C†
j.
Remark 6.4.13 It should be pointed out that the results reported here before
represent a major extension over [28, 348] since they either dealt with delay-
free systems [348] or targeted independent stability and stabilization [28].
Here, we essentially dealt with systems composed of linear discrete-time sub-
systems coupled by static nonlinear interconnections satisfying quadratic con-
straints and subject to unknown-but-bounded state delays. Subsequently we
developed delay-dependent robust stability and feedback stabilization results.
To attain decentralized computation, robust controllers based on state feed-
back and dynamic output feedback were designed on the subsystem level with

250
Chapter 6. Interconnected Time-Delay Systems
guaranteed overall desired system performance and in addition, maximized the
bounds of unknown interconnection terms. Moreover, we incorporated additive
gain perturbations to establish new resilient feedback stabilization schemes for
discrete-time-delay systems.
6.4.8
Illustrative example 6.4
To illustrate the usefulness of the results of the developed approach, let us con-
sider the following interconnected time-delay system which is composed of
three subsystems. With reference to (6.74), the data values are:
Subsystem 1
:
A1
=
 0.0
0.1
0.5
−0.5

, D1 =
 0.1
0.0
0.01
0.1

,
B1
=

0
0.05

, Ct
1 =
 0.4
0.6

, H1 = 1
Subsystem 2
:
A2
=
⎡
⎣
0
0
0.1
0.1
−0.6
0.1
0.3
0.7
0.9
⎤
⎦, D2 =
⎡
⎣
0.0
0.2
0.0
0.0
0.1
−0.2
0.1
−0.3
−0.2
⎤
⎦,
B2
=
⎡
⎣
0.03
0
0.04
⎤
⎦, H2 = 0.7, C2 =

0.3
0.5
0.2

Subsystem 3
:
A3
=

0.0
0.2
−0.6
0.6

, D3 =
 0.0
0.2
0.1
−0.1

,
B3
=
 0.1
0.1

, Ct
3 =
 0.5
0.5

, H3 = 0.5,
x1(k)
=

x11(k)
x12(k)
t ,
x2(k)
=

x21(k)
x22(k)
x23(k)
t ,
x3(k)
=

x31(k)
x32(k)
t

6.4. Interconnected Discrete-Time-Delay Systems
251
In terms of the overall state vector x(k) =

xt
1(k)
xt
2(k)
xt
3(k)
t ∈ℜ7,
the subsystem interconnections are given by
g1(., ., .)
=
0.1 cos(x22) U2,5 x(k) + 0.15 cos(x31) U2,5 x(k −d1(k)),
2
≤
d1(k) ≤6,
g2(., ., .)
=
0.3 cos(x21) U3,5 x(k) + 0.2 cos(x11) U3,5 x(k −d2(k)),
3
≤
d2(k) ≤7,
g3(., ., .)
=
0.2 cos(x12) U2,5 x(k) + 0.25 cos(x23) U2,5 x(k −d1(k)),
3
≤
d3(k) ≤8,
U2,5
=
 1
1
1
1
1
1
1
1
1
1
1
1
1
1

, U3,5 =
⎡
⎣
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
⎤
⎦
Using MATLAB R⃝-LMI solver, it is found that the feasible solution of Theo-
rem 6.4.3 is given by
δ1
=
1.5365, ν1 = 1.3982, Y1 =
 1.629
0.315
•
1.743

,
W1
=
 0.896
0.234
•
1.137

,
δ2
=
1.7025, ν2 = 1.6544, Y1 =
⎡
⎣
3.444
1.019
1.231
•
2.381
1.123
•
•
4.075
⎤
⎦,
W2
=
⎡
⎣
4.112
1.156
1.765
•
3.116
2.087
•
•
3.198
⎤
⎦,
δ3
=
1.4784, ν3 = 1.2986, Y1 =
 1.933
0.514
•
1.688

,
W3
=
 1.632
0.777
•
1.729

which illustrates the delay-dependent asymptotic stability. Proceeding to the
feedback stabilization schemes, the feasible solution of Theorem 6.4.5 is sum-

252
Chapter 6. Interconnected Time-Delay Systems
marized by
δ1 = 1.3614, ν1 = 1.8222, K1 =

−29.2634
−23.1445

,
||K1|| = 37.3097
δ2 = 1.7025, ν2 = 1.6544, K2 =

−26.1974
−27.3162
−24.6767

,
||K2|| = 45.1281
δ3 = 1.4784, ν3 = 1.2986, K3 =

−25.2634
−19.1445

,
||K3|| = 31.6978
Observe that the gains K1, .., K3 are relatively high. Considering Theorem
6.4.6 and given the tolerance bounds φ2
1 = 1.64,
ψ2
1
= 1.55,
φ2
2 =
1.85, ψ2
2 = 1.75, φ2
3 = 1.74, ψ2
3 = 1.95, the feasible solution is attained at
δ1 = 0.695, ν1 = 0.714, K1 =

−5.0732
−3.6114

,
||K1|| = 6.2273
δ2 = 0.632, ν2 = 0.644, K2 =

−3.1974
−2.3162
−2.9314

,
||K2|| = 4.9174
δ3 = 0.708, ν3 = 0.647, K3 =

−2.2634
−1.1215

,
||K3|| = 4.9174
The great reduction in the norms of the local gain matrices is quite evident and
supports the developed approach which aims at maximizing the tolerance to
uncertain nonlinear interconnections and perturbations.
Admitting gain perturbations of the form (6.95) with M1 = [1.5 1.5], N1 =
0.3, M2 = [2.5
2.5
2.5], N2 = 0.2, M3 = [2.0
2.0], N3 = 0.25, we
move to consider Theorem 6.4.7, numerical implementation of the LMI solver
yielding the following feasible solution. Theorem 6.4.5 is summarized by
δ1 = 1.3614, ν1 = 1.8222, K1 =

−34.4265
−28.5175

,
||K1|| = 44.7038
δ2 = 1.7025, ν2 = 1.6544, K2 =

−29.1484
−27.4444
−28.7375

,
||K2|| = 49.2815
δ3 = 1.4784, ν3 = 1.2986, K3 =

−30.2474
−22.5354

,
||K3|| = 37.7194
On the other hand, considering Theorem 6.4.8 and given the tolerance bounds
φ2
1 = 1.62, ψ2
1 = 1.53, φ2
2 = 1.82, ψ2
2 = 1.73, φ2
3 = 1.71, ψ2
3 = 1.92, the

6.4. Interconnected Discrete-Time-Delay Systems
253
feasible solution is attained at
δ1
=
0.695, ν1 = 0.714, K1 =

−5.2132
−3.6224

,
||K1||
=
6.3482
δ2
=
0.632, ν2 = 0.644, K2 =

−3.2444
−2.3354
−2.9664

,
||K2||
=
4.9774
δ3
=
0.708, ν3 = 0.647, K3 =

−2.4243
−1.3235

,
||K3||
=
4.9774
Once again, the great reduction in the norms of the local gain matrices is quite
evident.
Turning to the output feedback stabilization, simulation results show that
the feasible solution of Theorem 6.4.10 is given by
δc1
=
1.6674, νc1 = 1.7713, δo1 = 2.0165, νo1 = 2.1004,
Kc1
=

−2.5953
−2.4345

, Ko1 =
 0.5030
0.0100

,
δc2
=
1.7732, νc2 = 1.8824, δo2 = 2.1365, νo2 = 2.1477,
Kc2
=

−3.7598
−1.7746
1.2324

, Ko2 =
⎡
⎣
0.4121
0.0322
0.0714
⎤
⎦,
δc3
=
1.8235, νc3 = 1.8763, δo3 = 2.1125, νo3 = 2.1016,
Kc3
=

−2.4423
−1.9876

, Ko3 =
 0.6112
0.1007

Finally, we attend to Theorem 6.4.12. By incorporating gain perturbations
of the form (6.115) with
Mo1 = [1.5 1.5], No1 = 0.3, Mo2 = [2.5 2.5 2.5], No2 = 0.2
Mo3 = [2.0 2.0], No3 = 0.25, Mt
c1 = [1.6 1.6], Nc1 = 0.4,
Mt
c2 = [2.7 2.7 2.7] Nc2 = 0.2, Mt
c3 = [2.1 2.1], Nc3 = 0.2
the feasible solution is given by
δc1
=
1.7784, νc1 = 1.8923, δo1 = 2.3355, νo1 = 2.2278,
Kc1
=

−3.6643
−2.7576

, Ko1 =
 0.7104
0.1126

,
δc2
=
1.9810, νc2 = 2.0134, δo2 = 2.5122, νo2 = 2.4234,

254
Chapter 6. Interconnected Time-Delay Systems
0
5
10
15
20
25
30
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
Time (sec)
State Response of Substsrem 1
 
 
x11(t)
x12(t)
Figure 6.1: State trajectories of subsystem 1
Kc2
=

−4.0283
−1.6648
1.4684

, Ko2 =
⎡
⎣
0.7321
0.1323
0.1705
⎤
⎦,
δc3
=
2.0135, νc3 = 1.9845, δo3 = 2.2675, νo3 = 2.5324,
Kc3
=

−2.7322
−1.8584

, Ko3 =
 0.5514
0.2004

For the purpose of illustration, we plot in Figure 6.1 through 6.4 typical closed-
loop state trajectories under the resilient output-feedback control strategy. The
plotted results illustrate the smooth behavior of the system response and the
ability of the developed controller to push the system toward settlement along
the zero level.
6.5
Overlapping Control
One of the principal objectives of robust decentralized control is to synthesize
feedback controllers under a priori guarantees of the robust stability and perfor-
mance under information structure constraints. These guarantees are achieved
by means of well-known sparse matrix forms of gain matrices. A block tridi-
agonal form (BTD) corresponds to the concept of overlapping decompositions.
A general mathematical framework for this approach has been called the Inclu-
sion Principle. This approach is useful mainly when designing decentralized
controllers for subsystems with shared parts where the states of shared parts
have no direct control input.

6.5. Overlapping Control
255
0
5
10
15
20
25
30
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
Time (sec)
State Response of Substsrem 2
 
 
x21(t)
x22(t)
Figure 6.2: First two-state trajectories of subsystem 2
0
100
200
300
400
500
600
−0.2
−0.1
0
0.1
0.2
0.3
0.4
0.5
Time (sec)
Additional State Response of Substsrem 2
 
 
x23(t)
Figure 6.3: Third state trajectory of subsystem 2

256
Chapter 6. Interconnected Time-Delay Systems
0
5
10
15
20
25
30
−0.6
−0.5
−0.4
−0.3
−0.2
−0.1
0
0.1
0.2
0.3
0.4
Time (sec)
State Response of Substsrem 3
 
 
x31(t)
x32(t)
Figure 6.4: State trajectories of subsystem 3
Robust control of linear systems with real parameter uncertainties has re-
cently attracted a lot of attention. The focus has been concentrated mainly on
systems with norm bounded arbitrarily fast time-varying parameter uncertain-
ties and polytopic uncertainties for systems with time-invariant (or constant)
parameters. A common quadratic Lyapunov function independent of uncertain
parameters is used when considering quadratic stability of the system for arbi-
trarily fast time-varying admissible uncertainties. However, this concept leads
to conservative results when considering this approach for constant uncertain-
ties. In order to reduce the conservatism of quadratic stability, the notion of
parameter-dependent Lyapunov functions was developed, i.e., quadratic Lya-
punov functions that are dependent on uncertain parameters. Moreover, the
guaranteed cost-control approach ensuring besides the robust stability an up-
per bound on a given performance has been developed.
Time-delays appear in many real world systems. The time-delays are a
source of instabilities and bad performance. This fact underlines the impor-
tance of new control design methods for time-delay systems. For continuous-
time systems, time-delay problems can be treated by the inﬁnite-dimensional
system theory, which usually leads to solutions in terms of Riccati-type partial
differential equations. They are difﬁcult to compute. Some attempts have been
realized recently to derive simple solutions to control problems by using LMIs.
As we learned before, the inclusion principle has been introduced into the
systems theory in [124, 129, 131, 324] and further extended to solve different
problems such as in [15, 16, 17]. In [19] sufﬁcient conditions were derived for
the expansion-contraction relations for a class of uncertain state-delay systems.

6.5. Overlapping Control
257
The solution of expansion relations can be performed at a general level by
using the PeanoBaker series. This section deals with overlapping controllers
for uncertain delay continuous-time systems.
6.5.1
Systems and inclusions
Consider a linear continuous-time uncertain system with state and input delay
described by the state equation
S : ˙x(t)
=
¯A(t)x(t) + ¯B(t)u(t) + ¯Ad(t)x(t −d) + ¯Bu(t)u(t −d),
y(t)
=
Cx(t),
(6.125)
x(t)
=
ϕ(t), −d ≤t ≤0
where
¯A(t)
=
A + ΔA(t), ¯B(t) = B + ΔB(t),
¯Ad(t)
=
Ad + ΔAd(t), ¯Bu(t) = Bu + ΔBu(t)
(6.126)
where x(t)
∈
ℜn,
u(t)
∈
ℜm,
y(t)
∈
ℜq,
d
>
0,
ϕ(t)
∈
ℜn denote the state, the control, the output, a point delay, and a given
vector corresponding to a continuous initial function, respectively. The set
x(t), u(s), s ∈[t −d, t], deﬁnes the complete state of the system (6.125) and
A, B, Ad, Bu, C are known constant matrices of appropriate dimensions.
Also ΔA(t), ΔB(t), ΔAd(t), ΔBu(t) are real-valued matrices of uncertain
parameters having the form
[ΔA(t) ΔB(t) ΔAd(t) ΔBu(t)] = D F(t) [E1 E2 E3 E4]
(6.127)
where D, E1, E2, E3, E4 are known constant real matrices of appropriate di-
mensions and F j×s(t) is an unknown matrix function with Lebesgue measur-
able elements satisfying
F t(t)F(t) ≤I
(6.128)
The unique solution of (6.125) for any complete initial state x(0), u(s) is given
by
x(t; ϕ(t), u(t)) = Φ(t, 0)x(0) +
 t
0
Φ(t, s) ¯A1(s)x(s −d)ds
+
 t
0
Φ(t, s)[ ¯B(s)u(s) + ¯B1(s)u(s −d)]ds
(6.129)

258
Chapter 6. Interconnected Time-Delay Systems
where Φ is the transition matrix. Extending on the overlapping concepts of
Chapter 5, we consider another system
¯S : ˙˜x(t)
=
¯˜A(t)˜x(t) + ¯˜B(t)u(t) + ¯˜Ad(t)˜x(t −d) + ¯˜Bu(t)u(t −d),
˜y(t)
=
˜C˜x(t),
(6.130)
˜x(t)
=
˜ϕ(t), −d ≤t ≤0
where
¯˜A(t)
=
˜A + Δ ˜A(t), ¯˜B(t) = ˜B + Δ ˜B(t),
¯˜Ad(t)
=
˜Ad + Δ ˜Ad(t), ¯˜Bu(t) = ˜Bu + Δ ˜Bu(t)
(6.131)
˜x(t) ∈ℜ˜n, u(t) ∈ℜm, ˜y(t) ∈ℜ˜q, and ˜ϕ(t) denote the state, the control, the
output, and a continuous initial function, respectively. Suppose that n ≤˜n, q ≤
˜q. In this regard, the set ˜x(t), u(s) with s ∈[t −d, t] deﬁnes a complete state
for (6.130). Norm-bounded uncertainties have the form
[Δ ˜A(t) Δ ˜B(t) Δ ˜Ad(t) Δ ˜Bu(t)] = ˜D ˜F(t) [ ˜E1 ˜E2 ˜E3 ˜E4]
(6.132)
where ˜D, ˜E1, ˜E2, ˜E3, ˜E4 are are known constant real matrices of appropriate
dimensions and ˜F˜i˜j(t) is an unknown matrix function with Lebesgue measur-
able elements satisfying
˜F t(t) ˜F(t) ≤I
(6.133)
The unique solution of (6.130) for any complete initial state ˜x(0), u(s) has the
form
˜x(t; ˜ϕ(t), u(t)) = ˜Φ(t, 0)˜x(0) +
 t
0
˜Φ(t, s) ¯˜A1(s)˜x(s −d)ds
+
 t
0
˜Φ(t, s)[ ¯˜B(s)u(s) + ¯˜B1(s)u(s −d)]ds
(6.134)
where ˜Φ is the transition matrix.
To establish the interlink between systems (6.125) and (6.130), we initially
denote
x(t) = x(t; ϕ(t), u(t)), ˜x(t) = ˜x(t; ˜ϕ(t), u(t))
as the formal solutions of (6.125) and (6.130) for given inputs u(t) and initial
complete states x(0), u(s) and ˜x(0), u(s), s ∈[−d, 0], respectively. Then, we
invoke the inclusion principle to develop the standard relations between the
states and the outputs. Eventually this means that systems S and ˜S are related
by the following linear transformations:
˜x(t) = V x(t),
x(t) = U ˜x(t),
˜y(t) = Ty(t),
y(t) = S˜y(t)
(6.135)

6.5. Overlapping Control
259
where
V, U = (V tV )−1V t, T, S = (T tT)−1T t
are constant full rank matrices of appropriate dimensions [124, 324].
To proceed further, we start with a quadruplet of matrices (U, V, S, T).
Therefore, the matrices ˜A, Δ ˜A(t), ˜B, Δ ˜B(t), ˜A1, Δ ˜A1(t), ˜B1, Δ ˜B1(t), and ˜C
can be described as follows:
˜A = V AU + M,
Δ ˜A(t) = V ΔA(t)U,
˜B = V B + N,
Δ ˜B = V ΔB(t),
˜A1 = V A1U + M1,
Δ ˜A1(t) = V ΔA1(t)U, (6.136)
˜B1 = V B1 + N1,
Δ ˜B1(t) = V ΔB1(t)
where M, N, M1, N1, and L are so-called complementary matrices.
Remark 6.5.1 In view of the overlapping decomposition principles [124]-
[131], it is quite frequent that the transformations (U, V, S, T) are selected
a priori to deﬁne structural relations between the state variables in both sys-
tems S and ˜S. It turns out that given these transformations, the choice of the
complementary matrices gives degrees of freedom to obtain different expanded
spaces with desirable properties [15].
The following deﬁnitions are essential in this regard.
Deﬁnition 6.5.2 A system S includes the system S, denoted by S ⊃S, if there
exists a quadruplet of constant matrices (U, V, S, T) such that UV = In, ST =
Iq, and for any initial function ϕ(t) and any ﬁxed input u(t) of S, x(t) = U ˜x(t)
and y[x(t)] = S˜y[˜x(t)] for all t. If S ⊃S holds then S is called and expansion
of S ⊃S and S ⊃S is a contraction of S ⊃S.
Deﬁnition 6.5.3 A static output feedback controller u(t) = ˜K˜y(t) for ˜S is
contractible to u(t) = Ky(t) for S if Ky(t) = ˜K˜y(t) for all t, any initial
function ϕ(t), and any ﬁxed input u(t).
6.5.2
Inclusion of linear quadratic costs
Consider the standard quadratic cost function associated with system S,
J(x, u) =
 ∞
0
[xt(t)Q∗x(t) + ut(t)R∗u(t)]dt
(6.137)
where Q∗> 0 and R∗> 0 are appropriate weighting matrices. Similarly,
introduce the quadratic cost function to be associated with system ˜S,
˜J(˜x, u) =
 ∞
0
[˜xt(t) ˜Q∗˜x(t) + ut(t) ˜R∗u(t)]dt
(6.138)

260
Chapter 6. Interconnected Time-Delay Systems
where ˜Q∗> 0 and ˜R∗> 0 are appropriate weighting matrices.
Toward our objective, we let the relation between matrices in (6.137) and
(6.138) be expressed in the form
˜Q∗= UtQ∗U + MQ∗,
˜R∗= R∗+ NR∗
(6.139)
where MQ∗and NR∗are complementary matrices. The following deﬁnitions
are appropriate hereafter.
Deﬁnition 6.5.4 A pair (S, ˜J) includes the pair (S, J), denoted by (˜S, ˜J) ⊃
(S, J), if ˜S ⊃S and J(x, u) = ˜J(˜x, u). If (S, ˜J) ⊃(S, J) holds then (˜S, ˜J) is
called an expansion of (˜S, J) and (S, J) is a contraction of (˜S, ˜J).
Deﬁnition 6.5.5 A control law u(t) = Ky(t) is said to be a quadratic guar-
anteed cost control with associated cost matrix P > 0 for the delay system
(6.125) and cost function (6.137) if the corresponding closed-loop system is
quadratically stable and the cost function satisﬁes the bound J ≤J0 for all
admissible uncertainties, that is,
d
dtxt(t)Px(t) + xt(t)[Q∗+ CtKtR∗KC]x(t) < 0
(6.140)
for all nonzero x ∈ℜn.
The following result gives sufﬁcient conditions to get a guaranteed cost con-
trol law. To simplify, the result is presented only for the problem (6.125)
and (6.137), but it evidently holds also for the expanded problem (6.130) and
(6.138). The following theorem can be easily established [255].
Theorem 6.5.6 Consider system (6.125) and quadratic cost (6.137). A static
output feedback controller u(t) = Ky(t) is a guaranteed cost controller if
there exist constant parameters μ > 0, ϵ > 0, matrices 0 < P, 0 < S, 0 <
Z ∈ℜn×n, and a matrix K ∈ℜm×q such that the following matrix inequality
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
Ψ
PBuKC
Et
1 + CtKtEt
2
In
CtKt
PAd
0
In
•
−PZP
CtKtEt
4
0
0
0
0
0
•
•
−μIj
0
0
0
0
0
•
•
•
−[Q∗]−1
0
0
0
0
•
•
•
•
−[R∗]−1
0
0
0
•
•
•
•
•
−S
Et
3
0
•
•
•
•
•
•
−ϵIj
0
•
•
•
•
•
•
•
−S−1
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
< 0
(6.141)

6.5. Overlapping Control
261
is feasible, where
Ψ := [A + BKC]tP + P[A + BKC] + PZP + (μ + ϵ)PDDtP
Moreover, the cost function given in (6.137) satisﬁes
J ≤ϕt(0)Pϕ(0) +
 0
−d
ϕt(s)[S−1 + PZP]ϕ(s)ds := J0
(6.142)
Now direct attention to the uncertain delayed system ˜S given by (6.125)(6.128)
with an associated cost function J by (6.137). Consider an expanded system ˜S
represented in (6.130)(6.133) with an associated cost function ˜J by (6.138).
We let SC denote the closed-loop system composed of the system S by (6.125)
and a static output controller K. We also let ˜SC denote a closed-loop system
for the expanded system ˜S by (6.130) with a static output controller ˜K. Our
immediate objective is to derive conditions under which ˜S ⊃S, ˜SC ⊃SC,
and (˜SC, ˜J0) ⊃(S, J0) and express the conditions in terms of complementary
matrices. The derivation of these relations led ﬁrst to the relations based on the
transition matrices as summarized by the following theorem.
Theorem 6.5.7 Consider systems (6.125)(6.128) and (6.130)(6.133). A system
˜S includes the system S if and only if
U ˜Φ(t, 0)V = Φ(t, 0),
U ˜Φ(t, s)M1V = 0,
U ˜Φ(t, s)N = 0,
U ˜Φ(t, s)N1 = 0,
SL˜Φ(t, 0)V = 0,
SL˜Φ(t, s)M1V = 0,
SL˜Φ(t, s)N = 0,
SL˜Φ(t, s)N1 = 0
(6.143)
hold for all t and s.
Proof: Let x(t) = U ˜x(t) for all t by Deﬁnition 6.5.2. On substituting (6.129)
and (6.134) into this relation and comparing both sides, we readily obtain
U ˜Φ(t, 0)V
=
Φ(t, 0), U ˜Φ(t, s) ¯˜A1(s)V = Φ(t, s) ¯A1(s),
U ˜Φ(t, s) ¯˜B(s)
=
Φ(t, s) ¯B(s), U ˜Φ(t, s) ¯˜B1(s) = Φ(t, s) ¯B1(s)
Next we get from (6.126) and (6.136) ∀t, s that
U ˜Φ(t, s) ¯˜A1(s)V = Φ(t, s) ¯A1(s) ⇐⇒U ˜Φ(t, s)M1V = 0,
U ˜Φ(t, s) ¯˜B(s) = Φ(t, s) ¯B(s) ⇐⇒U ˜Φ(t, s)N = 0,
U ˜Φ(t, s) ¯˜B1(s) = Φ(t, s) ¯B1(s) ⇐⇒U ˜Φ(t, s)N1 = 0

262
Chapter 6. Interconnected Time-Delay Systems
Setting y[x(t)] = S˜y[˜x(t)], it readily follows ∀t, s that
S ˜C ˜Φ(t, 0)V = CΦ(t, 0), S ˜C ˜Φ(t, s) ¯˜A1(s)V = CΦ(t, s) ¯A1(s),
S ˜C ˜Φ(t, s) ¯˜B(s) = CΦ(t, s) ¯B(s), S ˜C ˜Φ(t, s) ¯˜B1(s) = CΦ(t, s) ¯B1(s)
Consequently, (6.126) and (6.136) yield that
S ˜C ˜Φ(t, 0)V = CΦ(t, 0) ⇐⇒SL˜Φ(t, 0)V = 0,
S ˜C ˜Φ(t, s) ¯˜A1(s)V = CΦ(t, s) ¯A1(s) ⇐⇒SL˜Φ(t, s)M1V = 0,
S ˜C ˜Φ(t, s) ¯˜B(s) = CΦ(t, s) ¯B(s) ⇐⇒SL˜Φ(t, s)N = 0,
S ˜C ˜Φ(t, s) ¯˜B1(s) = CΦ(t, s) ¯B1(s) ⇐⇒SL˜Φ(t, s)N1 = 0
which concludes the proof. A remark is in order.
Remark 6.5.8 It is well known that to obtain a general solution for time-
varying systems is almost impossible. The problem is solved using approxi-
mations of transition matrices. However, even to compute such approximation
via PeanoBaker series is a complicated task when excluding trivial cases. In
this regard, Theorem 6.143 can be rewritten without a precise knowledge of
transition matrices only in terms of complementary matrices.
Theorem 6.5.9 Consider the systems (6.125)(6.128) and (6.130)(6.133). A
system ˜S includes the system S if and only if
UMjV = 0,
UMj−1M1V = 0,
UMj−1N = 0,
UMj−1N1 = 0,
SLMj−1V = 0,
SLMj−1M1V = 0,
SLMj−1N = 0,
SLMj−1N1 = 0
(6.144)
hold for all j = 1, 2, ..., ˜n.
Proof: On considering the transition matrix ˜Φ(t, s) of the expanded system ˜S
as a function of two variables deﬁned by the PeanoBaker series [147]
˜Φ(t, s) = I +
 t
s
¯˜A(σ1)dσ1 +
 t
s
¯˜A(σ1)
 σ1
s
¯˜A(σ2)dσ2dσ1
+
 t
s
¯˜A(σ1)
 σ1
s
¯˜A(σ2)
 σ2
s
¯˜A(σ3)dσ3dσ2dσ1 + ...
(6.145)

6.5. Overlapping Control
263
where in view of (6.126) and (6.136) we have
¯˜A(σj) = ˜A + Δ ˜A(σj) = V AU + M + V ΔA(σi)U, ∀j = 1, 2, ...
Pre- and postmultiplying both sides of ˜Φ(t, 0) by U and V after lengthy math-
ematical manipulations results in
U ˜Φ(t, 0)V = Φ(t, 0) ⇐⇒UMjV = 0, ∀j = 1, 2, ..., ns
Applying a similar process to each condition in (6.143) leads to the equivalence
relation for the corresponding condition in (6.144). This completes the proof.
Remark 6.5.10 The expansion-contraction relations are expressed in terms of
the transition matrices for continuous-time-delayed systems. This is a signiﬁ-
cant difference from the case of their discrete-time counterpart, where the gen-
eral terms using transition matrices lead to complicated recurrence relations.
Such relations can be used to derive general expansion-contraction relations.
Despite the fact that necessary and sufﬁcient conditions for the inclusion
relation ˜S ⊃S were presented, the requirements (6.144) are very difﬁcult to
verify due to the powers of M and matrix products. This motivates the deriva-
tion of simple sufﬁcient conditions that can be conveniently veriﬁed and com-
puted. These conditions are summarized by the next lemma, the proof of which
is a direct consequence of Theorem 6.5.9.
Lemma 6.5.11 Consider the problems (6.125), (6.137) and (6.130), (6.138). A
system ˜S includes the system S if
a)
MV = 0,
M1V = 0,
N = 0,
LV = 0
or
b)
UM = 0,
UM1 = 0,
UN = 0,
UN1 = 0,
SL = 0
(6.146)
hold.
Remark 6.5.12 The above cases when M1 = 0, N1 = 0 in (6.146), that
is, S is a system without any delays, correspond with particular cases of the
Inclusion Principle known as restrictions and aggregations, respectively [324].
Though Deﬁnition 6.5.3 establishes a sort of contractibility condition, it does
not guarantee that the closed-loop system ˜SC includes the closed-loop system
SC in the sense of the inclusion principle, that is, ˜SC ⊃SC. The following
theorem bridges this gap.

264
Chapter 6. Interconnected Time-Delay Systems
Theorem 6.5.13 Consider the systems (6.125)(6.128) and (6.130)(6.133) sat-
isfying the relation ˜S ⊃S. Suppose that u(t) = ˜K˜y(t) is a contractible control
law designed in S. If MV = 0, M1V = 0, N = 0, N1 = 0, and LV = 0 hold,
then SC ⊃SC.
Proof: Let ˜S ⊃S and denote u(t) = ˜K˜y(t) is a contractible control law
designed in ˜S. Then the corresponding closed-loop expanded system ˜SC has
the form
˜SC : ˙˜x(t) = [ ˜A + Δ ˜A(t) + [ ˜B + Δ ˜B(t)] ˜K ˜C]˜x(t)
+ [ ˜A1 + Δ ˜A1(t) + [ ˜B1 + Δ ˜B1(t)] ˜K ˜C]˜x(t −d)
= ˜Ap(t)˜x(t) + ˜Aq(t)˜x(t −d)
(6.147)
It is quite evident that a similar expression holds for the closed-loop system
Sc. It can be shown that ˜Ap(t) = V Ap(t)U + Mp implies Mp = M + [V B +
V ΔB(t)+N] ˜KL+N1 ˜KTCU and Mq = M1+[V B1+V ΔB1(t)+N1] ˜KL+
N1 ˜KTCU, where Mp and Mq are complementary matrices to be determined.
Since ˜SC ⊃SC is desired, the conditions (6.144) must be satisﬁed. Imposing
these requirements, we obtain that the relations
MV = 0, M1V = 0, N = 0, N1 = 0, LV = 0
are sufﬁcient conditions satisfying (6.144) and the proof is completed.
6.5.3
Guaranteed cost control
Initially, we consider that the relations ˜S ⊃S given by Theorems 6.5.7 and
6.5.9 and Lemma 6.5.11, as well as the relations ˜SC ⊃SC given by Theorem
6.5.13, hold. In addition, we consider the expansion inclusion relations within
the standard quadratic performance [129] for the corresponding systems S and
˜S, respectively.
Theorem 6.5.14 Consider systems (6.125), (6.128) and (6.130), (6.133). A
pair (˜S, ˜J) includes the pair (S, J) if and only if the conditions (6.143) and
V tMQ∗V = 0, NR∗= 0 hold for all t and s.
Proof: This theorem is a direct consequence of Theorem 6.5.7. The conditions
V tMQ∗V = 0 and NR∗= 0 follow from J(x0, u) = ˜J(V x0, u).
An analogous extension holds for Theorem 6.5.9 and Lemma 6.5.11.
Lemma 6.5.15 Consider the problems (6.125), (6.137) and (6.130), (6.138).
A pair (˜S, ˜J) includes the pair (S, J); if V tMQ∗V = 0,
NR∗= 0 and the
conditions (6.146) hold, then ˜SC ⊃SC.

6.5. Overlapping Control
265
Proof: The proof follows from Lemma 6.5.11 and uses the equality J(x0, u) =
˜J(V x0, u) .
Theorem 6.5.16 Consider systems (6.125), (6.128) and (6.130), (6.133) sat-
isfying the relation ˜SC ⊃SC. Suppose that u(t) = ˜K˜y(t) is a contractible
control law designed in ˜S. If MV = 0, M1V = 0, N = 0, N1 = 0, LV =
0, V T MQ∗V = 0, and NR∗= 0 hold, then ˜SC ⊃SC.
Proof: The proof follows from Theorem 6.5.13 and in view of J(x0, u) =
˜J(V x0, u).
Of interest is to emphasize that the assumptions underlying Theorem
6.5.16 coincide with the requirements in Lemma 6.5.15.
The objective now is to implement a guaranteed cost contracted controller
u(t) = Ky(t) into the delay system (6.125) obtained from a guaranteed cost
controller u(t) = ˜K˜y(t) designed for the problem (6.130), (6.138). It remains
to show that also the contracted controller is a quadratic guaranteed cost con-
troller and the cost bounds of both systems are identical. This theorem estab-
lishes the desired condition.
Theorem 6.5.17 Consider the problems (6.125), (6.137) and (6.130), (6.138).
Suppose that the relations
MV
=
0, M1V = 0, N = 0, N10,
LV
=
0, V tMQ∗V = 0, NR∗= 0
are satisﬁed. Suppose that u(t) = ˜K˜y(t) is a quadratic guaranteed cost con-
troller designed in the system ˜S with a cost matrix ˜P > 0. Then u(t) =
Ky(t) = ˜KTy(t) is the quadratic guaranteed cost controller with a cost ma-
trix P = V t ˜PV > 0 for S. Moreover, J0 = ˜J0 .
Proof: Suppose u(t) = ˜K˜y(t) is a contractible quadratic guaranteed cost con-
troller for the system ˜S. Then the inequality
d
dt ˜xt(t) ˜P ˜x(t) + ˜xt(t)[ ˜Q∗+ ˜CT ˜Kt ˜R∗˜K ˜C]˜x(t) < 0
(6.148)
is readily satisﬁed. Suppose ˜x(t) = V x(t), V tMQ∗V = 0, NR∗= 0, P =
V t ˜PV, K = ˜KT and apply (6.136). Then the inequality (6.148) leads directly
to the relation
d
dtxt(t)Px(t) + xt(t)[Q∗+ CTKT R∗KC]x(t) < 0
(6.149)

266
Chapter 6. Interconnected Time-Delay Systems
Moreover, the cost bounds satisfy
˜J0 = ˜ϕt(0) ˜P ˜ϕ(0) +
 0
−d
˜ϕt(s)[ ˜S−1 + ˜P ˜Z ˜P] ˜ϕ(s)ds
= ϕT (0)V t ˜PV ϕ(0)
+
 0
−d
ϕT (s)[V t ˜S−1V + V t ˜P(V ZV t) ˜PV ]ϕ(s)ds
= ϕT (0)Pϕ(0) +
 0
−d
ϕT (s)[S−1 + PZP]ϕ(s)ds = J0
(6.150)
The bounds J0 and ˜J0 are identical. If u(t) = ˜K˜y(t) is a quadratic guaranteed
cost controller for ˜S, then the contracted controller u(t) = Ky(t) = ˜KTy(t)
of S keeps the same property.
Remark 6.5.18 It is crucial to note that the equality J0 = ˜J0 in Theorem
6.5.17 presupposes that three matrix assumptions
P = V t ˜PV, S−1 = V t ˜S−1V,
˜Z = V ZV t
are simultaneously satisﬁed. The latter condition ˜Z = V ZV t, however, does
not offer the freedom required when designing controller in the expanded space
using the LMI by (6.141). Alternatively stated, ˜Z = V ZV t simply implies
Z = U ˜ZUt, but the reverse does not hold. Therefore, Z can be used in the
initial system together with the matrices P = V t ˜PV and S−1 = V T ˜S−1V .
6.5.4
Overlapping control design
The inequality (6.141) is not strictly a linear matrix inequality and therefore it
must be modiﬁed to a convenient form. The following result gives a sufﬁcient
condition for the existence of a guaranteed cost controller by Theorem 6.5.6
in terms of the framework of LMI. The result is presented only for the prob-
lem (6.125), (6.137). It evidently holds also for the expanded problem (6.130),
(6.138). However, the result is in fact used only for the controller design in the
expanded space.
Lemma 6.5.19 Consider the problem (6.125), (6.137). Suppose the existence
of positive deﬁnite matrices P, S, Z ∈Rn×n, a matrix K ∈Rm×q, and
constant parameters μ > 0, ϵ > 0 satisfying Theorem 6.5.17. The inequal-
ity (6.141) holds if and only if there exist symmetric positive-deﬁnite matrices

6.5. Overlapping Control
267
X, Y, Z ∈Rn×n, a matrix W ∈Rm×n, and constant parameters μ > 0, ϵ > 0
such that the following linear matrix inequality
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
Ψ1
B1W
Et
1X + W tEt
2
X
W t
A1Y
0
X
•
−Z
W tEt
4
0
0
0
0
0
•
•
−μIj
0
0
0
0
0
•
•
•
−[Q∗]−1
0
0
0
0
•
•
•
•
−[R∗]−1
0
0
0
•
•
•
•
•
−Y
Y Et
3
0
•
•
•
•
•
•
−ϵIj
0
•
•
•
•
•
•
0
−Y
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
< 0
(6.151)
is feasible, where Ψ := [AX + BW] + [AX + BW]T + Z + (μ + ϵ)DDt.
Proof: Introducing the matrices X = P −1, W = KCP −1, and Y = S−1
applying the congruent transformation
T = Blockdiag[P −1, P −1, Ij, In, Im, S−1, Ij, In]
to (6.141) leads directly to the inequality (6.151).
Remark 6.5.20 Lemma 6.5.19 yields W = KCX. However, the goal is to
obtain the gain matrix K. In what follows, we describe an algorithm to solve
this problem using the results of [397].
1. Select a full matrix Q ∈Rn×(n−q) such that CQ = 0.
2. Solve the LMI (6.151) using
X = QXqQt + Ct(CCt)−1C + CtXqC,
W = WcC
(6.152)
whereXq = Xt
q ∈R(n−q)×(n−q), Xc = Xt
c ∈Rq×q and Wc ∈Rm×q.
3. When the LMI (6.151) is feasible, the gain matrix K is computed as
K = Wc[I −CX−1
0 CtXc[I + CX−1
0 CtXc]−1]
(6.153)
where X0 = QXqQt+Ct[CCt]−1C. The procedure guarantees that WX−1 =
KC.
Theorem 6.5.21 Suppose given the problem (6.125), (6.137). Suppose that
there exist symmetric matrices Xq, Xc, a matrix Wc, and positive constant
parameters μ > 0, ϵ > 0 such that the linear matrix inequality (6.151) is

268
Chapter 6. Interconnected Time-Delay Systems
feasible with X and W given in (6.152). Then the static output feedback con-
troller u(t) = Ky(t) is a guaranteed cost controller for S, where K is given by
(6.153). Moreover, the cost function J satisﬁes the upper bound
J ≤ϕt(0)Pϕ(0) +
 0
−d
ϕt(s)[S−1 + PZP]ϕ(s)ds = J0
(6.154)
We remark that Theorem 6.5.21 is a direct consequence of Lemma 6.5.19.
Our immediate goal is to specialize the above results into the decentralized
setting. Overlapping structures correspond with the bi-tridiagonal (BTD) form
of sparse matrices. The basic structures with two overlapping subsystems for
the matrices A, ΔA(t), Ad, ΔAd(t), Bu, ΔBu(t), and C are well known [324,
330]. We consider the basic structure for Type II case. Let a standard particular
selection of the matrices V and T where
V =
⎛
⎜
⎜
⎝
In1
0
0
0
In2
0
0
In2
0
0
0
In3
⎞
⎟
⎟
⎠,
T =
⎛
⎜
⎜
⎝
Iq1
0
0
0
Iq2
0
0
Iq2
0
0
0
Iq3
⎞
⎟
⎟
⎠
(6.155)
This choice leads in a natural manner to an expanded system. The overlapped
components x2, q2 have dimensions n2, q2, respectively. These components ap-
pear repeated in ˜xu and ˜yu, where xu = (xu
1, xu
2, xu
3) and yu = (yu
1, yu
2 , yu
3).
The dimensions m1 and m2 are dimensions of vectors u1 and u2, where
uu = (uu
1, uu
2)t. It means that the decentralized controller designed in the ex-
panded state space is a block diagonal matrix with two subblocks of dimensions
m1 × (n1 + n2) and m2 × (n2 + n3) of the gain matrix. It has the form
˜KD =
 ˜K11
˜K12
0
0
0
0
˜K23
˜K24

(6.156)
Denote (∗)TD the BTD form of a matrix (∗). The contracted gain matrix has
the form
KτD =
 ˜K11
˜K12
0
0
˜K23
˜K24

(6.157)
Let us introduce the corresponding concept for this case.
Deﬁnition 6.5.22 Suppose given the problem (6.125), (6.137). A static output
feedback controller utg(t) = Ktdy(t) is said to be a td-quadratic guaranteed
cost controller Ptd if it is a quadratic guaranteed cost controller with K = Ktd
and P = Ptg = V T ˜PDV > 0, where PD is the solution provided by the
corresponding LMI.

6.5. Overlapping Control
269
Theorem 6.5.23 Suppose given the problems (6.125), (6.137) and (6.130),
(6.138). Suppose that MV
= 0, M1V
= 0, N
= 0, N1 = 0, LV
=
0, V T MQ∗V = 0, and NR∗= 0 hold. If uD(t) = ˜KD˜y(t) is a contractible
quadratic guaranteed cost controller with a cost matrix ˜PD > 0 for the system
˜S, then the contracted controller uTD(t) = KTDy(t) = ˜KDTy(t) is a td-
quadratic guaranteed cost controller with a cost matrix PTD = V T ˜PDV > 0
for S and J0 = ˜J0.
Proof: Theorem 6.5.23 follows as a particular case of Theorem 6.5.17.
6.5.5
Illustrative example 6.5
Consider the problem (6.125), (6.137) with the initial data
A
=
⎡
⎢⎢⎣
−2
0
−1
1
−1
0
2
0
0
−2
−1
0
1
0
0
−1
⎤
⎥⎥⎦,
B = Bu = D =
⎡
⎢⎢⎣
0.5
0
0.3
0.4
0
0.4
0
0.1
⎤
⎥⎥⎦,
Ad
=
⎡
⎢⎢⎣
−0.2
0
0
0
0
0.2
0.1
0
0
0.1
0
0
0
0
0
0.2
⎤
⎥⎥⎦,
C =
⎡
⎣
0.1
0
0
0
0
0.1
−0.1
0
0
0
0
0.1
⎤
⎦,
(6.158)
E1
=
E3 =
0.1
0
0.1
0
0
0
0
0.1

,
E2 = E4 =
0.1
0.1
0
0.1

,
Q∗
=
diag1, 2, 2, 1,
R∗= I2, ϕ(t) = [0.2, t, 0, 0]T ,
d = 1
The overlapped subsystems are A22 = 0
2
−2
−1 and C22 = 0.1
−0.1 in the
matrices A and C, respectively. The remaining overlapped subsystems corre-
sponding to the matrices ΔA(t), Ad and ΔAd(t) are also 2 × 2 dimensional
blocks. Find the guaranteed cost controller with the BTD structure of gain ma-
trix for the above system using the delay-independent LMI.
For the decentralized controller, we consider the expansion of the system S
with the transformations V and T given in (6.155) in the form
V =
⎛
⎜
⎜
⎜
⎜
⎜
⎜
⎝
1
0
0
0
0
1
0
0
0
0
1
0
0
1
0
0
0
0
1
0
0
0
0
1
⎞
⎟
⎟
⎟
⎟
⎟
⎟
⎠
,
T =
⎛
⎜
⎜
⎝
1
0
0
0
1
0
0
1
0
0
0
1
⎞
⎟
⎟
⎠
(6.159)

270
Chapter 6. Interconnected Time-Delay Systems
Select N = 0, M1 = 0, N1 = 0, NR∗= 0. The remaining complementary
matrices M, L, and MQ∗have the standard form by [352]. It results are in the
forms
M =
⎛
⎜
⎜
⎜
⎜
⎜
⎜
⎝
0
0
−0.5
0
0.5
0
0
0
1
0
−1
0
0
−1
−0.5
1
0.5
0
0
0
−1
0
1
0
0
1
0.5
−1
−0.5
0
0
0
0
0
0
0
⎞
⎟
⎟
⎟
⎟
⎟
⎟
⎠
,
MQ∗=
⎛
⎜
⎜
⎜
⎜
⎜
⎜
⎝
0
0
0
0
0
0
0
0.5
0
−0.5
0
0
0
0
0.5
0
−0.5
0
0
−0.5
0
0.5
0
0
0
0
−0.5
0
0.5
0
0
0
0
0
0
0
⎞
⎟
⎟
⎟
⎟
⎟
⎟
⎠
,
L =
⎛
⎜
⎜
⎝
0
0
0
0
0
0
0
0.05
−0.05
−0.05
0.05
0
0
−0.05
0.05
0.05
−0.05
0
0
0
0
0
0
0
⎞
⎟
⎟
⎠
These matrices satisfy the required relations MV
= 0,
LV
= 0, and
V tMQ∗V = 0. The resulting expanded weighting matrices are ˜Q∗= I6, ˜R∗=
I2 and the matrix ˜Q is selected as
˜Q =
0
0.1
0.1
0
0
0
0
0
0
0.1
0.1
0

It satisﬁes ˜C ˜Q = 0. These choices satisfy the results presented in Section 6.3.
Find the decentralized output guaranteed cost controller for the above system
by using a delay-independent LMI approach. Compare the results with the cen-
tralized output control design as a reference.
Impose necessary structural constraints on the matrices ˜Xc, ˜Xq, and ˜Wc to
get the block diagonal form of the matrix ˜KD:
˜Xc
=
⎛
⎜
⎜
⎝
xc11
xc12
0
0
xc12
xc22
0
0
0
0
xc33
xc34
0
0
xc34
xc44
⎞
⎟
⎟
⎠,
˜Xq =
 xq11
0
0
xq22

,
˜Wc
=
 w11
w12
0
0
0
0
w23
w24

(6.160)

6.6. Problem Set IV
271
The LMI computation by (6.151) for the system ˜S results in the gain matrix
˜KD =
 −0.7667
−0.6133
0
0
0
0
0.1278
0.5530

(6.161)
The corresponding contracted gain matrix has the following form:
KD =
 −0.7667
−0.6133
0
0
0.1278
0.5530

(6.162)
The associated bound on the cost is J0 = 1.83. Computation of the original
system results in the centralized controller
K =
 −5.8917
−2.3209
−1.4840
5.1895
0.9130
−1.1156

(6.163)
The cost bound in this case is J0 = 1.42. The centralized control design case
serves only as a reference to compare the cost bounds in both cases. The upper
bound is little greater in the decentralized case because of given information
structure constraints.
For the purpose of completeness, we provide in the next section some ques-
tions and problems that the reader might wish to examine.
6.6
Problem Set IV
Problem IV.1: Consider a large-scale system comprised of three subsystems
and described by:
A1
=
⎡
⎣
−5
−1
2
−1
3
−1
−3
2
−2
⎤
⎦, B1 =
⎡
⎣
1
−1
1
⎤
⎦, Γ1 =
⎡
⎣
1
−1
1
⎤
⎦,
Ad1
=
⎡
⎣
0.5
1
0
0
−1
0
−1
0
−1
⎤
⎦, E12 =
⎡
⎣
0.1
0
0.4
⎤
⎦, E13 =
⎡
⎣
0.3
0.1
0
−0.1
−0.1
0
⎤
⎦,
Gd1
=
⎡
⎣
0.2
0
−0.1
⎤
⎦, D1 = 0, Φ1 = 0.8, G1 =
⎡
⎣
0.1
0.3
0.2
⎤
⎦,
A2
=
−3, B2 = −3, Γ2 = 0.4, Ad2 = 0.5,
E21
=

−0.1
0
0.2

, E23 =

0.1
−0.1

,

272
Chapter 6. Interconnected Time-Delay Systems
Gd2
=
−0.3, D2 = 0, Φ2 = 0.6, G2 = 0.4,
A3
=
 −2
3
1
2

, B3 =
 1
1

, Γ3 =
 −1
1

,
Ad3
=
 0.1
0
0
−1

, E31 =
 0.1
−0.3
0
0
0.4
0.1

, E32 =

0.3
−0.1

,
Gd3
=
 0.2
0
0
−0.1

, D3 = 0, Φ3 = 0.4, G3 =
 0.1
0.3
0.2
−0.1

Choose arbitrary bounds on the system delays and determine the subsystem
stability and state feedback stabilization. Repeat for a different set of delay
patterns and deduce the relevant results.
Problem IV.2: Consider a discrete-time LSS described by:
x1(k + 1)
=
⎡
⎣
0
1
0
0
0
1
−1
4
3
⎤
⎦x1(k) +
⎡
⎣
0
0
1
⎤
⎦u1(k) + f1(xk(k)),
x2(k + 1)
=
 0
1
4
5

x2(k) +
 0
1

u2(k) + f2(xk(k)),
f t
1(xk(k))f1(xk(k))
≤
α1 xt
1(k)x1(k),
f t
2(xk(k))f2(xk(k))
≤
α2 xt
2(k)x2(k)
where α1 and α2 are free parameters. Using appropriate quadratic Lyapunov
functions, derive sufﬁcient conditions for stability and express them in LMI
format. What is the maximal bounds for α1 and α2 that preserve the stability?
Problem IV.3: Consider a large-scale system comprised of three second-order
subsystems and described by:
˙x1(t)
=

1
1.5
0.3
−2

x1(t) +
 0.5ξ1
0
0
0.1ξ1

x2(t −0.25)
+
 5
1

{u1(t) + v1(t)},
˙x2(t)
=
 −2
0
−1
−1

x1(t) +
 0
0
ξ2
ξ3

x1(t −0.2)
+
 0
0
ξ2
0

x3(t −0.1)
+
 0
1

{φu2(t) + v2(t)},

6.6. Problem Set IV
273
˙x3(t)
=
 −1
0
−1
−2

x1(t) +
 0
0
ξ4
ξ4

x2(t −0.1)
+
 1
0
0
1

{u3(t) + v3(t)}
where the different parameter bounds are given by
||ξ1||
≤
1, ||v1|| ≤0.1, ||ξ2|| ≤1, ||ξ3|| ≤2, ||v2|| ≤0.5,
||ξ3||
≤
2, ||v3|| ≤0.1, 2 ≤φ 4
The objective is to determine a decentralized controller such that the solutions
of the overall system are uniformly ultimately bounded with respect to the
bound ε ≤
0.18. To derive appropriate conditions, apply the stability the-
ory based on constructive use of the Lyapunov function [152].
Problem IV.4: Consider two stands of cold rolling mill in tandem and de-
scribed by:
˙x1(t)
=
⎡
⎣
−100
0
0
0
−40
0
4.517
−34.335
−56.063
⎤
⎦x1(t)
+
⎡
⎣
100
0
0
40
0
0
⎤
⎦u1(t) + f1(t, x, u),
˙x2(t)
=
⎡
⎣
−100
0
0
0
−40
0
6.428
−35.982
−100.295
⎤
⎦x2(t)
+
⎡
⎣
100
0
0
40
0
0
⎤
⎦u2(t) + f2(t, x, u),
C1
=
 0.455
0
−5.589
0
0
1

.
C2
=
 0.491
0
−6.931
0
0
1

,
f t
1(t, x, u)f1(t, x, u)
≤
α1 xt(t)M1x(t), f t
2(t, x, u)
f2(t, x, u)
≤
α2 xt(t)M2x(t),

274
Chapter 6. Interconnected Time-Delay Systems
M1
=
⎡
⎢⎢⎢⎢⎢⎢⎣
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0.1
0.1
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
⎤
⎥⎥⎥⎥⎥⎥⎦
,
M2
=
⎡
⎢⎢⎢⎢⎢⎢⎣
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0.1
0
0.1
0
0
0
⎤
⎥⎥⎥⎥⎥⎥⎦
where α1 and α2 are adjustable parameters. Using an appropriate quadratic
Lyapunov function, derive LMI-based sufﬁcient conditions of asymptotic sta-
bility and static output feedback stabilization. What is the maximal bounds for
α1 and α2 that preserve the stability?
Problem IV.5: Consider the following model of LSS with state-dependent de-
lays
Sj :
˙xj(t)
=
Ajxj(t) + Δj(xj(t), t) +
ns

k=1,k̸=j
Ajkxk(t −ηjk(xj(t), t))
j
∈
{1, ..., ns}
where ηjk(xj(t), t) are bounded continuous functions and the nonlinear para-
metric uncertainties are bounded in the form
||Δj(xj(t), t)|| ≤βj||xj(t)||, βj ∈[0, ∞)
Apply the Lyapunov-Razumikhn theory to derive the sufﬁcient conditions that
guarantee the LSS is asymptotically stable independent of delay.
Problem IV.6: Consider the following model of LSS with parametric uncer-
tainties:
Sj :
˙xj(t)
=
[Ajj + ΔAjj(x(t), t)]xj(t)
+
ns

k=1,k̸=j
[Ajk + ΔAjk(x(t), t)]xk(t)

6.7. Notes and References
275
+
ns

k=1,k̸=j
[Djk + ΔDjk(x(t −ηjk))]xk(t −ηjk),
×
j ∈{1, ..., ns}
where the nonlinear parametric uncertainties are bounded in the form
||ΔAjk(x(t), t)|| ≤βjk, βj ∈[0, ∞),
||ΔDjk(x(t −ηjk))|| ≤σjk, βj ∈[0, ∞)
Assume for simplicity that λ(Ajj) ∈C−, j ∈{1, ..., ns}. Use the LKF
V (x)
=
ns

k=1

xt
j(t)Pjxj(t) +
 t
t−ηjk
xt
j(s)Qjxj(s) ds
to derive the sufﬁcient conditions that guarantee the LSS is asymptotically sta-
ble.
Problem IV.7: It is of interest to develop an overlapping decomposition proce-
dure to deal with the case of time-delay systems with polytopic uncertainties.
The objective is to derive appropriate expansion-contraction relations that al-
low the design of a linear quadratic controller.
Problem IV.8: Extend the results of the overlapping control methods to the
class of discrete-time systems
S :
x(k + 1)
=
¯A(k)x(k) + ¯B(k)u(k) + ¯Ad(k)x(k −d) + ¯D(k)u(k −d),
y(k)
=
Cx(k),
x(k)
=
ϕ(k), −d ≤k ≤0,
¯A(k)
=
Ao + ΔA(k), ¯B(k) = Bo + ΔB(k),
¯Ad(k)
=
Ado + ΔAd(k), ¯D(k) = Do + ΔD(k)
where
[ΔA(k) ΔB(k) ΔAd(k) ΔD(k)] = H F(k) [E1 E2 E3 E4]
where H, E1, E2, E3, E4 are known constant real matrices of appropriate di-
mensions and F t(k)F(k) ≤I.
6.7
Notes and References
A set of expansion-contraction relations extending the Inclusion Principle is
proved for a class of linear continuous-time uncertain systems with state and

276
Chapter 6. Interconnected Time-Delay Systems
control delays. Norm bounded arbitrarily time-varying uncertainties and a
given point delay are considered. The resulting structural relations are easily
extendable to polytopic systems with constant uncertainties. The presented in-
clusion relations are applied on the quadratic guaranteed cost control design.
Conditions preserving the expansion-contraction relations for closed-loop sys-
tems including the equality of cost bounds have been proved. The guaranteed
cost control design is performed using the LMI delay-independent procedure in
the expanded space and subsequently contracted into the original system. The
results are specialized on the overlapping static output feedback design.

Chapter 7
Decentralized Reliable Control
In this chapter, we continue further into the decentralized-control techniques
for interconnected systems, where we focus herein on methods for design-
ing classes of reliable decentralized controllers to deal with possible actuator
and/or sensor failures. Thus we study hereafter the problem of designing re-
liable decentralized feedback control for linear interconnected systems where
we focus initially on subsystems with internal time-delays and additional time-
delay couplings, under actuator and/or sensor failures. Then we specialize the
result to delay-free subsystems. We equally treat continuous- and discrete-time
system representations. The failures are described by a model that takes into
consideration possible outages or partial failures in every single actuator/single
sensor of each decentralized controller. The decentralized control design is per-
formed through two steps. First, a decentralized stabilizing reliable feedback
control set is derived at the subsystem level through the construction of ap-
propriate Lyapunov-Krasovskii functional (LKF) and, second, a feasible linear
matrix inequalities procedure is then established for the effective construction
of the control set under different feedback schemes. Two schemes are con-
sidered: the ﬁrst is based on state-measurement and the second utilizes static
output-feedback. The decentralized feedback gains in both schemes are deter-
mined by convex optimization over linear matrix inequalities (LMIs).
7.1
Interconnected Continuous Systems
Large-scale interconnected systems appear in a variety of engineering appli-
cations including power systems, large structures, and manufacturing systems
and for those applications, decentralized control schemes present a practical
and effective means for designing control algorithms based on the individual
277

278
Chapter 7. Decentralized Reliable Control
subsystems [324]. Relevant research results on decentralized control of rele-
vance to the present work can be found in [173, 288, 328]. There are funda-
mental issues arising quite frequently when designing feedback controllers for
interconnected systems. The ﬁrst major issue regards the construction of de-
centralized control schemes to confront the practical limitations in the number
and the structure of the feedback loops. The second issue is due to the presence
of uncertainties and/or time-varying delays both in the subsystems and in the
interconnections. The third issue concerns the reliability of the control systems
against different component failures. It becomes increasingly evident that the
reliability of control systems in the presence of system component failures is
of paramount importance for maintaining the critical functionality and surviv-
ability of many safety critical systems. For these systems, the overall reliability
is enhanced not by using more reliable components, but by managing them in a
way that the reliability of the overall system is greater than the reliability of its
parts. This is the fundamental concept of fault-tolerant control and the reliable
control problem. It is needless to stress that reliable operation is of prime im-
portance in the case of interconnected dynamical systems since failures could
occur independently in each subsystem or actuator channel in the form of total
outage or partial degradation.
In the literature on designing reliable controllers for single systems, there
is one approach based on the use of multiple redundant controls [161]. There is
another direction that aims to design controls without redundancy by ensuring
stability with some degree of performance for speciﬁed classes of admissi-
ble failures of particular control components [270]. Classical quadratic optimal
control has been used for reliable design [108, 367, 401] to achieve stability
and performance. Reliable optimal controllers have been designed by using
H2/H∞tools in [83, 388] where a condition for decentralized and quadratic
stabilizability was presented and subsequently used to provide a solution of
H2-norm optimization. In [39], the integral constraints and the guaranteed cost
control were applied to address robustness issues. In the reported papers, sys-
tem interconnections were not considered and the classes of admissible failures
were usually modeled as outages [83, 388]. This model considers the control
set partitioned into one subset with the actuators whose failures are admissible
in the control design and a complementary subset with the actuators that are
assumed to keep a normal operation. The literature on designing reliable con-
trollers for interconnected systems is quite limited [296] where an initial effort
for decentralized reliable control was developed for a class of interconnected
systems.

7.1. Interconnected Continuous Systems
279
7.1.1
Problem description
We consider a class of linear systems S structurally composed of ns coupled
subsystems Sj and the model of the jth subsystem is described by the state-
space representation:
˙xj(t)
=
Ajxj(t) + Adjxj(t −τj(t)) + Bjuj(t) + cj(t) + Ωjwj(t)
zj(t)
=
Gjxj(t) + Gdjxj(t −τj(t)) + Djuj(t) + Bjwj(t)
yj(t)
=
Cjxj(t) + Cdjxj(t −τj(t))
(7.1)
where for j ∈{1, ..., ns}, xj(t) ∈ℜnj is the state vector, uj(t) ∈ℜmj is
the control input, yj(t) ∈ℜpj is the measured output, wj(t) ∈ℜqj is the
disturbance input which belongs to L2[0, ∞), zj(t) ∈ℜqj is the performance
output. The matrices Aj ∈ℜnj×nj, Bj ∈ℜnj×mj, Dj ∈ℜqj×mj, Adj ∈
ℜnj×nj, Bj ∈ℜqj×qj, Ωj ∈ℜnj×qj, Cj ∈ℜpj×nj, Cdj ∈ℜpj×nj, Gj ∈
ℜqj×nj, Gdj ∈ℜqj×nj
are real and constants. The initial condition is Bj ∈
L2[−τ ∗
j , 0], j ∈{1, ..., ns}. The interactions between subsystem Sj and the
other subsystems are summarized by the coupling vector cj(t) ∈ℜnj where
cj(t)
=
ns

k=1,k̸=j
Fjkxk(t) +
ns

k=1,k̸=j
Ejkxk(t −ηjk(t))
(7.2)
The matrices Fjk ∈ℜnj×nk, Ejk ∈ℜnj×nk
are real and constants. The
factors τj, ηjk, j, k ∈{1, ..., ns} are unknown time-delay factors satisfying
0
≤
τj(t) ≤ϱj,
˙τj(t) ≤μj,
0
≤
ηjk(t) ≤ϱjk,
˙ηjk(t) ≤μjk
(7.3)
where the bounds ϱj, ϱjk, μj, μjk are known constants in order to guar-
antee smooth growth of the state trajectories. The inclusion of the terms
Adjxj(t −τj(t)), Ejkxk(t −ηjk(t)) is meant to emphasize the delay within
each subsystem (local delay) and among the subsystems (coupling delay), re-
spectively. A block-diagram representation of the subsystem model (7.1) is
depicted in Figure 7.1. It should be observed that the class of systems de-
scribed by (7.1)-(7.2) subject to delay-pattern (7.3) is frequently encountered
in modeling several physical systems and engineering applications including
large space structures, multimachine power systems, cold mills, transportation
systems, and water pollution management, to name a few [252, 253, 324].

280
Chapter 7. Decentralized Reliable Control
Figure 7.1: Subsystem model
7.1.2
Actuator failure model
In the sequel, we consider that system (7.1) is assumed to operate under fail-
ures described by extension of the representation [39] to the decentralized set-
ting treated hereafter. Such representation allows independent outage or par-
tial degradation in any single actuator of every decentralized controller. In this
way, a rather general scenario is deﬁned for the design of reliable decentralized
control structure for a class of interconnected systems simultaneously facing
uncertainties and failures. Let uf
j ∈ℜfj denote the vector of signals from the
fj actuators that control the jth subsystem. We consider the following failure
model:
uf
j (t) = Σjuj(t) + βj(uj)
(7.4)
where 0 < Σj ∈ℜfj×fj = diag(σj1, ...., σjfj) and the function βj(uj) =
[βj1(uj1), ..., βjfj(ujfj)]t is uncertain ans satisﬁes, for each j,
β2
jk ≤γ2
jk u2
jk,
k = 1, ..., fj, γ2
jk ≥0
(7.5)
When (7.5) holds, then
||βj(xj)||2 ≤||Γjuj||2,
j = 1, ..., ns
(7.6)
where 0 ≤Γj = diag(γj1, ...., γjfj) ∈ℜfj×fj. The value of σjk, k = 1, .., fj
represents the percentage of failure in the actuator j controlling subsystem Sj.
With this representation, each subsystem actuator can fail independently. Note
that the condition σjk = 1, γjk = 0 represents the normal case for the kth
actuator of the jth subsystem (uf
jk(t) = ujk(t)). When this situation holds

7.1. Interconnected Continuous Systems
281
for all k, we get that Σj = Ifj and Γj = 0 which in turn clariﬁes the normal
case in the jth channel (uf
j (t) = uj(t)). In the particular case σjk = γjk,
(7.4) and (7.5) covers the outage case (uf
jk = 0) since βjk = −σjkujk satisﬁes
(7.5). Alternatively, the case βj(uj) = −σjuj discloses the outage of the whole
controller of the jth system. Indeed, there are different cases that would reveal
partial failures or partial degradations of the actuators.
Our objective now is to study two main problems:
1. The ﬁrst problem is with the decentralized reliable stabilization by devel-
oping decentralized feedback controllers (based on state, static output,
and dynamic output) in the presence of failures described by (7.4)-(7.5)
and deriving a feasibility testing at the subsystem level so as to guaran-
tee the overall system asymptotic stability with a prescribed performance
measure.
2. The second problem deals with the design of resilient decentralized con-
trollers guaranteeing reliable stabilization by developing resilient de-
centralized feedback controllers that takes into consideration additive
gain perturbations while ensuring that the overall closed-loop system is
asymptotically stable with a prescribed performance measure.
7.1.3
State-feedback reliable design
In this section, we develop new criteria for LMI-based characterization of de-
centralized reliable stabilization by local state feedback. The criteria include
some parameter matrices aimed at expanding the range of applicability of the
developed conditions. Using the local state feedback uj(t) = Kjxj(t), j =
1, ..., N, the local closed-loop subsystem under failure becomes
˙xj(t)
=
&Ajxj(t) + Adjxj(t −τj(t)) + Bjβj(uj) + cj(t) + Ωjwj(t)
zj(t)
=
&Gjxj(t) + Gdjxj(t −τj(t)) + Djβj(uj) + Bjwj(t)
cj(t)
=
ns

k=1,k̸=j
Fjkxk(t) +
ns

k=1,k̸=j
Ejkxk(t −ηjk(t))
&Aj
=
Aj + BjΣjKj,
&Gj = Gj + DjΣjKj
(7.7)
The following theorem establishes the main design result for subsystem Sj
where in the subsections that follow, asymptotic stability conditions and the
reliable decentralized feedback gains are derived.

282
Chapter 7. Decentralized Reliable Control
Theorem 7.1.1 Given the bounds ϱj > 0,
μj > 0,
ϱjk > 0, μjk >
0,
j, k = 1, ..., ns and matrix Wj, then the family of subsystems {Sj}
where Sj is described by (7.7) is delay-dependent asymptotically stabiliz-
able by decentralized controller uj(t) = Kjxj(t), j = 1, ..., ns with L2-
performance bound γj, j = 1, ..., ns if there exist positive-deﬁnite matri-
ces Xj, Yj, Wk, {Λkj}ns
k=1, {Ψrj}4
r=1,
satisfying the following LMIs for
k, j = 1, ..., ns :
(Πj
=
)
(Πaj
(Πcj
•
(Πej
*
< 0
(Πaj
=
⎡
⎢⎢⎢⎢⎣
Πoj
Πaj
−ϱjΨ1j
0
Bj
•
−Πmj
−ϱjΨ3j
0
0
•
•
−ϱjΨ4j
0
0
•
•
•
−Πnj
0
•
•
•
•
−Ij
⎤
⎥⎥⎥⎥⎦
,
(Πcj
=
⎡
⎢⎢⎢⎢⎣
Ωj
Πt
zj
Yt
jΓt
j
ϱk(XjAt
j + Yt
jΣt
jBt
j)Wk
0
Gt
dj
0
ϱkXjAt
djWk
0
0
0
0
0
0
0
ϱk
ns
k=1 XjEkjWk
0
0
0
0
⎤
⎥⎥⎥⎥⎦
,
(Πej
=
⎡
⎢⎢⎣
−γ2
j Ij
Bt
j
0
ϱkΓt
jWk
•
−Ij
0
0
•
•
−Ij
0
•
•
•
−ϱkWk
⎤
⎥⎥⎦
(7.8)
where
Πoj
=
[Aj +
ns

k=1
Fkj]Xj + BjΣjYj + Xj[Aj +
ns

k=1
Fkj]t
+
Yt
jΣt
jBt
j + Ψ1j + Ψt
1j + Ψ2j +
ns

k=1,k̸=j
Λkj + (ns −1)Xj
Πaj
=
AdjXj −Ψ1j + Ψt
3j, Πzj = GjXj + DjΣjYj,
Πnj
=
ns

k=1,k̸=j
(1 −μkj)Λkj +
ns

k=1,k̸=j
XjEt
kjPkEkjXj,
Πmj
=
Ψ3j + Ψt
3j + (1 −μj)Ψ2j −Ψt
4j + Ψt
4js
(7.9)
Moreover, the local gain matrix is given by Kj = YjX −1
j
.

7.1. Interconnected Continuous Systems
283
Proof: Consider the LKF:
V (t)
=
ns

j=1
Vj(t), Vj(t) = Voj(t) + Vaj(t) + Vmj(t) + Vnj(t),
Voj(t)
=
xt
j(t)Pjxj(t), Vaj(t) =
 0
−ϱj
 t
t+s
˙xt
j(α)Wj ˙xj(α)dα ds,
Vmj(t)
=
 t
t−τj(t)
xt
j(s)Qjxj(s) ds,
Vnj(t)
=
ns

k=1,k̸=j
 t
t−ηjk(t)
xt
k(s)Zjkxk(s) ds
(7.10)
where 0 < Pj = Pt
j, 0 < Wj = Wt
j, 0 < Qj = Qt
j, 0 < Zjk =
Zt
jk, j, k ∈{1, ..., ns} are weighting matrices of appropriate dimensions. Ob-
serve that V (t) has been used before in Chapter 6. Now by using the failure
model inequality (7.6) with uj(t) = Kjxj(t), we have
βt
j(uj)βj(uj) ≤xt
jKt
jΓt
jΓjKjxj
(7.11)
For the time being, we consider that the gains Kj are speciﬁed. A straightfor-
ward computation gives the time-derivative of V (t) along the solutions of (7.7)
with w(t) ≡0 as:
˙Voj(t)
=
2xt
jPj ˙xj = 2xt
jPj[ &Ajxj(t) + Adjxj(t −τj(t)) + Bjβj(uj)]
+
2xt
jPj
ns

k=1
Fjkxk(t) + 2xt
jPj
ns

k=1
Ejkxk(t −ηjk(t))
(7.12)
Standard manipulations of (7.12) yield
˙Voj(t)
=
2xt
jPj[ &Aj + Adj]xj(t) + 2xt
j[Θj −PjAdj]
 t
t−τj(t)
˙xj(s)ds
+
2xt
jPjBjβj(uj)
+
2xt(t −τj(t))Υj
 t
t−τj(t)
˙xj(s)ds −

2xt
jtΘj
 t
t−τj
˙xj(s)ds
+
2xt(t −τj(t))Υj
 t
t−τj(t)
˙xj(s)ds

+
2xt
jPj
ns

k=1
Fjkxk(t) + 2xt
jPj
ns

k=1
Ejkxk(t −ηjk(t))
(7.13)

284
Chapter 7. Decentralized Reliable Control
Little algebra on (7.13) yields
˙Voj(t) =
1
τj(t)
 t
t−τj(t)
)
2xt
j[Pj &Aj + Θj]xj
+2xt
j[PjAdj −Θj + Υt
j]xj(t −τj(t)) −2xt
j(t −τj(t))Υjx(t −τj)
−2xtτjΘ ˙xj(s) −2xt
j(t −τj(t))τj(t)Υj ˙xj(s)
+2xt
jPjBjβj(uj) + 2xt
jPj
ns

k=1
Fjkxk(t)
+2xt
jPj
ns

k=1
Ejkxk(t −ηjk(t))
*
ds
(7.14)
where Θj ∈ℜnj×nj and Υj ∈ℜnj×nj are appropriate relaxation matrices
injected to facilitate the delay-dependence analysis.
˙Vaj(t) =
 t
t−ϱj
[ ˙xt
j(t)Wj ˙xj(t) −˙xt
j(s)Wj ˙xj(s)]d s
= ϱj ˙xt
j(t)Wj ˙xj(t) −
 t
t−τj
˙xt
j(s)Wj ˙xj(s)ds
−
 t−τj
t−ϱj
˙xt
j(s)Wj ˙xj(s)
(7.15)
Little algebra on (7.15) yields
˙Vaj(t) ≤ϱj ˙xt
j(t)Wj ˙xj(t) −
 t
t−τj
˙xt
j(s)Wj ˙xj(s)ds
=
1
τj(t)
 t
t−τj(t)

ϱj ˙xt
j(t)Wj ˙xj(t) −τj ˙xt
j(s)Wj ˙xj(s)

ds
(7.16)
Note that the term Tj =
 t−τj
t−ϱj ˙xt
j(s)Wj ˙xj(s) accounts for the enlarged time
interval from t −ϱj →t to t −τj →t. It is obvious that Tj > 0 and hence
expression (7.16) holds true without conservatism. There has been an alterna-
tive route to handle Tj by employing extra parameter matrices and adding more

7.1. Interconnected Continuous Systems
285
identities [103] and [146]. Also,
˙Vmj(t)
=
xt
j(t)Qjxj(t) −(1 −˙τj(t)) xt(t −τj(t))Qjxj(t −τj(t))
≤
xt
j(t)Qjxj(t) −(1 −μj) xt
j(t −τj(t))Qjxj(t −τj(t))
=
1
τj(t)
 t
t−τj(t)

xt
j(t)Qjxj(t)
−
(1 −μj) xt
j(t −τj(t))Qjxj(t −τj(t))

ds
(7.17)
Also, we have
˙Voj(t) ˙Vnj(t)
=
ns

k=1,k̸=j
×

xt
k(t)Zjkxk(t)
−
(1 −˙ηjk(t))xt
k(t −ηjk(t))Zjkxk(t −ηjk(t))

≤
ns

k=1,k̸=j

xt
k(t)Zjkxk(t)
−
(1 −μjk) xt
k(t −ηjk(t))Zjkxk(t −ηjk(t))

(7.18)
For the class of interconnected systems (7.1), the following structural identity
holds:
ns

j=1
ns

k=1,k̸=j
xt
k(t)Zjkxk(t) =
ns

j=1
ns

k=1,k̸=j
xt
j(t)Zkjxj(t)
(7.19)
By combining (7.10)-(7.19) and using Schur complements, we have
˙Vj(t)|(7.7)
≤
ns

j=1
 1
τj
 t
t−τj
χt
j(t, s) Ξj χj(t, s) ds

(7.20)
where
χj(t, s) =

xt
j(t) xt
j(t −τj) ˙xt
j(s) xt
j(t −ηkj) βt(xj)
t

286
Chapter 7. Decentralized Reliable Control
Ξj
=
⎡
⎢⎢⎢⎢⎢⎢⎢⎣
Ξoj
Ξaj
−ϱjΘj
Ξcj
PjBj
ϱj &At
jWj
•
−Ξmj
−ϱjΥj
0
0
ϱkAt
djWk
•
•
−ϱkWk
0
0
0
•
•
•
−Ξnj
0
ϱk
ns
k=1 EkjWk
•
•
•
•
−Ij
0
•
•
•
•
•
−ϱkWk
⎤
⎥⎥⎥⎥⎥⎥⎥⎦
Ξoj
=
Pj[ &Aj +
ns

k=1
Fkj] + [ &Aj +
ns

k=1
Fkj]tPj + Θj + Θt
j + Qj
+
ns

k=1
Zkj + Kt
jΓt
jΓjKj + (ns −1)Pj,
Ξaj
=
PjAdj −Θj + Υt
j, Ξmj = Υj + Υt
j + (1 −μj)Qj,
Ξnj
=
ns

k=1
(1 −μkj)Zkj +
ns

k=1,k̸=j
Et
kjPkEkj
(7.21)
where ˙Vj(t)|(7.7) deﬁnes the Lyapunov derivative along the solutions of system
(7.1). Internal stability requirement ˙Vj(t)|(7.7) < 0 implies that Ξj < 0. It
is readily seen from (7.21) using the delay bounds of (7.3) that there exists a
scalar σj > 0 such that
⎡
⎢⎢⎢⎢⎢⎢⎢⎣
Ξoj + σjIj
Ξaj
−Θj
0
PjBj
ϱk &At
jWk
•
−Ξmj
−Υj
0
0
ϱkAt
djWk
•
•
−ϱ−1
j Wj
0
0
0
•
•
•
−Ξnj
0
ϱk
ns
k=1 EkjWk
•
•
•
•
−Ij
0
•
•
•
•
•
−ϱkWk
⎤
⎥⎥⎥⎥⎥⎥⎥⎦
< 0
(7.22)
Therefore, for all τj satisfying (7.3) we have
⎡
⎢⎢⎢⎢⎢⎢⎢⎣
Ξoj + σjIj
Ξaj
−τjΘj
0
PjBj
ϱk &At
jWk
•
−Ξmj
−τjΥj
0
0
ϱkAt
djWk
•
•
−τjWj
0
0
0
•
•
•
−Ξnj
0
ϱk
ns
k=1 EkjWk
•
•
•
•
−Ij
0
•
•
•
•
•
−ϱkWk
⎤
⎥⎥⎥⎥⎥⎥⎥⎦
< 0
(7.23)

7.1. Interconnected Continuous Systems
287
and hence
˙Vj(t)|(7.7)
<
ns

j=1

1
τj(t)
 t
t−τj
χt
j(t, s)diag[−σj, 0, 0, 0, 0, 0]χj(t, s) ds

=
−
ns

j=1
σj ||xj||2 < 0
(7.24)
We continue further and consider the L2 −gain performance measure
J =
ns

j=1
 ∞
0

zt
j(s)zj(s) −γ2
j wt
j(s)wj(s)

ds
For any wj(t) ∈L2(0, ∞) ̸= 0 with zero initial condition xj(0) = 0 hence
V (0) = 0, we have
J
=
ns

j=1
 ∞
0

zt
j(s)zj(s) −γ2
j wt
j(s)wj(s) + ˙Vj(t)|(7.1) −Vj(∞)

ds
≤
ns

j=1
 ∞
0

zt
j(s)zj(s) −γ2
j wt
j(s)wj(s) + ˙Vj(t)|(7.1)

ds
Proceeding as before, we make use of (7.24) to get
ns

j=1

zt
j(s)zj(s) −γ2
j wt
j(s)wj(s) + ˙Vj(t)|(7.1)

=
ns

j=1
¯χt
j(t, s) &Ξj ¯χj(t, s)
(7.25)
where
¯χj(t, s) =
 xt
j(t)
xt
j(t −τj)
˙xt
j(s)
xt
j(t −ηkj)
βt(xj)
wt
j(s) t
&Ξj =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
Ξoj
Ξaj
−ϱjΘj
Ξcj
PjBj
PjΩj
&Gt
j
ϱj &At
jWj
•
−Ξmj
−ϱjΥj
0
0
0
Gt
dj
ϱjAt
djWj
•
•
−ϱjWj
0
0
0
0
0
•
•
•
−Ξnj
0
0
0
ϱj
ns
k=1 EkjWj
•
•
•
•
−Ij
0
0
0
•
•
•
•
•
−γ2
j Ij
Bt
j
ϱjΓt
jWj
•
•
•
•
•
•
−Ij
0
•
•
•
•
•
•
•
−ϱjWj
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦

288
Chapter 7. Decentralized Reliable Control
It is readily seen that when &Ξj < 0 the condition
ns

j=1

zt
j(s)zj(s) −γ2
j wt
j(s)wj(s) + ˙Vj(t)|(7.1)

< 0
for arbitrary s ∈[t, ∞). This in turn implies that for any wj(t) ∈L2(0, ∞) ̸=
0 we have
J < 0
leading to ns
j=1 ||zj(t)||2 < ns
j=1 γj ||w(t)j||2, which assures the desired
performance.
7.1.4
Feedback gains
The immediate task now is to determine the decentralized gain matrices Kj.
Applying the congruent transformation T = diag[Xj, Xj, Xj, Xj, Ij, Ij,
Ij, Ij], Xj = P−1
j
to &Ξj with Schur complements and using the linearizations
Yj
=
KjXj, Ψ1j = XjΘjXj, Ψ2j = XjQjXj,
Ψ3j
=
XjΥjXj, Λkj = XjZkjXj, Ψ4j = XjWjXj
we readily obtain LMI (7.8) by Schur complements and therefore the proof is
completed.
Remark 7.1.2 It is signiﬁcant to recognize that the methodology of this section
incorporates four weighting matrices Pj, Qj, Wj, Zjk and two parameter
matrices Θj, Υj at the subsystem level in order to ensure least conservative
delay-dependent stability results. This will eventually result in reduced compu-
tational requirements as evidenced by a simple comparison with the improved
free-weighting matrices method of [103] for single time-delay systems in terms
of two aspects. One aspect would be due to reduced computational load as
evidenced by less number of manipulated variables and faster processing. An-
other aspect arises by noting that LMIs (7.8) subject to (7.9) for ns = 1 the-
oretically cover the results of [146, 174] as special cases. Furthermore, in the
absence of delay (Adj ≡0, Qj ≡0, Wj ≡0), it is easy to infer that LMIs
(7.8) subject to (7.9) for ns = 1 will eventually reduce to parameterized delay-
independent criteria. LKF composed of the ﬁrst three terms has been consid-
ered in [74, 103, 261, 290] for single time-delay systems. In comparison with
the reported results on interconnected systems [251, 283, 287, 288, 328, 371],
LKF (7.10) represents a new effective form and therefore the advantages and
reduced conservatism afforded in [74, 103, 261, 290] are carried over herein.

7.1. Interconnected Continuous Systems
289
Remark 7.1.3 The optimal performance-level γj, j = 1, .., ns for the inter-
connected system can be determined for decentralized reliable state feedback
by solving the following convex optimization problem:
Problem A:
For j, k = 1, ..., ns, Given ϱj, μj, ϱjk, μjk, Wj
min
Xj, Yj, {Λkj}ns
k=1, {Ψrj}3
r=1
γj
subject to LMI(7.8)
(7.26)
7.1.5
Interconnected uncertain systems
Suppose now that the interconnected system (7.1) undergoes parametric uncer-
tainties. One convenient representation would be the state-space model
˙xj(t)
=
AjΔxj(t) + AdjΔxj(t −τj) + BjΔuj(t) + cj(k) + ΩjΔwj(t)
zj(t)
=
GjΔxj(t) + GdjΔx(t −τj) + DjΔuj(t) + BjΔwj(t)
yj(t)
=
CjΔxj(t) + CdjΔx(t −τj)
cj(t)
=
ns

k=1,k̸=j
FjkΔxk(t) +
ns

k=1,k̸=j
EjkΔxk(t −ηjk(t))
(7.27)
whose matrices containing uncertainties which belong to a real convex bounded
polytopic model of the type
) AjΔ
AdjΔ
BjΔ
ΩjΔ
GjΔ
GdjΔ
DjΔ
BjΔ
CjΔ
CdjΔ
EjkΔ
FjkΔ
*
∈Πλ :=
5 ) Ajλ
Adjλ
Bjλ
Ωjλ
Gjλ
Gdjλ
Djλ
Bjλ
Cjλ
Cdjλ
Ejkλ
Fjkλ
*
=
N

s=1
λs
⎡
⎣
Ajs
Adjs
Bjs
Ωjs
Gjs
Gdjs
Djs
Bjs
Cjs
Cdjs
Ejks
Fjks
⎤
⎦, λs ∈Λ
6
(7.28)
where Λ is the unit simplex
Λ :=

(λ1, · · · , λN) :
N

j=1
λj = 1 , λj ≥0

(7.29)
Deﬁne the vertex set N = {1, ..., N}. We use {Ajo, ..., Bjo} to imply generic
system matrices and {Ajs, ..., Bjs, s ∈N} to represent the respective values
at the vertices. It is a straightforward task to show that the following result
holds.

290
Chapter 7. Decentralized Reliable Control
Theorem 7.1.4 Given the bounds ϱj > 0,
μj > 0,
ϱjk > 0, μjk >
0, j, k = 1, ..., ns and matrix Wj, then the family of subsystems {Sj} with
polytopic representation (7.28)-(7.29) where Sj is described by (7.2) is delay-
dependent asymptotically stabilizable by decentralized controller uj(t) =
Kjxj(t), j, k = 1, ..., ns with L2-performance bound γj, j = 1, ..., ns if
there exist positive-deﬁnite matrices Xj, Yj, Wk, {Λkj}ns
k=1, {Ψrj}3
r=1,
satisfying the following LMIs for j = 1, ..., ns, s = 1, ..., N
(Πjs
=
)
(Πajs
(Πcjs
•
(Πejs
*
< 0
(7.30)
where
(Πajs
=
⎡
⎢⎢⎢⎢⎣
Πojs
Πajs
−ϱjΨ1js
Πcjs
Bjs
•
−Πmjs
−ϱjΨ3js
0
0
•
•
−ϱjΨ4js
0
0
•
•
•
−Πnjs
0
•
•
•
•
−Ij
⎤
⎥⎥⎥⎥⎦
,
(Πcjs
=
⎡
⎢⎢⎢⎢⎣
Ωjs
Πt
zjs
Yt
jΓt
js
ϱk(XjAt
js + Yt
jΣt
jBt
js)Wk
0
Gt
djs
0
ϱkXjAt
djsWk
0
0
0
0
0
0
0
ϱk
ns
k=1 XjEkjsWk
0
0
0
0
⎤
⎥⎥⎥⎥⎦
,
(Πejs
=
⎡
⎢⎢⎣
−γ2
j Ij
Bt
j
0
ϱkΓt
jWk
•
−Ij
0
0
•
•
−Ij
0
•
•
•
−ϱkWk
⎤
⎥⎥⎦
(7.31)
with
Πojs
=
[Ajs +
ns

k=1
Fkjs]Xj + BjsΣjYj + Xj[Ajs +
ns

k=1
Fkjs]t + Yt
jΣt
jBt
js
+
Ψ1js + Ψt
1js + Ψ2js +
ns

k=1
Λkjs + (ns −1)Xj
Πajs
=
AdjsXj −Ψ1js + Ψt
3js, Πzj = GjsXj + DjsΣjYj,
Πnjs
=
ns

k=1,k̸=j
(1 −μkj)Λkjs +
ns

k=1,k̸=j
XjEt
kjsPkEkjsXj,
Πmj
=
Ψ3js + Ψt
3js + (1 −μj)Ψ2js + Ψt
4js
(7.32)
Moreover, the local gain matrix is given by Kj = YjX −1
j
.

7.1. Interconnected Continuous Systems
291
7.1.6
Static output-feedback reliable design
In this section, we develop new criteria for LMI-based characterization of de-
centralized reliable stabilization by local static output feedback. The criteria
include some parameter matrices aims at expanding the range of applicability
of the developed conditions. To facilitate further development, we consider the
case where the set of output matrices Cj, j = 1, ..., ns is assumed to be of full
row rank.
Using the local static output-feedback control uj(t) = Kojyj(t), j =
1, ..., N, the local closed-loop subsystem dynamics under failure become
˙xj(t)
=
Ajxj(t) + Adjxj(t −τj(t)) + Bjβj(uj) + cj(t) + Ωjwj(t)
zj(t)
=
Gjxj(t) + Gdjxj(t −τj(t)) + Djβj(uj) + Bjwj(t)
cj(t)
=
ns

k=1
Fjkxk(t) +
ns

k=1
Ejkxk(t −ηjk(t))
Aj
=
Aj + BjΣjKojCj, Adj = Adj + BjΣjKojCj,
Gj
=
Gj + DjΣjKojCj, Gdj = Gdj + DjΣjKojCdj
(7.33)
Proceeding further, we adopt the Lyapunov functional (7.10) to the re-
sulting closed-loop system (7.33). As a consequence, system (7.33) is
asymptotically stable with L2-performance bound γj if there exist matrices
Pj, Qj, Wj, Zkj, j, k = 1, ..ns, parameter matrices Θj Υj satisfying the
following LMI:
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
Ξoj
Ξaj
−ϱjΘj
0
PjBj
PjΩj
Gt
j
ϱkAt
jWk
•
−Ξmj
−ϱjΥj
0
0
0
Gt
dj
ϱkAt
djWk
•
•
−ϱjWj
0
0
0
0
0
•
•
•
−Ξnj
0
0
0
ϱk
ns
k=1 EkjWk
•
•
•
•
−Ij
0
0
0
•
•
•
•
•
−γ2
j Ij
Bt
j
ϱkΓt
jWk
•
•
•
•
•
•
−Ij
0
•
•
•
•
•
•
•
−ϱkWk
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
< 0
(7.34)
where
Ξoj
=
Pj[Aj +
ns

k=1
Fkj] + [Aj +
ns

k=1
Fkj]tPj + Θj + Θ
t
j + Qj +
ns

k=1
Zkj
+
Ct
jKt
ojΓt
jΓjKojCj + (ns −1)Pj,

292
Chapter 7. Decentralized Reliable Control
Ξaj
=
PjAdj −Θj + Υ
t
j + Ct
jKt
ojΓt
jΓjKojCdj,
Ξmj
=
Υj + Υ
t
j + (1 −μj)Qj + Ct
djKt
ojΓt
jΓjKojCdj,
Ξnj
=
ns

k=1,k̸=j
(1 −μkj)Zkj +
ns

k=1,k̸=j
Et
kjPjEkj
(7.35)
The following theorem establishes the main design result for subsystem Sj.
Theorem 7.1.5 Given the bounds ϱj > 0, μj > 0, ϱjk > 0, μjk > 0, j, k =
1, ..., ns and matrix Wj, then the family of subsystems {Sj} where Sj is de-
scribed by (7.7) is delay-dependent asymptotically stabilizable by decentral-
ized static output-feedback controller uj(t) = Kojyj(t), j = 1, ..., N with
L2-performance bound γj, j = 1, ..., ns if there exist positive-deﬁnite matri-
ces Xj, Yj, Wk, {Λkj}ns
k=1,
{Ψrj}6
r=1, satisfying the following LMIs for j, k = 1, ..., ns:
(Πj
=
)
(Πaj
(Πcj
•
(Πej
*
< 0
(7.36)
(Πaj
=
⎡
⎢⎢⎢⎢⎣
Πoj
Πaj
−ϱjΨ1j
Πcj
Bj
•
−Πmj
−ϱjΨ3j
0
0
•
•
−ϱjΨ4j
0
0
•
•
•
−Πnj
0
•
•
•
•
−Ij
⎤
⎥⎥⎥⎥⎦
,
(Πcj
=
⎡
⎢⎢⎢⎢⎣
Ωj
Πt
zj
Yt
jΓt
j
ϱk(XjAt
j + Yt
jΣt
jBt
j)Wk
0
Πt
xj
Ψt
6jΓt
j
ϱkXjAt
djWk
0
0
0
0
0
0
0
ϱk
ns
k=1 XjEkjWk
0
0
0
0
⎤
⎥⎥⎥⎥⎦
,
(Πej
=
⎡
⎢⎢⎣
−γ2
j Ij
Bt
j
0
ϱkΓt
jWk
•
−Ij
0
0
•
•
−Ij
0
•
•
•
−ϱkWk
⎤
⎥⎥⎦
(7.37)
where
Πoj
=
[Aj +
ns

k=1
Fkj]Xj + BjΣjYj + Xj[Aj +
ns

k=1
Fkj]t + Yt
jΣt
jBt
j
+
Ψ1j + Ψt
1j + Ψ2j +
ns

k=1
Λkj + (ns −1)Xj

7.1. Interconnected Continuous Systems
293
Πaj
=
AdjXj −Ψ1j + Ψt
3j, Πmj = Ψ3j + Ψt
3j + (1 −μj)Ψ2j
Πnj
=
ns

k=1
(1 −μkj)Λkj + +
ns

k=1,k̸=j
XjEt
kjsPkEkjsXj,
Πxj
=
GdjXj + DjΣjΨ6j, Πzj = GjXj + DjΣjYj
(7.38)
Moreover, the local gain matrix is given by Kj = YjX −1
j
C†
j.
Proof: Applying the congruent transformation
T = diag[Xj, Xj, Xj, Xj, Ij, Ij, Ij, Ij], Xj = P
−1
j
to LMI (7.34) with Schur complements and using the linearizations
Yj
=
KojCjXj, Ψ1j = XjΘjXj, Ψ2j = XjQjXj, Ψ3j = XjΥjXj
Λkj
=
XjZkjXj, Ψ4j = XjWjXj, Ψ5j = XjCt
djKt
ojΓt
j, Ψ6j = Kt
ojCt
djXj
we readily obtain LMI (7.36) by Schur complements and therefore the proof is
completed.
Remark 7.1.6 Similarly, the optimal performance-level γj, j = 1, .., ns can
be determined in case of decentralized static output-feedback stabilization by
solving the following convex optimization problems:
Problem B: Static Output-Feedback Stabilization
For j, k = 1, ..., ns,
Given ϱj, μj, ϱjk, μjk,
min
Xj, Yj, Mj, Ωj, {Λrj}ns
r=1, {Ψrj}6
1
γj
subject to
LMI(7.36)
(7.39)
7.1.7
Illustrative example 7.1
Consider an interconnected system composed of three subsystems, each of the
type (7.1) with the following subsystem coefﬁcients:
Subsystem 1 :
A1 =
 −2
0
−2
−1

, Ω1 =
 0.2
0.2

, B1 =
 1
2

,
G1
=

0.2
0.1

,
Ad1 =
 −1
0
−1
0

, Gd1 =

−0.1
0

, B1 = 0.5, D1 = [0.1]
Subsystem 2 :
Ac =
 −1
0
−1
−4

, Ωc =
 0.1
0.3

, B2 =

1
1
−1
2

,

294
Chapter 7. Decentralized Reliable Control
G2 =

0.2
0.1

,
Ad2 =
 1
0
−2
−1

, Gd2 = [ 0.1
0 ], B2 = 0.2, D2 = [0.2
0.4]
Subsystem 3 :
A3 =

0
1
−1
−2

, Ω3 =
 0.1
0.5

, B3 =
 2
1

,
G3 =

0.1
−0.1

,
Ad3 =
 0
0
0
−1

, Gd3 =

−0.1
0

, B3 = 0.1, D3 = [0.3]
and the coupling pattern
Couplings 1 :
E12 =
 1
0
1
0

, E13 =
 0
−1
0
−1

, F12 =
 0.2
−0.1
0
0.2

,
F13 =
 0
−0.4
0.1
−0.5

,
Couplings 2 :
E21 =
 −1
−2
3
6

, E23 =
 −1
1
3
−2

, F21 =
 0
−0.5
0.8
−0.5

,
F23 =
 −0.7
0.6
0
−0.2

,
Couplings 3 :
E31 =
 1
2
1
2

, E32 =
 0
0
0
−1

,
F31 =
 0.7
0
0
0.8

, F32 =
 0
0
0
−1

In order to illustrate the effectiveness of our reliable control algorithm, we ini-
tially consider the nominal control design in which no actuator failures will
occur. Then, by using the data values Σ1 = 1, Σc = 1, Σ3 = 1, Γ1 =
0, Γc = 0, Γ3 = 0 and solving Problem A, it is found that the feasible
solution yields the following control gain matrices and performance levels:
γ1 = 1.7874, K1 =

1.2551
−2.3786

,
γc = 3.1742, K2 =
 −12.9437
2.0436
−9.4414
−8.0502

,
γ3 = 2.0297, K3 =

−0.0540
1.0240

(7.40)

7.1. Interconnected Continuous Systems
295
Next, we study different failure scenarios. The ﬁrst scenario is described by the
following model:
uf
1(t)
=
0.6 u1(t) + β1(u1), β2
1(u1) ≤0.01 u2
1,
uf
2(t)
=
0.8 u2(t) + βc(u2), β2
2(u2) ≤0.09 u2
2,
uf
3(t)
=
0.4 u3(t) + β3(u3), β2
3(u3) ≤0.04 u2
3
(7.41)
which corresponds to allowing a failure of the order of 60% in the actuator of
system Sj with an error of the order of 10%. In a similar way, the tolerances
allowed for other actuators are interpreted in the same way. Thus we have Σ1 =
0.6, Γ1 = 0.1, Σc = 0.8, Γc = 0.3, Σ3 = 0.4, Γ3 = 0.2 and upon solving
Problem A again, the resulting feasible solution is summarized by
γ1
=
1.9492, K1 =

2.4945
−4.6355

,
γc
=
3.7842, K2 =
 −18.3947
3.3116
−14.5364
−12.5472

,
γ3
=
2.4123, K3 =

−0.1177
2.1270

Next consider the static output feedback design with the additional coefﬁcients
C1 = [0.2
0], C1 = [0.6
0.4], C1 = [0.5
0]
Considering Problem C, it is found that the feasible solution is attained at
γ1
=
1.8011, K1 =

1.1187
0.8962

,
γc
=
13.4931, K2 =
 −8.8441
1.3237
−3.9501
−3.3300

,
γ3
=
1.4746, K3 =

0.6289
−0.2550

(7.42)
Using numerical simulation, three typical experiments were performed for
three operational modes.
1) Ideal mode, where the nominal controllers (7.40) were implemented in
an operation without failures.
2) Failure mode, where the nominal controllers (7.40) are implemented in
an operation under the failures described in (7.41).
3) Reliable control failure mode, where the reliable controllers (7.42) are
implemented in an operation under the failures described in (7.41).
Simulation results of the ﬁrst state trajectories of the three subsystems are
displayed in Figures 7.2 through 7.4 for the prescribed modes of operation.
The trajectories of the state-feedback control input for the ﬁrst subsystem are

296
Chapter 7. Decentralized Reliable Control
0
1
2
3
4
5
6
7
8
−0.5
−0.4
−0.3
−0.2
−0.1
0
0.1
0.2
Time
Trajectories of first state−Subsystem S1 
Failure Mode−Reliable
Failure Mode−Nominal
Ideal Mode
Figure 7.2: Trajectories of ﬁrst state-Subsystem 1
depicted in Figure 7.5. In the case of static output feedback, the trajectories
of the output of the ﬁrst subsystem are depicted in Figure 7.6 (under the three
modes) and the corresponding trajectories for the output-feedback control sig-
nal are displayed in Figure 7.7.
It is observed that the nominal control clearly deteriorates its ideal per-
formance when operating under failures. When using the reliable control, we
notice that the state response results drastically improved in spite of working
under the same failures, being very close to the one obtained in the ideal case.
As illustrated by Figures 7.5 and 7.7, the control effort in this case has a big-
ger initial magnitude than for the nominal cases, quickly approaching the ideal
control signals. These results illustrate the satisfactory behavior of the proposed
reliable control scheme.
7.2
Application to Multi-Area Power Systems
It becomes increasingly apparent that large-scale systems manifest the real
world and appear in different applications such as power systems, digital com-
munication networks, economic systems, and urban trafﬁc networks. An inte-
gral feature of these systems is that they are composed of a set of small inter-
connected subsystems [224]; due to technical and/or economical reasons it is
generally quite difﬁcult to incorporate feedback from all the subsystems into
the controller design. These difﬁculties motivate the development of decentral-
ized control theory where each subsystem is controlled independently based

7.2. Application to Multi-Area Power Systems
297
0
1
2
3
4
5
6
7
8
−0.6
−0.5
−0.4
−0.3
−0.2
−0.1
0
0.1
0.2
0.3
0.4
Time
Trajectories of first state−Subsystem S2
Failure Mode−Reliable
Failure Mode−Nominal
Ideal Mode
Figure 7.3: Trajectories of ﬁrst state-Subsystem 2
0
1
2
3
4
5
6
7
8
−0.7
−0.6
−0.5
−0.4
−0.3
−0.2
−0.1
0
0.1
0.2
0.3
Time
Trajectories of first state−Subsystem S3
Failure Mode−Reliable
Failure Mode−Nominal
Ideal Mode
Figure 7.4: Trajectories of ﬁrst state-Subsystem 3

298
Chapter 7. Decentralized Reliable Control
0
1
2
3
4
5
6
7
8
−1.4
−1.2
−1
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
Time
Trajectories of first control−Subsystem S1
Failure Mode−Reliable
Failure Mode−Nominal
Ideal Mode
Figure 7.5: Trajectories of control input-Subsystem 1
0
5
10
15
20
−0.5
0
0.5
1
1.5
2
2.5
Time
Trajectories of output−Subsystem S1 
Failure Mode−Nominal
Failure Mode−Reliable
Ideal Mode
Figure 7.6: Trajectories of output-Subsystem 1

7.2. Application to Multi-Area Power Systems
299
0
5
10
15
20
−0.8
−0.7
−0.6
−0.5
−0.4
−0.3
−0.2
−0.1
0
0.1
Time
Trajectories of output feedback control−Subsystem S1 
Failure Mode−Reliable
Failure Mode−Nominal
Ideal Mode
Figure 7.7: Trajectories of output feedback control-Subsystem 1
on locally available information [324]. Relevant research results on decentral-
ized control of relevance to this paper can be found in [173, 288, 328]. Among
the fundamental issues that arise quite frequently when designing feedback
controllers for interconnected systems is the reliability of the control systems
against different component failures. It becomes increasingly evident that the
reliability of control systems in the presence of system component failures is
of paramount importance for maintaining the critical functionality and surviv-
ability of many safety critical systems.
On another research front, various advanced control technologies have been
applied to excitation and steam valving controllers of power systems including
differential geometric tools [33, 190, 256]. It has been shown that the dynamics
of power systems can be exactly linearized by employing nonlinear feedback
and a state transformation. In the load-frequency control function, it is nec-
essary to keep the system frequency and the inter-area tie-line power as near
to the scheduled values as possible through control action. Considering the
automatic-generation control (AGC) function, it is required to design the con-
trols at the governor terminals while taking into account possible delays and
control actuator failures.
In what follows, the AGC problem of multi-area power systems subject
to actuator failures is translated into an equivalent problem of decentralized
reliable feedback control for a class of linear interconnected continuous-time
systems having internal subsystem time-delays and additional time-delay cou-
plings under a class of control failures. The failure model takes into considera-
tion possible outages or partial failures in every single actuator of each decen-

300
Chapter 7. Decentralized Reliable Control
tralized controller.
7.2.1
Single-area AGC model
In the sequel, we consider the AGC problem of multi-area power systems. Our
objective is to study this problem subject to possible actuator failures while
considering different delay patterns. For single area AGC model including ACE
delay, the linearized equations can be expressed as:
˙xj(t)
=
Ajxj(t) + Adjxj(t −τj(t)) + Bjuj(t) + ΓjΔPdj
yj(t)
=
Cjxj(t),
Aj
=
⎡
⎢⎢⎣
−Dj/Mj
1/Mj
0
0
0
−1/Tej
1/Tej
0
−1/RjTgj
0
−1/Tgj
−1/Tgj
Kj
0
0
0
⎤
⎥⎥⎦
(7.43)
and
Bj
=
⎡
⎢⎢⎣
0
0
1/Tgj
0
⎤
⎥⎥⎦, Ct
j =
⎡
⎢⎢⎣
1
0
1
1
⎤
⎥⎥⎦, Γt
j =
⎡
⎢⎢⎣
−1/Mj
0
0
0
⎤
⎥⎥⎦
Adj
=
⎡
⎢⎢⎣
0
0
0
0
0
0
0
0
0
0
0
1/Tgj
0
0
0
0
⎤
⎥⎥⎦
(7.44)
with xj = [Δfj,
ΔPmj,
ΔPvj,
ΔEj]t, uj is the control at the governor
terminal, ΔPdj is the load disturbance, Dj is a load damping constant, Mj
is the inertia constant, Tej is the turbine time-constant, Tgj is the governor
time-constant, Rj is the speed regulation due to governor action, Kj is the
integral control gain, Δfj is the incremental frequency deviation, ΔPmj is the
incremental generator output change, and ΔPvj is the incremental governor
valve position change. Observe that Adj reﬂects the effect of delayed ACE
signal and the structure of matrix Cj implies that the output simply tracks the
frequency deviation and the integral control error (ACE) deviation. In the case
of a linearized multi-area power system composed of ns power areas, the model
(7.43) is then modiﬁed to include the area couplings and associated delays into

7.2. Application to Multi-Area Power Systems
301
the state-space representation:
˙xj(t)
=
Ajxj(t) + Adjxj(t −τj(t)) + Bjuj(t)
+
ns

k=1,k̸=j
Fjkxk(t) +
ns

k=1,k̸=j
Ejkxk(t −ηjk(t))
(7.45)
where the matrices Fjk ∈ℜnj×nk, Ejk ∈ℜnj×nk are real and constants. The
factors τj, ηjk, j, k ∈{1, ..., ns} are unknown time-delay factors satisfying
0 ≤τj(t) ≤ϱj, 0 ≤ηjk(t) ≤ϱjk
(7.46)
where the bounds ϱj, ηjk are known constants in order to guarantee smooth
growth of the state trajectories. The inclusion of the term Ejkxk(t −ηjk(t))
is meant to emphasize the communication and telemetry delays and the delays
among the power areas.
In the sequel, we consider that system (7.45) is assumed to operate under
failures described by extension of the representation [39] to the decentralized
setting treated hereafter. Such representation allows independent outage or par-
tial degradation in any single actuator of every decentralized controller. In this
way, a rather general scenario is deﬁned for the design of a reliable decen-
tralized control structure for a class of interconnected systems simultaneously
facing uncertainties and failures. Our objective is to apply the decentralized
reliable stabilization method by developing decentralized state feedback con-
trollers in the presence of failures described in Theorem 7.1.1 and deriving a
feasibility testing at the subsystem level so as to guarantee the overall system
asymptotic stability with a prescribed performance measure.
7.2.2
Simulation results
In the following, the developed decentralized reliable control method is demon-
strated on a three-area power system model. For purposes of AGC, area one is
modeled by two generators while the other two areas have single generator
equivalents. Standard simpliﬁed models are used [328]. In order to illustrate
the effectiveness of our reliable control algorithm, we initially consider the
nominal control design in which no actuator failures will occur. Then, by using
the data values Σ1 = 1, Σc = 1, Σ3 = 1, Π1 = 0, Π2 = 0, Π3 = 0, it is
found that the feasible solution of Theorem 7.1.1 yields the following control

302
Chapter 7. Decentralized Reliable Control
gain matrices and performance levels:
γ1
=
3.0297,
K1
=

1.2551
−0.1421
0.0011
−2.3786

,
γc
=
1.9117,
K1
=

−1.9437
2.0436
−0.0541
1.0242

,
γ3
=
1.9117,
K1
=

1.9437
2.0436
−0.0541
1.0242

Next, we study different failure scenarios. The ﬁrst scenario is described by the
following model:
uf
1(t)
=
0.6 u1(t) + β1(u1), β2
1(u1) ≤0.01 u2
1,
(7.47)
uf
2(t)
=
0.8 u2(t) + βc(u2), β2
2(u2) ≤0.09 u2
2
uf
3(t)
=
0.4 u3(t) + β3(u3), β2
3(u3) ≤0.04 u2
3
(7.48)
which corresponds to allowing a failure of the order of 60% in the actuator of
system Sj with an error of the order of 10%. In a similar way, the tolerances
allowed for other actuators are interpreted in the same way. Thus we have Σ1 =
0.6, Π1 = 0.1, Π2 = 0.8, Π2 = 0.3, Σ3 = 0.4, Π3 = 0.2 and Theorem
7.1.1 was solved again. Using numerical simulation, three typical experiments
were performed for three operational modes.
1) Ideal mode, where the nominal AGC controllers are implemented in an
operation without failures.
2) Failure mode, where the nominal AGC controllers are implemented in
an operation under the failures described in (7.48).
3) Reliable control failure mode, where the reliable AGC controllers are
implemented in an operation under the failures described earlier.
Simulation results of the frequency deviations of the three power areas are
displayed Figures 7.8 through 7.10 for the prescribed modes of operation. The
trajectories of the state-feedback AGC control input for the ﬁrst power area are
depicted in Figure 7.11.
It is observed that the nominal AGC control clearly deteriorates its ideal
performance when operating under failures. When using the reliable AGC con-
trol, we notice that the state response results drastically improved in spite of
working under the same failures, being very close to the one obtained in the
ideal case.

7.2. Application to Multi-Area Power Systems
303
0
1
2
3
4
5
6
7
8
−0.5
−0.4
−0.3
−0.2
−0.1
0
0.1
0.2
Time
Trajectories of first state−Subsystem S1 
Failure Mode−Reliable
Failure Mode−Nominal
Ideal Mode
Figure 7.8: Trajectories of frequency deviation (pu)-Area 1
0
1
2
3
4
5
6
7
8
−0.6
−0.5
−0.4
−0.3
−0.2
−0.1
0
0.1
0.2
0.3
0.4
Time
Trajectories of first state−Subsystem S2
Failure Mode−Reliable
Failure Mode−Nominal
Ideal Mode
Figure 7.9: Trajectories of frequency deviation (pu)-Area 2

304
Chapter 7. Decentralized Reliable Control
0
1
2
3
4
5
6
7
8
−0.7
−0.6
−0.5
−0.4
−0.3
−0.2
−0.1
0
0.1
0.2
0.3
Time
Trajectories of first state−Subsystem S3
Failure Mode−Reliable
Failure Mode−Nominal
Ideal Mode
Figure 7.10: Trajectories of frequency deviation (pu)-Area 3
0
1
2
3
4
5
6
7
8
−1.4
−1.2
−1
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
Time
Trajectories of first control−Subsystem S1
Failure Mode−Reliable
Failure Mode−Nominal
Ideal Mode
Figure 7.11: Trajectories of AGC control input-Area 1

7.2. Application to Multi-Area Power Systems
305
7.2.3
Reliable control against sensor failures
In what follows, we direct attenuation to the reliable decentralized feedback
stabilization problem under a class of sensor failures. These failures are de-
scribed by a model that takes into consideration possible outages or partial
failures in every sensor of each decentralized control loop. Our development
follows the results of the foregoing section with appropriate modiﬁcations.
We consider a class of linear systems S structurally composed of ns cou-
pled subsystems Sj and the model of the jth subsystem is described by the
state-space representation:
˙xj(t)
=
Ajxj(t) + Adjxj(t −τj(t)) + Bjuj(t) + cj(t)
yj(t)
=
Cjxj(t) + Cdjxj(t −τj(t))
(7.49)
where for j ∈{1, ..., ns}, xj(t) ∈ℜnj is the state vector, uj(t) ∈ℜmj
is the control input, yj(t) ∈ℜpj
is the measured output, wj(t) ∈ℜqj is
the disturbance input which belongs to L2[0, ∞), zj(t) ∈ℜqj is the perfor-
mance output. The matrices Aj ∈ℜnj×nj, Bj ∈ℜnj×mj, Dj ∈ℜqj×mj,
Adj ∈ℜnj×nj,
Bj ∈ℜqj×qj,
Ωj ∈ℜnj×qj,
Cj ∈ℜpj×nj,
Cdj ∈
ℜpj×nj, Gj ∈ℜqj×nj, Gdj ∈ℜqj×nj
are real and constants. The ini-
tial condition ⟨xj(0), xj(r)⟩= ⟨xoj, Bj⟩, j ∈{1, ..., ns} where Bj(.) ∈
L2[−τ ∗
j , 0], j ∈{1, ..., ns}. The interactions between subsystem Sj and the
other subsystems is summarized by the coupling vector cj(t) ∈ℜnj where
ct
j(t)cj(t) ≤αjxt
j(t)Et
jEjxj(t) + βjxt
j(t −τj(t))F t
j Fjxj(t −τj(t)) (7.50)
where αj, βj are adjustable parameters and the matrices Fj ∈ℜnj×nj, Fj ∈
ℜnj×nkj are real and constants. The factors τj, j ∈{1, ..., ns} are unknown
time-delays satisfying
0
≤
τj(t) ≤ϱj,
˙τj(t) ≤μj
(7.51)
where the bounds ϱj, μj are known constants in order to guarantee smooth
growth of the state trajectories. It must be emphasized that inequality (7.50)
is guaranteed to satisfy the interconnection patterns (7.2) when taking over all
subsystems under the condition (7.19). Similar inequalities have been used in
the foregoing chapters to classify the information structures.
Consider that system (7.49) is operating under sensor failures and our ap-
proach goes in parallel with the case of actuator failure. We extend the rep-
resentation of [39] to a decentralized setting since such representation allows
independent outage or partial degradation in any single sensor of every decen-
tralized observation channel. In this way, a rather general scenario is deﬁned

306
Chapter 7. Decentralized Reliable Control
for the design of reliable decentralized control structure for a class of intercon-
nected systems facing simultaneous uncertainties and sensor failures. Proceed-
ing further, we let yf
j ∈ℜfj denote the vector of signals from the fj sensor of
the jth subsystem. In the sequel, we consider the following failure model:
yf
j (t)
=
Πjyj(t) + θj(yj)
(7.52)
where 0 < Πj ∈ℜfj×fj = diag(πj1, ...., πjfj) and the function
θj(yj) = [θj1(yj1), ..., θjfj(yjfj)]t
is uncertain and satisﬁes, for each j,
θ2
jk ≤λ2
jk u2
jk,
k = 1, ..., fj, λ2
jk ≥0
(7.53)
When (7.53) holds, then
||θj(xj)||2 ≤||Λjuj||2,
j = 1, ..., ns
(7.54)
where 0 ≤Λj = diag(λj1, ...., λjfj) ∈ℜfj×fj. The value of πjk, k = 1, .., fj
represents the percentage of failure in the sensor j controlling subsystem Sj.
With this representation, each subsystem sensor can fail independently. Note
that the condition λjk = 1, λjk = 0 represents the normal case for the kth
sensor of the jth subsystem (yf
jk(t) = yjk(t)). When this situation holds for
all k, we get that Πj = Ifj and Λj = 0 which in turn clariﬁes the normal case
in the jth channel (yf
j (t) = yj(t)). In the particular case πjk = λjk, (7.52) and
(7.53) cover the outage case (yf
jk = 0) since θjk = −πjkyjk satisﬁes (7.53).
Alternatively, the case θj(yj) = −πjuj discloses the outage of the observation
channel of the jth system. Indeed, there are different cases that would reveal
partial failures or partial degradations of the sensors.
Our objective hereafter is to study two main problems:
1. The ﬁrst problem is with the decentralized reliable stabilization by de-
veloping decentralized feedback controllers (based on state, static out-
put, and dynamic output) in the presence of sensor failures described by
(7.52)-(7.53) and deriving a feasibility testing at the subsystem level so
as to guarantee the overall system asymptotic stability with a prescribed
performance measure.
2. The second problem deals with the resilient decentralized reliable sta-
bilization by developing resilient decentralized feedback controllers that
take into consideration additive gain perturbations while ensuring that
the overall closed-loop system is asymptotically stable with a prescribed
performance measure.

7.2. Application to Multi-Area Power Systems
307
7.2.4
State-feedback reliable design
New criteria for LMI-based characterization of decentralized reliable stabiliza-
tion are developed using local state feedback. The criteria include some param-
eter matrices aimed at expanding the range of applicability of the developed
conditions. Using the local state feedback uj(t) = Kjxj(t), j = 1, ..., N, the
local closed-loop subsystem under failure becomes
˙xj(t)
=
&Ajxj(t) + Adjxj(t −τj(t)) + Bjβj(uj) + cj(t) + Ωjwj(t)
zj(t)
=
&Gjxj(t) + Gdjxj(t −τj(t)) + Djβj(uj) + Bjwj(t)
&Aj
=
Aj + BjΣjKj,
&Gj = Gj + DjΣjKj
(7.55)
The following theorem establishes the main design result for subsystem Sj
where in the subsections that follow, asymptotic stability conditions and the
reliable decentralized feedback gains are derived.
Theorem 7.2.1 Given the bounds ϱj > 0,
μj > 0,
ϱjk > 0, μjk >
0,
j, k = 1, ..., ns and matrix Wj, then the family of subsystems {Sj}
where Sj is described by (7.55) is delay-dependent asymptotically stabiliz-
able by decentralized controller uj(t) = Kjxj(t), j = 1, ..., ns with L2-
performance bound γj,
j = 1, ..., ns if there exist positive-deﬁnite ma-
trices Xj,
Yj,
{Λkj}ns
k=1,
{Ψrj}4
r=1,
satisfying the following LMIs for
j = 1, ..., ns:
(Πj
=
)
(Πj1
(Πj2
•
(Πj3
*
< 0
(7.56)
(Πj1
=
⎡
⎢⎢⎢⎢⎣
Πoj
Πaj
−ϱjΨ1j
Πcj
Bj
•
−Πmj
−ϱjΨ3j
0
0
•
•
−ϱjΨ4j
0
0
•
•
•
−Πnj
0
•
•
•
•
−Ij
⎤
⎥⎥⎥⎥⎦
(Πj2
=
⎡
⎢⎢⎢⎢⎣
Ωj
Πt
zj
Yt
jΓt
j
ϱj(XjAt
j + Yt
jΣt
jBt
j)Wj
0
Gt
dj
0
ϱkXjAt
djWk
0
0
0
0
0
0
0
ϱk
ns
k=1 XjEkjWk
0
0
0
0
⎤
⎥⎥⎥⎥⎦
(Πj3
=
⎡
⎢⎢⎣
−γ2
j Ij
Bt
j
0
ϱkΓt
jWk
•
−Ij
0
0
•
•
−Ij
0
•
•
•
−ϱkWk
⎤
⎥⎥⎦
(7.57)

308
Chapter 7. Decentralized Reliable Control
where
Πoj
=
[Aj +
ns

k=1
Fkj]Xj + BjΣjYj + Xj[Aj +
ns

k=1
Fkj]t
+
Yt
jΣt
jBt
j + Ψ1j + Ψt
1j + Ψ2j +
ns

k=1
Λkj
Πaj
=
AdjXj −Ψ1j + Ψt
3j, Πmj = Ψ3j + Ψt
3j + (1 −μj)Ψ2j,
Πnj
=
ns

k=1,k̸=j
(1 −μkj)Λkj, Πcj =
ns

k=1,k̸=j
EkjXj,
Πzj
=
GjXj + DjΣjYj
(7.58)
Moreover, the local gain matrix is given by Kj = YjX −1
j
.
Proof: Consider the LKF:
V (t)
=
ns

j=1
Vj(t), Vj(t) = Voj(t) + Vaj(t) + Vmj(t) + Vnj(t),
Voj(t)
=
xt
j(t)Pjxj(t), Vaj(t) =
 0
−ϱj
 t
t+s
˙xt
j(α)Wj ˙xj(α)dα ds,
Vmj(t)
=
 t
t−τj(t)
xt
j(s)Qjxj(s) ds,
Vnj(t)
=
ns

k=1,k̸=j
 t
t−ηjk(t)
xt
k(s)Zjkxk(s) ds
(7.59)
where 0 < Pj = Pt
j, 0 < Wj = Wt
j, 0 < Qj = Qt
j, 0 < Zjk = Zt
jk, j, k ∈
{1, ..., ns} are weighting matrices of appropriate dimensions. Observe that by
using the failure model inequality (7.53) with uj(t) = Kjxj(t), we have
βt
j(xj)βj(xj) ≤xt
jKt
jΓt
jΓjKjxj
(7.60)
For the time being, we consider that the gains Kj are speciﬁed. A straight-
forward computation gives the time derivative of V (t) along the solutions of
(7.55) with w(t) ≡0 as:
˙Voj(t)
=
2xt
jPj ˙xj = 2xt
jPj[ &Ajxj(t) + Adjxj(t −τj(t)) + Bjβj(uj)]
+
2xt
jPj
ns

k=1
Fjkxk(t) + 2xt
jPj
ns

k=1
Ejkxk(t −ηjk(t))
(7.61)

7.2. Application to Multi-Area Power Systems
309
Some manipulations lead to
˙Voj(t)
=
= 2xt
jPj[ &Aj + Adj]xj(t)
+
2xt
j[Θj −PjAdj]
 t
t−τj(t)
˙xj(s)ds + 2xt
jPjBjβj(uj)
+
2xt(t −τj(t))Υj
 t
t−τj(t)
˙xj(s)ds
−

2xt
jtΘj
 t
t−τj
˙xj(s)ds + 2xt(t −τj(t))Υj
 t
t−τj(t)
˙xj(s)ds

+
+2xt
jPj
ns

k=1,k̸=j
Fjkxk(t) + 2xt
jPj
ns

k=1,k̸=j
Ejkxk(t −ηjk(t))
(7.62)
Little algebra gives
˙Voj(t)
=
1
τj(t)
 t
t−τj(t)
)
2xt
j[Pj &Aj + Θj]xj
+
2xt
j[PjAdj −Θj + Υt
j]xj(t −τj(t))
−
2xt
j(t −τj(t))Υx(t −τj) −2xtτjΘ ˙xj(s)
−
2xt
j(t −τj(t))τj(t)Υj ˙xj(s) + 2xt
jPjBjβj(uj)
+
2xt
jPj
ns

k=1,k̸=j
Fjkxk(t) + 2xt
jPj
ns

k=1,k̸=j
Ejkxk(t −ηjk(t))
*
ds
(7.63)
where Θj ∈ℜnj×nj and Υj ∈ℜnj×nj are appropriate relaxation matrices
injected to facilitate the delay-dependence analysis.
˙Vaj(t)
=
 t
t−ϱj
[ ˙xt
j(t)Wj ˙xj(t) −˙xt
j(s)Wj ˙xj(s)]d s
=
ϱj ˙xt
j(t)Wj ˙xj(t) −
 t
t−τj
˙xt
j(s)Wj ˙xj(s)ds −
 t−τj
t−ϱj
˙xt
j(s)Wj ˙xj(s)
≤
ϱj ˙xt
j(t)Wj ˙xj(t) −
 t
t−τj
˙xt
j(s)Wj ˙xj(s)ds
=
1
τj(t)
 t
t−τj(t)

ϱj ˙xt
j(t)Wj ˙xj(t) −τj ˙xt
j(s)Wj ˙xj(s)

ds
(7.64)

310
Chapter 7. Decentralized Reliable Control
Note that the term Tj =
 t−τj
t−ϱj ˙xt
j(s)Wj ˙xj(s) accounts for the enlarged time
interval from t −ϱj →t to t −τj →t and it is obvious that Tj > 0. Next, we
have
˙Vmj(t)
=
xt
j(t)Qjxj(t) −(1 −˙τj(t)) xt(t −τj(t))Qjxj(t −τj(t))
≤
xt
j(t)Qjxj(t) −(1 −μj) xt
j(t −τj(t))Qjxj(t −τj(t))
=
1
τj(t)
 t
t−τj(t)

xt
j(t)Qjxj(t)
−
(1 −μj) xt
j(t −τj(t))Qjxj(t −τj(t))

ds
(7.65)
Also, we have
˙Vnj(t)
=
ns

k=1,k̸=j

xt
k(t)Zjkxk(t) −(1 −˙ηjk(t))xt
k(t −ηjk(t))Zjkxk(t −ηjk(t))

≤
ns

k=1,k̸=j

xt
k(t)Zjkxk(t) −(1 −μjk) xt
k(t −ηjk(t))Zjkxk(t −ηjk(t))

(7.66)
For the class of interconnected systems (7.49), the following structural identity
holds:
ns

j=1
ns

k=1,k̸=j
xt
k(t)Zjkxk(t) =
ns

j=1
ns

k=1,k̸=j
xt
j(t)Zkjxj(t)
(7.67)
By combining (7.59)-(7.67) with the aid of Schur complements, we have
˙Vj(t)|(7.55)
≤
ns

j=1
 1
τj
 t
t−τj
χt
j(t, s) Ξj χj(t, s) ds

(7.68)
χj(t, s)
=

xt
j(t) xt
j(t −τj) ˙xt
j(s) xt
j(t −ηkj) βt(xj)
t

7.2. Application to Multi-Area Power Systems
311
Ξj
=
⎡
⎢⎢⎢⎢⎢⎢⎢⎣
Ξoj
Ξaj
−ϱjΘj
Ξcj
PjBj
ϱj &At
jWj
•
−Ξmj
−ϱjΥj
0
0
ϱjAt
djWj
•
•
−ϱjWj
0
0
0
•
•
•
−Ξnj
0
ϱj
ns
k=1 EkjWj
•
•
•
•
−Ij
0
•
•
•
•
•
−ϱjWj
⎤
⎥⎥⎥⎥⎥⎥⎥⎦
Ξoj
=
Pj[ &Aj +
ns

k=1
Fkj] + [ &Aj +
ns

k=1
Fkj]tPj
+
Θj + Θt
j + Qj +
ns

k=1
Zkj + Kt
jΓt
jΓjKj,
Ξaj
=
PjAdj −Θj + Υt
j, Ξcj = Pj
ns

k=1
Ekj
Ξmj
=
Υj + Υt
j + (1 −μj)Qj, Ξnj =
ns

k=1
(1 −μkj)Zkj
(7.69)
where ˙Vj(t)|(7.55) deﬁnes the Lyapunov derivative along the solutions of sys-
tem (7.49). Internal stability requirement ˙Vj(t)|(7.55) < 0 implies that Ξj < 0.
It is readily seen from (7.68) using the delay bounds of (7.51) that there exists
a scalar σj > 0 such that
⎡
⎢⎢⎢⎢⎢⎢⎢⎣
Ξoj + σjIj
Ξaj
−Θj
Ξcj
PjBj
ϱj &At
jWj
•
−Ξmj
−Υj
0
0
ϱjAt
djWj
•
•
−ϱ−1
j Wj
0
0
0
•
•
•
−Ξnj
0
ϱj
ns
k=1 EkjWj
•
•
•
•
−Ij
0
•
•
•
•
•
−ϱjWj
⎤
⎥⎥⎥⎥⎥⎥⎥⎦
< 0
(7.70)
Therefore, for all τj satisfying (7.51) we have
⎡
⎢⎢⎢⎢⎢⎢⎢⎣
Ξoj + σjIj
Ξaj
−τjΘj
Ξcj
PjBj
ϱj &At
jWj
•
−Ξmj
−τjΥj
0
0
ϱjAt
djWj
•
•
−τjWj
0
0
0
•
•
•
−Ξnj
0
ϱj
ns
k=1 EkjWj
•
•
•
•
−Ij
0
•
•
•
•
•
−ϱjWj
⎤
⎥⎥⎥⎥⎥⎥⎥⎦
< 0
(7.71)

312
Chapter 7. Decentralized Reliable Control
and hence
˙Vj(t)|(7.55) <
ns

j=1
 1
τj(t)
 t
t−τj
χt
j(t, s)diag[−σj, 0, 0, 0, 0, 0]χj(t, s) ds

= −
ns

j=1
σj ||xj||2 < 0
(7.72)
Consider the L2 −gain performance measure
J =
ns

j=1
 ∞
0

zt
j(s)zj(s) −γ2
j wt
j(s)wj(s)

ds
For any wj(t) ∈L2(0, ∞) ̸= 0 with zero initial condition xj(0) = 0 hence
V (0) = 0, we have
J
=
ns

j=1
 ∞
0

zt
j(s)zj(s) −γ2
j wt
j(s)wj(s) + ˙Vj(t)|(7.55) −Vj(∞)

ds
≤
ns

j=1
 ∞
0

zt
j(s)zj(s) −γ2
j wt
j(s)wj(s) + ˙Vj(t)|(7.55)

ds
Proceeding as before, we make use of (7.68) to get
ns

j=1

zt
j(s)zj(s) −γ2
j wt
j(s)wj(s) + ˙Vj(t)|(7.55)

=
ns

j=1
¯χt
j(t, s) &Ξj ¯χj(t, s)
(7.73)
where
¯χj(t, s) =
 xt
j(t)
xt
j(t −τj)
˙xt
j(s)
xt
j(t −ηkj)
βt(xj)
wt
j(s) t
&Ξj =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
Ξoj
Ξaj
−ϱjΘj
Ξcj
PjBj
PjΩj
&Gt
j
ϱj &At
jWj
•
−Ξmj
−ϱjΥj
0
0
0
Gt
dj
ϱjAt
djWj
•
•
−ϱjWj
0
0
0
0
0
•
•
•
−Ξnj
0
0
0
ϱj
ns
k=1 EkjWj
•
•
•
•
−Ij
0
0
0
•
•
•
•
•
−γ2
j Ij
Bt
j
ϱjΓt
jWj
•
•
•
•
•
•
−Ij
0
•
•
•
•
•
•
•
−ϱjWj
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦

7.2. Application to Multi-Area Power Systems
313
It is readily seen that when &Ξj < 0 the condition
ns

j=1

zt
j(s)zj(s) −γ2
j wt
j(s)wj(s) + ˙Vj(t)|(7.55)

< 0
for arbitrary s ∈[t, ∞), which implies for any wj(t) ∈L2(0, ∞) ̸= 0 that
J < 0 leading to ns
j=1 ||zj(t)||2
< ns
j=1 γj ||w(t)j||2, which assures the
desired performance.
The immediate task now is to determine the decentralized gain matrices
Kj. Applying the congruent transformation
T = diag[Xj, Xj, Xj, Xj, Ij, Ij, Ij, Ij], Xj = P−1
j
to Ξj with Schur complements and using the linearizations
Yj
=
KjXj, Ψ1j = XjΘjXj, Ψ2j = XjQjXj,
Ψ3j
=
XjΥjXj, Λkj = XjZkjXj, Ψ4j = XjWjXj
we readily obtain LMI (7.56) by Schur complements and therefore the proof is
completed.
Remark 7.2.2 It is signiﬁcant to recognize that our methodology incorpo-
rates four weighting matrices Pj, Qj, Wj, Zjk
and two parameter ma-
trices Θj, Υj at the subsystem level in order to ensure least conservative
delay-dependent stability results. This will eventually result in reduced com-
putational requirements as evidenced by a simple comparison with the im-
proved free-weighting matrices method of [103] for single time-delay systems
in terms of two aspects. One aspect would be due to reduced computational
load as evidenced by a less number of manipulated variables and faster pro-
cessing. Another aspect arises by noting that LMIs (7.77) subject to (7.58) for
ns = 1 theoretically cover the results of [146, 174, 186] as special cases.
Furthermore, in the absence of delay (Adj ≡0, Qj ≡0, Wj ≡0), it
is easy to infer that LMIs (7.77) subject to (7.58) for ns = 1 will eventu-
ally reduce to a parameterized delay-independent criteria. LKF composed of
the ﬁrst three terms has been considered in [74, 103, 261, 290] for single
time-delay systems. In comparison with the reported results on interconnected
systems [251, 283, 287, 288, 328, 371], LKF (7.59) represents a new effec-
tive form and therefore the advantages and reduced conservatism afforded in
[74, 103, 261, 290] are carried over hereafter.

314
Chapter 7. Decentralized Reliable Control
Remark 7.2.3 The optimal performance-level γj, j = 1, .., ns for the inter-
connected system can be determined for decentralized reliable state feedback
by solving the following convex optimization problem:
Problem A
For j, k = 1, ..., ns, Given ϱj, μj, ϱjk, μjk, Wj
min
Xj, Yj, {Λkj}ns
k=1, {Ψrj}3
r=1
γj
subject to LMI(7.77)
(7.74)
7.2.5
Dynamic output-feedback reliable design
In this section, we develop new criteria for LMI-based characterization of de-
centralized reliable stabilization by local static output feedback. The criteria
include some parameter matrices aimed at expanding the range of applicability
of the developed conditions. To facilitate further development, we consider the
case where the set of output matrices Cj, j = 1, ..., ns is assumed to be of full
row rank. Using the local dynamic output-feedback controller:
˙ξj(t)
=
Ajξj(t) + Bjuj(t) + Lj[yf
j (t) −Cjξj(t)]
uj(t)
=
Kjξj(t)
(7.75)
where Lj, Kj are the unknown gain matrices. By deﬁning the state error
ej(t) = xj(t) −ξj(t), then we obtain the closed-loop system as:
˙xj(t)
=
Ajxj(t) + BjKjxj(t) + Adjxj(t −τj(t)) −BjKjej(t) + cj(t)
˙ej(t)
=
(Aj −LjCj)ej(t) + Adjxj(t −τj(t))
+
Lj(Fj −I)Cjxj(t) + LjCdjxj(t −τj(t)) + cj(t)
+
Ljθj(Cjxj(t) + Cdjxj(t −τj(t)))
(7.76)
The following theorem establishes the main design result for subsystem Sj.
Theorem 7.2.4 Given the bounds ϱj > 0, μj > 0, j, k = 1, ..., ns and matrix
Wj, then the family of subsystems {Sj} where Sj is described by (7.76) is delay-
dependent asymptotically stabilizable by decentralized controller uj(t) =
Kjxj(t), j = 1, ..., ns with L2-performance bound γj, j = 1, ..., ns if there
exist positive-deﬁnite matrices Xj, Yj, {Λkj}ns
k=1, {Ψrj}4
r=1, satisfying the
following LMIs for j = 1, ..., ns:
(Πj =
⎡
⎢⎢⎣
Π1j
Nj
Π2j
Π3j
•
−ρWj
0
0
•
•
−ρWj
0
•
•
•
−1
⎤
⎥⎥⎦
(7.77)

7.2. Application to Multi-Area Power Systems
315
where
Π1j =
⎡
⎢⎢⎣
E1
E2
E3
E4
•
E5
E6
E7
•
•
E8
E9
•
•
•
E10
⎤
⎥⎥⎦
(7.78)
E1
=
PjAcj + At
cjPj + Qj + Rj + N1j + N t
1j + αj
E2
=
PjAdj, E3 = N1j,
E4 = Yj(Σj −I)Cj −BjKj
(7.79)
E5
=
−(1 −μj)Qj −2N2j −2N t
2j + βj,
E6 = N2j
E7
=
At
dj + Ct
djFjY t
j ,
E8 = −Rj, Acj = Aj + BjKj
E9
=
0,
E10 = SjAj + At
jSj −YjCj −Ct
jY t
j
Π2j =
⎡
⎢⎢⎢⎢⎣
ρj(At
j + BjKj)Wj
ρjAt
djWj
0
−ρjKt
jBt
jWj
ϱjWj
⎤
⎥⎥⎥⎥⎦
,
Π3j =
⎡
⎢⎢⎢⎢⎣
Ct
jΓt
jY t
j
Ct
djΓt
jY t
j
0
Sj
0
⎤
⎥⎥⎥⎥⎦
, Nj =
⎡
⎢⎢⎢⎢⎣
N1j
N2j
0
0
0
⎤
⎥⎥⎥⎥⎦
Moreover, the local gain matrix is given by Lj = S−1
j Yj.
Proof: Consider the LKF:
V (t)
=
ns

j=1
Vj(t), Vj(t) = V1j(t) + V2j(t) + V3j(t)) + V4j(t) + V5j(t),
V1j(t)
=
xt
j(t)Pjxj(t), V2j(t) =
 0
−ϱj
 t
t+s
˙xt
j(α)Wj ˙xj(α)dα ds,
V3j(t)
=
 t
t−τj(t)
xt
j(s)Qjxj(s) ds,
V4j(t)
=
 t
t−ρj
xt
j(s)Rjxj(s) ds, V5j(t) = et
j(t)Sjej(t)
(7.80)
where 0 < Pj = P t
j , 0 < Wj = Wt
j, 0 < Qj = Qt
j, , j, k ∈{1, ..., ns}
are weighting matrices of appropriate dimensions. Straightforward calculations
yield
˙V1j(t)
=
2xt
jPj ˙xj = 2xt
jPj[Ajxj(t) + KjBjxj(t)
+
Adjxj(t −τj(t)) −KjBjej(t) + cj(t)]
˙V2j(t)
=
 t
t−ϱj
[ ˙xt
j(t)Wj ˙xj(t) −˙xt
j(s)Wj ˙xj(s)]d s
(7.81)

316
Chapter 7. Decentralized Reliable Control
and
˙V3j(t)
=
xt
j(t)Qjxj(t) −(1 −˙τj(t)) xt
j(t −τj(t))Qjxj(t −τj(t))
≤
xt
j(t)Qjxj(t) −(1 −μj) xt
j(t −τj(t))Qjxj(t −τj(t))(7.82)
˙V4j(t)
=
xt
j(t)Rjxj(t) −xt(t −ρj)Rjxj(t −ρj
=
2et
jSj((Aj −LjCj)ej + (Adj + LjCdj)xj(t −τj(t))
+
Lj(Fj −I)Cjxj(t)
(7.83)
+cj(t) + Ljβj(Cjxj(t) + Cdjxj(t −τj(t)))
≤
2et
jSj[(Aj −LjCj)ej + (Adj + LjCdj)xj(t −τj(t))
+
Lj(Fj −I)Cjxj(t) + cj(t)]
+et
j(t)SjSjej(t) + (Cjxj(t)
+
Cdjxj(t −τj(t)))tΓtY t
j YjΓ(Cjxj(t) + Cdjxj(t −τj(t)))
(7.84)
Then by adding the following zero value terms
 xt
j(t)
xt
j(t −τj(t))   2N1j
2N2j

[xj(t) −xj(t −τj(t))
−
 t
t−τj(t)
˙xj(s)ds]
 xt
j(t)
xt
j(t −τj(t))   −N1j
−N2j

[xj(t)
−
xj(t −ρj) −
 t
t−ρj
˙xj(s)ds]
(7.85)
Algebraic manipulations lead to
xt
j(t)[N1j + N t
1j]xj(t) + 2xt
j(t)[−2N1j + N t
2j]xj(t −τ(t))
+2xt
j(t)[N1j]xj(t −ϱ) + 2xt
j(t −τ(t))[−2N2j −2N t
2j]xj(t −τ(t))
+2xt
j(t −τ(t))[N2j]xj(t −ϱ)
−2 ξt
j(t)2Nj
 t
t−τ(t)
˙xj(s)ds −2 ξt
j(t)(Nj)
 t
t−ϱ
˙xj(s)ds = 0
(7.86)
where ξt
j(t) = [xt
j(t) xt
j(t −τj(t)) xt
j(t −ρj) ej(t)]

7.2. Application to Multi-Area Power Systems
317
Since
ϱξt
j(t) Nj W−1
j
N t
j ξj(t) −τ(t)ξt
j(t) Nj W−1
j
N t
j ξj(t)
−(ϱ −τ(t))ξt
j(t) Nj W−1
j
N t
j ξj(t)
−2 ξt
j(t)Nj
 t
t−τ(t)
˙xj(s)ds + 2 ξt
j(t)Nj
 t−τ(t)
t−ϱ
˙xj(s)ds
+
 t−τ(t)
t−ϱ
˙xt
j(s)Wj ˙x(s)jds
+
 t
t−τ(t)
˙xt
j(s)Wj ˙xj(s)ds
(7.87)
= ξt
j(t)
5
ϱNjW−1
j
N t
j
6
ξj(t) −
 t
t−τj(t)
[ξt
j(t)Nj
+ ˙xt
jWj]W−1
c [ξj(t)tNj + ˙xt
j(s)Wj]tds
−
 t−τj(t)
t−ρj
[−ξt
j(t)Nj + ˙xt
j(s)Wj]W−1
j
[−ξt
j(t)Nj + ˙xt
j(s)Wj]tds
Applying the congruent transformation
T = diag[Xj, Xj, Xj, Xj, Ij, Ij, Ij, Ij], Xj = P
−1
j
with Schur complements and using the linearizations
Yj
=
KojCjXj, Ψ1j = XjΘjXj, Ψ2j = XjQjXj, Ψ3j = XjΥjXj
Λkj
=
XjZkjXj, Ψ4j = XjWjXj, Ψ5j = XjCt
djKt
ojΓt
j, Ψ6j = Kt
ojCt
djXj
we readily obtain LMI (7.77) by Schur complements and therefore the proof is
completed.

318
Chapter 7. Decentralized Reliable Control
7.2.6
Illustrative example 7.2
A1
=
⎡
⎢⎢⎣
−4.93
−1.01
0
0
−3.2
−5.3
−12.8
0
6.4
0.347
−32.5
−1.04
0
0.833
11.0
−3.96
⎤
⎥⎥⎦, Bj =
⎡
⎢⎢⎣
1
0
0
1
0
0
0
0
⎤
⎥⎥⎦,
Ad1
=
⎡
⎢⎢⎣
2.92
0
0
0
0
2.92
0
0
0
0
2.87
0
0
0
0
2.724
⎤
⎥⎥⎦,
F12 =
⎡
⎢⎢⎣
1
0
0
0
0
1
0
0
0
0
1
0
0
0
0
1
⎤
⎥⎥⎦,
A2
=
⎡
⎢⎢⎣
−4.0
−2.01
0
1
−3.2
−4.3
−1.8
0
0
1.347
−32.5
−1.04
0
1
11.0
−4
⎤
⎥⎥⎦, Bj =
⎡
⎢⎢⎣
1
0
0
1
0
0
0
0
⎤
⎥⎥⎦,
Ad2
=
⎡
⎢⎢⎣
1.92
0
1
0
0
2
1
0
0
0
2.87
0
0.5
0
0
1.5
⎤
⎥⎥⎦,
F21 =
⎡
⎢⎢⎣
1
0
0
0
0
1
0
0
0
0
1
0
0
0
0
1
⎤
⎥⎥⎦,
Co2
=
 1
10
0
0
0
0
10
10

Cdo2 =
 2
1
0
0
0
0
1
3

It is found that the feasible solution of LMI (7.77) yields
Kc1
=
 −34.5094
−7.2128
14.8074
−12.4102
3.0766
−15.0809
−29.8711
−18.4153

L1
=
⎡
⎢⎢⎣
−2.5426
4.1353
3.9288
−0.3947
−1.0332
1.3764
−0.1978
10.9388
⎤
⎥⎥⎦
Kc2
=
 −24.4560
−4.9061
−52.4436
−130.5408
17.5392
−12.7566
79.5070
157.7008

L2
=
⎡
⎢⎢⎣
−2.1034
2.9994
3.9288
0.7478
0.6681
0.6586
3.2221
10.9388
⎤
⎥⎥⎦

7.2. Application to Multi-Area Power Systems
319
0
0.5
1
1.5
2
−600
−400
−200
0
200
400
Subsystem 1
x11
x12
x13
x14
0
0.5
1
1.5
2
−500
0
500
Subsystem 2
x21
x22
x23
x24
Figure 7.12: Failure mode response
Next, to study the effect of sensor failures, we consider a scenario described by
the following model:
yf
1(t)
=
0.6 y1(t) + θ1(y1), θ2
1(y1) ≤0.01 y2
1,
yf
2(t)
=
0.7 y2(t) + θc(y2), θ2
2(y2) ≤0.02 y2
2
(7.88)
which corresponds to allowing a failure of the order of 60% in the sensor of
system S1 with an error of the order of 10% and a failure of the order of 70%
in the sensor of system S2 with an error of the order of 20%. Using numerical
simulation, typical experiments were performed for two operational modes.
1) Failure mode, where failures occurred without implementing controls.
2) Reliable control mode, where the reliable output-feedback controllers
are implemented in an operation under the failures described in (7.88).
From the plotted graphs, we record the following observations. First, the
failure-mode response in Figure 7.12 clearly shows that the system under this
operational mode is unstable. Second, injecting the reliable controller yields the

320
Chapter 7. Decentralized Reliable Control
0
0.5
1
1.5
2
−400
−200
0
200
400
Subsystem 1
x11
x12
x13
x14
0
0.5
1
1.5
2
−100
0
100
200
Subsystem 2
x21
x22
x23
x24
Figure 7.13: Reliable control mode response

7.3. Interconnected Discrete Delay Systems
321
closed-loop response shown in Figure 7.13. Here the impact of the controller
is evidently quite effective in deriving the system states toward the stable level.
These results illustrate the satisfactory behavior of the proposed reliable control
scheme.
7.3
Interconnected Discrete Delay Systems
In this section, we study the reliable decentralized feedback stabilization prob-
lem of a class of linear interconnected discrete-time systems with interval de-
lays under a class of control failures. These failures are described by a model
that takes into consideration possible outages or partial failures in every sin-
gle actuator of each decentralized controller. The local subsystem has convex-
bounded parametric uncertainties and time-varying delays within the local sub-
systems and across the interconnections. We construct appropriate Lyapunov-
Krasovskii functional in order to exhibit the delay-dependent dynamics. We
develop reliable decentralized feedback stabilization methods which guaran-
tee overall delay-dependent asymptotic stability with an ℓ2 gain smaller that
a prescribed constant level. The solution is expressed in terms of convex op-
timization over new parametrized linear matrix inequalities (LMIs) which can
be conveniently solved by interior-point minimization methods. The developed
results are tested on a representative example.
7.3.1
Problem formulation
We consider a class of linear systems S structurally composed of ns coupled
subsystems Sj and the model of the jth subsystem is described by the state-
space representation:
xj(k + 1)
=
Ajxj(k) + Djxj(k −dj(k)) + Bjuj(k)
+
cj(k) + Ωjwj(k)
(7.89)
zj(k)
=
Gjxj(k) + Hjxj(k −dj(k)) + Ljuj(k)
+
Bjwj(k)
(7.90)
where for j ∈{1, ..., ns}, xj(k) ∈ℜnj is the state vector, uj(k) ∈ℜmj
is the control input, wj(k) ∈ℜqj is the disturbance input which belongs to
ℓ2[0, ∞), zj(k) ∈ℜqj is the performance output, and cj(k) ∈ℜnj is the
coupling vector. The matrices Aj ∈ℜnj×nj, Bj ∈ℜnj×mj, Dj ∈ℜqj×mj,
Bj ∈ℜqj×qj,
Ωj ∈ℜnj×qj,
Lj ∈ℜqj×mj,
Gj ∈ℜqj×nj,
Hj ∈
ℜqj×nj, Fjk ∈ℜnj×nk, and Ejk ∈ℜnj×nk
are real and constants. The

322
Chapter 7. Decentralized Reliable Control
initial condition ⟨xj(0), xj(r)⟩= ⟨xoj, Bj⟩, j ∈{1, ..., ns} where Bj(.) ∈
ℓ2[−τ ∗
j , 0], j ∈{1, ..., ns}. In the sequel, we treat cj(k) as a piecewise-
continuous vector function in its arguments and it satisﬁes the quadratic in-
equality
ct
j(k, ., , ) cj(k, ., .) ≤Bj xt
j(k)F t
j Fjxj(k) +
ψj xt
j(k −ηj(k))Et
djEdjxj(k −ηj(k))
(7.91)
where Bj
>
0, ψj
> 0 are adjustable bounding parameters. The factors
τj, ηjk, j, k ∈{1, ..., ns} are unknown time-delay factors satisfying
0 < d−
j ≤dj(k) ≤d+
j , 0 < η−
j
≤ηj(k) ≤η+
j
(7.92)
where the bounds d−
j , d+
j , η−
jk, η+
jk are known constants in order to guarantee
smooth growth of the state trajectories. Note in (7.89) and (7.91) that the de-
lay within each subsystem (local delay) and among the subsystems (coupling
delay), respectively, are emphasized. The class of systems described by (7.89)-
(7.90) subject to delay-pattern (7.92) is frequently encountered in modeling
several physical systems and engineering applications including large space
structures, multi-machine power systems, cold mills, transportation systems,
and water pollution management, to name a few [252, 253, 324].
7.3.2
Failure model
In the sequel, we follow the treatment of interconnected continuous-time sys-
tems and the reader will notice exact matching between the continuous-time
domain and the discrete-time domain. Thus, we consider that system (7.90) is
assumed to operate under failures described by extension of the representation
[39] to the decentralized setting treated hereafter. Such representation allows
independent outage or partial degradation in any single actuator of every de-
centralized controller. In this way, a rather general scenario is deﬁned for the
design of reliable decentralized control structure for a class of interconnected
systems simultaneously facing uncertainties and failures. Let uf
j ∈ℜfj denote
the vector of signals from the fj actuators that control the jth subsystem. We
consider the following failure model:
uf
j (k) = Σjuj(k) + βj(uj)
(7.93)
where 0 < Σj ∈ℜfj×fj = diag(σj1, ...., σjfj) and the function βj(uj) =
[βj1(uj1), ..., βjfj(ujfj)]t is uncertain and satisﬁes, for each j,
β2
jk ≤γ2
jk u2
jk,
k = 1, ..., fj, γ2
jk ≥0
(7.94)

7.3. Interconnected Discrete Delay Systems
323
When (7.94) holds, then
||βj(uj)||2 ≤||Γjuj||2,
j = 1, ..., ns
(7.95)
where 0 ≤Γj = diag(γj1, ...., γjfj) ∈ℜfj×fj. The value of σjk, k = 1, .., fj
represents the percentage of failure in the actuator j controlling subsystem Sj.
With this representation, each subsystem actuator can fail independently. Note
that the condition σjk = 1, γjk = 0 represents the normal case for the kth
actuator of the jth subsystem (uf
jk(t) = ujk(t)). When this situation holds for
all k, we get that Σj = Ifj and Γj = 0 which in turn clariﬁes the normal case
in the jth channel (uf
j (k) = uj(k)). Of the particular case σjk = γjk, (7.93)
and (7.94) cover the outage case (uf
jk = 0) since βjk = −σjkujk satisﬁes
(7.94). Alternatively, the case βj(uj) = −σjuj discloses the outage of the
whole controller of the jth system. Indeed, there are different cases that would
reveal partial failures or partial degradations of the actuators.
Our objective is to study two main problems: the ﬁrst problem is with the
decentralized reliable stabilization by developing decentralized feedback con-
trollers (based on state, static output, and dynamic output) in the presence of
failures described by (7.93)-(7.94) and deriving a feasibility testing at the sub-
system level so as to guarantee the overall system asymptotic stability with a
prescribed performance measure. The second problem deals with the resilient
decentralized reliable stabilization by developing resilient decentralized feed-
back controllers that take into consideration additive gain perturbations while
ensuring that the overall closed-loop system is asymptotically stable with a
prescribed performance measure.
7.3.3
State-feedback reliable design
In this section, we develop new criteria for LMI-based characterization of de-
centralized reliable stabilization by local state feedback. The criteria include
some parameter matrices aimed at expanding the range of applicability of the
developed conditions. Using the local state feedback uj(k) = Kjxj(k), j =
1, ..., N, the local closed-loop subsystem under failure becomes
xj(k + 1)
=
&Ajxj(k) + Djxj(k −dj(k)) + Bjβj(uj)
+
cj(k) + Ωjwj(k)
(7.96)
zj(k)
=
&Gjxj(k) + Hjxj(k −dj(k)) + Ljβj(uj)
+
Bjwj(k)
(7.97)
&Aj
=
Aj + BjΣjKj, &Gj = Gj + LjΣjKj
(7.98)

324
Chapter 7. Decentralized Reliable Control
Observe that by using the failure model inequality (7.95) with uj(t) =
Kjxj(t), we have
βt
j(xj)βj(xj) ≤xt
jKt
jΓt
jΓjKjxj
(7.99)
For the time being, we consider that the gains Kj are speciﬁed. Let d∗
j = (d+
j −
d−
j + 1), η∗
j = (η+
j −η−
j + 1) represent the respective number of samples.
The following theorem establishes the asymptotic stability conditions of the
feedback design for subsystem Sj.
Theorem 7.3.1 Given the bounds d+
j > 0, d−
j > 0, η+
j > 0, η−
j > 0, j =
1, ..., N. The global system S with subsystem Sj given by (7.89)-(7.90) is delay-
dependent asymptotically stable with an ℓ2−gain < γj if there exist weighting
matrices 0 < Pj, 0 < Qj, 0 < Zjm, ∀j = 1, ..., ns, m = 1, ..., ns and
scalars γj > 0 satisfying the following LMIs:
&Ξj =
⎡
⎣
Ξaj
Ξcj
&Ξzj
•
−&Ξoj
&Ξwj
•
•
−Ij
⎤
⎦< 0
(7.100)
where
&Ξaj
=
⎡
⎢⎢⎣
Ξ1j
0
0
0
•
−Qj
0
0
•
•
−Ij
0
•
•
•
−Ij
⎤
⎥⎥⎦,
Ξcj
=
⎡
⎢⎢⎣
0
0
&At
jPj
Kt
jΓt
j
F t
j
0
0
0
Dt
jPj
0
0
Et
dj
0
0
Bt
jPj
0
0
0
0
0
Pj
0
0
0
⎤
⎥⎥⎦
(7.101)
with
&Ξoj
=
 &Ξo1j
0
•
Ξo2j

,
&Ξo1j
=
⎡
⎣
−γ2Ij
0
Ωt
jPj
•
−ns
k=1,k̸=j Zjk
0
•
•
−Pj
⎤
⎦,
Ξo2j
=
⎡
⎣
−Ij
0
0
•
−BjI
0
•
•
−ψjI
⎤
⎦
(7.102)

7.3. Interconnected Discrete Delay Systems
325
and
&Ξzj
=
⎡
⎢⎢⎣
&Gt
j
Ht
j
Lt
j
0
⎤
⎥⎥⎦, &Ξwj =
⎡
⎢⎢⎢⎢⎢⎢⎣
Bt
j
0
0
0
0
0
⎤
⎥⎥⎥⎥⎥⎥⎦
,
Ξ1j
=
−Pj + d∗
jQj +
ns

k=1,k̸=j
Zjk
(7.103)
Proof: Introduce the LKF:
V (k) =
ns

j=1
Vj(k), Vj(k) = xt
j(k)Pjxj(k)
+
k−1

m=k−dj(k)
xt
j(m)Qjxj(m)
+
1−d−
j

s=2−d+
j
k−1

m=k+s−1
xt
j(m)Qjxj(m)
+
ns

k=1,k̸=j
k−1

m=k−ηjk(k)
xt
k(m)Zjkxk(m)
+
ns

k=1,k̸=j
1−η−
jk

s=2−η+
jk
k−1

m=k+s−1
xt
k(m)Zjkxk(m)
(7.104)
where 0 < Pj, 0 < Qj, 0 < Zjk are weighting matrices of appropri-
ate dimensions. A straightforward computation gives the ﬁrst difference of
ΔV (k) = V (k + 1) −V (k) along the solutions of (7.96) as:
ΔV (k) =
ns

j=1
ΔVj(k)
ΔVj(k) = [ &Ajxj(k) + Djxj(k −dj(k)) + Bjβj(uj)
+cj(k) + Ωjwj(k)]tPj[ &Ajxj(k) + Djxj(k −dj(k))

326
Chapter 7. Decentralized Reliable Control
+Bjβj(uj) + cj(k) + Ωjwj(k)]
−xt
j(k)Pjxj(k) + xt
j(k)Qjxj(k)
−xt
j(k −dj(k))Qjxj(k −dj(k))
+
ns

k=1,k̸=j
xt
k(k)Zjkxk(k)
−
ns

k=1,k̸=j
xt
k(k −ηj(k))Zjkxk(k −ηj(k))
+
k−1

m=k+1−dj(k+1)
xt
j(m)Qjxj(m)
−
k−1

m=k+1−dj(k)
xt
j(m)Qjxj(m)
+(d+
j −d−
j )xt
j(k)Qjxj(k)
−
k−d∗
j

m=k+1−d+
j
xt
j(m)Qjxj(m)
+
ns

k=1,k̸=j
k−1

m=k+1−ηk(k+1)
xt
k(m)Zjkxk(m)
−
ns

k=1,k̸=j
k−1

m=k+1−ηk(k)
xt
k(m)Zjkxk(m)
+
ns

k=1,k̸=j
(η+
j −η−
k )xt
k(m)Zjkxk(m)
−
ns

k=1,k̸=j
k−η−
k

m=k+1−η+
k
xt
k(m)Zjkxk(m)
(7.105)

7.3. Interconnected Discrete Delay Systems
327
Since
k−1

m=k+1−dj(k+1)
xt
j(m)Qjxj(m) =
k−1

m=k+1−d−
j
xt
j(m)Qjxj(m)
+
k−d−
j

m=k+1−dj(k+1)
xt
j(m)Qjxj(m)
≤
k−1

m=k+1−dj(k)
xt
j(m)Qjxj(m) +
k−d−
j

m=k+1−d+
j
xt
j(m)Qjxj(m) (7.106)
In addition, we have
ns

k=1,k̸=j
k−1

m=k+1−ηk(k+1)
xt
k(m)Zjkxk(m)
=
ns

k=1,k̸=j
k−1

m=k+1−η−
k
xt
k(m)Zjkxk(m)
+
ns

k=1,k̸=j
k−η−
k

m=k+1−ηk(k+1)
xt
k(m)Zjkxk(m)
≤
ns

k=1,k̸=j
k−1

m=k+1−ηj(k)
xt
k(m)Zjkxk(m)
+
ns

k=1,k̸=j
k−η−
j

m=k+1−η+
j
xt
k(m)Zjkxk(m)
(7.107)

328
Chapter 7. Decentralized Reliable Control
Then using (7.106) and (7.107) into (7.105) and manipulating, we reach
ΔVj(k) ≤[ &Ajxj(k) + Djxj(k −dj(k)) + Bjβj(uj)
+cj(k) + Ωjwj(k)]tPj[ &Ajxj(k) + Djxj(k −dj(k))
+Bjβj(uj) + cj(k) + Ωjwj(k)]
+xt
j(k)[d∗
jQj −Pj]xj(k)
−xt
j(k −dj(k))Qjxj(k −dj(k))
+
ns

k=1,k̸=j
η∗
kxt
k(k)Zjkxk(k)
−
ns

k=1,k̸=j
xt
k(k −ηj(k))Zjkxk(k −ηj(k))
(7.108)
For the class of interconnected systems (7.1), the following structural identity
holds:
ns

j=1
ns

k=1,k̸=j
xt
k(m)Zjkxk(m) =
ns

j=1
ns

k=1,k̸=j
xt
j(m)Zkjxj(m)
In terms of the vectors
ξ1j(k) = [xt
j(k), xt
j(k −dj(k)), βj(k), ct
j(k)]t
ξ2j(k) = [ωt
j(k),
ns

m=1,m̸=j
xt
m(k −ηm(k))]t
ξj(k) = [ξt
1j(k), ξt
2j(k)]t
we combine (7.99)-(7.108) with algebraic manipulations using the constraint
inequalities (7.91) and (7.95) and Schur complements [29] to arrive at
ΔV (k) =
ns

j=1
ΔVj(k) =
ns

j=1
ξt
j(k) Ξj ξj(k)
(7.109)
where Ξj corresponds to &Ξj in (7.100) with ωj(k) ≡0, Gj ≡0, Hj ≡
0, Lj ≡0, B ≡0, γj ≡0. It is known that the sufﬁcient condition of
subsystem internal stability is ΔV (k) < 0 when ωj(k) ≡0, Gj ≡0, Hj ≡
0, Lj ≡0, B ≡0, γj ≡0. This implies that Ξj < 0 under the same
requirements.

7.3. Interconnected Discrete Delay Systems
329
Next, consider the performance measure
J =
ns

j=1
∞

j=0

zt
j(k)zj(k) −γ2ωt
j(k)ωj(k)

For any ωj(k) ∈ℓ2(0, ∞) ̸= 0 and zero initial condition xjo = 0 (hence
Vj(0) = 0), we have
J
=
ns

j=1
∞

j=0

zt
j(k)zj(k) −γ2ωt
j(k)ωj(k) + ΔVj(k)|(7.89)

−
ns

j=1
∞

j=0
ΔVj(k)|(7.89)
=
ns

j=1
∞

j=0

zt
j(k)zj(k) −γ2ωt
j(k)ωj(k) + ΔVj(k)|(7.89)

−
Vj(∞)
≤
ns

j=1
∞

j=0

zt
j(k)zj(k) −γ2ωt
j(k)ωj(k)
+
ΔVj(k)|(7.89)

(7.110)
where ΔVj(k)|(7.89) deﬁnes the Lyapunov difference along the solutions of
system (7.89) with uj(k) ≡0. On considering (7.90), (7.100), (7.103), and
(7.110), it can easily be shown by algebraic manipulations that
zt
j(k)zj(k) −γ2ωt
j(k)ωj(k) + ΔVj(k)|(7.89) =
χt
j(k) &Ξj χt
j(k)
(7.111)
where &Ξj is given in (7.100) by Schur complements [29]. It is readily seen that
zt
j(k)zj(k) −γ2ωt
j(k)ωj(k) + ΔVj(k)|(7.89) < 0
for arbitrary j ∈[0, ∞), which implies for any ωj(k) ∈ℓ2(0, ∞) ̸= 0 that
J < 0. This eventually leads to ||zj(k)||2 < γ ||ωj(k)||2 and hence the proof
is completed. The next theorem provides expression for reliable decentralized
feedback gains.
Theorem 7.3.2 Given the bounds d+
j
> 0,
d−
j
> 0,
η+
j
> 0,
η−
j
>
0, j = 1, ..., ns. The closed-loop subsystem Sj (7.96)-(7.98) is delay-dependent
asymptotically stable with an ℓ2 −gain < γj if there exist weighting matrices

330
Chapter 7. Decentralized Reliable Control
0 < Xj, Yj, 0 < Ψj, 0 < Λjm, j = 1, ..., ns, m = 1, ..., ns and scalars
Bj > 0, ψj > 0, γj > 0 satisfying the following LMIs:
&Πj =
⎡
⎣
Πaj
Πcj
&Πzj
•
−&Πoj
&Πwj
•
•
−Ij
⎤
⎦< 0
(7.112)
where
&Πaj
=
⎡
⎢⎢⎣
Π1j
0
0
0
•
−Qj
0
0
•
•
−Ij
0
•
•
•
−Ij
⎤
⎥⎥⎦,
Πcj
=
⎡
⎢⎢⎣
0
0
Π2j
Yt
jΓt
j
XjF t
j
0
0
0
XDt
j
0
0
XjEt
dj
0
0
Bt
j
0
0
0
0
0
Ij
0
0
0
⎤
⎥⎥⎦,
&Πoj
=
 &Πo1j
0
•
Πo2j

,
&Πo1j
=
⎡
⎣
−γ2Ij
0
Ωt
j
•
−ns
m=1,m̸=j Λjm
0
•
•
−Xj
⎤
⎦,
Πo2j
=
⎡
⎣
−Ij
0
0
•
−BjI
0
•
•
−ψjI
⎤
⎦,
&Πzj
=
⎡
⎢⎢⎣
Π3j
XjHt
j
Lt
j
0
⎤
⎥⎥⎦, &Ξwj =
⎡
⎢⎢⎢⎢⎢⎢⎣
Bt
j
0
0
0
0
0
⎤
⎥⎥⎥⎥⎥⎥⎦
(7.113)
Π1j
=
−Xj + d∗
jΨj +
ns

m=1,m̸=j
Λjm
Π2j
=
XjAt
j + Yt
jΣt
jBt
j,
Π3j
=
XjGt
j + Yt
jΣt
jLt
j
(7.114)
Moreover, the local gain matrix is given by Kj = YjX −1
j
.

7.3. Interconnected Discrete Delay Systems
331
Proof: Applying the congruent transformation
T = diag[Xj, Xj, Ij, Ij, Ij, Xj, Ij, Ij, Ij, Ij, Ij]
with Xj = P−1
j
to LMI (7.100) with Schur complements and using the lin-
earizations
Yj
=
KjXj, Ψj = XjQjXj, Λmj = XjZmjXj
we readily obtain LMI (7.112) by Schur complements and therefore the proof
is completed.
Remark 7.3.3 The optimal performance-level γj, j = 1, .., ns for the inter-
connected system can be determined for decentralized reliable state feedback
by solving the following convex optimization problem:
Problem A
For j, m = 1, ..., ns,
Given d+
j > 0, d−
j > 0, η+
j > 0, η−
j > 0
min
Xj, Yj, Ψj, {Λjm}ns
m=1
γj
subject to LMI(7.112)
(7.115)
7.3.4
Illustrative example 7.3
To illustrate the usefulness of the results of the developed approach, let us con-
sider the following interconnected time-delay system which is composed of
three subsystems. With reference to (7.96)-(7.98), the data values are:
Subsystem 1 :
A1 =
 0.0
0.1
0.5
−0.5

, D1 =
 0.1
0.0
0.01
0.1

,
B1 =

0
0.05

, Ω1 = diag

0.4
0.6

,
F1 =

0
0.1
0.01
0.02

, Ed1 =
 0.03
0.1
0
0.04


332
Chapter 7. Decentralized Reliable Control
Subsystem 2 :
Ac =
⎡
⎣
0
0
0.1
0.1
−0.6
0.1
0.3
0.7
0.9
⎤
⎦, D2 =
⎡
⎣
0.0
0.2
0.0
0.0
0.1
−0.2
0.1
−0.3
−0.2
⎤
⎦,
B2 =
⎡
⎣
0.03
0
0.04
⎤
⎦, Ed2 =
⎡
⎣
0.05
0
0.01
0
0.01
0
0.01
0.04
0.02
⎤
⎦,
F2 =
⎡
⎣
0
0.1
0
0.01
0
0.02
0.03
0.04
0
⎤
⎦, Ωc = diag

0.3
0.5
0.7

Subsystem 3 :
A3 =

0.0
0.2
−0.6
0.6

, D3 =
 0.0
0.2
0.1
−0.1

,
B3 =
 0.1
0.1

, Ω3 = diag

0.5
0.5

,
F3 =
 0.02
0.01
0.01
0.03

, Ed3 =
 0.04
0.05
0.1
0.04

In order to illustrate the effectiveness of our reliable control algorithm, we ini-
tially consider the nominal control design in which no actuator failures will
occur. Then, by using the data values Σ1 = 1, Σc = 1, Σ3 = 1, Γ1 =
0, Γc = 0, Γ3 = 0 and solving Problem A using MATLAB R⃝-LMI solver,
it is found that the feasible solution of Theorem 7.3.2 yields the following
control gain matrices and performance levels:
γ1 = 1.7874, K1 =

−5.2132
−3.6224

,
γc = 3.1742, K2 =

−3.2444
−2.3354
−2.9664

,
γ3 = 2.0297, K3 =

−2.4243
−1.3235

(7.116)
Next, we study different failure scenarios. The ﬁrst scenario is described by the
following model:
uf
1(k)
=
0.6 u1(k) + β1(u1), β2
1(u1) ≤0.01 u2
1,
uf
2(k)
=
0.8 u2(k) + βc(u2), β2
2(u2) ≤0.09 u2
2,
uf
3(k)
=
0.4 u3(k) + β3(u3), β2
3(u3) ≤0.04 u2
3
(7.117)

7.3. Interconnected Discrete Delay Systems
333
0
1
2
3
4
5
6
7
8
−0.5
−0.4
−0.3
−0.2
−0.1
0
0.1
0.2
Time
Trajectories of first state−Subsystem S1 
Failure Mode−Reliable
Failure Mode−Nominal
Ideal Mode
Figure 7.14: Trajectories of ﬁrst state-Subsystem 1
which corresponds to allowing a failure of the order of 60% in the actuator of
system Sj with an error of the order of 10%. In a similar way, the tolerances
allowed for other actuators are interpreted in the same way. Thus we have Σ1 =
0.6, Γ1 = 0.1, Σc = 0.8, Γc = 0.3, Σ3 = 0.4, Γ3 = 0.2 and upon solving
Problem A again, the resulting feasible solution is summarized by
γ1 = 1.9492, K1 =

2.4945
−4.6355

,
γc = 3.7842, K2 =

−1.3947
−4.5364
−2.5472

,
γ3 = 2.4123, K3 =

−0.1177
2.1270

(7.118)
Using numerical simulation, three typical experiments were performed for
three operational modes.
1) Ideal mode, where the feedback controllers (7.116) were implemented
in an operation without failures.
2) Failure mode, where the feedback controllers (7.116) were implemented
in an operation under the failures described in (7.117).
3) Reliable control failure mode, where the reliable controllers (7.118) were
implemented in an operation under the failures described in (7.117). Simula-
tion results of the ﬁrst state trajectories of the three subsystems are displayed
in Figures 7.14 through 7.16 for the prescribed modes of operation. The trajec-
tories of the state-feedback control input for the ﬁrst subsystem are depicted in
Figure 7.17. It is observed that the nominal control clearly deteriorates its ideal
performance when operating under failures. When using the reliable control,
we notice that the state response results drastically improved in spite of work-

334
Chapter 7. Decentralized Reliable Control
0
1
2
3
4
5
6
7
8
−0.6
−0.5
−0.4
−0.3
−0.2
−0.1
0
0.1
0.2
0.3
0.4
Time
Trajectories of first state−Subsystem S2
Failure Mode−Reliable
Failure Mode−Nominal
Ideal Mode
Figure 7.15: Trajectories of ﬁrst state-Subsystem 2
0
1
2
3
4
5
6
7
8
−0.7
−0.6
−0.5
−0.4
−0.3
−0.2
−0.1
0
0.1
0.2
0.3
Time
Trajectories of first state−Subsystem S3
Failure Mode−Reliable
Failure Mode−Nominal
Ideal Mode
Figure 7.16: Trajectories of ﬁrst state-Subsystem 3

7.4. Reliable Control of Symmetric Composite Systems
335
0
1
2
3
4
5
6
7
8
−1.4
−1.2
−1
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
Time
Trajectories of first control−Subsystem S1
Failure Mode−Reliable
Failure Mode−Nominal
Ideal Mode
Figure 7.17: Trajectories of control input-Subsystem 1
ing under the same failures, being very close to the one obtained in the ideal
case. As Figure 7.17 shows, the control effort in this case has a bigger initial
magnitude than for the nominal cases, quickly approaching the ideal control
signals. These results illustrate the satisfactory behavior of the proposed reli-
able control scheme.
7.4
Reliable Control of Symmetric Composite Systems
Symmetric composite systems are those composed of identical subsystems that
are symmetrically interconnected. The motivation for studying this class of
systems is due to its very diverse application areas, such as in electric power
systems, industrial manipulators, and computer networks [107, 191, 356]. In
recent years there has been a great interest in studying symmetric composite
systems. It is shown that many analysis and synthesis problems for symmetric
composite systems can be simpliﬁed because of their special structure. In [191]
the state-space model of symmetric composite systems is proposed and some
fundamental properties of the systems are investigated. For centralized control
systems, the output regulation for symmetric composite systems is treated in
[180]. The model reduction problem was considered in [160]. Methods of H2
and H∞optimal control were studied in [107]. In [383], the reliable control of
such systems was analyzed. For the decentralized control of symmetric com-
posite systems [191], it is proved that the system has no decentralized ﬁxed
modes if and only if it is completely controllable and observable. A sufﬁcient

336
Chapter 7. Decentralized Reliable Control
condition is presented in [356] for such systems to be decentralized stabiliz-
able using identical subsystem controllers. The decentralized control using two
kinds of subsystem controllers is studied in [366]. The decentralized control
for uncertain symmetric composite systems is studied in [14, 366]. Further-
more, a reduced-order decentralized control design of time-delayed uncertain
symmetric composite systems was considered in [18].
In the last decade, a great deal of attention has been devoted to the H∞
control of dynamic systems. As the H∞-norm is a particularly useful perfor-
mance measure in solving such diverse control problems as disturbance rejec-
tion, model reference design, tracking, and robust design, many corresponding
important design procedures have been established. An introduction of some
standard results is found in [62].
Sometimes, control systems may result in unsatisfactory performance or
even instability in the event of control component failures. Recently, in [366],
the design of reliable control systems was considered. The resulting control
systems provide guaranteed stability and satisfy an H∞-norm disturbance at-
tenuation bound not only when all control components are operational, but also
in the case of control-channel outages in the systems. The outages were re-
stricted to occur within a preselected subset of available measurements or con-
trol inputs. In [385], the reliable control is studied using redundant controller
using a simple design approach.
In [117], the state feedback fault-tolerant decentralized H∞control prob-
lem for symmetric composite systems is studied. By using the special structure
of the systems, a state feedback decentralized H∞control law is constructed
by design state feedback H∞controllers for two modiﬁed subsystems. Since
the full state of the control systems are generally not available in practice, to
study the more general output feedback problem is of great importance.
This section is concerned with the dynamic output feedback decentralized
H∞control and reliability analysis of symmetric composite systems. First, it
is shown that the dynamic output feedback decentralized H∞control prob-
lem is equivalent to a simultaneous H∞control problem of two modiﬁed sub-
systems. A design procedure based on the simultaneous H∞control method
given in [34] is presented. The reliability considered in this paper concerns the
largest number of control inputs or measurements failures that will keep the
closed-loop system stable and maintain the required level of performance. By
exploiting the special structure of the systems, it is shown that the computa-
tion of the poles and the H∞-norm of the resulting closed-loop system when
control-channel outages occur can be reduced to the computation of the poles
and the H∞-norm of three auxiliary systems. The order of one auxiliary system
is twice that of any isolated subsystem, while the orders of the other two auxil-

7.4. Reliable Control of Symmetric Composite Systems
337
iary systems are equal to that of any isolated subsystem. Thus the tolerance to
control input failures and measurement failures can be tested more efﬁciently.
7.4.1
Problem formulation
The symmetric composite system under consideration consists of N subsys-
tems; the jth subsystem is described by
˙xj
=
Aoxj +
N

k=1,k̸=j
Acxk + Γwj +
N

k=1,k̸=j
Φwk + Buj
zj
=
Cxj + Duj
yj
=
Gxj + Fwj
(7.119)
where j = 1, 2, . . . , N and xj ∈ℜn, uj ∈ℜm, wj ∈ℜr, zj ∈ℜs, yj ∈ℜp
are the state, control input, exogenous input, penalty and measured variables,
respectively, and Ao ∈ℜn×n, Ac ∈ℜn×n, Γ ∈ℜn×r, Φ ∈ℜn×r, B ∈
ℜn×m, C ∈ℜs×n, D ∈ℜs×m, G ∈ℜp×n, F ∈ℜp×r.
Then the overall system is given by
˙x
=
Asx + Γsw + Bsu
z
=
Csx + Dsu
y
=
Gsx + Fsw
(7.120)
where
x
=

xt
1, . . . , xt
N

, u =

ut
1, . . . , ut
N

, w =

ut
1, . . . , wt
N

,
z
=

zt
1, . . . , zt
N

, y =

yt
1, . . . , yt
N

and
As
∈ℜNn×Nn, Γs ∈ℜNn×Nr, Bs ∈ℜNn×Nm, Cs ∈ℜNs×Nn,
Ds
∈ℜNs×Nm, Gs ∈ℜNp×Nn, Fs ∈ℜNp×Nr
have the following structure:
As
=
⎡
⎢⎢⎢⎣
Ao
Ac
· · ·
Ac
Ac
Ao
· · ·
Ac
...
...
...
...
Ac
Ac
· · ·
Ao
⎤
⎥⎥⎥⎦,
Γs =
⎡
⎢⎢⎢⎢⎣
Γ
Φ
· · ·
Φ
Φ
Γ
· · ·
Φ
...
...
...
...
Φ
Φ
...
Γ
⎤
⎥⎥⎥⎥⎦
,
Bs
=
Blockdiag[B, · · · , B],
Cs = Blockdiag[C, · · · , C],
Ds
=
Blockdiag[D, · · · , D],
Gs = Blockdiag[G, · · · , G],
Fs
=
Blockdiag[F, · · · , F]

338
Chapter 7. Decentralized Reliable Control
Remark 7.4.1 It is quite evident from the structure of matrices As, ..., Fs
that the individual subsystems have similar dynamics and the coupling pattern
is similar too among different subsystems. This is the basis for the designation
of symmetric composite systems.
In what follows, we examine the decentralized H∞control problem that is
considered based on dynamic output feedback and formally described by:
Given γ > 0, ﬁnd a decentralized dynamic output feedback controller
 ζj = Fcζj + Gcyj
uj = Hcζj
(7.121)
where ζj ∈ℜv, j = 1, · · · , N, such that
(C1): The matrix
 As
BsH
GC2
F

,
is stable, where
H
=
Block diag[Hc, · · · , Hc], G = Block diag[Gc, · · · , Gc],
F
=
Block diag[Fc, · · · , Fc]
(C2): The transfer function matrix T c(s) of the closed-loop system,
⎧
⎨
⎩
˙xj = Asx + BsHζ + Bsw
˙ζ = HFζ + GGsx + GFsw
z = Csx + DsHζ
where ζ = [ζt
1, · · · , ζt
N]t, satisﬁes ∥T c(s) ∥< γ.
Remark 7.4.2 It should be emphasized that the feedback controllers (7.121)
are identical for all subsystems, thereby exploiting the structural properties of
system (7.120) to reduce the complexity of the controller design.
We now examine the reliability of the closed-loop system composed of system
(7.120) and decentralized controller of the form (7.121). To achieve our goal,
we will study the tolerance to control-channel outages, which include control
input failures and measurement failures. In this course, we consider the jth
control input failure takes the form uj = 0 and the jth measurement failure is
modeled as yk = 0, j, k ∈{1, · · · , N}.
Following [117], for a positive integer p, we denote
mk = [1 vk v2
k · · · vp−1
k
]t
k = 1, 2, · · · , p

7.4. Reliable Control of Symmetric Composite Systems
339
where vk = exp

2Π(k −1)
√
1/p

, k = 1, 2, · · · , p. This implies that vk is a
root of the equation vp = 1. For simplicity in exposition, we denote
r1 = m1 = [1 1 · · · 1]t, r p
2 + 1 = m p
2 + 1
if p is an even number. Let t = p+1
2
if p is odd and t = p
2 if p is even. Then for
j = 2, 3, · · · , t, we deﬁne
rj =
1
√
2(mj + mp+2−j), rp+2−j =
√−1
√
2 (mj −mp+2−j)
Finally, introduce
Rp =
1
√p[r1 r2 · · · rp]
(7.122)
Tpj = Rp ⊗Ij
(7.123)
where ⊗denotes the Kronecker product.
7.4.2
Decentralized H∞control
To simplify the notations, we denote
Aα
=
Ao + (N −1)Ac,
Aβ = Ao −Ac,
(7.124)
Γα
=
Γ + (N −1)Φ,
Γβ = Γ −Φ
(7.125)
then from (7.123) and the results of [117], there exist appropriate transforma-
tions
TNn, TNm, TNp, TNr, TNs
leading to
T −1
NnAsTNn
=
diag[Aα, Aβ, · · · , Aβ],
T −1
NnΓsTNr
=
diag[Γα, Γβ, · · · , Γβ],
T −1
NnBsTNm
=
Blockdiag[B, · · · , B],
T −1
NsCsTNn
=
Blockdiag[C, · · · , C],
T −1
NpGsTNn
=
diag[G, · · · , G],
T −1
NsDsTNm
=
Blockdiag[D, · · · , D],
T −1
NpFsT Nr
=
diag[F, · · · , F]
(7.126)

340
Chapter 7. Decentralized Reliable Control
and further we denote
Ac
=
 As
BsH
GcGs
H

,
Ac
α =
 Aα
BHc
GcG
Fc

,
(7.127)
Ac
β
=
 Aβ
BH1c
GcG
Fc

,
W
=
sI −Ac, Wα = sI −Ac
α, , Wβ = sI −Ac
(7.128)
Then the following lemma holds [117].
Lemma 7.4.3 There exists a permutation matrix P such that
P−1
T −1
Nn
0
0
T −1
Nv

W −1
TNn
0
0
TNv

P = diag

W −1
α ,
W −1
β , · · · , W −1
β
	
Proof 7.4.4 Let P be the permutation matrix such that
P−1
diag[Aα, Aβ, · · · , Aβ]
diag[BHc, · · · , BHc]
diag[GcG, · · · , GcG]
diag[Fc, · · · , Fc]

P
= diag
 Aα
BHc
GcG
Fc

,
 Aβ
BHc
GcG
Fc

, · · · ,
 Aβ
BHc
GcG
Fc

Then from (7.126), we have
P−1
T −1
Nn
0
0
T −1
Nv

W −1
TNn
0
0
TNv

P
=

P−1
T −1
Nn
0
0
T −1
Nv

W
 TNn
0
0TNv

P
−1
= P−1diag[sI −Aα, sI −Aβ, · · · , sI −Aβ]
diag[−G1G, · · · , −G1G]
diag[−BHc, · · · , −BHc]
diag[sI −Fc, · · · , sI −Fc]P
diag
sI −Aα
−BHc
−GcG
sI −Fc

,
sI −Aβ
−BHc
−GcG
sI −Fc

,
, · · · ,
sI −Aβ
−BHc
−GcG
sI −Fc

diag

W −1
α , W −1
β , · · · , W −1
β
	
Some manipulations yield the desired results and thus the proof is completed.

7.4. Reliable Control of Symmetric Composite Systems
341
Exploiting the special structure of system (7.120), the the decentralized H∞
control (DHC) problem under consideration will be shown to be simpliﬁed to
a simultaneous H∞control problem for two modiﬁed subsystems. The main
result is established by the following theorem.
Theorem 7.4.5 A decentralized dynamic output feedback controller of the
form (7.121) satisﬁes conditions (C1) and (C2) if and only if it satisﬁes the
following two conditions:
(C3): Ac
α and Ac
β are stable.
(C4): ∥T c
α(s)∥∞≤γ and ∥T c
β(s)∥∞≤γ
where
T c
α(s)
=
[C
DHc]W −1
α
 Γα
GcF

and
T c
β(s)
=
[C
DHc]W −1
β
 Γβ
GcF

(7.129)
Proof 7.4.6 (C1) ⇔(C3): From (7.126), we have
spec
 As
BsH
GGs
F

=
spec
T −1
Nn
0
0
T −1
Nv
  As
BsH
GGs
F
 TNn
0
0
TNv

=
spec

T −1
NnAsTNn
T −1
NnBsTNmT −1
NmHTNv
T −1
NvGTNpT −1
NpGsTNn
T −1
NvFTNv

=
spec
diag[Aα, Abeta, · · · , Aβ]
diag[BHc, · · · , BHc]
diag[GcG, · · · , GcG]
diag[Fc, · · · , Fc]

=
spec

Block diag
 Aα
BH1
GcG
Fc

,
 Aβ
BHc
GcG
F1

, · · · ,
 Aβ
BHc
GcG
Fc

Hence (C1) holds if and only if (C3) holds.
(C2)⇐⇒(C4): From (7.123), it is easy to see that Tpj is an orthogonal
matrix for integers p ≥2 and j ≥1. Since T c(s) = [Cs
DsH]W −1
 Γs
GFs

,
premultiplication or postmultiplication of T c(s) by orthogonal matrices will

342
Chapter 7. Decentralized Reliable Control
leave the H∞-norm intact. Hence we have
∥T c(s)∥∞
=
∥T −1
NsT c(s)TNr∥∞
=
∥T −1
Ns[Cs
DsH]
TNn
0
0
TNv

PP−1
T −1
Nn
0
0
T −1
Nv

W −1
×
TNn
0
0
TNv

PP−1
T −1
Nn
0
0
T −1
Nv
  Γs
GFs

TNr∥∞
Then from Lemma 7.4.3 we have
∥T c(s)∥∞
=
∥[Block diag[C, · · · , C]
Block diag[DHc, · · · , DHc]]P
×Blockdiag[W −1
α , W −1
β , · · · , W −1
β ]P−1
×
Blockdiag[Γα, Γβ, · · · , Γβ]
Blockdiag[GcF, · · · , GcF]

∥∞
=
∥{Blockdiag[C
DH1], · · · , [C
DH1]}
×[W −1
α , W −1
β , · · · , W −1
β ]
×Blockdiag
 Γα
GcF

,
 Γβ
GcF

, · · · ,
 Γβ
GcF

∥∞
=
∥Blockdiag[T c
α(s), T c
β(s), · · · , T c
β(s)]∥∞
=
max
/
∥T c
α(s)∥∞, ∥T c
β(s)∥∞
0
Thus (C2) holds if and only if (C4) holds.
Remark 7.4.7 It should be noted that Theorem 7.4.5 establishes that the DHC
problem under consideration is equivalent to the simultaneous H∞control
problem of two modiﬁed subsystems
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎩
˙xα = Aαxj + Γsαwj + Buj
zα = Cxα + Du
y = Gxα + Fwα
˙xβ = Aβxj + Γsβwj + Buj
zβ = Cxα + Du
y = Gxβ + Fwβ
(7.130)
using the same controller
 ˙η = Fcη + Gcy
u = Hcη
(7.131)

7.4. Reliable Control of Symmetric Composite Systems
343
7.4.3
Controller design
Initially, we make some the standard assumptions:
1. (Aα, Γα), (Aα, B), (Aβ, Γβ), (Aβ, B) are all stabilizable,
2. (C, Aα), (G, Aα), (C, Aβ), (G, Aβ) are all detectable,
3. Dt[C
D] = [0
I],
4.
Γα
F

F t =
0
I

,
Γβ
F

F t =
0
I

.
It should be pointed out that the assumptions are equivalent to those usually
applied to (7.120) in a standard H∞synthesis problem and that lead to the
following well-known result [62].
Lemma 7.4.8 For γ > 0 and i = α, β, there exists an admissible controller
such that ∥T c
j (s)∥∞< γ if and only if the following three conditions hold:
(S1) there exists a Xi∞≥0, such that
At
jXj∞+ Xj∞Aj + Xj∞(γ−2ΓsjΓt
sj −BBt)Xi∞+ CtC = 0
(7.132)
(S2) there exists a Yj∞≥0, such that
AjYj∞+ Yj∞At
j + Yj∞(γ−2CtC −GtG)Yj∞+ ΓsjΓt
sj = 0
(7.133)
(S3) ρ(Yj∞Xj∞) < γ2.
Deﬁning
Fj∞
=
BtXj∞
Lj∞
=
(I −γ−2Yj∞Xj∞)−1Yj∞Gt
ˆAj∞
=
Aj + γ−2Γj∞Γt
j∞Xj∞−BFj∞−Lj∞G
(7.134)
Zj∞
=
(I −γ−2Yj∞Xj∞)
then all admissible controllers Kj∞(Qj(s)) resulting in ∥T c
j (s)∥∞< γ are
parameterized as in Figure 7.18, where
Mj∞(s) ↔
⎡
⎣
ˆAj∞
Lj∞
Zi∞B
−Fi∞
0
I
−G
I
0
⎤
⎦
and Qj(s) is a stable real-rational transfer function satisfying ∥Qj(s)∥∞< γ.

344
Chapter 7. Decentralized Reliable Control
Figure 7.18: Modiﬁed system
From Theorem 7.4.5 and Lemma 7.4.8, the necessary conditions for the DHC
problem to have a solution are that conditions (S1)-(S3) hold for j = α, β. And
if these conditions hold, the problem is to ﬁnd Qα(s) and Qβ(s) such that
∥Qα(s)∥∞< γ
and
Kα∞(Qα(s)) = Kβ∞(Qβ(s))
Such a problem was considered in [34] and based on the ensuing results, we
have the following theorem.
Theorem 7.4.9 For γ ≥0, if there exist two matrices Nα ≥0, Nβ ≥0, such
that
Nα ˜At
α + ˜AαNα + Nα ˜EαNα + ˜Rα ˜ℜt
α = 0,
Nβ ˜At
β + ˜AβNβ + Nβ ˜EβNβ + ˜Rβ ˜ℜt
β = 0
(7.135)
where
˜Aα
=
 ˆAα∞+ Zα∞BFα∞
Zα∞BFβ∞−Lα∞G
0
ˆAβ∞+ Lβ∞G

˜Aβ
=

ˆAα∞+ Lα∞G
0
Zβ∞BFα∞−Lβ∞G
ˆAβ∞+ Zβ∞BFβ∞


7.4. Reliable Control of Symmetric Composite Systems
345
˜Eα
=
˜Eβ =
)
γ−2F t
α∞Fα∞−GtG
γ−2F t
α∞Fβ∞−Ct
21G
γ−2F t
β∞Fα∞−GtG
γ−2F t
β∞Fβ∞−GtG
*
˜Rα
=
 1
2Lα∞
1
2Lβ∞

+ Nβ
Gt
Gt

(7.136)
˜Rβ
=
 1
2Lα∞
−1
2Lβ∞

+ Nα
Gt
Gt

(7.137)
then the controller
 ˙ζj = ( ˆA−ˆL ¯C)ζj + ˆLyj
uj = ˆFζj
(7.138)
is a solution of the DHC problem under consideration, where j = 1, · · · , N,
ˆA
=
 ˆAα∞+ Lα∞G
0
0
Aβ∞+ Lβ∞G

,
ˆL
=
 1
2Lα∞
−1
2Lβ∞

+ (Nα + Nβ)
Gt
Gt

,
ˆF
=
[−Fα∞
−Fβ∞],
¯C
=
[G
G]
Proof 7.4.10 It follows from [34], if (7.135) holds, then the controller
 ˙η=( ˆA −ˆL ¯C)η + ˆLy
u = ˆFη
is a simultaneous H∞suboptimal controller guaranteeing ∥T c
α(s)∥∞< γ and
∥T c
β(s)∥∞< γ. The desired results then follow from Theorem 7.4.5.
Remark 7.4.11 It was demonstrated in [34] that the parameter-embedding
method may be used to solve the two equations in (7.135). Alternatively, we
may use an iterative method as follows:
First let N (0)
α
= N (0)
β
= 0 in (7.136) and (7.137), then the two equations in
(7.135) can be solved. Use the obtained solutions N (1)
α
and N (1)
β
to calculate
˜Rα and ˜Rβ and solve for N (2)
α
and N (2)
β . The process is continued until N (k)
α
and N (k)
β
converge.

346
Chapter 7. Decentralized Reliable Control
7.4.4
Illustrative example 7.4
Consider the voltage/reactive power behavior of a multimachine power system
consisting of several synchronous machines including their PI-voltage con-
trollers, which feed the load through a distribution net [191] with a system
model given by
˙xj
=
−2.51
−0.16
2.55
0

xj +
N

k=1,k̸=i
 −0.065
0
−0.0027
0

xk +
0.9
−1

uj
+
0
0.02
0
0.01

wj +
N

k=1,k̸=j
0
0.01
0
0.01

wk
(7.139)
zj
=
2
0.2
0
0

xj +
0
1

uj
yj
=
[2.54
0]xj + [1
0]wj
(j = 1, · · · , 20)
(7.140)
Assume that γ = 0.62, it is easy to test that assumptions (i)-(iv) hold and
hence Theorem 7.4.9 can be applied to design the controller. Using the iterative
method suggested in Remark 7.4.11 to solve the two equations in (7.135), we
obtain the decentralized H∞controller
ζj
=
⎡
⎢⎢⎣
−2.4451
−0.1597
−0.0003
0
2.5527
−0.0002
0.0002
0
−0.0247
0
−3.6915
−0.0484
0.1767
0
2.6478
−0.0400
⎤
⎥⎥⎦ζj +
⎡
⎢⎢⎣
0.0001
−0.0001
0.0097
0.0696
⎤
⎥⎥⎦yj
uj
=
[0.0002
0.0002
0.0549
0.0788]ζj
(7.141)
where j = 1, . . . , 20. The resulting closed-loop system is stable and satisﬁes
the performance requirement. In fact, we have
|T c
α(s)∥∞= 0.6143 < γ,
|T c
β(s)∥∞= 0.0613 < γ
7.4.5
Illustrative example 7.5
Consider an open-loop unstable symmetric composite system composed of
N = 20 subsystems given by
˙xj
=
−2
−6
5
0

xj +
N

k=1,k̸=i
−0.500
0.1
−0.002
0.1

xk +
 2
−1

uj
+
0
0.02
0
0.01

wj +
N

k=1,k̸=i
0
0.01
0
0.01

wk
(7.142)

7.4. Reliable Control of Symmetric Composite Systems
347
zj
=
2
0.2
0
0

xj +
0
1

uj
yj
=
[2
3]xj + [1
0]wj
(i = 1, . . . , 20)
Letting γ = 10, it is easy to test that assumptions (1)-(4) hold and hence
Theorem 7.4.9 can be applied to design the controller. Once again, using the
iterative method suggested in Remark 7.4.11 to solve the two equations in
(7.135), we obtain the decentralized H∞controller
⎧
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎩
˙ζj =
⎡
⎢⎢⎣
−10.2465
0.3761
0.1692
0.2538
3.8375
−1.0802
−0.5880
−0.8821
0.0086
0.0130
−4.1214
−4.8844
0.0077
0.0115
6.3247
−0.6898
⎤
⎥⎥⎦ζj +
⎡
⎢⎢⎣
−0.0846
0.2940
−0.0043
−0.0038
⎤
⎥⎥⎦yj
uj = [0.5402
2.1067
−1.3150
0.6013]ζj
where j = 1, · · · , 20. To test the effectiveness of the controller, we compute
spec(Ac
α), spec (Ac
β), ∥T c
α(s)∥∞, ∥T c
β(s)∥∞and obtain
spec(Ac
α),
{−9.7727, −10.4685, −0.1682, −0.5199, −2.4043 ± 5.2885i} ⊂C−,
spec(Ac
β),
{−10.3945, −0.2453, −1.1333 ± 5.4437i, −2.4157 ± 5.2913i} ⊂C−,
∥T c
α(s)∥∞= 4.9213 < γ,
∥T c
β(s)∥∞= 2.4335 < γ
7.4.6
Reliability analysis
In this section, we consider the reliability of the closed-loop system composed
of system (7.120) and decentralized controller of the form (7.121). Here the
reliability means the ability to tolerate control channel failures such as control-
input channel failure or sensor measurement channel failures. For integer 1 ≤
ℓ≤N −1, we denote
Uℓ
=
Ao + (ℓ−1)Ac,
˜Uℓ=

ℓ(N −l)Ac
Vℓ
=
Γ + (ℓ−1)Φ,
˜Vℓ=

ℓ(N −l)Φ
7.4.7
Control input failures
Since the subsystems (7.119) are all identical, without loss of generality, we
may assume that the ﬁrst l control inputs fail. Then the system matrix of the
resulting closed-loop system is
Ac
ℓ=
 A
(BsH)ℓ
GGs
F


348
Chapter 7. Decentralized Reliable Control
where
(BsH)ℓ= diag

ℓ
= >? @
0, . . . , 0,
N−ℓ
=
>?
@
BHc, . . . , BHc

The transfer function matrix of the resulting closed-loop system is
T c
ℓ(s) = [Cs
(DsH)ℓ](sI −Ac
ℓ)−1
 Γs
GFs

where
(DsH)ℓ= diag

ℓ
= >? @
0, . . . , 0,
N−ℓ
=
>?
@
DHc, . . . , DHc

Using a similar method as in the proof of Theorem 8.4.12 in [117], the follow-
ing theorem can be established.
Theorem 7.4.12 When ℓcontrol inputs fail, the poles of the resulting closed-
loop system are
spec(Ac
ℓ) =
⎧
⎨
⎩
spec( ¯Ac
l ) ∪spec(Ac
β)
(ℓ= 1)
spec( ¯Ac
ℓ) ∪spec( ¯Ac
β) ∪spec( ¯Ac
β)
(2 ≤ℓ≤N −2)
spec( ¯Ac
ℓ) ∪spec( ¯Ac
β)
(ℓ= N −1)
where
spec( ¯Ac
ℓ) =
⎡
⎢⎢⎣
Uℓ
˜Uℓ
0
0
˜Uℓ
UN−ℓ
0
BHc
GcG
0
Fc
0
0
GcG
0
Fc
⎤
⎥⎥⎦, ¯Ac
β =
 Aβ
0
GcG
Fc

and Ac
β is deﬁned in (7.127). The transfer function matrix of the resulting
closed-loop system is
T c
ℓ(s)
=

Tℓs
0
0T(N−ℓ)s

diag
)
¯T c
ℓ(s),
ℓ−1
=
>?
@
¯T c
β(s), . . . , ¯T c
β(s),
N−ℓ−1
=
>?
@
T c
β(s), . . . , T c
β(s)
*
×
)
T −1
ℓr
0
0
T −1
(N−ℓ)r
*
(7.143)
where
¯T c
ℓ(s)
=
C
0
0
0
0
C
0
DHc

(sI −¯Ac
ℓ)−1
⎡
⎢⎢⎣
Vℓ
˜Vℓ
˜Vℓ
VN−ℓ
GcF
0
0
GcF
⎤
⎥⎥⎦,
¯T c
β(s)
=
[C
0](sI −¯Ac
β)−1
 Γsβ
GcF


7.4. Reliable Control of Symmetric Composite Systems
349
and T c
β(s) is deﬁned in (7.129). Moreover, if Ac
ℓis stable, the H∞-norm of the
transfer function matrix is
∥T c
ℓ(s)∥∞
=
⎧
⎪
⎪
⎨
⎪
⎪
⎩
max
$
∥¯T c
ℓ(s)∥∞, ∥T c
β(s)∥∞
%
(ℓ= 1)
max
$
∥¯T c
ℓ(s)∥∞, ∥T c
β(s)∥∞, ∥T c
β(s)∥∞
%
(2 ≤ℓ≤N −2)
max
$
∥¯T c
ℓ(s)∥∞, ∥T c
β(s)∥∞
%
(ℓ−N −1)
7.4.8
General failures
In practice, a particular control-channel failure may have three possibilities:
control-input failure only, measurement failure only, and simultaneous control-
input and measurement failure. The following theorem shows that the above
three possibilities can be considered together.
Theorem 7.4.13 For 1 ≤ℓ≤N −1, the poles of the resulting closed-loop
system for any l control-channel failures are the same. Moreover, the transfer
function matrices are also identical.
Proof 7.4.14 Suppose there are 1 ≤ℓ≤N −1 control-channel failures in
which ℓ1 control-channels with only control-input failures, ℓ2 control-channels
with only measurement failures, and ℓ3 control-channels with both control-
input and measurement failures, thus ℓ1 + ℓ2 + ℓ3 = l. The system matrix and
the transfer function matrix of the resulting closed-loop system are
¯Ac
ℓ=

A
BsH∗
G∗Gs
F

and
¯T c
ℓ(s) = [Cs
DsH∗](sI −ˆAc
ℓ)−1
 Γs
G∗Fs

respectively, where
G∗
=
diag

ℓ2
=
>?
@
Gc, . . . , Gc,
ℓ2
= >? @
0, . . . , 0,
ℓ3
= >? @
0, . . . , 0,
N−l
=
>?
@
Gc, . . . , Gc

H∗
=
diag

ℓ2
= >? @
0, . . . , 0,
ℓ2
=
>?
@
Hc, . . . , Hc,
ℓ3
= >? @
0, . . . , 0,
N−l
=
>?
@
Hc, . . . , Hc

When sI −F is invertible, we have
|sI −ˆAc
ℓ|
=
AAAA
sI −A
−B2H∗
−G∗Gs
sI −F
AAAA
=
|sI −F| |(sI −A) −BsH∗(sI −F)−1G∗Gs|

350
Chapter 7. Decentralized Reliable Control
Since
(sI −F)−1 = diag[(sI −Fc)−1, . . . , (sI −Fc)−1]
we have
BsH∗(sI −F)−1G∗Gs
= diag

ℓ
= >? @
0, . . . , 0,
=>?@
B Hc(sI −Fc)−1GcG, . . . , BHc(sI −Fc)−1GcGN−ℓ

which is only affected by ℓ= ℓ1 + ℓ2 + ℓ3. Therefore
spec( ˆAc
l ) = spec(Ac
l )
Since system (7.120) has the particular symmetric structure and the decentral-
ized controller (7.121) has identical subsystem controllers, measurement fail-
ures and control-input failures have the same effect on the closed-loop transfer
function matrix [366], that is,
ˆT c
ℓ(s) = T c
ℓ(s)
which concludes the proof.
Remark 7.4.15 Since ℓmeasurement failures is a special case of l control-
channel failures, the results of ℓmeasurement failures are the same as that of ℓ
control-input failures.
Remark 7.4.16 It can be easily seen from (7.143) that the necessary condition
for Ac
ℓto be stable (ℓ≥1) is spec(Fc) ⊂C−. In other words, spec(Fc) ⊂C−
is necessary for the closed-loop system to endure at least one control-channel
failure.
Remark 7.4.17 From Theorems 7.4.12 and 7.4.13, one can determine the re-
liability of the controller by simply computing the poles and the H∞-norm of
at most three lower order systems. Noting that there is no conservativeness
introduced in the simpliﬁcation, thus the resulting reliability is also exact.
Remark 7.4.18 The control-channel failure considered in this paper means
the control channel of particular subsystems completely fail. If each subsystem
is a multiple-input system and the same part of the input fails for ℓsubsystems,
similar reliability analysis results can be obtained. However, if a different part
of the input fails in different subsystems, the result in this paper cannot be
applied because the symmetric structure of the whole system will no longer
hold. Certainly the reliability analysis method suitable for an arbitrary system
could still be applied but the analysis will not be so simple.

7.4. Reliable Control of Symmetric Composite Systems
351
7.4.9
Illustrative example 7.6
Consider the closed-loop system composed of system (7.140) and the controller
(7.141) designed in the previous section. For 1 ≤ℓ≤19 control-channel fail-
ures, Theorem 7.4.12 is used to compute ∥T c
ℓ(s)∥∞. The results are summa-
rized in Table 7.1 (ℓ= 0 refers to the closed-loop system with no control-
channel failure). Following the foregoing analysis, we take γ = 0.62. Table 7.1
shows that for 1 ≤ℓ≤16, ∥T c
ℓ(s)∥∞< γ while ∥T c
17(s)∥∞> γ. Hence the
closed-loop system will maintain its stability and with the norm of the transfer
function matrix less than γ when ℓ< 16 control-channel failures occur.
Table 7.1: Summary of Results for Example 7.6 (γ = 0.62)
ℓ
∥T c
ℓ(s)∥∞
ℓ
∥T c
ℓ(s)∥∞
ℓ
∥T C
ℓ(s)∥∞
ℓ
∥T C
ℓ(s)∥∞
0
0.6143
5
0.6160
10
0.6177
15
0.6195
1
0.6146
6
0.6164
11
0.6181
16
0.6198
2
0.6150
7
0.6167
12
0.6184
17
0.6201
3
0.6153
8
0.6170
13
0.6188
18
0.6205
4
0.6157
9
0.6174
14
0.6191
19
0.6208
7.4.10
Illustrative example 7.7
Consider the closed-loop system derived in Illustrative example 7.5. For 1 ≤
ℓ≤19 control-channel failures, Theorem 7.4.12 is used to compute spec(Ac
ℓ)
and ∥T c
ℓ(s)∥∞. The results are summarized in Table 7.2 (ℓ= 0 and ℓ= 20
refer to the closed-loop system with no control-channel failure and the open-
loop system, respectively).
Following the foregoing analysis, we take γ = 10; Table 7.2 shows that
for 1 ≤ℓ≤8, Ac
ℓis stable and ∥T c
ℓ(s)∥∞> γ while ∥T c
g (s)∥∞> γ.
Therefore, the closed-loop system will maintain its stability and with the norm
of the transfer function matrix less than γ when ℓ< 9 control-channel fail-
ures occur. Moreover, the closed-loop system becomes unstable when ℓ≥14
control-channel failures occur.
7.4.11
Illustrative example 7.8
Consider the voltage/reactive power behavior of a multimachine power system.
The overall system consists of several synchronous machines including their
PI-voltage controller, which feeds the load through a distribution net [191].

352
Chapter 7. Decentralized Reliable Control
Table 7.2: Summary of Results for Example 7.7 (γ = 10)
ℓ
Ac
ℓ
∥T c
ℓ(s)∥∞
0
stable
4.9213
1
stable
5.1988
2
stable
5.5178
3
stable
5.8893
4
stable
6.3286
5
stable
6.8579
6
stable
7.5104
7
stable
8.3385
8
stable
9.4292
9
stable
10.9398
10
stable
13.1864
11
stable
16.9131
12
stable
24.3899
13
stable
47.4609
≥14
unstable
−−
The system can be modeled by
˙xi =
−2.51
−0.16
2.55
0

xi +
N

k=1,k̸=i
 −0.065
0
−0.0027
0

xk
+
0.9
−1

ui +
0.2
0.1

+
N

k=1,k̸=i
0.1
0.1

wk
zi = [2.540]xi + ui,
i = 1, 2, . . . , N
Taking N = 20 and computing directly, we have
As
=
−2.445
−0.16
2.5527
0

Ao
=
−3.745
−0.16
2.4987
0

Gs
=
0.1
0

Go
=
2.1
2


7.5. Problem Set V
353
Suppose γ = 0.8 , we choose α = 0.4, ϵ = 0.0002. Solving the Riccati equa-
tions (7.135) and (7.136), we have
Po
=
 0.001
0.0011
0.0011
0.0014

Ps
=
0.000694
0.000625
0.000625
0.0006025

By testing, we know that inequalities Theorem 7.4.5 do not hold; we try by
choosing
K1 = −R−1
1 (BT
1 Po + DT
1 C1)
and obtain K1
= [−2.5397, 0 : 0003]. From Theorem 7.2.12, we get
spec(Ac) = 4.552, −0.179, −5.8942, −0.1368 ⊂C−, and ∥T∥∞= 0 :
0083 < γ. Thus the decentralized H∞control law can be chosen as
ui = K1xi = [−2.5397, 0.0003]xi,
i = 1, . . . , N
For l = 1, 2, 3, 4, Theorems 7.4.12 and 7.4.13 are used to compute spec (Acl)
and ∥Tl∥∞. The results are summarized in Table 7.3.
Since for l = 1, 2, 3, spec(Acl) ⊂C−and ∥Tl∥∞< γ ,but ∥T4∥∞> γ,
hence l0 = 4. As a result, the closed-loop system will maintain its stability
and the transfer matrix will satisfy ∥Tl∥∞≤γ when less than four subsystem
controllers fail.
Table 7.3: Summary of Results
l
spec (Acl)
∥Tl∥∞
1
-4.552, -0.179, 5.8517, -2.3089, -0.802, -0.1352
0.4501
2
-4.552, -0.179, -2.2646, -0.1804, -5.8082, -2.3541, -0.1801, -0.1336
0.6368
3
-4.552, -0.179, -2.2646, -0.1804, -5.7635, -2.4005, -0.18, -0.1321
0.7803
4
-4.552, -0.179, -2.2646, -0.1804, -5.7176, -2.448, -0.1799, -0.1305
0
7.5
Problem Set V
Problem V.1: Consider the stabilization problem of subsystems with collocated
sensors and actuators, which are described by
Mj ¨qj + Dj ˙qj + Kjqj
=
Ljuj
yj
=
Lt
jqj,
j = 1, 2, ...ns

354
Chapter 7. Decentralized Reliable Control
where qj ∈ℜn
j , uj ∈ℜr
j, and yj ∈ℜr
j are the displacement (translational
displacement and rotational angle), control input (force and torque), and mea-
sured displacement output of the jth subsystem, respectively. The mass matrix
Mj is positive-deﬁnite while the damping and stiffness matrices Dj and Kj are
positive-semideﬁnite such that
rank[Dj
Kj] = rank[Dj] = rank[Kj] < nj
The matrix Lj is deﬁned by the locations and directions of actuators and the
matrix Lt
j expresses the locations and directions of sensors. Assume that the
rigid modes of each subsystem are controllable and observable. Establish con-
ditions under which the use of a dynamic displacement feedback controller at
the subsystem level
˙xj
=
−Rjxj + Sjyj
uj
=
St
jxj −Kjyj
where xj ∈ℜp
j, pj ≥rj, Rj > 0 and the matrix Sj is of full rank, guaran-
tees the closed-loop subsystem stability. Study the reliability of the closed-loop
system when the jth local subsystem controller fails and justify your results.
Problem V.2: Consider the multicontroller problem of linear time-invariant
systems of the form
˙x
=
Ax +
q

j=1
Buj + Gwo,
q > 1
yj
=
Cx + wj,
j = 1, 2, ...q,
z
=
[xtHt ut
1 · · · ut
q]t
where x ∈ℜn
is the state, yj, j = 1, 2, ...q are the measured outputs, z
is an output to be regulated, wj, j = 0, 1, 2, ...q are the square-integrable
disturbances, and uj, j = 1, 2, ...q are the control inputs. We seek to design q
identical controllers for the system, generated by the dynamic form
˙ξj
=
Acξj + Lyj
uj
=
K ξj j = 1, 2, ...q
where K is the feedback gain, L is the observer gain, Kw is the disturbance
estimate gain, and Ac = A + BK + GKw −LC. It is required to propose a
method to design the gains K, L, and Kw so that for any p controller failures

7.5. Problem Set V
355
(0 ≤p ≤q −1), the resulting closed-loop system is internally stable and
the H∞-norm of the closed-loop transfer function matrix is bounded by some
prescribed constant β > 0. Illustrate your method on the following data:
A
=
⎡
⎢⎢⎣
−2
1
1
1
3
0
0
2
−1
0
−2
−3
−2
−1
2
−1
⎤
⎥⎥⎦, G =
⎡
⎢⎢⎣
0.5
0
0
0
⎤
⎥⎥⎦, B =
⎡
⎢⎢⎣
0
0
0
1
⎤
⎥⎥⎦,
H
=

0
0
0.5
0

, C =

1
0
0
0

, q = 2
and provide some interpretations.
Problem V.3: A linear state-delayed system is described by
˙xj(t)
=
Ajxj(t) + Adjxj(t −τj(t)) + Bjuj +
ns

k=1,k̸=j
Fjkxk(t)
zj(t)
=
Gjxj(t) + Ωjwj(t), j = 1, ..., ns,
xj(t)
=
φj(t),
t ∈[−τj, 0]
where xj ∈ℜnj is the state, zj ∈ℜpj is the measurement output,
uj ∈
ℜmj is the control input, wj, j = 0, 1, 2, ...q is the unexpected sensor signal
(sensor fault), τj is the constant delay, and φj(t) ∈ℜnj is the initial state
vector. Consider an observer-based controller of the form
˙ξj
=
Ajξj + Adjξj(t −τj(t)) + Bj(uj) + Kj(zj −Gjξj)
uj
=
KFj ξj
where ξj ∈ℜnj is the state estimate, Kj is the observer gain, and Fj is the
state-feedback gain. Generate the augmented closed-loop dynamics in terms of
the augmented state-vector ζ = [xt
xt−ξt]t and establish conditions of stabil-
ity when wj = 0. To study the performance of the closed-loop observer-based
control system, we consider adding appropriate control signals Bfjuj(t −η)
and Dfjuj(t−η) to the input and output channels, respectively. It is required to
develop complete analysis and control synthesis for the reliable observer-based
control system.
Problem V.4: Consider the multicontroller problem of linear time-invariant

356
Chapter 7. Decentralized Reliable Control
systems of the form
˙x
=
Ax +
M

j=1
Buj + Gwo,
M > 1
yj
=
Cjx + wj,
j = 1, 2, ...M,
z
=
[xtHt ut
1 · · · ut
M]t
where x ∈ℜn
is the state, yj, j = 1, 2, ...M are the measured outputs, z
is an output to be regulated, wj, j = 0, 1, 2, ...M are the square-integrable
disturbances, and uj, j = 1, 2, ...M are the control inputs. For the measured
output yj, j = 1, 2, ...M, let yF
j be the signal from the sensor that has failed.
Then the following sensor failure model is used:
yF
j = αsjyj + αsojβF
sj
where βF
sj is a bounded disturbance, and αsj, αsoj satisfy
0 ≤αsjm ≤αsj ≤αsjM, 0 ≤αsoj ≤αsojM
for j = 1, 2, ...M. In a similar way, let uF
j be the signal from the actuator that
has failed. The actuator failure model has the form
uF
j = αajuj + αaojβF
aj
where βF
aj is a bounded disturbance, and αaj, αaoj satisfy
0 ≤αajm ≤αaj ≤αajM, 0 ≤αaoj ≤αaojM
for j = 1, 2, ...M and where αsojM ≥1 and αaojM ≥1.
It is desired to design a controller of the following form:
˙ζ
=
Fζ + Ly
u
=
K ζ
j = 1, 2, ...M
such that the resulting closed-loop system is asymptotically stable and with an
H∞-norm bound not only when all control components are operational, but
also in the case of some sensor and actuator failures. Examine the developed
conditions under different operational conditions.

7.6. Notes and References
357
7.6
Notes and References
In the ﬁrst part of this chapter, the decentralized reliable feedback stabilization
problem was discussed for a class of linear interconnection of continuous time-
delay plants subjected to convex-bounded parametric uncertainties and coupled
with time-delay interconnections. In the problem set-up, either actuator or sen-
sor failures have been described by a model that considers possible outage or
partial failures in every actuator/sensor of each decentralized controller. We
ﬁrst establish a sufﬁcient condition for the existence of a decentralized reliable
control scheme. This control, based on either state or static output-feedback,
has been effectively constructed by means of a feasible LMI optimization prob-
lem. A key point in the control design has been the formulation of an LMI
characterization, which uses assumptions over model uncertainties to remove
the parameter dependence of the control characterization. This part is further
complemented by developing the complete counterpart results of the decentral-
ized reliable feedback stabilization problem for a class of linear interconnection
of discrete-time-delay plants.
In the second part of this chapter, we moved to examine the dynamic out-
put feedback decentralized H∞control and reliability analysis of symmetric
composite systems. By using the structural properties of the systems, we pro-
vided a simple method to design its dynamic output feedback decentralized
H1 controller. Moreover, the reliability of the controller can be easily tested
by computing the poles and the H∞-norm of systems of possibly much lower
orders. Though we presented simple controller design and reliability analysis
methods for symmetric composite systems, the reliability analysis can only be
conducted after the controller design. In practice, the method proposed in this
chapter can be applied in an iterative way. That is, if the reliability of the de-
signed system is not satisfactory, then we can increase the performance require-
ment for the nominal case design and use our method to check the reliability
again.
The area of decentralized reliable control is attactive and much more is
anticipated to deal with different models of actuator/sensor faults.

Chapter 8
Decentralized Resilient Control
In this chapter, we continue probing further into the decentralized-control tech-
niques for interconnected systems, where we focus herein on methods for de-
signing resilient controllers to accommodate both parametric uncertainties and
controller gain perturbations. We address two approaches: the ﬁrst approach is
an extension of Chapter 6 on time-delay systems and the second approach is an
extension of the overlapping methods discussed in Chapter 5.
8.1
Introduction
In this paper, we develop robust decentralized delay-dependent stability and
resilient feedback stabilization methods for a class of linear interconnected
continuous-time systems. The subsystems are subjected to convex-bounded
parametric uncertainties while time-varying delays occur within the local sub-
systems and across the interconnections and additive feedback gain perturba-
tions are allowed. In this way, our control design offers decentralized structure
and possesses robustness with respect to both parametric uncertainties and gain
perturbations. For related results on resilient control, the reader is referred to
[258]-[266] where it is shown to provide a framework of extended robustness
properties. In this chapter, we construct appropriate Lyapunov-Krasovskii func-
tional in order to exhibit the delay-dependent dynamics. The developed meth-
ods for decentralized stability and stabilization deploy an “injection procedure”
within the individual subsystems which eliminates the need for overbounding
and utilizes a smaller number of LMI decision variables. By this way, improved
and less conservative solutions to the robust decentralized delay-dependent sta-
bility and resilient feedback stabilization problems in terms of feasibility test-
ing of new parameterized linear matrix inequalities (LMIs) are developed. In
359

360
Chapter 8. Decentralized Resilient Control
our analysis, we consider the time-delay factor as a differentiable time-varying
function satisfying some bounding relations and derive the solution criteria for
nominal and polytopic models. Then, resilient decentralized feedback stabiliza-
tion methods are provided based on state measurements, static output feedback,
and dynamic output feedback by allowing additive gain perturbations while
guaranteeing that the corresponding closed-loop family of individual subsys-
tems enjoys the robust decentralized delay-dependent stability with an L2 gain
smaller than a prescribed constant level.
8.2
Problem Statement
We consider a class of linear systems S structurally composed of ns coupled
subsystems Sj and modeled by the state-space model:
˙xj(t)
=
Ajxj(t) + Adjxj(t −τj(t)) + Bjuj(t) + cj(t) + Γjwj(t)
zj(t)
=
Gjxj(t) + Gdjxj(t −τj(t)) + Djuj(t) + Φjwj(t)
yj(t)
=
Cjxj(t) + Cdjxj(t −τj(t))
cj(t)
=
ns

k=1,k̸=j
Fjkxk(t) +
ns

k=1,k̸=j
Ejkxk(t −ηjk(t))
(8.1)
where for j ∈{1, ..., ns}, xj(t) ∈ℜnj is the state vector, uj(t) ∈ℜmj is
the control input, yj(t) ∈ℜpj is the measured output, wj(t) ∈ℜqj is the
disturbance input which belongs to L2[0, ∞), zj(t) ∈ℜqj is the performance
output, cj(t) ∈ℜnj is the coupling vector, and τj, ηjk, j, k ∈{1, ..., ns}
are unknown time-delay factors satisfying
0
≤
τj(t) ≤ϱj,
˙τj(t) ≤μj,
0
≤
ηjk(t) ≤ϱjk,
˙ηjk(t) ≤μjk
(8.2)
where the bounds ϱj, ϱjk, μj, μjk are known constants in order to guar-
antee smooth growth of the state trajectories. The matrices Aj ∈ℜnj×nj,
Bj ∈ℜnj×mj,
Dj ∈ℜqj×mj,
Adj ∈ℜnj×nj, Φj ∈ℜqj×qj, Γj ∈
ℜnj×qj, Cj ∈ℜpj×nj, Cdj ∈ℜpj×nj, Gj ∈ℜqj×nj, Gdj ∈ℜqj×nj, Fjk ∈
ℜnj×nk, Ejk ∈ℜnj×nk are real and constants.
The initial condition ⟨xj(0), xj(r)⟩= ⟨xoj, φj⟩, j ∈{1, ..., ns} where
φj(.) ∈L2[−τ ∗
j , 0], j ∈{1, ..., ns}. The inclusion of the terms Adjxj(t −
τj(t)), Ejkxk(t −ηjk(t)) is meant to emphasize the delay within each sub-
system (local delay) and among the subsystems (coupling delay), respectively;
see Figure 8.1. The class of systems described by (8.1) subject to delay-pattern

8.2. Problem Statement
361
Figure 8.1: Subsystem model
(8.2) is frequently encountered in modeling several physical systems and en-
gineering applications including large space structures, multimachine power
systems, cold mills, transportation systems, and water pollution management,
to name a few [252, 253, 324]. Our objective in this chapter is to study two
main problems: the ﬁrst problem is the decentralized delay-dependent asymp-
totic stability by deriving a feasibility testing at the subsystem level so as to
guarantee the overall system asymptotic stability. The second problem deals
with the resilient decentralized feedback stabilization by developing decentral-
ized feedback controllers (based on state, static output, and dynamic output)
that takes into consideration additive gain perturbations while ensuring that the
overall closed-loop system is delay-dependent asymptotically stable.
The following theorem is a variant of results from Chapter 6.
Theorem 8.2.1 Given ϱj
>
0,
μj
>
0,
ϱjk
>
0, and μjk
>
0, j, k = 1, ..., ns. The family of subsystems {Sj} with uj(.) ≡0 where
Sj is described by (8.1) is delay-dependent asymptotically stable with L2-
performance bound γj, j = 1, ..., ns if there exist positive-deﬁnite matrices
Pj, Qj, Wj, Zkj, k, j = 1, ..ns, parameter matrices Θj Υj satisfying the

362
Chapter 8. Decentralized Resilient Control
following LMIs for j, k = 1, ..., ns:
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
Ξoj
Ξaj
−ϱjΘj
0
PjΓj
Gt
j
ϱkAt
jWk
•
−Ξmj
−ϱjΥj
0
0
Gt
dj
ϱkAt
djWk
•
•
−ϱjWj
0
0
0
0
•
•
•
−Ξnj
0
0
ϱk
ns
k=1,k̸=j EkjWk
•
•
•
•
−γ2
j Ij
Φt
j
ϱkΓt
jWk
•
•
•
•
•
−Ij
0
•
•
•
•
•
•
−ϱkWk
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
< 0
(8.3)
where
Ξoj
=
Pj[Aj +
ns

k=1
Fkj] + [Aj +
ns

k=1
Fkj]tPt
j + Θj + Θt
j
+
Qj +
ns

k=1,k̸=j
Zkj + (ns −1)Pj,
Ξmj
=
Υj + Υt
j + (1 −μj)Qj, Ξaj = PjAdj −Θj + Υt
j,
Ξnj
=
ns

k=1,k̸=j
(1 −μkj)Zkj +
ns

k=1,k̸=j
Et
kjPkEkj
(8.4)
In the foregoing section, we considered the design of feedback controllers un-
der the condition that the implementations of the gains do not undergo any
perturbations or parameter tolerances. In what follows, we extend the design
results to the case when the feedback gain perturbations are incorporated into
the analysis. This design approach is often called resilient control theory; see
[258] for further reading.
8.3
Resilient Decentralized Stabilization
We now direct attention to resilient decentralized feedback stabilization
schemes that take into account possible feedback gain variations. Essentially,
our approach builds upon the framework of resilient control theory [258] and
extends the results of [105, 174]. We start with the state feedback case.

8.3. Resilient Decentralized Stabilization
363
8.3.1
Resilient state feedback
Consider the resilient state feedback control
uj(t)
=
[Kj + ΔKj(t)]xj(t), ΔKj(t) = MjΔj(t)Nj,
Δt
j(t)Δj(t) ≤I,
∀t
(8.5)
where ΔKj(t) represent additive gain perturbations with Mj, Nj being con-
stant matrices. Applying controller (8.5) to the linear system (8.1) yields the
following closed-loop system and matrices:
˙xj(t)
=
Afjxj(t) + Adjxj(t −τj(t)) + cj(k) + Γjwj(t)
zj(t)
=
Gfjx(t) + Gdjx(t −τj(t)) + Φjwj(t)
yj(t)
=
Cjxj(t) + Cdjxj(t −τj(t))
cj(t)
=
ns

k=1,k̸=j
Fjkxk(t) +
ns

k=1,k̸=j
Ejkxk(t −ηjk(t))
Afj
=
Aj + BjKj + BjΔKj, Gfj = Gj + DjKj + DjΔKj (8.6)
Then it follows from Theorem 8.2.1 that the resulting closed-loop system
(8.6) is delay-dependent asymptotically stable with L2-performance bound γ
if there exist matrices Pj, Qj, Wj, Wk, Zkj, j, k = 1, ..ns,
parameter
matrices Θj Υj, and a scalar γj > 0 satisfying the following LMI:
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
Ξfj
Ξaj
−ϱjΘj
Ξcj
PjΓj
Gt
fj
ϱkAt
fjWk
•
−Ξmj
−ϱjΥj
0
0
Gt
dj
ϱkAt
djWk
•
•
−ϱjWj
0
0
0
0
•
•
•
−Ξnj
0
0
ϱk
ns
k=1,k̸=j EkjWk
•
•
•
•
−γ2
j Ij
Φt
j
ϱkΓt
jWk
•
•
•
•
•
−Ij
0
•
•
•
•
•
•
−ϱkWk
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
< 0
(8.7)
where
Ξfj
=
Pj[Afj +
ns

k=1
Fkj] + [Afj +
ns

k=1
Fkj]tPt
j + Θj + Θt
j
+
Qj +
ns

k=1,k̸=j
Zkj + (ns −1)Pj
(8.8)

364
Chapter 8. Decentralized Resilient Control
and Ξaj, Ξcj, Ξmj, Ξnj are given by (8.4). Application of Inequality 1 from
the Appendix to LMI (8.7) using (8.5) yields
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
Ξkj
Ξaj
−ϱjΘj
Ξcj
PjΓj
Gt
kj
ϱjAt
kjWj
•
−Ξmj
−ϱjΥj
0
0
Gt
dj
ϱjAt
djWj
•
•
−ϱjWj
0
0
0
0
•
•
•
−Ξnj
0
0
ϱj
ns
k=1 EkjWj
•
•
•
•
−γ2
j Ij
Φt
j
ϱjΓt
jWj
•
•
•
•
•
−Ij
0
•
•
•
•
•
•
−ϱjWj
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
+εj
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
PjBjMj
0
0
0
0
DjMj
ϱjWjBjMj
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
PjBjMj
0
0
0
0
DjMj
ϱjWjBjMj
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
t
+ ε−1
j
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
N t
j
0
0
0
0
0
0
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
N t
j
0
0
0
0
0
0
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
t
<0 (8.9)
Ξkj = Pj[Akj +
ns

k=1
Fkj] + [Akj +
ns

k=1
Fkj]tPt
j + Θj + Θt
j +
Qj + +
ns

k=1,k̸=j
Zkj + (ns −1)Pj
Gkj = Gj + DjKj, Akj = Aj + BjKj
(8.10)
for some εj > 0. The main decentralized resilient feedback design results are
established by the following theorems.
Theorem 8.3.1 Given the bounds ϱj > 0, μj > 0 and matrix Wj, the in-
terconnected system (8.1) with decentralized resilient controller (8.5) is delay-
dependent asymptotically stable with L2-performance bound γj if there exist
positive-deﬁnite matrices Xj, Yj, {Λkj}ns
k=1, {Ψrj}4
r=1, and a scalar εj > 0
satisfying the following LMIs for j = 1, ..., ns:
 Ξ1j
Ξ2j
•
Ξ3j

< 0
(8.11)

8.3. Resilient Decentralized Stabilization
365
Ξ1j =
 Ξ1aj
Ξ1cj
•
Ξ1sj

Ξ1aj =
⎡
⎢⎢⎣
Πoj
Πaj
−ϱjΨ1j
0
•
−Πmj
−ϱjΨ3j
0
•
•
−ϱjΨ4j
0
•
•
•
−Πnj
⎤
⎥⎥⎦
Ξ1cj =
⎡
⎢⎢⎣
Γj
Πt
zj
ϱk(XjAt
j + Yt
jBt
j)Wk
0
Gt
dj
ϱkXjAt
djWk
0
0
0
0
0
ϱk
ns
k=1,k̸=j XjEkjWk
⎤
⎥⎥⎦
Ξ1sj =
⎡
⎣
−γ2
j Ij
Φt
j
ϱkΓt
jWk
•
−Ij
0
•
•
−ϱkWk
⎤
⎦
Ξ2j =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
εjBjMj
XjN t
j
0
0
0
0
0
0
0
0
εjDjMj
0
εjϱjWjBjMj
0
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
, Ξ3j =
 −εjIj
0
•
−εjIj

(8.12)
where
Πoj
=
[Aj +
ns

k=1
Fkj]Xj + BjYj + Xj[Aj +
ns

k=1
Fkj]t + Yt
jBt
j + Ψ1j
+
Ψt
1j + Ψ2j +
ns

k=1,k̸=j
Λkj + +(ns −1)Xj
Πaj
=
AdjXj −Ψ1j + Ψt
3j, Πmj = Ψ3j + Ψt
3j + (1 −μj)Ψ2j + Ψt
4j,
Πnj
=
ns

k=1,k̸=j
(1 −μkj)Λkj +
ns

k=1,k̸=j
XjEt
kjPkEkjXj,
Πzj
=
GjsXj + DjsYj
(8.13)
Moreover, the local gain matrix is given by Kj = YjX −1
j
.
Proof: Applying the congruent transformation
Blockdiag[Xj, Xj, Xj, Xj, Ij, Ij, Ij, Ij, Ij], Xj = P−1
j

366
Chapter 8. Decentralized Resilient Control
to LMI (8.9) Schur complements and using the linearizations
Yj
=
KjXj, Ψ1j = XjΘjXj, Ψ2j = XjQjXj,
Ψ3j
=
XjΥjXj, Ωj = αjXjF t
j , Λkj = XjZkjXj, Ψ4j = XjWjXj
we readily obtain LMI (8.11) by Schur complements.
Theorem 8.3.2 Given the bounds ϱj > 0, μj > 0 and matrix Wj, the in-
terconnected system (8.1) with decentralized controller uj(t) = Kjxj(t) and
polytopic representation (6.28)-(6.29) is delay-dependent asymptotically sta-
ble with L2-performance bound γj if there exist weighting matrices Xj, Yj,
{Λkj}ns
k=1, {Ψrj}3
r=1
satisfying the following LMIs for j = 1, ..., ns, s =
1, ..., N:
 Ξ1js
Ξ2js
•
Ξ3j

< 0
(8.14)
Ξ1js =
 Ξajs
Ξcjs
•
Ξejs

Ξajs =
⎡
⎢⎢⎣
Πojs
Πajs
−ϱjΨ1j
0
•
−Πmj
−ϱjΨ3j
0
•
•
−ϱjΨ4j
0
•
•
•
−Πnj
⎤
⎥⎥⎦
Ξcjs =
⎡
⎢⎢⎣
Γjs
Πt
zjs
ϱk(XjAt
js + Yt
jBt
js)Wk
0
Gt
djs
ϱkXjAt
djsWk
0
0
0
0
0
ϱk
ns
k=1,k̸=j XjEkjsWk
⎤
⎥⎥⎦
Ξejs =
⎡
⎢⎢⎣
−γ2
j Ij
Φt
j
ϱjΓt
jWj
•
−Ij
0
bullet
•
−ϱkWk
⎤
⎥⎥⎦
Ξ2js =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
εjBjsMj
XjN t
j
0
0
0
0
0
0
0
0
εjDjsMj
0
εjϱjWjBjsMj
0
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
, Ξ3j =
 −εjI
0
•
−εjI

(8.15)

8.3. Resilient Decentralized Stabilization
367
where
Πojs
=
[Ajs +
ns

k=1
Fkjs]Xj + BjsYj + Xj[Ajs +
ns

k=1
Fkjs]t + Yt
jBt
js
+
Ψ1j + Ψt
1j + Ψ2j +
ns

k=1,k̸=j
Λkjs + (ns −1)Xj
Πajs
=
AdjXj −Ψ1j + Ψt
3j, Πmj = Ψ3j + Ψt
3j + (1 −μj)Ψ2j,
Πnj
=
ns

k=1,k̸=j
(1 −μkj)Λkjs +
ns

k=1
XjEt
kjsPkEkjsXj,
Πzjs
=
GjsXj + DjsYj
(8.16)
Moreover, the local gain matrix is given by Kj = YjX −1
j
.
Proof: Follows by parallel development to Theorems 6.2.6 and 6.2.7.
Remark 8.3.3 Similarly, the optimal performance-level γj, j = 1, .., ns can
be determined in case of decentralized resilient state feedback stabilization by
solving the following convex optimization problems:
Problem A: Resilient state feedback stabilization
For j, k = 1, ..., ns,
Given ϱj, μj, ϱjk, μjk,
min
Xj, Yj, Mj, Ωj, {Λrj}ns
r=1, {Ψrj}4
1
γj
subject to LMI(8.12)
(8.17)
Next, we move to the static output feedback case. To facilitate further develop-
ment, we consider the case where the set of output matrices Cj, j = 1, ..., ns
are assumed to be of full row rank.
8.3.2
Resilient static output feedback
Consider the resilient static output feedback control
uj(t)
=
[Koj + ΔKoj(t)]yj(t), ΔKoj(t) = MojΔj(t)Noj,
Δt
j(t)Δj(t) ≤I,
∀t
(8.18)
where ΔKoj(t) represent additive gain perturbations with Moj, Noj being
constant matrices. Using controller (8.18) and the output equation, the closed-

368
Chapter 8. Decentralized Resilient Control
loop subsystem dynamics can be written as
˙xj(t)
=
Ajxj(t) + Adjxj(t −τj(t)) + cj(t) + Γjwj(t)
+
Bj(Koj + ΔKoj)[Cjx(t) + Cdjx(t −τj(t))]
=
Agjxj(t) + Adgjxj(t −τj(t)) + cj(t) + Γjwj(t)
(8.19)
zj(t)
=
Gjxj(t) + Gdjxj(t −τj(t)) + Φjwj(t)
+
Dj(Koj + ΔKoj)[Cjx(t) + Cdjx(t −τj(t))]
=
Ggjxj(t) + Gdgjxj(t −τj(t)) + Φjwj(t)
(8.20)
cj(t)
=
ns

k=1,k̸=j
Fjkxk(t) +
ns

k=1,k̸=j
Ejkxk(t −ηjk(t))
(8.21)
where
Agj
=
Aj + BjKojCj + BjΔKojCj =
ˆAgj + BjΔKojCj
Adgj
=
Adj + BjKojCdj + BjΔKojCdj =
ˆAdgj + BjΔKojCdj
Ggj
=
Gj + DjKojCj + DjΔKojCj = ˆGgj + DjΔKojCj
Gdgj
=
Gdj + DjKojCdj + DjΔKojCdj = ˆGdgj + DjΔKojCdj
(8.22)
Proceeding further, we apply Theorem 8.2.1 to the resulting closed-loop sys-
tem (8.22). As a consequence, system (8.22) is delay-dependent asymptotically
stable with L2-performance bound γ if there exist matrices
Pj, Qj, Wj, Wk, Zkj, j, k = 1, ..ns
and parameter matrices Θj Υj and a scalar γj > 0 satisfying the following
LMI:
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
Ξgj
Ξaj
−ϱjΘj
Ξcj
PjΓj
Gt
gj
ϱjAt
gjWj
•
−Ξmj
−ϱjΥj
0
0
Gt
dgj
ϱjAt
dgjWj
•
•
−ϱjWj
0
0
0
0
•
•
•
−Ξnj
0
0
ϱj
ns
k=1 EkjWj
•
•
•
•
−γ2
j Ij
Φt
j
ϱjΓt
jWj
•
•
•
•
•
−Ij
0
•
•
•
•
•
•
−ϱjWj
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
< 0
(8.23)

8.3. Resilient Decentralized Stabilization
369
where
Ξgj = Pj[ ˆAgj +
ns

k=1,k̸=j
Fkj + BjΔKojCj]
+ Θj + Θt
j + Qj + [ ˆAgj +
ns

k=1,k̸=j
Fkj + BjΔKojCj]tPj
+
ns

k=1,k̸=j
Zkj + (ns −1)Pj
= Pj[ ˆAgj +
ns

k=1
Fkj + BjΔKojCj] + [ ˆAgj +
ns

k=1
Fkj + BjΔKojCj]tPj
+ Θj + Θt
j + Qj +
ns

k=1,k̸=j
Zkj + (ns −1)Pj
+ PjBjΔKojCj + Ct
jΔKt
ojBt
jPj
= ˆΞgj + PjBjΔKojCj + Ct
jΔKt
ojBt
jPj
(8.24)
and Ξaj, Ξcj, Ξmj, Ξnj are given by (8.4). Algebraic manipulation of (8.23)
using (8.22) yields
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
ˆΞgj
Ξaj
−ϱjΘj
Ξcj
PjΓj
ˆGt
gj
ϱk ˆAt
gjWk
•
−Ξmj
−ϱjΥj
0
0
ˆGt
dgj
ϱk ˆAt
dgjWk
•
•
−ϱjWj
0
0
0
0
•
•
•
−Ξnj
0
0
ϱk
ns
k=1,k̸=j EkjWk
•
•
•
•
−γ2
j Ij
Φt
j
ϱkΓt
jWk
•
•
•
•
•
−Ij
0
•
•
•
•
•
•
−ϱkWk
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
+
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
PjBjMoj
0
0
0
0
DjMoj
ϱjWjBjMoj
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
Δj
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
Ct
jN t
oj
0
0
0
0
0
0
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
t
+
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
Ct
jN t
oj
0
0
0
0
0
0
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
Δt
j
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
PjBjMoj
0
0
0
0
DjMoj
ϱjWjBjMoj
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
t

370
Chapter 8. Decentralized Resilient Control
+
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
0
0
0
0
0
DjMoj
ϱjWjBjMoj
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
Δj
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
0
Ct
djN t
oj
0
0
0
0
0
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
t
+
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
0
Ct
djN t
oj
0
0
0
0
0
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
Δt
j
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
0
0
0
0
0
DjMoj
ϱjWjBjMoj
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
t
< 0
(8.25)
With the aid of Inequality 1 of the Appendix, expression (8.25) becomes
≤
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
ˆΞgj
Ξaj
−ϱjΘj
Ξcj
PjΓj
ˆGt
gj
ϱk ˆAt
gjWk
•
−Ξmj
−ϱjΥj
0
0
ˆGt
dgj
ϱk ˆAt
dgjWk
•
•
−ϱjWj
0
0
0
0
•
•
•
−Ξnj
0
0
ϱk
ns
k=1,k̸=j EkjWk
•
•
•
•
−γ2
j I
Φt
j
ϱkΓt
jWk
•
•
•
•
•
−I
0
•
•
•
•
•
•
−ϱkWk
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
+εj
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
PjBjMoj
0
0
0
0
DjMoj
ϱjWjBjMoj
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
PjBjMoj
0
0
0
0
DjMoj
ϱjWjBjMoj
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
t
+ ε−1
j
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
Ct
jN t
oj
0
0
0
0
0
0
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
Ct
jN t
oj
0
0
0
0
0
0
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
t
+ϕj
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
0
0
0
0
0
DjMoj
ϱjWjBjMoj
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
0
0
0
0
0
DjMoj
ϱjWjBjMoj
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
t
+ ϕ−1
j
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
0
Ct
djN t
oj
0
0
0
0
0
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
0
Ct
djN t
oj
0
0
0
0
0
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
t
< 0
(8.26)
for some εj > 0, ϕj > 0. By Schur complements, we express the last ﬁve
terms in (8.26) into the form
 Ξ4j
Ξ5j
•
Ξ6j

< 0
(8.27)

8.3. Resilient Decentralized Stabilization
371
where
Ξ4j
=
 Ξ41j
Ξ42j
•
Ξ43j

(8.28)
where
Ξ41j
=
⎡
⎢⎢⎣
ˆΞgj
Ξaj
−ϱjΘj
0
•
−Ξmj
−ϱjΥj
0
•
•
−ϱjWj
0
•
•
•
−Ξnj
⎤
⎥⎥⎦
Ξ42j
=
⎡
⎢⎢⎢⎣
PjΓj
ˆGt
gj
ϱj ˆAt
gjWj
0
ˆGt
dgj
ϱk ˆAt
dgjWk
0
0
0
0
0
ϱk
ns
k=1,k̸=j EkjWk
⎤
⎥⎥⎥⎦
Ξ43j
=
⎡
⎣
−γ2
j Ij
Φt
j
ϱkΓt
jWk
•
−Ij
0
•
•
−ϱkWk
⎤
⎦
(8.29)
and
Ξ5j
=
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
εjPjBjMoj
Ct
jN t
oj
0
0
0
0
Ct
djN t
oj
0
0
0
0
0
0
0
0
0
0
0
0
0
εjDjMoj
0
ϕjDjMoj
0
εjϱjWjBjMoj
0
ϕjϱjWjBjMoj
0
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
Ξ6j
=
⎡
⎢⎢⎣
−εjIj
0
0
0
•
−εjIj
0
0
•
•
−ϕjIj
0
•
•
•
−ϕjIj
⎤
⎥⎥⎦
Ξ6j
=
⎡
⎢⎢⎣
−εjIj
0
0
0
•
−εjIj
0
0
•
•
−ϕjIj
0
•
•
•
−ϕjIj
⎤
⎥⎥⎦
(8.30)
The main decentralized resilient feedback design results are established by the
following theorem.

372
Chapter 8. Decentralized Resilient Control
Theorem 8.3.4 Given the bounds ϱj > 0, μj > 0 and matrix Wj, j =
1, ..., ns, the interconnected system (8.1) with decentralized resilient controller
(8.19) is delay-dependent asymptotically stable with L2-performance bound γj
if there exist weighting matrices Xj, Gj, Rj, {Λkj}ns
k=1, {Ψrj}7
1, and scalar
γj > 0, εj > 0 satisfying the following LMI:
 Ξ7j
Ξ8j
•
Ξ6j

< 0
(8.31)
CjXj = GjCj
(8.32)
where
Ξ7j
=
 Ξ71j
Ξ72j
•
Ξ73j

Ξ71j
=
⎡
⎢⎢⎣
Πoj
Πaj
−ϱjΨ1j
0
•
−Πmj
−ϱjΨ3j
0
•
•
−ϱjΨ4j
0
•
•
•
−Πnj
⎤
⎥⎥⎦
Ξ72j
=
⎡
⎢⎢⎣
Γj
XjGt
j + Ψ5j
ϱk(XjAt
j + Ct
jRt
jBt
j)Wk
0
XjGt
dj + Ψ6j
ϱk(XjAt
dj + Ψ7j)Wk
0
0
0
0
0
ϱk
ns
k=1,k̸=j XjEkjWk
⎤
⎥⎥⎦
Ξ73j
=
⎡
⎣
−γ2
j Ij
Φt
j
ϱkΓt
jWk
•
−Ij
0
•
•
−ϱkWk
⎤
⎦
Ξ8j
=
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
εjBjMoj
XjCt
jN t
oj
0
0
0
0
Ct
djN t
oj
0
0
0
0
0
0
0
0
0
0
0
0
0
εjDjMoj
0
ϕjDjMoj
0
εjϱjWjBjMoj
0
ϕjϱjWjBjMoj
0
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
(8.33)
Πoj
=
[Aj +
ns

k=1,k̸=j
Fkj]Xj + BjRjCj + Xj[Aj
+
ns

k=1,k̸=j
Fkj]t + Ct
jRt
jBt
j
+
Ψ1j + Ψt
1j + Ψ2j +
ns

k=1,k̸=j
Λkj + (ns −1)Xj

8.3. Resilient Decentralized Stabilization
373
Πaj
=
AdjXj −Ψ1j + Ψt
3j, Πmj = Ψ3j + Ψt
3j + (1 −μj)Ψ2j,
Πzj
=
DjsYj
Πnj
=
ns

k=1,k̸=j
(1 −μkj)Λkj +
ns

k=1,k̸=j
EkjXjEt
kjPkEkjXj
(8.34)
Moreover, the local gain matrix is given by Koj = RjG−1
j .
Proof: Introduce the relation CjXj = GjCj and let KojGj = Rj. Applying the
congruent transformation diag[Xj, Xj, Xj, Xj, Ij, Ij, Ij, Ij, Ij], Xj =
P−1
j
to LMI (8.31) with Schur complements and using the linearizations
Ψ1j
=
XjΘjXj, Ψ2j = XjQjXj, Ψ3j = XjΥjXj, Ωj = αjXjF t
j,
Λkj
=
XjZkjXj, Ψ7j = XjCt
djKt
ojBt
j,
Ψ4j
=
XjWjXj, Ψ5j = XjCt
jKt
ojDt
j, Ψ6j = XjCt
djKt
ojDt
j
we readily obtain LMI (8.33) by Schur complements.
We note that the presence of matrix equality in (8.32) renders the compu-
tations of (8.31)-(8.33) using MATLAB R⃝-LMI Toolbox or similar LMI solver
rather costly. Therefore one is encouraged to convert (8.31)-(8.32) into true
LMIs. With this in mind, we recall that the use of singular value decomposition
(SVD) can express the output matrix Cj in the form
Cj
=
Uj [Λpj,
0] Vt
j
(8.35)
where Uj ∈ℜpj×pj, Vj ∈ℜnj×nj
are unitary matrices and Λpi ∈ℜpj×pj
is a diagonal matrix with positive diagonal elements in decreasing order. The
conversion to LMIs can now be accomplished by the following theorem [258].
Theorem 8.3.5 Given a matrix Cj ∈ℜpj×nj, rank[Cj] = pj and let 0 <
Xj = X t
j ∈ℜnj×nj. Then there exists a matrix 0 < Gj ∈ℜpj×pj such that
CjXj = GjCj
(8.36)
if and only if
Xj = Vj
Xju
0
•
Xjv

Vt
j, Xiu ∈ℜpj×pj, Xiv ∈ℜ(nj−pj)×(nj−pj) (8.37)
It is signiﬁcant to observe that Theorem 8.3.5 substitutes the matrix equation
(8.32) by structural selection of the matrix variable Xj. Incorporating this result
into Theorem 8.3.5, we have thus established the following design result.

374
Chapter 8. Decentralized Resilient Control
Theorem 8.3.6 Given the bounds ϱj > 0, μj > 0 and matrix Wj, the inter-
connected system (8.1) with decentralized resilient controller (8.19) with output
matrix Cj having the SVD form (8.35) is delay-dependent asymptotically stable
with L2-performance bound γj if there exist weighting matrices
Xj, Gj, Rj, {Λkj}ns
k=1, {Ψrj}7
1
and scalars εj > 0, ϕj > 0 satisfying the following LMI:
 Ξ7j
Ξ8j
•
Ξ6j

< 0
(8.38)
where Ξ7j, Ξ8j, Πoj, Πaj, Πnj, Πmj, Πcj are given by (8.34). Moreover,
the local gain matrix is given by Koj = RjUjΛpjX −1
ju Λ−1
pj U−1
j
.
Remark 8.3.7 Similarly, the optimal performance-level γj, j = 1, .., ns can
be determined in case of decentralized resilient static output-feedback stabi-
lization by solving the following convex optimization problems:
Problem B: Resilient static output feedback stabilization
For j, k = 1, ..., ns,
Given ϱj, μj, ϱjk, μjk,
min
Xj, Yj, Mj, Ωj, {Λrj}ns
r=1, {Ψrj}4
1
γj
subject to
LMI(8.38)
(8.39)
Finally, we deal with the dynamic output feedback case.
8.3.3
Resilient dynamic output feedback
Consider the resilient dynamic output feedback control
˙ˆxj(t)
=
Ajˆxj(t) + Bjuj(t) + [Koj + ΔKoj(t)][yj(t) −Cjˆxj(t)]
uj(t)
=
[Kcj + ΔKcj(t)]ˆxj(t),
(8.40)
ΔKoj(t)
=
MojΔj(t)Noj, ΔKcj(t) = McjΔj(t)Ncj,
Δt
j(t)Δj(t) ≤I,
∀t
(8.41)
where ΔKoj(t), ΔKcj(t) represent additive observer-gain and controller-gain
perturbations with Moj, Noj, Mcj, Ncj being constant matrices. Applying the
dynamic controller (8.40) to the linear system (8.1), we obtain the closed-loop

8.3. Resilient Decentralized Stabilization
375
system and associated matrices
ej(t)
=
 xt
j(t)
xt
j(t) −ˆxt
j(t) t
(8.42)
˙ej(t)
=
[Aj + ΔAj]ej(t) + [Adj + ΔAdj]ej(t −τj(t)) + ˆcj(t) + ˆΓjwj(t)
zj(t)
=
[ ˆGj + Δ ˆGj]ej(t) + ˆGdje(t −τj(t)) + Φjwj(t)
cj(t)
=
ns

k=1
ˆFjkek(t) +
ns

k=1
ˆEjkek(t −ηjk(t))
(8.43)
where
Aj
=
 Aj + BjKcj
−BjKcj
0
Aj −KojCj

, ΔAdj =

0
0
−ΔKojCdj
0

,
Adj
=
 Adj
0
0
Adj −KojCdj

, ΔAj =
 BjΔKcj
−BjΔKcj
0
−ΔKojCj

,
ˆGj
=

Gj + DjKcj
−DjKcj

, ˆGdj =

Gdj
0

,
ˆcj(t)
=
 cj(t)
cj(t)

, ˆΓj =
 Γj
Γj

, ˆFjk =
 Fjk
0
Fjk
0

,
ˆEjk
=
 Ejk
0
Ejk
0

,
Δ ˆGj
=

DjΔKcj(t)
−DjΔKcj(t)

(8.44)
Then it follows from Theorem 8.2.1 that the resulting closed-loop system (8.6)
is delay-dependent asymptotically stable with L2-performance bound γ if there
exist matrices &Pj, &Qj, '
Wj, &
Zkj, k = 1, ..ns, parameter matrices &Θj &Υj, and
a scalar γj > 0 satisfying the following LMI:
)
&Ξs1j
&Ξs2j
•
&Ξs3j
*
< 0
(8.45)

376
Chapter 8. Decentralized Resilient Control
with
&Ξs1j
=
⎡
⎢⎢⎢⎣
&Ξoj
&Ξaj
−ϱj &Θj
0
•
−&Ξmj
−ϱj &Υj
0
•
•
−ϱj '
Wj
0
•
•
•
−&Ξnj
⎤
⎥⎥⎥⎦
&Ξs2j
=
⎡
⎢⎢⎢⎣
&Pj ˆΓj
ˆGt
j + Δ ˆGt
j
ϱk[Aj + ΔAj]t '
Wk
0
ˆGt
dj
ϱk[Adj + ΔAdj]t '
Wk
0
0
0
0
0
ϱk
ns
k=1,k̸=j ˆEkj '
Wk
⎤
⎥⎥⎥⎦< 0
&Ξs3j
=
⎡
⎢⎣
−γ2
j Ij
Φt
j
ϱkˆΓt
j '
Wk
•
−Ij
0
•
•
−ϱk '
Wk
⎤
⎥⎦< 0
(8.46)
where
&Ξoj
=
&Pj[Aj + ΔAj +
ns

k=1
ˆFkj] + [Aj + ΔAj +
ns

k=1
ˆFkj]t &Pj
+
&Θj + &Θt
j + &Qj +
ns

k=1,k̸=j
&
Zkj + (ns −1) &Pj
=
Ξoj + &PjΔAj + ΔAt
j &Pj
&Ξmj
=
&Υj + &Υt
j + (1 −μj) &
Qj,
&Ξnj
=
ns

k=1
(1 −μkj) &
Zkj +
ns

k=1
ˆEt
kj &Pj ˆEkj,
&Ξaj
=
&Pj[Adj + ΔAdj] −&Θj + &Υt
j = Ξaj + &PjΔAdj
(8.47)
along with the following block matrices:
&Pj
=
 Pcj
0
•
Poj

, &Qj =
 Qcj
0
•
Qoj

,
'
Wj
=
 Wcj
0
•
Woj

, &
Zjk =
 Zcjk
0
•
Zojk

,
&Θj
=
 Θcj
0
•
Θoj

, &Υj =
 Υcj
0
•
Υoj

(8.48)

8.3. Resilient Decentralized Stabilization
377
Manipulating LMI (8.45) using (8.47)-(8.48), it yields
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
Ξoj
Ξaj
−ϱj &Θj
&Ξcj
&PjˆΓj
ˆGt
j
ϱkAt
j '
Wk
•
−&Ξmj
−ϱj &Υj
0
0
ˆGt
dj
ϱkAt
dj '
Wk
•
•
−ϱj '
Wj
0
0
0
0
•
•
•
−&Ξnj
0
0
ϱk
ns
k=1,k̸=j ˆEkj '
Wk
•
•
•
•
−γ2
j Ij
Φt
j
ϱkˆΓt
j '
Wk
•
•
•
•
•
−Ij
0
•
•
•
•
•
•
−ϱk '
Wk
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
+
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
Haj
0
0
0
0
DjMcj
Hcj
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
Δj
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
Hoj
0
0
0
0
0
Oj
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
t
+
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
Hoj
0
0
0
0
0
Oj
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
Δt
j
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
Haj
0
0
0
0
DjMcj
Hwj
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
t
+
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
Hsj
0
0
0
0
DjMcj
Hwj
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
Δj
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
Hvj
0
0
0
0
0
Oj
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
t
+
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
Hvj
0
0
0
0
0
Oj
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
Δt
j
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
Hsj
0
0
0
0
DjMcj
Hwj
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
t
+
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
−Hsj
0
0
0
0
0
−Hwj
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
Δj
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
Hej
0
0
0
0
0
Oj
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
t
+
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
Hej
0
0
0
0
0
Oj
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
Δt
j
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
−Hsj
0
0
0
0
0
−Hwj
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
t
< 0
(8.49)

378
Chapter 8. Decentralized Resilient Control
Applying Inequality 1 of the Appendix to LMI (8.49), it becomes
≤
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
Ξoj
Ξaj
−ϱj &Θj
&Ξcj
&Pj ˆΓj
ˆGt
j
ϱkAt
j '
Wk
•
−&Ξmj
−ϱj &Υj
0
0
ˆGt
dj
ϱkAt
dj '
Wk
•
•
−ϱj '
Wj
0
0
0
0
•
•
•
−&Ξnj
0
0
ϱk
ns
k=1,k̸=j ˆEkj '
Wk
•
•
•
•
−γ2
j Ij
Φt
j
ϱkˆΓt
j '
Wk
•
•
•
•
•
−Ij
0
•
•
•
•
•
•
−ϱk '
Wk
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
+εj
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
Haj
0
0
0
0
DjMcj
Hcj
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
Haj
0
0
0
0
DjMcj
Hcj
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
t
+ ε−1
j
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
Hoj
0
0
0
0
0
Oj
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
Hoj
0
0
0
0
0
Oj
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
t
+ϕj
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
Hsj
0
0
0
0
DjMcj
Hwj
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
Hsj
0
0
0
0
DjMcj
Hwj
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
t
+ ϕ−1
j
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
Hvj
0
0
0
0
0
Oj
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
Hvj
0
0
0
0
0
Oj
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
t
+ψj
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
−Hsj
0
0
0
0
DjMcj
−Hwj
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
−Hsj
0
0
0
0
DjMcj
−Hwj
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
t
+ ψ−1
j
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
Hej
0
0
0
0
0
Oj
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
Hej
0
0
0
0
0
Oj
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
t
< 0
(8.50)
where
Haj
=
 PcjBjMcj
0

, Hoj =

N t
cj
−N t
cj

, Hcj =
 ϱjWcjBjMcj
0

,
Hsj
=

0
PojMoj

, Hej =
 Ct
djN t
oj
0

, Oj =
 0
0

,
Hvj
=
 Ct
djN t
oj
0

, Hwj =

0
ϱjWojMoj

(8.51)

8.3. Resilient Decentralized Stabilization
379
for some εj > 0, ϕj > 0, ψj > 0. Inequality (8.50) with the help of Schur
complements can be written as
 Ξ1j
Ξ2j
•
&Ξ3j

< 0
(8.52)
where
Ξ1j =
⎡
⎢⎢⎢⎣
Ξoj
Ξaj
−ϱj &Θj
0
•
−&Ξmj
−ϱj &Υj
0
•
•
−ϱj '
Wj
0
•
•
•
−&Ξnj
⎤
⎥⎥⎥⎦,
Ξ2j =
⎡
⎢⎢⎢⎣
&PjˆΓj
ˆGt
j
ϱkAt
j '
Wk
Ξsj
0
ˆGt
dj
ϱkAt
dj '
Wk
0
0
0
0
0
0
0
ϱj
ns
k=1,k̸=j ˆEkj '
Wk
0
⎤
⎥⎥⎥⎦,
Ξ3j =
⎡
⎢⎢⎢⎣
−γ2
j Ij
Φt
j
ϱkˆΓt
j '
Wk
0
•
−Ij
0
0
•
•
−ϱk '
Wk
0
•
•
•
−Ξvj
⎤
⎥⎥⎥⎦
(8.53)
and
Ξsj =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
εjHaj
Hoj
ϕjHsj
Hvj
−ψjHsj
Hej
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
εjDjMcj
0
ϕjDjMcj
0
ψjDjMcj
0
εjHcj
Oj
ϕjHwj
Oj
−ψjHwj
Oj
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
Ξvj = Blockdiag

εjIj
εjIj
ϕjIj
ϕjIj
ψjIj
ψjIj

(8.54)
Our immediate task is to determine the observer and controller gain matrices
Koj, Kcj and we do this by convexiﬁcation of inequality (8.52). The main de-
centralized resilient feedback design results are summarized by the following
theorems.
Theorem 8.3.8 Given the bounds ϱj
>
0,
μj
>
0 and matrices
Wcj,
Woj, the interconnected system (8.1) with decentralized resilient
observer-based controller (8.40) is delay-dependent asymptotically stable

380
Chapter 8. Decentralized Resilient Control
with L2-performance bound γj if there exist positive-deﬁnite matrices
Xcj, Xoj, Ycj, Yoj, Ymj, Yvj, Ywj, {Λkj1}ns
k=1, {Λkj1}ns
k=1, {Ψrsj}4
r=1,
s = 1, 2, and scalars εj > 0, ϕj > 0, ψj > 0 satisfying the following LMIs
for j = 1, ..., ns:
 (Ξd1j
(Ξd2j
•
Ξvj

< 0
(8.55)
(Ξd1j
=
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
(Πoj
(Πaj
−ϱj (Ψ1j
(Πcj
ˆΓj
(Πt
zj
ϱj (Πt
vj
•
−(Πmj
−ϱj (Ψ3j
0
0
ˆGt
dj
ϱj (Πt
wj
•
•
−ϱj (Ψ4j
0
0
0
0
•
•
•
−(Πnj
0
0
ϱj (Πt
sj
•
•
•
•
−γ2
j Ij
Φt
j
ϱj (Πt
rj
•
•
•
•
•
−Ij
0
•
•
•
•
•
•
−ϱj 4
Wj
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
(Πd2j
=
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
εj (Haj
(Hoj
ϕj (Hsj
(Hvj
−ψj (Hsj
(Hej
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
εjDjMcj
0
ϕjDjMcj
0
ψjDjMcj
0
εj (Hcj
Oj
ϕj (Hwj
Oj
−ψj (Hwj
Oj
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
(8.56)
where
(Πoj
=
)
(Πo1j
(Πo2j
•
(Πo3j
*
,
(Πaj
=
 AdjXcj −Ψ11j + Ψt
31j
0
•
AdjXoj −Yvj −Ψ12j + Ψt
32j

(Πo1j
=
[Aj +
ns

k=1,k̸=j
Fkj]Xcj + BjYcj + Xcj[Aj +
ns

k=1,k̸=j
Fkj]t + Yt
cjBt
j
+
Ψ11j + Ψt
11j + Ψ21j +
ns

k=1,k̸=j
Λkj1 + (ns −1)Xcj
(Πo2j
=
−Ymj + Xcj
ns

k=1,k̸=j
F t
kj, (Πzj = [GjXcj + Yj
−Ywj]

8.3. Resilient Decentralized Stabilization
381
(Πo3j
=
AjXoj + Yoj + XojAt
j + Yt
oj + Ψ12j + Ψt
12j + Ψ22j
+
ns

k=1,k̸=j
Λkj2 + (ns −1)Xoj
(Πmj
=
)
Ψ31j + Ψt
31j + (1 −μj)Ψ21j
0
•
Ψ32j + (Ψt
32j + (1 −μj)Ψ22j
*
(Πnj
=
Blockdiag[(Πn1j
(Πn2j],
(Πn1j
=
ns

k=1,k̸=j
(1 −μkj)Λkj1 +
ns

k=1,k̸=j
XcjEt
kjPcjEkjXcj,
(Πn2j
=
ns

k=1,k̸=j
(1 −μkj)Λkj2 +
ns

k=1,k̸=j
XojEt
kjPojEkjXoj,
(Ψ1j
=
Ψ11j
0
•
Ψ12j

, (Ψ2j =
Ψ21j
0
•
Ψ22j

, (Ψ3j =
Ψ31j
0
•
Ψ32j

,
&Λkj
=
 Λkj1
0
•
Λkj2

, (Ψ4j =
 Ψ41j
0
•
Ψ42j

(Πt
vj
=
 (XcjAt
j + Yt
cjBt
j)Wcj
0
−Yt
mjWcj
(XojAt
j −Yt
oj)Woj

,
(Πt
rj
=
[Γt
jWcj
Γt
jWoj], (Hej =
 XcjCt
djN t
oj
0

(Πt
wj
=
 XcjAt
djWcj
0
0
XojAt
dj −Yt
vj)Woj

(Haj
=
 BjMcj
0

, (Hoj =

XcjN t
cj
−XojN t
cj

,
(Hcj
=
 ϱjWcjBjMcj
0

, (Hsj =

0
Moj

,
(Hvj
=
 XcjCt
djN t
oj
0

, (Hwj =

0
ϱjWojMoj

,
(Πt
sj
=
 Xcj
ns
k=1 Et
kjWcj
0
Xoj
ns
k=1 Et
kjWcj
0

(8.57)
Moreover, the local gain matrix is given by Kcj
= YcjX −1
cj ,
Koj
=
YojX −1
oj C†
j.
Proof: Applying the congruent transformation
Blockdiag[ &
Xj, &
Xj, &
Xj, &
Xj, Ij, Ij, Tj], &
Xj = &P−1
j

382
Chapter 8. Decentralized Resilient Control
with
&
Xj = diag[Xcj
Xoj], Tj = diag[Ij, Ij, Ij, Ij, Ij, Ij ]
to LMI (8.52) with (8.54) Schur complements and using the linearizations
Ycj
=
KcjXcj, Yoj = KojCjXoj, Ymj = BjKcjXoj,
(Ψ1j
=
&
Xj &Θj &
Xj =
 Ψ11j
0
•
Ψ12j

, (Ψ2j = &
Xj &Qj &
Xj =
 Ψ21j
0
•
Ψ22j

,
(Ψ3j
=
&
Xj &Υj &
Xj =
 Ψ31j
0
•
Ψ32j

, &Λkj = &
Xj &
Zkj &
Xj =
 Λkj1
0
•
Λkj2

,
Yvj
=
KojCdjXoj, Ywj = DjKcjXoj
we readily obtain LMI (8.56) with (8.57) by Schur complements.
Remark 8.3.9 The optimal performance-level γj, j = 1, .., ns can be deter-
mined in case of decentralized resilient dynamic output feedback stabilization
by solving the following convex optimization problems:
Problem C: Resilient dynamic output feedback stabilization
For j, k = 1, ..., ns,
Given ϱj, μj, ϱjk, μjk,
min
Xj, Yj, Mj, Ωj, {Λrj}ns
r=1, {Ψrj}4
1
γj
subject to
LMI (8.56) with (8.57)
(8.58)
Remark 8.3.10 It is important to note that the methodology developed in this
chapter established robust decentralized criteria for delay-dependent stabil-
ity by deploying an injection procedure and resilient feedback stabilization
schemes applicable to a class of linear interconnected continuous time-delay
systems. These criteria are LMI-based to handle local subsystems that are sub-
jected to convex-bounded parametric uncertainties and additive feedback gain
perturbations while allowing time-varying delays to occur within the local sub-
systems and across the interconnections. Our control design offers efﬁcient
decentralized control structures and possesses superior robustness properties
with respect to both parametric uncertainties and gain perturbations. Note also
in the nominal case (without parametric uncertainties and gain perturbations)
and for delay-free systems, our results are an improved version of [105, 174].
This in turn enhances the utility and effectiveness of our approach.

8.3. Resilient Decentralized Stabilization
383
8.3.4
Illustrative example 8.1
Consider an interconnected system composed of three subsystems; each is of
the type (8.1) with the following coefﬁcients:
Subsystem 1 :
A1 =
 −2
0
−2
−1

, Γ1 =
 0.2
0.2

, G1 =

0.2
0.1

,
Ad1 =
 −1
0
−1
0

, Gd1 =

−0.1
0

, Φ1 = 0.5
Couplings 1 :
E12 =
 1
0
1
0

, E13 =
 0
−1
0
−1

, F12 =
 0.2
−0.1
0
0.2

,
F13 =

0
−0.4
0.1
−0.5

Subsystem 2 :
A2 =
 −1
0
−1
−4

, Γ2 =
 0.1
0.3

, G2 =

0.2
0.1

,
Ad2 =

1
0
−2
−1

, Gd2 =

0.1
0

, Φ2 = 0.2
Couplings 2 :
E21 =
 −1
−2
3
6

, E23 =
 −1
1
3
−2

, F21 =

0
−0.5
0.8
−0.5

,
F23 =
 −0.7
0.6
0
−0.2

Subsystem 3 :
A3 =

0
1
−1
−2

, Γ3 =
 0.1
0.5

, G3 =

0.1
−0.1

,
Ad3 =
 0
0
0
−1

, Gd3 =

−0.1
0

, Φ3 = 0.1
Couplings 3 :
E31 =
 1
2
1
2

, E32 =
 0
0
0
−1

, F31 =
 0.7
0
0
0.8

,
F32 =
 0
0
0
−1


384
Chapter 8. Decentralized Resilient Control
Considering Theorem 8.2.1, it is found that the feasible solution is attained at
Subsystem 1 :
ϱ1 = 3, μ1 = 1.5, ϱ21 = 2, μ21 = 0.8, ϱ31 = 2, μ31 = 0.8,
γ1 = 2.2817
P1 =
 2.0612
0.0023
•
0.0322

, Q1 =
 14.1238
−1.3752
•
19.5388

Subsystem 2 :
ϱ2 = 2.5, μ2 = 1.3, ϱ12 = 1.5, μ12 = 0.9, ϱ32 = 1.5, μ32 = 0.9,
γ2 = 0.9958
P2 =
 0.1706
−0.0281
•
0.0817

, Q2 =
 5.8316
0.4328
•
5.4059

Subsystem 3 :
ϱ3 = 3, μ3 = 1.1, ϱ13 = 1.8, μ13 = 0.75, ϱ23 = 1.8, μ23 = 0.75,
γ3 = 1.0142
P3 =
 0.5784
0.0662
•
0.1153

, Q3 =
 16.7851
−0.5316
•
7.2042

Since Pj, Qj, > 0, j = 1, 2, 3 then the conditions required by Theorem 8.2.1
are satisﬁed.
8.3.5
Illustrative example 8.2
Consider the interconnected system of Example 8.2 with the additional coefﬁ-
cients
B1 =
 1
2

, B2 =

1
1
−1
2

, B3 =
 2
1

, D1 = [0.1],
D2 = [0.2
0.4], D3 = [0.3]
Considering Problem A, it is found that the feasible solution is attained at
γ1 = 3.9292, K1 =

1.2551
−2.3786

, γ3 = 7.0397,
K3 =

−0.0540
1.0240

,
γ2 = 13.1742, K2 =
 −12.9437
2.0436
−9.4414
−8.0502


8.3. Resilient Decentralized Stabilization
385
8.3.6
Illustrative example 8.3
Consider the interconnected system of Example 8.1 with the additional coefﬁ-
cients
C1 = [0.2
0], C2 = [0.6
0.4], C3 = [0.5
0]
Considering Problem B, it is found that the feasible solution is attained at
γ1
=
18.8905, K1 = 5.9245, γ3 = 37.0898, K3 = 0.8416,
γ2
=
22.7111, K2 =
 −0.5448
1.6161

8.3.7
Illustrative example 8.4
Consider the interconnected system of Example 8.1 with the additional coefﬁ-
cients
C2 =
 0.6
0.4
0.1
0

, G2 =
 0.2
0.1
0
0

, Gd2 =
 0.1
0
0
0

,
Cd2 =
 0.6
0.3
0.2
0

, D2 =
 0.2
0.4
0.1
0.2

Considering Problem C, it is found that the feasible solution is attained at
γ1 = 13.3086, Kc1 =

0.9070
−0.0722

, Ko1 =
 8.8571
7.8083

,
γ3 = 6.9512, Kc3 =

0.0270
0.4458

, Ko3 =
 −1.4133
1.6144

,
γ2 = 3.2553, Kc2 =
0.1575
−1.1567
0.2612
1.1867

, Ko2 =
0.2890
−8.9054
9.9524
54.4992

The closed-loop state trajectories under the action of state feedback, static out-
put feedback, and dynamic output feedback, which correspond to solutions of
Problems B, C, and D, respectively, are depicted in Figures 8.2 through 8.4.
From the plotted graphs, it is quite clear that all of the generated feedback
controls guarantee regulation to the zero level. In addition, the dynamic out-
put feedback control yields smoother trajectories in comparison to the other
feedback controls. This is generally expected since the dynamic output feed-
back control employs more degrees of freedom. In order to demonstrate the
effectiveness of the developed decentralized control strategies, the closed-loop
state trajectories under the action of regular (without gain perturbations) and

386
Chapter 8. Decentralized Resilient Control
0
5
10
15
20
25
30
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
Time (sec)
States of subsystem I
 
 
x1(t)
x2(t)
Figure 8.2: State trajectories of state feedback control
0
5
10
15
20
25
30
−0.5
0
0.5
1
1.5
2
Time (sec)
States of subsystem III
 
 
x1(t)
x2(t)
Figure 8.3: State trajectories of static output feedback control
resilient (with gain perturbations) state feedback controls are depicted in Fig-
ures 8.5 though 8.10. From the plotted graphs, it is quite clear that all of the
generated feedback controls guarantee regulation to the zero level. The effect
of resilience is signiﬁcant in the initial period before settling to the desired
level. This enhances the need of resilient control in decentralized systems to
accommodate the possible gain perturbations.

8.4. Resilient Overlapping Control
387
0
5
10
15
20
25
30
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
Time (sec)
States of subsystem II
 
 
x1(t)
x2(t)
Figure 8.4: State trajectories of dynamic output feedback control
0
5
10
15
20
25
30
−1
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
Time (sec)
x11 with and without gain perturbations
 
 
with gain perturbations
without gain perturbations
Figure 8.5: Trajectories of x11 with regular and resilient control
8.4
Resilient Overlapping Control
Standard assumption on designed controllers is that they can be implemented
exactly into real world systems. In practice, control laws designed using theo-
retical methods and simulations are implemented imprecisely because of var-
ious reasons such as ﬁnite word length in any digital system, round-off errors
in the imprecision inherent in analog systems, or the need for additional tuning
of parameters in the ﬁnal controller implementation. The controller designed

388
Chapter 8. Decentralized Resilient Control
0
5
10
15
20
25
30
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
Time (sec)
x12 with and without gain perturbations
 
 
with gain perturbations
without gain perturbations
Figure 8.6: Trajectories of x12 with regular and resilient control
0
5
10
15
20
25
30
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
Time (sec)
x21 with and without gain perturbations
 
 
with gain perturbations
without gain perturbations
Figure 8.7: Trajectories of x21 with regular and resilient control
for uncertain plants may be sufﬁciently robust against system parameters, but
the controller parameters themselves may be sensitive to relatively small per-
turbations and could even destabilize a closed-loop system. The importance of
fragility, i.e., high sensitivity of controller parameters on its very small changes,
is underlined when considering large-scale complex systems controlled by low
cost local controllers. Such control systems are generally characterized by un-
certainties, information structure constraints, delays, and high dimensionality.
This situation naturally motivates the development of new effective control de-

8.4. Resilient Overlapping Control
389
0
5
10
15
20
25
30
−1
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
Time (sec)
x22 with and without gain perturbations
 
 
with gain perturbations
without gain perturbations
Figure 8.8: Trajectories of x22 with regular and resilient control
0
5
10
15
20
25
30
−2.5
−2
−1.5
−1
−0.5
0
0.5
1
1.5
2
Time (sec)
x31 with and without gain perturbations
 
 
with gain perturbations
without gain perturbations
Figure 8.9: Trajectories of x31 with regular and resilient control
sign methods taking into account particular features of these systems including
implementation aspects of controller parameter uncertainties.
In this section, the expansion-contraction relations, developed earlier
within the inclusion principle, are applied for a class of continuous-time state-
delayed uncertain systems when considering H∞state memoryless control
with additive controller uncertainty. All uncertainties are supposed to be time-
varying norm bounded. The main contribution is the derivation of conditions
under which a resilient H∞control law designed in the expanded space is

390
Chapter 8. Decentralized Resilient Control
0
5
10
15
20
25
30
−1
−0.5
0
0.5
1
1.5
2
2.5
3
Time (sec)
x32 with and without gain perturbations
 
 
with gain perturbations
without gain perturbations
Figure 8.10: Trajectories of x32 with regular and resilient control
contracted into the initial system preserving simultaneously both the robust
quadratic stability of closed-loop systems and the value of the H∞-norm dis-
turbance attenuation bound. An LMI delay-independent procedure is supplied
for control design. The results are specialized into the overlapping decentral-
ized control setting which enables to construct robust H∞resilient block tridi-
agonal state feedback controllers.
8.4.1
Feedback problem formulation
Consider a class of linear interconnected continuous-time uncertain time-delay
(UTD) systems where the jth subsystem is described by
Sj : ˙xj(t)
=
[Aj + ΔAj(t)]xj(t) + [Bj + ΔBj(t)]uj(t)
+
[Adj + ΔAdj(t)]xj(t −dj) +
ns

k=1,k̸=j
Zjkxk(t) + Γjwj(t),
xj(t0)
=
φj(t0), −dj ≤t0 ≤0
(8.59)
zj(t)
=
Cxj(t) + Duj(t)
(8.60)
where for subsystem j , xj(t) ∈ℜnj is the state, uj(t) ∈ℜmj is the control
input, dj > 0 is the delay factor, wj(t) ∈Lp
2[0, ∞) is the disturbance in-
put, zj(t) ∈ℜq
j is the controlled output, and φj(t0) is a given continuous initial
function. The term ns
k=1,k̸=j Zjkxk(t) represents a static-type coupling among
subsystems which implies the coupling transfer is faster than the isolated sub-
system dynamics. The matrices Aj, Bj, Adj, Γj, Cj, Dj are known real

8.4. Resilient Overlapping Control
391
constant of appropriate dimensions and ΔAj(t), ΔBj(t), ΔAdj(t) are real-
valued matrices of time-varying, norm-bounded uncertain parameters of the
form
ΔAj(t)
=
HAjFj(t)EAj,
ΔAdj(t) = HdjFj(t)Edj,
ΔBj(t)
=
HBjFj(t)EBj
(8.61)
where HAj, Hdj, HBj, EAj, EBj, Edj are known real constant matri-
ces of appropriate dimensions and Fj(t) ∈ℜsj×rj are unknown real time-
varying matrices with Lebesgue measurable elements satisfying the condition
F t
j (t)Fj(t) ≤Ij. From now onward, we let
¯Aj(t)
=
Aj + ΔAj(t),
¯Bj(t) = Bj + ΔBj(t),
¯Adj(t)
=
Adj + ΔAdj(t)
(8.62)
System (8.60) can be expressed into the form
Sj : ˙xj(t)
=
¯Aj(t)x(t) + ¯Bj(t)uj(t) + ¯Adj(t)x(t −dj)
+
ns

k=1,k̸=j
Zjkxk(t) + Γjwj(t),
zj(t)
=
Cjxj(t) + Djuj(t),
(8.63)
xj(t0)
=
φj(t0), −dj ≤t0 ≤0
From (8.60)-(8.64), the interconnected system is described by
S : ˙x(t)
=
¯A(t)x(t) + ¯B(t)u(t) + ¯Ad(t)x(t −d) + Γw(t),
z(t)
=
Cx(t) + Du(t)
(8.64)
where
x
=

x1
x2
· · ·
xns

, u =

u1
u2
· · ·
uns

,
¯B
=
Blockdiag{ ¯B1, ..., ¯Bns}, ¯Ad(t) = Blockdiag{ ¯Ad1, ..., ¯Adns},
¯C(t)
=
Blockdiag{C1, ..., Cns}, ¯D = Blockdiag{D1, ..., Dns},
¯A(t)
=
⎡
⎢⎢⎢⎣
¯A1
Z12
· · ·
Z1ns
Z21
¯A2
· · ·
Z2ns
...
...
...
...
Zns1
Zns2
· · ·
¯Ans
⎤
⎥⎥⎥⎦
(8.65)
Now, consider a local resilient state feedback controller in the form
uj(t) = [Kj + ΔKj(t)]xj(t) = ¯Kj(t)xj(t)
(8.66)

392
Chapter 8. Decentralized Resilient Control
for system (8.60), where Kj ∈ℜmj×nj. The gain matrix perturbation ΔKj(t)
satisﬁes
ΔKj(t) = HkjFkj(t)Ekj
(8.67)
where F t
kj(t)Fkj(t) ≤Ij with Fkj ∈ℜsj×rj being an unknown real time-
varying matrix with Lebesgue measurable elements. Hkj, Ekj are known con-
stant matrices of appropriate dimensions. The overall resilient state feedback
controller takes the form
u(t)
=
[K + ΔK(t)]x(t) = ¯K(t)x(t)
(8.68)
¯K
=
Blockdiag[ ¯K1, ..., ¯Kns], K = Blockdiag[K1, ..., Kns],
ΔK
=
Blockdiag[ΔK1, ..., ΔKns]
Applying controller (8.68) to system (8.60), we get the resulting overall closed-
loop system in the form
Sc :
˙x(t)
=
[A + AK + HBF(t)EBK + HAF(t)EA + BHkFk(t)Ek
+
HBF(t)EBHkFk(t)Ek]x(t) +
ns

k=1,k̸=j
Zjkxk(t −hjk)
+
[Ad + HdF(t)Ed]x(t −d) + Z(t)x(t −h) + Γw(t)
=
Ap(t)x(t) + Aq(t)x(t −d) + Z(t)x(t −h) + Γw(t),
z(t)
=
[C + DK + DHkFk(t)Ek]x(t)
(8.69)
where
HA = {HAj}, HB = {HBj}, Hk = {Hkj}, Hd = {Hdj},
EA = {EAj}, Ek = {Ekj}, EB = {EBj}, Ed = {Edj}
are the block-structure of matrices in (8.61) and (8.67). Now to examine the ro-
bust stability, we consider the overall Lyapunov-Krasovskii functional (LKF):
V (x, t) = xt(t)Px(t) +
 t
t−d
xt(σ)[I + Et
dEd]x(σ)dσ
(8.70)
where P = {Pj}, Pj ∈ℜnj×nj, (I + Et
dEd) ∈ℜn×n are positive-deﬁnite
symmetric matrices. The following results can derived using arguments from
basic time-delay theory [255].
Lemma 8.4.1 System (8.60) with u(t) = 0, w(t) = 0 is robustly quadratically
stable if there exist matrices 0 < Pt = P such that the family of inequality
PA + AtP + P(HAHt
A + HdHt
d + AdAt
d)P +
PZP + Et
AEA + Et
dEdj + I
(8.71)
for all admissible uncertainties (8.61).

8.4. Resilient Overlapping Control
393
Lemma 8.4.2 System (8.60) is robustly quadratically stabilizable if there exist
a matrix 0 < P t = P and a gain matrix K given by (8.68) such that
P(A + BK) + (A + BK)tP + εKtEt
BEBK +
P(HAHt
A + HdHt
d + (1 + 1
ε)HBHt
B + AdAt
d + BHkHt
kBt)P +
Et
AEA + Et
dEd + (1 + α)Et
kEK + I < 0
(8.72)
where α = ∥Ht
kEt
BEBHK∥for all ε > 0 and all admissible uncertainties
(8.61) and (8.67).
To extend these results further, we introduce the following deﬁnitions.
Deﬁnition 8.4.3 Given system (8.60) and a scalar γ > 0. This system is ro-
bustly quadratically stable with H∞-norm bound γ if it is robustly quadrat-
ically stable in light of Lemma 8.4.1 and under zero initial conditions
||z(t)||2 ≤γ||w(t)||2 holds for any w(t) ̸= 0 and for all admissible uncer-
tainties (8.61).
Deﬁnition 8.4.4 Given system (8.60) and a scalar γ > 0. This system is ro-
bustly quadratically stabilizable with H∞-norm bound γ if there exist a matrix
0 < P t = P and a gain matrix K given by (8.68) such that
P(A + BK) + (A + BK)tP
+
P(HAHt
A + HdHt
d + AdAt
d + γ−2ΓΓt)P
+
εKtEt
BEBK +

1 + 1
ϱ

(C + DK)t(C + DK)
(8.73)
+
(1 + ϱ)σEt
kEk + Et
AEA + Et
dEd + (1 + α)Et
kEK + I < 0
hold for all admissible uncertainties (8.61) and (8.67), where σ
=
∥Ht
kDtDHk∥.
8.4.2
LMI control design
Since the delay factor is considered constant in the present formulation, the
best we hope for is a delay-independent procedure [255]. It is included as an
effective control design tool.
Theorem 8.4.5 Consider the linear UTD system (8.60) and constant γ > 0. If
for some positive real values ε, ϱ, there exist matrices Q and Y satisfying the

394
Chapter 8. Decentralized Resilient Control
following LMI,
⎡
⎢⎢⎢⎢⎢⎣
Π
QΦt
QEt
k
YtEt
B
Ψt
•
−I
0
0
0
•
•
−[σ−1
1+ϱ]I
0
0
•
•
•
−[1
ε]I
0
•
•
•
•
−[
ϱ
1+ϱ]I
⎤
⎥⎥⎥⎥⎥⎦
< 0
(8.74)
where
Π
=
AQ + QAt + BY + YtQt
+
HAHt
A + HdHt
d + AdAt
d + γ−2ΓΓt,
Φt
=
[Et
A
Et
d
(1 + σ)1/2Et
k
I]
(8.75)
Ψt
=
QQCt + YtDt
then there exists a memoryless state feedback controller (8.68) such that the
resulting closed-loop system (8.69) is robustly quadratically stable with H∞-
norm bound γ. Moreover, the gain matrix K is given by K = YQ−1.
8.4.3
Application of the inclusion principle
We now proceed to apply the inclusion principle discussed in Chapter 5. We
consider a new larger-dimension system, similar to system (8.60), in the form
˜S : ˙˜x(t)
=
[˜A + Δ˜A(t)]˜x(t) + [˜B + Δ˜B(t)]u(t)
+
[˜Ad + Δ˜Ad(t)]˜x(t −d) + ˜Γw(t),
(8.76)
˜z(t)
=
˜C˜x(t) + Au(t),
(8.77)
˜x(t0)
=
˜φ(t0), −d ≤t0 ≤0
where ˜x(t) ∈ℜ˜n is the state, u(t) ∈ℜm is the control input, d > 0 is the delay
time, w(t) ∈Lp
2[0, ∞) is the disturbance input, ˜z(t) ∈Rq is the controlled
output and ˜φ(t0) is a continuous initial function. According to the inclusion
principle, we consider n ≤˜n, q ≤˜q. The conditions (8.61) and the notation
(8.62) for system S are analogous for system ˜S, while considering now all
matrices with tilde (∼). The corresponding resilient state feedback controller
for the system ˜S is given by
u(t) = [˜K + Δ˜K(t)]˜x(t)
(8.78)
where ˜K ∈ℜm×˜n. The uncertain gain matrix Δ˜K(t) satisﬁes
Δ˜K(t) = ˜Hk ˜Fk(t) ˜Ek
(8.79)

8.4. Resilient Overlapping Control
395
where ˜F t
k(t) ˜Fk(t) ≤I, ˜Fk ∈ℜs×r is an unknown real time-varying matrix
with Lebesgue measurable elements and ˜Hk, ˜Ek are known constant matrices
of appropriate dimensions.
The performance measure of the expanded system ˜S is now assessed by
∥˜z(t)∥2 ≤˜γ∥w(t)∥2
(8.80)
provided that the corresponding expanded closed-loop system is robustly
quadratically stable with zero initial condition.
Now let x(t) = x(t; φ(t0), u(t), w(t)), ˜x(t) = ˜x(t; ˜φ(t0), u(t), w(t)) be
the solutions of (8.60) and (8.77) for initial functions φ(t0) and ˜φ(t0), given
inputs u(t) and disturbance inputs w(t), respectively. Applying the standard
relations of the inclusion principle, it means that the systems S and ˜S are re-
lated by the following linear transformations:
˜x(t) = Vx(t),
x(t) = U˜x(t)
(8.81)
where V and its pseudo-inverse matrix U = (VtV)−1Vt are constant full-rank
matrices of appropriate dimensions [324]. Therefore, the following deﬁnitions
are recalled.
Deﬁnition 8.4.6 A system ˜S includes the system S, denoted by ˜S ⊃S, if there
exists a pair of constant matrices (U, V) such that UV = In, and for any initial
function φ(t0), any ﬁxed input u(t) and any disturbance input w(t) of S, it
follows that
x(t; φ(t0), u(t), w(t)) = U ˜x(t; V φ(t0), u(t), w(t)), ∀t
Deﬁnition 8.4.7 A pair ( ˜S, ˜γ) is an expansion of (S, γ), denoted by ( ˜S, ˜γ) ⊃
(S, γ), if ˜S ⊃S and γ = ˜γ.
Deﬁnition 8.4.8 A controller u(t) = [˜K + ΔK(t)]˜x(t) for ˜S is contractible to
u(t) = [K + ΔK(t)]x(t) for S if the choice ˜φ(t0) = Vφ(t0) implies
[K + ΔK(t)]x(t; φ(t0), u(t), w(t)) = [˜K + Δ˜K(t)]˜x(t; Vφ(t0), u(t), w(t))
for all t, any initial function φ(t0), any ﬁxed input u(t), and any disturbance
input w(t) of S.
Remark 8.4.9 As we learned from Chapter 6, the inclusion principle can be
used for the analysis and control design of different classes of dynamic systems
with different objectives. In general, a dynamic system is expanded to obtain

396
Chapter 8. Decentralized Resilient Control
another larger dimension system containing all information about the initial
system. Then, the controller design is usually performed for the expanded sys-
tem and consequently contracted into the original system. This approach is
quite effective mainly when considering decentralized controller design for the
expanded system without shared parts. In the sequel, we consider that the gain
matrix ˜K appearing in the controller u(t) = [˜K + Δ˜K(t)]˜x(t) is not the ex-
panded gain matrix of K but a ”free” matrix designed for the system ˜S with
given ˜γ.
Suppose we are given a pair of matrices (U,
V). Then, the matrices
˜A, Δ˜A(t), ΔB, Δ˜B(t), ˜Ad, Δ˜Ad(t), ˜Γ and ˜C can be described as follows:
˜A = VAU + M,
Δ˜A(t)
=
VΔA(t)U,
˜B = VB + N,
Δ˜B(t)
=
VΔB(t),
˜Ad = VAdU + Md,
Δ˜Ad(t)
=
VΔAd(t)U,
(8.82)
˜Γ = VΓ + R,
˜C
=
CU + L
(8.83)
where M, N, Md, R, and L are called complementary matrices. The transfor-
mations (U, V) can be selected a priori to deﬁne structural relations between
the state variables in both systems S and ˜S. The choice of the complementary
matrices then provides degrees of freedom to obtain different expanded spaces
with desirable properties [15, 16].
For system (8.60) with positive numbers γ, ˜γ, consider an expanded sys-
tem ˜S described by (8.77) via the relations (8.83) such that ˜S ⊃S holds. The
immediate objective is to derive conditions under which ( ˜SC, ˜γ) ⊃(SC, γ) us-
ing robust quadratic stability with H∞-norm bound γ. At this stage, we recall
that the necessity of overlapping structure is dictated by structural constraints
on the system and there is no principal need to expand also the controlled out-
put. Thus, we can put z(t) = ˜z(t) without any restriction. The same applies to
the disturbance input. As a result, we can introduce the equality on the H∞-
norm bound γ,
that is, γ = ˜γ. Additionally, some conditions on the com-
plementary matrices (8.83) must be imposed on ( ˜S, ˜γ) to be an expansion of
(S, γ) as per Deﬁnition 8.4.7. This is summarized by the following theorem,
the proof of which can be derived following [17].
Theorem 8.4.10 Consider the systems (8.60) and (8.77) with (8.80). A pair
( ˜S, ˜γ) includes the pair (S, γ) if and only if
U˜Φ(t, 0)V
=
Φ(t, 0),
UΦ(t, s)MdV = 0,
U˜Φ(t, s)N
=
0,
UΦ(t, s)R = 0,
(8.84)
LV
=
0

8.4. Resilient Overlapping Control
397
hold for all t and s.
Remark 8.4.11 It is signiﬁcant to note that obtaining an explicit solution of a
time-varying system is a difﬁcult problem. Therefore, effort should be focused
on conditions under which ( ˜S, ˜γ) ⊃(S, γ) holds but without any necessity to
compute the transition matrices.
Equivalent conditions to those of Theorem 8.4.10 expressed in terms of com-
plementary matrices are provided by the following theorem.
Theorem 8.4.12 Consider the systems (8.60) and (8.77) with (8.80). A pair
( ˜S, ˜γ) includes the pair (S, γ) if and only if
UMjV
=
0,
UMj−1MdV = 0,
UMj−1N
=
0,
UMj−1R = 0,
(8.85)
LV
=
0
hold for all k = 1, 2, ..., ˜n.
Proof 8.4.13 Consider the transition matrix Φ(t, 0) of ˜¯A. Following the nota-
tion given in (3), ˜¯A = ˜A + Δ˜A(t) represents the state matrix of the expanded
space ˜S as a function of two variables deﬁned by the Peano-Baker series [17]:
Φ(t, 0) = I
+
 t
0
˜¯A(σ1)dσ1 +
 t
0
˜¯A(σ1)
 σ1
0
˜¯A(σ2)dσ2dσ1
+
 t
0
˜¯A(σ1)
 σ1
0
˜¯A(σ2)
 σ2
0
˜¯A(σ3)dσ3dσ2dσ + ...... (8.86)
In the light of (8.83),
˜¯A(σi)
=
˜A + Δ˜A(σi),
=
VAU + M + VΔA(σj)U,
∀j = 1, 2, ...
From Theorem 8.4.10, pre- and postmultiplying both sides of ˜Φ(t, 0) by A
and A, respectively, we can prove that U˜Φ(t, 0)V = Φ(t, 0) is equivalent to
UMjV = 0 for j = 1, 2, ..., ˜n. In a similar way, U˜Φ(t, s)MdV = 0 is equiv-
alent to UMj−1MdV = 0 for j = 1, 2, ..., ˜n. The condition U˜Φ(t, s)N = 0 is
equivalent to UMj−1N = 0 and U˜Φ(t, s)R = 0 is equivalent to UMj−1R = 0,
for all j = 1, 2, ..., ˜n. The requirement LV = 0 can be obtained by imposing
γ∗= ˜γ, which completes the proof.

398
Chapter 8. Decentralized Resilient Control
It is evident that Theorem 8.4.12 paves the way to derive expanded systems
satisfying the inclusion principle with the same H∞performance attenuation
bound γ without an exact knowledge of transition matrices. The following
corollary stands out.
Corollary 8.4.14 Consider the systems (8.60) and (8.77) with (8.80). A pair
( ˜S, ˜γ) includes the pair (S, γ) if LV = 0 and
MV
=
0,
MdV = 0,
N = 0,
R = 0 or
UM
=
0,
UMd = 0,
UN = 0,
UR = 0
(8.87)
Remark 8.4.15 If Md = 0, R = 0 in (8.87), then 8.87 corresponds to partic-
ular cases within the inclusion principle called restrictions and aggregations,
respectively [324].
Recall that Deﬁnition 8.4.8 provides the conditions under which a control law
designed in the expanded system ˜S can be contracted and implemented into the
initial system S.These requirements, however, do not guarantee that the closed-
loop system ˜Sc includes the closed-loop system Sc in the sense of the inclusion
principle, that is, ˜Sc ⊃Sc. Now consider conditions which include also H∞
performance attenuation bounds γ. The ensuing results are presented by the
following theorem using complementary matrices.
Theorem 8.4.16 Consider the systems (8.60) and (8.77) with (8.80) such that
˜S ⊃S. Suppose that u(t) = [˜K + Δ˜K(t)]˜x(t) is a contractible control law
designed in ˜S. If MV = 0, MdV = 0, N = 0, R = 0, and LV = 0, then
( ˜Sc, ˜γ) ⊃(Sc, γ).
Proof 8.4.17 Suppose ˜Sc ⊃Sc and consider the resilient control u(t) = [˜K +
Δ˜K(t)]˜x(t) a contractible law designed in ˜S. The corresponding closed-loop
expanded system is given as follows:
˜Sc: ˙˜x(t)
=
[˜A + ˜A˜A + Δ˜A(t) + ΔA(t)˜A + ˜AΔA(t)
+
Δ˜A(t)Δ˜A(t)]˜x(t) + [˜Ad + Δ˜Ad(t)]˜x(t −d)
+
˜Γw(t)
(8.88)
=
˜Ap(t)˜x(t) + ˜Aq(t)˜x(t −d) + ˜Γw(t),
˜z(t)
=
[˜A + A[˜A + Δ˜A(t)]]˜x(t)
It follows from Deﬁnition 8.4.8 that the contracted state feedback controller
u(t) = [K + ΔK(t)]x(t) has the form u(t) = [˜K + Δ˜K(t)]Vx(t). Consider

8.4. Resilient Overlapping Control
399
the relation between the state matrices of the closed-loop systems SC and ˜SC
given in (8.69) and (8.88), respectively. It follows that
˜Ap(t)
=
VAp(t)U + Mp =⇒
Mp
=
M + N[˜K + Δ˜K(t)] + VB[ ˜K + Δ ˜K(t)] −VB[ ˜K + Δ ˜K(t)]VU
+
VΔB(t)[˜K + Δ˜K(t)](I −VU)
where Mp is a complementary matrix, will be determined shortly. Since we
seek ˜S ⊃SC, the condition UMj
pV = 0,
j = 1, 2, ..., ˜n, must be sat-
isﬁed. Imposing this condition and using (8.83), it can be established that
MV = 0, N = 0 is a sufﬁcient condition so that UMj
pV = 0 holds for
all j = 1, 2, ..., ˜n. Similarly, the relation ˜Aq(t) = VAq(t)U + AMq implies
Mq = Md. In order to verify the inclusion principle, we impose UMd
jV = 0
MdV = 0 to reach that MdV = 0 is a sufﬁcient condition to satisfy for all
j = 1, 2, ..., ˜n. The condition U[˜Γw(t)] = Γw(t) is equivalent to UR = 0 in
terms of complementary matrices and consequently R = 0 is a sufﬁcient con-
dition. Finally, LV = 0 is the same requirement as given in Theorem 8.4.12
when imposing γ = ˜γ.
The particular case 1) satisﬁes Theorem 8.4.16 under which ( ˜Sc, ˜γ) ⊃
(Sc, γ). Suppose that a controller u(t) = [˜K + Δ˜K(t)]˜x(t) designed in the
expanded system ˜S satisﬁes the inequality in Deﬁnition 8.4.4. This implies
that the robust quadratic stability with H∞-norm bound γ is guaranteed for the
closed-loop system (8.88). Note that the controller design is performed with a
given ˜γ.
It is necessary to establish whether the condition ˜γ = γ is satisﬁed for
the closed-loop system (8.69) with the contracted controller u(t) = [K +
ΔK(t)]x(t) implemented into the initial system S. This condition is provided
by the following theorem.
Theorem 8.4.18 Consider the systems (8.60) and (8.77) with (8.80). Suppose
that
MV = 0,
MdV = 0,
N = 0,
R = 0,
LV = 0
hold. Also, suppose that there exist a matrix 0 < ˜Pt = ˜P and a gain matrix ˜K
such that the inequality
˜P(˜A + ˜B˜K) + (˜A + ˜B˜K)t˜P +
˜P(V[HAHt
A + HdHt
d + AdAt
d]U + γ−2˜Γ˜Γt)˜P +
ε˜Kt ˜Et
B ˜EB ˜K +

1 + 1
ϱ

(˜C + ˜D˜K)t(˜C + ˜D˜K) +
˜σ(1 + ϱ)(Et
kEk + Et
AEA + Et
dEd + (1 + α)Et
kEK + I) < 0
(8.89)

400
Chapter 8. Decentralized Resilient Control
holds for ε > 0,
ϱ > 0 and all admissible uncertainties, where ˜σ =
∥˜Ht
kDtD ˜Hk∥. Then, there exist a positive-deﬁnite symmetric matrix P =
Vt˜PV and a gain matrix K = ˜KV such that the robust stability with H∞per-
formance attenuation bound γ is guaranteed for closed-loop system (8.69).
Moreover, γ = ˜γ.
Proof 8.4.19 Consider u(t) = [˜K + Δ˜K(t)]˜x(t) a contractible controller de-
signed for the system ˜S. Suppose the gain matrix ˜K together with a matrix
0 < ˜Pt = ˜P satisfying (8.89). Using (8.83) into (8.89), then inequality (8.89)
implies inequality (8.73) by Deﬁnition 8.4.4 when matrix 0 < Pt = P in the
form P = Vt˜PV, EB = ˜EB, Ek = ˜EkV and Hk = ˜HkV. Hence, the ro-
bust quadratic stability with H∞-norm bound γ is guaranteed for closed-loop
system (8.69) using the contracted controller u(t) = [K + ΔK(t)]x(t)x(t) =
[˜K + Δ˜K(t)]Vx(t) and consequently γ = ˜γ.
8.4.4
Overlapping state feedback
Information structure constraints on the state feedback gain matrices include
different practically important structures corresponding with the sparsity forms
of gain matrices well known in the theory of sparse matrices. These particu-
lar forms are a block diagonal form, a block tridiagonal form, and a double-
bordered block diagonal form corresponding with decentralized, overlapping,
and gain matrices, respectively. Generally, their control design may be effec-
tively performed using LMI approach [329].
To demonstrate this approach, consider two overlapping subsystems with
the structure of matrices A, ΔA(t), Ad, ΔAd(t) and B, ΔB(t), Γ, respec-
tively, in the form:
⎡
⎣
∗
∗
∗
∗
∗
∗
∗
∗
∗
⎤
⎦,
⎡
⎢⎢⎣
∗
...
∗
∗
...
∗
∗
...
∗
⎤
⎥⎥⎦
(8.90)
where Ajj,
ΔAjj(t),
AdA,
ΔAdjj(t) ∈ℜnj×nj for j = 1, 2, 3, and
Bjk, ΔBij(t) ∈ℜnj×mj, Γjk ∈ℜnj×pj for j = 1, 2, 3. The dimensions of the
components of the vector xt(t) = [xt
1(t), xt
2(t), xt
3(t)] are n1, n2, n3, respec-
tively, and satisfy n1 +n2 +n3 = n. The partition of ut(t) = [ut
1(t), ut
2(t)] has
two components of dimensions m1, m2 such that m1 + m2 = m. A standard

8.4. Resilient Overlapping Control
401
particular selection of the matrix V is selected as follows:
⎡
⎢⎢⎣
In1
0
0
0
In2
0
0
In2
0
0
0
In3
⎤
⎥⎥⎦
(8.91)
As it has been shown before, this transformation leads naturally to an ex-
panded system where the state vector x2 appears repeated in ˜xt(t)
=
[xt
1(t), xt
2(t), xt
2(t), xt
3(t)]. The expanded controller has a block diagonal form
with two subblocks of dimensions m1 × (n1 + n2) and m2 × (n2 + n3) as
follows:
˜Kd =
˜K11
˜K12
0
0
0
0
˜K23
˜K24

(8.92)
The corresponding contracted gain matrix has a block tridiagonal form as fol-
lows:
Ktd =
˜K11
˜K12
0
0
˜K23
˜K24

(8.93)
The design of overlapping controllers depends on the structure of matrices B,
ΔB(t). As has been demonstrated in [352], Type I corresponds with all nonzero
elements of all input matrices in (8.90), while Type II corresponds with all
elements −(∗)21 = 0 and (∗)22 = 0. The LMI control design for Type I can be
performed directly on the original system. Type II requires performing the LMI
control design in the expanded space because the direct design usually leads to
infeasibility [329].
To simplify the control design for the Type II case, we denote Ptd a block-
tridiagonal matrix with the dimensions of its blocks corresponding with the
dimensions of overlapping subsystems. To proceed, we introduce the follow-
ing.
Deﬁnition 8.4.20 Consider the system (8.60). The controller utdx(t)
=
[Ktd + ΔKtd(t)]x(t) with block-tridiagonal matrices Ktd and ΔKtd(t) is a
tridiagonal-resilient H∞state feedback controller if there exist a matrix 0 <
Pt
td = Ptd and a gain matrix Ktd such that the inequality
Ptd(A + BKtd) + (A + BKtd)tPtd +
Ptd(HAHt
A + HdHt
d + (1 + 1
ε)HBHt
B + AdAt
d + BHkHt
kBt
+γ−2ΓΓt)Ptd +
εKt
tdEt
BEBKtd + (1 + 1
ϱ)(C + DKtd)t(C + DKtd) +
(1 + ϱ)σEt
kEk + Et
AEA + Et
dEd + (1 + σ)Et
kEK + I < 0 (8.94)

402
Chapter 8. Decentralized Resilient Control
holds for all admissible uncertainties (8.61) and (8.67), where σ
=
∥Ht
kDtDHk∥.
The robust quadratic stability with H∞-norm bound γ of the closed-loop sys-
tem (8.69) is guaranteed. The following result can be easily established as a
particular case of Theorem 8.4.18:
Theorem 8.4.21 Consider systems (8.60) and (8.77). Suppose that
MV
=
0,
MdV = 0,
N = 0,
LV
=
0,
R = 0
(8.95)
holds. Consider the subsystem structure (8.90) and the transformation matrix
(8.91). If there exist a matrix ˜PD > 0 and a gain matrix ˜KD satisfying (8.89),
then
utdx(t) = [Ktd + ΔKtd(t)]x(t) = [˜KD + ΔKD(t)]Vx(t)
is a tridiagonal-resilient H∞state feedback controller with the matrix Ptd =
Vt˜PDV > 0 for the system S satisfying γ = ˜γ.
8.4.5
Illustrative example 8.5
Consider the interconnected system with the numerical coefﬁcients
A
=
⎡
⎢⎢⎣
−2
0
−1
1
−1
0
2
0
0
−2
−1
0
1
0
0
−1
⎤
⎥⎥⎦, B =
⎡
⎢⎢⎣
0.5
0
0.3
0.4
0
0.4
0
0.1
⎤
⎥⎥⎦,
Ad
=
⎡
⎢⎢⎣
−0.2
0
0
0
0
0.2
0.1
0
0
0.1
0
0
0
0
0
0.2
⎤
⎥⎥⎦, Γ =
⎡
⎢⎢⎣
0.3
0.2
0.4
0.3
0.2
0.2
0.1
0
⎤
⎥⎥⎦,
C
=
⎡
⎣
0.1
0
0
0
0
0.1
−0.1
0
0
0
0
0.1
⎤
⎦, HA =
⎡
⎢⎢⎣
0.2
0
0.4
0
0.2
0.1
0.1
0
⎤
⎥⎥⎦,

8.4. Resilient Overlapping Control
403
Ht
B
=
⎡
⎢⎢⎣
0.1
0
0
0.1
0.2
0
0.1
0.1
⎤
⎥⎥⎦, Ht
d =
⎡
⎢⎢⎣
0
0.2
0
0.4
0.1
0.2
0
0.2
⎤
⎥⎥⎦,
EA
=
 0.1
0
0.1
0
0
0
0
0.1

, EB =
 0.1
0.1
0
0.1

,
Ed
=
 0
0.1
0
0
0
0.1
0
0.1

The overlapped subsystems are
A22
=

0
2
−2
1

, C22 =

0.1
−0.1

in the matrices A and C, respectively. The remaining overlapped subsystems
corresponding to the matrices ΔA(t) A1 and ΔA1(t) are also 2×2 dimensional
blocks. Following [352], the transformation matrices are taken as
V
=
⎡
⎢⎢⎢⎢⎢⎢⎣
1
0
0
0
0
1
0
0
0
0
1
0
0
1
0
0
0
0
1
0
0
0
0
1
⎤
⎥⎥⎥⎥⎥⎥⎦
,
M =
⎡
⎢⎢⎣
1
0
0
0
1
0
0
1
0
0
0
1
⎤
⎥⎥⎦
We select N = 0, Md = 0, R = 0 and evaluate the remaining complementary
matrices as
M
=
⎡
⎢⎢⎢⎢⎢⎢⎣
0
0
−0.5
0
0.5
0
0
0
1
0
−1
0
0
−10
−0.5
1
0.5
0
0
0
−1
0
1
0
0
1
0.5
−1
−0.5
0
0
0
0
0
0
0
⎤
⎥⎥⎥⎥⎥⎥⎦
,
L
=
⎡
⎢⎢⎣
0
0
0
0
0
0
0
0.05
−0.05
−0.05
0.05
0
0
−0.05
0.05
0.05
−0.05
0
0
0
0
0
0
0
⎤
⎥⎥⎦

404
Chapter 8. Decentralized Resilient Control
which satisfy the required relations (8.95). Application of Theorem 8.4.21
yields the contracted and centralized gain matrices which are
KD
=
 −0.7356
−0.6244
0
0
0.1198
0.4763

,
KC
=
 −4.8886
−2.2419
−1.3895
4.8957
0.8587
−1.1244

8.5
Resilient Stabilization for Discrete Systems
Power systems, transportation systems, manufacturing processes, communica-
tion networks, and economic systems are some of the examples of large-scale
interconnected systems [224]. Conventional centralized control methodology
of such systems requires means of exchanging information between the sub-
systems for the controller implementation, and, therefore, sufﬁciently large
communication bandwidth is needed for transferring information between the
subsystems. This makes centralized controllers when applied to large-scale in-
terconnected systems impractical and uneconomical. In addition, often, there
are no means for subsystem information exchange, which prevents the appli-
cation of centralized control. To overcome this, decentralized control method-
ology has been developed, which only uses local information available at each
subsystem level for the controller implementation. In this way, multiple sepa-
rate controllers are articulated each of which has access to different measured
information and has authority over different decision or actuation variables.
Hence, in real applications, decentralized controllers are simpler and more
practical than centralized controllers. An exhaustive list of publications on the
subject of decentralized control of large-scale interconnected systems is given
in [57, 324]. A survey of early results can be found in [194].
Decentralized feedback control (DFC) of large-scale systems has received
considerable interest in the systems and control literature. It effectively exploits
the information structure constraint commonly existing in many practical large-
scale systems. Over the past few decades, a large body of literature has become
available on this subject; see [82]-[406] and the references therein. The com-
putational advantages of DFC the approach have also recently attracted consid-
erable attention, particularly in the context of parallel processing.
Decentralized robust controller design in the presence of uncertainties can
be found in [88, 248]. Most of the proposed decentralized control strategies as-
sume that subsystem states are available for feedback implementation (see, for
example, [327, 396, 400]). However, in real applications, the availability of the
states of each subsystem cannot be guaranteed. This motivated the development

8.5. Resilient Stabilization for Discrete Systems
405
of decentralized output feedback controllers, which incorporate local observers
to estimate the states of the subsystems (see, for example, [346, 406]). In re-
cent years, a new systematic methodology has been proposed in [348] based
on linear matrix inequalities (LMIs) [29] and extended to continuous-time in-
terconnected systems in [327, 348, 398] and to time-delay systems in [28]. The
appealing feature of these results is that the underlying problem is formulated
as a convex optimization problem, which is designed to maximize the system
robustness with respect to uncertainties.
In this section, we consider the stabilization problem of a class of large-
scale interconnected discrete-time systems with unknown nonlinear intercon-
nections and gain perturbations. The interconnection of each subsystem sat-
isﬁes a quadratic constraint bound as, for example, in [28] and extending the
results of [289, 348]. We develop a resilient control scheme1 to cope with the
gain perturbations. The main objective is to develop an LMI-based method for
testing robust stability and designing robust feedback schemes for decentral-
ized stabilization of interconnected systems. Our contribution is to extend the
work in [28, 348] further and generalize their results in different ways. First,
we deal with systems composed of linear discrete-time subsystems coupled by
static nonlinear interconnections satisfying quadratic constraints. The devel-
oped solution is cast into the framework of convex optimization problems over
LMIs. Second, we develop robust asymptotic stability and feedback stabiliza-
tion results. Output feedback controllers are designed on the subsystem level
to guarantee robust stability of the overall system and, in addition, maximize
the bounds of unknown interconnection terms. Third, by incorporating additive
gain perturbations we establish new resilient feedback stabilization schemes
for discrete-time delay systems. To illustrate the application of the developed
schemes we include a numerical example of three interconnected time-delay
systems and provide detailed results of implementation.
8.5.1
Problem statement
We consider a class of nonlinear interconnected discrete-time systems Σ com-
posed of N coupled subsystems Σj, j = 1, .., N and represented by:
Σ :
x(k + 1)
=
Ax(k) + Bu(k) + g(k, x(k))
y(k)
=
Cx(k)
(8.96)
where for k ∈Z+ := {0, 1, ...} and x = (xt
1, ..., xt
N)t
∈ℜn,
n =
N
j=1 nj, u = (ut
1, ..., ut
N)t
∈ℜp, p = N
j=1 pj, y = (yt
1, ..., yt
N)t
∈
1Throughout the chapter, we use the term “resilient” as introduced in [258] corresponding to
“non-fragile” used in [60, 70].

406
Chapter 8. Decentralized Resilient Control
ℜq, q = N
j=1 qj being the state, control, and output vectors of the intercon-
nected system Σ. The associated matrices are real constants and modeled as
A = diag{A1, .., AN}, Aj ∈ℜnj×nj, B = diag{Γ, .., BN }, Bj ∈ℜnj×pj,
C = diag{C1, .., CN},
Cj
∈ℜqj×nj. The function g : Z+ × ℜn ×
ℜn →ℜnj, g(k, x(k)) = (gt
1(k, x(k)), .., gt
N (k, x(k)))t is a vector func-
tion piecewise-continuous in its arguments. In the sequel, we assume that this
function is uncertain and the available information is that, in the domains of
continuity G, it satisﬁes the quadratic inequality
gt(k, x(k))g(k, x(k)) ≤xt(k) (Gt(Φ−1 (Gx(k)
(8.97)
where (G = [ (Gt
1, .., (Gt
N]t,
(Gj ∈ℜrj×nj
are constant matrices such that
gj(k, 0, 0) = 0 and x = 0 is an equilibrium of system (8.96).
Exploiting the structural form of system (8.96), a model of the jth subsys-
tem Σj can be described by
Σj :
xj(k + 1)
=
Ajxj(k) + Bjuj(k) + gj(k, x(k))
yj(k)
=
Cjxj(k)
(8.98)
where xj(k) ∈ℜnj, uj(k) ∈ℜpj, and yj(k) ∈ℜqj are the subsystem state,
control input, and measured output, respectively. The function gj : Z+ × ℜn ×
ℜn →ℜnj is a piecewise-continuous vector function in its arguments and in
line of (8.97) it satisﬁes the quadratic inequality
gt
j(k, x(k)) gj(k, x(k)) ≤φ2
j xt(k) (Gt
j (Gjx(k)
(8.99)
where φj
>
0 are bounding parameters such that (Φ = diag{φ−2
1 Ir1, ..,
φ−2
N IrN } where Imj represents the mj × mj identity matrix. From (8.97) and
(8.99), it is always possible to ﬁnd matrices Φ such that
gt(k, x(k))g(k, x(k))
≤
xt(k)GtΦ−1Gx(k)
(8.100)
where G = diag{G1, .., GN}, Φ = diag{δ1Ir1, .., δNIrN }, and δj = φ−2
j .
Our aim in this chapter is to develop new tools for the analysis and design
of a class of interconnected discrete-time systems with uncertain function of
nonlinear perturbations by exploiting the decentralized information structure
constraint. We seek to establish complete LMI-based procedures for the robust
stability and feedback (output, resilient) stabilization by basing all the compu-
tations at the subsystem level.

8.5. Resilient Stabilization for Discrete Systems
407
8.5.2
Subsystem stability
Our goal is to establish tractable conditions guaranteeing global asymptotic
stability of the origin (x = 0) for all g(k, x(k)) ∈G. The main result of
subsystem stability is established by the following theorem.
Theorem 8.5.1 System (8.96) with u ≡0 is asymptotically stable for all non-
linear uncertainties satisfying (8.97) if there exist matrices 0 < Yt
j = Yj ∈
ℜnj×nj and scalars δj > 0 such that the following convex optimization prob-
lem is feasible:
min
Yj,δj
N

j=1
δj
subject to : Y1 > 0, ..., YN > 0,
diag

Γ1, ..., ΓN

< 0,
Γj =
⎡
⎢⎢⎣
−Yj
YjAt
j
YjAt
j
YjGt
j
•
Ij −Yj
0
0
•
•
−Yj
0
•
•
•
−δjIj
⎤
⎥⎥⎦
(8.101)
Proof: Introduce the Lyapunov functional (LF):
V (k) =
N

j=1
Vj(k) =
N

j=1

xt
j(k)Pjxj(k)

(8.102)
where 0 < Pt
j = Pj ∈ℜnj×nj are weighting matrices for j = 1, .., N. A
straightforward computation gives the ﬁrst-difference of ΔV (k) = V (k+1)−
V (k) along the solutions of (8.96) with uj(k) ≡0, j = 1, .., N as:
ΔV (k)
=
N

j=1
[Ajxj(k) + gj]tPj[Ajxj(k) + gj] −
N

j=1
xt
j(k)Pjxj(k)
=
ξt(k) Ξ ξ(k)
(8.103)
where
Ξj
=
diag(Ξ1, ..., ΞN), Ξj =
 At
jPjAj −Pj
At
jPj
•
Pj

,
ξ(k)
=
[ξt
1(k), ..., ξt
N (k)]t,
ξt
j(k) =
 xt
j(k)
gt
j(k, x(k)) 
(8.104)

408
Chapter 8. Decentralized Resilient Control
Recalling that (8.99) can be conveniently written as
ξt diag
  −φ2
1 Gt
1G1
0
•
I1

, ...,
 −φ2
N Gt
NGN
0
•
IN
 
ξ
≤0
(8.105)
Then the sufﬁcient condition of stability ΔV (k) < 0 implies that Ξ < 0. By
resorting to the S-procedure, inequalities (8.103) and (8.105) can be rewritten
together as
P1 > 0, ..., PN > 0, ω1 ≥0, ..., ωN ≥0,
diag

Π1, ..., ΠN

< 0,
Πj
=
 At
jPjAj −Pj + ωjφ2
jGt
jGj
At
jPj
•
Pj −ωjIj

(8.106)
which describes nonstrict LMIs since ωj ≥0. Recall from [29] that mini-
mization under nonstrict LMIs corresponds to the same result as minimization
under strict LMIs when both strict and nonstrict LMI constraints are feasible.
Moreover, if there is a solution for (8.106) for ωj = 0, there will be also a so-
lution for some ωj > 0 and sufﬁciently small φj. Therefore, we safely replace
ωj ≥0 by ωj > 0. Equivalently, we may further rewrite (8.106) in the form
¯P1 > 0, ..., ¯PN > 0,
diag

¯Π1, ..., ¯ΠN

< 0,
¯Πj
=
 At
j ¯PjAj −¯Pj + φ2
jGt
jGj
At
j ¯Pj
•
¯Pj −Ij

(8.107)
where ¯Pj = ω−1
j
Pj. Using the change of variable Yj = ¯P−1
j
with δj = φ−2
j ,
multiplying by ωj, then pre- and postmultiplying by ¯Pj with some arrange-
ment, we express (8.107) using Schur complements in the form (8.101). Ro-
bust stability of the nonlinear interconnected system (8.96) under the constraint
(8.97) with maximal φj is thus established.
Remark 8.5.2 Note that for all possible nonlinear perturbations g(k, 0) = 0,
the origin x = 0 is an equilibrium of system (8.96) and therefore in the light
of [348], the overall asymptotic stable is guaranteed. It is signiﬁcant to ob-
serve that Theorem 8.5.1 yields a block-diagonal structure and provides an

8.5. Resilient Stabilization for Discrete Systems
409
LMI-based characterization of the overall system stability in terms of the lo-
cal subsystem asymptotic stability. In implementation, the local LMI problems
could be solved in parallel since they virtually decoupled and the overall min-
imal solution is attained by minimizing the sum of the local tolerances
In what follows, we consider the decentralized feedback stabilization for in-
terconnected system (8.96) within LMI-based formulation. We will be looking
for a feedback controller that robustly stabilizes Σ. The main trust is to guaran-
tee that local closed-loop subsystems are asymptotically stable for all possible
nonlinear interconnections satisfying (8.99). In this way, the local controllers
stabilize the linear part of Σ and, at the same time, maximize its tolerance to
uncertain nonlinear interconnections and perturbations.
8.5.3
State feedback design
Now we examine the application of a linear local feedback controller of the
form
uj(k) = Kj xj(k)
(8.108)
to system (8.96), where Kj ∈ℜpj×nj is a constant gain matrix. Substituting
(8.108) into (8.98) yields:
Σs :
xj(k + 1)
=
[Aj + BjKj]xj(k) + gj(k, x(k))
=
Ajsxj(k) + gj(k, x(k))
(8.109)
yj(k)
=
Cjx(k)
(8.110)
A direct application of Theorem 8.5.1 leads to the following optimization
problem:
min
Yj,δj
N

j=1
δj
subject to : Y1 > 0, ..., YN > 0,
diag

Γ1s, ..., ΓNs

< 0,
Γjs =
⎡
⎢⎢⎣
−Yj
YjAt
js
YjAt
js
YjGt
j
•
Ij −Yj
0
0
•
•
−Yj
0
•
•
•
−δjIj
⎤
⎥⎥⎦
(8.111)
To put inequality (8.111) in a proper LMI setting, we need to separate the lo-
cal gain from the local Lyapunov matrix. This is achieved by introducing the

410
Chapter 8. Decentralized Resilient Control
variable KjYj = Mj. This in turn gives the following convex minimization
problem over LMIs for:
min
Yj,δj
N

j=1
δj
subject to : Y1 > 0, ..., YN > 0,
Blockdiag

Γ1s, ..., ΓNs

< 0,
Γjs =
⎡
⎢⎢⎣
−Yj
YjAt
j + MjBt
j
YjAt
j + MjBt
j
YjGt
j
•
Ij −Yj
0
0
•
•
−Yj
0
•
•
•
−δjIj
⎤
⎥⎥⎦
(8.112)
and thus the following theorem is established.
Theorem 8.5.3 System (8.96) is robustly asymptotically stabilizable by the
decentralized control law (8.108) if there exist matrices 0 < Yt
j = Yj ∈
ℜnj×nj, Mj ∈ℜpj×nj and scalars δj > 0 such that the convex optimiza-
tion problem (8.112) has a feasible solution. The controller gain is given by
Kj = MjY−1
j .
8.5.4
Bounded state feedback design
Following the approach of [28, 348], we consider hereafter the case of local
state feedback control with bounded gain matrix Kj of the form Kt
j Kj
<
κj I, with κj > 0. Since Kj = MjY−1
j
this condition corresponds to the
additional constraints on the component matrices Mj and Y−1
j
by setting
Mt
j Mj
<
μjI,
μj > 0,
Y−1
j
<
σj I,
σj > 0, j = 1, .., N. In
turn, these are equivalent to the LMIs
 −μj Ij
Mt
j
•
−Ij

< 0,
 −σj Ij
Ij
•
−Yj

< 0
(8.113)
In a similar way, in order to guarantee desired values (φj) of the bounding
factors (δj), we recall that φ−2
j
= δj. Thus we require
δj −
1
φ2
j
< 0
(8.114)

8.5. Resilient Stabilization for Discrete Systems
411
Incorporating the foregoing modiﬁcations into the present analysis leads to es-
tablishing the following convex optimization problem over LMIs for the local
subsystem j:
min
Yj,δj
N

j=1
δj
subject to : Y1 > 0, ..., YN > 0,
diag

Γ1s, ..., ΓNs

< 0,
(8.115)
Γjs =
⎡
⎢⎢⎣
−Yj
YjAt
j + MjBt
j
YjAt
j + MjBt
j
YjGt
j
•
Ij −Yj
0
0
•
•
−Yj
0
•
•
•
−δjIj
⎤
⎥⎥⎦,
diag

δ1 −
1
φ2
1
, ..., δN −
1
φ2
N

< 0,
diag
  −μ1 I1
Mt
1
•
−I1

, ...,
 −μN IN
Mt
N
•
−IN
 
< 0,
diag
  −σ1 I1
I1
•
−Y1

, ...,
 −σN IN
IN
•
−YN
 
< 0
Hence, the following theorem summarizes the main result.
Theorem 8.5.4 Given the bounds φj, σj, μj, system (8.96) is robustly asymp-
totically stabilizable by control law (8.108) with constrained feedback gains
and bounding factors if there exist matrices 0 < Yt
j = Yj ∈ℜnj×nj, Mj ∈
ℜpj×nj and scalars δj > 0, μj > 0, σj > 0 such that the convex optimiza-
tion problem (8.115) has a feasible solution. The controller gain is given by
Kj = MjY−1
j .
8.5.5
Resilient state feedback design
Now we address the performance deterioration issue in controller implementa-
tion [258] by considering that the actual linear local state feedback controller
has the following perturbed form:
uj(k) = [Kj + ΔKj] xj(k)
(8.116)
where Kj ∈ℜpj×nj is a constant gain matrix and ΔKj is an additive gain
perturbation matrix represented by
ΔKj
=
Mj Δj Nj,
Δj ∈Δ := {Δj : Δt
jΔj ≤I}
(8.117)

412
Chapter 8. Decentralized Resilient Control
The application of control law (8.116) to system (8.98) yields the perturbed
closed-loop system
Σp :
xj(k + 1)
=
(Ajs + BjΔKj)xj(k) + gj(k, x(k))
yj(k)
=
Cjx(k)
(8.118)
For simplicity in exposition, we let Υj = YjAt
js + Yj(BjΔKj)t. It follows
by applying Theorem 8.5.1 to system (8.118), we obtain the following convex
problem:
min
Yj,δj
N

j=1
δj
subject to : Y1 > 0, ..., YN > 0,
Blockdiag

Γ1, ..., ΓN

< 0,
(8.119)
Γj =
⎡
⎢⎢⎣
−Yj
Υj
Υj
YjGt
j
•
Ij −Yj
0
0
•
•
−Yj
0
•
•
•
−δjIj
⎤
⎥⎥⎦
which we seek its feasibility over all possible perturbations Δj ∈Δ. In order to
convexify inequality (8.119) and at the same time bypass the exhaustive search
over the perturbation set Δ, we exploit the diagonal structure of inequality
(8.119) and manipulate the jth-block (corresponding to subsystem j) with the
aid of Inequality 1 of the Appendix to reach
⎡
⎢⎢⎣
−Yj
YjAt
js
YjAt
js
YjCt
j
•
Ij −Yj
0
0
•
•
−Yj
0
•
•
•
−δjIj
⎤
⎥⎥⎦+
⎡
⎢⎢⎣
0
BjMj
BjMj
0
⎤
⎥⎥⎦Δj
⎡
⎢⎢⎣
YjN t
j
0
0
0
⎤
⎥⎥⎦
t
+
⎡
⎢⎢⎣
YjN t
j
0
0
0
⎤
⎥⎥⎦Δt
j
⎡
⎢⎢⎣
0
BjMj
BjMj
0
⎤
⎥⎥⎦
t
≤

8.5. Resilient Stabilization for Discrete Systems
413
⎡
⎢⎢⎣
−Yj
YjAt
js
YjAt
js
YjCt
j
•
Ij −Yj
0
0
•
•
−Yj
0
•
•
•
−δjIj
⎤
⎥⎥⎦+ ηj
⎡
⎢⎢⎣
0
BjMj
BjMj
0
⎤
⎥⎥⎦
⎡
⎢⎢⎣
0
BjMj
BjMj
0
⎤
⎥⎥⎦
t
+
η−1
j
⎡
⎢⎢⎣
YjN t
j
0
0
0
⎤
⎥⎥⎦
⎡
⎢⎢⎣
YjN t
j
0
0
0
⎤
⎥⎥⎦
t
<
0
(8.120)
for some scalars ηj > 0 . By Schur complements, inequality (8.120) becomes
⎡
⎢⎢⎢⎢⎢⎢⎣
−Yj
YjAt
js
YjAt
js
YjCt
j
0
YjN t
j
•
Ij −Yj
0
0
ηjBjMj
0
•
•
−Yj
0
ηjBjMj
0
•
•
•
−δjIj
0
0
•
•
•
•
−ηjIj
•
•
•
•
•
−ηjIj
⎤
⎥⎥⎥⎥⎥⎥⎦
<
0
(8.121)
Introducing the change of variables KjYj = Mj, inequality (8.121) becomes
Θj =
⎡
⎢⎢⎢⎢⎢⎢⎣
−Yj
YjAt
j + MjBt
j
YjAt
j + MjBt
j
YjCt
j
0
YjN t
j
•
Ij −Yj
0
0
ηjBjMj
0
•
•
−Yj
0
ηjBjMj
0
•
•
•
−δjIj
0
0
•
•
•
•
−ηjIj
•
•
•
•
•
−ηjIj
⎤
⎥⎥⎥⎥⎥⎥⎦
< 0
(8.122)
The foregoing analysis has established the following theorem.
Theorem 8.5.5 System (8.96) is robustly asymptotically stabilizable by the ac-
tual control law (8.116) for all possible gain variations (8.117) if there exist
matrices 0 < Yt
j = Yj ∈ℜnj×nj, Mj ∈ℜpj×nj and scalars δj > 0, ηj such
that the following convex optimization problem
min
Yj,Mj,δj,ηj
N

j=1
δj + ηj
subject to : Y1 > 0, ..., YN > 0, M1, ..., MN
Blockdiag

Θ1, ..., ΘN

< 0
has a feasible solution where Θj is given by (8.122). The controller gain is
given by Kj = MjY−1
j .

414
Chapter 8. Decentralized Resilient Control
Had we taken the modiﬁcations made previously to constrain the local state
feedback gains, we would have reached an alternative convex optimization
problem over LMIs summarized by the following theorem.
Theorem 8.5.6 Given the bounds φj, σj, μj, system (8.96) is robustly asymp-
totically stabilizable by the actual control law (8.116) for all possible gain vari-
ations (8.117) if there exist matrices 0 < Yt
j = Yj ∈ℜnj×nj, Mj ∈ℜpj×nj
and scalars δj > 0, μj > 0, σj > 0, ηj such that the following convex
optimization problem
min
Yj,Mj,δj
N

j=1
δj + ηjμj + σj
subject to : Y1 > 0, ..., YN > 0, M1, ..., MN
diag

Θ1, ..., ΘN

< 0,
diag

δ1 −
1
φ2
1
, ..., δN −
1
φ2
N

< 0,
diag
  −μ1 I1
Mt
1
•
−I1

, ...,
 −μN IN
Mt
N
•
−IN
 
< 0,
diag
  −σ1 I1
I1
•
−Y1

, ...,
 −σN IN
IN
•
−YN
 
< 0
has a feasible solution. The controller gain is given by Kj = MjY−1
j
.
Remark 8.5.7 It should be observed that Theorems 8.5.3-8.5.6 provide a com-
plete decoupled set of LMI-based state feedback design algorithms for a class
of interconnected discrete-time systems and quadratically bounded nonlinear-
ities and perturbations. It is signiﬁcant to record that Theorem 8.5.6 is a new
addition to the resilient control theory [258, 389]. Indeed, these algorithms
assume the accessibility of local states.
In the sequel, we drop the assumption on complete accessibility of local state
variables and consider the availability of local output measurements. We fo-
cus on the design of a local dynamic output feedback stabilization scheme. To
facilitate further development, we consider the case where the set of output
matrices Cj, j = 1, ..., ns are assumed to be of full row rank. We shall be
looking for a general linear time-invariant dynamic controller that obeys the
decentralized information structure constraint requiring that each subsystem is
controlled using only its own local output.

8.5. Resilient Stabilization for Discrete Systems
415
8.5.6
Output feedback stabilization
In this part, we consider the design of a local dynamic output feedback stabi-
lization scheme:
zj(k + 1)
=
Ljzj(k) + Fjyj(k)
uj(k)
=
Kcjzj(k) + Kojyj(k)
(8.123)
where zj(k) ∈ℜmj is the local observer state such that for the intercon-
nected system z
= (zt
1, ..., zt
N)t
∈ℜm,
m = N
j=1
mj,
L =
diag{L1, ..., LN}, F = diag{F1, ..., FN}, Kc = diag{Kc1, ..., KcN}, Ko =
diag{Ko1, ..., KoN}. The matrices Lj, ∈ℜmj×mj, Fj, ∈ℜmj×qj, Kcj, ∈
ℜpj×mj, Koj, ∈ℜpj×qj are unknown gains to be determined. In the sequel,
we let
Kj =
 Lj
Fj
Kcj
Koj

∈ℜmj+pj × ℜmj+qj
(8.124)
to represent the local control parameter matrix of subsystem j to be determined
such that the overall closed-loop controlled system achieves asymptotic stabil-
ity.
We proceed, in line of the foregoing analysis, by appending the subsys-
tem dynamics (8.98) and output feedback controller (8.123), to get the local
augmented system
ζj(k + 1)
=
Aj ζj(k) + ¯gj(k, ζ(k))
ξj(k)
=
Cj ζj(k)
(8.125)
where
ζj(k)
=
 xj(k)
zj(k)

∈ℜnj+mj , ¯gj(k, ζ(k)) =
 gj(k, x(k))
0

Aj
=
 Aj + BjKojCj
BjKcj
FjCj
Lj

, Cj =

Cj
0

(8.126)
Note in light of (8.100), we have
¯gt(k, ζ(k))¯g(k, ζ(k))
≤
ζt(k) &GtΦ−1 &Gζ(k)
(8.127)
where &G = diag[ &G1, ..., &GN],
&Gj = [Gj
0]. Introduce the block matrix
¯Yj
=
 Ycj
0
0
Yoj

(8.128)

416
Chapter 8. Decentralized Resilient Control
where Ycj ∈ℜnj×nj and Yoj ∈ℜmj×mj are symmetric and positive-deﬁnite
matrices. It follows from Theorem 8.5.1 that the robust asymptotic stability
of the augmented system (8.125) guaranteed by the solution of the following
convex optimization problem
min
¯Yj,δj
N

j=1
δj
subject to : Yc1 > 0, , ..., YcN > 0, Yo1 > 0, , ..., YoN > 0,
diag

(Γ1, ..., (ΓN

< 0,
(Γj =
⎡
⎢⎢⎣
−¯Yj
¯YjAt
j
¯YjAt
j
¯Yj &Gt
j
•
Ij −¯Yj
0
0
•
•
−¯Yj
0
•
•
•
−δjIj
⎤
⎥⎥⎦< 0
(8.129)
is feasible. Algebraic manipulations of inequality (8.129) using (8.126)-(8.128)
and basing the analysis on the subsystem level lead to the following theorem.
Theorem 8.5.8 System (8.125) is robustly asymptotically stable if there exist
matrices 0 < Yt
cj = Ycj ∈ℜnj×nj, 0 < Yt
oj = Yoj ∈ℜnj×nj, Scj ∈
ℜpj×nj, Soj ∈ℜmj×mj, Rcj ∈ℜmj×nj, Roj ∈ℜpj×mj and scalars δj > 0
such that the following convex optimization problem
min
Ycj,Yoj,Scj,Soj,Roj,Rcj,δj
N

j=1
δj
subject to : Yc1 > 0, , ..., YcN > 0, Yo1 > 0, , ..., YoN > 0,
Blockdiag
  Ξc1
Ξd1
•
Ξo1

, ...,
 ΞcN
ΞdN
•
ΞoN
 
< 0(8.130)
where for j = 1, ..., N
Ξcj =
⎡
⎢⎢⎣
−Ycj
0
YcjAt
j + St
cjBt
j
Rt
cj
•
−Yoj
Rt
ojBt
j
St
oj
•
•
Ij −Ycj
0
•
•
•
Ij −Yoj
⎤
⎥⎥⎦,
Ξdj =
⎡
⎣
YcjAt
j + St
cjBt
j
Rt
cj
YcjGt
j
Rt
ojBt
j
St
oj
0
0
0
0
⎤
⎦,
Ξoj =
⎡
⎣
−Ycj
0
0
•
−Yoj
0
•
•
−δjIj
⎤
⎦
(8.131)

8.5. Resilient Stabilization for Discrete Systems
417
is feasible. Moreover, the gain matrices are given by
Kj =
 Soj
Rcj
Roj
Scj
  Yoj
0
0
Ycj
−1 )
Ij
0
0
C†
j
*
Proof: Introducing the change of variables:
Soj
=
LjYoj, Roj = KojYoj, Rcj = FjCjYcj,
(8.132)
Scj
=
KcjCjYcj, Rsj = FjYcj
(8.133)
and expanding the LMI (8.129) using (8.128), we readily obtain LMI (8.130)
with (8.131).
Remark 8.5.9 In the literature, it is reported that general forms of Lyapunov
matrices Yj lead to nonlinear matrix inequalities. Therefore, the selection of
the block-diagonal form of the Lyapunov matrices (8.128) becomes common
in control system design and has been widely used in dynamic output feed-
back design [28, 346]. In our approach, this selection yields systematic design
procedure that aims at developing convenient noniterative computational algo-
rithm while maintaining all the computations at the subsystem level.
8.5.7
Resilient output feedback stabilization
Next we address the resilience problem of output feedback stabilization. For
this purpose, we re-express the controller (8.123) into the form
zj(k + 1)
=
Ljzj(k) + Fjyj(k)
uj(k)
=
[Kcj + ΔKcj]zj(k) + [Koj + ΔKoj]yj(k)
(8.134)
where the matrices ΔKoj, ΔKcj are gain perturbations represented by
ΔKoj
=
MojΔjNoj, ΔKcj = McjΔjNcj,
Δj
∈
Δ := {Δj : Δt
jΔj ≤I}
(8.135)
Following the foregoing analysis, the augmented local subsystem becomes
ζj(k + 1)
=
[Aj + ΔAj] ζj(k) + ¯gj(k, ζ(k))
=
¯
Aj ζj(k) + ¯gj(k, ζ(k))
ξj(k)
=
Cj ζj(k)
(8.136)
where
ΔAj =
 BjΔKojCj
BjΔKcj
0
0

(8.137)

418
Chapter 8. Decentralized Resilient Control
where ζj(k), Aj, Cj are given by (8.126). In light of the procedure developed
earlier, it follows from Theorem 8.5.1 that the robust asymptotic stability of
the augmented system (8.136) is guaranteed by the feasible solution of the
following convex optimization problem:
min
¯Yj,δj
N

j=1
δj
subject to : Yc1 > 0, , ..., YcN > 0, Yo1 > 0, , ..., YoN > 0,
diag

(Γ1, ..., (ΓN

< 0,
(Γj =
⎡
⎢⎢⎣
−¯Yj
¯Yj ¯
At
j
¯Yj ¯
At
j
¯Yj &Gt
j
•
Ij −¯Yj
0
0
•
•
−¯Yj
0
•
•
•
−δjIj
⎤
⎥⎥⎦< 0
(8.138)
In order to convexify (8.138) we invoke Inequality 1 of the Appendix while
basing the analysis on the subsystem level and manipulate using (8.135) to
reach
⎡
⎢⎢⎣
−¯Yj
¯YjAt
j
¯YjAt
j
¯YjCt
j
•
Ij −¯Yj
0
0
•
•
−¯Yj
0
•
•
•
−δjIj
⎤
⎥⎥⎦+
⎡
⎢⎢⎣
σ1j
U
U
0
⎤
⎥⎥⎦Δt
⎡
⎢⎢⎣
U
σ2j
σ2j
0
⎤
⎥⎥⎦
t
+
⎡
⎢⎢⎣
U
σ2j
σ2j
0
⎤
⎥⎥⎦Δ
⎡
⎢⎢⎣
σ1j
U
U
0
⎤
⎥⎥⎦
t
⎡
⎢⎢⎣
σ3j
U
U
0
⎤
⎥⎥⎦Δt
⎡
⎢⎢⎣
U
σ4j
σ4j
0
⎤
⎥⎥⎦
t
+
⎡
⎢⎢⎣
U
σ4j
σ4j
0
⎤
⎥⎥⎦Δ
⎡
⎢⎢⎣
σ3j
U
U
0
⎤
⎥⎥⎦
t

8.5. Resilient Stabilization for Discrete Systems
419
≤
⎡
⎢⎢⎣
−¯Yj
¯YjAt
j
¯YjAt
j
¯YjCt
j
•
Ij −¯Yj
0
0
•
•
−¯Yj
0
•
•
•
−δjIj
⎤
⎥⎥⎦+
ε−1
j
⎡
⎢⎢⎣
U
σ2j
σ2j
0
⎤
⎥⎥⎦
⎡
⎢⎢⎣
U
σ2j
σ2j
0
⎤
⎥⎥⎦
t
+ εj
⎡
⎢⎢⎣
σ1j
U
U
0
⎤
⎥⎥⎦
⎡
⎢⎢⎣
σ1j
U
U
0
⎤
⎥⎥⎦
t
+
ϕ−1
j
⎡
⎢⎢⎣
U
σ4j
σ4j
0
⎤
⎥⎥⎦
⎡
⎢⎢⎣
U
σ4j
σ4j
0
⎤
⎥⎥⎦
t
+
ϕj
⎡
⎢⎢⎣
σ3j
U
U
0
⎤
⎥⎥⎦
⎡
⎢⎢⎣
σ3j
U
U
0
⎤
⎥⎥⎦
t
< 0
(8.139)
where
σ1j
=
 Ct
jN t
oj
0

, σ2j =
 YcjBjMoj
0

, σ3j =

0
N t
cj

,
σ4j
=
 YcjBjMcj
0

, U =
 0
0

(8.140)
for some εj > 0, ϕj > 0. Inequality (8.139) with the help of Schur comple-
ments can be written as
⎡
⎢⎢⎢⎢⎣
−¯Yj
¯YjAt
j
¯YjAt
j
¯YjCt
j
Ξvj
•
Ij −¯Yj
0
0
0
•
•
−¯Yj
0
0
•
•
•
−δjIj
0
•
•
•
•
−Ξwj
⎤
⎥⎥⎥⎥⎦
< 0
(8.141)

420
Chapter 8. Decentralized Resilient Control
with
Ξvj
=
⎡
⎢⎢⎣
U
εjσ1j
U
εjσ3j
σ2j
U
σ4j
U
σ2j
U
σ4j
U
0
0
0
0
⎤
⎥⎥⎦,
Ξwj
=
⎡
⎢⎢⎣
εjIj
0
0
0
•
ϕjIj
0
0
•
•
εjIj
0
•
•
•
ϕjIj
⎤
⎥⎥⎦
(8.142)
Our immediate task is to determine the feedback controller gain matrices
Lj, Fj, Koj, Kcj
and we do this by extending on the convexiﬁcation procedure of Theorem
8.5.8. The desired result is summarized by the following theorem.
Theorem 8.5.10 System (8.136) is robustly asymptotically stable if there exist
matrices 0 < Yt
cj = Ycj ∈ℜnj×nj, 0 < Yt
oj = Yoj ∈ℜnj×nj, Scj ∈
ℜpj×nj,
Soj
∈ℜmj×mj,
Rcj
∈ℜmj×nj,
Roj
∈ℜpj×mj,
Rsj ∈
ℜmj×nj, Moj ∈ℜnj×nj and scalars δj > 0, νj > 0, εj > 0, ϕj > 0
such that the following convex optimization problem
min
Ycj,Yoj,Scj,Roj,Rcj,Rsj,Moj,δj,εj,ϕj
N

j=1
δj + εj + ϕj
(8.143)
subject to : Yc1 > 0, , ..., YcN > 0, Yo1 > 0, , ..., YoN > 0,
diag
 ⎡
⎣
Ξc1
Ξd1
Ξv1
•
Ξo1
0
•
•
−Ξw1
⎤
⎦, ...,
⎡
⎣
ΞcN
ΞdN
ΞvN
•
ΞoN
0
•
•
−ΞwN
⎤
⎦

<
0
(8.144)
is feasible, where Ξcj, Ξdj, Ξoj are as in (8.131) and Ξvj, Ξwj are given by
(8.142). Moreover, the gain matrices are given by
Kj =
 Soj
Rcj
Roj
Scj
  Yoj
0
0
Ycj
−1 )
Ij
0
0
C†
j
*
Proof: By introducing the change of variables (8.133) and expanding the LMI
(8.141) using (8.128), we readily obtain LMI (8.144).

8.5. Resilient Stabilization for Discrete Systems
421
8.5.8
Illustrative example 8.6
To illustrate the usefulness of the developed resilience approach, let us consider
the following interconnected system which is composed of three subsystems.
With reference to (8.98), the data values are:
Subsystem 1 :
A1
=
 0.9
0.5
0.8
0.1

, Γ =

1
0.5

, C1 =

0
1

Subsystem 2 :
A2
=
⎡
⎣
0
0
0.1
0.1
−0.6
0.1
0.3
0.7
0.9
⎤
⎦, B2 =
⎡
⎣
0.3
0
0.4
⎤
⎦,
C2
=

1
0
0

Subsystem 3 :
A3
=

0.3
0.2
−0.6
0.6

, B3 =
 0.5
0.7

, C3 =

0.5
0

,
x1(k)
=

x11(k)
x12(k)
t ,
x2(k)
=

x21(k)
x22(k)
x23(k)
t ,
x3(k)
=

x31(k)
x32(k)
t
In terms of the overall state vector x(k) =

xt
1(k)
xt
2(k)
xt
3(k)
t ∈ℜ7,
the interconnection is given by
g(k, x(k)) =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
0.1
−0.1
|
0
0.2
0
|
0.1
0
0.1
0.3
|
1
0
0
|
0
1
−−
−−
−−
−−
−−
−−
−−
−−
−−
−0.1
0.1
|
0
−0.2
0
|
0.1
0
0
−0.1
|
0
0
0.3
|
0
0.1
0
0
|
−0.3
0.4
0.3
|
0
0.2
−−
−−
−−
−−
−−
−−
−−
−−
−−
0.1
−0.1
|
0.1
−0.1
0
|
0.2
−0.1
0.1
−0.1
|
0
0.2
0
|
0.4
0.5
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
e(k, x(k)) x(k)
where e(k, x(k)) : ℜ8 −→[0, 1] represents a normalized interconnection pa-
rameter and the dashed (horizontal and vertical) lines correspond to the three
subsystems.

422
Chapter 8. Decentralized Resilient Control
The objective here is to compute a decentralized control law that would
connectively stabilize the system for all values of e(k, x(k)) ∈[0, 1] based on
state or output feedback schemes. Using MATLAB-LMI solver, it is found that
the feasible solution of Theorem 8.5.1 is given by
δ1
=
1.6535, Y1 =
 1.711
0.318
•
1.844

,
δ2
=
1.7335, Y2 =
⎡
⎣
4.252
1.121
1.441
•
2.824
1.327
•
•
4.225
⎤
⎦,
δ3
=
1.4964, Y3 =
 2.223
0.625
•
1.914

which illustrates the asymptotic stability of the individual subsystems and
hence the overall system.
For the output feedback stabilization design, we used second-order dy-
namic controllers (m1 = m2 = m3 = 2). The ensuing simulation results
show that the feasible solution of Theorem 8.5.8 is given by
δ1
=
1.6764,
L1
=
 −0.0123
0.0043
0.0046
−0.0134

, F1 =

0.1167
0.3914
−0.1015
−0.3208

,
Kc1
=

0.1109
−0.1103

,
Ko1
=

−0.3829
−0.2531

,
δ2
=
1.7864,
L2
=
 −0.0424
0.0118
0.0216
−0.0209

, F2 =

0.1203
0.4024
0.2247
−0.1276
−0.2958
−0.4216

,
Kc2
=

−0.1007
−0.2125

, Ko2 =

−0.2471
−0.3667
−0.0845

,
δ3
=
1.8795,
L3
=
 −0.0583
0.0029
−0.0189
−0.2601

, F3 =

0.2088
0.4314
−0.1023
−0.2678

,
Kc3
=

−0.1243
−0.3108

,
Ko3
=

−0.5104
−0.3017

Turning to Theorem 8.5.8, by incorporating gain perturbations of the form
(8.135) with Mo1 = [0.5 0.5], No1 = 0.8, Mo2 = [1.5 1.5 2.5], No2 =
0.6, Mo3 = [1.0 1.0], No3 = 0.5, Mt
c1 = [1.2 1.8], Nc1 = 0.6, Mt
c2 =
[2.0
2.5
2.0], Nc2 = 0.4, Mt
c3 = [1.5
2.5], Nc3 = 0.1,
the feasible

8.6. Problem Set VI
423
solution is given by
δ1
=
1.9814,
L1
=
 −0.0245
0.0173
0.0136
−0.0323

, F1 =

0.1143
0.3764
−0.1015
−0.4218

,
Kc1
=

0.1109
−0.1103

,
Ko1
=

−0.3779
−0.2620

,
δ2
=
2.0456,
L2
=
−0.0451
0.0129
0.0334
−0.0212

, F2 =
−0.1269
−0.2768
−0.4213
0.1204
0.4033
0.2239

,
Kc2
=

−0.1013
−0.2131

, Ko2 =

−0.2471
−0.3427
−0.0785

,
δ3
=
2.1135,
L3
=
 −0.0578
0.0114
−0.0189
−0.2501

, F3 =

0.2098
0.4294
−0.1023
−0.2678

,
Kc3
=

−0.1243
−0.3108

,
Ko3
=

−0.5105
−0.3016

The obtained results indicated slightly higher tolerance levels δj in the case of
resilient feedback control which is expected to accommodate for the effects of
gain perturbations.
8.6
Problem Set VI
Problem VI.1: Consider the following two linear systems
S
:
˙x(t) = Ax(t) + Bu(t), x(0) = xo,
y
=
Cx,
˜S
:
˙˜x(t) = ˜A˜x(t) + ˜B˜u(t), ˜x(0) = ˜xo,
˜y
=
˜C˜x
where x ∈ℜn, u ∈ℜm, y ∈ℜp, ˜x ∈ℜ˜n, ˜u ∈ℜ˜m, ˜y ∈ℜ˜p are the
state, input, and output vectors for systems S and ˜S, respectively. Consider the
transformations
T
:
ℜn −→ℜ˜n, rank(T) = n,
U
:
ℜ˜m −→ℜm, rank(U) = m,
T†
:
ℜ˜n −→ℜn, T†T = In,
U†
:
ℜm −→ℜ˜m, rank(U) = m

424
Chapter 8. Decentralized Resilient Control
such that ˜xo = Txo, u = U˜u. Based thereon, establish that
TA = ˜AT, TBU = ˜B
In this case, system ˜S is called an extension of system S. Consider the linear
feedback stabilizing controls:
u = Kx, ˜u = ˜K˜u
such that ˜A + ˜B ˜K is asymptotically stable and the following relation
Kx(t; xo, U˜u = U ˜K˜x(t; Txo, ˜u)
holds. Verify that the condition
K = U ˜KT
holds.
Problem VI.2: Extending on Problem VI.1, consider the following cost func-
tions
S
:
J =
 ∞
0
(xtQx + utRu) dt,
˜S
:
˜J =
 ∞
0
(˜xt ˜Q˜x +˜ut ˜R˜u) dt
Verify in light of the contractability conditions that
J(xo, Kx) = ˜J(Txo, ˜K˜x)
Hence derive the relations
˜Q = (T†)tQT† + ˜E,
˜R = UtRU + ˜F
Extend these results to resilient overlapping control.
Problem VI.3: For a class of uncertain linear interconnected system of the type
(8.60)-(8.62), consider a local resilient state feedback controller
uj(t) = Kj[Ij + ΔKj(t)]xj(t), ΔKj(t) = HkjFkj(t)Ekj
Examine the robust stability with respect to the overall Lyapunov-Krasovskii
functional (LKF):
V (x, t) = xt(t)Px(t) +
 t
t−d
xt(σ)[I + Et
dEd]x(σ)dσ

8.6. Problem Set VI
425
where P = {Pj}, Pj ∈ℜnj×nj, (I + Et
dEd) ∈ℜn×n are positive-deﬁnite
symmetric matrices. Then, or otherwise, derive an LMI-based condition for ro-
bust stabilizability.
Problem VI.4: Consider an uncertain linear composite system comprised of
ns subsystems, where the jth subsystem is described by
Sj :
˙xj(t)
=
[A + ΔAj(t)]xj(t) + [Ad + ΔAdj(t)]xj(t −dj)
+
Buj(t) + zj(t),
yj(t)
=
Cxj(t), xj(t) = φj(t), ∀t ∈[−dj, 0], j ∈{1, ..., ns},
zj(t)
=
ns

k=1
Ljkyxk + Ldjkydk,
yxk
=
Cyxj,
ydk = Cdyxj(t −dj)
where the interconnection matrices have the following structure:
Ljj
=
0, Ljk = Lq + ΔLqjk(t),
Ldjj
=
0, Ldjk = Ldq + ΔLdqjk(t), j ̸= k
and the nonlinear parametric uncertainties are given by
ΔAj(t)
=
DaΔajEa, ΔAdj(t) = DdaΔdajEda,
ΔLqjk(t)
=
DℓΔℓjEℓ, ΔLdqjk(t) = DdℓΔdℓajEdℓ
where Δt
∗(t)Δ∗(t) ̸= I. It is desired to design ns resilient decentralized con-
trollers of the form
˙ξj(t)
=
[Ar + ΔArj]ξj(t) + [Adr + ΔAdrj]xj(t −τj(t)) + Buj(t)
+
[Ko + ΔKoj][yj(t) −Crjξj(t)],
uj(t)
=
[Kc + ΔKcj][ξj(t) +
 t
t−τj(t)
Adrξj(s) ds]
ΔArj(t)
=
DrΔrjEr, ΔAdrj(t) = DdrΔdrjEdr,
ΔKoj(t)
=
DoΔojEo, ΔKrj(t) = DcΔcjEc
where Δt
∗(t)Δ∗(t) ̸= I. Develop a procedure to determine the observer matri-
ces Ar, Adr and unknown gain matrices Ko, Kc such that the observer-based
controlled system is asymptotically stable.

426
Chapter 8. Decentralized Resilient Control
8.7
Notes and References
We have considered the resilient decentralized feedback stabilization problem
of a class of nonlinear interconnected discrete-time systems. This class of sys-
tems has uncertain nonlinear perturbations satisfying quadratic constraints that
are functions of the overall state vector. Decentralized state and output feedback
schemes have been developed and analyzed such that the overall closed-loop
system guarantees global stability condition, derived in terms of local subsys-
tem variables. Incorporating feedback gain perturbations, new resilient decen-
tralized feedback schemes have been subsequently developed. The proposed
approach has been formulated within the framework of convex optimization
over LMIs. Simulation results have illustrated the effectiveness of the proposed
decentralized output feedback controllers.
Decentralized delay-dependent stability and stabilization methods have
been developed for a class of linear interconnections of time-delay plants sub-
jected to convex-bounded parametric uncertainties and coupled with time-delay
interconnections. We have constructed an appropriate decentralized Lyapunov-
Krasovskii functional to exhibit the delay-dependent dynamics at the subsys-
tem level. Decentralized LMIs-based delay-dependent stability conditions have
been derived such that every local subsystem of the linear interconnected delay
system is robustly asymptotically stable with a γ−level L2−gain. A decentral-
ized state feedback stabilization scheme has been designed such that the fam-
ily of closed-loop feedback subsystems enjoys the delay-dependent asymptotic
stability with a prescribed γ−level L2 gain for each subsystem. The decentral-
ized feedback gains are determined by convex optimization over LMIs and all
the developed results are tested on a representative example.
The chapter contributes to the solution of the overlapping H∞resilient
state feedback control design for a class of nonlinear continuous-time uncertain
state-delayed nominally linear systems. Time-varying unknown norm-bounded
parameter uncertainties are considered in the system and the controller. Con-
ditions preserving closed-loop systems expansion-contraction relations guar-
anteeing the H∞disturbance attenuation bounds have been proved. They are
derived in terms of conditions on complementary matrices. An LMI delay-
independent procedure has been supplied as a control design tool. The re-
sults have been specialized into an overlapping decentralized control setting.
It means that the presented method leads to the control design of robust H∞
resilient state tridiagonal feedback controllers.
In [258], extensive discussions were carried on incorporating gain pertur-
bations. The decentralized versions of some of these results need further inves-
tigation.

Chapter 9
Decentralized Sliding-Mode
Control
In this chapter, we continue further into the decentralized control techniques
for interconnected systems, where we focus herein on methods for designing
classes of decentralized controllers based on sliding-mode control (SMC) the-
ory. Our effort is divided into two sections: in the ﬁrst section we deal with
a class of nonlinear interconnected systems with nonlinear uncertain subsys-
tems considered where matched and mismatched uncertainties are both dealt
with. In the second section, global decentralized stabilization of a class of inter-
connected delay systems is considered where both known and uncertain inter-
connections involve time delay. Matched and mismatched interconnections are
treated separately to reduce the conservatism. In both sections, the approach
followed allows a more general structure for the interconnections and uncer-
tainty bounds than other literature in this area. The conservatism in the results
is reduced by fully using system output information and the uncertainty bounds.
9.1
Robust Sliding-Mode Control
Large-scale systems are often modeled as dynamic equations composed of in-
terconnections of lower-dimensional subsystems. One of the main features of
these systems is that they are often spatially distributed, and thus the informa-
tion transfer among subsystems may incur high cost or even encounter prac-
tical limitations. Moreover, system state variables are often not fully available
for practical systems. Some state variables may be difﬁcult/costly to measure
and sometimes have no physical meaning and thus cannot be measured at all.
It may be possible to use an observer to estimate unknown states, but this
427

428
Chapter 9. Decentralized Sliding-Mode Control
approach faces the twin problems of requiring more hardware resources and
greatly increasing the dimension of the system. In turn, this brings about fur-
ther difﬁculties especially for large-scale systems. It is therefore pertinent to
study decentralized control for large-scale interconnected systems using output
feedback.
In this regard, many of the decentralized output feedback control meth-
ods [302, 377, 378] where Lyapunov approaches are used to form the control
scheme and strict structural conditions are imposed on the nominal subsystems
together with some strong limitations on the admissible interconnections. On
the other hand, adaptive control techniques are employed in [140, 141] with
parametric uncertainty. The corresponding results can only be applied to cer-
tain systems with special structure. Sliding mode control has been used suc-
cessfully by many researchers [66, 67, 365, 395], mostly focusing on central-
ized control which is hard to implement in large-scale interconnected systems.
Sliding mode control schemes for large-scale systems have also been reported
in [109, 172].
9.1.1
Introduction and preliminaries
In this section, the focus is on a decentralized output feedback control strat-
egy based on sliding-mode techniques. A class of nonlinear large-scale inter-
connected systems with matched and mismatched uncertainties is considered.
No statistical information about the uncertainties is imposed. Furthermore, the
bounding functions on the uncertainties and interconnections take a more gen-
eral structure than that imposed by other authors. Nonlinear interconnections
are considered along with nonlinear nominal subsystems.
To set the scene for subsequent analysis, we consider a linear system
˙x
=
Ax + Bu
(9.1)
y
=
Cx
(9.2)
where x ∈ℜn, u ∈ℜm, y ∈ℜp are the states, inputs, and outputs, respectively,
and assume m ≤p < n. The triple (A, B, C) comprises constant matrices of
appropriate dimensions with B and C both being of full rank.
For system (9.1)-(9.2), it is assumed that rank(CB) = m. Then it can
be shown [65] that a coordinate transformation ˜x = ˜Tx exists such that the
system triple (A, B, C) with respect to the new coordinates ˜x has the following
structure:
˜A =
 ˜A11
˜A12
˜A21
˜A22

,
˜B =
 0
B2

,
˜C =

0
˘T

(9.3)

9.1. Robust Sliding-Mode Control
429
where ˜A ∈ℜ(n−m)×(n−m), B2 ∈ℜm×m is nonsingular and ˘T ∈ℜp×p is
orthogonal. Further, it is assumed that system ( ˜A11, ˜A12, ˜C1) with C1 deﬁned
by
˜C1 = [0(p−m)×(n−p)
Ip−m]
(9.4)
is output feedback stabilizable, that is, there exists a matrix K ∈ℜm×(p−m)
such that ˜A11 −˜A12K ˜C1 is stable. A necessary condition for ( ˜A11, ˜A12, ˜Cl) to
be stabilizable is that [65] the invariant zeros of (A, B, C) lie in the open left
half-plane and a sliding surface
FCx = 0
(9.5)
is proposed, where F = F2[K
Im] ˘T t and F2 ∈ℜm×m is any nonsingu-
lar matrix. A coordinate change is then introduced based on the nonsingular
transformation z = ˆT ˜x with ˆT deﬁned by
ˆT =
In−m
0
K ˜C1
Im

Then in the new coordinates z, system (9.1)-(9.2) has the following form:
ˆA =
A11
A12
A21
A22

,
ˆB =
 0
B2

,
ˆC =

0
C2

(9.6)
where Al1 = ˜A11 −˜A12K ˜C1 is stable, C2 ∈ℜp×p is nonsingular, and C
satisﬁes F ˆC = [0
F2] with F2 nonsingular. The canonical form in (9.6) can
be obtained from a systematic algorithm together with any output feedback
pole placement algorithm of choice; see [65, 67] for more details.
9.1.2
System description
We consider a nonlinear large-scale system formed by ns coupled subsystems
as follows:
˙xj
=
Ajxj + fj(xj) + Bj(uj + Δgj(xj)) + Hj(x)
(9.7)
yj
=
Cjxj,
j = 1, 2, ..., ns
(9.8)
where x = col(x1, x2, ..., xN), xj ∈ℜnj, uj ∈ℜmj, yj ∈ℜpj are the states,
inputs, and outputs of the jth subsystem, respectively, and mj ≤pj < nj.
The triple (Aj, Bj, Cj) represents constant matrices of appropriate dimensions
with Bj and Cj being of full rank. The function fj(xj) represents known non-
linearities in the ith subsystem. The matched uncertainty of the jth isolated
subsystem is denoted by Δgj(xj) and Hj(x) represents system interconnec-
tions including all mismatched uncertainties. The functions are all assumed to
be continuous in their arguments.

430
Chapter 9. Decentralized Sliding-Mode Control
Assumption 9.1.1 rank(Cj, Bj) = mj
for j = 1, 2, ..., ns.
It follows that there exists a coordinate transformation ˜xj = ˜Tjxj such that the
triple (Aj, Bj, Cj) with respect to the new coordinates has the structure
 ˜Ai11
˜Ai12
˜Ai21
˜Ai22

,
 0
˜Bi2

,

0
˜Ci2

(9.9)
where ˜Ai11 ∈ℜ(nj−mj)×(nj−mj), ˜Bi2 ∈ℜmj×mj, and ˜Ci2 ∈ℜpj×pj forj =
1, 2, ..., ns.
Assumption 9.1.2 For the triples ( ˜Aj11, ˜Aj12, ¯Cj2) with
¯Cj2 = [0(pj−mj)×(nj−pj)
I(pj−mj)]
there exist matrices Kj such that ˜Aj11−˜Aj12Kj ¯Cj2 are stable for j = 1, ..., ns.
Remark 9.1.3 It must be emphasized that Assumptions 9.1.1 and 9.1.2 are
based on the linear part of the individual nominal subsystems to guarantee the
existence of the output sliding surface. Observe that Assumption 9.1.2 demands
( ˜Aj11, ˜Aj12, ¯Cj2) instead of (Aj, Bj, Cj) to be output feedback stabilizable. As
shown in [65], a necessary condition for this is that the triple (Aj, Bj, Cj) is
minimum phase.
Assumption 9.1.4 Suppose that fj(xj) has the decomposition fj(xj)
=
Γj(yj)xj, where Γj ∈ℜnj×nj is a continuous function matrix for j =
l, 2, ..., ns.
Assumption 9.1.5 There exist known continuous functions ρj(·) and ηj(·)
such that for i = l, 2, ..., ns
|Δgj(xj)| ≤ρj(yj),
|Hj(x)| ≤ηj(x)
where ηj(·) satisﬁes ηj(x) ≤βj(x)|x| for some continuous function βj.
Remark 9.1.6
1. If fj(0) = 0 and fj is sufﬁciently smooth, then the decomposition
fj(xj) = Γj(yj)xj is guaranteed. The restriction on fj imposed here
is the requirement that Γj(xj) = Γj(yj).

9.1. Robust Sliding-Mode Control
431
2. Assumption 9.1.5 ensures that all uncertainties in (9.7)-(9.8) are
bounded by known functions, and the matched uncertainty is bounded by
a function of the output. In this way, a more general bound for ∥Δgj(xj)∥
than ρj(yj) is allowed which is only used to show that the effect of the
matched uncertainty can be eliminated completely if its bound can be de-
scribed by a function of the system output. Additionally, the uncertainties
and interconnections in system (9.7)-(9.8) have more general forms than
the parametric structure in [140, 141], and no special requirement for
the structure of the uncertainty and interconnection terms is imposed.
9.1.3
Stability analysis
It is observed under Assumptions 9.1.1 and 9.1.2 that there exist matrices Fj
such that for j = 1, 2, ..., ns the system
˙xj = Ajxj + Bjuj
when restricted to the surface FjCjxj = 0, is stable. The composite sliding
surface for the interconnected system (9.7)-(9.8) is chosen as
σ(x) = 0
(9.10)
with σ(x) ≡: col(σ1(x1), σ2(x2), ..., σN(xns)) and
σj(xj) = FjCjxj = Fjyj
(9.11)
where the Fj are obtained from the algorithm given in [65]. Subsequently, un-
der Assumptions 9.1.1-9.1.4 there exist nonsingular coordinate transforma-
tions zj = Tjxj such that in the new coordinates z = col(z1, z2, ..., zns) sys-
tem (9.7)-(9.8) has the following form:
˙zj
=
Aj11
Aj12
Aj21
Aj22

zj +
Γj1(yj)
∗
∗
∗

zj
 0
Bj2

(uj + Δgj(T −1
j
zj)) + TjHj(T −1z),
(9.12)
yj
=

0
Cj2

zj,
j = 1, 2, ..., ns
(9.13)
where Aj11 = ˜Aj11 −˜Aj12Kj ¯Cj2 is stable, Γj1(yj) ∈ℜ(nj−mj)×(nj−mj) and
the ∗are subblocks of TjΓj(·)T −1
j
that play no part in the subsequent analysis,
T −1 ≡: diagT −1
1
, T −1
2 , ..., T −1
ns and the square submatrices Bj2 ∈ℜmj×mj and
Cj2 ∈ℜpj×pj are nonsingular. Furthermore, Fj[0
Cj2] = [0
Fj2] where

432
Chapter 9. Decentralized Sliding-Mode Control
Fj2 ∈ℜmj×mj is nonsingular. Since Aj11 is stable for j = 1, ..., ns, for any
Qj > 0, the following Lyapunov equation has a unique solution Pj > 0 such
that
At
j11Pj + PjAj11 = −Qj,
j = 1, 2, ..., ns
(9.14)
Proceeding further and in order to fully use the available structure characteris-
tics, partition zj = col(zj1, zj2) with zj1 ∈ℜnj−mj and zj2 ∈ℜmj. It follows
that in the new coordinate z, the switching function FjCjxj can be described
by Fj[0
Cj2]zj = Fj2zj2, and from the nonsingularity of Fj2, it follows that
the sliding surface (9.11) becomes zj2 = 0 with j = 1, 2, ..., ns. Further, parti-
tion Cj2 and zj1 as Cj2 = [Cj21
Cj22] and zj1 = col(zj11, zj12), respectively,
where Cj21 ∈ℜpj×(pj−mj), zj11 ∈ℜnj−pj, and zj12 ∈ℜpj−mj. It is observed
that yj = Cj21zj12 + Cj22zj2. By restricting system (9.12)-(9.13) to move on
the sliding surface zj2 = 0, the sliding mode has the following form:
˙zj1 = Aj11zi1 + Γj1((Cj21zj12)zj1 + Wj(z11, ..., zns1))
(9.15)
where Wj(z11, ..., zns1) is the ﬁrst (nj −mj) component of
TjHj(T −1z)|(z12,...,zns2)=0
From Assumption 9.1.5, it is easy to ﬁnd a function γj(z11, z21, ..., zns1) de-
pending ηj(T −1x) and Tj such that
∥Wj(z11, ..., zns1)∥≤γj(z11, ..., zns1)
ns

j=1
∥zj1∥
(9.16)
It is readily evident that (9.15) is a reduced-order interconnected system com-
posed of ns subsystems with dimension nj −mj for which the following sta-
bility result is established.
Theorem 9.1.7 Consider the sliding mode dynamics (9.15). Under Assump-
tions 9.1.1-9.1.5, the sliding motion is asymptotically stable if there exists a
domain
Ω = {(z11, z21, ..., zns1)|∥zj1|∥≤dj, i = 1, 2, ..., N}
for some constants dj > 0 such that Mt + M > 0 in Ω\{0} where M =
(mij)ns×ns and for j, k = 1, 2, ..., ns
mjk =
 λ(Qj) −∥Rj(Cj21zj12∥−2∥Pj∥γj(·),
j = k
−2∥Pj∥γj(·),
j ̸= k
(9.17)
with Pj and Qj satisfying (9.14), Rj(·) :≡PjΓj1(·) + Γt
j1(·)Pj with Γj1(·)
given by (9.12), and γj(·) determined by (9.16).

9.1. Robust Sliding-Mode Control
433
Proof 9.1.8 It sufﬁces to prove that system (9.15) is asymptotically stable. Con-
sider the Lyapunov function candidate
V (z11, z21, ..., zNns1) =
ns

i=1
zt
j1Pjzj1
(9.18)
Evaluating the time derivative of V (z11, z21, ..., zns1) along the trajectories of
system (9.15) using (9.14) gives
˙V =
N

i=1
{−zt
i1Qjzi1 + zt
i1(PjΓi1(·)Pj)zi1
+ 2zt
i1PjWj(·)}
(9.19)
By (9.16), it follows that
˙V
≤
N

i=1
{−λ(Qj)∥zi1∥2 + ∥PjΓi1(·) + Γt
i1(·)Pj∥∥zi1∥2
+2∥zi1∥∥Pj∥∥Wj(·)∥}
≤
N

i=1
{−λ(Qj)∥zi1∥2 + ∥Rj(·)∥∥zi1∥2}
+2
N

i=1
{∥zi1∥∥Pj∥γj(·)
N

j=1
∥zj1∥}
=
−
N

i=1
{λ(Qj) −∥Rj(·)∥−2∥Pj∥γj(·)}∥zi1∥2
+2
N

i=1
N

j=1,j̸=i
∥Pj∥γj(·)∥zi1∥∥zj1
=
−1
2Y t(Mt + M)Y
(9.20)
where
Y ≡: col(∥zii∥, ..., ∥zns1∥)
Since by assumption Mt + M > 0 in Ω{0}, the proof is concluded.
Remark 9.1.9 It must be observed that the function matrix M in Theorem
9.1.7 only depends on the sliding mode variables zj1 instead of zj, with
j = 1, 2, ..., ns. When Γj1(·) and the bounds for all mismatched parts can

434
Chapter 9. Decentralized Sliding-Mode Control
be expressed as functions of zj1 with j = 1, 2, ..., ns, a global stability re-
sult is obtained. In [377, 378] the corresponding matrix M depends on all the
state variables. Moreover, since Γj1 only depends on zj12, Rj(·) is reduced to
a null matrix if pj = mj. This greatly relaxes Γj(·). In addition, the matrices
Fj are completely determined by choice of Kj which is required to ensure that
˜Aj11 −˜Aj12Kj ¯Cj2 is stable. From the foregoing analysis, it is observed that
the matrix M depends on Rj, γj, Pj, and Qj, where the quantities Rj and γj
are determined by the given system, whereas Pj depends on Qj, which can be
designed freely. From (9.17) a reasonable selection is the one that minimizes
λM(Pj)/λm(Qj) which assists in making M2 + M diagonally dominant and
having all positive diagonal elements.
9.1.4
Decentralized sliding-mode control
Our goal now is to design a decentralized output feedback sliding-mode control
such that the system state is driven to the sliding surface (9.10). In terms of the
interconnected system (9.7)-(9.8), the corresponding condition is described by
[109]
N

i=1
σt
j(xj) ˙σj(xj)
∥σj(xj)∥
< 0
(9.21)
where σj(xj) is deﬁned by (9.11). The result of comparing system (9.7)-(9.8)
with (9.12)-(9.13) yields Cj = [0
Cj2]Tj = Cj2[0
Ip]Tj where Cj2 is given
by (9.13). Then
xj = T −1
j
Tjxj = T −1
j
(Tjxj)1
C−1
i2 yj

(9.22)
where (Tjxj)1 is the ﬁrst nj −pj components of Tjxj. Now, consider system
(9.7)-(9.8) in the domain
Θ ≡: Θ1 × Θ2 × ... × Θns, Θj ∈ℜnj
and explicitly
Θj ≡: {xj|xj ∈ℜnj,
∥(Tjxj)1∥≤μj}
(9.23)
for some positive constant μj with j = 1, 2, ..., ns. We now let i = 1, 2, ..., ns:
FjCj(Aj+Γj(yj))T −1
j
:= [Υj1(yj)
Υi2(yj)], Υj1 ∈ℜmj×(nj−pj) (9.24)
In view of
FjCjBj = FjCjT −1
j
TjBj = [0
Fj2]
 0
Bi2

= Fj2Bj2

9.1. Robust Sliding-Mode Control
435
it is readily seen that FjCjBj is nonsingular. Then, the following control law
is proposed:
ui = −(FjCjBj)−1 Fjyj
∥Fjyj∥{∥Υi2(·)C−1
i2 yj∥+ εj
2 ∥Υi1(·)∥2
+
μ2
j
2εj
+ ∥FjCjBj∥ρj(yj) + kj(yj)}
(9.25)
for j = 1, 2, ..., ns where εj > O is an adjustable constant; Fj and ρj are
deﬁned by (9.11) and Assumption 9.1.5, respectively; and kj(yj) is the control
gain to be designed later. The following result stands out.
Theorem 9.1.10 Consider the nonlinear interconnected system (9.7)-(9.8).
Under Assumptions 9.1.1-9.1.5, the decentralized control (9.25) drives the sys-
tem (9.7)-(9.8) to the composite sliding surface (9.10) and maintains a sliding
motion for the domain Θ{0}, kj(yj) satisﬁes
N

i=1
kj(yj) −
N

i=1
ηj(x)∥FjCj∥> 0
(9.26)
where Fj and ηj are determined by (9.11) and Assumption 9.1.5, respectively,
and Θ is deﬁned by (9.23).
Proof: We need to be prove that the composite reachability condition (9.21) is
satisﬁed. From (9.11) and Assumption 9.1.4, we have
˙σj(xj) =FjCj(Aj + Γj(yj))xj + FjCjBj(uj + Δgj(xj))
+ FjCjHj(x)
(9.27)
for i = 1, 2, ..., N. Substituting (9.25) into (9.27), we obtain
σt
j ˙σj
∥σj∥=(Fjyj)t
∥Fjyj∥{FjCj(Aj + Γj(·))xj + FjCjHj(x)
+ FjCjBjΔgj(xj)} −∥Υi2(yj)C−1
j2 yj∥
−εj
2 ∥Υi1(·)∥2 −
μ2
j
2εj
−∥FjCjBj∥ρj(·) −kj(·).
(9.28)

436
Chapter 9. Decentralized Sliding-Mode Control
From (9.22) and the algebraic inequality ab ≤(ε/2)a2 + (b2/2ε) for ε > 0,
see the Appendix, for j = 1, 2, ..., ns.
∥FjCj(Aj + Γj(·)∥
= ∥FjCj(Aj + Γj(·))T −1
j
(Tjxj)1
C−1
i2 yj

= ∥Υj1(yj)(Tjxj)1 + Υi2(·)C−1
j2 yj
≤∥Υj2(yj)C−1
j2 yj∥+ εj
2 ∥Υj1(yj)∥2 + ∥(Tjxj)1
2εj
(9.29)
Also
∥FjCjBjΔgj(xj)∥
≤
∥FjCjBj∥ρj(yj)
(9.30)
∥FjCjHj(x)∥
≤
∥FjCj∥ηj(x)
(9.31)
Substituting (9.29)-(9.31) into (9.28), we have
σt
j(xj) ˙σj(xj)
∥σj(xj)∥
≤∥(Tjxj)1∥2
2εj
−
μ2
j
2εj
−kj(·) + ηj(˙)∥FjCj∥
≤−kj(·) + ηj(·)∥FjCj∥
in the domain Θj. Then, if kj(yj) is selected to satisfy (9.26), it follows that in
the domain Θ, the reachability condition (9.21) is satisﬁed. Hence, the result
follows.
Remark 9.1.11 We observe that the decompositions (9.22) and (9.24) attempt
to use as much as possible the known quantities associated with fj(xj), that is,
Γj(yj), in the control law, to reduce conservatism. The effect of Υj2(yj)C−1
j2
from γj(yj) is canceled out completely by the nonlinear control (9.25) and
from which it can be readily seen that εj can be used to adjust the control
amplitude to some extent by considering the size of Θj and the value of Υj2(yj)
if a global result is not available. It can also be concluded that the reaching
condition (9.26) is satisﬁed theoretically in any compact domain of the origin
if high gain control is allowed. Generally speaking, the larger the domain that
is required, the higher the required control gain. This is in contrast with the
results of [377, 378], where the conclusion can only be satisﬁed in a small
domain about the origin.
The following result follows.

9.1. Robust Sliding-Mode Control
437
Corollary 9.1.12 For system (9.7)-(9.8), suppose Assumptions 9.1.1-9.1.5 are
satisﬁed, and Mt + M > 0 by Theorem 9.1.7 with M ∈ℜ
PN
i=1(nj−mj){0}.
Then
(i) The sliding mode dynamics (15) are globally asymptotically stable.
(ii) The closed-loop system composed of (9.7)-(9.8) and the control law
uj(yj) = −(FjCjBj)−1 Fjyj
∥Fjyj∥{∥Υi2(yj)C−1
j2 yj∥
+ ∥FjCjBj∥ρj(yj) + kj(yj)}
(9.32)
is globally asymptotically stable if Υj1(yj) = 0 and ∥Hj(x)∥≤ns
j=1 υjk(yj)
for some continuous υjk with j = 1, 2, ..., ns.
Proof:
(i) From the structure of the Lyapunov function (9.18), the result is obtained
directly from Theorem 9.1.7.
(ii) From the proof of Theorem 9.1.10 and considering the control
law (9.18), the expressions (εj/2)∥Υi1(yj)∥2 + (μ2
j/2εj) are introduced to
counteract Υj1(yj)(Tjxj)1. In fact, this is unnecessary if Υj1(yj) = 0.
In this case, (9.25) reduces to (9.1.4) and it sufﬁces to choose kj(yj) >
N
j=1 ∥FjCj∥υjk(yj) for j = 1, 2, ..., ns. By parallel development to The-
orem 9.1.10, it can be shown that the corresponding reachability condition is
satisﬁed. Therefore, the controlled trajectories of system (9.7)–(9.8) are steered
toward the sliding surface (9.10) globally and remain on the surface thereafter.
In combination with (i), the conclusion (ii) is obtained.
9.1.5
Illustrative example 9.1
Consider the interconnected system composed of two third-order subsystems
˙x1
=
⎡
⎣
−7.9
0
1
0
−6.9
1
1
0
0
⎤
⎦x1 +
⎡
⎣
y2
12x12
y11x12
x11 sin y11
⎤
⎦
+
⎡
⎣
0
0
1
⎤
⎦(u1 + Δg1(x1)) + H1(x)
(9.33)

438
Chapter 9. Decentralized Sliding-Mode Control
˙x2
=
⎡
⎣
−5.9
0
1
0
−6.9
1
1
0
0
⎤
⎦x2 +
⎡
⎣
x12
y21x23
0
⎤
⎦
+
⎡
⎣
0
0
1
⎤
⎦(u2 + Δg2(x2)) + H2(x)
(9.34)
yj
=
1
1
0
0
0
1

xj
j = 1, 2
(9.35)
where xj = col(xj1, xj2, xj3) and yj = col(yjl, yj2) are, respectively, the state
variables and outputs of the ith subsystem for j = 1, 2. The uncertainties are
assumed to satisfy
∥Δg1(x1)∥
≤
∥y1∥sin2 y12 := ρ1(y1),
∥Δg2(x2)∥
≤
(y21 + y22)2 := ρ2(y2)
and the interconnections satisfy
∥H1(x)∥
≤
(x21 + x22)2 sin2 x13 := η1(x)
∥H2(x)∥
≤
1
4(|x13| + |x23| + |x11 + x12|) := η2(x)
Clearly Assumption 9.1.1 is satisﬁed since CjBj = [0 1]t and thus is full rank.
Applying the algorithm of [65], the coordinate transformation ˜xj = ˜Tjxj with
˜T1 = ˜T2 =
⎡
⎣
1
0
0
1
1
0
0
0
1
⎤
⎦
yields the canonical form (9.9) as follows:
 ˜A111
˜A112
˜A121
˜A122

=
⎡
⎢⎢⎢⎢⎢⎣
−7.9
0
...1
−1
−6.9
...2
· · ·
· · ·
· · ·
1
0
...0
⎤
⎥⎥⎥⎥⎥⎦
(9.36)
 ˜A211
˜A212
˜A221
˜A222

=
⎡
⎢⎢⎢⎢⎢⎣
−5.9
0
...1
1
−5.9
...2
· · ·
· · ·
· · ·
1
0
...0
⎤
⎥⎥⎥⎥⎥⎦
(9.37)

9.1. Robust Sliding-Mode Control
439
with
˜B12 = ˜B22
and
˜C12 = ˜C22 = I2
(9.38)
It is easy to check that Assumption 9.1.2 is satisﬁed with the choice K1 =
K2 = 0 due to the stability of ˜A111 and ˜A211. Since (9.36)-(9.38) already has
the canonical form (9.12), (9.13), it follows that
T1 = ˜Tj,
Aj11 = ˜Aj11,
Bj2 = ˜Bj2,
Cj2 = ˜Cj2
for j : 1, 2. In addition, the components of the nonlinearities
Γ11(y1) =
−y2
12
y2
12
−y2
12
y2
12

and
Γ21(y2) =
1
0
1
0

According to [65], we have
F1 = F2 = [0
1]
and the designed sliding surface from (9.10) is described by σ = 0 which
implies yj2 = 0 for j = 1, 2. Choosing Q1 = Q2 = 7.5I2 and solving the
Lyapunov equation (9.14) yield
P1 =
0.5032
−0.0377
•
0.5698

,
P2 =
0.6735
0.0440
•
0.5988

By considering the switching surface σ = 0, it is straightforward to show that
γl = 0, and ∥R1∥= 0 since Γ11(y1)|σ=0 = 0. By direct computation, ∥R21∥=
1.6598. Furthermore, since ∥Tj∥= l.6l8 and ∥H2(z)∥σ=0 ≤
1
4∥z∥, γ2 =
1.618/4 = 0.4045. Then from (9.17), it follows that
Mt + M =
15.98
−0.56
•
11.68

> 0
This implies, from Theorem 9.1.7, the designed sliding mode is globally
asymptotically stable. It follows that
η1(x)∥F1C1∥+ η2(x)∥F2C|2∥
= y2
21 sin2 y12 + 1
4(|y12| + |y22| + |y11|)
≤1
4(|y11| + |y12|) + 1
2 sin4 y12 + 1
2y4
21 + 1
4|y22|
and to satisfy the reachability condition (9.26), the control gains can be chosen
as
k1(y1)
=
1
4(|y11| + |y12|) + 1
2 sin4 y12 + α1
k2(y2)
=
1
2(y4
21 + 1
4|y22| + α2

440
Chapter 9. Decentralized Sliding-Mode Control
where α1 and α2 are any positive constants. From (9.24), Υ11(y1) = 1 +
sin y11 and Υ21(y2) = 1. Therefore, by Corollary 9.1.12, system (9.33)-(9.35)
is globally stabilizable by the control
u1
=
−y12
|y12|(|1 + sin y11||y11 + yl2| + ∥y1∥+ sin2 y12 + k1)
u2
=
−y22
|y22|(|y21 + y22| + (y21 + y22)2 + k2)
It should be emphasized that the example above yields a global result and
has the following characteristics:
(i) the nonlinearity fj(xj) cannot be bounded by a linear function of ∥xj∥
globally;
(ii) the interconnection is nonlinear with unknown structure;
(iii) the interconnection and fj(xj) are both mismatched;
(iv) the condition FCA = XC employed in [395] is not satisﬁed for any
X for the system (Aj, Bj, Cj) with j = 1, 2. Therefore, existing decentralized
output feedback schemes [140, 172, 302] are not applicable here. Furthermore,
the schemes of [65, 159, 395] cannot be used even if a centralized control
scheme is allowed.
9.2
Delay-Dependent Sliding-Mode Control
In this section, we direct attention to the problem of global decentralized sta-
bilization of a class of interconnected delay systems, where both known and
uncertain interconnections involve time delay. Matched and mismatched inter-
connections are considered separately to reduce the conservatism. A composite
sliding surface is designed and the stability of the associated sliding motion,
which is governed by a time-delay interconnected system, is analyzed based
on the Razumikhin Lyapunov approach. A decentralized static output feedback
variable structure control which is delay-dependent synthesized to drive the
interconnected system to the sliding surface globally.
Recently, various control approaches have been employed to deal with
time-delay control systems and the reader is referred to Chapter 6 for a re-
cent account. Sliding-mode control, as one of the discontinuous control ap-
proaches, is completely robust to so-called matched uncertainty, and can be
used to deal with mismatched uncertainty [380]. Since sliding-mode dynamics
are reduced-order, it is possible to reduce the conservatism in the stability anal-
ysis of the sliding motion. This has motivated the application of sliding-mode
techniques to time-delay systems [90, 285]. However most of the published

9.2. Delay-Dependent Sliding-Mode Control
441
work focuses on centralized control systems. The results of applying sliding-
mode techniques to time-delayed interconnected systems are very few. In the
limited available literature [113, 320, 379], it is required that all states are avail-
able and the interconnections are linear and matched. The assumption that all
the terms involving time-delay are matched means that the sliding mode is no
longer a time-delay system.
In what follows, extending the material of Chapter 6, a class of nonlin-
ear interconnected systems with time-varying delays is considered, where the
time-delay appears not only in the isolated subsystems, but also in the inter-
connections. The interconnections are separated as matched and mismatched
parts and are dealt with separately to reduce the conservatism. By using appro-
priate coordinate transformations, sliding-mode dynamics are derived which
are reduced-order time-delayed interconnected systems. Sufﬁcient conditions
are developed using a Razumikhin-Lyapunov approach such that the sliding
motion is uniformly globally asymptotically stable. A decentralized control
scheme based on only output information is proposed to drive the system to
the composite sliding surface. It is shown that the effect of the interconnections
can be canceled by designing an appropriate decentralized controller under ap-
propriate conditions.
9.2.1
System description
Consider a time-varying delayed interconnected system composed of ns sub-
systems, where the jth subsystem has nj-th order and is described by
˙xj = Ajxj + Bj

uj + Gj(t, xj, xj(t −dj(t)))

+
n

k=1 k̸=j

Hjkyj(t −dj(t)) + ΔHij(t, xj, xj(t −dj(t)))

(9.39)
yj = Cjxj,
j = 1, 2, ..., ns
(9.40)
where xj ∈ℜnj, uj ∈ℜmj, and yj ∈ℜpj with mj ≤pj < nj are the state
variables, inputs, and outputs, of the ith subsystem, respectively. The triples
(Aj, B)i, Cj) and Hjk ∈ℜnj×pj with i ̸= j represent constant matrices of
appropriate dimensions with Bj and Cj of full rank. The function Gj(.) is a
matched nonlinearity in the ith subsystem. n
k=1,k̸=j Hjkyk(t −dk(t)) and
n
k=1,k̸=j ΔHjk(t, xk, xk(t −dk(t))) are, respectively, a known interconnec-
tion and an uncertain interconnection of the ith subsystem. The factor dj(t) is
the time-varying delay which is known continuous, nonnegative, and bounded
in ℜ+, and thus dj := supt∈ℜ+{dj(t)} < ∞. The initial conditions are given

442
Chapter 9. Decentralized Sliding-Mode Control
by
xj(t) = φj(t),
t ∈[−¯dj, 0]
for j = 1, 2, ..., n. All the nonlinear functions are assumed to be smooth
enough such that the unforced system has a unique continuous solution.
For convenience, a variable/vector with subscript dj is introduced to denote
the time-delayed variable throughout this section, for example, xjdj(t) denotes
xj(t −dj(t)) and yjdj(t) represents yj(t −dj(t)). It is known that the sliding
motion is insensitive to matched uncertainty and hence it is useful to separate
the treatment of matched interconnections from mismatched interconnections
to reduce conservatism. Accordingly, we consider the decompositions of the
interconnections:
Hjk
=
Ha
jk + Hb
jk
(9.41)
ΔHjk(t)
=
ΔHa
jk(t, xk, xkdk) + ΔHb
jk(t, xk, xkdk)
(9.42)
where
Ha
jk
=
BjDjk
(9.43)
ΔHa
jk(t, xk, xkd)
=
BjΔΘjk(t, xk, xkdk)
(9.44)
where for some ΔΘjk(.) ∈ℜmj and Djk ∈ℜmj×pj where ΔΘjk(.) is uncer-
tain for i ̸= j, i, j = 1, 2, ..., n. It must be asserted that the decompositions
in (9.41) and (9.42) that satisfy (9.43) and (9.44) can be readily obtained from
basic matrix operations.
Assumption 9.2.1 There exist known continuous functions gj(.), αjk(.), and
βjk(.) such that
∥Gj(t, x, xidj)∥
≤
gj(t, yj, yjdj)
(9.45)
∥ΔΘjk(t, xj, xkdk)∥
≤
αjk(t, yj, yjdj)∥yjdj∥
(9.46)
∥ΔHb
jk(t, xj, xkdk)∥
≤
βjk(t, yj, ∥yjdj∥)∥yjdj∥
(9.47)
for j ̸= k, j, k = 1, 2, ..., ns where βjk(., ., r) is nondecreasing with respect to
the variable r in ℜ+.
It follows from (9.42), (9.44), (9.46), and (9.47) that there exist known contin-
uous functions ρjk(.) such that
∥ΔHjk(t, xk, xkdk)∥≤ρjk(t, yk, ykdk)∥ykdk∥for j, k = 1, 2, ..., ns, j ̸= k
(9.48)

9.2. Delay-Dependent Sliding-Mode Control
443
It must be observed that Assumption 9.2.1 limits the type of uncertainties that
can be tolerated by the interconnected system to be bounded by functions of the
system outputs. Since the interconnections involve time-delays, the bounding
functions are nonlinear and depend on the delayed information.
Assumption 9.2.2 rank(CjBj) = mj for i = 1, 2, ..., ns.
Assumption 9.2.2, in light of [67], implies that there exists a nonsingular linear
coordinate transformation
˜xj = ˜Tjxj
such that the triple (Aj, Bj, Cj) with respect to the new coordinates has the
structure
˜Aj =
 ˜Aj1
˜Aj2
˜Aj3
˜Aj4

,
˜Bj =
 0
˜Bj2

,
˜Cj = [0
˜Cj2]
(9.49)
where ˜Aj1 ∈ℜ(nj−mj)×(nj−mj), ˜Bj2 ∈ℜmj×mi is nonsingular, and ˜Cj2 ∈
ℜpj×pj is orthogonal.
Assumption 9.2.3 The triple ( ˜Aj1, ˜Aj2, Ξj) is output feedback stabilizable,
where for j = 1, 2, ..., ns
Ξj := [0(pj−mj)×(nj−pj)
Ipj−mj]
We note that ˜Aj1, ..., ˜Aj4, ˜Bj2, ˜Cj2 are dependent on the coordinate trans-
formation employed. Assumptions 9.2.2 and 9.2.3 together describe inherent
properties of the triplet (Aj, Bj, Cj).
More importantly, Assumption 9.2.3 implies that there exists a matrix ˜Kj
such that Aj1 = ˜Aj1 −˜Aj2 ˜KjΞj is stable. From [67], the coordinate transfor-
mation
˜xj →zj = ¯Tj˜xj
where
¯Tj =

I
0
−˜KjΞj
I

i = 1, 2, ..., ns
(9.50)
will transform the triple (Aj, Bj, Cj) to the following form in the new coordi-
nate system
Aj1
Aj2
Aj3
Aj4

,
 0
Bj2

,

0
Cj2

(9.51)
where Ai1 =
˜Aj1 −˜Aj2 ˜KjΞj is stable and both Bj2 ∈ℜmj×mj and
Cj2 ∈ℜpj×pj are nonsingular. In the sequel, we assume that mj < pj. In
case that mj = pj, then Assumption 9.2.3 can then be replaced by the stan-
dard assumption that ˜Aj1 is stable.

444
Chapter 9. Decentralized Sliding-Mode Control
Remark 9.2.4 Assumptions 9.2.2 and 9.2.3 are limitations on the triple
(Aj, Bj, Cj). Effectively, they ensure the existence of the output sliding sur-
face. Assumption 9.2.2 requires ( ˜Ai1, ˜Ai2, Ξj) instead of (Aj, Bj, Cj) to be
output feedback stabilizable. Note that the former is related to a system with
order nj −mj, while the latter is an nj-order system. Sometimes this reduced
order problem is more amenable to solution, for example, if the matrix triple
is related to a one-input and two-output system, the output feedback problem
reduces to a classical root-locus investigation.
In the sequel, we seek to design a variable structure control law of the form
uj = uj (t, yj, yjdj)
(9.52)
based on sliding-mode techniques such that the associated closed-loop system
formed by applying the control law (9.52) to the interconnected system (9.39)
and (9.40) is globally uniformly asymptotically stable even in the presence of
the uncertainties and time-delays. It is evident that the control uj in (9.52)
depends on the time t, the jth subsystem output yj, and the delayed output
yjdj, which is available since the delay d(t) := (d1(t), d2(t), ..., dns(t)) is
assumed to be known.
9.2.2
Stability analysis
In the following, we consider that Assumptions 9.2.2 and 9.2.3 hold. Let
Fj := Fj2

Kj
Imj
 ˜Ct
j2,
j = 1, 2, ..., ns
(9.53)
where Fj2 ∈ℜmj×mj is any nonsingular matrix, Kj is related to ˜Kj, and ˜Cj2
is given in (9.49). It has been shown in [67] that Fj deﬁned in (9.53) satisﬁes
Fj

0
˜Cj2

=

0
Fj2

(9.54)
where Fj2 ∈ℜmj×mj is nonsingular. Then, for the interconnected system
(9.39) and (9.40), consider the composite sliding surface deﬁned by
{col(x1, x2, ..., xns)
|
Sj(xj) = 0,
j = 1, 2, ..., ns}
(9.55)
where
Sj(xj) := FjCjxj = Fjyj
(9.56)
and the matrices Fj for j = 1, 2, ..., n are given in (9.53). Under Assump-
tions 9.2.2 and 9.2.3, it follows from the foregoing analysis that there exists a
coordinate transformation
xj →zj = Tjxj, j = 1, 2, ..., ns

9.2. Delay-Dependent Sliding-Mode Control
445
such that in the new coordinates
z = col(z1, z2, ..., zns)
system (9.39) and (9.40) can be described by
˙zj
=
Aj1
Aj2
Aj3
Aj4

zj +
 0
Bj2

(uj + Gj(t, T −1
j
zj, T −1
j
zjdj)
+
ns

k=1,k̸=j
(Djkykdk + ΔΘjk(t, T −1
k zk, T −1
k zkdk)))
+
ns

k=1,k̸=j
Tj(Hb
jkykdk + ΔHb
jk(t, T −1
k zk, T −1
k zkdk))
(9.57)
yj
=

0
Cj2

zj,
j = 1, 2, ..., ns
(9.58)
where Aj1 = ˜Aj1 −˜Aj2KjΞj ∈ℜnj−mj is stable, both Bj2 ∈ℜmj×mj and
Cj2 ∈ℜpj×pj are nonsingular, Ha
jk(.) and Hb
jk(.),
ΔΘjk(.) and ΔHb
jk(.)
are given in (9.41), (9.44), and (9.42), respectively. Since Aj1 is stable, for any
Qj > 0, the Lyapunov equation
At
j1Pj + PjAj1 = −Qj
(9.59)
has a unique solution Pj > 0 for j = 1, 2, ..., n. For convenience, we partition
Tj ≡:
Tj1
Tj2

,
T −1
j
≡:

Wj1
Wj2

(9.60)
where Tj1 ∈ℜ(nj−mj)×nj and Wj1 ∈ℜnj×(nj−mj). Combining (9.56) and
(9.57), we get
˙zj1
=
Aj1zj1 + Aj2zj2 +
n

k=1,k̸=j
Tj1(Hb
jkykdk
+
ΔHb
jk(t, T −1
k zk, T −1
k zkdk))
(9.61)
˙zj2
=
Aj3zj1 + Aj4zj2 + Bj2(uj + Gj(.)
+
n

k=1,k̸=j

Djkykdk + ΔΘjk(t, T −1
k zj, T −1
k zkdk)

)
+
n

k=1,k̸=j
Ti1

Hb
jkykdk + ΔHb
jk(t, T −1
k zk, T −1
k zkdk)

(9.62)
yj
=

0
Cj2

zj,
i = 1, 2, ..., ns
(9.63)

446
Chapter 9. Decentralized Sliding-Mode Control
where zj := col(zi1, zi2) with zi1 ∈ℜnj−mj and zi2 ∈ℜmj. From (9.56),
(9.63), and (9.53), we obtain
Sj(xj)
=
Fjyj = Fj

0
Cj2

zj
=

0
Fj2
  zj1
zj2

= Fj2zj2
where Fj2 ∈ℜmj×mj is nonsingular. Therefore, in the new coordinates z, the
sliding surface (9.55) can be described by
{col(z1, z2, ..., zns)
|
zj2 = 0,
i = 1, 2, ..., ns}
In a similar way, we partition the output distribution matrix in (9.63) as

0
Cj2

= [0
Cj21
? @= >
Cjs
|
Cj22]
(9.64)
where Cjs :=

0
Cj21

∈ℜpj×(nj−mj) and Cj22 ∈ℜpj×mj. When con-
strained along the sliding surface, the jth subsystem output yj is then described
by
yjs :=

0
Cj21

zj1 = Cjszj1,
j = 1, 2, ..., ns
(9.65)
Now we take a look at the structure of system (9.61)-(9.62) in view of the par-
tition for T −1
j
in (9.60). We observe that the sliding-mode dynamics of system
(9.39)-(9.40) associated with the sliding surface (9.55)-(9.56) can be expressed
by
˙zj1
=
Aj1zj1 +
n

k=1,k̸=j
Tj1(Hb
jkCkszk1dk
+
ΔHb
jk(t, Wk1zk1, Wk1zk1dk))
(9.66)
where Wj1 is deﬁned by the partition (9.60) for j = 1, 2, ..., ns.
Theorem 9.2.5 Assume that Assumptions 9.2.1 - 9.2.3 hold. Then, for the slid-
ing surface in (9.55), the sliding motion of the interconnected time-delay sys-
tem (9.39)-(9.40) is governed by dynamical system (9.66). Moreover, the sliding
motion is globally uniformly asymptotically stable if
(i) The nj × nj symmetric matrix
Nj := Qj−PjTj1(
ns

k=1,k̸=j
1
εj
Hb
jkCksP −1
k Ct
ks(Hb
jk)t)T t
j1Pj−
ns

k=1,k̸=j
εkPk > 0

9.2. Delay-Dependent Sliding-Mode Control
447
for some εj > 0 for j = 1, 2, ..., ns
(ii) The n × n matrix function M + Mt > 0 where M = [mjk(.)]n×n is
deﬁned by
mjk(.) :=
 λmin(Nj),
j = k
−γjβjk(t, Cjszj1γk∥Cjs∥∥zk1∥)∥PjTj1∥∥Cks∥,
j ̸= k
for some γj > 1 for j, k = 1, 2, ..., ns and
μ :=
inf
z11,...,zns1{λmin(M + Mt)} > 0
Proof: It sufﬁces to focus on the system described in (9.66) and show that it
is globally uniformly asymptotically stable. Consider the Lyapunov function
candidate
V (z11, z21, ..., zns1) =
ns

j=1
zt
j1Pjzj1
where Pj > 0 satisﬁes (9.59) for j = 1, 2, ..., ns. A little algebra shows that
the time derivative of V (.) along the trajectories of system (9.66) using (9.59)
is given by
˙V
=
−
ns

j=1
zt
j1Qjzj1 + 2
n

j=1
ns

k=1,k̸=j
zt
j1PjTj1Hb
jkCkszk1dk
+
2
ns

j=1
ns

k=1,k̸=j
zt
j1PjTj1ΔHb
jk(.)
(9.67)
By Inequality 2 of the Appendix, for any εj > 0, we have
2zt
j1PjTj1Hb
jkCkszk1dk ≤1
εk
zt
j1PjTj1Hb
jkCksP −1
k (Tj1Hb
jkCks)tPjzj1
+εkzt
k1dkPkzk1dk
(9.68)
Since the zj1 for j = 1, 2, ..., n are independent of each other, it is clear that
V (z11d1, z21d2, ..., zns1dn) ≤q V (z11, z21, ..., zns1)
for q > 1, is equivalent to
zt
j1djPjzj1dj ≤q zt
j1Pjzj1,
j = 1, 2, ..., ns
(9.69)

448
Chapter 9. Decentralized Sliding-Mode Control
which implies
∥zj1dj∥≤γj∥zj1∥,
j = 1, 2, ..., ns
(9.70)
for some positive constants γj > 1 with j = 1, 2, ..., n. It follows from (9.65)
and (9.70) that
∥yisdj∥= ∥Cjszj1dj∥≤γj∥Cjs∥∥zij∥
(9.71)
Since βjk(t, yks, r) is nondecreasing with respect to the variable r ∈ℜ+, it
follows from (9.47), (9.71), and (9.65) that
PjTj1ΔHb
jk(.) ≤γkβjk(t, Ckszk1, γk∥Cks∥∥zk1∥)∥PjTj1∥∥Cks∥∥zk1∥
(j ̸= k)
(9.72)
Therefore, from (9.47), (9.68), and (9.72), it follows that when
V (z11d1, z21d2, ..., zns1dn) ≤qV (z11, z21, ..., zns1)
˙V ≤−
ns

j=1
zt
j1Qjzj1
+
ns

j=1
ns

k=1,k̸=j
 1
εk
zt
j1PjTj1Hb
jkCksP −1
k (Tj1Hb
jkCks)tPjzj1

+
ns

j=1
ns

k=1,k̸=j
εkzt
k1PkTk1
+
2
ns

j=1
ns

k=1,k̸=j
γkβjk(t, Ckszk1, γk∥Cks∥∥zk1∥)∥PjTi1∥∥Cks∥∥zk1∥∥zj1∥
≤−
ns

j=1
zt
j1Njzj1
+
2
ns

j=1
ns

k=1,k̸=j
γkβjk(t, Ckszk1, γk∥Cks∥∥zk1∥)∥PjTi1∥∥Cks∥∥zk1∥∥zj1∥
= −1
2Z(M + Mt)Zt
≤−1
2
inf
z11,...,zn1{λmin(M + Mt)}
ns

j=1
∥zj1∥2
(9.73)
= −1
2μ∥z∥2
(9.74)

9.2. Delay-Dependent Sliding-Mode Control
449
where
z = col(z1, z2, ..., zn), Z = [∥z11∥∥z21∥...∥zns1∥]
and the fact zt
j1Njzj1 ≥λmin(N)∥zj1∥2 has been used. Since μ > 0, the
conclusion follows from the basic Razumikhin theorem.
Remark 9.2.6 If mr0 = pr0 for the r0-th (1 ≤r0 ≤n) subsystem, then
yr0 = zr02, and thus from (9.65), yr0s = 0. In this case, from the proof of
Theorem 9.2.5, condition (i) can be weakened by
Nj =
Qj −PjTi1(n
j=1,j̸=i,r0
1
εj Hb
jkCjsP −1
j
Ct
js(Hb
jk)t)
−n
j=1,j̸=i,r0 εjPj > 0,
i = 1, 2, ..., n
9.2.3
Reachability analysis
We now proceed to design a decentralized static output feedback sliding-mode
control such that the system states are steered along the sliding surface (9.55)
and (9.56). For interconnected system (9.39) and (9.40), a well-known reacha-
bility condition is described by [109]:
n

j=1
St
j(xj)Sj(xj)
∥Sj(xj)∥
< 0
(9.75)
where the switching function Sj(.) is deﬁned by (9.56). To proceed further, the
following condition is imposed on system (9.39)-(9.40).
Assumption 9.2.7 The matrix equation ΓjCj = CjAj is solvable for Γj with
i = 1, 2, ..., ns.
Remark 9.2.8 Assumption 9.2.7 implies that there exist matrices Γj with i =
1, 2, ..., ns such that
Ct
jΓt
j = At
jCt
j, j = 1, 2, ..., ns
This ensures that the linear algebraic equations
Ct
jΓℓ
j = (t
jCt
j)ℓ, j = 1, 2, ..., ns, ℓ= 1, 2, ..., pj
are solvable for Γℓ
j.
The following result will be used in the subsequent analysis.

450
Chapter 9. Decentralized Sliding-Mode Control
Lemma 9.2.9 Assume Hjk ∈ℜnj×pj with nj and pj positive integer numbers,
and x = col(x1, x2, ..., xn) where xj ∈ℜnj for i = 1, 2, ..., n. Then
(1)
||x|| ≤xtsgn(x)
(2)
ns

j=1
ns

k=1,k̸=j
Hjkxk =
ns

j=1
⎛
⎝
ns

k=1,k̸=j
Hkj
⎞
⎠xj
where sgn(.) denotes the usual vector signum function.
Proof: Condition (1) follows from [381]. To show condition (2) we proceed
from the fact that ns
j=1
ns
k=1 Hjkxk = ns
k=1
ns
j=1 Hjkxk. It follows that
ns

j=1
ns

k=1,k̸=j
Hjkxk =
ns

j=1
ns

k=1
Hjkxk −H11x1 −H22x2 −... −Hnsnsxns
=
ns

j=1
ns

k=1
Hjkxk −
n

k=1
Hkkxk
=
ns

j=1
(
ns

k=1
Hjk −Hkk)xk
=
ns

j=1
ns

k=1,k̸=j
Hkj)xj
The main result is now provided.
Theorem 9.2.10 Consider the interconnected time-delay system (9.39) and
(9.40). Under Assumptions 9.2.1-9.2.7, there exists a global delay-dependent
static output feedback decentralized control law that drives the system (9.39)
and (9.40) to the composite sliding surface (9.55) and (9.56) and maintains a
sliding motion on it thereafter.
Proof: Since the triple in (9.51) is obtained from (Aj, Bj, Cj) using the trans-
formation zj = Tjxj, it follows that
TjBj =
 0
Bj2

, CjT −1
j
= [0
Cj2]

9.2. Delay-Dependent Sliding-Mode Control
451
where both Bj2 ∈ℜmj×mj and Cj2 ∈ℜpj×pj are nonsingular. In view of
(9.54), we have
FjCjBj = Fj[0
Cj2]
 0
Bj2

= Fj2Bj2
which shows that FjCjBj is nonsingular because Fj2 and Bj2 are nonsingular.
Construct a variable structure control
uj = −(FjCjBj)−1FjΓjyj −(FjCjBj)−1

∥FjCjBj∥gj(t, yj, yidj)
+
ηj

sgn(Fjyj)
−
(FjCjBj)−1

ns

k=1,k̸=j
∥FkCkHjki∥)∥yjdj∥sgn(Fjyj)

−
(FjCjBj)−1

ns

k=1,k̸=j
∥FkCk∥ρkj(.))∥yjdj∥sgn(Fjyj)

(9.76)
where gj(.), βjk, and ρjk(.)(i ̸= j) are deﬁned by (9.45), (9.47), and (9.48),
respectively; ηj can be chosen as any positive constant for j, k = 1, 2, ..., ns
and the symbol sgn(.) denotes the usual signum vector function. From (9.39),
(9.56), and (9.48), it follows that under Assumption 9.2.7
ns

j=1
St
j(xi) ˙Sj(xj)
∥Sj(xj)∥
≤
ns

j=1
(Fjyj)t
∥Fjyj∥FjΓjyj
+
ns

j=1
(Fjyj)t
∥Fjyj∥FjCjBj(uj + Gj(t, xj, xjdj))
+
ns

j=1
ns

k=1,k̸=j
∥FjCjHjk∥∥ykdk∥
+
ns

j=1
ns

k=1,k̸=j
ρjk(t, yk, ykdk)∥FjCj∥∥ykdk∥
(9.77)

452
Chapter 9. Decentralized Sliding-Mode Control
Substituting the control of (9.74) into (9.77) and using Lemma 9.2.9, it follows
from (9.45) that
ns

j=1
St
j(xj) ˙Sj(xj)
∥Sj(xj)∥
≤
ns

j=1
(−(Fjyj)tsgn(Fjyj)
∥Fjyj∥
∥FjCjBj∥gj(t, yj, yidj)
+
∥FjCjBj∥∥Gj(t, xj, xjdj)∥) −
ns

j=1
(Fjyj)tsgn(Fjyj)
∥Fjyj∥
ηj
−
ns

j=1
(Fjyj)tsgn(Fjyj)
∥Fjyj∥
(
ns

k=1,k̸=j
∥FkCkHkj∥)∥yjdj∥
+
ns

j=1

ns

k=1,k̸=j
∥FjCjHkj∥

∥yjdj∥
−
ns

j=1
(Fjyj)tsgn(Fjyj)
∥Fjyj∥
ns

k=1,k̸=j
ρkj(t, yj, yjdj)∥FjCj∥∥ykdk∥
+
ns

j=1
ns

k=1,k̸=j
ρjk(t, yk, ykdk)∥FkCk∥∥ykdk∥< 0
which concludes the proof.
From sliding mode control theory, it follows that Theorems 9.2.5 and
9.2.10 together show that the developed decentralized control law (9.76) uni-
formly asymptotically stabilizes system (9.39)-(9.40) globally.
9.2.4
Illustrative example 9.2
Consider an interconnected time-delay system of the type (9.39)-(9.40) with
the following data:
A1
=
⎡
⎣
−8
0
1
0
−8
1
1
1
0
⎤
⎦, B1 =
⎡
⎣
0
0
1
⎤
⎦,
G1
=
(x11 + x12)2x13d1 sin x12d1Δg1(.), H12 =
⎡
⎣
0
−1
1
0
4
1
⎤
⎦,

9.2. Delay-Dependent Sliding-Mode Control
453
A2
=
⎡
⎣
−6
0
1
0
−6
1
1
1
0
⎤
⎦, B2 =
⎡
⎣
0
0
1
⎤
⎦,
G2
=
Δg2(.), H21(.) =
⎡
⎣
4(x11d1 + x12d1)(sin x13)2Δh1(.)
4(sin x13)2x13d1(Δh1(.))2
(x11 + x12)x13d1(sin x11d1)2Δh2(.)
⎤
⎦,
C1
=
 1
1
0
0
0
1

, C1 =
 1
1
0
0
0
1

where x1 = col(x11, x12, x13) ∈ℜ3 and x2 = col(x21, x22, x23) ∈ℜ3,
u1 ∈R and u2 ∈R, and y1 = col(y11, y12) ∈ℜ2 and y2 = col(y21, y22) ∈
ℜ2 are, respectively, the state variables, inputs and outputs of the system. The
uncertainties Δg1(.), Δg2(.), Δh1(.), and Δh2(.) are assumed to satisfy
 |Δg1(.)| ≤(x13d1)2 sin 2(x11 + x12)
|Δh1(.)| ≤1
|Δg2(.)| ≤|x21d2 + x22d2|x2
23d2 sin 2x22
|Δh2(.)| ≤|y1d1|

Note thatΔH12 = 0 and ΔH21 = 0 and the decomposition in the form of
(9.41) and (9.42) is given by
Ha
12 =
⎡
⎣
0
0
0
0
4
1
⎤
⎦,
Hb
12 =
⎡
⎣
0
−1
1
0
0
0
⎤
⎦
(9.78)
ΔHa
12 = ΔHb
12 = 0,
Ha
21 = Hb
21 = 0
(9.79)
Ha
21 =
⎡
⎣
0
0
(x11 + x12)x13d1(sin x11d1|)2Δh2(.)
⎤
⎦
(9.80)
Hb
21 =
⎡
⎣
4(x11d1 + x12d1)(sin x13)2Δh1(.)
4(sin2(x13))x13d1(Δh1(.))2
0
⎤
⎦
(9.81)
It is easy to check that Assumption 9.2.1 is satisﬁed with
g1(.)
=
y2
11|y12d1|3 sin2(y1),
g2(.) = |y21d2|y2
22,
α12(.)
=
0,
α21(.) = |y11y12d1|
β12(.)
=
0,
β21(.) = 4 sin2(y12),
ρ12(.)
=
0,
|rho21(.) =

16 sin4(y12) + y2
11

454
Chapter 9. Decentralized Sliding-Mode Control
and Assumption 9.2.2 holds. Algebraic manipulation shows that Assumption
9.2.3 is satisﬁed with K1 = ˜K2 = 0, and the coordinate transformation zj =
Tjxj, j = 1, 2 is given by
T1
=
⎡
⎣
0.7071
0.7071
0
−1
−1
0
0
0
−1
⎤
⎦, T2 =
⎡
⎣
0.7071
0.7071
0
−1
−1
0
0
0
−1
⎤
⎦
The sliding surface matrices are F1 =

0
−1

and F2 =

0
−1

.
Let Q1 = Q2 = I2. The corresponding solutions to the Lyapunov equa-
tions (9.59) are
P1 =
 0.0625
0
0
0.0625

,
P2 =
 0.0833
0
0
0.0833

Further, let γ1 = γ2 = 1.1. By direct computation, it is easy to show that
N1 =

0.9108
−0.0083
−0.0083
0.9049

,
N2 =
 0.9375
0
0
0.9375

and
M =

0.8991
0
−0.5185 sin 2(y12)y12
0.9375

It is easy to verify that the conditions in Theorem 9.2.5 are satisﬁed globally.
Accordingly, the sliding motion associated with the sliding surface
{(x11, x12, x13, x21, x22, x23)|x13 = 0, x23 = 0}
is globally uniformly asymptotically stable. Moreover, letting
Γ1 =
−8
2
1
0

and Γ2 =
−8
amp; 2
2
2

It is quite evident that Assumption 9.2.7 holds. Therefore, the decentralized
control law in (9.76) stabilizes the interconnected system under consideration
globally.
9.3
Problem Set VII
Problem VII.1: Consider the following uncertain interconnected time-delay
system
˙xj
=
Ajxj + Adjxj(t −τj(t)) + Bj(uj + ξj(t, xj, uj)),
yj
=
Cjxj,
j = 1, 2, ..., ns

9.3. Problem Set VII
455
where xj ∈ℜnj, uj ∈ℜmj, yj ∈ℜpj are the state, input, and output vectors,
respectively. The time-varying delay is bounded 0 ≤τj(t) ≤dj. The matrices
Bj, Cj are of full rank and the unknown functions ξj(., ., .) are assumed to
satisfy
||ξj(t, xj, uj)||
≤
αj||uj|| + βj(t, yj), αj < 1
j = 1, 2, ..., ns
for some known function βj(t, yj). Assume that rank(CjBj) = mj. Apply
a similar procedure of Section 9.1 to derive a SMC based on the local output
information that guarantees asymptotic stability of the closed-loop system.
Problem VII.2: We consider a nonlinear discrete-time large-scale system
formed by ns coupled subsystems as follows:
xj(k + 1)
=
Ajxj + fj(xj) + Bj(uj + Δgj(xj)) + Hj(x),
yj
=
Cjxj,
j = 1, 2, ..., ns
where, by similarity to the continuous-time case, x = col(x1, x2, ..., xN), xj ∈
ℜnj, uj ∈ℜmj, yj ∈ℜpj are the states, inputs, and outputs of the jth sub-
system, respectively, and mj ≤pj < nj. The triple (Aj, Bj, Cj) repre-
sents constant matrices of appropriate dimensions with Bj, and Cj is of full
rank such that rank(Cj, Bj) = mj
for j = 1, 2, ..., ns. Assume that
fj(xj) = Γj(yj)xj, Γj ∈ℜnj×nj. Considering that there exist known contin-
uous functions ρj(·) and ηj(·) such that for i = l, 2, ..., ns
|Δgj(xj)| ≤ρj(yj), |Hj(x)| ≤ηj(x)
where ηj(·) satisﬁes ηj(x) ≤βj(x)|x| for some continuous function βj. De-
velop a complete analysis and feedback control design to render the closed-loop
system asymptotically stable. Illustrate the basic differences with regards to the
continuous-time case.
Problem VII.3: Consider interconnected discrete-time-delay system com-
posed of ns subsystems where the jth subsystem is described by
xj(k + 1) = Ajxj + Bj

uj + Gj(k, xj, xj(k −τj))

+
n

m=1 m̸=j

Hjmym(t −τm) + ΔHjm(k, xm, xm(k −τm))

,
yj = Cjxj,
j = 1, 2, ..., ns

456
Chapter 9. Decentralized Sliding-Mode Control
where xj ∈ℜnj, uj ∈ℜmj, and yj ∈ℜpj with mj ≤pj < nj being the state
variables, inputs, and outputs of the ith subsystem, respectively. The triples
(Aj, Bj, Cj) and Hjm ∈ℜnj×pm with m ̸= j represent constant matrices of
appropriate dimensions with Bj and Cj of full rank. The function Gj(.) is a
matched nonlinearity in the jth subsystem. The terms
n

m=1,m̸=j
Hjmym(t −τm),
n

m=1,m̸=j
ΔHjm(k, xm, xm(t −τm))
are, respectively, a known interconnection and an uncertain interconnection of
the ith subsystem. The factor τm is the bounded time-varying delay. In addi-
tion, consider the decompositions of the interconnections:
Hjm
=
Ha
jm + Hb
jm,
ΔHjm(t)
=
ΔHa
jm(k, xk, xm(k −τm)),
+
ΔHb
jm(k, xm, xm(k −τm)),
Ha
jm
=
BjDjm,
ΔHa
jm(k, xm, xm(k −τm))
=
BjΔΘjm(k, xm, xm(k −τm))
and assume that there exist known continuous functions gj(.), αjk(.), and
βjk(.) such that
∥Gj(k, xm, xm(k −τm))∥
≤
gj(k, ym, ym(k −τm)),
∥ΔΘjm(k, xm, xm(k −τm))∥
≤
αjm(k, ym, ym(k −τm))∥ym(k −τm)∥,
∥ΔHb
jk(k, xm, xm(k −τm))∥
≤
βjm(k, ym, ∥ym(k −τm)∥)∥ym(k −τm)∥
for j ̸= m, j, m = 1, 2, ..., ns where βjm(., ., r) is nondecreasing with respect
to the variable r in ℜ+. Develop a complete analysis and feedback control de-
sign to render the closed-loop system asymptotically stable. Illustrate the basic
differences with regards to the continuous-time case.
Problem VII.4: A class of uncertain interconnected time-delay systems is de-
scribed by
˙xj
=
Ajxj +
ns

k=1,k̸=j
Ajk(t)xk(t −τk(t)) + Bj(uj + gj(t, xj, uj, σj))
where xj ∈ℜnj, uj ∈ℜmj, σj ∈ℜpj are the state, input, and uncertain pa-
rameter vectors, respectively. The time-varying delay is bounded 0 ≤τj(t) ≤
τM. The matched perturbations are summarized by gj(t, xj, uj, σj) ∈ℜmj,

9.4. Notes and References
457
the matrix pairs (Aj, Bj), j = 1, ..., ns are completely controllable. Let the
delayed uncertainties be matched and satisfy the unknown functions ξj(., ., .)
as assumed to satisfy
Ajk = BjGjk(t),
||Gjk(t)|| ≤αjk, αjk ≥0,
j, k = 1, 2, ..., ns
Consider the case where the lumped perturbations gj(t, xj, uj, σj) are bounded
in the form
||gj(t, xj, uj, σj)|| ≤ρj||xj(t)|| + φj||uj(t)|| + ψj
In terms of the local switching surface
Ωj(t) = B†
jxj(t) −
 t
0
(B†
jAj + Kj)xj(s)ds
where Ωj(t)ℜmj, Kj ∈ℜMj×nj, B†
j ∈ℜMj×nj with B†
j being the general-
ized inverse of Bj and the gain matrix Kj satisﬁes λj(Aj +BjKj) < 0. Apply
a similar procedure of Section 9.2 to derive an appropriate SMC based on the
local output information that guarantees asymptotic stability of the closed-loop
system. Illustrate your results on the data:
A1
=

0
1
−2
1

, B1 =
 0
1

,
A2
=

0
1
−3
2

, B2 =
 0
1

,
A12
=

0
0
sin(t)
0.3cos(2t)

,
A21
=

0
0
1 + sin(t)
1 + 0.3cos(2t)

,
||g1(t, x1, u1, σ1)||
≤
(0.5 + 0.2sin(t))||x1(t) + 0.2cos(t)||u1(t)|| + 0.4,
||g2(t, x2, u2, σ2)||
≤
(1 −2sin(3t))||x2(t) + 0.2expcos(t)||u2(t)||
+ 0.2sin(t),
τ1(t)
=
(|0.4 −0.1sin(t))|, τ2(t) = (|0.3 −0.2cos(2t))|,
τM
=
0.5,
φ1
=
0.205, φ2 = 0.544
9.4
Notes and References
This chapter has adopted a sliding-mode control strategy to stabilize a class of
nonlinear interconnected systems with mismatched uncertainty that uses only

458
Chapter 9. Decentralized Sliding-Mode Control
static output feedback. A composite sliding surface is ﬁrst constructed and sub-
sequently, a decentralized control scheme is synthesized. A reachability con-
dition is developed for the interconnected system. In certain situations global
results can also be obtained and it is shown that the results are applicable to a
wide class of interconnected systems.
The methods and results have been given for systems in continuous-time
domain. We observed that it requires high-speed discontinuous action to steer
the states of a system into a sliding surface and to maintain subsequent mo-
tion along this surface. Applying a discrete-time sliding-mode approach would
have the beneﬁt of reducing the chattering phenomenon that arises in computer-
control applications. It is suggested to pursue further research work on applying
delta operator within sliding-mode control for interconnected systems. Extend-
ing the work to time-interval-delay systems will support the method presented
in this chapter. Also, incorporating the results of [381, 382, 403] will yield
improved development of sliding-mode control techniques for interconnected
systems with and without time-delays.

Chapter 10
Decentralized Filtering-I
In this chapter, we continue our evaluation of the development of large-scale
systems theories and techniques, where we focus herein on decentralized ﬁlter-
ing and estimation techniques with particular considerations to robustness and
resilience issues.
10.1
Introduction
For dynamical systems, the topic of robust ﬁltering arose in view of the desire
to determine estimates of nonmeasurable state variables when the system un-
dergoes parametric uncertainties. From this perspective, robust ﬁltering can be
viewed as an extension of the celebrated Kalman ﬁlter to uncertain dynamical
systems. The past decade has witnessed major developments in robust ﬁlter-
ing problems [24, 75, 83, 278, 313, 375]. There have been two basic cate-
gories of approaches: the ﬁrst is based on the Riccati equation (RE) through
the search of appropriate scaling parameters and the other relies on feasibil-
ity testing of linear matrix inequalities (LMIs) formulation. The later approach
has gained widespread popularity in view of the development of the interior
point algorithm for convex optimization. When dealing with large-scale or in-
terconnected systems, the topic becomes more compounded as one has to be
careful with the issues of dimensionality, nonlinearities, and/or robustness. For
a constructive approach to decentralized control of large-scale systems, see the
results reported in [324, 328]. It seems that the topic of decentralized ﬁltering
receives little attention.
In another research front and during the course of ﬁlter implementation
based on different design algorithms, it turns out that the ﬁlters can be sen-
sitive with respect to errors in the ﬁlter coefﬁcients [60, 257, 264, 387]. The
459

460
Chapter 10. Decentralized Filtering-I
sources for this include, but are not limited to, imprecision in analogue-digital
conversion, ﬁxed word length, ﬁnite resolution instrumentation, and numerical
roundoff errors. Similar concern was raised earlier when using observers [61].
The objective of this section is to address two problems for a class of inter-
connected discrete-time nonlinear systems. The ﬁrst problem deals with robust
decentralized ﬁltering and the second problem studies resilient decentralized
ﬁltering. It is needless to stress that the phrase “resilient” implies robustness
with respect to plant parametric uncertainties and against gain perturbations in
ﬁlter matrices. Speciﬁcally, the robust ℓ∞ﬁltering design problem is treated
for a class of interconnected discrete-time systems with uncertain function of
nonlinear perturbations by exploiting the decentralized information structure
constraint. We develop LMIs-based conditions for designing the robust decen-
tralized ﬁlters. Then by considering additive ﬁlter gain perturbations, we solve
the resilient decentralized ﬁltering and express the results as convex minimiza-
tion over LMIs. Simulation examples are provided to illustrate the theoretical
developments.
10.2
Problem Statement
A class of nonlinear interconnected discrete-time systems with state-delay Σ
composed of N coupled subsystems Σj, j = 1, .., ns is represented by:
Σ :
x(k + 1)
=
Ax(k) + g(k, x(k)) + Bw(k)
(10.1)
y(k)
=
Cx(k) + Dw(k)
(10.2)
z(k)
=
Lx(k)
(10.3)
where k ∈Z+ := {0, 1, ...}, x = (xt
1, ..., xt
ns)t
∈ℜn, n = ns
j=1 nj is
the interconnected system state, y = (yt
1, ..., yt
ns)t
∈ℜm, m = ns
j=1 mj
is the measured output of the interconnected system, z = (zt
1, ..., zt
ns)t
∈
ℜp,
p = ns
j=1
pj is the vector of state combination to be estimated,
w = (wt
1, ..., wt
ns)t
∈ℜp, p = ns
j=1 pj is a vector with zero-mean in-
put noise and having unity power spectrum density matrix. The initial con-
dition x(0) is a zero-mean random variable uncorrelated with w(k) for all
k ≥0. The associated matrices are real constants and modeled as A =
diag{A1, .., Ans}, Aj ∈ℜnj×nj, B = diag{B1, .., Bns}, Bj ∈ℜnj×pj,
C = diag{C1, .., Cns}, Cj ∈ℜmj×nj,
D = diag{D1, .., Dns}, Dj ∈
ℜmj×pj,
L = diag{L1, .., Lns}, Lj ∈ℜpj×nj, which describe the nom-
inal system. The function g : Z+ × ℜn × ℜn →ℜnj,
g(k, x(k)) =
(gt
1(k, x(k)), .., gt
ns(k, x(k)))t is a vector function piecewise-continuous in its

10.3. Robust Subsystem Filters
461
arguments. In the sequel, we assume that this function is uncertain and the
available information is that, in the domains of continuity G, it satisﬁes the
quadratic inequality
gt(k, x(k))g(k, x(k)) ≤xt(k) (Gt(Φ−1 (Gx(k)
(10.4)
where (G = [ (Gt
1, .., (Gt
N]t,
(Gj ∈ℜrj×n
are constant matrices such that
gj(k, 0, 0) = 0 and x = 0 is an equilibrium of system (10.1).
Exploiting the structural form of system (10.1), the jth subsystem model
Σj can be described by
Σj :
xj(k + 1)
=
Ajxj(k) + Bjwj(k) + gj(k, x(k))
yj(k)
=
Cjxj(k) + Djw(k)
zj(k)
=
Ljxj(k)
(10.5)
where xj(k) ∈ℜnj, wj(k) ∈ℜpj, zj(k) ∈ℜpj, and yj(k) ∈ℜmj are the
subsystem state, disturbance input, linear combination of states, and measured
output, respectively. The function gj : Z+ × ℜn × ℜn →ℜnj is a piecewise-
continuous vector function in its arguments and in line of (10.4) it satisﬁes the
quadratic inequality
gt
j(k, x(k)) gj(k, x(k)) ≤φ2
j xt(k) (Gt
j (Gjx(k)
(10.6)
where φj
>
0 are bounding parameters such that (Φ = diag{φ−2
1 Ir1, ..,
φ−2
ns Irns} where Imj represents the mj × mj identity matrix. From (10.4) and
(10.6), it is always possible to ﬁnd matrices Φ such that
gt(k, x(k))g(k, x(k))
≤
xt(k)GtΦ−1Gx(k)
(10.7)
where G = diag{G1, .., Gns}, Φ = diag{δ1Ir1, .., δnsIrns}, and δj = φ−2
j .
Our objective in this chapter is to develop new tools for the linear ﬁlter de-
sign of a class of interconnected discrete-time systems with uncertain function
of nonlinear perturbations (10.4)-(10.7) by exploiting the decentralized infor-
mation structure constraint. We seek to establish complete LMI-based proce-
dures for the linear decentralized ﬁltering by basing all the computations at the
subsystem level.
10.3
Robust Subsystem Filters
In the ﬁltering problem considered hereafter, we consider the feasible set Cf as
the set of all linear shift-invariant operators with state-space realization at the

462
Chapter 10. Decentralized Filtering-I
Figure 10.1: Filtered subsystem model
subsystem level of the form:
ˆxj(k + 1)
=
Ejˆxj(k) + Fj yj(k),
ˆx(0) = 0
ˆzj(k)
=
Hjˆxj(k)
(10.8)
where the matrices Ej ∈ℜsj×sj, Fj ∈ℜsj×mj, and Hj ∈ℜpj×sj and the
scalar sj > 0 are the design parameters. Recall from (10.1)-(10.3) and (10.8)
that all matrices are shift-invariant since we are focusing on the stationary case.
Connecting the ﬁlter (10.8) to the subsystem (10.5), we obtain the ﬁltering error
subsystem
ζj(k + 1)
=
˜Ajζj(k) + ˜Bjwj(k) + ˜gj(k, x(k))
ej(k)
=
˜Ljζj(k)
(10.9)
where the subsystem estimation error ej(k) := zj(k) −ˆzj(k) and
˜gj(k, x(k))
:=
 gj(k, x(k))
0

, ζj :=
 xj
ˆxj

, ˜L := [Lj
−Hj]
˜Aj
:=

Aj
0
FjCj
Ej

, ˜B :=

Bj
FjDj

(10.10)
A schematic diagram of the ﬁltered subsystem is displayed in Figure 10.1.
10.3.1
Robust ℓ∞ﬁlter
Considering the ﬁltering error subsystem (10.9), our goal in this part is to es-
tablish tractable conditions for designing the subsystem ﬁlter to guarantee the

10.3. Robust Subsystem Filters
463
global asymptotic stability of the origin (x = 0) for all g(k, x(k)) ∈G and
achieving induced ℓ2 disturbance attenuation γ according to the following def-
inition.
Deﬁnition 10.3.1 Given γj > 0, the ﬁltering error subsystem (10.10) is said
to be robustly asymptotically stable with an induced ℓ2 disturbance attenuation
γ if it is asymptotically stable for all admissible uncertainties satisfying (10.7)
and under zero initial conditions ||ej(k)||2
<
γ ||wj(k)||2 for all nonzero
wj(k) ∈ℓ2[0, ∞).
The main result of subsystem ﬁlter design is established by the following theo-
rem.
Theorem 10.3.2 The ﬁltering error subsystem (10.10) is robustly asymptoti-
cally stable for all nonlinear uncertainties satisfying (10.4) if there exist ma-
trices 0 < Yt
aj = Yaj ∈ℜnj×nj, 0 < Yt
oj = Yoj ∈ℜsj×sj, Ycj ∈
ℜsj×sj, Yej ∈ℜsj×nj, Ysj ∈ℜsj×mj, Hj ∈ℜpj×sj and scalars δj >
0, γj > 0 such that the following convex optimization problem is feasible:
min
Yaj,Yoj,Ycj,Yej,Ysj,Hj,δj
N

j=1
δj + γj
subject to : {Yaj > 0, Yoj > 0}N
j=1,
diag

Γ1, ..., ΓN

< 0,
Γj =
⎡
⎢⎢⎢⎢⎢⎢⎣
−Ψ1j
Ψ2j
0
Ψ2j
Ψ4j
Ψ5j
•
−Ψ6j
Ψ3j
0
0
0
•
•
−γ2
j Ij
Ψt
3j
0
0
•
•
•
−Ψ1j
0
0
•
•
•
•
−δjIj
0
•
•
•
•
•
−Ij
⎤
⎥⎥⎥⎥⎥⎥⎦
(10.11)
where
Ψ1j
=
 Yaj
0
•
Yoj

, Ψ2j =
 At
jYaj
Yt
ej
0
Yt
cj

, Ψ3j =
 YajBj
YsjDj

,
Ψ4j
=

Gt
j
YsjDj

, Ψ5j =

Lt
j
−Ht
j

,
Ψ6j
=
 Ij −Yaj
0
•
Ij −Yoj

(10.12)
Moreover, the ﬁlter gains are given by Ej = Y−1
oj Ycj, Fj = Y−1
oj Ysj, Hj.

464
Chapter 10. Decentralized Filtering-I
Proof: Introduce the Lyapunov functional (LF):
V (k) =
N

j=1
Vj(k) =
N

j=1

ζt
j(k)Pjζj(k)

(10.13)
where 0 < Pt
j = Pj ∈ℜ(nj+sj)×(nj+sj) are weighting matrices for j =
1, .., N. A straightforward computation gives the ﬁrst-difference of ΔV (k) =
V (k + 1) −V (k) along the solutions of (10.9) as:
ΔV (k)
=
N

j=1
[ ˜Ajζj(k) + ˜Bjwj(k) + ˜gj(k, x(k))]tPj
[ ˜Ajζj(k) + ˜Bjwj(k) + ˜gj(k, x(k))]
−
N

j=1
ζt
j(k)Pjζj(k)
:=
ξt(k) Ξ ξ(k)
(10.14)
Ξ
=
diag(Ξ1, ..., ΞN), Ξj =
⎡
⎣
˜At
jPj ˜Aj −Pj
˜At
jPj ˜Bj
˜At
jPj
•
˜Bt
jPj ˜Bj
˜Bt
jPj
•
•
Pj
⎤
⎦,
ξ(k)
=
[ξt
1(k), ..., ξt
N (k)]t,
ξt
j(k)
=
 ζt
j(k)
wt
j(k)
˜gt
j(k, x(k)) 
(10.15)
In terms of ˜Gj = [Gj
0] and recalling that (10.7) can be conveniently written
as
ξt diag
 ⎡
⎣
−φ2
1 ˜Gt
1 ˜G1
0
0
•
0
0
•
•
I1
⎤
⎦, ...,
⎡
⎣
−φ2
N ˜Gt
N ˜GN
0
0
•
0
0
•
•
IN
⎤
⎦

ξ
≤0
(10.16)
then the sufﬁcient condition of stability ΔV (k) < 0 implies that Ξ < 0. By
resorting to the S-procedure, inequalities (10.14) and (10.16) can be rewritten
together as
P1 > 0, ..., PN > 0, ω1 ≥0, ..., ωN ≥0,
diag

Π1, ..., ΠN

< 0,
Πj =
⎡
⎣
˜At
jPj ˜Aj −Pj + ωjφ2
j ˜Gt
j ˜Gj
˜At
jPj ˜Bj
˜At
jPj
•
˜Bt
jPj ˜Bj
˜Bt
jPj
•
•
Pj −ωjIj
⎤
⎦(10.17)

10.3. Robust Subsystem Filters
465
which describes nonstrict LMIs since ωj ≥0. Recall from [29] that mini-
mization under nonstrict LMIs corresponds to the same result as minimization
under strict LMIs when both strict and nonstrict LMI constraints are feasible.
Moreover, if there is a solution for (10.17) for ωj = 0, there will be also a so-
lution for some ωj > 0 and sufﬁciently small φj. Therefore, we safely replace
ωj ≥0 by ωj > 0. Equivalently, with Yj = ω−1
j
Pj and multiplying by ω−1
j ,
we may further rewrite (10.17) in the form
Y1 > 0, ..., YN > 0,
diag

¯Π1, ..., ¯ΠN

< 0,
¯Πj =
⎡
⎣
˜At
jYj ˜Aj −Yj + φ2
j ˜Gt
j ˜Gj
˜At
jYj ˜Bj
˜At
jYj
•
˜Bt
jYj ˜Bj
˜Bt
jYj
•
•
Yj −Ij
⎤
⎦
(10.18)
Consider the ℓ2-performance measure
J =
N

j=1
Jj =
N

j=1
∞

m=0

et
j(m)ej(m) −γ2wt
j(m)wj(m)

For any wk ∈ℓ2(0, ∞) ̸= 0 and zero initial condition xo = 0 (hence Vj(0) =
0), we have
Jj
=
∞

m=0

et
j(m)ej(m) −γ2wt
j(m)wj(m) + ΔVj|(10.9)

−
∞

j=0
ΔVj|(10.9)
=
∞

j=0

et
j(m)ej(m) −γ2wt
j(m)wj(m) + ΔVj|(10.9)

−Vj(∞)
≤
∞

j=0

et
j(m)ej(m) −γ2wt
j(m)wj(m) + ΔVj|(10.9)

(10.19)
where ΔVj|(10.9) deﬁnes the Lyapunov difference along the solutions of system
(10.9). By combining (10.9) and (10.19), it can easily be shown by algebraic

466
Chapter 10. Decentralized Filtering-I
manipulation that
et
j(m)ej(m) −γ2wt
j(m)wj(m) + ΔVj|(10.9) =
ζt
j(k)˜Lt
j ˜Ljζj(k) −γ2wt
jwj + ξt
j ¯Πj ξj := ξt
k &Πj ξt
k
&Πj =
⎡
⎣
˜At
jYj ˜Aj −Yj + φ2
j ˜Gt
j ˜Gj + ˜Lt
j ˜Lj
˜At
jYj ˜Bj
˜At
jYj
•
˜Bt
jYj ˜Bj −γ2Ij
˜Bt
jYj
•
•
Yj −Ij
⎤
⎦(10.20)
Focusing on &Πj, using the change of variable δj = φ−2
j
and followed by
Schur complement operations we arrive at
Πj
=
⎡
⎢⎢⎢⎢⎢⎢⎢⎣
−Yj
˜At
jYj
0
˜At
jYj
˜Gt
j
˜Lt
j
•
Yj −Ij
Yj ˜Bj
0
0
0
•
•
−γ2Ij
˜Bt
jYj
0
0
•
•
•
−Yj
0
0
•
•
•
•
−δjIj
0
•
•
•
•
•
−Ij
⎤
⎥⎥⎥⎥⎥⎥⎥⎦
(10.21)
Introducing the change of variables
Yj
=
 Yaj
0
•
Yoj

, Ycj = YojEj,
Yej
=
YojFjCj, Ysj = YojFj
(10.22)
to (10.18), we obtain LMI (10.11) which establishes the internal asymptotic
stability with ℓ2 disturbance attenuation, and eventually leads to ||ej(k)||2 <
γ||wj(k)||2 for all nonzero wj(k) ∈ℓ2[0, ∞). Therefore, the proof is com-
pleted.
Remark 10.3.3 It should be noted that the family of N linear ﬁlters in the form
(10.8) guarantees the decentralized reproduction of the linear combination of
the interconnected system’s state with disturbance attenuation level N
j=1 δj
under the information structure constraint (10.7) with maximal φj. Observe
also that the ﬁlter order is 1 < sj ≤nj and thus covers both the full- and
reduced-order cases. The performance of these subsystem ﬁlters will be demon-
strated in the simulation studies.

10.3. Robust Subsystem Filters
467
10.3.2
Illustrative example 10.1
In order to illustrate the theoretical results thus far, we consider a model of the
type (10.1)-(10.3) with the following data:
A
=
⎡
⎢⎢⎢⎢⎢⎢⎣
−0.8
0
0.1
0
0
0
0
0.7
0.1
0
0
0
−0.1
0
0.1
0
0
0
0
0
0
−0.6
0
0.2
0
0
0
0
−0.5
0.1
0
0
0
−0.3
0
0.2
⎤
⎥⎥⎥⎥⎥⎥⎦
, Ct =
⎡
⎢⎢⎢⎢⎢⎢⎣
1
0
0
0
1
0
0
0
0
1
0
0
0
0
1
0
0
0
1
0
0
0
0
1
⎤
⎥⎥⎥⎥⎥⎥⎦
B
=
⎡
⎢⎢⎢⎢⎢⎢⎣
0.15
0
0.25
0
0.1
0
0
0.3
0
0.1
0
0.2
⎤
⎥⎥⎥⎥⎥⎥⎦
, D =
⎡
⎢⎢⎣
0.1
0
0.1
0
0
0.2
0
0.2
⎤
⎥⎥⎦, Lt =
⎡
⎢⎢⎢⎢⎢⎢⎣
0.4
0
0.3
0
0.2
0
0
0.1
0
0.2
0
0.3
⎤
⎥⎥⎥⎥⎥⎥⎦
g(k, x(k))
=
⎡
⎢⎢⎢⎢⎢⎢⎣
0
0
−1
0
0
0
0
1
0
0
0
0
1
0
0
0
0
−1
0
0
1
0
0
0
0
−1
0
0
0
0
−1
0
0
0
0
1
⎤
⎥⎥⎥⎥⎥⎥⎦
e(k, x(k))x,
e(k, x(k))
=
ℜ7 →[0, 0.6]
In the numerical computations of the robust ℓ∞ﬁlter, we considered three cases
and the ensuing results are given by
s1
=
3, s2 = 3 (Full(third) −orderfilter),
δ1
=
0.1559,
γ1 = 1.9865,
δ2 = 0.1558,
γ2 = .9865
E1
=
⎡
⎣
0.0154
0.0171
0.0056
0.0254
0.2241
−0.0460
0.0093
−0.1142
0.3236
⎤
⎦, F1 =
⎡
⎣
0.7355
0.1328
0.1444
−0.5201
0.8498
−0.4101
⎤
⎦,
H1
=
⎡
⎣
0.5048
−0.0381
0.6740
−0.0444
−0.5714
0.1014
⎤
⎦,
E2
=
⎡
⎣
0.0154
0.0171
0.0056
0.0254
0.2241
−0.0460
0.0093
−0.1142
0.3236
⎤
⎦, F2 =
⎡
⎣
0.7355
0.1328
0.1444
−0.5201
0.8498
−0.4101
⎤
⎦,

468
Chapter 10. Decentralized Filtering-I
H2
=
⎡
⎣
0.5048
−0.0381
0.6740
−0.0444
−0.5714
0.1014
⎤
⎦,
s1
=
2, s2 = 2 (Reduced(second) −orderfilter),
δ1
=
0.4973,
γ1 = 2.6485,
δ2 = 0.4973,
γ2 = 2.6485
E1
=
 0.1309
0.0321
0.0418
0.2378

, F1 =
 0.6438
0.1277
0.4882
−0.1305

,
H1
=

0.8674
−0.0472
−0.7364
0.0887

,
E2
=
 0.1874
0.0574
0.1134
−0.2630

, F2 =
 0.8765
0.2008
0.5648
−0.7101

,
H2
=
 0.9106
−0.3811
0.8840
−0.9614

,
s1
=
1, s2 = 1 (Reduced(first) −orderfilter),
δ1
=
0.7384,
γ1 = 4.5724,
δ2 = 0.7384,
γ2 = 4.5724
E1
=
[0.1352], F1 =

0.6948
−0.6603

, H1 =

0.4483
−0.7455

,
E2
=
[0.2241], F2 =

0.7782
−0.5301

, H2 =

0.3877
−0.8013

From the ensuing results, we observe that the full-order ﬁltered subsystem per-
forms better than the reduced-order ﬁltered subsystems in the sense of yielding
smaller values of γ−and δ−levels. This is quite expected in view of the addi-
tional degrees of freedom the full-order ﬁlter has over the reduced ones.
10.4
Resilient Subsystem Filters
In this section, we are going to study the issue of ﬁlter implementation. It turns
out that implementing the designed ﬁlter (10.8) for a single subsystem, much
in line with the controller design counterpart, one might encounter inaccuracies
or parameter perturbations that eventually lead to the resilient ﬁltering problem
[258]. Indeed, the problem is further compounded for the case of an intercon-
nected system. In this regard, this problem has been overlooked in the literature
on discrete-time systems and/or interconnected systems. For the continuous-
time case, Kalman ﬁltering with respect to estimator gain perturbations that was
considered in [387], linear resilient ﬁltering was treated in [257] and resilient

10.4. Resilient Subsystem Filters
469
L2/L∞ﬁltering for state-delay polytopic systems was developed in [264]. In
the sequel, we generalize the result of [257, 258, 387] in different ways by con-
sidering the resilient linear ﬁltering of discrete-time interconnected systems
with respect to perturbations in the estimator gains and cast the ﬁlter design
conditions in computationally tractable LMI forms.
Incorporating the additive perturbations in the ﬁlter gains, we consider in
the sequel the feasible set Cf as the set of all resilient shift-invariant operators
with state-space realization at the subsystem level of the form:
ˆxj(k + 1)
=
[Ej + ΔEj(k)]ˆxj(k) + [Fj + ΔFj(k)] yj(k),
=
EjΔˆx(k) + FjΔ y(t),
ˆxj(0) = 0
(10.23)
ˆzj(k)
=
[Hj + ΔHj(k)]ˆxj(k) = HjΔˆx(k)
(10.24)
where the matrices Ej, Fj, Hj are the design parameters as introduced before
and the additive gain perturbations are represented by
 ΔEj(k)
ΔHj(k)

=
 Maj
Mcj

Δj(k) Naj, ΔFj(k) = MajΔj(k) Ncj,
Δt
j(k) Δj(k) ≤Ij,
∀k
(10.25)
with the matrices Maj ∈ℜsj×αj, Naj ∈ℜβj×sj, Mcj ∈ℜpj×αj, Δj ∈
ℜαj×βj, and Ncj ∈ℜβj×mj as constants.
Connecting the ﬁlter (10.23)-(10.24) to the system (10.8), we can express
the ﬁltering error subsystem as follows:
ζj(k + 1)
=
˜AjΔζj(k) + ˜BjΔwj(k) + ˜gj(k, x(k))
ej(k)
=
˜LjΔζj(k)
(10.26)
where the subsystem estimation error ej(k) := zj(k) −ˆzj(k) and
˜AjΔ
:=

Aj
0
FjΔCj
EjΔ

,
=

Aj
0
FjCj
Ej

+
 Ct
jN t
cj
N t
aj

Δt
j(k)
 0
Mt
ajYoj

,
=

Aj
0
FjCj
Ej

+ αjΔt
j(k)βt
j,
˜BjΔ
:=

Bj
FjΔDj

=

Bj
FjDj

+

0
Maj

Δj(k)NcjDj,

470
Chapter 10. Decentralized Filtering-I
˜LjΔ
=
[Lj
−HjΔ] = [Lj
−Hj] + McjΔj(k)[0
−Naj],
=
[Lj
−HjΔ] = [Lj
−Hj] + McjΔj(k)πt
j,
Yj ˜BjΔ
=

YajBj
YojFjDj

+

0
YojMaj

Δj(k)NcjDj,
=

YajBj
YojFjDj

+ βjΔj(k)NcjDj
(10.27)
10.4.1
Resilient ℓ∞ﬁlter
Considering the ﬁltering error subsystem (10.26), our immediate task is to es-
tablish tractable conditions for designing the subsystem ﬁlter to achieve in-
duced ℓ2 disturbance attenuation γ according to Deﬁnition 10.3.1 for all pos-
sible gain perturbations (10.25). It follows from the foregoing analysis and in
particular (10.19) that the ﬁltering error subsystem (10.26) has ℓ2 disturbance
attenuation level γj provided that the following LMI,
ΠjΔ
=
⎡
⎢⎢⎢⎢⎢⎢⎢⎣
−Yj
˜At
jΔYj
0
˜At
jΔYj
˜Gt
j
˜Lt
jΔ
•
Yj −Ij
Yj ˜BjΔ
0
0
0
•
•
−γ2Ij
˜Bt
jΔYj
0
0
•
•
•
−Yj
0
0
•
•
•
•
−δjIj
0
•
•
•
•
•
−Ij
⎤
⎥⎥⎥⎥⎥⎥⎥⎦
=
⎡
⎢⎢⎢⎢⎢⎢⎢⎣
−Yj
˜At
jYj
0
˜At
jYj
˜Gt
j
˜Lt
j
•
Yj −Ij
Yj ˜Bj
0
0
0
•
•
−γ2Ij
˜Bt
jYj
0
0
•
•
•
−Yj
0
0
•
•
•
•
−δjIj
0
•
•
•
•
•
−Ij
⎤
⎥⎥⎥⎥⎥⎥⎥⎦
+
⎡
⎢⎢⎢⎢⎢⎢⎢⎣
0
Δ ˜At
jYj
0
Δ ˜At
jYj
0
Δ˜Lt
j
•
0
YjΔ ˜Bj
0
0
0
•
•
0
Δ ˜Bt
jYj
0
0
•
•
•
0
0
0
•
•
•
•
0
0
•
•
•
•
•
0
⎤
⎥⎥⎥⎥⎥⎥⎥⎦
< 0 (10.28)
has a feasible solution for all possible gain perturbations (10.25). Applying
Fact 1 and using (10.27), it can be shown that inequality (10.28) is majorized

10.4. Resilient Subsystem Filters
471
into the form
ΠjΔ ≤
⎡
⎢⎢⎢⎢⎢⎢⎢⎣
−Yj
˜At
jYj
0
˜At
jYj
˜Gt
j
˜Lt
j
•
Yj −Ij
Yj ˜Bj
0
0
0
•
•
−γ2Ij
˜Bt
jYj
0
0
•
•
•
−Yj
0
0
•
•
•
•
−δjIj
0
•
•
•
•
•
−Ij
⎤
⎥⎥⎥⎥⎥⎥⎥⎦
+
εj
⎡
⎢⎢⎢⎢⎢⎢⎣
αj
0
Dt
jN t
cj
0
0
0
⎤
⎥⎥⎥⎥⎥⎥⎦
⎡
⎢⎢⎢⎢⎢⎢⎣
αj
0
Dt
jN t
cj
0
0
0
⎤
⎥⎥⎥⎥⎥⎥⎦
t
+ ε−1
j
⎡
⎢⎢⎢⎢⎢⎢⎣
0
βj
0
βj
0
0
⎤
⎥⎥⎥⎥⎥⎥⎦
⎡
⎢⎢⎢⎢⎢⎢⎣
0
βj
0
βj
0
0
⎤
⎥⎥⎥⎥⎥⎥⎦
t
(10.29)
+
σ−1
j
⎡
⎢⎢⎢⎢⎢⎢⎣
πj
0
0
0
0
0
⎤
⎥⎥⎥⎥⎥⎥⎦
⎡
⎢⎢⎢⎢⎢⎢⎣
πj
0
0
0
0
0
⎤
⎥⎥⎥⎥⎥⎥⎦
t
+ σj
⎡
⎢⎢⎢⎢⎢⎢⎣
0
0
0
0
0
Mcj
⎤
⎥⎥⎥⎥⎥⎥⎦
⎡
⎢⎢⎢⎢⎢⎢⎣
πj
0
0
0
0
Mcj
⎤
⎥⎥⎥⎥⎥⎥⎦
t
< 0 (10.30)
for some εj > 0, σj > 0. Schur complement operations cast inequality (10.30)
into the form
 Π1
Π2
•
Π3

< 0
Π1 =
⎡
⎢⎢⎢⎢⎢⎣
−Yj
˜At
jYj
0
˜At
jYj
˜Gt
j
•
Yj −Ij
Yj ˜Bj
0
•
•
−γ2Ij
˜Bt
jYj
0
•
•
•
−Yj
0
•
•
•
•
−δjIj
⎤
⎥⎥⎥⎥⎥⎦
,

472
Chapter 10. Decentralized Filtering-I
Π2 =
⎡
⎢⎢⎢⎢⎣
˜Lt
j
εjαj
0
πj
0
0
0
βj
0
0
0
εjDt
jN t
cj
0
0
0
0
0
βj
0
0
0
0
0
0
0
⎤
⎥⎥⎥⎥⎦
,
Π3 =
⎡
⎢⎢⎢⎢⎣
−Ij
0
0
0
σjMcj
•
−εjIj
0
0
0
•
•
−εjIj
0
0
•
•
•
−σjIj
0
•
•
•
•
−σjIj
⎤
⎥⎥⎥⎥⎦
(10.31)
The main result of subsystem ﬁlter design is established by the following theo-
rem.
Theorem 10.4.1 The ﬁltering error subsystem (10.9) is robustly asymptoti-
cally stable for all nonlinear uncertainties satisfying (10.7) if there exist ma-
trices 0 < Yt
aj = Yaj ∈ℜnj×nj, 0 < Yt
oj = Yoj ∈ℜsj×sj, Ycj ∈
ℜsj×sj, Yej ∈ℜsj×nj, Ysj ∈ℜsj×mj, Hj ∈ℜpj×sj and scalars δj >
0, γj > 0 such that the following convex optimization problem is feasible:
min
Yaj,Yoj,Ycj,Yej,Ysj,Hj,δj
N

j=1
δj + γj
subject to : {Yaj > 0, Yoj > 0}N
j=1,
diag

Υ1, ..., ΥN

< 0,
Υj =
 Υj1
Υj2
•
Υj3

Υj1 =
⎡
⎢⎢⎢⎢⎣
−Ψ1j
Ψ2j
0
Ψ2j
Ψ4j
•
−Ψ6j
Ψ3j
0
0
•
•
−γ2Ij
Ψt
3j
0
•
•
•
−Ψ1j
0
•
•
•
•
−δjIj
⎤
⎥⎥⎥⎥⎦
Υj2 =
⎡
⎢⎢⎢⎢⎣
Ψ5j
εjαj
0
πj
0
0
0
βj
0
0
0
εjDt
jN t
cj
0
0
0
0
0
βj
0
0
0
0
0
0
0
⎤
⎥⎥⎥⎥⎦

10.4. Resilient Subsystem Filters
473
Υj3 =
⎡
⎢⎢⎢⎢⎣
−Ij
0
0
0
σjMcj
•
−εjIj
0
0
0
•
•
−εjIj
0
0
•
•
•
−σjIj
0
•
•
•
•
−σjIj
⎤
⎥⎥⎥⎥⎦
(10.32)
where Ψ1j, Ψ2j, Ψ3j, Ψ4j, Ψ5j, Ψ6j are given by (10.12). Moreover, the
ﬁlter gains are given by Ej = Y−1
oj Ycj, Fj = Y−1
oj Ysj, Hj.
10.4.2
Illustrative example 10.2
We reconsider Example 1 with sj = 3 (full-order ﬁlter) and
Ma1
=
⎡
⎣
0.7
0.5
0.3
⎤
⎦, Ma2 =
⎡
⎣
0.3
0.6
0.4
⎤
⎦, N t
a1 =
⎡
⎣
0.2
0.2
0.2
⎤
⎦, N t
a2 =
⎡
⎣
0.3
0.3
0.3
⎤
⎦,
Mc1
=
⎡
⎣
0.4
0.4
0.4
⎤
⎦, Mc2 =
⎡
⎣
0.6
0.1
0.5
⎤
⎦, N t
c1 =
⎡
⎣
0.4
0.1
0.1
⎤
⎦, N t
c2 =
⎡
⎣
0.1
0.4
0.5
⎤
⎦
The feasible solution of the convex minimization problem (10.32) gives the
full-order resilient ﬁlters as summarized by
s1
=
3, s2 = 3 (Full(third) −orderfilter),
δ1
=
0.1341,
γ1 = 1.6885,
δ2 = 0.1341,
γ1 = 1.6885
E1
=
⎡
⎣
0.0149
−0.0117
0.0105
0.0254
−0.3301
−0.0380
−0.0078
0.1062
0.2424
⎤
⎦, F1 =
⎡
⎣
0.6665
0.1256
−0.1336
0.4901
−0.5377
0.2351
⎤
⎦,
H1
=
⎡
⎣
−0.3777
0.1474
−0.0650
0.3987
0.1875
−0.4243
⎤
⎦
E2
=
⎡
⎣
0.0146
−0.0132
0.0114
0.0307
−0.3412
−0.1055
−0.0108
0.1055
0.2637
⎤
⎦, F2 =
⎡
⎣
0.7015
0.1225
−0.1401
0.4871
−0.5426
0.2440
⎤
⎦,
H2
=
⎡
⎣
−0.3667
0.1884
−0.0690
0.4112
0.1905
−0.4008
⎤
⎦

474
Chapter 10. Decentralized Filtering-I
Had we considered the design of reduced-order resilient ﬁlters, we would have
used the additive perturbation matrices as
s1
=
2, s2 = 2 (Reduced(second) −orderfilter),
Ma1
=
 0.5
0.3

, Ma2 =
 0.3
0.4

, N t
a1 =
 0.2
0.2

, N t
a2 =
 0.3
0.3

,
Mc1
=
 0.4
0.4

, Mc2 =
 0.1
0.5

, N t
c1 =
 0.1
0.1

, N t
c2 =
 0.1
0.5

s1
=
1, s2 = 1 (Reduced(first) −orderfilter),
Ma1
=
[0.5], Ma2 = [0.4], N t
a1 = [0.2], Na2 = [0.3], Mc1 = [0.4],
Mc2
=
[0.5],
Nc1
=
[0.1], Nc2 = [0.5]
In this case, the feasible solution of the convex minimization problem (10.32)
is obtained as
s1
=
2, s2 = 2 (Reduced(second) −orderfilter),
δ1
=
0.4327,
γ1 = 2.3307,
δ2 = 0.4327,
γ1 = 2.3307
E1
=
 0.1298
0.0445
0.0512
0.2446

, F1 =

0.7140
0.2083
−0.1312
0.5120

,
H1
=

0.7554
−0.0733
−0.8055
−0.0717

E2
=
 −0.0748
0.1766
−0.1409
0.2550

, F2 =

0.7126
0.2111
−0.4568
−0.7103

,
H2
=
 0.7807
−0.4411
0.6642
−0.8837

s1
=
1, s2 = 1 (Reduced(first) −orderfilter),
δ1
=
0.6498,
γ1 = 4.0694,
δ2 = 0.6498,
γ1 = 4.0694
E1
=
[0.1245], F1 =

0.6776
−0.7102

, H1 =

0.3925
−0.6614

E2
=
[0.2198], F2 =

0.6962
−0.4991

, H2 =

0.3695
−0.7891

On comparing the ensuing results of the resilient and robust ﬁlters, it is found
that we observe that the resilient ﬁltered subsystem performs better than the
robust ﬁltered subsystem in the sense of yielding smaller values of γ−and
δ−levels. In fact, in this numerical example, we attained 11-14% improvement
and this is true for full- and reduced-order cases.

10.5. Problem Set VIII
475
10.5
Problem Set VIII
Problem VIII.1: Consider a linear large-scale system represented by:
Σj :
˙xj(t)
=
Ajxj(t) + Bjuj(t) +
ns

k=1,k̸=j
Ajkxk(t)
yj(t)
=
Cjxj(t)
where xj(t)
∈ℜnj, uj(t)
∈ℜmj, and yj(t) ∈ℜpj are the subsystem
state, control input, and measured output, respectively. In addition, matrices
Aj, Bj, Cj, Aj, Ajk are all constant matrices of appropriate dimensions with
rank(Cj) = pj, j = 1, ..., ns. It is desired to design q local observer to
estimate the unmeasurable components of xj, j = 1, ..., ns using only local
inputs and local output measurements. One possible form would be
˙wj(t)
=
Fjwj(t) + Ljuj(t) + Ejyj(t)
˜xj(t)
=
Mjwj(t) + Njyj(t)
where Fj, Lj, Ej, Mj, and Nj are the design matrices to be determined.
Using the following data
A1
=
⎡
⎣
−1
0
0
−1
0
1
1
−2
−1
⎤
⎦, B1 =
⎡
⎣
0
1
1
0
1
1
⎤
⎦,
A2
=
⎡
⎣
−1
0
0
−1
−2
0
0
0
−4
⎤
⎦, B2 =
⎡
⎣
0
−1
1
0
0
1
⎤
⎦,
A12
=
⎡
⎣
0
0
0
0
0
0
−1
1
1
⎤
⎦, A21 =
⎡
⎣
0
0
0
−8
1
−1
4
−0.5
0.5
⎤
⎦,
C1
=
 0
1
0
0
0
1

, C2 =
 0
1
0
0
0
1

evaluate your results.
Problem VIII.2: Consider a collection of ns coupled discrete-time systems of

476
Chapter 10. Decentralized Filtering-I
the form
Σj :
xj(k + 1)
=
Ajxj(k) + Bjwj(k) +
ns

m=1,m̸=j
Ajmxm(k)
yj(k)
=
Cjxj(k) + Djw(k)
zj(k)
=
Ljxj(k), j = 1, ..., ns
where xj(k) ∈ℜnj, wj(k) ∈ℜpj, zj(k) ∈ℜpj, and yj(k) ∈ℜmj are the
subsystem state, disturbance input, linear combination of states, and measured
output, respectively. It is required to develop a class of subsystem ﬁlters of the
form
ˆxj(k + 1)
=
Ejˆxj(k) + Fj yj(k),
ˆx(0) = 0
ˆzj(k)
=
Hjˆxj(k)
where the matrices Ej ∈ℜsj×sj, Fj ∈ℜsj×mj, and Hj ∈ℜpj×sj and the
scalar sj > 0 are the design parameters such that collection of the ﬁltered sub-
systems are asymptotically stable with an ℓ2 −ℓ∞performance measure.
Problem VIII.3: Develop a decentralized resilient ℓ∞ﬁlter for the system ad-
dressed in Problem VIII.2 with state-space realization at the subsystem level
of the form
ˆxj(k + 1)
=
Ej[Ij + ΔEj(k)]ˆxj(k) + Fj[Ij + ΔFj(k)] yj(k),
ˆzj(k)
=
Hj[Ij + ΔHj(k)]ˆxj(k)
where the matrices Ej, Fj, Hj are the design parameters and the multiplica-
tive gain perturbations are represented by
 ΔEj(k)
ΔHj(k)

=
 Maj
Mcj

Δj(k) Naj, ΔFj(k) = MajΔj(k) Ncj,
Δt
j(k) Δj(k) ≤Ij,
∀k
where the matrices are constant matrices with appropriate dimensions.
10.6
Notes and References
In this chapter, we have developed new tools for robust and resilient ﬁlter de-
sign of a class of interconnected discrete-time systems with uncertain function

10.6. Notes and References
477
of nonlinear perturbations. These tools essentially exploit the decentralized in-
formation structure constraint. Speciﬁcally, we have established complete so-
lution procedures for linear robust ﬁltering with ℓ∞performance and linear
resilient ﬁltering in the face of additive gain variations by basing all the compu-
tations at the subsystem level. By a suitable convex analysis, it has been shown
that both design problems can be converted into convex minimization prob-
lems over linear matrix inequalities (LMIs). Several extensions are possible as
outlined in the set of problems. While this chapter focused on decentralized ﬁl-
tering within a deterministic setting, the next chapter will discuss decentralized
ﬁltering within a stochastic setting.

Chapter 11
Decentralized Filtering-II
In this chapter, we approach the end of our guided tour into techniques and
methods of large-scale systems, where we focus on decentralized ﬁltering and
fault detection based on overlapping decomposition. The material covered is
divided into two sections. In the ﬁrst section, the optimal state estimation in
a large-scale linear interconnected dynamical system is considered and a de-
centralized computational structure is developed. The decentralized ﬁlter uses
hierarchical structure to perform successive orthogonalization on the measure-
ment subspace of each sub-system in order to provide the optimal estimate.
This ensures substantial savings in computation time. In addition, since only
low-order subsystem machine equations are manipulated at each stage, numer-
ical inaccuracies are reduced and the ﬁlter remains stable for even high-order
system. In the second section, the problem of fault detection in linear, stochas-
tic, interconnected dynamic systems is examined. The objective addresses a
design approach based on employing a set of decentralized ﬁlters at the sub-
system level resulting from overlapping decomposition. The malfunctioning
sensors can be detected and isolated by comparing the estimated values of a
single state from different Kalman ﬁlters.
11.1
Decentralized Kalman Filtering
Throughout the book we have tackled the problems of optimization and control
of large-scale systems comprising interconnected dynamical subsystems from
a deterministic point of view [271]-[331]. The objective has been to trace the
development of decentralized control methods. On the other hand, the work re-
ported in [8, 40, 98, 307] has emphasized the importance of the stochastic con-
trol problem. Filter structure for large systems has previously been suggested
479

480
Chapter 11. Decentralized Filtering-II
in [8, 98, 332, 335]. However, the ﬁlter structures proposed in [8, 333] pro-
vide estimates that are suboptimal while the optimal decentralized ﬁlter [98]
is not readily extendable to a system comprising more than two subsystems.
It is quite natural to seek the design of a decentralized structure that provides
optimal estimation and that is applicable to systems comprising ns subsystems.
11.1.1
Basis of ﬁltering method
It is well known that the most appealing property of the global Kalman ﬁl-
ter from a practical viewpoint is its recursive nature. Essentially, this recur-
sive property of the ﬁlter arises from the fact that if an estimate exists based
on measurements up to that instant, then upon receiving another set of mea-
surements, one could subtract from these measurements that part that could be
anticipated from the results of the ﬁrst measurements, that is, the updating is
based on the part of the new data that is orthogonal to the old data. In searching
for an appropriate decentralized ﬁlter for a system comprising lower order in-
terconnected subsystems, one endeavors to perform this orthogonalization on
a subsystem-by-subsystem basis, that is, the optimal estimates of the state of
subsystem one is obtained by successively orthogonalizing the error based on a
new measurement for subsystems {1, 2, 3, . . . , ns} with respect to the Hilbert
space formed by all measurements of all the subsystems up to that instant.
Much computational saving would be expected to result by using this succes-
sive orthogonalization procedure since, at each stage, only low-order subspaces
are manipulated. The actual orthogonalization procedure that is performed in
the Kalman ﬁlter is based on the following theorem [181].
Theorem 11.1.1 Let β be a member of space H of random variables which is
a closed subspace of L2 and let ˆβ denote its orthogonal projection on a closed
subspace y1 of H (thus, ˆβ1 is the best estimate of β in Y1). Let y2 be an m
vector of random variables generating a subspace Y2 of H and let ˆy2 denote
the m-dimensional vector of the projections of the components of y2 on to Y1
(thus ˆy2 is the vector of best estimates of y2 in Y1). Let ˜y2 = y2 −ˆy2.
Then the projection of β onto the subspace Y1 ⊕Y2, denoted ˆβ, is
ˆβ = ˆβ1, +IE{β˜yT
2 }[IE{˜y2˜yT
2 }]−1˜y2
(11.1)
where IE is the expected value.
Equation (11.1) can be interpreted as ˆβ is ˆβ1 plus the best estimate of β in the
subspace ˜y2 generated by ˜y2.

11.1. Decentralized Kalman Filtering
481
Next consider the system comprising ns interconnected linear dynamical
subsystems deﬁned by
xj(k + 1) = φjjxj(k) +
ns

k=1;k̸=j
φjkxj(k) + wj(k)
j = 1, 2, . . . , ns (11.2)
with the outputs given by
yj(k + 1) = Hjxj(k + 1) + vj(k + 1)
j = 1, . . . , ns
(11.3)
where wj, vj are uncorrelated zero mean Gaussian white noise sequences with
covariances Qj, Rj, respectively. Consider the Hilbert space Y formed by the
measurements of the overall systems. At the instant k+1, this space is denoted
by Y(k + 1). The optimal minimum variance estimate ˆx(k + 1|k + 1) is given
by
ˆx(k + 1|k + 1) = IE{x(k + 1)|Y(k + 1)}
= IE{x(k + 1)|Y(k)} + E{x(k + 1)|˜y(k + 1|k)}
(11.4)
This equation spells out, in algebraic terms, the geometrical result of The-
orem 11.1.1. This motivates the idea of generating a ﬁlter by decomposing the
second term, that is, IE{x(k + l)|˜y(k + 1|k)}, such that the optimal estimate
˜x(k + 1|k + 1) is given using the two terms by considering the estimate as the
orthogonal projection of xj(k + 1) taken on the Hilbert space generated by
Y(k) ⊕˜Y1(k + 1|k) ⊕˜Y1
2(k + 1|k + 1)
⊕˜Y2
3(k + 1|k + 1) ⊕· · · ⊕˜Yns−1
ns
(k + 1|k + 1)
where ˜Yj−1
j
(k + 1|k + 1) is the subspace generated by the subspace of mea-
surements Yj(k + 1) and the projection of it on the subspaces generated by
Y(k) + Y1(k + 1) + Y2(k + 1) + . . . + Yj−1(k + 1), which leads to the fol-
lowing theorem.
Theorem 11.1.2 The optimal estimate ˆxj(k + 1|k + 1) of the ith subsystem is
given by the projection of xj(k+1) on the space generated by all measurements
up to k (Y(k)) and projection of xj(k + 1) on the subspace generated by
˜Y1(k + 1|k) ⊕˜Y1
2(k + 1|k + 1) + . . . ⊕˜Yns−1
ns
(k + 1|k + 1)

482
Chapter 11. Decentralized Filtering-II
Proof: Rewrite (11.4) as
ˆxj(k + 1|k + 1) = IE{xj(k + 1)|Y(k), y1(k + 1), y2(k + 1), . . .
yj(k + 1), yj+1(k + 1), . . . yns(k + 1)}
= IE{xj(k + 1)|Y(k), y1(k + 1), y2(k + 1) + . . .
+yj(k + 1), yi+1(k + 1), . . . yN−1(k + 1)}
+IE{xj(k + 1)|˜yN−1
N
(k + 1|k + 1)}
where
˜yN−1
N
(k + 1|k + 1) = yN(k + 1)
−E{yN(k + 1)|Y(k), y1(k + 1), . . . yN−1(k + 1)}
Equivalently stated,
ˆxj(k + 1|k + 1)
=
IE{xj(k + 1)|Y(k)}
+
IE{xj(k + 1)|˜y1(k + 1|k)}
+
ns

r=2
IE{xj(k + 1)|˜yr−1
r
(k + 1|k + 1)}
which establishes the desired result.
Using the idea of successive orthogonalization of the spaces deﬁned above,
the algebraic structure of the decentralized ﬁlter is described in the next section.
11.1.2
The algebraic structure
In order to develop the ﬁlter equations for the overall systems comprising ns
interconnected subsystems, write the equations for the overall systems as
x(k + 1)
=
φ(k + 1, k)x(k) + w(k)
y(k + 1)
=
H(k + 1)x(k + 1) + v(k + 1)
To display the subsystems structure more clearly, we decompose the above
equations as
xj(k + 1)
=
ns

k=1
φjk(k + 1, k)xk(k) + wj(k)
yj(k + 1)
=
Hj(k + 1)xj(k + 1) + vj(k + 1)

11.1. Decentralized Kalman Filtering
483
Then the optimal state prediction for the jth subsystem is given by
ˆxj(k + 1|k) =
ns

k=1
φjk(k + 1, k)ˆxj(k|k)
(11.5)
Now, by deﬁnition of the prediction errors, ˜xj(k + 1|k) = xj(k + 1) −ˆxj(k +
1|k). A recursive expression for the covariance of the prediction error can be
written as
Pjj(k + 1|k)
=
ns

k=1
ns

r=1
φjk(k + 1, k)
·P˜xk˜xrφt
ir(k + 1, k) + Qj(k)
=
ns

k=1
φjk(k + 1, k)
·
5 ns

r=1
P˜xk˜xr(k|k)φt
jr(k + 1, k)
6
+ Qj(k) (11.6)
Also,
Pjk(k + 1|k)
=
ns

r=1
ns

ℓ=1
φjr(k + 1, k)Prℓ(k|k)φt
kℓ(k + 1, k)
=
ns

r=1
φjr(k + 1, k)
5 ns

ℓ=1
Prℓ(k|k)φt
kℓ(k + 1, k)
6
(11.7)
It is easy to show, using the proof of Theorem 11.1.2, that
ˆxj(k + 1|k + 1)
=
ˆxj(k + 1|k + 1)ℓ
+
ns

r=ℓ+1
Pxj ˜yr−1
r
(k + 1|k + 1)
·P −1
˜yr−l
r
˜yr−1
r
(k + 1|k + 1)˜yr−1
r
(k + 1|k + 1)(11.8)
where
ˆxj(k + 1|k + 1)ℓ
=
ˆxj(k + 1|k + 1)ℓ−1
·kℓ−1
jℓ(k + 1)˜yℓ−1
ℓ
(k + 1|k + 1)
(11.9)
and
Pjj(k + 1|k + 1)l
=
Pjj(k + 1|k + 1)ℓ−1
−
Kℓ−1
jℓ
(k + 1)P˜yℓ−1
ℓ
˜xjℓ−1(k + 1|k + 1) (11.10)

484
Chapter 11. Decentralized Filtering-II
where
Kℓ−1
jiℓ(k + 1)
=
P˜xjℓ−1 ˜yℓ−1
ℓ
(k + 1|k + 1)
·P −1
˜yℓ−l
ℓ
˜yℓ−1
ℓ
(k + 1|k + 1)
(11.11)
˜yℓ−1
ℓ
(k + 1|k + 1)
=
˜yℓ−2
ℓ
(k + 1|k + 1)
−
Kℓ−2
ℓ−1(k + 1)˜yℓ−2
ℓ−1(k + 1|k + 1)
(11.12)
Kℓ−2
ℓℓ−1 = P˜yℓ−2
ℓ
˜yℓ−2
ℓ
(k + 1|k + 1)P −1
˜yℓ−2
ℓ−1 ˜yℓ−2
ℓ−1(k + 1|k + 1)
(11.13)
P˜yℓ−1
ℓ
˜yℓ−1
ℓ
(k + 1|k + 1)
=
P˜yℓ−2
ℓ
˜yℓ−2
ℓ
(k + 1|k + 1)
−
Kℓ−2
ℓℓ−1(k + 1)P˜yℓ−2
ℓ−1 ˜yℓ−2
ℓ−1(k + 1|k + 1)
(11.14)
P˜yℓ−1
ℓ
˜yℓ−1
ℓ
(k + 1|k + 1) = HℓP˜xℓ−1
ℓ
˜xℓ−1
ℓ
·(k + 1|k + 1)Ht
ℓ+ Rℓ(k + 1)
P˜xjℓ−1 ˜yℓ−1
ℓ
(k + 1|k + 1) = P˜xℓ−1
ℓ
˜xℓ−1
ℓ
(k + 1|k + 1)
·Ht
ℓ(k + 1)
(11.15)
Pjk(k + 1|k + 1)l = Pjk(k + 1|k + 1)ℓ−1
−
Kℓ−1
jℓ
(k + 1)P˜yℓ−1
ℓ
˜xℓ−1
k
(k + 1|k + 1)
(11.16)
In effect, (11.5)-(11.7) and (11.9)-(11.16) provide the algebraic equations of
the new ﬁlter
Implementation of the algorithm for one step of ﬁlter consists
of the following:
1. From (11.5), (11.6), and (11.7) we compute the prediction estimate as
well as its covariance matrix.
2. Put ℓ= 1 [note that ˆxj(k + 1|k + 1)0 = ˆxj(k + 1|k) and Pjk(k + 1|k +
1)0 = Pjk(k + 1|k)j = 1, . . . , ns k = 1, . . . , ns]. From (11.9)-(11.16),
we compute the ﬁltered estimate xj(k+1|k+1)ℓ, and the corresponding
covariance matrix.
3. If ℓ= N the resulting estimate is the optimal Kalman estimate and the
covariance matrix is the minimum error covariance matrix; otherwise go
to Step 2.

11.1. Decentralized Kalman Filtering
485
We note that although the foregoing algorithm and the global Kalman ﬁlter are
algebraically equivalent, the numerical properties of the decomposed ﬁlter are
signiﬁcantly better. In particular, the decentralized algorithm is amenable to
parallel processing [99]. Additionally, a good measure of the computation time
requirements of the global Kalman ﬁlter and the decentralized ﬁlter is given
by the number of elementary multiplication operations involved. To provide a
comparison, we assume that x ∈ℜn, y ∈ℜm x, then the number of mul-
tiplications required under the assumption that H is block diagonal and each
subsystem has the same number of states and outputs is
1.5n2 + 1.5n3
+
nm
 1
ns
+ m + 1
2ns
+ m + 1 + n + 1
2

+ m2(3m + 1)
2
where ns is the number of subsystem.
On the other hand, assume that all subsystems have an equal number of
state variables n/ns and an equal number of measurements m/ns. Then the
number of multiplications required is [99]:
1.5n2 + 1.5n3
+
ns +
5
mn
ns2 + mn(m + N)
2ns3
+
m2(3m
ns + 1)
2ns2
+
N
)
n2m
ns3 + nm2
ns3 + nm
ns2 + nm(n + ns)
2ns3
*
+
ns(ns −1)
2
.n2m
ns3

For high-order systems, substantial savings in computation time is quite evi-
dent.
11.1.3
Application to multimachine system
The multimachine power system under consideration consists of 11 coupled
machines. The model of an n-machine system consists of a set of nonlinear
equations that can be written for the ith machine as [99]:
Mj¨δj = Pj −
n

j=1
j̸=i
bijsinδij
i = 1, . . . , ns
where M is the inertia, P is the power injected, bij is the interconnection vari-
able, and δ is the angle.
For the system to be completely controllable and completely observable the

486
Chapter 11. Decentralized Filtering-II
nth machine is taken as reference. Then, by subtracting the nth equation from
the equation of each machine, a model can be constructed for the n machine
system.
For small perturbations, the nonlinear model can be linearized about the
equilibrium point so that the linear equations that result can be written in dis-
crete form:
x(k + l) = Ax(k) + ζ
For the 11-machine system, A is the 20 × 20 matrix given below and ζ is
a zero mean Gaussian white noise vector. For the ith machine, the observation
equation is given by
yj =

0
1
 x1i
x2i

+

uj

where yj is the speed of the ith machine and uj is also a zero mean Gaussian
white noise vector sequence.
A =
⎡
⎣
A1
A2
A3
A4
⎤
⎦
with
A1
=
⎡
⎢⎣
A11
· · ·
A15
...
...
...
A51
· · ·
A55
⎤
⎥⎦, A2 =
⎡
⎢⎣
A16
· · ·
A110
...
...
...
A56
· · ·
A510
⎤
⎥⎦,
A3
=
⎡
⎢⎣
A61
· · ·
A65
...
...
...
A101
· · ·
A105
⎤
⎥⎦, A4 =
⎡
⎢⎣
A66
· · ·
A610
...
...
...
A106
· · ·
A1010
⎤
⎥⎦
along with the numerical values
A11
=

1
0.006
−0.587
1

, A12 =

0
0
0.055
0

, A13 =

0
0
0.034
0

A14
=

0
0
0.016
0

, A15 =

0
0
0.025
0

, A16 =

0
0
−0.010
0

A17
=

0
0
−0.017
0

, A18 =

0
0
−0.034
0

, A19 =

1.0
0.006
−0.070
0

A110
=

0
0
−0.079
0

, A21 =

0
0
0.099
0

, A22 =

1
0.006
−0.8772
1


11.1. Decentralized Kalman Filtering
487
A23
=

0
0
0.06
0

, A24 =

0
0
0.055
0

, A25 =

0
0
0.042
0

A26
=

0
0
0.017
0

, A27 =

0
0
0.009
0

, A28 =

0
0
−0.013
0

A29
=

0
0
−0.044
0

, A210 =
 −0.059
0
0
0

, A31 =

0
0
0.066
0

A32
=

0
0
0.064
0

, A33 =

1.0
0.006
−0.725
1.0

, A34 =

0
0
0.039
0

A35
=

0
0
0.025
0

, A36 =

0
0
0.003
0

, A37 =

0
0
−0.007
0

A38
=

0
0
−0.029
0

, A39 =

0
0
−0.073
0

, A310 =
 −0.072
0
0
0

A41
=

0
0
0.053
0

, A42 =

0
0
0.113
0

, A43 =

0
0
0.048
0

A44
=

1
0.006
−0.825
1

, A45 =

0
0
0.025
0

, A46 =

0
0
0.017
0

A47
=

0
0
0.007
0

, A48 =

0
0
−0.019
0

, A49 =

0
0
−0.048
0

A410
=

0
0
−0.064
0

, A51 =

0
0
0.071
0

, A52 =

0
0
0.054
0

A53
=

0
0
0.037
0

, A54 =

0
0
0.027
0

, A55 =

1
0.006
−0.779
1

A56
=

0
0
0.0162
0

, A57 =

0
0
−0.004
0

, A58 =

0
0
−0.00083
0

A59
=

0
0
−0.059
0

, A510 =

0
0
−0.056
0

, A61 =

0
0
0.012
0

A62
=

0
0
0.012
0

, A63 =

0
0
0.011
0

, A64 =

0
0
0.008
0

A65
=

0
0
0.011
0

, A66 =

1
0.006
−0.623
1

, A67 =

0
0
0.012
0

A68
=

0
0
−0.006
0

, A69 =

0
0
−0.057
0

, A610 =

0
0
−0.062
0

A71
=

0
0
0.044
0

, A72 =

0
0
0.064
0

, A73 =

0
0
0.034
0


488
Chapter 11. Decentralized Filtering-II
A74
=

0
0
0.047
0

, A75 =

0
0
0.034
0

, A76 =

0
0
0.074
0

A77
=

1
0.006
−1.042
1

, A78 =

0
0
0.035
0

, A79 =

0
0
0.045
0

A710
=

0
0
−0.2750
0

, A81 =

0
0
0.0012
0

, A82 =

0
0
−0.0019
0

A83
=

0
0
0.004
1

, A84 =

0
0
−0.002
0

, A85 =

0
0
0.003
0

A86
=

0
0
0.008
0

, A87 =

0
0
−0.004
0

, A88 =

1
0.006
−0.558
1

A89
=

0
0
−0.0420
0

, A810 =
 0
0
0
0

, A91 =

0
0
0.0317
0

A92
=

0
0
0.047
0

, A93 =

0
0
0.025
0

, A94 =

0
0
0.035
0

A95
=

0
0
0.025
0

, A96 =

0
0
0.038
0

, A97 =

0
0
0.046
0

A98
=

0
0
0.050
0

, A99 =

1
0.006
−0.587
1

, A910 =

0
0
−0.003
0

A101
=

0
0
0.010
0

, A102 =

0
0
0.068
0

, A103 =

0
0
0.006
0

A104
=

0
0
0.005
0

, A105 =

0
0
0.011
0

, A106 =

0
0
0.010
0

A107
=

0
0
0.003
0

, A108 =

0
0
0.010
0

A109
=

0
0
−0.006
0

, A1010 =

1
0.006
−0.587
1

The covariances of ζ and u are given by Qj = 5 × I2 and Rj = I2,
respectively; P0 = 25 × I is the initial covariance matrix. The initial estimate
was taken to be zero while the initial states were all taken to be 10.
The global and decentralized ﬁlters are then simulated to illustrate the com-
putational behavior. The ensuing results for the global ﬁlter are plotted in Fig-
ures 11.1 - 11.3 for the ﬁrst three states and the corresponding estimates. The
corresponding states and estimates using the decentralized ﬁlter are depicted in
Figures 11.4 - 11.6. It should be observed that the global Kalman ﬁlter is nu-
merically unstable while the developed decentralized solution is stable. This is
essentially due to buildup of numerical errors when implementing a 20th-order

11.2. Decentralized Fault Detection
489
Figure 11.1: The global Kalman ﬁlter: ﬁrst state and estimate
Kalman ﬁlter. These numerical inaccuracies are avoided in the case of the co-
ordinated hierarchical solution as it implements only second-order subsystems
at each stage, thereby yielding stable ﬁlter.
In what follows, we direct attention to an approach for fault detection in
linear, stochastic, interconnected dynamic systems, based on designing a set of
decentralized ﬁlters for the subsystems resulting from overlapping decomposi-
tion of the overall large-scale system. The malfunctioning sensors are detected
and isolated by comparing the estimated values of a single state from different
Kalman ﬁlters.
11.2
Decentralized Fault Detection
An important problem facing engineers in industrial complexes, which has at-
tracted scientists and researchers in the ﬁeld of systems science, is the problem
of failure detection in running systems. A fault detection technique for large-
scale deterministic systems has been developed [338], using an overlapping
decomposition method. A clearly mentioned before, this concept has been uti-
lized [124] for constructing decentralized control strategies for interconnected
systems, such that each local subsystem has a range of information that may
partially overlap with that of other subsystems [129]. The central idea behind
the technique was the design of a set of Luenberger observers [182] for the
overlapping subsystems. Failures can be detected and localized by comparing
the estimates of the same states via the different observers.

490
Chapter 11. Decentralized Filtering-II
Figure 11.2: The global Kalman ﬁlter: second state and estimate
In this section, we extend the above technique to the important case of fault
detection in stochastic large-scale systems. We will beneﬁt from the appealing
result of the foregoing section and proceed to design a set of decentralized
Kalman ﬁlters based on the overlapping subsystems that constitute the overall
system considered. Discrepancies between the estimated values of the same
state from different Kalman ﬁlters point to the malfunctioning sensors.
11.2.1
System model
Consider a large-scale linear interconnected system S, which is described by
the following state and output equations:
x(k + 1)
=
Ax(k) + Bw(k)
(11.17)
y(k + 1)
=
Hx(k + 1) + v(k + 1)
(11.18)
where x(k) ∈ℜn is the state vector, w(k) ∈ℜm is the input noise vector,
y(k + 1) ∈ℜq is the output measurement vector, and u(k + 1) ∈ℜq is the
noise disturbing the output. A, B, and H are the system matrices of appropriate
dimensions, in which B and H are assumed to be block diagonal matrices with
ns blocks corresponding to the ns subsystems.
For the above system given by (11.17) and (11.18), we made the following
assumptions:
1. w(k) and v(k) are Gaussian random vectors with zero mean and covari-
ances given by IE{w(k)wt(j)} = Qδkj, IE{v(k)vt(j)} = Rδkj.

11.2. Decentralized Fault Detection
491
Figure 11.3: The global Kalman ﬁlter: third state and estimate
2. The disturbance vectors are uncorrelated, that is, IE{v(k)wt(j)} =
0 ∀k, j.
3. The initial state vector x(0) is a Gaussian random vector with mean
IE{x(O)} = μo and covariance IE{[x(O) −μ0][x(0) −μ0]t} = p(0).
4. x(0) and the noise vectors u(k) and w(k) are uncorrelated, that is,
IE{x(0)vt(k)} = 0, IE{x(O)wt(k)} = 0∀k.
11.2.2
Overlapping decomposition
Now, we proceed to identify the subsystem models. On considering the state
and output measurement models (11.17) and (11.18), we express the ith sub-
system Sj in the form
xj(k + 1)
=
Ajxj(k) + Bjwj(k) +
ns

k=1
Ajkxk(k)
(11.19)
yj(k + 1)
=
Hjxj(k + 1) + vj(k + 1)
(11.20)
where
xj ∈ℜnj, wj ∈ℜmj, yj ∈ℜqj, vj ∈ℜqj
and
ns

j=1
nj = n,
ns

j=1
mj = m,
ns

j=1
qj = q

492
Chapter 11. Decentralized Filtering-II
Figure 11.4: The decentralized Kalman ﬁlter: ﬁrst state and estimate
The state vector of the jth subsystem xj(k + 1) is partitioned into two parts:
xj(k + 1) =
⎡
⎣
xj1(k + 1)
. . . . . . . . . .
xj2(k + 1)
⎤
⎦,
j = 1, 2, . . . , ns
(11.21)
where
xi1 ∈ℜnj,1, xj2 ∈ℜnj,2 and
nj = nj,1 + nj,2
To comply with the principles of overlapping decomposition, each subsystem,
except the ﬁrst one, is expanded to include the second state vector of the pre-
ceding subsystem. The result is an overlapping decomposition scheme for the
overall system for which the state vector of the ith expanded subsystem is given
by
˜xj(k + 1) =
⎡
⎣
xj−1,2(k + 1)
xj,1(k + 1)
xj,2(k + 1)
⎤
⎦;
j = 2, 3, . . . , ns
(11.22)
Consequently, the state and output equations of the expanded overall system ˜S
are expressed by:
˜x(k + 1)
=
˜A˜x(k) + ˜Bw(k)
(11.23)
˜y(k + 1)
=
˜H˜x(k + 1) + v(k + 1)
(11.24)
where ˜x(k+1) ∈ℜn is the overall expanded state vector. Following the results
of Chapter 5, we have the fundamental relations
˜A = TAT t + M, ˜B = TB + N, ˜H = HT t + L, ˜x = Tx

11.2. Decentralized Fault Detection
493
Figure 11.5: The decentralized Kalman ﬁlter: second state and estimate
M, N, and L are complementary matrices of appropriate dimensions and T t
is the generalized inverse of T ∈ℜ˜n×n which is a transformation matrix given
by
T =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
Ij,1
Ij,2
Ij,2
0
I2,1
0
...
Ins,1
Ins,2
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
(11.25)
and
T ′ = (T tT)−1
(11.26)
where Ij,1 is an identity matrix with dimension (nj −nj,2) × (nj −nj,2) and
Ij,2 is an identity matrix with dimension nj,2 × nj,2, j = 1, 2, 3, . . . , ns.
11.2.3
Fault detection technique
In what follows, we consider the problem of detecting the malfunctioning sen-
sors of the augmented system ˜S, which comprises ns overlapping subsystems.
This will be carried out through the design of decentralized Kalman ﬁlters for
the subsystems and by comparing the estimated states, which are obtained by
two successive ﬁlters for each subsystem.

494
Chapter 11. Decentralized Filtering-II
Figure 11.6: The decentralized Kalman ﬁlter: third state and estimate
Neglecting the interactions with other subsystems for the time being, the
equations of the ith expanded subsystem ˜Sj are given by
˜xj(k + 1)
=
˜Aj ˜xj(k) + ˜Bjwj(k)
(11.27)
˜yj(k + 1)
=
˜Hj˜xj(k) + vj(k + 1)
(11.28)
It is interesting to emphasize that the results obtained for suboptimal decen-
tralized controllers can be applied by duality to the problem of decentralized
estimators [224]. Thus, in order to estimate the state ˜xj(k), we construct a set
of decentralized Kalman ﬁlters as follows:
ˆxj(k|k)
=
˜Aj ˆxj(k −1|k −1) + Kj ¯yj(k)
(11.29)
¯yj(k)
=
yj(k) −˜Hj ˜Aj ˆxj(k −1|k −1)
(11.30)
where Kj is the gain matrix computed by
kj = Pj(k|k −1) −˜Ht[ ˜HjPj(k|k −1) ˜Ht
j + Rj]−1
(11.31)
and Pj(k|k −1) is the covariance matrix of the predicted error, such that
Pj(k/k −1) = ˜AjPj(k/k) ˜At
j + ˜BjQj ˜Bt
j
(11.32)
Also, Pj(k/k) is the ﬁltered error covariance matrix given by
Pj(k|k) = Pj(k|k −1) −Kj ˜HjPj(k|k −1)
(11.33)

11.2. Decentralized Fault Detection
495
Owing to overlapping decomposition, the state vectors ˜xj and ˜xi−1 share the
part ˜xi−1,2, that is,
˜xj−1 =
⎡
⎣
˜xj−2,2
˜xj−1,1
˜xj−1,2
⎤
⎦
and
˜xj =
⎡
⎣
˜xj−1,2
˜xj,1
˜xj,2
⎤
⎦
Let K1, K2, . . . , Kns denote the N gain matrices of the local Kalman ﬁlters,
and [ˆxj−1,2(k/k)]s.s.(j−1), [ˆxj−1,2(k/k)]s.s.(j) represent the estimated values
of the state vector ˜xj−1,2 from the ﬁlters of subsystems j−1 and j, respectively.
During normal operation of the overall system we have
∥[ˆxj−1,2(k|k)]s.s.(j−1) −[ˆxj−1,2(k|k)]s.s.(j)∥< ϵ
(11.34)
where ϵ is a sufﬁciently small positive number and j = 2, 3, . . . , ns.
Interestingly enough, if one of the ns subsystem sensors is malfunctioning,
the above condition will then be violated. Thus, by inspecting the validity of
(11.34), we could not only detect the sensor failure among the ns subsystems,
but also know which one has failed.
It is important to emphasize that overlapping decomposition can be used
for the design of state feedback decentralized controllers which provide redun-
dancy in the overall system, hence yielding improved system reliability. In this
case, the estimated states from the set of decentralized Kalman ﬁlters can be
used to obtain the overlapping controllers. Therefore, the design procedure can
be used for both control and failure detection purposes. Figure 11.7 represents
the structure of this failure detection scheme, in which the comparison of the
state variables takes place at the higher level in a hierarchical structure of the
system.
11.2.4
Simulation results
To illustrate the developed fault-detection technique, we consider a simulation
example of a ladder network that may represent a high-voltage transmission
network or an LC ﬁltering circuit. The state dynamics and output equations are
given in the form
˙x(t)
=
Gx(t) + Fw(t) + c
(11.35)
y(t) = Hx(t) + v(t)
(11.36)

496
Chapter 11. Decentralized Filtering-II
Figure 11.7: Structure of failure detection scheme
where x, w ∈ℜ6; y, v ∈ℜ3 and G, F, H, and c are given by
G =
⎡
⎢⎢⎢⎢⎢⎢⎣
−1.5
1.2
0.0
0.0
0.0
0.0
0.8
−2.4
1.6
0.0
0.0
0.0
0.0
1.6
−2.4
0.8
0.0
0.0
0.0
0.0
0.6
−1.2
0.6
0.0
0.0
0.0
0.0
0.8
−2.4
1.6
0.0
0.0
0.0
0.0
4.8
−4.8
⎤
⎥⎥⎥⎥⎥⎥⎦
F is a 6 × 6 identity matrix.
H =
⎡
⎣
0.0
1.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
1.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
1.0
⎤
⎦
c = [0.291 0.008 −0.136 0.0 0.024 0.0]t
The above model is then discretized, assuming that w(t) and V (t) change
only at equally spaced sampling instants. Thus, the discrete model for a sam-
pling period T = 0.001 s is given by
x(k + 1)
=
Ax(k) + w(k) + c
(11.37)
y(k + 1)
=
Hx(k + 1) + v(k + 1)
(11.38)

11.2. Decentralized Fault Detection
497
where
A =
⎡
⎢⎢⎢⎢⎢⎢⎣
0.985
0.012
0.000
0.000
0.000
0.000
0.008
0.976
0.016
0.000
0.000
0.000
0.000
0.016
0.976
0.008
0.000
0.000
0.000
0.000
0.006
0.988
0.006
0.000
0.000
0.000
0.000
0.008
0.976
0.016
0.000
0.000
0.000
0.000
0.048
0.952
⎤
⎥⎥⎥⎥⎥⎥⎦
c =

0.00291
0.00008
−0.00136
0.0
0.00024
0.0
t
w(k) is assumed to be a zero mean Gaussian random vector with covariance
Q = diag

0.001
0.001
0.001
0.001
0.001
0.001

v(k) is assumed to be a Gaussian random vector with zero mean and covariance
R = diag

0.001
0.001
0.001

The initial state x(0) is a Gaussian random vector with zero mean and covari-
ance matrix P(O), given by
P(0) = diag

0.526
0.526
0.526
0.526
0.526
0.526

For the purpose of failure detection, the overlapping decomposition is applied
to the system (11.37) and (11.38), resulting in the following expanded system:
˜x(k + 1)
=
˜A˜x(k) + ˜w(k) + ˜c
(11.39)
y(k + 1)
=
˜H˜x(k + 1) + v(k + 1)
(11.40)
where
˜c =

0.0029
0.0008
0.0008
−0.00136
0.0
0.0
0.024
0.0
t
˜A =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
0.985
0.012
0.000
0.000
0.000
0.000
0.000
0.000
0.008
0.976
0.000
0.016
0.000
0.000
0.000
0.000
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
0.008
0.000
0.976
0.016
0.000
0.000
0.000
0.000
0.000
0.000
0.016
0.976
0.008
0.000
0.000
0.000
0.000
0.000
0.000
0.006
0.988
0.000
0.006
0.000
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
0.000
0.000
0.000
0.000
0.000
0.988
0.006
0.000
0.000
0.000
0.000
0.000
0.000
0.008
0.976
0.016
0.000
0.000
0.000
0.000
0.000
0.000
0.048
0.952
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦

498
Chapter 11. Decentralized Filtering-II
˜H =
⎡
⎢⎢⎢⎢⎣
0.0
1.0
0.0
0.0
0.0
0.0
0.0
0.0
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
0.0
0.0
0.0
0.0
1.0
0.0
0.0
0.0
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
0.0
0.0
0.0
0.0
0.0
0.0
0.0
1.0
⎤
⎥⎥⎥⎥⎦
˜x =

x1
x2
x2
x3
x4
x4
x5
x6
t
y =

y1
y2
y3
t
The overall system is decomposed into three interconnected subsystems, as
shown by the dotted lines in ˜A and ˜x. The decentralized Kalman ﬁlters are
computed for the subsystems. The steady-state gain matrices of the ﬁlters are
given below:
Subsystem 1 : k1 =
0.15722
0.61377

Subsystem 2 : k2 =
⎡
⎣
0.08593
0.13266
0.61600
⎤
⎦
Subsystem 3 : k3 =
⎡
⎣
0.17980
0.40430
0.62008
⎤
⎦
The computed gain matrices were used to estimate the system states in the
following cases:
1. Normal operation. For this case, we have
|[˜x2(k/k)]s.s.1 −[˜x2(k/k)]s.s.2| < ϵ1
and
|[ˆx4(k/k)]s.s.1 −[ˆx2(k/k)]s.s.3| < ϵ2
The results obtained are shown in Figures 11.8 and 11.9, and ϵ1 and
ϵ2 are constants which are usually determined by the experience of the
designer. In this application, ϵ1 and ϵ2 were taken to be equal to 0.1.
In the following cases, failures of the sensors of subsystems (11.17),
(11.18), and (11.19) are assumed to occur one at a time. Sufﬁcient time
is given for the estimators to produce satisfactory values of the estimated
states before the injection of sensor failures. To simulate these failures,
the output of the respective sensor falls to zero after 1.2 s.

11.2. Decentralized Fault Detection
499
Figure 11.8: Case I: Actual x2 and estimated x2
2. The sensors of subsystem 1 have failed (y1 = 0) after 1.2 s (1200 recur-
sions). As a result, we have
|[˜x2(k/k)]s.s.1 −[˜x2(k/k)]s.s.2| > ϵ1
and
|[ˆx4(k/k)]s.s.2 −[ˆx4(k/k)]s.s.3| < ϵ2
The estimate of x2 from subsystem 1 is highly affected, whereas that
from subsystem 2 is not. Consequently, the difference between these two
estimates exceeds ϵ1. The estimates of x4 from subsystems 2 and 3 are
not affected by this failure. The results are shown in Figures 11.10 and
11.11, respectively.
3. The sensors of subsystem 2 have failed (y2 = 0) after 1.2 s (1200 recur-
sions), thus:
|[˜x2(k/k)]s.s.1 −[˜x2(k/k)]s.s.2| > ϵ1
and
|[ˆx4(k/k)]s.s.2 −[ˆx4(k/k)]s.s.3| > ϵ2
In this case, as shown by Figures 11.12 and 11.13, the difference be-
tween the estimates of x2 obtained by subsystems 1 and 2, as well as
that between the estimates of x4 from subsystems 2 and 3, exceeds the
prespeciﬁed values of ϵl and ϵ2.

500
Chapter 11. Decentralized Filtering-II
Figure 11.9: Case I:Actual x4 and estimated x4
Figure 11.10: Case II: Actual x2 and estimated x2

11.2. Decentralized Fault Detection
501
Figure 11.11: Case II: Actual x4 and estimated x4
4. The sensors of subsystem 3 have failed (y3 = 0) after 1.2 s (1200 recur-
sions), yielding
|[ˆx2(k/k)]s.s.1 −[ˆx2(k/k)]s.s.2| < ϵ1
and
|[ˆx4(k/k)]s.s.2 −[ˆx4(k/k)]s.s.3| > ϵ2
As shown in Figures 11.14 and 11.15, the estimates of x2 are not affected,
whereas the difference between the estimates of x4 exceeds ϵ2. Figures 11.16
- 11.21 show the estimated states in the different cases of affected sensors.
The obtained results, demonstrated by the previous ﬁgures, indicate that the
proposed fault detection scheme not only detects failure, but can also localize
the malfunctioning sensors in the system.
This is achieved by overlapping
decomposition of the system, and the design of a set of decentralized Kalman
ﬁlters for the subsystems. It is shown that, by comparing the estimates of the
states shared by the overlapped subsystems, it is possible to detect and isolate
the malfunctioning sensors in the system. The results of the simulation example
emphasize the efﬁciency of the proposed technique.

502
Chapter 11. Decentralized Filtering-II
Figure 11.12: Case III: Actual x2 and estimated x2
Figure 11.13: Case III: Actual x4 and estimated x4

11.2. Decentralized Fault Detection
503
Figure 11.14: Case IV: Actual x4 and estimated x4
Figure 11.15: Case IV: Actual x4 and estimated x4

504
Chapter 11. Decentralized Filtering-II
Figure 11.16: Case II: Estimated x1, x2, and x3
Figure 11.17: Case II: Estimated x4, x5, and x6

11.2. Decentralized Fault Detection
505
Figure 11.18: Case III: Estimated x1, x2, and x3
Figure 11.19: Case III: Estimated x4, x5, and x6

506
Chapter 11. Decentralized Filtering-II
Figure 11.20: Case IV: Estimated x1, x2, and x3
Figure 11.21: Case IV: Estimated x4, x5, and x6

11.3. Problem Set IX
507
11.3
Problem Set IX
Problem IX.1: Consider a collection of ns linear coupled static models of the
form
zj
=
Hjjθj +
ns

m=1,m̸=j
Hjmθm + ψj, j = 1, ..., ns
where zj ∈ℜnj, θj ∈ℜmj, and ψj ∈ℜmj are the subsystem measurement
vector, the constant parameter vector, and the vector of measurement errors,
respectively. Also, Hjj ∈ℜnj×mj is the modulation matrix with known ele-
ments. It is assumed that θj, ψj are independent Gaussian random vectors with
the parameters
IEθj
=
μj, varθj = Pj, IEψj = 0, varψj = Qj
The objective is to derive a nonrecursive two-level algorithm that computes the
optimum minimum variance estimate. You may extend the ideas of multiple
projection approach. Provide an assessment of the computational requirements.
Problem IX.2: Consider the model of Problem IX.1. Develop a two-level re-
cursive algorithm for the minimum variance estimator and evaluate the struc-
ture of the different covariance matrices. Show the performance of the algo-
rithm on the following single-input single-output discrete transfer function with
unknown coefﬁcients
y(z)
u(z) = bo + b1z−1 + · · · + bnz−n
1 + a1z−1 + · · · + anz−n
Consider two speciﬁc model parameters:
Model 1
=
bo = 0, b1 = 1, b2 = 0.5, a1 = −1.5, a2 = 0.7
Model 2
=
bo = 1, b1 = 0.1, b2 = −0.8, b3 = 0, b4 = −0.45,
a1 = −2.3, a2 = 1.93, a3 = −0.713, a4 = 0.11,
a5 = −0.006
and use appropriate values for Pj and Qj.
Problem IX.3: A decentralized control system in standard feedback conﬁg-
uration with the actuator and decentralized controller are in cascade with the

508
Chapter 11. Decentralized Filtering-II
process in the forward path and the sensor in the feedback path is considered.
Let the state-space realization be given by
˙x(t)
=
A x(t) + B ua(t),
y(t)
=
C x(t)
where x ∈ℜn is the state vector, ua ∈ℜm is the actuator output vector, and
y ∈ℜm is the process output vector. The outputs from the controller and the
sensor are u
∈ℜm and ys
∈ℜm, respectively. The model of actuator and
sensor failures can be represented by
ua(t)
=
Ea x(t) + fa,
ys
=
Es y(t) + fs
where Ea, Es ∈ℜn×n are the diagonal actuator and sensor fault matrices that
inﬂuence the closed-loop stability. Design the decentralized output-feedback
controller
ua(t) = F y(t) + r, F ∈ℑ⊂ℜm×m
such that the resulting closed-loop system is asymptotically stable, where
ℑ⊂ℜm×m denotes the set of matrices that have prespeciﬁed structures. Dis-
cuss the features of several controller forms in detecting several fault patterns.
Problem IX.4: Consider a linear discrete model that includes possible loss of
control effectiveness of the form
xk+1
=
Ak xk + Bk uk + Ekγk + wk,
yk+1
=
Ck xk+1 + vk+1
where xk
∈ℜn, uk
∈ℜm, and yk+1
∈ℜp are the state, control input,
and output variables, respectively, and wk and vk+1 denote the white noise
sequences of uncorrelated Gaussian random vectors with zero means and co-
variance matrices Qk and Rk+1, respectively. The initial state xo is speciﬁed
as a random Gaussian vector with means φ and covariance Po. The matrices
Ek, γk are speciﬁed by
Ek
=
Bk Uk, Uk = Blockdiagonal[u1
k, u2
k, ..., um
k ],
γk
=
col[γ1
k, γ2
k, ..., γm
k ]
The objective is to examine the loss in control effectiveness by introducing the
control effectiveness factors such that
γk+1 = γk + wk,
−1 ≤γjk ≤0, j = 1, ..., m

11.4. Notes and References
509
with the mean and covariance of γk being 0 and S, respectively. Develop the
minimum variance solution by a direct application of a two-stage Kalman ﬁlter
algorithm. Then examine the application of controller
uk = −Fkˆxk|k −Hkˆγk|k
by invoking the separation theorem and study the behavior of the closed-loop
system.
11.4
Notes and References
In the ﬁrst part of this chapter, an improved decentralized algorithm has been
developed for optimal state estimation in large-scale linear interconnected dy-
namical systems. The algorithm essentially embodies a series of successive
orthogonalization on the measurement subspaces for each subsystem within a
hierarchical computational structure in order to provide the optimal estimate. In
turn, this ensures substantial savings in computation time. Additionally, since
only low-order subsystem equations are manipulated at each stage, numerical
inaccuracies are drastically reduced and the ﬁlter remains stable for even high-
order systems. The hierarchical structure is ideally suited for implementation
using a parallel processing system and the effectiveness of the algorithm has
been demonstrated on multiple machine power systems. Ample extensions de-
mand further investigation to improve the efﬁciency and widen the applicability
of decentralized Kalman ﬁltering.
In the second part of this chapter, we have developed a decentralized ap-
proach for failure detection in large-scale interconnected stochastic dynamic
systems. The approach exploits the advantages of overlapping decomposition
technique and the ﬂexible design of a set of decentralized Kalman ﬁlters for the
subsystems. By comparing the estimates of the states shared by the overlapped
subsystems, it is shown in principle to achieve the detection and isolation of
the malfunctioning sensors in the system.

Chapter 12
Epilogue
In this closing chapter, it is our hope that an agreement must have be reached
that decentralized systems would be the most convenient designation for large-
scale systems, complex systems, or interconnected systems since the chief goal
in these systems is to deploy decentralization in the analysis, control, ﬁltering,
and processing tasks. Equivalently stated, the effort of any task is distributed
among various units that are cooperating to achieve the desired objective. In
what follows, a critical evaluation of the achieved versus remaining results is
made with reference to the major ideas including decomposition, coordination,
decentralization, and overlapping. In particular, our purpose hereafter is to shed
more light on some prevailing aspects and potential remarks in decentralized
systems.
12.1
Processing Aspects
Initially, we note that a comparison between distributed information process-
ing (DIP) and centralized information processing (CIP) schemes reveals the
following features:
1. The computations within DIP schemes are much easier because less in-
formation is needed and manipulated.
2. Parallel computation of DIP is possible without the need for complete
synchronization.
3. The computation is reliable of DIP as far as failures in the computing
elements are concerned.
511

512
Chapter 12. Epilogue
This eventually leads us to the ﬁrst potential remark that decentralized schemes
can be applied by means of low-cost computing facilities. However, the under-
lying off-line effort behind DIP is quite tremendous. The problem of decom-
posing the overall analytical and design problems adequately is crucial in or-
der to guarantee that the resulting subproblems are relatively autonomous (or
have some degrees of freedom) if strong coordination is to be avoided. This
in turn poses a fundamental compromise between off-line efforts and on-line
processing in the sense that to make sacriﬁce at the beginning would be to gain
advantages at the end.
Therefore the degree of success made in developing large-scale systems
theories has to be contrasted with regard to its contribution to the solution of
this fundamental problem.
12.2
Modeling and Analysis Aspects
A predominant characteristic of large-scale systems (LSS) is the underlying
structure of different interacting subsystems. This is reﬂected by examining the
models explained in Chapter 3. It is quite natural to seek clariﬁcation of the role
in which the performance of LSS depends on the properties of the subsystems
and the interaction relations. It must be emphasized that the features, merits,
and demerits of the coupling pattern are of primary concern; particularly, one
has to investigate whether the subsystems are weakly or strongly coupled and
whether the couplings turn out to be cooperative or competitive in nature. By
and large, our guided tour throughout the book has shown that interconnected
systems can be classiﬁed into three main groups as follows.
12.2.1
Serially coupled systems
In typical systems appearing in water resources and petrochemical industries,
the subsystems have a unidirectional pattern of interaction arising from the
mass or energy ﬂow. In those cases, the model structures might dictate a tech-
nique for the underlying analysis and design problems including coordinated
control. In this way, the analysis and design subproblems are directly associ-
ated with the subsystems in addition to a coordinator that supervises the overall
job.
12.2.2
Weakly coupled subsystems
As demonstrated throughout the book, we mean here that LSS is comprised
of interacting subsystems but the interactions inﬂuence the subsystem behavior

12.2. Modeling and Analysis Aspects
513
weakly. By and large, interactions are weak if the links have low reinforcements
or if the time-scales of the subsystems are quite different. There are numerous
measures for weak-coupling; see Chapter 3. Analytical and design problems
of LSS with weakly coupled subsystems can be decomposed according to the
subsystem structure of the overall system, but the resulting subproblems are
still dependent upon each other. Iterative procedures are invoked to reduce this
interdependence.
12.2.3
Strongly coupled subsystems
This is evidently the general case. Due to the strong interdependence among
subsystems, analytical and design problems cannot be effectively divided along
the boundaries of the subsystems. Rather, each subsystem has to be considered
within its own surrounding, or some approximation of it. In this regard, diago-
nal dominance (Chapter 3), overlapping decomposition (Chapter 5), or particu-
lar methods utilizing the symmetric structure of the system (Chapter 7) can be
used to derive subproblems with weak interdependence.
With regards to the available decomposition methods, some prominant fea-
tures are important to mention for the purpose of their evaluation and future
extension:
1. Decomposition methods rely heavily on structural properties of the over-
all system. Looked at in this light, graph theoretic methods seem to pro-
vide a promising direction for LSS with high dimension and uncertain-
ties. Such a direction has not been fully exploited.
2. The boundaries deﬁning individual subsystems appear to be a matter of
engineering intuition. The appropriate criteria would be to select those
parts of the overall system that identify subsystems with weak interac-
tions, that belong to the slow or fast part of the system, or that have to be
used as the overlapping parts. Strictly speaking, the question of where
to place the boundaries of the subsystems in a practical example has not
been satisfactorily answered and demands further research activities.
3. The degree of success of a given decomposition method hinges upon the
appropriate design of the associated control stations to form a decen-
tralized feedback system in which the couplings between the subsystems
turn out to be weak. This is a sort of a posteriori judgment and deserves
further investigations of reasonable decompositions that start from the
closed-loop system.

514
Chapter 12. Epilogue
4. The literature is nearly void of techniques to establish modeling and
identiﬁcation schemes of LSS that avoid setting up a model of the overall
system but rather end up directly with separate models of the subsystems
including their speciﬁc surroundings. Indeed, this is a challenging ap-
proach. Opposite to the prevailing trend of deriving the models of the
subsystems from the overall system description, the ultimate objective
would be new methods that have to be characterized to select that part
or those properties of LSS that have to be referred to in the analysis of a
certain subsystem or the design of a certain local control station.
12.2.4
Multivariable design methods
We have learned from Chapter 4 that analytical and design methods based on
the multivariable control theory have been satisfactorily extended to decentral-
ized systems. It turns out that ﬁxed modes occur as direct consequence of the
on-line information structure constraints of decentralized control and therefore
occur more for decentralized control than for centralized control. The design
principles of pole assignment and optimal control have been extended to de-
centralized controllers (Chapters 3 and 4). It was shown clearly how the overall
system behaves under the control of several independent control agents.
The extent of applicability of the multivariable (centralized) design princi-
ples to LSS poses major difﬁculties. The main reasons for this are:
1. A complete model of the LSS has to be known,
2. Most of the manipulations have to be carried out with this large-order
model, and
3. The design goals are formulated for the overall system.
Strictly speaking, these design methods are, therefore, applicable only for rela-
tively small systems, where decentralized controllers are to be used and where
the dimensionality and uncertainty of the plant does not pose serious difﬁcul-
ties in the analytical and design problems. Exception to this is the treatment of
decentralized systems with hierarchical structures; see Chapter 4.
12.2.5
Design of decentralized systems
Experience has shown that new problems arise whenever the information struc-
ture used in the off-line procedures of analysis and design is somehow con-
strained. Decentralized control is realized in the form of several control agents

12.2. Modeling and Analysis Aspects
515
(independent with no communication) although, in reality, the subproblems re-
sulting from a decomposition procedure of the overall problem are usually cou-
pled (weakly or strongly). This approach could be phrased as multicontroller
structure approach.
A major concern arises here: How can the discrepancy conﬂicts between
the solutions of the subproblems be resolved?
Given the goals of the subsystem and the subsystem interactions, the sub-
problems can generally be cooperative or competitive. Theoretical investiga-
tions showed that in the former case, conﬂict resolution represents a minor
problem, so that no or only a simple coordination is necessary. On the other
hand in the latter case, major conﬂicts occur and pose the main difﬁculties for
the solution.
Conﬂict resolution within a decentralized information structure has to be
made possible by appropriately organizing the analytical or design process. Re-
garding the construction of analytical and design schemes with decentralized
information structure can incorporate some sequencing order among control
agents, in which case each design step has a centralized information structure.
Since only one control station is considered at a time, the subsystem controller
can be designed as a centralized feedback. The speciﬁcation of the sequenc-
ing order is crucial to guarantee that the designed decentralized controller will
eventually satisfy the design speciﬁcations stated for the overall system. Much
more work is needed to derive design speciﬁcations for the kth design step
from the given overall system speciﬁcations.
Alternatively, with the overall system being split into weakly coupled sub-
systems the design problem can then be decomposed accordingly and solved
while ignoring the subsystem interactions. The control stations obtained from
independent design problems are used together to constitute a ﬁrst-level of a co-
ordinated control. On the second level, there is another supervisory controller
to accommodate the interaction pattern; see Chapter 3.
12.2.6
Application aspects
As repeatedly emphasized throughout the book, high dimensionality, infor-
mation structure constraints, model uncertainty, gain perturbations, and time-
delays characterize the complexity of large-scale systems. Depending on the
practical application under consideration, one aspect or another dominates. All
the methods described in this volume take account of these aspects to a differ-
ent extent and thus have their speciﬁc ﬁelds of application.
A major facet pertaining to the large body of analytical and design methods
is that the practically prevailing question of which method should be applied to

516
Chapter 12. Epilogue
the practical problem at hand is quite open. Engineering intuition and human
experience are certainly needed in order to assess modeling and measurement
information concerning its importance for the solution of a given problem and
to structure the plant and the analytical and design processes accordingly.
In conclusion, the theory of feedback control of decentralized systems
contributes to the application of two distinct but related areas: the control
of large (interconnected), spatially distributed dynamical processes, and dis-
tributed computing for implementing control algorithms. It essentially provides
the control engineer with the technical background and design algorithms that
facilitate an efﬁcient solution of complex control problems by using modern
computing facilities.

Chapter 13
Appendix
In this appendix, we collect some useful mathematical inequalities and lemmas
that have been extensively used throughout the book.
13.1
Stability Notions
In this section, we present some deﬁnitions and results pertaining to stability of
dynamical systems. A detailed account of this topic can be found in [9, 176].
Deﬁnition 13.1.1 A function of x and t is a carathedory function if, for all
t ∈ℜ, it is continuous in x and for all x ∈ℜn, it is Lebesgue measurable in
t.
13.1.1
Practical stabilizability
Given the uncertain dynamical system
˙x(t)
=
[A + ΔA(r) + M]x(t) + [B + ΔB(s)]u(t)
+
Cv(t) + H(t, x, r),
x(0) = xo
(13.1)
y(t)
=
x(t) + w(t)
(13.2)
where x ∈ℜn, u ∈ℜm, y =∈ℜn, v ∈ℜs, w ∈ℜn are the state, control,
measured state, disturbance, and measurement error of the system, respectively,
and r ∈ℜp, s ∈ℜq are the uncertainty vectors. System (13.1)-(13.2) is said to
be practically stabilizable if, given d > 0, there is a control law g(., .) : ℜm ×
ℜ→ℜm, for which, given any admissible uncertainties r, s, disturbances
w ∈ℜn, v ∈ℜs, any initial time to ∈ℜ, and any initial state xo ∈ℜn, the
following conditions hold:
517

518
Chapter 13. Appendix
1. The closed-loop system
˙x(t)
=
[A + ΔA(r) + M]x(t) + [B + ΔB(s)]g(y, t)
+
Cv(t) + H(t, x, r)
(13.3)
possesses a solution x(.) : [to, t1] →ℜn, x(to) = xo.
2. Given any ν > 0 and any solution x(.) : [to, t1] →ℜn, x(to) = xo of
system (13.3) with ||xo|| ≤ν, there is a constant d(ν) > 0 such that
||x(t)|| ≤d(ν), ∀t ∈[to, t1].
3. Every solution x(.) : [to, t1] →ℜn can be continued over [to, ∞).
4. Given any ¯d ≥d, any ν > 0 and solution x(.) : [to, t1] →ℜn, x(to) =
xo of system (13.3) with ||xo|| ≤ν, there exists a ﬁnite time T( ¯d, ν) <
∞, possibly dependent on ν but not on to, such that ||x(t)|| ≤¯d, ∀t ≥
to + T( ¯d, ν).
5. Given any d ≥d and any solution x(.) : [to, t1] →ℜn, x(to) = xo
of system (13.3) there is a constant δ(d) > 0 such that ||x(to)|| ≤δd
implies ||x(t)|| ≤¯d, ∀t ≥to.
13.1.2
Razumikhin stability
A continuous function α : [0, a) −→[0, ∞) is said to belong to class K if it
is strictly increasing and α(0) = 0. Further, it is said to belong to class K∞if
a = ∞and limr→∞α(r) = ∞.
Consider a time-delay system
˙x(t) = f(t, x(t −d(t))
(13.4)
with an initial condition
x(t) = (t),
t ∈[−¯d, 0]
where the function vector f : ℜ+ × C[−¯d,0] →ℜn takes R× (bounded
sets of C[−¯d,0]) into bounded sets in ℜn; d(t) is the time-varying delay and
d := supt∈ℜ+{d(t)} < ∞. The symbol C[a,b] represents the set of ℜn-valued
continuous function on [a, b].
Lemma 13.1.2 If there exist class K∞functions ζ1(.) and ζ2(.),
a class K
function ζ3(.) and a function V1(.) : [−¯d, ∞] × ℜn →ℜ+ satisfying
ζ1(||x||) ≤V1(t, x) ≤ζ2(||x||),
t ∈ℜ+, x ∈ℜn

13.1. Stability Notions
519
such that the time derivative of V1 along the solution of the system (13.4) sat-
isﬁes
˙V1(t, x) ≤−ζ3(||x||) if
V1(t + d, x(t + d)) ≤V1(t, x(t))
(13.5)
for any d ∈[−¯d, 0], then system (13.4) is uniformly stable. If, in addition,
ζ3(τ) > 0, τ > 0
and there exists a continuous nondecreasing function ξ(τ) > 0, τ > 0 such
that (13.5) is strengthened to
˙V1(t, x) ≤−ζ3(||x||) if
V1(t + d, x(t + d)) ≤ξ(V1(t, x(t)))
(13.6)
for any d ∈[−¯d, 0],
then system (13.4) is uniformly asymptotically stable.
Further, if, in addition, limτ→∞ζ1(τ) = ∞, then system (13.4) is globally
uniformly asymptotically stable.
The proof of this lemma can be found in [93].
Lemma 13.1.3 Consider system (13.4). If there exists a function
Vo(x) = xtPx, P > 0
such that for d ∈[−¯d, 0] the time derivative of Vo along the solution of system
(13.4) satisﬁes
˙Vo(t, x) ≤−q1∥x∥2 if
Vo(x(t + d)) ≤q2Vo(x(t))
(13.7)
for some constants q1 > 0 and q2 > 1, then the system (13.4) is globally
uniformly asymptotically stable.
Proof: Since P > 0, it is clear that
λmin(P)∥x∥2 ≤Vo(x) ≤λmax(P)∥x∥2
Let ζ1(τ) = λmin(P)τ 2 and ζ2(τ) = λmax(P)τ 2. It is easy to see that both
ζ1(.) and zeta2(.) are class K∞functions and
ζ1(∥x∥) ≤V0(x) ≤ζ2(∥x∥),
xℜn
Further, let zeta3() = −q1 τ 2 and ξ(τ) = q2 τ. It is evident from q1 > 0 and
q2 > 1 that for τ > 0,
ξ(τ) > and ζ3(τ) > 0
Hence, the conclusion follows from (13.7).

520
Chapter 13. Appendix
13.2
Basic Inequalities
All mathematical inequalities are proved for completeness. They are termed
facts due to their high frequency of usage in the analytical developments.
13.2.1
Inequality 1
For any real matrices Σ1 , Σ2, and Σ3 with appropriate dimensions and
Σt
3 Σ3 ≤I, it follows that
Σ1Σ3Σ2 + Σt
2Σt
3Σt
1 ≤α Σ1Σt
1 + α−1 Σt
2Σ2,
∀α > 0
Proof: This inequality can be proved as follows. Since ΦtΦ ≥0 holds for any
matrix Φ, then take Φ as
Φ = [α1/2 Σ1 −α−1/2 Σ2]
Expansion of ΦtΦ ≥0 gives ∀α > 0
α Σ1Σt
1 + α−1 Σt
2Σ2 −Σt
1Σ2 −Σt
2Σ1 ≥0
which by simple arrangement yields the desired result.
13.2.2
Inequality 2
Let Σ1, Σ2, Σ3 and 0 < R = Rt be real constant matrices of compatible di-
mensions and H(t) be a real matrix function satisfying Ht(t)H(t) ≤I. Then
for any ρ > 0 satisfying ρΣt
2Σ2 < R , the following matrix inequality holds:
(Σ3 + Σ1H(t)Σ2)R−1(Σt
3 + Σt
2Ht(t)Σt
1)
≤
ρ−1Σ1Σt
1 + Σ3

R −
ρΣt
2Σ2
−1
Σt
3
Proof: The proof of this inequality proceeds like the previous one by consider-
ing that
Φ = [(ρ−1 Σ2Σt
2)−1/2Σ2R−1Σt
3 −(ρ−1 Σ2Σt
2)−1/2Ht(t)Σt
1]
Recall the following results:
ρΣt
2Σ2 < R,
[R −ρΣt
2Σ2]−1 = [R−1 + R−1Σt
2[ρ−1I −Σ2R−1Σt
2]−1Σ2R−1Σ2

13.2. Basic Inequalities
521
and
Ht(t)H(t) ≤I =⇒H(t)Ht(t) ≤I
Expansion of ΦtΦ ≥0 under the condition ρΣt
2Σ2 < R with standard matrix
manipulations gives
Σ3R−1Σt
2Ht(t)Σt
1 + Σ1H(t)Σ2R−1Σt
3 + Σ1H(t)Σ2Σt
2Ht(t)Σt
1 ≤
ρ−1Σ1H(t)Ht(t)Σt
1 + Σt
3R−1Σ2[ρ−1I Σ2Σt
2]−1Σ2R−1Σt
3 =⇒
(Σ3 + Σ1H(t)Σ2)R−1(Σt
3 + Σt
2Ht(t)Σt
1) −Σ3R−1Σt
3 ≤
ρ−1Σ1H(t)Ht(t)Σt
1 + Σt
3R−1Σ2[ρ−1I −Σ2Σt
2]−1Σ2R−1Σt
3 =⇒
(Σ3 + Σ1H(t)Σ2)R−1(Σt
3 + Σt
2Ht(t)Σt
1) ≤
Σ3[R−1 + Σ2[ρ−1I −Σ2Σt
2]−1Σ2R−1]Σt
3 +
ρ−1Σ1H(t)Ht(t)Σt
1 =
ρ−1Σ1H(t)Ht(t)Σt
1 + Σ3

R −ρΣt
2Σ2
−1
Σt
3
which completes the proof.
∇∇∇
13.2.3
Inequality 3
For any real vectors β, ρ and any matrix Qt = Q > 0 with appropriate dimen-
sions, it follows that
−2ρtβ ≤ρt Q ρ + βt Q−1 β
Proof: Starting from the fact that
[ρ + Q−1β]t Q [ρ + Q−1β] ≥0 , Q > 0
which when expanded and arranged yields the desired result.
∇∇∇
13.2.4
Inequality 4 (Schur complements)
Given a matrix Ω composed of constant matrices Ω1, Ω2, Ω3 where Ω1 = Ωt
1
and 0 < Ω2 = Ωt
2 as follows:
Ω =
 Ω1
Ω3
Ωt
3
Ω2

We have the following results:

522
Chapter 13. Appendix
(A)
Ω ≥0 if and only if either
⎧
⎨
⎩
Ω2 ≥0
Π = ΥΩ2
Ω1 −Υ Ω2 Υt ≥0
(13.8)
or
⎧
⎨
⎩
Ω1 ≥0
Π = Ω1Λ
Ω2 −Λt Ω1 Λ ≥0
(13.9)
hold where Λ, Υ are some matrices of compatible dimensions.
(B)
Ω > 0 if and only if either

Ω2 > 0
Ω1 −Ω3 Ω−1
2
Ωt
3 > 0
or

Ω1 ≥0
Ω2 −Ωt
3 Ω−1
1
Ω3 > 0
hold where Λ, Υ are some matrices of compatible dimensions.
In this regard, matrix Ω3 Ω−1
2
Ωt
3 is often called the Schur complement
Ω1(Ω2) in Ω.
Proof: (A) To prove (13.8), we ﬁrst note that Ω2
≥0 is necessary. Let
zt = [zt
1
zt
2] be a vector partitioned in accordance with Ω. Thus we have
zt Ω z = zt
1Ω1z1 + 2zt
1Ω3z2 + zt
2Ω2z2
(13.10)
Select z2 such that Ω2z2 = 0. If Ω3z2 ̸= 0, let z1 = −πΩ3z2, π > 0. Then
it follows that
zt Ω z = π2 zt
2Ωt
3Ω1Ω3z2 −2π zt
2Ωt
3Ω3z2
which is negative for a sufﬁciently small π > 0. We thus conclude Ω1 z2 = 0
which then leads to Ω3z2 = 0, ∀z2 and consequently
Ω3 = Υ Ω2
(13.11)
for some Υ.
Since Ω ≥0, the quadratic term zt Ω z possesses a minimum over z2 for
any z1. By differentiating zt Ω z from (13.10) wrt zt
2, we get
∂(zt Ω z)
∂zt
2
= 2Ωt
3 z1 + 2Ω2 z2 = 2Ω2 Υt z1 + 2Ω2 z2

13.2. Basic Inequalities
523
Setting the derivative to zero yields
Ω2 Υ z1 = −Ω2 z2
(13.12)
Using (13.11) and (13.12) in (13.10), it follows that the minimum of zt Ω z
over z2 for any z1 is given by
min
z2
zt Ω z = zt
1[Ω1 −Υ Ω2 Υt]z1
which proves the necessity of Ω1 −Υ Ω2 Υt ≥0.
On the other hand, we note that the conditions (13.8) are necessary for
Ω ≥0 and since together they imply that the minimum of zt Ω z over z2 for
any z1 is nonnegative, they are also sufﬁcient.
Using a similar argument, conditions (13.9) can be derived as those of
(13.8) by starting with Ω1.
The proof of (B) follows as a direct corollary of (A).
13.2.5
Inequality 5
For any quantities u and v of equal dimensions and for all ηt = i ∈S, it
follows that the following inequality holds:
||u + v||2 ≤[1 + β−1] ||u||2 + [1 + β]||v||2
(13.13)
for any scalar β > 0,
i ∈S
Proof: Since
[u + v]t [u + v] =
ut u + vt v + 2 ut v
(13.14)
it follows by taking norm of both sides of (13.14) for all i ∈S that
||u + v||2 ≤||u||2 + ||v||2 + 2 ||ut v||
(13.15)
We know from the triangle inequality that
2 ||ut v|| ≤β−1 ||u||2 + β ||v||2
(13.16)
On substituting (13.16) into (13.15), it yields (13.13).

524
Chapter 13. Appendix
13.2.6
Inequality 6
Given matrices 0 < Qt = Q, P = Pt, then it follows that
−PQ−1P ≤−2 P + Q
(13.17)
This can be easily established by considering the algebraic inequality
(P −Q)tQ−1(P −Q) ≥0
and expanding to get
PQ−1P −2P + Q ≥0
(13.18)
which when manipulating, yields (13.17). An important special case is obtained
when P ≡I, that is,
−Q−1 ≤−2 I + Q
(13.19)
This inequality proves useful when using Schur complements to eliminate the
quantity Q−1 from the diagonal of an LMI without alleviating additional math
operations.
13.3
Lemmas
The basic tools and standard results that are utilized in robustness analysis and
resilience design in the different chapters are collected hereafter.
Lemma 13.3.1 The matrix inequality
−Λ + S Ω−1 St <
0
(13.20)
holds for some 0 < Ω = Ωt ∈ℜn×n, if and only if
 −Λ
SX
•
−X −X t + Z

<
0
(13.21)
holds for some matrices X ∈ℜn×n and Z ∈ℜn×n.
Proof: (=⇒) By Schur complements, inequality (13.20) is equivalent to
 −Λ
SΩ−1
•
−Ω−1

<
0
(13.22)

13.3. Lemmas
525
Setting X = X t = Z = Ω−1, we readily obtain inequality (13.21).
(⇐=) Since the matrix [I
S] is of full rank, we obtain
 I
St
t  −Λ
SX
•
−X −X t + Z
  I
St

<
0 ⇐⇒
−Λ + S Z St <
0 ⇐⇒−Λ + S Ω−1 St <
0 , Z = Ω−1 (13.23)
which completes the proof.
Lemma 13.3.2 The matrix inequality
AP + PAt + Dt R−1 D + M <
0
(13.24)
holds for some 0 < P = Pt ∈ℜn×n, if and only if
⎡
⎣
AV + VtAt + M
P + AW −V
DtR
•
−W −Wt
0
•
•
−R
⎤
⎦<
0
(13.25)
holds for some V ∈ℜn×n and W ∈ℜn×n.
Proof: (=⇒) By Schur complements, inequality (13.24) is equivalent to
 AP + PAt + M
DtR
•
−R

<
0
(13.26)
Setting V = Vt = P, W = Wt = R,
it follows from Lemma (13.3.1)
with Schur complements that there exists P > 0, V, W such that inequality
(13.25) holds.
(⇐=) In a similar way, Schur complements to inequality (13.25) imply that:
⎡
⎣
AV + VtAt + M
P + AW −V
DtR
•
−W −Wt
0
•
•
−R
⎤
⎦<
0
⇐⇒
 I
A
  AV + VtAt + M + DtP−1D
P + AW −V
•
−W −Wt

 I
A
t
<
0 ⇐⇒AP + PAt + Dt P−1 D + M <
0 , V = Vt
(13.27)
which completes the proof.
The following lemmas are found in [294].

526
Chapter 13. Appendix
Lemma 13.3.3 Given any x ∈ℜn:
max {[xt RHΔG x]2 : Δ ∈ℜ} = xt RHHtR x xt GtG x
Lemma 13.3.4 Given matrices
0 ≤X = Xt ∈ℜp×p, Y = Y t < 0 ∈
ℜp×p, 0 ≤Z = Zt ∈ℜp×p, such that
[ξt Y ξ]2 −4 [ξt X ξ ξt Z ξ]2
>
0
for all 0 ̸= ξ ∈ℜp is satisﬁed. Then there exists a constant α > 0 such that
α2 X + α Y + Z < 0
Lemma 13.3.5 For a given two vectors α ∈ℜn, β ∈ℜm and matrix N ∈
ℜn×m deﬁned over a prescribed interval Ω, it follows for any matrices X ∈
ℜn×n, Y ∈ℜn×m, and Z ∈ℜm×m the following inequality holds:
−2

Ω
αt(s) N β(s) ds ≤

Ω
 α(s)
β(s)
t 
X
Y −N
Y t −N t
Z

 α(s)
β(s)

ds
where
 X
Y
Y t
Z

≥0
An algebraic version of Lemma 13.3.5 is stated below.
Lemma 13.3.6 For a given two vectors α ∈ℜn, β ∈ℜm and matrix N ∈
ℜn×m deﬁned over a prescribed interval Ω, it follows for any matrices X ∈
ℜn×n, Y ∈ℜn×m, and Z ∈ℜm×m the following inequality holds:
−2 αt N β
≤
 α
β
t 
X
Y −N
Y t −N t
Z
  α
β

=
αtXα + βt(Y t −N t)α + αt(Y −N)β + βtZβ
subject to
 X
Y
Y t
Z

≥0

13.3. Lemmas
527
Lemma 13.3.7 Let 0 < Y = Y t and M, N be given matrices with appropri-
ate dimensions. Then it follows that
Y + M Δ N + N t Δt Mt
<
0,
∀Δt Δ ≤I
holds if and only if there exists a scalar ε > 0 such that
Y + ε M Mt + ε−1 N t N
<
0
In the following lemma, we let X(z) ∈ℜn×p
be a matrix function of the
variable z. A matrix X∗(z) is called the orthogonal complement of X(z) if
Xt(z) X∗(z) = 0 and X(z) X∗(z) is nonsingular (of maximum rank).
Lemma 13.3.8 Let 0 < L = Lt and X, Y be given matrices with appropriate
dimensions. Then it follows that the inequality
L(z) + X(z) P Y (z) + Y t(z) P t Xt(z)
>
0
(13.28)
holds for some P and z = zo if and only if the following inequalities
Xt
∗(z) L(z) X∗(z)
>
0,
Y t
∗(z) L(z) Y∗(z)
>
0
(13.29)
hold with z = zo.
It is signiﬁcant to observe that feasibility of matrix inequality (13.28) with
variables P and z is equivalent to the feasibility of (13.29) with variable z and
thus the matrix variable P has been eliminated from (13.28) to form (13.29).
Using Finsler’s lemma, we can express (13.29) in the form
L(z) −β X(z) Xt(z)
>
0,
L(z) −β Y (z) Y t(z)
>
0 (13.30)
for some β ∈ℜ.
The following is a statement of the reciprocal projection lemma.
Lemma 13.3.9 Let P > 0 be a given matrix. The following statements are
equivalent:
i) M + Z + Zt
<
0
ii) the LMI problem
 M + P −(V + V t)
V t + Zt
V + Z
−P

<
0
is feasible with respect to the general matrix V .

528
Chapter 13. Appendix
A useful lemma that is frequently used in overbounding given inequalities is
presented.
Lemma 13.3.10 For matrices X and Y and Kt = K ≥0 of appropriate
dimensions with K† being the Moore-Penrose generalized inverse of matrix K,
the following lemma is proved:
XtKK†Y + Y tKK†X ≤XtKX + Y tK†Y
In particular, if x and y are vectors and Kt = K > 0, then
xty ≤(1/2)xtKx + (1/2)ytK−1y
Proof: Let the real Schur decomposition of K be K = UtV U where U = U−t
is orthogonal and V = diag(λ1, ..., λn) is the diagonal matrix of eigenvalues.
The lemma then follows from
0
≤
[
√
V UX −
√
V †U−tY ]t[
√
V UX −
√
V †U−tY ]
≤
XtUtV UX + Y tU−1V †UY −Y tU−1√
V †√
V UX
−
XtUt√
V
√
V †U−tX
as U−1√
V †√
V U = Ut√
V
√
V †U−t = KK† and K† = U−1V †U.
13.4
Linear Matrix Inequalities
It has been shown that a wide variety of problems arising in system and control
theory can conveniently reduce to a few standard convex or quasi convex op-
timization problems involving linear matrix inequalities (LMIs). The resulting
optimization problems can then be solved numerically very efﬁciently using
commercially available interior-point methods.
13.4.1
Basics
One of the earliest LMIs arises in Lyapunov theory. It is well known that the
differential equation
˙x(t) = A x(t)
(13.31)
has all of its trajectories converge to zero (stable) if and only if there exists a
matrix P > 0 such that
At P + A P
<
0
(13.32)
This leads to the LMI formulation of stability, that is, a linear time-invariant
system is asymptotically stable if and only if there exists a matrix 0 < P = P t

13.4. Linear Matrix Inequalities
529
satisfying the LMIs
At P + A P
<
0,
P > 0
Given a vector variable x ∈ℜn
and a set of matrices 0 < Gj = Gt
j ∈
ℜn×n, j = 0, ..., p, then a basic compact formulation of a linear matrix in-
equality is
G(x) := G0 +
p

j=1
xj Gj
>
0
(13.33)
Notice that (13.33) implies that vtG(x)v > 0 ∀0 ̸= v ∈ℜn. More impor-
tantly, the set {x |G(x) > 0 is convex. Nonlinear (convex) inequalities are
converted to LMI form using Schur complements in the sense that
 Q(x)
S(x)
•
R(x)

> 0
(13.34)
where Q(x) = Qt(x), R(x) = Rt(x), S(x) depend afﬁnely on x, is equiva-
lent to
R(x) > 0,
Q(x) −S(x)R−1(x)St(x) > 0
(13.35)
More generally, the constraint
Tr[St(x) P −1(x) S(x)] < 1,
P(x) > 0
where P(x) = P t(x) ∈ℜn×n, S(x) ∈ℜn×p depend afﬁnely on x, is handled
by introducing a new (slack) matrix variable Y (x) = Y t(x) ∈∈ℜp×p and the
LMI (in x and Y ):
TrY < 1,
 Y
S(x)
•
P(x)

> 0
(13.36)
Most of the time, our LMI variables are matrices. It should be clear from the
foregoing discussions that a quadratic matrix inequality (QMI) in the variable
P can be readily expressed as a linear matrix inequality (LMI) in the same
variable.
13.4.2
Some standard problems
Here we provide some common convex problems that we encountered through-
out the monograph. Given an LMI G(x) > 0, the corresponding LMI prob-
lem (LMIP) is to

530
Chapter 13. Appendix
ﬁnd a feasible x ≡xf such that G(xf) > 0, or
determine that the LMI is infeasible.
It is obvious that this is a convex feasibility problem.
The generalized eigenvalue problem (GEVP) is to minimize the maximum
generalized eigenvalue of a pair of matrices that depend afﬁnely on a variable,
subject to an LMI constraint. GEVP has the general form
minimize λ
subject to
λB(x) −A(x) > 0
,
B(x) > 0,
C(x) > 0
(13.37)
where A, B, C are symmetric matrices that are afﬁne functions of x. Equiv-
alently stated,
minimize λM[A(x), B(x)]
subject to
B(x) > 0 , C(x) > 0
(13.38)
where λM[X, Y ] denotes the largest generalized eigenvalue of the pencil
λY
−X with Y > 0. This is a quasi-convex optimization problem since
the constraint is convex and the objective, λM[A(x), B(x)], is quasi-convex.
The eigenvalue problem (EVP) is to minimize the maximum eigenvalue of
a matrix that depends afﬁnely on a variable, subject to an LMI constraint. EVP
has the general form
minimize λ
subject to
λ I −A(x) > 0,
B(x) > 0
(13.39)
where A, B are symmetric matrices that are afﬁne functions of the optimiza-
tion variable x. This is a convex optimization problem.
EVPs can appear in the equivalent form of minimizing a linear function subject
to an LMI, that is,
minimize ctx
subject to
G(x) > 0
(13.40)
where G(x) is an afﬁne function of x. Examples of G(x) include
PA + AtP + CtC + γ−1PBBtP < 0,
P > 0
It should be stressed that the standard problems (LMIPs, GEVPs, EVPs) are
tractable, from both theoretical and practical viewpoints:
They can be solved in polynomial time.
They can be solved in practice very efﬁciently using commercial softwares.

13.4. Linear Matrix Inequalities
531
13.4.3
The S-procedure
In some design applications, we faced the constraint that some quadratic func-
tion be negative whenever some other quadratic function is negative. In such
cases, this constraint can be expressed as an LMI in the data variables deﬁning
the quadratic functions.
Let Go, ..., Gp be quadratic functions of the variable ξ ∈ℜn:
Gj(ξ) := ξtRjξ + 2ut
jξ + vj ,
j = 0, ..., p,
Rj = Rt
j
We consider the following condition on Go, ..., Gp:
Go(ξ) ≤0 ∀ξ
such that
Gj(ξ) ≥0,
j = 0, ..., p
(13.41)
It is readily evident that if there exist scalars ω1 ≥0, ...., ωp ≥0 such that
∀ξ,
Go(ξ) −
p

j=1
ωj Gj(ξ) ≥0
(13.42)
then inequality (13.41) holds. Observe that if the functions Go, ..., Gp are
afﬁne, then Farkas lemma states that (13.41) and (13.42) are equivalent. In-
terestingly enough, inequality (13.42) can be written as
 Ro
uo
•
vo

−
p

j=1
ωj
 Rj
uj
•
vj

≥0
(13.43)
The foregoing discussions were stated for nonstrict inequalities. In the case of
strict inequality, we let Ro, ..., Rp ∈ℜn×n be symmetric matrices with the
following qualiﬁcations:
ξtRoξ > 0 ∀ξ
such that
ξtGjξ ≥0,
j = 0, ..., p
(13.44)
Once again, it is obvious that if there exist scalars ω1 ≥0, ...., ωp ≥0 such that
∀ξ,
Go(ξ) −
p

j=1
ωj Gj(ξ) > 0
(13.45)
then inequality (13.44) holds. Observe that (13.45) is an LMI in the variables
Ro, ω1, ..., ωp.
It should be remarked that the S-procedure dealing with nonstrict inequali-
ties allows the inclusion of constant and linear terms. In the strict version, only
quadratic functions can be used.

532
Chapter 13. Appendix
13.5
Some Continuous Lyapunov-Krasovskii Func-
tionals
In this section, we provide some Lyapunov-Krasovskii functionals and their
time-derivatives which are of common use in stability studies throughout the
text.
V1(x)
=
xtPx +
 0
−τ
xt(t + θ)Qx(t + θ) dθ
(13.46)
V2(x)
=
 0
−τ
  t
t+θ
xt(α)Rx(α) dα

dθ
(13.47)
V3(x)
=
 0
−τ
  t
t+θ
˙xt(α)W ˙x(α) dα

dθ
(13.48)
where x is the state vector, τ is a constant delay factor, and the matrices 0 <
P t = P, 0 < Qt = Q, 0 < Rt = R, 0 < W t = W
are appropriate
weighting factors.
Standard matrix manipulations lead to
˙V1(x)
=
˙xtPx + xtP ˙x + xt(t)Qx(t) −xt(t −τ)Qx(t −τ)
(13.49)
˙V2(x)
=
 0
−τ

xt(t)Rx(t) −xt(t + α)Rx(t + α)

d θ
=
τ xt(t)Rx(t) −
 0
−τ
xt(t + θ)Rx(t + θ)

d θ
(13.50)
˙V3(x)
=
τ ˙xt(t)Wx(t) −
 t
t−τ
˙xt(α)W ˙x(α) dα
(13.51)
13.6
Some Formulas on Matrix Inverses
This section presents some useful formulas for inverting matrix expressions in
terms of the inverses of their constituents.
13.6.1
Inverse of block matrices
Let A be a square matrix of appropriate dimension and partitioned in the form
A =
 A1
A2
A3
A4

(13.52)

13.6. Some Formulas on Matrix Inverses
533
where both A1 and A4 are square matrices. If A1 is invertible, then
Δ1 = A4 −A3 A−1
1
A2
is called the Schur complement of A1. Alternatively, if A4 is invertible, then
Δ4 = A1 −A2 A−1
4
A3
is called the Schur complement of A4.
It is well known that matrix A is invertible if and only if either
A1
and
Δ1
are invertible
or
A4
and
Δ4
are invertible
Speciﬁcally, we have the following equivalent expressions:
 A1
A2
A3
A4
−1
=

Υ1
−A−1
1 A2Δ−1
1
−Δ−1
1 A3A−1
1
Δ−1
1

(13.53)
or
 A1
A2
A3
A4
−1
=

Δ−1
4
−Δ−1
4 A2A−1
4
−A−1
4 A3Δ−1
4
Υ4

(13.54)
where
Υ1
=
A−1
1
+ A−1
1 A2Δ−1
1 A3A−1
1
Υ4
=
A−1
4
+ A−1
4 A3Δ−1
4 A2A−1
4
(13.55)
Important special cases are
 A1
0
A3
A4
−1
=

A−1
1
0
−A−1
4 A3A−1
1
A−1
4

(13.56)
and
 A1
A2
0
A4
−1
=
 A−1
1
−A−1
1 A2A−1
4
0
A−1
4

(13.57)
13.6.2
Matrix inversion lemma
Let A ∈ℜn×n and C ∈ℜm×m be nonsingular matrices. By using the deﬁni-
tion of matrix inverse, it can be easily veriﬁed that
[A + B C D]−1 = A−1 −A−1 B [D A−1B + C−1]−1 DA−1 (13.58)

534
Chapter 13. Appendix
13.7
Some Discrete Lyapunov-Krasovskii Functionals
In this section, we provide a general form of discrete Lyapunov-Krasovskii
functionals and their ﬁrst-difference which can be used in stability studies of
discrete-time throughout the text.
V (k)
=
Vo(k) + Va(k) + Vc(k) + Vm(k) + Vn(k)
Vo(k)
=
xt(k)Pσx(k), Va(k) =
k−1

j=k−d(k)
xt(j)Qσx(j)
Vc(k)
=
k−1

j=k−dm
xt(j)Zσx(j) +
k−1

j=k−dM
xt(j)Sσx(j)
Vm(k)
=
−dm

j=−dM+1
k−1

m=k+j
xt(m)Qσx(m)
Vn(k)
=
−dm−1

j=−dM
k−1

m=k+j
δxt(m)Raσδx(m)
+
−1

j=−dM
k−1

m=k+j
δxt(m)Rcσδx(m)
(13.59)
where
0 < Pσ
=
N

j=1
λjPj, 0 < Qσ =
N

j=1
λjQj, 0 < Sσ =
N

j=1
λjSj,
0 < Zσ
=
N

j=1
λjZj, 0 < Raσ =
N

j=1
λjRaj, 0 < Rcσ =
N

j=1
λjRcj
(13.60)
are weighting matrices of appropriate dimensions. Consider now a class of
discrete-time systems with interval-like time-delays that can be described by
x(k + 1)
=
Aσx(k) + Dσx(k −dk) + Γσω(k)
z(k)
=
Cσx(k) + Gσx(k −dk) + Σσω(k)
(13.61)
where x(k) ∈ℜn is the state, z(k) ∈ℜq is the controlled output, and ω(k) ∈
ℜp is the external disturbance that is assumed to belong to ℓ2[0, ∞). In the
sequel, it is assumed that dk is time-varying and satisfying
dm ≤dk ≤dM
(13.62)

13.7. Some Discrete Lyapunov-Krasovskii Functionals
535
where the bounds dm > 0 and dM > 0 are constant scalars. The system matri-
ces contain uncertainties that belong to a real convex bounded polytopic model
of the type
[Aσ, Dσ, ..., Σσ] ∈&Ξλ :=
5
[Aλ,
Dλ, ..., Σλ]
=
N

j=1
λj[Aj, Dj, ..., Σj], λ ∈Λ
6
(13.63)
where Λ is the unit simplex
Λ :=

(λ1, · · · , λN) :
N

j=1
λj = 1 , λj ≥0

(13.64)
Deﬁne the vertex set N = {1, ..., N}. We use {A, ..., Σ} to imply generic
system matrices and {Aj, ..., Σj, j ∈N} to represent the respective values at
the vertices. In what follows, we provide a deﬁnition of exponential stability of
system (13.61):
A straightforward computation gives the ﬁrst-difference of ΔV (k) =
V (k + 1) −V (k) along the solutions of (13.61) with ω(k) ≡0 as:
ΔVo(k)
=
xt(k + 1)Pσx(k + 1) −xt(k)Pσx(k)
=
[Aσx(k) + Dσx(k −dk)]tPσ[Aσx(k) + Dσx(k −dk)]
−
xt(k)Pσx(k)
ΔVa(k)
≤
xt(k)Qx(k) −xt(k −d(k))Qx(k −d(k))
+
k−dm

j=k−dM+1
xt(j)Qx(j)
ΔVc(k)
=
xt(k)Zx(k) −xt(k −dm)Zx(k −dm) + xt(k)Sx(k)
−
xt(k −dM)Sx(k −dM)
ΔVm(k)
=
(dM −dm)xt(k)Qx(k) −
k−dm

j=k−dM+1
xt(k)Qx(k)
ΔVn(k)
=
(dM −dm)δxt(k)Raδx(k) + dMδxt(k)Rcδx(k)
−
k−dm−1

j=k−dM
δxt(j)Raδx(j) −
k−1

j=k−dM
δxt(j)Rcδx(j) (13.65)

536
Chapter 13. Appendix
13.8
Additional Inequalities
A basic inequality that has been frequently used in the stability analysis of
time-delay systems is called Jensen’s Inequality or the Integral Inequality, a
detailed account of which is available in [93].
Lemma 13.8.1 For any constant matrix 0 < Σ ∈ℜn×n, scalar τ∗< τ(t) <
τ +, and vector function ˙x : [−τ +, −τ∗] →ℜn such that the following integra-
tion is well deﬁned, then it holds that
−(τ + −τ∗)
 t−τ∗
t−τ + ˙xt(s)Σ ˙x(s)ds ≤
 x(t −τ∗)
x(t −τ +)
t  −Σ
Σ
•
−Σ

 x(t −τ∗)
x(t −τ +)

Building on Lemma 13.8.1, the following lemma speciﬁes a particular in-
equality for quadratic terms.
Lemma 13.8.2 For any constant matrix 0 < Σ ∈ℜn×n, scalar τ∗< τ(t) <
τ +, and vector function ˙x : [−τ +, −τ∗] →ℜn such that the following integra-
tion is well deﬁned, then it holds that
−
(τ + −τ∗)
 t−τ∗
t−τ +
˙xt(s) Σ ˙x(s) ds ≤ξt(t) Υ ξ(t)
ξ(t)
=
⎡
⎣
x(t −τ∗)
x(t −τ(t))
x(t −τ +)
⎤
⎦
t
,
Υ =
⎡
⎣
−Σ
Σ
0
•
−2Σ
Σ
•
•
−Σ
⎤
⎦
Proof: Considering the case τ∗< τ(t) < τ + and applying the Leibniz-Newton
formula, it follows that
−
(τ + −τ∗)
 t−τ∗
t−τ +
˙xt(s) Σ ˙x(s) ds −(τ + −τ∗)
 t−τ∗
t−τ(t)
×

˙xt(s) Σ ˙x(s) ds +
 t−τ(t)
t−τ +
˙xt(s) Σ ˙x(s) ds
	
≤
−(τ(t) −τ∗)
 t−τ∗
t−τ(t)

˙xt(s) Σ ˙x(s) ds
−
(τ + −τ(t))
 t−τ(t)
t−τ +
˙xt(s) Σ ˙x(s) ds
	
≤
−
 t−τ∗
t−τ(t)
˙xt(s) ds Σ
 t−τ∗
t−τ(t)
˙xt(s) ds

13.8. Additional Inequalities
537
−
 t−τ(t)
t−τ+
˙xt(s) ds Σ
 t−τ(t)
t−τ+
˙xt(s) ds
=
[x(t −τ∗) −x(t −τ(t))]t Σ [x(t −τ∗) −x(t −τ(t))]
−
[x(t −τ(t)) −x(t −τ +)]t Σ [x(t −τ(t)) −x(t −τ +)]
which completes the proof.
Lemma 13.8.3 For any constant matrix 0 < Σ ∈ℜn×n, scalar η,
any
t ∈[0, ∞),
and vector function g : [t −η, t] →ℜn such that the follow-
ing integration is well deﬁned, then it holds that
  t
t−η
g(s) ds
t
Σ
 t
t−η
g(s) ds ≤η
 t
t−η
gt(s) Σ g(s) ds
(13.66)
Proof: It is simple to show that for any s ∈[t −η, t], t ∈[0, ∞), and Schur
complements
 gt(s)Σg(s)
gt(s)
•
Σ−1

≥0
Upon integration, we have
)  t
t−η gt(s)Σg(s)ds
 t
t−η gt(s)ds
•
ηΣ
*
≥0
By Schur complements, we obtain inequality (13.66).
The following lemmas show how to produce equivalent LMIs by an elimi-
nation procedure.
Lemma 13.8.4 There exists X such that
⎡
⎣
P
Q
X
•
R
Z
•
•
S
⎤
⎦> 0
(13.67)
if and only if
 P
Q
•
R

> 0,
 R
Z
•
S

> 0
(13.68)

538
Chapter 13. Appendix
Proof: Since LMIs (13.68) form subblocks on the principal diagonal of LMI
(13.67), necessity is established. To show sufﬁciency, apply the congruence
transformation
⎡
⎣
I
0
0
•
I
0
0
−V tR−1
I
⎤
⎦
to LMI (13.67); it is evident that (13.67) is equivalent to
⎡
⎣
P
Q
X −QR−1Z
•
R
0
•
•
S −ZtR−1Z
⎤
⎦> 0
(13.69)
Clearly (13.68) is satisﬁed for X = QR−1Z if (13.68) is satisﬁed in view of
Schur complements.
Lemma 13.8.5 There exists X such that
⎡
⎣
P
Q + XG
X
•
R
Z
•
•
S
⎤
⎦> 0
(13.70)
if and only if
 P
Q
•
R −VG −GtVt + GtZG

> 0,
 R −VG −GtVt + GtZG
V −GtZ
•
Z

> 0
(13.71)
Proof: Applying the congruence transformation
⎡
⎣
I
0
0
0
I
0
0
−G
I
⎤
⎦
to LMI (13.70) and using Lemma 13.8.4, we readily obtain the results.
Lemma 13.8.6 There exists 0 < X t = X such that
 Pa + X
Qa
•
Ra

> 0,
 Pc −X
Qc
•
Rc

> 0
(13.72)

13.8. Additional Inequalities
539
if and only if
⎡
⎣
Pa + Pc
Qa
Qc
•
Ra
0
•
•
Rc
⎤
⎦> 0
(13.73)
Proof: It is obvious from Schur complements that LMI (13.73) is equivalent to
Ra > 0,
Rc > 0
Ξ = Pa + Pc −QaR−1
a Qt
a −QcR−1
c Qt
c > 0
(13.74)
On the other hand, LMI (13.72) is equivalent to
Ra > 0,
Rc > 0
Ξa = Pa + X −QaR−1
a Qt
a > 0,
Ξc = Pc −X −QcR−1
c Qt
c > 0
(13.75)
It is readily evident from (13.74) and (13.75) that Ξ = Ξa + Ξc and hence
the existence of X satisfying (13.75) implies (13.74). By the same token, if
(13.74) is satisﬁed, X = QaR−1
a Qt
a −Pa −1
2Ξ yields Ξa = Ξc = Ξa = 1
2Ξ
and (13.75) is satisﬁed.

Bibliography
[1] Al-Fuhaid, A. S., M. S. Mahmoud and F. A. Saleh, “Stabilization of
Power Systems by Decentralized Systems and Control Theory”, Electric
Machines and Power Systems, vol. 21, no. 3, 1993, pp. 293–318.
[2] Aly, G. S. and H. Ottertum, “Dynamic Benhaviour of Mixer-Settlers, Part
III: Testing Mathematical Models”, J. Appl. Chem. Biotechnol., vol. 23,
1973, pp. 643–651.
[3] Anderson, B. D. O. and J. B. Moore, Linear Optimal Control, Prentice-
Hall, Inc., Englewood Cliffs, NJ, 1971.
[4] Anderson, B. D. O. and J. B. Moore, “Time-Varying Feedback Laws for
Decentralized Control”, IEEE Trans. Automat. Control, vol. AC-26, 1981,
pp. 1133–1138.
[5] Anderson, B. D. O. and D. J. Clements, “Algebraic Characterization of
Fixed Modes in Decentralized Control”, Automatica, vol. 17, 1981, pp.
703–712.
[6] Anderson, B. D. O., “Transfer Function Matrix Description of Decentral-
ized Fixed Modes”, IEEE Trans. Automat. Control, vol. AC-27, 1982, pp.
1176–1182.
[7] Anderson, B. D. O. and A. Dehghani, “Challenges of Adaptive Control-
Past, Permanent and Future”, Annual Reviews in Control, vol. 32, 2008,
pp. 123–135.
[8] Arafeh, S. and K. P. Sage, “Multi-Level Discrete Time System Identiﬁ-
cation in Large Scale Systems,” Int. J. Syst. Sci, vol. 5, no. 8, 1974, pp.
753–791.
[9] Bahnasawi, A. A. and M. S. Mahmoud, Control of Partially-Known
Dynamical Systems, Springer-Verlag, Berlin, 1989.
541

542
Bibliography
[10] Bahnasawi, A. A., A. S. Al-Fuhaid and M. S. Mahmoud, “Decentralized
and Hierarchical Control of Interconnected Uncertain Systems”, Proc.
IEE Part D, vol. 137, 1990, pp. 311–321.
[11] Bahnasawi, A. A., A. S. Al-Fuhaid and M. S. Mahmoud, “A New Hi-
erarchical Control Structure for a Class of Uncertain Discrete Systems”,
Control Theory and Advanced Technology, vol. 6, 1990, pp. 1–21.
[12] Bakule, L. and J. Lunze, “Decentralized Design of Feedback Control for
Large Scale Systems”, Kybernetika, vol. 24, no. 3–6, 1988, pp. 1–100.
[13] Bakule, L. and J. Rodellar, “Decentralized Control and Overlapping De-
composition of Mechanical Systems. Part 1: System Decomposition. Part
2: Decentralized Stabilization”, Int. J. Control, vol. 61, 1995, pp. 559–
587.
[14] Bakule, L. and J. Rodellar, “Decentralized Control Design of Uncertain
Nominally Symmetric Composite Systems”, IEE Proc. Control Theory
and Applications, vol. 143, no. 6, 1996, pp. 530–535.
[15] Bakule, L., J. Rodellar and J. M. Rossell, “Structure of Expansion-
Contraction Matrices in the Inclusion Principle for Dynamic Systems,”
SIAM J. Matrix Anal. Appl., vol. 21, no. 4, 2000, pp. 1136–1155.
[16] Bakule, L., J. Rodellar and J. M. Rossell, “Generalized Selection of Com-
plementary Matrices in the Inclusion Principle,” IEEE Tran. Automat.
Contro., vol. AC-45, no. 6, 2000, pp. 1237–1243.
[17] Bakule, L., J. Rodellar and J. M. Rossell, “Overlapping Quadratic Op-
timal Control of Linear Time-Varying Commutative Systems,” SIAM J.
Control and Optimization, vol. 40, no. 5, 2002, pp. 1611–1627.
[18] Bakule, L., “Reduced-Order Control Design of Time-Delayed Uncertain
Symmetric Composite Systems”, Proc. 10th IFAC/IFORS/IMACS/IFIP
Symposium on Large Scale Systems: Theory and Applications, Osaka,
Japan, 2004, pp. 130–135.
[19] Bakule, L., F. P. Crainiceanu, J. Rodellar and J. M. Rossell, “Overlapping
Reliable Control for a Cable-Stayed Bridge Benchmark”, IEEE Trans.
Control Sys. Tech., vol. 13, no. 4, 2005, pp. 663–669.
[20] Bakule, L., “Complexity-Reduced Guaranteed Cost Control Design for
Delayed Uncertain Symmetrically Connected Systems”, Proc. American
Control Conference, 2005, pp. 2590–2595.

Bibliography
543
[21] Bakule, L., J. Rodellar and J. M. Rossell, “Robust Overlapping Guar-
anteed Cost Control of Uncertain State-Delay Discrete-Time Systems”,
IEEE Trans. Automat. Contro., vol. 51, no. 12, 2006, pp. 1943–1950.
[22] Bakule, L., “Decentralized Control: An Overview”, Annual Rev. Control,
vol. 32, 2008, pp. 87–98.
[23] Benitez-Read, J. S. and M. Jamshidi, “Adaptive Input-Output Linearizing
Control of Nuclear Reactor”, C-TAT Journal, vol. 8, no. 3, 1992, pp. 525–
545.
[24] Bernstein, D. S. and W. M. Haddad, “Steady-State Kalman Filtering with
an H∞Error Bound”, Systems and Control Letters, vol. 16, 1991, pp.
309–317.
[25] Bernstein, D., “Some Open Problems in Matrix Theory Arising in Linear
Systems and Control”, Linear Algebra Applicat., vol. 164, 1992, pp. 409–
432.
[26] Bertsekas, D. P. and J. N. Tsitsiklis, Parallel and Distributed Computa-
tion, Prentice-Hall, Upper Saddle River, NJ, 1989.
[27] Blondel, V., M. Gevers and A. Lindquist, “Survey on the State of Systems
and Control”, European J. Control, vol. 1, 1995, pp. 5–23.
[28] Boukas, E. K. and M. S. Mahmoud, “A Practical Approach to Control of
Nonlinear Discrete-Time State-Delay Systems”, Optimal Control Appl.
and Methods, vol. 28, no. 5, 2007, pp. 397–417.
[29] Boyd, S., L. El Ghaoui, E. Feron and V. Balakrishnan, Linear Matrix
Inequalities in Systems and Control Theory, SIAM Studies in Applied
Mathematics, Philadelphia, PA, 1994.
[30] Brasch, F. M. and J. B. Pearson, “Pole Placement Using Dynamic Com-
pensators”, IEEE Trans. Automatic Control, vol. 15, no. 1, 1970, pp. 34–
43.
[31] Cantoni, M., E. Weyer, Y. Li, S. K. Oai, I. Mareels and M. Ryan, “Control
of Large-Scale Irrigation Networks”, Proc. IEEE, vol. 59, no. 1, 2007, pp.
75–91.
[32] Chandra, R. S., C. Langbort and R. D’Andrea, “Distributed Control De-
sign with Robustness to Small Time Delays”, Systems & Control Letters,
vol. 58, no. 4, 2009, pp. 296–303.

544
Bibliography
[33] Chapman, J. W., M. D. Ilic, C. A. King, L. Eng and H. Kaufman, “Sta-
bilizing a Multimachine Power System via Decentralized Feedback Lin-
earizing Excitation Control”, IEEE Trans. Power Systems, vol. 8, no. 3,
1993, pp. 830–839.
[34] Chen, H. B., J. K. Shiau and J. H. Chow, “Simultaneous H∞-Suboptimal
Control Design”, Proc. American Control Conference, Seattle, WA, 1995,
pp. 1946–1950.
[35] Chen, C. T., Introduction to Linear System Theory, Prentice-Hall, New
York, 1996.
[36] Chen, X. B. and S. S. Stankovic, “Decomposition and Decentralized Con-
trol of Systems with Multi-Overlapping Structure”, Automatica, vol. 41,
2005, pp. 1765–1772.
[37] Chen, J. D., “Stability Criteria for Large-Scale Time-Delay Systems: The
LMI Approach and the Genetic Algorithms”, Control and Cybernetics,
vol. 35, no. 2, 2006, pp. 291–301.
[38] Chen, J. D., “LMI-Based Stability Criteria for Large-Scale Time-Delay
Systems”, JSME Int. Journal, series C, vol. 49, no. 1, 2006, pp. 225–229.
[39] Cheng, C. and Q. Zhao, “Reliable Control of Uncertain Delayed Systems
with Integral Quadratic Constraints”, IEE Proc. Control Theory Appl.,
vol. 151, no. 6, 2004, pp. 790–796.
[40] Chong, C. Y. and M. Athans, “On the periodic coordination of linear
stochastic systems”, Proc. 6th IFAC World Congress, Boston, 1975.
[41] Chu, D. and D. D. Siljak, “A Canonical Form for the Inclusion Principle
of Dynamic Systems”, SIAM Journal on Control and Optimization, vol.
44, no. 3, 2005, pp. 969–990.
[42] Cohen, G. and A. Benveniste, “Decentralization without Coordination,”
Ricarche Ricarche Di Automatica, vol. 5, no. 1, 1974, pp. 16–29.
[43] Corfmat, J. P. and A. S. Morse, “Decentralized Control of Linear Multi-
variable Systems”, Automatica, vol. 12, 1976, pp. 479–496.
[44] Davis, M., “Markov Models and Optimization”, Chapman & Hall, Lon-
don, 1992.

Bibliography
545
[45] Davison, E. J. and S. H. Wang, “Properties of Linear Time-Invariant Mul-
tivariable Systems Subject to Arbitrary Output and State Feedback”, IEEE
Trans. Automat. Contro., vol. AC-18, 1973, pp. 24–32.
[46] Davison, E. J., “A Generalization of the Output Control of Linear Mul-
tivariable Systems with Unmeasurable Arbitrary Disturbances”, IEEE
Trans. Automat. Contro., vol. AC-20, 1975, pp. 788–792.
[47] Davison, E. J. and A. Goldenberg, “The Robust Decentralized Control
of a General Servomechanism Problem: The Servo-Compensator”, Auto-
matica, vol. 11, 1975, pp. 461–471.
[48] Davison, E. J., “The Robust Decentralized Control of a General Ser-
vomechanism Problem”, IEEE Trans. Automat. Contro., vol. AC-21,
1976, pp. 114–124.
[49] Davison, E. J., “Decentralized Stabilization and Regulation in Large Mul-
tivariable Systems”, in Ho, Y. C. and S. K. Mitter (eds.) Directions in
Large Scale Systems, Plenum Press, New York, 1976, pp. 303–323.
[50] Davison, E. J., “The Robust Decentralized Servomechanism Problem
with Extra Stabilizing Control Agents”, IEEE Trans. Automat. Contro.,
vol. AC-22, 1977, pp. 256–259.
[51] Davison, E. J., “Recent Results on Decentralized Control of Large Scale
Multivariable Systems”, IFAC Symposium on Multivariable Technologi-
cal Systems, Fredericton, Canada, 1977, pp. 1–10.
[52] Davison, E. J., “The Robust Decentralized Control of a Servomechanism
Problem for Composite Systems with Input-Output Interconnections”,
EEE Trans. Automat. Contro., vol. AC-23, 1979, pp. 325–327.
[53] Davison, E. J. and W. Gesing, “Sequential Stability and Optimization of
Large Scale Decentralized Systems”, Automatica, vol. 15, 1979, pp. 307–
324.
[54] Davison, E. J. and U. Ozguner, “Synthesis of Decentralized Robust Ser-
vomechanism Problem Using Local Models Fixed Modes”, IEEE Trans.
Automat. Contro., vol. AC-27, 1982, pp. 583–600.
[55] Davison, E. J. and U. Ozguner, “Characterizations of Decentralized Fixed
Modes for Interconnected Systems”, Automatica, vol. 19, no. 2, 1982, pp.
169–182.

546
Bibliography
[56] Davison, E. J. and T. N. Chang, “Decentralized Stabilization and Pole
Assignment for General Proper Systems”, IEEE Trans. Automat. Contro.,
vol. AC-35, 1990, pp. 652–664.
[57] D’Andrea, R. and G. E. Dullerud, “Distributed Control Design for Spa-
tially Interconnected Systems”, IEEE Trans. Automat. Contro., vol. 48,
no. 9, 2003, pp. 1478–1495.
[58] de Souza, C. E. and M. D. Fragoso, “H∞Control for Linear Systems with
Markovian Jumping Parameters,” Control-Theory and Advanced Technol-
ogy, vol. 9, no. 2, 1993, pp. 457–466.
[59] Dorato, P. and R. K. Yedavalli, Recent Advances in Robust Control, IEEE
Press, New York, 1990.
[60] Dorato, P. “Non-Fragile Controllers Design: An Overview”, Proceedings
the American Control Conference, Philadelphia, PA, 1998, pp. 2829–
2831.
[61] Doyle, J. C. and G. Stein, “Robustness with Observers”, IEEE Trans. Au-
tomat. Contro., vol. 24, 1979, pp. 607–611.
[62] Doyle, J. C., K. Glover, P. P. Khargonekar and B. A. Francis, “State-Space
Solutions to Standard H2 and H∞Control Problems”, IEEE Trans. Au-
tomat. Contro., vol. 34, 1989, pp. 831–847.
[63] Elliott, R. J. and D. D. Sworder, “Control of a Hybrid Conditionally Lin-
ear Gaussian Processes”, J. Optimization Theory and Applications, vol.
74, 1992, pp. 75–85.
[64] El Ghaoui, L. and S. Niculescu, Eds., Advances in Linear Matrix Inequal-
ities Methods in Control. SIAM, Philadelphia, PA, 2000.
[65] Edwards, C. and Spurgeon, S. K., “Sliding Mode Stabilization of Uncer-
tain Systems Using Only Output Information”, Int. J. Control, vol. 62, no.
5, 1995, pp. 1129–1144.
[66] Edwards, C. and Spurgeon, S. K., “Sliding-Mode Output Feedback Con-
troller Design Using Linear Matrix Inequalities”, IEEE Trans. Auto. Con-
trol, vol. 46, no. 1, 2001, pp. 115–119.
[67] Edwards, C. and S. K. Spurgeon, Sliding Mode Control: Theory and Ap-
plications, Taylor & Francis, London, 1998.

Bibliography
547
[68] Edwards, C., X. G. Yan and S. K. Spurgeon, “On the Solvability of
the Constrained Lyapunov Problem”, IEEE Trans. on Automat. Control,
vol. 52, no. 10, 2007, pp.1982–1987.
[69] Even, S. Graph Algorithms, Computer Science Press, London, 1979.
[70] Famularo, D., P. Dorato, C. T. Abdallah, W. M. Haddad and A. Jadbabie,
“Robust Non-Fragile LQ Controllers: The Static State Feedback Case”,
Int. J. Control, vol. 73, no. 2, 2000, pp. 159–165.
[71] Fax, J. A. and R. M. Murray, “Information Flow and Cooperative Control
of Vehicle Formations”, IEEE Trans. Automat. Contro., vol. 49, no. 9,
2004, pp. 1465–1476.
[72] Fleming, W., S. Sethi and M. Soner, “An Optimal Stochastic Production
Planning Problem with Randomly Fluctuating Demand”, SIAM J. Con-
trol and Optimization, vol. 25, 1987, pp. 1494–1502.
[73] Feng, X., K. A. Loparo, Y. Ji and H. J. Chizeck, “Stochastic Stability
Properties of Jump Linear Systems”, IEEE Trans. Automatic Control, vol.
37, 1992, pp. 38–53.
[74] Fridman, E. and U. Shaked, “Delay-Dependent Stability and H∞Control:
Constant and Time-Varying Delays”, Int. J. Control, vol. 76, 2003, pp.
48–60.
[75] Fu, M., C. E. de Souza and L. Xie, “H∞-Estimation for Uncertain Sys-
tems”, Int. J. Robust and Nonlinear Control, vol. 2, 1992, pp. 87–105.
[76] Gahinet, P., A. Nemirovski, A. L. Laub and M. Chilali, LMI Control
Toolbox, The Math Works, Inc., Boston, MA, 1995.
[77] Gahinet, P. and P. Apkarian, “A Linear Matrix Inequality Approach to H∞
Control”, Int. J. Robust and Nonlinear Control, vol. 4, 1994, pp. 421–448.
[78] Gao, H., J. Lam, C. Wang and Y. Wang, “Delay-Dependent Output-
Feedback Stabilization of Discrete-Time Systems with Time-Varying
State Delay”, IEE Proc. Control Theory and Applic., vol. 151, no. 6, 2004,
pp. 691–698.
[79] Gao, H. and T. Chen, “New Results on Stability of Discrete-Time Systems
with Time-Varying State-Delay”, IEEE Trans. Automat. Contro., vol. 52,
no. 2, 2007, pp. 328–334.

548
Bibliography
[80] Gavel, D. T. and D. D. Siljak, “Decentralized Adaptive Control: Structural
Conditions for Stability”, IEEE Trans. Automatic Control, vol. 34, no. 4,
1989, pp. 413–426.
[81] Grateloup, G. and A. Titli, “Two-Level Dynamic Optimization Methods”,
J. Optimization Theory and Applications, vol. 15, no. 5, 1975, pp. 533–
547.
[82] Geromel, J. C., J. Bernussou and P. Peres, “Decentralized Control through
Parameter Space Optimization”, Automatica, vol. 30, 1994, pp. 1565–
1578.
[83] Geromel, J. C., J. Bernussou and M. C. de Oliveira, “H∞Norm Optimiza-
tion with Constrained Dynamic Output Feedback Controllers: Decentral-
ized and Reliable Control”, IEEE Trans. Automat. Contro., vol. 44, no. 5,
1999, pp. 1449–1454.
[84] Geromel, J. C., P. L. D. Peres and S. R. de Souza “A Convex Approach
to the Mixed H2/H∞Control Problem for Discrete-Time Uncertain Sys-
tems”, SIAM J. Control Optim., vol. 33, 1995, pp. 1816–1833.
[85] Ghosh, S., S. K. Das and G. Ray, “Decentralized Stabilization of Un-
certain Systems with Interconnection and Feedback Delay: An LMI Ap-
proach”, IEEE Trans. Automat. Contro., vol. 54, no. 4, 2009, pp. 905–912.
[86] Godbole, D. N. and J. Lygeros, “Longitudinal Control of the Lead Car of
a Platoon”, IEEE Trans. Vehicular Tech., vol. 43, no. 4, 1994, pp. 1125–
1135.
[87] Golub, G. H. and C. F. Van Loan, Matrix Computations, John Hopkins
Studies in the Math Sciences, Baltimore, 1996.
[88] Gong, Z., “Decentralized Robust Control of Uncertain Interconnected
Systems with Prescribed Degree of Exponential Convergence”, IEEE
Trans. Automat. Contro., vol. 40, no. 4, 1995, pp. 704–707.
[89] Gong, Z. and M. Aldeen, “Stabilization of Decentralized Control Sys-
tems”, J. Math Systems, Estimation and Control, vol. 7, 1997, pp. 1–16.
[90] Gouaisbaut, F., Y. Blanco and J. P. Richard, “Robust Sliding Mode Con-
trol of Non-Linear Systems with Delay: A Design via Polytopic Formu-
lation”, Int. J. Control, vol. 77, no. 2, 2004, pp. 206–215.

Bibliography
549
[91] Grigoriadis, K. and R. Skelton, “Low-Order Design for LMI Problems
Using Alternating Projection Methods”, Automatica, vol. 32, 1997, pp.
837–852.
[92] Gu, G., “Stabilizability Conditions of Multivariable Uncertain Systems
via Output Feedback”, IEEE Trans. Automat. Contro., vol. 35, 1990, pp.
925–927.
[93] Gu, K., V. L. Kharitonov and J. Chen, Stability of Time-Delay Systems,
Birkhauser, Boston, 2003.
[94] Gu, K. Q., “Discretized Lyapunov Functional for Uncertain Systems with
Multiple Time-Delay”, Int. J. Control, vol. 72, no. 16, 1999, pp.1436–
1445.
[95] Guo, Y., D. J. Hill and Y. Wang, “Nonlinear Decentralized Control of
Large-Scale Power Systems”, Automatica, vol. 36, 2000, pp. 1275–1289.
[96] Haddad, W. M. and J. R. Corrado, “Robust Resilient Dynamic Controllers
for Systems with Parametric Uncertainty and Controller Gain Variations”,
Proceedings the American Control Conference, Philadelphia, PA, 1998,
pp. 2837–2841.
[97] Haimes, Y. Y., Hierarchical Analyses of Water Resources Systems,
McGraw-Hill, New York, 1977.
[98] Hassan, M. F. “Optimal Kalman Filter for Large Scale Systems Using
the Prediction Approach”, IEEE Trans. Syst. Man Cybern., vol. SMC-6,
1976, pp. .
[99] Hassan, M. F., G. Salut, M. G. Singh and A. Titli, “A Decentralized Com-
putational Algorithm for the Global Kalman Filter”, IEEE Trans. Au-
tomat. Contro., vol. AC-23, 1978, pp. 262–268.
[100] Hassan, M. F., M. S. Mahmoud and M. I. Younis, “A Dynamic Leontief
Modeling Approach to Management for Optimal Utilization in Water Re-
sources Systems”, IEEE Trans. Syst. Man Cybern., vol. SMC-11, 1981,
pp. 552–558.
[101] Hassan, M. F., M. S. Mahmoud, M. G. Singh and M. P. Spathopolous,
“A Two-Level Parameter Estimation Algorithm Using the Multiple Pro-
jection Approach”, Automatica, vol. 18, 1982, pp. 621–630.

550
Bibliography
[102] Hayakawa, T., H. Ishii and K. Tsumura, “Adaptive Quantized Control
for Linear Uncertain Discrete-Time Systems”, Automatica, vol. 45, 2009,
pp. 692–700.
[103] He, Y., Q. G. Wang, L. H. Xie and C. Lin, “Further Improvement of Free-
Weighting Matrices Technique for Systems with Time-Varying Delay”,
IEEE Trans. Automat. Contro., vol. 52, no. 2, 2007, pp. 293–299.
[104] Himmelblau, D. M., Ed., Decomposition of Large-Scale Problems, El-
sevier, New York, 1973.
[105] Ho, D. W. C. and G. Lu, “Robust Stabilization for a Class of Discrete-
Time Non-Linear Systems via Output Feedback: The Uniﬁed LMI Ap-
proach”, Int. J. Control, vol. 76, no. 1, 2003, pp. 105–115.
[106] Ho, Y. C. and S. K. Mitter, Eds., Directions in Large Scale Systems,
Plenum Press, New York, 1976.
[107] Hovd, M. and S. Skogestad, “Control of Symmetrically Interconnected
Plants”, Automatica, vol. 30, no. 6, 1994, pp. 957–973.
[108] Hsieh, C. S., “Reliable Control Design Using a Two-Stage Linear
Quadratic Reliable Control”, IEE Proc. Control Theory Appl., vol. 150,
no. 1, 2003, pp. 77–82.
[109] Hsu, K. C., “Decentralized Variable-Structure Control Design for Un-
certain Large-Scale Systems with Series Nonlinearities”, Int. J. Control,
vol. 68, no. 6, 1997, pp.1231–1240.
[110] Hu, Z., “Decentralized Stabilization of Large-Scale Interconnected Sys-
tems with Delays”, IEEE Trans. Automat. Contro., vol. 39, no. 5, 1994,
pp. 180–182.
[111] Hua, C., X. Guan and P. Shi, “Robust Decentralized Adaptive Control
for Interconnected Systems with Time Delays”, J. Dyn. Systems, Mea-
surements and Control, vol. 127, 2005, pp. 656–662.
[112] Hua, C., X. Guan and P. Shi, “Decentralized Robust Model Reference
Adaptive Control for Interconnected Time-Delay Systems”, J. Computer
and Applied Math., vol. 193, 2006, pp. 383–396.
[113] Hua, C. and X. Guan, “Output Feedback Stabilization for Time-Delay
Non-Linear Interconnected Systems Using Neural Networks”, IEEE
Trans. Neural Networks, vol. 19, no. 4, 2008, pp. 673–688.

Bibliography
551
[114] Hua, C. C., Q. G. Wang and X. P. Guan, “Exponential Stabilization Con-
troller Design for Interconnected Time Delay Systems”, Automatica, vol.
44, 2008, pp. 2600–2606.
[115] Huang, P. and Sundareshan, M. K., “A New Approach to the Design of
Reliable Decentralized Control Schemes for Large-Scale Systems”, Proc.
IEEE Int. Conf. Circuits and Systems, Houston, TX, 1980, pp. 678–680.
[116] Huang, S., J. Lam and G. H. Yang, “Reliable Linear-Quadratic Control
for Symmetric Composite Systems”, Int. J. Systems Science, vol. 32, no.
1, 2001, pp. 73–82.
[117] Huang, S., J. Lam, G. H. Yang and S. Zhang, “Fault Tolerant Decen-
tralized H∞Control for Symmetric Composite Systems”, IEEE Trans.
Automat. Contro., vol. 44, no. 11, 1999, pp. 2108–2114.
[118] Ibrir, S., W. F. Xie and C. Y. Su, “Observer-Based Control of Discrete-
Time Lipschitzian Nonlinear Systems: Application to One-Link Joint
Robot”, Int. Journal of Control, vol. 78, no. 6, 2005, pp. 385–395.
[119] Iftar, A. and Ozguner, U, “An Optimal Control Approach to the Decen-
tralized Robust Servomechanism Problem”, IEEE Trans. Automat. Con-
tro., vol. 34, 1989, pp. 1268–1271.
[120] Iftar, A. and U. Ozguner, “Contractible Controller Design and Optimal
Control with State and Input Inclusion”, Automatica, vol. 26, 1990, pp.
593–597.
[121] Iftar, A., “Decentralized Estimation and Control with Overlapping Input,
State and Output Decomposition”, Automatica, vol. 29, 1993, pp. 511–
516.
[122] Iftar, A. and U. Ozguner, “Overlapping Decompositions, Expansions,
Contractions, and Stability of Hybrid Systems”, IEEE Trans. Automatic
Control, vol. 43, no. 8, 1998, pp. 1040–1055.
[123] Iftar, A. and E. J. Davison, “Decentralized Control Strategies for Dy-
namic Routing”, Optimal Control Applications and Methods, vol. 23,
2002, pp. 329–335.
[124] Ikeda, M. and D. D. ˇSiljak, “Overlapping Decompositions, Expansions
and Contractions of Dynamic Systems”, Large Scale Syst., vol. 1, 1980,
pp. 29–38.

552
Bibliography
[125] Ikeda, M. and D. D. ˇSiljak, “Decentralized Stabilization of Linear Time-
Varying Systems”, IEEE Trans. Automat. Contro., vol. AC-25, 1980, pp.
106–107.
[126] Ikeda, M. and D. D. ˇSiljak, “On Decentrally Stabilizable Large-Scale
Systems”, Automatica, vol. 16, 1980, pp. 331–334.
[127] Ikeda, M. and D. D. ˇSiljak, “Overlapping Decompositions, Expansions
and Contractions of Dynamic Systems”, Large Scale Systems, vol. 1,
1980, pp. 29–38.
[128] Ikeda, M. and D. D. ˇSiljak, “Generalized Decompositions of Dynamic
Systems and Vector Lyapunov Functions”, IEEE Trans. Automat. Contro.,
vol. 26, 1981, pp. 1118–1125.
[129] Ikeda, M., D. D. ˇSiljak and D. E. White, “Decentralized Control with
Overlapping Informations Sets”, J. Optimization Theory and Applic., vol.
34, no. 2, 1981, pp. 279–309.
[130] Ikeda, M., D. D. ˇSiljak and D. E. White, “An Inclusion Principle for Dy-
namic Systems”, IEEE Trans. Automat. Contro., vol. 29, 1984, pp. 244–
249.
[131] Ikeda, M. and D. D. ˇSiljak, “Overlapping Decentralized Control with
Input, State and Output Inclusion”, Control Theory Adv. Tech., vol. 2,
1986, pp. 155–172.
[132] Ioannou, P. A., “Decentralized Adaptive Control of Interconnected Sys-
tems”, IEEE Trans. Automat. Contro., vol. AC-31, no. 4, 1986, pp. 291–
298.
[133] Istepanian, R. and J. Whidborne, Eds., Digital Controller Implementa-
tion and Fragility, Springer-Verlag, New York, 2001.
[134] Iwasaki, T. and R. Skelton, “Parametrization of all Stabilizing Con-
trollers via Quadratic Lyapunov Functions”, J. Optim. Theory Applicat.,
vol. 77, 1995, pp. 291–307.
[135] Iwasaki, T., R. Skelton and J. Geromel, “Linear Quadratic Suboptimal
Control with Static Output Feedback”, Syst. Control Lett., vol. 23, 1994,
pp. 421–430.
[136] Jamshidi, M., Large-Scale Systems: Modeling, Control and Fuzzy Logic,
Prentice-Hall, New York, 1997.

Bibliography
553
[137] Javdan, M. R., “A Uniﬁed Theory of Optimal Multilevel Control,” Int.
J. Control, vol. 22, no. 4, 1975, pp. 517–527.
[138] Javdan, M. R., “Extension of Dual Coordination to a Class of Nonlinear
Systems”, Int. J. Control, vol. 24, no. 4, 1976, pp. 551–571.
[139] Ji, Y. and H. J. Chizeck, “Controllability, Stabilizability and Continuous-
Time Markovian Jump Linear-Quadratic Control”, IEEE Trans. Auto-
matic Control, vol. 35, 1990, pp. 777–788.
[140] Jain, S. and F. Khorrami, “Decentralized Adaptive Output Feedback De-
sign for Large-Scale Nonlinear Systems”, IEEE Trans. Automat. Contro.,
vol. 42, no. 5, 1997, pp. 729–735.
[141] Jiang, Z. P., “Decentralized and Adaptive Nonlinear Tracking of Large-
Scale Systems via Output Feedback”, IEEE Trans. Automat. Contro., vol.
45, no. ll, 2000, pp. 2122–2128.
[142] Jiang, Z. P., D. W. Repperger and D. J. Hill, “Decentralized Nonlin-
ear Output-Feedback Stabilization with Disturbance Attenuation”, IEEE
Trans. Automatic Control, vol. 46, no. 10, 2001, pp. 1623–1629.
[143] Jiang, Z. P., “Decentralized Disturbance Attenuating Output-Feedback
Trackers for Large-Scale Nonlinear Systems”, Automatica, vol. 38, 2002,
pp. 1407–1415.
[144] Jiang, X. and Q. L. Han, “H∞Control for Linear Systems with Interval
Time-Varying Delay”, Automatica, vol. 41, no. 12, 2005, pp. 2099–2106.
[145] Jiao, X. and T. Shen, “Adaptive Feedback Control of Nonlinear Time-
Delay Systems: The LaSalle-Razumikhin-Based Approach”, IEEE Trans.
Automat. Contro., vol. 50, no. 11, 2005, pp. 1909–1913.
[146] Jing, X. J., D. L. Tan and Y. C. Wang, “An LMI Approach to Stability
of Systems with Severe Time-Delay”, IEEE Trans. Automat. Contro., vol.
49, no. 7, 2004, pp. 1192–1195.
[147] Kailath, T., Linear Systems, Prentice-Hall, Englewood Cliffs, NJ, 1980.
[148] Kalsi, K., J. Lian and S. H. Zak, “On Decentralized Control of Nonlinear
Interconnected Systems”, Int. J. Control, vol. 82, no. 3, 2009, pp. 541–
554.

554
Bibliography
[149] Karafyllis, I., “Robust Global Stabilization by Means of Discrete-Delay
Output Feedback”, Systems & Control Letters, vol. 57, 2008, pp. 987–
995.
[150] Kawka, P. A. and A. G. Alleyne, “Stability and Feedback Control of
Wireless Networked Systems”, Proc. American Contr. Conf., Portland,
OR, 2005, pp. 2953–2959.
[151] Keel, L. H. and S. P. Bhattacharyya, “Robust, Fragile, or Optimal ?”,
IEEE Trans. Automat. Control, vol. 42, 1997, pp. 1098–1105.
[152] Khalil, H. K., Nonlinear Systems, Second Edition, Prentice-Hall, Engle-
wood Cliffs, NJ, 2002.
[153] Khargonekar, P. P., M. A. Rotea and E. Baynes, “Mixed H2/H∞Filter-
ing”, Int. J. Robust and Nonlinear Control, vol. 6, 1996, pp. 313–330.
[154] Kobayashi, Y., M. Ikeda and Y. Fujisaki, “Stability of Large Space Struc-
tures Preserved under Failures and Local Controllers”, IEEE Trans. Au-
tomat. Contro1, vol. 52, no. 2, 2007, pp. 318–322.
[155] Kokotovic, P. A., “Applications of Singular Perturbation Techniques to
Control Problems”, SIAM Review, vol. 26, no. 4, 1984, pp. 501–550.
[156] Krishnamurthy, P. and F. Khorrami, “Decentralized Control and Dis-
turbance Attenuation for Large-Scale Nonlinear Systems in Generalized
Output-Feedback Canonical Form”, Automatica, vol. 9, 2003, pp. 1923–
1933.
[157] Kushner, H., Stochastic Stability and Control, Academic Press, New
York, 1967.
[158] Kwakernaak, H. W. and R. Sivan, Linear Optimal Control Systems, Wi-
ley, New York, 1972.
[159] Kwan, C. M. “Further Results on Variable Output Feedback Con-
trollers”, IEEE Trans. Auto. Control, vol. 46, no. 9, 2001, pp. 1505–1508.
[160] Lam, J. and G. H. Yang, “Balanced Model Reduction of Symmetric
Composite Systems”, Int. J. Control, vol. 65, no. 6, 1996, pp. 1031–1043.
[161] Lam, J., G.-H. Yang, S.-Y. Zhang and J. Wang, “Reliable Control Using
Redundant Controllers”, IEEE Trans. Automat. Contro., vol. 43, 1998, pp.
1588–1593.

Bibliography
555
[162] Langenhop, C. E., “On Generalized Inverses of Matrices”, SIAM L Appl.
Math, vol. 15, 1967, pp. 1239–1246.
[163] Langbort, C. L., R. S. Chandra and R. D’Andrea, “Decentralized Stabi-
lization of Linear Continuous or Discrete-Time Systems with Delays in
the Interconnection”, IEEE Trans. Automat. Contro., vol. 49, no. 9, 2004,
pp. 1502–1519.
[164] Lasdon, L. S., Optimization Theory for Large Systems, Macmillan, New
York, 1970.
[165] Lavaei, J. and A. G. Aghdam, “A Necessary and Sufﬁcient Condition
for the Existence of a LTI Stabilizing Decentralized Overlapping Con-
troller”, Proc. the 45th IEEE Conf. on Decision and Control, San Diego,
CA, 2006, pp. 6179–6186.
[166] Lavaei, J. and A. G. Aghdam, “Elimination of Fixed Modes by Means
of High-Performance Constrained Periodic Control”, Proc. the 45th IEEE
Conf. on Decision and Control, San Diego, CA, 2006, pp. 4441–4447.
[167] Lavaei, J. and A. G. Aghdam, “Characterization of Decentralized and
Quotient Fixed Modes via Graph Theory”, Proc. American Control Con-
ference, New York, 2007, pp. 790–795.
[168] Lavaei, J. and A. G. Aghdam, “Simultaneous LQ Control of a Set of LTI
Systems Using Constrained Generalized Sampled-Data Hold Functions”,
Automatica, vol. 43, 2007, pp. 274–280.
[169] Lavaei, J. and A. G. Aghdam, “High-performance Decentralized Control
Design for General Interconnected Systems with Applications in Cooper-
ative Control”, Int. J. Control, vol. 80, 2007, pp. 935–951.
[170] Lavaei, J., A. Momeni and A. G. Aghdam, “A Model Predictive Decen-
tralized Control Scheme with Reduced Communication Requirement for
Spacecraft Formation”, IEEE Trans. Control Systems Technology, vol. 16,
3008, pp. 268–278.
[171] Lavaei, J., A. Momeni and A. G. Aghdam, “LQ Suboptimal Decen-
tralized Controllers with Disturbance Rejection Property for Hierarchical
Systems”, Int. J. Control, vol. 81, 2008, pp. 1720–1732.
[172] Lee, J. L., “On the Decentralized Stabilization of Interconnected Vari-
able Structure Systems Using Output Feedback”, J. Franklin Institute,
vol. 332, no. 5, 1995, pp. 595–605.

556
Bibliography
[173] Lee, K. H., “Robust Decentralized Stabilization of a Class of Linear
Discrete-Time Systems with Nonlinear Interactions”, Int. J. Control, vol.
80, 2007, pp. 1544–1551.
[174] Lee, T. N. and U. L. Radovic, “Decentralized Stabilization of Linear
Continuous or Discrete-Time Systems with Delays in the Interconnec-
tion”, IEEE Trans. Automat. Contro., vol. 33, no. 5, 1989, pp. 757–760.
[175] Lee, S. R. and M. Jamshidi, “Stability Analysis for Large-Scale Time
Delay Systems via the Matrix Lyapunov Function”, Kybernetika, vol. 28,
no. 4, 1992, pp. 271–283.
[176] Leitmann, G., “Guaranteed Ultimate Boundedness for a Class of Uncer-
tain Linear Dynamical Systems”, IEEE Trans. Automat. Contro., vol. 23,
no. 9, 1978, pp. 1109–1110.
[177] Leitmann, G., “Guaranteed Asymptotic Stability for Some Linear Sys-
tems with Bounded Uncertainties”, ASME J. Dyn. Syst. Meas. & Control,
vol. 101, no. 3, 1979, pp. 212–219.
[178] Leibfritz, F. and E. M. Mostafa, “Trust Region Methods for Solving the
Optimal Output Feedback Design Problem”, Int. J. Control, vol. 76, 2003,
pp. 501–519.
[179] Leros, A. P. and P. P. Groumpos, “Time-Invariant BAS-Decentralized
Large-Scale Linear Regulator Problem”, Int. J. Control, vol. 46, no. 1,
1987, pp. 129–152.
[180] Liu, X., “Output Regulation of Strongly Coupled Symmetric Composite
Systems”, Automatica, vol. 28, no. 5, 1992, pp. 1037–1041.
[181] Luenberger, D. G., Optimization by Vector Space Method, New York,
Wiley, 1969.
[182] Luenberger, D. G., “An Introduction to Observers”, IEEE Trans. Au-
tomat. Control., vol. AC-16, no. 3, 1971, pp. 596–602.
[183] Levine, W. S. and M. Athans, “On the Optimal Error Regulation of a
String of Moving Vehicles,” IEEE Trans. Automat. Contro., vol. AC-11,
1966, pp. 355–361.
[184] Levine, W. S. and M. Athans, “On the Determination of the Opti-
mal Constant Output Feedback Gains for Linear Multivariable Systems,”
IEEE Trans. Automat. Contr., vol. AC-15, 1970, pp. 44–48.

Bibliography
557
[185] Li, R. H. and M. G. Singh, “Information Structures in Deterministic De-
centralized Control Problems”, IEEE Trans. Syst., Man and Cybern., vol.
SMC-13, 1983, pp. 162–166.
[186] Lin, Q., G. Wang and T. H. Lee, “A Less Conservative Robust Stability
Test for Linear Uncertain Time-Delay Systems”, IEEE Trans. Automat.
Contr., vol. 51, 2006, pp. 87–91.
[187] Litkouhi, B. and H. K. Khalil, “Inﬁnite-Time Regulators for Singularly
Perturbed Difference Equations”, Int. J. Control, vol. 39, 1984, pp. 567–
598.
[188] Litkouhi, B. and H. K. Khalil, “Multirate and Composite Control of
Two-Time-Scale Discrete-Time Systems”, IEEE Trans. Automat. Control,
vol. AC-30, 1985, pp. 645–651.
[189] Liu, F., P. Jiang, H. Su and J. Chu, “Robust H∞Control for Time-Delay
Systems with Additive Controller Uncertainty”, Proc. the 4th World
Congress on Intelligent Control and Automation, Shanghai, P. R. China,
2002, pp. 1718–1722.
[190] Lu, Q., Y. Sun, Z. Xu and T. Mochizuki, “Decentralized Nonlinear Opti-
mal Excitation Control”, IEEE Trans. Power Systems, vol. 11, no. 4, 1996,
pp. 1957–1962.
[191] Lunze, J., “Dynamics of Strongly Coupled Symmetric Composite Sys-
tems”, Int. J. Control, vol. 44, no. 6, 1986, pp. 1617–1640.
[192] Lunze, J., Feedback Control of Large-Scale Systems, Prentice-Hall, Lon-
don, 1992.
[193] Luyben, W. L., Chemical Reactor Design and Control, John Wiley &
Sons, New Jersey, 2007.
[194] Mahmoud, M. S., “Multilevel Systems Control and Applications: A Sur-
vey”, IEEE Trans. Systems, Man and Cybernetics, vol. SMC-7, no. 3,
1977, pp. 125–143.
[195] Mahmoud, M. S., “Closed-Loop Multilevel Control for Large Nonlinear
Systems via Invariant Embedding Techniques”, J. Computers and Elec-
trical Eng., vol. 4, 1977, pp. 525–543.
[196] Mahmoud, M. S., W. G. Vogt and M. H. Mickle, “Multilevel Control and
Optimization Using Generalized Gradients Techniques”, Int. J. Control,
vol. 25, 1977, pp. 525–543.

558
Bibliography
[197] Mahmoud, M. S., W. G. Vogt and M. H. Mickle, “Feedback Multilevel
Control for Continuous Dynamic Systems”, J. Franklin Institute, vol. 303,
no. 5, 1977, pp. 453–471.
[198] Mahmoud, M. S., “A Class of Optimization Techniques for Linear State
Regulators”, Int. J. Systems Science, vol. 8, no. 5, 1977, pp. 513–537.
[199] Mahmoud, M. S., “Dynamic Feedback Methodology for Interconnected
Control Systems”, Int. J. Control, vol. 29, no. 5, May 1979, pp. 881–898.
[200] Mahmoud, M. S., “A Quantitative Comparison between Two Decentral-
ized Control Approaches”, Int. J. Control, vol. 28, no. 2, 1978, pp. 261–
275.
[201] Mahmoud, M. S., W. G. Vogt and M. H. Mickle, “Decomposition and
Coordination Methods for Constrained Optimization”, J. Optimization
Theory and Applications, vol. 28, 1979, pp. 549–594.
[202] Mahmoud, M. S., “Dynamic Multilevel Methodology for Interconnected
Control Systems”, Int. J. Control, vol. 29, no. 5, 1979, pp. 881–898.
[203] Mahmoud, M. S., “Dynamic Multilevel Optimization for a Class of Non-
linear Systems”, Int. J. Control, vol. 30, no. 6, 1979, pp. 927–948.
[204] Mahmoud, M. S., M. F. Hassan and M. G. Singh, “A New Hierarchical
Approach to the Joint Problem of Systems Identiﬁcation and Optimiza-
tion”, Large Scale Systems Theory and Applications, vol. 1, 1980, pp.
159–166.
[205] Mahmoud, M. S., “Multilevel Systems: Information Flow in Large Lin-
ear Problems”, in Handbook of Large Scale Systems Engineering Appli-
cations, Madan G. Singh and Andre Title (eds.), North Holland, Amster-
dam, 1979, pp. 96–109.
[206] Mahmoud, M. S. and M. G. Singh, Large-Scale Systems Modelling,
Pergamon Press, London, 1981.
[207] Mahmoud, M. S. and M. G. Singh, “Decentralized State Reconstruction
of Interconnected Discrete Systems”, Large Scale Systems, vol. 2, 1981,
pp. 151–158.
[208] Mahmoud, M. S., “Design of Observer-Based Controllers for a Class of
Discrete Systems”, Automatica, vol. 18, no. 3, 1982, pp. 323–329.

Bibliography
559
[209] Mahmoud, M. S., “Order Reduction and Control of Discrete Systems”,
Proc. IEE Part D, vol. 129, no. 4, 1982, pp. 129–135.
[210] Mahmoud, M. S., “Structural Properties of Discrete Systems with Slow
and Fast Modes”, Large Scale Systems Theory and Applications, vol. 3,
no. 4, 1982, pp. 227–236.
[211] Xinogalas, T. C., M. S. Mahmoud and M. G. Singh, “Hierarchical Com-
putation of Decentralized Gains for Interconnected Systems”, Automat-
ica, vol. 18, 1982, pp. 474–478.
[212] Mahmoud, M. S., “Multi-Time Scale Analysis in Discrete Systems”, J.
Engineering and Applied Sciences, vol. 2, no. 4, 1983, pp. 301–315.
[213] Mahmoud, M. S., “Comments on Singular-Perturbation Method for Dis-
crete Models of Continuous Systems in Optimal Control”, Proc. IEE Part
D, vol. 130, no. 3, 1983, pp. 136.
[214] Mahmoud, M. S. and Y. Chen, “Design of Feedback Controllers by Two-
Stage Methods”, Applied Math Modeling, vol. 7, no. 3, 1983, pp. 163–
168.
[215] Hassan, M. F., M. S. Mahmoud and M. I. Younis, “Linear Multilevel
Estimators for Stabilization of Discrete Systems”, Int. J. Systems Science,
vol. 14, no. 7, 1983, pp. 731–743.
[216] Fawzy, A. S., M. S. Mahmoud and O. R. Hinton, “Hierarchical Tech-
niques for On Line Microprocessor Control of an Industrial Fermentation
Process”, Int. J. Systems Science, vol. 14, 1983, pp. 19–29.
[217] Mahmoud, M. S. and M. G. Singh, Discrete Systems: Analysis, Opti-
mization and Control, Springer-Verlag, Berlin, 1984.
[218] Mahmoud, M. S. and A. S. Fawzy, “On the Hierarchical Algorithms
for Nonlinear Systems with Bounded Control”, Optimal Control Appli-
cations and Methods, vol. 5, 1984, pp. 275–288.
[219] Mahmoud, M. S., N. M. Khraishi and H. A. Othman, “Bounds on Sub-
optimality in Discrete Aggregated Models”, Large Scale Systems Theory
and Applications, vol. 8, 1985, pp. 19–32.
[220] Mahmoud, M. S., Y. Chen and M.G. Singh, “On the Eigenvalue Assign-
ment in Discrete Systems with Slow and Fast Modes”, Int. J. Systems
Science, vol. 16, no. 1, 1985, pp. 168–187.

560
Bibliography
[221] Mahmoud, M. S., N. M. Khraishi and H. A. Othman, “Bounds on Sub-
optimality in Discrete Aggregated Models”, Large Scale Systems Theory
and Applications, vol. 8, no. 1, 1985, pp. 19–32.
[222] Mahmoud, M. S. and M. G. Singh, “On the Use of Reduced-Order Mod-
els in Output Feedback Design of Discrete Systems”, Automatica, vol. 21,
no. 4, 1985, pp. 485–489.
[223] Othman, H. A., N. M. Khraishi and M. S. Mahmoud, “Discrete Regu-
lators with Time-Scale Separation”, IEEE Trans. Automat. Control, vol.
AC-30, no. 6, 1985, pp. 293–297.
[224] Mahmoud, M. S., M. F. Hassan and M. G. Darwish, Large Scale Control
Systems: Theories and Techniques, Marcel Dekker Inc., New York, 1985.
[225] Mahmoud, M. S., M. F. Hassan and S. J. Saleh, “Decentralized Struc-
tures for Stream Water Quality Control Problems”, Optimal Control Ap-
plications and Methods, vol. 6, 1985, pp. 167–186.
[226] Mahmoud, M. S. and S. J. Saleh, “Regulation of Water Quality Stan-
dards in Streams by Decentralized Control”, Int. J. Control, vol. 41, 1985,
pp. 525–540.
[227] Mahmoud, M. S. and M. G. Singh, “On the Use of Reduced-Order Mod-
els in Output Feedback Design of Discrete Systems”, Automatica, vol. 21,
1985, pp. 485–489.
[228] Mahmoud, M. S., “Stabilization of Discrete Systems with Multiple Time
Scales”, IEEE Trans. Automat. Control, vol. AC-31, no. 2, 1986, pp. 159–
162.
[229] Mahmoud, M. S., Y. Chen and M. G. Singh, “Discrete Two-Time Scale
Systems”, Int. J. System Science, vol. 17, no. 8, 1986, pp. 1187–1207.
[230] Mahmoud, M. S., Y. Chen and M. G. Singh, “A Two-Stage Output Feed-
back Design”, Proc. IEE Part D, vol. 133, no. 6, 1986, pp. 279–284.
[231] Mahmoud, M. S. and M. F. Hassan, “A Decentralized Water Quality
Control Scheme”, IEEE Trans. Systems, Man and Cybernetics, vol. SMC-
16, 1986, pp. 694–702.
[232] Mahmoud, M. S. and J. A. Assiri, “Performance Analysis of Two-Level
Structures on Finite Precision Machines”, Automatica, vol. 22, 1986, pp.
371–375.

Bibliography
561
[233] Nassar, A. M. and M. S. Mahmoud, “Implementation of Two-Level Al-
gorithms Using Fixed-Point Arithmetic”, Int. J. Systems Science, vol. 17,
1986, pp. 1279–1292.
[234] Mahmoud, M. S. and M. F. Hassan, “A Decentralized Water Quality
Control Scheme”, IEEE Trans. Systems, Man and Cybernetics, vol. SMC-
16, 1986, pp. 694–702.
[235] Mahmoud, M. S., Y. Chen and M. G. Singh, “A Two-Stage Output Feed-
back Design”, Proc. IEE Part D, vol. 133, 1986, pp. 279–284.
[236] Mahmoud, M. S., M. F. Hassan and S. J. Saleh, “Decentralized Struc-
tures for Stream Water Quality Control Problems”, Optimal Control Ap-
plications and Methods, vol. 6, 1987, pp. 167–186.
[237] Mahmoud, M. S., “Costate Coordination Structure”, in Encyclopedia of
Systems and Control, vol. 2, Pergamon Press, Oxford, 1987, pp. 859–862.
[238] Mahmoud, M. S., “Singular Perturbations: Discrete Version”, in Ency-
clopedia of Systems and Control, vol. 7, Pergamon Press, Oxford, 1987,
pp. 4429–4434.
[239] Mahmoud, M. S. and S. Z. Eid, “Optimization of Freeway Trafﬁc Con-
trol Problems” Optimal Control Applications and Methods, vol. 9, 1988,
pp. 37–49.
[240] Mahmoud, M. S., “Discrete Systems with Multiple-Time Scales”, in
Control and Dynamic Systems Series, vol. 27, C. T. Leondes (ed.), Aca-
demic Press, New York, 1988, pp. 307–367.
[241] Mahmoud, M. S., “Algorithms for Decentralized Hierarchical Systems
with Application to Stream Water Quality”, in Control and Dynamic Sys-
tems Series, vol. 29, C. T. Leondes (ed.), Academic Press, New York,
1989, pp. 283–302.
[242] Mahmoud, M. S., “Algorithms for Decentralized Hierarchical Systems”,
in Control and Dynamic Systems Series, vol. 30, C. T. Leondes (ed.), Aca-
demic Press, New York, 1989, pp. 217–245.
[243] Mahmoud, M. S., “Singular Perturbations: Discrete Version”, in Con-
cise Encyclopedia of Modeling and Simulation, Pergamon Press, Oxford,
1989.

562
Bibliography
[244] Mahmoud, M. S., “Dynamic Decentralized Stabilization for a Class of
Multi-Stage Processes”, Automatica, vol. 24, no. 3, 1989, pp. 421–425.
[245] Mahmoud, M. S., Computer-Operated Systems Control, Marcel Dekker
Inc., New York, 1991.
[246] Mahmoud, M. S., “Stabilizing Control for a Class of Uncertain Intercon-
nected Systems”, IEEE Trans. Automat. Contro., vol. 39, no. 12, 1994, pp.
2484–2488.
[247] Mahmoud, M. S. and A. A. Bahnasawi, “Control Design of Uncertain
Systems with Slow and Fast Modes”, J. Systems Analysis and Modeling
Simulation, vol. 17, no. 1, 1994, pp. 67–83.
[248] Mahmoud, M. S., “Guaranteed Stabilization of Interconnected Discrete-
Time Systems”, Int. J. Systems Science, vol. 26, no. 1, 1995, pp. 337–358.
[249] Mahmoud, M. S., “Adaptive Stabilization of a Class of Interconnected
Systems”, Int. J. Computers and Electrical Engineering, vol. 23, 1997,
pp. 225–238.
[250] Mahmoud, M.
S. and S. Kotob, “Adaptive Decentralized Model-
Following Control”, Systems Analysis and Modelling Analysis, vol. 27,
1997, pp. 169–210.
[251] Mahmoud, M. S. and S. Bingulac, “Robust Design of Stabilizing Con-
trollers for Interconnected Time-Delay Systems”, Automatica, vol. 34,
1998, pp. 795–800.
[252] Mahmoud, M. S. and M. Zribi, “Robust and H∞Stabilization of Inter-
connected Systems with Delays”, IEE Proc. Control Theory Appl., vol.
145, 1998, pp. 558–567.
[253] Mahmoud, M. S., “Robust Stability and Stabilization of a Class of Non-
linear Systems with Delays”, J. Mathematical Problems in Engineering,
vol. 4, no. 2, 1998, pp. 165–185.
[254] Mahmoud, M. S. and M. Zribi, “H∞Controllers for Time-Delay Sys-
tems Using Linear Matrix Inequalities”, J. Optimization Theory and Ap-
plications, vol. 100, 1999, pp. 89–123.
[255] Mahmoud, M. S., Robust Control and Filtering for Time-Delay Systems,
Marcel-Dekker, New York, 2000.

Bibliography
563
[256] Mahmoud, M. S. and A. Ismail, “Control of Electric Power Systems”,
Int. J. Systems Analysis and Modeling Simulation, vol. 43. no. 12, 2003,
pp. 1639–1673.
[257] Mahmoud, M. S., “Robust Linear Filtering of Uncertain Systems”, Au-
tomatica, vol. 40, 2004, pp. 1797–1802.
[258] Mahmoud, M. S., Resilient Control of Uncertain Dynamical Systems,
Springer, Berlin, 2004.
[259] Mahmoud, M. S. and A. Ismail, “Robust Control Redesign of an Inverted
Wedge”, Proc. 2nd IEEE GCC Conf., Bahrain, December 2–5, 2004, pp.
37–46.
[260] Mahmoud, M. S. and A. Ismail, “Robust Control Redesign of an Inverted
Wedge”, Proc. 2nd IEEE GCC Conf., Bahrain, December 2–5, 2004, pp.
37–46.
[261] Mahmoud, M. S., “New Results on Robust Control Design of Discrete-
Time Uncertain Systems”, IEE Proc. Control Theory and Appli., vol. 152,
no. 4, 2005, pp. 453–459.
[262] Mahmoud, M. S., “Resilient Adaptive Control of Polytopic Delay Sys-
tems”, IMA J. Math Control and Info, vol. 22, no. 4, 2005, pp. 200–225.
[263] Mahmoud, M. S. and A. Ismail, “Passivity and Passivication of Intercon-
nected Time-Delay Models of Reheat Power Systems”, J. Math Problems
in Engineering, vol. 13, no. 4, 2006, pp. 1–21.
[264] Mahmoud, M. S., “Resilient L2/L∞Filtering of Polytopic Systems with
State-Delays”, IET Control Theory and Appli., vol. 1, no. 2007, pp. 141–
154.
[265] Mahmoud, M. S., “Improved Stability and Stabilization Approach to
Linear Interconnected Time-Delay Systems”, Optimal Control Applica-
tions and Methods, vol. 31, no. 3, 2010, pp. 81–92.
[266] Mahmoud, M. S. and N. B. Almutairi, “Decentralized Stabilization of
Interconnected Systems with Time-Varying Delays”, European J. Con-
trol, vol. 15, no. 6, 2009, pp. 624–633.
[267] Makila, P. M. and H. T. Toivonen, “Computational Methods for Para-
metric LQ Problems: A Survey”, IEEE Trans. Automat. Contro., vol. 32,
1987, pp. 658–671.

564
Bibliography
[268] Massioni, P. and M. Verhaegen, “Distributed Control for Identical Dy-
namically Coupled Systems: A Decomposition Approach”, IEEE Trans.
Automat. Contro., vol. 54, no. 1, 2009, pp. 124–135.
[269] Mao, C. and J. H. Yang, “Decentralized Output Tracking for Linear
Uncertain Interconnected Systems”, Automatica, vol. 31, 1995, pp. 151–
154.
[270] McFarlane, A. C. J., Complex Variable Methods for Linear Multivari-
able Feedback Systems, Taylor & Francis, London, 1980.
[271] Mesarovic, M. D., D. Macko and Y. Takahara, Theory of Hierarchical
Multilevel Systems, Academic Press, New York, 1970.
[272] Mesbahi, M., “A Semi-Deﬁnite Programming Solution of the Least Or-
der Dynamic Output Feedback Synthesis Problem”, Proc. 38th IEEE
Conf. Decision and Control, Phoenix, AZ, 1999, pp. 1851–1856.
[273] Michel, A. N. and R. K. Miller, Qualitative Analysis of Large-Scale Dy-
namical Systems, Academic Press, New York, 1977.
[274] Mirkin, B. M. and P. O. Gutman, “Adaptive Coordinated Decentralized
Control of State Delayed Systems with Actuator Failures”, Asian Journal
of Control, vol. 8, no. 4, 2006, pp. 441–448.
[275] Moheimani, O. and I. Petersen, “Optimal Quadratic Guaranteed Cost
Control of a Class of Uncertain Time-Delay Systems”, IEE Proc. Control
Theory Appl., vol. 144, no. 2, 1997, pp. 183–188.
[276] Monk, J. and J. Comfort, “Mathematical Model of an Internal Combus-
tion Engine and Dynamometer Test Rig”, Measurement Control, vol. 3,
1970, 3, pp. T93–Tl00.
[277] Munro, N. and S. N. Hirbod, “Multivariable Control of an Engine and
Dynamometer Test Rig”, Proc. Seventh IFAC Congress, Helsinki, 1978,
pp. 369–376.
[278] Nagpal, K. M. and P. P. Khargonekar, “Filtering and Smoothing in H∞
Setting”, IEEE Trans. Automat. Contro., vol. 36, 1991, pp. 152–166.
[279] Naidu, D. S. and A. K. Rao, Singular Perturbation Analysis of Discrete
Control Systems, Springer-Verlag, New York, 1985.

Bibliography
565
[280] Naidu, D. S., “Singular Perturbations and Time-Scales in Control The-
ory and Applications: An Overview”, Dynamics of Continuous, Discrete
and Impulsive Systems Series B: Applications & Algorithms, vol. 9, 2002,
pp. 233–278.
[281] Narendra, K. S., N. Oleng and S. Mukhopadhyay, “Decentralized Adap-
tive Control with Partial Communication”, IEE Proc. Control Theory
Appl., vol. 153, no. 5, 2006, pp. 546–555.
[282] Nguang, S. and P. Shi, “Delay-Dependent H∞Filtering for Uncertain
Time Delay Nonlinear Systems: An LMI Approach”, Proc. American
Contr. Conf., Minneapolis, MN, 2006, pp. 5043–5048.
[283] Nian, X. and R. Li, “Robust Stability of Uncertain Large-Scale Systems
with Time-Delay”, In J. Systems Sciences, vol. 32, 2001, pp. 541–544.
[284] Nicholson, N., “Dynamic Optimization of a Boiler”, Proc. IEE, vol. 3,
1964, pp. 1479–1486.
[285] Niu, Y., D. W. C. Ho, and J. Lam, “Robust Integral Sliding Mode Control
for Uncertain Stochastic Systems with Time-Varying Delay”, Automatica,
vol. 41, no. 5, 2005, pp. 873–880.
[286] Ohta, Y. and D. D. Siljak, “An Inclusion Principle for Hereditary Sys-
tems”, J. Math. Anal. Appl., vol. 98, 1984, pp. 581–598.
[287] Oucheriah, S., “Decentralized Stabilization of Large-Scale Systems with
Multiple Delays in the Interconnection”, Int. J. Control, vol. 73, 2000, pp.
1213–1223.
[288] Pagilla, P. R., “Robust Decentralized Control of Large-Scale Intercon-
nected Systems: General Interconnections”, Proc. American Control Con-
ference, San Diego, 1999, pp. 4527–4531.
[289] Pagilla, P. R. and Y. Zhu, “A Decentralized Output Feedback Controller
for a Class of Large-Scale Interconnected Nonlinear Systems”, J. Dy-
namic Systems, Measurement, and Control, vol. 127, 2005, pp. 167–172.
[290] Park, P. G. and J. W. Ko, “Stability and Robust Stability for Systems
with a Time-Varying Delay”, Automatica, vol. 43, 2007, pp. 1855–1858.
[291] Patel, R. V. and M. Toda, “Quantitative Measure of Robustness for Mul-
tivariable Systems”, Proc. Joint Auto. Control Conf., San Francisco, CA,
TPS-A.

566
Bibliography
[292] Pearson, J. D., “Dynamic Decomposition Techniques”, in Optimization
Methods for Large-Scale Systems, Wismer, D. A. (ed.), McGraw-Hill,
New York, 1971.
[293] Peaucelle, D., D. Arzelier and C. Farges, “LMI Results for Resilient
State-Feedback with H∞Performance,” Proc. the 43rd IEEE Conference
on Decision and Control, Paradise Island, Bahamas, December 2004, pp.
400–405.
[294] Petersen, I. R., “A Stabilization Algorithm for a Class of Uncertain Lin-
ear Systems”, Systems & Control Letters, vol. 8, 1987, pp. 351–357.
[295] Phohomsiri, P., F. E. Udwadia and H. Von Bremmen, “Time-Delayed
Positive Velocity Feedback Control Design for Active Control of Struc-
tures,” J. Engineering Mechanics, vol. 132, no. 6, 2006, pp. 690–703.
[296] Pujol, G., J. Rodellar, J. M. Rossell and F. Fozo, “Decentralized Reliable
Guaranteed Cost Control of Uncertain Systems: An LMI Design”, IET
Control Theory Appl., vol. 1, no. 3, 2007, pp. 779–785.
[297] Quazza, G., “Large-Scale Control Problems in Electric Power Systems”,
Automatica 13, 1977, pp. 579–593.
[298] Rautert, T. and E. W. Sachs, “Computational Design of Optimal Output
Feedback Controllers”, SIAM J. Optim., vol. 7, 1996, pp. 1117–1125.
[299] Richard, J. P., “Time-Delay Systems: An Overview of Some Recent Ad-
vances and Open Problems”, Automatica, vol. 39, no. 10, 2003, pp. 1667–
1694.
[300] Rotkowitz, M. and S. Lall, “Decentralized Control Information Struc-
tures Preserved under Feedback”, Proc. 41st IEEE Conf. Dec. and Con-
trol, Las Vegas, NV, 2002, pp. 569–575.
[301] Rotkowitz, M. and S. Lall, “A Characterization of Convex Problems in
Decentralized Control”, IEEE Trans. Automatic Control, vol. 51, 2006,
pp. 274–286.
[302] Saberi, A. and Khalil, H., “Decentralized Stabilization of Interconnected
Systems Using Output Feedback”, Int. J. Control, vol. 4l, no. 6, 1985,
pp. 1461–1475.
[303] Saeks, R., Ed., Large Scale Dynamic Systems, Point Lobos Press, No.
Hollywood, CA, 1976.

Bibliography
567
[304] Saeks, R., “On the Decentralized Control of Interconnected Dynamic
Systems”, IEEE Trans. Automat. Contro., vol. AC-24, 1979, pp. 269–271.
[305] Sage, A. P., Optimum Systems Control, Prentice-Hall, Englewood Cliffs,
NJ, 1968.
[306] Sage, A. P., Methodology for Large-Scale Systems, McGraw-Hill, New
York, 1977.
[307] Sandell, N. P. , P. Varaiya, M. Athans and M. G. Safonov, “A Survey of
Decentralized Control Methods for Large-Scale Systems”, IEEE Trans.
Automat. Contro., vol. AC-23, 1978, pp. 108–128.
[308] Sastry, S. S., Nonlinear Systems: Analysis, Stability and Control,
Springer, New York, 1999.
[309] Savastuk, S. K. and D. D. Siljak, “Optimal Decentralized Control”, Proc.
American Control Conference, Baltimore, MD, 1994, pp. 3369–3373.
[310] Sezer, M. E. and D. D. Siljak, “On Structural Decomposition and Stabi-
lization of Large-Scale Control Systems”, IEEE Trans. Automat. Contro.,
vol. AC-26, 1981, pp. 439–444.
[311] Sezer, M. E. and D. D. Siljak, “Nested Epsilon-Decomposition of Clus-
tering Complex Systems” , Automatica, vol. 22, 1986, pp. 321–331.
[312] Scorletti, G. and G. Duc, “An LMI Approach to Decentralized H∞Con-
trol”, Int. J. Control, vol. 74, no. 3, 2001, pp. 211–224.
[313] Shaked, U. and C. E. de Souza, “Robust Minimum Variance Filtering”,
IEEE Trans. Signal Processing, vol. 43, 1995, pp. 2474–2483.
[314] Scherer, C., “Mixed H2/H∞Control”, in Trends in Control: A Euro-
pean Perspective, A. Isidori (ed.), Springer-Verlag, Berlin, pp. 171–216.
[315] Scherer, C., P. Gahinet and M. Chilali, “Multiobjective Output-Feedback
Control via LMI Optimization”, IEEE Trans. Automat. Contro., vol. 42,
1997, pp. 896–911.
[316] Shi, L. S., C. K. Ko, Z. Jin, D. Gayme, V. Gupta, S. Waydo and R.
M. Murray, “Decentralized Control across Bit-Limited Communication
Channels: An Example”, Proc. American Contr. Conf., Portland, ME,
2005, pp. 3348–3353.

568
Bibliography
[317] Shi, P. and E. K. Boukas, “H∞Control for Markovian Jumping Lin-
ear Systems with Parametric Uncertainty”, J. Optimization Theory and
Applications, vol. 95, no. 1, 1997, pp. 75–99.
[318] Shi, P., E. K. Boukas and R. K. Agarwal, “Control of MMarkovian Jump
Discrete-Time Systems with Norm Bounded Uncertainty and Unknown
Delays”, IEEE Trans. Automat. Contro., vol. 44, no. 11, 1999, pp. 2139–
2144.
[319] Shi, P., E. K. Boukas and R. K. Agarwal, “Kalman Filtering for
Continuous-Time Uncertain Systems with Markovian Jumping Parame-
ters”, IEEE Trans. Automat. Contro., vol. 44, no. 8, 1999, pp. 1592–1597.
[320] Shyu, K., W. Liu and Hsu K. “Design of Large-Scale Time-Delayed Sys-
tems with Dead-Zone Input via Variable Structure Control”, Automatica,
vol. 41, no. 7, 2005, pp. 1239–1246.
[321] ˇSiljak, D. D., “On Stability of Large-Scale Systems under Structural Per-
turbations”, IEEE Trans. Systems, Man and Cybernetics, vol. SMC-3, no.
4, 1973, pp. 415–417.
[322] ˇSiljak, D. D. and M. K. Sundareshan, “A Multilevel Optimization of
Large-Scale Dynamic Systems”, IEEE Trans. Automat. Contro., vol. 21,
no. 2, 1976, pp. 79–84.
[323] ˇSiljak, D. D., Large-Scale Dynamic Systems: Stability and Structure,
North-Holland, Amsterdam, 1978.
[324] ˇSiljak, D. D., Decentralized Control of Complex Systems, Academic,
Cambridge, 1991.
[325] ˇSiljak, D. D., “Decentralized Control and Computations: Status and
Prospects”, Annual Reviews in Control, vol. 20, 1996, pp. 131–141.
[326] ˇSiljak, D. D. and D. M. Stipanovic, “Robust Stabilization of Nonlinear
Systems: The LMI Approach”, Math. Prob. Eng., vol. 6, 2000, pp. 461–
493.
[327] ˇSiljak, D. D., D. M. Stipanovic and A. I. Zecevic, “Robust Decentral-
ized Turbine/Governor Control Using Linear Matrix Inequalities”, IEEE
Trans. Power Syst., vol. 17, 2002, pp. 715–722.
[328] ˇSiljak, D. D., D. M. Stipanovic and A. I. Zecevic, “Robust Decentralized
Turbine/Governor Using Linear Matrix Inequalities”, IEEE Trans. Power
Syst., vol. 17, 2002, pp. 715–722.

Bibliography
569
[329] ˇSiljak, D. D. and A. I. Zecevic, “Control of Large-Scale Sys-
tems:
Beyond
Decentralized
Feedback”,
Preprints
of
the
10th
IFAC/IFORS/IMACS/-IFIP
Symposium
on
Large
Scale
Systems:
Theory and Applications, vol. 1, Osaka, Japan, 2004, pp. 1–10.
[330] ˇSiljak, D. D. and A. I. Zecevic, “Control of Large-Scale Systems: Be-
yond Decentralized Feedback”, Annual Reviews in Control, vol. 29, 2005,
pp. 169–179.
[331] Singh, M. G., S. A. W. Drew and J. F. Coales, “Comparisons of Practical
Hierarchical Control Methods for Interconnected Dynamical Systems”,
Automatica, vol. 11, no. 4, 1973, pp. 331–350.
[332] Singh, M. G., “A New Algorithm for the On-Line Multilevel Control of
Large Interconnected Systems with Fast Dynamics,” Int. J. Control, vol.
21, no. 4, 1975, pp. 587–597.
[333] Singh, M. G., “Multi-Level State Estimation,” Int. J. Syst. Sci., vol. 6,
no. 6, 1975, pp. 535–555.
[334] Singh, M. G., M. F. Hassan and A. Titli, “Multilevel Feedback Control
for Interconnected Dynamical Systems Using the Prediction Principle”,
IEEE Trans. Systems, Man and Cybernetics, vol. SMC-6, no. 4, 1976, pp.
233–239.
[335] Singh, M. D., Dynamical Hierarchical Control, North-Holland, Amster-
dam, 1977.
[336] Singh, M. G. and A. Titli, Systems: Decomposition, Optimization and
Control, Pergamon Press, Oxford, 1978.
[337] Singh, M. D. and A. Title, Eds., Large Scale Systems: Theory and Ap-
plications, North-Holland, Amsterdam, 1979.
[338] Singh, M. G., M. F. Hassan, Y. L. Chen and O. R. Pan, “New Approach
to Failure Detection in Large-Scale Systems”, IEE Proc. D, Control The-
ory Appl., vol. 130, 1983, pp. 117–121.
[339] Srichander, R. and B. K. Walker, “Stochastic Analysis for Continuous-
Time Fault-Tolerant Control Systems”, Int. J. Control, vol. 57, no. 2,
1989, pp. 433–452.
[340] Smith, N. J. and A. P. Sage, “An Introduction to Hierarchical Systems
Theory,” Comput. and Elec. Engrg., vol. 1, 1973, pp. 55–71.

570
Bibliography
[341] Smith, R. S. and F. Y. Hadaegh, “Closed-Loop Dynamics of Cooperative
Vehicle Formations with Parallel Estimators and Communication”, IEEE
Trans. Automat. Contro., vol. 52, no. 8, 2007, pp. 1404–1405.
[342] Sojoudi, S., J. Lavaei and A. G. Aghdam, “Optimal Information Flow
Structure for Control of Interconnected Systems”, Proc. American Con-
trol Conference, New York, 2007, pp. 1508–1513.
[343] Sourias, D. D. and V. Manousiouthakis, “Best Achievable Decentralized
Performance”, IEEE Trans. Automatic Control, vol. 40, 1995, pp. 1858–
1871.
[344] Spooner, M. D. and K. Passino, Stable Adaptive Systems, North-Holland,
Amsterdam, 2002.
[345] Stankovic, S. S. and D. D. Siljak, “Contractibility of Overlapping De-
centralized Control”, Systems & Control Letters, vol. 44, 2001, pp. 189–
200.
[346] Stankovic, S. S., D. M. Stipanovic and D. D. Siljak, “Decentralized Dy-
namic Output Feedback for Robust Stabilization of a Class of Nonlinear
Interconnected Systems”, Automatica, vol. 43, 2007, pp. 861–867.
[347] Stankovic, S. S. and D. D. Siljak, “Robust Stabilization of Nonlinear
Interconnected Systems by Decentralized Dynamic Output Feedback”,
Systems & Control Letters, vol. 58, no. 4, 2009, pp. 271–275.
[348] Stanojevic, M. J. and D. D. Siljak, “Robust Stability and Stabilization of
Discrete-Time Non-Linear Systems: The LMI Approach”, Int. J. Control,
vol. 74, 2001, pp. 873–879.
[349] Stanojevic, M. J. and D. D. Siljak, “Contractibility of Overlapping De-
centralized Control”, Systems and Control Letters, vol. 44, 2001, pp. 189–
199.
[350] Stankovi´c, S. S., M. J. Stipanovi´c and D. D. ˇSiljak, “Decentralized Over-
lapping Control of a Platoon of Vehicles”, IEEE Trans. Control System
Technology, vol. 8, 2000, pp. 816–832.
[351] Stipanovic, D. M. and D. D. Siljak, “Connective Stability of Discontin-
uous Dynamic Systems”, J. Optimization Theory and Applic., vol. 115,
no. 3, 2002, pp. 711–726.

Bibliography
571
[352] Stipanovic, D. M., G. Inalhan, R. Teo and C. J. Tomlin, “Decentralized
Overlapping Control of a Formation of Unmanned Aerial Vehicles”, Au-
tomatica, vol. 40, 2004, pp. 1285–1296.
[353] Sundareshan, M. K., “Exponential Stabilization of Large-Scale Systems:
Decentralized and Multilevel Schemes”, IEEE Trans. Syst. Man. Cyber.,
vol. SMC-7, 1977, pp. 478–483.
[354] Sundareshan, M. K., “Generation of Multilevel Control and Estima-
tion Schemes for Large-Scale Systems: A Perturbation Approach”, IEEE
Trans. Syst. Man. Cyber., vol. SMC-7, 1977, pp. 144–152.
[355] Sundareshan, M. K., “Decentralized Observation in Large-Scale Sys-
tems”, IEEE Trans. Syst. Man. Cyber., vol. SMC-7, 1977, pp. 863–864.
[356] Sundareshan, M. K. and R. M. Elbanna, “Qualitative Analysis and De-
centralized Controllers Synthesis for a Class of Large-Scale Systems with
Symmetrically Interconnected Subsystems”, Automatica, vol. 27, no. 2,
1991, pp. 383–388.
[357] Swarnakar, A., H. J. Marquez and T. Chen, “A Design Framework for
Overlapping Controllers and Its Application”, Proc. 46th IEEE Conf.
Dec. and Control, New Orleans, LA, 2007, pp. 2809–2814.
[358] Syrmos, V. L., C. T. Abdallah, P. Dorato and K. Grigoriadis, “Static
Output Feedback: A Survey”, Automatica, vol. 33, 1997, pp. 125–137.
[359] Tarokh, M. and Jamshidi, M., “Elimination of Decentralized Fixed
Modes with Minimum Number of Interconnection Gains”, Large Scale
Systems, vol. 2, 1987, pp. 207–215.
[360] Troﬁno-Neto, A. and V. Kucera, “Stabilization via Static Output Feed-
back”, IEEE Trans. Automat. Contro., vol. 38, 1993, pp. 764–765.
[361] Udwadia, F. E. and R. Kumar, “Time-Delayed Control of Classically
Damped Structural Systems”, Int. J. Control, vol. 60, 1994, pp. 687–713.
[362] Udwadia F. E., H. von Bremen, R. Kumar and M. Hosseini, “Time De-
layed Control of Structural Systems”, Int. J. Earthquake Engineering and
Structural Dynamics, vol. 32, 2003, pp. 495–535.
[363] Udwadia, F. E. and P. Phohomsiri, “Active Control of Structures Using
Time Delayed Positive Feedback Proportional Control Designs”, Struc-
tural Control and Health Monitoring, vol. 13, no. 1, 2006, pp. 536–552.

572
Bibliography
[364] Udwadia, F. E., H. von Bremen and P. Phohomsiri, “Time-Delayed Con-
trol Design for Active Control of Structures: Principles and Applica-
tions”, Struct. Control Health Monit., vol. 14, no. 1, 2007, pp. 27–61.
[365] Utkin, V. I., Sliding Modes and Their Applications to Variable Structure
Systems, MIR Publication House, Moscow, 1978.
[366] Veillette, R. J., J. V. Medanic and W. R. Perkins, “Design of Reliable
Control Systems”, IEEE Trans. Automat. Contro., vol. 37, no. 3, 1992,
pp. 290–304.
[367] Veillette, R. J., “Reliable Linear Quadratic State Feedback Control”, Au-
tomatica, vol. 31, 1995, pp. 137–143.
[368] Vidyasagar, M. and N. Viswanadham, “Algebraic Design Techniques for
Reliable Stabilization”, IEEE Trans. Automat. Contro., vol. AC-17, 1982,
pp. 1085–1095.
[369] Voulgaris, P. G., “A Convex Characterization of Classes of Problems in
Control with Speciﬁc Interaction and Communication Structures”, Proc.
American Contr. Conf., Arlington, VA, 2001, pp. 3128–3133.
[370] Wang, S. H. and E. J. Davison, “On the Stabilization of Decentralized
Control Systems”, IEEE Trans. Automat. Contro., vol. 18, no. 2, 1973,
pp. 473–478.
[371] Wang, Y., C. de-Souze and L. H. Xie, “Decentralized Output Feedback
Control of Interconnected Uncertain Delay Systems”, Proc. 12th IFAC
Congress, Australia, vol. 6, 1993, pp. 38–42.
[372] Watanabe, K., E. Nobuyama and A. Kojima, “Recent Advances in Con-
trol of Time Delay Systems—A Tutorial Review”, Proc. 35th IEEE Conf.
Dec. and Contr., Kobe, Japan, 1996, pp. 2083–2089.
[373] Wismer, D. A., Ed., Optimization Methods for Large-Scale Systems with
Applications, McGraw-Hill, New York, 1971.
[374] Wu, H., “Decentralized Adaptive Robust Control for a Class of Large-
Scale Systems Including Delayed State Perturbations in the Interconnec-
tions”, IEEE Trans. Automat. Contro., vol. 47, no. 10, 2002, pp. 1745–
1751.
[375] Xie, L. H., C. E. de Souza and M. Fu, “H∞Estimation for Discrete-
Time Linear Uncertain Systems”, Int. J. Robust and Nonlinear Control,
vol. 1, 1991, pp. 11–23.

Bibliography
573
[376] Xu, S. and J. Lam, “A Survey of Linear Matrix Inequality Techniques
in Stability of Delay Systems”, Int. J. Systems Science, vol. 39, 2008, pp.
1095–1113.
[377] Yan, X. G., J. J. Wang, X. Y. Li and S. Y. Zhang, “Decentralized Output
Feedback Robust Stabilization for a Class of Nonlinear Interconnected
Systems with Similarity”, IEEE Trans. Automat. Contro., vol. 43, no. 2,
1998, pp. 294–299.
[378] Yan, X. G. and L. Xie, “Reduced-Order Control for a Class of Nonlin-
ear Similar Interconnected Systems with Mismatched Uncertainty”, Au-
tomatica, vol. 39, no. l, 2003, pp. 91–99.
[379] Yan, J. J., “Memoryless Adaptive Decentralized Sliding Mode Control
for Uncertain Large-Scale Systems with Time-Varying Delays”, ASME
Journal Dynamics Systems, Measurement and Control, vol. 125, no. 2,
2003, pp. 172–176.
[380] Yan, X. G., C. Edwards and S. K. Spurgeon, “Decentralized Robust
Sliding-Mode Control for a Class of Nonlinear Interconnected Systems
by Static Output Feedback”, Automatica, vol. 40, no. 4, 2004, pp. 613–
620.
[381] Yan, X. G. and C. Edwards, “Adaptive Sliding-Mode Observer-Based
Fault Reconstruction for Nonlinear Systems with Parametric Uncertain-
ties”, IEEE Trans. on Industrial Electronics, vol. 55, no. 11, 2008, pp.
4029–4036.
[382] Yan, X. G. and C. Edwards, “Robust Decentralized Actuator Fault De-
tection and Estimation for Large-Scale Systems Using Sliding-Mode Ob-
server”, Int. J. Control, vol. 81, no. 4, 2008, pp. 591–606.
[383] Yang, G. H., J. Wang, C. B. Soh and J. Lam, “Design of Reliable Con-
trollers for Symmetric Composite Systems: Primary Contingency Case”,
Proc. the 35th IEEE Conference on Decision and Control, Kobe, Japan,
1996, pp. 3612–3617.
[384] Yang, G. H. and S. Zhang, “Stabilizing Controllers for Uncertain Sym-
metric Composite Systems”, Automatica, vol. 31, no. 2, 1995, pp. 337–
340.
[385] Yang, G. H., S. Zhang, J. Lam and J. Wang, “Reliable Control Using
Redundant Controllers, IEEE Trans. Automat. Contro., vol. 43, no. 11,
1998, pp. 1588–1593.

574
Bibliography
[386] Yang, T. C., “An Algorithm to Find the Smallest Possible Values in a
Matrix to Satisfy the M-Matrix Condition”, IEEE Trans. Automat. Con-
tro., vol. 42, no. 12, 1997, pp. 1738–1740.
[387] Yang, G. H. and J. L. Wang, “Robust Resilient Kalman Filtering for
Uncertain Linear Systems with Estimator Gain Uncertainty”, IEEE Trans.
Automat. Contro., vol. 46, 2001, pp. 343–348.
[388] Yang, G.-H., J. L. Wang and Y. C. Soh, “Reliable H∞Controller Design
for Linear Systems”, Automatica, vol. 37, 2001, pp. 717–725.
[389] Yang, G. H., J. L. Wang and C. Lin, “H∞Control for Linear Systems
with Additive Controller Gain Variations”, Int. J. Control, vol. 73, 2000,
pp. 1500–1506.
[390] Yang, G.-H. and J. Wang, “Non-Fragile H∞Control for Linear Sys-
tems with Multiplicative Controller Gain Variations”, Automatica, vol.
37, 2001, pp. 727–737.
[391] Yee, J. -S., G.-H. Wang and J. Wang, “Non-Fragile Guaranteed Cost
Control for Discrete-Time Uncertain Linear Systems”, Int. J. Systems Sci-
ence, vol. 32, no. 7, 2001, pp. 845–853.
[392] Y¨uksel, S., H. Hindi and L. Crawford, “Optimal Tracking with
Feedback-Feedforward Control Separation over a Network”, Proc. Amer-
ican Contr. Conf., Minneapolis, MN, 2006, pp. 3500–3506.
[393] Y¨uksel, S. and T. Basar, “On the Absence of Rate Loss in Decentralized
Sensor and Controller Structure for Asymptotic Stability”, Proc. Ameri-
can Contr. Conf., Minneapolis, MN, 2006, pp. 5562–5567.
[394] Y¨uksel, S. and T. Basar, “Communication Constraints for Decentral-
ized Stabilizability with Time-Invariant Policies”, IEEE Trans. Automatic
Control, vol. 52, no. 6, 2007, pp. 1060–1066.
[395] Zak, S. H. and S. Hui, “On Variable Structure Output Feedback Con-
trollers for Uncertain Dynamic Systems”, IEEE Trans. Automat. Contro.,
vol. 38, no. l0, 1993, pp. 1509–1512.
[396] Zecevic, A. I. and D. D. Siljak, “Stabilization of Nonlinear Systems with
Moving Equilibria”, IEEE Trans. Automat. Contro., vol. 48, 2003, pp.
1036–1040.

Bibliography
575
[397] Zecevic, A. I. and D. D. Siljak, “Design of Robust Static Output Feed-
back for Large-Scale Systems”, IEEE Trans. Automatic Control, vol. 49,
no. 11, 2004, pp. 2040–2044.
[398] Zecevic, A. I., G. Neskovic and D. D. Siljak, “Robust Decentralized
Exciter Control with Linear Feedback”, IEEE Trans. Power Syst., vol. 19,
2004, pp. 1096–1103.
[399] Zecevic, A. I. and D. D. Siljak, “Global Low-Rank Enhancement of
Decentralized Control for Large-Scale Systems”, IEEE Trans. Automatic
Control, vol. 50, no. 5, 2005, pp. 740–744.
[400] Zhai, G., M. Ikeda and Y. Fujisaki, “Decentralized H∞Controller De-
sign: A Matrix Inequality Approach Using a Homotopy Method”, Auto-
matica, vol. 37, 2001, pp. 565–572.
[401] Zhao, Q. and J. Jiang, “Reliable State Feedback Control System Design
with Actuator Failures”, Automatica, vol. 34, 1998, pp. 1267–1272.
[402] Zhong, W. S., G. M. Dimirovski and J. Zhao, “Decentralized Synchro-
nization of an Uncertain Complex Dynamical Network”, Proc. American
Contr. Conf., New York, NY, 2007, pp. 1437–1442.
[403] Zhou, J. “Decentralized Adaptive Control for Large-Scale Time-Delay
Systems with Dead-Zone Input”, Automatica, vol. 44, no. 7, 2008, pp.
1790–1799.
[404] Zhou, K. and J. C. Doyle, Essentials of Robust Control, Prentice-Hall,
Englewood Cliffs, NJ, 1998.
[405] Zhou, B. and G. R. Duan, “Global Stabilization of Linear Systems via
Bounded Controls”, Systems & Control Letters, vol. 58, 2009, pp. 54–61.
[406] Zhu, Y. and P. R. Pagilla, “Decentralized Output Feedback Control of a
Class of Large-Scale Interconnected Systems”, IMA J. Math Control and
Info., vol. 24, 2007, pp. 57–69.
[407] Zribi, M., M. S. Mahmoud, M. Karkoub and T. Li “H∞-Controllers for
Linearized Time-Delay Power Systems”, IEE Proc. Gene. Trans. and Dis-
tribution, vol. 147, no. 6, 2000, pp. 401–408.

