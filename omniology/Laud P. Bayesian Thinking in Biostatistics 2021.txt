Bayesian 'Thinking in 
Biostatistics

CHAPMAN Ir: HALUCRC
Toti In Statlidcal Science Serio
JoM!ph K. Klituh!in, Harvard Univtnlt)', USA
Julian J. faraway, University ofBath, UK
Martin Tanner, North^waiun University. USA 
Jim Zidek, University. ofBritish Columbia, Canada
RecentJy Pubiiihed l1tlei
Practicd Muldvariate Anaib, Si^h Edition
Abddmonem Ajlji, S^ianne May. RobinA. Donatdlo, and Virginia A. Clark
lime Serin: A Ant Coune with Bootstrap Starter
FTuder £ McElroy and DimitrU N. Polu&
Probability and Baynla.n Modelini
JimAlbertand/iqrkenHu
Sarroptei
Gaussian Process Modeling, Design, and Optimization for the Applied Sciences
Robertrt 8 Gramacy
StadiUcal Analyaii o(Anandal Data
With Examples in R
/llmoGemtle
Statiidcal Rethinldq
A Bayesian Course with Examples in R and STAN, Second Edition 
Richard McElreath
Statlidcal Machine LearnlnB
A Model-Hased Approach
Richard Gulden
Randomization, Bootstrap and Monte Carlo Methods In BiololJY
Fourth Edition
Bryan F. J. Manly, /orje A. Navarro Alberto
Principles o(Uncertalnty, Second Edition
fosep},B.Kadane
Beyond Multiple Unear Regress.Ion
Applied Generalized linear Models and Multilevel Models in R
Paul Riihark, Julie Legler
Bayeiian Thinking in Biostattsdcs
Gary L. Rosner, Purushottam W. Laud, and Wesley a /ohnson
Modern Data Science with R, Second Edition
Benjamin S. Baumer. Daniel T Kaplan, and Nicholas f Horton
Probability and Statistical Inference
1ium Pasie l'rmnp/es to Advanced iWodefs
Miftiadis Mavrakakis and Je"my Panzer
For more informadon about this series, please visit: https;//w^^.crcpress.com/Chapman--Hall- 
CRC Texts-in-Stadsticai-Science/book-series/CHTEXSTASCI

Bayesian Thinking in 
Biostatistics
by
Gary L. Rosner 
Purushottam W. Laud 
Wesley O. Johnson
CRC Press
Taylor & Francis Croup 
Boca Raton London New York
CRC Press is an imprint of .he
Taylor & Francis Croup, an Infonna business
A CHAPMAN & HALL BOOK

First edition published 2021
by CRC Press
6000 Broken Sound Parkway NW, Suite 300, Boca Raton, FL 33437-2742
and by CRC Press
2 Park Square, Milton Park, Abingdon, Oxon, 0X14 4RN
© 2021 Taylor & Francis Group, LLC
CRC Press is an Imprint of Taylor & Francis Group, LLC
Reasonable efforts have been made to publish reliable data and information, but the author and publisher cannot as­
sume responsibility for the validity of all materials or the consequences of their use. The authors and publishers have 
attempted to trace the copyright holders of all material reproduced in this publication and apologize to copyright holders 
If permission to publish In this form has not been obtained. If any copyright material has not been acknowledged please 
write and let us know so we may rectify in any future reprint.
Except as permitted under U.S. Copyright Law, no part of this book may be reprinted, reproduced, transmitted, or 
utilized in any form by any electronic, mechanical, or other means, now known or hereafter invented, including pho­
tocopying, microfilming, and recording, or in any information storage or retrieval system, without written permission 
from the publishers.
For permission to photocopy or use material electronically from this work, access www.copyright.com or contact the 
Copyright Clearance Center, Inc. (CCC), 222 Rosewood Drive, Danvers, MA 01923, 978-750-8400. For works that are 
not available on CCC please contact mpkbookspcrmissions@tandf.co.uk
Trademark notice: Product or corporate names may be trademarks or registered trademarks, and are used only for iden­
tification and explanation without intent to infringe.
Library of Congress Cataloging-in-Publication Data
Names: Rosner. Gary L„ author. | Laud. Purushottam, 1948- author. | 
Johnson. Wesley O„ author.
Title: Bayesian thinking in biostatistics I Gary L. Rosner, Purushottam 
W. Laud, Wesley O. Johnson.
Description: First edition. | Boca Raton : CRC Press. 2021. | Includes 
bibliographical references and index.
Identifiers: l.CCN 2020049870 (print) | LCCN 2020049871 (ebook) | ISBN 
9781439800089 (hardcover) | ISBN 9781439800102 (ebook) 
Subjects LCSI I: Biometry -Methodology. | Bayesian statistical decision theory. 
Classdication: I.CC QH323.5 .R68 2021 (print) | LCC QH323.5 (ebook) |
570 l/5l95-dc23
l.C record available at https://lccn.loc.gov/2020049870
l.C ebook record available at https://lccn.loc.gov/2020049871
ISBN: 978-1-4398-0008-9 (hbk)

To my wife, Naomi, and my children, Joshua and Molly, for their support, under­
standing, patience, and, most of all, love. GLR
To Kaye and the boys - Raj, Kavi, Sanjiv and Filip - who have believed since its 
conception that this project would come to fruition. PWL
To my friend and mentor, Seymour Geisser. I miss him very much. WOJ


Contents
Preface 
xv
1 
Scientific Data Analysis 
1
1.1 
Philosophy ......................................................................................................... 2
1.2 
Examples............................................................................................................ 3
1.3 
Essential Ingredients for Bayesian Analysis ............................................ 5
1.3.1 Observables and Design for Their Collection........................... 6
1.3.2 Unknowns of Scientific Interest...................................................... 6
1.3.3 Probability Models and Model Parameters................................ 7
1.3.4 External Knowledge (or Prior) Distribution............................ 7
1.4 
Recap and Readings........................................................................................ 9
2 
Fundamentals I: Bayes’ Theorem, Knowledge Distributions, Pre­
diction 
11
2.1 
Elementary Bayes’ Theorem: Simple but Fundamental Probability 
Computations .............................................................................................. 12
2.2 
Science and Knowledge about Uncertain Quantities ......................... 16
2.3 
More on Bayes’ Theorem: Inference for Model Unknowns .............. 19
2.4 
Prediction .......................................................................................................... 27
2.5 
Monte Carlo Approximation ....................................................................... 30
2.6 
Recap and Readings........................................................................................ 31
2.7 
Exercises ............................................................................................................. 32
3 
Fundamentals II: Models for Exchangeable Observations 
37
3.1 
Overview of Binomial, Normal, Poisson and Exponential Models 
38
3.2 
Posterior and Predictive Inferences............................................................ 41
3.2.1 
Bernoulli and Binomial Models...................................................... 41
3.2.2 Normally Distributed Exchangeable Observations..................  
47
3.2.3 Poisson Distributed Exchangeable Count Observations ... 
59
3.2.4 Exchangeable Exponentially Distributed Time-to-Event Ob­
servations ................................................................................ 61
3.3 
*More Flexible Models ............................................................................... 65
3.3.1 Mixture Distributions....................................................................... 66
3.3.2 Dirichlet Process Mixtures................................................................ 67
vii

viii
Contents
3.3.3 Computation via DPpackage....................................................... 69
3.4 
Recap and Readings................................................................................. 69
3.5 
Exercises .................................................................................................... 70
4 
Computational Methods for Bayesian Analysis 
75
4.1 
Additional Sampling Distributions....................................................... 76
4.1.1 Gamma Distributed Data........................................................... 76
4.1.2 Weibull Distributed Data........................................................... 76
4.2 
Asymptotics: Normal and Laplace Approximations ...................... 77
4.3 
Approximating Posterior Inferences using Monte Carlo Sampling . 
79
4.3.1 
Random Number Generation.................................................... 80
4.3.2 
Inverse cdf Method....................................................................... 80
4.3.3 
Importance Sampling ................................................................. 81
4.3.4 
Rejection Sampling....................................................................... 83
4.3.5 
Adaptive Rejection Sampling for Log-Concave Densities . . 
85
4.4 
Markov Chain Monte Carlo Sampling ................................................ 87
4.4.1 
Gibbs Sampler.............................................................................. 89
4.4.2 
Metropolis-Hastings Algorithm................................................. 92
4.4.3 
Slice Sampling.............................................................................. 96
4.4.4 
Hamiltonian Markov Chain Monte Carlo Sampling............... 
97
4.4.4.1 Overview........................................................................ 97
4.4.4.2 Expanding the Parameter Space.............................. 98
4.4.4.3 Basics of Hamiltonian Dynamics.............................. 98
4.4.4.4 Approximation to Generate Candidate.................... 100
4.4.5 
Convergence Diagnostics . . ....................................................... 102
4.5 
Recap and Readings................................................................................. Ill
4.6 
Exercises .................................................................................................... 112
5 
Comparing Populations 
119
5.1 
Comparing Proportions in Bernoulli Populations............................. 119
5.1.1 Prior Distributions for Binomial Proportions......................... 120
5.1.1.1 
Reference Priors........................................................... 121
5.1.1.2 
Informative Beta Priors............................................... 121
5.1.1.3 
Other Priors.................................................................. 124
5.1.2 Effect Measures............................................................................... 125
5.1.3 Cross-Sectional or Cohort Sampling .......................................... 126
5.1.4 Case-Control Sampling.................................................................. 128
5.2 
Comparing Normal Populations ......................................................... 132
5.2.1 Priors for 
i = 1,2.......................................................... 132
5.2.1.1 Reference Priors........................................................... 132
5.2.1.2 Informative Priors....................................................... 134
5.2.2 Posterior Inference for Comparing Populations.................... 135
5.2.3 Prediction ..................................................................................... 136

Contents
5.2.4 DiaSorin Data Analysis..................................................................... 137
5.3 
Inferences for Rates .................................................................................. 141
5.3.1 Reference Priors................................................................................... 142
5.3.2 Informative Priors............................................................................... 142
5.3.3 Nurses’ Health Study Data Analysis............................................ 143
5.4 
Recap and Readings ..................................................................................... 144
5.5 
Exercises ............................................................................................................ 144
6 
Specifying Prior Distributions 
149
6.1 
Flat Priors ........................................................................................................... 150
6.2 
*Jeffreys Priors.................................................................................................... 152
6.3 
Scientifically Informed Priors ...................................................................... 154
6.4 
*Data Augmentation Priors............................................................................. 159
6.5 
Reference Priors ................................................................................................. 161
6.6 
Recap and Readings 
.......................................................................................... 163
6.7 
Exercises ................................................................................................................ 164
7 
Linear Regression 
167
7.1 
The Linear Regression Model....................................................................... 168
7.1.1 Simple Linear Regression: Single Numeric Predictor .... 
169
7.1.2 From Model to Data Analysis.......................................................... 171
7.1.3 Multiple Covariates: Continuous and Categorical.................. 174
7.1.4 Centering and Standardization of Covariates ......................... 178
7.2 
Matrix Formulation and an Analytic Posterior Distribution .... 
180
7.2.1 Matrix Notation.................................................................................... 180
7.2.2 Posterior Analysis using the Flat Prior........................................ 181
7.2.2.1 Deriving the Posterior with the Flat Prior.................. 
181
7.2.2.2 Inference with Flat Prior................................................. 182
7.3 
Priors 
.................................................................................................... 184
7.3.1 Flat Prior .................................................................................................... 185
7.3.2 A Proper Approximation to the Flat Prior................................. 185
7.3.3 Conditionally Conjugate Independence Prior............................... 185
7.3.3.1 
Conditional Means Prior for /3...................................... 187
7.3.3.2 
An Informative Prior for г and <r................................. 189
7.3.4 
Partial Information Prior.................................................................. 190
7.4 ‘Conjugate Priors ................................................................................................ 192
7.4.1 
Generic Normal-Gamma Prior ....................................................... 192
7.4.2 
Zellner’s g-Prior .................................................................................... 194
7.5 
Beyond Additivity: Interaction (Effect Modification)............................ 195
7.6 ANOVA...................................................................................................................... 200
7.7 Recap and Readings............................................................................................... 205
7.8 
Exercises 
........................................................................................................... 207

Contents
8 
Binary Response Regression 
215
8.1 
Logistic Regression Model..................................................................... 215
8.2 
Logistic Regression Model with Interaction ..................................... 222
8.3 
Inference for Regression Coefficients and Their Functions ........... 223
8.3.1 
Inference for Lethal Dose a....................................................... 225
8.4 
Prior Distributions................................................................................. 226
8.4.1 
Conditional Means Priors.......................................................... 226
8.4.2 Partial Prior Information.......................................................... 229
8.4.3 
Low-Information Omnibus Priors............................................... 231
8.5 Prediction ................................................................................................ 232
8.6 Alternatives to Logistic Regression: Other Link Functions..............  
234
8.7 Recap and Readings................................................................................ 236
8.8 Exercises ................................................................................................... 237
9 
Poisson and Nonlinear Regression 
241
9.1 
The Basic Poisson Regression Model 
............................................ 241
9.2 Poisson-Based More General Models for Count Data........................ 252
9.2.1 Overdispersion............................................................................. 252
9.2.2 Zero-Inflated Poisson Data ...................................................... 254
9.3 Overview of Generalized Linear Model Regression .......................... 258
9.4 *Nonlinear Regression............................................................................. 260
9.5 Recap and Readings ............................................................................. 264
9.6 Exercises ................................................................................................... 265
10 
Model Assessment 
269
10.1 
Model Selection Based on Posterior Probabilities and Bayes Factors 270
10.1.1 Choice between Two Models ................................................... 270
10.1.2 Cautions Regarding Bayes Factors.......................................... 273
10.1.3 Choosing among Multiple Models............................................. 275
10.1.4 Computing Bayes Factors via Sampling................................ 275
10.2 
Model Selection Based on Predictive Information Criteria .... 278
10.2.1 
Log Pseudo Marginal Likelihood........................................... 280
10.2.2 Akaike Information Criterion.................................................. 281
10.2.3 Bayesian Information Criterion............................................... 282
10.2.4 Widely Applicable Information Criterion............................... 283
10.2.5 Deviance Information Criterion............................................... 284
10.2.6 Model Selection in Linear Regression..................................... 285
10.2.7 Comments on Information Criteria........................................ 287
10.2.8 Statistical versus Practical Import in Model Selection . . . 
287
10.3 
Model Checking (Model Diagnostics) ............................................ 289
10.3.1 Classical Checking..................................................................... 289
10.3.2 Box Check .................................................................................. 290

Contents 
xi
10.3.3 Johnson Check.................................................................................. 290
10.3.4 *Outlier Checking and Influential Observations..................... 293
10.3.5 Diagnostics for Linear Regression................................................. 297
10.3.6 Diagnostics for Binary Regression................................................ 300
10.4 
Recap and Readings .................................................................................. 301
10.5 
Exercises ......................................................................................................... 302
11 
Survival Modeling I: Models for Exchangeable Observations 311
11.1 
Some Concepts and Definitions............................................................... 311
11.1.1 
Survival and Hazard Functions................................................... 312
11.1.2 Censoring............................................................................................. 313
11.1.2.1 Right Censoring................................................................. 313
11.1.2.2 Left and Interval Censoring............................................ 313
11.1.2.3 Assumptions for Censoring Mechanism .................. 314
11.1.3 Sampling Distribution (Likelihood) for Exchangeable Data 314
11.1.3.1 Right Censored Data ..................................................... 315
11.1.3.2 More General Case: Interval Censored Data .... 
316
11.1.4 Inference and Its Targets ............................................................... 316
11.1.5 Prediction............................................................................................... 318
11.1.6 Plotting Survival and Hazard Functions................................... 318
11.2 An Empirical Survival Function: The Kaplan-Meier Estimate . . 
320
11.3 Models for Samples from a Single Population..................................... 322
11.3.1 Parametric Models............................................................................. 323
11.3.1.1 Exponential Model............................................................ 323
11.3.1.2 Weibull Model................................................................... 326
11.3.1.3 Log-Normal Model............................................................ 330
11.3.2 Nonparametric Models...................................................................... 331
11.4 Two-Sample Models...................................................................................... 336
11.5 Competing Risks............................................................................................. 340
11.6 Recap and Readings...................................................................................... 343
11.7 Exercises ........................................................................................................... 344
12 
Survival Modeling II: Time-to-Event Regression Models 
347
12.1 
Accelerated Failure-Time Regression Models ................................... 347
12.1.1 Prior Distributions for AFT Parameters.................................. 354
12.1.1.1 Specifying p(/3).................................................................. 354
12.1.1.2 Specifying p(a).................................................................. 357
12.1.2 Sensitivity Analysis ........................................................................ 359
12.2 
Proportional Hazards: A Semiparametric Model ............................ 360
12.2.1 Modeling the Baseline Hazard Function.................................. 363
12.2.2 Counting Process Formulation or Poisson Likelihood Analog. 365
12.2.3 Prior Distributions for Parameters in Proportional Hazards 
Regression Models............................................................... 367

xii
Contents
12.2.3.1 Prior Distributions for Hazard Functions in Each
Interval.......................................................................... 367
12.2.3.2 Prior Distribution for the Log Hazard Ratios ... 
368
12.3 
Nonparametric Regression for Survival Analysis .......................... 371
12.4 
Survival Analysis with Random Effects (FYailty) .......................... 375
12.5 
Recap and Readings............................................................................. 376
12.6 
Exercises ................................................................................................ 377
13 
Clinical Trial Designs 
381
13.1 
What Are Clinical Trials?.................................................................... 382
13.2 
Phase 1 Studies (Dose Finding) ....................................................... 383
13.2.1 Joint Safety and Efficacy Monitoring....................................... 390
13.3 
Evaluation of a Design’s Characteristics.......................................... 394
13.4 
Phase 2 Studies (Activity) ................................................................ 395
13.4.1 Sample Size................................................................................... 396
13.4.2 Precision of Estimates................................................................ 397
13.4.3 Decision-Theoretic Sample Size Determination...................... 399
13.5 
Interim Analyses and Stopping Rules ............................................. 402
13.5.1 Posterior Probability-Based Stopping Rules............................ 402
13.5.2 Prediction-Based Stopping Rules............................................. 403
13.5.3 Hypothesis Test-Based Stopping Rules.................................... 408
13.5.4 Decision-Theoretic Stopping Rules.......................................... 410
13.6 Phase 3 Study Designs ......................................................................... 412
13.7 Response-Adaptive Randomization...................................................... 416
13.8 Recap and Readings............................................................................... 421
13.9 Exercises ................................................................................................... 422
14 
Hierarchical Models and Longitudinal Data 
427
14.1 Normal Hierarchical Models ............................................................... 428
14.1.1 Simple Examples.......................................................................... 428
14.1.2 Basics for Two-Level and Three-Level Models for the Data 432
14.1.3 Prior Specification....................................................................... 435
14.1.4 Meta-Analysis............................................................................. 437
14.2 Hierarchical Binomial Regression Modeling ....................................... 439
14.2.1 Informative Prior Elicitation ................................................... 446
14.2.1.1 Logit-Normal Prior Specification for 0 ................ 446
14.2.1.2 Conditional Means Prior for 0 Using Beta Distribu­
tions ................................................................ 448
14.2.1.3 Prior for а-у ................................................................ 448
14.2.2 ‘Gibbs Sampling......................................................................... 450
14.2.2.1 Centering on 0i .......................................................... 450
14.2.2.2 Centering on Group-Level Covariates..................... 453
14.2.3 Meta-Analysis: Ganzfeld Studies of ESP................................. 454

Contents 
xiii
14.3 
Hierarchical Longitudinal and Spatial Data Modeling ................. 458
14.3.1 Longitudinal Modeling as Hierarchical Modeling................. 461
14.3.2 Incorporating Latent Effects with Autoregressive Structure 468
14.4 Recap and Readings...................................................................................... 473
14.5 Exercises ........................................................................................................... 474
15 
Diagnostic Tests 
481
15.1 
Basics of Diagnosis with One Imperfect Binary Test and with Avail­
able Gold Standard Information ..................................................... 483
15.2 Continuous Biomarkers ............................................................................... 489
15.2.1 Receiver Operating Characteristic Curves.................................. 491
15.2.2 Diagnosis Based on Continuous Biomarkers.............................. 493
15.2.3 Statistical Inference for Binormal Diagnostic Outcome Data: 
GS Case.................................................................................... 496
15.2.4 ROC Regression: GS Case............................................................... 498
15.3 Recap and Readings...................................................................................... 502
15.4 Exercises ............................................................................................................ 504
A Probability and Random Variables 
509
A.l 
Probability Axioms and Rules ................................................................... 509
A.2 
Random Variables and Their Distributions ............................................ 511
A.2.1 Univariate Random Variables........................................................ 511
A.2.2 Bivariate Random Variables............................................................ 512
A.2.3 Multivariate Random Variables..................................................... 514
A.3 Expectation and Moments ......................................................................... 516
В Common Distributions 
521
C Software for Sampling Posterior Distributions 
527
C.l WinBUGS............................................................................................................ 527
C.1.1 OpenBUGS ........................................................................................... 530
C.l.2 Censored Data in BUGS................................................................... 530
C.1.3 Interface with R: R2WinBUGS and BRugs............................... 531
C.2 JAGS ................................................................................................................... 537
C.2.1 Censored Data in JAGS.................................................................. 538
C.3 Stan and rstan .................................................................................................. 540
C.3.1 Censored Data in Stan...................................................................... 549
C.4 R Packages ......................................................................................................... 551
Bibliography 
553
Index
581


Preface
How could they see anything but the shadows if they were never allowed to move 
their heads? (Plato, The allegory of the cave, The Republic, Book VII)
Why an introductory book on Bayesian biostatistics?
Bayesian statistical methods have found increased use and acceptance in biomed­
ical research. More and more clinical trials are including Bayesian considerations in 
their designs. Interim analyses based on posterior or predictive probabilities have 
appeared in protocols for clinical studies sponsored by the largest pharmaceutical 
companies and at internationally renowned academic medical centers. Governmen­
tal regulatory agencies, such as the U.S. Food and Drug Administration and the Eu­
ropean Medicines Agency, are becoming more open to considering clinical trials with 
Bayesian designs. In our roles as biostatisticians at active academic medical centers, 
we have used Bayesian methods in our collaborations. We receive frequent requests 
for information about Bayesian methods from our colleagues in other disciplines. We 
teach courses on Bayesian methods, focusing on biostatistical applications, and our 
students come from many different departments. Given this widespread interest— 
especially from our colleagues in disciplines outside of statistics—we felt the time 
is right for an introductory textbook that reviews Bayesian inference from the 
standpoint of someone whose interest is biostatistical but whose background is not. 
Aside from providing a summary of the concepts and theory of Bayesian inference, 
information that one can find in many available texts, we also discuss methods that 
biomedical investigators would want to use for their research. We cover Bayesian 
methods for analyzing time-to-event data (i.e., survival analysis), clinical trial de­
sign, longitudinal data analysis, and diagnostic tests.
Another factor that has contributed to broader use of Bayesian methods in 
biostatistics is the availability of computer programs to carry out the necessary 
computations. The stand-alone packages WinBUGS (and its current incarnation 
OpenBUGS), JAGS, and Stan, as well as packages and functions written for the 
statistical computing environment R, have put the ability to carry out rather so­
phisticated and complex data analyses in the hands of more people than ever be­
fore. The availability of these tools provides the opportunity to promote the use of 
Bayesian biostatistical methods to a wider audience. In the book and an accompa-
XV

xvi 
Preface
nying website, we provide programs in the BUGS language, with variants for JAGS 
and Stan, that one can use or adapt for one’s own research.
The topics we cover are the applications we see most often in our respective 
institutions. We are not able to cover each topic as thoroughly as we might like, 
since one could expand each method-focused chapter into a book. (In fact, books 
are available that focus on each chapter’s topic.) We have, however, endeavored to 
cover the elements that we consider to be the more important or useful aspects of 
each topic and provide the necessary background to allow further study if the reader 
wishes. We have ended each chapter with a section called “Recap and Readings” in 
which we provide references to books or research papers that contain further details 
or development of methods we discuss in the chapter.
What this book tries to accomplish
As mentioned above, we wrote this book for use by scientists and researchers who 
may not have extensive background in mathematics and statistics. Although we do 
include some of the mathematics, anyone with an understanding of basic calculus 
will be able to appreciate the underlying theory. Furthermore, we explain in words 
the concepts that underlie complicated methods. The goal is to give the scientist 
the ability to think about and use statistical models effectively in the context of 
the data available for analysis, as well as other information that may inform that 
analysis. In doing so, the analysis can focus on questions raised by the science, not 
restrictions imposed by the statistical method.
We describe the basics of Bayesian inference and explain many ways in which 
one may apply this statistical approach to carry out inference in one’s research. 
We describe models based on assumptions of particularly convenient distributions, 
such as the binomial, Gaussian (or normal) distributions, as do many standard 
textbooks. Unlike several other textbooks, however, we emphasize the availability of 
information with which one can form informed prior distributions. We feel strongly 
that one should put some thought into prior distributions instead of immediately 
using standard reference or so-called “non-informative” prior distributions. In many 
biomedical settings, we statisticians and our subject-matter collaborators know 
enough to be able to say that certain outcomes are highly unlikely (e.g., living 200 
years after suffering a myocardial infarction at age 65) or even impossible. The prior 
distribution is. after all. part of the statistical model. In our view, an advantage of 
the Bayesian approach is that it forces each member of the study team to think 
carefully about assumptions, including the assumptions that underlie statistical 
models.
We go beyond standard statistical models in the book. We introduce a few 
Bayesian nonparametric methods and illustrate their uses in data analysis. Bayesian 
nonparametric models provide a flexible and less restrictive approach to inference. 
These statistical models place uncertainty on the underlying probability distribu-

Preface
xvii
tions in the inferential model. This extra uncertainty relaxes one of the most ubi­
quitous assumptions in statistics, namely, that random continuous quantities follow 
normal distributions. Aside from removing the distributional assumption of normal­
ity, the extra flexibility also carries over into characterizing relationships between 
outcomes and covariates not as, say, linear but as mixtures of linear regressions. 
This freedom from more rigid modeling assumptions allows for exploration and a 
touchstone against which to assess parametric assumptions and particular models. 
Each of us has applied Bayesian nonparametric models in our research and writ­
ten on its application in complex problems. The availability of DPPackage in R 
and approximations via other software packages make these flexible inferential ap­
proaches available for use by many researchers who are not skilled at writing their 
own computer programs. We illustrate these methods in the book.
As it is natural in the Bayesian approach, we emphasize estimation of biomed- 
ically relevant quantities and assessment of the uncertainty in this estimation. This 
is in contrast to an emphasis on hypothesis formulation and testing that appears 
in most standard textbooks in biostatistics.
How to navigate and learn from the book
The first chapter introduces the components that are necessary for carrying out 
Bayesian inference and presents some biomedical example studies that we analyze 
in later sections of the book. In particular, this chapter presents our understand­
ing and vision of what statistical inference in science is all about. This philosophy 
underlies Bayesian thinking. Chapter 2 presents the fundamentals of Bayesian in­
ference. Chapter 3 illustrates Bayesian inference with some basic statistical models. 
Chapter 4 reviews computational methods for carrying out Bayesian inference, em­
phasizing Markov chain Monte Carlo methods and software to implement these 
computational approaches. Comparing populations is common in biostatistics, and 
Chapter 5 contains many models for such analyses. Chapter 6 covers the import­
ant topic of prior distributions, including prior elicitation and implementation via 
Markov chain Monte Carlo. Linear regression from a Bayesian perspective is cov­
ered in Chapter 7, and regression models for dichotomous outcomes are covered in 
Chapter 8. Several other regression models are given in Chapter 9. Once one has fit 
a model or models, one has to decide which of several competing models appears to 
fit the best and also assess how well the model actually fits the data. We cover this 
important topic in Chapter 10. Many biostatistical analyses concern time-to-event 
data, and Chapters 11 and 12 cover this topic from a Bayesian perspective. We 
provide a brief review of Bayesian approaches to designing clinical trials in Chapter 
13. Hierarchical models and longitudinal data are the subjects of Chapter 14. We 
present some basic models for evaluating diagnostic tests in Chapter 15.
There are also three appendices that provide some reference or background ma­
terial. Appendix A reviews elementary probability theory that forms the basis of

xviii 
Preface
statistical inference. We include several probability distributions in the book, and 
Appendix В contains a table of these distributions’ densities and key characteris­
tics. Since computation is critical for modern Bayesian data analysis, Appendix C 
contains brief descriptions of several software tools that one can use in one’s own 
research when one analyzes data. Readers will likely find several of the more general 
packages useful when doing the exercises at the end of each chapter.
We recommend that one read Chapters 1-6 in order before choosing topics 
from the remaining chapters. The choice of topics, chapters to cover, and the order 
could depend on available time, instructor or student interest, and other courses 
the student or reader may take as part of a degree program. One possibility is to 
include linear and binary regression (Chapters 7 and 8), followed by model criticism 
and choice (Chapter 10).
Another choice could be to include survival analysis (Chapters 11 and 12), along 
with some discussion of clinical trials (Chapter 13). There are many combinations 
that will fill a good semester of Bayesian biostatistics.
Sections with an asterisk (*)  in their title involve more difficult probability 
calculus that some readers may prefer to skip on first reading. Later chapters and 
sections not marked with * will not require the material in these sections. The * 
sections will be beneficial for those who wish to have a deeper understanding of 
the Bayesian approach to statistics and the underlying theory, but they are not 
necessary in order to practice it.
Web material
The book has a dedicated website that provides example programs written 
for use with WinBUGS (or OpenBUGS), JAGS, and Stan, along with data, at 
https://github.com/BTB-RLJ. We will post corrections we learn about on this 
site, as well as any addenda to the material already in the book. We hope this 
website will be dynamic and allow us to expand the models and discussion relating 
to Bayesian inference in biostatistics, as we receive comments and suggestions from 
readers, students, and teachers.
What this book does not do and where you can find that information
As we stated earlier, we cannot in this introductory book cover all application 
areas of Bayesian inference in biostatistics. Additionally, the field is dynamic and a 
rapidly expanding area of research, with new models arising all the time to address 
new subject-matter research questions and sources of biomedical data. Although 
we provide citations and references in each chapter, we will now provide a small list

Preface 
xix
of references that some readers may wish to consult alongside or after reading this 
book.
A general introduction to Bayesian thinking that does not use any calculus is 
given in the book by Donald Berry [36]. The books by Gelman et al. [133] and Carlin 
and Louis [63] provide a general but modern (i.e., computational) presentation of 
the Bayesian approach to inference. Christensen et al. [79] cover some (but not all) 
of the same methods that we present in this book. A very good source of interesting 
examples is The BUGS Book by Lunn et al. (2012) [232]. Another good source for 
examples is McElreath (2020) [241]. Kadane (2011) [196] presents the theoretical 
foundations underlying Bayesian statistical models, including decision theory.
Acknowledgments
We wish to thank our teachers and colleagues for their inspiration and guidance. 
We also thank our students for always helping us learn new things or gain a new 
understanding of methods and theory. Many people have helped us along the way 
in writing this book. We thank Yushu Shi and Jacob Fiksel for their programming 
help. We have made use of materials in the book Bayesian Ideas and Data Analysis: 
An Introduction for Scientists and Statisticians [79] in the writing of this book. We 
appreciate the authors’ efforts that have in turn helped us in our efforts. We also 
wish to express our appreciation for David Grubbs of Chapman & Hall/CRC for 
his patience and guidance throughout the process. Last, but definitely not least, we 
thank our families for their never ending support.


Chapter 1
Scientific Data Analysis
Bayesian statistical methods follow a well-defined set of principles and rely on the 
mathematics of probabilities. These principles require a focus on a model for the 
data to be analyzed and on the information available about the model in sources 
extraneous to these data. The method combines this information with the informa­
tion in the data, and then proceeds to make scientific conclusions with quantified 
certainty. Typically, the certainty of conclusions is captured in clear probability 
statements and in predictions for future data. Such post-data statements consist 
of what is termed “inference.” Essentially, this is the culmination of taking the 
external-to-data knowledge about a biomedical mechanism and its outcome, learn­
ing from the collected data, and arriving at an updated state of knowledge.
As an example, suppose data will be collected to study the extent of the rota­
tional acceleration involved in injuries leading to a concussion diagnosis during high 
school football games. The gathering of such data would involve helmets equipped 
with sophisticated measuring devices [154]. The resulting data may be regarded as 
repeated measurements, in units of radians per second squared, corresponding to 
each concussion event. Describing the data via statistical summary measures (e.g., 
means and standard deviations) and via graphical displays (e.g., histograms and 
boxplots) is an important first step in the analysis. However, as there will be varia­
tion in these numbers from one event to another, it is also very useful next to think 
of the mechanism by which data similar to those collected could arise. This thought 
process is called modeling the data, the model specifying a probabilistic mechanism 
that might have generated the data. Methods of Bayesian statistics emphasize the 
model-based approach to data analysis. As an initial step, we could think of the 
rotational acceleration data as arising from a normal distribution, and without 
any probabilistic distinction from one event to another. Now, the data-generating 
normal distribution has some mean and standard deviation. These two unknown 
quantities, in turn, are represented by probability distributions assigned to their 
possible values. Such distributions for unknowns are to characterize mathematically 
any possible external information available from sources (perhaps laboratory data 
in animal models, historical reports) distinct from the data to be collected. Bayesian 
inference then represents data-incorporated knowledge about the unknowns, com­
bining the data and the outside-data information. This knowledge is characterized 
by probability statements that include estimates and uncertainty about the esti­
mates, as well as used to predict future data.
In this chapter, after a description of our approach, we introduce some examples 
and then give brief general presentations of the pieces needed for Bayesian analysis.
1

2
Bayesian Thinking in Biostatistics
1.1 
Philosophy
We motivate the book with a general philosophy of data analysis that will be 
illustrated in the next section, with details to follow in the remainder of the book:
• 
that a primary role of statistics in science and society is to provide appropriate 
tools for addressing scientific questions;
• 
that appropriate statistical analysis of data involves a collaborative effort 
between subject-matter scientists and statisticians;
• 
that it is both appropriate and necessary to incorporate the scientist’s exper­
tise into making decisions related to the data;
• 
that foundational issues matter in statistics;
• 
that prediction is of fundamental importance.
To achieve these aims, we have adopted a Bayesian approach. Bayesian statistical 
analysis is based on the premise that all uncertainty should be modeled using prob­
abilities and that statistical inferences should be logical conclusions based on the 
laws of probability.
The field of statistics has long embraced the concept of probability models for 
data. Such models typically involve parameters that are presumed to be related 
to characteristics of the sampled populations. These parameters can range from 
few in number with simple interpretations to an uncountable number. Parameters 
can never be known with absolute certainty unless we sample the entire popula­
tion. Moreover, parameters may not have physical interpretations since, inevitably, 
models rarely are precisely true. Models are, we hope, useful approximations to 
some truth that can provide good predictions. Nonetheless, statistical inquiry has 
focused more on the estimation of parameters than on prediction.
As we already indicated, given a statistical model for the data, the Bayesian 
approach mandates an additional probability model for all unknown parameters in 
the data model. Our approach is to model this uncertainty about the parameters 
using scientific expert information, or what we will term knowledge-based informa­
tion. This information must be obtained independently of the data being analyzed. 
One way to guarantee that scientific input about model parameters is independent 
of the data is to acquire that information before the data have been collected. How­
ever this is often unrealistic except in situations such as a well-planned clinical trial. 
Our experience is that it is generally possible to obtain independent information 
from sources such as existing literature or colleagues of the scientists who collected 
the current data. We also discuss the formation of so-called “reference” or “flat” 
priors, when there is an absence of knowledge-based information. There is an art 
to the formation of probability distributions that incorporate available scientific 
knowledge, and the lack of it.

Scientific Data Analysis
3
1.2 
Examples
We now provide a glimpse into the types of data that we analyze later in the book 
to illustrate concepts and methods in Bayesian analysis. In later chapters, we will 
elaborate on some of these examples, and introduce additional examples as more 
advanced models are considered.
Example 1.1. Dr. Jeffrey Whittle designed and conducted a study of hypertension 
in members of U.S. veterans’ organizations such as the Veterans of Foreign Wars 
(VFW) and the American Legion. Blood pressure (systolic and diastolic), height 
and weight were measured at baseline, and after 6 and 12 months. Blood pressure 
is measured in millimeters of mercury (mm Hg), height in inches and weight in 
pounds. These measurements were a part of a randomized trial [353] to compare two 
different methods of educating and encouraging hypertensive veterans to achieve 
better control of this condition. One method recruited and trained leaders from the 
organizations’ posts (or local chapters) who then educated and encouraged their 
peers. The other method consisted of seminars given by health professionals at the 
posts. Data on the 405 participants are in the data file named VetBP.csv. We will 
refer to this example and the data set with the name VetBP.
Example 1.2. In a study of breast cancer survivors, Dr. Tina Yen and colleagues 
considered possible risk factors for lymphedema, a condition caused by a blockage 
of lymph vessels that drain fluids from body tissues. Lymphedema results in arm 
swelling, possibly leading to decreased functioning, skin breakdown and chronic 
infections if untreated. The reported article [356] uses data on women 65 to 89 
years of age collected from telephone surveys, Medicare claims, and state cancer 
registries. The measured variables include patient demographics such as age and 
race, tumor characteristics such as size and grade, and treatment variables such as 
type of surgery, number of lymph nodes examined and receipt of radiation, chemo 
and hormonal therapy. Data for 1,307 patients are included in the file named LE.csv. 
We will refer to this example and its data with the name LE.
Example 1.3. Mild traumatic brain injury (MTBI) is a term currently used by the 
scientific community studying what is commonly known as concussion. It is caused 
by a rapid linear or rotational acceleration of the head, typically caused by a blunt 
impact. McCrea [237] gives an excellent overview of the field. As an example, we 
will focus on the data that led to a threshold for predicting MTBI [363] and refer 
to this example and its data with the name MTBI.
Example 1.4. Patients brought to a trauma center after severe injuries often face 
heavy odds against short-term survival. Dr. Turner Osler, a trauma surgeon and 
former head of the Burn Unit at the University of New Mexico Trauma Center, was 
interested in studying which factors are associated with such odds. In particular, 
he targeted measurements routinely available from trauma center records: injury 

Bayesian Thinking in Biostatistics
severity score, revised trauma score, age, and whether the injury is blunt or pen­
etrating. Analysis resulting from Dr. Osler’s data is discussed in [24]. We refer to 
these data and this example with the name Trauma.
Example 1.5. Falls in the elderly are quite common and can have serious conse­
quences. Unintentional falls cause approximately 2 million injuries requiring care 
in emergency departments per year among Americans over the age of 65. Many 
falls lead to fractures and hospital admissions for trauma. Each year, 16,000 deaths 
are attributed to complications from such falls. For the state of Wisconsin, sum­
mary data of yearly emergency department visits are available at the website 
www.dhs.wisconsin.gov/wish. Accompanying analysis of a multi-county interven­
tion was led by Dr. Peter Layde and reported in [153] We will refer to this example 
and its data with the name Falls.
Example 1.6. To study biomechanical aspects of various severe brain injuries 
caused by motor vehicle crashes as well as penetrating objects, computer simula­
tion is a major tool. Such simulation requires good measurements of the material 
properties of the brain tissue, such as the coefficient value in a stress-strain rela­
tionship. For this purpose, animal tissue is harvested after sacrifice, stored and later 
used in laboratory measurements. Dr. Yoganandan’s laboratory conducted a study 
[362] to determine if the temperature at which the tissue is stored affects the co­
efficient measurement obtained. Stress and strain measurements were made at the 
same lab temperature on two groups of specimens of tissue, one group preserved 
ice-cold and the other at 37°C. The file named Brain.csv contains these data. We 
will refer to this example and its data with the name Brain.
Example 1.7. Dr. Ann Nattinger and her research team conducted a longitud­
inal survey of women over 65 who had incident breast cancer in 2003 [247]. There 
were four waves of this survey, following the patients for 5 years beyond surgery. 
The file BRCAsurvey.csv contains data on all 3,083 patients. The variables in the 
data set include survival information (five-year survival as a yes/no outcome, and 
time of death if applicable), age at surgery, type of surgery (breast conserving or 
mastectomy), some tumor characteristics such as size and grade, an index of comor­
bidity (the variable named nci), case volume measures for the patient’s surgeon 
and hospital, and others. We will refer to this example and its data with the name 
BRCAsurvey.
Example 1.8. This example illustrates the analysis of time-to-event data, data 
about how long it takes for something to happen. How long until a drug kicks 
in? How long does a person with a fatal disease survive? Bedrick, Christensen, 
and Johnson [25] consider data on 45 cows that naturally aborted their fetuses 
prematurely. It is of interest to dairy managers to determine whether cows infected 
with Ncospora caninum typically abort later than uninfected cows; 19 of the 45 
cows were infected. The times to abortion in the uninfected group are 60, 74, 37, 
45. 75. 40, 50. 50. 146. 70. 50. 84. 60. 149. 50. 90. 259. 40. 90, 101. 70. 90. 254. 130, 
80. and 40 days. For the infected group the times are 50, 130, 100. 130, 50. 140. 129, 
76. 138. 69. 70. 144. 70. 130. 70. 150. 251. 110. and 120 days. One way to answer

Scientific Data Analysis
the study question is to compute a summary statistic, such as the mean or median, 
for each group of cows and decide if the difference between these group-specific 
summary measures is reasonably close to zero. How close to zero one considers 
to be reasonably close to zero will determine the inference about the association 
between infection with Neospora caninum and a cow’s time to abortion. We will 
refer to this example as DairyCattle.
Example 1.9. Our next example is another illustration of time-to-event data. 
The Cancer and Leukemia Group В (CALGB) conducted a randomized clinical 
trial to compare the benefits of different dose intense regimens of a three-drug 
combination to treat non-metastatic breast cancer. Benefit in this study referred 
to living longer without the breast cancer recurring, sometimes called disease-free 
survival (DFS). The study, CALGB 8541 [59], randomized over 1,500 women to one 
of three treatment regimens.
The analysis of time-to-event data is often complicated by the fact that one 
does not get to see when the event occurs in all study participants. That is, some 
patients are alive and free of breast cancer at the time of analysis. If the recurrence 
occurs in these patients, it occurs in the future, but we do not know when in the 
future. This complicating factor is called censoring. Some people buy a refrigerator 
because their previous one broke. Those people know how long their refrigerator 
survived. But many people replace their refrigerator before it breaks, so the data 
on how long it would last are censored. All they know is that it was still running 
when it was replaced. Censoring is discussed more extensively in Chapter 11.
Since there are known patient or disease characteristics that may affect DFS be­
yond any treatment effect, the analyst may want to account for potential differences 
in the distribution of these prognostic characteristics across the treatment groups. 
Regression methods allow one to adjust for any differences in characteristics, and 
we will illustrate these methods in Chapter 12 in the context of the analysis of 
time-to-event data.
These breast cancer study data, contained in the file CALGB8541.csv, also 
appeared in [37]. We will refer to this example and its data with the name 
CALGB8541. CALGB also conducted other studies, some of which we will de­
scribe and use as examples in later chapters.
1.3 Essential Ingredients for Bayesian Analysis
In science, one carries out experiments to learn about the world around us. In this 
book we focus on biological sciences, but many, if not most, of the concepts we 
present apply more broadly. Scientists ask questions and design studies to obtain 
answers. Why do certain people get cancer? Why do some patients respond to 
drug A while other patients do not? Will intervention X reduce the risk of heart 
disease? When analyzing data from a study, it is conceptually useful to step back 
from the data at hand and consider the question (or questions) the study data are

6
Bayesian Thinking in Biostatistics
supposed to answer. Ask, for example, what was known about this question when 
the investigators designed the study, and why the study’s investigators designed 
the study as they did. What was the state of knowledge prior to the analysis of 
these data? Thinking about the state of knowledge and the goals of the study helps 
us understand the ingredients of Bayesian data analysis and how the data analyst 
combines them.
Consider the VetBP blood pressure study, for example. The study planned to 
recruit members from veterans’ organizations and measure their systolic and dia­
stolic blood pressure at recruitment. Although the full study had many other goals, 
let us focus only on this baseline measurement for the moment. As a simple goal, 
consider quantifying the mean and variation of blood pressure in the population 
from which the study subjects were selected.
Here then is a list of ingredients we need, described in a little more detail in 
this section, and elaborated throughout the book:
• 
the observable measurements and the process of collecting these observables;
• 
the unobservables or unknowns of scientific interest;
• 
the probability mechanism or model that will generate the data;
• 
the state of pre-data or outside-data knowledge about the unknowns;
• 
the mathematical formulation (or a learning mechanism) by which the data 
will add to this knowledge;
• 
the resulting post-data or data-informed knowledge.
1.3.1 Observables and Design for Their Collection
It is good to begin with the definition of measurements that are to be made during 
data collection. In the VetBP study the centrad measurement was the blood pres­
sure, both systolic (SBP) and diastolic (DBP) in millimeters of mercury. It is also 
important to consider the design for subject recruitment for the study. Veterans’ 
organizations in the Milwaukee area were contacted with participation requests and 
visited upon invitation, subsequently enrolling individuals with their written con­
sent. Here the observables are blood pressure measurements on individuals from 
the population of veterans known to these organizations in the area and accessible 
via these organizations.
1.3.2 Unknowns of Scientific Interest
In scientific inquiry, study objectives often focus on learning about interesting un­
knowns such as the probability of surviving at least 5 years after a cancer diagnosis 
(Example 1.9. CALGB8541): the effect of treatment on the risk of lymphedema 
among breast cancer survivors (Example 1.2. LE): or the effect of injury severity, 
revised trauma score, age. and type of injury on the probability of death while being 
treated for trauma in an emergency department (Example 1.4. Trauma). Typical

Scientific Data Analysis
unknowns of scientific interest are summary measures, such as the mean, median, 
or standard deviation, of the population from which the individuals in the study 
were recruited.
A typical statistical model may also include unknowns that, by themselves, are 
not of particular scientific interest but that nonetheless are useful in specifying a 
model that fits the data well. It will often be the case that some functions of model 
parameters are of scientific interest. This will be a recurring theme throughout the 
book. Knowledge about these unknowns is updated by using the collected data.
Several quantities relating to the veteran population were of interest to Dr. 
Whittle, the study’s principal investigator (Example 1.1, VetBP). These quantities 
include the population mean SBP and DBP, standard deviations of these in the 
population, SBP and DBP ranges that describe the middle 50% of the population 
and, most importantly, the percentage of the veteran population with SBP greater 
than 140 mm Hg or DBP greater than 90 mm Hg. Of even greater interest is the 
effect of treatment on reducing both types of BP.
1.3.3 Probability Models and Model Parameters
We begin with the simplest models that characterize the generation of a study’s 
data; we introduce numerous additional models in subsequent chapters.
By regarding participants in Dr. Whittle’s study as a random sample from the 
population, we can consider blood pressure (BP) measurements on individuals to be 
interchangeable, with no characteristics distinguishing one subject from the next. 
The model assumes a distributional form for the BP measurements, starting with 
the assumption of a normal distribution, which must be checked. We may also 
consider the possibility of a log-normal distribution, namely, that the logarithms of 
the BP measurements are normally distributed. We would want to compare normal 
and log-normal models to see which is preferable. Model parameters are typically 
means and variances of familiar or interpretable measurements; in the case of a 
log-normal model, it is not the mean on the log scale that is of primary scientific 
interest, but rather the mean or median on the scale of the original data measured 
in millimeters of mercury.
1.3.4 External Knowledge (or Prior) Distribution
Bayesian inference requires one to quantify one’s current state of knowledge about 
the unknowns prior to (or apart from) collecting the current data. For illustration, 
consider the case where a study is to be performed to assess the effect of taking 
statins in order to lower BP. On the web we found a reference to a meta-analysis of 
a number of studies that examined this question [310]. We only focus on one piece of 
their study, which involved 12 studies of patients whose SBP at the beginning of the 
study exceeded 130 mm Hg. Patients were randomly assigned to either a placebo or 
to a particular statin regimen, and estimates of the differences in average SBP were 
obtained for each study. The (overall, meta-analysis-based) estimated reduction 
in average SBP was 4 mm Hg with a 95% confidence interval for the difference

8
Bayesian Thinking in Biostatistics
in means of (—5.8, —2.2). Here we consider a hypothetical situation where a new 
study is to be performed with a new type of statin that is cheaper than those used 
in the above studies, and which is hoped (or expected) to improve on the reduction 
in mean SBP.
The actual improvement is of course unknown. There are approaches that can 
be taken to specify a prior distribution on the unknown difference in means. A 
conservative approach would virtually ignore the above information and place a 
uniform distribution on a very wide interval, say (-35,35), to reflect prior uncer­
tainty for the difference in average SBP. In this case, we would be saying that we 
were 100% certain that the reduction could be no more than 35 mm Hg and that it 
would be possible that new average difference could be an increase in average SBP 
up to 35 mm Hg. A somewhat less conservative approach would place a N(Q, 152) 
distribution on the difference in mean SBPs. The normal prior would convey that 
we were about 97.5% certain that the improvement would be at most 30 and simi­
larly that there was a 97.5% chance that the new statin could increase average SBP 
up to 30 mm Hg. The most likely improvements would be closer to zero than to 30 
and similarly if the new statin worked against lowering SBP.
These two priors would be considered to be quite diffuse relative to the informa­
tion from the above study. A physician with lots of experience with statins may 
pick a less diffuse prior that also allows for less probability that the statin would 
increase mean SBP relative to the placebo. For example, they may have good rea­
son to believe that it is impossible to drop average SBP by more than 10 mm Hg 
and that, if the new statin did increase mean SBP relative to the placebo, it would 
be unlikely to be more than 3 mm Hg. In this case a uniform prior on the interval 
(-10,5) might be sensible, or a comparable N(-l,32) prior.
Alternatively, the same physician may prefer to take account of the above in­
formation from the meta-analysis. Note that the width of the confidence interval 
is only 3.6. So we could imagine a prior that was centered on —4 and that still 
allowed for the new statin to be worse than placebo, say a uniform distribution on 
(—10,2), or a Af(—4,32) distribution, to reflect substantive prior information from 
these studies.
In addition to the above possible specifications, we would need a prior specifica­
tion for the average SBP among individuals who were taking the placebo. Focusing 
on mean SBP, it would be very safe to say that the mean SBP in this population 
is likely greater than 120 mm Hg and less than 200 mm Hg, keeping in mind that 
the population under study consists of individuals with SBP > 130. We emphasize 
that this range is for the possible values of the mean and not for individual blood 
pivssure values in the population. We could represent the pre-data knowledge about 
the unknown population mean for this population with a ЛГ(160,202) distribution 
or a uniform distribution on (120,200). The range of likely values for the mean SBP 
is expected to be different in a different type of patient population.
In Chapter 6. we address in more detail how to turn a range of likely values into 
a distribution. We also consider the possibility of not having external information 
in Chapter 6.
The rest of the book expands on these essential concepts of Bayesian inference

Scientific Data Analysis 
9
and presents the mathematical tools needed for Bayesian analysis in biostatistics, 
such as probability models for data and knowledge distributions for unknowns.
1.4 Recap and Readings
In this chapter, we addressed general notions of statistical and scientific inference, 
putting in perspective how Bayesian analysis weaves these together. We then gave 
a brief listing of what ingredients are essential for Bayesian analysis. We also pre­
sented a few motivating examples of statistics at work in the biomedical sciences. 
Many other excellent textbooks present Bayesian thinking as applied to data ana­
lysis. Examples include the books by Carlin and Louis [63], Gelman et al. [133], 
Christensen et al. [79], Robert [271] and Hoff [166].
We did not discuss one topic often presented early by many authors: the so- 
called subjectivity of Bayesian methods that requires a prior distribution. Chapter 
6 covers some ground in this area, while an accessible discussion can be found in a 
pair of articles by Berger and Goldstein [30, 146].


Chapter 2
Fundamentals I: Bayes’ Theorem, 
Knowledge Distributions, Prediction
In this chapter we introduce the principles and basic tools of Bayesian statistical 
inference. In particular, we consider an approach to statistical inference that leads 
to making probability statements about unknown quantities of interest or events, 
for example the occurrence of a disease such as cancer (yes/no) in a particular 
patient, or the event of surviving at least 5 years after diagnosis with stage 3 breast 
cancer.
We begin with an elementary form of Bayes’ theorem. Bayes’ theorem follows 
from the mathematical definition of conditional probability, which we also discuss. 
This elementary form of Bayes’ theorem describes how to handle unknown quant­
ities that are dichotomous (two categories) or polychotomous (multiple categories). 
For example, we may sample individuals and test them for an infection, in which 
case there is a simple yes/no or 1/0 dichotomous outcome, or we may observe in 
addition, for individuals who are infected, whether they are in an early or late stage 
of infection, in which case the outcome is trichotomous. We provide illustrations of 
basic probability concepts that illustrate these probability rules before proceeding 
to discuss probability models for unknowns of interest, for example, the propor­
tion of HIV infections among blood donors or the proportion of a population with 
uncontrolled hypertension.
Next is a discussion by example of how to transform scientific knowledge about 
population characteristics of interest into probability models that describe and char­
acterize that knowledge. Then we introduce and discuss the concepts of continuous 
and discrete random variables (RVs). Random variables are numerical outcomes 
associated with studies or events that are not precisely predictable. A continuous 
outcome in theory has a continuum of possible values, while a discrete outcome has 
a finite or countably infinite number of possible values. An example of the former 
case might involve a study where systolic blood pressure (SBP) values were collected 
from a population with an interest in the reduction in average SBP when using a 
new treatment regimen compared with a standard treatment. In the latter case, we 
may be observing cancer counts over time with an ultimate goal of studying and 
comparing cancer rates under differing circumstances. A binary response coded as 
0/1 is a special case of a discrete RV.
A more general Bayes’ theorem is presented in conjunction with the concept of 
a likelihood function. The likelihood function encapsulates the information in the 
data while scientific knowledge about population characteristics is encapsulated in 
the form of a so-called prior probability distribution. These are combined using
11

12
Bayesian Thinking in Biostatistics
Bayes’ theorem to produce the ultimate Bayesian inference, the so-called posterior 
distribution. It is then shown how the posterior distribution is used to make specific 
statistical inferences for objects of interest.
The chapter concludes with an introduction to the important problem of pre­
diction and an introduction to Bayesian computation.
2.1 Elementary Bayes’ Theorem: Simple but Fundamental Prob­
ability Computations
The mathematical basis for combining data and external knowledge to arrive at an 
updated state of knowledge is provided by Bayes’ theorem. Our initial discussion 
below is somewhat removed from Dr. Whittle’s BP study in order to introduce the 
ideas in simpler situations. The theorem addresses conditional probabilities, which 
we introduce first.
A systematic development of probability is an extensive undertaking. Here we 
take the pragmatic view that the reader has had previous exposure to probability 
and views it in terms of long-run relative frequencies (e.g., the home team wins 
54% of professional baseball games) or a degree of certainty (e.g., the probability 
of precipitation in my city tomorrow is 80%).
Regardless, it is important to recognize that the probability of an event can 
depend on knowledge of whether or not another related event has occurred. 
For example, suppose we roll two six-sided dice sequentially. We focus on the 
probability that the sum is 6. With 36 equally likely possible outcomes, and 5 
of these—(1,5), (2,4), (3,3), (4,2), (5,1)—resulting in a sum of 6, we can write 
P(sum equals 6) = 5/36.
Now suppose we are told that the first die shows a number less than 4. So we 
know that one of the 18 possible outcomes, {(j, 1), (j, 2), (j, 3), (j, 4), (j, 5), (j, 6) : 
j = 1,2,3}, occurred. How does this affect the 5/36 probability? We see that there 
are three outcomes that result in a 6 that are also outcomes that result in the first
toss being less than 4. We are now seeking the conditional probability that the sum
equals 6 given the first die shows a number less than 4. Intuitively, this should be
3/18 = 1/6. The definition of the conditional probability of A given that an event
В has occurred is
P(A | B) = P(AnB) 
P(B)
(2-1)
whore П means “and.” and P(B) must be greater than zero. One can explain this 
formula as meaning the proportion of the probability of В that is associated with A. 
For the two events above. .4 П В is represented by the outcomes (1,5), (2,4), (3,3) 
and thus has probability 3/36. and the conditioning event В has probability 18/36 
= 1/2. Thus the desired conditional probability is (3/36)/( 18/36) = 1/6. Knowing 
В increased slightly the probability of A from 5/36 to 1/6 = 6/36. Knowledge of

Fundamentals I: Bayes’ Theorem. Knowledge Disttibutions. Prediction 
13
some other events can have a dramatic impact. Consider, for example, C = "first 
die shows a number greater than 5.” Then P(A | C) = 0.
Observe that A and В are not generally interchangeable in that P(A | B) 
may not equal P(B | A). Indeed, a moment’s reflection reveals that these two 
probabilities usually have entirely different meanings. Yet, this is a common point 
of confusion. For example, nearly 46% of smokers are women but only about 18% 
of women smoke. An overwhelming majority of race car drivers are men but only 
a small fraction of men are race car drivers! And in our dice throwing example, 
P(B | A) = 3/5 while P(A | B) = 1/6.
Bayes’ theorem provides the link that enables proper reversal of conditioning. 
In its simplest form, we have the following version for two events.
Bayes’ Theorem for Two Events. Let A and В be two events with P(A) > 0. 
Then
. P(A | B)P(B)___________ P(A|B)P(B)
' 1 ’ P(A) P(A | B)P(B) + P(A | B')P(B') 
' ’
where the superscript c stands for complement (i.e., “not”).
The right-hand side of this equation follows from the definition of conditional prob­
ability as a ratio, and the denominator follows from the law of total probability (see 
Appendix A). Notice that this reversal of conditioning requires P(B) and P(A | Bc) 
in addition to P(A | B).
Example 2.1 
. Diagnostic testing for diseases is seldom perfect. It is thus useful 
to know the probability that an individual has the disease after the testing result 
is available. Experiments evaluating a new diagnostic test typically enroll a fixed 
number of individuals with the disease and a fixed number without the disease 
and apply the diagnostic test to both groups. These experiments tell us directly 
what the chance of a positive (or negative) test result is given that the person has 
the disease (or does not have the disease). We want to know, however, what the 
probability is that a person with a positive test result has the disease.
Let T+ and T— denote the events that a person tests positive and negative, 
respectively. Similarly define D+ and D— as true disease status. For a person testing 
positive, we are interested in P(D+ | T+). To calculate this we need: (i) P(D+), the 
unconditional or marginal probability of disease in the population (or prevalence, 
i.e., the probability of disease without regard to test outcome); (ii) P(T+ | D+), the 
probability that an individual with the disease tests positive; and (iii) P(T+ | D-), 
the probability that an individual without the disease tests positive. In Chapter 15 
we define these probabilities in more detail. Here we point out that Bayes’ theorem 
allows us to carry out the necessary calculations if appropriate probabilities are 
available.
Example 2.2 
. Nattinger et al. [246] constructed an algorithm that inspects billing 
records of patients in the Medicare system in the U.S. to determine incident cases 
of breast cancer. By using records of patients with known incident breast cancer as

14
Bayesian Thinking in Biostatistics
well as cancer-free controls (as determined by the carefully constructed and highly 
regarded SEER-Medicare linked registry [289]), they estimated that the algorithm 
detects a true case with probability 0.80 and falsely declares a non-case as a case of 
incident breast cancer with probability 0.0005. Taking the overall cancer incidence 
in this population to be 0.005, we calculate the chance that an algorithm-declared 
case is indeed an incident breast cancer case. Using the notation A+ for algorithm 
positive, A— for algorithm negative, D+ for true case, D— for true non-case, we 
compute P(D+ | A+). The form of Bayes’ theorem in equation (2.2) gives
P(D+ | A+)
P(A+ | £>+)P(£>+)
Р(Л+ | £>+)P(£>+) + P(A+ | D-)P(D-) 
0.80 x 0.005
0.80 x 0.005 + 0.0005 x (1 - 0.005)
0.004 
0.004 
.
0.004 + 0.0004975 ” 0.0045030 " ’ 9’
where = means “is approximately equal to.”
We now introduce a second, and more commonly stated, form of Bayes’ the­
orem. This is an extension of the above form, replacing the pair of complementary 
events В and Bc by a general partition consisting of mutually exclusive events 
Bi,..., Bk that constitute all possibilities. In other words, we mean a collection of 
non-overlapping (or disjoint or mutually exclusive) events that cover all possibilities 
(i.e., the entire event space). In this case, again using the definition of conditional 
probability and the law of total probability, we have the following result.
Bayes’ Theorem for an Event-Space Partition. Let Bi,..., Bk be a finite 
partition of an event space Q, that is, Bi U ■ ■ • U Bk = Q and Bi П Bj = ф, 1 < i < 
j < k. Let A be an event in Q with P(A) > 0. Then
P(B\A}~ 
P(A\Bj)P(Bi)
( l| } 
P(A|B1)P(P1) + --- + P(A|BJfc)P(Bfc)’ 
( ‘ }
Notice that this equation allows us to compute the conditioned probabilities of all к 
events in the partition, all conditioned on the same event A. The formula requires 
the unconditional probabilities of all partitioning events. In addition, we need the 
conditional probability of A given each partitioning event. Although at first sight 
this appears to be more demanding than equation (2.2), it turns out that working 
with general partitions gives more freedom in terms of model specification. The 
theorem will be further generalized for this purpose, ultimately conditioning on the 
data from a scientific experiment, analogous to conditioning on the event A in this 
simpler setting. This will be made precise shortly.
Example 2.3 
. Returning to Example 2.2. Nattinger et al. [246] observe that the

Fundamentals I: Bayes’ Theorem. Knowledge Distributions. Prediction
15
algorithm’s performance varies for the following four groups of the target population 
of women enrolled in Medicare:
Di+ women with first breast cancer in the incidence year:
£)2+ : women with prevalent breast cancer (i.e., incident in a prior year):
D3+ : women with incident or prevalent cancer other than breast cancer;
D- : women who have never had any cancer.
Observe that the four events constitute a partition of the set of possible outcomes. 
Recall that 4+ denotes that the algorithm indicates incident cancer. So now we are 
interested to know which cancer category is more likely when the algorithm detects 
cancer, namely, we calculate Р(£)$+ | 4+) for a randomly chosen woman from the 
population. Notice, however, that D+ from the previous example and D^ + are the 
same event.
Based on data from the SEER registries [288], the authors give the following 
unconditional probabilities for the partitioning events: P(£>i+) = 0.005, P(D2+) = 
0.03, Р(Рз+) = 0.07, P(D-) = 0.895. They also quantify the performance of the 
algorithm as P(4+ | Di+) = 0.80, P(A+ | D2+) = 0.0065, P(A+ | D3+) = 
0.0007, P(A+ I D-) = 0.0003. This leads to
P(4+|D1+)P(D1+)
Р(£>1+ 1 Л+) P(4+ I Di+)P(Di+) + ■■■ + P(A+ I D-)P(D-) 
0.80 x 0.005
“ 0.80 x 0.005 + 0.0065 x 0.03 + 0.0007 x 0.07 + 0.0003 x 0.895 
0.0040055
“ 0.0040055 + 0.0001950 + 0.0000490 + 0.0002685 
0.0040055 
0.004518 
’ ‘
Similarly, P(P2+ | 4+) = 0.0432, P(D3+ I 4+) = 0.0108, P(D- | 4+) = 
1-0.8866-0.0432-0.0108 = 0.0594. So the algorithm is clearly most likely to detect 
incident breast cancer, as we already knew since P(D+ | 4+) = P(£>i+ | 4+).
Finally, we observe that P(D- | 4-) = 0.895 (1 - 0.003)/(l - 0.004518) = 
0.8964 = P(D—). So we have an example where the events D- and 4- are, for 
practical purposes, independent. Knowing that the algorithm says “no cancer” for a 
particular individual gives us very little additional information beyond the “prior” 
belief that there is no cancer.
Data-Informed Knowledge (or Posterior) Distribution. To illustrate how 
information from data can update our knowledge about unknowns, we continue to 
look at Example 2.3. If a Medicare-enrolled woman over 65 is chosen at random, 
our (pre-data) knowledge about her breast cancer status, (Di+, D2+, D3+, D-), 
is represented by a probability distribution with respective event probabilities 
(0.005,0.03,0.07,0.895).
Next consider the information contained in the billing records of the randomly 
chosen woman. If it results in the algorithm declaring the woman positive or neg­
ative for incident breast cancer, calculations like those in Example 2.3 result in

16 
Bayesian Thinking in Biostatistics
new, data-informed knowledge about her breast cancer status. We summarize this 
in Table 2.1.
TABLE 2.1: Knowledge distributions for breast cancer status
Status
Conditioning (billing record) information
P(D.)
P(D. | A+)
P(D. | A—)
£>i+: Incident 
breast cancer
0.0050
0.8866
0.0010
D2+'. Prevalent 
breast cancer
0.0300
0.0432
0.0300
£>3+ : Incident or 
prevalent other cancer
0.0700
0.0108
0.0703
D-: Cancer-free
0.895
0.0594
0.8987
Each column shows the knowledge distribution under different information­
based scenarios about the randomly chosen woman. Most of the probabilities of 
incident breast cancer, and of being cancer-free, change dramatically with informa­
tion. Of course, the algorithm was constructed precisely to achieve this ability to 
respond to different information about the patient.
2.2 Science and Knowledge about Uncertain Quantities
Fundamentally, the field of statistics is about using probability models to analyze 
data in the presence of variation or uncertainty. There are two major philosophical 
positions about the use of probability models. One is that probabilities are deter­
mined by the outside world. The other is that probabilities exist in people’s heads. 
Historically, probability theory was developed to explain games of chance. For ex­
ample, the physical structures involved in rolling dice, spinning roulette wheels, 
and dealing well-shuffled decks of cards suggest obvious probabilities for various 
outcomes.
The notion of probability as a belief is more subtle. For example, suppose that 
you arc in my presence when I flip a coin. Prior to flipping the coin, the phys­
ical mechanism involved suggests probabilities of 0.5 for each of the outcomes, 
heads and tails. But now I have flipped the coin, looked at the result, but not 
told you the outcome. As long as you believe I am not cheating you, you would 
naturally continue to describe the probabilities for heads and tails as 0.5. But this 
probability is no longer the probability associated with the physical mechanism 
involved, because you and I have different probabilities. I know whether the coin 
is heads or tails, and your probability is simply describing your personal state of 
knowledge.
Bayesian statistics starts by using (knowledge-based or prior) probabilities to de-

Fundamentals I: Bayes’ Theorem. Knowledge Distributions. Prediction
17
scribe current states of knowledge. It then incorporates information through data 
collection. Updating the knowledge given the data, according to the rules of prob­
ability calculus, results in new (posterior) probabilities to describe your state of 
knowledge after combining the prior information with the data.
In Bayesian statistics, uncertainty and information are incorporated through the 
use of probability distributions, and conclusions obey the laws of probability theory.
Some form of prior information is always available. If our inferential goal is to 
estimate the mean SBP of American men, we all know that this average cannot 
exceed 200 mm Hg. The probability of death during trauma surgery for a 20-year- 
old with a small injury and good vital signs is not close to 1. Very conservatively, 
the probability of being transfused with HIV infected blood in the U.S. cannot 
possibly be above 5%. At a minimum, a prior distribution for a parameter 6 can 
easily exclude values that are simply unrealistic, and it seems silly to ignore such 
information. Our goal is not to find the “perfect” knowledge distribution but rather 
to incorporate salient features of available scientific knowledge into the data ana­
lysis. As such, we need to examine whether other reasonable prior distributions lead 
to substantively similar posterior conclusions.
Example 2.4 
. Gastwirth, Johnson, and Reneau [122] studied the prevalence of 
HIV infection in the blood supply in the U.S. In the medical literature, they found 
an estimate of the proportion of infected blood donors at that time to be 0.0004. 
They used this information to construct a beta distribution (Be(a, b)) that had a 
mode of 0.0004. Their goal was to estimate the actual proportion of infected blood 
units after screening for HIV that would be available for transfusion; this proportion 
was expected to be much smaller than 0.0004 since test accuracies were reasonably 
high. Here we imagine the simpler goal of estimating prevalence of HIV among 
blood donors.
We suppose that an expert might posit a 95th percentile of 0.05. That is, the 
expert would be 95% certain that the prevalence among U.S. donors at that time, 
say в, was less than 0.05. The expert’s best estimate of that prevalence is 0.0004. 
One can approximately characterize this uncertainty with a Be(l,59) distribution, 
using a method that we describe later. We note that a one-sided 95% probability 
interval is (0,0.05), a two-sided 90% interval is (0.00087,0.05), the median is 0.012, 
and the mean is 0.017. Since the prior distribution is so skewed, we have very differ­
ent values for the mean, median, and mode. The main purpose here was to provide 
a distribution that covers a plausible range of values. A somewhat reasonable al­
ternative to this choice might be a 17(0,0.1) distribution, if the expert was 100% 
certain that the proportion could not be above 0.1, a likely possibility given that 
their best estimate was 0.0004.
As we proceed through the book, we will perform what are called sensitivity 
analyses. For these analyses, we will start with an expert-knowledge-based prior 
and consider plausible alternatives to that prior. Applying the inferential tools we 
discuss throughout the book, we will obtain posterior inferences based on each 
prior (expert and alternative) to see what impact the choice of prior has on the

18
Bayesian Thinking in Biostatistics
corresponding inferences. The ideal situation is when there is minimal impact. When 
inferences are sensitive to the choice of prior, this must be reported in any analysis.
Example 2.5 
. A team of researchers plans to collect data to ascertain whether 
dieting or exercise is preferable for weight loss in men. We assume that men are 
randomly assigned at the beginning of the study to be either in the dieting group 
or the exercise group, and that all participants agree to only use the protocol 
presented to them by the scientists. Also assume that the data (i.e., weight loss) will 
be reasonably approximated for each group by normal distributions with different 
means. Let Д be the difference in mean weight loss for the dieting group minus 
that for the exercise group.
Suppose that, based on real data from a previous experiment, the dieting group 
had lost more weight on average than the exercise group, and also suppose that the 
scientists involved with the current study are interested to see if the previous study 
results will hold up in their own study. If an estimated effect of Д = 5 had been 
presented in the literature with a 95% interval of (2,8), that information can be used 
as the basis for specifying a prior distribution for the current study. It will generally 
be the case that one would specify a prior distribution that expresses additional 
uncertainty beyond that conveyed by an analysis of previous data. Alternatively, 
physicians might be asked to simply provide their expert best guess for 0 and to 
specify an interval in which they are, say, at least 95% certain that Д would lie.
In practice, we typically obtain expert information or knowledge about some 
characteristics in the population under study, obtaining as much information as is 
reasonable and convenient to elicit. We then incorporate this information into a 
suitable class of distributions in ways that will be described throughout the book. 
Such information must be collected independently of the current data.
Describing uncertainty with a prior distribution is a collaborative effort between 
scientist and statistician and should ultimately involve validation by the expert to 
be certain that the selected knowledge distribution is a reasonable approximation to 
the expert’s actual information.
Example 2.6 
. Consider the weight loss study above with 95% interval for Д of 
(2,8). If we use a normal distribution to model scientific information about Д, 
say Д ~ N(a, b2), then the 95% interval around the mean must have endpoints of 
about a ± 2b. We set the best guess for Д to be До = 5, so a = 5. With a + 2b = 8, 
we obtain b = 1.5. The size of b is directly related to the width of the specified 
95% interval. Note that this technique used the fact that (2,8) is centered around 
До = 5. If we wanted to add uncertainty, say by considering the wider interval 
(1.9) as a 95% interval, then we would get b = 2 since 5 4- 4 = 9 is two standard 
deviations above the mean.
As previously suggested, it is often difficult for experts to provide direct in­
formation on the parameters of statistical models because they are not comfortable 
with the parameterization. In such cases, we elicit information about quantities 
that are more familiar to the expert and use that information to induce a prior on

Fundamentals I: Bayes’ Theorem. Knowledge Distributions. Prediction 
19
the model parameters. Typically, experimenters would have some ideas about mean 
weight loss under specified protocols and could give a best guess and. perhaps, a 
wide probability interval for it. When considering a difference in means as above, 
the choice of 0 for the difference in means will often be a reasonable choice, unless 
one has good reason to expect that one treatment is superior to another. On the 
other hand, it is more difficult for experts to think directly about likely values for 
a standard deviation.
To address this question, we propose the following. Suppose that weight loss 
for a randomly selected individual under a particular treatment can be modeled 
with a TV(/z,<72) distribution. How would we place a prior on <r? Since a is not easy 
to think about, we could ask questions about the lower quartile of weight losses 
among the population of men that would use the given protocol for weight loss. 
This number has 75% of the values above it and 25% below. The lower quartile of 
a normal distribution is p.- 0.675a, so if our expert’s experience suggested that the 
lower quartile was about —5, and that ц was about /zo = — 2, then a natural guess 
for a is сто = (—2 + 5)/0.675 = 4.44. For a2, we could pick a distribution that had 
a median or mode equal to the best guess, 4.442, and which was suitably diffuse. 
We discuss both diffuse and informative priors for a in some detail later on.
Although parameters are often mere conveniences, frequently a parameter 0 has 
some basis in physical reality. This was the case for our parameter Д in the above 
example. Rather than describing where 0 exactly is, the prior describes beliefs about 
where 0 is. The probabilities specified by the physicians are their beliefs about 0. 
Different physicians, or groups of physicians, will have different knowledge bases 
and, therefore, different probabilities for в. If they analyze the same data, they will 
continue to have different beliefs about 0 until sufficient data are collected so that 
they reach a consensus. This consensus should occur unless one or more of them 
is unrealistically dogmatic. For example, when considering extrasensory perception 
(ESP), some people refuse to place any positive probability on the phenomenon’s 
existence, so no amount of data will change their beliefs [337]. A nice feature of 
Bayesian statistics is that scientist-statistician collaborations require that precon­
ceptions be openly asserted. So a prior of IO-40 that ESP exists pretty much says 
that there is no need to collect data.
2.3 More on Bayes’ Theorem: Inference for Model Unknowns
In Section 2.1 we discussed knowledge-based probabilities for events followed by 
their updated versions, conditioned on a potentially informative event (data). We 
also discussed in Section 2.2 some issues related to specifying knowledge-based in­
formation for model parameters that are on a continuum. In biostatistics it is most 
common to observe numerical data in the form of variables that are either contin­
uous or discrete. For example, for the VetBP data (Example 1.1) the information 
is a collection of blood pressure values that are treated as continuous outcomes.

20
Bayesian Thinking in Biostatistics
On the other hand, for the LE data of Example 1.2, the outcome is discrete, since 
occurrence of lymphedema is coded as a 1 and non-occurrence is coded as a 0. This 
leads us to a discussion of random variables.
Random Variable. A random variable (RV), say X, is a numerical outcome as­
sociated with a randomly selected person or experiment. We use capital letters, 
generally towards the end of the Latin alphabet, to represent RVs. When X is 
observed, we denote the actual outcome by the corresponding lower-case letter, 
namely X = x. If X is SBP and is observed to be 120, we say X = 120 was ob­
served, but the generic x is a useful notation. Not all RVs are observable, however.
Population parameters are fundamental to all of statistical modeling. Random 
effects also play an important role in statistical modeling, as we shall see later in the 
book (Chapter 14). Neither is observable, even after data collection. Such unknow­
able quantities are treated as RVs in Bayesian analysis, and thus the statistician 
specifies probability distributions for them, since all uncertainty is to be modeled 
with probability. In Example 2.3, a knowledge-based distribution was placed on the 
different breast cancer event probabilities that were then modified when conditioned 
on A+ or A—. Here again, distributions for model parameters (and random effects 
variables) are modified when distributions are conditioned on observed data. Typ­
ically, we use lower-case Greek letters(e.g., p,a, A,0) for these unobservable quant­
ities. Corresponding upper-case Greek letters denote the space of possible values 
taken by the unknowable quantities. For example, 0 is the set of all possible values 
for 0.
In specifying a model for data to be collected, observable and unobservable 
quantities can be either discrete or continuous. Probability mass functions (pmfs) 
are used as descriptors for the behavior of discrete random variables, and probability 
density functions (pdfs) are used for continuous random variables (see Appendix 
A). In this book, we often blur the distinction and simply call these descriptors 
probability density functions for the random variables, regardless of whether con­
tinuous or discrete. We use the letter p to denote density functions, and we often 
write that “the distribution of X is p(-)’: or equivalently “X ~p(-).”
We denote conditional distributions (see Appendix A) in a way that is similar to 
conditional probabilities for events, namely, by using a vertical bar. For example, 
X | 0 is read as “X given 0" and represents the random variable X when the 
conditioning variable takes the particular value 0. This notation will be used in the 
specification of a probability model for the data, X, given the model parameter(s) 
0. For example, we could say X | 0 ~ p(- | 0) where p(- | 0) is the conditional 
density for the random variable X.
He write p(.r | 0) and X | 0 ~ p(- | 0) interchangeably. When we think of x 
as observed data on X. we will be very much interested in the (posterior) density 
p(0 | .r). We present these notational conventions in Table 2.2.
With this notation in hand, we return to Bayes' theorem, now stated for random 
variables. This takes a similar form to that for events (as in Section 2.1), with the

Fundamentals I: Dayes’ Theorem. Knowledge Distributions. Prediction
TABLE 2.2: Notational conventions
21
Quantity_________
Letter/symbol
Examples
Observable RVs 
(will become data)
UC Latin, 
end of alphabet
X. Y. Z
Observed data
LC Latin, 
end of alphabet
x, y, z
Unknowable RV 
(parameter)
LC Greek
p, <r, A, 8
Parameter Space 
of Unknowable RV
UC Greek
A, 0
pmf or pdf
P(-)
p(x)
“Distributed as” or 
“has distribution”
x~p(.), y~p(.)
Conditional RV
Vertical bar |
Х|У = у 
0 1 у ■ К I g
Conditional 
distribution
P(- 1 ')
p(p | x,8), p{8 | y)
sum in the denominator replaced by an integral. Consider two random variables: an 
observable Y and an unobservable в. Let p(0) be the density for 8 representing the 
external (or prior) knowledge about 6. A model for the observable specifies p(y | 0), 
a conditional probability density. We then have the following result.
Bayes’ Theorem for Two Random Variables. Let Y and 8 be two random
variables. Then
P(0 I У) =
p(y I ^)Р(^) 
$p(y | 8)p(8)d8'
8eQ,
(2-4)
where the integral is over 0, the entire space for 8. The equality follows from the 
definition of a conditional density, and the denominator is simply the marginal 
density for Y, p(y), using the law of total probability.
To illustrate, suppose Y is the (binary) indicator1 of heads on a coin flip and 8 
is the unknown probability of heads. Then the distribution of Y | 8 is Bernoulli 
with parameter 8, that is, p(y | 6) = 8y(l — 8)^~v^ (see Appendix B). We say 
that Y | 8 ~ Ber(0). We might consider taking the prior distribution of 8 to be 
uniform on (0,1), since 8 is constrained to lie between 0 and 1. That is, we assign 
equal probability across the range of values 8 may take. We can write p(ff) = 1 for 
8 € (0,1), and apply Bayes’ theorem to get
P(0 I y) =
8У(1-еу-у 
^ey(i-ey-yde'
lrThe indicator of an event equals 1 if the event happens, 0 if it does not.

22
Bayesian Thinking in Biostatistics
If the coin shows heads, we have the update
while tails results in
p(0\y = 1) = fo0dd
p(0 | у = 0) =
1-0
= 2(1-0).
Figure 2.1 shows how pre-data knowledge about the probability of heads is updated 
by data. Although the Bayes’ theorem above is stated for two random variables, it is
FIGURE 2.1: Bayesian knowledge updates after coin flip data.
quite general in that у and 0 can be made up of many components or even collections 
of mathematical objects. Of course, specifying the density requires much care and 
can be quite intricate, depending on the structure of these objects. In general, it is 
useful to think of у as (possibly multivariate) data and 0 as (a vector of) parameters 
(or unobservables). We can then state our next result.
Bayes’ Theorem for Modeled Data. From here on, we allow for the generic 
parameter or unobservables в € © to be a vector of. say, r elements. (0i,... ,0r).

Fundamentals I: Bayes' Theorem. Knowledge Distributions, Prediction 
23
Most statistical models have more than one parameter, but when r = 1, this reduces 
to the single-parameter case. Bayesian inference for the parameter vector. Q. is just 
the joint posterior distribution. The joint posterior pdf is
| 
= Р(У I g) PW 
,,
₽( 11 fep(vl«)p(e)<ie 
(,)
where the integral is over the entire r-dimensional space, 0, for the unobservables.
Using Bayes’ Theorem for Inference. Equation (2.5) provides the density that 
contains post-data knowledge about unobservables or parameters. We now describe 
how it can be used explicitly for inference.
With multiple parameters, such as в = (0i, 02), we will usually be interested 
in some function of them, say 7(0), as the primary scientific target of inference. 
For example, we might be interested in 71 = 01/02 or 72 = 0i - 02, or 73 = 0b or 
74 = P(0i > 0г), or in all four. Inferences for 0, derive from the marginal posterior 
for di. This is obtained by integrating the joint posterior with respect to all r - 1 
elements of the & vector other than 0j. For example, with r = 2, we obtain
p(0i 12/) = JP^i,02 I y)dd2.
We remind the reader of our emphasis on the distinction between model para­
meters, 0, and parameters of scientific interest, say 7 = 7(0). There will often 
be more than one scientifically relevant parameter, so we would generally regard 
7 as a vector of parameters. In practice, however, we generally focus on a single 
parameter at a time. For the rest of this discussion, we consider a scalar 7. The 
Bayesian approach to inferences for 7 is based solely on its posterior distribution, 
or equivalently p(y | y) = p(7(0) | y).
In a calculus-based probability class, techniques are developed for finding the 
pdfs for functions of random variables. This can be hard work, however, and it 
is most often impossible to obtain an analytically tractable (nice) expression for 
p(0 I y) or p(7 I y). These issues are resolved by using Monte Carlo numerical tech­
niques to approximate posterior distributions, regardless of the complexity. Nu­
merical approximations are discussed in detail in Chapter 4. We give a preview 
illustration of their use later in this chapter, in Section 2.5.
Point inferences for 7 provide a one-number summary of the (marginal) poster­
ior, p(7 I y). A natural choice to consider first is the posterior mean, 7,
7 = E(7 I У) = У 7P(7 I !/)rf7-
But, as just indicated, the posterior for 7 may not be analytically tractable. For 
the moment, suppose we know the joint posterior for 0. We can then obtain
7 = S(7(0) I y) = [ 7(0)p(0 I V)d0

24
Bayesian Thinking in Biostatistics
from a convenient result in probability theory that avoids first obtaining p(7 | y)-
If the posterior for 7 is skewed (has a long tail in one direction and a shorter 
tail in the other), the middle of the distribution is better represented by the median 
of the posterior, med(7 | y), which is the value m that satisfies
[ Ph I у№ = 0.5 = f ph I у№-
J-00 
Jm
Another quantity of interest is the mode of the posterior, which is the value, say 
7, that achieves the maximum ph | y) over all possible 7. This is usually obtained 
by taking the derivative, ln(p(7 | y)), setting it to zero, and solving for 7.
We are also interested in a measure of how spread out or diffuse the posterior 
for 7 is. The posterior variance is
Var(7 I y) = Hy - 7)2p(7 | i/)d7
and the posterior standard deviation, sd(7 | y) = y/Vaxh I !/)•
Point estimates such as 7 and 7 do not convey any quantitative uncertainty 
about the unknown. While the posterior standard deviation takes a step in quanti­
fying uncertainty, we can be more direct by computing an interval with a specified 
high probability under the posterior density. In other words, intervals (l,u) for 
which P(l <7<u|j/) = l-a, where a is often chosen to be 0.05. If the posterior 
is symmetric about 7, then the mean, mode, and median are all the same. Moreover, 
the natural choice for I and и will be equidistant from 7 with a/2 area under the 
posterior to the left of I and to the right of u. With a skewed posterior, there are 
other possible choices for intervals, but we will generally find intervals that have 
a/2 area to the left of I, and a/2 area to the right of u, so that there is 1 - a area 
in between these values. Thus we have
У ph I y)<h = 1 - a­
We may also be interested in one-sided versions, namely where Ph < и | y) = 0.95 
or 0.99, etc.
Summary inferences for a Bayesian analysis generally involve presentation of 
a point estimate, a 95% interval estimate, and a posterior standard deviation. If 
the posterior is symmetric, then the mean should be presented; however, if it is 
skewed, then the median should be presented. These quantities, except for the 
posterior mode, are all obtained approximately using Monte Carlo methods, which 
are discussed in Chapter 4.
Bayes’ Theorem in Proportionality Form. This helpful form avoids some 
unnecessary calculations when dealing with p(6 | y). To see this we first return to 
equation (2.5). Both sides of this equation should be seen as functions of 8 only, 
as у represents observed numerical data that are regarded as fixed in any Bayesian 
analysis. Also observe that the denominator on the right-hand side is a definite

Fundamentals I: Bayes' Theorem. Knowledge Distributions, Prediction
integral and is free of в. In other words, the denominator is a constant with respect 
to в. In fact, it is the constant that makes the post-data density integrate to 1. 
Thus, the post-data density of 0 is determined up to a multiplicative constant 
by the numerator alone. Stated another way, this density is proportional to the 
numerator.
In addition, there are often multiplicative constants in p(y | 0) and p(0) as 
well. Observe that any such constants will cancel out in the ratio in equation (2.5), 
since this same term is in both the numerator and the denominator. Removing the 
multiplicative constant from p(y | 0), we write
Lik(6) <xp(y \0).
This function of 0 is called the (Fisher) likelihood function. Thus with у represent­
ing observed data and 0 denoting the collection of unobservables, the data-informed 
knowledge distribution for 0 is determined by
p(0 | y) <x p(y | 0) p(0) (X Lifc(0)p(0), 
(2.6)
where the proportionality constant is {fQ Lik(0) p(0)d0}~1, which is just the con­
stant of integration that makes the joint posterior integrate to 1. The symbol oc is 
read as “is proportional to.”
2Dr. Whittle defined this as systolic blood pressure greater than 140 mm Hg or diastolic greater 
than 90 mm Hg, decreasing these cut-points by 10 mm Hg for diabetics.
3For simplicity at the outset, we disregard individual characteristics that may be related to the 
outcome, such as age and body mass index.
The main purpose of deriving expression (2.6) is to simplify calculations. This sim­
plification occurs since we will often be able to recognize the name of the posterior 
density by simply knowing its functional form as a function of 0, making it unne­
cessary to keep track of constants. Also, keeping track of all of the constants can 
be quite tedious. In addition, even when we are not able to recognize the form, we 
will find in Chapter 4 that it is still not necessary to keep track of the constant of 
integration for reasons that will be discussed there.
Example 2.7. Using a small portion of the VetBP data of Example 1.1, we 
illustrate how one specifies a model for the data and an external knowledge dis­
tribution (or prior) for the unknowns in that model. Recall that Dr. Whittle’s 
study recruited hypertensive veterans. Many with this condition are success­
ful in controlling their hypertension through diet and medication while others 
are not. We focus here on one interesting unknown: the percentage of veter­
ans who have uncontrolled hypertension. As a fraction, we denote this by 0 = 
probability that a random veteran has uncontrolled hypertension.2
For now, we make no distinctions among individuals in the sample.3 Consider 
data from 404 participants in the VetBP study. Let у = t/i,.. •, t/404, where yi 
indicates whether or not the zth person in the study had uncontrolled hypertension. 
We assume that Yi | в ~ Ber(0) for i = 1,... ,404, where 0 is the proportion of

26 
Bayesian Thinking in Biostatistics
individuals in the population that have uncontrolled hypertension. We use iid to 
mean that these observations are independent and identically distributed, in this 
case conditional on the given value of 0. Because of this assumption, we have
404
р(у I *)  = П^(1 - 0)1-v< = 0S(1 - 0)4O4~S, 
i=l
where S = Vi c°unts the number of individuals out of the 404 who have 
uncontrolled hypertension. It turns out that S = 184, so that 404 — S = 220 for 
these data and Lik(0) = 0184(1 — 0)220.
Now suppose, for the moment, that we want to act as though absolutely nothing 
is known about what 0 might be for this population before data collection. Then 
a reasonable prior would be p(0) = 1 if 0 e (0,1) and 0 otherwise. We can also 
express this as p(0) = /(o,i)(#), where / is the indicator function. Alternatively, 
0 ~ £7(0,1), which means that we believe all values of 0 are equally plausible at the 
outset. Then using expression (2.6), we obtain
p(0 | y) oc 0184+1~i(1 - 0)22O+1-1,
which is the kernel of a Be(185,221) density function (see Appendix B), meaning 
that this is a beta pdf up to the constant of integration. Thus we have the very nice 
result that 0 | у ~ Be(185,221). The prior and posterior pdfs are shown in Figure 
2.2. It indicates that much information was gained about 0 through the data.
Bayes’ Theorem in Proportionality Form for an Event-Space Partition. 
Let Bi,..., Bfc be a finite partition of an event space Q. Let A be an event in Q 
with P(A) > 0. Then
P(Bi | A) oc P(A | Bi)P(Bi), i = l,...,k, 
(2.7)
where the proportionality constant is P(A | Bj)P(Bj)}-1. Recall that the 
denominator in equation (2.3) is the normalizing constant that follows from the 
law of total probability. Its inverse is the constant of proportionality in expression 
(2.7). Let us see how this helps with calculations via the next example.
Example 2.8. We return to Example 2.3 and consider the observed event “the 
algorithm indicates that the randomly chosen woman has incident breast cancer.” 
Conditioned on this event (data), we can calculate (posterior) probabilities for 
(£>i + . £>2+> D3+. D-). We show the calculations in Table 2.3.
The normalizing constant is the sum of the entries in the “product” column; it 
equals 0.004518. Dividing the products by this sum yields the last column. Notice 
that the procedure is to multiply the prior and the likelihood columns and normalize 
the resulting column of products by dividing each entry by the sum of the column. 
The final column would remain the same even if we multiplied each of the first two 
columns by distinct positive numbers. It is the relative size of the entries within 
each of the first two columns that is important in the calculation of the final column.

FIGURE 2.2: Prior and posterior distributions for fraction of uncontrolled hyper­
tension among hypertensive veterans.
2.4 Prediction
Inference for unknowns in a model given the data leads naturally to prediction of 
quantities that involve future observations. Prediction is destined to play a major 
role in the future of biostatistics. Continuing with the VetBP data of Example 
1.1, we extend Example 2.7 to prediction. Suppose we are planning a future study 
for which 100 veterans are to be recruited. We then ask the question (as did Dr. 
Whittle), how many of the 100 veterans to be sampled will have uncontrolled hy­
pertension?
We tackle a simpler prediction problem first. Consider a single veteran in the 
future study. Let Z denote his or her status regarding uncontrolled hypertension, 
with Z = 1 if the veteran’s hypertension is uncontrolled and 0 otherwise. Given the 
data from the 404 participants in the VetBP study, that is, given у = (з/i, ■ • •, 3/404), 
where again yi indicates whether or not the zth person in the study had uncontrolled 
hypertension, we wish to determine the predictive probability P(Z = 1 | y)- Using

28
Bayesian Thinking in Biostatistics
TABLE 2.3: Posterior distribution given algorithm positive
Partition event
Prior 
prob, of 
part, 
event
Prob, of 
obs. data 
given 
part, event
Product
Post, 
prob, of 
part 
event
Z?i+:
Incident BC_____
0.0050
0.8011
0.0040055
0.8866
Prevalent BC
0.0300
0.0065
0.0001950
0.0432
L>3+: Inc. or prev. 
other cancer
0.0700
0.0007
0.0000490
0.0108
D-: Cancer-free
0.8950
0.0003
0.0002685
0.0594
the law of total probability, we have
P(Z = z\y) = p(z, 0 | y)d0 = ^р(г\ 0, y)p(0 | y)dO.
The second equality follows from the fact that a joint pdf equals one of the marginals 
times a conditional (the multiplication rule for pdfs), for the same reason that the 
multiplication rule for events is P(A A B) = P(B | A)P(A).
Now consider the first term in the integrand on the far right above. Assuming 
that past and future data are independent, conditional on 0, means that Z and у 
are independent when 0 is regarded as fixed and known. Therefore, the conditioning 
on у in the first term in the integrand can be dropped. More formally, we write
p(z = z 10 
- р(г’У I^)pW _ p(2 I Vp(v I *)  _ I m
which here is just 0г(1 — #)1-г. As a consequence, in general we get
P(Z = z | j/) = p(z | 0)p(0 | y)d0. 
(2.8)
From Example 2.7 we know that 0 | у ~ Be(185,221). Substituting into equa­
tion (2.8) yields
= B(185 + z. 222 — z)
B(185.221)
= Г(185 + z)T(222 — z) Г(406)
Г(407) 
Г(185)Г(221)’ 2 =

Fundamentals I: Bayes' Theorem. Knowledge Distributions. Prediction 
29
In the equation, B(a,b) is the beta function (not density) defined in terms of the 
gamma function, and equals Г(а)Г(5)/Г(а + 5). It is the constant of integration for 
the Be(a, b) distribution. The third equality above follows, since the integrand in 
the second equality is just the kernel of a Be(185 + z, 221 + 1 - z) distribution. Then 
dividing the integrand in line 2 by 5(185 + z,221 + 1 — z) results in an integral of 
1. It remains to multiply by the same constant, which is what we see in line 3. For 
the predictive probability that Z = 1, the last expression takes the form
Г(18б)Г(221) 
Г(40б) 
_ 185
Г(407) 
Г(185)Г(221) “ 406 “ °‘4°6
as Г(186) = 185 х Г(185) and Г(407) = 406 х Г(406) by the factorial property of 
the gamma function. A similar calculation results in 221/406 for Z = 0. We could 
also get this last result by noting that P(Z = 0 | y) = 1 — P(JZ = 1 | y).
Returning to the future study of 100 veterans, denote the future observations by 
Z = (Zi,..., Zjoo), the vector of unknown status values (uncontrolled hypertension 
or not) for all veterans in the future sample. The joint predictive density for Z can 
be obtained by the same argument that led to equation (2.8) above, simply replacing 
z with z. The resulting joint predictive density is obtained below.
Joint Predictive Density. When future Z and data Y are conditionally inde­
pendent given the unobservable the joint predictive density is
P(Z = z I y) = jT p> I 0)p(0 I y)<W, 
(2.9)
where boldface denotes a vector.
Example 2.9. For the future study of 100 veterans, we are interested in the dis­
tribution of Sf = Zt given у = (t/i,... ,3/404). Clearly, Sf is a function of Z. 
Since we have conditional independence between Sf and Y given 0, equation (2.9) 
can be applied directly, that is, we have
P(SF = s\y) = I 0)p(0 I y)M.
From elementary probability, we note that Sf | 0 ~ 5m(100,0). We thus obtain
P(SF в I у) /0 s!(100-s)!e (1 
5(185,221) 
’
s = 0,..., 100. While it is straightforward to obtain an analytical result using the 
same technique used in the scalar case, it is somewhat ugly. Moreover, there is no 
actual necessity for having analytic formulas, as we now discuss.
In practice, most predictive distributions or densities turn out to be quite com­
plex. Equation (2.9), for example, requires an integration over a possibly high­
dimensional space, 0. Fortunately, it is usually much easier to employ sampling­
based Monte Carlo computation, which will be described briefly in the next section, 
and in detail in Chapter 4. Figure 2.3 gives precisely such a numerical approxima­
tion to the predictive density for the VetBP problem discussed above.

Bayesian Thinking in Biostatistics
30
number with uncontrolled hypertension in future sample of size 100
FIGURE 2.3: Predictive density.
Historical note. The predictive distribution defined in equation (2.8) goes back to 
at least the early to mid-1960s. We refer to Geisser (1971) [123], who was an ardent 
proponent of Bayesian prediction and who made a strong effort to clarify its utility 
as an important tool for making statistical inferences. Aitchison and Dunsmore 
(1975) [3] and Geisser (1993) [127] continued to make this case. More recently, at 
least since Gelman et al. (1995) [134], equation (2.8) has been termed the posterior 
predictive distribution. We will also introduce what has been termed the marginal 
predictive distribution (sometimes called the marginal likelihood of the observed 
data). This is obtained from equation (2.8) as p(j/) = fep(y | 0)p(0)d0, which has 
also more recently been termed the prior predictive distribution. We will, however, 
continue to use the original terminology.
2.5 
Monte Carlo Approximation
Numerical approximations for Bayesian statistical inferences are presented in Chap- 
tei 4. It is these approximations that make the modern Bayesian inference so pow-

Fundamentals I: Bayes' Theorem. Knowledge Distributions. Prediction 
31
erful in handling complex scientific problems. Here, we give a brief overview of what 
is coming for estimation and for prediction. We assume the background model for 
the data, p(y | 0), the pre-data scientific input, p(0). and a model for future data. 
p(z | в}, where past and future are assumed to be independent given the parameters. 
We again assume the scientific estimation goal is for a parameter 7 = 7(6).
Suppose it is possible to sample vectors (using a computer algorithm), say 
0<2\ ..., for large M, from the posterior distribution р(в | y). Then, 
calculating the corresponding values for {7(J> = 
: j = 
results
in a large sample from the (marginal) posterior of interest, p(7 | y). This sample 
can be used to approximate the density of 7 using a variety of techniques, includ­
ing just smoothing a histogram of these samples. The posterior mean is approxi­
mated by 7 = 
7^/М, the posterior standard deviation is approximated by
~ 5)2/A^» and quantiles of the posterior are obtained by ordering the 
7^) from smallest to largest. Of particular interest are the 0.025, 0.5, and 0.975 
quantiles of this Monte Carlo sample. The sample median is a numerical approxi­
mation to the median of the underlying posterior distribution, and the 0.025 and 
0.0975 sample quantiles give numerical approximations to (Z,u), the posterior in­
terval for the parameter of interest.
Sampling from the Predictive Distribution. Monte Carlo samples from p(z | 
y) can be obtained as follows. For each sample
Z0) I 0O) ~ p(Z I 0O)),
independently for j = 1,..., M. Under conditional independence, this amounts to 
sampling from the distribution with density p(z | 0^\y), independently for all 
j = 
which results in a random sample from the predictive distribution
with pdf p(z I y). One then uses either the mean or the median of this distribution 
as a point estimate, depending on whether or not it is skewed. One can also take 
quantiles of this distribution to obtain prediction intervals. Monte Carlo samples 
of functions of Z, such as Sf in Example 2.9, can be obtained by computing 
from each sampled Z^. Figure 2.3 was constructed using such generated predictive 
samples of Sf-
2.6 Recap and Readings
In this chapter we presented the main ingredients needed to accomplish Bayesian 
inference in a little more detail. These ingredients are conditional probability, 
Bayes’ theorem, data generating distribution or likelihood, knowledge distributions 
of knowledge of unknowns both external (prior) and data-informed (posterior), and 
predictions. The books cited in Section 3.4 (Carlin and Louis [63], Gelman et al. 
[133], Christensen et al. [79], Robert [271], and Hoff [166]) also cover these topics.

32
Bayesian Thinking in Biostatistics
We have postponed discussion of one topic considered early in many books. This 
topic is the so-called subjectivity of Bayesian methods as they require a prior dis­
tribution. Chapter 6 covers some ground in this area, and an accessible discussion 
can be found in a pair of articles by Berger and Goldstein [30, 146].
2.7 
Exercises
Exercise 2.1. An enzyme-linked immunosorbent assay (ELISA) test is per­
formed to determine if the human immunodeficiency virus (HIV) is present in the 
blood of individuals. The test is not perfect. Suppose that it correctly indicates HIV 
99% of the time, and the proportion of time it correctly indicates no HIV is 99.5%. 
Suppose that the prevalence of HIV among blood donors is known to be 1/10,000.
(a) 
What proportion of the blood that is donated will test positive for HIV using 
the ELISA test?
(b) 
What proportion of the blood that has tested negative on the ELISA test is 
actually infected with HIV? One minus this term, the proportion of blood that 
has tested negative on the ELISA and that is actually not infected, is termed the 
negative predictive value (NPV).
(c) 
What is the probability that a positive ELISA outcome is truly positive, that 
is, what proportion of individuals with positive test outcomes are actually infected 
with HIV? This probability is termed the positive predictive value (PPV).
Exercise 2.2. Suppose that hospital surgeries are performed five days a week, 
with 15% of surgeries on Mondays, 25% on Tuesdays, 25% on Wednesdays, 25% 
on Thursdays, and 10% on Fridays. Suppose that Monday and Friday surgeries are 
successful 80% of the time, and that Tuesday-Thursday surgeries are successful 
95% of the time.
(a) 
What proportion of surgeries are successful during a typical week?
(b) 
What proportion of non-successful surgeries occur on Monday? Tuesday? 
Wednesday? Thursday? Friday?
Exercise 2.3. Suppose it is known that 7% of British children attend special 
schools that cater to privileged parents and that 75% of all hospital administrators 
arc known to have attended such schools. Consider the implication that under- 
privilegtxi but presumably intelligent and hard-working children might have been 
excluded from high-ranking professions such as hospital administration. We look at 
the relative probabilities of becoming a hospital administrator given that one did 
or did not attend an elite school.
Specifically, let E denote attending an elite school, with Ec the complement. 
Let H denote becoming a hospital administrator, with Hc the complement. Let 
p = P(H) be the (unknown to us) proportion of hospital administrators among the 
populace of Great Britain. We are given that P(E | H) = 0.75 and P(E) = 0.07.

Fundamentals I: Bayes’ Theorem. Knowledge Distributions. Prediction 33
(a) 
Use the definition of conditional probability to find P(H | E) and P(H | Ec) 
as functions of p.
(b) 
Find an actual number for the (risk) ratio P(H\E)/P(H\EC).
(c) 
What can you say about the effect of availability of elite schooling on the 
prospects of becoming a hospital administrator in Great Britain?
(d) 
Let q = P(E). What value of q corresponds to no effect of school type on the 
chances of becoming a hospital administrator later in life? No effect means that 
P(H | E) = P(H | Ec) = P(H).
Exercise 2.4. Reproduce Figure 2.3.
Exercise 2.5. Model, prediction, and inference for conditionally geometric data. 
Consider a sequence of independent Bernoulli trials with 0 denoting the probability 
of success. The random variable Y = “number of failures before the first success” 
then has the geometric distribution:
p(y | 9) = (1 -0)«0, y = 0,l,....
Let the data consist of Yi,..., Yn conditionally independent and identically dis­
tributed as geometric with parameter 0. In the following, use a uniform prior on 
(0,1) for 0. The observed values are у = (yi,... ,yn).
(a) Derive the posterior pdf for 0. Identify the corresponding distribution precisely, 
(b) For a future value Z ~ p(z | 0), independent of the observed data, derive the 
explicit form of the predictive density, p(z | y).
(c) Suppose we are interested in the mean of the geometric distribution, p = (1 - 
0)/0. Using the usual transformation of variables technique from probability theory 
(see Appendix A), derive the posterior pdf for p.
(d) Extension to negative binomial data. If in the definition of the geometric distri­
bution above we change Y to “number of failures before the rth success” where г 
is a known number, we get the negative binomial distribution:
р(г/1'-,») = 
+ 
y = o,i........
Again with a uniform prior for 0, and using your results above, find the posterior 
and predictive densities given conditionally independent and identically distributed 
negative binomial data у = (j/i,...,yn).
Exercise 2.6. A man with a prostate specific antigen (PSA) test value exceeding 
4 will be suspected of having prostate cancer. Men over 50 are generally screened 
using the PSA test. Suppose it is known that the proportion of PSA values that will 
exceed 4 when such men do not have prostate cancer is 0.3; that for men who have 
stage I or II prostate cancer, the probability is 0.75; and that for men with higher 
than stage II prostate cancer, the probability is 0.85. Suppose that the proportion 
of men (over 50) who will ultimately be determined through various means to not 
actually have prostate cancer is 0.80, to have stages I or II is 0.15, and to be above 
stage II is 0.05.

34
Bayesian Thinking in Biostatistics
(a) 
What proportion of men over 50 will be diagnosed based on their PSA values to 
have prostate cancer? Keep in mind that all this means is that their PSA is greater 
than 4; it does not mean that they necessarily have cancer.
(b) 
Under these made-up assumptions, suppose an individual has just been di­
agnosed as potentially having prostate cancer (PSA > 4). What are the chances 
that he actually has: stage I or II prostate cancer? above stage II cancer? prostate 
cancer? no prostate cancer?
(c) 
Now suppose he has just been diagnosed as potentially not having prostate 
cancer. What are the chances that he actually has: stage I or II prostate cancer? 
above stage II cancer? prostate cancer? no prostate cancer?
(d) 
Construct a table with rows corresponding to disease status and three columns 
of probabilities corresponding to (i) no PSA information, (ii) PSA > 4, and (iii) 
PSA < 4. Comment on what you think of this PSA screening test.
Exercise 2.7. Exercise 2.6, continued. Generally, if the PSA outcome is pos­
itive, a follow-up test is performed that involves an invasive biopsy of the prostate. 
Biopsies are much more accurate in detecting cancer. While they also include in­
formation on the stage of cancer if present, for this exercise we consider only whether 
the biopsy is positive or negative for cancer. First suppose that such a biopsy is 
performed only on those that show PSA > 4, and that everyone with PSA > 4 un­
dergoes a biopsy. Next suppose that biopsies for prostate cancer have the following 
properties: for those without cancer, it is cancer negative with probability 0.999; for 
those with disease stage I or II, it is cancer positive with probability 0.90; and for 
someone with disease stage higher than II, it detects cancer with 98% accuracy. Use 
this information and that in the question and answers for Exercise 2.6 to answer 
the following questions.
(a) 
As in Exercise 2.6(d), construct and fill a table with rows corresponding to 
disease status and three columns of probabilities corresponding to (i) no biopsy 
information for someone about to have this test, (ii) a positive biopsy for cancer, 
and (iii) biopsy negative for cancer. Comment on what you think of the value of a 
biopsy.
(b) 
Compute the probability that a randomly chosen man over 50 who is waiting for 
the result of his PSA test has a positive biopsy as a result of this two-step testing 
procedure.
(c) 
Compute the probability that a randomly chosen man over 50 who is waiting for 
the result of his PSA test has a negative biopsy as a result of this two-step testing 
procedure.
Exercise 2.8. Let X1.X2 be conditionally independent and distributed as ex­
ponential random variables with pdf p(x | 0) = 0е~вх. Let p(0) = e~e, namely 
0 ~ exp(l). Lot .r = (гьгг) be the observed data.
(a) 
Write down and simplify the likelihood function Lifc(0) oc p(x | 0).
(b) 
Obtain the pdf for p(0 | x). There is a name for this distribution. Identify the 
precise distribution.

Fundamentals I: Bayes' Theorem. Knowledge Distributions. Prediction 
35
(c) 
Let Z | 0 also be exponential, the same as the Xi, and conditionally independent 
of them. Obtain the precise form of the predictive density p(z | x).
(d) 
Obtain the formula for the predictive probability P(Z > c | x).
Exercise 2.9. For the VetBP data discussed in Example 2.7, use R or some 
other program to determine the posterior median, mean, and a 95% probability 
interval for 0. Also obtain the posterior probability that 0 is greater than 0.4 and 
0.5.


Chapter 3
Fundamentals II: Models for Exchangeable 
Observations
In this chapter we discuss commonly used models for exchangeable observations. 
Measurements taken on individuals are regarded as exchangeable provided the in­
dividuals are sampled randomly from a particular population without regard to 
their individual characteristics beyond simply belonging to that population. This 
implies a symmetry about the role of individuals in the sampling. Technically, ex­
changeable means that the joint distribution of a collection, say (Yj,... , Yn), of 
random variables (RVs) is unaffected by any reordering of the observations. While 
exchangeable random variables are not necessarily independent, they are identically 
distributed. In other words, their marginal distributions are the same. If we start 
with Yi\3 ~ p(y | в) and then let 0 ~ p(0), then the Yi are exchangeable. In this 
instance, the Yi are (unconditionally) dependent. Dependence in the context of ex­
changeable RVs allows us to learn from observing some outcomes in order to predict 
outcomes that are not yet observed. This kind of model is our common theme in 
this chapter for different choices of sampling distribution and prior.
A major purpose of this chapter is to establish familiarity with the mathematical 
manipulations in Bayesian analysis in relatively simple scenarios. Understanding 
these computations will be useful for building more complex and more realistic 
models in later chapters. We introduce Bernoulli, binomial, normal, Poisson and 
exponential models for data along with probability models that reflect pre-data 
knowledge about unknown quantities or parameters associated with these models. 
The presentation includes illustrations of standard Bayesian inferences that use 
these models in conjunction with mostly so-called conjugate priors.
Model specification consists of writing down a sampling distribution (likelihood) 
and specifying a suitable family of (prior) distributions to be used to represent know­
ledge about unobservable parameters in the sampling distribution. For the pre-data 
knowledge distributions in this chapter, we use what are called conjugate families 
in all but one instance. Conjugate families have the property that both knowledge 
distributions, data-excluded and data-informed, are in the same family. To derive 
the data-informed knowledge distribution (the posterior), we use expression (2.6) 
for Bayes’ theorem in the proportionality form, and recognize that the product of 
prior and likelihood belongs to the same family as p(0).
While conjugacy is rarely necessary in modern Bayesian statistics, it does allow 
for simple calculations that result in a known form for the posterior pdf, which 
results in a relative ease of illustration at this early stage of our development of 
Bayesian inference. Moreover, these simple calculations can also provide insight
37

38 
Bayesian Thinking in Biostatistics
into the relative influence of the data compared with the prior on the posterior 
distribution.
The statistical model for the data is selected to be appropriate for the particular 
type of exchangeable data to be analyzed. The selected sampling distribution gives 
rise to a likelihood function, which gives rise to a possible form for the prior in the 
conjugate case. In later chapters, we often select families of pre-data distributions 
for the unknowns that are not conjugate.
The chapter concludes with a discussion of nonparametric models, which provide 
an alternative to the more constrained parametric models that are often used in 
data analysis. Required background material is in Appendix A.
3.1 Overview of Binomial, Normal, Poisson and Exponential 
Models
We consider four fundamental models for statistical data. The presentation at times 
will be somewhat technical as we focus on generic data of various types. However, 
scientific illustrations based on each type of data are given.
Bernoulli. The Bernoulli RV is named for the seventeenth-century mathematician 
Jacob Bernoulli. It occurs in the context of what is termed a Bernoulli trial, an 
experiment where there is a simple yes or no outcome. For example, we have per­
formed a Bernoulli trial if we sample a blood donor at random from the population 
of Red Cross donors, test the donor’s blood for HIV, and declare the outcome as 
yes or no. We also discussed Bernoulli trials in Example 2.7 in the previous chapter.
In general, if Y represents the outcome of a Bernoulli trial and the trial results 
in a “yes,” we let У = 1; if the answer is “no,” we let Y = 0. Generic terminology 
designates У = 1 as “success” and У = 0 as “failure.” With this specification, У 
is a numerical outcome associated with the Bernoulli trial. Furthermore, let 0 be 
the proportion of “successes” in the sampled population. We write У | 0 ~ Ber(0) 
where P(Y = 1 | 0) = 0 and P(Y = 0 | 0) = 1 - 0.
Binomial. From elementary probability, we know that the binomial distribution is 
just the sum of independent and identically distributed Ber(0) random variables. 
Suppose there are n iid Ber(ff) random variables and S equals the sum of them. 
We then have S | 0 ~ Bin(n,0). In other words, the binomial is the total number 
of yes answers for some characteristic out of a total of n independently sampled 
individuals from a single population.
As an illustration, suppose we place the names of all current Red Cross blood 
donors on a list and then randomly sample 100 names from that list. We then 
test each of the 100 sampled individuals for HIV and count the number of positive 
outcomes. If the actual population proportion of positive outcomes that we would 
observe if we tested everyone on the entire list were, say, 0.01. we would write 
S| 0~ Bin(lOO.O.Ol).

Fundamentals II: Models for Exchangeable Observations
39
Given the fixed known value of n, the binomial is completely characterized by 
the unknown parameter 0, which will be the primary scientific unknown of interest 
for making statistical inferences in this setting. The wonderful thing about the 
binomial is that it is possible to think about the way the sampling was done and 
characterize the distribution of possible outcomes with the binomial distribution.
It is well known that 
P(S = k | 0) =
-0)ПЛ
fc = 0, l,...,n,
and that E(Y) = пв and Уаг(У) = nO(l — 0). We discuss Bernoulli and binomial 
outcomes in Section 3.2.1.
Normal. The normal or Gaussian distribution is ubiquitous in the world of data 
analysis. While it is possible a priori to reasonably assert that a random variable is 
binomial, it is not possible to know with any degree of certainty that a random vari­
able is normal. It is possible, however, to check whether the assumption of normality 
is reasonable using various statistical techniques, such as by constructing a so-called 
quantile-quantile plot based on observed data. We make such considerations later 
in the book.
The normal distribution is a model for a continuous RV. In theory, a normal RV 
can take on any value in IR = (-oo, oo) to any degree of decimal accuracy. However, 
observed data can only be measured to a finite degree of accuracy. For example, if we 
measure the time to death from diagnosis with lung cancer, the time of observation 
would rarely be more accurate than to the minute, and data that biostatisticians 
analyze would generally only be accurate to the day of death. We would not gen­
erally model time-to-event data with a normal distribution, but one possibility is 
to take logs and to assume log times are approximately normal. When observed 
data can take on a sufficient number of possible values, somehow approximating a 
continuum over a large enough range of possibilities, they are usually modeled by a 
RV that is defined on the continuum, and this seems eminently reasonable in most 
instances. This assumption is made for all continuous RVs considered in this book.
When we write Y | p,a2 ~ N(p,a2), we are asserting that the probability 
density function (pdf) of Y is bell-shaped, symmetric about /z, that 95% of the 
area under the curve is in the interval (/z - 1.96cr,/z + 1.96cr), that its median and 
thus its mean are both p, and that its standard deviation is a. We know that 
the standardized version of У, Z = (У - /z)/cr, has a standard normal, 7V(0,1), 
distribution with pdf
/(2) = -Le"
*
2/2, z e IR.
V2tt
We discuss statistical inference for normal outcomes in Section 3.2.2.
Poisson. The Poisson distribution is named for the nineteenth-century mathemat­
ician and physicist Simeon Poisson. The Poisson random variable has the property 
that its mean, say A, also equals its variance (Л). We use the notation У|А ~ Po(A). 
It is a count variable that Poisson originally used to characterize the distribution of 

40
Bayesian Thinking in Biostatistics
the number of events occurring during a fixed time interval. The distribution has 
also found much use in other applications. Two examples are modeling the number 
of blood transfusions per month among cancer patients suffering chemotherapy- 
induced anemia and the number of tumors in the livers of mice exposed to a car­
cinogen. The Poisson distribution is similar to but different from the binomial.
The Poisson also arises as an approximation to the binomial when n is large 
and 0 is small. Under these circumstances, if Y | 0 ~ Bin(n,0), then we can show 
that Y | 0 ~ Po(n0), where ~ means is approximately distributed as. The Poisson 
approximation was historically important before the advent of fast computers.
Consider the following examples one might characterize via the Poisson distri­
bution: (i) the number of lung cancer incidences (events) in New York City over the 
period of a year; (ii) the number of babies born in Los Angeles during a specified 
year; (iii) the number of unique incidences of individuals infected with the Zika 
virus (events) in the U.S. since January 2016. By “unique” we mean that if Zika 
was transmitted to a member of a family, we do not count additional incidences 
within the same family.
The assumptions for a variable Y to be Po(X) are as follows.
• 
Events occur independently of one another. Specifically, if it is known that a 
certain number of events occurred in a particular time window, this knowledge 
has no effect on the probability of any number of events occurring in a non­
overlapping time window, conditional on Л.
• 
The probability of seeing a particular number of events in any given time 
window is the same for all time windows of the same length; this is called 
stationarity.
• 
The probability of exactly one event occurring in a small time window is 
proportional to Л times the length of the time window.
• 
The probability of two or more events occurring in a small time window is 
very small.
Examples (i)—(iii) above should at least approximately satisfy these assumptions. 
Observe that there is no fixed number of individuals that constitute a sample, as 
in the binomial case. In the cancer incidence case, there is no fixed number of 
individuals living in a city over the course of a year, since many people move into 
a city, many die, and many leave a city during any given year. The “babies being 
born” and the Zika examples clearly have no fixed ascertainable n.
Under the above assumptions, it can be shown that
P(Y = к | A) = —e-A, A: = 0,1,...,
with E(Y | A) = A and Var(Y | A) = A. In fact, under these assumptions, if we define 
N(t) to be the number of events to occur by time t, it is true that N(t) ~ Po(At). 
The collection of Poisson random variables {A(t) : t > 0} is called a Poisson process 
with rate A. We discuss inferences for Poisson outcomes in Section 3.2.3.

Fundamentals II: Models for Exchangeable Observations
41
Exponential. If we let T be the waiting time for the first event in a Poisson 
process {AT(t) : t > 0}, we must have P(T > 11 Л) = P(N(t) = 0 | A) = e-Af. since 
{T > t} <=> {N(t) = 0}- (The symbol <=> means “if and only if.”) This probability is 
called the survival (or survivor) function and is 1 minus the cumulative distribution 
function (cdf). The pdf for T is the derivative of the cdf and we obtain
p(t | A) = Xe~Xl, t > 0.
We write T ~ Exp(X) and it is easy to show that E(T) = 1/X and Var(T) = 1/A2. 
It can also be shown that the waiting times between events in a Poisson process 
with rate parameter A are independent and identically distributed as Exp(X). We 
discuss exponential models in Section 3.2.4.
We proceed to obtain posterior and predictive distributions and make inferences 
using these models.
3.2 Posterior and Predictive Inferences
3.2.1 Bernoulli and Binomial Models
In this section we first discuss statistical inferences for exchangeable Bernoulli RVs. 
We assume that n conditionally iid Ber(0) RVs are observed. We also observe the 
sum of the Bernoullis. Since, conditional on the success probability в, the sum 
of n iid Ber(0) RVs is distributed as Bin(n,ff), and since the likelihood, Lik(ff), 
is identical whether only the sum is observed or if the individual Bernoullis are 
observed, Bayesian inferences based on the binomial and Bernoulli models will be 
identical if the same prior is used for в.
Exchangeable Bernoulli Model. We already considered an illustration of this 
model in Example 2.7. Here, we present a general version of what was presented 
there.
With notation from the distribution table in Appendix B, we write the model 
as
Yi,...,yn|0~Ber(fl).
We need an analytical form for the distribution of the data given the parameter if 
we are to use Bayes’ theorem. As discussed just above expression (2.6), the pdf for 
this sampling distribution of the data, when looked at as a function of the parameter 
for fixed observed data, is proportional to the likelihood function, Lik(6). We have
Lik(6) = Р(У1,...tVn 10) = П^(1 - 0)1"*  = eZ?=1 *(1  - &)n~^ Vi- 
i=l
The next step is to specify an external (or pre-data) knowledge distribution (or 

42
Bayesian Thinking in Biostatistics
prior) for в, which must be obtained without looking at the data. We have argued 
throughout that such considerations must be made independently of the data to 
be analyzed. This means that the information could be obtained before the data 
are even collected, or simply obtained from sources that are separate from any 
information provided in the data.
The beta family of prior distributions is conjugate here. So let us assume that 
scientific knowledge about 0 can be reasonably reflected by a Be(ao, bo) distribution. 
Then by expression (2.6), and defining s = j/i, we have
p(0 | у)оС0в(1-0)П~а0ао~\1-0)Ь°-1 <Х0“о+в-1(1 -fljbo+n-s-1
which is the kernel of a Be(ao + s,bo + n — s) pdf. Then we say that
0 | У ~ Be(a0 + s, bo + n - s).
The prior and the posterior are in the same family. This property has also been 
called “closed under sampling.”
We note that the prior and posterior means are
ВД = -А, esE(e\y-)= + 
=u,^- + (i-u,)l,
a + о 
ao + oq + n ao + bo 
n
where w = (ao + bo)/(ao + b0 + n). The posterior mean is a weighted average of 
the prior mean and the proportion of successes, s/n, in the sample. If ao + bo = n, 
each part gets equal weighting. Generally, we would expect ao + bo < n so that 
more weight is given to the data than to the prior; ao + bo is often regarded as the 
“prior sample size” because of this weighting. Such estimators are called “shrinkage” 
estimators since they shrink away from the solely data-based estimate towards the 
prior guess.
The unique mode of a Be(ao, bQ) distribution is (ao — l)/(ao + bo — 2), provided 
ao > 1, ao + bo > 2. With ao = bo = 1, we have the uniform distribution, C7(0,1); 
with ao < 1, bo > 1 the unique mode is 0; with ao > 1, bo < 1 the unique mode is 
1. With ao < 1, bo < 1, there are two modes, at 0 and 1. The latter case implies 
that the scientist would have a belief that 0 was more likely to be close to 0 or 1, 
and less likely to be in between. It would be unusual for real scientific information 
to follow this reasoning.
The posterior standard deviation is
^0(1 — 0)/(ao + bo + n).
So the larger is a0 + b0 + n, the more concentrated the posterior for 0 is about its 
mean. Since good approximations to the quantiles of the beta distribution are easily 
obtained in packages like R. it is simple to obtain a 95% probability interval (PI) 
for 0 by obtaining the 0.025 and 0.975 quantiles of the specified beta distribution. 
The posterior median is also easily obtained in this way. For this kind of situation, 
the Monte Carlo-based computational methods are not needed.

Fundamentals II: Models for Exchangeable Observations
43
Example 3.1. Here we continue with the VetBP illustration from Example 2.7. 
Recall that a Be(l, 1) (or (7(0,1)) prior was used there. Since n — 40-1 and o0 + 
bo = 2, estimates are primarily driven by the data. We obtain the posterior mean. 
185/(185 + 221) = 0.457, posterior mode, 184/(185 + 221-2) = 0.455, and median,1 
0.456, posterior standard deviation, 0.025, and 95% interval.2 (0.408.0.504). We can 
also obtain P(0 < c | y), using R. For example, with c = 0.5, we find the probability 
that 0 is less than 0.5 is about3 0.96.
'qbetaCO.5,185,221) in R.
2qbeta(c(0.025,0.975),185,221) in R.
3pbeta(0.5,185,221) in R.
As previously discussed, the median will actually be more appropriate as a 
point estimate if the corresponding posterior pdf is skewed since, in that instance, 
it may well represent the “middle” of the posterior distribution much better than 
the posterior mean, especially if highly skewed. Since mean, median, and mode are 
nearly identical in this illustration, it would make little difference which was used 
as a point estimate.
The interpretation for the probability interval is straightforward: conditional on 
the data, the probability is 0.95 that the unknown fraction of uncontrolled hyper­
tension among hypertensive veterans in the target population is between 0.408 and 
0.504. The interval is often called a 95% credible interval, but it is also called a 95% 
posterior probability interval, and often just a 95% probability interval. There are 
also 95% prior probability intervals that are simply based on the prior distribution. 
In this example, a 95% prior probability interval for 0 is simply (0.025,0.975). We 
are using intervals that have 0.025 area to the left of the lower endpoint and to 
the right of the upper endpoint, under the prior or the posterior pdf, respectively. 
Other choices are possible; we discuss one possibility in the next paragraph. Point 
and interval estimates for the VetBP data are shown in Figure 3.1.
Another method of interval estimation involves calculation of the highest pos­
terior density (HPD) interval. This is the interval with the correct area for which 
all points outside the interval have smaller density (or plausibility). If the pos­
terior pdf is symmetric and unimodal, the interval obtained will be identical to 
the one described above. However, if the posterior were bimodal with modes 
at 0 and 1, for example with a Be(0.5,0.5) posterior, the 95% HPD would be 
(0,0.46) U (0.54,1), where 0.46 is the 0.475 quantile and 0.54 is the 0.525 quantile. 
On the other hand, the interval corresponding to the 0.025 and 0.975 quantiles 
would be (0.0015,0.9985), which is radically different since all the ordinates outside 
the interval are more plausible than all the ordinates inside the interval. The HPD 
is obviously preferable in general and especially in this situation. However, it is 
doubtful that this particular posterior would arise, and if it did, we would use the 
HPD. Highly skewed posteriors also warrant HPD intervals. We generally use the 
equal-tail method unless the nature of the posterior demands otherwise.
Functions of Unknowns in the Model. As previously discussed, interest often 
lies in some function of the unknown used in the model. To illustrate, suppose we 
are interested in the odds of uncontrolled hypertension in addition to the fraction

44
Bayesian Thinking in Biostatistics
0.35 
0.40 
0.45 
0.50 
0.55
theta
FIGURE 3.1: Posterior distribution with mean, median, and 95% equal-tail credible 
interval.
(or probability). With 7 denoting odds, the relationship is
e 
7 “ 1 -0'
The prior or posterior distribution of 7 is induced from the specified distribution 
for 0. While an analytical derivation is possible using the calculus of probability 
(set; Appendix A), inferences can be readily obtained by Monte Carlo sampling of 
a large number, say M, of values of 0 from its distribution, {0^,0^,... ,0^M^}, 
and calculating the corresponding values {7^) = 0^/(1 — t?U)) : j = l,...,jVf}. 
This effectively gives a large sample from the posterior distribution of 7 that can 
be used to approximate the density of 7. as well as any summaries, such as mean, 
median, and PI for Figure 3.2 displays the knowledge distributions for 7, both 
pre-data (obtained analytically) and post-data (obtained via sampling).
Moreover, since the function of 0 above is monotone and increasing, the median 
of the posterior for -> is just the transformed median of 0, namely, 0.456/(1-0.456) = 
0.84. and the 95% posterior interval is (0.69,1.02). We are thus 95% certain that 
the odds of uncontrolled hypertension are between 0.69 and 1.02.

Fundamentals II: Models for Exchangeable Observations
45
FIGURE 3.2: Prior and posterior distributions for 7, for the VetBP data, the 
posterior obtained via sampling.
Binomial Model. Let Y | в ~ Bin(0) and assume that Y = у is observed. We 
continue as above with a generic Be(ao>&o) prior to model uncertainty about the 
binomial success probability в. While it is convenient, it is by no means necessary to 
use a beta distribution as a model for the prior. The beta distribution is conjugate 
to the binomial distribution, the same as it was for exchangeable Bernoullis. The 
Be(ao> bo) pdf is
pW = 
(3.1)
Г(ао)Цоо)
Here Г(-) is the well-known gamma function; ao and bo are selected to reflect the 
researcher’s beliefs and uncertainty.
Since
p(!/1 v = (j0V(i - 
a 01/(1"0)n-I/ = Lik^'

46
Bayesian Thinking in Biostatistics
Bayes’ theorem in proportionality form gives
p(0 | y) <x p(y | 0)p(0)
oc 0V(1 -0)n~V0a°-\l -0)b°~1
« flao+lZ-l^ _0)bo+n-l/-l5
which is the kernel of the Be(ao+y, bo+n—y) distribution. Thus we have established 
that
О I У ~ Be(a0 + y, bQ + n - y),
which is identical to the result obtained when n exchangeable Ber(0) RVs were 
observed; there y, the observed number of “successes,” was denoted s.
‘Prediction in the Binomial Model. We have just developed Bayesian estima­
tion for the Bernoulli and binomial models, and we developed predictive inferences 
for a particular example in Chapter 2. We now extend the methodology to predic­
tion of a generic binomial count. For example, if it is known that m blood units 
have been donated but have not yet been tested, we may be interested in using the 
data at hand to predict the number of those units that might test positive for HIV 
infection.
Let Z | 0 ~ Bin(m,0) be a future binomial count of interest. Furthermore, 
suppose we have already observed data Y = у that we take to be distributed 
as Y | 0 ~ Bin(n,0) and that Y and Z are conditionally independent given 0. 
Assume the prior 0 ~ Be(ao, bo). We showed above that the posterior was also beta 
distributed. Let us denote the updated parameters of the posterior beta distribution 
as (av,by), where ay = ao + y and by = bo+n — y. We can now obtain both pre-data 
and post-data prediction probabilities in one calculation:
P{Z = r\y) = [ P(Z = r | y,0)p(0 | y)d0
Jo
= /' (YW - er"r
Jo \r / 
Г(ау)Г(оу)
= 
/'10(“>'+r)-i(i_0)bv+m-r-1 do
\r J Г(ау)Г(Ьу) Jo
_ fm\ Г(ау + by) Г(ау + г)Г(Ьу + m - r) 
\r J Г(ау)Г(Ьу) Г(ау + Ьу + т)
If m = 1, the probability that the next observation will be Z = 1, given the current 
data, is ay/(ay + by). This predicted probability follows from the factorial property 
of the gamma function: Г(о + 1) = оГ(н). The general r case simplifies by repeatedly 
using this property.
Example 3.2. Predicting HIV Infection. Let the proportion of infected blood 
units in the population be denoted as the prevalence of infection, or simply, the 
prevalence. Suppose that, before any blood units have been tested, we are tempted 
to assert that the prevalence is equally likely to be any number between 0 and 1.

Fundamentals II: Models for Exchangeable Observations
As we have already seen, the t/(0,1) (or Be(l.l)) distribution would be a prime 
candidate in this instance. This prior reflects a belief that the prevalence is equally 
likely to be above or below 0.5. However, some reflection may lead us to think 
that such a prior would fail to represent scientific reality. If the population sampled 
involves units donated to the American Red Cross, it is difficult to imagine that 
the prevalence could even be 10%, let alone above 50%.
Let us assume that information is available that suggests that it is extremely 
unlikely that 10% or more blood donors could be HIV infected. A little calculus 
can be used to show that a Be(l,43.7) only admits a 1% chance for a value above 
0.1. This prior has a mode of 0 and would be conservative if the likely prevalence 
is very much smaller than 0.1.
Suppose we examine 10,000 units of blood and test each for HIV. If 2 of the 
10,000 units are infected, our posterior distribution for the proportion of infected 
units of blood will have a beta distribution with parameters 3 (= 1+2) and 10,041.7 
(= 43.7 +10,000 — 2). This posterior is quite skewed so we would choose the median 
of the posterior as a point estimate for the prevalence. The posterior median is 
0.00027 and a 95% PI is (0.000062,0.00072). If asked to predict what proportion 
of future blood units we examine will be infected with HIV, our answer would be 
0.027%, or about 27 in 100,000, and with 95% certainty, we would assert that the 
prevalence was between 6.2 and 72.0 per 100,000 units.
If we then plan to examine another 10,000 blood units, we find that the mean of 
the predictive distribution is 3, the median is 2, and a 95% prediction interval for 
the number of HIV infected units in the future sample is [0,9]. This was performed 
using Monte Carlo methods, yet to be discussed.
These calculations were based on the assumption that the probability that each 
unit of blood is infected is essentially the same across all tested units, and that 
knowing the test outcome for any particular selection of units conveys no informa­
tion about the chances that other units are infected, conditional on a given true 
value for the probability of infection. This all translates to the conditionally iid 
sampling assumption. These assumptions may be too strong. An example of how 
the binomial assumption could be wrong would be if our sample contained multiple 
units of blood from the same person, or if the sample was meant to include only 
men, and if units from one or more women were included by mistake.
3.2.2 Normally Distributed Exchangeable Observations
We now consider the 7V(/z,<j2) distribution for exchangeable continuous observa­
tions. A new feature is the fact that there are two model parameters, the mean, 
ц, and the variance, a2. We will need to obtain the likelihood for this model, and 
we will need to specify one or more families of prior distributions for the model 
parameters. In this section it will be convenient, for technical reasons, to repa­
rameterize the model. There are a variety of reasons in statistical modeling why 
reparameterization can be helpful and important. Therefore, in addition to making 
the presentation easier, we think it will be helpful to provide an in-depth example, 
so that subsequent experiences will seem more familiar.

48
Bayesian Thinking in Biostatistics
For the development and presentation of the joint posterior, it will be much 
easier for us to use the parameter т = X/a2, rather than а2; т is the “precision” of 
the distribution. We thus proceed to discuss making inferences for (д,т). Once we 
have inferences for (д, r), it is a simple matter when using Monte Carlo methods 
to make inferences for (д,а2), and for virtually any function, 7 = 7(д,а2). For 
example, we may be interested in the 90th percentile of the normal distribution, 
which is у + 1.28a = p + 1.28/^. Another parameter of interest might be the 
probability
P(Y < с I y,a) = P (z < 
= Ф (^7^) >
which can just as easily be written in terms of r. It is equally easy to make inferences 
regardless of the model parameterization.
When it is time to place a normal prior distribution on, say, д, which we will 
do, we find that it is considerably easier to leave the parameterization for that 
distribution alone. So our notation throughout this section will be Y ~ 7V(/z, 1/r) 
when modeling data. And when we model external knowledge about д, we write 
д ~ Af(/zo,Oo), where до is a prior guess for д and <jq is the standard deviation of 
the prior for д, which determines how precise the prior information is.
We now present some important technical details that will be needed for the 
rest of the section.
The Joint Likelihood and Posterior. With the data modeled as
Уг|д,Т ~ ДГ(д, l/т), Z = l,...,n, 
we have the likelihood function
Lik(p,r) a 
= rn/2e~i ^=^~^2.
i=i
One can easily show that
=n(M-y)2 + ^(3/i-y)2, 
(3.2)
i=i 
i=i
where у = Уг/п, the sample mean. Showing this result is left as an exercise. 
Using equation (3.2), we obtain
£г£(д,т) ос 
. 
(3.3)
Specifying the joint prior for (д. r) as р(д, r). the joint posterior is
д(д.т | у) ос £г£(д.т)р(д,т),
where у denotes the vector (j/i,... ,yn)'. Two basic choices for prior families will 
be considered.
/>(/'• т) = р(д I r)p(r) and р(д, т) = р(д)р(т).

Fundamentals II: Models for Exchangeable Observations
49
In the first instance, knowledge about ц is assumed to be dependent on the value 
of t, while the second specification assumes independence.
Based on conjugacy considerations, we use gamma distributions for the marginal 
priors for r in this section. We consider other types of priors later in the book. We 
also consider normal distributions for ц in both cases, where in the first case the 
prior for ц will depend on т in a way that results in joint conjugacy, meaning that 
the joint posterior will be in the same form as the joint prior. In the second case, the 
conditional distribution р(д | т,у) will be normal, and the conditional distribution 
р(т I wiH be gamma, which results in what is termed “conditional conjugacy.”
The advantage of the independence prior is that it is easier to think about the 
mean ц independently of the precision (or variance or standard deviation). The 
price paid for the assumption of independence is that there is no analytical solution 
for obtaining the precise joint posterior. The particular choice in the dependence 
case, on the other hand, results in a more difficult prior specification for д.
In practice, we use the independence assumption, since there are computational 
methods that we discuss in Chapter 4 that make the analytical intractability disap­
pear using Monte Carlo simulation. So why consider the analytically tractable but 
less practicable dependence prior if the independence prior is conceptually nicer and 
is computationally tractable? Part of the answer is that we present it for historical 
reasons. Before the advent of modern computational methods, the dependence prior 
was the only one that could be used. In addition, the dependence prior specifica­
tion allows us to illustrate how the Bayesian method works when there is analytical 
tractability in a somewhat complex two-parameter problem.
Using the development above, we first present methods for the case with known 
precision or variance. While it would be extremely rare that the variance is known, 
the presentation further demonstrates how Bayesian methods work. We will see 
that the posterior mean is a weighted average of the sample mean, y, and the prior 
guess, до, and where the weights depend on the relative magnitudes of n and <to- 
If сто is very small, it means that we basically believe, before seeing any data, that 
д = до, so the posterior mean should shrink to be very close to до for moderate n. 
On the other hand, if there is substantial prior uncertainty about д, meaning ctq is 
large, and if n is moderate to large, the posterior mean should be relatively close 
to the sample mean.
Known Variance or Precision. Using expression (3.3), and with д ~ 
ЛГ(до, 1/To), we have
р(д | T,y) ос e-V(M-S)2e-^(M-Mo)2 = е-|{тй(м-До)2+пт(Д-у)2}
For conditional conjugacy to hold, this must be proportional to a normal density 
in д, which is not at all obvious at this stage. A technique called “completing the 
square” results in the very useful formula
то(д - до)2 + Нд - у)2 = (т0 + пт)(д - д)2 + ^^.(До “ У)2, 
(3-4)
where
- r0 
пт _
P =-----------До H-------:----- У-
tq + пт то + пт

50
Bayesian Thinking in Biostatistics
It follows immediately that
p(/z I т,у) ос е_^{(го+пг)(/1“Д)2+^^(мо-!')2} ос e-HC’-o+nr)^-/!)8}, 
(3.5)
which implies that the conditional posterior is indeed normal, namely
+ 
_J_\ 
(3.6)
\ ПТ + Tq 
Tq+ПТ J
As claimed above, conditional on knowing r, the posterior mean /z is a weighted 
average of our pre-data guess for ц and the sample mean, y. The weight on the latter 
is proportional to sample size, while the weight on the prior guess is proportional 
to to = 1/<Tq.
This is another example of a shrinkage estimator; with larger sample sizes, 
the prior mean is downweighted in relation to the data, while with small ao, the 
estimator shrinks towards the prior guess. It is also interesting to note that the 
precision in the posterior is the sum of precisions, the precision for the prior and 
the precision for the sample mean of n observations, namely пт.
The posterior variance is Var(/z | a2,y) = <7q<72/(nog + a2) with <7q = l/r0 and 
er2 = 1/r. Thus the posterior distribution of ц will be more concentrated about its 
posterior mean if n is large or a is small compared to ao-
Both Mean and Variance (or Precision) Unknown. We consider two distinct 
priors when both /z and r are unknown. The first is a joint prior in which /z and r 
are dependent. The particular choice leads to a posterior in the same joint family 
(i.e., it is conjugate). The second prior uses independent /z and r, which also has 
some useful properties of posterior conditional distributions of /z, r being conjugate 
with simple parameter updates.
♦Jointly Conjugate Dependence Prior. Here, we assume a jointly conjugate 
prior for (/z, r). Let
V I т ~ N (/z0, 
, r~Ga(c,d).
We call this a normal-gamma distribution and denote it NoGa(no,k,c, d). Recall 
that the pdf for a Ga(c, d) RV is
for c.d > 0. The mean of the Ga(c, d) distribution using our parameterization 
is c/d. and its variance is c/d2. The mode is (c - l)/d, provided c > 1 and is 
zero if 0 < c < 1. If one has a prior guess for r, such as т = tq, one can set 
c/d = to or (<•- l)/d = r0. Letting d be somewhat small gives a gamma distribution 
that is diffuse. We give a more nuanced discussion later.
A useful observation is that, since the gamma density is a density, we must have
= 
(3.7)

Fundamentals II: Models for Exchangeable Observations
This is the normalizing (or integration) constant for the gamma distribution as in 
the table in Appendix B. We will use such constants often.
The prior for у depends on unknown t, which was not the case in the previous 
discussion where there was no reference to To depending on t. The specific reason 
for this choice of prior is that it leads to joint conjugacy, as we shall soon set'.
Any joint distribution for a pair of RVs can be expressed as a marginal times a 
conditional. Here we have
p(p,t I У) = p(t I 2/)p(p I т,у).
We already know that p(p | t, y) is the normal density given in expression (3.5). 
only with кт replacing To in that formula, namely
<3-8>
In this formula,
_ кт 
пт _ к 
n _
д- (ГПо7Мо + (k+”Fy = 
+ k^v'
We see that к and n play comparable roles in the analysis, for example if к = n, 
the prior guess and sample mean get equal weight. Observe that the conditional 
prior and posterior distributions for у are in precisely the same form, normal with 
distinct means and with precisions кт and (к + п)т, respectively.
Using expression (3.3) and defining 52”=1(pi-p)2 = ns2, the joint posterior can 
be represented as
р(у,т\у) ОС Tn/'2e-^{n(u-y)2+ns2}Tl/2e-^{(u-Uo)2}Tc-le-Td
= т1/2е-|{(п+к)(м-Д)2} |-TC+n/2-le-T{d+ns2/2+^(Mo-i/)2/2}] 
oc p(p I т,у)р(т I y),
where the middle result follows from using the complete-the-square technique as in 
equation (3.4) with to replaced by кт, some simple algebra and a rearrangement of 
terms. The last expression follows since f p(y,r | y)dy = p(r | y), and since the 
expression just above is the product of the kernel for a A^(p, 1/[(А: + п)т]) density in 
p times a function of only т (in square brackets). Thus integrating with respect to 
p results in a constant (not depending on т or p) times the term in brackets, which 
is the kernel of a gamma pdf; hence the joint posterior pdf is in conjugate normal­
gamma form. Simplifying notation, we term it a NoGa(y, k + n,<f, d') distribution, 
with
с' = c + n/2, d' = d + ns2/2 + (po - p)2/2.
We are also interested in the marginal posterior for p,
Р^\у) = I p(y,r\y)dr.

52
Bayesian Thinking in Biostatistics
With our simplified notation, we have
p(p,T I y) « Tc' + 1/2-le-r{(n+A:)(M-M)2/2+d'}
and thus
P(Mll/) « yTC' + 1/2-le-r{(n+A:)(M-M)2/2+d'}dT 
_ 1__________________ 
a {(п+к^-цу/2+d'}^^
using the integration constant from equation (3.7), since the integrand is the kernel 
of a Ga(d 4-1/2, {(n 4- к){ц - p)2/2 4- d'}) Pdf- Multiplying the above expression 
and dividing by the constant (d')c +1/2 results in
1 У) a {1 + c/(n + fc)(/z - Д)2/(2^')}(2с'+1)/2 ’
which is the kernel of a t(2c/, p, y/d'/{d(n + k)}) distribution. The parameters in 
the Student’s distribution are 2c', called the degrees of freedom (df); p, the location; 
and у/d'/{d(n 4- fc)}, the scale. For those unfamiliar with this distribution, it is a 
simple generalization of the usual t distribution. In fact,
+ fc)J 1 У
where t2c' is the usual t RV with 2d df. In the table of distributions in Appendix 
B, this corresponds to t(2d,0,1). The general form of the Student’s t distribution 
is t(y, у,, a) with pdf
( (s - u.}2 1 (p+1)/2 
p(s)exl/|l + ^^7 | 
, se(-oo,oo).
The Student’s distribution is similar to the normal distribution in that it is 
symmetric about its location parameter and its spread depends on its dispersion 
parameter. When df = 1, it is also called a Cauchy distribution. A peculiarity of 
the Cauchy distribution is that its mean and variance do not exist, which is why 
we use the terms “location” and “dispersion” rather than mean and variance. We 
get the standardized Student distribution by subtracting the location and dividing 
by the square root of the dispersion. Student’s distribution approximates a normal 
distribution as the df parameter grows.
A posterior probability interval for p is obtained as follows. The standardized 
Student distribution is symmetric about 0, allowing us to specify appropriate ends 
for the interval. For example, we might consider equal-tail percentiles, such as 
-fo.O25 and the 0.025 and 0.975 percentage points of the standard t dis­
tribution with 2d df. Using these percentiles, we have a 95% posterior probability 
interval from the standardized distribution as
P 025 < ^/Hn'+A-)] < ‘° 025 1 
= ° 95'

Fundamentals II: .Models for Exchangeable Observations 
53
We rewrite this interval using simple algebra as
P& - «0.025 >/d7[c'(n + fc)] < M < Д + «0.025 \/d7[c'(n + A:)] | y) = 0.95
and have a 95% posterior probability interval for p, namely.
Д ± «0.025 \/d'/cf{n + A:)].
Remark. A considerably simplified prior distribution that has been used historically 
is described as follows. First, let c,d be very close to zero. Then we know p(r) oc 
rc-1e-rd, but this is approximately equal to 1/r. Moreover, if we let /zo = 0 and 
к be approximately zero, we have p(p | r) oc e~kr^ , which is approximately a 
constant in p. Then under these conditions, we have p(/z,r) ex 1/r approximately. 
There is a “small” issue with this approximation, which is that the approximate 
joint prior is not a pdf because f 1/rdpdr = oo. This is called an “improper” prior 
as a result, and thus using this approximation violates a key probability law.
Nonetheless, if we used this prior, following the same method just described, we 
would more easily get the following results:
M | т, у ~ N (у, + 
> т I У ~ Ga ^(yi ~ У)2/^ ,
so the conditional posterior mean is simply the sample mean. The posterior mean 
of r is
the reciprocal of the usual unbiased estimate of ст2. In addition,
/z | у ~ t(n - l,y,s7v^)>
so that a 95% PI for /z in this case is у ± «0.025^7 which is precisely the same 
interval that frequentists use in this setting. The only difference is that their inter­
pretation of the interval is quite convoluted. The Bayesian interpretation is simply 
that we are 95% certain that /z is in the calculated interval based on observed data.
Moreover, since the posterior for (n - l)(s')2 т I У ~ Ga([n - l]/2,1/2) = Xn-1> 
we can derive a 95% posterior probability interval that is identical to the usual 
frequentist interval for ст2.
Since this particular (improper) prior results in inferences that compare with 
frequentist inferences, it is often called a “reference” prior. Showing these results is 
left as exercises at the end of this chapter.
Independence Prior. We assume p(p, t) = p(/z)p(r). Since analytic tractability is 
not possible here, we proceed in a direction that leads to computational tractability. 
We make the same assumptions that we made when considering the known variance 
or precision case, namely, /z ~ 7V(/zo, l/то). We also assume т ~ Ga(c, d), as we did 
in the dependence case. We already know from expression (3.5) that the conditional 

54
Bayesian Thinking in Biostatistics
posterior distribution is p | т, у ~ N(p, 1/(to + nr)), where fl is given in equation 
(3.6).
Try as we might, it would be impossible to obtain the marginal posterior for 
т | y, under the assumption of prior independence that we have made. Thus the 
plan now is to obtain the conditional distribution of т | д, у, which is quite easy, 
as we will soon see. As it turns out, if we can sample from the two conditional 
posterior distributions, we can obtain a sample from the joint posterior, р(д, т | у), 
and consequently we can numerically approximate the joint posterior and various 
parameters of interest. Throughout the book, these will be called “full conditional 
distributions.”
Using the joint likelihood, expression (3.3), times the prior for т gives
р(т\р,у) ос тп/2е-^<п('х-»)г+^"=1(^"®)г}тс-1е-'г</
= Tc+n/2-1 e-r {d+n(M-p)2/2+E,n=1 
—p)2/2}
which is the kernel of a gamma distribution. We thus have
т | p, у ~ Ga (c + n/2, d + n(p - p)2/2 + £(т/< - p)2/2^ . 
(3.9)
As a preview of how this posterior distribution can be used for inference, consider 
the following algorithm, (i) Select initial values (p(0\-r<0>). (ii) Sample | 
from its normal distribution, followed by sampling | p^\y from its gamma 
distribution, (iii) Sample p^ | т^\у from its normal distribution, followed by 
sampling t® | from its gamma distribution. Continue sampling from the 
two full conditional distributions using previous iterates for conditioning until you 
have a sample of size M, {(р^,т^) : i = 1,...,Л/}. The later samples, after 
what is called a “burn-in,” in this sequence will be random iterates from the joint 
posterior. This overall procedure is called Gibbs sampling, which we discuss thor­
oughly in Chapter 4. Gibbs sampling is a particular type of Markov chain Monte 
Carlo (MCMC) sampling that facilitates modern Bayesian methods, allowing one 
to carry out inference with many types of complex statistical models and inferential 
problems, including the present illustration.
♦Prediction. We discuss both independence and dependence priors, with normal 
and gamma priors on p and т in the former case, and with normal-gamma priors 
in the latter case. We first consider the case under the independence prior with p | 
т ~ iV(/7o, 1/tq). Simplifying notation, we denote the posterior distribution given 
in equation (3.6) as N(/ii. 1/ri). For further simplicity, we denote the predictive 
distributions with respect to the prior and the posterior as follows:
p(; | г. t) = f p(z | r. p)p(p | r, r) dp
dp.

Fundamentals II: Models for Exchangeable Observations 
55
for r = 0,1, respectively: namely, p(p | r = 0,r) = 
| r). p(z | r = 0. r) = p(c |
t), and p(p | r = l,r) = p(p | т,у), p(z\r = l,r) = p(z | r.y). We obtain 
p(z|r,r)oc i е-|{т(г-м)2+тг(м-мг)
*}
J-oo
Recognizing the exponent as the sum of two quadratics in p, we can apply the 
complete-the-square technique given in equation (3.4) but with the different com­
ponents. We obtain
р(г|г,т) « 
d/J
where
p(z) = T + r z + T + r ^r'
which does not involve p. The third line follows from the second, because the 
integrand in the second is just the kernel of a normal density for p in which the mean 
and variance are free of p, and the variance is free of z. The constant of integration 
for that density is у/2И/у/(т + rr), and dividing by it makes the integral equal 
to 1. Thus multiplying and dividing the integrand by the constant of integration 
results in just the constant of integration, which is free of z, and thus we have 
proportionality at line three. We recognize the final form in line three as the kernel 
of a normal density. We have thus established that
Z | г, т, у ~ N(pr, a2 + a2),
since the posterior precision is
ттг 
1
т + тг 1/т + 1/тг'
Thus the variance, given r, is 1/r + 1/тг = u2 + a2.
We now consider the case with unknown t. We already know that this prob­
lem is analytically intractable in terms of identifying the joint posterior under the 
independence prior. This is also true in the r = 0 case. Our solution to analyt­
ical intractability is to sample from the full conditional distributions p(p | r,r) 
and p(r | r,p), resulting in the MCMC sample {(р(1\т(г)) : i = 1,..., M}, where 
we drop the subscript r to ease the notation. For the predictive distribution, we 
sample Z*  | г,р^,т^ ~ 
1/т^) for i = 1,...,M. This results in a sample,
{ZB/+1, ZBI+2,..., ZM} (BI is burn-in), from the marginal predictive distribution 
p(z) when r = 0, and from the predictive distribution with pdf p(z | y) when r = 1. 
This sample can be used to obtain a smoothed histogram as an approximation 
to the actual marginal predictive or predictive densities, respectively; the median 

56 
Bayesian Thinking in Biostatistics
of these iterates is a numerical approximation to the median of the appropriate 
predictive distribution, etc.
For the conjugate (dependence) prior for (/z,r), we only consider the r = 1 
(posterior) case. By expression (3.5) with r0 = кт, we have д | т,у ~ N(ji, 1/[(A: + 
n)r]). Then, since Z - у | т, y,y ~ N(0,1/r), we know that Z - у is independent 
of у when т is known, and thus
Z | т,у~ (Z-y) + y | r,y^N^y,^ 
+ 
•
Recall that т | у ~ Ga(d,d'). Then we can calculate
p(z 11/) = f P(z I У)р(т I y)dr
ОС У rl/2e-f (^-M)2/[l + l/(fc+n)]rC'-le-rd'dr
= у rc' + l/2-le-r{d'+(i-M)2/[2(l + l/(fc+n))]}rfr
oc l/{d' + (z - Д)2/[2( 1 + 1/(к + n))]}(2c'+1>/2
1
* (i ■ 
(^-M)2/y , i(2c,+1)/2’
V + {l + l/(fc+n)}d'/c' J
where we have used equation (3.7) to obtain the second to last term. The result is 
proportional to a Student’s pdf, namely,
In the special case of the reference prior referred to above, we obtain Z | у ~ 
t(n - l,y, (s')2(l + 1/n)). Here again, (s')2 = ns2/(n - 1). In either case, we can 
obtain a 95% prediction interval for the future Z. With the reference prior, the 
interval is 
______
У ± /0.025^ \/l + 1/n,
which is again the standard frequentist formula for a prediction interval in this 
setting. As we already indicated, Bayesian and frequentist interpretations of this 
interval are radically different. We simply say that we are 95% sure that the future 
value will reside in this fixed interval.
Remark. Observe that the conjugate case does not reduce to the reference prior 
case for any choice of parameters for the prior. If we let к = c = d = 0, we get 
2c' = n.d' = ns2. which results in a t(n, y, s2(l + 1/n)) predictive distribution.
Example 3.3. Data Analysis. In this example, we look again at the VetBP 
data set. We make inferences about average baseline systolic blood pressure of these 
veterans. We assume a N(y. a2) sampling distribution for the baseline SBPs of these 

Fundamentals II: Models for Exchangeable Observations
men. For illustration, we consider cr2 to be known since the posterior distribution 
is available analytically. If the variance in the data is unknown, inference requires 
computational methods that were briefly discussed just after expression (3.9) and 
which we fully cover in the next chapter. We will show how to carry out inference 
for the unknown mean and variance case after presenting those methods.
4The sample average is adjusted for the age distribution in the U.S. in the year 2000. Such 
adjustment makes it easier to make comparisons across time or place if one uses the same age 
distribution each time. In this way, any age-associated changes will not affect the comparison, even 
if one population is older than the other in the comparison.
5As with the means, these percentiles are age adjusted, but we assume that this makes little 
difference.
6This estimate is based on a much larger sample than the current sample. But we remind the 
reader that we are in effect pretending that we know a for the purpose of illustration at this stage 
in the book.
We need a prior for our uncertainty about ц, and we need to specify a value for 
the known variance. There are surveys that provide information about the distri­
bution of blood pressures among men in the U.S. The National Center for Health 
Statistics (NCHS) published a report with the distribution of blood pressures among 
U.S. adults during the beginning of the twenty-first century [355]. From this report, 
we gather that the mean SBP for men older than 18 years is around 124 mm Hg, 
based on a sample of 10,142 men.4 Since the age distribution among our veterans 
may not be the same as that in the general U.S. population in 2000, we allow for 
greater uncertainty about the mean specification of 124 mm Hg.
The document reports a standard error of 0.3 mm Hg for the mean SBP. This 
standard error leads to a 95% confidence interval for the mean SBP among U.S. 
men older than 18 of (123.4,124.6) mm Hg. We choose to inflate the reported 
standard error by a factor of 25 to characterize greater uncertainty in mean SBP. 
This inflation of the standard error leads to a prior standard deviation equal to 
7.5 mm Hg. Thus, we could choose a prior N( 124,56.25) distribution for the mean 
SBP. Using the notation in expression (3.5), we have цо = 124 mm Hg, tq = 
1/56.25 = 0.0178 in the prior specification for the mean SBP.
We specify the known variance of SBP in the population to be similar to the 
variance in the report from the NCHS. The latter also provides percentiles for blood 
pressures.5 We obtain a robust estimate of a based on the interquartile range (i.e., 
the difference between the 25th and 75th percentiles of the normal distribution). 
For a normal distribution, the interquartile range is 1.34 cr. The 25th and 75th 
percentiles of SBPs among U.S. males aged 18 years and older are 113 and 131 mm 
Hg, respectively. This leads to specifying known a = 13.43 mm Hg, or cr2 = 180.44.6
For this analysis, our model is given by
Prior: 
/х~ЛГ( 124,56.25),
Sampling distribution: Yi | p, ~ N(p,, 180.44).
Using the formulas for a normal sampling distribution with known variance and 
normal prior for the mean given in equation (3.6), we can immediately write out

58
Bayesian Thinking in Biostatistics
the posterior distribution as
. N /(404 x 134.5/180.44) + (124/56.25) __________ 1__________ \
M 1 У ~ 
\ 
(404/180.44) + (1/56.25) 
’ (404/180.44) + (1/56.25))
or
ц I 7V( 134.41,0.44).
We see that the posterior mean is close to the SBP sample mean even though we 
started with a prior distribution centered at 124 mm Hg.
Another researcher may think that a sample of male veterans may tend to be 
older than the general population of adult men who are older than 18 years. In line 
with this thinking, the researcher may think that the average SBP for the veterans 
will likely be higher than the average in the NCHS report. This researcher may 
specify their prior distribution for the mean SBP as follows.
There are categories for SBP with ranges that allow for diagnosing hypertension. 
Health authorities suggest that “normal” SBP is 120 mm Hg or below, that so-called 
“pre-hypertension” is SBP in the range of 120 to 139 mm Hg, and hypertensive 
individuals have SBP of 140 mm Hg or higher. For our population of veterans, 
the new researcher might take 120 mm Hg as a lower bound of a likely mean SBP 
values among the VetBP sample and 140 mm Hg as an upper bound, to allow 
for an expected increase in SBP with age, giving (120,140) as a prior 95% credible 
interval for y, based on this information. Then a reasonable prior specification would 
have a mean of 130 mm Hg and standard deviation equal to 10/1.96 = 5.1 mm Hg, 
resulting in a N(130,5.12) distribution.
Again, we will use the variance of the population SBPs (i.e., 180.44) that we 
calculated from the NCHS report as the variance in our VetBP data, treating it 
as known. For this researcher, the prior model in the notation of equation (3.5) is 
Ho = 130 mm Hg and to = 1/26.01 = 0.0384 in the prior for the mean SBP in our 
population, or н ~ N(130,26.01). We obtain the posterior distribution as
/(404 x 134.5/180.44) + (130/26.01) 
1 
\
(404/180.44) + (1/26.01) 
’ (404/180.44) + (1/26.01) /
or
/z | у ~ 7V(134.42,0.44).
Again, the data dominate and the posterior mean is very close to the sample mean 
SBP.
What if we simply plug in the sample variance from the VetBP sample, treating 
it as known? This is not appropriate since it is an estimate based on the data we 
are analyzing.' However, we can sec; how changing the data variance changes the 
inference. In the data, the variance is 242.24 (mm Hg)2, which is around 134% 
of the value we used in the previous calculation. In other words, our data show
'Using the VetBP data to specify <r amounts to using the current data in specifying the prior. 
Recall that prior information must be independent of the current data. 

Fundamentals II: Models for Exchangeable Observations 
59
greater variability (less precision) than the survey's data in the report. Will this 
lower precision in the data lead to greater dominance of the prior in our inference?
Using calculations with the prior у ~ 7V(130.242.24). we obtain /z | у ~ 
7V(134.39,0.59). Despite the larger variance for the data in this calculation, poster­
ior inferences hardly change. The posterior mean is still very close to the sample 
mean, and the posterior standard deviations change from 0.66 to 0.77, reflecting 
the greater variability we assumed to be in the data. This example illustrates an 
important lesson that, when there is a large sample size relative to the uncertainty 
in the prior distribution, the data will dominate the inference. In other words, the 
prior distribution has less influence on the inference as the sample size increases.
3.2.3 Poisson Distributed Exchangeable Count Observations
The Poisson distribution is often suitable as a model for count data, where each 
observation is a non-negative integer, especially when the counts are small and can 
equal zero with a non-zero probability. This type of count data arises frequently 
in biostatistical applications. Some examples are the number of doctor visits in a 
year paid to individuals on a patient panel, the number of ear infections during a 
six-month period among children between 2 and 4 years of age, and the number of 
lymph nodes examined during surgery for breast cancer.
The Poisson distribution has a single parameter, the rate at which “events” 
occur per unit interval. The unit interval could be time, if one is counting the 
number of events over a specified period of time; space, if one is counting the 
number of occurrences of some “event” over a length; area or volume, if within 
such units one is counting events. We say time to be specific, and let Л be the 
expected number of events per unit time. Assumptions for the Poisson were given 
in Section 3.1.
If we have a sample of n conditionally iid Poisson variates,
n xyi
Lik(X) oc p(yi,... ,yn I Л) = П-Ге"Л a ^=1Vie~nX.
^=1 yi'
The form of likelihood suggests that the gamma family will be conjugate. With 
Ga(ap, bo) as the prior, we get
р(Л | у) ос Лао-1е_ЬоАе_пЛЛ^<‘=‘Vi
(X д(ао+Е?=1 yd-lg-Mbo+n),
which is the kernel of a Ga(ai, bi) distribution with ai = a0 + ny, bi = bp + n. 
(Note that ny = Y>i=i У*-)
The posterior mean is
QQ + E?=i Vi = ( bp \ /ао\ + / n \ _ 
bp + n 
\bo + n) \bp/ \bo + n) V’
which is a weighted average of the prior mean and the sample mean (again a shrink­
age estimator). The sample size and bp play comparable roles in the weighting. The 

60
Bayesian Thinking in Biostatistics
posterior mode is (a] - l)/t>i, and the posterior variance is O]/b?. The median 
and a 95% PI can be obtained using R with the command qgamma(c(0.025, 0.5, 
0.975), al, bl).
Example 3.4. Women with tuberculosis receive multiple diagnostic chest X-rays 
to monitor their disease. Radiation exposure, however, is associated with a risk 
of developing cancer. A group of researchers set out to assess the risk of breast 
cancer among women who are exposed to radiation. We use a Poisson model for 
the number of incident breast cancers among a cohort of women with tuberculosis.
We note that incidence involves counts of the number of cases over time at risk, 
whereas prevalence simply involves counts of the number of cases among a group 
at a particular point in time. Thus, the unit of measurement for incident breast 
cancers in this example is a person-year of exposure to chest X-rays, rather than 
the number of cases per 1,000 women at a static point in time (which would be a 
measure of prevalence).
The total exposure for women in this study is the sum of individual exposures, 
measured as years for each woman. The researchers determined that this cohort’s 
total exposure to diagnostic X-ray imaging, denoted E, was 28,010 person-years. Let 
Y be the number of incident breast cancers among these women with tuberculosis 
who received multiple X-rays of the chest. In this study, there were у = 41 cases 
of breast cancer. Let A denote the rate of breast cancers per 10,000 person-years of 
exposure to diagnostic X-rays for tuberculosis. The observed breast cancer incidence 
rate for these women is 41/2.801 = 14.6 cases per 10,000 person-years. The sampling 
distribution is Y | A ~ Po(AE).
Based on information from the general population of women, the researchers 
assessed an a priori 95% probability that the rate would be between 5 and 17 
cases per 10,000 person-years of exposure. If one treats these numbers as the 0.025 
and 0.975 quantiles for prior distribution for A, a Ga(10,1) distribution provides 
a reasonable approximation for characterizing this prior information about A. In 
particular, qgamma(c(0.025,0.975), 10,1) = (4.8, 17.1), which was obtained 
by trial and error using R.
With the prior distribution A ~ Ga(10,1), the prior mean is 10 cases of breast 
cancer per 10,000 person-years of exposure and P(4.8 < A < 17.1) = 0.95. With this 
prior and these data, the posterior distribution for the incidence rate of breast can­
cers among women with tuberculosis exposed to repeated diagnostic X-ray exams 
is Ga(10 + 41,1 + 2.801). The posterior mean is 14.7 cases per 10,000 person-years, 
the median is 13.4. and the posterior 95% credible interval is (10.0,17.3) cases per 
10,000 person-years.
Of considerable interest is the comparison of this rate to the background rate 
of breast cancer in the general population. Suppose that there was a 95% a priori 
science-bast'd belief that the background rate was in the interval (5, 11). Then we 
would have considerable evidence, reflected in the statement P(A > 11 | data) = 
0.91. that the rate among women exposed to this kind of radiation is higher than the 
background rate. In a later chapter, we consider the formal statistical comparison 
of rates of risk when we have data for both kinds.

61
Fundamentals II: Models for Exchangeable Observations
♦Prediction. The predictive density, p(z | y). can be obtained as
P(z | y)
Jo 
Jo z\ Г(О1)
b? Г(г + щ)
r(z + Q1) ( h V1 / _ V 
z! r(ai) \ 1 + bi J \ 1 + bi ) ’
z'.r(fli) (l+bO^0*
z = 0,1......
This is the pdf with support on the non-negative integers, the same as a Poisson, 
and is known as the negative binomial distribution. It is easy to see that if we were 
interested in computing the prior predictive distribution p(z) (i.e.. the marginal 
distribution of z, also sometimes called the marginal likelihood), the calculation 
would be very similar. We would replace p(A | y) by p(A), leading again to a 
negative binomial distribution with and bi replaced by prior parameters ao and 
bo, respectively.
3.2.4 Exchangeable Exponentially Distributed Time-to-Event Observa­
tions
Time-to-event data are commonplace in medical applications. Examples include 
time to death after bone marrow transplantation, time to recurrence after an initial 
treatment for breast cancer, and time to complete recovery after knee replacement 
surgery. Such data are also known as survival-time data, and statistical method­
ology in this context is called survival analysis. Historically, these methods first 
addressed time to death after treatment for some life-threatening conditions. While 
such studies abound, the techniques are more widely used to analyze the times to 
any event from a well-defined moment such as a surgical treatment.
A simple model for exchangeable time-to-event data is the exponential distri­
bution. While this distribution is limited in flexibility for practical applications, it 
gives us a good starting point from which to build. This is a one-parameter dis­
tribution. Let T | Л ~ Exp(X), where E(T | Л) = 1/Л. This expectation has time 
units (e.g., hours, days, months). Suppose that we planned to observe a sequence of 
times until events for a series of patients. Denote the potential list of times to event 
as Ti,T2,..., with Tj | Л ~ Exp(X) random variables. For example, these could be 
times until a patient is able to walk independently after undergoing hip replacement 
surgery, with 7\ the time until the first patient can walk independently, T2 the time 
until the second patient can walk independently, etc.
Using the notation for the exponential distribution in the table of distributions 
in Appendix B, we write the likelihood as
Lifc(A) oc p(ti,..., tn | A) = U Ae-At< oc Xne~x E"=
*
.
This form clearly suggests that the gamma family will be conjugate. With A

62
Bayesian Thinking in Biostatistics
Ga(ao,bo), we have
p(A | t) ос дао-1е-ь°Адпе-АЕ?=1‘i 
СК дао+п-1е-А(Ьо+Е>"=1 *•),
which is the kernel of a Ga(ai, £7) distribution with ai = o,q + n and bi = bo + nt, 
where t is the sample average of the follow-up times.
Inferential interest in time-to-event analysis will generally center on the median 
time and the survivor function, namely the probability of surviving (i.e., not ex­
periencing the event) at least t years after diagnosis for various choices of t. The 
median survival time is obtained by solving
P(T > m | A) = e~Xm = 0.5 О m =
The survivor function is
S(t | A) = e~Xt.
While we could easily obtain formulas for E(A | t) and E(e~xt | t), we can more eas­
ily find the median and a 95% PI for these quantities. First, we get the median and 
a 95% interval for A using the command qgamma(c(0.5, 0.025, 0.975),al,bl) 
in R. Then we simply transform these values, since all parameters of interest are 
monotone functions of A.
For example, let (m, I, u) be the posterior median and posterior lower and upper 
limits for A. Let 7 = e~xt for a fixed value of t of interest. Then since
0.5 = P(A > m 1t) = P(e"At < e-ATh 1t),
we must have the result that e~mt is the posterior median of 7. We similarly obtain 
the 95% interval for 7, (e~ut,e~u), since the survivor function is monotone and 
decreasing in A. Results are similarly obtained for the median and mean times to 
event.
The mean of the posterior for A is (ao + n)/(t>o + nt). But we would make 
inferences for A, the rate of events, using posterior quantiles as discussed above. 
The general topic of survival analysis is covered in Chapters 11 and 12.
Example 3.5. Leukemias are cancers that are associated with different types of 
blood cells. Many different types of blood cells are produced in the bone marrow, 
and one can classify them broadly into myeloid cells and lymphocytes. Lympho­
cytes are mature white cells that fight infections. Myeloid cells include white blood 
cells (other than lymphocytes), red blood cells, and cells that produce platelets 
(megakaryocytes). Whereas immature blood cells (called blasts) divide quickly to 
produce more mature cells that the body needs for normal functioning, leukemias 
are characterized by blasts continuing to divide rather than stopping to become 
normal healthy white blood cells. Acute myelogenous leukemia (AML) is a cancer 
that starts with immature myeloid cells and produces an overabundance of white 
blood cells. The disease progresses very quickly if left untreated, which is why it is 
called an "acute" leukemia.

Fundamentals II: Models for Exchangeable Observations
63
Feigl and Zelen [107] provide data from a study of 33 patients who died of 
AML. The goal of the paper was to show how one might analyze the association 
between a baseline characteristic, such as white blood cell count (WBC) at the 
time of diagnosis, and time to death. In addition to WBC. the data also include a 
variable called POS, for positive. This is a variable that takes the value 1 or 0 and 
indicates the presence of so-called Auer rods or of leukemia cells having significant 
granulature (POS = 1). We will analyze the survival times of the 17 patients whose 
bone marrow at diagnosis had POS = 1. Analyses later in the book will account 
for the effect of WBC and POS on survival.
As we have seen, a gamma prior distribution is mathematically convenient for 
the rate parameter, A, of the Exp(X) sampling distribution. We adopt a Ga(a. b) 
prior.
Let Ti be the time (weeks) until death for the zth patient (i = 1,..., 17). Since 
these patients have acute leukemias, a reasonable a priori estimate of the median 
time until death for similar patients, ln(2)/A = 0.69/A, could be 6 months or 26 
weeks. Since the survival times in these data are in weeks, the rate parameter A is 
in units deaths per week. A reasonable prior estimate for A is Ao = 0.69/26 = 0.027 
deaths per week.
If we are 90% certain that the median time to death is somewhere between 3 
months (approximately 13 weeks) and 18 months (around 78 weeks), we can find a 
Ga(a, b) distribution that reasonably matches our prior uncertainty. We note that
0.9 = P(l < 0.69/A < u) = P(0.69/u < A < 0.69/1),
since the median time to death is a monotone and decreasing function of A. Thus 
setting I = 13, u = 78, we obtain the prior 90% probability interval (0.0089,0.053) 
for A.
Using a little trial and error in R looking for an a and b that result in gamma 
distribution quantiles that match these, we obtain the a priori median of 0.027 and 
a 90% PI of (0.0089,0.0521),8 which gives numbers very close to the ones specified 
above. We thus take a Ga(3.3,110) prior for A. Using this prior, and converting 
from rates of death per week back to median times to death, we get a prior median 
of 25.5 and a 90% PI for median time to death of (11.3, 77.8),9 which is quite close 
to our original specification on this scale.
8qgamma(c(0.05,0.5,0.95),3.3,110) = (0.0089, 0.0270, 0.0521)
90.69/qgamma(c(0.05,0.5,0.95),3.3,110) = (77.8, 25.5, 11.3)
l°qgainma(c(0.025,0.5,0.975) ,20.3,1172) - (0.0106, 0.0170, 0.0256)
The sum of the survival times among the 17 AG patients equals 1,062 weeks. 
Since we assume a priori that A ~ Ga(3.3,110), we immediately determine that the 
posterior distribution for A is Ga(20.3,1172). The posterior mean is 20.3/1172 = 
0.0173 deaths per week.
Using R again, we obtain the posterior median and a 95% interval for A, namely, 
0.0170 and (0.0106, 0.0256).10 So we have
0.95 = P(0.0106 < A < 0.0256 1t) = P(26.9 < 0.69/A < 65 11).

64
Bayesian Thinking in Biostatistics
Nfe are a posteriori 95% certain that the median time to death is between 26.9 and 
65 weeks, or equivalently, between 0.52 and 1.25 years. The posterior median rate of 
deaths per week is 0.0170, so the posterior mean and median are virtually identical. 
While the median time to death can be obtained as 0.69/0.0170 = 40.6,11 it is not 
possible to obtain the posterior mean time to death using this output since the mean 
of 1/A is not equal to 1 over the mean of A. We could, however, easily approximate 
E(l/A | data) by a simple simulation from Ga(20.3,1172). For example, the R 
command mean(l/rgamma(1000,20.3,1172)) resulted in E(l/A | data) ~ 61.4. 
For the median time to death, 0.69/A, we get E(0.69/A | data) = 40.5 and posterior 
95% interval (26.9,65.0).12
" There is rounding error here since we rounded all quantiles to four decimal places
l20.69/qgamma(c(0.025,0.5,0.975),20.3,1172) = (65.0, 40.5, 26.9)
In a similar fashion, we obtain inferences for the two-year survival rate, e-104A, 
using R functions rgammaO, mean(), and quantile() as P(e-104A | data) = 0.17 
and P(0.07 < e-104A < 0.33 | data) = 0.95. So we are 95% certain that between 
7% and 33% of individuals in this population will survive at least 2 years.
Since the natural purely data-based estimate of A is 17/1062 = 0.016, and our 
Bayesian estimate is 0.017, and since our prior estimate was 0.027, we see that even 
with just 17 patients, the data dominate the estimate over the prior distribution.
♦Motivation for Exponential Distribution: Relationship to the Poisson. 
Let N(t) to be the number of “events” that have occurred by time t > 0 under the 
conditions described in Section 3.1 for the Poisson distribution to hold for count 
data.
Let Ti denote the time between the (i — l)th and ith events in this event gen­
erating process. For the sake of being concrete, suppose that the event of interest 
is a seizure in a patient with brain cancer and we are measuring the time between 
successive seizures. Then Ti is the time between the (i — l)th and ith seizures, and 
N(t) is the number of seizures by time t. We have N(t) = 0 if Ti > t, and N(t) = 1 
if Ti < t and Ti + T2 > t. Generalizing, N(t) = i if Ti - * an<^ i Ti > 
for i = 1,2,.... Then
7V(t) | A~Po(At)
so that E(7V(t)) = At, and if we let t = 1 unit of time, it follows that F(N(1)) = A. 
The units for A are “events per unit time,” and the units for 1/A are “time per 
event.” Note that if the Poisson assumption holds, then
S(t | A) = P(Tj > t | A) = P(7V(t) = 0 | A) = e-At,
since the only way that a wait time for an event can be longer than t is if no events 
occur before time t. The pdf of T\ is the derivative of this expression for the cdf 
and is
p(t | A) = Ae-At/(0.oo)(t).
The collection {A'(f) : t > 0} is called a Poisson process with rate A, and 
the result implied here is that the waiting times. T, between events in a Poisson 

Fundamentals II: Models for Exchangeable Observations
65
process are iid Exp(X) conditional on A. The reverse implication is also true: in an 
infinite sequence of waiting times with 7} ~ Exp(X). if jV(t) is the count of event 
occurrences up to time t, {N(t) : t > 0} is a Poisson process with rate A (Ross, 
2014 [275]).
♦Prediction. A future observation, Z, can be predicted using p(z | t). where
which is the pdf of a Pareto distribution of the second kind.
Perhaps of greater interest is the predictive survival distribution
p(Z > z | t) = [ p(Z > z | A)p(A | t)dA = [ e~Xzp(X | t)dX 
Jo 
Jo
where we assume, as usual, conditional independence of future data and past data
given A. Then
P(Z > z 11) =
iarl z>oo
-H- / Xa'-xe-^z+b^dX 
r(ai) Jo
bf1 T(ai)
IW+z)*
We note again that the prior predictive calculation would be very similar, replacing 
p(z | t) and p(A | t) by p(z) and p(A), respectively. The result is again a Pareto of 
the second kind with replaced by prior parameters (ao,bo).
3.3 
More  Flexible Models
*
All of the models considered in the previous section are termed parametric, and 
except for the Bernoulli, they have some restrictions. The normal distribution, for 
example, is unimodal and symmetric, and the exponential pdf has a mode of 0 and 
is monotone and decreasing; both models are very restrictive for many types of 
data arising in practice. The Poisson model is restricted in the sense that the mean 
and the variance are the same. In this section we briefly consider a broad class 
of distributions for data with few restrictions. In other words, we discuss a flexible 

66
Bayesian Thinking in Biostatistics
class of models that is often termed nonparametric. But “nonparametric” is actually 
a historical misnomer, since more flexible models are actually “richly parametric,” 
meaning that they have many more parameters than traditional parametric models.
3.3.1 Mixture Distributions
To gain more flexibility, mixing distributions to generate other distributions is a 
fairly straightforward and highly useful idea. Consider two densities, /j(-) and /2С), 
with a common domain where the densities are strictly greater than zero. Then 
+ (1 -p)/2(-) is also a density on this domain for 0 < p < 1. While mixtures 
can be made from any two densities on a common domain, it is useful to choose 
the components of the mixture from a parametric family. The normal family is 
particularly fruitful in this regard. Figure 3.3 shows some mixture densities made 
with two or three components. The thickest line represents the mixture density and 
all other lines the components. It is clear that much flexibility in the shape of the 
density is gained by mixing just a few normals. In general, we can make a finite 
0 
5 
10 
15 
20 
25 
30
FIGURE 3.3: Some mixtures of normal densities.

Fundamentals II: Models for Exchangeable Observations
67
mixture of m parametric pdfs and write
Р(У I 
= J2pip(p | Oi).
We would need to place prior distributions on the Ot and the p,. Since the p, 
must sum to 1, a natural choice would be an m-dimensional Dirichlet distribution 
Dm(a\,..., am) (see Appendix B); in the m = 2 case, the Dirichlet is simply a 
beta distribution, Ве(о],а2).
A possible choice for the prior on the Oi might be ~ G for a fixed known 
distribution G that is defined on 0. There are many possible choices. The idea 
here is to convey the sense of flexibility that is possible when making a mixture of 
parametric distributions.
If we pick a common a > 0, and select the Dm(a/m, a/m,..., a/m) distribution 
for the vector of weights, and if we consider an indefinitely large m, we obtain an 
amazing result: the induced prior distribution on the unknown G is approximately 
distributed as a Dirichlet process [108]. The next subsection describes some details 
of such a fruitful way of specifying mixtures to gain great flexibility.
3.3.2 Dirichlet Process Mixtures
As before for parametric models, consider a family of distributions, pe(-), indexed 
by a parameter в. As an example, we can think of the normal family TV(p,<72) 
indexed by the two-dimensional parameter в = (р,ст2). We now model successive 
observations as
Vi\0i ~ PoM, г = 1,2,...,
Bi\G ~ G(-), г = 1,2,...,
where G is unknown and needs a prior. This specification of G, or its prior, will 
determine how flexible the mixture density will be. One particular choice for G has 
proved to be very useful in practice. It is called the Dirichlet process (DP) [108]. 
It generates 0s from a random distribution G on 0 (the space of possible values of 
0s).
We now give a heuristic and constructive description of the DP. Begin with a 
single fixed distribution Go on О and a scalar variability or concentration parameter 
a > 0. Go is called the “base” distribution. We need two more ingredients to 
proceed. Let
0i,02)... | Go ~ Go and Vj,V2,... |a~ Be(l,a).
Both are sequences of iid random variables, and these two sequences are independent 
of each other. The first sequence is a sample of 6s from the base distribution, and the 
second is a sequence of random variates that will be used to construct the weights, 
Pi,p2,.... Consider any event A in 0. The DP generates a random distribution G, 

68
Bayesian Thinking in Biostatistics
and we start by thinking about the random probability of the event A, G(A)- We 
can describe the distribution of G(A) by writing
gw = f;
Jt=l
where = means “equal in distribution,” and <5®(Л) is an indicator function that 
equals 1 if в G A and 0 otherwise. The weights in this expression are given by
p1 = V1,p2 = V2(l - Vi),. •. ,pk = (1 - Ц)(1 - V2) • • • (1 - П-0П,....
Since the Vk and 0k are independent of each other, the pk are independent of the 
0k, leading to
= EWWM = E(pk)E(IA(Ok)) = E(pfe)G0(A)
for all k. We argue below that SfcPfc = 1, so that
E(G(A)) = G0(A)E pj = G0(A)
since the expected value of a sum is the sum of expected values when these ex­
pectations are finite.
While it is not easy to show, it is true that
G(A)~ Be(aG0(A),aG0(Ac)),
which obeys E(G(A)) = G0(A). In addition, Var(G(A)) = GO(A)(1 - С0(Л))/(а + 
1). We say that the random G is “centered” on the fixed distribution Go and that 
G ~ DP(a, Go). Observe that the magnitude of a determines how concentrated the 
random G is about Go- If a is very large, then G will be very close to Go-
The expression above is called the Sethuraman “stick-breaking” representation 
of the DP [291]. It is a randomly weighted average of random point masses. The 
random weights (p,) are obtained by randomly breaking a stick (of original length 
1) and its successive remnants after keeping one piece of each successive break. 
Specifically, Ц is the first break of the (0,1) stick, and 1 - Ц is length of the first 
remnant. We keep the Ц piece, call it pi, and break the remnant of length 1 - Ц in 
two, according to the proportion V2. We keep the new piece of length V2(l - Ц), call 
it p2, and break the remaining piece, which has length (1 - V2)(l - Ц). We continue 
in this fashion, keeping one piece and breaking the remaining piece, so that at the ith 
break we have pieces of length {Ц, V2(l - Vi), V3(l - V2)(l - Vj),..., Ц П}=1C1 _ 
Vj)}. The elements of this sequence are {pi,p2, • • • ,Pi}. After the ith break, the 
remnant has length П^=i С1 _ Ki)- not surprising that by breaking off enough 
sticks, the })j will sum to 1.
We thus have a model for datum Y that has random pdf
p(y | ci, G) = 52PiP(y I 
(3-10) 

Fundamentals II: .Models for Exchangeable Observations
69
which is an infinite mixture of randomly weighted parametric densities that have 
parameters that are randomly selected from a random G centered on Go- This 
model for the observable Y is called a Dirichlet process mixhire (DPM) model.
In general, mixtures of densities have great flexibility. Finite mixtures are often 
used to achieve that flexibility, but it is necessary to select the number of terms in 
the mixture. It turns out that in practice we will have to truncate the above sum 
to be finite, but that this particular choice of mixture model allows the data to 
decide how many terms in the mixture will matter. Alternatively, we can use the 
approximation by Ishwaran and Zarepour [174] that was mentioned above.
The full model for a sample of n exchangeable Yi is
F; |0, ~dp(-|0Д 
| G ~ G, G~DP(a, Go).
Inference and prediction for such models can be carried out by computational meth­
ods, mainly relying on sampling any unknowns of interest conditioned on the data. 
There are many additional uses of the DP and the DPM; this one has been presented 
to give the basic ideas involved.
3.3.3 Computation via DPpackage
Computation for many nonparametric models is now available from several evolving 
resources distributed by academic researchers. One such resource is the R package 
named DPpackage [176, 175] originated and maintained by Alejandro Jara with 
contributions by several other authors. For time-to-event data, the package named 
DPWeibull [294] is useful.
Example 3.6. Let us return to the leukemia data in Example 3.5. We modeled the 
data with an exponential distribution there. Using the 17 observations available, 
we constructed a 95% posterior probability interval for the median from 26.9 weeks 
to 65 weeks. The posterior mean survival probabilities and pointwise 95% intervals 
for these are shown in Figure 3.4a. Using the flexible models of this section, we 
obtain the corresponding plot shown in Figure 3.4b. We can see that the shape of 
the curves in (a) is dictated by the exponential model, whereas the shape in (b) 
is more responsive to the local variation in the data points. Notice that there are 
appreciable differences early on the time axis. Also, a 95% posterior probability 
interval for the median now is 38.8 weeks to 80.8 weeks. The exponential model 
is too restrictive and unsuitable for data of this type. We postpone until a later 
chapter the details of how such computations can be carried out.
3.4 
Recap and Readings
This chapter and the previous chapter have introduced the essential concepts and 
mathematical tools needed for Bayesian analysis in biostatistics. Probability models

70
Bayesian Thinking in Biostatistics
(a) Exponential
FIGURE 3.4: Survival function estimation with leukemia data, based (a) on the 
exponential distribution, (b) on the Dirichlet process.
(b) Dirichlet process
for data, knowledge distributions for unknowns, conditional probability, and Bayes’ 
theorem are central to Bayesian thinking. Bayesian theory and methods in general 
are introduced and discussed in many other excellent textbooks, including those 
by Carlin and Louis [63], Gelman et al. [133], Christensen et al. [79], Robert [271], 
and Hoff [166]. Most of these books also address, to varying degrees, two topics 
that we do not cover here. These are: why we might choose Bayesian analysis 
over more traditional (or frequentist) methods, and a comparison of Bayesian and 
other approaches. Robert’s book most directly addresses the first and emphasizes a 
decision-theoretic approach. More advanced readings in this regard would include 
books and monographs by Berger and Wolpert [33], Bernardo and Smith [35], Berger 
[29], Savage [279], Kadane [196], and a volume in honor of James Berger [70]. Most 
of these require a good degree of mathematical preparation.
3.5 
Exercises
Exercise 3.1. Conditionally iid Poisson data. In the LE data for Dr. Yen’s 
study, the variable exam contains the number of lymph nodes examined during 
breast cancer surgery for 1.307 patients. For illustration, suppose these observations 
arise from a conditionally iid Poisson distribution. Suppose that the mean of this 
variable is 7.5 for these patients. Let /r ~ Ga(2.58,0.32) be the prior for the unknown 
Poisson mean ц of the population from which the 1,307 patients can be considered 
a random sample.

Fundamentals II: Models for Exchangeable Observations 
71
(a) 
Plot the posterior and prior pdf for ц on the same plot, and obtain the posterior 
mean, median, and a 95% probability interval for /t.
(b) 
Plot the predictive density for the number of nodes examined in a future ran­
domly chosen breast cancer patient from this population, and then obtain a Monte 
Carlo sample from the predictive distribution by first sampling from the posterior 
for /1 and then sampling from the conditional distribution for Z | //. (You might use 
R or some statistical package.) Use this sample to obtain a numerical approximation 
to the predictive mean, median, and 95% prediction interval for a future value, Z.
Exercise 3.2. Conditionally iid normal data. In the VetBP data set, consider 
the 404 baseline systolic blood pressure (variable SBP_00) observations to arise from 
the normal model. The data show a mean of 134.5 and a variance of 242.2.
(a) 
For illustration only, consider that the population variance is known to be 242.2. 
Use a normal prior for the population mean, p. ~ 7V(130,100), and with у = 134.5, 
plot the posterior and prior distributions of p. on a common set of axes, and obtain 
the posterior mean and median, and a 95% posterior probability interval for p..
(b) 
Plot the predictive density for the systolic blood pressure of a future randomly 
chosen veteran from this population, and obtain a random sample from the pre­
dictive distribution for a future Z to obtain a numerical approximation to the 
predictive mean, median, and 95% prediction interval.
EXERCISE 3.3. Conditionally iid normal data. In the VetBP data set, consider 
again the 404 baseline systolic blood pressure (variable SBP_00) observations to 
arise from the normal model. Assume that the population mean is known to be 
134.5. Assume the prior т ~ Ga(4,1000), and that ^^(.Уг ~ m)2 = 403 x 242.2 is 
observed.
(a) 
Plot the posterior and prior pdfs for т on a common set of axes, and obtain the 
posterior mean, mode, and a 95% probability interval for r.
(b) 
Plot the posterior and prior distributions of a on a common set of axes. You 
will need to transform to a = 1/^/(r) to obtain the precise pdfs for a.
(c) 
Plot the predictive distribution for the systolic blood pressure of a future ran­
domly chosen veteran from this population by first sampling from the posterior for r 
and then sampling from the sampling distribution for Z | t, to obtain a sample from 
the predictive distribution. Use that sample to obtain a numerical approximation 
to the predictive mean, median, and 95% prediction interval.
‘EXERCISE 3.4. Consider again the VetBP data set and the information from 
it, namely, the sample mean is 134.5 mm Hg and the sample variance is 242.2, for a 
sample of 404 vets. In the following, use the NoGa( 130,1/3,4,1000) prior on (jj,, t).
(a) 
Plot the marginal posterior pdf for ц.
(b) 
Compute the posterior probability that ц is between 132.5 and 135.5.
(c) 
Plot the posterior pdf for a. Use the usual transformation technique for a =

72
Bayesian Thinking in Biostatistics
(d) 
Compute the posterior probability that a is between 14.5 and 16.5.
(e) 
Simulate a Monte Carlo sample from the joint posterior for (g,r). Using that 
sample, obtain the approximate posterior probability that g is between 132.5 and 
135.5 and that a is between 14.5 and 16.5. Comment on how the answer here relates 
to parts (b) and (d).
Exercise 3.5. 
Show that ^,?=1(Уг ~ д)2 = n(y ~ M2) + E7=i(?A _ 3/)2-
Exercise 3.6. 
Let Fj,Уз be iid 7V(0, l/т), and assume the prior specification
r ~ Ga(2,2).
(a) 
Obtain and identify the precise posterior distribution for t.
(b) 
Suppose the sum of the squares of the observed yi is 10. Plot the prior and 
posterior pdfs on the same graph. Comment.
(c) 
Now plot the prior and posterior pdf for a = 1 /у/т on the same graph. Comment.
Exercise 3.7. Let X ~ Ga(a, b).
(a) 
Show that the transformed random variable cX ~ Ga(a, b/c) for a, b, c > 0.
(b) 
Argue that if a' is a positive integer then a Ga(a!/2,1/2) random variable is 
the same as a y2, random variable.
(c) 
Assume that 6 ~ Ga(10,20). Use the facts in parts (a) and (b) to derive an exact 
formula for a 95% probability interval for 0 that uses the appropriate quantiles of 
the appropriate y2 distribution.
(d) 
Obtain an exact 95% interval for 0 and for y/0 (e.g., with R).
’Exercise 3.8. Let Yj,Y2, ..., Yn be iid 7V(y, l/т), and let p(g,r) oc l/т, which 
is of course an improper diffuse prior.
(a) 
Derive the conditional posterior for g | r.
(b) 
Obtain the marginal posterior for g and identify it precisely.
(c) 
Using part (b), obtain a 95% probability interval formula using appropriate 
notation.
(d) 
Now obtain the marginal posterior for r, identify its distribution, and, using 
results in Exercise 3.6, obtain a 95% probability interval formula for т using the 
appropriate y2 distribution.
(e) 
Using part (d), obtain a probability interval formula for a = 1/^/r.
Exercise 3.9. Let 0 ~ Ga(a,5) and Y | 6 ~ Po(0). Also let Z | 0 ~ Po(0), 
independently of Y, conditional on knowing 0.
(a) 
Derive the posterior pdf for 0 | у and identify it.
(b) 
Obtain a simple formula for the marginal predictive probability, P(Z = fc) = 
$okc-oik\i)Wde for к >o.
(c) 
Obtain the predictive probability P(Z = к | y). Write this in a neat simple 
formula that can be interpreted.

Fundamentals II: Models for Exchangeable Observations 
73
Exercise 3.10. Let 0 ~ Be(a,6) and Y | 0 ~ Ber(0) . Also let Z | 6 ~ Ber(0). 
independently of Y, conditional on knowing в.
(a) 
Derive the posterior pdf for 0 | у and identify it.
(b) 
Obtain a simple formula for the marginal predictive probability. P(Z = k} = 
J0fc(l - ey-bp^de for k = 0,1.
(c) 
Obtain the predictive probability P(Z = к | y). Write this in a neat simple 
formula that can be interpreted.
Exercise 3.11. Let 0 ~ Be(l,5) for b > 0. Find b such that P(0 < 0.1) = c for 
c = 0.1.0.2,0.5. Using R or some other program, find P(X < c) for the three values 
of b obtained, where X ~ Be(l, b).
Exercise 3.12.
(a) 
Find a Be(a, 6) prior that has a mean of 0.5 and a 95th percentile of 0.8. So 
a/(a + b) = 0.5 and 0.8 is 95th percentile of the Be(a,6) distribution. Use trial and 
error.
(b) 
Repeat (a) but set the mode equal to 0.5. How different are the priors?
(c) 
Now repeat (a) but set the median equal to 0.5. How different are the priors?
Exercise 3.13.
(a) 
Find a Ga(a, 6) prior that has a mean of 10 and a 95th percentile of 20. So 
а/Ь) = 10 and, in R, qgamma(0.95,a,b) = 20. Use trial and error.
(b) 
Repeat (a) but set the mode equal to 10. How different are the priors?
(c) 
Now repeat (a) but set the median equal to 10. How different are the priors?


Chapter 4
Computational Methods for Bayesian 
Analysis
Bayesian inference statements stem from the data-informcd knowledge distribution 
(or posterior distribution) of the unknown quantities in the model. As introduced in 
Chapters 2 and 3, computing this distribution involves integration, often in a multi­
dimensional space. This chapter addresses how this can be accomplished, especially 
in the vast majority of models where closed-form integrals are not available. Sections 
4.1.1-4.3 introduce analytical, asymptotic (large-sample) and Monte Carlo sampling 
methods, respectively. Section 4.4 discusses the ground-breaking Gibbs sampling 
method and its generalization, Markov chain Monte Carlo (MCMC). Section 4.4.5 
deals with the issue of whether or not the Markov chain generated samples can be 
considered as “random” samples from the target (posterior) distribution. Section 
4.5 concludes the chapter with a recap and recommendations for further reading. 
Appendix C provides a brief introduction to software that makes it possible to carry 
out Bayesian inference in practice.
Bayesian inference statements all flow from the posterior distribution in various 
forms. Posterior expectations, medians and other percentiles and standard devi­
ations of unknowns are often of interest. We now address the three main approaches 
to calculating such quantities.
Whenever possible, it is useful to obtain the data-informed distribution in a 
closed-form expression as this generally simplifies computation. For likelihoods aris­
ing from some models, one can design a prior that leads to a posterior of the same 
form. Such priors are termed conjugate, as discussed in Chapter 3. There we en­
countered several such cases involving normal data, binary and Poisson count data, 
and exponentially distributed time-to-event data. In all of the conjugate cases con­
sidered in Chapter 3, we were able to obtain closed-form analytical methods for 
making statistical inferences. Recall that in non-conjugate cases, we indicated that 
Monte Carlo methods would be needed. Here we consider two additional models 
where purely analytical methods are not possible.

76
Bayesian Thinking in Biostatistics
4.1 Additional Sampling Distributions
4.1.1 Gamma Distributed Data
The gamma distribution (see the table of common distributions in Appendix B) 
is a generalization of the exponential as well as the chi-square distribution. It has 
a shape parameter a and a rate parameter A, and is denoted by Ga(a, A). With 
conditionally iid observations (Kj,..., Yn),
n \a 
\na ( n 1 Q 1
• • • ,Уп | a, A) « П Г(^Г1е_Л“ “ r(^F {jVj
Note that, with a fixed, the last expression can be recognized as the kernel of the 
gamma distribution. Also note that with A fixed, there is no recognizable kernel 
in a. We claim that there is no obvious conjugate prior for (a, A), and therefore, 
there is no nice analytical formulation for the joint posterior. Consequently, we first 
specify an independence joint prior, and then consider obtaining full conditional 
distributions as we did in Section 3.2.2 for the normal distribution.
We thus specify p(a, A) = p(a)p(A) and we take A ~ Ga(a, b). Then
p(X\a,y) oc {Aa-1e-bA}{AnQe-A^"=i««} 
a да+па —lg—A(b+J2"=1 vt),
which is the kernel of a Ga(a + na,b + ny) distribution. We say that the gamma 
prior here is conditionally conjugate. The full conditioned for a is
р(а| p(q)’
which is not recognizable for any known choice of p(a), so we do not even have con­
ditional conjugacy in this instance. We address how to handle situations like this 
later in this chapter. As discussed for the normal distribution with an independ­
ence prior in Chapter 3, we will sample iteratively from these two full conditional 
distributions to obtain a Monte Carlo sample from the joint posterior.
4.1.2 Weibull Distributed Data
The Weibull distribution (see the table of common distributions in Appendix B) 
is another generalization of the exponential, often used in describing time-to-event 
data (see Section 3.2.4). It also has a shape parameter a and a rate parameter A, 
and is denoted by П'егЬ(а.А). With conditionally iid observations,
P(.Vi
Un

Computational Methods for Bayesian Analysis
Once again with n known, multiplicative terms in о can be omitted in this sampling 
distribution when viewed as a likelihood function in Л. The last expression can be 
recognized as the kernel of a gamma distribution for Л. Thus, as in the gamma 
distribution case, we assume p(o,A) = p(o)p(A) and we take Л ~ Ga(a.b}. We 
obtain
р(Х\а,у} ex 
|лпе-л^"=>у“}
K Aa+n-ie-x(b+E?=ly?)t
which is the kernel of a Ga(a + n, b + 
у?} distribution. So we again have
conditional conjugacy. The full conditional for a is
e A^i=1 y‘^p(o),
which again is not recognizable for any known choice of prior on a.
4.2 Asymptotics: Normal and Laplace Approximations
Historically, large-sample approximations have played an important role in stat­
istics. Before the advent of Monte Carlo (MC) methods, and more particularly, 
Markov chain Monte Carlo methods (MCMC), large-sample approximations were 
crucial in Bayesian statistics. We present these approximations in order to give a 
historical perspective, and also because aspects of these approximations have con­
tinued to play an important role in some implementations of Bayesian methods—in 
particular, they are used in the implementation of certain MCMC procedures.
Assume that Y = (Yi, Y?,..., Yn) are conditionally iid with probability density 
p(- I в), where 0 = (0i,02, • • • ,0pY € K₽. Then the joint pdf for Y is p(y | 0) = 
ПГ=1Р(^ I &Y Assume a knowledge-based pdf for 0, p(0}. Then, as always, the 
posterior pdf is p(0 | y} oc p(y | 0}p(0} oc Lifc(0)p(0).
Normal Approximation to the Joint Posterior. In the case p = 1, if p(0 | y} 
is unimodal and symmetric, we might think that it could be approximated by a 
normal distribution with mean equal to the posterior mean, and variance equal to 
the posterior variance. If the sample size is large, we can consider the following 
approximation in the arbitrary p case.
Let 1(0} = ln(p(0 I ?/)), and let 1(0} be the vector of p partial first derivatives 
and 1(0} be the matrix of second partials of £(0}, namely
We are, of course, assuming all of these derivatives exist. Further, suppose the

78
Bayesian Thinking in Biostatistics
posterior mode, 0, exists and that it is not on the boundary of the parameter space. 
It follows that t(0) = 0, the zero vector. Then under some regularity conditions,1 
we can take a second-order Taylor series approximation of £(0) as
’Similar to those needed for the large-sample normal approximation of maximum likelihood 
estimators. See, for example, [65].
2This is analogous to the inverse of the Fisher observed information (FOI) matrix, which serves 
as the large-sample covariance matrix estimate for the maximum likelihood estimate (MLE) for 0. 
In fact, if we set p(0) to be constant in 0, the posterior mode is the MLE and the large-sample 
covariance matrix is exactly equal to the inverse of the FOI. Thus large-sample posterior inferences 
will be exactly the same as large-sample MLE inferences.
£(0) = £((?) + t(0)(0 - 0) + 1(0 - 0)'t(0)(0 - 0).
Then, using the facts that £(0) = 0 and that £(0) is free of the parameter vector 0, 
we obtain
Thus the joint posterior is distributed as approximately multivariate normal in large 
samples, namely
«I y~Np(e, (-адг1),
with mean vector equal to the posterior mode and large-sample2 covariance matrix 
(-W1-
The negative of second derivative matrix evaluated at the mode provides a 
measure of the curvature of the joint posterior around 0. For example, with p = 1, 
if it is “large,” the posterior pdf will be highly concentrated about 0, while if it is 
small, the posterior will be diffuse while still centered on the mode.
Most statistical software packages have routines that will find the posterior 
mode vector and covariance matrix. Approximations can sometimes be improved 
by transforming the parameters. For example, a posterior distribution for a log 
odds ratio is more likely to be approximately normal than the posterior of the odds 
ratio itself. The log odds of a binomial proportion is more likely to have a normal 
posterior than the binomial proportion itself. The log mean volume of a tumor in 
an animal study of anticancer drugs is more likely to have a normal posterior than 
the mean volume itself, etc. Normal approximations will not be useful if there is 
skewness or multimodality in the posterior distribution.
*Laplace Approximation to a Posterior Expectation. Another large-sample 
approximation is based on the Laplace transform [328, 329]. Suppose we wish to 
approximate the posterior expected value of a positive function, g(&) > 0, namely
E[sW | y] = $ g(0}Lik(e)p(0}de 
f Lik(0)p(e)de

Computational Methods for Bayesian Analysis 
79
The Laplace method involves rewriting this as
E r (। ] = Jexp{ln(ff(g)) +ln(L?fr(g)) + ln(p(0))}d0 
' 1 
f exp{ln(£zk(0)) + ln(p(0))}d0
_ Jexp{L
*(0)}d0
— f exp{L(0)}d6 '
Suppose L*(0)
 and L(0) have unique maxima, в*  and 0, respectively. Then expand 
each in a second-order Taylor series expansion. We obtain
E(w| । /ехр{Ь‘(Г) + 0.5(9 - 
~
11/11 
/ехр{£(9)+0.5(9-9)'£(9)(9-9)}rf9
= exp{L-(
*-)
 - 
))(» ~ HM9
/exp{—0.5(9 — 9)/(—L(9))(9 — 9)}d9
= exp{L-(9’) - L(9))|L(9)|1/2|L
*(9
*)|
-1/2.
The last equality follows by recognizing the integrands as kernels of multivariate 
normal distributions (Appendix B). The advantage of this method of approximation 
is that it tends to the actual posterior expectation very quickly (on the order of 
1/n2).
4.3 Approximating Posterior Inferences using Monte Carlo Sam­
pling
As indicated in Chapter 3, numerical approximations to posterior distributions and 
their characteristics may be necessary in order to obtain statistical inferences due 
to lack of analytical tractability. In some situations, when data sample sizes are 
sufficiently large, large-sample approximations like those discussed above may be 
useful and even desirable. However, it will usually be preferable to obtain a Monte 
Carlo sample from the posterior. This is certainly the case when n is small or when 
it is not known whether it is large enough to justify a large-sample approximation, 
when the dimension of the parameter vector is large and we are interested in making 
inferences for complicated functions of в, and when there is a lack of analytical 
tractability. We will see many such examples throughout the book. As indicated 
in Chapter 3, an appropriate Monte Carlo sample can be used to approximate the 
posterior density for any p(0) and its characteristics, such as posterior quantiles, 
means and standard deviations.
We proceed to discuss some useful methods of simulating samples from various 
distributions.

80
Bayesian Thinking in Biostatistics
4.3.1 Random Number Generation
Simulating samples from a distribution requires random number generation. Most 
statistical packages provide one or more random number generators, along with 
several functions to simulate from common families of distributions.
Computer generated random numbers are more properly called “pseudorandom 
numbers.” The algorithm that outputs a sequence of these is deterministic, following 
some fixed rules to compute the next number given the current one; yet the sequence 
behaves in the same way as a truly random sequence. The mathematics of these 
algorithms has been well developed over the past decades, along with statistical 
techniques to test whether an algorithm generates sequences that mimic random 
numbers. While most generators produce random integers, these are easily rescaled 
to the interval (0,1), resulting in pseudo-samples from the uniform distribution on 
this interval. In R, for example, the simple expression runif (n) produces a sequence 
of n such 17(0,1) random numbers. Starting with such uniforms, one can generate 
samples from a rich variety of distributions via transformations and other methods.
For example, if U ~ (7(0,1), then W = - ln((7) ~ Exp(l). Moreover, V = 
W/X ~ Ga(l,X). Then we can obtain an S ~ Ga(k, Л) variate by first simulating 
(I7i,..., t/fc) as iid (7(0,1), then calculating Vi = -ln((7i) and finally calculating 
S = J2i=i K- We obtain a pair of independent standard normals using the Box­
Muller transformation, (Zi,^) = (\/—2ln((7i) cos(2tt(72), \/—2ln((7i) sin(27r(72)), 
where the Ui are independent 17(0,1). A normal N(p, a2) variate is obtained as 
X = p 4- aZ from a standard normal Z. We can simulate a Ber(0) variate as 
У = Z(o,e)(i7), and a Bin(n, 0) is simulated as the sum of n iid Ber(0)s. There are 
many more distributions that can be simulated along these lines. All of the standard 
types of well-known distributions can be simulated in most statistical programs. For 
example, in R the command X = nonn(100, 10, 5) will simulate 100 7V(10,25) 
random variates.
In the next subsections, we discuss additional methods of simulation, including 
distributions that are not necessarily known, meaning that they do not have a 
name, or their normalizing constant is not known or there is no known simple way 
to simulate from them directly via transformations.
4.3.2 Inverse cdf Method
This method is based on the probability integral transform U = F(X), so called 
because the cdf, F(x) = J^oop(s)ds, is the integral of the density that yields the 
cumulative probability up to and including x. For a continuous cdf F, a random 
variable X having this cdf, when transformed to U = F(X), will result in U having 
a (7(0,1) distribution. When F has an inverse, this is easy to see:
P(U < u) = P(F(X) <u) = P(X< F~\u))
= F (F-1(u)) = u. 0 < и < 1.
Reversing this process generates X having cdf F via X = F-’((/). This method 
works well when we have a simple analytic form for F-1. For example, X ~ Fxp(A)

Computational Methods for Bayesian Analysis
has cdf 1 -e_Al. Setting this to и and solving for a: yields x = - ln{(l - u)}/,\. In R. 
we can generate n Exp(X) variates as -log(runif (n))/lambda, since U ~ (ДО. 1) 
if and only if 1 - U ~ [7(0,1). R also provides the function rexpO directly for this 
purpose.
4.3.3 Importance Sampling
The situation considered here involves the need to sample from a distribution, say 
p(-), that is intractable, but where it is possible to find a “mimicking” distribution 
that can be sampled directly, say <?(■), as in those cases discussed above.
Our discussion begins with an approach to computing the expectation of a 
function of a RV, X, say h(X), where X ~ p(-). We assume that, in some sense, 
p(-) behaves in a similar way to p(-), and that we know how to sample from </(•). 
Then we note that
ЕР{Л(Х)} = У h(x)p(x)dx = У fc(x){^}9(x)dx = E9{h(X)w(X)},
where w = f/g can be seen as a weight function, and the expectations are sub­
scripted according to the distribution with respect to which the expectation is taken. 
Thus, if we sample 
with X® ~ p(-), we obtain
м
EP{h(X)} = £h(x(l>)w(X<l>)/M
t=l
for large M by the strong law of large numbers. The method works well when the 
weight function is stable in the sense that it does not grow wildly in the tails of p, 
which can occur if the tail ordinates of g are relatively much smaller than those for 
p. Thus the tails for g should be somewhat “fat” compared to those for p for this 
to work well.
The use of this technique in Bayesian statistics must be modified slightly. Let 
p(0 | y) be the posterior pdf for a parameter (vector) 0. We are interested in the 
posterior expectation
У I v)M.
but the integral is intractable due to the fact that we may only know the posterior 
up to the constant of integration, that is, all we know is that p{0 | y) a Lik(0)p(0). 
Thus rewrite
Jh(ew\y)de = 
J£a:(„)p(„)dg
f h(0)w(0)g(0)d0
“ 
fw(0)g(0)d0 ’

82 
Bayesian Thinking in Biostatistics
Suppose we now have an iid sample . , 0{M)} from g(-). Then a numerical 
approximation to the posterior expectation is
««I... agglp
M
t=l
where w(0(t)) = №(»<«)/E", w(0(j')). This is again justified by the strong law of 
large numbers. Observe that w(0) need only be specified up to a constant, since 
any constant will cancel in the calculation of w(ff).
Now we return to the main problem of interest, namely, obtaining a sample from 
the posterior, р(в | y). Observe that the collection {(0{t),w(0(t))) : t = 1,...,M} 
defines a discrete distribution with the sampled as discrete points with prob­
abilities 
It is not difficult to show that this discrete distribution tends to
the continuous distribution with pdf p(6 | y), and so it is a discrete approximation 
to the posterior.
The method can be taken a step further to convert samples from one density 
into those from another by resampling from this discrete approximation. To illus­
trate, suppose the posterior for scalar в is Ga(1.5,0.5). The mean and variance of 
this distribution are 3 and 6, respectively. We select g(ff) = O.25e-o’25e/(0 > 0), 
which is an Ea;p(0.25) pdf. We obtain samples from this exponential distribution 
by obtaining 0^ = - ln(t/W)/0.25 for ~ «7(0,1), t = 1,..., M. Then with
Д1.5-1„-0.50
■"№= 
e-o,5< 
= 
-°2M.
we obtain the Then sample M
*  values (with replacement) from the discrete 
approximation to the Ga(1.5,0.5) distribution to obtain {0(t) : t = 1,...,M
*},
 
where we now have 0W~Ga(1.5,0.5). This method of generating samples is known 
as the SIR (sampling-importance resampling) algorithm.
The following short R code generates samples for this illustration and verifies 
that the histogram matches the true density.
theta <- -log(runif(10000))/0.25
weights <- theta‘(0.5)
*exp(-0.25
*theta)
ttheta <- sample(theta,10000,replace-TRUE,prob-weights)
xx <- seq(min(ttheta),max(ttheta).length.out-200) 
yy <- dgamma(xx,1.5,0.5) 
breaks <- quantile(ttheta,probs-seq(0,1,0.02)) 
hist(ttheta,breaks-breaks,probability-TRUE) 
lines(xx,yy,lty—1)
While this illustrates the SIR algorithm, we note that gamma random variates can 
be generated by other more efficient methods. For example, R provides the function 
rgammaO for this purpose.

Computational Methods for Bayesian Analysis 
83
4.3.4 Rejection Sampling
This method also substitutes an easily sampled density function to achieve sampling 
from a more difficult density under some conditions, this time by rejecting samples 
with the “correct” frequencies dictated by a ratio. To understand this method, first 
imagine that you are able to throw darts at a cut-out of the target density in such a 
way that you will always hit the picture and that you are equally likely to hit regions 
with equal areas, namely, according to a uniform distribution on the target itself. 
Then taking the horizontal coordinate of the dart’s position results in a randomly 
sampled value from the target density.
Correspondingly, generating a random value, в ~ p(0), followed by drawing a 
value, U = u, from the uniform distribution on (O,p(0)). results in the coordinate 
location (0,u), that is equivalent to throwing a dart uniformly at the cut-out of the 
density. This is true since the joint pdf is just
p(0,u) = p(0)p(u | 0) = p(0) —< p(0)) = 1
over the graph of (0,p(0)), which has total area 1. Of course if we could sample from 
p(-), we would not need to take this extra step of simulating the uniform variate. 
But the idea of sampling from the cut-out graph leads us to the following parallel 
argument that allows us to obtain samples from p(-).
The target density of interest for us is again the posterior p(6 | y), where, 
for easy visualization, we think of в as a scalar. We often do not know the con­
stant of integration (i.e., we know a kernel /(0) that is proportional to p(0|p)). 
Let 
= Cf, with this normalizing constant Cf typically unknown. We
continue the dart throwing scenario, only now we consider the cut-out of the plot 
of /(0), which does not integrate to 1. With the help of Figure 4.1 we can describe 
the actual algorithm as follows.
Our goal is to sample 0 ~ p(0) = /(0)/c/. Suppose we can find another kernel, 
g(ff), such that /(0) < g(ff) for all в and we can sample easily from g(ff)/cg, where 
c5 = 
g(J))d0 is the normalizing constant for p, possibly also not known. Then
the following algorithm generates the desired samples from the distribution with 
pdf p(0):
• 
Step 1: Generate 0 from p(-).
• 
Step 2: Generate U ~ 17(0,1).
• 
Step 3: If U < then accept else reject в and go to Step 1.
Step 3 follows from observing that (0,p(0)) is a dart thrown at the function p(-) 
uniformly, and when its vertical coordinate is greater than /(0), we discard darts 
landing in the sliver between p(-) and /(•). This leaves darts thrown uniformly 
under /(•). It will be seen below that, despite the fact that /(•) is only the kernel 
and not the actual pdf, the accepted value of в is still coming from the distribution 
with pdf p(0).

84
Bayesian Thinking in Biostatistics
x and/or у
FIGURE 4.1: Illustration showing how the rejection sampling algorithm emulates 
a dart thrown randomly and uniformly in the area under f(-) by throwing such a 
dart under g(-') and keeping it if it is under f(■).
It is clear from Figure 4.1 that the rejected proportion of samples from g(-) 
equals the ratio of the area between the functions g(-) and f(-) (i.e., cg — c/) 
to that under p() (i.e., cg). To make this area smaller, and thus to make the 
sample acceptance probability c.f/cg larger, let S = supg{f(0)/g(0)} < 1 and set
= Sg(0). The acceptance probability is now c.f/cg- = Cf/(Scg') = (cf/cg)/S. 
This choice of g*  simply means the envelope defined by g*  is closer to / than that 
defined by g, and improves the sample acceptance probability by a factor of 1/S 
which is clearly greater than or equal to 1.
The proof that the accepted value is from the correct distribution follows as
P(S < c | Accept)
I - 
\ 
~g(6)J
f'\ p (и <^l&) (g(ff)/cf/)M
P (7/ < $$ / ff) (n(O)/eg)dff

Computational Methods for Bayesian Analysis 
85
f-xmde 
fZ/We
= Г p(e)de, 
J — oc
which is the cdf corresponding to pdf p(0). We used the law of total probability 
and the property that P(U < v) = v.
Example 4.1. Truncated Normal. To generate в from the truncated normal 
distribution, say A(0, l)7(c oo)(0) for c > 1, let
/(S) = e-i“’/(e.oo)(S).
Take p(-) to be proportional to a truncated Weibull density with shape parameter 
a = 2 and rate parameter b = | (Appendix B). We have
= ea~le~be\ 6>c.
Then
SW = e-i»8 
1
g(&) 0а~1е~ьва e'
Clearly this ratio is no greater than 1 since c > 1. Now Cf = 
e~?e2d0 =
у/27г(1 — Ф(с)), where Ф denotes the standard normal cdf. We also have cg = 
Oe~^e2dO = ^e~ldt = e~?t2, and S = 1/c so that the sample acceptance 
probability (SAP) is
P(Accept Sample) = (cf/cg^/S = л/2тг(1 - Ф(с))се^с2
if we generate the truncated Weibull and accept it if U < Numerically, we get 
the following:
c
1 
2
3
4
5
10
50
SAP
0.6557 0.8427
0.9138
0.9466
0.9640
0.9903
0.9996
Truncated Weibull samples can be obtained easily by the inverse cdf method. This 
and similar examples appear in [214].
4.3.5 Adaptive Rejection Sampling for Log-Concave Densities
Rejection sampling works well with the large class of densities in which the loga­
rithm of the density (or kernel of the density) is a concave function. Such densities 
are unimodal and the second derivative of the log-density is non-positive. For such 
densities, we work with the kernel since the constant of integration is usually not 
known. A good envelope can be constructed by first finding two tangent lines to

86
Bayesian Thinking in Biostatistics
the log kernel, one on each side of the mode. Then transform the kernel and the 
tangent lines by exponentiating. The method is adaptive in the sense that the re­
jected samples can be used to construct additional tangent lines, thus creating a 
more efficient envelope. As just discussed, the target distribution is p with kernel 
f, and the envelope described here is g which can be sampled from.
Tangents at x=2 and x=10
Tangents at x=2 and x=10
Tangents at x=2, x=5 and x=10
0 
5 
10 
15
FIGURE 4.2: The top row shows the target and envelope with two initial points. 
The second row shows how the addition of a rejected point improves the envelope.
Tangents at x=2, x=5 and x=10
0 
5 
10 
15
To illustrate, consider the target kernel f(x) = x4e~x. It is easy to verify that 
this is a log-concave function. Working initially with tangents at two points, x = 2 
and .r = 10. an envelope is constructed for the log of the kernel. This is shown in 
the top left plot of Figure 4.2. and the corresponding envelope for the kernel itself 
is shown to its right. If we now pretend that sampling from the envelope generated 
the value 5. and this value was rejected, we can add this point to the initial two to 
improve the SAP. This is shown by the plots in the second row of the figure.

Computational Methods for Bayesian Analysis
Log-concave kernels arise as so-called full conditional distributions for joint pos­
teriors for many statistical models. Bayesian software packages use versions of this 
method widely. The tangent-based method described above requires evaluation of 
the derivative of the log-kernel. A derivative-free version constructs an envelope for 
the log-kernel using cords in place of tangents. In R the arms function in the pack­
age HI implements this version. We use it in Example 4.3 below. Observe that the 
constructed envelope gives a non-negative function that could be integrated to find 
the area underneath it. A “good” envelope constructed in this way would closely 
track, from above, the kernel of the pdf that we are attempting to sample.
4.4 Markov Chain Monte Carlo Sampling
Thus far in this chapter, we have considered how to obtain independent random 
samples from a distribution where the target is univariate. In most statistical 
models, we have more than one parameter. This means the posterior distribution is 
multivariate. In the case of exchangeable normal observations, we have encountered 
a bivariate parameter 0 = In Section 3.2.2, with both parameters unknown, 
we used а ЛГ(//о, ^о) prior for //, independent of a <7a(c, d) prior for t. This resulted 
in conditional conjugacy, that is, the full conditional for p. was normal and the full 
conditional for r was gamma. The fully conjugate normal-gamma prior was also 
discussed in a section marked with an asterisk (*).  We briefly introduced the con­
cept of Gibbs sampling there, which involves sampling successively from these full 
conditional distributions to obtain, ultimately, a sample from the joint posterior.
Two other examples of unfamiliar bivariate posteriors are inherent in Sections 
4.1.1 and 4.1.2 where we considered two-parameter distributions for which there is 
no nice form for the joint posterior, and where one full conditional is nice and the 
other is not. Nonetheless, Gibbs sampling is a method that will allow us to obtain 
samples from such analytically intractable posteriors.
To understand Gibbs sampling and other methods to be discussed in this chap­
ter, we begin with some notation and concepts. We gave some introduction to 
this topic in the previous two chapters, but we give a more formal and more gen­
eral treatment here. Suppose we need samples from a joint posterior distribution 
for a parameter vector 0 with components 0\,... ,0k- We had к = 2 in the three 
examples above. Under mild conditions, Gibbs sampling generates a sequence of 
iterates, 0^\0^2\..., where eventually iterates are from the joint posterior.
Unlike the methods of Section 4.3, the sequence does not result in iid samples 
from the posterior distribution. In fact, the first iterate will not be from the poster­
ior; and successive iterates in the sequence are not independent since the method of 
sampling uses the value of a current iterate, say to generate the next iterate, 
0(t+1\ for every t. Such a stochastic sequence is termed a Markov chain. Gibbs 
sampling uses the realization of a particular type of Markov chain to achieve its 
goal.

88
Bayesian Thinking in Biostatistics
A Markov chain is defined on a state space, in our case the parameter space 0 for 
0. In the normal data example, this is a half-plane defined by д G (—00,00), т G 
(0,00). For the gamma and Weibull data examples, the state space is the first 
quadrant of the coordinate plane, as the parameter components are both positive 
in each case. To construct a Markov chain, we must specify what is termed in the 
stochastic process literature as a transition kernel. It is just a conditional density 
that governs how to sample the next iterate given the current iterate, which we 
represent as r(0^t+l^ | 0^). Our goal is to sample from the posterior distribution 
for в, which we simply write here as p{0). The joint posterior is used to obtain the 
transition kernel in a variety of different ways in general, but for Gibbs sampling it 
is obtained in a very particular way involving the full conditional distributions of 
the joint posterior. We formally define this in Section 4.4.1.
Markov Chain Concepts. The theory of Markov chains contains results about 
the distribution of 0^ as t grows indefinitely. In brief, under some conditions, the 
distribution of 0^ converges to the joint posterior as t grows, regardless of where 
the chain was initiated. The main condition is that the transition kernel satisfies 
p(0) = l^e\e^p(e^de\ 
(4.1)
When r(- I ■) satisfies this condition, it is called a stationary transition kernel. 
This is a necessary condition for the iterates to ultimately be sampled from the 
joint posterior. Transition distributions satisfying (4.1) are called “stationary tran­
sition kernels of the chain,” and the target distribution, p, is called the “stationary 
distribution of the chain.” There can be more than one such r that satisfies this 
condition, which means that there can be different chains, generated by different 
rs, that lead to samples from the same target p(-).
If we generate the first iterate in the sequence by sampling, say 0° ~ p(0), then 
it is easy to show using the law of total probability that 0(1) ~ p(0), and then by 
induction that 0^ ~ p(0). This is precisely what it means for p to be the stationary 
distribution.
There is a rather large practical issue associated with this fact, namely, that we 
are looking for a method of sampling from p when we do not already know how to 
do it. Thus, since we cannot sample the initial iterate from the target distribution, 
the result is practically useless, though it does give us some hope that if we start 
with some initial we might eventually obtain a sample from p and that subsequent 
samples will be from p.
In practice, we select some reasonable initial iterate, 0^, possibly by sampling 
from the prior distribution or possibly by just selecting values that seem reason­
able in view of any scientific interpretations or knowledge about 0. Then indeed, 
under mild conditions on the kernel and stationary distribution, there is Markov 
chain theory that asserts that we will eventually sample from the target posterior 
distribution. In other words, for a sufficiently large number, BI. if t > BI then 
fld) ~ p(0); BI is termed the “burn-in.” Moreover, it also asserts that for any 

Computational Methods for Bayesian Analysis
r
integrable function </(•),
дШМ
as M —> oo, meaning that the Markov chain Monte Carlo average above will become 
arbitrarily close to the posterior mean of g(0) (almost surely) as M grows. This is 
called an “ergodic” theorem. It is analogous to the strong law of large numbers, 
which is identical to this one if the iterates are obtained as an iid sequence.
The major implication of this result is that MCMC iterates can be treated 
almost the same as MC iterates that might be obtained by other means. There 
are two issues here that are different. We will need to study what is called the 
convergence aspect of the chain, which amounts to selecting a suitable value for 
BI. The second issue is that the total number of MCMC samples after the burn-in, 
M — BI, may need to be larger than for other methods, due to the correlation 
between iterates that is implied by the Markov property of the chain.
Markov chain theory applies to a number of situations that we now discuss. The 
Gibbs sampler employs precisely one such chain, and another type is introduced 
subsequently.
4.4.1 Gibbs Sampler
With this background, we describe the Gibbs sampler for vector {0i,... ,0k}'-
• 
Select an initial value 0(°\
• 
Denote the target distribution by p(0) and the full conditional distributions 
asp{6i | 6-i), where 0-t is shorthand for 0\,. ■■ 
■ ,0k-
• 
Simulate 0^ ~p(0i | 0-1)-
• 
Simulate 0^ ~p(02 | 0j1),0£)),... ,0<o)).
• 
Continue simulating from the conditional distributions p(0i|0_i), always using 
the most recently generated component iterates in the conditioning set. With 
the generation of the fcth component, the vector 0(4 is complete.
• 
Using this procedure, generate a sequence 0^\0^2\0^,... ,0(M^ for some 
sufficiently large M.
• 
The stationary distribution of this Markov chain on 0 is the target distri­
bution p(0), that is, the transition kernel implied by this procedure satisfies 
(4-1).
Consider the к = 2 case. We have
r(0(t+1) | 0(t)) = p(0<t+1) | 0?})р(0?+1) I 0^t+1)).
It is not difficult to show that this satisfies equation (4.1). We illustrate the sampler 
with some examples.

90
Bayesian Thinking in Biostatistics
Example 4.2 
. Normal Data. Consider the joint likelihood of Section 3.2.2, with 
independent priors on p and т. The full conditional distributions for this case 
were derived before, and given in expressions (3.5) and (3.9), respectively. We set 
p ~ N(Q, 100) and т ~ Ga(l, 1). Gibbs sampling can be easily coded in R as a 
function and used to obtain samples from the joint posterior (after the burn-in) as 
follows:
gibbsnormal <- function( 
y-rnorm(lOO), 
• default data
muO-O, 
• prior mean for mu
tau0-0.01, 
» prior precision for mu
aO-l.O, 
• shape parameter in prior for tau
b0-1.0, 
• rate parameter in prior for tau
bumin-100, 
• initial iterations to discard
thin-1, 
# thinning factor; no thinning by default
M-1000, 
muinit-NULL, 
tauinit-NULL 
)
• number of samples returned
* initial value for mu 
« initial value for tau
if(length(muinit) ——0) muinit <- muO
if(length(tauinit)--O) tauinit <
aO/bO
mus <- rep(0,M); taus <- rep(l,H) 
mu <- muinit; tau <- tauinit 
n <- length(y); nybar <- sum(y) 
tm <- tau0
*mu0;
 al <- aO+n/2 
for(g in (1-burnin):(H
*thin)){
 # begin Gibbs loop 
precision <- n*tau+tau0
 
mu <- rnorm(l)/sqrt(precision) + (nybar»tau+tm)/precision 
bl <- b0+sum((y-mu)‘2)/2 
tau <- rgamma(l,shape-al,rate-bl) 
if(g>0 t (g7.7.thin)--0){ 
# save posterior sample
mus[g] <- mu; taus[g] <- tau
} 
# end Gibbs loop
return(list(mu-mus,tau"taus))
samples <- gibbsnormal() 
summary(samplesSmu)
summary(samples$tau)
summary(1/sqrt(samples$tau))
9 summary of posterior sd
Example 4.3 
. Gamma Data. Returning to the likelihood of Section 4.1.1, with 
A ~ Ga(a, b) as before, and an independent prior on a, p(a), we can write down 
the joint posterior for A, о as
{
„ \ Q-1 
П I
e-A^"=»y*A a-1e“'’Ap(a), 
i=i J
where, for the moment, the prior for о is unspecified. From this, we recognize the 
kernel of the full conditional for A. and thus
A | о. у ~ Ga(a + na. b + ny).
Since there is no obvious choice for a prior on o, we will pick a clever one that 

Computational Methods for Bayesian Analysis
91
allows us to sample from it, even though it is not conditionally conjugate. We later 
discuss how one would be able to make the prior diffuse in a way that maintains 
the balance between prior and data-based information. When scientific input is 
available, we might elicit information for the mean, o/A. or mode, (o - 1)/A. and 
a quantile of the Ga(ct,A) distribution. Since this is a chapter on computation, 
however, we postpone that discussion.
The clever prior that leads to full conditionals that we know how to sample 
involves the specification of a joint distribution on a. and an “auxiliary’' parameter, 
say ф, which will be specified as p(a,0) = p(o | ф)р(ф\ This induces a prior on 
a, p(pi) = f р(а,ф)с1ф. For our particular choice, it will turn out that the full 
conditional for ф | a, A, у is easy to sample and that the full conditional for a | о. A. у 
is log-concave and can thus be sampled using adaptive rejection sampling (ARS). 
We are thus able to obtain a sample from the joint posterior, p(o. А,ф | y), but 
where the samples for ф are superfluous to the Bayesian analysis and are thus 
discarded. The samples for (a, A) are indeed from the marginal target distribution, 
p(a,A | y), using this technique of auxiliary parameters. It turns out that this is 
useful in other contexts as well, as we shall see when the opportunity arises.
The particular choice of hierarchically specified prior that works here is
p(a | 0)p(</>) oc |iz(o,0)(a)} 
> c > °> d > 0 •
Conditioned on ф, a is uniformly distributed on (0,0) and the marginal of ф has 
what is known as a Pareto distribution of the first kind on the interval (c, oo). 
Multiplying the likelihood by this prior, we have
p(a,0 | A,?/) oc |-r^jn 
0-(d+2)/(o^)(QU(c,oo)(0)-
Observing that the product of the two indicator functions can be written as 
Amax{c,a},oo)(</>), we can obtain the separate Gibbs conditionals
р(Ф | a, A, y) oc </>"(d+2)Z(max{C,a},oo)(</>),
дпа ( « I ° 1
p(a | ф, A, 2/) oc {r(Q)}n ЩУ*  J Ло,Ф)(<>) •
The first of these is a Pareto distribution, Par(max{c, a},d + 1). It has a simple 
inverse cdf, so ф can be generated using it. The second, although not in a simple 
form, is log-concave and can be sampled using ARS. The R code in the file named 
GibbsGamma.R under Chapter 2 on the book’s website shows how this Gibbs sampler 
can be implemented.
Example 4.4 
. Weibull Data. For the likelihood here, we return to that in Section 
4.1.2, with the prior for A as before and an independent hierarchical uniform-Pareto 
prior on (a, 0) as in Example 4.3. This yields
p(A,a | y) oc (Aa)n {ft
*}
е-АЕ"=11/?да le bAp(Q) .

92
Bayesian Thinking in Biostatistics
Again, for the Gibbs conditional for A, we reuse our previous derivation in Section 
4.1.2 with a considered known: A | a, у ~ Ga(a + n,b + 
у?). Derivation of
the other Gibbs conditional follows in the same manner as in Example 4.3, namely
p(a, ф | X,y) oc an
e 
(d+2)Z(o,0)(a)Z(C1oo)(0), 
from which we get the separate Gibbs conditionals
р(ф|а,А,1/)ос ф (d+2)Z(max{c.Q})Oo)(0),
p(a | ф, A, p) oc an
e >E?=itfz(O0)(a).
Again, the first of these is a Pareto distribution, Par(max{c,a},d + 1). Samples of 
ф can be generated using the inverse cdf method. The second can be shown to be 
log-concave. The R code is similar to that in the previous example. It is in a file 
named GibbsWeibull.R in the same folder as the file GibbsGamma.R.
4.4.2 Metropolis-Hastings Algorithm
The Gibbs sampler in the previous section iterates through the components (or 
blocks of components) of a multidimensional vector to generate the successive real­
izations of a Markov chain. In contrast, the Metropolis-Hastings algorithm gener­
ates the next multivariate iterate in the chain directly as a whole, without needing 
the conditionals of the target density as in the Gibbs sampler. On the other hand, 
it requires another distribution called the proposal (or candidate-generating) dis­
tribution as we describe below. The chain is then constructed in such a way that its 
stationary distribution equals the target density. The algorithm was first developed 
in the physics literature as the Metropolis algorithm [242], and later generalized 
by Hastings [160] in the statistics literature. The Gibbs sampler turns out to be a 
special case of this algorithm. We present Hastings’ generalization first, pointing 
out the simpler Metropolis case immediately after.
As before, consider a space 0 with target distribution p(0) from which we wish 
to draw random samples. Suppose <7(0;0
*)
 is a family of probability densities on 
0 indexed by 0*,  that is, q(-; 0*)  is a probability density on 0 for each 0*.  This 
is called the “proposal density,” as it is used to generate a candidate value for 
the next iteration of the chain when it is currently in state 0* . This candidate 
value is accepted as the next one in the chain with a specified probability. The 
transition kernel for this chain can be shown to satisfy the stationarity condition 
(4.1). which means that, eventually, samples obtained in this way will be from the 
target distribution. p(0). We state the algorithm.
• With iteration index t and the chain in state 0^\ generate 0 from the proposal 
distribution </(•: 0^).

Computational Methods for Bayesian Analysis
93
• 
Set = в with acceptance probability
a(0,0w) = min (1. _P(yg(<); Л . 
(J.2)
I p(0(t))<?(0; 0(,)) J
Otherwise set 0(t+1) = (№.
• 
Advance the iteration index to t + 1 and go to first bullet.
The Metropolis algorithm requires <?(•;-) to be symmetric, that is, g(0;0(t)) = 
q(0^ : O'). This leads to the simplification
a(0,0™) = min {1,₽(»)/?((»<•>)} . 
(4.3)
In either case, notice that the chain either stays in place or moves to a new value. 
If the ratio in the definition of acceptance probability is greater than or equal to 
1, the chain moves to the generated candidate. If the ratio is less than one, we 
generate a 17(0,1) variate and accept the candidate if the random variate is less 
than the ratio. Also, because the ratio contains a ratio of p(-) at two values of 0 in 
both numerator and denominator, it is only necessary to know this density up to a 
multiplicative constant (i.e., p( ) can be replaced by a kernel).
The Markov chain resulting from this algorithm has p{0) as its stationary distri­
bution under conditions that are typically satisfied if we pick g(-; 0*)  to be positive 
everywhere that p(-) is positive, for each 0*.  In most applications this is easy to 
accomplish. One special class of <?(■; •) leads to what is termed an “independence 
chain.” Here q(O’,0
*)
 = qo(0) so that the proposal density does not depend on the 
current state.
Another popular class uses q(0-, 0*)
 = qo(0 -0
*),
 where now the candidate value 
will depend on 0*  in that the new value will be the current iterate plus or minus 
an increment where the increment has density goG)- This is called the “random 
walk chain,” since it “steps” forward or backward from the current iterate at each 
iteration. The candidate generating distribution of the increment is often taken to 
be multivariate-normal or Student with location 0*.  Since these distributions are 
symmetric about their location vectors, we must have q(0; 0*)  = q(0
*
; 0), or equiv­
alently qo(0) = qo(—0). In this case the acceptance probability takes the simpler 
form a(0,0^) =■ min{l,p(0)/p(0W)} due to cancellation of the generating densi­
ties in numerator and denominator of the acceptance probability formula. In this 
instance it is easy to see that the new value is accepted with probability 1 if the can­
didate value is more plausible than the previous iterate, under the target posterior 
distribution. The greater the plausibility of the candidate relative to the previous 
iterate, the higher the probability of acceptance.
In practice, it is recommended that the acceptance rate for the chain should be 
between 0.2 and 0.5. To control this rate, it is convenient to put a tuning parameter 
сто, typically a scale, in qo(O | cr0). We illustrate with a univariate and a bivariate 
example.

94 
Bayesian Thinking in Biostatistics
Example 4.5. Suppose we want to simulate from the Ga(0.5,1) distribution, whose 
density is proportional to x-1/2e-a:. Let Y = ln(X) so that p(y) oc exp{y/2 - ev}. 
We simulate Y using the random walk chain and JV(O, Oq) as the density for the 
increment. Note that the log-gamma and the normal distributions both have the 
entire real line as support. The acceptance probability is a simple ratio of the density 
for У at the proposed value and the density for Y at the current state. Once a value 
for Y = у is accepted, we obtain a value for X = x = ev.
In the following R code we implement the Metropolis-Hastings algorithm. Notice 
that the implementation uses the log of the acceptance probability, ln(a(-, ■)). This 
is often computationally convenient.
MHgamma <- function(
burnin-100,
thin-1, 
M-1000, 
sigma-5 # tuning parameter; after trial and error
)
eamplee <- rep(O,M) 
reject <- 0
current <- rnorm(l)
for(g in (1-burnin):(M
*thin)){
 
candidate <- current+eigma
*rnorm(l)
 
if(log(runif(1))<((0.5*candidate-exp(candidate)
)
-(0.5«current-exp(current)))) 
current <- candidate
else reject <- reject+1
if(g>0 t (g7.7.thin)--O) samples[g/thin] <- exp(current)
acceptprob <- l-reject/(burnin+thin
*M)
returndiet(acceptprob-acceptprob,samples-samples))
out <- MHgamma(sigma-5,M-1000,thin-2) 
outSacceptprob
summary(out$samples)
The value cr0 = 5 was arrived at by trial and error to tune the acceptance ratio 
to be in the desirable range. The additional code
x <- outSsamples 
par(mfrow-c(l,2)) 
xx <- seq(min(x),max(x),length.out-200) 
yy <- dgamma(xx,0.5,1)
breaks <- quantile(x,probs-seq(0,1,0.05)) 
hist(x.breaks-breaks,probability-TRUE) 
lines(xx,yy,lty-l)
b <- quantile(x,probs-0.75) 
x <- x[x<b]
xx <- seq(min(x),b,length.out-200)
yy <- dgamma(xx,0.5,l)/pgamma(b,0.5,l) 
breaks <- quantile(x,probs-seq(0,1,0.05)) 
hist(x,breaks-breaks,probability-TRUE) 
lines(xx,yy,lty-1)
produces Figure 4.3 to verify that the samples come from the target density. The 
trimmed sample plot takes a closer look at the density agreement up to the 75th 
percentile in the sample.

Computational Methods for Bayesian Analysis
95
FIGURE 4.3: Histogram and gamma 
Metropolis-Hastings algorithm.
target density for samples using the
Example 4.6. In Example 4.2 we discussed sampling (д, r) pairs from the joint 
posterior with an independence prior for parameters of the normal model using the 
Gibbs sampler. Here we use the Metropolis-Hastings algorithm on the bivariate 
pair (д, 7] = log(r)) and recover т = e7’ by back transformation. We obtain
1п(р(д,т?1 y)) = const +(a + ^)7?-p + ^ 
“ ^)2 Ь’ - yO
*
 ~ ^°)2-
The R code below uses the random walk chain with independent normals for incre­
ments in
MHmutau <- function(
y-rnorm(lOO), 
muOO, 
tauO-O.Ol, 
a0-1.0, 
b0-1.0.
« default data
It prior mean for mu
» prior precision for mu
• shape parameter in prior for tau
* rate parameter in prior for tau

96
Bayesian Thinking in Biostatistics
burnin"100 
thin"!, 
M-1000, 
eigmal-0.2 
sigma2"0.2
В initial iterations to discard
S thinning factor; no thinning by default
S number of samples returned
S tuning parameters; after trial and error
hub <- rep(O.H) 
taue <- rep(0,M) 
reject <- 0 
curnnu rnorm(l) 
curreta <- rnorrn(l) 
a <- a0+length(y)/2 
b <- tauO/2 
for(g in d-burnin):(H
*thin)){
 
candmu <- currmu+8igmal»rnorin(l) 
candeta <- curreta+eigma2»rnorm(l) 
if(log(runif(l))<
• (i) With a unhnodal q(0). and starting with 
«(*>), step along the 0-axis
by finding the two points 0tl < 0t2 that satisfy 
= q(0tl) = q(0t2) and then
simulate ~ C(0tl,0/2)- Move to 
(ii) For non-unimodal
densities, find {0 : <?(0) > u(,)} and sample from a uniform distribution on
((a
*candeta-exp(candeta)
*(bO+sum((y-candmu)
 2)/2) 
-b»(candmu-muO)"2)
-(a
*curreta-exp(curreta)»(bO+sum(
 (y-currnu) *2)/2)  
-b»(currmu-muO) ”2)))
{curnnu <- candmu 
curreta <- candeta} 
else reject <- reject+1 
if(g>0 t (gTZthin)—0) {mustg/thin] <- curnnu 
taus[g/thin] <- exp(curreta)
acceptprob <- l-reject/(burnin+thin
*H)
returndiet (y-y,acceptprob-acceptprob.mu-mus, tau-taus))
out <- MHmutau(M-2000,thin-2,8igmal-0.2,8igma2-0.2) 
outtacceptprob 
summary(out$y) 
summary(out$mu) 
summary(outStau)
4.4.3 Slice Sampling
Slice sampling uses a Markov chain to sample from a univariate distribution with 
density p(0). Since we generally will not know the constant of integration, we work 
with the kernel of the posterior, g(0). Imagine the two-dimensional graph of g(0). 
Slice sampling takes a random walk through the area under the graph of q(0), 
alternating steps along the two axes. To sample a slice, proceed as follows:
• 
Choose an arbitrary 0^ in the support of p(0) to initialize the chain. The 
random walk starts at (0(o),O).
• 
Given 0<o), step up by simulating uw ~ {7(О,д(0<о>)) and move to (0(o),i/o)). 
Then continue as follows.

Co7Tiputational Methods for Bayesian Analysis
that set. The main difficulty in slice sampling is finding this set when </(#)
is not unimodal.
• 
Simulate u(/ + 1) ~ C/(0, q(0(t+1))) and move to (0(, + 1\ u(f+1)).
The random walk used for slice sampling is a special case of Gibbs sampling, since 
we alternate between sampling U | 0 = 0*  ~ t7(O,</(0
*))
 and 0 | U = и ~ 
uniform on the set {в' : q(0') > u).
4.4.4 Hamiltonian Markov Chain Monte Carlo Sampling
This section discusses a very important and useful special case of the Metropolis et 
al. [242] algorithm for simulating blocks of random variables. This approach docs 
not require the modification of Hastings [160], so it is in fact simpler. It uses Hamil­
tonian dynamics from physics to generate new candidate iterates that will either be 
accepted or rejected according to the Metropolis acceptance probability in equation 
(4.3). In Section 4.4.2, a “candidate generating distribution” was used to simulate 
a new candidate. We next explain how first, in theory, candidates can be concep­
tualized deterministically using Hamiltonian dynamics, and then implemented in 
practice by an approximation.
4.4.4.1 Overview
First, the Hamiltonian MCMC method expands the parameter space of the para­
meters in the model, much like the method of auxiliary variables first introduced in 
Example 4.5. This leads to more efficient exploration of both parameter spaces. It is 
especially helpful in high-dimensional spaces, which are notoriously difficult to han­
dle with methods presented up to now. These auxiliary variates are discarded after 
each full iteration of the procedure, since their only purpose is in facilitating the 
computational aspects of Bayesian inferences. In this expanded space, Hamiltonian 
dynamics is used to “generate” a deterministic candidate for the next iteration.
Next, upon realizing the impracticality of actually implementing this generation, 
we discuss an approximation that combines deterministic theory and random simu­
lation of candidates. It has been argued that this method, if properly optimized, can 
be much more efficient than the usual random-walk Metropolis-Hastings method 
of generating MCMC samples from the target distribution.
The main reason for the development of this method is that it has the potential 
to be much faster and more efficient in exploring the support of posterior and/or 
predictive distributions. The method was first introduced by Duane et al. [99], 
who called it “hybrid Monte Carlo.” More recently, Neal [248] provided a substan­
tial review of this method with many illustrations and advice for implementation. 
Betancourt [42] has also given a lengthy introduction to the topic and has pre­
sented numerous graphical representations of the geometry involved in connecting 
the physics to the statistical problem of obtaining high-quality proposals with high 
acceptance probability in the Metropolis procedure. Both authors give arguments 
for why the target distribution is indeed the stationary distribution of the chain and 
address technical details for the implementation of the procedure. Other references 

98
Bayesian Thinking in Biostatistics
of interest are Shahbaba et al. [292], Hoffman and Gelman [167], and Nishimura 
and Dunson [250]. Here, we give a brief summary of the procedure and refer readers 
to these works for a much broader and more detailed perspective on the topic.
The method proposes states that are distant from the current state, but which 
still have a high probability of acceptance. These proposals are found by using 
Hamiltonian dynamics, much used in physics and astronomy. Since we do not expect 
most readers to be familiar with the physics, we instead describe the method as a 
very clever way of making proposals for acceptance or rejection in the Metropolis 
algorithm. While the procedure is more general, we focus directly on obtaining 
Hamiltonian proposals that will be used in the Metropolis algorithm.
4.4.4.2 Expanding the Parameter Space
Suppose we have a statistical model with parameter в € Q, with prior p(0) and data 
generating distribution p(y | 6), resulting in the posterior p(0 | y). There may be 
covariates and the data components may be conditionally independent or not. The 
model may be nonlinear in the parameters. The goal is to obtain posterior samples 
of в. Let the dimension of в be r, which is allowed to be large.
Next define the auxiliary random variables <5 ~ M-(0, D) with D = diag{dj : 
i = 1,... , r}, and we assume that <5 is independent of (0, y), which implies that <5 
is independent of в given y. Thus we can define the joint pdf
?(M I У) =P(0 13/)p(<5)> 
(4.4)
By auxiliary, we mean that these variates, <5, have nothing to do with the model for 
the data or the prior information about it. They are constructed as a clever device 
that will facilitate good proposals that can be used to obtain iterates from the 
target distribution, p(0 | y). The way this is done is to regard the joint distribution 
in equation (4.4) as the target distribution. Once we have samples from it, we 
simply disregard the iterates for r-dimensional <5, and use the iterates for в to make 
inferences. In fact, the iterates for <5 are removed after each full iteration of the 
algorithm; there is no need to waste space storing them.
4.4.4.3 Basics of Hamiltonian Dynamics
For this setup, the Hamiltonian function is defined as p(0,6 | у) ос ехр{-Я(0, <5)}, 
where
H(M) = -log(p(M|p))
= - log(p(0 | p)) - log(p(<5)) 
(4.5)
= L/(0) + K(<S).
In physics, the function is called the potential energy that corresponds to the 
“position." 6. and the function К (d) is called the kinetic energy, which is determined 
by the “momenta," 8. Momentum would have physical meaning in a real physical 
problem, but here it is used as a device, so we do not discuss its meaning. The 
Hamiltonian function H is termed the total energy.

Computational Methods for Bayesian Analysis 
99
These terms are very much related to the mechanics of physical systems that 
involve objects or particles moving in space, water or on surfaces. Different choices 
for U and К correspond to different physical systems. Here, we are focused on 
sampling from the support of the distribution p(0 | y).
The range of the mapping 0 
t/(0) defines a space. For a log-concave posterior
with dim(0) = 2, C/(0) looks like a bowl, perhaps somewhat irregular in shape 
but still having a smooth surface, due to its convexity, sitting on top of a table 
or floor that corresponds to the support of the posterior. The bottom of the bowl 
corresponds to values in the support that have highest posterior density. There 
are contours of the bowl that correspond to level sets in the support, namely. 
{0 G R2 : p(0 I j/) = c} = {0 6 R2 : t/(0) = — log(c)}. Our goal is to "explore" 
the entire space by iterating through values for 0 that will be accepted by the 
Metropolis procedure.
Here is where the magic comes in. In order to explore this space, an expanded 
space, called phase space, is considered. The expanded space is the support of 
the mapping (0,5) —> H(0,5). This is a mapping from R2r, the 2r-fold Cartesian 
product of the real line, R. Note that the parameter space fi is a subset of this 
space. The mapping that actually defines how we would obtain candidate iterates 
is determined by a set of differential equations, called Hamilton’s equations.
The mechanics of physical systems involves the evolution of particles or masses 
in space, here (0,5), and time, t. So far there has been no mention of time; this would 
be obvious to physicists in the context of a real physical mechanistic system. Here, 
time is fictitious. But we insert it into the problem in order to use the Hamiltonian 
physics. The Hamilton equations are
d0(t) 
9H(0(t),^)) 9K(6(t)) г
~dT = --------96--------= 
= 
6(i)’ 
(4>6)
d5(t) 
ая(0(«),5(0) 
at7(0(t)) л
~dF =-----------96--------=---------90- =W))’
where £(0) = c?log(p(0 | y))/96. Note that we have taken the Hamiltonian that 
did not depend on t and forced it to depend on t. Derivatives are with respect to 
the fictitious t, which implies that the solution to these equations is a deterministic 
process in t.
The solution of Hamilton’s equations of motion will yield a trajectory in terms of 
positions, 0(t), and momenta, 5(t), as functions of time, say Tt{<$(£))} : t > 0, 
which is only implicitly defined. There are three major properties of the system 
that correspond to these equations:
• 
H(0(t),5(t)) = H(0(t + s),6(t + s)) for all t,s > 0. This follows since = 
0, which holds by using the chain rule and equations (4.6). This is termed 
conservation of energy, since the total energy is conserved by the Hamiltonian 
along its path. This then implies that the joint pdf, p(0,<5 | y), is constant 
along this path as well. In other words, the level sets of the target density are 
the same as the level sets of the Hamiltonian.
Consider a region, E, of the phase space that is the support ofp(0,6 | y). Then

100
Bayesian Thinking in Biostatistics
consider the transformation of that region to the set, say E', by the mapping 
Ta : 
+ s),6(t + s)), which was determined by Hamilton’s
equations. Then the volume of E is the same as the volume of E1. This is 
termed conservation of volume in Hamiltonian dynamics.
• 
The mapping Ta : (0(t),<S(t)) -> (0(t 4- s),6(t + s)) is one-to-one. This im­
plies that Hamiltonian dynamics are reversible. What does reversibility mean? 
Since the transformation Ta is one-to-one, it has an inverse, which is termed 
T_a. Reversibility in this context means that this process can be run in reverse 
time and that it will maintain the same properties as the original.
We are now in a position to generate candidates that can be tested for accept­
ance using the Metropolis sampler. We observe from the first bullet, however, that 
no matter what increment of time, s, is selected, p(0(t), <J(t) | y) = p(9(t+s'),6(t+s') | 
?/), and so the Metropolis acceptance probability will always be 1. This sounds like 
a really nice feature provided that, as argued in Neal [248] and in Betancourt [42], 
the value would behave as if it were a random iterate from the target distribution. 
But this is only a single iterate. We could continue obtaining values for s = 1,2,..., 
up to some finite number, but we would only be sampling values from the level set 
corresponding to whatever initial values we used for (#,£).
In order to sufficiently explore the phase space, we would need to construct an 
appropriate mechanism for moving from one level set to another. Moreover, we have 
assumed that we could solve Hamilton’s equations analytically, which would rarely 
be the case. So it is time to discuss the approximation that we mentioned above.
4.4.4.4 Approximation to Generate Candidate
While Neal [248] gives a simple example in which an analytical solution to equations 
(4.6) is easily obtained, such analytic solutions are not possible in general. So why 
have we spent this much effort to end up at an apparent dead end? A lesson for 
everyone is that exact solutions are often not possible, but good, useful approximate 
solutions often are. This is indeed the case here. For the approximation to work 
well, it must satisfy the properties discussed above, and the approximation can 
obviously be better understood by knowing what it is approximating.
We now switch to more familiar notation for MC iterates. The goal is to obtain 
t = 0,1,... ,M}, starting with an initial value and obtaining M iter­
ates from a Metropolis Markov chain with target distribution p(0,8 | y). We regard 
the current iterate as (0(t),<S(t)), and the goal is to describe how we obtain the next 
iterate, (0(t+1).using an approximate Hamiltonian technique.
The approximation has two phases for obtaining a new iterate given the current 
iterate. The first phase randomly selects a new vector for 6, say 6*  ~ Nr(0. D), 
and replaces the current iterate with (0^,6
*).
 The reason for doing this is that, as 
discussed earlier, the exact Hamiltonian dynamics resulted in the next iterate being 
restricted to the same level set as the current iterate. By randomly selecting 8*  and 
replacing with it. this problem is avoided. The question arises as to whether 
modifying the current iterate in this way will affect the stationarity of iterates, that 
is. can they still be regarded as having come from the target distribution?

Computational Methods for Bayesian Analysis 
UH
Since 6 is independent of в given у at every iteration, sampling <5*  ~ ,Vr(0. D) 
can be regarded as sampling from the conditional distribution of 6 | в.у. Then 
since p(0,6 | y) = p(6 | y)p(8 | 0,y) is the target distribution at every iteration of 
the Metropolis sampler, and since the current value 0(t) can be regarded as having 
come from the marginal for 0 | y, the new pair (0(t\d'
*)
 can also be regarded as 
coming from the stationary distribution (of course, after some burn-in). We now 
relabel (0^,5
*)
 = (0^,6^) for the sake of notation, recognizing that what used 
to be 6^ was replaced by the new vector <5
*  that has now been relabeled as
The second phase involves approximating Hamilton’s equations by consider­
ing discrete time and by incrementally using some small step size e, repeatedly L 
times, in order to obtain a candidate for 
For dealing with Hamilto­
nian mechanics, we revert temporarily to the notation (0(t).<5(t)), which for fixed t 
equals <5^), and where we consider time that is local to that value and can be 
considered in steps of size e. The method is termed leapfrog. It consists of iterating 
the steps
6(i + e/2) = 5(i) - (e/2)^(0(i)), 
da
«(
*
 + <) = «(t) + €^(5(t + e/2)), 
(4.7)
do
W + ') = 5(i + e/2) - (e/2)^(0(t + e)) 
da
L times in order to obtain one candidate in the overall Metropolis scheme. Here 
dU/dO and dK/d8 are both r-dimensional vectors of partial derivatives, and we have 
selected К(<5) = 0.5 ^=1 8l/di. The main reason for taking multiple steps is to 
leap to a further point in the space, resulting in less autocorrelation and ultimately 
exploring the space more broadly.
At the end of phase two, we ultimately obtain a single final iterate of the leapfrog 
procedure at local time Le. This iterate is taken as the new proposal for (0(t + 
1), 6(t + 1)). We label this final local iterate as (0
*,<5
*),
 and either accept or reject 
it, with the acceptance probability
min[l, p(0
*,<5
*
 | !/)/p(0(t),<S(t)) | !/)]•
Neal [248] gives R code for implementing the leapfrog and gives illustrations 
of the implementation. A nice illustration is also given in Shahbaba et al. [292] in 
the introductory part of their paper, before they move on to discuss a potential im­
provement in the Hamiltonian procedure by splitting the Hamiltonian. For practical 
Bayesian computations, the software Stan, discussed and illustrated in Appendix 
C, makes extensive use of Hamiltonian Monte Carlo.
Remark. The initial approximation that was used to approximate the exact Hamil­
tonian equations (4.6) was to simply approximate each equation with a first-order 
Taylor series approximation to 0(t+e) and to 6(t+e), expanding each as a function 
of (small) e for fixed t. The Hamiltonian derivatives in equation (4.6) were used 
to obtain the first-order derivatives in the expansions. But the approximation was 

102 
Bayesian Thinking in Biostatistics
poor. The leapfrog equations replaced this first attempt, and iterates obtained from 
using them have been found to satisfy all of the properties that were discussed for 
the exact approach. These features are ultimately responsible, according to Neal 
[248] and Betancourt [42], for approximate Hamiltonian iterates to move rapidly 
through the phase space, with appropriate choice of (e, L).
Remark. It was mentioned that the step where <5 was simulated from the Nr(0, D) 
distribution was crucial for moving from one level set to another at each full itera­
tion. It should also be mentioned that conservation of energy dictates that if K(6) 
is larger in a new iteration, then [7(0) must be smaller so that the sum remains the 
same. The sum of the kinetic and potential energies is conserved.
4.4.5 Convergence Diagnostics
Most methods for assessing convergence rely on informal evaluations of individual 
parameters or functions of parameters. With a small number of parameters of in­
terest, monitoring each individually is not too burdensome. On the other hand, if 
there are many parameters and one does not monitor all of them, one may be fooled 
into thinking that the process has converged based on the apparent convergence of 
the subset under examination.
Many convergence diagnostics are available in the R packages coda and boa. 
Several of the routines that are part of coda are built into OpenBUGS. Aside from 
providing built-in tools for assessing convergence, both of these packages also in­
clude functions to simplify the process of loading saved iterates from an MCMC 
program into R. The purpose of moving MCMC iterates into an analysis environ­
ment like R is to be able to manipulate the output when creating summary Bayesian 
inferences and/or to create pretty pictures of numerical approximations to posterior 
and predictive distributions.
Trace and History Plots. After we carry out an iterative method to generate 
samples from the posterior distribution, we will be interested in showing that the 
method did, in fact, converge. If the algorithm has not converged, then the generated 
values may not be random samples from the posterior distribution.
We first give an illustration of what a (non-Markov chain) iid Monte Carlo 
sample from a known bivariate distribution looks like as the sample size increases. 
Figure 4.4 illustrates an example in which we generated random samples from 
a bivariate normal distribution. Since we know how to sample bivariate normals 
exactly, all pairs are exact and there is no need for a burn-in. In the figure, there 
are separate graphs showing what happens after 5, 10, 25, and 100 iterations. Each 
graph shows sequential iterates for four sequences of bivariate normals, which is 
analogous to what we will do when we have actual MCMC iterates. This example 
illustrates how iterates should look in a vanilla setting where we can sample directly 
from the target distribution.
When thousands of iterates are generated from the posterior distribution, a plot 
such as Figure 4.4 will show a thick cluster of points piling up in the center but it 
will not be too helpful in terms of evaluating a trend towards convergence. There

Computational Methods for Bayesian Analysis
103
FIGURE 4.4: Paths taken by four different sequences, with different symbols indi­
cating the initial points. Each path represents MCMC samples from the same joint 
posterior distribution.
are several ways we can monitor convergence. The easiest way involves plotting the 
history of the generated iterates for each parameter or variable, starting with the 
first saved value. We produce these trace or history plots by graphing the iterates 
as a time series, with iteration number on the X-axis and the iterate itself on the 
У-axis, to show the history of the consecutively generated random samples. The 
trajectories should eventually look like white noise without a discernible trend or 
hiccup.
Starting chains at different initial values is a way to show that we have reached 
convergence. That is, we should run two or more parallel chains, each starting 
from a different initial value. If the algorithm converges, then regardless of the 
initial values, all of the chains will generate random samples from the same target 
distribution. If plotted on the same graph, the individual trace or history plots 
should merge together at some point and then stay together. If the chains remain 
separate after several thousand iterations, then there is potential for a convergence 
problem.

104
Bayesian Thinking in Biostatistics
(a)
g[6] chains 1:2
ЙМШ
5000 
10000 
15000 
20000
(C)
Or chains 1:2
(b)
pi[19] chains 1:2
1 
250 
500 
750 
1500
(d)
Or chains 1:2
501 
750 
1000 
1250 
1500
50000 60000 
80000 
100000
FIGURE 4.5: Four history plots each with two chains that start at different values. 
Plot (a) shows chains merging sometime before 5000 iterations. Plot (b) shows 
chains that separate and then start to merge. Plot (c) shows chains that are wildly 
distinct and which show high autocorrelation (see next section). Plot (d) shows 
chains that appear to be merging after 50,000 iterations, but where it is not quite 
clear if they have really merged yet.
Figure 4.5 shows four plots of histories where plots (a) and (d) are reasonably 
well behaved and plots (b) and (c) are not. The chains in (a) are well behaved and 
appear to have converged before 5,000 iterations. Plot (b) shows possible merging 
of chains at around 500 iterations, but we would want to see more iterations to be 
comfortable. The chains in (c) are wild up to 1,500 iterations and display strong 
autocorrelation, which is discussed next. The chains in (d) are continuations of the 
chains in (c) and they appear to have merged reasonably well by 50,000 iterations, 
but there may still be some doubt about convergence.
Quantile Plots. An additional type of plot involves plotting running estimates of 
the moan and the 0.025 and 0.975 quantiles of the iterates for each variable that 
is monitored. These are numerical approximations to the posterior mean and the 
values that would ultimately give 95% posterior probability intervals. The running 
estimates art' based on iterates up to fixed numbers of iterations, as this number 
grows. Approximating these quantiles based on a small number of iterates is in­
evitably unstable, while the more iterates there are, the more stable the quantile

Computational Methods for Bayesian Analysis
105
(a)
(b)
Teta(1]
1249 
10000 
20000
10 
10000 
20000
FIGURE 4.6: Two history plots of two chains that start at different values and 
their corresponding quantile plots. Plot (a) shows a well-behaved history plot after 
10 iterations, while plot (b) shows the corresponding well-behaved quantile plot. 
Plot (c) shows a badly behaved history plot, while plot (d) shows the corresponding 
badly behaved quantile plot.
(d)
Or chains 2:1
541 
750 
1000 
1250
approximations should be. If there is a lack of convergence, the running quantiles 
should be unstable until convergence has occurred.
Figure 4.6 shows history plots for two chains and their corresponding running 
quantile plots. Plot (a) shows a very well-behaved chain and plot (b) shows the cor­
responding very well-behaved quantile plots. Plot (c) shows badly behaved histories 
and plot (d) shows the corresponding badly behaved quantiles.
Autocorrelation Plot. Many MCMC methods generate samples from the poster­
ior distribution (after a burn-in period), but these samples are often autocorrelated. 
For example, the Metropolis-Hastings method allows the iterate (i.e., sample) at 
the next iteration of the sampler to remain at the same value as the current iter­
ate. A graphical illustration of the autocorrelation as a function of the lag between 
iterates is often helpful. The sample autocorrelation for lag A: in a sequence of M 
saved samples of в is
Pk = ^=~k [(0(>+fc) - (№(i) ~ £)]

106 
Bayesian Thinking in Biostatistics
So with к = 1, pi is the Pearson correlation between running adjacent pairs of iter­
ates. We expect the autocorrelation to decrease as the lag increases. In other words, 
if the chain is mixing well, then there should be less correlation—hopefully much 
less—between values 20 iterations apart than between values only one iteration 
apart.
Figure 4.7 shows two chains and their corresponding autocorrelations. Plot (a) 
shows a well-behaved chain with modest autocorrelation, shown in plot (b), which 
has virtually disappeared by lag 10. Plot (c) shows a reasonably well-behaved chain 
but with exceptionally high autocorrelation, shown in plot (d).
0 
20 
40
lag
(C)
(d)
421
°|:liiniinilllllllll№l
-0.5-
■1.0L__________ ___________
0 
20 
40
lag
FIGURE 4.7: Plot (a) shows a history plot for a well-behaved chain, and plot (b) 
shows the corresponding autocorrelation plot. Plots (c) and (d) give the same plots 
for a chain with high autocorrelation.
A problem caused by autocorrelation in the sample is that the effective sample 
size (i.e., the effective number of independent samples from the posterior) is gen­
erally smaller, and sometimes much smaller, than the number of samples that are 
kept (ЛГ = .W - burn-in).
We illustrate by considering a hypothetical situation. Suppose our target dis­
tribution is the posterior for a parameter 0. Then assume that samples based on 
a particular MCMC approach are first-order autocorrelated. This means that the 
true correlation between samples к units apart is pk, for к = 1,2,.... So the true 

Computational Methods for Bayesian Analysis
107
first-order autocorrelation is just p > 0. Then, using time series theory, one can 
show that the standard error of the MC sample mean3 of АГ kept iterates for 0 is
M 1 + P
M'l-p'
where ag is the posterior standard deviation of в. The smaller this is, the better is 
the numerical approximation. Note that with p = 0. the standard error follows the 
usual formula, ад/'/M'.
Consider a sample mean approximation to the posterior mean based on an 
uncorrelated sample of size M
*.
 It will have standard error ag/\/M
*
. Then equate 
this to the above correlated sample’s standard error and solve for the sample size 
M' that will give the same standard error as the uncorrelated sample. The solution 
is M' = [(1 + p)/(l — Since the multiple of M
*  is greater than or equal 
to 1, this shows how much larger the correlated MCMC sample must be in order 
to achieve the same standard error as one would achieve with a sample of M
*
 
uncorrelated samples. For example, if p = 0.5, one would need three times as large 
a sample. If p = 0.75, the required number increases to sevenfold.
One approach to reducing autocorrelation is to re-parameterize the model and 
thereby reduce the correlation among the parameters. An example of this approach 
is centering the covariates (Figure 4.8b) in a regression model, which will also 
improve mixing from Figure 4.8a.
(a) Uncentered covariate in linear regression
FIGURE 4.8: Centering covariates, plot (b), reduces correlation between slope and 
intercept and improves mixing, compared to the model without centering the co­
variate, plot (a).
Another way to reduce autocorrelation is by thinning. This means keeping the 
value generated by every rth iteration after convergence is reached. In general, then,
(b) Centered covariate in linear regression
'Numerical approximation to the posterior mean is 0 = 0м/М'. 

108
Bayesian Thinking in Biostatistics
if (I = BI + 1,..., M) is a sequence of M' = M - BI values generated by an 
MCMC method (e.g., Metropolis-Hastings) after discarding the first BI iterations 
as burn-in, and if one wishes to thin by r = 10, then one would retain iterates 
z(B/+u) z(B/+2i), One can determine a useful value of r by examining 
plots of the autocorrelation in the MCMC sample for different choices.
We caution the reader that thinning amounts to reducing the information in 
the MCMC sample, so that MC standard errors for posterior mean approximations 
may increase. Moreover, reducing autocorrelation does nothing to help convergence. 
There is an advantage, however, if iterates are to be used to subsequently make plots 
of posterior or predictive distributions. Huge MCMC sample sizes can make this 
task unpleasant, so thinning can be useful for this purpose.
Are We There Yet? Beyond plots, there are some recommended and useful 
statistics we can compute to judge if we have reasonably arrived at convergence. 
Two such are by Geweke [142] and Brooks, Gelman, and Rubin [138, 56]. There 
is also a method developed by Raftery and Lewis [266] that estimates how many 
additional samples may be needed to achieve convergence.
Geweke. If the Markov chain leading to random samples from the posterior distribu­
tion has converged, then random subsets of the realized iterates should behave like 
random samples from the posterior and, thus, be similar to one another. Geweke 
[142] proposed carrying out a modified two-sample test to compare means between 
subsets.
For example, one can take the first 20% of the sample iterates for 0 (after a trial 
burn-in) and the last 50% of the sample and test for equality of the means. If each 
batch is a random sample from the same distribution, the resulting test statistic 
should not show a “significant” difference in the frequentist sense. Geweke’s pro­
cedure is like the normal Z test to compare two means (provided the two sample 
sizes are large), except that the standard error of the difference accounts for au­
tocorrelation in the subsets. Asymptotically, the standardized difference follows a 
standard normal distribution, allowing one to assess indirectly whether the sampled 
values follow the same distribution. Rejection of the null hypothesis that the means 
are the same will imply that the chain may not have converged, that is, a larger 
burn-in is needed. Of course if the sample sizes are too large, then the rejection 
may involve only a slight difference in the two means that would be of little or no 
practical import.
Brooks-Gelman- Rubin. Alternatively, as mentioned earlier, an intuitive approach to 
assessing convergence is to start several independent and parallel chains at different 
widely dispersed initial values and to see if the iterates from the separate chains 
manage to be distributed around the same central value and have the same amount 
of variability after sufficiently many iterations. The Brooks-Gelman-Rubin (BGR) 
method [138. 56] formalizes this notion by comparing the between-chain variation 
to within-chain variation.
Consider a parameter of interest, say 0, which may be a function of one or 
several model parameters. Suppose that J independent MCMC sequences have been 
sampled, each starting at a different value. Also, suppose that M' iterates remain

Computational Methods for Bayesian Analysis 
109
for each chain. Let 0^ be iterate i from chain j. i = 1........j = 1...................J. Also
let
л/' 
j
0j =^0^/М',
which are each numerical approximations to the posterior mean of 0, the first based 
on only chain j and the second based on all J chains. If all iterates are from the 
target distribution, both are appropriate approximations to the posterior mean, but 
the overall mean would be preferred since it is based on a larger MC sample size, 
J x M'.
Throughout, we suppose that a particular test burn-in value has been specified 
and the corresponding iterates discarded for all J chains. We discuss two different 
approaches to the BGR method.
The simplest approach proceeds as follows. For each parameter, obtain a plot 
of the running ratio (as a function of M') of the width of an 80% credible interval 
based on pooling the chains to the average of J 80% interval widths for the J 
chains. Thus the numerator interval approximation is based on all of the {0^ : i = 
1,..., M’;j = 1,..., J} values considered as a single sample of size J x M', and 
the denominator interval is based on the average of the J intervals, with interval 
j based on {0^г) : i = 1,..., M'}, across j = 1,..., J. If the chains have converged 
before the selected burn-in, this ratio should be close to 1, since all of the 80% 
intervals are valid approximations to the actual posterior 80% interval for 0. Using 
different test burn-in values, one finds the value where this ratio is subsequently 
close enough to 1. WinBUGS and OpenBUGS, in particular, provide this type of 
diagnostic plot.
The second approach recognizes that the structure here is like that of a balanced 
one-way analysis of variance (ANOVA) with J factors and M' observations per 
factor. The between-chain variation estimator is defined as
j=l
where SSB is the sum of squares between chains, and MSB is the between-chain 
mean square, by direct analogy with ANOVA. If the all samples are from the actual 
posterior distribution, namely if the test burn-in is large enough, then MSB is an 
unbiased estimate of aj, the posterior variance of 0.
Within-chain variation is defined as
j=l 
1=1
where sj is the usual (frequentist unbiased) estimate of the variance of the iterates 
from chain j. If all chains are being sampled from the posterior for 0, then W is a 
pooled (unbiased) estimate of the common posterior variance of 0, aj. In fact, W is 
the usual pooled estimate of the common variance in an ANOVA setting, referred 

no 
Bayesian Thinking in Biostatistics
to as the within-chain mean square (MSW) variability. If the iterates were from 
normal distributions with common variance, the ratio F = MSB/MSW is the usual 
Fisher F statistic for testing that all J means are the same.
★Remark. It is not difficult to show that the expected value of MSB under general 
assumptions is 
(/Ъ~Д)2’ where ej is a column vector
of J ones, Ej is the M' x M‘ variance covariance matrix of M' iterates from chain 
j, p,j is the expectation of Oj, and p = ^=1 iij/J- Let Im> be the M'-dimensional 
identity matrix. Then if Ej = Zm'O’J for all j, namely if the iterates for each chain 
were independent with distinct variances, and defining a2 = a2/ J, we find that 
the simplified expected value of MSB is a2 + A/z 
- Д)2- Finally, if the a2
are equal to and the p.j are all equal, which they will be after convergence, we 
see that the expected value of MSB is indeed aj. The case with dependent iterates 
(e.g., Ej 0 iM'&j) is more difficult to show.
Another numerical approximation to aj is given by BGR as the weighted average
= f1 - тЙ W + 777MSB- 
e \ 
M'J 
M
If the chain has already converged and the burn-in discarded, this is an unbiased 
estimate of cr|. Both W and MSB will converge to a# as M' grows. However, before 
convergence, it is generally expected that the weighted average will be large and 
thus exceed <t|. This will certainly be the case in the beginning of the chain due 
to overdispersed initial values and since it is generally expected that the MCMC 
means for different chains will be somewhat different for the early part of the chains.
A slight modification of the BGR criterion for convergence is based on the ratio 
where F = MSB/MSW = MSB/W. Thus a large value for the Fisher F statistic is 
an indication of lack of convergence. BGR anticipate this ratio to be greater than 
1 before convergence, but under the appropriate assumptions for the Markov chain 
to converge, it will approximate 1 as M' grows. The user would increase the test 
burn-in until the value of R is sufficiently close to 1 (say, no greater than 1.2) for 
all iterates after a selected value.
How many iterations until convergence? Raftery-Lewis method. An approach pro­
posed by Raftery and Lewis [266] provides an estimate of the number of additional 
iterations one needs before one can be confident that convergence has been achieved. 
The method requires that one choose a tail quantile q (e.g., 2.5%, 5%, 97.5%), a 
level of accuracy £. and a power for reaching this degree of accuracy for the quantile 
of interest. One then forms a sequence of Os and Is by comparing the saved samples, 
0^. to the quantile q. That is. the jth element of the sequence is 1 if 0^ < q and 
0 otherwise.

Computational Methods for Bayesian Analysis
The method then involves thinning the sample, say by keeping every / th sampled 
value, where r is selected to be large enough that autocorrelation for the 0 chain is 
approximately of order 1, meaning that the transition probability involving the next 
iterate given all previous iterates only depends on the current one. Consequently, 
the sequence of Os and Is is an approximate two-state Markov chain. Using the 
thinned series of 0/1 iterates, transition probabilities can be estimated. For example, 
the estimated (approximate) conditional probability of transitioning from state 0 
(corresponding to 0^ > q) to state 1 (corresponding to 0^ < q) is just the number 
of times the thinned chain has a 0 followed by a 1 divided by the number of thinned 
iterates that equal 0.
The Raftery-Lewis method uses these estimated transition probabilities to (i) 
suggest the number of additional burn-in iterations required before one can be con­
fident about convergence to stationarity, (ii) to assess the fraction of intermediate 
saves to discard (i.e., thinning), and (iii) to determine a value for the length of 
the chain (i.e., the number of saved samples) that one will need to achieve the de­
sired degree of accuracy. The computation is based on estimating the quantile to a 
prespecified level of precision.
One may wish to evaluate several quantiles of the quantity of interest and then 
choose the largest number of iterations recommended by the procedure. Clearly, if 
one is interested in making inferences for several model characteristics, then one 
will need to evaluate this statistic for each. The number of such evaluations can 
become large.
To summarize, overall in practice, it is important to check sufficient burn-in and 
avoid long persisting autocorrelations. Then, with sufficient burn-in and moderate 
to low autocorrelations (after thinning if needed), one should routinely compute 
the Monte Carlo error for all quantities of interest while taking into account the 
residual correlations.
4.5 
Recap and Readings
In this chapter we focused on how to accomplish calculation of quantities needed 
for inference. Although we began with some analytic methods, the main workhorse 
of Bayesian inferential computations is simulation of samples from the posterior 
distribution. Not only are such methods widely applicable, they are often more 
useful than analytic forms as they allow easy inference for functions of original 
parameters. The transition to sampling-based inference began in earnest with the 
advent of the Gibbs sampler, as described in the seminal paper by Gelfand and 
Smith [132]. Although the Metropolis and Metropolis-Hastings algorithms existed 
long before, the role of Markov chains in Monte Carlo simulations was clarified by 
Tierney [327], leading to much development and usage in Bayesian inference. Two 
accessible and well-written articles explain the Gibbs sampler and the Metropolis- 
Hastings algorithm. The first is by Casella and George [66], and the second is by 
Chib and Greenberg [73].

112
Bayesian Thinking in Biostatistics
As we have seen, all these methods depend on simulating random variates with 
various specified distributions. A classic and excellent book discussing such simula­
tion is by Devroye [95]. The adaptive rejection sampler for log-concave densities is 
described by Gilks and Wild [143, 354]. Development of BUGS and WinBUGS fol­
lowed soon after. This enabled Bayesian data analysis for a wide range of statistical 
models. The evolution and direction of the BUGS project is described by Lunn et 
al. [232, 233], all of whose co-authors played key roles in its origination and growth.
4.6 
Exercises
Exercise 4.1. Let Y | 6 ~ Bin(n, 0). Let p(ff) a. 0a-1(l - 0)6-1, with a, b > 0.
(a) 
Using the method discussed in Section 4.2, obtain an explicit formula for the 
normal approximation to the posterior for в and identify the corresponding distri­
bution.
(b) 
Now with a = b = 1, let observed y/n = 0.5. Then, for n = 10,20,50, plot 
the true posterior and the approximate posterior together on three separate plots. 
Comment on the quality of the approximation as n increases.
(c) 
Again with a = b = 1, let observed yin = 0.10. Find the smallest n such that 
the normal approximation has 99.5% actual posterior probability that в > 0. Then 
compare that approximate posterior to the true one on the same graph.
Exercise 4.2. Let Yi,..., Yn | 9 ~ Ро(Л), independently. Let р(Л) а Ло-1е-ьл, 
a, b > 0. And let S = 
1$, the sum of the Poisson random variables.
(a) 
Recall that S | Л ~ Ро(пЛ). Show that the likelihood based on the sample of n 
observations, i/i,... , pn, is the same as the likelihood based on the observed S = s 
provided s = ^xyi- We say that the sum, S, is sufficient for making inferences 
about в so that it is unnecessary to know the actual values of the y^ Technically, 
when the likelihood factorizes in this way, the statistic S is termed Fisher sufficient, 
in honor of Sir Ronald Fisher.
(b) 
Using the method discussed in Section 4.2, obtain an explicit formula for the 
normal approximation to the posterior for Л and identify the corresponding distri­
bution.
(c) 
With a = b = 1, let s/n = 1. Then, for observed n = 10,20,50, plot the true 
posterior and the approximate posterior together on three separate plots. Comment 
on the quality of the approximation as n increases.
(d) 
Again with a = b = 1. let observed y/n — 0.10. Find the smallest n such that 
the normal approximation has 99.5% actual posterior probability that Л > 0. Then 
compare that approximate posterior to the true one on the same graph.
‘Exercise 4.3. For the data and model described in Exercise 4.1, obtain the 
Laplace approximation to the posterior mean for 6. Compare the approximation to 
the known posterior mean for this situation.

Computational Methods for Bayesian Analysis 
113
*Exercise 4.4. For the data and model described in Exercise 4.2. obtain the 
Laplace approximation to the posterior mean for Л. Compare the approximation to 
the known posterior mean for this situation.
Exercise 4.5 Suppose you have a black-box simulator that can give you in­
dependent E'xp(l) = Ga(l,l) random values. Recall that if X ~ Ga(a,b). then 
cX ~ Ga(a,b/c) for a,b, c > 0. Then explain how you would use those values to 
obtain the following RVs.
(a) 
Ga(10,l) and Ga(10,l/2).
(b) 
Xio> a chi-square with 10 degrees of freedom.
(c) 
The Fisher F(r fc), an F distribution with numerator and denominator degrees 
of freedom r and k, respectively, for positive integers r and k.
(d) 
A Student’s t distribution with к degrees of freedom.
Exercise 4.6 Let Y | a,X ~ Weib(a, A). Recall that the cdf for Y is F(y) = 
1 — e~Xya. Using the inverse cdf method for simulating variates, explain how to 
simulate from this distribution.
Exercise 4.7. Generate samples from Ga(0.6,0.5) by using the SIR algorithm 
with Ga(0.5,0.5) as the initial sampling distribution. Note that Ga(0.5,0.5) is x2(l), 
which you can generate by squaring standard normal samples. Make plots as in 
Figure 4.3 to verify your sampling.
Exercise 4.8 Code the truncated normal algorithm of Example 4.1. Generate 
samples with c = 2 and c = 10. Empirically verify the corresponding sample ac­
ceptance probabilities given in the table of Example 4.1. Plot a sample histogram 
and the target density for the c = 2 case.
Exercise 4.9. Consider the rejection sampling algorithm to generate samples 
from Be(1.5,1.5), which has density proportional to /(x) = x0,5(l — x)o,5Z(oii)(x), 
using p(x) = Z(01)(x), that is, a uniform.
(a) 
Specify the steps of the algorithm.
(b) 
Derive the sample acceptance probability.
(c) 
Code the algorithm, (i) Generate samples and empirically verify your answer to 
(b). (ii) Plot a histogram of samples and superimpose the target density on it.
Exercise 4.10. Show log-concavity of p(a | X,data) in the Weibull model of 
Section 4.1.2 where p(a) is taken to be log-concave.
Exercise 4.11. With the exchangeable normal model for observations and inde­
pendent priors p ~ 7V(po, го)> т ~ Ga(a, b), show that the log of the joint posterior 
density is as given in Example 4.6. Recall that the N(/j,0,to) distribution has vari­
ance 1/tq.
Exercise 4.12. Assume equation (4.1) holds.

114
Bayesian Thinking in Biostatistics
(a) 
Prove that if an initial sample is taken from the target distribution and then 
a new sample is taken from the transition kernel, then the new observation will 
be from the target distribution. More specifically, prove that if 6° ~ p(-), and if 
01 | 0° ~ r(- | 0°) (e.g., according to the transition kernel with given 0°), then the 
marginal pdf for 01 is just 01 ~ p(-).
(b) 
Using induction, prove that under this sampling scheme, 0‘ ~ p(-) for t = 
0,1,....
Exercise 4.13. The general algorithm for the Gibbs sampler is given in Section 
4.4.1. In the two-parameter case, the transition kernel for moving from 0^ to 0O+1) 
is given by
r(0(t+1) | 0(0) = p(0(‘+1) | 0<t))p(0<t+1) | 0<t+1)),
where the second coordinate was sampled first, given the current value of the first 
coordinate, followed by sampling the first coordinate, given the newly sampled value 
of the second coordinate. Prove that this choice of kernel satisfies equation (4.1), 
where p(-, •) is the joint pdf of the target distribution that was used to obtain the 
full conditionals p(02 | 0i) and p(0] | 02) that were used in the definition of r(- | •) 
above. Of course we could have reversed the sampling order and the same result 
would obtain.
Exercise 4.14. Weibull data. Suppose a random sample of 10 bone marrow 
transplants done in 2005 showed the following survival times (available in datafor- 
Weibull.csv on the book’s website):
7.64, 7.21, 1.05, 0.73, 6.76, 0.85, 1.20, 3.29, 3.29, 6.29.
Modeling these as exchangeable Weibull observations, and using priors as in Ex­
ample 4.4, use OpenBUGS, JAGS or Stan to obtain posterior inferences that can 
be used to address the questions below. Take a0 = 0.1, Ло = 0.05; this yields a 
prior mean of 2 and a standard deviation of л/40 for Л. Further, take a = 1.62 and 
b = 3.32; this corresponds to a prior median of 2 and a 95th percentile of 10 for ф.
(a) 
Perform convergence diagnostics for posterior samples of a and Л.
(b) 
Plot posterior densities for a and Л.
(c) 
Plot the posterior density for median survival in the population from which this 
sample was taken. Compute a 95% probability interval for the median.
(d) 
Plot the posterior density for the probability of surviving 5 years. Also give a 
95% probability interval for this probability.
(e) 
It turns out that these data are not real data from patients! These numbers 
were generated from a Weibull with о = 1.7 and Л = 0.2. Plot this true density 
and a density that you would estimate from the data on the same graph. Justify 
your estimate of the density. You may use R for this part, with samples saved from 
OpenBUGS. JAGS or Stan.
(f) 
How would you obtain an estimate of the density that included pointwise 95% 
probability intervals over a grid of ordinates for it?
(g) 
Show that the prior for ф above has median 2 and 95th percentile 10.

Computational Methods for Bayesian Analysis
115
Exercise 4.15. Gamma data. Data for this exercise are in dataforGamnia.csv 
on the book’s website. Model these 300 observations as arising from a gamma 
density. Use the same priors as in the previous problem, as these represent very 
little prior information in this setting also. Answer the following questions (e.g.. 
with OpenBUGS, JAGS, or Stan).
(a) 
Perform convergence diagnostics for posterior samples of a and Л.
(b) 
Plot posterior densities for a and Л.
(c) 
Plot the posterior density for median survival in the population from which this 
sample was taken. Compute a 95% probability interval for the median.
(d) 
Plot the posterior density for the probability of surviving 5 years. Also give a 
95% probability interval for this probability.
(e) 
The data here were generated from a gamma with a = 1.5 and Л = 0.3. Plot 
this true density and the density you would estimate from the data on the same 
graph. Justify your estimate of the density.
(f) 
Construct an estimate of the survival function (probability) at each point on the 
grid (0,1 ,2, 5, 8,10,12,15) and corresponding pointwise 95% probability intervals.
Exercise 4.16. Let Y | 0 ~ Exp(0).
(a) 
Give an explicit algorithm for sampling from this distribution using the slice 
sampler.
(b) 
Sample 5,000 iterates with 0 = 1 using this algorithm. Then plot the history 
of the iterates. Does it look like there is convergence? If not, try deleting some 
initial iterates until the history looks like it might have converged. Take a larger 
MC sample size if needed to be superficially confident that the series has converged, 
(c) For your final selection of iterates, give a histogram and a plot of the exact pdf 
on the same plot. How well did you do?
Exercise 4.17. Let p(0 | u) and p(u | 0) be the full conditional distributions for 
the slice sampler. These distributions can be inferred from the sampling algorithm 
that is given in Section 4.4.3. Specify these distributions. They are both obviously 
uniform distributions, but care is needed in writing them down precisely. Since the 
slice sampler is implemented as a particular Gibbs sampler, Exercise 4.13 establishes 
that the corresponding transition kernel satisfies equation (4.1), and consequently, 
that sampling using the slice sampler results in samples from the target distribution, 
eventually, after some burn-in.
Exercise 4.18. Suppose that X and Y are random variables for which {(x, y) : 
p(x | y) > 0} = {(x, y) : p(y | x) > 0, and where these conditional distributions 
have been obtained by some means, not necessarily from a known joint pdf—for 
example, as illustrated in Exercise 4.17 with the slice sampler. We say that these 
conditional distributions are compatible if the ratio
Р(.У I x)/p(x | y) oc g(y)h(x), g(y)dy < oo, 

116
Bayesian Thinking in Biostatistics
holds for some functions g(-) and /i(-). It has been shown by Arnold and Press 
[12] that there exists a joint, possibly generalized, probability density function for 
the pair (X, Y) if and only if the conditional distributions are compatible. Thus in 
this instance, there is a joint pdf, say p(x, y}, that can be used to obtain the same 
conditional distributions above. On the other hand, if the conditional densities are 
not compatible, then there is an obvious problem. Suppose, for example, that we 
were to iteratively sample incompatible full conditionals using Gibbs sampling.
(a) 
Explain precisely what is problematic in probabilistic terms. Then discuss what 
might be problematic with the samples.
(b) 
Let Y | X = x ~ Exp(x) and X | Y = у ~ Exp(y). Show that these two 
distributions are incompatible.
(c) 
Iteratively sample the full conditionals in (b) and monitor the histories for 
X and Y. Are they well behaved? What can be said about any possible target 
distribution?
Exercise 4.19. (a) Using Exercises 4.17 and 4.18, argue that the full conditionals 
in Exercise 4.17 are compatible and thus that there exists a joint density, p(0,u), 
that gives rise to those full conditionals for the generic slice sampler. This means 
that p(0 | u) = p(0,u)/p(u) and p(u | в) = p(0,u)/p(0), where we have p(0) = 
J p(0, u)du and p(u) = f p(0,u}d0. Note that no such joint pdf has been given. It 
immediately follows that p(0 | u)/p(u | д') = p(0)/p(u) oc p(0). Thus, there has been 
cancellation of parts that involve both в and p in order for the ratio to be a simple 
function of 0 alone divided by a simple function of и alone.
(b) Taking the ratio of full conditional densities for the slice sampler, obtain the 
kernel of the marginal pdf for 0 and identify it. For this problem, the parts in 
numerator and denominator that involve both parameters mixed up together are 
indicator functions. The goal is to show that these indicator functions are identical 
and thus cancel out in the sense that either both are 1 or both are 0. Just ignore 
the 0/0 issue.
Exercise 4.20. Modify the code in Example 4.2 to obtain inferences p, a, for 
the coefficient of variation, cr/p, and for Ф[(2 - p)/cr], the proportion of samples 
from the population that would be less than 2.
(a) 
Obtain posterior medians and 95% probability intervals for all parameters. 
Compare inferences with the truth since the actual sampling distribution is given 
in the code.
(b) 
Repeat (a) after changing the prior on r to Ga(20,10). Comment on any changes 
in inferences.
(c) 
Let т ~ G<i(20.10). Plot the induced prior on a. Would this be a reasonable 
prior for <t if it was believed that the standard deviation of the data might be in a 
neighborhood of 1?
Exercise 4.21 Modify and run the code in Example 4.3 to make inferences about 
the population mean and standard deviation, p = q/A and a = x/a/A, respectively.

Computational Methods for Bayesian Analysis
117
Give posterior medians and 95% probability intervals. Compare inferences with the 
truth since the actual sampling distribution is given in the code.
Exercise 4.22 Modify the code in Example 4.4 to make inferences about the 
population median, m = (log(2)/A)1/Q, and the survival probability S = P(Y > 
2 | a, A) = e“A2 . Give posterior medians and 95% probability intervals. Compare 
inferences with the truth, since the actual sampling distribution is given in the 
code.
Exercise 4.23 Run the code in Example 4.5. Try different values of cr0 and 
compare acceptance probabilities to the choice cr0 = 5.
Exercise 4.24 Run the code in Example 4.6. Obtain the proportion of accepted 
samples and estimate the autocorrelation in the chains for p and a up to order 10. 
Give an autocorrelation plot. Plot histories for д and a and comment.
Exercise 4.25 Write BUGS, JAGS or Stan code to analyze the data generated 
in Example 4.2 and considered in Exercise 4.20. Write the code to provide basic 
inferences for д, cr, cr/д and Ф[(2 — р)/а]. Run two chains to obtain history plots, 
quantile plots, BGR plots and autocorrelation plots.
(a) 
Give inferences.
(b) 
Comment on the plots.
(c) 
If you did Exercise 4.20, compare results with those obtained there.
Exercise 4.26 Write BUGS, JAGS or Stan code to analyze the data generated 
in Example 4.3 and considered in Exercise 4.21. Write the code to provide basic 
inferences for p = a/X and a = y/a/X. Run two chains to obtain history plots, 
quantile plots, BGR plots and autocorrelation plots.
(a) 
Give inferences.
(b) 
Comment on the plots.
(c) 
If you did Exercise 4.21, compare results with those obtained there.
Exercise 4.27 Write BUGS, JAGS or Stan code to analyze the data generated 
in Example 4.4 and considered in Exercise 4.22. Write the code to provide basic 
inferences for the median, tn, and the survival probability, S, both defined in Ex­
ercise 4.22. Run two chains to obtain history plots, quantile plots, BGR plots and 
autocorrelation plots.
(a) 
Give inferences.
(b) 
Comment on the plots.
(c) 
If you did Exercise 4.22, compare results with those obtained there.
♦Exercise 4.28 Derivation of E(MSB) in Section 44.5. _ Let X ~ Dp(p, E), that 
is, a p-variate from some possibly unknown distribution D with mean vector p and 
covariance matrix E. Let A be a p x p fixed matrix. Then consider taking the ex­
pectation of the quadratic form, Q = X'AX. Since Q is a scalar, it is a 1 x 1 matrix.

118 
Bayesian Thinking in Biostatistics
Recall that the trace of a matrix is just the sum of its diagonal elements. Moreover, 
it is easy to show that the trace of the product of two compatible matrices, say A 
and B, is 4г(ЛВ) = <г(ВЛ). “Compatible” simply means that it is possible to both 
multiply A times В and vice versa. Thus we have Q = tr(Q) = tr(AXX'), and
E(Q) = tr(AE(XX')) = tr(-4(Cov(X) + /z/z') = tr(4S) + /z'4/z.
This is a standard formula from mathematical statistics.
Now referring to the section that discusses the Brooks-Gelman-Rubin statistic, 
let 6j = 
• ■ • ,GjM be the collection of iterates from chain j. Then let
в = 
... ,0jY be the vector that contains all iterates from all J chains. Let
p.j = E(0j) and Cov(0j) = Sj. We note that /zj = щем’, where ел/' is a vector 
of Is of dimension M'. We observe that the Oj will be independent, but that the 
variates within each chain will generally not be independent. So the covariance 
matrix S must be block diagonal with the jth block being Sj.
Now let C be a block diagonal matrix with jth block equal to 
J> and D
the matrix е(м> 
J), where the vector et is a vector of Is of dimension
k. Define the matrix A = C — D.
(a) 
Show that
J _ 
_
Q = e'A0 =
(b) 
Let /z = (Др ... ,/zj)'. Show that Д'ЛД = 
~ Д)2-
(c) 
Using the above results, show that
E(Q) = (J- 
~ Д)2-
Finally, we have E(MSB) = E(Q)/(J - 1).

Chapter 5
Comparing Populations
In this chapter we revisit the binomial, normal, and Poisson distributions, which 
we use as models for two-sample data. The goal, as the chapter title suggests, is 
to compare populations, a much more interesting topic than merely estimating a 
single parameter from a single population. Population comparisons are usually ac­
complished by contrasting scientifically relevant parameters. For example, we might 
be interested in comparing the proportion of HIV infections in two large cities, or in 
comparing rates of infection with malaria in different regions in Africa. A general 
theme here and throughout the book is to obtain scientifically relevant informa­
tion for parameters in the two populations, then incorporate that information into 
the model and ultimately make posterior and predictive inferences for scientific 
quantities of interest.
5.1 Comparing Proportions in Bernoulli Populations
Does smoking increase the probability of lung cancer? Would a new treatment better 
solve your medical problem than the conventional therapy? These questions involve 
comparing probabilities for two groups. Relevant data involve sampling individuals 
from each group and recording binary outcomes. More complex problems with 
binary data are examined in Chapter 8.
The basic model for the data involves two independent binomial samples. There 
are at least three versions of independent binomial sampling that we consider. The 
first involves sampling at a particular point in time to make inferences about the 
proportions of individuals in distinct populations that exhibit a particular charac­
teristic; this is called cross-sectional sampling. For example, suppose there are two 
medical devices that can be used for a particular procedure. We wish to perform an 
experiment to compare the proportions of “successful” procedures under the two 
devices by randomly selecting one of the devices to use with each of a series of 
patients. We are interested in assessing which device has the better probability of 
being successful.
A second type of sampling is called prospective cohort sampling. In this instance, 
we could imagine fixed random samples of smokers and non-smokers who have all 
agreed to be followed over an extended but fixed period of time. We could then 
observe the number in each group that developed lung cancer during that period. 
Interest here focuses on comparing the proportion of smokers who develop cancer
119

120
Bayesian Thinking in Biostatistics
to the proportion of non-smokers who develop cancer. Using this type of sampling, 
it is possible to attribute whether or not the smoking has a causal effect on the 
occurrence of lung cancer.
In these two types of sampling, let the corresponding binomial proportions be 
6i, i = 1,2. In these instances we assume data of the form
Yy | ~ Bin^Oi), У2 | 02 ~Bm(n2,02), 
(5.1)
with the Yi independent conditional on the parameters.
The third type of sampling is called a case-control design. Here, two distinct 
populations are again sampled but the Bernoulli responses do not correspond to the 
primary goals of the experiment. For example, suppose we obtained random samples 
of individuals known to have lung cancer and known to not have lung cancer at 
a particular fixed point in time. We then obtain information about each sampled 
individual as to whether they smoked or not. Here, the binomial proportions are 
the probabilities of smoking given lung cancer and the probability of smoking given 
no lung cancer. These are not the probabilities of primary interest. Nonetheless, 
we still have independent binomial sampling. It turns out that we are still able to 
directly address the question about whether or not smoking status is related to lung 
cancer occurrence. However, it is not possible to attribute causality to that effect. 
We explain this situation in greater detail later in this chapter.
Before analyzing data, we give an extensive discussion of how to specify priors 
for binomial proportions. A key feature is the elaboration on the selection of beta 
priors, but we also discuss the logit-normal prior. The logit-normal distribution also 
appears in two subsequent chapters as a model for random effects in the context of 
binary regression.
5.1.1 Prior Distributions for Binomial Proportions
We discuss prior distributions for binomial data. We have been using Be(a, b) distri­
butions in a number of examples already, but we provided little detail about how to 
get them. The beta family provides a flexible and convenient class of distributions 
for modeling uncertainty about probabilities. Different choices for the parameters a 
and b lead to a variety of density shapes, including U-shaped, J-shaped, L-shaped, 
unimodal symmetric, unimodal skewed right or left, and the uniform density on 
(0,1)-
Finding a prior that agrees with expert information is far more important than 
the convenience of using a beta distribution. For example, if the expert’s prior is 
bhnodal, we would abandon beta distributions due to their unimodality.1 We could 
accomplish bimodality by using a mixture of betas but do not discuss this possibility 
further, since we believe it would be rare that this was the case. In our experience 
the single beta works well.
We begin by discussing what we will call “reference” priors, if only because 
we have relatively little to say about them. A reference prior is meant to have
'Except with modes at 0 and 1. as with a < 1.5 < 1.

Comparing Populations
121
minimal impact on the posterior. Whether or not a particular prior achieves this 
goal depends on the circumstances. Most of this subsection is devoted to methods 
for eliciting substantive information for use in a beta prior. The subsection closes 
with discussion of truncated beta priors and logit-normal priors.
5.1.1.1 Reference Priors
For a binomial random variable Y | 9 ~ Bin(n,9), there is little agreement on 
how to choose a reference prior from among the three standard candidates: (1) 
the improper Be(0,0) distribution, (2) the Jeffreys prior Be(0.5.0.5), and (3) the 
[/(0,1) = Be(l, 1) prior. We discuss what a Jeffreys prior is in the next chapter. 
The first two are U-shaped and place most of their probability on values very near 
0 and 1, the improper prior Be(0,0) overwhelmingly so. In Chapter 6, where we 
discuss our general philosophy on priors, we argue that we would not use either of 
these priors for making inference in the absence of data in a scientific context. So 
in some sense, they are “silly.” We have argued previously that the uniform prior 
would be silly if we were trying to model our uncertainty about the prevalence of a 
rare infection like HIV in a general population. Fortunately, these two priors tend 
to have little effect on the posterior when sample sizes are moderate and when the 
data do not concentrate near 0 or 1. So we call them “reference” priors.
The Be(a,b) prior is a data augmentation prior in the sense that it can be 
viewed as adding a prior successes and b prior failures to the data. Thus the im­
proper Be(0,0) prior adds no prior observations, while the Jeffreys prior adds one 
prior observation with half a success and half a failure, and the uniform adds two 
observations with one success and one failure.
When the data are all successes or all failures, these so-called reference priors 
can actually have a very large impact on the posterior, thus making clear that a 
particular prior may not be harmless, depending on the circumstances.
If no successes are observed in a large number of samples, the population prob­
ability of success is likely to be quite small. While it would not be appropriate 
to change the prior from whatever had been specified without a serious argument 
about flawed thinking when specifying that prior, we argue that if a success prob­
ability is very small, an expert would probably know that it was at least some order 
of small. It would thus be necessary to specify an appropriate prior that reflected 
that fact. We specifically discuss this issue in Example 5.1.
5.1.1.2 Informative Beta Priors
Suppose we are 95% sure that 9 < 0.10, and we believe that values of 9 that are 
closer to 0 are more plausible than those that are not. Then a reasonable choice of 
prior is a beta distribution with a mode of 0 and 95% of the area under the density 
to the left of 0.10. If we pick a = 1 and b > 1, it is easy to see from the form of the 
beta density that the mode will be 0. (If b = 1 and a > 1, the mode is 1.)
With a = 1 and b > 1, simple calculus lets us solve for the b that gives P(9 < 
0.10) = 0.95. By the definition of the gamma function,
Г(Ь+1) = ЬГ(Ь), Г(1) = 1.

122 
Bayesian Thinking in Biostatistics
Let c = 0.10 and
0.95 = J p(6)de
= ГЛ1 + b^i~i(i -e)b~xde
2BetaBuster is available for free download at, for example, 
https://cadins.vctmed.ucdavis.edu/diagnostics/software under the heading "Prior Elicitation.”
= [ 5(1 - в)ь~Чв 
Jo
Io
Solving for b gives
log(l-0.95) 
log(l - c) ’
which is 28.43 for c = 0.1. A Be(l, 28.43) agrees with our prior beliefs. If we take 
an arbitrary percentile a such that a = 
p(0)d0, then b = log(l - a)/log(l - c).
Most often we obtain a prior on 0 from an expert by eliciting two pieces of 
information:
• 
Give me your best scientifically based estimate for the probability.
• 
Give me the biggest value the probability could reasonably be, i.e., a value 
with only a 5% chance that the probability is bigger than it.
In essence, our elicitation involves the expert expressing available knowledge via 
a single value (best guess) for 0 and providing a percentile (95th in the above 
statement) for the prior distribution for 0. We typically treat the best guess as 
the mode of the prior distribution. In some circumstances, we may ask for the 
smallest number the probability could reasonably be. In this case, we would be 
asking for, say, the 5th percentile. We might also change the percentiles (95th and 
5th) themselves which are a quantification of what is meant by “reasonably” in the 
above bulleted statement. If the prior mode of 0 is less than 0.5, we typically ask 
for an upper value that the expert is 95% or 99% sure 0 falls below. If the prior 
mode is greater than 0.5, we typically ascertain a lower value that the expert thinks 
0 exceeds with high probability. These values must be elicited independently of the 
current data being analyzed. Priors are often elicited after the current data have 
been collected, which makes elicitation ignoring the current data more difficult. 
Rather than asking an expert, these inputs could be based on published values or 
historical data.
The application program Beta Buster2 was designed to determine the parameters 
of the beta distribution given two such inputs. Here is a description of how Beta­
Buster works. Suppose that our prior mode is 0O. A beta distribution has mode 

for a, b > 1, so solving yields
a(b) = i±^-2). 
(5,,
Now we can find b by using information on a percentile, say a percentile c such that
a = P(0 < e < c) =
Jo Па(о))Цо)
A simple computerized search procedure allows us to find a and b. Suppose 
во = 0.2, a = 0.95, and c = 0.45. We create a vector of possible b values. 
b = (1,..., 100) and corresponding a(5) values. Then we find the 0.95 quantiles for 
all of these Be(a(5),5) distributions, say qbeta(a(b),b) in R, and check the quan­
tiles against the specified prior quantile c = 0.45. Suppose we find that 0.45 G 
(qbeta(a(14),14),qbeta(a(15),15)). We create a new vector 51 = 14 + (5/100). and 
repeat the process using 51 in place of 5 until sufficient accuracy is achieved.
After inputting the mode and a quantile for the beta prior, Beta Buster com­
putes a and 5, reports summary characteristics of the distribution, and provides a 
graph of the density. The user can also specify a and 5 and then obtain summary 
characteristics and a density plot for that choice.
Example 5.1. *Prior  for a Very Small Probability. Tuyl et al. [335, 336] 
discuss the dangers of combining priors having a < 1 with data that are all failures 
(or 5 < 1 with all successes). Specifically, they consider data on bad reactions to a 
new radiological contrast agent. Let 0^ be the probability of a bad reaction using 
the new agent. The standard agent causes bad reactions about 15 times in 10,000, 
giving a prior estimate for в^ of 0.0015. We consider two priors for this probability, 
both with mean 0.0015: a Be(l,666) and a Be(0.05,33.33). We think of the first 
prior as one bad reaction in 667 prior trials and the second as 0.05 bad trials in 
33.38 prior trials. The number of prior trials indicates the amount of information in 
the prior. The a priori probabilities that в^ < 0.0015 are 0.63 and 0.88 for the two 
priors; the lower-information prior reflects a moderately strong belief that the new 
agent has fewer bad reactions. Now consider two sets of hypothetical data based on 
using the new agent, each with 100 trials, the first with no successes and the second 
with one success. Results for the various posterior probabilities that в^ < 0.0015 
follow:
Data 
None 
(0/100) 
(1/100)
Prior parameters 
(1,666) (0.05,33.33) 
0.632 
0.882
0.683 
0.939
0.319 
0.162
From the two posteriors, we see that the probability of в^ < 0.0015 is more 
affected by the data using the low-weight prior. Intuitively we would want a lot 
more than 100 observations (with no reactions) before we claimed that the new 

124
Bayesian Thinking in Biostatistics
agent was better. Yet with the second prior, one is 94% sure that the new agent 
is better after only 100 good trials. It takes 1,330 trials without a reaction to be 
95% sure that the new agent is better using the higher-weight Be( 1,666) prior, 
whereas only 145 good trials are needed with the Be(0.05,33.33) prior. Thus, it 
takes considerably less information to be convinced of the superiority of the new 
agent using the lower-information prior.
We actually want and need a very strong prior for this problem. To know that 
we are dealing with very small (or large) probabilities is to have a great deal of 
prior information, and we ignore or lessen that information at our peril. Imagine 
how much information we must have on the standard agent to be able to say with 
confidence that reactions occur about 15 times in 10,000. To change to the new 
agent, we should require data strong enough to make an impact on those very 
strong prior beliefs.
As a design issue, one would probably want to continue sampling until at least 
one reaction occurs. With the standard agent, we expect to see 667 = 1/0.0015 
trials before getting a reaction, so why would we be satisfied with 100 trials? Yet, 
even with the Be{ 1,666) prior, the posterior gives more than a two-thirds chance 
that the new agent is better after 100 good trials. If anything, the Be(l,666) prior 
is too weak. Fixing a = 1 in these situations is a way to force ourselves not to 
underestimate the prior information (too badly).
5.1.1.3 Other Priors
A prior that arises occasionally is restricted to a subset of (0,1). For example, if 
0 is the proportion of blood donors that are infected with HIV, we could specify 
0 ~ [7(0,0.10), which is the same as a Be(l, 1) that is restricted to (0,0.10). We 
write this as 0 ~ Be(l, 1)7(0,0.10). More generally, if we know that 0 € (s,t), we 
can consider a density
This distribution is a truncated beta expressed as 0 ~ Be(a, b)I(s, t). The constant 
of integration is free of 0, so for most purposes we do not need to know it. Choosing 
a = b = 1 results in a L7(s,t) prior.
A viable alternative to the beta is the logit-normal (a, b2) distribution. We say
0 ~ logit-normal(a,b2) <=> logit(0) ~ 7V(a,b2).
The logit function represents log odds, that is, logit(0) = In(0/{1 — 0}). The inverse 
of this function is called the expit function. It is easy to check that for 0 = logit(0), 
we must have 0 = e3/{1 + e3} = expit(^).
Since the logit function is monotone and increasing, and since the median of the 
.V(a.b2) distribution is a. the median of the prior on 0 is expit(a). In fact, the a 
quantile of the prior on 0 is expit(a + zQ b) where za is the a quantile of the standard 
normal distribution. Thus an a priori 1 - a prior probability interval for 0 under 
this prior is {expit(a + za/2 b), expit(a + Z!_o/2b)}. When specifying an explicit 

Comparing Populations
logit-normal prior for в, if 0O is our prior guess for в. we have = expit (a) a = 
logit(0o). If 0o < 0.5, we specify a 95th percentile for 0. say c. Then we must have 
c = expit(a + z0.95 b). Solving for b, after substituting a = logit(0q), we obtain
logit(c) = a + z0.95 b b = {logit(c) - logit(0o)}/zo,95-
We do not pursue the analytical form of the posterior, since the logit-normal is 
not conjugate. However, the posterior is log-concave when using this prior, so that 
adaptive rejection sampling makes sampling easy. Of particular note is that the 
prior specification is easy, since we know the quantiles of the standard normal 
distribution and since the quantiles of the logit-normal distribution are so easily 
obtained using the expit function.
5.1.2 Effect Measures
With binary data, the main subject of interest is the probability of “success,” 6. 
In biomedical sciences, в is often referred to as a risk, which is a probability. For 
example, the proportion of smokers who develop lung cancer relates to the “risk” 
of lung cancer if one smokes. The word “risk” is used to connote both good and 
bad outcomes just as we call в the probability of success even though в may be the 
probability of death or failure.
A measure related to risk is the odds. The odds, Q, are the ratio of the success 
probability to the failure probability,
Q = 0/(1 - 0).
Since, 0 < 0 < 1, the odds are a positive number, 0 < Q < oo. The odds get larger 
as 0 gets larger. Things that cannot happen have both probability 0 and odds of 0. 
Odds of 1 correspond to 0 = 0.5. The odds are infinite when the probability is 1, 
that is, the event is a sure thing.
Life gets more complicated and more interesting when we have two populations 
to compare. As discussed above, we can compare the probabilities of lung cancer for 
smokers, say 0i, and non-smokers, 02- One comparison looks at their ratio, known 
as the relative risk,
RR = 01/02-
An RR of 3 means that the event of interest is three times more likely in the 
numerator group than in the other. RR is also sometimes called risk ratio.
For two populations we may also look at the odds ratio, defined as
OR = Qi/Q2 = ^1/(1 ~^i) 
02/(i-02r
Why would anyone abandon a perfectly intuitive measure like risk ratios to discuss 
the odds ratio? Part of the reason is that it is embedded in the epidemiology 
literature and is convenient in many contexts. OR has a certain kind of simplicity 
that we will see in later chapters. Another reason is that it is not possible to estimate 

126 
Bayesian Thinking in Biostatistics
the RR with case-control data (Section 5.1.4), while it is possible to estimate the 
OR, as we shall soon see. Additionally, since probability cannot exceed 1, RR is 
capped at l/02, while OR is not limited in this way.
One issue with ORs is that there are many possible combinations of 0i and 02 
that will give rise to the same OR but produce different RRs. For example, suppose 
OR = 2. That occurs when 0i = 1/2 and 02 = 1/3, which corresponds to RR = 1.5. 
It also occurs when 0i = 2/7 and 02 = 1/6, which corresponds to RR = 12/7. There 
can be a loss of information when only ORs are presented. However, if 0i = 0.002 
and 02 = 0.001, OR = RR = 2. In this latter case, we see that the risk ratio and 
the odds ratio are very similar numbers when both of the risks are small, as is the 
case in many epidemiology studies.
A third effect measure for two populations is the risk difference,
RD = 0i — 02,
also called the attributable risk. For smoking this is the difference between the 
proportion of smokers that get lung cancer and the proportion of non-smokers that 
get lung cancer.
Although odds and odds ratios are staples of medical research, RR and RD are 
easier to interpret, so preference should go to making statistical inferences about 
them when it is possible to do so. Point estimates and probability intervals for RD, 
RR, or OR are often readily available using a sample from the posterior. They can 
be used to assess both statistical import and practical import of differences between 
two probabilities. For example, if a 99% posterior interval for RR is (9.9,10.1), we 
are virtually certain that one risk is essentially ten times the other. This would be 
both practically and statistically important. On the other hand, if the 99% posterior 
interval was (1.01,1.02), we would be virtually certain that one risk was larger than 
the other, but would it be clinically important?
5.1.3 Cross-Sectional or Cohort Sampling
The model assumed here is the same as the one defined in equation (5.1). Assuming 
independent Be(ai,bi) priors for 0j, i = 1,2, we obtain the posterior distribution
0» I У1,У2 Ве(гц + аг,щ - yi +bi), г =1,2. 
(5.3)
This also means p(0i,02 | yby2) = p(0i | У1)р(02 | Уг)-
There will be many instances where a single population will be sampled either 
cross-sectionally or as a prospective cohort, and where after sampling, each individ­
ual is cross-classified as having had an event (success) or not, and whether they were 
from a particular subpopulation. We argue below that this sampling structure leads 
to the same posterior analysis as the structure that involves sampling щ individ­
uals from subpopulation i. and then observing the number of events or successful 
outcomes in each. The former type of sampling is termed multinomial, and the 
latter product binomial, since the likelihood function Тг/с(01,02) = Lifc(0i)Lifc(02) 

Comparing Populations
is the product of marginal likelihoods in that case. In the multinomial case, each 
individual can fall into one of four cells.
We consider multinomial sampling in the context of the lung cancer and smoking 
paradigm. We sample n individuals from a broad cohort, observe them over a 
specified period of time, and then at the end of that time observe whether they 
had acquired lung cancer (LC) or not, and also whether they smoked (Smoke) or 
not. The observed data would be in the form of a 2x2 table that is cross-classified 
according to counts of the number of individuals out of n that were observed to be 
in the categories (LC, Smoke), (LC, NoSmoke), (NoLC, Smoke), (NoLC, NoSmoke). 
The sum of these counts must be n, and the collection of the four counts would have 
a multinomial distribution. In this instance, we are interested in the probabilities 
of LC given Smoke and NoSmoke, respectively.
Let smoking categories be i = 1 for Smoke, and i = 2 for NoSmoke. It turns out 
that if we condition on the observed number of Smokers, say ni, and the observed 
number of non-smokers, say n? (ni + П2 = n), the counts for the numbers of lung 
cancers for these two cases are independent and Bin(ni,0i) with 0£ = P(LC | 
Smoke Category = г), i = 1,2. Thus even if the data are multinomial at the outset, 
and if they are cross-classified appropriately, we are able to use our two-sample 
binomial model to analyze the data. In statistical terms, the smoking status is called 
an explanatory factor, since we explore whether larger or smaller probabilities of 
lung cancer can be inferred to depend on smoking status. We proceed to illustrate 
using the LE data.
Example 5.2. Yen et al. [356] studied lymphedema (LE) in breast cancer patients 
as described in Example 1.2. We use data from the n = 1,211 women who were 
followed for 4 years with information available on LE status and the number of 
lymph nodes examined during breast cancer surgery.
After sampling, the 1,211 individuals were cross-classified into the 2x2 array 
of counts presented in Table 5.1. The rows correspond to high node counts (> 5) 
and low node counts (< 5), and the columns correspond to whether they had 
lymphedema or not (yes/no).
TABLE 5.1: LE data with number of nodes (high or low) examined
Nodes 
examined
Lymphedema
Yes 
No
High (> 5) 
Low (< 5)
126 
351
53 
681
477
734
Our interest focuses on ascertaining whether or not the probability of LE varies 
according to the number of nodes examined, so we condition on the high and low 
counts, which allows us to treat the number of lymphedema cases in the high and low 
categories as two independent binomial random variables (see Exercise 5.9). Here, 
01 and 02 denote the probabilities of LE for high and low node counts, respectively.

128
Bayesian Thinking in Biostatistics
The actual data are ni = 477, n2 = 734, yx = 126, and y2 = 53, where the щ are 
viewed as fixed known numbers and the y, are viewed as observations on random 
variables. The sample proportion of LE is 0.264 for high and 0.072 for low node 
counts.
In the absence of available prior information it is tempting to put independent 
t/(0,1) reference priors on the probabilities. However, literature in the field clearly 
indicated reasonable ranges for lymphedema probability after breast cancer surgery. 
The risk is about 2% per year and continues for many years. For a four-year period, 
we take 0.08 as the prior mode and specify 0.95 prior probability that LE risk is less 
than 0.3. Using BetaBuster, we obtain a\ = a2 = 2.044 and bi = b2 = 13.006. This 
prior tacitly assumes that there is no prior belief that one of these probabilities 
would be larger than another. Using this information, the posteriors are
0i | У1 ~ Be(128.044,364.006) indep. 02 | y2 ~ Be(55.044,694.006).
Summary information for these two distributions is listed in the top two rows of 
Table 5.2. The posterior means, medians, standard deviations (sds), and 95% prob­
ability intervals are shown. The clearly separated intervals show strong evidence 
of a higher risk of LE for the high exposure group. More directly, the last line of 
the table indicates virtual certainty that RD is positive. Other lines show similarly 
strong evidence that RR and OR are both greater than 1. Patients undergoing ex­
amination of more than five lymph nodes are estimated to be about 3.6 times more 
likely to develop lymphedema over 4 years compared to those having five or fewer 
nodes examined, with the true RR value in the interval (2.68,4.83) with probability 
0.95.
TABLE 5.2: Posterior summaries for LE data
Parameter
mean
sd
2.5%
median
97.5%
01
0.260
0.020
0.222
0.260
0.300
02
0.073
0.010
0.056
0.073
0.093
RR
3.612
0.545
2.677
3.565
4.830
OR
4.543
0.789
3.204
4.472
6.300
RD
0.187
0.021
0.145
0.187
0.229
5.1.4 Case-Control Sampling
The type of data in the previous subsection involved sampling individuals from two 
distinct populations or classifying them into two distinct populations. As previously 
mentioned, we often refer to the population status as an explanatory factor. We 
arc always interested in how the probabilities of a particular event that is of some 
consequence will vary as a function of the explanatory factor. However, in this 
section, we reverse the roles of explanatory factor and event of interest for practical 
reasons. In a case-control study, the investigators choose individuals based on case 

Comparing Populations
129
or control status and then examine exposure. With the type of data considered 
here, it is difficult to estimate P(LC | Smoke), for example. But we will be able to 
estimate the odds ratio
_ P(LC | Smoke)/{1 - P(LC | Smoke)} 
P(LC | NoSmoke)/{l - P(LC | NoSmoke)} 
_ Q(LC | Smoke)
= Q(LC | NoSmoke)!
if the data are sampled as case-control data with cases corresponding to people 
with LC and controls corresponding to those with NoLC.
Prospective cohort sampling can often be very expensive if large samples of 
individuals have to be monitored over a considerable length of time, maybe decades. 
It is even more expensive when the event of interest is relatively rare, due to the 
necessity of taking larger sample sizes than might be needed otherwise. In addition, 
it is often difficult to sample certain populations based on the explanatory factor 
of interest.
Below, in Example 5.3, we consider Reye’s syndrome (RS) in children where the 
factor of interest is whether or not children are given aspirin. RS is a rare but very 
serious condition. In order to obtain a prospective cohort sample, we would have 
to take a very large sample of children who were to be given aspirin, and a sample 
who were not to take aspirin, over an extended period of time. This would be an 
awkward experiment and, moreover, there would be no guarantee that we would 
see any or very many children with RS, even in a very large sample.
With case-control sampling, the event of interest itself is used to define popula­
tions to sample. In the RS example, щ known RS children would be sampled, and 
П2 children known not to have RS would be sampled, independently. Then, for each 
group, the observed number of children who were given aspirin during appropriate 
windows of time would be obtained. More generally, independent samples are taken 
from each of the two levels of the “response variable.” The sampled populations 
are called cases and controls, respectively. Then, for each group, there is a count 
for each of the two explanatory categories; for cases they add to щ and for con­
trols they add to П2, these numbers having been fixed by the design. We obtain 
two independent binomial samples, with success or failure corresponding to the two 
explanatory categories (often called “exposure levels”).
In the RS example, we are only able to estimate P(Aspirin | RS) and P(Aspirin | 
NoRS), while the probabilities of interest, P(RS | Aspirin) and P(RS | NoAspirin), 
are not estimable using case-control data. Think about it. Since the number of indi­
viduals in the sample who have RS is fixed by design, the proportion of RS children 
in the combined sample is meaningless, since that proportion is determined in ad­
vance by the experimenters. However, as indicated above, we are able to estimate 
OR = Q(RS | Aspirin)/fl(RS | NoAspirin).
This method of sampling is considerably less expensive than prospective cohort 
sampling. However, the price that is paid for the lower expense is that it is not 
possible to attribute causality to the explanatory factor, which is possible with 

130 
Bayesian Thinking in Biostatistics
prospective sampling. With case-control sampling, it is only possible to assert that 
there is an association between aspirin use and RS.
Example 5.3. Reye’s Syndrome. In the late 1970s, it was observed that, in a 
sample of щ = 7 children with Reye’s syndrome (RS), all seven of them were taking 
aspirin at the time they became sick. A second sample of size пг = 16 children 
known to be free of Reye’s syndrome was also taken, and it was determined that 
eight of them were taking aspirin when sampled.
The sample fraction of children on aspirin in the RS group is 1 and the 
corresponding fraction in the non-RS group is 0.5. Based on these estimates, 
OR = oo. Just for fun, we will see what happens if we had seen six aspirin 
takers with RS instead of the actual seven. The estimated OR would be OR = 
[(6/7)/(l/7)]/[(l/2)/(l/2)] = 6, which epidemiologists normally think of as quite 
large. But with the small sample sizes, is the result statistically important? More 
importantly, why would we care that children with RS are more likely to take as­
pirin? What we care about is whether children who take aspirin are more likely to 
get RS.
We introduce some notation in order to formally describe the situation we face. 
Consider a disease or infection or condition of interest, say D, with D = 1 indicating 
presence and D = 0 absence of the disease. Also consider an exposure variable, say 
E, with E = 1 indicating exposure and E = 0 no exposure. For example, if we 
were considering performing a case-control experiment to study the relationship 
between smoking and lung cancer, E = 1 would correspond to “smoker” and E = 0 
to “non-smoker,” while D = 1 would correspond to “lung cancer” and D = 0 to 
“no lung cancer.” Exposure status is now the explanatory factor, in the language of 
epidemiology.
We are still primarily interested in determining the direct effect of E on the 
probability of D, namely P(D | E). We want to compare 0! = P(D = 1 | E = 1) 
and #2 = P(D = 1 | E = 0). Ideally, we would like to make inferences about the 
risk ratio and risk difference,
RR = el/e2, RD = di - 02,
as we were able to do with prospective cohort data and cross-sectional data. But 
we well know at this stage that our study design does not allow us to estimate the 
0i, so it is also not possible to use the data alone to make inferences about RR or 
RD.
Now define 0\ = P(E = 1 | D = 1) and 02 = P(E = 1 | D = 0). Let Yj be the 
count of the number of individuals in sample i who have been exposed, for example, 
with E = 1. Then we have
Yt | 0i 
г = 1,2.
Clearly we can estimate the 0,, and so we can also estimate the odds ratio
OR -Q(£=1I D = 1) ■
Q(E = 1 | D = 0) 
^2/(1 — 6*2)

131
Comparing Populations
The odds ratio that we are actually interested in is
Q(D=1|E=1) 
07(1-0»)
OR2 Q(D = 1 | E = 0) 
02/(l - 02) ’ 
(°’4)
It is left as an exercise to show that ORi = OR2 = OR. Then it is clear that we 
can obtain a data-based estimate of OR.
Recall our previous discussion about how there are generally multiple possible 
combinations of 0» and 02 that will give rise to the same value of OR. Thus, there 
is unavoidable information loss associated with case-control sampling. Nonetheless, 
we always know that
0i > 02 <=> OR > 1.
Moreover,
OR = к & Q(£> = 1 | E = 1) = 
= 1 | E = 0).
So if к = 10, we say that the odds of disease for exposed individuals is 10 times the 
odds of disease for unexposed individuals, considerably higher than even odds. If 
к = 3, the odds are still high; if к = 1.1, not so much. Clearly we will be interested 
in obtaining F(0i > 02 | y) = P(OR > 1 | y) and more generally, P(OR > k\y). 
If we are 98% certain that OR > 3, we have a clear statistical result. Such a 
probability is easily calculated from posterior samples.
As previously mentioned, with small probabilities, the odds ratio is a good 
approximation to the risk ratio. For example, if OR = 10, the odds of D in an 
exposed group would be 10 times that for the non-exposed group. If P(D = 1 | 
E = 1) = 0.01 and P(D = 1 | E = 0) = 0.001 we get RR = 10 = OR. On the other 
hand, when the probabilities are not small, say if P(D = 1 | E = 1) = 10/19 = 0.53 
and P(D = 1 | E = 0) = 0.1, OR = 10 but RR = 5.3, a big difference.
The analysis takes on different forms depending on how the prior information 
is specified. If the experts have prior information on 0» = F(E = 1 | D = 1) 
and 02 = P(E = 1 | D = 0), then simple independent beta priors on these may 
suffice and the analysis is just like the others illustrated in this section. The only 
caveat is that interest focuses almost entirely on the odds ratio. Here is pseudo-code 
borrowing from the BUGS syntax. One would supply the data (у [1] ,y[2]) and 
prior parameters for the group i beta prior distributions.
■nodeHfor (i in 1:2){ 
y[i] " dbin(ttheta[i] ,n[i]) 
ttheta[i] " dbeta(a[i] ,b[i]) 
0[i] <- ttheta[i]/(l-ttheta[i]) } 
OR <- 0[l]/0[2]
prob <- step(0R -1) «Posterior Pr(0R > 1)
Another situation that can arise is where there is prior information about OR, 
perhaps based on a previous case-control study that is similar to the one at hand. We 
can place a prior on the parameters by placing, say, a normal prior on <5 = log(OF) 

132 
Bayesian Thinking in Biostatistics
and an independent beta prior on 02. These induce a prior on (0i,02). To apply 
this, we need to solve for 0i in terms of 6 and 02. Some algebra gives
01 = __ZL__ 
l-02(l-e6)
5.2 Comparing Normal Populations
Normal data are ubiquitous in the scientific world because they often arise from 
measurements. We have all been exposed to the “bell-shaped curve.” Standardized 
test scores displayed in a histogram look like a bell. Data on how long people 
can hold their breath under water look like a bell. We already discussed how to 
handle one-sample normal data. Here, we move on to the comparison of two normal 
populations.
We consider the two-sample normal model:
YiX,..., Yini I Pi, a2 АГ(дъ a2), i = 1,2.
We are often interested in making inferences about pi — p2. This is perfectly sensible 
if <72 = <72, but the issue becomes complicated if one variance is appreciably smaller 
than the other. We discuss this issue later in this section.
5.2.1 Priors for (/Zj.a2), i = 1,2
Traditionally, Bayesians used either a reference prior or a conjugate prior. As we dis­
cussed previously in the one-sample case, the conjugate prior has limited practical 
utility for data analysis, since it is somewhat awkward to elicit expert information 
for the parameters, due to the dependence of the means on the variances. As in the 
one-sample case, we focus on priors with independent information on щ and a2. In 
fact, we assume
p(/41.<rf./Z2.<72) = p(pi,<7?)p(p2,<72) =р(М1)р(<7?)р(р2)р(<7^).
5.2.1.1 Reference Priors
Let Tj = l/<72 for i = 1,2. Historically, the classic reference prior puts “independent” 
flat priors on both ц = (pi.p2) and 7 = (ln(ri),ln(r2)), that is, p(p.7) ос 1. This
To elicit a prior on 6 we think about OR. If our best guess is that OR = 3, then 
we take the mean of a prior normal distribution for 6 to be log(3) = 1.1. Moreover, 
if we are, say, 90% sure that the OR is at least 0.8, then we are also 90% sure that 
log((97?) is at least log(0.8) = —0.22. We need to find a normal distribution with 
a mean of 1.1 and a 10th percentile of -0.22. We know (or can look up) that the 
10th percentile of a normal is 1.28 standard deviations below the mean, so we set 
1.1 - 1.28sd = -0.22 and solve for sd = 1.03. Our prior on 6 is 7V(1.1, (1.03)2).

Comparing Populations
133
implies that
2 
р(м,т) oc {Jl/Tj. 
1=1
This is the obvious extension of the prior we used for the one-sample normal problem 
where results obtained were directly comparable to frequentist results, meaning 
that point, interval, and predictive inferences were numerically identical, except 
for their interpretations. If we were to assume that erf = 
= cr2 here, with
p(pi,P2,'r) oc 1/t, we would again obtain the standard frequentist point, interval, 
and prediction formulas. This is our ideal definition of a reference prior. However, 
we need to point out that these same priors rarely work for this purpose in other 
contexts, such as nonlinear modeling.
Using this improper reference prior, the joint posterior satisfies р(м1«'г1<М2,т'2 | 
y) = p(pi,Ti | y)p(p2,T2 | y), and the marginal posterior of p, is Student's Цщ - 
where yi = Y<jyijlni and s? = 
- УгУКъ - 1), * = 1,2. This
result was derived in Chapter 3, except that now we have two independent samples 
resulting in two independent posteriors. The posteriors for the t; are independent 
and gamma. Nonetheless, there is no nice analytical result for the posterior of 
A = Mi “М2-
A proper prior approximation to the improper reference prior is
Pi ~ N(0,106) ind Ga(0.001,0.001).
Since Var(Mi) = 1,000,000 and Var(rj) = 1,000, the prior precisions for pi and ъ are 
near zero, meaning that there is huge uncertainty involved in the prior specification. 
The posterior is largely “unaffected” by the prior in the normal data case; therefore, 
many are happy to regard this prior as “non-informative.” However, no one would 
choose this prior to make inferences in the absence of data. We discuss this issue 
further in the next chapter. So in a sense, it is a “silly” prior, but since we all trust 
the frequentist formulas in this case, we are content to use it.
In BUGS, we can write the code:
model{ 
for (i in 1:2){
for (j in l:n[i]){
y[i,j] " dnorm(mu[i] ,tau[i]) 
}
mu[i] " dnorm(0,0.000001)
tau[i] ’ dgamma(0.001, 0.001)}
Delta <- mu[l] - mu [2]
prob <- step(Delta) #Postprob(Delta > 0) 
}
list(n - c(2,2))
yC.l] y[,2]
55.6 
66.3
45.8 
59.7
END
list(mu - c(0,0), tau - c(l,D)
This is a made-up data set with щ = n2 = 2. The data are comprised of 
the first list, and the yij given in 2 x 2 array form. Two clicks of “load data” 

134
Bayesian Thinking in Biostatistics
are needed to input the data before compiling. The second list gives initial values. 
An alternative to this code is to replace dnorm(0,0.000001) with dflatO, which 
replaces the normal prior on the means with the improper flat prior on them. Gibbs 
sampling is easily performed in BUGS, alternating between the normal and gamma 
full conditionals for щ and л, respectively, for i = 1,2, at each iteration, resulting 
in numerical approximations to full Bayesian inferences.
5.2.1.2 Informative Priors
We already discussed how to select a somewhat informative prior for the mean 
systolic blood pressure when we were discussing the one-sample normal case in 
Chapter 3. We continue the discussion here for a generic mean, д, and we also 
discuss how to place a prior on the precision, r. In general, we recommend specifying 
д ~ ЛГ(до,^о)- So до is a best guess for д. As in the binomial proportion case, we 
pick a percentile of the prior, say да (i.e., Р(д < да) = a), so that
a = P(ji< fia) = Р({д - До}/сгО < {Да - До}М) => {Да “ До}/<^О = ZQ
and thus
^0 = {Да - До}/2а-
Example 5.4. Consider blood serum sodium levels in a (new) population of inter­
est. Assume that they are normally distributed and that we will collect a sample 
of individuals and make inferences about the average blood serum sodium levels 
in this population. On the web, we find that in the general population, “normal 
serum sodium levels are 135 to 145 mmol/L” (Wikipedia). Without any additional 
knowledge about whether the population of interest had a higher or lower average 
blood serum sodium, our best guess would be до = 140. We assume that the (135, 
145) range is a 95% prediction interval of some sort, meaning that it is expected 
that 95% of the general population would have sodium values inside this range. If 
we believe that the new population were similar to the general population, setting 
До.05 = 138 mmol/L would be conservative if the prediction interval were to be 
believed. A considerably less informative prior would set д0.05 = 135 mmol/L.
An issue that requires serious consideration is that an individual with blood 
serum sodium <135 mmol/L is considered to have hyponatremia, which is a serious 
condition that may result in hospitalization. So if д = 135, for example, half of the 
new population would be considered to have this condition. It is highly unlikely 
that this would go unnoticed. The main point of this example is that biology really 
matters when specifying a prior. For illustration, we set до.05 = 136. Then we obtain 
сто = (140 - 136)/1.645 = 2.43. Thus a 95% prior probability interval for д would 
be (135.2. 144.7). If the new population is similar to the general population at all, 
this will be a very conservative prior, meaning that it is relatively quite diffuse.
In the two-population case, wc proceed in the same way, regarding each pop­
ulation separately and independently. The case where we would regard means as 
dependent is discussed in the next chapter.
We now turn to specifying a mildly informative prior for the precision r where 

Comparing Populations
135
we go to some effort to find an informative prior guess for it but otherwise allow for 
considerable uncertainty. Since it is not easy to think about r. we think about the 
90th percentile of the distribution of у values, уо.эо- So P(Y < ";0.90 I /'.<?) = 0.90. 
This means that 90% of the responses will be less than 70.90- Let и be a best guess 
for 7o.9- Then, since
70.90 = Д + 1.28 \/1/t.
we can use our best guesses for p and 70.90 to obtain a best guess for т (т0) by 
solving
u = p0 + 1-28 y/l/r0 <=> t0 = 1.28/(zz - p0)2.
We then specify the conditionally conjugate prior
r~Ga(c,d), —-^- = r0, 
a
so the mode is r0. We have c = 1 4-dro. This prior will be diffuse for small d, since 
Var(r) = (1 +dT0)/d2. In Chapter 6, we consider how to specify a fully informative 
prior for a2. Of course in the two-population case, the same process applies to both 
sets of population parameters.
5.2.2 Posterior Inference for Comparing Populations
Under the assumption of independent priors for the means and variances or preci­
sions, the joint posterior satisfies
I !/) =р(Д1,П,д2,т2 | y) =p(pi,ri I y)p(p2,T2 I y).
So inference procedures for the two sets of population parameters are identical 
to what they would be if we simply carried out posterior calculations for them 
separately. Either way, we can take Markov chain Monte Carlo iterates to make 
inferences about any function of the parameters, say д(р,т).
Since we are comparing populations, particular interest will focus on Д = p2 — 
Pi. This effect measure is most useful when cti and a2 are not too different, since 
then the primary distinction between the two populations is characterized by Д. 
For example, see Figure 5.1a where Д = 1.
When comparing two normal populations, it makes sense to first take a look at 
the ratio of standard deviations, SDR = <J\/cr2. For example, if P(SDR > 2 | y) 
is large, we need to think harder about what it means for p2 > pi, or vice versa. 
Figure 5.1b shows N(0,1) and 2V(l,0.25) pdfs where Д = 1, but the situation is 
quite different from the one with equal variances. It is obviously not enough to only 
focus on Д.
In addition, it is possible that Д = 0 and SDR is large. In this case, only 
focusing on Д would lose sight of the fact that the distributions are quite different. 
Inference would require discussion of this type of difference in the context of the 
scientific background for the data.

136
Bayesian Thinking in Biostatistics
(a) N(0,1) and N(l,l).
(b) N(O,1) and N(0,0.25).
FIGURE 5.1: Graphs showing normal densities one may wish to compare and the 
effect of the variances on the comparisons. Panel (a) shows ?V(0,1) (solid) and 
7V(1,1) (dashed) densities. Panel (b) shows ?V(0,1) (solid) and 77(1,0.25) (dashed) 
densities.
Another quantity that may be of interest in comparing populations is the prob­
ability that a random value from population 2 would exceed a random value from 
population 1. Let us name it EPR for “exceedance in pairs rate,” so that
EPR = P(Y21 >УП |д,т) = 1-Ф 
where Ф(-) is the cdf for a standard normal variate. This probability equals 0.76 
and 0.81 for the densities in Figure 5.1. As this value approaches 1, we know that 
the two pdfs approach complete separation, meaning virtually no overlap.
5.2.3 Prediction
Prediction is easy after we already have a random sample from the posterior (e.g., 
an MCMC sample) for the model parameters. Let Zt | р,т X N(p,i,Ti),i = 1,2, 
independently of the two-sample data, y. The marginal predictive density for Zi is
p(z; | у) = У p(zi I Ti)p(fii, Ti I yjdpidTi, i = 1,2.
Because of the assumed independence, we have p(zi,z2 | y) = p{zx | y)p(z2 I У)- 
These marginal predictive densities are identical to the ones we considered in the 
one-sample normal case: they are Student’s t pdfs. However, for a variety of reasons, 

Comparing Populations 
137
it is usually much easier to use MCMC sampling to make predictive and estimative 
inferences.
Suppose we are interested in the predictive probability that a future value from 
population 1 would be less than a future value from population 2. This is calculated 
as 
oc z2
P(Zi < Z2\y)= [ f p(zY | y)p(z2 | y)dz]dz2, 
J-OQ J-OO
which is an intractable integral. But if we have a sample of iterates,
= 
........A/},
we simply sample
Z<‘> I (д«,г«) ‘S' w(g<‘), 1/T«>), i = 1,2.
Then we approximate the above integral,
м 
P(Z,<^|k) = £ 
t=BI+l
5.2.4 DiaSorin Data Analysis
Renal osteodystrophy is a bone disease that occurs when the kidneys fail to maintain 
proper levels of calcium and phosphorus in the blood. Monitoring patients with 
loss of kidney function for lower than normal bone turnover aids in managing the 
disease. A commercially available diagnostic assay, DiaSorin, was believed to have 
the potential to determine which patients have low versus normal bone turnover. 
A cross-section of 34 kidney patients from the bone registry at the University of 
Kentucky were identified as low or normal turnover by other means and then given 
the commercial assay to determine whether it could correctly identify them. From 
boxplots, a normal sampling model appears to be untenable, due to observable 
skewness; however, boxplots and quantile plots of the log-transformed data appear 
to be reasonably normal (see Figure 5.2).
Since data are on the log scale, we write log(K) | p, a2 ~ N(pt a2). For analyzing 
the data, we could just take logs of all of the data and then treat them as normally 
distributed. The prior can be taken as W(po, °o) f°r Д» an^ ал independent Ga(c, d) 
prior for т = 1/cr2. This needs to be implemented for each of the two populations.
Prior Elicitation. We first consider eliciting prior information for p. It is natural 
for us to specify such information on the original data scale instead of the log scale. 
We can then induce it onto the model parameter p as follows.
Note that if m is the median of DiaSorin scores У in a population, then log(m) is 
the median of log(K) measurements in the population. This is because the logarithm 
is a monotone function. Now specify a best guess m for the population median m of 
DiaSorin scores. Then we take po = log(m). Next specify a value, йо.95, such that 
we are 95% percent certain that m cannot exceed it, namely P(m < йо.95) = 0.95.

138
Bayesian Thinking in Bwetatisttcs
Low Norm*
Theoretic* Ouontrtw»
FIGURE 5.2: DiaSorin data.
This is equivalent to asserting 0.95 = Р(д < log(u0.95)) = 
_ Moj/o’o <
{log(uo,95) - Mo}/<7o), from which we get
log(iio.95) - log(m) 
log(uo.9s) - log(m)
------------- -----------= 1.645 «• ao =--------------------------- ■
Dr. Johann Herberth of the University of Kentucky gave his best guess of the 
median for the low bone turnover population as 130, and he was 95% sure that 
this median was less than 142 in this patient population. This results in цс, = 
/11 ~ 7V(4.87,0.00288). The corresponding values elicited from Dr. Herberth for 
the normal bone turnover population were 220 and 240, respectively. This led to 
UN = /i2 ~ N(5.39,0.00280).
Let us next consider the prior for r. In general, we can ask the expert to think 
about the lOOoth percentile. %, of the distribution of Y values, with some com­
fortably high value of о such as 0.95. Let u be the value the expert specifies. Since 
the lOOnth percentile of the Ar(/i.r) distribution is /i + zal\Jr. and since the log 
is a monotone increasing transformation, we must have 7Q = 
. Then our
best prior guess for т must satisfy u = 
<=► r0 = z2/{log(u) - /io}2.
I his can be taken for the prior mode for r. Dr. Herberth provided his best 
guess for the 95th percentile of DiaSorin values in the low (u = 170) and normal 
(u = 280) Ixme turnover patient populations. Requiring gamma priors with modes 
1.6452/{log(170) - log(130)}2 = 37.6 and 1.6452/{log(280) - log(220)}2 = 46.53.

Comparing Populations 
139
TABLE 5.3: Posterior summaries for informative prior, log DiaSorin data
Parameter
mean
sd
2.5%
50%
97.5%
Mi
4.860
0.052
4.757
4.860
4.961
М2
5.395
0.051
5.294
5.395
5.496
М2 - Mi
0.536
0.073
0.392
0.536
0.679
T\
1.275
0.394
0.625
1.231
2.161
T2
1.285
0.439
0.576
1.236
2.274
r2/ri
1.114
0.555
0.387
1.003
2.495
and with large variances for rs specified by choosing dt = d2 = 0.001. results in 
П ~ Ga(l.0376,0.001) and r2 ~ Ga(1.04653,0.001).
Inference on Log Scale. The analysis on the log scale with our informat­
ive prior begins with Table 5.3, which gives posterior summaries for the two 
groups. We glean from the table that a 95% probability interval for <ti/ct2 is 
(\/0.387, x/2.495) = (0.62,1.58), with posterior median 1.001. Thus there is no 
evidence that the standard deviations for the log data are different. Moreover, we 
are nearly 100% certain that A = м/v — Ml > 0 (result not shown in Table 5.3) and 
we are 95% certain that A G (0.39,0.68). Thus we can conclude that A > 0 and 
that we are 95% certain that д/у is between 0.39 and 0.68 times larger than д/,. 
We term this a highly statistically important result.
However, it is unclear what the practical import of the result is. We know for 
sure that “normal” DiaSorin scores tend to be higher than “low” DiaSorin scores, 
but we need to go further to address the question about whether or not DiaSorin 
scores can be used reliably to discriminate between individuals from the normal 
and low bone turnover populations.
Inference on Original Scale. Again using our informative prior, Table 5.4 gives 
results of the analysis on the untransformed scale. The posterior median and 95% 
probability interval for the median DiaSorin value among low bone turnover pa­
tients, eML, was 129 (116.4, 142.8), and the corresponding estimate and interval 
for the median among patients with normal bone turnover, eMN, was 220.6 (199.1, 
243.6). Inference for the relative median eMN/eML = еМл,-Мд comparing the Dia­
Sorin values of normal to low bone turnover patients was 1.71 (1.48, 1.97). We are 
thus 95% certain that the median of DiaSorin scores in the “normal” population is 
between about 1.5 and 2 times that for the “low” population. Prediction intervals 
for new values from both groups are also given. These intervals are substantially 
wide because of the small sample sizes (щ = 19,n2 = 15). Code that generated 
these results is available on the book’s webpage under Chapter 5 in files named 
diasorin.bugs.
Predictive Densities. Figure 5.3a gives predictive densities for a future log Dia­
Sorin value from the low and normal groups. Note the similarity of the distributional

140 
Bayesian Thinking in Biostatistics
Inference target
mean sd 2.5% median 97.5%
TABLE 5.4: Posterior summaries on original scale for DiaSorin data, informative 
prior
Pred Dens L
20.1
128.0
821.7
Pred Dens N
34.4
219.9
1416.0
Med: e^1-
129.1 6.74 116.4
129.0
142.8
Med: e™
220.6 11.35 199.1
220.3
243.6
RelMed:
1.71 
0.13 
1.48
1.71
1.97
shapes, which is due to the similarity of the precisions (see Table 5.3). With similar 
precisions, it becomes clear that the “normal” group has higher scores and that the 
means characterize the differences between the two distributions.
However, when we consider predictive distributions of DiaSorin scores on the 
original scale (Figure 5.3b) obtained by exponentiating samples from the predictive 
distribution on the log scale, we see that these densities are much more difficult to 
interpret relative to one another. In particular, it is not obvious that the difference 
in the means of the predictive distributions would be a good measure of how the 
two distributions differ.
200 
400 BOO BOO 1000
Diasorin Score
(a) Predictive densities for log(DiaSorin scores), (b) Predictive densities for raw DiaSorin scores.
FIGURE 5.3: Pnxiictive distributions for the analyses of the DiaSorin data, (a) 
Predictive densities for analyses on the log scale, (b) Predictive densities for the 
analyst's on the original scale.
Predictive Classification. We now address the question of whether a factor like 
DiaSorin can lx' list'd effectively to classify future patients as low or normal in bone

Comparing Populations
111
turnover based on their DiaSorin score. Suppose, for example, we were to use the 
cutoff 164. This value is between the two estimated medians. 129 and 220. Our 
decision rule would assert that an individual had normal bone turnover if their 
score was greater than 164, and that they had low bone turnover if their score was 
less than 164. The predictive probability that someone from the "normal'' popula­
tion will score above this value is the area under the "normal” pdf in Figure 5.3b 
to the right of 164, here 0.63. The predictive probability that someone from the 
“low” group will score below 164 is the corresponding area under the “low” pdf in 
Figure 5.3b, here 0.61. These are the probabilities of making correct decisions. Cor­
respondingly, the probabilities of making incorrect decisions are about 0.40 in each 
instance. This means that using 164 as a cutoff will result in about 40 out of every 
100 “normal” individuals being misdiagnosed as “low,” and about 40 out of every 
100 “low” individuals being misdiagnosed as “normal.” It should be clear due to 
the large overlap in the “normal” and “low” predictive pdfs that, regardless of the 
choice of cutoff, a substantial number of errors in diagnosis will result if DiaSorin 
score alone is used to make diagnoses.
5.3 
Inferences for Rates
In this section we discuss the Poisson distribution for modeling two-sample data. 
As previously discussed, Poisson distributions are used to model counts. Examples 
include the number of emergency department admissions in a day, the number of 
fatal accidents in a geographic area over a specified period of time, and the number 
of individuals that become infected with particular virus over a specified geographic 
area and during a specified time window. With binomial data, we know that a count 
cannot exceed the fixed number of trials n. A Poisson variate has no obvious upper 
limit, but the magnitude of counts is usually associated with the length of time 
period or the size of geographic area.
The two-sample Poisson model has independent observations with
Yt PotfiMt), i=l,2.
As in the one-sample case, Mi denotes a quantity related to the length of time 
sampling was performed or the size of a geographic area sampled, or the number 
of person-years sampled in the case of a longitudinal study with many individuals 
observed over time. fy. is the rate of occurrence of the type of events that are under 
study. When events are observed over simple time, the rate is the number of event 
occurrences per unit time; when counts are observed over space, the rate is the 
number of events per unit area; and when events are observed in person-years, the 
rate is the number of events per person-year under study. Each particular situation 
actually dictates the units to be considered.

142
Bayesian Thinking tn Biostatistics
5.3.1 Reference Priors
Wc begin with a generic rate parameter, 0. The Jeffreys prior (Section 6.2) is
p(0) ос 1/Д
which is equivalent to an improper Ga(0.5,0) distribution. An approximation with 
a proper gamma prior to the Jeffreys prior is 0 ~ Ga(0.5,0.001). The Jeffreys prior 
corresponds to a flat prior on 7 = \/0. This follows by using the usual transformation 
technique, p(0) = p^{V0)^ a \/\/0, since the prior on 7 is constant. The Jeffreys 
prior for the two-sample problem is
Р(^Ь^г) ОС 1/^2-
It is well known that у/Y | 0 ~ N(V0,1/4), when 0 is moderate to large 
{0 > 15). This is shown using the delta method in conjunction with the fact that, 
for large 0, Y | 0 ~ N(0,0). Thus if we were analyzing Poisson counts that were 
themselves moderately large, indicating that 0s were moderately large also, the 
usual reference prior for the mean of a normal distribution, in this case д = \/0, 
would be a constant. This leads again to the choice p(0) a i/V0 just as above when 
we let 7 = \/~0. Arguing by analogy with placing a constant prior on the mean of 
a normal distribution, we expect posterior inferences to depend very little on this 
prior. We thus refer to it as a reference prior.
5.3.2 Informative Priors
For a generic rate 0, the conjugate prior is a Ga(ao, bo)- We again elicit a value for 
the prior mode 0q, and for the a quantile, say c, for a chosen a. The mode of the 
Ga(ao, bo) distribution is
a0 - 1
t/o — —г—, ao > 1.
bo
If ao < 1, the mode is 0. We solve to get ao as a function of b0:
ao(bo) = 1 + bo 0q-
With specified mode 0q, we thus have
= I Ga(0 I ao,bo)d0 = f Ga(0 | 1 + bo0o,bo)d0.
Jo 
Jo
With a computer routine that gives the a quantile of a gamma distribution, we 
can find the values of bo by trial and error, which then determines a0 as above. 
GammaBuster, which is a "shinyapp'' that is analogous to BetaBuster, is available 
at ht t ps: / /gjones.shinyapps.io/priorapp/. For example, if we wanted a gamma prior 
with Oo = 30 and with 95th percentile = 40. we find it quickly in GammaBuster 
to Im' approximately Ga(34.16. 1.11). Alternatively, one can use the R function 
pgaama(alpha, l+b0
*theta0,b0)
 iteratively with different choices of bO until the 
result is dost' to o.

Comparing Populations
143
5.3.3 Nurses’ Health Study Data Analysis
The Nurses’ Health Study (Colditz et al. [83]) sought to estimate and compare the 
rates of breast cancer for 50-59-year-old postmenopausal women who were current 
users of estrogen replacement therapy (group 1) and those who were not (group 2). 
The data are given in Table 5.5.
TABLE 5.5: Breast cancer data
Group
Cases
Person-years
1—Hormone therapy
123
46,524
2—None
288
145,159
There were two cohorts of women who agreed to be in the study. The first cohort 
involved women who were on hormone therapy. During the course of the study, 
Mi = 46,524 is the number of woman-years during which 123 women developed 
breast cancer. The second group involved women who were not using hormone 
therapy and М2 = 145,159 is the number of woman-years during which 288 women 
developed breast cancer. The “size” of the group of women not on hormone therapy 
was on the order of three times the “size” of the group who were on hormone 
therapy, so one would expect three times as many cancers in that group compared 
to the hormone users on this basis alone.
We assume independent conjugate priors as discussed above. With
Qi Ga(ai,bi), i=l,2,
we get independent posteriors
0i 12/1 >Mi ~ Ga(ai + yi,bi + Mi), 
02 I У21 М2 ~ Ga(fl2 + 3/2> ^2 + М2).
In addition to estimating the individual rates, 0i and 02, we also estimate the 
difference of rates (means) RD = 0\ — 02, and the relative rate RR = 0\/02-
Prior elicitation from experts involves asking them to think about the 0j in­
dependently and in whatever units with which they would be most familiar. We 
regard the 0, as rates of breast cancers per 1,000 person-years at risk. Since we have 
no access to breast cancer experts, we use reference gamma priors on the incidence 
rates, a\ = bi = 0.5, a2 = b2 = 0.001.
Based on this cohort, there was an estimated rate of 2.65 (2.21, 3.14) breast 
cancer cases per 1,000 person-years with hormone replacement therapy and 2.06 
(1.83, 2.30) without. The 95% probability intervals have little overlap. The posterior 
median and 95% probability interval for the rate ratio comparing current hormone 
users to non-users are 1.28 (1.04,1.58). Moreover, P(0i > 02 | J/bJ/г) > 0.9884, so 
the incidence of breast cancer is higher for 50-59-year-old postmenopausal women 

144 
Bayesian Thinking tn Biostatistics
who are current users of estrogen replacement therapy. Even knowing the exact 
posterior distribution, these numbers are easier to obtain by simulation.
We also used Ga(0.001,0.001) priors for the Os. Posterior inferences for the 6s 
were 2.64 (2.20, 3.13) and 1.98 (1.76, 2.22), respectively. Rate ratio inferences were 
1.33 (1.07,1.64). Most of these are very close to the ones based on the Jeffreys 
prior, and all are close enough that there would be no practical import to their 
differences.
It is clear that these data suggest that the rate of breast cancers in the hormone 
replacement therapy group is greater than in the no-therapy group. We should 
add that there is considerable controversy about whether or not women should 
use hormone therapy during or after menopause. We are unaware of any definitive 
outcome of that controversy, which revolves around the fact that rates for other 
kinds of cancer have been found to be statistically lower in the hormone therapy 
group.
5.4 
Recap and Readings
This chapter covered some aspects of Bayesian biostatistics and quantitative epi­
demiology. The sampling distributions that were discussed in the binomial com­
parisons section are important in epidemiology. Broemeling [55] parallels our own 
approach to Bayesian biostatistics, but from the point of view of epidemiology. We 
have emphasized the incorporation of prior information into Bayesian statistical 
analyses in the form of reference, informative, Jeffreys, and other prior distributions 
in this chapter. We see this as very important and also constructive. In thinking 
about what we know about scientifically relevant parameters, we are also forced to 
think about what are the scientific questions that we should be addressing in the 
analysis. Geisser [125] gives a full discussion of the relative merits of reference priors 
for binomial proportions. Tuyl et al. [335, 336] discuss unfortunate consequences 
associated with a possibly careless specification of priors for binomial proportions 
when they are very small, which we also discussed. We also addressed the import­
ant issue of how to analyze data that require transformation in order to satisfy 
model assumptions. The use of predictive distributions played a role in this ana­
lysis. Geisser was a major proponent of prediction for his entire professional life; 
details can be found in his monograph [127].
5.5 
Exercises
Exercise 5.1. Using calculus. find the mode and 5th percentile of a Z?e(10,1) 
distribution.

Comparing Populations
145
Exercise 5.2. Using calculus, find a and b such that a Be(a,b) distribution has 
a mode of 1 and a 5th percentile of 0.2.
Exercise 5.3. 
Derive formula (5.2), including the formula for 0q.
Exercise 5.4. Use BetaBuster to find the Be(a.b) priors for mode 0.75 and 5th 
percentile 0.60, and for mode 0.01 and 99th percentile 0.02. What is the beta prior 
when the mode is 1 and the first percentile is 0.80?
Exercise 5.5. Show that 0 ~ Be(1.6,1) and 0 ~ Be(l, 0.577) both have a mode 
of 1 and both have P(0 < 0.5) = 1/3. Which of these two does BetaBuster give?
Exercise 5.6. Find three sets of (#i, 0q) values that correspond to OB = 3. Give 
the corresponding RR and RD values. Argue that OR = RR when the 0s are close 
to zero.
Exercise 5.7. Derive the result in equation (5.3).
♦Exercise 5.8. Let X = {XtJ : i = 1,2; j = 1,2} be a 2 x 2 table of counts 
that sum to n. Let p = {p^ : i = 1,2; j = 1,2} be the corresponding 2x2 table of 
population probabilities for individuals falling into these cross-classified categories. 
Then we have
X ~ Multan,p).
Let Xi. = Хц + Xi2, i = l,2, be the row totals in the table and let р». = рц + pi2, 
i = 1,2, be the corresponding row totals for the table of category probabilities. 
Then show that
Xn | 
Втп(ц.,рц/рг.), i = 1,2.
Note: The data in Table 5.1 of Example 5.2 are multinomial, and there we used the 
result of this exercise to analyze the data as two independent binomial samples.
Exercise 5.9. Reproduce the results of Example 5.2. (We provide example BUGS 
code on the book’s website. The file name is Lymphedema.bug.) Then perform a 
sensitivity analysis by changing the prior moderately and looking to see if results 
change enough that you would care.
Exercise 5.10. Suppose we ignore the pre-data information available for the 
probability of LE and use the C7(0,1) prior for 0\ and 0? instead.
(a) 
Obtain the corresponding posterior summaries as in Table 5.2 and compare. 
In particular, notice the direction of change in the effect size measures. Does this 
agree with the usual intuition that the 17(0,1) is a “less informative” prior?
(b) 
Write a program that you can use to look at the induced prior on RD, RR, and 
OR based on using uniform priors on the 0s. Use summary information about the 
induced priors on these quantities to shed light on the obtained posterior results.

146
Bayesian Thinking in Biostatistics
Exercise 5.11. The following exercise applies independent logit-normal priors 
for the fl, in the lymphedema analysis. Sample BUGS code is available on the book’s 
website in a file named LogitNonnalLE. bug. You may use this code or something 
similar in another language or program.
(a) 
Run your program for 11,000 iterations and obtain results with a 1,000 iter­
ation burn-in. Observe that results are virtually identical to those obtained using 
independent U(0,1) priors.
(b) 
Now modify the code so that you can get plots of the induced priors on the fl,. 
Try different values of d until the induced prior looks the closest to a {7(0,1).
Exercise 5.12. 
(a) Analyze the Reye’s syndrome (RS) data using [7(0,1) priors
on 0\ and ^2-
(b) 
Discuss issues of causation and correlation for the RS data. For example, people 
with high blood pressure are more likely to take beta blocker drugs than people 
without high blood pressure. Can we conclude that using beta blockers causes high 
blood pressure?
Exercise 5.13. An expert has no belief that there is or is not an effect of aspirin 
on the risk of Reye’s syndrome (RS), but that if there is one, it will not be “huge” 
in either direction. They place a Af(O,2) prior on 5, so their best guess for the OR 
is e° = 1. The prior also indicates that they are 95% sure that the OR is in the 
interval
(e(0—1.96
*1.414),
 g(0+l.96
*1.414)}
 = (0.063,16.0).
The interval is centered on 1 and allows for a broad range of possibilities in both 
directions. Place the Jeffreys Be(0.5,0.5) prior on 02-
(a) Analyze the RS data according to this expert’s prior. (Example code in the 
BUGS language is available on the book’s website. The file name is Reyes.bug.) 
(b) Examine the sensitivity of the results to the choice of prior. Try a prior that 
reflects much more skepticism about any effect, and a prior that suggests that any 
effect will be a positive one. Also try a Be(l, 1) prior for 02 to see what impact that 
has on the results. Be sure to calculate the posterior probability that OR > к for 
к = 1.2.
Exercise 5.14. Referring to the previous exercise, another possibility is to elicit 
prior information for
01 = P(D = 1 I E = 1). 02 = P(D = 1 I E = 0), 7 = P(E=1).
With priors on these three parameters, we can use the case-control likelihood to 
obtain posterior inferences for all parameters of interest, including the risk ratio 
of the flj. However, no matter how large аге щ and П2, the posterior for the fls 
will still have uncertainty that is commensurate with the uncertainty in the prior 
specification.
Let fl,. fl2. and -> have independent beta priors. Write a program to handle case­
control data. Hint: Since the model parameters are the fls and since the prior is on 

Comparing Populations 
147
(#1 > 02S 7), you will need to solve for the 0s in terms of (0\. 0-2- 7)- You will also need 
to use Bayes’ theorem.
Exercise 5.15. Let 0, ~d 17(0,1) i = 1,2. Simulate the induced prior on the 
corresponding odds ratio. Be sure to calculate the prior probability that OH exceeds 
several values, including 50. Comment.
Exercise 5.16. Using the fact P(D = i.E = j) = P(E = j)P(D = j | E = 
j) = P(D = i)P(E = j I D = г), show ORi = OR? where the ORi are defined in 
Equation 5.4 and just above.
Exercise 5.17. Use the approximate reference prior in this exercise.
(a) 
With possibly unequal variances, analyze the two-sample data that can be found 
on the book’s website (Chapter 5, dataforExl7.csv).
(b) 
Repeat (a) under the assumption of equal variances.
(c) 
Obtain the predictive densities for the two populations and plot them on the 
same plot under model (a), and under model (b) on a separate plot. Compare the 
results. Give thoughts about whether the assumption of equal variances is tenable.
Exercise 5.18. It is possible to use the exact reference prior for the precision r. 
Let 7 = ln(r) and />(7) ос 1.
(a) 
Derive the induced (improper) pdf for 7.
(b) 
Write a program that uses the exact reference prior.
(c) 
Redo the analysis in part (a) of Exercise 5.17 using this prior for both precisions, 
and compare results.
Exercise 5.19. Let 1п(У,) s W, N(n,r), » = 
namely Yt | д,т l~
LN(n, 1/r).
(a) 
Derive the pdf for Yi | /z, r.
(b) 
Show that the independence prior with /z ~ 
and т ~ Ga(c,d) results
in conditional conjugacy for log-normal data. Give the full conditional distributions 
in precise form.
Exercise 5.20. 
(a) Perform an analysis for the DiaSorin data (on the book’s
website under Chapter 5 in diasorin.csv) on the original scale using the log­
normal model of Exercise 5.19 with at least two different choices of prior. Comment, 
(b) Analyze these data with the normal model (not log-normal) and consider infer­
ences based on this wrong model assumption. Discuss.
Exercise 5.21. This problem will involve simulating two samples from normal 
distributions under several circumstances. Consider sample sizes m = пг = n, 
means /zi = 20, ^2 = 20+A, for A > 0, and standard deviations 04 = 5, 
= 5+A,
for A > 0.
(a) 
The first goal is to explore circumstances that make it easy or difficult to detect 

148 
Bayesian Thinking in Biostatistics
a statistically important difference in means when the standard deviations are equal 
(e.g., A = 0).
(b) 
The second goal is to explore circumstances that make it easy or difficult to 
detect a statistically important difference in standard deviations. Explore with in­
creasing sample sizes, n = 10,50,100, using several different combinations of (Д, A). 
Use independent reference prior approximations for all analyses. Make inferences 
for comparing means and standard deviations. A statistically important difference 
in means is defined to be a difference for which the posterior probability that A > 0 
is at least 0.95 or when the posterior probability that SDR < 1 is at least 0.95. To 
simulate normals in R, use the function rnorm(n, mu, sigma), where n is the sample 
size, mu is the mean, and sigma is the desired standard deviation.
♦Exercise 5.22. Derive the Jeffreys prior for в if Y | в ~ Po(ff).
Exercise 5.23. Referring to Section 5.3.2, do a simple search to find b0 for an 
example with 60 = 10, c = 30, and a = 0.95, using R. The resulting prior should 
be approximately 0 ~ Ga(3.2,0.22).
Exercise 5.24. Differentiate the log of the Ga(aQ,b0) density and set it equal 
to 0 to solve for the mode of the distribution.
Exercise 5.25. Reanalyze the breast cancer data using an informative prior 
where the modes for 6i and 02 are 3 and 1, respectively, and with 95th percentiles 
of 10 and 7, respectively. Are the results substantially different from those obtained 
in Section 5.3.3? (Example BUGS code is available on the book’s website in a 
file named NursesHealthStudy.bug. You may want to modify that program or a 
similar one for this exercise.)
Since the Mi units are in the hundred thousands, the are rates per hundred 
thousand. If we changed Mi = 46.524 and M2 = 145.159, the rates would then be 
per 1,000, which is how we chose to interpret them. Care must be taken in the the 
analysis program to be sure that reported rates are in the correct units.
Exercise 5.26. Reanalyze the breast cancer data (Section 5.3.3) using the ref­
erence prior but now change the data so that Mi = 93,000 and Af2 = 290,000, 
that is, with about twice the amount of person-time. Compare results with those 
obtained earlier.
Exercise 5.27. Suppose we have completely independent count data Y = 
()'i....... Y„) and X = (X,.........A’,,,) from two populations. The sampling model for
the first population is | 0i ~ Po(0i) with prior 0i ~ Ga(ai, b\), and the sampling 
model for the second population is Xj | 02 ~ Po(02) with prior 02 ~ Ga(a2,b2). 
Derive the analytical form of the joint posterior distribution for (0i,02) and char­
acterize it.

Chapter 6
Specifying Prior Distributions
The topics in this chapter are fundamental to the theory and application of Bayesian 
statistics at the intermediate and advanced levels. However, not all topics rovcred 
in this chapter are required for understanding much of the rest of the book. In a 
first reading, some may prefer to skip * sections and read them later as detuned 
necessary.
1 We do not restrict our use of the term “reference prior” to the specific technical definition given 
by Bernardo (1979) [34].
The specification of priors is extremely important in Bayesian statistics and is 
accordingly the main topic in this chapter. We have already introduced the topic in 
some examples in previous chapters, but we believe it deserves additional attention. 
The main reason is the great potential for misspecification of priors, which can 
easily lead to what has been termed garbage in, garbage out, in computer science 
and statistics.
In Section 1.3.4 the concept of the “prior” distribution was called an external 
knowledge distribution containing information outside the data being modeled and 
analyzed. The distribution is designed to capture such information as it reflects 
on the probability model for the data. While we have used this phrase “external 
knowledge distribution” to initially highlight the concept, much throughout the 
book we use the more traditional “prior distribution” as this terminology is nearly 
universal in the literature.
Advances in computational methods have made it fairly straightforward to apply 
Bayesian methods in many scientific contexts. A main goal of Section 6.3 is to 
emphasize the importance of incorporating scientifically relevant information into 
priors when it is available. These are called informative priors. We also focus on 
situations when this kind of information is not available, in which case there is 
obviously still a need to specify an appropriate prior in order to proceed with 
the Bayesian analysis. When information about scientifically relevant parameters is 
unavailable, we discuss the use of what we and others call reference priors, which 
are generally specified so as to have a minimal impact on the Bayesian analysis.
There are few general rules for developing priors in the absence of scientifically 
relevant information, and there are none that we know of that would apply across 
any broad range of statistical models. Thus, we have to be careful in each instance 
to study a candidate prior to make certain that it is sensible, not misleading or 
absurd.
By a reference prior1 we mean any prior that is not chosen for the information 
that it models. Rather, it is chosen to provide a common base for people to evaluate
149

150 
Bayesian Thinking tn Biostatistics
data. Because their use avoids the inconvenience of specifying informative prior 
distributions, reference priors are sometimes called convenience priors.
Historically, there has been considerable effort spent on the development of so- 
called non-informative priors. The name stems from the fact that these priors are 
meant to have little influence on the posterior distribution. While attractive from a 
semantic point of view, we avoid this terminology. Although priors that have little 
effect on the posterior do exist, there is really no such thing as a non-informative 
prior. All priors express information about the parameters. Often, the information 
expressed by these priors is uniquely uninspired in the sense that nobody would use 
them to make decisions in the absence of data. Some may automatically believe 
from the name that a non-informative prior is genuinely not informative, since no 
scientific input has been applied. While there will be situations where priors that 
are so named would have little effect on the posterior, we will give examples of 
such priors that are in fact, disinformative, meaning that they convey a form of 
disinformation that is contrary to the scientific context. We will also argue that 
some are plainly silly from a subject-matter point of view.
6.1 Flat Priors
One sort of reference prior is called a flat prior. Consider Y | 0 ~ Bin(n,0). Often 
people think that putting a uniform distribution on 0 denotes ignorance of the value 
of в. As argued by Raiffa, Schlaifer, and Pratt [264, 267], if you are ignorant about 
0 you should also be ignorant about 02, and you cannot find a distribution that is 
uniform on both 0 and в2.
Nonetheless, people often use uniform priors for a univariate parameter 0 that 
takes values on the entire real line. That is, they use p(0) = c, where c is a constant, 
as a prior. It really does not matter whether one uses p(0) = 1 or p(0) = 123,456. 
The point is that the prior is flat over the entire real line. The point is also that 
the prior is improper, because f p(0)d0 = oo regardless of the constant one chooses 
for the density. In fact, flat priors are inherently silly. Given any bounded set A 
and its complement Ac, the integral outside the set A is JAcp(0)d0 = oo whereas 
the integral inside is fAp(0)d0 < oo, so the prior belief is that virtually all weight 
goes to parameter values that are larger in absolute value than any number you 
can think of. Moreover, if you have a sampling distribution p(y | 0) and use a flat 
prior p(0) = 1, the marginal density for the data p(y) = f p(y | 0)d0 often does not 
exist.
The virtue of a flat prior is that it is often easily overwhelmed by the data. For 
example, using p(0) = c. Bayes' theorem gives
= Lik(0)p(0) = Lik(0)c = Lik(0) 
И l,V /Lik(0)p(0)d0 fLik(0)cd0 fLik(0)d0’
The posterior is simply a normalization of the likelihood into a density for 0. (Not 

Specifying Prior Distributions 
151
all likelihoods can be normalized, because not all have finite integrals with respect 
to в.)
Example 6.1 
. Normal Data. Assume independent normally distributed data 
with unknown mean 0, and known precision to, namely
Yi,...,yn | 0 ~ N(0, 1/to).
Then the likelihood is
Lik(0) oc exp [-у 
- 0)2j .
With у = (yi + •• ■ + yn)/n and recalling that £"=1(yi “ вУ2 = Z"=iG/i ~ У)2 + 
n(y _ 0)2, we have
Lik(0) oc exp [-^(y - 0)2] .
As a function of 0, this is proportional to a N(y,nro) density, so the normal dis­
tribution is the posterior under a flat prior. For example, with <г0 = 1/a 95% 
posterior interval with a flat prior is у±1.96(7о/л/п> which is numerically equivalent 
to, but philosophically vastly different from, the traditional 95% confidence interval 
for this problem.
Example 6.2 
. Suppose 0 is a variance parameter. Then consider an improper prior 
on the positive real numbers
₽(«) = !, e > o.
It is improper because f£°(l/0)d0 = oo. We transform to 7 = log(0) = y(0) and find 
the “density” using the usual transformation technique. Noting that y-1(7) = e7 
and de1 /d'l = e7, the density becomes
g(?) = I e7 I = 1, 7 € (-00,00).
Thus, our initial prior corresponds to a flat prior on the transformed variate, log(0). 
Although the prior p(0) = (1/0)Z(O1OO)(0) may work well in the sense that it is not 
highly influenced by the data, one should never forget that in itself it implies silly 
things, namely that p(0) is either huge if 0 is close to 0 or essentially 0 when 0 is 
large.
For
У1.......Уп|Д,г!ЙЛГ(Д,1/г),
with p and r unknown, the traditional “flat” prior is 
, ч 1 
Р(д,т) = -.
One can think of this as p(p, r) = p(p)p(r) with p(p) = 1 and p(r) = 1/r. So in a 
sense we are taking independent flat priors on p and log(r).

152 
Bayesian Thinking in Biostatistics
Example 6.3 
. Consider an improper prior on the unit interval for a probability в:
p(0) = 0-1(l-0)-1, 0€(O,1).
It is improper because Jo' 0-1(l - 0)~ld0 = oo. We transform to the log odds, 
7 = log[0/(l - 0)] = g(0), and derive its density. Noting that p-1(7) = e7/(l + e7) 
and dfr'trMdi = e7/[l + e7]2, the density becomes
»™ = (iT?) (тттг) 1(177^1 = 1’ 7e(-°°’oo)-
Thus, our initial prior corresponds to a flat prior on 7 = log[0/(l — 0)]. Although 
the prior p(0) = 0-1(l - 0)-1Z(o,i)(0) may work well in the sense that it is not 
highly influenced by the data, one should never forget that in itself it implies that 
в is most likely to be essentially either 0 or 1.
The moral of this story is that a flat prior in one parameterization is not neces­
sarily flat in another. So there is nothing intrinsically non-informative about a flat 
prior, at least according to what the negation of the English definition of the word 
“informative” would imply. However, we did find in Example 6.1 that, with the 
flat prior selected there, formulas for point and interval inferences were identical to 
standard frequentist formulas. Moreover, with unknown mean and precision, and 
with p(^, r) oc 1/r, we also obtain identical formulas for posterior point and interval 
inferences to standard frequentist intervals based on the Student’s t distribution. 
This was established in the remark on page 53 for the case with both mean and 
variance unknown, with jointly conjugate dependence prior in Section 3.2.2.
One of the definitions of a reference prior is that it leads to Bayesian (posterior) 
point and interval estimates, as well as predictive inferences, that are the same as 
a frequentist would obtain without a prior. In this sense, the selected prior is often 
deemed not to affect the posterior “adversely.” We will see later that such reference 
priors are available for the linear model, so that corresponding Bayesian predictive 
inferences will again be identical to standard frequentist inferences, but with distinct 
interpretations of results.
6.2 *Jeffreys  Priors
Jeffreys (1946) [177] proposed a class of non-subjective priors for Bayesian problems 
that can often be termed reference priors. A feature of the Jeffreys prior is that 
it is often improper, meaning that it does not integrate to 1. So it is often not 
probability based. Howver, it has a long history and it has been found to be useful 
in a number of instances. So we discuss it briefly here.
Tlu> Jeffreys prior is defined as
р(в) a y/7(0).

Specifying Prior Distributions
153
where 1(0) is the Fisher expected information, which is the expected value of the 
negative second derivative of the log-likelihood. As mentioned above, this quantity 
will often integrate to infinity, resulting in an improper prior specification. To its 
credit, it is non-negative.
Jeffreys proposed it because it is invariant to monotone transformations. What 
does this mean? In words, it means that if we consider a reparameterization of the 
model, say g = g(0), where p( ) is monotone over the domain of 0, then the Jeffreys 
prior for g is precisely the same as the induced prior that we would obtain for g 
using the transformation formula p(g) = p(g~x(g))\dg~i(g)/d0\. Proof of this fact 
is handled in an exercise.
Example 6.4 
. Normal Data. Suppose we have independent normal observations 
with known mean p0 and unknown variance ст2:
У1.........Yn I a2
With precision т = l/ст2, the likelihood for r (up to a constant) is
Lifc(r) oc nT1/2eXp{-I(2/i - д0)2} = rn/2exp ^(j/i - д0)2} , 
leading to
}og{Lik(r)} oc log(r) + 
- до)21 ■
The derivative of the log-likelihood is
io&{Lik(r)} = 
^(yi - до)2|
and the second derivative is
^log{Lik(r)} = -2r-2.
So, Jeffreys prior for this problem is
Р(т) oc ^r"2oc 7-
Example 6.5 
. Binomial Data. Let Y | 0 ~ Bin(n,0), so
Lik(0) = 0^(1 - 0)n~v.
The log-likelihood is proportional to t/log(0) + (n - y) log(l - 0). The derivative is 
(y/0) — (n - y)/( 1 - 0) and the negative of the second derivative is (y/02) + (n - 
y)/(l - 0)2. The expected value of this under the binomial assumption is
n0 t n-n0 fl 11 n
02+ (i-0)2 “ n (0 + (1 - *))  ~ «(1 - 9Y

154
Bayesian Thinking in Biostatistics
Then Jeffreys prior is
which is a proper Z?e(0.5,0.5) distribution. This is a U-shaped prior that favors 
values of в close to 1 and 0 and thus would not be a likely candidate for a subjective 
prior. For example, it would be silly to say that we were equally ambivalent about 
whether the prevalence of HIV infection was near 1 or near 0, and that it was 
unlikely to be in the center range of 0.
Remark. Interestingly, the use of Jeffreys priors does not satisfy the likelihood prin­
ciple. What does that mean? Loosely stated, the principle asserts that if two likeli­
hoods are the same (up to a constant of proportionality), then inferences should be 
the same in the two cases. For example, suppose we randomly sample ten individu­
als from a population of students and we ask each of them if they have had the flu 
in the last year. Suppose three of them answer yes. Then with 6 defined to be the 
proportion of students in this population who would say yes to this question, we 
have a binomial likelihood, Liki(0) = 03(1 — fl)7. Next, suppose we sample students 
from the same population until we observe the third student who had the flu in 
the last year. In this instance the random variable is the number of samples that 
it takes to observe the fixed number of successes. Suppose we observed the third 
student with the flu on the tenth try. Then we have observed a negative binomial 
response that results in the likelihood Likzfd) = fl3(l — fl)7, which is identical to 
the binomial likelihood. There are different constants that we ignore. According to 
the likelihood principle, we should obtain the same inferences for 0 with the two 
distinct experiments.
The Jeffreys priors for binomial and negative binomial data are different, how­
ever, so the corresponding posterior pdfs are different as well, leading to distinct 
posterior inferences. This is true because, while finding the negative of the second 
derivative of the log-likelihood is equivalent in the two cases, the expected Fisher 
information involves taking an expected value under the two distinct model types. 
The expected values come out differently in the binomial and negative binomial 
cases.
6.3 Scientifically Informed Priors
In this section we discuss informative priors. We have previously discussed the 
import mice of eliciting scientifically relevant information for parameters that are, 
well, scientifically relevant. When 0 represents the probability of HIV infection in 
a population of interest, its relevance is automatic. When sampling a 
model. 0 is a model parameter, and it is often a scientifically relevant parameter at 
the same time. It is usually easy to imagine how to obtain information for it. We 
haw already provided a number of examples. Our purpose here is to extend the 
conversation to mow complex situations. In the previous chapter, we considered 

Specifying Prior Distributions
the two-sample binomial problem, with YJ | 0, Bin(iii. 0,). i = 1.2. Usually (but 
not always) both will be scientifically relevant. For example. 0i might be the 
proportion of men who survive at least 5 years after diagnosis with lung cancer, 
and 02 might be the corresponding proportion of women.
Before proceeding, we need to discuss the key assumption of prior independ­
ence between parameters. For example, with A’(/y.cr2) data, we usually assume 
independence of knowledge about these two parameters. Similarly with two bino­
mial distributions, we usually assume independence of knowledge about population 
proportions. We make similar assumptions throughout the book. We now give an 
example of how to think about this assumption for the binomial case. The thought 
process is similar for other situations. This argument was made in Bedrick et al. [24]. 
where they discuss priors for model parameters in binomial regression models that 
are induced from independent informative priors on scientifically relevant binomial 
proportions.
Example 6.6 
. Prior Independence for the Two-Sample Binomial Model. 
Suppose we have specified prior information as
0i~Be(5,5), 02~Be(7,3),
for which 95% prior probability intervals are (0.21,0.79) and (0.40,0.93), respect­
ively. Consider the hypothetical situation in which we are informed that 0i is near 
its mode 0.5. Since this information is completely consistent with prior information, 
we would have no reason to alter the prior for 02. We argue that if we were informed 
that 0i was a particular value within most of the range of the above 95% interval 
for it, we would still choose not to revise the prior on 02. Consequently, since we 
would not think about revising the prior for 02 when informed in this way about 
0i, we are comfortable regarding these parameters independently.
A counterargument supposes that we are informed that 0i = 0.9. Then, clearly, 
we would want to revise our prior for 02, and clearly we would not be thinking 
of knowledge being independent. Under this purely hypothetical scenario, it would 
be clear that our prior for 0i was poorly informed, which would likely lead us to 
believe that our prior on 02 was also bad.
In fact, under the prior on 0b P(0i > 0.9) = 0.0009, so knowing that 0i is so 
large is extremely unlikely under the given prior specification. Consequently, assum­
ing we believe the prior specification, there is no point in considering hypotheticals 
that we do not consider to be relevant or plausible. Thus, if, after reflection, those 
situations that might cause concern about independence are believed unlikely, the 
independence assumption is reasonable.
An alternative situation would be one in which prior beliefs about the para­
meters were exchangeable, meaning that there was no reason to believe that 0i >02, 
or vice versa, for example. By definition, such parameters cannot be regarded in­
dependently.
We now move on to consider a situation in which the model parameters and the 
scientifically relevant parameters are not the same. We do this in the context of a 
multinomial data example.

156
Bayesian Thinking in Biostatistics
TABLE 6.1: Lung infection versus smoking
S NS___
LI yn y\2 Vi 
NLI У21 1/22 У2 
~y~i 1/ 2 n
S NS ___
LI Pll P12 Pl
NLI P21 P22 P2
~p~l P2 Г
Example 6.7 
. Multinomial Data. Suppose we randomly sample n individuals 
from a particular population of interest and observe them for a year. After the year, 
we ask each of them two questions: (i) Are you a smoker (S) or a non-smoker (NS)? 
(ii) Did you have any form of lung infection (LI) over the course of the year or not 
(NLI)? The data, {KJ, form a 2 x 2 table of counts that follows a multinomial 
distribution with cell probabilities {pej (see Table 6.1). The model parameters are 
the pij. But note that this case is distinct from the sampling scheme discussed in 
Section 5.1, where independent binomial samples were considered. We now define 
the scientifically relevant parameters.
Let = P(LI | S) = pn/p.i, = P(LI | NS) = pi2/P-2, and 7 = Pi = P(S). 
Thus pH = 70i, p12 = (1 - 7)02, P21 = 7(1 - 01), and p22 = (1 - 7)(1 - 0г); 
observe that the cell probabilities sum to 1. Also note that we are unable to think 
directly about the ptj, although with some effort we can find information for the 
scientifically relevant parameters (01,02,7). We place independent beta priors on 
them. Primary inferential interest would focus on the difference 0i -02, or the ratio 
0i/02- In the worst case, if absolutely nothing is known about (01,02,7), we could 
use uniform priors. But of course at a minimum, it would be easy to go on the web 
to obtain information about the proportion of smokers.
The next example illustrates a situation with two distinct parameterizations 
for the same model, where in the first instance the parameters are scientifically 
relevant, and in the second they are not. In general, it is important to know how to 
shift back and forth between different parameterizations. In the current instance, 
one version of the model considered is a special case of the well-known logistic 
regression model that we discuss in Chapter 8.
Example 6.8 
. The Two-Sample Binomial Revisited. We continue with the 
model
Yi I 0i Вт(тц,е,), г = 1,2.
Consider the reparameterized model with
p3i 
е31+3з
“ 1 4- c3, ' 
~ J _|_ e3i +З2 ‘
This is a one-to-one transformation, which means that we have precisely the same 
model as above, only with different meaning attached to the new parameters. For 
example, consider the odds ratio 
OR = 02/(1-02)
01/(1-01)-

Specifying Prior Distributions 
157
which was discussed in Chapter 5. Observing that 0i/(l—0\) = e31 and 0>/(1-Я>) = 
e3i+325 we see that
OR = e32, which implies 3-1 = log((9/?).
We also see that 3\ = log(0i/(1 - 0i)) = logit(0i).
If the model were parameterized in terms of the vector 3 = (/3i, /32)'. as above, 
it should be obvious that it would be difficult to directly think about 3- It would be 
equally difficult to specify a prior for /3. We would, of course, choose to directly place 
beta priors on the 0s, as we have discussed in Chapter 5; or independent normal 
priors on 3i = logit(0j), i = 1,2. This is the logit-normal model we discussed in 
Chapter 5 for the probability If we were insistent on the parameterization in 3, 
which we will be in the next chapter, we would then obtain the induced prior on 3 
using the standard transformation technique that we now discuss.
As in Chapter 5, we regard the 0s to be independent. Here we are able to display 
simple BUGS code that will generate the induced prior on 3'
model{
thetaCl] * dbeta(a.b)
theta[2] ' dbeta(c.d) 
beta[l] <- logit(thetaCl]) 
beta[2] <- logit(theta[2]) - logit(thetaCl]) 
}
Monitoring the /3s, we can plot their induced prior pdfs via histograms.
The general principle that we apply throughout the book is that prior informa­
tion should be elicited for scientifically relevant parameters to the extent possible, 
no matter how little may be available. A probability model that reflects the avail­
able information about these parameters is then specified. Inference is relatively 
straightforward if all model parameters axe scientifically relevant. There are many 
details still to consider about placing priors on such parameters, both when informa­
tion is available and when it is not. When model parameters are not scientifically 
relevant, we develop a prior for scientifically relevant quantities and then induce 
a prior on the model parameters. Bayesian inference follows directly by obtaining 
the corresponding posterior, most often using computational methods resulting in 
samples from the posterior.
Situations will commonly arise in which there are many parameters. It is gen­
erally difficult to specify information for many parameters in a coherent way, that 
is, in a way that does not violate the laws of probability. It would also be quite 
tiresome. In some instances we will be informative about a subset of scientifically 
relevant parameters, and we will look for priors on remaining parameters that will 
have a small impact on the analysis.
In what follows, we consider some simple situations in which more information 
is available for some parameters than for others. More complex examples are given 
as needed in subsequent chapters.
Example 6.9 
. Priors for Parameters of the Two-Sample Binomial Model, 
Continued. Suppose that scientific information is available for 0b but none is 

158 
Bayesian Thinking in Biostatistics
available for 02. Then we can place an informative beta prior on 0\. If we believe 
all values of в2 € (0,1) are equally plausible, then a U(0,1) (i.e., Be(l, 1)) prior is 
reasonable.
We now revisit the ubiquitous N(p,,a2) problem, where prior information is 
available for both parameters. This is followed by the situation where there is 
information for д but not for a.
Example 6.10 
. Priors for Parameters of the Normal Model, Continued. 
Let У1,..., Yn | д, <r2 ~ 7У(д,<т2). We use an informative Nfjio, l/r0) prior for д, 
which is conditionally conjugate, meaning that the full conditional for ц is also nor­
mal. Recall that using a gamma prior for r = 1/a2 is also conditionally conjugate; 
however, т is not easy to think about directly. It would be easier, but still somewhat 
difficult, to think about a. At least the scale for a is the same as for the data, and 
we can think about the actual support values for the data. For example, we know 
that ages cannot be very far above 100, thus we know that a for age data would 
have to be less than 100, and would certainly be much less.
The 90th percentile of the А(д,ст2) distribution, 70.90 = Д + 1.28a, is a para­
meter that a scientist can think about. It is the value in the population that has 
90% of all values below it and 10% above. If we also have information for ц (specif­
ically the prior guess до), we can think about the scientifically relevant parameter, 
70.90, conditionally on д = до- As previously, we regard knowledge about д and a 
independently.
Suppose our best guess for 70.90 is m. Then our best guess for a is ao = (тп — 
до)/1.28. Moreover, suppose that we are 95% certain that 70.9 < и for some и > m. 
Then
0.95 = P(7o.9 < и | д = до) = P(a< (и-д0)/1.28| д = до)
= P(a < (и- д0)/1.28).
Thus сто.95 = (и - до)/1.28 is the 95th percentile of the prior distribution of a.
There are many possible choices of distribution for incorporating this prior 
knowledge, including the conditionally conjugate prior for 1/cr2. If we forget about 
condit ional conjugacy, the gamma distribution for a is a candidate since its support 
is (0.00). We choose the log-normal distribution, since it is easier to find the precise 
prior distribution that has these characteristics. We remind the reader that specify­
ing a prior is not rocket science. We are mainly interested in incorporating the prior 
scientific input in a reasonable way. We want the prior to cover a reasonable range 
of possible values for the parameter of interest. In the informative case, the precise 
form of the distribution is not expected to have a major impact on the posterior. 
Despite the lack of conditional conjugacy, modern computing methods often handle 
this issue with ease.
Specifying log(rr) ~ .V(«,52). in other words a log-normal prior for a or 
n ~ Z.A((i.ft2). we can easily find a and b values that result in the prior on 
n having median <r0 and 95th percentile <t0.95- The median (and mode) of the 

Specifying Prior Distributions
159
LN(a,b) distribution is e“. so we must have a = log(oo)- since the log transforma­
tion is monotone and increasing. Moreover, the quantiles of the normal distribution 
transform directly, so the 95th percentile for a is cro.95 = ee+1 6',аЬ. Thus we set 
и = eiog(<r0)+1-645b t0 obtain ь = [log(u) - log(o-0)]/l-645.
Partially Informative Case. We continue with the same example. Some may 
find it difficult to specify и and/or m. The simplest solution in this case is to let 
p(r) oc 1/r while keeping the informative normal prior for p. This is the Jeffreys 
prior for the known д case. Packages for performing Bayesian analysis may not 
have this prior as an option. A solution is to observe that for a Ga(a. 6) prior on r. 
we have р(т) ос та-1е-6т, which is approximately equal to 1/r for small a and b. 
This prior would not be used to make inference in the absence of data. However, 
with data, we expect little harm to come from its use as it is the standard diffuse 
reference prior for the normal model.
An alternative prior specification for a that involves a little thought proceeds as 
follows. Suppose we still have a best guess for p, namely po- Also suppose that we 
would be incredulous that 70.9 could be larger than u*.  In this instance we get an 
upper bound for cr, a*  = (и
*  — po)/l-28. We could then place a [7(0, cr*)
 prior on cr. 
For example, suppose we are looking at blood pressure data. If our best guess for 
the mean SBP is до = 130, and we are 100% certain that 70 9 cannot be larger than 
u*  = 190, we have po+1.28a < 190, which leaves us with a < (190—130)/l.28 = 47, 
which is very conservative since two standard deviations is 94. It is interesting that 
a Ga(0.001,0.001) has prior probability 0.9975 that cr < 47 (using the pgmamaO 
function in R).
Subsequent chapters present more examples of the basic principles that were 
presented here for prior elicitation and specification. The details may vary, but 
the basic approach is always the same. Specify priors on objects that you and/or 
an appropriate scientist can think about. Then convey that information through 
probability transformation onto the model parameters. Finally, obtain posterior 
inferences, having induced real prior information for those model parameters in a 
sensible way.
6.4 ‘Data Augmentation Priors
By definition, a data augmentation prior (DAP) has the same form as the likelihood. 
In other words, we base the prior for the parameters on “prior observations” that 
give rise to a likelihood that has the same form as the likelihood for our data. This 
results in a posterior that is also in the same form as the likelihood. With large 
sample sizes, standard software can be used in conjunction with a data file that is 
augmented by the “prior data observations.” This results in large-sample posterior 
inferences corresponding to the specified DAP. The same software using only the 
observed data would result in large-sample MLE-based inferences.

160
Bayesian Thinking in Biostatistics
We return to Example 6.8, which involved the reparameterization of the stand­
ard two-sample binomial model. With the independent beta priors that were as­
sumed there, we establish that the induced prior on the 0 coefficients is a DAP.
Example 6.11 
. The Two-Sample Binomial, Continued. Recall that we have
Yt | 6i Bin(n<, 6,), logit(0j) = 31, logit (#2) = 3i + 02-
We first show how this can be reframed as a regression model. Define covariate 
values xi = 0 and x? = 1. Then the observed data can be expressed as 
:
i=l,2} where the yt are realizations of the random binomial variables above, and 
the X{ are regarded as fixed known covariates that are expected, in general, to be 
related to the yt. We rewrite the model as
Yi |z< 
logit(0f) =31+Zi32, г = 1,2.
This corresponds to
So we see that the probability of a success depends on whether xt is 1 or 0, unless 
02 = 0. Thus Oi = 02 if and only if 02 = 0 if and only if OR = e02 = 1.
The likelihood function is
Recall that 31 = logit(0i) and 02 = logit(02) - logit(0i). We write the trans­
formation in vector notation, with 0 = (0i,02):
д _ (0Л _ ( logit^) \ _ (gi(0)\ _ 
p - \02) ~ vogit(e2) - iogit(^); - ^2w -
The inverse of this transformation is <?-1(3) = 0, where the Oi are given as functions 
of 0 in equation (6.1).
The standard transformation formula for obtaining the induced prior density 
function for 3. p(3), from the prior pdf p(0) for 0, is
P(0)=P(O)\ J|+,
where 0 in p(0) are written as functions of 0 using (6.1), | • |+ denotes the absolute 
value of the determinant, and J is the 2x2 matrix of partial derivatives of y-1(3) 
with respect to li (i.e., the Jacobian). Using equation (6.1) again, we obtain
pHl-0!) 
0 
\
' 
^2(1-02) 02(1-02)Г
where the 0, are functions of again using equation (6.1). Thus
2
I J k=0>(l -0i)02(l -02) = 
-0J.

Specifying Prior Distributions
We allow for the possibility of an informative prior by specifying 0, 
Вс^ц.Ь,).
This specification leads to a posterior that is in the same form as the likelihood. It 
will be slightly easier to recognize this fact if we reparameterize to let n, = y, and 
= Щ — Vi- Thus щ = (Ц + bi. We obtain
2 
2 
2
p(/3) ex [рГ *(!  - Ipt1 -= rpf’t1 -
So we see that this is in exactly the same form as the likelihood function in equation 
(6.2), so it is a DAP. Now let iq = 0 and iq = 1. Since the posterior is proportional 
to the prior times the likelihood, 
P(3 I У)
which is in the same form as the prior, resulting in a conjugate DAP.
6.5 
Reference Priors
In this section we discuss a number of examples that illustrate the type of priors 
that we advocate in the absence of substantive scientific information. We hasten to 
point out that in virtually any modeling situation, there will be some background 
scientific information that should perhaps not be ignored. This section considers 
“diffuse” priors that are expected to have little impact on the posterior. At the 
same time, the process of examining whether we have achieved our goal of minimal 
impact will involve exploring the consequences of making particular choices. As 
previously indicated, there are no universal rules for selecting “reference” priors. 
The concept is illustrated in a series of examples.
Example 6.12. A reference prior for a binomial proportion, в, would often be 
(7(0,1). As previously indicated, however, a major goal of a reference prior is that 
it will have minimal impact on the posterior. If we have Y | 0 ~ Bin( 100,000, в), 
and if у = 1 is observed, the posterior mean is 2/100,002 while the usual frequen- 
tist estimate is 1/100,000, resulting in the Bayes estimate being double the usual 
frequentist estimate. The comparison is worse if у = 0, since the posterior mean is 
1/100,002 and the frequentist estimate is 0. The problem is that the uniform prior 
contributes to the posterior information equivalent to a sample of size 2 from the 
population where there was one success and one failure. The uniform prior in this 
example corresponds to a data-augmentation prior. The posterior median or mode 
would be better choices than the posterior mean, but the problem of “arbitrarily” 
adding one success out of two trials remains.

162
Bayesian Thinking in Biostatistics
If we are in a situation where the event being considered is extremely rare, 
it seems that someone would know that fact and consequently would not have 
regarded all values for 0 as equally plausible. If scientists knew that the event 
under consideration was rare, it only seems fair that they should quantify that 
information using a prior.
Example 6.13. As another example, suppose one has just developed a new diag­
nostic test for a particular infection. (We discuss inference for diagnostic tests in 
greater detail in Chapter 15.) The quality of a diagnostic test, T, is determined by 
what are called the test sensitivity and specificity. Denote 1+ and I— as “infected” 
and “not infected,” and T+ and T- as test positive and negative, respectively. 
Then the sensitivity is Se = P(T+ | /+) and the specificity is Sp = P(T— | I—). 
Diagnostic tests are generally developed so that Se > 0.5 and Sp > 0.5; otherwise, 
we might just as well toss a coin to decide whether the individual being tested 
is positive or negative. At an absolute minimum, Se + Sp > 1 is required. Then, 
provided all possible values of Se and Sp are equally plausible, a possible choice of 
“flat” prior for each could be U(0.5,1). It is often the case that scientific information 
is available for either or both test accuracy measures, in which case independent 
beta priors are used (Branscum, Gardner, and Johnson [48]).
Example 6.14. Consider a situation, as we have discussed in Chapter 5, where 
we are interested in comparing two populations with respect to each one’s average 
diastolic blood pressure. Let p\ and p2 denote these averages. In Chapter 5 we 
considered only conjugate and reference priors. Here, since we know with virtual 
certainty that these values must be between 40 and 200, we could place U(40,200) 
priors on them. With additional appropriate scientific information, we could further 
restrict the ranges of the uniform priors on the ps. And of course, we could place a 
subjective prior on one, and some form of “flat” U(a, b) prior on the other, provided 
appropriate scientific information is used in choosing a and b.
Example 6.15. The Two-Sample Binomial (Example 6.8), Continued. A 
choice of diffuse prior for fa, i = 1,2, might be fa ~ N(0,106). This prior has 
95% of its area in the interval (-2000,2000). Specifying a prior in this way is 
clearly without any thought about scientific relevance; the scientifically relevant 
parameters are the 6,. We have argued for specifying priors on these and then 
inducing the corresponding prior on the model parameters, 3. Now we consider the 
reverse. Here, we have specified a diffuse prior for the model parameters, so now it 
is logical to consider the consequences of this choice by looking at the induced prior 
for the 0s. We claimed earlier that the induced prior for each 6 would be U-shaped 
with virtually all of the mass piled up near 0 and 1.
Note that 3] < -4 if and only if 0i < 0.018. Under this prior, we must have 
0.4984 = /’(.-?! < -4) = P(0! < 0.018). Similarly, P^ > 0.982) = 0.4984. The 
induced prior on 0\ has almost 50% of the probability on values less than about 
0.02 and almost 50% of the probability on values greater than 0.98. We also have 
P(0.018 < 
< 0.982) = 1 - 2 x 0.4984 = 0.0032. This is indeed a prior that no one
would use by itself to make inferences about 0X. This example illustrates the point 

Specifying Prior Distributions
163
that it is important to ascertain if a "diffuse” prior on model parameters induces a 
reasonable prior on scientifically relevant parameters.
We wrote R code to simulate the same results:
nSim - 10000
TH « matrix(NA, nrow-nSim, ncol“2) 
b - sqrt(1000000) 
beta ■ matrix(rnonn(2
*nSim,
 0, b), nrow-nSim, 
ncol“2, byrow«T) 
TH[,1) - exp(beta[,l])/(l + exp (beta [, 1])) 
TH[,2] = exp(beta[,l] + beta[,2])/(l + exp(beta[,l] 
♦ beta[,2]))
Many of the generated values for TH are NaN. Thus, there are computer overflow 
problems when simulating the ds. (Think about calculating eJ1 for 3 = 1.000 or 
2,000.)
Example 6.16. Prior for Effect Size. We give an illustration of a “diffuse” 
prior that was selected with the intent for it to be “non-informative.” The problem 
considered involves two independent normal samples with equal variances.
Let Yij 
i = 1,2; j = 1,... ,nt. A common focus in medical and
psychology research is the effect size, Д = (^i — If Д = 2, we know that 
the difference in population means is two population standard deviations above 
zero. This is an extraordinary difference and exemplifies a difference that one could 
actually see. For example, the effect size for the difference between adult male and 
female heights in the U.S. is 2 (cf. Utts and Heckard [338, p. 541]). If one can 
actually see the difference, there may be no real need to conduct an expensive 
experiment to a forgone conclusion. In some literature, effect sizes between 0.2 and 
0.5 are common and effect sizes larger than 0.8 are considered quite large.
There are a number of fairly recent Bayesian articles that propose different 
priors for Д. See Gonen et al. [147] for a recent discussion. One particular choice 
of prior is Cauchy(0,1), that is, a Cauchy with location 0 and scale 1. The Cauchy 
is also a Student’s t with one degree of freedom, so the mean and variance do 
not exist. The median is 0 and the tails of the pdf are “fat.” Under this prior, 
Р(Д > fc) = (0.25,0.15,0.06,0.03,0.003) for k = (1,2,5,10,100), respectively. If a 
scientist believes that the effect size cannot possibly be larger than 1 or 2, a standard 
Cauchy prior should be regarded as inappropriate. By considering a Cauchy(0, b) 
with a small enough b, however, one can cover a more reasonable range of values, 
though it would still have relatively fat tails.
6.6 
Recap and Readings
We have gone into some depth about how, and how not, to specify priors across a 
range of examples. The general principle is to think about parameters that scientists 
care about and understand, and to elicit information about these parameters that 
is independent of the observed data. The parameters that should be easiest to think 

164
Bayesian Thinking in Biostatistics
about are the parameters that would be of most interest when having a discussion 
with colleagues or even the general public. For example, recall the reparameteriza­
tion of the two-sample binomial problem in Example 6.8 where log(Ofl) = /fe was 
one of the model parameters. If 6\ was the probability of living at least 5 years 
after diagnosis with cancer if a particular treatment regimen is used, and Bi was 
the same probability under a second regimen, it would be much more interesting 
to share the information that
P(0.8 < Bt < 0.9 | y) = 0.95 and Pr(0.6 < B2 < 0.7 | y) = 0.95,
which can be inferred from the information about the individual Bi, than it would 
be to tell everyone that P(0.54 < log(OP) < 1.8 | y) = 0.95. So thinking about the 
B{ a priori and then inducing a prior on model parameters is purely logical.
On the other hand, if only a little information is available about the Bi, it is 
still logical to specify diffuse priors for them and then to induce a prior onto model 
parameters. If one insists on placing diffuse priors on and /32 in Example 6.8, 
say, then one should investigate the consequences by looking at the induced prior 
on the Bi.
There are many articles in the literature that discuss how to elicit expert opin­
ions that can expressed using probability distributions; see, for example, Kadane et 
al. [197], Garthwaite and Dickey [120], Kadane and Wolf [199], Ibrahim and Chen 
[170], Garthwaite, Kadane, and O’Hagan [121], Gill and Walker [144], and O’Hagan 
et al. [253]. The authors Kahneman and Tversky [200] famously discussed issues 
related to the quality of subjective determinations of the type involved in prior elic­
itation. The theory underpinning the types of priors discussed in Bedrick et al. [24] 
and their generalizations is discussed in Bedrick et al. [23]. Tools for actually finding 
prior distributions in a variety of families are given and illustrated in Jones and 
Johnson [191]. Seaman, Seaman, and Stamey [284] discuss a number of potential 
perils underlying the use of so-called “non-informative” priors.
6.7 
Exercises
Exercise 6.1. 
(a) Find the Jeffreys prior and posterior for В when Yi,... ,Yn |
В iid Po(B).
(b) Now let у = e~e. which is just the probability of no events under the Poisson 
model. Obtain the induced prior for i], and then obtain the Jeffreys prior for r/ by 
repanuneterizing the log-likelihood and taking second derivatives of it with respect 
to r/. You should get the same results.
Exercise 6.2. Find the Jeffreys prior for В when (Уь ..., Yn) | В ~ N(B, r) with 
known r.
Exercise 6.3. Let q = g(B) be a monotone transformation. Let ji(B) and ji(ri) 
1м
*  the Jeffreys priors for В and r/. respectively.

Specifying Prior Distributions 
165
(a) 
Derive using the reparameterized likelihood, and using the definition of 
the Jeffreys prior.
(b) 
Obtain a formula for the induced prior on tj, say r(zj). using the usual trans­
formation technique.
(c) 
Argue that г(т?) = jzfjf), which means that the Jeffreys prior is invariant to 
monotone transformations.
Exercise 6.4. Derive the Jacobian, J, given in Example 6.11.
Exercise 6.5. Show that in Example 6.11, placing independent Jeffreys priors 
on the 0s results in a DAP with yt = 0.5 and n*  = 1 for i = 1,2.
Exercise 6.6. In Example 6.13, suppose that a random sample of 100 individuals 
has been taken from a population of interest and a test T applied to all. Let Y be 
the number that test positive and suppose that у = 10 is observed. Let P(Z+) = я, 
the prevalence of infection in the sampled population.
(a) 
Using the above notation, give the likelihood function for (тг, Se,Sp).
(b) 
What are the model parameters for this problem?
(c) 
What are the scientifically relevant parameters?
(d) 
What kinds of issues might you anticipate if all uniform priors were specified 
for (7Г, Se, Sp)?
Exercise 6.7. 
(a) Run the R code at the end of Example 6.15 and obtain a den­
sity plot for 0\ when b = 100. Use the iterates to approximate the prior probability 
P(0.02 <0!< 0.98).
(b) Find a value of b that results in an induced pdf for 0X that looks crudely like 
the U(0,1) pdf.
Exercise 6.8. Use R to verify the probabilities for the Cauchy distribution given 
in Example 6.16.


Chapter 7
Linear Regression
Regression models lie at the foundation of statistics and biostatistics. They play a 
major role in the analysis of data across many disciplines. These models are dr- 
fined mathematically with a functional relationship between the mean of a response 
variable and one or more predictor variables (also called covariates). In addition, 
we must also specify a statistical model that describes the variation of individuals 
from the mean response.
For example, consider the VetBP data that was first introduced in Chapter 
1 (Example 1.1). Suppose we want to model the baseline diastolic blood pressure 
(DBP) as a function of age. Here age is the predictor variable and DBP is the 
response variable. The regression function would describe how average diastolic 
blood pressure relates to age. If Y represents DBP and X represents age, then 
the regression of DBP on age is E(Y | X). Regression models characterize this 
relationship through functions of predictor variables (or covariates) and parameters. 
The simplest functional relationship is no relationship—average DBP is the same 
regardless of age, E(Y | X, £0) = A)-
Next, we might consider a simple linear relationship between DBP and age, 
namely E(Y | X,A>>A) = A> + We might consider the effect of age on 
DBP by studying the difference in mean response for two distinct age groups of 
individuals who are d units in age apart. Taking the difference between the mean 
values for the older and younger individuals, we obtain dxft, since fa cancels. 
If d = 10 and fa = 0.5, for example, the average DBP for individuals who are 10 
years older would be 5 units (mm Hg) higher, regardless of their actual ages under 
this model. The value of d is often taken to be 1, but this difference in age may not 
be as interesting to interpret. Asserting that the one-year-older age group would 
have mean DBP response 0.5 units higher just does not seem as interesting or even 
practically important.
Nonetheless, a change in mean blood pressure corresponding to a single year’s 
difference in ages is represented by the parameter fa, which corresponds to the slope 
on a graph of mean DBP (?/-axis) and age (x-axis). We apply the methods of linear 
regression to learn about the value of fa, and d x fa for appropriately chosen d. 
We also consider adding other predictor variables, as well as the possibility deleting 
any, including age, that may not be useful in predicting DBP. An important aspect 
of the development is to recognize that patients of the same age will not all have 
the same DBP. This requires a statistical model specifying how individual values 
of DBP distribute around the mean value given by the regression line for any age.
In regression modeling, it is important to distinguish two types of predictor 
variables: numerical and categorical. Examples of numerical predictors are age,
167

168
Bayesian Thinking in Biostatistics
weight, body mass index, number of nodes examined in breast cancer surgery, and 
number of children. Measurements here are numbers that are meaningful on an 
interval scale.
Alternatively, there are categorical predictors, such as smoking status (with cat­
egories: current, past, never) and marital status (married, divorced, never married). 
We would not want to label three categories with the numbers 1, 2, 3, and then treat 
them as if they were numerical. If we place a regression coefficient in front of such 
a variable, with only that variable in the model, the implication would be that the 
difference in mean response between the third and first categories would be twice 
the difference between the second and first categories. Thus the distinction between 
numerical and categorical variables is necessary to interpret the model parameters 
properly. We begin with the case of a single numerical predictor, then move on 
to categorical predictor(s) and to combining multiple predictors, introducing along 
the way various concepts arising in linear models.
Section 7.1 introduces the regression model and its basic analysis with one and 
multiple predictors. Section 7.2.1 introduces a matrix formulation for regression and 
discusses analytic posterior inference with flat priors. We then describe five different 
types of priors in Section 7.3. Interaction is introduced in Section 7.5. Section 
7.6 presents analysis of variance from the Bayesian viewpoint, using the model 
formulation already discussed. The chapter concludes with a recap and further 
readings in Section 7.7.
7.1 The Linear Regression Model
Linear regression models generally presume that variation about the mean is nor­
mally distributed. The normal distribution was discussed in detail in previous chap­
ters. Here we extend the normal model to involve data with a response and one 
or more predictor variables (sometimes called “covariates”). Generally, Y refers 
to the response or dependent variable, and X refers to the predictors (or co­
variates). We assume the data consist of sets of observations for each of n units, 
{(j/t , r,) : i = 1,..., тг}, where the xt may be vectors of covariates. Furthermore, we 
will assume that the outcomes that we observe vary randomly about a linear func­
tion of parameters and covariates that characterizes the outcome-specific expected 
values. The random deviation about the expected value follows a normal distribu­
tion in the linear regression model, with the variance of this normal distribution 
not changing with covariates. Mathematically, we write the statistical model in two 
parts:
У, 1 N(E[TJ A\.3].<T2), i=l,...,n, 
(7.1)
E(Y, | X„ 3) = 30 + X,., 3t + Xj,232 + ... + Xi.p3p. 
(7.2)
As in previous chapters, we will also use the notation т = 1/cr2 for precision as the 
reciprocal of variance.

Linear Regression
169
Although the predictor variables often result from random sampling in practice, 
we always condition on them in this chapter: hence, we treat them as fixed, denoting 
them using lower-case letters as (z,i.... . xip). Covariate combinations can consist 
of continuous variables, categorical variables, or a mix of data types. The standard 
analysis of variance (ANOVA) model characterizes group-specific means and is a 
linear model with categorical covariates. Traditionally, the analysis of covariance 
(ANCOVA) is the special case in which there is a categorical and a continuous 
covariate. Both of these models are special cases of the linear regression model 
above.
7.1.1 Simple Linear Regression: Single Numeric Predictor
We first illustrate basic concepts by considering a simple linear regression. Simple 
linear regression predicts a continuous (measurement) response using only an in­
tercept and one predictor variable. In this simple case, the likelihood is a function 
of the three parameters (/30, /?i, r).
Figure 7.1 shows what is called a scatter diagram of diastolic blood pressure 
versus age in the VetBP data introduced in Example 1.1. At each age there is 
appreciable variation in the blood pressure, and overall there is a downward trend 
as age values increase. A model that could lead to such data can be thought of 
in terms of the mean blood pressure being a deterministic function of age, with 
individual blood pressure values at any age scattered about that mean.
Using Y for the response variable (diastolic blood pressure), x for the predic­
tor (age), and following equation (7.2), the conditional mean of Y given x—the 
deterministic part of the model—is
E(Y \ x, 0) = 0q + 0\x.
The model states that the relationship between average DBP and age is linear in age 
(ж), with two regression coefficients: the intercept, 0o, and slope, A. Notice that the 
left-hand side in the above equation is the conditional expected value of Y given 
x and not an individual measurement. That is, we are modeling the conditional 
mean of У as a linear function of the covariate x. The name linear regression comes 
from the model of the conditional mean of У as a linear combination of regression 
coefficients times covariates.
To describe variation of individuals from this line, we need a statistical model 
as in equation (7.1), equivalently written as
Y = 0q + 01X + e, £~AT(0,<t2).
The model thus assumes that at each x, the distribution of deviations from the 
corresponding mean of У is normal, with some variance a2. In practice, we need to 
model x and у values for several individuals, so we write
Yi = 0q +/31Xi + в, ~ AT(0,a2), i= l,...,n.
Now we have added two more assumptions: (1) the deviations from the mean,

170
Bayesian Thinking in Biostatistics
age (years)
FIGURE 7.1: Scatter diagram of DBP versus age (VetBP data).
the €i, have the same scatter, no matter the value of the covariate; and (2) the 
Ei (i = 1,..., n) are independent random variables. Figure 7.2 shows a stylistic 
picture of the model and the meaning of the parameters /3q and The density 
curves centered on the regression should actually be drawn in the third dimension 
and aligned parallel to the у-axis, so that individual measurements Y generated 
from any given curve are all at the same value of x.
Combining equations (7.2) and (7.1), the model is
У>,....У„ |/3,a2<~ Mz30+/?irrt,<72),
which wit h т = 1 /<т'2 leads to the likelihood
Z./A-(30. Jj.r) = 
........yn | во,a2) oc JJ
i=i
With priors for the parameters 30-3i- and r. we can proceed to sampling the 
posterior using MCMC methods.

Linear Regression
FIGURE 7.2: A depiction of the linear regression model with intercept betao and 
slope betai.
7.1.2 From Model to Data Analysis
Adding priors to the sampling model, we can convey the linear regression model to 
Bayesian MCMC software (BUGS, JAGS, Stan, etc.); for example, in BUGS we use 
the model statements
model{
ford in l:n){
mu[i] <- betaO + betal * x[i] 
y[i] ' dnorm(mu[i] ,tau)
tau ' dgamma(a,b)
betaO ~ dnorm(mubetaO.taubetaO) 
betal ~ dnorm(mubetal,taubetal)
The form of the priors used here should be familiar from Section 3.2.2 on nor­
mally distributed exchangeable data. It is like the independence prior there, which 
here, too, is conditionally conjugate for Gibbs sampling (see Section 7.3 below). 
Now we must choose the six parameters
(a, b, mubetaO, taubetaO, mubetal, taubetal).
With x[] containing the ages of the veterans in years, fa represents the mean 

172
Bayesian Thinking tn Biostatistics
DBP for veterans of age 0. Clearly, this is not meaningful and only represents 
a mathematical abstraction. It is, therefore, not wise to express any knowledge 
about such a parameter directly. However, if we define the “centered” age variable 
ex = Age - 60 = cAge, now with cAge = 0 we see that fa represents the mean 
DBP of 60-year-old veterans.1 While this fa is unknown, a reasonable prior guess 
might be 75, so we could set mubetaO = 75.
In the absence of additional real scientific knowledge, we could allow a consider­
able degree of uncertainty about it by taking the prior standard deviation for fa to 
be 10, say. This expresses the knowledge that the mean DBP of 60-year-old veterans 
can range from 55 to 95 with 95% probability. Notice that this interval is not for 
an individual’s blood pressure; it is for the population mean. We can see that this 
is a very wide interval expressing very little information. A standard deviation of 
10 is translated into precision as taubeta0= 1/100 = 0.01.
Next we must express our knowledge about the regression coefficient fa. If we 
also have a prior guess for the mean DBP for 50-year-old veterans, say рдьо, then 
we can set pg^o = fa - 10fa, from which we obtain prior guess for fa, namely 
(75 - p<?5o)/lO. If pgso = 70, we would set mubetal= 0.5. Suppose, on the other 
hand, that we are uncertain about whether mean DBP would increase or decrease 
from 75 for veterans who are older or younger than 60. In this case, we can take 
mubetal = 0.
Next we need to specify taubetal, which involves a little more effort. Suppose 
that we are virtually certain that, combining veterans of all ages in the age range 
of the data, the mean DBP is between 50 mm Hg and 100 mm Hg. This is a rather 
wide interval for such averages for DBP. Then using the prior guess for fa, this 
information translates to 50 < 75 4- cAge fa < 100, or —25 < cAge fa < 25. Since 
the range of ages in the data is 35 to 85, or equivalently — 25 < cAge < 25, we 
must have -1 < fa < 1. It is then reasonable to take a prior standard deviation 
for /?i to be 0.5 as this gives 95% prior probability that fa is in this range, leading 
to taubetal = 1/0.25 = 4.
The third unknown, r, or equivalently a, represents the variation in individual 
blood pressures at any fixed age. An extreme range would be about 60 mm Hg, 
implying 2a = 30, which translates to believing that a < 15. Thus a prior guess for a 
lower bound for r is 1/225 = 0.004. For a low limit on a, a tight range for individual 
DBPs at any fixed age would be 25. This leads to 2a > 12.5, or r < 0.0256. By 
trial and error using R functions pgammaO and qgammaO, we find that a = 5 and b 
= 400 yields a 95% interval for r, (0.0041, 0.0256). The corresponding interval for 
a is (6.25, 15.7). with a median of 9.25.
With these prior parameters, carrying out the analysis (using code on the book’s 
webpage for Chapter 7 in files named dbpage.R and dbpagemodel.txt). we con­
st ructed Table 7.1 which shows posterior means, standard deviations, and 95% 
probability intervals for the three model parameters.
Taking the posterior means as our best estimates of corresponding parameters,
’We note that the mean age in the data is 68.18. Here, we have not centered age on the mean 
age.

Linear Regression 
173
TABLE 7.1: Posterior summary for VetDP analysis with one covariate
Mean 
sd 
2.5% 
97.5%
/30 76.5 
0.65 75.2 
тГгГ~
Pi -0.49 
0.05 -0.59 
-0.39
a 
10.1 
0.36 9.5 
10.8
we can see that the estimated mean DBP among 60-year-olds is 76.5 mm Hg. and 
that this estimate decreases by about 0.5 mm Hg for each one-year increase in 
the age in such a population, or about 2.5mm Hg for each five-year increase in 
age. Of course, there are uncertainties associated with these estimates. These are 
quantified by the posterior standard deviations and probability intervals. It is quite 
unlikely, for example, that the population mean DBP at age 60 is higher than 78 
mm Hg, and it is virtually certain that the slope of the regression line is negative 
(see the next two paragraphs!). We also know the variation in DBP from individual 
to individual up to a reasonable level of uncertainty. The standard deviation very 
likely is between 9.5 and 10.8 mm Hg.
It is important to point out a somewhat unexpected aspect of the above es­
timates and a possible explanation of it. For individuals in this study, inferences 
indicate that there is a negative association between age and mean DBP. Since 
the 95%i probability interval for /31 is well below zero, we are virtually certain that 
/31 < 0. This result is contrary to what we all might believe, namely that as we age, 
average DBP would increase, not decrease.
We note that the measurements in Dr. Whittle’s study were on different in­
dividuals in the same time-frame. This precludes making conclusions about the 
progression of DBP in those individuals as they get older. Even so, one might ex­
pect cross-sectional data by age to show an increasing trend. The explanation here 
lies in how the veterans were selected to be part of this study (see Example 1.1). 
They were asked, through veterans’ organizations, to volunteer their participation. 
It is quite possible that older veterans participating in the activities of the organ­
izations and who agreed to participate in this study were the healthier among their 
age cohorts. While this is an important point in interpreting the regression results, 
it has less relevance for Dr. Whittle’s study, which aimed to distinguish between 
the effects of two interventions to lower blood pressure. He randomized the avail­
able subjects to the two interventions for that comparison. Randomization should 
lead to the same distribution of ages in the two treatment groups, so age-related 
effects on blood pressure should be balanced. Furthermore, one can adjust for the 
individuals’ baseline DBPs, as we will see later in Section 7.1.3.
Limiting our conclusions to the population of those veterans who are active in 
some veterans’ organizations and are inclined to participate in a blood pressure 
study, we can estimate the mean DBP at any age within the range of ages in 
the collected data, about 40 to 90 years. For example, at age 70, the posterior 
mean DBP is 76.5 — 0.49(70 — 60) = 71.6. Posterior uncertainty is obtained for 
/30 + /31 (70 — 60) by using random samples from the joint posterior to obtain the 

174
Bayesian Thinking in Biostatistics
corresponding approximate 95% posterior probability interval for this mean. With 
MCMC samples for regression coefficients, vectors betaO and betal in R, we can 
summarize this posterior distribution by:
■•■ndbpatTO <- bete0
*betal
*(70-60)
 
имиу (••. mcmc (■•andbpat70))
We get a posterior mean DBP of 71.6 mm Hg, standard deviation 0.522 mm Hg 
and a 95% probability interval (70.6, 72.7). As expected, the estimated mean DBP 
is smaller at age 70 than at age 60. But note also that the standard deviation is 
smaller. The reason for this is more subtle. The information for the mean of the 
response variable is higher at values of the predictor that are closer to the mean 
predictor value in the data. In our case, the mean age is 68.15 years, where the 
information for estimating the mean response is the highest, or the variation the 
lowest. As we move away from this central age, the uncertainty of model-based 
estimates increases. By adding a couple of lines to the R code, you can verify that 
at age 90, the posterior mean for the mean DBP is 61.75 mm Hg, and the posterior 
standard deviation is 1.21 mm Hg with the corresponding 95% probability interval 
being wider, (59.5, 64.3).
We now turn to the prediction of DBP for a randomly chosen individual from 
the 70-year-old cohort in the population. While we have already seen that the un­
certainty in fa + /?i(70 — 60) is propagated from the uncertainty of the regression 
coefficients (fa and /3J, now there is additional variation from individual to indi­
vidual, represented by a. Moreover, cr itself is not completely known. As we have 
posterior samples at hand, we can easily account for all these sources of uncertainty 
or variation. With each posterior sample of the triplet (/?o,/3i,cr), we can simulate a 
normal random variate with mean fa + fa (70 — 60) and standard deviation o. This 
yields samples from the predictive distribution that we want. Here is the R code:
preddbpat70 <- rnorm(length(beta0), betaO+betal
*
(70-60), sigma)
Bununary (as. mcmc (preddbpat70))
Not surprisingly, we find the mean of the predictive distribution to be 71.1 (close to 
71.6 above; they should be virtually identical up to MCMC error). The predictive 
standard deviation is 10.3 (considerably larger them mean estimation uncertainty 
0.52). ns it should be since a > 0. The 95% prediction interval is (51.8,91.9), 
conditioning on the data and reflecting all remaining uncertainties in the model. 
We have plotted these in Figure 7.3 at 10-year age intervals from 40 to 90, with 
a slight offset from the decade points along the horizontal axis for clarity, and to 
emphasize the distinction between a probability interval for the population mean 
response and a prediction interval for an individual’s response. A careful look also 
reveals how interval widths increase as one moves from the center of the data 
outward.
7.1.3 Multiple Covariates: Continuous and Categorical
We continue with the VetBP example to illustrate relationships between outcome 
and more than one predictor variable.

Linear Regression
FIGURE 7.3: Estimated regression line (solid sloped line), credible intervals for 
unknown line (solid vertical lines), and prediction intervals for individual response 
(dashed vertical lines), VetBP data.
Example 7.1. VetBP data. Recall from Example 1.1 that these data came from 
a randomized study evaluating two different methods of educating and encourag­
ing hypertensive veterans to achieve better control of this condition. One method 
recruited and trained leaders from the veterans’ organizations’ posts (or local chap­
ters), who then educated and encouraged their peers (treatment EP). The other 
method consisted of seminars given by health professionals at the posts (treatment 
EH). We take DBP6 (diastolic blood pressure in mm Hg) six months after the 
start of the educational program to be the outcome or response variable (y). We 
consider the following four covariates: Xi = treatment (Trt), which takes the values 
1 for EP and 2 for EH; x2 = baseline DBP (DBPO, mm Hg); хз = the participant’s 
height in inches (Ht) at baseline; x4 = the participant’s weight in pounds (Wt) at 
baseline.
Figure 7.4 shows a scatterplot matrix of the continuous variables (у,х2,хз,хл) 

176
Bayesian Thinking in Biostatistics
in order to visualize pairwise relationships with the response and between covari­
ates. These plots illustrate that six-month diastolic BP is positively associated with 
baseline DBP, but the corresponding association with height and weight is less ap­
parent.
The linear regression model for these data is expressed as
E(DBP6 | Trt,DBPO,Ht,Wt,0) = 0o + (Trt-1) 0t+DBPO 02 +Ht 03 + Wt 04, 
which is a special case of equation (7.2). Why have we written (Trt - 1) 0i instead 
of Trt0i? If we did not subtract 1, Trt x 0! would equal 0i under treatment 1 
(EP) and 2/?i under treatment 2 (EH). If 0t > 0, the implication would be that 
the added effect (added to 0q) of treatment 2 is assumed to be double the added 
effect of treatment 1 on the mean response. If 0i < 0, the implication would be 
that the decline in mean DBP under treatment 2 is twice that of treatment 1. This 
assumption is unreasonable. With the treatment covariate being an indicator vari­
able, coding it as 0 for one treatment and 1 for the other treatment, the regression 
coefficient is simply the effect of the treatment coded 1 over and above that of the 
one coded 0; (Trt — 1) achieves this 0/1 coding from the original 1/2. Of course, 
the 0/1 coding could have been used in the original data to avoid subtracting 1 in 
the model.
We now turn to analyzing the data. To demonstrate a type of prior choice 
different from that in Section 7.1.2, we use flat priors on 0q,...,04 and log(a). 
This is a somewhat commonly used prior (sometimes called a reference prior) in 
the regression setting. We discuss it more in Section 7.3. Posterior results, using 
this flat prior, are given in Table 7.2. In addition to inferences for the 0s, the table 
also includes predictive inferences for a new future observation yf with covariates 
corresponding to a veteran randomized to the EH education program and whose 
baseline DBP is 84 mm Hg, height is 66 inches, and weight is 230 pounds at the 
start of the study (i.e., Trtf = 2,DBP0f = 84,Htf = 66,Wtf = 230). These 
happen to be covariate values for the person with the highest six-month DBP in 
t he data, 112 mm Hg.
TABLE 7.2: Results of regression of six-month DBP on treatment, baseline DBP, 
height and weight, with flat priors on the 0s and log(a)
Mean
sd
2.5%
97.5%
Const
9.30
8.53
-7.48
26.07
Trt
-0.86
0.84
-2.50
0.79
DBP0
0.62
0.038
0.55
0.70
Ht
0.24
0.13
-0.006
0.50
Wt
0.005
0.010
-0.015
0.025
E(yf)
78.0
0.85
76.3
79.7
yf
78.0
8.1
62.0
93.9
The output suggests that we are 95% sure a veteran who receives peer education 
(EP) will have a DBP. on average, between 2.5 nun Hg lower and 0.8 mm Hg higher

Linear Regression
FIGURE 7.4: Pairwise scatterplots for continuous covariates and response.

178
Bayesian Thinking in Biostatistics
than a veteran receiving eduction from a health professional (EH), both of them 
having the same baseline DBP, height, and weight. As this interval implies a possible 
decrease or increase, it is not clear which group is better off. In other words, with 
the estimated mean effect equaling -0.86, the interpretation would be that using 
the EP treatment would be associated with about 0.86 mm Hg lower mean DBP. 
However, because of the estimation uncertainty, we cannot be confident that EP is 
superior to EH in lowering DBP. We note also that the question unanswered by this 
analysis is whether either treatment would be helpful compared with no treatment, 
and whether the improvement would be clinically meaningful.
FYom the rest of the table, we can say that we are 95% sure that each additional 
5 mm Hg diastolic blood pressure at baseline corresponds to an increased blood 
pressure after 6 months that is, on average, between 2.5 to 3.5 mm Hg higher, with 
other variables fixed. But there is a clear statistical import to this result since the 
95% posterior probability interval is well above 0. This result does give some insight 
into within-individual change in DBP over a six-month period. Tempting as it may 
be, however, it is not possible to interpret this relationship as causal. Finally, the 
effect of Wt on the six-month DBP (in addition to the effect of baseline DBP) is 
unclear, based on the posterior distribution of /34 (its regression coefficient). While 
the 95% two-sided probability interval for (coefficient of Ht) contains 0, there is 
substantial probability that /34 > 0.
The future individual’s DBP is predicted to be between 62.0 and 93.9 mm Hg 
with 95% assurance. Now the person in the sample with these covariates had DBP 
of 112 mm Hg at 6 months. While the wide interval indicates the prediction is not 
precise, it is still interesting that this veteran’s six-month diastolic blood pressure 
is actually higher than the upper bound of the prediction interval. One possibility 
is that this veteran had some other health issues during the six months. Another 
is that the model we used is not appropriate for these data. The sampling model 
should always be validated using the standard array of regression diagnostics; we 
discuss these in Chapter 10.
7.1.4 Centering and Standardization of Covariates
In data analysis it is often useful to center and/or standardize (or rescale) contin­
uous predictor variables. One reason for this is to improve convergence of MCMC 
sampling. Another is to make model parameters more easily interpretable, which 
can also help with prior specification. We saw an example of the latter in Section 
7.1.2 where we created a centered covariate cAge = Age — 60. The centering value 
60 was not exactly the average age in the data but was a convenient value near the 
average.
In this section we illustrate first centering, and then standardization, using the 
VctBP data again. There are three continuous covariates in those data: the baseline 
diastolic blood pressure (DBP0). height (Ht). and weight (Wt). There are n = 383 
observations. and the sample means for these three covariates are 72.4 mm Hg, 
68.9 inches, and 210.9 pounds, respectively. The treatment variable in the data, 
Trt. has lewis 1 and 2. So we transform this variable into a 0/1 variable as Trt — 1. 

Linear Regression
179
as discussed in Section 7.1.2. While it is possible to center such binary variables, we 
choose not to do this to keep the interpretation of its regression coefficient as the 
treatment effect. The model with centered continuous covariates is thus written as
E(DBP6 | x,0) = 3o + (Trt - 1)3, + (DBPQ - 72.4)32
+ (Ht - 68.9)3з + (Wt - 205.9)3.,:
that is, 0o is the expected DBP6 for vets of average height, weight and baseline 
DBP, and given treatment 1 (Trt = 1). Note that with some rearrangement of 
terms, this is the same as
E(DBP6 | x, 0) = 0£ + (Trt - 1)0, + DBPQ 02 + Ht 03 + П7 3.,.
Now the intercept 0J in the model without centering, equaling 0о-72.432-68.90з — 
205.904, has a different interpretation from 0O in the centered model. The predic­
tor coefficients in the uncentered model, however, are exactly the same as in the 
centered model.
Standardizing covariates involves one more step. For example, with covariate 
DPBO, sDBPQ = (DBPQ - PBP0)/sd(DBP0), where DBPQ and sd(PBPO) are 
the mean and standard deviation, respectively, of DBPQ in the data. As in the case 
of centering (at or around the mean), rescaling can be done by using a value other 
than the standard deviation (sd). However, the term “standardization” is generally 
reserved for centering at the mean and dividing by the sd. The model with the 
single standardized covariate, sDBPQ, is
E(Y\DBPQ,0) = ft + sDBPQ 0^
= 0Q + {(DBPQ - DBPQ)/sd(DBPQ) }0t.
In this model, 0, is interpreted as the effect on the mean response of a one standard 
deviation unit increase in DBPQ. The sample mean and standard deviation of 
DBPQ are 71.8 mm Hg and 10.6 mm Hg, respectively. So sDBPQ = (DBPQ - 
71.8)/10.6 = 1 implies DBPQ = 71.8 + 10.6 = 82.4, and 02 is interpreted as the 
effect on the mean response of an increase in baseline diastolic blood pressure of 1 
standard unit or 10.6 mm Hg from the average of 71.8.
Standardization (or centering and rescaling) of covariates can be easily done in 
data preparation before defining the model in any Bayesian MCMC software. Most 
such software will also allow new variable definitions for this purpose. For example, 
in a BUGS model the following statements do this:
DBP6[i] * dnorm(mu[i] ,tau)
mu[i] <- ЪО + Ы • (DBP0[i] - mean(DBPO))/ed(DBPO)
Of course, the prior specification now must be relevant to bO and bl in this 
model.

180
Bayesian Thinking in Biostatistics
7.2 
Matrix Formulation and an Analytic Posterior Distribution
For algebraic and analytic simplicity, as well as for conceptual unity, it is useful 
to consider simultaneously the single (Section 7.1.1) and multiple (Section 7.1.3) 
predictor(s) cases. To do this, we introduce vector and matrix notation in Section 
7.2.1. Then, in Section 7.2.2, we employ this notation and flat priors to derive the 
posterior distribution for the parameters in the linear model.
7.2.1 Matrix Notation
First, let us put the regression coefficients into a vector /3 = 
• • • ,0рУ
and, correspondingly, the covariate values for the ith individual into a vector 
X{ = (1,хд,... ,iip)'. Notice that the first element of each xt is 1 corresponding to 
the intercept /3q. Now this allows us to write equation (7.2) as
E(Yi\0,Xi) = x'i/3.
Next, we represent the data for all n individuals: response variable values in the
with
e \ r ~ Nn(0,r~lIn).
Succinctly, the multiple linear regression model is expressed as
Y = X(3 + e, £\r^Nn(0,T~1In). 
(7.3)
It follows from simple rules, as in Appendix A, about expected values and covari­
ances of linear transformations (Section A.3) that E(Y) = X0, Cov(V) = r~lIn. 
Therefore, the linear regression sampling model is also written
Y | B.T~Nn(X^T~lIn). 
(7.4)
Vhe data (or sampling) distribution (or likelihood, see end of Section 7.1.1) is now, 
from the distribution table in Appendix B,
p(y\3.T.X) X г”/*ехр{_1(у_хЗ)'(у-ад}. 
(7.5)

Linear Regression
IS!
7.2.2 Posterior Analysis using the Flat Prior
We begin with the flat prior: p(3) ос 1 and p(log(cr)) ex 1. Using the method of 
transformations of random variables (Section A.2). it can be shown that this also 
means р(<т) ос 1/<т, р(<т2) ос 1/<т2 and р(т) ex 1/т. We call this the flat prior, as in 
Sections 7.1.3 and 7.3. Assuming independence, we have the joint prior
р(0,т) ex 1/r. 
(7.6)
7.2.2.1 Deriving the Posterior with the Flat Prior
Multiplying the distributions in expressions (7.5) and (7.6), we can write the pos­
terior as
p(0,r\data) ос тп/2-1 exp |-^r(p - X/3)'(y - X/3) J .
To recognize the form of this posterior, we note that the conditional distribution 
р(/3|т, data) is proportional to exp{ —i-r x a quadratic form in /?}, that is, a multi­
variate normal kernel. To identify the parameters of this distribution, we can expand 
out (у — X (3)'(у — X (3) and collect terms to find coefficients of /3 and 0'0 and com­
pare to the Norp+i(-, •) density in Appendix B. We can then proceed to convert 
the result to the 7Vp+i(-, •) form. This approach is straightforward and we use it in 
Section 7.4. However, here it is algebraically a bit messy and lacking in insight. We 
now turn to a different simplification of (y-X0)'(y-X0) using some introductory 
material from linear algebra, vector spaces, and orthogonal projections.
Consider the n x n matrix
P = X(X'X)-'X'.
Simple algebra reveals two interesting properties of P: it is symmetric (i.e., P' = P) 
and idempotent (i.e., PP = P). As a mapping of the n-dimensional vector space 
Rn, it orthogonally projects any vector у € Rn onto C(X), the vector space spanned 
by the columns of X. It is interesting and easy to see that In — P is also symmetric 
and idempotent, where In is the n x n identity matrix. Moreover, In-P maps 
у € Rn onto the orthogonal complement of C(X) in Rn. Since P(/n - P) =0» 
vectors Py and (7n — P)y are orthogonal with inner product 0.
Returning to the quadratic form of interest, first write
У - X0 = у - Ру + Py - X0
= (In-P)y + X(X,X)-1X,y-X/3
= (Jn-P)y + X(0-0), 0 = (Х'Х)~1Х'у.
This leads to
(y-X0)'(y-X0) = {y\In-P)y + X(0-0)}f 
x {(/„-P)?/+ *(/?-/?)
} 
= y\in-P)y + W-PYx'x(j3-p), 

182 
Bayesian Thinking tn Biostatistics
since (In -P)X = 0. Using this last expression for the quadratic form (y-X0)'(y- 
X0), we have
p(0,r | data) a 7n/2-1 exp |-^7j/'(Zn - Р)у| exp 
- 0)'X'X(0 - 0)|.
As 0 here appears only in the third term, which is the kernel of a multivariate normal 
density, a simple comparison with the Nop+1(-, •) entry in the table in Appendix В 
identifies the conditional posterior
0 | r,data ~ Nop+l(0,rX'X) or Np+}(0,^(X'X)"1).
Finally, to obtain p(r\data), we can divide the expression for the kernel of 
p(0, rfdata) above by the conditional density of /?|7, data given by Nop+i (0, rX'X). 
We must be careful to account for the normalizing constant |7X'X|-1/2 = 
t-(p+i)/2|X'X|~i/2 in this density as the constant involves r. Dividing and multi­
plying by r“<p+1)/2, we get
p(r\data) a 7n/2-17"(p+1)/2 exp 
- P)i/|
oc 7<n-P“1)/2-1 exp |-^7i/'(/n - oc Ga(a,b),
where a = (n - p - 1 )/2 and b = y'(In - P)y/2.
It is interesting here to note that 2b has a nice interpretation. Since Py = y, say, 
is the orthogonal projection of y, it is the “closest” point in C(X) to the data y. 
Thus (In-P)y the error or residual in approximating у by y, and y'(In—P)y is the 
squared length of this error, namely, 
— j/i)2- This squared error is typically
denoted by SSE (sum of squares of errors). We also note that 0 = (X'X)~lX'y 
is called the least squares estimate of 0. It is also the MLE. Traditional regression 
methods emphasize 0, SSE, and related quantities. More details are available in 
many texts ([98],[351],[77]), especially in [79] as relates to the material here.
We summarize the posterior distribution as
r\y,x~Ga((n-p-l)/2,SSE/2), 0\y,x,r ~ Np+x(0,a2X'X~'). 
(7.7)
7.2.2.2 Inference with Flat Prior
The posterior in expression (7.7) is a multivariate version of the normal-gamma 
distribution (NoGa) from Appendix B. We have seen NoGa(-,-,■,■) as the conju­
gate prior and posterior for exchangeable normal data in Section 3.2.2. To obtain 
posterior samples we do not need Markov chain methods and can do direct Monte 
Carlo. First simulate т | data from the gamma distribution. Using the simulated 
r. generate 3 | r.data from a (p + l)-dimensional multivariate normal by comput­
ing 3=3 + (\/y/r)Qz. where Q is a matrix square root of (X'X)~l. such that 
QQ' - (-V'-V) *.  and г is a vector of p + 1 iid N(0,1) variables. The following 
stylistic R code
*
 will do this:
tau <- rganma(1,shape-n-p-1,rate-SSE) 
z <- rnorm(p+l)
XpX - t(X)X»XX
Q • chol(solve(XpX))
beta <- beta.hat ♦ (diag(l/sqrt(tau)) X»X t(Q)7.»Xz)

Linear Regression
183
In general, joint posterior samples of (в.т) allow us to carry out Bayesian in­
ference and prediction in linear regression. Of course, such functions of interest are 
closely tied to the scientific context. Even as posterior samples are versatile for 
general targets of inference, it is interesting to note that for linear combinations of 
the components of 3 we can get analytic posterior intervals without Monte Carlo 
sampling.
Such linear combinations of the regression coefficients, say c'3 for some vector 
of constants c = (ci,..., Ср+1)', are often of scientific interest. A vector c with all 
zeros except in the ith slot gives c'3 = ctfi- For example, if .r2 is the covariate for 
age measured in years, and we are interested in the effect of a five-year increase in 
age on the mean response, we would set c = (0,0, 5,0,.... 0). providing there are 
no interactions in the model.
Since linear combinations of multivariate normal variables are normal, 
namely с'З | <т2,3/ ~ N(d3,d(X'X)~1ca2), it follows that (c'3, t) has the 
NoGa(3, (l/d(X'X)~xc), (n-SSE/ty distribution. The marginal of с'/З | у 
is then a t(n — p— l,d(3, y/(c,(X/X)-1c)(S5E)/(n - p — 1)), similar to the deriva­
tion in Section 3.2.2. Thus,
ta/2^MSE(\ + x'j(X'X}~xXf}. The estimation interval width depends on uncer­
tainty about the parameters, while the prediction interval width also depends on 
variability among individuals. If 3 were known, the interval width for the mean 
response would of course be zero, while the prediction interval would still involve 
uncertainty resulting from individual variation in response, even though all such 
individuals have the same predictor combination xj.
While these formulas are nice for shedding light on the frequentist intervals, 
they only work for one-at-a-time simple linear combinations of the components of 
3- There are many other inference targets that will not be tractable analytically. For 
example, let p = 1 and suppose a?! is a binary indicator where Xi = 1 corresponds 
to a particular treatment and xj = 0 corresponds to a placebo. Then, as in Chapter 
5 but with different notation, the effect size for the treatment would be Д = 3\!<J- 
There is no simple formula for making inferences about Д. Another example would
у ~ tn-p, MSE = SSE/(n — p — 1), 
and the 1 — a posterior probability interval is
c'3 ± ta/2y/MSEd(X'X}~lc . 
(7.8)
This interval matches the 100(1 — a)% confidence interval from the frequentist 
perspective, providing a Bayesian interpretation for it that conditions on the data 
at hand. Of course, this agreement is under the flat prior.
Now consider setting с = X/ so that the estimation interval x'j/3 ± 
ta/2\jMSEx'j(X'X}~ lXf corresponds to estimating the mean response for 
all individuals with predictor variables xj. It can be shown that the corre­
sponding prediction interval is similar but with additional uncertainty: x'j3 ± 
^/MSEd(X'XYxc

184
Bayesian Thinking in Biostatistics
involve inferences about the ratio of two mean responses, perhaps (/?o 4- 0\)/0o = 
1 + 0\/0o- For Bayesian analysis, such inferences can be carried out by sampling 
(0, т) I data as detailed above and computing these quantities from each sample.
Predictive inferences are also easily obtained using such posterior samples but 
with an additional step. For each iterate (0^k\ rw), sample y^ ~ No(if0(k\ r<fc)), 
к = 1,..., m, where m is the MCMC sample size. Then obtain the usual quantiles 
and smoothed histogram to approximate prediction intervals and predictive density 
estimates.
Example 7.2. VetBP, Continued. We discuss the VetBP data analysis from the 
formulaic point of view discussed in this section. Recall that the basic data analysis 
was performed in Section 7.1.3 using the flat prior. The basis for the analysis was 
the output given in Table 7.2. In the analysis, there were n = 383 observations 
in the data and four covariates, (DBP0,Trt, Ht, W<); the response was DBP6, 
diastolic blood pressure at 6 months. Under our assumptions, we have 0 | у ~ 
<(378,0, MSE (X'X)-1), where the degrees of freedom are 383 - 5 = 378.
From Table 7.2, we see that 0' = (9.30,-0.86,0.62,0.24,0.005) = E(0' | y). It 
follows that 0i | у ~ <(378, -0.86,0.842) and thus that a posterior 95% interval for 
0i is 0i ± <0.025 0.84 = (-2.5,0.79), where <0.025 based on 378 degrees of freedom is 
approximately 1.96. In addition, the posterior mean of x'j0 = (1,1,84,66,230)/? is 
9.30 - 0.86 4- 84 x 0.62 4- 66 x 0.24 4- 230 x 0.005) = 78, etc. (there has been some 
rounding).
For inference about <7, we start with inference for r. Using the fact that
т I у ~ Gamma(378/2, SSE/2),
where SSE = 24,570.7, we obtain
т = Е(т I y) = ЫЪ/SSE = 0.0154.
Since т SSE | у ~ X378’ we have
0.95 = P(l <rSSE <u\y) = P(l/SSE <r <u/SSE\y) 
= P^SSE/u <a< y/SSEjl | j/),
where I = 326.03 and и = 433.76 are the 0.025 and 0.975 quantiles of the X378 
distribution. Thus a 95% posterior probability interval for a is (7.53, 8.68).
7.3 
Priors
We discuss five types of prior specifications for (/?. r) in the linear regression model 
in expression (7.4). These are: (i) the flat prior, which is the main prior we have 
been using up to now: (ii) a proper prior approximation to the flat prior; (iii) a 
conditionally conjugate independence prior, including its informative elicitation via 

Linear Regression
the conditional means prior (CMP) for 3. with 3 and т independent: (iv) a partially 
informative CMP: and (v) the conjugate normal-gamma prior. The Zellner (1986) 
g-prior is discussed as an important special case of the conjugate normal-gamma 
prior. [361].
7.3.1 Flat Prior
The flat prior for linear regression analysis is defined by
p(/3, r) oc 1/t.
Its integral is not finite and hence it is an improper prior. The prior results from 
taking independent flat priors on the components of 3, and an independent flat 
prior on log(cr).2
2Using the method of transformations of random variables (Section A.2), it can be shown that 
this also means p(a) oc l/a, p(<72) oc l/o2, and p(r) oc 1/r.
Although improper, we noted in Section 7.2.2.2 that this prior results in nice 
formulas for point and interval inference that are the same formulas as one finds 
in frequentist presentations of linear regression. In particular, the posterior mean 
of 3 is the least-squares estimate which, with normally distributed es, is also the 
maximum likelihood estimate, 3- Even with the nice formulas for basic inference 
for model parameters, we note it is still necessary to obtain posterior samples to 
make inferences for nonlinear functions of the parameters.
7.3.2 A Proper Approximation to the Flat Prior
A commonly used proper prior is
3j ~ W(0»&)» T ~ Ga{c,c), т independent of the 3j-
With b large and c small, this prior approximates the flat prior, since the kernel 
of a Gamma(c,c) is тс-1е-тс, so if c is a small number, we have p(r) de 1/r. 
Similarly, p(/3) is approximately uniform over any realistic finite range when b is 
large (cf. Exercise 7.13). The actual values of b and c in the normal and gamma 
distributions should be selected depending on the scale of the measurements being 
considered. This prior can be used when very little information is available or for 
sensitivity analysis when an informative prior is available. The posterior requires 
MCMC simulation. The conditionals for Gibbs sampling are conveniently conjugate 
in this case. Results typically are very similar to those from the flat prior.
7.3.3 Conditionally Conjugate Independence Prior
This section presents the priors that we use most often in practice. We again assume 
prior independence of 3 and r, that is, р(/?,т) = p(3)p(r)- We write it as
3 ~ ЛГр(Ьо, О)), т ~ Ga(a, b), т independent of 3- 
(7.9) 

186
Bayesian Thinking in Biostatistics
Notice that, unlike with the flat prior and its proper prior approximation, the 
components of 0 are not necessarily independent or identically distributed; /9 has 
a multivariate normal distribution. Our task is to determine values a, b, bo, and 
Co that accurately reflect available prior information. We address this in Sections 
7.3.3.1 and 7.3.3.2 below and focus on the conditional conjugacy of the prior here.
*Conditional Conjugacy. The prior in expression (7.9) translates to
p(/3,r) a exp{ — (0 - boYC^1^ - Ьо)/2}тв-1 exp{-rb}.
Multiplying this by the data sampling distribution (or likelihood) in expression 
(7.5) and expanding the terms in the exponent, we obtain
p(0,r | data) oc ra+n/2-1 exp {-r(b + y'y/2)}
x exp {~(0'X'X0 - 2y'X0) + (/? - bo)^1^ - b0)} 
Kra+n/2-l exp {_r(6 _|_ y'y/2)}
x exp {-^(0'(rX'X + Col)0 - 2(туХ + Ь'оС^)0
FYom the last expression, we can write
p(0 | r,data) oc exp {-±(0'(rX'X + Co-,)£ - 2(ry'X + boCo-1)£ 
р(т I 0, data) <x та+п/2~х exp {-r(b + (y'y + 0'X'X0 - 2y'X0)/2} .
We now recognize these as
0 | r,data ~ Norp+X (rX'X + Cq \ (rX'y + C^bo)') , 
т | 0, data ~ Ga (a + n/2, b + (y'y + 0'X'X0 — 2y'X0)/2).
By using the multivariate normal mean and covariance on the Nor line of the 
Distributions Table in Appendix B, we can also write the posterior of 0 | т in the 
more familiar Np+i(M0|r.d<ita^fl\T.data) form as
3\r.data ~ Np+1({tX'X + Cq{тХ'у + Cq *Ь 0}, {tX'X + Cq *} _1).
For posterior simulation, we can simulate 3 | r.data and r | 0,data from these dis­
tributions in a cycle of a Gibbs sampler, using their most recently generated values 
for conditioning. Notice that three statistics (compact data description quantities) 
can be computed before entering the Gibbs iteration: y'y, X'X, X'y—a scalar, a 
(p + 1) x (p + 1) matrix, and a (p-f- 1 )-dimensional vector, respectively.
It is also possible, and perhaps comforting to those who have seen traditional 
regression methods, that the parameters for the posterior conditionals can be put 

Linear Regression
in terms of the least squares and maximum likelihood estimates j = (A'A') 1X' у 
and SSE = (у - X3)’(y - X3). For example,
E(3\r,data) = p^T,data = {rX'X + Cq 1 }-1 {r A" A' 3 + C0-1b0}
by noting X'y = X' X(X' X)~l X'y = X' X3. Observe that this is a linear combina­
tion of the MLE and the prior guess. Similarly, the second parameter in the gamma 
distribution for r | 3, data can be written as
b + (SSE + (3 - 3)'X'X(3 ~ 3)) /2.
In this form, the three statistics 3,SSE, and X'X can be computed outside the 
Gibbs loop.
7.3.3.1 Conditional Means Prior for 3
To implement the conditionally conjugate independence prior, we now turn to the 
task of determining values for b0, Co, a, and b. Since it is not straightforward to think 
about 3, the regression coefficients, we think about the mean values of potential 
observables. We elicit a prior for the mean response at a particular set of values of 
predictor variables. Thus we elicit priors on conditional means
Pi = E(Y | ii) = х[3
for p + 1 subpopulations defined by different predictor vectors ii, i = 1,... ,p + 1. 
That is, we specify a knowledge-based prior for
E(Y \X,3)=3 = X3,
where X consists of the p + 1 rows of predictor variable combinations, z', that 
correspond to types of individuals that an expert can easily think about. The z, 
are chosen so that the matrix X is non-singular. We specify prior uncertainty about 
p as
p ~ Np+i(m, D(w)), i.e., p, N(rhi,Wi), г = 1,... ,p + 1, 
(7.10)
with a knowledge-based (p + l)-vector m, and diagonal matrix D(w). The induced 
prior on 3 is obtained by noting 3 = Х~хр and using the well-known fact about 
multivariate normal distributions that such linear transformations of them are also 
multivariate normal. For example if V ~ 2Vfc(p, S) and A is an г x к matrix of 
constants, then A V ~ Nr(Ap, ASA'). Thus
3 ~ WP+1 [x_17n,X-1£>(w)(X_1)'] • 
(7.11)
This is the method of informative prior specification described in Bedrick et 
al. [23] that is termed the conditional means prior, since the prior specification is 
on the conditional mean. Our goal is not to find the perfect prior to characterize 

188
Bayesian Thinking in Biostatistics
someone’s beliefs but to find a sensible prior that incorporates some basic scientific, 
experiential or historical knowledge. We now illustrate the method.
Remark. While the narrative here is in the form of communicating with a subject­
matter expert, the elicited quantities could be calculated from historical data if 
available.
Example 7.3. FEV Data. Rosner (2006) [272] provides a data set on pulmonary 
function (lung capacity) in adolescents. The response у is forced expiratory volume 
(FEV), which measures the air in liters expelled in 1 second of a forceful breath. 
Lung function is expected to increase during adolescence, but smoking may slow its 
progression. The association between smoking and lung capacity in adolescents is 
investigated using data from n = 345 adolescents between the ages of 10 and 19. The 
predictor variables include Age in years (zi); a 0/1 indicator variable for smoking 
status, Smoke (x2); and the interaction term хз = Xii2- Adding an interaction 
to the model implies a belief that the effect of smoking status on FEV is different 
for different ages. Interactions are discussed in Section 7.5. A predictor vector is 
x' = (1,Х1,Х2,хз). The data are in the file named FEVdata.txt on the book’s 
website under Chapter 7.
With four regression parameters, we select four covariate combinations 
i = 1,2,3,4, corresponding to circumstances that the expert can assess inde­
pendently. In particular, we use prior experience to specify information about the 
subpopulation of 11-year-old non-smokers, x\ = (1,11,0,0); 13-year-old smokers, 
x'2 = (1,13,1,13); 16-year-old non-smokers, x'3 = (1,16,0,0); and 18-year-old smok­
ers, х'л = (1,18,1,18). In matrix form we have
'1 11 0 O'
1 13 1 13
1 16 0 0
1 18 1 18
'xir
X2
*з'
x^ _
It is important to choose the z, so that, during elicitation, the Д, can be each 
regarded separately and independently of the others.
Although FEV values display variability, even within subpopulations, first we 
are interested in the mean FEV value jit for the four circumstances xi, z2, z3, and 
i4. The elicitation process mimics that for the one- and two-sample normal cases 
discussed in Chapter 5, only here we are eliciting information about four groups.
To illustrate, suppose that our medical collaborator expects the average FEV 
among all 18-year-old smokers in the sampled population to be 3.3, and is 99% sure 
that the mean FEV is less than 4.0 in this group. Thus we take m4 = 3.3 and, 
with ic.t ilenoting the prior uncertainty about Д (in the form of variance), the 99th 
percentile of fi । satisfies 4.0 = 3.3 + 2.33>/и^. This gives w4 = (4.0 - З.З)2/2.332 = 
0.09. so that
p., ~ Ar(3.3.0.09).
Similar steps are used to construct normal priors for ji\. Д2, and suppose they 
yield
/И ~ .V (2.8.0.04). ji2 ~ V (3.0.0.04), д3 ~ N (4.0.0.04).

Linear Regression
1S9
In matrix form, we have
X3 = m = X 
7712 
7713 
_7774
2.8‘
3.0
4.0
3.3
’0.04 
0
0 
0.04
0 
0
0 
0
0 
0
0 
0 
I
0.04 
0 
'
0 
0.09] /
N
leading to the induced prior on 3,
where
which is also easily accomplished in R. It is important to remember that this method 
obviously requires that X be invertible. If it is not, then perhaps the partial prior 
specification in the next section would be the easiest solution. Alternatively, one 
can replace one or more of the ii to obtain a non-singular matrix.
7.3.3.2 An Informative Prior for r and a
To construct an informative Ga(a, b) prior for r, we ask an expert to think about 
a percentile for the response values in the population of individuals corresponding 
to a particular predictor vector, say x. To be specific, the 1 — a quantile equals 
i^ + Zi-a a. We elicit a best guess for this quantile, conditional on the best guess 
for xfi from the elicitation in Section 7.3.3.1. Setting this elicited value to xfi+zi-a ° 
leads to a best guess for a, and subsequently to one for т = While this can 
be used to specify a central value for the prior distribution, we need additional 
information to express uncertainty about the best guess for r. We illustrate using 
the FEV data.
Example 7.4. FEV Data, Continued. To choose a and b for a Ga(a, b) prior 
on r, we again consider 18-year-old smokers, i'4 = (1,18,1,18). Given the expert’s 
best guess for the mean FEV for this population, 7Й4 = 3.3, we ask the expert what 
would be a large value for an individual FEV observation that s/he would expect 
to see from this group that could be considered as the 95th percentile. We then 

190
Bayesian Thinking in Biostatistics
set this value equal to ттц 4- 1.645a, where zo.95 = 1-645 is the 95th percentile of 
the A(0,1) distribution. Suppose the expert’s best guess for the 95th percentile 
is 5. Since m4 = 3.3, our best guess for a, say ao, satisfies 5 = 3.3 4- 1.645<7q. So 
<70 = 1.7/1.645 = 1.03, and r0 = (1.645/1.7)2 = 0.94 is the best guess for r. We 
take T0 to be the mode of the gamma prior for r, that is,
0.94 = Q * or a — 0.94b 4- 1. 
b
We complete the specification of the gamma prior by eliciting a measure of 
uncertainty about the 95th percentile. In addition to a best guess (5 above) for 
the 95th percentile, we ask for a lower bound on this guess, looking for the 95th 
percentile of the best guess. Suppose the expert gives the value 4. It follows that
0.95 = P (3.3 4- 1.645a > 4) = P (1.645a > 0.7) 
= P (т < (1.645/0.7)2) = P(r < 5.52).
So we want a and b such that a = 0.94b 4- 1 and the 95th percentile of G(a, b) 
equals 5.52; equivalently, b such that the 95th percentile of G(0.94b4- 1, b) equals 
5.52. We can solve this equation in b numerically by using, for example, pgamma 
or qgamma functions in R. A solution can be obtained by trial and error or, more 
systematically, with a method such as the golden search (see Exercise 7.5).
These specifications, combined with the model, have implications worth pointing 
out. For example, suppose we consider 11-year-old non-smokers with the specified 
conditional mean FEV of m\ = 2.8 instead of m4 = 3.3 for 18-year-old smokers. 
The corresponding 95th percentile should be about 2.84-1.7 = 4.5. According to the 
model and being consistent with the first information, the 95th percentile should 
be about 1.645a0 = 1.7 units above the mean FEV, regardless of the values of the 
predictor variables X2, T3, and rr4. The expert should be made aware of this to see 
if these implications are numerically reasonable. If not, some changes, perhaps to 
the model, should be considered.
7.3.4 Partial Information Prior
In practice, it may often be the case that the available information is insufficient to 
specify a complete conditional means prior (as in Section 7.3.3.1) for the regression 
coefficients, especially when p is moderate or large. Eliciting real prior information 
can be time-consuming. In this section we discuss how to place a partial prior on 
regression coefficients when we are only able to specify information for pi < p 4- 1 
mean values, corresponding to a subset of pi predictor vectors ij, as opposed to 
p 4- 1 as necessary for CMP.
I he simplest case corresponds to pi = 1, that is, when prior information is 
available at only one setting of the p predictor variables. For models with an inter­
cept. consider an individual whose dichotomous predictor variables were all equal 
to 0. with all the continuous covariate та lues set to their sample mean from the 
data. If the continuous variates are standardized or centered, then we simply set

Linear Regression
191
x\ = (1,0,.... 0)'. In this case. pi = 3o- the intercept. We place an informative 
prior normal distribution on pi as we have previously discussed. We now require 
some kind of a reference prior to be placed on (.?i..........ip). We either select an
improper flat prior for these coefficients or a set of independent normal priors with 
mean 0 and large variances.
If an additional elicitation is made for p2 corresponding to predictor vector 
X2 = (1,1,0,... ,0), then independent normal distributions are placed on the /7,. 
which induces a joint normal distribution on 3o and via
CH :](»■“
A reference prior can be placed on the remaining (ij . In this case of two equations 
in two unknowns, we can solve them to get fa = pi and fa = m2 - nq. Using 
such explicit transformations, a prior for (^0,/?i) is easily specified in software 
such as BUGS, JAGS, or Stan: we specify the independent normal priors for pi,p2 
with means mi,m2 and variances wi,w2, and define fa, fa as explicit deterministic 
functions of Д1,д2. An example of this is in the file partialinfopriorcode.txt 
on the book’s webpage under Chapter 7.
More generally, let X be a (pi + 1) x (p-b 1) matrix containing the row vectors 
and let p = X0 be the (pi + 1) x 1 vector of mean responses that correspond 
to X. We would generally pick X so that p only depends on the same pi predictor 
coefficients and no others (although this is not strictly necessary; see Christensen 
et al. [79] for details). This can be done using X = (X],X2) = (X>,0), where Xi 
is (pi 4-1) x (pi + 1). We have rearranged the columns of X so that the first pi + 1 
correspond to the pi 4-1 components of /3. We denote this “shortened” 0 by /3. 
The rows of X must be linearly independent, as was the case with the full CMP, 
so Xi must be non-singular. Write До = X00 = (0o,..., /3P1)' as the corresponding 
“shortened” version of p.
We then specify p = X\0 ~ NPi(rho,D(w)) as in the CMP (Section 7.3.3.1), 
Xi being a non-singular pi x pi matrix. Thus the same argument applies to obtain 
the result given in equation (7.11), with Xi replacing X, and pi replacing p 4-1.
Using a technical argument, Christensen et al. (Section 8.4.5 in [79]) suggest 
that it is reasonable under these circumstances to place independent N(0, b) priors 
on the remaining fas, namely for i = pi 4-1,... ,p 4-1, with b large.
Example 7.5. FEV Data, Continued. There are two additional predictor vari­
ables available for the FEV data: height and sex. In the expanded regression prob­
lem, we can use the CMP prior as a partial information prior in conjunction with 
flat priors on the two additional regression coefficients. This presumes that the 
earlier elicitation applies to children in the four subpopulations with, say, the same 
average height and the same sex. This may be unrealistic in that adding knowledge 
of a person’s sex would probably change one’s opinions about 18-year-old smokers’ 
mean FEV. In any case, the parameterization of the model requires height to be 
standardized and that the selected sex correspond to a predictor value of 0.

192
Bayesian Thinking in Biostatistics
7.4 
* Conjugate Priors
For exchangeable normal observations in Section 3.2.2, we introduced a jointly 
conjugate dependence prior. Here we have a similar situation, except that 0 is a 
vector, while in Chapter 3 p is a scalar. Thus we will use a multivariate normal 
prior for 0 here, but again conditioning on г as there. We first discuss a generic 
conjugate prior and then an important special case of it.
7.4.1 Generic Normal-Gamma Prior
The conjugate prior for linear regression specifies a normal-gamma distribution for 
0, т via a gamma marginal for т and a normal for 0 conditional on r. Specifically,
r~Ga(a,f>), 0 | т ~ Nop+i(0o,kOTTo). 
(7.12)
The parameters here are a, b,0o,ko, and To, with a and b as before, 0o a (p+ 1)- 
dimensional vector,3 To a (p + 1) x (p + 1) symmetric non-singular matrix, and 
ко > 0. This is not as convenient as the independence prior used in the CMP 
for prior parameter elicitation. The difference is that the expert needs to think 
about 0 conditional on knowing the value of r. Nonetheless, the mathematical 
results are pretty, and they have historical as well as practical significance, especially 
as building blocks in Bayesian nonparametric analysis involving Dirichlet process 
mixture models. With sampling distribution
Y\0,r~Non(X0,rIn)
we can write the posterior as
p(/3, г | у) ос т“-1 exp{—br}r(p+1)/2 exp 
- 0o)'To(0 - 0o)
XTn/2exp{~(y-X0Y(y-X0)}
« T(a+n/2)-l exp (b + |(y'y + ko0oTo0o)^ T
X T^I4xp[-T-{0,{koTo + X,X)0 - 2(y'X +ko0'oTo)0}} .
Recognizing this as a product of a gamma kernel in т and a normal kernel (in 
iVor,)+l(.4. B) form) for 3 conditional on r. we conclude that this posterior is 
again normal-gamma, hence conjugate. To identify the parameters, we observe 
.1 = r(A-o7’o + A''A'). В = т(Х'у + коТоЗо), note that A and В involve r, and 
so does the normalizing constant (27г)р/2|.4|_1/2е(1/2)в л_1в.
’ Hen' we use to denote a vector that is a prior guess for 3, even though we have used 3o as 
the scalar first component of J. We rely on context to recognize its meaning.

Linear Regression
193
To see how r appears in this, we write
|A|-
*/
2 = \r(k0T0 + X'X)|“1/2 a г-<₽+1)/2.
B'A~XB = r(y'X + fco^To)(T(fcoTo + Х'Х)Гхт{Х'у + A-0T030) 
= т(у'X + Ло/ЗДХЫЬ + X'X) l(X'y + A'oTodo) 
= тс, say.
Thus, as a function of r, the normalizing constant is proportional to 
r_(p+1)/2exp{(l/2)rc} (see the Nor line for multivariate normal distribution in 
Appendix B). Dividing and multiplying by e^1/2^ as t-(p+1)/2 is included in the 
last expression for p(/3, r | data) above, we get
/3 I т,у ~ Np+i ((&oTo + X'X) x(X'y + &о7о$о)>'г 
+ X'X)-1),
г I у ~ Ga (a + n/2, b + ^(у'у + коР'оТо0о - c)^ . 
(7.13)
It is interesting to note that by formally setting a = b = ко = 0 you can almost 
recover the normal-gamma posterior in Section 7.2.2 when using flat priors. This 
follows since, with these choices, we have
y'y - c = y'Iny - y'X(X'X)~xX'y = y'Iny - y'Py = y’(In - P)y = SSE.
The only difference is in the first parameter of the gamma: n/2 here and (n-p-1)/2 
there in expression (7.7). As we noted there, posterior samples in this case can be 
obtained without Markov chain methods by sampling r from its posterior gamma 
marginal, followed by /3\т from the multivariate normal. The gamma parameters, 
the covariance matrix of the normal, and its mean up to the multiplier r-1 can be 
computed before entering the sampling loop.
If we elicit priors as in the previous section, we would specify
Х0|т~^+1(тп,(1/т)ОД),
with known (p+ 1) x (p+ 1) matrix X, p+1 vector m, and diagonal matrix D(w). 
The induced prior for (3 is
13 | r ~ Np(X~'m, (l/r)X-lD(w)X-y).
Thus we have
0o = X-'m, To = X'fZKw)]-1*,  k0 = 1, 
and the posterior is given by
/3\r,y~Np
where
E(0 | T,y) = {x'X +X'D-l(w)x}-1 {X'y + X'lr^w)™} , 
т | у ~ Ga (a -I- n/2, b + ±(y'y + mX~1X'{D(w)}~1XX~1m - C)
E(0 | т,у), 1 {X'X + X'D"1^)
*}

194
Bayesian Thinking in Biostatistics
7.4.2 Zellner’s g-Prior
Zellner (1986) [361] recommended the prior
p(r) 
P\T^Np+M,gr-4X,X)-1), 
(7.14)
where g is a fixed (tuning parameter) constant. This is known as Zellner’s g-prior. 
Model (7.14) is almost a special case of the conjugate prior in expression (7.12) 
with To = X'X, ko = 1/.9, but with flat prior on log(r) (or log (ст)) which could 
be represented by formally taking a = b = 0. With some care, we can use the 
normal-gamma posteriors in expressions (7.13) and (7.7). As we noted immediately 
after expression (7.13), the first parameter in the gamma posterior for т should be 
(n - p - l)/2, in place of n/2. Moreover, the choice of 7b = X'X, kQ = 1/g in 
expression (7.14) leads to considerable simplifications. In the posterior conditional 
Wp+i distribution for 0 in expression (7.13), the covariance matrix reduces to
S^lT, data =
and the expectation to
WM
*
 = TT7<X'X>‘‘ (x'v +
1+P 
\ 
9 
/ 
1+9 
1+P
since X'y = X'X(X'X)~lX'y = X'X{3. While it is possible similarly to obtain an 
expression for the second parameter in the gamma posterior for т in (7.13), it is 
algebraically simpler to follow the pattern of derivation in the conjugate prior case 
that led to the posterior. In either case we obtain
T I У ~ Ga 
, 1 {sSE + 
- MX'X(0 - ft)}) ,
(7.15)
This posterior has some interesting properties. Since it is normal-gamma, as in the 
flat and conjugate prior cases, Markov chain sampling is not needed; independent 
Monte Carlo samples can be drawn. As g becomes indefinitely large, it agrees with 
the flat prior inference in expression (7.7). With g = 1, the posterior mean for 
3 gives equal weights to the maximum likelihood estimate /3 and the prior mean 
Jo- The choice g = 11 corresponds to assigning a weight to the prior comparable 
to a single observation. For this reason, setting g = n is sometimes called a “unit 
information prior." Several other choices of g, including suitable priors on it, have 
also Ixx'n developed (see Section 7.7).

Linear Regression
195
7.5 Beyond Additivity: Interaction (Effect Modification)
Here we discuss the situation where a treatment may have a different effect on an 
outcome depending on which subgroup of individuals the treatment may be applied 
to. For example, suppose that a well-established drug is known to improve survival 
time after diagnosis for individuals who have been diagnosed with a certain cancer. 
However, suppose that the drug can be safely applied at a low dose and also at 
a high dose. It is of interest to study if dose level affects the degree of survival 
outcome. As the study endpoint, let us use the median survival after diagnosis. 
The comparison of median survival times at high versus low levels of the drug is 
thought of as the “dose effect.” This comparison can be made, for example, by 
a ratio of these two medians or the difference. Now, as the drug can be used for 
women as well as men, the comparison of median survival between women and men 
is then the “sex effect.” Now suppose that the median survival time for women on 
the low dose is 10 years, and with a high dose is 5 years; for men, the low dose 
results in a median survival of 4 years under the low dose, and 10 years under the 
high dose. This artificial example is made to illustrate an exaggerated instance of an 
interaction between the drug’s dose effect and its sex effect. Women benefit from the 
low dose over high; but men benefit from the high dose over low. Conversely, we can 
say that at low dose, women derive a greater benefit than men, but at the high dose, 
men have a greater benefit. In both cases, the effect of one factor is modified by the 
levels of the other factor. In most practical examples, such “directional reversal” is 
rare. Typically, the size of the effect changes with level of the other factor but the 
direction (or sign) remains the same.
To be specific, let us use the relative median as a means of comparison or a 
measure of effect size. This relative median for women to men is, at the low dose, 
10/4 = 2.25; and at the high dose it is 5/10 = 1/2. If there had been no effect 
modification, the relative medians would have been the same for both doses. On 
the other hand, the relative median for comparing low to high dose is 10/5 = 2 for 
women; and 4/10 for men. Here again we see that women have double the median 
survival under the low dose than under the high dose, and men have less than half 
the median survival under the low dose than under the high dose.
The effect modification does not have to be opposite as in the hypothetical 
above. It could be that the dose effect on median survival is non-existent for men, 
that is, if the relative median comparing low to high dose for men was 1 (in this 
case it would not matter if men took the high or the low dose); but that it was 
appreciable for women, that is, the relative median was 2 as above (in this case 
women would be encouraged to take the low dose). Another scenario could be a 
positive effect of taking the low dose for both men and for women (longer survival 
on the low dose than for the high dose), but that the effect is appreciably stronger 
for women than it is for men (e.g., the relative medians above were 2 for women and 
1.5 for men). For all of these situations, effect modification is modeled by including 
a cross-product (or interaction) term in the model.

196
Bayesian Thinking in Biostatistics
In genera), a predictor xi is an effect modifier of a predictor X2 if the effect of 
X2 depends on the value of xi. Note that xi and x2 can both be continuous, both 
categorical, or a mixture of both. The hypothetical example above involved both 
being binary. In general, the model written in regression notation is
E(Y I ZbZ2) = 00 + 01X1 +02X2+03^1X2. 
(7.16)
For the two binary predictors case, if we let E(Y | Xi = i,X2 = j) = L+j, 
i,j = 0,1, then we have
Д00 = 00. Д1О = /?о + /?1» №1=00+02, Ди =/?о 4-/?i 4-/?г 4-/?з-
In this instance, we would define the effect of xi when X2 = 1 to be дц — Д01 = 
01 +0з, and the effect of xi when X2 = 0 to be дю — Доо = 0i - So the model allows 
these effects to be different, provided 03 / 0. With a non-zero value, the sign of 
03 can take the effect modification in either direction. Depending on the values 
of 01,02,03, an effect reversal as in the above hypothetical example is possible. 
Symmetrically, we could have discussed the effect of a?2 for different levels of xb
Next, we consider the case with xi binary, taking the values 0 or 1, and with 
X2 continuous. The model is again expressed as equation (7.16). We can easily see 
that if 0з = 0 and if xi = 0, this is just a simple linear regression model in z2 
with intercept 0q and slope 02- And if xi = 1, it is again a simple linear regression 
model in a:2, but now with intercept 0q 4- 0i and slope 02- So the model allows two 
regression lines, but forces them to be parallel. The effect of the predictor xi is 
measured as
E(Y | xi = l,x2) - E(Y | Xi = 0,z2) = 02
for all values of a:2. This is a special case of the so-called analysis of covariance 
model. With 0з = 0, there is no interaction; the effects of xi and i2 are additive. If 
/?i/0 and 02 / 0, both Xi and x2 modify the response, but neither modifies the 
other’s effect.
So what happens when 03 / 0? We still have two lines, but now the slopes are 
different. The slope when xi = 0 is 02 as before, but when = 1, it is 02 4- 0з- 
The effect modification is no longer as simple to explain. First, suppose that the 
two lines cross, say somewhere in the middle. And for concreteness, suppose that 
t2 is age and .Ti is sex. with a?i = 1 corresponding to females. Also assume that 
02 < 0 and 02 4- 0з > 0. So the mean response is increasing in age for females and 
decreasing in age for males. This is clear-cut effect modification. If 0з = 0, the effect 
of age (i.e.. how response varies with age) is the same for males and for females. If 
any slopes are 0. there is no corresponding age effect. If 02 = 0 and 0з / 0, then 
there is no effix-t of age for men, but there is for women.
Example 7.6. FEV Data Analysis. We now analyze the FEV data that were de­
scribed in Example 7.3. and discussed there and in Example 7.4 with an informative 
prior specification. The model was
E(FEV | Smoke. Age) = 3Q 4- Smoke 4- Age 02 4- Smoke x Age 03, 

Linear Regression
197
where Smoke = 1 denotes smoker status and 0 denotes non-smoker status, and 
Age represents ages between 11 and 19 treated as a continuous variable. We did 
not previously discuss the interaction term .so we do so now.
We ran this model in BUGS using a proper prior approximation to the reference 
prior p(far) oc 1/r and obtained the output in Table 7.3. In a model with an
TABLE 7.3: Posterior summary for FEV analysis with predictors Smoke. Age and 
Smoke x Age
Predictor
Reg. coef.
2.5%
50%
97.5%
Intercept
fa
0.43
1.09
1.75
Smoke
fa
0.13
0.18
0.23
Age
fa
0.0022
1.29
2.67
Interaction
fa
-0.21
-0.11
-0.018
a
0.64
0.70
1.72
interaction term, it does not make sense to attempt to interpret the regression 
coefficients for the variables, in this case Age and Smoke, by themselves. This is 
because we know that the effect of Smoke may be different for different ages, and 
conversely, the regression line of FEV on Age itself depends on the level of Smoke. 
The one regression coefficient that we can discuss is /З3. Since the 95% probability 
interval for /З3 is (-0.21, —0.018), we are at least 97.5% certain that it is less than 
zero. We thus assert that the interaction is statistically important.
The two regression lines for smokers and for non-smokers respectively are
E(FEV I Smoke = 1, Age) = fa + fa + Age{fa + /З3), 
E(FEV I Smoke = 0, Age) = /?o + Age fa.
The posterior means (not shown in Table 7.3) for the regression coefficients are 
virtually identical to the posterior medians, so it can be seen from the table that 
the posterior estimates of fa and fa+fa are positive. Thus both estimated regression 
lines show an increasing trend in expected FEV as a function of age or lung power 
is increasing with age in both cases. However, since the estimate of fa < 0, the 
slope of the line for smokers, is estimated to be attenuated by about -0.11. While 
FEV capacity is increasing with age, the rate of increase is diminished somewhat 
for smokers relative to non-smokers. Since P(fa < 0 | y) > 0.975, this effect has 
statistical importance.
A definition of the effect of smoking on the mean FEV response for a particular 
age is the difference
E(FEV I Smoke = 1, Age) - E(FEV | Smoke = 0, Age) = fa + faAge.
If there were no interaction in the model, the effect of smoking would be the same, 
fa, for all ages. Another definition might be the ratio of the two means, but we 
prefer the difference for this example.

198
Bayesian Thinking in Biostatistics
In order to ascertain if there is any practical import to this observation, we can 
make more explicit the effect of Smoke on the FEV response. Posterior inferences 
for the mean FEV responses for smokers and non-smokers for three different ages 
are shown in Table 7.4. It is clear that there is not a statistically important dif-
TABLE 7.4: Posterior inferences for mean FEV values for smokers and non-smokers, 
and their differences, for ages 11, 15, and 19
Mean response/difference
2.5%
50%
97.5%
Smoker, age 11
00+ 01 + 11(02 + 0з)
2.96
3.19
3.43
Non-Smoker, age 11
00+ 1102
2.94
3.07
3.19
Difference
01 + И03
-0.26
0.06
0.40
Smoker, age 15
00+ 01 + 15 (02 + 0з)
3.19
3.39
3.59
Non-Smoker, age 15
00 + 1502
3.62
3.78
3.95
Difference
01 + 150з
-0.66
-0.39
-0.14
Smoker, age 19
0o + 0i + 19(02 + 03)
3.19
3.66
4.11
Non-Smoker, age 19
0o + 19&
4.15
4.50
4.86
Difference
01 + 190з
-1.46
-0.85
-0.28
ference in the mean FEV values for smokers versus non-smokers for 11-year-olds, 
but the differences for 15- and for 19-year-olds are statistically important. In fact, 
the posterior probabilities that these mean differences are negative are 0.35, 0.9985 
and 0.9977, respectively. So, because of the interaction, while we see that younger 
smokers have similar expected FEV values to younger non-smokers, there is an ob­
vious deterioration in expected FEV values for older smokers compared to older 
non-smokers. In 15-year-olds we see a reduction in FEV for smokers of about 0.4, 
and in 19-year-olds it is about 0.85. While we suspect that these differences are of 
practical import, we would have to rely on the expertise of a qualified physician to 
know for sure. Presumably, the team that collected these data involved precisely 
such an expert.
One question that arises at this stage is whether the assumption of a linear 
relationship in age for smokers and for non-smokers is appropriate. Perhaps the 
relationship is nonlinear for smokers and linear for non-smokers, or vice versa. We 
leave it as an exercise for readers to address this question.
There will often be more than two predictor variables, and. consequently, there 
could be more than one pair of them that one might expect to be effect modifiers. 
One may be tempted to simply add multiple or perhaps even all possible pairwise 
interaction terms in a model. If the number of original predictors is large, this 
would create many additional predictors in the model. For example, if there were 
fixe predictors and all possible pairs of interactions were included in the model, 
then' would then be an intercept, five so-called main effects, and ten interaction 
terms. The number grows quickly as the number of predictors grows. Models with 
many interactions are difficult to interpret, and in some instances, the number 

Linear Regression
199
of parameters involved might exceed the amount of information in the data that 
would be available to estimate them. Data analysis is almost always an endeavor 
involving some well-informed judgments. While it would be important not to ignore 
an obvious interaction when choosing a model, it would also be important not to 
fit an overabundance of terms. Parsimony is a general principle in data analysis, 
meaning that smaller models have a general tendency to be better for prediction 
than larger models. Interpretability of models is also very important, and smaller 
models are surely easier to interpret than larger ones. The exercises as the end of 
the chapter will involve analyzing data with interactions, including the full FEV 
data, which has a total for four predictor variables.
A Note Regarding Measurement and Absence of Interaction. A subtle 
and seldom emphasized aspect of effect modification or interaction is that its very 
definition depends on how we define the effect of a treatment (or any covariate or 
predictor or regressor). Two things matter:
1. The measure of response or outcome (e.g., population mean, population me­
dian, probability or odds of success).
2. The definition of effect (i.e., the function used for comparison of response 
measure at two levels of a covariate). Examples are difference (in means, 
medians, probabilities, etc.), ratio (of means, medians, probabilities, odds, 
etc.), and percent change.
The answer to whether or not an interaction is present depends on each of these. 
To illustrate the second consideration, we return to the example at the beginning 
of this section, with survival time medians at two dose levels for women and men. 
Consider the scenario in the following table, albeit numerically very different from 
the original:
Low dose
High dose || Difference
Ratio
Women
8
4
4
2.00
Men
10
4
1.67
Comparison by differences shows no effect modification by sex. However, if we use 
ratios for dose-level comparisons (i.e., effects), sex is an effect modifier.
An instance where the response measure matters (first point in the list above) 
is for a binary outcome as in Chapters 5 and 8. Using probability or odds will 
influence the existence of an interaction.
Typically, the absence of effect modification or interaction is considered desir­
able, as this situation leads to a simpler explanation of the regression relationship. 
This note is intended as a caution that such simplicity is limited to the chosen 
measure of the response and the function used to compare responses at two levels.

200
Bayesian Thinking in Biostatistics
7.6 ANOVA
The methods from Chapter 5 for analyzing two-sample normal data can be extended 
to compare three or more populations. TYeatment of such data was pioneered by the 
famed early twentieth-century statistician Sir Ronald Fisher and termed analysis 
of variance (ANOVA). Fisher also made many other seminal advances in statistical 
theory and methods, including likelihood-based inference and design of agricultural 
experiments that led to the green revolution in agricultural productivity of the 
twentieth century that is widely credited with alleviating world-wide food short­
ages. Now ANOVA has come to mean the special case of linear models in which only 
categorical predictor variables are used. One-way ANOVA involves a single multi­
level factor, two-way ANOVA has two categorical predictors (and possibly their 
interaction), etc. Such multilevel factor variables must be transformed into a series 
of group indicator variables to include as predictors in a linear model. A related 
model is the analysis of covariance (ANCOVA), which also falls within the frame­
work of the linear model. The simplest ANCOVA model has one continuous and 
one categorical predictor but no interaction. The analysis of FEV data in Section 
7.5 is an example of this.
Suppose we have one categorical variable called Factor A with levels 1,2,..., k. 
Such levels often correspond to distinct groups or populations of patients; for ex­
ample, patients with a certain condition that are untreated or treated by one of 
several possible drugs. Suppose there are n_, response observations yij,..., ynj j in 
the jth group (or level or population) with n = nj being the total sample 
size. For j = 1,..., k, let gj and denote the mean and standard deviation of the 
response in the jth population. Then we can write the model as
ЛГ(^,а2), i = l,...,nj; j = l,...,fc. 
(7.17)
This is a straightforward extension of the normally distributed two-population com­
parison in Chapter 5. In this model, means are allowed to differ among populations 
but the variance is constant.
To put this in the linear model framework, we first label the response values 
with a single subscript as yi,..., yn. We then construct к binary indicator variables 
Л = (х»ь ■ • • >-?:м)/ for each subject, with x,_, = 1 if the observation of response yi 
is at level j of Factor A, and 0 otherwise. Clearly, we must have Xij = 1 for 
each i. For observations yi.... ,ytI, we can then write
Yi | .tj.fi l~ N(.r'fi.a2). i = l,...,n, 
(7.18)
where // = (//].........gA.). Note that for each y, the value of one and only one predic­
tor. say the /th one. equals 1. the rest being 0: and x'g picks off the jth component 
ol fi. We also note that, unlike in expression (7.2). there is no intercept here, and 
the symbol 3 is replaced by ц because of the context. Stacking the y, into a vector 
and the x' into a matrix, we can also write this model as
Y | fi.a2 ~ Хп(Хц.а21п}.

Linear Regression
201
Finally, from a Bayesian modeling viewpoint it is simple to allow the variances to 
differ from population to population. In the model, a2 simply acquires the subscript 
j. But then, a separate prior must be specified for each variance (or precision t}). 
The MCMC sampling structure remains essentially intact with some changes in 
details of parameters for the full conditionals. If using Bayesian software, the code 
changes minimally.
We now illustrate one-way ANOVA by an extension of the DiaSorin data ex­
ample of Section 5.2.4.
Example 7.7. DiaSorin Data. We compared DiaSorin levels of chronic kidney 
disease patients with low bone turnover to those with normal turnover using a two- 
group normal analysis. In addition, there is a third group of 713 = пц = 50 patients 
with high bone turnover. It is useful to distinguish low bone turnover patients, so 
that they can be properly treated. It is also important to identify patients with 
high turnover, because a different course of treatment is given to them.
In Section 5.2.4, we transformed DiaSorin scores (?/) to achieve approximate 
normality. Using the prior information provided by Dr. Herberth (on the scale of 
the scores), we carefully specified the priors for means of log(?/) as 
~
TV(4.87, 0.00288) and p.N = jz2 ~ TV(5.39, 0.00280). Similar methods to those de­
scribed there also led to the informative prior ^3 = цн ~ 7V(6.40, 0.006). To show 
another possibility, we also employ here independent flat priors on М1,М2,Мз-
A standard assumption in traditional ANOVA is that variances are the same 
in the separate populations. In Section 5.2.4 we made no such assumption. In­
stead, we elicited distinct but diffuse priors for (ri,r2): n ~ Ga(1.0376,d) ,r2 ~ 
Ga( 1.04653, d), with d = 0.001. However, to mimic traditional ANOVA, we make 
the equal variance assumption and model uncertainty about the resulting common 
precision as r ~ Ga(0.001,0.001). We combine this prior for т with two different 
prior specifications for the means: (a) informative priors on the gs as above; and 
(b) flat priors on the jtzs.
The one-way ANOVA consists of the factor “turnover group” having three levels: 
low, normal, and high. The primary scientific issue is whether DiaSorin can discrim­
inate among the three groups. As a first step, the data analysis looks for evidence 
that ^1 < jz2 < ^3. While the inferences we made on the means of log(?/) can be 
reinterpreted on the original measurement scale as inferences for medians (we did 
this in Section 5.2.4), we do not need to do this to address the primary inference 
target P(^i < Ц2 < М3 I data).
Basic posterior inference is shown in Table 7.5 under both the informative and 
the flat priors. Posterior location summaries (means and medians) of the fis increase 
from low to normal to high turnover groups in both analyses. Notice, however, that 
for the high-turnover group, these location summaries are considerably larger under 
prior (a). Moreover, all of the posterior standard deviations for the p.s are appre­
ciably smaller under prior (a) than under (b). As is often the case, the informative 
prior yields less posterior uncertainty and tighter probability intervals for the p.s.
While not included in Table 7.5, it is easy to approximate P(^i < д2 < Мз | 
data) with posterior MCMC samples by simply computing the fraction of samples

202 
Bayesian Thinking in Biostatistics
TABLE 7.5: Posterior summaries from ANOVA of the DiaSorin data
Parameter
(a) Informative Prior on fjs
Mean
sd
2.5%
Median
97.5%
ML
4.86
0.05
4.76
4.86
4.96
мн
5.40
0.05
5.29
5.40
5.50
MH
6.26
0.07
6.12
6.26
6.39
T
1.20
0.19
0.85
1.19
1.60
(b) Approximate Flat Prior on ps
Mean
sd
2.5%
Median
97.5%
PL
4.70
0.20
4.31
4.71
5.10
PN
5.49
0.23
5.05
5.49
5.94
MH
5.85
0.12
5.61
5.85
6.10
T
1.32
0.21
0.95
1.31
1.76
that show Д] < д2 < Мз- Under both priors, at least 90% of the samples satisfy 
this inequality. So we are quite certain that the median in the high group is larger 
than the median in the normal group, which is larger than the median in the low 
group. The posterior probability < д2 < Мз I data) equals 1 under prior (a), 
and equals 0.91 under prior (b). With prior (b), the 95% probability interval for 
Дн -ftN includes 0, but the posterior probability that цн is larger than д# is 0.92.
Figure 7.5 shows predictive densities using prior (a) for all three groups on the 
log scale. While these predictive pdfs appear to be somewhat different from each 
other, they show substantial overlap. Note, as always, that predictive distributions 
have larger variances than the corresponding posterior distributions of the p,s (not 
shown). The diagnostic potential of DiaSorin to distinguish among bone turnover 
groups will depend more on how different the predictive distributions are from each 
other than on clear separation of the posterior distributions of the (is.
For inference on the original DiaSorin score scale, we transformed the MCMC 
samples summarized in Table 7.5, exponentiated each д in each sample, and summa­
rized those in Table 7.6. We note that the inference targets are now the population 
medians of DiaSorin scores, and for comparing low, normal, and high bone turnover 
groups the targets are median ratios. With informative prior (a), just as the 95% 
probability intervals for p, — /г, all excluded 0 on the log scale, the intervals for the 
relative medians on the original scale all exclude 1. Thus for any two medians, we 
are quite sure that they differ. In addition, we are 97.5% sure that the median in 
the high group is at least 3.41 times that for the low group. The posterior means 
of the group medians are 129.0. 220.2. and 520.5 for the low, normal, and high cat­
egories. respectively. The analysis for prior (b) is similar but with greater posterior 
uncertainty.
Relevant files for this analysis are on the book's webpage under Chapter 7 as 
diasorinANOVA.txt.

Linear Regression
203
log (Diasorin Score)
FIGURE 7.5: Predictive densities for log DiaSorin scores.
A Note on Traditional ANOVA. In this book nearly all data analysis techniques 
begin with a probability model for the data to be observed—a conceptualization of 
the mechanisms by which the data are thought to arise (i.e., data sampling model 
or distribution; sometimes called the likelihood). Then we express knowledge (via a 
prior distribution) about certain numerical characteristics of the sampled popula­
tion and induce this prior information onto the parameters of the model. Next we 
use Bayes’ theorem to update our knowledge in light of the data (posterior distri­
bution). Finally, all inference flows from this data-informed knowledge distribution. 
Prediction is accomplished using this distribution and the model.
Notice that the data aspects (descriptions and summaries such as mean, median, 
range, standard deviation) themselves do not directly play any role. In traditional 
statistics, on the other hand, one often begins with such functions of data (in fact, 
these are called statistics'.} that are contextually useful. Then one tries to address 
the question of how the particular value of the statistic fits into the possible values 
that would be obtained if the data collection were repeated a very large number of 
times under the data sampling mechanism, regardless of the values of the unknowns 
in this mechanism.
This traditional approach to data analysis has proved very successful in pro-

204 
Bayesian Thinking in Biostatistics
TABLE 7.6: Posterior summaries from ANOVA of the DiaSorin data, original scale
(a) Informative prior on pis_______________
Inference target
Mean
sd
2.5%
Median
97.5%
Medb
129.2
6.72
116.5
129.0
142.8
Med/у
220.5
11.36
199.1
220.2
243.7
Med и
522.0
36.03
455.5
520.5
596.8
Med/y/Medj,
1.71
0.13
1.48
1.71
1.97
Med и/Med l
4.05
0.35
3.41
4.04
4.78
MedH/Med/y.
2.37
0.20
2.00
2.36
2.80
(b) Approximate flat prior on ps
Mean
sd
2.5%
Median
97.5%
MedL
112.7
22.98
74.32
110.50
164.10
Med/у
248.40
57.12
155.30
242.10
377.90
Med и
349.80
43.84
272.10
347.10
444.10
Med/у/Med д
2.30
0.72
1.21
2.19
3.99
Med н/Med л
3.23
0.78
1.97
3.14
4.99
Med/f/Med/y
1.48
0.39
0.86
1.43
2.38
viding scientists and researchers with many tools to carry out inference (drawing 
conclusions from data), especially over the past century. Early examples of these 
arc the ubiquitous “t test” and, of course, ANOVA. We take this opportunity to 
explain ANOVA from this Fisherian approach. It might also shed light on why it is 
called analysis of “variance” when the main goal is to detect whether several means 
are all equal or not.
To keep notational simplicity, let us consider samples of equal sizes n from three 
populations for a total sample size of 3n. The individual observations in the first 
group are denoted yn,yi2, • • • ,2/in, using 1 as the first subscript. This subscript 
order is reversed from that used in our previous notation (e.g., in expression 7.18) 
to keep it consistent with common practice. The previous notation was designed to 
fit into the general linear regression model. Similarly denoting observations from 
the other groups, we write the observations as yy, i = 1,2,3; j = 1,... ,n. This 
extends easily to more groups.
Now we would like to construct a single statistic that will measure the degree of 
discrepancy in the three group means. A clear separation of the means will result 
if distances between group means much exceed the sizes of distances of observations 
within groups. A convenient single number summary of distances between numbers 
in a set is the variance of the numbers. So. we should compare the between-group 
variance to the within-group variance.
Hecall that, in general, the variance of numbers zt,, zn is s2z = 
(zfc-
c)2. Applying this to group means У1.у2-Уз- we get the between-group vari­
ance 
- yY. where у, = ^52"=1yij is the mean of zth group, and

Linear Regression
205
у = я;; 
Уу >4 s the overall mean of all 3n observations. The within-group
4The mathematical reason for this n - 3 divisor is subtle, having to do with the expected value 
of the statistic over conceptually repeated experiments.
sThis definition is for equal-sized groups.
variance should, clearly, use the squared deviation (y^ - у,)2 of an individual obser­
vation from the mean of the group to which it belongs. All such squared deviations 
are to be added and divided by 3n — 3. as 3 distinct means are used as centers 
for deviations,4 resulting in Ea=i У2”=\(Уц ~ У>У2- Extending to J groups of 
equal sizes n, we thus arrive at the single statistic we set out to define, called the 
F statistic in honor of Fisher:5
F 7Т7тЕг=1(Уг-у)2
F=—-------- г------------------------- . г = 
7 = 1........n.
EL. ft)2
Setting aside the divisors I-1 and nl-I, a closer look at the sum of squares (SS) in 
the numerator and denominator reveals a very interesting (and by now fundamen­
tal) equality of statistics: these two SSs add up to the total SS, ^=1 
(s/
*j
 ~уУ2>
which ignores the groups and treats the data as arising from a single population. 
We now see why Fisher termed it analysis of variance-, the total sum of squares is 
broken down into a between-group SS and a within-group SS. A rescaled ratio of 
these two pieces is the statistic we were looking for. This brilliant construction, from 
the data up, played a ubiquitous role in many sciences and engineering where ex­
perimentation is common, especially in the pre-computer-age twentieth century. Of 
course, it continues to be quite useful in many contexts. The Bayesian formulation 
and analysis described earlier, using computer-age posterior sampling techniques, 
allows us to make inferences more readily for a much richer variety of targets than 
the basic and important detection of differences in population means.
7.7 Recap and Readings
Regression, that is, modeling the relationship between the expected value of an 
outcome and potentially explanatory variables, is a basic and fundamental method 
for statistical inference. Most scientific endeavors seek to understand associations 
and relationships. Linear regression is, perhaps, the simplest form of regression, 
particularly since it often involves inference on the scale of measurement without 
requiring a transformation. As we indicated, the topic of linear regression includes 
ANOVA and ANCOVA models. The differences relate to the covariates’ data types. 
Historically, though, the ability to derive answers analytically contributed to the 
separate development of these models.
We have introduced the topic of linear regression and developed it from the 
Bayesian viewpoint for students who may or may not have previous experience 
with it. Two early classic books that concerned models we have discussed in this 

206
Bayesian Thinking in Biostatistics
chapter are the book on ANOVA by Scheffe [280], originally published in 1959, 
and the 1971 book on linear models by Searle [285]. These books base inference on 
frequentist statistics. An early Bayesian book on linear models is by Broemeling 
[54].
As Bayesian statisticians, we consider the regression coefficients as unknowns 
about which we wish to learn more than just a single value—which values may 
be more likely and which less likely? We characterize the entire distribution of 
the coefficients’ values via probability distributions that incorporate the data and, 
possibly, other sources of information. Classical regression books consider probab­
ility distributions for the estimates of the regression coefficients, because they are 
functions of the data. The classical development does not consider variation com­
ing from uncertainty regarding the coefficients themselves or from other sources. 
An early exception is the case of random effects in regression models. The mo­
tivation for adding random effects (as opposed to so-called fixed effects, which are 
the usual regression coefficients) seems to have arisen in agricultural applications. 
Analyses of studies in animals often appeared to exhibit more variation than one 
may have anticipated. Adding a random herd effect, for example, or some other 
source of variation as a coefficient with a probability distribution often improved 
model fit. These random effects in the regression models were essentially treated 
as nuisance parameters in the sense that they were not the focus of the inference. 
Instead of estimating the contribution of these coefficients, the methods integrated 
over them, thereby adding more variation. This methodology is developed in the 
book by Searle et al. [286]. These random effects do have some relationship with 
Bayesian regression modeling. It is not a great leap to see that “extra variation” in 
terms of deviation of observations from expected values and “uncertainty” in the 
regression model may be related.
Attempts to improve efficiency and reduce mean squared error in frequentist es­
timation led to two topics that are closely related. James-Stein and ridge regression 
estimators are two methodologies that lead to shrinkage estimators that are more 
efficient than regular estimation in ANOVA and general regression settings, re­
spectively [152]. The ridge estimator in linear regression is /? = (X'X + kl)~l X'Y, 
where к is a positive constant. If we look closely at the ridge estimator and com­
pare it to the posterior mean in the case of known (or conditioning on) residual 
variance, we see that these two quantities are quite similar. From Section 7.3.3 and 
with the prior of 0 being N(0,Z), E[0 | т,у}....... yn] = (rX'X + Z)-1(tX'?/) =
(X'X + a'2I)~x(X'y). That is, the ridge estimator is the posterior mean of the 
regression coefficients when the prior mean of the coefficients is 0 and the prior 
variance is the identity matrix. We discussed posterior means as shrinkage estima­
tors in Chapter 2. In particular, the case of univariate normal exchangeable models 
showed that the posterior mean is a precision-weighted average of the prior mean 
and the sample mean, conditional on the residual variance (see expression (3.6)). 
1 his notion of the posterior mean being a weighted combination carries over to the 
multivariate case, as we can set' in the development in Section 7.3.3.
An important part of building regression models is selecting the covariates that 
matter in the regression. In regression, one will likely start with a set of covariates 

Linear Regression
207
and then decide whether or not each should stay in the model. We talked about 
looking at individual regression coefficients' posterior distributions in this chapter 
to help make this decision. An approach that several researchers have chosen for 
regression modeling is the so-called spike-and-slab prior for the regression coeffi­
cients. Initially proposed for linear regression [243]. the spike-and-slab prior assigns 
to each regression coefficient for the jth covariate (aj) the following prior distri­
bution: p(/3j = 0) = noj and p(0j G [—Wj.Wj].5j / 0) = 2^7?^ = (1 - ttoj). This 
prior distribution for /3j consists of a spike of height tfoj at zero and a slab of width 
2wj centered at zero with height тг^. Each of the 2P possible models from the p 
covariates has a prior probability that is a product of the 1 — tfoj for the covariates 
that are included in the model and a product of the iroj for those covariates that 
are left out of the model. The spike-and-slab prior and variants are easy to program 
via MCMC and also lend themselves to posterior averaging across multiple models 
(Bayesian model averaging [165]). Further details may be found in George and Mc- 
Cullogh (1993, 1997) [139, 140]. Statistical research continues to provide extensions 
and variations of the spike-and-slab prior
Assessing the fit of different models includes more than just deciding whether 
or not to include a covariate, of course. We discuss model comparison in Chapter 
10. The Zellner g-prior is especially useful for Bayesian hypothesis testing using 
Bayes factors (see Chapter 10). With this prior, the Bayes factor is available in 
closed form for testing a coefficient having value 0 [352]. This approach was used 
in a pharmacogenomics study to screen through single nucleotide polymorphisms’ 
associations with a drug’s pharmacokinetics [274].
The mathematical derivation of the distribution of the regression coefficients 
used many techniques from linear algebra. The multivariate normal model finds 
itself used very often across several Bayesian models. An important paper that 
presents many results for the multivariate normal distribution is by Lindley and 
Smith [228]. In fact, the ideas in that paper form the basis for analysis of so-called 
multilevel or hierarchical models (Chapter 14).
Many of the remaining chapters of this book build on the concepts we have pre­
sented for linear regression. Although the mathematical formulations of the models 
differ according to the sampling distribution of the observed outcome or response, 
the basic idea of a regression and a conditional mean being a linear function of 
coefficients and covariates is fundamental.
7.8 Exercises
Exercise 7.1. Refer to the VetBP data analysis in Section 7.1.2 for this ex­
ercise. Using “flat” priors, or proper approximations to them, do the following:
(a) 
Obtain inferences (posterior median, 95% probability intervals) and comment 
on them for:

208
Bayesian Thinking in Biostatistics
(i) 
the mean DBP for 50-, 60-, and 70-year-old veterans;
(ii) 
the three pairwise differences in these means.
(b) 
Compute the posterior probabilities of:
(i) 
fa < 0; (ii) fa < 78.
(c) 
Obtain predictive inferences for 50-, 60-, and 70-year-old patients.
(d) 
Obtain the predictive probability that a randomly chosen 50-year-old veteran 
will have a higher DBP than a randomly chosen 70-year-old veteran.
Exercise 7.2. Refer to Example 7.1 and posterior results that were given in 
Table 7.2. Write your own code to obtain inferences for the model after centering 
the continuous covariates DBPO, Ht and Wt.
(a) 
Assess convergence of your Markov chains.
(b) 
Construct a table similar to Table 7.2; compare results and discuss.
(c) 
Using posterior samples, obtain appropriate quantities to interpret the effect of 
an increase in 10 mm Hg of the baseline DBP (DBPO) on the six-month DBP for 
populations of veterans under treatment 1, and under treatment 2. Discuss.
(d) 
Rerun your MCMC sampling code, this time using original uncentered variables. 
Discuss how well the MCMC procedure is converging under this parameterization.
♦Exercise 7.3. Define 0 = (X'X)-1 X'y, SSE = (y - Xfa'(y - Xfa as in 
Section 7.3.3, just before Section 7.3.3.1.
(a) 
Show that
(y - Xfa'(y - Xfa = y'y + faX'Xfi - 2y'Xfa
(b) 
Then use the result in (a) to show that
(у - X fatty - Xfa = SSE + (0 - fa'X'Xtf - fa.
(c) 
Argue that the minimizer of this quantity is 0 = fa and consequently argue that 
the MLE for 0 is just fa The first of these is a classic result from traditional linear 
models theory, which is the essence of the Gauss-Markov theorem.
*(d 
) Defining P as in Section 7.2.2, using its properties from that section, and using 
that fact that
(y - Xfatty - Xfa = (y-Py + Py + xfa'{y -Py + Py + Xfa,
provc the result in part (b); this is obviously a different approach than was used in 
part (b).
Exercise 7.1. Consider the FEV data and CMP prior specified for 0 that was 
discussed in Example 7.3. There, in' — (2.8.3.0,4.0,3.3) is the vector of prior guesses 
for the mean FEV values for the predictor combinations specified in the matrix X 
in the example.
(a) 
If you believe that smoking might affect lung capacity over time, is the prior 

Linear Regression
209
specification in this example reasonable? Explain in words what the prior is sug­
gesting in terms of the effects of smoking and age on the FEV response.
(b) 
Now consider an alternative prior specification with m' = (2.8. 2.5. 4.0. 3.5). 
How are these prior beliefs different from those in the example?
(c) 
Simulate the induced marginal prior distributions for the components of 3 us­
ing both priors discussed above; discuss similarities and differences between the 
corresponding induced priors.
(d) 
Analyze the FEV data using both priors discussed above. Discuss. The data 
can be found on the book’s website (Chapter 7, FEVdata.txt).
(e) 
Analyze the FEV data using the standard reference prior (flat prior from Section 
7.2.2), p(0,r) oc 1/t, or a proper prior approximation to it. Compare results with 
those obtained in part (d).
Exercise 7.5. FEV data. Consider Example 7.4, where we discussed the elici­
tation of a Ga(a, b) prior for r.
(a) 
Complete the trial and error needed to obtain values of a and b. Plot this gamma 
density.
(b) 
Simulate 5,000 samples of т from this gamma density and plot a histogram of 
corresponding as.
(c) 
How well does the plot in (b) satisfy the prior input?
(d) 
Obtain posterior inferences for regression coefficients for the FEV data using a 
flat prior for 3 and with prior for r:
(i) 
Ga(a, b) from part (a); and (ii) Ga(0.001,0.001).
Compare results. The data can be found on the book’s website (Chapter 7, 
FEVdata.txt).
Exercise 7.6. FEV data. Consider Example 7.4 where we discussed the elicita­
tion of a Ga(a, 5) prior for t.
(a) 
Place a Ga(a',b') prior on a (instead of t) using the same prior information 
that was given in the example. Find the (a',b') pair that best satisfies the given 
prior information.
(b) 
Simulate 5,000 samples of a ~ Ga(a',b') and plot a histogram of the corre­
sponding as.
(c) 
How well does the plot satisfy the specified prior input?
(d) 
If you did Exercise 7.5, compare the two histograms for a. Are they nearly the 
same? Which is more consistent with the elicitation information in Example 7.4?
Exercise 7.7. With FEV data from the book’s website (Chapter 7, 
FEVdata.txt), obtain posterior inferences using the CMP prior in Section 7.3.3.1 
on /3 and a Ga(a',b') prior on a.
(a) 
Select the prior on a to satisfy the prior information specified in Example 7.4.
If you did Exercise 7.6(b), you already know (a',b').
(b) 
Discuss convergence of your Markov chains.
(c) 
Compute posterior probability intervals for

210 
Bayesian Thinking in Biostatistics
(i) 
E(FEV | Age = c, Smoke = 1,0)- E(FEV | Age = c, Smoke = 0,0) for 
c = 13 and c = 18
(ii) 
E(FEV | Age = 18, Smoke = 1,0)- E(FEV | Age = 13, Smoke = 0,0)
(iii) 
the 0i 
and obtain 
(iv) numerical approximations to P(0i > 0 | data), for all 0i- 
(d) Give a brief one- or two-paragraph summary of the most salient conclusions 
that can be made based on your output. Explain in terms that would be clear to a 
medical professional. Make distinctions between statistical and practical import.
Exercise 7.8. Head circumference and gestational age. Consider fitting a simple 
linear regression model for the average head circumference (in centimeters) at birth 
as a linear function of the newborn’s gestational age (in weeks). We elicit a prior for 
Д1, the average head circumference for male infants at 40 weeks’ gestation, based 
on tables for boys from the World Health Organization (WHO) available at
www.who.int/childgrowth/standards/second_set/chts_hcfa_boys_z/en/
The tables list the average head circumferences at birth (and at various ages after 
birth).
Average human gestation is 40 weeks (280 days). We use here the head circum­
ference at birth from the WHO table (downloaded 7/28/2018) as the prior mean for 
a boy baby’s head circumference at birth after 40 weeks’ gestation. The WHO table 
(“Head circumference-for-age: Birth to 13 weeks”) gave the median head circum­
ference for boys at birth to be 34.5 cm, and 97.5th percentile 37.0 cm. We thus take 
the prior mean rh\ = 34.5. For the standard deviation, we equate 34.5 + 2a = 37.0 
and solve a = (37.0-34.5)/2 = 1.25 cm, assuming that the head circumferences are 
roughly normally distributed with standard deviation a. Note that this represents 
variation from infant to infant. We can, quite conservatively, take this as the upper 
limit on our prior uncertainty about др
Now consider д2, mean head circumference corresponding to a birth at 36 weeks 
of gestation. For illustrative purposes, we specify that the average boy baby’s head 
circumference at 36 weeks is a centimeter smaller, m2 = 33.5 cm. To compensate 
for this assumption, we allow for greater uncertainty by doubling the standard 
deviation for the mean head circumference at birth after 40 weeks’ gestation. In 
other words, we arc 97.5% certain that the head circumference of a baby boy born 
at 36 weeks' gestation is less than 38.5 cm (= 33.5 + (2 x 2.5)). We note that the 
greater uncertainty for a boy born at 36 weeks leads to a larger upper bound than 
the corresponding upper bound for a 40-week gestational period, even though the 
40-week mean is larger than the 36-week mean.
(a) 
Derive the induced CMP for 0 and give 95% prior probability intervals for /?0 
and using normal distributions
(b) 
Simulate from the induced prior on 3 by first simulating д and then solving for 
3 in terms of д. Then obtain exact 95% prior probability intervals using the results 
in part (a). Compare the simulated results with the exact ones.

Linear Regression
211
(c) 
Place independent uniform priors on the two mean head circumferences, say 
Д1 ~ U(32.37) and p2 ~ U(28.5.38.5). Simulate from the new induced prior on 3 
and compare intervals with the previous results.
Exercise 7.9. Head circumference and gestational age. continued. Consider the 
problem described in Exercise 7.8. Suppose that, independently of the data, the best 
estimate of the 90th percentile of head circumferences among baby boys born at 36 
weeks was 32.0 cm. Moreover, with 95% certainty assume that the 90th percentile 
of the head circumferences of these babies is believed to be at least 35.0 cm.
(a) 
Using any additional needed prior information from the description in Exercise 
7.8, derive an appropriate gamma prior for r given this information. Plot the prior. 
Then obtain the induced prior for a using the usual transformation technique and 
plot it. Comment.
(b) 
Now assume, with 95% certainty, that the 90th percentile of the head circum­
ferences of these babies is believed to be at most 38.0 cm. Find an appropriate 
Ga(a, b) prior for a. Plot it.
EXERCISE 7.10. Head circumference and gestational age, continued from Exercises 
7.8 and 7.9. Now suppose that there is a second predictor variable for the head 
circumference data, say the baby’s weight. Assume that the prior information col­
lected in Exercise 7.8 can be regarded as if it was for babies that were of an average 
weight of 3.4 kg.
(a) 
Using the CMP prior developed in Exercise 7.8(a), construct a partial informa­
tion prior for regressing head circumference on both gestational age and weight. 
{Hint’. Consider reparameterizing the model by using the centered covariates, cAge 
and cW eight. It is then easier to obtain the precise induced prior on the “new” 
parameters.)
(b) 
Simulate from your partial information prior and induce a prior on mean head 
circumference corresponding to four newborns as follows:
(i) 
Two babies born after 37 weeks’ gestation: one baby weighs 2.7 kg, and the 
other baby weighs 3.5 kg.
(ii) 
Two babies born at 41 weeks: one baby weighs 3.4 kg, and the other baby 
weighs 4.5 kg. Comment.
Exercise 7.11 Consider a situation with p = 4 covariates and suppose the first 
covariate is Sex, which takes the value 1 for females and 0 for males, and the 
second covariate is Long, which takes the value 1 if there is “good longevity” in 
their close family and 0 if not. Let the third covariate be centered cAge, and the 
fourth be centered diastolic blood pressure, cDBP (centered meaning that their 
means in the data have been subtracted). Suppose that individuals under study 
all have high-quality insurance and that the response is the total cost of medical 
treatment over a five-year period. Also suppose that cost information is available 
for two types of individuals. The first is a male with Long = 0 and of average age 
and DBP {cAge = 0, cDBP = 0). The second is the same as the first, except that 
their cDBP = 15. The two m, are $25,000 and $30,000, respectively; and both w. 

212 
Bayesian Thinking in Biostatistics
equal $5,000. Give an appropriate partial information prior for the five-dimensional 
0.
Exercise 7.12. Full FEV data. Recall the FEV data from Example 7.6. We now 
consider the full data set, which includes two additional predictor variables, height 
and weight. The data now include predictor variables smoking status (S'), age (4), 
height (Я), and sex as an indicator of being male (Af); (see the book’s website, 
Chapter 7, FEVdata-full.cav). We consider the model with sex and centered age 
and height, namely
E(FEV\S, cA, cH, M) = fa + 0icA + 02S + 03S xcA + 04cH + faM.
Assume a normal linear model with constant variance, a2 = 1/r.
(a) 
Analyze the data using a flat prior (р(0,т) <x l/т), or a proper diffuse approx­
imation to it.
(b) 
Interpret the interaction effect in terms of practical and statistical import.
(c) 
Compare inferences for the full model to inferences for the model without height 
or weight. Do they change appreciably, and if so how? If they do change, what might 
that mean from a scientific vantage point?
Exercise 7.13. Full FEV data, continued. Recall the FEV data from Ex­
ample 7.6. We consider the full data set, which includes predictor variables 
(Age, Hgt, Male, Smoke); (see the book’s website, Chapter 7, FEVdata-f ull. csv). 
We consider the same model as in Exercise 7.12 with centered age and height.
We construct a partially informative prior for 0 based on the prior of Example 
7.3. We specify a normal prior on two expected FEV values that correspond to 
two predictor combinations, fa, i = 1,2. These will correspond to an 11-year-old 
and a 16-year-old female, both non-smokers and both of average height. Recall in 
Example 7.3, where we only had age and smoking status as predictors, we specified 
a CMP that included specifications for 11- and 16-year-old non-smokers. If we 
regard those two children as having average height, then the prior specifications 
made there will be precisely the same here (ignoring differences in average heights 
for male and female children in this age range). One difference is that here we 
have centered the continuous covariates. For convenience, center age at 16, so that 
the 16 in the X matrix in Example 7.3 becomes 0 and the 11 becomes -5. Now 
we have .г, = (1,-5,0,0,0,0) and x'2 = (1,0,0,0,0,0). Using the prior specified in 
Example 7.3. we have fa ~ N(2.8.0.04) and fa ~ N(4.0,0.04), independently. This 
will induce a prior on and 0\. Specify a flat prior on the remaining parameters, 
namely p(32. Л-^i- fa-т) x 1/r. or a proper diffuse approximation to it.
(a) 
Obtain posterior inferences using this prior. If you did Exercise 7.12, compare 
inferences.
(b) 
Repeat (a) using a partial prior that uses only the specification for fa. Compare 
results with those in (a).
(c) 
Now extend the partial prior in (a), so that it includes an additional normal 
prior for pa. which corresponds to .r'3 = (1.0.0.0.1,0). Assume that there is no 

Linear Regression
213
reason to believe that being one standard deviation above the mean in height will 
result in a higher or lower mean FEV value. You may be more uncertain about 
this than we were in the previous example for the corresponding situation. Then 
again, using the prior information given in Example 7.3. obtain the induced partial 
information prior for (/30, £1, З4). You can do this analytically by obtaining the exact 
trivariate normal distribution, or by simulating the marginal prior distributions for 
these three regression coefficients.
Exercise 7.14. Blood versus breath alcohol project. Most governments impose tut 
upper limit on blood alcohol levels of drivers as a way to reduce the risk of accidents 
caused by driving impairment. It is easier for law enforcement agents to collect a 
sample of the alcohol level by measuring the alcohol concentration in the driver's 
breath than by drawing a blood sample on the side of the highway. The research 
question was whether one can estimate a person’s blood alcohol concentration by 
measuring the concentration of alcohol in the breath.
Austrian researchers sought to answer this question. They assembled a group of 
59 Austrian volunteers (27 women and 32 men) to participate in this experiment. 
The volunteers’ ages ranged from 20 years to 40 years. After verifying that each 
participant was sober at the start of the experiment, the experimenters allowed the 
participants to drink alcoholic beverages of their choice over a two-hour period. The 
average alcohol consumption for the volunteers was 1.07 ± 0.23 g/kg body weight. 
The experimenters then measured the alcohol concentration in the individual’s 
breath every 30 minutes, starting 30 minutes after the volunteer finished drinking. 
Blood alcohol measurements occurred at the same time. Breath and blood sampling 
continued up to five hours after the individual finished drinking or until the breath 
alcohol concentration was <0.1 mg/L. Volunteers could eat sandwiches and drink 
water during the measurement phase.
The data, available on the book’s website under Chapter 7 in file named 
breathalcohol.csv, consist of an identification number for each participant, 
whether the participant was male (0) or female (1), the breath alcohol concen­
tration (mg/L), and the concentration of alcohol in the blood (g/L). We wish to 
predict у (blood alcohol level) based on x (breath alcohol concentration level). We 
also wish to know if the relationship between these two alcohol elimination rates 
differs for men and women.
(a) 
Make a scatterplot of blood alcohol versus breath alcohol with different symbols 
or colors representing males and females. Comment.
(b) 
Model the data using a linear model that allows for two distinct lines. Super­
impose a plot of the two fitted lines on the scatterplot of the data from part (a). 
Comment on the plot. Do the data suggest the possibility of fitting the model with 
parallel lines?
(c) 
Interpret the model that was fit in part (b). Then fit the model with parallel 
lines and decide if the simpler model might be preferable. Discuss.
(d) 
For your chosen model in part (c), plot the estimated mean response as a 
function of the measured alcohol level in breath over a grid, and also plot 95% 

214 
Bayesian Thinking in Biostatistics
probability interval values (upper and lower) for each grid point. Then repeat giving 
95% prediction curves.
(e) 
To interpret the association between x and y, present posterior inferences for 
parameters and predictions in an appropriately designed table. Give a brief narra­
tive with the table, addressing the association.
Exercise 7.15. FEV data. For the two-predictor version of the FEV data (see 
the book’s website, Chapter 7, FEVdata.txt), analyze the data with the goal of 
assessing whether or not the square of age should be added to the model that 
has linear terms in age for smokers and non-smokers. It could be that there is a 
quadratic trend in age for smokers or for non-smokers or both. You may wish to 
start by plotting FEV values versus age for smokers and for non-smokers on the 
same plot with different colors or symbols for smokers and non-smokers. Justify 
your conclusions based on an appropriate data analysis. You may use flat priors or 
proper prior approximations to them.
‘Exercise 7.16 Marginal posterior for /3. With the flat (or reference) prior 
p{0,r) oc 1/t, and referring to Section 7.2.2 for background and notation, show 
that
0 | у ~ Tp+1 (n - p - 1, Д MSE(X'X)-1) ,
the multivariate T distribution with dimension p + 1, location 0 and dispersion 
matrix MSE (X'X)-1; the general form is given in Appendix B.
‘Exercise 7.17. Marginal posterior for d0. Under the same conditions as Ex­
ercise 7.16, show that
c'0 | у ~ T\ (n - p - 1, c'0, MSEc^X'X^cj .
{Hint-. First obtain the distributional result for c'0 | т, у and then obtain the kernel 
of the marginal density for d0 | у by integrating the density for {c'0, т) | у with 
respect to r.)
‘Exercise 7.18. Pirdiction of yj. Assume the same conditions as in Exercise 
7.16.
(a) 
Derive the predictive density for a future response, yf, for an individual with a 
known predictor combination x.f. that is, show that
Ilf | xf.y (n-p- 1. .r'f0. MSE {1 + x'f{X'X)~l xf)j .
(b) 
find an expression for a 95% predictive probability interval for yf.

Chapter 8
Binary Response Regression
As we saw in Chapter 7, linear regression involves modeling the average of a numeric 
and continuous response variable Y as depending on a vector of predictors (or 
covariates), say x, via a linear function of x and the regression coefficients. In this 
chapter, we consider binary (or dichotomous) Y responses that take on one of two 
possible values (typically, 0 or 1). In particular, we introduce logistic regression and 
some other forms of binary regression models.
As one example, we analyze the data on lymphedema (LE), a possible con­
sequence of surgical treatment of breast cancer that results in arm swelling that 
can lead to decreased functioning, skin breakdown, and chronic infections if left 
untreated. The goal is to ascertain whether the probability of LE depends on the 
number of lymph nodes examined during breast cancer surgery, whether cancer 
was found in one or more of the nodes (lymph node metastasis), and the age of 
the patient. We also analyze a second data set that has not yet been introduced. 
Here we have records of whether patients admitted to the University of New Mex­
ico Trauma Center were discharged alive or died prior to discharge. The goal is to 
model the probability of death as a function of a number of potential predictors, 
such as age; nature of the injury that brought them to the center, classified as blunt 
or penetrating; and a measure that reflects injury severity.
Section 8.1 introduces the logistic regression model and its basic analysis for 
Bernoulli as well as grouped binomial data. Section 8.2 discusses interaction between 
predictors. Section, 8.3, tackles inference for functions of model parameters. Section 
8.4 considers priors, and Section 8.5 considers prediction. Section 8.6 briefly treats 
the probit and complementary log-log links.
8.1 Logistic Regression Model
Binary and binomial data were discussed in detail in Chapters 3 and 5. To model 
such data when the outcome (or response) probability is thought to possibly depend 
on predictors (or covariates), we begin with data denoted {(yi, Xi) : i = 1,... , n}, 
where the yi are the Bernoulli outcomes and Xi are the covariate vectors. To begin 
with, let us denote the unknown probability of the conditional event Yi = 1 | ц by 
6i so that Yi | Xi, Bi ~ Ber(0i). Now we wish to specify a model for Bi to depend on 
Xi. Looking to linear regression for guidance and noting E(Yi | Xi,Bi) = Bi, we might 
think of modeling the Bi as a linear function of the covariates and suitable regression
215

216
Bayesian Thinking in Biostatistics
parameters. However, since the 0, are probabilities, they must be restricted to the 
interval [0,1]. Linear functions, without cumbersome side conditions, do not have 
such a limited range. We thus turn to transforming probability to a logit (the log of 
the odds, first defined in Section 5.1.1.3), which has range (—00,00). Then logit(0j) 
can be modeled as a linear function of regression coefficients, namely,
logit(0,) = 0O + Piiii +■■■+ PpXip
following notation from Chapter 7 on the right-hand side. Moreover, using vector 
notation as in linear regression, we also write this as
logit(0i) = х'^З,
where Xi = (1,хц,... ,XiP)' is the vector with first element equal to 1 for the 
intercept and the rest corresponding to the p covariate values for the zth observation. 
The data model can now be written as
Г1,...,Гп I 0b...,0n ~ Ber(0i), logit(0i) = 43. 
(8.1)
To see explicitly how the probability that У = l|xt,0, relates to the regression 
coefficients, we invert the linear logit function as
logiK#,) = log (д^) = x’t0 
=> #, =
The last expression is the inverse of the logit function. We formalize it with the 
name expit as
ea
expit(a) = -—— , a G (-00,00),
which is also known to be the cdf of the standard logistic distribution. From the 
above two displays, it follows that 1 — 
= 1/(1 + ех‘&) and the odds of У = l|xi, 0
equal ex'A
To complete the Bayesian model, we need priors for the intercept and the re­
gression coefficients in 0. Unlike in previous chapters (where data model and sci­
entifically meaningful priors are discussed before data analysis), for simplicity, we 
proceed here from the data model directly to analysis. We do this initially using 
(improper) flat priors on the regression parameters. The intent here is to emphasize 
tools of inference and prediction first. A detailed discussion of more suitable priors 
is given in Section 8.4.
Another point of departure from our development of the linear regression model 
is that we will move from this model specification to computation using Bayesian 
software, such as BUGS, JAGS or Stan, without first “deriving” the posterior dis­
tribution. rhe reason for this is twofold. First, the derivation does not lead to any 
familiar family of distributions for 3 | data. that is, conjugate or other analytic­
ally tractable priors are not available. Second, most current Bayesian data analysis 
software allows one to specify the model and priors in the language of random 
quantities and their distributions. Then, given data, the software automatically 

Binary Response Regression 
217
generates posterior samples using appropriate techniques from Chapter 4 by means 
of symbol manipulation to generate code. It is. however, quite possible (and very 
useful for students intending to develop new models for data) to start from first 
principles, namely, write down densities for the data model and priors, and рпнччч! 
to develop MCMC sampling algorithms, writing code in R. C++. Python, etc. It 
turns out that with log-concave priors, posterior samples can be generated using 
Gibbs sampling and log-concave simulation. It is possible also to employ other tech­
niques, such as the Metropolis-Hastings algorithm or Hamiltonian Monte Carlo. In 
this chapter we avoid this first-principles effort, except in some optional exercises.
Finally, before turning to examples, we briefly discuss the binomial regression 
model, closely related to the Bernoulli specification above and useful when appropri­
ate. When data arise in groups, it is convenient to use counts of observations in each 
group. Let щ, i = l,...,p, be the number of individuals (or experimental units) 
in each group, and the number of “successes” (typically coded 1 in the Bernoulli 
formulation) be yi, i = 1,... ,g. The number of observations here can be seen as g 
with each observation having a binomial distribution, У) | Oi Bin(ni,0i). Thus, 
we can write
Y\,...,Yg | 01,...,0g ~ BinM), logit(0ff) = х\/3. 
(8.2)
For this formulation, all observations within a group have identical predictor values. 
This situation typically arises when all covariates are categorical in nature and 
the data can be represented as cross-tabulated counts. Our first example below 
considers a simple case: one covariate with two categories. Thus g = 2 is the number 
of observations in the data set. For an equivalent Bernoulli model as in expression 
(8.1), there would need to be n = Щ Bernoulli observations in the next data 
set (n = 1,211 in the example).
Example 8.1 
. Analyzing Grouped LE Data Using a Logistic Regression 
Model for Binomial Observations. We return to the study of lymphedema 
(LE) in breast cancer patients described in Example 1.2 and further discussed in 
Example 5.2. Recall that there were n = 1,211 women who were followed for up to 
4 years. We will consider the LE status as the outcome and the number of lymph 
nodes examined during breast cancer surgery as the covariate. We set У = 1 if 
LE is present and 0 otherwise. As previously, we dichotomize the number of nodes 
examined. The covariate High = 1 if the number of lymph nodes is greater than 5, 
and High = 0 if the count is 5 or less. We note from Table 5.2 that for 0i = P(Yi = 
1 | High = 1) and 02 = P(Y2 | High = 0), the posterior medians were 0.26 and 
0.073, respectively, indicating a large difference. We now revisit this problem using 
a regression approach. We are summarizing the data set of 1,211 women as data 
for two groups. In effect, then, this example’s data set has outcome observations 
(number of women with LE) for two groups with щ = 477 for Highi = 1 and 
n2 = 734 for High2 = 0, not 1,211 individual observations. Thus, the data in Table 
5.1 are represented here as {(3/1 = 126, High], = 1), (3/2 = 53, High2 = 0)}, with 
Yi I Highi, 01 ~ Bin(477,0i) and Y2 | High2,02 ~ Bm(734,02). The linear logit 

218
Bayesian Thinking in Biostatistics
relationship in expression (8.2) is then written as
logit(d<) = 0q + High,, i = 1,2.
where
1 + e^o+^1 ’ 
1 + e^°
The odds ratio comparing odds of LE for a woman with a high count of nodes 
examined to one with a low count is OR = 
= e^‘ •
In Chapter 5, we used an informative prior for fa and 02. Here, we consider 
flat (and thus improper) priors for the fa, which could be used if there really was 
no scientific information available. The model and data can then be conveyed to 
software such as WinBUGS, OpenBUGS, JAGS, Stan, etc. For example, BUGS code 
is on the book’s website for Chapter 8 in file example8-l.txt. Using this code, 
inferences given in Table 8.1 are close to those given in Table 5.2, indicating that 
the somewhat informative prior used there had little impact on the analysis due to 
the large sample size. The posterior probability that OR > 1 is effectively 1.
TABLE 8.1: Posterior summaries for LE data using the logistic regression model
Parameter
mean
sd
2.5%
median
97.5%
0.26
0.02
0.23
0.26
0.30
fa
0.072
0.01
0.055
0.072
0.092
RR
3.72
0.58
2.74
3.68
4.99
OR
4.72
0.84
3.30
4.64
6.68
RD
0.19
0.022
0.15
0.19
0.24
The next example involves three covariates.
Example 8.2 
. Consider the LE data again, with the same covariate High as before 
and two more covariates: Met, taking the value 1 if there was metastasis found in 
any examined nodes and 0 otherwise; and Age, the patient’s age in years as of 2003.
Using the subset of 1,210 patients with complete information on these three 
covariates, we represent the data as
{(y,. Highi, Met,. Agei) : i = 1,..., 1210}.
With .r, = (1. Highj. Met,. Ада)' and following expression (8.1), the data are mod­
eled as conditionally independent Bernoulli observations У, | Xi.O, ~ Ber(0,). with
logit (fa) = fa + Highi + Meti 32 + Agei fa = x',3 
(8.3)
where 3 = (30.........33)'.
It is often useful in regression problems to standardize (center and scale) con­
tinuous eovariatcs to improve interpretation and computational performance. Here 

Binary Response Regression 
219
we standardize the covariate Age by subtracting the mean age (72.7 years) in the 
data and dividing by the sample standard deviation of ages (5.6 years), defining a 
new variable sAge = (Age - 72.7)/5.6 for the standardized Age. Now the model is
logit(0j) = 5o + Highi 3\ + Met, 3-2 + sAge, 3^. 
(8.4)
While this model for the data is equivalent to the model in equation (8.3), the 
meanings of the starred first and fourth 5s are different. The intercept's inter­
pretation changes because of centering and the regression coefficient for the age 
variables is different, because of the change in units of age from 1 year to 5.6 years. 
In particular. 5o has the awkward interpretation that a woman of age zero (and 
High = 0,Met = 0) has LE probability logit-1(5o), while logit_1(3(*)  is the prob­
ability of LE for a woman of average age (here 72.7 years) with High = 0 and 
Met = 0.
Now let us look at the regression coefficients 5з and /?з- In (8.3), the odds ratio 
comparing the odds of LE for a woman who is a + 1 years old to the odds of 
LE for a woman who is a years old (other covariates being equal for the two) is 
е(а+1)0з/еа0з = е0з a neat fact js that this odds ratio is free of a. Now the effect of 
a single year in age on the odds of LE might be less useful to report than, perhaps, 
the effect of a five-year difference. In this case, we get the odds ratio e5/9a. In (8.4), 
e0* is the ratio of LE odds for a woman one standard unit above the mean age (or 
above any other age a) to a woman who is of average age (or age a). In years, these 
two women would be 5.6 years apart in age.
One can go back and forth between the 0s and the 0*s
 using the relationships
03 = 0o = 0o ~ “■&
*;
 0з = s03, 0o= 0o + m03.
where m and s, respectively, are the mean and standard deviation of the original 
variable. From here on, we will write models with standardized and unstandardized 
covariates using the same notation, namely, logit(#i) = х^0, with the understanding 
that coefficients must be interpreted appropriately as illustrated above.
For inference, we will mainly focus on the relative risks (RRs), odds ratios 
(ORs), risk differences (RDs), and the risks (fh) themselves rather than on the 0i, 
which are on a peculiar scale and thus are more difficult to interpret.
Results using flat priors on the 0s, standardized age, and code (available on 
the book’s webpage under Chapter 8 code in the file example8-2. txt) are given in 
Table 8.2. The inferential targets considered are:
Notation Interpretation
ORi 
e^1, odds ratio, high to low node exam count
OR2 
e02, odds ratio, with to without metastasis
OR3 
e03, odds ratio, standardized age aat + 1 to age aet
RR\ 
risk ratio, high to low node exam count
(age 72.7 years, Met = 1)

220
Bayesian Thinking in Biostatistics
RR.2 risk ratio, high to low node exam count
(age 72.7 years, Met = 0)
RR3 risk ratio, high to low node exam count 
(age 78.3 years, Met =1)
RR4 risk ratio, high to low node exam count 
(age 78.3 years, Met = 0)
Note: The sample mean age is 72.7 years, and the standard deviation is 5.6 years.
Observe that posterior means and medians are very similar, indicating that 
the posterior distributions are roughly symmetric. We, therefore, focus on means 
in our analysis. If they were noticeably different, we would focus on medians. The 
estimated OR\ is 3.80 with an interval that is far above 1. The posterior probability 
that OR\ > 1 is very close to 1. The interpretation is that the odds of LE for a 
woman with a high node count are estimated to be between about 2.5 and 5.5 
times greater than for a woman with a low node count, other covariate values being 
equal. Moreover, this interpretation remains the same regardless of the particular 
values of the other covariates, as long as they are equal for the two women in the 
comparison. This last property is a feature of odds ratios in the particular regression 
model we used. It is an additive (or no-interaction) logistic regression model. It leads 
to simplicity of interpretation but involves the no-interaction assumption. We also 
note that even in this case, relative risks do not have this property of being free of 
the other covariate values.
TABLE 8.2: Posterior summary for LE data using three covariates
Mean
sd
2.5%
Median
97.5%
ОЛ1
3.80
0.74
2.57
3.73
5.46
OR2
1.98
0.39
1.32
1.95
2.85
OR3
0.83
0.07
0.69
0.83
0.98
RRi
2.84
0.48
2.04
2.79
3.91
rr2
3.20
0.54
2.28
3.15
4.38
RR3
2.95
0.52
2.10
2.90
4.11
RR4
3.28
0.57
2.32
3.23
4.54
Turning to relative risks, RR\ = 2.84 is the estimated relative risk of LE com­
paring women with high node counts to women with low node counts (i.e., High = 1 
vs. High = 0) for women with a metastasis and of age 72.7 years. Comparing two 
women who are 78.3 years old and have a metastasis, the one who has a high 
count is estimated to be 2 95 (RR3) times as likely to acquire LE as the one with 
a low count. Similarly. RR2 = 3.20 involves the same type of comparison of two 
72.7-year-old women who did not have metastases; and RR4 = 3.28 involves the 
comparison of 78.3-year-old women who did not have metastases. First observe that 
none of these RR estimates is the same as ORi. although they are ail in the same 
direction. All estimate the "effect" of the number of nodes tested on the risk of 

Binary Response Regression
acquiring LE. each on its own terms. Since all intervals are considerably above 1. 
there is a strong indication that the number of nodes is strongly associated with 
the risk of acquiring LE, regardless of whether there was a metastasis or whether 
the woman was younger or older.
The estimated odds ratio OR2 = 1-98 estimates the effect of having a metastasis 
or not on the odds of LE, and similarly, the estimate OR3 = 0.83 estimates the 
effect of being 5.6 years older on the odds of LE. So. having a metastasis is posit­
ively associated, and being older in negatively associated, with acquiring LE. The 
posterior probability that OR2 > 1 is again effectively 1. and the corresponding 
probability that OR3 < 1 is 0.986. These last two probabilities are not shown in 
the table, but the code on the book webpage shows how these can be calculated. 
We could also obtain relative risks corresponding to these risk factors if we wished. 
All effects here are statistically important and appear to have practical import as 
well.
Table 8.3 gives estimates of the eight probabilities of LE corresponding to the 
eight combinations of the covariates: High (1 or 0), Met (1 or 0), Age (78.3 years or 
72.7 years). This table provides what are perhaps the most interesting outcomes of 
the analysis. We know we have statistically important predictors in the model. Now 
by simply looking at this table, we can see if those differences are practically mean­
ingful. Comparing high versus low node counts for older women with metastases, 
the estimates are 0.3 and 0.10. Not only do we know that the relative risk is about 
3, we also know the actual estimated probabilities of LE for these women with high 
counts and with low counts. These could be used in a large population of women to 
estimate, for instance, the added population-wide burden of examining more than 
five nodes. We can also see, looking at the same ratios across all combinations of 
presence of metastasis and age, that the relative risks are about 3. In addition, we 
can look at the effect of metastasis by comparing 0.30 to 0.18, 0.10 to 0.06, 0.34 
to 0.21, and 0.12 to 0.068. All the corresponding ratios are in a neighborhood of 
1.6. Similarly, we can look at the effect of age. The highest estimated probability 
of LE in the table, 0.34, is for a woman with a high count, with a metastasis, and 
who is younger. The lowest estimated probability, 0.06, is for a woman with a low 
number of examined nodes, no metastasis, and who is older. Recall that when we 
only considered the effect of the number of nodes (more than 5 vs. 5 or fewer) on 
LE, as in Example 8.1 and Table 8.1, the risk estimates were 0.26 versus 0.072. 
Clearly there is a more nuanced message to be told when adjusting for age and 
metastasis.
TABLE 8.3: Estimated probabilities of LE across High (1 or 0), Met (1 or 0), and 
Age (78.3 years or 72.7 years); posterior medians and 95% probability intervals
Age = 78.3
Age = 72.7
High
Met = 1
Met = 0
Met = 1
Met = 0
1
0
0.30 (0.23,0.38)
0.10 (0.07,0.16)
0.18 (0.14,0.23)
0.06 (0.04,0.08)
0.34 (0.28,0.41)
0.12 (0.08,0.18)
0.21 (0.17,0.26) 
0.068 (0.050,0.09)

222
Bayesian Thinking in Biostatistics
8.2 Logistic Regression Model with Interaction
While the logistic regression model as expressed in expression (8.1) is general enough 
to contain the models presented in this section, the notion of interaction was not 
included explicitly there and also not included in the examples. In fact, the models 
in those examples are additive logit models in which each predictive variable (e.g., 
age, metastasis, node count status) contributes only an additive piece to the logit of 
the probability being modeled. Possible effect modification is not allowed. However, 
this additivity assumption led to simpler interpretations. For instance, in Example 
8.2 the effect of metastasis, as measured by the odds ratio, is captured in a single 
odds ratio regardless of age. This may not be appropriate. If so, we can use the 
device of including an interaction term in the model discussed in Section 7.5 for 
linear regression. There, additivity (or its violation) was on the scale of the response 
means. Here, it is on the scale of logits of probabilities of an event. While conclusions 
about interactions on this scale often translate to the probability axis, this is not 
guaranteed (see the note at the end of Section 7.5). We turn to an example to 
illustrate interaction in the context of logistic regression.
Example 8.3. Trauma Data. Dr. Turner Osler, a trauma surgeon and former 
head of the Burn Unit at the University of New Mexico Trauma Center, provided 
data on survival of patients admitted to the Trauma Center between 1991 and 1994. 
The predictor variables are injury severity score (ISS), revised trauma score (RTS), 
age, and type of injury (TI). TI is either blunt (TI = 0, e.g., the result of a car 
crash), or penetrating (TI = 1, e.g., a gunshot or stab wound). The ISS is an overall 
index of a patient’s injuries based on the approximately 1,300 injuries catalogued 
in the Abbreviated Injury Scale. The ISS takes on values from 0 for a patient with 
no injuries to 75 for a patient with severe injuries in three or more body areas. The 
RTS is an index of physiologic status derived from the Glasgow Coma Scale. It is 
a weighted average of a number of measurements on an incoming patient, such as 
systolic blood pressure and respiratory rate. The RTS takes on values from 0 for a 
patient with no vital signs to 7.84 for a patient with normal vital signs. We used a 
randomly selected subset of 300 observations. Bedrick et al. [24], Christensen [76], 
and Christensen et al. [79] provide similar analyses to that given here. The data 
are contained in the file trauma.csv on the book’s website.
Dr. Osler proposed a logistic regression model to estimate the probability of 
a patient's death using an intercept; the predictors ISS, RTS, age, and TI; and 
an interaction between age and TI. Age is viewed as a surrogate for a patient’s 
physiologic reserve, that is. their ability to withstand trauma. With 0, standing 
tor the /th patient's probability of death given his or her covariate values and the 
regression coefficients, the model can be written as
logit(0,) = 30 + 3XISS, + 32KTSi + 33AGEi + в4ТЦ + 05(AGE x Т1\ (8.5) 
or. using the generic .r notation for covariates, as
logit (0,) - 3o + Jbr(1 + З2.г;2 + Лпз + 54х<4 + 55х,5, T15 = х,з.г,4.

Binary Response Regression 
223
So what is the point of including an interaction term in the model? It is to allow 
the possibility that the effect of the type of injury on the odds of dying (i.e., the 
difference in the logit of death for penetrating versus blunt injury) may depend on 
age. In fact. Dr. Osler anticipated that there will be little difference in risk by type 
of injury for older patients, because of their lack of "reserve.” For younger patients, 
on the other hand, this difference in the risk of death by injury type is expected to 
be substantial.
Including a regression term with a product of covariates as an added covariate 
is a means of allowing the effect of one covariate to depend on the level of another. 
But the added regression coefficient has a direct meaning only on the scale chosen 
for the response variable side of the regression equation. The effect difference, say 
d, in our example is
d = logit(Death | 0, ISS, RTS, TI = 1, AGE)
- 
logit(Death | 0, ISS, RTS, TI = 0, AGE)
= & + ft ISS + fa RTS + ft AGE + ft (1) + ft (1) x AGE
- ft + ft ISS + ft RTS + ft AGE + ft (0) + ft AGE
= fa AGE.
To interpret this more readily, we can convert this to the odds scale. In particular, 
the odds of “death” for a patient with a penetrating injury equal
g^o+^i ISS+02 RTS+fSi + ifls+fls) AGE
and for the same type of patient with a blunt injury the odds equal
e0o+0i ISS+02 RTS+03 AGE
Thus the odds ratio is e^
*
+^5 AGE = ed. The dependence of the effect of TI on age, 
as measured by the odds ratio, is now clearly expressed as a function of age. Of 
course, this odds ratio is ft if fa = 0, in which case the effect of TI does not depend 
on age. In the next section on inference, we discuss what the data tell us about this.
8.3 Inference for Regression Coefficients and Their Functions
As usual, to carry out inference we need to compute the posterior distribution for 
0 or, more usefully, obtain samples from this posterior. We do this by conveying 
the model and data to appropriate software, such as BUGS, JAGS, or Stan. Until we 
discuss informative priors in Section 8.4, we continue to use independent flat priors 
on components of the vector /3. Example code is provided on the book’s website.
The model is stated in terms of regression coefficients, so the posterior samples of 
these are generated by the Bayesian software you use. Inference for these is straight­
forward: make summaries, histograms, density plots, probability statements, etc.,

224
Bayesian Thinking in Biostatistics
TABLE 8.4: Trauma data: Posterior summaries with flat prior
Variable
Flat Prior
mean
sd
2.5%
median
97.5%
Intercept
-2.71
1.71
-6.04
-2.71
0.66
ISS
0.085
0.029
0.029
0.085
0.142
RTS
-0.60
0.18
-0.96
-0.59
-0.26
AGE
0.056
0.017
0.024
0.055
0.091
TI
1.41
1.42
-1.43
1.42
4.17
AGE x TI
-0.008
0.035
-0.081
-0.007
0.057
from the samples. As we have seen in the previous sections, these regression coeffi­
cients are generally less interesting in logistic regression, because they are on the log 
odds or logit scale. Nonetheless, sometimes it is important to address whether they 
are zero or not. If a 95% interval for a regression coefficient excludes zero, we can 
be at least 95% certain that the coefficient is either positive, or negative, depending 
on the placement of the interval. Suppose we find P(fij > c | data) = 0.95 for some 
positive c > 0. Then we can say that the corresponding variable Xj is statistically 
important. Because the phrase statistically significant has been used extensively to 
indicate a specific repeated-data frequency related to a “null hypothesis,” it is not 
appropriate to use that phrase in a Bayesian context.
Our probability statement is conditional on the data at hand. It does not refer 
to a frequency in conceptual replications of such data. It quantifies the updated 
certainty about fij in light of the data at hand, updating it from our initial (prior) 
certainty. Even so, we emphasize that a statistically important variable may have 
little practical import, the latter depending on the magnitude of c. Conversely, stat­
istical importance may not be achieved in light of a particular data set even when 
the variable may be of potentially practical importance. Typically, this happens 
when the data set does not contain sufficient information about fij, such as when 
the sample size is relatively small.
Example 8.4. Trauma Data (Example 8.3, Continued). Table 8.4 presents 
means, standard deviations, and percentiles of posterior samples of the fy of the 
trauma data model. When an interaction is included in the model, its statistical 
importance should be considered first. If it is important, the interpretation of coef­
ficients of covariates that constitute the interaction is substantially affected (as we 
saw in Section 7.5 for the linear model). On the other hand, these coefficients have 
simpler interpretations if the interaction is judged not statistically important. In 
Table 8.4. the interval for the TI x AGE interaction coefficient includes 0, so the 
interaction is judged not statistically important. In other words, the effect of TI, if 
any, does not appear to depend on age.
The coefficient of TI can now be interpreted directly from the row for TI in 
Table 8.4. We see that 0 is well within the 95% interval. Type of injury does not 
appear to affect the probability of death. As for RTS, low values are bad for the 

Binary Response Regression
patient, so the tendency of the RTS coefficient to be negative is reasonable. The 
95% probability interval for this coefficient is entirely below zero, so RTS is counted 
as a statistically important variable. Similarly, the intervals for ISS and AGE 
are entirely above 0, so they are also statistically important predictors of death. 
Higher RTS is associated with smaller probabilities, and higher ISS and AGE are 
associated with larger probabilities.
It would be possible now to consider reducing the number of terms in the model 
by removing TI and AGExTI. Such decisions can be guided by methods introduced 
in Chapter 10. Here we choose not to do that, keeping all variables suggested by 
Dr. Osler in the model. For more discussion of this interaction, see Example 8.10.
8.3.1 Inference for Lethal Dose о
An interesting target of inference has its origins in the field of toxicology where 
logistic regression was used in its early days. It involves the dose of an insecti­
cide at which a specified percentage of an insect population would be killed. This 
percentile relating to the lethality of the chemical to 100o% of the population is 
called the LDQ for lethal dose in bioassay problems. In general, the dose at which 
100o% of subjects would have some form of event is of interest. For example, a 
pharmaceutical company might be interested to know the dose of a drug at which 
a certain percentage of a population of patients, perhaps 95%, would be cured. In 
this context, such a dose would be denoted ED95 for effective dose] we denote it 
EDq, a = 0.95.
EDq is obtained by solving a = P{Event | 
= logit-1 (^o + ^a^i) for
dose da- This means logit(a) = /30 + da0\ so that da = {logit(a) - /30 }/Z?i. If A is 
near zero, posterior samples of dQ can be highly variable and unstable. Summaries 
of the posterior distribution should be based on percentiles, such as the median and 
quartiles, not the mean and standard deviation. Of course, if fa is small, the drug 
or insecticide does not much affect the probability of the event and is not of much 
interest to the scientist, nor is EDQ.
Example 8.5. Snake Bite Data. Parveen et al. (2017) [257] studied the effect 
on survival of mice after injection with different types of snake venom. We consider 
their data involving the saw-scaled viper. Four distinct doses were applied to eight 
rats each. The doses were (32, 16, 8, 4) fig. To stabilize the analysis, we standardized 
dose by subtracting 8 and dividing by 4. So, sDose = {Dose — 8)/4, and the 
observed standardized doses were (6,2,0, —1). The observed binomial death counts 
were (j/i = 8,y2 = 5, уз = 3,т/4 = 0), each out of 8 mice. Coding this as a logistic 
regression model for binomial data with “flat” priors (code on the book’s website 
under Chapter 8 in the file example8-5.txt), we obtained posterior samples of 
fa and fa. From each such sample, we then calculated, in addition to LDq.s» the 
probabilities of death (denoted p[l],p[2],p[3],p[4]) at the experimental dose levels 
{sDose = 6,2,0, —1), respectively. Results are shown in Table 8.5.
The estimated probabilities of death are (0.91,0.77,0.10,0.007) for doses 
(32,16,8,4), respectively, based on the medians of the MCMC samples. The esti­
mated LDo.5 is sDose = 1.19, which corresponds to a dose od 8+4 x 1.18 = 12.7 /zg;

226
Bayesian Thinking in Biostatistics
Percentiles 
2.5% 50% 97.5%
TABLE 8.5: Snake bite data: Posterior summaries
LDo.5
0.27
1.19
2.31
p[l]
0.70
0.91
0.98
P[2]
0.56
0.77
0.92
p[3]
0.10
0.31
0.56
p[4]
0.0001
0.007
0.118
we are 95% certain that it is in the interval (8 + 4 x 0.027, 8 + 4 x 2.31) = 
(9.1, 17.2) pg, which is quite wide. More dose values and larger numbers of mice 
would be required to have better precision.
8.4 Prior Distributions
Thus far in this chapter we have used flat priors on regression coefficients. It is 
not a practice we recommend. We used flat priors only as a device to postpone 
discussion of priors and focus on different aspects of the logistic regression model 
and to demonstrate the types of inference possible. We now turn to more appro­
priate priors, informative as well as low-information omnibus priors that work well 
when context-specific prior information is not available or one wishes to keep such 
information out of the analysis in an attempt to “let the data speak for themselves.”
8.4.1 Conditional Means Priors
As was pointed out in the linear regression case in Section 7.3.3.1, regression para­
meters are difficult targets for direct quantification of prior information. So we 
again turn to the conditional expectation of the observable Y | x for some chosen 
covariate vectors x that are convenient for elicitation of prior information. For bi­
nary regression, Y has the Bernoulli distribution so Е(У|х) = P(Y = l|rr). This is 
much more meaningful to subject-matter experts than the regression coefficients. 
The prior information specified for these conditional means is then induced on the 
regression parameters. The development parallels that in Section 7.3.3.1. We first 
illustrate with a simple example, then state the method in general, followed by 
another example.
Example 8.6. Conditional Means Priors for Lymphedema Data. In Ex­
ample 5.2 we considered the LE data with one covariate. In particular, although 
we were dealing with data on 1.211 women, we considered it as a grouped logistic 

Binary Response Regression 
227
regression analysis with only two binomial observations. Specifically, we had
Yi\0i. Hight Bin(ni.Oi)' logit(0t) = 30 + 3iHight, i = 1.2.
with zi! = 734. П2 = 477 as known constants that correspond to subscript i - 1 
for the High = 0 (i.e., the low count) group (see Table 5.1). Here, we take the 
informative prior from Example 5.2 to induce an informative prior for 3. Recall 
that available information in the literature on LE rates after surgical treatment of 
breast cancer led to representing this knowledge by a Bc(2.044.13.006) distribution 
for the probability of LE without knowing the number of nodes examined. Desiring a 
priori not to enforce a particular direction for this probability (increase or decrease) 
with the number of nodes examined, we take identical independent priors for both 
0i-
0i Be(2.044, 13.006), i = 1,2.
Since logit(6?i) = Po and logit(02) = Z?o + Z?i, we must have Po = logit (0J and 
Pi = logit(#2) ~fa- To “see” the prior on the Pi, we can take advantage of a 
feature of most Bayesian MCMC software (e.g., BUGS, JAGS, Stan) that allows us 
to simulate from a prior (i.e., without data). We can then transform the simulated 
values. In fact, in the analysis code itself we can include these steps to define 
the prior for the transformed parameters (see Example 8.7 below). For simulating 
the prior, see the BUGS code on the book’s website under Chapter 8 in the file 
example8-6.txt. The corresponding R code is also in this file.
Running such code and summarizing the samples, we find that the induced 
prior on Po has median and 95% probability interval —2.00 (-3.96,-0.65), and 
the prior on Pi has median and 95% interval 0.0036 (—2.36,2.35). Observe that 
the prior inference for “slope” (or effect size Pi) is neutral in terms of whether the 
slope might be positive or negative, as we wanted. The two Ps are also correlated in 
the induced joint prior as expected. Interestingly, Pi has an approximately normal 
distribution with mean 0 and a standard deviation about 1.2. The analysis involving 
the two probabilities will be identical, up to Monte Carlo error, to the analysis that 
was performed in Example 5.2.
The induced prior construction in the above example can be stated in general 
similar to the discussion in the linear regression case (see Section 7.3.3.1). As there, 
we begin with a (p+ 1) x (p + 1) matrix X with rows corresponding to (p + 1) 
covariate vectors chosen for convenience in eliciting prior and such that X is of full 
rank. Then we equate XP to a vector, 0,, whose ith component is logit(0,) where 
0; = P(Yi = 1 I x'p for i = l,...,p+- 1. Since в is more directly interpretable 
than P, we elicit a prior on 0 that induces a prior on P = X-1logit(0), with the 
logit function applied componentwise to 0. Typically we take independent Be(a,, 
priors on 0,. As in Chapter 7, rows of X should be chosen so that the independence 
of priors on the components of 0 is reasonable.
Reframing Example 8.6, let logit(0~i) = Po and logit(02) = Po + Pi- We thus 
have logit(0,) = x^P, with x\ = (1,0) and x2 = (1,1)- So
-Ч !)■ 
!)■ ftW-'CS»

228
Bayesian Thinking in Biostatistics
TABLE 8.6: Trauma data: prior specification
j
Design for prior 
x'
Be(aj,bj)
Prior median
a.j
bj
1
1 25 7.84 60 0 0
1.1
8.5
0.09
2
1 25 3.34 10 0 0
3.0
11.0
0.20
3
1 41 3.34 60 1 60
5.9
1.7
0.80
4
1 41 7.84 10 1 10
1.3
12.0
0.07
5
1 33 5.74 35 0 0
1.1
4.9
0.15
6
1 33 5.74 35 1 35
1.5
5.5
0.19
The solution, as before, is fa = logit(0i) and fa = logit(fa) — fa- We now illustrate 
the CMP with p = 5 predictors so that is a six-dimensional vector, including the 
intercept.
Example 8.7. Trauma Data. For these data as analyzed in Example 8.3, p +1 = 
6. To induce a CMP on /3, we require a joint distribution on death probabilities 
for six sets of conditions x' = (l,ISSj,RTSj, AGEj,TIj, AGEj x TIj). We now 
describe the process that led to the selected covariate conditions and the resulting 
informative priors on в listed in Table 8.6.
With four distinct predictor variables, our expert Dr. Osler selected four “com­
fortable” covariate combinations. The idea was to select values of the variables that 
were sufficiently different within the data range but still had substantial probabil­
ities for both success and failure. Dr. Osler had relatively little difficulty specifying 
priors for these first four combinations in Table 8.6. The first setting for eliciting 
fa corresponds to an individual who “has good physiology, is ‘not badly hurt,’ does 
not have a lot of reserve,” and for whom there is “added uncertainty due to age.” 
Following elicitation methods for a prior on a probability that were detailed in Sec­
tion 5.1.1.2, and using the key values supplied by Dr. Osler, we determined that 
the Be(l.l,8.5) distribution suitably reflects his uncertainty about fa. The median 
of his prior is around 0.09. The second type of individual “has bad physiology, is 
very ill, but is young and resilient and is not so badly hurt.” The prior for fa is 
Be(3,11), with median around 0.20. Incidentally, “bad physiology” and “very ill” 
refer to poor RTS scores, while how badly hurt one is relates to ISS. The third 
individual has “bad physiology, a pretty bad injury, and there is much more un­
certainty here due to the age factor.” The prior is Be(5.9,1.7) with median around 
0.8. Prior individual four “is young, resilient, and has a big injury.” The prior is 
Bc(1.3. 12) with a median of around 0.07.
Since our logistic regression model in Example 8.3 also included an intercept 
and an interaction, we needed p + 1 = 6 combinations to specify a full prior. The 
last two rows were constructed to keep A' non-singular and satisfy some design 
principles (beyond the scope of this book) by the authors of [23. 24]. Admittedly, 
Dr. Osler had more difficulty with these fifth and sixth types of individuals, because

Binary Response Regression
229
TABLE 8.7: Trauma data: posterior summaries with informative prior
Variable
Informative prior
mean
sd
2.5% median
97.5%
Intercept
-1.76
1.15
-4.00
-1.76
0.49
ISS
0.065
0.021
0.024
0.065
0.106
RTS
-0.60
0.15
-0.90
-0.60
-0.33
AGE
0.047
0.014
0.021
0.047
0.075
TI
1.10
1.09
-1.23
1.10
3.24
AGE x TI
-0.017
0.028
-0.072
-0.016
0.037
their conditions were less extreme than those already considered, and, presumably, 
because he did not select them. Nonetheless, the resulting priors for 65 and fa are, 
respectively, Be(l.1,4.9) with median 0.15, and Be(1.5,5.5) with median 0.19.
Since inducing these priors shown in Table 8.6 onto the regression coefficients 
requires inverting a matrix, we provide a combination of R and BUGS or JAGS code 
on the book’s website under Chapter 8 in the file example8-7.txt. The process 
consists of converting the data in Table 8.6 to the object Xtilde, converting it 
to a 6 x 6 matrix, and inverting it, all in R. This inverse is then read into BUGS 
by a somewhat manual process by printing and copying. Running the BUGS code 
generated the results in Table 8.7.
Comparing these results in Table 8.7 with flat-prior results in Table 8.4, we see 
that they are qualitatively the same. However, intervals in Table 8.7 for ISS, RTS, 
and AGE are more narrow than they were in Table 8.4. The estimated coefficient 
for the interaction is a bit more negative than before but is still not statistically 
important. We discuss this further in Example 8.10.
8.4.2 Partial Prior Information
As we saw in Chapter 7, specifying a prior distribution for a regression model 
with several predictor variables can be daunting. For logistic regression, priors that 
are partially CMP and partially diffuse follow in much the same way as for linear 
regression in Chapter 7. There are two cases: (i) we can specify p + 1 linearly 
independent covariate vectors x but can get priors on 0s elicited for only r < p + 1 
vectors; or (ii) p + 1 is too large to even consider specifying that many conditions, 
so we settle for r < p xs. Strategies in these two cases and their examples follow.
In case (i) we put informative priors on some fa and flat £7(0,1) or Jeffreys 
invariant Be(0.5,0.5) priors on the rest. The approach is presented and justified in 
Christensen et al. [79].
In case (ii), specifying fewer than r < p vectors, we choose the {xj : j = 
l,...,r} so that the corresponding 0j only induce information on a subset of r 
regression coefficients. We accomplish this by choosing the ij so that the predictor 
variables associated with the remaining p — r coefficients are fixed at the same 
values, often 0 for standardized continuous covariates (standardization as discussed

230 
Bayesian Thinking in Biostatistics
TABLE 8.8: Trauma data: partial prior specification with standardized ISS, RTS, 
and AGE
Design for prior
Be{aj,bj)
ai 
bi
Prior mode
1
2
3
1 0 0 0 0 0
1 1 0 0 0 0
1 1 -2 0 0 0
2.06 21.2
2.70 10.66
1.9 
3.7
0.05
0.15
0.25
in Section 7.1.4) and at a reference category, 0, for categorical covariates. We then 
place independent appropriate 7V(0, b) priors on the corresponding p — г regression 
coefficients. The choice b = 1 provides a relatively diffuse prior for coefficients of 
categorical as well as standardized continuous covariates.
Example 8.8. Grouped LE Data. Assume that P(LE | High = 0) = 
~
Be(2.044,13.006), but that there is now no information for P(LE | High = 1) = 
02- As in Example 8.6, /?o = logit^), so the informative prior on induces an 
informative prior on /?o- The other regression parameter is /?i = logit(#2) — 3o- 
At this point, we have two choices. Our preference is for a reference prior on the 
probability 0i, such as a uniform or Jeffreys prior. This induces a diffuse prior on 31. 
Alternatively, we can put a flat or large-variance, mean-zero normal prior directly 
on /?i. The latter type of choice will be much simpler when p is large, since then we 
do not have to specify so many appropriate ii vectors.
Example 8.9. Trauma Data. We use the model from Example 8.3, but now 
with standardized covariates (see Section 7.1.4). We will assume that our expert 
was only willing to specify three Xj and three corresponding probabilities. We take 
as “baseline” conditions a patient who has the average values (mean(ZSS) = 14.3, 
mean(/?TS) = 7.29. and mean(AGE) = 31.4, these corresponding to 0s on the stan­
dardized covariates) and has a blunt injury (meanTZ = 0). Let = (1,0,0,0,0,0) 
correspond to the baseline patient. This i'i implies that logit(#i) = /3q. Next, 
lot 
= (1,1,0,0,0,0). which corresponds to a baseline patient except with
an ISS score that is one standard deviation above the mean. From £2 we have 
logit(02) = /?о + в\. Finally, let X3 = (1,1,-2,0.0,0), which corresponds to a hy­
pothetical patient who is the same as the second patient except that this patient’s 
RTS is two standard deviations below the mean. Then logit(0a) = /3O + /31 -2/32- We 
place independent £?e(o,. 5,) priors on these parameters with (ai,bi) given in Table 
8.8. along with the prior modes for each probability. These choices were made by 
the authors based in the information that was provided by Dr. Osler for the six 
probabilities of death discussed earlier.
Clearly, the prior information involves only 3q. 3i, and /32- More importantly, 
since AGE. TI. and AGE xTI never varied from their baseline values, it is rea­
sonable to treat the information on 30. and 32 as independent of З3, /34, and 3$. 
These parameters only affect how probabilities change as AGE. TI. and AGE x TI 

Binary Response Regression
231
change from the baseline case. Finally, we complete the prior by taking independent 
0j ~ b) with large b ~ 1 for j = 4,5.6.
8.4.3 Low-Information Omnibus Priors
We consider the ability of Bayesian analysis to include all available information, 
suitably quantified via informative priors, to be the central feature of this approach 
to statistical inference and prediction. While we have emphasized this throughout 
the book, there are situations when such inclusion of information external to the 
data is not feasible. Resource availability is often the limitation. In biostatistical 
practice, it is often desirable to keep the external information away from t he analysis 
to convince those who may not agree with its value or to carry out a ‘‘what if” 
analysis. Bayesian researchers pursuing so-called objective priors have long sought 
to create coherent analyses without any (or much) extra-data information. We 
have already come across such priors, namely, flat, reference, information invariant 
(Jeffreys), and approximately flat. Most of these are improper priors and should be 
used with care, as we have pointed out.
Here, we describe proper priors that are designed to be of weak or low informa­
tion and work well in almost any data situation in practice. Gelman et al. [136] 
introduced such priors for logistic regression with the following observations: “We 
recommend this prior distribution as a default choice for routine applied use. It has 
the advantage of always giving answers, even when there is complete separation 
in logistic regression (a common problem, even when the sample size is large and 
the number of predictors is small), and also automatically applying more shrinkage 
to higher-order interactions. This can be useful in routine data analysis as well 
as in automated procedures such as chained equations for missing-data imputa­
tion.” Recently, Shi et al. [296], using a similar viewpoint, constructed what they 
termed “low-information omnibus” (LIO) priors for a popular Bayesian nonpara­
metric model. In their words: “Gelman et al. (2008) suggested specific scaling and 
a low information prior that is ‘vague enough to be used as a default in routine ap­
plied work’ instead of aiming for a no-information prior. The latter pursuit can be 
challenging both theoretically and computationally.” We now summarize Gelman’s 
LIO prior for logistic regression.
The prior requires standardization of predictor variables in a specific manner. 
Binary variables are centered to have a mean 0 and to differ by “1” in their lower 
and upper levels. If the two levels are originally coded as 0 and 1, simply subtracting 
the mean achieves the required standardization. Continuous variables are centered 
to have a mean 0 and standard deviation 0.5. Subtracting the original mean and 
dividing by twice the standard deviation meets the requirement. The motivation for 
this standardization is to better align the continuous covariate case with the binary 
one (which has a range of 1), so that the same prior specification (see below) can 
work for regression coefficients of both types of covariates.
With this standardization, independent Cauchy priors are used for fa,..., 0P. 
For fa, the prior has median 0 and scale 10. The prior for each of 0\,... ,0P has 
median 0 and scale 2.5. Some Bayesian model specification software may not offer 

232
Bayesian Thinking in Biostatistics
the Cauchy distribution as a choice. One can use a combination of normal and 
gamma, or the ^-distribution to circumvent this. In particular (and in notational 
agreement with BUGS),
£o I 
r~Ga(0.5,50) or £0 ~ St(0,0.01,1)
and
fa | т ~ No(Q, т), т ~ Ga(0.5,3.125) or ft ~ St(0,0.16,1)
are alternate specifications that result in the appropriate Cauchy marginals for the 
08. 
_
This prior assigns approximately 0.7 probability to odds ratios between e-5 and 
e5 150 for one standard deviation unit change in any predictor. This wide spread 
easily covers almost any practical situation. Any covariate effects greater than these 
70% limits would be dramatically obvious from the scientific point of view, perhaps 
without the need for statistical models. Nonetheless, use of the Cauchy distribution 
allows for occasionally extreme values too. At the mean setting for all predictors, 
the success odds are between 10-9 and 109 with approximate probability 0.7. These 
choices align with the intended low-information nature of the prior while maintain­
ing good Markov chain convergence and numerical stability for almost any practical 
application in biostatistics.
8.5 Prediction
In the context of logistic regression, we are interested in predicting binary outcomes, 
so the focus is on a probability for a certain type of patient. For example, what is 
the probability that a cancer patient will survive 5 years after diagnosis given the 
patient’s characteristics as measured by the covariates and the data we analyzed? 
Or what is the probability that a treatment will be effective, conditioned on the data 
and the patient’s covariates? Given our data and analysis, what is the probability 
that a particular patient who has been admitted to the emergency department will 
survive?
We have denoted logistic regression data by {(j/», Xi) : г = 1,..., n}, where yi is 
an indicator of an event. In the sampling model, the predictive probability of the 
event for a new patient with known covariate vector if is
f ex'f&
P(Yf = 1 | data) = J 
p(3 | data) d3.
1 he Monte Carlo approximation with a random sample ..., from the 
posterior distribution of 3 is
= 1 | x/.data) = - £ — 
a<.,. 
(8.6)

Binary Response Regression
a Age = 60 and Rts = 3.34
FIGURE 8.1: Trauma data: predictive probabilities of death.
ISS
As in other prediction formulas we have encountered before, equation (8.6) 
has a direct interpretation as the predictive probability that the next trial will 
be a success, without reference to the regression coefficients, as they have been 
integrated out. It also has a secondary interpretation as the posterior mean of 
the parameter, exf0/(l + exf0), which is the proportion of future patients that we 
expect to have the event. With the second interpretation, one may be interested in 
interval estimates. A 95% probability interval, say, is approximated by finding the 
appropriate percentiles of {(e®/^)/(1 + e®/^°’) : j = 1,..., M}.
Example 8.10. Trauma Data (Examples 8.3 and 8.7, Continued). We re­
turn to our discussion of the trauma data where the outcome is death, and the 
covariates in our analysis are injury severity score (ISS), revised trauma score 
(RTS), age of the patient (AGE), and type of injury (77). Using the posterior 
samples from our informative prior analysis from Table 8.7, we computed (with 
equation (8.6)) predictive probabilities of death for various specifications of Xf. 
Figure 8.1 presents predictive probabilities of death as a function of ISS for blunt 
and penetrating injuries. The four graphs are for two values each of RTS and AGE. 
The general effect of ISS is obvious, as the probability of death increases dramat­
ically with increasing values, regardless of the values of RTS and AGE. The effect 
of RTS is observed by comparing top plots to bottom plots in each column, and 
the effect of AGE is noted by comparing row plots from left to right. There are 
clear and dramatic effects for all three of these predictors, a visual confirmation of 
the results in Table 8.7.
Also note that for 60-year-old individuals, there is essentially no difference in the 
probability of death due to blunt or penetrating injury, while for 10-year-olds, the 

234
Bayesian Thinking in Biostatistics
probability of death is higher for a penetrating injury than for an blunt injury type. 
Thus, the effect of TI, as reflected by the difference in plots of predictive probabilit­
ies of death for penetrating and blunt injuries, appears to depend on AGE. In Table 
8.7, however, the regression coefficient for the AGE x TI interaction was not seen 
to be statistically different from 0. It is important to recognize that interaction in 
the logistic regression model speaks to non-additivity of the log odds, but the plots 
in Figure 8.1 are on the probability scale. In addition, the figure does not show any 
uncertainty measure, such as posterior probability intervals. Nonetheless, including 
the interaction (cross-product) term allows for quantifying what is termed “effect 
modification” in the epidemiology literature. If the interaction term were left out, 
the model would dictate that whatever effect TI might have would be the same 
regardless of the value of AGE. Similarly, the effect of age on the risk of death 
would be the same for each TI type.
Careful inspection of Figure 8.1 allows us to visualize the statistically important 
effects of RTS, ISS, and AGE in terms of probabilities. It also allows us to ascertain 
whether these effects are of practical import (they clearly are), and whether there 
is any potential practical importance for the variable TI. It appears to us that 
indeed there is, but the importance may differ by age. TI affects the probability of 
death for a younger patient, but clearly not for an older one. It is this difference in 
potential effect that is so effectively portrayed in this figure.
It is important here to point out that the interaction effect may be due to the 
influence of the prior specification by Dr. Osler. We prefer to include the interaction 
in the model, in part since it nicely illustrates the concept of effect modification. In 
addition, it illustrates a situation where scientific judgment is needed, perhaps with 
additional data, to determine if this interaction is statistically and scientifically 
important.
8.6 
Alternatives to Logistic Regression: Other Link Functions
The logistic regression model is actually a special case within a general class of 
models for binary regression. With data t/, | Xi,0 ~ Вег(вх), independent for 
each ?. we can generalize the logistic regression model by considering other possible 
ways to specify 6X = P(Y = 1 | x,0). The logistic regression model specifies this 
as 0r = ( x 
+ ex й) = expit(.r'/3). Restricting to linear functions of 0, we can
look for other functions of the linear combination x'0 that could work. The main 
requirement for such a function is that вх be a probability (i.e., between 0 and 1) 
with domain (-oc.oc). We also want it to be an increasing function for simplicity 
in interpreting the regression relationship. The above expit function is actually the 
rdf of the logistic distribution. F(ir) = eu'/(l +eu’). -oo < w < oo. This indicates 
that for any cdf corresponding to a random variable with support (—oo, oo), we can 
specify a new binary regression model.
Here we only consider two alternative choices for F(-). First, consider the natural 
choice. F(ir) = Ф(<с). where Ф( ) is the standard normal cdf. Second, consider 

Binary Response Regression
235
the choice F(w) = 1 — e_®u which is the cdf of what is called the extreme-value 
distribution. So the general form for such models is вх = F(j-'3). In the theory of 
generalized linear models, which we have not discussed up to now. the relationship 
is described in the reverse form
F-1(0) = x'fi, so that F(x'3) = вх = P(Y = 1 | a-. 3).
The model is described as having as link function F-1. since this is the function 
that links the probability of an event to the linear form x'J.
Thus when we solve for x'0 in terms of в, we have logit (0) = x'3 when we use 
the logistic cdf; we have Ф-1(0) = x'p in the case of the normal cdf: and we have 
log(-log(l - 0)) = x'0 for the extreme-value cdf. Those three link functions are 
called logit, probit, and complementary log-log, respectively.
The reason why the logit link is preferred in applications over the others is that 
it is the only link function for which the odds ratio simplifies interpretation. In 
particular, with one covariate in a model, the odds ratio for the response is e^1 for 
predictor value x 4-1 versus x, regardless of the particular value of x. With other 
links, the odds ratio is a complicated function of the covariate, and does not 
have a simple interpretation. Moreover, there is no other simple way to describe 
how the probability at covariate value x 4-1 relates to the probability when the 
covariate value is x such that the description is free of x.
We discuss link functions and generalized linear models further in Chapter 9. 
In Chapter 10, we discuss the choice of link function based on certain criteria. Of 
course, simple interpretation is not a great excuse for the choice of the logit link 
if one of the other models provides a better fit to the data or, more importantly, 
better predictions.
In general, with a link function F-1 (i.e., with 0, = F(z</3)), we have the model
Yi |хй0/~ В er (di), i = l,...,n.
The sampling distribution (likelihood function) is
Lik(0) a p(y | X, 0) = [рЛаЭДН! - F( W’' • 
i=l
For Bayesian analysis, these models are fit and estimated in much the same manner 
as with the logistic regression model. Software we have referenced throughout the 
book (BUGS, JAGS, and Stan) can accommodate different link functions very nicely. 
For example, if one wants to carry out probit regression in BUGS, one simply 
specifies Ф as PHI. For the complementary log-log model, one must specify the 
extreme-value cdf directly using the exponential function. The rest of the code 
for these alternatives is identical to that for logistic regression to obtain posterior 
samples of /3. Processing these samples for suitable inference targets (functions of 
j0) is, however, distinct for each link function.
Finally, we need to comment on the important topic of priors. One choice is to 
simply use an improper flat prior. Another is to use a CMP or a partially informative 

236
Bayesian Thinking in Biostatistics
version of it. A nice feature of the CMP is that the scientific information is elicited 
for event probabilities no matter which link function is being used. The induction 
of the prior information onto the regression coefficients is different due to solving 
different equations for 0 in terms of 0x. This is straightforward to do, however. In 
the case of a flat prior, using it for regression coefficients with one link function is not 
the same as a flat prior for the coefficients with another link function. So there are 
issues with comparing models with different links, due to lack of comparability in 
the prior specifications. The LIO prior, too, is not the same as for logistic regression. 
It requires separate development for each link function.
8.7 Recap and Readings
Binary regression is one of the more important topics in biostatistics. We have 
attempted to provide a fully Bayesian approach that allows for the use of inform­
ative priors through collaboration of scientists and statisticians. Since the sample 
sizes for our main two illustrations were quite large, external information was less 
important than it would have been with smaller sample sizes. We have also emphas­
ized the importance of attempting to provide sensible diffuse priors on regression 
coefficients. Placing uniform priors on probabilities to induce diffuse priors on 0 
can be reasonable, provided there really is no information about event probabilities 
of interest, which is seldom the case. When prior information about one or more 
event probabilities is available, we recommend a partial prior that induces scien­
tific information onto some of the components of 0. We encourage looking at the 
induced prior on event probabilities for any choice of diffuse prior on 0 to make 
sure that misinformation or disinformation is not being conveyed.
Since logistic regression models logits, it is particularly useful to summarize pos­
terior inference in terms of probabilities that are more readily interpreted. Presence 
or absence of interactions is readily understood for linear regression but, as we saw 
in the section on prediction, it is more subtle for logistic regression. Transform­
ing inference to understandable targets is important in practice, and this requires 
special attention when more complex models are used.
We discuss link functions and generalized linear models again in Section 9.3, 
where we provide some of the theory of these models. McCullagh and Nelder [239] 
provided the first complete development of generalized linear models (GLMs), al­
beit from a non-Bayesian perspective. Ibrahim and Laud showed why Jeffreys priors 
are better than uniform priors for the coefficients in GLMs [172]. Zeger and Karim 
[359] applied Gibbs sampling to carry out inference in GLMs that include random 
eHerts by capitalizing on the similarity with Bayesian models. Other notable pub­
lications expanded the use of MCMC algorithms for inference in Bayesian GLMs, 
such as Dellaportas and Smith [93] and Gamerman [119]. Dey. Ghosh, and Mallick 
published an edited volume that discusses carrying out Bayesian inference with 
generalized linear models [96].

Binary Response Regression
8.8 Exercises
Exercise 8.1. Refer to the LE data and analysis in Example 8.1 using a logistic 
regression model and the flat prior, with results given in Table 8.1. Recall that 
and 02 were probabilities of LE corresponding to high- and low-count groups, 
respectively, and that the model specified logit(02) = 3o and logit(0i) = 30 + Л.
(a) 
Using the flat prior, write code to reproduce the results in Table 8.1. Be sure 
to be careful about convergence. Comment.
(b) 
Now analyze the data using a CMP prior on the 3s induced by iid 
Be(2.044,13.006) priors on probabilities #i and 02 for the high- and low-count 
groups, respectively. Comment on the information conveyed by the priors. Then 
compare results of your analysis with your results in part (a).
(c) 
Now use a partially informative prior by using the prior information about 02 
in part (b), and a [7(0,1) prior on 0j. Compare results again.
(d) 
Now use a different partially informative prior by using the prior information 
about 02 in part (b) and an improper uniform prior on . Compare results again.
(e) 
Finally, use a low-information omnibus prior on /3. Compare results again.
Exercise 8.2. Refer to Example 8.2. Let 0i = P(LE | High = 0, Met = 
0,sAge = 0), 02 = P(LE | High = l,Met = 0,sAge = 0), O3 = P(LE | High = 
0, Met = 1, sAge = 0), O4 = P(LE | High = 0, Met = 0, sAge = 1).
(a) 
Using a flat prior, provide a table of posterior inferences for all regression coef­
ficients as well as the odds ratios given in Table 8.2. Be sure to check convergence 
of chains. Discuss.
(b) 
Now regard the covariate combinations in the probability specifications as i;. 
Write down the corresponding matrix X. Is it non-singular? Solve for each /?i in 
terms of the 0t. Then write this in matrix form using X. Find the explicit solution 
by simply solving four equations in four unknowns. Then solve using the matrix 
formulation. Observe that you get the same results.
(c) 
Write a program to analyze the data using the implied CMP prior that uses 
the predictor combinations discussed in part (b) and that has independent uniform 
priors on the 0i- Provide a table of posterior inferences for all regression coefficients 
as well as the odds ratios given in Table 8.2. Compare results with those in part 
(a). Be sure to check convergence of chains. Discuss.
Exercise 8.3. In Example 8.2, we considered the LE data with three covari­
ates: High (0/1), Met (0/1), and sAge (standardized age). There were p 4- 1 = 4 
regression coefficients and we used flat priors on the 3-
(a) 
Consider specifying independent beta priors on the two probabilities of LE 
corresponding to = (1,1,0,0) and x2 = (1,0,0,0). Define corresponding probab­
ilities of LE, 02 and 61, respectively. Use the independent priors specified in Exercise 
8.1(b) for these and flat priors for the remaining coefficients. Analyze the data.

238 
Bayesian Thinking in Biostatistics
(b) 
With 0i, 02, and priors for these as in part (a), use independent N(0,1) priors 
on coefficients of standardized versions of the remaining covariates. Analyze the 
data and compare the results with those obtained in part (a). This situation is in 
the framework of Section 8.4.2.
(c) 
Now extend the partial prior to a full CMP for all four regression coefficients. 
Select two more is appropriately to obtain X. Then solve for (3 algebraically and 
by numerically inverting X.
(d) 
Now place [7(0,1) priors on 0з and 04 and write code to analyze the data using 
this prior. You may either just obtain the analytically induced prior on /3 or specify 
the prior on 0 and then induce the prior on /3 in a program. Compare results with 
those in Table 8.2.
Exercise 8.4. Refer to the trauma data in Examples 8.3 and 8.7. Table 8.4 gives 
results with a flat prior on /3.
(a) 
Analyze the data and check your results with Table 8.4.
(b) 
Obtain the predictive probabilities of death for the covariate vectors
(25,5,20,1),
(iSs,sts,age,ti)=
(50,5,50,1),
(25,3,20,1),
(25,3,50,1),
(50,3,20,1),
(50,5,50,1).
(c) 
Make a 2 x 2 x 2 table of estimated probabilities of death under these circum­
stances and discuss it in terms of practical import. You may want to look up ISS 
and RTS on the web to ascertain what these values mean on those scales.
Exercise 8.5. Give a full analysis of the trauma data using (i) flat priors and 
(ii) low information omnibus priors. Be sure to monitor convergence. With each, 
include:
(a) 
assessment of posterior probabilities that regression coefficients are positive (or 
negative).
(b) 
estimates of probabilities of “death on the table” for the 16 possible combina­
tions of (ISS, RTS, AGE, ТГ) corresponding to ISS = 20,40; RTS = 3.34,5.74; 
AGE = 10,60; and TI = 0,1. As part of your analysis, create a table of entries that 
includes the median and a 95% probability interval for each combination. Inferences 
are for the proportions of deaths in the populations of trauma patients that fall into 
these 16 categories.
(c) 
Compare with results obtained using priors (i) and (ii) with those in Figure 8.1.
Exercise 8.6. Repeat Exercise 8.5 using standardized continuous covariates. 
(There is no need to repeat analyses with the LIO prior for parts (a) and (b), as 
this prior is only defined with standardized covariates.) Comment on statistical 
versus practical import in the words of the problem as relevant below.
(a) 
Compare your estimates of the 16 probabilities. They should be nearly the same 

Binary Response Regression
239
if everything was done correctly, since this is just a reparameterization of the model 
used there. Be sure to monitor convergence. Was convergence better than, worse 
than, or about the same as it was in Exercise 8.5?
(b) 
Obtain and interpret (in the words of the problem) estimated odds ratios for 
the effect of TI for AGE = 60 and then for AGE = 10.
(c) 
Obtain and interpret estimated odds ratios for the effect of ISS, comparing 
ISS = 41 to 25, and for RTS. comparing RTS = 3.34 to 7.84. Be sure to interpret 
the results in the words of the problem.
Exercise 8.7. Refer to the snake bite data in Example 8.5. Table 8.5 shows 
results with an improper uniform prior on /3.
(a) 
Use £7(0,1) priors on the death probabilities at dose 8 and 16 to induce a prior 
on /3. Analyze the data with this prior and carry out inference for components of 
/3.
(b) 
With your posterior MCMC samples, make a table corresponding to Table 8.5 
and compare.
(c) 
Obtain inferences for the dose at which 90% of mice would die using this prior, 
(d) Change the prior to uniforms on probabilities at dose 32 and 4. Repeat parts 
(a), (b), and (c). Compare. Note: These would be stupid priors, since it is doubtful 
that the experimenters would believe in a prior that was equivalent to adding one 
success and one failure for an imaginary rat that was given a dose of 32 and also 
for such a rat at a dose of 4. They would surely believe there would be a smaller 
probability of death for the much lower dose than for the higher one. However, they 
could think of this prior information as being quite neutral and that sufficient data 
would be needed to overwhelm the information that was contrary to their true prior 
beliefs.
Exercise 8.8. Consider two independent binomial samples with probabilities 0i 
and 02- Define ft = logit(ft) and (З2 = logit(02) - logit(ft).
(a) For independent (3j ~ АГ(0,103), j = 1,2, simulate the induced prior distribu­
tions on ft, 02, and OR = [£?i/(1 — ft]/[ft/(l — #2)]- Note that the densities for the 
0jS are concentrated near 0 and 1, and the density for OR will be widely dispersed, 
(b) Place independent 77(0, b) priors on the 0j and, by trial and error, find a value 
of b that induces reasonably spread-out (ideally, close to uniform) priors on the 0j. 
(c) Place independent 77(0, c) priors on the /3j and, by trial and error, find a value 
of c that induces a prior on OR that has about 95% of its probability concentrated 
between -10 and 10. In our experience, estimated О Rs tend to be relatively small, 
perhaps in this range.
(d) 
Now let 0j ~ [7(0,1). Plot histograms of the induced distributions for the (3j. 
Do they resemble the 77(0, b) prior you found in part (b)?
Exercise 8.9. Use a flat prior to reanalyze the LE data with the single covariate 
High that was discussed in Example 8.1.
(a) 
Using the probit link, compare estimates of the two probabilities of LE with 
those using the logit link presented in the example. How was convergence?

240 
Bayesian Thinking in Biostatistics
(b) 
Using the complementary log-log link, compare estimates of the two probab­
ilities of LE with those using the probit and logit links. How was convergence?
Exercise 8.10. Write code, using links specified in parts below, to analyze the 
trauma data using the full model but with standardized continuous covariates. 
Using a flat prior, obtain the usual table of inferences for all regression coefficients. 
Also obtain a plot of the probabilities of death for individuals with IS = 1, sAge = 
0, aRTS = 0, and over a suitable grid of sISS scores that range from the smallest 
to the largest values in the data.
(a) 
Use the logit link.
(b) 
Use the probit link.
(c) 
Use the complimentary log-log link.
(d) 
Discuss any qualitative and/or appreciable quantitative differences in the results 
from the analysis with these three links and give all three plots on the same graph.
Exercise 8.11. Consider the binary regression model with two predictor vari­
ables and with no interaction. Fix the second predictor at the value c and obtain 
the odds ratio comparing the odds of an event for an individual with value a + 1 
to the odds for an individual with value a for the first predictor. Show this for all 
three links discussed in this chapter.
Exercise 8.12. Consider the binary regression model with one predictor vari­
able.
(a) 
Describe how to implement a CMP prior for the two regression coefficients if you 
have elicited information for two distinct covariate combinations (i) in the probit 
link case and (ii) in the complementary log-log case. One way to do this is to write 
the code that is necessary for inducing the CMP onto the regression coefficients.
(b) 
Write the analytical form for the two induced priors for (3. Are either of them 
data augmentation priors?

Chapter 9
Poisson and Nonlinear Regression
In this chapter we first consider regression models for Poisson data. In binary regres­
sion we related appropriately transformed success probabilities -via logit, probit 
and complementary log-log functions—to linear combinations of covariates. Here, 
we relate log-transformed rates of Poisson events, log E(Yt), to linear combinations 
of covariates.
This chapter also includes the extension to the problem of overdispersion and 
its resolution by considering continuous mixtures of Poisson regression models. An 
additional extension is to the common problem where considerably more zeros occur 
than are expected under either of these two Poisson models. This leads to the 
introduction of the zero-inflated Poisson regression model. We also briefly discuss 
how these and other like models fit into a broader framework of models called 
generalized linear models.
Finally, we introduce nonlinear regression models via one particular model where 
the data are considered to be normally distributed but the mean response has a 
nonlinear structure.
9.1 The Basic Poisson Regression Model
We discussed exchangeable Poisson distributed observations in Chapter 3. Poisson 
data are counts of events where there is no specified upper limit for the number 
of events that could occur over time or in space. There are four basic assumptions 
required for count data to be Poisson distributed (Ross, 2014; [275]). The first 
assumption is that events are “rare” in the sense that the chance that there would 
be two or more events in a small interval of time, or a small region in space, would 
tend to zero very quickly as the interval or region becomes small. Second, event 
occurrence is stationary in the sense that the probability of a specified number of 
events in an interval of fixed length (or a region of fixed size) is the same regardless of 
where the interval appears on the time line (or where the region is located in space). 
Third, counts in non-overlapping intervals of time (or regions in space) are mutually 
independent. This is referred to as “independent increments.” The final assumption 
is that the probability of a single event in a small interval (or region) is proportional 
to the length (or size) of the interval (or region). Under these circumstances, the 
number of events counted in any fixed time interval (or region) is a Poisson random 
variable with mean equal to the constant rate A multiplied by the length of the time
241

242
Bayesian Thinking in Biostatistics
interval (or size of the region). What is new in this chapter is that the time-constant 
or space-constant rate at which events occur depends on covariates. As the rate Л is 
a positive number, we use the log link here, so the linear combination of covariates 
can be any real number.
Let the response data у = (yi,..., yn) constitute a vector of Poisson counts, and 
let x\ = (l,Xii,... ,xjp) where in,... ,xip are p predictor variables for individual 
i, i = 1,... ,n. For example, we could have randomly sampled n children from a 
population of interest and over the course of several years counted the number of 
colds each child caught over a period of time. Possible predictor variables are age, 
number of family members, family income, race and ethnicity. The basic model for 
Poisson regression is
У, | n, Xi Po(Xi), log(Ai) = xtf, /3 = (&,•••, /3РУ, i = 1, • • •, n. (9.1)
We observe some similarities between this and the logistic regression model in 
expression (8.1). Here,1 E(Yi) = Xi and log^F,)) is related to covariates via 
a linear function. In logistic regression, E(Yi) = Р(У, = 1) and logit(E(Vi)) is 
a linear function of covariates. In linear regression for normally distributed data, 
E(Yi) itself is a linear function of the covariates, that is, the link function is the 
identity function.
Example 9.1. Epilepsy Data. We analyze a simplified version of a data set that 
was discussed in Thall and Vail (1990) [321] and which was subsequently analyzed 
in Breslow and Clayton (1993) [52]. The data are seizure counts over a fixed period 
of time (four two-week intervals post-randomization) in a randomized trial of anti­
convulsant therapy for epilepsy. The counts are for 59 patients, and covariates are 
treatment (Trt: 0,1), eight-week baseline seizure count (Base), and age in years 
(Age). Counts range from 0 to 302, with a median of 16; ages range from 18 to 42, 
with a median of 28; baseline counts ranged from 6 to 151, with a median of 22; 
and 31 individuals were treated out of the 59. BUGS code and programs for JAGS 
and Stan may be found on the book’s website for Chapter 9. The data and program 
files include “epilepsy” in their names.
Since the data on Age and Base are clearly skewed to the right, we use the 
logarithms of these variables. We also standardize them by subtracting their re­
spective means and dividing by their standard deviations. While standardization 
is not strictly necessary, it will often stabilize the implementation of statistical in­
ferences. We have found that placing independent standard normal priors on the 
regression coefficients for standardized and dichotomous predictors to be a reason­
able reference prior.
In the following regression model. wv denote the standardized logarithm of the 
baseline seizure count as slogBase, for patient i and this patient’s standardized age 
by The model is
log(A,) = do + Ji slogBasei + З2 Trt, + З3 slogBasei x Trt, + S^sAgei,
Л11 observations are initially assumed to be on an interval of unit length (or region of unit 
size). We address other situations later, through examples.

243
Poisson and Nonlinear Regression
TABLE 9.1: Model parameter inferences for epilepsy data
Predictor 
slogBase 
Trt
slogBase x Trt 
sAge
Med 957c PI 
0.68 
(0.62.0.74)
-0.31 (-0.42.-0.19)
0.40 
(0.31.0.49)
0.20 
(0.15.0.25) 
where we include an interaction between the treatment and the standardized log­
arithm of the base count, since it was anticipated that the effect of the treatment 
could vary with age. The original data were obtained longitudinally where counts 
were obtained over four distinct time periods. Our version of the data simply takes 
the total over the four periods, since we have not discussed how to handle longit­
udinal outcomes at this stage in the book. Those methods are discussed in Chapter 
14.
Since all predictors are standardized or are binary, we use independent IV (0,1) 
priors on the /3s. As an alternative, we also use independent improper flat priors on 
the /3s. (dflatO in BUGS or Stan’s facility for allowing improper priors). Posterior 
results using this latter prior are virtually identical to those presented in Table 9.1, 
where we used the N(0,1) priors. We see that all of the regression coefficients are 
clearly statistically important, including the coefficient for the interaction.
Because the interaction is important, it is not easy to interpret results directly 
from Table 9.1. Therefore, we include Table 9.2 in which we present inferences that 
show how the effect of the treatment varies as we vary the baseline seizure count 
(Base) for fixed ages. The table shows posterior median seizure rates for Trt = 1 
and Trt = 0 for individuals with Base = 22 and Age taking values (22,28,35), and 
then again with Base = 50. We also show inferences for the differences in rates for 
Trt = 1 versus Trt = 0 in Table 9.2 to highlight how the effect of treatment varies 
across all of these conditions. We did this by monitoring the posterior samples of 
rates
Arrt = exp(j0o + fa slogBase + 02 Trt + fa slogBase x Trt + fa sAge) (9.2)
for all of these combinations of covariates and for the rate differences, Л1 - Ло, for 
each sample.
Observe that the first three posterior median rate differences in Table 9.2 are 
—5.6, —7.6, and —9.2, respectively, while the bottom three are 3.4, 4.6, and 5.6. The 
implication is that there is an appreciably lower rate of seizures for treated than for 
non-treated individuals who have average baseline seizure counts (Base = 22), while 
there is an appreciably greater rate for treated versus non-treated individuals who 
have baseline seizure counts of 50. Moreover, these estimated effects become more 
pronounced with increasing age. Thus, with average baseline counts, the estimated 
treatment effect improves with age, and with Base = 50, the negative effect of

244 
Bayesian Thinking in Biostatistics
TABLE 9.2: Inferences for seizure rates (Л) according to Age, Base, and Trt
Trt = 1
Trt = 0
Difference
Med
95% PI
Med
95% PI
Med
95% PI
22
Base = 22
12.4
(10.9,14.0)
18.0
(16.0,20.3)
-5.6
(-7.7,-3.7)
28
16.7
(15.2,18.3)
24.3,
(22.3,26.4)
-7.6
(-10.1,-5.1)
35
20.4
(18.4,22.5)
29.6
(27.0,32.4)
-9.2
( — 12.4, —6.2)
A#e 
22
Base — 50
42.8
(39.4,46.4)
39.4
(35.2,43.9)
3.4
(-0.6, 7.3)
28
57.7
(53.9,61.7)
53.1
(49.6,56.8)
4.6
(-0.8,10.1)
35
70.4
(63.7,77.5)
64.7
(60.0,69.9)
5.6
(—0.9,12.6)
treatment also increases. The modeled interaction effect is clearly appreciable and 
of both statistical and practical import.
Finally, observe that the effect of increasing the baseline seizure count (Base) 
is quite substantial; the estimated rates for those with higher Base values are all 
considerably larger than their counterparts with smaller Base values. It is not 
surprising that individuals with higher baseline seizure counts would also have 
higher estimated counts during the study than would individuals with lower baseline 
counts. It may be surprising, however, that the treatment works well for individuals 
with smaller baseline counts but is evidently detrimental for individuals with high 
baseline counts.
Another summary, besides rate difference, that is often used to compare two 
treatments in Poisson regression is the relative rate (RR) of occurrence of seizures 
under the two conditions, defined by
Л | Trt = 1 _ exp{/?o + fa slogBase + fa + faslogBase + faAge}
X\Trt = Q 
exp{ fa + faslogBase + faAge}
_ e02+P3slogBase
This formula makes clear that the treatment effect is modified by the value for 
Base. For these data, the estimated value for fa is —0.31 and for fa is 0.40. So 
we anticipate that the relative rate of seizures will be smaller (and less than 1) 
when the Base rate is relatively small and that the relative rate will be larger (and 
greater than 1) when the Base rate is relatively high. This is precisely what we can 
glean from Table 9.2 by visually comparing rates with and without treatment for 
the situations with low and high Base rates.
To elaborate further, if slog Base = 0. the treatment effect is measured as e02-. 
while if slogBase = 1. the treatment effect is measured as e^2+^3; slogBase = 0 
corresponds to Base = 25. and slogBase = 1 corresponds to Base = 51. These val­
ues are obtained by transforming slogBase values back to Base using the average 
and standard deviation of the logBase values. 3.21 and 0.72, respectively. The pos­
terior inference for the treatment effect RR at Base = 25 is e-0 31 (e-0 42, e-019) =

Poisson and Nonlinear Regression 
215
TABLE 9.3: Predicted seizure counts for an individual according to Aye. Bast. and 
Trt
Trt = 1
Trt = 0
Med
957c PI
Med
957c PI
Age
Base = 22
22
12
(6.20)
18
(10.27)
28
17
(9,25)
24
(15.35)
35
20
(12,30)
30
(19,41)
Age
Base = 50
22
43
(30,57)
39
(27,53)
28
58
(43,74)
53
(39,68)
35
70
(53,89)
65
(49,82)
0.73 (0.66,0.83). At Base = 51, the median RR = e-o.3i+o.40 = } 20. The probab­
ility interval, however, is not available from Table 9.1. The interval could be easily 
obtained by monitoring /32 + 03 if posterior samples of 0 were available. It turns 
out that this interval is entirely above 1. As the RR is below 1 for Base = 25, we 
infer that the two measured effects are statistically different from 1 and in opposite 
directions. Thus again, from a different quantification, we reach the same conclu­
sion that the treatment appears to be effective for patients with average baseline 
rates of seizures, but harmful for patients with high baseline rates.
We conclude the example by showing prediction results in Table 9.3 that are 
parallel to the estimation results in Table 9.2. Observe how the point predictions 
are directly comparable to the corresponding rate estimates in Table 9.2, while the 
corresponding intervals are considerably wider here, as they should be.
Next we consider the common situation in which one carries out long-term 
studies on patient populations. The studies seek to address major health issues, 
such as the effect of smoking on eventual acquisition of lung cancer or the effect of 
obesity, smoking, and other factors on the eventual acquisition of coronary heart 
disease. Such studies are generally quite large, take many years to complete, and 
are expensive. We have two small versions of such data that we analyze below. Our 
intent here is to illustrate methodology.
Example 9.2. Framingham Heart Study. The Framingham Heart Study was 
initiated in 1948 with the primary goal of identifying common factors or char­
acteristics that contribute to cardiovascular disease [236]. The data involve 4,699 
subjects collectively contributing 103,710 person-years of follow-up. While there are 
a number of outcomes and predictors that are considered in the study, we use a 
small version of the data on the web that involved counts of coronary heart disease 
(CHD) for men and for women for specified person-years of exposure. In particular, 
there were 823 men who experienced CHD over the course of 42,259 person-years of 

246 
Bayesian Thinking in Biostatistics
follow-up, and there were 650 women who experienced CHD over a total of 61,451 
person-years of follow-up.
When fitting a Poisson regression model, we input the person-years of follow-up 
as what is called an “offset variable.” The reason is that the rate parameter gives the 
expected number of events per unit time. If the total amount of time is M person- 
years, then the expected number of events is Л x M, which is the rate parameter 
for the corresponding Poisson sampling distribution. (A similar argument applies 
when one is modeling occurrences over space, with the offset corresponding to the 
size of the space in appropriate units.) Offset variables are treated as fixed and are 
used so that the rates corresponding to all Poisson counts will be comparable in 
terms of units. For example, the raw estimate of rate of CHD occurrence for men is 
823/42,259 = 0.0195 events per person-year and for women is 650/61,451 = 0.0106 
events per person-year. If we divide person-years by 1,000, then we obtain 19.5 and 
10.6 events per 1,000 person-years, respectively, which is easier to think about.
A feature of this example, distinct from the epilepsy example, is that, all other 
factors being the same, we would expect larger counts in the group that had the 
larger number of person-years of exposure. In the epilepsy example, each individual 
was observed over the same length of time, so the number of person-years was the 
same for each of the sets of conditions considered. Differences in follow-up times 
did not play a role in the analysis. Here we write a model to accommodate varying 
exposure time as follows.
As we wish to study differences by sex, we first think of the model
Kf|Ai ~ Po(AJ, log(Ai) =/30 +/Зх Sex^ г = 1,2,
where observations correspond to the two groups Sex^ = 0 for men and Sex 2 = 1 
for women. However, this does not account for different exposure times for the two 
groups. We therefore write, with Mi equal to the total exposure in group i,
Yi\Xi Po(MiXi), log(Ai) = 0o + 0i Sexi, i=l,2.
In this model, E(Yi) is not A*,  but A/jAj. Alternatively, we can write the model as
Yi|A
*
 ~ Po(A
*),
 log(X
*)
 = 1од(М{) + 0O + 0i Sex^, i = 1,2.
With ЛЛ = 42,259 and M2 = 61,451, 0' = (3o,01), and x{ = (1,0) and x'2 = (1,1), 
we can write the model in vector form as
У,|А
*
 ~ Po(A’). log(A‘) = log(AA) + а:'/?, г = 1,2.
For our analysis, we specify independent standard normal priors for 0o and 
3|. The relative rate comparing males to females with offsets set to be equal is 
HR = Xi/X-2 = exp( —with A, = А*/Л/,.
 г = 1.2.
Fitting this model, we obtained the posterior median for the rate of CHD among 
men as 19.5 events per 1.000 person-years with a 95% posterior probability interval 
of (18.2.20.8) events per 1.000 person-years. (Data and code for fitting the data have 
a name that includes "CHD" on the book's website for Chapter 9.) For women, the 

Poisson and Nonlinear Regression 
217
corresponding results were 10.6 (9.8.11.4). The rate ratio of CHD for men relative to 
women was estimated to be 1.84 (1.66. 2.04). Thus men are estimated to experience 
CHD at between 66% and 104% higher rate compared to women.
Of course these results do not account for potential person-level covariates that 
might be relevant, for example, age at the beginning of the study, or any behavior 
patterns like alcohol consumption and smoking. Other factors such as blood pressure 
and body mass index might even be of greater interest than sex as predictors of 
CHD. We address such a situation next.
Example 9.2 used a grouped data model that, when appropriate, can con­
dense the data considerably. While there are n = 4,699 individuals contributing 
42,259 + 61,451 = 103,710 person-years of follow-up, the data for the model con­
sisted of only two observations! On the other hand, perhaps important individual­
level information was ignored in the analysis. The following model can correct the 
situation:
Yi | Xi ~ Po(Xi), log(Ai) = log(Mi) + z'/?, i = l,...,n.
As in regression models of Chapters 7 and 8, here /3' = (J3q, ... , /3P) is the vector 
of regression coefficients, including the intercept (30, and x, is the corresponding 
(p+1) x 1 vector of covariates for individual i with first element set to 1. In addition, 
Mi is the number of years over which individual i was in the study (exposure 
time). As before, if we wish to express event rates per 1,000 person-years, we would 
use M
*  = Mj/1,000 as the offset; alternatively, rates obtained with Mi can be 
multiplied by 1,000. The next example illustrates an analysis with such a model.
Example 9.3. British Doctors Study. Christensen et al. (2010) analyzed data 
from a historic study on the effects of smoking [79]. Table 9.4 presents the data. 
The participants were male British doctors surveyed in 1951. The data consist of 
age and whether the respondent smoked tobacco. Ten years later the investigators 
determined the number of deaths from CHD and the number of person-years on 
study in each group defined by initial smoking status. We compare death rates for 
smokers and non-smokers, controlling for age.
TABLE 9.4: Ten-year mortalities from CHD and empirical rate ratios by age cat­
egories
Smoker
Non-smoker
Age
У
M
У
M
Observed rate ratio
35-44
32
52,407
2
18,790
5.7
45-54
104
43,248
12
10,673
2.1
55-64
206
28,612
28
5,710
1.5
65-74
186
12,663
28
2,585
1.4
75-84
102
5,317
31
1,462
0.9

248
Bayesian Thinking in Biostatistics
FIGURE 9.1: Empirical death rates from CHD for smokers and non-smokers.
Before carrying out model-based inference, we describe the sample data con­
sisting of five age groups. Figure 9.1 plots these death rates for smokers and non- 
smokers. With the exception of the 75-84 age range, the empirical (or sample or 
raw) mortality rates from CHD are higher in smokers than non-smokers, and the dif­
ferences increase with age, with one exception: the 75-84 range shows non-smokers 
with a higher empirical rate of death than for smokers. It is also noticeable that 
the death rates increase at an increasing pace rather than at a constant or linear 
pace in age. Table 9.4 displays calculations from the sample, including rate ratios 
comparing smokers to non-smokers, which decrease from over 5 for the youngest 
group to about 1 for the eldest group. This decline indicates that the magnitude 
of the smoking effect may diminish with age, in spite of the fact that death rates 
themselves and even the differences in death rates for smokers and non-smokers 
increase with age, except for the difference in the eldest group.
While these are good summaries of the data, they do not contain measures of 
variability in these rates, differences, and rate ratios. Variability assessment is es­
sential to draw conclusions from the data. To this end we propose some models 
for the data. Let (yi.......y5) be the mortality counts for smokers and (ye,.... ую)
be the corresponding mortality counts for non-smokers in each of the five age cat­
egories. Also let (A/i....... ЛД) and (M$, .... Л/щ) be the corresponding numbers of
person-years of observation.
We have a number of choices for a model. Christensen et al. (2010) [79] treated 
categorical age groups as numerical. Thus, as a covariate in the model, Age took 
on the values 1........ 5: and of course Smoke is binary. An issue we need to address,
however, is the fact that Age in these data is categorical. If we let Age take the 

Poisson and Nonlinear Regression
249
values 1,.... 5, there is a presumption that the rate difference (on the logarithmic 
scale) between Age = 1 and Age = 2 equals that between Age = 2 and Age = 3. 
In general, it is not a good idea to treat a categorical variable as numerical. For 
example, think about what it would mean if the categories were colors, a situation 
in which it would make no sense to think that the response difference in the color 
blue and the color red equals that between the red and white. Even so. age being 
numerical in nature and the categories being equally spaced lessen this concern 
assuming, of course, that log(rate) is a linear function of age.
To account for the shape of the empirical curves displayed in Figure 9.1, Chris­
tensen et al. [79] included both a linear and a quadratic term for Age. They 
also included an interaction between Age and Smoke, and between Age2 and 
Smoke, so that distinct nonlinear curves could be modeled for smokers and for 
non-smokers. In our version of the model, we standardize Age and use the square 
of (Age — mean(Age))/sd(Age). The regression model is
log(Aj) = /?o + PiSmokei + fasAi + 03sA2 + faSmokeisAi + faSmokei sA?, (9.3)
where Smokei is smoker status (1 for smoker, 0 for non-smoker), Ai is age, sA, = 
(Ai -mean(Ape))/sd(Ape), and sAj = [(Ape
*
 -mean(Ape))/sd(Ape)]2, for groups 
i = 1,..., 10. With these standardizations, if Aj = mean(Ape) = 3, then sA, = 
sA2 = 0. This will allow us to easily specify a conditional means prior (CMP), or 
at least a partially informative CMP, as we shall see.
For our initial analysis of the data, we let & ~ U(—10,10), which is a proper 
prior that gives virtually the same results as p(0) ос c for any constant c. In the 
analysis, we divided all of the person-years at risk by 10,000. This means that risk 
is to be interpreted as expected number of deaths per 10,000 person-years at risk. 
(BUGS and Stan code can be found on the course website, under Chapter 9, in the 
file with name that starts “British”.) Results for regression coefficients are given in 
Table 9.5. Observe that all coefficients except are statistically important, since
TABLE 9.5: Inference for regression coefficients, model equation (9.3)
Coef.
Med
95% PI
00
3.81
(3.52,4.08)
0x
0.47
(0.18,0.77)
02
1.85
(1.54,2.21)
03
-0.55
(-0.91, -0.23)
04
-0.53
(-0.92, -0.21)
05
0.12
(-0.22,0.50)
the corresponding 95% posterior probability intervals exclude zero. The effects of 
Age and Smoke are nuanced, because the model includes an interaction between 
them. These effects are discussed next. Clearly & is not statistically important. We 
leave it as an exercise to compare this model to the one without £5, as well as to 
consider a model that treats Age as a factor rather than as a quantitative variable.

250
Bayesian Thinking in Biostatistics
We also estimated death rates for smokers and for non-smokers, the rate differ­
ences (RD), and the relative rates (RR). Results are given in Tables 9.6 and 9.7. 
Clearly, fitted rates increase with age for smokers and for non-smokers. For the first 
three age categories, there is no overlap for smoker and non-smoker intervals (see 
Table 9.6); consequently, results for these rate differences and relative rates show 
clear statistical import (see also Table 9.7).
TABLE 9.6: Ten-year posterior mortality rates, model equation (9.3)
Flat prior
Age
Smokers 
Med
95% PI
Non-smokers 
Med
95% PI
35-44
5.7
(4.3, 7.6)
1.4
(0.5,3.1)
45-54
24.7
(21.7,27.9)
10.2
(6.7,14.5)
55-64
72.2
(65.1,80.1)
45.1
(33.7,59.1)
65-74
143.4
(130.3158.4)
121.6
(94.6,154.6)
75-84
194.0
(162.9,230.1)
199.4
(138.5,278.3)
Observe that interval widths increase with age, because the number of person- 
years at risk decreases with age for both smokers and non-smokers. For any given 
age cohort, intervals are wider for non-smokers since there are fewer person-years 
for them than there are for smokers.
TABLE 9.7: Ten-year posterior mortality rate differences and relative rates, model 
equation (9.3)
Flat Prior
Smokers
Non-smokers
RD
RR
Age
Med
95% PI
Med
95% PI
35-44
4.3
(2.1,6.4)
4.1
(1.7,11.5)
45-54
14.5
(9.2,19.2)
2.4
(1.7,3.7)
55-64
27.0
(11.5,40.8)
1.6
(1.2,2.2)
65-74
21.8
(-13.4,52.3)
1.2
(0.9,1.5)
75 84
-5.5
(—90.1.65.6)
0.97
(0.67,1.5)
Partially informative prior
35 44
4.3
(2.1.6.4)
4.2
(1.7,11.8)
45 54
14.5
(9.1.19.3)
2.4
(1.6,3.8)
55 64
26.6
(12.4.40.2)
1.6
(1.2,2.1)
65 74
21.3
(-12.6.51.8)
1.2
(0.9,1.5)
75 84
-4.5
(-89.3.66.8)
0.98
(0.67.1.46)

Poisson and Nonlinear Regression
251
Next we consider a partially informative CMP by specifying independent, in­
formative log-normal distributions for two scientifically relevant rates, which then 
induces informative distributions on two regression coefficients. We specify diffuse 
distributions on the remaining coefficients. While we could use gamma distribu­
tions, the log-normal is slightly more convenient to specify as a prior distribution 
because there are simple formulas for the median and a quantile of the log-normal. 
With extra effort, the gamma can be used as well.
The first specified mortality rate, Ab corresponds to a doctor who is in the 
middle age category and is a non-smoker. The second specified rate. A2. corresponds 
to a doctor who is also in the third age category but is a smoker. From equation 
(9.3). we obtain 
_ 
„ 
.
A^A A2 = e* +*
Specifying the prior as
log(A()'~ LN(bio,^0), i = l,2,
we can induce the prior on (ft, ft) by specifying the relationship as
ft=log(A|), ft = log(A2)-ft. 
(9.4)
In this way, we would use scientifically relevant information to induce a prior for 
the model parameters (ft,ft). For the remaining regression coefficients, we specify 
independent diffuse priors: ft U(-10,10), i = 3,..., 6. With these steps, we will 
have induced some real prior information into the model. We could of course have 
focused on a single rate, or more than two rates, and accordingly modify this prior 
induction process.
How do we specify the parameters in the log-normal priors? We have done this 
before in previous chapters. We first specify a guess for the rate corresponding to 
individuals in the middle age cohort who do not smoke. We might think that the 
rate is 50 deaths per 10,000 person-years. For the smoker in the same age cohort, we 
hypothesize that the rate might be 80 deaths per 10,000 person-years. (We cheated 
and looked at the data, so our exercise here is purely illustrative of the technique.) 
We then specify the 95th percentile of the prior for the rates to be 100 and 150, 
respectively; we are 95% certain that the mortality rate per 10,000 person-years for 
smokers is less than 100, among non-smoker doctors in the middle age cohort, and 
that for smokers it is less than 150.
Generically, if A ~ ZJV(5o,<7q), ^e corresponding a quantile is 
Aa = ebo+2°' a°.
Thus, if our best guess for A is Ao and we let Au be the user-specified value that 
satisfies P(X < Au) = 0.95, then we have Ao = e60 and Au = e&o+1-645ffo) which 
results in bo = log(Ao) and cr0 = (log(Au) - log(A0))/1.645). Then for our specific 
problem, we have Ью = log(50), cr10 = (log(100) - log(50))/1.645, b2o = log(80), 
<T2o = (log(150) - log(80))/1.645.
Results for rate differences and ratios using this partially informative prior are 
given in Table 9.7. They are remarkably similar to those using the flat prior. The 
similarity may be in part because of the large number of person-years involved in 
the study.

252
Bayesian Thinking in Biostatistics
9.2 Poisson-Based More General Models for Count Data
We now discuss two models that address typical violations of the basic Poisson 
model frequently seen in practice. Both still use the Poisson distribution but extend 
the model in interesting ways to account for its shortcomings in the basic form. The 
first addresses higher variation than indicated by the Poisson distribution, and the 
second addresses higher frequency of zero counts.
9.2.1 Overdispersion
We know that the Poisson distribution imposes the restriction that its variance 
equals its mean, Y ~ Po(A) => E(Y) = Var(F) = Л (see distribution table in 
Appendix B). In many instances with data, y,, that have been assumed to be, say 
Po(Aj), it can be empirically verified that Var(y | A,) > E(Yi | Aj). Since the mean 
and variance must be the same if the data are actually Poisson distributed, this is 
termed “extra-Poisson variation.” If the data indicate extra variation, a common 
solution is to use a model that employs a mixture of Poisson distributions. It is 
generally the case that mixtures of distributions will have larger variances than 
the components in the mixture. This is shown using the iterated variance formula, 
which we demonstrate here for a continuous mixture of Poisson distributions.
Take Y ~ Po(A) and let A ~ Ga(a,7) be the mixing distribution where a and 
7 are unknown parameters. The resulting mixture model will have (a, 7) as its 
unknown parameters. We observe that
Р(У|а,7) = Е(Е(У|А,а,7)) = E(A|a,7) = a/7, 
Уаг(У I a,7) = Уаг(Е(У | A, a, 7)) + Е(Уаг(У | A, a, 7)) 
= Var(A I a, 7) + E(A | a, 7) = a/72 + a/7 > a/7.
We can also derive the mixture distribution as
= [ P(y\X)p(X\a,y)dX 
Jo
_ A^-A7QAQ-1e-
P(?/ I a, 7)
Jo У'- Г(а) dX
/‘OOAa+!/-le-A(l+7)dA 
у!Г(о) Jo
7°Г(а +y)
j/!(l +7)a+wr(a)
/ 7 V/ 1 УГ(а + у) 
\1+7/ М+7/ р!Г(а) ’
This is a negative binomial distribution.
We can now model multiple counts as independent gamma mixtures of Poisson 
random variables, resulting in a model that allows for variances to be larger than 

Poisson and Xonlinear Regression
253
the means. An alternative mixture distribution places a log-normal distribution on 
A, which will also generate overdispersion.
We first consider grouped data of the form у = {: i = 1........A" j = 1.........n,}.
This is to allow for the possibility of easily checking the assumption of equal vari­
ances. Later, we go back to the case with щ = 1. We have к groups of data. Let 
Mij be the offset for the jth individual in group i and let Л/, = ^2 
assume a common covariate vector, Zj, for each group. Our regression model that 
allows for overdispersion is
Ту | Л, Ро(ЛЛА0, > = 1,...,71;.
log(AJ ЛГОг'^ст
*),
 i = l........к. 
(9.5)
This parameterization is termed “centered,” since the mean of log(A.) is j-'/L in 
contrast to the standard parameterization below. If <7^ is very small, the model 
reduces to regular Poisson regression for grouped data. If щ are all 1 and a*  is 
small, it is just Poisson regression as we have discussed it in the previous section. 
We observe that there is only one additional parameter from the standard Poisson 
regression model.
The model in expression (9.5) is equivalent to the model
Yij | Xi ~d Po(MiXi), i = l,...fc; j =
log(AJ = x'iP + Ui, 
(9.6)
U, ~
This version of the model is termed the “standard parameterization” and is obvi­
ously structurally equivalent to the centered version. The standard version is often 
used in more traditional non-Bayesian analysis. Motivation for the centered version 
is that the corresponding Markov chains may have better convergence properties 
than those in the standard version.
With grouped data, it is possible to directly check the assumption that the mean 
equals the variance. Assume for the moment that the Poisson model holds. Since, 
for each i, the observations {y^ : j = 1,... ,rii} constitute a random sample with 
mean Ait then the sample mean for group i, yi = y^/щ, is a reasonable estimate 
of the Poisson mean. Moreover, the sample variance, s| = 
_ Уг)2/(пг ~
1), can also be used as an estimate of A,, the Poisson variance for the model. 
Then we could order the yi from smallest to largest and subsequently plot these 
ordered values versus their corresponding s?. We would expect to see something 
resembling a 45-degree straight line if the Poisson assumption was correct. On the 
other hand, if we see a pattern of variances that are above the 45-degree line, 
we might suspect overdispersion. When we suspect overdispersion, we can turn to 
models in expressions (9.5) or (9.6) as alternatives.
Example 9.4. British Doctors Study with Overdispersion. We modified the 
code used in Example 9.3 to allow for overdispersion using both parameterizations 
discussed above. We used au ~ [7(0,1) and we have ni = 1 for all i. We found 

254
Bayesian Thinking in Biostatistics
Markov chains to be much better behaved using the version in expression (9.5) than 
with the version corresponding to expression (9.6). MCMC with the latter model 
was somewhat ill-behaved at the outset, but the chains did eventually converge. 
Inference for au was 0.06 (0.002,0.33), so the point estimate was not particularly 
large. Our decision to stick with the regular Poisson regression model over this one 
was because of the fact that inferences were not appreciably different from those in 
Table 9.6, which led us to believe that overdispersion was not a concern.
9.2.2 Zero-Inflated Poisson Data
Count data sometimes exhibit more zeros than expected under a Poisson sampling 
model. This is due to the fact that e~x may not be large enough to account for 
excess zero values. The expected number of zero counts, ne~x, will be too small and 
the expected values for a number of non-zero counts will be too large compared to 
actual count data. We now define a model that can be used when it is anticipated 
that there will be more zeros than allowed under a standard Poisson model. The 
basic problem of having excess zeros has been termed “zero-inflation.” This model 
is a mixture of a point mass at zero for the excess zeros and a Poisson regression 
model. The probability of zero is modeled as a logistic regression.
We assume data {t/i,..., yn}, with covariate vectors {xi,..., xn}. For brevity, 
we ignore the possibility that there are offsets, Mi, but the model is easily adapted 
to that situation. Each of the Yi is modeled as its own zero-inflated Poisson (ZIP) 
as follows:
Yi | Zi, Xi 
Po(zx x 0 + (1 - Zi) x X^,
Zi | 7Tj 
Ber^i), logit(7Ti) = x'rf, 
(9.7)
log(Aj) =
A Poisson with a rate of zero is just zero with probability 1. Thus the model specifies 
point mass at zero of probability 7Tj, and a Poisson count with probability 1 — 7Tj, 
allowing the possibility that a zero count can come from the point mass or the 
Poisson. The expected proportion of zeros in the ZIP is 714 + (1 — ttJc-*’, and the 
proportion in excess of what would be observed using the ZIP model over the basic 
Poisson regression model is щ + (1 - 7Ti)e-Ai - е-л< = 7Tj(l — е-л’).
We would not necessarily expect exactly the same covariates to be related to the 
binary and Poisson counts. A subset of x can be used for the binary regression and 
a different subset for the non-zero Poisson regression. Li (2012) has shown that the 
model is identifiable [222]. which means that the parameters of the model can be 
estimated. There are many models that lack identifiability, so this is an important 
issue in order to avoid nonsense inferences for non-identifiable parameters in the 
model. In general, lack of parameter identifiability does not mean the model is 
invalid for all inferences. In fact, there often exist useful and identifiable targets for 
inference even when some parameters arc not identifiable.2
In some cases. it is even useful to include non-identifiable model parameters: an example, while 
not treated there, is a version of the AXOVA model of Section 7.6.

Poisson and Nonlinear Regression
FMD Count in 1998
FIGURE 9.2: Histogram of FMD in 66 provinces of Turkey in 1998.
Example 9.5. Foot-and-Mouth Disease. Branscum et al. (2008) [51] analyzed 
data on reported cases of foot-and-mouth disease (FMD) in each province of Turkey 
over the eight years from 1996 to 2003. We consider data from 1998, with the goal of 
assessing the difference in FMD incidence between the eastern and western regions 
of the country. The histogram in Figure 9.2 shows that the majority of provinces 
(44 out of 66) had no reported FMD cases in 1998.
We consider both ordinary and zero-inflated Poisson regression models using 
Region (1 = eastern, 0 = western) and standardized cattle population size, sSize = 
(Size - mean(Size))/sd(Size), for each province as covariates. We used uniform 
priors for the regression coefficients.
We immediately suspect that there are far too many zeros for the standard 
Poisson regression model to be reasonable. For the purpose of illustration, we ran 
this model using U(—5,5) priors for the regression coefficients. (BUGS, JAGS, and 
Stan code are on the book’s website in files with names that contain “FMD”.) 
We obtained virtually identical results with U(-2,2) priors. History or trace plots 
were very well behaved with these diffuse priors. Inferences for 0i (eastern versus 

256
Bayesian Thinking in Biostatistics
western) and (eSize) are -0.14 (-0.65,0.35) and 0.46 (0.29,0.62), respectively. 
Under this standard analysis, there is no statistical import for the difference in 
eastern versus western rates of FMD, but the size of the cattle population (Size) is 
clearly important. The larger the population, the larger the rate of FMD. Of course 
the latter result is no surprise, since we know that FMD is endemic in Turkey; FMD 
rates would necessarily increase with population size.
In our analysis we also obtained a Bayesian version of the Pearson goodness-of- 
fit statistic and the corresponding Pearson residuals. In addition, we obtained the 
expected number of zeros if the standard Poisson model were valid. The standard 
Pearson goodness of fit measure is
PGOF = 
Л — > 
(9.8)
where of course E(Yi | А,) = A*.  In most non-Bayesian analyses, the MLE would be 
substituted for Aj. Here, we use the posterior median of the PGOF. We do not have 
a direct way to calibrate this median for how large is large in our approach. We 
could use probabilities from the posterior distribution for PGOF. In what follows, 
we take a simpler route and compare the magnitude of the median PGOF for a 
standard Poisson regression to the median PGOF for the ZIP model. The posterior 
median PGOF is 183.6 for the standard Poisson regression model, and 50.9 for the 
ZIP model.
The Bayesian version of a Pearson residual is simply the posterior median of
PRi = (yi - Xi)/y/Xi.
Note that PGOF is just the sum of squares of the PR. A plot of these residuals 
gives some indication of which observations in the data might be contributing to a 
large PGOF. The usual rule of thumb is to look for values for which |P/?| > 2. By 
analogy with normal theory, we might expect 5% of these to be larger than 2. We 
give an index plot of the Pearson residuals in Figure 9.3. While we would expect 
about half of the residuals (33) to be below zero, there are 46 that are negative. 
We might expect 66/20, or about three or four, to be above 2 in absolute value, 
but there are 10 that actually exceed 2 and none that are below —2. These results 
indicate the failure of the standard Poisson model. Moreover, the expected number 
of zeros in the data set is e-A', with a posterior median of 26. We have observed 
44 zeros and we expect 26 under the Poisson model. We are justifiably concerned 
about the validity of our assumptions.
We proceed to consider the ZIP model. (Code is available on the book’s website 
for Chapter 9 in files that include “FMD-ZIP” in the name.) We regressed non­
zero FMD counts and the probability of zero counts on both Region and Size. 
Inferences for regression coefficients are given in Table 9.8. We see that Size is 
statistically important regarding both the logistic probability of a zero count (the 
larger is Size, the smaller the probability of a zero), and the Poisson rates of 
FMD (the larger the Size, the larger the expected count). The effect of region is 
not statistically important in the logistic model of a zero count or for the rate of

CD
aS® % oaft><fe <% o (Poo Wa 
о °°
0 
10 
20 
30 
40 
50 
60
Index
FIGURE 9.3: Pearson residuals for FMD data using the standard Poisson regression 
model.
FMD. The estimated coefficient for 71 is 0.16, which seems negligible. However, 
the regression coefficient for region in the binary regression model has posterior 
probability 0.86 of being positive. The estimated coefficient is 0.62, which seems 
non-negligible.
We obtained posterior inferences for the excess probability of zero counts, com­
paring ZIP and standard regression models, for West versus East when Size was 
equal to its average value. The posterior medians were 0.72 and 0.59, respectively. 
The posterior probability for the difference being positive is 0.87, giving some evi­
dence that there may be more zero counts in the West than in the East.
The Pearson goodness-of-fit measure for this model was 50.9, which is much 
smaller than 183.6, its value for the standard Poisson model. The corresponding 
residuals are given in Figure 9.4. They also look better than the ones in Figure 9.3. 
In summary, there is not a definitive case for a difference in rates between eastern 
and western Turkey.

258 
Bayesian Thinking in Biostatistics
TABLE 9.8: Inferences for regression coefficients for ZIP model (9.7)
Coef.
Med 
95% PI
P(0 > 0 | y)
00 
Region 
Size
1.07 
(0.76,1.36)
0.16 (-0.48,0.71)
0.15 (—0.04,0.34)
0.69
0.94
P(7 > 0 | y)
7o 
Region 
Size
0.52 
(-0.14,1.20)
0.62 (—0.50,1.84)
-0.52 ( — 1.12,0.02)
0.86
0.03
9.3 Overview of Generalized Linear Model Regression
The generalized linear model (GLM) includes a fairly broad class of regression 
models, including many we have discussed already, such as binary regression, linear 
regression, and Poisson regression. The class of GLMs was introduced by Nelder 
and Wedderburn (1972) [249], and has been discussed by many authors since. We 
do not study this class in detail, but we introduce it so that readers can have a 
bigger picture of how they fit together.
What GLMs do is tie together models in which the response variable has a 
distribution in what is called the exponential class of families of distributions. In 
addition, these models relate a linear combination of covariates, to the mean 
E(Y | x,/3), through what is called a link function. We came across link functions 
for binary regression in Section 8.6. Recall the notation g(x'0) = E(Y | z,/3), or 
equivalently,
S-‘[E(r | x,/3)] = x'0.
So, for GLMs the first assumption is that the response distribution family is in the 
exponential class, and the second is that the expectation of the response is a known 
function of a linear combination of the covariates. The link function is defined to 
be y-1(-). as we have seen. The first assumption requires that the model for the 
data, y, satisfies
p(y|0I) = /l(y,(7)elT(^)-^)l/-2,
where the support for у is free of вх. In the formula, T(y) is some function of the 
data only, b(-) and </(•) are functions of dx only, and /i(-, •) is a function of the data 
and a only; a is a scale parameter. The only situation that we have considered so 
tar where ст could play a role is when we considered the normal linear model; it 
plays no role in binary or Poisson regression.
If 
the exponential family is said to be in canonical form. If T(y) = y,
then вг is called the canonical or natural parameter. The exponential family is 
usually introduced in non-regression settings but, being in the regression context, 
we have used the notation

Poisson and Nonlinear Regression
259
J
о
° О 
О °
<з9 о
о
о
1------1--------1--------
1--------1--------1---------- 1------
О 
10 
20 
30 
40 
50 
60
Index
FIGURE 9.4: Pearson residuals for FMD data using the ZIP regression model.
Perhaps the main feature of this description is that it covers a broad class of 
models, including almost all of those discussed so far3 and many more. It turns out 
that making large-sample maximum-likelihood-based inferences within this frame­
work is straightforward. This has made it possible for traditional statistical packages 
to handle many GLMs; all that is needed is to specify the appropriate family of 
distributions and the link function. Easy access to such packages has made them 
very popular. This, however, is not of advantage for the Bayesian approach. So we 
conclude this section with a couple of illustrations.
Example 9.6. Binomial Regression. If Y | 6X ~ Bin(n,6x), we have
p(y । ex) =
so we have
T{y) = y, b(0x) = logit(^), q(0x) = —n log(l - 0X), h(y) = 
.
‘Exceptions are the ZIP and the nonlinear models.

260 
Bayesian Thinking in Biostatistics
Thus it turns out that if we were to choose the logit link, logit(0I) = x'0, it would be 
termed the canonical link. This is related to the fact that, if we had reparameterized 
to 7a; = logit^), then it would be the case that yx was the canonical parameter 
of the model. If we had chosen the probit link, Ф01 = x'0, the specification would 
correspond to probit regression. Similarly for the complementary log-log link that 
was discussed in Chapter 8.
Example 9.7. Poisson Regression. For Y | 0X ~ Po(Xx), we have 
so we have
T(y) = y, b(Xx) = \og(Xx), q(Xx) = Xx, h(y) = W­
In this instance it turns out that, since T(y) = y, b(0a;) = log(Ax) = x'0 is the 
canonical link. We are not aware of other links that are actually used in Poisson 
regression data analysis.
9.4 *Nonlinear  Regression
All of our regression models up to now have been of the form g(E(Y | x,/3)) = x'0, 
where <?(•) is a link function. In the case of a linear model, g was the identity; 
for binary regression, it was a logit, probit, or complementary log-log link; and for 
Poisson, it was a log link. In this section we depart from that structure and allow 
an even more general form for the regression function. Our treatment here parallels 
that of Christensen et al. (2010) [79]. We consider the nonlinear form
E(Y\x,0) = m(x-,0),
where m(x,,0') is a known (nonlinear) function of x and 0-, x is observed but /3 is 
a vector of unknown parameters. For data у = (j/i,... ,yn), with covariate vectors 
(i'i,... ,xn), we further assume that observations deviate from the mean response 
according to a normal distribution. Then the model can be written as
Yi \0,т1~ N(Xi,l/r), Xi=m(xf,0).
Before going into more detail, we emphasize an important notational point for 
this section. In all regression models thus far, all being linear in 0, we have de­
noted the components of the (p+ l)-dimensional regression parameter vector 0 by 
•A).-A.........3p. The first component 0q stood for the intercept and the rest were
coefficients of covariates. We make a change in this section. We let 0 stand for a 
generic q-dimensional parameter vector of components 0i,...,0q. It is important 
to recognize that with nonlinear functions, these 0s may not be multiplying co­
efficients: they are just parameters in the function m(x;/3). Hence the change in 
notation. The following example and discussion related to it will help to clarify.

Poisson and Nonlinear Regression
261
Example 9.8. Carlin and Gelfand (1991) [61] reported data from a growth study 
by Ratkowsky (1983) [268] on length у and age x measurements collected on 27 
dugongs, large marine mammals. Carlin and Gelfand consider a growth curve model 
that is similar to
Xi = 0i - е32+3зЛ9е‘.
There are no new issues as far as making statistical inferences is concerned. As we 
have seen and already used, there are programs available (such as BUGS. JAGS, or 
Stan) that use Markov chain Monte Carlo for posterior inference even in cases where 
full conditionals are not in familiar mathematical forms. Readers can of course write 
their own code to do this as an exercise; but with the availability of easy-to-use 
programs, we prefer to focus on the specification of the prior and the analysis of 
the data.
We proceed as always by placing a prior on quantities that a scientist can think 
about directly. For the dugong data, the dimension of 0 is 3, so we choose three 
covariate vectors of convenient pseudo-observations i, and write
rhi = mi(0) = m(xi’,0), г = 1,2,3.
(9.9)
We can write this in matrix and vector notation as m = m(X',0), where X = 
(£1,^2,яз)'. For the dugong data, X = (Agei, Agez, Адез)' is a 3 x 1 vector of ages 
that will be selected for eliciting information for the mean lengths for three large 
groups of hypothetical dugongs of corresponding ages. A conditional means prior 
is obtained by eliciting
m ~ АГз(т71о, D(w)). 
(9.10)
So the components of m0 are our expert’s best specifications of mean dugong length 
for the three chosen age values, and the y/wl are elicited by specifying something 
like the 95th percentile of the prior distribution for m,, as we have done many times 
before.
Our standard protocol involves inducing the prior on 0 from the prior on rh. 
This is slightly trickier here than it was with the linear structure. We need to solve 
for 0 in terms of th, as we did in Chapters 7 and 8, only now there is no general 
explicit solution. Assuming m(0) is a one-to-one mapping, we let h be its inverse 
satisfying 0 = h(m). Obviously, 
= m(0) = m, by definition.
As usual, we standardize the ages to get sAgei and let the standardized version 
be X = (0,1,-1)', which corresponds to a hypothetical dugong of average age, 
another that is one standard deviation above the average age, and a third that is 
one standard deviation below average age. We would then like to solve
' 01 ~ e* \ 
0i - еА+л 
,0i -e02~03J
(9.11)
for 0. When there is no obvious solution, as in this case, we obtain a linear approx­
imation to the nonlinear model that does have an explicit solution. This is done 
using a standard Taylor series approximation. Given the linear approximation, our 

m(0) = I 1
262 
Bayesian Thinking in Biostatistics
approach results in an approximate CMP, since we are able solve the corresponding 
linear equations for (3. To elaborate, we now describe the process.
First, find 0o that satisfies ttiq = m(0o), where mo is our vector of prior estimates 
of the rhi. If we know the mapping function h(-), the solution is easy: 0o = h(mo). 
Since we usually will not know h in any closed form, we need to find a solution by 
using an iterative scheme. This approach requires the matrix of partial derivatives 
of m(0),
Л(/3)={Л^);. •=1ЛЗ}>
which are obtained by taking each row on the right-hand side of equation (9.11) 
and differentiating with respect to 0i, 02, and /З3, forming a matrix in which each 
row is a vector of partial derivatives. In our example, we obtain
—e02 
0 
\
_e02+03 _e02 +03 I . 
(9.12)
_e02~03 
e02~03 J
Now the first-order expansion about an arbitrary value 3*  is
m(0) = m(0
*)
 + m(0
*)(0
 - 0*),
with m(0
*)
 defined as in equation (9.12). We find an approximate solution of mo = 
m(0o) by writing
m(0o) = m0 = m(0
*)
 + m(0
*)(0
o - 0*),
and solving for 3o, obtaining
0o = /3*  + [m(0
*)]
-1 (m0 —m(0
*)).
 
(9-13)
Note that we need the matrix m(0
*)
 to be non-singular. We also need to specify a 
value for 0*  as an initial value for the procedure. Let (3^ denote this initial value. 
A standard first try might be 0q°^ = 0. A better choice would be the maximum 
likelihood estimate (MLE). Rewriting equation (9.13) as
0<1} = £«» + [m(0W)] -1 (mo - m(j3^ ,
we repeat this process к times to obtain 0(/c). If m is well behaved, /3^ will converge 
to the solution 3Q.
At every iteration, the value 0^> must result in a non-singular matrix m. In 
our example. 3 = 0 gives a singular matrix in equation (9.12). It is easy to show, 
however, that as long as 3^ / 0, the matrix will be non-singular. One way to decide 
when 3<K’+1) is close enough to 3^ to stop is to continue until |0jfc+1^ _ 
for some value of k. where 6 is a small value, perhaps 0.001.
We resume our quest for an induced normal prior for 0. We have the prior mean, 
3o. Since the Taylor expansion worked so well for finding 0o, we use it again for 

Poisson and .\onlinear Regression
263
obtaining an approximation to the full distribution. Since 3 = h(rii). we can take a 
first-order approximation to this equality by expanding about mo-
3 = h(m) = h(m0) + h(m0)(m - m0) = 
+ h(th0)(/h - ”'o)-
Now, 3 is approximated by a linear function of m. Since we have placed a normal 
prior on m in equation (9.10), we obtain an approximate induced normal prior for 
3, namely
3 ~ Wo, A(m0)D(w)/l(m0)'), 
(9.14)
by using the usual formula for a linear transformation of normals.
We still need /i(mo), the derivative of h evaluated at /ho- We assumed the 
existence of h, but it is generally only implicitly defined. Since ni(h(///.)) — m, dif­
ferentiating both sides gives m(h(m))/i(m) = I, which is equivalent to h(/h) = 
[m(h(m))]-1. This equality implies that h(mo) = [m(h(/ho))]-1 = [/п(Д)))]-1. 
Thus, from equation (9.14) we have the final computable result,
3 ~ Wo, [Wo)]-1 WWo)]"1')-
Standardized Age
FIGURE 9.5: Dugong growth curve: posterior mean (solid) and 95% pointwise 
posterior band (dashed).

264 
Bayesian Thinking in Biostatistics
One can obtain a diffuse prior by specifying a maximum range of values for the ms 
and selecting normal distributions for the m, that cover those ranges with sufficient 
probability.
Finally, a word of warning. It can be difficult to get convergence in the MCMC 
algorithms for nonlinear regression. You may need to run very long chains, and it 
might help to reparameterize the problem.
Example 9.9. Dugong Growth Study, Continued. For the dugong growth 
study, primary interest lies in the mean length as a function of age. Figure 9.5 
plots posterior medians of expected lengths and the corresponding 95% Pls across 
standardized ages of -1.3 (Age 0.7), -1.2,..., 2.6 (Age 31.4). Clearly, mean length 
increases with a plateau around 1 (Age 19).
We obtained /?o and the prior precision matrix in R. We used X = (0,1, -1)', 
rho = (2.4,2.6,2.0), D(w) = diag(25,25,25), and tolerance <5 = 0.001, with 
Ga(0.001,0.001) prior for r. The induced prior on /3 is
’ 2.8 '
-0.9
-0.7
0~N
’825.0 2312.5
2312.5 6562.5
1312.5 3750.0
1312.5’
3750.0
2187.5
9.5 
Recap and Readings
We covered the highlights of basic Poisson regression modeling, and its complements 
that attempt to cope with overdispersion and too many zeros. There are many 
papers that discuss these issues; we are guessing that the majority of them are 
non-Bayesian. Much of the material in this chapter is similar to that presented 
in Christensen et al. (2010) [79]. We have revised and/or expanded some of their 
analyses and added new ones. The dugong analysis is effectively theirs, and the 
section on nonlinear modeling parallels their section on this material quite closely.
The material discussed here should find considerable utility for those perform­
ing long-term studies that involve counts per person-year. Extensions to spatial 
and spatial-temporal count data are beyond the scope of this book. The book by 
Banerjee, Carlin, and Gelfand (2015) [15] is an important reference and provides 
the right background for diving into this important area. GeoBUGS is an add-on 
to WinBUGS that uses conditionally autoregressive models for spatial data. Barker 
et al. (2010) [16] used GeoBUGS in WinBUGS to model spatio-temporal mosquito 
count data. Those are just a few places to begin a study of this area.
We note that the Hurdle model (Mullahy. 1986; [244]) is a competitor for the ZIP 
model. This model specifies a logistic regression for the zeros, as in the ZIP model, 
but then specifies a zero-truncated Poisson model for the non-negative counts. Thus 
the probability of a zero count is just 7r, using our notation, and the probabilities for 
all non-zero counts are obtained as zero-truncated Poisson(Aj). The zero-truncated 
Poisson can be found most easily on Wikipedia.

Poisson and Nonlinear Regression
265
9.6 Exercises
EXERCISE 9.1. Re-examining the epilepsy data (Example 9.1). The data and 
some code are available on the book's website for Chapter 9 with file names that 
include “Epilepsy”. Observe that the data include 12 NAs (indicating missing data) 
at the end of the Poisson counts y. Also, for each of the covariates, there are 12 
additional records in the data set beyond the 59 values that correspond to actual 
data. Adding these 12 pseudo-observations is a trick we used for obtaining the 
inferences in Table 9.2. For example, the first three of the 12 added records have 
Trt values equal to 1, followed by three that are 0, followed by three that are 1. and 
three more that are 0. The first six values of Base for the 12 pseudo-observations are 
22, and the last six are 50. Finally, the pseudo-observations’ values for the variable 
Age are listed as 22, 28, and 35 repeated four times. In this way, the program that 
generates the posterior samples via MCMC for the Bayesian model also estimates 
the corresponding predicted risks for these 12 sets of covariates, (Лео,..., A71), using 
posterior samples for the model parameters to obtain predictions for the unobserved 
(Убо> • • • ,Уп). These posterior risks and predictions are summarized in Tables 9.2 
and 9.3, respectively.
(a) 
Using any method of your choosing and 7V(0,1) priors for the regression co­
efficients, write code to reproduce the results in Example 9.1 for all rates, RDs, 
and RRs. Also obtain the posterior probabilities that the RRs are greater than 1. 
Compare your results with those in the example.
(b) 
Repeat part (a) using the specified partially informative prior discussed in the 
example. Compare results.
(c) 
Rerun your code using a flat reference prior as a default prior for the regression 
coefficients and assess the effect of this choice of prior compared to using 7V(0,1) 
priors for the regression coefficients (i.e., compare to results from part (a)).
(d) 
Rerun the model from the example without the interaction effect using any of 
the above priors. Compare inferences with those obtained in part (a) and in the 
example. Comment.
Exercise 9.2 Revise the model from Example 9.1 to simply involve log(Base) 
instead of standardized log(Base), keeping everything else the same. Modify your 
code in Exercise 9.1 to handle this reparameterization of that model. Run the code 
and compare results with those in the example. Are there any convergence issues 
when performing this analysis? If not, compare inferences to those in the example. 
Except for regression coefficients, the results should be the same, namely RRs and 
RDs corresponding to the same specifications of predictors should be the same up 
to Monte Carlo error. Explain as precisely as you can why this would be the case.
Exercise 9.3 Refer to the Framingham Study and Example 9.2.
(a) 
Using your preferred programming language, write a program that you can use 

266
Bayesian Thinking in Biostatistics
to specify a generic conditional means prior. Use the program to induce the corre­
sponding prior for 0 in a Poisson regression model with two regression coefficients: 
an intercept and a coefficient for a dichotomous variable, such as a treatment indi­
cator. Use independent gamma priors for the two means and induce the prior for 
/М/Ш
(b) 
Suppose your best guesses for the rate of CHD for men and women are 25 and 
20, respectively, and that you are 95% certain that these rates are less than 50 and 
45, respectively. Obtain specific gamma priors that reflect this information.
(c) 
Using this prior, obtain the induced prior for /3 using your code from part (a) 
and plot the corresponding induced priors.
(d) 
Now write code that can be used to analyze the Framingham Study data using 
this specific prior. Analyze the data and compare your results with the means for 
men and women and the corresponding rate ratio given in Example 9.2.
(e) 
Now write code to reanalyze the data using the gamma priors in part (b) directly, 
the way you would have in Section 5.3. Compare results from part (d). They should 
be identical up to Monte Carlo error.
Exercise 9.4 Repeat Exercise 9.3 replacing gamma priors with log-normal 
priors.
Exercise 9.5. Consider the British Doctors Study in Example 9.3 using BUGS. 
The data and some code are on the book’s website for Chapter 9, with a file name 
that includes “British”. In the data, A is age, S is smoking status, and у and M 
give the Poisson counts and offsets, respectively.
(a) 
Write your own code to analyze the data using the flat prior that was specified 
in Example 9.3 (i.e., Pt ~ U(—10,10)). Run the code, and then modify and run 
it using an improper flat prior for /3 (or substantially increase the limits of the 
uniform prior if you are using JAGS). Compare with results in Tables 9.5 and 9.6. 
Comment.
(b) 
Now modify the code in part (a) to handle the model without /З5 and compare 
inferences with those obtained in part (a) for the risks and for RR and RD. Do 
inferences change appreciably? If they do, how?
(c) 
Now treat the variable A (age) as a factor with five categories, which means 
you will have a reference category, perhaps the middle age group, and then four 
variables that take values of 0 or 1 to indicate the other four age categories. There 
will be no opportunity for linear and quadratic terms, but you will need to include 
an interaction between A and S (smoking status) that will involve these four terms. 
Interpret the results and compare them with those from parts (a) and (b).
(d) 
For the three models discussed above, plot posterior median estimates of the 
death rate per 10.000 person years as a function of age group (i) for smokers and 
(ii) for non-smokers. Include the empirical rates on the same plot (i) for smokers 
and (ii) for non-smokers. Comment.

Poisson and Nonlinear Regression 
267
*Exercise 9.6. Suppose you have three independent Poisson counts, (i/i .</■_>. 1/3) 
with rates (А^Аз-Аз) where
log(Ai) = 3i, log(A2) = 3i + 32. log(A3) = 3i + 33.
(a) 
Assume that prior information about the rates can be expressed as A1 
Ga(ai,bi). Show that this prior is a data augmentation prior: in other words, using 
the usual transformation technique, obtain p(,3) from the known joint pdf for the 
rates.
(b) 
Now assume A, LN(ci,di). Obtain the joint pdf. p(3). and argue that it is 
not a data augmentation prior.
(c) 
Write code, with comments, for obtaining the induced prior for 3 in parts (a) 
and (b) above.
(d) 
Now just consider one rate, say. A = e0. Let (a - l)/i> = 5 and c = log(5) so 
that both priors have mode = 5. Obtain b and d such that each prior has a 95th 
percentile of around 20. Plot the two priors for A and compare.
(e) 
Now obtain the induced prior for 3 in each case in part (d) and compare.
Exercise 9.7. Modify and run two versions of the code in Exercise 9.1 to ex­
tend the Poisson regression model to allow for overdispersion in the epilepsy data 
using the parameterizations in expressions (9.5) and (9.6), respectively. Check for 
convergence in each case and compare the Markov chain behavior for the two para­
meterizations. Compare inferences in Example 9.1 with those obtained here. Are 
they sufficiently different to raise concerns about overdispersion?
Exercise 9.8. Modify and run the code in Exercise 5 (British Doctors Data) 
to extend the Poisson regression model to allow for overdispersion using the para­
meterizations in expressions (9.5) and (9.6). Check for convergence in each case 
and compare the Markov chain behavior for the two parameterizations. Compare 
inferences with those obtained in Example 9.3. Are they sufficiently different to be 
concerned about overdispersion?
Exercise 9.9. Refer to the foot-and-mouth disease data in Example 9.5.
(a) 
Either run your own program or use code available on the book’s website for 
Chapter 9 (files with “FMD” in their names) to analyze these data using the priors 
that were specified in the example. Then try different priors, including normal and 
an improper flat prior, to see what effect these other priors have on the results. 
Obtain inferences for the relative rate, comparing the eastern and western regions, 
which are of the same size.
(b) 
It might have seemed unusual not to think of the region’s size as an offset for 
this problem. Now revise your model to use the actual size (which is given in the 
data as the variable Size) as an offset rather than as a covariate. Using this model, 
check on the assumptions as we did in Example 9.5. Compare inferences for the 
eastern and western regions with those obtained in the example.

268 
Bayesian Thinking in Biostatistics
Exerc’ISE 9.10. Code and data for analyzing the FMD data using the zero- 
inflated Poisson regression model in Example 9.5 are on the book’s website in files 
with “FMD-ZIP” in their names.
(a) 
Run the code from the website or write your own program to analyze the 
data using a zero-inflated Poisson model with the priors that were specified in the 
example. Then try different priors, including a normal prior and an improper flat 
prior, to see what effect they have on the results. Obtain inferences for the relative 
rate comparing the two regions (East and West) that are of the same size.
(b) 
Compare the probabilities of zero counts for East and West for a couple of 
same-size regions.
(c) 
Redo the analysis after revising your program to treat the variable Size as an 
offset rather than a covariate for this problem. Actual size is given in the data. 
Using this model, check on the assumptions as we did in the example in the text. 
Compare inferences for East and West.
Exercise 9.11. In our analysis of the FMD data using the zero-inflated Poisson 
regression model, we also obtained a Bayesian version of the Pearson goodness-of-fit 
statistic and corresponding Pearson residuals in equation (9.8). Explain why the 
Pearson residuals and the Pearson goodness-of-fit measure are sensible. Give an 
explicit formula using mathematical notation for the PGOF for the zero-inflated 
model.
*EXERCISE 9.12. Prove that the matrix in equation (9.12) is singular if /3 = 0 
and is non-singular as long as /Зз 0. Hint: Use the standard formula for finding 
the determinant of a 3 x 3 matrix.
* Exercise 9.13. The dugong data are available in the Chapter 9 directory of the 
book’s website. Write your own program or use code from the website to analyze 
the dugong data. Use the prior development in Section 9.4 and prior inputs given 
in Example 9.9, in conjunction with R, to obtain the approximate induced prior for 
the three regression coefficients. Then run the code and report results. Also obtain 
a plot that is similar to the one in Figure 9.5. Perform a sensitivity analysis by 
using at least one other prior to see how the results might change.

Chapter 10
Model Assessment
Until now, our primary inferential goals have been estimation and prediction, and 
we have generally assumed one model for each data set. For the most part, we have 
not explored the possibility that there could or would be very many alternative 
models for consideration. Moreover, thus far we have generally assumed that fitted 
models were reasonable for the data without making checks.
In this chapter we consider the topics of model selection and model checking, 
which are special cases of model assessment. Model selection is a big topic and has 
been studied by researchers over many years. See Kadane and Lazar (2004) [198] 
for a review from Bayesian and frequentist perspectives. We discuss how to choose 
among a finite number possible known models.
One approach to model selection is to obtain posterior probabilities that each 
model is “correct.” Often, the model with the largest posterior probability is se­
lected. In simple cases, this could be choosing among logit, probit or complemen­
tary log-log links for binomial regression data (see Chapter 8); or choosing between 
models with and without interaction between two selected covariates; or deciding 
whether or not to include a particular covariate in the model. We discuss this ap­
proach based on posterior model probabilities in Section 10.1.
Another approach, addressed in Section 10.2, involves the consideration of 
prediction-based criteria for model selection. Such methods are also termed “in­
formation criteria,” and they involve selecting models that satisfy a form of good­
ness of fit that is penalized in different ways for overfitting. The criteria involve 
the sum of a measure of goodness of fit and a penalty. There is an obvious tradeoff 
between the two competing factors, namely, goodness of fit and too good a fit to 
the current data. For example, it is often easy to get a good fit to data in simple 
linear regression modeling if the model includes a large number of polynomial terms 
in the covariates. More generally, model fit is always improved by fitting additional 
covariates, so adding more covariates will appear to fit the data better in terms of 
goodness of fit. Unfortunately, such models will rarely be useful for making predic­
tions about future observations. Moreover, estimates of parameters will be biased. 
Adding a penalty for overfitting improves this situation considerably.
We also discuss hypothesis testing in this chapter, which is a special case of 
model selection. Bayesian hypothesis testing involves a formal decision-making pro­
cess to choose between two (or more) hypotheses. The process begins with a model 
for each hypothesis, priors on the model parameters, and prior probabilities of hypo­
theses being considered. This is followed by the calculation of posterior probabilities 
of hypotheses given the data. At the simplest level, the model or hypothesis with 
the highest posterior probability might be selected. At a more general level not
269

270
Bayesian Thinking in Biostatistics
considered here, one would specify a loss function, and the Bayes decision would 
correspond to minimizing the posterior expected loss.
Once we have selected a model (or models) by one or more criteria, we need to 
assess whether it (they) is (are) reasonable. Goodness-of-fit criteria play a major 
role in this endeavor, with the understanding that models that are overfit may 
be problematic. On the other hand, if the “best” model according to a particular 
criterion does not fit the data well, additional modeling is usually necessary. We 
also give an introductory discussion of model diagnostics (model checking), a rather 
large topic, in Section 10.3.
A considerable amount of model selection involves variable selection in regres­
sion. For example, if a regression model has age and body mass index in it, it may 
be the case that the simpler model with just age in it would suffice. So the corre­
sponding two models can be compared according to the above criteria for selection 
and for model fit.
Finally, we note that a major aspect of model selection involves the consideration 
of science in the process. Medical researchers will often be concerned with the 
attendant biology involved in a statistical analysis to the extent that they require 
that certain variables be included in a model, no matter what the statistical criteria 
appear to dictate. This aspect of model selection cannot be ignored.
10.1 Model Selection Based on Posterior Probabilities and Bayes 
Factors
With a fixed number of models, and when proper priors are used, the most straight­
forward Bayesian approach simply selects the model associated with the largest 
posterior probability. We will see that the Bayes factor (BF), which is a ratio of 
two marginal densities for the data under different models, plays an integral role in 
the expression for these posterior probabilities. In fact, Bayes factors are often used 
by themselves for model selection. They are, however, often difficult to compute, 
can be quite sensitive to prior specification, and are undefined when improper priors 
are used. Nonetheless, in this section we will define, discuss, and use Bayes factors, 
pointing out as needed how care must be taken in their use.
10.1.1 Choice between Two Models
Suppose we have two competing models for data, y. Model Mq has a sampling 
density p0((/ | 0O). and the competing model is Mi with sampling density pi(y | 6i). 
l or clarity, we will often also use the somewhat redundant notation pj(y | fy) = 
/b(.V I ^j.Afj) to make clear that the subscript refers to model Mj. We wish to 
distinguish the functional form of the sampling density under model Mj, namely, 
Pj(‘ I 0j)< fro“i the fact that we are assuming model Mj. For example, one model 
might be a log-normal sampling distribution for the data (Mo ■ у ~ LN(p, er2)), 

Model Assessment
and the alternative model might be a Weibull distribution for the data <Л/> : у 
Weib(a,X)). Then p0(- | в0) is the log-normal density. p,(- | is the Weibull 
density, and we can write у | Mj ~ Pj(y | Oj.Mj). J = 0.1.
The parameters for the models and the model-specific distributional families 
may be quite distinct as indicated above. Alternatively, for two models relating to 
distributions that are in the same family, the parameters in could be a subset of 
the parameters in в\, in which case we would say that the model MQ is nested in 
model M\.
We place prior distributions on 0O and Qi, namely, po(0o) and and we 
have prior probabilities on the two models, q0 = P(Mq) and q\ = 1 - </0 = 1\M\). 
respectively. Consider deciding between the models Mo and M\. We wish to evaluate 
the posterior probabilities of each model, that is, P(M] | y) = 1 - P(A/0 I !/)■ When 
applying Bayes’ theorem to obtain these probabilities, we will require the marginal 
predictive densities for the observed data:
Pj(y | Mj) = f Pj(y | ejjpj^dOj, j = 0,1. 
(10.1)
We regard the marginal density in equation (10.1) as the (marginal) “plausibility” 
of the observed data under model Mj. It also has been termed the (marginal) 
“likelihood” of the model, Mj, given the observed data. With a flat prior for 0j, 
the marginal density Pj(y) is not guaranteed to exist, and often does not, leaving 
us with no way forward. Consequently, we always assume that priors are proper 
when obtaining posterior probabilities of different models. We note that while we 
are using traditional terminology, the marginal predictive density has more recently 
been called the “prior predictive density”
Applying Bayes’ theorem,
} = 9iPi(y) 
?opo(p) + qipi(y)'
Without any further input, we would tend to choose model Mi if P(Mi | y) > 0.5, 
and model Mo otherwise. Of course, if we were very concerned about making a 
mistake of, say, selecting Mi when in fact the model Mo is the true model, we 
might want to make it more difficult to select Mi by increasing the threshold 
for model selection from 0.5 to a larger value, perhaps 0.95. In this instance we 
would be at least 95% certain that Mi was the true model and we would have 
Pr(Mo | y) < 0.05. A straightforward procedure would select Mi if P(Mi | у) > к 
for some к > 0.5.1 Making a decision in this way is equivalent to selecting M] if 
the posterior odds satisfy the criterion P(Mi | j/)/{1 - P(Mi | j/)} > k/(l - k).
As in equation (10.2), Bayes’ theorem also leads to
} <7oPo(y)
gopo(p) + giPi(p)
‘This kind of thinking can be formalized with a decision-theoretic criterion.

272
Bayesian Thinking in Biostatistics
Now we can write posterior odds for Л/j as
| у) = giPi(y)/{goPo(y) + QiPi(y)} 
P(Mq I y\ <7оРо(у)/{?оРо(у) + 9iPi(j/)}
Posterior odds
= <?iPi(y)
<?oPo(y)
_ 
P(Mt) pi(y | AfQ 
f 103)
JW Ро(У I MO •
Prior odds Bayes factor
Thus, the BF is the factor by which the prior odds can be multiplied to update to 
the posterior odds, and this factor is free of go and gi. Rewriting this, we see that 
the BF is the odds ratio of posterior to prior odds for Mi versus Mo- To be specific, 
we denote this by BFiq:
. P(Mi | y) / P(Mi) 
10 P(Mo|y) / P(M0)-
Similarly, BFoi stands for the ratio of posterior to prior odds for Mo versus Mi and 
equals the reciprocal of BFiq. Revisiting equation (10.3), from the final expression 
in it, the BF can also be seen as the ratio of marginal densities of the data under Mi 
and Mq, namely, the data densities after integrating out the model-specific para­
meters with respect to their respective priors: pj(y | Mj) = fe, Pj(y | 0j, Mj)pj(0j | 
Mj)d0i, j = 0,l. 
’
Back to choosing a model. If the prior odds are 0.5/0.5 = 1, and к = 0.5, then we 
would select model Mi if BF > 1. With a different threshold, say with к = 0.95, 
we would select model Mi if BF > 0.95/0.05 = 19, which is considerably more 
stringent. Now, we would select Mi if the plausibility of the observed data under 
Mi were at least 19 times greater than the plausibility under Mq- Another way to 
say this is: we would select Mi if the post-data odds for Mi versus Mq were at least 
19 times greater than the pre-data odds for it.
Sir Harold Jeffreys was a proponent of the BF and suggested some levels of 
evidence to aid interpretation of BFs when comparing models. He proposed the 
admittedly arbitrary grades displayed in Table 10.1 in terms of hypothesis tests. As 
before, we consider model Mi to be in the numerator and model Mq to be in the 
denominator of the BF. Here is an example of calculation and use of Bayes factor.
Example 10.1. Recall the VetBP data set (in Sections 2.3 and 2.4, for example) 
regarding blood pressure in veterans: в is the probability that a random veteran 
has uncontrolled hypertension. Consider testing Hq : в < 0.5 versus Hi : в > 0.5. 
Thus set Qo = (0.0.5] and Qi = (0.5,1). The data are binomial with n = 404, and 
the number of veterans with uncontrolled hypertension is 184. With a (7(0,1) prior 
on в. qo = qi = 0.5. and 0 | 0 G Qo ~ (7(0.0.5) and 0 | 0 G Qi ~ (7(0.5,1). Using

Model Assessment
TABLE 10.1: Jeffreys' levels of evidence
BFi0(y) < 1 
1 < BFio(y) < 10^2
101/2 < BF10(y) < 101
101 < BFjo(y) < 102
102 < BF10(y)
Model .Mo supported
Evidence against Mq.
but not worth more than a bare mention
Evidence against Mo substantial
Evidence against Mo strony
Evidence against Mo decisive
(10.1) and R to carry out the computations:
Rr _ Jo's LikWPiWM 
"Г 10 — _n к
Jo Lik(e)po(6)d0
Jo.5 01+184-1(i - 0)l+4O4-ia4-l/qid0 
JO-5 01 + 184-1(1 _ 0)1+404-184-1/^0 
= (1 - pbeta(0.5,185,221))/pbeta(0.5,185,221) = 0.038,
where pbeta(0.5,185,221) = 0.963 using the Rfunction that gives the area to 
the left of 0.5 for a 5e(185,221) distribution. As BFio = 0.038, the plausibility 
of the data under Mo is about 26 (1/0.038) times what it is under Mi. Moreover, 
since q0 = Qi = 0.5 means that the prior odds for Mi are taken to be 1, P(Mo | 
y) = 26/(1 + 26) = 0.963. We would thus likely accept the hypothesis that the 
proportion of veterans with uncontrolled hypertension is less than 0.5.
Although this example was designed to illustrate explicit calculation of the 
BF, we note that for most model selection problems it is necessary to use Monte 
Carlo computational methods to obtain posterior probabilities and/or BFs, a topic 
considered in Section 10.1.4.
10.1.2 Cautions Regarding Bayes Factors
Bayes factors can be misleading under certain circumstances. In one such case, 
the situation of testing a point null Ho : 0 = 0 against the alternative hypothesis 
Hi : 0 / 0, it turns out that BFw can depend heavily on the choice of prior, 
especially when very diffuse priors are used. Of course, an often stated goal of 
specifying diffuse priors is to minimize the effect of the prior on the posterior. But 
with BFs, overly diffuse priors can have a huge impact on inferences. This issue has 
been discussed in the literature extensively for some time (e.g., in [17, 28, 224]).
Diffuse Priors and Bayes Factors. With improper priors, the BF is not a defined 
finite number, as the marginal densities in its defining ratio are not themselves 
defined due to the prior not integrating to a finite quantity. It follows that we should 
not use overly diffuse proper priors either. For example, suppose Y ~ N(0,1), and 
we want to decide between Hq : Y ~ 7V(0,1), 0 = 0 and Hi : Y ~ jV(0, 1), 0 ~ 

274 
Bayesian Thinking in Biostatistics
N(no,<7$). We specify the prior probabilities P(Hq) = 0.5 = P(Hi). It is easy to 
show that the marginal predictive distribution for Y | Hi is N(jio, 1 + <Tq). Thus
1 
c-0.5Kw-mo)2/(1+^)1
Let us suppose the expert’s best guess for в under the alternative is до = 1, but that 
they are incredibly unsure about this guess, so they select &o = 107. Imagine that 
у = 5 is observed. The classical two-sided p-value for testing Ho is 2(1 — Ф(5)) == 
5.7/107, so virtually any non-Bayesian would be rejecting the null. However, BFio = 
0.027 and consequently P(Hq | у = 5) = 0.974 as the prior probability of Hq is 
taken as 0.5. This illustrates the so-called Lindley paradox [224] where a Bayesian, 
albeit with what we would term a silly prior for any realistic situation, would 
emphatically accept the null hypothesis while the classical analysis would suggest 
its strong rejection. The dominant point here is that the result very much depends 
on the prior specification. If we were to plot the prior for д, it would be difficult to 
distinguish it from a constant but improper prior.
Now suppose that our expert was quite unsure about the actual value of в. 
When pressed, they gave a best guess of 1.0. After some thought and subject­
matter input, they said that в is between -4 and 6, but they would not attach a 
probability to the statement that в is in this interval. With more reflection, they 
were willing to assert that they were virtually certain that в is in the substantially 
wider interval, (-9.3,11.3). Furthermore, they were ultimately comfortable with 
the assertion P(—9.3 < в < 11.3) = 0.99. Assuming that a normal distribution 
corresponds to their certainty about the value of 0, 0 ~ A(l,16) matches their 
belief as expressed by the probability statement. With this prior, BF10 = 40,000 
and P(Hi | у = 5) = 0.9999754. Repeating the calculation with до = 0 in place 
of 1.0 gives virtually the same result. In the previous paragraph, we found that 
BFio = 0.027 with a diffuse prior. So the BF is heavily influenced by the choice of 
prior. It is essential that careful effort be made to specify a scientifically meaningful 
prior and not resort to diffuse priors when using BFs.
Testing Hypotheses about Parameters. Consider, in general, a sampling den­
sity p{y I 0) and a continuous prior density p(0) defined on a parameter set Q. 
Testing the null hypothesis Hq : 0 e Qq versus the alternative H] : 0 e Qj, where 
Qi is the complement of Qo relative to Q, covers a large majority of hypothesis 
testing situations. As before, we treat hypotheses (Hj) and corresponding models 
(Afj) interchangeably. Assuming qj = F(0 6 Qj) = p(JT)dd are strictly positive 
for j = 0.1. the prior under Hj is then
Pj(0) = p(0 I 0 e QJ = p(0)/9j, 0 e Qj, j = 0,1.
A typical instance of this general scenario involves a scalar parameter, 0, with model 
Ma corresponding to the hypothesis Hq : 0 < cq. and model Afi corresponding to the 
alternative hypothesis. H] : 0 > cq. Another instance with two scalar parameters,

.Model Assessment
01,02, is Hq : 
< #2 versus Hi : 0i > #2- Both of these fit the above framework as
long as qo and qi are both positive.
On the other hand, in the case of a point null hypothesis, like : 0 = <‘o. 
or 0i = 02. the above description requires modification as = 0. We must. then, 
specify a prior probability qo € (0.1) that reflects our belief that the null hypothesis 
is true. If Hq is a simple hypothesis, so that Qo contains a single point, then it 
completely specifies the sampling distribution for the data. In this case, we can 
specify the prior under the alternative H{ as pi(0) = p(0) for all 0 e Q. This works 
since fnop(0)d0 = 0. If, however, Hq is not a simple hypothesis, such as 0} — 0-2. 
further modifications are required. We will not consider such hypotheses in this 
book but instead recommend the excellent treatment by Berger and co-authors 
[29, 31, 32, 92] to interested readers.
10.1.3 Choosing among Multiple Models
Let pj(y | 0j) and Pj(0j) be the probability density functions for the data and the 
prior under model Mj, respectively, and let qj = P(Mj), for j = 0,1,... ,r. Define 
the marginal predictive densities for all r + 1 models for the data as in equation 
(10.1). Then
| y) =
QjPjty) 
Y,k=oQkPk(yY
(Ю.4)
As before, a straightforward procedure would be to select the model with the largest 
posterior probability.
If qj = l/(r + 1) for all j, we could simply pick the model with the greatest 
marginal likelihood or plausibility, pj(y | Mj). It is common in this instance to 
obtain Bayes factors against Mo, namely, BFjo = Pj(y)/po(y) for j = l,...,r. 
We would then select the model, say Mi, that achieves maxJ=i....rBFjo = BFio,
provided BFio > 1, and model Mq if this is not the case.
10.1.4 Computing Bayes Factors via Sampling
Recall that the Bayes factor, BFio = Pi(y)/po(yY is the ratio of the two marginal 
predictive densities for the data under models Mi and Mq, respectively. We illustrate 
with i = 0,1 for simplicity, and we use 0q and 0i to denote parameters from the 
two models, even if the two families are distinct, such as gamma and Weibull.
Bayes factors can be difficult to compute analytically but can, in principle, be 
numerically approximated. Specifically, we sample 0$k\ к = 1,..., m. from the prior 
density pi(0i) and use the approximation
₽.(») = -У>(1/1 
(10.5)
Since BFs are actually only evaluated for the data that are observed, the computa­
tion is manageable. Also recall that if the priors were improper, the above discussion 

276
Bayesian Thinking in Biostatistics
could be meaningless. Moreover, if the priors are overly diffuse, convergence of the 
above average to the marginal could be difficult to achieve in practice.
If во and Of have the same dimension and a common parameter space, say Q, 
a more efficient computational scheme is available by applying Bayes’ rule after 
substituting 3q for 0i in pi(-), etc. Write
„„ _ fgPl(y I ^1)?1№)<W1
10 /npo(m)po№)<»o
po(a)
Jq Po(y I ^o)po(^o) 
= [ ш(во)ро(во I y)de0.
Jn
The third line follows from the second line by applying Bayes’ theorem: ро(во | y) = 
Po(y I #o)Po(0o)/po(y)- The requirement to have the same parameter space is needed 
at the third and fourth equalities for the integrals to be meaningful. Sampling в^к\ 
к = 1,..., m, from the posterior density ро(во | y), we obtain the approximation
вг,о-™£ро^)Ро(ё=-£ (o ’•
Thus, we can obtain the BF by post-processing the posterior output (samples from 
po(#o I y)) fr°m the analysis of Mo and calculating a simple arithmetic average. 
This is easily done in R. If more convenient for sampling, the roles of Mo and Mi 
can be reversed so posterior samples from Mi could be post-processed instead. Of 
course, in this case the definition of w(-) must be modified accordingly.
For good numerical results, the function w(-) must be stable, as was the case in 
importance sampling (Chapter 4). A successful implementation may require a sens­
ible reparameterization of one or both models. Typically, comparison of regression 
models of equal dimensions diminish the need for this. An example is link selection 
in binary regression. For the case of the trauma data discussed in Chapter 8, con­
sider these link functions: logistic (MJ, probit (M2), and complementary log-log 
(М3), as in Section 8.6. Bayes factors can be used to indicate which of the three is 
most appropriate.
A particularly useful prior specification here is the conditional means priors 
(CMPs). In prior elicitation, the CMP allows us to focus on interpretable prob­
abilities. kix’ping away from regression coefficients, which have varying meaning 
depending on the link function. Moreover, the posterior simulation monitoring can 
also remain focused on these probabilities, as they can be treated as link-invariant 
parameters. To implement CMPs in model selection, recall that we begin with a 
selection of covariate vectors ii that are convenient for eliciting di = F(Fj I 
Note that those в, equal expit(i-|3) for logistic, Ф(хг/3) for probit, and expfe'd1’*3)} 
for the complementary log-log. Inverses of these functions define 0s in each model.

Model Assessment
This single specification of priors for the 9s can be used to induce appropriate 
but distinct priors on regression coefficients for the three' link functions. With a 
little effort this CMP approach can be extended to many other model selection 
applications.
Example 10.2. Bayes Factors for the LE Data. We want to compare link 
functions for modeling the risk of lymphedema (LE). We are considering link 
functions corresponding to models Mi. M2. and given above. The code in 
LymphedemaBF.txt under Chapter 10 on the book's website illustrates how one 
can calculate the BF to compare model M3 (complementary log-log link) to 
(logistic link). We have used the method described above for computing the BF.
Suppose we have elicited a prior for the risk of LE for the women grouped by 
high and low node counts, as in Example 8.6. Let 9X be the elicited prior risk for 
the high node count group, with corresponding prior uncertainty characterized by 
a beta distribution, 6i ~ Be(ai,6i). Similarly, 02 is the elicited risk for the group 
of women in the low node count group, with 02 ~ Be(a2,t>2). The elicited prior on 
the risk scale induces a prior for the regression coefficients in the logistic model, 
because of the relationship between the logits and the coefficients. In particular,
Г1 lj = /logit(^1)\ 
= ГО 11 /logit(0!)\
[0 1] \/32J 
\logit(02)/ 
\J32) 
[1 -1J \logit(02)/ •
We then use the above to determine the prior for the regression coefficients. In the 
BUGS code, we have set ai = a2 = 2.044 and Ьг = b2 = 13.006. The matrix (X')-1 
in the code is the matrix that, on the right-hand side of the equation, premultiplies 
the vector [logit(0i), logit(02)]'. We can use a similar equation for the probit and 
complementary log-log links by replacing logit(-) by the appropriate cdf in each case 
(Ф(-) and log(— log(-)), respectively). As a result of running the code, we obtained 
BF = 1.004. From the statistical perspective, there is no difference between the two 
models. We prefer the logistic for better interpretability of its regression coefficients.
Change of variables from в to gives the induced prior for /?. For example, 
under the complementary log-log transformation we get
pOT « []{1 - exp(-et«e)}“'-1{exp(-ei"’)}t'ei>s.
1=1
However, this expression is not needed in the BUGS code, as priors can be specified 
via transformations in BUGS.
Example 10.3. Trauma Data. For the trauma data, we computed the BFs under 
our informative priors for the same three link functions we discussed above. The 
results, using code similar to that for Example 10.2, were BF2i = 1.05, BFi3 = 20.7, 
and thus
BF23 = BF21/BF31 = BF21BF13 = 1.05 x 20.7 = 21.7.
There is a suggestion against the complementary log-log model (Л/3), but there is 
little to choose between the logistic and probit models. Since logistic models are 
easier to interpret, we prefer the logistic.

278
Bayesian Thinking in Biostatistics
10.2 Model Selection Based on Predictive Information Criteria
In this section we discuss methods of model selection that are based on how well a 
model might predict future observations. We are in agreement with Seymour Geisser 
[127] that statistical inferences should ultimately focus on observable quantities 
rather than on unobservable parameters that often do not exist and have been 
incorporated largely for convenience. He argued that the success of a statistical 
model should be measured by the quality of the predictions made from it (see 
Geisser [123, 127] and Christensen and Johnson [78]). In this section we discuss 
model selection based on such criteria.
There is a range of predictive model selection criteria that can be regarded 
as approximations to a particular theoretical criterion. These include the Bayesian 
information criterion (BIC), the Akaike information criterion (AIC), the log pseudo­
marginal likelihood (LPML) criterion, the widely applicable information criterion 
(WAIC), and the deviance information criterion (DIC). We discuss their common 
motivation and then present the different criteria themselves.
Consider one or more initial parametric models for the data at hand. Of course, 
the “true” model for the data may or may not be any of these. But the hope and 
expectation is that there will be one that somehow reasonably reflects the truth. 
It is possible that more than one, or that none, would. To quote Box [44], “All 
models are wrong, but some are useful.” A simple definition of useful might be 
“good enough.” In what follows we will assume a finite collection of models from 
which we want to select one. Individual models in the collection could possibly be 
different parametric families for the sampling distribution of the data.
We begin with p(y) as the probability density function for the “true” probability 
mechanism that generates the observed data у = (pi,...,pn), which could be a 
member of the collection of models under consideration. Let у = (y^,..., yn) be 
a future data set of the same size, n, that we assume to be generated by this 
same mechanism. Modeled and “true” distributions for yi and & may depend on a 
covariatc vector Xj. Now consider predicting the new data set, y, that is just like 
the current data y. For example, we may have a standard linear model for the data, 
У, = Xifl + Ej. and wish to predict & = Xj/3 + e*,  with e, and e* all distributed as 
independent 7V(O.tr2) random variables. For simplicity, we use notation that hides 
the fact that the current data and future data may not be identically distributed, 
which occurs in regression and other modeling situations. We assume that the y^ 
are independent, conditional on parameter values for any specified model. From 
here on. we assume the collection of models under consideration is finite, say {Mj : 
.) = 0.1.........J}. For simplicity of notation, we often refer to model Mj using the
subscript j.
One measure of the magnitude of the difference between two distributions is 
the Rollback Leibler divergence (KLD). It provides a measure of how different 
one distribution is from another. For two densities, p(z) and q(z). supported on a 
common sample space. KLD is the expected logarithm of the ratio p(z)/g(z), with 

Model Assessment
expectation taken under p(z):
KLD(p.,) = I log (^) Mdx = - J log W
The KLD is always non-negative, and is strictly positive unless the two density 
functions are virtually identical. If the two densities are widely discrepant, the 
value will be large. The KLD, however, is not a distance metric, since it is not 
symmetric in its arguments and it does not satisfy the triangle inequality.
Recall that the predictive density based on a candidate model. .V,-. is pj(ij | y) = 
f Pj(.y I 0j)p(0j I y)d6j. If we knew the “true” density p( ). we could use the KLD 
to assess the discrepancy between the “true” predictive density and one under each 
candidate model, that is, between p(y) and pj(y | y) for all j. We would then select 
the model, j*,  that has the “closest” predictive density to that from the true model 
in the Kullback-Leibler sense, that is, the one that has the smallest KLD across 
models j = 0,1,..., J. Of course, we do not know the true model. Nonetheless, let 
us define an idealized criterion based on KLD called the Kullback Lcibler criterion 
(KLC), namely,
KLC, = KLDW,P)(-1»)) = Ур(Й log 
(10<i)
Again, since the true model is unknown, it is not possible to calculate KLCj, 
much less minimize it to find model j*.  The conceptual goal now is to find a 
surrogate for the KLC that does not depend on unknown p(-) and that can be 
used to find the model that is “closest” to the true model in the collection under 
consideration. We proceed by replacing the KLC with what amounts to an estimate 
of it and then minimizing that approximating criterion.
Since KLCj can be written as f p(y) log[p(y)]dy - f p(y) log[pt(y | y)]dy, and 
since the first integral is free of the model specification, it is sufficient to maximize 
the second term instead of minimizing the KLD. The second term is called the 
negative cross entropy (NCE):
NCEj = /p^log^^ I V)]dy = Ep{log[pj(y | j/)]}.
The next step considers a simplified version of this quantity that Gelman et al. 
[135] term the expected log pointwise predictive density (ELPPD), defined as
ELPPDj =^EP {log[pjfa | y)]} . 
(10.7)
i=l
If Pj(y | y) = П;Pjfa | y), then NCEj = ELPPDj. The ys are generally de­
pendent, however, often without and always with conditioning on the data у at 
hand. The simplification is thus made on purely practical grounds. According to 
this criterion, we are looking for the model that does the best job of predicting new 
responses that are modeled to be stochastically like the actual data responses when 

280
Bayesian Thinking in Biostatistics
the new responses are generated by the “true” model. Unfortunately, the problem 
of not knowing the true model persists as the expectation is with respect to the 
unknown true model p(-).
To overcome this obstacle, noting the data у = (yi, • ■ • ,yn) are actually drawn 
from the “true” model, Gelman et al. [135] suggested an alternative to equation 
(10.7) by defining the log pointwise predictive density (LPPD),
(10.8)
1=1
as a computable criterion. It is the sum of the logarithms of the predictive densities 
for the observed yi, which can be regarded as an approximation to equation (10.7). 
It is also an approximation to the log of the M-criterion defined in Laud and Ibrahim 
[217], again based on ignoring the dependence in the components of у | y.
If Pj(yt I y) > Pi(yi I У) f°r all models I / j and all observations i, then we 
prefer Mj to all other models. We would therefore want to select models with large 
LPPDj. One possible problem with this criterion is that observation yt is being 
predicted using all of the data, y, including the corresponding y^ In regression (and 
other non-exchangeable) models, using a fit of the model that includes the obser­
vation whose future counterpart is being predicted could lead to overly optimistic 
predictions. It is best to avoid this possibility, as will be the case with the next 
criterion, after which we also introduce other “information” criteria.
10.2.1 Log Pseudo Marginal Likelihood
A natural way to adjust overly optimistic predictions is to substitute Pj(yi | y^) 
for Pj(yi | y) in equation (10.8), where y^y denotes the data with y, removed. 
The method of predicting an observation based on the reduced data set that does 
not include it is called “leave-one-out cross-validation.” The corresponding model 
selection criterion is termed the log pseudo-marginal likelihood,
LPML, = jSogfota I !/(<))]. 
(Ю.9)
1=1
which was proposed by Geisser and Eddy [128]. The LPML criterion (10.9) has 
seen increased popularity, in part, because of the relative ease with which it can be 
computed from MCMC output. It is also intuitive, involving prediction of observed 
data based on a criterion that leaves out the observations (one at a time) that are 
being predicted.
For a model. the term Pj(yi | */(i))  is also called the “conditional predictive 
ordinate" (CP()t) [124], which also has other uses (see Section 10.3). Gelfand and 
Dey [129] showed that CPOi and thus the LPML are easily approximated. They 
first showed that for model Л/j (if the ys are conditionally independent given 0),
cpo’'4{l^}p^d(l- 
(1010)

Model Assessment
Then, using a posterior sample (0(1)........№). where 0U) ~ pj(O | «/). we haw the
following Monte Carlo approximation:
Since
LPMLj = log JJp/t/i | y{i}) = log JJCPOj. 
i=l 
i=l
it is easily approximated using equation (10.11).
Geisser and Eddy [128] also discussed the calculation of a pseudo-Bayes factor 
(PBF) for comparing two models, say Mi and A/o, namely
PBFio = eLPMLi~LPML° . 
(10.12)
While the PBF does not enjoy the simple interpretation of a Bayes factor as the 
ratio of posterior to prior odds (as explained in Section 10.1), it approximates the 
BF in large samples. At the very least it provides a predictive quantification of how 
well one model fits the data compared to another.
Construction of CPO Statistics. CPO and LPML statistics can be computed 
using BUGS, JAGS or other Bayesian software in conjunction with R if needed. For 
a given linear regression model j, the values of CPO~^ can be computed directly in 
BUGS by defining nodes for Pj(!/i|/?,T)-1. In BUGS, for example, one could include 
the statements
for(i in l:nMCPOinv[i]<-
sqrt(2
*3.
14159/tau)
*exp(0
.5»tau
*pov(y[i]-mu[i]
,2)) }
in the model code, where the response is BUGS will output the posterior 
mean of each CPOinvEi], which gives a numerical approximation to {CPO)~^ = 
^.rlylp/l/il^.T)-1], for i = l,...,n.
The arithmetic needed to obtain LPMLj can be done in R by taking the sum of 
the logs of the approximate CPOij values. Running BUGS from R from the outset 
makes this process simple. The R commands are:
CPO <- l/y.fit$meantCPOinv S CPO is a vector of length n 
LPML <- sumQog(CPO))
For non-normal models, Ру(р»|^,т)-1 should be replaced by appropriate code 
for the corresponding predictive density p/pi]#)-1-
10.2.2 Akaike Information Criterion
The Akaike information criterion [4] is a frequentist criterion that is widely used 
and has been broadly studied for its properties. From a predictive point of view, 
one can begin with the frequentist analog of LPPDi by substituting the plug-in 
density estimate, pj(yi 10,), for Pj(yi | y) in equation (10.8), where 0j is the maxi­
mum likelihood estimate (MLE) of 0 under model Mj. This frequentist “predictive” 

282
Bayesian Thinking in Biostatistics
criterion, log{pi(y3 | 0<)}, also results in overly optimistic predictions of the j/,, 
as in the Bayesian case. A “corrective” adjustment would subtract a penalty for 
this over-optimism. This penalty is kj, the number of parameters in model M3. This 
adjustment leads to what we call a predictive version of the AIC:
In the literature, this predictive version is modified by multiplying it by —2. This 
results in
AICj = —2 J21og[pj(j/i | A,)] + 2kj = -2\og{Lik(6i)} + 2kj,
which is minus twice the log of the maximized likelihood under model Mj plus 
twice the number of model parameters. Instead of making this term as large as 
possible, we use the original criterion, which is —2 x AlCi by convention, and find 
the model that makes this term as small as possible, to be consistent with the 
overall approach.
The goal with this criterion is to make it as small as possible, subject to not 
overfitting. Here adding twice the number of model parameters makes the criterion 
larger, and increasingly penalizes models that include a larger number of para­
meters. The term “overfitting” arises since, with a fixed sample size n, letting kj 
grow due to expanding models results in decreasing the first term (the goodness-of- 
fit measure). Too many parameters in a model will fit the current data better but 
decrease actual predictive ability in future samples. Too few parameters will result 
in poor goodness of fit. The AIC attempts to strike a balance between these two 
characteristics of a model fit to a data set.
10.2.3 Bayesian Information Criterion
Historically, one of the most important model selection criteria has been the 
Bayesian information criterion, also called the “Schwarz information criterion,” pro­
posed by Schwarz [283]. A neat feature of the BIC is that it can be used to provide 
a large-sample approximation to the Bayes factor for comparing two models.
The original derivation of the BIC established that selecting the model with the 
largest posterior probability was equivalent, with large samples, to selecting the 
model that maximizes
Eiog{ftta 
.
This looks just like the predictive version of the AICj criterion, except that the 
adjustment term has a penalty multiplier of log(n)/2 instead of 1. The larger n is, 
the greater the adjustment.
As with the AIC. this criterion is also generally multiplied by —2. so that
BICj = -21og{L/A’(0j)} + log(n)fcj,

Model Assessment
283
which is still a predict ion-based criterion that we wish to minimize. Larger sample 
sizes result in larger penalties for overfitting. The particular penalty terms for A1C 
and BIC arise naturally because of their derivations.
Cavanaugh and Neath [67] have shown that, under general conditions.
-21og{p/y)} = -2 log{pj\y | fl,)} + kj log(n) = BICj, 
for large n. where p/-) is the marginal predictive pdf for the observed data under 
Mj. This implies that, for large n,
—2\og(BFjj>) = BICj-BICy
= —21og{p_,(y | Oj)/pr(y | 0y)] + (к} - Ay)log(zz).
and thus BFjj’ = 
Integration is thus not required for the aj>-
proximation.
Consider the special case with j = 0 and j' = 1 where Mq is a special case of 
Mi; that is, when Mq is nested in the model Mi, resulting in ко < kj. If we let 
these models correspond to hypotheses Hq and Hi, respectively, the alternative hy­
pothesis is that M\ holds but Mq does not. In this case, we see that -2 log(BF0i) is 
minus twice the log of the frequentist generalized likelihood ratio (LR) test statistic 
for testing Hq versus Hi, minus (ki — ko)log(n). The standard large-sample fre­
quentist LR test rejects Hq in favor of Hi if -2 log(LR) is larger than a pre-selected 
quantile of the X^-ko distribution. There is, however, no generally accepted cri­
terion for deciding how small BFqi should be before we would conclude that H\ 
was true. Note as well that the additional penalty term in the BIC could lead to 
different inference using BIC than the classical LR test. In fact, the LR test will 
tend to favor the more complex model. Avoiding this is one of the motivations for 
the information criteria we are discussing.
A confusing feature of the BIC is that it does not depend on the prior, pj(0j), 
leading one potentially to think it is not actually Bayesian. But this is just an 
interesting aspect of this particular asymptotic result. The only assumption about 
the prior is that it must be bounded above in general, and bounded below in a 
neighborhood of the “true” value of в у, in other words, the prior must not exclude 
the “truth” as a possibility and cannot attach too much weight to any particular 
value.
10.2.4 Widely Applicable Information Criterion
Watanabe [346] proposed an alternative model-fitting criterion that adjusts for over­
fitting. Watanabe’s measure is called the widely applicable information criterion. 
Computation involves subtracting a term from LPPDj to make it less biased for 
ELPPDj, which amounts to adjusting equation (10.8) for over-optimism.
Construction of the WAIC requires a numerical approximation to the predictive 
criterion LPPDj = 52»l°g{Pj(yi I y)}- This is accomplished using an MCMC 
sample from the posterior, ((№,..., where ~ Pj(6 | y), to obtain
Pj(yi I У) = | I 0(Z)) = PjtVi I У)-

284
Bayesian Thinking in Biostatistics
The Watanabe penalty adjustment is
PWj = 52 Va4l« togObfa
*
 I ВД- 
1=1
*lt is interesting that both Dj and D(0*J‘'yes) can be regarded as goodness-of-fit statistics from 
different points of view.
A nice feature of this adjustment is that it will always be non-negative. Gelman et 
al. [135] discuss two possible penalty adjustments but argue in favor of this one, 
since they expect numerical approximation to it to be stable. The predictive version 
of the WAIC is log{pj(t/i | j/)} ~pwj ■ We again multiply by -2 to be consistent 
with the other information criteria, and write the WAIC as
WAICj = -2^1og{pJ(2/i | t/)J + 2Plyr 
(Ю.13)
Watanabe [346] has shown that, under some conditions, WAICj = LPMLj = 
AlCj, for large n.
10.2.5 Deviance Information Criterion
Another model selection criterion is the deviance information criterion due to 
Spiegelhalter et al. [304]. They motivated the DIC as follows. In the statistical liter­
ature, the deviance function is defined as D{0) = -21og{Lifc(0)J, which is usually 
regarded as a goodness-of-fit measure (i.e., discrepancy from a perfect fit to data). 
Making D(0) small is equivalent to making the predictive criterion log{Lifc(0)J 
large. For assessing model Mj, the authors defined
DICj = 
+ ро5 = Dj + рог 
(10.14)
Here, the penalty is a measure of model complexity (or the effective dimension of 
the model) given by
PO, = —2 {£?^|vlog{p,(y | 0,)) — log{p^(y | 0®aye8)}} 
= Dj - £>(0®ayes),
which is the posterior mean deviance minus the deviance evaluated at the posterior 
mean.2 By Jensen’s inequality, pui is non-negative, provided Pj(y | dj) is log-concave 
in 6j. The motivation for this penalty is that, for the normal fixed effects linear 
model with k regression coefficients and known variance, the penalty reduces to k. 
Moreover, for a generalized linear model with к regression coefficients, a second- 
order Taylor expansion shows that the penalty is approximately к.
We now consider the predictive version of this criterion, which is analogous 
to that in the AIC where pj(t/j | 0j1L) was substituted for Pj(yi | y) in equation 
(10.8). Here, if we substitute Pj(yt | 0®ayes) into equation (10.8), where 0®ayes is 
the approximate posterior mean of в under model Mj based on an MCMC sample, 

Model Assessment
285
then the predictive criterion is ^2'1=1 \og{pj(yt | 0°aycs)} = log{pj(</ | 0Bayes)}. This 
is simply the log-likelihood function evaluated at the posterior mean instead of at 
the MLE.
Using the original definition of DIC in equation (10.14) and that of pD just 
below it, we rewrite equation (10.14) as
DICj = D(^Bayes) + 2pD]. 
(10.15)
which equals
DICj = -21og{Lifc(0Bayes)} + 2pDj. 
(10.16)
This is the predictive version of the DIC, since it is -2 times a bias-adjusted 
approximation to the LPPD, which is a goodness-of-fit measure plus a penalty. 
One can easily use a random sample from the posterior distribution (e.g., samples 
via MCMC) to compute the DIC. Since the DIC is already available in packages 
like BUGS and JAGS, we use it fairly often in this book.
An alternative measure of model complexity is half the posterior variance of the 
deviance, which can be estimated as
1 
1 1 M 
M V
P'D1 = 5Var(D((>,)) = 
- <VM) £ P(0”>) 
.
m=l I 
m=l J
The formula uses an MCMC sample from Pj(0j | y). An advantage of p'D. over the 
earlier measure is that it cannot be negative.
*Caveat. The quantity poj corresponds to the effective dimensionality in a nor­
mal linear hierarchical model. The justification starts to get a bit fuzzy as one 
deviates from exponential families. There will be models for which poj does not 
represent model dimension. It is not recommended, for example, for hierarchical 
models, a topic in Chapter 14; or if poj is negative in which case the DIC is not a 
useful criterion. An additional concern is that po is not invariant to reparameteri­
zation.
10.2.6 Model Selection in Linear Regression
We now illustrate some aspects of model selection in the context of linear regression, 
demonstrating the use of LPML, PBF, DIC and BIC. Candidate models are all 
linear regression models, distinguished by different covariate combinations and/or 
transformations of predictor variables. We note that the response (or dependent or 
outcome) variable is not transformed. It is not possible to compare two models if 
the dependent variable is transformed differently in each, such as where one model 
has the original dependent variable and the other model uses its log transformation.
Recall that we have to obtain LPML by post-processing the output after run­
ning the code in BUGS, JAGS or Stan. This is easily accomplished by driving such 
software from R as discussed in Appendix C. The PBF is obtained by simply using 
its formula once the LPML has been computed for the two models. The DIC is 
easily obtained as direct output from BUGS or JAGS.

286 
Bayesian Thinking in Biostatistics
TABLE 10.2: FEV model selection statistics. S = Smoke, A = Age
Model
Predictors
LPML
DIC
BIC
(1)
S
-394.7
789.2
800.7
(2)
A
-356.5
712.6
724.1
(3)
S, A
-356.3
711.9
727.2
(4)
S, A, SA
-351.5
702.4
721.5
(5)
S, A, A2, SA, SA2
-350.7
700.3
727.2
(6)
S, A, SA, (1 - S)A2
-349.8
698.4
721.4
Example 10.4. FEV data of Example 7.3. Table 10.2 gives LPML, DIC, and 
BIC statistics for a variety of models predicting FEV from the dichotomous variable 
S (Smoke) and the continuous covariate A (Age). Code is available on the book’s 
website with filename FEVmodelselect.txt under Chapter 10. Models (1) and (2) 
are the simple linear regression models, which in the case of model (1) is a two- 
group model. Model (3) is the ANCOVA (parallel lines) model. Model (4) includes 
the interaction, yielding separate straight lines for smokers and non-smokers that 
have different slopes. Model (5) has separate quadratic trends for smokers and non­
smokers, and model (6) includes a straight line trend for smokers and quadratic 
trend for non-smokers. Diffuse, independent N(0,1000) priors were used for all 
regression coefficients independently of a Ga(0.001,0.001) for the precision.
Although model (6) is supported over the other models by all three selection 
criteria, the values of DIC and LPML for models (4) and (5) are not very different 
from those for model (6). One might argue that the more parsimonious model (4) 
should prevail. Although a consensus was reached on model (6) by DIC, BIC, and 
LPML in this example, different criteria can give rise to different preferred models. 
The best approach to model selection combines a selection criterion with guidance 
from subject-matter experts.
We also computed the PBFs for all 15 pairwise comparisons among the six 
models. Model (1) without age clearly fits worse than any other model: PBF2i = 
4 x 1016, PBF31 = 5 x 1016, PBF4i = 6 x 1018, PBF5{ = 1 x 1019, PBF61 = 
3 x 1019. Model (2) with age alone fits only slightly worse than the model with 
parallel lines for age, PBF32 = 1-31, but the model with age alone clearly fits 
worse than any of the more sophisticated models: PBF 42 = 150.9, PBF52 = 336.8, 
PBFG2 = 820.7. Since it hardly fits better than the model with age alone, the 
parallel lines model (3). not surprisingly, also fits much worse than any of the more 
sophisticated models: PBF43 - 115.3, PBF33 = 257.3, PBFG3 = 627.0. The 
real choice is between models (4), (5), and (6) with PBF34 = 2.2, PBFq4 = 5.4, 
РВЬ\ъ = 2.4. Model (6). which is bigger than model (4) yet smaller than model 
(5). is preferred.

Model Assessment
287
10.2.7 Comments on Information Criteria
We find the LPML criterion to be the most intuitive, and since PBF is a function of 
it (equation (10.12)). we tend to favor the PBF. It has the advantage over the BF 
that priors need not be proper, and it is also more stable to compute when diffuse 
proper priors are used.
The large-sample approximation to the Bayes factor using the BIC criterion is 
also compelling, since BFs are so directly interpretable. The “adjustment’’ A’log(n) 
arises naturally from the approximation to the marginal predictive density for each 
model.
The other criteria involve mathematical justifications as approximations to the 
ELPPD. A nice feature of the WAIC is that it only involves Bayesian objects 
and does not rely on “plug-in” estimates of pdfs, namely estimates of the form 
p(y | в), as in the case of the AIC and DIC. Gelman et al. [135] emphasize that the 
WAIC is based on the predictive densities that a Bayesian would actually use for 
predictions, rather than plug-in prediction densities. In this sense, it is more strictly 
Bayesian than the DIC, for example. The WAIC also has the advantage that it is 
approximately equal to the LPML in large samples. The DIC has the advantage 
that it has been programmed in software such as BUGS and JAGS, so one need only 
ask for it in those environments.
Finally, because the definitions of LPML and WAIC only involve integrals that 
are well defined and do not involve substituting point estimates, they are appro­
priate for mixed or hierarchical models. It is not obvious that the DIC or the AIC 
would be appropriate for assessing the quality of mixed models. Gelman et al. [135] 
also express doubts; also see Celeux et al. [68]. Mixed and hierarchical models are 
discussed in Chapter 14.
10.2.8 Statistical versus Practical Import in Model Selection
Suppose, through a careful statistical analysis, we come to be quite certain (say 
99% posterior probability) that a treatment is effective, and most model selection 
criteria also agree that the model should include the treatment. There is still a 
necessity to ascertain whether the magnitude of the effect is sufficient to warrant 
a change in current medical practice. We thus conclude this section by discussing 
the distinction between statistical and practical import.
We have discussed situations where posterior probabilities that regression coef­
ficients were positive (or negative) are quite large, say greater than 0.95. We have 
asserted that the corresponding regression effect was statistically important in this 
instance. Statistical importance is to be contrasted with practical importance. For 
example, the analysis of the trauma data with a diffuse prior was reported in Table 
8.4. The posterior median and 95% probability interval for the regression coefficient 
that corresponds to the revised trauma score (RTS) was —0.59 (—0.96, -0.26). The 
posterior probability that this coefficient is negative is virtually 1, so there is clear 
statistical importance of this variable. One would not think of removing this variable 
from the model. Furthermore, looking at Figure 8.1, we can clearly see the practi­
cal importance of this variable. For example, the estimated probability of death for

288
Bayesian Thinking in Biostatistics
60-year-olds with injury severity of 40 is about 0.6 with the larger RTS and about 
0.8 with the smaller RTS. This is quite a noticeable difference and much more rel­
evant to judging practical importance than the actual estimate of the regression 
coefficient and its uncertainty interval.
Also in the trauma data analysis table, there are inferences for the interac­
tion term between Age and type of injury, TI. The posterior probability that this 
coefficient is negative is 0.59, and the posterior median (—0.007) is very close to 
zero. There is obviously no statistical import here, and the estimate is useless for 
assessing practical import. Looking at Figure 8.1 again, however, and comparing 
the left and right side figures, there is a noticeable difference. That is, there is an 
observable difference in the estimated effect of Age on the curves: there is no ap­
parent effect of TI for older patients but there is for younger ones. The question 
beyond the lukewarm statistical importance of the interaction is whether to retain 
it regardless.
Consider the following generic situation. Investigators want to compare a novel 
anti-cancer therapy to the standard treatment. In the study, they randomly assign 
cancer patients to receive the new treatment or the treatment that is the standard 
of care. Study personnel follow the enrolled patients over time and record which 
patients survive and which die. The predictor variable of interest in an analysis 
of survival is the indicator of assignment to receive the new treatment, since this 
variable’s coefficient provides a measure of the treatment’s effect on mortality rel­
ative to the standard-of-care treatment. With the likelihood of including additional 
covariates, an analysis may be based on a logistic regression model in which the 
parameter /?i is the coefficient that corresponds to the indicator variable for “new” 
versus standard treatment. Further, suppose P(/?j > 0 | y) = 0.999, and that the 
posterior median difference (new minus standard) in survival probabilities at some 
clinically relevant time (e.g., 30 days after the start of treatment) for individuals 
who are otherwise comparable is 0.20, with corresponding 95% probability interval 
(0.15, 0.25). This is a clear story of statistical and practical import. No one would 
even think of removing the treatment variable from the model.
Now, suppose we found that P(j3i > 0 | y) = 0.96, and that the posterior median 
difference and 95% PI were 0.20 (0.01,0.29). The estimates are the same but we 
are no longer very certain about the magnitude of the effect, beyond believing that 
there is an effect. We would surely leave the indicator variable in the model.
Finally, suppose we obtained > 0 | y) = 0.83, and that the posterior me­
dian and 95% PI for the difference in survival probabilities were 0.05 (-0.03,0.09). 
Here, it is less clear what conclusions to draw.
As another generic situation representative of a somewhat different type of 
model choice, consider a situation in which we fit a Weibull regression model and 
a log-normal regression model for the time to death after diagnosis with leukemia, 
with gender as a covariate of interest. Suppose a model selection criterion has 
favored the Weibull over the log-normal. The issue of statistical versus practical 
import remains regarding the effect of gender based on the selected model.
We mention here the work of Laud and Ibrahim [217] that can be used to 
assess the practical impact of various models from the predictive perspective. They 

Model Assessment
289
consider three criteria labeled K, L and M, based on Kullback Leibler. Euclidean, 
and probability density scales, respectively. К and M arc similar in principle to 
the LPPD and LPML. The criterion L, however, measures models on the scale of 
the outcome or response variable in its units. This affords an interpretation more 
directly meaningful to the scientist to weigh models against one another. On the 
other hand, this measure does not yield interpretations on the probability scale 
as do BF and PBF. We recommend the use of L as supplementary to the other 
methods discussed in this section.
Finally, we remind ourselves that just because we have selected a model based 
on some criterion, there is no guarantee that the model will fit the data well. In 
other words, just because one model appears to fit the data better than the other 
models we have considered, the best-fitting model may still not necessarily fit the 
data well. It is always important to scrutinize a selected model for its fit to the 
data. We thus proceed to discuss model checking.
10.3 Model Checking (Model Diagnostics)
Suppose we have selected a model using one or more criteria from the previous 
sections. We would like to know whether the data are consistent or inconsistent with 
that model. The fact is that the “best” model according to some criterion may still 
provide a poor fit to the data. More precisely, in considering a model for the data, 
p(y I 
we now ask whether the data look like they could reasonably have
come from that distribution. If not, we will have some concern about this choice of 
model. Bayesian model checking, however, does not just involve the model for the 
data, since we must also specify a prior distribution, p(0 | Af). Having to consider 
the prior distribution as well as the sampling model adds a layer of complexity to 
the issue.
10.3.1 Classical Checking
Classical methods of model checking are much more highly developed than are 
Bayesian methods. A simple example of model checking is the following basic model 
for the data that assumes that the residuals are normally distributed. We can take 
residuals from either a frequentist fit of the selected model or a Bayesian fit, and 
obtain quantile-quantile (Q-Q) plots to see if they look reasonably normal.
There are various tests and checks for constant variance. For example, if one 
assumes a Poisson model for data, there are methods to check if there is extra­
Poisson variability, meaning that the variances are larger than the means. If the 
Poisson model holds, the variances should equal the means (see Section 9.2.1). The 
Pearson x2 goodness-of-fit statistic for categorical data models is a classical test 
that one may use to check a model’s fit. We occasionally employ such methods and 
will discuss them when we do.

290
Bayesian Thinking in Biostatistics
10.3.2 Box Check
In order to check a Bayesian model’s specification, Box (1980) [45] considered using 
the marginal predictive density, p(y | M} = f p(y | 0, M\p(0 | M)d0. In particular, 
he suggested obtaining the marginal predictive p-value,
p = P{Y: p(Y | M) < p(y | M)}, У ~ p(- | M), 
(10.17)
which is the probability of seeing a new data set (from the same model, M, that 
was assumed for the observed data) that is less plausible than the observed data, 
y. If a very small value is obtained, then it might seem very unlikely that the data 
were generated under model M. The criterion (10.17) is generalized as
P = P{T(Y) > T(y)}, 
(10.18)
In equation (10.18), T(-) is some function of the data that reflects goodness of fit, 
namely where large values would be incompatible with the model, M. Small values 
of p indicate poor model fit. An advantage of this method is that p is straightforward 
to compute using simulation. A disadvantage is that it is meaningful only with 
proper priors so that the marginal densities will be proper.
For example, if the model specifies that the mean of the data is zero, then 
T(y) = Ij/L absolute value of the arithmetic average, would be such a function. 
Similarly, if yt is the model prediction for the observed yt, i = 1,... ,n, and T(y) =
|z/i — Vi\/ni a small value of p would indicate a poor model fit. Unlike with 
criterion (10.17), however, it is possible that a large value of p could be a cause for 
concern. In the latter case, if T(y) = 0, for example, p would typically be close to 
1, indicating a near perfect model fit. Large values of p should cause concern that 
the model fit is too good to be true, as might occur, for example, if the number of 
parameters was close to the number of observations. The penalties included in the 
criteria discussed in Section 10.2 attempt to account for such overfitting.
Gelman, Meng, and Stern (1996) [137] have recommended the use of the pos­
terior predictive p-value. This quantity is defined as in equation(10.18) only with 
Y ~ p(- | у, M) = Jp(- | 0, M)p(0 | y, M)d0. The measure is thus
P*  = P(T(Y) > T(y) ] p), У~рм(-|р).
3The proofs are not simple!
A tremendous advantage is that these quantities are easy to compute and that 
prior specifications need not be proper. However, Bayarri and Berger (2000, 2004) 
[21. 22] argue against the use of this criterion because of “double use of data,” which 
unduly favors the model, as the same data were also used to choose the model.
10.3.3 Johnson Check
Valen Johnson [179] developed a Bayesian method of model checking that uses the 
data only once, is relatively easy to compute, and is intuitively appealing. Johnson 
has established some remarkable and simple3 large-sample results.

Model Assessment
291
The development involves a particular form of the classic Pearson \2 goodness- 
of-fit statistic that requires a partition of the data support into К mutually exclusive 
and exhaustive categories. We begin with a sample from a presumed parametric 
model,
y, | 
e~p(- \m).
Let F(- | 0) be the corresponding cumulative distribution function, and let 0 be 
a single sample taken from the posterior, p(- | y, A/). where у = (yp... , y„). the 
observed data. For simplicity of exposition, let F(-) = F(- | в). Then let 0 < 
<
ak < 1, к = 1,...,F; and, for each such к > 0, define Ck = (F~l(ak—i), F 1 («*•)]
 
which is a set in the support of the response variable in the data. Notice that the 
interval Ck corresponds to the ajt-i and ak quantiles of the distribution F(- | в). 
With a0 = 0 and = 1, we have F-1(0) = —oo and F-1(l) = oo. The collection 
{Cfc : к = 1,..., К} forms a partition of the real line, so that every observation, yi5 
must fall into precisely one of these sets.
Under the presumed model, and if в were the true value of в, for к = 1,..., К 
we must have
pk = P(Ti € 
| 0, M) = [ p(yi | 0, M)dyi
Jck
= F(F-1(afc)) - F(F-1(afc_1)) = ak - ak^. (10.19)
With 0 = 0 known, the expected number of observations in the data that would be 
observed in Ck is npk. The usual x2 goodness-of-fit statistic under these circum­
stances would be
Вв(в) = £ 
(10.20)
where mk(&) = ^7=1^Уг € Gt) ’s ^e observed number of observations in the 
interval Ck and has expectation npk.
If 0 = 0 were truly known, this would be identical to the original frequentist 
Pearson x2 statistic for testing the hypothesis that 0 was indeed equal to 0. Of 
course, there would have been a scientific choice for 0 under a null hypothesis of 
interest, and it would have been typically denoted 0o rather than 0. With large 
n, the approximate sampling distribution for the Pearson statistic under the null 
hypothesis is Хк-i, and the hypothesis would be rejected if the statistic was larger 
than something like the 95th quantile of this distribution.
In fact, Johnson’s statistic is defined exactly as above, with 0 a sample from 
the posterior. Under some conditions, he has shown that with large n and for 
0 ~p(0 | y,M),
RBm~x2K-t-
This is a remarkable result. It is the simplicity of Johnson’s result that leads us to 
incorporate it into an introductory book.
So, how do we proceed from here? Johnson recommends computing the frac­
tion of times FB(0) exceeds the 95th percentile of the Xk-i (uo.95, say). This is 

292
Bayesian Thinking in Biostatistics
accomplished by calculating the following quantity:
м
p = 52 
(10.21)
z=i
where ..., are samples from the posterior. If the model fits, we only expect 
5% to exceed this value, sop = 0.05. We would be concerned if, say, p = 0.2, meaning 
that FB(-) exceeded the 95th percentile for 20% of the samples. We might also be 
concerned if p = 0.005.
Johnson also considers the statistic
м
A = 52 ЛЯВ(0(/)) > 
(10.22)
i=i
where Xi... ,Хм ате independent draws from Хк-i- This is a cool number to ob­
tain; it says something about how different the actual distribution of the goodness- 
of-fit statistic is from its large-sample distribution. If the two distributions are about 
the same, then it can be shown that A = 0.5. If A is close to 1, then the density 
for RB(0) is concentrated well above the density for X, and if A is close to 0, the 
reverse would be true. The bottom line is that values of A close to 0.5 are consistent 
with a good fit and other values are not.
These quantities are all easily calculated in R after selecting and running the 
model M. To select the Ck, the simplest choice is Ck such that pk = 1/K. For 
example, with К = 5, take ao = 0,ai = 0.2, a2 = 0.4, аз = 0.6, a4 = 0.8,05 = 1. 
Then, if we were checking whether a data set was distributed as N(p, a2), we would 
have (F-1 (a), F-1(5)] = (д+стФ-1 (a), д+стФ-1 (5)], where Ф is the cdf for a normal 
7V(0,1) variate and Ф-1(а) is its a quantile. With p = 0, a = 1, and К = 5, we 
get Ci = (-oo,-0.84], C2 = (-0.84,-0.25], C3 = (-0.25,0.25], C4 = (0.25,0.84], 
C5 = (0.84,00).
For selection of K, Johnson [179] recommends К = n0,4, rounded. For example, 
if n = 100, 100° 4 = 6.3, and К = 6 categories will suffice.
Now a note regarding cases where F is discrete. For example, if the data are 
binomial, the cdf, F(-), is not continuous. Obtaining the Ck in this case is not as 
straightforward as in the continuous case, since it is likely not possible to obtain 
categories that have exactly pit = 1 /К for all k. This problem is easily addressed 
by simply selecting categories that have approximately the same probabilities. For 
example, if n = 15 and в = 0.3, we might set К = 3. We find the intervals by noting 
that for a binomially distributed random variable X with n = 15 and 0 = 0.3, 
P(X' < 3) = 0.3 and P(.Y < 5) = 0.72. With intervals formed by setting a\ = 3 
and a > = 5. we get p1 = 0.3, p2 = 0.42. and p3 = 0.28. The Johnson asymptotics 
hold as long as n = 15 is "large enough." With larger values of n, and provided 0 
is not too small, the normal approximation to the binomial can be used to find 
categories.
In addition to its simplicity of procedure, a remarkable feature of this Johnson 
check is that it can be extended to regression and, more generally, to situations

Model Assessment
293
where the model for Yt is even allowed to depend on i. In the regression case, 
we would write Yi | Xi,0 рД- | More generally, we can write Y, | 0 
Pi(" I #) where we have suppressed the dependence of Y, on a family of models 
for notational simplicity. The only part of the above results that changes for this 
more general case is the definition of the sets Cfc, which now depend on i. So define 
Gfc = 
and mk(0) = 
e C’ik)- Then all the above
results remain the same.
10.3.4 “Outlier Checking and Influential Observations
Data are not always well behaved. What does this mean? Often, one can model a 
set of data reasonably well with a parametric model like the normal or log-norinal 
distribution. Sometimes, however, one or a few of the observations are erroneous. 
Perhaps someone entered the number 10.67 into the data file as 1.067 or 106.7. 
Sometimes the stipulated data collection protocol is violated. For example, an ex­
periment on cloud seeding for producing rainfall (Cook and Weisberg [86]) specified 
randomized seeding, or not, on “suitable” days. Unfortunately, cloud seeding was 
done on one day that was not suitable, and an extraordinary amount of rainfall 
was recorded. “Mistakes” like these often result in what are called “outlier” obser­
vations. In some instances, outliers can have a major effect on the resulting data 
analysis, though this will not always be the case. It is important in any data ana­
lysis to look carefully to see if there are any gross instances of outliers. Outliers 
will not always be visible to the eye, however, especially if there is a multivariable 
aspect to the data. Here we present some methods for outlier detection, along with 
accommodation where appropriate.
Outlier Detection Using Conditional Predictive Ordinates. A useful and 
natural procedure for outlier detection is to compute the CPOi, introduced in 
Section 10.2.1 and equation (10.10), to obtain the index plot of - log(CPOj) versus 
г = 1,... ,n for a given model M. In this way we ascertain which observations, yi, 
are predicted least well by the model (excluding yi from the data for the prediction 
of yi). The observation fitting worst to the model has the smallest value of CPOi 
and consequently the largest value of - log(CPOi).
Outlier Detection Using Predictive p-Values. Geisser [126] also suggested 
calculating the predictive p-values
ppi = P (pfa | y(i},M) < CPO^ , Yi~p(- | y{i},M), 
(10.23)
for all data points. Interpreting CPOi as the predictive plausibility of the observed 
yj, the predictive p-value is the predictive probability of seeing a less plausible value 
for Yi under the assumed model. Small predictive p-values indicate the possibility 
of lack of fit and signal that the corresponding data points should receive further 
scrutiny. One can also find transcription errors like the example of 10.67 above in 
this way. Only when one ascertains that an error of some sort has been made should 
one consider discarding a data point. If all or most of these predictive p-values are 

294
Bayesian Thinking in Biostatistics
small, then one may infer that the model itself is not fitting the data very well. In 
such cases model selection should be revisited to find a more appropriate model.
For the normal model with exchangeable data, Johnson and Geisser [183] ob­
tained an explicit expression for ррг that results in a simple numerical evaluation. 
To be specific, let {У» : i = l,...,n} be a random sample from the 7V(p,a2) 
distribution, with p(p, <72) a 1/a2. Let у = "^пУг/п, Sy = ^^yi -y)2/n and define
t2 = (yi-y)2 T2 = i2 
г 
— 1/n) ’ 
1 
1 - t2
Johnson and Geisser [183] showed that the predictive p-value in equation (10.23) 
can be analytically obtained for this model as
FPl = P(F(l,n-2)>T?),
where F(l,n - 2) denotes an F distribution with 1 and n — 2 degrees of freedom. 
In this instance it is actually possible to calibrate the magnitude of “outlyingness” 
of yi. As a numeric example, suppose n = 25, у = 5, yi = 10, ns2 = 35. Then 
i2 = 0.744, Tt2 = 2.91 and using R, the predictive p-value is 1- pf (2.91,1, 24) = 0.1. 
If we had instead observed yj = 12 with the rest of the data remaining the same, 
then we would have у = 5.08 and 25s2 = 59. Then t2 = 0.845 and T2 = 5.47. 
Now the predictive p-value is 1 - pf (5.47,1, 24) = 0.028. So, it is quite unlikely 
that we would have observed a value that was as discrepant as yj = 12 under the 
assumed model. We would next investigate the circumstances of this case thoroughly 
and decide whether removing the observation is warranted or if one might possibly 
consider a new model, one that may be more robust in the presence of possible 
outliers.
Johnson and Geisser [183] also extended these results for the normal linear 
model. In general, the criterion in equation (10.23) can be obtained by straightfor­
ward numerical approximation (see exercises).
Outlier Accommodation in Normal Linear Regression. If the outlying data 
points are judged not to be outright errors, there are models available to allow 
for occasional occurrences of large (or small) observations. For example, Johnson, 
Pearson, and Utts [185] present a Bayesian robust approach to estimation of the 
mean when outliers are anticipated.
Having many outliers may be indicative of a skewed or multimodal or heavy­
tailed distribution. If so, the model should allow for such possibilities. We consider 
here the heavy-tailed case. A common choice for this is a t distribution with low 
degrees of freedom. The t distribution can be written as a scale mixture of normals, 
where the mixing is over the variance. We model each individual’s residual (observed 
minus expected value) as a random variable that follows a normal distribution with 
mean zero and a variance that is a subject-specific scale factor times a common 

Model Assessment
295
variance. Mathematically, we write the model as follows:
Yi = x'i0 + ei.
0 ~ N(b0, S/з), с» | ст2, А, ~ Дг(0. a2/Xi). 
\~x2(I/), l/c2 ~ Ga(a,b).
With this model, | a2 ~ t(t/,0,cr2). Aside from the added robustness from having 
t-distributed residuals, we can examine the posterior means of the Aj and compare 
them to their expected values, v. A small value of v is recommended to allow for 
heavier tails for the t distribution, so as to minimize the effect of the prior. Wishing 
the first two moments of e to be finite, v in the range from 3 to 5 is appropriate. 
We use 4 in the following example.
Example 10.5. Carlin and Louis [63] present data from a study of the effectiveness 
of aspirin in reducing fevers in children. The data set has temperatures in degrees 
Fahrenheit for 12 five-year-old children just before and one hour after taking as­
pirin. We are interested in the change in temperature after taking aspirin, so our 
dependent variable is pre-aspirin temperature minus post-aspirin temperature. It is 
likely that the temperature change depends on the pre-treatment temperature, and 
we use that temperature as a covariate. Our analysis will be based on a linear model 
of change in temperature (У) as a function of the pre-treatment temperature (To). 
We want to see if there are any outliers, so we assume a scale mixture of normals 
model for the residuals written as
У = 0o + 0\ (To — mean(To)) + £, 
(A),ft)z-N2(0,Eo), So = 10 x I, 
e | ст2, A; ~/V(0, ct2/A;),
At ~ X2(4), 1/ct2 ~ Ga(0.001,0.001).
We ran the model in JAGS (code and data available on the book’s website 
under Chapter 10 with filename Aspirin. xxx). Table 10.3 summarizes the posterior 
distributions of each parameter in the model, and Figure 10.1 shows boxplots of 
the MCMC samples of each child’s A. We expect each child’s Af to be around 4, the 
mean of a x2(4) distribution. We see that child #1 and child #11 may be outliers, 
since the posterior means for their As are 2.97 and 2.88, respectively. All other 
Xi are between 3.64 (A10) and 4.78 (Ai2), which are fairly close to the expected 
value. An analyst would typically look more closely at the potential outliers to 
try to determine why the model may not fit these individual observations as well 
as others. If, say, one determines that there was a recording error, the data value 
could be corrected. The proper inference becomes more difficult if no reasons for the 
outlying values can be found. Each case is different and has to be handled according 
to the scientific basis and context of the study.
Influence of Individual Observations. In addition to looking for outliers in 
data, it is perhaps even more important to see what effect particular observations

Bayesian Thinking in Biostatistics
296
5 
6 
7 
8 
9 
10 
11 
12
Child
FIGURE 10.1: Boxplots of posterior samples for each child’s A.
have on an analysis. Observations that change inference substantially are termed 
“influential.” Cook [85], Cook and Weisberg [86], and Belseley, Kuh, and Welsch 
[27] initiated the study of finding influential observations in the classical setting. 
Johnson and Geisser [183, 184] followed with Bayesian methods for detecting influ­
ential observations by considering prediction and estimation. In [183] they defined 
the predictive influence measure for removing observation i from the data to be
KLDPi = KL(p(y | p,M),p(j/ 1y(i)),M),
where у stands for predictive vector for all observations. This measure is the 
Kullback-Leibler divergence between the joint predictive density for a future vector 
that is based on all of the data and the corresponding joint predictive density that is 
based on all of the data except y,. If КLDPi is close to zero, there is little effect on 
prediction if observation г is held out from the data. The observation corresponding 
to the largest value may be influential for predictive purposes. Observations with 
large values of A LDP should thus be subject to scrutiny. If one removes the “most 
influential" data point and reanalyzes the reduced data set, one looks to see if the 
inferences are different enough to care about. Again, we may not want to remove 
such cases just because they are influential but report analyses with and without 
them, unless permanent removal is scientifically justified.
Johnson and Geisser [184] defined what they term an estimative influence mea-

Model Assessment
297
TABLE 10.3: Posterior summaries from robust regression analysis of pediatric as­
pirin study data
Mean
Std dev.
95% predictive interval
/Зо
1.76
0.20
(1.36, 2.13)
/31
0.82
0.24
(0.33, 1.31)
Ai
2.97
2.10
(0.42, 8.38)
Л2
3.91
2.65
(0.56, 10.69)
Аз
4.77
3.05
(0.71, 12.34)
a4
3.96
2.69
(0.60, 10.86)
As
4.05
2.67
(0.67, 10.64)
A6
4.56
2.90
(0.76, 11.78)
A?
3.97
2.60
(0.65, 10.55)
As
3.77
2.55
(0.61, 10.33)
A9
4.70
3.04
(0.73, 12.35)
A10
3.64
2.37
(0.58, 9.68)
Au
2.88
2.03
(0.42, 8.17)
A12
4.78
3.00
(0.78, 11.80)
a
1.11
0.32
(0.65, 1.89)
sure,
KLDEi = KL(p(y | j/,Af),p(7 |
where 7 = g(0) is a function of the parameters, possibly the identity, that is of 
particular interest to scientists. For linear and multivariate linear models, the es­
timative influence measure has explicit formulas [184] for direct computation. In 
the linear model case, there are good analytic approximations for the predictive in­
fluence measure. In general, Monte Carlo techniques are used to approximate these 
quantities.
While the measures in this subsection are discussed in some generality for a 
broad class of models, specifics for linear models were developed by Johnson and 
Geisser [183, 184], some of which are included in the next subsection. For binary 
response models, a more challenging topic, Johnson [182] discusses the assessment 
of predictive influence.
10.3.5 Diagnostics for Linear Regression
Standard linear regression models assume independence of observations conditioned 
on parameters, linearity (in regression coefficients) of the functional relationship, 
along with normality, and constant variance of the deviations from the regression 
surface. There are a variety of methods available to check these assumptions based 
on least squares (LS) estimates, which are the same as the maximum likelihood 
(ML) estimates in the case of linear regression ([77, Chapter 13]). The methods 
include looking at an initial scatterplot matrix to determine marginal relationships 

298
Bayesian Thinking in Biostatistics
between the response and each covariate, whether continuous, ordinal, or nominal; 
residual plots; and tests for non-constant variance. A plot of residuals versus time­
order may be appropriate and enlightening too. We recommend these techniques as 
quite useful in general for assessing whether the normal linear model is appropriate 
for the data at hand. After reviewing and illustrating these briefly, we discuss 
Bayesian methods that condition on the observed data and use a more predictive 
approach as introduced in the preceding subsections of this section.
Residuals are observed deviations of yi from the fitted values fa = x'Jl, where 0 
is an estimate of /3, typically (X'X)-1 X'y, the ML (also LS) estimate. Studentized 
(also called standardized) residuals are residuals that are divided by their frequentist 
estimated standard deviations in repeated data sampling. The Studentized residual 
is 
.
q. = 
& ~ xi&
' ~ y/MSEii-hi)'
where hi = x'i(X'X)~1Xi and MSE stands for mean squared error (y — y)'(y — 
y)/(n—p— 1), у = X/3, and dim(/3) = p+1. The measure hi is called the “leverage,” 
taking on values between 0 and 1 and increasing with the distance between z, and 
x., the average of the vectors Xi in the data. If Xi is far removed from the average, 
leading to hi = 1, the regression surface is pulled or leveraged towards the ith 
observation, y^ and the frequentist standard error of (p, — x<3) will be near zero. 
Case-deleted residuals have the same form,
T, = 
Vi -, 
(10.25)
except that MSE^) and the least squares estimate are computed with case i 
removed from the data; similarly, X^ is X with case (row) i removed. A significance 
test compares 7) to a t(n - r - 1) distribution.
If we have the correct regression model, residuals when plotted against any 
variable should look like a band of noise with no discernible pattern. In particular, 
any fitted trend line should be horizontal at zero. This should be true for variables 
that are in the model and for variables left out of the model. The most commonly 
used variable on the z-axis in such plots is made up of the fitted values yi = х'^З.
Finally, the £, should be normal. This can be checked by examining a normal 
probability (rankit) plot of the residuals. Q-Q plots can also be used. We illustrate 
with an example.
Example 10.6. FEV Data of Examples 7.3 and 10.4. For the linear regression 
model with
E(FEV | Age. Sex) = 3} + 32Age + 3$Sex + в^Аде x Sex,
the MLEs and the posterior mean of 3 using proper reference priors (cis in Example 
10.4) are both approximately 3 = (0.67.0.21.1.72,-0.14)'. Figure 10.2 contains 
Q-Q and residual plots, separately for smokers and non-smokers. One can fit a

Model Assessment
299
В55
В
Fitted Values
Theoretical Quantiles
Smokers 
Normal Plot
Smokers
Residual Plot
Fitted Values
Theoretical Quantiles
FIGURE 10.2: FEV diagnostic plots for linear trends in age.
nonparametric trend line to the plot of residuals against the fitted values or indi­
vidual covariates to help visualize deviations from the assumed zero slope (i.e., no 
association). The trend lines in Figure 10.2 were computed using local weighted 
scatterplot smoothing (lowess); see Cook and Weisberg [87]. The Q-Q normal plots 
show that the sample quantiles are larger than the theoretical quantiles, suggest­
ing a slight right skew in these distributions. The skewness appears to be larger 
for non-smokers. The constant variance condition may also be in question. Among 
non-smokers, fitted values above 3.75 show larger variance. Since the regression co­
efficient of age is positive, larger fitted values will tend to relate to older individuals. 
This suggests a higher variance for older non-smoking children. Data are sparse for 
this group, however.
Interpreting these plots is obviously subjective. One might conclude that there 
is no definitive indication of departure from normality or non-constant variance 
across age, based on these same graphics. A log or other transformation could be 
applied if normality were in question. In our experience, normal plots frequently 
deviate from the straight line in the tails.
Johnson and Geisser [183, 184] developed Bayesian methods for detecting the

300
Bayesian Thinking in Biostatistics
influence that individual cases in the data have on the prediction of future observa­
tions and on estimating parameters. While a number of measures were considered 
there, the simplest one turns out to be proportional to Cook’s distance measure 
[85], namely,
1 •t'i
This is the square of the Studentized residual in equation (10.24) times a monotone 
function of the leverage. Cook’s motivation was that £>$ = (/? — /3(_^)'Х'Х(/3 — 
P(-i))/(p+ 
which measures the effect of deleting the ith observation on
the estimate of /3.
Now consider a future case (outcome denoted yf) that will have predictor in­
formation Xf = Xi and that will be predicted using the data Y^y. Then
yf ~
Тц = , 
*"  ~'"v’ 
' I if, i/(<> ~ t(n - p - 1).
Tfi is a function of yj, which is unobserved, but we can use this distribution 
to evaluate whether the observed value of the case-deleted residual Ti (equation 
(10.25)) is compatible with the model. We assess this compatibility by calculating 
the “p-value” P(|T/i| > |Ti| | Xi,y(iy). Case i is declared an outlier at level a if 
|Ti| > t(l - a/2,n — p — 1). It is also shown in [183] that
2 _ (n-r- 1)S? 
г n — r — S? '
so it is easy to obtain Tf from the Studentized residuals Si.
10.3.6 Diagnostics for Binary Regression
For deciding among link functions in binary regression, we provided Examples 10.2 
and 10.3 as illustrations. However, we did not discuss how to assess model fit with 
binary data. This is quite challenging.
For grouped data where there are щ observations corresponding to the same 
covariate vector, say Xi, it is possible to somewhat mimic the linear regression 
procedures if the щ are all moderately large, say greater than 10. It is also possible 
to produce a plot for model assessment. To see how, let yi = у^щ be the proportion 
of Is corresponding to case г. Then f)i = yi is a natural (nonparametric) estimate 
of the corresponding success probability 0i. For logistic regression, the difference 
between the logit of 0, (i.e., log(0i/(l — 0j))) and the model fitted estimate x'/3 can 
be treated as a “residual.” Here 3 is the posterior mean of /3 under the logistic 
regression model. (Of course, there are difficulties if yi = 0 or yi = щ for any i.) 
One can also plot .r'3 versus logit(0,). If the model fits, the plot should look like a 
straight line with some random scatter around it. Any striking pattern in this scatter 
would indicate a lack of fit. The process can be repeated for other link functions 
or for models with different subsets of covariates. The model corresponding to the

Model Assessment
301
best-looking straight-line plot could be accepted as the best-fitting model. Of course 
if none of the plots looks like a straight line, there is evidence against the fit of all 
models under consideration.
In our experience, the щ tend to equal 1 more often than not (i.e.. data are 
typically not grouped). We can, of course, proceed with model selection using the 
BF, LPML, or WAIC, as in Sections 10.1 and 10.2. However, model diagnostics 
remain challenging. One option is to consider Bayesian nonparametric methods 
that allow for a broad class of link functions [205], but these are beyond the scope 
of this book.
10.4 
Recap and Readings
We have discussed model selection and assessing model fit in some detail. One can 
base model selection on posterior probabilities of specific models among a collection 
of models. An uncomfortable aspect of using posterior probabilities is the neces­
sity to pick prior probabilities for the models under consideration. Imagine trying 
to assign a prior probability to the hypotheses in a jury trial for murder. What 
should be the prior probability that the defendant is guilty? This would not be 
easy, especially as this probability can have a substantive effect on the posterior 
probability. In a scientific context, one of the authors of this book was apprised that 
a colleague’s prior probability for the hypothesis that the reported phenomenon of 
extrasensory perception (ESP) actually exists was IO-40. Virtually no amount of 
data could move this prior probability in the direction of affirming the existence 
of ESP. Quantifying weight of evidence via Bayes factors avoids the difficulties of 
specifying prior probabilities for hypotheses in such situations.
Another approach, though not quite as directly interpretable as the BF, is to 
use one of several predictive information criteria. We gave a summary of advantages 
and disadvantages of eac.h With large samples, the BIC is a relatively easy criterion 
to implement and interpret. The DIC has the advantage of being readily available 
in BUGS and JAGS, but be advised not to use it if the penalty pp is negative. 
We find LPML and WAIC quite useful in most situations, including hierarchical 
models.
In the context of model selection with two models, this is often framed as test­
ing two competing hypotheses. Traditional methods rely on the use of p-values. 
Although ubiquitous in the medical literature, this emphasis on p-values for scien­
tific purposes has come under severe scrutiny that indicates much caution, perhaps 
even shunning this approach entirely. In an accessible discussion without excessive 
mathematics, Goodman argues effectively in favor of the Bayes factor as a proper 
measure of evidence when testing hypotheses [148, 149]. Other influential articles 
in this direction are by Berger and Sellke [32], loannidis [173], Sellke, Bayarri, and 
Berger [290], Bayarri and Berger [21], and a statement by the American Statistical 
Association that includes discussion by several researchers [345].

302
Bayesian Thinking in Biostatistics
The final topic was model checking, which is likely the least developed topic in 
the current Bayesian armamentarium. Looking for outliers using the CPO statistic, 
model checking using the Box and Johnson methods, and obtaining case influence 
diagnostics are all straightforward to program and can be recommended for routine 
use. In some instances we have seen analytic formulas, as is the case for the KLDP 
and KLDE statistics in linear models.
One final bit of advice. There are one-hundred-dollar analyses of data that have 
to be done by “tomorrow,” there are one-thousand-dollar analyses that have to be 
done by next week, and there are analyses that really need to be done “right.” 
The caveat garbage-in, garbage-out comes to mind. The analysis that must be done 
by tomorrow has a much higher probability of being garbage than if there were 
sufficient time to get the model “right”; on the other hand it may well be “good 
enough.” Of course there is always a point in a data analysis where it is not worth 
appreciable effort to obtain “perfection,” whatever that might be perceived to be. 
Data analysis is an art form that takes time and effort. Part of the art is knowing 
when to keep going and when to stop.
10.5 
Exercises
Exercise 10.1. Let the data {Yi : i = 1,..., n} be iid from the model Mo : Yi ~ 
H(0,1/r) or from Mi : Yi ~ 
Let рДт) ос l/т and pi(p) ос 1. Define
во = т and di = 
.
(a) 
Obtain explicit formulas for рДр) and BFiq\ simplify the formula for the Bayes 
factor.
(b) 
Simulate 10 observations from 7V(0.1,l) and obtain BFiq. Comment.
(c) 
Repeat (b) with observations from H(l, 1).
(d) 
Repeat (b) and (c) with n = 100.
Exercise 10.2. Suppose we have independent normal observations with un­
known mean в and known precision r0:
Г1,...,Г„|0 ~ H(0,l/ro).
Since the likelihood function for в only depends on у = ^ii yi/n, Bayesian statistical 
inferences need only depend on y. We thus simply assume that the observed datum 
is y. Then
Ык(в) ос exp [-^(p - Я)2] •
We wish to test Hq : в = 0 versus Hi : в / 0. The prior under Ho is po(0) and must 
be a point mass assigning probability 1 to в = 0. Take pi(0) to be a 7V(0. l/rj 
density. Strictly speaking, pi(0) should not be defined for 0 = 0, but any integral 
over 0 = 0 is zero, so it does not matter.

Model Assessment
303
(a) 
Obtain explicit (analytical) representations for the "marginal" probability den­
sity functions for the observed data, Pi(y), i = 0,1. Hint: In performing the second 
integration, you could first prove that у - 0 is independent of 0. given known r0 
and given в / 0, and then use their independence to ascertain the marginal dis­
tribution of their sum (with в integrated out). Alternatively, you could perform 
the integration using the complete-the-square formula that we used when deriving 
the posterior distribution of the mean in the case of a normal-normal model with 
known variance (see Section 3.2.2).
(b) 
Obtain BF10 and simplify algebraically as best you can.
(c) 
Then obtain -21og(BF0i) and argue that this is larger than a constant k  if 
and only if \z| = y/n\y - 0|/ \/1/to > fc, for a specific value k.
*
(d) 
Assume the datum Y | в ~ N(0,10), n = 49, and the prior в ~ N(0,1). For each 
of the values y, (0,0.2,0.4,0.6,0.8,1), calculate the corresponding BF, —21og(BF) 
and z values. Comment.
(e) 
Using the same data, write computer code to obtain numerical approximations 
to the BF values in (d). Comment.
Exercise 10.3. Referring to Exercise 10.2, establish the fact that you will obtain 
the same marginal Bayes factor formula if you use all of the data or if you restrict 
the data to be y, as was done in Exercise 10.2.
‘Exercise 10.4. Bayes factors for the LE data. Answer the following ques­
tions based on the assessment of link functions for the LE data in Example (10.2). 
Recall that BUGS code is given in the example, and in the files with the name 
LymphedemaBFdata on the book’s website.
(a) 
Derive the expression for u [i] in the code.
(b) 
Run the code, or write your own code, and give the BF for comparing the two 
models.
(c) 
Revise the code to obtain the BF comparing the complementary log-log model 
to the probit model. Then give the BFs for comparing complementary log-log to 
probit, and for comparing probit to logit. Which model do you prefer and why?
Exercise 10.5. Let Ylf..., Yn | в ~ N(6, l/r0) with r0 known. Let the hypo­
theses be Ho : 0 = 0 and Hr : 0 / 0, and let MQ and Mi be the corresponding 
model indicators. Let 0 | Mx ~ 7V(0,1).
(a) 
Obtain the analytical BIC formula for each of these models and discuss them 
in terms of tradeoff between goodness of fit and penalty.
(b) 
Obtain the approximate BFqi formula using the BIC and compare it with the 
exact analytical form of BFoi-
(c) 
Suppose that n = 4, to = 1, and that the observed data are 
(0.158,0.747,1.253,1.841). Obtain BICi for г = 0,1 and the exact and approx­
imate values for BFq\.
Exercise 10.6. Let Yi,..., Yn | в ~ Exp(&), with p(&) ос 02e-5e. Consider the 
hypotheses Hq : 0 = 1 versus Hi : в / 1.

304
Bayesian Thinking in Biostatistics
(a) 
Obtain an analytical formula for BF0l.
(b) 
Using R, obtain the value of the Bayes factor when n = 50, у = 2.
(c) 
Give a Monte Carlo approximation to the Bayes factor to see how close you can 
get to the actual value.
(d) 
Obtain the approximate value of the Bayes factor using the BIC.
(e) 
Compare results and comment.
Exercise 10.7. Establish that (10.10) is true. Hint: First show that
’ -ftto I %)) - /П1#.р.(ю | e)pWd3-
Exercise 10.8. Precisely why is the PBF not a real BF?
Exercise 10.9. Consider the two-sample binomial model with Yt | 0, 
i = 1,2. Suppose щ = n2 = 25, and that yi = 3 and y2 = 6 are
observed. Let 0, ~ [7(0,0.5), independently, for i = 1,2. For this problem, we con­
sider the models Mi, which allows for distinct 6s, and Mq, which equates them.
(a) 
Write code to obtain point and interval estimates for 62 — 0i, and also to obtain 
the posterior probability that 62 > 0i. Discuss.
(b) 
Write code to obtain the PBFiq. The prior for the common 0 is the same 
[/(0,0.5) distribution. Discuss.
(c) 
Write code to obtain BFio, and compare with PBFiq. They do not have to be 
the same since they are different criteria.
(d) 
Repeat all parts above with щ = n2 = 100 and with yi = 12 and y2 = 24.
(e) 
Now discuss, compare, and contrast all of the above parts together.
Exercise 10.10. For the two-sample binomial problem in Exercise 10.9, obtain 
the WAIC statistic for both models and both data sets. Discuss. Details for nu­
merical approximation to equation (10.13) are given in Gelman et al. [135], but 
they are not difficult to figure out on your own. Keep in mind that a population 
variance can always be approximated by a sample variance, the sample here being 
an MCMC sample from the posterior.
Exercise 10.11. Show that the three expressions for the DIC given in equation 
(10.14). (10.15), and (10.16) are the same.
Exercise 10.12. Using the definition of the deviance function, observe that the 
AIC statistic can be expressed as AIC = D(0XIL) +2k, where 0ML is the maximum 
likelihood estimate and к is the dimension of the parameter vector. Let к = 1 for 
now.
(a) 
Assuming the improper prior ex c. argue that the posterior mode for 0 is 
the same as the MLE. 0X,L.

Model Assessment
305
(b) 
Obtain a second-order Taylor series expansion for D(d) bv expanding about 
flML
(c) 
Argue that if the DIC is defined using the posterior mode instead of the posterior 
mean, then DIC = AIC for large n. Hint: You can assume that with large n, the 
posterior mode and the posterior mean are approximately the same.
•Exercise 10.13. Repeat Exercise 10.12 with arbitrary k. Let 6 = 0XIL. Hint: 
Show that
b = d(0) + 1/(0- ОУЬЩ) - ё)РМ(е | у)<ю,
where D(0) is the second derivative of D(0), the corresponding к x к matrix of second 
partial derivatives when к is arbitrary. Note that the integral can be written as 
Ee|j/(0-0)'.D(0)(0-0) = 1та,се[Ь(О)Ев\у(0-ё)(О-ОУ] = trace[D(0)cove|y(0)]. Then 
use the fact that the large-sample approximation to the posterior is Nk(0,2D(0)-1).
Exercise 10.14. Compute the AIC and DIC statistics for both models and both 
sample sizes for the two-sample binomial models in Exercise 10.9.
Exercise 10.15. Recall that we analyzed the trauma data in Chapter 8 and that 
the data can be found on the book’s website for that chapter. Using the prior of 
your choice, and with non-standardized covariates, obtain the DIC for each of the 
three link functions. Comment on which model seems to be preferable.
Exercise 10.16. Recall again the LE data with three covariates discussed and 
analyzed in Chapter 8. Using the prior of your choice, and with non-standardized 
covariates, obtain the DIC for each of the three link functions. Comment on which 
model seems to be preferable.
Exercise 10.17. For the two-sample binomial problem in Exercise 10.9, obtain 
the joint marginal predictive densities, j/2), г = 0,1, for the т = пг = 25 case. 
The joint pdf will factorize as the product of two independent betarbinomial pdfs 
under model Mi. Simulate from the corresponding marginal predictive distributions 
and obtain a numerical approximation to (10.17).
Exercise 10.18. Suppose a random sample of ten blood donors was taken and 
that individuals were tested for HIV with a perfect test. A perfect test means that 
the test’s sensitivity, the probability of a positive test outcome given the blood is 
indeed HIV infected, and specificity, the probability that a negative outcome on 
the test given that the blood is disease free, are each 100%. (Chapter 15 discusses 
diagnostic tests.) Suppose that two donors’ samples were determined to be positive 
for HIV and eight were not. Check whether the data are consistent with a model
yi,...,r10 |0 ~ Ber(0.01)
using the Box p-value criterion (10.17). (You can think of this as having a prior 

306 
Bayesian Thinking in Biostatistics
with P(0 = 0.01) = 1.0.) Would the outcome change if it was based on Уг ~ 
Bin(10,0.01)? Comment.
Exercise 10.19. Simulate к observations from a N(p,<r2) distribution, with 
p = 10, a = 2, and with к = 20,50,100.
(a) 
Using these data obtain p as defined in equation (10.21), and A as in equation 
(10.22), for all values of k. Comment.
(b) 
Now add a spurious observation, уь+\ = 0, to each of the data sets and repeat 
(a).
Exercise 10.20. Consider the FEV data with four predictors: Age, Smoke, 
Height, and Male. The data are given on the book’s website for Chapter 7 in 
the file FEVdata-full.xxx.
(a) 
Obtain p as in equation (10.21) and A as in equation (10.22) for the LE data 
using the model with two covariates (Age and Smoke) and an informative prior. 
Comment.
(b) 
Repeat part (a) using the data with four covariates (Age, Smoke, Height, Male). 
Use a diffuse proper prior.
Exercise 10.21. Simulate two independent binomial samples with щ = n2 = 
50, di = 0.5, and 02 = 0-4. Here, the total sample size is 100, so consider К = 
5 categories. Select the categories so that a Bm( 100,0.45) random variable has 
roughly 0.2 probability of being in each category. Using those categories, obtain the 
Johnson statistics p (equation (10.21)) and A (equation (10.22)) for the model that 
allows the binomial probabilities to be different. Then repeat under the (incorrect) 
model assumption that the binomial probabilities are the same. Comment.
Exercise 10.22. Using the fact that у = yj/n + yi}/n and Y,i(yi ~ y)2 = 
(yj ~ У)2 + 
~ У)2, AH in the details from the discussion of outlier detection
using CPOs about why tj above is 0.845 when pj is changed to 12 from 10, with 
other observations remaining the same.
’Exercise 10.23. For the situation considered in Section 10.2.1 with Yj 
(У1,...,УП) | 0,M, Yj p(- | 6,M), and Yi | 0 ~ p(- | 0,M), do the follow­
ing.
(a) 
Show that
(b) 
Explain why this is a proper density in yj.
(c) 
Explain how you could numerically approximate the predictive p-values specified 
in equation (10.23) using this result.
Exercise 10.24. Let У........У,, be iid N(p, 1) with p(p) oc c. a constant, and let
У = (pi........pn) and p(j) be the vector p with pj removed.

Model Assessment
307
(a) 
Obtain the explicit formulas for | y) and p(/i | y^))-
(b) 
Then obtain an explicit formula for KLDEj with 7 = I1- It П1аУ be useful to 
recognize that у = yj/n + yi/n = yj/n + уи)(п - l)/n.
(c) 
Explain why it is somehow sensible for detecting influential observations.
(d) 
Now explain how you would obtain MC samples and how you would use them 
to approximate the KLDEj statistic if you did not have formulas.
•Exercise 10.25. Continuing with Exercise 10.24. let у = (yi,... , yn). with Y, | 
p jV(/j, 1), independently of Y.
(a) 
Derive explicit formulas for p(y | y) and p(y | ytj)). They will be multivariate 
normal with dependence covariance structure. Hint: Show that Y | у is Nn(yen, In + 
en e'n/ri), where en is a vector of n ones.
(b) 
Obtain an explicit formula for KLDPj. Hint: It will be helpful to know that 
the inverse of the matrix In + en e'n/n is In — en e'n/(n + 1).
(c) 
Explain why the formula for KLDP is somehow sensible for detecting influential 
observations.
(d) 
Explain how you would obtain MC samples and how you would use them to 
approximate the KLDPj statistic if you did not have formulas.
Exercise 10.26. The FEV data have been analyzed a number of times in this 
book. The data with two (and four) predictors can be found on the book’s website 
for Chapter 7. Here, we consider model selection with two covariates, Age and 
Smoke.
(a) 
Using proper diffuse priors, run the following linear regression models and obtain 
the DIC for each: (i) with only the variables Smoke and Age, (ii) with Smoke, 
Age, and a Smoke-by-Age interaction, (iii) with separate quadratic trends in age 
for smokers and for non-smokers, and (iv) with a quadratic trend for non-smokers 
and a separate linear trend for smokers.
(b) 
Using the model with the smallest DIC statistic, obtain posterior inferences for 
the regression coefficients and obtain the posterior probability that each regression 
coefficient is positive. What does this analysis suggest about the associations be­
tween FEV and age for smokers and non-smokers? It will help to graph curves of 
estimated mean response against age for smokers and for non-smokers on the same 
plot.
Exercise 10.27. We continue with model checking for the FEV data, only now 
using the data set with four predictors, which is on the book’s website for Chapter 
7. Perform a parallel analysis to what was suggested in Exercise 10.26, only now 
including the extra two predictor variables, Height and Male.
Exercise 10.28. Consider Exercise 10.26 again. Using model (iv) in part (a), 
do the following.
(a) 
Construct the matrices
H = Х(Х'ХГХХ', e = Y — Y = Y -X0, V = diag(H),

308
Bayesian Thinking in Biostatistics
s= 
’e, D = V(Z-V)-1diag(S)S,
where diag(S) is a diagonal matrix that is constructed so that the elements of the 
vector S constitute the diagonals, with zeros off the diagonals, while diag(H’) is a 
diagonal matrix that has off-diagonal zeros with the diagonal elements of H in its 
diagonal.
(b) 
Show that D is just the column vector of Cook’s distances with zth element 
Di ~ &i 1-/ц •
(c) 
Identify the case in the FEV data with the largest Studentized residual and the 
case with the largest Cook’s distance.
(d) 
Test the hypothesis that the former case belongs to the assumed model.
(e) 
Remove the case with the largest Di and rerun the analysis using the same 
model. Report any substantial differences from the analysis done in Exercise 10.26 
using model (iv) of part (a).
Exercise 10.29. Justify that Tfi (defined near the end of Section 10.3.5) has the 
specified t distribution.
Exercise 10.30. Obtain the LPML and DIC statistics for the models in Table 
10.2, and for each model, j, construct a plot of {(i, CPOij) : i = 1,..., n}. Discuss. 
The FEV data and BUGS code for analyzing these data can be found on the book’s 
website for Chapter 7.
Exercise 10.31. Consider a proper diffuse prior for the three-sample (log- 
transformed) DiaSorin data, first assuming equal variances. The DiaSorin data were 
analyzed in Chapter 7, and the data can be found on the book’s website for that 
chapter.
(a) 
Give statistical inferences on the untransformed scale for the median values and 
for predictions. Obtain the DIC and LPML statistics for this model.
(b) 
Modify your code to handle unequal variances (or precisions) and repeat part 
(a). Also monitor the ratios of standard deviations, comparing the first and second, 
first and third, and second and third groups. Is the assumption of equal variances 
reasonable?
(c) 
Regardless of your answer to (b), explain how inferences would change if you 
assumed heterogeneous variances. Are there appreciable differences?
Exercise 10.32. FEV data analysis project. Conduct a complete Bayesian 
linear regression analysis of the full FEV data available from the book’s website 
for Chapter 7. These data include the predictor variables Age, Smoke, Height (in 
inches), and Male (yes/no) (1 = Male).
Information for informative prior construction was provided by Dr. David Man­
nino. M.D. (Division of Pulmonary, Critical Care, and Sleep Medicine and Director 
of the Pulmonary Epidemiology Research Laboratory at the University of Ken­
tucky). The values are measured in liters. The two numbers are the prior best 
guess for median FEV followed by the 99th percentile for the median. For 18-year- 
old female smokers. 70 inches tall: 4.0 and 4.8. For 16-year-old male non-smokers, 

Model Assessment 
309
70 inches tall: 4.2 and 5.0. For 13-year-old male smokers, 66 inches tall: 3.4 and 4.0. 
For 12-year-old male non-smokers, 60 inches tall: 2.7 and 3.5.
One issue to be addressed in this study is the determination of normal ranges 
of FEV for a given type of adolescent. For instance, what range of FEV values is 
predicted for a 15-year-old male who does not smoke and is 66 inches tall? Do the 
following in your analysis.
(a) 
Carry out an exploratory data analysis. This means make yourself familiar with 
salient features of the data by computing meaningful summaries and plotting the 
data for descriptions of it that you can communicate easily to Dr. Mannino.
(b) 
Discuss prior construction, predictor selection (including interactions), and con­
vergence and model diagnostics.
(c) 
Present posterior inferences for regression parameters and for subpopulation 
means in appropriately designed tables or figures. Based on your analysis, is smoking 
related to FEV?
(d) 
Determine normal FEV ranges for several different types of adolescents, pre­
senting the results in a table.
(e) 
Perform and discuss a sensitivity analysis.


Chapter 11
Survival Modeling I: Models for 
Exchangeable Observations
This chapter concerns the analysis of data that arise when studying the time un­
til the occurrence of an event. Such data are often called “tinie-to-event data,” 
and their analysis is termed “survival analysis.” Medical studies often involve such 
situations. For example, the time until death after diagnosis with leukemia, or the 
time it takes to develop symptoms of Covid-19 after infection with the SARS-Cov- 
2 virus. Because one often does not get to record the precise time of the event of 
interest for each study participant, statisticians have developed methods to handle 
this mix of complete and incomplete measurements. As one example, a study of 
the effectiveness of a new anti-cancer drug may focus on time to death of patients 
as the primary measurement relevant to the drug’s potential benefit. While some 
patients may have died by the time of the analysis (and their time of death known), 
others may still be alive. In the latter case, we do not know the time of death but 
we do know a lower bound for it - the time of analysis. This is also informative and 
relevant to the goal of the study. Another example is when a study outcome is the 
time the patient experienced some event (e.g., sero-conversion to AIDS), but the 
records do not allow us to determine an exact time of this event and we only know 
that the event occurred before a known time. Survival analysis is the collection of 
methods for analyzing such data in which not all individuals have experienced the 
event of interest and/or we cannot observe the precise time of the event.
In this chapter, we consider situations without covariates; in other words, the 
case of exchangeable observations. After delineating some concepts and terminol­
ogy, we discuss methods based on parametric sampling distributions for the under­
lying event times. We then introduce Bayesian semiparametric and nonparametric 
methods.
11.1 Some Concepts and Definitions
We build the discussion of survival-analytic methods by defining key terms and 
developing some notation. We will generally let T denote a random survival time. 
Survival times are never negative, so one can use any probability model for positive 
random variables to characterize survival times. Common distributions that find 
use in modeling time-to-event data are the log-normal distribution, the exponential
311

312
Bayesian Thinking in Biostatistics
distribution, and the Weibull distribution. Some distributions Eire more convenient 
mathematically for certain types of models, especially when one is concerned with 
covariate effects (see Chapter 12).
11.1.1 Survival and Hazard Functions
One key element of survival analysis concerns the so-called hazard function, which 
we now define. Let the cumulative distribution function for the random sur­
vival time T be Fr(t) = P(T < t). We call Sr(t) = 1 — Fr(t) = P(T > t) 
the survival function. The density function of T is defined as it is for all con­
tinuous random variables (see Appendix A) as the derivative of Fr(t), that is, 
/T(i) = 
= Ншд^о 37P(T 6 [t,t +At)). The hazard function for T, called
the “force of mortality” in demography, is the rate of risk of the event occurring 
in an instantaneous time interval just beyond t, given that the event has not yet 
happened (up to and including t). Mathematically, we write
ft(() = Л (г e + Д() 1T >() = WY (111)
By definition, h(t) > 0. The integral of this hazard function, called the cumulative 
hazard, and defined as
H(t) = f h(s)ds 
(11.2)
Jo
is also non-negative. The relationships among the hazard function, the density 
function, and the survival function can now be written as
ад = 4^. fW = 
S(i) = {^, 5(i) = e-«<‘>. 
(11.3)
b\t) 
fl(t)
As lim^oo S(t) = 0, we have lim^oo H(t) = 00. If one knows any of the four 
functions in expression (11.3), then one knows them all. Specifically, along with 
equations (11.1) and (11.2), we have
ад = ^{Н«)}, H(i) = - log{S(i)}. 
(11.4)
at
Also, using the second and last equalities in expression (11.3), we have
F(t) = [ h(s)e~ % h^duds 
(11.5)
Jo
Survival analysis consists of models and inference for the sampling distribution of T 
(discussed in this chapter), often with primary interest in the relationship between 
explanatory variables and some function of T (the topic of Chapter 12). Inference 
on the sampling distribution will often focus on estimating S(t) or h(t).

Survival Modeling I: Models for Exchangeable Observations
313
11.1.2 Censoring
We introduce notation that is commonly used in survival analysis. This notation 
allows us to write mathematical models for situations in which one is not able to 
observe the actual time that an event occurred, such as in the examples at the 
beginning of the chapter.
11.1.2.1 Right Censoring
We will consider first the case of right censoring. This is the most common form 
of censoring in medical studies where we may be prevented from observing the 
precise time to the event of interest due to another “censoring” event occurring 
prior to it. The censoring event could be the study team losing contact with the 
patient (typically called “loss to follow-up”) or the time we wish to conduct inference 
(typically called the “end-of-study time”). Notationally, let C denote the random 
censoring time. The observed follow-up time Y is the minimum of the time until 
the event, T, and the censoring time C. With n patients, the observed outcome for 
patient i is = min(Ti,Ci), i = l,...,n. In addition to the observed follow-up 
time, Yi, we generally also learn whether the patient experienced the event or the 
censoring time. Data for survival analysis, therefore, consist of a set of follow-up 
times and a corresponding set of indicators that let us know if each patient’s time is 
the time until the actual event or if it is a censored time. Let Si denote the Bernoulli 
indicator of whether the event occurred at the time for the ith patient (i.e., the 
event time is not censored). Thus, <5» equals 1 if we observe the actual event time 
for individual i, and it equals 0 if we do not observe the actual event at the end of 
follow-up. The outcome data in survival analysis, therefore, consist of two random 
quantities, (Y4,5J, for i = 1,..., n, where (dropping subscripts)
Y = min(T,C) and 8 = 1 if T < C, S = 0 if T > C. (11.6)
This also means
<5=1 & Y = T and <5 = 0 Y = C. 
(11.7)
We care about censored data, because we want to include all information in the 
data set. Even censored observations contain information; a patient still alive 5 
years after entering the study tells us something about the treatment, particularly 
if most patients with this disease tend to die within a year of diagnosis.
11.1.2.2 Left and Interval Censoring
We now turn to two other kinds of censoring we may encounter: left censoring 
and interval censoring. An example of left censoring is the time of infection for a 
patient diagnosed with pneumonia. We know the infection preceded the time of 
diagnosis, but we usually do not get to record the actual time the pathogen caused 
the infection. Interval censoring occurs when an event time is both left and right 
censored. Interval censoring would occur, for example, if a woman underwent a series 
of mammography screening examinations every 2 years, starting at age 50, and has 

314
Bayesian Thinking in Biostatistics
a positive mammogram at age 62. We know the cancer reached a detectable level 
some time between the most recent cancer-positive mammogram and the previous 
negative one, but we do not get to record the exact time when the tumor became 
detectable by mammography.
11.1.2.3 Assumptions for Censoring Mechanism
A common assumption is that censoring is independent of the event of interest, 
that is, T is independent of C. An example where this assumption makes sense is a 
clinical study that analyzes the study data 5 years after the first patient enters the 
study. Patients still alive at the time of analysis will be those early entrants with 
long lives and the later entrants who have not yet been on-study long enough to 
have experienced the event. As long as there are no trends in the sorts of patients 
who enter the study over time and long-lived patients are as likely to enter the 
study early as late in the course of the enrollment period, it seems reasonable to 
assume that the time of analysis (i.e., the censoring time) is independent of the 
failure times. On the other hand, if older patients or sicker patients tend to enter 
the study in the latter part of enrollment or if the study team tends to censor 
patients who are about to die prior to their actual death, then it is inappropriate 
to assume independent censoring.
Another assumption is that the censoring distribution, say G(c) = P(C < 
c), does not depend on any of the same parameters as 5(t). This is called non- 
informative censoring or uninformative censoring. For example, suppose we observe 
survival in days for a single patient and see the event (uncensored observation) at 
у = 25. Then 25 would be our estimate of the center of the distribution, say the 
mean or median time of survival. However, if the observation is censored, (т/, 3) = 
(25,0), this would make our estimate of the same central measure something larger 
than 25. Now suppose we have informative censoring so that the time to event and 
censoring distributions have a parameter in common. Specifically, let T ~ Exp(0) 
with mean 1/6 and C ~ Exp(6/S) with mean 5/0. Seeing a censored observation of 
25 now makes us think that the median time to event should be about 4 because of 
the informative censoring. Non-informative censoring is assumed in most survival 
analysis studies.
Remark on the need for censoring. Inference would clearly be better if all observa­
tions were complete and none censored. This is often not feasible, nor advisable, as 
if one were to wait until all study participants have died. We may want to publish 
results sooner rather than wait many years to avoid censoring. Deleting censored 
observations from the analysis, however, would clearly bias the inference. Thus, 
the statistical methods for survival analysis incorporate all information, whether 
complete or partial, for all patients at a pre-chosen time of analysis.
11.1.3 Sampling Distribution (Likelihood) for Exchangeable Data
We need a way to characterize the sampling distribution of the observation times 
in the presence of censoring. Although any distribution for continuous random 

Survival Modeling I: Models for Exchangeable Observations 
315
variables that do not take negative values would be appropriate, there are a few 
families of distributions that are useful in survival modeling. These parametric 
distributions are the exponential, Weibull, log-normal, and gamma. We also discuss 
nonparametric estimation of survival distributions following the parametric cases 
in the next two sections, one-sample (Section 11.3) and two-sample (Section 11.4) 
models. However, the expressions in this subsection are in a general form, suitable 
for both parametric and nonparametric cases. These expressions are then adapted 
to the particular situations of the next two sections and their subsections.
11.1.3.1 Right Censored Data
Here, we assume that the only censoring mechanism at work in our data set is right 
censoring that is independent of the failure times. We consider the observations as 
pairs, (yi,<5i), for each individual in our sample (i = l,...,n), with yi and <5, the 
ith individual’s follow-up time and event indicator, respectively. The sampling dis­
tribution for the observations (conditional on any model parameters 0) is a product 
of the contribution from all observations stemming from the usual exchangeable 
(conditionally iid) model, although some care is needed in deriving this. We begin 
by noting that the usual model applies to the pairs (Т»,Сг), i = 1,... ,n and can 
be written as
ffi.Ci) I /(•),,( )-/(•)«(■), 
with Ti ~ /(•) independent of Q ~ g(-). Thus, as usual, we can write the joint 
distribution as
p[№,Ci),i = 
| /(-),p(-)] =ПА^(с<)-
г=1
However, unlike previously (see various subsections of Section 3.2), our observed 
data are data = {(j/i,<5»), i = 1,..., n}, not {(ti, c*),i
 = 1,...,n}. We now appeal 
to expressions (11.6) and (11.7) to see (Yi,6i) as the one-to-one transformation
Yt = {Т,}
*^}
1"*,  6i = I(Ti < Ci),
of (Ti,Ci), so that {(У»,<5г),г = l,...,n | /(•),#(•)} are iid since (^.G) I /(•)»$(•) 
are. So, the sampling distribution of the data can be written as p(data | в = 
{/(•)> #(•)}) = П7=1 P(yi^i I &)■ Now, we can write р(з/г,<5» | 0) by recalling from 
expressions (11.6) and (11.7) that 6i = 1 <=> {(3/
*
 = ti) and (Cj > yi)} and = 0 <=> 
{(j/i = с») and (ti > yi)}. This event equivalence and independence of T and C lead 
to the joint distribution
pfa” "I 1 lP(Ti>S«|e)=9(!«)Sta). if*  = 0.
An alternate way to write the last display is
р(й1
*,ад
 = №<){i - cw}}
*
1 шт,)}1-*'
= Ш){1 - G(».)}}
*'
 Ш()}’-4‘3(и)
= {л(и)}4‘ s(w){i - ОШ}‘‘ Ш)}1-4', 

316
Bayesian Thinking in Biostatistics
where S(-) is the survival function; h(-) is the hazard function corresponding to 
density /(•), with /(•) = /i(-)S(-) from expression (11.3); and g(-) and G(-) are the 
pdf and cdf of the censoring random variable C, respectively. We can thus write 
the sampling distribution (likelihood) as
Лил. i = i. ••.,»} । ff)« 
(ii-s)
t=l
Notice here the proportionality (rather than equality) for this sampling distribution, 
caused by omitting the multiplicative terms in g(-) and G(-). This omission would 
not be possible if there are shared parameters between /(•) and g(-), which are 
the distributional families of the survival time and the censoring variables. This 
would be the exceptional case of informative censoring mentioned in the previous 
subsection.
11.1.3.2 More General Case: Interval Censored Data
Suppose we have event times
ЛФ)
but each Tt is possibly censored in such a way that we would only observe that it 
falls between two numbers Li < Ui. As before, let <5г denote the indicator random 
variable of non-censoring. Thus, the observed data are
{
1, if uncensored,
0, if censored,
and Ti = ti if 6i = 1 or Ti G (Li,t/f) if 6i = 0. The case of right censored data 
above has Li = Ci and Ui = oo. Similarly, in the left censored case we would define 
Li = 0 and Ui = Ci where Ci is the left censoring time.
The sampling distribution for the data (likelihood function) is
p(data I «) = ft {/(«|/J’ 
(11-9)
Note that if 5i = 0, all that is known is Li < Ti < Ui.
11.1.4 Inference and Its Targets
With event times that arc conditionally iid from /(• | 0) and subject to right 
censoring, we work with the sampling distribution in equation (11.8) that uses the 
hazard and survival functions. Sometimes the following form, a precursor in our 
development of equation (11.8) using the density instead of the hazard function, is 
useful:
МЛ i = 1........»} | 9) а f[ {/,(», | 
| «)}■-'-. 
(11.10)

Survival Modeling I: Models for Exchangeable Observations
317
In the parametric cases, the functions h, f, and S are more appropriately written as 
h(- | 9), f(- I #), and S(- | 0) to make the parameter explicit. Indeed, that is how we 
have written equation (11.10). With prior p(ff), the posterior is obtained as usual. 
Occasionally, the posterior is recognizable, as we shall see with the exponential 
distribution. More often it is not recognizable, so we rely on MCMC sampling. As 
we have seen in previous chapters, even when an analytical solution exists, it is often 
easier to use posterior sampling as our inference targets are typically complicated 
functions of Q.
Given posterior samples {0(m) : m = 1,...,M} as MCMC iterates, for any 
function of 0, say 7 = <?(0), we approximate the posterior 39(7 | data) numerically 
by using the transformed samples {7^) = g(0(™>) : m = 1,... ,Л/}. We have seen 
this, of course, in many previous chapters. What is new here are the functions of 0 
that are the targets of inference and of particular interest in survival analysis. We 
list a few.
1. 
Mean survival time. While the meaning and importance of this target are 
obvious, for inference implementation as above, we need to express this mean 
as a function of 0 for the particular parametric model at hand. This requires 
a usually straightforward derivation or the use of Appendix B.
2. 
Median survival time. Again, the same comments apply here as for the 
mean, except for the direct use of Appendix B, which does not contain any 
expressions for the median. The quantile functions in R can be very useful 
here. Examples are qexp(0.5,...), qweib(0. 5,...), log(qnorm(0.5,...)) 
and qlnorm(0.5,...), depending on the scale of measurement. Inference for 
quantiles other than the median is accomplished in a same manner.
3. 
Survival probability at a fixed time point. This is a very common target 
(e.g., five-year survival after definitive treatment for breast cancer). For some 
parametric families, S(- | 0) is analytically available as a function of t and 
0. We can again use R functions here: l-pexp(t0,...), l-pweib(t0,...), 
l-pnormQog(tO),...) or the regular cdf functions with lower .tail=FALSE 
indicated in the function call.
4. 
Survival function. The entire estimated survival function can be displayed 
by plotting S(tj I 0), j = 1,..., J on a grid of points ,... ,tj}. At each 
point, the survival probability is computed as above and averaged over the 
MCMC samples. If one uses the quantiles of these samples at each time point 
to make posterior probability intervals (or credible intervals), these should be 
declared as pointwise intervals with the specified probability. A simultaneous 
probability band can also be computed, but it takes more care and an iterative 
process to accomplish.
5. 
Hazard function. Parallel to the case of the survival function, one must 
compute h(tj | 0(m)) for each j,m. One may employ analytic functions when 
available, or R functions using h(-) = f(-)/S(-)- Density functions are available 
as, for example, dweibO in R. For the log-normal distribution, one can use

318
Bayesian Thinking in Biostatistics
the dinorm О function; care must be taken to allow for the Jacobian when
working with the log-normal if using the R function dnormO.
11.1.5 Prediction
Prediction can be important in survival modeling, especially in the regression set­
ting of Chapter 12. As for most other models, point prediction and point estimation 
(here, of the population survival function) tend to agree with each other. The vari­
abilities or uncertainties associated with these, however, are almost always very 
different in size. Prediction for an individual is much less certain than estimation of 
a quantity averaged over the population. With Tf denoting a future survival time 
(conditionally independent of the current data, conditioned on knowing the “true” 
survival function), the predictive density is
f{tj | data) = J f(tj | 8)p{8 | data)d8.
The predictive survival function is similarly obtained as
S(tf | data) = У S(tf | 8)p(8 | data)dd.
From these, one can find the predictive median or mean and probability intervals 
if the integrals are analytically tractable. Such tractability being rare, we often ac­
complish prediction via simulation. As in previous chapters, we simulate a Tf from 
the distribution identified by each posterior sample of в, namely, generate from 
5(. । e^), m = 1,..., M. This collection of tfS approximates the predictive distri­
bution. When /(• | в) and/or S(- | 8) are available analytically or computationally 
(as in R), it is possible to carry out the above integrals as averages of MCMC 
samples of them. This avoids simulating Tf, and has better numerical accuracy.
11.1.6 Plotting Survival and Hazard Functions
As discussed in Section 11.1.4, primary objects of inference for time-to-event data 
arc the survival curve and the hazard function. To be displayed effectively, informa­
tion about these quantities should be plotted. Consider a general parametric model 
for survival data that depends on a vector of parameters 8 and, possibly, on a vec­
tor of covariate information x. For a one-sample problem (Section 11.3), x never 
changes and can be ignored. For a two-sample problem (Section 11.4), x identi­
fies the two groups and 8 contains parameters for both groups. More complicated 
models involving ,r are discussed in Chapter 12.
To estimate S(t\x,8) for all t > 0, we use simulated 8^,... from the 
posterior distribution of 8. For each we compute 5(t|x,8^). Since we cannot 
evaluate the survival function at all t > 0. we do this over a fine grid, perhaps 
t = 0.0.01.0.02........Tj. where Tj is just bigger than the largest observed time in
the data. Figure 11.1 shows the first 10 sampled posterior survival curves for the 
data in Example 11.3. Details of the data are given there along with modeling and 

Survival Modeling I: Models for Exchangeable Observations
319
inference in Section 11.3.1.1. The figure shown here is meant to help visualize what 
posterior samples of the survival function S(t|x, might look like. While the 
smoothness and shape of the curves are determined by the parametric model one 
uses, the variability seen is interesting and driven by the data and the prior on 
model parameters.
FIGURE 11.1: Ten instances of S(t) from posterior samples of the survival functions 
with model and data from Example 11.3.
From these samples, the posterior mean of the survival function and, if desired, 
of the hazard function can be approximated as
м 
, м
= “d = м E w'”’),
where can be computed as /(t|0(m))/S(f|0(m)) if necessary. For simplicity, 

320
Bayesian Thinking in Biostatistics
we have suppressed the possible dependence of these functions on a covariate vector 
x.
11.2 
An Empirical Survival Function: The Kaplan-Meier Estimate
The main target of inference in survival analysis is the survival function S'(t) = 
P{T > t) which equals l-F(t), where F(t) = P(T < t) is the cdf. Without censored 
data, we have the well-known empirical distribution function Fn(t) = ± 527=1 Л*»
 — 
t) as an omnibus estimate of F(t) without specifying a distributional form via 
a parametric family such as the exponential, Weibull or log-normal. A natural 
question then is how can this Fn be modified to accommodate censoring, beginning 
with its most common form of right censoring. Kaplan and Meier discussed such 
an estimator in 1958 [202]. This has become ubiquitous in describing survival data. 
Before explaining its construction, we consider data from a clinical trial to focus 
attention on a specific analysis.
Example 11.1. A Cancer Clinical Trial. The Cancer and Leukemia Group В 
(CALGB) conducted a randomized clinical trial to compare the benefits of three 
dose regimen intensities (high, moderate, and low) of a three-drug combination 
to treat non-metastatic breast cancer. The study, CALGB 8541, randomized over 
1,500 women to one of the three treatment regimens. The file CALGB8541. csv under 
Chapter 11 on the book’s website contains information collected in this trial, as 
shown in Berry et al. [37]. We give a brief description of the trial and the data set 
here, and use it in various examples in this and the next chapter.
Arm 1 (the high-intensity regimen) of the randomized trial consisted of women 
who received the most dose-intense regimen: four 28-day cycles of cyclophosphamide 
(600 mg/m2 on day 1), doxorubicin (60 mg/m2 on day 1), and 5-fluorouracil 
(600 mg/m2 on days 1 and 8). Arm 2 (moderate intensity) patients received lower 
dose levels of the drugs (400, 40, 400 mg/m2 on days 1 and 8), but in six 28-day 
cycles. Arm 3 received the low-intensity regimen made up in the same cycles as those 
in arm 1 but at the lowest levels of the drugs (300, 30, 300 mg/m2, respectively).
The data set contains several variables: seqno, study, arm, er, pgr, npn, 
tsizecm, premeno, survyrs, survstat, dfsyrs, and dfsstat. As needed in the 
examples that use this data set, we will describe the information contained in each. 
For now. seqno is the sequence number of study participants; study always equals 
1 for this trial, so we can ignore it; survyrs and survstat, respectively, contain 
the survival time in years and its censoring status (0 if uncensored time of death, 
1 if right censored). Note that in the notation of Sections 11.1.2 and 11.1.3, this 
variable represents 6 - 1 and not 6 itself. The variables dfsyrs and dfsstat are 
similar, except they refer to disease-free survival. This means if dfsstat=0, then 
dfsyrs is the time at which either death or disease relapse or recurrence occurred; 
if dfsstat=l. then dfsyrs is the time at which the patient was last known to be 
alive without relapse or recurrence of disease (but the patient’s disease or survival 

Survival Modeling I: Models for Exchangeable Observations 
321
status is not available beyond this point). Other variables in the data set contain 
tumor and patient information that we will describe as needed, mostly in Chapter 
12.
There are 519, 517, and 513 subjects in arms 1, 2, and 3, respectively. Of these, 
right censored observations number 265, 231, and 244 for the survival outcome and 
224, 188, and 197 for disease-free survival. The maximum follow-up time is about 
20 years in each arm. Focusing on arm 1 for this example, how might one construct 
an empirical estimate of S(t) for overall survival at some selected values of time 
t? The smallest right censoring time for overall survival is 3.47 years, and there 
are 67 deaths before this time ranging from 0.64 to 3.45 years. S(3.46) is easy 
to estimate since there are no censored observations before 3.46; we simply form 
the ratio (519 — 67)/519 = 0.871, which is the relative frequency of survival times 
known to be greater than 3.46 without ambiguity. Now consider i = 4.00. While 
there are 17 more deaths after 3.45 and by 4.00 years, for a total of 84 deaths by 
4.00 years, there are no more censoring events in this period. Here, it is not clear 
how to compute the relative frequency of deaths after 4.00 years. We know there are 
at least 519 — 85 = 434 patients alive beyond 4 years, but what about the patient 
who was right censored at 3.47 years? This patient may or may not have died by 4 
years; we simply do not know.
In general, with no censored observations, the empirical estimate is simply the 
relative frequency of observations greater than to, that is, Sn(to) = £ 
>
to) = 1 — Fn{to). Notice that even in the presence of right censored observations, 
Sn(to) is computable if all of the right censored cases occur after to. However, if 
one or more are less than or equal to to, it is not clear how to compute Sn(to), that 
is, how many of those censored observations with times less than to might have 
contributed uncensored event times had we followed them longer.
To address this problem, an empirical estimate is formed based on a previ­
ously existing product estimate that was used with life-table data. For continu­
ous time data it is called the Kaplan-Meier product-limit estimate or, simply, the 
Kaplan-Meier (or K-M) estimate. Here is how it works. Consider right censored data 
{(j/i,<5t),i = 
as defined in equations (11.6) and (11.7). Let tj < •■■ < t£
denote the к > 1 ordered times at which events occur, with к < n. Collectively, 
these times come from the observations with <5=1. However, к may not equal the 
count of uncensored observations if there are multiple observations with events at 
the same time point(s), that is, if not all the yt with <5j = 1 are distinct; in yet other 
words, multiple events at any t*  are allowed.
Now let ej denote the number of events at t*,  and n.j denote the number of 
patients known to be at risk of the event just prior to time t*-.  So, rtj is the number 
of observations with у > tj. In words, it is the number of patients who have neither 
experienced the event nor been censored before tj. This leads to the fraction (nj - 
ej)/rij as a natural relative frequency estimate of the conditional probability P(T > 
tj | T > tj). Note that this works for any t, not just an observed event time, because 
no events at t means ej = 0 and the conditional probability estimate equals 1. We

322
Bayesian Thinking in Biostatistics
(a) Overall survival, arm 1
FIGURE 11.2: Empirical (Kaplan-Meier product limit) estimates of overall and 
disease-free survival.
(b) Disease-free survival, arm 1
now write the K-M estimate as
Sn(t) =
(И-ll)
Notice that this is a non-increasing step function in t, constant between successive 
event times. It equals 1 at t = 0 if there are no events at time 0, and equals 
(n - ej/n if there are. Taking 0/0 to be 1, Sn(t) = 0, t > t*k if there are no 
censored observations at or beyond tk, that is, the largest event time exceeds the 
largest right censoring time in the data. However, if the largest event time does not 
exceed the largest right censoring time, Sn(t) = Sn(t£), t > tk. In other words, 
there is no strict decrease in Sn(t) beyond the largest event time.
Example 11.2. K-M Estimate for CALGB8541 Data: Example 11.1, Con­
tinued. Figure 11.2 shows the K-M estimates for survival and disease-free survival 
for arm 1 of the trial. The estimates were obtained by using the R package survival.
11.3 
Models for Samples from a Single Population
One-sample models involve sampling from a homogeneous population in which indi­
vidual observations are seen, as in Chapter 3. as exchangeable or conditionally iid. 
For survival data with exact and right censored observations, we developed a gen­
eral form of the sampling distribution (likelihood function), equation (11.8), in the 

Survival Modeling I: Models for Exchangeable Observations
323
previous section. Here we consider specific cases with analytical details, first with 
three commonly used parametric families, and then with a flexible nonparametric 
model similar to that in Section 3.3.
11.3.1 Parametric Models
When we take /(•), and consequently S( ) and /i(-). to be in a family of distribu­
tions indexed by a parameter 0 (possibly a vector), we consider the model to be 
parametric. We introduce three parametric models that are often used in survival 
analyses, along with priors and posterior analyses.
11.3.1.1 Exponential Model
The simplest survival model uses the exponential distribution, Exp(0). While it 
arises as the waiting time between events in a Poisson process (see Section 3.2.4), 
its usefulness is mainly as an introductory model. It is a bit too restrictive to fit 
most data in practice.
Let T\0 ~ Exp(9). Without right censored observations, the analysis would be 
identical to that in Section 3.2.4. As there, we use the Ga(ao,bo) prior here. It is 
easy to see that
f(t]9) = 9e-0t, S(t\0) = e~dt, h(t | 0) = 9, t > 0.
The median, to.5! satisfies 0.5 = exp(-0to.s), so that to.5 = log(2)/0 = 0.69/0. The 
hazard function is obtained as h(t | 0) = f(t | 0)/S(t | 0) = 9e~et/e~et = 0, which is 
constant in t. Thus, if the time to event has an exponential distribution, the hazard 
of an event occurring is the same no matter what the time. This constant hazard 
reflects the memoryless property of the exponential: the probability of surviving an 
additional time у given survival up to t, P(T >t + y\ T>t), does not depend on 
t; it equals е~ву. The hazard (which is a conditional instantaneous rate) of an event 
after, say, 100 years is the same as the hazard of the event at any other time, 0 
included. Interpreted this way, the memoryless property is also called the “no-aging 
property.”
Now consider data yi = min{Ti,Ci}, 5i = I(yi = Ti), and Ti ~ Exp(9). With 
the prior 0 ~ Ga(a, b), using equation (11.8), we have
p(0 | data) oc
p(data | 0)p(0)
0a°-le-0b°
Qa0+nu-lg~0(bo+Z7=i Vi)
where nu = Yli=i fa *s t^e number of uncensored observations. Recognizing the last 
expression above as the kernel of a gamma, we write
0 | data ~ Ga(ai,5i),
(H-12)
where ai = a0 + nu and bi = bo + ny. As in Section 3.2.4, the gamma prior 

324
Bayesian Thinking in Biostatistics
is conjugate for the exponential, even with right censored data. While sampling 
approximations to posteriors are typically needed for other models, the analytic 
results in this simple parametric family are nice to see and can serve as building 
blocks for more flexible models. With this posterior, it is straightforward to obtain 
posterior probability (or credibility) intervals for в. We simply find f. and и such
1-а = Р^£<в<и 
.
Taking £ and и as the lower and upper a/2 quantiles of the Ga(ai,bi) distribution 
satisfies this equality. These quantiles can be determined computationally by using, 
for example, the function qgammaO in R.
Inference for the survival function S(t | в) is straightforward too. Any quantile 
of the posterior distribution of the survival function at any t can be obtained easily 
by noting that this is a monotonically decreasing function of в that has a gamma­
distributed posterior given the data. To be specific, we have, for example, that the 
posterior median of S(t) is exp{—0meat}, where 0med is the posterior median of в 
that one can obtain from the Ga(ai, bi) in equation (11.12). For other quantiles, it 
can be easily shown that the ath quantile of S(t) equals exp{—0i_Qt}, where 0i-Q 
is the (1 - a)th quantile of 6. An alternative to this approach that also works in 
distributional models that are not so nice analytically as the exponential is posterior 
sampling of в followed by plots of S(- | 0^). This was done and shown in Figure 
11.1.
How do we select the prior for 0? The considerations are exactly the same as 
in Example 3.5 in Section 3.2.4. Essentially, we specify a prior best guess for the 
median and a large probability (say, 90%) interval for it. These specifications yield 
a system of two equations for two unknowns. We then use an iterative numerical 
process to solve for the unknowns ao and bo. Details are given in Example 3.5.
Prediction. Using the Ga(ai, bi) posterior, we derive the predictive survival dis­
tribution as
S(tf\data) = J е~в1/р(в | data)d6
Jo 4^1)
= 
[ ^i-ie-e(u+bi)d0
гы Jo
_ b? 
r(aj)
~ ЦаМ + м-»
- (—bi V1
v/ + bi/
The predictive density is the negative of the derivative of this S(tf | data). Such 
clean analytical results are rare with censored data.

Survival Modeling I: Models for Exchangeable Observations
325
Example 11.3. Exponential Model Analysis. Let us consider the disease-free 
survival outcome in arm 1 of the CALGB 8541 trial described in Examples 11.1 and 
11.2. Since we have an explicit distributional result for the posterior in expression 
(11.12), we used R to obtain posterior samples of 0. We employed a diffuse prior with 
ao = 1.4 and bo = 5 that gives E(l/0) = 11.5 with a 95% interval for 1/8 extending 
from 1.1 to 57.6 years a priori. Using these samples of 0, we constructed a posterior 
95% probability interval for 1/0, the mean disease-free survival time. With code 
available on the book’s website in file named ExpModelAnalysis.R under Chapter 
11, we obtained E{l/0 | data) = 16.7 and P(14.9 < 1/0 < 18.7 | data) = 0.95. The 
posterior mean disease-free survival function and a 95% posterior probability band 
for it are shown in Figure 11.3. As a reference, we also show the Kaplan-Meier 
curve in the figure.
Disease-free survival
FIGURE 11.3: Posterior mean of S(t) for disease-free survival in arm 1 (Example 
11.3). Dashed lines show 95% posterior probability band for S(t). Kaplan-Meier 
estimate is also shown.

11.3.1.2 Weibull Model
The Weibull distribution is a generalization of the exponential that incorporates 
a power transformation. If T ~ Weib (а, Л), then Ta ~ Exp(A); thus a is the 
power that transforms the Weibull into an exponential. A Weibull with a = 1 is 
an exponential. In our notation from the general presentation at the beginning of 
Section 11.1.3, 0 = (a, A) for the Weibull sampling distribution.
Define T | a, A ~ Weib (a, A) if
/(t|a,A) = Aata-1e-At“, S(t | a, A) = e~Xt“, t > 0, a > 0, A > 0.
Percentiles of Weibulls are easy to find: the 1 — /3 percentile is the value ti-p 
that satisfies /3 = P(T > ti-&) = exp{-Ati'_j3}. Solving, we obtain t\-$ = 
{—log(/3)/A}1/a. In particular, the median to.5 is the time at which the survival 
probability is 0.50, that is, 0.50 = exp{—Ato.5} so that to.5 = {log(2)/A}1/a. The 
mean is more complicated, but we often focus on medians in survival analysis. The 
hazard function is
fe(t|a,A)=^ °’* =Aata-‘.
5(t I a, A)
The hazard is increasing in t if a > 1, and decreasing if a < 1.
Now consider data yt = min{Ti,C'i}, = I(yt = TJ, and Т\ ~ Weib (A), 
i = 1,..., n. Using equation (11.8), we have
p(data I a, A) = №<< 1}<5iexp(-A?/?) 
i=l
= Ua)nu 
exP 
’
with nu = 
Letting v = — 
) an<^ w(a) = 
y?, we have
p(data I a, A) <x (Xa)n'‘e-ave~Xw<a'>. 
(11.13)
This is not the functional form of a recognizable joint distribution for (a, A), unless 
a is known. If a is known, it is the kernel of a gamma distribution for A and would 
lead to the gamma prior as the conjugate family. This, however, is the same result 
as for the exponential model, essentially stemming from the fact that a Weibull with 
known a can be turned into an exponential. With a unknown, and w(a) depending 
on a in a complicated way. we do not have a known prior for (a, A) that leads to 
a recognizable. analytically tractable joint posterior distribution. While we must 
rely on simulations, we can utilize to advantage the conditionally conjugate gamma 
prior for A as described in the following.
Recall from Section 4.1.2 that we considered p(a, A) ex p(A | a)p(a) with A | 
о ex Ga(o.b), and this led to conditional conjugacy for A as p(A | a,data) = 
Ga(a + n.6 + J2"=1 y“). Now the sampling distribution for the data with possibly 
some right censored observations in equation (11.13) is of the exact same form

Survival Modeling I: Models for Exchangeable Observations
as that without right censored observations that we considered in Section 4.1.2. 
The details are different: Act is raised to power nu. not n: and in the middle term 
of products of yi the product is only over uncensored observations. So. just as in 
Section 4.1.2, this leads to A | a ex Ga(a + nu,b + 
?/P) a,id
p(o I A, y) oc on" {fb?} ^A(E'-
It remains to specify the form of p(a). Again, we turn to the uncensored ease in 
Chapter 4. In particular, in Example 4.4 we used the prior obtained via an auxiliary, 
Pareto-distributed, ф (first introduced in the context of gamma observations in 
Example 4.3). To be specific here, the prior for a is the marginal distribution 
stemming from
p(a,0) oc p(a | 0)p(0) ос |^/(o,»)(a) | 
c > 0, d>0,
that is, a | ф ос [7(0, ф), ф ос Par(c, d). This distribution has some useful proper­
ties as a prior for the shape parameter in the Weibull model.1 We develop these 
properties in Exercise 11.8.
‘Also for the gamma shape parameter; we used it in Section 4.4.1, Example 4.3. Unlike in the 
gamma case, however, this prior continues to be useful for the right censored case for the Weibull.
2For a fixed a, a scale change of t keeps the transformed variable in the Weibull family as a 
member with the same a but the new A depends on a.
For posterior Gibbs sampling, we can directly adapt the full conditionals of 
Example 4.4:
р(ф | a, A, data) ос ф (d+2)/(max{c,a},oo)(^),
p(a | ф, A, data) ос аПи
p(A | а, ф, data) = p(A | a, data) = Ga
As mentioned in Example 4.4, the full conditional for a is log-concave, so the R 
code given there is usable here with minor changes as would be indicated by the 
notational and likelihood changes above.
We now turn to the problem of specifying the parameters in the prior for a 
and A. This is a more challenging task here, since there is no nice interpretation, 
even for A when a / l.2 Moreover, a is difficult to think about. Our idea is to pick 
alternative interpretable quantities that are easy to think about, specify distribu­
tional aspects of these, and translate this information to solve for the parameters 
in the distributions for a and A. We have used this technique many times in pre­
ceding chapters; for example, in specifying prior parameters in the examples in 
Sections 3.2.1-3.2.4 (see Example 3.5, in particular). A natural choice here for one 

328
Bayesian Thinking in Biostatistics
alternative quantity is the median survival to.5 = (log(2)/A)1/Q; another is a high 
percentile such as the 90th, denoted t0.9, so that 0.1 = P(T > <0.9) = e~xt°-9. The 
technique then proceeds by solving for the model parameters a and Л in terms of 
to.5 and <o.9- We find it convenient here to consider a and A in sequence.
Although individual values of a are difficult to interpret, the hazard function 
is h(t | a, A) = AatQ-1, so that a = 1 is the dividing value between decreasing 
and increasing hazard in time. In many biomedical applications it may be possible 
to assess a prior probability that the hazard is decreasing, that is, specify pdhr = 
P(a < 1). This would occur, for instance, if the risk of an event such as death after 
a surgery is the highest soon after the surgery and diminishes as recovery proceeds. 
Increasing hazard might be considered if time 0 corresponds to diagnosis of early 
stage cancer. It is reasonable to specify an informed choice for pdhr- or take it as 
1/2.
To focus on the prior for a, it turns out (see Exercise 11.8) that its marginal 
distribution is a mixture of a uniform and a Pareto. In particular,
a ~ 7гС7(0,с) + (1 — 7г) Par(c, d).
We also have
{
cd
1--Г—-, C<1, 
dt
(d+ l)c’ C~ l’
Now, from the distributions table in Appendix B, the variance of Par(c, d) is finite 
only if d > 2. We suggest d = 3 for typical use to keep the variance of a finite yet 
reasonably large. Also, using the above expression for P(a < 1) = pdhr and solving 
for c, we get
{
d . 
' d
J^/Pdbn 
Pdhr <
{(d + 1)(1 -Pdh,)}1/d, Pdhr >7^7- 
d + 1
With these choices, d = 3 and c as above, we can proceed to specify a and b in 
the prior for A. Here, we would like to use the expression for the 1 — /3 quantile of the 
Weibull-distributed T, namely, = {- log(^)/A}1/Q. If we fix a reasonable value 
of a (say, о») according to its prior, we can use this quantile expression to advantage 
in specifying a and b. One such choice for a» is its prior mean E(a) = 0.5cd/(d— 1) if 
d > 1 (see Exercise 11.8). Next, denoting the elicited best value for the prior Weibull 
median <o,5 by <5.5, we solve <q 5 = (log(2)/A)1/Q* to get A, = 0.69/(<5 5)Q’ • Then, 
with A*  as the mode, (a - l)/b, of the prior A ~ Ga(a,b), we have a = 1 + X*b.
 
Finally, one more elicitation from the scientist expert allows determination of both 
a ami b. For this, denote by uq.95 the expert-specified value for the prior 95th 
percentile for the median of event time T, P(<o.5 < «0.95) = 0.95. This represents 
the uncertainty in the expert’s point value <5 5 for the median of T. We can now 
write
0.95 = P{(log(2)/A)1/«- < uo.95} = P{0.69/ug;95 < A).
Thus 0.69/uq*95 is the 5th percentile of A ~ Ga(l + A»b, b). We can determine 

Survival Modeling I: Models for Exchangeable Observations
329
b by trial and error using pgammaO or qgammaO in R. See code in the tile 
WeibModelAnalysis.R on the book’s website under Chapter 11.
An alternative to the uniform-Pareto hierarchical prior for о (see Example 4.4) 
is to take < = log(a) ~ JV(c, d) where c = log(cu). With P(a < U0.95) = 0.95. we get 
■P(C < log(uo.95)) = 0.95. Standardizing gives 0.95 = P{(< - o)/\/d < (log(uQ) - 
c)/\/d}. Since 1.645 is the 95th percentile of the standard normal distribution, 
we have 1.645 = (log(ua) - c}/\fd which gives d =■ {log(ua} - c)2/1.6452. If we 
take a, = 1 and ua = 5, then d = 0.957. With such choices of c, and d, we 
can proceed to determine a and b in the prior for A as explained in the previous 
paragraph.
(a) Overall survival
FIGURE 11.4: The figures show prior and posterior means of overall and disease-free 
survival functions, along with pointwise 95% probability intervals, for the Weibull 
sampling distribution in Example 11.4. The empirical K-M curve is also shown.
Omm-kw wrvMi ten»
(b) Disease-free survival
Example 11.4. Weibull Model Analysis. To illustrate the analysis for this 
model, we return to the arm 1 data of Example 11.3. Using the uniform-Pareto 
hierarchical prior for a, the conditional gamma prior for Л | a, and following the 
prior elicitation process described above, we made the following choices to represent 
a relatively low level of information: d = 3, Pdhr = 1/2, giving c = 3/2 and leading 
to a» = 1.125. Specifying <0.5 = 12, u0 95 = 20 yielded А» = 0.04234, and computing 
0.69/^0.95 = 0.02383 as the 5th percentile of Ga(l + A»t>,b), we obtained b = 3.325 
by trial and error. Finally, a = 1+X,b= 1.141. Relevant code for this entire example 
is in the file named WeibModelAnalysis.R under Chapter 11 on the book’s website.
To carry out the analysis, we used an appropriate modification of the R code for 
inference with the Weibull model first presented in Section 4.1.2. The modification 
accommodates the sampling distribution in expression (11.13) that allows for right 
censoring. Results obtained with the above referenced R code are shown in Figure

330
Bayesian Thinking in Biostatistics
(a) Disease-free Survival Function
(b) Disease-free Median Survival
FIGURE 11.5: The figures show posterior comparisons of disease-free survival func­
tions and median survival time along with pointwise 95% probability intervals for 
the survival function, for the exponential and Weibull models in Examples 11.3 and 
11.4. The empirical K-M curve is also shown.
11.4 for both the overall and disease-free survival functions. Also shown are point­
wise 95% posterior Pls, and the empirical К-M estimate for reference. We used the 
same prior parameter settings for both outcomes. The prior mean and 95% Pls are 
shown too. It is quite clear that this is a low-information prior and the posterior 
inference is almost entirely determined by the information in the data.
Figure 11.5 shows posterior inference with the exponential and Weibull models. 
There is some difference in the inference with the two models, especially for the me­
dian survival time. The respective posterior medians and 95% posterior Pls for them 
are: exponential model, 11.55 (10.32,12.95); Weibull model, 12.27 (10.71,14.04).
11.3.1.3 Log-Normal Model
Analysis for the log-normal sampling model is similar to treatment of ordinary nor­
mal data. If there are no censored cases and we transform the data with logarithms, 
the likelihood function takes the same form that it did in Section 3.2.2. Adding cen­
sored observations alters the likelihood and the posterior but not the prior. Neither 
reference priors nor prior elicitation changes because of censoring. The “reference” 
prior is still p(p. t) x \/t (t is the precision) but the posterior is more complicated 
with censoring. Our standard prior for this model is a normal distribution for ц and 
an independent gamma distribution for r. We sometimes specify a uniform distri­
bution for a. As illustrated in Section 3.2.2. priors are induced from information 
on the median and another convenient percentile of the distribution for T. Prior 
elicitations and posterior inferences about medians and other percentiles transform 

Survival Modeling I: Models for Exchangeable Observations
331
easily from the original scale to the log scale and back again. The model can be 
written as
log(Tf)|M,T^^,l/r) or T^LN^I/t)
with
v) ind r ~ Ga(a,b).
Here, we have the density and survival functions
= ^=~t exp{-^(!og(t)-/t)2}.
S(t|/i,r) = 1 - Ф { \/7[log(t) - /<]} .
where Ф(-) is the cdf for the N(Q, 1) distribution. The median t0.5 satisfies 0.50 = 
P(T < to.s) = P(log(T) < log^o.s)), so log(io.o) = Mi the center of symmetry of the 
N(p, 1/r) distribution. Obviously then, to.5 = eg. The distribution of T is skewed, 
so the mean is not as useful as the median and slightly more difficult to obtain. 
The hazard function does not simplify beyond being the ratio of the two expressions 
for f and S above. However, the a percentile of the log-normal distribution has an 
explicit form: 7 = where a = 1/x/r and za is the a percentile of the 2V(0,1). 
This occurs because P(T < eM+2t>CT) = P(log(T) < д + zQa) = P((log(T) - д)/ст < 
za) = a.
For analysis of this model with a data set, we refer to Exercise 11.9. Depending 
on the software you use (BUGS, JAGS, or Stan), you will need to code the model 
as described in Appendix C. They each use a different mechanism for specification 
of censored observations.
11.3.2 Nonparametric Models
An important part of inference with time-to-event data concerns estimating the risk 
of death over time. The most common way of presenting this inference is by way 
of the survival curve. That is, we compute an estimate of S(t). The Kaplan-Meier 
or product-limit estimator is a popular method most often used for estimation of 
the survival probability curve [202, 204]. This is an empirical method that also has 
justification as a nonparametric maximum likelihood estimate ([210]).
One approach to Bayesian nonparametric inference is based on the Dirichlet 
process (Ferguson [108]). We introduced this towards the end of Chapter 3. To 
recall, the Dirichlet process (DP) is a way to characterize a distribution on the 
set of distributions. In Section 3.3 we presented the DP via its stick-breaking con­
struction and proceeded to introduce Dirichlet process mixtures (DPMs) of normal 
distributions as a model for an unknown density. Here we work with the DP itself 
and write
tu...,tn I F ~ F, F ~ DP(M,F0), 
(11.14)
as a model for uncensored data. It turns out [108] that with such conditionally iid 
observations, the posterior of F is
\ 
M + n M+nn^ j 

332
Bayesian Thinking in Biostatistics
where 6t indicates unit point mass at t. Thus, the DP is a conjugate prior for the 
distribution function, and lends itself quite naturally to estimating a distribution 
function or survival function.
The above discussion does not include censored observations. It turns out that 
the posterior distribution with censored observations is a mixture of DPs. Several 
authors have described posterior inference with a DP prior in the presence of cen­
soring, including Susarla and van Ryzin [313], Blum and Susarla [43], and Ferguson 
and Phadia [109]. Kuo and Smith [209] described the use of the Gibbs sampler 
to generate random samples from the posterior distribution of the survival curve 
based on a DP prior. They consider left, right, and interval censoring. Rosner [273] 
illustrated the use of a DP prior for monitoring clinical trials, which typically in­
clude right censored observations. Posterior sampling consists of two steps in this 
approach. In the first step, one computes the posterior, conditional on the uncen­
sored observations. This posterior is just a DP as in expression (11.15) and requires 
no sampling. The next step predicts the future failure times for the censored ob­
servations. This step uses MCMC methods to carry out posterior inference. Within 
each iteration, the MCMC imputes a possible future failure time based on the cur­
rent posterior DP. One can either use the posterior, conditional on the observed 
failure times and the failure times imputed at the previous iterations, or one can 
update the posterior after each imputation within a chain. Regardless of the ap­
proach taken, one ends up with a mixture of DPs, thanks to the imputations for 
the censored observations. After convergence, one uses the posterior samples for 
inference, since they are random samples from the correct posterior distribution.
Before we describe another, recently developed, model that is based on a DP 
mixture, we note that the advantage of these flexible nonparametric models over the 
Kaplan-Meier empirical estimate stems from the Bayesian inferential framework. 
While the posterior mean based on the DP prior and the Kaplan-Meier estimate are 
generally very close to each other under low-information priors, one can carry out 
predictive inference much more easily within a Bayesian framework. The advantage 
of posterior prediction is evident if one is monitoring an ongoing study, for example, 
and one wants to estimate the probability that the study will reach a solid conclusion 
after accrual of patients ends and planned follow-up is complete (i.e., the end-of- 
study analysis). One can easily impute the future event times for currently censored 
observations and for future enrollees into the study. If projecting to end-of-study 
time, one can simply treat imputed event times as censored at the end of the study 
if they exceed that date. The general form of the algorithm in R-like statements is 
shown in Figure 11.6 and is also available on the book’s website for this chapter in 
a file named GibbsDP.R.
Example 11.5. DP Prior Model. We illustrate the algorithm by estimating the 
disease-free survival from the clinical trial described in Example 11.1. We focus 
again on arm 1 in this example, namely, the group that received the most dose­
intense regimen. Figure 11.7 shows prior and posterior mean survival functions 
and the Kaplan Meier estimate of the disease-free survival probability for the 519 
women randomized to receive this regimen. The prior mean, Fq. is a piecewise

Survival Modeling I: Models for Exchangeable Observations 
333
for = (iter in 1:(Maxlter-l)) {
PostDirichletParms[iter,] • TempDirichletParms
ProjectedFailTime *=  rep(NA, nCensor) 
for - (j in l:nCensor) { 
# Grab the remaining time for the censored observation.
Startlndx « findInterval(CensorTime[j], TimeGrid) 
PotentialFailTimes » TimeGrid[(StartIndx+l):nGrid] 
# Use multinomial sampling over the remaining time grid to 
# generate a future failure time for the censored observation. 
# The multinomial probabilities are proportional to the 
# parameters from vector TempDirichletParms corresponding 
# to the part of the time grid to the right of the censored time.
ProjectedFailTime[j] -
sample(PotentialFailTimes, 1, 
prob»Probs[iter, (Startlndx+l):nGrid] ) 
}
# 
Add the imputed failure times to the current Dirichlet 
# distribution parameter vector.
Matchlndx - match(ProjectedFailTime, TimeGrid) 
oMatchlndx - order(Matchlndx) 
TempTable = table(Matchlndx) 
for (i in l:length(TempTable)) { 
loc " as.integer(names(TempTable)[i]) 
PostDirichletParms [iter, loc] « TempDirichletParms[loc] + TempTable[i] 
}
# 
Generate a sample from the posterior Dirichlet distribution
# 
(with the imputed failure times at this iteration) 
# via random gammas.
Probs[iter+1,] - rdirichletU, PostDirichletParms[iter,]) 
}
FIGURE 11.6: General form of the algorithm in R-like statements. This code is 
available on the book’s website for this chapter in a file named GibbsDP. R.
exponential function consisting of the following two hazard rates: during the first 
year of follow-up, the hazard was 0.1, switching to a constant of 0.2 thereafter. 
Figure 11.7a shows what happens when the prior mass parameter is M = 2 in the 
DP prior. By contrast, the prior mass parameter was M = 100 in Figure 11.7b. In 
both cases, we ran the Gibbs sampler for 500 iterations and discarded the first 100 
as burn-in.
In Figure 11.7a, the Kaplan-Meier estimate and the posterior mean are almost 
indistinguishable. The prior mean is far from the data and does not appear to have 
influenced inference in this example. When the prior mass is 100, as in Figure 11.7b, 
which is roughly one-third as large as the number of events in the data (295), the 
prior has more influence on posterior inference.
One can also illustrate the precision in particular estimates. For example, the 
posterior distributions of the disease-free survival at 1, 5, and 10 years are shown 
in Figure 11.8.
We now describe a method originally proposed by Kottas [207], especially as 
developed by Shi [293] and in Shi et al. [295, 296]. The accompanying R package 
DPWeibull [294] implementing these methods makes computations quite accessible 
for analyses encountered in this and the next chapter. The model used is one we 
described in Section 3.3.2, the Dirichlet process mixture, here made up of Weibull

334
Bayesian Thinking in Biostatistics
FIGURE 11.7: The figures show the prior and posterior means of disease-free sur­
vival, and the Kaplan-Meier estimate.
----- DP Prior м = 2 
— DP Prior M = 100
DFS @ 1 year
Probability
FIGURE 11.8: The posterior estimates of disease-free survival at 1, 5, and 10 years 
with prior F ~ DP(M, Fo), where Fq is the piecewise exponential function de­
scribed in the text. When M = 100, the prior has greater influence on posterior 
estimates, especially at later times when there is less information.
distribution components. In particular, we can write a simpler version of the model 
as
T, \щ.х/'~ Weib(ahXi), (a,, A,)|G ~ G, G ~DP{v, Go). (11.16)
To specify the prior for this model, we must make choices for v and Go- The Bayesian 
nonparametric models literature strongly recommends a gamma distribution for v,

Survival Modeling I: Models for Exchangeable Observations
335
and a hierarchical prior for Go- Shi et al. [296] follow these recommendations to 
specify priors for a particular standardization of the data with the intention of con­
structing a rich set of Weibull components for the DPM that have good probability 
content in the relevant range of the data, while also allowing for possibly long-tailed 
distributions. We skip the details here as our intention is to use this methodology 
for applications and to illustrate the type of inferences it allows. We note, however, 
that the method in Shi et al. [296] is designed to include situations in which very 
little information is available for determining substantive priors, that is. to include 
low-information omnibus (LIO) priors (see Section 8.4.3). If substantive prior in­
formation is available, currently there is a need for appropriate prior elicitation 
methods for this model. We expect that such methods will be developed in the near 
future following similar developments for other Bayesian nonparametric models.
(a) Survival functions
(b) Hazard functions
FIGURE 11.9: The figures show posterior means of overall and disease-free survival, 
and corresponding hazard functions for a Dirichlet process mixture of Weibulls 
analysis of the clinical trial data in Example 11.6. Also included are pointwise 95% 
posterior probability intervals.
Example 11.6. DPM of Weibulls Model. We return again to data from arm 
1 of the CALGB8541 trial introduced in Example 11.1 and continued in Example 
11.5. Here we illustrate the use of the DPM of Weibulls model in expression (11.16). 
With the DPWeibull package in R, the code (in file DPMWeibullmodelCALGB.R) is 
fairly simple. Figure 11.9 shows posterior mean survival and hazard functions for 
both overall and disease-free survival, along with their corresponding 95% posterior 
probability intervals. The output object generated by the function dpweib contains 
posterior samples which can be post-processed to obtain full posterior inference 
for many other quantities, such as mean and median survival times or survival 

336 
Bayesian Thinking in Biostatistics
probabilities at chosen time points as in Figure 11.8. We illustrate this further in 
Example 12.4.
In the survival analysis literature, there are many alternatives to the DP method 
described above. An early method specifying a prior on the space of increasing 
hazard functions is developed in Dykstra and Laud [100] and Laud [215]. Some 
extensions and computations can be found in [216, 342]. In the past two decades 
these priors have been generalized and adapted to various survival analysis situ­
ations. Another method is based on piecewise exponentials, considered in Ibrahim 
et al. [171]. We describe this method in some detail and show its use in the next 
chapter on regression methods in survival analysis.
11.4 Two-Sample Models
As in Chapter 5, comparison of two populations is a very commonly encountered 
situation in medical studies. Classic examples include a comparison of patient 
outcomes with a treatment versus placebo, studying sex differences in outcomes, 
or examining adult versus pediatric populations. In Chapter 5 we considered re­
sponses that were normally distributed or binary or in the form of counts. Here 
the focus is on time-to-event outcomes with possibly censored data. The generic 
two-population-comparison design begins with independent sampling from the two 
populations.
With independent, possibly censored, samples from two populations i = 1,2, the 
observations are written as у = {yij = min(7ij,<5y) : i = 1,2; j = 1,... , where 
the non-censoring indicators are defined as 5^ = I (Ту < Cij) for right censoring 
and as 6ij = I(Lij < Tij < Uij) for interval censoring. The task is to compare 
the populations’ survival prospects. This involves comparing their survival curves, 
say, Si(t) and 5г(<), or comparing the densities for the groups, /i(t) and /2(^)- 
The top row of Figure 11.10 illustrates this idea. Alternatively, one could com­
pare the hazard functions /ii(t) and perhaps by examining the hazard ratio 
hi(£)//i2(£), as illustrated in the bottom row of Figure 11.10. The relative median 
*s another common target of inference. In the context of randomized in­
tervention and control groups, such group differentiating quantities are often called 
effect measures.
In Bayesian analysis, the two-sample model is very similar to the correspond­
ing one-sample case, especially when the two samples are independent. Posterior 
sampling can be done separately for each sample, repeating the one-sample version 
for each. Then, any effect measures quantifying group differences can be calculated 
from these samples to obtain the posterior samples of the effect measures of inter­
est. Typically, from a programming standpoint, we accomplish this by writing code 
in a single program. We provide one example below, and encourage the reader to 
recognize this “repeat twice” aspect of the problem addressing comparison of two 
populations in the independent samples and priors case.

Survival Modeling I: Models for Exchangeable Observations
Group 1
I \ Group 2
t
FIGURE 11.10: Illustration of effect measures for comparing two groups in survival 
analysis.
It is important also to point out that there are exceptions to this. In some cases, 
the priors in the two models may not be independent. In others, the samples may 
not be independent. An example of the latter situation is if the study forms pairs 
of subjects by matching on age and disease stage and randomizing one member of 
the pair to the treatment and the other to the control regimen. Appropriate care 
must be exercised in obtaining posterior samples in such paired-data situations.
Before turning to the example, we mention that the two-sample problem can 
be cast in the framework of regression, using a binary covariate to indicate group 
or population identity. We pointed this out also in the context of continuous, bi­
nary, and count data outcomes, as in Chapters 7, 8 and 9 on regression. These 
regression models contained the corresponding two-sample cases of Chapter 5. For 
time-to-event data, we typically use semiparametric formulations that involve an 
assumption of proportional hazards or accelerated event times as explained in Chap-

338
Bayesian Thinking in Biostatistics
TABLE 11.1: WinBUGS output for leukemia data
node
mean
sd
2.5%
median
97.5%
medianl
43.030
10.560
27.040
41.490
68.060
median2
13.030
3.234
8.124
12.550
20.650
relmedian
3.495
1.202
1.718
3.303
6.380
S[l]
0.668
0.062
0.541
0.670
0.783
S[2]
0.272
0.082
0.129
0.266
0.447
Sdiff
0.396
0.103
0.183
0.400
0.585
thetal
0.017
0.004
0.010
0.017
0.026
theta2
0.056
0.013
0.034
0.055
0.085
ter 12. As such, these models may not quite contain the two-independent-samples 
case, not without an additional assumption.
Example 11.7. Leukemia Data. In Example 3.5, we modeled part of the data 
presented in Feigl and Zelen [107], namely the survival times of 17 AG+ (POS = 1) 
patients. Here we also include the 16 patients in the AG— (POS = 0) group and 
compare the survival times of the two groups. With i = 1 for the AG+ group, we 
use the exponential model with a gamma prior described in Section 11.3.1.1, and 
write
Тц | Xi ~ Exptfi), i = 1,2; j = l,...,ni, 0; ~d GoM, i = 1,2.
We construct a prior with the following information. Suppose the best available 
pre-data value for t^, the median survival time of AG— patients, is 20 weeks, and 
we believe that the median is greater than 5 weeks with 95% certainty. With such 
information, albeit with different numbers, we described in Example 3.5 how a\ 
and bi can be determined using relatively simple R code. Following this method, 
we get 02 ~ Ga(2.31,37.95). For 0i we use a Ga(1.53,26.4), which has mode 0.02 
and 95th percentile 0.15. These correspond to a prior guess of t^l = 34.5 weeks and 
a 5th percentile of 4.6 weeks. As a reference prior, we approximate Jeffreys’ prior 
р(01,0г) 
l/(^i^2) by independent Ga(0.001,0.001) priors.
Code for the analysis is on the book’s website under Chapter 11 with file names 
Leukemia.xxx. Table 11.1 provides the output when using the informative priors. 
The prior and posterior distributions for 6\ and 02 are plotted in Figure 11.11. The 
median time to death for the AG-I- group is estimated as 41.5 weeks with 95% 
probability interval (27.68). much higher than for the AG— group with estimate 
12.6 weeks and 95% probability interval (8,21). The relative median 62/^1 is roughly 
3.3 and probably between 1.7 and 6.4. About two-thirds of AG+ patients will live 
at least 24 weeks, whereas only about a quarter of AG- patients will live 24 weeks 
or longer. The probability intervals do not overlap. The difference in the 24-week 
survival probabilities is about 0.4. with a probability interval that is clearly positive.
A sensitivity analysis was conducted using the informative prior and two sets of 
diffuse priors: 
~ G«(0.001.0.001) and 0Ь02 ~ (7(0,1000). The gamma priors

Survival Modeling I: Models for Exchangeable Observation,
339
FIGURE 11.11: Prior (dashed lines) and posterior (solid lines) distributions for 0i 
and fa.
have mean 1 and variance 1,000. Both priors can be considered diffuse, given what 
we know about leukemia survival times. Results are given in Table 11.2 along with 
some from the previous analysis. Even with the relatively small sample sizes, the 
different priors do not give appreciably different results.
In Section 11.1.6, we described how to generate and plot posterior samples of 
survival functions on a grid. Following this method, we generated Figure 11.12. 
Here S(t | 0) has an explicit form so it is easy to evaluate at each grid point. With 
the MCMC samples, it is also easy to obtain probability intervals from quantiles of 
these samples. Although not shown, it would be easy to plot hazard functions; but 
here, for the exponential model, it would be a trivial plot as the hazard is constant 
in t.

340
Bayesian Thinking in Biostatistics
TABLE 11.2: Comparison of posterior medians and 95% probability intervals for 
three sets of priors (informative, diffuse-gamma, diffuse-uniform in respective rows)
61
62
median 1
median2
ratio
0.017
0.055
41.5
12.6
3.3
(0.010,0.026)
(0.034,0.085)
(27.0,68.0)
(8.1,20.7)
(1.7,6.4)
0.016
0.055
44.2
12.7
3.5
(0.009,0.025)
(0.032,0.087)
(28.3,74.7)
(8.0,21.7)
(1.7,7.0)
0.016
0.055
44.2
12.7
3.5
(0.009,0.025)
(0.032,0.087)
(28.3,74.7)
(8.0,21.7)
(1.7,7.0)
FIGURE 11.12: Posterior survival and 95% pointwise probability bands for AG+ 
(solid lines) and AG — (dashed lines).
11.5 Competing Risks
As mentioned earlier in this chapter, one may be interested in characterizing the 
lisk of failure of a given type (i.e.. due to a given cause) when study participants 

Survival Modeling I: Models for Exchangeable Observations 
341
are subject to risks of failing from different causes. If one and only one failure type 
can be observed, we call the different failure types competing risks. For example, 
a population-based study may follow patients until death but be interested in the 
cause of death. Some people may die from heart disease, some may have a stroke, 
others may die from cancer. Deaths can be classified as arising from a single primary 
cause, despite the presence of other conditions and diseases. Analyzing data in 
which patients are subject to competing risks is challenging because of a problem 
of identifiability.
First we will define terms. Let <5 index the failure type, that is. 8 = j if the failure 
is of type j, j = 1,..., J.3 We observe only one failure time, which will be the 
minimum of the (conceptual) times to failure due to all causes under consideration. 
That is, we observe T = min{Ti,T2,... ,Tj}. We call the instantaneous risk of 
failure of type j at time t, denoted hj(t), the cause-specific hazard-.
3In this notation, 5 = 0 can indicate right censoring for the event if present. For an explanation 
of basic concepts and functions, censoring is not relevant.
MO-jjm 
nS=j |r-f)-
The overall hazard at time t, or the hazard of failure due to any cause, is the sum of 
the cause-specific hazards, h(t) = hj(t). This follows from the J types being 
mutually exclusive and (T € [t, t + At)) = A/=1(T G [t, t + At) A <5 = j).
Functions of interest in competing risks are: (i) the overall or all-cause mor­
tality represented by the function F(t) = P(T < t), that is, the probabil­
ity of death by time t regardless of cause; and (ii) the probability of death by 
time t due to each particular cause jt called the cumulative incidence function 
(CIF) for cause j and represented by Fj(t) = P(T < t, 6 = j). The former is 
straightforward with all-cause hazard h(t), and follows equation (11.5), so that 
F(t) = 1 - Jq h(s) exp{- Joe h(u)du}ds. The CIF, however, does not follow from 
the cause-specific hazard for cause j alone. In fact, it is given by
F,(t) = P(T < t,6 = j) = jT Aj(s) exp(-H(s))ds,
where H(s) = Joe hj(u)du, is the all-cause cumulative hazard function. While 
F(-) is a distribution function, the CIF is not because its limit as t -> oo equals 
P(<5 = j) which is typically less than 1. Except for this fact, the CIF has other 
required properties of a distribution function (non-negative, non-decreasing with 
F(0) = 0 for positive random variables), so it is a sub-distribution function.
From a different (i.e., multivariate) point of view, consider the joint sur­
vival function for failure times of each type, S(ti,t?,... ,tj) = P(7\ > t\,Tz > 
t2,... ,Tj > tj). The cause-specific hazard can also be written as
-Wi..... I. _

342
Bayesian Thinking in Biostatistics
The net survival function, Sj(t), is derived from the joint survival function with 
arguments tk = 0 for all k, except к = j: Sj(t) = S(Q,..., t,..., 0).
The identifiability problem referred to earlier arises because we only get to 
observe the failure time for one cause in each individual. The observed failure 
censors the failure times of all other causes, so we do not get to observe these 
other causes’ potential failure times. Thus, we cannot use the data to verify any 
hypotheses relating to the dependence structure of the causes’ times to failure. In 
particular, if we assume that each of the J causes acts independently, then the 
joint survival function is S(ti,...,tj) = I]/=i Sj(t). This relationship leads to the 
cause-specific hazard rate being equal to the hazard rate for cause j resulting from 
the net survival function. We can see this by writing
=
dt~ ki=-- 
rifc=i
btj
As shown by Tsiatis (1975) [332], one can find an independent risk model that is 
indistinguishable from a dependent risk model.
Proceeding under the assumption of independent causes, it is possible to es­
timate the quantities of interest in biomedical applications. These are, typically, 
the all-cause distribution function, the CIFs for each cause, and the cause-specific 
hazards. Each of these three quantities has a clearer interpretation in practice, 
namely, as P(T < t), P(T < t,6 = j), and the instantaneous risk of event of type 
j, respectively. Empirical estimates of the first two follow construction similar to 
that of the K-M estimate of Section 11.2. Inference is more readily available for 
these functions from the Bayesian viewpoint. For example, the Dirichlet process 
mixture of Weibulls model of expression (11.16) is extended to competing risks by 
Shi, Laud, and Neuner [295]. We refer the reader to this paper for details, but note 
that the posterior sampling for this model has been implemented in the R package 
DPWeibull, and provide an example next.
Example 11.8. Paquid Data. The R package riskRegression contains a data set 
of 2,561 subjects in a prospective study of cerebral aging. The variables in the data 
set are time, the time to event in years; status, equal to 0 if right censored at 
time, 1 if event is dementia onset, and 2 if it is death without dementia.
Wc performed an analysis with these data using the dependent Dirichlet pro­
cess Weibull model of expression (11.16) and a LIO prior. We used the DPWeibull 
package in R. The code is available on the book’s website under Chapter 11 in 
the file named Paquid.R. The output object was post-processed in R to generate 
Figure 11.13. The two CIFs are well separated beyond 2.5 years with the probabil­
ity ol death without dementia exceeding that of dementia prior to death. Even so, 
10% of the population is expected to develop dementia (prior to death) by year 9. 
The posterior distribution of any related inference target, such as the median time 
to dementia among those that develop it before death, can be obtained by post­
processing the posterior samples in the object returned by the function dpweibO 
in the DPWeibull package.

343
Smnval Modelin, I: Model, for Ezd,a„,cMr
FIGURE 11.13: Posterior means of cumulative incidence functions for dementia 
prior to death (cause 1) and death without dementia (cause 2) in Example 11.8. 
Thinner lines show pointwise 95% posterior probability limits for the CIFs.
11.6 Recap and Readings
In this chapter we introduced the modeling needs of biomedical studies that primar­
ily focus on the time to a significant medical event from some relevant time zero. 
One major aspect of such data is that time-to-event is restricted to the positive real 
line. More importantly, the sampling mechanism and analysis timings often do not 
allow for observation of the event for each patient. This led to what is termed cen­
sored data that required special care in writing the sampling distribution. Inference 
targets are also somewhat distinct here from those we saw in other chapters. We 
also considered nonparametric models in this chapter more than in others. This is 
because of the somewhat common practice of employing such general and flexible 

344
Bayesian Thinking in Biostatistics
models to address time-to-event data. We should point out that parametric models 
can also be useful if experience in certain scientific areas justifies their use.
As we have encountered in several previous chapters, regression analyses are 
much more common in biomedical research than are exchangeable (or conditionally 
iid) sampling studies of a single homogeneous population. Time-to-event studies 
are no exception to this. The next chapter addresses regression in this context. 
Much of the current literature routinely includes regression of various types. We 
chose to separate the exchangeable data case in a separate chapter for pedagogical 
reasons. The new concepts that relate to censoring and to inference targets such as 
survival and hazard functions are easier to introduce without having to model how 
certain covariates might affect these inference targets, particularly in the presence 
of censoring. As most literature includes regression and treats the exchangeable 
data situation as a special case, we defer recommending readings until the end of 
the next chapter.
11.7 Exercises
Exercise 11.1. Show that if T ~ Weib(a, Л), then Ta ~ Exp(A).
Exercise 11.2. Let W = log(T) ~ ЛГ(д, 1/r).
(a) 
Derive the density and survival function for T.
(b) 
Show that the likelihood, and therefore the Bayesian analysis, does not depend 
on whether we transform the data before analyzing them in the no-censoring case.
(c) 
Show that this result remains true when the data are censored.
Exercise 11.3. Plot hazard, density, and survival functions for the Weibull and 
log-normal distributions that have the following (median, 90th percentile) pairs: 
(1,20), (20,30), and (50,70). Compare these Weibull and log-normal models by 
visual inspection.
Exercise 11.4. With right censoring, the data are unambiguously defined by 
the vectors у and 6. We now define the data for interval censoring as two vectors £ 
and // where
t,.
Lt.
6 =
if uncensored, 
if censored,
if uncensored, 
if censored.
Observing that 6,■ = 1 - /(o.oo)(7h)- write the likelihood in terms of £ and 77.
Exercise 11.5. Turnbull and Weiss (1978) [334] reported data on 191 California 
high school boys who were asked. “When did you first use marijuana?” The data 
only noted ages in years, so we regard the ages as interval censored. Thus age 18 

Survival Modeling I: Models for Exchangeable Observations 
3-15
is the interval [18,18.99) in our analysis. Twelve boys indicated use before a given 
age, so those data are left censored. In addition. 89 boys had never used marijuana 
before the time of the survey, so were right censored. We regarded left and right 
censored observations for a given year as being in the middle of the year, thus a 
(left or right) censored observation for year 18 is taken as censored at 18.5 years. 
The data are in files with the word marijuana in their names on the website.
(a) 
Carry out a log-normal model analysis using low-information priors. Choose 
three interesting targets of inference and plot the posterior distributions for these'.
(b) 
Carry out a Weibull model analysis of the same data and inference targets.
(c) 
Compare inferences based on the two models. Which model would you prefer, 
or does it matter?
Exercise 11.6. Leukemia data. Using relatively low-information priors, give 
plots of survival and hazard functions for the two groups in the leukemia study 
using:
(a) 
the log- normal model,
(b) 
the Weibull model, and
(c) 
the exponential model.
(d) 
Make comparative comments on the results of parts (a), (b) and (c).
Exercise 11.7. This exercise deals with priors only.
(a) 
For the Weibull model with a log-normal prior on a, log(a) ~ 7V(c, d) or 
a ~ LN(c, d) and a gamma prior Л ~ Ga(a, b) on Л, obtain the prior for (a, A) that 
has median t0.5 = 20, P(a < 1) = 0.2, c = log(a«) = 0, and P(0.69/A < 501 a = 
1) = 0.95.
(b) 
Plot the implied prior distributions on the median and the 20-year survival 
probability.
(c) 
For the Weibull model with the uniform-Pareto prior on a and an independ­
ent gamma prior for A, compute prior parameters with the given information. If 
insufficient, make reasonable additions to the information.
(d) 
Repeat (b) with the prior determined in (c).
(e) 
Compare the induced distributions from (b) and (d).
(f) 
Now use the exponential model for the data, with a gamma prior on its rate 
parameter 0. Specify the parameters of the gamma prior for A. In doing so, you 
may need to ignore some of the given information if not usable.
(g) 
Repeat (b) with the model and prior of (f) and compare with results from (b) 
and (d). Comment on how the induced prior on the median using the exponential 
model conforms with the specified prior information on the median.
Exercise 11.8. Consider the uniform-Pareto hierarchical prior on a for the 

346 
Bayesian Thinking in Biostatistics
Weibull model in Section 11.3.1.2. Note that most of the expressions that you are 
asked to derive are stated in Section 11.3.1.2.
(a) 
Derive the marginal distribution of a and express it as a mixture of a uniform 
and a Pareto, identifying the mixture probabilities.
(b) 
Derive the mean and variance of a. Use conditions on the parameters as neces­
sary.
(c) 
Obtain an expression for P(a < 1).
(d) 
Obtain an expression for Fa(x) = P(a < x) for x > 0.
(e) 
Find an expression for the median of a.
Exercise 11.9. Log-normal model analysis. With the arm 1 disease-free survival 
data from the CALGB 8541 trial (Example 11.4), use WinBUGS, JAGS or Stan to 
obtain posterior samples of (а, Л) for the log-normal model. For prior specification, 
use the settings elicited in Section 11.3.1.2. Refer to Appendix C for specifying a 
model with censored data in the software you use.
(a) 
Graph prior and posterior densities of a on the same plot.
(b) 
Graph prior and posterior densities of Л on the same plot.
(c) 
Plot posterior mean and 95% pointwise Pls for the survival function.
(d) 
Plot posterior mean and 95% pointwise Pls for the hazard function.
(e) 
Plot prior and posterior median survival time.

Chapter 12
Survival Modeling II: Time-to-Event 
Regression Models
In Chapter 11, we introduced the complexities associated with the analysis of cen­
sored time-to-event data and discussed some estimation methods. We now turn to 
regression analysis of censored data. As in other regression methods, we are inter­
ested in discovering or determining associations between explanatory variables and 
time until the occurrence of an event when that time may be censored. We discuss 
parametric, semiparametric, and nonparametric methods for censored time-to-event 
data. We continue using the same notation for censored times as in Chapter 11, 
namely, individual i's outcome is a pair of observations with <5, an indicator 
of whether yi is an observed failure time or a censored time. In addition, we now 
include a vector of p explanatory variables for individual i, Xi.
12.1 Accelerated Failure-Time Regression Models
Parametric regression models for failure-time data generally consider a linear model 
for the logarithm of the failure times. A commonly used class of parametric regres­
sion models for these data is the accelerated failure-time (AFT) model,
log(Ti) = X^ + aSi,
(12.1)
In model (12.1), s, is a residual term with cdf Fe(-), and <7 is a scale parameter. 
The 0 are, of course, the regression coefficients. The “survival” function is Se(w) = 
1 - Fe(w) and the “hazard” function is he(w) = fe(w)/S£(w), where fe(w) is the 
pdf corresponding to Fe(w). If we want to indicate that a random variable T is 
characterized by any AFT model, we will write T AFT(Fe,0,T | x), leaving out 
the subscript i.
These are called accelerated failure-time models because of the following prop­
erty. Let V = effe, and let So(c) = P(V > c). Model (12.1) implies, then, that 
T = ex'0V. As a result,
P(T > 11 X = x,0) = P(V > te~x'0 | X = x,0)
= 50{iexp(-x^)} 
= So(te~0l~x'0),
347

348
Bayesian Thinking in Biostatistics
where (3 and x are just /3 and x with the first components removed. If x = 0, the 
survival function is just 
We see, then, that the effect of the covariates x
on the survival probability is to rescale the time by a factor of exp(— £'/3).
In the preceding, the observed failure times T follow different distributions, 
according to the assumed form of the distribution of the random variable e (Fe), 
conditioning on the coefficients. When e ~ ^(0, 1), we have a log-normal AFT. If 
instead the density function of e is /(w) = exp(w — ew), — oo < w < oo, which 
corresponds to the extreme value distribution, we get a Weibull AFT. Now, the 
survival function for T is
S(t | x, /3, <t) = exp {-exp 
x |.
Letting Soft) = exp(—t1/* 7) be the survival function of a Weibull distribution, we 
get
S(t \x,/3) = exp {-t1/aexp ( 
}
= exp 
[texp(-x'/3)]1/a} = So{texp(-x'/3)}.
If a = 1, the sampling distribution of the failure times is the exponential distribu­
tion.
When fitting model (12.1) to data, we need the survival function. Individual i’s 
covariate vector is х^, and their failure time is Ti, possibly censored. The survival 
function is
Sft | rr, /3, cr2) = P(T > t | x,/3,a2)
= P{log(T)>log(t)|z,/3,<72}
= P [{log(T) - x'/3} la > {log(t) - x'$}la | x, /3, a2]
= P [e > {log(t) - x&}ja | x, /3, a2] 
‘
= S£ [{log(t) - x'/3}/a]
= 1 - Fe [{log(t) - x'/3}/a].
The density and hazard functions that correspond to the regression model (12.2) 
are
fft | x, /3, a2) = ^-f£ [{log(t) - x'fi} /a], 
<7
*
h(t | x,3,a2) = — h£ [{log(t) - x'(3}/a\.
(TI
If F£ is the standard normal distribution (i.e., e ~ N(0,1)), then
fft, | хь .3,а2) = ^_L=lexp [-2^ {log(^) “ ^'/3}2] ,
and Tj ~ L.V(.r'.3.o-2). If s has the extreme value distribution, then Ti ~ 
H’eib(l/a. r~r,

Survival Modeling II: Time-to-Event Regression Models 
349
In the regression part of model (12.1), the 3 vector consists of the regression 
coefficients. We note that eM is the median of a random variable with a L.V(/z.ct2) 
distribution. We can then easily show that the median of T is er if we consider T 
to follow a log-normal AFT model. We include an intercept in the regression model, 
so хц = 1 and xi has p+1 elements, namely, a 1 and individual i's p covariates. 
We again often standardize the covariates, which makes it easier to elicit priors on 
observable quantities that are functions of the 0s. For example, if x, = (1,0,..., 0)', 
which corresponds to someone with average values for continuous covariates and 
the baseline values for discrete covariates, then is the regression parameter for 
a standard reference individual.
Recall that a particular AFT model includes the distributional assumption 
e ~ Fe(-). Let te be the median of this distribution (i.e., F£(te) = 0.5). If 
T ~ AFT(Fe,/3,ст2 | x), then the median time until the event (tm) satisfies 
0.5 = S(tm | x,0, ст2). From the survival function in equation (12.2), we have
0.5 = 1 - Fe [{log(tm) - x'0} /ст]
which means that
= {log(tm) - x'0} /ст
or, equivalently, 
tm = exp(x'0 + tecr).
Since tm is a function of the covariates x, we also write tm(x}.
If Fe has median zero, then te = 0 and tm{x} = exp(xz/3). This will be the case 
if e has a standard normal distribution or a logistic distribution, for example. We 
can also rewrite the extreme value distribution so te = 0, namely,
Fe(u) = 1 - exp{— log(2)en}. 
(12.3)
For eliciting priors, we will often be interested in the relative median. Comparing 
someone whose covariate is x^, possibly a vector, to someone with covariate equal 
to X2, we find the relative median is exp{(xi — хг}0}.
Biomedical researchers are also generally interested in hazard ratios in much 
the same way they characterize covariate effects via relative risks when considering 
binary outcomes. When considering covariates xi and x2, the hazard ratio with an 
AFT model is
HR = /t(t | ст2) = ЦМНМ/
*)
 
h(t | x2,0, ст2) he ({log(t) - x'20}/aj
As we have throughout the book, we often focus on prediction. In survival ana­
lysis, one might think of predictive survival probabilities in one of two ways. A 
predictive probability associated with covariate x may apply to the individual if 
that individual has that covariate (or set of covariate values) or as a prediction of 
the fraction of the population with covariate x that survive. Considering the pro­
portion of the population surviving interpretation, we can approximate predictive 

350
Bayesian Thinking in Biostatistics
survival probabilities at time t as S(t | x, 0, a2) = 1 - Fe [{log(t) - x'0} /а]. We can 
then generate pointwise probability intervals for predictive survival probabilities at 
multiple times, showing uncertainty along with the prediction.
Example 12.1. Cancer of the Larynx. Kardaun [203] published an analysis of 
90 men with cancer of the larynx, and Klein and Moeschberger [204] included this 
data set in their survival analysis textbook. The outcome is months from diagnosis 
until death or censoring for each of the men, and there are with three covariates: 
the stage of the disease at diagnosis (Stage), the year of diagnosis (Yr), and the age 
at diagnosis (Age). In our analysis, we consider stage 1 the baseline or comparator 
category and create indicator variables for each stage (Sij = 1 if the ith man’s stage 
of disease is j = 2,3, or 4; 0 otherwise). The analysis considers the standardized 
versions of age (sAge) and year of diagnosis (sYr). The resulting regression model, 
leaving out person i’s subscripts for ease of reading, is
log(T) = /?i + 02 S2 + 0з S3 + 04 S4+ 05 sAge + 0&sYr + ae,
with £ ~ 7V(0,1).
With this model, the median time to death from diagnosis is e&1 for a man 
whose age and year of diagnosis (from 1900) equal the average age of 64.6 years 
and 74.2, respectively. The median survival time of a man whose disease is stage 2, 
relative to a man with stage 1 disease, is e^x when both are of average age and their 
year of diagnosis equals the average diagnosis year. An increase in a man’s age of 
one sample standard deviation unit (10.8 years) leads to a change in the median 
time to death of e^5 when the two men were otherwise diagnosed in the same year 
with the same stage of disease. Similarly, a one sample standard deviation unit (2.2 
years) difference in year of diagnosis (all other covariates the same) will lead to a 
relative median time to death equal to e^e.
We fit a log-normal AFT model to the data using BUGS. The book’s web­
site has the BUGS program, as well as versions for JAGS and Stan. The files have 
LarynxLogNormal in the name. (Each of these programs handles censoring differ­
ently.) Table 12.1 contains summary statistics for the posterior distributions of the 
model parameters. The 95% posterior (or data-informed) PI for the effect of stage 
2 disease on median time to death relative to stage 1 (e^2) does not show much 
effect. Stages 3 and 4 do appear to be associated with much shorter median times 
to death from diagnosis (i.e.. e^3 and e04). For stage 4 disease, we are 95% certain 
that stage 1 disease at diagnosis is associated with longer median time to death 
that is between 3 (as 1/0.36) times and 20 (as 1/0.05) times longer. The coefficient 
for age (35) has more probability below zero, suggesting that older patients tend to 
have shorter survival from diagnosis. Diagnosis in later years (0$) appears to lead 
to better survival, but the coefficient is not very far from zero, relative to its uncer­
tainty. Furthermore, we would expect more time since diagnosis to be associated 
with greater risk of dying.
Since the 95% Pls for the age and the year of diagnosis coefficients contain 
0. there is not much statistical import. We can consider posterior probabilities as 
evidence of an association. For age. P(3s < 0 | D) = 0.90. indicating that most of

Survival Modeling II: Time-to-Event Regression Models 
TABLE 12.1: Log-normal regression fit to the larynx cancer dat:
Node
mean
sd
2.5%
median
97.57c
01
2.33
0.32
1.75
2.32
3.01
02
-0.25
0.51
-1.25
-0.25
0.76
03
-0.97
0.41
-1.81
-0.96
-0.17
04
-2.02
0.53
-3.09
-2.00
-1.01
05
-0.22
0.17
-0.56
-0.22
0.10
06_________________
0.13
0.19
-0.24
0.12
0.52
St2/Stl
0.89
0.49
0.29
0.78
2.11
St3/Stl
0.41
0.17
0.17
0.38
0.83
e^4 St4/Stl
0.15
0.08
0.05
0.14
0.36
St3/St4
3.23
1.83
1.07
2.80
7.89
e05 (Age +lsd)/Age
0.81
0.14
0.57
0.80
1.11
(Yr +lsd)/yr
1.15
0.22
0.80
1.12
1.63
a
1.40
0.17
1.12
1.38
1.76
the support is for values below zero. For year of diagnosis, the probability that the 
coefficient is positive is P(0e > 0 | D) = 0.74. The evidence appears stronger for 
an age effect on survival than for the year of diagnosis affecting survival.
We also evaluate each covariate’s effect on survival by comparing median sur­
vival times and survival probabilities. Table 12.2 shows estimates of median sur­
vival times and 5-month survival probabilities for different stages. Specifically, we 
can compare median survival times for men who were 50 years old to that of men 
70 years old when diagnosed, conditioning on the year of diagnosis being 1971 or 
1977. A 50-year-old man diagnosed with stage 2 cancer of the larynx in 1971 has 
a median time to death of around 9 months. If this same man were diagnosed in 
1977 instead, however, the model estimated median time to death is 12 months. 
Median survival times for 70-year-old men diagnosed in 1971 or 1977 were around 
6 or 8 months, respectively, which is a smaller difference. We note that the relative 
medians are about 1.33 with the later year of diagnosis, which is the same for the 
50-year-old men and for the 70-year-old men. A comparable examination of median 
survival time effects among men with stage 4 disease shows very little effect in 
terms of months. The differences in medians are roughly one-half to three-quarters 
of a month. Stage 4 disease has such a poor prognosis in these data that there is 
relatively little practical difference.
The analysis suggests that there is a substantial difference between stage 3 and 
stage 4 disease. Table 12.1 contains some summary statistics for the effect of stage 
3 relative to stage 4. The posterior median of the relative median survivals is 2.8, 
and the 95% PI is (1.07, 7.89). In fact, the posterior probability that the stage 3 
median survival is longer than it is for stage 4 disease is almost 1 (P(e 3 4 > 1 | 
Z>) = 0.981). We are 98% certain that those with stage 3 disease will live longer

352
Bayesian Thinking in Biostatistics
Node 
I mean sd 2.5% median 97.5%
TABLE 12.2: Median survival times and 5-month survival probabilities estimated 
from a log-normal regression analysis of the larynx data
Age = 50, Yr = 71
10.6
6.9
3.1
8.9
28.2
Stage 2
Age = 50, Yr = 77
14.5
9.9
4.5
12.0
39.3
Medians
Age = 70, Yr = 71
6.8
3.8
2.3
5.9
16.3
Age = 70, Yr = 77
9.3
5.1
3.4
8.0
22.5
Age = 50, Yr = 71
1.83
1.18
0.48
1.55
4.93
Stage 4
Age = 50, Yr = 77
2.42
1.40
0.80
2.10
5.99
Medians
Age = 70, Yr = 71
1.18
0.66
0.36
1.03
2.83
Age = 70, Yr = 77
1.55
0.72
0.62
1.40
3.35
Age = 50, Yr = 71
0.72
0.10
0.51
0.73
0.88
Stage 1
Age = 50, Yr = 77
0.78
0.10
0.56
0.79
0.94
5-month surv.
Age = 70, Yr = 71
0.62
0.09
0.43
0.62
0.79
Age = 70, Yr = 77
0.69
0.10
0.48
0.70
0.87
Age = 50, Yr = 71
0.46
0.12
0.24
0.46
0.70
Stage 3
Age = 50, Yr = 77
0.55
0.12
0.31
0.55
0.78
5-month surv.
Age = 70, Yr = 71
0.35
0.10
0.17
0.35
0.56
Age = 70, Yr = 77 | 0.44
0.11
0.23
0.43
0.66 |
TABLE 12.3: Weibull regression fit to the larynx cancer data
Node
mean
sd
2.5%
med
97.5%
2.22
0.29
1.71
2.20
2.86
&
-0.14
0.49
-1.07
-0.15
0.86
/?3
-0.66
0.38
-1.45
-0.65
0.05
-1.69
0.46
-2.64
-1.68
-0.83
-0.21
0.16
-0.54
-0.21
0.09
0.09
0.18
-0.24
0.08
0,45
^2 St2/Stl
0.99
0.54
0.35
0.87
2.37
r*'  St3/Stl
St4/Stl
0.55
0.20
0.21
0.10
0.24
0.07
0.52
0.19
1.04
0.43
e3'’ (Age +lsd)/Age
0.82
0.13
0.58
0.81
1.11
1.58
1.32
<’36 (Yr -t-lsd)/yr 
a
1.10
1.007
0.20
0.14
0.78
0.77
1.08
0.99

Survival Modeling II: Time-to-Event Regression Models 
353
TABLE 12.4: Median survival times and 5-month survival probabilities estimated 
from a Weibull regression analysis of the larynx data
Node
mean
sd
2.5%
med
97.5%
Stage 2
Age = 50, Yr = 77
13.64
8.67
4.86
11.42
35.72
Medians
Age = 70, Yr = 77
8.67
5.26
3.43
7.71
22.3
Stage 4
Age = 50, Yr = 77
2.75
1.36
1.10
2.45
6.19
Medians
Age = 70, Yr = 77
1.77
0.66
0.87
1.7
3.39
Stage 1
Age = 50, Yr = 77
0.76
0.09
0.55
0.77
0.90
5-month surv.
Age = 70, Yr = 77
0.67
0.10
0.45
0.68
0.84
Stage 3
Age = 50, Yr = 77
0.59
0.12
0.33
0.60
0.81
5-month surv.
Age = 70, Yr = 77
0.47
0.13
0.22
0.47
0.71
than those with stage 4 disease if the two men are diagnosed in the same year and 
are the same age at the time.
Table 12.2 contains posterior calculations that allow us to compare 5-month 
survival probabilities for men with the same ages and diagnosed in the same two 
years we have been examining. Not unexpectedly, 50-year-old men diagnosed with 
stage 1 disease in 1977 have substantially better 5-month survival probabilities 
than do 70-year-old men diagnosed in 1971 with stage 3 disease; the 95% Pls do 
not overlap, according to the table.
As shown earlier, we get a Weibull AFT model when Fe is the extreme value 
distribution. Specifically, we have that T ~ Weib(l/ff,ex'0^a). With the modified 
version of the pdf that has median 0, Fe(u) = 1 - exp {- log(2)eu}, we get
T ~ Weib(l/a,\Qg(2}e-x'0/a).
We carried out an analysis of the laryngeal cancer data with this form of the 
Weibull AFT model. The results are in Table 12.3. Comparing the Weibull results 
to those in Table 12.1, we see that the overall inferences are quite similar with 
the two models (Weibull and log-normal AFTs). Consider two men with stage 2 
disease when diagnosed in 1977. The log-normal AFT model (Table 12.2) indicates 
a median survival of 12 months if the man is 50 years old when diagnosed and 8 
months if the man is 70 years old at diagnosis. The Weibull AFT analysis (Table 
12.4) gave estimated median survival times of 11.4 months and 7.7 months for a 
man 50 years old and 70 years old, respectively. This quantifies the similarity of age 
effect on the more direct scale of median survival and is a reflection of the similarity 
of inferences for the age regression coefficient: -0.22 (95% PI (-0.56,0.10)) with 
the log-normal AFT and —0.21 (—0.54,0.09) with the Weibull AFT.

354
Bayesian Thinking in Biostatistics
12.1.1 Prior Distributions for AFT Parameters
The parameters in the AFT model are (£,<т2), the regression coefficients and the 
variance, much like we saw in Chapter 7. We could consider the standard reference 
prior p(/3, r) oc 1/r (r equal to the precision) or some variant of it (see Ibrahim and 
Laud [172]).
With a log-normal AFT, we could consider the prior from Section 7.3, that 
is, р(/3,<т2) = p(/3)p(<T2), with a normal distribution for the former and an inverse­
gamma distribution for the latter. (If one works with the precision, one works with a 
gamma distribution for т = 1/cr2.) Without censoring, this prior would be conjugate 
for log-normal data. With censored data, however, we no longer have a conjugate 
model. We also do not have conjugacy if the AFT model has a residual distribu­
tion (Fe) that is neither normal nor log-normal. With large samples, however, the 
posterior distribution 0 will be approximately normal, so we might consider using 
this normal-inverse-gamma prior anyway.
As is our preference, we seek to specify prior distributions for observable or 
more commonplace measurements and not directly on the regression coefficients in 
complex models. Bedrick, Christensen, find Johnson [25] proposed specifying priors 
on median survival times and thereby inducing prior distributions on the 0s in AFT 
models. They assumed independence of the 0s find a2 (or т = 1/<т2) a priori, which 
allows one to specify priors p(0) separately from priors р(<т2).
12.1.1.1 Specifying p(0)
As stated when we introduced the AFT model, the median survival time tm equals 
ex & if the median of Fe is zero. Therefore, with the right distribution for the residu­
als (i.e., the es), we can ask our experts their opinions about median survival times 
for individuals with various different covariate values. We start by considering a set 
of p+1 linearly independent vectors of covariates. The ith covariate vector is denoted 
ii and consists of a specific constellation of covariate values that define an individ­
ual whose median survival we elicit from the expert. That is, ii = (1, хц,..., XiP)', 
where Xij is the value of the jth covariate of the individual defined by Xi.
For someone with covariate vector ii, the median survival time is tmi = ex^. 
Let the matrix X = (iib .... ip+i)' and define the vector of expert-elicited medians 
tm = (Ln,, • • • Лпр+i )'• Then tm = exp(X/3) and 0 = X-1 log(tm) (if X is non­
singular). If the expert can express an opinion about each median independently of 
the others, we can assume prior independence of the tmi and consider the joint prior 
p(Ln) = П&1 Pi(t ,„,). where Pi(tm,) is the prior distribution for this particular 
median.
We are eliciting priors on the scale of the data, so we have to consider the induced 
prior on the 3s as a transformation of variables if we write out the densities. (See 
Appendix A for a review of transformation of random variables.) In our setting, one 
can show that the Jacobian of the transformation is proportional to П?=1 e£'0■ 
we use BUGS or JAGS, we are able to specify the prior distribution for the medians 
and let the MCMC induce the prior on the 3s.
It is often convenient to consider a log-normal prior for the medians when in­

Survival Modeling II: Time-to-Event Regression Models 
355
ducing a prior for the 0s, although any distribution on the positive real line will 
do. With a log-normal distribution for the median, we treat the elicited median 
survival times as medians of the respective distributions. That is. if the expert's 
best guess for tmi is moi, we set the median of to be moi- We determine 
the variance of the log-normal prior distribution by eliciting an upper (or lower) 
percentile for the median survival time for each set of individuals defined by the 
That is, we ask the expert for an upper (or lower) bound for the median t,lh that 
they are, say, 95% certain is above (or below) the median. This upper bound leads 
to a prior standard deviation for the prior distribution of the median survival time 
for an individual with covariates £j. Call the resulting standard deviation do,. This 
process is much like what we did in Chapter 7 and elsewhere in the book. With a 
log-normal prior, we have
tmi LN(log(m0i),^oi)
or
log^mj 7V(log(m0l),d^).
If we want to move beyond normal or log-normal priors, we can consider any 
AFT in which the residual distribution has median 0. We would specify the prior 
via the following (where the residual e ~ F£):
log(^mi) — log(mQt) ind p 
(12 4)
°0i
The Weibull AFT model is considered for prior elicitation by Bedrick, Christensen, 
and Johnson [25], along with other AFT models. Just as we described for the log­
normal case, the prior for the median survival times characterized in expression 
(12.4) induces the prior density for the 0s from the relationship 0 = X~l log(tm). 
Also, as before, we determine by asking the expert for an upper bound щ such 
that P(tmi < щ) = a. Then, with qa the lOOath percentile of F£, we find the 
standard deviation &oi by solving the following equation for it:
log(ui) - log(moi)
Qa =---------------------------•
&0г
For example, consider the Weibull AFT as given in equation (12.3). If 
go.95 is the 95th percentile of the residual distribution, then F£(go.9s) = 0-95. 
From equation (12.3), we have F£ (<70.95) = 1 - exp{-log(2)e’0-95}. There­
fore, 0.95 = 1 - exp{-log(2)e90-96} and - log(2)e’°-96 = log(0.05), or <70.95 = 
log {log(0.05)/(—log(2))} = 1.46.
Example 12.2. Effect of Chemotherapy to Treat Breast Cancer. We illus­
trate using an elicited prior within a parametric AFT regression model using data 
from a randomized clinical trial carried out by the Cancer and Leukemia Group 
В [161]. The study randomized more than 3,000 women with breast cancer having 
nodal involvement to one of six treatment regimens. The study followed a factorial 

356
Bayesian Thinking in Biostatistics
design that evaluated three doses of the anticancer agent doxorubicin with or with­
out paclitaxel (Taxol), another anticancer drug. In this analysis, we will look at the 
possibility of an interaction between paclitaxel and estrogen-receptor status.
Our elicited priors are for median disease-free survival. Disease-free survival 
(DFS) is a common outcome measure in oncology and is defined as the time until 
relapse, recurrence, or death, whichever occurs first. We apply the model in expres­
sion (12.1) with a Weibull residual distribution. Based on historical studies at the 
time this study was designed, the expectation was that the median DFS would be 
around 7 years for these women, and the covariates would lead to a deviation from 
this baseline. Table 12.5 shows the prior estimates for the medians, 95th percentiles, 
and standard deviations in the analysis. In the table, we used the following abbre­
viations for the covariates. Paclitaxel is coded T, ER status is ER, having four 
or more positive lymph nodes is LN4+, and the interaction of paclitaxel and ER 
status is T.ER.
TABLE 12.5: Specification of the prior based on disease-free survival (years) in the 
breast cancer example
Configuration of covariates
Prior percentiles
Int.
T
ER
L2V4+
T.ER
7™0г
95%
<70i
1
1
0
0
0
0
7.0
12.0
0.369
2
1
1
0
0
0
8.5
13.5
0.317
3
1
0
1
0
0
8.0
13.0
0.333
4
1
0
0
1
0
6.0
11.0
0.415
5
1
1
1
0
1
9.0
14.0
0.303
Summary statistics from the posterior distribution are shown in Table 12.6. We 
notice that the interaction between paclitaxel and ER status appears to be negative, 
and there appears to be some strength to this deviation from zero. The posterior 
mean is -0.154 and the 95% PI is (-0.36,0.04). In fact, the posterior probability 
that the interaction term is negative is 0.94, based on the MCMC. We also see that 
one’s DFS is expected to be shorter if one has four or more positive lymph nodes 
on examination. The posterior mean is -0.43 and the 95% PI is (—0.52, —0.33), 
which is far from zero in terms of the estimate’s posterior standard deviation.
A plot of the hazard functions provides some insight into the nature of the 
interaction. Figure 12.1a contains posterior mean estimates of survival curves for 
four groups of women in the trial, all of whom had four or more positive lymph 
nodes. Figure 12.1b shows the posterior mean hazard functions for women in these 
same lour groups. We see that the benefit of paclitaxel in terms of reducing the risk 
of an event is larger among women who are ER negative than it is for women who 
are ER positive.
Partial Prior Information for 3. In Sections 7.3.4 and 8.4.2 we saw that one

Survival Modeling II: Time-to-Event Regression Models
357
FIGURE 12.1: Posterior estimates of the disease-free survival probabilities and 
hazard functions from an AFT model with an interaction between Taxol and ER 
status among women with four or more positive lymph nodes.
can specify fewer than all p+1 quantities (medians in the AFT case) to induce priors 
on the regression coefficients. As in the other regression settings, we first standardize 
all continuous covariates. Suppose we specify independent prior distributions on 
q < p + 1 median survival times tmi = eXi&, i = l,...,q. With the q covariate 
vectors, we have a q x (p + 1) matrix X = (Хг, 0), with X} a q x q non-singular 
matrix and the remaining columns set to 0. Suppose that j3*  is the set of coefficients 
most relevant to the specified medians. We can rearrange the vector 13 into (/?Г, /?г)- 
We then have tmi = eXi&* , i = l,...,g, which will induce a prior distribution 
for /?*  = X] log(tm). For the remaining regression coefficients we consider 
independent reference priors. As before, we have specified more informed priors for 
a subset of the regression coefficients and less informed priors for the remaining 
ones.
12.1.1.2 Specifying p(a)
We specify the prior distribution for a (or т = 1/a2) in much the same way as 
with models we have already discussed, including when we specified the standard 
deviation of the prior for 13 in Section 12.1.1.1. If the residual distribution in our 
AFT model has median 0, then we can think about another percentile of the survival 
distribution of T, the time until the event of interest. The steps are similar to 
those we discuss in reference to expression (12.4). The difference is that we were 
thinking about uncertainty regarding the median in expression (12.4), but now we

358
Bayesian Thinking in Biostatistics
TABLE 12.6: Summary of posterior distribution of Weibull AFT regression para­
meters from an analysis of women with four or more positive lymph nodes treated 
in a breast cancer randomized clinical trial
0
Moments
Posterior percentiles
Mean
Std dev.
2.5
25
50
75
97.5
Int.
2.520
0.059
2.406
2.481
2.520
2.560
2.637
T
0.276
0.079
0.116
0.222
0.276
0.329
0.431
ER
0.485
0.073
0.346
0.435
0.486
0.537
0.625
LN4+
-0.430
0.050
-0.523
-0.464
-0.431
-0.398
-0.331
T:ER
-0.154
0.103
-0.364
-0.220
-0.153
-0.087
0.042
shape
0.980
0.023
0.937
0.964
0.981
0.995
1.026
are considering uncertainty or variation of the survival times around some central 
value.
One may be concerned that variation may increase with the central tendency of 
the failure times. Populations in which times to the event tend to take longer may 
exhibit larger variation in failure times than populations with shorter failure times. 
If we specify the same scale term a for all populations (see expression (12.1)) then 
we will automatically have more variation in groups that tend to show longer times 
until the occurrence of the event and less variation among those in the populations 
that tend to experience the event sooner. Since AFT regression models refer to 
log(T), it reasonable to assume that a may be the same across the covariate-defined 
subpopulations in our data analysis. (See also Section 7.3.3.2.) As a consequence, 
we may also just focus on one of the covariate-defined subgroups to determine an 
informed prior distribution for a.
Let us reconsider the breast cancer trial we analyzed in Example 12.2 and use 
the group defined by covariate vector Xi for our purpose. Recall that our best 
guess of the median DFS for this group is mj. As we stated in the example, our 
expectation was that the median disease-free survival in that population of women 
was 7 years. We might think that 90% of women diagnosed with similar breast 
cancer conditions would relapse, experience a disease recurrence, or die within 15 
years. Let <70.9 be the proposed 90th percentile of the time to event outcome T for 
the group defined by covariate vector i\. From the AFT regression model (12.1), 
exp(.r'13 + 
9) = 7Й] схр(<т<7о.9). (Recall that we are assuming that Fe has g0.5 =
0.) If the best guess for this percentile is 15 years and we consider this quantity to 
be the center of the 90th percentile, we can combine this information with the best

Survival Modeling II: Time-to-Event Regression Models
359
guess for the median mi and solve for aoi:
0.5 = P{mi ехр(сгдо.э) < 
| mi = 7}
= p f log (mieg<?0 9) - log(mi) < log(15) - 1об(7)L = J 
I 
<70.9 
“ 
<7o.9 I J
\ 
<70.9 J
If our AFT has a Weibull distribution, then g0.9 = 1-201. With a log-normal AFT 
model, go.9 = 1.282. Another distribution that appears in AFT analyses is the 
log-logistic distribution, for which g0.9 = 2.197. We remind the reader that these 
percentiles are on the scale of log(T), as is the AFT model. For the Weibull distri­
bution in Example 12.2, we find ao = 0.635. This cr0 is our “best guess.” We can 
let p(a) ~ 17(0, crmax), where crmax is a clear upper bound for the standard devi­
ation. We used 4 as the upper bound in Example 12.2, feeling quite certain that 
the variation in disease-free survival times would not be as large as exp(4).
Alternatively, we might want to treat <tq as the median of the prior distribution 
of a in the AFT model. We could then specify another percentile for this parameter 
or for the precision r = 1/a2, as we have done in earlier chapters. In Section 5.3.2, 
we discussed how to determine an informed gamma prior for a parameter. We can 
do the same thing in this situation. Considering то = 1/<т2 to be the mode of p(r) 
and т ~ Ga(ao>bo), we can follow the procedures we followed in Section 5.3.2 to 
determine ao and bo.
12.1.2 Sensitivity Analysis
As with all data analyses, it is important to examine if the inferences are sensitive 
to assumptions. When we carry out a Bayesian analysis, we are not only inter­
ested in assumptions regarding the sampling distribution posited for the data but 
may also be curious about the sensitivity of inferences to assumptions about prior 
distributions. In the survival analysis setting, we can examine posterior survival 
probabilities at individual time points or the entire posterior mean survival curve 
under different prior assumptions as a way to evaluate sensitivity to assumptions 
about priors—particularly priors for the regression coefficients. We want to bring 
knowledge into our analyses, but we also want to be able to demonstrate to others 
that we are not just presenting our prior views in the posterior inferences. A simple 
approach to sensitivity analysis is to reanalyze the data with vaguer (i.e., more 
diffuse) prior distributions. In the extreme, one can analyze the data with a stand­
ard reference prior p(/?,cr2) ex 1/a2 (or in terms of r = 1/cr2, p(J3, r) ex 1/r) and 
compare the results to the analysis with more informed priors. Large discrepancies 
in posterior means, particularly with respect to important outcomes, may suggest 
that one take a closer look to see what is going on.
Such a sensitivity analysis may also help elucidate the relative importance of 
individual covariates on the final inference. Regression coefficients in AFTs relate to 

360 
Bayesian Thinking in Biostatistics
the effect of a covariate on the logarithm of time, which may not be a very intuitive 
scale for many researchers. Showing survival curves or survival probabilities at 
different times may be more immediately understood and appreciated. For example, 
fitting a model to learn about the association between duration of treatment and 
time to relapse may yield a posterior distribution for the treatment duration’s 
regression coefficient that is positive but spans 0. If adding 6 months of treatment 
does not lead to much separation of the survival curves out to 10 years, then one 
may have a better sense of the practical import (or lack thereof) of the covariate 
than one gets from the posterior distribution of the treatment duration’s regression 
coefficient.
An important tool to help sensitivity analyses is the ability to compare a more 
restrictive model to one that is less restrictive but may include the former model 
as a special case. The next section relaxes the AFT model’s assumption about the 
distribution of the residual term (i.e., the assumption about the distribution of 
log(T)) by making no assumptions about the underlying hazard function.
12.2 Proportional Hazards: A Semiparametric Model
While fully parametric regression models, such as the AFT models we have dis­
cussed, often offer advantages, especially when they are fairly close to the truth, 
these models could lead one’s inference astray. The distributions we considered for 
AFT models were all unimodal. Given the relationship between the hazard function 
and the density function, these unimodal densities may not be able to characterize 
different but real hazard functions. For example, the risk of another stroke may be 
high right after experiencing one and undergoing an invasive procedure. Thereafter, 
the risk may decline sharply only to start to rise again after a fairly long time. Such 
a U-shaped hazard function will be difficult to capture with the AFT models we 
discussed in Section 12.1.
Here we consider a ubiquitous approach that is semiparametric. We call this 
model semiparametric because it combines a parametric regression model involving 
covariates with a flexible and loosely defined model for the hazard function. The 
seiiiiparametric model that we discuss here is the proportional hazards regression 
model of Cox (1972) [88]. The innovation of the so-called Cox model is that it 
separates inference about the effects of covariates on survival from inference on the 
underlying hazard. We now discuss the proportional hazards model and Bayesian 
inference with it.
Recall from Section 11.1.1 that the hazard function at time t provides the in­
stantaneous probability of having the event at that moment, given that the event 
has not yet occurred. In general, we find it preferable to model the hazard function 
rather than the survival function. If we let hi(f) represent the hazard function at 
time t for the /th individual, then we have several options for relating this hazard 
function to this individual's covariates. Cox [88] proposed the partial likelihood 

Survival Modeling II: Time-to-Event Regression Models 
361
model. In this model, the hazard function decomposes into a part that is a function 
of time only and a component that is a function of the covariates but does not 
depend on time. The part of the hazard function that depends on time but not the 
covariates is called the baseline hazard function, and we denote it by ho(t). The 
baseline hazard is common to all observations in the data set. Covariates affect an 
individual’s hazard through the product of the baseline hazard and a function of 
the covariates but not time, д(х^(3). Thus, /it(t) = ho(t) x з(х'/3). Although most, 
any mathematical function could be used for the function of the covariates, the 
most commonly used regression function is g(x'i0') = exp(.r'5). This model for the 
hazard function is commonly called the Cox model, namely,
hi(t) = /io(i)exp(x'/3). 
(12.5)
We note that in this model, the hazard (or instantaneous risk of an event) at time 
t increases as х\(3 gets larger.
The cumulative hazard has a convenient form,
H(t | Xi,(3) = [ h(s\ Xi,!3)ds = ex<0 [ ho(s)ds = ex'^H0(t), 
Jo 
Jo
where Ho(t) = fQ ho(u)du is the baseline cumulative hazard function. We write 
Hi(t) = H(t | Xi,i3) interchangeably. Because of the assumption that the covariate 
effects are constant over time, the effect on the hazard function is the same as the 
effect on the cumulative hazard function. We note that one does not need to include 
an intercept in the (3s. The baseline hazard function takes the place of the intercept 
in this model.
The effect of covariates on the survival function Si(t) = S(t | Xi,(3) = 
ехр{-Я,(£)} is
S(t \x,(3) = exp{-e^Ho(«)} = (ехр{-Я0(«)})е1 = {5о(«)}е1'".
Unlike the AFT models, where the covariates rescale time, the covariates in the 
Cox model raise the baseline survival function to a power. If x^/3 > x'2/3, then 
S(t | xi,(3) < S(t | X2,(3) for all time t. This relationship follows from the fact that 
the survival function is less than 1, so raising it to a positive power results in a 
smaller number.
As noted, the proportional hazards model assumes that the covariate effects 
on the hazard function are constant over time. Consider two distinct values for a 
covariate Xi and x?. The ratio of the hazard function with a?2 to the hazard function 
with Xi is
ЯЯ(х2,Х1) = W | 
= exp{(x2 - Si)/?}.
n(i | xlyp)
We wrote the hazard ratio for two values of a single covariate, but the same result 
holds for a vector of covariate values. Because time is not included in the hazard 
ratio, it is often used as the target of inference relating to the effect of a covariate.

362
Bayesian Thinking in Biostatistics
Another consequence of the proportional hazards model is that the hazard func­
tions for two values of a covariate never cross, regardless of the magnitude of the 
effect. As a consequence, the survival functions will not cross either. If one wants to 
model a covariate effect that changes over time, then one must consider an interac­
tion of the covariate with time. There are several ways that one might characterize 
such a time-dependent covariate.
Suppose you have two treatments and that survival is better under the first 
treatment early in the study but better under the second treatment later on. This 
constitutes an interaction between treatment and time. Define a variable Trt with 
Trt = 1 for the first treatment and Trt = 0 for the second. An appropriate model 
allows for an effect of Trt up to a particular point in time, say tc, and for a different 
effect after that. Let z(t) take the value 0 for t < tc, and the value 1 for t > tc. 
Then write the model
h(t \Trt, z(t)) = exp{(3iTrt + (3?Trt x z(t)}ho(t).
Under this model, the hazard ratio comparing an individual with Trt = 1 to one 
with Trt = 0 is e01 for t < tc, and is e$l+02 for t > tc. Perhaps surprisingly, the 
proportional hazards assumption appears to work reasonably well in a wide variety 
of biomedical applications, particularly over relatively short follow-up times.
Unlike the AFT models, median survival times are not simple functions of the 
regression coefficients. We therefore tend to focus on the hazard ratio and some­
times on survival probabilities at particular times when expressing covariate effects. 
Hazard ratios are particularly straightforward with the proportional hazards model. 
If x is a covariate that equals 0 or 1, such as a treatment indicator, then e0 is the 
hazard ratio for x = 1 relative to x = 0. The regression parameter /3 is the logarithm 
of the hazard ratio. The hazard ratio is therefore a directly estimated parameter in 
the proportional hazards regression model.
The sampling distribution with the proportional hazards model for n observed 
times (у,, (5J, г = 1,..., n, is given by
i=l
Wc note that the sampling distribution is conditional on the baseline hazard func­
tion. as well as on the regression coefficients.
Cox [88] defined the partial likelihood for /3, PL(/?), as
PL(3)«nL eXPWg* Г 
(12.6)
У 1Е,€7г(„,)ехр(х^) /
In the definition of the partial likelihood. 7^(1/;) represents the individuals still at 
risk of the event at the time the zth individual experiences the event. Notice how the 
baseline hazard function is absent from the partial likelihood (12.6), allowing one to 
ignore the underlying hazard function. If we assumed that the failure times followed 
a particular distribution that has an analytically tractable hazard function, such as 

Survival Modeling II: Time-to-Event Regression Models 
363
the exponential distribution, we could evaluate the full likelihood. There are very 
few such distributions, unfortunately. Hence the widespread use of the Cox model. 
The values of /3 that maximize the partial likelihood are generally the targets of 
interest in a non-Bayesian analysis.
12.2.1 Modeling the Baseline Hazard Function
Bayesian inference for the Cox model will require a prior distribution for the re­
gression parameters (/3) and the baseline hazard function Ло(-)- Cox's approach 
brought enormous benefit to frequentist inference by allowing the analysis to treat 
the baseline hazard function as an ignorable nuisance. The advantage of Cox’s for­
mulation is less clear for Bayesian inference, however. Unlike frequentist inference 
that conditions on the parameters, Bayesian inference provides direct inference on 
the parameters via posterior distributions, which condition on the data. Bayesian 
analysis addresses all model parameters, and the baseline hazard function is a part 
of the model. Posterior inference will either have to provide a joint posterior in­
ference for the regression coefficients and the baseline hazard or, if interest focuses 
solely on the covariate effects, one will have to provide inference based on the 
marginal posterior distribution of the regression coefficients. A prior distribution 
for the regression coefficients is fairly straightforward; a normal prior for the /3s is 
often a reasonable choice. An appropriate prior for the baseline hazard function, 
however, is a bit more problematic. We now discuss several flexible models for the 
baseline hazard. By “flexible,” we mean that we make few assumptions about the 
shape of the hazard function. Even though we may not force a particular shape, 
our models for the baseline hazard function are not without parameters. In fact, 
we gain flexibility with these models by putting together local parametric models. 
Thus, our statistical model for the baseline hazard function may well consist of a 
large number of parameters, despite the full model being called “semiparametric.”
We start by breaking up the time axis (i.e., the positive real line) into 
intervals. Let a partition of К intervals spanning 0 to oo be given by 
[ao,ai)> [ai,a2)> • ••, [й/c-i. M, where ao = 0 and ак = oo. There are many ways 
one can define the partition. The intervals need not all have the same width, and the 
grid along the time axis can be as fine as one wants. For fitting the Cox model, one 
generally forms a grid based on the times of the observed failure times (both cen­
sored and uncensored times). One may only use the observed (uncensored) failure 
times and form the intervals so that each one brackets at least one of the observed 
(uncensored) failure times.
Let T be the random variable representing the time of an event (i.e., the sur­
vival time), and g, = P{T e [ai_i,ai) | T > 
where H is the cumulative
hazard function corresponding to the distribution of T. Bayesian models for mak­
ing inference via the proportional hazards model will consider different probability 
distributions to characterize the g*.  We note that if one’s model for the baseline 
hazard function has independent parameters across the intervals, then one will have 
К parameters for just the baseline hazard. If the number of parameters in the model 

364 
Bayesian Thinking in Biostatistics
(K plus p, the number of covariates) is greater than the number of uncensored ob­
servations, then the model will not be identifiable.
Piecewise Exponential Model. We now describe a fairly straightforward stat­
istical model for the baseline hazard function. The exponential distribution is a 
simple one-parameter model that sometimes is useful when modeling times until 
an event. The usefulness of this sampling model derives from its relationship to a 
Poisson process. That is, if one considers that the number of events that occur in 
an interval follows a Poisson distribution with parameter Л, then the time in be­
tween the events will follow an exponential distribution with parameter Л. We have 
seen that the gamma distribution is conjugate for the exponential distribution, so 
a gamma prior on Л will lead to a gamma posterior.
The gamma-exponential model is too restrictive for general use, having 
just one parameter and a mode that is always at 0. The gamma-exponential 
model is actually quite useful, however, when one models the failure-time dis­
tribution via a piecewise exponential model. Consider our ^interval partition 
[o.0,), [ai,<*2),
 • ■ •, [ак-х,ак). We are going to posit possibly different exponen­
tial distributions for T within each interval of our partition. Although we defined 
а к = oo, all we need for our analysis of a data set is for а к to be larger than any 
observed failure time. Let Д = [а&-х,а&), and assume that the baseline hazard 
function within interval Д is given by fio(t) = Afc,t € Д, k = l,...,j<. That 
is, there is a constant hazard that applies to each interval of the partition, which 
translates to an exponential sampling distribution within the interval. The A& are 
unknown parameters in the statistical model. We will usually want A& > 0 for each 
interval to ensure that fio(<) is a true hazard function. (Recall from Chapter 11 
that the cumulative hazard Ho(c) = Joc ho(u)du -> 00 as c -> 00 to ensure that the 
survival curve goes to 0 over time.)
The observed data for the ith individual consist of a follow-up time (tj), an 
indicator of failure or censoring status (<5i), and the set of covariates (xj). Let D be 
the observed data. We define Vik to be an indicator that equals 1 if individual i's 
follow-up time lies in interval Д and is 0 otherwise. That is, 1/^ = 1 if ti E Ik and 
0 otherwise. Finally, let 0 be the set of regression coefficients.
The sampling distribution or likelihood with the piecewise exponential model is 
given by
f(t,6 I 5,A,x) = fj n^fce1'^)6-^
'=1A = 1[ 
(12-7)
x exp < -Vikl Xk(ti - ak-i) + ^Xj(aj - aj-i))ex'0 > .
Our interest is in the baseline hazard at the moment, so we will temporarily 
ignore the covariates. Let T7\. be what is sometimes called the total uptime in 
interval Ik- TTk is defined as the sum of the lengths of earlier intervals plus the 
follow-up times during interval Ц- for observation times falling in the interval (i.e.,

Survival Modeling II: Time-to-Event Regression Models 
365
i'ifc = 1) plus the length of interval Ik for observations times falling later than the 
upper end of the interval, a*.  We can write this out successively as
TT1 = 52 
~ a°) + 1{ti>al}(a\ - do)} .
1=1
TT2 
= 
TTi + 52 {"alii - Qi) + Л*.>д?}(
а2 - Qi)} -
TTj 
= 
T7fc-i + 52 {viktii ~ Qfe-i) + I{t,>ak}(<lk ~ «К-1)} .
i=l
TTK = TTK^+^Mti-aK^)}.
i=l
The last equation follows from the assumption that tk exceeds all observed failure 
times.
We can determine the posterior distribution for the piecewise constant hazards 
(А
*,
 к = 1,... ,/<). Consider independent gamma priors for the exponential rate 
parameter Xk in interval Д, Xk ~ Ga(aofc,/?ofc), к = 1,..., К. Thanks to the con­
jugate nature of the statistical model, the posterior distribution in the interval is 
Xk | D ~ Ga^aok + Пк,0Ок + TTk), where Пк is the number of uncensored event 
times in interval Д.
The easiest way to add covariates is to assume that the covariates affect the 
underlying hazard function the same way over time. That is, the hazard effect 
does not change over time, only the baseline hazard does. This is the proportional 
hazards assumption. Thus the hazard at time t for patient i with covariates Xi is 
h(t) exp(x,/?i). While this model allows for a more flexible characterization of the 
baseline hazard, it, being a proportional hazards model, has the drawback that it 
assumes that covariate effects are independent of time. Thus, the hazard functions 
are parallel on the log scale. We illustrate this constant distance on the log scale in 
Figure 12.2. The figure shows four posterior mean hazard functions from an analysis 
of the CALGB breast cancer trial. The У-axis is logarithmic in the figure. One can 
see in the graph that the distances between group-specific hazard functions remain 
the same over time.
12.2.2 Counting Process Formulation or Poisson Likelihood Analog.
We now present a formulation of the likelihood that one can use when carrying out 
posterior inference via MCMC. The same basic approach works in BUGS, JAGS, 
and Stan, with minor modifications relating to syntax and setting up the data. See 
Appendix C for more information.
One of the earliest proposals for Bayesian analysis in a proportional hazards 
model is due to Kalbfleisch (1978) [201]. In this model, we consider a partition, 
as in the piecewise exponential model, and then posit a gamma process prior for 
the baseline hazard on the partition. This approach allows one to estimate the

366
Bayesian Thinking in Biostatistics
0 
2 
4 
6 
8 
10 
12
Years
FIGURE 12.2: Posterior mean hazard function from a piecewise exponential model 
of disease-free survival. The data are from CALGB study 9344. Separate hazard 
functions are shown for each set of covariate values.
underlying hazard function nonparametrically. The development follows from the 
counting process formulation first presented by Andersen and Gill (1982) [6] and 
later by Clayton (1994) [80] within a Bayesian context. It builds on the formulation 
of the similarity of the likelihood with a multinomial-JPoisson likelihood, as pointed 
out by Holford [168] and Olivier and Laird [211].
Ignoring the partition for the moment, we first consider continuous time. We
characterize the observed events as arising from a counting process A^(t) associated
with each individual in t ho st tidy j>ojjulation. These processes count the number
ofevents of interest that occur to the /th individual until time t. (We assume that 
only one event can occur in our case.) For this stochastic process, let Ji(t)(lt =
K(d.\r,(t) | Ff_) be the associated intensity process. which is related to a hazard
function. In this formulation. <7/V,(/) is the increment of the counting process JV,
over a short half-open interval [f. f +df). and denotes the available data up to
tint»' t. That is. 
equals O. except at the /th individuals event time, when
it takes till' vttltte 1. With this detinit ion. A'(d/V,(/) / 
) is th(, probability of an

Survival Modeling II: Time-to-Event Regression Models
367
event for the ith individual in [t,t + dt). The instantaneous hazard function for 
individual i corresponds to the limit of this expectation as dt goes to 0. With the 
proportional hazards formulation, we assume that the instantaneous hazard equals
= Уг(<)/10(<)ехр(.г'Д).
In the above formula, Уг(£) is a process that corresponds to the ith individual being 
at risk of an event at time t. That is, Yi(t) = 1 at time t if the individual is still 
in the risk set at time t and 0 otherwise. The rest of the right-hand side of the 
equation is the Cox model we presented earlier.
The data, therefore, consist of realizations of the processes and y,(i), 
along with the covariates Xi for each individual i = 1,..., n. The parameters in the 
model are the regression coefficients /3 and the integrated baseline hazard (H(t) = 
f0 ho(u)du). We estimate the integrated baseline via our nonparametric model.
The joint posterior distribution for the parameters is given by p (/3, Ha | D) oc 
p(D | (3, Яо)р(/^)р(Яо). Assuming that the censoring is ignorable, we can 
write the likelihood based on the sampling distribution as p (JD | /3, HQ) oc 
ПГ=1 {Пе>о 
exp {-7»(^)с?
*}.
 И we consider the increments dNi(t) as in­
dependent Poisson random variables with means (rates) 7j(t)dt in the short in­
terval [t,t + dt), then we would get the same likelihood. That is, we can treat 
dNi(t) ~ Po(7j(t)dt). Letting dHo(t) represent the jump in the integrated base­
line hazard in [t,t + dt), we have, as before, 7j(t) = yi(t)exp(x//5i)d^0(<)- The 
gamma distribution is the conjugate prior for the Poisson distribution, so we con­
sider that the increments (dHo(t)) have independent gamma distributions. As 
in Kalbfleisch [201], we posit the distributional assumption on the increments 
dHo(t) ~ Ga(c x TiQ(i), c), where the parameter c represents prior uncertainty as­
sociated with the prior guess for the baseline hazard function, h^t).
12.2.3 Prior Distributions for Parameters in Proportional Hazards Re­
gression Models
The gamma process prior formulation lends itself well to situations in which we have 
prior information about the baseline hazard. One can also carry out a Bayesian ana­
lysis in which one considers less informative priors for the independent increments 
of the cumulative baseline hazard. Prior specification of the regression effects (/3) 
completes the model. One can use a convenient vague prior, such as /3 ~ 7V(0,106), 
for example. We now discuss informed prior distributions for the At followed by a 
discussion related to the regression coefficients, the /3s.
12.2.3.1 Prior Distributions for Hazard Functions in Each Interval
We are assuming that a constant hazard rate applies within each interval. Recall 
our TC-interval partition over (0, oo) is [ao,ai), [01,02),-.., 
with ao = 0
and ok = 00. We denote the ith interval by 7, = [afc-i,ajt), and assume that the 
baseline hazard function within interval Ik is ho[t) = Ajt, t e Ik, к = 1,..., К. If

368
Bayesian Thinking in Biostatistics
we assumed a single exponential sampling model for all of the failure times (i.e., 
ho(t) = A for all times t), then the integrated hazard function in the ith interval 
would be 
= Ax (afc-ajt-i). We would like to relax the assumption
that the same rate parameter (A) applies in each interval, since that assumption 
seems unlikely to be true in most settings, particularly over long periods of time. 
Instead, we want a prior model that may consider the exponential model to be 
the prior mean of the hazard function but will also allow for interval-to-interval 
variation. We will specify the gamma process approach in a manner that will allow 
heterogeneity of hazard rates across intervals.
Let Afc be the constant hazard rate in the fcth interval [a^-i,^). Our prior 
model is
Afc ~ Ga(A
*c,c),
 k=l,...,K.
The prior mean hazard rate is A*  = E(Ajt) = E{ho(t)} for all к and at any time 
point. In case the intervals in our partition are of different widths, we may want 
to incorporate it into the prior by multiplying c by the width in each interval. The 
prior model becomes Afc ~ Ga{A
*c(ajt
 -вг-1),с(а^ — a^-i)} for interval Д. For 
ease of notation, we will simply write A^ ~ Ga(A
*Cfc,cjt)
 for the fcth interval.
We need c and A*  to specify the prior distribution. We focus on c first. The prior 
mean and variance of A ~ Ga(A
*c,
 c) are A*  and A*/c,
 respectively. If c is large, 
then the prior variance will be small and the prior mean will have relatively more 
weight in the posterior, leading to the posterior mean being closer to A*.
 If, on the 
other hand, c is small, then the posterior mean may deviate more from the prior 
mean and may be relatively farther from A*.  If c is too small, the posterior means 
of the Afc may jump around a lot, leading to overfitting. Many choose c = 0.001 to 
form a reference prior, although this seems arbitrary.
What value shall we use for A*?
 Recall that we are assuming the same prior mean 
for each interval and, basically, a prior mean that is an exponential distribution. 
The median for the Exp(A
*)
 distribution is log(2)/A
*.
 If we have a fairly good prior 
guess tm for the median, then we can set A*  = log(2)/tm. We could also put a prior 
distribution (e.g., Ga(a, b)) on A*  with a “best guess” and percentile, as we have 
done in earlier examples of gamma priors (such as the gamma-Poisson model in 
Section 5.3.2).
12.2.3.2 Prior Distribution for the Log Hazard Ratios
In the proportional hazards model, the Z3s are the logarithms of the hazard ratios. 
Since hazard ratios are a scale that researchers are familiar with, we can elicit prior 
information directly on the scale of for the jth covariate. It is quite common to 
consider a normal prior distribution for each 0. with mutual independence for these 
parameters. The normal distribution is not conjugate in this case but does corre­
spond to the large-sample distribution of these parameters. Therefore, a standard 
reference prior for a covariate would be a normal distribution with zero mean and 
a barge variance. The zero mean corresponds to a prior assumption that the hazard 
ratio is 1. that is. the covariate does not affect the hazard or survival probabilities, 
given the functional relationship.

Survival Modeling II: Time-to-Event Regression Models 
369
How large should the prior variance be in this reference prior? Depending on 
the context, it may be very unlikely that one will see really large hazard ratios. In 
randomized clinical trials, for example, hazard ratios larger than 3 when comparing 
treatments are quite rare. The 5th percentile of the standard normal distribution 
is —1.645, and e-1640 = 0.19. Since exponentiation preserves percentiles mid it is 
unlikely that a treatment would reduce the risk failure by as much as one-fifth, a 
prior variance of 1 is probably sufficient in many cases. In general, it would not 
matter if the prior variance is set to a much larger value, such as 10 or 100.
It is also possible to elicit a prior from knowledgeable individuals as we have 
in other contexts. Recall that is the hazard ratio associated with a one-unit 
increase in the jth covariate. Suppose Rj is the preliminary estimate of the most 
likely value of the hazard ratio e^. Then, the best preliminary estimate of the log 
hazard ratio for this covariate is 0oj = log(Rj).
We will determine the prior variance for /3j based on a prior estimate of a 
percentile of the hazard ratio. If we are, say, 95% certain that the hazard ratio is 
less than Rj, then we can find the prior standard deviation crOj from
о.95 = р№<н.) = ф{^^1)|,
where Ф(-) is the standard normal cdf. This equation leads to aoj = 
|log(R’1) - log(Rj) | /1.645 after plugging in the 95th percentile of the standard 
normal distribution. If we instead elicited a value that the individual was 100a 
percent certain was below the hazard ratio, we would work with a = P(J3j > Rj) 
to determine the prior standard deviation.
With continuous covariates, it may be more convenient to get opinions about 
hazard ratios associated with larger ranges than one unit. For example, if the jth 
covariate is years of smoking, one could ask for the best guess associated with 
the effect of 10 years of smoking on the hazard ratio relative to not smoking. If 
that preliminary estimate is Rj for this covariate, we have Rj = e10^, yielding 
foj = log(Rj)/10.
Informed priors for interactions are a bit more challenging. Suppose our pro­
portional hazards regression model includes two binary covariates, xi and x2, 
and their interaction. That is, our model for the hazard at time t is /i(t) = 
ho(t.)exp{/3ixi + /32х2 + /?з(я1 x x2)}. With this model, the hazard ratio for 
xi = l,x2 = 1 relative to xi = 0,X2 = 0 is exp(/?i + /32 +/?з) = e0le^2e^3. 
The hazard ratio for the interaction depends on e01, the hazard ratio for covariate 
xi, and e&2, the hazard ratio for covariate x2. Suppose we have /З01 and (З02 as our 
prior values for covariates 1 and 2, respectively. Furthermore, let R3 be an elicited 
prior hazard ratio for the interaction (i.e., the case when both covariates equal 1 
relative to when they are both equal to 0). Then we have R3 = e^°le0O2e^3, from 
which we get our prior best guess for the interaction term /?оз = 1оё(-йз)/(/?о1/?02)- 
Having assumed that the /3s are a priori independent, we can use an estimate of a 
percentile (Л3) and the normal prior distribution for /З3 to determine the standard 
deviation in ^3’s prior. As we did above for the general regression coefficients, we 

370
Bayesian Thinking in Biostatistics
find (with the condition that Р(Яз < R3 | ^1,^2) = a)
a = P 
< яф1 = (3OI,02 = £02)
= р(''”^ет|'3> = ль02 = л2)
= pf 03 - 003 < log(fl3e~fo1e~'9°2) - log(-Ro3e~^01e~^02) 
у О'ОЗ ” 
О'ОЗ
T f log(^/^3) 1
I OQ3 I ’ 
for some probability a. We can then find а0з = log(^3/^03)/za, where zQ is the 
lOOoth percentile of the standard normal distribution.
As in other regression analyses, it may be easier to determine informed priors 
for a subset of the 0s. In such situations, one may combine the informed priors with 
reference priors for the remaining 0s.
Example 12.3. Proportional Hazards Analysis of Breast Cancer Study. 
We revisit the analysis in Example 12.2. We now analyze disease-free survival among 
these women using a proportional hazards regression model. We again fit a model 
with four covariates, namely, an indicator for the drug paclitaxel (T), an indicator 
for the tumor being positive for the estrogen receptor (ER), an indicator for there 
being four or more positive lymph nodes upon examination during surgery (LN4+), 
and an interaction between paclitaxel and estrogen receptor positivity (T:ER).
We first determined the grid we would use to analyze these data. The study 
randomized 3,102 women to six treatment regimens, and there were 1,228 events 
in the data set. The last failure occurred 9.88 years after randomization, and the 
longest follow-up time was 10.96 years. Given the large number of events, we chose 
to create a partition over 11 years with each interval spanning roughly 1 month 
(i.e., each interval was one-twelfth of a year). We therefore had 132 intervals over 
the 11 years. Had we created a partition based on the unique event times, we would 
have had 581 intervals of varying width. We used the monthly intervals to avoid 
the program being too slow.
Having formed the partition for inference on the hazard function, we next de­
termine the prior parameters. Recall that our statistical model assumes a constant 
hazard rate within each interval with a gamma prior distribution: A<- ~ Ga(X
*Ck,
 c^) 
for the A*th  interval. Since our intervals all have the same width w = 0.083, 
c> = cir = c x 0.083 for all к. For A*,  we used the prior notion that the me­
dian disease-free survival in this population of women with breast cancer is 7 years. 
That assumption led to A*  = log(2)/7. We set c = 0.01, which when multiplied by 
the width w gave us a very diffuse prior for the rate in each interval.
Since the prior median is set by the prior rate parameter across the partition 
(A‘). we assumed that each covariate had negligible effect on the hazard function. 
We posited a .V(0.9) prior distribution for each of the /3s. We chose a variance of 

Survival Modeling II: Тгте-to-Event Regression Models 
371
9 because this prior led to a prior 95% probability interval for each hazard ratio 
that is (exp(±(1.96 x 3))) or (0.0028,357.81). It would be extremely unlikely that 
hazard ratios would be nearly that small or that large.
Table 12.7 contains posterior summary statistics for the regression parameters. 
We see that the posterior distributions are different with this model than they were 
with the Weibull AFT model. For one thing, the signs of the estimates are reversed. 
The effects of paclitaxel (T) and of estrogen receptor status (ERstatus) are about 
the same in magnitude, as are their respective posterior standard deviations. Having 
four or more positive lymph nodes at surgery remains a major risk factor. The 
interaction between T and ERstatus is positive, but the posterior inference suggests 
less of a predictive effect (i.e., affecting treatment choice). The posterior probability 
that the interaction is greater than zero is 0.79 with the proportional hazards model, 
which is substantially smaller than the value we saw with the Weibull regression 
model (0.94).
Figure 12.3a contains pointwise posterior mean disease-free survival probability 
curves for each of four groups of women who had four or more positive lymph nodes 
at surgery. We can compare these curves to the posterior mean survival curves in 
Figure 12.1a from the Weibull AFT regression. One thing to notice is that the 
survival probabilities are higher with the proportional hazards analysis than with 
the AFT analysis. This difference is attributable to the nonparametric estimation of 
the baseline hazard function, as opposed to the parametric model’s determination 
of the hazard function. We also notice less of an interaction effect, although we 
should examine the group-specific hazard functions to see that effect more clearly.
Figure 12.3b shows the hazard functions for the four treatment groups we have 
been discussing. Since we have a relatively fine grid over the 11 years of follow­
up, we used a lowess smoother to plot the posterior mean hazard functions [82]. 
We applied relatively less smoothing to allow some of the local features to show. 
Looking at Figure 12.3b, we see that the hazard functions from the proportional 
hazards analysis show variation over time. It often happens in cancer clinical trials 
that there is an early rise in the hazard of recurrence or death, followed by reduced 
risk over time, particularly right after treatment. We also see how the shapes of 
the hazard functions track each other as a result of the constant hazard ratios. If 
we plot these hazard functions on the log scale, we will see a constant distance 
between curves. It is also instructive to compare the estimates of the hazard func­
tions with the AFT model and the proportional hazards model. The Weibull AFT 
analysis yielded posterior mean hazard functions that were almost horizontal lines 
(see Figure 12.1a).
12.3 Nonparametric Regression for Survival Analysis
In the Bayesian nonparametric survival analysis literature, there are many nonpara­
metric models available that relax the assumptions of the AFT and Cox models,

372
Bayesian Thinking in Biostatistics
TABLE 12.7: Summary of the posterior distribution of the proportional hazards 
regression parameters from an analysis of women with four or more positive lymph 
nodes treated in a breast cancer randomized clinical trial
/3
Moments
Posterior percentiles
Mean
Std dev.
2.5
25
50
75
97.5
T
-0.267
0.076
-0.423
-0.318
-0.265
-0.215
-0.119
ER
-0.518
0.075
-0.661
-0.568
-0.517
-0.467
-0.371
LN4+
0.594
0.058
0.485
0.556
0.594
0.632
0.709
T . ER
0.083
0.104
-0.116
0.012
0.080
0.151
0.289
fffimn Гни Survival 
Hazard Function tor DFS
(a) Disease-free survival from a proportional 
hazards regression model.
(b) Hazards from a proportional hazards 
regression model.
FIGURE 12.3: Posterior estimates of the disease-free survival probabilities and 
hazard functions from proportional hazards regression model with an interaction 
between Taxol and ER status among women with four or more positive lymph 
nodes.
namely accelerated time and proportional hazards. While this is a large topic in it­
self. here we introduce one such method recently developed and implemented in an 
R package. The method is based on a dependent Dirichlet process (DDP), originally 
defined in MacEachern [234]. An early adoption of the DDP for survival regression 
is by Delorio et al. (2009) [90]. The model described here also constructs a DDP by 
using ideas similar to the Dirichlet process mixture (DPM) of Weibull distributions 
that we described for exchangeable observations in Example 11.5 in Chapter 11. It 
also uses, as building blocks, the proportional hazards model described in Section

Survival Modeling II: Time-to-Event Regression Models
373
12.2 with a Weibull baseline hazard. Details and model properties are available in 
the paper by Shi, Laud, and Neuner [295]. and its computational implementation 
by Shi [294] comprises the R package DPWeibull. Here we provide a very brief de­
scription of the model and then show an example of how its analysis can be carried 
out.
In a simpler form, the model can be written by beginning with
Ъ | Xi, 0 ~d Weib(Qi, Xie1'*3'), i = 1,..., n,
where Xi is the covariate vector and & is a vector of random covariates associated 
with observation i. As is usual in regression settings, the entire model is conditional 
on covariates Xi, i = 1,..., n. The Weibull parametric proportional hazards model is 
a baseline or building block for the model. Next, we define a mixture that employs 
the Dirichlet process, similar to the Weibull DPM model in expression (11.16), 
jointly for the vector (A^a,,^). Specifically, dropping the observation identifying 
subscript г for notational convenience, we have
a, X,/3 ~ DP(v,G0), Gq = p(a,X)p(0), v ~ Ga(a„,b,,).
In Shi, Laud, and Neuner [295], convenient choices are also made for p(a,A) and 
p(/3). There are choices one may make regarding prior distributions for the para­
meters (a, A, /3) that can lead to desirable properties for the model and/or allow 
incorporating a low-information omnibus (LIO) prior. We refer the reader to Shi, 
Laud, and Neuner for details [295]. We do note, however, that the model results in 
a stick-breaking representation (Section 3.3.2) for the distribution of event time T.
We now turn to an example to illustrate how this model can be used in analysis, 
with the help of the R package DPWeibull, when one chooses to use LIO priors.
FIGURE 12.4: Posterior estimates of the hazard ratio (stage 4 vs. 1) as a function 
of time from the dependent Dirichlet process analysis in Example 12.4. The right 
panel’s vertical axis is on the log scale and also shows 95% posterior Pls.

374
Bayesian Thinking in Biostatistics
Example 12.4. Dependent Dirichlet Process Model for the Larynx Can­
cer Data. We return to the data of Example 12.1. The DDP model, being non­
parametric, does not directly yield parameter inference. However, its very generality 
makes it possible to obtain inference for a very wide variety of inferential and pre­
dictive targets. For example, while there is not a single hazard ratio for survival 
after diagnosis of stage 4 vs. stage 1 laryngeal cancer in this model, we can calculate 
this hazard ratio at each time point from each posterior sample. The R code for ac­
complishing this uses the DPWeibull package and is available on the book’s website 
under Chapter 12 in a file named Larynx.R. The resulting plot is shown in Figure 
12.4. The posterior mean hazard ratio is plotted as a function of time in the left 
half of the figure. This seems to indicate that a constant hazard ratio assumption as 
in a proportional hazards model may not be appropriate. However, the right half of 
the figure shows the large uncertainty in this hazard ratio function. A flat line can 
easily fit within the 95% probability limits. Notice that the variation is so large that 
we resorted to the logarithm of the hazard ratio for plotting purposes. This large 
variability is not unexpected with a sample size of 90 patients in a nonparametric 
survival analysis regression with four stage groups and two other covariates.
FIGURE 12.5: The left panel shows posterior means and 95% Pls for survival 
functions for stages 4 and 1. The right panel shows posterior densities of median 
survival times for patients with disease stages 4 and 1; 95% limits are shown with 
vertical lines.
Inference for survival functions and median survival times can also be carried 
out. Figure 12.5 shows the results graphically of an analysis comparing stage 4 
disease with stage 1. It is clear that stage 4 disease is associated with much worse 
survival than stage 1. Other comparisons can also be made by following the code 
in the Larynx.R program mentioned in the previous paragraph. We note that the 
package provides a predict() function that works with an object produced by 
the dpweib() function that contains posterior samples. Estimates can be made at

12.4 
Survival Analysis with Random Effects (Frailty)
We sometimes have to analyze data where we wish to account for the fact that there 
may be a shared propensity for the event of interest among groups of individuals. 
We might encounter this issue, for example, when analyzing times until death in 
an animal study of a supposed carcinogen or treatment for a disease. Animals from 
the same litter may tend to live longer than animals from another litter in the 
absence of any intervention. This extra longevity may contribute to longer lifetimes 
after exposure. Similarly, studies of times to disease onset in familial studies may 
wish to account for heritable differences across families. If we had measured some 
observable factors on the individuals when such factors are directly related to the 
propensity, we could account for the higher or lower risks with covariates. Instead, 
we will include a random effect. The random effect basically attributes the between- 
group differences in outcome to some unmeasured quality or characteristic that 
group members share. This random effect is sometimes called a frailty, particularly 
when we think of it as representing heterogeneity of different groups’ tendencies 
to be more or less sensitive to the outcome. Since adding a random effect simply 
means that we include a regression parameter that we model with a probability 
distribution, such models present little challenge in a Bayesian analysis. A common 
model includes a group-specific parameter added to the linear or log-linear model.
Suppose, for example, there are G groups (e.g., families, litters, clinics) in our 
data set, with each individual belonging to just one of these groups. We might let 
bg be the random effect that we use to characterize the change from the baseline 
hazard for group g, g = 1,..., G. We augment the linear model (x'Jl) for the ith 
individual in our AFT or proportional hazards regression model by adding the 
appropriate group’s bg^. (In the notation, g(i) represents the group to which the 
zth individual belongs.) For example, the proportional hazards regression model of 
the hazard function for individual i in equation (12.5) becomes
hi(t} = h0(t) x exp(z'/3 + £><,(,)).
All individuals in the same group g will share the same baseline hazard ho(t)eb<>. We 
complete the model by assigning a distribution to the bg. A common assumption 
is that bg ~ 7V(0,<7j), g = 1,... ,G, with a vague prior distribution on аь (or the 
precision 1/af). One might also consider a gamma prior distribution for the hazard 

376
Bayesian Thinking in Biostatistics
ratio ebo. Regardless of the prior distribution, posterior inference via some MCMC 
approach proceeds as it does without the additional random effect.
12.5 Recap and Readings
Survival analysis has been a very active area of statistical research for at least 50 
years. A good in-depth review of Bayesian methods for survival analysis is the book 
by Ibrahim, Chen, and Sinha [171].
One of the earliest proposals for Bayesian analysis in a proportional hazards 
model is due to Kalbfleisch (1978) [201], which we discussed in Section 12.2.2. This 
approach includes the full likelihood. One might question whether any justifica­
tion exists for basing Bayesian inference on the partial likelihood proposed by Cox 
[88]. Sinha, Ibrahim, and Chen [297] address this, and find it reasonable to carry 
out inference via Cox’s partial likelihood in the Bayesian setting. They consider a 
prior for the hazard function that is degenerate with point mass only at each ob­
served failure time and give an algorithm for generating samples from this partial 
likelihood-based posterior. Their approach can also be used for frailty models and 
with time-dependent covariates.
Full likelihood-based approaches, however, are to be preferred as they follow 
Bayesian principles and generate coherent posterior inferences. There are many 
such methods available; for example in Laud, Damien, and Walker [216], Delorio 
et al. [90], Sparapani et al. [302, 300], and Shi, Laud, and Neuner [295].
Evaluation of influential cases as in Chapter 10 is always an important consid­
eration when carrying out model-based analyses. Johnson [186] introduced case­
deletion diagnostics for estimating survival curves in the Bayesian log-normal sur­
vival model.
Clayton [81] extended the proportional hazards model for use in studies of 
familial propensities to experience chronic disease epidemiology. He modeled the 
data with a random frailty having a gamma distribution. See also Gustafson [156] 
for a Bayesian presentation of frailty models. Somewhat related are models for 
multivariate times to events [13, 155]. Also related to this area is the analysis of 
recurrent events, such as repeat hospitalizations or strokes; see Sparapani et al. 
[303].
In Section 12.2 we briefly mentioned extending semiparametric regression to 
allow for time-dependent covariates. We refer readers interested in learning more 
about time-dependent covariates to Collett [84] or Klein and Moeschberger [204] 
for results in frequentist survival analysis, and Hanson, Johnson, and Laud [159] 
for seiniparamctric Bayesian analyses. Shi, Laud and Neuner [295] include time­
dependent covariates for a general nonparametric Bayesian survival model.
Another important area of survival analysis is inference in the presence of com­
peting risks: see Section 11.5. Analyzing data in which patients are subject to com­
peting risks is challenging because of a problem of identifiability. An early Bayesian 

Survival Modeling II: Time-to-Event Regression Models
377
treatment of semiparametric regression for competing risks is in the dissertation 
of Fan (2008) [104]; see also Chen et al. (2014) [69]. In a recent paper. Sparapani 
et al. (2020) bring a tree-ensemble-based Bayesian nonparametric approach to the 
analysis of times to events that are subject to competing risks [300].
Beyond semiparametric models, Bayesian nonparametric survival models also 
have been developed in the regression context. Delorio et al. [90] extend dependent 
Dirichlet model to allow inference when hazard functions may not be proportional. 
We presented the DDP Weibull model of Shi, Laud, and Neuner [295] in Section 
12.3 that can also address the non-proportional hazards situation. While these and 
other such models typically use generalizations of the Dirichlet process and mixtures 
of these, as we have seen, Sparapani et al. [300, 302, 303] take a different approach. 
They use Bayesian ensembles of binary trees to randomly tessellate the covariate 
space to model the outcome’s dependence on the covariates. This is currently an 
active area of new developments in regression methods in general, for survival as 
well as other types of outcomes.
12.6 
Exercises
Exercise 12.1. Fit an exponential AFT regression model to the larynx cancer data, 
including the same covariates as in Example 12.1. Since the exponential Exp(X) 
distribution is a special case of the Weib(a,X) distribution, you can accomplish 
this by setting a = 1. Compare the posterior inference with the exponential AFT 
model to the log-normal AFT model’s results. Compare inferences with those in 
Tables 12.1 and 12.2.
Exercise 12.2. Larynx cancer data.
(a) 
Reanalyze the larynx cancer data using the Weibull AFT regression model. 
Compare results with the previous analyses in Example 12.1.
(b) 
Pick either the log-normal or the Weibull AFT regression model and investigate 
whether adding interaction terms improves the selected model. If it does, modify 
the model interpretation accordingly.
Exercise 12.3. Log-normal priors.
(a) 
Assume a single predictor variable, so each covariate vector is x{ = (1,х<1). 
Obtain explicit log-normal priors for median survival times tml and tm2 if the best 
guesses for the two medians are moi = 10 and mo2 = 20 and the expert’s values of 
the 95th percentiles are 20 and 30, respectively.
(b) 
Assume that the single predictor variable is age and that it has been standard­
ized. The average age in the data is 50, and the standard deviation is 5. Write a 
program to induce the prior on j3 when you have selected an average age of 50 for 
the first predictor and an age of 60, two standard deviations above the average, for 

378
Bayesian Thinking in Biostatistics
the second. Then
Ml !)■
(c) 
Rewrite your program for the log-normal so that you solve two equations in two 
unknowns. Run the program and show the induced priors on the fa.
Exercise 12.4. Bedrick-Christensen-Johnson priors (see Section 12.1.1). Re­
peat parts (a) and (b) of Exercise 12.3 for the Weibull AFT model.
Exercise 12.5. Continuation of Exercise 12.3
(a) 
Carry out a Bayesian analysis for Exercise 12.3 that incorporates inducing a 
partial prior on /3, where p = 1. We elicit a prior best guess for the median survival 
in the baseline case, so the first row of X identifies tml = moi- Repeat using the 
second row of X and let tm\ = mo2-
(b) 
Now suppose that there is a second covariate, say a dichotomous one relating 
to the individual’s sex (= 1 if male and = 0 if female). Let
y _ /1 0 0\ 
л V 2 °/
and assume that the prior information for the two medians in Exercise 12.3 was 
actually specified for women. Using this partial prior information, write steps in a 
program to induce a prior on fa
Exercise 12.6. Case deletion. Let D = (y,6) represent the complete data. 
Denote the data with the ith case deleted by £>(,). Write the zth case data as 
di = (j/i, <5i), and let the likelihood based on all the data except di be L(fa a | D^) = 
L(/3,a|D)/L(/3,cr|di). Prove the following:
z. |D X . 
Ufaa\D{i})p(faa)
= 
р(/3,а|Р)/£(/3,а|4)
f p(faa | D)/L(faa | di)dPda
Exercise 12.7. Show that the Weibull regression model, with an appropriate 
redefinition of 3. satisfies the proportional hazards model (12.5). Give the explicit 
form for the baseline hazard ho, the baseline cumulative hazard Hq, and the baseline 
survivor function So-
Exercise 12.8. Suppose you have data on time from diagnosis of cancer to 
death with two dichotomous predictors, sex (S) and race (R). You wish to fit a 
proportional hazards regression model to the data. Let S be the first variable, 
taking the value 1 for a female individual and 0 for a male individual. Let R take 
the value 1 if the person is African-American and 0 for a white person.

Survival Modeling II: Time-to-Event Regression Models 
379
(a) With no interaction, construct an informative prior on the two regression coef­
ficients that reflects beliefs that the hazard ratio comparing males to females is 1. 
with a 5% lower bound of 1/10, and that the hazard ratio for comparing African- 
American to white individuals is 3/7, with a 95% upper bound of 3/2. Write the 
necessary steps in an MCMC program (e.g., BUGS) to induce the prior on (Jp^). 
(b) Now assume an interaction and construct an informative prior for (3\. в-л) as 
if you have elicited the following information. Assume a best guess for the hazard 
ratio comparing a white females to a white males of 5/9 with 95% upper bound 
3/2, and a best guess for the hazard ratio comparing African-American females to 
African-American males is 5 with a lower 95% bound of 4/5. Write the necessary 
steps in an MCMC program (e.g., BUGS) to induce the prior on (Z3|,/33)
(c) 
Now assume the same elicitation in (b) and add a best guess for the hazard ratio 
comparing an African-American female to a white female of 1.0 with an upper 95% 
bound of 3. Find the induced prior on (/3i, /Зд, /З3). Write the necessary steps in an 
MCMC program (e.g., BUGS) to induce the full prior. In the same program, induce 
the prior on the four hazard ratios comparing (i) white females to white males, 
(ii) African-American females to African-American males, (iii) African-American 
females to white females, and (iv) African-American males to white males.
(d) 
Modify the prior in (c) to be only partially informative, using only the first two 
specifications. Obtain the induced prior on all four hazard ratios.
Exercise 12.9. Full conditional distributions for the proportional hazards model. 
Consider the model specified in Sections 12.2 and 12.2.3. Assume the partition with 
interval = (ajt-i.afc) and a general prior model for each interval’s hazard rate 
Afc ~ Ga(bok,dok)- Further, assume one covariate and the prior 0 ~ N(0o,Oq).
(a) 
Derive the forms of the full conditional distributions for 0, the regression coef­
ficients, and for Ai,..., Лк assuming at least one death in every interval.
(b) 
Explain how to sample each.
(c) 
Suppose the interval [а^-ра
;)
 contains no deaths. Show that with A^ ~ 
Ga(bok,dok), the full conditional posterior distribution has the form A  ~ 
<7a{bofc»0(A(
),/3,Aita)}
 for some function <;(•)■ If bo
:  is small and р(А(
),/3,<Ыа)
 
is large, the distribution focuses on small values. Explain why this might cause 
computational difficulties. Are computational difficulties more likely to occur when 
к is large or small?
*
*
*
*
*
(d) 
Consider the prior model Xk ~ Ga(A
c,c)
 given in Section 12.2.3, with A  the 
best a priori guess for the baseline exponential hazard rate. Obtain the posterior 
mode for the full conditional of A^. Use this value to give a possible explanation of 
why the selection of the constant c could have a large impact on the posterior.
*
*
Exercise 12.10. Larynx cancer data. Analyze the larynx cancer data from Ex­
ample 12.1. Compare a PH analysis with the AFT model analyses based on (i) 
log-normal and (ii) Weibull residual distributions.
Exercise 12.11. Ovarian cancer trial. Edmonson et al. (1979) described a study

380
Bayesian Thinking in Biostatistics
that compared the anticancer drug cyclophosphamide to the combination of cy­
clophosphamide and doxorubicin [101]. The study enrolled 26 women who had 
ovarian cancer with tumors that were at least 2 centimeters in diameter. After 
surgery, any residual disease was assessed. The data set includes the following in­
formation for each woman; the name of the variable in the data set is in parentheses. 
The number of days from randomization until the woman died (futime), an indi­
cator of whether the woman was still alive at the time of data collection (fustatus 
= 1 if a death and 0 if censored), the woman’s age (age), an indicator of the extent 
of residual disease (resid.ds = 1 if incomplete, 2 if complete), and indicator of the 
treatment assignment (rx = 1 if single-agent cyclophosphamide, 2 if the combi­
nation regimen), and the patient’s mobility or performance status (ecog.ps = 1 if 
good and 2 if poor). The data are included with the R package survival and are also 
available on the book’s website with the file name OvarianCancerTrial. csv.
(a) 
Carry out an analysis using log-normal AFT regression.
(b) 
Carry out an analysis using Weibull AFT regression.
(c) 
Carry out an analysis using the Weibull proportional hazards model.
(d) 
Make comparative comments on results from parts (a), (b), and (c).
(e) 
Carry out an analysis using the DDP Weibull model with LIO priors.
(f) 
Use results from parts (a)-(e) to make recommendations regarding differences 
in the treatments with respect to survival.
Exercise 12.12. Modify your program for a Bayesian proportional hazards re­
gression analysis to include a single fixed time-dependent covariate.
Exercise 12.13. Carry out an analysis of the CALGB 8541 trial using the DDP 
Weibull model and LIO priors.
(a) 
Determine the posterior distributions for the median disease-free survival in 
each of the three treatment arms, for the 5-year disease-free survival probabilities 
for each arm, and for the hazard ratios of arms 2 and 3 relative to arm 1.
(b) 
What do you conclude about how the three treatment regimens compare with 
respect to the disease-free survival outcome? Arm 1 is the most dose-intense treat­
ment regimen of the three, although the total dose is the same for arms 1 and 2. 
What do you think the study tells you about dose versus dose intensity, based on 
a comparison of arms 1 and 2? Justify your conclusions by quantitative summaries 
as informed by the data. Also use graphs to communicate your conclusions.

Chapter 13
Clinical Trial Designs
An important goal of biomedical research is to discover the causes of diseases and 
find effective ways to treat them. Some diseases affect patients acutely, such as 
pneumonia or other infections. Other diseases may progress to become clinically 
symptomatic more slowly and last longer, requiring long-term therapy, sometimes 
for the rest of the person’s life. In all cases, however, the research is driven by 
learning, then developing and testing theories. Sometimes the research is based 
in a laboratory, either with cell lines, yeast, or mammals. Eventually, though, the 
research will move to evaluate the therapy in clinical settings, both human and 
veterinary. Clinical trials are a class of experiments carried out as research in a 
clinical setting.
There are several very good books that describe key aspects of clinical trials 
[118, 260]. Aside from the important statistical aspects of clinical trial methodology 
and practice, these books cover logistics, protocol development, administration, and 
so on.
This chapter seeks to provide some insight into how Bayesian ideas can be 
brought to bear on clinical trial design and analysis in order to improve the study. 
Improvement can relate to the study being more ethical, more efficient, more flex­
ible, more consistent with one’s views of inference or science, or some combination of 
these. We do not intend to be all-inclusive but, rather, seek to provide an overview 
of the ways some trialists have applied Bayesian thinking to the design of clinical 
trials and how Bayesian thinking has influenced current views of clinical research. 
Although we only scratch the surface, we present a fairly broad range of examples 
to whet the reader’s appetite. This topic is a dynamic area of research, and many 
more applications will appear in the literature. The recent book by Berry et al. 
provides details of Bayesian adaptive designs [41].
In the following sections, we will first define what we mean by “clinical trial.” 
We will then review the different types of studies often considered as clinical trials 
and provide some Bayesian approaches to designing these studies.
We do want to point out that there are several flavors of Bayesian designs 
in the literature. There are two main classifications: fully Bayesian and so-called 
stylized Bayesian designs [231]. The former type of Bayesian design sets the design 
parameters to maximize the expected value of some utility function that relates 
to the goals and costs of the study. The other type of design adjusts parameters 
in the prior distribution or modifies decision rules to achieve desirable frequentist 
characteristics. We discuss Bayesian designs of both types in this chapter.
381

382
Bayesian Thinking in Biostatistics
13.1 What Are Clinical Trials?
Clinical trials are essentially experiments evaluating different forms of therapy in a 
setting that is somewhat similar to the setting in which the therapy would be used. 
Some authors distinguish clinical trials from general clinical studies by reserving 
the term “trial” for a randomized study. We follow that practice in this chapter, 
since it allows us to distinguish studies designed to confirm or test hypotheses from 
studies that are primarily intended for estimation of treatment effects, or even to 
generate reasonable hypotheses.
One distinguishes clinical studies by their purpose in drug development. The 
development of pharmaceuticals is traditionally divided into different phases that 
proceed sequentially. Phase 1 studies seek to learn about toxicity as it relates to 
dose or schedule. Phase 2 studies generally look for activity, sometimes as a function 
of dose. Randomized studies that are designed to establish the clinical effectiveness 
of one therapy over one or several others are phase 3 clinical trials. Phase 3 trials are 
often the final step in the process of getting regulatory approval for a drug. There 
are also phase 4 studies that collect data as part of post-marketing surveillance 
after a drug has received regulatory approval. The goal of such pharmacovigilance 
is often to collect more information on side effects now that a larger number of 
people are taking the medication in general clinical settings.
Since we have used the term “effectiveness” already, we want to indicate that the 
term has a rather technical meaning in the context of clinical research. In general, 
“efficacy” is related more to the biologic effect of the treatment, whereas “effect­
iveness” relates more to what one might expect in real-world clinical settings. For 
example, effectiveness studies will typically have fewer eligibility criteria, in order to 
allow one to gather information in a broad population of potential patients. Many 
clinical trialists have proposed simple protocols for large randomized clinical trials 
to attempt to steer these randomized studies more towards collecting effectiveness 
data than efficacy data.
Another principle that one finds in effectiveness research is analysis by intention- 
to-treat. This principle dictates that comparisons of treatments in randomized trials 
will be based on data from all randomized patients, whether or not the patient took 
all of the medication and followed the prescribed course of treatment. An analysis 
of only those patients who took all of their medicine as prescribed would typically 
be asking questions relating to efficacy. An analysis of patients according to the 
treatment groups to which they were assigned, ignoring adherence to prescribed 
treatment, would have a focus on the clinical effectiveness. This analysis considers 
the treatment effect as one might see it in the real world, where patients choose to 
adhere or not to prescribed treatment.
A different but related distinction in types of trials is found in Schwartz arid 
Lellouch [282]. They coined the terms “explanatory” and “pragmatic” clinical trials. 
Explanatory trials focus on the biologic effect of the treatment, while pragmatic 

Clinical Trial Designs
383
trials provide treatment comparisons as they might be realized in actual clinical 
practice. Schwartz and Lellouch show how the distinction suggests different designs.
13.2 Phase 1 Studies (Dose Finding)
The discussion here will focus mostly on phase 1 study designs in oncology. One 
reason is that most of the proposals in the statistical literature have Ixx'u for this 
application. The other reason is that we have; the most experience working with 
phase 1 studies in oncology.
In a phase 1 study, one picks a starting dose and a set of dose levels to ex­
plore. The basis for the starting dose most commonly relates to preliminary animal 
studies. These animal studies examine toxicity and often include some measure of 
effect. Toxicity evaluations of many medicines in animals are indeed relevant to 
learning about toxicity in humans. An early investigation into metabolism showed 
that if one examines kinetics across species, the logarithms of these measures are 
linearly related to body surface area on the log scale [117]. Given this cross-species 
relationship, starting doses are usually some fraction of a dose having a prespe­
cified toxicity risk in a given species, usually whichever species turned out to be 
the most sensitive. The U.S. Food and Drug Administration issued Guidance for 
Industry: Estimating the Maximum Safe Starting Dose in Initial Clinical Trials for 
Therapeutics in Adult Healthy Volunteers in 2005 with guidelines for choosing the 
starting dose [105].
In medical oncology, however, the drugs have often been toxic, and phase 1 
studies have enrolled cancer patients rather than healthy volunteers as in drug 
development for other disease indications. Often, the starting dose for anticancer 
drugs has been one-tenth of the ££>ю in mice or one-third of a low-risk but toxic 
dose in dogs, whichever is smaller [8, 151]. The ££>ю is the dose that was associated 
with a 10% mortality (see Section 8.3.1 for more details). The doses above are scaled 
according to body surface area, since this scale seems to allow cross-species dose­
toxicity comparisons [117, 235].
The most commonly used study design for dose escalation in phase 1 oncology 
studies is the so-called “3+3” design. The algorithm for dose escalation with this 
design proceeds along the following lines. The first three patients in the study receive 
the starting dose. If none of these three patients experiences a dose-limiting toxicity 
(DLT), as defined in the study protocol, the next set of three patients will receive 
the next higher dose. While often prespecified, the sequence of doses may be more 
adaptive. For example, some phase I studies specify the dosing increment, often as 
a function of the degree of toxicity, that the study will follow when escalating the 
dose, rather than the actual doses.
If one of the three patients treated at a given dose experiences DLT, then the 
next group of three patients receives this dose of the drug. If two or more patients 
experience a DLT of the initial three patients or out of all six patients who received 

384
Bayesian Thinking in Biostatistics
the dose under consideration, then the study typically concludes that the maximally 
tolerated dose (MTD) has been exceeded. If only one of the six has experienced a 
DLT, then the study will consider the next higher dose level for the next group 
of three patients. This design stops and declares the MTD to be the highest dose 
examined for which no more than one patient experienced a DLT.
Often in cancer drug development, treatment of an additional cohort of patients 
follows the initial 3+3 dose escalation. The purpose is often to gain more informa­
tion about the toxicity associated with the dose that the dose escalation part of the 
study suggested is the MTD. Since at most six patients will have generally received 
the MTD or final schedule of the drug, one will want to monitor toxicity closely in 
this expansion cohort. One can easily include a Bayesian toxicity monitoring rule 
based on the posterior distribution of the risk of a DLT. This posterior distribution 
will include data from the initial dose-escalation part of the study via an informative 
prior distribution. This prior distribution for the expansion cohort could summarize 
the information for the MTD as a beta distribution. The two parameters for this 
prior beta distribution might consider that at most one patient experienced a DLT 
out of the six patients who received the drug at the MTD. Depending on one’s 
outlook or assessment of the resulting operating characteristics, one might charac­
terize this information about the dose-associated risk of a DLT as Be(a + 1, b + 5), 
where the parameters a and b would reflect the a priori (i.e., before starting the 
dose escalation) belief about the risk of a DLT with this dose. For example, if one 
considered that a Jeffrey’s prior distribution characterized that initial uncertainty, 
then a = b = 0.5, and the posterior distribution—after dose escalation but before 
the expansion cohort—for the risk of DLT at the MTD would follow a Be(1.5,5.5) 
distribution.
The following R code implements a toxicity monitoring rule for the expansion 
cohort. In the code, ThetaCutOff is the upper bound of the DLT risk that the 
investigators do not want to exceed.
a.post - a + x 
b.post ■ b + (n-x) 
PostDLTRiskTooHigh - 1 - pbetaCThetaCutOf  f, a.post, b.post) 
if (PostDLTRiskTooHigh <- RiskCutOff) stop
The result of applying this code is a set of rules of the form: stop if x out of n 
patients experience a DLT.
Example 13.1. Toxicity Monitoring in a Clinical Study. Investigators are 
evaluating a new treatment that has had only limited application clinically. The 
study will treat up to 15 patients. These investigators wish to set up data-based 
guidelines to warn them if the treatment is producing more serious adverse events 
than they deem worth the treatment's potential clinical benefit. Six patients have 
received the treatment, and one of the patients experienced a DLT. The investig­
ators agree that they want to be warned if the evidence suggests that the risk of a 
DLT is greater than 309c.
The investigators, including the study statistician, decide to generate a mon­
itoring rule that will trigger a warning if the posterior probability that the DLT 

Clinical Trial Designs
3S5
risk is greater than 30% is 75% of greater. In other words, the warning will come 
if the odds are at least 3 : 1 that the DLT risk is 30% or more. Let в be the DLT 
risk for the treatment under study. Since one of the first six patients experienced a 
DLT, the investigators and the statistician decide that a Be(1.5.5.5) distribution 
characterizes their current knowledge about 0, the risk of a DLT.
Table 13.1 shows the stopping rules for monitoring toxicity using the Be(1.5,5.5) 
prior distribution for the risk of a DLT. The rule calls for stopping if the posterior 
probability is 75% or more that the risk of DLT is 0.3 or more. The study protocol 
includes this table that the study statistician generated with the R program above. 
Including the table in the protocol allows all participating investigators to determine 
at any time whether or not the current DLT experiences of the patients suggest the 
treatment may be too toxic.
Stopping rule based on the number Posterior probability that
of DLTs out of n patients 
the toxicity risk > 0.3
TABLE 13.1: Toxicity monitoring stopping rules for an expansion cohort of 15 
patients
Stop if DLT in 3 of 3 patients.
P(Risk :> 0.31Data) = 0.830
Stop if DLT in 3 of 4 patients.
P(Risk :> 0.3|Data) = 0.762
Stop if DLT in 4 of 5 patients.
P(Risk :> 0.3|Data) = 0.867
Stop if DLT in 4 of 6 patients.
P(Risk :> 0.3|Data) = 0.814
Stop if DLT in 4 of 7 patients.
P(Risk:> 0.3|Data) = 0.754
Stop if DLT in 5 of 8 patients.
P(Risk :> 0.3|Data) = 0.853
Stop if DLT in 5 of 9 patients.
P(Risk:> 0.3|Data) = 0.804
Stop if DLT in 6 of 10 patients.
P(Risk:> 0.3|Data) = 0.883
Stop if DLT in 6 of 11 patients.
P(Risk:> 0.3|Data) = 0.843
Stop if DLT in 6 of 12 patients.
P(Risk:> 0.3|Data) = 0.798
Stop if DLT in 7 of 13 patients.
P(Risk:> 0.3|Data) = 0.874
Stop if DLT in 7 of 14 patients.
P(Risk;> 0.3|Data) = 0.836
Stop if DLT in 7 of 15 patients.
P(Risk ;> 0.3|Data) = 0.794
The beta posterior distribution in Example 13.1 follows from the investigators 
considering that a Jeffreys prior distribution for в was reasonable before they treated 
any patients. One might consider the Jeffreys prior (i.e., Be(0.5,0.5)) to be an 
unusual choice, since this distribution is U-shaped, placing more probability mass 
away from the center and near 0 and 1. One might, instead, think that a more 
reasonable choice might put less probability near 1, since there would be little 
reason to consider applying a treatment that is more likely to have near 100% risk 
of a DLT than to have a 50% risk.
Many authors have pointed out the inefficiency of the 3+3 design. In particular, 
there is no underlying model guiding dose selection. Thus, decisions are relatively ad 

386
Bayesian Thinking in Biostatistics
hoc, and there is no borrowing information across dose levels. The previous example 
illustrates the lack of precision in the estimated risk of DLT at the MTD following 
the initial dose escalation. With only six patients treated at the MTD, the uncer­
tainty of the risk at this dose, as characterized by a 90% predictive interval based 
on the Be(1.5,5.5) posterior distribution, is wide: (0.03,0.49). A model-based ap­
proach could allow the information from all patients treated during dose escalation 
to inform the posterior distribution and might lead to greater precision.
One attempt to improve on the 3+3 design is the continual reassessment method 
(CRM) of O’Quigley, Pepe, and Fisher [254]. When using the CRM, one first indi­
cates a target risk of DLT (0) for the dose one will call the MTD. Given the way the 
3+3 design decides on the MTD, one would imagine that the target risk is between 
16.7% and 33.3% (i.e., between 1 in 6 and 1 in 3). Generally, one chooses 25% or 
33%.
Dose escalation with the CRM is built upon a simple (i.e., single-parameter) 
sigmoidal model to explain the relationship between dose and the risk of toxicity. 
In their original paper, O’Quigley et al. considered the function in equation (13.1a) 
with the single parameter a to relate the risk of toxicity at dose di-
Other functional forms relating the risk of DLT to the dose of a drug have 
appeared in the CRM literature. Several authors use equation (13.1b). This prior 
specification is sometimes called a “skeleton,” because it is a simple relationship 
between each dose level (dj and the prior estimate of the risk of toxicity at that 
dose level (po,i)- The parameter in this model is a ~ p(a). In cases where one wants 
to allow using doses intermediate to the prespecified dose levels, one will prefer to 
have a function that depends on dose for interpolation. Goodman, Zahurak, and 
Piantadosi [150] proposed using a logistic regression model as in equation (13.1c). 
They fixed the intercept parameter bo to simplify the model into a one-parameter 
logistic regression model. Three of the CRM functions that one often sees are the 
following:
f(di, a) = {(tanhdj + l)/2}“ ,
f(di,a) =pg,j,
f(di,a) = exp(5o + a x di)/{ 1 + exp(50 + a x dj}.
(13.1a)
(13.1b)
(13.1c)
Each of these functions has only one parameter, a. Use of a one-parameter function 
makes the method efficient but probably not flexible enough to characterize the 
entire dose-toxicity risk curve. Although this function is unlikely to characterize 
adequately the dose toxicity risk curve across all doses, it performs reasonably well 
over a small part of the curve, much like a straight line might approximate a small 
part of a curve. As the algorithm assigns doses closer to the target MTD (i.e., the 
part containing the target toxicity) the model should perform well.
A Bayesian application of the model in dose escalation requires a prior dis­
tribution. p(a). to characterize the uncertainty about the parameter and, corre­
spondingly. the uncertainty of the dose-toxicity risk curve. Furthermore, we re­
quire the parameter a to be positive in the CRM equation to maintain the re­
lationship of increasing risk with increasing dose. We reparameterize the CRM 

Clinical Trial Designs
equations (13.1a)-(13.1c) with в - exp(a). For example, equation (13.1b) becomes 
f(di,0) = PojP(3)- Now we are sure that the increasing risks across dose levels, 
namely, po,i < ... < ро.м, ensure di < ... < dA/. A particularly simple and conve­
nient prior for the parameter is 0 ~ jV(O.cr^).
One way to specify a prior distribution is to elicit a prior mean risk of DLT 
at each of the prespecified dose levels in the study. Consider a study with six dose 
levels a?i,... ,;гб- Suppose the clinical experts assign prior estimates of DLT risk 
at each dose level, Po.i, • • • ,Po.6- If we assume the dose risk function in equation 
(13.1a), then we can use the inverse function to find the right scale into which to 
convert the actual doses. The conversion simply finds the rescaled doses (,r|.........r(‘)
such that the dose-risk function fits. That is, x*  = /“'(pj. assuming that « = 0. 
the prior mean.
Rather than use the actual doses, one typically relabels the dose levels when 
applying the CRM. The prior for the CRM consists of pairs of dose levels and risks 
(di,Po
*
p(3)), i = 
for the M dose levels. Since we assume an increasing
risk of toxicity with increasing dose level, we can invert the relationship to find the 
rescaled dose level. Specifically, we invert the prior relationship, perhaps assuming 
that the parameter (3 equals its prior mean. Finally, the rescaled dose levels with 
(3 = 0 are simply di = p0,i> i = 1, • • •, M. We can also invert the logistic function in 
equation (13.1c), with exp(/?) = a, to get rescaled dose levels.
As patients receive the different doses and some patients experience DLTs, 
Bayesian calculations lead to updated characterizations of the posterior distribu­
tion of the parameter and of any function of the parameter. The function of the 
parameter that is of greatest interest is the point on the dose-toxicity risk curve 
associated with the target toxicity risk. Using the function in equation (13.1a), we 
find that the MTD will be dose d*,  the dose that satisfies f(d
*,(3)
 = в.
Posterior inference is fairly straightforward. Suppose there are I dose levels, n, 
patients at each dose level, and that yi of the patients at dose level i experienced a 
DLT. Then the sampling distribution is binomial and the posterior distribution is 
proportional to the likelihood times the prior:
I Vl........И.П,.........n,) « 
|1 - f(dt,p(0).
One can easily use either model for the risk of a DLT. Based on a grid of possible 
parameter values, the algorithm generates the posterior distribution by evaluating 
p(y I #) x P(0)- From the posterior distribution on a grid, one can compute random 
samples of predicted binary events (toxicity or not) for the next patient and decide 
on the appropriate dose accordingly.
We include some R code that computes the posterior and the posterior predictive 
distributions with a one-parameter dose-risk function for the CRM. The sample 
code includes the one-parameter dose-risk function in equation (13.1a), but one 
can program any risk function that one considers appropriate. The code easily 
generalizes to accommodate a two-parameter dose-risk function. For example, if 

388
Bayesian Thinking in Biostatistics
one has a two-parameter logistic regression of the risk on dose, one can apply the 
grid-based approach given in Gelman et al. [133, Chapter 3].
# Define the function that computes the risk as a function of dose.
pYgivenX “ function(Dose, a) {
((tanh(Dose) + 1) / 2)
*a
}
« 
Form grid (ParamGrid) for parameter Param.
« 
nGrid is the length of the grid. Initialize the vector for evaluating the
« 
likelihood for each value of the parameter Param on the grid.
ParamGrid " seq(from-0, to-UpperLimitParam, by“0.1)
nGrid - length(ParamGrid)
Likeli - rep(0, nGrid)
* 
Compute likelihood times prior at each grid value
« 
using the function pYgivenX to evaluate the likelihood.
for (i in 1:nGrid) {
LikeliTimesPrior[i] - GetLikeliTimesPrior(ParamGrid[i], Y, Dose)
* Normalize posterior: Divide by integral of likelihood times prior.
PosteriorParam - LikeliTimesPrior /
integrate(LikeliTimesPrior, lower-0, upper-3){integral
# Compute the predictive distribution.
# First, initialize vector for predictive distribution at grid.
#
PredRisk - rep(0, nGrid)
# 
Predicted risk is the sampling distribution times the
* 
posterior at each grid value. Function pYgivenX
# 
evaluates the risk function for a dose at a given value
* 
of the parameter Param.
«
for (i in IznGrid) {
PredRisk[i] - pYgivenX(Dose, ParamGrid[i]) * PosteriorParam[i]
}
Babb, Rogatko, and Zacks [14] proposed an algorithm for dose escalation with 
overdose control (EWOC). The goal is to find the highest dose that has posterior 
probability of exceeding the MTD no greater than some small value a. In EWOC, 
the MTD is defined as the dose for which the risk of DLT is some prespecified value 
9. One can use EWOC in studies with prespecified dose levels and when determining 
doses between preset minimum and maximum doses.
With EWOC, one first chooses a sigmoidal curve, such as a cumulative dis­
tribution function, to characterize the dose-DLT risk curve. Consider the logistic 
function, with dose d, such that
p(DLT I d} — exP^^° +
P(DLT|d) 1 + exp(,50 +M'
The assumption is that the risk of DLTs increases with dose (i.e., [3^ > 0). As with 
the CRM. one chooses a target DLT risk (0) to determine the recommended phase 
2 dose (RP2D). Knowing 3q and Зр one can determine the RP2D from the logistic 
function. A perhaps more intuitive parameterization is given by po, the DLT risk 

Clinical Trial Designs
3S9
at the lowest dose considered in the study, and 7, the MTD or dose associated with 
the target risk of DLT (в). After transforming the probability model for (30. 
to a probability model for (po,7), one can find the marginal posterior distribution 
for the MTD, p(7 | data) = f p(y.po I data)dp0 (see Chapter 8). After treating the 
first patient cohort at the lowest dose (dmin), EWOC assigns subsequent cohorts 
of patients doses such that the posterior probabilities that these doses exceed the 
MTD (or, equivalently, the MTD is lower than these doses) are some prespecified 
value a. That is, with 7 equal to the MTD, the EWOC dose for the fcth cohort is 
dose d* k, such that
P(7 < d*  I data) = j ' p(-y | data)d,y — a.
Tighiouart, Rogatko, and Babb [330] subsequently defined a prior distribu­
tion for (ро,т) that includes a negative correlation between these two para­
meters and, thus, has safer operating characteristics without sacrificing effi­
ciency. A program for designing a phase 1 study using EWOC is available from 
https://biostatistics.csmc.edu/ewocWeb.php.
While many phase 1 studies concern dose finding for a single drug, treatment 
for several diseases (e.g., cancer, AIDS) involves combinations of drugs. Most phase 
1 studies of multiple drugs proceed with an ad hoc approach to dose escalation. 
Thall et al. [317] proposed a Bayesian method for escalating the doses of two drugs 
within a single phase 1 study. These authors use a six-parameter function to model 
the toxicity risk associated with the doses of the two drugs. The function has the 
property that the dose-toxicity risk curve for one of the two agents is a logistic 
function when the model parameters corresponding to the other agent and the two 
agents’ interaction are zero.
The procedure consists of two stages. In the first stage, successive cohorts of 
patients receive pairs of doses of the two drugs (di,^)- These dose pairs lie along a 
line called Li. This line consists of dose pairs that range from the lowest combination 
the investigators will consider, doses that are highly likely to be safe, to the pair 
that consists of the each drug’s single-agent MTD, the latter combination likely 
too toxic. Successive cohorts of patients receive the combinations of doses along Li 
until one has treated ni patients. Here, ni is a design parameter. The design then 
moves to the second stage, at which the algorithm assigns to patient cohorts pairs 
of doses along a contour of predicted equal toxicity risk. This contour is L2. Stage 2 
ends once it has enrolled П2 patients. That is, the total sample size will be n\ + П2. 
The four design parameters are the target toxicity risk, в, the number of patients 
in each stage, щ and П2, and the cohort size, c. A program for using this design is 
available from http://biostatistics.mdanderson.org.
While phase 1 studies typically focus on acute toxicities for dose escalation 
decisions, some therapies lead to late-occurring adverse events. In such instances, 
investigators may consider an extended follow-up period over which to collect tox­
icity information. Aside from the need to consider these late-occurring events when 
deciding on the recommended phase 2 dose, patients may enter the study before 

390
Bayesian Thinking in Biostatistics
other patients have provided complete follow-up over the extended observation pe­
riod. Cheung et al. [72] proposed an extension to the CRM approach for phase 1 
studies with long periods during which to assess risk of DLTs. This method con­
siders follow-up time when assessing the risk of an adverse event and is called the 
“time-to-event continual reassessment method “ [72]. The basic method weights the 
modeled risk of an adverse event for each patient’s contribution to the likelihood. 
The weight is a function of the proportion of the total prespecified follow-up time 
the patient contributes. If a patient has gone 45 days without an adverse event and 
follow-up will consist of 90 days, then the weight will be 0.5 if the weight func­
tion is linear in time. Obviously, nonlinear weight functions are also possible. More 
information is available in Cheung [71].
13.2.1 Joint Safety and Efficacy Monitoring
As already discussed, some Bayesian designs incorporate monitoring rules based 
on the posterior probability that a parameter, such as the probability of response, 
is far from some clinically meaningful target value. Thall and Russell and others 
[318, 357] have extended this approach to monitor the risk of adverse events and 
the probability of benefit. In the case of two binary end points, such as response 
and adverse event, the study design considers the multinomial distribution of four 
possible outcomes. By combining the appropriate categories, one can estimate the 
marginal posterior probabilities of an adverse event or response. One can then use 
these marginal posterior probabilities in separate monitoring rules to allow stopping 
the study if the treatment does not appear to show much efficacy or if it appears 
to be too toxic.
Consider the following scenario. Several clinicians wish to evaluate the safety and 
efficacy of a new therapy. Using a list of specific toxicities, coding their symptoms 
and manifestations as serious or worse, along with criteria for calling the treatment 
effective, the investigators reduce the outcomes to a pair of binary events: toxicity 
(yes or no) and efficacy (yes or no). A simple way to combine these events into a 
single outcome is to consider the four possible combinations, namely, {ET}, {ЁТ}, 
{ET}, and {ET}, corresponding to “efficacy without toxicity,” “no efficacy or tox­
icity,” “no efficacy but toxicity,” and “efficacy with toxicity,” respectively. For each 
of these four events, one assigns a priori probabilities via a multinomial distribution. 
These probabilities have, in turn, a Dirichlet distribution prior, and the posterior 
distribution for these probabilities will then be Dirichlet. Interim stopping rules may 
relate to the separate marginal probabilities of efficacy and toxicity. For example, 
one might want the study to stop early if a patient’s chance of achieving the effi­
cacy outcome seems to be below a threshold (pgff) or if toxicity exceeds a different 
threshold (po°x). With the full posterior distribution for the probabilities of the four 
combinations, one can easily determine the posterior probability that the risk of 
serious toxicity exceeds the relevant threshold. That is, one can compute the prob­
ability of achieving an efficacy outcome as pefT = P({E}) = P {{ET}} + P ({ET}), 
where, for ease of explanation, we have left off conditioning on the data to get the 
posterior probability. With this easily computed posterior probability, one might 

Clinical Trial Designs
391
stop if P(ptox > p^ox | data) exceeds a value that corresponds to the level of cer­
tainty that one wishes to have before one makes a decision to stop.
Designs for simultaneously finding the right dose while considering efficacy out­
comes have also appeared in the literature. Thall mid Russell [318] presented an 
approach that combined safety and efficacy outcomes into ordered categories. Many 
of the concepts underlying this design find application in many other designs for 
clinical studies that base study monitoring on Bayesian posterior calculations. In 
the situation considered by Thall and Russell, one defines three ordered outcomes 
for each patient in the study. If we assume an underlying risk across patients in the 
study that depends only on the dose of the drug, then the three ordered outcomes 
are
{
0, if serious toxicity without any efficacy,
1, if efficacy and serious toxicity, 
(13.2)
2, if efficacy without serious toxicity.
They consider a model that is appropriate for ordinal categorical outcomes, such 
as the proportional odds model, to relate the risk of outcome to dose [238]. We 
illustrate the model with an example scenario.
Let d be a particular dose in the study, and let oddsj(d) be the odds that Y < j 
at dose d. With the ordered outcomes shown above, we have
,, ,JX 
P(Y < j | dose = d) 
. 
_
od<fejM = p(r; .|dose = d), j = o,i.
Since P(Y < 2 | dose = d) = 1, P(Y > 2 | dose = d) is undefined, so we do not 
consider odds2(d). The proportional odds model incorporates covariates, such as 
dose, by assuming that the logarithm of the odds is linear in the covariates. That 
is,
log{oddsj(dose = d)} = 0j + /3 x d, j = 0,1.
Thus, there are three parameters in the model: (6o,6i,/3). We note that the slope 
parameter (/3) is assumed the same for all odds, which corresponds to the propor­
tional odds assumption. That is, for any dose, the odds of Y < 1 divided by the 
odds of У < 0 is exp(#i — #o)> which does not depend on dose.
Thall and Russell [318] use a slightly different form of the proportional odds 
model. They characterize the odds of being in the same or higher category, that is, 
the reciprocal of the usual formulation of the proportional odds model. Furthermore, 
they set #i = p, +a and 02 = Regardless of which form of the model one chooses, 
there are three model parameters. The next step is to characterize the uncertainty 
of the model parameters with a prior probability distribution. Rather than work 
on the scale of the parameters, Thall and Russell describe prior specification based 
on the associated probability functions P(Y = j | dose = d). As we emphasize in 
Chapter 6 and throughout the book, it is often easier to elicit priors on the scale 
that the investigators know than on the scale of the parameters. In many cases, 
one can go from one scale to the other, as in this case. By showing several different 
dose-probability curves to the investigators, including examples of extreme cases, 

392
Bayesian Thinking in Biostatistics
one is able to define likely domains for the parameters. That is, one would include 
cases in which the probability of efficacy without toxicity is below a target threshold 
across all doses included in the study as one extreme. Another extreme would be a 
dose-toxicity risk curve that had the risk of toxicity uniformly above an acceptable 
level at all dose levels. With three parameters in the model, we would need a 
third scenario—maybe something in the middle. From these sample cases, one can 
derive a range of possible parameter values. Without any other information, such 
as which dose-response curves are more likely and which less likely, one can assume 
that the prior distributions for the parameters are independent and the parameters 
are uniformly distributed within their respective ranges.
The study’s design has to consider the study’s goals. In this case, the goal is 
to find which of several possible doses provides the best chance of efficacy without 
being too toxic. Operationally, this goal corresponds to finding the dose that has 
enough probability that Y = 2 and low probability that Y = 0, referring to equation 
(13.2). It is up to the study investigators to decide on the respective threshold 
probabilities or risks. For example, for some diseases a chance greater than 25% 
that the patient will experience a clinical response without severe toxicity may be 
an improvement over standard care, while in other settings, the investigators may 
feel that a threshold of 65% may be a clinically meaningful minimum. Similarly, 
the study team will decide on toxicity risks that are appropriate for their study 
population. Call these thresholds p* ff and p* ox for efficacy and toxicity, respectively. 
With these cutoff values, one can formulate the early stopping rules for dose d in 
terms of futility. That is, one may wish to stop if mounting evidence suggests that 
P(Y = 2 | dose = d, data) < p* ff. Similarly, one may wish to drop a dose d' from 
further consideration if it appears too toxic, given the accumulating data; that is, 
stop dose d' if P(Y = 0 | dose = d', data) > p* ox.
We now have a probability model for the data and threshold probabilities for 
the chance a patient will achieve a positive outcome (efficacy) and the risk of serious 
toxicity. As we treat more patients at a given dose, we will learn more about these 
probabilities. That is, viewing these probabilities as model parameters or functions 
of model parameter, (e.g., functions of (Oo,Oi,0) in the proportional odds model), 
we can carry out Bayesian computations that lead to a posterior distribution for 
these quantities. Thus, even though P(Y = 2 | dose = d) is a probability, it is 
also a prediction and a function of model parameters. Both of our key outcome 
monitoring probabilities are functions of the model parameters, namely,
P(Y = 2 | dose = d) = 
d) = 1 + e(a1i+3xJ),
Ae0+i3xd)
P(Y=0\ dose = d) = 9о(во. 0,, 5, d) = 1+c(,o+fixd). 
(13.3)
Thus, we can talk about uncertainty in these functions, with the uncertainty chan­
ging (decreasing, one would hope) with accumulating data as we learn about the 
parameters. That is. with рг(0о, d) = P(Y = 2 | dose = d), we can compute its 
posterior expected value and also make probability statements about this function.

Clinical Trial Designs 
393
For example, we can talk about the posterior mean of P(Y = 2 | dose = </) as
£{p2(0o,01,0, d) | data} = J J J 02(00.0i • 0. d)p^ 0i • # I data)d0od0id3.
Similarly, we can compute the probability that the chance of efficacy without serious 
toxicity is below, say, 20% as
/ / / J{02(0°’ 01’ d>> <O.2}p(0o. Oi,0\data}deodO\d3. (13.4)
where /{X < x} is an indicator function that takes the value 1 when the condi­
tion {X < x} is true and 0 otherwise. Putting this statement into words leads to 
the cumbersome and, for some, problematic statement about the probability of a 
probability, namely, the posterior probability that P(Y — 2 | dose = d) < 0.2. 
Despite the awkwardness of such statements, they do allow us to set up monitoring 
rules for studies based on how certain we become that a patient’s chance of a good 
treatment outcome is too low or that the treatment-associated risk of toxicity is 
too high. This certainty is the posterior probability calculation in equation (13.4).
The next step in determining the monitoring rule is for the study team to decide 
how much certainty (in terms of posterior probabilities) they wish before concluding 
that a particular dose is either not effective enough or too toxic. Let these threshold 
probabilities be denoted by7 7Ti and 7t2 for the thresholds relating to efficacy and 
toxicity, respectively, borrowing the notation in Thall and Russell. Formally, then, 
we would want to consider stopping a particular dose (d
*)
 for lack of sufficient ef­
ficacy if P ({Р(У = 2 | d*,data)
 < p* ff}) *i
• That is, if we determine that there 
is high probability (i.e., tti or larger) that the treatment-associated chance of effi­
cacy without severe toxicity is below p* ff, then we might want to stop for futility. 
Similarly, we would consider stopping a dose if we find it appears too toxic, as in 
P({P(Y = 0 | d*,data)  > Ptox}) > тгг- Of course, we can write these statements 
without the “probability of a probability” by instead using the functions of the 
parameters in equations (13.3). The equivalent statements would be
P({$2(0o,0i,0) < p£ff} | data) > ти, 
P({PO(0O,01,0) > Ptox} I dato) я2-
As long as we can compute these posterior probabilities, perhaps by resorting to 
iterative sampling methods outlined in Chapter 4, we can run the study.
One extension of this approach is the following. One might want the study 
treatment to be a substantial improvement over the standard therapy. If p^nd = 0.2 
is the historical chance of efficacy with the standard form of therapy, then one might 
only be interested in the new therapy if the probability of efficacy with the new 
therapy is at least 0.4 (= p®^d + 0.2); see also [320].
Quite often, the historical value (p
*^)
 is an estimate and, therefore, subject to 
uncertainty. Some have argued that the design should account for this uncertainty 
by considering its distribution when determining the study design’s operating char­
acteristics [319, 320]. Incorporating this uncertainty into the study’s design does 

394
Bayesian Thinking in Biostatistics
affect the operating characteristics. If, however, the study does not treat patients 
with the historical standard therapy, then nothing is learned with respect to the 
standard. There is no notion of gaining knowledge or certainty as characterized 
by the transformation from the prior distribution to the posterior distribution. In­
stead, the stopping criterion based on peff > p^d now requires greater certainty to 
stop. In effect, then, placing a distribution on this historical probability of efficacy 
is really just a sort of trick to achieve better frequentist operating characteristics. 
One could achieve the same operating characteristics by changing the prior for peff, 
making this prior more diffuse. If, as may be the case, the prior for peff is based on 
prior data, then one would have to discount those early data to make the prior more 
diffuse. In this way, the choice is either to discount the early data, making the prior 
more uncertain, or to add the extra uncertainty to the benchmark criterion 
Logically, if the operating characteristics suggest greater certainty than one feels is 
warranted, as when the study seems to stop more often with smaller sample sizes 
than one feels comfortable, then it seems reasonable to associate the investigator’s 
preference with less prior certainty for the current treatment or change the decision 
rules, rather than place that uncertainty on a parameter about which the study 
will shed no light.
13.3 
Evaluation of a Design’s Characteristics
Part of determining whether a given study design is appropriate and will satisfy the 
needs and desires of the study team requires evaluation of the design’s performance 
under different scenarios. In general, one will have to use computer simulations, 
since many designs do not lend themselves to closed-form analytic solutions. We 
now discuss the general strategy for simulating designs that incorporate Bayesian 
calculations for monitoring or final analysis. The discussion focuses on some general 
principles, since each study will tend to have its own unique needs.
The study team and reviewers of the protocol generally want to ensure that the 
study design will allow for safe and efficient achievement of the study’s goals. Does 
the study stop early and often in case of severe toxicity? Can we be confident that, 
in the end, the right dose will be the one that gets recommended for subsequent 
study? Answers to these and similar questions will be desired by the team and re­
viewers of the study. By simulating the trial under various settings, one can provide 
information to answer these questions. With a statistical model to characterize the 
study data and the monitoring decision rules, it becomes fairly straightforward to 
simulate the study multiple times.
The scenarios under which one simulates the study design will represent gen­
erally realistic situations, as well as some extreme conditions. The reason why one 
includes extreme scenarios is not that they represent likely situations. It is to show 
that the design will act appropriately should these extreme situation arise.
In many cases, the scenarios will represent a single value for the parameter of 

Clinical Trial Designs
395
interest, such as the risk of dose-limiting toxicity at each dose level or the chance of 
an outcome indicating efficacy or no treatment difference in a randomized clinical 
trial. One has to distinguish the “true” underlying value of the parameter that one 
uses in the simulations from the prior distribution that is used for data analysis. 
The prior distribution for analysis may be vague or diffuse to allow the data to 
dominate inference. The simulated set of parameters, on the other hand, may be 
quite precise—in fact, it will often be a single fixed value, as already mentioned. The 
real difference between the prior distribution and the value or values of the para­
meters in the simulations, however, is that the prior distribution is used for analysis, 
while the simulated values are used to evaluate the design. Wang and Gelfand [3-13] 
call the distribution characterizing likely parameter values in a given scenario (i.e.. 
the simulation truth) the “sampling priors.” They call the prior distribution that 
is used in the analysis for monitoring and inference the “fitting prior.” Whether 
one considers a single underlying parameter value or not, one needs to keep this 
distinction in mind. The goal of the simulations is to elucidate and present the 
characteristics of the study’s design under different possible scenarios. Thus, one 
wants to assume certain parameter values, run the study in silico, and summarize 
the results. Running the study means using the inferential framework that is part 
of the study’s design and planned analyses. This inferential framework includes the 
analysis or fitting prior distribution that one will use to analyze the trial data. We 
give an example in Section 13.5.
13.4 
Phase 2 Studies (Activity)
The goal of phase 2 studies of pharmaceuticals is generally to provide early evidence 
of clinical activity. These studies may also evaluate different doses, even though 
phase 1 studies will have provided information about the dose-toxicity association 
and established the maximally tolerated dose. In many disease areas, phase 1 studies 
enroll healthy volunteers, and phase 2 studies are the first studies to treat patients 
with the new agent. Phase 1 studies of anticancer agents, on the other hand, tend 
to enroll patients who have relapsed or failed to respond to standard and, perhaps, 
experimental treatment options. Furthermore, phase 2 studies in oncology will often 
enlist patients who have received fewer prior therapies than have patients who often 
enroll in phase 1 studies of new anticancer therapies.
While it is still common to carry out single-arm phase 2 studies, especially 
in oncology, randomized phase 2 studies are becoming more widespread. Part of 
the rationale for randomized phase 2 studies concerns the desire to learn about 
the dose-efficacy relationship. By randomizing patients to different doses, one will 
collect dose-response data from which one can infer the relationship. Additionally, 
there may be questions about which of several possible formulations of the drug 
or dosing schedules might be better for clinical use. It is more efficient to address 
such questions in smaller phase 2 studies before one goes on to large, randomized 

396
Bayesian Thinking in Biostatistics
phase 3 clinical trials. Yet another impetus for randomization in phase 2 studies is 
the low frequency of phase 3 studies that demonstrate significant benefit of the new 
treatment. Without randomization to a control therapy in phase 2, the study may 
show greater than expected activity because it happened to enroll healthier patients 
or because of improvements in supportive care or other unmeasured factors.
Phase 2 study designs fall into two broad categories. Some designs seek to estim­
ate treatment activity, while others approach the objective by casting it in terms 
of testing statistical hypotheses. The ultimate design, particularly the sample size, 
will depend on the underlying philosophy. If the goal is estimation, the study will 
often try to achieve a certain precision in the estimate. Phase 2 studies based on 
hypothesis testing, on the other hand, often base sample size targets on frequentist 
power considerations, while interim monitoring rules will usually protect the fre­
quentist error probabilities. A third approach to phase 2 study design, one based 
on decision-theoretic considerations, seeks to maximize some prespecified utility 
function in expectation. We will now discuss these three approaches in turn after a 
few preliminaries.
13.4.1 Sample Size
A key question that investigators must address when designing a study concerns 
the number of individuals to enroll, treat, and follow for the study’s endpoint. 
The standard frequentist approach to sample size determination in the context of 
hypothesis testing uses the sampling distribution and finds the sample size, n, as 
the smallest number of observations that achieves a predetermined power for a 
specific (i.e., fixed) alternative parameter value (0a), subject to keeping a specific 
Type I error probability less than or equal to some upper bound (usually 0.05). 
The choice of the Type I error probability, a, generally enters into the sample size 
calculation by defining the part of the sample space that has probability a under 
the null hypothesis (0o), that is, the rejection region. Once the rejection region is 
defined, one can compute the probability associated with this portion of the sample 
space under any hypothesis as a function of the sample size. As the sample size 
increases, the probability of being in the rejection region under ва will also increase. 
The frequentist will typically choose the sample size n for which the probability of 
being in the rejection region equals the desired power (1-/5, where /3 is the Type II 
error probability).
Frequentist designs incorporate any prior knowledge that relates to the study 
as one or several constants in the model formulation. For example, the value of 
the parameter (e.g., treatment effect) for the null and alternative hypotheses may 
be informed by data from a previous or related clinical study. The prior data may 
well be an estimate from a small study, in which case there may be considerable 
uncertainty associated with it. This uncertainty is ignored, however, in the fre­
quentist formulation of the problem. Instead, the estimate is treated as a known 
constant when designing the study. Similarly, one may need to posit values for other 
parameters in the sampling model, such as variances. Even in these situations, the 
general frequentist approach treats the assumed values as constants.

Clinical Trial Designs
397
The Bayesian approach, on the other hand, allows one to account for the various 
levels of uncertainty arising from assumptions. The prior distribution can charac­
terize such uncertainty directly, and the Bayesian formulation includes prior dis­
tributions for all model parameters. Similarly, the posterior distribution captures 
all remaining uncertainty regarding the model parameters after accounting for the 
information contained in the observations.
There are several approaches that build on the Bayesian framework for de­
termining the sample size for a study. We consider two broad categories. Design 
approaches in one category consider the primary purpose of the study to be estima­
tion. The investigators want to estimate some quantity with a certain amount of 
precision. The other category of design consists of fully Bayesian approaches. These 
include a utility function that constitutes a tradeoff between the inferential or other 
goal of the study and the cost of each observation [229]. One chooses the sample 
size that maximizes the expected utility, where expectation is over the outcome's 
sample space and the parameter space with respect to the sampling distribution and 
prior distribution, respectively, through the predictive distribution. By including a 
utility function and taking expectation with respect to all sources of uncertainty, 
this approach is coherent. Here, “coherent” means that decisions are made with 
respect to probabilities that, by following the basic axioms of probability theory, 
are logically consistent.
13.4.2 Precision of Estimates
A Bayesian approach to designing a study that is seeking to provide an estimate with 
a certain level of precision will have to decide on a particular definition of precision. 
Earlier in the book, we defined precision as the reciprocal of the variance. That 
definition is a technical one. Here, we mean precision in a generic sense, although 
any operational definition for a study will be inversely related to the variance, since 
greater variance indicates less certainty and, hence, less precision.
’ Bayesian approaches tend to focus on finding a sample size that yields some 
level of precision in the estimate or some average behavior that satisfies the needs 
of the study organizers. Cao et al. [60] review and compare several Bayesian criteria 
for determining a sample size when one wants to achieve a certain precision in the 
estimate. Precision is based on characteristics of the predictive interval for the 
quantity one wishes to estimate. The criteria Cao et al. compare are what they 
call the average coverage criterion (ACC) [1], the average length criterion (ALC) 
[193], and the worst outcome criterion (WOC) [193]. One applies the ACC by 
first choosing an interval width I that one desires for a 100(1 — a)% predictive 
interval. Given I, one then finds the smallest integer that has average coverage at 
least 1 — a. The average is with respect to the marginal distribution of the data, 
/(j/) = f f(x | 
That is, one finds the smallest n that satisfies
f ( ra(y,n)+l 
1
/ { 
f(9\y,n)d0>f(y)dy>l — a,
where a(j/, n) is the lower bound of the interval.

398
Bayesian Thinking in Biostatistics
The ALC fixes the coverage, 1 — a, and finds the smallest integer for which 
the expected width of the interval is no larger than I. Again, one integrates with 
respect to the marginal density of the data. For this criterion, the interval’s width 
is a function of the data and sample size. Let w(y, n) be a function of the data and 
sample size that satisfies fa(yn)+W^’n^ fW I = 1 — The ALC sample size 
is the smallest integer such that
w(y,n)f(y)dy < I.
The WOC seeks to ensure that one achieves the desired coverage and the de­
sired interval width over all possible outcomes. Rather than focus on all possible 
outcomes, one usually only considers a region of the sample space that has high 
probability (e.g., 95%). As pointed out by Cao et al. [60], the WOC is the most 
conservative criterion and leads to the largest sample sizes, compared to the ACC 
and ALC.
These approaches do not explicitly state a utility function to maximize. As 
pointed out by Joseph and Wolfson [195] in their discussion of Lindley [229], it is 
often difficult to specify a utility function in practice. They argue that no utility 
function may seem appropriate in some cases or satisfy all who design the study. On 
the other hand, they continue, improving accuracy of an estimate is straightforward, 
and precise estimates should lead to the right decisions, in general. For example, 
one might want the study to provide an estimate with a 90% posterior predictive 
interval width less than or equal to some value, on average. Alternatively, one might 
seek to achieve some level for the expected or average coverage of the interval.
Example 13.2. Sample Size for Precision: Known Variance. Consider a 
sample of n observations yi,..., yn with yi | p, a2 ~ N(p, a2). Furthermore, assume 
p ~ N(/2q, cr2/no). From the frequentist standpoint, which assumes fixed p, the 
sample size required for a 100(1 — a)% confidence interval to have width I when a2 
is known is the smallest n that satisfies
In equation (13.5), Zi_q/2 is the 1 — a/2 quantile of the standard normal distribu­
tion.
If we assume that the variance, cr2, is known, the sample size required for a 
Bayesian prediction interval with width equal to I to have at least 100(1 — a)% 
probability of containing the p is given by
4<T2Z2 
/2
n>------(13.6)
Notice how the prior sample size. no. adds information in the formula, essentially 
reducing the required sample size by iiq. In other words, the total sample size 
requirement is the same as the frequentist s sample size in equation (13.5), but the 

Clinical Trial Designs
399
number of new samples we need to collect is no fewer than we would nix'd without 
this prior information.
If the variance is known, the sample size required by all three criteria is given 
by equation (13.6).
It is usually not the case that we know the variance, as we assumed in Example 
13.2. We may have one or more previous studies that may provide some information 
about likely (and unlikely) values of the variance in our study. If we have a strong 
belief that these earlier studies provide reasonably accurate estimates of the variance 
we might expect in our study, then we may feel justified treating a2 as a known 
quantity. A Bayesian approach might still treat a2 as unknown but with a fairly 
tight prior distribution.
Example 13.3. Sample Size for Precision: Unknown Variance. If a2 is 
unknown, the Bayesian approach would place a prior distribution on this parameter. 
As we saw in Chapter 3, a convenient prior distribution for a2 is the inverse gamma 
distribution with parameters (i/, /?). With this prior, the sample size required by 
ACC [60] is the smallest integer n that satisfies
n + n0>----- ---------. 
(13.7)
The quantity tdf,i-Q/2 represents the 1 — a/2 quantile of Student’s t distribution 
with df degrees of freedom.
If one wants to apply the criterion based on average length of the prediction 
interval (ALC [60]), then the required sample size is the smallest integer n that 
satisfies
2f / rmrm,,. ,13g. 
”+2"3 -°/2 V (n + 2.z)(n + no) Г (H±^=l) Г(^) - '■ 
(13'8)
We note that equation (13.8) is undefined if u < 0.5.
We refer the reader to [60] for the sample size required by WOC.
13.4.3 Decision-Theoretic Sample Size Determination
A strictly Bayesian approach to sample size determination would place the number 
of patients in the context of a decision problem. That is, one might frame the 
question of sample size in terms of the cost of recruitment, treatment, and follow­
up, balancing these costs against ultimate benefit. Whereas the costs of enrolling 
and treating patients are easy to imagine, it is often more difficult to find a proper 
metric on which to place the benefit of the study. From the standpoint of the entity 
that stands to benefit monetarily, it is more straightforward to allow the utility 
function to equate benefit to some monetary gain, against which one wants to 
consider the cost of carrying out the study. From the standpoint of public health 
or of increasing knowledge—both of which are reasonable benefits to consider as 
arising from clinical studies—the proper metric is less clear.
The components needed to apply Bayesian decision theory are the following.

400
Bayesian Thinking in Biostatistics
First, one needs to specify the space of possible actions one will consider. This action 
space may consist of nominal discrete points, such as whether or not to stop the 
study, or the set of actions may be essentially continuous, as when one decides on the 
number of future patients to enroll. Secondly, there will be a utility function. This 
utility function can relate each action to a loss function, a gain, or a combination of 
the two, such as a function that relates cost to benefit. Next, one needs to specify a 
sampling distribution that characterizes the stochastic nature of the data the study 
will collect. This distribution often includes model parameters, some of which may 
relate to the primary study outcome, such as the probability of response or the 
treatment-specific risk of an event. Finally, one needs a characterization of the 
uncertainty associated with the model parameters (i.e., prior distributions). One 
needs to account for all of this uncertainty when deciding which action to take 
based on the expected utility that would result from each action. Once one has the 
expected utility for each action, considering a discrete action space to simplify the 
discussion, one can choose the action that is associated with the maximal expected 
utility.
Lindley [227, 226] approaches sample size from a Bayesian perspective. He 
presents a fully Bayesian approach to sample size determination. Lindley argues 
that the optimal sample size is the number n that maximizes the expected utility 
over the parameter and sample spaces. The decision may relate to the precision of 
the estimated treatment effect, with, perhaps, a tradeoff for the cost of collecting 
each observation.
Consider that the study designers want to make some decision d about the 
parameter в at the end of the study. The designers will sample n individuals and 
collect data y, where the distribution of the data depends in some way on the 
parameter as characterized by p(y | в). The utility function u(n, y,d, 0) yields a 
value for each decision made and value of 0 after analyzing the data from the 
n patients. As mentioned already, the utility may relate to the precision of the 
estimate, the cost of collecting the data, the benefit of finding a highly effective 
therapy, or combinations of these. We note that in many situations the decisions, d, 
may be design characteristics, including the sample size. In this example, though, 
we separate the sample size decision from the decisions one will make at the end of 
the study.
Assuming that the observations are conditionally independent and identically 
distributed, we have that the joint sampling distribution isp(y | 0) = П”=1 Р^Уг I ^)- 
We want to find the decision that maximizes the expected utility while accounting 
for the uncertainty in the parameter value and the variation in the future data for 
a fixed sample size. That is, we find the expected value of the utility for a given 
decision and sample size, integrating with respect to p(y, 0 | d, n). We can approach 
the integration by noting that p(y. 0 | d, n) = p(0 | d, y, n)p(y | d, n). The two parts 
on the right-hand side are the posterior distribution times the marginal distribution 
of the data.
In Lindley's formulation of the problem. p(y | d, n) = p(y | n), because the 

Clinical Trial Designs
401
decision at the end, d, is conditionally independent of в. given у and n. so
max max u(n,y,d,0)p(0 | d.y,n)d0^ p(y | n)dy| . 
(13.9)
Suppose, now, that the utility function is of the form u(d, 6)-cn, where c is the cost 
per unit sample. In this formulation, the utility is solely a function of the decision 
d and the parameter 0.
Consider, for example, that we want an interval estimate of 0. The terminal 
decision may be to chose an interval based on the posterior distribution of 0 that 
has posterior probability 1 - a and is of minimum length, as discussed in Section 
13.4.2. Lindley contrasts this approach with one in which the terminal decision 
consists of values a and b that will form the interval estimate (a, b) for 0. The 
full utility function is u(a, b, 0) - cn, so that the cost of sampling appears in the 
utility function and the decision problem is coherent in the probabilistic sense. As 
an aside, a challenge in these sorts of problems is to determine the cost in the same 
units as the utility function—so-called “utiles.” Let the decision, d, be the choice 
of the endpoints of the interval (i.e., a and b). Ignoring any set-up costs, one would 
determine the sample size by substituting this utility function into equation (13.9), 
yielding
max < I max ( / u(d, 0)p(9 | d, у, n)d0 j p(y | n)dy - cn > .
This formula is for general utility u(d, 0). One can make this procedure for interval 
estimation more aligned with frequentist interval estimation by including coverage 
(i.e., the probability that 0 G (a,b)). Define the indicator function <5(0) = 1 if 
0 G (a,b) and 0 otherwise. Then one can include this in the utility function as 
u(d,0) = u(a,b) + <5(0).
Although we feel that most researchers conduct experiments to lead to a deci­
sion, there are studies with the goal of gathering information. There are different 
information measures in the statistical literature that one may consider to be con­
sistent with the goal of study. One may wish to achieve a certain level of precision 
of an estimate, as we have already discussed. Alternatively, we may wish to con­
sider a measure of information that is related to knowledge or uncertainty about a 
state of nature. (Most often, the state of nature corresponds to a parameter or set 
of parameters in a statistical model.) Inspired by Shannon’s theory of information, 
Lindley [223] proposed entropy of the posterior distribution as the relevant informa­
tion measure back in 1956. For an experiment that yields n observations Xi,..., xn, 
where x ~ p(z), the information in the experiment is given by £2»P(xt) log{p(zt)}. 
Since the experiment seeks to increase our knowledge about the state of nature 
(i.e., 0 in the statistical model), we may characterize the gain in information from 
an experiment that yields observations Xi,..., xn in terms of the change in entropy 
from the prior distribution to the posterior. Averaging over uncertainty, we would 
consider the average amount of information provided by the observations as
f p(0 | zi,... ,xn) log{p(0 | 
... ,xn)}d0 - Jp(0) log{p(0)}d0.

402
Bayesian Thinking in Biostatistics
If we now want to compare experiments (i.e., study designs) during the plan­
ning stage, we would also want to account for the uncertainty in the data. That 
is, we would also integrate over the possible outcomes of the experiment. Let 
Zq = f p(0)log{p(0)}d0, the amount of “knowledge” or information in the prior 
distribution. After the experiment that yields the observation x, the amount of in­
formation provided by the experiment is Ii(x) = f p(0 | x) log{p(0 | x)}d0. The av­
erage amount of information an experiment is expected to provide is Ex [Zi (x) — Zq], 
which equals
р(в | x) log{p(0 | x)}d0 - Jp(0) log{p(0)}d#] p(x)dx. (13.
This information measure provides a means with which to compare possible exper­
iments. One will choose the design that one expects will provide the most informa­
tion.
Other researchers have considered entropy in the design of studies. Sebastiani et 
al. [287] develop other entropy-like information measures. Piantadosi [260] considers 
the use of entropy when designing translational studies that typically have small 
sample sizes and seek to learn about biologic effects of a treatment. Recently, Ventz 
et al. [340] have proposed allocating patients to treatments adaptively based on 
entropy considerations.
13.5 Interim Analyses and Stopping Rules
An important part of designing a clinical study is knowing when to stop the study. 
We have discussed planning the size of the study in terms of the target sample size. 
Investigators, funding agencies, and patients will also want to know the results of 
a study as soon as one can draw a conclusion from the study’s data. Most clinical 
trials, therefore, include statistical monitoring rules or stopping boundaries. These 
boundaries may focus only on stopping early if there is sufficient evidence that the 
new treatment is superior to the control therapy. Many clinical trials also include 
futility stopping rules that suggest stopping the study earlier than planned when 
the accruing data indicate that there is little chance the study will conclude in favor 
of the new therapy’s superiority over the control. Any predefined monitoring rules 
that may lead to stopping the study prior to its planned end (either in terms of 
accrual or timing) are examples of adaptive designs. We discuss several monitoring 
approaches in this section.
13.5.1 Posterior Probability-Based Stopping Rules
Related to estimation-based designs are monitoring rules based on the posterior dis­
tribution of the study's primary measure of treatment effect. Consider a single-arm 
study for this example. A similar approach is often adopted for safety monitoring 

Clinical Trial Designt
-103
based on a high posterior probability that a risk of a serious adverse event excxxxls 
some value. Let 0 be the probability of an event, such as a response to therapy or 
an adverse event, associated with the study treatment. If the outcome is binary, 
then the sampling distribution is binomial. With a beta prior distribution for p(0). 
the posterior will again be beta, making the calculations easy. Suppose that 0C is 
a threshold value of treatment efficacy, such as the minimally clinically relevant 
chance of a favorable response to therapy. Then one would likely want to consider 
stopping the study if at any time during the study the probability is low that the 
current treatment’s underlying efficacy is at least 0C. One might characterize loir as 
some value CutOff between 0 and 1 but closer to 0. such as 0.1. Such a rule would 
be useful for futility monitoring: stop the study if P(0 > 0е | data) < CutOff. 
Then one would compute the posterior probability of this event (0 > 0C) at each 
interim analysis and decide accordingly whether or not to continue the study. We 
have included some R statements to show how one might compute this probability 
in R. In the code, the variable ThetaC is 0C. Assume that the prior distribution for 
0 is Be(a, b) with parameters equal to some prespecified values a and b. Further, 
let x be the current number of individuals achieving the endpoint of interest, such 
as response to therapy or experiencing an adverse event.
a.post = a + x
b.post = b + (n-x)
PostProbEnoughEfficacy = 1 - pbeta(ThetaC, a.post, b.post) 
if (PostProbEnoughEfficacy) <= CutOff
Stop
For toxicity monitoring, one might instead want to stop if the posterior prob­
ability is high that the risk of a serious adverse event exceeds a threshold value 
(0
*).
 In this case, the stopping rule might look like the following: stop the study if 
P(0 > 0*  | data) > CutOff.
Similar monitoring rules based on the posterior probabilities of events relating 
to some characteristic of the treatment (e.g., response or toxicity) underlie many 
approaches [357].
13.5.2 Prediction-Based Stopping Rules
Some Bayesian approaches to interim monitoring base the decision to continue a 
study on the predictive probability of ultimately reaching a conclusion if the study 
continues to the end. The relationship to estimation is, of course, that the predictive 
probability calculations incorporate current knowledge about the treatment effect 
through the posterior probability. Recall that p(Fnew I Kurrent) = f p(Ynew | 0)p(0 | 
^current)cW> where we have assumed conditional independence of Fnew and Current 
given 0. Generally, one will predict some function of a test statistic, such as whether 
the final test will fall in some “rejection” region.
We note that this approach is a sort of inferential hybrid, in that the monitoring 
rule employs Bayesian inferential calculations of a frequentist test. One reason why 
we have followed this approach in our own collaborations is the need to satisfy 

404 
Bayesian Thinking in Biostatistics
regulators or funding agency officials who tend to require frequentist statistical 
tests.
Herson [162] proposed using predictive probability calculations when monitoring 
a phase 2 study in cancer. The motivation was to introduce early termination rules 
in the desire to reduce the number of patients who may be given ineffective therapy. 
Since, in general, these studies utilize binary outcomes, such as tumor regression 
(yes or no), the final outcome of the study will rest on the number of responses 
among the treated patients. With such a binomial endpoint, there will ultimately 
be a cutoff number of responses at the end of the study, so that fewer patients 
will be assigned to the less effective (or ineffective) therapy. Herson, noting that a 
binomial sampling distribution and a beta prior distribution lead to a beta-binomial 
predictive distribution, illustrated the calculation of the probability that the final 
number of responses (Я) will be less than the cutoff value (C) at any time during the 
study. One combines the number of current responses with the predicted number 
of responses in each of the random samples and computes the proportion of total 
responses that are less than C. This proportion estimates the predictive probability 
that the study will ultimately not conclude in favor of the treatment being active 
enough to warrant further investigation. If this predictive probability of ultimately 
concluding against the treatment’s being active is large enough, one should stop the 
study for futility. The statistician works with the clinical investigators to set the 
threshold value corresponding to “large enough” according to the desired operating 
characteristics for the study.
A simple approach to computing a random sample (NewOutcomes in the code) 
from a beta-binomial distribution is by simply combining the two functions, as in 
the following R function.
RandomBetaBinomial - functionCnRandomSamples, nNewPatients, aPosterior, bPosterior) { 
pVector - rbeta(oftandomSamples, aPosterior, bPosterior)
NewOutcomes “ rbinom(nRandomSamples, nNewPatients, pVector) 
}
Lee and Liu [218] also present a way to design phase 2 studies with interim 
monitoring for efficacy and futility based on predictive probabilities. Again, consider 
the case of a binomial sampling distribution and beta prior. In their approach, they 
define a test statistic based on data at the end of the study. Let the primary endpoint 
be response, with в representing the underlying probability of a response. Consider 
Po to be null response probability, that is, the value such that the treatment is of no 
further interest if its associated probability of response is po or less. Alternatively, we 
can say that the treatment is of clinical interest if the event or statement {в > po} 
is true. The design calls for computing the posterior probability of this event after 
all planned patients will have entered the study and concluding in favor of the 
treatment’s clinical interest if the posterior probability of this event is above some 
threshold value. 0r. Mathematically, we would conclude at the end of the study that 
the treatment is active enough to warrant further study if P({0 > Po} I T) > 07. 
This probability is a new event, namely, the event that the ultimate posterior 
probability is 6T or higher that the treatment is active enough to warrant further 
study. Let Т(У) = {P ({0 > p0} | У) > 0r}.

Clinical Trial Designs
405
T(Y) is an event. But, because it contains a posterior probability, it is a func­
tion of the ultimate study data, Y, for fixed po. 0T, and prior for 0. At the end of 
the study, once all patients have received treatment and their outcomes recorded. 
T(Y) will equal either 1 or 0, according to whether it is true or not. Before the end 
of the study, however, T(Y) will be a function of the current data and projected 
future data. That is, we can speak of the predictive probability or expected value 
of T(Y) at some intermediate point in the study. Suppose we are partway through 
the study and have outcome information ^current the current cohort of patients. 
The study will not reach its planned accrual and information goal until collecting 
information from the remaining patients. Call this future information ynew. With 
a beta prior for 0 and observed binomial data ^current, we have a beta posterior 
distribution, as we have already seen. Additionally, we have a beta-binomial dis­
tribution for the future data, Knew The final test statistic, Т(У), is a function of 
3/current and ynew • We know pcurrent and can project ynew via the predictive distri­
bution, so we can also determine the predictive distribution of Т(У). The design 
of Lee and Liu calls for stopping the study for futility before enrolling and treating 
all patients if at an interim analysis the predicted probability that Т(У) = 1 is 
low. Similarly, one would stop the study early and declare the treatment active 
enough for further study if at an interim analysis the predicted probability that 
Т(У) = 1 is high. As part of designing the study, one quantifies what values would 
constitute “low” and “high” probabilities for early stopping. Lee and Liu suggest 
finding these last two threshold values according to the frequentist properties the 
investigators wish for the study. A program for designing a phase 2 study follow­
ing the Lee and Liu phase 2 predictive probability design (Predictive Probability 
Design (PID-535)) is available from the software library at the website of the De­
partment of Biostatistics at the University of Texas M. D. Anderson Cancer Center 
(https://biostatistics.mdanderson.org/SoftwareDownload/).
Sambucini [278] proposes a two-stage design that allows one to choose a different 
sample size for the second stage, given the results in the first stage. This design 
applies to studies in which the primary endpoint is a binary outcome. This work 
extends the two-stage design of Tan et al. [314] by accounting for uncertainty of 
future data via the predictive distribution. One typically will find the stage 2 sample 
size on a grid, applying a criterion to the posterior distribution of the probability 
of clinical benefit. Let yi be the number of treatment successes at the end of the 
first stage that enrolled ni patients. Conditional on (yi,zi), find the smallest total 
sample size, N*,
 such that
pD {pA(0 > Ru | S) > A2} > 72- 
(13.11)
In the equation, S = yi, yi +1,..., y\ + (N
*
 - m) is the total number of successes at 
the end of the study. This quantity involves predicting future successes, given that 
there were yi “responses” among the first ni patients. The quantities A2 and 72 
are probability thresholds corresponding to the posterior probability of a treatment 
success (в) exceeding a clinical threshold value (Ru) with high probability (A2) 
under the scenario characterized by the design prior pD(-) [343]. The posterior 
probability in equation (13.11) is with respect to the prior distribution that one 

406
Bayesian Thinking in Biostatistics
will use when analyzing the study’s data at the end (i.e., the analysis prior [343]). 
Once one has determined the final sample size (N
*)
 and, as a result, the stage 2 
sample size (IV
*
 — nJ, one computes the threshold (r*)
 for declaring the treatment 
of clinical interest. Specifically, r*  is the largest number of successes (out of 
such that one would not consider the treatment further. That is, r*  satisfies pA(0 > 
Ru | S > r*,
 IV
*)
 < A2. Again, рл(-) refers to the analysis prior for 0.
We have found it useful to plan the study with a commonly used test statistic, 
such as Fisher’s exact test for comparing two treatments with respect to a binary 
endpoint, to satisfy regulators and funding agencies. It is relatively straightforward 
to implement futility monitoring via predictive probabilities in this setting, as we 
show in Figure 13.1 and discuss further in Section 13.6. The R code is available on 
the book’s website section for this chapter as a file named FutilityBinaryRCT.R.
Example 13.4. Phase 2 Futility Monitoring. You are a member of a team planning 
a randomized controlled study to compare a new form of therapy to the current 
standard of care for acute myeloid leukemia. The primary endpoint is response. 
The funding agency requires a frequentist analysis at the end of the study, which 
will be Fisher’s exact test in this example. You want to include an interim analysis 
for futility halfway through the study. You will apply the code in Figure 13.1 to 
determine the operating characteristics of your design.
The final analysis will be a one-sided 0.1-level test. Let 0O be the probability of 
response associated with the standard of care and $i be the corresponding probab­
ility for the new treatment. Based on many studies with the standard of care, the 
investigators expect that around 55% of the patients will respond to the standard 
of care. You propose a Be(550,450) prior for the probability of response with the 
standard of care (#o), corresponding to the high level of certainty on the part of 
the investigators. The corresponding 10th and 90th percentiles of this distribution 
Eire 53% and 57%, respectively.
The investigators are less certain of the probability of response with the new 
treatment. Early studies suggest that up to 80% of the patients may respond to the 
treatment, but it may also not be any better than the current standard. Evaluating 
several possible beta distributions, you and the rest of the team decide that the prior 
distribution ~ Be(7.5,2.5) characterizes the investigators’ assessment about the 
new treatment’s clinical efficacy. That is, they expect that around 75% of patients 
will respond to the new treatment. This prior distribution corresponds to around 
80% probability that 0.55 < 
< 0.90 and puts only 8% probability on values of
0\ < 0.55.
You run 1.000 simulations with a [7(0.1) analysis prior for each treatment’s 
probability of response. The design priors in the simulations are the two beta dis­
tributions given in the previous paragraph. For each interim analysis, one will com­
pute the predictive power of ultimately rejecting the null hypothesis via Fisher’s 
exact test at the 0.1 level of significance. The study will enroll up 80 patients in each 
treatment group if it does not stop early. You include an analysis after cohorts of 
40 patients enter the study (20 per treatment group). Thus, there are three interim 
analyses and one final analysis.

Clinical Trial Designs
-107
for (iSim in l:nSim) { 
for (iGroup in l:nCroup) { 
# Generate data for the new cohort randomized to each of the two treatments 
Control[iGroup, 2] - rbinomd, nOPerGroup[iGroup] , pO) 
Trt[iGroup, 2] - rbinomd, nlPerGroup[iGroup] , pl)
# Parameters for the posterior beta distribution
TotalControlResponses ■ sum(Control[1:iGroup, 2])
TotalControlNoResponse - sum(Control[1:iGroup, 1]) - TotalControlResponses 
aControlPost - aControl + TotalControlRespond 
bControlPost ■ bControl + TotalControlNoRespond 
TotalTrtResponses - sum(Trt[1:iGroup, 2])
TotalTrtNoResponse - sum(Trt[1:iGroup, 1]) - TotalTrtResponses 
aTrtPost - aTrt + TotalTrtResponses; bTrtPost • bTrt + TotalTrtNoResponses 
# Generate remaining obs from predictive beta-binomial dist’n 
nORemaining - nO - nOEntered; nlRemaining ■ nl - nlEntered 
Pred.pValue - rep(NA, nPred) 
if (iGroup < nGroup) {
xOPred " RandomBetaBinomial(nPred, nORemaining, aControlPost, bControlPost) 
PredTotalControlResponses - TotalControlResponses + xOPred 
PredTotalControlNoResponse - TotalControlNoResponse +
(nORemaining - xOPred) 
xlPred " RandomBetaBinomial(nPred, nlRemaining, aTrtPost, bTrtPost) 
PredTotalTrtResponses ■ TotalTrtResponses + xlPred 
PredTotalTrtNoResponse - TotalTrtNoResponse + (nlRemaining - xlPred) 
# Generate future obs’ns and combine with current obs’ns for final test.
Pred.pValue " rep(NA, nPred) 
for (iPred in 1:nPred) { 
.
Tab - matrix(c(PredTotalTrtRespond[iPred], PredTotalTrtNoRespond[iPred], 
PredTotalControlRespond [iPred], PredTotalControlNoRespond[iPred]), 
ncol-2, byrov“T)
Pred.pValue [iPred] - fisher, test (Tab, altemative-"greater")$p. value 
} 
PredProbReject[iSim, iGroup] - 
sum(Pred.pValue < pValueToReject) / length(Pred.pValue) 
if (PredProbReject[iSim, iGroup] < CutOff) { 
Stop[iSim] - 1.0 
break
SampleSize[iSim,] ■ c(nOtemp, nltemp)
if ((iGroup ■■ nGroup) t (Stop[iSim]““0)) {
TabFinal - matrix(c(TotalTrtRespond, TotalTrtNoRespond, 
TotalControlRespond, TotalControlNoRespond), 
ncol-2, byrov-T)
pValue[iSim] - fisher.test(TabFinal, alternative-"g")$p.value 
SampleSizefiSim,] - c(nOtemp, nltemp)
FIGURE 13.1: R code to simulate a randomized clinical tried with futility analyses. The 
tried’s primary endpoint is binary, and the final emedysis uses Fisher’s exact test. R code 
available on the book’s web site as file FutilityBinaryRCT.R.

408
Bayesian Thinking in Biostatistics
Table 13.2 shows some of the design’s operating characteristics. The table also 
includes results with design priors that correspond to the underlying treatment­
specific probabilities of response being single numbers, as in point null and al­
ternative hypotheses. One sees that the extra uncertainty captured by the design 
prior increases the fraction of simulated trials that stop for futility and reduces 
the proportion of trials that ultimately reject the null hypothesis. For reference, a 
frequentist design without interim analyses would have around 90% power to reject 
the null hypothesis in favor of the alternative with 80 patients per group, assuming 
a one-sided 0.1-level Fisher’s exact test.
TABLE 13.2: Operating characteristics for a randomized clinical trial that includes 
futility analyses using predictive probabilities
Control 
prior
Treatment 
prior
Stop early 
for futility
Reject 
Ho
Average 
sample size
0O = 0.55
0i = 0.55
69%
8%
52.4 / arm
0O = 0.55
01 = 0.75
5%
88%
77.9 / arm
0o ~ Be(550,450)
0i ~ Be(7.5,2.5)
18%
71%
72.7 / arm
13.5.3 Hypothesis Test-Based Stopping Rules
As mentioned earlier, many phase 2 designs are based on frequentist statistical hy­
pothesis tests. If the primary outcome is binary, such as “response,” the underlying 
statistical hypothesis being tested is Hq : p < po for some value po representing a 
probability of success that would not be clinically useful.
Statistical hypothesis tests for phase 2 clinical studies may be evaluated by 
Bayes factors or posterior probabilities of the hypotheses. Johnson and Cook [180] 
describe a test-based design approach that uses Bayes factors. Their design is based 
on using so-called non-local prior densities (Johnson & Rossell [181]) for the prior 
distribution under the alternative hypotheses. An advantage of non-local priors 
in this application is a gain in efficiency relative to other Bayesian designs. Many 
Bayesian designs (or stylized Bayesian designs) characterize prior uncertainty about 
a treatment-effect parameter under the alternative hypothesis as vague or charac­
terized by a reference prior. These prior distributions place mass across a range of 
values that includes the null hypothesis. A classic example is testing the point null 
hypothesis Ho : 0 = 0 against the alternative : в / 0, with 0 ~ N(0.cr2) under 
the alternative distribution. By virtue of there being mass around parameter val­
ues that are consistent with both the null and the alternative hypotheses, evidence 
in favor of the null hypothesis over the alternative hypothesis amasses relatively 
slowly. Non-local densities under the alternative hypothesis, on the other hand, as­
sign no probability to regions of the parameter space that are consistent with the 
null hypothesis. As a result, evidence in favor of the null against the alternative 
will increase faster with a non-local alternative prior distribution than it will with 

Clinical Trial Designs
■109
a local alternative density that has support in the region of the null hypothesis. 
Of course, evidence in favor of the alternative will amass quickly when the "true" 
value of the parameter is far from the null region.
If one is considering two hypotheses and the decision rule is based on the Bayes 
factor, then one can convert the decision rule to be based on the posterior probab­
ility of each hypothesis (see Section 10.1 for more details). Let be the prior 
probability that hypothesis Ho is true, and F(Hi) be the prior probability that the 
alternative hypothesis is true. If Y represents the data, then the Bayes factor in 
favor of Hi over Ho (BFi0) is
Bf _ fv I H 1/IV I H 1 - P(-H' । 
। Y>
BFW - |Y | Я,)/[¥ | Wo]--------—. 
(1J.12)
Example 13.5. Bayes Factors with Non-Local Prior Distributions. Invest­
igators want to study whether adding a particular drug to a standard regimen 
of chemotherapy would improve clinical outcomes among patients with non-small 
cell lung cancer (NSCLC). The clinical outcome of interest is objective response 
rate (ORR) by the end of 6 months of therapy. A patient experiences an objective 
response if the patient’s tumor decreases in size by at least 30% from baseline, ac­
cording to commonly used criteria called RECIST [324]. Thus, the clinical endpoint 
is binary, with objective response defined as success.
The study design calls for interim futility analyses, beginning when 10 patients 
have enrolled to the study and have either received at least six cycles of therapy 
or experienced a PFS event.1 The next interim analysis will occur after 15 patients 
have either received at least six cycles of therapy or experienced a PFS event. The 
final analysis will occur after 20 patients have entered and received full therapy 
(six cycles). The interim analyses are for futility, meaning that there is at most 
weak evidence that the added drug improves clinical benefit above a predetermined 
threshold. If the combination therapeutic regimen under study is providing clinical 
benefit, we want to continue the study and enroll a total of 20 patients. The interim 
analyses is based on Bayesian hypothesis testing.
’PFS stands for progression-free survival, the time to disease progression or death, whichever 
comes first.
2https://biostatistics.mdanderson.org/SoftwareDownload/
We take the expected ORR to be 20% if the second drug does not increase the 
clinical effectiveness of the standard chemotherapy for NSCLC. This estimate is 
based on the results of several published studies. We would consider the addition 
of the experimental drug to yield encouraging clinical improvement if it leads to an 
ORR that is 35% or higher.
The program В F Designer2 allows one to determine a design based on hypothesis 
testing with Bayes factors in the case of a binomial sampling distribution. Here we 
use this program to determine interim analysis stopping guidelines.
The study will stop for futility if we see no responses among the first 10 patients 
or no more them one response in the first 15 patients. We will discard the combina­
tion as promising if we see three or fewer responders out of 20 patients. Table 13.3 
provides the operating characteristics based on 5,000 simulations.

410
Bayesian Thinking in Biostatistics
TABLE 13.3: Estimated operating characteristics of the study’s design based on 
5000 simulations for different possible “true” objective response rates
Scenario
Hypothetical 
true 
response rate
Probability 
stop for 
futility
Average number of 
patients treated 
(percentiles: 10th, 90th)
1
0.10
0.876
15.40 (10,20)
2
0.15
0.662
17.30 (10,20)
3
0.20
0.434
18.51 (10,20)
4
0.25
0.243
19.25 (20,20)
5
0.30
0.119
19.61 (20,20)
6
0.35
0.047
19.86 (20,20)
7
0.40
0.021
19.92 (20,20)
8
0.45
0.008
19.96 (20,20)
9
0.50
0.002
19.99 (20,20)
13.5.4 Decision-Theoretic Stopping Rules
In many instances, the study will lead to a decision—at least, in some generic 
sense. For example, the decision might relate to rejecting some hypothesis about 
the activity of the treatment, comparable to a null hypothesis. Another type of 
decision might relate to the next action to take for the treatment under study, such 
as whether to test the treatment further in a larger randomized study. The ultimate 
decision is whether to carry out the study. We outlined the framework for applying 
Bayesian decision theory in Section 13.4.3. In this section we focus on using decision 
theory in the context of interim analyses and deciding whether to continue or stop 
the study (i.e., on sequential decision-making).
A challenging aspect of applying sequential decision-making in study design is 
the computational part. Computation becomes even more difficult if the clinical 
trial includes sequential decision-making, in interim analyses as data accrue. The 
calculations for a Bayesian fully sequential design at time t have to consider all 
possible outcomes for all possible actions at future times to compute the expected 
utility. These calculations are usually carried out via dynamic programming [26, 29]. 
With a finite horizon (call it T), the calculations work backwards sequentially from 
the last decision time to the first. For illustration, consider a finite and discrete 
outcome space and a finite and discrete action space. At each time, the algorithm 
computes the expected utility for each action and each state. Knowing these at 
the last time point allows one to compute the optimal action for each state at 
the last time point. Then the algorithm goes to the penultimate decision time 
(T — 1) and determines the expected utility for each action at each state. That 
is, if we are at state or outcome Yj at time T — 1 and choose action аг. we know 
the probability of reaching each possible outcome at time T from the predictive 
distribution. Since we have already determined the optimal choice for each outcome

Clinical Trial Designs
411
at time T and the expected utility for that decision, we know just what to do and 
what the consequence will be for any possible outcome reached at T. We can then 
combine the information for each possible outcome at time T with the probability 
of reaching that outcome from state Yj at the previous time T - 1 to determine the 
expected utility for each decision one might take at T - 1. These calculations will 
show which of the possible actions will maximize the expected utility at the end. 
given one is at Yj at time T — 1. The algorithm carries out these calculations for 
each possible state or outcome at time T — 1 and yields the optimal action for each 
outcome one might reach at T— 1. The algorithm then goes backwards to time 7-2 
and determines the optimal action for each possible state at this time by following 
the same sort of calculations described for time T — 1. By working backwards to 
time 0, we end up with a table of optimal actions for each possible outcome one 
might observe at each decision time.
The previous example assumed a discrete set of outcomes at each of a finite 
set of decision times, with a discrete set of actions from which to choose at each 
time. As the set of possible outcomes or actions increases, the calculations become 
more difficult, growing exponentially. The problem becomes even more complex 
if one is dealing with a continuous outcome space, as when one is designing a 
clinical trial with a continuous primary endpoint, such as change in blood pressure. 
One can apply numerical methods to find the optimal solution or, at least, a close 
approximation to the set of optimal decisions. A particularly useful approach is 
based on generating random trajectories of the clinical study based on the assumed 
sampling distribution and some prior probability distribution for the parameters in 
the sampling model. If the outcome space is continuous, the computational burden 
is still enormous. When there is a sufficient or nearly sufficient summary statistic 
that one can use, over which one forms a grid, then one can get a reasonably good 
finite and discrete approximation to the full outcome space [53, 245]. One can then 
apply backward induction to the finite grid to find an approximate set of optimal 
decisions.
Carlin et al. [62] illustrate the use of forward sampling when designing a fully 
sequential Bayesian randomized clinical trial with a normally distributed primary 
endpoint. Rossell et al. [276] apply gridding and forward simulation to find the 
optimal phase 2 design and then approximate the boundaries by straight lines, 
while Ding et al. [97] use these same techniques to determine an optimal design 
for phase 2 screening trials that have a binary primary outcome. The latter two 
examples incorporate frequentist concerns in the utility function, providing a fully 
Bayesian approach that should satisfy frequentist requirements. There are many 
other examples of study designs based on decision-theoretic considerations [7, 39, 
220, 309, 221, 331, 341].

412
Bayesian Thinking in Biostatistics
13.6 Phase 3 Study Designs
Large randomized phase 3 studies are generally concerned with clinical questions of 
pragmatic interest. For example, a study might address the question whether or not 
a new form of therapy is better than a current standard or accepted way of treating 
some disease. Other examples include studies by large companies seeking regulatory 
approval to market a drug or device for some medical condition. Phase 3 studies are 
often designed and analyzed using frequentist considerations, although the designs 
of some phase 3 studies have been influenced by Bayesian considerations. Bayesian 
approaches to study design have been particularly accepted for studies by device 
manufacturers. The U.S. Food and Drug Administration’s Center for Devices and 
Radiological Health and Center for Biologies Evaluation and Research have issued 
Guidance for the Use of Bayesian Statistics in Medical Device Clinical Trials [106].
A particular impetus for incorporating Bayesian calculation in phase 3 clinical 
trials is the greater flexibility afforded by this form of inference. Frequentist charac­
teristics are affected by repeated testing of accumulating data, leading to the need 
to account for the number and timing of the analyses in the design. One approach 
to account for the inflation of the Type I error (risk of incorrectly rejecting the 
statistical null hypothesis) is to require more extreme values of the test statistic in 
order to reject the null hypothesis. Group sequential boundaries generally account 
for the inflation of the Type I error, and different authors have proposed different 
ways to compute such boundaries while still leaving the overall Type I error at some 
desired level.
As a result of the need to account for both the current value of a test statistic 
and the presence of interim analyses, the frequentist will analyze the data in a way 
that violates the so-called likelihood principle (cf. Chapter 6). The likelihood prin­
ciple relates to a fundamental assumption underlying statistical inference. Consider 
our usual situation, in which we conduct an experiment and collect data (y) where 
the variation in the samples is characterized by the sampling distribution [?/ | 0] 
for some parameter в. In turn, the likelihood will just be proportional to the joint 
sampling distribution of the observations. The likelihood principle states that all 
of the information about 0 is contained in the likelihood function, and two differ­
ent experiments that yield data producing the same value of the same likelihood 
function should lead to the same inference. Furthermore, two likelihood functions 
contain the same information about 6 if they are proportional to each other. A 
detailed discussion of the likelihood principle is given by Berger and Wolpert [33].
Since the number and timing of interim analyses can change the p-value and, 
hence, the inference from an experiment, the frequentist approach violates the like­
lihood principle. Bayesian inference, on the other hand, conditions on the data and 
is consistent with the likelihood principle. Heuristically, by looking at the relation­
ship between the posterior distribution and the likelihood, one sees that the same 
likelihood will lead to the same inference, as long as one considers the same prior 
distribution (i.e.. р(в | y) oc p(y | 0) x p(0)). By conditioning on the observed 

Clinical Trial Designs
■113
data through the likelihood. Bayesian posterior inference will not be affected by 
interim analyses, as long as the interim analyses do not affect the likelihood. By 
conditioning on the observed data and not what might have occurred, the Bayesian 
approach leads to study designs that are more flexible than frequentist designs. It 
should not matter whether the study monitors analyze the accruing data annually, 
semi-annually, or daily. The observed data are the observed data, and inference 
should proceed accordingly. Thus, the Bayesian pays no penalty for carrying out 
interim analyses as long as the likelihood is not affected.
One of the earliest discussions of sequential designs in the medical setting ap­
peared in 1960 with Peter Armitage’s book Sequential Medical Trials [9]. In his 
review of this book for the Journal of the American Statistical Association that ap­
peared in 1963, F. J. Anscombe argues against the underlying inferential philosophy 
in Armitage’s book, namely, concern for the error probabilities associated with re­
jecting or failing to reject the statistical null hypothesis [7]. Instead, Anscombe 
argues in favor of methods that are consistent with the likelihood principle, as well 
as making many other important points.
Although one would think there would be widespread acceptance of the notion 
of carrying out clinical studies with interim monitoring, one does not see many 
sequential designs in clinical studies until the 1980s. Rather than designing stud­
ies with monitoring patients one at a time, which would be logistically difficult at 
the time, group sequential study designs became popular. With these designs, one 
analyzes the data after cohorts of fixed size enter the study. The original proposals 
called for particular ways of setting the boundaries for the interim analyses, accord­
ing to how one wanted the interim analyses to relate to a single analysis at the end 
of the study [252, 262]. Flexibility was added when Lan and DeMets introduced the 
notion of a so-called “alpha spending function,” allowing a general approach for 
determining the thresholds for deciding on statistical significance at each interim 
analysis [213]. This methodology is still very much in use for phase 3 clinical trials.
Freedman and Spiegelhalter wrote many papers advocating Bayesian designs 
in clinical trials [111, 112, 113, 114, 115, 116, 305, 306, 307, 308]. They and their 
coworkers offered examples of the benefits of taking a Bayesian approach. In their 
implementation of a Bayesian inferential model to clinical trial design, particularly 
for interim analyses, they couched decisions in terms of “convincing” either a skeptic 
or enthusiast with respect to the benefit of the new treatment. Specifically, if a 
person, skeptical of the new treatment’s clinical effectiveness before the study, has 
seen the study’s data and is now inclined to favor the new treatment, then one 
might argue that the new treatment is the winner, so to speak. Similarly, if an 
enthusiastic supporter of the new therapy prior to the study has now, after seeing 
the study data, become dubious, then the new treatment is a loser. Carrying these 
notions to interim analyses allows one to consider stopping the study early, once 
the enthusiast or skeptic has reversed his or her a priori thinking about the new 
treatment.
Implementation of these ideas within the Bayesian framework requires one to 
mathematically characterize the prior beliefs of the skeptic and the enthusiast via 
prior distributions. The characterization and associated prior distributions are made 

414
Bayesian Thinking in Biostatistics
easier by the fact that many—if not most—test statistics have an asymptotic nor­
mal distribution. The method would proceed by associating the test statistic with 
a treatment difference and characterizing the treatment difference from the stand­
point of the enthusiast and the skeptic.
For example, consider a randomized clinical trial in which the parameter в 
characterizes the difference between two treatments, a new therapy and a standard 
of care (control), with positive 6 indicating superiority of the new treatment over 
the control. Clinicians generally have in mind some minimal level of treatment 
benefit that they would require of a new treatment before they would consider 
using it widely. Call this minimal level of benefit 0a]t. Clinicians would prefer the 
new treatment if its benefit over the control therapy is at least 0ait. Similarly, the 
current standard is clearly preferable if в < 0. Preference is somewhat ambiguous 
if в lies in the so-called range of equivalence (i.e., 0 < в < 0ац), however.
The skeptic’s prior may place only a small amount of probability on values of 
the treatment difference that favor the new treatment, reserving most of the prior 
probability for the region that supports the inferiority of the new treatment over its 
comparator in the trial (i.e., в < 0). On the other hand, the enthusiast might center 
the prior distribution at в = 0ait. This person’s prior would also put relatively little 
probability in the region of no benefit (i.e., the region в < 0), corresponding to 
the notion that it is relatively unlikely that the new treatment is not superior to 
the comparator; most of the enthusiast’s prior distribution has probability over the 
region in which 6 > 0.
A compromise approach for fully characterizing the skeptical and enthusiastic 
priors might set the enthusiast’s prior to place 10% or 20% prior probability in 
the region that corresponds to the new treatment’s clinical improvement being the 
same as or worse than the expected outcome with the control treatment (i.e., в < 0). 
Similarly, the skeptic’s prior might place only 5% or 10% probability in the region 
of treatment benefit (i.e., в > 0ait). Assuming a normally distributed test statistic, 
one would calibrate the prior variances to achieve these probabilities. Figure 13.2 
illustrates a skeptical and enthusiastic prior.
Example 13.6. Interim Analysis for Randomized Study with Skeptical 
and Enthusiastic Priors. Clinical investigators designed a randomized clinical 
trial, and it is time for an interim analysis. You will analyze the data and let the 
study’s data safety monitoring committee know if the data suggest that the study 
should stop now or continue.
The study compares two treatments for breast cancer. One group of patients 
receives drug A, and the other group receives the combination of drug A and drug B. 
The study's primary endpoint is progression-free survival (PFS), defined in Example 
13.5. The investigators chose a sample size and follow-up time to provide 80% power 
to detect a hazard ratio of 0.692. (This hazard ratio corresponds to increasing 
median PFS from 9 months to 13 months, assuming an exponential distribution, 
since the median equals log(2)/A for the Exp(X) distribution.) The final analysis 
will be a two-sided log rank test with significance declared at the 5% level.
It is common to consider the hazard ratio as the primary endpoint in a random-

Clinical Trial Designs
FIGURE 13.2: The difference between the two priors used in the study’s design. The 
skeptic’s prior (solid curve) is on the left and centered at 0; the enthusiast’s prior (dashed 
curve) is on the right and centered at 0a|t. The shaded region on the left shows the probability 
that the enthusiast assigns to treatment effects less than or equal to 0. The shaded region on 
the right indicates the probability the skeptic assigns to large treatment differences greater 
than or equal to 0ац.
ized clinical trial with a time-to-event endpoint. One reason is that the proportional 
hazards model (i.e., the Cox model) provides a flexible way to compare groups in 
the presence of censoring without making any assumptions about the form of the 
underlying hazard function [88]. Instead, one simply assumes that the ratio of the 
two group-specific hazard functions is constant over time, no matter the shape of 
the hazards. While this may seem unrealistic in many settings, it is a surprisingly 
robust assumption and is nearly ubiquitous in the applied clinical trial literature.
Consider the large-sample approximation to the distribution of the logarithm 
of the hazard ratio [333]. Under the null hypothesis that the hazard ratio is 1, the 
log rank test has variance approximately d/4, where d is the number of events in 
the analysis data set. Furthermore, the log rank test statistic is proportional to the 
log hazard ratio under the null hypothesis and so-call local alternatives [333]. We 
will use this large-sample approximation for the test statistic to approximate the 
likelihood.
Let 6 be the logarithm of the hazard ratio. We will consider two prior distri­
butions for 5, a skeptical and an enthusiastic prior. In both cases, we will consider 
6 ~ N(<5o, cr|). We first consider the skeptical prior. The skeptic will consider that 
adding drug В to drug A provides no additional benefit. The skeptic’s corresponding 
prior mean will be 0 for the log hazard ratio.
There are currently 263 events. Among patients randomized to receive drug 
A, there are 135 events; there are 128 events among patients randomized to the 

416
Bayesian Thinking in Biostatistics
combination A + B. At the time of your analysis, the observed hazard ratio is 0.83 
(A+B vs. B). The parameter of interest is 0, the logarithm of the hazard ratio 
(A+B vs. B). Given the specifications of the trial’s design, the range of equivalence 
is (ln(0.692),ln(l)) or (-0.368,0).
A skeptical prior distribution for в might have mean equal to 0, corresponding 
to no treatment difference. The skeptic’s prior variance would characterize this 
person’s prior belief that P(6 > 0ац) = 0.05. Using the relationship no = ((cr x 
1.645)/0ait)2, where a = 2, the skeptic’s variance would have no = 80. Therefore, 
the skeptical prior would be 0 ~ 7V(0,4/80).
Using similar logic, an enthusiastic prior distribution for в might have prior 
mean equal to 0alt = ln(0.692) = —0.368. The enthusiast would base the prior 
variance on the notion that P(0 < 0) = 0.05. As a result, the enthusiast’s prior 
distribution is в ~ ?V(—0.368,4/80).
Using conjugacy, the skeptic’s posterior is в | data ~ N(—0.143,0.0117), and 
the enthusiast’s posterior is в | data ~ 7V(-0.229,0.0117). Figure 13.3 shows the 
posterior skeptical and enthusiastic distributions along with the likelihood. The fig­
ure includes vertical lines at в = 0 and at в = 0ait to show the range of equivalence, 
as well as changes from the prior means.
One might calculate key posterior probabilities for the skeptic and enthusiast. 
Here, smaller hazard ratios indicate improvement by the treatment over the control. 
The skeptic would now assign probabilities to regions of 0, such as P(0 > 0 | 
data) = 0.093, P(0 < 0ait | data) = 0.018, and P(0ait > 0 < 0 | data) = 0.889. 
The enthusiast’s corresponding posterior probabilities are P(0 > 0 | data) = 0.098, 
P(6 < 0ait I data) = 0.098 and P(0ait > 0 < 0 | data) = 0.885.
Figure 13.3 shows the likelihood function and the two posterior densities. The 
posterior distributions for the enthusiast and the skeptic are fairly close to each 
other now. Although there is strong evidence that the hazard ratio is less than 1, 
it seems that the estimated treatment effect is in the range of equivalence (0a|t, 0). 
In fact, the posterior probabilities that 0 lies in this range are 0.89 for the skeptic 
and 0.88 for the enthusiast. Given the large sample size, it seems unlikely that the 
study will find that the log hazard ratio is less than 0ait. A data safety monitoring 
committee might want to consider stopping the study rather than continuing it at 
this point. The study should probably close.
13.7 Response-Adaptive Randomization
A major reason for designing clinical trials with early stopping rules is the ethi­
cal concern that the wider patient population—including patients yet to enroll in 
the study—should benefit from newer and improved therapies as soon as the im­
provement has been demonstrated in well-designed clinical trials. Likewise, policy­
makers should withdraw ineffective therapies from clinical practice. One can ex­
pand on this viewpoint by arguing that patients entering the study should benefit

Clinical Trial Designt
417
FIGURE 13.3: Posterior densities for the skeptic and enthusiast. Vertical lines show 
the range of equivalence.
from the knowledge already gained about the relative benefits of the treatments 
under study. That is, if the accumulating evidence suggests that one treatment 
may actually be superior to the other or others in the trial, then why not give the 
better-performing treatment to incoming patients? One way to achieve this prefer­
ential treatment assignment is by adapting the randomization probabilities to favor 
the better-performing treatments. Such considerations have given rise to so-called 
play-the-winner rules [360], biased-coin or Polya urn schemes [348, 349], and other 
implementations of response-based adaptive randomization. A related problem of 
adapting choices over time to increase one’s reward is often called the multi-armed 
bandit problem [38, 145].
A particularly important randomized trial that used an urn-based adaptive 
randomization method was the ECMO trial of Bartlett et al. [18] reported in 1985. 
The basis of the randomization is an imaginary urn that contains balls marked 
for the different treatments. In this study, some balls would be marked “ECMO” 
and the others would be marked, say, “control.” The randomization scheme called 
for randomly drawing a ball from the urn, assigning the associated treatment to 

418
Bayesian Thinking in Biostatistics
the patient. The ball would return to the urn. If the patient survived, another ball 
for the assigned treatment would go into the urn. If the patient died, a ball that 
corresponds to the other treatment would go into the urn.
When the trial began, the imaginary urn contained just two balls, one ball for 
“ECMO” and one ball for the standard of care. The first treatment assignment was 
to ECMO. The neonate lived, so the urn now contained three balls, two for ECMO 
and one for the control. The second baby received the control treatment and died. 
After the first two participants, the imaginary urn contained four ECMO balls and 
only one control ball, since the control patient died but the ECMO baby lived. All 
subsequent assignments were to ECMO, and each of these babies lived. The trial 
ended with nine babies assigned to ECMO—all of whom survived—and just one 
baby assigned to the standard of care who unfortunately died.
The particular implementation of an adaptive randomization method in this 
ECMO trial of neonates reached a conclusion that failed to convince a large number 
of pediatricians and led to subsequent trials of this treatment [255, 110]. Some 
interesting discussion of the statistical and ethical issues relating to this example 
appeared in the journal Statistical Science in papers by Ware in 1989 and Royall 
in 1991, with associated discussion [277, 344].
Perhaps because of the controversy that surrounded the ECMO trials or for 
other reasons, response-adaptive designs did not find much application in clinical 
trials until the end of the twentieth century. The ASTIN study was a particularly 
interesting study that combined adaptive dose finding within a randomized clinical 
trial [208]. The statistical details of this study can be found in Berry et al. [40]. 
Response-based adaptive randomization now enjoys fairly widespread interest.
There are several ways that one may determine randomization probabilities 
to adapt to accruing information about treatments and their associated clinical 
outcomes. Generally, one will choose some clinical outcome measure that is relevant 
for comparing the treatments under evaluation. The randomization probabilities 
will be functions of this outcome measure.
For example, suppose that there is a binary measure of clinical relevance, such as 
tumor shrinkage beyond some threshold percentage of baseline or the eradication of 
symptoms. Furthermore, let us consider a study that is comparing a new treatment 
to a standard of care. We might want to base randomization probabilities on the 
probability that the new treatment provides a better outcome than the standard 
of care. A simple implementation of response-adaptive randomization would assign 
a patient to the new treatment (A) with probability P(A > В | Z>t), where Dt 
represents the data up to time t, the time the patient enters the study. That is, 
we allocate patients to a treatment according to the posterior probability that the 
particular treatment is better than the other one.
The literature contains different proposals for relating the function P(A > В | 
Dt) to a measure of clinical benefit. For example, suppose that one is using a binary 
clinical endpoint. Let pj be the probability of clinical success with treatment j (j = 
0.1). with the control being denoted by j = 0. One may then use P(pi > p0 | Dt) 
for the probability of assigning a patient to the new treatment (and 1 minus this 
posterior probability as the probability of assignment to the control treatment).

Clinical Trial Designi
-119
Suppose instead that one wishes to use a time-to-event endpoint, such as sur­
vival, for evaluating the benefit of each treatment under study. One might consider 
using the median survival in the randomization probability in place of the probab­
ility of success (pj). That is, if m.j is the median survival for treatment j (J = 0.1). 
then one might assign a patient to the new treatment with probability equal to 
P(mi > mo | Dt). If one assumes that the failure times follow an exponential dis­
tribution with rate parameter A and that the prior distribution for A is Ga(a.b). 
then the posterior distribution for A is also gamma, as we show in Chapter 3. Fur­
thermore, using the theory for transformations of random variables, if A ~ Gn(o. b). 
then m = ln(2)/A ~ InvGa(a, b'), where b' = ln(2)/b.
Recalling the issues that arose around the urn sampling-based treatment al­
location in the ECMO trial mentioned earlier in this section, we generally prefer 
postponing modifying randomization probabilities until after the trial has accrued 
and treated several patients. If the trial adapts the randomization probabilities at 
the start of the trial, one will run the risk of assigning a larger number of patients 
to the inferior treatment [315, 347]. This unexpected outcome may occur because 
the posterior probability estimates are relatively unstable early in the study, espe­
cially if one starts with a fairly diffuse prior distribution for the treatment effects. 
Maintaining equal randomization for a while reduces this risk [347].
Aside from waiting until one has information on some minimum number of 
patients before changing from equal randomization to an allocation ratio that favors 
the better-performing treatment, one may consider approaches that smooth the 
randomization probabilities to make them more stable, especially early in the study. 
That is, one can modify the probabilities in a way that alters how quickly they 
react to accruing data. This attenuation can be accomplished by picking a constant 
0 < 7 < 1 and randomizing a patient who enters the study at time t to the new 
treatment with probability
„ 
=____________(P(Trt, > Trip |Д,)р___________
,W (P(Trip > Tri, I Dt)]y + {P(Trt[ > Trto I £!,)}•<' k 1
The function (t) will lead to equal randomization if 7 = 0. Randomization will 
adapt completely to the relative clinical benefit if 7 = 1. When there are only two 
treatments, Ri(t) = 0.5 whenever P(Trti > Trto | Dt) = 0.5.
One may also wish to let the exponent 7 change as more patients enter the 
study. That is, we want greater stability in the randomization probabilities (i.e., 
less wild variation) early in the trial, when data from relatively few patients are 
available. As more patients enter the trial and contribute outcome information, 
we will be willing to allow full adaptive randomization. Thall and Wathen [322] 
proposed making the exponent a function of the current and final sample sizes. 
That is, the exponent will increase as the accrual gets closer to the target sample 
size. The specific suggestion is that if n patients have entered the trial at time t, 
the exponent in the random allocation function becomes 7(4, n) = n/27V, where N 
is the target sample size. Early in the trial, there will be very few patients, and 
n/27V will be close to zero. As more patients provide outcome data, the exponent 
approaches 1/2.

420
Bayesian Thinking in Biostatistics
The use of the attenuation factor 7 (or some function 7(t,n)) is not particu­
larly Bayesian. In effect, this approach is discounting the posterior distribution. 
For a Bayesian, the posterior distribution summarizes the person’s knowledge or 
uncertainty in light of available information and data. Because the attenuation fac­
tor’s role is to keep the randomization probabilities from changing too quickly in 
an attempt to mitigate potential concerns by frequentists, particularly by slowing 
decision-making to improve frequentist operating characteristics, we call the use of 
7 a stylized Bayesian design.
If the trial is evaluating three or more treatments, then there are two primary 
ways one may adapt randomization probabilities to favor the better-performing 
treatments. One approach makes the randomization probabilities a function of the 
posterior probability that each treatment is the best performer among the treat­
ments under evaluation. The other approach either chooses a fixed threshold value 
for each treatment to surpass or considers one of the treatments to be the standard 
that the remaining treatments need to beat.
Suppose that the clinical outcome is binary (e.g., response to treatment) and 
that the probability of response with any new treatment would have to be at least p*  
to be considered worth further investigation. If the trial is evaluating J treatments, 
we might make the randomization probability for treatment j
т = (P(PJ>P-IJ,)P 
J
Note that the function rj may include the exponent 7 as an attenuation factor as 
discussed earlier in this section.
If one of the J treatments is a standard therapy that serves as a control in 
the study, then one can easily modify the allocation probabilities Vj. Let pi be 
the response probability associated with the control therapy. One might set the 
probability of randomizing a patient to treatment j to
№>P,IP,)P 
ELi{^to>PilA)P
We might set P(pi > pi | £)t) = 0.5.
Yuan et al. [357] pointed out some problems with this randomization function 
when there is a control treatment among the therapies under evaluation. One prob­
lem is that the randomization probability for the control treatment arm will never 
drop below 0.2 no matter how much better the other treatments are performing. 
Another problem is that the randomization probabilities may be sensitive to which 
of the treatments one sets as the control. Consider a trial with three treatments, 
with the arm labeled 1 the control therapy and the other two treatments the new 
ones. Suppose that the control and one of the new treatments have the same prob­
ability of response and that treatment 3 is inferior to these two treatments (i.e., 
Pi = p-2 and рз < pi = p2). In such a situation, the randomization probability for 
the control treatment will be greater than for arm 2, on average, even though they 
are equally effective. That is. r\ > r?. even though pi = p2.

Clinical Trial Designs
121
A related problem occurs when the control treatment is considerably worse 
than the other treatments. Again, suppose the trial is evaluating three treatments 
and that we label the control treatment with the number 1. If the probability 
of response with the control is much lower than it is for the two new treat­
ments. then the randomization probabilities for treatments 2 and 3 will be the 
same (or close to the same), even when their respective response probabilities are 
considerably different. For example, suppose the true response probabilities are 
Pi = 0.20, p2 = 0.70, рз = 0.85 for the control and two new treatments. On 
average, the randomization probabilities will be rj = 0.20. r-2 = 0.40. 
= 0.40
for the three treatments. Yuan and Yin [358] propose an algorithm that they call 
“moving-average adaptive randomization” to overcome the sensitivity of the ran­
domization probabilities to the treatment label. Note that basing each treatment’s 
randomization probability on the posterior probability that it is the best avoids the 
problem of sensitivity to labeling.
Although we have illustrated outcome-adaptive randomization with examples 
based on trials with binary clinical outcomes, the methods lend themselves to clin­
ical outcomes of any data type. For example, if a trial is evaluating treatments for 
hypertension, one might consider the mean change in blood pressure from baseline 
as the clinical outcome on which to base treatment allocation probabilities. With 
three or more treatments, one uses the function
TjoeP^pj =max(pi,...,pj) | Dt), j = l,...,J ,
where Pj is the mean change from baseline for treatment j. Similarly, one might 
consider approximating time-to-event distributions with exponential distributions 
and use the means or medians as the measure of clinical benefit for comparison and 
for determining randomization probabilities.
13.8 Recap and Readings
There are many variations of study designs for dose escalation with respect to a 
single outcome and dose finding based on two outcomes. The books by Cheung [71] 
and Yuan et al. [357] provide a more thorough discussion of dose finding designs 
than we could in this chapter. Thall and Cook [316] extend the designs in Section 
13.2.1 in recognition that different pairs of risks of toxicity and efficacy may be 
equally desirable. That is, one may be willing to accept a greater risk of serious 
toxicity in exchange for a greater chance at clinical benefit.
One can find a discussion of Bayesian sample size considerations in several 
papers that appeared in the journal Statistician in 1995. Adcock (1997) reviews 
frequentist and Bayesian methods for determining sample sizes [2].
A major part of Bayesian analysis concerns making decisions. We have touched 
on the basic ideas in this chapter. The books by Lindley (1972), DeGroot (2004), and

422 
Bayesian Thinking in Biostatistics
Parimigiani and Inoue (2009) give a more thorough presentation of this important 
topic [225, 91, 256].
One can apply decision theory to address concerns other than sample size. For 
example, Stroud et al. (2001) discuss the design of a study that sought to learn 
about the pharmacokinetics and pharmacodynamics of an anticancer drug [311]. 
Patients received the drug in the clinic as a three-hour infusion. The complexity 
of the drug’s pharmacokinetics led to the need to draw blood samples long after 
the end of the infusion. As a result, patients would have to stay in the hospital 
overnight, return to the clinic the following day, or remain in the clinic for 24 hours 
or longer. While the study wanted to estimate a pharmacokinetic parameter with 
some precision, the investigators did not want to disrupt patients’ lives. The utility 
function sought to balance the goal of precision against a cost related to drawing a 
blood sample more than 4 hours after the end of the three-hour infusion.
A good summary of Bayesian adaptive designs as of 2011 is contained in Berry 
et al. [41]. A full presentation of adaptive randomization would include discussion 
of the ethical considerations, in addition to the statistical and logistic issues. The 
ethical considerations touch on the generally accepted need for clinical equipoise for 
participation in a randomized clinical trial. One may consider the views of Armitage 
and Bather, expressed in 1985, to get a sense of some of the early differences of 
opinion [10, 11, 19, 20] on the matter of adaptively modifying randomization prob­
abilities in light of accruing information in the trial. Hey et al. (2015) argue against 
adaptively changing randomization probabilities on ethical grounds [163]. Many 
authors provide counterarguments in the discussion that followed that paper.
13.9 Exercises
Exercise 13.1. Suppose that you are designing a phase 1 study. You do not 
know the risk of a dose-limiting toxicity (DLT) and propose starting with a [/(0,1) 
prior for 0(1), the risk of a DLT at dose level 1.
(a) What is the predictive probability that the first patient will experience a DLT? 
(b) Based on the predictive probability of a DLT, does this prior make sense for 
the lowest dose level? (That is, should one even consider treating a patient with 
this dose?)
(c) Suppose that one thinks a priori that the risk of DLT at the first dose level 
is 1/3. What do you think would be a reasonable prior distribution for this dose 
level'?
(d) Find the predictive probability of a DLT using your prior distribution from part 
(c). What do you think of your prior?
Exercise 13.2. Suppose you are the statistician for a phase 1 study of a new 
anti-cancer drug called bumblebine. The trial will base dose escalation decisions on 
the CRM design. Patients will enter the study in cohorts of two. There are five dose 

Clinical Trial Designt
423
levels, shown in Table 13.4. You assume that the prior distribution for the slope 
parameter (a) is log-normal (i.e.. a = e3, в ~ A(0.1.34)).
TABLE 13.4: Table of dose levels, corresponding doses, and prior estimates of DLT 
risk
Dose
Level
Bumblebine dose 
(rag/m2)
Initial estimate 
of DLT risk
1
15.0
0.1
2
17.5
0.2
3
20.0
0.3
4
22.5
0.5
5
25.0
0.6
6
27.5
0.7
(a) 
Modify the code for the CRM on page 388 to use a logistic function (see equation 
(13.1c)) with bo = 3.
(b) 
Find the rescaled doses according to which the logistic function gives the risks 
in the last column of Table 13.4.
(c) 
Suppose the first five patients do not experience a DLT but the sixth patient 
does. (In other words, the first DLT occurs to the second patient who receives dose 
level 3.) Find the posterior distribution of 0 and the slope parameter (a = e3).
(d) 
The seventh patient has enrolled in the study. What dose level should this 
patient receive, based on the CRM algorithm?
Exercise 13.3. In this exercise, you will determine the sample size necessary 
to satisfy the average coverage criterion, namely, find the smallest value of n such 
that a prediction interval of width I has probability 1 - a of containing the mean 
д. The study will evaluate the effect of a new anti-hypertension medication by 
measuring the change in blood pressure after six weeks of therapy. Let yi,..., yn be 
the differences in blood pressure measurements for a sample of n patients. Assume 
yi ~ 7V(/i, cr2), i = 1,... ,n, p | a2 ~ NtWh^/no), and that cr2 is known.
(a) 
Find the formula for the smallest value of the sample size n that will ensure 
that average coverage will be at least 1 — a.
(b) 
Find the sample size when a2 = 50 (a = x/50), the prior sample size (no) is 2, 
and the prediction interval width is I = 10.
(c) 
Now, assume that cr2 is unknown. We characterize uncertainty about the vari­
ance via cr2 ~ InvGa(a, b), where a = 0.5 and 5=1. What is the required sample 
size now?
Exercise 13.4. You are designing a randomized clinical trial that will compare 
two treatments with respect to a binary endpoint. One treatment is the current 
standard of care and is expected to lead to clinical improvement for 50% of the 

424
Bayesian Thinking in Biostatistics
patients who receive it. The other treatment is a new form of therapy, and the 
investigators would like to develop this therapy further if it provides benefit to at 
least 75% of patients. The study will randomize a total of 100 patients, 50 per 
treatment arm, and the final analysis will be a one-sided Fisher’s exact test with 
a 10% Type 1 error. The investigators would like to include interim analyses for 
futility after treatment response information is available for 40, 60, and 80 patients. 
We assume that the response information is available quickly. The investigators feel 
fairly certain about the expected response rate with the standard therapy, based 
on data from 400 patients. They are less certain about the response to treatment 
for patients who receive the new treatment. Thus far, they have treated 20 patients 
with the new treatment, and 14 of the 20 patients responded to the treatment.
(a) 
What prior distribution would you consider for the probability that a patient 
responds if given the standard of care, based on the historical data?
(b) 
What prior distribution would you consider for the new treatment’s response 
probability?
(c) 
Using 1,000 simulations, what do you determine to be the probability that the 
study would stop for futility if the response probabilities for the two treatments are 
equal to 50%?
(d) 
In part (c), what is the average number of patients who enter the study?
(e) 
Using 1,000 simulations, what do you determine to be the probability that the 
study would stop for futility if the response probability for the new treatment is 
75%, while for the standard it is 50%?
(f) 
What is the average number of patients enrolled in the study in part (e)?
(g) 
Do your estimates of the study’s operating characteristics (parts (c)-(f)) seem 
appropriate to you?
Exercise 13.5. You have designed a phase 2 study that will enroll a maximum 
of 30 patients. Suppose the analysis prior for the probability a patient responds 
(0) is Be(2,3), corresponding to a prior mean probability of response equal to 40% 
and a 95% probability interval of (0.068,0.806). The criterion for deciding that the 
treatment demonstrates sufficient clinical activity to warrant further study is that 
the posterior probability that the response probability is greater than 0.33 is 75% or 
more. That is, we conclude in favor of the treatment if P(0 > 0.33 | Data) > 0.75. 
After treating 20 patients, the investigators note that four patients responded.
(a) 
What is the predictive probability that there will be a total of five patients who 
respond after the study finishes enrollment and treats 30 patients?
(b) 
Compute the predictive probability of five responses in 30 patients if the “true” 
underlying probability of response is 0.2. 0.3, 0.4, and 0.5, conditional on four 
responders among the first 20 patients.
(c) 
Calculate the criterion in favor of the new treatment for n = 30, 50. and 100. 
That is. determine P(0 > 0.33 | Data) > 0.75 when the trial will enroll a total of 
30. 50. and 100 patients, conditional on four responders among the first 20 patients. 
You may assume that the “true” underlying probability of response equals 0.4.
(d) 
Should the trial stop after enrolling 30 patients or continue to enroll more 
patients? If more patients. 50 or 100? Explain your decision.

Clinical Trial Design»
EXERCISE 13.6. You are designing a randomized controlled trial with interim 
analyses to evaluate a new treatment for cancer. The trial will compare a new 
therapy to the current standard of care, with the latter being the control. You will 
use skeptical and enthusiastic priors in the trial design to guide interim decision­
making. The primary endpoint is survival. The control therapy is associated with a 
one-year survival probability of 65%. For clinicians to want to use the new therapy, 
one-year survival probability will have to increase to 75% or more. We will assume 
that the distribution of survival times is exponential with hazard rates Ao for the 
control and Ai for the treatment. Furthermore, we will assume that the logarithm 
of the hazard ratio (0) is normally distributed.
(a) 
Find the hazard ratio (control divided by new treatment), assuming that the 
new treatment achieves the minimal hazard rate (75%). Also, find the log of the 
hazard ratio (0ait)-
(b) 
We now want to determine an appropriate skeptical prior as in Section 13.6. 
The skeptic’s prior mean is 0. We determine the standard deviation of the prior 
distribution based on the skeptical prior having just 5% probability that в > 0a\t. 
Assuming that в has a normal distribution and using the value of 0ajt from part (a) 
of this problem, find the standard deviation for the skeptical prior distribution.
(c) 
Assume that the enthusiastic prior is centered at 0ait and places 10% probab­
ility on the region в < 0. Find the standard deviation of this enthusiastic prior 
distribution.
(d) 
The first interim analysis occurs when there are 100 events out of a planned 250 
events. At this time, the estimate of the logarithm of the hazard ratio is в = -0.288. 
Find the corresponding normal likelihood and plot it.
(e) 
Find the skeptic’s posterior distribution and the enthusiast’s posterior distri­
bution. Plot the respective densities on the same graph. Plot the likelihood on the 
same graph with the posterior distributions.
(f) 
Compute the posterior probability P(0 < 0ац | data) for the skeptic and for the 
enthusiast. Do you think the study should continue?
Exercise 13.7. Consider a randomized clinical trial that is comparing two treat­
ments with respect to times to failure. Assuming that the failure times follow an 
exponential distribution, we will set up response-adaptive randomization for this 
study. Let Ло and Ai be the hazard rates for the control and experimental therapies, 
respectively. Randomization probabilities will be equal to F(/xi > до I data), where 
the mean д, = 1/A,. We could also use the median, which is the more common 
measure of a distribution of failure times. Letting m, be the median time to failure 
with treatment i = 0,1, we have m, = 1п(2)/Л, = 1п(2)д,. Then the randomiza­
tion probabilities could be based on the posterior medians of the treatment-specific 
median time to failure.
(a) 
If Y | Л ~ Exp(X) and Л ~ Ga(a,b), then д = Е[У] = 1/Л. Show that 
p. ~ InvGa(a,b). Furthermore, since the median, m = ln(2)/A, show that m ~ 
InvGa(a, ln(2)f>).
(b) 
Suppose that a previous clinical study provided an estimate of the median time 

426 
Bayesian Thinking in Biostatistics
to failure for the control treatment mo = 26 weeks. Furthermore, the investig­
ators are 95% certain that the median time to failure is less than 52 weeks. Find 
an informed prior distribution for mo and mi based on this information and the 
assumption that the two priors are the same.
(c) 
Suppose that the study has enrolled 40 patients in 1 year at a rate of one 
patient every week. Furthermore, suppose that at 1 year there were 12 failures 
among patients randomized to the control treatment and nine failures among the 
experimental treatment patients. The total follow-up times for the two treatments 
are 182.3 for the control group and 322.97 for the experimental treatment. Find 
the posterior distribution for each treatment’s median time to failure (mo and mJ 
at this interim analysis. Also, find the posterior distribution of the hazard rate for 
each treatment group.
(d) 
Using the posterior means of the treatment-specific median time to failure, 
determine the randomization probabilities if there is no discounting, that is, 7 = 1 
in equation (13.13).

Chapter 14
Hierarchical Models and Longitudinal Data
This chapter considers models that have additional complexity beyond those that 
we have already considered. In all the chapters that considered regression model­
ing, there was a presumption that important predictor variables were taken into 
account. Indeed, when designing a study to assess the importance of various pre­
dictor variables on a response variable of interest, scientists will do their best to 
include those variables that they deem important and they are able to measure. 
There will be situations, however, where this has been done and where it is also 
suggested that there may be some other factors that (i) were not taken into account 
and perhaps should have been, (ii) are difficult to measure and are consequently 
left out of the model, or (iii) are perhaps even impossible to measure. With a slight 
abuse of the term, we refer to such variables as latent. Strictly, the word “latent” 
implies that such variables are unobservable. Here we extend this interpretation 
to mean that they are unobservable or unobserved (perhaps due to some form of 
scientific oversight). This chapter focuses on extending previous models to allow for 
latent variables.
Generically, we have data y, latent variables 7, and a collection of parameters, 
0. We pose a model for the data given the parameters and latents, p(y | 0,7), a 
model for the latents, p(7 | 0), and a prior distribution, p(0). This leads to a joint 
distribution (probability density function)
Р(у,7,0) = Р(У I M)p(7 I ^)p(^),
from which it is possible to obtain the joint pdf for unknown and uncertain (0,7), 
p(0>7 12/) ocp(!/.7>^).
with у regarded as fixed and equal to the observed data. In theory, we can obtain 
the marginals p(0 | y) = J p(0,7 | y)dy and p(7 | y) = f p(0, у | y)d0. The model 
as described thus far is a generic version of a two-level hierarchical model for the 
data, with a third level corresponding to the prior. Such models are also termed 
multilevel models.
If we have a vector of future data, z, with model p(z | 0,y,y), where we do 
not necessarily assume that Z is independent of Y conditional on (0,7), then the 
predictive density is defined as
p(z I y) = Jp(z I 0,7,y)p(0,7 I y)d0dy.
Theoretically, it is quite simple to make a full range of statistical inferences based on
427

428
Bayesian Thinking in Biostatistics
this model. It is often simple in practice, as well, provided we are able to iteratively 
sample from the conditional distributions
P(0 I 7, iO, P(7 I d, 7/), p(z | 0, ъ y).
This basic structure underlies the rest of this chapter, wherein we illustrate such 
inferential models across a number of very important areas of statistical modeling.
In the next section, we motivate and, by example, illustrate the concept of 
hierarchical modeling. Next, we discuss applications of hierarchical structures to 
regression modeling. In the literature, such models are termed “mixed models,” 
because of the addition of latent (random) effects to standard regression models. We 
then discuss the important topic of longitudinal and correlated data modeling. In 
addition, we use the same hierarchical modeling structure to handle meta-analysis. 
Meta-analysis infers a common effect across a finite number of studies that were 
designed separately but with the same purpose in mind. For example, one may 
posit a general model in which each study assessed the effectiveness of a particular 
drug for treating a particular disease. The essence of a meta-analysis is to combine 
information from similar studies to make an overall inference about the effectiveness 
of the treatment.
14.1 Normal Hierarchical Models
We begin with some simple illustrations of models for normally distributed data 
that involve latent variables. We then give the basic structure of such models.
14.1.1 Simple Examples
Example 14.1. Conception Data. We consider a data set that was given in 
the classic applied statistics book by Snedecor and Cochran (1967) [299, Example 
10.18.1]. The data are percentages of successful artificial inseminations in cows for 
six bulls. For bull i, щ series of semen samples were sent out and the percentage of 
conceptions was determined for each series. Let yij be the percentage of conceptions 
in scries j for bull i. The data are given in Table 14.1. Observe that we also give 
the sample means for each bull as & = Уц/щ.
Snedecor and Cochran consider the following model for these data:
| <т2.7г JL N(7n<r2) and 1 A’^,^).
Observations for different bulls are assumed independent. Observations within bulls 
would be conditionally independent if the bulls’ means were known. The bull­
specific means are modeled with their own normal distributions, so within-bull 
observations are exchangeable. With this model, we assume that bull-specific mean 
percentages are a random sample from a population with mean p, and standard 
deviation In our new terminology, the model assumes that the underlying mean

Hierarchical Models and Longitudinal Data
■129
TABLE 14.1: Conception data
Bull
Percentages of conceptions
Hi
Ui
1
46, 31, 37, 62, 30
5
41.2
2
70, 59
9
64.5
3
52, 44, 57, 40, 67, 64. 70
7
56.3
4
47, 21, 70, 46, 14
5
39.6
5
42, 64, 50, 69, 77, 81, 87
67.1
6
35, 68, 59, 38, 57, 76, 57, 76, 57. 29, 60
9
53.2
responses for different bulls are latent and vary from bull to bull. The model also 
implicitly presumes that there are other bulls in the population (but not in our 
sample) that also have means that vary around the unknown value д. The assump­
tion of a normal distribution for the means is common but somewhat arbitrary. We 
discuss this issue later.
There are two types of variability in these data that are of interest, the within- 
bull variability, measured by a, and the between-bull variability, measured by ay. 
If ay = 0, then there are no differences among bulls, since in this case the mean 
percentages for all bulls would be close to the same value д. On the other hand, if a 
is small and ay is large, the implication is that some bulls reliably have percentages 
above д and others reliably below д.
We proceed to analyze these data with proper reference priors. We consider 
д ~ [7(0,100), a ~ C7(0,100), and ay ~ [7(0,100), all independent. These are 
extremely diffuse priors. Since percentages are all in (0,100), there would be no 
point in allowing for д to take values outside of this interval. Similarly, it would 
be impossible for the standard deviations to take values outside this interval. It is 
important that the prior for a7 be a proper prior. We discuss this issue later.
Table 14.2 gives output for the analysis. Inferences relate to the latent mean 
variables, the overall mean, and the two standard deviations along with their ratio. 
Statistical literature may refer to inferences for the latent means as predictions, 
since the 7$ are not regarded as parameters in the traditional sense. It is clear that 
ay / 0, which means that there are differences in the latent means. The estimated 
standard deviations are of the same order of magnitude, though the 95% probability 
interval for the ratio has an upper limit of 2.2, implying that ay could be as large 
as 2a.
The overall average, д, is estimated to be about 54% with 95% PI (40.5,68.1). 
Since the model for the 7, centered them on д, it is not surprising that the pre­
dicted 7i range from 45.1 to 63.1. Notice that the predicted values below 0.54 are all 
greater than the corresponding sample mean values in Table 14.1, and the predicted 
values above 0.54 are all less than their corresponding sample means. For example, 
the sample means are 39.6 and 67.1 for bulls 4 and 5, respectively, and the corre­
sponding predicted means are 45.1 and 63.1. These differences are due to the fact 
that the predictions from this model are shrunk from the sample means towards

430 
Bayesian Thinking in Biostatistics
TABLE 14.2: Analysis of conception data with diffuse proper prior
Post. med.
(95% PI)
54.3
(40.5,68.1)
71
46.1
(32.0,58.6)
72
58.4
(43.2,77.4)
73
55.7
(45.3,66.5)
74
45.1
(30.8,58.0)
75
63.1
(51.6,75.2)
76
57.0
(47.7,66.9)
a
16.1
(12.5,21.4)
10.9
(1.5,34.5)
0.68
(0.08,2.2)
their overall average. We call this the “shrinkage” effect, which plays a large role 
in Bayesian statistics. We introduced this concept in Chapter 3 and address this 
effect theoretically in Exercise 14.4.
As a final note in this example, we observe that the predicted percentage of 
conceptions for bull 5 is 0.63 and for bull 4 is 0.45. The 95% PI for the ratio 75/74 
is 1.4 (0.99, 2.2), and the predictive probability that the ratio exceeds 1 is 0.964. This 
is reasonable evidence in favor of the hypothesis that bull 5 is more productive than 
bull 4. We considered several other diffuse proper priors and results were practically 
the same. We also ran several chains and checked for convergence. There were no 
convergence issues. The code for this analysis is in files named Chl4-Conception 
on the book’s website.
Example 14.2. Rat Data. We now consider a data set that was analyzed in 
Gelfand et al. (1990) [130]. The data consist of weights (in grams) of 30 rats at 1, 
2, 3, 4, and 5 weeks after birth. The goal is to model each rat’s weight over this 
time period as a linear function of weeks since birth. Since weight measurements 
are taken on the same rat over the five-week period, one might expect that there 
will be individual rat characteristics that might result in higher or lower intercepts 
and slopes across the rats.
Wc consider the following model. Let yij be the weight measurement on the 
ith rat in the jth week. Let Xj take on the values (—2, -1,0,1,2), where we have 
subtracted 3 (the midpoint) from the actual numbers of weeks. Thus Xj = -2 
corresponds to week 1, Xj =0 corresponds to week 3, etc. We have thus centered 
the actual covariate to have a mean 0, which will help to stabilize inferences. The 
statistical model is
I 7i.(72 X А(711+72la,-j,CT2) and 7i = X N2(&, E7), 
\7i2/
where 3' = (Jb 32) and is a diagonal matrix with components (<727,<727) on the 
diagonals. This model assumes that every rat has its own intercept and slope and

Hierarchical Models and Longitudinal Data
•131
FIGURE 14.1: Plot of predicted growth curves for four rats plus an “average” rat 
(solid curve).
that these intercepts and slopes vary around an overall intercept /31 and slope 02. If 
= 0, the model says that all slopes are approximately fa-, similarly, if ai7 = 0, 
all intercepts are approximately the same. If both standard deviations are close to 
0, then all rats have approximately the same intercept and slope, or in other words, 
approximately the same growth curve.
Our main interest in this example is to make inferences about the average growth 
curve + fax for x € (—2, —1,0,1,2) and to assess how much variability there is 
in growth curves among rats in terms of slopes and intercepts. We also might be 
interested in making predictive inferences about a new rat. What would we expect 
that curve to look like?
In Table 14.3, we have given posterior medians and 95% Pls for the components 
of 0, several 7, and for a and E7. It is clear that the intercepts’ and slopes’ standard 
deviations are not close to zero and that there is considerably more variability 
among intercepts them there is among slopes. In Figure 14.1, we have plotted several 
predicted growth profiles for rats in the data, plus the estimated average growth 
profile, 0! + 02x, which is plotted with a solid line. This line is identical to the 
predicted curve for a new rat, say rat 31. Predictions for a new rat are the same as 
the estimates of the average weights at each time point among all rats. Probability 
intervals at each of the five points on the curve are wider if predicting an actual set 
of five future measurements on a new rat, say {j/31 j ■ j = 1,..., 5} than they will

432
Bayesian Thinking in Biostatistics
TABLE 14.3: Analysis of rat data with diffuse proper prior
Post. med.
(95 % PI)
/5i
242.6
(237.0,248.1)
/52
43.3
(41.8,44.8)
7ii
239.9
(234.6,245.2)
721
247.8
(242.5,253.2)
731
252.5
(247.1,257.7)
712
42.5
(39.0,45.8)
722
49.5
(45.9,53.0)
732
45.4
(42.1,48.8)
a
6.1
(5.3,7.1)
Gig
14.6
(11.4,19.7)
Olg
3.7
(2.6,5.2)
be for predicting 71,31 +72,31 z (the predicted weight trajectory), and these intervals 
will be wider than those corresponding to the average, /3i + fax. The extra width 
comes from the variation of a rat’s observed weight from its model-predicted weight. 
The predicted growth curves for rats literally vary around the growth curve that 
corresponds to the overall average.
In the analysis, we used very diffuse proper priors for all parameters. We used 
[/(0,200) priors for all three standard deviations and /7(0,105) priors for the com­
ponents of /3. All Markov chains converged immediately. The code used and the 
data are given in files on the book’s website that include Chl4-rat in the name.
14.1.2 Basics for Two-Level and Three-Level Models for the Data
We now write these models using a generic notation. Let Yij be a random variable 
corresponding to an observation. The double subscripts may indicate that this ob­
servation is the jth measurement made on the ith experimental unit. For example, 
there may be repeated observations on a person over time, and is the measure­
ment made at time tij, as was the case with the rat data. Alternatively, there may 
be multiple biopsies of a patient’s tumor, and Y^ is the J th biopsy’s result. In this 
instance, the biopsy measurements are said to be clustered within patient.
We can add another level by considering continuous patient outcomes after 
hospitalization. Consider the structure where there are patients who are treated 
by physicians who are associated with particular hospitals. We may let yijfc be the 
outcome for patient к, who is being treated by physician j who is associated with 
hospital i. Suppose that there are H hospitals involved, щ physicians associated 
with hospital Л and physician j in hospital i has patients. In addition to this 
structure, there could be vectors of predictor variables associated with hospital i, 
say v, (i = 1.........Я). predictor variable vectors that are associated with physician
j in hospital i (say u’ij). and vectors of patient characteristics. Xijk- Predictors in 
.r,jK- could indicate the particular treatment that the patient receives, the patient’s 

Hierarchical Models and Longitudinal Data
133
overall quality of health, age, blood pressure, etc. At the physician level, years of 
experience in their specialty is one possible covariate. At the hospital level, there 
may be quantitative factors available that pertain to the quality of care. Any model 
that corresponds to this structure would have at least three levels plus a level 
corresponding to the priors on parameters. At the top level there would be a latent 
hospital variable (or variables), at the next level there would be a latent physician 
variable (or variables), and at the third level there would be a model for the data 
that depends on predictor and latent variables.
We could make this even more interesting by observing perhaps multiple hos­
pitalizations that resulted in observations, The subscript I corresponds to the 
Zth hospitalization for this patient. In this case, we could have covariatcs xtjki for 
patient к of physician j in hospital i at hospitalization I, covariates for physician 
j at hospitalization /, and covariates Wu for hospital i at the time of hospitaliza­
tion I, since all predictor variables could change from one hospitalization to the 
next. In addition, more latent variables could be added to model specific types of 
correlation structures for repeated observations on the same patient. For example, 
if two hospitalizations are a month apart, one might expect greater similarity in 
responses than if they were 2 years apart. This type of situation suggested adding 
autoregressive structure to the model. Having said all of this, we refrain for now 
from specifying a specific model for such a complicated scenario and instead specify 
a simpler one. A point we wish to make is that the number of levels of the hier­
archy, as implied through subscripts, is limited only by what makes sense for the 
problem at hand. We do need to point out the awkwardness of this notation when 
programming for data analysis. Different notation is often required.
We begin with two subscripts. For concreteness, let index i refer to hospital i 
and index к to patient к in hospital i. We allow for hospital-level and patient-level 
covariates, as well as for latent hospital-level intercepts. The model is
Yik | 
± N(xncP + 7i,a2),
7, | 0 ± ЛГ(и,5,а2).
We have modeled the effect of patient-level covariates as XikP = Pi + xua&2 4- • • • 4- 
XikpPp, assuming that there are p — 1 patient-level predictor variables, and hospital 
covariates as Vi& = vn&i 4- ... 4- viq6q if there are q hospital-level covariates. Note 
that there is already an intercept in /3, so we must not include intercepts for hos­
pital (or physician) regression effects. We specify the prior p(0) = p(/3,<5,a2,a2) = 
р(/3,<5)р(<т2)р(<т2), where for the moment we imagine proper reference priors for 
each.
An equivalent model specification for the data is
Yilc | 7?,0 JL N(xikP + vt6 4- 7Г-^2). 
(
7*  I 0 ± W(0,a2). 
(
Both models have a latent effect for hospital, but one (equation (14.1)) is centered 
on the regression effect involving hospital predictors (v<5), and the other is centered 
on zero. Therefore, 7$ and 7? have different meanings. Nonetheless, the two models 

434
Bayesian Thinking in Biostatistics
for the data are indeed equivalent. The reason is that the marginal density of 
the data after integrating out the latent effects from the joint density, namely 
Р(У I 0) = f p{Vi 7 I 0)^7, is precisely the same using either representation.
In the absence of predictor variables, and where, in our notation, hospitals would 
be regarded as exchangeable, a classic representation of model (14.1) is
Yij |7i,^2 ~ ^(7j,<72), i = 1,-..,H, j = l,...,7li,
The marginal distribution of all the У^- is identical for all i and J, and the У^ are 
pairwise correlated with fixed i. As in the case previously discussed, predictions for 
the 7i would be shrunk away from the sample means for each hospital towards the 
overall mean, p,, because of the shrinkage effect that arises with models like this.
According to the model specification in (14.3) with known (/z, cr2), if the scientist 
were told the value of 71, the model for (72, • • • ,7h) would not change. Since the 
full hierarchical model allows for dependence among the 7i and since it also implies 
exchangeability, then knowing дц would require the scientist to think that other 7? 
might take similar values. Under this model, it makes no sense to consider specifying 
informative prior information for individual 7i, beyond what might be specified 
about (/z, <r^). If we were to regard the 7i as unknown but not latent effects, each 
with its own (independent) prior distribution, it would be difficult to specify those 
prior distributions for more than a few groups.
We now add a level and consider three indices (i,j, k), with j regarded as physi­
cian j, and к as patient к who is treated by physician j in hospital i. The model 
with covariates and latent effects for hospital and for physician can be represented 
as
Уцк I 7ij, 0,°2 JL N(xijk/3 + 70, <r2),
7ij I 7i,<5,^7-IL N(w0A + 7i,(7?7), 
(14.4)
7i I А,<т|7 X ЛГ(иД<т|7).
In equation (14.4), we have modeled hospital covariates as v-rf, and physician-level 
covariates as w^A = w^jAi + ... + wljr^r if there are r physician-level covariates.
It is possible to write a structurally identical but different version of this model 
by incorporating all covariates into the vector Xijk. Hospital-level covariates are 
included, but they do not vary with (J, k). Physician-level covariates are also in­
cluded. but they do not vary with k. In this instance we can write model (14.4) 
equivalentIv as
' 
У,,к\-^,0,а2 X^Tyrf + 77,a2),
7y I 77.^1, J- 
(14.5)
I X W,^),
where hospital covariates (v,) and physician-level covariates (w,j) have been in­
cluded in Xjjk.
Model (14.4) is called a “centering" model, since latent variables have means 
that are centered on their corresponding linear covariate effects. Gelfand and Sahu 

Hierarchical Models and Longitudinal Data
■135
(1995) [131] have argued that centered hierarchical models may have better con­
vergence properties than uncentered models like (14.5).
We could, of course, keep adding levels. Once the basic two level and three- level 
models have been understood, however, one can imagine how to extend to higher 
levels. In Section 14.3.1, we discuss adding one more level to model (14.4).
Also, as in Example 14.2, any of the above models could include latent effects 
for slopes in addition to the latent effects for intercepts. We rely on the reader to 
be able to adapt models in this section to allow for this type of generalization.
14.1.3 Prior Specification
Until now, we have suggested specifying proper reference priors for all parameters. 
We begin this discussion by specifying proper priors for the parameters (р,ст2,ст2) 
in the simpler model (14.3).
In this model, specifying an informative prior for p should be straightforward, 
since p = E(7i | p, ct7) for all i. We ask our expert to think about the average for 
the population of means. Specifically, we elicit a best guess for p, and, say, the 
95th percentile. The model would specify that p ~ N(po,b), where po is the best 
guess and b is selected to obtain the specified value for the percentile. We have done 
this many times before, so we skip details. The classic diffuse proper prior for p is 
something like a N(0,106) distribution. It could also be a sufficiently wide uniform 
distribution, which we used in the simple examples earlier.
One can specify an informative prior for a in a similar way as done in Chapter 7. 
Here, we think about the 90th percentile for an observation for a hospital that would 
correspond to the average response with mean equal to p, namely po.9 = p 4-1.28 ст. 
We would obtain a best guess for this percentile, say po- We would be thinking that 
90 out of 100 7i would be smaller than po- With po our best guess for p, we obtain 
a best guess for a as сто = (po — Po)/l-28. At this point, we could take a Ga(c,d) 
prior for ст and set the mode equal to ст0 (сто = (c— l)/d), and solve for c = 1 +dcro- 
We could then make the prior diffuse by setting d = 0.001, which results in a large 
variance for the gamma distribution with mode сто.
Alternatively, we could select a maximum value for the 90th percentile, say m. 
We would interpret this to mean that p+ 1.28ct < m with probability 1. Condition­
ing on our best guess for p = po, and assuming our prior inferences for p and ст are 
independent, we obtain virtual certainty that ст < (m — p0)/1.28. We could then 
place a uniform distribution on ст with this upper limit. We leave it as an exercise 
to obtain a fully informative gamma prior for ст.
Specifying an informative prior for ct7 is similar to that for ст. Instead of thinking 
about the 90th percentile of the data outcomes, which is governed by ст, we let 
To.9 = P + 1.28ct7 be the 90th percentile of the distribution of the 7,, which is 
governed by ct7. As before, po is the expert’s best guess for p, and as always, we 
assume that knowledge about p is independent of knowledge about ct7. In addition, 
suppose that, based on scientific input, it is known with virtual certainty that 
To.9 < 7max- Then an appropriate proper diffuse prior for ct7 is [7(0, max) with 
max = (7max -po)/l-28.

436
Bayesian Thinking in Biostatistics
Alternatively, if we let 70 be the expert’s best guess for 70.9, the best guess for 
cr7 would be ffQg = (?o — Mo)/l-28. Now assume that the expert is 95% sure that 
70.9 is less than u. Then we have P(^ 4- 1.28<t7 < и | p = jz0) = 0.95, which is 
equivalent to asserting that P(cr7 < (и — до)/1.28 = cr7) = 0.95. We can then select 
a Ga(e,f) distribution with mode (e - 1)// = cro7 and with 95th percentile <r7 as 
an informative prior for cr7.
We note that if H is small, then estimating the variability in the 7г has to be 
difficult. Imagine trying to estimate a variance with only two or three observations. 
In this instance, no one gets to observe the latent 7г. Yet, we are still attempting 
to estimate the variance. Of course, this is virtually impossible with only a small 
number of the latent variables. The point is that if H is small, the posterior for cr7 
will often look just like the prior. There is no harm in this, but the analyst needs to 
be aware of this possibility when specifying the prior on cr7. A sensitivity analysis 
with respect to the choice of prior for cr7—one that considers all inferences—is 
especially warranted if H is small.
Historically, there has been a tendency to use Ga(0.001,0.001) priors for the 
precisions т = 1/cr2 and r7 = 1/cr2, and an improper flat prior for p. A nice feature 
of this specification is that all the full conditionals for model (14.3) axe recognizable, 
so Gibbs sampling is easy. We do not recommend using an improper prior for r7 
(or cr7), however, since this would result in an improper posterior and posterior 
inferences could be meaningless (Hobert and Casella, 1996, [164]).
The conditionally conjugate prior specification for model (14.3) is
p~N(a,b), r~Ga(c,d), ~ Ga(e,f), 
(14.6)
independently. This means that the full conditionals for each of these are in the 
same family as the prior and, moreover, the full conditionals for the 7< are also 
independent and normal. One can, therefore, easily sample from all posteriors. The 
reader is asked to establish this result in an exercise.
We conclude this section with a brief discussion about prior specification when 
regression coefficients and/or additional latent effects are included in the model. 
Linear regression coefficients can be handled as in Chapter 7, with a flat improper 
prior, with diffuse proper normal priors, or with partial information conditional 
means priors. Here, we make these specifications conditional on thinking about 
experimental units with any latent effects set to their average value. This approach 
corresponds to setting the latent effects equal to zero in the model representation 
(14.2). where we modeled latent effects with mean zero.
For a model with two types of latent effect, consider the illustration with hos­
pitals and physicians. There were standard deviations for two latent effects in that 
example, namely, cri7 and <Т27. We could think about the 90th percentile for each 
of the corresponding latent effect distributions separately in the same way that 
we thought about only one of them above. It is probably easiest to place uniform 
distributions on these standard deviations, with some thought about what the up­
per value should be. The corresponding latent effects are on the scale of the data, 
which helps when selecting the upper limit. For example, if all the values in the 

Hierarchical Models and Longitudinal Data
data are expected to be in the range (0.100), it would be virtually impossible for 
any standard deviation to be larger than 100 (see Exercise 14.8).
14.1.4 Meta-Analysis
Meta-analysis often consists of bringing together data from different sources to help 
produce an overall inference, perhaps to estimate a single effect measure common to 
all studies. The most common examples include meta-analyses of different clinical 
trials evaluating some form of therapy. The meta-analysis brings together the data 
or some summary measures from each of the studies and synthesizes this information 
in a probabilistically coherent way.
By “probabilistically coherent way” we mean to imply that a non-Bayesian ap­
proach to meta-analysis might not be the best way to go. Consider as an example 
the GUSTO randomized clinical trial [323]. GUSTO randomized more than 41,000 
patients to four different thrombolytic treatments. The objective was to determine 
if one treatment strategy improved survival among patients who suffered a myocar­
dial infarction. The analysis of the trial indicated superior survival among patients 
randomized to receive accelerated tissue plasminogen activator (t-PA) given with 
intravenous heparin, compared to the other treatments. Brophy and Joseph (1995) 
[58] examined the evidence in favor of t-PA in the GUSTO trial in light of other 
randomized clinical trials that had been carried out and published by the time the 
GUSTO results appeared in the New England Journal of Medicine [323]. In their 
meta-analysis of the data relating to t-PA, Brophy and Joseph (1995) simply pooled 
the data without taking a hierarchical approach. Subsequently, they reanalyzed the 
data with a hierarchical model [57]. They conclude that accounting for the other 
studies leads to a less optimistic inference regarding the benefit of t-PA.
An important point to remember is that a meta-analysis is an observational 
study, even though the observations may include only randomized clinical trials. 
Each randomized clinical trial may epitomize the science of clinical research, but 
the meta-analysis is, in the end, a random sample of the population of clinical trials 
of the treatment of interest. Thus, meta-analyses are subject to all of the design 
and analysis considerations that one would apply when designing and carrying out 
any observational study.
Why take a hierarchical approach? The advantages for a meta-analysis include 
relaxing the assumption of exchangeability of patients across studies carried out at 
different times and with possibly different populations, the ability to make predic­
tion not just for a future patient but also for a future study [281], and the ability 
to estimate study-specific effects with shrinkage towards the overall mean, to name 
but a few. The data frequently take the form of a summary statistic obtained from 
each study, such as a mean, odds ratio, or relative risk, and the associated estimate 
of uncertainty, such as the standard deviation or standard error.
We give examples of three meta-analyses, one here and two in the binomial 
regression section of this chapter (Section 14.2).
Example 14.3. Intensive Care Unit Study. This example involves data on 14 
clinical trials that study a treatment for decontaminating intensive care unit pa­

438
Bayesian Thinking in Biostatistics
tients’ digestive tracts. We present a similar analysis to that of Christensen et al. 
(2010) [79]. The thought is that the treatment may help prevent lethal infections. 
Each of the clinical trials randomized patients to receive either a combination reg­
imen that consisted of systemic antibiotics plus a topical antibiotic or a control 
therapy. The primary endpoint is mortality, and the main analysis compares the 
risk of death for the treatment groups via the odds ratio. (We discuss odds ratios in 
Chapters 5 and 8.) Our meta-analysis of the 14 trials uses the estimated odds ratios 
from each trial, and our target of inference is the overall or population median odds 
ratio for mortality for the combination regimen relative to the control treatment.
The data у = {yi : i = 1,..., 14} are in the form of empirical log odds ratios 
from the various studies. They are available on the book’s website for this chapter 
in file Chl4-ICU-Metaanalysis.txt. Our sampling model is
Yi\0i,a? ±N(0i,af),
and we assume that erf is known. In our statistical model, is the actual underlying 
log odds ratio for study i. The known af is the estimated standard deviation of yi 
in study i and is, of course, just an approximation. In our meta-analysis, we use 
the latent effects model
| ц,сг2,сг2 X ЛГ(д,а2).
The model characterizes the study-specific log odds ratios as normally distributed 
quantities that vary about an overall mean log odds ratio ц. We specify proper 
reference priors for the two parameters,
д~С7(—2,2) and as~C7(0,2).
This prior specification centers the overall mean log odds ratio at zero and assumes 
that the between-study variance is not very large. The prior for a2 seems reasonable, 
since the scale of the log odds ratios is quite small, as can be seen from the data. As 
stated above, we wish to infer the median odds ratio, eM, across the studies. That 
is, half of the studies’ odds ratios will be less than eM, and half will have odds ratios 
above this central value.
The posterior median odds ratio was = 0.82 with 95% posterior probability 
interval (0.66,1.01). In words, our inference is that the midpoint of our estimated 
odds of death with the combination treatment is around 82% of the odds of dying 
with the control therapy among studies represented by our sample of 14. Further­
more. we are 95% certain that the median value is as low as 2/3 and as high as 
1 (i.e.. the same odds). In fact, our analysis indicates a posterior probability of 
0.965 that the median is less than 1 (lower mortality risk with the combination 
treatment). Our meta-analysis provides fairly strong statistical strength to a claim 
of lower mortality with the combination treatment than with the control.
The estimated odds ratios for the 14 trials are (0.78, 0.77, 0.77, 0.81, 0.82. 
0.81. 0.81. 0.82. 0.83. 0.85, 0.86. 0.88. 0.91, 0.92), which are fairly consistent. The 
estimated value for ag is 0.15 (0.01.0.44). The estimated 20th and 80th percentiles 
of the induced distribution of odds ratios are ем±о.84а9 an(j are estimated to be 
0.72 and 0.94. respectively. This means that we would estimate that about 20% of 

Hierarchical Models and Longitudinal Data
439
odds ratios would be less than 0.72 and another 20% would be above 0.94. We also 
considered an extremely diffuse N(0.1000) prior for // and a 17(0.10) prior for а9. 
The results were virtually identical.
Unfortunately, since the observed data are already in the form of empirical odds 
ratios, there is no hope of saying anything about the probabilities of death with the 
treatments in the studies. So, there is no hope of assessing the practical import of 
the result.
14.2 Hierarchical Binomial Regression Modeling
We now consider binary response data with latent variables. The concepts are 
basically the same as with the normal data modeling that we just discussed, but 
now everything is on a nonlinear scale. The change of scale will have a considerable 
effect on how we elicit priors involving the variability of the latent variables, since 
in the logistic model, for example, these variables are on the logit scale rather than 
on the scale of the data. A different kind of thought process is needed.
As in the normal model case, introducing latent effects introduces correlations 
among Bernoulli observations when appropriate. The latent variables can adjust 
for missing or unknown covariates or predictors that are common to a group of ob­
servations while not fundamentally changing the nature of the statistical inference.
Example 14. 
4. Suppose we sample 100 hospitals and then randomly sample a 
number of patients from each hospital. At the end of each patient’s (non-life­
threatening) stay, we ask them if they were satisfied with their care in the hos­
pital (yes or no). Patient-reported satisfaction is our binary response. In addition, 
we track certain hospital characteristics such as the average number of nursing 
staff per 10 patients and the percentage of physicians who are board certified. We 
also assume that we could include patient variables, such as age and some kind of 
assessment of overall health.
Let Xij denote the vector of covariate information for the jth patient in the ith 
hospital with a 1 in the first slot for the intercept (i.e., x^ = 1, j = 1,... ,m;i = 
1,..., 100). Let уц be the indicator of the satisfaction for patient j in hospital i, 
and let 0ij = Р(уц = 1 | хц). Hospital variables are included in the vector хц, but 
they do not vary with j. The standard logistic regression model
Ytj | Oij ± Bernoulli^), logit(0fj) = x'^/3
allows for the effects of measured hospital and patient characteristics on the prob­
ability of satisfaction for any hospital in the data and also to predict patient satis­
faction for any new hospital for which we have the appropriate covariates.
We may suspect, however, that important hospital variables have been omitted 
because they were too expensive to measure or because they were not considered 

440
Bayesian Thinking in Biostatistics
important. To the extent that these are hospital variables and not patient variables, 
we can accommodate them by incorporating a surrogate, latent hospital effect. 
While there are always multiple ways to write such a model, we write it as
logit(0y) = 7i + 7г J- 
(14.7)
We leave the 1 out of xi:j, resulting in = Xijifa +... + where some of 
the Xijr values correspond to hospital covariates. We have moved the intercept term 
so that we could center the latent effects distribution on it. We could have centered 
the latent effects distribution on the sum of the components of that correspond 
to the intercept and hospital covariate effects. Alternatively, we could have left the 
intercept in х'^/З and set the latent effects’ means to zero. All three representations 
correspond to the same model for the data, but the ones not centered on zero may 
have better Monte Carlo (MC) convergence properties (Gelfand et al. (1995) [131]).
In this model, each hospital is regarded as having been sampled from a pop­
ulation of hospitals. Satisfaction probabilities for patients in each hospital go up 
or down depending on whether 7, is greater than or less than fa. A hospital with 
7i = is regarded as a “typical” hospital in our subsequent discussion involving 
prior specification.
Prediction for a new hospital (denoted by subscript /) with hospital and patient 
covariates x is accomplished by augmenting the existing model. Here, we model
Yf I x,yf,/3 ~ Ber(0f), logit(0z) = 7/ + xfa 
7/ I ^1,^? ~
Monitoring Yf, however, can only result in a point prediction, since it is a Bernoulli 
variable. On the other hand, monitoring Of will give the same result, since it is 
a parameter; one can also provide a 95% PI for Of. The predicted probability of 
satisfaction for a new patient in a new hospital will be the same as the point estimate 
of the proportion of satisfied patients in the new hospital with predictors x, and we 
will have a 95% PI for this proportion.
The variability in the 7$, as measured by cr7, affects the variability in the prob­
abilities of satisfaction for patients. For example, if cr7 = 0, then patients who are 
in hospitals with the same predictor values and who also have the same patient 
predictor values will all have the same estimated probabilities of satisfaction. If cr7 
is large, then there will be considerable variability among these probabilities.
Finally, this model also correlates responses within each hospital. That is, 
{.Vij : i = 1........Ki} are all correlated, while responses from different hospitals
are independent. The fact that all patients from hospital i share the same latent 7$ 
effect induces the correlation.
Our next example involves the analysis of toenail fungus data. We apologize for 
the image this presents, but the problem is real.
Example 14. 
5. Toenail Fungus. Toenail onychomycosis, known as toenail fun­
gus. is fairly common. It can disfigure and sometimes destroy the nail. It may afflict 
between 2% and 18% of people worldwide. Onychomycosis can be caused by several 

Hierarchical Models and Longitudinal Data
441
types of fungi known as dermatophytes, as well as by non-dermatophytic yeasts or 
molds. We consider data from a clinical trial on toenail fungus reported by De 
Backer et al. (1996) [89]. The randomized study compares two oral treatments for 
dermatophyte onychomycosis infection: terbinafine and intraconazole. These are 
well-known commercially available treatments.
Specifically, we consider data on an unpleasant side effect: the degree of separa­
tion of the nail plate from the nail bed. This is scored in four categories (0. absent: 
1, mild; 2, moderate; 3, severe). For the 294 patients in the trial, the response' was 
evaluated at seven visits (approximately in weeks 0, 1. 2, 3, 6. 9. and 12). Tinies 
in the data are given with decimal points, so 0.96 would correspond to 0.96 of a 
week for example. A total of 937 measurements were made on the 146 intraconazole 
(Trti = 0) patients, and 971 measurements were made on 148 terbinafine (Trt, = 1) 
patients. The data were obtained from the pharmaceutical company Novartis at a 
website that no longer exists, but they are available on the book’s website in the 
files for this chapter. The files have toenail in their names.
Following Lesaffre and Spiessens (2001) [219], who also analyzed these data, 
the responses were dichotomized into categories with toenail separation at the time 
either (i) absent or mild, or (ii) moderate or severe. Since there were repeated 
responses on each individual in the sample, they fit a logistic regression model 
with a latent variable for each individual. Specifically, let yij = 1 if individual i 
has moderate or severe toenail separation at time j, and let = 0 otherwise. 
Measurements taken at time 0 precede the application of any treatment, and our 
model needs to reflect this fact. Thus, in the model specification below, we let 
Zij = 0 if Timetj = 0 and = 1 if Timeij / 0. The model is
Yij | Oij JL Ber{0ij),
logit (0O) = 02Trti + ^Timeij 4- ^Trti x Time^ z^ 4- 7Й
for i = 1,..., 294 and j = 1,..., щ < 7. The latent effects, 7i, are centered on the 
intercept, 0i, and are included to allow for correlation among the repeated obser­
vations on the same individual, as well as to account for the possibility that each 
individual may have a biological tendency to have higher (or lower) probabilities of 
moderate or severe toenail separation through time. The z^ enforce that treatment 
effects can only exist after time 0.
Trt is the binary treatment indicator. Time is the visit time as measured in 
four-week periods, which is treated as a continuous covariate although it could also 
be considered a factor with seven levels. The model also includes an interaction, 
Trt x Time, that allows for the possibility that the effect of the treatment could 
be modified by time (effect modification in action).
Let us recall the meaning of the interaction effect using odds ratios. We consider 
two odds ratios, one comparing the effect of treatment for individual i at time 
t2 € {0,1,2,3,6,9,12} and for the same individual at an earlier time tj. We note 
that here, Zi = 1 is synonymous with t > 0. The odds of moderate to severe 
separation at time t for an individual under Trt = 1 are e^2+^3+^4)t+'1'< if t > 0, 

442
Bayesian Thinking in Biostatistics
and the odds of moderate to severe separation at time t for an individual under 
Trt = 0 are eA’*+7<, regardless of the value of t > 0. Thus if t > 0, the odds ratio 
for assessing the effect of treatment (comparing Trt = 1 to Trt = 0) at time t is
OR(t) = e0Mt, t > 0.
If OR(t) > 1, then the probability of moderate to severe separation is greater under 
Trt = 1 than it is under Trt = 0, and vice versa if OR(t) < 1. If /?4 =0, then 
the treatment effect, as measured by the odds ratio (OR(t) = e^2), is the same no 
matter which t one considers, implying no effect modification due to treatment.
Now we consider the case when Zi = 0, which corresponds to time t = 0. Random 
treatment assignments occur at time t = 0. We should have no treatment effect at 
this time, since we can assume that neither treatment has yet been applied. Our 
model with Zi included reflects this fact and implies that the model is constrained to 
have OR(t = 0) = 1, by definition. We point out, in addition, that since a treatment 
effect is anticipated at later times, odds ratios for t > 0 should subsequently be 
different from 1.
We obtain the ratio of odds ratios that assess the treatment effect at time t2 > t\ 
and the treatment effect at time ti > 0:
OR(t2)/OR(ti) =
If t\ = 0 and t > 0, 
OR(t)/OR(0) = e02+04t = OR{t).
So the ratio of odds ratios, which is used to assess effect modification, takes a 
different form if ti = 0 or not. If ti = 0, it reflects the difference in the treatment 
effect from time 0, where there is no effect. If ti > 0, it reflects the change in effect 
for the two times.
Finally, if both treatments are eventually “effective,” one would expect 04 to be 
negative and OR(t2)/OR(ti) to decrease as t2 increases for all ti > 0.
We require priors for 0 = (J3i,02,and cr7. We standardized the continu­
ous variable Time, by subtracting its mean and dividing by the standard deviation:
sTimei = (Timei - ave(Time))/sd(Tzme).
Since Trt is dichotomous, we consider default proper priors 0t X ?V(0,1), as we did 
in Chapter 8 in similar situations. We also specified cr7 ~ £7(0,10). When analyz­
ing the toenail data, we first tried £7(0,4). It became clear that 4 was too small, 
since posterior iterates for cr7 were clearly truncated at the value 4. There was no 
truncation when we used the value 10. We also considered a reference prior (e.g., 
dflatO in the BUGS language) and N(0,2) priors for the 0s as a sensitivity ana­
lysis. In Chapter 8. we thoroughly discussed informative priors for binomial regres­
sion models, and we continue the discussion for handling latent variable parameters 
in the next section.
Posterior output for the toenail study analysis is given in Table 14.4. Observe 
that all of the regression coefficients are negative with high probability; specifically, 

Hierarchical Models and Longitudinal Data
the probabilities are 1, 0.9984. 1, 0.979, respectively. Since 3., < 0 with high pos­
terior probability, the interaction effect is clearly statistically important, and the 
values of OR(t) are expected to decrease as t increases. Posterior medians of OR(t) 
for t 6 (0.5,1,3,5,8) are (0.31,0.24,0.15,0.09,0.007). respectively, which indicates 
clear practical import of the effect modification. The treatment effect is clearly 
decreasing as a function of time from randomization. After half a week from treat­
ment application, the odds of moderate to severe separation under terbinafine is 
estimated to be about one-third of the corresponding odds using intraconazole, in­
dicating that terbinafine is the preferred treatment. As time goes on. the estimated 
OR(t) decreases to 0.007 after 8 weeks, indicating an even greater preference for 
terbinafine.
Table 14.4 also includes posterior medians for ratios of О Rs. These ratios of odds 
ratios tell us how the OR(t)s change relative to 071(0.5); they are decreasing, as we 
indicated earlier that they would, since the OR(t)s are themselves decreasing. This 
information is already well conveyed by simply looking at the estimated OR(t)s. 
Finally, we note that cr7 is estimated to be about 4 with 95% probability interval 
(3.2,4.6). There is not much to say about this variance parameter, except that it is 
clearly not close to zero and thus the latent effects clearly belong in the model.
As for the sensitivity analysis, changing to a AT(0,2) prior did result is small 
changes in inferences. For example, with this prior, the estimate of the interaction 
effect, fa, was -0.51 (-1.11,0.053). Compare this estimate with the result in the 
table, namely, -0.51 (-1.06,0.031). Using a reference prior, we obtained -0.51 
with 95% PI (—1.12,0.10). The posterior probability that /34 < 0 in the latter case 
is 0.95. Such differences are hardly worth mentioning. Other changes to the results 
shown in Table 14.4 were comparable.
Example code using the BUGS language can be found in the files labeled 
Chl5-Toenail-sTime on the book’s website. That file contains the program we 
used to obtain inferences in Table 14.4.
Example 14. 
6. Dairy Cow Abortion Data. Dr. Mark Thurmond and DR. 
Sharon Hietala of the Veterinary School at the University of California, Davis col­
lected data on the outcome abortion (yes or no) of individual cows coming from 
nine herds located in the central valley of California. Prior information was elicited 
from Dr. Thurmond. Let у =■ 1 correspond to “natural abortion,” and у = 0 corre­
spond to no abortion. There are two covariate values for each of the 13,145 cows. 
These are GR (gravidity, the number of previous successful pregnancies) and DO 
(days open, the number of days between the last successful birth and the current 
pregnancy). We expect that higher DOs will correlate with higher probabilities of 
natural abortion, since a longer DO may be a result of a difficult calving for the 
previous birth. We also expect that higher GR will result in lower probability of 
natural abortion. We assume a latent herd effect. The goal is to model the prob­
ability of abortion as a function of the covariates and a latent effect for herd. We 
expect that the effect of DO may be modified by GR, so we include an interaction 
effect.

444 
Bayesian Thinking in Biostatistics
TABLE 14.4: Posterior summaries for the toenail data. OR(t) compares the odds 
of moderate to severe separation for Trt = 1 (terbinafine) to the corresponding 
odds for Trt = 0 (intraconazole), at time t. Independent 7V(0,1) priors for & and 
U(0,10) prior for
Parameter
Posterior median
95% PI
0i (Intercept
-3.1
(-3.8, -2.5)
02 (Trt)
-0.91
(-1.59,-0.24)
03 (Time)
-1.60
(-1.97,-1.28)
04 (Trt x Time)
-0.51
(-1.06,0.031)
3.9
(3.2,4.6)
OR(0.5)
0.31
(0.14,0.72)
OR(1)
0.24
(0.08,0.69)
OR(2)
0.15
(0.03,0.65)
OR(3)
0.09
(0.01,0.65)
OR(5)
0.03
(0.001,0.68)
OR(S)
0.007
(0.00006,0.73)
OR(1)/OR(0.5)
0.78
(0.59,1.02)
OR(2)/OR(0.5)
0.47
(0.20,1.05)
OR(3)/OR(Q.5)
0.02
(0.0003,1.26)
In order to stabilize inferences, we standardized DO and GR as sDO = (DO — 
mean(DO)/sd(D) and sGR = (GR - mean(G.R))/sd(G7?), where mean(PO) = 
115.8, sDO = 59.7, mean(GR) = 3.5, and sGR = 1.5. Now, sDO = 0 corresponds 
to DO = 116 days, and sGR = 0 corresponds to 3.5 previous successful pregnancies, 
which, of course, is not a possibility.
The data are outcomes on Bernoulli random variables for dairy cows in nine 
herds with щ cows in herd г; we write у = {y^ : i = 1,..., fc; j = 1,..., nJ. 
Cow j in herd i has a covariate vector of standardized DO and GR, x'^ = 
(sDOij,sGRij,sDOij x sGRij), where we leave the 1 out. The regression coef­
ficient vector is 0*  = (&,&, Д1)'. The notation reflects the fact that there is no 
intercept in 0*.
 The model involves centering the latent effect, 7г, on the intercept, 
/?i, which should improve MC convergence properties. The model is
YJ I Oij X Ber(Oij), logit(#ij) = 7г + x'^0
*
,
7i | 0i,ay X ?/(/?!,ajj), i = j = l,...,nf, 
’
where
ву = expit(7i + sDOij02 + sGRijfa + sDOi:j x sGRijfit).
Dr. Thurmond wants to know the effect of the covariates on the probability of 
abortion for typical herds (e.g., with latent effects set to 7г = 0\ for all г) over the 
range of covariate values in the data. The probability of abortion for a “typical”

Hierarchical Models and Longitudinal Data
115
herd and given covariate combination (sDOf.sGRj) is
P(Yj = 1 | 7/ = 
= expit(3i + 32sDOf + 33sGRf + J.tsDO/ x sGRj).
He is also interested in knowing the latent effects for herds on these probabilities. 
This is because certain practices in maintaining herds, not accounted for by GR or 
DO, may result in either higher (with poor practices) or lower (with good practices) 
probabilities of abortion. We address this question by setting sDOf = sGRj = t) 
and obtaining posterior medians for
P(Yf = 1 | ъ) = expit(7i), i=l,....9.
We can then look at the differences in estimated probabilities. These estimated 
probabilities correspond to what might be termed an “average” cow, realizing that 
GR = 3.5 is not a possibility. Other choices can be made for the values of DO/ and 
GRf.
Finally, Dr. Thurmond is interested in the practical and statistical import of the 
interaction effect. This can be addressed by looking at a table of estimated prob­
abilities of abortion, perhaps with the combinations of {sDO,sGR) correspond­
ing to values of DO equal to (2,4,6) and values of GR equal to (60,116,172) 
(mean(GR) ± 56 days). We can assess the effect of GR by simply comparing the 
probabilities of abortion for GR = 2 and 4 (or 6) for DO = 60, with those probab­
ilities with DO = 116, and finally with DO = 172. Of course, this assessment can 
be done with odds ratios as well. Exercise 14.12 addresses these questions in the 
context of analyzing the cow abortion data.
The data and code are available on the book’s website in files with 
Chl4-Cowabortion in the name. We use a partially informative prior for regression 
coefficients. This prior accounts for our knowledge that the overall average rate of 
abortions is around 0.12. If we consider the “average cow” in a “typical herd,” then 
the logit of the probability of abortion for such a cow is just 3i- Consequently, the 
corresponding probability is expit(^i). Dr. Thurmond has been studying cows in 
the central valley of California for many years and his best estimate of the prob­
ability of abortion for such a cow in such a herd is 0.12. We, therefore, specify 
3i ~ N(—2,5), where -2 « logit(0.12) . Moreover, since there are over 13,000 
observations in the data, we do not require additional specific prior information 
about the coefficients; the other coefficients are modeled with independent N(0,5) 
priors. Since all predictors have been standardized, we set b = 1 for each. We also 
set b = 100 to check on the sensitivity to that choice.
In addition, we elicited from Dr. Thurmond his best estimate for <77, which was 
0.25. (We discuss the elicitation methods in the next section.) In the end, we used 
a relatively diffuse 17(0, c) prior with c = 2. We also ran the model with c = 10. 
Results from all analyses were virtually identical, despite the fact that the N(0,100) 
and U(0,10) priors are overly diffuse for reasons discussed in the next section.

446
Bayesian Thinking in Biostatistics
14.2.1 Informative Prior Elicitation
There are many possible models with different numbers of levels and parameter- 
izations that correspond to the types of data we have been considering. We have 
been focusing on the logistic regression model with latent variables, but we could 
also allow for probit or other regression model structures. Here, we discuss prior 
elicitation for a common type of situation.
The data are modeled as outcomes on Bernoulli variables for individuals in к 
groups with rii individuals in group г, {y^ : i = 1,..., к; j = 1,..., щ}. Individual 
j in group i has covariate vector x'^ = (xy2,... ,xiJP), where we leave out the 1 
that corresponds to the intercept. The regression coefficient vector is now /?*  = 
(/32,... ,/?₽)'• The notation reflects the fact that there is no intercept in /?*.  The 
model below involves centering the latent effect, 7,, on the intercept, /?i. We assume 
the covariate vector components have been standardized if they are continuous, and 
that categorical covariates have a reference category taking the value 0. The model 
is given as
{Yij : j = l,...,ni} I X Ber(0i), logit(^) = x'^
*
 + 7i,
7i I /?1,ст7 X ЛГ(/?1,ст2).
We continue to define /3 = (/3i, (/З
*)')'.
 The predictor vector is x = (l.x')'. 
Thus, x'/3 = /?i +x'/3
*.
 The distinctions are necessary because we treat the intercept 
differently than the regression coefficients in the model; the model centers the latent 
effects on the intercept /31.
14.2.1.1 Logit-Normal Prior Specification for В
We illustrate with two predictor variables, say Xi, which is dichotomous, and x2, 
which is continuous. Let sx2 = [x - mean(x2)]/sd(x2) be the standardized x2, and 
x1 = (xi,sx2). For simplicity, we do not include subscripts in the discussion. Let в 
be the generic probability of success, and specify the model as logit(0) = 74-х'/3*  = 
7 + xi(32 + sx2/33, with 7 ~ 7V(/3i, cr^).
We first consider specification of a prior distribution for /3]. We start by thinking 
about the probability of “success” for a new individual who is in a typical group 
with 7 = /31 and who also has covariate vector x\ = (xi = 0, sx2 = 0). Call this 
probability 6\. This individual has an average value of the continuous covariate and 
falls into the baseline category for xb which we regard as reflecting a typical group. 
Then
logit (0i) = /3j.
We can specify either a beta prior or a logit-normal prior for 0]. In Chapter 8, 
we primarily focused on beta priors. Now, we discuss the logit-normal model, first 
introduced in Chapter 5. In Example 14.6, we placed a 7V(-2,6) prior on , which 
is precisely a logit-normal(—2,b) prior on 6\.
For our generic problem, let 0o be our best guess for 0P Then our best guess 
for <3t is logit(0o)- Our specification will be
logit(0i) ~ Лг(а. b),

Hierarchical Models and Longitudinal Data 
147
with a = logit(#o)- In order to obtain a fully informative prior on 3(, we need to 
specify an appropriate value for b. This is accomplished by specifying either an 
upper 95th percentile (if 0O > 0.5) or lower 5th percentile (if 0q < 0.5) for our 
prior on 0i. Assume that 0$ > 0.5 and denote the upper percentile as u. Using the 
logit-normal distribution, we have
P(0i < u) = P(0i < logit(u))
= P{Z < (logit(u) - logit(^o)]/v/b} = 0.95.
Here, Z ~ 7V(0,l), since 0i ~ 7V(logit(0o). b). We must therefore have 1.615 = 
(logit(u) - logit(0o)]/x/b, so
b = {(logit(u) - logit(0o)]/1.645}2.
This is a conditioned means prior.
We next obtain a conditional means prior for 0*  = (/32,/3з)'. Define x2 = (1,0), 
which is a predictor vector for a hypothetical subject in the non-baseline category 
for the first predictor and the average value for the continuous predictor. Define 
x3 = (0,1) for a third hypothetical subject’s predictor vector, where this subject 
is in the baseline category for the first predictor and whose value for the second 
predictor is one standard deviation above the mean of this variable. Then define 
02 = expit(/?i + x20*)
 = expit(/?i +/32) and 03 = expit(/?i + x30*)
 = expit(/?i + /33). 
We elicit independent logit-normal priors for 0, for i = 1,2,3. Generically, we let 
logit(0j) X N(a,i,bi), i = 1,2,3. In vector and matrix notation, we write
logit(0) ~ N3(no,Le),
where ц'в = (а!,а2,аз) and E^ = diag{bi,b2,b3}.
Since 0i = logit(0i), 02 = logit (02) - logit(^i), and 03 = logit(03) - logit(6
*i
), 
we must have
/ 1 
° 0\ 
_ 
_
/3=1-1 1 0 I logit(0) = Clogit(0), 
\-l 0 1/
and, using standard properties of the multivariate normal distribution,
0 ~ N(0O, Eo), with 0o = Сцо and Eo = CE^C'.
Working through the arithmetic, we have 0'o = (ai,a2 - аьаз - ai) and
/ bi —bi —bi \
Eo = I —bi bi + b2 bi I .
bi bi bi+b3J
The induced prior distribution for 0 is N(/3o,Eo). Observe that the regression co­
efficients are correlated under this prior.
The demonstration using logit-normal priors to obtain 0 ~ Np(/3o,Eo) can 
be extended to the situation with multiple covariates where, of course, additional 
details are required. The prior probability density function is written as
p(/3) a 
(£-
*>)_

448
Bayesian Thinking in Biostatistics
14.2.1.2 Conditional Means Prior for (3 Using Beta Distributions
We could have just as well considered beta distributions rather than logit-normal 
distributions. The conditional means prior using beta distributions that was dis­
cussed in detail in Chapter 8 induces a prior on 0 that is in the same form as the 
likelihood function when there are no latent effects. This type of prior is also called 
a “data augmentation prior.” Since we have latent variables centered on 3i, we 
carry out the elicitation by thinking about probabilities that correspond to p indi­
viduals, as we did in Chapter 8. As above in the logit-normal case, we think about 
such individuals as all being in a typical group for whom 7 = /Зр As in Chapter 8, 
we have Oj JL beta(aj, 6j). The induced prior on ft is
In both the logit-normal and beta cases, we could of course specify a partial 
prior as discussed in Chapter 8. Moreover, we could specify a logit-normal prior on, 
say, 3i> and then use independent beta priors for the remaining 6s. Alternatively, 
we could specify ,/V(0,6) priors on the remaining fti. There are lots of possibilities.
14.2.1.3 Prior for 0^
We now elicit information for cr7. First, as in Sections 14.2.1.1 and 14.2.1.2, we think 
about the probability of success for an individual with standardized predictors, say 
x = 0, and who is also in a typical group, so that 7 = 31- This individual has 
average values for the continuous covariates and reference values for categorical 
covariates. Next, we obtain a best guess for the corresponding 6, call it 0q. We now 
have a best guess for 3i, namely logit(#o)- If £ / 0 (i.e., not a typical subject), 
our best guess for 31 + x'ft
*
 is logit(#o)- In this case, our thought process would be 
different, since we would be considering a success probability for a different type of 
individual.
We now switch gears and think about success probabilities for individuals across 
all of the groups. Consider individuals in these groups all having the same covariate 
vector, say x (possibly 0), but different 7s by virtue of being in different groups. 
We ask our expert for his or her best guess for, say, #o.9, the 90th percentile of 
satisfaction probabilities for such groups. What does that mean? Imagine we have 
100 groups with individuals having covariates x. We expect about 90 of these 100 
groups to have success probabilities less than or equal to #0.9 (i-e., among those 
individuals in each group with covariates £). Let U0.9 denote our expert’s best 
guess for #o.9< and suppose 1/0.9 = 0-7- From the normality of 7, we must have 
logit(0O9) = 3i + £'3
*
 + 1.28<t7. Since our best guess for 3i + £'3
*
 is logit(0o), our 
best guess for logit(0o.g) must satisfy logit(uo.9) = logit(0o) + l-28cr7. Solving the 
equation, we get a best guess for <t7,
oo7 = [logit(uo.g) - logit(0o)]/l-28.
Note the similarity with the derivation for ct7 in a normal model with latent 

Hierarchical Models and Longitudinal Data
449
effects. The added complication here was due to the logit scale involving the latent 
effect, rather than the linear scale under the normal model. Observe that if we were 
to parameterize the model with r7 = l/a
*.
 we would have a best guess for n, of 
to-, = l/crg7-
It is often important to select a prior for a-, that does not allow for values that 
are “too large.” The reason is that expit(7 + f'5‘) will be arbitrarily close to 1 or 
0 if |7| (or any l&l) becomes very large.
Our recommended choice for a diffuse yet informed prior for cr-, uses the above 
elicitation information in conjunction with a further inquiry about just how large 
00.9 could be. Suppose our expert is virtually certain that 0O.<) < «,nnx. Then we 
could argue that
1 = P[0O.9 < u,nax I logit(0o)]
= P[/3i + x'/3
*
 + 1.28<77 < logit(umax) I logit(0O)]
= P[logit(0o) + 1.28cr7 < logit(umax)]
= P[^ < [logit(izmax) - logit(0o)]/1.28],
where we have assumed that knowledge about (3 is independent of knowledge about 
cr7. This argument leads to our suggestion of a uniform prior for cr7,
<77 ~ U(0, O’max) 1 O’max = (logit(umax) ~ logit(^o)]/1.28. 
(14.10)
We note that if our best guess for в were во = 0.5 and our best guess for 0max 
were (0.6,0.8,0.9,0.95,0.99), we would obtain omax = (0.32,1.08,1.71,2.30,3.59), 
respectively. It is difficult to imagine a situation where 0o,9 could be as large as 
0.99, so with в0 = 0.5 it is hard to imagine selecting a value of omax as large as 
even 3. If во = 0.1 and umax = 0.95, a combination that is also somewhat difficult 
to imagine, we get a large value for crmax = 4.01.
Another way to think about the issue of constraining cr7 not to be too large is 
to think about the fact that we have modeled 7i ~ /V(/3i,cr2). Consequently, we 
expect 95% of the latent values to be in the interval (Z?i ± 1.96cr7). No matter what 
Pi is, this interval is bound to be extreme in one way or another if a-, > 3.
We briefly discuss how to elicit an informative gamma prior for cr7 (or for 
т7 = 1/<t7). Placing a Ga(a, 5) prior on a-, (or т7), we can set <707 = (a - l)/b (or 
tq-, = (a — l)/6) and solve for a in terms of b, as we have already done a number 
of times. Setting b to be small corresponds to a large prior variance, which may be 
undesirable if too much prior mass is attached to large values of cr7. If one wishes 
to take this approach, we recommend selecting b so that simulated values from the 
gamma prior for cr7 (or the induced prior on <t7 with a gamma prior for t7) do not 
exceed <ттах too often. We say a little more about this suggestion at the end of this 
section.
Alternatively, we can elicit more refined scientific information about 0o.9- Se­
lecting b involves eliciting a value that the expert is, say, 95% sure that 0o.9 could 
not exceed, say, 0o.9u, namely P(0O.9 < 0o.9u) = 0-95. Then in exactly the same 
way that we derived crmax in expression (14.10), we obtain the 95th percentile of a

450
Bayesian Thinking in Biostatistics
Ga(a,b) prior for cr7,
<70.95 = (logit(0o.9u) - logit(0o))/1.28. 
(14.11)
We find b so that the Ga(l +<to7 b, b) distribution has 95th percentile equal to cto.95- 
We now discuss the now infamous Ga(c, c) prior with small c (e.g., c = 0.001) 
for the precision of the latent effects. Let 7 ~ AT(O, l/r7), with r7 ~ Ga(c, c) for a 
small value of c. We examine the implication of using such a prior in light of the 
need to constrain the value of cr7 = l/^/r^. We considered values of c = (1,0.1,0.01) 
and found that the induced prior on <t7 with c = 1 resulted in P(<t7 > fc) = (0.22, 
0.06, 0.3) for к = 2,4,6, respectively; with c = 0.1 the same probabilities were 
(0.73, 0.63, 0.58), respectively, and with c = 0.01 they were (0.95, 0.94, 0.93). It is 
clear that we would only consider using c = 1 out of these choices.
14.2.2 *Gibbs  Sampling
We now obtain the full conditional distributions corresponding to model (14.9) 
to illustrate the calculation for a common situation. Knowing how to determine 
the full conditional distributions here will make it easier in other situations. This 
section is important for anyone who would like to or might need to write their own 
program instead of one of the software packages available for Bayesian inference, 
such as BUGS, JAGS, or Stan (see Appendix C). The illustration of Gibbs sampling 
below corresponds to the type of models we considered for the analysis of the cow 
abortion data and the toenail data. The most commonly used prior model is a 
normal prior for 3 and a gamma prior for the precision r. Some full conditionals 
are not recognizable no matter what prior or model one specifies.
We consider two distinct situations for the distribution of the latent effects. 
The first is identical to model (14.9), in which the distribution of latent effects is 
centered on the intercept ft. In the second situation, we let wi be the q x 1 vector of 
covariates in Xij that are associated with group i and that do not vary with j. We 
then replace the vector of individual covariates xi:j, literally and notionally, with a 
new (p - q) x 1 vector x^ that has only predictor values that vary with j. Thus, 
individuals are allowed to have covariates x^, and groups have covariates w,. The 
only part of the model that changes is that 7, X N(J3} + w^A
*,<
t7), where Л*  is a 
vector of regression coefficients associated with group-level covariates. Equivalently, 
we let Wi — (1, w'Y and = (ft> (A
*)')',
 so that w^X = ft + w^X
*.
 We write
7, X N^w'iX.a^), i = 
(14.12)
14.2.2.1 Centering on X
Consider the prior p(ftr7) = р(/?);?(т7). We write p(3) = p(ft)p(3
*|ft)
 when we 
consider 3i separately from 3*.
 the regression coefficients for covariates (other than 
the intercept). Let 7 = {7, : i = 1.....Д-}. Then p(/?,r7,7) = р(3)р(т7)р(7 | 
3. r7) = P(3)p(r7)p(-;. I -Зрt7). Thus, the joint density for the data, the latent

Hierarchical Models and Longitudinal Data
effects, and the parameters is
р(1/,7,31,3
*,л)
 = p(y | 7,3’)р(3)р(л))р(7|3ьт7)
к n,
ПП
(14.13)
n^/2e-^b‘-3l)2j P(3)p(b).
The full conditional posterior distributions are
p(3 I y, 7, ь), p(7 I У, 0, Ту), and р(т7 | у, в, 7).
We obtain all conditional distributions by simply lifting the part of equation (14.13) 
that depends on the variable of interest.
Consider the specific situation with
Ty ~ Ga(a', b') and 3 ~ N(3o, So),
where a' = a/2, b' = 6/2. (Dividing by 2 makes the formulas a little nicer.) From 
equation (14.13), after some simplification, we obtain
Observe that the first term is free of 3i- It is immediate from equation (14.14) that 
Ту | y, fa, 7 ~ Ga ((a + fc)/2, |б + £(7i - 3i)2j /2) .
Next we see from equation (14.14) that the 7, are conditionally independent 
with
This is not a recognizable distribution. At least it is a scalar distribution, making 
it easier to sample from via adaptive rejection sampling, since it is log-concave.
We note that
£(7, - A)2 = £<7. - 7>2 + 
- 7)2, 
(14.15)

452 
Bayesian Thinking in Biostatistics
where 7 = 
'"fi/k- Substituting equation (14.15) into equation (14.14), we have
p(J31 
«
~Vij
x exp ~^2)]
X eXP ~ ~
(14.16)
which is again not recognizable as a distribution. It can be sampled, however, 
using a Metropolis sampler. Alternatively, we could sample /3j from the distribution 
p(/3j I 3/,^(_j),7,t7) for j = l,...,p. Here, /3(_j) denotes the p - 1 vector that 
is 0 with removed. This approach is termed “Gibbs within Gibbs” sampling, 
since we sample from the joint full conditional for 0 by sampling from the full 
conditionals for the components of /3. Tierney (1994) [327] justified this approach 
theoretically. We obtain p(J3j | p, ^3(_7),7,т7) by factoring out the part of equation 
(14.16) that involves 0j, and then sample from that unknown univariate distribution 
using adaptive rejection sampling (since it will be log-concave) or by using some 
other method, such as slice sampling.
Alternatively, in order to sample from the full conditional for /3, we could sample 
sequentially from p(J3i | y,7,r7), followed by sampling from p(J3
*
 | p,7,/3i,r7). 
In this instance, we will be sampling from a known normal distribution for /31, 
followed by an unknown distribution for /3*.
 To see this, first replace the multivariate 
normal prior for /3 with p(/3i)p(/3
*
 | (3]0) in equation (14.16). We recognize that 
/31 ~ N(c, 1/d) for appropriate (c, d), and that the conditional prior distribution 
for /3*  I /31 is also normal with a known mean vector and covariance matrix that 
can be obtained using standard multivariate normal results (Johnson and Wichern, 
2002) [178]. Substituting this into equation (14.16), we have
p(0i|p,7,b) <*  exp-J-0.5 [/cr7 (/3i-7)2+d(/?i-c)2]J> 
oc exp 0.5(fcr7 +d)G3i - Д)2} ,
where we have used the complete-the-square method. We have
0i I У, 7, т-у ~ №(0!, l/(r7 + d)), /31 = W7 + (1 - w)c,
where w = [/ст^/(/гт7 + d)]. Observe that this full conditional does not depend on 
the data. y.
Finally, from equation (14.16), we obtain
к n* /
P(0
*
 I У. 3i.7.t7) oc
[exp “ £o)'EO 40 -w)].

Hierarchical Models and Longitudinal Data
453
One can obtain a sample from this distribution by sampling 3j from p{3j | 
j/,7,(j / 1), j = 2,...,p, where includes all 3*s  except 3}. 
This is accomplished by first obtaining the part of the prior, p{3). that depends on 
0j, which one can sometimes find by inspection. The inverse of So is involved, which 
could complicate matters unless it is diagonal. It would be simpler to recognize that 
this function of 0j is proportional to p(0j | 0i,0^_j^), which, as mentioned above, 
can be obtained using standard formulas. Then
P(0j I y,l,0i,0(-j)) ^Р(У I l,0
*)p(0j
 I
14.2.2.2 Centering on Group-Level Covariates
We consider the reparameterization of model (14.9) where the latent effects dis­
tributions for group i are centered on w(A, which is given explicitly in expression 
(14.12).
Gibbs sampling for this model is very similar to when we centered on the in­
tercept 0i. It looks like we now need to think about a prior for Л, which includes 
0i. We have already elicited this prior in different notation. Recall our discussion 
of the N(0o,Lq) prior specification for 0 in the logit-normal model for success 
probabilities. Suppose we had arranged the predictor variables with the group-level 
covariates, the ws, listed first and the individual-level predictors, the is, last. Then 
(A, 0*)
 would have the same prior distribution. We assume this ordering of predictor 
variables from here on. The conditional means prior using this ordering of variables 
and based on beta distributions will induce the same data augmentation prior for 
0 as one with a different ordering of variables, only now in a new notation.
The joint probability model is
x [т*/2е-^Е?=>(7‘-^А)2] 
(14.17)
x [е-|КА'.0')'-0о)'Ео‘((л'.З'Г-Л)]
We immediately obtain, independently, 
tt ( ex4li'+',i 
рЫуДА.Л.г,) « П(1 + е1;,з-+7
x
We also obtain
b |y,A,7~G'a |(fc + a)/2, |b + ^
ЛтттМ’
Г(7< - w<A)2] /2^ .

454
Bayesian Thinking in Biostatistics
These full conditionals hold regardless of the choice of prior for (A, /?).
In the logit-normal case, the full conditional for A is a recognizable normal 
distribution. We require the following, analogous to what we obtained in (14.15):
£(7< - w'A)2 = £(7i - 7,)2 + (A - 7)'W"^(A - 7), 
(14.18)
г 
г
with 7 = (W'W)-1W/7. W in equation (14.18) is the к x q matrix constructed 
by stacking the к row vectors w' on top of each other, and 7i = w'ff. We did things 
just like this in Chapter 7.
We must have A ~ jV(A0, Soo), where Soo is the q x q submatrix of So that corre­
sponds to A, and Ao is the corresponding qx 1 subvector of (3q. Let (Soo)-1 = too, the 
precision matrix for the prior on A. These marginal distributions and relationships 
hold because the joint distribution for (A,/?
*)
 is multivariate normal. Substituting 
equation (14.18) into equation (14.17), we have
p(A | p,7,/3
*,r
7) ос е-0.5[^(д-5),и/'^(д-7)+(А-Ао),тоо(А-Ао)1
Using the complete-the-square formula for vectors, we obtain
p(A I ?/,7,/3
*,
t7) oc e-o.sCA-AU^w'w+roolCA-A-),
where
A*  = r7(r7W'W + too)-1 И/'И/7 + (r^W'W + тоо)-1тооАо.
Thus
A | p,7,/3
*,r
7 ~ N (A
*,(
t7W'W + too)-1) .
The full conditional for /3*  is obtained in the same way as in the previous 
subsection.
14.2.3 Meta-Analysis: Ganzfeld Studies of ESP
We consider a meta-analysis of 56 studies that were designed to assess whether a 
particular type of extrasensory perception (ESP) is possible and for which we have 
available data. Each study’s design explores the possibility that two individuals, 
under experimental conditions, can communicate with each other when they are 
separated and in the absence of the usual means of communication. If this were 
possible, it would be a form of psychic, or psi, experience called ESP. Ganzfeld 
is German for “whole field”; the reason for this name will become apparent. In 
most ganzfeld studies, there is a sender and a receiver. These two individuals arc in 
separate acoustically shielded rooms. The session begins by each person listening to 
a relaxation tape. For the next 15 to 30 minutes, the sender looks at a target image 
on a television screen. The target may be a static photograph or a short movie 
segment that plays repeatedly. The sender attempts to transmit information about 
the target to the receiver. The receiver is seated in a reclining chair. The receiver is 
wearing headphones playing white noise while a whole field of red light is shining 
in the receiver’s eyes. The light is diffused with halved ping-pong balls placed over 

Hierarchical Models and Longitudinal Data
■155
the receiver’s eyes. The theory is that the ears and eyes are receiving input, but 
with no sense or pattern, so the mind, looking for input, hopefully will receive the 
information being sent by the sender. During this time period, the receiver provides 
an ongoing verbal report, picked up by a microphone, of his or her thoughts, images, 
and feelings. This is called the mentation period.
At the end of the mentation period, the receiver is shown four possible choices 
of targets, all of the same type (i.e., static photograph or movie segment). One is 
the correct target, and the other three are decoys. The receiver must choose the 
one that the receiver thinks best matches the description he or she gave during the 
mentation period. An experimenter, who does not know the correct answer but who 
has listened during the mentation period, will provide information about what was 
said if requested by the receiver. If the correct target is chosen by the receiver, the 
session is a hit; otherwise, it is a miss.
Before a study begins, a target pool is assembled, usually consisting of hundreds 
of potential targets (photographs and/or video segments). The pool is then organ­
ized into sets of four targets that are of the same type (photo or video) but that 
otherwise are as dissimilar as possible. For each session, one of the sets of four is 
randomly selected, and then one of the potential targets in the chosen set of four is 
randomly selected to be the actual target. The remaining three are the decoys used 
for judging. Therefore, the target is randomly selected from a larger pool in such a 
way that the probability that it will best match what the receiver said is 0.25 by 
chance alone, as it is for each decoy.
The 56 studies that we include all met criteria for methodological rigor and 
adherence to standard ganzfeld procedures. Data from these studies are listed in 
Table 14.5, with the number of sessions ni( the number of hits yt, and the empirical 
hit rate 0j. The studies we included were conducted by many different investigators 
and at a variety of laboratories in multiple countries. For more details about the 
data, see Utts et al. (2010) [339].
We analyze the data using a hierarchical model that assumes a constant probab­
ility of a hit within a study but allows for the possibility of different hit probabilities 
across studies. This is an important assumption, since the studies are generally per­
formed with different subjects and different experimenters in different parts of the 
world. There are lots of latent factors that can contribute to differing hit probabil­
ities across the studies.
Let 0i be the probability of a hit for study i, i = 1,2,..., 56. We have n» sessions 
with yi hits in study i. We assume
Yi | 6i X Bin^nM-
We are motivated to estimate the median hit rate in the population of all studies, 
and we are interested in assessing the variability in hit rate probabilities across the 
same population of studies. We make posterior inferences for the median(0) and 
percentiles (0о.1,0о.э), where median(0) is just 0o.s, and 6a is the lOOath percentile 
of the population distribution of hit rate probabilities. Thus, 10% of the hit rate 
probabilities will be less than #o.i, half less than #o.5, and so on.

456
Bayesian Thinking in Biostatistics
TABLE 14.5: Number of sessions (nJ, hits (т/J and hit rates (fii = т/j/nj for the 
56 studies
7lt
Vi
0,
i nt
1/i
| i nt
Vi
Qi
i щ
Vi
9i
1
32
14
0.44
15 60
27
0.45
29 50
12
0.24
43 30
14
0.47
2
7
6
0.86
16 48
10
0.21
30 50
12
0.24
44 30
11
0.37
3
30
13
0.43
17 22
8
0.36
31 50
9
0.18
45 97
32
0.33
4
30
7
0.23
18 9
3
0.33
32 51
19
0.37
46 22
2
0.09
5
20
2
0.10
19 35
10
0.29
33 29
12
0.41
47 50
13
0.26
6
10
9
0.90
20 50
12
0.24
34 128
60
0.47
48 32
8
0.25
7
10
4
0.40
21 50
18
0.36
35 32
13
0.41
49 58
11
0.19
8
28
8
0.29
22 50
15
0.30
36 50
11
0.22
50 46
12
0.26
9
10
4
0.40
23 36
12
0.33
37 
8
3
0.38
51 20
6
0.30
10
20
7
0.35
24 20
10
0.50
38 40
8
0.20
52 30
6
0.20
11
20
12
0.60
25 7
3
0.43
39 65
24
0.37
53 42
5
0.12
12
100
41
0.41
26 50
15
0.30
40 50
18
0.36
54 32
14
0.44
13
40
13
0.33
27 25
16
0.64
41 30
11
0.37
55 40
16
0.40
14
27
11
0.41
28 50
13
0.26
42 30
11
0.37
56 36
13
0.36
For the next layer of the hierarchical model, we assume a logit-normal distribu­
tion for the Qi'.
logit (0 J JL 7V(az,<Tj).
Note that ц is the median (as well as the mean) of the distribution of logit(0j, so 
we must have
median(0) =
More generally, since fi + za at is the lOOath percentile of the 7V(az, of) distribution, 
we have
pIJ.+za at 
n _ c___________
Q 1 + e^+2“ a‘
since the logit function is monotone and increasing.
The standard deviation of the distribution of the Ot is of interest as well. A 
small value of at indicates that the true probabilities of success are similar across all 
possible studies, whereas a large value indicates that there is substantial variability.
The final layer of the hierarchical model consists of a prior distribution on the 
median of the possible values of 0, which is equivalent to putting a prior distribution 
on (^,<r(). If #o is the prior guess for median(0), then the prior guess for ц, would 
be logit(0o) = д0-
We allowed for different prior beliefs by using four types of prior distributions 
for median(0). We expect that most individuals would specify priors for (/z,<rj that 
included the prior guess of 0.25 for the average hit rate. This results in the prior 
guess for /i. 
= logit(0.25) = -1.1. This would seem to be a fair choice for anyone
who is skeptical or who was simply ignorant of any data involving ESP. For all four 
types of priors, we specified p. ~ 
where we chose c by selecting a 95th
percentile for our knowledge about the median of в, say u. For all priors on we will 

Hierarchical Models and Longitudinal Data
specify that there is 95% certainty that median(0) < «. The four types of prior will 
involve different choices of u. This specification leads to logit (h) = logit (0O) +1.645 c, 
or c = (logit(u) - logit(0o)]/l-645.
For all types of prior distributions, we also used a [7(0.ainax) distribution for at. 
We first select 0max to be the largest possible value that we believe 0о.э could be. 
We then have logit(0o) +1.28at < logit(0max), which leads to <rinax = [logit (0luax) - 
logit(0o)]/1.28.
For a diffuse prior, we selected и = 0.8, which results in c = 1.5 and a 
7V(-1.1,2.25) prior for д. The induced prior for median(0) has 95% prior prol>- 
ability interval (0.02,0.87). We can allow for even more uncertainty by selecting 
larger values of u. We also selected 0max = 0.99, which results in <тшах = 4.5. This 
prior is extremely diffuse, relative to the prior knowledge that, if there is no ESP, 
the overall hit rate should be 0.25. And we should say that if this type of ESP truly 
existed with hit rates as high at 0.8, that fact should have already been discovered. 
So, in fact, there is real prior information available to all of us.
We next considered an open-minded person. For this person, we selected и = 
0.41 and 0max = 0.8. This results in p ~ 2V(-1.1,0.20), and at ~ [7(0,1.94).
A believer was speculated to have 0O = 0.33, и = 0.36 and 0max = 0.4. This 
results in p ~ N(—0.71,0.0065) and at ~ [7(0,0.24). The simulated induced prior 
for median(0) looks just right.
Finally, we consider a psi skeptic. Here, we set 0O = 0.25, и = 0.255, and 0max = 
0.26. This results in p ~ N(—1.1,0.000259) and at ~ [7(0,0.04). We provide code 
that automatically takes the inputs (0o,it,0max) and builds the appropriate priors 
into the analysis.
The data were analyzed using the code Chl5-Ganzf eld-Metaanalysis available 
on the book’s website. Table 14.6 gives a summary of some of the results. For each 
prior, the table shows the median of the corresponding posterior distribution and 
a 95% probability interval. The table also includes the posterior medians for 0o.i 
and 0o.9, under each prior. After all of this work, it is clear that the only prior 
that gives different results for median(0) is the skeptic’s prior. Their very strong 
prior was, for practical purposes, unmoved by the data, which was to be expected. 
The analyses based on the open-minded and diffuse priors are virtually identical to 
each other. We tried a half dozen other very diffuse priors, like p ~ 7V(0,0.01) with 
at ~ [7(0,4), and got precisely the same results as with these two priors.
The believer’s prior obviously did have some impact on inferences for 0o.i and 
00.9- Under this prior, the estimate of |0о.э — 0o.i| is much smaller than with the 
other priors. The implied greater certainty or precision arises because the believer’s 
prior was centered at 0.33, which is where the data sit as well, and it was a rather 
strong prior in terms of specifying 0max = 0.4.
Point inferences for at were (0.03,0.22,0.42,0.42) under the skeptic’s, the be­
liever’s, the open-minded, and the diffuse priors, respectively. There was a compar­
able effect on the widths of the corresponding 95% probability intervals for at.
Last, we calculated the posterior probabilities that median(0) > k, for к G 
(0.25,0.28,0.30). For the believer, they are (1.0,1.0,0.997); for the open-minded 
prior, they are (1.0,0.996,0.93); for the diffuse prior, they are (1.0,0.997,0.94);

458 
Bayesian Thinking in Biostatistics
TABLE 14.6: Prior guess and 95th percentile for median(0); posterior median and 
95% probability intervals for median(0), 0o.i and ^0.9
Prior inference
Posterior inference
Prior
med(0) (95%tile)
med(0) (95% PI)
#0.1
#0.9
Diffuse
0.25 (0.8)
0.33 (0.29,0.36)
0.22
0.45
Open
0.25 (0.41)
0.33 (0.29,0.36)
0.22
0.45
Believer
0.33 (0.36)
0.33 (0.31,0.35)
0.27
0.39
Skeptic
0.25 (0.255)
0.258 (0.252,0.264)
0.251
0.264
and, interestingly, for the skeptic, they are (0.997,0,0). The skeptic’s posterior 
was moved to the right ever so slightly by the data; the posterior interval is 
(0.252,0.264). The practical import, however, is nil under this prior, while under all 
of the other priors, we would say that there is statistical and practical import. This 
is yet another illustration of how the prior can very much matter. In this instance, 
it is clear that strong beliefs may need extraordinary amounts of data to overcome 
them.
In the ganzfeld analysis, the estimated odds of a hit in a “typical” study are 
(0.33/0.67 = 1/2), compared with the odds under chance (0.25/0.75 = 1/3), result­
ing in an estimated OR of 1.5. So if the “size of the psi effect” were to be measured 
using this odds ratio, it is comparable to the size of a treatment effect in many 
clinical studies that led to a change in clinical practice. It remains unclear how 
one could actually use the psi effect discussed here. The Bayesian analysis that we 
propose would be interesting, in part, because we would be obtaining estimated 
probabilities of events rather than the more opaque odds ratios.
14.3 Hierarchical Longitudinal and Spatial Data Modeling
In Chapter 9 we discussed some traditional methods for analyzing longitudinal 
data, such as growth curve modeling. In this section we employ and extend the 
hierarchical modeling techniques discussed in this chapter to handle longitudinal 
data. Sampling individuals who share a common environment or taking multiple 
observations on a single unit typically generates dependent observations. Correla­
tion structures discussed in the book so far have involved either a general structure, 
meaning that there are no constraints on the covariance matrix for a collection of 
dependent data, or they have involved compound symmetry (CS). Here, we extend 
that structure to accommodate the longitudinal (or spatial) nature of the data.
Longitudinal data arise when repeated measurements are taken on each unit 
through time. For example, in a sample of hospitals, we could obtain overall mea­
sures of patient satisfaction and collect these measurements on several occasions.

Hierarchical Models and Longitudinal Data
•159
Longitudinal studies are often conducted to assess time trends and the effect of 
covariates on time trends. We saw in Example 14.5 that a trial designed to com­
pare different toenail fungus treatments might involve a baseline (pro-treatment) 
measurement on each person prior to treatment assignment, followed by several 
post-assignment measurements. We may examined different trends in fungus erad­
ication over time and whether the trend depended on the treatment. We could 
also evaluate whether the treatment or time effects were affected by a participant’s 
particular characteristics. Units are assumed to be independent, but the repeated 
measurements on the same unit are typically dependent.
Spatial data involve taking measurements of a phenomenon such as cancer inci­
dence in different geographic regions. Some pairs of regions may be in close proxim­
ity to one another and others not. Cancer incidences corresponding to regions that 
are close to one another might be expected to be correlated, and those correspond­
ing to distant regions may be thought to be uncorrelated. Moreover, these spatially 
observed incidences can be monitored over time. These types of data are called 
“spatial” and “spatiotemporal.” A common phenomenon in longitudinal, spatial, 
and spatiotemporal data is that the correlation between observations decays with 
increased separation in time or distance. We do not discuss spatial data here but 
recommend the excellent treatment by Banerjee et al. (2015) [15].
Example 14.7. Reference Values for IL-1/?. Understanding the extent of day- 
to-day variation in key hormones is important background for evaluating effects of 
interventions. Do the changes one sees after some intervention reflect the effect of 
the intervention or just natural variation? Thomas et al. (2009) [325] describe a 
longitudinal study that investigated variability of several physiological compounds 
that they measured in healthy adults. The investigators thought one or more might 
be useful as biomarkers associated with predicting abnormalities or disease. Among 
these potential biomarkers was interleukin-1/? (IL-1/?). IL-1/? is a pro-inflammatory 
cytokine protein that already has several clinical applications but might also be 
useful as a measure of periodontal health.
The investigators measured concentrations of IL-1/? in samples of saliva they 
collected from 30 healthy subjects on six consecutive days. The data for subject i 
are the vector yi = (j/ii,2/i2,j/i3,l/i4,2/i5,j/i6) that consists of the measured concen­
trations in units of picograms per milliliter each day for the subject. The logarithms 
of the IL-1/? measurements are shown in Figure 14.2 in a trellis plot that includes 
a lowess curve [82] showing each subject’s trend over the six days. No consistent 
day-to-day trends appear across the subjects in the plots. Some of the measure­
ments increase over the six days, some decline, and some seem to fluctuate around 
a central value.
Figure 14.3 shows boxplots of the log of the IL-1/? measurements across subjects 
on each day. These plots do not suggest much change in the mean or variance from 
day to day. Day-to-day within-subject trajectories are shown in Figure 14.4 and 
confirm the impressions we have already formed.
We computed the sample correlation matrix for the logarithmically transformed

460
Bayesian Thinking in Biostatistics
FIGURE 14.2: Trellis plot containing each individual’s IL-1/3 data vector on the 
log scale.
data as follows:
/1.00 0.62
0.62 1.00
0.57 0.58
0.51 0.71
0.26 0.34
\0.18 0.46
0.57 0.51
0.58 0.71
1.00 0.68
0.68 1.00
0.42 0.44
0.28 0.37
0.26 0.18\
0.34 0.46
0.42 0.28
0.44 0.37
1.00 0.30
0.30 1.00/

Hierarchical Models and Longitudinal Data
Day
FIGURE 14.4: Spaghetti plot of log(IL-l/3) with sample means.
There appears to be substantial correlation across days, which makes us think that 
we do not want to assume independence of within-subject observations. We also 
note that the correlations appear to get smaller when we consider days that are 
farther apart. This phenomenon is not infrequent and might be something we want 
to consider in our models.
14.3.1 Longitudinal Modeling as Hierarchical Modeling
We consider data in the following form. Let у = {ytj : i = 1,..., k; j = 1,..., n^} 
be the observed response data, and let {(xij,tij) : i = l,...,k;j = l,...,nj} be 
covariate vectors and times of observations for all subjects in the sample. With this 
notation, yij is the Jth observation on subject г in a sample of к subjects sampled 
from a population of interest. The time of observation for y^ is ty, and the p 
observed covariate values at that time for that subject are in the (p+ l)-vector Xij, 
of course with a 1 in the first slot.
Laird and Ware (1982) were possibly the first to recognize the utility of hier­
archical models for modeling longitudinal data [212]. The simplest such model is 
one that we have already seen in this chapter. Let
Уц I J- N(x'J/? + 7i,<T2), j = 
| a2 X N(0,a2).
(14.19)
Observe that we are centering the latent effects on 0. Since the predictor variables 
for each subject are allowed to vary from one time to the next, Xy varies with j, so 
we cannot center the latent effects on х'^(3. Covariates that vary in time are called 
“time-dependent covariates.” We could always center on , or if Xy = x< we could 
center on х'^З. Markov chains may be better behaved in either case. In the text, we 

462 
Bayesian Thinking in Biostatistics
choose to center on zero for notational convenience, while in our examples we tend 
to center on the intercept.
A major drawback to this model for longitudinal data is that Cor г (У/,, Yik) 
is the same for all j / k. This is because Cov(Yij, Yik) = Cov(7i,7i) = cr^, and 
Vai(Yij) = a2 + a2, resulting in Согг(Уо, Yik) = <Гд/(<г2 + cr2), for all j < k. 
This correlation structure is termed “compound symmetry.” This structure may be 
considered to be inadequate, since it is often the case that we expect correlations 
to be smaller as к increases for any j. Before considering generalizations of this 
model for longitudinal data that address this issue, we analyze the interleukin-1/3 
data using the CS model (14.19).
Example 14.8. Reference Values for IL-1/3. We sometimes have to choose 
between analyzing data on the raw or original measurement scale or after some 
transformation, such as a logarithmic transform. Each approach has advantages 
and disadvantages. Many measurements appear more “normal” (i.e., symmetric) 
after taking logarithms, which can make modeling assumptions easier to justify, 
such as a normal sampling distribution. At the same time, interpretation is often 
easier on the raw scale; logarithms are not the most intuitive scale to consider for 
most people, unless this scale is in common use among subject-matter experts. We 
have been analyzing the IL-1/3 data on the log scale, because the data appear very 
skewed on their original scale. Despite the analysis being on log-transformed data, 
we often prefer to present inferences on the original scale, because it is easier to 
understand.
We used a log-normal sampling model to fit the IL-1/3 data with the model in 
expression (14.19). The log-transformed data range from —1.81 to 4.4 log(picograms 
per milliliter). Since the data are from healthy adults, we assume that the intercept, 
, is most likely to lie within this range. Of course, we recognize that an analysis 
of other individuals, particularly unhealthy adults or children, might give rise to a 
different range. We also make the assumption that the standard deviations a or ag 
most likely lie between 0 and 2. Our analysis, therefore, starts with [3i ~ TV (0,4) 
and both cr and ag distributed U(0,2) a priori.
Since the goal of the study was to characterize natural changes in IL-1/3 levels 
across consecutive days in healthy adults, we make our inferences on the raw or orig­
inal scale of measurement. We summarize the predictive distribution for a healthy 
adult’s IL-1/3 level in Table 14.7. The predicted median value for a future IL-1/3 
measurement is 4.7 pg/ml. The corresponding 95% prediction interval is (0.4,57.5). 
The fact that the predicted median is not near the center of the interval highlights 
the skewness of the distribution of values, which appears clearly in the plot of the 
predictive density. p(yj | y), in Figure 14.5. From the predictive density, we infer 
that with probability 10%, the future measurement will be larger than 23.7 pg/ml 
and that there is only a 5% chance that the future IL-1/3 measurement will be 
greater than 37.8 pg/ml. Since these measurements reflect a (hopefully representa­
tive) group of healthy adults, physicians might want to examine further individuals 
with measurements above the predictive 90th or 95th percentiles.
Table 14.7 also contains summaries of the posterior distributions of the standard

Hierarchical Models and Longitudinal Data
163
FIGURE 14.5: Predictive density, p(yf | y), for future IL-1/3 score, Yf, on untrans­
formed scale.
deviations (<7 and ag) and the correlation (p). The posterior medians of a and ag 
are about the same size, which we interpret to mean that there is roughly as much 
variation within individuals as among individuals, based on the sample of healthy 
adults.
Table 14.7 indicates that we expect 90% of future healthy adults to have IL-1/? 
levels greater than 1.5 pg/ml, the 10th percentile of the predictive distribution. The 
table also shows the uncertainty associated with our estimate via a 95% prediction 
interval (1.0,2.1). Our analysis also suggests that 90% of future healthy adults 
whom we measure will have IL-1/? levels less than 15.3 pg/ml. The corresponding 
95% prediction interval is (10.7,21.9). We generated these predictions for future 
observations by setting the latent parameter 7 equal to the parameter . By doing 
this, we can get an idea of the variability of the IL-1/? levels for typical healthy 
adults in that we do not take account of variability across individuals, only within 
individuals.
The book’s website contains some code for this example in the section for Chap­
ter 14 in files with Chl4-IL-lbeta in their name. The example appears again in 
Exercise 14.18. Note that the untransformed data are modeled with a log-normal 
distribution in the program. This is equivalent to transforming the data and then 
modeling them as normal.
The next level of generalization allows for an overall trend in time and latent 
departures from the overall trend that reflect differences in individuals. This modi-

464
Bayesian Thinking in Biostatistics
TABLE 14.7: Posterior results on untransformed scale for IL-1/3 data. The median 
outcome for typical patients is e^1. The a quantile of outcomes is exp(/?i + zQ ag) 
for a = 0.1 and 0.9
median (95% PI)
У/ 
exp(/3i)
4.7 
(0.4,57.5)
4.7 
(3.4,6.6)
exp(/?i — 1.28a) 
exp(/?i + 1.28a)
1.5 
(1.0,2.1)
15.3 
(10.7,21.9)
a
a9
P
0.92 
(0.82,1.03)
0.82 
(0.60,1.15)
0.45 
(0.29,0.62)
fication of the model has expectation
E(Yij | /3,7) = х'ц0 + 0p+itij + 7h + 72i«v • 
(14.20)
The vector for the latent intercept and slope, 7$ = (7u,72i)/, is specified to have a 
bivariate normal distribution
7i iN2(0,Es), Ss=P?»
* 
“ \cr12g °2g /
A standard simplification would be to let <Ti2S = 0, but a more thorough analysis 
would explore whether or not this was a reasonable assumption. It is not obvious 
that knowing the latent intercept would be uninformative for the latent slope.
This model can be written in matrix and vector form. Let yi = (рд> • • • ^УгпУ 
and let Xt be the щ x (p + 1) matrix that has rows x'^. The first column is all 
Is, the second column contains values for the first predictor for all щ responses for 
individual i, and so on. We augment this matrix by appending the column vector 
ti = (^1,^2,- • • Thus, we define the matrix Xi = (Xi,ti) so that Xi is 
nj x (p+2). Let 0 = (/3i,..., 0p+2)'- Finally, let Zi be the n; x 2 matrix that has all 
Is in the first column and has the vector ti in the second column. The conditional 
mean for Y/ can be expressed as
E(Yi\0n) = Xi0 + Ziyi.
We write the matrix version of the model for the entire data set у = (р'р... ,Ppz- 
Let A' be the T x (p + 2) matrix with all of the Xi stacked on top of each other 
and where T — 52, щ is the total number of observations in the data. Next define 
7 = (7',,..., 7(.)z. and the T x 2k matrix,
(
Zi 0 
0 \
0 
Z2 
0
.
0
о 0 Zk /

Hierarchical Models and Longitudinal Data
■165
Then we can write
У |~ N7-(XJ + 
(14.21)
where It is the TxT identity matrix. In the statistical literature, this model and its 
generalizations, some of which are discussed below, are referred to as "linear mixed 
models.” When the expected value is a generalized linear model (see Chapters 8 
and 9), such models are sometimes called “generalized linear mixed models." There 
are entire books dedicated to using these types of models [312].
The next level of generalization could allow for quadratic and higher-level poly­
nomial trends in time, with corresponding latent departures from each. These mo­
difications would simply involve augmenting the matrix X by adding columns that 
correspond to squared, cubic, etc. functions of the tij. One would add the same 
columns to the Z, and augment the vectors 7i with corresponding additional latent 
effects.
In addition, we could add latent effects that reflect individual departures from 
one or more predictor variables’ coefficients. This simply involves adding column 
vectors to the Zi that correspond to these variables, and of course adding more 
latent effect terms to the 7».
The 7i would now be modeled with a higher-dimensional multivariate normal 
distribution. There would be issues related to modeling the covariance matrix for 
that distribution. It would generally be the case that the covariance matrix, Es, 
would be constrained to be a function of a relatively small number of parameters, 
say 0 = (#i,... ,0fl). In this case we would write the covariance matrix as Eff(0). 
Considerable care is needed to guarantee that the resulting matrix is indeed a 
proper covariance matrix. One must also place a reasonable prior on 0. We refer 
the reader to Christensen et al. [79, Section 10.3] for illustrations of such covariance 
structures .
It was the generalized linear mixed model that Laird and Ware (1982) suggested 
for use in analyzing longitudinal data [212]. The nice feature of their suggestion was 
the fact that these models do not require having regular data for analysis. Regular 
data must have equal n*,  times of observation must be the same for all subjects, 
and they must be equally spaced, which was a requirement for classical methods for 
repeated measures data. As in the simple latent intercept case, this generalization 
does not directly address the issue that observations on the same individual that 
are near in time tend to be more highly correlated than those that are farther apart 
in time.
We now consider an example that involves modeling trends in time.
Example 14.9. Dental Data. We will examine the classic example of longit­
udinal data from the paper by Potthof and Roy (1964) [263]. The data consist of 
measurements based on X-rays taken every 2 years on 16 young men and 11 young 
women. Their ages at the time of the X-ray measurements were 8, 10, 12, and 14 
years. The data come from a study in which the investigators measured the dis­
tance (in millimeters) from the pituitary gland to the pterygomaxillary fissure as 

466
Bayesian Thinking in Biostatistics
an indicator of physiologic growth. In our analysis, we examine the effects of sex 
and age on the growth rate.
Figure 14.6 shows the data as individual plots for each of the 27 young people 
in the study. The figure also shows the sample means by age and sex, with separ­
ate lines connecting the age-specific means for the young men and young women. 
Note that we can consider age to be a surrogate for time, since the data collection 
occurred regularly at equally spaced times (ages 8, 10, 12, and 14). Also, there are 
no missing observations. Neither regularly spaced data nor no missing data will be 
the case in practice. The methods we are using here, however, work equally well for 
non-regularly spaced data.
We first consider a simple model that assumes that the boys and girls have 
trend lines of growth that are parallel over this age range but may have different 
intercepts. If we examine Figure 14.6, we can try to imagine two curves based on 
the sex-specific means. A difference in intercepts would characterize a sex-related 
difference in size. The effect of time (or aging) manifests itself via the slope of the 
curves. Since we are assuming parallel curves with possibly different intercepts, our 
model reflects a belief that males and females between 8 and 14 years of age grow at 
the same rate but may differ in size during those ages. Looking at the figure suggests 
that there are different intercepts and that the slopes of the lines are positive.
FIGURE 14.6: Plot of the dental data with sample means for boys and girls.
Our model allows for a latent intercept and a latent slope. We model these latent 
parameters with a bivariate normal distribution that centers the latent intercept 
(E[7i;]) on the overall average intercept 3[. We have standardized the covariate 
Age. creating the variable sAge^ = (Age2J - 11)/2. The covariate Male is coded

Hierarchical Models and Longitudinal Data
-167
as 1 = male and 0 = female. The model is
Yij | 7, 3,a2 X N^ij.a2). i = 1....... 27: j = 1.2,3.4.
= 7ii + fasAgeij + 721зД</е^ + 33.Ма1е> 
(14.22)
7г
where
••GO- -(7 ‘•■(is)
The average intercept for the females in this model is and the average in­
tercept for the males is + 33. Thus, the model considers the possibility that the 
two groups will have different average intercepts, according to the value of 33. We 
could add an interaction effect to the model, ^sAge^ x Ma/e,, to allow for different 
rates of growth for the two groups. With the interaction effect, the average slopes 
would be fa and 02 + 04 for females and males, respectively. We note that these 
parameters relate to average intercepts and slopes, since we have parameterized the 
model via Е,(7И) = 0i and Efai) = 0. The plots of the data in Figure 14.6 seem 
to indicate that parallel lines are appropriate, so we leave an interaction term out 
of the model.
We proceed to specify a diffuse proper prior. We standardized age out of force 
of habit, just to help with convergence properties. We placed a 7V(0,100) prior on 
all three regression coefficients, and a [7(0,10) prior on <r; the range of the data 
responses is only 12 mm so, in light of this fact, these priors axe quite diffuse. We 
also placed [7(0,10) priors on erkg for k = 1,2. It remains to place a prior on the 
covariance, <7i2s. This cannot be done arbitrarily, since our induced prior on the 
covariance matrix has to be positive definite with probability 1.
Specifying an appropriate prior on <7i2s is not difficult. The correlation between 
7н and 72i is just pg = a^g/^ig^g)', thus, <r12j = pg(J\ga2g- A simple diffuse prior 
for pg is [7(0,1). Having specified proper diffuse priors for (<7i9,<t29,p9), we have in 
effect specified a proper diffuse prior for E9. If we expected a negative relationship 
between latent intercept and slope, we could allow for negative values for pg.
If we were writing a program to fit the model and only know what we know 
thus far, we might want to specify the precision matrix in terms of (<т17,<т2>,р9). 
This is, of course, easily accomplished, since we know how to take the inverse of 
a 2 x 2 matrix. We leave as an exercise for the reader the case where the 7, are 
modeled as bivariate normal and the mean vector and precision matrix are specified 
appropriately in the code.
Here, instead, we use simple properties of the bivariate normal distribution 
to write the model for (7i,,72i) as a marginal N(0i,(T2g) for 7h, and conditional 
normal for 72i given 7h. The formulas for the mean and variance of our conditioned 
normal are
£(72i I 71i) = 0+pg —hit ~ 01),
<Mg 
(14.23)
Var(72i I 7h) = a2g(l - p2).

468
Bayesian Thinking in Biostatistics
TABLE 14.8: Posterior inferences for the dental data
median
(95% PI)
/?!
22.7
(21.4,23.9)
02
1.31
(1.02,1.61)
03
2.24
(0.57,3.92)
a
1.35
(1.13,1.63)
2.05
(1.47,2.92)
a2g
0.44
(0.08,0.78)
Pg
0.37
(0.02,0.85)
We are finally in a position to analyze the data. Figure 14.7 gives the sample 
means for males and females across ages, and it gives model-based predicted val­
ues, which appear to adhere to the data nicely. The predicted lines are parallel by 
construction. Again, with these fits it would not really occur to us to try to fit 
separate slopes, which could be accomplished by adding an interaction term. Para­
meter estimates are given in Table 14.8. The intercept is not particularly interesting 
here.
In our model, we created a “standardized” age covariate sAge = (Age - ll)/2. 
This is not a typical standardization but it marks ages in two-year increments. 
If sAge = 0, the age is 11, and if sAge = 1, the age is 13, and so on. Thus a 
difference in standardized ages of 1 corresponds to a difference in actual ages of 
2 years. We standardized ages in the model in order to have better Markov chain 
performance. Consequently, we are able to interpret the estimated coefficient for age 
as an estimate of the difference between median responses for individuals who are 2 
years apart in age, regardless of their actual ages. This (statistically important) age 
effect is estimated to be 1.31 for males and for females, since there is no interaction 
in the model. Similarly, the (statistically important) effect of sex is estimated to be 
2.24 regardless of age.
Our prior assumed that pg > 0. We also ran the model with pg ~ U(—1,1). 
The results were virtually identical to those in Table 14.8, with the exception of 
inferences for pg, which were 0.26 (—0.47,0.82). The implication is that there does 
not appear to be very much information in the data for estimating this correlation. 
In Exercise 14.20 we ask the reader to explore an alternative model for these data 
that assumes this correlation is zero.
14.3.2 Incorporating Latent Effects with Autoregressive Structure
In this section we expand the basic hierarchical model that we have been using 
to include latent effects that incorporate an autoregressive correlation structure 
into the basic model. In simple terms, this means that correlations can be larger 
between observations that are closer in time than for those that are farther apart. 
We first generalize the form of model expressed in expression (14.21) to allow for

Hierarchical Models and Longitudinal Data
•169
FIGURE 14.7: Plot of model-based predicted outcomes for boys and girls at ages 
8, 10, 12, and 14 years. Sample means for boys are squares and for girls are circles.
this structure. For simplicity of exposition, we illustrate by extending the simpler 
model in expression (14.19). The notation for the data, covariates, and observation 
times remains the same.
We discuss latent effects with autoregressive structure. For each i G 
let Wi = {wi(t) : t G (t*i
, t»2> • • -»
*иц)}
 be a collection of random variables indexed 
by time, namely, Wi = (wi(^ti), Wj(ti2), • • • > Wi(tini))'. This is the definition of a dis­
crete time stochastic process that is specific to the given time points. The extended 
processes {wj(t) : t G (0,T)} for T > maxi(tni), г = l,...,k, are regarded as 
independent continuous time stochastic processes. Practically speaking, it is only 
discrete time that matters. The vector Wi is modeled as
WdflXMUO.EiOM), г = 1,...,А:,
where Ej(0w) is, at the moment, a “patterned” covariance matrix that can have 
many possible forms. We will focus on only one form in this section. Under this 
assumption, the continuous time process {wj(f) : t G (0,T)} is called a “Gaus­
sian process.” We thus have к independent Gaussian processes for incorporating 
autoregressive structure into the model for the full data.
Here, we only consider the autoregressive form for Et(0w), which simply means 
that correlations are larger for times that are closer together than for times that 
are farther apart. We make this precise shortly, but right now, we incorporate w, 

470 
Bayesian Thinking in Biostatistics
into the model for the data as follows. The generalized version of model (14.21) is
Yi | 7i, Wi, /3, a2 X Nni+ Z^i + wt, <t27), i = 1,..., k. (14.24)
All that remains is to specify a Gaussian process that gives the Wi an autoregres­
sive structure. We accomplish this structure by specifying a covariance “function” 
for the processes, {Wj(s) : s e (0,T)}. We use a covariance function from the 
literature that specifies
Cov(Wi(t + s), Wi(t)) = <T2pw(s), Var(Wi(t)) = ст2 , pw(s) = p9w, pw > 0.
While there are other possible choices for pw(s), this particular one is termed the 
“exponential covariance function.” It follows that
Corr(Wi(f), Wi(t + s)) = psw < Corr(Wj(t), Wi(t + r))) = prw, s > r.
This immediately gives
\pw Pw 
1 
/
where 0w = (<?£,, pw). This is the (autoregressive) correlation structure that we have 
been seeking. We note that the correlation between pairs of observations in the data 
will depend on this structure when Wj is included in the model, and it will depend 
on the latent structure induced by including 7i in the model as well.
We now consider the actual correlation structure for the Yij when there are 
only random intercepts and Gaussian process terms in the model, namely, Y^ | 
7i, Wij,/3,<72 X N(xij/3 + yi + wij,a2), with 7s and ws independent. Then it is easy 
to obtain
„2 , „2 Jfc-JI
Согг(У„, Fit) = -Э "" 
(H.26)
°g + °w + a
We can see that this correlation decreases to <t2/(<t2 + 
+ a2) as the difference
in time, |fc — j|, increases. This limit is the same correlation that we had with the 
compound symmetry model with only latent intercepts in the model.
We also note that the autocorrelations between observations that are |fc- j| = m 
units apart for m = 1,2,..., n — 1 are interesting to monitor. This way it is possible 
to see if compound symmetry is plausible for a given data set. If it is plausible, 
then these correlations should be approximately equal. On the other hand, if the 
autocorrelations decrease and then flatten, we have some idea about how much time 
is needed before the autocorrelation fades.
A major advantage of the autoregressive structure is that the matrices £i(0w) 
can be analytically inverted, which results in precision matrices that are tri­
diagonal. Details are given in Quintana et al. (2016) [265] who developed a more

Hierarchical Models and Longitudinal Data
TABLE 14.9: Posterior results on untransformed scale for IL-13 data using model 
with autoregressive structure
median
(95% PI)
exp(4i)
4.8
(3.5.6.7)
exp(0i - 1.28a)
1.8
(1.2.2.8)
exp(3i + 1.28a)
12.7
(8.4.19.4)
a
0.92
(0.52.0.94)
a9
1.0
(0.05.1.9)
aw
0.64
(0.18,1.03)
Pw
0.53
(0.08,0.99)
general and more flexible model than our model (14.24). Using this result leads 
to a simple expression for a multivariate normal model for as the product of 
univariate conditional normals:
P(Wi I 0w) = p(w,i I 0w)p(Wi2 I Wib0w)p(wi3 | Wi2,0w) . .-p(wini I
We have used the fact that
p(Wij I Wii,Wi2...Wnj-!),0w) =p(Wij I wi(j_ 
J =2,...,fc,
which follows from the tri-diagonal form of the precision matrix, (E,(0W)]_ 1. Then, 
for J = 1,...,п, - 1, define ry = p™w+,,”<wl. Quintana et al. (2016) [265] have 
shown that
Wn~N(0,a2),
Wi2 | 
= wn ~ N (wnrn^Kl - rfO) , 
(i4 27j
wik I 
~ N (wi{k_1}rik_i,ffl(1 - rt2fc_i)) ,
for k = 2,... ,щ. This makes it straightforward to obtain the full conditional dis­
tribution of Wi in the Gibbs sampling algorithm.
Example 14.10. IL-1/3 Data Revisited. Recall Example 14.8 where we analyzed 
the IL-1/3 data that involved six repeated observations on 30 individuals using a 
model with latent intercepts. The data are plotted in Figure 14.2. Observe that 
most of the profile plots there either trend continuously upward or downward. This 
is an indication of high autocorrelation in the data, so we might expect a model 
that included autoregressive latent effects to improve on the model we fit in this 
example. This turns out to be the case.
We modified the code from our analysis in Example 14.8 to include the autore­
gressive terms specified in expression (14.27). Inferences based on model (14.24) 
with autoregressive correlation structure (14.25) are given in Table 14.9. We used 
proper diffuse priors for all parameters.

472
Bayesian Thinking in Biostatistics
CS + AR
FIGURE 14.8: Boxplot of residuals for the IL-1/3 data, yi - yi,i = 1,... ,fc, under 
model (14.19) on the left (& = E(E(Yi | 7i) | у) = Е(ц | ?/)), and under model 
(14.24) on the right (& = E(E(Yi | yi,Wi\ | y) = Е(ъ + Wi | $/)). CS refers to 
model (14.19) that only allows for compound symmetry, while CS +AR allows for 
compound symmetry and autoregressive structure.
Results for the overall average median e^1 are virtually identical under the two 
models. Remaining results show some minor differences in inferences for a and 
for the 10th and 90th percentiles for “typical” individuals. (Recall that typical 
individuals have 7 values set to /3\ and w values set to 0.) Inferences for ag show a 
much wider PI than we saw with the non-autoregressive model.
The most interesting aspect of the new model is that it fits the data noticeably 
better than the model without autoregressive structure. Figure 14.8 shows box­
plots of residuals. These plots suggest that the model with autoregressive structure 
(model (14.24)) has appreciably smaller residuals than the model with only a com­
pound symmetry structure (model (14.19)). Another interesting feature of fitting 
this model is that predicted values for a future individual at the six specified ages 
are (10.03, 10.33, 10.58, 10.61, 10.74, 10.94), respectively, indicating a slightly in­
creasing trend over time. Since we saw (Figure 14.2) individual profiles that went 
down, up, and somewhat flat, the implication is that overall, there was more of a 
tendency to go up than down. Under the model without autoregressive structure, 
the predicted values were (10.56, 10.54. 10.51, 10.63, 10.48, 10.58), respectively, and 

Hierarchical Models and Longitudinal Data
■173
we see no discernible pattern. The book’s website for Chapter 14 includes data and 
code for this analysis. The files include Ch-14-Interleukin-CSAR in their names.
14.4 
Recap and Readings
We have presented many of examples of the use of hierarchical models, both for 
normal and binomial models. We have shown how hierarchical models can be used 
to perform meta-analyses. We have used them to illustrate a general method of 
performing longitudinal and clustered data analyses. Our most general model il­
lustrated the use of latent effects to incorporate both compound symmetry and 
autoregressive components in an overall model for longitudinal data. These ap­
proaches all involved parametric modeling.
We did not discuss the extension of parametric longitudinal modeling in the 
case of binomial or other non-normal types of data. Models similar to (14.24) are 
easy to specify on the logit scale, for example. An additional section in this chapter 
would just parallel the development in Section 14.3.1 and would use materials from 
Section 14.2.
The assumption of normality for latent effects can certainly be questioned. Early 
papers that allowed for nonparametric mixtures of normal distributions as models 
for latent effects distributions were presented in Kleinman and Ibrahim (1998) [205, 
206]. In this chapter we referred to an extension of the parametric model to a 
semiparametric model for the latent effects; Quintana et al. (2016) [265] extended 
the model (14.24) to a situation where the processes, Wiy are modeled as Dirichlet 
process mixtures of the Gaussian processes with autoregressive structure, with the 
mixing on 6. This extension allows for the possibility of having individuals in the 
data whose latent effects are clustered, meaning that their latent (w) effects might 
coincide with those for a subgroup of individuals in the data set. The model also 
allows for a more general autoregression structure in which correlations of repeated 
observations on the same individual can have diminishing correlations over time, 
but where these correlations can diminish at a faster or slower rate than with 
parametric autoregression structure. Moreover, the correlations can diminish to a 
value and then remain flat afterwards. Quintana et al. give multiple additional 
references for this kind of generalization of latent effects models.
Here, we strongly re-emphasize the importance of specifying proper prior distri­
butions for the latent effects’ covariance parameters. We illustrated how to do this 
in the two-dimensional case. We also emphasized the simplicity of placing uniform 
priors on the latent effects’ standard deviation parameters, like ag, that were not 
unnecessarily diffuse in the case of binomial and normal models.
We finally remark that the Thurmond-Hietela cow data were analyzed in Han­
son et al. (2003) [158]. They jointly modeled the probability of abortion and time 
to abortion, using an expanded version of the data we discussed here that included 

474
Bayesian Thinking in Biostatistics
additional covariates not discussed here. A major goal of the survival part of the 
model was to assess whether early abortions were a result of certain factors. One 
of the highlights of the analysis involved the joint modeling of latent effects for the 
survival and binomial regression parts, and another highlight was that the survival 
distributions were semiparametric rather than parametric. This allowed flexibility 
in modeling that was similar to that discussed above for generalizing latent effect 
distributions to nonparametric mixtures of parametric distributions. Survival mod­
eling is discussed in Chapters 11 and 12. This paper may serve as an introduction 
to joint modeling, which is a topic that is large enough for a book [270, 102].
14.5 Exercises
Exercise 14.1. Reanalyze the conception data in Example 14.1 using several 
alternative choices of diffuse proper priors for the model parameters. Code and data 
are on the book’s website for Chapter 14 in files with Chl4-Conception in their 
names. Discuss the effect of changing the prior on posterior inferences. For three 
priors, including the one used in the example, obtain the predictive probability 
P(75 > 76 > 74)- Compare the results.
Exercise 14.2. We will reanalyze the rat growth data (Example 14.2). Code 
and data are on the book’s website for Chapter 14 in files with Chl4-rat in their 
names.
(a) 
Reanalyze the data using independent G<z(0.001,0.001) priors for the precisions 
but leaving the prior on /3 as is. Discuss the effect changing the prior has on posterior 
inferences.
(b) 
Obtain the induced prior on alg. Does this prior seem reasonable from a scientific 
point of view? Why or why not?
(c) 
Using both priors, obtain inferences for 79,1/729,1 and 72,2/74,2- Discuss.
Exercise 14.3. For the model in expression (14.3) and using the conditionally 
conjugate prior in expression (14.6), show that the full conditional for p is normal, 
for r is gamma, for is gamma, and for 7< is normal, with the 7^ being a posteriori 
independent. Completely specify these distributions. Hint: You will need to apply 
the complete-the-square formula. Also show and use the fact that — 7г)2 =
- .Vi)'2 + E, Ri(7i - yiY, where & = Ej Vij/Щ-
Exercise 14.4. For this exercise, refer to expression (14.3) where an ex­
changeable model is assumed for analysis-of-variance type data. Argue that Yi =
I 7i-o’2 ~ •^(7г,сг2/пг). Also assume that | p, <r2 ~ TV(/2.cr2), 
and that (<t2,/4.<t2) are known. Show that the conditional distribution 7i | j/г ~ 
N(wp + (1 — w)yh (Гд/(а2/щ +<r2), where w = (<т2/пг)/(<т2/пг) + crg)- Thus, argue 
that the Bayesian prediction for 7/ involves shrinkage away from the sample mean 
to the overall mean.

Hierarchical Models and Longitudinal Data
Exercise 14.5. Show that with Y = {У^ : i = 1........H: j = 1.........п,}. У | 0 ~~
/V (р(0). S(0)) with precisely the same mean vector and covariance matrix for the 
models in expressions (14.1) and (14.2).
EXERCISE 14.6. DiaSorin data. Analyze the log-transformed DiaSorin data with 
three groups using model (14.3) with the diffuse but proper prior p ~ A?(O.().(M)(M)1), 
т ~ Ga(0.001,0.001), and crg ~ £7(0, fc), for several choices of k. Be sure to give 
some thought to your choices of к and how you would explain your choices. What 
can be said about any differences or similarities in the three groups? What can be 
said about the sensitivity of inferences to the choice of k?
Exercise 14.7. Fully informative prior for a. Assume the model in expression 
(14.3). Let po.9 = P + 1.28cr, with po as a best guess for po.g. Recall that our 
best guess for a was oq = (po — po)/1.28, where po was our best guess for p. 
Assume that the expert is 95% sure that po.9 is less than p, conditional on all of the 
other information. Derive a suitable Ga(c,d) prior for ag based on this information. 
Actually obtain (c, d) if po = 10, po = 5, and p = 15.
Exercise 14.8. Show that if a random variable X with pdf p(x) has a finite 
range, say (r, s), then sd(X) < (s — r). Note: We realize that many distributions have 
infinite range, in theory. In the real world, however, everything is finite, including 
the values that data can actually take. In this sense, the range of the data is a 
reasonable start for determining how much variability there might be in them.
Exercise 14.9. Anesthesia data. Perry et al. (1974) studied concentrations of 
plasma epinephrine in 10 dogs that received three different types of anesthesia 
[259]. Epinephrine is essentially adrenaline, and one does not want high levels of 
adrenaline or epinephrine when giving a patient anesthesia. The anesthetic agents 
were isofluorane (I), halothane (H), and cyclopropane (C). The data from the study 
are given in Table 14.10, as given in Rice (1995) [269]. The variable Dogs constitutes
TABLE 14.10: Anesthesia data
Dog 
Dog 
Dog Dog 
Dog Dog 
Dog 
Dog Dog 
Dog
1 
23456789 
10
I 0.28 
0.51 
1.00 0.39 
0.29 0.36 
0.32 
0.69 0.17 
0.33
H 0.30 
0.39 
0.63 0.68 
0.38 0.21 
0.88 
0.39 0.51 
0.32
C 1.07 
1.35* 
0.69 0.28 
1.24 1.53* 
0.49 
0.56 1.02 
0.30
what we call a “blocking factor” in the statistical literature. We wish to compare 
the three anesthetics in terms of concentration of plasma epinephrine. Repeated 
observations on the same dog are likely to be correlated, since each dog has its 
own physiological and biological characteristics. Thus, epinephrine levels within a 
dog should tend to be higher or lower across all three anesthetics, depending on 
the particular dog’s innate physiology or metabolism for these agents. As we have 

476
Bayesian Thinking in Biostatistics
discussed in this chapter, we characterize such unmeasured sources of between-dog 
variability using latent effects. We thus include latent effects for the 10 dogs in our 
model.
Consider the following model for the data:
Yij | 7,/5,o-2 J- N(//y, a2), 
= pjlj + pHHj + 
+ 7i,
| a2 X N(0, a2), i = 1,..., 10; j = 1,2,3.
Each predictor (i.e., Ij, Hj, and Cj) is an indicator variable for the corresponding 
anesthetic. The unconditional mean for each anesthetic is the overall mean response 
for dogs that are being administered that particular anesthetic. This is a simple 
analysis of variance model with latent effects for dogs. The main goal is to assess 
which anesthetic has the best performance, and possibly which is worst in terms of 
mean responses. It is also possible that they are all equally effective or that one is 
better or worse than the other two, while the other two are equally effective.
(a) 
Calculate the analytical correlation between any two repeated measurements 
on any dog; that is, find p = Согг(Уу, У^), k ± j, under this model.
(b) 
Using a proper diffuse prior with p(pj,рн,Рс,&,&д) = P(pi)p(PH)p(Pc)P^P^g), 
where the ps are all 7V(0,4) and the as are both 17(0,4), analyze the anesthesia 
data. Obtain posterior inferences for all possible differences in mean responses. Also, 
obtain the posterior probabilities that pc > Ph-, that pc > pi, etc. Finally, look 
at joint probabilities of the form pc > Ph > Pi- Draw conclusions about which 
anesthetics are better. Also make inferences about the relative magnitudes of a 
and ag, and the correlation, p.
(c) 
Perform a sensitivity analysis using some alternate priors and discuss the effects 
of perturbing the prior on posterior inferences.
(d) 
Using the prior in (b), fit a model without the latent effects. Compare inferences 
with those in (b).
(e) 
Now suppose that the observations in Table 14.10 with asterisks ()  were miss­
ing. Redo the analysis by replacing these numbers with NA. If you are using a 
program that generates posterior samples via MCMC, the program can (and nor­
mally will) impute missing values at each iteration of the MCMC sampler, possibly 
using the full conditional distribution for that missing observation if one is using 
Gibbs sampling. The entries with asterisks are the largest ones in the data. Compare 
inferences to those in part (b) and discuss.
*
(f) 
Suppose y\\ were missing. Obtain and precisely identify the name of the full 
conditional distribution of Уп. Hint: It will be a normal distribution.
Exercise 14.10. On the book’s website for Chapter 14, we include the data and 
various programming statements to analyze the intensive care unit study data in 
Example 14.3. The files have icu in their names. Reanalyze the data and verify the 
results given in Example 14.3. Obtain a plot of the predictive density for a future 
odds ratio. This will be a point estimate for the pdf for the “true” distribution 
of odds ratios. Obtain a posterior estimate of the proportion of odds ratios in the 

Hierarchical Models and Longitudinal Data
population of odds ratios from which our 14 samples were taken that will be below 
0.9, 0.8, and 0.6, respectively, and above 1. 1.1, and 1.5. respectively.
Exercise 14.11. The data and program statements to analyze the data from 
the toenail study (Example 14.5) are on the book's website for this chapter. The 
files have toenail in their names.
(a) Modify the code so that you can create a table of inferences that provides 
predicted probabilities of moderate or severe separation at times 1. 2. 3. 5. 8. and 
10 for a new individual who receives Trt = 1 with | 
~ Ar(3,.aj-’). Repeat the
process for the same individual, assuming now that this person receives Trt — 0. 
The table should be 6 x 2. Compare the probabilities across times and treatments, 
(b) Now perform your own sensitivity analysis and comment.
Exercise 14.12.
(a) 
Fit the model for the cow abortion data analysis in Example 14.6. (The data 
and some example code are in files with cowabortion in their names on the book’s 
website for Chapter 14.) Before making inferences, monitor the chains to check 
on convergence. Comment. Now rerun the analysis with a £7(0,10) prior for ag 
and normal priors for the 0s, with precision 0.01 and the same means. Note that 
we believe these would be poor choices for reasons given in the prior specification 
section. What do you notice about the new analysis? (Be warned that the code takes 
about 2 minutes per thousand iterations.) Finally, make basic inferences using the 
output.
(b) 
Now modify the code to obtain estimates of abortion probabilities for “typical” 
herds, by which we mean herds that correspond to all combinations of (GR, DO), 
with GR taking values (2,4,6) and DO taking values (60,116,120). (Keep in mind 
that these values will need to be standardized if modifying code on the book’s web­
site; you would use the means meangr = 3.485024 and meando = 115.842 and 
standard deviations stdgr = 1.517102 and stddo = 59.72637.) Make an appro­
priate table and make appropriate additional inferences to those made in part (a). 
The additional inferences should include inferences for effect modification, still for 
“typical” cows.
(c) 
Revise your program to make inferences for odds ratios to assess whether the 
effect of DO is modified by GR. Create an appropriate table.
(d) 
Using results in parts (a)-(c), address the question of whether the interaction 
effect is statistically important and practically important.
(e) 
Modify your program yet again, now to obtain predictive probabilities for cows 
with specified values for sGR = 0 and sDO = 0, where these future cows will be 
from herds 1,2,...,9. That is, make inferences from the predictive probabilities 
P(Yf = 1 | sDO = sGR = 0,7i), i = 1,... ,9. Comment on how these probabilities 
vary across herds. Which herds have the best and worst “management policies”?
(f) 
Modify your program to use the standard parameterization in which the latent 
effects Eire centered at zero. Include the intercept in the regression part of the 
model. Run this program with two chains for around 1,000 iterations and look at 

478
Bayesian Thinking in Biostatistics
convergence properties of the two chains. What do you notice? The Markov chains 
for all variables except the random effects will have the same stationary distribution 
as in part (a). Centering as in part (a) often results in better-behaved chains.
Exercise 14.13. The development surrounding equation (14.11) led to the choice 
of the informative Ga(a,b) prior for cr7.
(a) 
Using this same development, what would you specify as a prior guess for тд, 
say ro7?
(b) 
Now obtain an informative Ga(a, b) prior for r7, where here we specify Р(0о.э > 
0o.9/) = 0.95 instead of P(0o,9 < 0o.9u) = 0.95. Given the elicited value 0о.э/, our 
expert is 95% certain that 0O.9 will exceed 0O.9/, giving us a probabilistic lower limit 
on what the 90th percentile of probabilities could be. In this same context, recall 
that our best guess for +x'is logit (0q), where we often set x = 0 to correspond 
to a “typical” predictor combination, provided continuous variates are standardized. 
Find the value for T0.95, the 95th percentile of the Ga(a,b) distribution, using this 
information. Then, with the mode ro7 = (a - l)/5, explain how to find the value of 
b so that the Ga(a,5) distribution has mode ro7 and 95th percentile to.95.
(c) 
Consider the cow abortion data scenario. Suppose that x = 0 and 7 = /?o, so 
that the corresponding 0 is the probability of abortion corresponding to a typical 
cow in a typical herd. Your best guess for 0 is 0o = 0.15, and you are 80% certain 
that 0o.9 is in the interval (0.05,0,25). Obtain informative gamma priors for r7 and 
cr7 using this information.
Exercise 14.14. Consider the cow abortion data in Example 14.6.
(a) 
Find an informative gamma prior for cr7 that takes account of the elicited 
information that 6q = 0.12 (best guess for the probability of abortion with sGR = 
0 = sDO), U0.9 = 0.20 (best guess for 90th percentile of probabilities of abortion 
across herds for cows with sGR = 0 = sDO), and 0o.9U = 0.24 (95% certainty that 
90th percentile of such probabilities is less than 0.24).
(b) 
Find a uniform prior for cr7 that corresponds to 0max = 0.3.
Exercise 14.15. Consider the prior and centering specified for the cow abortion 
data (Example 14.6). Write the explicit form of the full conditional distributions 
for , /3*
, and 7. (You may wish to look at the code on the book’s website for that 
example to see the precise prior distributions.)
’Exercise 14.16. Consider the cow abortion data (Example 14.6). Assume that 
the prior guess for the probability of abortion for an average cow in a typical herd 
is 0.12, as it was there. Also assume that Dr. Thurmond is 95% certain that this 
probability is less than 0.15.
(a) 
Obtain a prior on based on specifying a Be(ai,5i) prior for the probability 
of abortion for a typical herd with standardized DO and GR both equal to zero.
(b) 
Assume the prior specification for ,5i in (a) and an independent #6(02,62) prior 
distribution for the probability of abortion for a typical herd with DO = mean(-DO) 

Hierarchical Models and Longitudinal Data 
179
and GR = 4, so that sDO = Oand sGR = (4 - inean(G/?))/sd(GR). Further, 
assume that the best guess for this probability is 0.16 and that Dr. Thurmond is 
95% certain that this probability is less than 0.20. Simulate the induced joint prior 
for (/3i, /32) and plot smoothed histograms for the two marginals.
(c) 
Obtain the analytical expression for the induced joint prior for (3b 32).
(d) 
Repeat (a)-(c) using logit-normal distributions instead of beta distributions.
•Exercise 14.17. Suppose that you have specified a Ga(a.b) prior for = 
\/y/r^ but that your program for performing your own Gibbs sampler has been 
written for a gamma prior for r7.
(a) 
How might you use the prior information that you elicited and still use your 
code?
(b) 
Suppose your original prior was cr7 ~ Ga(3,2). How well do yon think your 
method in (a) would work with this prior?
Exercise 14.18. Recall the analysis of the IL-1/3 data using model (14.19). (The 
data and example programs can be found on the book’s website for this chapter. 
The files include IL-lbeta in their names.)
(a) 
Reproduce the results of Example 14.8. You may wish to modify one of the 
programs on the book’s website or write your own program.
(b) 
Perform a sensitivity analysis. What do you notice? (You may wish to look at 
the prior specifications for beta[l], sig, and sigg in the available programs.) 
(c) The variable ID [ ] identifies the 30 distinct individuals in the data. Each indi­
vidual gets his or her own latent effect. Modify your program to infer the predictive 
distribution for a new individual. That is, model yj using 731, or gam[31] in your 
program. (As we pointed out at the end of Example 14.8, the data are untransformed 
and we model them as log-normal in our programs. The analysis is equivalent to 
transforming the data and then modeling the log-transformed data as normal.)
Exercise 14.19. Dental data. Write a program or use one of the programs avail­
able on the book’s website to analyze the dental data (Example 14.9). (Sec the 
book’s website for the data and sample program files. The files’ names include 
dental in them.) Use the prior specified for the dental data in Example 14.9 and 
do this in the two ways discussed in that example. In one of the ways, you must 
find the precision matrix in terms of (<Tis,cr2p,Pp)- In the other way, you will pro­
gram the model described in expression (14.23) and the paragraph preceding these 
equations.
Exercise 14.20.
(a) 
Either use code from the previous exercise or write a program to analyze the 
dental data using the priors that were given in Example 14.9. Then perform a 
sensitivity analysis.
(b) 
Now expand the model to include an interaction term between Male and Age. 
Analyze the data and make inferences for the interaction term. Decide whether the 
interaction term belongs in the model.

480 
Bayesian Thinking in Biostatistics
(c) 
Reanalyze the dental data assuming independence between the intercept and 
slope latent effects. Compare the analysis with that of part (a). Comment on 
whether or not an interaction term would be needed in this model.
Exercise 14.21. Derive formulas for the variance of У^- and the covariance 
between Ytj and Yik under the random intercepts and slopes model (14.22). Assume 
that sAgeij = 0 and sAgeik = x. What can you say about the correlation as x 
increases?
Exercise 14.22. The IL-1/3 data using model (14.24) with autoregressive cor­
relation structure (14.25) were analyzed using code on the book’s website with the 
name Interleukin-CSAR. Results were presented in Table 14.9. Revise the code 
so that you can estimate autocorrelations between observations that are 1,2,..., 5 
years apart using equation (14.26).
(a) Run the modified code and monitor convergence using multiple chains. Discuss, 
(b) Perform a sensitivity analysis. Discuss.
(c) Modify the same code to analyze the data without the Gaussian process part 
of the model, which leads to model (14.19). Reproduce the boxplots in Figure 14.8 
using R.
Exercise 14.23. Establish the formula in equation (14.26) and give formulas for 
the first three autocorrelations.

Chapter 15
Diagnostic Tests
Diagnosis is an extremely important part of medical practice. Proper diagnosis 
will help determine the best course of treatment. Physicians are often faced with a 
patient who presents with a collection of symptoms and who has responded to ques­
tions related to them. It is routine for a physician to attempt to make a diagnosis 
as to what disease or disorder might be associated with these symptoms. In many 
instances, the physician will not have enough input to make a diagnosis with a high 
degree of certainty without obtaining additional diagnostic information. Blood and 
urine are often analyzed to provide such information.
For example, a patient may present with the symptoms “thick, cloudy or bloody 
discharge from the penis or vagina” and “pain or burning sensation when urinating.” 
There are other symptoms that could be present as well, but it is likely with these 
symptoms that either a blood or urine test or both would be made to see if the 
etiologic or infective agent, Neisseria gonorrhoeae, could be detected. This agent is 
the cause of the disease known as gonorrhea. On the other hand, if a patient has 
detected a lump in her breast, she would likely make an appointment to determine 
if the lump is suspicious and possibly malignant. If it seems suspicious on physical 
exam, the patient may undergo a mammogram, and if still uncertain about the 
nature of the lump, there may be a biopsy of the lump.
If the outcome of analyses of blood, urine, a mammogram, or a biopsy is a “yes,” 
or “no,” or a “maybe,” then the procedure used to produce the result is called a 
diagnostic test. It is often the case that such tests are designed to result in simply 
yes or no binary outcomes. A key feature of binary diagnostic tests is that they 
are seldom 100% accurate. Even in the absence of the condition, a test might say 
“yes.” Similarly, a test may incorrectly declare “no” when the condition is present. 
When a diagnostic test is perfect, it is often termed a “gold standard” test.
A procedure that ultimately results in a yes or no outcome for some infection 
or disease may be based on a single assay. For example, a physician may rely on a 
blood test in the absence of other testing. Alternatively, the diagnostic process may 
proceed in steps that involve a sequence of yes, no or maybe outcomes before one 
reaches a final definitive outcome, as would be the case with breast cancer. We call 
the diagnostic process a protocol, whether the process consists of a single assay or a 
sequence of steps. True gold standard tests often do not really exist. For example, a 
routine mammogram may not detect a cancerous growth at an early stage, in which 
case a more definitive biopsy would not be performed. Moreover, a blood test for 
something like human immunodeficiency virus (HIV) may not detect the virus if it 
has only been present for a short period of time. Early stages of any infection or 
disease are often very difficult to detect. In addition, protocols designed to detect
481

482
Bayesian Thinking in Biostatistics
an infection may react to some benign biological agent as if it were the infective 
agent under scrutiny, even though it is not. This is called “cross-reactivity” and 
results in positive (“yes”) outcomes when the infective agent is not present.
A biomarker is a numerical outcome that is based on a measurement of a bio­
logical substance that is associated with a particular disease or infection. Most 
biomarkers may reasonably be regarded as continuous, with higher values indicat­
ing a greater chance of the condition being present.
We often use a threshold value of a continuous biomarker, forming a dichotomy. 
If a patient’s biomarker exceeds a cutoff, c, the patient is presumed to have the 
condition, and if the value is less than c, they are deemed not to have it. The cutoff 
is selected to optimize the relative costs of a false positive declaration, as when the 
biomarker exceeds c but patient is healthy, versus a false negative determination. 
The larger the value of c is, the lower the chance of a false positive and the higher 
the risk of a false negative declaration. The relationships are reversed for smaller 
values of c.
Many diagnostic outcomes are indeed yes or no from the outset. For example, 
a microscopic examination involves looking for an infectious organism with a mi­
croscope. The examiner either sees the organism in the material being inspected 
(possibly stool, urine, or blood) or they do not. Another example is a colonoscopy. 
If the gastroenterologist fails to see anything suspicious, the result is negative. If 
the examination identifies something suspicious, the result is “maybe,” in which 
case there is a follow-up procedure and submission of suspicious materials (often 
polyps) for analysis and a determination of whether or not the disease is present.
The first part of this chapter will deal with binary diagnostic tests under a 
variety of circumstances. For example, the diagnostic protocol may only involve a 
single dichotomous outcome (perhaps based on a sequence of single tests). There 
may instead be more than one protocol, resulting in two or more single-outcome 
tests. For example, one test may involve a microscopic examination and the other a 
blood biomarker that has been dichotomized. From a scientific point of view, interest 
may focus on which test is preferable. If one of the tests has smaller false positive 
and false negative rates, then it would surely be preferable, unless it was much more 
costly, in which case that aspect would need to be taken into consideration.
For the sake of brevity in an already long book, we have decided to omit dis­
cussion of having multiple biomarkers and situations where a gold standard test 
does not exist or is too expensive to use for routine diagnosis. We give references 
to these materials in the recap and readings section at the end of this chapter.
The second part of the chapter deals with biomarkers that are regarded as 
continuous. In this part of the chapter, we discuss what are called receiver operating 
characteristic (ROC) curves. Investigators use ROC curves to determine where to 
place the threshold for declaring the presence or absence of a condition. These 
curves provide a way to trade off false positive and false negative rates. We also 
show how diagnosis can be accomplished using the biomarkers without the use of 
arbitrary cutoff values as in the traditional way. Instead, one obtains a predictive 
probability of disease and uses this probability as a criterion. We also discuss ROC

Diagnostic Tests
■183
regression in which covariate information can be used to help with diagnosis in 
various ways.
15.1 Basics of Diagnosis with One Imperfect Binary Test and with 
Available Gold Standard Information
Let T refer to the outcome of a diagnostic test that yields a binary outcome, poss­
ibly after comparing a continuous marker to some accepted diagnostic threshold. 
The two outcomes are defined to be T+ and T-, with T+ indicating that the 
characteristic is present, and T- that it is absent. Notation for the characteristic 
actually being present is D+. We indicate the absence of the condition as D—. 
Just because the test indicates T+ or T- does not necessarily prove the presence 
or absence of the characteristic. As part of developing a diagnostic test for use, 
research studies determine the test’s characteristics relating to its accuracy.
Test accuracies are defined as the proportions of time the test correctly declares 
D+ and D-. These proportions are defined to be
Se = P(T+ | D+) and Sp = P(T- | £>-),
which are called the sensitivity and specificity of test T, respectively. The false 
positive and false negative error rates are
P(FP) = P(T+ | £>-) = 1 - Sp and P(FJV) = P(T- | D+) = 1 - Se.
If Se = Sp = 1, there is no chance of error. In this instance, the test is deemed 
to be perfect and is often called a gold standard (GS) test or a perfect reference 
standard test. The term “reference standard” refers to a primary use of such a test 
to assess the quality of another test that is likely imperfect. This chapter focuses 
to a large extent on assessing the quality of various tests, both when a GS test is 
available and when one is not.
Gold standard tests are not necessarily easy to develop and are often quite 
expensive. It is easily the case that a sequential protocol of the type described 
for breast cancer screening can result in a final definitive correct outcome. Such 
protocols are often invasive and/or expensive, as in the case of performing a breast 
biopsy after a mammogram. When testing for HIV infection, one initially performs a 
relatively inexpensive but imperfect enzyme-linked immunosorbent assay (ELISA) 
test. If the outcome is positive, one carries out an expensive western blot test 
(possibly several of them) until the diagnosis is definitive. Even so, this protocol 
cannot result in a GS test, because if the ELISA test is negative, the sample unit 
being tested could still be D+, resulting in a false negative outcome.
For now, we assume that a GS test is available, or that by some other means it is 
possible to know if certain individuals are D+ or D-. Suppose we have a random 
sample of ni individuals known to be D+ and an independent random sample

484 
Bayesian Thinking in Biostatistics
of П2 individuals known to be D—. This is often termed a “training sample.” In 
addition, we apply a suitable test (T) to all individuals for diagnosing D+ or D—. 
The outcome for each sample is the number of T+ and T— individuals. Let Yi be 
the number of positive outcomes (T+) in the sample of individuals known to be 
£>+, and let Y2 be the number of negative outcomes (T—) in the D— sample. With 
Se = F(T+ I £>+) and Sp = P(T- | D-),
Yi I Se ~ Bin(ni, Se), У2 I Sp ~ Bin(ri2, Sp).
We place independent beta priors on Se and Sp, which results in independent beta 
posteriors for the test accuracies. Statistical inferences are easily obtained using the 
methods we have already developed in the book.
Alternatively, we could take a random sample of size n from a population that 
includes both D+ and D- individuals. This design is termed “cross-sectional sam­
pling.” If a GS test is available in addition to a presumably imperfect test T that 
has sensitivity Se and specificity Sp, we could apply both tests to all n individuals. 
Table 15.1 depicts the outcomes from such as study. We can summarize the data 
with a 2 x 2 multinomial table of counts, у = {yij : i,j = 0,1}. In Table 15.1, yn 
is the number of true positive individuals in the sample, ую is the number of false 
positive outcomes, poi is the number of false negatives, and poo is the number of 
true negatives. These counts must add to n, the total sample size.
TABLE 15.1: Cross-classification of test outcomes
P+
D-
Row sum
T+
Уп
У10
У1+
T-
У01
У00
У0+
Col. Sum
У+i
У+о
n
The column totals give the number of D+ and D- individuals, and the row to­
tals give the number of T+ and T— individuals. The natural or empirical estimates 
of the sensitivity and specificity are Se = pn/p+i and Sp = уоо/у+о, respectively. 
Se is just the sample proportion of known D+ individuals that test positive (T+), 
and Sp is just the sample proportion of known D— individuals that the test says 
are negative (T-).
In order to make Bayesian inferences, we need prior distributions. For the sens­
itivity and specificity, we assume independent beta priors as before. Now the prob­
ability model for the data will also depend on the prevalence, 7г = P(D+). We place 
yet another independent beta prior on я.
We need to specify the likelihood function to proceed further. We define the

Diagnostic Tests
•185
matrix of probabilities p = {p^ : i,j= 0.1}. where
Ph = P(T+,D+) = P(D+)P(T+ | D+) = 7rSc.
Poi = P(T-,D+) = P(D+)P(T- | D+) = 7t(1 - Se).
Pio = P(T+,D-) = P(D-)P(T+ | D-) = (1 - 7t)(1 - Sp).
poo = P(T~, D-) = P(D-)P(T- | D-) = (1 - 7r)Sp.
We write p in tabular form in Table 15.2. The distribution of the data is Y | /» ~ 
Mult4(n,p).
TABLE 15.2: Joint outcome probabilities
T+
T-
D+
Pu = irSe 
Poi = тг(1 - Se)
________ D—________
Pio = (1 ~ тг)(1 - Sp) 
Poo = (1 - ir)Sp
Col. sum
P+i = *
p+0 = 1 - 7Г
Row sum 
Pi+ = P(T+) 
Po+ = P(T-) 
1
Under multinomial sampling, every entry in the table and every marginal total 
has a binomial distribution. For example, Y+i | n ~ Вгп(п,тг) and Гц | ir,Se ~ 
Bin(n,irSe). Also, the multinomial likelihood after simplification is
Lik(ir, Se, Sp) ос к5еИ»[7г(1 - Se)]
**
 [(1 - 7r)(l - W°[(l - тг)$рГ
= 7ry+* (1 - 7r)«+°Sew"(l - Se)v°'SpVo°(l - Sp)
*'
0. 
( J
Observe that the maximum likelihood estimate of the prevalence is just the sample 
proportion of D+ individuals, for the sensitivity it is the proportion of D+ samples 
that are T+, and for specificity it is the proportion of D— samples that are T—. 
Clearly, with independent beta priors for the three model parameters, the joint 
posterior consists of independent beta distributions. We leave it as an exercise to 
show this fact.
Before we consider an example, we briefly discuss some additional parameters 
of interest. We actually discussed this same problem from a more elementary point 
of view in Chapter 3. If an individual has just tested T+ for some affliction, they 
will likely be interested to know whether the they actually have the condition. That 
is, they want to know their positive predictive value (PPV), namely
РР^р(Р+|Г+) = т5е+(/Де)(1_эд.
Similarly, if they have just tested negative, they may be interested to know if they 
might, in fact, be D+, that is,

486
Bayesian Thinking in Biostatistics
where NPV, the negative predictive value, is the probability of being D— given 
that you tested T—. Although it is more common to report NPV, it may be of 
greater interest to know the chance that one is D+ given that one tested T-. We 
model our uncertainty about the estimates of prevalence and the test accuracies 
(Sp and Se) with independent beta priors, which leaves us in a position to make 
realistic inferences that reflect all uncertainty about unknown inputs.
Example 15. 1. The cross-classified multinomial data presented in Table 15.3, 
taken from Weiner (1979) and Pepe (2004) [350, 258], are based on a sample of 
1,465 men who were suspected to be suffering from coronary artery disease (CAD). 
Each man was subjected to an imperfect exercise-based stress test, EST, and to 
arteriography, which is a method of perfectly determining whether or not coronary 
heart disease is present. Maximum likelihood estimates are
Se = 815/1023 = 0.80, Sp = 327/442 = 0.74, ff = 1023/1465 = 0.70, 
~PPV = 815/930 = 0.88, NPV = 327/535 = 0.61.
Since the study involved a sample of men “at risk,” the estimate of prevalence may 
not be of much interest for use in the general population. We leave it as an exercise 
to give a Bayesian analysis of these data.
TABLE 15.3: Cross-classification of EST by disease status
CAD+
CAD-
Row sum
EST+
815
115
930
EST-
208
327
535
Col. sum
1,023
442
1,465
The next situation we consider is one in which there is partial verification of an 
initial but imperfect test’s outcome results. Suppose that one applies test T for a 
particular infection in a sample of “units.” If the outcome of the initial test on a 
unit is T+, the unit will undergo further testing with a perfect test; if the outcome 
is T—, no retesting is done. This is actually the standard protocol for HIV testing of 
blood donated for transfusion. Of course, if your blood test outcome were positive, 
you would want to know whether or not you were actually infected. Generally, 
a relatively inexpensive and highly accurate but imperfect ELISA test is applied 
to blood donors as an initial screening test. Units that test positive with ELISA 
(ELISA+) are retested with a western blot (WB) test. Regardless of the outcome 
of the retest, the blood is discarded. If the outcome is ELISA—, the blood is then 
available for transfusion. We do not know the actual status of the units that are 
ELISA—, only that they are negative by the test. It would be incredibly expensive 
to apply the WB test to all donated units. Moreover, it would be anticipated that 
the NPV would be close to 1, indicating that most of the ELISA negatives would 

Diagnostic Tests
indeed be disease free. Thus it is generally the case that ELISA- units are not 
retested. Table 15.4 is a representation of data of this type.
TABLE 15.4: Cross-classification of test outcomes when T— outcomes are not veri­
fied with a gold-standard test
D+
D-
Row sum
T+
Ун
Ую
У1 +
T-
NA
NA
Уо+
Col. sum
У+1
У+о
n
Suppose we wish to estimate Se and Sp for the ELISA test that is used for 
testing for HIV infection. Our discussion here applies to generic tests, T, under 
similar circumstances. In such situations, a random sample of size n units from 
the population of interest is taken, and all units undergo testing with test T. Let 
у be the number out of n that are T+ and n - у the number that are T-. We 
have Y | ir,Se,Sp ~ Bin (n, P(T+)), where P(T+) = P(T+y D+) + P(T+, D-) = 
irSe + (1 - 7t)(1 - Sp). Suppose that incorrectly classifying a D+ unit as D- might 
be dangerous or costly. This is certainly the case when testing for HIV since, if 
an HIV+ sample is not detected, the individual involved may not get appropriate 
treatment and they may infect other individuals unknowingly.
Under the above circumstances, we would surely also be interested in estimating 
PPV = P(D+ | T+) = TrSe/[irSe + (1 - zr)(l - Sp)]. It is easy to show that 
PPV is monotone and increasing in Se and in Sp, and that PPV increases to 
1 as Sp increases to 1. The false negative rate is P(D+ | T-) = 1 - NPV = 
7r(l—Se)/[7r(l-Se)+(l-7r)Sp]. We see that 1-NPV decreases toOasSe increases 
to 1. Therefore, in order to protect the blood supply, it is clearly important to have 
a very high sensitivity for the ELISA test. Also, for the sake of a person who tests 
positive by ELISA, it is most important to have a high-quality follow-up test.
Looking at Table 15.4, we see that the counts poi and pOo are missing but 
their sum is available. The data are still multinomial but now there are only three 
cell probabilities in the multinomial sampling distribution instead of four as in 
Table 15.1. Now, Y | рц,рю,Ро+ ~ Mult3(n, {pn,Pio,Po+})- The corresponding 
likelihood is
Lik(Tr,Se,Sp) ex ttW11(1 - 7r)"‘°Se«ll(l - Sp)v'°[тг(1 - Se) + (1 - 7r)Sp]
*°+.
 (15.2)
It is clear that the joint posterior will not be recognizable with this likelihood, but 
we can still carry out Bayesian inference, especially with an iterative computational 
approach like MCMC.
Example 15. 
2. UK HIV Data. We consider HIV test data for blood donors from 
the UK that were previously analyzed by Johnson and Gastwirth (1991) [187]. The 
data were collected in 1986 with n = 3,122,556 samples that were tested using a 
Welcome ELISA. Among these samples were y+i = 373 positive outcomes that were 

488 
Bayesian Thinking in Biostatistics
retested with a western blot test (WB); 64 of those were positive. This results in 
2/n = 64 true positives, y\o = 373 — 64 = 312 false positives, and y+Q = 3,122,183 
negative outcomes. We encourage the reader to see Gastwirth and Johnson (1990) 
[122] and Johnson and Gastwirth (1991) [187] for considerable discussion about 
prior specification.
We selected the main prior used in [187] for our illustration here. We specified 
7Г ~ Beta(15,94092), Se ~ Beta(142,2), and Sp ~ Beta(1363,3). The prior on 
7Г has median 0.00016, and 99th percentile 0.00027, reflecting the belief that the 
prevalence of HIV in blood donors in the UK in 1986 was quite small, but that we 
are still relatively uncertain about how small. The median and first percentile for 
the prior on Se are 0.988 and 0.954, respectively. Thus, we are 99% sure that the 
ELISA Se is greater than 0.95. The median and first percentile for Sp are 0.998 
and 0.995, respectively.
Output from our data analysis is presented in Table 15.5 using our specified 
prior, prior 1 in the table, and a much less informative prior, prior 2. (The data 
and programs for these analyses are available in the Chapter 15 section of the book’s 
website. The file names include HIV.) Note that with both priors, the precision for 
the ELISA Sp is incredible and the same. The results for Sp suggest that we would 
only expect to see between 8 and 12 false positives per 100,000 HIV tests, with 
99.8% certainty. In addition, the prevalence of HIV in the sampled population is 
expected to be between about 2 and 3 individuals per 100,000 tested, with 95% 
certainty. Perhaps most importantly, if we consider blood units that have tested 
ELISA-, then we expect between 4 or 5 and 110 out of every 100 million blood 
units that have passed through the system to carry HIV positive blood. All of these 
results are virtually the same under both priors.
TABLE 15.5: Posterior inferences for UK HIV data. PM=posterior median. (PI) = 
probability interval. Prior 1: тг ~ Be(15,94092), Se ~ Be(142,2), Sp ~ Be(1363,3). 
Prior 2: тг ~ Be(0.5,99.5), Se ~ Be(142,2), Sp ~ Be(13.6,0.03).
Prior 1
Prior 2
PM
(PI)
PM
(PI)
Se
0.987
(0.958,0.998)
0.988
(0.962,0.998)
Sp
*
0.99990
(0.99988,0.99992)
0.99990
(0.99988,0.99992)
7t(x10-5)
2.48
(1.97,3.08)
2.49
(1.97,3.11)
PPV
0.20
(0.16,0.24)
0.20
(0.16,0.24)
(1 - NPVy
0.0316
(0.0045,0.1098)
0.0310
(0.0043,0.1079)
‘Pls are 99.8%, all other intervals are 95%.
Before finishing the data analysis, we need to discuss results that were developed 
in [122] and [187]. They investigated the HIV testing problem discussed here from 
a theoretical standpoint. They assumed the generic situation with a large sample 
size n. with a low prevalence disease, and where available tests would have high 
accuracy, which is clearly the case in the current illustration. They also assumed 
that with a Beta(o.b) prior for тг, the parameter a would be considerably smaller 

Diagnostic Tests
489
than b, with a Beta(ai, b}) prior for Se, ai would be considerably larger than bi. and 
that with a Beta(a2,62) prior for Sp, a2 would be considerably larger than b_>. Under 
these assumptions, they showed that the approximate posterior for St- would be the 
prior for Se. Their approximation to the posterior for Se is Se | у ~ Be(142,2) in 
the case of both priors discussed here. The results for Se in Table 15.5 show very 
close similarity under both priors 1 and 2 since the marginal priors for Se. are the 
same. When we analyzed these data with a 17(0.9.1.0) prior for Se. we noted in a 
plot of the posterior for Se that it was precisely the same as the prior.
Recall that we essentially have a missing-data problem here, since we only ol>- 
serve the marginal total of the number that test negative. Instead of a multinomial 
of dimension 4, we only have dimension 3. Since the sum of the multinomial counts 
must be n, we went from having three bits of information for estimating three 
parameters to having only two bits of information for estimating three parameters. 
Something had to give, and here, while it was not obvious until now, we find that 
we have no information in the data for estimating Se.
In addition, [187] showed that, under the low prevalence, high accuracy, large 
sample assumptions, we have
7ГI j/~Be(a 4-3/n,b +г/о+), Sp | у ~ Be(a2 + у0+,Ь2 + ую),
(lo.o)
PPV I у ~ 7T(1 - Se)|y, (1 - NPV) I у ~ tr/fr + 1 - Sp)\y,
where the notation ~ means “is distributed approximately as.” We carried out an 
analysis in which we calculated these approximations. We found them to be highly 
accurate, meaning that results using them were virtually identical to the results 
using no approximation. In addition, we can infer that there is information in the 
data and the prior for Sp and тг, which implies there is also information in the data 
for NPV under our assumptions. Since there is no information in the data for Se, 
it is clear that the PPV will be highly affected by the choice of prior for Se.
As a final note on this example, our Bayesian analysis gave 0.9999 for the 
posterior mean of Sp and all three quantiles (0.025,0.5,0.975). We used the beta 
approximation given in expression (15.3) in R to obtain the 99.8% Pls given in 
Table 15.5.
15.2 Continuous Biomarkers
We now focus on biomarkers that are continuous. In previous sections we considered 
continuous biomarkers that had been dichotomized (think ELISA) and others that 
were actually dichotomous, as in the case of microscopy where one either sees the 
“organism” or not. For those biomarkers that were continuous, someone decided on 
a cutoff that turned the outcome into a binary biomarker. Let у be the outcome 
of a continuous biomarker and suppose that large values of у are associated with 
an individual having the infection of interest. One might select a value, say k, and 

490
Bayesian Thinking in Biostatistics
give the diagnosis T+ if у > к and T- if у < k. For any particular choice of k, we 
have Se(fc) = P(Y > к | D+) and Sp(fc) = P(Y < к | D-).
Figure 15.1 displays density functions for a biomarker’s distribution in the D— 
and D+ populations. We see that the area to the right of к under the density 
function for individuals in the diseased or infected group is Se(fc), and the area to 
the left of к under the density function for healthy individuals is Sp(fc). Observe 
that as Sp(k) increases, Se(fc) decreases, and vice versa. Thus, a value of к that 
results in a good sensitivity may also result in a poor specificity.
40 
50 
60 к 70 
80 
90 
100 
110
FIGURE 15.1: Possible distributions for a continuous biomarker applied to D— and 
D+ individuals with hypothetical cutoff value k.
How should we select the value of к if we are dichotomizing a continuous 
biomarker? If we assessed the costs or losses associated with misclassifications, we 
could develop a decision rule that would choose the value of к that minimizes the ex­
pected loss. A simple approach would assign a loss of zero to a correct classification 
(e.g., T+ if D+ is the true state) and a non-zero loss for each misclassification (e.g., 
T+ when D— is the true state). The expected loss would be a weighted average of 
the false negative and false positive losses, where the weights are the probabilities of 
making the respective misclassifications. We compute these misclassification prob­
abilities based on the underlying probability model, which provides the sensitivity 
and specificity for any cutoff k. The goal is to find a decision rule that makes this 
loss small. In general, we will simply take the posterior mean of this quantity for 
as many rules we wish to consider (e.g., on a grid of possible biomarker cutoffs fc) 
and then select the rule k*,  say, with the smallest value.
Less formally, we will consider the tradeoffs involved in considering estimates 
of the pairs (1 - Sp(k). Se(k)) = (FP(k),TP(k)) for all possible choices of k. The 
ideal cutoff would yield the value (0,1). but this would imply that there was a GS 
test, which is rarely going to be the case. In general, we want FP(k) to be small, 
and TP(k) to be large. Cutoffs are generally selected by scientists who weigh the 
benefits and risks associated with having larger Se versus smaller Sp and vice versa.

Diagnostic Tests
-191
15.2.1 Receiver Operating Characteristic Curves
A plot of FP(k) versus Se(k) across all possible values of к is called a receiver 
operating characteristic (ROC) curve. An example of such a plot is given in Figure 
15.2. We now discuss how to model continuous biomarker data and how to estimate 
ROC curves.
FIGURE 15.2: Plot of ROC curve (solid) with 45-degree line (dashed).
For any cutoff k, a major criterion for a useful biomarker is that TP(k) = 
Se(k) = P(Y > к | Z>+) > P(Y > к | D-) = FP(k). We only consider biomarkers 
for which ROC curves are above the 45-degree line from (0,0) to (1,1) in the plot 
given in Figure 15.2. Since ideal ROC curves tend to increase rapidly from (0,0) up 
to the upper left-hand corner, (0,1), of this plot, the area under the curve (AUC) 
can be used to determine how useful the biomarker у might be for accurately 
classifying an individual or diagnosing a condition. If the curve is the 45-degree 
line, AUC = 0.5. If we were to simply toss a coin to decide T+ or T— for each value 
of k, we would have P(T+ | D+,k) = P(T- | D-,k) = 0.5. The ROC curve for 
this classifier would simply be the 45-degree line and would of course be useless. 
On the other hand, a perfect classifier would have AUC = 1. A perfect classifier 
can only occur if the support of the biomarker for healthy individuals is (virtually) 
completely separate from the support for the infected or diseased individuals. AUCs 
that are close to 1 are indicative of good classifiers, and AUCs near 0.5 indicate 
poor accuracy for any k.
We need models for Y | D+ and for Y | D—. We begin with generic parametric 
models. Let Y | D+,6\ ~ G\, where Gi(-) is a cdf with pdf <n(- | 0\), and Y |

492
Bayesian Thinking in Biostatistics
D-,Oq ~ GQ(-) where Go(-) is a cdf with pdf go{' | #o)- We drop the dependence 
of the cdfs on parameters for convenience. Survival curves, which are defined as 
1 minus the cdf of the associated random variable, are discussed in Chapter 11. 
Here we define the corresponding survival curves for the cdfs Go and Gi as So(t) = 
1 - G0(t) = P(Y > t | D-) and Sj(t) = 1 - Gi(t) = P(Y > t | D+). Our goal is to 
obtain an equivalent way of expressing (TP(k),FP(k)) by a change of variables, so 
that the new expression gives the same ROC curve. Almost immediately, we will 
have a simple expression for the AUC as well.
Consider the change of variables FP(k) = So(fc) = t. Then к = Sq1^) and 
Se(k) = Si(fc) = Si [So"1 (t)]. Define
ROC(t) = S1[S0-1(t)]. 
(15.4)
Then the plot of (So(A:), Si (A:)) for all к is our definition of the ROC curve, and this 
is precisely the same plot as for (t, ROC(t)) over all t 6 (0,1). Since, in general, 
к 6 (—oo, oo), the latter plot is much simpler.
By definition,
AUG = [ ROC(t)dt= [ Si[So\t)]dt = [°° S\{v)go{y)dv 
J0 
Jo 
J — oo
after changing variables to v = S^^t), which implies that t = So(v) and dt = 
-g0(y)dv. This is just the probability that a biomarker response for a D+ individual 
exceeds an independent biomarker response for a D— individual. To see this, let 
Yi ~ Gi be independent of Уо ~ Go- Then
P(Yi > Уо) = У°° P(Yi > Уо | Уо = v)g0(v)dv
= f P(Y\ > v)g0(v)dv = [ Si(v)g0(v)dv, 
J — oo 
J—oo
where we have used the law of total probability and the independence of Ух and Уо.
Example 15.3. Binormal Model. In this example, we assume that the pdfs g0 
and gi are normal. Thus we have that
Уо | D—,^o,ctq ~ N(ji0,cfy, У1 | D+,/zi,<rf ~ AT(^i,ct?)
independently. We are thus assuming that the continuous (biomarker) outcomes 
Уо and У are independent and normally distributed, conditional on disease status. 
This is often called the “binormal” distribution since the specification involves two 
normal distributions, one for each of two types of individual being sampled. The 
binormal distribution is illustrated in Figure 15.3.
Eventually, we will have either independent samples from these distributions if 
GS information is available, or a mixture of these distributions, where тг = P(D+) 
will be the mixing proportion. Moreover, it will often be the case that the actual 
bioniarker outcomes are not normally distributed, but a transformation of them

Diagnostic Tests
193
150
Serology Score
FIGURE 15.3: Binormal distribution.
might be reasonably approximated by a normal distribution. For now, we are sim­
ply interested in obtaining the ROC curve and AUC assuming binormality of the 
biomarker distribution.
Let Ф(-) and ф(-) denote the standard normal cdf and pdf, respectively. Then 
po(l/) ос е-о-5(у_до)2/сто <x ф([у - до]Ло), and gi(y) oc 
х <^([y _
Д1]/<Т1). Then
ROC{t) = P(y1>S0-1(i)) = P(ri>G0-1(l-t))
= P(Y\ >^о + аоф-1(1-<))
= P([Yi - /л]Л1 > [до - Mi + <т0Ф-1 (1 - i)]/<Ti)
= 1 — Ф(—a 4-ЬФ-1(1 -t))
= Ф(а + Ьф-1(<)) 
(15.5)
where a = (mi - and b = ao/a\. Exercise 15.15 asks the reader to establish 
the details that have been skipped in this demonstration.
We move on to the AUC. We have AUC = P(Y\ > Уо) = Р(У1 - Уо > 0). But 
У1 - Уо ~ /V(/zi - д0,<Т| + ag), so
AUC = 1 - Ф
(15.6)
Thus the more separated the two distributions are, the larger the AUC and the 
better will be the accuracy of diagnosis using the given biomarker.
15.2.2 Diagnosis Based on Continuous Biomarkers
Dichotomizing continuous biomarkers involves a loss of information. Here we discuss 
an alternative method of diagnosis that uses the actual value of у that is observed.

494 
Bayesian Thinking in Biostatistics
Consider Figure 15.4, for example. We see four observed values of a biomarker у and 
a cutoff к = 65. We continue to think of larger values of у being associated with 
the disease state and smaller values being associated with the non-disease state. 
With the given cutoff 65, the individual with the value 64 is classified T—, while 
the much smaller value, 40, is also classified T—. The value 66 is classified T+, 
while the much larger value 110 is also classified T+. There is barely a distinction 
between 64 and 66, but there is a huge distinction between 40 and 110. Despite the 
relative nearness of 64 to 66, the use of a cutoff forces classification of individuals 
with marker values 64 and 66 to be classified the same way they would be if their 
markers were 40 and 110, respectively. One would expect that P(D+ | у = 110) » 
P(D+ | у = 66) = P(D+ | у = 64) » P(D+ | у = 40). Using the cutoff 65 to 
decide is quite blunt by comparison with what could be much more nuanced if the 
actual values were used for diagnosis.
V
Y? Y3
____ Y4
40
64 66
110
k=65
FIGURE 15.4: Dichotomizing a continuous biomarker.
The observed data for the classical problem of diagnosis with only two categor­
ies involves sampling two distinct populations of interest. The goal is to use the 
information in the samples to form a diagnostic rule for allocating each new indi­
vidual with unknown population origin to one of the two. This is precisely what we 
have been talking about with the two categories (with or without the condition). 
R. A. Fisher tackled this problem decades ago with his development of discrimi­
nant analysis. Fisher considered the problem of sampling multivariate observations 
on individuals from two or more distinct populations. He cleverly devised statist­
ical methodology for using the data to allocate individuals with unknown status 
to one of the populations. From this point of view, the collected data are called 
“training data.” In light of our previous discussion, a training sample involves the 
ability to ascertain which individuals are infected and which are not through the 
use of some form of GS information. We assume the GS case. We briefly discuss 
the no-gold-standard (NGS) case in the recap and readings for this chapter.
Observed continuous biomarker data are represented as у = {yij : i = 0,1; j = 
1,.... n,}. where the index i = 0 corresponds to the sample of healthy individuals 
and i = 1 corresponds to infected or diseased individuals. While the y^ can be 
multivariate, we only consider the univariate case. In the next section we assume 
binonnality for the when it is time to make statistical inferences.
Consider the generic parametric model for the biomarker data,
Fij | D+,<?i X Pi(- I QiY i = 0,1; j = 1,... ,пг-

Diagnostic Tests
■195
Let в = (0o,0i) be the collection of unknown model parameters. The goal is to 
use this model and these data to diagnose the unknown disease status of a new 
individual with observed biomarker value, say j/p but whose group status Zf (which 
takes the values 1 = D+ or 0 = D-) is unknown.
Let the unknown prevalence of disease be тг = P(D+). We assume the same 
model for the future observation Yf conditional on disease status. The disease status 
of the new individual, Zf equals 1 if they are D+ and 0 if they are D-. .4 priori. 
Zf ~ Ber(ir). The marginal model is the mixture
Р(У/ I = P(Zf = O)po(!// | z} = O,0o) + I\Z} = l)pt(t> | Zf = 1,0»), 
or equivalently,
We assume that the current collection of biomarkers, Y, and the new individual's 
pair (Zf,Yf) are independent conditional on (0,7r).
We require a prior distribution for the above parameters. From now on we 
assume knowledge about these parameters can be specified independently as
р(тг, 0o, 0i) = р(л-)р(0о)р(01)-
In the case of the binormal distribution 0, = (Дг,<т$), and we will assume these two 
parameters can be regarded independently, as well.
Let 7 = (0,7r). The Bayesian method of diagnosis is to simply obtain the pos­
terior probability of disease,
P(Z = l\y,yf) = P(D+ | y,yf)
= I P(Z = 1 I 7,P,P/)p(7 I У,У/№
= У*  P(Z = 1 | 7,1//)p(7 I 
(15.7)
~ I I г = if?) + (I - I X = o,7)p(71 v'
° / I - - Xo - XI 1
where we have used Bayes’ theorem and the conditional independence of (Z, Yf) 
and Y.
Diagnosis without dichotomizing the biomarker by thinking about the Se/Sp 
tradeoff would follow by calculating P(Zf | y,yf) and deciding that Zf = 1 if this 
quantity is sufficiently large (see Thurmond et al., 2002 [326]; Choi et al., 2006 [75]; 
Norris et al., 2009 [251]). For example, if the ratio is 0.9999, most people would 
be comfortable saying that the individual was indeed D+. For mass screening, one 
could decide to say D+ if this probability exceeds 0.95, say, and D— if it is below 
0.05, and remain undecided otherwise. There are obviously many possibilities. If 
one can quantify the costs or losses associated with making classification errors, 
one can obtain the posterior risk and decide on a rule on that basis.

496
Bayesian Thinking in Biostatistics
15.2.3 Statistical Inference for Binormal Diagnostic Outcome Data: GS 
Case
While there are many possible forms of data that could be observed, we only con­
sider the univariate binormal case. We have
Yij | Цо,-IL N(ji.i,0i), i = 0,1; j = 1, • • • ,Щ.
These are obviously just two-sample normal data with unequal variances, which 
were discussed in detail in Chapter 5 and other chapters. The data may well have 
been transformed to better approximate binormality, using the same transformation 
for both samples.
Statistical inferences are quite straightforward and were previously discussed for 
this type of data. We are mainly interested in functions of the model parameters, 
such as the AUC and the ROC curve. If one uses conjugate priors, the posteriors for 
the model parameters are available in closed form. Since the parameters of interest 
are complicated functions of the model parameters, however, we use numerical 
approaches such as Monte Carlo methods to make our inferences. We have found it 
more efficient to obtain an MCMC sample from the joint posterior for (^0, hi , 0o, ) 
and then carry out post-processing of the posterior samples to make inferences 
about the ROC curve, the AUC, and predictive probabilities of disease.
Example 15.4. Diabetes Data: GS Case. Diabetes is a metabolic disease 
mainly characterized by high blood sugar concentration and insulin deficiency or 
resistance. Normally, the pancreas releases insulin to help the body store and use 
sugar from food. Diabetes can occur when the pancreas produces very little or no 
insulin or when the body does not respond appropriately to insulin. Diabetes is en­
demic in the U.S. and is a leading cause of blindness, kidney failure, amputations, 
heart failure, and stroke.
The data considered here were taken from a pilot survey of diabetes in Cairo, 
Egypt. The data consist of blood glucose measurements (milligrams per deciliter) 
from 286 subjects. High blood glucose is associated with acquiring diabetes. Based 
on World Health Organization criteria, 88 subjects were classified as diseased and 
198 as healthy (Smith and Thompson, 1996) [298]. Our method of assessing the 
quality of blood glucose measurements as a biomarker for diagnosing diabetes will 
be based on gold standard data.
Histograms for subjects classified as diseased and for subjects classified as 
healthy were obtained and scrutinized. We also plotted a histogram of the data 
after Box Cox transformation (Box and Cox, 1964) [46] and decided that the nor­
mality assumption was reasonable enough to consider for the untransformed data. 
We leave it to exercises for the reader to make these considerations on their own. 
We analyze the data as binormal.
Predictive densities using this model are given in Figure 15.5. The densities 
overlap considerably, and the center of the distribution for the diabetic subjects is 
shifted considerably to the right. We also note that the two distributions’ standard 
deviations appear to be quite different, the one for diabetics being considerably 
larger than that of the healthy subjects. Because of the considerable overlap, there 

Diagnostic Tests
■197
is no hope of having anything near a perfect diagnostic rule for any cutoff, nor is 
there any hope of having an AUC that is close to 1.
FIGURE 15.5: Predictive densities for healthy (dash) and diabetic (solid) patients.
We treat the problem as if we have virtually no knowledge about the science of 
this particular study and employ diffuse priors for the model parameters, which are 
the means and the standard deviations of the two populations. The range of the 
observed data for the healthy group was (57,275) mg/dl, and the corresponding 
range for the diabetic group was (80,484) mg/dL. The means of the corresponding 
populations are virtually certain to be within these rather wide ranges. For the 
two populations’ means, our priors are до ~ AT(100,1000) and Д1 ~ 7V(250,10000), 
which correspond to normal distributions with rather diffuse 95% prior probability 
intervals for mean glucose levels, (38,163) and (50,450), respectively. These inter­
vals are so wide that we hardly admit to having cheated by looking at the data to 
set the prior distribution.
We selected ъ X Ga(0.1,0.1) priors for the precisions. For normal data, 
these priors are diffuse and generally allow the data to speak for themselves. In­
duced priors on the standard deviations have 95% prior probability intervals of 
(0.32,40,000,000), which is silly but will have little impact on the posterior.
Table 15.6 summarizes the results. The posterior densities of до and Д1 are 
in Figure 15.6. There are clear statistically important differences in these means. 
Because of the large overlap in the data (see Figure 15.5), however, this is not 
of much interest to us for diagnosis. The AUC is estimated to be 0.86 with 95% 
PI (0.80,0.91); the corresponding posterior density is shown in Figure 15.7. The 
estimate (0.86) is not a large value, meaning that we do not expect to be able

498
Bayesian Thinking in Biostatistics
TABLE 15.6: Posterior medians and 95% Pls for population means, standard de­
viations, and the AUC for the diabetes data
Med (95% PI)
AUC
Ц0
Mi
co
ci
0.86 
100.6 
212.8 
28.1 
100.0
(0.80,0.91) 
(96.8,104.5) 
(191.8,233.8)
(25.6,31.2)
(86.8,117.1)
FIGURE 15.6: Posteriors for /zq and /zi for blood sugar glucose measurements.
to find a cutoff that would give both particularly large Se and Sp values. The 
estimated ROC curve with pointwise 95% probability limits is given in Figure 15.8.
We can glean from Figure 15.8 that it is possible to have 95% specificity with 
75% sensitivity, or 84% specificity with 80% sensitivity. In practice, it will be im­
portant to find the corresponding cutoffs. In the former case, it is 146.8 mg/dl, 
and in the latter case, it is 128.7 mg/dl. We obtain these values using the fact 
that, with cutoff fc, we have S'o(fc) = t (see equation (15.4)). Thus, we set 
So(k) = 0.05 in the former case (i.e., 95% specificity), and 0.16 in the latter. 
In the former case, we have 0.05 = 1 - Ф((/с - /z0)/cr0) = 1 - Ф(1.645). Solving 
the equation gives к = /z0 + 1.645<tq. Thus, the estimate of к in this instance is 
100.6 + 1.645 x 28.1 = 146.8.
15.2.4 ROC Regression: GS Case
It is often the case that there are additional biomarkers and/or covariates that 
are related to the biomarkers and/or disease status. When multiple biomarkers are 
available, it is necessary to model them jointly, conditional on disease status. The 
issue becomes even more interesting and complicated when multiple biomarkers are

FIGURE 15.7: Posterior density for the AUC.
observed longitudinally, with the goal of diagnosing an infection or illness over time. 
This effort is beyond the scope of our book. For an illustration with two biomarkers 
see Norris et al. (2009) [251].
Here we discuss how to use covariate information to improve biomarker-based 
diagnosis while at the same time possibly making the model identifiable (Branscum 
et al. (2008, 2015), [50, 49]). The modeling is straightforward as it simply involves 
specifying a linear model for the biomarker in the disease group, for the healthy 
group, or both.
We represent the data as {(j/y ,Xy) : i = 0,1; j = 1,... ,71,}, where the Xy are 
covariates that are associated with the biomarker of interest. Consequently, these 
covariates may be indirectly related to disease status. For ease of presentation, we 
assume xtJ is a scalar covariate, such as age, for the Jth individual in disease status 
group i. We set i = 0 for the healthy group and i = 1 for the “diseased” group. In 
our next example, we will assess whether it is easier to diagnose diabetes in younger 
people based on blood glucose than it is in older people.
First, we write the model as a form of binormal linear model.
Yij.\xij,/3,0 J-NtPn+faxijrf), i = 0,l; j = 
(15.8)
where 0 = [£0,£i] = [(^01,^02), (£11,£12)] and 0 = (<70,<ti). This is another situ­
ation where a conjugate prior for each regression would make the posterior analyt-

500
Bayesian Thinking in Biostatistics
FIGURE 15.8: Posterior median for the ROC curve with pointwise 95% posterior 
probability intervals.
ically tractable. With conditionally conjugate priors, the Gibbs sampler would be 
quite easy as well. However, none of this is necessary when using a general MCMC 
program (e.g., BUGS, JAGS, or Stan), since sampling from the corresponding un­
recognizable full conditionals has been automated in those packages.
Here, we could specify normal priors for /?o and /3\ and independent gamma 
priors for the precisions To = l/of and Ti = l/of, with the ъ independent of 
the fa. This specification results in conditional conjugacy for the pairs (fa,Ti), 
i = 0,1, as was discussed for a single normal regression sample in Chapter 7. We, of 
course, recommend induced priors via conditional means priors, which we discussed 
in Chapter 7. Such prior specification was particularly straightforward to do with 
only one or two predictor variables. We also advocate for the use of uniform priors 
for the ai over appropriately specified ranges, as we have done in previous examples. 
Conditional conjugacy remains for fa but not for n, though.
On the other hand, the proper reference prior here specifies fao X fa\ ~ 
Ar(0.10G) and Ti X Ga(0.001,0.001), which is simply an approximation to p(/?,r) oc 
r. In this case, as discussed in Chapter 7, we expect posterior inferences to be quite 
reasonable. Of course, we always advocate for using informative priors when suitable 
information is available.
With this model, we can perform ROC regression. In the previous section we 
assumed Yij | //,о X •№(//,, af), and we obtained the formulas in equations (15.5) 
and (15.6) for the ROC and AUC, respectively. These formulas were written as 
explicit functions of // and o. All we need to do now is replace //j with /Зц + fa?x, 

Diagnostic Tests 
501
where x is a particular covariate value of interest. We would generally select several 
values of x to study. Define
5ц - 5oi + (512 - ,502)x 
(To
ax =--------------------------------- and b = —.
<T1 
(T1
We see immediately that
ROCx(t) = Ф(ах 4- ЬФ-1(<)) and AUCX = Ф p) • 
(15.9)
What does this mean? The ROCX curve plots the false positive rate. 1-Spx(k) = 
P{Yq > k | x), against the true positive rate, Sex(fc) = P(Yi > k | x), where 
these quantities have been modeled to depend on the covariate x. Implicitly, these 
quantities also depend on (5, cr). As x grows, the difference in the two means, which 
equals 5n - 5oi + (512 - 5ог)^, will grow if the slope for the affected population 
is larger than the slope for the healthy population. In this case, AUCX increases 
as x increases, resulting in the possibility of having better diagnostic performance 
for larger values of x. Of course, if the difference in slopes is negative, diagnostic 
performance will be better for smaller values of x.
We note that it can easily be the case that 5ог or 512 or both could be negligible. 
In the case of ROC regression, it will be important to perform an initial analysis 
to determine if modeling the covariate in healthy and/or non-healthy samples will 
potentially be worthwhile.
Example 15.5. Diabetes Data with Age as Covariate. We augment the blood 
glucose data for 286 individuals with their ages. Our analysis uses what we have 
termed the binormal regression model with the reference prior just discussed. In 
exercises, we ask the reader to obtain ROC curves that depend on age. Results of 
our analysis are summarized in Table 15.7, where we include inferences for AUCx=4o 
and AUCx=7q, the areas under the ROC curves for 40-year-olds and 70-year-olds. 
In the analysis, we standardized the covariate age by subtracting its sample mean 
and dividing by its sample standard deviation.
We first fit model 2, which is the model that includes both slopes. Model 1 
excludes the slope for the diabetes group (51г), since its 95% PI was very wide, 
(—36.5,25.7), with zero in the middle. Additional reasons in support of model 1 are 
that P(5i2 > 0 | y) = 0.37 and DIC = 2,927 for model 2, while it was 2,925 for 
model 1. We also note that all the inferences not shown for model 2 were virtually 
identical to those for model 1, while intervals for the AUCs are appreciably wider 
than they are in model 1. For better or worse, the implication of choosing model 
1 over model 2 is that we are accepting the hypothesis that age is not related to 
blood glucose measurements in diabetics, but it is in healthy individuals. At the 
very least, there is no evidence in the data that there is a relationship in the diabetes 
group, while there is appreciable statistical evidence that there is a relationship in 
the healthy group where blood glucose appears to increase with age.
Observe that inferences for the intercept and standard deviation for the dia­
betes group are virtually identical to those obtained in Table 15.6, which is not

502
Bayesian Thinking in Biostatistics
TABLE 15.7: Posterior medians and 95% Pls for population means, standard devi­
ations, and AUCs for the diabetes data with covariate Age. Model 1 excludes the 
slope ^12, while model 2 includes it
Model 1
DIC = 2,925
Med.
(95% PI)
aucx=70
0.83
(0.76,0.88)
AU Cx=4o
0.87
(0.81,0.92)
£01
101.8
(98.1,105.5)
A)2
8.9
(5.5,12.4)
011
212.5
(191.2,233.5)
012 = 0
NA
NA
<70
26.5
(24.0,29.3)
<71
100
(86.8,116.9)
Model 2 DIC = 2,927.0 P(012 > 0) = 0.37
aucx=70
AU CX=4Q
0.81
0.88
(0.68,0.9)
(0.78,0.94)
012
-5.2
(-36.5,25.7)
surprising, since the model for this group is the same in both analyses. The very 
small differences in results are simply due to Monte Carlo error. The estimate of 
the intercept in the healthy group corresponds to average blood glucose for an in­
dividual of average age. It is not surprising that inferences for the intercept are 
similar to (but still different from) the previous analysis that did not take age into 
account.
The most interesting aspect of the analysis is that the estimated AUCs for 
40-year-olds are noticeably different than those for 70-year-olds. Since we clearly 
have /312 — Z?o2 = —002 < 0, we are in the situation where the AUC decreases as age 
increases. The estimated value of AUC40 - AUC70 is 0.04 with 95%PI (0.025,0.063), 
and up to four decimal places, the posterior probability that the true difference is 
positive is 1.0. Thus, it appears that it will be easier to diagnose 40-year-olds than 
70-year-olds when using only blood glucose as a biomarker.
15.3 
Recap and Readings
We have covered many topics in this chapter, including the assessment of the qual­
ity of dichotomous tests and prior specifications for model parameters. We also 
discussed how to model continuous biomarkers and how to use those models to 
estimate receiver operating characteristic curves that one can use to ascertain how 

Diagnostic Tests
503
to select cutoffs for future dichotomous tests. We discussed how to calculate predic­
tive probabilities of disease for individuals who might benefit from a more personal 
diagnosis based on appropriate biomarkers. We extended the gold standard results 
to depend on covariates, and we discussed the advantages of taking account of the 
extra information that comes from this extension.
One of the key goals in diagnostic testing is to ascertain if one test is better than 
another. Clearly if one test has higher test accuracies than another, it is preferable 
on those grounds. On the other hand, if it costs 100 times as much to apply the 
better test and many units will be tested, more thought may be required to make a 
decision. Making such inferences based on binary tests in the GS case was relatively 
straightforward, since many useful and relevant tools had already been developed 
in previous chapters.
Extension to the NGS case is actually much more challenging, since this involves 
the application of two or more tests to each unit to be tested, the subsequent 
modeling of often dependent multiple binary test outcomes, and the need to deal 
with the lack of identifiability that usually ensues in this case. The development 
of such models starts with Hui and Walter (1980) [169], who discussed the NGS 
model for two diagnostic test outcome data under the assumption of conditional 
independence for the two tests and assuming samples from distinct populations of 
individuals. Using their model, and under their assumptions, it is possible to assess 
the test accuracies for the two tests and consequently to ascertain whether, say, a 
new test is preferable to a standard reference test. This work has been the starting 
point for considerable subsequent work, including Bayesian methods by Joseph 
et al. (1995) [194], Enpe, Georgiadis, and Johnson (2000) [103], Dendukuri and 
Joseph (2001) [94], Johnson, Gastwirth, and Pearson (2001) [188], Georgiadis et al. 
(2003) [141], Branscum, Gardner, and Johnson (2004) [47], Hanson and Johnson’s 
comments relating to Gustafson (2005) [157], Jones et al. (2010) [192], Johnson, 
Jones, and Gardner (2019) [189], and Johnson, Ward, and Gillen (2017) [190]. For 
brevity, we do not consider this topic here.
Another topic that we have left out of the presentation involves the relaxation 
of the assumption of binormality. There are many possible shapes of distributions 
that nature could be following in any given situation. Branscum, Johnson, and 
Hanson (2008, 2015) [50, 49] developed semiparametric methods for estimating 
ROC cures with normal distributions replaced by flexible (nonparametric) classes 
of distributions. The linear regression form stays the same, so the mean biomarker 
responses for each group are still linear functions of one or more covariates. In 
the NGS case, a logistic regression model is used for the latent disease status. 
The flexibility of the semiparametric approach allows the shape of the distribution 
around the linear means to be multimodal, skewed, and so on.

504
Bayesian Thinking in Biostatistics
15.4 
Exercises
Exercise 15.1. Using the multinomial likelihood specified in equation (15.1) in 
conjunction with independent beta priors for the model parameters, show that the 
joint posterior is the product of independent beta distributions. Give the specific 
beta distributions.
Exercise 15.2. CAD data. Using your results from Exercise 15.1 with inde­
pendent U(0,1) priors, analyze the CAD data in Table 15.3. Plot the exact beta 
posterior densities for (тг, Se, Sp) using R or some other computing platform. Also, 
with the known beta posteriors for the model parameters, obtain plots of the pos­
terior densities for the PPV and NPV using simulation.
Exercise 15.3.
(a) 
Recall the CAD data from Example 15.1. Write your own or use sample code 
available on the book’s website for this chapter to analyze these data. The file names 
include CAD. Assume that prior information for model parameters is specified in the 
form of a best estimate and a 0.05 quantile of the prior (the latter in parentheses). 
For тг, we have 0.5 (0.2), for Se we have 0.7 (0.4), and for Sp, 0.7 (0.4), which are 
all relatively diffuse. Using these priors, reanalyze the CAD data. Compare point 
estimates with those in Exercise 15.2 and with the maximum likelihood estimates 
given in the example.
(b) 
Now modify the prior and the code so that the prevalence is specified to be 
precisely тг = 0.05 (point mass at 0.05). Reanalyze the data and make comparisons 
of inferences with those in part (a).
(c) 
Now suppose that 100 new patients from the same population will be tested. 
Using the prior in (a), obtain predictive inferences for the number out of the 100 
that will (i) test positive and (ii) will be D+.
Exercise 15.4. CAD data. For the data analysis parts of this exercise, use priors 
from part (a) of Exercise 15.3. It is a fact that if we condition on column totals in 
a multinomial table, as in Table 15.3, then individual cell counts in those columns 
are binomial with success probability equal to the conditional probability of being 
in the particular cell. Specifically,
Til | У+1-7Г. Se.Sp^ Bin(y+i,Se) and УОо | У+о, тг, Se, Sp ~ Bin(y+0, Sp),
independently.
(a) 
Show that the conditional distributions above are correct.
(b) 
Analyze the CAD data assuming that the column totals are fixed. What para­
meters are estimable under these circumstances?
(c) 
It is also true that if we condition on row totals, individual cell counts are 
binomial. Obtain the precise binomial distributions by analogy with the results 
when conditioning on column totals.

Diagnostic Tests
505
(d) 
Analyze the data when conditioning on row totals. What parameters are es­
timable under these circumstances?
Exercise 15.5. HIV Data.
(a) 
Analyze the HIV data from Example 15.2 using the large-sample results specified 
in expression (15.3). Use prior 1 specified in Example 15.2. Compare results with 
those obtained in Table 15.5.
(b) 
Use prior 1 in Example 15.2 to analyze the new data set у = (3.5. 1 18675), 
n = 148,693. These are the data analyzed there only divided by 21 and rounded so 
that they are actual counts. Compare with inferences in Table 15.5.
(c) 
Repeat part (a) using the new data in part (b). Comment on the quality of the 
approximation.
(d) 
Using the results in expression (15.3), obtain plots of the approximate densities 
for (7Г, Sp, PPV, 1 — NPV) for the full data and the reduced data (from part (b)).
EXERCISE 15.6. Canadian HIV data. A 1986 study of blood donated for trans­
fusion in Canada was performed. There were n = 94,496 blood units that were 
tested with an Abbot ELISA with 405 ELISA+ outcomes, and with all of 
these retested with western blot (WB), resulting in 14 WB+ outcomes and 391 
WB- outcomes. In addition, there was a sample of 627 blood units that were 
set aside by screeners based on the donors’ responses to a questionnaire about 
risky behavior. These were all tested with the ELISA and WB assays. Counts 
for (ELISA+,WB+), (ELISA+,WB—), (ELISA-,WB+), (ELISA-, WB-) 
were (11,3,1,612), respectively. An additional control sample was taken that res­
ulted in counts (1,2,0,619). Individuals in this sample were matched to those in 
the “risky behavior” sample based on age, sex, and other factors unrelated to the 
risky behavior. Assume that the WB test is perfect and that all three samples are 
independent and follow a multinomial distribution with appropriate probabilities 
for each cell in each multinomial.
(a) 
Write and simplify the likelihood function for the combined data.
(b) 
Using the prior Se ~ Beta(57,4), Sp ~ Beta(10,1), 7r ~ Beta(l, 10), analyze 
the combined data. Perform a sensitivity analysis. Keep in mind that the posterior 
for Se will be very similar to the prior.
Exercise 15.7. Consider the derivation of the functional form for the ROC curve 
in Example 15.3.
(a) 
Show that Sq (t)  = Gq (1  - t) = po + 
1 (1 ~ t)-
*
*
(b) 
Use this result to argue that ROC(t) = 1 - Ф(-а - ЬФ-1(1 - t)), where a = 
(Д1 ~ and b = ao/cr\.
(c) 
Show that Ф(х) = 1 — Ф(—x) for any x, and that —Ф-1(£) = Ф"1 (1 - t).
(d) 
Thus argue that ROC(t} as defined in equation (15.4) is equal to 
Ф [а + ЬФ-1()].
*
Exercise 15.8. Using equation (15.5), do the following:

506
Bayesian Thinking in Biostatistics
(a) 
Give a single plot of the ROC curves for which (i) (a = 0.5,b = 1), (ii) (a = 
1.5, b = 1), and (iii) (a = 2.5, b = 1).
(b) 
Obtain the AUC for each of these three models (see equation (15.6)).
Exercise 15.9. Establish the result in equation (15.7) that justifies going from 
line 2 to line 3. You need to explicitly use the conditional independence assumption 
given there. It does take an appropriate but brief technical argument.
Exercise 15.10. Suppose n0 = щ = 1, YOi I po ~ Мло, 1), Yii | 
~ 7V(^i, 1),
and Zf ~ Ber(7r
*)
 with 7r*  a constant. Let Yf | p.Q,Zf = 0 ~ 7V(^o,l) and Yf | 
pi,Zf = 1 ~ 7V(/xi,l). Assume that (Z/,Y/) is independent of Y conditional on 
the model parameters. Also let р(^о>Ам) к with к a constant.
(a) 
Determine an analytical formula for P(Zf = 1 | y,yf) using equation (15.7).
(b) 
From here on, suppose {3/01 = 0, j/ц = 2} and 7r  = 0.5. Plot P(Z = 1 \y,yf) 
as a function of yf and find the value of yf for which P(Zf = 1 | y, yf) = 0.95 and 
the value for which it is 0.05.
*
(c) 
Simulate predictions from P(Zf = 1 | y,yf) for several values of yf. Compare 
with analytical values from part (b).
Exercise 15.11. In the context of Example 15.4, show that the cutoff corre­
sponding to Sp = 0.84 and Se = 0.80 is approximately 146.8. Include details that 
were left out of the derivation of the cutoff 146.8.
Exercise 15.12. In this exercise we will reanalyze the glucose data in Example 
15.4. The data and sample code are available on the book’s website for Chapter 15. 
The file names contain glucose.
(a) 
Analyze the glucose data and try to reproduce all of the inferences presented in 
Example 15.4.
(b) 
Repeat (a) with 7V(0,106) priors on the means and Ga(0.001,0.001) priors on 
the precisions. Do results change appreciably?
(c) 
Using untransformed data, and log-transformed data, obtain Q-Q plots for each 
sample and discuss whether either version appears to be approximately normal and 
which one appears to be closer to normality.
(d) 
Formulate appropriate priors for the bi-log-normal case and revise your program 
to obtain results for the ROC and the AUC. Comment.
Exercise 15.13. Modify your program from Exercise 15.12 to obtain P(Zf = 1 | 
y.yf). where (Z/,Y/) is the disease status and observed blood glucose outcome for 
a new patient. Plot these probabilities over a suitable range of values of yf. What 
do you see?
Exercise 15.14. Consider the binormal regression model for GS data (y,x) dis­
cussed in Section 15.2.4: outcomes in у are biomarkers from diseased and healthy 
individuals, and values in x are the corresponding covariate values. Let (yf,Xf,Zf) 

Diagnostic Tests 
507
be the biomarker outcome, covariate value, and unknown disease status for a fu­
ture individual whose values are independent of the data conditional on model 
parameters. We have
Yf | if = x, Zf = i.0Zf JL W(4H + 
i = 0.1.
Derive the formula for the predictive probability
P(Z/ = 1 | xf = x.y/.y).
Hint: Recall the result in equation (15.7).
Exercise 15.15. In this exercise we reanalyze the data in Example 15.5. We have 
the data and sample code available on the book’s website for Chapter 15 in Hies 
with glucose-regression in their names. The code is currently set to fit model 2, 
the model that does not include a slope coefficient for the effect of age on glucose 
in the diabetes group.
(a) 
Run the code, and then revise it, to reproduce the results in Table 15.7 for 
models 1 and 2.
(b) 
Obtain posterior inferences for ROCX for x € {30,40,60,70}. Plot all four ROC 
curves on the same plot. Make inferences for the differences ROCzq - ROC7Q and 
ROC40 - ROC60- Comment.
(c) 
Modify your program for part (b) to obtain and plot the predictive probabilities, 
P(Zf = 1 \ Xf = x,yf,y), as functions of yf over an appropriate range. Generate 
four plots, one for each of the values of x specified in part (b). This was defined and 
discussed in Exercise 15.14 and for the simpler non-regression problem in equation 
(15.7).


Appendix A
Probability and Random Variables
This appendix simply lists the definitions and rules for probability and random 
variables that are used throughout this book. It is not intended to serve as an 
introduction to these topics, but as a reference for precisely what is meant when 
terms appearing here are used in the text. Our intention is to review material the 
reader may have already studied or inspire the reader to study the material in 
greater depth in a suitable textbook.
A.l Probability Axioms and Rules
Probability is a number attached to an event. For mathematical precision, we begin 
with any set fl, looking upon its elements as elementary or atomic events.
Event Space. A collection A of subsets of Q is called an event space if it satisfies 
the following:
(i) A E A implies Ac € A.
(ii) Ai, A?,... e A implies (J^j A, € A and A, € A.
Elements of an event space are events. When we call something an event, it is taken 
to be an element of some event space.
Probability Space. A probability space is a triple (Q, A,P), where A is an event 
space of Q. and P is a real-valued function with domain A satisfying the following:
(i) 
P(fl) = 1.
(ii) 
P(A) > 0 for all A e A.
(iii) 
If Ai, A2, ■ ■ • € A are mutually exclusive events (i.e., as subsets of Q, A,T)Aj =
0 (the empty set) for all i ± j) then
Й
\ 
00
4,J=£p(a).
FYom here onward, we take all events to be elements in the event space of some 
probability space.
Additive Law of Probability. If A and В are two events, then
P(A U B) = P(A) + P(B) - P(A П B).
509

510
Bayesian Thinking in Biostatistics
Independence of Two Events. Two events A and В are independent if and only 
if
Р(АПВ) = P(A)P(B).
Independence of Multiple Events. Events Ai,...,Afc, к > 3, are mutually 
independent if and only if
к
P(Ai П A2 П • • • П Ak) = J] 
i=l
A similar equality holds for any sub-collection containing at least two but fewer 
than к events.
Conditional Probability. For two events A and В such that P(A) > 0, the 
conditional probability of В given A is defined as
This also results in P(B A A) = P(A)P(B|A) if P(A) > 0, and P(B A A) = 
P(B)P(A|B) if P(B) > 0. Note also that if P(A) = 0 or P(B) = 0, then P(BAA) = 
0 since В A A is contained in A as well as in B.
Law of Total Probability. Let Bi,..., B*  be a finite partition of an event space 
Q.1. Then
1A finite partition of the event space Q consists of B\ U • ■ • U Bk = Q and В, Г\ B} = 0, 1 < i < 
j < k In other words, the partition consists of a finite set of subsets of Q such that their union is 
all of Q and none of the subsets intersect.
P(A) = P(A|B!) P(B0 + • • • + P(A|Bfe) P(Bfe).
Bayes’ Theorem. Let Bi,..., B& be a finite partition of an event space Q. Let A 
be an event in Q with P(A) > 0. Then
P(B-IA) = 
P^B^PW
W) P(A\Bl)P(B1) + -- + P(A\Bk)P(Bky 1
Note that for two events A and B, Bayes’ theorem tells us that P(B | A) = P(A | 
B)P(B)/P(A).

Probability and Random Variables
A.2 Random Variables and Their Distributions
We first consider univariate random variables. A strict construction of the math­
ematical definition of a random variable requires a good deal of preliminary devel­
opment and results. We avoid these details by noting that, essentially, a random 
variable is a function from a probability space into the real number line. As such, 
probabilities assigned to events in the probability space are acquired by appropri­
ate subsets of the real line. For statistical purposes, it suffices to focus on these 
probabilities and describe them via random variables without much consideration 
of the original probability space.
A.2.1 Univariate Random Variables
Cumulative Distribution Function. The cumulative distribution function (cdf) 
of a random variable У is a function F defined by
F(y) = 
< У), -oo < у < oo.
Although, at first look, this function seems to address only sets of the form (-oo, y), 
it is sufficient to determine the probabilities of any reasonable subsets of the real 
line. As such, the cdf provides one complete description of the probability structure 
of a random variable.
Properties of the Cumulative Distribution Function. Using standard nota­
tion for limits (right-hand and left-hand limits and limits at infinity), the cdf has 
the following properties.
(i) 
0 < F(y) < 1 for all у € (-oo,oo).
(ii) 
F(y) is a non-decreasing function of y.
(iii) 
F(-oo) = 0 and F(oo) = 1.
(iv) 
F(y+) = F(y) for all у G (-oo,oo), that is, F(-) is right continuous.
Discrete Random Variables. If the cdf has discontinuities at distinct and well- 
separated points that are either finite in number or countably infinite, and it is 
non-increasing between adjacent such points, we will call the random variable with 
this cdf a discrete random variable.
A discrete random variable takes values only in a finite or countably infinite 
set of real numbers, say, {ai,O2,...}. Its probability structure can be described 
completely by another function that is often useful in practice.
Probability Mass Function. The probability mass function (pmf) of a discrete 
random variable У is a function f defined by
f(y) = P(X = y), yt (-°°> °°)-

512
Bayesian Thinking in Biostatistics
Clearly, f(y) > 0 only at a countable number of points, whereas the cdf has 
discontinuities. We also have f(y) = F(y) - F(y-).2
2/•’({/—) denotes the left-hand limit of the cdf F( ) at y.
Probability Density Function. If the cdf is continuous at all points and has a 
derivative at all but a countable set of points, it can be reconstructed via another 
function, /, called a probability density function (pdf), by the relationship
= [ f(x)dx.
J-oo
Properties of the Probability Density Function. A probability density func­
tion of a random variable Y has the following properties.
(i) 
f(y) > 0 for all у E (-00,00).
(ii) 
P(a<Y<b) = tff(y)dy.
(iii) 
f(y) can be taken to equal -^F(y) at all points у where F has a derivative 
and set to any arbitrary finite values elsewhere.
Continuous Random Variables. We will call a random variable continuous if 
it has a cdf that can be reconstructed from a pdf as defined above. Typically, this 
means the cdf has a derivative everywhere, except perhaps at a few points.
Convention Regarding Use of the Words “Density” and “Distribution”. 
In this book, as has become common practice in the statistical literature, we use 
the word “distribution” in a general sense for any description (pdf, pmf, cdf, and 
possibly other functions) of the complete probability structure of a random variable. 
Most often, this description is via a pmf or a pdf. In either case we use the word 
“density,” and denote it by the letters p or /, disregarding the distinction between 
a pmf and a pdf. The context is typically sufficient to clarify whether the random 
variable is discrete or continuous. (This practice can be shown to be mathematically 
rigorous by defining an appropriate underlying measure with respect to which the 
pmf or pdf is defined.) Finally, when referring to a cumulative distribution function, 
we explicitly call it a cdf and use the upper-case letter F to denote the function.
A.2.2 Bivariate Random Variables
When considering two random variables simultaneously, it is not sufficient to sim­
ply describe their separate distributions. The possible set of values for a bivariate 
random vector (we use the word “vector” when more than one variable is considered 
simultaneously) are points in a coordinate plane. As such, a complete description 
of the probability structure must include the probability of any reasonable set in 
the plane, particularly rectangles. To describe the joint distribution of two random 
variables, we need extensions of the cdf. pdf, and pmf.

Probability and Random Variables
513
Bivariate (or Joint) Cumulative Distribution Function. The bivariate cdf 
of random variables X and Y is a function F defined by
F(z.j/) = P(X < x П Y < y), —oc < r < oc. -oo < у < ос.
Although this function directly addresses only lower left infinite rectangles, it is 
sufficient to determine the probabilities of any reasonable subsets of the plane. 
In this sense, the bivariate cdf provides a complete description of the probability 
structure of two random variables jointly.
Properties of the Bivariate Cumulative Distribution Function. A bivariate 
cdf has the following properties.
(i) 
0 < F(x, y) < 1 for all x G (-oo, oo), у G (-oo, oo).
(ii) 
F(x, oo) and F(oo,j/) are univariate cdfs.
(iii) 
F(b,d) — F(a,d) - F(b,c) + F(a,c) > 0 for all a < b, c < d.
(iv) 
F(-oo, -oo) = 0 and F(oo,oo) = 1,
(v) 
F(x+,y+) = F(x,y) for all x G (-00,00), у G (-00,00), that is, F(-,-) is 
right continuous.
Bivariate (or Joint) Probability Mass Function. The joint pmf of discrete 
random variables X and У is a function f defined by
f(x,y) = P(X = x A Y = y), x G (-00,00), у G (—00,00).
As in the univariate case, f(x, у) > 0 only at a countable number of points in the 
plane where the cdf has discontinuities.
Bivariate (or Joint) Probability Density Function. If the cdf is continuous 
at all points in the plane and has a mixed partial derivative at all but a countable 
set of points, it can be related to another function f called a bivariate (or joint) 
probability density function. The relationship is given by
F(x,y) = J j f(s,t)d3dt, f(x,y) = ^-F(xty).
A bivariate pdf has properties similar in concept to its univariate counterpart, 
namely:
(i) f(x,y) > 0 for all -00 < x < 00, -00 < у < oo;
(ii) P(a < X < b,c < Y < d) = £ £f(xty)dydx.
Convention Regarding Use of the Words “Density” and “Distribution”.
We follow the same convention as in the univariate case. See the description given 
at the end of Section A.2.1.
Marginal Distributions. The joint distribution of two random variables X and Y 
determines the separate individual distributions of X and of Y. These distributions 

514
Bayesian Thinking in Biostatistics
are called marginal distributions. A marginal distribution fully describes the prob­
ability structure of the random variable by itself, without reference to the other. 
The relevant expressions, with subscripts used on functions to clarify the random 
variable to which the marginal belongs, are:
Fx(x) = F(x,oo), FY(y) = F(oo,y);
fx(x) = f^ftx^dy, fy(y) =
fx(x) = Zallyf(x,y), fY(y) = Hall Xf(x,y).
Conditional Distributions. These distributions play a crucial role in Bayesian 
statistics. They describe how the probability structure of one random variable is 
affected by knowledge of the other. We use the notation Х|У = у to denote the 
random variable X when Y is known to take the value y. The distribution of this 
conditional random variable is determined by the joint distribution. The relation­
ships are given by the following expressions:
f 
f
These relationships hold for pmfs as well as pdfs. Of course, the denominators on the 
right-hand sides must be positive; otherwise, the conditional density is undefined.
Law of Total Probability. For two random variables, 
f(y) = j f(y\x) f(x)dx.
This follows from the relationship between the joint distribution and the marginal 
and conditional distributions stated above.
Bayes’ Theorem. For two random variables,
f(x\y) =
f(y\x)f(x) 
fZof(y\x>)f(x>)dx
A.2.3 Multivariate Random Variables
Extending the development of bivariate random variables to the case of more than 
two variables is straightforward. We state some of the above results for к joint 
random variables Xi,... ,Xk. When convenient, we collect all к random variables 
as components in a fc-dimensional random vector.
Joint Cumulative Distribution Function. The joint cdf is defined as
F(a-i,..., zfc) = P{X\ < П • • • П Xk < xfe), (xi..... xk) G Kfc-
Here R*
1’ denotes fr-dimensional Euclidean space consisting of all /с-tuples of real 
numbers.

Probability and Random Variables
515
Joint Probability Density Function. If the cdf is continuous at all points in Rfc 
and has a fcth-order mixed partial derivative at all but a countable set of points, it 
has a probability density function f with the relationships
= У - j .........rk)d.ri •••(/.rA..
№.■■■■■
**)
 = ... *»).
Marginal Distributions. These distributions follow the definitions for bivariate 
random variables with the single integrals replaced by appropriate multiple inte­
grals:
/
ОО 
/»OO
•■ / 
f(xx,x2,...,xk)dx2--dxk.
•oo J—oo
This also extends to the joint marginal distribution of a subset of the к random 
variables. Such a marginal equals the integral of the joint pdf of all к variables over 
all variables that are not in the subset of interest.
Conditional Distributions. While a large number of conditional distributions 
are possible, we often focus on one of the к variables conditioned on the rest:
Again, the general formula is a ratio of the joint density of pooled variables on 
both sides of the conditioning vertical bar over the joint density of the conditioning 
variables following the vertical bar.
Exchangeable Random Variables. A set of random variables X\,...,Xk are 
exchangeable if and only if the distribution of any permutation of the random 
variables is the same as the distribution of the random variables in the original 
order. To make this more precise, suppose тг(1),... ,ir(k) is any permutation of the 
integers 1,..., k. Then exchageability means
P(X„W < Xl П • • ■ П Xw(fc) < xk) = P(Xi < х, Л • • • Л Xk < xk).
Independence of Random Variables. A set of random variables Xi,...,Xk 
are independent if and only if their joint distribution equals the product of their 
marginal distributions. In terms of cdfs, this means
F(xi,..., xk) = FX1(xi) x •• • x Fx*(xfc),
where, for example, Fx,(®i) = F(zi, oo,..., oo). In terms of densities,
,...,xk) = f(xi) x ■ • • x f(xk).

516 
iJayestan Thinking in tftosiaiisiics
Under independence, conditional distributions are the same as marginal distribu­
tions, that is,
/(xi|x2) = 
/(xbx2|x3) =/(xbx2), /(z3|xi,x2) = f(x3),....
We use the notation Xi,...,xn to indicate that the random variables xj,... ,xn 
are independently distributed. Another notational device sometimes used to indi­
cate independence is Xi 1 x2.
Independent and identically distributed (iid) random variables are useful in 
specifying models. We use the notation xi,...,xn ~ to indicate this. While iid 
random variables are exchangeable, the class of exchangeable random variables is 
much wider.
One way to describe exchangeable random variables is via a conditionally iid 
specification. If 6 is a random variable and Xi,... ,xn\0 are iid, then the joint 
distribution of xb... ,xn,0 is such that the marginal distribution of Xi,... ,xn is 
exchangeable.
Distribution of a Transformed Random Variable or Vector. Suppose X 
is a continuous random variable with a pdf /x(-), and g(-) is an invertible and 
differentiable function on the space of possible values of X. Then the transformed 
random variable Y = g(X) has pdf
-Ml/) = |^)| (ГЧу)) ■
If X is discrete, so is Y with pmf
fy (y) = fx (g~1(y)) •
Suppose X is a continuous k-dimensional random vector with pdf /%(•), and g(-) 
is an invertible function for which all first-order partial derivatives exist and are 
finite on the space of possible values of X. Then the transformed random vector 
Y = g(X) has pdf
fY(y) = |det 
(9~ЧуУ) ,
where det(M) stands for the determinant of a matrix M, and denotes the 
matrix of first-order partial derivatives of the components of /1(3/) with respect to 
the components of y.
A.3 Expectation and Moments
Expectation is a basic notion in considering random variables. It is especially useful 
for statistical purposes.

Expectation of a Function
Given a random variable X, the expectation of a function <;(•) of A' is defined as
£{<?(
*)}
 = 
/(j-)d.r.
where X is the space of all possible values of X. This definition works for random 
variables and random vectors, with g(-) a scalar or vector-valued function. For 
discrete random variables, the integral is replaced by a sum:
= /(*)•
хел-
Expectations do not always exist in that the integral in the definition may not 
exist. When we refer to an expectation by writing a symbol for it, we make the 
tacit assumption that the expectation exists and is finite.
Moments
The rth moment of a random variable X is defined as E(Xr). When r = 1, we get 
E(X), which is also called the first moment or the mean of X.
Laws of Expectation
Expectation is a linear operation in that
E(aX + b) = aE(X) + b,
where a and b are scalars and X is a random variable or a random vector. In the 
random vector case, we also have
E(AX + b) = AE(X) + b,
where A is a matrix of multiplication-compatible dimensions and b is a vector of the 
same dimension as X. It is clear from the definition above that the expectation of 
a constant is the constant itself. The linearity of expectation can also be expressed 
for a function of X, namely,
E{ag(X) + b} = aE{g(X)} + b, E{Ag(X) + = ЛЕ{р(Х)} + b,
with appropriate dimension compatibility.
Variance
The variance of a random variable X is defined as
Var(X) = E ({% - E(X)}2) .

518
Bayesian Thinking in Biostatistics
The variance can be expressed in terms of the first two moments of X as
Var(X) = E(X2) - {E(X)}2.
For random vectors X, the notion of variance is more complex. We have the 
definition
Var(X) = E [{X - E(X\}{X - E(X)}'],
where M' denotes the matrix transpose of matrix M. In this case, Var(X) is a 
square and symmetric matrix with diagonal elements containing the variances of 
the components of X and off-diagonal elements containing the covariances between 
two components.
The covariance between two random variables Xi and X2 is given by
Cov(XltX2) = E[{Xi - E(Xi)}{X2 - E(X2)}].
This covariance can be expressed also as
Cov(Xi,X2) = E(XiX2) - E(Xi)E(X2).
If Xi and X2 are independent random variables, Cov(X],X2) = 0, since the ex­
pectation of a product of independent random variables equals the product of their 
expectations. On the other hand, Cov(X],X2) = 0 does not imply independence.
Laws of Variance and Covariance
For a random variable X,
Var(aX + 6) = a2Var(X).
For a random vector X,
Уаг(ЛХ + b) = A Var(X) A’.
Notice that the additive constant does not change the variance, as the variance of 
a constant is zero. For two random variables Xj and X2,
Cov(ajXi + b\, 0,2X2 + 62) = aia2Cov(Xi, X2)
and
Var(X! + X2) = Var(Xj) + Var(X2) + 2Соу(ХьХ2).
For independent random variables, the variance of their sum equals the sum of their 
variances.

Probability and Random Variables
519
Conditional Expectation and Variance
Consider two random variables X and Y. For each possible value у of У, there is a 
conditional distribution of X conditioned on Y = y. This conditional distribution 
has a mean (or expectation) denoted by Е(Х|У = у). This expectation is a function 
of y, say g(y). The random variable g(Y) is called the conditional expectation of X 
given Y and denoted Е(Х|У).
If we replace the conditional mean by the conditional variance in the above 
paragraph, we get the definition of conditional variance. Here Var(X|Y’ = у) is a 
function of y, say h(y). The random variable h(Y) is called the conditional variance 
of X given У and denoted Уаг(Х|У).
Laws with Conditional Expectations and Variances
The expectation of a random variable X can be expressed as a successive expecta­
tion in the following sense:
Е(Х) = Е{Е(Х|У)}.
Notice that the inside expectation on the right-hand side is an integral with respect 
to the conditional distribution of X, that is, the variable of integration is x. The 
outside expectation is an integral with respect to the marginal distribution of У as 
Е(Х|У) is a function of У.
The variance of a random variable also can be expressed in a similar fashion:
Var(X) = E {Уаг(Х|У)} + Var {Е(Х|У)} .
Strong Law of Large Numbers
Suppose Xi,X2)... is a sequence of iid random variables, and g(-) is a function 
such that E{p(Xi)} and Var {p(Xi)} are finite. Then, with probability 1,
lim i£9(X4) = E[S(X1)]. 
n—too n
This law also holds under milder conditions on the sequence of random variables, 
in particular when it is a stationary Markov chain.


Appendix В
Common Distributions
In this appendix we list the various distributions in common use. Table B.l lists 
discrete distributions, Table B.2 lists continuous univariate distributions, and Table 
B.3 continuous multivariate distributions.

TABLE B.l: Discrete univariate and multivariate distributions
Family and 
variable domain
Notation and 
parameter domain
Kernel 
of density
Normalizing 
constant
Mean
Variance
Bernoulli
X e {0,1}
Ber(%) 
% e (0,1)
№( 1 - 7Г)1-x
1
7Г
7Г(1 - %)
Binomial
x e {0,... ,n}
Bin(n, 7г)
ne {0,1,...},% e (o,i)
1
717T
П7Г(1 — %)
Multinomial 
yi e {0, ...,n}, 
Э Й=1 Vi = n
Multk(n, 0) 
n e {0,1,...}, 0 e Kfc, 
э 0i > о Vi, Eti = 1 nti^/nLwi
1/n!
Е(Уг} = nOi, 
i = 1,... ,n
Var(j/i) = n0,(l - 0i)
Cov(2/i,j/j) = -n0f,0j,(i Ф f)
Poisson
xe {0,1,...}
Po(A)
A e (0, oo)___________
Xx/x\
ex
A
A
522 
Bayesian Thinking in Biostatistics

Common Distributions
523
TABLE В.2: Continuous univariate distributic

TABLE В.2: Continuous univariate distributions (continued)
Family and 
variable domain
Notation and 
parameter domain
Kernel 
of density
Normalizing 
constant
Mean
Д
Variance
~2
Normal
x G (-00, 00)
a(m,^2)
g G (-00, 00), a2 G (0,00)
a ч/2тг
t)
ц e (-00,00), т G (0,00)
r-1/2^
1/t_______
е-^(х2-2дх)
r-1/2^^2/2 Д
1/t_______
Nor(a, t>)
a G (0, 00), b G (-00,00)
e-^(ax2-2bx)
v^eb2/<2") 
a*/2
b/a
1/a
Normal-gamma
x e (-00,00),
У G (O.oo)
NoGa(n, к, a, /3)
ц G (—00, 00), к G (0,00), 
a G (0, 00),/? G (0,00)
ya-^e-|fcy{(x-M)2+23/fc}
ч/2^Г(а) 
ki/2^a
a> 1/2
a > 1
Pareto
x G (a, 00)
Par(a, b)
a G (0,00), 6 G (0,00)
x-(b+,)AI.os)(z)
b>1 (b-l)2(b-2)> b>2
Student’s t
x G (-00,00)
t(i/,n,a2), 1/G (0,00), 
p, G (-00, 00), a G (0, 00)
д, и > 1
Й^>2
St(js,g, r), 1/G (0, 00), 
g G (-00, 00), T G (0,oo)
{1 + Х(х-д)2}-<-+1)/2
g, V > 1
Uniform
x G (a, b)
U(a,b)
a G (-00,00), b G (a, 00)
1
b — a
a+b 
2
(b—a)2 
12
Weibull
x G (0,00)
Weib(a, A)
a G (0,00), A G (0,00)
l/(aA)
Г(1/а)
2Г(2/а)—Г2(1/а) 
a>2/“
Bayesian Thinking in Biostatistics

TABLE B.3: Continuous multivariate distributions
acu = 
ПГж» H(u + 1 - 0/2)
Family and 
variable domain
Notation and 
parameter domain
Kernel 
of density
Normalizing 
constant
Mean
Vari­
ance
Dirichlet 
0G Rk,9 0, >0 
Vi, EL.
**
 = i
Dk(a)
a G Rfc, Э Qi > 0 Vi,
П?Г(аО/Г(а+)
о/о+
Normal
igR”
N₽(p,E), pgR₽
S p x p positive definite
(2тг)р/2|£|1/2
М
г
Nop(p,T), peRP
T px p positive definite
e-4(x-M)'T(x-p)
(2тг)р/2|ТГ1/2
М
Т-1
Norp(A,B), BgRp
A p x p positive definite
e-4(z'4z-2B'x)
(2тг)Р12\А\-х'гх 
е^в'А'в
А~1В
А-1
T
x e rp
Tp(i/,p,E),i/ > 0,p G Rp 
E p x p positive definite
{1 + 1(х-дУ£-1(х-д)}’(,'+,’)/2
егИ|/г '
Д
i/> 1
v > 2
Srp(i/,p,T),i/>0,pGRP
T p x p positive definite
{144(s-p)'T(s-p)}"("+₽)/2
ст\Т\~1'2
д
!/> 1
р>2
Wishart
X p x p matrix, 
symmetric and 
positive definite
Wp(M, v>p, 
Q px p positive definite
|X|(./-p-l)/2e-i‘r(Q-,X)
cwini
*
72 2
Ил»р(Ф,1/), v > p, 
Ф p x p positive definite
|X|(^-p-l)/2e-itr(
*X)
еил|ФГР/2
i/ф-1
Inverse Wishart 
X p x p matrix, 
symmetric and 
positive definite
ЛГр(Ф,1/), i/>p, 
П p x p positive definite
|X|-(p+p+l)/2e-itr(
*X-
*)
с^|Ф|"/2
♦
Common Distributions


Appendix С
Software for Sampling Posterior
Distributions
There are many basic calculations that one can perforin in R and the random num­
ber generation functions available in it for Bayesian inference, but more complicated 
probability models will either be too slow or too difficult to program in R. In this 
Appendix, we provide a brief introduction to software that is available for carrying 
out Bayesian computation. We focus primarily on WinBUGS, OpenBUGS, JAGS, 
and Stan. We also touch on the R packages that allow one to interface with these
*
 
programs, making the analysis more efficient. All of the software and packages we
*  
discuss are available free of charge and share some common syntax. They are
*
 geared 
towards simulation from posterior distributions given a model, prior, and elata.
The R2WinBUGS and BRugs packages allow one to drive WinBUGS anel Open­
BUGS from R. This is a major convenience, since this makes it easy to manipulate? 
MCMC output to make pretty pictures of collections of posterior densities, predic­
tive distributions, and so on. Moreover, if one needs to run the same BUGS code? 
many times with slight modifications, it is much simpler to do it from R using one 
of these packages. Similar functionality is available with Stan and JAGS. Finally, 
we give brief descriptions of some R packages useful for Bayesian work.
C.l WinBUGS
The BUGS language can be regarded as a device for communicating models anel 
distributions [232]. This is in contrast to usual scientific computing languages that 
expect instructions for carrying out calculations. Keeping this distinction in mind 
is helpful for understanding and writing code.
We describe the basics in three parts: (i) model specification; (ii) input of data 
and constants; and (iii) iterations and monitoring of variables. We strongly urge 
the reader to concurrently use the software while reading through the next two 
examples.
Model specification. This main component of the language asks the user to 
specify both the sampling model and the priors. For this purpose, two types of 
statements are available: one declaring the distribution of a variable, the other 
specifying a variable’s mathematical relationship to other variables. For the first 
purpose, most common distributions are given names with specified parametcriza-
527

528
Bayesian Thinking in Biostatistics
tions. A complete table of these distributions is contained in the software manual. 
We will introduce a few via their use in examples.
Example C.l. In Example 4.6, we generated samples from the posterior distribu­
tion of (^,t) when the sampling distribution of individual data points is 
and independent 7V(/^o > ^о) and Ga(ao, Ao) priors are used for p and r, respectively. 
Here we show how Win BUGS can be used to accomplish the same task.
First, we put into a text file the group of statements on the left in Figure C.l. 
These model statements can be represented as a directed acyclic graph that specifies 
relationships between all variables in the model. Such a graph consists of variables 
as nodes and directed arrows pointing between nodes as determined from the model 
specification. The graph’s visual representation is shown on the right in Figure C.l. 
Here {mu, tau, y[i], i=l,... ,n}, pictured in circles, are stochastic nodes, as 
these are assigned distributions. The remaining variables, {muO, tauO, alphaO, 
lambdaO, n} are constants and displayed in rectangles.
model{
for(i in l:n){
y[i] ~ dnorm(mu,tau)
mu " dnorm(muO,tauO)
tau'dgamma(alphaO,lambdaO)
FIGURE C.l: Simple normal-normal model in the BUGS language (left) and the 
corresponding directed acyclic graph (right).
Notice that WinBUGS automatically infers that the distribution of y[i] is a 
conditional distribution conditioned on mu and tau, as these are used as parameters 
in dnorm. We then ask WinBUGS to check this model for proper syntax by clicking 
the “check model” button on the Specification Tool started from the Model menu 
item on the menu bar.
Input of Data and Constants. The next task is to read in the constants and 
the data. This can be done by highlighting the word “list” from text, such as
list(n=403,alphaO=O.1,lambdaO=O.1,mu0=150,tau0=0.001)
written in an opened text (.txt) or ode (.ode) file, and clicking the “load data” 
button on the Specification Tool. In addition to these constants, we need to input

Software for Sampling Posterior Distributions
529
the data. Here we will use the Weight-00 variable's non-inissing response values 
from the VetBP data first introduced in Example 1.1. Using R and some manual 
editing, this was written into a text file (dataWeight_OO.txt on the book's website 
under Chapter 4) as
list(y=c(190.4,161.2,...,184.6)),
where the ... consist of 400 additional weight values. After all data are read in. 
we ask WinBUGS to “compile” this model. In this step. WinBUGS perforins a good 
deal of mathematical and coding tasks for us. Knowing which stochastic nodes have 
been given data values, it prepares to simulate posterior samples for all other nodes 
conditional on these data. Essentially, it is “deriving” the conditional distributions 
for the Gibbs sampler for the model, determining what simulation method to use 
(including the adaptive rejection sampler for log-concave distributions), and putting 
all this code together for iterative simulation of samples from the posterior.
If we want to monitor multiple chains, we need to input the number of chains 
using the “num of chains” button on the Specification Tool, after the data are loaded 
and before compiling.
MCMC Iterations and Monitoring of Variables. To start the simulations, 
WinBUGS needs initial values for all stochastic nodes that are not given data values. 
On the Specification Tool, the “load inits” button can be used in a manner similar 
to the “load data” button. An alternative is to let WinBUGS generate initial values 
(“gen inits”), which it does using the priors for these nodes. It is also passible 
to load initial values for some variables and generate them for the rest. We note, 
however, that there will be instances when it is necessary to specify initial values. 
This is often indicated by certain error messages when attempting to have BUGS 
generate initial values. If multiple chains are specified, then the same number of 
sets of distinct initial values are required. BUGS will keep requesting them until all 
have been specified.
At this point, WinBUGS is ready to start the Markov chain. We now click 
“samples” from the Inference menu, which brings up the Sample Monitor Tool. 
Here we type in the node names (mu, tau) one at a time and click the highlighted 
“set” button. When done, we need to type ♦, which informs BUGS that we have 
set all of the stochastic variables that we want to monitor. The other input items 
on this tool are relevant only after the samples are generated.
Next, we go back to the Model menu and click on the Update Tool. Here, we 
must indicate how many iterates are to be simulated. A thinning value can be 
specified here also, but this is not recommended when first running your program. 
The “refresh” button gives an indication of how much time is needed for the number 
of iterates specified there. For example, if it is set to 100, one can see how long 
each set of 100 iterates takes to simulate. Clicking the “update” button starts the 
sampling. This tool can be used repeatedly to add iterations if we wish.
To see the results, we return to the Sample Monitor Tool. The “history” button 
shows a plot of the chain, starting at the specified iteration. Looking at the chain 
from the very beginning, we see that convergence occurs rapidly; a burn-in of 100 

530
Bayesian Thinking in Biostatistics
iterations is quite sufficient. Now starting at iteration 101, we click the “density” 
button to see the posterior densities of mu and tau. The “stats” button puts out 
some summaries for each variable, and the “auto corr” button generates autocor­
relation plots. Finally, the “coda” button generates two files, one containing the 
posterior samples sequentially, and another containing indexing information for ex­
traction of the MCMC generated samples for each of the variables. As we see below, 
it is much more convenient to use R to convey input to Win BUGS and to extract 
samples from it to analyze in R.
C.1.1 OpenBUGS
OpenBUGS developed as an open-source version of WinBUGS and is very similar 
to it. It is also free of charge and readily available for downloading from the in­
ternet. There are some differences from WinBUGS, mainly enhancements, that are 
explained on the website openbugs. info. All of the above description of how Win­
BUGS works, including the code and the graphics interface, applies identically to 
OpenBUGS.
C.1.2 Censored Data in BUGS
BUGS handles censored data (see Chapters 11 and 12) in a special way. One sets 
the censored times to missing and uses a built-in function for censoring, I(L,U). 
The I(L,U) function follows a distributional statement for a stochastic node and 
means that the value lies between the values L and U.
For survival analysis with accelerated failure-time (AFT) regression models, the 
construct works as follows. If the ith individual’s time is not censored, the value 
of t[i] is the actual time of the event (i.e., t[i]=tj. If the ith individual’s time 
is censored, the value of t[i] is missing and entered as NA. If an observation is 
right censored at cit we set L[i] = q. That is, the lower bound is the censored 
observation time. For the upper bound, we leave it blank to indicate that there 
is no upper limit. In our program, we write I(c[i] If the observation is left 
censored at c^, set U[i] to c; and set L[i] equal to 0, since the actual time cannot 
be negative. If we have interval censored data, we use L [i] equal to the lower bound 
of the interval and U[i] equal to the upper bound. For uncensored observations, 
t [i] = ti, the observed time to the event. If the observation is not missing (i.e., 
t[i] is not set to NA), the constraints given in I(L,U) are ignored.
Below are some BUGS programming statements that specify a log-normal AFT 
model for Example 12.1 (see Chapter 12). The log-normal regression model uses 
reference priors, and the BUGS program includes a subset of the data listed at the 
end. In the code, the distribution of the times is specified in the statement
t[i] “ dlnorm(mu[i] , tau) I(c[i] ,)
The statement tells BUGS that the outcome times have a log-normal distribution 
with mean mu[i] and precision tau. Furthermore, the statement constrains the 

Software for Sampling Posterior Distributions 
531
times that are missing (i.e.. =NA) to be larger than c[i]. Again, if the time t[i] 
has a value and does not equal NA. the constraint is ignored. In the program below, 
c [i] equals 0 for all uncensored times.
model-f
ford in l:106){
sAge[i] <- (age[i]-mean(age[ ]))/sd(age[ ])
sYr[i] <- (Yr[i]-mean(Yr[ ]))/sd(Yr[ ])
t[i] " dlnorm(mu[i], tau) I(c[i],)
mu[i] <- beta[l] + beta[2]*equals(stage[i]  ,2)
+ beta[3]*equals(stage[i] ,3)
+ beta[4] *equals(staged]  ,4)
+ beta[5]
*sAge[i]
 + beta[6]*sYr[i]
# 
5 month survival probabilities using covariates in the data
S[i] <- 1- phi ((log (5)-mud] )*sqrt(tau))
# 
Medians corresponding to the covariates in the data
med[i] <- exp(mu[i])
ford in 1:6){
betad] " dnorm(0,0.000001)
rm[i] <- exp(beta[i]) # RMs for each variable
probti] <- step(beta[i])
tau " dgamma(0.001,0.001)
sigma <- sqrt(l/tau)
}
list(beta=c(0,0,0,0,0,0),tau=l) # Initial values
stage[ ] t[ ] age[ ] Yr[ ] c[ ]
1 0.6 77 76 0
1 1.3 53 71 0
1 2.4 45 71 0
1 
NA 57 78 2.5
1 3.2 58 74 0
1 NA 51 77 3.2
The last 84 data lines have been removed to save space 
END
We note that one does not have to use the above approach for handling censored 
data if one is fitting a proportional hazards regression model as given in Section 
12.2.2. An example program is in the folder for Chapter 12 on the book’s website. 
The file has PH Regression in the name.
C.1.3 Interface with R: R2WinBUGS and BRugs
R2WinBUGS and BRugs are R packages that enable one to interact with WinBUGS 
or OpenBUGS. These R packages allow data manipulation and preparation, conve­

532
Bayesian Thinking in Biostatistics
nient input of constants and data, and extraction of posterior samples for further 
processing and graphing in R. Here are some highlights of the packages, including 
R code to illustrate their use.
R2WinBUGS. With R2WinBUGS, we need several things to interact with one 
of the BUGS programs. We need (i) the BUGS program (the program statements 
either in a named text file or a character object in R), (ii) data lists for input, (iii) 
a vector with the names of model parameters whose posterior samples we want to 
save, and (iv) a function to initialize the chains. The following example illustrates 
the use of R2WinBUGS. The approach involves reading data into R and then writing 
R commands to drive WinBUGS or OpenBUGS in R.
Example C.2. We continue with Example C.l, where the variable Weight_00 was 
taken from the VetBP data set. The data set is contained in the file VetBP. csv on 
the book’s website under Chapter 3. The model specification (BUGS) code is also 
there in wtmodel.txt. Both files should be placed in the R working directory.
The BUGS code fits a simple model with a Gaussian likelihood, Gaussian prior 
for the mean, and a gamma prior for the precision, the reciprocal of the variance. 
Note that one specifies a normal or Gaussian distribution in the BUGS language in 
terms of the mean and the precision, not the mean and the standard deviation (as 
in R) or variance.
model{ # Likelihood
ford in l:n){
y[i] " dnorm(mu, tau) }
# 
Prior
mu " dnorm(muO, tauO)
tau " dgamma(alphaO, lambdaO)
# 
Parameter of interest 
sigma <- l/sqrt(tau) 
cv <- sigma/mu }
The following R code uses WinBUGS to generate posterior samples and sub­
sequently summarize inferences and graphs. The R function bugs() instructs R to 
run WinBUGS to generate posterior iterates. Inferences for the standard deviation 
<7 = 1/ y/r and coefficient of variation cv = <7/p. are illustrated.
We run the program in R using the R package R2WinBUGS, which can call 
OpenBUGS or WinBUGS (the default). The R commands below specify the data, 
the values of parameters of the prior distributions, and the names of the parameters 
to monitor. There is also a function that will generate initial values in R for the 
parameters mu and tau. The last command instructs R to call WinBUGS and save 
the results in the R object called VetBP.sim.
library ("R2WinBUGS11)
VetBPdata <- read.csv("VetBP.csv", header=T) 
# indices of non-missing observations 
ok <- 1 is.na(VetBPdata$Weight_OO)

Software for Sampling Posterior Distributions 
533
it vector of non-missing observations
у <- VetBPdata$Weight_OO[ok] 
n <- length(y)
alphaO <- 0.1; lambdaO <- 0.1;
muO <- 150; tauO <- 0.001
data <- list("n", "y", "muO", "tauO", "alphaO", "lambdaO") 
inits <- functionO {
list(mu = rnorm(l, mean=120, sd=5), 
tau = runif(l, min=0.1, max=10)) 
}
parameters <- c("mu", "tau", "sigma", "cv")
# 
Run using the default, WinBUGS
VetBP.sim <- bugs(data, inits, parameters, "wtmodel.txt", 
n.chains=3, n.iter=10000, debug=F, useWINE»F)
The R2WinBUGS package includes versions of the print ( ) and plot( ) com­
mands specifically for the MCMC samples that are returned via the bugs command. 
Here is the default output of the print ( ) command.
> 
print(VetBP.sim)
Inference for Bugs model at "VetBP_BUGS.txt", fit using WinBUGS, 
3 chains, each with 10000 iterations (first 5000 discarded), n.thin “ 1Б 
n.sims - 1002 iterations saved
mean 
sd 
2.57. 
257. Б07. 
757. 97.57, Rhat n.eff
mu 
210.0 2.1 205.8 208.5 210 211.4 214.1 
1 1000
sigma 
44.1 1.6 
41.0 
42.9 
44 
45.1 
47.4 
1 1000
deviance 4195.5 2.1 4194.0 4194.0 419Б 4196.0 4200.0 
1 
800
For each parameter, n.eff is a crude measure of effective sample size, 
and Rhat is the potential scale reduction factor (at convergence, Rhat"l).
# 
Deviance Information Criterion
DIC info (using the rule, pD ■ Dbar-Dhat) #We discuss DIC in Chapter 10
pD - 2.0 and DIC = 4197.5
DIC is an estimate of expected predictive error (lower deviance is better).
One can also use the R package R2WinBUGS with OpenBUGS. One simply spe­
cifies the name of the program in the program= argument of the bugs( ) command 
as in the following statement.
# 
Run with OpenBUGS
VetBP.sim <- bugs(data, inits, parameters, "wtmodel.txt", 
n.chains=3, n.iter=10000, program="openbugs")
We next use the features of the R package coda to check some characteristics of the 
MCMC output (with result in Figure C.2).
it Coerce to mcmc object for use with coda then plot 
MCMCout <- as.mcmc(VetBP.sim$sims.matrix)

Bayesian Thinking in Biostatistics
str(MCMCout)
plot(MCMCout[,c(1,3)]) 
# Plot mu and sigma
Density of mu
Trace of mu
0 
200 
400 
600 
800 1000 
205 
210 
215
Iterations 
N = 1002 Bandwidth = 0.5692
Density of sigma
Trace of sigma
0 
200 
400 
600 
800 1000 
38 40 42 44 46 48 50 52
Iterations 
N = 1002 Bandwidth = 0 4333
FIGURE C.2: Output of plot() function on object generated by R package coda.
We check autocorrelations with the coda function autocorr.
> autocorr(MCMCout[,c(l,3)]) 
, , mu
mu 
sigma
Lag 0 
1.00000000 
0.093958603
Lag 1 
0.03522100 -0.010263788
Lag 5 -0.05131544 0.024386797
Lag 10 0.06082433 0.002685143
Lag 50 0.03939281 0.004553790
, , sigma
mu 
sigma
Lag 0 
0.093958603 1.0000000000
Lag 1 
0.008429359 -0.0358526279

Lag 5 
0.040119814 -0.0174528540
Lag 10 0.019199481 -0.0008152195
Lag 50 -0.037513675 0.0243738396
Note that the autocorrelations for /z appear in the first column in the first 
set, and those for ст in the second column in the second set. The other 
columns contain cross-correlations. The autocorrelations can be plotted with au- 
tocorr.plot(MCMCout[,l:2]); the resulting graphs are shown in Figure C.3.
mu 
sigma
0 
5 
10 
15 
20 
25 
0 
5 
10 
15 
20 25
Lag 
Lae
FIGURE C.3: Autocorrelation plots from coda.
Additionally, we can create a new parameter as a function of model parameters 
and use the saved posterior samples to infer its posterior distribution and char­
acteristics related to it. For example, the following statements in R compute the 
coefficient of variation and plot its posterior distribution (see Figure C.4).
# Posterior for coefficient of variation.
cvs <- MCMCout[,4J
summary(cvs)
pdf("VetBP_CV_plots.pdf")
hist(cvs,probability=TRUE)
lines(density(cvs)) 
dev.off()
BRugs. This is an alternative interface with OpenBUGS. It is more direct and less 
automated than R2WinBUGS.
• BRugs supplies several functions that are equivalent to clicking various buttons

536
Bayesian Thinking in Biostatistics
Histogram of cvs
FIGURE C.4: Posterior density of the coefficient of variation of the Weight.OO 
variable.
on the three pop-up tools (Specification, Update, and Sample Monitor) in 
OpenBUGS.
• 
The modelData function provides two forms of data input. One form loads 
data directly from a text file containing data in OpenBUGS format. The other 
form takes a list of names of R objects matching variables in the syntax- 
checked model and passes the list to OpenBUGS in the appropriate format. 
This second form allows data reading and preparation to be performed in R. 
Data can be loaded in steps by using this function multiple times.
• 
The samplesSample function is somewhat like the coda button in WinBUGS. 
It extracts samples for a monitored variable. Again, this is very useful, as it 
makes posterior samples available in R for all post-MCMC manipulations and 
graphing.
For Example C.2, we replace the bugs() function call when using the R package 
R2WinBUGS with BRugs commands as follows.
library("BRugs")
modelCheckU'wtmodel .txt")
modelData(bugsData(
list("y", "n","muO", "tauO", "alphaO", "lambdaO"))
)
modelCompile(numChains=3)

Software for Sampling Posterior Distributions 
537
# initial values for three chains
mu <- rnormd, mean=120, sd=5)
tau <- runifU, min=0.1, max=10)
modelInits(bugsData(list("mu","tau")))
mu <- rnormU, mean=120, sd=5)
tau <- runif(l, min=0.1, max=10)
modellnits (bugsDatadist ("mu" , "tau")))
mu .<- rnormd, mean=120, sd=5)
tau <- runif(l, min=0.1, max=10)
modellnits (bugsDatadist ("mu" , "tau" ) ) )
modelUpdate(500) # burn-in 500 iterations
samplesSet(c("mu","tau")) # specify nodes to monitor
modelUpdate(1000)
samplesStats("
*")
samplesHistory("♦")
samplesDens ity("♦")
samplesBgr("
*")
samplesAutoCC'
*"
, 1)
# 
extract samples 
musamples <- samplesSample("mu") 
tausamples <- samplesSample("tau")
The R objects musamples and tausamples can be used in subsequent post-processing 
to accomplish inference for functions of these.
C.2 JAGS
JAGS [261], which humbly derives its name from Just Another Gibbs Sampler, is 
available for download at http://mcmc-jags.sourceforge.net/ and runs on multiple 
operating systems. In fact, the motivation for the development of JAGS was to 
have a BUGS-like program that will run in the Unix environment. JAGS is open­
source, and there is an active users’ group. The program shares many features 
with the original BUGS program, and the syntax is similar to that of WinBUGS, 
although there are some differences. Of particular interest for biostatisticians arc 
the differences in the way the programs handle censored observations.
We discuss the way to work with censoring when fitting an AFT regression model 
(see Section 12.1) in JAGS in the next section. We note that one does not have to 
use the same approach for handling censored data if one is fitting a proportional 

538
Bayesian Thinking in Biostatistics
hazards regression model as given in Section 12.2.2. An example program is in the 
folder for Chapter 12 on the book’s website. The file has PHRegression in the name.
Another difference between JAGS and WinBUGS or OpenBUGS is the ability 
to transform data within JAGS but separately from the programming carried out 
within the model block. One specifies these transformations in a set of programming 
statements enclosed in braces preceded by the keyword data. That is, the JAGS 
program would start with
data{
programming statements for data transformation
}
followed by statements specifying the sampling distribution and prior distributions
model{
programming statements
}
The programming statements could include things like standardizing covaxiates, 
computing logarithms, and similar one-time manipulations of the data. The ad­
vantage of having a separate data block is that the transformations will only occur 
once at the start of the program and not repeatedly at every iteration. Of course, 
one could also pass the transformed data to JAGS from R.
One can easily call JAGS from within the R programming environment, making 
it easy to use the graphical and analytical tools available there. There is the rjags 
package and a so-called wrapper package called R2jags that provides functionality 
similar to R2WinBUGS. The jagsUI package is another wrapper for rjags that 
tries to look and feel like R2WinBUGS, so one can easily move from JAGS to either 
WinBUGS or OpenBUGS.
C.2.1 Censored Data in JAGS
JAGS handles censored data (see Chapters 11 and 12) differently than BUGS. Cen­
soring is different from truncation, and unlike BUGS, JAGS can handle both. Cen­
soring simply means that we know that the observation could be larger than some 
value, although there was also a chance it could have been smaller. Truncation, 
on the other hand, means that the random variable cannot take values outside of 
the constrained range. An example of a truncated distribution is the half-normal 
distribution, which corresponds to the part of a normal density with mode at 0 but 
only allowing non-negative values. For example, one might specify a half-normal 
distribution for a standard deviation.
For censored data, JAGS uses the built-in function dinterval ( , ). For survival 
analysis with JAGS, dinterval( , ) is used as a distribution. The function takes

Software for Sampling Posterior Distributions 
539
two arguments. If we write y[i] ~ dinterval(t[i] , c[ij). then y[i] equals 0 
if t [i] < c [i] and 1 if t [i] > c [i].
In our survival analysis setting, we specify pairs (tj.c,) for each individual's 
event time and (potential) censoring time. Each individual has to have a potential 
censoring time, so we set c, to a very large number (call it tMax) if t, is an uncensored 
observation. The large number might be the largest possible follow-up time in the 
study under analysis.
We pass to JAGS an observation for each individual to indicate if the time is 
censored or not. For example, we can create a variable named is.censored[1] 
for each individual that we pass to JAGS with the data. This variable will equal 
1 if the observation is a censored time and 0 if it is the time the patient experi­
enced the event. We write in our JAGS program that this indicator variable has a 
distribution with the syntax is.censored[i] " dinterval(t [i], c[i]). In the 
statement, t[i] is either an actual time or missing (=NA), depending on whether 
the observation was the time of the actual event or a censoring time, respectively. 
The variable c [i] equals tMax if t [i] is an uncensored observation or a number a 
tiny bit larger than the follow-up time if t [i] is a censored observation. We wrote 
that c [i] should be a little larger than the censored follow-up time, because the 
function will expect 0 if t [i] equals c [i]. As a result of is. censored [i] equaling 
1 when the observation is censored and t [i] is missing, JAGS will impute a value 
for the censored time that is larger than c[i], thanks to the program statement 
is.censored[i] ~ dinterval(t[i], c[i]).
We give the JAGS statements for the larynx cancer example in Chapter 12 (sec 
Example 12.1). We fit a log-normal AFT regression to the data. In the program, 
the statements that specify the AFT model are the following.
is.censored[i] “ dinterval(t[i], c [i]) 
t[i] ~ dinorm(mu[i], tau)
We see that the variable is.censored[i] will be 0 or 1, depending on whether 
t [i] is less than or equal to c [i] or not. We specify t [i] as missing in the data we 
pass to JAGS, so only imputed values that are greater than c [i] will be allowed. 
Uncensored observations are treated as log-normally distributed observations in the 
program.
model {
### Create standardized covariates & means
for (i in l:(oldn + predn)) {
sAgefi] <- (age[i]-mean(age[l:oldn]))/sd(age[l:oldnj) 
sYr[i] <- (yr[i]-mean(yr[l:oldn]))/sd(yr[l:oldn]) 
mu[i] <- beta[l] + beta[2]«equals(stage[i],2)
+ beta[3]«equals(stage[i],3) 
+ beta[4]«equals(stage[i],4) 
+ beta[5]«sAge[i] + beta[6]
*sYr[i]
 
# 5 month survival probabilities using covariates in the data 
S[i] <- 1- phi((log(5)-mu[i])«sqrt(tau))

540
Bayesian Thinking in Biostatistics
# Medians corresponding to the covariates in the date
med[i] <- exp (mu [i] )
}
### Model observed subjects
for (i in l:oldn) <
is.censored[i] ~ dintervalCt [i], c[i]) 
t[i] ~ dinorm (mu [i] , tau)
1
# Make predictions for combinations of covariates
ford in l.'predn) <
predtdj ~ dinorm (mud + oldnj, tau)
for (i in 1:6) < 
betadJ ~ dnorm(0,0.000001) 
rmd] <- exp(beta[i]) # RMs for each variable
1
tau “ Hgatnina (О - ОО1,0.001.)
sigma <- sqrtCl/tau)
C.3 Stan and rstan
Stan [64] is another program that one can use for fitting complex Bayesian models to 
analyze data. Like the BUGS-based programs (WinBUGS, OpenBUGS, and JAGS), 
Stan uses simulation to generate posterior samples. After the Markov chain has 
converged, one can treat the sample the program generated like random samples 
from the posterior distribution of interest. Stan has a very active users’ group that 
contributes many example programs for fitting complex models.
A key difference between Stan and the BUGS-based programs is how Stan forms 
the Markov chain. Stan uses Hamiltonian Monte Carlo, whereas BUGS and related 
programs use methods based on the Metropolis Hastings algorithm which includes 
Gibbs sampling (cf. Sections 4.4.1 and 4.4.2). We provide an overview of Hamilto­
nian Monte Carlo in Section 4.4.4.
There are a few other differences between Stan and WinBUGS that are worth 
pointing out. One difference is that, one can compile a Stan prograni into a dynamic 
shared object that one can execute! multiple times to generate samples. With the 
resulting object, one can carry out inference with this model and t he same or similar 
data multiple times without the need to recompile the1 program. WinBUGS. Open­
BUGS. ami JAGS require that one use an interpreter that is part of t lie respective 
package each time one wishes to run a program to analyze data. Tims, while it

Software for Sampling Posterior Distributions
may take longer initially to compile a Stan program than it takes to interpret a 
comparable program in WinBUGS. one will save time later if one wishes to reuse 
the same Stan program with the same or different data.
An idiosyncrasy of Stan, or really of the Hamiltonian Monte Carlo algorithm’s 
reliance on gradients for directing proposals, is that one cannot haw model para­
meters or latent variables that have discrete probability distributions. While this 
restriction to continuous parameters may seem highly limiting, one can sometimes 
find ways to work around it for many models. We show one such method in Chapter 
9 where we discuss zero-inflated Poisson models (Section 9.2.2). The Stan code for 
that model is available on the book’s website for Chapter 9.
Structure of a Stan Program
Programs for characterizing models in Stan are built around specifying a like­
lihood and a prior distribution. In this respect, Stan is similar to the BUGS-like 
programs. The actual structure of a Stan program is different, however. Also, all 
programming statements have to end with a semicolon (;).
Stan programs consist of blocks. Some blocks tire required, and some are op­
tional. The six main blocks that make up a Stan program are, in order, a data block, 
a transformed data block, a parameters block, a transformed parameters block, a 
model block, and a generated quantities block. At a minimum, one will probably 
want to use three of the blocks, namely, the data, parameters, and model blocks. 
In addition to the general program blocks, one can also write one’s own functions 
for use in a Stan program. User-written function blocks are contained in separate 
function blocks that appear at the start of the Stan program, before the data block.
Each block starts with the name of the block as a keyword, followed by the 
block’s statements enclosed in curly braces. Here is a brief description of each block. 
We note that none of the blocks are required, although a blank file will generate a 
warning. Furthermore, declarations of variables must precede program statements 
within a block. Finally, included blocks must be in the order in which we present 
them here.
The data block. This block tells Stan which variables in the program are fixed 
quantities that one inputs to Stan. These quantities do not change while the Stan 
program is executing. The primary quantities that appear in the data block are 
the observations and any fixed quantities that one uses in the program, such as 
the parameters in prior distributions. Within the data block, one specifies the data 
type of each quantity. There are many data types in Stan. The ones that we use 
most often are integer, real, vector, and matrix or array.
The transformed data block. This block allows one to create new fixed quantities 
or carry out mathematical calculations on entities defined in the data block. Stan 
includes many built-in functions that one can use to carry out transformations 
of the data, such as taking logarithms, square roots, standardizing, and so on. 
Within this block, one first defines the new derived variables’ names, along with 
their respective data types. The declarations precede the program statements that 
involve the quantities.

542
Bayesian Thinking in Biostatistics
The parameters block. After introducing the data and any other fixed quantities 
or transformations of each, one tells Stan about the random unobserved quantities 
in the probability model one is fitting to the data. The parameters block tells Stan 
about the model parameters and any other unobserved variables one may have 
in the model. Again, we first declare the data types before we use any variables. 
Examples of unobservables that one might define in a parameters block are the 
rate parameter in a Poisson distribution or the mean and standard deviation in a 
normal model.
The transformed parameters block. Just as one could carry out calculations and 
transformations with the fixed quantities defined in the data block, one can carry 
out transformations of parameters using Stan’s built-in functions. The transformed 
parameters block will contain statements that create new parameters from para­
meters given in the parameters block and, possibly, the data. An example of a 
simple transformed parameter is the standard deviation, defined as the square root 
of the variance, with the variance defined in the parameters block. When fitting a 
regression, the expected value of an observation will be declared as a transformed 
parameter and then defined as some function of regression coefficients (given in the 
parameters block) and covariates in the data block or transformed data block. An­
other example is a vector of missing values that one wishes to impute as functions 
of covariates.
The model block. This block comes next in the Stan program. It describes 
the prior distribution of the parameters (parameters block) and the likelihood. 
The syntax in the model block is similar to the syntax in the BUGS language. 
In particular, one uses the tilde (“~”) to characterize a variable’s distribution, 
whether parameters or the likelihood. Again, all statements in Stan must end with a 
semicolon. No variables may be introduced in the model block, with a few exceptions 
such as indexing variables in loops. In several complex problems, one may wish to 
compute the likelihood explicitly instead of declaring the distribution of the data 
outcomes.
The generated quantities block. This last block consists of statements that op­
erate on the Markov chain iterates at each iteration of the sampler. One would 
generate predicted values in this block. In a regression model, for example, one 
may wish to consider different sets of covariates. In this block, one would write the 
statements to compute predicted means or predicted observations for observations 
with a new set of covariates. One could also generate any other functions of the 
data and parameters that one does not need to define in the sampling model (prior 
and likelihood).
Stan includes a host of built-in functions for distributions and specialized data 
types, such as a correlation matrix data type. As noted above, one can also write 
one’s own functions and put these in a function block at the beginning of the 
program (i.e., before the data block).
There is a package rstan that makes it easy to run Stan programs from within 
R. The package contains R functions for running Stan, retrieving output from Stan 
once the program is done, and evaluating the generated samples for convergence, 
etc.

Software for Sampling Posterior Distributions
Example C.3. We illustrate Stan by returning to Example C.2 but use Stan for 
posterior inference instead of OpenBUGS. In that example, we fit a simple normal 
model to make inference about the average weights of the veterans in the VetBP 
data set. The targets of inference were the mean, standard deviation, and the co­
efficient of variation of the men's weights. The model in Example C.2 consists of 
a Gaussian likelihood, a Gaussian prior for the mean, and a Gamma prior for the 
precision (i.e.. the reciprocal of the variance). The probability model is
у | д,ст2 ~ N(/t.a2)
p. ~ 
er,,) indep. ст2 ~ Inv-ganima(oo. Ao)
or ц ~ 
<t2) indep. т ~ gamma(oiQ, Ao).
The Stan program, available on the book’s website in a file named wtmodel.stan 
fits the same model.
One thing we wish to emphasize is the difference between Stan and the BUGS-like 
languages for characterizing normal or Gaussian distributions. The BUGS language 
programs specify the normal distribution in terms of the mean and the precision. 
In Stan, we specify the normal distribution in terms of the mean and the standard 
deviation. We will often, therefore, specify a prior distribution for the standard 
deviation when we use Stan. We could instead put a prior distribution on the 
variance or precision in Stan, but we would have to be careful about transformation 
of variables in any computation involving the densities. We refer the reader to the 
web for a discussion of transforming variables in Stan.
data {
int N; 
// Number of observations
vector[N] y; // Dependent variable
real alphaO;
real lambdaO;
real muO;
real tauO;
}
parameters {
real mu;
real<lower=0> precision;
}
transformed parameters-f
// Stan uses the standard deviation, 
// not the variance or precision, 
real sigma;
sigma = l/sqrt(precision);
}

544
Bayesian Thinking in Biostatistics
model {
mu " normal(muO, sqrt(1/tauO));
precision " gamma(alphaO, lambdaO);
for (i in 1:N) {
y[i] " normal(mu, sigma);
There are a few things to notice about this Stan program. First of all, there 
are more statements than we had in the BUGS-language program in Example C.2 
to accomplish the same thing. Many of the extra programming statements concern 
declarations of variables in the program. With a few exceptions, all variables that 
appear in a Stan program have to be declared at the start of the appropriate block. 
There are also more statements in the Stan program, because we wanted to use the 
precisions for the normal distributions to match the WinBUGS analysis in Example 
C.2. We could manage to save a few lines of code in the model block by specifying 
the likelihood without a for statement. We could instead write
model {
mu " normal(muO, sqrt(1/tauO));
precision " gamma(alphaO, lambdaO) 
у " normal(mu, sigma);
Stan knows that у is a vector, because we declared it to be so in the data block. Since 
the observations are conditionally independent (given p and cr) and у is a vector, 
Stan will substitute the appropriate statements when compiling the code. We wrote 
the likelihood specification as a loop to match the earlier WinBUGS example. Note 
that one of the advantages of declaring variables in Stan, especially vectors and 
matrices, is the ability to exploit the built-in vectorization capabilities of Stan.
We now review some of the features of the R package rstan for interacting with 
Stan from within the R environment. We first create the necessary objects in R to 
pass to the Stan program. Then we run Stan and generate posterior samples that we 
store in a stanfit object. We then carry out some inferences based on the MCMC 
output. The inferences are the same as the ones we include in Example C.2. One 
can either have the Stan code in a text file or make the Stan program a character 
object in R.
The R function stan() instructs Stan to generate posterior iterates. The R 
statements that follow provide inferences for the standard deviation a = l/т and 
coefficient of variation cv = a/p.
With the rstan package, one can pass data to Stan and retrieve the results 
of the MCMC in a similar manner as for WinBUGS, OpenBUGS, or JAGS. The 
statements below input the data, the names of the model parameters, and randomly 
generate (in R) initial values for random quantities. The call to the function stanO 
first converts the Stan program statements to C++, compiles the resulting C++ 
program, and then runs it to generate posterior samples.

Software for Sampling Posterior Oijttrtb tit ions
There? is another way to run Stan front R. While the fxuxctimx stanO xwVuxxWy 
accomplishes three steps, one can call the corresponAinp; three specific fxxxxctioxxs \u 
the rstan library in sequence if one wants uxore coutrof over the process, perhaps 
for debugging. The three steps are as follows.
• 
stancO This function translates the model statements ixx the Stan \auy,wayy 
to code» in C + + .
• 
stanjnodelO This function compiles the C + + code into ix binary shaved 
object . Tin? function also loads this executable shared object into tlxv current 
R session.
• 
sampling This function actually runs the executable program to draw 
samples. The output is “■wrapped” into an object of class etanfit.
Here is an example of statements in R that will prepare tbe files that rstan will 
send to Stan when we run it from R. The data arc in the file VetBP .csv.
library(rstan) 
library(coda)
# Read the data into object VetBPdata
VetBPdata = read.csv("VetBP.csv", header=T)
# Remove missing values
# Get indices of non-missing observations
ok <- ! is . na(VetBPdata$VJeight_00)
# Create vector of non-missing observations
у <- VetBPdata$Weight_OO(okj
n <- length(y) # Variable with the sample size.
# Set the hyperparameters.
alphaO <- 0.1; lambdaO <- 0.1;
muO <- 150; tauO <- 0.001
# Create a list object with elements for 
# the data block.
data <- listCn", "y", "muO", "tauO", "alphaO", "lambda0"j
# Create a function that will generate
# 
random initial values for the MCMC chains.
inits <- functionO <
list(mu = rnorm(l, mean=120, sd=5), 
tau = runif(l, min=0.1, max=10j)
# Create a character vector with the names
# of the parameters in the Stan model. 
parameters <- c("mu", "sigma"')
Now, run Stan from R.
VetBP.sim = stanC'wtmodel.stan" , data=data, 
pars=parameters, init=inits, chains=3, iter=10000')')

546
Bayesian Thinking in Biostatistics
After Stan has finished running and performed the requested number of iterations, it 
returns control to the user’s R session. At this point, one can examine the MCMC 
output that Stan returned. Summary statistics and plots are available via some 
functions in the rstan package or other R packages (e.g., the coda and bayesplot 
packages) that are available for carrying out Bayesian inference with MCMC output.
Summary statistics via the statement print(VetBP.sim) are as follows.
Inference for Stan model: wtmodel.
3 chains, each with iter-10000; warmup-5000; thin-1; 
post-warmup draws per chain-5000, total post-warmup draws-15000.
mean se.mean sd 2.57. 257. 507. 757. 97.57. n.eff Rhat 
mu 209.91 0.02 2.20 205.63 208.43 209.92 211.39 214.20 12279 1 
sigma 44.10 0.01 1.54 41.23 43.04 44.06 45.11 47.31 12838 1 
lp _ -1729.95 0.01 1.00 -1732.67 -1730.33 -1729.64 -1729.24 -1728.98 6846 1
Samples were drawn using NUTS(diag.e) at Wed Jul 1 16:13:04 2020.
For each parameter, n_eff is a crude measure of effective sample size, 
and Rhat is the potential scale reduction factor on split chains (at 
convergence, Rhat-1).
We next use the features of the R package coda to check some characteristics 
of the MCMC output. We first extract the output from Stan into an object that 
is appropriate for coda. In this example, we create a list mcmc object with the R 
function As.mcmc.list that keeps the three Markov chains separate. (Note that 
the capital “A” in the function’s name is important for use with a stanfit object.)
MCMCout <- As.mcmc.list(VetBP.sim)
summary(MCMCout)
Iterations = 5001:10000
Thinning interval = 1
Number of chains = 3
Sample size per chain = 5000
1. Empirical mean and standard deviation for each variable, 
plus standard error of the mean:
2. Quantiles for each variable:
Mean
SD Naive SE Time-series SE
mu
209.9 2.197 0.017935
0.01928
sigma
44.1 1.545 0.012611
0.01346
1P—
-1729.9 1.003 0.008189
0.01226
2.57, 25% 
mu 205.63 208.43 
sigma 41.23 43.04 
lp__ -1732.67 -1730.33
507, 
757, 
97.57,
209.92 
211.39 
214.20
44.06 
45.11 
47.31
-1729.64 -1729.24 -1728.98

The coda plot function generates the graph shown in Figure C.5.
plot(MCMCout)
FIGURE C.5: Plots of Stan’s MCMC output with R package coda.
We can check autocorrelations with the rstan function stan.ac(), which pro­
duces a plot (Figure C.6). Note that the autocorrelations for д appear on the 
left-hand side of the figure and those for a on the right-hand side.
We can create a new parameter as a function of model parameters and use the 
saved posterior samples to infer its posterior distribution and characteristics related 
to it. For example, the following statements in R compute the coefficient of variation 
and plot its posterior distribution (see Figure C.7). We extract the MCMC samples 
from the stanfit object VetBP.sim using the rstan package function extractO. 
Recall that Stan returned the standard deviation, not the variance or precision. 
We note that we could also have generated posterior samples of the coefficient of 
variation in our Stan program.
Stan.out = extract(VetBP.sim, permute=FALSE)\\
CV = Stan.outf,,2]/Stan.out[,,1]\\
summary(CV)
chain:1 
chain:2 
chain:3
Min. 
:0.1841 
Min. :0.1845 Min. :0.1836

548
Bayesian Thinking in Biostatistics
FIGURE C.6: Plots of Stan’s MCMC output with function stan.ac.
1st Qu.:0.2049
Median :0.2098
Mean :0.2101 
3rd Qu.:0.2151
Max. :0.2397
1st Qu.:0.2049 
Median :0.2100 
Mean :0.2103 
3rd Qu.:0.2155
Max. :0.2432
1st Qu.:0.2048
Median :0.2099
Mean :0.2102 
3rd Qu. .-0.2153
Max. :0.2401
Histogram of Posterior CV Samples
FIGURE C.7: Posterior distribution based on Stan’s MCMC output.
Overall, the inference with Stan is similar to results in Example C.2.

Software for Sampling Posterior Distributions 
5-19
C.3.1 Censored Data in Stan
Stan does not have the same capability as BUGS or JAGS for handling censored 
data in a model for AFT regression. Instead, we take advantage of Stan's method 
for computing the log-likelihood and built-in functions for evaluating log densities 
and survival functions.
As with BUGS and JAGS, we use the larynx cancer data to illustrate a Stan pro­
gram for fitting an AFT regression model. We create two vectors of observations: 
one vector consists of uncensored observations, and the other has all of the censored 
observations. We then compute the regressions for each individual in each of the 
two sets that we use as the individual’s mean. We let Stan evaluate the density 
of each uncensored observation by indicating the sampling distribution using the 
appropriate density function. We cannot do the same thing for the censored obser­
vations, but we can add the log of the sampling distribution’s survival function to 
the overall log-likelihood via the Stan keyword target. That is, we increment the 
log-likelihood using built-in Stan functions. The calculation of the log-likelihood in 
the laryngeal cancer example is contained in the model block and appears as follows 
for a log-normal AFT regression analysis.
for(i in l:Nobs) {
tobs[i] “ lognormal(muobs[i], sigma);
ford in 1:Ncens) {
target += lognormal_lccdf(teens[i]I mucens[i], sigma);
The observed failure times are in the data vector tobs[], and the censored times 
are in the vector teens []. We tell Stan to model the observed failure times 
as lognormal ( , ) with mean equal to the regression that we compute in the 
transformed parameters block. For the censored observations, we increment the 
log-likelihood via the keyword target, evaluating the log of the log-normal sur­
vival function (lognormal_lccdf (t, mean, sigma)) at the censored time. The 
survival function has the AFT regression function as the mean for the obser­
vation and the standard deviation sigma. (The _lccdf in the Stan function 
lognormal_lccdf (t, mean, sigma) stands for “log complementary cumulative 
distribution function,” i.e., the log of 1 minus the cdf.)
The following Stan program fits a log-normal AFT regression to the larynx 
cancer data in Example 12.1. The program uses the same priors for 0 and the 
precision r as the examples in BUGS and JAGS earlier in this appendix.
data {
int<lower=0> Nobs;
int<lower=0> Ncens;
vector<lower=0>[Nobs] tobs;
vector<lower=0>[Ncens] teens;
vector[90] age;
vector[90] yr;

550
Bayesian Thinking in Biostatistics
int stageobs[Nobs];
vector[Nobs] ageobs;
vector[Nobs] yrobs;
int stagecens[Ncens];
vector[Ncens] agecens;
vector[Ncens] yrcens;
transformed data{
vector[Nobs] sAgeobs;
vector[Nobs] sYrobs;
vector[Ncens] sAgecens;
vector[Ncens] sYrcens;
sAgeobs = (ageobs-mean(age))/sd(age);
sYrobs = (yrobs-mean(yr))/sd(yr);
sAgecens = (agecens-mean(age))/sd(age);
sYrcens = (yrcens-mean(yr))/sd(yr);
parameters {
vector[6] beta;
real<lower=0> tau;
transformed parameters {
real sigma;
vector [Nobs] muobs;
vector[Ncens] mucens;
sigma = sqrt(l/tau);
ford in l:Nobs) {
muobs[i] = beta[l] + beta[2] * (stageobs [i] == 2) + 
beta[3]
*
(stageobs[i] == 3) + beta[4]
*
(stageobs [i] == 4) + 
beta [5]*sAgeobs[i]  + beta[6]*sYrobs  [i];
ford in l:Ncens) {
mucens[i] = beta[l] + beta[2] * (stagecens[i] == 2) + 
beta [3]
*
(stagecens[i] == 3) + beta[4]
*
(stagecens [i] == 4) + 
beta[5]*sAgecens[i]  + beta[6]*sYrcens  [i];
}
}
model {
ford in l:Nobs) {
tobs[i] ~ lognormal(muobs[i], sigma);
}
ford in l:Ncens) {
target += lognormal.lccdf(teens[i]| mucens [i], sigma);
ford in 1:6) {

Software for Sampling Posterior Distributions
551
beta[i] ~ normal(0, 1 I sqrt(0.000001));
}
tau " gamma(0.001,0.001);
}
We note that one does not have to use the same approach we just presented for 
censored data if one is fitting a proportional hazards regression model as given in 
Section 12.2.2. An example program is in the folder for Chapter 12 on the book's 
website. The file has PHRegression in the name. The basic idea is the same as given 
in Section 12.2.2 and is conceptually the same as in the programs for WinBUGS, 
OpenBUGS, and JAGS.
C.4 R Packages
WinBUGS has made it easier for researchers to implement the Bayesian inferen­
tial paradigm in their work. It began as a Microsoft® Windows® implementation 
of BUGS. In the above subsections we have seen enhancements and alternatives 
to WinBUGS that adapt to various operating systems. It is also possible to run 
Windows programs on computers that are using other operating systems. One ex­
ample is WINE, which allows one to run Windows programs on various Unix-based 
platforms, such as Solaris, BSD, Linux, and Mac OSX. Although WINE does not 
emulate Windows (in fact, the original acronym WINE stands for “Wine Is Not 
an Emulator”), it does allow one to run many Windows programs. The R function 
R2WinBUGS discussed in the previous section can also be used in WINE by spe­
cifying via an argument in the function that the code is running in WINE, and 
making sure that WinBUGS is set up to run via WINE.
Despite the large array of models one can implement in WinBUGS, sometimes 
there may be difficulties actually running the models or, in some situations, the 
specific Bayesian model is outside the scope of WinBUGS. Several R packages have 
targeted such situations, providing functionality to fit such models via R functions. 
Such packages are, of course, evolving continually, with new ones appearing with 
regularity. We briefly list some examples her:
• 
MCMCPack is a package written for R that fits many different Bayesian regres­
sion models using MCMC. The built-in regression models carry out posterior 
simulation and return objects that one can evaluate directly with the R pack­
age coda. The package includes models that are used commonly in the social 
and behavioral sciences, such as linear regression; logistic regression; probit 
regression, including probit models for ordinal outcomes; Poisson regression; 
and hierarchical extensions of some of these. It also includes change-point 
models and some functions that are useful in general, such as functions for 
the Wishart and Dirichlet distributions. MCMCPack carries out posterior sam-

552
Bayesian Thinking in Biostatistics
pling via routines written mostly in programming languages, such as C++,
that can carry out the calculations much more quickly than R can.
• 
Learn Bayes [5] is a sizable collection of R functions that help in learning and 
using the basic ingredients of Bayesian analysis. Functions are available to 
carry out analysis of many commonly used models introduced in this book.
• 
DPpackage [176, 175] contains a set of R functions for fitting Bayesian non­
parametric and semiparametric models. While we do not address such models 
in a distinct chapter in this book, references are made to these, especially for 
survival modeling, in Chapters 11 and 12. The package includes functions 
for semiparametric density estimation, ROC curve analysis, fitting models 
for interval censored data, binary regression models, generalized linear mixed 
models, among others. The Bayesian nonparametric models are based on the 
Dirichlet process (Section 3.3.2) or Polya tree models.
• 
DPWeibull [295, 294] contains functions to analyze time-to-event or survival 
data via a semiparametric model based on Dirichlet process mixtures of 
Weibull distributions. Analysis of data with and without covariates is avail­
able, including some graphical displays of results. The package also provides 
for analysis of competing-risks data and handles most commonly seen cen­
sored data as well as time-varying covariates.
• 
spBayesSurv [364, 365] addresses semiparametric survival analysis models, in­
cluding for spatially correlated data. Several different types and approaches 
to models are implemented and various types of censoring are allowed. The 
package also provides calculations of three different model choice criteria.
• 
BART [74, 240, 301, 302] provides nonparametric regression analyses for var­
ious types of outcomes (continuous, binary, multinomial, survival) using en­
sembles of Bayesian additive regression trees. It also includes corresponding 
models that allow a Dirichlet prior on probabilities for choosing covariates at 
tree nodes (DART [230]). Some post-processing functions are provided, as are 
the posterior tree ensembles themselves (for possible later processing by the 
user).

[1] 
C. J. Adcock. A Bayesian approach to calculating sample sizes. The Statisti­
cian, 37(4/5):433-439, 1988.
[2] 
C. J. Adcock. Sample size determination: A review. The Statistician, 
46(2):261-283, 1997.
[3] 
J. Aitchison and I. R. Dunsmore. Statistical Prediction Analysis. Cambridge 
University Press, Cambridge, 1st edition, 1975.
[4] 
H. Akaike. A new look at the statistical model identification. IEEE Trans­
actions on Automatic Control, 19(6):716—723, 1974.
[5] 
J. Albert. LearnBayes: Functions for learning Bayesian inference. R-package 
Version 2.15.1, 2018. 
.
https://CRAN.R-project.org/packagesLearnBayes
[6] 
P. K. Andersen and R. D. Gill. Cox’s regression model for counting processes: 
A large sample study. Annals of Statistics, 10(4): 1100-1120, 12 1982.
[7] 
F. J. Anscombe. Sequential medical trials. Journal of the American Statistical 
Association, 58(302):365-383, 1963.
[8] 
S. G. Arbuck. Workshop on phase I study design. Ninth NCI/EORTC New 
Drug Development Symposium, Amsterdam, March 12, 1996. Annals of On­
cology, 7(6):567-73, 1996.
[9] 
P. Armitage. Sequential Medical Trials. Thomas, Springfield, IL, 1960.
[10] 
P. Armitage. Reply to discussion ‘On the allocation of treatments in sequential 
medical trials’ by J.A. Bather and ‘The search for optimality in clinical trials’ 
by P. Armitage. International Statistical Review / Revue Internationale de 
Statistique, 53(1 ):36, 1985.
[11] 
P. Armitage. The search for optimality in clinical trials. International Stat­
istical Review / Revue Internationale de Statistique, 53(l):15-24, 1985.
[12] 
В. C. Arnold and S. J. Press. Compatible conditional distributions. Journal 
of the American Statistical Association, 84(405):152-156, 1989.
[13] 
H. Aslanidou, D. K. Dey, and D. Sinha. Bayesian analysis of multivariate 
survival data using Monte Carlo methods. Canadian Journal of Statistics / 
Revue Canadienne de Statistique, 26(l):33-48, 1998.
553

554
Bibliography
[14] 
J. Babb, A. Rogatko, and S. Zacks. Cancer phase I clinical trials: Efficient 
dose escalation with overdose control. Statistics in Medicine, 17(10):l 103-20, 
1998.
[15] 
S. Banerjee, B. Carlin, and A. Gelfand. Hierarchical Modeling and Analysis 
for Spatial Data. Chapman and Hall/CRC, Boca Raton, FL, 2nd edition, 
2015.
[16] 
С. M. Barker, W. O. Johnson, B. F. Eldridge, В. K. Park, F. Melton, and 
W. K. Reisen. Temporal connections between culex tarsalis abundance and 
transmission of western equine encephalomyelitis virus in California. Ameri­
can Journal of Tropical Medicine and Hygiene, 82(6):1185—1193, 2010.
[17] 
M. S. Bartlett. A comment on D. V. Lindley’s statistical paradox. Biometrika, 
44(3/4) .-533-534, 1957.
[18] 
R. H. Bartlett, D. W. Roloff, R. G. Cornell, A. F. Andrews, P. W. Dillon, 
and J. B. Zwischenberger. Extracorporeal circulation in neonatal respiratory 
failure: A prospective randomized study. Pediatrics, 76(4):479-87, 1985.
[19] 
J. A. Bather. On the allocation of treatments in sequential medical trials. In­
ternational Statistical Review / Revue Internationale de Statistique, 53(1):1— 
13, 1985.
[20] 
J. A. Bather. Reply to discussion ‘On the allocation of treatments in sequen­
tial medical trials’ by J.A. Bather and ‘The search for optimality in clinical 
trials’ by P. Armitage. International Statistical Review / Revue Internationale 
de Statistique, 53(l):35-36, 1985.
[21] 
M. J. Bayarri and J. O. Berger. P values for composite null models. Journal 
of the American Statistical Association, 95:1127-1142, 2000.
[22] 
M. J. Bayarri and J. O. Berger. The interplay of Bayesian and frequentist 
analysis. Statistical Science, 19(l):58-80, 2004.
[23] 
E. J. Bedrick, R. Christensen, and W. Johnson. A new perspective on priors 
for generalized linear models. Journal of the American Statistical Association, 
91:1450-1460, 1996.
[24] 
E. J. Bedrick, R. Christensen, and W. Johnson. Bayesian binomial regression: 
Predicting survival at a trauma center. The American Statistician, 51(3):211 
218, 1997.
[25] 
E. J. Bedrick, R. Christensen, and W. O. Johnson. Bayesian accelerated 
failure time analysis with application to veterinary epidemiology. Statistics 
in Medicine, 19(2):221-237, 2000.
[26] 
R. E. Bellman. Dynamic Programming. Princeton University Press, Prince­
ton. NJ. 1957.

Bibliography
555
[27] 
D. A. Belsley, E. Kuh, and R. E. Welsch. Regression Diagnostics: Identifying 
Influential Data and Sources of Collinearity. John Wiley &: Sons. New York. 
1980.
[28] 
D. J. Bern, J. Utts, and W. O. Johnson. Must psychologists change the 
way they analyze their data? Journal of Personality and Social Psychology, 
101(4):716-719, 2011.
[29] 
J. O. Berger. Statistical Decision Theory and Bayesian Analysis. Springer- 
Verlag, New York, 1993.
[30] 
J. O. Berger. The case for objective Bayesian analysis. Bayesian Analysis, 
l(3):385-402, 2006.
[31] 
J. O. Berger and M. Delampady. Testing precise hypotheses. Statistical 
Science, 2(3):317-335, 1987.
[32] 
J. О Berger and T. Sellke. Testing a point null hypothesis: The irreconcilabil­
ity of p values and evidence. Journal of the American Statistical Association, 
82(397): 112-122, 1987.
[33] 
J. O. Berger and R. L. Wolpert. The Likelihood Principle. Institute of Math­
ematical Statistics, Hayward, CA, 2nd edition, 1988.
[34] 
J. M. Bernardo. Reference posterior distributions for Bayesian inference. 
Journal of the Royal Society, Series B, 41 (2): 113-147, 1979.
[35] 
J. M. Bernardo and A. F. M. Smith. Bayesian Theory. John Wiley & Sons, 
Chichester, 1994.
[36] 
D. A. Berry. Statistics: A Bayesian Perspective. Duxbury Press, Belmont, 
CA, 1996.
[37] 
D. A. Berry, C. Cirrincione, I. C. Henderson, M. L. Citron, D. R. Budman, 
L. J. Goldstein, S. Martino, E. A. Perez, H. B. Muss, L. Norton, C. Hudis, and 
E. P. Winer. Estrogen-receptor status and outcomes of modern chemother­
apy for patients with node-positive breast cancer. Journal of the American 
Medical Association, 295(14):1658-67, 2006.
[38] 
D. A. Berry and B. Fristedt. Bandit Problems: Sequential Allocation of Ex­
periments. Chapman & Hall, London, 1985.
[39] 
D. A. Berry and С. H. Ho. One-sided sequential stopping boundaries for 
clinical-trials: A decision-theoretic approach. Biometrics, 44(1):219 227, 
1988.
[40] 
D. A. Berry, P. Mueller, A. P. Grieve, M. K. Smith, T. Parke, and M. Krams. 
Bayesian designs for dose-ranging drug trials. In C. Gatsonis, R. E. Kass, 
B. Carlin, A. Carriquiry, and A. Gelman, editors, Case Studies in Bayesian 
Statistics, Vol. 5, pages 99-181. Springer-Verlag, New York, 2002.

556
Bibliography
[41] 
S. M. Berry, В. P. Carlin, J. J. Lee, and P. Muller. Bayesian Adaptive Methods 
for Clinical Trials. CRC Press, Boca Raton, FL, 2011.
[42] 
M. Betancourt. A conceptual introduction to Hamiltonian Monte Carlo. 
Preprint, arXiv:1701.02434, 2017.
[43] 
J. Blum and V. Susarla. On the posterior distribution of a Dirichlet process 
given randomly right censored observations. Stochastic Processes and their 
Applications, 5(3):207-211, 1977.
[44] 
G. E. P. Box. Science and statistics. Journal of the American Statistical 
Association, 71(356):791-799, 1976.
[45] 
G. E. P. Box. Sampling and Bayes’ inference in scientific modelling and 
robustness. Journal of the Royal Statistical Society, Series A, 143(4):383- 
404, 1980.
[46] 
G. E. P. Box and D. R. Cox. An analysis of transformations. Journal of the 
Royal Statistical Society, Series B, 26(2):211-252, 1964.
[47] 
A. J. Branscum, I. A. Gardner, and W. O. Johnson. Bayesian modeling of 
animal- and herd-level prevalences. Preventive Veterinary Medicine, 66(1— 
4):101—112, 2004.
[48] 
A. J. Branscum, I. A. Gardner, and W. O. Johnson. Estimation of diag­
nostic test sensitivity and specificity through Bayesian modeling. Preventive 
Veterinary Medicine, 68:145-163, 2005.
[49] 
A. J. Branscum, W. O. Johnson, T. E. Hanson, and A. T. Baron. Flexible 
regression models for ROC and risk analysis, with or without a gold standard. 
Statistics in Medicine, 34(30):3997-4015, 2015.
[50] 
A. J. Branscum, W. O. Johnson, T. E. Hanson, and I. A Gardner. Bayesian 
semiparametric ROC curve estimation and disease diagnosis. Statistics in 
Medicine, 27(13):2474-2496, 2008.
[51] 
A. J. Branscum, A. M. Perez, W. O. Johnson, and M. C. Thurmond. Bayesian 
spatiotemporal analysis of foot-and-mouth disease data from the Republic of 
Turkey. Epidemiology and Infection, 136(6):833-842, 2008.
[52] 
N. E. Breslow and D. G. Clayton. Approximate inference in generalized linear 
mixed models. Journal of the American Statistical Association, 88(421):9- 25, 
1993.
[53] 
A. E. Brockwell and J. B. Kadane. A gridding method for Bayesian sequen­
tial decision problems. Journal of Computational and Graphical Statistics, 
12(3):566 584, 2003.
[54] 
L. D. Broemeling. Bayesian Analysis of Linear Models. Marcel Dekker, New 
York. 1985.

Bibliography
557
[55] 
L. D. Broemeling. Bayesian Biostatistics and Diagnostic Medicine. Chapman 
and Hall/CRC, Boca Raton, FL, 2007.
[56] 
S. P. Brooks and A. Gelman. General methods for monitoring convergence 
of iterative simulations. Journal of Computational and Graphical Statistics. 
7(4):434—455, 1998.
[57] 
J. Brophy and L. Joseph. A Bayesian meta-analysis of randomiztxl inega- 
trials for the choice of thrombolytic agents in acute myocardial infarction. In 
D. K. Stangl and D. A. Berry, editors, Meta-Analysis in Medicine and Health 
Policy, pages 83-104. Marcel Dekker, New York, 2000.
[58] 
J. M. Brophy and L. Joseph. Placing trials in context using Bayesian-analysis. 
GUSTO revisited by Reverend Bayes. Journal of the American Medical As­
sociation, 273(11):871-875, 1995.
[59] 
D. R. Budman, D. A. Berry, С. T. Cirrincione, I. C. Henderson, W. C. Wood, 
R. B. Weiss, C. R. Ferree, H. B. Muss, M. R. Green, L. Norton, and E. Frei. 
Dose and dose intensity as determinants of outcome in the adjuvant treatment 
of breast cancer. The Cancer and Leukemia Group B. Journal of the National 
Cancer Institute, 90(16):1205-ll, 1998.
[60] 
J. Cao, J. J. Lee, and S. Alber. Comparison of Bayesian sample size crite­
ria: ACC, ALC, and WOC. Journal of Statistical Planning and Inference, 
139(12):4111-4122, 2009.
[61] 
В. P. Carlin and A. E. Gelfand. An iterative Monte Carlo method for non­
conjugate Bayesian analysis. Statistics and Computing, 1:119-128, 1991.
[62] 
В. P. Carlin, J. B. Kadane, and A. E. Gelfand. Approaches for optimal 
sequential decision analysis in clinical trials. Biometrics, 54(3):964-975, 1998.
[63] 
В. P. Carlin and T. A. Louis. Bayesian Methods for Data Analysis. Chapman 
and Hall/CRC, Boca Raton, FL, 2009.
[64] 
B. Carpenter, A. Gelman, M. Hoffman, D. Lee, B. Goodrich, M. Betancourt, 
M. Brubaker, J. Guo, P. Li, and A. Riddell. Stan: A probabilistic program­
ming language. Journal of Statistical Software, 76(1):1—32, 2017.
[65] 
G. Casella and R. Berger. Statistical Inference. Thomson Learning, Pacific 
Grove, CA, 2nd edition, 2002.
[66] 
G. Casella and E. I. George. Explaining the Gibbs sampler. The American 
Statistician, 46:167-174, 1992.
[67] 
J. E. Cavanaugh and A. A. Neath. Generalizing the derivation of the Schwarz 
information criterion. Communications in Statistics: Theory and Methods, 
28(l):49-66, 1999.

558
Bibliography
[68] 
C. Celeux, F. Forbes, С. P. Robert, and D. M. Titterington. Deviance in­
formation criteria for missing data models. Bayesian Analysis, 1:651-673, 
2006.
[69] 
M.-H. Chen, M. de Castro, M. Ge, and Y. Zhang. Bayesian regression models 
for competing risks. In J. P. Klein, H. C. VanHouwelingen, J. G. Ibrahim, 
and T. H. Scheike, editors, Handbook of Survival Analysis, pages 179-198. 
Chapman and Hall/CRC, Boca Raton, FL, 2014.
[70] 
M.-H. Chen, D. K. Dey, P. Miiller, D. Sun, and K. Ye. Frontiers of Statist­
ical Decision Making and Bayesian Analysis: In Honor of James 0. Berger. 
Springer-Verlag, New York, 2010.
[71] 
Y. K. Cheung. Dose Finding by the Continual Reassessment Method. CRC 
Press, Boca Raton, FL, 2011.
[72] 
Y. K. Cheung and R. Chappell. Sequential designs for phase I clinical trials 
with late-onset toxicities. Biometrics, 56(4):1177—1182, 2000.
[73] 
S. Chib and E. Greenberg. Understanding the Metropolis-Hastings algorithm. 
The American Statistician, 49(4):327-335, 1995.
[74] 
H. A. Chipman, E. I. George, and R. E. McCulloch. BART: Bayesian additive 
regression trees. Annals of Applied Statistics, 4(l):266-298, 2010.
[75] 
Y.-K. Choi, W. O. Johnson, and M. C. Thurmond. Diagnosis using predictive 
probabilities without cut-offs. Statistics in Medicine, 25(4):699-717, 2006.
[76] 
R. Christensen. Log-Linear Models and Logistic Regression. Springer-Verlag, 
New York, 2nd edition, 1997.
[77] 
R. Christensen. Plane Answers to Complex Questions: The Theory of Linear 
Models. Springer, New York, 4th edition, 2011.
[78] 
R. Christensen and W. Johnson. A conversation with Seymour Geisser. Stat­
istical Science, 22(4) :621-636, 2007.
[79] 
R. Christensen, W. Johnson, A. Branscum, and T. Hanson. Bayesian Ideas 
and Data Analysis: An Introduction for Scientists and Statisticians. Chapman 
and Hall/CRC, Boca Raton, FL, 2010.
[80] 
D. Clayton. Some approaches to the analysis of recurrent event data. Stat­
istical Methods in Medical Research, 3(3):244-262, 1994.
[81] 
D. G. Clayton. A model for association in bivariate life tables and its ap­
plication in epidemiological studies of familial tendency in chronic disease 
incidence. Biometrika, 65(1):141-151, 1978.
[82] 
\V. S. Cleveland. LOWESS: A program for smoothing scatterplots by robust 
locally weighted regression. The American Statistician, 35(1 ):54, 1981.

Bibliography
559
[83] 
G. A. Colditz, M. J. Stampfer, W. C. Willett, С. H. Hennekens, B. Reisner, 
and F. E. Speizer. Prospective study of estrogen replacement therapy and 
risk of breast cancer in postmenopausal women. Journal of the American 
Medical Association, 264(20) :2648-2653, 1990.
[84] 
D. Collett. Modelling Survival Data in Medical Research. CRC Press. Boca 
Raton, FL, 2015.
[85] 
R. D. Cook. Detection of influential observation in linear regression. Techno­
metrics, 19(1):15—18, 1977.
[86] 
R. D. Cook and S. Weisberg. Residuals and Influence in Regression. Chapman 
& Hall, New York, 1982.
[87] 
R. D. Cook and S. Weisberg. Applied Regression Including Computing and 
Graphics. John Wiley & Sons, 2009.
[88] 
D. R. Cox. Regression models and life-tables (with discussion). Journal of 
the Royal Statistical Society, Series B, 34(2):187-220, 1972.
[89] 
M. De Backer, P. De Keyser, C. De Vroey, and E. Lesaffre. A 12-week treat­
ment for dermatophyte toe onychomycosis terbinafine 250mg/day vs. itra­
conazole 200mg/day—a double-blind comparative trial. British Journal of 
Dermatology, 134(s46):16-17, 1996.
[90] 
M. De Iorio, W. O. Johnson, P. Muller, and G. L. Rosner. Bayesian nonpara­
metric nonproportional hazards survival modeling. Biometrics, 65(3) :762 
771, 2009.
[91] 
M. H. DeGroot. Optimal Statistical Decisions. John Wiley & Sons, Hoboken, 
NJ, 2004.
[92] 
M. Delampady and J. O. Berger. Lower bounds on Bayes factors for multi­
nomial distributions, with application to chi-squared tests of fit. Annals of 
Statistics, 18(3):1295-1316, 1990.
[93] 
P. Dellaportas and A. F. M. Smith. Bayesian inference for generalized lin­
ear and proportional hazards models via Gibbs sampling. Applied Statistics, 
42(3):443-459, 1993.
[94] 
N. Dendukuri and L. Joseph. Bayesian approaches to modeling the conditional 
dependence between multiple diagnostic tests. Biometrics, 57(1): 158 167, 
2001.
[95] 
L. Devroye. Non-Uniform Random Variate Generation. Springer-Ver lag, New 
York, 1986.
[96] 
D. K. Dey, S. K. Ghosh, and В. K. Mallick. Generalized Linear Models: A 
Bayesian Perspective. CRC Press, Boca Raton, FL, 2000.

560
Bibliography
[97] 
M. Ding, G. Rosner, and P. Muller. Bayesian optimal design for phase II 
screening trials. Biometrics, 64(3):886-894, 2008.
[98] 
N. R. Draper and H. Smith. Applied Regression Analysis. John Wiley & Sons, 
New York, 1998.
[99] 
S. Duane, A. D. Kennedy, B. J. Pendleton, and D. Roweth. Hybrid Monte 
Carlo. Physics Letters B, 195(2):216-222, 1987.
[100] 
R. L. Dykstra and P. Laud. A Bayesian nonparametric approach to reliability. 
Annals of Statistics, 9(2):356-367, 1981.
[101] 
J. H. Edmonson, T. R. Fleming, D. G. Decker, G. D. Malkasian, E. O. Jor­
gensen, J. A. Jefferies, M. J. Webb, and L. K. Kvols. Different chemother­
apeutic sensitivities and host factors affecting prognosis in advanced ovar­
ian carcinoma versus minimal residual disease. Cancer Treatment Reports, 
63(2):241-247, 1979.
[102] 
R. M. Elashoff, G. Li, and N. Li. Joint Modeling of Longitudinal and Time- 
to-Event Data. CRC Press, Boca Raton, FL, 2017.
[103] 
C. Enpe, M. P. Georgiadis, and W. O. Johnson. Estimation of sensitivity and 
specificity of diagnostic tests and disease prevalence when the true disease 
state is unknown. Preventive Veterinary Medicine, 45(1-2):61-81, 2000.
[104] 
X. Fan. Bayesian Nonparametric Inference for Competing Risks Data. Ph.D. 
Dissertation, Medical College of Wisconsin, 2008.
[105] 
FDA. Guidance for Industry Estimating the Maximum Safe Starting Dose in 
Initial Clinical Trials for Therapeutics in Adult Healthy Volunteers, 2005.
[106] 
FDA. Guidance for the Use of Bayesian Statistics in Medical Device Clinical 
Trials. U.S. Department of Health and Human Services, Food and Drug 
Administration, Center for Devices and Radiological Health, Silver Spring, 
Maryland, February 2010.
[107] 
P. Feigl and M. Zelen. Estimation of exponential survival probabilities with 
concomitant information. Biometrics, 21(4):826-838, 1965.
[108] 
T. S. Ferguson. Bayesian analysis of some nonparametric problems. Annals 
of Statistics, l(2):209-230, 1973.
[109] 
T. S. Ferguson and E. G. Phadia. Bayesian nonparametric estimation based 
on censored data. Annals of Statistics, 7( 1): 163—186, 1979.
[110] 
D. Field, C. Davis, D. Elbourne, A. Grant, A. Johnson, and D. Macrae. UK 
collaborative randomised trial of neonatal extracorporeal membrane oxygena­
tion. Lancet, 348(9020) :75-82, 1996.

Bibliography
561
[111] 
L. S. Freedman, D. Lowe. D. J. Spiegelhalter. and P. Macaskill. Stopping 
rules that incorporate clinical opinion. Controlled Clinical Trials, 4(2):152 
152, 1983.
[112] 
L. S. Freedman and D. J. Spiegelhalter. The assessment of subjective opinion 
and its use in relation to stopping rules for clinical trials. The Statistician. 
32(l-2):153-160, 1983.
[113] 
L. S. Freedman and D. J. Spiegelhalter. Using clinical opinion in the design 
of fixed-sized trials. Controlled Clinical Trials, 5(3):302 302, 1984.
[114] 
L. S. Freedman and D. J. Spiegelhalter. Comparison of Bayesian with group 
sequential methods for monitoring clinical trials. Controlled Clinical Trials, 
10(4):357—367, 1989.
[115] 
L. S. Freedman and D. J. Spiegelhalter. Application of Bayesian statistics to 
decision-making during a clinical trial. Statistics in Medicine, 11(1):23 35, 
1992.
[116] 
L. S. Freedman, D. J. Spiegelhalter, and M. К. B. Parmar. The what, why 
and how of Bayesian clinical trials monitoring. Statistics in Medicine, 13(13 
14):1371-1383; discussion 1385-1389, 1994.
[117] 
E. J. Freireich, E. A. Gehan, D. P. Rail, L. H. Schmidt, and H. E. Skipper. 
Quantitative comparison of toxicity of anticancer agents in mouse, rat, ham­
ster, dog, monkey, and man. Cancer Chemotherapy Reports, 50(4):219-244, 
1966.
[118] 
L. M. Friedman, C. Furberg, and D. L. DeMets. Fundamentals of Clinical 
Trials. Springer, New York, 4th edition, 2010.
[119] 
D. Gamerman. Sampling from the posterior distribution in generalized linear 
mixed models. Statistics and Computing, 7:57-68, 1997.
[120] 
P. H. Garthwaite and J. M. Dickey. Quantifying expert opinion in linear- 
regression problems. Journal of the Royal Statistical Society, Series B, 
50(3):462-474, 1988.
[121] 
P. H. Garthwaite, J. B. Kadane, and A. O’Hagan. Statistical methods for 
eliciting probability distributions. Journal of the American Statistical Asso­
ciation, 100(470):680-701, 2005.
[122] 
J. L. Gastwirth, W. O. Johnson, and D. M. Reneau. Bayesian analysis of 
screening data: Application to AIDS in blood donors. Canadian Journal of 
Statistics, 19(2):135-150, 1991.
[123] 
S. Geisser. The inferential use of predictive distributions. In V. P. Godambe 
and D. A. Sprott, editors, Foundations of Statistical Inference, pages 456 469. 
Holt, Reinhart, and Winston, Toronto, 1971.

562
Bibliography
[124] 
S. Geisser. A Predictivistic Primer. North-Holland, New York, 1980.
[125] 
S. Geisser. On prior distributions for binary trials. The American Statistician, 
38(4):244-247, 1984.
[126] 
S. Geisser. Influential observations, diagnostics and discovery tests. Journal 
of Applied Statistics, 14(2):133-142, 1987.
[127] 
S. Geisser. Predictive Inference: An Introduction. Chapman & Hall, New 
York, 1993.
[128] 
S. Geisser and W. F. Eddy. Predictive approach to model selection. Journal 
of the American Statistical Association, 74(365):153-160, 1979.
[129] 
A. E. Gelfand and D. K. Dey. Bayesian model choice: Asymptotics and exact 
calculations. Journal of the Royal Statistical Society, Series B, 56(3):501-514, 
1994.
[130] 
A. E. Gelfand, S. E. Hills, A Racine-Poon, and A. F. M. Smith. Illustration 
of Bayesian inference in normal data models using Gibbs sampling. Journal 
of the American Statistical Association, 85(412):972-985, 1990.
[131] 
A. E. Gelfand, S. K. Sahu, and В. P. Carlin. Efficient parametrizations for 
normal linear mixed models. Biometrika, 82(3):479-488, 1995.
[132] 
A. E. Gelfand and A. F. M. Smith. Sampling-based approaches to calculating 
marginal densities. Journal of the American Statistical Association, 85:398­
409, 1990.
[133] 
A. Gelman, J. B. Carlin, H. S. Stern, D. B. Dunson, A. Vehtari, and D. B. 
Rubin. Bayesian Data Analysis. Chapman & Hall/CRC, Boca Raton, FL, 
3rd edition, 2014.
[134] 
A. Gelman, J. B. Carlin, H. S. Stern, and D. B. Rubin. Bayesian Data 
Analysis. Chapman & Hall, London, 1995.
[135] 
A. Gelman, J. Hwang, and A. Vehtari. Understanding predictive information 
criteria for Bayesian models. Statistics and Computing, 24(6):997-1016, 2014.
[136] 
A. Gelman, A. Jakulin, M. G. Pittau, Y.-S. Su, et al. A weakly informative 
default prior distribution for logistic and other regression models. Annals of 
Applied Statistics, 2(4):1360-1383, 2008.
[137] 
A. Gelman, X.-L. Meng, and H. S. Stern. Posterior predictive assessment of 
model fitness via realized discrepancies (with discussion). Statistica Sinicu, 
6(4):733-760, 1996.
[138] 
A. Gelman and D. B. Rubin. Inference from iterative simulation using mul­
tiple sequences. Statistical Science. 7(4):457-472, 1992.

Bibliography
563
[139] 
E. I. George and R. E. McCulloch. Variable selection via Gibbs sampling. 
Journal of the American Statistical Association, 88(423):881-889, 1993.
[140] 
E. I. George and R. E. McCulloch. Approaches for Bayesian variable selection. 
Statistica Sinica, 7(2):339-373, 1997.
[141] 
M. P. Georgiadis, W. O. Johnson, I. A. Gardner, and R. Singh. Correlation- 
adjusted estimation of sensitivity and specificity of two diagnostic tests. Ap­
plied Statistics, 52(l):63-76, 2003.
[142] 
J. Geweke. Evaluating the accuracy of sampling-based approaches to the 
calculation of posterior moments. In J. M. Bernardo, J. O. Berger, A. P. 
Dawid, and A. F. M. Smith, editors, Bayesian Statistics b, Oxford, 1992. 
Oxford University Press.
[143] 
W. R. Gilks and P. Wild. Adaptive rejection sampling for Gibbs sampling. 
Applied Statistics, 41:337-348, 1992.
[144] 
J. Gill and L. D. Walker. Elicited priors for Bayesian model specifications in 
political science research. Journal of Politics, 67(3):841-872, 2005.
[145] 
J. Gittins, K. Glazebrook, and R. Weber. Multi-Armed Bandit Allocation 
Indices. John Wiley & Sons, Chichester, 2nd edition, 2011.
[146] 
M. Goldstein. Subjective Bayesian analysis: Principles and practice. Bayesian 
Analysis, l(3):403, 2006.
[147] 
M. Gonen, W. O. Johnson, Y. Lu, and P. H. Westfall. Comparing objective 
and subjective Bayes factors for the two-sample comparison: The classification 
theorem in action. The American Statistician, 73(1):22-31, 2018.
[148] 
S. N. Goodman. Toward evidence-based medical statistics. 1: The p-value 
fallacy. Annals of Internal Medicine, 130(12):995-1004, 1999.
[149] 
S. N. Goodman. Towards evidence-based medical statistics. 2: The Bayes 
factor. Annals of Internal Medicine, 130(12):1005—1013, 1999.
[150] 
S. N. Goodman, M. L. Zahurak, and S. Piantadosi. Some practical improve­
ments in the continual reassessment method for phase I studies. Statistics in 
Medicine, 14(11):1149-1161, 1995.
[151] 
С. K. Grieshaber and S. Marsoni. Relation of preclinical toxicology to findings 
in early clinical trials. Cancer Treatment Reports, 70(l):65-72, 1986.
[152] 
M. Gruber. Improving Efficiency by Shrinkage: The James-Stein and Ridge 
Regression Estimators. Marcel Dekker, New York, 1998.
[153] 
С. E. Guse, D. J. Peterson, A. L. Christiansen, J. Mahoney, P. Laud, and P. M. 
Layde. Translating a fall prevention intervention into practice: A randomized 
community trial. American Journal of Public Health, 105(7):1475-1481, 2015.

564
Bibliography
[154] 
К. M. Guskiewicz and J. P. Mihalik. Biomechanics of sport concussion: Quest 
for the elusive injury threshold. Exercise and Sport Sciences Reviews, 39(1):4- 
11, 2011.
[155] 
P. Gustafson. Large hierarchical Bayesian analysis of multivariate survival 
data. Biometrics, 53(l):23O-42, 1997.
[156] 
P. Gustafson. Bayesian analysis of frailty models. In Klein, JP and Van- 
Houwelingen, HC and Ibrahim, JG and Scheike, TH, editor, Handbook of 
Survival Analysis, pages 475-488. Chapman & Hall/CRC, Boca Raton, FL, 
2014.
[157] 
P. Gustafson, A. E. Gelfand, S. K. Sahu, W. O. Johnson, T. E. Hanson, 
L. Joseph, and J. Lee. On model expansion, model contraction, identifiabil­
ity and prior information: Two illustrative scenarios involving mismeasured 
variables [with comments and rejoinder]. Statistical Science, 20(2):ll 1-140, 
2005.
[158] 
T. Hanson, E. Bedrick, W. Johnson, and M. Thurmond. A mixture model 
for bovine abortion and foetal survival. Statistics in Medicine, 22:1725-1739, 
2003.
[159] 
T. Hanson, W. Johnson, and P. Laud. Semiparametric inference for survival 
models with step process covariates. Canadian Journal of Statistics, 37(1):60- 
79, 2009.
[160] 
W. K. Hastings. Monte Carlo sampling methods using Markov chains and 
their applications. Biometrika, 57(l):97-109, 1970.
[161] 
I. C. Henderson, D. A. Berry, G. D. Demetri, С. T. Cirrincione, L. J. Gold­
stein, S. Martino, J. N. Ingle, M. R. Cooper, D. F. Hayes, К. H. Tkaczuk, 
G. Fleming, J. F. Holland, D. B. Duggan, J. T Carpenter, E. Frei, R. L. 
Schilsky, W. C. Wood, H. B. Muss, and L. Norton. Improved outcomes 
from adding sequential paclitaxel but not from escalating doxorubicin dose in 
an adjuvant chemotherapy regimen for patients with node-positive primary 
breast cancer. Journal of Clinical Oncology, 21(6):976-983, 2003.
[162] 
J. Herson. Predictive probability early termination plans for phase II clinical 
trials. Biometrics, 35(4):775-83, 1979.
[163] 
S. P. Hey and J. Kimmelman. Are outcome-adaptive allocation trials ethical? 
Clinical Trials, 12(2):102-106, 2015.
[164] J. P. Hobert and G. Casella. The effect of improper priors on Gibbs sam­
pling in hierarchical linear mixed models. Journal of the American Statistical 
Association, 91(436):1461-1473, 1996.
[165] 
J. A. Hoeting, D. Madigan, A. E. Raftery, and С. T. Volinsky. Bayesian 
model averaging: A tutorial (with comments). Statistical Science, 14(4):382- 
417. 1999.

Bibliography 
565
[166] 
P. Hoff. A First Course in Bayesian Statistical Methods. Springer. New York, 
2009.
[167] 
M. D. Hoffman and A. Gelman. The No-U-Turn sampler: Adaptively setting 
path lengths in Hamiltonian Monte Carlo. Journal of Machine Learning 
Research, 15( 1): 1593-1623, 2014.
[168] 
T. R. Holford. The analysis of rates and of survivorship using log-linear 
models. Biometrics, 36(2):299-305, 1980.
[169] 
S. L. Hui and S. D. Walter. Estimating the error rates of diagnostic tests. 
Biometrics, 36(1):167-171, 1980.
[170] 
J. G. Ibrahim and M.-H. Chen. Prior elicitation and variable selection for 
generalized linear mixed models. In D. K. Dey, S. K. Ghosh, and В. K. 
Mallick, editors, Generalized Linear Models: A Bayesian Perspective, pages 
41-53. Marcel Dekker, New York, 2000.
[171] 
J. G. Ibrahim, M.-H. Chen, and D. Sinha. Bayesian Survival Analysis. 
Springer Series in Statistics. Springer, New York, 2001.
[172] 
J. G. Ibrahim and P. W. Laud. On Bayesian analysis of generalized linear 
models using Jeffreys’s prior. Journal of the American Statistical Association, 
86(416):981-986, 1991.
[173] 
J. P. A. loannidis. Why most published research findings are false. PLoS 
Medicine, 2(8):el24, 2005.
[174] 
H. Ishwaran and M. Zarepour. Exact and approximate sum representations 
for the Dirichlet process. Canadian Journal of Statistics, 4:269-283, 1994.
[175] 
A. Jara. DPpackage (version 1.1-4): Bayesian nonparametric modeling in R, 
2012. 
.
http://cran.r-project.org
[176] 
A. Jara, T. E. Hanson, F. A. Quintana, P. Mueller, and G. L. Rosner. DPpack­
age: Bayesian non- and semi-parametric modelling in R. Journal of Statistical 
Software, 40(5):l-30, 2011.
[177] 
H. Jeffreys. An invariant form for the prior probability in estimation problems. 
Proceedings of the Royal Society of London, Series A, 186(1007):453-461, 
1946.
[178] 
R. A. Johnson and D. W. Wichern. Applied Multivariate Statistical Analysis. 
Prentice Hall, Englewood Cliffs, NJ, 5th edition, 2002.
[179] 
V. E. Johnson. A Bayesian x2 test for goodness-of-fit. Annals of Statistics, 
32(6):2361-2384, 2004.
[180] 
V. E. Johnson and J. D. Cook. Bayesian design of single-arm phase II clinical 
trials with continuous monitoring. Clinical Trials, 6(3):217-226, 2009.

566
Bibliography
[181] 
V. E. Johnson and D. Rossell. On the use of non-local prior densities in 
Bayesian hypothesis tests. Journal of the Royal Statistical Society, Series B, 
72(2):143-170, 2010.
[182] 
W. Johnson. Influence measures for logistic regression: Another point of view. 
Biometrika, 72(l):59-65, 1985.
[183] 
W. Johnson and S. Geisser. A predictive view of the detection and char­
acterization of influential observations in regression analysis. Journal of the 
American Statistical Association, 78(381):137-144, 1983.
[184] 
W. Johnson and S. Geisser. Estimative influence measures for the multivariate 
general linear model. Journal of Statistical Planning and Inference, 11(1):33— 
56, 1985.
[185] 
W. Johnson, J. Utts, and L. Pearson. Bayesian robust estimation of the mean. 
Applied Statistics, 35(l):63-72, 1986.
[186] 
W. O. Johnson. Predictive influence in the log normal survival model. In 
J. C. Lee, W. O. Johnson, and A. Zellner, editors, Prediction and Modelling 
in Statistics and Econometrics: Essays in Honor of Seymour Geisser, pages 
104-121, Amsterdam, 1996. Elsevier.
[187] 
W. O. Johnson and J. L. Gastwirth. Bayesian inference for medical screening 
tests: Approximations useful for the analysis of acquired immune deficiency 
syndrome. Journal of the Royal Statistical Society, Series B, 53(2):427-439, 
1991.
[188] 
W. O. Johnson, J. L. Gastwirth, and L. M. Pearson. Screening without a 
“gold standard”: The Hui-Walter paradigm revisited. American Journal of 
Epidemiology, 153(9):921-924, 2001.
[189] 
W. O. Johnson, G. Jones, and I. A. Gardner. Gold standards are out and 
Bayes is in: Implementing the cure for imperfect reference tests in diagnostic 
accuracy studies. Preventive Veterinary Medicine, 167:113-127, 2019.
[190] 
W. O. Johnson, E. Ward, and D. L. Gillen. Bayesian methods in public 
health. Handbook on Statistics: Disease Modeling and Public Health, 36:407­
442, 2017.
[191] 
G. Jones and W. O. Johnson. Prior elicitation: Interactive spreadsheet graph­
ics with sliders can be fun, and informative. The American Statistician, 
68(1):42-51, 2014.
[192] 
G. Jones, W. O. Johnson, T. E. Hanson, and R. Christensen. Identifiability 
of models for multiple diagnostic testing in the absence of a gold standard. 
Biometrics, 66(3):855-863, 2010.

Bibliography
567
[193] 
L. Joseph and P. Belisle. Bayesian sample size determination for normal 
means and differences between normal means. The Statistician, 46(2) :209- 
226, 1997.
[194] 
L. Joseph, T. W. Gyorkos, and L. Coupal. Bayesian estimation of disease 
prevalence and the parameters of diagnostic tests in the absence of a gold 
standard. American Journal of Epidemiology, 141(3):263- 272. 1995.
[195] 
L. Joseph and D. B. Wolfson. Interval-based versus decision theoretic criteria 
for the choice of sample size. The Statistician, 46(2):145-149, 1997.
[196] 
J. B. Kadane. Principles of Uncertainty. Chapman & Hall/CRC, Boca Raton, 
FL, 2011.
[197] 
J. B. Kadane, J. M. Dickey, R. L. Winkler, W. S. Smith, and S. C. Peters. 
Interactive elicitation of opinion for a normal linear model. Journal of the 
American Statistical Association, 75(372):845-854, 1980.
[198] 
J. B. Kadane and N. A. Lazar. Methods and criteria for model selection. 
Journal of the American Statistical Association, 99(465):279-290, 2004.
[199] 
J. B. Kadane and L. J. Wolfson. Experiences in elicitation. The Statistician, 
47(1):3-19, 1998.
[200] 
D. Kahneman and A. Tversky. Subjective probability: A judgement of repre­
sentativeness. In D. Kahneman, P. Slovic, and A. Tversky, editors, Judgment 
under Uncertainty: Heuristics and Biases, pages 43-47. Cambridge University 
Press, Cambridge, 1982.
[201] 
J. D. Kalbfleisch. Non-parametric Bayesian analysis of survival time data. 
Journal of the Royal Statistical Society, Series B, 40(2):214-221, 1978.
[202] 
E. L. Kaplan and P. Meier. Nonparametric estimation from incomplete ob­
servations. Journal of the American statistical association, 53(282):457-481, 
1958.
[203] 
O. Kardaun. Statistical survival analysis of male larynx-cancer patients—A 
case study. Statistica Neerlandica, 37(3): 103-125, 1983.
[204] 
J. P. Klein and M. L. Moeschberger. Survival Analysis: Techniques for Cen­
sored and Truncated Data. Springer, New York, 2nd edition, 2003.
[205] 
К. P. Kleinman and J. G. Ibrahim. A semi-parametric Bayesian approach 
to generalized linear mixed models. Statistics in Medicine, 17(22):2579-2596, 
1998.
[206] 
К. P. Kleinman and J. G. Ibrahim. A semiparametric Bayesian approach to 
the random effects model. Biometrics, 54(3):921-938, 1998.

568
Bibliography
[207] 
A. Kottas. Nonparametric Bayesian survival analysis using mixtures 
of Weibull distributions. Journal of Statistical Planning and Inference, 
136(3) :578-596, 2006.
[208] 
M. Krams, K. R. Lees, W. Hacke, A. P. Grieve, J.-M. Orgogozo, G. A. Ford, 
and Investigators for the ASTIN Study. Acute stroke therapy by inhibition 
of neutrophils (ASTIN). Stroke, 34(ll):2543-2548, 2003.
[209] 
L. Kuo, A. F. M. Smith, S. MacEachern, and M. West. Bayesian computations 
in survival models via the Gibbs sampler. In J. P. Klein and P. K. Goel, 
editors, Survival Analysis: State of the Art, pages 11-24. Kluwer Academic 
Publishers, Dordrecht, The Netherlands, 1992.
[210] 
N. Laird. Nonparametric maximum likelihood estimation of a mixing dis­
tribution. Journal of the American Statistical Association, 73(364):805-811, 
1978.
[211] 
N. Laird and D. Olivier. Covariance analysis of censored survival data using 
log-linear analysis techniques. Journal of the American Statistical Associa­
tion, 76(374) :231-240, 1981.
[212] 
N. M. Laird and J. H. Ware. Random-effects models for longitudinal data. 
Biometrics, 38(4):963-974, 1982.
[213] 
К. K. G. Lan and D. L. DeMets. Discrete sequential boundaries for clinical 
trials. Biometrika, 70:659-663, 1983.
[214] 
P. Laud, P. Damien, and T. Shively. Sampling truncated distributions via 
rejection algorithms. Communications in Statistics: Simulation and Compu­
tation, 39(6):1111—1121, 2010.
[215] 
P. W. Laud. Bayesian nonparametric inference in reliability. Ph.D. Disser­
tation, University of Missouri, Columbia, MO, 1977.
[216] 
P. W. Laud, P. Damien, and S. G. Walker. Computations via auxiliary random 
functions for survival models. Scandinavian Journal of Statistics, 33(2):219- 
226, 2006.
[217] 
P. W. Laud and J. G. Ibrahim. Predictive model selection. Journal of the 
Royal Statistical Society, Series B, 57(l):247-262, 1995.
[218] 
J. J. Lee and D. D. Liu. A predictive probability design for phase II cancer 
clinical trials. Clinical Trials, 5(2):93- 106, 2008.
[219] 
E. Lesaffre and B. Spiessens. On the effect of the number of quadrature points 
in a logistic random-effects model: An example. Aplied Statistics, 50:325-335, 
2001.

Bibliography
569
[220] 
R. J. Lewis and D. A. Berry. Group sequential clinical-trials - A classical 
evaluation of Bayesian decision-theoretic designs. Journal of the American 
Statistical Association, 89(428):1528-1534, 1994.
[221] 
R. J. Lewis, A. M. Lipsky, and D. A. Berry. Bayesian decision-theoretic 
group sequential clinical trial design based on a quadratic loss function: A 
frequentist evaluation. Clinical Trials, 4(1):5-14, 2007.
[222] 
C.-S. Li. Identifiability of zero-inflated Poisson models. Brazilian Journal of 
Probability and Statistics, 26(3):306-312, 2012.
[223] 
D. V. Lindley. On a measure of the information provided by an experiment. 
Annals of Mathematical Statistics, 27(4):986-1005, 1956.
[224] 
D. V. Lindley. A statistical paradox. Biometrika, 44(1-2): 187-192, 1957.
[225] 
D. V. Lindley. Bayesian Statistics; A Review. Society for Industrial and 
Applied Mathematics, Philadelphia, 1972.
[226] 
D. V. Lindley. The choice of sample size. The Statistician, 46(2):129-138, 
1997.
[227] 
D. V. Lindley. The choice of sample size—Reply. The Statistician, 46(2):163- 
166, 1997.
[228] 
D. V. Lindley and A. F. M. Smith. Bayes estimates for the linear model. 
Journal of the Royal Statistical Society, Series B, 34(1): 1—41, 1972.
[229] 
J. K. Lindsey. Exact sample size calculations for exponential family models. 
The Statistician, 46(2) :231-237, 1997.
[230] 
A. R. Linero. Bayesian regression trees for high-dimensional prediction 
and variable selection. Journal of the American Statistical Association, 
113(522) :626-636, 2018.
[231] 
R. J. Little. Calibrated Bayes: A Bayes/frequentist roadmap. The American 
Statistician, 60(3):213-223, 2006.
[232] 
D. Lunn, C. Jackson, N. Best, A. Thomas, and D. Spiegelhalter. The BUGS 
Book: A Practical Introduction to Bayesian Analysis. CRC Press, Boca Raton, 
FL, 2012.
[233] 
D. Lunn, D. Spiegelhalter, A. Thomas, and N. Best. The BUGS project: 
Evolution, critique and future directions. Statistics in Medicine, 28(25) :3049- 
3067, 2009.
[234] 
S. N. MacEachern. Dependent Dirichlet processes. Unpublished manuscript, 
Department of Statistics, The Ohio State University, 2000.

570
Bibliography
[235] 
I. Mahmood and J. D. Balian. The pharmacokinetic principles behind scal­
ing from preclinical results to phase I protocols. Clinical Pharmacokinetics, 
36(1):1—11, 1999.
[236] 
S. S Mahmood, D. Levy, R. S. Vasan, and T. J. Wang. The Framingham 
Heart Study and the epidemiology of cardiovascular disease: A historical per­
spective. The Lancet, 383(9921):999-1008, 2014.
[237] 
M. McCrea. Mild Traumatic Brain Injury and Postconcussion Syndrome: The 
New Evidence Base for Diagnosis and Treatment. Oxford University Press, 
Oxford, 2008.
[238] 
P. McCullagh. Regression models for ordinal data. Journal of the Royal 
Statistical Society, Series B, 42(2):109-142, 1980.
[239] 
P. McCullagh and J. A. Nelder. Generalized Linear Models. Chapman and 
Hall, London, 2nd edition, 1989.
[240] 
R. McCulloch, R. Sparapani, R. Gramacy, C. Spanbauer, and M. Pratola. 
BART: Bayesian additive regresssion trees. R-package Version 2.7, 2019. 
.
https://CRAN.R-project.org/package=BART
[241] 
R. McElreath. Statistical Rethinking: A Bayesian Course with Examples in 
R and Stan. Chapman and Hall/CRC, Boca Raton, FL, 2nd edition, 2020.
[242] 
N. Metropolis, A. W. Rosenbluth, M. N. Rosenbluth, A. H. Teller, and 
E. Teller. Equation of state calculations by fast computing machines. Journal 
of Chemical Physics, 21(6):1087-1092, 1953.
[243] 
T. J. Mitchell and J. J. Beauchamp. Bayesian variable selection in linear 
regression. Journal of the American Statistical Association, 83(404): 1023­
1032, 1988.
[244] J. Mullahy. Specification and testing of some modified count data models. 
Journal of Econometrics, 33(3):341-365, 1986.
[245] 
P. Muller, D. A. Berry, A. P. Grieve, M. Smith, and M. Krams. Simulation­
based sequential Bayesian design. Journal of Statistical Planning and Infer­
ence, 137(10):3140-3150, 2007.
[246] 
A. B. Nattinger, P. W. Laud, R. Bajorunaite, R. A. Sparapani, and J. L. 
Freeman. An algorithm for the use of Medicare claims data to identify women 
with incident breast cancer. Health Services Research, 39(6pl):1733 50, 2004.
[247] 
A. B. Nattinger, L. E. Pezzin, R. A. Sparapani, J. M. Neuner, T. K. King, 
and P. W. Laud. Heightened attention to medical privacy: Challenges for 
unbiased sample recruitment and a possible solution. American Journal of 
Epidemiology. 172(6):637-44, 2010.

Bibliography
571
[248] 
R. M Neal. MCMC using Hamiltonian dynamics. In S. Brooks, A. Gelman, 
G. Jones, and X. L. Meng, editors, Handbook of Markov Chain Monte Carlo. 
Chapman and Hall/CRC, Boca Raton, FL, 2011.
[249] 
J. A. Nelder and R. W. M. Wedderburn. Generalized linear models. Journal 
of the Royal Statistical Society, Series A, 135(3):370-384, 1972.
[250] 
A. Nishimura and D. Dunson. Recycling intermediate steps to improve Hamil­
tonian Monte Carlo. Bayesian Analysis, 2020.
[251] 
M. Norris, W. O. Johnson, and I. A. Gardner. Modeling bivariate longitudinal 
diagnostic outcome data in the absence of a gold standard. Statistics and its 
Interface, 2(2):171-185, 2009.
[252] 
P. C. O’Brien and T. R. Fleming. A multiple testing procedure for clinical 
trials. Biometrics, 35(3):549-556, 1979.
[253] 
A. O’Hagan, С. E. Buck, A. Daneshkhah, J. R. Eiser, P. H. Garthwaite, D. J. 
Jenkinson, J. E. Oakley, and T. Rakow. Uncertain Judgements: Eliciting 
Experts’ Probabilities. Wiley, London, 2006.
[254] 
J. O’Quigley, M. Pepe, and L. Fisher. Continual reassessment method: A 
practical design for phase I clinical trials in cancer. Biometrics, 46:33-48, 
1990.
[255] 
P. P. O’Rourke, R. K. Crone, J. P. Vacanti, J. H. Ware, C. W. Lillehei, R. B. 
Parad, and M. F. Epstein. Extracorporeal membrane oxygenation and con­
ventional medical therapy in neonates with persistent pulmonary hyperten­
sion of the newborn: A prospective randomized study. Pediatrics, 84(6):957— 
963, 1989.
[256] 
G. Parmigiani and L. Inoue. Decision Theory: Principles and Approaches. 
John Wiley & Sons, Chichester, 2009.
[257] 
G. Parveen, M. F. Khan, H. Ali, T. Ibrahim, and R. Shah. Determination 
of lethal dose (LD50) of venom of four different poisonous snakes found in 
Pakistan. Biochemistry & Molecular Biology Journal, 3(3): 18, 2017.
[258] 
M. S. Pepe. The Statistical Evaluation of Medical Tests for Classification and 
Prediction. Oxford University Press, Oxford, 2004.
[259] 
L. B. Perry, R. A. Van Dyke, and R. A. Theye. Sympathoadrenal and hemo­
dynamic effects of isoflurane, halothane, and cyclopropane in dogs. Anesthe­
siology, 40(5):465-470, 1974.
[260] 
S. Piantadosi. Translational clinical trials: An entropy-based approach to 
sample size. Clinical Trials, 2(2):182-192, 2005.

572
Bibliography
[261] 
M. Plummer. JAGS: A program for analysis of Bayesian graphical 
models using Gibbs sampling, 2003. 
 ags / files/ M anuals/ 4 .x/j ags.user .manual, pdf/download.
https://sourceforge.net/projects/mcmc- 
j
[262] 
S. J. Pocock. Group sequential methods in the design and analysis of clinical 
trials. Biometrika, 64:191-199, 1977.
[263] 
R. F. Potthoff and S. N. Roy. A generalized multivariate analysis of variance 
model useful especially for growth curve problems. Biometrika, 51(3-4):313- 
326, 1964.
[264] J. W. Pratt, H. Raiffa, and R. Schlaifer. The foundations of decision under 
uncertainty: An elementary exposition. Journal of the American statistical 
association, 59(306) :353-375, 1964.
[265] 
F. A. Quintana, W. O. Johnson, L. E. Waetjen, and E. B. Gold. Bayesian 
nonparametric longitudinal data analysis. Journal of the American Statistical 
Association, 111(515):1168-1181, 2016.
[266] 
A. E. Raftery and S. M Lewis. One long run with diagnostics: Implementa­
tion strategies for Markov chain Monte Carlo, Comment on Practical Markov 
Chain Monte Carlo by Chares Geyer. Statistical Science, 7(4):493-497, 1992.
[267] 
H Raiffa and R Schlaifer. Applied Statistical Decision Theory. Division of 
Research, Graduate School of Business Adminitration, Harvard University, 
Boston, 1961.
[268] 
D. Ratkowsky. Nonlinear Regression Modeling. Marcel Dekker, New York, 
1983.
[269] 
J. A. Rice. Mathematical Statistics and Data Analysis. Wadsworth, Belmont 
CA, 1995.
[270] 
D. Rizopoulos. Joint Models for Longitudinal and Time-To-Event Data: With 
Applications in R. CRC Press, Boca Raton, FL, 2012.
[271] 
С. P. Robert. The Bayesian Choice: From Decision-Theoretic Foundations to 
Computational Implementation. Springer-Verlag, New York, 2001.
[272] 
B. Rosner. Fundamentals of Biostatistics. Duxbury Press, Belmont, CA, 
2006.
[273] 
G. L. Rosner. Bayesian monitoring of clinical trials with failure-time end­
points. Biometrics, 61(1):239 45, 2005.
[274] 
G. L. Rosner, J. C. Panetta, F. Innocenti, and M. J. Ratain. Pharmacoge- 
netic pathway analysis of irinotecan. Clinical Pharmacology & Therapeutics, 
84(3):393 402. 2008.
[275] 
S. Ross. A First Course in Probability. Pearson, Harlow. 9th edition, 2014.

Bibliography
573
[276] 
D. Rossell, P. Muller, and G. L. Rosner. Screening designs for drug develop­
ment. Biostatistics, 8(3):595-608, 2007.
[277] 
R. M. Royall. Ethics and statistics in randomized clinical trials. Statistical 
Science, 6( 1):52—62, 1991.
[278] 
V. Sambucini. A Bayesian predictive two-stage design for phase II clinical 
trials. Statistics in Medicine, 27(8): 1199-224, 2008.
[279] 
L. J. Savage. The Foundations of Statistics. Dover Publications, New York, 
1972.
[280] 
H. Scheffe. The Analysis of Variance. Wiley, 1999.
[281] 
H. Schmidli, S. Gsteiger, S. Roychoudhury, A. O’Hagan, D. Spiegelhalter, and 
B. Neuenschwander. Robust meta-analytic-predictive priors in clinical trials 
with historical control information. Biometrics, 70(4):1023-1032, 2014.
[282] 
D. Schwartz and J. Lellouch. Explanatory and pragmatic attitudes in thera­
peutical trials. Journal of Clinical Epidemiology, 62(5):499-505, 2009.
[283] 
G. Schwarz. Estimating the dimension of a model. Annals of Statistics, 
6(2):461-464, 1978.
[284] 
J. W. Seaman III, J. W. Seaman Jr., and J. D. Stamey. Hidden dangers 
of specifying noninformative priors. The American Statistician, 66(2) :77-84, 
2012.
[285] 
S. R. Searle. Linear Models. Wiley, New York, 1971.
[286] 
S. R. Searle, G. Casella, and С. E. McCulloch. Variance Components. Wiley, 
New York, 2009.
[287] 
P. Sebastiani and H. P. Wynn. Maximum entropy sampling and optimal 
Bayesian experimental design. Journal of the Royal Statistical Society, Series 
B, 62(1):145-157, 2000.
[288] 
SEER. Surveillance, Epidemiology and End Results program at 
, 2011.
seer.cancer.gov
[289] 
SEER-Medicare. SEER-Medicare Linked Database at healthcaredeliv-
, 2011.
 
ery.cancer.gov/seermedicare
[290] 
T. Sellke, M. J. Bayarri, and J. O. Berger. Calibration of p values for testing 
precise null hypotheses. The American Statistician, 55(1):62-71, 2001.
[291] 
J. Sethuraman. A constructive definition of Dirichlet priors. Statistica Sinica, 
4(2):639-650, 1994.
[292] 
B. Shahbaba, S. Lan, W. O. Johnson, and R. M. Neal. Split Hamiltonian 
Monte Carlo. Statistics and Computing, 24(3):339-349, 2014.

574
Bibliography
[293] 
Y. Shi. Weibull Mixture Models for Regression in the Context of Time-to- 
event Data. Ph.D. Dissertation, Medical College of Wisconsin, Milwaukee, 
WI, 2017.
[294] 
Y. Shi. DPWeibull: Dirichlet process Weibull mixture model for 
survival data. R-package Version 1.5, 2020. 
.
https://CRAN.R- 
project.org/package=DPWeibull
[295] 
Y. Shi, P. Laud, and J. Neuner. A dependent Dirichlet process model for 
survival data with competing risks. Lifetime Data Analysis, 2020.
[296] 
Y. Shi, M. Martens, A. Banerjee, and P. Laud. Low information om­
nibus (LIO) priors for Dirichlet process mixture models. Bayesian Analysis, 
14(3):677-702, 2019.
[297] 
D. Sinha, J. G. Ibrahim, and M.-H. Chen. A Bayesian justification of Cox’s 
partial likelihood. Biometrika, 90(3):629-641, 2003.
[298] 
P. J. Smith and T. J. Thompson. Correcting for confounding in analyzing 
receiver operating characteristic curves. Biometrical Journal, 38(7):857-863, 
1996.
[299] 
G. W. Snedecor and W. G. Cochran. Statistical Methods. Iowa State Univer­
sity Press, Ames, 6th edition, 1967.
[300] 
R. Sparapani, B. R. Logan, R. E. McCulloch, and P. W. Laud. Nonparametric 
competing risks analysis using Bayesian additive regression trees. Statistical 
Methods in Medical Research, 29(l):57-77, 2020.
[301] 
R. Sparapani, C. Spanbauer, and R. McCulloch. Nonparametric machine 
learning and efficient computation with Bayesian additive regression trees: 
The BART R package. Journal of Statistical Software, 2019.
[302] 
R. A. Sparapani, B. R. Logan, R. E. McCulloch, and P. W. Laud. Nonpara­
metric survival analysis using Bayesian additive regression trees (BART). 
Statistics in Medicine, 35(16):2741-2753, 2016.
[303] 
R. A. Sparapani, L. E. Rein, S. S. Tarima, T. A. Jackson, and J. R. Meurer. 
Non-parametric recurrent events analysis with BART and an application to 
the hospital admissions of patients with diabetes. Bio statistics, 21(l):69-85, 
2020.
[304] 
D. J. Spiegelhalter, N. G. Best, B. R. Carlin, and A. van der Linde. Bayesian 
measures of model complexity and fit. Journal of the Royal Statistical Society, 
Series B, 64(4):583 616, 2002.
[305] 
D. J. Spiegelhalter and L. S. Freedman. A predictive approach to selecting 
the size of a clinical trial, based on subjective clinical opinion. Statistics in 
Medicine, 5(1):1 -13, 1986.

Bibliography
575
[306] 
D. J. Spiegelhalter, L. S. Freedman, and P. R. Blackburn. Monitoring clinical 
trials: Conditional or predictive power? Controlled Clinical Trials, 7(1):8-17, 
1986.
[307] 
D. J. Spiegelhalter, L. S. Freedman, and M. K. Parmar. Applying Bayesian 
ideas in drug development and clinical trials. Statistics in Medicine. 12(15 
16):1501—1511; discussion 1513-1517, 1993.
[308] 
D. J. Spiegelhalter, L. S. Freedman, and M. К. B. Parmar. Bayesian ap­
proaches to randomized trials. Journal of the Royal Statistical Society, Series 
A, 157:357-387, 1994.
[309] 
N. Stallard, P. F. Thall, and J. Whitehead. Decision theoretic designs for 
phase II clinical trials with multiple outcomes. Biometrics, 55(3):971-977, 
1999.
[310] 
P. Strazzullo, S. M. Kerry, A. Barbato, M. Versiero, L. D’Elia, and F. P. 
Cappuccio. Do statins reduce blood pressure? Hypertension, 49(4):792-798, 
2007.
[311] 
J. R. Stroud, P. Muller, and G. L. Rosner. Optimal sampling times in popu­
lation pharmacokinetic studies. Applied Statistics, 50(3):345-359, 2001.
[312] 
W. W. Stroup. Generalized Linear Mixed Models: Modem Concepts, Methods 
and Applications. CRC Press, Boca Raton, FL, 2012.
[313] 
V. Susarla and J. Van Ryzin. Nonparametric Bayesian estimation of survival 
curves from incomplete observations. Journal of the American Statistical 
Association, 71(356):897-902, 1976.
[314] 
S. B. Tan and D. Machin. Bayesian two-stage designs for phase II clinical 
trials. Statistics in Medicine, 21(14):1991-2012, 2002.
[315] 
P. Thall, P. Fox, and J. Wathen. Statistical controversies in clinical research: 
Scientific and ethical problems with adaptive randomization in comparative 
clinical trials. Annals of Oncology, 26(8):1621-1628, 2015.
[316] 
P. F. Thall and J. D. Cook. Dose-finding based on efficacy-toxicity trade-offs. 
Biometrics, 60(3):684-693, 2004.
[317] 
P. F. Thall, R. E. Millikan, P. Mueller, and S. J. Lee. Dose-finding with two 
agents in phase I oncology trials. Biometrics, 59(3):487-496, 2003.
[318] 
P. F. Thall and К. E. Russell. A strategy for dose-finding and safety mon­
itoring based on efficacy and adverse outcomes in phase I/II clinical trials. 
Biometrics, 54(l):251-64, 1998.
[319] 
P. F. Thall and R. Simon. A Bayesian approach to establishing sample-size 
and monitoring criteria for phase II clinical trials. Controlled Clinical Trials, 
15(6):463—481, 1994.

576
Bibliography
[320] 
P. F. Thall and R. Simon. Practical Bayesian guidelines for phase IIB clinical- 
trials. Biometrics, 50(2):337-349, 1994.
[321] 
P. F. Thall and S. C. Vail. Some covariance-models for longitudinal count 
data with overdispersion. Biometrics, 46(3):657-671, 1990.
[322] 
P. F. Thall and J. K. Wathen. Practical Bayesian adaptive randomisation in 
clinical trials. European Journal of Cancer, 43(5):859-866, 2007.
[323] The GUSTO Investigators. An international randomized trial comparing four 
thrombolytic strategies for acute myocardial infarction. New England Journal 
of Medicine, 329(10):673-682, 1993.
[324] 
P. Therasse, S. G. Arbuck, E. A. Eisenhauer, J. Wanders, R. S. Kaplan, 
L. Rubinstein, J. Verweij, M. Van Glabbeke, A. T. van Oosterom, M. C. 
Christian, and S. G. Gwyther. New guidelines to evaluate the response to 
treatment in solid tumors. JNCI: Journal of the National Cancer Institute, 
92(3):205-216, 2000.
[325] 
M. V. Thomas, A. Branscum, C. S. Miller, J. Ebersole, M. Al-Sabbagh, and 
J. L. Schuster. Within-subject variability in repeated measures of salivary 
analytes in healthy adults. Journal of Periodontology, 80(7): 1146-1153, 2009.
[326] 
M. C. Thurmond, W. O. Johnson, C. A. Munoz-Zanzi, C.-L. Su, and S. K. Hi­
etala. A method of probability diagnostic assignment that applies Bayes the­
orem for use in serologic diagnostics, using an example of Neospora caninum 
infection in cattle. American Journal of Veterinary Research, 63(3):318-325, 
2002.
[327] 
L. Tierney. Markov chains for exploring posterior distributions. Annals of 
Statistics, 22:1701-1728 (discussion 1728-1762), 1994.
[328] 
L. Tierney and J. B. Kadane. Accurate approximations for posterior mo­
ments and marginal densities. Journal of the American Statistical Associa­
tion, 81(393):82-86, 1986.
[329] 
L. Tierney, R. E. Kass, and J. B. Kadane. Approximate marginal densities 
of nonlinear functions. Biometrika, 76(3):425-433, 1989.
[330] 
M. Tighiouart, A. Rogatko, and J. S. Babb. Flexible Bayesian methods for 
cancer phase I clinical trials. Dose escalation with overdose control. Statistics 
in Medicine, 24(14):2183-96, 2005.
[331] 
L. Trippa, G. L. Rosner, and P. Mueller. Bayesian enrichment strategies for 
randomized discontinuation trials. Biometrics, 68(l):203-211, 2012.
[332] 
A. Tsiatis. A nonidentifiability aspect of the problem of competing risks. Pro­
ceedings of the National Academy of Sciences of the United States of America, 
72(l):20 22, 1975.

Bibliography
577
[333] 
A. A. Tsiatis. The asymptotic joint distribution of the efficient scores test for 
the proportional hazards model calculated over time. Biometrika, 68(1):311— 
315, 1981.
[334] 
B. W. Turnbull and L. Weiss. A likelihood ratio statistic for testing goodness 
of fit with randomly censored data. Biometrics, 34(3):367-375, 1978.
[335] 
F. Tuyl, R. Gerlach, and K. Mengersen. A comparison of Bayes-Laplace. 
Jeffreys, and other priors: The case of zero events. The American Statistician, 
62(l):40-44, 2008.
[336] 
F. Tuyl, R. Gerlach, and K. Mengersen. Posterior predictive arguments in 
favor of the Bayes-Laplace prior as the consensus prior for binomial and multi­
nomial parameters. Bayesian Analysis, 4(1):151-158, 2009.
[337] 
J. Utts. Replication and meta-analysis in parapsychology (with discussion). 
Statistical Science, 6:363-403, 1991.
[338] 
J. Utts and R. Heckard. Mind on Statistics, 5th Edition. Brooks-Cole/ Cen- 
gage Learning, Boston, 2015.
[339] 
J. Utts, M. Norris, E. Suess, and W. Johnson. The strength of evidence versus 
the power of belief: Are we all Bayesians? In C. Reading, editor, Data and 
Context in Statistics Education: Towards an Evidence-Based Society. Proceed­
ings of the Eighth International Conference on Teaching Statistics, Voorburg, 
2010. International Statistical Institute.
[340] 
S. Ventz, M. Cellamare, S. Bacallado, and L. Trippa. Bayesian uncer­
tainty directed trial designs. Journal of the American Statistical Association, 
114(527) :962-974, 2018.
[341] 
S. Ventz and L. Trippa. Bayesian designs and the control of frequentist char­
acteristics: A practical solution. Biometrics, 71(1):218—226, 2015.
[342] 
S. G. Walker, P. Damien, P. W. Laud, and A. F. M. Smith. Bayesian non­
parametric inference for random distributions and related functions. Journal 
of the Royal Statistical Society, Series B, 61(3):485—527, 1999.
[343] 
F. Wang and A. E. Gelfand. A simulation-based approach to Bayesian sample 
size determination for performance under a given model and for separating 
models. Statistical Science, 17(2):193-208, 2002.
[344] 
J. H. Ware. Investigating therapies of potentially great benefit: ECMO. Stat­
istical Science, 4(4):298-306, 1989.
[345] 
R. L. Wasserstein and N. A. Lazar. The ASA statement on p-values: Context, 
process, and purpose. The American Statistician, 70(10): 129-133, 2016.

578
Bibliography
[346] 
S. Watanabe. Asymptotic equivalence of Bayes cross validation and widely 
applicable information criterion in singular learning theory. Journal of Ma­
chine Learning Research, 11:3571-3594, 2010.
[347] 
J. K. Wathen and P. F. Thall. A simulation study of outcome adaptive 
randomization in multi-arm clinical trials. Clinical Trials, 14(5):432-440, 
2017.
[348] 
L. J. Wei. An application of an urn model to the design of sequential controlled 
clinical trials. Journal of the American Statistical Association, 73(363):559- 
563, 1978.
[349] 
L. J. Wei. The generalized Polya’s urn design for sequential medical trials. 
Annals of Statistics, 7(2):291-296, 1979.
[350] 
D. A. Weiner, T. J. Ryan, С. H. McCabe, J. W. Kennedy, M. Schloss, F. Tris- 
tani, B. R. Chaitman, and L. D. Fisher. Exercise stress testing: Correlations 
among history of angina, st-segment response and prevalence of coronary­
artery disease in the Coronary Artery Surgery Study (CASS). New England 
Journal of Medicine, 301(5):230-235, 1979.
[351] 
S. Weisberg. Applied Linear Regression. John Wiley & Sons, Hoboken, NJ, 
2005.
[352] 
R. Wetzels, R. P. P. P. Grasman, and E.-J. Wagenmakers. A default Bayesian 
hypothesis test for ANOVA designs. The American Statistician, 66(2).-104- 
111, 2012.
[353] J. Whittle, M. M. Schapira, К. E. Fletcher, A. Hayes, J. Morzinski, P. Laud, 
D. Eastwood, K. Ertl, L. Patterson, and К. E. Mosack. A randomized trial of 
peer-delivered self-management support for hypertension. American Journal 
of Hypertension, 27(11):1416—1423, 2014.
[354] 
P. Wild and W. R. Gilks. Algorithm AS 287: Adaptive rejection sampling 
from log-concave density functions. Applied Statistics, 42:701-708, 1993.
[355] 
J. D. Wright, J. P. Hughes, Y. Ostchega, S. S. Yoon, and T. Nwankwo. Mean 
systolic and diastolic blood pressure in adults aged 18 and over in the united 
states, 2001 2008. Technical report, National Center for Health Statistics, 
Hyattsville, MD: National Center for Health Statistics., 2011.
[356] T. W. Yen, X. Fan, R. Sparapani, P. W. Laud, A. P. Walker, and A. B. Nat- 
tinger. A contemporary, population-based study of lymphedema risk factors 
in older women with breast cancer. Annals of Surgical Oncology. 16(4):979 
988, 2009.
[357] 
Y. Yuan, H. Q. Nguyen, and P. F. Thall. Bayesian Designs for Phase I-II 
Clinical Trials. CRC Press, Boca Raton, FL, 2016.

Bibliography
579
[358] 
Y. Yuan and G. Yin. Bayesian phase I/II adaptively randomized oncology 
trials with combined drugs. Annals of Applied Statistics, 5:924-942. 2011.
[359] 
S. L. Zeger and M. R. Karim. Generalized linear models with random effects: 
A Gibbs sampling approach. Journal of the American Statistical Association, 
86(413):79-86, 1991.
[360] 
M. Zelen. Play the winner rule and the controlled clinical trial. Journal of 
the American Statistical Association, 64(325): 131-146, 1969.
[361] 
A. Zellner. On assessing prior distributions and Bayesian regression analysis 
with g-prior distributions. In P. K. Goel and A. Zellner, editors, Bayesian 
Inference and Decision Techniques: Essays in Honor of Bruno de Finetti, 
pages 233-243. North-Holland, Amsterdam, 1986.
[362] 
J. Zhang, N. Yoganandan, F. A. Pintar, Y. Guan, B. Shender, G. Paskoff, 
and P. Laud. Effects of tissue preservation temperature on high strain-rate 
material properties of brain. Journal of Biomechanics, 44(3) :391-396, 2011.
[363] 
L. Zhang, К. H. Yang, and A. I. King. A proposed injury threshold for mild 
traumatic brain injury. Journal of Biomechanical Engineering, 126:226-236, 
2004.
[364] 
H. Zhou and T. Hanson. A unified framework for fitting Bayesian semipara­
metric models to arbitrarily censored survival data, including spatially refer­
enced data. Journal of the American Statistical Association, 113(522) :571 — 
581, 2018.
[365] 
H. Zhou and T. Hanson. spBayesSurv: Bayesian modeling and ana­
lysis of spatially correlated survival data. R-package Version 1.1.4, 2020. 
.
https://CRAN.R-project.org/package=spBayesSurv


Index
A
Abortion data example, 4-5, 443-446
Accelerated failure-time (AFT)
regression models, 347-360, 530
prior distributions, 354-359
sensitivity analysis, 359-360
Acute myelogenous leukemia (AML),
62-64
Adaptive designs, 402
Adaptive rejection sampling, 85-87, 91
Additive law of probability, 509
Akaike information criterion (AIC),
278, 281-282
Alpha spending function, 413
Analysis of covariance (ANCOVA), 169, 
200, 286
Analysis of variance (ANOVA),
109-110, 169, 200-205
Animal studies, 383-394
Anscombe, F. J., 413
Area under the curve (AUC), 491-494, 
496-500, 502
Armitage, Peter, 413
Artificial insemination data example,
428-430
ASTIN study, 418
Asymptotic approximations, 77-79
Attributable risk, 126
Autocorrelation plots, 105-108
Autoregressive latent effects, 468-473
Auxiliary random variables, 97, 98 
Average coverage criterion (ACC), 
397-398
Average length criterion (ALC),
397-399
BART, 552
Baseline hazard function, 361, 362.
363-365
Bayes factors (BFs), 270 277
Bayesian information criterion, 282 
hypothesis tests for clinical studies, 
408-409
pseudo-Bayes factor for comparing 
models, 281, 285-286
Bayesian design classifications, 381
Bayesian inference, 23-24
Bayesian information criterion (BIC), 
278-279, 282-283, 285-287
Bayesian software, See Software
Bayesian statistical analysis, basics, 1-2 
data examples, 3-5 
essential ingredients, 5-9 
observables, 6 
philosophy, 2 
unknowns, 6-7
Bayesian statistical analysis, flexibility 
compared to frequentist 
designs, 412-413
Bayesian statistical analysis, principles 
and basic tools, 11, 25-26, 
375-376
data-informed knowledge, 15-16, 
See also Posterior distributions 
inference for model unknowns, 
19-26
knowledge-based information, 2, 
7-8, 16-17, See also Prior 
distributions
notational conventions, 20-21 
numerical approximation, 30-31,
581

582
Index
See also Computational 
methods
prediction, 27-31, See also 
Prediction
simple probability computations, 
12-19
See also Bayes’ theorem; Posterior 
distributions; Prior 
distributions
Bayes’ theorem, 11, 510
for event-space partition, 14-15, 26 
for modeled data, 22-23 
proportionality form, 24-27 
simple probability computations,
12-19
for two events, 13-14
for two random variables, 21-22, 
514
using for inference, 23-24
Bernoulli models, 38, 41-44, 45, 522£ 
comparing populations, 119-132 
hierarchical binomial models, 
439-454
logistic regression model, 215-221 
See also Beta distribution; Binary
regression models; Binomial 
models; Population 
comparisons, Bernoulli 
populations
Bernoulli random variables, 38, See also 
Bernoulli models
Beta-binomial predictive distribution, 
404-405
BetaBuster, 122-123
Beta distribution, 42, 45, 120-123, 448, 
523t
diagnostic test priors, 484, 488-489 
informative priors, 121-123 
Phase 1 dose finding, 385 
reference priors, 121 
truncated, 124 
See also Dirichlet distribution
Beta function, prediction data example, 
29
Betwcen-group variance, 204-205
BFDesigner, 409
Binary diagnostic tests, See Diagnostic 
tests
Binary regression models, 215, 241 
alternatives to logistic regression, 
234-236
logistic regression, 215-235 
model diagnostics, 300-301
See also Logistic regression models 
Binomial models, 38-39, 45-47, 522t 
beta-binomial predictive 
distribution, 404-405
comparing proportions in Bernoulli 
populations, 119-132
data augmentation priors, 160-161
Jeffreys prior, 153-154
negative binomial distribution, 61, 
252
Poisson approximation, 40 
predictive inferences, 46-47 
prior distributions, 120-125 
prior specification for binomial 
proportions, 161-163
prior specification for two-sample 
model, 155-158, 160-161
See also Bernoulli models; 
Population comparisons, 
Bernoulli populations 
Binomial regression models, 215-221, 
259-260, 439-458, See also 
Hierarchical binomial 
regression modeling
Binormal regression model, 492-498, 
501
Biomarkers, 482
diagnostic testing, 489-502 
longitudinal data study, 459-465, 
471-473
See also Diagnostic tests 
Bivariate cumulative distribution 
function, 513
Bivariate probability density function, 
513
Bivariate probability mass function, 513 
Bivariate random variables, 512 514

Index
583
Bone turnover populations, 137-141
Box check, 290
Box-Muller transformation, 80
Brain injury data example, 4
Breast cancer data example 
(BRCAsurvey), 4
Breast cancer incidence, women with 
tuberculosis, 60
Breast cancer lymphedema data 
example (LE), 4, 6, 215-219
Breast cancer rates (Nurses’ Health 
Study), 143-144
Breast cancer treatment data example 
(CALGB8541), 5, 6, 320-322, 
325, 335-336, 355-359, 370-371
British doctors study, 247-252, 253-254 
Brooks-Gelman-Rubin (BGR) method, 
109-110
BRugs, 527, 531, 535-537
BUGS, 527
censored data in, 530-531
R interfaces, 531-537
Burn-in (BI), 54, 88
C
CALGB8541 clinical trial data example, 
5, 6, 320-322, 325, 335-336, 
355-359, 370-371
Cancer of the larynx survival model, 
350-353, 374-375
Candidate-generating (or proposal) 
distribution, 92-93, 97
Canonical form, 258, 260
Case-control sampling, 120, 128-132
Case-deleted residuals, 298, 300
Categorical predictors, 168
Cauchy distribution, 52, 163, 231-232
Cause-specific hazard, 341-342
Censored data capabilities in software
BUGS, 530-531
JAGS, 537-540
Stan, 549-551
Censored data models, See Survival 
analysis
Censoring, 5, 313-316
assumptions. 314
need for, 314
sampling distribution, 314 -316
Centered parameterization, 253
Centering, 178-179, 450-454
Chi-square (* 2) goodness of fit statistic.
289, 291
Chi-square distribution. 523i
Clinical trial designs, 355-359, 381 383
advocating Bayesian versus 
frequentist designs, 412-414
CALGB8541 data example, 5, 6, 
320-322, 325, 335-336, 
355-359, 370-371
effectiveness and efficacy, 382
forward sampling, 411
hypothesis testing, 396, 408-409 
interim analyses and stopping rules, 
402-411, See also Stopping 
rules for clinical trials
joint safety and efficacy monitoring, 
390-394
meta-analysis, 437
Phase 1 (dose finding), 382, 
383-394
Phase 2 (activity), 382, 395-402
Phase 3, 382, 412-416
response-adaptive randomization, 
416-421
sample size, 396-402
sequential designs, 413, 483
simulation and performance 
evaluation, 394-395
skeptical and enthusiast prior 
distributions, 413-416
34-3 design, 383-386
types, 382-383
Closed-form analytical methods, 75
“Closed under sampling,” 42
Cloud seeding, 293
Cohort sampling, 126-129
Comparing populations, See Population 
comparisons
Complementary log-log link function, 
235-236

584
Index
“Complete-the-square” derived 
expression, 49, 55, 452 
Compound symmetry (CS), 458, 461 
Computational methods, 75, 149 
asymptotics, 77-79 
importance sampling, 81-82 
inverse cdf, 80-81 
large-sample approximations, 77-79 
Monte Carlo sampling, 30-31, 79 
nonparametric models, 69 
random number generation, 80 
rejection sampling, 83-87, 91 
sample simulation from 
distributions, 80-87
See also Gibbs sampling; Markov 
chain Monte Carlo (MCMC) 
sampling; Software 
Conditional conjugacy, 12, 17, 23, 49, 
75, 87 
computational approximation 
approaches, 75, See also 
Computational methods 
probability intervals, 42-43, 52-53 
skewed, 24, 43 
using for inference, 23-24 
See also Posterior distributions 
Conditional distributions, 20, 514, 515 
full, 54 
independence prior, 54 
Conditional expectation, 519 
Conditionally conjugate priors, 49, 76, 
77, 158, 185-192, 436 
Conditional means prior (CMP), 
187-189, 226-229, 235-236, 
251, 276-277, 447-448 
Conditional predictive ordinate (CPO), 
280, 293 
Conditional probability, 12-13, 510 
Conditional variance, 519 
Conjugacy, See Conditional conjugacy;
Conjugate priors
Conjugate families, 37 
Conjugate priors, 37, 75 
conditional, 49, 76, 77, 87, 436 
conditionally conjugate 
independence, 185-192 
jointly conjugate dependence, 50-53 
regression models, 192-194
Continual reassessment method (CRM), 
386
Continuous biomarkers, 482, 489-502 
Continuous multivariate distributions 
(table), 5251
Continuous random variables, 11, 20, 
39, 512
Continuous univariate distributions 
(tables), 523-524
Control treatment, adaptive 
randomization, 420-421
Convenience priors, 150, See also 
Reference priors
Convergence diagnostics, 102-111 
ANOVA, 109-110 
autocorrelation plots, 105-108 
Brooks-Gelman-Rubin (BGR) 
method, 109-110
Geweke’s procedure, 108 
quantile plots, 104-105 
Raftery-Lewis method, 110-111 
R packages, 102 
trace and history plots, 102-105
Coronary artery disease (CAD), 486 
Coronary heart disease (CHD), 245-248 
Count data, 59, 141, 241, 252-262, See 
also Poisson distributions or 
models; Poisson process;
Poisson regression models
Covariance, laws of, 518
Covariance matrix, 78, 193-194, 452, 
458, 465, 467, 469, 475
Covariates for regression models, 168 
biomarker-based diagnostic testing, 
499-502
centering and standardization, 
178-179
effect modification, 196, 198 
matrix formulation, 180 
multiple predictors, 174-178 
single numeric predictor, 169-174

Index
585
standardization, 178-179, 231 
time-dependent, 461
Cow abortion data example, 4-5, 
443-446
Cox proportional hazards regression 
model, 360-371, See also 
Proportional hazards regression 
model
Credible interval, 42-43 
Cross-reactivity, 482 
Cross-sectional sampling, 119, 126-128, 
484
Cumulative distribution functions 
(cdfs), 511 
bivariate (or joint), 513 
inverse cdf method, 80-81 
multivariate (or joint), 514 
survival function, 41
Cumulative hazard, 312, 360-361
Cumulative incidence function (CIF), 
341
Cutoffs for continuous biomarkers, 482, 
489-490
D
Dairy cow abortion data, 4-5, 443-446 
Data augmentation prior (DAP), 121, 
159-161, 448
Data-informed knowledge, 15-16, 75, 
See also Posterior distributions
Decision-theoretic clinical study 
stopping rules, 410-411
Decision-theoretic sample size 
determination, 399-402 
“Density” term usage, 512, 513 
Dental data example, 465-468 
Dependent Dirichlet process (DDP) 
model, 372-375
Deviance information criterion (DIC), 
278, 284-287
Diabetes data example, 496-498, 
499-502
Diagnostic tests, 13, 162, 481-483 
binormal regression model, 
492-498, 501
continuous biomarkers. 482. 
489-502
DiaSorin data analysis, 137-141, 
201-202
gold standard, 481, 483
imperfect test with gold standard 
information. 483 489
multiple protocols, 482 
positive and negative predictive 
values, 485-486
posterior probability of disease, 
495
receiver operating characteristic 
(ROC) curves, 482-483, 
491-493
sensitivity and specificity, 162, 483, 
490
DiaSorin data analysis, 137-141, 
201-202
Dichotomous variables, 11
Diffuse priors, 161, 162-163, 273-274, 
435
Dirichlet distribution, 67, 525t
Dirichlet process mixture (DPM) 
model, 67-69, 331-336, 372, 
552
Discrete random variables, 11, 20, 511
Discrete univariate and multivariate 
distributions (table), 522
Discriminant analysis, 494
Disease-free survival (DFS), 5, 320, 
356
“Distribution” term usage, 512, 513
Distributions in common use (tables), 
521-525
Dose effect, 195
Dose escalation with overdose control 
(EWOC), 388-389
Dose finding studies, 383-394, See also
Phase 1 clinical study designs
Dose-limiting toxicity (DLT), 383, 
386-390
DPpackage, 69, 552
DPWeibull, 69, 333, 342, 373, 552
Dugong growth study, 261-264

586
Index
ECMO trial, 419
Effective dose, 225
Effectiveness, 382
Effect measures, 125-126
Effect modification (interaction), 442 
linear regression model, 195-199 
logistic regression model, 222-223 
Effect size, 163, 183, 195 
Efficacy, 382 
Efficacy and safety monitoring, 
390-394, See also Stopping 
rules for clinical trials
Empirical Kaplan-Meier (K-M) 
estimate, 320-322
Entropy-like information measures, 
401-402
Epilepsy data example, 242-245
Ergodic, 89
Event space, 509
Event-space partition, Bayes theorem 
for, 14-15, 26
Exchangeable Bernoulli model, 41-44 
Exchangeable observations, definition, 
37
Exchangeable observations, models for, 
37-70
Bernoulli, 38, 41-44 
binomial, 38-39, 45-47 
Dirichlet process mixture (DPM) 
model, 67-69 
exponential, 41, 61-65 
more flexible (nonparametric) 
models, 66-69 
normal, 39, 47-59 
Poisson, 39-40, 59-61 
survival models, 311-343 
See also Binomial models;
Exponential distributions and 
models; Normal distributions or 
models; Normally distributed 
models for exchangeable 
observations; Poisson 
distributions or models;
Survival analysis, models for 
exchangeable observations 
Exchangeable random variables, 
definition, 515
Expectation, 516-519
Expected log pointwise predictive 
density (ELPPD), 279, 283, 287
Expert knowledge, See Prior 
distributions
Expit function, 124, 216, 234 
Explanatory clinical trials, 382-383 
Explanatory factors, 127-130 
Exponential class of distributions, 
258-260
Exponential covariance function, 470 
Exponential distributions and models, 
41, 61-65, 258-260, 523t 
memoryless property, 323 
modeling time-to-event data, 
311-312 
model restrictions, 65 
nonparametric models, 69 
piecewise model for baseline hazard 
function, 364-365
Poisson distributions and, 64-65, 
364 
predictive inferences, 65 
time-to-event data and survival 
models, 61-65, 76, 323-325 
See also Gamma distribution;
Weibull distribution 
External knowledge, See Prior 
distributions
Extra-Poisson variation, 252 
Extrasensory perception (ESP) study, 
454-458
F
Falls in the elderly data example, 4 
False negative error rate, 483 
False positive error rate, 483 
Fisher, R. A., 200, 494
Fisher likelihood function, 25, See also 
Likelihood functions

Index
58"
Fisher’s exact test, 406, 408, 424
Fisher’s F, 523t
Flat priors, 150-152, 162, 176
logistic regression model, 216
Poisson regression model, 243 
posterior analysis using, 181-184 
proper approximation, 185
Foot-and-mouth disease (FMD) data 
example, 255-257
Forced expiratory volume (FEV) data 
example, 188-190, 196-198, 
298-299
Force of mortality, 312
Forward sampling, 411
Frailty (random effects), 375-376
Framingham Heart Study, 245-247
F statistic, 204, 523t
Full conditional distributions, 54
Fully Bayesian designs, 381
Futility stopping rules, 402, 406-408, 
See also Stopping rules for 
clinical trials
G
GammaBuster, 142
Gamma distribution, 76, 523t 
accelerated failure-time model, 354 
conjugate priors for regression
models, 192-194
exponential model for time-to-event 
data, 61-64, 323-324
Gibbs sampling, 90-92 
inverse, 399, 523t
jointly conjugate dependence prior, 
50-51
Metropolis-Hastings algorithm, 94 
normally distributed model for 
exchangeable observations, 49 
state space, 88
Weibull survival model, 326-327 
Gamma-exponential model, 364 
Gamma function, 29, 45, 46, 121, 190 
Gamma random variate generation, 82 
Ganzfeld ESP study, 454-458
Gaussian distribution. See Normal 
distributions or models
Generalized linear mixed models, 465
Generalized linear models (GLMs), 
234-235, 258-260, 465
Geweke’s procedure, 108
Gibbs sampling. 54. 87
Gibbs sampler, 89 92
hierarchical binomial regression 
models, 450-454
JAGS software, 537-540 
notation and concepts, 87-89 
slice sampling, 96-97
Weibull model for survival analysis, 
327
See also Markov chain Monte Carlo 
(MCMC) sampling
Gibbs within Gibbs sampling, 452
Gold standard tests, 481, 483, 496-498
Goodness-of-fit criteria for model 
selection, 269
Growth curve models, 261, 430-432, 
465-468
GUSTO trial, 437
H
Hamiltonian dynamics, 98-100
Hamiltonian Markov chain Monte Carlo 
sampling, 97-102, 540-541
Hazard, cause-specific, 341-342
Hazard functions, 312, 317, 360 
accelerated failure-time regression 
model, 347, 348, 360 
baseline, 361-365 
exponential model, 323 
plotting, 318-320 
prior distributions, 367-371 
proportional hazards regression 
model, 360-371
Weibull model, 328
Hazard ratios, 336
accelerated failure-time regression 
model, 349
clinical study interim analysis, 
413-416

588
Index
proportional hazards regression 
model, 361-362, 368-370
two-sample survival model, 336 
Heart disease study, 245-247 
Hierarchical binomial regression 
modeling, 439-458
centering, 450-454
Gibbs sampling, 450-454
prior specification, 446-450
simple examples, 439-446
Hierarchical models, 427-428 
binomial regression modeling, 
439-458
centering model, 434-435
information criteria, 287
latent effects with autoregressive 
structure, 468-473
longitudinal and spatial data 
modeling, 458-465
meta-analysis, 428, 437-439, 
454-458
multi-level models, 432-435
for normally distributed data, 
428-439
prior distributions, 446-450
prior specification, 435-437
See also Hierarchical binomial 
regression modeling; Normal 
hierarchical models
Highest posterior density (HPD) 
interval, 43
HIV prevalence data example, 17, 46-47
HIV testing, 486-489
Hurdle model, 264
Hybrid Monte Carlo sampling, 97 
Hypothesis testing, 269-270, 274-275, 
396, 408-409
I
Identifiability, 254
Importance sampling, 81-82
Improper prior, 53, 121, 150, 152, 185, 
273-274, See also Diffuse priors; 
Flat priors; Reference priors
Independence chain, 93
Independence of events, 510 
Independence of random variables, 
definition, 515-516
Independence priors, 49, 53-55, 76, 
155-158, 185-192, 242-243
Independent censoring assumption, 314
Independent increments, 241
Inference, 1, 23-24
Influential observations, 295-297 
Information criteria, 269, 278-289
Akaike information criterion, 278, 
281-282
Bayesian information criterion, 278, 
282-283, 285-287
deviance information criterion, 278, 
284-285, 287
Kullback-Leibler criterion, 279
log pseudo marginal likelihood, 278, 
280-281, 285-287
for mixed or hierarchical models, 
287
widely applicable information 
criterion, 278, 283-284, 287 
Information theory, 401-402 
Informative censoring, 314 
Informative priors, 149
binomial proportions, 121
comparing normal populations, 134, 
158-159
hierarchical models, 435-437
hierarchical regression modeling, 
446-449
inferences for rates, 142
linear regression model, 189-191 
low-information omnibus priors, 
231-232
partial information prior for 
regression models, 190 -191, 
229-231, 251-252
proportional hazards regression 
model, 367-371
specifying, 154-159
See also Prior distributions; Prior 
distributions, specifying
Intensive care unit study, 437 439

Index
589
Interaction
binomial hierarchical model, 445 
linear regression model, 195-199 
logistic regression model, 222-223, 
234
proportional hazards regression 
model, 369
Intercept coefficient, 169
Interim analyses for clinical studies, 
402-411, 413-416, See also 
Stopping rules for clinical trials
Interleukin-1/3 (IL-1/3), 459-465, 
471-473
Interval censoring, 313-314, 316
Inverse cdf method, 80-81
Inverse chi-square distribution, 5231
Inverse gamma distribution, 399, 5231
Inverse Wishart distribution, 5251
J
JAGS, 537-540
Jeffreys, Sir Harold, 272
Jeffreys prior, 121, 142, 152-154, 159, 
385
Johnson check, 290-293
Joint cumulative distribution function, 
513, 514
Jointly conjugate dependence prior, 
50-53
Joint posterior distribution, 23 
normal approximation, 77-78 
normally distributed model for 
exchangeable observations, 
48-49
See also Posterior distributions 
Joint predictive density, 29-30 
Joint probability density function, 513, 
515
Joint probability mass function, 513 
Joint safety and efficacy monitoring, 
390-394
К
Kaplan-Meier (K-M) estimate, 320-322, 
331
Kinetic energy, 98
К nowledge-based information, 2, 7-8, 
16-17, See also Prior 
distributions
Kullback-Leibler criterion (KLC). 279 
Kullback-Leibler divergence (KLD), 
278-279, 296
L
Laplace approximation, 78-79
Large-sample approximations, 77
Bayesian information criterion, 282 
Laplace approximation to posterior 
expectation, 78-79
normal approximation to joint 
posterior, 77-78
See also Computational methods 
Larynx cancer survival model, 350-353, 
374-375
Latent variables (or latent effects), 
427-429, 433-436 
autoregressive structure, 468-473 
binomial regression models, 
439-458
centering model, 434-435 
mixed models, 428
model for meta-analysis, 438
multi-level models, 433 
normal models, 428-439 
See also Hierarchical binomial 
regression modeling;
Hierarchical models; Normal 
hierarchical models
Law of total probability, 13, 14, 21, 26, 
28, 85, 88, 492 
definition, 510, 514
Leapfrog method, 101-102
LearnBayes, 552
Least squares (LS) estimates, 297-298
Leave-one-out cross-validation, 280
Lethal dose, 225-226, 383
Leukemia data example, 62-64, 338-339
Likelihood functions, 11, 25, 201-202 
counting process formulation for

590
Index
proportional hazards regression 
model, 365-367
data augmentation priors, 159-161 
diagnostic test priors, 484-485 
normal models, 48 
sampling distributions for 
censoring, 314-316 
simple regression model, 170 
Likelihood of model, 271 
Likelihood principle, 154, 412-413 
Lindley paradox, 274 
Linear mixed model, 465 
Linear regression, 167-169, 176, 215 
analytic posterior distribution, 
181-184
ANOVA, 200-205 
centering and standardization of 
covariates, 178-179 
conditional means prior, 187-189 
generalized linear models, 234-235, 
258-260 
hierarchical models, See
Hierarchical models 
interaction (effect modification), 
195-199 
matrix formulation, 180 
model diagnostics, 297-300 
model selection, 285-286 
multiple, 180 
multiple covariate model, 174-178 
outlier accommodation, 294-295 
parameters or coefficients, 167-168, 
See also Covariates for 
regression models 
posterior analysis using flat priors, 
181-184 
predictive inferences using posterior 
samples, 184 
sampling model, 180 
simple single numeric predictor 
model, 169-174
sum of squares of errors (SSE), 182 
time-to-event survival modeling, 
347 379, See also
Time-to-event regression 
models
two-sample survival model, 337 
Linear regression, prior distributions, 
184-194
conditionally conjugate 
independence, 185-192
conditional means prior, 187-189 
conjugate priors, 192-194 
flat priors, 185
informative priors, 189
partial information prior, 190-191 
posterior analysis using flat priors, 
181-184
Zellner’s g-prior, 194
Link functions, 235-236, 258-260 
Livestock conception data example, 
428-430
Log-concave densities, adaptive 
rejection sampling for, 85-87
Log-concave simulation, 215
Logistic regression models, 215-235 
alternatives to logistic regression, 
234-236
binary and binomial data, 215-221 
conditional means prior, 226-229 
hierarchical binomial models,
439-454
inference for coefficients and their 
functions, 223-226
interaction effects, 222-223, 234 
latent variables and, 439-440 
link functions, 235-236, 260 
model diagnostics, 300-301 
odds ratio, 219-221
predictive inferences, 232-234
prior distributions. 226-232
Logit function, 216
Logit link function, 235, 260 
Logit-normal model, 124-125, 157, 
446-447
Log-normal distributions, 7, 158-159, 
523£
accelerated failure-time model. 348, 
353-354

Index
591
hierarchical longitudinal model, 
462-465
modeling time-to-event data, 311 
survival models, 330-331
Log pointwise predictive density 
(LPPD), 280, 283, 285
Log pseudo marginal likelihood (LPML) 
criterion, 278, 280-281, 285-287
Longitudinal data, 458-459
BRCAsurvey example, 4 
dental data-based growth study, 
465-468
hierarchical models, 458-465
IL-/3 biomarker study, 459-465, 
471-473
latent effects with autoregressive 
structure, 468-469
Low-information omnibus (LIO) priors, 
231-232, 236, 335, 372
Lymphedema data example (LE), 3, 6, 
127-128, 215, 215-219, 
226-228, 230, 277
M
Marginal distributions, 513-514, 515
Marginal predictive distribution, 30
Marginal predictive p-value, 290 
Markov chain Monte Carlo (MCMC) 
sampling, 54, 77, 87-111
ANOVA data example, 201-202 
comparing normal populations, 135 
convergence diagnostics, 102-111 
convergence in nonlinear regression 
models, 264
Gibbs sampler, 89-92
Hamiltonian MCMC sampling, 
97-102, 540-541
Markov chain theory, 88-89
Metropolis-Hastings algorithm, 
92-96
notation and concepts, 87-89 
regression models, 171-172 
R packages, 551-552 
slice sampling, 96-97
software tools, 527, 529-530
See also Computational methods; 
Gibbs sampling; Software 
Markov chains, 88-89, 112 
Matrix formulation for regression 
modeling, 180-184
Matrix notation, 180
Maximally tolerated dose (MTD). 384, 
386 389
Maximum likelihood estimation (MLE), 
78n, 159, 182, 187, 262, 281, 
297-298, 485
MCMCPack, 551
Mean survival time, 317
Median survival time, 317, 354-355, 362
Medical device clinical trials, 412
Memoryless property, 323
Meta-analysis, 428, 437-439, 454-458 
Metropolis-Hastings algorithm, 92 -96, 
106, 540
Mild traumatic brain injury data 
example (MTBI), 3
Mixed models, 428
generalized linear models, 465 
information criteria, 287
Mixture distributions, 66-67, 252 
beta-binomial predictive 
distribution, 404-405 
logit-normal, 124-125, 157, 446-447 
uniform-Pareto hierarchical prior, 
328-329
See also Log-normal distributions 
Model assessment, 269-289, See also 
Model checking; Model 
selection
Model checking (model diagnostics), 
289-301
binary regression, 300-301 
box check, 290 
classical methods, 289 
influential observations, 295-297 
Johnson check, 290-293 
linear regression, 297-300 
outlier checking, 293-295
Model parameters, 7, 18-19, 20

592
Index
Bayes’ theorem for modeled data, 
22-23
centered and standard 
parameterizations, 253 
hypothesis testing, 274-275 
lack of identifiability, 254 
reparameterization, 47-48 
See also Regression coefficients;
specific parameters
Models, hierarchical, See Hierarchical 
models
Model selection, 269 
choice between two models, 270-275 
choosing among multiple models, 
275-277
conditional means priors, 276-277 
hypothesis testing, 269-270, 
274-275
Kullback-Leibler divergence, 
278-279
linear regression, 285-286 
posterior probabilities and Bayes 
factors, 270-277
predictive information criteria, 269, 
278-289
pseudo-Bayes factor, 281, 285-287 
statistical versus practical 
importance, 287-289
See also Information criteria 
Models for exchangeable observations, 
See Exchangeable observations, 
models for
Moments, 516-519
Monte Carlo sampling, 30-31, See also 
Markov chain Monte Carlo 
(MCMC) sampling
Multi-level hierarchical models, 432-435 
Multinomial distribution, 5221 
Multinomial sampling, 126-128, 156, 
485, 489
Multiple covariate regression model, 
174-178
Multiple linear regression, 180 
Multivariate random variables, 514-516
N
Natural parameter, 258
Negative binomial distribution, 61, 252
Negative cross entropy, 279
Negative predictive value (NPV), 
485-486
Net survival function, 342
Non-informative priors, 150, See also 
Reference priors
Nonlinear regression, 260-264
Non-local priors, 408-409
Nonparametric models, 66 
computational methods, 69 
survival models, 331-336, 371-375
Normal distributions or models, 1, 39, 
524t, 5251
binormal model for diagnostic test, 
492-498, 501
Gibbs sampling, 90 
joint posterior approximation, 
77-78
mixture distributions, 66-67 
model assumptions, 7, 39 
model restrictions, 65 
models for exchangeable 
observations, 47-59
population comparisons, 132-141, 
See also Population 
comparisons, normal 
populations
regression model assumptions, 168 
rejection sampling from truncated 
normal, 85
time-to-event data, 39
See also Normal hierarchical 
models; Normally distributed 
models for exchangeable 
observations
Normal distributions or models, prior 
specification 
flat priors, 151 
hierarchical models, 435-437 
informative priors, 134, 158-159 
Jeffreys prior, 153

Index
593
Normal-gamma distribution, 524t
Normal-gamma posterior, 193
Normal hierarchical models, 428-439 
centering model, 434-435 
meta-analysis, 437-439 
multi-level models, 432-435 
prior specification, 435-437 
simple examples, 428-432
Normally distributed models for 
exchangeable observations 
data example, 56-59 
independence prior, 53-54 
joint likelihood and posterior, 48-49 
jointly conjugate dependence prior, 
50-53
known variance, 49-50, 57-58 
prediction, 54-56
unknown mean and variance, 50 
See also Posterior distributions, 
normal models
Numerical approximation, See 
Computational methods
Numerical predictors, 167-168
Nurses’ Health Study data analysis, 121
О
Objective priors, 231
Odds, 44, 125
Odds ratio
effect modification assessment, 442 
linear regression model, 125-126, 
131-132
logistic regression model, 219-221 
logit link function, 235 
meta-analysis example, 438-439
Offset variable, 246
One-way ANOVA, 109-110, 200-205
OpenBUGS, 530, 531-535
Outlier checking, 293-295 
Overdispersion, 253 
Overfitting, 282
P
Paquid data example, 342-343
Parametric models, 65, 360, See also
Exchangeable observations, 
models for; specific models 
Pareto distribution, 91-92, 328-329, 
5241
Partial likelihood model, 360-363, 376, 
See also Proportional hazards 
regression model
Partially informative prior, 190 191.
229-231, 251. 356-357
Patient-reported satisfaction, 439-440.
458
Pearson goodness of fit measure, 256, 
289, 291
Phase 1 clinical study designs, 382, 
383-394
safety and efficacy monitoring, 
390-394
3+3 design, 383-386
toxicity monitoring, 384-385, 393 
Phase 2 clinical trial designs, 382, 
395-402
hypothesis testing, 396, 408-409 
sample size, 396-402
See also Stopping rules for clinical 
trials
Phase 3 clinical trial designs, 382, 
412-416
Phase 4 clinical trials, 382
Phase space, 99
Plausibility of data, 271
Play-the-winner rules, 417
Poisson distributions or models, 39-40, 
241, 522«
basic assumptions, 241 
exponential distribution and, 
64-65, 364
extra-Poisson variation, 252 
inferences for rates, 141-144 
mixture distributions, 252 
model for exchangeable count 
observations, 59-61
model restrictions, 65 
more general models for count data, 
252-262
predictive inferences, 61

594
Index
variance equals mean, 252
See also Poisson regression models 
Poisson process, 64-65, 365-367 
Poisson random variables, 39 
Poisson regression models, 241-252 
basic assumptions, 241 
centered and standard 
parameterizations, 253
Hurdle model, 264 
link functions, 260 
more general models for count data, 
252-262 
overdispersion, 253 
rate differences and relative rate, 
243-244
zero-inflated Poisson data, 254-258, 
541
Polya tree models, 552
Polya urn randomization, 417-418
Polychotomous variables, 11
Population comparisons, 119, 124-125 
ANOVA, See Analysis of variance 
inferences for rates, 141-144 
regression models, 337 
survival models, 336-340
Population comparisons, Bernoulli 
populations, 119-132 
case-control sampling, 128-132 
cross-sectional or cohort sampling, 
126-128 
effect measures, 125-126 
informative beta priors, 121-123 
logit-normal distribution, 124-125 
reference priors, 121
Population comparisons, normal 
populations, 132-141 
diagnostic assay data example, 
137-141 
posterior inference, 135-136 
predictive inferences, 136-137, 
139-141 
prior distributions, 132-135 
Population parameters, 20 
Positive predictive value (PPV), 485 
Posterior distributions, 150-151, 420
ANOVA data example, 201-202 
comparing normal populations, 
135-136
Dirichlet process mixture (DPM) 
models for survival analysis, 
332
entropy, 401-402
inference for survival analysis, 317 
matrix formulation, 180-184 
multivariate distributions, 87 
Phase 1 dose finding, 387 
reference priors and, 121, 133, 150, 
152, 161, See also Reference 
priors
sample generation using first 
principles, 215
skeptical and enthusiast prior 
distributions, 416
software for sampling, 527-531, See 
also Software
Posterior distributions, normal models, 
48-49
data example, 56-59
inference, 54
jointly conjugate dependence, 50-51 
joint posterior approximation,
77-78
Posterior distributions, regression 
models, 173-174
analysis using flat priors, 181-184 
conditionally conjugate
independence prior, 186
normal-gamma, 193
predictive inferences, 184
Posterior expectation
importance sampling, 81-82
Laplace approximation, 78-79 
Posterior means, 23, 42, 43, 49-50, 61, 
174, 197
Posterior medians, 24, 43, 197. 256, 
443, 463
Posterior modes, 24
Posterior predictive distribution, 30
Posterior predictive p-value, 290 
Posterior probabilities

Index
595
clinical design safety and efficacy 
monitoring, 390-393
clinical trial stopping rules, 402-403
density function, 37
diagnostic testing, 495
model selection approach, 269, 
270-277
Posterior standard deviation, 24, 42
Posterior variance, 24
Potential energy, 98
Power, 396
Practiced importance, 287-289
Pragmatic clinical trials, 382-383
Precision, 48, 49-51, 397-399
Prediction, 27-31
beta-binomial predictive 
distribution, 404-405
binomial models, 46-47
comparing normal populations, 
136-137, 139-141
conditional predictive ordinate, 280, 
293
exponential model, 65, 324
joint predictive density, 29-30
logistic regression models for binary 
outcomes, 232-234
normally distributed model for 
exchangeable observations, 
54-56
Poisson model, 61
regression models using posterior
samples, 184
survival models, 318
Prediction-based clinical study stopping 
rules, 403-408
Prediction-based criteria for model 
selection, 269, 278-289, See 
also Information criteria
Predictive distributions, 30-31, 61
Predictive information criteria
Akaike information criterion (AIC), 
281-282
Bayesian information criterion, 
283-284
deviance information criterion, 
284 286
log pseudo marginal likelihood. 
281-282
Predictive p-vahies, 293 294
Predictive survival distribution, 65 
Predictive survival probabilities, 
349 350
Predictor variables, 167 169
effect modification, 196, 198 
standardization, 231
See also Covariates for regression 
models
Prior distributions, 11, 16-17, 122-123 
Bayesian information criterion and, 
283
beta family, 42
binomial proportions, 120-125, See 
also Population comparisons, 
Bernoulli populations
clinical study designs, 413-416 
conjugate, 37, 75, 158, See also
Conjugacy
data augmentation, 121, 159 -161 
data examples, 17-19 
diagnostic tests, 484, 488-489, 497, 
500
diffuse, 161, 162-163, 273-274 
flat, 176, 181-185
gamma, See Gamma distribution 
hierarchical models, 435-437 
improper, 53, 121, 150, 152, 185, 
See also Reference priors 
independence, 49, 53-55, 155-158 
Jeffreys, 121, 142, 152-154, 159, 385 
jointly conjugate dependence, 50-53 
linear regression models, 171-172, 
176, 181-194, See also Prior 
distributions, regression models 
logistic regression models, 226-232 
logit-normal, 124-125 
log-normal, 158-159 
low-information omnibus, 231-232, 
236, 335, 372

596
Index
non-informative, 150, See also 
Reference priors
nonlinear regression models, 
261-264
non-local densities, 408-409 
normal models, 47-53 
normal populations, 132-139 
objective, 231
partial information, 190-191, 
229-231, 251-252
Phase 1 trial designs, 384-387 
probability intervals, 43 
reference (noninformative), See
Reference priors 
reparameterization, 47-48 
skeptical or enthusiast, 413-416 
on standard deviation (cr), 19 
survival models, 323-324 
See also Informative priors; specific 
types of distributions
Prior distributions, regression models, 
187-189, 226-229 
accelerated failure-time model, 
354-359
binomial models, 446-450 
conditionally conjugate
independence, 185-192 
conditional means, 187-189,
226-229, 235-236, 251, 447-448 
conjugate priors, 192-194 
dependent Dirichlet process (DDP)
model, 372 
flat priors, 185 
hierarchical models, 435-437, 
446-450
informative priors, 189 
low-information omnibus priors, 
231-232, 236
partial information prior, 190 -191, 
229-231, 251-252, 356-357
Poisson model, 242-243 
posterior analysis using flat priors, 
181-184
proportional hazards model, 363, 
367-371
Zellner’s g-prior, 194
Prior distributions, specifying, 149-150 
data augmentation priors, 159-161 
effect size, 163 
flat priors, 150-152 
Jeffreys priors, 152-154 
models with possible latent effects, 
435-437
reference priors, 161-163, See also 
Reference priors 
regression models, 184-194 
scientifically informed priors,
154-159, See also Informative 
priors 
standard deviations, 19, 159 
two-sample binomial models, 
155-158, 160-161, 162-163 
Prior distributions, survival models 
exponential, 323-324 
log-normal, 330-331 
nonparametric models, 331-336 
Weibull, 326-327 
See also Survival analysis, models 
for exchangeable observations 
Prior predictive distribution, 30, 61 
Prior sample size, 42, 398-399 
Probability, 12-19 
Probability axioms and rules, 509-510 
Probability density functions (pdfs), 20, 
• 23, 37, 512
bivariate (or joint), 513 
multivariate (or joint), 515 
Student’s, 56
Probability integral transform, 80 
Probability interval (PI), 42-43, 52-53 
Probability mass functions (pmfs), 20, 
511, 513
Probability models, 2, 7 
conditional probability, 12-13 
notational conventions, 20-21 
philosophical positions about, 16 
See also specific distributions or 
models
Probability of success, 125
Probability space, 509

Index
597
Probit link function, 235
Product binomial sampling, 126
Progression-free survival, 409n, 414-416
Proportional hazards regression model, 
360-371, 537-538, 551 
baseline hazard function, 361-365 
counting process formulation, 
365-367
dependent Dirichlet process (DDP) 
model, 372-375
piecewise exponential model, 
364-365
prior distributions, 367-371
Proportionality form of Bayes’ theorem, 
24-27
Proportional odds model for safety and 
efficacy monitoring, 391-392
Proposal (or candidate-generating) 
distribution, 97
Prospective cohort sampling, 119, 
126-129
Pseudo-Bayes factor (PBF), 281, 
285-286
Pseudorandom numbers, 80
Pulmonary function (FEV) data 
example, 188-190, 196-198, 
298-299
Q
Quantile plots, 104-105
Quantile-quantile (Q-Q) plots, 289, 299
R
R2WinBUGS, 527, 531-535, 551
Raftery-Lewis method, 110-111
Random effects (frailty), 375-376 
Randomization, response-adaptive, 
416-421
Random number generation, 80, 527
Random variables (RVs), 11, 20, 
511-516
auxiliary variables for Hamiltonian 
MCMC, 97, 98
Bayes theorem for two variables, 
21-22
Bernoulli, 38 
bivariate, 512-514 
distribution of transformed 
variable, 515-516 
exchangeable, 37, 515, See also
Exchangeable observations, 
models for: Models for 
exchangeable observations 
expectation and moments, 516-519 
independence of, 515-516 
multivariate, 514-516 
notational conventions, 20-21 
univariate, 511-512 
variance of, 517-519
Random walk chain, 93, 95-96 
Rate differences, 243-244 
Rates, inferences for, 141-144 
Rat growth data model, 430-432 
R code
clinical trial with futility analyses, 
407/
dose finding, 387-388 
Metropolis-Hastings algorithm, 94 
random walk chain, 95-96
Receiver operating characteristic 
(ROC) curves, 482-483, 
491-493, 498-502
Reference priors, 120-121, 133, 149-150 
comparing Bernoulli populations, 
121
comparing normal populations, 
132-134
comparing Poisson counts, 142 
diffuse, 161, 162-163
Jeffreys, 121, 142, 152-154, 159, 385 
Poisson regression model, 242 
posterior distributions and, 121, 
133, 150, 152, 161 
regression models, 176, 242 
Reference standard, 483 
Regression coefficients, 167-168, 169 
accelerated failure-time model, 347, 
349, 354-359, 530 
conditional means prior, 187-189 
informative prior, 189

598
Index
linear combinations, 183 
link functions and, 236 
logistic regression model, 223-226 
models with latent effects, 436-437 
See also Covariates for regression
models; Regression models 
Regression models, 167-168, 260, 
375-376
alternatives to logistic regression, 
234-236
binomial, 215-221, 259-260, 
439-458
binormal model for diagnostic 
testing, 492-498, 501
biomarker-based diagnostic testing, 
498-502
generalized linear models, 234-235, 
258-260
linear, 167-207
link functions, 234-236, 258-260 
logistic, 215-235 
nonlinear, 260-264 
Poisson, 241-252 
time-to-event survival modeling, 
347-379
See also Hierarchical binomial 
regression modeling;
Hierarchical models; Linear 
regression; Logistic regression 
models; Poisson regression 
models; Prior distributions, 
regression models;
Time-to-event regression 
models
Rejection sampling, 83-87, 91
Relative rate, 244
Relative risk (RR), 125, 220-221
Reparameterization, 47-48
Residuals, 298
Response-adaptive randomization, 
416-421
Reye’s syndrome, 129-131
Right censoring, 313, 315-316
Risk, 125, 340-341
Risk difference, 126
Risk ratio, 125-126, 131
Risks, competing, 340-342
R packages, 527
Bayesian software interfaces, 
531-535, 542, 544-545 
convergence diagnostics, 102 
DPpackage, 69, 552
DPWeibull, 69, 333, 342, 373
S
Safety and efficacy monitoring, 
390-394, See also Stopping 
rules for clinical trials
Sample simulation from distributions, 
See Computational methods;
Markov chain Monte Carlo
(MCMC) sampling
Sample size
decision-theoretic determination, 
399-402
large-sample approximations, 77, 
See also Computational 
methods
Phase 2 clinical trial designs, 
396-402
precision of estimate, 397-399
prior, 42, 398-399
Sampling distibutions for exchangeable 
data, 314-316
Schwarz information criterion, 282 
Semiparametric time-to-event
regression model, 360-371, 552
Sensitivity analysis, 17, 359-360
Sensitivity of diagnostic test, 162, 483, 
490
Sequential designs in clinical studies, 
413, 483
Sethuraman “stick-breaking” 
representation, 68 
Shrinkage effect, 429 430 
Shrinkage estimators, 42, 50 
Simulating clinical trial designs, 
394-395
Simulation methods, See 
Computational methods;

Index
599
Markov chain Monte Carlo 
(MCMC) sampling; Software
Simulation software for posterior 
distributions, See Software
SIR (sampling-importance resampling) 
algorithm, 82
Skewed posteriors, 24, 43
Slice sampling, 96-97
Slope parameter, 167, 169
Smoking effects study, 247-252, 
253-254, 299
Snake bite data, 225-226 
Software, 527-551
BRugs, 527, 531, 535-537
JAGS, 537-540 
link functions, 236 
logistic regression model, 216-217 
nonparametric model resources, 69 
OpenBUGS, 530 
R2WinBUGS, 527, 531-537 
random number generation, 80, 527 
R packages, 551-552
Stan, 540-551
WinBUGS, 527-537
WinBUGS-R interfaces, 531-537 
See also R packages
Spatial data, 459 
spBayesSurv, 552 
Specificity, 162, 483, 490 
Stan, 540-551
Standard deviation (a)
comparing normal populations, 135 
posterior, 24, 42
prior specification, 19, 159, 448-450 
Standardization of regression model 
covariates, 178-179, 231
Standard parameterization, 253 
State space, 88
Stationarity, 40
Statistical importance, 224, 287-289
Statistical power, 396
Statistical significance, 224 
Stopping rules for clinical trials, 
402-411
decision-theoretic, 410-411
futility. 402. 406 408
hypothesis testing-based, 408 409 
posterior probability-based, 
402-403
prediction-based, 403-408 
skeptical or enthusiast priors.
413-416
Strong law of large numbers. 519
Studentized residuals, 298, 300
Student’s probability density function
(pdf), 56
Student’s t, 163, 524 i
Student’s t distribution, 52
Stylized Bayesian designs, 381
Success probability, 125
Sum of squares of errors (SSE), 182
Survival analysis, 311
accelerated failure-time regression
model, 348, 530
censored data in BUGS, 530-531 
censoring, 313-316
concepts and definitions, 311-320 
data examples, 5
exponential model, 61-65
hazard functions, 312
interaction effects, 195 
logistic regression model for
snakebite data, 225-226 
nonparametric models, 331-336, 
371-375
predictive inferences, 65, 318 
predictive survival probabilities, 
349-350
predictor variable of interest,
287-288
sensitivity analysis, 359-360 
See also Time-to-event data
Survival analysis, models for
exchangeable observations, 311 
competing risks, 340-342 
concepts and definitions, 311-320 
Dirichlet process mixture (DPM)
model, 331-336
exponential model, 323-325 
inference and its targets, 316-318,

600
Index
See also Hazard functions; 
Survival functions 
log-normal model, 330-331 
nonparametric models, 331-336 
one-sample models, 322-336 
plotting functions, 318-320 
two-sample models, 336-340 
Weibull model, 326-330, 333-335 
See also Hazard functions; Survival 
functions
Survival analysis, regression models, 
347-379
accelerated failure-time, 347-360 
nonparametric models, 371-375 
proportional hazards model, 
360-371, 537-538
random effects (frailty), 375-376
See also Time-to-event regression 
models
Survival functions, 312, 317
empirical Kaplan-Meier estimate, 
320-322
exponential model, 324
net, 342
plotting, 317-320
proportional hazards regression 
model, 362
Survival probability at fixed time point, 
317
Survivor function, 41, 62
T
T distribution, 525t 
3+3 design, 383-386 
Time-dependent covariates, 461 
Time-to-event data, 311
common distributions for modeling, 
311-312
data examples, 4-5
exponential model, 61-65, 76 
normal models, 39 
See also Survival analysis 
Time-to-event regression models, 347 
accelerated failure-time, 347-360 
nonparametric models, 371-375 
proportional hazards model, 
360-371, 537-538, 551 
random effects (frailty), 375-376 
semiparametric regression model, 
360-371, 552
Toenail fungus, 440-443, 459
Toxicity monitoring, 384-385, 393
Toxicology, 225-226
Trace and history plots, 102-105
Traditional approach to data analysis, 
203-205
Training data, 494
Training samples, 484, 494
Transition kernel, 88
Trauma data example, 3-4, 6, 222-225, 
228-231, 233-234, 277, 287-288
Treatment effect interaction, See Effect 
modification
Truncated beta distribution, 124
Truncated normal distribution, 85
Two-sample data models 
prior specification, 155-158, 
160-161, 162-163 
survival models, 336-340 
See also Population comparisons
Two-way ANOVA, 200
Type I error, 396, 412
Type II error, 396
U
Uncertainty modeling, 2, 17, 20, 120, 
See also Prior distributions
Uniform distribution, 8, 42, 80, 83, 
96-97, 150, 330, 435, 436, 524f
Uniform-Pareto hierarchical prior, 
328-329
Uninformative censoring, 314
Univariate random variables, 511-512
Unix-based operating systems, 537, 551
Unobservable quantities, 20
Urn-based adaptive randomization, 
417-418
V
Variance, 204, 356-357
conditional means prior, 519

Index 
601
flat priors, 151 
between-group and within-group, 
204-205
laws of, 518
model checking, 289, 299
Poisson distributions, 252
posterior, 24
posterior derivation when known 
and unknown, 49-50, 57-58
precision, 48, 49-51, 397, 399
of random variable, 517-519
regression models, 168
See also Analysis of variance
Vector notation, 180
Veteran blood pressure data example 
(VetBP), 3, 6, 7, 19-20, 25-26, 
27-31, 43, 56-59, 167, 169, 
175-178, 184, 272-274, 532, 543
W
Weibull distribution, 76-77, 326, 524i 
accelerated failure-time regression 
model, 348, 353, 355, 359, 371
Dirichlet process mixture (DPM) 
models for survival analysis, 
333-335
Gibbs sampling, 91
modeling time-to-event data, 312
R packages, 69, 333, 342, 373, 552
state space, 88
survival models, 326 330, 333 335
Widely applicable information criterion
(WAIC), 278, 283 284, 287
WinBUGS, 527-537, 540-541, 551
Metropolis-Hastings algorithm, 540
R interfaces, 531-537
WINE, 551-552
Wishart distribution, 5251
Within-group variance, 204-205
Worst outcome criterion (WOC), 
397-398
Z
Zellner’s g-prior, 194
Zero-inflated Poisson (ZIP), 254-258, 
541


