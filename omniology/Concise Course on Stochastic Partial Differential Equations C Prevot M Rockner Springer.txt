Lecture Notes in Mathematics
1905
Editors:
J.-M. Morel, Cachan
F. Takens, Groningen
B. Teissier, Paris

Claudia PrÂ´evË†ot Â· Michael RÂ¨ockner
A Concise Course
on Stochastic Partial
Differential Equations
ABC

Authors
Claudia PrÂ´evË†ot
FakultÂ¨at fÂ¨ur Mathematik
UniversitÂ¨at Bielefeld
UniversitÂ¨atsstr. 25
33615 Bielefeld
Germany
e-mail: cprevot@web.de
Michael RÂ¨ockner
FakultÂ¨at fÂ¨ur Mathematik
UniversitÂ¨at Bielefeld
UniversitÂ¨atsstr. 25
33615 Bielefeld
Germany
e-mail: roeckner@math.uni-bielefeld.de
Departments of Mathematics
and Statistics
Purdue University
150 N. University St.
West Lafayette, IN 47907-2067
USA
e-mail: roeckner@math.purdue.edu
Library of Congress Control Number: 2007925694
Mathematics Subject Classiï¬cation (2000): 35-XX, 60-XX
ISSN print edition: 0075-8434
ISSN electronic edition: 1617-9692
ISBN-10 3-540-70780-8 Springer Berlin Heidelberg New York
ISBN-13 978-3-540-70780-6 Springer Berlin Heidelberg New York
DOI 10.1007/978-3-540-70781-3
This work is subject to copyright. All rights are reserved, whether the whole or part of the material is
concerned, speciï¬cally the rights of translation, reprinting, reuse of illustrations, recitation, broadcasting,
reproduction on microï¬lm or in any other way, and storage in data banks. Duplication of this publication
or parts thereof is permitted only under the provisions of the German Copyright Law of September 9,
1965, in its current version, and permission for use must always be obtained from Springer. Violations are
liable for prosecution under the German Copyright Law.
Springer is a part of Springer Science+Business Media
springer.com
câƒSpringer-Verlag Berlin Heidelberg 2007
The use of general descriptive names, registered names, trademarks, etc. in this publication does not imply,
even in the absence of a speciï¬c statement, that such names are exempt from the relevant protective laws
and regulations and therefore free for general use.
Typesetting by the authors and SPi using a Springer LATEX macro package
Cover design: WMXDesign GmbH, Heidelberg
Printed on acid-free paper
SPIN: 11982159
VA41/3100/SPi
5 4 3 2 1 0

Contents
1. Motivation, Aims and Examples
1
2. Stochastic Integral in Hilbert Spaces
5
2.1. Inï¬nite-dimensional Wiener processes
. . . . . . . . . . . . . .
5
2.2. Martingales in general Banach spaces . . . . . . . . . . . . . . .
17
2.3. The deï¬nition of the stochastic integral
. . . . . . . . . . . . .
21
2.3.1.
Scheme of the construction of the stochastic integral . .
22
2.3.2.
The construction of the stochastic integral
in detail . . . . . . . . . . . . . . . . . . . . . . . . . . .
22
2.4. Properties of the stochastic integral . . . . . . . . . . . . . . . .
35
2.5. The stochastic integral for cylindrical Wiener processes
. . . .
39
2.5.1.
Cylindrical Wiener processes
. . . . . . . . . . . . . . .
39
2.5.2.
The deï¬nition of the stochastic integral
. . . . . . . . .
41
3. Stochastic Diï¬€erential Equations in Finite Dimensions
43
3.1. Main result and a localization lemma . . . . . . . . . . . . . . .
43
3.2. Proof of existence and uniqueness . . . . . . . . . . . . . . . . .
49
4. A Class of Stochastic Diï¬€erential Equations
55
4.1. Gelfand triples, conditions on the coeï¬ƒcients and examples
. .
55
4.2. The main result and an ItË†o formula . . . . . . . . . . . . . . . .
73
4.3. Markov property and invariant measures . . . . . . . . . . . . .
91
A. The Bochner Integral
105
A.1. Deï¬nition of the Bochner integral . . . . . . . . . . . . . . . . . 105
A.2. Properties of the Bochner integral
. . . . . . . . . . . . . . . . 107
B. Nuclear and Hilbertâ€“Schmidt Operators
109
C. Pseudo Inverse of Linear Operators
115
D. Some Tools from Real Martingale Theory
119
E. Weak and Strong Solutions: Yamadaâ€“Watanabe Theorem
121
E.1. The main result . . . . . . . . . . . . . . . . . . . . . . . . . . . 121
F. Strong, Mild and Weak Solutions
133
V

VI
Contents
Bibliography
137
Index
140
Symbols
143

1. Motivation, Aims
and Examples
These lectures will concentrate on (nonlinear) stochastic partial diï¬€erential
equations (SPDEs) of evolutionary type. All kinds of dynamics with stochas-
tic inï¬‚uence in nature or man-made complex systems can be modelled by
such equations. As we shall see from the examples, at the end of this section
the state spaces of their solutions are necessarily inï¬nite dimensional such
as spaces of (generalized) functions. In these notes the state spaces, denoted
by E, will be mostly separable Hilbert spaces, sometimes separable Banach
spaces.
There is also enormous research activity on SPDEs, where the state spaces
are not linear, but rather spaces of measures (particle systems, dynamics in
population genetics) or inï¬nite-dimensional manifolds (path or loop spaces
over Riemannian manifolds).
There are basically three approaches to analysing SPDEs: the â€œmartingale
(or martingale measure) approachâ€ (cf. [Wal86]), the â€œsemigroup (or mild
solution) approachâ€ (cf. [DPZ92], [DPZ96]) and the â€œvariational approachâ€
(cf. [Roz90]). There is an enormously rich literature on all three approaches
which cannot be listed here. We refer instead to the above monographs.
The purpose of these notes is to give a concise introduction to the â€œvari-
ational approachâ€, as self-contained as possible. This approach was initiated
in pioneering work by Pardoux ([Par72],[Par75]) and further developed by
N. Krylov and B. Rozowskii in [KR79] (see also [Roz90]) for continuous mar-
tingales as integrators in the noise term and later by I. Gyongy and N. Krylov
in [GK81],[GK82],[GyÂ¨o82] for not necessarily continuous martingales.
These notes grew out of a two-semester graduate course given by the second-
named author at Purdue University in 2005/2006. The material has been
streamlined and could be covered in just one semester depending on the pre-
knowledge of the attending students. Prerequisites would be an advanced
course in probability theory, covering standard martingale theory, stochas-
tic processes in Rd and maybe basic stochastic integration, though the latter
is not formally required. Since graduate students in probability theory are
usually not familiar with the theory of Hilbert spaces or basic linear operator
theory, all required material from these areas is included in the notes, most
of it in the appendices. For the same reason we minimize the general theory
of martingales on Hilbert spaces, paying, however, the price that some proofs
1

2
1. Motivation, Aims and Examples
about stochastic integration on Hilbert space are a bit lengthy, since they have
to be done â€œby bare handsâ€.
In comparison with [Roz90] for simplicity we specialize to the case where
the integrator in the noise term is just a cylindrical Wiener process. But every-
thing is spelt out in a way so that it generalizes directly to continuous local
martingales. In particular, integrands are always assumed to be predictable
rather than just adapted and product measurable. The existence and unique-
ness proof (cf. Subsection 4.2) is our personal version of the one in [KR79],
[Roz90] and largely taken from [RRW06] presented there in a more general
framework. The results on invariant measures (cf. Subsection 4.3) we could
not ï¬nd in the literature for the â€œvariational approachâ€. They are, however,
quite straightforward modiï¬cations of those in the â€œsemigroup approachâ€ in
[DPZ96]. The examples and applications in Subsection 4.1 in connection with
the stochastic porous media equation are fairly recent and are modiï¬cations
from results in [DPRLRW06] and [RRW06].
To keep these notes reasonably self-contained we also include a complete
proof of the ï¬nite-dimensional case in Chapter 3, which is based on the very
focussed and beautiful exposition in [Kry99], which uses the Euler approxi-
mation. Among other complementing topics the appendices contain a detailed
account of the Yamadaâ€“Watanabe theorem on the relation between weak and
strong solutions (cf. Appendix E).
The structure of these notes is, as we hope, obvious from the list of con-
tents. We only would like to mention here, that a substantial part consists of
a very detailed introduction to stochastic integration on Hilbert spaces (see
Chapter 2), major parts of which (as well as Appendices Aâ€“C) are taken from
the Diploma thesis of Claudia PrÂ´evË†ot and Katja Frieler. We would like to
thank Katja Frieler at this point for her permission to do this. We also like to
thank all coauthors of those joint papers which form another component for
the basis of these notes. It was really a pleasure working with them in this
exciting area of probability. We would also like to thank Matthias Stephan
and Sven Wiesinger for the excellent typing job, as well as the participants
of the graduate course at Purdue University for spotting many misprints and
small mistakes.
Before starting with the main body of these notes we would like to give a few
examples of SPDE that appear in fundamental applications. We do this in a
very brief way, in particular, pointing out which of them can be analysed by
the tools developed in this course. We refer to the above-mentioned literature
for a more elaborate discussion of these and many more examples and their
role in the applied sciences.
Example 1.0.1 (Stochastic quantization of the free Euclidean quan-
tum ï¬eld).
dXt = (âˆ†âˆ’m2)Xt dt + dWt
on E âŠ‚Sâ€²(Rd).

1. Motivation, Aims and Examples
3
â€¢ m âˆˆ[0, âˆ) denotes â€œmassâ€,
â€¢ (Wt)tâ©¾0 is a cylindrical Brownian motion on L2(Rd) âŠ‚E (the inclusion
is a Hilbertâ€“Schmidt embedding).
Example 1.0.2 (Stochastic reaction diï¬€usion equations).
dXt = [âˆ†Xt âˆ’X3
t ] dt +

Q dWt
on E := Lp(Rd).
â€¢ Q is a trace class operator on L2(Rd), can also depend on Xt (then Q
becomes Q(Xt)),
â€¢ (Wt)tâ©¾0 is a cylindrical Brownian motion on L2(Rd).
Example 1.0.3 (Stochastic Burgers equation).
dXt = âˆ†Xt âˆ’Xt
d
dÎ¾ Xt +

Q dWt
on E := L2
[0, 1]

.
â€¢ Î¾ âˆˆ[0, 1],
â€¢ Q as above,
â€¢ (Wt)tâ©¾0 is a cylindrical Brownian motion on L2
[0, 1]

.
Example 1.0.4 (Stochastic Navierâ€“Stokes equation).
dXt =

Î½âˆ†sXt âˆ’âŸ¨Xt, âˆ‡âŸ©Xt

dt +

Q dWt
on E :=

x âˆˆL2(Î› â†’R2, dx)
 div x = 0

, Î› âŠ‚Rd, d = 2, 3, âˆ‚Î› smooth.
â€¢ Î½ denotes viscosity,
â€¢ âˆ†s denotes the Stokes Laplacian,
â€¢ Q as above,
â€¢ (Wt)tâ©¾0 is a cylindrical Brownian motion on L2(Î› â†’Rd),
â€¢ div is taken in the sense of distributions.
Example 1.0.5 (Stochastic porous media equation).
dXt =

âˆ†Î¨(Xt) + Î¦(Xt)

dt + B(Xt) dWt
on H := dual of H1
0(Î›) (:= Sobolev space of order 1 in L2(Î›) with Dirichlet
boundary conditions).

4
1. Motivation, Aims and Examples
â€¢ Î› as above,
â€¢ Î¨, Î¦ : R â†’R â€œmonotoneâ€,
â€¢ B(x) : H â†’H Hilbertâ€“Schmidt operator, âˆ€x âˆˆH.
The general form of these equations with state spaces consisting of functions
Î¾ 	â†’x(Î¾), where Î¾ is a spatial variable, e.g. from a subset of Rd, looks as
follows:
dXt(Î¾) = A
	
t, Xt(Î¾), DÎ¾Xt(Î¾), D2
Î¾

Xt(Î¾)

dt
+ B
	
t, Xt(Î¾), DÎ¾Xt(Î¾), D2
Î¾

Xt(Î¾)

dWt .
Here DÎ¾ and D2
Î¾ mean ï¬rst and second total derivatives, respectively. The
stochastic term can be considered as a â€œperturbation by noiseâ€. So, clearly one
motivation for studying SPDEs is to get information about the corresponding
(unperturbed) deterministic PDE by letting the noise go to zero (e.g. replace
B by Îµ Â· B and let Îµ â†’0) or to understand the diï¬€erent features occurring if
one adds the noise term.
If we drop the stochastic term in these equations we get a deterministic
PDE of â€œevolutionary typeâ€. Roughly speaking this means we have that the
time derivative of the desired solution (on the left) is equal to a nonâ€“linear
functional of its spatial derivatives (on the right).
Among others (see Subsection 4.1, in particular the cases, where âˆ†is
replaced by the p-Laplacian) the approach presented in these notes will cover
Examples 1.0.2 in case d = 3 or 4. (cf. Remark 4.1.10,2. and also [RRW06]
without restrictions on the dimension) and 1.0.5 (cf. Example 4.1.11). For
Example 1.0.1 we refer to [AR91] and for Examples 1.0.3 and 1.0.4 e.g. to
[DPZ92], [DPZ96].

2. The Stochastic Integral
in General Hilbert Spaces
(w.r.t. Brownian Motion)
This chapter is a slight modiï¬cation of Chap. 1 in [FK01].
We ï¬x two separable Hilbert spaces

U, âŸ¨, âŸ©U

and

H, âŸ¨, âŸ©

. The ï¬rst part
of this chapter is devoted to the construction of the stochastic ItË†o integral
 t
0
Î¦(s) dW(s),
t âˆˆ[0, T],
where W(t), t âˆˆ[0, T], is a Wiener process on U and Î¦ is a process with
values that are linear but not necessarily bounded operators from U to H.
For that we ï¬rst will have to introduce the notion of the standard Wiener
process in inï¬nite dimensions. Then there will be a short section about mar-
tingales in general Hilbert spaces. These two concepts are important for the
construction of the stochastic integral which will be explained in the following
section.
In the second part of this chapter we will present the ItË†o formula and
the stochastic Fubini theorem and establish basic properties of the stochastic
integral, including the Burkholderâ€“Davisâ€“Gundy inequality.
Finally, we will describe how to transmit the deï¬nition of the stochastic
integral to the case that W(t), t âˆˆ[0, T], is a cylindrical Wiener process. For
simplicity we assume that U and H are real Hilbert spaces.
2.1. Inï¬nite-dimensional Wiener processes
For a topological space X we denote its Borel Ïƒ-algebra by B(X).
Deï¬nition 2.1.1. A probability measure Âµ on

U, B(U)

is called Gaussian
if for all v âˆˆU the bounded linear mapping
vâ€² :U â†’R
deï¬ned by
u 	â†’âŸ¨u, vâŸ©U,
u âˆˆU,
5

6
2. Stochastic Integral in Hilbert Spaces
has a Gaussian law, i.e. for all v âˆˆU there exist m := m(v) âˆˆR and Ïƒ :=
Ïƒ(v) âˆˆ[0, âˆ[ such that, if Ïƒ(v) > 0,

Âµ â—¦(vâ€²)âˆ’1
(A) = Âµ(vâ€² âˆˆA) =
1
âˆš
2Ï€Ïƒ2

A
eâˆ’(xâˆ’m)2
2Ïƒ2
dx
for all A âˆˆB(R),
and, if Ïƒ(v) = 0,
Âµ â—¦(vâ€²)âˆ’1 = Î´m(v).
Theorem 2.1.2. A measure Âµ on

U, B(U)

is Gaussian if and only if
Ë†Âµ(u) :=

U
eiâŸ¨u,vâŸ©U Âµ(dv) = eiâŸ¨m,uâŸ©U âˆ’1
2 âŸ¨Qu,uâŸ©U ,
u âˆˆU,
where m âˆˆU and Q âˆˆL(U) is nonnegative, symmetric, with ï¬nite trace (see
Deï¬nition B.0.3; here L(U) denotes the set of all bounded linear operators
on U).
In this case Âµ will be denoted by N(m, Q) where m is called mean and Q
is called covariance (operator). The measure Âµ is uniquely determined by m
and Q.
Furthermore, for all h, g âˆˆU

âŸ¨x, hâŸ©U Âµ(dx) = âŸ¨m, hâŸ©U,
 
âŸ¨x, hâŸ©U âˆ’âŸ¨m, hâŸ©U

âŸ¨x, gâŸ©U âˆ’âŸ¨m, gâŸ©U

Âµ(dx) = âŸ¨Qh, gâŸ©U,

âˆ¥x âˆ’mâˆ¥2
U Âµ(dx) = tr Q.
Proof. (cf. [DPZ92]) Obviously, a probability measure with this Fourier trans-
form is Gaussian. Now let us conversely assume that Âµ is Gaussian. We need
the following:
Lemma 2.1.3. Let Î½ be a probability measure on (U, B(U)). Let k âˆˆN be
such that

U
âŸ¨z, xâŸ©U
k Î½(dx) < âˆ
âˆ€z âˆˆU.
Then there exists a constant C = C(k, Î½) > 0 such that for all h1, . . . , hk âˆˆU

U
âŸ¨h1, xâŸ©U Â· Â· Â· âŸ¨hk, xâŸ©U
 Î½(dx) â©½C âˆ¥h1âˆ¥U Â· Â· Â· âˆ¥hkâˆ¥U.
In particular, the symmetric k-linear form
U k âˆ‹(h1, . . . , hk) 	â†’

âŸ¨h1, xâŸ©U Â· Â· Â· âŸ¨hk, xâŸ©U Î½(dx) âˆˆR
is continuous.

2.1. Inï¬nite-dimensional Wiener processes
7
Proof. For n âˆˆN deï¬ne
Un :=

z âˆˆU


U
âŸ¨z, xâŸ©U
k Î½(dx) â©½n

.
By assumption
U =
âˆ

n=1
Un.
Since U is a complete metric space, by the Baire category theorem, there
exists n0 âˆˆN such that Un0 has non-empty interior, so there exists a ball
(with centre z0 and radius r0) B(z0, r0) âŠ‚Un0. Hence

U
âŸ¨z0 + y, xâŸ©U
k Î½(dx) â©½n0
âˆ€y âˆˆB(0, r0),
therefore for all y âˆˆB(0, r0)

U
âŸ¨y, xâŸ©U
k Î½(dx) =

U
âŸ¨z0 + y, xâŸ©U âˆ’âŸ¨z0, xâŸ©U
k Î½(dx)
â©½2kâˆ’1

U
âŸ¨z0 + y, xâŸ©U
k Î½(dx) + 2kâˆ’1

U
âŸ¨z0, xâŸ©U
k Î½(dx)
â©½2kn0.
Applying this for y := r0z, z âˆˆU with |z|U = 1, we obtain

U
âŸ¨z, xâŸ©U
k Î½(dx) â©½2kn0râˆ’k
0 .
Hence, if h1, . . . , hk âˆˆU \ {0}, then by the generalized HÂ¨older inequality

U

 h1
|h1|U
, x

U
Â· Â· Â·
 hk
|hk|U
, x

U
 Î½(dx)
â©½

U

 h1
|h1|U
, x

U

k
Î½(dx)
1/k
. . .

U

 hk
|hk|U
, x

U

k
Î½(dx)
1/k
â©½2kn0râˆ’k
0 ,
and the assertion follows.
Applying Lemma 2.1.3 for k = 1 and Î½ := Âµ we obtain that
U âˆ‹h 	â†’

âŸ¨h, xâŸ©U Âµ(dx) âˆˆR
is a continuous linear map, hence there exists m âˆˆU such that

U
âŸ¨x, hâŸ©U Âµ(dx) = âŸ¨m, hâŸ©
âˆ€h âˆˆH.

8
2. Stochastic Integral in Hilbert Spaces
Applying Lemma 2.1.3 for k = 2 and Î½ := Âµ we obtain that
U 2 âˆ‹(h1, h2) 	â†’

âŸ¨x, h1âŸ©UâŸ¨x, h2âŸ©U Âµ(dx) âˆ’âŸ¨m, h1âŸ©UâŸ¨m, h2âŸ©U
is a continuous symmetric bilinear map, hence there exists a symmetric Q âˆˆ
L(U) such that this map is equal to
U 2 âˆ‹(h1, h2) 	â†’âŸ¨Qh1, h2âŸ©U.
Since for all h âˆˆU
âŸ¨Qh, hâŸ©U =

âŸ¨x, hâŸ©2
U Âµ(dx) âˆ’

âŸ¨x, hâŸ©U Âµ(dx)
2
â©¾0,
Q is positive deï¬nite. It remains to prove that Q is trace class (i.e.
tr Q :=
âˆ

i=1
âŸ¨Qei, eiâŸ©U < âˆ
for one (hence every) orthonormal basis {ei | i âˆˆN} of U, cf. Appendix B).
We may assume without loss of generality that Âµ has mean zero, i.e. m = 0
(âˆˆU), since the image measure of Âµ under the translation U âˆ‹x 	â†’x âˆ’m is
again Gaussian with mean zero and the same covariance Q. Then we have for
all h âˆˆU and all c âˆˆ(0, âˆ)
1 âˆ’eâˆ’1
2 âŸ¨Qh,hâŸ©U =

U

1 âˆ’cosâŸ¨h, xâŸ©U

Âµ(dx)
â©½

{|x|Uâ©½c}

1 âˆ’cosâŸ¨h, xâŸ©U

Âµ(dx) + 2Âµ

x âˆˆU
 |x|U > c

â©½1
2

{|x|Uâ©½c}
âŸ¨h, xâŸ©U
2 Âµ(dx) + 2Âµ

x âˆˆU
 |x|U > c

(2.1.1)
(since 1 âˆ’cos x â©½1
2x2). Deï¬ning the positive deï¬nite symmetric linear oper-
ator Qc on U by
âŸ¨Qch1, h2âŸ©U :=

{|x|Uâ©½c}
âŸ¨h1, xâŸ©U Â· âŸ¨h2, xâŸ©U Âµ(dx),
h1, h2 âˆˆU,
we even have that Qc is trace class because for every orthonormal basis {ek |
k âˆˆN} of U we have (by monotone convergence)
âˆ

k=1
âŸ¨Qcek, ekâŸ©U =

{|x|Uâ©½c}
âˆ

k=1
âŸ¨ek, xâŸ©2
U Âµ(dx) =

{|x|Uâ©½c}
|x|2
U Âµ(dx)
â©½c2 < âˆ.

2.1. Inï¬nite-dimensional Wiener processes
9
Claim: There exists c0 âˆˆ(0, âˆ) (large enough) so that Q â©½2 log 4 Qc0 (mean-
ing that âŸ¨Qh, hâŸ©U â©½2 log 4âŸ¨Qc0h, hâŸ©U for all h âˆˆU).
To prove the claim let c0 be so big that Âµ

x âˆˆU
 |x|U > c0

â©½1
8. Let
h âˆˆU such that âŸ¨Qc0h, hâŸ©U â©½1. Then (2.1.1) implies
1 âˆ’eâˆ’1
2 âŸ¨Qh,hâŸ©U â©½1
2 + 1
4 = 3
4,
hence 4 â©¾e
1
2 âŸ¨Qh,hâŸ©U , so âŸ¨Qh, hâŸ©U â©½2 log 4. If h âˆˆU is arbitrary, but
âŸ¨Qc0h, hâŸ©U Ì¸= 0, then we apply what we have just proved to h/âŸ¨Qc0h, hâŸ©
1
2
U and
the claim follows for such h. If, however, âŸ¨Qc0h, hâŸ©= 0, then for all n âˆˆN,
âŸ¨Qc0nh, nhâŸ©U = 0 â©½1, hence by the above âŸ¨Qh, hâŸ©U â©½nâˆ’22 log 4. Therefore,
âŸ¨Qc0h, hâŸ©U = 0 and the claim is proved, also for such h.
Since Qc0 has ï¬nite trace, so has Q by the claim and the theorem is proved,
since the uniqueness part follows from the fact that the Fourier transform is
one-to-one.
The following result is then obvious.
Proposition 2.1.4. Let X be a U-valued Gaussian random variable on a
probability space (â„¦, F, P), i.e. there exist m âˆˆU and Q âˆˆL(U) nonnegative,
symmetric, with ï¬nite trace such that P â—¦Xâˆ’1 = N(m, Q).
Then âŸ¨X, uâŸ©U is normally distributed for all u âˆˆU and the following state-
ments hold:
â€¢ E

âŸ¨X, uâŸ©U

= âŸ¨m, uâŸ©U for all u âˆˆU,
â€¢ E

âŸ¨X âˆ’m, uâŸ©U Â· âŸ¨X âˆ’m, vâŸ©U

= âŸ¨Qu, vâŸ©U for all u, v âˆˆU,
â€¢ E

âˆ¥X âˆ’mâˆ¥2
U

= tr Q.
The following proposition will lead to a representation of a U-valued
Gaussian random variable in terms of real-valued Gaussian random variables.
Proposition 2.1.5. If Q âˆˆL(U) is nonnegative, symmetric, with ï¬nite trace
then there exists an orthonormal basis ek, k âˆˆN, of U such that
Qek = Î»kek,
Î»k â©¾0, k âˆˆN,
and 0 is the only accumulation point of the sequence (Î»k)kâˆˆN.
Proof. See [RS72, Theorem VI.21; Theorem VI.16 (Hilbertâ€“Schmidt theorem)].
Proposition 2.1.6 (Representation of a Gaussian random variable).
Let m âˆˆU and Q âˆˆL(U) be nonnegative, symmetric, with tr Q < âˆ. In
addition, we assume that ek, k âˆˆN, is an orthonormal basis of U consist-
ing of eigenvectors of Q with corresponding eigenvalues Î»k, k âˆˆN, as in
Proposition 2.1.5, numbered in decreasing order.

10
2. Stochastic Integral in Hilbert Spaces
Then a U-valued random variable X on a probability space (â„¦, F, P) is
Gaussian with P â—¦Xâˆ’1 = N(m, Q) if and only if
X =

kâˆˆN

Î»kÎ²kek + m
(as objects in L2(â„¦, F, P; U)),
where Î²k, k âˆˆN, are independent real-valued random variables with P â—¦Î²k
âˆ’1 =
N(0, 1) for all k âˆˆN with Î»k > 0. The series converges in L2(â„¦, F, P; U).
Proof.
1. Let X be a Gaussian random variable with mean m and covariance Q.
Below we set âŸ¨, âŸ©:= âŸ¨, âŸ©U.
Then X = 
kâˆˆNâŸ¨X, ekâŸ©ek in U where âŸ¨X, ekâŸ©is normally distributed with
mean âŸ¨m, ekâŸ©and variance Î»k, k âˆˆN, by Proposition 2.1.4. If we now deï¬ne
Î²k :

= âŸ¨X,ekâŸ©âˆ’âŸ¨m,ekâŸ©
âˆšÎ»k
if k âˆˆN with Î»k > 0
â‰¡0 âˆˆR
else,
then we get that P â—¦Î²âˆ’1
k
= N(0, 1) and X = 
kâˆˆN
âˆšÎ»kÎ²kek +m. To prove
the independence of Î²k, k âˆˆN, we take an arbitrary n âˆˆN and ak âˆˆR,
1 â©½k â©½n, and obtain that for c := âˆ’n
k=1, Î»kÌ¸=0
ak
âˆšÎ»k âŸ¨m, ekâŸ©
n

k=1
akÎ²k =
n

k=1,
Î»kÌ¸=0
ak
âˆšÎ»k
âŸ¨X, ekâŸ©+ c =

X,
n

k=1,
Î»kÌ¸=0
ak
âˆšÎ»k
ek

+ c
which is normally distributed since X is a Gaussian random variable. There-
fore we have that Î²k, k âˆˆN, form a Gaussian family. Hence, to get the
independence, we only have to check that the covariance of Î²i and Î²j,
i, j âˆˆN, i Ì¸= j, with Î»i Ì¸= 0 Ì¸= Î»j, is equal to zero. But this is clear since
E(Î²iÎ²j) =
1

Î»iÎ»j
E

âŸ¨X âˆ’m, eiâŸ©âŸ¨X âˆ’m, ejâŸ©

=
1

Î»iÎ»j
âŸ¨Qei, ejâŸ©
=
Î»i

Î»iÎ»j
âŸ¨ei, ejâŸ©= 0
for i Ì¸= j.
Besides, the series n
k=1
âˆšÎ»kÎ²kek, n âˆˆN, converges in L2(â„¦, F, P; U) since
the space is complete and
E

n

k=m

Î»kÎ²kek

2
=
n

k=m
Î»kE

|Î²k|2
=
n

k=m
Î»k.
Since 
kâˆˆN Î»k = tr Q < âˆthis expression becomes arbitrarily small for
m and n large enough.

2.1. Inï¬nite-dimensional Wiener processes
11
2. Let ek, k âˆˆN, be an orthonormal basis of U such that Qek = Î»kek,
k âˆˆN, and let Î²k, k âˆˆN, be a family of independent real-valued Gaussian
random variables with mean 0 and variance 1. Then it is clear that the
series n
k=1
âˆšÎ»kÎ²kek + m, n âˆˆN, converges to X := 
kâˆˆN
âˆšÎ»kÎ²kek + m
in L2(â„¦, F, P; U) (see part 1). Now we ï¬x u âˆˆU and get that
 n

k=1

Î»kÎ²kek + m, u

=
n

k=1

Î»kÎ²kâŸ¨ek, uâŸ©+ âŸ¨m, uâŸ©
is normally distributed for all n âˆˆN and the sequence converges in
L2(â„¦, F, P). This implies that the limit âŸ¨X, uâŸ©is also normally distributed
where
E

âŸ¨X, uâŸ©

= E
	
kâˆˆN

Î»kÎ²kâŸ¨ek, uâŸ©+ âŸ¨m, uâŸ©

= lim
nâ†’âˆE
	 n

k=1

Î»kÎ²kâŸ¨ek, uâŸ©

+ âŸ¨m, uâŸ©= âŸ¨m, uâŸ©
and concerning the covariance we obtain that
E
	
âŸ¨X, uâŸ©âˆ’âŸ¨m, uâŸ©

âŸ¨X, vâŸ©âˆ’âŸ¨m, vâŸ©

= lim
nâ†’âˆE
	 n

k=1

Î»kÎ²kâŸ¨ek, uâŸ©
n

k=1

Î»kÎ²kâŸ¨ek, vâŸ©

=

kâˆˆN
Î»kâŸ¨ek, uâŸ©âŸ¨ek, vâŸ©=

kâˆˆN
âŸ¨Qek, uâŸ©âŸ¨ek, vâŸ©
=

kâˆˆN
âŸ¨ek, QuâŸ©âŸ¨ek, vâŸ©= âŸ¨Qu, vâŸ©
for all u, v âˆˆU.
By part 2 of this proof we ï¬nally get the following existence result.
Corollary 2.1.7. Let Q be a nonnegative and symmetric operator in L(U)
with ï¬nite trace and let m âˆˆU. Then there exists a Gaussian measure Âµ =
N(m, Q) on

U, B(U)

.
Let us give an alternative, more direct proof of Corollary 2.1.7 without using
Proposition 2.1.6. For the proof we need the following exercise.
Exercise 2.1.8. Consider Râˆwith the product topology. Let B(Râˆ) denote
its Borel Ïƒ-algebra. Prove:
(i) B(Râˆ) = Ïƒ(Ï€k | k âˆˆN), where Ï€k : Râˆâ†’R denotes the projection on
the k-th coordinate.

12
2. Stochastic Integral in Hilbert Spaces
(ii) l2(R)
	
:=

(xk)kâˆˆN âˆˆRâˆ
âˆ

k=1
x2
k < âˆ

âˆˆB(Râˆ).
(iii) B(Râˆ) âˆ©l2(R) = Ïƒ

Ï€k |l2
 k âˆˆN

.
(iv) Let l2(R) be equipped with its natural norm
âˆ¥xâˆ¥l2 :=
	 âˆ

k=1
x2
k

 1
2 ,
x = (xk)kâˆˆN âˆˆl2(R),
and let B

l2(R)

be the corresponding Borel Ïƒ-algebra. Then:
B

l2(R)

= B(Râˆ) âˆ©l2(R).
Alternative Proof of Corollary 2.1.7. It suï¬ƒces to construct N(0, Q), since
N(m, Q) is the image measure of N(0, Q) under translation with m. For
k âˆˆN consider the normal distribution N(0, Î»k) on R and let Î½ be their
product measure on

Râˆ, B(Râˆ)

, i.e.
Î½ =

kâˆˆN
N(0, Î»k)
on

Râˆ, B(Râˆ)

.
Here Î»k, k âˆˆN, are as in Proposition 2.1.5. Since the map g : Râˆâ†’[0, âˆ]
deï¬ned by
g(x) :=
âˆ

k=1
x2
k ,
x = (xk)kâˆˆN âˆˆRâˆ,
is B(Râˆ)-measurable, we may calculate

Râˆg(x) Î½(dx) =
âˆ

k=1

x2
k N(0, Î»k)(dxk) =
âˆ

k=1
Î»k < âˆ.
Therefore, using Exercise 2.1.8(ii), we obtain Î½

l2(R)

= 1. Restricting Î½ to
B(Râˆ) âˆ©l2(R), by Exercise 2.1.8(iv) we get a probability measure, let us
call it ËœÂµ, on

l2(R), B

l2(R)

. Now take the orthonormal basis {ek | k âˆˆN}
from Proposition 2.1.5 and consider the corresponding canonical isomorphism
I : l2(R) â†’U deï¬ned by
I(x) =
âˆ

k=1
xkek,
x = (xk)kâˆˆN âˆˆl2(R).
It is then easy to check that the image measure
Âµ := ËœÂµ â—¦Iâˆ’1
on

U, B(U)

is the desired measure, i.e. Âµ = N(0, Q).

2.1. Inï¬nite-dimensional Wiener processes
13
After these preparations we will give the deï¬nition of the standard Q-Wiener
process. To this end we ï¬x an element Q âˆˆL(U), nonnegative, symmetric and
with ï¬nite trace and a positive real number T.
Deï¬nition 2.1.9. A U-valued stochastic process W(t), t âˆˆ[0, T], on a prob-
ability space (â„¦, F, P) is called a (standard) Q-Wiener process if:
â€¢ W(0) = 0,
â€¢ W has P-a.s. continuous trajectories,
â€¢ the increments of W are independent, i.e. the random variables
W(t1), W(t2) âˆ’W(t1), . . . , W(tn) âˆ’W(tnâˆ’1)
are independent for all 0 â©½t1 < Â· Â· Â· < tn â©½T, n âˆˆN,
â€¢ the increments have the following Gaussian laws:
P â—¦

W(t) âˆ’W(s)
âˆ’1 = N

0, (t âˆ’s)Q

for all 0 â©½s â©½t â©½T.
Similarly to the existence of Gaussian measures the existence of a Q-Wiener
process in U can be reduced to the real-valued case. This is the content of the
following proposition.
Proposition 2.1.10 (Representation of the Q-Wiener process). Let ek,
k âˆˆN, be an orthonormal basis of U consisting of eigenvectors of Q with cor-
responding eigenvalues Î»k, k âˆˆN. Then a U-valued stochastic process W(t),
t âˆˆ[0, T], is a Q-Wiener process if and only if
W(t) =

kâˆˆN

Î»kÎ²k(t)ek,
t âˆˆ[0, T],
(2.1.2)
where Î²k, k âˆˆ{n âˆˆN | Î»n > 0}, are independent real-valued Brownian
motions on a probability space (â„¦, F, P). The series even converges in
L2
â„¦, F, P; C([0, T], U)

, and thus always has a P-a.s. continuous modiï¬ca-
tion. (Here the space C

[0, T], U

is equipped with the sup norm.) In particu-
lar, for any Q as above there exists a Q-Wiener process on U.
Proof.
1. Let W(t), t âˆˆ[0, T], be a Q-Wiener process in U.
Since P â—¦W(t)âˆ’1 = N(0, tQ), we see as in the proof of Proposition 2.1.6
that
W(t) =

kâˆˆN

Î»kÎ²k(t)ek,
t âˆˆ[0, T],
with
Î²k(t) :

= âŸ¨W (t),ekâŸ©
âˆšÎ»k
if k âˆˆN with Î»k > 0
â‰¡0
else,

14
2. Stochastic Integral in Hilbert Spaces
for all t âˆˆ[0, T]. Furthermore, P â—¦Î²âˆ’1
k (t) = N(0, t), k âˆˆN, and Î²k(t),
k âˆˆN, are independent for each t âˆˆ[0, T].
Now we ï¬x k âˆˆN. First we show that Î²k(t), t âˆˆ[0, T], is a Brownian
motion:
If we take an arbitrary partition 0 = t0 â©½t1 < Â· Â· Â· < tn â©½T, n âˆˆN, of
[0, T] we get that
Î²k(t1), Î²k(t2) âˆ’Î²k(t1), . . . , Î²k(tn) âˆ’Î²k(tnâˆ’1)
are independent for each k âˆˆN since for 1 â©½j â©½n
Î²k(tj) âˆ’Î²k(tjâˆ’1) =

1
âˆšÎ»k

W(tj) âˆ’W(tjâˆ’1), ek

if Î»k > 0,
0
else.
Moreover, we obtain that for the same reason P â—¦

Î²k(t) âˆ’Î²k(s)
âˆ’1 =
N(0, t âˆ’s) for 0 â©½s â©½t â©½T.
In addition,
t 	â†’
1
âˆšÎ»k

W(t), ek

= Î²k(t)
is P-a.s. continuous for all k âˆˆN.
Secondly, it remains to prove that Î²k, k âˆˆN, are independent.
We take k1, . . . , kn âˆˆN, n âˆˆN, ki Ì¸= kj if i Ì¸= j and an arbitrary partition
0 = t0 â©½t1 â©½. . . â©½tm â©½T, m âˆˆN.
Then we have to show that
Ïƒ

Î²k1(t1), . . . , Î²k1(tm)

, . . . , Ïƒ

Î²kn(t1), . . . , Î²kn(tm)

are independent.
We will prove this by induction with respect to m:
If m = 1 it is clear that Î²k1(t1), . . . , Î²kn(t1) are independent as observed
above. Thus, we now take a partition 0 = t0 â©½t1 â©½. . . â©½tm+1 â©½T and
assume that
Ïƒ

Î²k1(t1), . . . , Î²k1(tm)

, . . . , Ïƒ

Î²kn(t1), . . . , Î²kn(tm)

are independent. We note that
Ïƒ

Î²ki(t1), . . . , Î²ki(tm), Î²ki(tm+1)

= Ïƒ

Î²ki(t1), . . . , Î²ki(tm), Î²ki(tm+1) âˆ’Î²ki(tm)

,
1 â©½i â©½n,
and that
Î²ki(tm+1) âˆ’Î²ki(tm) =

1
âˆš
Î»ki

W(tm+1) âˆ’W(tm), eki

U
if Î»k > 0,
0
else,

2.1. Inï¬nite-dimensional Wiener processes
15
1 â©½i â©½n, are independent since they are pairwise orthogonal in
L2(â„¦, F, P; R) and since W(tm+1) âˆ’W(tm) is a Gaussian random vari-
able. If we take Ai,j âˆˆB(R), 1 â©½i â©½n, 1 â©½j â©½m + 1, then because of the
independence of Ïƒ

W(s)
 s â©½tm

and Ïƒ

W(tm+1) âˆ’W(tm)

we get that
P
	 n
 
i=1

Î²ki(t1) âˆˆAi,1, . . . , Î²ki(tm) âˆˆAi,m,
Î²ki(tm+1) âˆ’Î²ki(tm) âˆˆAi,m+1

=P
	 n
 
i=1
m
 
j=1

Î²ki(tj) âˆˆAi,j

!
"#
$
âˆˆÏƒ

W(s)
 s â©½tm

âˆ©
n
 
i=1

Î²ki(tm+1) âˆ’Î²ki(tm) âˆˆAi,m+1

!
"#
$
âˆˆÏƒ

W(tm+1) âˆ’W(tm)


=P
	 n
 
i=1
m
 
j=1

Î²ki(tj) âˆˆAi,j

Â· P
	 n
 
i=1

Î²ki(tm+1) âˆ’Î²ki(tm) âˆˆAi,m+1

=
 n

i=1
P
	 m
 
j=1

Î²ki(tj) âˆˆAi,j


Â·
	 n

i=1
P

Î²ki(tm+1) âˆ’Î²ki(tm) âˆˆAi,m+1

=
n

i=1
P
	 m
 
j=1

Î²ki(tj) âˆˆAi,j

âˆ©

Î²ki(tm+1) âˆ’Î²ki(tm) âˆˆAi,m+1

and therefore the assertion follows.
2. If we deï¬ne
W(t) :=

kâˆˆN

Î»kÎ²k(t)ek,
t âˆˆ[0, T],
where Î²k, k âˆˆN, are independent real-valued continuous Brownian motions
then it is clear that W(t), t âˆˆ[0, T], is well-deï¬ned in L2(â„¦, F, P; U). Be-
sides, it is obvious that the process W(t), t âˆˆ[0, T], starts at zero and
that
P â—¦

W(t) âˆ’W(s)
âˆ’1 = N

0, (t âˆ’s)Q

,
0 â©½s < t â©½T,
by Proposition 2.1.6. It is also clear that the increments are independent.
Thus
it
remains
to
show
that
the
above
series
converges
in
L2
â„¦, F, P; C([0, T], U)

. To this end we set
W N(t, Ï‰) :=
N

k=1

Î»kÎ²k(t, Ï‰)ek

16
2. Stochastic Integral in Hilbert Spaces
for all (t, Ï‰) âˆˆâ„¦T := [0, T] Ã— â„¦and N âˆˆN. Then W N, N âˆˆN, is P-a.s.
continuous and we have that for M < N
E
	
sup
tâˆˆ[0,T ]
W N(t) âˆ’W M(t)
2
U

= E
	
sup
tâˆˆ[0,T ]
N

k=M+1
Î»kÎ²2
k(t)

â©½
N

k=M+1
Î»kE

sup
tâˆˆ[0,T ]
Î²2
k(t)

â©½c
N

k=M+1
Î»k
where ci = E

suptâˆˆ[0,T ] Î²2
1(t)

< âˆbecause of Doobâ€™s maximal inequal-
ity for real-valued submartingales. As

kâˆˆN
Î»k = tr Q < âˆ, the assertion
follows.
Deï¬nition 2.1.11 (Normal ï¬ltration). A ï¬ltration Ft, t âˆˆ[0, T], on a
probability space (â„¦, F, P) is called normal if:
â€¢ F0 contains all elements A âˆˆF with P(A) = 0 and
â€¢ Ft = Ft+ =
 
s>t
Fs for all t âˆˆ[0, T] .
Deï¬nition 2.1.12 (Q-Wiener process with respect to a ï¬ltration).
A Q-Wiener process W(t), t âˆˆ[0, T], is called a Q-Wiener process with respect
to a ï¬ltration Ft, t âˆˆ[0, T], if:
â€¢ W(t), t âˆˆ[0, T], is adapted to Ft, t âˆˆ[0, T], and
â€¢ W(t) âˆ’W(s) is independent of Fs for all 0 â©½s â©½t â©½T.
In fact it is possible to show that any U-valued Q-Wiener process W(t),
t âˆˆ[0, T], is a Q-Wiener process with respect to a normal ï¬ltration:
We deï¬ne
N :=

A âˆˆF
 P(A) = 0

,
ËœFt := Ïƒ

W(s)
 s â©½t

and
Ëœ
F0
t := Ïƒ( ËœFt âˆªN).
Then it is clear that
Ft :=
 
s>t
Ëœ
F0s ,
t âˆˆ[0, T],
(2.1.3)
is a normal ï¬ltration and we get:
Proposition 2.1.13. Let W(t), t âˆˆ[0, T], be an arbitrary U-valued Q-Wiener
process on a probability space (â„¦, F, P). Then it is a Q-Wiener process with
respect to the normal ï¬ltration Ft, t âˆˆ[0, T], given by (2.1.3).

2.2. Martingales in general Banach spaces
17
Proof. It is clear that W(t), t âˆˆ[0, T], is adapted to Ft, t âˆˆ[0, T]. Hence we
only have to verify that W(t)âˆ’W(s) is independent of Fs, 0 â©½s < t â©½T. But
if we ï¬x 0 â©½s < t â©½T it is clear that W(t)âˆ’W(s) is independent of Ëœ
Fs since
Ïƒ

W(t1), W(t2), . . . , W(tn)

= Ïƒ

W(t1), W(t2) âˆ’W(t1), . . . , W(tn) âˆ’W(tnâˆ’1)

for all 0 â©½t1 < t2 < Â· Â· Â· < tn â©½s. Of course, W(t) âˆ’W(s) is then also
independent of Ëœ
F0s . To prove now that W(t) âˆ’W(s) is independent of Fs it
is enough to show that
P
	
W(t) âˆ’W(s) âˆˆA

âˆ©B

= P

W(t) âˆ’W(s) âˆˆA

Â· P(B)
for any B âˆˆFs and any closed subset A âŠ‚U as E := {A âŠ‚U | A closed}
generates B(U) and is stable under ï¬nite intersections. But we have
P
	
W(t) âˆ’W(s) âˆˆA

âˆ©B

= E
	
1A â—¦

W(t) âˆ’W(s)

Â· 1B

= lim
nâ†’âˆE
%	
1 âˆ’n dist

W(t) âˆ’W(s), A

âˆ¨0
&
1B

= lim
nâ†’âˆlim
mâ†’âˆE
%	
1 âˆ’n dist

W(t) âˆ’W(s + 1
m), A

âˆ¨0
&
1B

= lim
nâ†’âˆlim
mâ†’âˆE
	
1 âˆ’n dist

W(t) âˆ’W(s + 1
m), A

âˆ¨0

Â· P(B)
= P

W(t) âˆ’W(s) âˆˆA

Â· P(B),
since W(t)âˆ’W(s+ 1
m) is independent of ËœF0
s+ 1
m âŠƒFs if m is large enough.
2.2. Martingales in general Banach spaces
Analogously to the real-valued case it is possible to deï¬ne the conditional
expectation of any Bochner integrable random variable with values in an
arbitrary separable Banach space

E, âˆ¥âˆ¥

. This result is formulated in the
following proposition.
Proposition 2.2.1 (Existence of the conditional expectation). Assume
that E is a separable real Banach space. Let X be a Bochner integrable E-
valued random variable deï¬ned on a probability space (â„¦, F, P) and let G be a
Ïƒ-ï¬eld contained in F.

18
2. Stochastic Integral in Hilbert Spaces
Then there exists a unique, up to a set of P-probability zero, Bochner inte-
grable E-valued random variable Z, measurable with respect to G such that

A
X dP =

A
Z dP
for all A âˆˆG.
(2.2.1)
The random variable Z is denoted by E(X | G) and is called the conditional
expectation of X given G. Furthermore,
E(X | G)
 â©½E

âˆ¥Xâˆ¥
 G

.
Proof. (cf. [DPZ92, Proposition 1.10, p. 27]) Let us ï¬rst show uniqueness.
Since E is a separable Banach space, there exist ln âˆˆEâˆ—, n âˆˆN, separating
the points of E. Suppose that Z1, Z2 are Bochner integrable, G-measurable
mappings from â„¦to E such that

A
X dP =

A
Z1 dP =

A
Z2 dP
for all A âˆˆG.
Then for n âˆˆN by Proposition A.2.2

A

ln(Z1) âˆ’ln(Z2)

dP = 0
for all A âˆˆG.
Applying this with A :=

ln(Z1) > ln(Z2)

and A :=

ln(Z1) < ln(Z2)

it
follows that ln(Z1) = ln(Z2) P-a.s., so
â„¦0 :=
 
nâˆˆN

ln(Z1) = ln(Z2)

has P-measure one. Since ln, n âˆˆN, separate the points of E; it follows that
Z1 = Z2 on â„¦0.
To show existence we ï¬rst assume that X is a simple function. So, there
exist x1, . . . , xN âˆˆE and pairwise disjoint sets A1, . . . , AN âˆˆF such that
X =
N

k=1
xk1Ak.
Deï¬ne
Z :=
N

k=1
xkE(1Ak | G).
Then obviously Z is G-measurable and satisï¬es (2.2.1). Furthermore,
âˆ¥Zâˆ¥â©½
N

k=1
âˆ¥xkâˆ¥E(1Ak | G) = E
	 N

k=1
âˆ¥xkâˆ¥1Ak
 G

= E

âˆ¥Xâˆ¥
 G

.
(2.2.2)

2.2. Martingales in general Banach spaces
19
Taking expectation we get
E

âˆ¥Zâˆ¥

â©½E

âˆ¥Xâˆ¥

.
(2.2.3)
For general X take simple functions Xn, n âˆˆN, as in Lemma A.1.4 and
deï¬ne Zn as above with Xn replacing X. Then by (2.2.3) for all n, m âˆˆN
E

âˆ¥Zn âˆ’Zmâˆ¥

â©½E

âˆ¥Xn âˆ’Xmâˆ¥

,
so Z := limnâ†’âˆZn exists in L1(â„¦, F, P; E). Therefore, for all A âˆˆG

A
X dP = lim
nâ†’âˆ

A
Xn dP = lim
nâ†’âˆ

A
Zn dP =

A
Z dP.
Clearly, Z can be chosen G-measurable, since so are the Zn. Furthermore, by
(2.2.2)
E(X | G)
 = âˆ¥Zâˆ¥= lim
nâ†’âˆâˆ¥Znâˆ¥â©½lim
nâ†’âˆE

âˆ¥Xnâˆ¥
 G

= E

âˆ¥Xâˆ¥
 G

,
where the limits are taken in L1(P).
Later we will need the following result:
Proposition 2.2.2. Let (E1, E1) and (E2, E2) be two measurable spaces and
Î¨ : E1Ã—E2 â†’R a bounded measurable function. Let X1 and X2 be two random
variables on (â„¦, F, P) with values in (E1, E1) and (E2, E2) respectively, and
let G âŠ‚F be a ï¬xed Ïƒ-ï¬eld.
Assume that X1 is G-measurable and X2 is independent of G, then
E

Î¨(X1, X2)
 G

= Ë†Î¨(X1)
where
Ë†Î¨(x1) = E

Î¨(x1, X2)

,
x1 âˆˆE1.
Proof. A simple exercise or see [DPZ92, Proposition 1.12, p. 29].
Remark 2.2.3. The previous proposition can be easily extended to the case
where the function Î¨ is not necessarily bounded but nonnegative.
Deï¬nition 2.2.4. Let M(t), t â©¾0, be a stochastic process on (â„¦, F, P) with
values in a separable Banach space E, and let Ft, t â©¾0, be a ï¬ltration on
(â„¦, F, P).
The process M is called an Ft-martingale, if:
â€¢ E

âˆ¥M(t)âˆ¥

< âˆfor all t â©¾0,
â€¢ M(t) is Ft-measurable for all t â©¾0,
â€¢ E

M(t)
 Fs

= M(s) P-a.s. for all 0 â©½s â©½t < âˆ.

20
2. Stochastic Integral in Hilbert Spaces
Remark 2.2.5. Let M be as above such that E(âˆ¥M(t)âˆ¥) < âˆfor all t âˆˆ
[0, T]. Then M is an Ft-martingale if and only if l(M) is an Ft-martingale
for all l âˆˆEâˆ—. In particular, results like optional stopping etc. extend to
E-valued martingales.
There is the following connection to real-valued submartingales.
Proposition 2.2.6. If M(t), t â©¾0, is an E-valued Ft-martingale and p âˆˆ
[1, âˆ), then
M(t)
p, t â©¾0, is a real-valued Ft-submartingale.
Proof. Since E is separable there exist lk âˆˆEâˆ—, k âˆˆN, such that âˆ¥zâˆ¥=
sup lk(z) for all z âˆˆE. Then for s < t
E

âˆ¥Mtâˆ¥
 Fs

â©¾sup
k
E

lk(Mt)
 Fs

= sup
k
lk

E(Mt | Fs)

= sup
k
lk(Ms) = âˆ¥Msâˆ¥.
This proves the assertion for p = 1. Then Jensenâ€™s inequality implies the
assertion for all p âˆˆ[1, âˆ).
Theorem 2.2.7 (Maximal inequality). Let p > 1 and let E be a separable
Banach space.
If M(t), t âˆˆ[0, T], is a right-continuous E-valued Ft-martingale, then

E
	
sup
tâˆˆ[0,T ]
M(t)
p
 1
p
â©½
p
p âˆ’1 sup
tâˆˆ[0,T ]
	
E

âˆ¥M(t)âˆ¥p
 1
p
=
p
p âˆ’1
	
E

âˆ¥M(T)âˆ¥p
 1
p .
Proof. The inequality is a consequence of the previous proposition and Doobâ€™s
maximal inequality for real-valued submartingales.
Remark 2.2.8. We note that in the inequality in Theorem 2.2.7 the ï¬rst
norm is the standard norm on Lp
â„¦, F, P; C([0, T]; E)

, whereas the second
is the standard norm on C

[0, T]; Lp(â„¦, F, P; E)

. So, for right-continuous
E-valued Ft-martingales these two norms are equivalent.
Now we ï¬x 0 < T < âˆand denote by M2
T (E) the space of all E-valued
continuous, square integrable martingales M(t), t âˆˆ[0, T]. This space will play
an important role with regard to the deï¬nition of the stochastic integral. We
will use especially the following fact.

2.3. The deï¬nition of the stochastic integral
21
Proposition 2.2.9. The space M2
T (E) equipped with the norm
âˆ¥Mâˆ¥M2
T := sup
tâˆˆ[0,T ]
	
E

âˆ¥M(t)âˆ¥2
 1
2 =
	
E

âˆ¥M(T)âˆ¥2
 1
2
â©½
	
E

sup
tâˆˆ[0,T ]
âˆ¥M(t)âˆ¥2
 1
2 â©½2 Â· E

âˆ¥M(T)âˆ¥2 1
2 .
is a Banach space.
Proof. By the Rieszâ€“Fischer theorem the space L2
â„¦, F, P; C

[0, T], E

is
complete. So, we only have to show that M2
T is closed. But this is obvious
since even L1(â„¦, F, P; E)-limits of martingales are martingales.
Proposition 2.2.10. Let T > 0 and W(t), t âˆˆ[0, T], be a U-valued Q-Wiener
process with respect to a normal ï¬ltration Ft, t âˆˆ[0, T], on a probability
space (â„¦, F, P). Then W(t), t âˆˆ[0, T], is a continuous square integrable Ft-
martingale, i.e. W âˆˆM2
T (U).
Proof. The continuity is clear by deï¬nition and for each t âˆˆ[0, T] we have that
E

âˆ¥W(t)âˆ¥2
U

= t tr Q < âˆ(see Proposition 2.1.4). Hence let 0 â©½s â©½t â©½T
and A âˆˆFs. Then we get by Proposition A.2.2 that

A
W(t) âˆ’W(s) dP, u

U
=

A

W(t) âˆ’W(s), u

U dP
= P(A)
 
W(t) âˆ’W(s), u

U dP = 0
for
all
u
âˆˆ
U
as
Fs
is
independent
of
W(t) âˆ’W(s)
and
E

âŸ¨W(t) âˆ’W(s), uâŸ©U

= 0 for all u âˆˆU. Therefore,

A
W(t) dP =

A
W(s) +

W(t) âˆ’W(s)

dP
=

A
W(s) dP +

A
W(t) âˆ’W(s) dP
=

A
W(s) dP,
for all A âˆˆFs.
2.3. The deï¬nition of the stochastic integral
For the whole section we ï¬x a positive real number T and a probability space
(â„¦, F, P) and we deï¬ne â„¦T := [0, T] Ã— â„¦and PT := dx âŠ—P where dx is the
Lebesgue measure.
Moreover, let Q âˆˆL(U) be symmetric, nonnegative and with ï¬nite trace
and we consider a Q-Wiener process W(t), t âˆˆ[0, T], with respect to a normal
ï¬ltration Ft, t âˆˆ[0, T].

22
2. Stochastic Integral in Hilbert Spaces
2.3.1. Scheme of the construction of the stochastic
integral
Step 1:
First we consider a certain class E of elementary L(U, H)-valued
processes and deï¬ne the mapping
Int :
E
â†’
M2
T (H) =: M2
T
Î¦
	â†’
' t
0 Î¦(s) dW(s),
t âˆˆ[0, T].
Step 2:
We prove that there is a certain norm on E such that
Int : E â†’M2
T
is an isometry. Since M2
T is a Banach space this implies that Int can be
extended to the abstract completion Â¯E of E. This extension remains isometric
and it is unique.
Step 3:
We give an explicit representation of Â¯E.
Step 4:
We show how the deï¬nition of the stochastic integral can be ext-
ended by localization.
2.3.2. The construction of the stochastic integral
in detail
Step 1:
First we deï¬ne the class E of all elementary processes as follows.
Deï¬nition 2.3.1 (Elementary process). An L = L(U, H)-valued process
Î¦(t), t âˆˆ[0, T], on (â„¦, F, P) with normal ï¬ltration Ft, t âˆˆ[0, T], is said to be
elementary if there exist 0 = t0 < Â· Â· Â· < tk = T, k âˆˆN, such that
Î¦(t) =
kâˆ’1

m=0
Î¦m1]tm,tm+1](t),
t âˆˆ[0, T],
where:
â€¢ Î¦m : â„¦â†’L(U, H) is Ftm-measurable, w.r.t. strong Borel Ïƒ-algebra on
L(U, H), 0 â©½m â©½k âˆ’1,
â€¢ Î¦m takes only a ï¬nite number of values in L(U, H), 1 â©½m â©½k âˆ’1.
If we deï¬ne now
Int(Î¦)(t) :=
 t
0
Î¦(s) dW(s) :=
kâˆ’1

m=0
Î¦m

W(tm+1 âˆ§t)âˆ’W(tm âˆ§t)

, t âˆˆ[0, T],
(this is obviously independent of the representation) for all Î¦ âˆˆE, we have
the following important result.

2.3. The deï¬nition of the stochastic integral
23
Proposition 2.3.2. Let Î¦ âˆˆE. Then the stochastic integral
 t
0
Î¦(s) dW(s),
t âˆˆ[0, T], deï¬ned in the previous way, is a continuous square integrable mar-
tingale with respect to Ft, t âˆˆ[0, T], i.e.
Int : E â†’M2
T .
Proof. Let Î¦ âˆˆE be given by
Î¦(t) =
kâˆ’1

m=0
Î¦m1]tm,tm+1](t),
t âˆˆ[0, T],
as in Deï¬nition 2.3.1. Then it is clear that
t 	â†’
 t
0
Î¦(s) dW(s) =
kâˆ’1

m=0
Î¦m

W(tm+1 âˆ§t) âˆ’W(tm âˆ§t)

is P-a.s. continuous because of the continuity of the Wiener process and the
continuity of Î¦m(Ï‰) : U â†’H, 0 â©½m â©½k âˆ’1, Ï‰ âˆˆâ„¦. In addition, we get for
each summand that
Î¦m

W(tm+1 âˆ§t) âˆ’W(tm âˆ§t)

â©½âˆ¥Î¦mâˆ¥L(U,H)
W(tm+1 âˆ§t) âˆ’W(tm âˆ§t)

U.
Since W(t), t âˆˆ[0, T], is square integrable this implies that
 t
0
Î¦(s) dW(s) is
square integrable for each t âˆˆ[0, T].
To prove the martingale property we take 0 â©½s â©½t â©½T and a set A from
Fs. If

Î¦m(Ï‰)
 Ï‰ âˆˆâ„¦

:= {Lm
1 , . . . , Lm
km} we obtain by Proposition A.2.2
and the martingale property of the Wiener process (more precisely using

24
2. Stochastic Integral in Hilbert Spaces
optional stopping) that

A
kâˆ’1

m=0
Î¦m

W(tm+1 âˆ§t) âˆ’W(tm âˆ§t)

dP
=

0â©½mâ©½kâˆ’1,
tm+1<s

A
Î¦m

W(tm+1 âˆ§s) âˆ’W(tm âˆ§s)

dP
+

0â©½mâ©½kâˆ’1,
sâ©½tm+1
km

j=1

Aâˆ©{Î¦m=Lm
j }
Lm
j

W(tm+1 âˆ§t) âˆ’W(tm âˆ§t)

dP
=

0â©½mâ©½kâˆ’1,
tm+1<s

A
Î¦m

W(tm+1 âˆ§s) âˆ’W(tm âˆ§s)

dP
+

0â©½mâ©½kâˆ’1,
sâ©½tm+1
km

j=1
Lm
j

Aâˆ©{Î¦m=Lm
j }
!
"#
$
âˆˆFsâˆ¨tm
W(tm+1 âˆ§t) âˆ’W(tm âˆ§t) dP
=

0â©½mâ©½kâˆ’1,
tm+1<s

A
Î¦m

W(tm+1 âˆ§s) âˆ’W(tm âˆ§s)

dP
+

0â©½mâ©½kâˆ’1,
tm<sâ©½tm+1
km

j=1
Lm
j

Aâˆ©{Î¦m=Lm
j }
W(tm+1 âˆ§s) âˆ’W(tm âˆ§s) dP
=

A
kâˆ’1

m=0
Î¦m

W(tm+1 âˆ§s) âˆ’W(tm âˆ§s)

dP.
Step 2:
To verify the assertion that there is a norm on E such that Int :
E â†’M2
T is an isometry, we have to introduce the following notion.
Deï¬nition 2.3.3 (Hilbertâ€“Schmidt operator). Let ek, k âˆˆN, be an or-
thonormal basis of U. An operator A âˆˆL(U, H) is called Hilbert-Schmidt
if

kâˆˆN
âŸ¨Aek, AekâŸ©< âˆ.
In Appendix B we take a close look at this notion. So here we only sum-
marize the results which are important for the construction of the stochastic
integral.
The deï¬nition of a Hilbertâ€“Schmidt operator and the number
âˆ¥Aâˆ¥L2 :=
	
kâˆˆN
âˆ¥Aekâˆ¥2
 1
2

2.3. The deï¬nition of the stochastic integral
25
are independent of the choice of the basis (see Remark B.0.6(i)). Moreover,
the space L2(U, H) of all Hilbertâ€“Schmidt operators from U to H equipped
with the inner product
âŸ¨A, BâŸ©L2 :=

kâˆˆN
âŸ¨Aek, BekâŸ©
is a separable Hilbert space (see Proposition B.0.7). Later, we will use the
fact that âˆ¥Aâˆ¥L2(U,H) = âˆ¥Aâˆ—âˆ¥L2(H,U), where Aâˆ—is the adjoint operator of A
(see Remark B.0.6(i)). Furthermore, compositions of Hilbertâ€“Schmidt with
bounded linear operators are again Hilbertâ€“Schmidt.
Besides we recall the following fact.
Proposition 2.3.4. If Q âˆˆL(U) is nonnegative and symmetric then there
exists exactly one element Q
1
2 âˆˆL(U) nonnegative and symmetric such that
Q
1
2 â—¦Q
1
2 = Q.
If, in addition, tr Q < âˆwe have that Q
1
2 âˆˆL2(U) where âˆ¥Q
1
2 âˆ¥2
L2 = tr Q
and of course L â—¦Q
1
2 âˆˆL2(U, H) for all L âˆˆL(U, H).
Proof.
[RS72, Theorem VI.9, p. 196]
After these preparations we simply calculate the M2
T -norm of
 t
0
Î¦(s) dW(s), t âˆˆ[0, T],
and get the following result.
Proposition 2.3.5. If Î¦ = kâˆ’1
m=0 Î¦m1]tm,tm+1] is an elementary L(U, H)-
valued process then

 Â·
0
Î¦(s) dW(s)

2
M2
T
= E
 T
0
Î¦(s)â—¦Q
1
2 2
L2 ds

=: âˆ¥Î¦âˆ¥2
T (â€œItË†o-isometryâ€).
Proof. If we set âˆ†m := W(tm+1) âˆ’W(tm) then we get that

 Â·
0
Î¦(s) dW(s)

2
M2
T
= E

 T
0
Î¦(s) dW(s)

2
H

= E

kâˆ’1

m=0
Î¦mâˆ†m

2
H

= E
	 kâˆ’1

m=0
âˆ¥Î¦mâˆ†mâˆ¥2
H

+ 2E
	

0â©½m<nâ©½kâˆ’1
âŸ¨Î¦mâˆ†m, Î¦nâˆ†nâŸ©H

.
Claim 1:
E
	 kâˆ’1

m=0
âˆ¥Î¦mâˆ†mâˆ¥2
H

=
kâˆ’1

m=0
(tm+1 âˆ’tm)E

âˆ¥Î¦m â—¦Q
1
2 âˆ¥2
L2

=
 T
0
E
	Î¦(s) â—¦Q
1
2 2
L2

ds.

26
2. Stochastic Integral in Hilbert Spaces
To prove this we take an orthonormal basis fk, k âˆˆN, of H and get by the
Parseval identity and Leviâ€™s monotone convergence theorem that
E

âˆ¥Î¦mâˆ†mâˆ¥2
H

=

lâˆˆN
E

âŸ¨Î¦mâˆ†m, flâŸ©2
H

=

lâˆˆN
E
	
E

âŸ¨âˆ†m, Î¦âˆ—
mflâŸ©2
U
 Ftm

.
Taking an orthonormal basis ek, k âˆˆN, of U we obtain that
Î¦âˆ—
mfl =

kâˆˆN
âŸ¨fl, Î¦mekâŸ©Hek.
Since âŸ¨fl, Î¦mekâŸ©H is Ftm-measurable, this implies that Î¦âˆ—
mfl is Ftm-measurable
by Proposition A.1.3. Using the fact that Ïƒ(âˆ†m) is independent of Ftm we
obtain by Lemma 2.2.2 that for P-a.e. Ï‰ âˆˆâ„¦
E

âŸ¨âˆ†m, Î¦âˆ—
mflâŸ©2
U
 Ftm

(Ï‰) = E
	
âˆ†m, Î¦âˆ—
m(Ï‰)fl
2
U

= (tm+1 âˆ’tm)

Q

Î¦âˆ—
m(Ï‰)fl

, Î¦âˆ—
m(Ï‰)fl

U,
since E

âŸ¨âˆ†m, uâŸ©2
U

= (tm+1 âˆ’tm)âŸ¨Qu, uâŸ©U for all u âˆˆU. Thus, the symmetry
of Q
1
2 ï¬nally implies that
E

âˆ¥Î¦mâˆ†mâˆ¥2
H

=

lâˆˆN
E
	
E

âŸ¨âˆ†m, Î¦âˆ—
mflâŸ©2
U
 Ftm

= (tm+1 âˆ’tm)

lâˆˆN
E

âŸ¨QÎ¦âˆ—
mfl, Î¦âˆ—
mflâŸ©U

= (tm+1 âˆ’tm)

lâˆˆN
E
	Q
1
2 Î¦âˆ—
mfl
2
U

= (tm+1 âˆ’tm)E


Î¦m â—¦Q
1
2 âˆ—
2
L2(H,U)

= (tm+1 âˆ’tm)E
	Î¦m â—¦Q
1
2 2
L2(U,H)

.
Hence the ï¬rst assertion is proved and it only remains to verify the following
claim.
Claim 2:
E

âŸ¨Î¦mâˆ†m, Î¦nâˆ†nâŸ©H

= 0 ,
0 â©½m < n â©½k âˆ’1.
But this can be proved in a similar way to Claim 1:
E

âŸ¨Î¦mâˆ†m, Î¦nâˆ†nâŸ©H

= E
	
E

âŸ¨Î¦âˆ—
nÎ¦mâˆ†m, âˆ†nâŸ©U
 Ftn

=

E
	
Î¦âˆ—
n(Ï‰)Î¦m(Ï‰)âˆ†m(Ï‰), âˆ†n

U

P(dÏ‰) = 0,

2.3. The deï¬nition of the stochastic integral
27
since E

âŸ¨u, âˆ†nâŸ©U

= 0 for all u âˆˆU (see Proposition 2.2.2). Hence the asser-
tion follows.
Hence the right norm on E has been identiï¬ed. But strictly speaking âˆ¥âˆ¥T
is only a seminorm on E. Therefore, we have to consider equivalence classes of
elementary processes with respect to âˆ¥âˆ¥T to get a norm on E. For simplicity
we will not change the notation but stress the following fact.
Remark 2.3.6. If two elementary processes Î¦ and ËœÎ¦ belong to one equiva-
lence class with respect to âˆ¥âˆ¥T it does not follow that they are equal PT -a.e.
because their values only have to correspond on Q
1
2 (U) PT -a.e.
Thus we ï¬nally have shown that
Int :

E, âˆ¥âˆ¥T

â†’

M2
T , âˆ¥âˆ¥M2
T

is an isometric transformation. Since E is dense in the abstract completion Â¯E
of E with respect to âˆ¥âˆ¥T it is clear that there is a unique isometric extension
of Int to Â¯E.
Step 3:
To give an explicit representation of Â¯E it is useful, at this moment,
to introduce the subspace U0 := Q
1
2 (U) with the inner product given by
âŸ¨u0, v0âŸ©0 :=

Qâˆ’1
2 u0, Qâˆ’1
2 v0

U,
u0, v0 âˆˆU0, where Qâˆ’1
2 is the pseudo inverse of Q
1
2 in the case that Q is not
one-to-one. Then we get by Proposition C.0.3(i) that (U0, âŸ¨, âŸ©0) is again a
separable Hilbert space.
The separable Hilbert space L2(U0, H) is called L0
2. By Proposition C.0.3(ii)
we know that Q
1
2 gk, k âˆˆN, is an orthonormal basis of

U0, âŸ¨, âŸ©0

if gk, k âˆˆN,
is an orthonormal basis of

Ker Q
1
2 âŠ¥. This basis can be supplemented to a
basis of U by elements of Ker Q
1
2 . Thus we obtain that
âˆ¥Lâˆ¥L0
2 =
L â—¦Q
1
2 
L2
for each L âˆˆL0
2.
Deï¬ne L(U, H)0 :=

T |U0
 T âˆˆL(U, H)

. Since Q
1
2 âˆˆL2(U) it is clear
that L(U, H)0 âŠ‚L0
2 and that the âˆ¥âˆ¥T -norm of Î¦ âˆˆE can be written in the
following way:
âˆ¥Î¦âˆ¥T =

E
 T
0
âˆ¥Î¦(s)âˆ¥2
L0
2 ds
 1
2
Besides we need the following Ïƒ-ï¬eld:
PT := Ïƒ
	
]s, t] Ã— Fs
 0 â©½s < t â©½T, Fs âˆˆFs

âˆª

{0} Ã— F0
 F0 âˆˆF0

= Ïƒ

Y : â„¦T â†’R
 Y is left-continuous and adapted to
Ft, t âˆˆ[0, T]

.

28
2. Stochastic Integral in Hilbert Spaces
Let ËœH be an arbitrary separable Hilbert space. If Y : â„¦T â†’ËœH is PT /B( ËœH)-
measurable it is called ( ËœH-)predictable.
If, for example, the process Y itself is continuous and adapted to Ft,
t âˆˆ[0, T], then it is predictable.
So, we are now able to characterize Â¯E.
Claim:
There is an explicit representation of Â¯E and it is given by
N 2
W (0, T; H) :=

Î¦ : [0, T] Ã— â„¦â†’L0
2
 Î¦ is predictable and âˆ¥Î¦âˆ¥T < âˆ

= L2 
[0, T] Ã— â„¦, PT , dt âŠ—P; L0
2

.
For simplicity we also write N 2
W (0, T) or N 2
W instead of N 2
W (0, T; H).
To prove this claim we ï¬rst notice the following facts:
1. Since L(U, H)0 âŠ‚L0
2 and since any Î¦ âˆˆE is L0
2-predictable by construction
we have that E âŠ‚N 2
W .
2. Because of the completeness of L0
2 we get by Appendix A that
N 2
W = L2(â„¦T , PT , PT ; L0
2)
is also complete.
Therefore N 2
W is at least a candidate for a representation of Â¯E. Thus there
only remains to show that E is a dense subset of N 2
W . But this is formulated
in Proposition 2.3.8 below, which can be proved with the help of the following
lemma.
Lemma 2.3.7. There is an orthonormal basis of L0
2 consisting of elements
of L(U, H)0. This implies especially that L(U, H)0 is a dense subset of L0
2.
Proof. Since Q is symmetric, nonnegative and tr Q < âˆwe know by
Lemma 2.1.5 that there exists an orthonormal basis ek, k âˆˆN, of U such
that Qek = Î»kek, Î»k â©¾0, k âˆˆN. In this case Q
1
2 ek = âˆšÎ»kek, k âˆˆN with
Î»k > 0, is an orthonormal basis of U0 (see Proposition C.0.3(ii)).
If fk, k âˆˆN, is an orthonormal basis of H then by Proposition B.0.7 we
know that
fj âŠ—

Î»kek = fjâŸ¨

Î»kek, Â·âŸ©U0 = 1
Î»k
fjâŸ¨ek, Â·âŸ©U,
j, k âˆˆN, Î»k > 0,
form an orthonormal basis of L2
0 consisting of operators in L(U, H). But, of
course,
span

1
âˆšÎ»k
fj âŠ—ek
 j, k âˆˆN with Î»k > 0

= L0
2.

2.3. The deï¬nition of the stochastic integral
29
Proposition 2.3.8. If Î¦ is a L0
2-predictable process such that âˆ¥Î¦âˆ¥T < âˆthen
there exists a sequence Î¦n, n âˆˆN, of L(U, H)0-valued elementary processes
such that
âˆ¥Î¦ âˆ’Î¦nâˆ¥T âˆ’â†’0
as n â†’âˆ.
Proof. Step 1: If Î¦ âˆˆN 2
W there exists a sequence of simple random variables
Î¦n = Mn
k=1 Ln
k1An
k , An
k âˆˆPT and Ln
k âˆˆL0
2, n âˆˆN, such that
âˆ¥Î¦ âˆ’Î¦nâˆ¥T âˆ’â†’0
as n â†’âˆ.
As L0
2 is a Hilbert space this is a simple consequence of Lemma A.1.4 and
Lebesgueâ€™s dominated convergence theorem.
Thus the assertion is reduced to the case that Î¦ = L1A where L âˆˆL0
2 and
A âˆˆPT .
Step 2: Let A âˆˆPT and L âˆˆL0
2. Then there exists a sequence Ln, n âˆˆN, in
L(U, H)0 such that
âˆ¥L1A âˆ’Ln1Aâˆ¥T âˆ’â†’0
as n â†’âˆ.
This result is obvious by Lemma 2.3.7 and thus now we only have to consider
the case that Î¦ = L1A, L âˆˆL(U, H)0 and A âˆˆPT .
Step 3:
If Î¦ = L1A, L âˆˆL(U, H)0, A âˆˆPT , then there is a sequence Î¦n,
n âˆˆN, of elementary L(U, H)0-valued processes in the sense of Deï¬nition 2.3.1
such that
âˆ¥L1A âˆ’Î¦nâˆ¥T âˆ’â†’0
as n âˆ’â†’âˆ.
To show this it is suï¬ƒcient to prove that for any Îµ > 0 there is a ï¬nite union
Î› =
N

n=1
An of pairwise disjoint predictable rectangles
An âˆˆ

]s, t] Ã— Fs
 0 â©½s < t â©½T, Fs âˆˆFs

âˆª

{0} Ã— F0
 F0 âˆˆF0

=: A
such that
PT

(A \ Î›) âˆª(Î› \ A)

< Îµ.
For then we get that N
n=1 L1An diï¬€ers from an elementary process by a
function of type 1{0}Ã—F0 with F0 âˆˆF0, which has âˆ¥Â· âˆ¥T -norm zero and
L1A âˆ’
N

n=1
L1An

2
T = E
 T
0
L
	
1A âˆ’
N

n=1
1An


2
L0
2
ds

â©½Îµâˆ¥Lâˆ¥2
L0
2.
Hence we deï¬ne
K :=

iâˆˆI
Ai
 I is ï¬nite and Ai âˆˆA, i âˆˆI

.
Then K is an algebra and any element in K can be written as a ï¬nite disjoint
union of elements in A. Now let G be the family of all A âˆˆPT which can
be approximated by elements of K in the above sense. Then G is a Dynkin
system and therefore PT = Ïƒ(K) = D(K) âŠ‚G as K âŠ‚G.

30
2. Stochastic Integral in Hilbert Spaces
Step 4:
Finally the so-called localization procedure provides the possibility
to extend the deï¬nition of the stochastic integral even to the linear space
NW (0, T; H) :=

Î¦ : â„¦T â†’L0
2
 Î¦ is predictable with
P
 T
0
âˆ¥Î¦(s)âˆ¥2
L0
2 ds < âˆ

= 1
(
.
For simplicity we also write NW (0, T) or NW instead of NW (0, T; H) and NW
is called the class of stochastically integrable processes on [0, T].
The extension is done in the following way:
For Î¦ âˆˆNW we deï¬ne
Ï„n := inf

t âˆˆ[0, T]

 t
0
âˆ¥Î¦(s)âˆ¥2
L0
2 ds > n

âˆ§T.
(2.3.1)
Then by the right-continuity of the ï¬ltration Ft, t âˆˆ[0, T], we get that
{Ï„n â©½t} =
 
mâˆˆN

Ï„n < t + 1
m

=
 
mâˆˆN

qâˆˆ[0,t+ 1
m [âˆ©Q
 q
0
âˆ¥Î¦(s)âˆ¥2
L0
2 ds > n

!
"#
$
âˆˆFq by the real Fubini theorem
!
"#
$
âˆˆFt+ 1
m and decreasing in m
âˆˆFt.
Therefore Ï„n, n âˆˆN, is an increasing sequence of stopping times with respect
to Ft, t âˆˆ[0, T], such that
E
 T
0
âˆ¥1]0,Ï„n](s)Î¦(s)âˆ¥2
L0
2 ds

â©½n < âˆ.
In addition, the processes 1]0,Ï„n]Î¦, n âˆˆN, are still L0
2-predictable since 1]0,Ï„n]
is left-continuous and (Ft)-adapted or since
]0, Ï„n] :=

(s, Ï‰) âˆˆâ„¦T
 0 < s â©½Ï„n(Ï‰)

=
	
(s, Ï‰) âˆˆâ„¦T
 Ï„n(Ï‰) < s â©½T

âˆª{0} Ã— â„¦

c
=
	 
qâˆˆQ

]q, T] Ã— {Ï„n â©½q}
!
"#
$
âˆˆFq

!
"#
$
âˆˆPT
âˆª{0} Ã— â„¦

c
âˆˆPT .
Thus we get that the stochastic integrals
 t
0
1]0,Ï„n](s)Î¦(s) dW(s),
t âˆˆ[0, T],

2.3. The deï¬nition of the stochastic integral
31
are well-deï¬ned for all n âˆˆN. For arbitrary t âˆˆ[0, T] we set
 t
0
Î¦(s) dW(s) :=
 t
0
1]0,Ï„n](s)Î¦(s) dW(s),
(2.3.2)
where n is an arbitrary natural number such that Ï„n â©¾t. (Note that the
sequence Ï„n, n âˆˆN, even reaches T P-a.s., in the sense that for P-a.e. Ï‰ âˆˆâ„¦
there exists n(Ï‰) âˆˆN such that Ï„n(Ï‰) = T for all n â©¾n(Ï‰).)
To show that this deï¬nition is consistent we have to prove that for arbitrary
natural numbers m < n and t âˆˆ[0, T]
 t
0
1]0,Ï„m](s)Î¦(s) dW(s) =
 t
0
1]0,Ï„n](s)Î¦(s) dW(s)
P-a.s.
on {Ï„m â©¾t} âŠ‚{Ï„n â©¾t}. This result follows from the following lemma, which
implies that the process in (2.3.2) is a continuous H-valued local martingale.
Lemma 2.3.9. Assume that Î¦ âˆˆN 2
W and that Ï„ is an Ft-stopping time such
that P(Ï„ â©½T) = 1. Then there exists a P-null set N âˆˆF independent of
t âˆˆ[0, T] such that
 t
0
1]0,Ï„](s)Î¦(s) dW(s) = Int

1]0,Ï„]Î¦

(t) = Int(Î¦)(Ï„ âˆ§t)
=
 Ï„âˆ§t
0
Î¦(s) dW(s)
on N c for all t âˆˆ[0, T].
Proof. Since both integrals which appear in the equation are P-a.s. continuous
we only have to prove that they are equal P-a.s. at any ï¬xed time t âˆˆ[0, T].
Step 1: We ï¬rst consider the case that Î¦ âˆˆE and that Ï„ is a simple stopping
time which means that it takes only a ï¬nite number of values.
Let 0 = t0 < t1 < Â· Â· Â· < tk â©½T, k âˆˆN, and
Î¦ =
kâˆ’1

m=0
Î¦m1]tm,tm+1]
where Î¦m : â„¦â†’L(U, H) is Ftm-measurable and only takes a ï¬nite number
of values for all 0 â©½m â©½k âˆ’1.
If
Ï„
is
a
simple
stopping
time
there
exists
n
âˆˆ
N
such
that
Ï„(â„¦) = {a0, . . . , an} and
Ï„ =
n

j=0
aj1Aj
where 0 â©½aj < aj+1 â©½T and Aj = {Ï„ = aj} âˆˆFaj. In this way we get that

32
2. Stochastic Integral in Hilbert Spaces
1]Ï„,T ]Î¦ is an elementary process since
1]Ï„,T ](s)Î¦(s) =
kâˆ’1

m=0
Î¦m1]tm,tm+1]âˆ©]Ï„,T ](s)
=
kâˆ’1

m=0
n

j=0
1AjÎ¦m1]tm,tm+1]âˆ©]aj,T ](s)
=
kâˆ’1

m=0
n

j=0
1AjÎ¦m
! "# $
Ftmâˆ¨aj -measurable
1]tmâˆ¨aj,tm+1âˆ¨aj](s)
and concerning the integral we are interested in, we obtain that
 t
0
1]0,Ï„](s)Î¦(s) dW(s) =
 t
0
Î¦(s) dW(s) âˆ’
 t
0
1]Ï„,T ](s)Î¦(s) dW(s)
=
kâˆ’1

m=0
Î¦m

W(tm+1 âˆ§t) âˆ’W(tm âˆ§t)

âˆ’
kâˆ’1

m=0
n

j=0
1AjÎ¦m
	
W

(tm+1 âˆ¨aj) âˆ§t

âˆ’W

(tm âˆ¨aj) âˆ§t

=
kâˆ’1

m=0
Î¦m

W(tm+1 âˆ§t) âˆ’W(tm âˆ§t)

âˆ’
kâˆ’1

m=0
n

j=0
1AjÎ¦m
	
W

(tm+1 âˆ¨Ï„) âˆ§t

âˆ’W

(tm âˆ¨Ï„) âˆ§t

=
kâˆ’1

m=0
Î¦m

W(tm+1 âˆ§t) âˆ’W(tm âˆ§t)

âˆ’
kâˆ’1

m=0
Î¦m
	
W

(tm+1 âˆ¨Ï„) âˆ§t

âˆ’W

(tm âˆ¨Ï„) âˆ§t

=
kâˆ’1

m=0
Î¦m
	
W(tm+1 âˆ§t) âˆ’W(tm âˆ§t)
âˆ’W

(tm+1 âˆ¨Ï„) âˆ§t

âˆ’W

(tm âˆ¨Ï„) âˆ§t

=
kâˆ’1

m=0
Î¦m
	
W(tm+1 âˆ§Ï„ âˆ§t) âˆ’W(tm âˆ§Ï„ âˆ§t)

=
 tâˆ§Ï„
0
Î¦(s) dW(s).
Step 2: Now we consider the case that Î¦ is still an elementary process while
Ï„ is an arbitrary stopping time with P(Ï„ â©½T) = 1.

2.3. The deï¬nition of the stochastic integral
33
Then there exists a sequence
Ï„n =
2nâˆ’1

k=0
T(k + 1)2âˆ’n1]T k2âˆ’n,T (k+1)2âˆ’n] â—¦Ï„,
n âˆˆN,
of simple stopping times such that Ï„n â†“Ï„ as n â†’âˆand because of the
continuity of the stochastic integral we get that
 Ï„nâˆ§t
0
Î¦(s) dW(s)
nâ†’âˆ
âˆ’âˆ’âˆ’âˆ’â†’
 Ï„âˆ§t
0
Î¦(s) dW(s)
P-a.s.
Besides, we obtain (even for non-elementary processes Î¦) that
1]0,Ï„n]Î¦ âˆ’1]0,Ï„]Î¦
2
T = E
 T
0
1]Ï„,Ï„n](s)âˆ¥Î¦(s)âˆ¥2
L0
2 ds

nâ†’âˆ
âˆ’âˆ’âˆ’âˆ’â†’0,
which by the deï¬nition of the integral implies that
E

 t
0
1]0,Ï„n](s)Î¦(s) dW(s) âˆ’
 t
0
1]0,Ï„](s)Î¦(s) dW(s)

2
nâ†’âˆ
âˆ’âˆ’âˆ’âˆ’â†’0
for all t âˆˆ[0, T]. As by Step 1
 t
0
1]0,Ï„n](s)Î¦(s) dW(s) =
 Ï„nâˆ§t
0
Î¦(s) dW(s),
n âˆˆN, t âˆˆ[0, T],
the assertion follows.
Step 3: Finally we generalize the statement to arbitrary Î¦ âˆˆN 2
W (0, T):
If Î¦ âˆˆN 2
W (0, T) then there exists a sequence of elementary processes Î¦n,
n âˆˆN, such that
âˆ¥Î¦n âˆ’Î¦âˆ¥T
nâ†’âˆ
âˆ’âˆ’âˆ’âˆ’â†’0 .
By the deï¬nition of the stochastic integral this means that
 Â·
0
Î¦n(s) dW(s)
nâ†’âˆ
âˆ’âˆ’âˆ’âˆ’â†’
 Â·
0
Î¦(s) dW(s)
in M2
T .
Hence it follows that there is a subsequence nk, k âˆˆN, and a P-null set N âˆˆF
independent of t âˆˆ[0, T] such that
 t
0
Î¦nk(s) dW(s)
kâ†’âˆ
âˆ’âˆ’âˆ’âˆ’â†’
 t
0
Î¦(s) dW(s)
on N c
for all t âˆˆ[0, T] and therefore we get for all t âˆˆ[0, T] that
 Ï„âˆ§t
0
Î¦nk(s) dW(s)
kâ†’âˆ
âˆ’âˆ’âˆ’âˆ’â†’
 Ï„âˆ§t
0
Î¦(s) dW(s)
P-a.s.

34
2. Stochastic Integral in Hilbert Spaces
In addition, it is clear that
âˆ¥1]0,Ï„]Î¦n âˆ’1]0,Ï„]Î¦âˆ¥T âˆ’â†’
nâ†’âˆ0
which implies that for all t âˆˆ[0, T]
E

 t
0
1]0,Ï„](s)Î¦n(s) dW(s) âˆ’
 t
0
1]0,Ï„](s)Î¦(s) dW(s)

2
nâ†’âˆ
âˆ’âˆ’âˆ’âˆ’â†’0.
As by Step 2
 t
0
1]0,Ï„](s)Î¦nk(s) dW(s) =
 Ï„âˆ§t
0
Î¦nk(s) dW(s)
P-a.s.
for all k âˆˆN the assertion follows.
Therefore, for m < n on {Ï„m â©¾t} âŠ‚{Ï„n â©¾t}
 t
0
1]0,Ï„n](s)Î¦(s) dW(s) =
 Ï„mâˆ§t
0
1]0,Ï„n](s)Î¦(s) dW(s)
=
 t
0
1]0,Ï„m](s)1]0,Ï„n](s)Î¦(s) dW(s) =
 t
0
1]0,Ï„m](s)Î¦(s) dW(s)
P-a.s.,
where we used Lemma 2.3.9 for the second equality. Hence the deï¬nition is
consistent.
Remark 2.3.10. In fact it is easy to see that the deï¬nition of the stochastic
integral does not depend on the choice of Ï„n, n âˆˆN. If Ïƒn, n âˆˆN, is another
sequence of stopping times such that Ïƒn â†‘T as n â†’âˆand 1]0,Ïƒn]Î¦ âˆˆN 2
W
for all n âˆˆN we also get that
 t
0
Î¦(s) dW(s) = lim
nâ†’âˆ
 t
0
1]0,Ïƒn](s)Î¦(s) dW(s)
P-a.s. for all t âˆˆ[0, T].
Proof. Let t âˆˆ[0, T]. Then we get that on the set {Ï„m â©¾t}
 t
0
Î¦(s) dW(s) =
 t
0
1]0,Ï„m](s)Î¦(s) dW(s)
= lim
nâ†’âˆ
 tâˆ§Ïƒn
0
1]0,Ï„m](s)Î¦(s) dW(s)
= lim
nâ†’âˆ
 tâˆ§Ï„m
0
1]0,Ïƒn](s)Î¦(s) dW(s)
= lim
nâ†’âˆ
 t
0
1]0,Ïƒn](s)Î¦(s) dW(s)
P-a.s..

2.4. Properties of the stochastic integral
35
2.4. Properties of the stochastic integral
Let T be a positive real number and W(t), t âˆˆ[0, T], a Q-Wiener process as
described at the beginning of the previous section.
Lemma
2.4.1. Let Î¦ be a L0
2-valued stochastically integrable process,
( ËœH, âˆ¥âˆ¥Ëœ
H) a further separable Hilbert space and L âˆˆL(H, ËœH).
Then the process L

Î¦(t)

, t âˆˆ[0, T], is an element of NW (0, T; ËœH) and
L
 T
0
Î¦(t) dW(t)

=
 T
0
L

Î¦(t)

dW(t)
P-a.s.
Proof. Since Î¦ is a stochastically integrable process and
L

Î¦(t)

L2(U0, Ëœ
H) â©½âˆ¥Lâˆ¥L(H, Ëœ
H)âˆ¥Î¦(t)âˆ¥L0
2,
it is obvious that L

Î¦(t)

, t âˆˆ[0, T], is L2(U0, ËœH)-predictable and
P
 T
0
L

Î¦(t)

2
L2(U0, Ëœ
H) dt < âˆ

= 1.
Step 1:
As the ï¬rst step we consider the case that Î¦ is an elementary
process, i.e.
Î¦(t) =
kâˆ’1

m=0
Î¦m1]tm,tm+1](t),
t âˆˆ[0, T],
where 0 = t0 < t1 < Â· Â· Â· < tk = T, Î¦m : â„¦â†’L(U, H) Ftm-measurable with
Î¦m(â„¦)
 < âˆfor 0 â©½m â©½k. Then
L
 T
0
Î¦(t) dW(t)

= L
	 kâˆ’1

m=0
Î¦m

W(tm+1) âˆ’W(tm)

=
kâˆ’1

m=0
L
	
Î¦m

W(tm+1) âˆ’W(tm)

=
 T
0
L

Î¦(t)

dW(t).
Step 2:
Now let Î¦ âˆˆN 2
W (0, T). Then there exists a sequence Î¦n, n âˆˆN, of
elementary processes with values in L(U, H)0 such that
âˆ¥Î¦n âˆ’Î¦âˆ¥T =

E
 T
0
âˆ¥Î¦n(t) âˆ’Î¦(t)âˆ¥2
L0
2 dt
 1
2
nâ†’âˆ
âˆ’âˆ’âˆ’âˆ’â†’0.
Then L(Î¦n), n âˆˆN, is a sequence of elementary processes with values in
L(U, ËœH)0 and
L(Î¦n) âˆ’L(Î¦)

T â©½âˆ¥Lâˆ¥L(H, Ëœ
H)âˆ¥Î¦n âˆ’Î¦âˆ¥T
nâ†’âˆ
âˆ’âˆ’âˆ’âˆ’â†’0.

36
2. Stochastic Integral in Hilbert Spaces
By the deï¬nition of the stochastic integral, Step 1 and the continuity of L we
get that there is a subsequence nk, k âˆˆN, such that
 T
0
L

Î¦(t)

dW(t) = lim
kâ†’âˆ
 T
0
L

Î¦nk(t)

dW(t)
= lim
kâ†’âˆL
 T
0
Î¦nk(t) dW(t)

= L

lim
kâ†’âˆ
 T
0
Î¦nk(t) dW(t)

= L
 T
0
Î¦(t) dW(t)

P-a.s.
Step 3:
Finally let Î¦ âˆˆNW (0, T).
Let Ï„n, n âˆˆN, be a sequence of stopping times such that Ï„n â†‘T as n â†’âˆ
and 1]0,Ï„n]Î¦ âˆˆN 2
W (0, T, H). Then 1]0,Ï„n]L(Î¦) âˆˆN 2
W (0, T, ËœH) for all n âˆˆN and
we obtain by Remark 2.3.10 and Step 2 (selecting a subsequence if necessary)
 T
0
L

Î¦(t)

dW(t) = lim
nâ†’âˆ
 T
0
1]0,Ï„n](t)L

Î¦(t)

dW(t)
= lim
nâ†’âˆL
 T
0
1]0,Ï„n](t)Î¦(t) dW(t)

= L

lim
nâ†’âˆ
 T
0
1]0,Ï„n](t)Î¦(t) dW(t)

= L
 T
0
Î¦(t) dW(t)

P-a.s.
Lemma 2.4.2. Let Î¦ âˆˆNW (0, T) and f an (Ft)-adapted continuous H-
valued process. Set
 T
0

f(t), Î¦(t) dW(t)

:=
 T
0
ËœÎ¦f(t) dW(t)
(2.4.1)
with
ËœÎ¦f(t)(u) :=

f(t), Î¦(t)u

, u âˆˆU0.
Then the stochastic integral in (2.4.1) is well-deï¬ned as a continuous R-valued
stochastic process. More precisely, ËœÎ¦f is a PT /B(L2(U0, R))-measurable map
from [0, T] Ã— â„¦to L2(U0, R),
âˆ¥ËœÎ¦f(t, Ï‰)âˆ¥L2(U0,R) = âˆ¥Î¦âˆ—(t, Ï‰)f(t, Ï‰)âˆ¥U0
for all (t, Ï‰) âˆˆ[0, T] Ã— â„¦and
 T
0
âˆ¥ËœÎ¦f(t)âˆ¥2
L2(U0,R) dt â©½sup
tâˆˆ[0,T ]
âˆ¥f(t)âˆ¥
 T
0
âˆ¥Î¦(t)âˆ¥2
L0
2 dt < âˆ
P-a.e..

2.4. Properties of the stochastic integral
37
Proof. Since f is continuous, ËœÎ¦f is clearly predictable. Let ek, k âˆˆN, be an
orthonormal basis of U0. Then for all (t, Ï‰) âˆˆ[0, T] Ã— â„¦
âˆ¥ËœÎ¦f(t, Ï‰)âˆ¥2
L2(U0,R) =
âˆ

k=1
âŸ¨f(t, Ï‰), Î¦(t, Ï‰)ekâŸ©2
=
âˆ

k=1
âŸ¨Î¦âˆ—(t, Ï‰)f(t, Ï‰), ekâŸ©2
U0
= âˆ¥Î¦âˆ—(t, Ï‰)f(t, Ï‰)âˆ¥2
U0
â©½âˆ¥Î¦âˆ—(t, Ï‰)âˆ¥2
L(H,U0)âˆ¥f(t, Ï‰)âˆ¥2
H
â©½âˆ¥Î¦âˆ—(t, Ï‰)âˆ¥2
L2(H,U0)âˆ¥f(t, Ï‰)âˆ¥2
H
= âˆ¥Î¦(t, Ï‰)âˆ¥2
L0
2âˆ¥f(t, Ï‰)âˆ¥2
H,
where we used Remark B.0.6(i) in the last step. Now all assertions follow.
Lemma 2.4.3. Let Î¦ âˆˆNW (0, T) and M(t) :=
' t
0 Î¦(s) dW(s), t âˆˆ[0, T].
Deï¬ne
âŸ¨MâŸ©t :=
 t
0
âˆ¥Î¦(s)âˆ¥2
L0
2 ds, t âˆˆ[0, T].
Then âŸ¨MâŸ©is the unique continuous increasing (Ft)-adapted process starting
at zero such that âˆ¥M(t)âˆ¥2 âˆ’âŸ¨MâŸ©t, t âˆˆ[0, T], is a local martingale. If Î¦ âˆˆ
N 2
W (0, T), then for any sequence
Il := {0 = tl
0 < tl
1 < . . . < tl
kl = T}, l âˆˆN,
of partitions with
max
i (tl
i âˆ’tl
iâˆ’1) â†’0 as l â†’âˆ
lim
lâ†’âˆE
â›
â


tl
j+1â©½t
âˆ¥M(tl
j+1) âˆ’M(tl
j)âˆ¥2 âˆ’âŸ¨MâŸ©t

â
â = 0.
Proof. For n âˆˆN let Ï„n be as in (2.3.1) and Ï„ an Ft-stopping time with
P[Ï„ â©½T] = 1. Then by Lemma 2.3.9 for Ïƒ := Ï„ âˆ§Ï„n, t âˆˆ[0, T]
E

 tâˆ§Ïƒ
0
Î¦(s) dW(s)

2
= E

 t
0
1]0,Ïƒ]Î¦(s) dW(s)

2
= E
 t
0
âˆ¥1]0,Ïƒ]Î¦(s)âˆ¥2
L0
2 ds

= E
 tâˆ§Ïƒ
0
âˆ¥Î¦(s)âˆ¥2
L0
2 ds

,

38
2. Stochastic Integral in Hilbert Spaces
and the ï¬rst assertion follows, because the uniqueness is obvious, since any
real-valued local martingale of bounded variation is constant.
To prove the second assertion we ï¬x an orthonormal basis {ei|i âˆˆN} of H
and note that by the theory of real-valued martingales we have for each i âˆˆN
lim
lâ†’âˆE
â›
â


tl
j+1â©½t
âŸ¨ei, M(tl
j+1) âˆ’M(tl
j)âŸ©2
H âˆ’
 t
0
âˆ¥Î¦(s)âˆ—eiâˆ¥2
U0 ds

â
â = 0, (2.4.2)
since by the ï¬rst part of the assertion and Lemmas 2.4.1 and 2.4.2
 t
0
âŸ¨ei, Î¦(s) dW(s)âŸ©H

t
=
 t
0
âˆ¥Î¦(s)âˆ—eiâˆ¥2
U0 ds, t âˆˆ[0, T].
Furthermore, for all i âˆˆN
E
â›
â


tl
j+1â©½t
âŸ¨ei, M(tl
j+1) âˆ’M(tl
j)âŸ©2
H âˆ’
 t
0
âˆ¥Î¦(s)âˆ—eiâˆ¥2
U0 ds

â
â 
â©½

tl
j+1â©½t
E
â¡
â£
 tl
j+1
tl
j
âŸ¨ei, Î¦(s) dW(s)âŸ©H
2â¤
â¦+ E
 t
0
âˆ¥Î¦(s)âˆ—eiâˆ¥2
U0 ds

=

tl
j+1â©½t
E
 tl
j+1
tl
j
âˆ¥Î¦(s)âˆ—eiâˆ¥2
U0 ds

+ E
 t
0
âˆ¥Î¦(s)âˆ—eiâˆ¥2
U0 ds

â©½2E
 t
0
âˆ¥Î¦(s)âˆ—eiâˆ¥2
U0 ds

(2.4.3)
which is summable over i âˆˆN. Here we used the isometry property of Int in
the second to last step. But
E
â›
â


tl
j+1â©½t
âˆ¥M(tl
j+1) âˆ’M(tl
j)âˆ¥2 âˆ’
 t
0
âˆ¥Î¦(s)âˆ¥2
L0
2 ds

â
â 
= E
â›
â

âˆ

i=1
â›
â
tl
j+1â©½t
âŸ¨ei, M(tl
j+1) âˆ’M(tl
j)âŸ©2
H âˆ’
 t
0
âˆ¥Î¦(s)âˆ—eiâˆ¥2
U0 ds
â
â 

â
â 
â©½
âˆ

i=1
E
â›
â


tl
j+1â©½t
âŸ¨ei, M(tl
j+1) âˆ’M(tl
j)âŸ©2
H âˆ’
 t
0
âˆ¥Î¦(s)âˆ—eiâˆ¥2
U0 ds

â
â 
where we used Remark B.0.6(i) in the second step. Hence the second assertion
follows by Lebesgue dominated convergence theorem from (2.4.2) and (2.4.3).

2.5. The stochastic integral for cylindrical Wiener processes
39
2.5. The stochastic integral for cylindrical
Wiener processes
Until now we have considered the case that W(t), t âˆˆ[0, T], was a standard
Q-Wiener process where Q âˆˆL(U) was nonnegative, symmetric and with
ï¬nite trace. We could integrate processes in
NW :=

Î¦ : â„¦T â†’L2(Q
1
2 (U), H) | Î¦ is predictable and
P
 T
0
âˆ¥Î¦(s)âˆ¥2
L0
2 ds < âˆ

= 1

.
In fact it is possible to extend the deï¬nition of the stochastic integral to the
case that Q is not necessarily of ï¬nite trace. To this end we ï¬rst have to
introduce the concept of cylindrical Wiener processes.
2.5.1. Cylindrical Wiener processes
Let Q âˆˆL(U) be nonnegative deï¬nite and symmetric. Remember that in
the case that Q is of ï¬nite trace the Q-Wiener process has the following
representation:
W(t) =

kâˆˆN
Î²k(t)ek,
t âˆˆ[0, T],
where ek, k âˆˆN, is an orthonormal basis of Q
1
2 (U) = U0 and Î²k, k âˆˆN, is
a family of independent real-valued Brownian motions. The series converges
in L2(â„¦, F, P; U), because the inclusion U0 âŠ‚U deï¬nes a Hilbertâ€“Schmidt
embedding from (U0, âŸ¨, âŸ©0) to (U, âŸ¨, âŸ©). In the case that Q is no longer of
ï¬nite trace one looses this convergence. Nevertheless, it is possible to deï¬ne
the Wiener process.
To this end we need a further Hilbert space (U1, âŸ¨, âŸ©1) and a Hilbertâ€“Schmidt
embedding
J : (U0, âŸ¨, âŸ©0) â†’(U1, âŸ¨, âŸ©1).
Remark 2.5.1. (U1, âŸ¨, âŸ©1)) and J as above always exist; e.g. choose U1 := U
and Î±k âˆˆ]0, âˆ[, k âˆˆN, such that âˆ
k=1 Î±2
k < âˆ. Deï¬ne J : U0 â†’U by
J(u) :=
âˆ

k=1
Î±kâŸ¨u, ekâŸ©0 ek,
u âˆˆU0.
Then J is one-to-one and Hilbertâ€“Schmidt.
Then the process given by the following proposition is called a cylindrical
Q-Wiener process in U.

40
2. Stochastic Integral in Hilbert Spaces
Proposition 2.5.2. Let ek, k âˆˆN, be an orthonormal basis of U0 = Q
1
2 (U)
and Î²k, k âˆˆN, a family of independent real-valued Brownian motions. Deï¬ne
Q1 := JJâˆ—. Then Q1 âˆˆL(U1), Q1 is nonnegative deï¬nite and symmetric with
ï¬nite trace and the series
W(t) =
âˆ

k=1
Î²k(t)Jek,
t âˆˆ[0, T],
(2.5.1)
converges in M2
T (U1) and deï¬nes a Q1-Wiener process on U1. Moreover, we
have that Q
1
2
1 (U1) = J(U0) and for all u0 âˆˆU0
âˆ¥u0âˆ¥0 = âˆ¥Q
âˆ’1
2
1
Ju0âˆ¥1 = âˆ¥Ju0âˆ¥
Q
1
2
1 U1,
i.e. J : U0 â†’Q
1
2
1 U1 is an isometry.
Proof. Step 1: We prove that W(t), t âˆˆ[0, T], deï¬ned in (2.5.1) is a Q1-
Wiener process in U1.
If we set Î¾j(t) := Î²j(t)J(ej), j âˆˆN, we obtain that Î¾j(t), t âˆˆ[0, T], is a
continuous U1-valued martingale with respect to
Gt := Ïƒ
 
jâˆˆN
Ïƒ(Î²j(s)|s â©½t)

,
t âˆˆ[0, T], since
E(Î²j(t) | Gs) = E(Î²j(t) | Ïƒ(Î²j(u)|u â©½s)) = Î²j(s)
for all 0 â©½s < t â©½T
as Ïƒ

Ïƒ(Î²j(u)|u â©½s) âˆªÏƒ(Î²j(t))

is independent of
Ïƒ
 
kâˆˆN
kÌ¸=j
Ïƒ(Î²k(u)|u â©½s)

.
Then it is clear that
Wn(t) :=
n

j=1
Î²j(t)J(ej),
t âˆˆ[0, T],
is also a continuous U1-valued martingale with respect to Gt, t âˆˆ[0, T]. In
addition, we obtain that
E
â›
âsup
tâˆˆ[0,T ]
âˆ¥
m

j=n
Î²j(t)J(ej)âˆ¥2
1
â
â â©½4 sup
tâˆˆ[0,T ]
E
â›
ââˆ¥
m

j=n
Î²j(t)J(ej)âˆ¥2
1
â
â 
= 4T
m

j=n
âˆ¥J(ej)âˆ¥2
1,
m â©¾n â©¾1.

2.5. The stochastic integral for cylindrical Wiener processes
41
Note that âˆ¥Jâˆ¥2
L2(U0,U1) =

jâˆˆN
âˆ¥J(ej)âˆ¥2
1 < âˆ. Therefore, we get the convergence
of Wn(t), t âˆˆ[0, T], in M2
T (U1), hence the limit W(t), t âˆˆ[0, T], is P-a.s. con-
tinuous.
Now we want to show that P â—¦(W(t) âˆ’W(s))âˆ’1 = N(0, (t âˆ’s)JJâˆ—). Anal-
ogously to the second part of the proof of Proposition 2.1.6 we get that
âŸ¨W(t) âˆ’W(s), u1âŸ©1 is normally distributed for all 0 â©½s < t â©½T and u1 âˆˆU1.
It is easy to see that the mean is equal to zero and concerning the covariance
of âŸ¨W(t) âˆ’W(s), u1âŸ©1 and âŸ¨W(t) âˆ’W(s), v1âŸ©1, u1, v1 âˆˆU1, we obtain that
E(âŸ¨W(t) âˆ’W(s), u1âŸ©1âŸ¨W(t) âˆ’W(s), v1âŸ©1)
=

kâˆˆN
(t âˆ’s)âŸ¨Jek, u1âŸ©1âŸ¨Jek, v1âŸ©1
= (t âˆ’s)

kâˆˆN
âŸ¨ek, Jâˆ—u1âŸ©0âŸ¨ek, Jâˆ—v1âŸ©0
= (t âˆ’s)âŸ¨Jâˆ—u1, Jâˆ—v1âŸ©0 = (t âˆ’s)âŸ¨JJâˆ—u1, v1âŸ©1.
Thus, it only remains to show that the increments of W(t), t âˆˆ[0, T], are
independent but this can be done in the same way as in the proof of Propo-
sition 2.1.10.
Step 2: We prove that Im Q
1
2
1 = J(U0) and that âˆ¥u0âˆ¥0 = âˆ¥Q
âˆ’1
2
1
Ju0âˆ¥1 for all
u0 âˆˆU0.
Since Q1 = JJâˆ—, by Corollary C.0.6 we obtain that Q
1
2
1 (U1) = J(U0) and that
âˆ¥Q
âˆ’1
2
1
u1âˆ¥1 = âˆ¥Jâˆ’1u1âˆ¥0 for all u1 âˆˆJ(U0). We now replace u1 by J(u0),
u0 âˆˆU0, to get the last assertion, because J : U0 â†’U1 is one-to-one.
2.5.2. The deï¬nition of the stochastic integral
for cylindrical Wiener processes
We ï¬x Q âˆˆL(U) nonnegative, symmetric but not necessarily of ï¬nite trace.
After the preparations of the previous section we are now able to deï¬ne the
stochastic integral with respect to a cylindrical Q-Wiener process W(t), t âˆˆ
[0, T].
Basically we integrate with respect to the standard U1-valued Q1-Wiener
process given by Proposition 2.5.2. In this sense we ï¬rst get that a process
Î¦(t), t âˆˆ[0, T], is integrable with respect to W(t), t âˆˆ[0, T], if it takes values
in L2(Q
1
2
1 (U1), H), is predictable and if
P
 T
0
âˆ¥Î¦(s)âˆ¥2
L2(Q
1
2
1 (U1),H) ds < âˆ

= 1.

42
2. Stochastic Integral in Hilbert Spaces
But in addition, we have by Proposition 2.5.2 that Q
1
2
1 (U1) = J(U0) and that
âŸ¨Ju0, Jv0âŸ©
Q
1
2
1 (U1) = âŸ¨Q
âˆ’1
2
1
Ju0, Q
âˆ’1
2
1
Jv0âŸ©1 = âŸ¨u0, v0âŸ©0
for all u0, v0 âˆˆU0 (by polarization). In particular, it follows that Jek, k âˆˆN,
is an orthonormal basis of Q
1
2
1 (U1). Hence we get that
Î¦ âˆˆL0
2 = L2(Q
1
2 (U), H) â‡â‡’Î¦ â—¦Jâˆ’1 âˆˆL2(Q
1
2
1 (U1), H)
since
âˆ¥Î¦âˆ¥2
L0
2 =

kâˆˆN
âŸ¨Î¦ek, Î¦ekâŸ©
=

kâˆˆN
âŸ¨Î¦ â—¦Jâˆ’1(Jek), Î¦ â—¦Jâˆ’1(Jek)âŸ©= âˆ¥Î¦ â—¦Jâˆ’1âˆ¥2
L2(Q
1
2
1 (U1),H)
Now we deï¬ne
 t
0
Î¦(s) dW(s) :=
 t
0
Î¦(s) â—¦Jâˆ’1 dW(s),
t âˆˆ[0, T].
(2.5.2)
Then the class of all integrable processes is given by
NW =

Î¦ : â„¦T â†’L0
2 | Î¦ predictable and P
	  T
0
âˆ¥Î¦(s)âˆ¥2
L0
2 ds < âˆ

= 1

as in the case where W(t), t âˆˆ[0, T], is a standard Q-Wiener process in U.
Remark 2.5.3.
1. We note that the stochastic integral deï¬ned in (2.5.2) is independent of
the choice of (U1, âŸ¨, âŸ©1) and J. This follows by construction, since by
(2.5.1) for elementary processes (2.5.2) does not depend on J.
2. If Q âˆˆL(U) is nonnegative, symmetric and with ï¬nite trace the stan-
dard Q-Wiener process can also be considered as a cylindrical Q-Wiener
process by setting J = I : U0 â†’U where I is the identity map. In this
case both deï¬nitions of the stochastic integral coincide.
Finally, we note that since the stochastic integrals in this chapter all have a
standard Wiener process as integrator, we can drop the predictability
assumption on Î¦ âˆˆNW and just assume progressive measurability, i.e. Î¦|[0,t]Ã— â„¦
is B([0, t])âŠ—Ft/B(L0
2)-measurable for all t âˆˆ[0, T], at least if (â„¦, F, P) is com-
plete (otherwise we consider its completion) (cf. [WW90, Theorem 6.3.1]).
We used the above framework so that it easily extends to more general
Hilbert-space-valued martingales as integrators replacing the standard Wiener
process. Details are left to the reader.

3. Stochastic Diï¬€erential
Equations in Finite
Dimensions
This chapter is an extended version of [Kry99, Section 1].
3.1. Main result and a localization lemma
Let (â„¦, F, P) be a complete probability space and Ft, t âˆˆ[0, âˆ[, a normal
ï¬ltration. Let (Wt)tâ©¾0 be a standard Wiener process on Rd1, d1 âˆˆN, with
respect to Ft, t âˆˆ[0, âˆ[. So, in the terminology of the previous section U :=
Rd1, Q := I. The role of the Hilbert space H there will be taken by Rd, d âˆˆN.
Let M(dÃ—d1, R) denote the set of all real dÃ—d1-matrices. Let the following
maps Ïƒ = Ïƒ(t, x, Ï‰), b = b(t, x, Ï‰) be given:
Ïƒ :[0, âˆ[Ã—Rd Ã— â„¦â†’M(d Ã— d1, R)
b :[0, âˆ[Ã—Rd Ã— â„¦â†’Rd
such that both are continuous in x âˆˆRd for each ï¬xed t âˆˆ[0, âˆ[, w âˆˆâ„¦,
and progressively measurable, i.e. for each t their restriction to [0, t] Ã— â„¦is
B([0, t])âŠ—Ft-measurable, for each ï¬xed x âˆˆRd. We note that then both Ïƒ and
b restricted to [0, t] Ã— Rd Ã— â„¦are B([0, t]) âŠ—B(Rd) âŠ—Ft-measurable for every
t âˆˆ[0, âˆ[. In particular, for every x âˆˆRd, t âˆˆ[0, âˆ[ both are Ft-measurable.
We also assume that the following integrability conditions hold:
 T
0
sup
|x|â©½R
{âˆ¥Ïƒ(t, x)âˆ¥2 + |b(t, x)|} dt < âˆon â„¦,
(3.1.1)
for all T, R âˆˆ[0, âˆ[. Here | Â· | denotes the Euclidean distance on Rd and
âˆ¥Ïƒâˆ¥2 :=
d

i=1
d1

j=1
|Ïƒij|2.
(3.1.2)
âŸ¨, âŸ©below denotes the Euclidean inner product on Rd.
43

44
3. Stochastic Diï¬€erential Equations in Finite Dimensions
Theorem 3.1.1. Let b, Ïƒ be as above satisfying (3.1.1). Assume that on â„¦
for all t, R âˆˆ[0, âˆ[, x, y âˆˆRd, |x|, |y| â©½R
2âŸ¨x âˆ’y, b(t, x) âˆ’b(t, y)âŸ©+ âˆ¥Ïƒ(t, x) âˆ’Ïƒ(t, y)âˆ¥2
â©½Kt(R)|x âˆ’y|2
(local weak monotonicity)
(3.1.3)
and
2âŸ¨x, b(t, x)âŸ©+ âˆ¥Ïƒ(t, x)âˆ¥2 â©½Kt(1)(1 + |x|2),
(weak coercivity)
(3.1.4)
where for R âˆˆ[0, âˆ[, Kt(R) is an R+-valued (Ft)-adapted process satisfying
on â„¦for all R, T âˆˆ[0, âˆ[
Î±T (R) :=
 T
0
Kt(R) dt < âˆ.
(3.1.5)
Then for any F0-measurable map X0 : â„¦â†’Rd there exists a (up to P-
indistinguish-ability) unique solution to the stochastic diï¬€erential equation
dX(t) = b(t, X(t)) dt + Ïƒ(t, X(t)) dW(t).
(3.1.6)
Here solution means that (X(t))tâ©¾0 is a P-a.s. continuous Rd-valued (Ft)-
adapted process such that P-a.s. for all t âˆˆ[0, âˆ[
X(t) = X0 +
 t
0
b(s, X(s)) ds +
 t
0
Ïƒ(s, X(s)) dW(s).
(3.1.7)
Furthermore, for all t âˆˆ[0, âˆ[
E(|X(t)|2eâˆ’Î±t(1)) â©½E(|X0|2) + 1.
(3.1.8)
Remark 3.1.2. We note that by (3.1.1) the integrals on the right-hand side
of (3.1.7) are well-deï¬ned.
For the proof of the above theorem we need two lemmas.
Lemma 3.1.3. Let Y (t), t âˆˆ[0, âˆ[, be a continuous, R+-valued, (Ft)-adapted
process on (â„¦, F, P) and Î³ an (Ft)-stopping time, and let Îµ âˆˆ(0, âˆ). Set
Ï„Îµ := Î³ âˆ§inf{t â©¾0|Y (t) â©¾Îµ}
(where as usual we set inf âˆ…= +âˆ). Then
P({ sup
tâˆˆ[0,Î³]
Y (t) â©¾Îµ}) â©½1
ÎµE(Y (Ï„Îµ)).

3.1. Main result and a localization lemma
45
Proof. We have
{ sup
tâˆˆ[0,Î³]
Y (t) â©¾Îµ} = {Y (Ï„Îµ) â©¾Îµ}.
Hence the assertion follows by Chebyshevâ€™s inequality.
The following general â€œlocalization lemmaâ€ will be crucial.
Lemma 3.1.4. Let n âˆˆN and X(n)(t), t âˆˆ[0, âˆ[, be a continuous, Rd-
valued, (Ft)-adapted process on (â„¦, F, P) such that X(n)(0) = X0 for some
F0-measurable function X0 : â„¦â†’Rd and
dX(n)(t) = b(t, X(n)(t)+p(n)(t)) dt+Ïƒ(t, X(n)(t)+p(n)(t)) dW(t), t âˆˆ[0, âˆ[
for some progressively measurable process p(n)(t), t âˆˆ[0, âˆ[. For n âˆˆN and
R âˆˆ[0, âˆ[ let Ï„ (n)(R) be (Ft)-stopping times such that
(i)
|X(n)(t)| + |p(n)(t)| â©½R
if
t âˆˆ]0, Ï„ (n)(R)]
P-a.e.
(ii)
lim
nâ†’âˆE
 T âˆ§Ï„ (n)(R)
0
|p(n)(t)| dt = 0
for all T âˆˆ[0, âˆ[.
(iii) There exists a function r : [0, âˆ[â†’[0, âˆ[ such that limRâ†’âˆr(R) = âˆ
and
lim
Râ†’âˆlim
nâ†’âˆP
	
Ï„ (n)(R) â©½T,
sup
tâˆˆ[0,Ï„ (n)(R)]
|X(n)(t)| â©½r(R)

= 0 for all T âˆˆ[0, âˆ[.
Then for every T âˆˆ[0, âˆ[ we have
sup
tâˆˆ[0,T ]
|X(n)(t) âˆ’X(m)(t)| â†’0
in probability as n, m â†’âˆ.
Proof. By (3.1.1) we may assume that
sup
|x|â©½R
|b(t, x)| â©½Kt(R)
for all R, t âˆˆ[0, âˆ[.
(3.1.9)
(Otherwise, we replace Kt(R) by the maximum of Kt(R) and the integrand
in (3.1.1).) Fix R âˆˆ[0, âˆ[ and deï¬ne the (Ft)-stopping times
Ï„(R, u) := inf{t â©¾0|Î±t(R) > u}, u âˆˆ[0, âˆ[.
Since t 	â†’Î±t(R) is locally bounded, we have that Ï„(R, u) â†‘âˆas u â†’âˆ.
In particular, there exists u(R) âˆˆ[0, âˆ[ such that
P({Ï„(R, u(R)) â©½R}) â©½1
R.

46
3. Stochastic Diï¬€erential Equations in Finite Dimensions
Setting Ï„(R) := Ï„(R, u(R)) we have Ï„(R) â†’âˆin probability as R â†’âˆand
Î±tâˆ§Ï„(R)(R) â©½u(R) for all t, R âˆˆ[0, âˆ[.
Furthermore, if we replace Ï„ (n)(R) by Ï„ (n)(R)âˆ§Ï„(R) for n âˆˆN, R âˆˆ[0, âˆ[,
then clearly assumptions (i) and (ii) above still hold. But
P

Ï„ (n)(R) âˆ§Ï„(R) â©½T,
sup
tâˆˆ[0,Ï„ (n)(R)âˆ§Ï„(R)]
|X(n)(t)| â©½r(R)
(
â©½P

Ï„ (n)(R) â©½T,
sup
tâˆˆ[0,Ï„ (n)(R)]
|X(n)(t)| â©½r(R), Ï„ (n)(R) â©½Ï„(R)
(
+ P({Ï„(R) â©½T, Ï„ (n)(R) > Ï„(R)})
and limRâ†’âˆP({Ï„(R) â©½T}) = 0. So, also assumption (iii) holds when Ï„ (n)(R)
is replaced by Ï„ (n)(R)âˆ§Ï„(R). We may thus assume that Ï„ (n)(R) â©½Ï„(R), hence
Î±tâˆ§Ï„ (n)(R)(R) â©½u(R) for all t, R âˆˆ[0, âˆ[, n âˆˆN.
(3.1.10)
Fix R âˆˆ[0, âˆ[ and deï¬ne
Î»(n)
t
(R) :=
 t
0
|p(n)(s)| Ks(R) ds,
t âˆˆ]0, âˆ[, n âˆˆN.
(3.1.11)
By (3.1.10) it follows that
lim
nâ†’âˆE
	
Î»(n)
T âˆ§Ï„ (n)(R)(R)

= 0 for all R, T âˆˆ[0, âˆ[.
(3.1.12)
Indeed, for all m, n âˆˆN
 T âˆ§Ï„ (n)(R)
0
|p(n)(t)| Kt(R) dt
â©½m
 T âˆ§Ï„ (n)(R)
0
|p(n)(t)| dt + R
 T âˆ§Ï„(R)
0
1]m,âˆ[(Kt(R)) Kt(R) dt.
By assumption (ii) we know that as n â†’âˆthis converges in L1(â„¦, F, P) to
R
 T âˆ§Ï„(R)
0
1]m,âˆ[(Kt(R)) Kt(R) dt,
which in turn is dominated by R Î±T âˆ§Ï„(R) â©½R u(R) and converges P-a.e.
to zero as m â†’âˆby (3.1.5). So, (3.1.12) follows by Lebesgueâ€™s dominated
convergence theorem. Let n, m âˆˆN and set
Ïˆt(R) := exp(âˆ’2Î±t(R) âˆ’|X0|),
t âˆˆ[0, âˆ[.
(3.1.13)

3.1. Main result and a localization lemma
47
Then by ItË†oâ€™s formula we have P-a.e. for all t âˆˆ[0, âˆ[
|X(n)(t) âˆ’X(m)(t)|2Ïˆt(R)
=
 t
0
Ïˆs(R)
1
2âŸ¨X(n)(s) âˆ’X(m)(s), b(s, X(n)(s) + p(n)(s))
âˆ’b(s, X(m)(s) + p(m)(s))âŸ©
+ âˆ¥Ïƒ(s, X(n)(s) + p(n)(s)) âˆ’Ïƒ(s, X(m)(s) + p(m)(s))âˆ¥2
âˆ’2Ks(R)|X(n)(s) âˆ’X(m)(s)|2
2
ds + M (n,m)
R
(t),
(3.1.14)
where M (n,m)
R
(t), t âˆˆ[0, âˆ[, is a continuous local (Ft)-martingale with
M (n,m)
R
(0) = 0. Writing
X(n)(s)âˆ’X(m)(s) = (X(n)(s)+p(n)(s))âˆ’(X(m)(s)+p(m)(s))âˆ’p(n)(s)+p(m)(s)
and by the weak monotonicity assumption (3.1.3), for t âˆˆ[0, Ï„ n(R) âˆ§Ï„ m(R)]
the right-hand side of (3.1.14) is P-a.e. dominated by
 t
0
Ïˆs(R)
1
2âŸ¨p(m)(s) âˆ’p(n)(s), b(s, X(n)(s) + p(n)(s))
âˆ’b(s, X(m)(s) + p(m)(s))âŸ©
+ Ks(R)|(X(n)(s) âˆ’X(m)(s)) + (p(n)(s) âˆ’p(m)(s))|2
âˆ’2Ks(R)|X(n)(s) âˆ’X(m)(s)|2
2
ds + M (n,m)
R
(t)
â©½2
 t
0
Ïˆs(R) Ks(R)
	
2|p(m)(s) âˆ’p(n)(s)| + |p(m)(s) âˆ’p(n)(s)|2
ds
+ M (n,m)
R
(t),
where we used (3.1.9) and assumption (i) in the last step. Since Ïˆs(R) â©½1
for all s âˆˆ[0, âˆ[ and since for s âˆˆ]0, Ï„ (n)(R) âˆ§Ï„ (m)(R)]
|p(m)(s) âˆ’p(n)(s)|2 â©½2R(|p(m)(s)| + |p(n)(s)|)
P-a.e.,
the above implies that for T âˆˆ[0, âˆ[ ï¬xed and Î³(n,m)(R) := T âˆ§Ï„ (n)(R) âˆ§
Ï„ (m)(R) we have P-a.e. for t âˆˆ[0, Î³(n,m)(R)]
|X(n)(t) âˆ’X(m)(t)|2Ïˆt(R) â©½4(1 + R)(Î»(n)
t
(R) + Î»(m)
t
(R)) + M (n,m)
R
(t).
(3.1.15)
Hence for any (Ft)-stopping time Ï„ â©½Î³(n,m)(R) and (Ft)-stopping times
Ïƒk â†‘âˆas k â†’âˆso that M (n,m)
R
(t âˆ§Ïƒk), t âˆˆ[0, âˆ[, is a martingale for all

48
3. Stochastic Diï¬€erential Equations in Finite Dimensions
k âˆˆN, we have
E(|X(n)(Ï„ âˆ§Ïƒk) âˆ’X(m)(Ï„ âˆ§Ïƒk)|2ÏˆÏ„âˆ§Ïƒk(R))
â©½4(1 + R)E(Î»(n)
T âˆ§Ï„ (n)(R)(R) + Î»(m)
T âˆ§Ï„ (m)(R)(R)).
First letting k â†’âˆand applying Fatouâ€™s lemma, and then using Lemma
3.1.3 we obtain that for every Îµ âˆˆ]0, âˆ[
P({
sup
tâˆˆ[0,Î³(n,m)(R)]
(|X(n)(t) âˆ’X(m)(t)|2Ïˆt(R)) > Îµ})
â©½4(1 + R)
Îµ
E(Î»(n)
T âˆ§Ï„ (n)(R)(R) + Î»(m)
T âˆ§Ï„ (m)(R)(R)).
Since [0, âˆ[ âˆ‹t 	â†’Ïˆt(R)(Ï‰) is strictly positive, independent of n, m âˆˆN, and
continuous, the above inequality and (3.1.12) imply that
sup
tâˆˆ[0,Î³(n,m)(R)]
|X(n)(t) âˆ’X(m)(t)| â†’0
as n, m â†’âˆ
in P-measure. So, to prove the assertion it remains to show that given T âˆˆ
[0, âˆ[,
lim
Râ†’âˆlim
nâ†’âˆP({Ï„ (n)(R) â©½T}) = 0.
(3.1.16)
We ï¬rst observe that replacing Kt(R) by max(Kt(R), Kt(1)) we may assume
that
Kt(1) â©½Kt(R) for all t âˆˆ[0, âˆ[, R âˆˆ[1, âˆ[.
(3.1.17)
Now we proceed similarly as above, but use the assumption of weak coercivity
(3.1.4) instead of the weak monotonicity (3.1.3). Let n âˆˆN and R âˆˆ[1, âˆ[.
Then by ItË†oâ€™s formula P-a.e. for all t âˆˆ[0, âˆ[ we have
|X(n)(t)|2Ïˆt(1)
=|X0|2eâˆ’|X0| +
 t
0
Ïˆs(1)

2âŸ¨X(n)(s), b(s, X(n)(s) + p(n)(s))âŸ©
+ âˆ¥Ïƒ(s, X(n)(s) + p(n)(s))âˆ¥2 âˆ’2Ks(1)|X(n)(s)|2
ds + M (n)
R (t),
(3.1.18)
where M (n)
R (t), t
âˆˆ
[0, âˆ[, is a continuous local (Ft)-martingale with
M (n)
R (0) = 0. By (3.1.4) and (3.1.9) and since Ïˆs(1) â©½1 for all s âˆˆ[0, âˆ[ the
second summand of the right-hand side of
(3.1.18) is P-a.e. for all

3.2. Proof of existence and uniqueness
49
t âˆˆ[0, T âˆ§Ï„ (n)(R)] dominated by
 t
0
Ïˆs(1)

2âŸ¨âˆ’p(n)(s), b(s, X(n)(s) + p(n)(s))âŸ©
+ Ks(1)|X(n)(s) + p(n)(s)|2 + Ks(1) âˆ’2Ks(1) |X(n)(s)|2
ds
â©½2
 t
0
Ks(R) |p(n)(s)|(1 + |p(n)(s)|) ds +
 t
0
eâˆ’2Î±s(1)Ks(1) ds
â©½2(1 + R)Î»(n)
t
(R) +
 Î±t(1)
0
eâˆ’2s ds,
(3.1.19)
where we used (3.1.9), (3.1.17) and assumption (i).
Again localizing M (n)
R (t), t âˆˆ[0, âˆ[, from (3.1.18) and (3.1.19) we deduce
that for every (Ft)-stopping time Ï„ â©½T âˆ§Ï„ (n)(R)
E(|X(n)(Ï„)|2ÏˆÏ„(1)) â©½E(|X0|2eâˆ’|X0|) + 1
2 + 2(1 + R)E(Î»(n)
T âˆ§Ï„ (n)(R)(R)).
Hence by Lemma 3.1.3 and (3.1.12) we obtain that for every c âˆˆ]0, âˆ[
lim
câ†’âˆ
sup
Râˆˆ[0,âˆ[
lim
nâ†’âˆP({
sup
tâˆˆ[0,T âˆ§Ï„ (n)(R)]
(|X(n)(t)|2Ïˆt(1)) â©¾c}) = 0.
Since [0, âˆ[ âˆ‹t 	â†’Ïˆt(1) is strictly positive, independent of n âˆˆN and contin-
uous, and since r(R) â†’âˆas R â†’âˆ, we conclude that
lim
Râ†’âˆlim
nâ†’âˆP({
sup
tâˆˆ[0,Ï„ (n)(R)]
|X(n)(t)| â©¾r(R), Ï„ (n)(R) â©½T})
â©½lim
Râ†’âˆ
sup
Ëœ
Râˆˆ[0,âˆ[
lim
nâ†’âˆP({
sup
tâˆˆ[0,T âˆ§Ï„ (n)( Ëœ
R)]
|X(n)(t)| â©¾r(R)}) = 0.
Hence (3.1.16) follows from assumption (iii).
Remark 3.1.5. In our application of Lemma 3.1.4 below, assumption (iii)
will be fulï¬lled, since the event under P will be empty for all n âˆˆN, R âˆˆ[0, âˆ[.
For a case where assumption (iii) is more diï¬ƒcult to check, we refer to [Kry99,
Section 1].
3.2. Proof of existence and uniqueness
Proof of Theorem 3.1.1. The proof is based on Eulerâ€™s method. Fix n âˆˆN
and deï¬ne the processes X(n)(t), t âˆˆ[0, âˆ[, iteratively by setting
X(n)(0) := X0

50
3. Stochastic Diï¬€erential Equations in Finite Dimensions
and for k âˆˆN âˆª{0} and t âˆˆ
 k
n, k+1
n

by
X(n)(t)
=X(n)
k
n

+
 t
k
n
b

s, X(n)
k
n

ds +
 t
k
n
Ïƒ

s, X(n)
k
n

dW(s).
This is equivalent to
X(n)(t) = X0 +
 t
0
b(s, X(n)(Îº(n, s))) ds
+
 t
0
Ïƒ(s, X(n)(Îº(n, s))) dW(s), t âˆˆ[0, âˆ[,
(3.2.1)
where Îº(n, t) := [tn]/n, and also to
X(n)(t) = X0 +
 t
0
b(s, X(n)(s) + p(n)(s)) ds
+
 t
0
Ïƒ(s, X(n)(s) + p(n)(s)) dW(s), t âˆˆ[0, âˆ[,
where
p(n)(t) :=X(n)(Îº(n, t)) âˆ’X(n)(t)
= âˆ’
 t
Îº(n,t)
b(s, X(n)(Îº(n, s))) ds
âˆ’
 t
Îº(n,t)
Ïƒ(s, X(n)(Îº(n, s))) dW(s), t âˆˆ[0, âˆ[.
Now ï¬x R âˆˆ[0, âˆ[ and deï¬ne
Ï„ (n)(R) := inf

t â©¾0
|X(n)(t)| > R
3

and
r(R) := R
4 .
Then clearly,
|p(n)(t)| â©½2R
3
and |X(n)(t)| â©½R
3 if t âˆˆ]0, Ï„ (n)(R)].
In particular, condition (i) in Lemma 3.1.4 holds and the event in Lemma
3.1.4(iii) is empty for all n âˆˆN, R âˆˆ[0, âˆ[, so this condition is satisï¬ed. Let

3.2. Proof of existence and uniqueness
51
ei, 1 â©½i â©½d, be the canonical basis of Rd and T âˆˆ[0, âˆ[. Since for t âˆˆ[0, T]
âˆ’âŸ¨ei, p(n)(t)âŸ©
=
 t
Îº(n,t)
âŸ¨ei, b(s, X(n)(Îº(n, s)))âŸ©ds +
 t
Îº(n,t)
âŸ¨ei, Ïƒ(s, X(n)(Îº(n, s))) dW(s)âŸ©,
it follows that for Îµ âˆˆ]0, âˆ[ and 1 â©½i â©½d, t âˆˆ[0, âˆ[
P({|âŸ¨ei, p(n)(t)âŸ©| â©¾2Îµ, t â©½Ï„ (n)(R)})
â©½P
 t
Îº(n,t)
sup
|x|â©½R
|b(s, x)| ds â©¾Îµ
(
+ P

sup
Ëœtâˆˆ[0,t]

 Ëœtâˆ§Ï„ (n)(R)
0
1[Îº(n,t),T ](s)
âŸ¨ei, Ïƒ(s, X(n)(Îº(n, s))) dW(s)âŸ©
 â©¾Îµ

and by Corollary D.0.2 the second summand is bounded by
3Î´
Îµ + P
 t
Îº(n,t)
sup
|x|â©½R
âˆ¥Ïƒ(t, x)âˆ¥2 ds > Î´2
(
.
Altogether, letting ï¬rst n â†’âˆand using (3.1.1), and then letting Î´ â†’0 we
obtain that for all t âˆˆ[0, âˆ[
1[0.Ï„n(R)](t) p(n)(t) â†’0 as n â†’âˆ
in P-measure. Since
1[0.Ï„n(R)](t)
pn)(t)
 â©½2R
3 , t âˆˆ[0, âˆ[,
it follows by Lebesgueâ€™s dominated convergence theorem and Fubiniâ€™s theorem
that condition (ii) in Lemma 3.1.4 is also fulï¬lled. Now Lemma 3.1.4 and the
fact that the space of continuous processes is complete with respect to locally
(in t âˆˆ[0, âˆ[) uniform convergence in probability imply that there exists a
continuous, (Ft)-adapted, Rd-valued process X(t), t âˆˆ[0, âˆ[, such that for all
T âˆˆ[0, âˆ[
sup
tâˆˆ[0,T ]
|X(n)(t) âˆ’X(t)| â†’0 in P-measure as n â†’âˆ.
(3.2.2)
To prove that X satisï¬es (3.1.6) we are going to take the limit in (3.2.1).
To this end, ï¬x T âˆˆ[0, âˆ[ and t âˆˆ[0, T]. By (3.2.2) and because of the path

52
3. Stochastic Diï¬€erential Equations in Finite Dimensions
continuity we only have to show that the right-hand side of (3.2.1) converges
in P-measure to
X0 +
 t
0
b(s, X(s)) ds +
 t
0
Ïƒ(s, X(s)) dW(s).
Since the convergence in (3.2.2) is uniform on [0, T], by equicontinuity we have
that also
sup
tâˆˆ[0,T ]
|X(n)(Îº(n, t)) âˆ’X(t)| â†’0 in P-measure as n â†’âˆ.
Hence for Y (n)(t) := X(n)(Îº(n, t)) and a subsequence (nk)kâˆˆN
sup
tâˆˆ[0,T ]
|Y (nk)(t) âˆ’X(t)| â†’0 P-a.e. as k â†’âˆ.
In particular, for S(t) := supkâˆˆN |Y (nk)(t)|
sup
tâˆˆ[0,T ]
S(t) < âˆ
P-a.e..
(3.2.3)
For R âˆˆ[0, âˆ[ deï¬ne the (Ft)-stopping time
Ï„(R) := inf{t âˆˆ[0, T]|S(t) > R} âˆ§T.
By the continuity of b in x âˆˆRd and by (3.1.1)
lim
kâ†’âˆ
 t
0
b(s, X(nk)(Îº(nk, s))) ds =
 t
0
b(s, X(s)) ds
P-a.e. on {t â©½Ï„(R)}.
(3.2.4)
To handle the stochastic integrals we need another sequence of stopping times.
For R, N âˆˆ[0, âˆ[ deï¬ne the (Ft)-stopping time
Ï„N(R) := inf{t âˆˆ[0, T]|
 t
0
sup
|x|â©½R
âˆ¥Ïƒ(s, x)âˆ¥2 ds > N} âˆ§Ï„(R).
Then by the continuity of Ïƒ in x âˆˆRd, (3.1.1), and Lebesgueâ€™s dominated
convergence theorem
lim
kâ†’âˆE
 Ï„N(R)
0
âˆ¥Ïƒ(s, X(nk)(Îº(nk, s))) âˆ’Ïƒ(s, X(s))âˆ¥2 ds

= 0,
hence
 t
0
Ïƒ(s, X(nk)(Îº(nk, s))) dW(s) â†’
 t
0
Ïƒ(s, X(s)) dW(s)
(3.2.5)

3.2. Proof of existence and uniqueness
53
in P-measure on {t â©½Ï„N(R)} as k â†’âˆ. By (3.1.1) for every Ï‰ âˆˆâ„¦there
exists N(Ï‰) âˆˆ[0, âˆ[ such that Ï„N(R) = Ï„(R) for all N â©¾N(Ï‰), so

NâˆˆN
{t â©½Ï„N(R)} = {t â©½Ï„(R)}.
Therefore, (3.2.5) holds on {t â©½Ï„(R)}. But by (3.2.3) for P-a.e. Ï‰ âˆˆâ„¦there
exists R(Ï‰) âˆˆ[0, âˆ[ such that Ï„(R) = T for all R â©¾R(Ï‰). So, as above we
conclude that (3.2.4) and (3.2.5) hold P-a.e. on â„¦. This completes the proof
for existence.
The uniqueness is a special case of the next proposition. So, let us prove
the ï¬nal statement. We have by ItË†oâ€™s formula for our solution X that P-a.e.
for all t âˆˆ[0, âˆ[
|X(t)|2eâˆ’Î±t(1) = |X0|2 +
 t
0
eâˆ’Î±s(1)
2âŸ¨X(s), b(s, X(s))âŸ©+ âˆ¥Ïƒ(s, X(s))âˆ¥2
âˆ’Ks(1)|X(s)|2
ds + M(t),
where M(t), t âˆˆ[0, âˆ[, is a continuous local martingale with M(0) = 0. By
the weak coercivity assumption (3.1.4) the latter is dominated by
|X0|2 +
 Î±t(1)
0
eâˆ’s ds + M(t).
So, again by localizing M(t), t âˆˆ[0, âˆ[, and Fatouâ€™s lemma we get
E(|X(t)|2eâˆ’Î±t(1)) â©½E(|X0|2) + 1, t âˆˆ[0, âˆ[.
Proposition 3.2.1. Let the assumptions of Theorem 3.1.1 apart from (3.1.4)
be satisï¬ed. Let X0, X(n)
0
: â„¦â†’Rd, n âˆˆN, be F0-measurable such that
P âˆ’lim
nâ†’âˆX(n)
0
= X0.
Let T âˆˆ[0, âˆ[ and assume that X(t), X(n)(t), t âˆˆ[0, T], n âˆˆN, be solutions
of (3.1.6) (up to time T) such that X(0) = X0 and X(n)(0) = X(n)
0
P-a.e.
for all n âˆˆN. Then
P âˆ’lim
nâ†’âˆsup
tâˆˆ[0,T ]
|X(n)(t) âˆ’X(t)| = 0.
(3.2.6)
Proof. By the characterization of convergence in P-measure in terms of P-a.e.
convergent subsequences (cf. e.g. [Bau01]), we may assume that X(n)
0
â†’X0
as n â†’âˆP-a.e..

54
3. Stochastic Diï¬€erential Equations in Finite Dimensions
Fix R âˆˆ[0, âˆ[ and deï¬ne
Ï†t(R) := exp(âˆ’Î±t(R) âˆ’sup
n |X(n)
0
|), t âˆˆ[0, âˆ[.
We note that since |X0| < âˆ, we have Ï†t(R) > 0 P-a.e. for all t âˆˆ[0, âˆ[.
Deï¬ne
Î³(n)(R) := inf{t â©¾0||X(n)(t)| + |X(t)| > R} âˆ§T.
Analogously to deriving (3.1.14) in the proof of Lemma 3.1.4 using the weak
monotonicity assumption (3.1.3), we obtain that P-a.e. for all t âˆˆ[0, T] and
all n âˆˆN
|X(n)(t âˆ§Î³(n)(R)) âˆ’X(t âˆ§Î³(n)(R))|2Ï†tâˆ§Î³(n)(R)(R)
â©½|X(n)
0
âˆ’X0|2eâˆ’supn |X(n)
0
| + m(n)
R (t),
where m(n)
R (t), t âˆˆ[0, T], are continuous local (Ft)-martingales such that
m(n)
R (0) = 0. Hence localizing m(n)
R (t), t âˆˆ[0, T], for any (Ft)-stopping time
Ï„ â©½Î³(n)(R) we obtain that
E(|X(n)(Ï„) âˆ’X(Ï„)|2Ï†Ï„(R)) â©½E(|X(n)
0
âˆ’X0|2eâˆ’supn |X(n)
0
|).
(3.2.7)
Since the right-hand side of (3.2.7) converges to zero, by Lemma 3.1.3 we
conclude that
P âˆ’lim
nâ†’âˆsup
tâˆˆ[0,T ]
	
|Xn)(t âˆ§Î³(n)(R)) âˆ’X(t âˆ§Î³(n)(R))|2Ï†tâˆ§Î³(n)(R)(R)

= 0.
(3.2.8)
Since P-a.e. the function [0, âˆ[âˆ‹t 	â†’Ï†t(R) is continuous and strictly positive,
(3.2.8) implies
P âˆ’lim
nâ†’âˆsup
tâˆˆ[0,T ]
|X(n)(t âˆ§Î³(n)(R)) âˆ’X(t âˆ§Î³(n)(R))| = 0.
(3.2.9)
But
P({Î³(n)(R) < T})
â©½P({ sup
tâˆˆ[0,T ]
|X(n)(t âˆ§Î³(n)(R))| + |X(t âˆ§Î³(n)(R))|) â©¾R})
â©½P({ sup
tâˆˆ[0,T ]
|X(n)(t âˆ§Î³(n)(R)) âˆ’X(t âˆ§Î³(n)(R))|) â©¾1})
+ P({2 sup
tâˆˆ[0,T ]
|X(t)| â©¾R âˆ’1}).
This together with (3.2.9) implies that
lim
Râ†’âˆlim
nâ†’âˆP({Î³(n)(R) < T}) = 0.
(3.2.10)
(3.2.9) and (3.2.10) imply (3.2.6).

4. A Class of Stochastic
Diï¬€erential Equations in
Banach Spaces and
Applications to Stochastic
Partial Diï¬€erential Equations
In this chapter we will present one speciï¬c method to solve stochastic dif-
ferential equations in inï¬nite-dimensional spaces, known as the variational
approach. The main criterion for this approach to work is that the coeï¬ƒ-
cients satisfy certain monotonicity assumptions. As the main references for
Subsection 4.2 we mention [RRW06] and [KR79], but also one should check
the references therein.
4.1. Gelfand triples, conditions on the
coeï¬ƒcients and examples
Let H be a separable Hilbert space with inner product âŸ¨, âŸ©H and Hâˆ—its
dual. Let V be a Banach space, such that V âŠ‚H continuously and densely.
Then for its dual space V âˆ—it follows that Hâˆ—âŠ‚V âˆ—continuously and densely.
Identifying H and Hâˆ—via the Riesz isomorphism we have that
V âŠ‚H âŠ‚V âˆ—
(4.1.1)
continuously and densely and if V âˆ—âŸ¨, âŸ©V denotes the dualization between V âˆ—
and V (i.e. V âˆ—âŸ¨z, vâŸ©V := z(v) for z âˆˆV âˆ—, v âˆˆV ), it follows that
V âˆ—âŸ¨z, vâŸ©V = âŸ¨z, vâŸ©H
for all z âˆˆH, v âˆˆV.
(4.1.2)
(V, H, V âˆ—) is called a Gelfand triple. Note that since H âŠ‚V âˆ—continuously and
densely, also V âˆ—is separable, hence so is V . Furthermore, B(V ) is generated
by V âˆ—and B(H) by Hâˆ—. We also have by Kuratowskiâ€™s theorem that V âˆˆ
B(H), H âˆˆB(V âˆ—) and B(V ) = B(H) âˆ©V, B(H) = B(V âˆ—) âˆ©H.
Below we want to study stochastic diï¬€erential equations on H of type
dX(t) = A(t, X(t))dt + B(t, X(t)) dW(t)
(4.1.3)
55

56
4. A Class of Stochastic Diï¬€erential Equations
with W(t), t âˆˆ[0, T] a cylindrical Q-Wiener process with Q = I on another
separable Hilbert space (U, âŸ¨, âŸ©U) and with B taking values in L2(U, H) as
in Chapter 2, but with A taking values in the larger space V âˆ—.
The solution X will, however, take values in H again. In this section we give
precise conditions on A and B.
Let T âˆˆ[0, âˆ[ be ï¬xed and let (â„¦, F, P) be a complete probability space with
normal ï¬ltration Ft, t âˆˆ[0, âˆ[. Let
A : [0, T] Ã— V Ã— â„¦â†’V âˆ—, B : [0, T] Ã— V Ã— â„¦â†’L2(U, H)
be progressively measurable, i.e. for every t âˆˆ[0, T], these maps restricted to
[0, t]Ã—V Ã—â„¦are B([0, t])âŠ—B(V )âŠ—Ft-measurable. As usual by writing A(t, v)
we mean the map Ï‰ 	â†’A(t, v, Ï‰). Analogously for B(t, v). We impose the
following conditions on A and B:
(H1) (Hemicontinuity) For all u, v, x âˆˆV, Ï‰ âˆˆâ„¦and t âˆˆ[0, T] the map
R âˆ‹Î» 	â†’V âˆ—âŸ¨A(t, u + Î»v, Ï‰), xâŸ©V
is continuous.
(H2) (Weak monotonicity) There exists c âˆˆR such that for all u, v âˆˆV
2 V âˆ—âŸ¨A(Â·, u) âˆ’A(Â·, v), u âˆ’vâŸ©V + âˆ¥B(Â·, u) âˆ’B(Â·, v)âˆ¥2
L2(U,H)
â©½câˆ¥u âˆ’vâˆ¥2
H on [0, T] Ã— â„¦.
(H3) (Coercivity) There exist Î± âˆˆ]1, âˆ[, c1 âˆˆR, c2 âˆˆ]0, âˆ[ and an (Ft)-
adapted process f âˆˆL1([0, T] Ã— â„¦, dt âŠ—P) such that for all v âˆˆV, t âˆˆ
[0, T]
2 V âˆ—âŸ¨A(t, v), vâŸ©V +âˆ¥B(t, v)âˆ¥2
L2(U,H) â©½c1âˆ¥vâˆ¥2
H âˆ’c2âˆ¥vâˆ¥Î±
V + f(t)
on â„¦.
(H4) (Boundedness) There exist c3 âˆˆ[0, âˆ[ and an (Ft)-adapted process
g âˆˆL
Î±
Î±âˆ’1 ([0, T] Ã— â„¦, dt âŠ—P) such that for all v âˆˆV, t âˆˆ[0, T]
âˆ¥A(t, v)âˆ¥V âˆ—â©½g(t) + c3âˆ¥vâˆ¥Î±âˆ’1
V
on â„¦,
where Î± is as in (H3).
Remark 4.1.1.
1. By (H3) and (H4) it follows that for all v âˆˆV, t âˆˆ
[0, T]
âˆ¥B(t, v)âˆ¥2
L2(U,H) â©½c1âˆ¥vâˆ¥2
H + f(t) + 2âˆ¥vâˆ¥V g(t) + 2c3âˆ¥vâˆ¥Î±
V
on â„¦.
2. Let Ï‰ âˆˆâ„¦, t âˆˆ[0, T]. (H1) and (H2) imply that A(t, Â·, Ï‰) is demicontin-
uous, i.e.
un â†’u as n â†’âˆ(strongly) in V

4.1. Gelfand triples, conditions on the coeï¬ƒcients and examples
57
implies
A(t, un, Ï‰) â†’A(t, u, Ï‰) as n â†’âˆweakly in V âˆ—
(cf. [Zei90, Proposition 26.4])
In particular if H = Rd, d âˆˆN, hence V = V âˆ—= Rd, then (H1) and
(H2) imply that u 	â†’A(t, u, Ï‰) is continuous from Rd to Rd.
Proof. Fix (t, Ï‰) âˆˆ[0, T] Ã— â„¦and set for u âˆˆV
A(u) := A(t, u, Ï‰) âˆ’cu.
The proof will be done in four steps.
Claim 1: A is locally bounded, i.e. for all u âˆˆV there exists a neighborhood
U(u) such that A(U(u)) is a bounded subset of V âˆ—.
Proof of Claim 1. Consider ï¬rst u := 0. Suppose A(U(0)) is unbounded for
all neighborhoods U(0) of 0. Then there exist un âˆˆV such that
un â†’0 and âˆ¥A(un)âˆ¥V âˆ—â†’âˆas n â†’âˆ.
Set
an := (1 + âˆ¥A(un)âˆ¥V âˆ—âˆ¥unâˆ¥V )âˆ’1.
Then by (H2) for all v âˆˆV
an V âˆ—âŸ¨A(un), un âˆ’(Â±v)âŸ©V âˆ’an V âˆ—âŸ¨A(Â±v), un âˆ’(Â±v)âŸ©V â©½0,
hence
âˆ“an V âˆ—âŸ¨A(un), vâŸ©V â©½âˆ’an V âˆ—âŸ¨A(un), unâŸ©V +an V âˆ—âŸ¨A(Â±v), un âˆ“vâŸ©V
â©½anâˆ¥A(un)âˆ¥V âˆ—âˆ¥unâˆ¥V + âˆ¥A(Â±v)âˆ¥V âˆ—âˆ¥un âˆ“vâˆ¥V
â©½1 + âˆ¥A(Â±v)âˆ¥V âˆ—

sup
n âˆ¥unâˆ¥V + âˆ¥vâˆ¥V

.
Consequently,
sup
n | V âˆ—âŸ¨anA(un), vâŸ©V | < âˆfor all v âˆˆV.
Therefore, by the Banachâ€“Steinhaus theorem
N := sup
n âˆ¥anA(un)âˆ¥V âˆ—< âˆ,
and thus for n0 âˆˆN so large that âˆ¥unâˆ¥â©½
1
2N for all n â©¾n0 we obtain
âˆ¥A(un)âˆ¥V âˆ—â©½aâˆ’1
n N â©½N + 1
2âˆ¥A(un)âˆ¥V âˆ—,

58
4. A Class of Stochastic Diï¬€erential Equations
i.e.
âˆ¥A(un)âˆ¥V âˆ—â©½2N for all n â©¾n0,
which is a contradiction. So, A(U(0)) is bounded for some neighborhood U(0)
of 0.
For arbitrary u âˆˆV we apply the above argument to the operator
Au(v) := A(u + v), v âˆˆV
which obviously is also hemicontinuous and weakly monotone. So, Claim 1 is
proved.
Claim 2: Let u âˆˆV, b âˆˆV âˆ—such that
V âˆ—âŸ¨b âˆ’A(v), u âˆ’vâŸ©V â©½0 for all v âˆˆV.
Then A(u) = b.
Proof of Claim 2. Let w âˆˆV, t âˆˆ]0, âˆ[ and set v := u âˆ’tw. Then
V âˆ—âŸ¨b âˆ’A(u âˆ’tw), twâŸ©V = V âˆ—âŸ¨b âˆ’A(v), u âˆ’vâŸ©V â©½0.
Dividing ï¬rst by t and then letting t â†’0, by (H1) we obtain
V âˆ—âŸ¨b âˆ’A(u), wâŸ©V â©½0 for all w âˆˆV.
So, replacing w by âˆ’w, w âˆˆV , we get
V âˆ—âŸ¨b âˆ’A(u), wâŸ©V = 0 for all w âˆˆV,
hence A(u) = b.
Claim 3: (â€œmonotonicity trickâ€). Let un, u âˆˆV, n âˆˆN, and b âˆˆV âˆ—such that
un â†’u as n â†’âˆweakly in V,
A(un) â†’b as n â†’âˆweakly in V âˆ—
and
lim V âˆ—âŸ¨A(un), unâŸ©V â©¾V âˆ—âŸ¨b, uâŸ©V .
Then A(u) = b.
Proof of Claim 3. We have for all v âˆˆV
V âˆ—âŸ¨A(un), unâŸ©V âˆ’V âˆ—âŸ¨A(v), unâŸ©V âˆ’V âˆ—âŸ¨A(un) âˆ’A(v), vâŸ©V
= V âˆ—âŸ¨A(un) âˆ’A(v), un âˆ’vâŸ©V â©½0.
Letting n â†’âˆwe obtain
V âˆ—âŸ¨b, uâŸ©V âˆ’V âˆ—âŸ¨A(v), uâŸ©V âˆ’V âˆ—âŸ¨b âˆ’A(v), vâŸ©V â©½0,
so
V âˆ—âŸ¨b âˆ’A(v), u âˆ’vâŸ©V â©½0 for all v âˆˆV.
Hence Claim 2 implies that A(u) = b.

4.1. Gelfand triples, conditions on the coeï¬ƒcients and examples
59
Claim 4: Let un, u âˆˆV, n âˆˆN, such that
un â†’u as n â†’âˆ(strongly) in V.
Then
A(un) â†’A(u) as n â†’âˆweakly in V âˆ—.
Proof of Claim 4. Since {un|n âˆˆN} is bounded, by Claim 1 also {A(un)|n âˆˆN}
is bounded in V âˆ—. Since bounded sets in V âˆ—are weakly compact by the
Banach-Alaoglu theorem, there exists a subsequence (nk)kâˆˆN and b âˆˆV âˆ—
such that A(unk) â†’b as k â†’âˆweakly in V âˆ—. Since unk â†’u strongly in V
as k â†’âˆ, we get
lim
kâ†’âˆV âˆ—âŸ¨A(unk), unkâŸ©V = V âˆ—âŸ¨b, uâŸ©V .
Therefore, all conditions in Claim 3 are fulï¬lled and we can conclude that
A(u) = b. So, for all such subsequences their weak limit is A(u), hence
A(un) â†’A(u) as n â†’âˆweakly in V âˆ—.
Let us now discuss the above conditions. We shall solely concentrate on A
and take B â‰¡0. The latter we do because of the following:
Exercise 4.1.2.
1. Suppose A, B satisfy (H2), (H3) above and ËœA is another map as A satis-
fying (H2), (H3). Then A + ËœA, B satisfy (H2),(H3). Likewise, if A and
ËœA both satisfy (H1), (H4) then so does A + ËœA.
2. If A satisï¬es (H2), (H3) (with B â‰¡0) and for all t âˆˆ[0, T], Ï‰ âˆˆâ„¦, the
map u 	â†’B(t, u, Ï‰) is Lipschitz with Lipschitz constant independent of
t âˆˆ[0, T], Ï‰ âˆˆâ„¦then A, B satisfy (H2), (H3).
Below, we only look at A independent of t âˆˆ[0, T], Ï‰ âˆˆâ„¦. From here
examples for A dependent on (t, Ï‰) are then immediate.
Example 4.1.3. V = H = V âˆ—(which includes the case H = Rd)
Clearly, since for all v âˆˆV
2 V âˆ—âŸ¨A(v), vâŸ©V â©½2 V âˆ—âŸ¨A(v) âˆ’A(0), vâŸ©V +âˆ¥A(0)âˆ¥2
V âˆ—+ âˆ¥vâˆ¥2
V ,
in the present case where V = H = V âˆ—, (H2) implies (H3) with c1 > c2
and Î± := 2. Furthermore, obviously, if A is Lipschitz in u then (H1)â€“(H4)
are immediately satisï¬ed. But for (H1)â€“(H3) to hold, purely local conditions
(with respect to u) on A can be suï¬ƒcient, as the following proposition shows.
Proposition 4.1.4. Suppose A : H â†’H is FrÂ´echet diï¬€erentiable such that
for some c âˆˆ[0, âˆ[ the operator DA(x) âˆ’cI (âˆˆL(H)) is negative deï¬nite for
all x âˆˆH. Then A satisï¬es (H1)â€“(H3) (with B â‰¡0).

60
4. A Class of Stochastic Diï¬€erential Equations
Proof. Since A is FrÂ´echet diï¬€erentiable it is continuous, so, in particular, (H1)
holds. Furthermore, for x, y âˆˆH we have
A(x) âˆ’A(y) =
 1
0
d
dsA(y + s(x âˆ’y))ds
=
 1
0
DA(y + s(x âˆ’y))(x âˆ’y)ds.
Hence by assumption
âŸ¨A(x) âˆ’A(y), x âˆ’yâŸ©H =
 1
0
âŸ¨DA(y + s(x âˆ’y))(x âˆ’y), x âˆ’yâŸ©Hds
â©½c
 1
0
âŸ¨x âˆ’y, x âˆ’yâŸ©Hds
= câˆ¥x âˆ’yâˆ¥2
H,
and so (H2) holds and hence (H3), as shown above.
We again note that Proposition 4.1.4 shows that purely local conditions on
A can already imply (H1)â€“(H3), if (V = H = V âˆ—and) Î± = 2. However, the
global condition (H4) then requires that A is of at most linear growth since
Î±âˆ’1 = 1 if Î± = 2. We also note that for H = R1 the conditions in Proposition
4.1.4 just mean that A is diï¬€erentiable and decreasing.
If H is a space of functions, a possible and easy choice for A would be e.g.
Au = âˆ’u3. But then we cannot choose H = L2 because A would not leave L2
invariant. This is one motivation to look at triples V âŠ‚H âŠ‚V âˆ—because then
we can take V = Lp and H = L2 and deï¬ne A from V to V âˆ—= Lp/(pâˆ’1). Let
us look at this case more precisely.
Example 4.1.5 (Lp âŠ‚L2 âŠ‚Lp/(pâˆ’1) and A(u) := âˆ’u|u|pâˆ’2).
Let p âˆˆ[2, âˆ[, Î› âŠ‚Rd, Î› open. Let
V := Lp(Î›) := Lp(Î›, dÎ¾),
equipped with its usual norm âˆ¥Â·âˆ¥p, and
H := L2(Î›) := L2(Î›, dÎ¾),
where dÎ¾ denotes Lebesgue measure on Î›. Then
V âˆ—= Lp/(pâˆ’1)(Î›).
If p > 2 we assume that
|Î›| :=

Rd IÎ›(Î¾) dÎ¾ < âˆ.
(4.1.4)

4.1. Gelfand triples, conditions on the coeï¬ƒcients and examples
61
Then
V âŠ‚H âŠ‚V âˆ—,
or concretely
Lp(Î›) âŠ‚L2(Î›) âŠ‚Lp/(pâˆ’1)(Î›)
continuously and densely. Recall that since p > 1, Lp(Î›) is reï¬‚exive.
Deï¬ne A : V â†’V âˆ—by
Au := âˆ’u|u|pâˆ’2, u âˆˆV = Lp(Î›).
Indeed, A takes values in V âˆ—= Lp/(pâˆ’1)(Î›), since

|Au(Î¾)|p/(pâˆ’1) dÎ¾ =

|u(Î¾)|p dÎ¾ < âˆ
for all u âˆˆLp(Î›).
Claim: A satisï¬es (H1)â€“(H4).
Proof. Let u, v, x âˆˆV . Then for Î» âˆˆR
V âˆ—âŸ¨A(u + Î»v) âˆ’A(u), xâŸ©V
=

(u(Î¾)|u(Î¾)|pâˆ’2 âˆ’(u(Î¾) + Î»v(Î¾))|u(Î¾) + Î»v(Î¾)|pâˆ’2)x(Î¾) dÎ¾
â©½
u|u|pâˆ’2 âˆ’(u + Î»v)|u + Î»v|pâˆ’2
V âˆ—âˆ¥xâˆ¥V
which converges to zero as Î» â†’0 by Lebesgueâ€™s dominated convergence the-
orem. So, (H1) holds.
Furthermore,
V âˆ—âŸ¨A(u) âˆ’A(v), u âˆ’vâŸ©V
=

(v(Î¾)|v(Î¾)|pâˆ’2 âˆ’u(Î¾)|u(Î¾)|pâˆ’2)(u(Î¾) âˆ’v(Î¾)) dÎ¾ â©½0,
since the map s 	â†’s|s|pâˆ’2 is increasing on R. Thus (H2) holds, with c := 0.
We also have that
V âˆ—âŸ¨A(v), vâŸ©V = âˆ’

|v(Î¾)|p dÎ¾ = âˆ’âˆ¥vâˆ¥p
V ,
so (H3) holds with Î± := p. In addition,
âˆ¥A(v)âˆ¥V âˆ—=

|v(Î¾)|p dÎ¾
 pâˆ’1
p
= âˆ¥vâˆ¥pâˆ’1
V
so (H4) holds with Î± := p as required.

62
4. A Class of Stochastic Diï¬€erential Equations
Remark 4.1.6. In the example above we may take A : V := Lp(Î›) â†’
L
p
pâˆ’1 (Î›) = V âˆ—deï¬ned by
A(v) := âˆ’Î¨(v), v âˆˆLp(Î›),
where Î¨ : R â†’R is a ï¬xed function satisfying properties (Î¨1)âˆ’(Î¨4) speciï¬ed
in Example 4.1.11 below.
Now we turn to cases where A is given by a (possibly nonlinear) partial
diï¬€erential operator. We shall start with the linear case; more concretely, A
will be given by the classical Laplace operator
âˆ†=
d

i=1
âˆ‚2
âˆ‚Î¾2
i
with initial domain given by Câˆ
0 (Î›). We want to take A to be an extension of
âˆ†to a properly chosen Banach space V so that A : V â†’V âˆ—is (deï¬ned on all
of V and) continuous with respect to âˆ¥Â·âˆ¥V and âˆ¥Â·âˆ¥V âˆ—. The right choice for V
is the classical Sobolev space H1,p
0 (Î›) for p âˆˆ[2, âˆ[ with Dirichlet boundary
conditions. So, as a preparation we need to introduce (ï¬rst-order) Sobolev
spaces.
Again let Î› âŠ‚Rd, Î› open, and let Câˆ
0 (Î›) denote the set of all inï¬nitely
diï¬€erentiable real-valued functions on Î› with compact support. Let p âˆˆ[1, âˆ[
and for u âˆˆCâˆ
0 (Î›) deï¬ne
âˆ¥uâˆ¥1,p :=

(|u(Î¾)|p + |âˆ‡u(Î¾)|p) dÎ¾
1/p
.
(4.1.5)
Then deï¬ne
H1,p
0 (Î›) := completion of Câˆ
0 (Î›) with respect to âˆ¥Â·âˆ¥1,p.
(4.1.6)
At this stage H1,p
0 (Î›), called the Sobolev space of order 1 in Lp(Î›) with
Dirichlet boundary conditions, just consists of abstract objects, namly equiv-
alence classes of âˆ¥Â·âˆ¥1,p-Cauchy sequences. The main point is to show that
H1,p
0 (Î›) âŠ‚Lp(Î›),
(4.1.7)
i.e. that the unique continuous extension
Â¯i : H1,p
0 (Î›) â†’Lp(Î›)
of the embedding
i : Câˆ
0 (Î›) â†’Lp(Î›)
is one-to-one. To this end it suï¬ƒces (in fact it is equivalent) to show that if
un âˆˆCâˆ
0 (Î›), n âˆˆN, such that
un â†’0
in Lp(Î›)

4.1. Gelfand triples, conditions on the coeï¬ƒcients and examples
63
and

|âˆ‡(un âˆ’um)(Î¾)|p dÎ¾ â†’0 as n, m â†’âˆ,
then

|âˆ‡(un(Î¾)|p dÎ¾ â†’0 as n â†’âˆ.
(4.1.8)
But by the completeness of Lp(Î›; Rd) there exists
F = (F1, . . . , Fd) âˆˆLp(Î›; Rd)
such that âˆ‡un â†’F as n â†’âˆin Lp(Î›; Rd). Let v âˆˆCâˆ
0 (Î›). Then for
1 â©½i â©½d, integrating by parts we obtain that

v(Î¾)Fi(Î¾) dÎ¾ = lim
nâ†’âˆ

v(Î¾) âˆ‚
âˆ‚Î¾i
un(Î¾) dÎ¾
= âˆ’lim
nâ†’âˆ

âˆ‚
âˆ‚Î¾i
v(Î¾)un(Î¾) dÎ¾
= 0.
Hence Fi = 0 dÎ¾-a.e. for all 1 â©½i â©½d, so (4.1.8) holds.
Consider the operator
âˆ‡: Câˆ
0 (Î›) âŠ‚Lp(Î›) â†’Lp(Î›; Rd).
By what we have shown above, we can extend âˆ‡to all of H1,p
0 (Î›) as follows.
Let u âˆˆH1,p
0 (Î›) and let un âˆˆCâˆ
0 (Î›) such that limnâ†’âˆâˆ¥u âˆ’unâˆ¥1,p = 0. In
particular, (âˆ‡un)nâˆˆN is a Cauchy sequence in Lp(Î›; Rd), hence has a limit
there. So, deï¬ne
âˆ‡u := lim
nâ†’âˆâˆ‡un
in Lp(Î›; Rd).
(4.1.9)
By what we have shown above this limit only depends on u and not on the
chosen sequence. We recall the fact that H1,p
0 (Î›) is reï¬‚exive for all p âˆˆ]1, âˆ[
(cf. [Zei90]).
Example 4.1.7 (H1,2
0
âŠ‚L2 âŠ‚(H1,2
0 )âˆ—, A = âˆ†).
Though later we shall see that to have (H3) we have to take p = 2, we shall
ï¬rst consider for p âˆˆ[2, âˆ[ and deï¬ne
V := H1,p
0 (Î›), H := L2(Î›),
so
V âˆ—:= H1,p
0 (Î›)âˆ—.
Again we assume (4.1.4) to hold if p > 2. Since then V âŠ‚Lp(Î›) âŠ‚H,
continuously and densely, identifying H with its dual we obtain the continuous
and dense embeddings
V âŠ‚H âŠ‚V âˆ—

64
4. A Class of Stochastic Diï¬€erential Equations
or concretely
H1,p
0 (Î›) âŠ‚L2(Î›) âŠ‚H1,p
0 (Î›)âˆ—.
(4.1.10)
Now we are going to extend âˆ†with initial domain Câˆ
0 (Î›) to a bounded linear
operator A : V â†’V âˆ—. First of all we can consider âˆ†as an operator taking
values in V âˆ—since
âˆ†: Câˆ
0 (Î›) â†’Câˆ
0 (Î›) âŠ‚L2(Î›) âŠ‚V âˆ—.
Furthermore, for u, v âˆˆCâˆ
0 (Î›) again integrating by parts we obtain
| V âˆ—âŸ¨âˆ†u, vâŸ©V | = |âŸ¨âˆ†u, vâŸ©H|
=
âˆ’

âŸ¨âˆ‡u(Î¾), âˆ‡v(Î¾)âŸ©dÎ¾

â©½

|âˆ‡u(Î¾)|
p
pâˆ’1 dÎ¾
 pâˆ’1
p 
|âˆ‡v(Î¾)|p dÎ¾
 1
p
â©½

|âˆ‡u(Î¾)|
p
pâˆ’1 dÎ¾
 pâˆ’1
p
âˆ¥vâˆ¥1,p.
Hence for all u âˆˆCâˆ
0 (Î›)
âˆ¥âˆ†uâˆ¥V âˆ—â©½âˆ¥|âˆ‡u|âˆ¥
p
pâˆ’1 .
(4.1.11)
So, by (4.1.4) and since
p
pâˆ’1 â©½2 â©½p, we get by HÂ¨olderâ€™s inequality
âˆ¥âˆ†uâˆ¥V âˆ—â©½|Î›|
pâˆ’2
p âˆ¥uâˆ¥1,p
for all u âˆˆCâˆ
0 (Î›),
(4.1.12)
where for p = 2 the factor on the right is just equal to 1.
So, âˆ†with domain Câˆ
0 (Î›) extends (uniquely) to a bounded linear operator
A : V â†’V âˆ—(with domain all of V ), also sometimes denoted by âˆ†.
Now let us check (H1)â€“(H4) for A.
Claim:
A(= âˆ†) : H1,p
0 (Î›) â†’
	
H1,p
0 (Î›)

âˆ—
satisï¬es (H1),(H2),(H4) and provided p = 2, also (H3).
Proof. Since A : V â†’V âˆ—is linear, (H1) is obviously satisï¬ed. Further, if
u, v âˆˆV then there exists un, vn âˆˆCâˆ
0 (Î›), n âˆˆN, such that un â†’u, vn â†’v
as n â†’âˆin V . Hence integrating by parts we get
V âˆ—âŸ¨A(u) âˆ’A(v), u âˆ’vâŸ©V = lim
nâ†’âˆV âˆ—âŸ¨âˆ†un âˆ’âˆ†vn, un âˆ’vnâŸ©V
= lim
nâ†’âˆâŸ¨âˆ†(un âˆ’vn), un âˆ’vnâŸ©H
= lim
nâ†’âˆâˆ’

|âˆ‡(un âˆ’vn)(Î¾)|2 dÎ¾ â©½0.

4.1. Gelfand triples, conditions on the coeï¬ƒcients and examples
65
So (H2) is satisï¬ed. Furthermore,
2 V âˆ—âŸ¨A(v), vâŸ©V = lim
nâ†’âˆ2âŸ¨âˆ†vn, vnâŸ©H
= âˆ’lim
nâ†’âˆ2

|âˆ‡vn(Î¾)|2 dÎ¾
= âˆ’2

|âˆ‡v(Î¾)|2 dÎ¾
= 2

âˆ¥vâˆ¥2
H âˆ’âˆ¥vâˆ¥2
1,2

.
So (H3) is satisï¬ed if p = 2 with Î± = 2. Furthermore, (H4), with Î± = 2 is
clear by (4.1.12).
Remark 4.1.8. The corresponding SDE (4.1.3) then reads
dX(t) = âˆ†X(t) dt + B(t, X(t)) dW(t).
If B â‰¡0, this is just the classical heat equation. If B Ì¸â‰¡0, but constant, the
solution is an Ornsteinâ€“Uhlenbeck process on H.
Example 4.1.9 (H1,p
0
âŠ‚L2 âŠ‚(H1,p
0 )âˆ—, A = p-Laplacian).
Again we take p âˆˆ[2, âˆ[, Î› âˆˆRd, Î› open and bounded, and V := H1,p
0 (Î›),
H := L2(Î›), so V âˆ—= (H1,p
0 (Î›))âˆ—. Deï¬ne A : H1,p
0 (Î›) â†’H1,p
0 (Î›)âˆ—by
A(u) := div(|âˆ‡u|pâˆ’2âˆ‡u), u âˆˆH1,p
0 (Î›);
more precisely, given u âˆˆH1,p
0 (Î›) for all v âˆˆH1,p
0 (Î›)
V âˆ—âŸ¨A(u), vâŸ©V := âˆ’

|âˆ‡u(Î¾)|pâˆ’2âŸ¨âˆ‡u(Î¾), âˆ‡v(Î¾)âŸ©dÎ¾
for all v âˆˆH1,p
0 (Î›).
(4.1.13)
A is called the p-Laplacian, also denoted by âˆ†p. Note that âˆ†2 = âˆ†. To
show that A : V â†’V âˆ—is well-deï¬ned we have to show that the right-hand
side of (4.1.13) deï¬nes a linear functional in v âˆˆV which is continuous with
respect to âˆ¥Â·âˆ¥V = âˆ¥Â·âˆ¥1,p. First we recall that by (4.1.9) âˆ‡u âˆˆLp(Î›; Rd) for
all u âˆˆH1,p
0 (Î›). Hence by HÂ¨olderâ€™s inequality

|âˆ‡u(Î¾)|pâˆ’1|âˆ‡v(Î¾)| dÎ¾ â©½

|âˆ‡u(Î¾)|p dÎ¾
 pâˆ’1
p 
|âˆ‡v(Î¾)|p dÎ¾
 1
p
â©½âˆ¥uâˆ¥pâˆ’1
1,p âˆ¥vâˆ¥1,p.
Since this dominates the right-hand side of (4.1.13) for all u âˆˆH1,p
0 (Î›) we
have that A(u) is a well-deï¬ned element of (H1,p
0 (Î›))âˆ—and that
âˆ¥A(u)âˆ¥V âˆ—â©½âˆ¥uâˆ¥pâˆ’1
V
.
(4.1.14)
Now we are going to check that A satisï¬es (H1)â€“(H4).

66
4. A Class of Stochastic Diï¬€erential Equations
(H1): Let u, v, x âˆˆH1,p
0 (Î›), then by (4.1.13) we have to show for Î» âˆˆR, |Î»| â©½
1
lim
Î»â†’0
 	
|âˆ‡(u + Î»v)(Î¾)|pâˆ’2âŸ¨âˆ‡(u + Î»v)(Î¾), âˆ‡x(Î¾)âŸ©
âˆ’|âˆ‡u(Î¾)|pâˆ’2âŸ¨âˆ‡u(Î¾), âˆ‡x(Î¾)âŸ©

dÎ¾ = 0.
Since obviously the integrands converge to zero as Î» â†’0 dÎ¾-a.e., we
only have to ï¬nd a dominating function to apply Lebesgueâ€™s dominated
convergence theorem. But obviously, since |Î»| â©½1
|âˆ‡(u + Î»v)(Î¾)|pâˆ’2|âŸ¨âˆ‡(u + Î»v)(Î¾), âˆ‡x(Î¾)âŸ©|
â©½2pâˆ’1 
|âˆ‡u(Î¾)|pâˆ’1 + |âˆ‡v(Î¾)|pâˆ’1
|âˆ‡x(Î¾)|
and the right-hand side is in L1(Î›) by HÂ¨olderâ€™s inequality as we have
seen above.
(H2): Let u, v âˆˆH1,p
0 (Î›). Then by (4.1.13)
âˆ’V âˆ—âŸ¨A(u) âˆ’A(v), u âˆ’vâŸ©V
=

âŸ¨|âˆ‡u(Î¾)|pâˆ’2âˆ‡u(Î¾) âˆ’|âˆ‡v(Î¾)|pâˆ’2âˆ‡v(Î¾), âˆ‡u(Î¾) âˆ’âˆ‡v(Î¾)âŸ©dÎ¾
=

(|âˆ‡u(Î¾)|p + |âˆ‡v(Î¾)|p âˆ’|âˆ‡u(Î¾)|pâˆ’2âŸ¨âˆ‡u(Î¾), âˆ‡v(Î¾)âŸ©
âˆ’|âˆ‡v(Î¾)|pâˆ’2âŸ¨âˆ‡u(Î¾), âˆ‡v(Î¾)âŸ©) dÎ¾
â©¾

(|âˆ‡u(Î¾)|p + |âˆ‡v(Î¾)|p âˆ’|âˆ‡u(Î¾)|pâˆ’1|âˆ‡v(Î¾)|
âˆ’|âˆ‡v(Î¾)|pâˆ’1|âˆ‡u(Î¾)|) dÎ¾
=

(|âˆ‡u(Î¾)|pâˆ’1 âˆ’|âˆ‡v(Î¾)|pâˆ’1)(|âˆ‡u(Î¾)| âˆ’|âˆ‡v(Î¾)|) dÎ¾
â©¾0,
since the map R+ âˆ‹s 	â†’spâˆ’1 is increasing. Hence (H2) is shown with
c = 0.
(H3): Because Î› is bounded by PoincarÂ´eâ€™s inequality (cf. [GT83]) there exists
a constant c = c(p, d, |Î›|) âˆˆ]0, âˆ[ such that

|âˆ‡u(Î¾)|p dÎ¾ â©¾c

|u(Î¾)|p dÎ¾
for all u âˆˆH1,p
0 (Î›).
(4.1.15)
Hence by (4.1.13) for all u âˆˆH1,p
0 (Î›)
V âˆ—âŸ¨A(u), uâŸ©V = âˆ’

|âˆ‡u(Î¾)|p dÎ¾ â©½âˆ’min(1, c)
2
âˆ¥uâˆ¥p
1,p.

4.1. Gelfand triples, conditions on the coeï¬ƒcients and examples
67
So, (H3) holds with Î± = p and c1 = 0. (We note that only for (H3) have
we used that Î› is bounded.)
(H4): This condition holds for A by (4.1.14) with Î± = p.
Before we go on to our last example which will include the case of the porous
medium equation we would like to stress the following:
Remark 4.1.10.
1. If one is given V âŠ‚H âŠ‚V âˆ—and A : V â†’V âˆ—(e.g.
as in the above examples) satisfying (H1)â€“(H4) (with B â‰¡0) one can
consider a â€œsmallerâ€ space V0, i.e. another reï¬‚exive separable Banach
space such that
V0 âŠ‚V
continuously and densely, hence (by restricting the linear functionals to
V0)
V âˆ—âŠ‚V âˆ—
0
continuously and densely, so altogether
V0 âŠ‚V âŠ‚H âŠ‚V âˆ—âŠ‚V âˆ—
0 .
Restricting A to V0 we see that A satisï¬es (H1),(H2) and (H4) with
respect to the Gelfand triple
V0 âŠ‚H âŠ‚V âˆ—
0 .
However, since âˆ¥Â·âˆ¥V0 is up to a multiplicative constant larger than âˆ¥Â·âˆ¥V ,
property (H3) might no longer hold. Therefore, e.g. if one considers a
map A which is given by a sum of the Laplacian (cf. Example 4.1.7)
and e.g. a monomial (cf. Example 4.1.5) one cannot just take any V0 âŠ‚
H1,2
0 (Î›) âˆ©Lp(Î›), since (H3) might get lost. However, if e.g. d â©¾3
and 1
d + 1
p = 1
2, then if Î› is bounded, by a Sobolev embedding theorem
(cf. [GT83, Theorems 7.10 and 7.15]), H1,2
0 (Î›) âŠ‚Lp(Î›) (âŠ‚Lpâ€²(Î›), pâ€² âˆˆ
[1, p]) continuously and densely, so one can take V
:=
H1,2
0 (Î›),
H = L2(Î›) and can consider
A(u) := âˆ†u âˆ’u|u|pâ€²âˆ’2, u âˆˆH1,2
0 (Î›).
Then (H3) holds with d := 2. So, if pâ€² âˆˆ[1, 2], also (H4) holds with
d = 2. The corresponding SDE (4.1.3) then reads
dX(t) = (âˆ†X(t) âˆ’X(t)|X(t)|pâ€²âˆ’2) dt
(+B(t, X(t)) dW(t))
and is called a (stochastic) reaction diï¬€usion equation.
In the case of the p-Laplacian, p âˆˆ[2, âˆ[, it is even easier to take
sums with monomials, since clearly H1,p
0 (Î›) âŠ‚Lp(Î›) continuously and
densely, so
A(u) := div(|âˆ‡u|pâˆ’2âˆ‡u) âˆ’u|u|pâˆ’2, u âˆˆH1,p
0 (Î›),

68
4. A Class of Stochastic Diï¬€erential Equations
satisï¬es (H1)â€“(H4), if Î› is bounded, with respect to the Gelfand triple
H1,p
0 (Î›) âŠ‚L2(Î›) âŠ‚(H1,p
0 (Î›))âˆ—.
But generally, taking sums of A as above requires some care and is not
always possible.
2. In all our analysis the space V âˆ—is only used as a tool. Eventually, since
the solutions to our SDE (4.1.3) will take values in H, V âˆ—will be of no
relevance. Therefore, no further information about V âˆ—such as its explicit
representation (e.g. as a space of Schwartz distributions) is necessary.
Example 4.1.11. [Lp âŠ‚(H1,2
0 )âˆ—âŠ‚(Lp)âˆ—, A = porous medium operator]
As references for this example we refer e.g. to [Aro86], [DPRLRW06], [RRW06].
Let Î› âŠ‚Rd, Î› open and bounded, p âˆˆ[2, âˆ[ and
V := Lp(Î›), H := (H1,2
0 (Î›))âˆ—.
Since Î› is bounded we have by PoincarÂ´eâ€™s inequality (4.1.15) that for some
constant c = c(2, d, |Î›|) > 0
âˆ¥uâˆ¥1,2 â©¾âˆ¥uâˆ¥H1,2
0
:=

|âˆ‡u(Î¾)|2 dÎ¾
 1
2
â©¾
min(1, c)
2
 1
2
âˆ¥uâˆ¥1,2
for all u âˆˆH1,2
0 (Î›).
(4.1.16)
So, we can (and will do so below) consider H1,2
0 (Î›) with norm âˆ¥Â·âˆ¥H1,2
0
and
corresponding scalar product
âŸ¨u, vâŸ©H1,2
0
:=

âŸ¨âˆ‡u(Î¾), âˆ‡v(Î¾)âŸ©dÎ¾, u, v âˆˆH1,2
0 (Î›).
Since H1,2
0 (Î›) âŠ‚L2(Î›) continuously and densely, so is
H1,2
0 (Î›) âŠ‚L
p
pâˆ’1 (Î›).
Hence
Lp(Î›) â‰¡
	
L
p
pâˆ’1 (Î›)

âˆ—
âŠ‚(H1,2
0 (Î›))âˆ—= H,
continuously and densely. Now we would like to identify H with its dual
Hâˆ—= H1,2
0 (Î›) via the corresponding Riesz isomorphism R : H â†’Hâˆ—deï¬ned
by Rx := âŸ¨x, Â·âŸ©H, x âˆˆH. Let us calculate the latter.
Lemma 4.1.12. The map âˆ†: H1,2
0 (Î›) â†’(H1,2
0 (Î›))âˆ—= H (deï¬ned by
(4.1.13) for p = 2) is an isometric isomorphism. In particular,
âŸ¨âˆ†u, âˆ†vâŸ©H = âŸ¨u, vâŸ©H1,2
0
for all u, v âˆˆH1,2
0 (Î›).
(4.1.17)

4.1. Gelfand triples, conditions on the coeï¬ƒcients and examples
69
Furthermore, (âˆ’âˆ†)âˆ’1 : H â†’Hâˆ—= H1,2
0 (Î›) is the Riesz isomorphism for H,
i.e. for every x âˆˆH
âŸ¨x, Â·âŸ©H = H1,2
0 âŸ¨(âˆ’âˆ†)âˆ’1x, Â·âŸ©H .
(4.1.18)
Proof. Let u âˆˆH1,2
0 (Î›). Since by (4.1.13) for all v âˆˆH1,2
0 (Î›)
HâŸ¨âˆ’âˆ†u, vâŸ©H1,2
0
=

âŸ¨âˆ‡u(Î¾), âˆ‡v(Î¾)âŸ©dÎ¾ = âŸ¨u, vâŸ©H1,2
0 ,
(4.1.19)
it follows that âˆ’âˆ†: H1,2
0 (Î›) â†’H is just the Riesz isomorphism for H1,2
0 (Î›)
and the ï¬rst part of the assertion including (4.1.17) follows. To prove the last
part, ï¬x x âˆˆH. Then by (4.1.17) and (4.1.19) for all y âˆˆH
âŸ¨x, yâŸ©H = âŸ¨(âˆ’âˆ†)âˆ’1x, (âˆ’âˆ†)âˆ’1yâŸ©H1,2
0
= HâŸ¨x, (âˆ’âˆ†)âˆ’1yâŸ©H1,2
0
.
Now we identify H with its dual Hâˆ—by the Riesz map (âˆ’âˆ†)âˆ’1 : H â†’Hâˆ—,
so H â‰¡Hâˆ—in this sense, hence
V = Lp(Î›) âŠ‚H âŠ‚(Lp(Î›))âˆ—= V âˆ—
(4.1.20)
continuously and densely.
Lemma 4.1.13. The map
âˆ†: H1,2
0 (Î›) â†’(Lp(Î›))âˆ—
extends to a linear isometry
âˆ†: L
p
pâˆ’1 (Î›) â†’(Lp(Î›))âˆ—= V âˆ—
and for all u âˆˆL
p
pâˆ’1 (Î›), v âˆˆLp(Î›)
V âˆ—âŸ¨âˆ’âˆ†u, vâŸ©V =
L
p
pâˆ’1 âŸ¨u, vâŸ©Lp =

u(Î¾)v(Î¾) dÎ¾.
(4.1.21)
Remark 4.1.14. One can prove that this isometry is in fact surjective, hence
(Lp(Î›))âˆ—= âˆ†(L
p
pâˆ’1 ) Ì¸= L
p
pâˆ’1 .
We shall not use this below, but it shows that the embedding (4.1.20) has to
be handled with care taking always into account that H is identiï¬ed with Hâˆ—
by (âˆ’âˆ†)âˆ’1 : H â†’Hâˆ—giving rise to a diï¬€erent dualization between Lp(Î›) and
(Lp(Î›))âˆ—. In particular, for all x âˆˆH, v âˆˆLp(Î›)
(Lp)âˆ—âŸ¨x, vâŸ©Lp = âŸ¨x, vâŸ©H

Ì¸=
L
p
pâˆ’1 âŸ¨x, vâŸ©Lp =

x(Î¾)v(Î¾) dÎ¾
provided x âˆˆL
p
pâˆ’1

.

70
4. A Class of Stochastic Diï¬€erential Equations
Proof of Lemma 4.1.13. Let u âˆˆH1,2
0 (Î›). Then since âˆ†u âˆˆH, by (4.1.2) and
(4.1.18) we obtain that for all v âˆˆV
V âˆ—âŸ¨âˆ†u, vâŸ©V = âŸ¨âˆ†u, vâŸ©H = âˆ’H1,2
0 âŸ¨u, vâŸ©H = âˆ’âŸ¨u, vâŸ©L2
(4.1.22)
since v âˆˆV âŠ‚L2(Î›). Therefore,
âˆ¥âˆ†uâˆ¥V âˆ—â©½âˆ¥uâˆ¥
p
pâˆ’1 .
So, âˆ†extends to a continuous linear map
âˆ†: L
p
pâˆ’1 (Î›) â†’V âˆ—
such that (4.1.22) holds for all u âˆˆL
p
pâˆ’1 (Î›), i.e. (4.1.21) is proved.
So, applying it to u âˆˆL
p
pâˆ’1 (Î›) and
v := âˆ’âˆ¥uâˆ¥
âˆ’q
p
q
u|u|qâˆ’2 âˆˆLp(Î›),
where q :=
p
pâˆ’1, by (4.1.21) we obtain that
V âˆ—âŸ¨âˆ†u, vâŸ©V = âˆ¥uâˆ¥
p
pâˆ’1
and âˆ¥vâˆ¥p = 1, so âˆ¥âˆ†uâˆ¥V âˆ—= âˆ¥uâˆ¥
p
pâˆ’1 and the assertion is completely proved.
Now we want to deï¬ne the â€œporous medium operator Aâ€. So, let Î¨ : R â†’R
be a function having the following properties:
(Î¨1) Î¨ is continuous.
(Î¨2) For all s, t âˆˆR
(t âˆ’s)(Î¨(t) âˆ’Î¨(s)) â©¾0.
(Î¨3) There exist p âˆˆ[2, âˆ[, a âˆˆ]0, âˆ[, c âˆˆ[0, âˆ[ such that for all s âˆˆR
sÎ¨(s) â©¾a|s|p âˆ’c.
(Î¨4) There exist c3, c4 âˆˆ]0, âˆ[ such that for all s âˆˆR
|Î¨(s)| â©½c4 + c3|s|pâˆ’1,
where p is as in (Î¨3).
We note that (Î¨4) implies that
Î¨(v) âˆˆL
p
pâˆ’1 (Î›)
for all v âˆˆLp(Î›).
(4.1.23)
Now we can deï¬ne the porous medium operator A : Lp(Î›) = V â†’V âˆ—=
(Lp(Î›))âˆ—by
A(u) := âˆ†Î¨(u),
u âˆˆLp(Î›).
(4.1.24)
Note that by (4.1.21) and Lemma 4.1.13 the operator A is well-deï¬ned. Now
let us check (H1)â€“(H4).

4.1. Gelfand triples, conditions on the coeï¬ƒcients and examples
71
(H1): Let u, v, x âˆˆV = Lp(Î›) and Î» âˆˆR. Then by (4.1.21)
V âˆ—âŸ¨A(u + Î»v), xâŸ©V = V âˆ—âŸ¨âˆ†Î¨(u + Î»v), xâŸ©V
= âˆ’

Î¨(u(Î¾) + Î»v(Î¾))x(Î¾) dÎ¾.
(4.1.25)
By (Î¨4) for |Î»| â©½1 the integrand in the right-hand side of (4.1.25) is
bounded by
[c4 + c32pâˆ’1(|u|pâˆ’1 + |v|pâˆ’1)]|x|
which by HÂ¨olderâ€™s inequality is in L1(Î›). So, (H1) follows by (Î¨1) and
Lebesgueâ€™s dominated convergence theorem.
(H2): Let u, v âˆˆV = Lp(Î›). Then by (4.1.21)
V âˆ—âŸ¨A(u) âˆ’A(v), u âˆ’v)âŸ©V = V âˆ—âŸ¨âˆ†(Î¨(u) âˆ’Î¨(v)), u âˆ’vâŸ©V
= âˆ’

[Î¨(u(Î¾)) âˆ’Î¨(v(Î¾))](u(Î¾) âˆ’v(Î¾)) dÎ¾
â©½0,
where we used (Î¨2) in the last step.
(H3): Let v âˆˆLp(Î›) = V . Then by (4.1.21) and (Î¨3)
V âˆ—âŸ¨A(v), vâŸ©V = âˆ’

Î¨(v(Î¾))v(Î¾) dÎ¾
â©½

(âˆ’a|v(Î¾)|p + c) dÎ¾.
Hence (H3) is satisï¬ed with c1 := 0, c2 := 2a, Î± = p and f(t) = 2c|Î›|.
(H4): Let v âˆˆLp(Î›) = V . Then by Lemma 4.1.13 and (Î¨4)
âˆ¥A(v)âˆ¥V âˆ—= âˆ¥âˆ†Î¨(v)âˆ¥V âˆ—
= âˆ¥Î¨(v)âˆ¥
L
p
pâˆ’1
â©½c4|Î›|
pâˆ’1
p
+ c3

|v(Î¾)|p dÎ¾
 pâˆ’1
p
= c4|Î›|
pâˆ’1
p
+ c3âˆ¥vâˆ¥pâˆ’1
V
,
so (H4) holds with Î± = p.
Remark 4.1.15.
1. For p âˆˆ[2, âˆ[ and Î¨(s) := s|s|pâˆ’2 we have
A(v) = âˆ†(v|v|pâˆ’2), v âˆˆLp(Î›),

72
4. A Class of Stochastic Diï¬€erential Equations
which is the non-linear operator appearing in the classical porous medium
equation, i.e.
âˆ‚X(t)
âˆ‚t
= âˆ†(X(t)|X(t)|pâˆ’2),
X(0, Â·) = X0,
whose solution describes the time evolution of the density X(t) of a
substance in a porous medium (cf. e.g. [Aro86]).
2. Let Î¨ : R â†’R be given such that (Î¨1)â€“(Î¨4) are satisï¬ed with some
p âˆˆ]1, âˆ[ (in (Î¨3), (Î¨4)). One can see that the above assumptions that
Î› is bounded and p â©¾2, can be avoided. But p then depends on the
dimension of the underlying space Rd. Let us assume ï¬rst that d â©¾3.
We distinguish two cases:
Case 1. |Î›| = âˆand p :=
2d
d+2, c = c4 = 0, where c, c4 are the constants in
(Î¨3) and in (Î¨4) respectively.
Case 2. |Î›| < âˆand p âˆˆ
%
2d
d+2, âˆ
%
.
By the Sobolev embedding theorem (cf. [GT83, Theorem 7.10]) we have
H1,2
0 (Î›) âŠ‚L
2d
dâˆ’2 (Î›)
continuously and densely, and
âˆ¥uâˆ¥2d
dâˆ’2 â©½
2(d âˆ’1)
âˆš
d(d âˆ’2)
âˆ¥uâˆ¥H1,2
0
for all u âˆˆH1,2
0 (Î›).
In Case 1 we have
2d
dâˆ’2 =
p
pâˆ’1 and in Case 2 (hence in both cases)
2d
d âˆ’2 â©¾
p
p âˆ’1
and thus
H1,2
0 (Î›) âŠ‚L
p
pâˆ’1 (Î›)
densely and for some c0 âˆˆ]0, âˆ[
âˆ¥uâˆ¥
p
pâˆ’1 â©½c0âˆ¥uâˆ¥H1,2
0
for all u âˆˆH1,2
0 (Î›).
Now the above arguments generalize to both Cases 1 and 2, i.e. for the
Gelfand triple
V := Lp(Î›) âŠ‚H := (H1,2
0 (Î›))âˆ—âŠ‚(Lp(Î›))âˆ—
the operator
A : Lp(Î›) =: V â†’V âˆ—= (Lp(Î›))âˆ—
deï¬ned in (4.1.24), satisï¬es (H1)â€“(H4).

4.2. The main result and an ItË†o formula
73
We note that in Case 1 the norm âˆ¥Â·âˆ¥H1,2
0
deï¬ned in (4.1.16) is in general
not equivalent to âˆ¥Â·âˆ¥1,2, because the Poincare inequality does not hold.
So, H1,2
0 (Î›))âˆ—as a dual to the normed vector spaces (H1
0(Î›), âˆ¥Â·âˆ¥H1,2
0 ) is
complete. In particular, if (3 â©½d) â©½6, we may take p = 3
2 and
Î¨(s) := sign(s)

|s|, s âˆˆR.
For Î› bounded the above extends, of course, also to the case d = 1, 2
where even stronger Sobolev embeddings hold (cf. [GT83, Theorems 7.10
and 7.15]).
4.2. The main result and an ItË†o formula
Consider the general situation described at the beginning of the previous
section. So, we have a Gelfand triple
V âŠ‚H âŠ‚V âˆ—
and maps
A : [0, T] Ã— V Ã— â„¦â†’V âˆ—,
B : [0, T] Ã— V Ã— â„¦â†’L2(U, H)
as speciï¬ed there, satisfying (H1)â€“(H4), and consider the stochastic diï¬€erential
equation
dX(t) = A(t, X(t)) dt + B(t, X(t)) dW(t)
(4.2.1)
on H with W(t), t âˆˆ[0, T], a cylindrical Q-Wiener process with Q := I taking
values in another separable Hilbert space (U, âŸ¨, âŸ©U) and being deï¬ned on a
complete probability space (â„¦, F, P) with normal ï¬ltration Ft, t âˆˆ[0, T].
Before we formulate our main existence and uniqueness result for solutions
of (4.2.1) we have to deï¬ne what we mean by â€œsolutionâ€.
Deï¬nition 4.2.1. A continuous H-valued (Ft)-adapted process (X(t))tâˆˆ[0,T ]
is called a solution of (4.2.1), if for its dt âŠ—P-equivalence class Ë†X we have
Ë†X âˆˆLÎ±([0, T] Ã— â„¦, dt âŠ—P; V ) âˆ©L2([0, T] Ã— â„¦, dt âŠ—P; H) with Î± as in (H3)
and P-a.s.
X(t) = X(0) +
 t
0
A(s, Â¯X(s))ds +
 t
0
B(s, Â¯X(s)) dW(s),
t âˆˆ[0, T],
(4.2.2)
where Â¯X is any V -valued progressively measurable dt âŠ—P-version of Ë†X.

74
4. A Class of Stochastic Diï¬€erential Equations
Remark 4.2.2.
1. The existence of the special version Â¯X above follows from Exercise 4.2.3
below. Furthermore, for technical reasons in Deï¬nition 4.2.1 and
below we consider all processes initially as V âˆ—-valued, hence by
dtâŠ—
P-equivalence classes we always mean classes of V âˆ—-valued processes.
2. The integral with respect to ds in (4.2.2) is initially a V âˆ—-valued Bochner
integral which turns out to be in fact H-valued.
3. Solutions in the sense of Deï¬nition 4.2.1 are often called variational
solutions in the literature. There are various other notions of solutions
for stochastic (partial) diï¬€erential equations. We recall the deï¬nition of
(probabilistically) weak and strong solutions in Appendix E below. The
notions of analytically weak and strong solutions as well as the notion
of mild solutions and their relations are recalled in Appendix F below.
Exercise 4.2.3.
1. Let BV âˆ—
1
denote the closed unit ball in V âˆ—. Since BV âˆ—
1
âˆ©H Ì¸= âˆ…, it has a
countable subset {li|i âˆˆN}, which is dense in BV âˆ—
1
âˆ©H with respect to
H-norm.
Deï¬ne Î˜ : H â†’[0, âˆ] by
Î˜(h) := sup
iâˆˆN
|âŸ¨li, hâŸ©H|, h âˆˆH.
Then Î˜ is lower semicontinuous on H, hence B(H)-measurable. Since
V âˆ—âŸ¨li, vâŸ©V = âŸ¨li, vâŸ©H, i âˆˆN, v âˆˆV , we have
Î˜(v) = âˆ¥vâˆ¥V
for all v âˆˆV,
and furthermore (by the reï¬‚exivity of V )
{Î˜ < âˆ} = V.
2. Let X : [0, T] Ã— â„¦â†’H be any progressively measurable (i.e. B([0, t]) âŠ—
Ft/B(H)-measurable for all t âˆˆ[0, T]) dtâŠ—P-version of Ë†X âˆˆLÎ±([0, T]Ã—
â„¦, dt âŠ—P; V ), Î± âˆˆ(0, âˆ). Then
Â¯X := I{Î˜â—¦X<âˆ}X
is a V -valued progressively measurable (i.e. B([0, t]) âŠ—Ft/B(V )-measu-
rable) dt âŠ—P-version of Ë†X.
3. Both A(Â·, Â¯X) and B(Â·, Â¯X) are V -valued respectively L2(U, H)-valued pro-
gressively measurable processes.
Now the main result (cf. [KR79]):

4.2. The main result and an ItË†o formula
75
Theorem
4.2.4.
Let
A, B
above
satisfy
(H1)â€“(H4)
and
let
X0 âˆˆL2(â„¦, F0, P; H). Then there exists a unique solution X to (4.2.1) in
the sense of Deï¬nition 4.2.1. Moreover,
E( sup
tâˆˆ[0,T ]
âˆ¥X(t)âˆ¥2
H) < âˆ.
(4.2.3)
The proof of Theorem 4.2.4 strongly depends on the following ItË†o formula,
from [KR79, Theorem I.3.1], which we shall prove here ï¬rst. The presentation
of its proof and that of Theorem 4.2.4 is an extended adaptation of those in
[RRW06].
Theorem 4.2.5. Let X0 âˆˆL2(â„¦, F0, P; H) and Y âˆˆL
Î±
Î±âˆ’1 ([0, T] Ã— â„¦, dt âŠ—
P; V âˆ—), Z âˆˆL2([0, T] Ã— â„¦, dt âŠ—P; L2(U, H)), both progressively measurable.
Deï¬ne the continuous V âˆ—-valued process
X(t) := X0 +
 t
0
Y (s)ds +
 t
0
Z(s) dW(s), t âˆˆ[0, T].
If for its dt âŠ—P-equivalence class Ë†X we have Ë†X âˆˆLÎ±([0, T] Ã— â„¦, dt âŠ—P, V )
with Î± as in (H3), then X is an H-valued continuous (Ft)-adapted process,
E

sup
tâˆˆ[0,T ]
âˆ¥X(t)âˆ¥2
H

< âˆ
and the following ItË†o-formula holds for the square of its H-norm P-a.s.
âˆ¥X(t)âˆ¥2
H = âˆ¥X0âˆ¥2
H +
 t
0
	
2 V âˆ—âŸ¨Y (s), Â¯X(s)âŸ©V +âˆ¥Z(s)âˆ¥2
L2(U,H)

ds
+ 2
 t
0
âŸ¨X(s), Z(s) dW(s)âŸ©H
for all t âˆˆ[0, T]
(4.2.4)
for any V -valued progressively measurable dt âŠ—P-version Â¯X of Ë†X.
As in [KR79] for the proof of Theorem 4.2.5 we need the following lemma
about piecewise constant approximations based on an argument due to
[Doo53]. For abbreviation below we set
K := LÎ±([0, T] Ã— â„¦, dt âŠ—P; V ).
(4.2.5)
Lemma 4.2.6. Let X : [0, T] Ã— â„¦â†’V âˆ—be B([0, T]) âŠ—F/B(V âˆ—)-measurable
such that for its
dt âŠ—P-equivalence class Ë†X we have Ë†X âˆˆK. Then there
exists a sequence of partitions Il := {0 = tl
0 < tl
1 < Â· Â· Â· < tl
kl = T} such that
Il âŠ‚Il+1 and Î´(Il) := maxi(tl
i âˆ’tl
iâˆ’1) â†’0 as l â†’âˆ, X(tl
i) âˆˆV P-a.e. for
all l âˆˆN, 1 â‰¤i â‰¤kl âˆ’1, and for

76
4. A Class of Stochastic Diï¬€erential Equations
Â¯Xl :=
kl

i=2
1[tl
iâˆ’1,tl
i[X(tl
iâˆ’1),
ËœXl :=
klâˆ’1

i=1
1[tl
iâˆ’1,tl
i[X(tl
i),
l âˆˆN,
we have Â¯Xl, ËœXl are ( dt âŠ—P-versions of elements) in K such that
lim
lâ†’âˆ

âˆ¥Ë†X âˆ’Â¯Xlâˆ¥K + âˆ¥Ë†X âˆ’ËœXlâˆ¥K

= 0.
Proof. For simplicity we assume that T = 1 and let Â¯X : [0, 1] Ã— â„¦â†’V be a
dt âŠ—P-version of Ë†X. We extend Â¯X to R Ã— â„¦by setting Â¯X = 0 on [0, 1]c Ã— â„¦.
There exists â„¦â€² âˆˆF with full probability such that for every Ï‰ âˆˆâ„¦â€² there
exists a sequence (fn)nâˆˆN âŠ‚C(R; V ) with compact support such that

R
âˆ¥fn(s) âˆ’Â¯X(s, Ï‰)âˆ¥Î±
V ds â‰¤1
2n,
n âˆˆN.
Thus, for every n âˆˆN,
lim sup
Î´â†’0

R
âˆ¥Â¯X(Î´ + s, Ï‰) âˆ’Â¯X(s, Ï‰)âˆ¥Î±
V ds
â‰¤3Î±âˆ’1 lim sup
Î´â†’0

R

âˆ¥Â¯X(Î´ + s, Ï‰) âˆ’fn(Î´ + s)âˆ¥Î±
V + âˆ¥Â¯X(s, Ï‰) âˆ’fn(s)âˆ¥Î±
V

ds
â‰¤3Î±âˆ’1
n
, n âˆˆN.
Here we used that since each fn is uniformly continuous, by Lebesgueâ€™s dom-
inated convergence theorem we have that for all n âˆˆN
lim
Î´â†’0

R
âˆ¥fn(Î´ + s) âˆ’fn(s)âˆ¥Î±
V ds = 0.
Letting n â†’âˆwe obtain
lim
Î´â†’0

R
âˆ¥Â¯X(Î´ + s, Ï‰) âˆ’Â¯X(s, Ï‰)âˆ¥Î±
V ds = 0,
Ï‰ âˆˆâ„¦â€².
(4.2.6)
Now, given t âˆˆR, let [t] denote the largest integer â‰¤t. Let Î³n(t) := 2âˆ’n[2nt],
n âˆˆN, that is, Î³n(t) is the largest number of the form
k
2n , k âˆˆZ, below t.
Shifting the integral in (4.2.6) by t and taking Î´ = Î³n(t) âˆ’t we obtain
lim
nâ†’âˆ

R
âˆ¥Â¯X(Î³n(t) + s) âˆ’Â¯X(t + s)âˆ¥Î±
V ds = 0 on â„¦â€².

4.2. The main result and an ItË†o formula
77
Moreover,
 1
0
âˆ¥Â¯X(Î³n(t) + s) âˆ’Â¯X(t + s)âˆ¥Î±
V ds
â‰¤1[âˆ’2,2](t)2Î±âˆ’1

R

âˆ¥Â¯X(Î³n(t) + s)âˆ¥Î±
V + âˆ¥Â¯X(t + s)âˆ¥Î±
V

ds
= 2Î±1[âˆ’2,2](t)
 1
0
âˆ¥Â¯X(s)âˆ¥Î±
V ds on â„¦â€².
So, by Lebesgueâ€™s dominated convergence theorem, we obtain that
0 = lim
nâ†’âˆE

R
dt
 1
0
âˆ¥Â¯X(Î³n(t) + s) âˆ’Â¯X(t + s)âˆ¥Î±
V ds
â‰¥lim
nâ†’âˆE
 1
0
ds
 1
0
âˆ¥Â¯X(Î³n(t âˆ’s) + s) âˆ’Â¯X(t)âˆ¥Î±
V dt.
(4.2.7)
Given s âˆˆ[0, 1) and n âˆˆN, let the partition In(s) be deï¬ned by
tn
0(s) := 0, tn
i (s) :=
	
s âˆ’[2ns]
2n

+ i âˆ’1
2n , 1 â‰¤i â‰¤2n, tn
2n+1(s) := 1.
Then, for t âˆˆ[tn
iâˆ’1(s), tn
i (s)[, 1 â©½i â©½2n + 1, one has t âˆ’s âˆˆ[2âˆ’n(i âˆ’[2ns] âˆ’
2), 2âˆ’n(i âˆ’[2ns] âˆ’1)[ and hence,
Î³n(t âˆ’s) + s =

2âˆ’n(i âˆ’[2ns] âˆ’2) + s
+ = tn
iâˆ’1(s),
1 â‰¤i â‰¤2n + 1.
Therefore, (4.2.7) implies
lim
nâ†’âˆE
 1
0
ds
 1
0
âˆ¥Â¯X(t) âˆ’Â¯Xn,s(t)âˆ¥Î±
V dt = 0,
where Â¯Xn,s is the process deï¬ned as Â¯Xl for the partition In(s) but with
X(tl
iâˆ’1(s)) replaced by Â¯X(tl
iâˆ’1(s)). Similarly, the same holds for ËœXn,s in place
of Â¯Xn,s by using ËœÎ³n := Î³n + 2âˆ’n instead of Î³n, where ËœXn,s is deï¬ned as ËœXl
for the partition In(s) but with X(tl
i(s)) replaced by Â¯X(tl
i(s)). Hence, there
exist a subsequence nk â†’âˆand a ds-zero set N1 âˆˆB([0, 1]) such that
lim
kâ†’âˆE
 1
0

âˆ¥Â¯X(t)âˆ’Â¯Xnk,s(t)âˆ¥Î±
V +âˆ¥Â¯X(t)âˆ’ËœXnk,s(t)âˆ¥Î±
V

dt = 0,
s âˆˆ[0, 1]\N1.
Since for 1 â‰¤i â‰¤2n the maps s 	â†’tn
i (s) are piecewise C1-diï¬€eomorphisms,
the image measures of ds under these maps are absolutely continuous with
respect to ds. Therefore, since Â¯X = X ds âŠ—P-a.e., there exists a ds-zero set
N2 âˆˆB([0, 1]) such that

78
4. A Class of Stochastic Diï¬€erential Equations
Â¯X(tn
i (s)) = X(tn
i (s)) P-a.e. for all s âˆˆ[0, 1] \ N2, 1 â‰¤i â‰¤2n.
Since for any s âˆˆ[0, 1] \ (N1 âˆªN2) one has E

âˆ¥Â¯X(tn
i (s))âˆ¥Î±
V

< âˆ, the map
[0, 1] Ã— â„¦âˆ‹(s, Ï‰) 	â†’X(tn
i (s), Ï‰) âˆˆV
is once again (a
dt âŠ—P-version of an element) in K. Therefore, ï¬xing
s âˆˆ[0, 1]\(N1âˆªN2), the sequence of the corresponding partitions Inl(s), l â‰¥1,
has all properties of the assertion.
Remark 4.2.7. As follows from the above proof all the partition points tl
i, l â‰¥
1, 1 â‰¤i â‰¤kl âˆ’1, in the assertion of Lemma 4.2.6 can be chosen outside an a
priori given Lebesgue zero set in [0, T] instead of N2 above.
Proof of Theorem 4.2.5. Since M(t) :=
' t
0 Z(s) dW(s), t âˆˆ[0, T], is already
a continuous martingale on H and since Y âˆˆKâˆ—= LÎ±/(Î±âˆ’1)([0, T] Ã— â„¦â†’
V âˆ—; dt âŠ—P) is progressively measurable,
' t
0 Y (s) ds is a continuous adapted
process on V âˆ—. Thus, X is a continuous adapted process on V âˆ—, hence
B([0, T]) âŠ—F/B(V âˆ—)-measurable.
Claim (a):
âˆ¥X(t)âˆ¥2
H =âˆ¥X(s)âˆ¥2
H + 2
 t
s
V âˆ—âŸ¨Y (r), X(t)âŸ©V dr + 2âŸ¨X(s), M(t) âˆ’M(s)âŸ©H
+ âˆ¥M(t) âˆ’M(s)âˆ¥2
H âˆ’âˆ¥X(t) âˆ’X(s) âˆ’M(t) + M(s)âˆ¥2
H
(4.2.8)
holds for all t > s such that X(t), X(s) âˆˆV.
Indeed, this follows immediately by noting that
âˆ¥M(t) âˆ’M(s)âˆ¥2
H âˆ’âˆ¥X(t) âˆ’X(s) âˆ’M(t) + M(s)âˆ¥2
H
+ 2âŸ¨X(s), M(t) âˆ’M(s)âŸ©H
= 2âŸ¨X(t) âˆ’X(s), M(t) âˆ’M(s)âŸ©H âˆ’âˆ¥X(t) âˆ’X(s)âˆ¥2
H
+ 2âŸ¨X(s), M(t) âˆ’M(s)âŸ©H
= 2âŸ¨X(t), M(t) âˆ’M(s)âŸ©H âˆ’âˆ¥X(t) âˆ’X(s)âˆ¥2
H
= 2âŸ¨X(t), X(t) âˆ’X(s)âŸ©H âˆ’2
 t
s
V âˆ—âŸ¨Y (r), X(t)âŸ©V dr
âˆ’âˆ¥X(t)âˆ¥2
H âˆ’âˆ¥X(s)âˆ¥2
H + 2âŸ¨X(t), X(s)âŸ©H
= âˆ¥X(t)âˆ¥2
H âˆ’âˆ¥X(s)âˆ¥2
H âˆ’2
 t
s
V âˆ—âŸ¨Y (r), X(t)âŸ©V dr.

4.2. The main result and an ItË†o formula
79
Claim (b): We have
E

sup
tâˆˆ[0,T ]
âˆ¥X(t)âˆ¥2
H

< âˆ.
(4.2.9)
Indeed, by (4.2.8), for any t = tl
i âˆˆIl \ {0, T} given in Lemma 4.2.6,
âˆ¥X(t)âˆ¥2
H âˆ’âˆ¥X0âˆ¥2
H
=
iâˆ’1

j=0
(âˆ¥X(tl
j+1)âˆ¥2
H âˆ’âˆ¥X(tl
j)âˆ¥2
H)
= 2
 t
0
V âˆ—âŸ¨Y (s), ËœXl(s)âŸ©V ds
+ 2
 t
0
âŸ¨Â¯Xl(s), Z(s) dW(s)âŸ©H + 2âŸ¨X(0),
 tl
1
0
Z(s) dW(s)âŸ©H
+
iâˆ’1

j=0

âˆ¥M(tl
j+1) âˆ’M(tl
j)âˆ¥2
H âˆ’âˆ¥X(tl
j+1) âˆ’X(tl
j) âˆ’M(tl
j+1) + M(tl
j)âˆ¥2
H

.
(4.2.10)
We note that since Â¯Xl is pathwise bounded the stochastic integral involving
Â¯Xl above is well-deï¬ned. By Lemma 4.2.6
E
 T
0
| V âˆ—âŸ¨Y (s), ËœXl(s)âŸ©V | ds

â‰¤âˆ¥Y âˆ¥Kâˆ—âˆ¥ËœXlâˆ¥K â‰¤c1
(4.2.11)
for some constant c1 > 0 independent of l. Moreover, by the Burkholderâ€“Davis
inequality (cf. Proposition D.0.1), Lemmas 2.4.2 and 2.4.3,
E

sup
tâˆˆ[0,T ]

 t
0
âŸ¨Â¯Xl(s), Z(s) dW(s)âŸ©H


â©½3E
1  T
0
âˆ¥Z(s)âˆ—Â¯Xl(s)âˆ¥2
U ds
21/2
â©½3E
1  T
0
âˆ¥Â¯Xl(s)âˆ¥2
Hâˆ¥Z(s)âˆ¥2
L2(U,H) ds
21/2
=3E
1  T
0
âˆ¥Â¯Xl(s)âˆ¥2
H dâŸ¨MâŸ©s
21/2
â‰¤1
4E

sup
klâˆ’1â‰¥jâ‰¥0
âˆ¥X(tl
j)âˆ¥2
H

+ 9E

âŸ¨MâŸ©T

,
(4.2.12)

80
4. A Class of Stochastic Diï¬€erential Equations
where âŸ¨MâŸ©t =
' t
0 âˆ¥Z(s)âˆ¥2
L2(U,H) ds and we used that
ab â©½1
12a2 + 3b2, a, b > 0.
Finally, by Lemma 2.4.3
E
â›
â
iâˆ’1

j=0
âˆ¥M(tl
j+1) âˆ’M(tl
j)âˆ¥2
H
â
â =
iâˆ’1

j=0
E
 tl
j+1
tl
j
âˆ¥Z(s)âˆ¥2
L2(U,H) ds

= E
 tl
i
0
âˆ¥Z(s)âˆ¥2
L2(U,H) ds

= E
	
âŸ¨MâŸ©tl
i

.
(4.2.13)
Combining (4.2.10)â€“(4.2.13), we obtain
E

sup
tâˆˆIl\{T }
âˆ¥X(t)âˆ¥2
H

â‰¤c2
for some constant c2 > 0 independent of l. Therefore, letting l â†‘âˆand setting
I := âˆªlâ‰¥1Il \ {T}, with Il as in Lemma 4.2.6, we obtain
E

sup
tâˆˆI
âˆ¥X(t)âˆ¥2
H

â©½c2,
since Il âŠ‚Il+1 for all l âˆˆN. Since for all t âˆˆ[0, T]
N

j=1
V âˆ—âŸ¨X(t), ejâŸ©2
V â†‘âˆ¥X(t)âˆ¥2
H as N â†‘âˆ,
where {ej
j âˆˆN} âŠ‚V is an orthonormal basis of H and as usual for x âˆˆV âˆ—\H
we set âˆ¥xâˆ¥H := âˆ, it follows that t 	â†’âˆ¥X(t)âˆ¥H is lower semicontinuous P-a.s.
Since I is dense in [0, T], we arrive at suptâˆˆ[0,T ] âˆ¥X(t)âˆ¥2
H = suptâˆˆI âˆ¥X(t)âˆ¥2
H.
Thus, (4.2.9) holds.
Claim (c):
lim
lâ†’âˆsup
tâˆˆ[0,T ]

 t
0
âŸ¨X(s) âˆ’Â¯Xl(s), Z(s) dW(s)âŸ©H
 = 0 in probability.
(4.2.14)
We ï¬rst note that because of (b) X is H-valued and by its continuity in V âˆ—the
process X is weakly continuous in H and, therefore, since B(H) is generated
by Hâˆ—, progressively measurable as an H-valued process. Hence, for any n âˆˆN
the process PnX(s) is continuous in H so that

4.2. The main result and an ItË†o formula
81
lim
lâ†’âˆ
 T
0
âˆ¥Pn(X(s) âˆ’Â¯Xl(s))âˆ¥2
H dâŸ¨MâŸ©s = 0,
P-a.s..
Here Pn denotes the orthogonal projection onto span{e1, . . . , en} in H. There-
fore, it suï¬ƒces to show that for any Îµ > 0,
lim
nâ†’âˆsup
lâˆˆN
P

sup
tâˆˆ[0,T ]

 t
0
âŸ¨(1 âˆ’Pn) Â¯Xl(s), Z(s) dW(s)âŸ©H
 > Îµ

= 0,
lim
nâ†’âˆP

sup
tâˆˆ[0,T ]

 t
0
âŸ¨(1 âˆ’Pn)X(s), Z(s) dW(s)âŸ©H
 > Îµ

= 0.
(4.2.15)
For any n âˆˆN, Î´ âˆˆ(0, 1) and N > 1 by Corollary D.0.2 we have that
P

sup
tâˆˆ[0,T ]

 t
0
âŸ¨(1 âˆ’Pn) Â¯Xl(s), Z(s) dW(s)âŸ©H
 > Îµ

â‰¤3Î´
Îµ + P
  T
0
âˆ¥Â¯Xl(s)âˆ¥2
H dâŸ¨(1 âˆ’Pn)MâŸ©s > Î´2

â‰¤3Î´
Îµ + P
	
sup
tâˆˆ[0,T ]
âˆ¥X(t)âˆ¥H > N

+ N 2
Î´2 EâŸ¨(1 âˆ’Pn)MâŸ©T .
By ï¬rst letting n â†’âˆ, and using Lemma 2.4.3, and then letting N â†’âˆ
and ï¬nally Î´ â†’0, we prove the ï¬rst equality in (4.2.15). Similarly, the second
equality is proved.
Claim (d): (4.2.4) holds for t âˆˆI.
Fix t âˆˆI. We may assume that t Ì¸= 0. In this case for each suï¬ƒciently large l âˆˆ
N there exists a unique 0 < i < kl such that t = tl
i. We have X(tl
j) âˆˆV a.s. for
all j. By Lemma 4.2.6 and (4.2.14) the sum of the ï¬rst three terms in the right-
hand side of (4.2.10) converges in probability to 2
' t
0
V âˆ—âŸ¨Y (s), Â¯X(s)âŸ©V ds +
2
' t
0âŸ¨X(s), Z(s) dW(s)âŸ©H, as l â†’âˆ. Hence by Lemma 2.4.3
âˆ¥X(t)âˆ¥2
H âˆ’âˆ¥X(0)âˆ¥2
H
= 2
 t
0
V âˆ—âŸ¨Y (s), Â¯X(s)âŸ©V ds + 2
 t
0
âŸ¨X(s), Z(s) dW(s)âŸ©H + âŸ¨MâŸ©t âˆ’Îµ0,
where
Îµ0 := P âˆ’lim
lâ†’âˆ
iâˆ’1

j=0
âˆ¥X(tl
j+1) âˆ’X(tl
j) âˆ’M(tl
j+1) + M(tl
j)âˆ¥2
H

82
4. A Class of Stochastic Diï¬€erential Equations
exists and â€œP âˆ’limâ€ denotes limit in probability. So, to prove (4.2.4) for t as
above, it suï¬ƒces to show that Îµ0 = 0. Since for any Ï• âˆˆV ,
âŸ¨X(tl
j+1) âˆ’X(tl
j) âˆ’M(tl
j+1) + M(tl
j), Ï•âŸ©H =
 tl
j+1
tl
j
V âˆ—âŸ¨Y (s), Ï•âŸ©V ds,
letting Ëœ
M l and Â¯
M l be deï¬ned as ËœXl and Â¯Xl respectively, for M replacing X,
we obtain for every n âˆˆN
Îµ0 = P âˆ’lim
lâ†’âˆ
  t
0
V âˆ—âŸ¨Y (s), ËœXl(s) âˆ’Â¯Xl(s) âˆ’Pn( Ëœ
M l(s) âˆ’Â¯
M l(s))âŸ©V ds
âˆ’âŸ¨X(tl
1) âˆ’X(0) âˆ’M(tl
1) + M(0), PnM(0) âˆ’X(0)âŸ©H
âˆ’
iâˆ’1

j=0
âŸ¨X(tl
j+1) âˆ’X(tl
j) âˆ’M(tl
j+1)
+ M(tl
j), (1 âˆ’Pn)(M(tl
j+1) âˆ’M(tl
j))âŸ©H

.
By the weak continuity of X in H the second term converges to zero as
l â†’âˆ. Lemma 4.2.6 implies that
' t
0 V âˆ—âŸ¨Y (s), ËœXl(s) âˆ’Â¯Xl(s)âŸ©V
ds â†’0 in
probability as l â†’âˆ. Moreover, since PnM(s) is a continuous process in V ,
' t
0 V âˆ—âŸ¨Y (s), Pn( Ëœ
M l(s) âˆ’Â¯
M l(s))âŸ©V ds â†’0 as l â†’âˆ. Thus, by Lemma 2.4.3
Îµ0 â‰¤P- lim
lâ†’âˆ
	 iâˆ’1

j=0
âˆ¥X(tl
j+1) âˆ’X(tl
j) âˆ’M(tl
j+1) + M(tl
j)âˆ¥2
H

 1
2
Â·
	 iâˆ’1

j=0
âˆ¥(1 âˆ’Pn)(M(tl
j+1) âˆ’M(tl
j))âˆ¥2
H

 1
2
= Îµ1/2
0
âŸ¨(1 âˆ’Pn)MâŸ©1/2
t
,
which goes to zero as n â†’âˆagain by Lemma 2.4.3 and Lebesgueâ€™s dominated
convergence theorem. Therefore, Îµ0 = 0.
Claim (e): (4.2.4) holds for all t âˆˆ[0, T]\I.
Take â„¦â€² âˆˆF with full probability such that the limit in (4.2.14) is a pointwise
limit in â„¦â€² for some subsequence (denoted again by l â†’âˆ) and (4.2.4) holds
for all t âˆˆI on â„¦â€². If t /âˆˆI, for any l âˆˆN there exists a unique j(l) < kl
such that t âˆˆ]tl
j(l), tl
j(l)+1]. Letting t(l) := tl
j(l), we have t(l) â†‘t as l â†‘âˆ. By
(4.2.4) for t âˆˆI, for any l > m we have on â„¦â€² (since the above applies to

4.2. The main result and an ItË†o formula
83
X âˆ’X(t(m)) replacing X)
âˆ¥X(t(l)) âˆ’X(t(m))âˆ¥2
H
= 2
 t(l)
t(m)
V âˆ—âŸ¨Y (s), Â¯X(s) âˆ’X(t(m))âŸ©V ds
+ 2
 t(l)
t(m)
âŸ¨X(s) âˆ’X(t(m)), Z(s) dW(s)âŸ©H + âŸ¨MâŸ©t(l) âˆ’âŸ¨MâŸ©(t(m)
= 2
 T
0
1[t(m),t(l)](s) V âˆ—âŸ¨Y (s), Â¯X(s) âˆ’Â¯Xm(s)âŸ©V ds
+ 2
 t(m)
t(l)
âŸ¨X(s) âˆ’Â¯Xm(s), Z(s) dW(s)âŸ©H + âŸ¨MâŸ©t(l) âˆ’âŸ¨MâŸ©(t(m).
(4.2.16)
The second summand is dominated by
4 sup
tâˆˆ[0,T ]

 t
0
âŸ¨X(s) âˆ’Â¯Xm(s), Z(s) dW(s)âŸ©H
 .
Thus, by the continuity of âŸ¨MâŸ©t and (4.2.14) (holding pointwise on â„¦â€²), we
have that
lim
mâ†’âˆsup
l>m

2

 T
0
1[t(m),t(l)](s)âŸ¨X(s) âˆ’Â¯Xm(s), Z(s) dW(s)âŸ©H

+ |âŸ¨MâŸ©t(l) âˆ’âŸ¨MâŸ©(t(m)|

= 0
(4.2.17)
holding on â„¦â€². Furthermore, by Lemma 4.2.6, selecting another subsequence
if necessary, we have for some â„¦â€²â€² âˆˆF with full probability and â„¦â€²â€² âŠ‚â„¦â€², that
on â„¦â€²â€²
lim
mâ†’âˆ
 T
0
| V âˆ—âŸ¨Y (s), Â¯X(s) âˆ’Â¯Xm(s)âŸ©V | ds = 0.
Since for all t /âˆˆI
sup
l>m
 t(l)
t(m)
| V âˆ—âŸ¨Y (s), Â¯X(s) âˆ’Â¯Xm(s)âŸ©V | ds
â‰¤
 T
0
| V âˆ—âŸ¨Y (s), Â¯X(s) âˆ’Â¯Xm(s)âŸ©V | ds,

84
4. A Class of Stochastic Diï¬€erential Equations
we have that
lim
mâ†’âˆsup
l>m
 t(l)
t(m)
V âˆ—âŸ¨Y (s), Â¯X(s) âˆ’Â¯Xm(s)âŸ©V ds = 0
holds on â„¦â€²â€².
Combining this with (4.2.16) and (4.2.17), we conclude that
lim
mâ†’âˆsup
lâ‰¥m
âˆ¥X(t(l)) âˆ’X(t(m))âˆ¥2
H = 0
holds on â„¦â€²â€². Thus, (X(t(l)))lâˆˆN converges in H on â„¦â€²â€². Since we know that
X(t(l)) â†’X(t) in V âˆ—, it converges to X(t) strongly in H on â„¦â€²â€². Therefore,
since (4.2.4) holds on â„¦â€²â€² for t(l), letting l â†’âˆ, we obtain (4.2.4) on â„¦â€²â€² also
for all t /âˆˆI.
Claim (f): X is strongly continuous in H.
Since the right-hand side of (4.2.4) is on â„¦â€²â€² continuous in t âˆˆ[0, T], so must
be its left-hand side, i.e. t 	â†’âˆ¥X(t)âˆ¥H is continuous on [0, T]. Therefore, the
weak continuity of X(t) in H implies its strong continuity in H.
Remark 4.2.8. In the situation of Theorem 4.2.5 we have
E(âˆ¥X(t)âˆ¥2
H)
= E(âˆ¥X0âˆ¥2
H) +
 t
0
E(2 V âˆ—âŸ¨Y (s), Â¯X(s)âŸ©V +âˆ¥Z(s)âˆ¥2
L2(U,H)) ds,
t âˆˆ[0, T].
(4.2.18)
Proof. Let M(t), t âˆˆ[0, T], denote the real valued local martingale in (4.2.4)
and let Ï„l, l âˆˆN, be (Ft)-stopping times such that M(t âˆ§Ï„l), t âˆˆ[0, T], is a
martingale and Ï„l â†‘âˆas l â†’âˆ. Then for all l âˆˆN, t âˆˆ[0, T], we have
E(âˆ¥X(t âˆ§Ï„l)âˆ¥2
H)
= E(âˆ¥X0âˆ¥2
H) +
 t
0
E(1[0,Ï„l](s)[2 V âˆ—âŸ¨Y (s), Â¯X(s)âŸ©V +âˆ¥Z(s)âˆ¥2
L2(U,H)]) ds.
(4.2.19)
Using Claim (b) from the proof of Theorem 4.2.5 and the fact that the inte-
grands on the right-hand side of (4.2.19) are dt âŠ—P-integrable we can apply
Lebesgueâ€™s dominated convergence theorem to obtain the assertion.
Now we turn to the proof of Theorem 4.2.4. We ï¬rst need some prepa-
rations. Let {ei|i âˆˆN} âŠ‚V be an orthonormal basis of H and let Hn :=
span{e1, . . . , en} such that span{ei|i âˆˆN} is dense in V . Let Pn : V âˆ—â†’Hn
be deï¬ned by
Pny :=
n

i=1
V âˆ—âŸ¨y, eiâŸ©V ei,
y âˆˆV âˆ—.
(4.2.20)

4.2. The main result and an ItË†o formula
85
Clearly, Pn|H is just the orthogonal projection onto Hn in H. Let {gi|i âˆˆN}
be an orthonormal basis of U and set
W (n)(t) :=
n

i=1
âŸ¨W(t), giâŸ©Ugi =
n

i=1
Bi(t) gi.
For each ï¬nite n âˆˆN we consider the following stochastic equation on Hn :
dX(n)(t)
= PnA(t, X(n)(t)) dt + PnB(t, X(n)(t)) dW (n)(t),
1 â‰¤j â‰¤n,
(4.2.21)
where X(n)(0) := PnX0. It is easily seen (cf. in particular Remark 4.1.1, parts
1 and 2) that we are in the situation of Theorem 3.1.1 which implies that
(4.2.21) has a unique continuous strong solution. Let
J := L2([0, T] Ã— â„¦, dt âŠ—P; L2(U, H)).
(4.2.22)
To construct the solution to (4.2.1), we need the following lemma.
Lemma 4.2.9. Under the assumptions in Theorem 4.2.4, there exists C âˆˆ
]0, âˆ[ such that
âˆ¥X(n)âˆ¥K + âˆ¥A(Â·, X(n))âˆ¥Kâˆ—+ sup
tâˆˆ[0,T ]
Eâˆ¥X(n)(t)âˆ¥2
H â‰¤C
(4.2.23)
for all n âˆˆN.
Proof. By the ï¬nite-dimensional ItË†o formula we have P-a.s.
âˆ¥X(n)(t)âˆ¥2
H = âˆ¥X(n)
0
âˆ¥2
H +
 t
0

2 V âˆ—âŸ¨A(s, X(n)(s)), X(n)(s)âŸ©V
+ âˆ¥Z(n)(s)âˆ¥2
L2(U,H)

ds + M (n)(t), t âˆˆ[0, T],
where Z(n)(s) := PnB(s, X(n)(s)) and
M (n)(t) := 2
 t
0
âŸ¨X(n)(s), PnB(s, X(n)(s)) dW (n)(s)âŸ©H, t âˆˆ[0, T],
is a local martingale. Let Ï„l, l âˆˆN, be (Ft)-stopping times such that âˆ¥X(n)(tâˆ§
Ï„l)(Ï‰)âˆ¥V is bounded uniformly in (t, Ï‰) âˆˆ[0, T] Ã— â„¦, M (n)(t âˆ§Ï„l), t âˆˆ[0, T], is
a martingale for each l âˆˆN and Ï„l â†‘âˆas l â†’âˆ. Then for all l âˆˆN, t âˆˆ[0, T]
E
	
âˆ¥X(n)(t âˆ§Ï„l)âˆ¥2
H

= E(âˆ¥X(n)
0
âˆ¥2
H) +
 t
0
E
	
1[0,Ï„l](s)(2 V âˆ—âŸ¨A(s, X(n)(s)), X(n)(s)âŸ©V
+ âˆ¥Z(n)(s)âˆ¥2
L2(U,H))

ds.

86
4. A Class of Stochastic Diï¬€erential Equations
Hence using the product rule we obtain
E(eâˆ’c1tâˆ¥X(n)(t âˆ§Ï„l)âˆ¥2
H)
= E(âˆ¥X(n)
0
âˆ¥2
H) +
 t
0
E(âˆ¥X(n)(s âˆ§Ï„l)âˆ¥2
H) d(eâˆ’c1s)
+
 t
0
eâˆ’c1s d(E(âˆ¥X(n)(s âˆ§Ï„l)âˆ¥2
H))
= E(âˆ¥X(n)
0
âˆ¥2
H) âˆ’
 t
0
c1E(âˆ¥X(n)(s âˆ§Ï„l)âˆ¥2
H)eâˆ’c1s ds
+
 t
0
eâˆ’c1sE
	
1[0,Ï„l](s)(2 V âˆ—âŸ¨A(s, X(n)(s)), X(n)(s)âŸ©V
+ âˆ¥Z(n)(s)âˆ¥2
L2(U,H))

ds.
(4.2.24)
Applying (H3) we arrive at
E(eâˆ’c1tâˆ¥X(n)(t âˆ§Ï„l)âˆ¥2
H) +
 t
0
c1E(âˆ¥X(n)(s âˆ§Ï„l)âˆ¥2
H)eâˆ’c1s ds
+ c2
 t
0
E(1[0,Ï„l](s)âˆ¥X(n)(s âˆ§Ï„l)âˆ¥Î±
V )eâˆ’c1s ds
â©½E(âˆ¥X(n)
0
âˆ¥2
H) +
 t
0
c1E(âˆ¥X(n)(s)âˆ¥2
H)eâˆ’c1s ds +
 T
0
E(|f(s)|) ds.
Now taking l â†’âˆand applying Fatouâ€™s lemma we get
E(eâˆ’c1tâˆ¥X(n)(t)âˆ¥2
H) + c2E
 t
0
âˆ¥X(n)(s)âˆ¥Î±
V eâˆ’c1s ds

â©½E(âˆ¥X(n)
0
âˆ¥2
H) + E
 T
0
|f(s)| ds

for all t âˆˆ[0, T]. Here we used that by Theorem 4.2.5 (applied to (4.2.21)) the
substracted terms are ï¬nite. Since âˆ¥X(n)
0
âˆ¥H â©½âˆ¥X0âˆ¥H, now the assertion fol-
lows for the ï¬rst and third summand in (4.2.23). For the remaining summand
the assertion then follows by (H4).
Proof of Theorem 4.2.4. By the reï¬‚exivity of K, Lemma 4.2.9 and Remark
4.1.1, part 1, we have, for a subsequence nk â†’âˆ:
(i) X(nk) â†’Â¯X weakly in K and weakly in L2([0, T] Ã— â„¦; dt âŠ—P; H).
(ii) Y (nk) := A(Â·, X(nk)) â†’Y weakly in Kâˆ—.

4.2. The main result and an ItË†o formula
87
(iii) Z(nk) := PnkB(Â·, X(nk)) â†’Z weakly in J and hence
 Â·
0
PnkB(s, X(nk)(s)) dW (nk)(s) â†’
 Â·
0
Z(s) dW(s)
weakly in Lâˆ([0, T], dt; L2(â„¦, P; H)) (equipped with the supremum
norm).
Here the second part in (iii) follows since also B(Â·, X(nk)) ËœPnk â†’Z weakly in
J, where ËœPn is the orthogonal projection onto span{g1, Â· Â· Â· , gn} in U, since
 Â·
0
PnkB(s, X(nk)(s)) dW (nk)(s) =
 Â·
0
PnkB(s, Xnk(s)) ËœPnk dW(s)
and since a bounded linear operator between two Banach spaces is trivially
weakly continuous. Since the approximants are progressively measurable, so
are (the dt âŠ—P-versions) Â¯X, Y and Z.
Thus from (4.2.21) for all v âˆˆ3
nâ©¾1 Hn, Ï• âˆˆLâˆ([0, T] Ã— â„¦) by Fubiniâ€™s
theorem we get
E
 T
0
V âˆ—âŸ¨Â¯X(t), Ï•(t)vâŸ©V dt

= lim
kâ†’âˆE
 T
0
V âˆ—âŸ¨X(nk)(t), Ï•(t)vâŸ©V dt

= lim
kâ†’âˆE
  T
0
V âˆ—âŸ¨X(nk)
0
, Ï•(t)vâŸ©V dt
+
 T
0
 t
0
V âˆ—âŸ¨PnkY (nk)(s), Ï•(t)vâŸ©V ds dt
+
 T
0
 t
0
Z(nk)(s) dW (nk)(s), Ï•(t)v

H
dt

= lim
kâ†’âˆ
1
E

âŸ¨X(nk)
0
, vâŸ©H
 T
0
Ï•(t) dt

+ E
 T
0
V âˆ—âŸ¨Y (nk)(s),
 T
s
Ï•(t) dt vâŸ©
V
ds

+
 T
0
E

Ï•(t)
 t
0
Z(nk)(s) dW (nk)(s), v

H

dt
2
= E
  T
0
V âˆ—âŸ¨X0 +
 t
0
Y (s) ds +
 t
0
Z(s) dW(s), Ï•(t)vâŸ©
V
dt

.

88
4. A Class of Stochastic Diï¬€erential Equations
Therefore, deï¬ning
X(t) := X0 +
 t
0
Y (s) ds +
 t
0
Z(s) dW(s),
t âˆˆ[0, T],
(4.2.25)
we have X = Â¯X dt âŠ—P-a.e.
Now Theorem 4.2.5 applies to X in (4.2.25), so X is continuous in H and
E

sup
tâ‰¤T
âˆ¥X(t)âˆ¥2
H

< âˆ.
Thus, it remains to verify that
B(Â·, Â¯X) = Z,
A(Â·, Â¯X) = Y,
dt âŠ—P-a.e..
(4.2.26)
To this end, we ï¬rst note that for any nonnegative Ïˆ âˆˆLâˆ([0, T], dt; R) it
follows from (i) that
E
 T
0
Ïˆ(t)âˆ¥Â¯X(t)âˆ¥2
H dt

= lim
kâ†’âˆE
 T
0
âŸ¨Ïˆ(t) Â¯X(t), X(nk)(t)âŸ©H dt

â‰¤

E
 T
0
Ïˆ(t)âˆ¥Â¯X(t)âˆ¥2
H dt
1/2
lim inf
kâ†’âˆ

E
 T
0
Ïˆ(t)âˆ¥X(nk)(t)âˆ¥2
H dt
1/2
< âˆ.
Since X = Â¯X dt âŠ—P-a.e., this implies
E
 T
0
Ïˆ(t)âˆ¥X(t)âˆ¥2
H dt

â‰¤lim inf
kâ†’âˆE
 T
0
Ïˆ(t)âˆ¥X(nk)(t)âˆ¥2
H dt

.
(4.2.27)
By (4.2.25) using Remark 4.2.8 and the product rule we obtain that
E

eâˆ’ctâˆ¥X(t)âˆ¥2
H

âˆ’E

âˆ¥X0âˆ¥2
H

= E
 t
0
eâˆ’cs
2 V âˆ—âŸ¨Y (s), Â¯X(s)âŸ©V + âˆ¥Z(s)âˆ¥2
L2(U,H) âˆ’câˆ¥X(s)âˆ¥2
H

ds

.
(4.2.28)
Furthermore, for any Ï† âˆˆK âˆ©L2([0, T] Ã— â„¦, dt âŠ—P; H) and taking l â†’âˆin

4.2. The main result and an ItË†o formula
89
(4.2.24) with c1 replaced by c
E
	
eâˆ’ctâˆ¥X(nk)(t)âˆ¥2
H

âˆ’E
	
âˆ¥X(nk)
0
âˆ¥2
H

= E
  t
0
eâˆ’cs
2 V âˆ—âŸ¨A(s, X(nk)(s)), X(nk)(s)âŸ©V
+ âˆ¥PnkB(s, X(nk)(s)) ËœPnkâˆ¥2
L2(U,H) âˆ’câˆ¥X(nk)(s)âˆ¥2
H

ds

â‰¤E
  t
0
eâˆ’cs
2 V âˆ—âŸ¨A(s, X(nk)(s)), X(nk)(s)âŸ©V
+ âˆ¥B(s, X(nk)(s))âˆ¥2
L2(U,H) âˆ’câˆ¥X(nk)(s)âˆ¥2
H

ds

= E
  t
0
eâˆ’cs	
2 V âˆ—âŸ¨A(s, X(nk)(s)) âˆ’A(s, Ï†(s)), X(nk)(s) âˆ’Ï†(s)âŸ©V
+ âˆ¥B(s, X(nk)(s)) âˆ’B(s, Ï†(s))âˆ¥2
L2(U,H) âˆ’câˆ¥X(nk)(s) âˆ’Ï†(s)âˆ¥2
H

ds
+ E
  t
0
eâˆ’cs	
2 V âˆ—âŸ¨A(s, Ï†(s)), X(nk)(s)âŸ©V
+ 2 V âˆ—âŸ¨A(s, X(nk)(s)) âˆ’A(s, Ï†(s)), Ï†(s)âŸ©V
âˆ’âˆ¥B(s, Ï†(s))âˆ¥2
L2(U,H) + 2âŸ¨B(s, X(nk)(s)), B(s, Ï†(s))âŸ©L2(U,H)
âˆ’2câŸ¨X(nk)(s), Ï†(s)âŸ©H + câˆ¥Ï†(s)âˆ¥2
H

ds

.
(4.2.29)
Note that by (H2) the ï¬rst of the two summands above is negative. Hence by
letting k â†’âˆwe conclude by (i)â€“(iii), Fubiniâ€™s theorem, and (4.2.27) that
for every nonnegative Ïˆ âˆˆLâˆ([0, T], dt; R)
E
 T
0
Ïˆ(t)(eâˆ’ctâˆ¥X(t)âˆ¥2
H âˆ’âˆ¥X0âˆ¥2
H) dt

â‰¤E
  T
0
Ïˆ(t)
  t
0
eâˆ’cs%
2 V âˆ—âŸ¨A(s, Ï†(s)), Â¯X(s)âŸ©V + 2 V âˆ—âŸ¨Y (s)
âˆ’A(s, Ï†(s)), Ï†(s)âŸ©V âˆ’âˆ¥B(s, Ï†(s))âˆ¥2
L2(U,H) + 2âŸ¨Z(s), B(s, Ï†(s))âŸ©L2(U,H)
âˆ’2câŸ¨X(s), Ï†(s)âŸ©H + câˆ¥Ï†(s)âˆ¥2
H
&
ds

dt

.

90
4. A Class of Stochastic Diï¬€erential Equations
Inserting (4.2.28) for the left-hand side and rearranging as above we arrive at
0 â‰¥E
  T
0
Ïˆ(t)
  t
0
eâˆ’cs
2 V âˆ—âŸ¨Y (s) âˆ’A(s, Ï†(s)), Â¯X(s) âˆ’Ï†(s)âŸ©V
+ âˆ¥B(s, Ï†(s)) âˆ’Z(s)âˆ¥2
L2(U,H) âˆ’câˆ¥X(s) âˆ’Ï†(s)âˆ¥2
H

ds

dt

.
(4.2.30)
Taking Ï† = Â¯X we obtain from (4.2.30) that Z = B(Â·, Â¯X). Finally, ï¬rst applying
(4.2.30) to Ï† = Â¯X âˆ’ÎµËœÏ† v for Îµ > 0 and ËœÏ† âˆˆLâˆ([0, T] Ã— â„¦, dt âŠ—P; R), v âˆˆV ,
then dividing both sides by Îµ and letting Îµ â†’0, by Lebesgueâ€™s dominated
convergence theorem, (H1) and (H4), we obtain
0 â‰¥E
 T
0
Ïˆ(t)
  t
0
eâˆ’cs ËœÏ†(s) V âˆ—âŸ¨Y (s) âˆ’A(s, Â¯X(s)), vâŸ©V ds

dt

.
By the arbitrariness of Ïˆ and ËœÏ†, we conclude that Y = A(Â·, Â¯X). This completes
the existence proof.
The uniqueness is a consequence of the following proposition.
Proposition 4.2.10. Consider the situation of Theorem 4.2.4 and let X, Y
be two solutions. Then for c âˆˆR as in (H2)
E(âˆ¥X(t) âˆ’Y (t)âˆ¥2
H) â©½ectE(âˆ¥X(0) âˆ’Y (0)âˆ¥2
H) for all t âˆˆ[0, T].
(4.2.31)
Proof. We ï¬rst note that by our deï¬nition of solution (cf. Deï¬nition 4.2.1)
and by Remark 4.1.1, part 1 we can apply Remark 4.2.8 to X âˆ’Y and obtain
for t âˆˆ[0, T]
E(âˆ¥X(t) âˆ’Y (t)âˆ¥2
H) = E(âˆ¥X0 âˆ’Y0âˆ¥2
H)
+
 t
0
E(2 V âˆ—âŸ¨A(s, Â¯X(s)) âˆ’A(s, Â¯Y (s)), Â¯X(s) âˆ’Â¯Y (s)âŸ©V
+ âˆ¥B(s, X(s)) âˆ’B(s, Y (s))âˆ¥2
L2(U,H)) ds
â©½E(âˆ¥X0 âˆ’Y0âˆ¥2
H) + c
 t
0
E(âˆ¥X(s) âˆ’Y (s)âˆ¥2
H) ds,
where we used (H2) in the last step. Applying Gronwallâ€™s lemma we obtain
the assertion.
Remark 4.2.11. Let s âˆˆ[0, T] and Xs âˆˆL2(â„¦, Fs, P; H). Consider the
equation
X(t) = Xs +
 t
s
A(u, Â¯X(u)) du +
 t
s
B(u, Â¯X(u)) dW(u), t âˆˆ[s, T] (4.2.32)

4.3. Markov property and invariant measures
91
with underlying Wiener process W(t)âˆ’W(s), t âˆˆ[s, T], and ï¬ltration (Ft)tâ©¾s,
i.e. we just start our time at s. We deï¬ne the notion of solution for (4.2.32)
analogously to Deï¬nition 4.2.1. Then all results above in the case s = 0 carry
over to this more general case. In particular, there exists a unique solution with
initial condition Xs denoted by X(t, s, Xs), t âˆˆ[s, T]. Let 0 â©½r â©½s â©½T.
Then for Xr âˆˆL2(â„¦, Fr, P; H)
X(t, r, Xr) = X(t, s, X(s, r, Xr)), t âˆˆ[s, T] P-a.e.
(4.2.33)
Indeed, we have
X(t, r, Xr) = Xr +
 t
r
A(u, Â¯X(u, r, Xr)) du +
 t
r
B(u, Â¯X(u, r, Xr)) dW(u)
= X(s, r, Xr) +
 t
s
A(u, Â¯X(u, r, Xr)) du
+
 t
s
B(u, Â¯X(u, r, Xr)) dW(u),
t âˆˆ[s, T].
But by deï¬nition X(t, s, X(s, r, Xr)), t âˆˆ[s, T], satisï¬es the same equation.
So, (4.2.33) follows by uniqueness. Furthermore, if for s âˆˆ[0, T], Xs = x for
some x âˆˆH and A and B are independent of Ï‰ âˆˆâ„¦, then X(t, s, x) obviously
is independent of Fs for all t âˆˆ[s, T], since so are collections of increments
of W(t), t âˆˆ[s, T].
4.3. Markov property and invariant measures
Now we are going to prove some qualitative results about the solutions of
(4.2.1) or (4.2.32) and about their transition probabilities, i.e. about
ps,t(x, dy) := P â—¦(X(t, s, x))âˆ’1(dy), 0 â©½s â©½t â©½T, x âˆˆH.
(4.3.1)
As usual we set for B(H)-measurable F : H â†’R, and t âˆˆ[s, T], x âˆˆH
ps,tF(x) :=

F(y)ps,t(x, dy),
provided F is ps,t(x, dy)-integrable.
Remark 4.3.1. The measures ps,t(x, dy), 0 â©½s â©½t â©½T, x âˆˆH, could in
principle depend on the chosen Wiener process and the respective ï¬ltration.
However, the construction of our solutions X(t, s, x), t âˆˆ[s, T], suggests that
this is not the case. This can be rigorously proved in several ways. It is e.g. a
consequence of the famous Yamadaâ€“Watanabe theorem which is included in
Appendix E below in a ï¬nite-dimensional case, which immediately extends to
inï¬nite dimensions if the underlying Wiener process has covariance of ï¬nite
trace. For the case of a cylindrical Wiener process we refer to [Ond04]. In
these notes we shall use the latter as a fact referring to this remark each time
we do so.

92
4. A Class of Stochastic Diï¬€erential Equations
Proposition 4.3.2. Consider the situation of Theorem 4.2.4. Let F : H â†’R
be Lipschitz with
Lip(F) :=
sup
x,yâˆˆH,xÌ¸=y
|F(x) âˆ’F(y)|
âˆ¥x âˆ’yâˆ¥H
(< âˆ)
denoting its Lipschitz constant. Then for all 0 â©½s â©½t â©½T
ps,t|F|(x) < âˆfor all x âˆˆH
and for all x, y âˆˆH
|ps,tF(x) âˆ’ps,tF(y)| â©½e
c
2 (tâˆ’s)Lip(F) âˆ¥x âˆ’yâˆ¥H,
(4.3.2)
where c is as in (H2).
Proof. Clearly, for all x âˆˆH
|F(x)| â©½|F(0)| + Lip(F) âˆ¥xâˆ¥H,
and thus for all 0 â©½s â©½t â©½T
ps,t|F|(x) = E(|F|(X(t, s, x)))
â©½|F(0)| + Lip(F) E(âˆ¥X(t, s, x)âˆ¥H)
â©½|F(0)| + Lip(F)

E

sup
tâˆˆ[s,T ]
âˆ¥X(t, s, x)âˆ¥2
H
1/2
< âˆ.
Furthermore, for x, y âˆˆH by (the â€œstarted at sâ€ analogue of) (4.2.31)
|ps,tF(x) âˆ’ps,tF(y)| â©½E(|F(X(t, s, x)) âˆ’F(X(t, s, y)))|)
â©½Lip(F) E(âˆ¥X(t, s, x) âˆ’X(t, s, y)âˆ¥H)
â©½Lip(F) e
c
2 (tâˆ’s)âˆ¥x âˆ’yâˆ¥H.
Proposition 4.3.3. Consider the situation of Theorem 4.2.4 and, in addition,
assume that both A and B as well as f and g in (H3),(H4) respectively, are
independent of Ï‰ âˆˆâ„¦. Then any solution X(t), t âˆˆ[r, T], of (4.2.32) (with r
replacing s) is Markov in the following sense:
for every bounded, B(H)-measurable F : H â†’R, and all s, t âˆˆ[r, T], s â©½t
E(F(X(t))|Fs)(Ï‰) = E(F(X(t, s, X(s)(Ï‰)))) for P-a.e. Ï‰ âˆˆâ„¦.
(4.3.3)

4.3. Markov property and invariant measures
93
Proof. Clearly, by a monotone class argument we may assume F in (4.3.3)
to be Lipschitz continuous. We ï¬rst note that by Proposition 4.3.2 for all
0 â©½s â©½t â©½T the map
H âˆ‹x 	â†’E(F(X(t, s, x))) = ps,tF(x)
is Lipschitz on H. So, the right-hand side of (4.3.3) is Fs-measurable. Further-
more, for any bounded Fs-measurable function Fs : â„¦â†’R, applying (4.2.33)
we have
E(FsF(X(t))) = E(FsF(X(t, s, X(s)))).
(4.3.4)
By Lemma A.1.4 there exists a sequence of H-valued Fs-measurable simple
functions
fn : â„¦â†’H, fn =
Nn

k=1
h(n)
k 1{fn=h(n)
k
},
Nn âˆˆN,
where h(n)
1 , . . . , h(n)
Nn âˆˆH are pairwise distinct and â„¦= 3Nn
k=1{fn = h(n)
k },
such that
âˆ¥fn(Ï‰) âˆ’X(s)(Ï‰)âˆ¥H â†“0 as n â†’âˆfor all Ï‰ âˆˆâ„¦.
Hence again by (the â€œs-shifted versionâ€ of) (4.2.31) the right-hand side of
(4.3.4) is equal to
lim
nâ†’âˆE(FsF(X(t, s, fn)))
= lim
nâ†’âˆ
Nn

k=1
E
	
Fs1{fn=h(n)
k
}F(X(t, s, h(n)
k ))

= lim
nâ†’âˆ
Nn

k=1
E
	
Fs1{fn=h(n)
k
}

E
	
F(X(t, s, h(n)
k ))

= lim
nâ†’âˆE

Fs
Nn

k=1
1{fn=h(n)
k
}E
	
F(X(t, s, h(n)
k ))


= lim
nâ†’âˆ

Fs(Ï‰)E(F(X(t, s, fn(Ï‰))))P(dÏ‰)
=

Fs(Ï‰)E(F(X(t, s, X(s)(Ï‰))))P(dÏ‰),
where we used the last part of Remark 4.2.11 for the ï¬rst and again (4.2.31)
for the last equality. Now the assertion follows.
Corollary 4.3.4. Consider the situation of Proposition 4.3.3 and let 0 â©½r â©½
s â©½t â©½T. Then
pr,sps,t = pr,t,
(4.3.5)

94
4. A Class of Stochastic Diï¬€erential Equations
i.e. for F : H â†’R, bounded and B(H)-measurable, x âˆˆH,
pr,s(ps,tF)(x) = pr,tF(x).
Proof. For F : H â†’R as above and x âˆˆH by Proposition 4.3.3 we have
pr,s(ps,tF)(x) = E(ps,tF(X(s, r, x))) =

E(F(X(t, s, X(s, r, x)(Ï‰))))P(dÏ‰)
=

E(F(X(t, r, x))|Fs)(Ï‰)P(dÏ‰)
= E(F(X(t, r, x))) = pr,tF(x).
Now let us assume that in the situation of Theorem 4.2.4 both A and B as
well as f and g in (H3), (H4) respectively are independent of (t, Ï‰) âˆˆ[0, T]Ã—â„¦
(so they particularly hold for all T âˆˆ[0, âˆ[). Then again using the notation
introduced in Remark 4.2.11 for 0 â©½s â©½t < âˆand x âˆˆH we have
X(t, s, x) = X
Ëœ
W (t âˆ’s, 0, x) P-a.e.,
(4.3.6)
where X Ëœ
W (t, 0, x), t âˆˆ[0, âˆ[, is the solution of
X(t) = x +
 t
0
A( Â¯X(u)) du +
 t
0
B( Â¯X(u)) d ËœW(u)
and ËœW := W(Â· + s) âˆ’W(s) with ï¬ltration Fs+u, u âˆˆ[0, âˆ[, which is again
a Wiener process. To show this let us express the dependence of the solution
X(t, s, x), s âˆˆ[t, âˆ) of (4.2.32) with Xs := x on the Wiener process W by
writing XW (t, s, x) instead of X(t, s, x) and similarly, pW
s,t(s, dy) instead of
ps,t(x, dy). Then, for all 0 â©½s â©½t < âˆ
XW ((t âˆ’s) + s, s, x)
=XW (t, s, x)
=x +
 t
s
A( Â¯XW (u, s, x)) du +
 t
s
B( Â¯XW (u, s, x)) dW(u)
=x +
 tâˆ’s
0
A( Â¯XW (u + s, s, x)) du +
 tâˆ’s
0
B( Â¯XW (u + s, s, x)) d ËœW(u),
So, by uniqueness the process XW (u+s, s, x), u âˆˆ[0, âˆ[, must P-a.e. coincide
with X Ëœ
W (u, 0, x), u âˆˆ[0, âˆ[. In particular, it follows by Remark 4.3.1 that
pW
s,t(x, dy) = P â—¦(X
Ëœ
W (t âˆ’s, 0, x))âˆ’1(dy) = p
Ëœ
W
0,tâˆ’s(x, dy) = pW
0,tâˆ’s(x, dy)
(4.3.7)

4.3. Markov property and invariant measures
95
(â€œtime homogeneityâ€), where we used Remark 4.3.1 for the last equality.
Deï¬ning
pt := pW
0,t,
t âˆˆ[0, âˆ[,
equality (4.3.5) for r = 0 and s + t replacing t turns into
ps+t = pspt for s, t âˆˆ[0, âˆ[.
(4.3.8)
For x âˆˆH we deï¬ne
Px := P â—¦(X(Â·, 0, x))âˆ’1,
(4.3.9)
i.e. Px is the distribution of the solution to (4.2.1) with initial condition x âˆˆH,
deï¬ned as a measure on C([0, âˆ[, H). We equip C([0, âˆ[, H) with the Ïƒ-
algebra
G := Ïƒ(Ï€s|s âˆˆ[0, âˆ[)
and ï¬ltration
Gt := Ïƒ(Ï€s|s âˆˆ[0, t]), t âˆˆ[0, âˆ[,
where Ï€t(w) := w(t) for w âˆˆC([0, âˆ[, H), t âˆˆ[0, âˆ[.
Proposition 4.3.5. Consider the situation of Theorem 4.2.4 and, in addition,
assume that both A and B as well as f and g in (H3),(H4) respectively, are
independent of (t, Ï‰) âˆˆ[0, T]Ã—â„¦(so they particularly hold for all T âˆˆ[0, âˆ[).
Then the following assertions hold:
1. Px, x âˆˆH, form a time-homogenous Markov process on C([0, âˆ), H)
with respect to the ï¬ltration Gt, t âˆˆ[0, âˆ[, i.e. for all s, t âˆˆ[0, âˆ[, and
all bounded, B(H)-measurable F : H â†’R
Ex(F(Ï€t+s)|Gs) = EÏ€s(F(Ï€t))
Px âˆ’a.e.,
(4.3.10)
where Ex and Ex(Â·|Gs) denote expectation, conditional expectation with
respect to Px respectively.
2. Suppose dim H < âˆ. If there exist Î·, f âˆˆ]0, âˆ[ such that
2 V âˆ—âŸ¨A(v), vâŸ©V +âˆ¥B(v)âˆ¥2
L2(U,H) â©½âˆ’Î·âˆ¥vâˆ¥2
H + f
for all v âˆˆV, (4.3.11)
(â€œstrict coercivityâ€) then there exists an invariant measure Âµ for (pt)tâ©¾0,
i.e. Âµ is a probability measure on (H, B(H)) such that

ptF dÂµ =

F dÂµ
for all t âˆˆ[0, âˆ[
(4.3.12)
and all bounded, B(H)-measurable F : H â†’R.
Proof.
1. The right-hand side of (4.3.10) is Gs-measurable by Proposition
4.3.2 and a monotone class argument. So, let 0 â©½t1 < t2 < . . . < tn â©½s

96
4. A Class of Stochastic Diï¬€erential Equations
and let G : Hn â†’R be bounded and âŠ—n
i=1B(H)-measurable. Then by
(4.3.3) and (4.3.6)
Ex(G(Ï€t1, . . . , Ï€tn)F(Ï€t+s))
= E(G(X(t1, 0, x), . . . , X(tn, 0, x))F(X(t + s, 0, x))
= E(G(X(t1, 0, x), . . . , X(tn, 0, x))E(F(X(t + s, 0, x))|Fs))
=

G(X(t1, 0, x)(Ï‰), . . . , X(tn, 0, x)(Ï‰))
E(F(X(t + s, s, X(s, 0, x)(Ï‰))))P(dÏ‰)
=

G(X(t1, 0, x)(Ï‰), . . . , X(tn, 0, x)(Ï‰))
E(F(X(t, 0, X(s, 0, x)(Ï‰))))P(dÏ‰)
=

G(Ï€t1(Ï‰), . . . , Ï€tn(Ï‰))E(F(X(t, 0, Ï€s(Ï‰))))Px(dÏ‰)
=

G(Ï€t1(Ï‰), . . . , Ï€tn(Ï‰))EÏ€s(Ï‰)(F(Ï€t))Px(dÏ‰).
Since the functions G(Ï€t1, . . . , Ï€tn) considered above generate Fs, equal-
ity (4.3.10) follows.
2. Let Î´0 be the Dirac measure in 0 âˆˆH considered as a measure on
(H, B(H)) and for n âˆˆN deï¬ne the Krylovâ€“Bogoliubov measure
Âµn := 1
n
 n
0
Î´0pt dt,
i.e. for B(H)-measurable F : H â†’[0, âˆ[

F dÂµn = 1
n
 n
0
ptF(0) dt.
Clearly, each Âµn is a probability measure. We ï¬rst prove that {Âµn|n âˆˆN}
is tight. By Remark 4.2.8 for any solution X to (4.2.1) applying the
product rule and using (4.3.11) we get that
E(eÎ·tâˆ¥X(t)âˆ¥2
H) = E(âˆ¥X(0)âˆ¥2
H) + E
  t
0
eÎ·s
2 V âˆ—âŸ¨A( Â¯X(s)), Â¯X(s)âŸ©V
+ âˆ¥B( Â¯X(s))âˆ¥2
L2(U,H) + Î·âˆ¥Â¯X(s)âˆ¥2
H

ds

â©½E(âˆ¥X(0)âˆ¥2
H) + f
 t
0
eÎ·s ds,
t âˆˆ[0, âˆ[.

4.3. Markov property and invariant measures
97
Therefore,
E(âˆ¥X(t)âˆ¥2
H) â©½eâˆ’Î·tE(âˆ¥X(0)âˆ¥2
H) + f
Î· ,
t âˆˆ[0, âˆ[,
(4.3.13)
which in turn implies that

âˆ¥xâˆ¥2
HÂµn(dx) = 1
n
 n
0
E(âˆ¥X(t, 0, 0)âˆ¥2
H) dt â©½f
Î·
for all n âˆˆN.
(4.3.14)
Hence by Chebychevâ€™s inequality
sup
nâˆˆN
Âµn({âˆ¥Â·âˆ¥2
H > R}) â©½1
R
f
Î· â†’0 as R â†’âˆ.
(4.3.15)
Since dim H < âˆ, the closed balls {âˆ¥Â·âˆ¥2
H â©½R}, R âˆˆ]0, âˆ[, are compact.
Hence by Prohorovâ€™s theorem there exists a probability measure Âµ and
a subsequence (Âµnk)kâˆˆN such that Âµnk â†’Âµ weakly as k â†’âˆ.
Now let us prove that Âµ is invariant for (pt)tâ©¾0. So, let t âˆˆ[0, âˆ[ and
let F : H â†’R be bounded and B(H)-measurable. By a monotone class
argument we may assume that F is Lipschitz continuous. Then ptF is
bounded and (Lipschitz) continuous by Proposition 4.3.2. Hence using
(4.3.8) for the third equality below, we obtain

ptF dÂµ
= lim
kâ†’âˆ

ptF dÂµnk
= lim
kâ†’âˆ
1
nk
 nk
0
ps(ptF)(0) ds
= lim
kâ†’âˆ
1
nk
 nk
0
ps+tF(0) ds
= lim
kâ†’âˆ

F dÂµnk + lim
kâ†’âˆ
1
nk
 nk+t
nk
psF(0) ds âˆ’lim
kâ†’âˆ
1
nk
 t
0
psF(0) ds
=

F dÂµ,
(4.3.16)
since |psF(0)| â©½supxâˆˆH |F(x)|, so the second and third limits above are
equal to zero.
Remark 4.3.6. If dim H = âˆ, the above proof of Proposition 4.3.5, part 2
works up to and including (4.3.15). However, since closed balls are no longer

98
4. A Class of Stochastic Diï¬€erential Equations
compact, one can apply Prohorovâ€™s theorem only on a Hilbert space H1 into
which H is compactly embedded. So, let H1 be a separable Hilbert space such
that H âŠ‚H1 compactly and densely (e.g. take H1 to be the completion of H
in the norm
âˆ¥xâˆ¥1 :=
4 âˆ

i=1
Î±iâŸ¨x, eiâŸ©2
H
51/2
, x âˆˆH,
where Î±i âˆˆ]0, âˆ[, âˆ
i=1 Î±i < âˆ, and {ei|i âˆˆN} is an orthonormal basis of
H); extending the measures Âµn by zero to B(H1) we obtain that {Âµn|n âˆˆN} is
tight on H1. This extension of the measures is possible, since by Kuratowskiâ€™s
theorem H âˆˆB(H1) and B(H1) âˆ©H = B(H). Hence by Prohorovâ€™s theorem
there exists a probability measure Â¯Âµ on (H1, B(H1)) and a subsequence (Âµnk)kâˆˆN
such that Âµnk â†’Â¯Âµ weakly on H1 as k â†’âˆ. As in Exercise 4.2.3, part 1 one
constructs a lower semicontinuous function Î˜ : H1 â†’[0, âˆ] such that
Î˜ :=

âˆ¥Â·âˆ¥H
on H
+âˆ
on H1\H.
Then (4.3.14) implies that for li, i âˆˆN, as in Example 4.2.3, part 1,

H1
Î˜2(x)Â¯Âµ( dx) = lim
Nâ†’âˆlim
Mâ†’âˆ

sup
iâ©½N
âŸ¨li, xâŸ©2
H1 âˆ§M Â¯Âµ(dx)
=
sup
M,NâˆˆN
lim
kâ†’âˆ

sup
iâ©½N
âŸ¨li, xâŸ©2
H1 âˆ§MÂµnk(dx)
â©½lim inf
kâ†’âˆ
sup
N,MâˆˆN

sup
iâ©½N
âŸ¨li, xâŸ©2
H1 âˆ§MÂµnk(dx)
= lim inf
kâ†’âˆ

H
âˆ¥xâˆ¥2
HÂµnk(dx)
â©½f
Î· .
Hence Î˜ < âˆÂ¯Âµ-a.e., so Â¯Âµ(H) = 1. Therefore, Âµ := Â¯Âµ

B(H) is a probability
measure on (H, B(H)).
Unfortunately, the part of the proof of Proposition 4.3.5, part 2 above, which
shows that Âµ is invariant, does not work. More precisely, for the ï¬rst equality
in (4.3.16) we need that ptF is continuous with respect to the same topology
with respect to which (Âµnk)kâˆˆN converges weakly, i.e. the topology on H1. This
one is, however, weaker than that on H. So, unless we can construct H1 in
such a way that ptF has a continuous extension to H1, the ï¬rst equality in
(4.3.16) may not hold.
So far, we have taken a positive time s as the starting time for our SDE
(see Remark 4.2.11). In the case of coeï¬ƒcients independent of t and Ï‰, it
is possible and convenient to consider negative starting times also. For this

4.3. Markov property and invariant measures
99
we, however, need a Wiener process with negative time. To this end we re-
call that we can run a cylindrical Wiener process W(t), t âˆˆ[0, âˆ[ on H
(with positive time) backwards in time and get again a Wiener process.
More precisely, for ï¬xed T âˆˆ[0, âˆ[ we have that W(T âˆ’t) âˆ’W(T), t âˆˆ
[0, T] is again a cylindrical Wiener process with respect to the ï¬ltration
Ïƒ({W(T âˆ’s) âˆ’W(T)|s âˆˆ[0, t]}), t âˆˆ[0, T], and also with respect to the
ï¬ltration Ïƒ({W(r2) âˆ’W(r1)|r1, r2 âˆˆ[T âˆ’t, âˆ[, r2 â©½r1}), t âˆˆ[0, T], where
the latter will be more convenient for us.
So, let A, B be independent of (t, Ï‰) âˆˆ[0, T]Ã—â„¦and let W (1)(t), t âˆˆ[0, âˆ[,
be another cylindrical Wiener process on (â„¦, F, P) with covariance operator
Q = I, independent of W(t), t âˆˆ[0, âˆ[. Deï¬ne
Â¯W(t) :=
 W(t),
if t âˆˆ[0, âˆ[,
W (1)(âˆ’t),
if t âˆˆ] âˆ’âˆ, 0]
(4.3.17)
with ï¬ltration
Â¯Ft :=
 
s>t
Â¯Fâ—¦
s ,
t âˆˆR,
(4.3.18)
where Â¯Fâ—¦
s := Ïƒ({ Â¯W(r2) âˆ’Â¯W(r1)|r1, r2 âˆˆ] âˆ’âˆ, s], r2 â©¾r1}, N) and N :=
{A âˆˆF|P(A) = 0}. As in the proof of Proposition 2.1.13 one shows that if
âˆ’âˆ< s < t < âˆ, then Â¯W(t) âˆ’Â¯W(s) is independent of Â¯Fs. Now for s âˆˆR
ï¬xed consider the SDE
dX(t) = A(X(t)) dt + B(X(t)) d Â¯W(t), t âˆˆ[s, âˆ[.
(4.3.19)
Remark 4.3.7. Let s âˆˆR and Xs âˆˆL2(â„¦, Â¯Fs, P; H) and consider the integral
version of (4.3.19)
X(t) = Xs +
 t
s
A( Â¯X(u)) du +
 t
s
B( Â¯X(u)) d Â¯W(u),
t âˆˆ[s, âˆ[,
(4.3.20)
with underlying Wiener process Â¯W(t)âˆ’Â¯W(s), t âˆˆ[s, âˆ[ and ï¬ltration ( Â¯Ft)tâ©¾s
(cf. Remark 4.2.11). We deï¬ne the notion of solution for (4.3.20) analogously
to Deï¬nition 4.2.1. Then again all results above for s = 0 (respectively for s âˆˆ
[0, âˆ[, see Remark 4.2.11) carry over to this more general case. In particular,
we have the analogue of (4.3.5), namely
pr,sps,t = pr,t
for all âˆ’âˆ< r â©½s â©½t < âˆ,
(4.3.21)
where for s, t âˆˆR, s â©½t, x âˆˆH
ps,t(x, dy) := P â—¦(X(t, s, x))âˆ’1(dy),
and analogously to (4.3.7) one shows that
ps,t(x, dy) = p0,tâˆ’s(x, dy).

100
4. A Class of Stochastic Diï¬€erential Equations
In particular, for t = 0 we have
pâˆ’s,0(x, dy) = p0,s(x, dy)
for all x âˆˆH, s âˆˆ[0, âˆ[.
(4.3.22)
Furthermore, for every s âˆˆR there exists a unique solution with initial con-
dition Xs denoted by X(t, s, Xs), t âˆˆ[s, âˆ[, and (4.2.33) as well as the ï¬nal
part of Remark 4.2.11 hold also in this case.
Our next main aim (cf. Theorem 4.3.9 below) is to prove the existence of
a unique invariant measure for (4.3.19) if the constant c in (H2) is strictly
negative (â€œstrict monotonicityâ€). The method of the proof is an adaptation
from [DPZ96, Subsection 6.3.1]. We shall need the following:
Lemma 4.3.8. Suppose (H3), (H4) hold and that (H2) holds for c := âˆ’Î» for
some Î» âˆˆ]0, âˆ[. Let Î· âˆˆ]0, Î»[. Then there exists Î´Î· âˆˆ]0, âˆ[ such that for all
v âˆˆV
2 V âˆ—âŸ¨A(v), vâŸ©V +âˆ¥B(v)âˆ¥2
L2(U,H) â©½âˆ’Î·âˆ¥vâˆ¥2
H + Î´Î·.
(4.3.23)
Proof. Let v âˆˆV and Îµ âˆˆ]0, 1[. Then using (H2) ï¬rst (with c = âˆ’Î» according
to our assumption), then Remark 4.1.1, part 1 and ï¬nally (H3) we obtain
2 V âˆ—âŸ¨A(v), vâŸ©V +âˆ¥B(v)âˆ¥2
L2(U,H)
= 2 V âˆ—âŸ¨A(v) âˆ’A(0), vâŸ©V +2 V âˆ—âŸ¨A(0), vâŸ©V +âˆ¥B(v) âˆ’B(0)âˆ¥2
L2(U,H)
âˆ’âˆ¥B(0)âˆ¥2
L2(U,H) + 2âŸ¨B(v), B(0)âŸ©L2(U,H)
â©½âˆ’Î»âˆ¥vâˆ¥2
H + 2Îµâˆ¥vâˆ¥Î±
V + 2Îµâˆ’
1
Î±âˆ’1 (Î± âˆ’1)Î±
âˆ’Î±
Î±âˆ’1 âˆ¥A(0)âˆ¥
Î±
Î±âˆ’1
V âˆ—
+ Îµâˆ’1âˆ¥B(0)âˆ¥2
L2(U,H)
+ Îµâˆ¥B(v)âˆ¥2
L2(U,H)
â©½âˆ’Î»âˆ¥vâˆ¥2
H + 2Îµâˆ¥vâˆ¥Î±
V + Î²Îµ
+ Îµ

c1âˆ¥vâˆ¥2
H + f + 2
Î±âˆ¥vâˆ¥Î±
V + 2Î± âˆ’1
Î±
g
Î±
Î±âˆ’1 + 2c3âˆ¥vâˆ¥Î±
V

â©½
1
âˆ’Î» + Îµc1

1 + 2
c2
(1 + Î±âˆ’1 + c3)
2
âˆ¥vâˆ¥2
H + ËœÎ²Îµ + 2
c2
Îµ(1 + Î±âˆ’1 + c3)f
âˆ’2
c2
Îµ(1 + Î±âˆ’1 + c3)(2 V âˆ—âŸ¨A(v), vâŸ©V +âˆ¥B(v)âˆ¥2
L2(U,H))
with Î²Îµ, ËœÎ²Îµ âˆˆ]0, âˆ[ independent of v and where we applied Youngâ€™s inequality
in the form
ab = [(Î±Îµ)âˆ’1/Î±a][(Î±Îµ)1/Î±b] â©½(Î±Îµ)âˆ’1/(Î±âˆ’1)
Î±/(Î± âˆ’1) aÎ±/(Î±âˆ’1) + ÎµbÎ±,
a, b âˆˆ[0, âˆ[ in the second step. Hence taking Îµ small enough we can ï¬nd
Î´Î· âˆˆ]0, âˆ[ such that for all v âˆˆV
2 V âˆ—âŸ¨A(v), vâŸ©V +âˆ¥B(v)âˆ¥2
L2(U,H) â©½âˆ’Î·âˆ¥vâˆ¥2
H + Î´Î·.

4.3. Markov property and invariant measures
101
Theorem 4.3.9. Consider the situation of Proposition 4.3.5 and, in addition,
assume that c âˆˆR in (H2) is strictly negative, i.e. c = âˆ’Î», Î» âˆˆ]0, âˆ[ (â€œstrict
monotonicityâ€). Then there exists an invariant measure Âµ for (pt)tâ©¾0 such
that

âˆ¥yâˆ¥2
HÂµ(dy) < âˆ.
Moreover, for F : H â†’R Lipschitz, x âˆˆH and any invariant measure Âµ for
(pt)tâ©¾0
|ptF(x) âˆ’

F dÂµ| â©½eâˆ’Î»
2 tLip(F)

âˆ¥x âˆ’yâˆ¥HÂµ(dy)
for all t âˆˆ[0, âˆ[.
(4.3.24)
In particular, there exists exactly one invariant measure for (pt)tâ©¾0 with the
property that

âˆ¥yâˆ¥HÂµ(dy) < âˆ.
Remark 4.3.10. (4.3.24) is referred to as â€œexponential convergence of (pt)tâ©¾0
to equilibriumâ€ (uniformly with respect to x in balls in H).
For the proof of Theorem 4.3.9 we need one lemma.
Lemma 4.3.11. Consider the situation of Theorem 4.3.9. Let t âˆˆR. Then
there exists Î·t âˆˆL2(â„¦, F, P; H), such that for all x âˆˆH
lim
sâ†’âˆ’âˆX(t, s, x) = Î·t in L2(â„¦, F, P; H).
Moreover, there exists C âˆˆ[0, âˆ[ such that for all s âˆˆ] âˆ’âˆ, t]
E(âˆ¥X(t, s, x) âˆ’Î·tâˆ¥2
H) â©½CeÎ»(sâˆ’t)(1 + âˆ¥xâˆ¥2
H).
Proof. For s1, s2 âˆˆ] âˆ’âˆ, t], s1 â©½s2, and x âˆˆH
X(t, s1, x) âˆ’X(t, s2, x)
=
 t
s2
[A( Â¯X(u, s1, x)) âˆ’A( Â¯X(u, s2, x))] ds
+
 t
s2
[B( Â¯X(u, s1, x)) âˆ’B( Â¯X(u, s2, x))] d Â¯W(u) + X(s2, s1, x) âˆ’x,
since
X(s2, s1, x) = x +
 s2
s1
A( Â¯X(u, s1, x)) du +
 s2
s1
B( Â¯X(u, s1, x)) d Â¯W(u).
(4.3.25)

102
4. A Class of Stochastic Diï¬€erential Equations
Since Remark 4.2.8 extends to our present case we can use the product rule
and (H2) with c = âˆ’Î» to obtain
E(eÎ»tâˆ¥X(t, s1, x) âˆ’X(t, s2, x)âˆ¥2
H) = E(eÎ»s2âˆ¥X(s2, s1, x) âˆ’xâˆ¥2
H)
+
t

s2
eÎ»uE
	
2 V âˆ—âŸ¨A( Â¯X(u, s1, x)) âˆ’A( Â¯X(u, s2, x)), Â¯X(u, s1, x) âˆ’Â¯X(u, s1, x)âŸ©V
+ âˆ¥B( Â¯X(u, s1, x)) âˆ’B( Â¯X(u, s2, x))âˆ¥2
L2(U,H)

du
+
t

s2
eÎ»uÎ»E

âˆ¥X(u, s1, x) âˆ’X(u, s2, x)âˆ¥2
H

du
â©½2eÎ»s2[E

âˆ¥X(s2, s1, x)âˆ¥2
H) + âˆ¥xâˆ¥2
H

.
(4.3.26)
But again by Remark 4.2.8 extended to the present case, the product rule and
(4.3.23) imply
E(eÎ·s2âˆ¥X(s2, s1, x)âˆ¥2
H)
= es1Î·âˆ¥xâˆ¥2
H +
 s2
s1
eÎ·uE
	
2 V âˆ—âŸ¨A( Â¯X(u, s1, x)), Â¯X(u, s1, x)âŸ©V
+ âˆ¥B( Â¯X(u, s1, x))âˆ¥2
L2(U,H)

du +
 s2
s1
eÎ·uÎ·E(âˆ¥X(u, s1, x)âˆ¥2
H) du
â©½es1Î·âˆ¥xâˆ¥2
H + Î´Î·
 s2
s1
eÎ·u du â©½es1Î·âˆ¥xâˆ¥2
H + Î´Î·
Î· es2Î·.
(4.3.27)
Combining (4.3.26) and (4.3.27) we obtain
E(âˆ¥X(t, s1, x) âˆ’X(t, s2, x)âˆ¥2
H) â©½2
Î´Î·
Î· + 2âˆ¥xâˆ¥2
H

eÎ»(s2âˆ’t).
(4.3.28)
Letting
s2
(hence
s1)
tend
to
âˆ’âˆ,
it
follows
that
there
exists
Î·t(x) âˆˆL2(â„¦, F, P; H) such that
lim
sâ†’âˆ’âˆX(t, s, x) = Î·t(x) in L2(â„¦, F, P; H),
and letting s1 â†’âˆ’âˆin (4.3.28) the last part of the assertion follows also,
provided we can prove that Î·t(x) is independent of x âˆˆH. To this end let

4.3. Markov property and invariant measures
103
x, y âˆˆH and s âˆˆ] âˆ’âˆ, t]. Then
X(t, s, x) âˆ’X(t, s, y)
=x âˆ’y +
 t
s
(A( Â¯X(u, s, x)) âˆ’A( Â¯X(u, s, y)) du
+
 t
s
(B( Â¯X(u, s, x)) âˆ’B( Â¯X(u, s, y)) d Â¯W(u).
Hence by the same arguments to derive (4.3.26) we get
E(eÎ»tâˆ¥X(t, s, x) âˆ’X(t, s, y)âˆ¥2
H) â©½eÎ»sâˆ¥x âˆ’yâˆ¥2
H,
so
lim
sâ†’âˆ’âˆ(X(t, s, x) âˆ’X(t, s, y)) = 0 in L2(â„¦, F, P; H).
Hence both assertions are completely proved.
Proof of Theorem 4.3.9. Deï¬ne
Âµ := P â—¦Î·âˆ’1
0
with Î·0 as in Lemma 4.3.11. Since Î·0 âˆˆL2(â„¦, F, P; H) we have that

âˆ¥yâˆ¥2
HÂµ(dy) < âˆ.
Let t âˆˆ[0, âˆ[. We note that by (4.3.21) and (4.3.22) for all s âˆˆ[0, âˆ[
pâˆ’s,0p0,t = pâˆ’s,t = p0,t+s = pâˆ’(t+s),0.
(4.3.29)
Let F : H â†’R, F bounded and Lipschitz. Then by Proposition 4.3.2 we have
that p0,tF is (bounded and) Lipschitz. Furthermore, by Lemma 4.3.11 for all
x âˆˆH
pâˆ’s,0(x, dy) â†’Âµ weakly as s â†’âˆ.
Hence by (4.3.29) for all x âˆˆH

p0,tF dÂµ = lim
sâ†’âˆpâˆ’s,0(p0,tF)(x) = lim
sâ†’âˆpâˆ’(t+s),0F(x) =

F dÂµ.
Recalling that by deï¬nition pt = p0,t, it follows that Âµ is an invariant measure
for (pt)tâ©¾0. Furthermore, if Âµ is an invariant measure for (pt)tâ©¾0, then by
Proposition 4.3.2 for all t âˆˆ[0, âˆ[
ptF(x) âˆ’

F dÂµ
 =


(ptF(x) âˆ’ptF(y))Âµ(dy)

â©½eâˆ’Î»
2 tLip(F)

âˆ¥x âˆ’yâˆ¥HÂµ(dy).

A. The Bochner Integral
This chapter is a slight modiï¬cation of Chap. A in [FK01].
Let

X, âˆ¥âˆ¥

be a Banach space, B(X) the Borel Ïƒ-ï¬eld of X and (â„¦, F, Âµ)
a measure space with ï¬nite measure Âµ.
A.1. Deï¬nition of the Bochner integral
Step 1:
As ï¬rst step we want to deï¬ne the integral for simple functions
which are deï¬ned as follows. Set
E :=

f : â„¦â†’X
 f =
n

k=1
xk1Ak, xk âˆˆX, Ak âˆˆF, 1 â©½k â©½n, n âˆˆN

and deï¬ne a semi-norm âˆ¥âˆ¥E on the vector space E by
âˆ¥fâˆ¥E :=

âˆ¥fâˆ¥dÂµ,
f âˆˆE.
To get that

E, âˆ¥âˆ¥E

is a normed vector space we consider equivalence classes
with respect to âˆ¥âˆ¥E. For simplicity we will not change the notations.
For f âˆˆE, f = n
k=1 xk1Ak, Akâ€™s pairwise disjoint (such a representation
is called normal and always exists, because f = n
k=1 xk1Ak, where f(â„¦) =
{x1, . . . , xk}, xi Ì¸= xj, and Ak := {f = xk}) and we now deï¬ne the Bochner
integral to be

f dÂµ :=
n

k=1
xkÂµ(Ak).
(Exercise: This deï¬nition is independent of representations, and hence linear.)
In this way we get a mapping
int :

E, âˆ¥âˆ¥E

â†’

X, âˆ¥âˆ¥

f
	â†’

f dÂµ
which is linear and uniformly continuous since
'
f dÂµ
 â©½
'
âˆ¥fâˆ¥dÂµ for all
f âˆˆE.
Therefore we can extend the mapping int to the abstract completion of E
with respect to âˆ¥âˆ¥E which we denote by E.
105

106
A. The Bochner Integral
Step 2:
We give an explicit representation of E.
Deï¬nition A.1.1. A function f : â„¦â†’X is called strongly measurable if it
is F/B(X)-measurable and f(â„¦) âŠ‚X is separable.
Deï¬nition A.1.2. Let 1 â©½p < âˆ. Then we deï¬ne
Lp(â„¦, F, Âµ; X) := Lp(Âµ; X)
:=

f : â„¦â†’X
 f is strongly measurable with
respect to F, and

âˆ¥fâˆ¥p dÂµ < âˆ

and the semi-norm
âˆ¥fâˆ¥Lp :=

âˆ¥fâˆ¥p dÂµ
 1
p
,
f âˆˆLp(â„¦, F, Âµ; X).
The space of all equivalence classes in Lp(â„¦, F, Âµ; X) with respect to âˆ¥âˆ¥Lp is
denoted by Lp(â„¦, F, Âµ; X) := Lp(Âµ; X).
Claim:
L1(â„¦, F, Âµ; X) = E.
Step 2.a:

L1(â„¦, F, Âµ; X), âˆ¥âˆ¥L1
is complete.
The proof is just a modiï¬cation of the proof of the Fischerâ€“Riesz theorem
by the help of the following proposition.
Proposition A.1.3. Let (â„¦, F) be a measurable space and let X be a Banach
space. Then:
(i) the set of F/B(X)-measurable functions from â„¦to X is closed under
the formation of pointwise limits, and
(ii) the set of strongly measurable functions from â„¦to X is closed under the
formation of pointwise limits.
Proof. Simple exercise or see [Coh80, Proposition E.1, p. 350].
Step 2.b:
E is a dense subset of L1(â„¦, F, Âµ; X) with respect to âˆ¥âˆ¥L1.
This can be shown by the help of the following lemma.
Lemma A.1.4. Let E be a metric space with metric d and let f : â„¦â†’E
be strongly measurable. Then there exists a sequence fn, n âˆˆN, of simple E-
valued functions (i.e. fn is F/B(E)-measurable and takes only a ï¬nite number
of values) such that for arbitrary Ï‰ âˆˆâ„¦the sequence d

fn(Ï‰), f(Ï‰)

, n âˆˆN,
is monotonely decreasing to zero.

A.2. Properties of the Bochner integral
107
Proof. [DPZ92, Lemma 1.1, p. 16] Let {ek | k âˆˆN} be a countable dense
subset of f(â„¦). For m âˆˆN deï¬ne
dm(Ï‰) := min

d

f(Ï‰), ek
  k â©½m


= dist(f(Ï‰), {ek, k â©½m})

,
km(Ï‰) := min

k â©½m
 dm(Ï‰) = d

f(Ï‰), ek

,
fm(Ï‰) := ekm(Ï‰).
Obviously fm, m âˆˆN, are simple functions since they are F/B(E)-measurable
(exercise) and
fm(â„¦) âŠ‚{e1, e2, . . . , em}.
Moreover, by the density of {ek | k âˆˆN}, the sequence dm(Ï‰), m âˆˆN, is
monotonically decreasing to zero for arbitrary Ï‰ âˆˆâ„¦. Since d

fm(Ï‰), f(Ï‰)

=
dm(Ï‰) the assertion follows.
Let now f âˆˆL1(Âµ; X). By the Lemma A.1.4 above we get the existence of
a sequence of simple functions fn, n âˆˆN, such that
fn(Ï‰) âˆ’f(Ï‰)
 â†“0
for all Ï‰ âˆˆâ„¦as n â†’âˆ.
Hence fn
nâ†’âˆ
âˆ’âˆ’âˆ’âˆ’â†’f in âˆ¥âˆ¥L1 by Lebesgueâ€™s dominated convergence theorem.
A.2. Properties of the Bochner integral
Proposition A.2.1 (Bochner inequality). Let f âˆˆL1(â„¦, F, Âµ; X). Then


f dÂµ
 â©½

âˆ¥fâˆ¥dÂµ.
Proof. We know the assertion is true for f âˆˆE, i.e. int : E â†’X is linear,
continuous with âˆ¥int fâˆ¥â©½âˆ¥fâˆ¥E for all f âˆˆE, so the same is true for its unique
continuous extension int : E = L1(Âµ; X) â†’X, i.e. for all f âˆˆL1(X, Âµ)


f dÂµ
 =
intf
 â©½âˆ¥fâˆ¥E =

âˆ¥fâˆ¥dÂµ.
Proposition A.2.2. Let f âˆˆL1(â„¦, F, Âµ; X). Then

L â—¦f dÂµ = L

f dÂµ

holds for all L âˆˆL(X, Y ), where Y is another Banach space.
Proof. Simple exercise or see [Coh80, Proposition E.11, p. 356].

108
A. The Bochner Integral
Proposition A.2.3 (Fundamental theorem of calculus). Let âˆ’âˆ< a <
b < âˆand f âˆˆC1
[a, b]; X

. Then
f(t) âˆ’f(s) =
 t
s
f â€²(u) du :=

'
1[s,t](u)f â€²(u) du
if s â©½t
âˆ’
'
1[t,s](u)f â€²(u) du
otherwise
for all s, t âˆˆ[a, b] where du denotes the Lebesgue measure on B(R).
Proof. Claim 1: If we set F(t) =
' t
s f â€²(u) du, t âˆˆ[a, b], we get that F â€²(t) =
f â€²(t) for all t âˆˆ[a, b].
For that we have to prove that

1
h

F(t + h) âˆ’F(t)

âˆ’f â€²(t)

X
hâ†’0
âˆ’âˆ’âˆ’â†’0.
To this end we ï¬x t âˆˆ[a, b] and take an arbitrary Îµ > 0. Since f â€² is continuous
on [a, b] there exists Î´ > 0 such that
f â€²(u) âˆ’f â€²(t)

X < Îµ for all u âˆˆ[a, b]
with |u âˆ’t| < Î´. Then we obtain that

1
h

F(t + h) âˆ’F(t)

âˆ’f â€²(t)

X
=

1
h
 t+h
t

f â€²(u) âˆ’f â€²(t)

du

X
â©½1
h
 t+h
t
f â€²(u) âˆ’f â€²(t)

X du < Îµ
if t + h âˆˆ[a, b] and |h| < Î´.
Claim 2: If ËœF âˆˆC1
[a, b]; X

is a further function with ËœF â€² = F â€² = f â€² then
there exists a constant c âˆˆX such that F âˆ’ËœF = c.
For all L âˆˆXâˆ—= L(X, R) we deï¬ne gL := L(F âˆ’ËœF). Then gâ€²
L = 0 and
therefore gL is constant. Since Xâˆ—separates the points of X by the Hahnâ€“
Banach theorem (see [Alt92, Satz 4.2, p. 114]) this implies that F âˆ’ËœF itself
is constant.

B. Nuclear and Hilbertâ€“Schmidt
Operators
This chapter is identical to Chap. B in [FK01].
Let

U, âŸ¨, âŸ©U

and

H, âŸ¨, âŸ©

be two separable Hilbert spaces. The space of
all bounded linear operators from U to H is denoted by L(U, H); for simplicity
we write L(U) instead of L(U, U). If we speak of the adjoint operator of
L âˆˆL(U, H) we write Lâˆ—âˆˆL(H, U). An element L âˆˆL(U) is called symmetric
if âŸ¨Lu, vâŸ©U = âŸ¨u, LvâŸ©U for all u, v âˆˆU. In addition, L âˆˆL(U) is called
nonnegative if âŸ¨Lu, uâŸ©â©¾0 for all u âˆˆU.
Deï¬nition B.0.1 (Nuclear operator). An element T âˆˆL(U, H) is said to
be a nuclear operator if there exists a sequence (aj)jâˆˆN in H and a sequence
(bj)jâˆˆN in U such that
Tx =
âˆ

j=1
ajâŸ¨bj, xâŸ©U
for all x âˆˆU
and

jâˆˆN
âˆ¥ajâˆ¥Â· âˆ¥bjâˆ¥U < âˆ.
The space of all nuclear operators from U to H is denoted by L1(U, H).
If U = H, T âˆˆL1(U, H) is nonnegative and symmetric, then T is called trace
class.
Proposition B.0.2. The space L1(U, H) endowed with the norm
âˆ¥Tâˆ¥L1(U,H) := inf

jâˆˆN
âˆ¥ajâˆ¥Â· âˆ¥bjâˆ¥U
 Tx =
âˆ

j=1
ajâŸ¨bj, xâŸ©U, x âˆˆU

is a Banach space.
Proof. [MV92, Corollar 16.25, p. 154].
Deï¬nition B.0.3. Let T âˆˆL(U) and let ek, k âˆˆN, be an orthonormal basis
of U. Then we deï¬ne
tr T :=

kâˆˆN
âŸ¨Tek, ekâŸ©U
if the series is convergent.
109

110
B. Nuclear and Hilbertâ€“Schmidt Operators
One has to notice that this deï¬nition could depend on the choice of the
orthonormal basis. But there is the following result concerning nuclear oper-
ators.
Remark B.0.4. If T âˆˆL1(U) then tr T is well-deï¬ned independently of the
choice of the orthonormal basis ek, k âˆˆN. Moreover we have that
|tr T| â©½âˆ¥Tâˆ¥L1(U).
Proof. Let (aj)jâˆˆN and (bj)jâˆˆN be sequences in U such that
Tx =

jâˆˆN
ajâŸ¨bj, xâŸ©U
for all x âˆˆU and

jâˆˆN
âˆ¥ajâˆ¥U Â· âˆ¥bjâˆ¥U < âˆ.
Then we get for any orthonormal basis ek, k âˆˆN, of U that
âŸ¨Tek, ekâŸ©U =

jâˆˆN
âŸ¨ek, ajâŸ©U Â· âŸ¨ek, bjâŸ©U
and therefore

kâˆˆN
âŸ¨Tek, ekâŸ©U
 â©½

jâˆˆN

kâˆˆN
âŸ¨ek, ajâŸ©U Â· âŸ¨ek, bjâŸ©U

â©½

jâˆˆN
	
kâˆˆN
âŸ¨ek, ajâŸ©U
2
 1
2 Â·
	
kâˆˆN
âŸ¨ek, bjâŸ©U
2
 1
2
=

jâˆˆN
âˆ¥ajâˆ¥U Â· âˆ¥bjâˆ¥U < âˆ.
This implies that we can exchange the summation to get that

kâˆˆN
âŸ¨Tek, ekâŸ©U =

jâˆˆN

kâˆˆN
âŸ¨ek, ajâŸ©U Â· âŸ¨ek, bjâŸ©U =

jâˆˆN
âŸ¨aj, bjâŸ©U,
and the assertion follows.
Deï¬nition B.0.5 (Hilbertâ€“Schmidt operator). A bounded linear opera-
tor T : U â†’H is called Hilbertâ€“Schmidt if

kâˆˆN
âˆ¥Tekâˆ¥2 < âˆ
where ek, k âˆˆN, is an orthonormal basis of U.
The space of all Hilbertâ€“Schmidt operators from U to H is denoted by
L2(U, H).

B. Nuclear and Hilbertâ€“Schmidt Operators
111
Remark B.0.6.
(i) The deï¬nition of Hilbertâ€“Schmidt operator and the
number
âˆ¥Tâˆ¥2
L2(U,H) :=

kâˆˆN
âˆ¥Tekâˆ¥2
does not depend on the choice of the orthonormal basis ek, k âˆˆN, and we
have that âˆ¥Tâˆ¥L2(U,H) = âˆ¥T âˆ—âˆ¥L2(H,U). For simplicity we also write âˆ¥Tâˆ¥L2
instead of âˆ¥Tâˆ¥L2(U,H).
(ii) âˆ¥Tâˆ¥L(U,H) â©½âˆ¥Tâˆ¥L2(U,H).
(iii) Let G be another Hilbert space and S1 âˆˆL(H, G), S2 âˆˆL(G, U), T âˆˆ
L2(U, H). Then S1T âˆˆL2(U, G) and TS2 âˆˆL2(G, H) and
âˆ¥S1Tâˆ¥L2(U,G) â©½âˆ¥S1âˆ¥L(H,G)âˆ¥Tâˆ¥L2(U,H),
âˆ¥TS2âˆ¥L2(G,H) â©½âˆ¥Tâˆ¥L(U,H)âˆ¥S2âˆ¥L2(G,U).
Proof.
(i) If ek, k âˆˆN, is an orthonormal basis of U and fk, k âˆˆN, is an
orthonormal basis of H we obtain by the Parseval identity that

kâˆˆN
âˆ¥Tekâˆ¥2 =

kâˆˆN

jâˆˆN
âŸ¨Tek, fjâŸ©
2 =

jâˆˆN
âˆ¥T âˆ—fjâˆ¥2
U
and therefore the assertion follows.
(ii) Let x âˆˆU and fk, k âˆˆN, be an orthonormal basis of H. Then we get
that
âˆ¥Txâˆ¥2 =

kâˆˆN
âŸ¨Tx, fkâŸ©2 â©½âˆ¥xâˆ¥2
U

kâˆˆN
âˆ¥T âˆ—fkâˆ¥2
U = âˆ¥Tâˆ¥2
L2(U,H) Â· âˆ¥xâˆ¥2
U.
(iii) Let ek, k âˆˆN be an orthonormal basis of U. Then

kâˆˆN
âˆ¥S1Tekâˆ¥2
G â©½âˆ¥S1âˆ¥2
L(H,G)âˆ¥Tâˆ¥2
L2(U,H).
Furthermore, since (TS2)âˆ—= Sâˆ—
2T âˆ—, it follows that by the above and (i)
that TS2 âˆˆL2(G, H) and
âˆ¥TS2âˆ¥L2(G,H) = âˆ¥(TS2)âˆ—âˆ¥L2(H,G)
= âˆ¥Sâˆ—
2T âˆ—âˆ¥L2(H,G)
â©½âˆ¥S2âˆ¥L(G,U) Â· âˆ¥Tâˆ¥L2(U,H).

112
B. Nuclear and Hilbertâ€“Schmidt Operators
Proposition B.0.7. Let S, T âˆˆL2(U, H) and let ek, k âˆˆN, be an orthonor-
mal basis of U. If we deï¬ne
âŸ¨T, SâŸ©L2 :=

kâˆˆN
âŸ¨Sek, TekâŸ©
we obtain that

L2(U, H), âŸ¨, âŸ©L2

is a separable Hilbert space.
If fk, k âˆˆN, is an orthonormal basis of H we get that fj âŠ—ek := fjâŸ¨ek, Â· âŸ©U,
j, k âˆˆN, is an orthonormal basis of L2(U, H).
Proof. We have to prove the completeness and the separability.
1. L2(U, H) is complete:
Let Tn, n âˆˆN, be a Cauchy sequence in L2(U, H). Then it is clear that it is
also a Cauchy sequence in L(U, H). Because of the completeness of L(U, H)
there exists an element T âˆˆL(U, H) such that âˆ¥Tn âˆ’Tâˆ¥L(U,H) âˆ’â†’0 as
n â†’âˆ. But by the lemma of Fatou we also have for any orthonormal basis
ek, k âˆˆN, of U that
âˆ¥Tn âˆ’Tâˆ¥2
L2 =

kâˆˆN

(Tn âˆ’T)ek, (Tn âˆ’T)ek

=

kâˆˆN
lim inf
mâ†’âˆ
(Tn âˆ’Tm)ek
2
â©½lim inf
mâ†’âˆ

kâˆˆN
(Tn âˆ’Tm)ek
2 = lim inf
mâ†’âˆâˆ¥Tn âˆ’Tmâˆ¥2
L2 < Îµ
for all n âˆˆN big enough. Therefore the assertion follows.
2. L2(U, H) is separable:
If we deï¬ne fj âŠ—ek := fjâŸ¨ek, Â· âŸ©U, j, k âˆˆN, then it is clear that fj âŠ—ek âˆˆ
L2(U, H) for all j, k âˆˆN and for arbitrary T âˆˆL2(U, H) we get that
âŸ¨fj âŠ—ek, TâŸ©L2 =

nâˆˆN
âŸ¨ek, enâŸ©U Â· âŸ¨fj, TenâŸ©= âŸ¨fj, TekâŸ©.
Therefore it is obvious that fj âŠ—ek, j, k âˆˆN, is an orthonormal system.
In addition, T = 0 if âŸ¨fj âŠ—ek, TâŸ©L2 = 0 for all j, k âˆˆN, and therefore
span(fj âŠ—ek | j, k âˆˆN) is a dense subspace of L2(U, H).
Proposition B.0.8. Let

G, âŸ¨, âŸ©G

be a further separable Hilbert space.
If T âˆˆL2(U, H) and S âˆˆL2(H, G) then ST âˆˆL1(U, G) and
âˆ¥STâˆ¥L1(U,G) â©½âˆ¥Sâˆ¥L2 Â· âˆ¥Tâˆ¥L2.
Proof. Let fk, k âˆˆN, be an orthonormal basis of H. Then we have that
STx =

kâˆˆN
âŸ¨Tx, fkâŸ©Sfk,
x âˆˆU

B. Nuclear and Hilbertâ€“Schmidt Operators
113
and therefore
âˆ¥STâˆ¥L1(U,G) â©½

kâˆˆN
âˆ¥T âˆ—fkâˆ¥U Â· âˆ¥Sfkâˆ¥G
â©½
	
kâˆˆN
âˆ¥T âˆ—fkâˆ¥2
U

 1
2 Â·
	
kâˆˆN
âˆ¥Sfkâˆ¥2
G

 1
2 = âˆ¥Sâˆ¥L2 Â· âˆ¥Tâˆ¥L2.
Remark B.0.9. Let ek, k âˆˆN, be an orthonormal basis of U. If T âˆˆL(U)
is symmetric, nonnegative with 
kâˆˆNâŸ¨Tek, ekâŸ©U < âˆthen T âˆˆL1(U).
Proof. The result is obvious by the previous proposition and the fact that
there exists T
1
2 âˆˆL(U) nonnegative and symmetric such that T = T
1
2 T
1
2 (see
Proposition 2.3.4). Then T
1
2 âˆˆL2(U).
Proposition B.0.10. Let L âˆˆL(H) and B âˆˆL2(U, H). Then LBBâˆ—âˆˆ
L1(H), Bâˆ—LB âˆˆL1(U) and we have that
tr LBBâˆ—= tr Bâˆ—LB.
Proof. We know by Remark B.0.6 (iii) and Proposition B.0.8 that LBBâˆ—âˆˆ
L1(H) and Bâˆ—LB âˆˆL1(U). Let ek, k âˆˆN, be an orthonormal basis of U
and let fk, k âˆˆN, be an orthonormal basis of H. Then the Parseval identity
implies that

kâˆˆN

nâˆˆN
âŸ¨fk, BenâŸ©Â· âŸ¨fk, LBenâŸ©

â©½

nâˆˆN
	
kâˆˆN
âŸ¨fk, BenâŸ©
2
 1
2 Â·
	
kâˆˆN
âŸ¨fk, LBenâŸ©
2
 1
2
=

nâˆˆN
âˆ¥Benâˆ¥Â· âˆ¥LBenâˆ¥â©½âˆ¥Lâˆ¥L(H) Â· âˆ¥Bâˆ¥2
L2.
Therefore, it is allowed to interchange the sums to obtain that
tr LBBâˆ—=

kâˆˆN
âŸ¨LBBâˆ—fk, fkâŸ©=

kâˆˆN
âŸ¨Bâˆ—fk, Bâˆ—Lâˆ—fkâŸ©U
=

kâˆˆN

nâˆˆN
âŸ¨Bâˆ—fk, enâŸ©U Â· âŸ¨Bâˆ—Lâˆ—fk, enâŸ©U =

nâˆˆN

kâˆˆN
âŸ¨fk, BenâŸ©Â· âŸ¨fk, LBenâŸ©
=

nâˆˆN
âŸ¨Ben, LBenâŸ©=

nâˆˆN
âŸ¨en, Bâˆ—LBenâŸ©U = tr Bâˆ—LB.

C. Pseudo Inverse of Linear
Operators
This chapter is a slight modiï¬cation of Chapter C in [FK01].
Let

U, âŸ¨, âŸ©U

and

H, âŸ¨, âŸ©

be two Hilbert spaces.
Deï¬nition C.0.1 (Pseudo inverse). Let T âˆˆL(U, H) and Ker(T) := {x âˆˆ
U | Tx = 0}. The pseudo inverse of T is deï¬ned as
T âˆ’1 :=

T |Ker(T )âŠ¥
âˆ’1 : T

Ker(T)âŠ¥
= T(U) â†’Ker(T)âŠ¥.
(Note that T is one-to-one on Ker(T)âŠ¥.)
Remark C.0.2.
(i) There is an equivalent way of deï¬ning the pseudo in-
verse of a linear operator T âˆˆL(U, H). For x âˆˆT(U) one sets T âˆ’1x âˆˆU
to be the solution of minimal norm of the equation Ty = x, y âˆˆU.
(ii) If T âˆˆL(U, H) then T âˆ’1 : T(U) â†’Ker(T)âŠ¥is linear and bijective.
Proposition C.0.3. Let T âˆˆL(U) and T âˆ’1 the pseudo inverse of T.
(i) If we deï¬ne an inner product on T(U) by
âŸ¨x, yâŸ©T (U) := âŸ¨T âˆ’1x, T âˆ’1yâŸ©U
for all x, y âˆˆT(U),
then

T(U), âŸ¨, âŸ©T (U)

is a Hilbert space.
(ii) Let ek, k âˆˆN, be an orthonormal basis of (Ker T)âŠ¥. Then Tek, k âˆˆN,
is an orthonormal basis of

T(U), âŸ¨, âŸ©T (U)

.
Proof. T : (Ker T)âŠ¥â†’T(U) is bijective and an isometry if (Ker T)âŠ¥is
equipped with âŸ¨, âŸ©U and T(U) with âŸ¨, âŸ©T (U).
Now we want to present a result about the images of linear operators. To
this end we need the following lemma.
Lemma C.0.4. Let T âˆˆL(U, H). Then the set TBc(0) (=

Tu
 u âˆˆ
U, âˆ¥uâˆ¥U â©½c

), c â©¾0, is convex and closed.
Proof. Since T is linear it is obvious that the set is convex.
Since a convex subset of a Hilbert space is closed (with respect to the norm)
if and only if it is weakly closed, it suï¬ƒces to show that TBc(0) is weakly
closed. Since T : U â†’H is linear and continuous (with respect to the norms
115

116
C. Pseudo Inverse of Linear Operators
on U, H respectively) it is also obviously continuous with respect to the weak
topologies on U, H respectively. But by the Banachâ€“Alaoglou theorem (see
e.g. [RS72, Theorem IV.21, p. 115]) closed balls in a Hilbert space are weakly
compact. Hence Bc(0) is weakly compact, and so is its continuous image, i.e.
TBc(0) is weakly compact, therefore weakly closed.
Proposition C.0.5. Let

U1, âŸ¨, âŸ©1

and

U2, âŸ¨, âŸ©2

be two Hilbert spaces.
In addition, we take T1 âˆˆL(U1, H) and T2 âˆˆL(U2, H). Then the following
statements hold.
(i) If there exists a constant c â©¾0 such that âˆ¥T âˆ—
1 xâˆ¥1 â©½câˆ¥T âˆ—
2 xâˆ¥2 for all
x âˆˆH then

T1u
 u âˆˆU1, âˆ¥uâˆ¥1 â©½1

âŠ‚

T2v
 v âˆˆU2, âˆ¥vâˆ¥2 â©½c

. In
particular, this implies that Im T1 âŠ‚Im T2.
(ii) If âˆ¥T âˆ—
1 xâˆ¥1 = âˆ¥T âˆ—
2 xâˆ¥2 for all x âˆˆH then Im T1 = Im T2 and âˆ¥T âˆ’1
1
xâˆ¥1 =
âˆ¥T âˆ’1
2
xâˆ¥2 for all x âˆˆIm T1.
Proof. [DPZ92, Proposition B.1, p. 407]
(i) Assume that there exists u0 âˆˆU1 such that
âˆ¥u0âˆ¥1 â©½1
and
T1u0 /âˆˆ

T2v
 v âˆˆU2, âˆ¥vâˆ¥2 â©½c

.
By Lemma C.0.4 we know that the set

T2v
 v âˆˆU2, âˆ¥vâˆ¥2 â©½c

is
closed and convex. Therefore, we get by the separation theorem (see
[Alt92, 5.11 Trennungssatz, p. 166]) there exists x âˆˆH, x Ì¸= 0, such that
1 < âŸ¨x, T1u0âŸ©
and
âŸ¨x, T2vâŸ©â©½1 for all v âˆˆU2 with âˆ¥vâˆ¥2 â©½c.
Thus âˆ¥T âˆ—
1 xâˆ¥1 > 1 and câˆ¥T âˆ—
2 xâˆ¥2 =
sup
âˆ¥vâˆ¥2â©½c
âŸ¨T âˆ—
2 x, vâŸ©2
 â©½1, a contradiction.
(ii) By (i) we know that Im T1 = Im T2. It remains to verify that
âˆ¥T âˆ’1
1
xâˆ¥1 = âˆ¥T âˆ’1
2
xâˆ¥2
for all x âˆˆIm T1.
If x = 0 then âˆ¥T âˆ’1
1
0âˆ¥1 = 0 = âˆ¥T âˆ’1
2
0âˆ¥2.
If x âˆˆIm T1 \ {0} then there exist u1 âˆˆ(Ker T1)âŠ¥and u2 âˆˆ(Ker T2)âŠ¥
such that x = T1u1 = T2u2. We have to show that âˆ¥u1âˆ¥1 = âˆ¥u2âˆ¥2.
Assume that âˆ¥u1âˆ¥1 > âˆ¥u2âˆ¥2 > 0. Then (i) implies that
x
âˆ¥u2âˆ¥2
= T2

u2
âˆ¥u2âˆ¥2

âˆˆ

T2v
 v âˆˆU2, âˆ¥vâˆ¥2 â©½1

=

T1u
 u âˆˆU1, âˆ¥uâˆ¥1 â©½1

.
But
x
âˆ¥u2âˆ¥2
= T1

u1
âˆ¥u2âˆ¥2

and

u1
âˆ¥u2âˆ¥2

1
> 1,

C. Pseudo Inverse of Linear Operators
117
therefore, there exists Ëœu1 âˆˆU1, âˆ¥Ëœu1âˆ¥1 â©½1, so that for Ëœu2 :=
u1
âˆ¥u2âˆ¥2 âˆˆ
(Ker T1)âŠ¥we have
T1Ëœu1 =
x
âˆ¥u2âˆ¥2
= T1Ëœu2 ,
i.e. Ëœu1 âˆ’Ëœu2 âˆˆKer T1.
Therefore,
0 = âŸ¨Ëœu1 âˆ’Ëœu2, Ëœu2âŸ©1 = âŸ¨Ëœu1, Ëœu2âŸ©1 âˆ’âˆ¥Ëœu2âˆ¥2
1
â©½âˆ¥Ëœu1âˆ¥1âˆ¥Ëœu2âˆ¥1 âˆ’âˆ¥Ëœu2âˆ¥2
1 =

1 âˆ’âˆ¥Ëœu2âˆ¥1

âˆ¥Ëœu2âˆ¥1.
This is a contradiction.
Corollary C.0.6. Let T âˆˆL(U, H) and set Q := TT âˆ—âˆˆL(H). Then we
have
Im Q
1
2 = Im T
and
Qâˆ’1
2 x
 = âˆ¥T âˆ’1xâˆ¥U for all x âˆˆIm T,
where Qâˆ’1
2 is the pseudo inverse of Q
1
2 .
Proof. Since by Lemma 2.3.4 Q
1
2 is symmetric we have for all x âˆˆH that


Q
1
2 âˆ—x

2
=
Q
1
2 x
2 = âŸ¨Qx, xâŸ©= âŸ¨TT âˆ—x, xâŸ©= âˆ¥T âˆ—xâˆ¥2
U.
Therefore the assertion follows by Proposition C.0.5.

D. Some Tools from Real
Martingale Theory
We need the following Burkholderâ€“Davis inequality for real-valued continuous
local martingales.
Proposition D.0.1. Let (Nt)tâˆˆ[0,T ] be a real-valued continuous local mar-
tingale on a probability space (â„¦, E, P) with respect to a normal ï¬ltration
(Ft)tâˆˆ[0,T ]. Then for all stopping times Ï„(â©½T)
E( sup
tâˆˆ[0,Ï„]
|Nt|) â©½3E(âŸ¨NâŸ©1/2
Ï„
).
Proof. See e.g. [KS88, Theorem 3.28].
Corollary D.0.2. Let Îµ, Î´ âˆˆ]0, âˆ[. Then for N as in Proposition D.0.1
P( sup
tâˆˆ[0,T ]
|Nt| â©¾Îµ) â©½3
ÎµE(âŸ¨NâŸ©1/2
T
âˆ§Î´) + P(âŸ¨NâŸ©1/2
T
> Î´).
Proof. Let
Ï„ := inf{t â©¾0| âŸ¨NâŸ©1/2
t
> Î´} âˆ§T.
Then Ï„(â©½T) is an Ft-stopping time. Hence by Proposition D.0.1
P

sup
tâˆˆ[0,T ]
|Nt| â©¾Îµ

=P

sup
tâˆˆ[0,T ]
|Nt| â©¾Îµ, Ï„ = T

+ P

sup
tâˆˆ[0,T ]
|Nt| â©¾Îµ, Ï„ < T

â©½3
ÎµE(âŸ¨NâŸ©1/2
Ï„
) + P

sup
tâˆˆ[0,T ]
|Nt| â©¾Îµ, âŸ¨NâŸ©1/2
T
> Î´

â©½3
ÎµE(âŸ¨NâŸ©1/2
T
âˆ§Î´) + P(âŸ¨NâŸ©1/2
T
> Î´).
119

E. Weak and Strong Solutions:
the Yamada-Watanabe
Theorem
Let (â„¦, F, P) be a complete probability space with normal ï¬ltration Ft, t âˆˆ
[0, âˆ[. Below we shall call ((â„¦, F, P, (Ft)) a stochastic basis. Let d, d1 âˆˆN and
let M(d Ã— d1, R) denote the set of all real d Ã— d1-matrices equipped with the
norm (3.1.2). Let
W d := C([0, âˆ[ â†’Rd)
(E.0.1)
and
W d
0 := {w âˆˆW d|w(0) = 0}.
(E.0.2)
W d is equipped with metric
Ï±(w1, w2) :=
âˆ

k=1
2âˆ’k( max
0â©½tâ©½k |w1(t) âˆ’w2(t)| âˆ§1),
w1, w2 âˆˆW d,
(E.0.3)
which makes it a Polish space. Its Borel Ïƒ-algebra is denoted by B(W d).
Let Bt(W d) denote the Ïƒ-Algebra generated by all maps Ï€s, 0 â©½s â©½t,
where Ï€s(w) := w(s), w âˆˆW d. Let Ad,d1 denote the set of all B([0, âˆ[) âŠ—
B(W d)/B(M(d Ã— d1, R))-measurable maps Î± : [0, âˆ[ Ã—W d â†’M(d Ã— d1, R)
such that for each t âˆˆ[0, âˆ[ the map
W d âˆ‹w 	â†’Î±(t, w) âˆˆM(d Ã— d1, R)
is Bt(W d)/B(M(d Ã— d1, R))-measurable.
E.1. The main result
Fix Ïƒ âˆˆAd,d1 and b âˆˆAd,1 and consider the following stochastic diï¬€erential
equation:
dX(t) = b(t, X) dt + Ïƒ(t, X) dW(t),
t âˆˆ[0, âˆ[.
(E.1.1)
Deï¬nition E.1.1. An Rd-valued continuous, (Ft)-adapted process X(t), t âˆˆ
[0, âˆ[, on some stochastic basis (â„¦, F, P, (Ft)) is called a (weak) solution to
(E.1.1), if
121

122
E. Weak and Strong Solutions: Yamadaâ€“Watanabe Theorem
(i)
 t
0
|b(s, X)| ds < âˆ
P-a.e. for all t âˆˆ[0, âˆ[.
(ii)
 t
0
âˆ¥Ïƒ(s, X)âˆ¥2 ds < âˆ
P-a.e. for all t âˆˆ[0, âˆ[.
(iii) There exists an Rd1-valued standard (Ft)-Wiener process W(t), t âˆˆ
[0, âˆ[, on (â„¦, F, P) such that P-a.e.
X(t) = X(0)+
 t
0
b(s, X) ds+
 t
0
Ïƒ(s, X) dW(s),
t âˆˆ[0, âˆ[. (E.1.2)
Remark E.1.2.
(i) Clearly, by the measurability assumption on elements
in Ad,d1 it follows that if X is a solution, then [0, t] Ã— â„¦âˆ‹(s, Ï‰) 	â†’
Ïƒ(s, X(Ï‰)) is B([0, t])âŠ—F/B(M(dÃ—d1, R))-measurable and Ïƒ(t, X) is Ft-
measurable for t âˆˆ[0, âˆ[. Likewise for b(Â·, X). The (Ft)-adaptedness for
Ïƒ(Â·, X) and b(Â·, X) follows since the (Ft)-adaptiveness of X is equivalent
to the Ft/Bt(W d) measurability of X.
(ii) Below we shall brieï¬‚y say (X, W) in Deï¬nition E.1.1 is a (weak) solution
to (E.1.1) not always mentioning explicitly the stochastic basis, that
comes with it.
Deï¬nition E.1.3. We say that (weak) uniqueness holds for (E.1.1) if when-
ever
X
and
Xâ€²
are
two
(weak)
solutions
(with
stochastic
bases
(â„¦, F, P, (Ft)), (â„¦â€², Fâ€², P â€², (Fâ€²
t))
and
associated
Wiener
processes W(t),
W â€²(t), t âˆˆ[0, âˆ[) such that
P â—¦X(0)âˆ’1 = P â€² â—¦Xâ€²(0)âˆ’1,
(as measures on (Rd, B(Rd))), then
P â—¦Xâˆ’1 = P â€² â—¦(Xâ€²)âˆ’1
(as measures on (W d, B(W d))).
Deï¬nition E.1.4. We say that pathwise uniqueness holds for (E.1.1), if
whenever X and Xâ€² are two (weak) solutions on the same stochastic basis
(â„¦, F, P, (Ft)) and with the same (Ft)-Wiener process W(t), t âˆˆ[0, âˆ[ on
(â„¦, F, P) such that X(0) = Xâ€²(0) P-a.e., then P-a.e.
X(t) = Xâ€²(t), t âˆˆ[0, âˆ[.
To deï¬ne strong solutions we need to introduce the following class Ë†E of
maps:

E.1. The main result
123
Let Ë†E denote the set of all maps F : RdÃ—W d1
0
â†’W d such that for every prob-
ability measure Âµ on (Rd, B(Rd)) there exists a B(Rd) âŠ—B(W d1
0 )
ÂµâŠ—P W
/B(W d)-
measurable map FÂµ : Rd Ã— W d1
0
â†’W d such that for Âµ-a.e. x âˆˆRd
F(x, w) = FÂµ(x, w) for P W -a.e. w âˆˆW d1
0 .
Here B(Rd) âŠ—B(W d1
0 )
ÂµâŠ—P W
denotes the completion of B(Rd) âŠ—B(W d1
0 ) with
respect
to
Âµ âŠ—P W ,
and
P W
denotes
classical
Wiener
measure
on
(W d1
0 , B(W d1
0 )).
Let F âˆˆË†E. For an F/B(Rd)-measurable map Î¾ : â„¦â†’Rd on some prob-
ability space (â„¦, F, P) and an Rd1-valued, standard Wiener process W(t),
t âˆˆ[0, âˆ[, on (â„¦, F, P) independent of Î¾, we set
F(Î¾, W) := FP â—¦Î¾âˆ’1(Î¾, W).
Deï¬nition E.1.5. A (weak) solution X to (E.1.1) on (â„¦, F, P, (Ft)) and
associated Wiener process W(t), t âˆˆ[0, âˆ[, is called a strong solution if there
exists F âˆˆË†E such that for x âˆˆRd, w 	â†’F(x, w) is Bt(W d1
0 )
P W
/Bt(W d)-
measurable for every t âˆˆ[0, âˆ[ and
X = F(X(0), W)
P-a.e.,
where Bt(W d1
0 )
P W
denotes the completion with respect to P W in B(W d1
0 ).
Deï¬nition E.1.6. Equation (E.1.1) is said to have a unique strong solution,
if there exists F âˆˆË†E satisfying the adaptiveness condition in Deï¬nition E.1.5
and such that:
1. For every Rd1-valued standard (Ft)-Wiener process W(t), t âˆˆ[0, âˆ[, on
a stochastic basis (â„¦, F, P, (Ft)) and any F0/B(Rd)-measurable Î¾ : â„¦â†’
Rd the continuous process
X := F(Î¾, W)
satisï¬es (i), (ii) and (E.1.2) in Deï¬nition E.1.1, i.e. (F(Î¾, W), W) is a
(weak) solution to (E.1.1), and X(0) = Î¾ P-a.e..
2. For any (weak) solution (X, W) to (E.1.1) we have
X = F(X(0), W) P-a.e..
Remark E.1.7. Since X(0) in the above deï¬nition is P-independent of W,
thus
P â—¦(X(0), W)âˆ’1 = Âµ âŠ—P W ,
we have that the existence of a unique strong solution for (E.1.1) implies that
also (weak) uniqueness holds.

124
E. Weak and Strong Solutions: Yamadaâ€“Watanabe Theorem
Now we can formulate the main result of this section.
Theorem E.1.8. Let Ïƒ âˆˆAd,d1 and b âˆˆAd,1. Then equation (E.1.1) has a
unique strong solution if and only if both of the following properties hold:
(i) For every probability measure Âµ on (Rd, B(Rd)) there exists a (weak)
solution (X, W) of (E.1.1) such that Âµ is the distribution of X(0).
(ii) Pathwise uniqueness holds for (E.1.1).
Proof. Suppose (E.1.1) has a unique strong solution. Then (ii) obviously
holds. To show (i) one only has to take the classical Wiener space
(W d1
0 , B(W d1
0 ), P W ) and consider (Rd Ã— W d1
0 , B(Rd) âŠ—B(W d1
0 )
ÂµâŠ—P W
, Âµ âŠ—P W )
with ï¬ltration
 
Îµ>0
Ïƒ(B(Rd) âŠ—Bt+Îµ(W d1
0 ), N),
t â©¾0,
where N
denotes all Âµ âŠ—P W -zero sets in B(Rd) âŠ—B(W d1
0 )
ÂµâŠ—P W
. Let
Î¾ : Rd Ã— W d1
0
â†’Rd and W : Rd Ã— W d1
0
â†’W d1
0
be the canonical projec-
tions. Then X := F(Î¾, W) is the desired weak solution in (i).
Now let us suppose that (i) and (ii) hold. The proof that then there exists a
unique strong solution for (E.1.1) is quite technical. We structure it through
a series of lemmas.
Lemma E.1.9. Let (â„¦, F) be a measurable space such that {Ï‰} âˆˆF for all
Ï‰ âˆˆâ„¦and such that
D := {(Ï‰, Ï‰)|Ï‰ âˆˆâ„¦} âˆˆF âŠ—F
(which is e.g. the case if â„¦is a Polish space and F its Borel Ïƒ-algebra).
Let P1, P2 be probability measures on (â„¦, F) such that P1 âŠ—P2(D) = 1. Then
P1 = P2 = Î´Ï‰0 for some Ï‰0 âˆˆâ„¦.
Proof. Let f : â„¦â†’[0, âˆ[ be F-measurable. Then

f(Ï‰1)P1(dÏ‰1) =

f(Ï‰1)P1(dÏ‰1)P2(dÏ‰2)
=

1D(Ï‰1, Ï‰2)f(Ï‰1)P1(dÏ‰1)P2(dÏ‰2)
=

1D(Ï‰1, Ï‰2)f(Ï‰2)P1(dÏ‰1)P2(dÏ‰2) =

f(Ï‰2)P2(dÏ‰2),
so P1 = P2. Furthermore,
1 =

1D(Ï‰1, Ï‰2)P1(dÏ‰1)P2(dÏ‰2) =

P1({Ï‰2})P2(dÏ‰2),
hence 1 = P1({Ï‰2}) for P2-a.e. Ï‰2 âˆˆâ„¦. Therefore, P1 = Î´Ï‰0 for some Ï‰0 âˆˆâ„¦.

E.1. The main result
125
Fix a probability measure Âµ on (Rd, B(Rd)) and let (X, W) with stochastic
basis (â„¦, F, P, (Ft)) be a (weak) solution to (E.1.1) with initial distribution Âµ.
Deï¬ne a probability measure PÂµ on (RdÃ—W dÃ—W d1
0 , B(Rd)âŠ—B(W d)âŠ—B(W d1
0 )),
by
PÂµ := P â—¦(X(0), X, W)âˆ’1.
Lemma E.1.10. There exists a family KÂµ((x, w), dw1), x âˆˆRd, w âˆˆW d1
0 , of
probability measures on (W d, B(W d)) having the following properties:
(i) For every A âˆˆB(W d) the map
Rd Ã— W d1
0
âˆ‹(x, w) 	â†’KÂµ((x, w), A)
is B(Rd) âŠ—B(W d1
0 )-measurable.
(ii) For every B(Rd) âŠ—B(W d) âŠ—B(W d1
0 )-measurable map f : Rd Ã— W d Ã—
W d1
0
â†’[0, âˆ[ we have

f(x, w1, w)PÂµ(dx dw1 dw)
=

Rd

W d1
0

W d f(x, w1, w)KÂµ((x, w), dw1)P W(dw)Âµ(dx).
(iii) If t âˆˆ[0, âˆ[ and f : W d â†’[0, âˆ[ is Bt(W d)-measurable, then
Rd Ã— W d1
0
âˆ‹(x, w) 	â†’

f(w1)KÂµ((x, w), dw1)
is B(Rd) âŠ—Bt(W d1
0 )
ÂµâŠ—P W
-measurable, where B(Rd) âŠ—Bt(W d1
0 )
ÂµâŠ—P W
de-
notes the completion with respect to Âµ âŠ—P W in B(Rd) âŠ—B(W d1
0 ).
Proof. Let Î  : Rd Ã—W d Ã—W d1
0
â†’Rd Ã—W d1
0
be the canonical projection. Since
X(0) is F0-measurable, hence P-independent of W, it follows that
PÂµ â—¦Î âˆ’1 = P â—¦(X(0), W)âˆ’1 = Âµ âŠ—P W .
Hence by the existence result on regular conditional distributions (cf. e.g.
[IW81, Corollary to Theorem 3.3 on p. 15]), the existence of the family
KÂµ((x, w), dw1), x âˆˆRd, w âˆˆW d1
0 , satisfying (i) and (ii) follows.
To prove (iii) it suï¬ƒces to show that for t âˆˆ[0, âˆ[ and for all A0 âˆˆB(Rd),
A1 âˆˆBt(W d), A âˆˆBt(W d1
0 ) and
Aâ€² := {Ï€r1 âˆ’Ï€t âˆˆB1, . . . , Ï€rk âˆ’Ï€t âˆˆBk},
t â©½r1 < . . . < rk, B1, . . . , Bk âˆˆB(Rd1),

126
E. Weak and Strong Solutions: Yamadaâ€“Watanabe Theorem

A0

W d1
0
1Aâˆ©Aâ€²(w)KÂµ((x, w), A1)P W(dw)Âµ(dx)
=

A0

W d1
0
1Aâˆ©Aâ€²(w)EÂµâŠ—P W (KÂµ(Â·, A1)|B(Rd) âŠ—Bt(W d1
0 ))P W(dw)Âµ(dx),
(E.1.3)
since the system of all A âˆ©Aâ€², A âˆˆBt(W d1
0 ), Aâ€² as above generates B(W d1
0 ).
But by part (ii) above, the left-hand side of (E.1.3) is equal to

1A0(x)1Aâˆ©Aâ€²(w)1A1(w1)PÂµ(dx dw1 dw)
=

1A0(X(0))1A1(X)1A(W)1Aâ€²(W) dP
=

1A0(X(0))1A1(X)1A(W)EP (1Aâ€²(W)|Ft) dP.
(E.1.4)
But 1Aâ€²(W) is P-independent of Ft, since W is an (Ft)-Wiener process on
(â„¦, F, P), so
EP (1Aâ€²(W)|Ft) = EP (1Aâ€²(W)).
Hence the right-hand side of (E.1.4) is equal to
P W (Aâ€²)

1A0(x)1A(w)1A1(w1)PÂµ(dx dw1 dw)
= P W (Aâ€²)

A0

A
KÂµ((x, w), A1)P W(dw)Âµ(dx)
= P W (Aâ€²)

A0

A
EÂµâŠ—P W (KÂµ(Â·, A1)|B(Rd) âŠ—Bt(W d1
0 ))((x, w))
P W(dw)Âµ(dx)
=

A0

W d1
0
1Aâˆ©Aâ€²(w)EÂµâŠ—P W (KÂµ(Â·, A1)|B(Rd) âŠ—Bt(W d1
0 ))((x, w))
P W(dw)Âµ(dx),
since Aâ€² is P W -independent of Bt(W d1
0 ).
For x âˆˆRd deï¬ne a measure Qx on
(Rd Ã— W d Ã— W d Ã— W d1
0 , B(Rd) âŠ—B(W d) âŠ—B(W d) âŠ—B(W d1
0 ))
by
Qx(A) :=

Rd

W d1
0

W d

W d 1A(z, w1, w2, w)
KÂµ((z, w), dw1)KÂµ((z, w), dw2)P W(dw)Î´x(dz).

E.1. The main result
127
Deï¬ne the stochastic basis
Ëœâ„¦:= Rd Ã— W d Ã— W d Ã— W d1
0
ËœFx := B(Rd) âŠ—B(W d) âŠ—B(W d) âŠ—B(W d1
0 )
Qx
ËœFx
t :=
 
Îµ>0
Ïƒ(B(Rd) âŠ—Bt+Îµ(W d) âŠ—Bt+Îµ(W d) âŠ—Bt+Îµ(W d1
0 ), Nx),
where
Nx := {N âˆˆËœFx|Qx(N) = 0},
and deï¬ne maps
Î 0 : Ëœâ„¦â†’Rd, (x, w1, w2, w) 	â†’x,
Î i : Ëœâ„¦â†’W d, (x, w1, w2, w) 	â†’wi âˆˆW d,
i = 1, 2,
Î 3 : Ëœâ„¦â†’W d1
0 , (x, w1, w2, w) 	â†’w âˆˆW d1
0 .
Then, obviously,
Qx â—¦Î âˆ’1
0
= Î´x
(E.1.5)
and
Qx â—¦Î âˆ’1
3
= P W (= P â—¦W âˆ’1).
(E.1.6)
Lemma E.1.11. There exists N0 âˆˆB(Rd) with Âµ(N0) = 0 such that for all
x âˆˆN c
0 we have that Î 3 is an ( ËœFx
t )-Wiener process on (Ëœâ„¦, ËœFx, Qx) taking
values in Rd1.
Proof. By deï¬nition Î 3 is ( ËœFx
t )-adapted for every x âˆˆRd. Furthermore, for
0 â©½s < t, y âˆˆRd, and A0 âˆˆB(Rd), Ai âˆˆBs(W d), i = 1, 2, A3 âˆˆBs(W d1
0 ),

Rd EQx(exp(iâŸ¨y, Î 3(t) âˆ’Î 3(s)âŸ©)1A0Ã—A1Ã—A2Ã—A3)Âµ(dx)
=

Rd

W d1
0
exp(iâŸ¨y, w(t) âˆ’w(s)âŸ©)1A0(x)1A3(w)
KÂµ((x, w), A1)KÂµ((x, w), A2)P W(dw)Âµ(dx)
=

W d1
0
exp(iâŸ¨y, w(t) âˆ’w(s)âŸ©)P W(dw)

Rd
Qx(A0 Ã— A1 Ã— A2 Ã— A3)Âµ(dx),
where we used Lemma E.1.10(iii) in the last step. Now the assertion follows
by (E.1.6), a monotone class argument and the same reasoning as in the proof
of Proposition 2.1.13.

128
E. Weak and Strong Solutions: Yamadaâ€“Watanabe Theorem
Lemma E.1.12. There exists N1 âˆˆB(Rd), N0 âŠ‚N1, with Âµ(N1) = 0 such
that
for
all
x
âˆˆ
N c
1,
(Î 1, Î 3)
and
(Î 2, Î 3)
with
stochastic
basis
(Ëœâ„¦, ËœFx, Qx, ( ËœFx
t )) are (weak) solutions of (E.1.1) such that
Î 1(0) = Î 2(0) = x
Qx-a.e.,
therefore, Î 1 = Î 2 Qx-a.e.
Proof. For i = 1, 2 consider the set Ai âˆˆËœFx deï¬ned by
Ai :=

Î i(t) âˆ’Î i(0) =
 t
0
b(s, Î i) ds +
 t
0
Ïƒ(s, Î i) dÎ 3(s)
for all t âˆˆ[0, âˆ[

âˆ©{Î i(0) = Î 0}.
Deï¬ne A âˆˆB(Rd) âŠ—B(W d) âŠ—B(W d1
0 ) analogously with Î i replaced by the
canonical projection from Rd Ã— W d Ã— W d1
0
onto the second and Î 0, Î 3 by the
canonical projection onto the ï¬rst and third coordinate respectively. Then by
Lemma E.1.10 (ii) for i = 1, 2

Rd

W d1
0

W d

W d 1Ai(x, w1, w2, w)
KÂµ((x, w), dw1)KÂµ((x, w), dw2)P W(dw)Âµ(dx)
= PÂµ(A) = P({(X(0), X, W) âˆˆA}) = 1.
(E.1.7)
Since all measures in the left-hand side of (E.1.7) are probability measures, it
follows that for Âµ-a.e. x âˆˆRd
1 = Qx(Ai) = Qx(Ai,x),
where for i = 1, 2
Ai,x :=

Î i(t) âˆ’x =
 t
0
b(s, Î i) ds +
 t
0
Ïƒ(s, Î i) dÎ 3(s), âˆ€t âˆˆ[0, âˆ[

!.
Hence the ï¬rst assertion follows. The second then follows by the pathwise
uniqueness assumption in condition (ii) of the theorem.
Lemma E.1.13. There exists a B(Rd) âŠ—B(W d1
0 )
ÂµâŠ—P W
/B(W d)- measurable
map
FÂµ : Rd Ã— W d1
0
â†’W d
such that
KÂµ((x, w), Â·) = Î´FÂµ(x,w)
(= Dirac measure on B(W d) with mass in FÂµ(x, w))

E.1. The main result
129
for
Âµ âŠ—P W -a.e.
(x, w)
âˆˆ
Rd
Ã— W d1
0 .
Furthermore,
FÂµ
is
B(Rd) âŠ—Bt(W d1
0 )
ÂµâŠ—P W
/Bt(W d)-measurable
for
all
t
âˆˆ
[0, âˆ[,
where
B(Rd) âŠ—Bt(W d1
0 )
ÂµâŠ—P W
denotes the completion with respect to Âµ âŠ—P W in
B(Rd) âŠ—Bt(W d1
0 ).
Proof. By Lemma E.1.12 for all x âˆˆN c
1, we have
1 = Qx({Î 1 = Î 2})
=

W d1
0

W d

W d 1D(w1, w2)KÂµ((x, w), dw1)KÂµ((x, w), dw2)P W(dw),
where D := {(w1, w1) âˆˆW d Ã— W d|w1 âˆˆW d}. Hence by Lemma E.1.9 there
exists N âˆˆB(Rd)âŠ—B(W d1
0 ) such that ÂµâŠ—P W (N) = 0 and for all (x, w) âˆˆN c
there exists FÂµ(x, w) âˆˆW d such that
KÂµ((x, w), dw1) = Î´FÂµ(x,w)(dw1).
Set FÂµ(x, w) := 0, if (x, w) âˆˆN. Let A âˆˆB(W d). Then
{FÂµ âˆˆA} = ({FÂµ âˆˆA} âˆ©N) âˆª({KÂµ(Â·, A) = 1} âˆ©N c)
and the measurability properties of FÂµ follow from Lemma E.1.10.
Having deï¬ned the mapping FÂµ let us check the conditions of Deï¬nition
E.1.5 and Deï¬nition E.1.6. We start with condition 2.
Lemma E.1.14. We have
X = FÂµ(X(0), W)
P-a.e..
Proof. By Lemmas E.1.10 and E.1.13 we have
P({X = FÂµ(X(0), W)})
=

Rd

W d1
0

W d
1{w1=FÂµ(x,w)}(x, w1, w)Î´FÂµ(x,w)(dw1)P W(dw)Âµ(dx)
=1.
Now let us check condition 1. Let W â€² be another Rd1-valued standard (Fâ€²
t)-
Wiener process on a stochastic basis (â„¦â€², Fâ€², P â€², (Fâ€²
t)) and Î¾ : â„¦â€² â†’Rd an
Fâ€²
0/B(Rd)-measurable map and Âµ := P â€² â—¦Î¾âˆ’1. Let FÂµ be as above and set
Xâ€² := FÂµ(Î¾, W â€²).

130
E. Weak and Strong Solutions: Yamadaâ€“Watanabe Theorem
Lemma E.1.15. (Xâ€², W â€²) is a (weak) solution to (E.1.1) with Xâ€²(0) = Î¾
P â€²-a.s..
Proof. We have
P â€²({Î¾ = Xâ€²(0)}) = P â€²({Î¾ = FÂµ(Î¾, W â€²)(0)})
= Âµ âŠ—P W ({(x, w) âˆˆRd Ã— W d1
0 |x = FÂµ(x, w)})
= P({X(0) = FÂµ(X(0), W)(0)}) = 1,
where we used Lemma E.1.14 in the last step.
To see that (Xâ€², W â€²) is a (weak) solution we consider the set A âˆˆB(Rd) âŠ—
B(W d)âŠ—B(W d1
0 ) deï¬ned in the proof of Lemma E.1.12. We have to show that
P â€²({(Xâ€²(0), Xâ€², W â€²) âˆˆA}) = 1.
But since Xâ€²(0) = Î¾ is P â€²-independent of W â€², we have

1A(Xâ€²(0), FÂµ(Xâ€²(0), W â€²), W â€²) dP â€²
=

Rd

W d1
0
1A(x, FÂµ(x, w), w)P W(dw)Âµ(dx)
=

Rd

W d1
0

W d 1A(x, w1, w)Î´FÂµ(x,w)(dw1)P W(dw)Âµ(dx)
=

1A(x, w1, w)PÂµ(dx dw1 dw)
=P({(X(0), X, W) âˆˆA}) = 1,
where we used E.1.10 and E.1.11 in the second to last step.
To complete the proof we still have to construct F âˆˆË†E and to check the
adaptiveness conditions on the corresponding mappings FÂµ. Below we shall
apply what we have obtained above now also to Î´x replacing Âµ. So, for each
x âˆˆRd we have a function FÎ´x. Now deï¬ne
F(x, w) := FÎ´x(x, w), x âˆˆRd, w âˆˆW d1
0 .
(E.1.8)
The proof of Theorem E.1.8 is then completed by the following lemma.
Lemma E.1.16. Let Âµ be a probability measure on (Rd, B(Rd)) and FÂµ :
Rd Ã— W d1
0
â†’W d as constructed in Lemma E.1.13. Then for Âµ-a.e. x âˆˆRd
F(x, Â·) = FÂµ(x, Â·)
P W âˆ’a.e..
Furthermore, F(x, Â·) is Bt(W d1
0 )
P W
/Bt(W d)-measurable for all x
âˆˆ
Rd,
t âˆˆ[0, âˆ[, where Bt(W d1
0 )
P W
denotes the completion of Bt(W d1
0 ) with respect
to P W in B(W d1
0 ).

E.1. The main result
131
Proof. Let
Â¯â„¦:= Rd Ã— W d Ã— W d1
0
Â¯F := B(Rd) âŠ—B(W d) âŠ—B(W d1
0 )
and ï¬x x âˆˆRd. Deï¬ne a measure Â¯Qx on (Â¯â„¦, Â¯F) by
Â¯Qx(A) :=

Rd

W d1
0

W d 1A(z, w1, w)KÂµ((z, w), dw1)P W(dw)Î´x(dz)
with KÂµ as in Lemma E.1.10. Consider the stochastic basis (Â¯â„¦, Â¯Fx, Â¯Qx, ( Â¯Fx
t ))
where
Â¯Fx := B(Rd) âŠ—B(W d) âŠ—B(W d1
0 )
Â¯
Qx,
Â¯Fx
t :=
 
Îµ>0
Ïƒ(B(Rd) âŠ—Bt+Îµ(W d) âŠ—Bt+Îµ(W d1
0 ), Â¯
Nx),
where Â¯
Nx := {N âˆˆÂ¯Fx| Â¯Qx(N) = 0}. As in the proof of Lemma E.1.12 one
shows that (Î , Î 3) on (Â¯â„¦, Â¯Fx, Â¯Qx, ( Â¯Fx
t )) is a (weak) solution to (E.1.1) with
Î (0) = x Â¯Qx-a.e. Here
Î 0 : Rd Ã— W d Ã— W d1
0
â†’Rd, (x, w1, w) 	â†’x,
Î  : Rd Ã— W d Ã— W d1
0
â†’W d, (x, w1, w) 	â†’w1,
Î 3 : Rd Ã— W d Ã— W d1
0
â†’W d1
0 , (x, w1, w) 	â†’w.
By Lemma E.1.15 (FÎ´x(x, Î 3), Î 3) on the stochastic basis (Â¯â„¦, Â¯Fx, Â¯Qx, ( Â¯Fx
t ))
is a (weak) solution to (E.1.1) with
FÎ´x(x, Î 3)(0) = x.
Hence by our pathwise uniqueness assumption (ii), it follows that
FÎ´x(x, Î 3) = Î 
Â¯Qx-a.s..
(E.1.9)
Hence for all A âˆˆB(Rd) âŠ—B(W d) âŠ—B(W d1
0 ) by Lemma E.1.13 and (E.1.9)

Rd

W d

W d1
0
1A(x, w1, w)Î´FÂµ(x,w)(dw1)P W(dw)Âµ(dx)
=

Rd
Â¯Qx(A)Âµ(dx)
=

Rd

Â¯â„¦
1A(Î 0, FÎ´x(x, Î 3), Î 3) d Â¯QxÂµ(dx)
=

Rd

W
d!
0
1A(x, FÎ´x(x, w), w)P W(dw)Âµ(dx)
=

Rd

W d1
0

W d 1A(x, w1, w)Î´FÎ´x(x,w)(dw1)P W(dw)Âµ(dx),

132
E. Weak and Strong Solutions: Yamadaâ€“Watanabe Theorem
which implies the assertion.
Let x âˆˆRd, t âˆˆ[0, âˆ[, A âˆˆBt(W d), and deï¬ne
Â¯FÎ´x := 1{x}Ã—W d1
0 FÎ´x.
Then
Â¯FÎ´x = FÎ´x
Î´x âŠ—P W âˆ’a.e.,
hence
{ Â¯FÎ´x âˆˆA} âˆˆB(Rd) âŠ—Bt(W d1
0 )
Î´xâŠ—P W
.
(E.1.10)
But
{ Â¯FÎ´x âˆˆA} = {x} Ã— {FÎ´x(x, Â·) âˆˆA} âˆª(Rd\{x}) Ã— {0 âˆˆA},
so by (E.1.10) it follows that
{FÎ´x(x, Â·) âˆˆA} âˆˆBt(W d1
0 )
P W
.

F. Strong, Mild and Weak
Solutions
This chapter is a short version of Chapter 2 in [FK01]. We only state the
results and refer to [FK01], [DPZ92] for the proofs.
As in previous chapters let (U, âˆ¥âˆ¥U) and (H, âˆ¥âˆ¥) be separable Hilbert spaces.
We take Q = I and ï¬x a cylindrical Q-Wiener process W(t), t â©¾0, in U on a
probability space (â„¦, F, P) with a normal ï¬ltration Ft, t â©¾0. Moreover, we
ï¬x T > 0 and consider the following type of stochastic diï¬€erential equations
in H:
dX(t) = [CX(t) + F(X(t))] dt + B(X(t)) dW(t),
t âˆˆ[0, T],
X(0) = Î¾,
(F.0.1)
where:
â€¢ C : D(C) â†’H is the inï¬nitesimal generator of a C0-semigroup S(t),
t â©¾0, of linear operators on H,
â€¢ F : H â†’H is B(H)/B(H)-measurable,
â€¢ B : H â†’L(U, H),
â€¢ Î¾ is a H-valued, F0-measurable random variable.
Deï¬nition F.0.1 (mild solution). An H-valued predictable process X(t),
t âˆˆ[0, T], is called a mild solution of problem (F.0.1) if
X(t) = S(t)Î¾ +
 t
0
S(t âˆ’s)F(X(s)) ds
+
 t
0
S(t âˆ’s)B(X(s)) dW(s)
P-a.s.
(F.0.2)
for each t âˆˆ[0, T]. In particular, the appearing integrals have to be well-
deï¬ned.
Deï¬nition F.0.2 (analytically strong solutions). A D(C)-valued pre-
dictable process X(t), t âˆˆ[0, T], (i.e. (s, Ï‰) 	â†’X(s, Ï‰) is PT /B(H)-
measurable) is called an analytically strong solution of problem (F.0.1) if
X(t) = Î¾ +
 t
0
CX(s) + F(X(s)) ds +
 t
0
B(X(s)) dW(s)
P-a.s.
(F.0.3)
133

134
F. Strong, Mild and Weak Solutions
for each t âˆˆ[0, T]. In particular, the integrals on the right-hand side have to be
well-deï¬ned, that is, CX(t), F(X(t)), t âˆˆ[0, T], are P-a.s. Bochner integrable
and B(X) âˆˆNW .
Deï¬nition F.0.3 (analytically weak solution). An H-valued predictable
process X(t), t âˆˆ[0, T], is called an analytically weak solution of problem
(F.0.1) if
âŸ¨X(t), Î¶âŸ©= âŸ¨Î¾, Î¶âŸ©+
 t
0
âŸ¨X(s), Câˆ—Î¶âŸ©+ âŸ¨F(X(s)), Î¶âŸ©ds
+
 t
0
âŸ¨Î¶, B(X(s))dW(s)âŸ©
P-a.s.
(F.0.4)
for each t âˆˆ[0, T] and Î¶ âˆˆD(Câˆ—). Here (Câˆ—, D(Câˆ—)) is the adjoint of (C, D(C))
on H.
In particular, as in Deï¬nitions F.0.2 and F.0.1, the appearing integrals have
to be well-deï¬ned.
Proposition F.0.4 (analytically weak versus analytically strong so-
lutions).
(i) Every analytically strong solution of problem (F.0.1) is also an analyti-
cally weak solution.
(ii) Let X(t), t âˆˆ[0, T], be an analytically weak solution of problem (F.0.1)
with values in D(C) such that B(X(t)) takes values in L2(U, H) for all
t âˆˆ[0, T]. Besides we assume that
P
 T
0
âˆ¥CX(t)âˆ¥dt < âˆ

= 1
P
 T
0
âˆ¥F(X(t))âˆ¥dt < âˆ

= 1
P
 T
0
âˆ¥B(X(t))âˆ¥2
L2 dt < âˆ

= 1.
Then the process is also an analytically strong solution.
Proposition F.0.5 (analytically weak versus mild solutions).
(i) Let X(t), t âˆˆ[0, T], be an analytically weak solution of problem (F.0.1)
such that B(X(t)) takes values in L2(U, H) for all t âˆˆ[0, T]. Besides

F. Strong, Mild and Weak Solutions
135
we assume that
P
 T
0
âˆ¥X(t)âˆ¥dt < âˆ

= 1
P
 T
0
âˆ¥F(X(t))âˆ¥dt < âˆ

= 1
P
 T
0
âˆ¥B(X(t))âˆ¥2
L2 dt < âˆ

= 1.
Then the process is also a mild solution.
(ii) Let X(t), t âˆˆ[0, T], be a mild solution of problem (F.0.1) such that the
mappings
(t, Ï‰) 	â†’
 t
0
S(t âˆ’s)F(X(s, Ï‰)) ds
(t, Ï‰) 	â†’
 t
0
S(t âˆ’s)B(X(s)) dW(s)(Ï‰)
have predictable versions. In addition, we require that
P(
 T
0
âˆ¥F(X(t))âˆ¥dt < âˆ) = 1
 T
0
E(
 t
0
âˆ¥âŸ¨S(t âˆ’s)B(X(s)), Câˆ—Î¶âŸ©âˆ¥2
L2(U,R) ds) dt < âˆ
for all Î¶ âˆˆD(Câˆ—).
Then the process is also an analytically weak solution.
Remark F.0.6. The precise relation of mild and analytically weak solutions
with the variational solutions from Deï¬nition 4.2.1 is obviously more diï¬ƒcult
to describe in general. We shall concentrate just on the following quite typical
special case:
Consider the situation of Subsection 4.2, but with A and B independent of t
and Ï‰. Assume that there exist a self-adjoint operator (C, D(C)) on H such
that âˆ’C â©¾const. > 0 and F : H â†’H B(H)/B(H)-measurable such that
A(x) = C(x) + F(x),
x âˆˆV,
and
V := D((âˆ’C)
1
2 ),
equipped with the graph norm of (âˆ’C)
1
2 . Then it is easy to see that C extends
to a continuous linear operator form V to V âˆ—, again denoted by C such that
for x âˆˆV , y âˆˆD(C)
V âˆ—âŸ¨Cx, yâŸ©V = âŸ¨x, CyâŸ©.
(F.0.5)

136
F. Strong, Mild and Weak Solutions
Now let X be a (variational) solution in the sense of Deï¬nition 4.2.1, then
it follows immediately from (F.0.5) that X is an analytically weak solution in
the sense of Deï¬nition F.0.3.

Bibliography
[Alt92]
H. W. Alt, Lineare Funktionalanalysis, Springer-Verlag, 1992.
[AR91]
S. Albeverio and M. RÂ¨ockner, Stochastic diï¬€erential equa-
tions in inï¬nite dimensions: solutions via Dirichlet forms,
Probab. Theory Related Fields 89 (1991), no. 3, 347â€“386. MR
MR1113223 (92k:60123)
[Aro86]
D. G. Aronson, The porous medium equation, Nonlinear dif-
fusion problems (Montecatini Terme, 1985), Lecture Notes
in Math., vol. 1224, Springer, Berlin, 1986, pp. 1â€“46. MR
MR877986 (88a:35130)
[Bau01]
H. Bauer, Measure and integration theory, de Gruyter Studies
in Mathematics, vol. 26, Walter de Gruyter & Co., Berlin, 2001.
[Coh80]
D. L. Cohn, Measure theory, BirkhÂ¨auser, 1980.
[Doo53]
J. L. Doob, Stochastic processes, John Wiley & Sons Inc., New
York, 1953. MR MR0058896 (15,445b)
[DP04]
G. Da Prato, Kolmogorov equations for stochastic PDEs,
Advanced
Courses
in
Mathematics
â€“
CRM
Barcelona,
Birkhaeuser, Basel, 2004.
[DPRLRW06] G. Da Prato, M. RÂ¨ockner, B. L. Rozowskii and F. Y. Wang,
Strong solutions of stochastic generalized porous media equa-
tions: existence, uniqueness, and ergodicity, Comm. Partial
Diï¬€erential Equations 31 (2006), nos 1â€“3, 277â€“291. MR
MR2209754
[DPZ92]
G. Da Prato and J. Zabczyk, Stochastic equations in inï¬nite
dimensions, Cambridge University Press, 1992.
[DPZ96]
, Ergodicity for inï¬nite-dimensional systems, London
Mathematical Society Lecture Note Series, vol. 229, Cambridge
University Press, 1996.
137

138
Bibliography
[FK01]
K. Frieler and C. Knoche, Solutions of stochastic diï¬€erential
equations in inï¬nite dimensional Hilbert spaces and their de-
pendence on initial data, Diploma Thesis, Bielefeld University,
BiBoS-Preprint E02-04-083, 2001.
[GK81]
I. GyÂ¨ongy and N. V. Krylov, On stochastic equations with re-
spect to semimartingales. I, Stochastics 4 (1980/81), no. 1, 1â€“
21. MR MR587426 (82j:60104)
[GK82]
, On stochastics equations with respect to semimartin-
gales.
II.
ItË†o
formula
in
Banach
spaces,
Stochastics
6
(1981/82), nos 3â€“4, 153â€“173. MR MR665398 (84m:60070a)
[GT83]
D. Gilbarg and N. S. Trudinger, Elliptic partial diï¬€erential
equations of second order, second ed., Grundlehren der Math-
ematischen Wissenschaften [Fundamental Principles of Math-
ematical Sciences], vol. 224, Springer-Verlag, Berlin, 1983. MR
MR737190 (86c:35035)
[GyÂ¨o82]
I. GyÂ¨ongy, On stochastic equations with respect to semimartin-
gales. III, Stochastics 7 (1982), no. 4, 231â€“254. MR MR674448
(84m:60070b)
[IW81]
N. Ikeda and S. Watanabe, Stochastic diï¬€erential equations
and diï¬€usion processes, North-Holland Mathematical Library,
vol. 24, North-Holland Publishing Co., Amsterdam, 1981.
[KR79]
N. V. Krylov and B. L. RozowskiË˜Ä±, Stochastic evolution equa-
tions, Current problems in mathematics, Vol. 14 (Russian),
Akad. Nauk SSSR, Vsesoyuz. Inst. Nauchn. i Tekhn. In-
formatsii, Moscow, 1979, pp. 71â€“147, 256. MR MR570795
(81m:60116)
[Kry99]
N.
V.
Krylov,
On
Kolmogorovâ€™s
equations
for
ï¬nite-
dimensional diï¬€usions, Stochastic PDEâ€™s and Kolmogorov
equations in inï¬nite dimensions (Cetraro, 1998), Lecture Notes
in Math., vol. 1715, Springer, Berlin, 1999, pp. 1â€“63. MR
MR1731794 (2000k:60155)
[KS88]
I. Karatzas and S. E. Shreve, Brownian motion and stochastic
calculus, Graduate Texts in Mathematics, vol. 113, Springer-
Verlag, New York, 1988. MR MR917065 (89c:60096)
[MV92]
R. Meise and D. Vogt, EinfÂ¨uhrung in die Funktionalanalysis,
Vieweg Verlag, 1992.
[Ond04]
M. OndrejÂ´at, Uniqueness for stochastic evolution equations in
Banach spaces, Dissertationes Math. (Rozprawy Mat.) 426
(2004), 1â€“63.

Bibliography
139
[Par72]
E. Pardoux, Sur des Â´equations aux dÂ´erivÂ´ees partielles stochas-
tiques monotones, C. R. Acad. Sci. Paris SÂ´er. A-B 275 (1972),
A101â€“A103. MR MR0312572 (47 #1129)
[Par75]
, Â´Equations aux dÂ´erivÂ´ees partielles stochastiques de type
monotone, SÂ´eminaire sur les Â´Equations aux DÂ´erivÂ´ees Partielles
(1974â€“1975), III, Exp. No. 2, Coll`ege de France, Paris, 1975,
p. 10. MR MR0651582 (58 #31406)
[Roz90]
B. Rozowskii, Stochastic evolution systems, Mathematics and
its Applications, no. 35, Kluwer Academic Publishers Group,
Dordrecht, 1990.
[RRW06]
J. Ren, M. RÂ¨ockner and F. Y. Wang, Stochastic porous media
and fast diï¬€usion equations, Preprint, 33 pages, 2006.
[RS72]
M. Reed and B. Simon, Methods of modern mathematical
physics, Academic Press, 1972.
[Wal86]
J. B. Walsh, An introduction to stochastic partial diï¬€erential
equations, Â´Ecole dâ€™Â´etÂ´e de probabilitÂ´es de Saint-Flour, XIVâ€”
1984, Lecture Notes in Math., vol. 1180, Springer, Berlin, 1986,
pp. 265â€“439. MR MR876085 (88a:60114)
[WW90]
H. WeizsÂ¨acker and G. Winkler, Stochastic integrals: an intro-
duction, Vieweg, 1990.
[Zab98]
J. Zabczyk, Parabolic equations on Hilbert spaces, Stochas-
tic PDEs and Kolmogorov Equations in Inï¬nite Dimensions
(Giuseppe Da Prato, ed.), Lecture Notes in Mathematics,
Springer Verlag, 1998, pp. 117â€“213.
[Zei90]
E. Zeidler, Nonlinear functional analysis and its applications.
II/B, Springer-Verlag, New York, 1990, Nonlinear monotone
operators, Translated from the German by the author and Leo
F. Boron. MR MR1033498 (91b:47002)

Index
Bochner inequality, 107
Bochner integral, 105
boundedness, 56
Burkholder-Davis inequality, 119
coercivity, 56
conditional expectation, 17
covariance operator, 6
demicontinuity, 56
elementary process, 22
existence
- of a unique solution in ï¬nite
dimensions, 44
fundamental theorem of calculus,
108
Gaussian
- law, 6
- measure, 5
- random variable, 9
representation and existence
of a -, 9
Gelfand triple, 55
hemicontinuity, 56
Hilbertâ€“Schmidt norm, 111
ItË†o isometry, 25
local weak monotonicity, 44
localization lemma, 45
localization procedure, 30
martingale, 19
maximal inequality, 20
normal ï¬ltration, 16
operator
Hilbertâ€“Schmidt -, 110
nonnegative -, 109
nuclear -, 109
symmetric -, 109
trace class -, 109
p-Laplacian, 65
predictable process, 28
predictable Ïƒ-ï¬eld, 27
pseudo inverse, 115
quadratic variation of the stochas-
tic integral, 37
Sobolev space, 62
solution
analytically strong -, 133
analytically weak -, 134
- in ï¬nite dimensions, 44
mild -, 133
strong -, 123
weak -, 121
square root of a linear operator, 25
stochastic basis, 121
stochastic diï¬€erential equation
Burgers equation, 3
heat equation, 65
- in ï¬nite dimensions, 44
- in inï¬nite dimensions, 55
Navierâ€“Stokes equation, 3
porous media equation, 3
141

142
Index
reaction diï¬€usion equation, 3,
67
stochastic integral
- w.r.t. a standard Wiener process,
22
stochastically integrable process, 30
strong measurability, 106
trace, 109
uniqueness
pathwise -, 122
strong -, 123
weak -, 122
weak monotonicity, 56
Wiener process
- as a martingale, 21
standard -, 13
representation and existence
of a -, 13
- with respect to a ï¬ltration,
16
Yamadaâ€“Watanabe
Theorem of -, 124

Symbols
N(m, Q)
Gaussian measure with mean m and covariance
Q, 6
W(t), t âˆˆ[0, T]
standard Wiener process, 13
cylindrical Wiener process, 39
E(X|G)
conditional expectation of X given G, 18
M2
T (E)
space of all continuous E-valued, square inte-
grable martingales, 20
E
class of all L(U, H)-valued elementary processes,
22
â„¦T
[0, T] Ã— â„¦, 21
dx
Lebesgue measure, 21
PT
dx|[0,T ] âŠ—P, 21
PT
predictable Ïƒ-ï¬eld on â„¦T , 27
'
Î¦(s) dW(s)
stochastic integral w.r.t. W, 22
Lp(â„¦, F, Âµ; X)
set of all with respect to Âµ p-integrable mappings
from â„¦to X, 106
Lp(â„¦, F, Âµ)
Lp(â„¦, F, Âµ; R)
Lp
0
Lp(â„¦, F0, P; H)
Lp([0, T]; H)
Lp([0, T], B([0, T]), dx; H)
Lp([0, T], dx)
Lp([0, T], B([0, T]), dx; R)
âˆ¥âˆ¥T
L2-norm on L2(â„¦T , PT , PT ; L0
2), 25
N 2
W (0, T; H)
L2(â„¦T , PT , PT ; L0
2), 28
N 2
W (0, T)
N 2
W (0, T; H)
N 2
W
N 2
W (0, T; H)
NW (0, T; H)
space of all stochastically integrable processes, 30
NW (0, T)
NW (0, T; H)
L(U, H)
space of all bounded and linear operators from U
to H, 109
L(U)
L(U, U)
L1(U, H)
space of all nuclear operators from U to H, 109
tr Q
trace of Q, 109
L2(U, H)
space of all Hilbertâ€“Schmidt operators from U to
H, 110
âˆ¥âˆ¥L2
Hilbertâ€“Schmidt norm, 111
143

144
Symbols
Aâˆ—
adjoint operator of A âˆˆL(U, H)
Q
1
2
square root of Q âˆˆL(U), 25
T âˆ’1
(pseudo) inverse of T âˆˆL(U, H), 115
U0
Q
1
2 (U), 27
L0
2
L2(Q
1
2 (U), H), 27
âŸ¨u, vâŸ©0
âŸ¨Qâˆ’1
2 u, Qâˆ’1
2 vâŸ©U, 27
L(U, H)0
{TU0 | T âˆˆL(U, H)}, 27
M(d Ã— d1, R)
set of all real d Ã— d1-matrices, 43
(V, H, V âˆ—)
Gelfand triple, 55
Câˆ
0 (Î›)
set of all inï¬nitely diï¬€erentiable real-valued func-
tions on Î› with compact support, 62
âˆ¥âˆ¥1,p
norm on Câˆ
0 (Î›), 62
H1,p
0 (Î›)
Sobolev space, completion of Câˆ
0 (Î›) w.r.t. âˆ¥âˆ¥1,p,
62
âˆ†p
p-Laplacian, p â©¾2, 65
W d
C([0, âˆ[â†’Rd), 121
W d
0
{w âˆˆW d | w(0) = 0}, 121
B(W d), Bt(W d)
121
Ad,d1
121
Ë†E
122

Lecture Notes in Mathematics
For information about earlier volumes
please contact your bookseller or Springer
LNM Online archive: springerlink.com
Vol. 1715: N. V. Krylov, M. RÃ¶ckner, J. Zabczyk, Stochas-
tic PDEâ€™s and Kolmogorov Equations in Inï¬nite Dimen-
sions. Cetraro, 1998. Editor: G. Da Prato (1999)
Vol. 1716: J. Coates, R. Greenberg, K. A. Ribet, K. Ru-
bin, Arithmetic Theory of Elliptic Curves. Cetraro, 1997.
Editor: C. Viola (1999)
Vol. 1717: J. Bertoin, F. Martinelli, Y. Peres, Lectures
on Probability Theory and Statistics. Saint-Flour, 1997.
Editor: P. Bernard (1999)
Vol. 1718: A. Eberle, Uniqueness and Non-Uniqueness
of Semigroups Generated by Singular Diffusion Opera-
tors (1999)
Vol. 1719: K. R. Meyer, Periodic Solutions of the N-Body
Problem (1999)
Vol. 1720: D. Elworthy, Y. Le Jan, X-M. Li, On the Geo-
metry of Diffusion Operators and Stochastic Flows (1999)
Vol. 1721: A. Iarrobino, V. Kanev, Power Sums, Goren-
stein Algebras, and Determinantal Loci (1999)
Vol. 1722: R. McCutcheon, Elemental Methods in Ergodic
Ramsey Theory (1999)
Vol. 1723: J. P. Croisille, C. Lebeau, Diffraction by an
Immersed Elastic Wedge (1999)
Vol. 1724: V. N. Kolokoltsov, Semiclassical Analysis for
Diffusions and Stochastic Processes (2000)
Vol. 1725: D. A. Wolf-Gladrow, Lattice-Gas Cellular
Automata and Lattice Boltzmann Models (2000)
Vol. 1726: V. MariÂ´c, Regular Variation and Differential
Equations (2000)
Vol. 1727: P. Kravanja M. Van Barel, Computing the Zeros
of Analytic Functions (2000)
Vol. 1728: K. Gatermann Computer Algebra Methods for
Equivariant Dynamical Systems (2000)
Vol. 1729: J. AzÃ©ma, M. Ã‰mery, M. Ledoux, M. Yor (Eds.)
SÃ©minaire de ProbabilitÃ©s XXXIV (2000)
Vol. 1730: S. Graf, H. Luschgy, Foundations of Quantiza-
tion for Probability Distributions (2000)
Vol. 1731: T. Hsu, Quilts: Central Extensions, Braid
Actions, and Finite Groups (2000)
Vol. 1732: K. Keller, Invariant Factors, Julia Equivalences
and the (Abstract) Mandelbrot Set (2000)
Vol. 1733: K. Ritter, Average-Case Analysis of Numerical
Problems (2000)
Vol. 1734: M. Espedal, A. Fasano, A. MikeliÂ´c, Filtration in
Porous Media and Industrial Applications. Cetraro 1998.
Editor: A. Fasano. 2000.
Vol. 1735: D. Yafaev, Scattering Theory: Some Old and
New Problems (2000)
Vol. 1736: B. O. Turesson, Nonlinear Potential Theory and
Weighted Sobolev Spaces (2000)
Vol. 1737: S. Wakabayashi, Classical Microlocal Analysis
in the Space of Hyperfunctions (2000)
Vol. 1738: M. Ã‰mery, A. Nemirovski, D. Voiculescu,
Lectures on Probability Theory and Statistics (2000)
Vol. 1739: R. Burkard, P. Deuï¬‚hard, A. Jameson, J.-L.
Lions, G. Strang, Computational Mathematics Driven
by Industrial Problems. Martina Franca, 1999. Editors:
V. Capasso, H. Engl, J. Periaux (2000)
Vol. 1740: B. Kawohl, O. Pironneau, L. Tartar, J.-P. Zole-
sio, Optimal Shape Design. TrÃ³ia, Portugal 1999. Editors:
A. Cellina, A. Ornelas (2000)
Vol. 1741: E. Lombardi, Oscillatory Integrals and Phe-
nomena Beyond all Algebraic Orders (2000)
Vol. 1742: A. Unterberger, Quantization and Non-
holomorphic Modular Forms (2000)
Vol. 1743: L. Habermann, Riemannian Metrics of Con-
stant Mass and Moduli Spaces of Conformal Structures
(2000)
Vol. 1744: M. Kunze, Non-Smooth Dynamical Systems
(2000)
Vol. 1745: V. D. Milman, G. Schechtman (Eds.), Geomet-
ric Aspects of Functional Analysis. Israel Seminar 1999-
2000 (2000)
Vol. 1746: A. Degtyarev, I. Itenberg, V. Kharlamov, Real
Enriques Surfaces (2000)
Vol. 1747: L. W. Christensen, Gorenstein Dimensions
(2000)
Vol. 1748: M. Ruzicka, Electrorheological Fluids: Model-
ing and Mathematical Theory (2001)
Vol. 1749: M. Fuchs, G. Seregin, Variational Methods
for Problems from Plasticity Theory and for Generalized
Newtonian Fluids (2001)
Vol. 1750: B. Conrad, Grothendieck Duality and Base
Change (2001)
Vol. 1751: N. J. Cutland, Loeb Measures in Practice:
Recent Advances (2001)
Vol. 1752: Y. V. Nesterenko, P. Philippon, Introduction to
Algebraic Independence Theory (2001)
Vol. 1753: A. I. Bobenko, U. Eitner, PainlevÃ© Equations in
the Differential Geometry of Surfaces (2001)
Vol. 1754: W. Bertram, The Geometry of Jordan and Lie
Structures (2001)
Vol. 1755: J. AzÃ©ma, M. Ã‰mery, M. Ledoux, M. Yor
(Eds.), SÃ©minaire de ProbabilitÃ©s XXXV (2001)
Vol. 1756: P. E. Zhidkov, Korteweg de Vries and Nonlin-
ear SchrÃ¶dinger Equations: Qualitative Theory (2001)
Vol. 1757: R. R. Phelps, Lectures on Choquetâ€™s Theorem
(2001)
Vol. 1758: N. Monod, Continuous Bounded Cohomology
of Locally Compact Groups (2001)
Vol. 1759: Y. Abe, K. Kopfermann, Toroidal Groups
(2001)
Vol. 1760: D. FilipoviÂ´c, Consistency Problems for Heath-
Jarrow-Morton Interest Rate Models (2001)
Vol. 1761: C. Adelmann, The Decomposition of Primes in
Torsion Point Fields (2001)
Vol. 1762: S. Cerrai, Second Order PDEâ€™s in Finite and
Inï¬nite Dimension (2001)
Vol. 1763: J.-L. Loday, A. Frabetti, F. Chapoton, F. Goi-
chot, Dialgebras and Related Operads (2001)

Vol. 1764: A. Cannas da Silva, Lectures on Symplectic
Geometry (2001)
Vol. 1765: T. Kerler, V. V. Lyubashenko, Non-Semisimple
Topological Quantum Field Theories for 3-Manifolds with
Corners (2001)
Vol. 1766: H. Hennion, L. HervÃ©, Limit Theorems for
Markov Chains and Stochastic Properties of Dynamical
Systems by Quasi-Compactness (2001)
Vol. 1767: J. Xiao, Holomorphic Q Classes (2001)
Vol. 1768: M. J. Pï¬‚aum, Analytic and Geometric Study of
Stratiï¬ed Spaces (2001)
Vol. 1769: M. Alberich-CarramiÃ±ana, Geometry of the
Plane Cremona Maps (2002)
Vol.
1770:
H.
Gluesing-Luerssen,
Linear
Delay-
Differential Systems with Commensurate Delays: An
Algebraic Approach (2002)
Vol. 1771: M. Ã‰mery, M. Yor (Eds.), SÃ©minaire de Prob-
abilitÃ©s 1967-1980. A Selection in Martingale Theory
(2002)
Vol. 1772: F. Burstall, D. Ferus, K. Leschke, F. Pedit,
U. Pinkall, Conformal Geometry of Surfaces in S4 (2002)
Vol. 1773: Z. Arad, M. Muzychuk, Standard Integral
Table Algebras Generated by a Non-real Element of Small
Degree (2002)
Vol. 1774: V. Runde, Lectures on Amenability (2002)
Vol. 1775: W. H. Meeks, A. Ros, H. Rosenberg, The
Global Theory of Minimal Surfaces in Flat Spaces.
Martina Franca 1999. Editor: G. P. Pirola (2002)
Vol. 1776: K. Behrend, C. Gomez, V. Tarasov, G. Tian,
Quantum Comohology. Cetraro 1997. Editors: P. de Bar-
tolomeis, B. Dubrovin, C. Reina (2002)
Vol. 1777: E. GarcÃ­a-RÃ­o, D. N. Kupeli, R. VÃ¡zquez-
Lorenzo,
Osserman
Manifolds
in
Semi-Riemannian
Geometry (2002)
Vol. 1778: H. Kiechle, Theory of K-Loops (2002)
Vol. 1779: I. Chueshov, Monotone Random Systems
(2002)
Vol. 1780: J. H. Bruinier, Borcherds Products on O(2,1)
and Chern Classes of Heegner Divisors (2002)
Vol. 1781: E. Bolthausen, E. Perkins, A. van der Vaart,
Lectures on Probability Theory and Statistics. Ecole dâ€™
EtÃ© de ProbabilitÃ©s de Saint-Flour XXIX-1999. Editor:
P. Bernard (2002)
Vol. 1782: C.-H. Chu, A. T.-M. Lau, Harmonic Functions
on Groups and Fourier Algebras (2002)
Vol. 1783: L. GrÃ¼ne, Asymptotic Behavior of Dynamical
and Control Systems under Perturbation and Discretiza-
tion (2002)
Vol. 1784: L. H. Eliasson, S. B. Kuksin, S. Marmi, J.-C.
Yoccoz, Dynamical Systems and Small Divisors. Cetraro,
Italy 1998. Editors: S. Marmi, J.-C. Yoccoz (2002)
Vol. 1785: J. Arias de Reyna, Pointwise Convergence of
Fourier Series (2002)
Vol. 1786: S. D. Cutkosky, Monomialization of Mor-
phisms from 3-Folds to Surfaces (2002)
Vol. 1787: S. Caenepeel, G. Militaru, S. Zhu, Frobenius
and Separable Functors for Generalized Module Cate-
gories and Nonlinear Equations (2002)
Vol. 1788: A. Vasilâ€™ev, Moduli of Families of Curves for
Conformal and Quasiconformal Mappings (2002)
Vol. 1789: Y. SommerhÃ¤user, Yetter-Drinfelâ€™d Hopf alge-
bras over groups of prime order (2002)
Vol. 1790: X. Zhan, Matrix Inequalities (2002)
Vol. 1791: M. Knebusch, D. Zhang, Manis Valuations
and PrÃ¼fer Extensions I: A new Chapter in Commutative
Algebra (2002)
Vol. 1792: D. D. Ang, R. Gorenï¬‚o, V. K. Le, D. D. Trong,
Moment Theory and Some Inverse Problems in Potential
Theory and Heat Conduction (2002)
Vol. 1793: J. CortÃ©s Monforte, Geometric, Control and
Numerical Aspects of Nonholonomic Systems (2002)
Vol. 1794: N. Pytheas Fogg, Substitution in Dynamics,
Arithmetics and Combinatorics. Editors: V. BerthÃ©, S. Fer-
enczi, C. Mauduit, A. Siegel (2002)
Vol. 1795: H. Li, Filtered-Graded Transfer in Using Non-
commutative GrÃ¶bner Bases (2002)
Vol. 1796: J.M. Melenk, hp-Finite Element Methods for
Singular Perturbations (2002)
Vol. 1797: B. Schmidt, Characters and Cyclotomic Fields
in Finite Geometry (2002)
Vol. 1798: W.M. Oliva, Geometric Mechanics (2002)
Vol. 1799: H. Pajot, Analytic Capacity, Rectiï¬ability,
Menger Curvature and the Cauchy Integral (2002)
Vol. 1800: O. Gabber, L. Ramero, Almost Ring Theory
(2003)
Vol. 1801: J. AzÃ©ma, M. Ã‰mery, M. Ledoux, M. Yor
(Eds.), SÃ©minaire de ProbabilitÃ©s XXXVI (2003)
Vol. 1802: V. Capasso, E. Merzbach, B. G. Ivanoff,
M. Dozzi, R. Dalang, T. Mountford, Topics in Spatial
Stochastic Processes. Martina Franca, Italy 2001. Editor:
E. Merzbach (2003)
Vol. 1803: G. Dolzmann, Variational Methods for Crys-
talline Microstructure â€“ Analysis and Computation (2003)
Vol. 1804: I. Cherednik, Ya. Markov, R. Howe, G. Lusztig,
Iwahori-Hecke Algebras and their Representation Theory.
Martina Franca, Italy 1999. Editors: V. Baldoni, D. Bar-
basch (2003)
Vol. 1805: F. Cao, Geometric Curve Evolution and Image
Processing (2003)
Vol. 1806: H. Broer, I. Hoveijn. G. Lunther, G. Vegter,
Bifurcations in Hamiltonian Systems. Computing Singu-
larities by GrÃ¶bner Bases (2003)
Vol. 1807: V. D. Milman, G. Schechtman (Eds.), Geomet-
ric Aspects of Functional Analysis. Israel Seminar 2000-
2002 (2003)
Vol. 1808: W. Schindler, Measures with Symmetry Prop-
erties (2003)
Vol. 1809: O. Steinbach, Stability Estimates for Hybrid
Coupled Domain Decomposition Methods (2003)
Vol. 1810: J. Wengenroth, Derived Functors in Functional
Analysis (2003)
Vol. 1811: J. Stevens, Deformations of Singularities
(2003)
Vol. 1812: L. Ambrosio, K. Deckelnick, G. Dziuk,
M. Mimura, V. A. Solonnikov, H. M. Soner, Mathematical
Aspects of Evolving Interfaces. Madeira, Funchal, Portu-
gal 2000. Editors: P. Colli, J. F. Rodrigues (2003)
Vol. 1813: L. Ambrosio, L. A. Caffarelli, Y. Brenier,
G. Buttazzo, C. Villani, Optimal Transportation and its
Applications. Martina Franca, Italy 2001. Editors: L. A.
Caffarelli, S. Salsa (2003)
Vol. 1814: P. Bank, F. Baudoin, H. FÃ¶llmer, L.C.G.
Rogers, M. Soner, N. Touzi, Paris-Princeton Lectures on
Mathematical Finance 2002 (2003)
Vol. 1815: A. M. Vershik (Ed.), Asymptotic Com-
binatorics with Applications to Mathematical Physics.
St. Petersburg, Russia 2001 (2003)
Vol. 1816: S. Albeverio, W. Schachermayer, M. Tala-
grand, Lectures on Probability Theory and Statistics.
Ecole dâ€™EtÃ© de ProbabilitÃ©s de Saint-Flour XXX-2000.
Editor: P. Bernard (2003)
Vol. 1817: E. Koelink, W. Van Assche (Eds.), Orthogonal
Polynomials and Special Functions. Leuven 2002 (2003)

Vol. 1818: M. Bildhauer, Convex Variational Problems
with Linear, nearly Linear and/or Anisotropic Growth
Conditions (2003)
Vol. 1819: D. Masser, Yu. V. Nesterenko, H. P. Schlick-
ewei, W. M. Schmidt, M. Waldschmidt, Diophantine
Approximation. Cetraro, Italy 2000. Editors: F. Amoroso,
U. Zannier (2003)
Vol. 1820: F. Hiai, H. Kosaki, Means of Hilbert Space
Operators (2003)
Vol. 1821: S. Teufel, Adiabatic Perturbation Theory in
Quantum Dynamics (2003)
Vol. 1822: S.-N. Chow, R. Conti, R. Johnson, J. Mallet-
Paret, R. Nussbaum, Dynamical Systems. Cetraro, Italy
2000. Editors: J. W. Macki, P. Zecca (2003)
Vol. 1823: A. M. Anile, W. Allegretto, C. Ring-
hofer, Mathematical Problems in Semiconductor Physics.
Cetraro, Italy 1998. Editor: A. M. Anile (2003)
Vol. 1824: J. A. Navarro GonzÃ¡lez, J. B. Sancho de Salas,
C âˆâ€“ Differentiable Spaces (2003)
Vol. 1825: J. H. Bramble, A. Cohen, W. Dahmen, Mul-
tiscale Problems and Methods in Numerical Simulations,
Martina Franca, Italy 2001. Editor: C. Canuto (2003)
Vol. 1826: K. Dohmen, Improved Bonferroni Inequal-
ities via Abstract Tubes. Inequalities and Identities of
Inclusion-Exclusion Type. VIII, 113 p, 2003.
Vol. 1827: K. M. Pilgrim, Combinations of Complex
Dynamical Systems. IX, 118 p, 2003.
Vol. 1828: D. J. Green, GrÃ¶bner Bases and the Computa-
tion of Group Cohomology. XII, 138 p, 2003.
Vol. 1829: E. Altman, B. Gaujal, A. Hordijk, Discrete-
Event Control of Stochastic Networks: Multimodularity
and Regularity. XIV, 313 p, 2003.
Vol. 1830: M. I. Gilâ€™, Operator Functions and Localization
of Spectra. XIV, 256 p, 2003.
Vol. 1831: A. Connes, J. Cuntz, E. Guentner, N. Hig-
son, J. E. Kaminker, Noncommutative Geometry, Martina
Franca, Italy 2002. Editors: S. Doplicher, L. Longo (2004)
Vol. 1832:
J. AzÃ©ma, M. Ã‰mery, M. Ledoux, M. Yor
(Eds.), SÃ©minaire de ProbabilitÃ©s XXXVII (2003)
Vol. 1833: D.-Q. Jiang, M. Qian, M.-P. Qian, Mathemati-
cal Theory of Nonequilibrium Steady States. On the Fron-
tier of Probability and Dynamical Systems. IX, 280 p,
2004.
Vol. 1834: Yo. Yomdin, G. Comte, Tame Geometry with
Application in Smooth Analysis. VIII, 186 p, 2004.
Vol. 1835: O.T. Izhboldin, B. Kahn, N.A. Karpenko,
A. Vishik, Geometric Methods in the Algebraic Theory
of Quadratic Forms. Summer School, Lens, 2000. Editor:
J.-P. Tignol (2004)
Vol. 1836: C. NË‡astË‡asescu, F. Van Oystaeyen, Methods of
Graded Rings. XIII, 304 p, 2004.
Vol. 1837: S. TavarÃ©, O. Zeitouni, Lectures on Probabil-
ity Theory and Statistics. Ecole dâ€™EtÃ© de ProbabilitÃ©s de
Saint-Flour XXXI-2001. Editor: J. Picard (2004)
Vol. 1838: A.J. Ganesh, N.W. Oâ€™Connell, D.J. Wischik,
Big Queues. XII, 254 p, 2004.
Vol.
1839:
R.
Gohm,
Noncommutative
Stationary
Processes. VIII, 170 p, 2004.
Vol. 1840: B. Tsirelson, W. Werner, Lectures on Probabil-
ity Theory and Statistics. Ecole dâ€™EtÃ© de ProbabilitÃ©s de
Saint-Flour XXXII-2002. Editor: J. Picard (2004)
Vol. 1841: W. Reichel, Uniqueness Theorems for Vari-
ational Problems by the Method of Transformation
Groups (2004)
Vol. 1842: T. Johnsen, A. L. Knutsen, K3 Projective Mod-
els in Scrolls (2004)
Vol. 1843: B. Jefferies, Spectral Properties of Noncom-
muting Operators (2004)
Vol. 1844: K.F. Siburg, The Principle of Least Action in
Geometry and Dynamics (2004)
Vol. 1845: Min Ho Lee, Mixed Automorphic Forms, Torus
Bundles, and Jacobi Forms (2004)
Vol. 1846: H. Ammari, H. Kang, Reconstruction of Small
Inhomogeneities from Boundary Measurements (2004)
Vol. 1847: T.R. Bielecki, T. BjÃ¶rk, M. Jeanblanc, M.
Rutkowski, J.A. Scheinkman, W. Xiong, Paris-Princeton
Lectures on Mathematical Finance 2003 (2004)
Vol. 1848: M. Abate, J. E. Fornaess, X. Huang, J. P. Rosay,
A. Tumanov, Real Methods in Complex and CR Geom-
etry, Martina Franca, Italy 2002. Editors: D. Zaitsev, G.
Zampieri (2004)
Vol. 1849: Martin L. Brown, Heegner Modules and Ellip-
tic Curves (2004)
Vol. 1850: V. D. Milman, G. Schechtman (Eds.), Geomet-
ric Aspects of Functional Analysis. Israel Seminar 2002-
2003 (2004)
Vol. 1851: O. Catoni, Statistical Learning Theory and
Stochastic Optimization (2004)
Vol. 1852: A.S. Kechris, B.D. Miller, Topics in Orbit
Equivalence (2004)
Vol. 1853: Ch. Favre, M. Jonsson, The Valuative Tree
(2004)
Vol. 1854: O. Saeki, Topology of Singular Fibers of Dif-
ferential Maps (2004)
Vol. 1855: G. Da Prato, P.C. Kunstmann, I. Lasiecka,
A. Lunardi, R. Schnaubelt, L. Weis, Functional Analytic
Methods for Evolution Equations. Editors: M. Iannelli,
R. Nagel, S. Piazzera (2004)
Vol. 1856: K. Back, T.R. Bielecki, C. Hipp, S. Peng,
W. Schachermayer, Stochastic Methods in Finance, Bres-
sanone/Brixen, Italy, 2003. Editors: M. Fritelli, W. Rung-
galdier (2004)
Vol. 1857: M. Ã‰mery, M. Ledoux, M. Yor (Eds.), SÃ©mi-
naire de ProbabilitÃ©s XXXVIII (2005)
Vol. 1858: A.S. Cherny, H.-J. Engelbert, Singular Stochas-
tic Differential Equations (2005)
Vol. 1859: E. Letellier, Fourier Transforms of Invariant
Functions on Finite Reductive Lie Algebras (2005)
Vol. 1860: A. Borisyuk, G.B. Ermentrout, A. Friedman,
D. Terman, Tutorials in Mathematical Biosciences I.
Mathematical Neurosciences (2005)
Vol. 1861: G. Benettin, J. Henrard, S. Kuksin, Hamil-
tonian Dynamics â€“ Theory and Applications, Cetraro,
Italy, 1999. Editor: A. Giorgilli (2005)
Vol. 1862: B. Helffer, F. Nier, Hypoelliptic Estimates and
Spectral Theory for Fokker-Planck Operators and Witten
Laplacians (2005)
Vol. 1863: H. FÃ¼hr, Abstract Harmonic Analysis of Con-
tinuous Wavelet Transforms (2005)
Vol. 1864: K. Efstathiou, Metamorphoses of Hamiltonian
Systems with Symmetries (2005)
Vol. 1865: D. Applebaum, B.V. R. Bhat, J. Kustermans,
J. M. Lindsay, Quantum Independent Increment Processes
I. From Classical Probability to Quantum Stochastic Cal-
culus. Editors: M. SchÃ¼rmann, U. Franz (2005)
Vol. 1866: O.E. Barndorff-Nielsen, U. Franz, R. Gohm,
B. KÃ¼mmerer, S. ThorbjÃ¸nsen, Quantum Independent
Increment Processes II. Structure of Quantum LÃ©vy
Processes, Classical Probability, and Physics. Editors: M.
SchÃ¼rmann, U. Franz, (2005)
Vol. 1867: J. Sneyd (Ed.), Tutorials in Mathematical Bio-
sciences II. Mathematical Modeling of Calcium Dynamics
and Signal Transduction. (2005)

Vol. 1868: J. Jorgenson, S. Lang, Posn(R) and Eisenstein
Series. (2005)
Vol. 1869: A. Dembo, T. Funaki, Lectures on Probabil-
ity Theory and Statistics. Ecole dâ€™EtÃ© de ProbabilitÃ©s de
Saint-Flour XXXIII-2003. Editor: J. Picard (2005)
Vol. 1870: V.I. Gurariy, W. Lusky, Geometry of MÃ¼ntz
Spaces and Related Questions. (2005)
Vol. 1871: P. Constantin, G. Gallavotti, A.V. Kazhikhov,
Y. Meyer, S. Ukai, Mathematical Foundation of Turbu-
lent Viscous Flows, Martina Franca, Italy, 2003. Editors:
M. Cannone, T. Miyakawa (2006)
Vol. 1872: A. Friedman (Ed.), Tutorials in Mathemati-
cal Biosciences III. Cell Cycle, Proliferation, and Cancer
(2006)
Vol. 1873: R. Mansuy, M. Yor, Random Times and En-
largements of Filtrations in a Brownian Setting (2006)
Vol. 1874: M. Yor, M. Ã‰mery (Eds.), In Memoriam Paul-
AndrÃ© Meyer - SÃ©minaire de probabilitÃ©s XXXIX (2006)
Vol. 1875: J. Pitman, Combinatorial Stochastic Processes.
Ecole dâ€™EtÃ© de ProbabilitÃ©s de Saint-Flour XXXII-2002.
Editor: J. Picard (2006)
Vol. 1876: H. Herrlich, Axiom of Choice (2006)
Vol. 1877: J. Steuding, Value Distributions of L-Functions
(2007)
Vol. 1878: R. Cerf, The Wulff Crystal in Ising and Percol-
ation Models, Ecole dâ€™EtÃ© de ProbabilitÃ©s de Saint-Flour
XXXIV-2004. Editor: Jean Picard (2006)
Vol. 1879: G. Slade, The Lace Expansion and its Applica-
tions, Ecole dâ€™EtÃ© de ProbabilitÃ©s de Saint-Flour XXXIV-
2004. Editor: Jean Picard (2006)
Vol. 1880: S. Attal, A. Joye, C.-A. Pillet, Open Quantum
Systems I, The Hamiltonian Approach (2006)
Vol. 1881: S. Attal, A. Joye, C.-A. Pillet, Open Quantum
Systems II, The Markovian Approach (2006)
Vol. 1882: S. Attal, A. Joye, C.-A. Pillet, Open Quantum
Systems III, Recent Developments (2006)
Vol. 1883: W. Van Assche, F. MarcellÃ n (Eds.), Orthogo-
nal Polynomials and Special Functions, Computation and
Application (2006)
Vol. 1884: N. Hayashi, E.I. Kaikina, P.I. Naumkin,
I.A. Shishmarev, Asymptotics for Dissipative Nonlinear
Equations (2006)
Vol. 1885: A. Telcs, The Art of Random Walks (2006)
Vol. 1886: S. Takamura, Splitting Deformations of Dege-
nerations of Complex Curves (2006)
Vol. 1887: K. Habermann, L. Habermann, Introduction to
Symplectic Dirac Operators (2006)
Vol. 1888: J. van der Hoeven, Transseries and Real Differ-
ential Algebra (2006)
Vol. 1889: G. Osipenko, Dynamical Systems, Graphs, and
Algorithms (2006)
Vol. 1890: M. Bunge, J. Funk, Singular Coverings of
Toposes (2006)
Vol.
1891:
J.B.
Friedlander,
D.R.
Heath-Brown,
H. Iwaniec, J. Kaczorowski, Analytic Number Theory,
Cetraro, Italy, 2002. Editors: A. Perelli, C. Viola (2006)
Vol. 1892: A. Baddeley, I. BÃ¡rÃ¡ny, R. Schneider, W. Weil,
Stochastic Geometry, Martina Franca, Italy, 2004. Editor:
W. Weil (2007)
Vol. 1893: H. HanÃŸmann, Local and Semi-Local Bifur-
cations in Hamiltonian Dynamical Systems, Results and
Examples (2007)
Vol. 1894: C.W. Groetsch, Stable Approximate Evaluation
of Unbounded Operators (2007)
Vol. 1895: L. MolnÃ¡r, Selected Preserver Problems on
Algebraic Structures of Linear Operators and on Function
Spaces (2007)
Vol. 1896: P. Massart, Concentration Inequalities and
Model Selection, Ecole dâ€™EtÃ© de ProbabilitÃ©s de Saint-
Flour XXXIII-2003. Editor: J. Picard (2007)
Vol. 1897: R.A. Doney, Fluctuation Theory for LÃ©vy
Processes, Ecole dâ€™EtÃ© de ProbabilitÃ©s de Saint-Flour
XXXV-2005. Editor: J. Picard (2007)
Vol. 1898: H.R. Beyer, Beyond Partial Differential Equa-
tions, On linear and Quasi-Linear Abstract Hyperbolic
Evolution Equations (2007)
Vol. 1899: SÃ©minaire de ProbabilitÃ©s XL. Editors:
C. Donati-Martin, M. Ã‰mery, A. Rouault, C. Stricker
(2007)
Vol. 1900: E. Bolthausen, A. Bovier (Eds.), Spin Glasses
(2007)
Vol.
1901:
O.
Wittenberg,
Intersections
de
deux
quadriques et pinceaux de courbes de genre 1, Inter-
sections of Two Quadrics and Pencils of Curves of Genus
1 (2007)
Vol. 1902: A. Isaev, Lectures on the Automorphism
Groups of Kobayashi-Hyperbolic Manifolds (2007)
Vol. 1903: G. Kresin, V. Mazâ€™ya, Sharp Real-Part Theo-
rems (2007)
Vol. 1904: P. Giesl, Construction of Global Lyapunov
Functions Using Radial Basis Functions (2007)
Vol. 1905: C. PrÃ©vË†ot, M. RÃ¶ckner, A Concise Course on
Stochastic Partial Differential Equations (2007)
Vol. 1906: T. Schuster, The Method of Approximate
Inverse: Theory and Applications (2007)
Vol. 1907: M. Rasmussen, Attractivity and Bifurcation for
Nonautonomous Dynamical Systems (2007)
Vol. 1908: T.J. Lyons, M. Caruana, T. LÃ©vy, Differential
Equations Driven by Rough Paths, Ecole dâ€™EtÃ© de Proba-
bilitÃ©s de Saint-Flour XXXIV-2004. (2007)
Vol.
1909:
H.
Akiyoshi,
M.
Sakuma,
M.
Wada,
Y. Yamashita, Punctured Torus Groups and 2-Bridge Knot
Groups (I) (2007)
Vol. 1910: V.D. Milman, G. Schechtman (Eds.), Geo-
metric Aspects of Functional Analysis. Israel Seminar
2004-2005 (2007)
Vol.
1911:
A.
Bressan,
D.
Serre,
M.
Williams,
K. Zumbrun, Hyperbolic Systems of Balance Laws.
Lectures given at the C.I.M.E. Summer School held in
Cetraro, Italy, July 14â€“21, 2003. Editor: P. Marcati (2007)
Vol. 1912: V. Berinde, Iterative Approximation of Fixed
Points (2007)
Recent Reprints and New Editions
Vol. 1618: G. Pisier, Similarity Problems and Completely
Bounded Maps. 1995 â€“ 2nd exp. edition (2001)
Vol. 1629: J.D. Moore, Lectures on Seiberg-Witten
Invariants. 1997 â€“ 2nd edition (2001)
Vol. 1638: P. Vanhaecke, Integrable Systems in the realm
of Algebraic Geometry. 1996 â€“ 2nd edition (2001)
Vol. 1702: J. Ma, J. Yong, Forward-Backward Stochas-
tic Differential Equations and their Applications. 1999 â€“
Corr. 3rd printing (2007)
Vol. 830: J.A. Green, Polynomial Representations of
GLn, with an Appendix on Schensted Correspondence
and Littelmann Paths by K. Erdmann, J.A. Green and
M. Schocker 1980 â€“ 2nd corr. and augmented edition
(2007)

