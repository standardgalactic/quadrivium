
Contents
Cover
Title
Copyright
Foreword
Notations and Abbreviations
1: Mathematical Concepts
1.1 Basic concepts on probability
1.2 Conditional expectation
1.3 Projection theorem
1.4 Gaussianity
1.5 Random variable transformation
1.6 Fundamental statistical theorems
1.7 Other important probability distributions
2: Statistical Inferences
2.1 Statistical model
2.2 Hypothesis tests
2.3 Statistical estimation
3: Monte-Carlo Simulation
3.1 Fundamental theorems
3.2 Stating the problem
3.3 Generating random variables
3.4 Variance reduction
4: Second Order Stationary Process
4.1 Statistics for empirical correlation
4.2 Linear prediction of WSS processes
4.3 Non-parametric spectral estimation of WSS processes
5: Inferences on HMM
5.1 Hidden Markov Models (HMM)
5.2 Inferences on HMM
5.3 Gaussian linear case: the Kalman filter
5.4 Discrete finite Markov case

6: Selected Topics
6.1 High resolution methods
6.2 Digital Communications
6.3 Linear equalization and the Viterbi algorithm
6.4 Compression
7: Hints and Solutions
H1 Mathematical concepts
H2 Statistical inferences
H3 Monte-Carlo simulation
H4 Second order stationary process
H5 Inferences on HMM
H6 Selected Topics
8: Appendices
A1 Miscellaneous functions
A2 Statistical functions
Bibliography
Index
End User License Agreement
List of Tables
2: Statistical Inferences
Table 2.1. – Growth in mm under the action of fertilizers 1 and 2
Table 2.2. – H: height in cm, W: weight in kg.
Table 2.3. – Observed pairs (xn,yn)
Table 2.4. —Cavity figures given as thousands. The fluoride level is given in ppm
(parts per million).
Table 2.5. – Temperature in degrees Fahrenheit and state of the joint: 1 signifies the
existence of a fault and 0 the absence of faults
Table 2.6. – Survival period Y in number of months and state c of the patient. A value
of c = 1 indicates that the patient is still living, hence their survival period is greater
than value Y. A value of c = 0 indicates that the patient is deceased
3: Monte-Carlo Simulation
Table 3.1. – The initial probabilities P{X0 = i} and the transition probabilities P

{Xn+1=j |Xn=i} of a three-state homogeneous Markov chain. We verify that, for all i, 
4: Second Order Stationary Process
Table 4.1. – Correlation vs. partial correlation
List of Illustrations
1: Mathematical Concepts
Figure 1.1 – Orthogonality principle: the point X0 which is the closest to X in  is
such that X−X0 is orthogonal to 
Figure 1.2 – The conditional expectation 
 is the orthogonal projection of X
onto the set  of measurable functions of Y. The expectation 
 is the orthogonal
projection of X onto the set  of constant functions. Clearly, 
2: Statistical Inferences
Figure 2.1 – The two curves represent the respective probability densities of the test
function Φ(X) under hypothesis H0 (m0 = 0) and under hypothesis H1 (m1 = 2). For a
threshold value η, the light gray area represents the significance level or probability
of false alarm, and the dark gray area represents the power or probability of
detection.
Figure 2.2 – ROC curve. The statistical model is 
, where m  {0,
1}. The hypothesis H0 = {0} is tested by the likelihood ratio (2.9). The higher the
value of n, the closer the curve will come to the ideal point, with coordinates (0, 1).
The significance level α is interpreted as the probability of a false alarm. The power
β is interpreted as the probability of detection.
Figure 2.3 – Diagram showing the calculation of the GLRT
Figure 2.4 – Least squares method for a non-linear model given by equation (2.34).
The points represent observed value pairs (Table 2.3)
Figure 2.5 – Percentage of dental cavities observed as a function of fluoride levels in
drinking water in ppm (parts per million).
Figure 2.6 – Multimodal distribution
Figure 2.7 – Step equal to 1/N for the five values of the series, ranked in increasing
order
Figure 2.8 – Cross-validation: a block is selected as the test base, for example block
no. 4 in this illustration, and the remaining blocks are used as a learning base,
before switching over.
3: Monte-Carlo Simulation

Figure 3.1 – Direct calculation (circles) and calculation using a Monte-Carlo
method (crosses), showing that the Monte-Carlo method presents faster convergence
in terms of sample size. The error εMC represented in the lower diagram is random in
nature. In the case of direct calculation, the error is monotone and decreasing
Figure 3.2 – Typical form of a cumulative function. We choose a value in a uniform
manner between 0 and 1, then deduce the realization t = F(−1)(u)
Figure 3.3 – The greater the value of M, the more samples need to be drawn before
accepting a value. The value chosen for M will therefore be the smallest possible
value such that, for any x, Mq (x) ≥ p (x). The curve noted MUq (x) in the figure
corresponds to a draw of the r.v. U from the interval 0 to 1. For this draw, the only
accepted values of Y are those for which p (x) ≥ MUq (x)
4: Second Order Stationary Process
Figure 4.1 – Forward/backward predictions: 
n−1,N is the linear space spanned by Xn
−1, …, Xn−N. The dotted arrows represent the forward prediction error 
 and the
backward prediction error 
. The two errors are orthogonal to 
 and to 
.
Figure 4.2 – Modulus of the lattice analysis filter
Figure 4.3 – The lattice analysis filter
Figure 4.4 – The lattice synthesis filter
Figure 4.5 – Application of a smoothing window to the spectrum
Figure 4.6 – Spectral estimation. Full line: spectrum estimated using a smoothed
periodogram. Dotted line: theoretical spectrum
Figure 4.7 – Integrated MSE (expression (4.63)) as a function of the size M of the
smoothing window. The signal is a second order auto-regressive process. The
number of samples is N = 4096. The points represent the values of the MSE over 20
draws. The full line shows the mean for these 20 draws
5: Inferences on HMM
Figure 5.1 – The Directed Acyclic Graph associated with an HMM takes the form of
a tree
Figure 5.2 – Lattice associated with S = 3 states for a sequence of length N = 6
6: Selected Topics
Figure 6.1 – Calculation of the coefficients of 
 based on P = GGH
Figure 6.2 − DTFT of the signal x (n) = cos(2πf1n) + 0.2cos(2πf2n) + b (n) with f1 =
0.2, f2 = 0.21, N = 60. The signal-to-noise ratio is equal to 20 dB

Figure 6.3 – Performances of the MUSIC algorithm. Signal x (n) = cos(2pf1n) + 0.02
cos(2pf2n) + b (n) with f1= 0.2, f2 = 0.21, N = 60. Square root of the square deviation
of the estimation, for each of the two frequencies, evaluated for a length 300
simulation, for several values of the signal-to-noise ratio in dB
Figure 6.4 – Linear antenna with three sensors and P = 1 distant source assumed to
be far away. The dashed lines represent the equiphase lines
Figure 6.5 – Angular references
Figure 6.6 – Baseband modulation and demodulation
Figure 6.7 – Carrier frequency modulation and demodulation
Figure 6.8 – 8-PSK state constellation
Figure 6.9 – 8-PSK modulation signal
Figure 6.10 – An example of 8-PAM modulation
Figure 6.11 – HDB3 coding: processing the four consecutive zeros and updating the
bipolar violation bits
Figure 6.12 – Diagram of the receiver
Figure 6.13 – A raised cosine function satisfying the Nyquist criterion
Figure 6.14 – PAM-2: eye pattern without noise
Figure 6.15 – Constructing the signal transmitted based on the symbols and the
polyphase components of the emission filter in the case where NT = 4
Figure 6.16 – The eye pattern for M = 4. The noise is null Spectrum support B = 300
Hz, rate 1,000 bps
Figure 6.17 – Eye pattern for M = 4. The noise is null. Spectrum support B = 500 Hz,
rate 1,000 bps
Figure 6.18 – Eye pattern for M = 4. The signal-to-noise ratio is equal to 15 dB, the
spectrum support is B = 300 Hz and the rate 1,000 bps
Figure 6.19 – Eye pattern for M = 4. The signal-to-noise ratio is equal to 15 dB, the
spectrum support is B = 500 Hz and the rate 1,000 bps
Figure 6.20 – Transition probability graphs for the four states depending on the
input symbol
Figure 6.21 – Comparing the error probabilities as functions of the signal-to-noise
ratio in dB. Plot (‘×’): zero forcing linear equalization. Plot (‘o’): Viterbi algorithm.
Results obtained through a simulation with a length of 5,000. The channel filter has
the finite impulse response (1 − 1.4 0.8)
Figure 6.22 – Two partitions of the plane in 16 regions (four bits are used to code

each representative element of the corresponding region)
Figure 6.23 – Partition R of the plane
Figure 6.24 – 
 partition by the perpendicular bisectors
Figure 6.25 – Original image on the left and the result of the LBG compression with
m = 16 and b = 3
Figure 6.26 – LBG compression: (m = 4, b = 2) on the left (m = 4, b = 4) on the right
7: Hints and Solutions
Figure H2.1 – Top left: the N points (xn,1, yn) and 
 in the space Ox1y. The points
(’.’) are observed values and (’x’) the predicted values. Bottom left: the N points
(xn,2, yn) and (xn,2, 
) in the space Ox2y. Right: the N points (xn,1, xn,2, yn) and (xn,1,
xn,2, 
) in the space Ox1 x2y
Figure H2.2 – Prediction errors as a function of the supposed order of the model: ‘x-’
for the learning base, ‘o-’ for the test base. The observation model is of the form 
, where Z includes p = 10 column vectors. As the number of regressors
increases above and beyond the true value, we “learn” noise; this is known as
overtraining
Figure H4.1 – Variations of the mean square integrated bias, the mean integrated
variance and the mean integrated MSE for 20 trajectories as a function of M. The
signal is made up of 4096 samples, and smoothing is carried out using the Hamming
window
Figure H5.1 – Results for the study of the filtering
Figure H6.1 – Gray code for an 8 state phase modulation
Figure H6.2 – The real and imaginary parts of the complex envelope and the signal
Figure H6.3 – Constellation and Gray code
Figure H6.4 – Noised signal, the signal-to-noise ratio is equal to 20 dB; signal
containing the ISI caused by the FIR filter, h0 = 1 and h1 = −1.6; signal after
equalization
Figure H6.5 – Comparison for a minimum phase channel
Figure H6.6 – Comparison for a non-minimum phase channel
Figure H6.7 – Signals at different points of the communication line
Figure H6.8 – Symbol-by-symbol detection of a Zero Forcing equalizer’s output for a
binary transmission. The equivalent channel has the coefficients g0 = 1, g1 = −1.4, g2
= 0.8. The x’s indicate the probabilities obtained through 5,000 simulations for
different values of the signal-to-noise ratio in dB

Figure H6.9 – Error probability plotted against the signal-to-noise ratio in dB after
equalizing with the Wiener filter (‘o’) and with the Zero Forcing filter (‘ x’). The
results are obtained through simulation using 5,000 symbols. The channel filter has
the finite impulse response (1 – 1.4 0.8)
8: Appendices
Figure A2.1 – Distribution (left) and cumulative distribution (right) for values of k 1,
3, 5 and 10. The limiting Gaussian is shown alongside with the distributions
Figure A2.2 – Application of Newton’s method to find t from T = 0.8 and k = 3
Figure A2.3 – A few probability densities and cumulative distributions of the χ2
distribution
Figure A2.4 – Use of the mychi2inv function to generate a random sequence,
histogram and theoretical pdf
Figure A2.5 – pdf and cdf of the Fisher distribution for k1 = 5 and k2 = 7

Digital Signal and Image Processing
using MATLAB®
Advances and Applications: The Stochastic Case
Revised and Updated 2nd Edition
Volume 3
Gérard Blanchet
Maurice Charbit

First published 2015 in Great Britain and the United States by ISTE Ltd and John Wiley & Sons, Inc.
Apart from any fair dealing for the purposes of research or private study, or criticism or review, as permitted under the
Copyright, Designs and Patents Act 1988, this publication may only be reproduced, stored or transmitted, in any form or by any
means, with the prior permission in writing of the publishers, or in the case of reprographic reproduction in accordance with the
terms and licenses issued by the CLA. Enquiries concerning reproduction outside these terms should be sent to the publishers at
the undermentioned address:
ISTE Ltd
27-37 St George’s Road
London SW19 4EU
UK
www.iste.co.uk
John Wiley & Sons, Inc.
111 River Street
Hoboken, NJ 07030
USA
www.wiley.com
© ISTE Ltd 2015
The rights of Gérard Blanchet and Maurice Charbit to be identified as the authors of this work have been asserted by them in
accordance with the Copyright, Designs and Patents Act 1988.
Library of Congress Control Number: 2015948073
British Library Cataloguing-in-Publication Data
A CIP record for this book is available from the British Library
ISBN 978-1-84821-795-9
MATLAB® is a trademark of The MathWorks, Inc. and is used with permission. The MathWorks does not warrant the
accuracy of the text or exercises in this book. The book’s use or discussion of MATLAB® software does not constitute
endorsement or sponsorship by The MathWorks of a particular pedagogical approach or use of the MATLAB® software.

Foreword
This book is the third volume in a series on digital signal processing and associated
techniques. Following on from “Fundamentals” and “Advances and Applications, The
Deterministic Case”, it addresses the stochastic case. We shall presume throughout that readers
have a good working knowledge of MATLAB® and of basic elements of digital signal
processing.
Whilst our main focus is on applications, we shall also give consideration to key principles. A
certain number of the elements discussed belong more to the domain of statistics than to signal
processing; this responds to current trends in signal processing, which make extensive use of
this type of technique.
Over 60 solved exercises allow the reader to apply the concepts and results presented in the
following chapters. There will also be examples to alleviate any demonstrations that would
otherwise be quite dense. These can be found in more specialist books referenced in the
bibliography. 92 programs and 49 functions will be used to support these examples and
corrected exercises.
Mathematical Concepts
The first chapter begins with a brief review of probability theory, focusing on the notions of
conditional probability, projection theorem and random variable transformation. A number of
statistical elements will also be presented, including the law of large numbers (LLN), the
limit-central theorem, or the delta-method.
Statistical inferences
The second chapter is devoted to statistical inference. Statistical inference consists of
deducing interesting characteristics from a series of observations with a certain degree of
reliability. A variety of techniques may be used. In this chapter, we shall discuss three broad
families of techniques: hypothesis testing, parameter estimation, and the determination of
confidence intervals. Key notions include Cramer-Rao bound, likelihood ratio tests, maximum
likelihood approach and least square approach for linear models.
Monte-Carlo simulation
Monte-Carlo methods involve a set of algorithms which aim to calculate values using a
pseudo-random generator. The quantities to calculate are typically integrals, and in practice,
often represent the mathematical expectation of a function of interest. In cases using large
dimensions, these methods can significantly reduce the calculation time required by
deterministic methods. Monte-Carlo methods involve drawing a series of samples, distributed
following a target distribution. The main generation methods, including importance sampling,
the acceptance-rejection method, the Gibbs sampler, etc., will be presented. Another objective
is to minimize the mean square error between the calculated and true values, and variance
reduction methods will be studied using simulations.

Second order stationary process
The fourth chapter covers second order random stationary processes in the broadest sense:
Wide Sense Stationary (WSS). The chapter is split into three parts, beginning with empirical
second order estimators, leading to the correlogram. Then follow general and detailled results
on the linear prediction which is fundamental role in the WSS time series. The third part is
devoted to the non-parametric spectral estimation approaches (smooth periodograms, average
periodograms, etc.). A detailed discussion on the bias-variance compromise is given.
Inferences on HMM
States are directly visible in simple Markov models, and the modeling process depends
exclusively on transition probabilities. In hidden-state Markov models (HMM), however,
states can only be seen via observed signals which are statistically linked to these states.
HMMs are particularly useful as control models, using latent variables of mixtures connected
to each observation.
A wide variety of problems may be encountered in relation to inference, for example seeking
the sequence most likely to have produced a given series of observations; determining the a
posteriori distribution of hidden states; estimating the parameters of a model; etc. Key
algorithms include the Baum-Welch algorithm and the Viterbi algorithm, to cite the two best-
known examples. HMM have applications in a wide range of domains, such as speech
recognition (analysis and synthesis), automatic translation, handwriting analysis, activity
identification, DNA analysis, etc.
Selected Topics
The final chapter presents applications which use many of the principles and techniques
described in the preceding chapters, without falling into any of the categories defined in these
chapters. The first section is devoted to high resolution techniques (MUSIC and ESPRIT
algorithms), whilst the second covers classic communication problems (coding, modulation,
eye diagrams, etc.). The third section presents the Viterbi algorithm, and the fourth is given
over to scalar and vectorial quantification.
Annexes
A certain number of functions are given in simplified form in the appendix. This includes a
version of the boxplot function, alongside functions associated with the most common
distributions (Student, χ2 and Fischer).
Remarques
The notation used in this book is intended to conform to current usage; in cases where this is
not the case, every care has been taken to remove any ambiguity as to the precise meaning of
terms. On a number of occasions, we refer to nitnslseries instead of nitnsltime series or
nitnslsequences to avoid confusion.

Notations and Abbreviations
θ
empty set
= 
rectT (t)
= 
sinc(x)
= 
= 
 (indicator function of A)
(a, b ]
= {x: a < x ≤ b}
δ (t)
Re(z)
real part of z
Im(z)
imaginary part of z
i or j
= 
Fourier transform
(x*y)(t)
continuous time convolution
(x*y)(t)
discrete time convolution
x or x

vector x
I N
(N × N)-dimension identity matrix
A *
complex conjugate of A
A T
transpose of A
A H
transpose-conjugate of A
A−1
inverse matrix of A
A#
pseudo-inverse matrix of A
probability measure
probability measure indexed by θ
expectation of X
expectation of X under the distribution 
zero-mean random variable
variance of X
covariance of (X, Y)
cov (X) = cov (X, X) = var (X)
variance of X
conditional expectation of X given Y
a converges in law to b 
or a converges in distribution to b
converges in probability to b
a converges almost surely to b
ADC
Analog to Digital Converter
ADPCM

Adaptive Differential PCM
AMI
Alternate Mark Inversion
AR
Autoregressive
ARMA
AR and MA
BER
Bit Error Rate
bps
bits per second
cdf
cumulative distribution function
CF
Clipping Factor
CZT
Causal z-Transform
DAC
Digital to Analog Converter
DCT
Discrete Cosine Transform
d.o.f.
degree of freedom
DFT
Discrete Fourier Transform
DTFT
Discrete Time Fourier Transform
EM
Expectation Maximization
ESPRIT
Estimation of Signal Parameter via Rotational Invariance Techniques
FIR
Finite Impulse Response
FFT
Fast Fourier Transform
FT
Continuous Time Fourier Transform
GLRT

Generalized Likelihood Ratio Test
GEM
Generalized Expectation Maximization
GMM
Gaussian Mixture Model
HDB
High Density Bipolar
HMM
Hidden Markov Model
IDFT
Inverse Discrete Fourier Transform
i.i.d./iid
independent and identically distributed
IIR
Infinite Impulse Response
ISI
InterSymbol Interference
KKT
Karush-Kuhn-Tucker
LDA
Linear Discriminant Analysis
LBG
Linde, Buzzo, Gray (algorithm)
LMS
Least Mean Squares
MA
Moving Average
MSE
Mean Square Error
MUSIC
MUltiple SIgnal Charaterization
PAM
Pulse Amplitude Modulation
PCA
Principal Component Analysis
PSK
Phase Shift Keying
QAM

Quadrature Amplitude Modulation
rls
recursive least squares
rms
root mean square
ROC
Receiver Operational Characteristic
SNR
SSignal to Noise Ratio
r.v./rv
random variable
STFT
Short Term Fourier Transform
TF
Transfer Function
WSS
Wide (Weak) Sense Stationary (Second Order) Process

(1.2)
(1.3)
(1.1)
Chapter 1
Mathematical Concepts
1.1 Basic concepts on probability
Without describing in detail the formalism used by Probability Theory, we will simply remind
the reader of some useful concepts. However we advise the reader to consult some of the many
books with authority on the subject [1].
Definition 1.1 (Discrete random variable) A random variable X is said to be discrete if the
set of its possible values is, at the most, countable. If {a0, …, an, …}, where n 
, is the set
of its values, the probability distribution of X is characterized by the sequence:
representing the probability that X is equal to the element an. These values are such that 0 ≤
pX (n) ≤ 1 and ∑n≥ 0pX (n) = 1.
This leads us to the probability for the random variable X to belong to the interval ]a,b ]. It is
given by:
The function defined for x   by:
is called the cumulative distribution function (cdf) of the random variable X. It is a monotonic
increasing function, and verifies FX (−∞) = 0 and FX (+∞) = 1. Its graph resembles that of a
staircase function, the jumps of which are located at x-coordinates an and have an amplitude of
pX (n).
Definition 1.2 (Two discrete random variables) Let X and Y be two discrete random
variables, with possible values {a0,…, an, …} and {b0, …, bk, …} respectively. The joint
probability distribution is characterized by the sequence of positive values:
Pr(X = an, Y = bk) represents the probability to simultaneously have X = an and Y = bk. This
definition can easily be extended to the case of a finite number of random variables.

(1.4)
(1.5)
(1.6)
(1.7)
Property 1.1 (Marginal probability distribution) Let X and Y be two discrete random
variables, with possible values {a0,…, an, …} and {b0,…, bk, …} respectively, and with
their joint probability distribution characterized by pXY (n, k). We have:
pX (n) and pY (k) denote the marginal probability distribution of X and Y respectively.
Definition 1.3 (Continuous random variable) A random variable is said to be continuous 1 if
its values belong to  and if, for any real numbers a and b, the probability that X belongs to
the interval ]a,b ] is given by:
where pX (x) is a function that must be positive or equal to zero such that 
.pX
(x) is called the probability density function (pdf) of X.
The function defined for any x 
 by:
is called the cumulative distribution function (cdf) of the random variable X. It is a monotonic
increasing function and it verifies FX (−∞) = 0 and FX (+∞) = 1. Notice that pX (x) also
represents the derivative of FX (x) with respect to x.
Definition 1.4 (Two continuous random variables) Let X and Y be two random variables
with possible values in  × . They are said to be continuous if, for any domain Δ of 
2, the
probability that the pair (X, Y) belongs to Δ is given by:
where the function pXY (x, y) ≥ 0, and is such that:
pXY (x, y) is called the joint probability density function of the pair (X, Y).
Property 1.2 (Marginal probability distributions) Let X and Y be two continuous random
variables with a joint probability distribution characterized by pXY (x,y). The probability
distributions of X and Y have the following marginal probability density functions:

(1.8)
(1.9)
(1.10)
An example involving two real random variables (X, Y) is the case of a complex random
variable Z = X + jY.
It is also possible to have a mixed situation, where one of the two variables is discrete and the
other is continuous. This leads to the following:
Definition 1.5 (Mixed random variables) Let X be a discrete random variable with possible
values {a0,…,an, …} and Y a continuous random variable with possible values in . For
any value an, and for any real numbers a and b, the probability:
where the function pXY (n, y), with n  {0,…, k, …} and y  , is ≥ 0 and verifies 
.
Definition 1.6 (Two independent random variables) Two random variables X and Y are said
to be independent if and only if their joint probability distribution is the product of the
marginal probability distributions. This can be expressed:
– for two discrete random variables:
– for two continuous random variables:
– for two mixed random variables:
where the marginal probability distributions are obtained with formulae (1.4) and (1.8).
It is worth noting that, knowing pXY (x, y), we can tell whether or not X and Y are independent.
To do this, we need to calculate the marginal probability distributions and to check that pXY
(x,y) = pX (x)pY (y). If that is the case, then X and Y are independent.
The following definition is more general.
Definition 1.7 (Independent random variables) The random variables (X1,…,Xn) are jointly
independent if and only if their joint probability distribution is the product of their marginal
probability distributions. This can be expressed:

(1.11)
where the marginal probability distributions are obtained as integrals with respect to (n −
1) variables, calculated from 
.
For example, the marginal probability distribution of X1 has the expression:
In practice, the following result is a simple method for determining whether or not random
variables are independent: if 
 is a product of n positive functions of the
type f1(x1)f2( x2) …f n(xn), then the variables are independent.
It should be noted that if n random variables are independent of one another, it does not
necessarily mean that they are jointly independent.
Definition 1.8 (Mathematical expectation) Let X be a random variable and f (x) a function.
The mathematical expectation of f (X) – respectively f (X, Y) – is the value, denoted by 
– respectively 
 – defined:
– for a discrete random variable, by:
– for a continuous random variable, by:
– for two discrete random variables, by:
– for two continuous random variables, by:
provided that all expressions exist.
Property 1.3 If {X 1 , X2 , …, Xn} are jointly independent, then for any integrable functions
f1, f2,…, fn :
Definition 1.9 (Characteristic function) The characteristic function of the probability
distribution of the random variables X 1,…, Xn is the function of (u 1,…,un) 
n defined by:

(1.12)
(1.16)
(1.13)
(1.14)
(1.15)
Because 
, the characteristic function exists and is continuous even if the moments 
 do not exist. The Cauchy probability distribution, for example, the probability density
function of which is pX (x) = 1/π (1 + x2), has no moment and has the characteristic function e
−|u|. Let us notice 
.
Theorem 1.1 (Fundamental) (X 1,…,Xn) are independent if and only if for any point (u 1, u2,
…,un) of 
n:
Notice that the characteristic function 
 of the marginal probability distribution of Xk can
be directly calculated using (1.12). We have 
 
.
Definition 1.10 (Mean, variance) The mean of the random variable X is defined as the first
order moment, that is to say 
. If the mean is equal to zero, the random variable is said
to be centered. The variance of the random variable X is the quantity defined by:
The variance is always positive, and its square root is called the standard deviation.
As an exercise, we are going to show that, for any constants a and b:
Expression (1.14) is a direct consequence of the integral’s linearity. We assume that Y = aX +
b, then var 
. By replacing 
, we get var 
.
A generalization of these two results to random vectors (their components are random
variables) will be given by property (1.6).
Definition 1.11 (Covariance, correlation) Let (X,Y) be two random variables 2. The
covariance of X and Y is the quantity defined by:
In what follows, the variance of the random variable X will be noted var (X). cov (X) or cov
(X, X) have exactly the same meaning.
X and Y are said to be uncorrelated if cov (X, Y) = 0 that is to say if 
 .

(1.17)
(1.18)
(1.20)
(1.19)
The correlation coefficient is the quantity defined by:
Applying the Schwartz inequality gives us | ρ (X,Y)| ≤ 1.
Definition 1.12 (Mean vector and covariance matrix) Let {X 1, …, Xn } be n random
variables with the respective means 
 . The mean vector is the n dimension vector with
the means 
 as its components. The n×n covariance matrix C is the matrix with the
generating element 
.
Matrix notation: if we write
to refer to the random vector with the random variable Xk as its k-th component, the mean-
vector can be expressed:
the covariance matrix:
and the correlation matrix
with
R is obtained by dividing each element 
 of C by 
 , provided that 
. Therefore
.
Notice that the diagonal elements of a covariance matrix represent the respective variances of
the n random variables. They are therefore positive. If the n random variables are
uncorrelated, their covariance matrix is diagonal and their correlation matrix is the
identity matrix.
Property 1.4 (Positivity of the covariance matrix) Any covariance matrix is positive,
meaning that for any vector a  Cn, we have aHCa ≥ 0.

(1.21)
(1.22)
Property 1.5 (Bilinearity of the covariance) Let X 1 , …, Xm, Y 1 , …, Yn be random
variables, and v 1 , …, vm, w1 ,…,wn be constants. Hence:
Let V and W be the vectors of components vi and wj respectively, and A = V H X and B = W H
Y . By definition, cov 
 
. Replacing A and B by their respective
expressions and using 
 and 
, we obtain, successively:
thus demonstrating expression (1.21). Using matrix notation, this is written:
where C designates the covariance matrix of X and Y .
Property 1.6 (Linear transformation of a random vector) Let {X 1,…, Xn} be n random
variables with 
 as their mean vector and C X as their covariance matrix, and let {Y 1 ,
…,Yq} be q random variables obtained by the linear transformation:
where A is a matrix and b is a non-random vector with the adequate sizes. We then have:
Definition 1.13 (White sequence) Let {X 1 ,…, Xn} be a set of n random variables. They are
said to form a white sequence if var (Xi) = σ 2 and if cov (Xi, Xj) = 0 for i≠j. Hence their
covariance matrix can be expressed:
where I n is the n × n identity matrix.
Property 1.7 (Independence 
 non-correlation) The random variables {X 1 ,…, Xn} are
independent, then uncorrelated, and hence their covariance matrix is diagonal. Usually the
converse statement is false.

(1.24)
(1.23)
(1.25)
1.2 Conditional expectation
Definition 1.14 (Conditional expectation) We consider a random variable X and a random
vector Y taking values respectively in χ
 and 
 with joint probability density pXY
(x,y). The conditional expectation of X given Y, is a (measurable) real valued function g (Y)
such that for any other real valued function h (Y) we have:
g (Y) is commonly denoted by 
.
Property 1.8 (Conditional probability distribution) We consider a random variable X and a
random vector Y taking values respectively in χ   and 
 with joint probability
density pXY (x, y). Then 
 where:
with
 is known as the conditional probability distribution of X given Y .
Property 1.9 The conditional expectation verifies the following properties:
1. linearity: 
;
2. orthogonality: 
 for any function 
;
3. 
 , for all functions 
 and 
;
4. 
 for any function 
; specifically
5. refinement by conditioning: it can be shown (see page 13) that
The variance is therefore reduced by conditioning;
6. if X and Y are independent, then 
 . Specifically, 
 .
The reverse is not true;
7. 
 , if and only if X is a function of Y .
1.3 Projection theorem

(1.26)
(1.27)
(1.28)
Definition 1.15 (Scalar product) Let  be a vector space constructed over . The scalar
product is an application
which verifies the following properties:
– (X, Y) = (Y, X)*;
– (αX + βY, Z) = α (X, Z) + β (Y, Z);
– (X, X) ≥ 0. The equality occurs if and only if X = 0.
A vector space constructed over  has a Hilbert space structure if it possesses a scalar
product and if it is complete 3 . The norm of X is defined by 
 and the distance
between two elements by d (X 1 ,X 2 ) = 
. Two elements X 1 and X 2 are said to be
orthogonal, noted X 1 X 2, if and only if (X 1 , X 2 ) = 0. The demonstration of the following
properties is trivial:
– Schwarz inequality:
the equality occurs if and only if λ exists such that X 1 = λX 2;
– triangular inequality:
– parallelogram identity:
In a Hilbert space, the projection theorem enables us to associate any given element from the
space with its best quadratic approximation contained in a closed vector sub-space:
Theorem 1.2 (Projection theorem) Let  be a Hilbert space defined over  and  a closed
vector sub-space of . Each vector of  may then be associated with a unique element X 0 of
 such that Y   we have d(X, X 0 ) ≤ d(X, Y).
Vector X0 verifies, for any Y  , the relationship (X−X 0 )  Y
The relationship (X − X 0 )  Y constitutes the orthogonality principle.
A geometric representation of the orthogonality principle is shown in Figure 1.1. The element
of  closest in distance to X is given by the orthogonal projection of X onto C. In practice, this
is the relationship which allows us to find the solution X 0.
This result is used alongside the expression of the norm of X − X 0, which is written:

(1.29)
(1.30)
(1.31)
The term (X 0 , X − X 0 ) is null due to the orthogonality principle.
Figure 1.1 – Orthogonality principle: the point X 0 which is the closest to X in  is such that
X−X 0 is orthogonal to 
In what follows, the vector X 0 will be noted (X|C), or (X |Y 1:n ) when the sub-space onto
which projection occurs is spanned by the linear combinations of vectors Y 1 ,…, Y n.
The simplest application of theorem 1.2 provides that for any X   and any ε 
:
The projection theorem leads us to define an application associating element X with element
(X| ). This application is known as the orthogonal projection of X onto . The orthogonal
projection verifies the following properties:
1. linearity: (λX 1 + µX2| ) = λ (X1| ) + µ (X 2| );
2. contraction: ||(X | )|| ≤ || X ||;
3. if '  ,then((X | )| ') = (X | ');
4. if 1  2, then 
.
The following result is fundamental:
where ε = Y n +1 − (Y n +1 |Y 1:n). Because the sub-space spanned by Y 1:n +1 coincides with the
sub-space spanned by (Y 1:,n , ε) and because ε is orthogonal to the sub-space generated by (Y
1:n), then property (4) applies. To complete the proof we use (1.30).
Formula (1.31) is the basic formula used in the determination of many recursive algorithms,
such as Kalman filter or Levinson recursion.
Theorem 1.3 (Square-integrable r.v.) Let 
 be the vector space of square-integrable

(1.32)
(1.33)
random variables, defined over the probability space 
 . Using the scalar product 
, 
 has a Hilbert space structure.
Conditional expectation
The conditional expectation 
 may be seen as the orthogonal projection of X onto sub-
space  of all measurable functions of Y. Similarly, 
 may be seen as the orthogonal
projection of X onto the sub-space  of the constant random variables. These vectors are
shown in Figure 1.2. Because   , using Pythagoras’s theorem, we deduce that:
demonstrating var 
 var (X). This can be extended to random vectors, giving the
inequality (1.25) i.e. cov 
 cov (X).
Figure 1.2 - The conditional expectation 
 is the orthogonal projection of X onto the
set  of measurable functions of Y. The expectation 
 is the orthogonal projection of X
onto the set  of constant functions. Clearly, 
1.4 Gaussianity
Real Gaussian random variable
Definition 1.16 A random variable X is said to be Gaussian, or normal, if all its values
belong to  and if its characteristic function (see definition (1.9)) has the expression:
where m is a real parameter and σ is a positive parameter. We check that its mean is equal
to m and its variance to σ 2.
If σ ≠ 0, it can be shown that the probability distribution has a probability density junction
with the expression:

(1.34)
(1.35)
Complex Gaussian random variable
In some problems, and particularly in the field of communications, the complex notation X = U
+jV is used, where U and V refer to two real, Gaussian, centered, independent random
variables with the same variance σ 2 / 2. Because of independence (definition (1.7)), the joint
probability distribution of the pair (U, V) has the following probability density:
If we notice that |x |2 = u 2 + v 2, and if we introduce the notation p X(x) = p UV (u,v), we can
also write:
Expression (1.34) is called the probability density of a complex Gaussian random variable.
The word circular is sometimes added as a reminder that the isodensity contours are the
circles u2 + v2 = constant.
Note that:
Gaussian random vectors
Definition 1.17 (Gaussian vector) X1, …, X n are said to be n jointly Gaussian variables, or
that the length n vector [ X 1 … X n ] T is Gaussian, if any linear combination of its
components, that is to say Y = a H X for any a= [ a 1 … a n ]T  
n, is a Gaussian random
variable.
This definition is applicable for vectors with real or complex components.
Theorem 1.4 (Distribution of a real Gaussian vector) It can be shown that the probability
distribution of a n Gaussian vector, with a length n mean vector m and an (n × n)
covariance matrix C, has the characteristic function:
where u =(u 1 ,…,un )T  
n. Let x = (x 1 ,…,x n ) T . If det {C} ≠ 0, the probability
distribution’s density has the expression:

(1.36)
(1.37)
(1.38)
(1.39)
(1.40)
(1.41)
Theorem 1.5 (Distribution of a complex Gaussian vector) We consider a length n complex
Gaussian vector, with a length n mean vector m and an (n×n) covariance matrix C. If det
{C} ≠ 0,the probability distribution’s density has the expression:
We have
where 0 n is the (n × n) null-matrix.
Below, the real and complex Gaussian distributions will be noted 
 (m,C) and 
c (m,C)
respectively.
Theorem 1.6 (Gaussian case: non-correlation 
 independence) If n jointly Gaussian
variables are uncorrelated,  is diagonal; then they are independent.
Theorem 1.7 (Linear transformation of a Gaussian vector) Let [X1 … Xn ] T be a Gaussian
vector with a mean vector m x and a covariance matrix C X. The random vector Y = AX + b,
where A and b are a matrix and a vector respectively, with the ad hoc length, is Gaussian
and we have:
In other words, the Gaussian nature of a vector is untouched by linear transformations.
Equations (1.40) are a direct consequence of definition (1.17) and of property (1.6).
More specifically, if X is a random Gaussian vector 
, then the random variable Z = C
−1/ 2( X − M ) follows a Gaussian distribution 
. Another way of expressing this is to say
that if Z has the distribution 
 then X = M + C 1/ 2 Z has the distribution 
.
Note that, if C denotes a positive matrix, a square root of C is a matrix M which verifies:
Hence, if M is a square root of C , then for any unitary matrix U , i.e. such that UU H = I ,
matrix MU is also a square root of C . Matrix M is therefore defined to within a unitary matrix.
One of the square roots is positive, and is obtained in MATLAB® using the function sqrtm.
The Gaussian distribution is defined using the first and second order moments, i.e. the mean
and the covariance. Consequently, all moments of an order greater than 2 are expressed as a
function of the first two values. The following theorem covers the specific case of a moment of

(1.42)
(1.43)
(1.44)
(1.45)
(1.46)
order 4.
Theorem 1.8 (Moment of order 4) Let X1, X2, X3 and X4 be four real or complex centered
Gaussian random variables. Hence,
where βi is either “star” (conjugate variable) or “non-star” (non-conjugate variable).
Hence:
where 
 is “star” if βj is “non-star” and conversely.
Note that, based on (1.39), for complex Gaussian variables, the terms 
.
Gaussian conditional distribution
Consider two jointly Gaussian variables X and Y , taking their values from χ   p and 
respectively. The respective means are noted µ X and µ Y , and
is the joint covariance matrix. This produces the following results:
Property 1.10 The conditional expectation of X given Y coincides with the orthogonal
projection of X onto the affine sub-space spanned by 1 and Y, written B + AY. Hence:
– the conditional expectation is expressed as:
– the conditional covariance is expressed as:
– the conditional distribution of p X |Y ( x , y ) is Gaussian. The mean is expressed as
(1.45) and the covariance is given by expression (1.46).
Let g (Y) be the second member of (1.45), and let us demonstrate that g (Y) is the conditional
expectation of X given Y. A rapid calculation shows that  {(X − g (Y))Y H } = 0.
Consequently, the random vectors Z = ( X − g ( Y )) and Y are uncorrelated. As the vectors are
jointly Gaussian, following property (1.9), they are independent and hence 
.

(1.47)
Using the second member of (1.45), we obtain 
. On the other hand:
It follows that 
. To demonstrate expression (1.46), let us denote X c = X − µ X
and 
. Hence, successively:
where, in the first equality, we use the fact that 
 is independent of Y . In conclusion,
the conditional distribution of X , given Y , is written:
Note that the distribution for random vector 
 should not be confused with the
conditional distribution p X |Y ( x , y ) of X given Y . We shall restrict ourselves to the real,
scalar case taking µX and µY as the respective means of X and Y, and
with −1≤ ρ ≤ 1 as the covariance matrix. The conditional distribution of X given Y has a
probability density 
. On the other hand the random
variable distribution 
 has a probability density of 
. Indeed based on equation
(1.45) 
 and 
.
1.5 Random variable transformation
1.5.1 Change of variable formula
In many cases, it is necessary to determine the distribution of Y = g (X) from the distribution of
X. We shall consider this question in the context of continuous random vectors of dimension 2;
the generalization to higher dimensions is straightforward.
Take two random variables X 1 and X 2 with a joint probability density 
 and two
measurable functions g 1(x 1 , x 2) and g 2(x 1 , x 2). We shall consider the two random
variables:
and assume that the transformation defined in this way is bijective. For any pair (y 1 , y 2),

(1.48)
there is a single solution (x 1 , x 2). We may therefore write:
In this case, the probability distribution of the random variables (Y 1 ,Y 2) has a density of:
where 
 denotes the Jacobian of h : y → x which is expressed as:
In cases where the transformation is not bijective, it is necessary to sum all of the solutions
giving the pair (x 1, x 2) as a function of the pair (y 1,y2 ).
Note that the Jacobian of a bijective function has one particularly useful property. Taking a
bijective function x   d ↔ y   d ,we have:
This property allows us to calculate the Jacobian using the expression which is easiest to
calculate, and, if necessary, to take the inverse.
Example 1.1 (Law of the sum of two random variables)
As an example, let us consider two random variables X1 and X2 with a joint probability density
. We wish to determine the joint distribution of the pair (Y 1, Y 2), defined by the
following transformation:
where the determinant of the Jacobian has a value of 1. Applying (1.48), we obtain the
following probability density for the pair (Y 1, Y 2)
From this, the probability density of Y2 = X 1+X 2 may be deduced by identifying the marginal
distribution of Y 2. We obtain:
In cases where X 1 and X 2 are independent:

(1.50)
(1.51)
(1.49)
hence:
which is the expression of the convolution product 
.
1.5.2 δ-method
In cases where only the first two moments are considered, under very general conditions, the δ-
method allows us to obtain approximate formulas for the mean and the covariance of:
for any function 
. Let 
. Assuming that g is differentiable at point μX
and using the first order Taylor expansion of g in the neighborhood of μX, we write
where
is the q × m Jacobian matrix of g performed at point μX. For the sake of simplicity, this is
noted J (μX) below. Therefore, taking the expectation of (1.50), we get at first order
then
Therefore, according to the definition (1.18) of cov ( Y ), we have
It is worth noting that cov (g (X)) is a q × q matrix and cov ( X ) is a m × m matrix. In
summary we have:

The δ-method is commonly used when calculating the mean and the covariance of g (X) is
either intractable or the probability distribution of X is not fully specified.
Exercise 1.1 (δ-method) (see page 235) Consider two random variables (X1, X2), Gaussian
and independent, with means of μ1 and μ2 respectively, and with the same variance σ2. Using
the pair (X1, X2), we determine the pair (R, θ) by bijective transformation:
Use the δ-method to determine the covariance of the pair (R, θ). Use this result to deduce the
variance of R. This may be compared with the theoretical value given by:
where 
 is the hypergeometric function. We see that, when 
 tends
toward infinity, var (R) tends toward σ2. Additionally, when µ 1 = µ 2 = 0, we have var (R) =
(4 − π)σ2/2 ≈ 0.43σ 2.
1.6 Fundamental statistical theorems
The following two theorems form the basis of statistical methods, and are essential to the
validity of Monte-Carlo methods, which are presented in brief in Chapter 3. In very general
conditions, these theorems imply that the empirical average of a series of r.v.s will converge
toward the mean. The first theorem, often (erroneously) referred to as a law, sets out this
convergence; the second theorem states that this convergence is “distributed in a Gaussian
manner”.
Theorem 1.9 (Law of large numbers) Let Xn be a series of random vectors of dimension d,
independent and identically distributed, with a mean vector 
 and finite
covariance. In this case,
and convergence is almost sure.
One fundamental example is that of empirical frequency, which converges toward the
probability. Let Xn be a series of N random variables with values in a 1, a 2 , …, aJ and let fj
be the empirical frequency, defined as the relationship between the number of values equal to
aj and the total number N. In this case:

(1.52)
Theorem 1.10 (Central limit theorem) Let Xn be a series of random vectors of dimension d,
independent and identically distributed, of mean vector 
 and covariance matrix C
= cov (X 1 , X 1). In this case:
with convergence in distribution.
Convergence in distribution is defined as follows:
Definition 1.18 (Convergence in distribution) A set of r.v. UN is said to converge in
distribution toward an r.v. U if, for any bounded continuous function f, when N tends toward
infinity, we have:
Theorem 1.10 is the basis for calculations of confidence intervals (see definition 2.6), and is
used as follows: we approximate the probability distribution of the random vector 
, for which the expression is often impossible to calculate, by the
Gaussian distribution. For illustrative purposes, consider the case where d = 1, taking 
. Hence, for any c > 0:
Letting  = cσ, we have:
Aim for a probability equal typically to 0.05, c = 1.96.
As expected, the smaller σ and/or the higher N, the narrower, i.e. “better”, the interval will be.
Exercise 1.2 (Asymptotic confidence interval) (see page 236) Consider a sequence of N
independent random Bernoulli variables Xk such that 
. To estimate the proportion
p, we consider 
.
1. Using the central limit theorem 1.10, determine the asymptotic distribution of .
2. Use the previous result to deduce the approximate expression of the probability that p will
lie within the interval between 
.
3. Use this result to deduce an interval which ensures that this probability will be higher than
100 α %, expressed as a function of N and α typically, α = 0.95.

(1.53)
4. Write a program which verifies this asymptotic behavior.
The following theorem, known as the continuity theorem, allows us to extend the central limit
theorem to more complicated functions:
Theorem 1.11 (Continuity) Let U N be a series of random vectors of dimension d such that
and let g be a function 
 supposed to be twice continuously differentiable. Thus,
where Γ = ∂g (m)  ∂Tg (m) and where
is the Jacobian of g and ∂g(m) the Jacobian calculated at point m.
Applying theorem (1.11), consider the function associating vector U N with its ℓ-th component,
which is written:
where E ℓ is the vector of dimension d of which all components are equal to 0, with the
exception of the ℓ-th, equal to 1. Direct application of the theorem gives:
where mℓ is the ℓ-th component of m and Cℓℓ the ℓ-th diagonal element of C .
1.7 Other important probability distributions
This section presents a non-exhaustive list of certain other important probability distributions.
Some of the associated functions, which are not available in the basic version of MATLAB®,
are given in simplified form in the Appendix.
Uniform distribution over (a, b): noted (a, b) of density
where a < b. The mean is equal to (b + a)/2 and the variance to (b − a)2 / 12.
Exponential distribution: noted E (θ), of density

(1.55)
(1.56)
(1.57)
(1.54)
with θ > 0. The mean is equal to θ and the variance to θ 2. We can easily demonstrate that E
(θ) = θE (1).
Gamma distribution: noted G (k,θ), of density
where θ  
+ and k  
+. The mean is equal to kθ and the variance to kθ2. Note that E (θ) = G
(1, θ).
χ2 distribution with k d.o.f.: noted 
. The r.v. 
 where Xi are k Gaussian,
independent, centered r.v.s of variance 1 follows a χ 2 distribution with k degrees of freedom
(d.o.f.). The mean is equal to k and the variance to 2k.
Fisher distribution with (k 1 , k 2 ) d.o.f.: noted F (k 1 ,k 2 ). Let X and Y be two real, centered
Gaussian vectors of respective dimensions k 1 and k 2, with respective covariance matrices 
and 
, and independent of each other, then the r.v.
follows a Fisher distribution with (k 1 ,k 2) d.o.f.
Student distribution with k d.o.f.: noted Tk . Let X be a real, centered Gaussian vector, with a
covariance matrix Ik , and Y a real, centered Gaussian vector, of variance 1 and independent of
X. The r.v.
follows a Student distribution with k d.o.f.
We can show that if Z follows a Student distribution with k degrees of freedom, then Z2
follows a Fisher distribution with (1, k) degrees of freedom.
Notes
1 The exact expression says that the probability distribution of X is absolutely continuous with
respect to the Lebesgue measure.
2 Except in some particular cases, the random variables considered from now on will be real.
However, the definitions involving the mean and the covariance can be generalized with no
exceptions to complex variables by conjugating the second variable. This is indicated by a
star (*) in the case of scalars and by the exponent H in the case of vectors.

3 A definition of the term “complete” in this context may be found in mathematical textbooks. In
the context of our presentation, this property plays a concealed role, for example in the
existence of the orthogonal projection in theorem 1.2.

(2.1)
(2.2)
Chapter 2
Statistical Inferences
In probability theory, we consider a sample space, which is the set of all possible outcomes,
and a collection of its subsets with a structure of σ-algebra, the elements of which are called
the events. In what follows, an element of the sample space χ is denoted x, the associated event
space is denoted 
. The pair 
 is known as a measurable space [25]. Often, in the
following, the sample set will be 
n and the associated event set the Borel σ-algebra derived
from the natural open topology.
2.1 Statistical model
Definition 2.1 (Statistical model) A statistical model is a family of probability measures
defined over the same space 
 and indexed by θ  Θ, which is written:
When the set 
 is of finite dimensions, the model is said to be parametric; otherwise,
it is said to be non-parametric.
In what follows, we shall focus on parametric models, where χ = 
n, for which the probability
distribution has either a discrete form or a density p (x; θ) with respect to the Lebesgue
measure. This model is noted:
θ is said to be identifiable if, and only if:
We shall only consider models with identifiable parameters. It is essential that two different
parameter values will not, statistically, produce the same observations.
Example 2.1 (Gaussian model) In the case of the Gaussian model, the probability measure Pθ
is Gaussian over  with mean m and variance σ2. Parameter θ is thus θ = (m, σ2)  Θ =  × 
+ and the model is parametric. If σ ≠ 0 the probability has a density which is written:
In many applications, the statistical model is connected to a series of observations. For
example, consider the observations modeled by n independent Gaussian random variables,
with respective means m1, …, mn and respective variances 
. In this case,

(2.3)
(2.4)
the statistical model is characterized by a law for which the probability density over χ = 
n is
written:
We see that the dimension of the parameter set is dependent on n. In the specific case where the
random variables are identically distributed, Θ is no longer dependent on n and is reduced to 
 × 
+. This model, which forms the basis for a significant number of important results, will
be noted below as:
where parameter θ = (m, σ2)   × 
+.
Expression (2.3) may be generalized in cases where the observation is modeled by a series of
n random vectors X n of dimension d which are Gaussian and independent:
where x k = (x1,k, …, xd, k). Parameter 
, where 
, denotes the set
of positive square matrices of dimension d.
Example 2.2 (Stationary process) Consider a series of n successive observations of a
second-order, stationary random process. The statistical model associated with these
observations is the set of all probability distributions with a given mean for which the
covariance depends solely on the difference between the instants of two observations. The
model is clearly non-parametric.
Definition 2.2 (Statistic) A statistic or estimator is any measurable function of
observations.
The statistical model 
, where σ2 is presumed to be known, is fundamentally
different to model 
 where σ2 is an unknown parameter. In the first case, an
estimator may contain variable σ2, whereas in the second case this is not possible.
Statistical inference
The aim of statistical inference is to obtain conclusions based on observations modeled using
random variables or vectors. A number of examples of statistical inference problems are
shown below:
— estimation of the value of a parameter,
— estimation of an interval which has a 95% probability of containing the parameter

(2.5)
(2.6)
value,
— testing the hypothesis that a parameter belongs to a given region of Θ,
— grouping and/or classifying and/or ordering observations.
We do not aim to provide exhaustive coverage in this brief discussion, but simply to provide
some examples of hypothesis and estimator tests.
2.2 Hypothesis tests
Definition 2.3 (Hypothesis) A hypothesis is a non-empty subset of Θ. A hypothesis is said to
be simple if it reduces down to a singleton; in all other cases, it is said to be composite.
Example 2.3 Consider the model 
 of mean m  Θ =  and variance 1. The
hypothesis H0 = {0} is simple, whilst the alternative hypothesis H1 = Θ − H0 is composite.
Example 2.4 Consider the model 
 with (m, σ2)  Θ =  × 
+. The two
hypotheses H0 = {0} × 
+ and H1 = Θ − H0 are composite.
A test of hypothesis H0 consists of defining a sub-set χ1 of the space χ such that if realization x
belongs to χ1, then H0 is rejected. This is equivalent to defining the statistic T(X) = (X  χ1)
taking values of 0 or 1 and such that:
Subset χ1 is known as the critical region and statistic T (X) as the critical test function. Note
that 
In many cases, a statistic S (X) exists with real values and a number η such that the critical
function may be written in the form 
. In this case, the test is said to be
unilateral. In other cases, we find η1 ≤ η2 such that 
. In these cases
the test is said to be bilateral. S (X) is referred to as the test statistic.
Definition 2.4 (Significance level) A test associated with the critical function T (X) is said
to have a significance level α if
Note that for a random variable T with values in the interval {0,1}, 
 
.
Consequently, 
. Thus, in a radar context, the significance level represents
the probability of H1 being accepted when H0 is true. In the context of radars, the significance
level is known as the false alarm probability.
Definition 2.5 A test of a hypothesis H0 against the alternative H1 = Θ − H0, associated with

(2.7)
(2.9)
(2.10)
(2.8)
(2.11)
the critical function T (X), is said to be uniformly most powerful (UMP) at level α if for any
θ  H1, its power 
 is higher than that of any other test of level α. This is written:
where 
 denotes the set of tests of hypothesis H0 of level α.
In the context of radars, the power is interpreted as the probability of detection, which consists
of accepting H1 when H1 is true.
However, UMP tests do not exist for most situations.
2.2.1 Simple hypotheses
Consider the following statistical model:
characterized by a set Θ which only contains two elements and by the hypothesis H0 = {θ0}.
Take:
The following result, obtained by Neyman and Pearson, is fundamental: it gives the expression
of the UMP test at level α [20].
Theorem 2.1 For any value of α, there are two constants η and f  (0,1), such that the
critical function test
is UMP at level α. η and f are chosen in such a way as to satisfy the following constraint:
Function Λ(X) is known as the likelihood ratio.
This test is said to be “randomized” due to the fact that the decision strategy, when Λ(X) = η,
is random. The decision is made using an auxiliary random Bernoulli variable, with a value in
the interval {0,1}, with a probability f of being equal to 1.
In a large number of practical cases, the probability of the random variable Λ(X) being exactly
equal to η is null. In this case, f = 1 and the critical function is written:

(2.12)
(2.13)
The fundamental result is that the optimal test is based on the likelihood ratio.
The inequality Λ(X) ≥ η can often be simplified, as in the case of exponential models. This
may be illustrated using an example. Consider the model 
 with m  {m0, m1} and
m1 > m0. The likelihood ratio is written:
However, as the exponential function increases, comparing Λ(X) to a threshold is equivalent to
comparing the argument to another threshold. This comes down to comparing to a threshold the
quantity:
This can be simplified further by comparing the following statistic to a threshold ζ:
Statistic Φ has a much simpler expression than that used for the likelihood ratio. The critical
function is expressed as 
. Under H0 the random variable Φ(X) is
Gaussian, with mean m0 and variance 1/n. The threshold value is then determined in such a
way as to satisfy level α; this is written:
where Q[−1](α) is the inverse cumulative function of the standard Gaussian distribution.
Note that the UMP test of level α is not dependent on m1.
Figure 2.1 shows the connection between the significance level (or probability of false alarm),
the power (or probability of detection) and the probability densities of the random variable
Φ(X) under the two hypotheses.

(2.14)
(2.15)
Figure 2.1 – The two curves represent the respective probability densities of the test
function Φ(X) under hypothesis H0 (m0 = 0) and under hypothesis H1 (m1 = 2). For a
threshold value η, the light gray area represents the significance level or probability of false
alarm, and the dark gray area represents the power or probability of detection.
Evidently, raising the threshold reduces the probability of a false alarm, but also reduces the
probability of detection. A compromise between the two types of error is therefore required,
see example 2.5.
For certain problems, costs are assigned to each decision. A cost function is an application of 
. Let Ci,j  
+ be the cost of decision i knowing that j. The Bayesian approach
consists of determining the threshold which minimizes the mean risk:
The choice of the cost function depends on the target application, and should be made with
assistance from experts in the relevant field.
Example 2.5 (ROC curve) Let us take a statistical model 
 
 where m  {m0, m1}
with m1 > m0 and the hypothesis H0 = {m0}. The UMP test of level α compares:
with a threshold ζ, calculated based on the value α of the significance level. Starting from this
value of threshold ζ, we deduce the power β of the test. The curve giving β as a function of α is
known as the Receiving Operational Characteristic (ROC) curve. In our case, its expression as
a function of the parameter ζ   is written:
where σ2 = 1/n. Figure 2.2 shows the ROC curve for m0 = 0 and m1 = 1 and different values of
n. The form of these curves is typical. The ROC curve increases and is concave above the first
bisector. Note that the first bisector is the ROC curve associated with a purely random test,
which consists of accepting the hypothesis H1 with probability α. Hence, for a given
significance level, the power may not be as high as we would like. The closer the ROC curve
comes to the point (0,1), the more efficient the detector is in discriminating between the two

(2.16)
hypotheses. One way of characterizing this efficiency is to calculate the area under the ROC
curve, known as the AUC (Area Under the ROC Curve). The expression of the AUC associated
to the test function S is given by:
where pS (u0; θ0) and pS (u1; θ1) are the respective distributions of S under the two hypotheses.
The AUC may be seen as the probability that U0 is lower than U1 for two independent random
variables U0 and U1 with respective distributions pS (u0;θ0) and pS (u1;θ1).
Experimental ROC curve and AUC
The ROC curve and the AUC are valuable tools for evaluating test functions. However, it is
important to note that in problems with composite hypotheses, the power depends on the choice
of the parameter in the hypothesis H1. There is therefore an infinite number of possible ROC
curves, each associated with a value of parameter θ  H1. We may therefore choose a sub-set
of values of H1 beforehand, carrying out a random draw in order to obtain a mean curve.
Figure 2.2 – ROC curve. The statistical model is 
, where m  {0, 1}. The
hypothesis H0 = {0} is tested by the likelihood ratio (2.9). The higher the value of n, the
closer the curve will come to the ideal point, with coordinates (0, 1). The significance level
α is interpreted as the probability of a false alarm. The power β is interpreted as the
probability of detection.
An experimental approach may also be used. To do this, a series of measurements is carried
out including N0 examples under hypothesis H0 and N1 examples under H1. This data is then
used to evaluate the test statistic Φ in both cases. We obtain a series of values Φn o|0, with n0
from 1 to N0 for data labeled H0 and Φno|1 with n1 from 1 to N1 for data labeled H1. Using
these two series of values, it is possible to estimate the ROC curve and the area A under the

(2.17)
ROC curve, see exercise 2.1. To obtain an estimation A of the area under the ROC curve, we
may use expression (2.16) to deduce the Mann-Whitney statistic, which is written:
Note that the choice of the database, containing examples under both H0 and H1, is critical: this
database must include a sufficient number of examples which are representative of the
application in question.
Exercise 2.1 (ROC curve and AUC for two Gaussians) (see page 237) Consider the
statistical model 
 where m  {m0, m1}, with m1 > m0, and a hypothesis H0 =
{m0} to be tested. We consider that a database is available containing N0 observations for H0
and N1 observations for H1. In this exercise, these observations will be used to estimate the
ROC curve and the AUC associated with statistic (2.13), even though analytical expressions of
these two quantities are available in this specific case.
1. Using definition (2.6), propose an estimator, based on the data for H0, of the significance
level. Carry out the same exercise for the estimated power.
2. Write a program:
– simulating N0 = 1000 draws of length n = 10 for H0 and N1 = 1200 draws of length n
= 10 for H1,
– estimating the ROC curve and comparing it to the theoretical expression given by
(2.15),
– estimating the area under the ROC curve with the Mann-Whitney statistic.
2.2.2 Generalized Likelihood Ratio Test (GLRT)
Let us consider the parametric statistical model {Pθ; θ  Θ  
p}. Below, we shall presume
that this family is dominated, and hence Pθ has a probability density which may be simply
noted p (x; θ). The basic hypothesis H0 and the alternative H1 are both presumed to be
composite.
Generally speaking, no UMP test exists. As an example, consider a situation where the
parametric family is dependent on a single scalar parameter θ and where the hypothesis under
test is H0 = {θ ≤ θ0}. If the UMP test of level α of the simple hypothesis {θ0} against the
simple hypothesis {θ1}, with θ1 > θ0, does depend on θ1, then a UMP test cannot be carried
out.
In practice, in the absence of a UMP test, the generalized likelihood ratio test (GLRT) is used,
although it has attracted a good deal of criticism.
The GLRT is defined by the critical function 
, with the following test statistic:

(2.18)
(2.19)
(2.20)
This situation is illustrated in Figure 2.3. The larger the value of Λ(X) is compared to 1, the
more it is reasonable to reject hypothesis H0.
Note that Λ(x) is positive. We may therefore take the logarithm and define:
Figure 2.3 – Diagram showing the calculation of the GLRT
Subsequently, as the logarithmic function is monotonous and increasing, comparing Λ(X) to
threshold η is equivalent to comparing 
 to threshold log η
Taking θ = (θ1, …,θq, θq +1, …,θp) and the hypothesis under test:
H0 = {θ:θ1 = … = θq = 0,θq+1,…,θp}
under relatively general conditions [18], the test function (2.19) for H0 may be shown to
asymptotically follow a χ2 distribution with q degrees of freedom, written:
This result is used in exercises 2.8 and 2.17.
In the specific case where q = 1, the hypothesis H0 to be tested is often:
– of the form H0 = {θ1 ≤ µ0}, where µ0 is a chosen value. The hypothesis is said to be
unilateral. It is often tested using a unilateral test; or
– of the form H0 = {µ0 ≤ θ1 ≤ µ1}, where µ0 and µ1 are chosen values. In this case, the
hypothesis is said to be bilateral. One specific case occurs when µ0 = µ1, which gives the
hypothesis H0 = {µ = µ0}. Bilateral hypothesis testing is often carried out in these cases.
This case is illustrated by the test presented in the following section.
Bilateral mean testing

(2.21)
(2.22)
Consider the statistical model 
 where (m, σ2)  Θ =  × 
+ and with a
hypothesis H0 = {m0} × 
+. Let us determine the GLRT at significance level α The log-
likelihood is written:
Canceling the first derivative with respect to σ2, we obtain the expression of the maximum:
For m = m0 (hypothesis H0), the maximum is expressed as:
and for m ≠ m0 (hypothesis H1), the maximum is obtained by canceling the first derivative of 
 with respect to m, and is expressed as:
where 
 and, consequently, following (2.18):
Due to the monotonous nature of function 1/(1 + u2), comparing statistic Λ(X) to a threshold is
equivalent to comparing statistic |V (X)| to a threshold, where:
Setting p = 0 and then β0 = m0 in equation (2.62), we establish that, under H0, V (X) follows a
Student distribution with (n − 1) degrees of freedom. The test of H0 of level α is therefore
written:
Exercise 2.2 (Student distribution for H0) (see page 238) Take the statistical model 
 and the hypothesis H0 = {m = m0}. Write a program:

(2.23)
(2.24)
– simulating, for H0, 10000 draws of a sample of size n = 100,
– calculating V (X) following expression (2.22),
– comparing the histogram of V (X) to the theoretical curve given by Student’s distribution.
The tpdf function in MATLAB® provides the probability density values of Student’s
distribution (see also appendix A.2.3).
Exercise 2.3 (Unilateral mean testing) (see page 239) Take the statistical model 
 where (m, σ2)  Θ =  × 
+ and the hypothesis H0 = {m ≥ m0} × 
+.
Determine the GLRT of H0 at significance level α.
p -value associated with a test
Let us consider a test of hypothesis H0, for which the critical function is of unilateral form, 
, where S (X) is a function with real values. Based on observation X, it
is possible to calculate T (X), which takes a value of either 0 or 1. We wish to determine a
confidence level associated with this decision. The first idea would be to give the calculated
value of S (X); however, this value is meaningless in absolute terms. However, the probability
of observing a value greater than S (X) under the hypothesis H0 has a clear meaning: the lower
the probability, the more reasonable it will be to reject H0. The probability distribution of S
(X) for all values of parameter θ  H0 is necessary in order to carry out this calculation. The
probability density of this distribution is noted pS (s; θ). The following statistic is known as the
p-value:
The closer this value is to 0, the more reasonable it is to reject H0. Clearly, if the critical
function is of bilateral form, 
 
, the p-value is defined by:
Note that a common error consists of comparing the p-values of two samples of different sizes.
This is irrelevant as, generally, as the size of a sample increases, the distribution of S (X)
narrows and thus the p-value decreases. Moreover, note that the p-value is dependent on the
chosen test statistic. Consequently, for the same observations, it may take a high value for one
test statistic and a low value for another statistic. Its meaning is therefore often debated, but
this technique remains widespread. Typically, rejection of H0 is recommended in cases with a
p-value of less than 1%.
Confidence interval associated with a test
Definition 2.6 Consider a statistical model {Pθ; θ  θ} defined over χ and a series of
observations X = {X1, …, Xn}. Let α  (0,1). The confidence region for θ at 100(1 − α)% is

a region 
 such that, for any θ:
When θ is of dimension 1, we speak of a confidence interval.
A test may therefore be associated with a region of confidence, as follows. Taking a region of
confidence 
 at 100(1 − α)% of θ, then the indicator 
 is a critical test function of
the hypothesis H0 = {θ = θ0} at significance level α.
Reciprocally, consider a statistical model, and let Rα (θ0)  χ be the critical region of a test of
significance level α associated with the hypothesis H0: {θ = θ0}. In this case, each value x  χ
may be associated with a set Sα (x)  Θ defined by:
As the test is of level α, 
 and thus:
meaning that Sα (X) is a region of confidence at 100(1 − α)% of θ0.
Example 2.6 (Variance confidence interval) Take the statistical model 
,
with unknown mean and variance. Determine the GLRT of significance level α associated with
the hypothesis H0 = {σ = σ0}. Use this result to deduce a confidence interval at 100(1 − α)%
of σ2.
Hints: based on (2.18), after simplification, we obtain the following test statistic:
where 
 with 
. Using the results of property 2.2, Φ(X)
may be shown to follow a 
 distribution with (n − 1) degrees of freedom.
We may then identify a critical region at level α:
where 
 is the inverse of the cumulative function of the χ2 distribution with (n − 1)
degrees of freedom. From this, we can deduce a confidence interval at 100(1 − α)% of σ2:
Exercise 2.4 (Mean equality test) (see page 240) Consider two samples, 
 and 
, i.i.d Gaussian, independent, with respective means of m1 and m2 and a common variance σ2
and of respective lengths n1 and n2. σ is presumed to be unknown. Determine a test for the

hypothesis m1 = m2.
1. Describe the statistical model and the hypothesis H0.
2. Determine the GLRT of H0 at significance level α.
3. Show that, for H0, the test statistic is expressed as the modulus of a Student r.v. with (n1 +
n2 − 2) degrees of freedom. Use this result to identify the test at level α.
4. Use this result to determine the p-value.
5. Consider Table 2.1, which provides the growth results of a plant, in mm, using two
different fertilizers, noted 1 and 2. Give the p value of the mean equality test and present
your conclusions.
Table 2.1. – Growth in mm under the action of fertilizers 1 and 2
F
1
1
1
1
2
2
2
size (mm) 51.0 53.3 55.6 51.0 55.5 53.0 52.1
Exercise 2.5 (Correlation test) (see page 243) Consider two samples {X1,1, …, X1,n} and
{X2,1, …, X2,n}, i.i.d. Gaussian, with respective means m1 and m2 and respective variances 
and 
, and with a correlation coefficient ρ  (−1,1). Consider the hypothesis H0 = {−ρ0 ≤ ρ
≤ ρ0}, which tests whether the modulus of the correlation is lower than a given positive value
ρ0.
1. Describe the statistical model and the hypothesis H0.
2. Determine the GLRT of H0.
3. Transformation 
 is known as a Fisher transformation. The Fisher
transformations of  and ρ0 are noted  and f0 respectively. Under the hypothesis H0, the
random variable  can be shown to follow, approximately, a Gaussian distribution of mean
f0 and variance 1/(n − 3). Use this result to determine the p-value of the test for hypothesis
H0 = {|p | ≤ 0.7} using the data supplied in Table 2.2 and present your conclusions.
Table 2.2. – H: height in cm, W: weight in kg.
H (cm) 162 167 167 159 172 172 168
W (kg) 48.3 50.3 50.8 47.5 51.2 51.7 50.1
Exercise 2.6 (CUSUM) (see page 244) Consider a sequence of n independent random
variables. These variables are presumed to have the same probability distribution, of density p
(x; µ0), between instants 1 and m and the same probability distribution, of density p (x; µl),
between instants m + 1 and n, where m may take any value from 1 to n − 1 inclusive, or keep

(2.25)
(2.26)
the same distribution p (x; µ0) over the whole sample. The value of m is unknown.
We wish to test the hypothesis H0 that no sudden jump exists from µ0 toward µl.
1. Describe the statistical model.
2. Determine the test function Tn of the GLRT of hypothesis H0, associated with a sample of
size n.
3. Taking 
, show that Tn may be calculated
recursively using the form Tk = max{0, Tk−1 + sk}.
4. Write a program implementing this algorithm.
As this test is carried out using the cumulated sum of likelihood ratios, it is generally referred
to as the CUSUM. By carrying out maximization of µ0 and µ1, it may be extended to cases
where these parameters are unknown.
2.2.3 χ2 goodness of fit test
A goodness of fit test is a test using the basic hypothesis H0 that the observed sample comes
from a given probability distribution. As before, hypothesis H0 = {P = P0} may be simple or
composite. Hence, if the hypothesis H0 is that the observation follows a Gaussian distribution
with a given mean and variance, H0 is simple. However, if the variance is unknown then H0 is
composite. Evidently, if the set of possible probability distributions under consideration cannot
be indexed using a parameter of finite dimensions, the model will be non-parametric.
Consider a series of n real random variables, {X1, …, Xn}, i.i.d., and a partition of  into g
disjoint intervals ∆1, …, ∆g. Take:
which represents the number of values in the sample {X1, …, Xn} which are located within the
interval ∆j. Note that N1 +…+ Ng = n, and 
 
 with ∑jpj,0 = 1. In cases
where hypothesis H0 is composite, the quantities pj,0 may be dependent on unknown
parameters. In this case, these parameters are replaced by consistent estimations. In exercise
2.7, for example, the true value of the variance is replaced by an estimation.
Exercise 2.7 shows that the random variable:
This result has an obvious meaning: X2 measures the relative distance between the empirical
frequencies Nj/n and the theoretical probabilities. Based on the law of large numbers (theorem

1.9), Nj/n converges under H0 toward pj,0 and under H1 toward pj,1 ≠ pj,0. Thus, statistic X2
will take small values for H0 and large values for H1; these values will be increasingly large
as n increases. This justifies the use of an unilateral test, which compares X2 to a threshold and
proves its consistency.
The choice of the number g and the interval sizes ∆j is critical. One method consists of
selecting g classes of the same probability, or of dividing the set of sample values into classes
with the same empirical weight (see exercise 2.8).
Exercise 2.7 (Proof of (2.26)) (see page 246) Using the conditions associated with
expressions (2.25) and (2.26), take D = diag (P) with P = [p1 … pg ]T, where 
.
1. Determine the expressions of 
 and 
 and as a function of pj. Use these
expressions to deduce the fact that the covariance matrix of the random vector (N1, …, Ng)
is written nC, where C is a matrix for which the expression will be given.
2. Show that D−1/2CD−1/2 is a projector of rank (g − 1).
3. Taking 
, determine the asymptotic distribution of the random vector Y = [ Y1
… Yg ]T. Use this result to determine the asymptotic distribution of vector Z = D−1/2Y.
4. Finally, identify the asymptotic distribution of variable 
.
Exercise 2.8 (Chi2 fitting test) (see page 247) Write a program simulating the hypothesis H0
= {m = 0} for model 
. To do this, 3000 drawings of a sample of size n =
200 are required, with a Gaussian random variable of mean 0 and unknown variance σ2. The
set of values of each draw should be separated into g = 8 blocks containing the same number of
samples, i.e. 200/8. Using the function which produces the cumulative function of a Gaussian,
calculate the values of 
, in which the true, unknown value of σ is replaced by the
estimation given using the std function in Matlab. Using this result, deduce the values of X2
given by expression (2.26), and create a histogram, which will be compared to the theoretical
curve of χ2 with g − 1 = 7 degrees of freedom.
2.3 Statistical estimation
2.3.1 General principles
In this section, we shall consider the problem of parameter estimation. We shall begin by
presenting a number of general results concerning performance evaluation, notably bias and
quadratic error. We shall then examine three methods used in constructing estimators: the least
squares method, mainly in the case of the linear model, the moment method, and the maximum
likelihood approach.
Definition 2.7 (Estimator) Let {Pθ; θ  Θ} be a statistical model of observation X. An

(2.27)
estimator is any (measurable) function of X with values in Θ.
One fundamental question concerns the evaluation of estimator quality. We might try to choose
an estimator  such that 
. Estimators of this type only exist in exceptional situations,
and have no practical interest. In practice, two quantities are used, the bias and the risk: these
are defined below.
Definition 2.8 (Bias and risk of an estimator) Consider an estimator : 
. The bias
is the vector of dimension d:
The quadratic risk is the square matrix of dimension d:
It is easy to show that
where
is the covariance matrix of .
It is worth noticing that an estimator does not depend on the unknown parameter being
estimated, but the performance of the estimator does depend on this parameter. Thus, the bias
and the risk are generally dependent on θ.
It is pointless to try and find an estimator with the minimum quadratic risk for all values of θ.
For this reason, we have to restrict the search class for . For example we could limit the
search to bias-free estimators, or to the class of linear estimators, or the class of estimators
which are invariant by translation, etc.
Another method involves a Bayesian approach, which consists of taking account of available
knowledge concerning θ, which takes the form of a probability distribution p Θ (θ) and may be
used for minimizing the average risk:
over the set of all estimators.
Cramer-Rao bound
Quadratic risk has a fundamental lower-bound, known as the Cramer-Rao bound (CRB).
Theorem 2.2 (Cramer-Rao bound (CRB)) Any estimator  of the parameter θ  Θ  
d

(2.28)
(2.30)
(2.29)
(2.31)
(2.33)
(2.32)
verifies 1:
where 
 is the Jacobian matrix of the vector 
 with respect to θ, and where
where 
 log p (X; θ) is the Hessian of log p (X; θ) (square matrix of dimension d) for which
the element in line m, column ℓ is written 
.
In the case of an unbiased estimator, formula (2.28) may be simplified, giving:
Matrix F is known as the Fisher information matrix. An estimator which reaches the CRB is
said to be efficient; however, an efficient estimator does not always exist.
It can be shown that:
where ∂θ log p (X; θ) is the Jacobian of log p (X; θ) (vector of length d).
2.3.2 Least squares method
Consider a series of observations yn of the form:
where xn (β) is a deterministic model dependent on the parameter of interest β  Θ  
d and
wn is a random process representing an additive noise. Take the example of a sinusoid in
noise, written:
Parameter θ = (A, f0, ϕ)  Θ = 
+ × (0, 1/2) × (0, 2π). Note that the model is non-linear with
respect to f0.
Using a series of N observations, the least squares method consists of using the following
estimator of β:
This very general method was introduced by Gauss for use in determining the trajectories of
the planets. It still plays a key role in estimator construction methods. It may be applied on the

(2.34)
condition that we have a deterministic model, dependent on the parameter being estimated. The
added noise wn models the measurement noise, but also the “model” noise, i.e. the fact that we
are not completely certain of the presumed model xn (β). As we shall see, the least squares
estimator corresponds to the maximum likelihood estimator in cases where wn is a Gaussian
random process.
Example 2.7 (Non linear model) Consider N = 6 observations yn which are written:
where the parameter of interest is θ = (θ0, θ1). Using the function fminsearch (one of the
components of the optim toolbox, write a program to estimate parameter θ using the least
squares methods. Use the data provided in Table 2.3.
Table 2.3. – Observed pairs (xn,yn)
xn 21
23
25
27
29
31
yn 0.02 0.05 0.03 0.08 0.25 0.38
xn 33
35
37
39
41
43
yn 0.6
0.7
0.9
0.94 0.99 1
Hints: type the program:
Figure 2.4 shows the curve obtained based on the estimated value of the pair (θ0,θ1).
2.3.3 Least squares method: linear model
Using (2.33) to find an estimator using the least squared method does not generally result in a
simple analytical expression, and requires the use of numerical approaches. Moreover, whilst
a number of asymptotic results exist, performance often needs to be studied on a case-by-case
basis. The exception to this rule is the case of the linear model, for which a considerable
number of results have been found. This section is based on a detailed study of this model,
written, for n = 1, …., N:

(2.35)
(2.36)
(2.37)
Figure 2.4 – Least squares method for a non-linear model given by equation (2.34). The
points represent observed value pairs (Table 2.3)
where {Zn = [1 Xn,1 … Xn,p ]T = [1 Xn ]T} is a series of known vectors and 
n is a random
sequence of white, zero-mean uncorrelated r.v. with variance 1, and σ is a positive number.
The expression “linear model” refers to linearity of expression (2.35) with respect to β. This
is also known as linear regression.
The variables yn are known as responses or dependent variables. The variables Xn,j are known
as regressors or explanatory variables, or as independent variables (not to be confused with
independent random variables). Explanatory variables may be seen in two ways: either as N
points in the space 
p, or as p points in the space 
N.
Below, we shall consider the case of real data, but the results are applicable to cases
involving complex data values.
Geometric properties
Using matrix notions, (2.35) may be rewritten:
where
— y is a vector of dimension N × 1;
— Z= [1N X ] is a matrix of dimension N × (p + 1), in which all of the components in the
first column are equal to 1;
— β = (β0, …, βp)  
p+1. Coefficient β0 is known as the intercept;
— σ  
+.
and where 
 is a random vector verifying either the hypotheses:
or the hypothesis

(2.39)
(2.38)
(2.40)
(2.41)
Model (2.37) is non-parametric, whereas (2.38) is parametric. Clearly, (2.38) entails (2.37),
but the reverse is not the case. The parameter for estimation in the proposed statistical model
is thus:
Notation
— r denotes the rank of matrix Z. We can show that r ≤ min {N, p + 1}. If r = (p + 1) ≤ N,
Z is said to be of “full column rank”, and the square matrix ZTZ of dimension p + 1 is
invertible.
— ΠZ denotes the orthogonal projector onto the sub-space spanned by the columns of Z.
This sub-space is noted Im(Z) as image of Z. Remember that 0N ≤ ΠZ ≤ I N, ΠZ has r
eigenvalues equal to 1 and that the (N–r) others are null. Hence, trace {ΠZ} = r.
— 
 denotes the projector onto the sub-space orthogonal to Im(Z). 
 is positive.
Hence trace 
.
— hn, n denotes the n-th diagonal element of matrix ΠZ. From this, we can deduce that 
. If un denotes the vector for which all components are null
except for the n-th component, which is 1, hence, 
. Applying expression
(2.51) (Π1 ≤ ΠZ ≤ I N) to vector un, we obtain:
Note that hn, n is dependent on the Xn variables, but not on the yn variables. The mean value of
the hn, n is r/N. A value for hnn which is close to 1 indicates that, in the space 
p, point Xn is
far from the center of the cloud of points associated with other values. Conversely, a value
close to 1/N indicates that the point is close to this center. The quantity hn, n is known as the
leverage, see exercise 2.9.
As 
, any sum of the diagonal elements of the same rank in 
 and ΠZ must be equal
to 1, i.e. 
, and any sum of non-diagonal elements of the same rank will
be equal to 0, i.e. 
.
According to the projection theorem 1.2, the best approximation, in the least square sense, of y
in the sub-space Im(Z) is given by the orthogonal projection:
An estimator 
 of β, in the least square sense, therefore verifies:

(2.42)
(2.43)
(2.44)
(2.45)
(2.46)
(2.47)
(2.48)
If Z is of full column rank, then projector ΠZ = Z (ZT Z)−1ZT. There is therefore a single
element 
 which verifies equation (2.41), written:
In cases where Z is not full rank, there are an infinite number of solutions defined to within an
additive factor, an element of the null-space (kernel) of Z.
One expression which is useful in practice can be obtained by replacing y by (2.36) in
expression (2.41). We obtain:
If Z is full column rank, then (2.43) may be rewritten:
This allows us to deduce the properties of 
 from those of 
.
Centering variables
In this section, we shall show that the intercept and the other coefficients of β are associated
with orthogonal spaces, and can therefore be calculated “separately”.
Let 1N be a vector of length N all the components of which are 1. We can verify that the
projector of rank 1 onto the sub-space spanned by 1N is expressed as:
Let Xc be a matrix of which the column vectors are the centered column vectors of X, written:
Finally, let 
 be the orthogonal projector over the sub-space spanned by the columns of Xc.
Multiplying expression (2.45) by 
 on the left we obtain 
, and thus:
This implies that 1N is orthogonal to Xc and, consequently, Im([1N Xc ]) = Im (1n) 
 Im
(Xc). Exercise 2.9 demonstrates that:
From (2.47), we may deduce that the orthogonal projection , given by expression (2.40), is
written:
Using (2.46), we have 
, which can be rewritten:

(2.49)
(2.50)
(2.51)
Take 
. (2.48) may also be written:
Once again, this expression uses (2.46). Expression (2.50) shows that the orthogonal
projection may be determined in two separate steps: one for projection onto the space spanned
by the centered variables, and the other one for calculating the mean
Exercise 2.9 (Decomposition of Z) (see page 248)
1. Demonstrate the expression (2.47). To do this, show that 
.
2. Use this result to show that:
Remember that, for two positive matrices A and B, A ≥ B means that, for any vector v, we
have vHAυ ≥ υHBυ.
3. Multiplying (2.51) by a vector all components of which are null except for the n-th
which is 1, demonstrate the double inequality (2.39).
4. Let Xn be the n-th line of matrix X. Write a program which shows that, if hn, n is close to
1/N, the point of coordinates Xn in 
p is close to the center of the cloud formed by the
other points. Inversely, if hn, n is close to 1, the point is far from the cloud. To allow a
display in 
p, set p = 2.
Probabilistic properties
Consider the linear model given by expression (2.35) with hypotheses (2.37). The 
n are
centered r.v.s, of variance 1, which are not correlated with each other. Suppose that Z is of full
column rank, matrix ZT Z being therefore invertible.
Property 2.1 (Best Linear Unbiased Estimator - BLUE) The estimator
is an unbiased estimator of β and has the lowest covariance of all of the linear unbiased
estimators. It is said BLUE for Best Linear Unbiased Estimator. This covariance is
expressed:
Replacing y by (2.35) in , we obtain 
. As 
 0, then 
.  is
unbiased. From this, we deduce that cov 
 
.
Now, consider another linear estimator with respect to y of the form 
 Qy, such that 
.

(2.54)
(2.55)
(2.52)
(2.53)
In this case, 
, implying that QZ = Ip+1. From this, we deduce that cov 
.
Additionally, A = I N − Z (ZTZ)−1 ZT is a projector; A = AT and AA = A. Hence:
By developing the expression and using QZ = I, we deduce that:
which is the expected result.
In the rest of this chapter, unless indicated otherwise, we shall consider hypothesis (2.38), i.e.
that 
 is white and Gaussian.
Property 2.2 The solution to problem (2.36) using hypothesis (2.38) possesses the following
properties:
— 
,
— 
, where the rank of ΠZ is r,
— 
 where the rank of 
. We have 
— ê and  are independent random variables,
— if Z is of full rank, ê and  are independent random variables.
Inserting expression (2.36) into expression (2.40), we obtain:
using ΠZ Z = Z. From this, we deduce that the prediction residual defined by vector 
 is written:
This produces the following results:
— based on (2.49), 
;
— based on (2.52), the distribution of  is Gaussian, and is written:
— based on (2.53), the distribution of error ê is Gaussian, and is written:
— the random vectors ê and  are independent. Indeed, following (2.52) and (2.53), cov 

(2.57)
(2.56)
, meaning that ê and  are not correlated; as they are jointly
Gaussian, they are independent;
— if Z is of full rank, then random vectors ê and  are independent. In this case, cov 
, and if Z is of full rank, 
 0.
This completes the proof.
Note that the random vector 
 should not be confused with the random vector 
.
The former is not observable, as the true value of β is unknown, whereas the latter is
observable.
Unbiased estimator of σ2
Following (2.55), 
 and thus
From this, we deduce that , defined as
is an unbiased estimator ofσ2.
Calculating a confidence interval for Znβ
Using expression (2.54) and multiplying the left hand side by a vector of which all components
are null except for the n-th which has a value of 1, we deduce that 
,
using theorem (1.7). Applying (2.55) and the definition of Student’s law, we deduce that:
where TN−r denotes a Student r.v. with (N − r) degrees of freedom.
Remember that in expression (2.39), 1/N <hn, n ≤ 1.If hn, n is small, close to 1/N, then  is
weakly dispersed around the true value Znβ. However, if hn, n ≈ 1,  is strongly dispersed
around the true value Znβ- hence the term leverage.
Calculating a confidence interval for σ2
The distribution of 
 is the sum of the squares of (N − r) independent, Gaussian r.v.s of
variance 1. 
 is thus χ2 with (N − r) degrees of freedom written:
From this, we may deduce a confidence interval of level 100(1 − α)% of σ, written:

(2.58)
(2.61)
(2.62)
(2.59)
(2.60)
Calculating a confidence interval for new data points
Using the estimated value of β for N learning data points (yn, Zn), we can deduce the prediction
of y0 (new data) based on an observation z0, vector of length (p +1). This is written:
Hence:
Taking Z as being of full column rank, ŷo is a centered Gaussian r.v. of variance:
Using (2.42) we can write:
Note that, following (2.53), the variance of the n-th component of ŷ is expressed σ2(1 − hn, n)
where 1/N ≤ hn, n ≤ 1 is the n-th diagonal element of Π Z. Moreover, following (2.59), var (ŷ0)
ŷ≥ σ2(1 − hn,n). This is legitimate, given that it is harder to make a prediction using new data
points than using data taken from the learning set for model β.
Following (2.55), the r.v (yo − yo)/σ is independent from ê/σ. Hence:
From this result, we deduce a confidence interval of 100(1 − α)% for yo:
Testing the hypothesis H0 = {βk = 0}
We shall begin by showing that:
where TN−p −1 denotes a Student r.v. with (N − p − 1) degrees of freedom.
Following (2.44), in the case where Z is of full column rank:

(2.63)
(2.64)
(2.65)
(2.66)
Multiplying the left hand side by the vector of which all components are null except the k-th
which is 1, then dividing by 
, we obtain:
Dividing the first member of (2.63) by the square root of the first member of (2.57), we obtain
(2.62).
The function defined by (2.62)2 can be used to deduce a critical function for testing hypothesis
H0 = {βk = 0}. With H0, we have:
The bilateral test with critical function 
 can therefore be used, where η is
determined for a given significance level. Based on expression (2.24), this bilateral test has a
p-value of:
where 
 is the probability density of Student’s distribution with (N − p − 1) degrees of
freedom. As stated in section 1.7, note that the Student distribution is a specific instance of the
Fisher distribution.
Testing the hypothesis H0 = {β1 = … = βp = 0}
We wish to test the hypothesis H0 = {β1 = … = βp = 0}. To do this, we take:
— the mean 
 yn;
— the sum of squares regression 
. Following (2.54), for H0, the
relationship SSR/σ2 follows a χ2 distribution with p degrees of freedom;
— the sum of square errors SSE = êTe. Following (2.55), for H0, the relationship SSE/σ2
follows a χ2 distribution with N − (p + 1) degrees of freedom;
— the sum of square total 
. Based on Pythagoras’s theorem (see also
Figure 1.2), we have SST = SSE + SSR;
— coefficient R such that:
The closer R2 is to 1, the smaller the residuals, and the better the model will explain
observations. Inversely, if R2 ≈ 0, there will be little connection between the set of explanatory

(2.67)
(2.68)
variables and the response y. This may be used to deduce a test for hypothesis H0. To do this,
we note:
In accordance with section 1.7, for H0, S (X) follows a Fisher distribution with (p, N − p − 1)
degrees of freedom, written:
We can therefore construct a critical test function 
 and calculate the
threshold η for a given significance level, along with a p-value.
Exercise 2.10 (Car consumption) (see page 248) Use the data file available in MATLAB®
with the command load carsmall. Among other things, this contains the gas consumption of
around one hundred vehicles expressed in miles per gallon (the MPG variable), which we
shall note y, along with the weight (Weight variable) noted x1 and the horsepower
(Horsepower variable), noted x2, of these vehicles. Write a program to test whether variables
x1 and x2 are explanatory for variable y using a linear model of the form:
Calculate the p-value of the test of hypothesis H0 = {βk = 0} for the two values k = 1 and k =
2.
Determine the value of R2 and the p-value associated with the test of hypothesis H0 = {β1 = β2
= 0}.
Example 2.8 (Water fluoridation) The values given in Table 2.4 give the occurrence of dental
cavities and the level of fluoride in drinking water observed in 21 American cities for a total
of 7257 children [16]. These values are illustrated on the left hand side of Figure 2.5. The
linear model does not appear to be suitable. A model of the form y ≈ γ (x + 1)α with α < 0
seems to give a more satisfactory result. Taking the logarithm of the two members, we obtain
log y ≈ β0+ β1 log (x + 1), which is linear with respect to log(x + 1). This corresponds well
with the illustration in the right hand side of Figure 2.5.
Take y = β0+ β1x, where x denotes the log-percent of the number of cavities and y the log-
concentration of fluoride. Test the hypothesis that β1 = 0.

Table 2.4. — Cavity figures given as thousands. The fluoride level is given in ppm (parts per
million).
fluoride
cavities
1.90
17.13
2.60
17.85
1.80
18.29
1.20
18.72
1.20
20.39
1.20
21.99
0
23.44
fluoride
cavities
1.30
24.89
0.90
29.90
0.60
32.22
0.50
40.35
0.40
47.32
0.30
51.02
0
51.23
fluoride
cavities
0.20
53.19
0.10
56.02
0.20
59.73
0.10
75.26
0.10
58.78
0.10
48.84
0
52.40
Figure 2.5 – Percentage of dental cavities observed as a function of fluoride levels in
drinking water in ppm (parts per million).
Hints: we obtain R2 = 0.9092 and 
, and the p-value ≈ 2.4 × 10−11. This leads
us to reject the hypothesis according to which β1 = 0.
Execute the following program:

(2.70)
(2.69)
(2.72)
(2.71)
 
Weighted least squares (WLS)
For model y = Zβ + σ
, the covariance of 
 is, in certain cases, a known matrix. If this matrix
is noted Γ, then the best estimator in terms of least squares is expressed:
(2.69) is known as the weighted least squares (WLS) estimator.
Let P be the square matrix of dimension N such that Γ = PPT. We have PY = (PZ)β + σ ξ with
ξ = P . We may verify that cov (ξ) = I n, as in the case of ordinary least squares (see
expression (2.42) of the ordinary least squares (OLS) estimator), with Y replaced by PY and Z
by PZ. From this, we deduce that the estimator given by (2.69) is unbiased, and its covariance
is expressed:
It is easy to show that the weighted least squares estimator minimizes the following function:
2.3.4 Method of moments
Let us begin with an example: consider N observations X 1, …, XN distributed following a
Gamma distribution of parameter θ = (k,λ)  
+ × 
+, with a probability density of:

(2.73)
(2.74)
(2.75)
(2.76)
where 
. We can show that 
 and 
.
The basic idea behind the method of moments is to relate statistical and empirical moments
written:
To obtain estimators, we must simply solve these two equations, with two unknowns, with
respect to (k, λ). Hence:
where 
 and 
.
Exercise 2.11 (Central limit for a moment estimator) (see 250) For the moment estimator
given by (2.73), determine the asymptotic behavior deduced from the central limit theorem
1.10 and the continuity theorem 1.11.
Generalized method of moments
Clearly, multiple estimators may be obtained by choosing moments of the form 
. It is
even possible to choose more moments (i.e. equations) than there are parameters (i e.
unknowns) to estimate. Starting with M moments of the form 
 (X1may be used
with no loss of generality, as the r.v.s are taken to be i.i.d.) the generalized method of moments
consists of taking the following estimator:
where Ŝ is a vector of length M, written:
The estimator given by expression (2.74) may be improved by using the covariance matrix of Ŝ
and by using the weighted least squares approach shown in expression (2.71). This gives the
following estimator
where the covariance matrix is given by:

(2.77)
(2.78)
Using the fact that the r.v.s Xn are i.i.d., we have:
(2.76) is generally minimized using a computational approach via a minimization program such
as fminsearch in MATLAB®, see exercise 2.12.
Another possibility is to replace matrix C (θ) in expression (2.76) by a consistent estimation,
giving:
then applying a general minimization program.
However, a major issue with the generalized method of moments is that there is nothing to
indicate, a priori, how many and which moments we have to choose, except in cases where a
“sufficient” statistic exists (see the Fisher factorization criterion in [20, 27]); however, in these
cases, the maximum likelihood approach is preferable.
In conclusion, the method of moments is easy to apply, but a case-by-case study is required in
order to obtain satisfactory performances. However, in the case of large samples, the law of
large numbers 1.9 and the central limit theorem 1.10 can be used for performance evaluation.
Exercise 2.12 (Estimation of the mixture proportions) (see page 251) Consider a series of
N random variables Xn, i.i d., where the commun distribution writes:
where α  (0,1).
Suppose that α is unknown and that m1, m2, σ1 and σ2 are known:
1. Give the expression of the statistical model.
2. Determine a moment estimator for α based on the statistic 
 
. Use
this result to deduce the expressions of 
 and 
.
3. Determine a moment estimator for α based on the two statistics 
 
 and 
 and using the expression of S (α) given (2.75).
4. Determine the expression of the covariance C (α), defined by (2.77). Use expression (2.76)
to find a moment estimator for α.
5. Write a program to simulate and compare the behavior of the three estimators.

(2.80)
(2.81)
(2.82)
(2.79)
2.3.5 Maximum likelihood
The maximum likelihood estimation method is based on the fact that a good estimator of θ may
be reasonably thought to maximize the probability of what has been observed In the case of
“continuous” r.v.s, the probability is replaced by the probability density.
Definition 2.9 (Likelihood) Let X = (X1, …, XN) be a set of N observations, with a joint
probability density pX (x, …, xN θ) where θ  Θ. The likelihood is the function of Θ in 
:
The maximum likelihood estimator (MLE) is the estimator defined by:
The logarithm of the likelihood function is known as the log-likelihood. As the logarithm is an
increasing function, likelihood may be replaced by log-likelihood in expression (2.80) Note
that:
— one sufficient condition for the existence of a maximum is that the set Θ is compact and
that function ℓ (x; θ) is continuous over Θ;
— the MLE is not generally unique;
— the MLE is invariable by re-parameterization. This means that if θ → g (θ) is a function
defined over Θ and if  is an MLE of θ, then 
 is an MLE of g (θ).
In most practical situations, the maximum likelihood estimator converges toward the true value
of the parameter as the number of samples tends toward infinity. More precisely, under very
general conditions, it can be shown that:
where
This result is fundamental, showing that maximum likelihood estimators are asymptotically
unbiased and asymptotically efficient in that their asymptotic covariance matrix is the limit of
the Cramer-Rao bound, expression (2.30), normalized by N.
This is the reason why this estimator is generally preferred, even when the problem (2.80) can
only be solved using a computational approach. Note, however, that the maximum likelihood
approach can fail: an example is shown in exercise 2.14.
MLE of the i.i.d. Gaussian model
Consider a series of N observations {i.i.d. N (N; m, C)} where m is a vector of dimension d
and C is a square matrix of dimension d, taken to be strictly positive. C is therefore invertible

(2.83)
(2.84)
(2.86)
(2.87)
(2.85)
with det {C} ≠ 0. The log-likelihood is written:
where 
.
Maximization of ℓ with respect to m is carried out by canceling the gradient of ℓ:
Hence, assuming C is of full rank, we have:
Let:
Inserting 
 and  into ℓ, using the identity υTAυ = trace {AυυT} and the linearity of the
trace, we obtain the log-likelihood as a function of C:
We now need to maximize 
 with respect to C. To do this, note that the trace and the
determinant (for matrices of ad hoc dimensions) verify:
trace {AB} = trace {BA} and det {AB} = det {BA} = det {A} det {B} Let:
S is positive and can therefore be diagonalized. Carrying (2.85) into (2.84), we obtain,
successively:
Let λs be the eigenvalues of S. Expression (2.86) may be rewritten:
Canceling the derivative with respect to λs we obtain λs = 1 and thus S = Id which is clearly a

(2.88)
(2.89)
(2.90)
positive matrix. Using S = Id in expression (2.85), we deduce that the matrix C which
maximizes the likelihood is, in fact, the matrix . In conclusion, the maximum likelihood
estimators of the i.i.d. Gaussian model are:
The maximum is expressed as:
In the specific case where d = 1, we obtain:
Example 2.9 (Poisson distribution) Consider N observations, i.i.d., with values in  and a
Poisson distribution:
where λ  
+. Determine an MLE for λ.
Hints: The log-likelihood is written:
Canceling the derivative with respect to λ, we obtain 
.
Exercise 2.13 (Γ(k, λ) distribution) (see page 253) Consider N observations Xn, i.i.d. with
1. distribution Γ(1, λ) of density 
. Determine the expression of
the MLE of λ. Carry out a simulation. Compare the obtained dispersions to the Cramer-Rao
bound, expression (2.82);
2. distribution Γ(k, λ); the expression of the distribution is given in (2.72). Determine the
expression of the MLE of θ = (k, λ).
Exercise 2.14 (Singularity in the MLE approach) (see page 255) Consider N observations,

i.i.d., with values in , with the probability distribution:
where θ = (m1, m2, σ1, σ2)  Θ =  ×  × 
+ × 
+. Show that the likelihood ℓ (θ) may tend
toward infinity. More precisely, for any A > 0, it exists θ  Θ such that ℓ (θ) ≥ A.
Exercise 2.15 (Parameters of a homogeneous Markov chain) (see page 255) Consider a
series of N Markovian r.v.s X1, …, XN with values in the finite set S = {1, …, S}, with an
initial distribution  {X1 = s} = αs ≥ 0 and a transition law:
Hence, 
 and for any 
. For ease of calculation, the
following notation may be used:
where xn belong to S.
Note (this may be verified by identification) that, if the function g (x) = 
, then
for any function f:
1. Determine the expression of the likelihood of the series of observations X1, …, Xn as a
function of ps|s′ and αs.
2. Use this result to deduce a maximum likelihood estimator for ps |s'.
3. Write a program creating a series of N Markov r.v.s with values in {1, …, S} for a
transition law P (drawn at random) and for an initial distribution α (drawn at random), then
estimate the matrix P.
Logistic regression
Consider a series of N observations (Xn, Yn), taken to be i.i.d. Variable Xn  X is said to be
explanatory and variable Yn  y is said to be the explained or response variable.
Variables Xn and Yn may be quantitative, categorical (qualitative) with no notion of order, or
ordered categorical. Unordered categorical values include, for example, gender (man, woman)
or place of residence. Ordered categorical values include size (very tall, tall, small, very

(2.91)
(2.92)
(2.93)
(2.94)
small) or product satisfaction (good, bad, no opinion). In the case where response Yn is
quantitative, we speak of regression. When Yn is qualitative without order, we speak of
classification.
Finally, when Yn is qualitative and ordered, we speak of ranking.
In this section, we consider that the value of the explanatory variable falls within X = 
p and
that the categorical response has values within Y = {0,1}. Logistic regression consists of
modeling the probability of response Yn, conditionally to the explanatory variable Xn, in the
following manner:
where β0   and β  
p.
Writing the log-likelihood of N observations, assumed to be independent, we obtain 
. Assuming that the marginal distribution of X does
not depend on β, the log-likelihood may be written, to within an additive constant (which does
not depend on β):
where α = [β0 β ]T and 
.
The search for a maximum likelihood estimator is a non-linear maximization problem. It may
be numerically solved, for example using the Newton-Raphson method.
The Newton-Raphson algorithm is an iterative algorithm which aims to minimize a function ℓ
(α) with values in . Let αp be the value calculated in step p. Thus the value at step p + 1
writes:
When maximizing expression (2.92), the first and second derivatives are written:
and

(2.95)
(2.96)
This algorithm is implemented in exercise 2.16.
Whilst the logistic model is not identically distributed, property (2.81) may still be used,
where
 is the matrix of dimension N × (p + 1), for which line n has the following expression:
Thus, F (α) ≈ N−1 
. From this, we see that:
This expression allows the calculation of asymptotic confidence intervals for the components
of α, along with test statistics following the construction presented in the sub-section on page
37. These results are applied in exercise 2.16.
Exercise 2.16 (Logistic regression) (see page 257) Write a function which estimates
parameter α of the logistic model, starting from iteration (2.93) of the Newton-Raphson
algorithm.
Apply the result to the data series shown in Table 2.5 which gives the state of a joint as a
function of temperature:
1. using (2.96), calculate a confidence interval at 95% of α;
2. using (2.20), calculate the p-value of the log-GLRT of hypothesis H0 = {α2 = 0};
3. compare the two previous results.
Exercise 2.17 (GLRT for the logistic model) (see page 259) The function determined in
exercise 2.16 calculates the log-likelihood of a logistic model based on a set of observations.
It may therefore be used to determine the log-GLRT (2.19) of the hypothesis that one of the
coefficients of model (2.91) is null.
Consider the logistic model where parameter α = [0.3 0.5 1 0 0]. Write a program to verify
that the log-GLRT associated with hypothesis H0 = {α:α4 = α5= 0} follows, in accordance
with (2.20), a χ2 distribution with 2 degrees of freedom.

(2.97)
(2.98)
(2.99)
(2.100)
Table 2.5. – Temperature in degrees Fahrenheit and state of the joint: 1 signifies the existence
of a fault and 0 the absence of faults
K 53 56 57 63 66 67 67 67 68 69 70 70
S 1
1
1
0
0
0
0
0
0
0
0
1
K 70 70 72 73 75 75 75 76 78 79 80 81
S 1
1
0
0
0
1
0
0
0
0
0
0
EM algorithm
Consider an observation Y with likelihood function pY (y; θ) the maximization of which is
intractable. On the other hand we assume that a joint probability law pX, Y (x, y; θ) exists such
that:
In this context, the pair (X, Y) is known as complete data and X as incomplete data. Because
log pX, Y (x, y; θ) cannot be maximized directly, since X has not been observed, the idea
consists to maximize the conditional expectation 
 which is, by definition,
a function of Y and is therefore observable. The EM (Expectation-Maximization) algorithm is
used to solve this problem. Each iteration involves the two following steps:
Expectation
Maximization
where θ(p) denotes the estimated value of the parameter at the p-th iteration of the algorithm.
This two step process is repeated until convergence. Because the EM algorithm is only able to
reach a local maximum, the choice of the initial value of θ is crucial. It is commonly advised to
choose random starting points and keep the value giving the highest maximized likelihood.
The following property is fundamental:
Property 2.3 For each iteration of the EM algorithm, the likelihood of the observations
increases; this is written:
Indeed, if θ is such that 
, then using Bayes’ rule, 
, we have:

(2.101)
(2.102)
Making use of the concavity of the log function and the Jensen inequality, we obtain
Carrying this result in (2.100) shows that:
Therefore choosing θ such that 
 leads to the expression (2.99).
From the demonstration, we also see that the likelihood of the observations increases as long
as Q (θ, θ(p)) increases. It is not necessary to take the maximum of Q (θ,θ(p)) as it is expressed
in (2.98). In this case, the algorithm is known as the Generalized Expectation Maximization
(GEM) algorithm.
Two examples of applications of the EM algorithm are shown below, the first for mixture
model, and the other for model with censured data.
Mixture model
Consider a series of N observations, i.i.d., with a probability density written
where, for example
The parameter for estimation is therefore θ = (m1, σ1, α1,…, mK, σK, αK) with Σkαk = 1 and
where σk  
+. This model is known as the Gaussian Mixture Model (GMM). It is used in a
variety of fields, particularly speaker recognition and population mixing. A distribution of this
type is shown in Figure 2.6. There are three discernible “states” or “modes”: one around a
value of 1, the second around 5 and the third around 8. In certain cases, there is a clear
explanation for the presence of these “modes”. For example, using a problem concerning the
size of adult individuals, if two modes occur, these will clearly correspond to the male and
female populations.

(2.103)
(2.104)
Figure 2.6 – Multimodal distribution
From (2.101), the analytical expression of maximum likelihood is given by:
Unfortunately, in this case, the calculation is intractable. This leads us to use the EM algorithm,
which consists of an iterative search process for local maximums of the likelihood function log
pY1,…,YN (y1,…,yn; θ).
Consider a series of random variables Sn, i.i.d., with values in {1,…, K} and such that {Sn =
k} = αk. We note:
We then verify that 
, which is expression (2.101) of the
mixture model. We may therefore consider the pair (Sn,Yn) as complete data. Taking the
logarithm of the complete law (2.104), we obtain:
We shall now determine the expression of the auxiliary function Q. Note that as the pairs
(Sn,Yn) are independent, the conditional expectation of Sn conditionally to Y1:n is only
dependent on Yn. Using the expression of fk given by (2.102) and taking 
, we obtain:
The expression of 
 is obtained using Bayes’ rule:

(2.105)
(2.106)
We must therefore simply calculate 
 then normalize using
In what follows, we shall use:
which verifies, for any n, 
 and thus 
.
We may now determine the value of the parameter which maximizes function Q (θ, θp)),
canceling the derivatives with respect to θ.
For a maximization with respect to α, we consider the Lagrange multiplier η, associated to the
constraint Σkαk = 1. Canceling the derivative with respect to αk of the Lagrangian:
we obtain:
hence, after normalization:
Placing this value into function Q, we obtain the function Q. Canceling the derivative of Q with
respect to mk we have:
then, canceling the derivative with respect to vk, we obtain:
Finally, note that, following expression (2.105), the log-likelihood of the observations for each

(2.107)
iteration is written:
It is important to verify that ℓ(p) increases with each iteration of the EM algorithm.
The previous algorithm may be easily generalized to cases with a mixture of K Gaussians of
dimension d, with respective means m1, …, mK and covariancesC1,…,CK. We note:
The algorithm is written:
Remarks:
— initialization may be carried out either at random or using a rough estimation, for example
obtained by dividing the data into K blocks and calculating the empirical means and
covariances for each block;
— the stopping condition may concern the relative increase of 
 in the form
and/or a maximum number of iterations;
— the EM algorithm is similar to the K-means algorithm [11].

(2.108)
Exercise 2.18 (GMM) (see page 260) Write:
– a function which creates N data points of a mixture of K Gaussians with means and
variances mk, 
, with proportions αk,
– a function which estimates the parameters of a GMM using the EM algorithm. Initialize
this function by dividing ordered observations into K groups and estimating the mean and
the variance for each group.
– a program to test the EM algorithm.
Exercise 2.19 (Estimation of states of a GMM) (see page 262) Consider the mixture model
used in exercise 2.18. We presume that the parameters of the model have been estimated, for
example using the program written in exercise 2.18.
1. Using equation (2.106), propose an estimator of state S.
2. Write a program which estimates the state of a series of observations and compares this
state with the true value of obtained data. Begin by applying a learning process for θ using
a sample of 10000 values.
Censored data model
In this section, we shall consider the distribution of survival times of patients receiving
treatment. The survival period for each patient is collected at a given moment. There are two
possibilities: either the patient is deceased and the survival period is therefore known, or the
patient is still living, in which case we know only that the survival period is greater than the
observed treatment time. Observations of this type are said to be right-censored.
In more general terms, samples are either the values taken by the r.v. over different outcomes,
or an interval which the outcome value belongs to.
More precisely, consider a series of N random variables {Xn}, scalar and independent, with a
probability density noted pX (x; θ) and a cumulative function FX (x; θ).
Take the pair (yn, cn) where, when cn = 0, the realization of the r.v. Xn is yn and, when cn = 1,
we only know that Xn is greater than yn, i.e. Xn  (yn, + ∞). Note that, when cn = 0, the
likelihood of the observation may be calculated, i.e. pX (yn; θ); however, when cn = 1, this is
no longer possible, and we only know that Xn  (yn, + ∞), which has a probability of (1 − FX
(yn; θ)). An approach similar to the maximum likelihood method consists of maximizing the
following expression:
Other forms of censoring model exist, for example the clipping mechanism, where, when cn =
1, then Xn has a known value a.
Generally speaking, it is impossible to maximize expression (2.108); this leads us to use the

(2.109)
EM algorithm. To do this, we consider that the full model is the survival value Xn, and thus:
where the Xn are complete data points and Yn are incomplete data points. Using the
independence hypothesis, we obtain:
− when cn = 0, as Xn = yn, the conditional expectation of log pX (Xn; θ) conditionally to Yn
is, based on the definition of conditional expectation itself, equal to log pX (yn; θ),
− when cn = 1, the conditional expectation of pX (Xn; θ) conditionally to the fact that Xn >
yn is written:
where
Applying Bayes’ rule, we obtain:
Consequently, applying a derivation with respect to x, we obtain the density of Xn
conditionally to Xn > yn, giving:
Finally, using the fact that for any function h (x) independent of y:
we obtain, using h (x) = logpX (x; θ) (NB: we use θ and not θ′), the result set out in (2.109).
Finally, we have:

(2.110)
In cases where the cancellation of the derivative with respect to θ is hard to express, we may
choose to use the GEM algorithm instead of the EM algorithm; this consists of calculating an
increase in function Q. This may be done using a number of steps from the gradient algorithm.
The method of moments may be used for initialization (see section 2.3.4).
Exercise 2.20 (MLE on censored data) (see page 264) This exercise considers an unusual
case where the recurrence of the EM algorithm has an analytical solution. We suppose that,
following medical treatment, patient survival times Xn follow an exponential distribution of
parameter θ, i.e. 
 
 and thus log p (x; θ) = log θ − θx. During the
evaluation process, certain survival times are censored as the patients are still living at the
moment of evaluation.
1. Using expression (2.110), determine function Q (θ,θ ′).
2. Determine the recurrence over θ associated with the EM algorithm.
3. Carry out a simulation to compare the estimator obtained in the previous question with an
estimation leaving aside the indication of censored data and an estimation which only uses
uncensored data, using results from exercise 2.13, question 1.
4. Table 2.6 shows the survival period and state of patients for a given treatment. Write a
program to estimate θ.
Table 2.6. – Survival period Y in number of months and state c of the patient. A value of c = 1
indicates that the patient is still living, hence their survival period is greater than value Y. A
value of c = 0 indicates that the patient is deceased
Y 1 30 7 4 8 5
10 2 9 36 3 9
c 0 1
0 0 0 0
1
0 0 1
0 0
Y 3 35 8 1 5 11 56 2 3 15 1 10
c 0 1
0 0 0 1
0
0 0 1
0 1
2.3.6 Estimating a distribution
This section provides a simplified discussion of non-parametric estimations of probability
densities and cumulative functions. We shall not consider kernel-based methods, which are
essential when searching for a consistent estimation of probability density. The probability
density estimation problem is similar to the estimation of spectral density, presented in section
4.3. The variance of an estimator may be reduced by carrying out smoothing using a kernel
function.
Estimating probability density from a histogram

Consider a sample of N r.v.s X1, …, Xn, taken to be i.i.d. The distribution is taken to have a
density noted p (x). The approach used here to estimate p (x) is very similar to that used in
section 2.2.3 for goodness tests, and the same notation will be used. Note that the range of
observed values is divided into g intervals; this is equivalent to applying a rectangular
smoothing kernel to the data.
The total observation interval is split into g intervals ∆j of respective length ℓ (∆j). We can
therefore write:
Based on the empirical distribution, we obtain an estimator of {Xn  ∆j} which is written:
For a more detailed definition of the empirical distribution, see section 2.3.7, page 79.
Equalizing the last two expressions, we obtain an estimator for p (cj) written:
Exercise 2.7 shows that the asymptotic distribution of a vector , with g components 
,
converges in law toward vector P, with g components of values  {Xn  ∆j}:
where C = diag (P) − PPT. Hence:
where γj = Cjj/ℓ2(∆j). This expression allows us to calculate the confidence intervals of p (cj)
of the form:
where α is given by 
. In practice, γj is replaced by an estimate obtained
from .
The following program provides an example:

(2.111)
(2.112)
Estimation of the cumulative function
Consider a sample of N i.i.d. r.v.s X1, …, XN. The cumulative function is noted F (x). In cases
where the distribution has a probability density, this is the integral of the density. There are
thus two possible approaches: (i) estimate F (x) = {Xn ≤ x} from the empirical law, or (ii)
estimate the probability density using the method proposed in section 2.3.6 and carry out a
cumulative sum.
The empirical distribution method consists of assigning a probability of 1/N to each observed
value. The empirical distribution of the cumulative function is therefore expressed:
Taking {X(n)} to be the series of values arranged in increasing order, known as the order
statistic, 
 may be written:
 is therefore a stepwise function, with steps equal to 1/N and located in the ordered value
series. From this, we deduce the algorithm for performing 
: (i) ordering the values in
ascending order and (ii) assign a step 1/N to the ordered values.
Figure 2.7 – Step equal to 1/N for the five values of the series, ranked in increasing order
Following (2.111), 
 appears as the mean of the sequence of i.i.d. r.v.s 
.
Noting that 
 and that var(Y1) = F (x)(1 − F (x)), the central limit theorem is written:

(2.113)
(2.114)
where γ = F (x)(1 - F (x)). Hence, an approximate confidence interval at 95% may be obtained
using:
In the following program, we consider two cases, depending on whether a sample of size N
follows a multinomial distribution (select='M') or a Gaussian distribution (select='G').
Exercise 2.21 (Estimation of a quantile) (see page 265) Consider an r.v. with a cumulative
function noted F (x). The quantile at 100c % associated with F (x) is defined by:
The notion of a quantile may be interpreted as the inverse function of (1 − F (x)). The quantile
situated at 50% is the median.
1. Use definition (2.114) to deduce an estimator  of s.
2. Applying the δ-method (see section 1.5.2) to the expression (2.113), deduce the asymptotic
distribution of 
:
3. Use this result to deduce an approximate confidence interval at 95%.
4. Write a program which verifies these results.
Exercise 2.22 illustrates the estimation of the cumulative function in the context of image
processing.

(2.115)
Exercise 2.22 (Image equalization) (see page 266) Image equalization in grayscale consists
of transforming the value of pixels so that the pixel value distribution of the transformed image
is uniform. In section 3.3.1, we saw that the application of function F (x) to an r.v. of
cumulative function F (x) gives an r.v with a uniform distribution over (0,1). This result can be
applied in equalizing images. To do this, we begin by estimating the cumulative function of the
original image, then we apply the estimated distribution to the image.
Consider a grayscale image where the value In, m of pixel (n, m) is modeled as an r.v. with
values in the set 
. Let ps be the probability that a pixel will be equal to s,
and F (x) the cumulative function. This is a piecewise linear function with steps located in 
of height 
 (see Figure 2.7). Thus, to estimate the cumulative function of the image,
we estimate the probability ps using the empirical law, written, for s from 0 to S − 1:
This gives us an estimate of the cumulative function:
Write a program to equalize levels of gray in an image. Verify the result by estimating the
cumulative function of the transformed image. Note that the cumulative function of the uniform
distribution over (0,1) is written F (x) = 
2.3.7 Bootstrap and others
In this section, we shall give a brief introduction to non-parametric estimation of estimator
variance. In practice, three approaches are generally used: the bootstrap approach, the
jackknife approach, and cross-validation. In all cases, once the variance has been estimated
and based on the assumption of Gaussian behavior, it becomes possible to estimate a
confidence interval.
Before considering the way in which estimator variance is determined, let us define the
empirical distribution and expectation.
Definition 2.10 (Empirical distribution) Consider a series of N observations X1,..., Xn, taken
to be i.i.d. and with values in 
, with a Borel set 
. The empirical distribution
associated with observations X1,..., Xn is the probability distribution defined over 
,
which associates each Borelian 
 with the probability:
In short, each observation has an assigned probability of 1/N. Moreover, based on the
hypothesis that the Xn are i.i.d., the empirical distribution of the sequence X1, …, Xn can be

(2.116)
taken to be the product of the identical empirical laws, written:
where 
 are N Borelians in 
.
Note that, strictly speaking, the empirical distribution is random due to the use of series Xn:
each outcome ω is associated with a realization of the series X1, ..., XN, and thus with a
realization of the empirical distribution.
The empirical expectation is obtained from the empirical law:
Definition 2.11 (Empirical expectation) Consider a series of N observations X1, …, XN,
taken to be i.i.d. with values in 
 and a Borel set 
. The empirical distribution of this
series is noted 
. The empirical expectation of the function g (X1, …, XN) with values in 
 is the vector:
Using (2.116), it is easy to show that:
Note that this is equivalent to assigning a probability of 1/NN to all of the N-uplets constructed,
with duplication, using these observations. In the specific case where 
, we have:
In the specific case where g (X1, …, XN) = g (X1), we have:
Now, consider a series of N observations, i.i.d., of unknown distribution, and let θ be the
parameter of interest and 
 an estimator of θ. To estimate the variance of 
,
expression (2.116) could be applied to calculate the first two moments of 
;
however, this calculation is often impossible, even for simple estimators. Note that, in general,
NN terms are involved (a very large number of terms for N = 100, for example). This leads us
to consider a Monte-Carlo type approach, which consists of carrying out a draw from these NN
possible cases; the bootstrap approach, introduced by B. Efron [7], may be seen in this way.
Bootstrap

(2.117)
Consider a series of observations X1, …, XN, and a parameter of interest θ of dimension p. The
bootstrap technique consists of carrying out B random draws, with replacement, of N samples
from the set of observations. B is always very small compared to NN, typically, B = 300. The
samples of the b-th drawing are noted 
, and the associated estimation value is
noted 
. For simplicity’s sake, we note 
. The
bootstrap technique may then be used to obtain the empirical covariance:
Note that the term (B − 1) in (2.117) leads to the creation of an unbiased estimator of the
covariance matrix.
Example 2.10 Consider a series of N Gaussian r.v.s of mean µ and variance 1, and consider
the estimation of the mean 
. Create a program comparing the variance via
the bootstrap technique and the theoretical variance of , with a value of 1/N, over L
simulations.
Hints: Type:
Exercise 2.23 (Bootstrap for a regression model) (see page 267) Consider a series of N
observations of the linear model:
where
and where  is a centered Gaussian vector with covariance I N. Remember that, according to

(2.119)
(2.120)
(2.121)
(2.118)
property 2.1, the covariance matrix of 
 is expressed as(ZTZ)−1 Write a
program comparing the covariance obtained using the bootstrap technique and the theoretical
covariance over L simulations.
Jackknife
The Jackknife - multi-usage - technique was introduced by M. H. Quenouille [23, 17] to reduce
the bias of an estimator. J. W. Tukey [28] extended the technique for estimating estimator
variance.
The fundamental idea involves calculating  several times, removing a sample each time. More
precisely, if X(j) denotes the series of observations from which sample Xj is removed, we
obtain the N following values:
From this, we obtain the empirical covariance by jackknife associated with the estimator :
Cross-validation
Cross-validation may be seen as a generalization of the jackknife approach. Instead of
removing a single value (Leave One Out, LOO) we remove several values. Typically, a series
of observations is divided into K blocks of the same length, and each of the K blocks is used
successively as a test database, with the remaining (K −1) blocks acting as a learning base. Let
block k be our test data. Over the remaining (K − 1) blocks, we estimate θ, obtaining a value
of 
. We then calculate the error for the test data using a parameter value of 
. We then
calculate an average over the K blocks, see Figure 2.8.
Without losing generality, we may suppose that N = LK, where L is the size of a block. The
block of test data k is noted 
 and the remaining data is noted 
 The covariance
of the estimator 
 is written:
Figure 2.8 – Cross-validation: a block is selected as the test base, for example block no. 4
in this illustration, and the remaining blocks are used as a learning base, before switching
over.

Consider an example using the linear model:
where  is a centered random vector of covariance I N and matrix Z, of dimension N × r with
r < N, is taken to be full column rank. The series is divided into L blocks of K data points.
Using (L − 1) blocks for learning and one block for testing, we calculate the prediction
variance using expression (2.59). We then use each block in turn for testing purposes and
calculate the mean.
This approach may be used to estimate the order of the model. If we add columns to Z, the
projection theorem guarantees that the average prediction error for the learning data can only
decrease or, at worst, remain constant if the additional vector is contained in the space created
by the columns of Z. In simple terms, the more columns are added, the easier it is to “explain”
the noise 
 However, the more columns are added, the more the error over the test data will
increase; this is illustrated in exercise 2.24.
Exercise 2.24 (Model estimation by cross-validation) (see page 268) Write a program:
— which produces N = 3000 data points following a linear model of the form y = Zθ + σ
, where Z is a matrix, which may be created using the function randn including p = 10
columns (regressors). It is best to create a matrix X with N lines and 20 columns and to
extract the first 10 columns in order to obtain matrix Z. Use σ = 2;
— which applies a cross validation of order K = 10;
— which varies the number  of regressors, taken to be from 1 to 20;
— which calculates the prediction errors over the learning base and over the test base as a
function of p;
— which displays the error curves as a function of p.
Notes
1 Take two positive square matrices A and B of the same dimension d. We say that A ≥ B if, and
only if, A − B ≥ 0, i.e. for any w  
d we have wH Aw ≥ wH Bw.
2 The observation function defined by (2.62) is not a statistic, as it depends on the unknown
parameter ß. The function is said to be pivotal.

Chapter 3
Monte-Carlo Simulation
3.1 Fundamental theorems
As we saw in section 1.6, theorems 1.9 and 1.10 form the basis for statistical methods, and are
crucial to the validity of Monte-Carlo methods. These theorems set out the way in which
empirical means converge toward statistical moments. Noting that a statistical moment is
defined as the integral of a certain function, this statement says, in some ways, that you can
approximate this integral using a mean based on a random (or pseudo-random) sequence. Using
these two theorems, we see that the convergence as a function of the number N of samples is of
the order of N−1/ 2.
It is therefore interesting to compare the value N−1/ 2 to those obtained using deterministic
numerical methods, such as the trapezoid method or Simpson’s method. Figure 3.1 illustrates
the calculation of the volume of a unit sphere using a direct method (Id) and the Monte-Carlo
method (IMC) as a function of sample size.
The deterministic method can be seen to have a convergence speed of the order of N−2/d, where
d is the dimension of the space over which the function to integrate is defined. Consequently,
when the dimension increases, the speed decreases. On the other hand, Monte-Carlo methods
present two advantages compared to deterministic methods: (i) the convergence speed does not
depend on the dimension d and (ii) their use does not depend on the regularity of the function
being integrated.
In a less formal manner, the trapezoidal method can be seen as using a grid with a large number
of points, many of which have a negligible effect on the calculated value of the integral;
following the Monte-Carlo method, only the significant values are used. There is, however,
one major drawback, in that the numerical result depends on the realization: the error is
therefore random.

(3.1)
(3.2)
Figure 3.1 – Direct calculation (circles) and calculation using a Monte-Carlo method
(crosses), showing that the Monte-Carlo method presents faster convergence in terms of
sample size. The error εMC represented in the lower diagram is random in nature. In the
case of direct calculation, the error is monotone and decreasing
3.2 Stating the problem
The aim of Monte-Carlo methods is to calculate an integral using a random generator rather
than a deterministic value set. The term Monte-Carlo refers to the role of chance in games
played in the world-famous casino in Monaco. Let us consider an integral over , which is
written:
If the integral is defined over 
, it may be written using the indicative function of  in
the form:
where 
 and where 
 has a value of 1 if x   and 0 in all other cases. It
therefore takes the form of expression (3.1).
In many applications, the integral for calculation is associated with the mathematical
expectation of a function f, i.e. an integral of the form:
where pX (x) is the density of a probability distribution. Sometimes, the function to integrate
does not have an explicit form, and can only be calculated using an algorithm.

(3.3)
The central idea behind the Monte-Carlo method is to use a random generator, with a
distribution characterized by a probability density µ, then to use the law of large numbers to
calculate the integral. We may write
where h (x) = g (x)/µ (x). If we have a realization of N random variables X1…, XN,
independent and identically distributed following distribution µ, we may write:
More precisely, the law of large numbers states that
where the convergence is in probability. Note that, when the integral I (g) is associated with a
mathematical expectation as in expression (3.2), it is not, a priori, necessary to draw the
sample using the distribution pX (x) As we shall see, the choice of a different distribution can
even lead to a better approximation in these cases.
Note that a real random variable is a measurable function from a sample space Ω into ,
written X: ω  Ω 
 x  . Each outcome (or experiment) is associated with a real value x
known as the realization. In the context of a statistical simulation, stating that N independent
draws will be used signifies that N distinct random variables X1…, XN will be considered, and
that for each outcome ω  Ω, we obtain N realizations x1…,xN, and not N realizations of a
single random variable! In more general terms, we consider an infinite series of random
variables, i.e. a family {Xn} of r.v. indexed by . The practical applications of statistical
methods are thus essentially linked to the properties obtained when N tends toward infinity.
These properties are often easier to establish when the random variables in the series are taken
to be independent.
This approach is easily extended to the integral of a function defined over 
d and with values
in . Let g: (x1,...,xd) 
d 
  be a function of this type, and consider the integral
To calculate an approximate value for I (g), we carry out N independent random drawings, for
which the probability distribution defined over 
d has a probability density µ (x1, …, xd) and
we write:

(3.4)
where h (x1,..,xd) = g (x1,…,xd)/µ (x1,…,xd).
Two types of problems should be considered when using the Monte-Carlo method to calculate
an integral:
1. how to determine the “optimum” way of choosing the drawing distribution µ in order to
calculate a given interval;
2. how to create samples following a given distribution.
We shall begin by considering the second problem, the generation of random variables. In this
context, we shall begin by presenting distribution transformation methods, followed by
sequential methods based on Markov chains. We shall then consider the first issue in a section
on variance reduction.
Before that, a bit of history. The first method for calculating integrals using a Monte-Carlo type
technique was proposed by N. Metropolis in 1947, in the context of a statistical physics
problem In 1970, K. Hastings published an article establishing the underlying principle for
general random variable generation methods, known as the Metropolis-Hastings sampler and
based on Markov chains; in this context, we speak of MCMC, Monte-Carlo Markov Chains. In
1984, S. Geman and D. Geman proposed the “Gibbs” sampler, a specific form of the
Metropolis-Hastings sampler, used by the authors in the context of image restoration.
3.3 Generating random variables
In this section, we shall consider that we have access to a generator using uniform distribution
over the interval (0,1), able to supply a given number of independent draws. Without going into
detail, note that a variety of algorithms propose generators of this type. One example, which is
no longer particularly widespread, is the Mersenne Twister algorithm (MT) based on the
Mersenne prime 19937 [14]. MATLAB® uses a variant, named MT19937ar (“ar” stands for
ARray). This variant has a period of 219937 — 1 of the order of 106600 (a period of the order of
10170 would be sufficient for the majority of simulations). Calculated using 32-bit integers, it
produces values which are uniformly distributed across the hypercube (0, 1)d with d > 600. A
64-bit version of this algorithm is also available in MATLAB®.
We shall now consider the generation of sequences following a given probability distribution,
starting with a generator giving a uniform distribution over (0,1).
3.3.1 The cumulative function inversion method
Taking a real valued random variable, with a cumulative function F (x), this method is based
on the following result. Letting
the inverse of the cumulative function F, the random variable X = F (−1)(U) follows a
distribution with the cumulative function F if, and only if, U is a random variable which is

uniformly distributed over the interval (0,1).
Firstly, note that, by definition, the cumulative function of a real r.v. is the probability that it
belongs to the interval (−∞, x ]. A cumulative function is a monotone increasing function which
may contain jumps and may be constant over certain intervals. A typical form is shown in
Figure 3.2.
Take Y = F (X). Using the fact that F (x) is monotone, we may write, successively:
Finally, denoting F (x) = y, we have 
 which is, by definition, the
cumulative function of the uniform law.
Example 3.1 (Rayleigh law) A probability distribution is said to follow the Rayleigh law if it
has a density expressed as:
where σ2 > 0. From this, we may deduce the cumulative function and its inverse:
Write a program to create a sequence of length N following a Rayleigh law with parameter σ =
1. Compare the histogram obtained in this way with the theoretical probability density.
Figure 3.2 – Typical form of a cumulative function. We choose a value in a uniform manner
between 0 and 1, then deduce the realization t = F(−1)(u)
HINTS: Type the program:

Exercise 3.1 (Multinomial law) (see page 269) A multinomial random variable is a random
variable with values in  = {a1,…,aP} such that  {X = ai} = µi, where µi ≥ 0 and 
.
The associated cumulative function is written:
and the inverse is written:
Write a program which creates a sequence of length N following a multinomial law with
values in {1, 2,3, 4, 5}, for which the probabilities are 0.1, 0.2, 0.3, 0.2, and 0.2 respectively.
Exercise 3.2 (Homogeneous Markov chain) (see page 269) Consider a sequence {Xn} where
n   and which has values in the finite discrete set  = {1,…, K}. By definition (for more
details, see the section page 96) a sequence {Xn} is said to be a Markov chain if {Xn +1 =
xn+1| {Xs = xs,s ≤ n}} coincides with {Xn +1 = xn +1|Xn = xn}. The chain is said to be
homogeneous if, in addition, the transition probabilities {Xn +1 = xn +1| Xn = xn} do not
depend on n.
Consider a Markov chain with K = 3 states, the initial distribution and the transition
distribution of which are shown in Table 3.1.
{X o = 1} = 0.5
{X o = 2} = 0.2
{X o = 3} = 0.3

(3.5)
Table 3.1. – The initial probabilities {X0 = i} and the transition probabilities  {Xn +1=j
|Xn=i} of a three-state homogeneous Markov chain. We verify that, for all i, 
Pij
i = 1 i =2 i =3
j =l 0.3
0
0.7
j =2 0.1
0.4 0.5
j =3 0.4
0.2 0.4
Write a program to create a sequence of N values from this Markov chain. Hint: exercise 3.1
may be used. Check that the estimated transition probabilities correspond to those given in
Table 3.1.
3.3.2 The variable transformation method
Linear transformation
Let X be a linear vector, the probability distribution of which has a density of pX (x). The
random vector Y = AX + B, where A is a square matrix taken to be invertible and B is a vector
of ad hoc dimension, follows a probability distribution of density
Thus, to simulate a random vector with a vector mean M and covariance matrix C, we must
simply apply:
where W is a random vector of vector mean 0 and covariance matrix I and where A is a square
root of C. Remember that if W is Gaussian, then X will also be Gaussian.
Exercise 3.3 (2D Gaussian) (see page 270) Write a program:
1. which uses a centered Gaussian generator of variance 1 to generate a sequence of length N
of a centered Gaussian random variable, of dimension 2, with the following covariance
matrix:
2. which displays the obtained points and the principal directions associated with the
covariance matrix in the plane.
The non-linear case
If X follows a distribution of density pX (x) and if f is a derivable monotone function, then the
random variable Y = f (X) follows a distribution of density:

where f(− 1)(y) denotes the inverse function of f, and f ′ its derivative. This result can be
extended to a bijective transformation for variables with multiple dimensions, replacing the
derivative by the determinant of the Jacobian. The example shown below concerns a function
with two variables.
Example 3.2 (Distribution of the modulus of a Gaussian vector)
Consider two independent, centered Gaussian random variables (X, Y) of the same variance σ2.
We are concerned with the bijective variable substitution (r, θ) 
 (x, y) defined by:
As this substitution is bijective and its Jacobian is equal to r, which is positive, the joint
distribution of the pair (R, Θ) has a density of:
Exercise 3.4 (Box-Muller method) (see page 270) Using the results of example 3.2,
determine an algorithm to create two centered, Gaussian random variables, of the same
variance σ2, from two independent uniform random variables in (0,1). Create a program which
uses this algorithm, which is known as the Box-Muller algorithm.
Exercise 3.5 (The Cauchy distribution) (see page 271) A Cauchy random variable may be
obtained in two ways:
1. consider a random variable U which is uniform over (0,1). Note Z = z0 + a tan(π (U −
1/ 2)). Determine the distribution of Z. 
The distribution of Z is a Cauchy distribution of parameters (a, z0) and is noted (z0, a). It
has no moment;
2. consider two centered, independent Gaussian variables X and Y of variance 1. We then
construct Z = z0 + aY/X where a > 0;
3. write a program which creates a sample following the Cauchy distribution of parameters
a = 0.8 and z0 = 10, using both methods. Compare the obtained histograms to the
probability density of the Cauchy distribution.
Sequence of correlated variables
It may be useful to produce a sequence of correlated random variables. ARMA(P, Q)
processes see [2], are a key example. They are defined by the following recurrence equation:

where Wn is a centered white noise of variance σ2 and where all of the roots of the polynomial
are strictly within the unit circle. We know that the spectral density is expressed as:
In theory, it is easy to determine the series of covariances using S (f), but the calculation itself
can prove difficult.
3.3.3 Acceptance-rejection method
In the acceptance-rejection method, we use an auxiliary distribution q (x) which is known to
be “easy” to create in order to construct samples with a distribution p (x) considered
“difficult”. Moreover, we consider that a value M exists such that, for any x, Mq (x) ≥ p (x)
(see Figure 3.3). We use the following algorithm:
– draw a random variable X for which the distribution has a density of q;
– independently, draw a uniform random variable U with values in (0,1);
– if UMq (X) ≤ p (X), apply Y = X, otherwise reject the result.
Figure 3.3 – The greater the value of M, the more samples need to be drawn before
accepting a value. The value chosen for M will therefore be the smallest possible value such
that, for any x, Mq (x) ≥ p (x). The curve noted MUq (x) in the figure corresponds to a draw
of the r.v. U from the interval 0 to 1. For this draw, the only accepted values of Y are those
for which p (x) ≥ MUq (x)
The distribution of Y can be shown to have a probability density p. Let Z be the random
variable which takes a value of 0 if the draw is rejected and a value of 1 otherwise. The
probability that Z = 1 is written:

Taking into account the fact that U and X are independent, we can write:
To obtain this equation, we begin by integrating with respect to u then with respect to t. Now,
let us calculate the conditional probability:
Carrying out a derivation with respect to x, we see that the density of Y conditional on Z = 1 is
expressed as:
which concludes the proof.
This method has two main drawbacks:
– when M is large, the acceptation rate is low;
– it is not possible to predict how many draws are required to get N samples.
To illustrate, if p (x) is the Gaussian distribution 
(0, σ2) and q (x) is the Gaussian
distribution 
(0,1), then M is equal to 1/σ. If σ = 0.01 then M = 100 hence the mean
acceptance rate will be 1/ 100.
3.3.4 Sequential methods
Sequential methods implement algorithms with value distributions which converge toward the
distribution which we wish to simulate. Two of the most commonly used approaches are the
Metropolis-Hastings sampler and the Gibbs sampler. These techniques, which are both based
on the construction of a Markov chain, will be presented below. The acronym MCMC, Monte-
Carlo Markov Chain, is used to refer to both samplers.
The structure of these algorithms means that they require a burn-in period, leading to the
removal of a certain number of initial values. However, it is often difficult to evaluate this

(3.6)
(3.7)
burn-in period. We expect that, asymptotically, the random variables are identically distributed
and simultaneously approximately independent. The main interest of these methods lies in the
fact that the samples they produce may be used for high dimensional random vectors.
To begin with, let us introduce a number of Markov chain properties.
Markov chain
A Markov chain is a discrete-time random process with values in 
 and such that the
conditional distribution of Xn with respect to the algebra spanned by all past events {Xs;s < n}
coincides with the conditional distribution of Xn given only Xn−1 = x ′. The conditional
probability measure of Xn knowing Xn− 1 is denoted Qn (dx;x ′). Qn (dx;x ′) is known as the
transition law. A Markov chain is said to be homogeneous if the transition law Qn (dx;x′) does
not depend on n.
In cases where the set of possible values of Xn is finite and denoted 
 = {1,…, K}, the
transition law Q is characterized by the probabilities q (x |x ′) = {Xn = x |Xn −1=x′} for any
pair (x,x ′) 
. In this case, for any x′  
, we have:
In cases where transition law Q has a density, noted q (x |x '), we can write that, for any A 
and for any x′  
:
In this case, for any x′  
, we have:
In what follows, unless stated otherwise, we will only use the notation associated with cases
where the transition law possesses a density.
Let us determine a recurrence equation for the probability distribution of Xn. Using Bayes’ rule
pXnXn−1 (x, x ′) = pXn|Xn−1(x, x ′) pXn−1 (x ′) = q (x|x′)pXn−1(x ′), we deduce that:
A chain is said to be stationary if pXn (x) is not dependent on n. This means that a density p (x)
exists such that:
Equation (3.7) may be seen as an equation with eigenvectors p (x) for the transition kernel q (x

(3.10)
(3.8)
(3.9)
|x ′). The condition
on p (x) is sufficient to satisfy (3.7). Indeed integrating the two members of (3.8) with respect
to x ′, we obtain (3.7). Expression (3.8) is known as the detailed balance equation.
Metropolis-Hastings algorithm
We wish to carry out a draw using a distribution p (x) known as being “difficult” to produce
samples. Firstly, we select two conditional probability densities r (x |x ′) and a (x |x ′). The
draw using r (x |x ′) is taken to be “easy”. The conditional distribution a (x |x ′) is implemented
in an acceptance/rejection mechanism, and is chosen so that the following condition is
verified:
At stage n, we have xn−1 and the algorithm entails the application of the following two steps:
1. draw a sample X following the distribution r (x |xn−1);
2. independently, draw a Bernoulli variable Bn with a value in the set {0,1} and such that 
{Bn = 1} = a (X |Xn –1). B is then used in the following acceptance/rejection mechanism:
Condition (3.9) implies that p (x) verifies condition (3.8). Indeed let us denote:
The two stages of the algorithm mean that the conditional distribution of Xn given Xn−1 has a
density of q (x |x ′) = a (x |x ′)r (x |x ′) + PR (x ′) (x = x ′). We can thus write, successively,
that:
Using (3.9), we obtain (3.8). In conclusion, p (x) is the stationary distribution associated with
q (x |x ′).
In the Metropolis-Hastings algorithm, the acceptance/rejection law has the following specific
expression:
This supposes that r (x |x ′) ≠ 0 for any pair (x, x'). Expression (3.10) must be shown to verify

condition (3.9). One important property is that the target distribution p (x) only needs to be
known to within a multiplicative constant. Two specific cases may arise:
1. the chosen distribution r (x |x ′) is symmetrical, i.e. such that r (x |x ′) = r (x ′|x). The
algorithm can therefore be simplified, and is written:
(a) draw a sample X using the distribution r (x | xn-1),
(b) independently, draw a Bernoulli variable Bn with a value in the set {0,1} such that 
{Bn = 1} = p (x)/p (xn−1), on the condition that p (x) < p (xn−1). B is then used in the
following acceptance/rejection mechanism:
Put simply, if X is more likely than Xn−1, it will always be accepted;
2. the chosen distribution r (x |x ′) = r (x) is independent of x ′. In this case, the
acceptance/rejection mechanism is written:
Exercise 3.6 (Metropolis-Hastings algorithm) (see page 272) We wish to calculate I = ∫x2p
(x)dx where 
. It is worth noticing that p (x) is given up to an unknown
multiplicative factor (even if we know that this factor is 
. For r (x |x ′), we select a
uniform distribution over the interval [−5σ, 5σ ], hence r (xt−1/r (x) = 1. Write a program
implementing the Metropolis-Hastings algorithm to calculate the value of the integral I, which
has a theoretical value of σ2.
Gibbs sampler
When simulating multivariate samples, it is sometimes interesting to change single components
individually. The Gibbs sampler, a specific case of the Metropolis Hastings algorithm, fulfills
this function. Consider a distribution with a joint probability noted px1,…, xd (x1,…, xd); let us
use the Metropolis-Hastings algorithm, where the proposition law r (x |x ′) is the conditional
distribution pXk|X−k (x1,…,xd), with X-k the set of variables excluding Xk. The probability of
acceptance/rejection, given by expression (3.10), is therefore equal to 1 for each pair (x, x ′),
meaning that the sample is always accepted.
Exercise 3.7 (Gibbs sampler) (see page 272) Consider a bivariate Gaussian distribution of
mean µ = [ µ1 µ2 ]T and covariance matrix:
1. Determine the expression of the conditional distribution pX2|X1 (x1, x2).

(3.11)
(3.12)
(3.13)
(3.14)
2. Using the Gibbs sampler, write a program which simulates a bivariate Gaussian
distribution of mean (0,0) and covariance matrix C.
Gibbs sampler in a Bayesian context
The Gibbs sampler is used in a Bayesian context. Using a statistical model characterized by a
probability density pX (x;θ), we consider that θ  T is a random vector, of which the
distribution has a probability density p
 (θ). Considering pX (x; θ) as the conditional
probability of X given 
, it is possible to deduce the conditional distribution of 
 given X:
This expression can be used to generate samples of θ, given X, with the Gibbs sampler.
3.4 Variance reduction
3.4.1 Importance sampling
Consider the calculation of the following integral:
With no loss of generality, we may consider that f (x) ≥ 0. This is possible as f(x) = f+(x) − f−
(x), where f+(x) = max(f (x), 0) and f−(x) = max(−f (x),0) are both positive, and to note that, by
linearity, ∫f (x)dx = ∫f+ (x)dx − ∫ f− (x)dx − ∫ f− (x)dx
Direct application of the Monte-Carlo method consists of drawing N independent samples X1,
…, XN following distribution p (x) and approximating the integral using:
Based on the hypothesis that the N variables are independent and identically distributed, the
law of large numbers ensures that  converges in probability toward I. As the mean is 
, the estimator is unbiased. Its variance is given by:
Now, consider a situation where instead of drawing N samples following the distribution
associated with p (x), the draw is carried out using an auxiliary distribution of density µ,
known as the instrumental or proposition distribution. This technique is known as
importance sampling. The use of an auxiliary distribution may appear surprising, but, as we
shall see, improves the results of the calculation. Let us return to expression (3.12), which may

(3.15)
(3.16)
(3.17)
be rewritten:
We may now apply the previous approach to function f (x)p (x) /µ (x) and take the following
estimation of I:
where the values of function h (x) = p (x)/µ (x) for the values of x = Xn are known as
importance weights. The law of large numbers implies that  converges in probability toward
I. Using the fact that the random variables X1, … XN are independent and identically
distributed, we may deduce the mean:
meaning that the estimator is unbiased and the variance:
From (3.15), the term I2 does not depend on the choice of µ. Consider the first term 
.
Based on the Schwarz inequality, we have:
in which equality occurs if and only if µ (x)  f (x)p (x) and, by normalization,
Notably, the variance of 
 has a value of 0! However, this result is pointless, as it presumes
knowledge of ∫ f (u)p (u)du, the quantity which we wish to calculate. Nevertheless, it shows
that the “optimum” distribution needs to be as close as possible to the function being
integrated. Specifically, if f is the indicator of the interval (α, +∞), it is better to use an
auxiliary law with a large number of values greater than α; this would not be the case using a
centered Gaussian distribution of variance 1 for high values of α.
The importance sampling method may be modified by using the following quantity as the
estimator of the integral I:

(3.18)
(3.19)
(3.20)
The law of large numbers states that:
using the fact that 
. From this, we see that  tends in probability
toward I. The interest of expression (3.17) in relation to expression (3.15) may therefore be
questioned. The response to this query is that, in certain situations, we only know distribution p
to within an unknown multiplicative coefficient λ. Let the available expression be noted 
. Placing this expression into h (x), we obtain 
 then, applying the
result to (3.17), the unknown constant λ disappears: knowledge of this constant is therefore not
required.
Introducing the normalized importance weights:
expression (3.17) may be rewritten:
Note that, following expression (3.18), the ω (Xn) are positive and their sum has a value of 1.
We may therefore begin by calculating h (Xn) for all values of Xn, then calculate the values w
(Xn) by normalization.
Example 3.3 Consider a centered Gaussian random variable of variance 1. We wish to
calculate the probability that this variable will be greater than a given value α. This
probability is written:
HINTS: The direct approach consists of drawing N independent, centered Gaussian samples of
variance 1 and using the following value for the integral:
The random variables Yn have values in {0,1} with {Yn} = 
 = I. Consequently, E
{Yn} = I and var(Yn) = I (1 − I). Moreover, the independence of the variables Xn implies that
the variables Yn will also be independent. Hence,  is a random variable of mean I and
variance N−1var (Y1) = N−1I (1 − I). Applying the central limit theorem to Yn, we obtain:

(3.21)
Hence, we deduce a confidence interval of 95% of the value of I using this method:
Consider an approach using the importance sampling technique and the Cauchy distribution 
(0,1) as the proposition distribution. The integral is written:
where h (x) = 
From this, we see that 
 = I and that:
which may be compared to the variance var 
 =I (1 − I).
Numerically we can show that, for large values of α,  will be better than .
Exercise 3.8 (Direct draws and importance sampling) (see page 273) Write a program
which estimates  {X > α} when X is Gaussian, centered, of variance 1. Consider three cases.
In the first case, samples are produced following the Gaussian distribution, and in the second
following the Cauchy distribution. In the third case, samples are produced following the
Cauchy distribution, but considering that we only know that the probability density of X is
proportional to 
.
3.4.2 Stratification
Returning to the calculation of the integral:
To reduce the variance of the estimator associated with a drawing of N i.i.d. samples,
following a distribution characterized by the probability density pX (x), the stratification
method involves splitting  into “strata”, optimizing the number of points to draw in each of
these strata. As we shall see, this technique requires:
– the ability to calculate {X  A} for any segment A,
– the ability to carry out a random draw conditional on X  A.
Let A1,…, AS be a partition of  and

(3.22)
(3.23)
(3.24)
(3.25)
(3.26)
(3.27)
We deduce the conditional probability density of X given X  As:
It follows that the integral I may be rewritten:
Inserting (3.23), we obtain:
Hence the idea of carrying out independent draws from the S strata under conditional
distributions. Let 
 be the Ns variables of stratum s distributed following 
. An
approximate value of I may be obtained using:
From this result we see that 
 = I, and estimator 
 is therefore unbiased. Let us now
determine the variance. Using the hypothesis of independent drawings in the S strata, we have:
where
It is interesting to note that, in expression (3.24), the integral
is interpreted as the conditional expectation of f (X) given 
. Following property
5 of the properties 1.9, var 
 ≤ var (f (X)) and therefore var 
 where 
is given by (3.13), i.e. an approximation of I using a single stratum.

It is now possible to minimize (3.25) under the constraint 
. Canceling the
derivative of the Lagrangian 
 
, we obtain:
This solution is unusable, as it requires knowledge of σs and thus of the value of the integral I.
One solution (not ideal) is to take Ns = Nps , giving a variance
To use this method, we now need to carry out a random draw following the conditional
distribution pX|X As (x). One simple approach would be to carry out a random draw using the
distribution pX (x), then to conserve only those values situated within the interval As. The
problem with this approach is that the number of values to draw is random. This drawback
may be overcome if (i) we use the property of inversion of the cumulative function (see section
3.3.1), which uses the uniform distribution over (0,1), and if (ii) we note that for a uniform
random variable U, the conditional distribution of U given that U belongs to an interval B is
itself uniform, written pU|U B (u) = (u  B)/ℓ, where ℓ denotes the length of B.
In summary, to calculate (3.21):
– we choose S intervals (a0, a1], ]a1, a2], …, ]aS−1,aS), where a0 = − ∞ and aS = +∞;
– we calculate the S integer values
where ps = FX (as) − FX (as−1) and FX (x) denotes the cumulative function associated with pX
(x);
– we calculate [b0, b1], ]b1, b2], …, ]bS−1, bS ] where bs = FX (as) with b0 = 0 and bS = 1;
– for each value of s, we draw Ns values 
, independently and following a
uniform distribution 
;
– for each value of s, we calculate 
;
– we calculate

(3.28)
(3.29)
(3.30)
(3.31)
Exercise 3.9 (Stratification) (see page 275) In this exercise, we shall use a Monte-Carlo
method with and without stratification to compare the calculation of the following integral:
1. determine the analytical expression of I (use the characteristic function 
;
2. write a program which compares the calculation with and without stratification
3.4.3 Antithetic variates
We wish to estimate the integral:
The antithetic variates method consists of finding a pair of random variables (X, ) such that
functions f (X) and f ( ) have the same expectation, the same variance, and satisfy the
condition:
Using an i.i.d. series of random variables Xn distributed following the law px (x), we take the
following estimator of I:
Hence
Exercise 3.10 (Antithetic variates approach) (see page 276) We wish to calculate the
integral:
Integral I may be seen as the expectation, following the uniform distribution 
 of f (X) = 1/
(1 + X). Take  = 1 − X. Hence, if 
, then 
.
Let  and  be the estimators given by (3.12) and (3.30) respectively:

1. determine the values of var (f (X)); cov 
 for N =100;
2. write a program to compare the direct calculation with the antithetic variate method.

(4.1)
(4.3)
(4.2)
Chapter 4
Second Order Stationary Process
In this chapter, we shall consider second order wide sense stationary (WSS) processes. At
first, we shall begin with the estimation of the mean and covariance function, before
introducing the notion of linear prediction. We will then consider non-parametric spectral
estimation.
4.1 Statistics for empirical correlation
In this section, we shall present results relating to the estimation of the mean, of the covariance
function and of the correlation function of a WSS random process. A number of properties of
WSS processes are presented hereafter; for further details, see [2].
Second order stationarity
A second order WSS random process is a sequence of random variables Xn defined on the
same probability space and such that:
– 
 is independent of n,
– 
– 
 is independent of n.
The sequence R (h) is known as the (auto-)covariance function.
It follows that R (0) ≥ 0 and R (h) = R* (−h). In the following, we shall assume the existence1
of the function:
γ (f) is known as the spectral density, and is, by construction, a periodic function of period 1.
We shall use the following fundamental result:
Remember that if Xn is real, then γ (f) is even, and limiting its representation to the interval
(0,1/ 2) is sufficient
The series
is known as the (auto-)correlation function, and verifies |ρ (h)| ≤ 1.

(4.4)
(4.5)
(4.6)
(4.7)
Empirical moments
Beginning with N successive observations, X1, …, XN, of a WSS process, we are able to
define the empirical mean:
the empirical covariance function:
and the empirical correlation function:
Hence 
. The following conditions may be demonstrated under very general
conditions [4]:
– when N tends toward infinity, the series µN tends in probability toward µ,
– the sequence 
 is a sequence of covariances (meaning that it is positive semi-
definite) and, when N goes to infinity, it tends in probability to R (h),
– if 
, then, for any P, the Toëplitz covariance matrix constructed using 
 is positive and invertible,
– for any value of P, it exists an AR-P process whose (P + 1) first values of the covariance
function are 
,
– using 
, the solution to the Yule-Walker equations (4.19) produces a polynomial with
roots which are strictly inside the unit circle [4].
A sequence of independent, centered random variables of the same variance σ2 is known as
strong sense white noise. Weak sense white noise, on the other hand, is a sequence of
uncorrelated, centered random variables of the same variance σ2.
Consider the process Xn constructed by linear filtering of the sequence {Zn} following
expression 
 where Zn is a strong sense white noise and where 
.
Let ρ = [ρ (1) … ρ (k)]T and 
. In [4] it is shown that:
where the matrix W of dimension k has a generating element Wp,q:

(4.8)
(4.9)
In the specific case where Xn = Zn, expression (4.8) may be simplified and written:
Hence, the Box-Pierce statistic
follows, based on the hypothesis that the process is white, 
 distribution with k degrees of
freedom (exercise 4.1). The Ljung-Box statistic is sometimes preferred:
Under the hypothesis that the process is white, this statistic also follows a 
 distribution with
k degrees of freedom. These “portmanteau statistics” are widely used to test the whiteness
hypothesis. The fact that the distribution of these two statistics is known, under the whiteness
hypothesis, allows us to calculate a p-value (section 2.2.2) for the process whiteness test
(exercise 4.2).
Example 4.1 (Whiteness test) Write a program which produces L draws of N samples of a
strong sense white noise, which calculates the K first empirical correlations, which displays a
histogram of values and which compares this histogram to the χ2 distribution with k degrees of
freedom (function chi2pdf in the stats toolbox).
Hints: Type the program shown below. The Box-Pierce statistic may also be replaced by the
Ljung-Box statistic.
Example 4.2 (AR test on sunspots) Consider the file sunspots.mat. The sunspots are taken
to be the result of an AR-2 process. Using the lpc.m function in MATLAB®, estimate the

prediction residual. Write a program to test the hypothesis that this residual is white. Give the
p-value.
Hints: in program whitenesstest, we have also drawn a confidence interval at 95% of the
correlation components following (4.9). This test leads to the conclusion that the residual is
white and therefore that the AR modeling the sunspots is of order 2.
If lpc.m is not available, the function xtoa may be used (see [2, 3]):
4.2 Linear prediction of WSS processes
The linear prediction of a random process consists of calculating an estimation 
 of the value
Xn of the process at instant n based on its immediate past of length N. The prediction error 
 therefore represents anything which is new at instant n in relation to that which has
already happened. Linear prediction is used in a wide variety of applications, such as
compression, noise elimination, signal analysis and synthesis. The solution is given by the
Yule-Walker equations.
4.2.1 Yule-Walker equations
Consider a WSS random process Xn with mean µ and covariance function 

(4.14)
(4.15)
(4.16)
(4.10)
(4.11)
(4.12)
(4.13)
. Remember that R (h) = R* (−h). Specifically, if Xn has real
values, R (h) is real and R (h) = R (−h). The general form of the linear prediction (affine of Xn
based on the N last previous values takes the form:
The prediction problem is to determine the expression of the sequence γk from µ and R (h),
while minimizing the quadratic error. Expression (4.10) may also be written:
A priori, the coefficients αk,N might be thought to depend on n, but this is not the case. Let:
thus 
.
Theorem 1.2 states that the coefficients α0,N , …, αN,N that minimize the mean square error 
 between the actual value Xn and the predicted value 
 are such that the error or
residue:
is orthogonal to 1 and to any 
 with 1 ≤ k ≤ N. This orthogonality is written
Applying (4.15) to (4.13), we obtain 
 and the orthogonality of
en,N with 
 is therefore written:
Using the expectation’s linearity, we get:
By replacing 
 by its expression (4.13), then by again using the expectation’s linearity, we
get:
Because the process is stationary, i.e. 
, we have:

(4.17)
(4.18)
(4.19)
(4.20)
The minimum mean square error is given by 1.29 which here has the expression:
A fundamental consequence of this is that, for a fixed N, neither the coefficients αK,N nor the
prediction error 
 are dependent on n.
Remark: the previous results show that no loss of generality results from supposing that µ = 0.
The prediction coefficients of 
 are calculated using the covariance function R (h) alone,
then in order to obtain Xn we use expressions (4.11) and (4.12), which use the mean µ.
Stacking the equation (4.18) and the N equations (4.17) in matrix form leads us to
where
These equations are called the Yule-Walker equations, or the normal equations. They allow us
to calculate the prediction coefficients and the minimum prediction mean-square error using the
covariance function of a WSS process. In practice, when µ and R (h) are unknown, they are
estimated using (4.4) and (4.5).
In the remainder of this section, all processes will be taken to be real, and the conjugation will
therefore be omitted.
Example 4.3 (Prediction of an MA-1) Let Xn = Zn+ b1Zn−1, where Zn is a white process of
variance σ2. Let R (h) be the autocovariance function of Xn. The process may be easily shown
to be centered, and 
, R (1) = R (−1) = b1σ2 and R (h) = 0 for |h | ≥ 2.
Determine the prediction of Xn as a function of Xn−1 and Xn−2.
Hints: we obtain 
 where, following (4.19), α1 and α2 are given by:

(4.22)
(4.21)
(4.23)
and 
. Solving the equation, we obtain:
Theorem 4.1 (Predicting a causal AR-P process) Let Xn be a causal AR-P process defined
by equation:
with 
 for |z| ≥ 1 and where Zn is a WSS white process
with the variance σ2. Then for any N ≥ P, the prediction coefficients to the N-th order are
given by:
and the minimum prediction mean square error is equal to 
.
Hints: Xn can be shown to be centered. Note [2] that, if A (z) = 0 for |z| 1, then Xn is expressed
causally as a function of Zn, i.e. Xn only depends on the Zn−ℓ, with ℓ ≥ 0. As Zn is white, Zn and
Xn−h are uncorrelated for any h ≥ 1, le. 
 for h ≥ 1. This is written 
. This result implies that (i) the variable 
 is
orthogonal to the sub-space 
n−1,m spanned by the variables Xn−1, …, Xn−m for any m ≥ 1, and
(ii) 
 belongs to 
n−1,m for any m ≥ P. Consequently, based on the projection
theorem, 
 is the orthogonal projection Xn onto the sub-space 
n−1,m, which
demonstrates (4.22) In these conditions, the prediction error is Zn and thus 
.
To conclude, the orthogonal projection of a causal AR-P causal onto its immediate past N ≥ P
coincides with the orthogonal projection onto its past of length P and the prediction
coefficients are the coefficients of the recursive equation (4.21), changing the signs.
Note that the coefficients ak of an AR model, equation (4.21), are linked in a linear manner to
the covariances. This property is not valid for MA processes. The estimation of the
coefficients of a model based on the estimated covariances is therefore simpler for an AR
model than for an MA model.
Theorem 4.2 (Choleski) Let Xn be a WSS process, with zero-mean, and covariance function
R (h). Then ΓN+1 defined by (4.20) can be written:
where:

where αi,j is the i-th prediction coefficient of length 
 is the norm of the associated error
and 
.
The following theorem will be admitted (4.3) [4].
Theorem 4.3 If Xn is a WSS process such that εN does not tend toward 0 when N tends
toward infinity, then for any N, the polynomial A (z) = 1 − 
 for |z |≥1.
One direct consequence of theorem 4.3 is that any covariance sequence R (h) may be
associated, for any N, with a causal AR process of order N, of which the first (N + 1)
coefficients are R (0), …, R (N) exactly.
The empirical covariance 
, given by expression (4.5), can easily be shown to be a
sequence of covariances (see [2], property). Based on theorem 4.3 we see that, for any value
of N, the coefficients solving the Yule-Walker equation associated with the sequence 
 define a stable causal filter.
4.2.2 Levinson-Durbin algorithm
Let 
n−1,N be the sub-space spanned by the variables Xn−1, …, Xn−N. The Levinson-Durbin
algorithm makes use of the specific geometric structure of second order stationary processes to
establish a recursive formula, giving prediction coefficients for order (N+ 1) based on the
prediction coefficients obtained for order N. It is written:
In practical terms, the Levinson algorithm is used to obtain an estimation of prediction and
reflection coefficients using the estimation of covariance coefficients obtained from expression
(4.5).
Hints: consider a real, centered WSS process Xn with a covariance function R (h). Let 
n−1,n

(4.24)
(4.25)
(4.28)
(4.26)
(4.27)
be the space generated by Xn−1, …, Xn−N. The forward orthogonal projection of Xn onto 
n−1,N
is noted:
and the backward orthogonal projection of Xn − N − 1 onto 
n−1,N
The two prediction errors, forward and backward, are respectively noted:
A geometric illustration is shown in Figure 4.1.
Applying the projection theorem in a similar way to that used in obtaining equation system
(4.19), we obtain the following equation system for the backward projection:
Figure 4.1 – Forward/backward predictions: 
n−1,N is the linear space spanned by Xn−1, …,
Xn−N. The dotted arrows represent the forward prediction error 
 and the backward
prediction error 
. The two errors are orthogonal to 
 and to 
.
Comparing equations (4.26) to (4.19), we deduce that αk,N = βk,N and that 
.
Moreover, process 
 appears as the filtering process for a WSS
process N- and is therefore itself WSS; hence, its norm is not dependent on n. This is written:
Replacing βk,N by αk,N in (4.25), then using k = N + 1−h, we obtain:

(4.29)
(4.30)
(4.31)
(4.32)
(4.33)
(4.34)
(4.35)
Assembling the backward and forward predictions, we have:
We now wish to express the projection of Xn for order N + 1 using the projection of Xn for
order N. Using equation (1.31) based on the direct sum
 (see Figure 4.1), we obtain:
with
where we make use of the fact that 
. Following the Schwarz inequality, |kN+1| ≤
1. Based on (4.31) and using 
 
, we obtain:
Inserting the second equation of (4.30) into (4.29) we obtain:
which, by identification with the first equation of (4.29), gives us:
Using (4.30), we obtain:
Taking the norm of the two members, we deduce that:
Using (4.31), we obtain:

(4.36)
(4.37)
Bringing together (4.32), (4.33) and (4.35), we arrive at the Levinson algorithm.
The sequence of coefficients kN given by equation (4.32) is equal to the partial autocorrelation
function defined by:
Table 4.1. – Correlation vs. partial correlation
correlation
partial correlation
Causal AR-P
evanescent
null from (P + 1)
Invertible MA-Q
null from Q + 1 evanescent
Casual and invertible ARMA-(P,Q) evanescent
evanescent
Definition 4.1 (Partial autocorrelation function) Let Xn be a WSS random process with
covariance function R (h). The partial autocorrelation function is the sequence defined by:
Due to stationarity, the sequence is not dependent on the choice of n.
In (4.36), the expression for i = 1 agrees with that for i ≥ 2 in that 
and that 
. Furthermore, in the expressions giving ki, Xn and Xn−i are projected
onto the same sub-space 
n−1,i.
The result of this, equation (4.33), is notable and shows that the sequence of partial correlation
coefficients is given by:
where the αi,i are calculated using the Levinson algorithm.
In the specific case of a causal AR-P process, we therefore have:
We can easily verify that the partial autocorrelation function of an MA-Q does not go to 0
unlike that of an AR-P which is null above P. However, the absolute value is bounded by a
decreasing exponential. Table 4.1 provides a summary of these different results.
Exercise 4.1 (Levinson algorithm) (see page 277) Write a function which estimates
prediction coefficients using the recursion og the Levinson algorithm. Test this function.
4.2.3 Reflection coefficients and lattice filters

(4.38)
(4.39)
When linearly predicting Xn as a function of Xn−1, …, Xn−m +1 we write that the error
prediction, equation (4.14), is orthogonal to the past2, that is:
We are now going to perform what is called the backward “prediction” of Xn−m as a function of
the (m − 1) values of the immediate future, that is Xn−m +1, …, Xn−1.Wehave:
 is a linear combination of Xn−1,Xn−2, …, Xn−m, hence the index (n − 1) in its
definition. Notice that, because of stationarity, 
 
with a sequence of coefficients βk,m −1 that do not depend on n.
By expressing the orthogonality, and by using the stationarity hypothesis, we can easily check
that the same Yule-Walker equations are obtained for the forward and backward predictions
and that:
Notice that for m = 0, the forward and backward prediction errors are written:
respectively. By construction, 
 and 
 are orthogonal to the same subspace
generated by Xn−1, Xn−2, …, Xn−m +1, and therefore for any scalar λ:
Let us choose λ such that δ is also orthogonal to Xn−m, and refer to this particular value of λ as
km. The vector 
 is therefore orthogonal to the subspace generated by Xn
−1, Xn−2, …, Xn−m. Because δm is a linear combination of the type Xn −un where un is a linear
combination of Xn−1, Xn−2, …, Xn−m, δm is, according to the projection theorem, the m-th step
prediction error. Hence we can write it:
where km is defined by:
which is expressed as 
.
By replacing the prediction errors with their expressions as functions of Xn, we get:

(4.40)
(4.41)
(4.42)
where R (k) refers to the covariance function of the WSS process Xn. This proves expressions
(4.36) and (4.40). Expression (4.41), which is recalled below, can be demonstrated in the
same way:
In the following section, we shall present the direct and inverse filtering structures which
connect the process to its two prediction errors. One of the advantages of this structure is that
we have a simple stability criterion, based on the reflection coefficients.
The analysis filter: 
The recurrence equation (4.34) was established during the demonstration of the Levinson
algorithm:
In the same way as we calculated expression (4.40), we may show that
Bringing together equations (4.40) and (4.41), we obtain a system of two filtering equations:
Figure 4.2 – Modulus of the lattice analysis filter
The input for this system is the pair 
, and the output is the pair 
. This calculation modulus is illustrated in Figure 4.2.
If we cascade these blocks and use the initial condition 
 we get the filtering
diagram of Figure 4.3, called the lattice filter, which changes the signal Xn into the two
prediction errors.
Figure 4.3 – The lattice analysis filter

(4.43)
(4.44)
(4.45)
Noting 
 and using the z-transformation, from system (4.42) we obtain:
The synthesis filter: 
The filter that changes 
 into Xn is causal and stable. Starting off with equations (4.42), we
can write:
Relations (4.44) lead to a cell set-up with the input sequences 
 and 
 and the two
output sequences 
 and 
. If we cascade these cells, we get the filtering diagram of
Figure 4.4, called a synthesis filter, which changes the signal 
 into the signal Xn.
Figure 4.4 – The lattice synthesis filter
Stability
Let us begin by considering the analysis filter which connects process Xn with the forward and
backward prediction errors. Iterating equation (4.43) and using the initial conditions 
, we obtain two impulse response filters with input Xn. These filters are
therefore stable.
However, the synthesis filter, which is the inverse of the analysis filter, is an infinite impulse
response filter (IIR). Using expression (4.43), we may write that:
Iterating this expression N times, we obtain an IIR filter, where the moduli of the poles are the
reflection coefficients. Consequently, this filter, the implementation of which is causal by
construction, is stable if and only if |ki | < 1. This condition is verified if we use the Levinson
algorithm.
Exercise 4.2 (Lattice filtering) (see page 278)
1. Analysis: write the lattice filtering function that implements the formulas (4.42).
2. Synthesis: write the lattice filtering function that implements the formulas (4.44).

3. Write a program that checks the two previous functions, by generating an AR-P process
using white noise and the filter function Use the atok function to extract the reflection
coefficients.
The two following functions atok and ktoa can be used to compute the coefficients at from the
ki and conversely.
4.3 Non-parametric spectral estimation of WSS
processes
In this section, we consider the problem of the non-parametric estimation of the spectrum of a
Wide-Sense Stationary (WSS) random process. The estimation is based on smoothing of the
periodogram. The notion of stationarity will then be extended to the intercovariance function of
two random processes, and a definition of the cross-spectrum will be given. This function is
often used in signal processing to check for the presence of linear filtering between two
observations.
The periodogram is derived from the Fourier transform of N successive samples. It provides
an unbiased estimator of the spectral density but, unfortunately, its variance does not tend to 0
when the number of samples tends toward infinity. However a consistent estimator may be
obtained by applying a smoothing approach.
Note: as both the time and frequency of signals will be manipulated, a lower-case letter will
be used to denote the temporal representation, e.g. xn, and an upper-case letter will be used to
denote the frequency representation, e.g. Xk

(4.46)
(4.47)
4.3.1 Correlogram
In order to estimate the spectral density the first simple idea is to mimic its expression from the
covariance function. Indeed the spectral density, when it exists, is the discrete Fourier
transform (DFT) of the covariance function. Therefore for that estimation, we can take the
discrete Fourier transform (DFT) of the empirical covariance 
 as defined in (4.5). This
leads to the spectral density estimate:
In the litterature 
 is called the correlogram.
It is easy to show that, under very general conditions, the correlogram is very close to the
periodogram defined by the expression (4.50). Therefore their performances can be derived
simultaneously. It is shown in the next sections that the periodogram, and hence the
correlogram, is a poor spectral density estimator More specifically, they present variances
which do not vanish to zero even when the number of samples goes to infinity. Without going in
the details, it is clear that the covariance estimates for lags h close to N are based on a few
number of samples and, thus, suffer of large errors the sum of which could not go to zero.
In spite of the bad performances of the correlogram, an efficient estimator can be derived from
it. The main idea is to restrict the numbers of lags and apply a sequence of weights giving the
Blackman-Tuckey estimator:
The sequence of weights is referred to as the time window. This appproach reduces the
variance but introduces a bias. We can expect that the variance will be of the order of L/N
whereas the bias will be of 1/L. As a rule of thumb, L is often chosen of the order of N/10.
This discussion will be continued with more details, in particular addressing the window
shape, in the section 4.3.3.
4.3.2 Periodogram
The discrete Fourier transformation (DFT) of N successive observations x0, …, xN−1 is
expressed:
where k ranges from 0 to N − 1. This definition does not correspond to that which is generally
used in signal processing, which does not include the term 
. However, it makes the
transformation more symmetrical, e.g. the inverse contains the same factor 
.
Firstly, let 
. Noting the useful identity

(4.49)
(4.48)
(4.50)
we deduce that, for k = 0, the value Xk does not depend on the mean of the process (if we
replace xn by xn + α, only X0 is modified).
If xn is real then 
 Moreover if N is even, hence X0 and XN/2 are real.
In a what follows, we shall only consider the complex values associated with the indexes
ranging3 from 1 to K = N/2 − 1 .
We shall use the following fundamental result [4]:
Property 4.1 Let xn be a WSS random process and γ (f) its spectral density. Thus, for the set
of values of k ranging from 1 to K = N/2 − 1 , the K complex random variables Xk
converge in distribution, when N tends to infinity, toward independent random variables
with Gaussian, complex, circular, centered distributions, of respective variances γk = γ
(k/N). This is written:
The probability density of Xk, deduced from expression (1.37), is written:
Without giving a detailed proof, note that for any random second order stationary process, the
vectors formed from the exponentials e2jπkn/N are, asymptotically the eigenvectors of the
covariance matrices. In the Fourier base, the random variables Xk therefore have a tendency to
decorrelate, becoming independent as they are asymptotically Gaussian.
Below, we shall consider that N is sufficiently large for the distribution of Zk to be considered
almost equal to its asymptotic distribution.
Definition 4.2 (Periodogram) The following sequence is known as a periodogram:
In the next section we derive the probability density of Pk from that of Xk.
Probability distribution of Pk
Let us show that, for any frequency index k between 1 and N/2 − 1, the variables Pk of the
periodogram are random variables following an exponential distribution of parameter γk.
Based on the property 4.1, the joint probability density of the real part Xr and imaginary part Xi
of Xk is given by:

(4.51)
(4.52)
where, for simplicity’s sake, the index k has been omitted. Let Xr = R cos(
) and Xi = R sin(
), where R ≥ 0 and 
  (0, 2 π). The Jacobian of this transformation is R. The joint probability
density of (R, 
) is therefore written:
Integrating with respect to θ leads to the probability density of R:
From definition (4.50), we note that Pk = R2, a transformation whose Jacobian is equal to 2R.
Hence, the probability density of Pk is given by:
In conclusion, Pk follows an exponential distribution of parameter γk. Noting that an r.v. with
an exponential distribution of parameter λ may be seen as λ times an r.v. with an exponential
distribution of parameter 1, we may write:
where Ek is an r.v. with an exponential distribution of parameter 1. Expression (4.52) shows
that in this situation, everything happens as if spectrum γk were affected by a multiplicative
“noise” following an exponential distribution of parameter 1. Hence, using the logarithm
(expression in dB), the estimation noise becomes additive.
As 
 and var (Ek) = 1, (4.52) shows that 
 and var
. This means that
the periodogram is an unbiased estimator of γk, but that, unfortunately, its variance does not
tend toward 0 when N tends toward infinity. The periodogram is not, therefore, a consistent
estimator of the spectral density.
We have indicated section 4.3.1 that the approach used in the Blackman-Tukey correlogram is
equivalent to a convolution in the frequency domain. We are going to show that the smoothe
periodogram forms a consistent estimator sequence of the spectral density.
Finally let us notice that an other, commonly used, approach consists of segmenting the data
into several blocks with an overlap, typically of 50%, and calculating the mean of the
periodograms obtained for each block. This is known as the Welch method: see [3]. This
approach presents similar performances in terms of quadratic error than the smoothed
periodogram.
4.3.3 Smoothed periodograms

(4.53)
(4.54)
The estimator of the smoothed periodogram is written:
where k (f) is the integer which verifies (Nf − 1/ 2) < k ≤ (Nf + 1/ 2). For multiple frequencies
of the form k/N, we have:
The sequence {Wm} is known as the smoothing window. Its application is illustrated in Figure
4.5.
Figure 4.5 – Application of a smoothing window to the spectrum
Property 4.2 (Smoothing window) The following hypotheses are applied in order to obtain
a consistent estimator:
1. 
2. W−m = Wm, therefore 
 (centered window),
3. 
 when M tends toward infinity and thus Wm tends toward 0,
4. M = Nβ/2 with β  (0,1); β is typically between 0.2 and 0.4 inclusive. This guarantees
that M and N/ (2M + 1) both tend toward infinity when N tends toward infinity.
The rectangular window Wm = 1/ (2M +1) verifies the first three properties.
Figure 4.6 shows the theoretical spectrum (dotted line) and the spectrum estimated using N =
4096 samples of an auto-regressive process defined by xn −1.7xn−1+0.9xn−2 = wn, where wn is
a white noise. The smoothing window is a normalized Hamming window and M = 20. We see
that at frequencies where the spectrum has a high second derivative, the differences are larger,
in accordance with equation (4.60) demonstrated after.

(4.55)
(4.56)
(4.57)
(4.58)
Figure 4.6 – Spectral estimation. Full line: spectrum estimated using a smoothed
periodogram. Dotted line: theoretical spectrum
As we shall see in the following section, when N tends toward infinity, the bias and variance
of 
 tend toward 0. However, for a fixed value of N, as M increases, the bias increases
whereas the variance decreases. The choice of a window and its size therefore involves a
compromise between bias and variance. This compromise is discussed in the next section. We
shall also see, on page 134, that, for sufficiently high values of N, the bias can be considered to
be small in relation to the standard deviation, and it is possible to identify a confidence
interval.
Bias/variance of the smoothed periodogram
Using expression (4.54) of the smoothed periodogram:
where, following (4.52), Pk−M, …, Pk+M are (2M +1) independent, exponential random
variables, of mean γk +m and respective variances 
. Hence we obtain for the expectation of
and for its variance
From (4.56) we see that the estimator includes a bias, given by:
Under very general conditions, the points in the periodogram in the window of length (2M + 1)
become closer and closer, and, supposing (for example) that 
, we can
show [4] that when N tends toward infinity Γk+m = Γk + O ((2M + 1)/N). The estimator is
therefore asymptotically unbiased.
Choice of M

(4.59)
In practice, the choice of M is more complex than it first appears. The theoretical spectrum is
unknown, and consequently formula (4.58), giving the bias, and formula (4.57), giving the
variance, cannot be calculated. Hence, with no particular a priori assumptions, the choice of
M is often simply related to the number N of observations. Thus we commonly use M = Nβ/ 2
with β ≈ 0.3.
One way of refining the choice of M is to assume that the spectral density has a certain
regularity, for example that it is differentiable up to order 2. Then taking a Taylor expansion up
to order 2 of γ (f), we can write:
where 
 and 
 respectively denote the first and second derivatives of the spectrum
calculated at point f For neighboring points separate from m/N, this expression leads us to
take:
where 
 and 
.
According to (4.52), the random variable Pk+m = γk+mEm appears as the product of the
deterministic value γk+m and a random variable Em following an exponential distribution of
parameter 1. Thus using (4.59) we get:
where Em are independent random variables. Using (4.55), we obtain:
From this, we deduce that
using the facts that (i) 
, (ii) 
 and (iii) 
. The bias of the
estimator 
 is therefore written:
For a fixed value of N, we see that the bias increases with M.
The variance of  is given by:

(4.60)
(4.61)
(4.62)
(4.63)
(4.64)
using the fact that var (Em) = 1. We see that the quadratic error at frequency k is expressed:
For the rectangular window, 
 and thus 
, whilst 
. Both therefore tend toward zero as N tends toward
infinity, but the squared bias decreases with a speed 4 times greater than that of the variance.
Hence, for a sufficiently large value of N, confidence intervals are often determined based on
the variance alone (see exercise 4.4).
Finally, a single numerical factor may be obtained for the bias, the variance and the mean
square error by summation of the values of k. This gives us the “integrated” bias:
the “integrated” variance:
and the “integrated” mean square error:
The choice of M may be based on the minimization of the “integrated” mean square error MSE.
However, the second derivative of the spectrum is still unknown. In practice, this may be
approximated by:
using the fact that ∂f ≈ 1/N.
Figure 4.7 shows the values of the integrated MSE as a function of M for 20 draws of a second
order auto-regressive process. The number of samples is N = 4096. We see that the minimum
mean square error occurs at around M = 15. Using the formula 2M + 1 = 31 ≈ Nβ, this gives us
β ≈ 0.4.

Figure 4.7 – Integrated MSE (expression (4.63)) as a function of the size M of the smoothing
window. The signal is a second order auto-regressive process. The number of samples is N =
4096. The points represent the values of the MSE over 20 draws. The full line shows the
mean for these 20 draws
Exercise 4.3 (Smoothed periodogram, bias/variance compromise) (see page 279) In this
exercise, we shall consider the effect of smoothing on the bias/variance compromise. To do
this, consider the smoothed spectrum given by expression (4.53). Write a program:
– which produces N samples of an auto-regressive process defined by xn − 1.7xn−1 + 0.9xn
−2 = wn, where wn is a centered white noise of variance 1,
– which estimates the spectrum by a smoothed periodogram using a Hamming window of
length (2M + 1),
– which calculates the mean square error between the smoothed periodogram and the
theoretical spectrum, presumed to be known. What happens when the size (2M + 1) of the
window is altered?
Choice of the window shape
Once the length of the frequency window has been determined, you have to select its shape.
The selection is based on the fact that the window shape induces two adverse and opposite
effects. One is due to the main lobe width, inducing a smoothing in the sharp region, and the
other is the heights of the values out of the main lobe, that induces leakage. Leakage is defined
as the effect of transferring energy from the bands where the energy is high to the bands where
the energy is low. Therefore the choice of the windows depends on the spectrum we want to
estimate, that is of course unknown. Practically the window shape is selected on a case-by-
case approach using some a priori knowledge on the signal.
We can relate that to the time window used in the Blackman-Tukey correlogram (4.47). Indeed
the convolution by a window in the frequency domain, as it is the case for the smoothed
periodogram, is equivalent to a multiplication by a window in the time domain, as it is the case
for the Blackman-Tukey cor-relogram. Under very general conditions the width in the time
domain varies in opposite sense than the width in the frequency domain. That means that, using
notations of expressions (4.47) and (4.53), we can write that ML  N. Therefore for the
correlogram, L/N plays a similar role than 1/M for the periodogram. For example the

(4.65)
(4.66)
(4.67)
correlogram variance is on order of L/N whereas the periodogram variance is on order of 1/M.
On the other hand the correlogram bias is on order of 1/L whereas the periodogram bias is on
order of M/N.
The adverse and opposite effects of the windowing is easy to see in the Blackman-Tukey
approach. Indeed the frequency window, associated to the time window, see expression (4.47),
usually presents a main lobe and multiples secondary lobes. It is clear that, regarding the
convolution, the main lobe width induces a smoothing for the sharp cut-off transitions whereas
the secondary lobe heights induces a leakage. Unfortunately when we reduce the secondary
lobe heights we increase the main lobe width. For more details on the use of windowing on
spectral estimation see [3]. A comprehensive overview of the windowing effects is given in
[29].
In summary, the choice of the value of M is related to the compromise bias/variance whereas
the choice of the window shape to the compromise between sharp cut-off smoothing and
leakage.
Approximate confidence interval
In this section, we derive a confidence interval for the smoothed periodogram. The calculation
is made possible, requiring that the spectrum is almost constant along the frequency window of
width 2M +1. This assumption is approximately true if (2M + 1)/N is sufficiently small
compared to the signal bandwidth Based on item 4 of assumptions 4.2, (2M + 1)/N is of the
order of 1/N1−β and can be considered as negligible for N sufficiently large.
Under this assumption and using (4.55) and (4.52) we can write:
where E−M, …, EM is a sequence of 2M + 1 independent random variables, with the same
exponential distribution of parameter 1. Consequently, 
 is the weighted sum of (2M + 1)
independent random variables, with the same exponential distribution of parameter 1. At first,
as we have assumed, assumption 4.2, that 
 and 
 when M tends to
infinity, the bias is zero and its variance, equal to 
, goes to zero when M tends to
infinity. Therefore the sequence of the smoothed periodograms is asymptotically consistent.
On the other hand, 
 (multiplication by 2) appears as the sum of 2M + 1 r.v. with
exponential distribution with parameter 2 which also coincides with the 
 distribution with 2
degrees of freedom. Let us denote:
and using the following approximation4:

(4.68)
(4.69)
(4.70)
(4.72)
(4.71)
we see that:
This result allows us to build a confidence interval at 100α % of the form:
Converting the expression into dB, we obtain the following confidence interval:
To conclude, presuming that the spectrum is, to all intents and purposes, constant over the
whole frequency window of width 2M + 1, the estimator is unbiased as 
, and its
variance is equal to 
. Note that this is based on the hypothesis that 
when M tends toward infinity. The smoothed estimator therefore has a variance which tends
toward 0 when M tends toward infinity.
Exercise 4.4 (Smoothed periodogram - confidence interval) (see page 281) Write a
program:
– which produces N samples of an auto-regressive process defined by xn − 1.7xn−1 + 0.9xn
−2 = wn, where wn is a centered white noise of variance
– which estimates the spectrum by smoothing the periodogram using a rectangular window
of length (2M + 1) where M =Nβ/2 with β = 0 4,
– which calculates a confidence interval at 95%,
– which compares these results with those obtained using the pwelch function in
MATLAB®
4.3.4 Coherence
Consider two random WSS processes xn and yn, with respective means µx and µy and
respective spectra Sxx (f) and Syyf·xn and yn are said to be covariance-stationary if
is solely dependent on h. We deduce that 
. The Fourier transformation of
Ryx (h) is known as the interspectrum, and is written:

(4.74)
(4.73)
(4.75)
(4.76)
This function is periodic of period 1 and verifies 
, so |γxy (f)| = |γyx (f)|
Unlike the spectral density, the interspectrum γyx (f) is not necessarily positive or real.
However, if processes xn and yn are real then 
 and the modulus |γyx (f)| of the
interspectrum is an even function. This will be taken as given in the remainder of this section.
Estimation of the interspectrum
In a similar way to that used for spectral estimation based on a smoothed periodogram, we
define the interperiodogram:
A property analogous to 4.1 states that, when N tends toward infinity, the random vectors [Xk
Yk ]T, for values of k between 1 and K = N/2 − 1, are independent, Gaussian, circular complex
and centered, of covariance:
From this result, we deduce [4] that the estimator 
 is unbiased, but its variance does not
tend toward 0 when N tends toward infinity. To obtain a consistent estimator, we apply a
smoothing process of the form:
where the sequence Wm verifies the hypotheses 4.2. Under very general conditions, 
 can
be shown to converge toward γyx,k.
Coherence
For any frequency f such that 
, the following function is known as the
magnitude squared coherence (MSC) or simply coherence:
Note that if xn and yn are real, then MSC(f) is an even function. In this case, we limit its
representation to the interval (0,1/ 2).
Using the Schwarz inequality, it is easy to show that:
This function has important practical applications for testing the presence of linearity. This is
illustrated in the following example. Suppose that xn and

(4.77)
(4.78)
(4.79)
yn are, respectively, the input and output of a stable linear filter of complex gain G (f). Hence:
Thus, for any f, the coherence is equal to 1:
This property is characteristic. We may show that:
where the equality is verified if and only if xn and yn are the result of filtering of one of them
by the other. In many practical applications, the function MSC(f) is used to see whether or not
two given signals are related by linear filtering
In order to estimate the coherence, we successively estimate spectra γxx (f) and γyy (f) along
with the interspectrum γyx (f). Using (4.53) and (4.74), we obtain an estimation of MSCk =
MSC(k/N) of the form:
[4] shows that, when N tends toward infinity and for 
:
where Lw is given by (4.66). From this, we deduce a confidence interval at 100α % for the
coherence, of the form:
where c verifies:
Typically, for α = 0.95, we have c ≈ 1.96.
Exercise 4.5 (Magnitude square coherence) (see page 282) Consider the two processes
defined by:
where g1,0 = g2,0 = 1, g1,1 = −1.2, g1,2 = 0.9, g2,1 = −0.4 and g2,2 = 0.3; where en is a causal
auto-regressive process of order 1, defined by the equation en− 0.3en−1 = zn, in which zn is a

centered white noise of variance 1; and where w1,n and w2,n are two centered white noises of
respective variance 
 and 
. Processes en,w1,n and w2,n are taken to be uncorrelated.
1. Identify the expression of the coherence.
2. Using MATLAB® generate processes x1,n and x2,n.
3. Using expression (4.77), estimate the coherence and a confidence interval at 90%
following expression (4.79). Compare the result with the theoretical MSC.
Notes
1 This condition is not particularly restrictive; for example, it is sufficient for R(h) to tend
toward 0 more quickly than 1/h when h tends toward infinity.
2 In this section, we assume the processes to be real and omit the star indicating conjugation.
3 The consistent estimation of X0 and XN/2 requires a smoothing process slightly different to
that presented below.
4 We consider that the r.v. 
 approximately follows the distribution 
. To
obtain c and v dentify the mean cv = 2 and the variance 2c2v = 4/Lw. We deduce that c =
1/LW v = 2LW. The result is valid for the rectangular window.

(5.2)
(5.3)
(5.1)
Chapter 5
Inferences on HMM
In this chapter, we shall give a brief overview of Hidden Markov Models (HMM) [6]. These
models are widely used in signal processing. They have a fundamental property which results
in the existence of recursive algorithms, meaning that the number of operations and the size of
the memory needed to calculate the required values do not increase with the number of
samples. The best-known example of this is the Kalman filter [10].
Throughout this chapter, for simplicity, the notation (n1: n2) will be used to denote the sequence
of integer values from n1 to n2 inclusive.
5.1 Hidden Markov Models (HMM)
A hidden Markov model (HMM) is a bivariate, discrete time process (Xn,Yn), where Xn and Yn
are two real random vectors of finite dimension such that:
— Xn, n ≥ 1, is a Markov process, i.e. for any function f the conditional expectation of f
(Xn+1) given the σ-algebra generated by {Xs;s ≤ n} (the past until n) coincides with the
conditional expectation of f (Xn+1) given the σ-algebra generated by {Xn}. If the
conditional distributions have a density, that writes:
— Yn, n ≥ 1, is a process such that the conditional distribution of Y1,…, Yn given X1,…,Xn
is the product of the distributions of Yk conditionally to Xk. If the conditional distributions
have a density, we obtain:
— the initial r.v. X1 has a known probability law. If this initial distribution has a
probability density, it will be denoted 
.
The following expression of the joint distribution can be deduced from the previous
assumptions:
Indeed using Bayes’ rule and equation (5.2), we have:

Using Bayes’ rule once again and equation (5.1), we may write:
Reiterating this writing process, we deduce that:
which completes the proof of expression (5.3).
Expression (5.3) may be represented by the Directed Acyclic Graph (DAG) shown in Figure
5.1, using the coding rule:
where  denotes the set of all nodes in the graph. Note that the DAG of an HMM is a tree. In
more general cases, we speak of a dynamic Bayesian network.
In practice, the variables Y1:n represent observations and variables X1:n represent “hidden”
variables. Our objective is thus to make inferences concerning the hidden variables based on
the observations. In very general terms, we therefore need to calculate conditional
distributions of the form 
 
. Thus, if we wish to “extract” all information
concerning Xn based on the observations Y1:n, we need to determine the distribution 
. Subsequently, any function of interest f (Xn) may be calculated using the
conditional expectation:
Figure 5.1 – The Directed Acyclic Graph associated with an HMM takes the form of a tree
which is a “measurable” function of the observations.
A priori, the problem appears very simple. We only need to apply Bayes’ rule and write that:

(5.4)
(5.5)
(5.6)
Let us notice that the numerator and the denominator can be obtained by integrating the joint
probability distribution a certain number of times. For example we have:
Unfortunately, with the exception of certain cases - such as the linear Gaussian case which
leads to the Kalman filter, or the case where the variables X1: n have values within a discrete
finite set - this expression is impossible to calculate. Other methods are therefore required for
these cases. One notable solution [8] is based on the creation of samples, known as particles,
which simulate the a posteriori distributions of Xn given the Yn. This is known as particle
filtering.
The factorized form of the expression (5.3) induces separation properties which are the basis
of recursive algorithms. Let us consider a few examples. For any k ≤ n, it is easy to show that:
or that:
or that, for any j ≥ 1:
Taking j = 1 and integrating expression (5.5) over x1:k − 1 and over xk+2:n,
All of these results may be determined using graphic rules applied to the DAG associated to
the considered Bayesian network. For more details, refer to [21].
5.2 Inferences on HMM
The list below covers a number of inference problems:
— Learning: the joint law (5.3) is taken to depend on a parameter θ, which may be
constituted of parameters µ associated to the distributions of observations 
,
and/or parameters ϕ associated to the distributions of the hidden states 
.
The aim is to estimate θ based on a series of observations Y1:n. The EM algorithm
presented in section (2.3.5) may be used.

(5.7)
— Inferences on Xn+k based on the observations Y1:n. Here the joint law (5.3) is assumed
to be known, and we wish to find the expression of 
:
1. if k = 0, this is known as filtering;
2. if k > 0, this is known as prediction;
3. if k < 0, this is known as smoothing.
— Estimation of the sequence of hidden states X1:n based on observations Y1:n in the case
where the values of Xn are found in S = {1,…, S}, which is finite and discrete. To do this,
the a posteriori maximum can be used:
One rough approach consists of “testing” the Sn possible value combinations. However, a
deeper examination allows us to obtain an algorithm with a complexity in terms of only n × S2.
This is the Viterbi algorithm, presented in section 5.4.5.
5.3 Gaussian linear case: the Kalman filter
In general cases, filtering consists of calculating 
. A simple calculation shows
that the HMM structure leads to a recursive algorithm, which calculates 
in two steps based on 
:
1. a correction step, which calculates:
2. an update step, which calculates:
Note that the denominator 
 is not dependent on xn+1. Hence, using the fact that
the integral of 
 with respect to xn+1 is equal to 1, we deduce that:
Therefore we only need to calculate the numerator of (5.7)
and then normalize by integration with respect to xn+1. Hence we can replace, in the update

(5.8)
step, expression (5.7) with:
where the symbol  means “proportional to”.
Generally speaking, the correction and update expressions are intractable; however there are
two important cases in which closed form expressions may be obtained. Firstly, the linear
Gaussian case leads to the Kalman filter, which is discussed in this section. The second case
arises when Xn takes its values in a finite state set, and will be discussed in section 5.4.
Let us consider the model defined for n ≥ 1 by the two following equations:
where {An} and {Cn} are two sequences of matrices with adequate dimensions. {Bn} and
{Un} are two centered Gaussian vector sequences, independent of each other, with the
covariances 
 and 
 respectively. We also assume that the random vector X1 is Gaussian
with zero-mean and covariance Σ1.
The first equation of (5.8) describes the evolution of the hidden state Xn.
The vector Xn is called the state vector, or just the state, and the first equation is called the
state equation or evolution equation. The vector Yn is the measurement vector and the second
equation is called the observation equation.
Generally speaking, we wish to make inferences concerning states on the basis of
observations. In this context, the evolution equation may be viewed as an a priori probability
distribution of the states. For this reason, we can consider that we are in a Bayesian
framework.
Let us return to equations (5.8). As an exercise, the following properties can be shown:
— based on the linear transformation property of Gaussian distribution, (X1:n , Y1:n) is
jointly Gaussian;
— the sequence Xn is a Markov chain;
— the probability density of the conditional distribution of Xn +1 given Xn has the
expression:
— the probability distribution of Y1:n conditionally to X1:n verifies the property of
independence expressed in equation (5.2);
— the probability density of the conditional distribution of Yn given Xn has the expression:

(5.9)
(5.10)
The bivariate process (X1:n , Y1:n) is therefore an HMM.
The fact that the probability distribution of Xn conditional on Y1:n is Gaussian constitutes a
fundamental property. We therefore simply need to determine the expression of its mean and
covariance. The Kalman algorithm provides a recursive means of calculating these two
quantities. In this context, the following notation is generally used:
Note that, in accordance with property 1.10, the Gaussian character implies that the conditional
expectation Xn|k corresponds to the orthogonal projection of Xn onto the linear space spanned
by Y1, …, Yk. The Kalman filter can therefore be deduced on the basis of geometric arguments
alone, associated with the projection theorem (see section 1.3). In this context, remember that
(X,Y) = {XY} denotes the scalar product of X and Y, and that (X |Y1:n) is the orthogonal
projection of X onto the linear space spanned by Y1:n.
Before discussing the Kalman algorithm in greater detail, let us consider a classic example,
concerning trajectography, leading to equations of the form set out in (5.8).
Example 5.1 Consider a vehicle moving along a straight line at the constant speed v. The
position at the time n + 1 is given by dn+1 = dn + vT where T denotes the sampling period. This
motion equation can also be written:
with the initial conditions d1 and v1. Notice that the second equation of the system is reduced to
vn = v1 if we assume that the vehicle has a constant speed. But if we have little faith in this
hypothesis of a constant speed, the possible variability can be taken into account by assuming
that:
where bn is a random process acting as a modeling noise.
Hence the evolution equation has the expression, in matrix form:
Let us now assume that the position dn is observed at the output of a noised device delivering
the value yn = dn + un, where un is a random process used as a model for the measurement

noise. The set comprising the equation that describes the motion and the one that describes the
observation leads to the following system of equations:
If we let Xn = [dn vn ]T, and if we write the expression of the observation Yn in vector form, we
get:
which is similar to the expression (5.8).
Kalman filter algorithm
The Kalman algorithm offers a recursive solution to the HMM filtering problem in the linear
Gaussian case, as defined in expressions (5.8). Its recursive characteristic should be
understood in the sense that the number of operations and the amount of memory required by
the algorithm do not increase as the number of observations increases. The Gaussian and linear
characteristics of the model mean that the a posteriori law of Xn given Y1:n is Gaussian, and is
therefore characterized completely by its mean Xn|n and covariance Pn|n.
exercise 5.1 gives a detailed proof of the Kalman algorithm in the scalar case. For the
vectorial case, a fully similar proof leads to the algorithm (3).

The Kalman algorithm performs a computation of Xn|n at the time n from the value Xn−1 | n −1 in
two successive steps: the prediction by equation (5.11) and the update by equation (5.16). And
this calculation only requires the memorization of the finite dimension state.
The variable in = Yn − {Yn |Y1:n − 1} is known as the innovation, and is the difference between
that which is observed at instant n and that which can be “explained” by previous
observations.
The variable noted 
 (Y1: n) in algorithm (3) is the log-likelihood of the observations,
calculated using the series of innovations. In the case where 
 depends on an unknown
parameter θ, the Kalman algorithm can be used to carry out maximization with respect to θ (see
Exercise 5.4).
The expression of this algorithm calls for a few additive comments:
1. Gn is called the Kalman gain. It can be calculated beforehand, since it is determined by
equations (5.12), (5.14) and (5.17), which do not depend on the observed data Yn.
However, except in the case of scalars (see exercise 5.1), the expression of Gn requires to
solve a complex recursive equation referred as the Riccati equation. Without going into
detail concerning the solution to this equation, note that MATLAB® includes a function
dare.m (Control System toolbox) which calculates the limit of the gain, if such a limit
exists, when n tends toward infinity.
2. Let 
. Using expressions (5.13) and (5.14), we obtain Gn = 
.

(5.19)
From this, we see that 
. In the absence of observation noise, the Kalman gain is
the right inverse of the observation matrix.
3. Now, let 
. The Kalman gain can be shown to tend toward 0. In this case, the
evolution model is highly reliable, and the estimation Xn|n is principally calculated using
prediction An−1 Xn−1|n −1.
4. The significance of equation (5.16) is obvious. According to the state equation of (5.8), the
“best” value of Xn at time n is An−1Xn−1|n −1. Then this value is corrected by a quantity
proportional to the difference between what we observe, saying Yn and what we can expect
from the previous observation, saying CnAnXn−1|n −1. That may seen as an adaptive
compromise between what we see, that is Yn and what we know, that is the equation of
evolution.
5. We wish to draw your attention to the fact that the algorithm requires us to know 
 and 
. However, the theory can be generalized to include the situation where these quantities
have to be estimated based on the observed data. In that case the sequence of gains can no
longer be calculated beforehand.
Exercise 5.1 (Kalman recursion in the scalar case) (see page 283) Consider the system
described by the two equations:
where {an} and {cn} are two sequences of scalars. {Bn} and {Un} are two centered Gaussian
sequences, independent of each other, with the variances 
 and 
 respectively. In
particular, 
 and 
.
We wish to determine the filtering distribution, i.e. the conditional distribution of Xn given Y1:n.
As we saw in section 1.4, this conditional distribution is Gaussian. Its mean corresponds to the
orthogonal projection of Xn onto the sub-space spanned by Y1:n, expression (1.45), and its
covariance is given by (1.46). Using the notation from section 1.4, we can therefore write that
Xn|n = (Xn |Y1:n), that Xn+1|n = (Xn+1|Y1:n) and that 
.
1. Show that Xn+1|n = anXn|n.
2. Show that (Yn+1|Y1:n) = cn+1Xn+1|n.
3. Use this result to deduce that Gn exists such that Xn+1|n +1 = Xn+1|n + 
4. Let Pn+1|n = (Xn+1 − Xn+1|n,Xn+1 − Xn+1|n). Show that:
5. Show that the r.v. i1:n are independent. Use this to deduce the expression of 
 as a

function of i1:n and var(i1:n).
6. From this result, deduce that:
7. Show that:
then that:
Bringing together all of the previous results, verify that we obtain algorithm (3).
Exercise 5.2 (Denoising an AR-1 using Kalman) (see page 286) The discrete-time signal Yn
= Xn + Un is observed, where n ≥ 1. The observation Yn is obtained with the following
program:
This program corresponds to the system described by:
Bn and Un are assumed to be two white noises, uncorrelated with each other. Hence, Xn is an
AR-1 process and Yn a noisy AR-1. Let 
. We want estimate Xn using the observed
Y1:n.
1. Determine, as a function of a and 
, the expression of the power 
 corresponding to
the stationary solution of the state equation. This value will serve as the initial expression
for P1|1.
2. Determine, as a function of a and ρ, the recursive equation of the Kalman gain, as well as
the initial value G1. Show that the Kalman gain tends toward a limit, and determine the
expression of this limit.
3. Write a program that implements the Kalman filter for this model.
Exercise 5.3 (2D tracking) (see page 288) Consider a mobile element in the plane Ox1x2. Let
x1(t) and x2(t) be continuous time functions representing the two components of its position, 
 and 
 their first derivatives (speeds) and 
 and 
 their second derivatives

(accelerations).
If the acceleration is null, i.e. 
 and 
, the trajectory of the mobile element is a
straight line. When the acceleration is non-null, this may mean that the vehicle has increased or
decreased its speed in a straight line, and/or that the vehicle has deviated from the straight line.
To take account of possible acceleration, 
 and 
 are modeled by two Gaussian,
centered white noises of the same variance σ2 This allows us to track a mobile element with a
trajectory which does not follow a straight line.
Let T be the sampling period For i = 1 and i = 2, let Xi,n = xi (nT) and 
, and let 
.
We presume that only the position is observed, and that this observation is subject to additional
noise. The position is therefore written Yn = CXn + Un with:
and Un is the observation noise.
1. Use a first-order Taylor approximation to show that:
and where Bn is a noise. Give the covariance matrix as a function of T and σ2.
2. Suppose that T = 1/ 10 s and that the speed is of the order of 30 m/s (approximately 90
km/h). Explain the connection between σ and a possible acceleration over a duration T.
The speed may be considered to vary by a quantity proportional to v0.
3. Write a function implementing the Kalman algorithm in the case where the parameters of
the model are not dependent on time.
Write a program:
— which creates noised observations Yn from a trajectory of any form, for example that
obtained using:
— which uses the Kalman algorithm to estimate Xn|n and Pn|n,
— which displays the confidence ellipse of the estimated position. Remember [2] that the
confidence region at 100α % of a random Gaussian vector of dimension 2, mean µ and

(5.20)
(5.21)
covariance matrix C is an ellipse with equation (x − µ) TC−1(x − µ) = −2log(1 − α).
Exercise 5.4 (Calibration of an AR-1) (see page 291) In the case of model (5.8), calibration
consists of estimating the matrices based on a series of observations, for example using a
maximum likelihood-type estimator.
Consider the AR-1 from exercise 5.2. We wish to estimate the three parameters a, σb and σu,
maximizing the likelihood of the observations Y1:N. We shall use the KalmanFilter.m function
coded in Exercise 5.3.
Write a program which estimates these parameters by an exhaustive search. As an exercise,
you may also wish to use the fminsearch function in MATLAB® (Optimization Toolbox) or
the EM algorithm [26].
Exercise 5.5 (Calculating the likelihood of an ARMA) (see page 291) Consider the HMM
model defined by:
where Zn is a sequence of independent random variables, with a Gaussian distribution, of
mean 0 and variance σ2, and Xn is a vector of length r, where
1. Show that Yn verifies the recursive equation:
Consequently, if aj = 0 for j > p and bj = 0 for j > q, and taking r = max(p,q + 1)Yn
verifies:
Thus, if 
 for |z | ≥ 1, Yn is an ARMA-(p, q) [2] which is expressed
causally as a function of Zn.
2. Use the Kalman algorithm to calculate, recursively, the log-likelihood 
 of an ARMA associated with parameter θ = {a1:p, b1: q,σ2}.
3. Let θ = {a1:p, b1:q , σ2} and 
. Determine the relationship giving the

likelihood ℓ associated with θ as a function of the likelihood  associated with .
4. Write a program which calculates the likelihood of an ARMA-(p, q) using the Kalman
algorithm.
5. Write a function which uses a1, …, ap, b1, …, bq and σ2 to calculate the first n
covariance coefficients of an ARMA. Find the likelihood. Compare this result to those
obtained using the program of the previous question.
5.4 Discrete finite Markov case
In cases where the states Xn of an HMM take their value in a finite set of values, the inference
on Xn has a closed form expression. This expression is based on two smoothing algorithms, as
defined in section 5.2, known as the Baum-Welch or forward-backward algorithms.
Consider an HMM with hidden states Xn, where n ranges from 1 to N, which have values in a
finite set S = {1, 2,…, S}. The distribution of the observations Yn given Xn = i is taken to have
a probability density denoted gn (yn |i). Let us denote pn (i |j) = {Xn = i |Xn−1 = j} and ω (i) =
{X1 = i}.
Exercise 5.6 (Discrete HMM generation) (see page 295) Consider an HMM with S = 4
hidden states, with an initial distribution ω = [1/ 2 1/ 4 1/ 8 1/ 8 ] and the following transition
probability matrix1:
Let Fs (x) be the cumulative function associated with the conditional distribution of Xn given
Xn−1 = s. More precisely:
1. Show that:
where Un is a sequence of independent r.v.s with a uniform distribution over (0,1).
2. Consider that the distribution of the observations conditionally to the states is Gaussian,
with respective means µi and covariance Ci with i = 1 to S. Using the results of exercise
3.2, write a function which generates a sequence of data following the proposed HMM.

(5.23)
(5.25)
(5.26)
(5.22)
(5.24)
Now let us determine two recursive formulas, known as the forward-backward formulas. We
shall then consider the way in which these formulas are used in 1 and 2 instant smoothing
algorithms, and in the algorithm used to estimate X1:n on the basis of Y1:N.
5.4.1 Forward-backward formulas
Let:
where
is the likelihood associated with the observations Y1:n when the distribution of Y1:n has a
density. In the case of discrete r.v.s, 
 should be replaced by {Y1:n = y1:n}.
Forward recursion
We wish to determine the recursion giving αn (i) as a function of αn−1(i). We can write:
Based on expression (5.3), we have:
Summing on xk with k = 1 to n − 2, we obtain:
Applying this expression to (5.25), we obtain:
Let us notice that the initial value writes α1(i) = g1(Y1| i) ω (i)/L (y 1).
Remark: the sum of the αn (i) for i ranging from 1 to S is equal to 1. For this reason, we simply
need to calculate the following terms:

(5.27)
(5.28)
(5.29)
(5.30)
and then sum these terms over i in order to obtain the normalization constant. This constant is
expressed:
This result allows us to find an important formula giving the log-likelihood of the N
observations:
In summary, the forward algorithm is written:
Backward recursion
We now wish to determine the recursion giving βn (i) as a function βn+1(i). As an exercise,
following an approach very similar to that used to obtain (5.26), we can show that:
with the final value βN (i) = 1 for any i. The backward algorithm is written:

(5.31)
(5.32)
5.4.2 Smoothing with one instant
In this section, for the sake of simplicity, expression {X1:N = x1:N |Y1:N} × L (y1:n) will be
noted {X1:N = x1:N,Y1:N = y1:N}, which is more concise, but only correct in cases where Xn and
Yn are random variables with discrete values. Remember that L (y1:n) is obtained using
expression (5.24).
We wish to calculate, recursively:
Using expression (5.4), we can write that:
Summing over x1:n −1 and xn+1:N and replacing xn by i, we obtain:
Using expressions (5.22), we obtain:
Therefore:
5.4.3 Smoothing with two instants
We wish to calculate, recursively:

(5.33)
(5.34)
Starting with expression (5.6), which may be rewritten:
we have:
Bringing together the forward and backward algorithms along with expressions (5.32) and
(5.33), we obtain a means of calculating smoothing formulas for cases with one and two
instants.
5.4.4 HMM learning using the EM algorithm
As we shall see, the one and two instant smoothing formulas are required in order to calculate
the auxiliary function of the EM algorithm associated with the estimation of θ = (ωi, p (i|j), ρi),
where ρi is a parameter of the observation distribution g (y |i) = g (y; ρi). In this case, we
presume that these distributions are not dependent on n
Let us prove that the auxiliary function of the EM algorithm, as defined byequation (2.97),
associated with the distribution of the discrete HMM has the following expression:
where the prime indicates that the calculated quantity is associated with the value θ′ of the
parameter.
Indeed the joint probability law of (X1:N, Y1:N) is written:
Taking its logarithm we have:

(5.35)
(5.36)
(5.37)
(5.38)
Using the identity 
, we obtain:
Taking the conditional expectation with respect to Y1:N under parameter θ′ and using the fact
that 
, we have:
This demonstrates (5.34).
Re-estimation formulas
The maximization of Q (θ, θ′) with respect to θ is carried out as follows. Canceling the first
derivative with respect to ωi, under the constraint that 
, we obtain:
Canceling the first derivative of Q with respect to p (i|j), under the constraint that 
for any j, we have:
In addition, we assume that the distribution g (y|i) is Gaussian, with mean µi and covariance
Ci. Canceling the first derivative of Q with respect to µi, we have:
Similarly, canceling the first derivative of Q with respect to Ci, we have:
Exercise 5.7 (EM algorithm for HMM) (see page 296) Consider an HMM with S = 4
discrete states, including the initial stateω = [ 1/ 2 1/ 4 1/ 8 1/ 8 ], with the following matrix of
transition probabilities:

and where the densities g (y; µi, Ci) are Gaussian, with respective means µi and respective
covariances Ci Let us remark that µi and Ci are assumed to be independent of n. Let θ = (µi, Ci,
ωi, p (i |j)) and let Y1:N be a sequence of N observations.
1. Use MATLAB® to write a function which implements algorithms (4) and (5). The inputs
consist of the observations, along with ω, p (i|j), µi and Ci. The function will perform the
sequences α and β and the likelihood.
2. Write a function to estimate θ using the EM algorithm.
3. Test this algorithm using the generator obtained in exercise 5.6.
5.4.5 The Viterbi algorithm
Consider an HMM of which the states have values in a finite set S = {1,…, S} of S values. The
transition distributions pn (i | j) = {Xn = i | Xn−1 = j} are assumed to be known, as are the
probability densities Yn conditionally to Xn = i, denoted gn (y |i).
We observe y1, …, yN and we wish to determine the sequence x1, …, xN which maximizes 
{X1:N = x1:N |y1:N}. Maximizing {X1:N = x1:N |y1:N} with respect to x1:N is equivalent to
maximizing the joint distribution of (X1:N, Y1:N).
The “brute force” approach involves calculating the joint law for the SN possible
configurations of the sequences x1:N. As we shall see, the Viterbi algorithm reduces the number
of calculations requiring only NS2 steps, which is considerably lower than SN.
We assume that, at time step n − 1, we have S optimal sequences of length n − 1 ending with
the S possible values of xn−1. In what follows, the sequence finishing with the value j  {1,
…,S} at instant (n − 1) will be referred to as the j-th path of length (n − 1). Let metn − 1) (j) be
the associated joint probability, known as the path metric. Using (5.3), taking the logarithm and
noting dn (i |j) = log {X1:n −2 = x1:n −2, Xn−1 = j, Xn = i,y1:n}, we have:
dn (i|j) is known as the branch metric (going from j to i at step n). There are S possible ways
of extending the j-th path of length n − 1. However, as we wish to find the maximum metric,
only the ascendant giving the maximum metric should be retained. Consequently, the i-th path of
length n has the following metric:
The ascendant giving the maximum value is written:

This ascendant should be retained in order to calculate the optimal sequence for step N.
Figure 5.2 shows a calculation diagram for S = 3 and N = 6, with an oriented graph of SN =
18 nodes. This type of representation is known as a lattice. At step n, we calculate the S2 = 9
branch metrics going from (n − 1) to n. From these 9 possible extensions, we only retain the S
= 3 optimal metrics reaching the S nodes of step n, along with their ascendants.
In conclusion, for each stage, we determine the S possible paths of length n with their
associated metrics. The calculation is continued up to step N. The optimal sequence is
obtained at the end of the process via backtracking.
Figure 5.2 – Lattice associated with S = 3 states for a sequence of length N = 6
The Viterbi algorithm is a dynamic programming algorithm in a lattice. In theory, the optimal
sequence is deduced based on the totality of the N observations. In practice, if the observations
are time indexed, as in digital communications (see section 6.3.2), we use stopping criteria in
order to take intermediate decisions before the final observations have been received.
Example 5.2 Consider an HMM with observations of which the log-likelihoods for each

hidden state are elements of the matrix logG, the transition matrix for which is given by A. Use
this data to write a code, in MATLAB®, which extracts the sequence of states using algorithm
(6). Note that the choice of likelihoods clearly favors the sequence 1, 2, 3, 4, 5.
The data is produced by the following program:
Use the function:
Notes
1 The number in line j denotes the initial state, and the number in column i gives the final state.
Thus, 
, i.e. the sum of the elements in a line is equal to 1.

(6.1)
Chapter 6
Selected Topics
6.1 High resolution methods
In this section, we are going to present methods that belong to the category of what are called
subspace methods, and that will provide us with a way of estimating the frequencies of a
harmonic mixture by finding the P minima of a single-variable function.
6.1.1 Estimating the fundamental of periodic signals: MUSIC
The algorithm presented hereafter, the acronym of which is MUSIC, for MUltiple SIgnal
Characterization, works better than the DTFT when the frequency differences are much
smaller than the inverse of the number of observed points (resolution limit of Fourier).
Furthermore, it can be applied to a broader observation model than that of sines corrupted by
noise.
Based on the example of a sum of P real sines corrupted by white noise, we are going to end
up with equation (6.3) responsible, because of how it is written, for the notable properties of
the covariance matrix.
Sum of P real sines corrupted by white noise
Consider the real observation x (n), n  {0, …, N − 1}, of the type:
1. {fk} is a sequence of P frequencies, all of them different from one another, belonging to the
interval (0,1/ 2),
2. {ak} and {bk} are two sequences of P real values,
3. b (n) is a centered, white noise, with the unknown variance σ2.
Once the sequence fk has been estimated, the sequences ak and bk can be estimated using the
least squares method [2, 3].
Let us now develop s (n + ℓ). We successively get:

(6.5)
(6.2)
(6.3)
(6.4)
Let θ = [θ1 … θP ]T where θk = 2πfk and let:
With these notations, we have:
If we stack M values s (n + ℓ) for ℓ = 0, …, M − 1, we can write:
Finally, if we add noise, we end up with the observation model:
where we have assumed:
and where A (θ) is an (M × 2P) matrix with the expression:
Notice that, in expression (6.3), the observation is of the type “signal plus noise”, and that the
signal part, that is A (θ)s (n), is the product of two terms, one of them, A (θ), depending only
on the paramater θ we wish to estimate and the other, s (n), depending only on n.
Based on a sequence of N observations x (0), …, x (N − 1), consider the (M × M) matrix
defined by:
If we change over to the mathematical expectation on the two sides of (6.5), then use (6.3) and
the white noise hypothesis, we get:

(6.7)
(6.6)
(6.8)
where I M is the M × M identity matrix and where:
is a (2P × 2P) matrix.
We will assume rather than prove that if N is much greater than M, 
 is a good estimate of the
M × M matrix defined by:
The MUSIC algorithm uses the fact that the eigendecomposition of the matrix R 0 = A (θ)R sAH
(θ) can be obtained directly from that of R, and hence from that of its estimate 
. Before we
present the MUSIC algorithm, we are going to determine an important property inferred from
the general form of the observation model provided by expression (6.3).
General Form of the Observation Model
Consider the size M complex observation model:
where the M × P matrix A (θ) with M > P is of the type:
where θk belongs to a scalar domain Θ. Notice that the same function a (θ) is used to define the
P columns of the matrix A (θ). This model includes of course the case of a sum of P real sines.
This is done simply by decomposing each sine with the frequency fk as the sum of two complex
exponentials with the frequencies ±fk. In that case, the matrix A (θ) is given by expression
(6.4).
We now come back to the general model (6.7). The P column vectors of the matrix A (θ)
generate in 
M a P′ dimension subspace, with P′ ≤ P, called the signal subspace. Its
complementary, dimension (M−P') subspace is called the noise subspace.
Let s (n) be a centered, length P, complex vector, and let R s =  {s (n)sH (n)} be its
covariance matrix. Let b (n) be a centered, length M, complex noise such that:
s (n) and b (n) are assumed to be uncorrelated. This means that x (n) is centered and that its
covariance matrix has the expression:

(6.9)
(6.10)
where we have assumed R0 = A (θ)R sAH (θ). The form of expression (6.9) leads to the
following properties:
R0 is a positive matrix with a rank ≤ P
This is because R s is a positive matrix, the rank of which is less than or equal to P.
Therefore A (θ)R sA (θ)H is itself positive with a rank smaller than or equal to P, since it
is generated by the P column vectors of A.
If the ranks of A (θ) and R s are equal to P, in other words if A (θ) and R s are full rank
matrices, then R 0 is a full rank matrix.
R and R 0 have the same eigenvectors
This is because R 0 has P′ ≤ P strictly positive eigenvalues and (M−P') null eigenvalues.
This result is a direct consequence of the previous result. The set of these eigenvectors is
an orthonormal basis of 
M.
Let υ1, …, υP, be the eigenvectors associated with the strictly positive eigenvalues of R 0.
We have R 0υi = λiυi. If we multiply equation (6.9) on the right by υ i, we get Rυ i =
(σ2+λi)υ i. Therefore µi =σ2 +λi > σ2 is an eigenvalue of R associated with the
eigenvector υ i.
Let g1, …, g K, with K = M − P′, be the eigenvectors associated with the null eigenvalues
of R 0. We have R 0gi = 0. If we multiply equation (6.9) on the right by g i, we get Rg i =
σ2g i. Therefore σ2 is an eigenvalue of R with multiplicity K, associated with the
eigenvectors g1, …, g K.
Remember that 
 for any pair (j,k), which is a consequence of the orthogonality
of the eigendecomposition of a positive matrix.
Comment: we know that the periodogram of a sum of sines and of a noise tends to σ2 for
the frequency values that are different from the frequencies of the sine components. This
result is similar to the previous one stating that the eigenvalues of the noise subspace are
all equal to σ2. The Fourier transform performs some kind of orthogonal decomposition
that approximately separates the space in a signal subspace and a noise subspace. In the
noise subspace, each component then has the same power σ2.
As a conclusion, we have the following theorem:
Theorem 6.1 Let x (n) be the size M complex observation model:

(6.11)
(6.12)
(6.13)
where the (M × P) matrix A (θ ) with M > P is of the type:
s (n) is a centered process with the covariance matrix Rs =  {s (n)s H (n)}, b (n) is a
centered white noise with the covariance matrix  {b (n)b H (n)} = σ2 IM. s (n) and b (n) are
assumed to be uncorrelated. If R0 = A (θ)R sAH (θ) then x (n) is centered and its covariance
matrix is such that:
where the matrix V is comprised of P′ ≤ P orthonormal eigenvectors of R0 associated with
strictly positive eigenvalues, where Λ = diag(λ1, …,λP ’) is the diagonal matrix with these
eigenvalues on its diagonal, and where the matrix G is comprised of the M−P′ unit
eigenvectors of R0 associated with null eigenvalues. We have VHG = 0. Notice that GHG = I
and therefore that GGH is the orthogonal projector onto the noise subspace.
Theorem 6.1 implies that:
Property 6.1 The subspace generated by the columns of V coincides with the subspace
generated by the columns of A (θ)R s, and both are contained in the space generated by the
columns of A (θ). This means that if P′ refers to the rank of Rs where P′ ≤ P, then there is a
full rank (P × P′) matrix T such that V = A (θ)T.
Estimation Based on the Noise Subspace
Consider the general complex situation presented in theorem 6.1. Starting off with the
orthogonality rproperty of A (θ) with the noise subspace, we are going to construct an
estimation of θ1, … θP based on the P minima of a single- variable function. In the case where
a (θ) is of the complex exponential type, this function is in the form of a trigonometric
polynomial.
If we multiply equation (6.11) on the right by G, we get R 0G = 0 and therefore:
The MUSIC estimator searches for the value of θ such that A H (θ)G = 0, which means that
(6.12) is true. The converse is true if the (M × P) matrix A (θ)R s is a full rank matrix.
Remember that for any matrix M, we have the equivalence:
We simply have to notice that trace(MM H) = ∑i ∑k |mik |2, where mik refers to the generic
element of M.
Using (6.13) then leads us to the following expression for the MUSIC estimator of the θ

(6.14)
(6.15)
parameter:
Property 6.2 (MUSIC estimator) The MUSIC estimator of the θ parameter associated with
the model (6.7) is:
where GGH is the orthogonal projector onto the noise subspace obtained from the
decomposition of the covariance matrix estimate.
If we replace (6.8) in expression (6.14), we get:
Because GG H is a positive matrix, the minimization is equivalent to finding the P arguments of
the P minima that are closest to 0 of the single-variable function:
Numerical Computation of the P minima
The simplest and broadest method for finding the minima of J (θ) consists of calculating J (θ)
on a set of values θ sampled on a fine grid. The minima are identified by typing:
This method will be used in the FFT-MUSIC algorithm.
We are now going to see methods for which a (θ) is comprised of complex exponentials, which
means we can use the FFT.
Case where the components are complex exponentials
Consider the particular case where the function can be written:
This includes the case defined by expression (6.4). All we have to do is group together the two
columns c (θk) and s (θk) obtained from the sequences cos(ℓθk) and sin(ℓθk), then to set a (θk)
= c (θk) + js (θk).
According to (6.15), an estimation of θ1, … θP is obtained by determining the P minima of the
single-variable function:
Notice that Q (ejθ) can also be interpreted as the value, calculated on the unit circle, of the

(6.17)
(6.16)
polynomial:
where a z (z) = [1 z … zM−1]T and where z = ejθ. With this notation, we then have 
 and:
 is a 2(M − 1) degree polynomial in z the roots of which come in pairs, since, by
construction, if z0 is a root, then 
 is a root.
Calculation of the coefficients of the polynomial 
Let P = GGH be the matrix with its generating element given by:
where gik is the i-th component of the k-th column vector of G = [g 1 … gk … gK ]. The
coefficients qd of the polynomial 
 are obtained from the relation (6.17), which
is written:
As you can see, the coefficients qd are calculated as the sum of the diagonal terms of the matrix
GGH according to the diagram in Figure 6.1.
Figure 6.1 – Calculation of the coefficients of 
 based on P = GGH
Implementation of the MUSIC Algorithm
The following sums up the MUSIC algorithm in the case of an observation that is the sum of P
complex exponential components. In the case where the signal x (n) is the sum of P real sines,
all we have to do is apply the algorithm by considering x (n) as a linear combination of
complex exponentials.

1. Choose M>P.
2. Calculate:
3. Calculate the eigendecomposition of 
. Use it to find the (M × (M−P)) matrix G,
constructed from the (M−P) eigenvectors associated with the (M − P) smallest
eigenvalues. Calculate the (M × M) matrix GG H.
4. Use the previous result to find the coefficients of the polynomial (equation (6.17)):
Once the polynomial 
 is obtained, the estimation of the P values fk = θk/2π can then be
achieved, among other possibilities:
1. by calculating the 2(M −1) roots of 
, then keeping the P stable roots that are closest to
the unit circle. This is called the root-music method;
2. or by finding the P minima of 
. This is achieved simply by calculating, with the help of
the fft function, 
 for θ = 2πk/L, where k {0, …, L −1}. This is called the fft-music
method.
The two methods lead basically to the same values if the roots of the polynomial 
 are very
close to the unit circle. Remember that they would be on the unit circle if the signal were a
perfect mixture of exponentials without noise. The FFT method then has a small advantage,
because root finding algorithms often require more computation time. However, in the presence
of significant noise, it would seem the root finding method is better suited.
Performances depend on the choice of M. What should be remembered is that M has to tend to
infinity when N tends to infinity, but not as fast as N, which is the case for example for M = Nγ,
with γ < 1, such as γ = 4/ 5, or γ = 2/ 3.
ROOT-MUSIC The music(xm,p) function given below implements the MUSIC algorithm for
the estimation of the frequencies of a sum of P complex exponentials by using a root finding
method for the polynomial 
. It first calculates 
 based on the expression (6.5) where we
chose M = N4/ 5 (try also for example M = N2/ 3). Then it calculates the vectors of the noise
subspace with the use of the MATLAB® function svd1 and uses the result to find the
coefficients of the polynomial 
 (given by (6.17)). Finally, the function returns the roots of 
 using the MATLAB® function roots. Based on the values of these roots, it can then
estimate the frequencies f1, …, fP using the angle function.

This function can be used for signals containing P real sines, simply by considering 2P
complex exponentials. The function returns a sequence of complex conjugate values (see
example 6.1).
FFT-MUSIC The musicFFT(xm,p) function implements the MUSIC algorithm for the
estimation of the frequencies of a sum of P complex exponentials by searching for the minima
of the polynomial on the unit circle. It first calculates 
 based on the expression (6.5) where
we chose M = N4/5. Then it uses the result to find the coefficients of the polynomial 
 (given
by (6.17)). Finally, it returns the P values of z on the unit circle that minimize 
. This is
achieved by the FFT computation of Lfft values of the polynomial 
. Then the P minima are
found first by determining the sign of the derivative between two consecutive values with the
use of the command dQQfft=filter([−1 1],1, QQfft) (you can also use the diff function
which returns one less value). When the sign of the derivative goes from −1 to +1, it means we
just went by a minimum. To run this test, the filter function is used once more by executing
dsdQQfft=filter([1 −1],1,sdQQfft) and comparing the result with the value (+1)−(−1) =
2.
The choice of Lfft modifies the accuracy of the calculation of the obtained minima. We chose
Lfft=16*1024 in the function function musicFFT.m. Restricting the search to the minima by
calculating more values of 
 could save you some time, but only in the neighborhoods of the
obtained values.

Example 6.1 (Implementation and simulations)
1. Write a program that generates a size N = 60 sample of the P = 2 sines defined by the
values:
with a noise added to it such that the SNR is equal to 20 dB.
2. We wish to evaluate the performances depending on the signal-to-noise ratio. This is
achieved by setting N = 60, f1 = 0.2, f2 = 0.21 and the amplitude ratio to 0.2. The signal-to-
noise ratio varies between 10 and 20 dB. The square deviation between the estimator and
the real value is a useful performance indicator. In practice, the analytical expression of the
result is impossible to obtain, which is why simulations are done by performing a large
number of trials. This is called a Monte-Carlo simulation.
Write a program that conducts such a simulation based on 300 trials.
Hints:
1. Type:

The parameters cannot be properly estimated with the DTFT since f2 −f1= 0.01 < 1/N 
 0
017. As you can see, in Figure 6.2, the DTFT only shows one maximum instead of two
around the frequencies f1 and f2.
Figure 6.2 − DTFT of the signal x (n) = cos(2πf1n) + 0.2cos(2πf2n) + b (n) with f1 = 0.2,
f2 = 0.21, N = 60. The signal-to-noise ratio is equal to 20 dB
You can also test the musicFFT.m function, simply by typing racm=musicFFT(x,2*p);
instead of racm=music(x,2*p); before executing the program again.

2. simumusic.m implements a simulation to evaluate the performances for the measurement
of f1 and f2 for several values of the signal-to-noise ratio. These results, obtained from 300
trials, are shown in Figure 6.3.
The graph on the left shows the mean square deviation of the estimation of f1, and the one
on the right shows the mean square deviation of the estimation of f2, for several values of
the signal-to-noise ratio. Notice that in both cases, the square deviation “decreases” as the
signal-to-noise ratio increases. Furthermore, performances are better for f1 than they are
for f2, because the amplitude of the sine with the frequency f2 is much smaller than the one
associated with f1.
Figure 6.3 – Performances of the MUSIC algorithm. Signal x (n) = cos(2pf1n) + 0.02
cos(2pf2n) + b (n) with f1= 0.2, f2 = 0.21, N = 60. Square root of the square deviation of the
estimation, for each of the two frequencies, evaluated for a length 300 simulation, for
several values of the signal-to-noise ratio in dB

You can also conduct the simulation for the function musicFFT.m.
Remember that, in practice, the periodogram is better suited than the MUSIC algorithm as soon
as the product RTs is greater than 3, whatever the value of the signal-to noise ratio. However,
if the product RTs < 3 and if the signal-to-noise ratio is greater than 30 dB, then the MUSIC
algorithm should be used rather than the periodogram.
6.1.2 Introduction to array processing: MUSIC, ESPRIT
Figure 6.4 shows a linear antenna comprising M = 3 sensors assumed to be identical and
separated by the distance d. A source located in the direction θ sends a wave with the carrier
frequency F0. This source is assumed to be far enough for the wave’s phase lines to be
considered parallel lines. The received signal is sampled at the frequency Fs and f0 = F0/Fs.
Figure 6.4 – Linear antenna with three sensors and P = 1 distant source assumed to be far
away. The dashed lines represent the equiphase lines

(6.20)
(6.18)
(6.19)
Under these conditions, if 
 represents the complex (sampled) signal received
by sensor 1, then the signal received by sensor 2, located at a distance d from sensor 1, has the
expression 
, where the delay τ = d sinθ/c and where θ  (−π/ 2,π/ 2). c
refers to the propagation speed. In radiocommunications, c = 3 × 108 m/s.
Narrow Band Hypothesis
Let us assume that bs 
 f0, where bs refers to the frequency band of the signal e (n). Then the
signal s (n) is said to be a narrow band signal around f0. In that case, if we use f0 = c/λ0 where
λ0 refers to the wavelength and τ = d sinθ/c, then bsτ 
 f0d/c = d/λ0.
When c = 3 × 108, the value of f0d/c can be small, meaning that the condition bsτ 
 1 is met,
and hence that e (n) varies little during the time τ. We can then infer that e (n − τ) ≈ e (n). As a
conclusion, when the signals are narrow band and when the propagation speed is very high:
This result is no longer true for acoustic propagation (SONAR type propagation), for which the
value of c is too small, meaning that the value of f0d/c is always high. In that case, it is not
always possible to have bsτ 
 1. From now on, we will assume that the conditions are those
of the first case, meaning that the approximation e (n − τ) ≈ e (n) is valid.
Expressions (6.18) are true for two sensors, and can easily be extended to a set of M sensors,
which leads to:
where
with α = f0τ = df0 sinθ/c. The function a (α) is called the array manifold. From now on, we
will only be considering the case of a linear and uniform antenna for which a (α) is of the type
(6.19).
If we use the expression λ0 = c/f0 for the wavelength, we get:
To achieve an univocal identification of α, α must belong to the interval (−1/ 2,+1/ 2), and
therefore we must have:
The distance between two sensors must be smaller than half the wavelength.

(6.21)
(6.22)
If we now assume that there are P sources, located in P directions θ1, …, θP of the plane, and
that the observation is the sum of these P contributions and of a noise, then we can write:
where s (n) = [s1(n) … sP (n)]T and where
b (n) is an (M × 1) noise vector. The noise is assumed to be centered and white. We then have 
{b (n)} = 0 and
Notice that the signal model provided by equation (6.21) is identical to the one given by
equation (6.7).
We will not extensively discuss the problem of determining the P arrival directions based on
the observation of N shots {x (1), …, x (N)}. We will merely give a few answers.
Classic Beamforming
We saw that the wave originating from source p reaches the M sensors with delays
proportional to αp, hence the idea of multiplicating x (n) on the left by the weighting sequence 
, then to find the maximum. In the absence of noise, we have:
where the function:
has maxima in α ≈ αp with p  {1, …, P}. Everything happens as if the antenna’s gain was
focused in the direction αp. This is called beamforming. Therefore, to estimate the P arrival
directions, we have to find the P maxima of the function:
where 
. The separations between the maxima increase, or in other words
the resolution is enhanced when mini≠j |αi − αj| 
 1/M. This condition can also be written:
If we need to distinguish arrival angles separated by e, for small values of e, we can write that:

(6.23)
(6.24)
For e = 1/ 10 radian and for d/λ0 = 1/ 2, we have to set M 
 20.
In the case where condition (6.23) is not well satisfied, the performances of this method
become mediocre. Different methods can be used such as the MUSIC algorithm, seen in section
6.1.1.
The Capon Method
In order to enhance the resolution obtained by the classic approach, Capon suggests in [5]
searching for the weighting vector w k which, on the one hand, minimizes:
where 
 and, on the other, satisfies the constraint 
 . The idea is to
perform a weighted sum of the observations in order to cancel every component, except for the
one coming from the direction αk for which the gain is equal to 1. w k therefore performs a
spatial filtering that focalizes the antenna on the source located in the direction αk.
The solution is obtained using the Lagrange multiplier method, which consists of solving the
following equivalent problem:
By setting to zero the derivative with respect to w k of the first expression, we get R xwk− λa
(αk) = 0, which leads to:
By expressing the fact that 
, we get λ = (a H (αk)R −1a (αk))−1. If we replace it in w
k, we get:
Replacing this in the expression of the criterion leads us to:
In an estimation problem, the matrix R is replaced by:
The Capon method consists of determining the P maxima of the function:

(6.25)
(6.26)
This expression should be compared with (6.22).
MUSIC
This approach was presented in detail in section 6.1.1. Just remember that, starting with
equation (6.21), we end up with the following expression of the covariance matrix:
where R0 = ARsA H is assumed to be a full rank matrix. We showed with equation (6.11) that:
where GG H refers to the orthogonal projector onto the noise subspace. The MUSIC algorithm
then consists of finding the P maxima of the function:
ESPRIT
The ESPRIT algorithm, short for Estimation of Signal Parameters via Rotational Invariant
Techniques, was first suggested in [24]. It uses the fact that the antenna can be decomposed in
two identical sub-antennas. It also assumes that R s is a full rank matrix, and therefore that
there is (see property 6.1) a full rank (P × P) matrix T such that:
Let A1 = [I M−1 0]A and A2 = [0 I M−1 ]A. In other words, A1 represents the first (M − 1) lines
of A and A2 the last M − 1). The expression of A (α) implies that A2 = A1Ω where Ω = diag
(e2jπα1 , …, e2jπαp).
Let V1 = [I m−1 0] V and V2 = [0 I M−1]V. Because of the expression V = AT V1 = A1T and V2
= A2T, and therefore:
The pseudo-inverse of V1 is denoted by 
. By definition 
. This means
that we can write:
Notice that 
 is a (P × P) matrix.
We are now going to show that, if TA = BT, then A and B have the same eigenvalues. This is
because if λ is an eigenvalue of A associated with the eigenvector u, meaning that Au = λu,
then we have T Au = λTu on one hand, and T Au = B Tu on the other, and therefore B × Tu =

λ × Tu which leads to the fact that λ is an eigenvalue of B associated with the eigenvector Tu.
Because of this property, and because Ω is a diagonal matrix, we have the following result:
Property 6.3 (ESPRIT estimation) The ESPRIT estimator of the parameter α associated
with the model (6.7) is 
 where the α1, …, αP are the P eigenvalues of the
matrix 
 where V1 = [I M−1 0] V , V2= [0 I M−1 ]V and where V is defined by equation
(6.11).
The ESPRIT algorithm uses this property: the covariance matrix is estimated based on a
sequence of observations x (n), and its eigendecomposition leads to the matrix V associated
with the signal subspace of the P highest eigenvalues. We then have to determine the
eigenvalues of 
. One of the strong points of ESPRIT compared to MUSIC is that it does
not require the search for maxima.
Example 6.2 (Comparison of MUSIC and ESPRIT)
1. Write a MATLAB® function that implements the ESPRIT algorithm.
2. Write a function that implements the MUSIC algorithm for antenna processing:
— either with the FFT, by computing the function SMUSIC (α) given by expression
(6.26) then by determining its P maxima,
— either by finding the P roots closest to the unit circle with a modulus smaller than 1
of the polynomial Q (z) given by expression (6.17).
3. Write a program that simulates the three sources coming in from the three directions θ1 =
−30°, θ2 = 15° and θ3 = 20°, on an antenna comprising M = 8 sensors. The distance
between two sensors will be set equal to half the wavelength.
4. Evaluate for 100 trials the square deviations for the estimations as functions of the signal-
to-noise ratio for T = 20 snapshots.
5. By referring to condition (6.23), notice that the difference e = θ3 − θ1 is smaller than 1/
10th of a radian and that therefore Med/λ0 = 0.4.
HINTS:
1. This function implements the ESPRIT algorithm. Type:

2. This function implements the MUSIC algorithm. Type:
3. Type the following program:

which uses the signal generating function:

Exercise 6.1 (MUSIC 2D) (see page 300) We consider an antenna comprising M sensors
assumed to be identical. The vectors r m = [xm ym zm ]T, with m  {1, …, M}, describe the 3D
location of the m-th sensor. K < M sources are assumed to be narrow band with a wavelength
λ0. When the plane wave hypothesis is valid (the sources are far from the antenna), the
response of the m-th sensor to the k-th source is given by:
where the wave-vector:
and where ζk is the elevation and φk the azimuth (see Figure 6.5) of the direction of
propagation of the k-th source.
Figure 6.5 – Angular references
Under the narrow band assumption, the observed signal may be written:
1. Determine the expression of the MUSIC function (see formula 6.26).
2. Write a program:
— that simulates N = 100 samples of x (n) for K = 3 with ζ = [30° 40° 50°], φ = [60°

(6.27)
50° 20°] and with an antenna comprising M = 25 sensors located on a grid in the plane
x Oy;
— that displays the MUSIC function in 2D.
6.2 Digital Communications
6.2.1 Introduction
Digital communications offer many challenges to people working in signal processing. The
new services provided for cellular communications or the internet pose problems which have
to do partly with digital signal processing.
Simply put, “making a digital communication” consists of transmitting a continuous-time signal
constructed from a message comprised of a sequence {dk} of bits. To conduct this transmission
operation, a device called a modulators used for emitting. When the signal is received, the
opposite operation is conducted by a device called a demodulator. Therefore, in two-way
communications, a modulator and a demodulator are necessary at both ends of the
communications line. The word modem comes from the contraction of these two words.
According to the characteristic features of the channel, low-pass or high-pass, the modulation
is implemented in baseband, or on a carrier frequency.
Baseband modulation
In baseband modulations, the modulation operation consists of producing a signal xe (t)
(Figure 6.6) defined by:
Figure 6.6 – Baseband modulation and demodulation
In expression (6.27):
— ak is a sequence of symbols with possible values in a finite set of M values, called a
constellation. The sequence ak is constructed from the sequence of the bits dk by an coding
algorithm that associates a sequence of bits with each symbol of the constellation. Most of
the time, the constellation is comprised of M = 2N real values, and hence, to each possible

(6.29)
(6.28)
(6.30)
(6.31)
value in the constellation corresponds a code word with the length:
— T represents the time interval between the transmission of two consecutive symbols.
The symbol rate, or modulation rate, expressed in Bauds, is defined by:
— The choice of the impulse function he (t) depends on the characteristic features of the
transmission channel.
“On the other end of the line”, the operations that have to be performed to reconstruct the
original sequence consist of a filtering, followed by a sampling and a test designed to retrieve
the symbols ak as best as possible. These symbols are then decoded to obtain the sequence of
bits dk. The exercises in this section shed light on the methods used all along the transmission
channel.
Carrier frequency modulation
In carrier frequency modulations F0 (Figure 6.7), the transmitted signal has the expression:
where
The symbols ak are complex. The complex signal α (t) is called the complex envelope of the
real signal xe (t) with respect to the frequency F0. The real and imaginary parts of α (t) are
called the phase component and the quadrature component of xe (t) respectively.
The complex envelope can be quite useful both in theoretical calculations and in simulation
programs. This is due to the fact that the error probabilities, in the presence of additive white
noise, do not depend on the choice of the carrier frequency F0. Therefore, it is useless in a
simulation to generate the modulated signal.
The diagram in Figure 6.7 shows an implementation of the modulator for which he (t) was
assumed to be real. As for the demodulator, the received signal is first processed so as to
extract the real and imaginary parts from the complex envelope. Each of the two signals is then
filtered and sampled. The two results make up the real and imaginary parts of a sequence of
complex observations used by the decision-making system to determine the transmitted
sequence of symbols, then the transmitted sequence of bits.

(6.32)
Figure 6.7 – Carrier frequency modulation and demodulation
Relation between symbol rate and bit rate
As a result of the operation putting together the bits in groups of N, the time T between the
transmission of the two consecutive symbols is equal to N times the time interval Tb between
two consecutive bits. If the binary rate is denoted by D = 1/Tb, and if we use expressions
(6.28) and (6.29), we get formula (6.32), which shows the relation between the symbol rate
the binary rate, and the size of the modulation alphabet:
6.2.2 8-phase shift keying (PSK)
We will start with the example of the 8-phase digital modulator that associates the portion of
the sinusoidal signal x (t) = A cos(2πF0t + Φ) lasting a duration of T with each 3-bit group.
Because there are 8 ways of grouping three bits together, the values of Φ are chosen in the set
comprised of the 8 phases regularly spread out between 0 and 2π. This set defined by {0, 2π/ 8
4π/ 8, …, 14π/ 8} makes up the constellation.
This constellation is represented in Figure 6.8, which shows a coding example. Notice that the
chosen coding is such that the codes of two adjacent symbols differ by only one bit. This is
called a Gray code. We will see equation (6.44)) what the point of such a coding is for the
value of the bit error probability. Figure 6.9 shows the signal corresponding to a sequence of
15 bits.
Figure 6.8 – 8-PSK state constellation

(6.33)
Figure 6.9 – 8-PSK modulation signal
Let us check that the complex envelope of a phase modulation is written:
where the ak = ejΦk are the complex symbols shown in Figure 6.8. Indeed, the signal xe (t) in
the interval (kT, (k + 1)T) is written:
By referring to expression (6.30), we can conclude that the complex envelope is equal to Aak
in the interval (kT,(k + 1)T), which is the expected result.
Exercise 6.2 (Phase modulator) (see page 301) Consider an 8-PSK modulator and a binary
rate of 1,500 bps.
1. Determine the symbol rate.
2. Determine a coding such that two neighboring points of the constellation differ by only one
bit (Gray code).
3. Write a program that generates the signal transmitted, for a carrier frequency F0 = 2 kHz
(take a sampling frequency equal to 20 kHz for the display) and for the binary sequence
[000 101 001 100 011].
6.2.3 PAM modulation
We now return to expression (6.27) of a baseband modulation, and we will consider that the
sequence {ak} is a sequence with possible values in the constellation comprised of M real
symbols and defined by:
Most of the time, M is a power of 2. For instance, if M = 8, the alphabet is the set {−7, −5, −3,
−1, +1, +3, +5, +7}. This modulation is called an M state pulse amplitude modulation, or M-
PAM. Still in the case where M = 8, the association of 3-bit sequences with alphabet symbols
can be done by using the following Gray code:

An example of the type of signal transmitted, when he (t) is a rectangular impulse with a
duration T, is shown in Figure 6.10.
Figure 6.10 – An example of 8-PAM modulation
We will see, using formula (6.35), that this signal, in the case where he (t) is a rectangular
impulse, theoretically takes up an infinite amount of space in the spectrum, meaning that it
cannot be transmitted through a B band limited channel without distortion, particularly if B <
1/T. We will see in section 6.2.5 that it is then preferable to choose he (t) so as to satisfy a
criterion better suited to the demodulation problem, called the Nyquist criterion.
In any case, the signal is deformed when it is transmitted through the channel. If we assume that
the channel acts as a linear filter with the impulse response hc (t) added to a noise w (t), the
received signal is the following:
where the impulse h (t) = (he  hc)(t) corresponds to the cascading of the emission filter he (t)
and hc (t).
Under the hypothesis that w (t) is a white, centered, Gaussian noise, it can be shown [22] that
in order to perform an optimal detection of the sequence of symbols {ak}, and hence of the
sequence of binary elements {dk}, all we need to do is filter the signal xr (t) as it is received
by the matched filter with the impulse response h* (−t), and to make the decision based only
on the samples taken at the symbol rate 1/T from the matched filter’s output.
Generally speaking, the transmission channel acts as a low-pass filter, which causes the signals
to stretch out in time. In most cases, such as for instance the phone channel, hc (t) stretches out
beyond T. As a consequence, the signal corresponding to the symbol ak “overflows” onto the
following time intervals. This is called InterSymbol Interference, or ISI.
This phenomenon is a nuisance as it makes it more difficult to retrieve the symbols from the

(6.34)
matched filter’s output samples. Even if we assume that the noise is Gaussian and white, the
optimal receiver has to use a complex algorithm, called the Viterbi algorithm, to retrieve the
most likely sequence of symbols (see section 6.3). However, as we will see, retrieving the
symbols is very simple in the absence of ISI.
Error probability and signal-to-noise ratio
An important element for determining the performances parameters of the transmission system
is the value of the Bit Error Rate, or BER. For the simplest modulations, it is possible to find
an analytical expression [9]. However, most of the time, it is simply estimated using a
simulation program that compares the sequence of emitted bits to the sequence of decided bits.
Remember, while we are on the subject, that to obtain a 10% accuracy on the error probability
Pe with a 70% confidence, we need a test sequence with a length N ≈ 100/Pe For Pe = 10−2,
this means N = 10,000, making it understandable that this can lead to a long simulation time,
even for a fast computer.
The BER is usually plotted against the signal-to-noise ratio Eb/N0 between the mean energy Eb
necessary to send a bit and the quantity N0 where N0/2 represents the psd of a white noise. We
wish to emphasize that N0 is expressed in Joules, as it should be, because N0 represents a
power spectral density, and is therefore measured in Watt/Hz. The ratio Eb/N0 can also be
expressed as a function of the signal-to-noise ratio of the powers. If Ps refers to the power of
the useful signal, and Pb refers to the noise power in the (−B, +B) band, then:
Hence the signal-to-noise ratio also has the expression:
where R refers to the symbol rate (expression (6.29)).
6.2.4 Spectrum of a digital signal
Consider the digital signal:
where {ak} is a WSS random sequence with possible values belonging to a finite alphabet. We
will use the notations ma = {an} and 
 where 
. g (t) is
a modulation pulse, and U is a random variable uniformly distributed on (0, T) and
independent of the random variables {ak}. T represents the time interval separating the
transmission of two consecutive symbols. We are going to prove that the signal x (t) is WSS
stationary and that its power spectral density has the expression:

(6.35)
First, notice that the probability distribution of U has the probability density 
. Hence, because the random variables ak and U are assumed to be
independent (the product’s expectation is equal to the product of the expectations), we have:
Making the variable change υ = t − kT + u and noticing that the integrals for k  
 are
defined on adjacent intervals, we get:
where G (f) refers to the Fourier transform of g (t).
We now calculate {x (t + τ)x* (t)}. Because ak and U are independent:
If we make the variable change υ = t + τ - kT + u and use the expression 
,
we get:
By defining ℓ = (n − k), by using the equality 
 and by noticing that the
integrals for k  
 are defined on adjacent intervals, we have:
If we denote by h (θ) the convolution of g (θ) with g* (−θ), the integral can be written simply
as h (τ − ℓT). This leads us to:
which depends only on τ. x (t) is therefore a WSS process. The Fourier transform of h (τ − ℓT)
is H (f)exp (−2jπℓTf). Because h (θ) = g (θ) g* (−θ), we have H (f) = G (f)G* (f) = |G (f)|2.
If we use the Poisson formula, we infer that:

(6.36)
If we calculate the Fourier transform of the two sides of 
, we then get:
where δ (f − f0) was used to denote the Fourier transform of exp(2jπf0τ). Remember that the
psd is precisely Γ(f) from which the peak 
 at the origin is subtracted, which
leads us to the expected result.
As you can see, the spectrum depends, on the one hand on the chosen pulse, and on the other
hand on the correlations introduced in the sequence {ak} by way of the expression:
This function is periodic with period 1/T. Therefore all we have to do is calculate it on an
frequency interval with a length of 1/T, or by considering the normalized variable u = fT, on an
interval with a length of 1. If the sequence {an} is real, then Sa (f) is an even function, and we
can restrict our calculations to the positive frequencies. Theoretically, Sx (f) has an infinite
support. However, because of the multiplication of the periodic function Sa (f) by the function
|G (f)|2, we can restrict the plotting of Sx (f) to a few length 1/T intervals, since |G (f)|2 usually
decreases fast, typically like 1/f2 for the rectangular pulse. This is why in exercise 6.4, we
only represented the function in the frequency interval (0,1/T), that is to say the interval (0,1)
for the normalized variable u = fT.
Peaks can appear in multiples of 1/T in the case where ma ≠ 0. These peaks can be used to
retrieve the symbol rate by filtering the signal after receiving it.
In the particular case where the sequence ak is a sequence of uncorrelated centered variables
with the same variance 
, 
 for k ≠ 0 and the spectrum’s
expression comes down to:
In the following exercises, we are going to study, through calculation, then through simulation
the coding contribution for two codes of great practical importance: the AMI code and the
HDB3 code. We will see in particular that these codes are such that Sx (f) is null in f = 0. This
is one of the important elements involved in the choice of a modulation, because many systems
“pass” the spectrum’s components very poorly around 0. Also, a zero gain in 0 can possibly
add a continuous components, ensuring the system’s power supply.
Exercise 6.3 (AMI code) (see page 303) In AMI coding, the sequence ak is obtained using the
following coding rule: if the bit dk = 0, then ak = 0 is transmitted, and if the bit dk = 1, then ak

= −1 and ak = 1 are alternately transmitted. AMI stands for Alternate Mark Inversion. We can
check that ak  {−1, 0, 1} is obtained from the dk  {0,1} by using the following relations:
1. Let {dk} be an sequence of random variables, i.i.d. in {0, 1}, with the probability Pr(dk =
0) = Pr(dk = 1) = 1/ 2. Calculate 
 and 
. Use the result to find the
expression:
2. Design a program that calculates the theoretical psd of Sa (f) and compares it with the psd
estimate obtained through simulation. Use the welch function to estimate the psd:
Exercise 6.4 (HDB3 code) (see page 304) In AMI coding, see exercise 6.3, the presence of a
long sequence of zeros can cause the receiver to desynchronize. We then have to make sure
never to transmit more than three consecutive zeros. In HDB3 coding (HDB stands for High
Density Bipolar) solves this problem in the following way: when we encounter a sequence of
four consecutive zeros, the fourth zero is coded as a “1”. To prevent any ambiguity when
decoding, this 1 is coded by violating the alternation rule: this is called bipolar violation.
EXAMPLE: consider the sequence 101100000000000010. Its coding leads to:
bit:
+ 1 0 + 1 + 1 0 0 0 0
0 0 0 0
0 0 0 0
+ 1 0
symb.: + 1 0 − 1 + 1 0 0 0 + 1 0 0 0 + 1 0 0 0 + 1 − 1 0

Locally, this sequence has a mean different from 0. To avoid this local decentering
phenomenon, an alternating rule is applied to the bipolar violation. In order to do this, we have
to introduce a additional variable (pv) that memorizes the bipolar violation.
If p1 denotes the variable used to store the polarity of the last bit coded as “1”, then we have
the following algorithm (see the diagram in Figure 6.11):
1. If the last bit coded as 1 is transmitted with a + polarity, which is memorized as p1 = +1,
then the sequence 0000 is associated with either the sequence 0 0 0 + 1 or the sequence
−100 −1, depending on whether the bit pv = −1 or +, respectively. Then the polarity of pv is
changed, and we redefine p1=pv.
2. In the other case, p1 = −1, the sequence 0000 is associated with either +1 0 0 + 1, or 0 0 0
− 1, depending on whether the bit pv = −1 or +1 respectively. Then the polarity of pv is
changed, and we redefine p1 = pv.
Figure 6.11 – HDB3 coding: processing the four consecutive zeros and updating the bipolar
violation bits
It can be shown that the resulting sequence is centered. The decoding is particularly simple: if
a bipolar violation is encountered, the last 4 bits are set to zero.
1. Starting with the initial conditions pv = +1 and p1 = –1, apply HDB3 coding to the binary
sequence:
0111000010000010
2. Write a MATLAB® function that performs the HDB3 coding of any sequence of bits.
3. With the use of the welch function (see exercise 6.3), perform the signal’s spectrum
estimation based on a sequence of 10,000 symbols and for a rectangular pulse with a
duration equal to the symbol rate.
Exercise 6.5 (Linear equalization of a communications channel) (see page 306) Consider
the double side band modulation with the complex envelope:
The carrier frequency value F0 is not specified since all of the processings will apply to the
complex envelopes of the signals encountered in different places along the transmission line.
Let ak = uk + jvk where the possible values of uk and vk belong to {−3, −1,+1,+3}. This type

of modulation is called Quadrature Amplitude Modulation (QAM).
The received signal is sampled at a rate 1/T. Let {xk} be the sequence of the samples. We will
assume that the channel introduces by filtering an intersymbol interference affecting L = 2
symbols, meaning that:
where wk refers to a white, centered, complex, Gaussian, additive noise. A simple, but not
very effective idea is to invert the filter H (z) = h0 + h1z −1.
1. Represent the constellation associated with this code. Find a Gray code associated with
this constellation.
2. Determine a causal approximation of G (z) = 1/H (z) using a 21 coefficient FIR filter in the
following two cases: h0 = 1, h1 = −0.6 and h0 = 1, h1 = −1.6.
3. Write a program that represents, in the complex plane, the samples that are emitted,
received, and processed by the inverse filter.
6.2.5 The Nyquist criterion in digital communications Expressing
the Nyquist criterion for PAM modulation
Given the digital signal Σk akhe (t − kT), corresponding to a PAM modulation, we are going to
try to determine the conditions that the pulse he (t) has to satisfy so that the emitted signal, once
it has travelled through a B band limited ideal low-pass channel (its complex gain has the
expression 
, then gone through the matched filter with the impulse response
, leads an output with no intersymbol interference at the sampling times. Since the
channel is B band, we can choose a B band limited signal without being any less general. In
that case the received signal can be written:
where ak refers to a sequence of symbols from the alphabet {−(M − 1), …, −3, −1, +1, +3, …,
+(M − 1)}. If we assume that 
, and calculate the Fourier transform, we
get:
Hence, if P (f) is B band limited, that is if P (f) = 0 for |f | > B, then he (t) is B band limited
itself. This condition precisely expresses the constraint that has to be satisfied if the channel is
B band limited. If y (t) now refers to the output signal of the matched filter2 with the impulse
response 
, then we can write:

(6.37)
(6.38)
(6.39)
where b (t) represents the noise w (t) after it has been filtered. The samples taken from the
sampler’s output at the times nT then have the expression:
The first term is directly related to the symbol an emitted at the time nT. The second one
represents the contribution, at the sampling times, of all the symbols emitted other than an. This
term is called the InterSymbol Interference.
A situation of particular practical importance is the one where p (t) satisfies the two following
conditions, called the Nyquist criterion:
1. P (f) = 0 for |f | > B, where B refers to the channel’s bandwidth;
2. p (kT) = 0 for k ≠ 0.
According to the Poisson formula, condition 2 is equivalent to:
This expression means that the algebraic sum of the spectra shifted by 1/T, 2/T, etc. is equal to
a constant. If we introduce the symbol rate R = 1/T, we can determine a necessary condition for
the Nyquist criterion to be satisfied on a B band channel. This condition is expressed:
Let us examine how the Nyquist criterion leads to a simplified decision rule. If p (t) satisfies
the Nyquist criterion, then the expression (6.37) giving y (nT) can be simplified and we have:
Because y (nT) only depends on one symbol, and because it can be shown (you can do it as an
exercise) that the noise samples are independent, since they are uncorrelated and Gaussian, the
decision can be taken symbol by symbol simply by comparing y (nT) to thresholds.
What we did is start out with a transmission system designed for a pulse he (t) such that 
 verifies the Nyquist criterion, and in the end, the reception set is
composed of:
– a matched filter with the impulse response 
;
– a sampler at the rate T;
– and a symbol-by-symbol decision-making system that compares the sample with
thresholds.

(6.40)
(6.41)
Figure 6.12 – Diagram of the receiver
For example, with an PAM modulation with four symbols {–3, –1, +1, +3}, the decision rule is
as follows:
When the ISI is low but not completely non-existent, we can still use symbol-by-symbol
decision. To explain what a low ISI means, we have to go back to expression (6.37). The most
unfavorable case concerning the use of symbol-by-symbol decision occurs when all the
symbols other than an interfere destructively with the amplitude anp (0). For example, if an = 1
and p (0) > 0, all the other symbols assume the value ± (M − 1) causing each contribution to be
negative. This leads us to the following definition on how to measure the level of ISI, also
called the maximum ISI:
If D is close to 0, the ISI is low and the symbol-per-symbol detector will yield excellent
results. Otherwise, optimal processing requires a more complex algorithm called the Viterbi
algorithm (see page 211) that takes into account all of the received symbols. In section 6.2.6
we will discuss another tool for evaluating the ISI called the eye pattern.
The raised cosine Nyquist function
We are now going to define a set of real functions he (t) depending on one parameter, and such
that 
 satisfies the Nyquist criterion. These functions play a major
practical role. Consider the function:
where the parameter α  (0,1) is called the roll-off factor.

(6.42)
(6.43)
It can be shown by way of a long calculation that 
 satisfies the Nyquist
conditions, meaning that p (kT) = 0 for k ≠ 0 and P (f) = 0 for |f | > B with:
Theoretically, he (t) has an infinite duration. However, the function quickly becomes
evanescent, and we can maintain satisfactory properties if we truncate the function to keep
about a dozen lobes around 0.
The racnyq.m function generates the samples of he (t) based on the roll-off factor alpha the
number of lobes nblobes remaining to the right and left of 0, as well as the number of samples
Npts on the interval with a duration T. Save this function as racnyq.m:
A long but not at all difficult calculation shows that:
with α  (0, 1). P (f) is called a raised cosine function.
Let us now check numerically that the function p (t) satisfies the Nyquist criterion. Let R = 1/T
= 1,000 symbols per second and B = 600 Hz (this way we have B > R /2). Hence, according to
(6.42), α = 2B/R− 1 = 0.2. To perform the computation, we will take 10 points per symbol
time T and truncate he (t) down to about 20 lobes around 0. The convolution 

 is obtained using the MATLAB® function conv. p (t) and its Fourier
transform are plotted for 1,024 frequency points. To do this, type:
The results are shown in Figure 6.13. As you can see, the function p (t) is null for every
multiple of T, except at the origin, and the spectrum is B band limited, meaning that P (f) = 0
for |f | > B = (1 + α)/2T.
Figure 6.13 – A raised cosine function satisfying the Nyquist criterion
6.2.6 The eye pattern
As we have said before, the receiver shown in Figure 6.12 is so simple because of the absence
of ISI. This is why it is essential to have access to a practical tool for measuring its level. We
have already given on page 198 a quantitative definition, with equation (6.40), of the maximum
ISI, and we are now going to present another very important tool, called the eye pattern, for
reasons that will be obvious if you refer to Figure 6.14.
The eye pattern is obtained by superimposing a large number of trajectories, with durations 2T,
of the matched filter’s output signal. It can be displayed on an oscilloscope by synchronizing
with the symbol rate 1/T. The afterglow of the screen makes it possible for the superposition to
persist. In the presence of noise, as we are going to see, the wider the eye is vertically, the
lower the error probability. Therefore, we have to choose the decision time where the eye is
vertically “widest”.
In the following exercise, we are going to generate a complete simulation line for 2-PAM

modulation, in the form of five different programs. We will examine the eye pattern and choose
the optimal sampling time. All the computed values are saved as we go along, so they can be
used as input data for the next program.
Exercise 6.6 (2-PAM modulation) (see page 308) Consider a PAM modulation with two
levels {−1, +1}. The binary rate is equal to 1,000 bps. The signal’s expression is:
To display the signal as if it were time-continuous, choose Fs = 20 kHz as the sampling
frequency.
1. Write a program that computes the samples xe of the signal xe (t) for a random sequence of
300 bits. Display part of the chronogram of xe (zoom xon). Save all of the values.
2. Write a program that generates and displays the received signal xr. To simulate a
transmission channel, use a low-pass filter hc (t) the impulse response of which is
obtained by hc=rif(lhsT*NT−1,bc) with lhsT=3.5 and bc=0.06, and where NT refers
to the number of points corresponding to the time interval between two symbols. Therefore
the channel’s response stretches out over 3.5 symbols
3. Let h (t) = (hc * he)(t). The receiver’s matched filter therefore has the impulse response h
(−t). The matched filter’s output signal is denoted by xa. Write a program that
superimposes the “sections” of xa lasting a duration of two “symbol periods” so as to
display the eye pattern. The program will have to be designed so that the time coordinate
of the place where the eye is vertically “widest” can be interactively defined as input data.
You can use the function ginput.
4. Write a program that displays the matched filter’s output signal xa and superimposes the
values taken from the sampler’s output.
5. Write a program that, based on the value of the signal-to-noise ratio, expressed in dB:
– adds a white, centered, Gaussian noise with the power Pb to the received signal xc;
– decides that the bit is equal to 1 if its value at the sampler’s output is positive and 0 if
it is not;
– and evaluates the error probability.
In exercise 6.6, the overall impulse response ensures that the ISI is low enough for the symbol-
by-symbol decision to yield good results. The low level of interference is clearly shown by the
eye pattern without noise represented in Figure 6.14. The trajectories almost converge to the
same point at multiples of T. Therefore, if the sampling is done at these times, the values
located around 1 are likely to correspond to the transmission of a bit 1.
Convergence of the trajectories

Figure 6.14 – PAM-2: eye pattern without noise
6.2.7 PAM modulation on the Nyquist channel
We are now going to present a sequence of programs designed to simulate a PAM modulation
on the Nyquist channel. The following sections describe in this order:
– the generation of symbol sequences;
– the generation of the emitted digital signal;
– the addition of noise by the channel;
– matched filtering and the examination of the eye pattern;
– symbol-by-symbol decision.
Generating the sequence of symbols
The gsymb.m function generates a sequence of N symbols taken from the alphabet {−(M − 1),
…,−3, −1, +1, +3, …, (M − 1)} with M = 2m. Save this function as gsymb.m:
Generating the receiver filter’s output signal
We are going to try to numerically compute the sample at the rate Ts = T /NT of the signal xe (t)
= ∑k akhe (t − kT). NT represents the number of samples per symbol duration T. These samples
can be used for creating the continuous-time signal using a digital-to-analog converter. In this
case, these samples will be used for the display. They have the expression:

The samples of he (t) taken at the rate Ts can be obtained with the use of the racnyq.m
function. The function he (t) can be truncated down to about 30 lobes around 0. If we choose a
high enough value for NT, the resulting plot of xe (t) is “almost continuous”. To calculate the
samples of xe (t), we can use the diagram explaining the principle, from Figure 6.15, drawn for
NT = 4.
Figure 6.15 – Constructing the signal transmitted based on the symbols and the polyphase
components of the emission filter in the case where NT = 4
If we let n = ℓNT + r, where r = 0, …, NT − 1, then we indeed have:
If we let 
, and 
, then we can write:
The component 
 is called the r-th NT-polyphase component. It is obtained by filtering the
sequence ak by the filter with the impulse response 
 obtained by undersampling the
sequence he (mTs) by a factor NT In MATLAB®, given a sequence he of the coefficients of he
(t), the filter with the impulse response 
 is obtained simply by typing:
In Figure 6.15, we chose a response he (t) with 18 non-zero coefficients. The number of
samples per symbol is NT = 4. The transmitted signal is obtained by superimposing the 4
shifted components.
The roll-off expression of α is obtained with relations (6.32) and (6.42):
Once the samples of xe (t) have been generated, a noise is added by setting the signal-to-noise
ratio. The noised signal is filtered by the filter with the impulse response he (−t). y (t) is the

resulting signal. The following program computes the samples of y (t) and displays the result
of the superimposing the trajectories with a duration of 2T:
By superimposing portions of trajectories with a duration 2T, that is to say 2NT points, we get
the eye pattern shown in Figure 6.16. If M refers to the alphabet size, then there are (M − 1)
eye apertures. In the case of a non-ideal channel, the trajectories no longer have the shapes
shown here. In particular, they no longer perfectly converge in at the multiples of T, which is
imposed by the Nyquist criterion.

Figure 6.16 represents the eye pattern for M = 4 (number of bits per symbol = 2), a rate of
1,000 bps, and a spectrum support of 300 Hz, hence α = 0.2.
Figure 6.16 – The eye pattern for M = 4. The noise is null Spectrum support B = 300 Hz,
rate 1,000 bps
Figure 6.17 shows the same eye diagram for M = 4, but for a spectrum support of 500 Hz,
hence α = 1 The vertical opening at the times kT is the same as before. In terms of probability,
the performances are the same. However, if the sampling time is slightly shifted, the vertical
opening becomes wider at that time for the 500 Hz. The error probability will be smaller. To
put it more simply, the vertical opening guarantees a better resistance when the sampler is
desynchronized.
Figures 6.18 and 6.19 show the eye pattern for a signal-to-noise ratio of 15 dB.
If we “place ourselves” in the center of the eye, and set the thresholds to the values −2, 0 and
2, the error probability has to remain very small, which is checked with the following
program. Type:
Figure 6.17 – Eye pattern for M = 4. The noise is null. Spectrum support B = 500 Hz, rate
1,000 bps
Figure 6.18 – Eye pattern for M = 4. The signal-to-noise ratio is equal to 15 dB, the
spectrum support is B = 300 Hz and the rate 1,000 bps

(6.44)
Figure 6.19 – Eye pattern for M = 4. The signal-to-noise ratio is equal to 15 dB, the
spectrum support is B = 500 Hz and the rate 1,000 bps
The program estimates the error probability Ps per symbol. If the signal-to-noise ratio is
high, we can consider that the only errors are caused by a decision in favor of one of the two
symbols adjacent to the symbol actually transmitted. Therefore, if we are using a Gray code,
these adjacent symbols only cause one false bit over the m = log2(M) emitted bits, leading us
to the following formula, which gives us the relation between the probability per symbol Ps
and the bit error rate BER:
With this program, we can also test the error probability increase when the sampling time is
shifted. All we need to do is modify the variable t0. We have to check that this increase
becomes greater as the chosen band becomes narrower. However, when we are right in the
center of the eye (where the trajectories converge in the absence of noise), the error
probability is independent of the value of B.
6.3 Linear equalization and the Viterbi algorithm

(6.45)
(6.47)
(6.46)
Consider the case of the binary baseband modulation that associates the continuous-time
signal xe (t) = ∑k akhe (t − kT) with the sequence {dk} of binary elements {0 1} according to
the following rule: if dk = 0 then ak = −1 and if dk = 1, then ak = 1. The signal he (t) refers to
the impulse response of the emission filter. The signal xe (t) is filtered by the transmission
channel and is subjected to additive noise. The received signal can then be written xr (t) = ∑
akh (t − kT) + w (t) where h (t) is obtained by convoluting the filter he (t − kT) with the
channel filter, and w (t) is the noise. When the signal is received, it is filtered by the matched
filter then sampled. The result is a sequence of values xa (n), the expressions of which linearly
depend on the sequence ak of the type:
The term b (n) accounts for the noise, which is assumed to be Gaussian. Without being any less
general, we can assume that b (n) is white. If it is not, we know that there exists a causal filter
that can make it white. This filter changes the values of the coefficients g (k), but the general
form of expression (6.45) stays the same. The variance of b (n) is denoted by 
.
The coefficients g (n) take into account the emission filter, as well as the channel filter and the
receiver matched filter. From now on, the sequence g (n) is causal and has a finite duration L.
This hypothesis is actually quite realistic. The only problem is that the complexity of the
processes increases with L. Remember that we have already discussed the case where k ≠ 0:
this is the case where the ISI is equal to 0
In the end, we can describe the digital transmission line as a “black box”, with the sequence of
symbols a (n) (  {−1, 1}) as the input, and as the output the sequence of real values given by
the expression:
The choice of the likeliest decision sequence is based on the observations xa (n) for n  {1,
…, N}. In the example we are going to discuss, we have chosen L = 3.
In practice, the emission and reception filters are known, whereas the channel filter is not. We
have already said that in order to measure the quantities g (k), we could then use a set
sequence of symbols called the training sequence. From now on, we will assume that the
values of g0, g1, …, gL−1 are known. If we then use the Gaussian distribution of the sequence b
(n) and expression (6.46), the probability density of the observed sequence {xa (1), … xa (N)}
can be written:
with 

(6.48)
where we have assumed that a (0) = a (−1) = −1. Based on the N observations {xa (1), …, xa
(N)}, the maximum likelihood rule consists of finding the sequence {a (1), …, a (N)} that
maximizes pX (x; a1,…, aN), that is to say the sequence that minimizes the quantity:
Theoretically, there are 2N possible sequences and we could just bluntly compute the 2N values
of ℓ ({xa}, {a}) for the observed sequence {xa (1), …, xa (N)}, and choose the sequence a that
leads to the minimum.
The Viterbi algorithm makes it possible to cut down to N × 2L the number of values that have to
be calculated. Before we present this algorithm, we are going to study a simpler, but
suboptimal process.
6.3.1 Linear equalization
The first idea consists of using the filter with the impulse response w (n) that inhibits the effect
of the channel {g0, g1, g2}. This is called equalizing the channel and the filter w (n) is called
an equalizer. There are two common approaches:
– The equalizer is chosen so that, in the absence of noise, it completely eliminates the
intersymbol interference. This is called Zero Forcing.
– The equalizer is chosen so as to minimize, in the presence of noise, the square deviation
between the original signal and the signal after it has been equalized. This is called the
Wiener equalization. It requires for the noise’s variance  to be known. The expression of
its complex gain is given by:
Obviously, in the absence of noise (σb = 0), the two solutions coincide.
Exercise 6.7 (“Zero Forcing” linear equalization) (see page 309) In the absence of noise, the
Zero Forcing equalizer eliminates the ISI. Its transfer function is W (z) = 1/G (z) with G (z) =
g0 + g1z−1 + g 2z−2. If G (z) has its zeros inside the unit circle, the solution is stable and
causal. Otherwise, the stable solution has a non-causal impulse response. It is possible to
implement it by approximating it with a finite delay (see exercise 6.5).
Because G (z) is a polynomial, that is to say a filter with a finite impulse response, the series
expansion of W (z) has an infinite number of coefficients and hence the filter has an infinite
impulse response. In practice, it is often approximated by a filter with a long enough finite
impulse response. Here we are going to design the filter W (z) = 1/G (z) in its exact form using
the MATLAB® function filter, which is possible only if G (z) has all its zeros strictly inside
the unit circle.

(6.49)
(6.50)
(6.51)
1. Using equation (6.46), show that the output signal y (n) of the equalizer W (z) can be
expressed as y (n) = a (n) + u (n), where u (n) is a noise.
2. Let g0 = 1, g1 = −1.4 and g2 = 0.8. Notice that the zeros are inside the unit circle, and
therefore the equalizer w (n) is stable and causal. Determine the variance of u (n). You can
use expression (6.49):
3. Use the result to find the probability distribution of y (n) when a (n) = −1 and when a (n) =
+1.
4. Given the previous, we have come up with the following rule: if y (n) is positive, then the
decision is that a (n) = 1, and otherwise the decision is that a (n) = −1. Determine the
expression of the error probability.
5. Write a program that:
– generates a random binary sequence, made up of −1 and +1, with a length N;
– filters the resulting sequence by the filter with the impulse response gc =[1 −1.4 0.8];
– adds a Gaussian noise with a variance σ2 such that the signal-to-noise ratio is equal
to R dB;
– passes the obtained signal through a filter with the transfer function W (z) = 1/G (z);
– compares the equalizer’s output to the threshold 0 to decide what symbol was
transmitted;
– evaluates the number of errors (bear in mind that for the evaluation to be relevant,
about a hundred errors have to be counted, hence N must be chosen high enough);
– compares the results with the theoretical plot.
Exercise 6.8 (Wiener equalization) (see page 311) Consider again equation (6.46):
a (n) is assumed to be a sequence of equally distributed i.i.d. random variables with possible
values in {−1, +1}. This means that 
 and that 
.
We wish to find a filter with a finite impulse response w (n), with a length N, that minimizes
the square deviation:
where â(n) = x (n) * w (n) refers to this filter’s output. This filter is an example of the Wiener
filter. d is a positive integer that accounts for the fact that a delay is required, because if the
filter h (n) is not minimum phase, then we know that the stable inverse is not causal. In

practice, a delay must therefore be introduced to obtain a proper causal approximation.
1. Determine, as a function of the autocovariance function Raa (k) of the sequence a (n) and of
the covariance function Rax (k) between a (n) and x (n), the filter w (n) that minimizes
(6.51).
2. Determine the expression of Rax (k) as a function of Raa (k), and the expressions of g
(k)and of the autocovariance function Rbb (k) of the noise b (n).
3. Write the problem in matrix form. Determine the solution’s expression.
4. Write a program that performs the equalization.
5. Write a program that uses the equalized output and applies symbol-by-symbol decision.
Compare the results, in terms of error probability, with those obtained with the Zero
Forcing equalizer.
6.3.2 The soft decoding Viterbi algorithm
As we said, based on the N observations, we have to calculate the 2N quantities:
corresponding to the 2N length N binary sequences. Let us assume that, initially, a (0) = −1 et a
(−1) = −1. Let s (n) = [a (n − 1) a (n − 2)]T be the size 2 vector constructed by concatenating
two consecutive symbols. In our case, s (n) can only assume four different values, denoted
symbolically by {00, 01, 10, 11}.
Let us calculate the probabilities for s (n + 1) to be equal to 00, 01, 10 and 11, respectively,
knowing that s (n) = 00. If s (n) = 00, the only possible states for s (n + 1) are 00 if a (n) = −1
and 10 if a (n) = +1. Therefore:
The probabilities of s (n + 1) with respect to the three other values of s (n) can be calculated
in the same way and represented by Figure 6.20.

Figure 6.20 – Transition probability graphs for the four states depending on the input
symbol
The probabilities can be grouped together in a transition matrix:
representing the state transition probability for two consecutive times. This description of the
evolution of s (n) is called a Markov, or Markovian model. The Markovian property is what
makes it possible to use the Viterbi algorithm. Consider again the expression we wish to
minimize, and let g = [g1 g2]T. We are going to use the definition of s (n). If we stop the
computation at step p, we get:
From now on, the quantity d(s (p),p) will be called the path metric (a (1), …,a (p)) at step p.
Let us assume that at step p, we still have four sequences (a1, …, ap) competing each other
ending with s (p) equal to 00, 01, 10 or 11 respectively and with the metric d (00,p),d (01,p), d
(10,p) and d (11 p) respectively.
In order to calculate the metric of the sequence (a (1), …, a (p + 1)), we then have to write the
positive term (x (p + 1) − g0a (p + 1 − g Ts (p + 1)2 for the two possible values of a (p + 1),
that is to say −1 and +1. Hence each state has two possible children. We will therefore have to
calculate, as functions of the observation xa (p + 1) at the time (p + 1), 8 values that lead to one
of the four possible states. These calculations are summed up in the following table:
Notice that there are two ways of ending up in each state. For example we end up in s (p + 1) =
10 either by starting in s (p) = 00, if we choose a (p + 1) = 1, either by starting in s (p) = 01, if

(6.52)
(6.53)
(6.54)
(6.55)
we choose a (p + 1) = 1. These two possibilities correspond to the two values v (00,10) and v
(01,10) respectively. It is useless to keep the largest one of the two, since any further value
will have a higher metric. Hence d (10, p + 1) = min(v (00,10), v (01,10)).
In the end, the algorithm calculates, at step p + 1:
At each step, all the parents leading to the smallest metric have to be memorized. For example
if the minimum of d (00, p + 1) is obtained for d (01, p) + (xa (p + 1) − (−g0 − g1+ g2)2), at it
will be memorized as the state 00 at the time p that leads to the state 01 a), the time p + 1. The
same is done for the three other states. The initial values are calculated based on the fact that
we have assumed a (0) = a (−1) = −1, that is to say s (0) = 00. This means that when the first
symbol is transmitted, either the state 00 or the state 10 is reached, and therefore:
We then infer that:
Obviously, the intermediate metrics do not need to be memorized. Only the four current ones
have to be. Hence, formulae (6.52) to (6.55) have to be used as updating formulae for the four
states reached at the considered state. The algorithm stops at the end of the length N
observation sequence. Then the sequence considered to be the most likely is the one that leads
to the state with the smallest metric. The sequence of states is determined by going back up the
table of parents corresponding to this sequence. Once the sequence of states has been obtained,
we simply compute the symbol sequence. The viterbi.m program determines the emitted
sequence using the Viterbi algorithm. The results are given in Figure 6.21. The plot (‘o’)
represents the error probability when using the Viterbi algorithm. The plot (‘×’) reproduces the
results provided by the program from exercise 6.5 (a Zero Forcing equalization followed by a
symbol-by-symbol threshold detection) by typing, after running it:

As you can see, the Viterbi results are much better than the ones obtained by linear
equalization.
Figure 6.21 – Comparing the error probabilities as functions of the signal-to-noise ratio in
dB. Plot (‘×’): zero forcing linear equalization. Plot (‘o’): Viterbi algorithm. Results
obtained through a simulation with a length of 5,000. The channel filter has the finite
impulse response (1 − 1.4 0.8)

6.4 Compression
6.4.1 Scalar Quantization
The scalar quantization of a random quantity X consists of partitioning R in n sub-intervals:
and of defining a sequence {µl,…, µn} of real values. From then on:
– the coding process associates x, the value assumed by the random variable X, with the
index k of the interval to which the word belongs, that is associates k with x if x  Ik;
– the decoding process associates the index k with the value µk.
The value µk can be called either the code word or the representative element of the interval
Ik, or simply the reconstruction value. The set of code words is called a codebook.
Hence you can see that the coding consists of associating the value x with the adress of one of
the words in the codebook. In practices, the codebook size n is often chosen equal to a power
of 2, that is n = 2N, and the memory addresses are then written using N bits.
The linear quantization of a signal is the simplest case of scalar quantization: all of the n
intervals, except for the first one and the last one, are chosen with the same length q, and the
representative elements are taken from the middle of the interval. Coding amounts to testing
whether x belongs to one of the n intervals of the type (kq − q /2, kq + q /2) and to transmit k

(6.56)
(6.57)
(6.58)
Mathematically, these two operations, coding and decoding, are summarized by the
application:
What this actually means is that no difference is made between all the elements of the interval
Ik and the code word µk. In this context, coding improves as the distorsion caused by these
operations grows fainter, for a given number n of intervals. Of course, for the elements close to
µk, the error is small. On the other hand, for the elements far away, the error is high. Hence it
is best to have intervals of small length for the most frequent values of x and to let the intervals
be longer for the less probable values. We are now going to give a mathematical expression for
this relation.
The problem is to find, based on a probability distribution of X known beforehand, the best
partitioning and the best representative elements with respect to a given criterion of distorsion
between X and µ (X). In the search for a solution, the pioneers are undoubtedly Lloyd and Max,
and the reader can look up the famous reference [13,15].
We will give here the solution in the case where the criterion that has to be minimized is the
square deviation defined by 
, and the expression of which is:
where pX (x) refers to the probability density of X. The problem consists of determining the (2n
− 1) values a1 …, an−1, µ1, …, µn that minimize J ({ak},{µk}). This solution can be obtained
by setting to zero the partial derivatives of J with respect to the ak and the µk. This leads to a
system of equations which, once simplified, can be written:
The first expression simply means that the interval Ik is the set of points closest to µk. And
according to the second one, µk can be interpreted as the barycenter of the interval Ik
weighted by pX (x).
Unfortunately, the expressions 6.57 generally do not lead to a simple analytical form for the
quantities a1, …, an , and µl, …, µn. Numerical methods can then be used, such as the gradient
algorithm, the general form of which is:
where θ refers to the parameter for which we want to determine the numerical value that
minimizes the criterion J (θ). The index p refers in this case to the p-th iteration. The positive

(6.59)
(6.60)
(6.61)
number λ is the gradient step.
In our case, the parameter we have to determine is θ = (a1,…, an−1, µl,…, µn)T, which is
comprised of (2n −1) values. Using 6.56, we can infer the (2n −1) component expression of the
gradient:
with:
If pX (x) is a Gaussian distribution, the second relation of the system 6.60 can be numerically
evaluated using MATLAB® with the erf function. The following program implements the
gradient algorithm 6.58:
For n = 4 and σ = 1, the program returned:
In the case of a centered, Gaussian random process with the variance σ2, all we have to do is
multiply these values by σ. As we have already said, the gradient method converges slowly
and the calculation time is long. However, it can be shown that, if the function log(pX (x)) is
strictly concave, the function J has only one minimum.
6.4.2 Vector Quantization
Introductory Example
The vector quantization problem is formulated in the same way as the scalar quantization. The
difference is that we now wish to code length m vectors instead of real scalars. Hence we have

to determine the best way of partitioning 
m in n regions and associate each one of these
regions with the best representative element.
The simplest idea consists of coding the m components separately, using scalar quantization.
Consider, for example, the case where m = 2 and where four bits are used to code a point of 
2. We can allocate two bits to each of the vector’s two components and then code each of the
two components using two-bit scalar quantization. But we can also try to directly code the
point in 
2 using four bits. We are going to see, with an example first, that this second method
can be better.
To obtain a sequence of correlated vectors we consider the AR-1 process defined by the
equation s (n) +as (n − 1) = w (n), where |a | < 1 and where w (n) is a centered, Gaussian,
random sequence with the variance σ2. We are going to use the following representation: based
on the signal s (n), we construct the two component vector s2 (p) = [ s (2p − 1) s (2p) ]T
obtained by grouping together the two consecutive samples of s (n). The following program
displays a sequence of 1,000 values of s2 (p) in the form of a scatter in 
2. The results are
shown in Figure 6.22. The correlation found in the AR-1 process reveals itself by the elliptical
shape of the scatter.
with [2]:
Coding the vector s2 (p)  
2 using four bits means that we have to partition 
2 in 16 regions.
In the case where the two components of s2 (p) are coded separately using two bits, this
partition is made of rectangular regions with their sides parallel to the axes. This is shown in
Figure 6.22(a). The positions of the boundary lines are determined by the optimal values of the
2-bit scalar quantization of a Gaussian random variable, provided by 6.61.

Figure 6.22(b) also shows a partition based on 16 other regions, which takes more into account
the elliptical distribution of the points in the plane. The regions are delimited first by the
ellipse’s major axis and second by the eight lines parallel to the minor axis located in scalar
positions indicated by the 3 bit Lloyd Max algorithm.
Figure 6.22 – Two partitions of the plane in 16 regions (four bits are used to code each
representative element of the corresponding region)
Another idea consists of whitening the two components of the sequence s2 (p) so as to
transform the elliptical scatter into a circular scatter. This operation is achieved by applying a
square root of the inverse of the covariance matrix:
to the sequence of vectors s2 (p). Note that the operation suggested here does not decorrelate
the vectors that are transformed, only their two components. In plainer terms, if we use the
notation t2(p) = Ms2(p), where M is the modal matrix, 
 is diagonal but 
.
In practice, the matrix R can be estimated, from the length N sequence s (n) (and therefore the
length of s2(p) is equal to N /2), as follows:
We then obtain a sequence of vectors 
 the two components of which are
uncorrelated. We can then perform the 2-bit quantization of each of the two components. You
can check by typing:
As an exercise, you can perform a simulation on 1,000 values and compare the square

(6.63)
(6.62)
deviation of these three quantization rules by choosing as representative elements the points
located in the center of these regions.
The last method which, after estimating the covariance matrix, whitens the two components,
can be extended to a higher number of components. This method can also be generalized to any
form of transformation that tends to perform a decorrelation of the data. This is the case for
example of the discrete Fourier transform, of the discrete cosine transform. The coding can
then be performed component by component in the transformed region: in this context, this is
called transform coding [19].
Voronoi Regions and Centroids
We now come back to the problem of determining the best partition and the best representative
elements in vector quantization. Let:
be the partition of the observation space 
m in n disjoint regions and:
the codebook of the n representative elements (Figure 6.23) where µk is the element in 
m that
replaces every point of the region Rk.
Let us assume that the probability distibution of the vector observation X, with possible values
in 
m, has a probability density denoted by pX (x). Then the mean square deviation has the
expression:
Figure 6.23 – Partition R of the plane
where 
 represents the euclidean-norm of the vector v. The goal is to minimize 
with respect to 
 and . This can be performed numerically, by repeating the two following
operations:
1. We start with n representative elements , and find the n regions that minimize 
;
2. Once the n regions have been determined, we find the n new representatives that minimize 
.

(6.64)
(6.65)
After each step, 
 becomes smaller. The two operations are iterated until 
reaches a value deemed small enough. It is unfortunately possible with this algorithm to end up
at a local minimum. Let us examine these two operations in detail:
1. If  is set, minimizing 
 with respect to 
 amounts, according to expression 6.63, to
assigning to Rk all of the points of 
m such that:
The regions defined by such a partition are called Voronoi regions. This concept can of
course be extended to other distances, not just the basic euclidean distance.
Figure 6.24 shows the Voronoi regions for a set of points of 
2 when the distance used in
the euclidean distance. In this case, we start with the set of representative elements, and the
lines delimiting the regions are simply defined by the perpendicular bisectors of the line
segments formed by the pairs of these points. The points belonging to the perpendicular
bisectors can indifferently be assigned to either one of the adjacent regions.
2. If 
 is set, and under sufficient regularity conditions, 
 can be minimized with
respect to  by setting to zero the partial derivative of 
 with respect to µk. This leads
to:
Figure 6.24 – 
 partition by the perpendicular bisectors
The point in 
m defined by the expression 6.65 is called the centroid of the region Rk for
the ditribution with the probability distribution pX (x).
In practice, the probability distribution of the observation X we wish to code is unknown, and
therefore it probability density pX (x) even more so. However, the latter can be estimated
based on a set of outcomes. This leads us to the algorithm presented in the following section.
LBG Algorithm
The LBG algorithm, named after its creators Linde, Buzzo and Gray (see reference [12]),
allows us to determine the n best representative elements of an unknown distribution based on
a set of N outcomes called a training set:

(6.66)
(6.67)
In practice, N 
 n. Replacing the unknown probability distribution pX (x) with the histogram
of the values is equivalent to assigning the same probability 1/N to every observation. If we
then replace this in 6.65, we get:
where Nk refers to the number of points in the region Rk. Using this result, we can implement
the following algorithm. We start with an initial codebook  of n centroids {µl, …, µn}
belonging to 
m, then successively perform the following operations:
1. construction of the n Voronoi regions associated with the n centroids, that is to say the
partition of the set  in n subsets containing the points closest to the µk;
2. computation, based on expression 6.66, of the n new corresponding centroids;
3. stopping criterion: if the n new centroids are “close” enough to the previous ones, the
algorithm stops, otherwise, it picks up at step 1.
It can be shown that the estimated square deviation, defined by:
decreases after each iteration and that the algorithm converges to a local minimum.
On the other hand, this algorithm poses two problems related to the initialization: first, we are
not sure that the algorithm converges to the global minimum, and second, empty spaces can
appear while the algorithm is running. To avoid these problems, the LBG algorithm has the
following efficient initialization procedure:
1. the centroid is calculated for the set of the whole training sequence;
2. based on each centroid, two points are constructed by a small shift in two opposite
directions. As a consequence, the number of points is doubled;
3. the Voronoi regions, associated with the set of previously obtained points, are determined,
as well as their respective centroids;
4. the algorithm goes back to step 2 until a set of n centroids is obtained. The resulting
codebook size is a power of 2.
The voronoi.m Function
The voronoi.m function determines the n Voronoi regions associated with the codebook C. It
returns the vector indR that contains, for each element of the training sequence x, the number of
the region to which it belongs.

The centroides.m Function
The centroides.m function determines the n centroids (matrix C) based on the training
sequence along with the number of the region to which each of its elements belong. It returns
the value of the square deviation E given by expression 6.67.
The initlbg.m Function
The initlbg.m function determines an initial size n codebook based on the training sequence
x. The value delta sets the shifts in the direction (1, 1, … , 1) and in the direction (−1, −1, …,
−1).

Implementing the LBG algorithm
The 1bg.m function implements the LBG algorithm and returns a size n codebook, based on the
training sequence x. This function also returns the initial codebook produced by the function
initlbg.m as well as the decreasing sequence of values of the square deviation. The length of
E gives the number of iterations needed to reach the minimum.
Example 6.3 (Applying the LBG function) We are going to use the lbg.m function to find the
four representative elements of a centered Gaussian distribution with the variance 1. Type:

Through simulation, we found, values for Cf such as:
This result is in agreement with the values µ4 = −µ1 = 1.5104 and µ3 = −µ2 = 0.4528 obtained
by numerical resolution of the Lloyd-Max equation (see page 222).
The Codebook Size Problem
Let us assume that we have to code the elements of 
m using 20 bits. A direct application of
vector quantization leads to the creation of a 220 ≈ 1000000 word codebook. If this number is
too large for the considered application, we can, at the cost of an acceptable performance loss
(see exercise 6.9), break the 20 bits down to two or more smaller sub-codebooks. For
instance, if the 20 bits are broken down to two sets of 10 bits, two codebooks have to be
created, each one containing 210 ≈ 1000 words. An illustration of this method is given by the
vector quantization of the prediction coefficients in a speech coder
The MELP coder (Mixed Excitation Linear Prediction) converts speech sampled at 8,000 Hz
into a sequence of binary symbols flowing at a rate of 2,400 bits per second. As the name
implies, the coder performs a linear prediction analysis on 10 coefficients every 22.5 ms.
Therefore, it has at its disposal 2400 × 22.5 10−3 = 54 bits to code a frame. 25 of these 54 bits
are assigned to coding the 10 prediction coefficients. A direct application of vector
quantization would lead to producing a 225 ≈ 32,000,000 word codebook in 
10. Obviously,
this is infeasible. Instead, the solution consists of creating several nested codebooks. The
principle can be explained, without being any less general, by first considering a vector coding
using 6 bits. A direct construction would then consist of using a dictionary of 26 = 64 elements.
Instead, and at the cost of an acceptable performance loss, we can construct a first dictionary
of 4 representative elements, therefore coded using 2 bits, then code the distance between the
vector to be coded and the representative element using the 4 remaining bits with a single
dictionary of 24 = 16 representative elements. Thus, the set of two dictionnaries is now only
comprised of 16+4 = 20 representative elements instead of 64. To get a better idea, imagine a
first partition of the space in 4 regions, then each region is partitioned in an identical way in
16 sub-regions. All we need to do when decoding is concatenate the value of the value of the
representative element associated with the first two bits and the value of the representative
element associated with the last 4 bits. The solution chosen for the MELP coder uses 4 sub-
codebooks with the sizes 27 = 128, 26 = 64, 26 = 64 and 26 = 64, respectively, for a total of
only 320 words to code the vector of the 10 prediction coefficients using 25 bits.
Exercise 6.9 (Performances with two sub-codebooks) (see page 315) Consider the AR-1
process s (n) defined by the recursive equation:
where a = 0.9 and where w (n) is a centered, Gaussian random sequence with a variance equal

to 1. The “vector” signal s2(p) = [s (2p − 1) s (2p)]T is reconstructed from the signal s (n) by
grouping together two consecutive samples of s (n). We wish to code s2(p) using 6 bits.
1. Write a program that generates the length N = 5000 sequence s2(p) then constructs a
codebook of 26 = 64 representative elements with the use of the 1bg.m function.
2. Using the same sequence, construct two sub-codebooks with 22 = 4 and 24 = 16
representative elements, respectively. Compare the performances. Bear in mind that the
computation can take up to a few minutes on a standard computer. However, this usually is
not a problem since the computation is done once and for all before the use of the
codebooks.
Image Applications
To illustrate the performances of the LBG algorithm, we are now going to discuss the example
of the compression of an image defined in levels of gray. We are going to start with the size
(256 × 256) image of Lena, and cut it up into T “thumbnails” of m pixels. If we want to code
each thumbnail using b bits (hence b /m bits per pixel), we have to find 2b representative
elements. The following program applies the lbg.m function to the T thumbnails.

If m = 1 and b = 1, this is equivalent to coding each pixel using 1 bit. The result has to be a
“finely detailed” image but with 2 levels of gray. If, on the contrary m = 4 and b = 4, hence still
1 bit per pixel, the image definition will not be as good, with 24 = 64 thumbnails to represent
the image. Figures 6.25 and 6.26 illustrate the differences obtained depending on the values of
m and b.

Figure 6.25 – Original image on the left and the result of the LBG compression with m = 16
and b = 3
Figure 6.26 – LBG compression: (m = 4, b = 2) on the left (m = 4, b = 4) on the right
Notes
1 You can also use the MATLAB® function eig, since the matrix we are dealing with is square,
positive, and therefore its singular value decomposition (svd function) and its
eigendecomposition (eigen values) coincide. However, the eig function does not sort the
eigenvalues, and must be followed by the MATLAB® function sort.
2 All of the results in this section are still true in the case of side band modulations with the
carrier frequency F0 if we replace xr (t) with its complex envelope with respect to F0.

(7.1)
Chapter 7
Hints and Solutions
H1 Mathematical concepts
H1.1 (δ-method) (see page 20)
We shall use the hypothesis cov (X1, X2) = σ2 I2. The Jacobian, here noted ∂g, of g: (X1,X2) →
(R, θ) is deduced from the Jacobian ∂h of h: (R, θ) → (X1, X2) following:
We have:
and, from (1.51):
we deduce:
This result is therefore correct on the condition that 
 is large. This result may appear
weak; note, however, that the δ-method allows us to calculate an approximation even in cases
where cov (X1,X2) is different from σ2I2.
Let 
. Program deltaMethodRice.m estimates the variance of R by carrying out a
simulation using 100000 draws. If ν/σ > 4, then the approximation is acceptable. Note that the
function g under consideration is not differentiable at point (0,0), associated with the case
where µl = µ2 = 0. Type:

(7.2)
H1.2 (Asymptotic confidence interval) (see page 22)
1. From the hypotheses, we deduce that, for any 
 and var (Xk) = p (1 − p).
According to the central limit theorem 1.10 when N tends toward infinity we have:
2. From this, we deduce:
3. Solving the double inequality in terms of p, we deduce the confidence interval at 100 α %:
where 
 and where δ is linked to value α by
Typically, for α = 0.95, δ= 1.96
Type the program:
H2 Statistical inferences

H2.1 (ROC curve and AUC for two Gaussians) (see page 33)
1. The significance level α represents the probability that, under H0, the statistic Φ(X) will be
higher than the threshold ζ. Consequently, to estimate α for the threshold ζ, we need to count
how many values of Φ(x) are greater than ζ in the database H0. The same approach should be
taken for the power; to obtain the ROC curve, we alter ζ across a range dependent on the
minimum and maximum values of Φ(X). One simple approach is to rank the set of values of
Φ(X) in decreasing order, then calculate the cumulative sum of the indicators associated with
the two hypotheses. This is written:
where Tj is the sequence of values ranked in decreasing order 
, where j = 1 to Nt
= N0 + N1.
2. Type the program:
H2.2 (Student distribution for H0) (see page 35)
In the following program, the variance and the mean have been chosen at random, and we see

that they have no effect on the distribution of V (X).
Type:
H2.3 (Unilateral mean testing) (see page 36)
The log-likelihood is written:
Firstly, maximizing with respect to σ2, we obtain:
The maximum for H0 is obtained for 
 on the condition that 
,
otherwise it is obtained for m0. The maximum for H0 is therefore written:
The maximum for Θ is expressed:
The log-GLRT, noted A, is written:

(7.3)
taking:
Taking the exponential of the two members with n ≠ 0, we obtain:
and the test:
If η < 0, we always decide in favor of H1.
We then verify that V is an increasing monotone function of U. Comparing V to a threshold is
therefore equivalent to comparing U to a threshold. We know that, for H0, the statistic U (X)
follows a Student distribution with (n − 1) degrees of freedom. The test is therefore written:
H2.4 (Mean equality test) (see page 38)
1. The model is constituted by 
 where θ = (m1,m2, σ) Θ
= 
+. Hypothesis H0 = {θ  Θ: s.t. m1 = m2}.

2. Let n = n1+n2. The maximization of the probability density for Θ leads us to take 
 and 
.
Maximization of the probability density for H0 leads us to take 
 and 
 From
this, we deduce:
and the GLRT:
Comparing the GLRT to a threshold can be shown to be equivalent to comparing the following
statistic W (X) to a threshold:
where 
.
3. Based on property 2.2 (section 2.3.3), we deduce that 
 and 
are jointly independent and Gaussian. Hence, for H0:
We also deduce that 
 and that S2 is independent of U. Hence, in accordance with
(1.57):
where Tn−2 is a Student variable with (n − 2) degrees of freedom. This distribution is
symmetrical around the value 0. The test therefore takes the form:
where 
 and where α is the confidence level.
4. The p-value is written:
5. The program below provides a p-value of 0.63, so the hypothesis of mean equality is

accepted.
Program studentlawdiffm1m2.m shows by simulation that W follows a Student distribution
with n − 2 degrees of freedom (see appendix A.2.3).
H2.5 (Correlation test) (see page 38)
1. The log-likelihood is given by (2.83) with d = 2. Parameter θ = (m1,m2,σ1,σ2,ρ)  Θ =  × 
× 
+ × + × (−1,1). Hypothesis H0=  ×  × 
+ × +×{(−ρ0,ρ0)}}.
The maximum log-likelihood in relation to m1 and m2 is given by expression (2.84):
where Ĉ is obtained using expressions (2.88) and (2.89), and where

2. The maximum log-likelihood for all parameters together is obtained using expression (2.90)
Let 
 Given that the log-likelihood is an increasing function of , maximization for
H0 may be carried out using the expression:
Canceling the derivatives with respect to γi and after a long but simple calculation process, we
obtain the following GLRT test:
Threshold η is determined based on the distribution of  for H0 and from the significance
level, or, more precisely, from the approximate distribution of 0.5 log 
.
3. The following program gives a p-value of 0.0176. We can therefore reject H0. This
indicates that the correlation is likely to have a modulus greater than 0.7.
The following program shows that the distribution of the Fisher transformation of , for H0,
approximately follows a Gaussian distribution of mean f0 and variance 1 /(N − 3). The
generation process uses the square root of the theoretical covariance matrix. The means,
variances and the number of samples N may be modified.

(7.4)
(7.5)
H2.6 (CUSUM) (see page 39)
1. The statistical model is a family of probability distributions dependent on parameter m with
values in {1,…,n} and a log-density which is written:
Using this notation, the hypothesis to test is H0 = {n}.
2. For the sample of length n, the test function of the GLRT is written:
taking sk = log p (xk;µ1)/p (xk;µ0). Hence, Tn (X) ≥ 0.
3. Assuming that we know the test function for a sample of size n − 1 and that we are observing
a new value sn, C (n) is either greater or less than 
. If 
, then 
 and 
. If 
, then 
, we deduce that:
The following program verifies that the direct formula (7.4) gives the same values as the
recursive expression of the CUSUM, (7.5).

(7.6)
4. The following program implements the CUSUM test for a change in the means of two
Gaussians with the same variables. The test works better as the difference between the means
increases in relation to the standard deviation.
H2.7 (Proof of (2.26)) (see page 40)
1. 
, using the fact that
In the same way, 
. Therefore:
where D = diag (P).
2. We have:
where 
. And thus:
We note that VtV = 1 and that VVT is the projector onto V with rank 1. Γ is therefore a projector
of rank (g − 1). A unit matrix U therefore exists such that
3. Let:

The central limit theorem 1.10 tells us that the random variable
converges in distribution toward a Gaussian of mean vector 0 and covariance matrix C. The
random vector Z = D−1/2Y therefore converges in distribution following:
Using equation (7.6), ZT Z appears asymptotically as the sum of the squares of (g − 1)
Gaussian, independent, centered random variables with variance 1. ZT Z therefore converges
in distribution toward a variable of χ2 with (g − 1) degrees of freedom. This demonstrates
expression (2.26).
H2.8 (Chi2 fitting test) (see page 41)
Type the program:

H2.9 (Decomposition of Z) (see page 48)
1. As Πi and Πxc are orthogonal projectors, (Π1 + ΠXc) is a projector. To show that Πz = Π1 +
ΠXc, we must simply demonstrate that (Π1 + ΠXc)Z = Z. Using the fact that 
 we
obtain, successively:
where, following equations (2.45) and (2.46), we use the fact that Xc = ΠXc Xc = ΠXc X + 0.
2. As 
, ΠXc and ΠZ are projectors and 
, we have, for any v 
N:
In other words In ≥ ΠZ ≥ Πi.
3. We have 
 and 
.
4. Type and run program leverageeffect.m. Changing the test value, 0 or 1, we observe the
effect of significant leverage.
H2.10 (Car consumption) (see page 54)
Type and run the following program:

We see that the p-values are all very small. We can therefore be confident in rejecting the idea
that the coefficients βk are null.
Figure H2.1 shows the N observed points and the predicted points in the space(x1,y), (x2,y) and
(x1,x2,y). Note that the predicted points 
 do not lie in a straight line. The predicted solutions 
 are of the form yn = β o + β1xi,1 + β2 xi,2; they therefore belong to the same plane of
dimension 2, but there is no reason for them to lie on the same straight line. The same applies
to their projections onto planes (Ox1 y) and (Ox2 y).
We obtain R2 = 0.7521 and 
, with a p-value ≈ 0. This allows us to reject the
hypothesis that all of the coefficients are null.

(7.7)
Figure H2.1 – Top left: the N points (xn,1, yn) and 
 in the space Ox1y. The points (’.’)
are observed values and (’x’) the predicted values. Bottom left: the N points (xn,2, yn) and
(xn,2, 
) in the space Ox2y. Right: the N points (xn,1, xn,2, yn) and (xn,1, xn,2, 
) in the space
Ox1 x2y
H2.11 (Central limit for a moment estimator) (see page 57)
Let 
 and 
. Expression (2.73) may be rewritten 
 where
The central limit theorem 1.10 states that, when N tends toward infinity:
where

Readers may wish to determine the expression of C (k, λ) as a function of k and λ. The
continuity theorem 1.11, applied to function g states that, when N tends toward infinity:
where Γ(k, λ) = JCJT with
This may be calculated in terms of (k, λ) using (7.7). Clearly, the performance depends on the
parameter values. In the context of a practical problem, if we wish to calculate a confidence
interval, the values of the parameter (k, λ) may be replaced by an estimate.
H2.12 (Estimating the proportions of a mixture) (see page 58)
1. The statistical model has a density of:
where the parameter α  (0,1). We deduce that 
 and 
.
2. We have 
. Hence, 
.
3. 
. Therefore:
Let Ŝ(X) = [Ŝ1 (X) Ŝ2 (X) ], and J (α) = ||S (α) − Ŝ(X) ||2. From this, we deduce the value 
which minimizes J (α), canceling the derivative of J (α).
4. Using the fact that for a Gaussian, centered, random variable U of variance σ 2, we have 
 and 
, we obtain:
We obtain the estimator of α3 by digitally minimizing the function K (α) = (Ŝ (X) − S (α))TC
−1(α)(Ŝ (X) − S (α)) in relation to α.
5. Type and run the following program:

where the function fgmm.m is:
In this case, the minimization applies to the scalar variable α  (0,1). The minimization
operation may therefore be carried out using a value grid. Modifying the parameters mi, σi we
see that the reduction of the mean squares error obtained with 
 and 
 in relation to 
depends on a significant extent on the choice of these values.
H2.13 (Γ(k, λ) distribution) (see page 62)

(7.8)
1. The Γ(1, λ) distribution is an exponential distribution of parameter λ.
The log-likelihood is expressed 
. Canceling the derivative with respect
to λ, we obtain:
The Fisher information is written:
Hence, following (2.82):
Type and run the following program:
This program uses the property of inversion of the cumulative distribution function F (x) = 1 −
e−x/  and thus x = −λ log(1 − F), as presented in section 3.3.1. Finally, if F is a uniform r.v.,
then (1 − F) is also a uniform r.v. This explains the generation of an exponential law using Y=–
lambda*log(rand(N,1));.
2. The log-likelihood is written:
Canceling the Jacobian with respect to (k, λ), we obtain
From the first equation, let 
. Applying this to the second equation gives
us:

(7.9)
where 
. Function 
 is known as the “digamma” function and noted ψ. We
have:
The solution to (7.9) has no simple analytic expression, but may be calculated using a
numerical procedure such as the Newton-Raphson algorithm.
H2.14 (Singularity in the MLE approach) (see page 62)
We can assume, without loss of generality, that the observations verify xn ≠ x1 for any n ≥ 2.
The log-likelihood is expressed 
 Choosing m1 = x1, the log
likelihood is written:
Choosing any m2   and σ2  
+, let us make σ1 tend toward 0. As xn − x1 ≠ 0, the second
term tends toward a finite value. ℓ therefore tends toward infinity. To avoid this situation, a
constraint must be introduced:
– either by requiring the variances to be above a certain threshold, which is equivalent to
restricting the domain by replacing Θ with 
, and writing:
– or, using a Bayesian approach, considering a probability distribution for θ with density f
(θ) and writing:
– or by imposing a constraint on . In the case of this specific example, we can impose that
the unknown means must be computed with at least two unequal observations.
H2.15 (Parameters of a homogeneous Markov chain) (see page 63)
1. Using Bayes rule and the Markov property, we have:
Reiterating, we obtain:

Taking the log, we have:
2. The estimator of the maximum likelihood of αs is the solution to
Hence 
. To clarify, the values of αs are all null except for that for which the
position is the observed value of X1.
The estimator of the maximum likelihood of ps|s' is the solution to
The Lagrangian is written 
.
Canceling the derivative of the Lagrangian with respect to ps|s', we obtain:
and:
The meaning of this expression is evident: we count the number of ordered pairs of form (s′, s)
and we divide the result by the total number of pairs beginning with s′. In practice, we simply
need to calculate the numerator for every (s′,s) then apply 
.
3. Type:

H2.16 (Logistic regression) (see page 65)
The following function estimates the parameters of a logistic model, and is based on the
Newton-Raphson algorithm.

Program testlogistic.m simulates a sample with a logistic distribution. It uses the function
logisticNR.m to estimate α. Type:
Program ORing.m estimates the parameters of the data provided in table 2.5, along with the
associated confidence intervals, given by expression (2.96). It calculates the p-value of the
log-GLRT, expression (2.19), associated with the hypothesis H0 = {α 2 = 0}.
We see that the p-value of the log-GLRT associated with hypothesis H0 is 0.01, leading us to
reject H0. Furthermore, the confidence interval at 95%, 0.01 ≤ α2 ≤0.34, does not contain the
value 0, which also leads us to reject H0.
Type:

H2.17 (GLRT for the logistic model) (see page 65)
Program testGLRTlogistic.m verifies the distribution of the GLRT for H0. It uses the
function logisticNR.m from solution H2.16. Type:
H2.18 (GMM) (see page 72)
– Type:

– Type:

– Type:

H2.19 (Estimation of states of a GMM) (see page 72)
1. Equation (2.106) gives the probability of state Sn at instant n, conditional on the observation
Yn. Knowing parameter θ, we can therefore use the EM algorithm to calculate
2. Type the function:

Type the program:
H2.20 (MLE on censored data) (see page 74)
1. We have 
. Using expression (2.110), we have:
2. Canceling the derivative with respect to θ, we obtain the recursion of the EM algorithm:

(7.10)
where 
 and 
. This equation converges, as ρ1 < 1. The
limit therefore verifies the equation, giving:
Using expression (2.108), we obtain a likelihood expressed as 
 
3. Program censoredsimul.m carries out a simulation with N = 30. 10 censored data points
are obtained by random reduction of the “true” values. We see that the mean square error is
better for estimator (7.10) than with the estimator which considers that none of the data points
are censored, and than the estimator which only takes account of the uncensored data.
4. Program censoredHIV.m estimates the constant θ for the proposed data.
H2.21 (Estimation of a quantile) (see page 78)
1. An estimator is given by
where X(n) is the n-th value of the series arranged in increasing order, known as the order
statistic. This estimator may be refined by approximating the cumulative function locally
around X(
cN ) by a polynomial.
2. Applying the δ-method to expression (2.113), we are able to deduce the asymptotic
distribution of sN

3. From this, we deduce an approximate confidence interval at 95%:
4.Program:

H2.22 (Image equalization) (see page 78)
Type and run the program egalizeimage.m:
H2.23 (Bootstrap for a regression model) (see page 81)
Type and run the program bootstraponregression.m:

H2.24 (Model estimation by cross validation) (see page 83)
Type and estimate the program orderEstimCV.m:

Figure H2.2 shows the results of a simulation. The curve marked using ‘x-’ represents the
prediction error calculated over the learning base. The mean decreases as the number of
regressors increases. The curve marked using ‘o-’, which represents the prediction error
calculated using the test base, passes through a minimum for the true value p = 10. Thus, when
the number of regressors is increased above the true value, we “learn” noise. This is known as
overtraining. Furthermore, note that the error for the test base is greater than that for the
learning base, as predicted by equation (2.59).
Figure H2.2 – Prediction errors as a function of the supposed order of the model: ‘x-’ for
the learning base, ‘o-’ for the test base. The observation model is of the form 
,
where Z includes p = 10 column vectors. As the number of regressors increases above and
beyond the true value, we “learn” noise; this is known as overtraining

H3 Monte-Carlo simulation
H3.1 (Multinomial law) (see page 90)
Type:
H3.2 (Homogeneous Markov chain) (see page 91)
Type:
H3.3 (2D Gaussian) (see page 91)
Type:
H3.4 (Box-Muller method) (see page 92)

The generation algorithm is written:
1. draw two independent samples (U,V) with a uniform distribution over (0,1),
2. calculate the variable pair:
Type:
H3.5 (The Cauchy distribution) (see page 92)
1. The cumulative function of Z is written:
The density is therefore expressed:
2. The cumulative function of Z is written:
From the derivative with respect to z we obtain the density:

3. Type:
H3.6 (Metropolis-Hastings algorithm) (see page 98)
Type:
H3.7 (Gibbs sampler) (see page 98)
1. The conditional distribution is given by expression (1.47):

2. Type:
H3.8 (Direct draws and importance sampling) (see page 103)
Type:

Instead of boxplot, readers may wish to use myboxplot (see section A1) or any other more
sophisticated realization freely available.
H3.9 (Stratification) (see page 105)
1. Following (1.32) for µ = 0 and σ2 = 1:

Thus 
.
2. Type the program:
H3.10 (Antithetic variates approach) (see page 106)
1. Using the estimators given by (3.12) and (3.30) respectively, we have

and
For N = 100, we therefore obtain:
2. Type the program:
H4 Second order stationary process
H4.1 (Levinson algorithm) (page 120)
Type the function:

Run the following program:
This program compares the calculated values with those supplied by the l pc.m function in
MATLAB®. Note that this function produces coefficient values with the opposite sign,
preceded by the value 1. This corresponds to the coefficients of the AR model (see theorem
4.1).
H4.2 (Lattice filtering) (page 123)
1. Type the function:

2. Type the function:
3. Run the following program:
H4.3 (Smoothed periodogram (bias/variance compromise)) (see
page 132)

Type the program:
We have chosen to draw a new trajectory for each value of M. It is also possible to use the
same trajectory for each value of M; if N is sufficiently large, the results are equivalent. The
Boolean variable known allows us to compare results depending on whether the spectrum is
presumed to be known or unknown.
Figure H4.1 shows the variations of the mean square integrated bias, the mean integrated
variance and the mean integrated MSE for 20 trajectories as a function of M. We see that the
bias increases, the variance decreases and the MSE passes through a minimum around 15.

Figure H4.1 – Variations of the mean square integrated bias, the mean integrated variance
and the mean integrated MSE for 20 trajectories as a function of M. The signal is made up
of 4096 samples, and smoothing is carried out using the Hamming window
We recommend modifying the value of N, the form of the window or the spectrum under
consideration in order to visualize the effects of these parameters on the estimation.
H4.4 (Smoothed periodogram – confidence interval) (see page 135)
Type the program:

The function pwelch is in the signal toolbox of the most recent versions of MATLAB®.
H4.5 (Magnitude square coherence) (see page 137)
Let G1(f) and G2(f) be the frequency responses of the two filters.
– We obtain:

(7.11)
(7.12)
(7.13)
The MSC is expressed
where
is interpreted as the inverse of a signal to noise ratio. In the case of an 
.
– Type the program:

(7.14)
H5 Inferences on HMM
H5.1 (Kalman recursion in the scalar case) (see page 148)
In the Gaussian case, relationship 
 takes the following form:
1. Using the linearity of the expectation in the evolution equation, we have:
Noting that Bn is independent of Y1:n and is centered, we deduce:
2. If we replace Yn + 1 with (cn + 1 Xn+1 + Un + 1) and use the hypothesis stating that Un+1 and
Bn+1 are orthogonal to Y1, …, Yn, we get
3. Using the property (1.31) we write:
where Gn+1 = (Xn+1, in)/(in, in) and in+1 = Yn+1 − (Yn+1|Y1:n).

(7.16)
(7.15)
Using (7.14), we also get in = Yn+1 − cn + 1Xn + 1|n. Therefore:
4. We have:
Let Pn+1|n = (Xn+1 − Xn+1|n, Xn+1 − Xn+1|n). Because (Xn+1 – Xn+1|n) and Un+1 are orthogonal, we
can write:
5. The process
is known as the innovation process. We verify that 
. By definition, in belongs to the
linear space spanned by the Y1:n In accordance with the projection theorem, in +1 is orthogonal
to the linear space generated by the Y1:n. Consequently, in  in +1 and, being Gaussian, they are
independent.
Moreover, the linear space spanned by the Y1:n corresponds with the linear space generated by
i1:n. The joint distribution of the Y1:n is therefore equal to the joint distribution of the i1:n.
Hence:
6. Furthermore:
And hence:
7. Let us now determine the expression of Pn + 1|n. We have:
This leads us to:

(7.19)
(7.17)
(7.18)
(7.20)
(7.21)
involving that Xn|n and Bn are orthogonal. Using (7.15) we obtain:
Using the fact that Xn +1 − Xn + 1|n and Un + 1 are orthogonal, the expression (7.16) leads to:
If we group expressions (7.15), (7.16), (7.17) and (7.18) together, we get the following
algorithm in accordance with the Kalman algorithm (3):
with the initial conditions x1|1 = 0 and 
.
H5.2 (Denoising an AR-1 using Kalman) (see page 149)
1. The state equation shows that the stationary solution is an AR-1 process. Therefore, its
power has the expression:
2. According to (5.13) and (5.14), we have:
which leads us to 
. Using (5.12) and (5.17):
Carrying this result in the expression (7.20) that gives the recursive formula:
In this case, the initial conditions lead to 
. Therefore G1 = ρ /(1 + ρ − a2). From
the calculation point of view, everything happens as if we started out with formula (7.21) and

the initial values 
 and G0 = ρ /(1 − a2).
We can easily verify that the series Gn is increasing monotone and bounded by 1. It therefore
converges and the limit verifies the recursive equation, giving 
.
The Kalman algorithm can be summed up as follows:
– Initial conditions: 
 et G0 = ρ/ (1 − a2).
– For n from 1 to N:
3. The following program is designed to test the algorithm:
The results are shown in Figure H5.1.
Figure H5.1 – Results for the study of the filtering
When we presented the Kalman filter, and implemented it in the previous program, we
assumed that the model as well as the characteristic features of the noise were known.
However, this is usually not the case. For example, if in our case the signal Xn is an AR
process, the choice of a and of 
 requires that we compromise between the ability of Xn to
track the trajectory and the elimination of the noise. Choosing a too close to 1 means that the

(7.22)
(7.23)
model does not take into account the rapid variations of the signal Xn. Therefore, the filter has
difficulties “keeping up” with such variations. Likewise, if we choose 
 too high, we assume
that we expect significant variations of the signal Xn with respect to the equation Xn ≈ aXn − 1.
You can check by using the previous algorithm and changing the parameters.
H5.3 (2D tracking) (see page 149)
1. Using a second-order Taylor expansion, for each component i we have:
Hence:
Considering that the pairs 
, representing the acceleration components, form a
series of independent, centered, Gaussian random variables with a covariance matrix σ2I2, we
have:
with
σ is expressed in m/s2.
2. Let the speed v0 be 30 m/s, and consider that it may vary by a quantity proportional to v0 of
the form λv0. We can therefore take σ ≈ v0/T as the dispersion of the acceleration.
3. Type the following functions:

and
Type and run the following program:

Comments: Modifying the value of σ using , we modify our initial ideas concerning the
acceleration, and thus concerning the fact that the trajectory more or less follows a straight
line. Hence if σ is small, the mobile element is easy to follow when the trajectory is close to a
straight line, but harder to follow if the trajectory curves. If σ is large, the observation noise is
difficult to remove. The Kalman filter establishes a good compromise between prior
knowledge, i.e. σ, and observations, i.e. Yn.
H5.4 (Calibration of an AR-1) (see page 150)
Type and run the following program:

(7.24)
(7.28)
(7.25)
(7.26)
(7.27)
H5.5 (Calculating the likelihood of an ARMA) (see page 151)
1. The first equation of expression (5.20) is written:
Applying a series of delays such as those given in the first column of (7.24), we obtain:
Noting that, following (5.20), X1, n = Yn, we deduce that Yn is an ARMA-p, q.
2. For t ranging from 2 to n, the Kalman algorithm giving the log-likelihood is written

(7.32)
(7.36)
(7.29)
(7.30)
(7.31)
(7.33)
(7.34)
(7.35)
with initial values
3. A tilde is used to indicate quantities calculated using the algorithm with σ = 1. We consider
that, on initialization, 
. We deduce that 
, that 
 and
that 
 The log-likelihood is therefore written:
We must therefore simply apply the algorithm for σ = 1 then use formula (7.36) to calculate the
likelihood. This relationship is highly useful for maximum likelihood-based estimation
problems, as maximization in relation to σ2 possesses an analytical solution.
Remark: The choice of P1|1 requires further explanation. According to question 3, we can
consider that σ2 = 1. One choice for P1|1 is the matrix which corresponds to the stationary form
of Xt. Noting P1 = cov(Xt) and using the evolution equation and the stationarity we have:
taking Q = RRT. This is known as the Lyapunov equation. Using the identity
where the operator noted “vec” denotes the column vectorization operation applied to a matrix.
This last equation may be rewritten
where  denotes the Kronecker product. Hence:
4. Type:

5. Type:

Type:
H5.6 (Discrete HMM generation) (see page 152)
1. Let us show that:

where Un is a series of independent r.v.s with values in (0,1). To do this, let us determine 
{Xn +1 = s|Xn = k}. As, according to our hypothesis, Un is independent of Xn, we can write:
using the fact that Un is uniform. Note that this expression may be written:
where Un is an i.i.d. series with uniform distribution over (0,1). It is similar to the expression
of the state equation evolution expression (5.8), except that it is neither linear, nor Gaussian.
2. Type and run the program:
We use the function:

H5.7 (EM algorithm for HMM) (see page 158)
1. Type the function:


2. Type the function:

3. Type and run the program:

H6 Selected Topics
H6.1 (MUSIC 2D) (see page 185)
1. The 2D-MUSIC function is given by
where GGH refers to the orthogonal projector onto the noise subspace.
2. Type:

H6.2 (Phase modulator) (see page 190)
1. Because the binary rate is equal to 1, 500 bps, each bit lasts 1/ 1, 500 s. Since the bits are
arranged in groups of three, the transmission of each elementary signal lasts a duration of T = 3
× 1/1,500 = 2 ms.
2. Figure H6.1 shows a Gray code solution.
3. Type (see Figure H6.2):
Figure H6.1 – Gray code for an 8 state phase modulation

Figure H6.2 – The real and imaginary parts of the complex envelope and the signal
H6.3 (AMI code) (see page 195)
1. Because dk is a uniform, i.i.d. sequence with possible values in {0,1}:
for k ≠ j. According to the coding rule:

therefore ak = dk (1 − 2dk − 1)(1 − 2dk − 2)…
Because the dk are independent, 
. By expanding, we get 
 and 
.
Using the fact that the dk are independent, we get 
 and:
Therefore, Ra (± 1) = −1/ 4. We have to check that 
 for |j | ≥ 2. We infer that:
2. Type:
H6.4 (HDB3 code) (see page 196)
1. Starting with the initial values pv = +1 and p1 = −1, we have:
2. Type:

By typing:
check the result of the previous question.
3. Because the symbol sequence is centered in AMI coding, formula (6.35), which gives us the
digital signal’s spectrum, amounts to only the first term. The welch function then allows us to
estimate the periodic part between 0 and 1/T, corresponding to the correlations of the symbols
an, that is to say:
at the frequency points f = m/TL where m = 0, …, L − 1 and where L refers to the number of
frequency points between 0 and 1/T. All we have to do after that is multiply by the square
modulus of the pulse spectrum, given, except for a multiplication factor (related to the
amplitude), by G (f) = sin(πfT) /πfT. If we restrict ourselves to the (0, 1/T) frequency band, we
have:
where the Sa (m/TL) are estimated by applying the welch function to the sequence an. Type:

H6.5 (Linear equalization of a communications channel) (see page
198)
1. The constellation contains 16 symbols that can be coded using four bits. Remember that if F0
refers to the carrier frequency, the transmitted signal can be written 
.
Figure H6.3 – Constellation and Gray code
2. The filter G(z) = 1/(h0 + h1z−1) is stable if the convergence area contains the unit circle.
Therefore, if the square root of the denominator has a modulus greater than 1, the stable filter is
anti-causal.
For h0 = 1 and h1 = −1.6:
A length 21 causal approximation leads to a delay of 21 (see Figure H6.6).
Figure H6.4 – Noised signal, the signal-to-noise ratio is equal to 20 dB; signal containing
the ISI caused by the FIR filter, h0 = 1 and h1 = −1.6; signal after equalization
3. Type:

Figure H6.5 – Comparison for a minimum phase channel
Figure H6.6 – Comparison for a non-minimum phase channel
H6.6 (2-PAM modulation) (see page 204)
1. Generating the coded signal:

2. Received signal:
3. Type:
4. Type:

5. Type:
H6.7 (“Zero Forcing” linear equalization) (see page 213)
1. If g(n) refers to the channel’s impulse response, the suggested equalizer has the impulse
response w (n), such that w (n)  g (n) = δ (n). The equalizer’s output signal therefore has the
expression:
Figure H6.7 – Signals at different points of the communication line
Notice that y(n) only contains the contribution of the symbol a(n). Interference due to other
symbols is completely eliminated. This is why this equalizer is said to be “Zero Forcing”, in
the sense that it forces the ISI to be equal to zero.

2. The output noise u(n) = w(n)  b(n) of the filter w (n) is Gaussian and centered. Using
formula (6.49) for P = 2, we get the variance:
3. We have y(n) = a(n) + u(n). Therefore, under the hypothesis that an = −1, y(n) is a Gaussian
variable with the mean −1 and the variance 
. Under the hypothesis that an = +1, y(n) is a
Gaussian variable with the mean +1 and the variance 
.
4. The error probability is:
with ρ = 1/σu. In MATLAB®, Q(ρ) is obtained by typing Q=(1−erf(rho/sqrt(2)))/2.
5. Type:

(7.37)
Figure H6.8 shows the results. They are in perfect agreement with the theoretical values.
H6.8 (Wiener equalization) (see page 214)
1. Let us assume that w = (w (0), …, w (N − 1))T and x (n) = (x (n), ldots, x (n − N + 1))T. The
expression we have to minimize with respect to w, is written 
. Using the
projection principle, we have a(n − d) − wT x (n)  x (p) for p  {n, …, n − N + 1}, which
can be written 
 where k  {0, …, N − 1}, or also, in matrix
form:

Figure H6.8 – Symbol-by-symbol detection of a Zero Forcing equalizer’s output for a binary
transmission. The equivalent channel has the coefficients g0 = 1, g1 = −1.4, g2 = 0.8. The x’s
indicate the probabilities obtained through 5,000 simulations for different values of the
signal-to-noise ratio in dB
2. If we assume that a(n) is an identically and independently distributed sequence with
possible values in {−1,+1}, we have 
 and:
Let s (n) be the channel output. According to the filtering formulas, we have:
This sequence only has 2L − 1 non-zero terms since g(k) is of length L.
By assuming that b(n) is independent of a(n), b(n) is independent of s (n) and we have:
Likewise, if we use the input/output filtering formula, we have:
3. If we refer to expression (7.37), 
 where R ss is a Toeplitz matrix
constructed from the sequence Rss(k). The vector 
 is comprised of the
coefficients g(k):
Therefore, the filter we are trying to determine is 
.
4. The mmse.m program allows us to examine the histograms of the received values as well as

the histogram after equalization. As you can see, the intersymbol interference leads to a more
spread-out histogram:
5. We can now perform the equalization with the Wiener filter, then, by simple detection with
the threshold 0, estimate the binary sequence and measure the error probability. We can then
compare the results for a Zero Forcing equalization. If the filter g(n) is minimum phase, we can
perform the Zero Forcing equalization simply by typing filter(1, gc, xk) and comparing
the error probabilities. On the other hand, if the filter g(n) is not minimum phase, the Zero
Forcing equalization can only be achieved using the command filter, which implements the
causal solution that is not stable. We then have to determine a causal and stable approximation
of the inverse of g(n).
The following program implements the performance comparison in terms of error probability.
After having run the mmse.m program, run the following program (Figure H6.9):
Notice that the results are significantly better with the Wiener filter.

Figure H6.9 – Error probability plotted against the signal-to-noise ratio in dB after
equalizing with the Wiener filter (‘o’) and with the Zero Forcing filter (‘ x’). The results are
obtained through simulation using 5,000 symbols. The channel filter has the finite impulse
response (1 – 1.4 0.8)
H6.9 (Performances with two sub-codebooks) (see page 232)
1. Type:
2. Type:
In the first case, we obtained a mean square error ED = 0.1189. In the second one, we
obtained for the first (very crude) codebook EC1 = 1.4684 and for the second one, which is
“more subtle”, EC2 = 0.5890. Hence the second one gives the order of magnitude of the
distortion caused by this second type of partition. We therefore have to compare, in terms of
square deviation, the values 0.1189 and 0.5890. The loss is significant, but the total size of the
two sub-codebooks is 20 instead of 64 for the maximum size dictionary.

(8.1)
Chapter 8
Appendices
A1 Miscellaneous functions
A2 Statistical functions
A.2.1 Notable functions
The following functions are used in defining the most widespread distributions in the field of
statistics:
– gamma function (gamma):
– beta function (beta):

(8.2)
(8.3)
(8.4)
(8.5)
(8.6)
(8.7)
A.2.2 Beta distribution
The beta distribution fx (z, w) is defined as:
The cumulative of fx (z, w) is called the regularized incomplete beta function or RIBF, Ix
(z,w).
where Bx (z, w) is called the incomplete beta function.
In MATLAB® the function betainc implements the RIBF Ix (z, w).
A.2.3 Student’s distribution
The Student’s t- distribution has the following probability density function:
With MATLAB®, we obtain:
The Student’s t cumulative distribution function is given by:
With MATLAB®, we obtain:

Student’s t -distribution implementation
MATLAB® provides five functions for the Student’s law. They can be replaced, up to a point,
by the functions listed below:
– tcdf: computes Student’s t cumulative distribution:
– tpdf: provides the Student’s t probability density function:
Application (Figure A2.1):

– tinv: function betaincinv is used to calculate the Student’s t inverse cumulative
distribution function:
Figure A2.1 – Distribution (left) and cumulative distribution (right) for values of k 1, 3, 5
and 10. The limiting Gaussian is shown alongside with the distributions
The mytinvd function directly applies Newton’s method to calculate the inverse:

Figure A2.2 – Application of Newton’s method to find t from T = 0.8 and k = 3
– trnd: generates random numbers from Student’s t-distribution. See generation
testmychi2rnd.m for the method [2].
– and tstat: Student’s t mean and variance.

(8.8)
(8.9)
A.2.4 Chi-squared distribution
The chi-squared distribution or -distribution is the distribution of a sum of the squares of k
(“degrees of freedom”) independent 
.:
– chi2pdf: the probability density function is given by:
which may be writen:
– chi2cdf: the cumulative distribution function is given by:
which may be writen:

The testmychi2 program displays the densities and the 
 distributions for k = 1, 3, 5, 7 and
10 (Figure A2.3).
– chi2inv: inverse cdf:
– chi2rnd: r.v.s are generated using the mychi2inv function (Figure A2.4). This method is
illustrated in program testmychi2rnd.m.

Figure A2.3 – A few probability densities and cumulative distributions of the χ2 distribution
– chi2stat

(8.10)
Figure A2.4 – Use of the mychi2inv function to generate a random sequence, histogram
and theoretical pdf
A.2.5 Fisher’s distribution
The Fisher’s centered distribution has the following probability density function:
where k1 and k2 are degrees of freedom (integers > 0). They correspond to an r.v. generated by
the relationship 
, where X1 and X2 are r.v.s with a χ2 type distribution.
The Fisher’s cumulative distribution function is given by the RIBF:
Fisher’s distribution implementation
– fpdf: Fisher probability density function:
– fcdf: Fisher cumulative distribution function:

– finv:
Figure A2.5 – pdf and cdf of the Fisher distribution for k1 = 5 and k2 = 7
– frnd: generates random numbers from Fisher distribution. See generation
testmychi2rnd.m for the method.
– and fstat: the Fisher mean and variance are given by:

and

Bibliography
[1] P. Billingsley. Probability and Measure. Probability and Statistics. John Wiley and Sons,
2012.
[2] G. Blanchet and M. Charbit. Digital Signal and Image Processing, Volume 1:
Fundamentals, volume 1. ISTE Ltd, London and John Wiley & Sons, New York, 2nd edition,
2014.
[3] G. Blanchet and M. Charbit. Digital Signal and Image Processing, Volume 2 - Advances
and Applications: The Deterministic Case, volume 2. ISTE Ltd, London and John Wiley &
Sons, New York, 2nd edition, 2015.
[4] P. Brockwell and R. Davies. Time Series: Theory and Methods. Springer Verlag, 1990.
[5] J. Capon. “High-resolution frequency-wavenumber spectrum analysis”. Proc. IEEE, 57, no.
8:1408–1418, August 1969.
[6] O. Cappé, E. Moulines, and T. Ryden. Inference in Hidden Markov Models. Springer
Series in Statistics. Springer-Verlag New York, 2005.
[7] B. Efron. “Bootstrap methods: Another look at the jackknife”. Annals of Statistics, 7(1):1–
26, 1979.
[8] N. J. Gordon, D. J. Salmond, and A.F.M. Smith. “Novel approach to nonlinear/non-
gaussian bayesian state estimation”. IEE Proceedings-F on Radar and Signal Processing,
140(2):107–113, 1993.
[9] M. Joindot and A. Glavieux. Introduction aux Communications Numériques. Collection
Pédagogique de Télécommunication. Ellipses, 1995.
[10] R. E. Kalman. “A new approach to linear filtering and prediction problems”.
Transactions of the ASME–Journal of Basic Engineering, 82(Series D):35–45, 1960.
[11] S. M. Kay. Fundamentals of Statistical Signal Processing: Estimation Theory. Prentice
Hall, 1993.
[12] Y. Linde, A. Buzzo, and R. Gray. “An algorithm for vector quantizer design”. IEEE Trans.
on Communications, COM-28:84–95, January 1980.
[13] S.P. Lloyd. “Least squares quantization in PCM”. IEEE Trans. on Information Theory,
pages 129–137, March 1982.
[14] M. Matsumoto and T. Nishimura. “Mersenne twister: A 623-dimensionally
equidistributed uniform pseudorandom number generator”. ACM Trans., Modeling and
Computer Simulations, 1998.

[15] J. Max. “Quantizing for minimum distorsion”. IRE Trans. on Information Theory, pages
7–12, March 1960.
[16] F.J. Mc Clure. “Ingestion of fluoride and dental caries: Quantitative relations based on
food and water requirements of children one to twelve years old”. American Journal of
Diseases of Children, 66(4):362–369, 1943.
[17] R. G. Miller. “The jackknife – a review”. Biometrika, 61(1):1–15, 1974.
[18] D. C. Montgomery and G. C. Runger. Applied Statistics and Probability for Engineers.
John Wiley and Sons, Inc., March 2010.
[19] N. Moreau. Techniques de Compression des Signaux. Masson, 1995.
[20] J. Neyman and E. S. Pearson. “On the problem of the most efficient tests of statistical
hypotheses”. Philosophical Transactions of the Royal Society A: Mathematical, Physical
and Engineering Sciences, 231:694–706, 1933.
[21] J. Pearl. Probabilistic Reasoning in Intelligent Systems: Networks of Plausible
Inference. Number 1558604790. Morgan Kaufmann Publishers Inc., 1988.
[22] J.G. Proakis and Masoud Saheli. Digital Communications. Electrical and Computer
Engineering. McGraw-Hill, 5 edition, 2007.
[23] M. H. Quenouille. “Notes on bias in estimation”. Biometrika, 43, 1956.
[24] R. Roy and T. Kailath. “ESPRIT-estimation of signal parameters via rotational invariance
techniques”. IEEE Trans. on Acoust. Speech, Signal Processing, ASSP-37:984ñ–995, August
1989.
[25] W. Rudin. Real and Complex Analysis. 3rd edition, International Series in Pure and
Applied Mathematics. McGraw-Hill Science/Engineering/Math, 3rd edition, 1986.
[26] R. H. Shumway and D. S. Stoffer. Time Series Analysis and Its Applications: With R
Examples (Springer Texts in Statistics). 2nd edition, Springer, May 2006.
[27] S. Stigler. “Studies in the history of probability and statistics. xxxii: Laplace, fisher and
the discovery of the concept of sufficiency”. Biometrika, pages 439–445, December 1973.
[28] J. W. Tuckey. “Bias and confidence in not-quite large samples”. Ann. Math. Statist., 29,
1958.
[29] F. J. Harris, “On the Use of Windows for Harmonic Analysis with the Discrete Fourier
Transform”. Proc. IEEE, 66, pages 51-83, January, 1978.

Index
A
acceptance-rejection method
algorithm
backward recursion
Box-Muller
coding
expectation-maximization (EM)
forward recursion
GMM
gradient
Kalman
Levinson-Durbin
Metropolis-Hastings
Viterbi
AMI
antenna
antithetic variates method
AR
area under the ROC curve (AUC)
autoregressive
B
backward error
backward prediction
backward projection

band
base
narrow
baud
Bayesian statistics
beamforming
BER
best linear unbiased estimator (BLUE)
beta distribution
beta function
bias
bilateral hypothesis testing
bilateral test
bipolar violation
bit error rate
Blackman-Tuckey (correlogram)
bootstrap
Box-Muller method
burn-in period
Buzzo (LBG)
C
Capon
Cauchy
generation
law
moment
cdf
censored data

centered
random variable
central limit
theorem
centroid
characteristic function
marginal probability distribution
chi-squared, 
cumulative distribution function
probability density function
classification
code
AMI
Gray
HDB3
code word
codebook
coding
coefficients
correlation
complete data (EM algorithm)
composite hypothesis
conditional
covariance (gaussian case)
distribution (gaussian case)
expectation
expectation (gaussian case)
probability distribution
confidence ellipse
confidence interval

constellation
continuity
theorem
correction step
correlation
coefficients
distribution
correlation matrix
correlogram
covariance
Cramer-Rao bound (CRB)
critical
region
test function
cross validation
cross-spectrum
cumulated sum (CUSUM)
cumulative function
D
degrees of freedom
demodulator
density (probability)
detailed balance equation
detection probability
digamma function
directed acyclic graph
discrete Fourier transform (DFT)

distribution
beta
Student
E
efficient (estimators)
efficient estimator
empirical
correlation
covariance
mean
equalization
linear
Wiener
Zero Forcing
equalizer
equation
detailed balance
evolution
normal
observation
state
Yule-Walker
equations
normal
ESPRIT
estimator
expectation-maximization (EM)
eye pattern

F
false alarm probability
fft-music
filter
Kalman
lattice
matched
particles
filtering
Fisher
cdf
cumulative distribution
distribution
information matrix
probability distribution
transformation
formula
Poisson
forward error
forward projection
frequency
carrier
function
arma2ACF
array2D
atok
beta
centroides
characteristic
confidenceellipse

cumulative distribution
digamma
ellipse
EMforHMM
esprit_doa
estimGMM_EM.m
estimState_GMM_EM.m
Fgene
fgmm
fminsearch
ForwBackwGaussian
fviterbi
gamma
geneGMM.m
gsymb
hdb3
HMMGaussiangenerate
initlbg
joint probability density
KalmanFilter
ktoa
lattice_analysis.m
lattice_synthesis
lbg
levinsonA.m
LLarmaKalman
logisticNR
music
music_doa
musicFFT

myboxplot
mychi2cdf
mychi2inv
mychi2pdf
mychi2stat
myfcdf
myfinv
myfpdf
myfstat
mytcdf
mytinv
mytinvd
mytpd
mytstat
probability density
racnyq
voronoi
welch
xtoa
G
gamma function
Gaussian mixture model (GMM)
generalized expectation maximization (GEM)
generalized likelihood ratio test (GLRT)
generalized method of moments

generation
Cauchy
cumulative function inversion
Gauss
Gauss 2D
Markov chain
multinomial
Rayleigh
Gibbs sampler
goodness of fit test
gradient
algorithm
Gray (LBG)
Gray code
H
HDB3
hidden Markov model
HMM generation
homogeneous Markov chain
hypothesis
composite
simple
test
I
identifiable
importance sampling
importance weights
incomplete data (EM algorithm)

inequality
Schwarz
innovation
instrumental distribution
intercept
interSymbol interference
inverse cdf
Fisher
inversion method
ISI
J
jackknife
Jacobian
joint probability
joint probability density
K
Kalman
gain
innovation
prediction
update
Kalman filter
kernel (smoothing)
L
Lagrange multipliers
large numbers
law

lattice
law
Cauchy
Gauss
Gaussian
multinomial
Rayleigh
transition
uniform
learning sequence
least squares
method
ordinary
weighted
leave one out (LOO)
leverage
likelihood
likelihood ratio
Linde (LBG)
linear filter
matched
linear prediction
linear regression
log-likelihood
logistic regression
Lyapunov equation
M
Mann-Whitney statistics
marginal probability distribution

characteristic function
Markov
homogeneous
transition law
Markov chain
Markov process
markovian model
matched
linear filter
matrix
covariance
trace of a
transition
Max (Lloyd and)
maximum ISI
maximum likelihood
method
maximum likelihood estimator
MCMC
mean
vector
measurement vector
Mersenne twister

method
acceptance-rejection
Capon
ESPRIT
fft-music
MUSIC
MUSIC 2D
root-music
subspace
Metropolis-Hastings algorithm
mixed excitation linear prediction (MELP)
MLE
model
Gaussian mixture (GMM)
hidden Markov
parametric
statistical
modem
modulation
PAM
quadrature amplitude
modulator
moments
method
Monte-Carlo
Monte-Carlo Markov chain
Monte-Carlo methods
MSC
MUSIC

N
new data-point
noise
measurement
model
subspace
noise subspace
normal equations
Nyquist
criterion
O
observation equation
order statistics
ordinary least squares (OLS)
orthogonal projection
orthogonality principle
overtraining
P
PAM
parameter estimation
parametric model
partial autocorrelation
particle filter
particles
path metrics
periodogram
phase
component

pivotal
prediction
backward
principal direction
probability
density
distribution
error
joint
probability distribution
complex gaussian
complex normal
gaussian
normal
sum of two r.v.
program
genenoisyAR1.m
ami.m
antithetic.m
applicationGibbs.m
applicationMetropolis.m
applmusic.m
bootstraponmean.m
bootstraponregression.m
boxmuller.m
BoxPierceTest.m
calibratenoisyAR1.m
cauchylaw.m
censoredHIV.m
censoredsimul.m

chi2test.m
Cmaq.m
Cmia1.m
Cmia2.m
Cmia3.m
Cmia4.m
Cmia5.m
correlationdistribution.m
Cpsk.m
critnyq.m
cumulEstimate.m
CumulInverseEstimate.m
CUSUMrecursiveformula.m
CUSUMtest.m
deltaMethodRice.m
egalizeimage.m
egallin.m
egallinCmp.m
estimdsproba.m
estimMarkovchain.m
fitLSnonlin.m
gauss2d.m
ICpercent.m
imagette.m
IS_GaussfromCauchy.m
kalmannoisyAR1.m
kalmantraj2D.m
LBG64.m
LBGcomp.m
leverageeffect.m

lloyd.m
MC.m
MLEexponential.m
MMmixture.m
mmse.m
MSCexo.m
multinomial.m
music2D.m
NyquistEye.m
orderEstimCV.m
ORing.m
partqv2ar1partqv2ar1.m
partqv2w.m
peestim.m
rayleighsimul.m
regcar.m
roccurve2gaussians.m
simumusic.m
smoothperio1dMSE.m
smoothperioCI.m
stratification.m
studentlawdiffm1m2.m
studentlawmdiffm0.m
testcorrelationWH.m
testEMforHMMG
testEMonGMM.m
testEspritMusic.m
testEstimState.m
testfluorcaries.m
testGLRTlogistic.m

testhdb3.m
testHMMGgenerate.m
testKarmaOnARMApq.m
testlattice.m
testlevinson.m
testlogistic.m
testmychi2.m
testmychi2rnd.m
testmyfisher.m
testmystudent.m
testmytinv.m
testviterbi.m
trajectorygeneration.m
Ttest.m
viterbi.m
whitenesstest.m
proposition distribution
p-value
Q
QAM
quadratic risk
quadrature component
quantile
quantization
linear
vector
R
raised cosine

random
vector
random process
AR
random value
mean
variance
random variable
complex gaussian
gaussian
independence
standard deviation
randomized test
ranking
Rayleigh
receiving operational characteristic (ROC) curve
regions
Voronoi
regression
regressors
regularized incomplete beta function
resolution limit of Fourier
RIBF
Riccati equation
right-censored data
ROC curve
roll-off
root-music
S

sequence (learning)
signal
subspace
signal-to-noise ratio
significance level
simple hypothesis
simulation (Monte-Carlo)
smoothed periodogram
smoothing
smoothing window
spectral density
spectrum
of a digital signal
state
vector
stationary (Markov chain)
statistical inference
statistical model
statistics (estimate)
step
gradient
strong sense white noise
strongly white noise
Student’s t
cdf
cumulative distribution
distribution
probability distribution

subspace
noise
signal
subspace methods
symbol
proportional to
rate
T
ternary alphabet
test statistic
trace
training set (LBG)
U
UMP
uniform distribution
uniformly most powerful
unilateral hypothesis testing
unilateral test
update step
V
variable
dependent
explanatory
independent
response
Voronoi regions

W
weak sense white noise
weakly white noise
weighted least squares
white
random sequence
white noise
strong sense
weak sense
whitening
wide sense stationary
Wiener
equalization
window
smoothing
WLS
WSS
Y
Yule-Walker
equations
Z
zero forcing

WILEY END USER LICENSE AGREEMENT
Go to www.wiley.com/go/eula to access Wiley’s ebook EULA.


