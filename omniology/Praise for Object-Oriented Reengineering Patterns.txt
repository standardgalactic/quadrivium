Praise for Object-Oriented 
Reengineering Patterns 
"How" to refactor is already well covered in the literature. However, "When" 
and "Why" can only be learned by experience. This book will give you a 
head start in learning when to start redesigning a system, when to stop for 
now, and what effects you can expect to see from your efforts. 
~Kent Beck, Director, Three Rivers Institute 
This book is full of practical, hands-on reengineering knowledge and ex- 
pertise presented in a form that makes it easy to understand and use. The 
patterns in this book thus help everyone who is concerned with using re- 
engineering to guide their work. I wished I had had this book in my library 
earlier. 
~Frank Buschmann, Senior Principal Engineer, Siemens AG 
This book is more than its title advertises. Effective reengineering is really 
about purposeful and efficient reading of someone else's code in order to 
produce predictable change. The same processes the authors highlight as 
patterns of skillful reengineering behavior can easily be cast as the skills 
you need to create readable, maintainable software systems. 
~Adele Goldberg, Neometron, Inc. 
If a guy named Dave brought a large box to my office that contained a lot of 
documentation and two CDs~installation disks for software that my com- 
pany wanted to reengineer~I'd be happy to have the authors of this book 
by my side. Barring that, having their book is the next best thing. No silver 
bullets, no hype, no promises that this will be easy~just a down-to-earth, 
easy-to-read, extremely useful book of helpful guidelines to tackle the 
project. Buy this book and browse it before Dave arrives in your office! It 
just might save you and your company a lot of grief. 
~Linda Rising, Independent Consultant 

About the Authors 
Serge Demeyer is a professor in the Department of Mathematics and Com- 
puter Science at the University of Antwerp in Belgium. He leads a research 
group investigating the theme of software reengineering, particularly re- 
engineering in an object-oriented context. He is an active member of the 
corresponding international research communities, serving in various con- 
ference organizations and program committees. 
St6phane Ducasse is an assistant professor in the Software Composition 
Group at the University of Bern where he serves as co-technical leader of the 
FAMOOS esprit project--a project whose goal is to come up with a set of 
reengineering techniques and tools to support the development of object- 
oriented frameworks. He has been involved in the organization of several 
workshops (at ECOOP and ESEC) and one tutorial concerning object- 
oriented reengineering. 
Oscar Nierstrasz is a professor of computer science at the University of Bern 
where he leads the Software Composition Group. He has been active in the 
object-oriented research community for many years, serving on program 
committees of ECOOR OOPSLA, ESEC, and others. He has given several 
tutorials and invited talks on object-oriented technology at various inter- 
national conferences and workshops. 

Foreword 
Martin Fowler 
ThoughtWorks, Inc. 
For a long time it's puzzled me that most books on software development 
processes talk about what to do when you are starting from a blank sheet of 
editor screen. It's puzzled me because that's not the most common situa- 
tion that people are in when they are writing code. Most people have to 
make changes to an existing code base, even if it's their own. In an ideal 
world this code base is well designed and well factored, but we all know 
how often the ideal world appears in our careers. 
This book is important because it's written from the perspective ofwhat 
to do with an imperfect yet valuable code base. I also like the fact that it's 
based on an effective mix of academic and industrial work. I visited the 
FAMOOS group in their early days during a chill early winter in Bern. I liked 
the way that they cycled between the field and the lab, trying out ideas on 
real projects, then coming back to the lab to reflect. 
This resulting book speaks with that experience. It gives you the build- 
ing blocks for a plan to tackle a difficult code base, and it gives you context 
for techniques like refactoring. It is a sad fact that there are too few of these 
kinds of books out there, when reengineering is still a common event. But 
I'm at least glad to see that while there aren't many books in this vein, this 
book is an example of how good they are. 
ix 

Foreword 
Ralph E.Johnson 
University of Illinois at Urbana-Champaign 
One of the signs of a good pattern is when experts who read it are likely to 
say, "Of course, everybody knows that" but beginners are likely to say, "In- 
teresting, but will it work?" Patterns should be easy to follow, but the most 
valuable patterns are those that are not obvious. Experts have learned from 
experience that patterns work, but beginners have to take patterns on faith 
until they use them and develop their own experience. 
Over the last couple of years, I've had the chance to give the patterns in 
this book to a wide variety of people and discuss them. My pattern discus- 
sion group has a few members who have decades of consulting experience, 
and they can quickly regale the group with stories of using these patterns. 
The younger members love the stories, as they are convinced of the value 
of the patterns. 
I made students in my software engineering class read some of the pat- 
terns as part of a section on reengineering. The section went well even 
though none of the students were excited about the patterns. They didn't 
have the experience to evaluate them. However, one of the students came 
back to me after his summer job and said that of everything in the course, 
the content that was the most useful was the patterns on reverse engineer- 
ing. Before that experience, the patterns seemed believable. Afterwards, 
they were believed! 
If you have a lot of experience with software reengineering then you 
probably won't learn much from this book. You should read it anyway, 
because you will want to give copies to people you work with, and you will 
want to use the vocabulary of the book when you talk with them. If you are 
new to reengineering, you should read the book, learn the patterns, and try 
them. You will learn a lot that will be valuable. Don't expect to understand 
the patterns completely before you try them because patterns are practi- 
cal, and practical knowledge has to be experienced to be fully understood. 
Nevertheless, the book will give you a big advantage. It is much easier to 
learn when you have a path to follow, and this book provides a reliable 
guide. 
xi 

Preface 
A Fairy Tale 
Once upon a time there was a Good Software Engineer whose 
customers knew exactly what they wanted. The Good Software Engineer 
worked very hard to design the Perfect System that would solve all the 
Customers' problems now and for decades. When the Perfect System was 
designed, implemented, and finally deployed, the Customers were very 
happy indeed. The Maintainer of the System had very little to do to keep 
the Perfect System up and running, and the Customers and the 
Maintainer lived happily every after. 
Why isn't real life more like this fairy tale? 
Could it be because there are no Good Software Engineers? Could it be 
because the Customers don't really know what they want? Or is it because 
the Perfect System doesn't exist? 
Maybe there is a bit of truth in all of these observations, but the real rea- 
sons probably have more to do with certain fundamental laws of software 
evolution identified several years ago by Manny Lehman and Les Belady 
[Lehm85]. The two most striking of these laws are 
9 The law of continuing change: A program that is used in a real-world en- 
vironment must change, or become progressively less useful in that en- 
vironment. 
9 The law of increasing complexity: As a program evolves, it becomes 
more complex, and extra resources are needed to preserve and simplify 
its structure. 
In other words, we are kidding ourselves if we think that we can know 
all the requirements and build the perfect system. The best we can hope 
for is to build a useful system that will survive long enough for it to be 
asked to do something new. 
eo 
XVll 

xviii 
P R E F A C E 
What Is This Book? 
This book came into being as a consequence of the realization that the 
most interesting and challenging side of software engineering may not be 
building brand-new software systems, but rejuvenating existing ones. 
From November 1996 to December 1999, we participated in a Euro- 
pean industrial research project called FAMOOS (ESPRIT Project 21975~ 
Framework-based Approach for Mastering Object-Oriented Software Evo- 
lution). The partners were Nokia (Finland), Daimler-Benz (Germany), Sema 
Group (Spain), Forschungszentrum Informatik Karlsruhe (Germany), and 
the University of Berne (Switzerland). Nokia and Daimler-Benz were both 
early adopters of object-oriented technology and had expected to reap 
significant benefits from this tactic. Now, however, they were experiencing 
many of the typical problems of legacy systems: they had very large, very 
valuable object-oriented software systems that were very difficult to adapt 
to changing requirements. The goal of the FAMOOS project was to develop 
tools and techniques to rejuvenate these object-oriented legacy systems so 
they would continue to be useful and would be more amenable to future 
changes in requirements. 
Our idea at the start of the project was to convert these big, object-ori- 
ented applications into frameworks~generic applications that can be eas- 
ily reconfigured using a variety of different programming techniques. We 
quickly discovered, however, that this was easier said than done. Mthough 
the basic idea was sound, it is not so easy to determine which parts of the 
legacy system should be converted, and exactly how to convert them. In 
fact, it is a nontrivial problem just to understand the legacy system in the 
first place, let alone figuring out what (if anything) is wrong with it. 
We learned many things from this project. We learned that, for the most 
part, the legacy code was not bad at all. The only reason that there were 
problems with the legacy code was that the requirements had changed 
since the original system was designed and deployed. Systems that had 
been adapted many times to changing requirements suffered from design 
drifl~the original architecture and design was almost impossible to rec- 
ognize~and that made it almost impossible to make further adaptations, 
exactly as predicted by Lehman and Belady's laws of software evolution. 
Most surprising to us, however, was the fact that, although each of the 
case studies we looked at needed to be reengineered for very different rea- 
sons--such as unbundling, scaling up requirements, porting to new envi- 
ronments, and so on--the actual technical problems with these systems 
were oddly similar. This suggested to us that perhaps a few simple tech- 
niques could go a long way to fixing some of the more common problems. 
We discovered that pretty well all reengineering activity must start with 
some reverse engineering, since you will not be able to trust the documen- 
tation (ifyou are lucky enough to have some). Basically you can analyze the 
source code, run the system, and interview users and developers to build a 

P R E F A C E 
xix 
model of the legacy system. Then you must determine what are the ob- 
stacles to further progress and fix them. This is the essence of reengineer- 
ing, which seeks to transform a legacy system into the system you would 
have built if you had the luxury of hindsight and could have known all the 
new requirements that you know today. But since you can't afford to re- 
build everything, you must cut corners and just reengineer the most criti- 
cal parts. 
Since FAMOOS, we have been involved in many other reengineering 
projects and have been able to further validate and refine the results of 
FAMOOS. 
In this book we summarize what we learned in the hope that it will help 
others who need to reengineer object-oriented systems. We do not pretend 
to have all the answers, but we have identified a series of simple tech- 
niques that will take you a long way. 
Why Patterns? 
A pattern is a recurring motif, an event or structure that occurs over and 
over again. Design patterns are generic solutions to recurring design prob- 
lems [Gamm95]. It is because these design problems are never exactly 
alike, but only very similar, that the solutions are not pieces of software, 
but documents that communicate best practice. 
Patterns have emerged in recent years as a literary form that can be 
used to document best practice in solving many different kinds of prob- 
lems. Although many kinds of problems and solutions can be cast as pat- 
terns, they can be overkill when applied to the simplest kinds of problems. 
Patterns as a form of documentation are most useful and interesting when 
the problem being considered entails a number of conflicting forces, and 
the solution described entails a number of trade-offs. Many well-known 
design patterns, for example, introduce run-time flexibility at the cost of 
increased design complexity. 
This book documents a catalogue of patterns for reverse engineering 
and reengineering legacy systems. None of these patterns should be ap- 
plied blindly. Each patterns resolves some forces and involves some trade- 
offs. Understanding these trade-offs is essential to successfully applying 
the patterns. As a consequence the pattern form seems to be the most nat- 
ural way to document the best practices we identified in the course of our 
reengineering projects. 
A pattern language is a set of related patterns that can be used in com- 
bination to solve a set of complex problems. We found that clusters of pat- 
terns seemed to function well in combination with each other, so we have 
organized this book into chapters that each presents such a cluster as a 
small pattern language. 

PREFACE 
We do not pretend that these clusters are "complete" in any sense, and 
we do not even pretend to have patterns that cover all aspects of reengi- 
neering. We certainly do not pretend that this book represents a systematic 
method for object-oriented reengineering. What we do claim is simply to 
have encountered and identified a number of best practices that exhibit 
interesting synergies. Not only is there strong synergy within a cluster of 
patterns, but the clusters are also interrelated in important ways. Each 
chapter therefore contains not only a pattern map that suggests how the 
patterns may function as a "language," but each pattern also lists and ex- 
plains how it may be combined or composed with other patterns, whether 
in the same cluster or a different one. 
Who Should Read This Book? 
This book is addressed mainly to practitioners who need to reengineer 
object-oriented systems. If you take an extreme viewpoint, you could say 
that every software project is a reengineering project, so the scope of this 
book is quite broad. 
We believe that most of the patterns in this book will be familiar to any- 
one with a bit of experience in object-oriented software development. The 
purpose of the book is to document the details. 
Acknowledgments 
We would like to thank first and foremost our FAMOOS partners at Nokia, 
Daimler, FZI, and Sema who provided the context for discovering these 
patterns. People like Juha (Julho) Tuominen, Roland Trauter, Eduardo Casais, 
and Theo Dirk Meijler played a crucial role while starting the project. We 
would especially like to thank our coauthors of the prototype for this book, 
The FAMOOS Object-Oriented Reengineering Handbook: Holger B~ir, Markus 
Bauer, Oliver Ciupke, Michele Lanza, Radu Marinescu, Robb Nebbe, Michael 
Przybilski, Tamar Richner, Matthias Rieger, Claudio Riva, Anne-Marie Sassen, 
Benedikt Schulz, Patrick Steyaert, Sander Tichelaar, and Joachim Weisbrod. 
Special thanks go to Perdita Stevens for the first discussions on reengineer- 
ing patterns. 
We gratefully acknowledge the financial support of the European Union 
toward ESPRIT Project 21975 (FAMOOS) as well as that of the Swiss govern- 
ment toward projects NFS-2000-46947.96 and BBW-96.0015. The Univer- 
sity of Antwerp provided financial support in the form of a grant entitled 
"Object Oriented Reengineering," while the Fund for Scientific Research in 
Flanders sponsored a research network named "Foundations of Software 
Evolution." 

PREFACE 
xxi 
Some of the material in this book was presented in the graduate course 
"Object-Oriented Software Reengineering," held at the University of Bern 
in the winter semesters of 1998 and 1999, and at several tutorials at OOPSLA 
and ECOOP. We would like to thank the participants of the courses and tu- 
torials for their feedback and input. We also would like to thank members 
of the Software Composition Group at the University of Bern for participat- 
ing in several pattern workshops and giving valuable feedback on many of 
the patterns in this book: Michele Lanza, Pietro Malorgio, Robbe Nebbe, 
Tamar Richner, Matthias Rieger, and Sander Tichelaar. 
Several of the patterns in this book have been presented elsewhere. We 
would like to thank our EuroPLoP shepherds Kent Beck (1998), Kyle Brown 
(1999), Neil Harrison (2000), Mary Lynn Manns (2000), Don Roberts (1998), 
and Charles Weir (1998), and all participants of the writers' workshops where 
these patterns have been discussed. Special thanks go to lens Coldewey for 
helping us out with pattern forms and forces. 
We would like to thank the members and friends of Ralph Johnson's 
Software Architecture Group who workshopped several chapters of this 
book: John Brant, Brian Foote, Alejandra Garrido, Peter Hatch, Ralph John- 
son, Brian Marick, Andrew Rosenfeld, Weerasak Witthawaskul, and Joe u 
Downloading and playing voluminous megabytes of workshop recordings 
in mp3 format truly made each of us feel like a "fly on the wall"! 
We would like to thank Tim Cox, our editor, Stacie Pierce, his assistant, 
and the team at Morgan Kaufmann for following our project with such dedi- 
cation. Also, thanks to Christa Preisendanz at DPunkt Verlag for putting us 
in touch with Tim in the first place! We especially appreciated the two very 
thorough rounds of reviews that this book underwent, and we only regret 
that the final draft of this book is nothing like the definitive work some of 
the reviewers clearly hoped it would be! We thank our reviewers for reading 
between the lines and helping to explain many of these patterns to us: Kyle 
Brown, Thierry Cattel, Oliver Ciupke, Koen De Hondt, Jim Coplien, Gert 
Florijn, Neil Harrison, Mary Lynn Manns, Alan O'Callaghan, Don Roberts, 
and Benedikt Schulz. 

CHAPTER 
Reengineering Patterns 
Why Do We Reengineer? 
A legacy is something valuable that you have inherited. Similarly, legacy 
software is valuable software that you have inherited. The fact you have 
inherited it may mean that it is somewhat old-fashioned. It may have been 
developed using an outdated programming language or an obsolete devel- 
opment method. Most likely it has changed hands several times and shows 
signs of many modifications and adaptations. 
Perhaps your legacy software is not even that old. With rapid develop- 
ment tools and rapid turnover in personnel, software systems can turn into 
legacies more quickly than you might imagine. The fact that the software is 
ualuable, however, means that you do not want to just throw it away. 
A piece of legacy software is critical to your business, and that is pre- 
cisely the source of all the problems: in order for you to be successful at 
your business, you must constantly be prepared to adapt to a changing 
business environment. The software that you use to keep your business 
running must therefore also be adaptable. Fortunately a lot of software can 
be upgraded, or simply thrown away and replaced when it no longer serves 
its purpose. But a legacy system can neither be replaced nor upgraded 
except at a high cost. The goal of reengineering is to reduce the complexity 
of a legacy system sufficiently that it can continue to be used and adapted 
at an acceptable cost. 
The specific reasons that you might want to reengineer a software sys- 
tem can vary significantly. For example: 
9 You might want to unbundle a monolithic system so that the individual 
parts can be more easily marketed separately or combined in different 
ways. 
9 You might want to improve performance. (Experience shows that the 
right sequence is "first do it, then do it right, then do it fast," so you 

C H A P T E R 1 Reengineering Patterns 
might want to reengineer in order to clean up the code before thinking 
about performance.) 
9 You might want to port the system to a new platform. Before you do that, 
you may need to rework the architecture to clearly separate the plat- 
form-dependent code. 
9 You might want to extract the design as a first step to a new implementa- 
tion. 
9 You might want to exploit new technology, such as emerging standards 
or libraries, as a step toward cutting maintenance costs. 
9 You might want to reduce human dependencies by documenting knowl- 
edge about the system and making it easier to maintain. 
Although there may be many different reasons for reengineering a sys- 
tem, as we shall see, the actual technical problems with legacy software are 
often very similar. It is this fact that allows us to use some very general 
techniques to do at least part of the job of reengineering. 
Recognizing the Need to Reengineer 
How do you know when you have a legacy problem? 
Common wisdom says, "If it ain't broke, don't fix it." This attitude is 
often taken as an excuse not to touch any piece of software that is perform- 
ing an important function and seems to be doing it well. The problem with 
this approach is that it fails to recognize that there are many ways in which 
something may be "broken." From a functional point of view, something is 
broken only if it no longer delivers the function it is designed to perform. 
From a maintenance point of view, however, a piece of software is broken if 
it can no longer be maintained. 
So how can you tell that your software is going to break very soon? For- 
tunately there are many warning signs that tell you that you are headed 
toward trouble. The following symptoms usually do not occur in isolation 
but several at a time. 
9 Obsolete or no documentation. Obsolete documentation is a clear sign 
of a legacy system that has undergone many changes. Absence of docu- 
mentation is a warning sign that problems are on the horizon, as soon 
as the original developers leave the project. 
9 Missing tests. Even more important than up-to-date documentation is 
the presence of thorough unit tests for all system components, and sys- 
tem tests that cover all significant use cases and scenarios. The absence 
of such tests is a sign that the system will not be able to evolve without 
high risk or cost. 

Why DoWe Reengineer? 
3 
9 Departure of the original developers or users. Unless you have a clean, 
well-documented system with good test coverage, it will rapidly deteri- 
orate into an even less clean, more poorly documented system. 
9 Disappearance of inside knowledge about the system. This is a bad sign. 
The documentation is out of sync with the existing code base. Nobody 
really knows how it works. 
9 Limited understanding of the entire system. Not only does nobody 
understand the fine print, but hardly anyone has a good overview of the 
whole system. 
9 Too long to turn things over to production. Somewhere along the line the 
process is not working. Perhaps it takes too long to approve changes. 
Perhaps automatic regression tests are missing. Or perhaps it is difficult 
to deploy changes. Unless you understand and deal with the difficulties 
it will only get worse. 
9 Too much time to make simple changes. This is a clear sign that Lehman 
and Belady's law of increasing complexity has kicked in: the system is 
now so complex that even simple changes are hard to implement. If it 
takes too long to make simple changes to your system, it will certainly 
be out of the question to make complex changes. If there is a backlog of 
simple changes waiting to get done, then you will never get to the diffi- 
cult problems. 
9 Need for constant bugfixes. Bugs never seem to go away. Every time you 
fix a bug, a new one pops up next to it. This tells you that parts of your 
application have become so complex that you can no longer accurately 
assess the impact of small changes. Furthermore, the architecture of 
the application no longer matches the needs, so even small changes 
will have unexpected consequences. 
9 Maintenance dependencies. When you fix a bug in one place, another 
bug pops up somewhere else. This is often a sign that the architecture 
has deteriorated to the point where logically separate components of 
the system are no longer independent. 
9 Big build times. Long recompilation times slow down your ability to 
make changes. Long build times may also be telling you that the organi- 
zation of your system is too complex for your compiler tools to do their 
job efficiently. 
9 Difficulties separating products. If there are many clients for your prod- 
uct, and you have difficulty tailoring releases for each customer, then 
your architecture is no longer right for the job. 
9 Duplicated code. Duplicated code arises naturally as a system evolves, 
as a shortcut to implementing nearly identical code, or merging differ- 
ent versions of a software system. If the duplicated code is not elimi- 
nated by refactoring the common parts into suitable abstractions, 

C H A P T E R 1 ReengineeringPatterns 
maintenance quickly becomes a nightmare as the same code has to be 
fixed in many places. 
Code smells. Duplicated code is an example of code that "smells bad" 
and should be changed. Long methods, big classes, long parameter 
lists, switch statements, and data classes are a few more examples that 
have been documented by Kent Beck and others [Fowl99]. Code smells 
are often a sign that a system has been repeatedly expanded and 
adapted without having been reengineered. 
What's Special about Objects? 
Although many of the techniques discussed in this book will apply to any 
software system, we have chosen to focus on object-oriented legacy sys- 
tems. There are many reasons for this choice, but mainly we feel that this is 
a critical point in time at which many early adopters of object-oriented 
technology are discovering that the benefits they expected to achieve by 
switching to objects have been very difficult to realize. 
There are now significant legacy systems even in Java. It is not age that 
turns a piece of software into a legacy system, but the rate at which it has 
been developed and adapted without having been reengineered. 
The wrong conclusion to draw from these experiences is that "objects 
are bad, and we need something else." Already we are seeing a rush toward 
many new trends that are expected to save the day: patterns, components, 
UML, XMI, and so on. Any one of these developments may be a Good 
Thing, but in a sense they are all missing the point. 
One of the conclusions you should draw from this book is that, well, 
objects are pretty good, but you must take good care of them. To under- 
stand this point, consider why legacy problems arise at all with object- 
oriented systems, if they are supposed to be so good for flexibility, main- 
tainability, and reuse. 
First of all, anyone who has had to work with a nontrivial, existing object- 
oriented code base will have noticed that it is hard to find the objects. In a 
very real sense, the architecture of an object-oriented application is usu- 
ally hidden. What you see is a bunch of classes and an inheritance hier- 
archy. But that doesn't tell you which objects exist at run time and how they 
collaborate to provide the desired behavior. Understanding an object- 
oriented system is a process of reverse engineering, and the techniques 
described in this book help to tackle this problem. Furthermore, by re- 
engineering the code, you can arrive at a system whose architecture is 
more transparent and easier to understand. 
Second, anyone who has tried to extend an existing object-oriented 
application will have realized that reuse does not come for free. It is actually 

The Reengineering Life Cycle 
5 
very hard to reuse any piece of code unless a fair bit of effort was put into 
designing it so that it could be reused. Furthermore, it is essential that 
investment in reuse requires management commitment to put the right 
organizational infrastructure in place and should only be undertaken with 
clear, measurable goals in mind [Gold95]. 
We are still not very good at managing object-oriented software pro- 
jects in such a way that reuse is properly taken into account. Typically 
reuse comes too late. We use object-oriented modeling techniques to de- 
velop very rich and complex object models, and hope that when we imple- 
ment the software we will be able to reuse something. But by then there is 
little chance that these rich models will map to any kind of standard library 
of components except with great effort. Several of the reengineering tech- 
niques we present address how to uncover these components after the 
fact. 
The key insight, however, is that the "right" design and organization of 
your objects is not something that is or can be evident from the initial 
requirements alone, but rather as a consequence of understanding how 
these requirements evolve. The fact that the world is constantly changing 
should not be seen purely as a problem, but as the key to the solution. 
Any successful software system will suffer from the symptoms of legacy 
systems. Object-oriented legacy systems are just successful object-oriented 
systems whose architecture and design no longer respond to changing 
requirements. A culture of continuous reengineering is a prerequisite for 
achieving flexible and maintainable object-oriented systems. 
The Reengineering Life Cycle 
Reengineering and reverse engineering are often mentioned in the same 
context, and the terms are sometimes confused, so it is worthwhile to be 
clear about what we mean by them. Chikofsky and Cross [Chik92] define 
the two terms as follows: 
Reverse Engineering is the process of analyzing a subject system to identify 
the system's components and their interrelationships and create represen- 
tations of the system in another form or at a higher level of abstraction. 
That is to say, reverse engineering is essentially concerned with trying to 
understand a system and how it ticks. 
Reengineering. . . is the examination and alteration of a subject system to 
reconstitute it in a new form and the subsequent implementation of the 
new form. 

C H A P T E R 1 ReengineeringPatterns 
Reengineering, on the other hand, is concerned with restructuring a sys- 
tem, generally to fix some real or perceived problems, but more specifically 
in preparation for further development and extension. 
The introduction of the term "reverse engineering" was clearly an invi- 
tation to define "forward engineering," so we have the following as well: 
Forward Engineering is the traditional process of moving from high-level 
abstractions and logical, implementation-independent designs to the 
physical implementation of a system. 
How exactly this process of forward engineering can or should work is a 
matter of great debate, although most people accept that the process is 
iterative and conforms to Barry Boehm's so-called spiral model of software 
development [Boeh88]. In this model, successive versions of a software 
system are developed by repeatedly collecting requirements, assessing 
risks, engineering the new version, and evaluating the results. This general 
framework can accommodate many different kinds of more specific pro- 
cess models that are used in practice. 
If forward engineering is about moving from high-level views of re- 
quirements and models toward concrete realizations, then reverse engi- 
neering is about going backward from some concrete realization to more 
abstract models, and reengineering is about transforming concrete im- 
plementations to other concrete implementations. 
Figure 1.1 illustrates this idea. Forward engineering can be understood 
as being a process that moves from high-level and abstract models and 
artifacts to increasingly concrete ones. Reverse engineering reconstructs 
higher-level models and artifacts from code. Reengineering is a process 
that transforms one low-level representation to another, while recreating 
the higher-level artifacts along the way. 
The key point to observe is that reengineering is not simply a matter of 
transforming source code, but of transforming a system at all its levels. For 
this reason it makes sense to talk about reverse engineering and reengi- 
neering in the same breath. In a typical legacy system, you will find that not 
only the source code, but all the documentation and specifications are out 
of sync. Reverse engineering is therefore a prerequisite to reengineering 
since you cannot transform what you do not understand. 
Reverse Engineering 
You carry out reverse engineering whenever you are trying to understand 
how something really works. Normally you only need to reverse engineer 
a piece of software if you want to fix, extend, or replace it. (Sometimes 
you need to reverse engineer software just in order to understand how 
to use it. This may also be a sign that some reengineering is called for.) 

The Reengineering LifeCycle 
7 
FIGURE 
Forward, reverse, and reengineering. 
As a consequence, reverse engineering efforts typically focus on redocu- 
menting software and identifying potential problems, in preparation for 
reengineering. 
You can make use of a lot of different sources of information while re- 
verse engineering. For example, you can 
9 read the existing documentation 
9 read the source code 
9 run the software 
9 interview users and developers 
9 code and execute test cases 
9 generate and analyze traces 
9 use various tools to generate high-level views of the source code and 
the traces 
9 analyze the version history 

C H A P T E R 1 Reengineering Patterns 
As you carry out these activities, you will be building progressively re- 
fined models of the software, keeping track of various questions and an- 
swers, and cleaning up the technical documentation. You will also be 
keeping an eye out for problems to fix. 
Reengineering 
Although the reasons for reengineering a system may vary, the actual tech- 
nical problems are typically very similar. There is usually a mix of coarse- 
grained architectural problems and fine-grained design problems. Typical 
coarse-grained problems include the following: 
9 Insufficient documentation: Documentation either does not exist or is 
inconsistent with reality. 
9 Improper layering: Missing or improper layering hampers portability 
and adaptability. 
9 Lack of modularity: Strong coupling between modules hampers evolu- 
tion. 
9 Duplicated code: "Copy, paste, and edit" is quick and easy, but leads to 
maintenance nightmares. 
9 Duplicated functionality: Similar functionality is reimplemented by 
separate teams, leading to code bloat. 
The most common fine-grained problems occurring in object-oriented 
software include the following: 
9 Misuse of inheritance: for composition and code reuse rather than 
polymorphism 
9 Missing inheritance: duplicated code and case statements to select 
behavior 
9 Misplaced operations: unexploited cohesion~operations outside in- 
stead of inside classes 
9 Violation of encapsulation: explicit type-casting, C++ "friends" 
9 Class abuse: lack of cohesion~classes as namespaces 
Finally, you will be preparing the code base for the reengineering ac- 
tivity by developing exhaustive test cases for all the parts of the system that 
you plan to change or replace. 
Reengineering similarly entails a number of interrelated activities. Of 
course, one of the most important is to evaluate which parts of the system 
should be repaired and which should be replaced. 

Reengineering Patterns 
9 
The actual code transformations that are performed fall into a number 
of categories. According to Chikofsky and Cross: 
Restructuring is the transformation from one representation form to an- 
other at the same relative abstraction level, while preserving the system's 
external behavior. 
Restructuring generally refers to source code translation (such as the 
automatic conversion from unstructured "spaghetti" code to structured, 
or "goto-less," code), but it may also entail transformations at the design 
level. 
Refactoring is restructuring within an object-oriented context. Martin 
Fowler defines it this way [Fowl99]: 
Refactoring is the process of changing a software system in such a way that 
it does not alter the external behavior of the code yet improves its internal 
structure. 
It may be hard to tell the difference between software "reengineering" 
and software "maintenance." IEEE has made several attempts to define 
software maintenance, including this one: 
9 the modification of a software product after delivery to correct faults, 
to improve performance or other attributes, or to adapt the product to a 
changed environment. 
Most people would probably consider that "maintenance" is routine 
whereas "reengineering" is a drastic, major effort to recast a system, as sug- 
gested by Figure 1.1. Others, however, might argue that reengineering is 
just a way of life. You develop a little, reengineer a little, develop a little 
more, and so on [BeckO0]. In fact, there is good evidence to support the 
notion that a culture of continuous reengineering is necessary to obtain 
healthy, maintainable software systems. 
Continuous reengineering, however, is not yet common practice, and 
for this reason we present the patterns in this book in the context of a 
major reengineering effort. Nevertheless, keep in mind that most of the 
techniques we present will apply just as well when you reengineer in small 
iterations. 
Reengineering Patterns 
Patterns as a literary form were introduced by the architect Christopher 
Alexander in his landmark 1977 book, A Pattern Language. In this book, 
Alexander and his colleagues presented a systematic method for archi- 

10 
r H A P T e R 1 Reengineering Patterns 
tecting a range of different kinds of physical structures, from rooms to 
buildings and towns. Each issue was presented as a recurring pattern, a 
general solution that resolves a number of forces, but must be applied in a 
unique way to each problem according to the specific circumstances. The 
actual solution presented in each pattern was not necessarily so interest- 
ing, but rather the discussion of the forces and trade-offs consisted of the 
real substance they communicated. 
Patterns were first adopted by the software community as a way of doc- 
umenting recurring solutions to design problems. As with Alexander's pat- 
terns, each design pattern entailed a number of forces to be resolved, and a 
number of trade-offs to consider when applying the pattern. Patterns turn 
out to be a compact way to communicate best practice: not just the actual 
techniques used by experts, but the motivation and rationale behind them. 
Patterns have since been applied to many aspects of software development 
other than design, and particularly to the process of designing and devel- 
oping software. 
The process of reengineering is, like any other process, one in which 
many standard techniques have emerged, each of which resolves various 
forces and may entail many trade-offs. Patterns as a way of communicat- 
ing best practice are particularly well suited to presenting and discussing 
these techniques. 
Reengineering patterns codify and record knowledge about modifying 
legacy software: they help in diagnosing problems and identifying weak- 
nesses that may hinder further development of the system, and they aid in 
finding solutions that are more appropriate to the new requirements. We 
see reengineering patterns as stable units of expertise that can be con- 
sulted in any reengineering effort: they describe a process without propos- 
ing a complete methodology, and they suggest appropriate tools without 
"selling" a specific one. 
Many of the reverse engineering and reengineering patterns have some 
superficial resemblance to design patterns, in the sense that they have 
something to do with the design of software. But there is an important dif- 
ference in that design patterns have to do with choosing a particular solu- 
tion to a design problem, whereas reengineering patterns have to do with 
discovering an existing design, determining what problems it has, and 
repairing these problems. As a consequence, reengineering patterns have 
more to do with the process of discovery and transformation than purely 
with a given design structure. For this reason the names of most of the 
patterns in this book are process-oriented, like Always Have a Running 
Version (Pattern 7.5), rather than being structure-oriented, like Adapter 
(Pattern A.11) or Facade (Pattern A.12). 
Whereas a design pattern presents a solution for a recurring design 
problem, a reengineering pattern presents a solution for a recurring re- 
engineering problem. The artifacts produced by reengineering patterns are 
not necessarily designs. They may be as concrete as refactored code, or in 

A Map of Reengineering Patterns 
11 
the case of reverse engineering patterns, they may be as abstract as insights 
into how the system functions. 
The marks of a good reengineering pattern are (1) the clarity with which 
it exposes the advantages, the cost, and the consequences of the target 
artifacts with respect to the existing system state, and not how elegant the 
result is, and (2) the description of the reengineering process: how to get 
from one state of the system to another. 
Reengineering patterns entail more than code refactorings. A reengi- 
neering pattern may describe a process that starts with the detection of the 
symptoms and ends with the refactoring of the code to arrive at the new 
solution. Refactoring is only the last stage of this process and addresses the 
technical issue of automatically or semiautomatically modifying the code 
to implement the new solution. Reengineering patterns also include other 
elements that are not part of refactorings: they emphasize the context of 
the symptoms, by taking into account the constraints that reengineers are 
facing, and include a discussion of the impact of the changes that the 
refactored solution may introduce. 
The Form of a Reengineering Pattern 
In Figure 1.2 we see an example of a simple pattern that illustrates the for- 
mat we use in this book. The actual format used may vary slightly from pat- 
tern to pattern, since they deal with different kinds of issues, but generally 
we will see the same kinds of headings. 
The name of a pattern, if well chosen, should make it easy to remember 
the pattern and to discuss it with colleagues. ("I think we should Refactor 
to Understand or we will never figure out what's going on here.") The intent 
should communicate very compactly the essence of a pattern and tell you 
whether it applies to your current situation. 
Many of the reengineering patterns are concerned with code transfor- 
mation, in which case a diagram may be used to illustrate the kind of trans- 
formation that takes place. Typically such patterns will additionally include 
steps to detect the problem to be resolved, as well as code fragments illus- 
trating the situation before and after the transformation. 
A Map of Reengineering Patterns 
The patterns in this book are organized according to the reengineering life 
cycle presented earlier. In Figure 1.3 we can see the chapters in this book 
represented as clusters of patterns along the life cycle. The diagram sug- 
gests that the patterns may be applied in sequence. Although this may well 
be the case, in practice you are more likely to iterate between reverse engi- 
neering and reengineering tasks. The diagram is simplistic in the same 

12 
C H A P T E R 1 Reengineering Patterns 
PATTERN 
Problem 
Solution 
Trade-offs 
Rationale 
Known 
Uses 
Related 
Patterns 
What Next 
If It Ain't Broke, Don't Fix It 
-1 The name is usually an action phrase. 
Intent: Save your reengineering effort for the parts of the 
system that will make a difference. 
Which parts of a legacy system should you reengineer? 
This problem is difficult because 
9 Legacy software systems can be large and complex. 
9 Rewriting everything is expensive and risky. 
Yet, solving this problem is feasible because 
9 Reengineering is always driven by some concrete goals. 
The intent should capture the 
essence of the pattern. 
The problem is phrased as a simple 
-] question.Sometimes the context is 
explicitly described. 
Next we discuss the forces! They tell 
us why the problem is difficult and 
interesting. We also pinpoint the key 
to solving the problem. 
Only fLX the parts that are "broken"mthose that can no 
-7 The solution sometimes includes a 
longer be adapted to planned changes. 
_I recipe of steps to apply the pattern. 
Pros 
You don't waste your time fixing things that are not on 
your critical path. 
Cons 
Delaying repairs that do not seem critical may cost you 
more in the long run. 
Difficulties 
It can be hard to determine what is "broken." 
Each pattern entails some positive 
and negative trade-offs. 
There may well be parts of the legacy system that are ugly 
but work well and that do not pose any significant main- 
tenance effort. If these components can be isolated and 
wrapped, it may never be necessary to replace them. 
I 
We explain why the solution makes 
sense. 
J 
Alan M. Davis discusses this in his book, 201 Principles of 
We list some well-documented 
Software Development. 
instances of the pattern. 
Be sure to Fix Problems, Not Symptoms (Pattern 2.5). 
Consider starting with the Most Valuable First (Pattern 2.4). 
Related patterns may suggest 
alternative actions. Other patterns 
may suggest logical follow-up action. 
FIG U R E 
The format of a typical reengineering pattern. 

A Map of Reengineering Patterns 
13 
Tests: Your Life Insurance! 
~_ 
_ 
(Chapter 6) 
/ DetailedModel Capture 
Migration Strategies 
~__ 
i Chapter 5) 
(Chapter 7) 
[ Initial Understanding 
Detecting Duplicated Code 
/~ 
(Chapter 4) 
(Chapter 8) 
/ (chaCten:3~ t 
Re distrib(chaptSP 9)sibilitie s 
FIGURE 
Setting Direction 
(Chapter 2) 
Legacy 
system 
A map of reengineering pattern clusters. 
Transform Conditionals to I~ 
Polymorphism 1 
(Chapter 10) 
Reengineered 
system 
sense that the "waterfall" life cycle is simplistic: it may be a useful way to 
keep track of the different software engineering activities and their rela- 
tionships, even though we know that they are not carried out sequentially 
but iteratively. 
Each cluster of patterns is presented as a simple "pattern language"~a 
set of related patterns that may be combined to address a common set of 
problems. As such, each chapter will typically start with an overview and a 
map of the patterns in that chapter, suggesting how they may be related. 
"Setting Direction" (Chapter 2) contains several patterns to help you 
determine where to focus your reengineering efforts and make sure you 
stay on track. "First Contact" (Chapter 3) consists of a set of patterns that 
may be useful when you encounter a legacy system for the first time. "Ini- 
tial Understanding" (Chapter 4) helps you to develop a first simple model 
of a legacy system, mainly in the form of class diagrams. "Detailed Model 
Capture" (Chapter 5) helps you to develop a more detailed model of a par- 
ticular component of the system. 

14 
C H A P T E R I ReengineeringPatterns 
"Tests: Your Life Insurance!" (Chapter 6) focuses on the use of testing 
not only to help you understand a legacy system, but also to prepare it for a 
reengineering effort. "Migration Strategies" (Chapter 7) helps you keep a 
system running while it is being reengineered and increases the chances 
that the new system will be accepted by its users. "Detecting Duplicated 
Code" (Chapter 8) can help you identify locations where code may have 
been copied and pasted, or merged from different versions of the software. 
"Redistribute Responsibilities" (Chapter 9) helps you discover and reengi- 
neer classes with too many responsibilities. "Transform Conditionals to 
Polymorphism" (Chapter 10) will help you to redistribute responsibilities 
when an object-oriented design has been compromised over time. 

CHAPTER 
Setting Direction 
When you start a reengineering project, you will be pulled in many differ- 
ent directions, by management, bythe users, by your own team. It is easy to 
be tempted to focus on the parts that are technically the most interesting, 
or the parts that seem like they will be easiest to fix. But what is the best 
strategy? How do you set the direction of the reengineering effort, and how 
do you maintain direction once you have started? 
Forces 
The following is a list of forces you should be aware of during the course of 
a reengineering project. 
9 A typical reengineering project will be burdened with a lot of interests 
that pull in different directions. Technical, ergonomic, economic, and 
political considerations will make it difficult for you and your team to 
establish and maintain focus. 
9 Communication in a reengineering project can be complicated by either 
the presence or absence of the original development team. 
9 The legacy system will pull you toward a certain architecture that may 
not be the best for the future of the system. 
9 You will detect many problems with the legacy software, and it will be 
hard to set priorities. 
9 It is easy to get seduced by focusing on the technical problems that in- 
terest you the most, rather than what is best for the project. 
9 It can be difficult to decide whether to wrap, refactor, or rewrite a prob- 
lematic component of a legacy system. Each of these options will ad- 
dress different risks and will have different consequences for the effort 
required, the speed with which results can be evaluated, and the kinds 
of changes that can be accommodated in the future. 
17 

18 
C H A P T E R 2 Setting Direction 
When you are reengineering the system, you may be tempted to over- 
engineer the new solution to deal with every possible eventuality. 
Overview 
Setting Direction is a cluster of patterns that can apply to any development 
project, but also has special relevance to a reengineering effort (see Figure 
2.1 on page 16). As such, we have chosen a streamlined pattern format to 
describe them (Problem, Solution, and Discussion). 
You should Agree on Maxims (Pattern 2.1) in order to establish a 
common understanding within the reengineering team of what is at stake 
and how to achieve it. You should Appoint a Navigator (Pattern 2.2) to 
maintain the architectural vision. Everyone should Speak to the Round 
Table (Pattern 2.3) to maintain team awareness of the state of the project. 
To help you focus on the right problems and the critical decisions, it is 
wise to tackle the Most Valuable First (Pattern 2.4). Note that this will help 
you to Involve the Users (Pattern 7.1) and Build Confidence (Pattern 7.2). 
In order to decide whether to wrap, refactor, or rewrite, you should Fix Prob- 
lems, Not Symptoms (Pattern 2.5). Change for change's sake is not produc- 
tive, so If It Ain't Broke, Don't Fix It (Pattern 2.6). Although you may be 
tempted to make the new system very flexible and generic, it is almost 
always better to Keep It Simple (Pattern 2.7). 
PATTERN 
Problem 
Agree on Maxims 
How do you establish a common sense of purpose in a team? 
Solution 
Establish the key priorities for the project and identify guiding principles 
that will help the team to stay on track. 
Discussion 
Any reengineering project must cope with a large number of conflicting 
interests. Management wants to protect its legacy by improving competi- 
tiveness of its product and reducing maintenance costs. Users want im- 
proved functionality without disrupting their established work patterns. 
Developers and maintainers would like their jobs to become simpler with- 
out being made obsolete. Your team members may each have their own 
ideas about what a new system should look like. 

P A T T E R N 2.2 Appoint a Navigator 
19 
Unless there is a clear understanding about certain fundamental ques- 
tions, such as What is our business model? or Who is responsible for what? 
you risk that the team will be pulled apart by conflicting interests, and you 
will not achieve your goal. Maxims are rules of conduct that can help steer 
a project that is pulled in many directions. Goldberg and Rubin [Gold95] 
give numerous examples of maxims, such as "Everyone is responsible for 
testing and debugging" and "You cannot do it right the first time." 
All of the patterns in this chapter can be read as maxims (rather than as 
patterns), since they are intended to guide a team and keep it on track. A 
maxim like Most Valuable First (Pattern 2.4), for example, is intended to 
prevent a team from squandering reengineering effort on technically inter- 
esting but marginal aspects that neither protect nor add value to the legacy 
system. Agree on Maxims is itself a maxim that can help a team detect 
when it is rudderless. 
A key point to remember is that any maxim may only have a limited life- 
time. It is important to periodically reevaluate the validity of any maxims 
that have been adopted. A project can get completely off track if you agree 
on the wrong maxims, or the right ones but at the wrong time. 
PATTERN 
Problem 
Solution 
Appoint a Navigator 
How do you maintain architectural vision during the course of a complex 
project? 
Appoint a specific person whose responsibility in the role of Navigator is to 
ensure that the architectural vision is maintained. 
Discussion 
The architecture of any system tends to degrade with time as it becomes 
less relevant to new, emerging requirements. The challenge of a reengi- 
neering project is to develop a new architectural vision that will allow the 
legacy system to continue to live and evolve for several more years. With- 
out a Navigator, the design and architecture of the old system will tend to 
creep into and take over the new one. 
You should tackle the Most Valuable First (Pattern 2.4) so you can deter- 
mine what are the most critical issues that the new architecture should 
address, and test those aspects early in the reengineering project. 
A sound architecture will help you to Fix Problems, Not Symptoms (Pat- 
tern 2.5). 
Alan O'Callaghan also refers to the Navigator as the "Keeper of the Flame" 
[Oca199]. 

20 
C H A P T E R 2 Setting Direction 
PATTERN 
Problem 
Speak to the Round Table 
How do you keep your team synchronized? 
Solution 
Hold brief, regular round table meetings. 
Discussion 
Knowledge and understanding of a legacy system is always distributed and 
usually hidden. A reengineering team is also performing archeology. The 
information that is extracted from a legacy system is a valuable asset that 
must be shared for it to be exploited. 
Nobody has time for meetings, but without meetings, communication 
is ad hoc and random. Regular, focused round table meetings can achieve 
the goal of keeping team members synchronized with the current state of 
affairs. Round table meetings should be brief, but everyone must be re- 
quired to contribute. A simple approach is to have everyone say what they 
haue done since the last meeting, what they haue learned or perhaps what 
problems they haue encountered, and what they plan to do until the next 
meeting. 
Round table meetings should be held at least once a week, but perhaps 
as often as daily. 
Minutes of a meeting are important to maintain a log of progress, but 
keeping minutes can be an unpleasant task. To keep it simple, record only 
decisions taken and actions to be performed by a certain deadline. 
Beck and Fowler recommend "Stand Up Meetings" (meetings without 
chairs) as a way to keep round table meetings short [Beck01]. 
PATTERN 
Most Valuable First 
Problem 
Which problems should you focus on first? 
Solution 
Start working on the aspects that are most valuable to your customer. 
Discussion 
A legacy system may suffer from a great number of problems, some of 
which are important, and others of which may not be at all critical for the 
customer's business. By focusing on the most valuable parts first, you 
increase the chances that you will identify the right issues at stake and that 

P A T T E R N 2.4 Most Valuable First 
21 
you will be able to test early in the project the most important decisions, 
such as which architecture to migrate to or what kind of flexibility to build 
into the new system. 
By concentrating first on a part of the system that is valuable to the 
client, you also maximize the commitment that you, your team members, 
and your customers will have in the project. You furthermore increase your 
chances of having early positive results that demonstrate that the reengi- 
neering effort is worthwhile and necessary. 
Nevertheless there are a number of difficulties in applying this pattern. 
First, who is your customer? 
There are many stakeholders in any legacy system, but only one of 
these is your customer. You can only set priorities if you have a clear 
understanding of who should be calling the shots. 
Second, how do you tell what is valuable? 
9 It can be difficult to assess exactly what is the most valuable aspect for a 
customer. Once a company asked us to assess if a system could be mod- 
ularized because they wanted to switch their architecture. After long 
discussions with them, however, it turned out that in fact they really 
wanted to have a system where business rules could be more explicit, a 
system that new programmers could understand more easily, to reduce 
the risk that only one programmer understands it. 
9 Try to understand the customer's business model. This will tell you how 
to assess the value of the various aspects of the system. Everything that 
does not relate directly to the business model is likely to be a purely 
technical side issue. 
9 Try to determine what measurable goal the customer wants to obtain. 
This must be an external manifestation of some aspect of the system or 
its evolution, for example, better response time, faster time to market of 
new features, or easier tailoring to individual clients needs. 
9 Try to understand whether the primary goal is mainly to protect an exist- 
ing asset, or rather to add value in terms of new features or capabilities. 
9 Examine the change logs and determine where the most activity has 
historically been in the system. The most valuable artifact is often the 
one that receives the most change requests (see Learn from the Past, 
Pattern 5.5). 
9 If the customer is unwilling or unable to set priorities, then play the 
Planning Game [Beck01]: collect requirements from all the stakehold- 
ers, and make a ballpark estimate of the effort required for each identi- 
fiable task. Given an initial budget of effort for an early first milestone, 
ask the customer to select tasks that will fit in the budget. Repeat this 
exercise at each iteration. 

22 
C H A P T E R 2 SettingDirection 
PATTERN 2.4 continued 
Beware of changing perceptions. Initially the customer may draw your 
attention to certain symptoms of problems with the legacy system, 
rather than the problems themselves (see Fix Problems, Not Symptoms, 
Pattern 2.5). 
Third, isn't there a risk of raising expectations too high? 
If you fail to deliver good initial results, you will learn a lot, but you risk 
losing credibility. It is therefore critical to choose carefully initial tasks 
that not only demonstrate value for the customer, but also have a high 
chance of success. Therefore, take great care in estimating the effort of 
the initial tasks. 
The key to success is to plan for small, frequent iterations. If the initial 
task identified by the customer is too large to demonstrate initial results 
in a short time flame (such as two weeks), then insist on breaking it 
down into smaller subtasks that can be tackled in shorter iterations. If 
you are successful in your first steps, you will certainly raise expecta- 
tions, but this is not bad if the steps stay small. 
Finally, what if the most valuable part is a rat's nest? 
9 Unfortunately, reengineering a legacy system is often an act of despera- 
tion, rather than a normal, periodic process of renovation. It may well 
be that the most valuable part of the system is also the part that is the 
most complex, impenetrable, and difficult to modify and debug. 
9 High change rates may also be a sign of large numbers of software de- 
fects. Typically 80% of software defects occur in 5% of the code, thus the 
strategy to "Renovate the Worst First" [Davi95] can pay off big by elimi- 
nating the most serious source of problems in the system. There are 
nevertheless considerable risks: (1) it may be hard to demonstrate early, 
positive results, (2) you are tackling the most complicated part of the 
system with little information, and (3) the chances are higher that you 
will fall flat on your face. 
9 Determine whether to wrap, refactor, or rewrite the problematic com- 
ponent by making sure you Fix Problems, Not Symptoms (Pattern 2.5). 
Once you have decided what is the most valuable part of the system to 
work on, you should Involve the Users (Pattern 7.1) in the reengineering 
effort so you can Build Confidence (Pattern 7.2). If you Migrate Systems 
Incrementally (Pattern 7.3), the users will be able to use the system as it is 
reengineered and provide continuous feedback. 

P A T T E R N 2.5 Fix Problems, Not Symptoms 
23 
PATTERN 
Problem 
Solution 
Fix Problems, Not Symptoms 
How can you possibly tackle all the reported problems? 
Address the source of a problem, rather than particular requests of your 
stakeholders. 
Discussion 
Although this is a very general principle, it has a particular relevance for 
reengineering. Each stakeholder has a different viewpoint of the system 
and may only see part of it. The problems they want you to f'Lx may be just 
manifestations of deeper problems in the system. For example, the fact 
that you do not get immediate feedback for certain user actions may be a 
consequence of a dataflow architecture. Implementing a workaround may 
just aggravate the problem and lead to more workarounds. If this is a real 
problem, you should migrate to a proper architecture. 
A common difficulty during a reengineering effort is to decide whether 
to wrap, refactor, or rewrite a legacy component. Most Valuable First (Pat- 
tern 2.4) will help you determine what priority to give to problems in the 
system and will tell you which problems are on your critical path. Fix Prob- 
lems, Not Symptoms tells you to focus on the source of a problem, and not 
its manifestation. For example: 
9 If the code of a legacy component is basically stable, and problems 
mainly occur with changes to clients, then the problem is likely to be 
with the interface to the legacy component, rather than its implemen- 
tation, no matter how nasty the code is. In such a case, you should con- 
sider applying Present the Right Interface (Pattern 7.8) to just f'LX the 
interface. 
9 If the legacy component is largely defect free, but is a major bottleneck 
for changes to the system, then it should probably be refactored to limit 
the effect of future changes. You might consider applying Split Up God 
Class (Pattern 9.3) to migrate toward a cleaner design. 
9 If the legacy component suffers from large numbers of defects, consid- 
er applying Make a Bridge to the New Town (Pattern 7.7) as a strategy 
for migrating legacy data to the new implementation. 
This pattern may seem to conflict with If It Ain't Broke, Don't Fix It (Pat- 
tern 2.5), but it doesn't really. Something that is not really "brokeff' cannot 
really be the source of a problem. Wrapping, for example, may seem to be a 
workaround, but it may be the right solution if the real problem is just with 
the interface to a legacy component. 

24 
C H A P T E R 2 SettingDirection 
PATTERN 
Problem 
Solution 
Discussion 
If It Ain't Broke, Don't Fix It 
Which parts of a legacy system should you reengineer and which should 
you leave as they are? 
Only fix the parts that are "broken"~those that can no longer be adapted 
to planned changes. 
Change for change's sake is not necessarily a good thing. There may well be 
parts of the legacy system that may be ugly, but work well and do not pose 
any significant maintenance effort. If these components can be isolated 
and wrapped, it may never be necessary to replace them. 
Anytime you "f'Lx" something, you also risk breaking something else in 
the system. You also risk wasting precious time and effort on marginal issues. 
In a reengineering project, the parts that are "broken" are the ones that 
are putting the legacy at risk: 
9 Components that need to be frequently adapted to meet new require- 
ments, but are difficult to modify due to high complexity and design drift 
9 Components that are valuable, but traditionally contain a large number 
of defects 
Software artifacts that are stable and do not threaten the future of the 
legacy system are not "broken" and do not need to be reengineered, no mat- 
ter what state the code is in. 
PATTERN 
Problem 
Solution 
Discussion 
Keep It Simple 
How much flexibility should you try to build into the new system? 
Prefer an adequate but simple solution to a potentially more general but 
complex solution. 
This is another general principle with special significance for reengineer- 
ing. We are bad at guessing how much generality and flexibility we really 

P A T T E R N 2.7 Keep It Simple 25 
need. Many software systems become bloated as every conceivable feature 
is added to them. 
Flexibility is a double-edged sword. An important reengineering goal is 
to accommodate future change. But too much flexibility will make the new 
system so complex that you may actually impede future change. 
Some people argue that it is necessary to "plan for reuse," hence to 
make an extra effort to make sure that every software entity that might 
conceivably be useful to somebody else is programmed in the most gen- 
eral way possible, with as many knobs and buttons as possible. This rarely 
works, since it is pretty well impossible to anticipate who will want to use 
something for what purpose. The same holds for end user software. 
"Do the simplest thing that will work" is a maxim of extreme program- 
ming [Beck00] that applies to any reengineering effort. This strategy re- 
inforces Involve the Users (Pattern 7.1) and Build Confidence (Pattern 7.2) 
since it encourages you to quickly introduce simple changes that users can 
evaluate and respond to. 
When you do the complex thing, you will probably guess wrong (in 
terms ofwhat you really need) and it will be harder to fix. Ifyou keep things 
simple, you will be done faster, get feedback faster, and recover from errors 
more easily. Then you can make the next step. 

CHAPTER 
First Contact 
You are part of a Swiss team developing a software system named proDoc 
that supports doctors in their day-to-day operations. The main functional 
requirements concern (1) maintaining patient files and (2) keeping track of 
the money to be paid by patients and health insurance companies. The 
health care legislation in Switzerland is quite complicated and changes 
regularly, hence there are few competitors to worry about. Nevertheless, a 
flesh start-up company has recently acquired considerable market share 
with a competing product named XDoctor. The selling features of XDoctor 
are its platform independence and its integration with the Internet. The 
system offers a built-in email client and Web browser. XDoctor also ex- 
ploits the Internet for the transaction processing with the health insurance 
companies. 
To ensure its position in the market, your company has purchased 
XDoctor and now wants to recover as much as possible from the deal. In 
particular, they want to lift the Internet functionality out of XDoctor to re- 
use it in proDoc. You are asked to make a first evaluation and develop a 
plan on how to merge the two products into one. At the outset, there is very 
little known about the technical details of the competing product. From 
the original development team of four people, only one has joined your 
company. His name is Dave and he has brought a large box to your office 
containing lots of paper (the documentation?) and two CDs. The first is the 
XDoctor installation disk containing an installer for Windows, MacOS, and 
Linux. The other contains about 50,000 lines of Java code and another 
10,000 lines of C code. Looking kind of desperately at this box sitting on 
your desk, you're wondering, "Where on earth do I start?" 
Forces 
It is surprising how often reengineering projects get started. Not only does 
it happen after a fusion of two companies, but we also encountered projects 
27 

28 
CHAPTER 3 First Contact 
in which code libraries were obtained from companies that later went 
bankrupt, or in which complete maintenance teams quit their project, 
leaving behind a very valuable but incomprehensible piece of code. Of 
course, the obvious question to ask is "Where do I start?" It turns out that 
this is one of the crucial questions to answer during a reengineering proj- 
ect, which is why we devote an entire chapter to its answer. 
All the patterns in this cluster can be applied to the very early stages of a 
reengineering project: you're facing a system that is completely new to 
you, and within a few days you must determine whether something can be 
done with it and present a plan on how to proceed. Making such an initial 
assessment is difficult, however, because you quickly need accurate results 
while considering the long-term effects of your decisions. To deal with the 
inherent conflict between quick, accurate, and longer-term effects, the 
patterns in this cluster must resolve the following forces: 
9 Legacy systems are large and complex. Scale is always an issue when 
dealing with legacy systems. ~ However, there is only so much a single 
reengineering team can do, and when the legacy system is too big or too 
complex, you can't do the job in one shot. Consequently, split the system 
into manageable pieces, where a manageable piece is one you can han- 
dle with a single reengineering team. 
How much a single team can manage varies with the goal of the reengi- 
neering project, the state of the original system, the experience and skills 
in your team, and the culture in your organization. Our teams consisted 
of three to five people, and they could handle between 500,000 and a 
million lines of code. However, these figures will certainly have to be 
adapted for the reengineering project you are facing. As a rule of thumb, 
assume that a single team can reengineer as much code as they can 
write from scratch. Improve your estimates during the reengineering 
project by keeping logs of how much your team actually reengineered. 
If you need to split the code up, stay as close as possible to current sys- 
tem structure and the organization of the maintenance team. Once you 
have a good understanding of the system structure, consider alterna- 
tives that are better suited for the project goal. 
9 Time is scarce. Wasting time early in a project has severe consequences 
later on. This is especially relevant during reverse engineering because 
there you feel uncertain and then it is tempting to start an activity that 
will keep you busy for a while instead of addressing the root of the prob- 
lem. Consequently, consider time as your most precious resource. There- 
fore, defer all time-consuming activities until later and use the first 
days of the project to assess the feasibility of the project's goals. All pat- 
1. During the FAMOOS project we faced systems ranging between 500,000 lines of C247 
and 2.5 million lines of Ada. 

Overview 29 
terns in this cluster are meant to quickly identify the opportunities and 
risks for your project and as such will help you set the overall direction 
of the project. 
First impressions are dangerous. Making important decisions based on 
incomplete knowledge implies that there is a chance you will make the 
wrong decision. There is no way to avoid that risk during your first con- 
tact with a system; however, you can minimize its impact if you always 
double-check your sources. 
People have different agendas. Normally, you will join a group of people 
where several members will have lots of experience with the system to 
be reengineered. Perhaps members of the original development team 
are still available or maybe the reengineering team includes people who 
have been maintaining the system for some time. At least there will be 
end users and managers who believe enough in this system to request a 
reengineering project. You are supposed to complement the team with 
your reengineering skills and expertise; hence you should know whom 
you are dealing with. 
Typically, your new colleagues will fall into three categories. The first 
category comprises the faithful, the people who believe that reengi- 
neering is necessary and who trust that you are able to (help them) do 
it. The second is the category of the skeptical, who believe this whole 
reengineering business is just a waste of time, either because they want 
to protect their jobs or because they think the whole project should 
start again from scratch. The third category is the category of the fence 
sitters, who do not have a strong opinion on whether this reengineering 
will pay off, so they just wait and see what happens. Consequently, in 
order to make the project a success, you must keep convincing the faith- 
ful, gain credit with the fence sitters, and be wary of the skeptics. 
Overview 
Wasting time is the largest risk when you have your first contact with a sys- 
tem; therefore these patterns should be applied during a short time span, 
say, one week. After this week you should grasp the main issues and based 
on that knowledge plan further activities, or~when necessary~cancel the 
project. 
The patterns Chat with the Maintainers (Pattern 3.1) and Interview dur- 
ing Demo (Pattern 3.4) will help you get acquainted with the people in- 
volved (see Figure 3.1 on page 26). As a rule of thumb, spend four days to 
gather information and use the last day of the week to compile all this 
information into a first project plan. There is no strict order in which to 
apply the patterns, although the order suggested by the sequence in this 

30 
CHAPTER 3 First Contact 
book is typical. Nevertheless, we have often found ourselves combining 
fragments of these patterns because of the necessity to double-check. For 
instance, during a second meeting with the maintainers we usually start 
with an Interview during Demo (Pattern 3.4) but ask questions about what 
we have learned from Read All the Code in One Hour (Pattern 3.2) and 
Skim the Documentation (Pattern 3.3). Also, after an interview we quickly 
check the source code and documentation to confirm what has been said. 
In certain situations we have experienced that some patterns are not 
applicable due to a lack of resources. For instance, if all the maintainers 
have left the company, you cannot Chat with the Maintainers (Pattern 3.1). 
Also, certain systems lack an external user interface, and then it is pointless 
to try an Interview during Demo (Pattern 3.4) with an end user. This isn't 
necessarily a problem because some of these patterns may be irrelevant 
for your project goal anyway. However, the absence of resources is an extra 
risk to the project, and it should be recorded as such in the first project 
plan. 
What Next 
Once you have the necessary information, it is time to compile the first 
project plan. Such a plan is very similar to the plans you normally use when 
launching a project, and the standard document templates used in your 
company should therefore be used. When necessary, bend the rules to 
include at least the following items: 
9 Project scope. Prepare a short (half a page) description of the project, 
including its context, its goals, and the criteria that will be used to verify 
whether you reached those goals. Involve the Users (Pattern 7.1) and 
Agree on Maxims (Pattern 2.1) to write this part of the plan. 
9 Opportunities. Identify those factors you expect will contribute to achieve 
the project goals. List the items that you have discovered during the 
first contact, such as the availability of skilled maintainers and power 
users, the readability of the source code, or the presence of up-to-date 
documentation. 
9 Risks. Consider elements that may cause problems during the course 
of the project. List those items that you did not find or where the quality 
was inferior, such as missing code libraries or the absence of test suites. 
If possible, include an assessment of the likelihood (unlikely, possible, 
likely) and the impact (high, moderate, low) for each risk. Special atten- 
tion must be paid to the critical risks, that is, the ones that are possible/ 
likely and have a moderate/high impact or the ones that are likely but 
have a low impact. 

P A T T E R N 3.1 Chat with the Maintainers 
31 
Go~no-go decision. At some point you will have to decide whether the 
project should be continued or canceled. Use the opportunities and 
risks you have identified to argue that decision. 
Actiuities. In the case of a "go" decision, prepare a fish-eye view of the 
upcoming period, explaining how you intend to reach the project goal. 
In a fish-eye view, the short-term activities are explained in consider- 
able detail, while for the later activities a rough outline is sufficient. 
Most likely, the short-term activities will correspond to the patterns 
described in "Initial Understanding" (Chapter 4). For the later activities 
check the Subsequent chapters. 
The list of activities should exploit the opportunities and reduce the 
(critical) risks. For instance, if you list the presence of up-to date docu- 
mentation as an opportunity and the absence of a test suite as a critical 
risk, then you should plan an activity that will build a test suite based 
on the documentation. 
PATTERN 
Chat with the Maintainers 
Problem 
Intent: Learn about the historical and political context of your project 
through discussions with the people maintaining the system. 
How do you get a good perspective on the historical and political context of 
the legacy system you are reengineering? 
This problem is difficult because 
9 Documentation, if present, typically records decisions about the solu- 
tion, not about the factors that have influenced that solution. Conse- 
quently, the important events in the history of the system (i.e., its his- 
torical context) are rarely documented. 
9 The system is valuable (otherwise they wouldn't bother to reengineer 
it), yet management has lost control (otherwise they wouldn't need to 
reengineer the system). At least some of the people-related issues con- 
cerning the software system are messed up; thus the political context of 
a legacy system is problematic by nature. 
9 People working with the system might mislead you. Sometimes people 
will deliberately deceive you, especially when they are responsible for 
the problematic parts of the system or when they want to protect their 

32 
C H A P T E R 3 First Contact 
Solution 
PATTERN 
3.1 continued 
jobs. Most of the time they will mislead you out of ignorance, especially 
when chief developers are now working on other projects and the 
junior staff are the only ones left for system maintenance. 
Yet, solving this problem is feasible because 
You are able to talk to the maintenance team. While they might not 
know everything about the original system context, they most likely 
know a great deal about how the system got to its current state. 
Discuss the problem with the system maintainers. As technical people who 
have been intimately involved with the legacy system, they are well aware 
of the system's history and the people-related issues that influenced that 
history. 
To avoid misleading information, treat the maintainers as "brothers in 
arms." Try to strike a kind of bargain where you will make their job easier 
(more rewarding, more appreciated,.., whatever is most likely to convince 
them) if they will just take some time to explain to you about what they are 
doing. This has the extra benefit that it will gain you the respect you need 
for the later phases of your reengineering project. 
Hints 
Here are some questions that may help in your discussion with the main- 
tainers. It is best to ask these questions during an informal meeting (no 
official minutes, no official agenda), although you should be prepared to 
make notes after the meeting to record your main conclusions, assump- 
tions, and concerns. 
9 What was the easiest bug you had to fix during the last month? And 
what was the most difficult one? How long did it take you to fix each of 
them? Why was it so easy or so difficult to fix that particular bug? 
These kinds of questions are good starters because they show that you 
are interested in the maintenance work. Answering the questions also 
gives the maintainers the opportunity to show what they excel at, which 
will make them less protective of their jobs. Finally, the answers will 
provide you with some concrete examples of maintenance problems 
you might use in later, more high-level discussions. 
9 How does the maintenance team collect bug reports and feature re- 
quests? Who decides which request gets handled first? Who decides to 

P A T T E R N 3.1 Chat with the Maintainers 
33 
Trade-offs 
assign a bug report or feature request to a maintainer? Are these events 
logged in some kind of database? Is there a version or configuration 
management system in place? 
These questions help to understand the organization of the mainte- 
nance process and the internal working habits of the maintenance 
team. As far as the political context concerns, it helps to assess the rela- 
tionship within the team (task assignment) and with the end users (col- 
lection of bug reports). 
Who was part of the development/maintenance team during the course 
of years? How did they join/leave the project? How did this affect the 
release history of the system? 
These are questions that directly address the history of the legacy sys- 
tem. It is a good idea to ask about personnel because people generally 
have a good recollection of former colleagues. By asking how they joined 
or left the project, you get a sense for the political context as well. 
How good is the code? How trustworthy is the documentation? 
These questions are especially relevant to see how well the mainte- 
nance team itself can assess the state of the system. Of course you will 
have to verify their claims yourself afterward (see Read All the Code in 
One Hour (Pattern 3.2) and Skim the Documentation (Pattern 3.3). 
Why was this reengineering project started? What do you expect from 
this project? What will you gain from the results? 
It is crucial to ask what the maintainers will gain from the reengineering 
project, as it is something to keep in mind during the later phases. Listen 
for differencesmsometimes subtlemin what management told you they 
expect from the project and what the maintainers expect from it. Iden- 
tifying the differences will help you get a sense of the political context. 
Pros 
Obtain information effectively. Most of the significant events in the life- 
time of a software system are passed on orally. Discussing these with 
the maintainers is the most effective way to tap into this rich informa- 
tion source. 
Get acquainted with your colleagues. By discussing the situation with 
the maintainers, you have a first chance to appraise your colleagues. As 
such, you're likely to gain the necessary credibility that will help you in 
the later phases of the reengineering project. 

34 
CHAPTER 3 First Contact 
Example 
PATTERN 3.1 continued 
Cons 
Obtain anecdotal evidence only. The information you obtain is anec- 
dotal at best. The human brain is necessarily selective regarding which 
facts it remembers; thus the recollection of the maintainers may be 
insufficient. Worse, the information may be incomplete to start with, 
since the maintainers are often not the original developers of the sys- 
tem. Consequently, you will have to complement the information you 
obtained by other means (see, for instance, Skim the Documentation, 
Pattern 3.3; Interview during Demo, Pattern 3.4; Read All the Code in 
One Hour, Pattern 3.2; and Do a Mock Installation, Pattern 3.5). 
Difficulties 
People protect their jobs. Some maintainers may not be willing to pro- 
vide you with the information you need because they are afraid of los- 
ing their jobs. It's up to you to convince them that the reengineering 
project is there to make their job easier, more rewarding, more appreci- 
ated. Consequently, you should ask the maintainers what they expect 
from the reengineering project themselves. 
Teams may be unstable. Software maintenance is generally considered 
a second-class job, often left to junior programmers and often leading 
to a maintenance team that changes frequently. In such a situation, the 
maintainers cannot tell you about the historical evolution of a software 
system, yet it tells you a great deal about its political context. Indeed, 
you must be aware of such instability in the team, as it will increase the 
risk of your project and reduce the reliability of the information you 
obtain. Consequently, you should ask who has been part of the devel- 
opment/ maintenance team over the course of the years. 
While taking over XDoctor, your company has been trying to persuade the 
original development team to stay on and merge the two software systems 
into one. Unfortunately, only one member--Dave--has agreed to stay, and 
the three others have left for another company. As it is your job to develop a 
plan for how to merge the two products, you invite Dave to lunch to have 
an informal chat about the system. 
During this chat you learn a great deal. The good news is that Dave was 
responsible for implementing the Internet communication protocols han- 
dling the transactions with the health insurance companies. As this was 
one of the key features lacking in your product, you're happy to have this 

P A T T E R hi 3.1 Chat with the Maintainers 
35 
Rationale 
experience added to your team. More good news is that Dave tells you his 
former colleagues were quite experienced in object-oriented technology, 
so you suspect a reasonable design and readable source code. Finally, you 
hear that few bug reports were submitted and that most of them have been 
handled fast. Likewise, a list of pending product enhancements exists and 
is reasonably small. So you conclude that the customers are quite happy 
with the product and that your project will be strategically important. 
The not-so-good news is that Dave is a hard-core C programmer who 
was mainly ignored by his colleagues and left out of the design activity for 
the rest of the system. When you ask about his motives to stay in the proj- 
ect, he tells you that he originally joined because he was interested in 
experimenting with Internet technology but that he is kind of bored with 
the low-level protocol stuff he has been doing and wants to do more inter- 
esting work. You ask him what he means by "more interesting," and he 
replies that he wants to program with objects. 
After the discussion, you make a mental note to check the source code 
to assess the quality of the code Dave has written. You also want to have a 
look at the list of pending bugs and requests for enhancements to compare 
the functionality of the two products you are supposed to merge. Finally, 
you consider contacting the training department to see whether they have 
courses on object-oriented programming as this may be a way to motivate 
your new team member. 
The major problems of our work are not so much technological as socio- 
logical in nature. 
[DeMa99] 
Accepting the premise that the sociological issues concerning a software 
project are far more important than the technological ones, any reengi- 
neering project must at least know the political context of the system 
under study. 
Organizations which design systems are constrained to produce designs 
which are copies of the communications structure of these organizations. 
[Conw68] 
(Conway's lawmoften paraphrased as "If you have 4 groups working on a 
compiler, you'll get a 4-pass compiler.") 
One particular reason why it is important to know about the way the 
development team was organized is because it is likely that this structure 
will somehow reflect the structure of the source code. 

36 
CHAPTER 3 First Contact 
P AT T E R N 3.1 continued 
A second reason is that before formulating a plan for a reengineering 
project, you must know the capabilities of your team members as well as 
the peculiarities of the software system to be reverse engineered. Holding 
discussions with the maintainers is one of the ways~and given the "time is 
scarce" principle, a very efficient one--to obtain that knowledge. 
Maintenance fact #1. In the late '60s and throughout the '70s, production 
system support and maintenance were clearly treated as second-class work. 
Maintenance fact #2. In 1998, support and maintenance of production sys- 
tems continues to be treated as second-class work. 
[Thom98] 
While talking with the maintainers, you should be aware that software 
maintenance is often considered second-class work. If that's the case for 
the maintenance team you are talking with, it may seriously disturb the 
discussion, either because the maintenance team has changed frequently, 
in which case the maintainers themselves are unaware of the historical 
evolution, or because the people you talk with are very protective about 
their jobs, in which case they will not tell you what you need to know. 
Known 
Uses 
During our experience with reengineering projects we made it a habit to 
kick off the project during a meeting with the maintenance team. Only in 
retrospect did we understand how crucial such a meeting is to build up the 
trust required for the rest of the project. We learned the hard way that 
maintainers are very proud of their job and very sensitive to criticism. 
Therefore, we emphasize that such a kick-off meeting must be "maintainer 
oriented," that is, aimed to let the maintainers show what they do well and 
what they want to do better. Coming in with the attitude that youmthe 
newcomer~will teach these stupid maintainers how to do a proper job 
will almost certainly lead to disaster. 
The RT-100... was developed by a third-party software vendor in the late 
1980s and acquired by Nortel in 1990. For the next three years Nortel en- 
hanced and maintained it before outsourcing it to another vendor to be 
systematically rewritten. This effort failed and the system was returned to 
Nortel in mid 1994. By this time, the original design team had been dis- 
banded and scattered, and the product's six customers' organizations were 
quite unhappy. 
RT-100 was assigned to Nortel's Atlanta Technology Park laboratory. No 
staff members there had any experience with ACD software, and, due to 
another project's cancellation, staff morale was quite low. 
[Ruga98] 

P A T T fi R N 3.1 Chat with the Maintainers 
37 
The above quote is from a paper that describes the story of a reengi- 
neering project and depicts very well the typical desperation a reengineer- 
ing project has to start with. Yet~as described in the paper itself~this 
early assessment of the historical and political context made it possible for 
the project to succeed because they knew very well which factors would 
make the stakeholders happy and consequently could motivate the new 
reengineering team. 
In one of the case studies of the DESEL (Designing for Ease of System 
Evolution) project, Stephen Cook reports that it is crucial to talk to the 
maintainers because they know best which aspects of the domain are likely 
to change and which ones are likely to remain stable [CookO 1]. As such, the 
maintainers have submerged knowledge about how the system could have 
been built--knowledge that is seldom documented. Yet, during this dis- 
cussion one must emphasize a "design for evolution" mind set, to force the 
maintainers to detach themselves from the latest problems they have been 
solving. 
Related 
Patterns 
There are several pattern languages that explicitly deal with the way a soft- 
ware development team is organized [Cop195] [Harri96] [Tayl00] [Beed00]. 
Although they were developed for forward engineering situations, it is 
good to be aware of them while talking with the maintainers because it 
may help you assess the situation more quickly. 
What Next 
During the discussion, you should avoid jumping to conclusions. There- 
fore, make sure that whatever you learn from the discussion is verified 
against other sources. Typically these sources are the people working with 
the system (Interview during Demo, Pattern 3.4), the documentation (Skim 
the Documentation, Pattern 3.3), and the system itself (i.e., Read All the 
Code in One Hour, Pattern 3.2, and Do a Mock Installation, Pattern 3.5). 
With this verification, you have a solid basis to write down an initial 
plan for tackling the legacy system, including the possibility to cancel the 
project altogether. The discussion with the maintainers will influence this 
plan in various ways. First of all, you have a sense of the willingness of the 
maintenance team to cooperate, which will affect the work plan consider- 
ably. Second, you know the history of the system, including those parts 
that make it valuable and those events that caused most of the mainte- 
nance problems. Your plan will aim to resurrect the valuable parts and 
tackle those maintenance problems. Third, you have a sense of how the 
maintenance team communicates with the other stakeholders, which is 
important to get the plan accepted. 

38 
CHAPTER 3 First Contact 
PATTERN 
Read All the Code in One Hour 
/ntent: Assess the state of a software system by means of a brief but inten- 
sive code review. 
Problem 
Solution 
How can you get a first impression of the quality of the source code? 
This problem is difficult because 
9 The quality of the source code will vary quite a lot, depending on the 
people that have been involved in the development and maintenance 
of the system. 
9 The system is large, so there is too much data to inspect for an accurate 
assessment. 
9 You're unfamiliar with the software system, so you do not know how to 
filter out what's relevant. 
Yet, solving this problem is feasible because 
9 You have reasonable expertise with the implementation language being 
used; thus you can recognize programming idioms and code smells. 
9 Your reengineering project has a clear goal, so you can assess the kind 
of code quality required to obtain that goal. 
Grant yourself a reasonably short amount of study time (e.g., approxi- 
mately one hour) to read the source code. Make sure that you will not be 
disturbed (unplug the telephone and disconnect your email) and take 
notes sparingly to maximize the contact with the code. 
After this reading session, produce a short report about your findings, 
including 
9 a general assessment of whether reengineering seems feasible and why 
(not) 
9 entities that seem important (e.g., classes, packages, and so on) 
9 suspicious coding styles discovered (i.e., "code smells" [Fowl99]) 
9 parts that must be investigated further (e.g., tests) 
Keep this report short, and name the entities as they are mentioned in 
the source code. 

P A T T E R N 3.2 ReadAll the Code in One Hour 
39 
Tradeoffs 
Hints 
The "time is scarce" principle demands some preparation. A checklist 
might help you focus your effort during the reading session. Such a check- 
list may be compiled from various sources: 
9 The development team may have employed code reuiews as part of their 
quality assurance. If they did, make sure you incorporate the checklists 
used during the reviews. If they didn't, try some generic checklists used 
to review the kind of code you are dealing with. 
9 Some development teams may have applied coding styles, and if they 
did, it is good to be aware of them. Naming conventions are especially 
crucial to scan code quickly. 
9 The programmers might have used coding idioms (e.g., C++ [Cop192] 
[Meye98] [Meye96]; Smalltalk [Beck97]) that help you recognize typical 
language constructs. 
9 You probably have some questions that you would like answers to. 
Here are some other items you might add to your checklist because 
they provide good entry points for further examination: 
9 Functional tests and unit tests convey important information about the 
functionality of a software system. They can help to verify whether the 
system is functioning as expected, which is very important during 
reengineering (see "Tests: Your Life Insurance," Chapter 6). 
9 Abstract classes and methods reveal design intentions. 
9 Classes high in the hierarchy often define domain abstractions; their 
subclasses introduce variations on a theme. 
9 Occurrences of the Singleton pattern (Pattern A.17) may represent 
information that is constant for the entire execution of a system. 
9 Surprisingly large structures often specify important chunks of func- 
tionality. 
9 Comments reveal a lot about the design intentions behind a particular 
piece of code, yet may often be misleading. 
Pros 
Start efficiently. Reading the code in a short amount of time is very effi- 
cient as a starter. Indeed, by limiting the time and yet forcing yourself to 
look at all the code, you mainly use your brain and coding expertise to 
ferret out what seems important. 

40 
CHAPTER 3 First Contact 
PATTERN 3.2 continued 
9 Judge sincerely. By reading the code directly, you get an unbiased view 
of the software system, including a sense of the details and a glimpse of 
the kind of problems you are facing. Because the source code describes 
the functionality of the system~no more, no less~it is the only accu- 
rate source of information. 
Learn the developers' vocabulary. Acquiring the vocabulary used inside 
the software system is essential to understanding it and communicat- 
ing about it with other developers. This pattern helps to acquire such a 
vocabulary. 
Cons 
Obtain low abstraction. Via this pattern, you will get some insight into 
the solution domain, but only very little about how these map onto 
problem domain concepts. Consequently, you will have to complement 
the information you obtained with other, more abstract representa- 
tions (for instance, Skim the Documentation, Pattern 3.3, and Interview 
during Demo, Pattern 3.4). 
Difficulties 
9 Does not scale. Reading all the code does not scale very well; from our 
experience a rate of 10,000 lines of code per hour is reasonable. When 
facing large or complex code, don't try to spend more time to read more 
code because intensive reading is most effective when done in short 
bursts of time (no more than two hours). Instead, ifyou have a clear cri- 
terion to split the source code, try to pass a series of sessions. Other- 
wise, just go through all of the code and mark those parts that seem 
more important than others (based on Chat with the Maintainers, Pat- 
tern 3.1) and then read in different sessions. 
However, given the "time is scarce" principle, you should force yourself 
to be brief. Consequently, when dealing with large or complex code, 
don't bother too much with the details, but remind yourself of the goal 
of reading the code, which is an initial assessment of the suitability for 
reengineering. 
9 Comments may mislead you. Be careful with comments in the code. 
Comments can help you in understanding what a piece of software is 
supposed to do. However, just like other kinds of documentation, com- 
ments can be outdated, obsolete, or simply wrong. Consequently, when 
you find a comment, mark on your checklist whether it seems helpful 
or whether it seems outdated. 

P A T T E R N 3.2 Read All the Code in One Hour 
41 
Example 
From the discussion with Dave (the sole person left from the original de- 
velopment team and the one responsible for the low-level C code), you re- 
call that their system was mainly written in Java, with some low-level parts 
written in C and the database queries in SQL. You have experience with all 
these languages, so you are able to read the code. 
You start by preparing a checklist, and besides the normal items (coding 
styles, tests, abstract classes and methods, classes high in the hierarchy), 
you add a few items concerning some questions you want resolved. One of 
them is "readability of the C code" because you want to verify the coding 
style of Dave, your new team member. A second is the "quality of the data- 
base schema" because you know that the data of the two systems sooner or 
later will have to be integrated. A third is the "handling of currencies" be- 
cause Switzerland will join the Euro region and within six months all finan- 
cial data must be converted to this new currency. 
From reading the C code, you learn that this part is quite cryptic (short 
identifiers with mysterious abbreviations, long multiexit loops). Neverthe- 
less, the modules handling the Internet protocols have unit tests, which 
makes you feel more confident about the possibility of incorporating them 
into your system. 
The Java code presents a problem of scale: you can't read 50,000 lines of 
code in a single hour. Therefore, you pick some files at random and you im- 
mediately discover that most class names have a two-character prefix, 
which is either U I or DB. You suspect a naming convention marking a two- 
tiered architecture (database layer and user interface layer), and you make 
a note to investigate this further. Also, you recognize various class and at- 
tribute names as being meaningful for the health care domain (such as 
class DBPati ent with attributes name, address, health insurance,...). You 
even perceive a class DBCurrency, so you suppose that switching to the Euro 
won't cause a lot of problems, since the developers took the necessary pre- 
cautions. Most of the classes and methods have comments following the 
javadoc conventions, so you suspect that at least some of the documenta- 
tion will be up to date. Finally, you identified a large singleton object that 
contains various strings that are displayed on the screen, which leads you 
to conclude that it will even be possible to localize the system. 
All this looks rather promising; however, there are also a number of dis- 
couraging observations. What makes you most pessimistic is the presence 
of numerous long methods with large parameter lists and complex condi- 
tionals. Many of them seem to mix UI logic (enabling/disabling of buttons 
and menu items) with business logic (updating database records). One 
thing (the calculation of prices) seems especially complicated, and you 
make a note to investigate this further. 
Concerning the database, you again recognize various table names and 
column names that are meaningful in the context of the health care domain. 
At first glance, the schema looks normalized, which for reverse engineering 

42 
C H A P T E R 3 First Contact 
Rationale 
PATTERN 3.2 continued 
seems promising. The database also employs some stored procedures, 
which warrants further investigation. 
After the reading session, you summarize your conclusions in the fol- 
lowing notes: 
9 Incorporating the Internet protocols is feasible: unit tests and responsi- 
ble programmer available. 
9 Suspect a two-tiered architecture based on naming convention. What 
about the business logic~mixed in with UI? (Further verification!) 
9 Readable code with meaningful identifiers; reverse engineering looks 
promising. 
9 Currency object is present; Euro conversion looks feasible. (Further 
investigationI) 
9 javadoc conventions used; verify documentation. 
9 Calculation of prices seems complicated. Why? 
9 Database schema looks promising. Stored procedures require further 
investigation. 
Code reviews are widely acknowledged as being a very effective means to 
find problems in programs written by peers [Gilb93] [Glass97]. Two im- 
portant prerequisites have to be met in order to make such reviews cost- 
effective: (1) a checklist must be prepared to help the reviewer focus on the 
relevant questions, and (2) a review session must be kept short because re- 
viewers cannot concentrate for a very long time (two hours at maximum). 
I took a course in speed reading and read "War and Peace" in twenty min- 
utes. It's about Russia. 
~Woody Allen 
There is an important difference between traditional code reviews and 
the ones you perform during your first contact with a software system. The 
former is typically meant to detect errors, while the latter is meant to get a 
first impression. This difference implies that you need to care less about 
details so that you can read more code. Typical guidelines for code reviews 
state that about 150 statements per hour can be reviewed [Barn94]. How- 
ever, during your first contact you don't need such a detailed analysis and 
thus can increase the volume of code to be reviewed. We didn't perform 
any serious empirical investigation, but from our experience 10,000 lines 
of code per hour seems reasonable. 

P A T T E R N 3.2 ReadAll the Code in One Hour 
43 
Known 
Uses 
The original pattern was suggested by Kent Beck, who stated that it is one 
of the techniques he always applies when starting a consulting job on an 
existing system. Robson [Robs91] reports code reading as "the crudest 
method of gaining knowledge about a system" and acknowledges that it is 
the method most commonly used to understand an existing program. 
Some case study reports also mention that reading the source code is one 
of the ways to start a reengineering project [Bray95] [Jack00]. 
While writing this pattern, one of our team members applied it to re- 
verse engineer the Refactoring Browser [Robe97]. The person was not 
familiar with Smalltalk, yet was able to get a feel for the system structure by 
a mere inspection of class interfaces. Also, a special hierarchy browser did 
help to identify some of the main classes, and the comments provided 
some useful hints about what parts of the code were supposed to do. 
Applying the pattern took a bit more than an hour, which seemed enough 
for a relatively small system; the slow progress was due to the unfamiliarity 
with Smalltalk. 
One particularly interesting occurrence of this pattern took place 
toward the end of the FAMOOS project. During the course of one week, a 
heterogeneous team of reverse engineers went for an on-site visit to partic- 
ipate in a kind of reverse engineering contest. The assignment was to 
invest four days and use the available reverse engineering tools to learn as 
much as possible about a particular C++ system. The fifth day was then 
used to report the findings to the original developers for verification. One 
of the team members finished his assignment too early and took the 
opportunity to Read All the Code in One Hour. It turned out that this one 
person had a much better overview of the system: he could participate 
in all discussions and could even explain some of the comments of the 
developers. 
What Next 
After you Read All the Code in One Hour you should Do a Mock Installation 
(Pattern 3.5) to evaluate the suitability for reengineering. You may comple- 
ment your findings if you Skim the Documentation (Pattern 3.3) and carry 
out an Interview during Demo (Pattern 3.4) to maximize your chances of 
getting a coherent view of the system. Before actually making a decision on 
how to proceed with the reengineering project, it is probably worthwhile to 
Chat with the Maintainers (Pattern 3.1) once more. 
At the end of your first contact with the system, you should decide on 
how to proceed with (or cancel) the project. Reading the code will influ- 
ence this decision in various ways. First of all, you have assessed the qual- 
ity of the code (i.e., the presence of coding idioms and suspicious coding 
styles) and thus of the feasibility of the reengineering project. Second, you 
have identified some important entities, which are good starting points for 
further exploration. 

44 
CHAPTER 3 First Contact 
PATTERN 3.2 continued 
The list of the important entities (e.g., classes, packages, and so on) 
resulting from Read All the Code in One Hour can be used to start to Ana- 
lyze the Persistent Data (Pattern 4.1) and Study the Exceptional Entities 
(Pattern 4.3). This way you can refine your understanding of the source 
code, especially the way it represents the problem domain. 
PATTERN 
Skim the Documentation 
Intent: Assess the relevance of the documentation by reading it in a limited 
amount of time. 
Problem 
How do you identify those parts of the documentation that might be of help? 
This problem is difficult because 
9 Documentation, if present, is usually intended for the development 
team or the end users and as such is not immediately relevant for re- 
engineering purposes. Worse, it is typically out of date with respect to 
the current state of affairs; thus it may contain misleading information. 
9 You do not yet know how the reengineering project will proceed; hence 
you cannot know which parts of the documentation will be relevant. 
Yet, solving this problem is feasible because 
9 Some form of documentation is available, so at least there is a descrip- 
tion that was intended to help the humans concerned with the system. 
9 Your reengineering project has a clear goal, so you can select those 
parts of the documentation that may be valuable and those parts that 
will be useless. 
Solution 
Prepare a list summarizing those aspects of the system that seem interest- 
ing for your reengineering project. Then, match this list against the docu- 
mentation, and meanwhile make a crude assessment of how up to date the 
documentation seems. Finally, summarize your findings in a short report, 
including 

P A T T E R N 3.3 Skim the Documentation 
45 
9 a general assessment of whether the system documentation will be 
useful and why (not) 
9 a list of those parts of the documentation that seem useful and why 
(e.g., requirement specifications, desired features, important constraints, 
design diagrams, user and operator manuals) 
9 for each part, an impression of how up to date the description is 
Hints 
Depending on the goal of the reengineering project and the kind of docu- 
mentation you have at your disposal, you may steer the reading process to 
match your main interest. For instance, ifyou want insight into the original 
system requirements, then you should look inside the system specifica- 
tion, while knowledge about which features are actually implemented 
should be collected from the end user manual or tutorial notes. If you have 
the luxury of choice, avoid spending too much time trying to understand 
the design documentation (e.g., class diagrams, database schemas); rather, 
record the presence and reliability of such documents since this will be of 
great help in the later stages of reengineering. 
Check whether the documentation is outdated with respect to the ac- 
tual system. Always compare version dates with the date of delivery of the 
system, and make note of those parts that you suspect are unreliable. 
The fact that you are limited in time should force you to think how you 
can extract the most useful information. Here are some hints about things 
to look out for: 
9 A table of contents gives you a quick overview of the structure and the 
information presented. 
9 Version numbers and dates tell you how up to date that part of the docu- 
mentation is. 
Figures are a good means to communicate information. A list of figures, 
if present, may provide a quick access path to certain parts of the docu- 
mentation. 
9 Screen dumps, sample printouts, sample reports, and command de- 
scriptions reveal a lot about the functionality provided by the system. 
9 Formal specifications (e.g., state charts), if present, usually correspond 
with crucial functionality. 
9 An index, if present, contains the terms the author considers significant. 

46 
C H A P T E R 3 First Contact 
P AT T E R N 3.3 continued 
Trade-offs 
Pros 
9 Provides a high abstraction level. Documentation is supposed to be 
read by humans, thus at a certain level of abstraction. It may be that this 
abstraction level is not high enough for your reengineering project, but 
at least you can skip a few decoding steps. 
9 Allows you to focus on relevant parts. By preparing yourself with a list of 
what seems interesting, the reading session becomes goal oriented, as 
such increasing your chances of finding something worthwhile. More- 
over, by making a quick assessment ofhow up to date the description is, 
you avoid wasting time on irrelevant parts. 
Cons 
You may miss crucial facts. A quick read in overview mode is likely to 
miss crucial facts recorded in the documentation. However, you can 
counter this effect to some degree by preparing a list of what you would 
like to find. 
You mayfind irrelevant information only. There is a small chance that 
not a single part of the documentation will seem relevant for your re- 
engineering project. Even in such a situation, the time spent on reading 
is worthwhile because now you can justify not worrying about the doc- 
umentation. 
Difficulties 
9 Targets a different audience. Documentation is costly to produce and 
hence is written for the end users (e.g., user manuals) or the develop- 
ment team (e.g., design). Documentation is also costly to maintain; 
hence only the stable parts of the system are documented. Conse- 
quently, the information you find may not be directly relevant and will 
require careful interpretation. 
9 Documentation contains inconsistencies. Documentation is almost 
always out of date with respect to the actual situation. This is quite dan- 
gerous during the early phases of a reengineering project because you 
lack the knowledge to recognize such inconsistencies. Consequently, 
avoid making important decisions based on documentation only~first 
verify your findings by other means (in particular, Read All the Code in 
One Hour, Pattern 3.2, and Interview during Demo, Pattern 3.4). 

P AT T E R N 3.3 Skim the Documentation 
47 
Example After your informal chat with Dave and your code-reading sessions, you 
have some general idea of what the interesting aspects of the system are. 
You decide to skim through the documentation to see whether it contains 
relevant information. 
You prepare yourself by compiling a list of aspects you would like to 
read about. Besides obvious items like design diagrams, class interface de- 
scriptions (javadoc?), and database schemas, the list includes the Euro 
(does the user manual say something about Euro conversions?) and the 
specification of Internet protocol. 
Next, you go to Dave and ask him for all of the documentation concern- 
ing the software system. Dave looks at you with a small grin on his face: 
"You're not really gonna read all of that, are you?" "Not exactly," you say 
to him, "but at least I want to know whether we can do something with 
it." Dave looks in the box he has given you earlier and hands you three fold- 
ers full of paper~the design documentation~and one booklet~the user 
manual. 
You start with the user manual and.., bingo! In the index you discover 
an entry for Euro. Turning to the corresponding pages, you see that the 
Euro is actually a chapter on its own consisting of about five pages, so you 
mark those page numbers for further study. Next you skim through the 
table of contents, and there you notice a title "Switching to French/German." 
Reading these pages you see that localizing the software is a documented 
feature. Localizing wasn't in your checklist, but it is still important, so you 
gladly add a note about it. All of this looks rather promising, so you verify 
the release date of the user manual and you see that it is quite recent. A 
good start indeed! 
Opening the first folder (entitled "Classes") of the design documenta- 
tion, you find more or less what you were expecting: a printout of the class 
interface as generated by javadoc. Not that interesting to read on paper, 
but you continue to leaf through the pages anyway. Your first impression is 
that the actual descriptions coming with each of the classes and methods 
are quite shallow~an impression that gets confirmed when you examine 
three random pages in more detail. Next, you look for descriptions for 
those classes interfacing with the C code implementing the Internet proto- 
col, and there you even find empty descriptions. The litmus test with the 
release date of the documentation reveals that this documentation is quite 
old, so you make a note to check the online documentation. 
The second folder contains a nice surprise: it is a generated description 
of the database schema, describing for each table what the purpose of each 
column is. Just as with the javadoc class interface descriptions, the docu- 
mentation itself is quite shallow, but at least you have a way of finding what 
each record in the database is supposed to represent. Here as well, the lit- 
mus test with the document release date tells you to verify the online ver- 
sion of the same documentation. 

48 
C H A P T E R 3 First Contact 
Rationale 
p AT T E R N 3.3 continued 
At first glance, the third folder seems to contain rubbish: various copies 
of miscellaneous documents that seem only vaguely related with your proj- 
ect. The first document is a price list for medicines; the next ten are extracts 
from the health care legislation. Still you continue to leaf through the pages, 
and you stumble upon some finite state diagrams that appear to describe 
the Internet protocol used to communicate with the health insurance 
companies. Apparently, the document is a copy from some pages out of a 
technical specification, but unfortunately no references to the original are 
included. Even the release date for this document is missing, so you don't 
have the means to verify whether this specification is outdated. 
You conclude the reading session with the following report: 
9 User manual is clear and up to date: good source for black-box de- 
scription of functionality. 
9 Euro is provided for (pp. 513-518); localization as well (pp. 723-725). 
9 Class interface descriptions are generated; shallow but verify on line. 
9 Documentation for database schema is generated; shallow, but verify 
on line. 
9 Finite state machines for the Internet protocol? Status questionable; 
verify with Dave. 
9 One folder containing miscellaneous documents (price lists, instruc- 
tion leaflets, and so on). 
It is not unusual for a software development organization to spend as much 
as 20 or 30 percent of all software development effort on documentation. 
[Pres94] 
Documentation, as opposed to source code, is intended to explain the soft- 
ware system at an abstraction level well suited for humans. Therefore, the 
documentation will certainly contain information "nuggets"; the only 
problem is how to find the relevant ones. Finding relevant information is 
made difficult because of two typical circumstances present in almost all 
reengineering projects. 
All of the case-studies face the problem of non-existent, unsatisfactory or 
inconsistent documentation. 
[Deme97] 
First of all, the documentation is likely to be out of sync with respect to 
the actual situation. For the five case studies we investigated during the 

P AT T E R N 3.3 Skim the Documentation 
49 
Known 
Uses 
FAMOOS project, "insufficient documentation" was the only problem all 
maintainers complained about. Nevertheless, even outdated information 
may be useful because at least it tells you how the system was supposed to 
behave in the past. This is a good starting point to infer how it is used 
today. 
The documentation that exists for these systems usually describes isolated 
parts but not the overall architecture. Moreover, the documentation is 
often scattered throughout the system and on different media. 
[Wong95] 
Second, documentation is normally produced in a forward engineering 
context and hence is not intended for reengineering purposes. Generated 
design documentation (e.g., database schemas, javadoc), for instance, is 
typically quite up to date, yet too fine-grained to be useful during the initial 
phases of a reengineering project. User manuals are black-box descrip- 
tions of the software system, and thus cannot serve as blueprints of what's 
inside the boxes. Here as well you should see the documentation as a good 
starting point to infer what you're really interested in. 
A study by Fjeldstadt and Hamlen reported that "in making an enhance- 
ment, maintenance programmers studied the original program about 
three-and-a-half times as long as they studied the documentation, but just 
as long as they spent implementing the enhancement" ([Corb89] quoting 
[Fje179]). This equation gives a good impression of the relative importance 
that studying the documentation should have. 
The case-study began with an effort to understand the existing design of 
CTAS in general and the CM in particular .... The documentation for CTAS 
includes motivation and architecture overview, software structures, user 
manuals and research papers on the underlying algorithms. However, there 
appears to be no document that explains in high-level terms what the sys- 
tem computes or what assumptions it makes about its environment. Nor is 
there a design document that explains the relationship between the CTAS 
components: how they communicate, what services they offer, and so 
forth. We were forced to infer this information from the code, a challenge 
common to many commercial development efforts. 
[Jack00] 
The above quotation summarizes quite well that you need to study the 
documentation yet it will not tell you all you need to know. The case study 
they are referring to concerns an air-traffic control system (CTAS) where 
they reverse- and reengineered a key component, CommunicationsManager 
(CM), of about 80 kilo lines of code (KLOC) C++ code. 

50 
CHAPTER 3 First Contact 
What Next 
PATTERN 
3.3 continued 
The following anecdote reveals how documentation might mislead 
you. In one of the FAMOOS case studies we were asked to evaluate whether 
a distributed system connecting about a dozen subsystems could be scaled 
up to connect approximately a hundred subsystems. During this evalua- 
tion, we studied the class responsible for maintaining all of the TCP/IP 
connections where the comments described how all of the open connec- 
tions were maintained in a kind of lookup table. We did find a lookup table 
in the code, but we were unable to map the description of how it worked 
back to operations manipulating the table. After half a day of puzzling, we 
gave up and decided to ask the maintainer. His matter-of-fact response 
was, '~J3, but this class comment is obsolete. Now that you mention it, I 
should have deleted it when I redesigned that class." 
You may want to Read All the Code in One Hour (Pattern 3.2) immediately 
after you Skim the Documentation to verify certain findings. It may also be 
worthwhile to Chat with the Maintainers (Pattern 3.1) and Interview dur- 
ing Demo (Pattern 3.4) to confirm certain suspicions. 
At the end of your first contact with the system, you should decide on 
how to proceed with (or cancel) the project. Once you have discovered rel- 
evant documentation, you know that at least you do not have to reproduce 
this information. Even better, for those parts of the documentation that are 
relevant but seem inaccurate, you have some good starting points for fur- 
ther exploration (for instance, Analyze the Persistent Data, Pattern 4.1, and 
Speculate about Design, Pattern 4.2). 
PATTERN 
Interview during Demo 
Intent: Obtain an initial feeling for the appreciated functionality of a soft- 
ware system by seeing a demo and interviewing the person giving the 
demo. 
Problem 
How can you get an idea of the typical usage scenarios and the main fea- 
tures of a software system? 
This problem is difficult because 
9 Typical usage scenarios vary quite a lot depending on the type of user. 

P A T T E R N 3.4 Interview duringDemo 
$1 
Solution 
9 If you ask the users, they have a tendency to complain about what's 
wrong, while for reverse engineering purposes you're mainly interested 
in what's valuable. 
9 The system is large, so there is too much data to inspect for an accurate 
assessment. 
9 You're unfamiliar with the software system, so you do not know how to 
filter out what's relevant. 
Yet, solving this problem is feasible because 
You can exploit the presence of a working system and a few users who 
can demonstrate how they use the software system. 
Observe the system in operation by seeing a demo and interviewing the 
person who is demonstrating. Note that the interviewing part is at least as 
enlightening as the demo. 
After this demo, take about the same amount of time to produce a re- 
port about your findings, including 
9 some typical usage scenarios 
9 the main features offered by the system and whether they are appreci- 
ated or not 
9 the system components and their responsibilities 
9 bizarre anecdotes that reveal the folklore about using the system 
Hints 
The user who is giving the demo is crucial to the outcome of this pattern, 
so take care when selecting the person. In fact, you may want to do the 
demonstration several times with different people giving the demo. This 
way you will see variations in what people find important, and you will 
hear different opinions about the value of the software system. Always be 
wary of enthusiastic supporters or fervent opponents: although they will 
certainly provide relevant information, you must spend extra time to look 
for complementary opinions in order to avoid prejudices. 
Here are some hints concerning people you should be looking for, what 
kind of information you may expect from them, and what kind of ques- 
tions you should ask. Which people you should talk to depends very much 
on the goal of your reengineering project and the kind of organization sur- 
rounding it; hence this list is provided as a starting point only. 
An end user should tell you what the system looks like from the outside 
and explain some detailed usage scenarios based on the daily working 

52 
CHAPTER 3 First Contact 
PATTERN 3.4 continued 
practices. Ask about the working habits before the software system was 
introduced to assess the scope of the software system within the busi- 
ness processes. 
A manager should inform you how the system fits within the rest of the 
business domain. Ask about the business processes around the system 
to check for unspoken motives concerning your reengineering project. 
This is important, as reengineering is rarely a goal in itself; it is just a 
means to achieve another goal. 
A person from the sales department ought to compare your software 
system with competing systems. Ask for a demo of the functionality 
most requested by the users (this is not necessarily the same as most 
appreciated!) and ask how this has evolved in the past and how it might 
evolve in the future. Use the opportunity to get insight into the various 
types of end users that exist and the way the software system is likely to 
evolve. 
9 A person from the help desk should demonstrate to you which features 
cause most of the problems. During this part of the demo, ask how they 
explain it to their users because this may reveal mismatches between 
the actual business practices and the way it is modeled by the software 
system. Try to get them to divulge bizarre anecdotes to get a feeling for 
the folklore around the software system. 
9 A system administrator should show you all that is happening behind 
the scenes of the software system (e.g., start-up and shutdown, back-up 
procedures, data archiving, etc.). Ask for past horror stories to assess 
the reliability of the system. 
9 A maintainer~developer may demonstrate to you some of the subsys- 
tems. Ask how this subsystem communicates with the other subsystems 
and why (and by whom!) it was designed that way. Use the opportunity 
to get insight into the architecture of the system and the trade-offs that 
influenced the design. 
Variant 
Demonstrate to Yourself A scaled-down variant of Interview during Demo 
entails the reverse engineer demonstrating the system to him- or herself via 
a trial-and-error process. Such a demonstration obviously lacks the group 
dynamics that boosts the demonstration, but on the other hand may serve 
as a preparation technique for a discussion with the designers/maintainers. 

P A T T E R N 3.4 Interview duringDemo 
53 
Trade-offs 
Pros 
9 Focuses on valued features. The fact of giving a demo will gently coerce 
the interviewee to demonstrate those features that are appreciated. As 
a reverse engineer, that's your main interest. 
9 Provides lots of qualitative data. Conducting an interview typically re- 
sults in a wealth of relevant information, which is very hard to extract 
by other means. 
9 Increases your credibility. Performing an interview shows to the inter- 
viewee that there is a genuine interest in his or her opinions about that 
system. The interview thus provides a unique opportunity to enlarge 
the end users' confidence in the result of your reengineering project. 
Cons 
Provides anecdotal evidence only. The information you obtain is anec- 
dotal at best, just as it is when you Chat with the Maintainers (Pattern 
3.1). Interviewees will almost certainly omit important facts, either be- 
cause they forgot or because they deemed them uninteresting. This ef- 
fect will be countered to some degree by demonstration, yet prepare to 
complement the information you obtained by other means (see, for 
instance, Skim the Documentation, Pattern 3.3; Read All the Code in 
One Hour, Pattern 3.2; and Do a Mock Installation, Pattern 3.5). 
Time may be lacking. At least one person should be able to do the dem- 
onstration. This seems a simple requirement but may be hard to achieve 
in practice. Some systems (embedded systems, for example) just don't 
have human users and~given the "time is scarce" principle--sometimes 
it will take too long to make an appointment with someone who is will- 
ing to demonstrate the system. 
Difficulties 
9 Requires interviewing experience. The way the questions are phrased 
has considerable impact on the outcome of the interview. Unfortunately, 
not all reverse engineers have the necessary skills to conduct good inter- 
views. When you're inexperienced, rely on the flow of the demonstra- 
tion to trigger the right kind of questions. 
9 Selecting interviewees may be difficult. You should avoid interviewing 
enthusiastic supporters or fervent opponents. Unfortunately, in the be- 
ginning of a reengineering project you lack the knowledge to make a 
good selection. Consequently, rely on other people's opinions to make 
the selection, but prepare to adjust the results based on the enthusiasm 
(or lack of it) of the interviewees. 

54 
C H A P T E R 3 First Contact 
PATTERN 3.4 continued 
Handling real-time software can be difficult. For certain kinds of sys- 
tems (especially real-time systems), it is impossible to answer ques- 
tions while operating the software system. In such a situation, jot down 
your questions while seeing the demo, and do the actual interview 
afterward. 
Example Now that you checked the source code and the documentation, you're 
almost convinced that reengineering the XDoctor system will be feasible. 
However, you still have some doubts about precisely what should be re- 
verse engineered because you don't really know what the users appreciate 
in the system. Via the sales department, you get in touch with one of the 
current users, and you make an appointment for the next day. You're also 
worried about the state of the Internet protocol (including the state chart 
specification you discovered in the documentation) and the way it fits in 
with the rest of the system, so you go to Dave and ask him whether he can 
give you a demo of the Internet protocols. 
Dave is quite pleased to show you his work and immediately starts to 
type on his keyboard. "See, now I launched the server," he says, pointing at 
a little console window that appeared on the screen. "Wait a second," you 
reply, "what command did you type there?" "LSRV. You know, for Launch 
Server." A bit surprised, you ask Dave if there is some kind of manual ex- 
plaining how to start up and shut down this server. Dave explains that 
there isn't, but that it is quite easy to infer from the batch file starting the 
whole system. He even tells you that there are some command-line op- 
tions associated with LSVR and that they are all documented in a READ.ME 
file and via the -h(elp) option. Next, Dave starts a test program (yes, it is 
invoked via LSVRTST), and in the console window you see that the server is 
actually receiving traffic, while the test program is spitting out a long log of 
all the messages sent and received. Of course, you ask him how he knows 
that the test succeeded, and to your dismay he states that this is done by 
manually inspecting the log. You decide to switch topics and ask him why 
this subsystem is called a server because you would guess that it is actually 
running on the client machine. This question triggers a heated discussion 
that eventually leads to an architecture diagram like the one depicted in 
Figure 3.2, showing a remote server (managed by the health insurance 
companies and accepting requests), a local server (the L in LSVR probably 
stands for "local" and not "launch"), and some local clients. From this dis- 
cussion you kind of understand how the complete system is working. The 
basic idea is that there are several client computers on various desks con- 
nected to a local server via a LAN network. The local server maintains the 
database and the Internet connections to the health insurance companies. 

P A T T E R N 3.4 Interview duringDemo 
55 
FIGURE 
The architecture diagram as you inferred it from the discussion with the maintainer. 
With the diagram on a little sheet of paper, you ask Dave where this Inter- 
net protocol originated. This question again triggers a long story that re- 
minds you that the protocol is designed in Germany (hence the reason why 
it's documented with state charts) and now adopted by the national health 
insurance companies. 
The next day, you put on your suit and drive off to have a meeting with 
Dr. Mary Johanssen. While introducing yourself, you get the impression 
that she is not so pleased. You explain the reason for your visit, and during 
the conversation you understand that the doctor is quite worried about 
your company taking over the XDoctor software. You do your very best to 
assure her that the main purpose of the demonstration and interview is 
precisely to learn how your company may best serve the current users and 
that they do not intend to stop supporting it. Reassured, she starts the 
actual demonstration. Not surprisingly, the most appreciated feature is the 
automatic transaction processing with the health insurance companies 
because "it means that I can save on a secretary to do the paperwork." How- 
ever, Dr. Johanssen also shows you some other features you were not aware 
of: built-in email, export to spreadsheet ("I just email this file to my book- 
keeper"), and payments in multiple currencies ("Real good to deal with 
Euros"). During the course of the demo she tells you that in the beginning 
the system was a bit unstable (apparently she served as a beta tester) and 
that there are some weird mistakes (the list of patients is sorted by first 

56 
C H A P T E R 3 First Contact 
PATTERN 
3.4 continued 
name instead of family name), but all in all she is very pleased with the sys- 
tem. 
Once you are back in your office you write a small report that includes 
the sequence of commands for testing the local server, plus the usage sce- 
narios for the automatic transaction processing and the payment with 
multiple currencies. Your report also includes the architecture diagram 
(Figure 3.2) and the following observations: 
9 Testing of Internet protocols is manual; investigate regression tests. 
9 Internet protocol spec comes from a consortium of German health in- 
surance companies. 
9 Sorting of patient list: by first name instead of last name. 
Rationale 
The ability to respond flexibly to the interviewee's responses is one of the 
reasons why interviews are so widely used. 
[Benn99] 
Interviews are well suited to exploratory studies where one does not know 
yet what one is looking for, since the interviewer can adjust the interview to 
the situation. 
[Nie193] 
Interviewing people working with a software system is essential to getting 
a handle on the important functionality and the typical usage scenarios. 
However, asking predefined questions does not work because in the initial 
phases of reengineering you do not know what to ask. Merely asking what 
people like about a system will result in vague or meaningless answers. On 
top of that, you risk getting a very negative picture because users have a 
tendency to complain about a legacy system. 
The real challenge of analysis begins when the expert must communicate 
the concept to someone elsemto an analyst... Since the concept is often 
very rich and expansive, it is generally not possible for experts adequately 
to communicate their entire understanding in a single, holistic expression. 
[Gold95] 
Compared with a forward engineering situation, a reverse engineer has 
one major advantage: there is a working software system available and you 
can exploit its presence. In such a situation it is safe to hand over the initia- 
tive to the user by requesting a demo. First of all, a demo allows users to tell 
the story in their own words, yet it is comprehensible because the demo 
imposes some kind of tangible structure. Second, because users must start 

P A T T E R N 3.4 Interview duringDemo 
57 
from a working system, they will adopt a more positive attitude explaining 
what works. Finally, during the course of the demo, the interviewer can ask 
lots of precise questions and get lots of precise answers, and in this way dig 
out the expert knowledge about the system's usage. 
Known 
Uses 
The main idea of this pattern~let the user explain the system while using 
it~is commonly used for evaluating user interfaces: "Thinking aloud may 
be the single most valuable usability engineering method. Basically, a 
thinking-aloud test involves having a test subject use the system while 
continuously thinking out loud" [Nie193]. The same idea is also often ap- 
plied during rapid prototyping for requirements elicitation [Somm96]. 
One anecdote from the very beginning of the FAMOOS project~an 
application of the Demonstrate to Yourself variant of this pattern~shows 
how ignorant questions arising from seeing a software system in action 
may trigger dormant expertise within the maintenance team. For one of 
the case studies~a typical example ofa three-tiered system with a data- 
base layer, domain objects layer, and User .interface layer~we were asked 
"to get the business objects out." Two separate individuals were set to that 
task: One took a source code browser and a CASE tool and extracted some 
class diagrams that represented those business objects. The other installed 
the system on his local PC and spent about an hour playing around with 
the user interface (that is, he demonstrated the system to himself) to come 
up with a list of 10 questions about some strange observations he made. 
Afterward, a meeting was organized with the chief analyst/designer of the 
system and the two individuals who tried to reverse engineer the system. 
When the analyst/designer was confronted with the class diagrams, he 
confirmed that these were indeed the business objects, but he couldn't tell 
us whether there was something missing, nor did he tell us anything about 
the rationale behind his design. It was only when we asked him the 10 
questions that he launched off into a very enthusiastic and very detailed 
explanation of the problems he was facing during the design~he even 
pointed to our class diagrams during his story! After having listened to the 
analyst/designer, the first reaction of the person that extracted the class 
diagrams from the source code was "Gee, I never read that in the source 
code." 
Related 
Patterns 
A lot of good advice concerning how to interact with end users is embodied 
in the "Customer Interaction Patterns" [Risi00]. The main message of these 
patterns is that "it's a relationship, not a sale," emphasizing that your con- 
tacts with the end users should aim to develop a relationship of trust. 
What Next 
For optimum results, you should carry out several attempts of Interview 
during Demo with different kinds of people. Depending on your taste, you 

58 
C H A P T E R 3 First Contact 
PATTERN 
3.4 continued 
may perform these attempts before, after, or interwoven with Read All the 
Code in One Hour (Pattern 3.2) and Skim the Documentation (Pattern 3.3). 
Afterward, you may want to Chat with the Maintainers (Pattern 3.1) to ver- 
ify some of your findings. 
At the end of your first contact with the system, you should decide on 
how to proceed with (or cancel) the project. By seeing the demonstrations, 
you get a feeling for how the people use the system and which features are 
appreciated. Thus you know the valuable parts of the software system, and 
these are probably the ones that must be reverse engineered. The usage 
scenarios will also serve as an input for patterns like Speculate about 
Design (Pattern 4.2) and Record Business Rules as Tests (Pattern 6.5). 
PATTERN 
Do a Mock Installation 
Problem 
Intent: Check whether you have the necessary artifacts available by in- 
stalling the system and recompiling the code. 
How can you be sure that you will be able to (re)build the system? 
This problem is difficult because 
9 The system is new to you, so you do not know which files you need to 
build the system. 
9 The system may depend on libraries, frameworks, and patches, and 
you're uncertain whether you have the right versions available. 
9 The system is large and complex, and the exact configuration under 
which the system is supposed to run is unclear. 
9 The maintainers may answer these questions, or you may find the 
answers in the manual, but you still must verify whether this answer is 
complete. 
Yet, solving this problem is feasible because 
9 You have access to the source code and the necessary build tools (i.e., 
the makefiles, compilers, linkers). 
9 You have the ability to reinstall the system in an environment that is 
similar to that of the running system (i.e., the installation CD and a 
computer with the right operating system). 

P A T T E R N 3.5 Do a Mock Installation 
59 
Maybe the system includes some kind of self-test (see "Tests: Your Life 
Insurance!," Chapter 6), which you can use to verify whether the build 
or install succeeded. 
Solution 
Try to install and build the system in a clean environment during a limited 
amount of time (at most one day). Run the self-test if the system includes 
one. 
Trade-offs 
Hints 
The main idea is to verify whether you are able to replicate the install and 
build processes, not to understand them completely. 
Log all small failures you encounter during the build and installation 
process and the way you solved them, because this will tell you about the 
configuration of the system and its dependencies on libraries, frameworks, 
and patches. For example, you may learn that the system cannot be com- 
piled on a certain location, needs an old legacy library only accessible from 
a particular machine, or needs a particular patch of the libraries. 
It is possible that at the end of the day you did not succeed in building 
or installing the system completely. This corresponds to a high probabil- 
ity/high impact risk for your reengineering project and therefore, before 
you continue, you must plan to study the build and install procedures and 
adapt them where necessary. 
After this build and install experiment, prepare a report containing 
9 version numbers of libraries, frameworks, and patches used 
9 dependencies between the infrastructure (database, network toolkits, 
ports, etc.) 
9 problems you encountered and how you tried to solve them 
9 suggestions for improvement 
9 (in case of incomplete installation or build) your assessment of the situ- 
ation, including possibilities for solutions and workarounds 
Pros 
9 Is an essential prerequisite. The ability to (re)build or (re)install the sys- 
tem is essential for a reengineering project; therefore you must assess 
this issue early on. If building or installing proves to be difficult or 
impossible, plan the necessary corrective actions. 
9 Demands precision. Replicating the build and installation process 
forces you to be precise about the components required. Especially for 

60 
CHAPTER 3 First Contact 
Example 
PATTERN 3.5 continued 
migration projects, this information is crucial because all the compo- 
nents must be available on the target platform as well. 
Increases your credibility. After the build or install you will have first- 
hand experience with the steps that prove to be difficult. It should be 
easy to offer some concrete suggestions for improvement, which will 
undoubtedly increase your credibility with the maintenance team. 
Cons 
9 Tedious activity. You will feel very unproductive while you are busy 
tracking down the causes behind your failures to install the system, 
especially since most of the problems depend on trivial details that do 
not interest you right now. You can counter this effect to some extent by 
limiting the amount of time you devote to Do a Mock Installation, but 
then you will feel even more unproductive because you will not have 
succeeded in building or installing the system. 
9 No certainty. Although this pattern demands precision, there is no guar- 
antee that you will actually succeed in building the system after you 
have reengineered some of its components. Especially when a reliable 
self-test is missing, you cannot verify whether your build or install was 
complete. 
Difficulties 
Easy to get carried away. Building or installing a complex system may 
easily fail due to external factors (missing components, unclear instal- 
lation scripts). It is tempting to continue fixing these annoying prob- 
lems due to the "next time it will work" effect. Rather than getting car- 
ried away with these details, it is important not to lose sight of the main 
goal, which is not to build the system, but to gain insight into the build 
process. Consequently you should limit the time you spend and focus 
on documenting the problems that arise so you can address them later. 
You have carried out an Interview during Demo (Pattern 3.4) with some 
end users and consequently have a feeling for the important features that 
should be preserved during your reengineering project. However, before 
accepting the project, you still must verify whether you will be able to change 
the system. Hence, you decide to do a quick experiment to see whether you 
should carry out a clean build of the system. 
From the box that Dave has left in your office, you take the second CD 
containing all the source code. Browsing the directories you notice one 

P A T T E R N 3.5 Do a Mock Installation 
61 
top-level makefile, and you decide to give it a try. You copy all the files to 
the Linux partition of your system and type the command make a] ] at the 
prompt. Everything goes smoothly for a while, and the system reports 
numerous successful java compilations. Unfortunately, after a few min- 
utes the make fails due to a missing library java. sq]. You realize that you 
still have a JDKI.1 installed, while you remember that the documentation 
mentioned that it should have been JDK1.3. Reluctantly, you trash the 
whole directory structure, uninstall JDKI.1, download and install a JDK1.3 
(downloading takes forever so you fetch yourself a cup of real coffee), and 
then start again. This time the make proceeds smoothly until the compil- 
ing of the C code starts. The first compilation immediately fails due to a 
missing library file, and you open the C file to see what exactly is causing 
this failure. Apparently something must be wrong with the search paths 
because assert, h is a standard library you know is available in your sys- 
tem. By then it is almost lunchtime, and since you planned to finish this 
build experiment today, you decide to leave the whole C compilation for 
later. Dave is here anyway, and since he wrote this C code he will surely be 
able to show you how to compile it. 
After lunch, you want to verify whether what you built is OK. A grep 
"void ma i n (" reveals that the XDoctor.java file contains the main entry so 
you type java XDoctor to launch the system. And indeed, the start-up 
screen you recognize from the demonstration appears, and a little status 
window appears telling you that "the system is connecting to the data- 
base." Immediately thereafter, the system fails with a "something unex- 
pected happens" message, and you suspect this is due to the missing data- 
base. You decide to investigate this issue later and turn your attention to 
the installation procedure. 
You put the installation CD in the CD drive of your Macintosh to see 
whether you are able to install the system. Automatically, the typical instal- 
lation window appears, and you proceed through the installation process 
smoothly. After the installation process completes, the installer asks you to 
reboot your computer before launching the system. You make a note to 
verify which system extensions are installed, reboot your computer, and 
then double-click the XDoctor icon that appeared on your desktop. Unfor- 
tunately, a window appears that asks you to provide a license key. Studying 
the CD box you read that you must have received the license key in a sepa- 
rate letter, which of course you did not receive. "Too bad," you think. "It 
would have been nice to run a demo version of the system when no license 
key is provided, just as we do with our proDoc." Frustrated, you decide to 
give up and write the following report: 
9 Make with a JDK1.3 appears to work; could not verify whether this build 
was complete. 
9 C compilation fails; request Dave to demonstrate the build. 

62 
CHAPTER 3 First Contact 
Known 
Uses 
What Next 
PATTERN 
3.5 continued 
9 Investigate licensing in further detail: how is the system protected? 
9 Suggestion: If no license key is provided, run in demo mode (compare 
with proDoc). 
9 Suggestion: Verify preconditions when calling XDoctor.main0; system 
exits with "something unexpectedly happens" after a fresh build. 
In one of the FAMOOS case studies, we had to reengineer a distributed sys- 
tem that was communicating over sockets with a central server by means 
of a little command language. We received a tape containing a tar file 
that--according to the letter attached~"contains everything that is 
required." Rebuilding and reinstalling the system proved to be difficult, 
however, and we had to dive into the installation scripts and ask the main- 
tainers for clarification. In the end, we could not communicate with the 
central server due to security and connection problems, but we were able 
to test the system in simulation mode. Although the experiment did not 
succeed completely, it gave us insights into the system's architecture. In 
particular, the way the simulation mode mimicked the central server and 
the way this was encoded in the source code and the makefiles provided us 
with information that turned out to be crucial during the rest of the 
project. 
Toward the end of the first day of an auditing project we carried out, we 
requested to see a clean install the following morning. We considered this 
to be an innocent request meant to prepare things for an Interview during 
Demo (Pattern 3.4), but during the installation we discovered that one 
maintainer had to stay overnight to prepare the installation CD. From the 
subsequent discussion we learned that the system wasn't meant to be 
installed: the user base was fixed and the system was designed to down- 
load weekly updates over the Internet. This explained many peculiarities 
we observed during a previous effort to Read All the Code in One Hour 
(Pattern 3.2) and helped us a lot to expose the design issues during the 
remainder of the auditing project. 
When working with a configuration management system, it is a good 
idea to first try to import the code into a clean configuration before recom- 
piling it. In the case of a Smalltalk system, for instance, one general piece of 
advice is to first try to load the Envy configuration maps that compose the 
system and then load the code into a clean image [Pelr01]. 
It can be a good idea to Chat with the Maintainers (Pattern 3.1) before you 
report your conclusions. They may be able to confirm your findings and 
clear up some misconceptions. Concrete suggestions for improvement are 

P A T T E R N 3.5 Do a Mock Installation 
63 
best discussed with the maintainers because it is the best way to convince 
them that you really mean to help them. 
When the build or installation fails completely, you may want to com- 
bine Interview during Demo (Pattern 3.4) with Do a Mock Installation. In 
that case, invite a maintainer to demonstrate the build or installation pro- 
cess and ask questions about those steps you have found unclear. 

CHAPTER 
Initial Understanding 
Your company develops and distributes a medical information system 
named proDoc for use by doctors. Now the company has bought a compet- 
ing software product, XDoctor, that provides Internet support to perform 
transactions with various health insurance companies. The two products 
should be merged into a single system. 
A first evaluation of XDoctor has revealed that a few components 
should somehow be recovered and integrated into yours. Of course, to suc- 
cessfully recover a software component, you must understand its inner 
structure as well as its connections with the rest of the system. For instance, 
your company has promised that customers "won't lose a single byte of 
data"; hence you must recover the database contents and consequently 
understand the database structure and how the upper layers depend on it. 
Also, your company has promised to continue and even expand the trans- 
action support with health insurance companies; hence you must recover 
the network communication component used to communicate with these 
remote services. 
Forces 
Situations similar to this one occur frequently in reengineering projects. 
'After the First Contact" (Chapter 3) with the system and its users, it is clear 
what kind of functionality is valuable and why it must be recovered. How- 
ever, you lack knowledge about the overall design of the software system, 
so you cannot predict whether this functionality can be lifted out of the 
legacy system and how much effort that will cost you. Such initial under- 
standing is crucial for the success of a reengineering project, and this 
chapter will explain how to obtain it. 
The patterns in "First Contact" (Chapter 3) should have helped you to 
get some first ideas about the software system. Now is the right time 
to refine those ideas into an initial understanding and to document that 
65 

66 
C H A P T E R 4 Initial Understanding 
understanding in order to support further reverse engineering activities. 
The main priority at this stage of reverse engineering is to set up a reliable 
foundation for the rest of your project; thus you must make sure that your 
discoveries are correct and properly documented. 
How to properly document your discoveries depends largely on the 
scope of your project and the size of your team. A complicated reverse 
engineering project involving more than ten developers demands some 
standard document templates and a configuration management system. 
At the other extreme, a run-of-the-mill project involving fewer than three 
people may be able to manage just fine with some loosely structured files 
shared on a central server. However, there are a few inherent forces that 
apply to any situation: 
9 Data is deceptiue. To understand an existing software system you must 
collect and interpret data and summarize it in a coherent view. There is 
usually more than one way to interpret data, and when choosing be- 
tween alternatives you will make assumptions that are not always backed 
up by concrete evidence. Consequently, double-check your sources to 
make sure you build your understanding on a solid foundation. 
9 Understanding implies iteration. Understanding occurs inside the hu- 
man brain and thus corresponds to a kind of learning process. Reverse 
engineering techniques must support the way our minds assimilate 
new ideas and hence be very flexible and allow for a lot of iteration and 
backtracking. Consequently, plan for iteration and feedback loops in 
order to stimulate a learning process. 
9 Knowledge must be shared. Once you understand the system, it is im- 
portant to share this knowledge with your colleagues. Not only will it 
help them to do their job, it will also result in comments and feedback 
that may improve your understanding. Therefore, put the map on the 
wall: publish your discoveries in a highly visible place and make ex- 
plicit provisions for feedback. How to do this will depend on the team 
organization and working habits. Team meetings in general are a good 
way to publish information (see Speak to the Round Table, Pattern 2.3), 
but a large drawing on the wall near the coffee machine may serve just 
as well. 
9 Teams need to communicate. Building and documenting your under- 
standing of a system is not a goal; it is a means to achieve a goal. The 
real goal of understanding the system is to communicate effectively 
with the other people involved in the project; thus the way you docu- 
ment your understanding must support that goal. There is, for instance, 
no point in drawing UML class diagrams if your colleagues only know 
how to read ER diagrams; there is no point in writing use cases if your 
end users can't understand their scope. Consequently, use their language: 
choose the language for documenting your understanding so that your 

What Next 
67 
team members can read, understand, and comment on what you have 
documented. 
Overview 
When developing your initial understanding of a software system, incor- 
rect information is your biggest concern. Therefore these patterns rely 
mainly on source code because this is the only trustworthy information 
source. 
In principle, there are two approaches for studying source code: one is 
top down; the other is bottom up (see Figure 4.1 on page 64). In practice, 
every reverse engineering approach must incorporate a little bit of both, 
but still it is worthwhile to make the distinction. With the top-down ap- 
proach, you start from a high-level representation and verify it against the 
source code (as, for instance, described in Speculate about Design, Pattern 
4.2). In the bottom-up approach, you start from the source code, deter- 
mine what's relevant, and cast the relevant entities into a higher-level rep- 
resentation. This is the approach used in Analyze the Persistent Data (Pat- 
tern 4.1) and Study the Exceptional Entities (Pattern 4.3) 
There is no preferred order in which to apply each of these patterns. It 
may be natural to first Analyze the Persistent Data (Pattern 4.1), then refine 
the resulting model via Speculate about Design (Pattern 4.2), and finally 
exploit this knowledge to Study the Exceptional Entities (Pattern 4.3). There- 
fore the patterns are presented in that order. However, large parts of your 
system won't have anything to do with a database (some systems lack any 
form of persistent data), and then Speculate about Design (Pattern 4.2) 
must be done without having studied the database. And when you lack the 
inspiration to start with Speculate about Design (Pattern 4.2), then Study 
the Exceptional Entities (Pattern 4.3) will surely provide you with an initial 
hypothesis. 
The amount of time you should devote to each of these patterns de- 
pends largely on the goal of your reengineering project. In principle, none 
of these patterns will take long, but each of them should be applied several 
times. You cannot predict how many cycles will be necessary because the 
assessment ofwhether your team understands enough to proceed with the 
rest of the project can only be done after the patterns have been applied. 
Therefore these patterns must be applied on a case-by-case basis. 
What Next 
You should make sure to reflect your increased understanding in the 
project plan. For instance, Analyze the Persistent Data (Pattern 4.1) and 
Speculate about Design (Pattern 4.2) will document parts of the system, 

68 
C H A P T E R 4 Initial Understanding 
and this documentation must be added to the opportunities. On the other 
hand, Study the Exceptional Entities (Pattern 4.3) will reveal some suspi- 
cious components, and these must be added to the risks. 
Once you have obtained a solid foundation for your understanding, 
you should fill in the details for those components that are important for 
the rest of your project. Activities described in "Detailed Model Capture" 
(Chapter 5) may help you to fill in those details. 
PATTERN 
Analyze the Persistent Data 
Problem 
/ntent: Learn about objects that are so valuable they must be kept inside a 
database system. 
Which object structures represent the valuable data? 
This problem is difficult because 
9 Valuable data must be kept safe on some external storage device (e.g., a 
file system, a database). However, such data stores often act as an attic: 
they are rarely cleaned up and may contain lots of junk. 
9 When loaded in memory, the valuable data is represented by complex 
object structures. Unfortunately there is a big gap between the data 
structures provided by external storage devices and the object struc- 
tures living in main memory. Inheritance relationships, for instance, 
are seldom explicitly provided in a legacy database. 
9 "Valuable" is a relative property. It is possible that large parts of the 
saved data are irrelevant for your reengineering project. 
Yet, solving this problem is feasible because 
9 The software system employs some form of a database to make its data 
persistent. Thus there exists some form of database schema providing a 
static description of the data inside the database. 
9 The database comes with thenecessary tools to inspect the actual ob- 
jects inside the database, so you can exploit the presence of legacy data 
to fine-tune your findings. 
9 You have some expertise with mapping data structures from your im- 
plementation language onto a database schema, enough to reconstruct 
a class diagram from the database schema. 

P A T T E R N 4.1 Analyze the Persistent Data 
fi9 
Solution 
You have a rough understanding of the system's functionality and the 
goals of your project (for example, obtained via "First Contact," Chap- 
ter 3), so you can assess which parts of the database are valuable for 
your project. 
Analyze the database schema and assess which structures represent valu- 
able data. Derive a class diagram representing those entities to document 
that knowledge for the rest of the team. 
Steps 
The following steps assume that the system makes use of a relational dam- 
base, which is commonly the case for object-oriented applications. How- 
ever, in case you're confronted with another kind of database system, 
many of these steps may still be applicable. The steps themselves are guide- 
lines only; they must be applied iteratively, with liberal doses of intuition 
and backtracking. 
Prepare model To derive a class diagram from a relational database schema, 
first prepare an initial model representing the tables as classes. You may do 
this by means of a software tool, but a set of index cards may serve just as 
well. 
1. Enumerate all table names, and for each one, create a class with the 
same name. 
2. For each table, collect all column names and add these as attributes to 
the corresponding class. 
3. For each table, determine candidate keys. Some of them may be read 
directly from the database schema, but usually a more detailed analy- 
sis is required. Certainly check all (unique) indexes because they often 
suggest candidate keys. Naming conventions (names including ID or 
#) may also indicate candidate keys. In case of doubt, collect data sam- 
ples and verify whether the candidate key is indeed unique within the 
database population. 
4. Collect all foreign key relationships between tables and create an asso- 
ciation between the corresponding classes. Foreign key relationships 
may not be maintained explicitly in the database schema, and then 
you must infer these from column types and naming conventions. 
Careful analysis is required here, as homonyms (= identical column 
name and type, yet different semantics) and synonyms (= different 
column name or type, yet identical semantics) may exist. To cope with 
such difficulties, at least verify the indexes and view declarations 
because these point to frequent traversal paths. If possible, verify the 

70 
C H A P T E R 4 Initial Understanding 
PATTERN 4.1 continued 
join clauses in the SQL statements executed against the database. 
Finally, confirm or refute certain foreign key relationships by inspect- 
ing data samples. 
Incorporate inheritance. After the previous steps, you will have a set of 
classes that represents the tables being stored in the relational database. 
However, because relational databases cannot represent inheritance rela- 
tionships, you have to infer these from the foreign keys. (The terminology 
for the three representations of inheritance relations in steps 5-7 stems 
from [Fros94].) 
5. One to one (Figure 4.2(a)). Check tables where the primary key also 
serves as a foreign key to another table, as such foreign keys may rep- 
resent inheritance relationships. Examine the SELECT statements that 
are executed against these tables to see whether they usually involve a 
join over this foreign key. If this is the case, analyze the table names 
and the corresponding source code to verify whether this foreign key 
indeed represents an inheritance relationship. If it does, transform the 
association that corresponds with the foreign key into an inheritance 
relationship. 
6. Rolled down (Figure 4.2(b)). Check tables with common sets of col- 
umn definitions, since these probably indicate a situation where the 
class hierarchy is spread over several tables, each table representing 
one nonabstract class. Define a common superclass for each cluster of 
duplicated column definitions and move the corresponding attributes 
inside the new class. Check the source code for the name applicable 
for the newly created classes. 
7. Rolled up (Figure 4.2(c)). Check tables with many columns and lots of 
optional attributes because these may indicate a situation where a 
complete class hierarchy is represented in a single table. If you have 
found such a table, examine all the SELECT statements that are exe- 
cuted against this table. If these SELECT statements explicitly request 
subsets of the columns, then you may break this one class into several 
classes depending on the subsets requested. For the names of these 
classes, check for an encoding of subtype information like, for in- 
stance, a "kind" column holding an enumeration type number. 
Incorporate associations. Note that the class diagram extracted from the 
database may be too small: it is possible that classes in the actual inheri- 
tance hierarchy have been omitted in the database because they did not 
define any new attributes. Also, table and column names may sound 
bizarre. Therefore, consider verifying the class diagram against the source 

P A T T E R N 4.1 Analyze the Persistent Data 
71 
Tables with foreign key relationships 
Person 
id: char(5) 
< 
name: char(40) 
address: char(60) 
I 
Inheritance hierarchy 
Person 
id: ObjectID 
name: String 
address: String 
4 
I 
I 
Patient 
Salesman 
| 
Patient 
Salesman 
insuranceID: String 
company: String 
id: char(5) 
id: char(5) 
insuranceID: char(7) 
company: char(40) 
insurance: String 
i 
insurance: char(5) 
Tables with common column definitions 
Large table with many optional columns 
Patient 
id: char(5) 
name: char(40) 
address: char(60) 
insuranceID: char(7) 
insurance: char(5) 
Salesman 
id: char(5) 
name: char(40) 
address: char(60) 
company: char(40) 
Person 
id: char(5) 
kind: integer 
name: char(40) 
address: char(60) 
insuranceID: char(7) ,optionab~ 
insurance: char(5) ,optionab~ 
company: char(40) ,optionab~ 
FIGURE 
Mapping a series of relational tables onto an inheritance hierarchy: (a) one to one, 
(b) rolled down; (c) rolled up. 
code (see Speculate about Design, Pattern 4.2) because this may provide 
extra insight. Afterward, refine the remaining associations. 
8. Determinate association classesmclasses that represent the fact that 
two objects are associated. The most common example is a many-to- 
many association, which is represented by a table having a candidate 
key consisting of two foreign keys. In general, all tables where the can- 
didate keys are concatenations of multiple foreign keys are potential 
cases of an association class. 
9. Merge complementary associations. Sometimes class A will have a for- 
eign key association to class B, and class B, an inverse foreign key to 
class A. In that case, merge the two associations into a single associa- 
tion navigable in both directions. 
10. Resolve foreign key targets. When inheritance hierarchies have been 
rolled up or down in the database, foreign key targets may become 

72 
C H A P T E R 4 Initial Understanding 
PATTERN 4.1 continued 
ambiguous after the table has been decomposed into its constituent 
classes. Foreign key targets may be too high or too low in the hierarchy, 
in which case the corresponding association will have too little or too 
many participating classes. Resolving such situations typically requires 
analyzing data samples and SQL statements to see which classes actu- 
ally participate in the association. 
11. Identify qualified associations--associations that can be navigated by 
providing a certain lookup key (the qualifier). Common examples are 
ordered one-to-many associations, where the ordering number serves 
as the qualifier. In general, all tables where the candidate key com- 
bines a foreign key with extra columns are potential qualified associa- 
tions; the extra columns then represent the qualifier. 
12. Note multiplicities for the associations. Since all associations are de- 
rived from foreigfi key relationships, all associations are by construc- 
tion optional one-to-many associations. However, by inspecting non- 
null declarations, indices, and data samples, you can often determine 
the minimum and maximum multiplicities for each of the roles in the 
association. 
Verification. Note the recurring remark that the database schema alone is 
too weak as a basis to derive a complete class diagram. Fortunately, a leg- 
acy system has a populated database and programs manipulating that 
database. Hence, data samples and embedded SQL statements can be 
used to verify the reconstructed classes. 
9 Data samples. Database schemas only specify the constraints allowed 
by the underlying database system and model. However, the problem 
domain may involve other constraints not expressed in the schema. By 
inspecting samples of the actual data stored in the database, you can 
infer other constraints. 
9 SQL statements. Tables in a relational database schema are linked via 
foreign keys. However, it is sometimes the case that some tables are 
always accessed together, even if there is no explicit foreign key. There- 
fore, it is a good idea to check which queries are actually executed 
against the database engine. One way to do this is to extract all embed- 
ded SQL statements in the program. Another way is to analyze all exe- 
cuted queries via the tracing facilities provided with the database 
system. 
Incorporate operations. It should be clear that the class diagram you ex- 
tract from a database will only represent the data structure, not the opera- 
tions used to manipulate those structures. As such, the resulting class dia- 

P A T T E R N 4.1 Analyze the Persistent Data 
73 
gram is necessarily incomplete. By comparing the code with the model 
extracted from the database (see Speculate about Design, Pattern 4.2, and 
Look for the Contracts, Pattern 5.4), it is possible to incorporate the opera- 
tions for the extracted classes. 
Trade-offs 
Pros 
9 Improues team communication. By capturing the database schema 
you will improve the communication within the reengineering team 
and with other developers associated with the project (in particular the 
maintenance team). Moreover, many if not all of the people associated 
with the project will be reassured by the fact that the data schema is 
present because lots of development methodologies stress the impor- 
tance of the database design. 
9 Focuses on ualuable data. A database provides special features for 
backup and security and is therefore the ideal place to store the valu- 
able data. Once you understand the database schema, it is possible to 
extract the valuable data and preserve it during future reengineering 
activities. 
Cons 
9 Has limited scope. Although the database is crucial in many of today's 
software systems, it involves but a fraction of the complete system. As 
such, you cannot rely on this pattern alone to gain a complete view of 
the system. 
9 Contains junk data. A database will contain a lot more than the valu- 
able data, and depending on how old the legacy system is, a lot of junk 
data may be stored just because nobody took time to remove it. There- 
fore, you must match the database schema you recovered against the 
needs of your reengineering project. 
9 Requires database expertise. The pattern requires a good deal of knowl- 
edge about the underlying database plus structures to map the data- 
base schema into the implementation language. As such, the pattern 
should preferably be applied by people having expertise in mappings 
from the chosen database to the implementation language. 
9 Lacks behavior. The class diagram you extract from a database is very 
data oriented and includes little or no behavior. A truly object-oriented 
class diagram should encapsulate both data and behavior, so in that 
sense the database schema shows only half of the picture. However, 
once the database model exists, it is possible to add the missing behav- 
ior later. 

74 
C H A P T E R 4 Initial Understanding 
PATTERN 4.1 continued 
Difficulties 
Polluted database schema. The database schema itself is not always the 
best source of information to reconstruct a class diagram for the valu- 
able objects. Many projects must optimize database access and often 
sacrifice a clean database schema. Also, the database schema itself evolves 
over time and will slowly deteriorate. Therefore, it is quite important to 
refine the class diagram via analysis of data samples and embedded SOL 
statements. 
Example While taking over XDoctor your company has promised to continue to 
support the existing customer base. In particular, you have guaranteed 
customers that they won't lose a single byte of data, and now your boss asks 
you to recover the database structure. From experience with your own 
product, you know that doctors care a lot about their patient files and that 
it is unacceptable to lose such information. Therefore you decide that you 
will start by analyzing the way patient files are stored inside the database. 
You start by browsing all table names looking for a table named Patient, 
but unfortunately you don't find one. However, there is a close match in a 
table named Person, where column names like i nsuranceID suggest that at 
least some patient information is stored. Nevertheless, many column names 
are optional, so you suspect a rolled-up representation, where patient in- 
formation is mixed with information from other kinds of people. There- 
fore, you check the source code and look for all embedded SQL statements 
querying the table Person (i.e., grep "SELECT * Person"). Indeed, there are 
two classes where such a query is used, namely, Pati ent and Salesman, and 
from the subsets of columns queried in each class, you infer the inheri- 
tance hierarchy depicted in Figure 4.2. 
Now that you recovered the Patient, you start looking for the table that 
stores the treatments a patient received. And indeed there is a table Treat- 
ment, which has a foreign key to the table Person. However, since you have 
decomposed Person into the classes Patient and Salesman, it is necessary 
to resolve the target of the foreign key. You join the tables Person and Treat- 
ment over patientlD (SELECT DISTINCT name, kind FROM Person, Treatment 
WHERE Person. id = Treatment.patientID) and see that all selected persons 
indeed have a kind that corresponds to a Patient. Therefore, you set the 
target of the foreign key leaving from Treatment to Patient (see left side of 
Figure 4.3). Next, you verify the indices defined on Treatment and notice 
that there is a unique index on the columns patientID-date-nr, which 
makes you conclude that these columns serve as a candidate key. Since the 
candidate key on Treatment consists of a foreign key combined with two 
extra columns, you suspect a qualified association. To confirm this assump- 

P A T T E R N 4.1 Analyze the Persistent Data 
75 
FIGURE 
Rationale 
Identify a qualified association via a key consisting of a foreign key (pati entID) and 
two extra columns (date, nr). 
tion you analyze a data sample (SELECT name, date, nr FROM Person, Treat- 
ment WHERE Person.id = Treatment.patientIDORDER BY name, date, nr) and 
see that the date and the number uniquely identify a treatment for a given 
patient. As a consequence, you transform the foreign key into a qualified 
association had-treatment with a multiplicity of one on each role. 
The object model is important for database applications because it con- 
cisely describes data structure and captures structural constraints. 
[Blah98] 
Having a well-defined central database schema is a common practice in 
larger software projects that deal with persistent data. Not only does it 
specify common rules on how to access certain data structures, it is also a 
great aid in dividing the work between team members. Therefore, it is a 
good idea to extract an accurate model of the database before proceeding 
with other reverse engineering activities. 
Note that extracting a database model is essentially a bottom-up ap- 
proach: you start from the rough information contained in the database 
schema and you polish it up until you have a satisfactory class diagram. A 
bottom-up approach works quite well in such a situation because a data- 
base schema is already an abstraction from a more detailed representation. 
All data should be hidden within its class. 
[Rie196], Heuristic 2.1 
Information hiding is an important design principle, and most authors 
agree that for a class this implies that all data should be encapsulated 
within the class and only accessed via the operations defined on that class. 
Unfortunately, the class diagram you extract from a database will expose 

76 
C H A P T E R 4 Initial Understanding 
Known 
Uses 
What Next 
PATTERN 4.1 continued 
all of its data because that's the nature of a database. Therefore, this class 
diagram is just a first step toward a well-designed interface to the database. 
The reverse engineering and reengineering of database systems is a well- 
explored area of research [Arno92] [Mull00]. Several experiments indicate 
that it is feasible to recover the database structure, even for database sys- 
tems that are poorly designed. [Prem94], for instance, reports on an experi- 
ment concerning the reverse engineering of a data dictionary of a leading 
RDBMS vendor, as well as a production database storing data about mech- 
anical parts. [Hain96] describes a prototype database reverse engineering 
toolkit, as well as five industrial cases where the toolkit has been applied. 
To illustrate the unpredictable nature of database reverse engineering, 
[Jahn97] reports on the use of a fuzzy reasoning engine as the core of a tool 
that extracts class diagrams out of relational database schemas. 
Analyze the Persistent Data results in a class diagram for the persistent 
data in your software system. Such a class diagram is quite rough and is 
mainly concerned with the structure of the data and not with its behavior. 
However, it may serve as an ideal initial hypothesis to be further refined by 
applying Speculate about Design (Pattern 4.2) and Look for the Contracts 
(Pattern 5.4). 
Ifyou need to migrate to another database, you should cast your under- 
standing of the database model in a test suite as explained in "Tests: Your 
Life Insurance!" (Chapter 6). 
Note that there exist patterns, idioms, and pattern languages that de- 
scribe various ways to map object-oriented data structures to relational 
database counterparts [Brow96b] [Kel198]. Consulting these may help you 
when you are reverse engineering a database schema. 
PATTERN 
Problem 
Speculate about Design 
Intent: Progressively refine your model of the system by checking hy- 
potheses about the design against the source code. 
How do you recover the way design concepts are represented in the source 
code? 

P A T T E R N 4.2 Speculate about Design 77 
Solution 
This problem is difficult because 
9 There are many design concepts, and there are countless ways to repre- 
sent them in the programming language used. 
9 Much of the source code won't have anything to do with the design but 
rather with implementation issues (glue code, user interface control, 
database connections, etc.). 
Yet, solving this problem is feasible because 
9 You have a rough understanding of the system's functionality (for exam- 
ple, obtained via Skim the Documentation, Pattern 3.3, and Interview 
during Demo, Pattern 3.4), and you therefore have an initial idea which 
design issues should be addressed. 
9 You have development expertise, so you can imagine how you would de- 
sign the problem yourself. 
9 You are somewhat familiar with the main structure of the source code 
(for example, obtained by Read All the Code in One Hour, Pattern 3.2) 
so that you can find your way around. 
Use your development expertise to conceive a hypothetical class diagram 
representing the design. Refine that model by verifying whether the names 
in the class diagram occur in the source code and by adapting the model 
accordingly. Repeat the process until your class diagram stabilizes. 
Steps 
1. With your understanding of the system, develop a class diagram that 
serves as your initial hypothesis of what to expect in the source code. 
For the names of the classes, operations, and attributes, make a guess 
based on your experience and potential naming conventions (see Skim 
the Documentation, Pattern 3.3). 
2. Enumerate the names in the class diagram (that is, names of classes, at- 
tributes, and operations) and try to find them in the source code, using 
whatever tools you have available. Take care as names inside the source 
code do not always match with the concepts they represent. 1 To coun- 
ter this effect, you may rank the names according to the likelihood that 
they would appear in the source code. 
1. In one particular reverse engineering experience, we were facing source code that 
was a mixture of English and German. As you may expect, this complicates matters 
alot. 

78 
C H A P T E R 4 Initial Understanding 
PATTERN 4.2 continued 
3. Keep track of the names that appear in source code (confirm your hy- 
pothesis) and the names that do not match with identifiers in the 
source code (contradict your hypothesis). Remember that mismatches 
are positive because they will trigger the learning process that you must 
go through in trying to understand the system. 
4. Adapt the class diagram based on the mismatches. Such adaptation 
may involve 
(a) renaming, when you discover that the names chosen in the source 
code do not match with your hypothesis. 
(b) remodeling, when you find out that the source code representation 
of the design concept does not correspond with what you have in 
your model. For instance, you may transform an operation into a 
class, or an attribute into an operation. 
(c) extending, when you detect important elements in the source code 
that do not appear in your class diagram. 
(d) seeking alternatives, when you do not find the design concept in the 
source code. This may entail trying synonyms when there are few 
mismatches but may also entail defining a completely different 
class diagram when there are lots of mismatches. 
5. Repeat steps 2-4 until you obtain a class diagram that is satisfactory. 
Variants 
Speculate about Business Objects. A crucial part of the system design is the 
way concepts of the problem domain are represented as classes in the 
source code. You can use a variant of this pattern to extract those so-called 
business objects. 
One way to build an initial hypothesis is to use the noun phrases in the 
requirements as the initial class names and the verb phrases as the initial 
method names. (See [Wirf90] [Bell97] [Booc94] for in-depth treatments of 
finding classes and their responsibilities.) You should probably augment 
this information via the usage scenarios that you get out of Interview dur- 
ing Demo (Pattern 3.4), which may help you to find out which objects fulfill 
which roles. (See [Jaco92] [Schn98] for scenarios and use cases and [Reen96] 
[Rieh98] for role modeling.) 
Speculate about Patterns. Patterns are "recurring solutions to a common 
design problem in a given context." Once you know where a certain pat- 
tern has been applied, it reveals a lot about the underlying system design. 
This variant verifies a hypothesis about occurrences of architectural 
[Busc96], analysis [Fowl97], or design patterns [Gamm95]. 

P A T T E R N 4.2 Speculate about Design 
79 
Trade-offs 
Speculate about Architecture. "A software architecture is a description of 
the subsystem and components of a software system and the relationships 
between them" [Busc96] (a.k.a. Components and Connectors [Shaw96]). 
The software architecture is typically associated with the coarse-level de- 
sign of a system, and as such it is crucial in understanding the overall struc- 
ture. Software architecture is especially relevant in the context of a distrib- 
uted system with multiple cooperating processes, an area where reverse 
engineering is quite difficult. 
This variant builds and refines a hypothesis about which components 
and connectors exist, or in the context of a distributed system, which pro- 
cesses exist, how they are launched, how they get terminated, and how 
they interact. Consult [Busc96] for a catalogue of architectural patterns 
and [Shaw96] for a list of well-known architectural styles. See [Lea96] for 
some typical patterns and idioms that may be applied in concurrent pro- 
gramming and [Schm00] for architectural patterns in distributed systems. 
Pros 
9 Scales well. Speculating about what you'll find in the source code is a 
technique that scales up well. This is especially important because for 
large object-oriented programs (over 100 classes), a bottom-up approach 
quickly becomes impractical. 
9 Investment pays off. The technique is quite cheap in terms of resources 
and tools, especially when considering the amount of understanding 
you obtain. 
Cons 
9 Requires expertise. A large repertoire of knowledge about idioms, pat- 
terns, algorithms, and techniques is necessary to recognize what you 
see in the source code. As such, the pattern should preferably be ap- 
plied by experts. 
9 Consumes much time. Although the technique is quite cheap in terms 
of resources and tools, it requires a substantial amount of time before 
you derive a satisfactory representation. 
Difficulties 
Maintain consistency. You should plan to keep the class diagram up to 
date while your reverse engineering project progresses and your under- 
standing of the software system grows. Otherwise your efforts will be 
wasted. Therefore, make sure that your class diagram relies heavily on 
the naming conventions used in the source code and that the class dia- 
gram is under the control of the configuration management system. 

80 
C H A P T E R 4 Initial Understanding 
Example 
PATTERN 4.2 continued 
While taking over XDoctor, your company has promised to continue to 
support the existing customer base. Prod since Switzerland will be joining 
the Euro region within six months, the marketing department wants to 
make sure that Euro conversions will be supported properly. A first evalua- 
tion has revealed that the Euro is supported to some degree (i.e., it was 
described in the user manual and there exists a class named Currency). 
Now, your boss asks you to investigate whether they can meet the legal 
obligations, and if not, how long it will take to adapt the software. 
From a previous code review, you learned that the design is reasonably 
good, so you suspect that the designers have applied some variant of the 
Quantity pattern (Pattern A.16). Therefore, you define an initial hypothesis 
in the form of the class diagram, depicted in Figure 4.4(a). There is one 
class Money holding two attributes; one for the amount of money (a floating 
point number) and one for the currency being used (an instance of the 
Currency class). You assume operations on the Money class to perform the 
standard calculations like addition, subtraction, multiplication, and so on, 
plus one operation for converting to another currency. Currency should 
have subclasses for every currency supported and then operations to sup- 
port the conversion from one currency into another. Of course, some ques- 
tions are left unanswered, and you note them down on your class diagram: 
1. What is the precision for an amount of Money? 
2. Which calculations are allowed on an instance of Money? 
3. How do you convert an instance of Money into another currency? 
4. How is this conversion done internally? How is the support from the 
Currency class? 
5. Which are the currencies supported? 
To answer these questions you verify your hypothesis against the source 
code and you adapt your class diagram accordingly. A quick glance at the 
filenames reveals a class Currency but no class named Money; a grep search 
on all of the source code confirms that no class Money exists. Browsing which 
packages import Currency, you quickly find out that the actual name in the 
source code is Price, and you rename the Money class accordingly. 
Looking inside the Price class reveals that the amount of money is rep- 
resented as a fixed-point number. There is a little comment line stating: 
Michael (Oct 1999)--Bug Report #324--Replaced Float by BigDecimal 
due to rounding errors in the floating point representation. 
Trimmed down the permitted calculation operations as well. 

P A T T E R N 4.2 Speculate about Design 81 
aClass 
amount: Money 
Precision? 
Money 
amount: float 
currency: Currency 
"~ 
*,/ 
convert (Currency) 
Calculations? 
/ 
// 
Conversion 
Conversion to 
~ 
support on currency? I 
other currency? 
/ 
/ 
/ 
/ 
(a) 
1 ~1 
Currency 
o
.
.
 
Convert?? 
I 
I 
Supported currencies? 
aClass 
amount: Price 
Renamed 
Remodeled 
Confirmed 
1 
- -Price 
! 
/ 
! 
amount: BigDecimal 
currency: Currency 
add (Price) 
negate (Price) 
f 
, .. 
.. isNegative(): Boolean 
= _ - - subtractPercent (float) 
.. 
multiplyInt (int) 
'" 
multiplyDouble (double) 
convert (Currency) 
Currency 
i 
convFactor: BigDecimal 
I 
Currency(factor: BigDecimal) 
I 
conversion Factor(): BigDecimal I 
\ 
Alternative 
\ 
\ 
Currencies 
\ \ default()" Currency 
lookUp(String)" Currency 
isPresent(String): Boolean 
enumerator()" Enumeration 
(b) 
FIGURE 
Refining the hypotheses concerning the Euro representation. (a) An initial hypothe- 
sis where the open questions are inserted as Notes (subclasses for the different cur- 
rencies) and (b) a refined hypothesis after verification against the source code (fly- 
weight approach); the modifications are shown as Notes. 
Checking the interface of the Pri ce class you see that the calculation oper- 
ations are indeed quite minimal: only addition and negation (apparently 
subtraction must be done via an addition with a negated operand) and some 
extra operations to take percentages and multiply with other numbers. 
However, you also spot a convert operation, which confirms your hypothe- 
sis concerning the conversion of prices. 

82 
C H A P T E R 4 Initial Understanding 
P AT T E R N 4.2 continued 
Next you look for subclasses of Currency, but you don't seem to find any. 
Puzzled, you start thinking about alternative solutions, and after a while 
you consider the possibility of a Flyweight (Pattern A.14). After all, having a 
separate subclass for each currency is a bit of an overhead because no extra 
behavior is involved. Moreover, with the flyweight approach you can save a 
lot of memory by representing all occurrences of the Euro currency with a 
single Euro object. To verify this alternative, you look for all occurrences of 
constructor methods for Currency. A grep 'Currency (' does the trick~and 
you actually discover a class Currencies that encapsulates a global table 
containing all currencies accepted. Looking at the initialize method, you 
learn that the actual table contains entries for two currencies: the Euro and 
the Swiss franc. 
Finally, you study the actual conversion in a bit more detail by looking 
at the Pri ce.convert operation and the contents of the Currency class. 
After some browsing, you discover that each Currency has a single conver- 
sion factor. This makes you wonder: isn't conversion supposed to work in 
two ways and between all possible currencies? But then you check all invo- 
cations of the convers i onFactor method, and you deduce that the conver- 
sion is designed around the notion of a default currency (i.e., the Cur- 
rencies.default() operation) and that the conversionFactor is the one 
that converts the given currency to the default one. Checking the Price. 
convert operation, you see that there is indeed a test for default currency, 
in which case the conversion corresponds to a simple multiplication. In 
the other case, the conversion is done via a two-step calculation involving 
an intermediate conversion to the default currency. 
You're quite happy with your findings and you adapt your class diagram 
to the one depicted in Figure 4.4(b). That model is annotated with the 
modifications you made to the original hypothesis; thus you store both the 
original and refined models into the configuration management system so 
that your colleagues can reconstruct your deductive process. You also file 
the following report summarizing your findings. 
Conversion to Euro: Facilities for Euro conversion are available, but extra 
work is required. One central class (Currencies) maintains a list of sup- 
ported currencies, including one default currency (Currenci es. defau] t). To 
convert to Euro, the initialization of this class must be changed so that the 
default becomes Euro. All prices stored in the database must also be con- 
verted, but this is outside the scope of my study. 
Follow-up actions: 
9 Adapt initialization of class Currencies so that it reads the default cur- 
rency and conversion factors from the configuration file. 
9 Check the database to see how Prices should be converted. 

P A T T E R N 4.2 Speculate about Design 83 
FIGURE 
Rationale 
Known 
Uses 
White noise obtained by a bottom-up design extraction approach. The figure shows 
a fragment of an inheritance hierarchy augmented with all method invocations and 
attribute accesses for a medium-sized system. The visualization is performed by 
CodeCrawler [Deme99] [Lanz99]. 
The naive approach to design extraction is bottom up: first build a com- 
plete class diagram from source code and afterward condense it by remov- 
ing the noise. Unfortunately, the bottom-up approach does not work for 
large-scale systems because you typically get a lot of white noise to start 
from (see, for example, Figure 4.5, showing an inheritance hierarchy with 
associations for a medium-sized system). Moreover, such a bottom-up ap- 
proach does not improve your understanding very much because it forces 
you to focus on the irrelevant noise instead of the important concepts. 
We get things wrong before we get things right. 
[Cock93] 
In order to gain a true understanding of the legacy problem, you must go 
through a learning process. Speculate about Design is intended to stimu- 
late such a learning process, and therefore evidence that contradicts your 
hypothesis is as valuable as evidence that confirms it. Indeed, mismatches 
force you to consider alternative solutions and assess their pros and cons, 
and that is the moment when true understanding emerges. 
In [Murp97] there is a report of an experiment where a software engineer at 
Microsoft applied this pattern (it is called "the Reflection Model" in the 
paper) to reverse engineer the C code of Microsoft Excel. One of the nice 

84 
C H A P T E R 4 Initial Understanding 
What Next 
PATTERN 4.2 continued 
sides of the story is that the software engineer was a newcomer to that part 
of the system and that his colleagues could not spend too much time to 
explain it to him. Yet after a brief discussion he could come up with an 
initial hypothesis and then use the source code to gradually refine his 
understanding. Note that the paper also includes a description of a light- 
weight tool to help in specifying the model, mapping from the model to the 
source code, and checking of the code against the model. 
The articles [Bigg89] [Bigg93] [Bigg94] report several successful uses of 
this pattern (there it is called the "concept assignment problem"). In par- 
ticular, the authors describe a tool prototype named DESIRE, which in- 
cludes advanced browsing facilities, program slicing, and a Prolog-based 
query language. The tool has been used by a number of people in different 
companies to analyze programs of up to 220 KLOC. Other well-known 
applications are reported by the Rigi group which, among others, has ap- 
plied this pattern on a system consisting of over 2 million lines of PL/AS 
code [Wong95]. 
It has been shown that such an approach can be used to map an object- 
oriented design onto a procedural implementation purely based on a 
static analysis of the source code [Gall99] [Weid98]. Nevertheless, newer 
approaches try to exploit richer and more diverse information sources. 
DALI, for instance, also analyzes information from makefiles and profilers 
[Bass98] [Kazm98] [Kazm99]. Gaudi, on the other hand, verifies the hy- 
pothesis against a mixture of the static call graphs with run-time traces 
[Rich99]. 
After this pattern, you will have a class diagram representing a part of the 
design. You may want to Study the Exceptional Entities (Pattern 4.3) to get 
an impression of the design quality. Ifyou need a more refined model, con- 
sider the patterns in "Detailed Model Capture" (Chapter 5). When your 
reverse engineering efforts are part of a migration or reengineer project, 
you should cast your understanding of design in a test suite as explained in 
"Tests: Your Life Insurance!" (Chapter 6). 
PATTERN 
Study the Exceptional Entities 
Intent: Identify potential design problems by collecting measurements 
and studying the exceptional values. 

P A T T E R N 4.3 Study the Exceptional Entities 
85 
Problem 
Solution 
How can you quickly identify potential design problems in large software 
systems? 
This problem is difficult because 
9 There is no easy way to discern problematic from good designs. As- 
sessing the quality of a design must be done in the terms of the problem 
it tries to solve and thus can never be inferred from the design alone. 
9 To confirm that a piece of code represents a design problem, you must 
first unravel its inner structure. With problematic code this is typically 
quite difficult. 
9 The system is large. Thus a detailed assessment of the design quality of 
every piece of code is not feasible. 
Yet, solving this problem is feasible because 
You have a metrics tool at your disposal, so you can quickly collect a 
number of measurements about the entities in the source code. 
9 You have a rough understanding of the system's functionality (for exam- 
ple, obtained via "First Contact," Chapter 3), so you can assess the qual- 
ity of the design in the system context. 
9 You have the necessary tools to browse the source code, so you can ver- 
ify manually whether certain entities are indeed a problem. 
Measure the structural entities forming the software system (i.e., the inher- 
itance hierarchy, the packages, the classes, and the methods) and look for 
exceptions in the quantitative data you collected. Verify manually whether 
these anomalies represent design problems. 
Hints 
Identifying problematic designs in a software system via measurements is 
a delicate activity that requires expertise in both data collection and inter- 
pretation. Here are some hints you might consider to get the best out of the 
raw numbers: 
Which tool to use? There are many tools~commercial as well as public 
domain~that measure various attributes of source code entities. Never- 
theless, few development teams make regular use of such tools, and 
therefore it is likely that you will have to look for a metrics tool before 
applying this pattern. 
In principle, start by looking at the tools used by the development team 
and see whether they can be used to collect data about the code. For 

86 
C H A P T E R 4 Initial Understanding 
PATTERN 
4.3 continued 
instance, a code verification tool such as ]i nt can serve as a basis for 
your measurements. Start looking for a metrics tool only when none of 
the development tools currently in use may collect data for you. If that's 
the case, simplicity should be your main tool adoption criterion, as you 
do not want to spend your precious time on installing and learning. The 
second tool adoption criterion is how easily the metrics tool integrates 
with the other development tools in use. 
9 Which metrics to collect? In general, it is better to stick to the simple 
metrics, since the more complex ones involve more computation, yet 
will rarely perform better. 
For instance, to identify large methods it is sufficient to count the lines 
of code by counting all carriage returns or new lines. Most other method- 
size metrics require some form of parsing, and this effort is usually not 
worth the gain. 
9 Which metric variants to use? Usually, it does not make a lot of differ- 
ence which metric variant is chosen, as long as the choice is clearly 
stated and applied consistently. Here as well, it is preferable to choose 
the most simple variant, unless you have a good reason to do otherwise. 
For instance, while counting the lines of code, you should decide 
whether to include or exclude comment lines, or whether you count the 
lines after the source code has been normalized via pretty printing. 
However, when looking for potential design problems, it usually does 
not pay off to make the extra effort of excluding comment lines or nor- 
malizing the source code. 
9 Which thresholds to apply? Due to the need for reliability, it is better 
not to apply thresholds. 2 First, selecting threshold values must be done 
based on the coding standards applied in the development team, and 
you do not necessarily have access to these. Second, thresholds will dis- 
tort your perspective on the anomalies inside the system since you will 
not know how many normal entities there are. 
9 How to interpret the results? An anomaly is not necessarily problem- 
atic, so care must be taken when interpreting the measurement data. To 
assess whether an entity is indeed problematic, it is a good idea to 
simultaneously inspect different measurements for the same entity. For 
instance, do not limit yourself to the study of large classes, but combine 
the size of the class with the number of subclasses and the number of 
2. Most metric tools allow you to focus on special entities by specifying some threshold 
interval and then only displaying those entities where the measurements fall into 
that interval. 

P A T T E R N 4.3 Study the Exceptional Entities 
87 
Trade-offs 
superclasses, because this says something about where the class is 
located in the class hierarchy. 
However, formulas that combine different measurements into a single 
number should be avoided as you lose the sense of the constituting ele- 
ments. Therefore it is better to present the results in a table, where the 
first column shows the name of the entity, and the remaining columns 
show the different measurement data. Sorting these tables according to 
the different measurement columns will help you to identify excep- 
tional values. 
How to identify anomalies quickly? Although it is possible to identify 
exceptional values in a tabular representation of measurement data, 
such an approach is tedious and error prone. Most metric tools include 
some visualization features (histograms, scatter plots, etc.) to help you 
scan large volumes of measurements, and this is usually a better way to 
quickly focus on potential design problems. 
Should I browse the code afterward? Measurements alone cannot de- 
termine whether an entity is truly problematic: some human assess- 
ment is always necessary. Metrics are a great aid in quickly identifying 
entities that are potential problems, but code browsing is necessary for 
confirmation. Note that large entities are usually quite complicated; 
thus understanding the corresponding source code may prove to be 
difficult. 
What about normal entities? Experienced programmers tend to distrib- 
ute important functionality over a number of well-designed compo- 
nents. Conversely, exceptional entities are quite often irrelevant as truly 
important code would have been refactored. Therefore, you should be 
aware that you are only applying a heuristic; it is possible that you are 
studying code that does not represent a design problem simply because 
it is deemed unimportant. 
Pros 
9 Scales well. Metrics are readily applicable to large-scale systems, mainly 
because with metric tools about 20% of all the entities require further 
investigation. When different metrics are combined properly (prefera- 
bly using some form of visualization), you can deduce quite rapidly 
which parts of the system represent potential design problems. 
9 Overview mode is appealing. With proper tool support you can pro- 
duce visual representations of the metrics data that provide immediate 
insight into the good as well as the problematic parts of the design. 

88 
C H A P T E R 4 Initial Understanding 
Example 
PATTERN 
4.3 continued 
Cons 
9 Results are inaccurate. Some of the entities having exceptional mea- 
surements will turn out not to be problematic. Metrics are only a heu- 
ristic, and false positives are likely to occur. Moreover, the metric may 
reveal problems that are not worth solving because the solutions will 
not contribute to your reengineering goal. Unfortunately, you will only 
know this after you have analyzed the source code. 
9 Priorities may be missing. Identifying a potential problem is easy; the 
real difficult part is assessing the severity of the problem. Especially 
during a reengineering project, you identify far more problems than 
you have time to solve. Prioritizing the list requires a good understand- 
ing of both the system and the reengineering project. 
Difficulties 
9 Data is tedious to interpret. To measure the quality of a piece of code, 
you must collect several measurements. Interpreting and comparing 
such multivalued tuples is quite tedious, especially when dealing with 
large software systems. Therefore, use visualizations that allow you to 
analyze different measurements simultaneously. 
9 Requires expertise. The interpretation of measurement data is difficult 
and requires a lot of expertise. Fortunately, part of this expertise is doc- 
umented in the form of design heuristics (see among others [Rie196] 
[Lore94]) and the rest can be acquired on the job. 
The analysis of the database and the design of XDoctor was quite reassur- 
ing. Although there were some things to improve, the overall quality was 
quite good. Yet you want to confirm this feeling and therefore plan to col- 
lect a number of quality metrics and visualize them. (Of course the visual- 
ization can be done with ordinary spreadsheets, but in this case you decide 
to use the CodeCrawler tool [Deme99b] [Lanz99].) 
Class Size Overview 
As a starter, you get an impression of the raw physical size of all the classes 
constituting XDoctor. You measure the class size in terms of number of 
lines of code (LOC) and number of instance variables (NIV) and use a 
checkers graph to show the relative proportion of the sizes. In such a graph 
all nodes are shown as squares, where the size of the square is proportional 
to one size (here LOC) and the gray value is proportional to another size 
(here NIV). 

P A T T E R N 4.3 Study the Exceptional Entities 
89 
FIGURE 
Class size overview with node size showing the number 
of lines of code and gray value showing the number of 
instance variables. 
Figure 4.6 shows the checker graph for XDoctor. The picture reveals 
that the class size is distributed quite evenly~which is reassuring~with a 
few noteworthy exceptions. For instance, class B is the largest in terms of 
lines of code (with 1495) and class L has most instance variables and sec- 
ond most lines of code. The classes in row Z are exceptional in the sense 
that they are very small; some of them are even empty. 
Class Inheritance 
Next, you get a feeling for the way inheritance is used by studying the vari- 
ous subtrees in the inheritance hierarchy. Therefore, you measure the 
classes in terms of hierarchy nesting level (HNL) and number of descen- 
dant classes (NDC). You include size measurements as well to assess the 
magnitude of the classes within the inheritance tree. Therefore, you collect 
the number of methods (NOM), number of instance variables (NW), and 
number of lines of code (LOC) as well. You use an inheritance tree to visual- 
ize the various subtrees and the proportion of class sizes inside each of 
them. All nodes in such a tree have a rectangular shape where the height, 
width, and gray values of each node show three measurements. 
Figure 4.7 shows such an inheritance tree for XDoctor, where the height, 
width, and gray values of each node represent NOM, NIV, and LOC. To the 
left, you observe several normal inheritance trees, namely, small ones 
where the size of the classes is quite similar. One exceptional value is the 
same B you noticed earlier; however, you now see that it also has a large 
superclass A (defining 70 methods), making it even more suspicious. The L 
you've seen before appears here as a solitary class. The hierarchies rooted 
in K, F, and G seem quite interesting: they go deep (four levels of inheri- 
tance) and have one large root class plus many smaller subclasses. H and I, 
plus M and N, are cases of large sibling classes, which may imply that too 
little is inherited from the common superclass. This must be verified via 
code browsing, however. 

90 
C H A P T E R 4 Initial Understanding 
PATTERN 4.3 continued 
FIGURE 
Inheritance tree focusing on class size. The node width shows the number of 
instance variables, the node height shows the number of methods, and the gray 
value shows the number of code lines. 
Method Inheritance 
To analyze particular inheritance trees in further detail, you investigate 
how methods in a subclass relate to methods in their superclass. Therefore, 
you produce a table showing for each class the number of methods over- 
riding a method defined in a superclass (NMO), the number of methods 
added to the superclass (NMA), and the number of methods extending a 
method defined in a superclass (NME). Here as well you use an inheritance 
tree to identify exceptional values in the measurements. 
Figure 4.8 shows the A, G, and F subtrees identified earlier, but now the 
height, width, and gray values of each node represent NMO, NMA, and NME. 
The root classes are displayed as narrow white rectangles, which is normal 
as root classes can neither override nor extend. As far as the subclasses are 
concerned, you observe two phenomena. On the one hand, the subclasses 
of A add a lot, yet override very little, which suggests that code reuse is the 
main purpose of this inheritance tree. On the other hand, the subclasses of 
F and G override more methods than they add, which suggests a lot of hook 
methods and an inheritance tree aimed at specializing behavior. Here as 
well, these assumptions must be verified by code browsing. 
Method Size Overview 
An example of how to identify potential problems in the method bodies 
concerns the ratio of lines of code (LOC) and the number of messages sent 
(MSG). In most method bodies, these two measurements will correlate, but 

P A T T E R N 4.3 Study the Exceptional Entities 
91 
FIGURE 
Inheritance tree focusing on method inheritance. The node width shows the num- 
ber of methods added, the node height shows the number of methods overridden, 
and the gray value shows the number of methods extended. 
methods where this correlation does not hold typically represent special 
code. 
To study this correlation relationship, you might divide the two mea- 
surements. 3 However, then you lose the sense of the constituting measure- 
ments, which makes interpretation difficult. Therefore, you visualize the 
relationship by means of a correlation graph, where each method is shown 
as a small square and where the x, y position shows the measurements that 
are supposed to correlate. In such a graph, the nodes where the measure- 
ments correlate cluster around a diagonal, while the exceptions are farther 
from the diagonal. 
Figure 4.9 shows a correlation graph where the horizontal axis (left to 
right) represents the number of messages sent and the vertical axis (top to 
bottom) the number of lines of code. You observe a big cluster in the top- 
left corner, where most nodes are superimposed on each other. This is 
reassuring because it implies that most methods have fewer than 15 lines 
of code and 10 messages sent. The exceptions appear at the edges of the 
picture. For instance, node A is a large method with 99 messages packed in 
45 lines of code. Node D and its neighbors are also methods where many 
messages are packed in a single line of code. Via code browsing you see 
that many of them are initialization methods. At the other side of the diag- 
onal there is node B, which represents a method with 16 lines of code yet 
no messages sent. Code browsing reveals that it is a case where the whole 
method body has been commented out. 
3. Metrics theory prohibits arbitrary manipulations of numbers; you should first verify 
whether the scale of the measurement permits the calculation [Fent96]. However, 
both are counting measurements having a ratio scale and then division is permitted. 

92 
C H A P T E R 4 Initial Understanding 
PATTERN 
4.3 continued 
FIGURE 
Correlation graph, with the x-position showing the number of 
messages sent and the y-position showing the lines of code. 
Rationale 
You cannot control what you cannot measure. 
[DeMa82] 
In several places in the literature it is mentioned that measuring source 
code helps in problem identification (see among others, [Lore94] [Fent96] 
[Mayr96] [Nesi98]). Most metric tools applied during these experiments 
visualize information by means of histograms and Kiviat diagrams. How- 
ever, little research has studied the impact of thresholds while identifying 
exceptional entities; our own experience is that thresholds don't really 
matter [Deme99a]. 
Unfortunately, the current research is inconclusive with regard to the 
accuracy of the results. Lip until now, no experiments exist that count how 

P A Y Y E R N 4.3 Study the Exceptional Entities 
93 
many problems remain undiscovered, nor is there any work on assessing 
the severity of the problems discovered. As such it is impossible to assess 
the reliability of metrics for reverse engineering. 
Known 
Uses 
During the FAMOOS project one event provided anecdotal evidence for 
how well a simple approach may outperform more specialized and com- 
plex approaches. Once we visited a business unit for a few days to dem- 
onstrate our CodeCrawler tool. At first the developers were quite skeptical 
because they felt that they would see "yet another metrics tool." The first 
surprise came when we showed them results the very first day. They told us 
that other tools would typically require several days' configuration time 
before they could parse their C+ code because it made such heavy use of 
special C features and macros. Moreover, and this was the second sur- 
prise, this simplicity did not diminish the quality of our results. The pro- 
grammers confirmed most of the design anomalies we discovered, yet 
were intrigued by some observations we made. During the subsequent dis- 
cussions they at least considered design alternatives. 
What Next 
Applying this pattern will result in an overall impression of design quality 
and the identification of a few potential design problems. With this knowl- 
edge you should at least reconsider whether the goal of your reengineering 
project is still attainable. If it is, you will probably want to solve some of 
these design problems, for instance, using patterns in "Redistribute Re- 
sponsibilities" (Chapter 9) and "Transform Conditionals to Polymorph- 
ism" (Chapter 10). Solving some of these problems may require a more 
detailed understanding of that design, which may be obtained by patterns 
in "Detailed Model Capture" (Chapter 5). 

CHAPTER 
Detailed Model Capture 
The patterns in "First Contact" (Chapter 3) should have helped you to get 
acquainted with the software system, while those in "Initial Understand- 
ing" (Chapter 4) should have helped you to understand which are the most 
important entities in the system. Your main priority now is to build up a 
detailed model of those parts of the system that will be important for your 
reengineering effort. 
Most of the patterns concerned with "Detailed Model Capture" entail 
considerably more technical knowledge, use of tools, and investment of ef- 
fort than the patterns we have applied up to now. This is only natural, since 
only after you have built up your "Initial Understanding" can you deter- 
mine whether more intensive investment of effort will pay off. 
Forces 
Although you already have an impression of the system, there are several 
forces at play that may make it difficult to extract a more detailed model: 
9 Details matter As argued by Brooks [Broo87], software engineering is 
different from other engineering disciplines because of the inherent 
lack of abstraction barriers. Other engineering disciplines rely on the 
laws of nature to hide irrelevant details, but software engineering must 
build on less solid foundations. Consequently, it is essential to pay atten- 
tion to the details. The only question is how to filter out those details 
that do not matter because you cannot possibly investigate everything. 
9 Design remains implicit. As you read the code, many design decisions 
will become apparent to you, but it will not be clear why and how these 
decisions were made. In particular, it will be hard to tell which design 
decisions were easy to make, and which of them created a lot of grief. 
95 

96 
C H A P T E R 5 Detailed Model Capture 
Nevertheless, such knowledge is crucial during a reengineering project 
because you want to avoid making the same mistakes over and over 
again. Consequently, once you discouer the underlying design rationale, 
make sure that it is properly recorded. This way, your successors will be 
able to build on your discoveries rather than be forced to reinvent the 
wheel. 
Design does euolue. Change is an essential ingredient of a successful 
system, and certainly in object-oriented development processes with 
their emphasis on iterative development. As a consequence, design 
documents will always be out of date with respect to the actual situa- 
tion. However, this also implies that change itself is the key to under- 
standing how and why the design of a system has evolved the way it has. 
Consequently, assume that important design issues will be reflected in 
the source code and in the way this code has changed ouer time. 
Static structure uersus dynamic behauior. Object-oriented source code 
tells you which classes are defined, and how they are arranged in a class 
hierarchy. It is much harder to see which objects are instantiated at run 
time and how they collaborate to support the system. On a fine-grained 
level, however, the latter is much more relevant than the former, espe- 
cially due to the use of polymorphism. Consequently, to extract the 
detailed design you must ineuitably study the dynamic behauior. 
Overview 
The patterns of"Detailed Model Capture" propose a series of activities that 
help you to expose design artifacts that are hidden in the code. Although 
some of these patterns, in particular Tie Code and Questions (Pattern 5.1), 
are lightweight, most of them entail considerable effort, so you should 
evaluate carefully how much you expect to get out of applying them. 
Figure 5.1 on page 94 suggests some possible relationships between the 
patterns. Tie Code and Questions (Pattern 5.1) is perhaps the most funda- 
mental of these patterns, and the easiest to apply. As you work through the 
source code, keep track of comments, questions, hypotheses, and possible 
actions to perform by directly annotating the source code at the point 
where the comment applies. This pattern works well with the other patterns 
in this cluster and can be productively applied throughout a reengineering 
project. 
Refactor to Understand (Pattern 5.2) helps you to expose the design of 
cryptic code. It is important to understand that the intent of this pattern is 

What Next 
97 
not to improve the code base itself, but only to improve your understand- 
ing. It might well be that you decide to keep the results ofyour refactorings, 
but this should not be your goal at this point. Your refactorings should 
instead be treated as experiments to tests various hypotheses concerning 
the code. 
Since the source code gives you only a very static view of the class hier- 
archy, it is useful to Step through the Execution (Pattern 5.3) to learn what 
objects are instantiated at run time and how they interact. 
Mthough it is very easy to extract the interfaces of the classes in the sys- 
tem, this will not tell you very much about how these interfaces can or 
should be used. What you really need to do is Look for the Contracts (Pat- 
tern 5.4) supported by each class. The contracts tell you which client-sup- 
plier relationships exist, and how the public interface of a class supports 
that relationship. Idiomatic coding practices and design patterns typically 
express such contracts in a direct way, so you should train yourself to rec- 
ognize them. 
Finally, although you may be able to extract various design artifacts 
from the source code, you will not necessarily be able to get an insight into 
how the system evolved that way. In particular, you may wonder whether 
certain design decisions were really justified, or whether they were arbi- 
trary, and you may wonder how stable parts of the design are. By compar- 
ing different versions of the code base and focusing on places where func- 
tionality was removed or refactored, you will be able to Learn from the Past 
(Pattern 5.5). 
What Next 
Now that you have mastered the details of a part ofyour system, it is a good 
time to prepare for the actual reengineering by applying the patterns in 
"Tests: Your Life Insurance!" (Chapter 6). In particular, as you Refactor to 
Understand (Patten 5.2), it is a good idea to Write Tests to Understand (Pat- 
tern 6.6), as this will give you confidence in your experiments. Mso, pat- 
terns like Step through the Execution (Pattern 5.3), Look for the Contracts 
(Pattern 5.4), and Learn from the Past (Pattern 5.5) help you to see which 
components implement what functionality; this knowledge must be used 
to Test the Interface, Not the Implementation (Pattern 6.4) and to Record 
Business Rules as Tests (Pattern 6.5). 

98 
c H A P T E R 5 Detailed Model Capture 
PATTERN 
Tie Code and Questions 
Intent: Keep the questions and answers concerning your reengineering 
activities synchronized with the code by storing them directly in the source 
files. 
Problem 
Solution 
How do you keep track ofyour understanding about a piece of code and the 
questions that you have, keep these remarks synchronized with the code 
during its future evolution, and share them with the other members ofyour 
team? 
This problem is difficult because 
9 Writing up what you know and don't know about the system you are 
analyzing is tedious and time-consuming. 
9 Your understanding is a moving target, so it is hard to keep a written doc- 
ument up to date. 
9 If you don't write down your questions and insights as soon as they 
occur to you, you will not be able to keep track of them. 
9 You want to share your knowledge with the team to maximize its value. 
9 Logging questions and answers in log files, bulletin boards, or email dis- 
tribution lists may be convenient for disseminating knowledge within 
the team, and may provide a convenient searchable history of the team's 
understanding, but when you are looking at a piece of code, it will be 
hard to tell what questions and answers pertain to it. 
Yet, solving this problem is feasible because 
You can annotate the code and therefore record your understanding 
physically close to the code element it refers to. 
While you are working on the code, annotate it directly and immediately 
with the questions you are facing. 
In principle there are two ways to annotate the code. 
Comment-based annotations. This approach uses the commenting 
conventions of the programming language and as such is better suited 
for a text-oriented environment. A few conventions are needed to dis- 
tinguish the normal comments from the annotations. 

P A T T E R N 5.1 Tie Code and Questions 
99 
/ 
~r 
#to: John #by: SD #on: 3/12/99 ******************* 
Screws up when we have nested I Fs. */ 
Basic tools that are a part of your program environment can then be 
used to search and modify annotations. With a little bit of extra effort 
you can easily build tools to query, extract, and cross-index all com- 
ment-based annotations. 
Method-based annotations. This approach exploits the possibility of 
querying which method invokes a given method, a feature provided by 
many of today's programming environments. The idea is to declare a 
global method accepting a few strings as an argument and having 
an empty method body. Each time you want to annotate a particular 
piece of code, you invoke that method, passing your annotations as a 
parameter. 
this.annotatefiode("#to: John #by: SD #on: 3/12/99," 
"Screws up when we have nested I Fs."); 
You can then use the querying and browsing facilities of your program- 
ming environment to identify the locations where this special method 
is invoked and thus where the annotations occur. Most programming 
environments can be extended by means of little scripts, in which case 
it is possible to develop tools to generate reports about all annotations. 
Note that the less you change the code, the less likely it is that you will 
introduce errors. This makes the comment-based version safer than the 
method-based version. 
Hints 
Record your annotations as close as possible to the code to which they 
refer. 
9 Annotations may be questions, hypotheses, "to do" lists, or simply obser- 
vations about the code that you wish to record for future reference. 
9 Use conventions to identify your annotations. In a team context, in- 
clude, for example, the initials of the developer that made the com- 
ments and the date the comment was entered. This way you can easily 
query them. 
9 Follow the corporate practices. If comments are written in a language 
other than English, continue if you can. However, if you have the 
choice, never write your annotations in a language different from that 
in which the source code is written (English in most cases). Otherwise, 
you create a different context and force the reader to switch between 
them. 

100 
C H A P T E R 5 Detailed Model Capture 
Tradeoffs 
PATTERN 
5.1 continued 
When you discover the answer to any one of your questions, immedi- 
ately update the annotation for the benefit of future readers, or simply 
delete the question if it is no longer relevant. 
Pros 
9 Improves synchronization. You keep the code and the annotations in 
close physical proximity, and you thereby improve your chances of 
keeping them in sync. While modifying the code, you will more natu- 
rally modify the annotations, or remove them if they become obsolete. 
9 Improves team communication. Tie Code and Questions avoids forcing 
team members to open an extra communication channel (email, bulle- 
tin boards, etc.). They must read the code they work with anyway, so 
you can multiplex the code as a communication channel. 
9 Minimizes context description. When you annotate the code you are 
immediately in context. This way you will minimize the need to de- 
scribe the context ofyour questions and keep your effort low while doc- 
umenting your questions and annotations. 
Cons 
Passive in nature. Questions that you enter are not necessarily directed 
to anyone, and even if they are, it is not certain that the addressee will 
read them or answer them in time. Additional tools are needed to col- 
lect the annotations and maybe even notify the appropriate people. 
Incompatible with some processes. Many companies are organized 
around a hierarchical reporting structure. Tie Code and Questions may 
be rejected by these organizations because it circumvents the normal 
communication channels. Also, some corporate practices impose strong 
constraints on what programmers are allowed to do with the code, 
which may limit the potential of this pattern. For instance, if annota- 
tions cannot be removed when they become obsolete, they will create 
too much noise to be useful. 
Difficulties 
Finding the right granularity. As with any kind of comments, you should 
take care to introduce just the right amount of detail. Terse or cryptic 
annotations quickly lose their value, and verbose annotations will dis- 
tract the reader from the code itself. 

P A T T E R N 5.1 Tie Code and Questions 
101 
9 Motivating the programmers to write comments. Programmers gener- 
ally do not like to write comments or documentation. One way of moti- 
vating them is to use the annotations during code reviews or status 
meetings; this way the comments have an immediate benefit. 
9 Quality of the answers. As with any other kind of documentation, it may 
happen that wrong answers are given. One way to deal with this situa- 
tion is to review the annotations regularly within the team. 
9 Eliminating the annotations. On certain occasions you may wish to 
remove the annotations~for instance, if you must deliver a "clean" ver- 
sion of the source code to your customer, or ifyour compiler isn't smart 
enough to remove an invocation of an empty method body. In that case, 
make sure that you have the proper tools to filter out the annotations. 
Rationale 
This pattern has its roots in literate programming [Reen89] [Knut92]. A lit- 
erate program reverses the usual relationship between program text and 
comments: executable code is embedded within documentation, not the 
other way around. Literate programming puts the emphasis on keeping 
the code and its documentation physically close. The physical proximity 
reduces the effort spent in keeping the code and its documentation in sync. 
Known 
Uses 
Comment-based annotations 
Various programming environments provide implicit support for manag- 
ing annotations within the code. Emacs, for example, has a built-in tool, 
called e-tags, which allows you to easily generate a cross-reference data- 
base of a set of files [Came96]. The Eiffel environment, on the other hand, 
allows you to assign different levels of visibility to your comments (and 
your code). If you assign private scope to your annotations, you can easily 
separate the annotations yet make sure that they will not be seen externally. 
The company MediaGeniX~a Belgian company operating in the multi- 
media sector~uses a systematic code tagging mechanism to record infor- 
mation about changes. The programming environment was altered in 
such a way that every change to the code is automatically annotated with a 
tag describing the motivation for the code change (bug fix, change request, 
new release), the name of the developer, and the time of the modification. 
Only the last tag is kept in the code, but via the configuration management 
system it is possible to inspect previous tags and changes. The tag also 
includes a free field where the developers may write what they want and is 
often used for questions and answers. 

102 
C H A P T E R 5 Detailed Model Capture 
PATTERN 5.1 continued 
FIGURE 
Finding all senders of a message in Squeak. 
Method-based annotations 
The Squeak development team [Inga97] used this technique not so much 
to keep track of questions but as a means to facilitate communication in an 
open-source development project. In this team comments were intro- 
duced by invoking the method fl ag: defined in the class Object. Devel- 
opers can query all senders of the flag: message to locate annotations. 
Furthermore, the method is defined to accept a symbol as its argument. 
This makes it possible to search more specifically, for example, for all the 
annotations flagged with the symbol #noteFordohn. 
Object>>fl ag: aSymbol 
"Send this message, with a relevant symbol as argument, to flag 
a message for subsequent retrieval. For example, you might put 
the fol lowing I ine in a number of messages: 
self flag: #returnHereUrgently 
Then, to retrieve all such messages, browse all senders of 
#returnHereUrgent ly. " 
Figure 5.2 shows, on the top pane, all the senders of the fl ag: message 
in the Squeak 2.7 environment. The bottom pane then shows the code of 

P A T T E R N 5.2 Refactor to Understand 
103 
the method removeEmptyRows that contains a call to the method fl ag: high- 
lighted. The flag: message is sent with argument #noteToOohr~ The actual 
content of the annotation follows as a comment. 
Related 
Patterns 
Tie Code and Questions works well in tandem with Refactor to Understand 
(Pattern 5.2). Questions in the code may often be resolved by refactoring it. 
Conversely, as you Refactor to Understand, new questions will be raised 
and can be entered as annotations. 
PATTERN 
Refactor to Understand 
Problem 
Solution 
/ntent: Iteratively refactor a part of a software system in order to validate 
and reflect your understanding of how it works. 
How can you understand a cryptic piece of code? 
This problem is difficult because 
9 Cryptic code is difficult to read, and hence to understand. 
9 You may have some idea how the code works, but it is hard to verify 
because the code does not reflect your ideas. 
Yet, solving this problem is feasible because 
9 The piece of code is relatively small and has clearly defined boundaries. 
9 Your development tools allow for rapid edit-compile cycles, so you can 
make some small changes and check whether you're still able to com- 
pile the source code or whether your tests still run. 
9 You have a source code browser that allows you to query dependencies 
between source code entities (e.g., which methods invoke a given oper- 
ation, which methods access a given attribute, etc.), so that you can 
infer its purpose. 
Iteratively rename and refactor the code to introduce meaningful names 
and to make sure the structure of the code reflects what the system is actu- 
ally doing. Run regression tests after each change if they are available, or 
else compile often to check whether your changes make sense. Decide 
what to do with the code after you have refactored it. 

104 
C H A P T E R 5 Detailed Model Capture 
P A T T E R N 5.2 continued 
Hints 
Your primary goal here is to understand the system, not to improve the 
code. The changes you make to the code should therefore be treated as 
"experiments" to test your understanding of the code. As a consequence, 
you should make a copy of the code before you start. After you have re- 
factored the code, it is possible that you will release any of the changes you 
make, but you do not want to make that decision up front. Perhaps your 
refactoring experiments will actually improve the code, but it is just as 
likely that you will make a mess of things since you do not yet understand 
the code. It does not really matter at this stage. After a first experience you 
will be in a better position to do a proper job of refactoring. 
It is hard to do a good job of refactoring without having tests in place to 
verify that your changes have not broken anything. If adequate tests do not 
exist, you should not seriously consider keeping the results of your re- 
factoring experiments. However, consider applying Write Tests to Under- 
stand (Pattern 6.6) in tandem with Refactor to Understand. 
You should select refactoring operations that will make design deci- 
sions more explicit in the code. The typical refactorings applied during this 
iterative restructuring are Rename Attribute (Pattern A.7), Rename Method 
(Pattern A.8), and Extract Method (Pattern A.5). 
The following guidelines will help you to find out where and how to 
apply these refactorings to improve the readability of the code. Many of 
these guidelines are considered to be just good, standard practice in Small- 
talk programming [Beck97]. They apply, however, equally well to other pro- 
gramming languages. They can be applied in any order; each of them par- 
ticipates in the understanding of the others. 
9 Rename attributes to convey roles. Focus on attributes with cryptic names. 
To find out about their roles, look at all the attribute accesses (including 
invocations of accessor methods). Afterward, rename the attribute and 
its accessors according to its role, update all references, and recompile 
the system. 
9 Rename methods to convey intent. To retrieve the intent of a method 
that does not have an intention-revealing name, investigate all invoca- 
tions and attribute uses, and deduce the method's responsibility. After- 
ward, rename the method according to its intent, update all invoca- 
tions, and recompile the system. 
9 Rename classes to convey purpose. To capture the purpose of a class 
having an unclear name, investigate clients of the class by examining 
who is invoking its operations or who is creating instances of it. After- 
ward, rename the class according to its purpose, update all references, 
and recompile the system. 

P A T T E R N 5.2 Refactor to Understand 
105 
9 Remove duplicated code. If you identify duplicated code, try to refactor 
it into a single location. As such, you will identify slight differences that 
you probably would not have noticed before refactoring and that are 
likely to reveal some subtle design issues. 
9 Replace condition branches by methods. If you encounter conditions 
with large branches, extract the leaves as new (private) methods. To 
name these methods, study the condition until you understand it well 
enough to choose an intention-revealing name. 
9 Define method bodies with same level of abstraction. Long method 
bodies with comments separating blocks of code violate the rule of 
thumb that all statements in a single method body should have the 
same level of abstraction. Refactor such code by introducing a new (pri- 
vate) method for each separated block of code; name the method after 
the intent recorded in the comment. 
Trade-offs 
Pros 
9 Exposes design. Not only will the refactoring process improve your under- 
standing of the code, but this understanding will also become explicit in 
the structure of the code. This will make it easier to further document 
that understanding by means of Tie Code and Questions (Pattern 5.1) 
or Write Tests to Understand (Pattern 6.6). 
9 Validates incremental approach. Normally, understanding does not arise 
as part of a single revelation, but as the result of an iterative process in 
which earlier understanding is the base for the next iteration. Refactor to 
Understand encourages such an approach because of its emphasis on 
small steps and frequent verification (either by running tests or by 
compiling often). 
Cons 
Risks introducing errors. The less you change the code, the smaller 
your chances of introducing errors. Small refactorings should be be- 
havior preserving, but it may be nontrivial to verify that even simple 
refactorings do not break the code. If you do not have adequate regres- 
sion tests in place, it can be risky to introduce changes, or costly to de- 
velop the needed tests. For these reasons it is important to attempt to 
Refactor to Understand only on a working copy of the software. 
Difficulties 
Tool support. Manually refactoring code can be tedious and risky 
[Fowl99]. Various tools, like the Refactoring Browser [Robe97], greatly 

106 
C H A P T E R 5 Detailed Model Capture 
Known 
Uses 
Related 
Patterns 
What Next 
PATTERN 5.2 continued 
simplify the task of refactoring, and especially help to apply nontrivial 
refactorings such as Extract Method. 
9 Acceptance of changes. Refactoring someone else's code may prove a 
lot harder than refactoring your own. A lot of companies have a strong 
culture of code ownership, so improving someone else's code is often 
considered an insult. That is one of the reasons why you should not 
necessarily release the refactored version to the rest of the team. 
9 Knowing when to stop. It is often difficult to stop changing code when 
you identify problems. Remember that your primary goal here is just to 
understand the system. When you have achieved that goal, it is time to 
stop. 
Don Roberts and John Brant coined the term "Refactor to Understand" at 
ESUG'97 and Smalltalk Solution'97 during a demonstration of the Re- 
factoring Browser. They showed how they gradually understood an algo- 
rithm by renaming and refactoring its code. During the subsequent itera- 
tions of the pattern, the code slowly started to make sense, and the design 
gradually became explicit in the code. 
We applied this pattern ourselves during a FAMOOS case study. We had 
to understand a single method of about 3000 lines of C++, which was a 
deeply nested conditional. We first replaced the leaf condition branches by 
methods, gradually working our way up the nesting structure. After several 
iterations, we discovered that this method was actually implementing a 
complete parser for a small command language. 
Harry Sneed reports several reengineering projects where a large Cobol 
program was refactored by removing all goto statements. However, he was 
later forced to reintroduce the goto statements because the developers 
rejected his changes [Snee99]. 
'~krranging the furniture" [Tayl00] is a pattern to help newcomers feel at 
home when they start in a new project. The pattern solution is '~.n adopter 
should be encouraged to 'move in' by cosmetically arranging the code." 
Refactor to Understand works well in tandem with Tie Code and Questions 
(Pattern 5.1). Refactorings are more expensive to implement than simply 
annotating the code, so first annotate, and then refactor. Also, consider 
applying Write Tests to Understand (Pattern 6.6) as you refactor. These two 
activities reinforce each other since tests document your understanding of 
how a software artifact works, and refactoring helps you to expose its 
design. Furthermore, tests will help you to verify that your refactorings 
didn't break anything. 

P A T T E R N 5.3 Step through the Execution 
107 
When you have finished a round of Refactor to Understand, you must 
decide what to do with your changes. Ifyou discard the experimental code, 
you should consider applying Tie Code and Questions (Pattern 5.1) to 
annotate the code base with the knowledge you have acquired. 
PATTERN 
Problem 
Step through the Execution 
Intent: Understand how objects in the system collaborate by stepping 
through examples in a debugger. 
How do you discover which objects are instantiated at run time and how 
they collaborate? 
This is a difficult problem because 
9 The source code exposes the class hierarchy, not the objects instan- 
tiated at run time and how they interact. 
9 Collaborations are typically spread out through the code. Although it is 
easy to see which classes and methods are defined in a system, it can be 
hard to tell by reading the source code alone which sequence of events 
will lead to an object being created or a method being invoked. 
9 In the presence of polymorphism, it can be especially difficult to tell 
which objects are clients of which service providers. Just because an 
object uses a certain interface that another object provides does not 
mean that the former is actually a client of the latter. 
9 Reading the code will not tell you what concrete scenarios can take 
place. The actual flow of execution will depend on the internal state of 
all participating objects, and this cannot be inferred directly from the 
source code. 
9 The source code will not tell you which objects are long-lived and 
which are ephemeral (i.e., local to the execution of a single method). 
Yet, solving this problem is feasible because 
9 You are aware of some typical usage scenarios. 
9 You can run the code inside a debugger. 
9 Your attention is focused on a specific part of the system. 

108 
C H A P T E R 5 Detailed Model Capture 
Solution 
Trade-offs 
PATTERN 
5.3 continued 
Run each of the scenarios and use your debugger to step through the code. 
Observe which objects collaborate and how they are instantiated. After- 
ward, generalize these observations and record your knowledge for future 
reference, possibly by means of Tie Code and Questions (Pattern 5.1) and 
Record Business Rules as Tests (Pattern 6.5). 
Hints 
It is too time-consuming to step through every single statement of a run- 
ning system. The assumption here is that you are focused on some specific 
aspect of the system that is difficult to understand. 
9 Set breakpoints to interrupt execution when the system enters the code 
you are interested in. 
9 Change the internal state of the objects to see how alternative execu- 
tion paths are triggered. 
9 Restart a method currently on the execution stack to quickly verify a 
similar scenario. 
Pros 
Provides a realistic view. By stepping through the running program, you 
get a precise picture of how the scenario unfolds. Moreover, you can 
inspect the internal state of the objects involved, see how new objects 
are created, and observe which objects collaborate under which 
circumstances. 
Handles complexity. On a small scale it is possible to infer object col- 
laborations from analyzing the source code. Slicing tools, for instance, 
may tell you which statements of the source code are affected by a given 
variable. For large and complex systems, however, the number of possi- 
bilities and interactions is just too large. Therefore, the only reasonable 
way to learn how objects collaborate is to study the execution traces. 
Cons 
Scenario based. You must restrict yourself to a limited set of scenarios; 
hence the observed object collaborations are necessarily incomplete. 
Of course you must do your best to choose representative scenarios. 
Unfortunately, this choice brings you back to square one, because the 
only way to be sure that you have a representative set of scenarios is to 
verify whether they cover all possible object collaborations. 

P A T T E R N 5.4 Look for the Contracts 
109 
What Next 
Restricted applicability. For systems where time plays a crucial role, 
stepping through the execution will give you an unrealistic view of the 
system's behavior. Worse, for concurrent or distributed systems, the 
mere fact of stepping through concurrent code may perturb the execu- 
tion of the system itself. As such, you get the same effects as in Heisen- 
berg's uncertainty experiments, where determining exact positions of 
quantum particles implies that other attributes about these particles 
become uncertain. 
Difficulties 
Dependency on tools. You need to have good debugger to Step through 
the Execution. Not only must it allow the setting and removal of break- 
points dynamically, it also should provide the means to examine the 
state of the objects involved. And to easily verify alternative paths, the 
debugger should allow you to change the internal state of an object or 
even restart a method currently on the execution stack. 
You will need concrete scenarios in order to Step through the Execution 
(possibly inferred from Interview during Demo, Pattern 3.4). Consider 
encoding these scenarios as test cases. You can then iteratively Write Tests 
to Understand (Pattern 6.6) as you Step through the Execution since the 
insights you gain into the states of collaborating objects can then be for- 
mulated as concrete tests. 
As you Step through the Execution, it is a good idea to keep an eye on 
the way collaborating objects use each other's interface. Afterward, you 
can exploit the knowledge you have gained to Look for the Contracts (Pat- 
tern 5.4). 
PATTERN 
Look for the Contracts 
Problem 
Intent: Infer the proper use of a class interface by studying the way clients 
currently use it. 
How do you determine which contracts a class supports? That is, how do 
you know what a class expects from its client classes in order to function as 
intended? 

110 
C H A P T E R 5 Detailed Model Capture 
PATTERN 5.4 continued 
This problem is difficult because 
9 Client/supplier relationships and contracts are only implicit in the code. 
Although interfaces are easy to extract from the code, they do not nec- 
essarily tell you how to use them properly. If not explicitly documented, 
it can be hard to guess (1) the proper sequence in which methods 
should be invoked, (2) the valid parameters that should be supplied, 
(3) which methods should be invoked by which clients, and (4) which 
methods should be overridden by subclasses. 
9 Typing and scoping rules often force programmers to compromise the 
provider's interface. Moreover, encapsulation constructs (e.g., public/ 
private declarations) are frequently misused to cope with implementa- 
tion issues. For instance, database and user interface toolkits often 
require the presence of public accessor methods. 
Yet, solving this problem is feasible because 
9 You have a good understanding of the system's structure (for example, 
obtained via "Initial Understanding," Chapter 4), so you can distinguish 
key classes from less important ones. 
9 You trust that the class is being used properly by its clients and its sub- 
classes. 
Solution 
Look for common programming idioms that expose the way clients make 
use of the class interface. Generalize your observations in the form of con- 
tractsmexplicit declarations of what a class expects from its clients. 
Hints 
Your goal here is to understand how classes collaborate by exposing the 
way in which the interface to a class is used by its different clients. Since an 
exhaustive analysis of the code will probably exhaust you, you need some 
way to expose the contracts without stepping through every single line of 
code. 
Although contracts are only implicit in the code, most frequently there 
will be hints in the code that a particular relationship exists between vari- 
ous classes. These hints may manifest themselves as idioms particular to 
the programming language in use, conventions in use by the development 
team, or even common design patterns. 
What precisely you should look for will depend on the context, but here 
are a few examples that are generally useful: 

P A T T E R N 5.4 Look for the Contracts 
1 1 1 
Use Your Tools. To get an overview of the relationships between classes, 
make the best use you can of the available tools. Although you could ana- 
lyze the code by hand to infer relationships between classes, the process is 
tedious when applied to more than a couple of classes. 
Many organizations use design extraction or round-trip engineering 
tools to document their systems. You can easily generate a draft view of the 
system you are analyzing without investing too much time. However, be 
prepared to be flooded with "boxes and arrows" diagrams containing irrel- 
evant detail. Nevertheless, design extraction tools let you specify filters and 
ways to interpret code, so once your mappings are defined you can reuse 
them over multiple extractions. 
The design overview can help you to identify key classes in the hier- 
archy (i.e., abstract classes that many other classes inherit from), part- 
whole relationships, and so on. 
Look for Key Methods. Focus on the most important methods. With your 
knowledge of the system, you will recognize key methods based on their 
signature: 
9 Method names. Key methods are likely to bear intention-revealing 
names [Beck97]. 
9 Parameter types. Methods taking parameters with types corresponding 
to key classes in the system are likely to be important. 
9 Recurring parameter types. Parameters represent temporary associa- 
tions between objects. When the same parameter types often recur in 
method signatures, they are likely to represent important associations. 
Look for Constructor Calls. To understand how and when to instantiate 
objects of a particular class, look for methods in other classes invoking the 
constructors. 
Pay particular attention to which parameters are passed to the con- 
structor, and whether the parameters are shared or not. This will help you 
determine which instance variables are parts of the constructed object and 
which are merely references to shared objects. 
Invocations of constructor methods may reveal a part-whole relation- 
ship. When a client stores the result of a constructor method in an attri- 
bute, then this client will probably serve as the whole. On the other hand, 
when a client passes itself as an argument to a constructor method, it is 
likely to act as a part. 
Invocations of a constructor method may also expose a Factory Method 
(Pattern A.13) or even an Abstract Factory (Pattern A.10). If they do, then 
you know that you will be able to extend the system by subclassing the 
class under study. 

112 
C H A P T E R 5 Detailed Model Capture 
Trade-offs 
Known 
Uses 
P A T T E R N 5.4 continued 
Look for Template~Hook Methods. To understand how to specialize a class, 
look for (protected) methods that are overridden by subclasses, and iden- 
tify the public methods that call them. The public calling method is almost 
certainly a Template Method (Pattern A.21). Check the class hierarchy to 
determine whether the overridden method is abstract, in which case sub- 
classes must implement it, or whether a default implementation is pro- 
vided. In the latter case, it is a hook method, and subclasses may choose to 
override it or be happy with the default. 
For each template method check all the other methods it invokes, as 
these are likely to represent other hook methods. 
Look for Super Calls. To understand what assumptions a class makes about 
its subclasses, look for super calls. Super calls may be used by subclasses to 
extend an inherited method in an ad hoc way. But very often super calls 
express the fact that a particular method must not be ouerridden by sub- 
classes unless the overridden method is explicitly invoked by a super call. 
This idiom is heavily used in Java by classes that define multiple con- 
structors. Any subclass ofj ava. ]ang. Excepti on, for example, is expected to 
define both a default constructor and a constructor that takes a String 
argument. Those constructors should do nothing in particular except 
invoke the super constructor so that the exception subclass will be cor- 
rectly initialized. 
Pros 
9 Reliable. You can trust the source code more than the documentation. 
Cons 
9 Bad habits linger. Just because certain practices appear in the code 
doesn't mean that's the right way to do things. The contracts that clients 
and subclasses adhere to are not necessarily the ones that the class 
actually supports. 
9 Noisy. Browsing the source code is like mining~once in a while you will 
find a gem, but you will have to dig through a lot of dirt first. By focusing 
your attention on idiomatic usages, you should be able to reduce the 
noise factor to a large degree. 
Many researchers have investigated ways to analyze how clients use a class 
interface. For instance, Brown [Brow96a], Florijn [Flor97], and Wuyts 
[Wuyt98] have all shown that it is possible to find symptoms of design pat- 

PATTERN 5.5 Learn from the Past 
113 
What Next 
terns in code. Also, Schauer et al. [Scha99] report about a technique to 
semiautomatically detect hook methods based on analysis of overridden 
methods. The latter technique scales quite well, due to their particular way 
of visualizing class hierarchies and emphasizing classes where many meth- 
ods are overridden and hence are likely to define hook methods. Addi- 
tionally, Steyaert et al. [Stey96] have shown that it is possible to capture how 
subclasses depend on their superclasses (they have named these depend- 
encies reuse contracts) and afterward detect potential conflicts when the 
superclasses gets changed. 
One way to validate the contracts you have identified is to Step through the 
Execution (Pattern 5.3). Conversely, as you Step through the Execution you 
will uncover collaborations between various objects. At that point you may 
Look for the Contracts that govern those collaborations. 
If the code is hard to read, you may wish to Refactor to Understand (Pat- 
tern 5.2) before you Look for the Contracts. To understand how the con- 
tracts evolved to their current state, you might Learn from the Past (Pattern 
5.5). 
PATTERN 
Learn from the Past 
Problem 
Intent: Obtain insights into the design by comparing subsequent versions 
of the system. 
How can you discover why the system is designed the way it is? How can you 
learn which parts of the system are stable and which parts aren't? 
This problem is difficult because 
The lessons learned during a development process are rarely recorded 
in documentation. Furthermore, the developers' perceptions and mem- 
ory of design decisions tend to warp over time. Therefore, you can only 
rely on source code and must reconstruct the learning process from 
there. 
The system is large and has been released in successive versions, and 
therefore you have a large quantity of source code to analyze. Text com- 
parison tools (such as Unix di ff) will not scale up for the sizes you're 
dealing with. 

114 
C H A P T E R 5 Detailed Model Capture 
Solution 
PATTERN 5.5 continued 
Even if you have a tool to identify the changes between two subsequent 
releases, most of the changes will concern adding new functionality. 
For the reconstruction of the learning process and how this consoli- 
dated into the class design, your main interest lies in what happened 
with the old functionality. 
Yet, solving this problem is feasible because 
9 You have a good understanding of the system's structure (for example, 
obtained via "Initial Understanding," Chapter 4), so you're able to focus 
on appropriate subsystems. 
9 You have access to the subsequent releases of the system, so you can 
reconstruct the changes by comparing the source code of the versions. 
9 You have the means to examine what happened with individual source 
code entities. For instance, you have a metrics tool at your disposal, 
which allows you to quantify the size of entities in the source code and 
use these numbers as a basis for comparison. As an alternative, you 
have a configuration management system that can provide you with 
information about particular changes to source code entities. 
9 You have enough expertise with refactorings in the implementation lan- 
guage being used, so you are able to recognize refactorings from their 
effects on source code. Moreover, once you know which refactorings 
have been applied, you can use this expertise to make an educated 
guess at the underlying design rationale. 
9 You have a source code browser that allows you to query which methods 
invoke a given operation (even for polymorphic operations), so you can 
find out dependencies between classes and investigate how they are 
affected by the refactorings. 
Use the metrics or configuration management tool to find entities where 
functionality has been remoued because such entities are a sign of a con- 
solidating design. Also, look for entities that change often, as these may 
point you to an unstable part of the design. 
Hints 
Your goal is to get a feeling for how and why the system has evolved to its 
current state. In particular, you want to understand which parts of the sys- 
tem have been heavily refactored, which parts have become stable, and 
which parts are hot spots of activity. 

P A T T E R N 5.5 Learn from the Past 
1 15 
Portions of the software system that have been heavily extended are 
simply a sign of growth, not of evolution of the design. On the other hand, 
portions where software has been removed are signs that the design of the 
system has been altered. By understanding how it has been altered, you 
can obtain insights into the stability of the design. 
Unstable design. Ifyou detect repeated growth and refactoring in the same 
portion of the system, that should be a sign that the design is unstable. It 
may indicate opportunities to redesign that portion of the system to better 
accommodate the kinds of changes and extensions that habitually take 
place. 
Mature and stable design. A mature subsystem will exhibit some growth 
and refactoring, followed by a period of stability. Early versions of the sub- 
system will show growth followed by refactoring, followed by a period in 
which only new classes and subclasses are added. As the hierarchy stabi- 
lizes, classes near the top of the hierarchy will exhibit only moderate growth, 
but little refactoring. 
Trade-offs 
Pros 
9 Concentrates on important design artifacts. The changes point you to 
those places where the design is expanding or consolidating, and this in 
turn provides insight into the underlying design rationale. 
9 Provides an unbiased view of the system. You do not have to formulate 
assumptions about what to expect in the software (in contrast to top- 
down techniques like Speculate about Design,Pattern 4.2). 
Cons 
9 Requires considerable experience. The reverse engineer must be well 
aware of how the refactorings interact with the coding idioms in the 
particular implementation language. 
9 Requires considerable tool support. You need (1) a metrics tool or a 
configuration management system and (2) a code browser that is able 
to trace back polymorphic method invocations. 
Difficulties 
Imprecise for many changes. When too many changes have been ap- 
plied on the same piece of code, it becomes difficult to reconstruct the 
change process. 

116 
C H A P T E R 5 Detailed Model Capture 
PATTERN 
5.5 continued 
Sensitive to renaming. If one identifies classes and methods via their 
name, 1 then rename operations will show up as removals and addi- 
tions, which makes interpreting the data more difficult. 
Rationale 
Many object-oriented systems came into being via a combination of itera- 
tive and incremental development (see [Booc94] [Gold95] [Jaco97] [Reen96]). 
That is, the original development team recognized their lack of problem 
domain expertise and therefore invested in a learning process where each 
learning phase resulted in a new system release. It is worthwhile to recon- 
struct that learning process because it will help you to understand the 
rationale embodied in the system design. 
One way to reconstruct the learning process is to recover its primitive 
steps. In object-oriented parlance, these steps are called refactorings, and 
consequently this pattern tells you how to recover refactorings as they 
have been applied in the past. The technique itself compares two subse- 
quent releases of the source code, identifying entities that decrease in size, 
because that's the typical symptom of functionality that has been moved 
elsewhere. 
Known 
Uses 
We ran an experiment on three medium-sized systems implemented in 
Smalltalk. As reported in [Deme00], these case studies suggest that some 
simple heuristics can support the reverse engineering process by focusing 
attention on parts of the system where functionality has been removed. 
This way we could, for instance, detect where a class had been split or 
where methods had been moved to a sibling class. Of course these refac- 
torings must be examined in further detail to guess the intent behind the 
refactoring. This is never easy, but in our experience it has proven worth- 
while. In one particular case, for instance, we discovered several classes 
where methods had been moved to sibling classes. Closer examination 
revealed that the reengineer was moving these methods to break circular 
dependencies and was in fact introducing a layer. 
Other researchers also report on examining changes to support the re- 
verse engineering process. For instance, Ball and Eick annotate code views 
with colors showing code age [Ball96]. On the other hand, ]azayeri et al. use 
a three-dimensional visual representation for examining a system's soft- 
ware release history []aza99]. The same people have also investigated which 
1. Note that some configuration management systems keep track of renaming opera- 
tions, which will of course alleviate the problem. 

P A T T E R N 5.5 Learn from the Past 
117 
change requests affect which software modules to detect logical depend- 
encies between software modules [Gall98]. 
What Next 
Now that you have discovered some stable parts in the design, you will 
probably want to reuse them. In that case take some precautions: first doc- 
ument the interfaces of that part (see Look for the Contracts, Pattern 5.4) 
and then write the corresponding test cases (see Test the Interface, Not the 
Implementation, Pattern 3.1). 
On the other hand, the unstable parts of the design should probably 
be dismissed. Nevertheless, if the unstable part seems crucial for your 
reengineering project, then you must seek which change requests caused 
the instability. In that case, Chat with the Maintainers (Pattern 3.1) or even 
Interview during Demo (Pattern 3.4), and based on this knowledge decide 
how to restructure that part so that it is better suited for the kind of change 
requests that come in. 

CHAPTER 
Tests: Your Life 
Insurance! 
You are at the beginning of a reengineering project. You know that you will 
have to perform radical surgery on many parts of a valuable legacy system. 
You are wondering how you will be able to minimize the risks of changing a 
system on which your business depends: the risk of breaking features that 
used to work, the risk of spending too much effort on the wrong tasks, the 
risk of failing to integrate needed new functionality into the system, and the 
risk of further increasing maintenance costs. 
The patterns presented in this cluster present effective ways of using 
tests in a reengineering context to reduce the risks posed by reengineering 
changes. 
Caveat: Testing is a rich and important subject that can scarcely be cov- 
ered in any depth in the few pages we devote to it in this chapter. We have 
done no more than identify a few of the more significant testing patterns 
that are especially relevant to reengineering projects, and briefly sketch 
out some of the key issues. Binder, for example, devotes an entire book to 
testing object-oriented systems [Bind99]. 
Forces 
These patterns share common forces that concern various elements of risk 
for the evolution of the legacy system. Each pattern addresses some of 
these forces in order to achieve a certain balance between effort and risk. 
Certain forces are inherent to reengineering: 
9 Legacy systems often do not have test procedures defined. 
9 Changing parts of a system without introducing new bugs is a challeng- 
ing task. 
Other forces concern system development: 
121 

122 
C H A P T E R 6 Tests: Your Life Insurance! 
9 
Not every aspect of a system can be tested. 
9 Certain aspects like concurrency and user interfaces are difficult to test. 
9 Under time pressure, writing tests is always the task that is eliminated 
first. 
9 Having all the knowledge of a system concentrated in only a few people 
poses a high risk for the future of the project. 
Customers come into a project with certain expectations: 
9 Customers ultimately do not pay for tests but for new features in the 
system. 
9 An unstable or buggy system is not acceptable for customers. 
Testing is not typically a programmer's prime concern: 
9 Programmers believe they do not need tests, since they write good code. 
9 Programmers are not motivated by long-term goals, since they may 
leave the project a month from now. 
9 Programmers are more interested in tools and processes that can re- 
duce the time they are losing in identifying problems. 
9 Fixing bugs is not fun. 
9 Writing tests is not considered to be a noble task. 
Overview 
As shown in Figure 6.1 on page 120, Write Tests to Enable Evolution (Pat- 
tern 6.1) is the root of this cluster. It explains why systematic tests are criti- 
cal to reengineering projects and what kinds of tests are necessary. It is 
based on Grow Your Test Base Incrementally (Pattern 6.2), which advocates 
strategies for introducing new tests as you need them. 
In order to effectively manage the incremental introduction of tests, it 
is important to Use a Testing Framework (Pattern 6.3) to structure and or- 
ganize suites of tests. The testing framework should support you in design- 
ing certain styles of tests. In particular, if you Test the Interface, Not the 
Implementation (Pattern 6.4) of components, by using black-box testing 
strategies, then your tests will tend to be more useful in the face of system 
changes. Furthermore, if you can Record Business Rules as Tests (Pattern 
6.5), then you will have an effective way to keep the business rules explic- 
itly represented and continuously synchronized with the running system 
even in the presence of radical changes. 
Tests may be introduced at various times for various reasons. Write 
Tests to Understand (Pattern 6.1) advocates investing testing effort in those 

P A T T E R N 6.1 Write Tests to Enable Evolution 
123 
parts of the system that you need to understand in order to implement 
changes. More specifically, it is a good idea to Test Fuzzy Features (Pattern 
A.2), to Test Old Bugs (Pattern A.3), and especially to Retest Persistent 
Problems (Pattern A.1). 
The patterns in this cluster directly support "Migration Strategies" 
(Chapter 7) for reengineering: Regression Test after Every Change (Pattern 
7.6) helps you build confidence by ensuring that everything still runs after 
every incremental change to the system. In effect, tests are a necessary pre- 
condition to Always Have a Running Version (Pattern 7.5), and they enable 
you to Migrate Systems Incrementally (Pattern 7.3). 
PATTERN 
Write Tests to Enable Evolution 
Problem 
Intent: Protect your investment in the legacy code by imposing a system- 
atic testing program. 
How do you minimize the risks of a reengineering project, specifically, the 
risks of 
9 failing to simplify the legacy system 
9 introducing yet more complexity to the system 
9 breaking features that used to work 
9 spending too much effort on the wrong tasks 
9 failing to accommodate future change? 
This problem is difficult because 
9 The impact of changes cannot always be predicted because parts of the 
system may not be well understood or may have hidden dependencies. 
9 Any change to a legacy system may destabilize it due to undocumented 
aspects or dependencies. 
Yet, solving this problem is feasible because 
You have a running system, so you can determine what works and what 
doesn't work. 
You know which parts of the system are stable, and which are subject to 
change. 

124 
C H A P T E R 6 Tests: Your Life Insurance! 
Solution 
P AT T E R N 6.1 continued 
Introduce a testing process based on tests that are automated, repeatable, 
and stored. 
Hints 
Well-designed tests exhibit the following properties: 
9 Automation. Tests should run without human intervention. Only fully 
automated tests offer an efficient way to check after every change to the 
system whether it still works as it did before. By minimizing the effort 
needed to run tests, developers will hesitate less to use them. 
9 Persistence. Tests must be stored to be automatable. Each test docu- 
ments its test data, the actions to perform, and the expected results. A 
test succeeds if the expected result is obtained; otherwise it fails. Stored 
tests document the way the system is expected to work. 
9 Repeatability. Confidence in the system is increased if tests can be 
repeated after any change is implemented. Whenever new function- 
ality is added, new tests can be added to the pool of existing tests, 
thereby increasing the confidence in the system. 
9 Unit testing. Tests should be associated with individual software com- 
ponents so that they identify clearly which part of the system they test 
[Davi95]. 
9 Independence. Each test should minimize its dependencies on other 
tests. Dependent tests typically result in avalanche effects: when one 
test breaks, many others break as well. It is important that the number 
of failures represent quantitatively the size of the detected problems. 
This minimizes distrust in the tests. Programmers should believe in 
tests. 
Trade-offs 
Pros 
9 Tests increase your confidence in the system and improve your ability 
to change the functionality, the design, and even the architecture of the 
system in a behavior-preserving way. 
9 Tests document how artifacts of a system are to be used. In contrast to 
written documentation, running tests are an always up-to-date de- 
scription of the system. 
9 Selling testing to clients who are concerned with security and stability 
is not usually a problem. Assuring the long-term life of the system is 
also a good argument. 

P A T T E R N 6.1 Write Tests to Enable Evolution 
12S 
9 Tests provide the necessary climate for enabling future system evolution. 
9 Simple unit testing frameworks exist for all the main object-oriented 
languages like Smalltalk, Java, C++, and even perl. 
Cons 
Tests do not come free. Resources must be allocated to write them. 
9 Tests can only demonstrate the presence of defects. It is impossible to 
test all the aspects of a legacy system (or any system, for that matter). 
9 Inadequate tests will give you false confidence. You may think your sys- 
tem is working well because all the tests run, but this might not be the 
case at all. 
Difficulties 
9 A plethora of testing approaches exists. Choose a simple approach that 
fits your development process. 
9 Testing legacy systems is difficult because they tend to be large and 
undocumented. Sometimes testing a part of a system requires a large 
and complex set-up procedure, which may seem prohibitive. 
9 Management may be reluctant to invest in testing. Here are some argu- 
ments in favor of testing: 
.~ Testing helps to improve the safety of the system. 
Tests represent a tangible form of confidence in the system func- 
tionality. 
Debugging is easier when automated tests exist. 
Tests are simple documentation that is always in sync with the 
application. 
9 Developers may be reluctant to adopt testing. Build a business case to 
show them that tests will not only speed up today's development, but 
they will speed up future maintenance efforts. Once we talked with a 
developer who spent one day fixing a bug and then three more days 
checking if the changes he made were valid. When we showed him that 
automated tests could help him in his daily work to debug his program 
more quickly, he was finally convinced. 
9 Testing can be boring for developers, so at least use the right tools. For 
unit testing, SUnit and its many variants are simple, free, and available 
for Smalltalk, C++, Java, and other languages [Beck98]. 

126 
C H A P T E R 6 Tests: Your Life Insurance! 
Example 
Rationale 
PATTERN 6.1 continued 
The following code illustrates a unit test written using JUnit in Java 
[Beck98]. The test checks that the add operation defined on a class Money 
works as expected, namely, that 12 + 14 = 26. 
public class MoneyTest extends TestCase { 
//... 
public void testSimpleAdd() { 
Money mI2CHF= new Money(12, "CHF"); 
Money mI4CHF= new Money(14, "CHF"); 
Money expected= new Money(26, "CHF"); 
Money result= mI2CHF.add(mI4CHF) ; 
// (I) 
// (2) 
as sert (resu I t. currency (). equa I s (expected. currency ()) 
&& result.amount() == expected.amount()); 
// (3) 
This satisfies the properties that a test should have: 
9 This test is automated: it returns the boolean value true if the action is 
the right one and false otherwise. 
9 It is stored: it is a method of a test class, so it can be versioned like any 
other code. 
It is repeatable: its initialization part (1) produces the context in which 
the test can be run and rerun indefinitely. 
It is independent of the other tests. 
Using tests with these properties helps you to build a test suite for the long 
term. Every time you write a test, either after a bug fix or after adding a new 
feature, or to test an already existing aspect of the system, you are adding 
reproducible and verifiable information about your system into your test 
suite. Especially in the context of reengineering a system, this fact is im- 
portant because this reproducible and verifiable information can be checked 
after any change to see if aspects of a system are compromised. 
Tests represent confidence in a system because they specify how parts of 
the system work in a verifiable way, and because they can be run at any 
time to check if the system is still consistent. 

P A T T E R N 6.1 Write Tests to Enable Evolution 
127 
Long-term evolution] 
I System documentation I I Architectural evolution I 
,, 
,System confidence I I Turn-over risk minimization II Confidence in change 
Automated tests 
FIGURE 
Automated tests are the foundation of reengineering. They establish your confi- 
dence in the system, reduce risks, and improve confidence in your ability to change 
the system. 
Related 
Patterns 
... testing simply exposes the presence of flaws in a program; it cannot be 
used to verify the absence of flaws. It can increase your confidence that a 
program is correct. 
[Davi95], Principle 111 
Systematic testing is heavily promoted by Extreme Programming [Beck00] 
as one of the basic techniques necessary to be able to adapt programs 
quickly to changing requirements. Changing legacy systems is risky busi- 
ness. Will the code still work after a change? How many unexpected side 
effects will appear? Having a set of automated, repeatable tests helps to 
reduce this risk (see Figure 6.2). 
9 A set of running tests provides confidence in the system. ('~xe you 
really sure this piece of code works? .... Yes. Look, here I have the tests 
that prove it.") 
9 A set of running tests represents reproducible and verifiable informa- 
tion about your system and is at all times in sync with the application. 
This is in contrast to most of the written documentation, which is typi- 
cally slightly outdated already the next day. 
9 Writing tests increases productivity because bugs are found much ear- 
lier in the development process. 
Write Tests to Enable Evolution is a prerequisite to Always Have a Running 
Version (Pattern 7.5). Only with a comprehensive test program in place can 
you Migrate Systems Incrementally (Pattern 7.3). 
Grow Your Test Base Incrementally (Pattern 6.2) and Test the Interface, 
Not the Implementation (Pattern 6.4) introduce a way to incrementally 
build a test suite while a system is evolving. 

128 
C H A P T E R 6 Tests: Your Life Insurance! 
PATTERN 
Problem 
Solution 
Grow Your Test Base Incrementally 
Intent: Balance the costs and the benefits of tests by incrementally intro- 
ducing just the tests you need at a given point in time. 
When should you start to introduce tests? When can you stop? 
This problem is difficult because 
9 In a reengineering project, you cannot afford to spend too much time 
on writing tests. 
9 Legacy systems tend to be huge, so testing everything is impossible. 
9 Legacy systems tend to be poorly documented and poorly understood. 
9 The original developers may have left, and the system maintainers may 
have only limited knowledge of the system's inner workings. 
Yet, solving this problem is feasible because 
9 We know where the fragile parts or the parts that we would like to change 
are. 
9 We can convince programmers that they can benefit from tests. 
Introduce tests incrementally for parts of the system you are working on. 
Hints 
9 Carefully assess your priorities and initially develop tests only for the 
most critical components. As you reengineer the system, introduce 
tests for the new features, parts of the legacy that may be affected, and 
any bugs you identify along the way. 
9 Keep a snapshot of the old system handy so you can later introduce 
tests that should run against both the original system and its new incar- 
nation. 
Focus on business values. Start to write tests for the parts of your sys- 
tem that have the most important artifacts. Try to Record Business 
Rules as Tests (Pattern 6.5). 
If you have the history of bug fixes or problems, apply Test Old Bugs 
(Pattern A.3) as a starting point. 

P A T T E R N 6.2 Grow Your Test Base Incrementally 
129 
Trade-offs 
Example 
9 Ifyou have acceptable documentation and some original developers of 
the system at hand, consider applying Test Fuzzy Features (Pattern A.2). 
9 Apply Test the Interface, Not the Implementation (Pattern 6.4), start to 
test big abstractions, and then refine tests if time allows. For example, if 
you have a pipeline architecture, start to write tests that ensure you that 
the output of the full pipeline is right given the right input. Then write 
tests for the individual pipeline components. 
9 Black-box test parts (subsystems, classes, methods) that are likely to 
change their implementation in the future. 
Pros 
9 You save time by only developing the tests that you need. 
9 You build up a base of the most critical tests as the project progresses. 
9 You build confidence as you go along. 
9 You streamline future development and maintenance activities. 
Cons 
9 You may guess wrong which aspects are critical to test. 
9 Tests can give you false confidence~untested bugs can still lurk in the 
system. 
Difficulties 
Setting up the proper context for the tests may require considerable 
time and effort. 
Identifying the boundaries of the components to test is just hard. 
Deciding which parts to test and how fine-grained these tests should be 
requires a good understanding of the system and the way you intend to 
reengineer it. 
Initially introduce tests only for the subsystems and components you in- 
tend to change. In Figure 6.3 we introduce some tests for subsystem ABC 
and for its component B. We apply Test the Interface, Not the Implementa- 
tion (Pattern 6.4) to ensure that the tests for B should also pass for newB. 
Note that ifwe only introduce tests for component B, then we fail to test 
its integration with A and C. In any case, it may be that we fail to test all im- 
portant aspects, so it is important to incrementally add new tests as bugs 
are detected and repaired. 

130 
C H A P T E R 6 Tests: Your Life Insurance! 
PATTERN 6.2 continued 
FIGURE 
Rationale 
Related 
Patterns 
Introduce tests for the parts of the system you intend to change. 
An incremental testing strategy allows you to start reengineering efforts 
before all the tests are in place. By focusing on just those tests that concern 
the parts of the system you are currently changing, you enable change with 
a minimal investment in testing, while you help your team build confi- 
dence as you grow your test base. 
Use a Testing Framework (Pattern 6.3) to organize your tests. 
Test the Interface, Not the Implementation (Pattern 6.4) provides a 
strategy for developing tests at arbitrary granularities. Record Business 
Rules as Tests (Pattern 6.5) provides another strategy for testing compo- 
nents that implement business logic. Write Tests to Understand (Pattern 
6.6) helps you prime a test base while you are still reverse engineering the 
system. 
PATTERN 
Problem 
Use a Testing Framework 
Intent: Encourage developers to write and use regression tests by provid- 
ing a framework that makes it easy to develop, organize, and run tests. 
How do you encourage your team to adopt systematic testing? 
This problem is difficult because 
9 Tests are boring to write. 
9 Tests may require considerable test data to be built up and torn down. 

P A T T E R N 6.3 Use a Testing Framework 
131 
9 It may be hard to distinguish between test failures and unexpected errors. 
Yet, solving this problem is feasible because 
9 Most tests follow the same basic pattern: create some test data, perform 
some actions, see if the results match your expectations, clean up the 
test data. 
9 Very little infrastructure is needed to run tests and report failures and 
errors. 
Solution 
Trade-offs 
Use a testing framework that allows suites of tests to be composed from 
individual test cases. 
Steps 
Unit testing frameworks, like JUnit and SUnit [Beck98], and various com- 
mercial test harness packages are available for most programming lan- 
guages. If a suitable testing framework is not available for the program- 
ming language you are using, you can easily brew your own according to 
the following principles: 
9 The user must provide test cases that set up test data, exercise them, 
and make assertions about the results. 
9 The testing framework should wrap test cases as tests that can distin- 
guish between assertion failures and unexpected errors. 
9 The framework should provide only minimal feedback if tests succeed. 
Assertion failures should indicate precisely which test failed. Errors 
should result in more detailed feedback (such as a full stack trace). 
9 The framework should allow tests to be composed as test suites. 
Pros 
A testing framework simplifies the formulation of tests and encourages 
programmers to write tests and use them. 
Cons 
Testing requires commitment, discipline, and support. You must con- 
vince your team of the need and benefits of disciplined testing, and you 
must integrate testing into your daily process. One way of supporting 
this discipline is to have one testing coach in your team; consider this 
when you Appoint a Navigator (Pattern 2.2). 

132 
C H A P T E R 6 Tests: Your Life Insurance! 
P AT T E R N 6.3 continued 
A Test can run a 
number of concrete[ 
test cases. 
[ 
TestCase 
abstract 
+ create(String) 
+ assert(boolean) 
+ assertEquals(Object, Object) 
+ fail() 
+ void runBare() ..... 
# void runTest() 
# void setup() 
# void tearDown ( ) 
 name() "String 
<< interface )) 
Test 
+ countTestCasesO "int 
$ 
+ run(TestResult) 
57 
~', 
t 
\ 
\ 
IX 
setUp() ; 
try { 
runTest() 
; 
} 
finally 
{ 
tearDown() ; 
} 
> 
All errors and 
failures are collected I 
into a TestResult. 
| 
A TestSuite bundles 
I 
a set of TestCases 
and TestSuites. 
TestSuite 
+ create() 
+ create(Class) 
+ addTest(Test) 
TestResult 
+ create() 
# void run(TestCase) 
+ addError(Test, Throwable) 
+ addFailure(Test, Throwable) 
+ errors() 9 Enumeration 
+ failures() :Enumeration 
FIGURE 
JUnit is a popular testing framework for Java that offers much more flexibility than 
the minimal scheme described earlier. 
Example 
JUnit is a popular testing framework for Java, which considerably enhances 
the basic scheme described previously. Figure 6.4 shows that the flame- 
work requires users to define their tests as subclasses of TestCase. Users 
must provide the methods setUp (), runTest (), and tearDown (). The default 
implementations of setup() and tearDown() are empty, and the default 
implementation of runXest () looks for and runs a method that is the name 
of the test (given in the constructor). These user-supplied hook methods 
are then called by the runBare () template method. 
JUnit manages the reporting of failures and errors with the help of an 
additional TestResult class. In the design of JUnit, it is an instance of 
TestResul t that actually runs the tests and logs errors or failures. In Figure 
6.5 we see a scenario in which a TestCase, in its run method, passes control 
to an instance of YestResult, which in turn calls the runBare template 
method of the TestCas~ 
TestCase additionally provides a set of different kinds of standard as- 
sertion methods, such as assertEqual s, assertFai l s, and so on. Each of 

P A T T E R N 6.3 Use a Testing Framework 
133 
: TestRunner [ 
run(tr) 
run(tr) 
: TestSuite 
I 
I 
setup() 
runTest() ~ 
tearDown( 
lie 
tc:TestCase ] 
Iv 
1 
run(tc) 
runB are ( ) 
tr: TestResult [ 
Iill 
addFailure() 
D 
FIGURE 
In JUnit, tests are actually run by an instance of TestResult, which invokes the 
runBare template method of a TestCase. The user only needs to provide the setUp() 
and tearDownO methods and the test method to be invoked by runTestO. 
these methods throws an AssertionFailedError, which can be distin- 
guished from any other kind of exception. 
In order to use the framework, we will typically define a new class, say, 
TestHashtabl e, that bundles a set of test suites for a given class, Hashtabl e, 
that we would like to test. The test class should extend j uni t. frame- 
work.TestCase: 
import junit, framework.*; 
import java.util .Hashtable; 
public class TestHashtable extends TestCase { 
The instance variables of the test class will hold the fixture~the actual 
test data: 
private Hashtable boss ; 
private String joe = "Joe"; 
private String mary = "Mary"; 
private String dave = "Dave"; 
private String boris = "Boris"; 

134 
C H A P T E R 6 Tests: Your Life Insurance! 
P AT T E R N 6.3 continued 
There should be a constructor that takes the name of a test case as its 
parameter. Its behavior is defined by its superclass: 
public TestHashtable(String name) { 
super(name); 
} 
The setUp() hook method can be overridden to set up the f'Lxture. If 
there is any cleanup activity to be performed, we should also override 
tearDown (). Their default implementations are empty. 
protected void setUp() { 
boss 
= new Hashtable(); 
} 
We can then define any number of test cases that make use of the fLX- 
ture. Note that each test case is independent and will have a fresh copy of 
the f'Lxture. (In principle, we should design tests that not only exercise the 
entire interface, but the test data should cover both typical and boundary 
cases. The sample tests shown here are far from complete.) 
Each test case should start with the characters "test": 
public void testEmpty() { 
assert (boss . i sEmpty()) ; 
assertEquals(boss .size(), 0); 
assert ( !boss . contains (joe)) ; 
assert ( !boss . contai nsKey(joe)) ; 
} 
public void testBasics() { 
boss .put(joe, mary) ; 
boss .put(mary, dave); 
boss .put(boris, dave); 
assert ( !boss . i sEmpty() ) ; 
assertEquals(boss .size(), 3); 
m 
assert(boss .contains(mary) ); 
assert(!boss .contains(joe)); 
assert (boss .containsKey(mary)) ; 
assert ( !boss . contai nsKey(dave) ) ; 
B 
assertEquals(boss .get(joe), mary); 
assertEquals(boss .get(mary), dave) ; 
m 
assertEquals(boss .get(dave), null); 

P A T T E R N 6.3 Use a Testing Framework 
13*J 
FIGURE 
An instance of java.ui.TestRunner. 
You may provide a static method suite() that will build an instance of 
juni t. framework. TestSui te from the test cases defined by this class: 
public static TestSuite suite() 
{ 
TestSuite suite = new TestSuite() ; 
suite.addTest(new TestHashtable("testBasics")) ; 
suite, addTest (new TestHashtabl e ("testEmpty")) ; 
return suite; 
} 
The test case class should be compiled, together with any class it de- 
pends on. 
To run the tests, we can start up any one of a number of test runner 
classes provided bythe JUnit framework, for instance juni t. ui. TestRunner 
(see Figure 6.6). 
This particular test runner expects you to type in the name of the test 
class. You may then run the tests defined by this class. The test runner will 
look for the suite method and use it to build an instance of TestSui te. If 
you do not provide a static sui te method, the test runner will automati- 
cally build a test suite assuming that all the methods named test* are test 
cases. The test runner then runs the resulting test suite. The interface will 
report how many tests succeeded (see Figure 6.7). A successful test run will 
show a green display. If any individual test fails, the display will be red, and 
details of the test case leading to the failure will be given. 

136 
C H A P T E R 6 Tests: Your Life Insurance! 
PATTERN 
6.3 continued 
FIGURE 
A successful test run. 
Rationale 
Known 
Uses 
A testing framework makes it easier to organize and run tests. 
Hierarchically organizing tests makes it easier to run just the tests that 
concern the part of the system you are working on. 
Testing frameworks exist for a vast number of languages, including Ada, 
ANT, C, C++, Delphi, .Net (all languages), Eiffel, Forte 4GL, GemStone/S, 
Jade, JavaScript, k language (ksql, from kbd), Objective C, Open Road (CA), 
Oracle, perl, Php, PowerBuilder, Python, Reboll~ Ruby, Smalltalk, Visual 
Objects, and Visual Basic. 
Beck and Gamma give a good overview in the context of JUnit [Beck98]. 
PATTERN 
Test the Interface, Not the Implementation 
Also Known As: Black-Box Testing [Pres94] 
Intent: Build up reusable tests that focus on external behavior rather than 
on implementation details and that thereby will survive changes to the sys- 
tem. 

P A T T E R N 6.4 Test the Interface, Not the Implementation 
131 
Problem 
Solution 
Trade-offs 
How can you develop tests that not only protect your software legacy, but 
also will continue to be valuable as the system changes? 
This problem is difficult because 
9 Legacy systems have many features that should continue to function as 
the system evolves. 
9 You cannot afford to spend too much time writing tests while reengi- 
neering the system. 
9 You do not want to waste effort in developing tests that will have to be 
changed as you change the system. 
Yet, solving this problem is feasible because 
The interfaces to the components of the system tell you what should be 
tested. 
Interfaces tend to be more stable than implementations. 
Develop black-box tests that exercise the public interface of your compo- 
nents. 
Hints 
9 Be sure to exercise boundary values (i.e., minimum and maximum val- 
ues for method parameters). The most common errors occur here. 
9 Use a top-down strategy to develop black-box tests if there are many 
fine-grained components that you do not initially have time to develop 
tests for. 
Use a bottom-up strategy if you are replacing functionality in a very 
focused part of the legacy system. 
Pros 
9 Tests that exercise public interfaces are more likely to be reusable if the 
implementation changes. 
9 Black-box tests can often be used to exercise multiple implementations 
of the same interface. 
9 It is relatively easy to develop tests based on a component's interface. 
9 Focusing on the external behavior reduces considerably the possible 
tests to be written while still covering the essential aspects of a system. 

138 
C H A P T E R 6 Tests: Your Life Insurance/ 
Example 
PATTERN 6.4 continued 
Cons 
Back-box tests will not necessarily exercise all possible program paths. 
You may have to use a separate coverage tool to check whether your 
tests cover all the code. 
If the interface to a component changes, you will still have to adapt the 
tests. 
Difficulties 
Sometimes the class does not provide the right interface to support 
black-box testing. Adding accessors to sample the state of the object 
can be a simple solution, but this generally weakens encapsulation and 
makes the object less of a black box. 
Let's look back at the test presented in Write Tests to Enable Evolution (Pat- 
tern 6.1). The code we saw earlier was supposed to check whether the add 
operation defined on a class Money works as expected. However, we see that 
the assert in line (3) actually depends on the internal implementation of the 
Money class because it checks for equality by accessing the two attributes. 
public class MoneyTest extends TestCase { 
//... 
public void testSimpleAdd() { 
Money m12CHF= new Money(12, "CHF"); 
Money mI4CHF= new Money(14, "CHF"); 
Money expected= new Money(26, "CHF"); 
Money result = mI2CHF.add(mI4CHF) ; 
assert (result. currency () . equal s (expected. currency() ) 
&& result.amount() 
:: expected.amount()) ; 
// (I) 
// (2) 
II (3) 
However, if the class Money would override the default equals operation 
defined on Object (doing so would also require overriding hashCode), the 
last assert statement could be simplified and would become independent 
of the internal implementation. 
public class MoneyTest extends TestCase { 
//... 
public void testSimpleAdd() { 

P A T T E R N 6.5 Record Business Rules as Tests 
139 
Money m12CHF = new Money(12, "CHF"); 
Money m14CHF= new Money(14, "CHF"); 
Money expected = new Money(26, "CHF"); 
Money result= m12CHF.add(m14CHF) ; 
assert (expected.equal s (resul t)) ; 
// (1) 
// (2) 
// (3) 
Rationale 
Known 
Uses 
The interface of a component is a direct consequence of its collaborations 
with other components. Black-box tests therefore have a good chance of 
exercising the most important interactions of a system. 
Since interfaces tend to be more stable than implementations, black- 
box tests have a good chance of surviving major changes to the system, and 
they thereby protect your investment in developing tests. 
Black-box testing is a standard testing strategy [Somm96]. 
Related 
Patterns 
Record Business Rules as Tests (Pattern 6.5) adopts a different strategy to 
develop tests that focuses on exercising business rules. This is fine if the 
components to be tested are the ones that implement the business logic. 
For most other components, Test the Interface, Not the Implementation 
will likely be more appropriate. 
Components that implement complex algorithms may not be well 
suited to black-box testing, since an analysis of the interface alone may not 
reveal all the cases that the algorithm should handle. White-box testing 
[Somm96] is another standard technique for testing algorithms in which 
test cases are generated to cover all possible paths through an algorithm. 
PATTERN 
Record Business Rules as Tests 
Problem 
Intent: Keep the system in sync with the business rules it implements by 
encoding the rules explicitly as tests. 
How do you keep the actual business rules, the documentation about those 
business rules, and the system implementation in sync, while all three are 
changing? 

140 
C H A P T E R 6 Tests: Your Life Insurance! 
PATTERN 
6.5 continued 
This problem is difficult because 
9 Written documentation gets out of date quickly and does not ensure 
you that your system really implements the description of the business 
rules you have. 
9 Business rules tend to be implicit in the code. It may not be obvious 
which pieces of software are responsible for computing a given busi- 
ness rule. 
9 Developer turnover introduces a high risk for your business by having 
more and more people knowing less and less about the system. 
9 Most of the time only one programmer or user knows specific rules, and 
that person could be leaving tomorrow. 
9 Business rules are likely to change due to external factors, such as the 
introduction of a new law, so it is important to represent them explicitly. 
Yet, solving this problem is feasible because 
Most business rules are well expressed by sets of canonical examples, 
each of which requires certain well-defined actions to be taken and 
results in some clear, observable results. 
Solution 
Trade-offs 
Write executable tests that record the business rules as test cases, actions, 
and tests over the results. When tests break, you know that things are out of 
sync. 
Hints 
9 Developers and clients can write tests. Developers may write tests asso- 
ciated with specific functionality or a piece of code. Users may also 
have to write integration tests in the form of use cases that bind to- 
gether several unit tests [Davi95] [Beck00]. 
9 Note that you are not interested in the implementation strategies or 
optimization aspects, but only the business rules. 
Pros 
The rules become explicit, thereby reducing dependency on human 
memory. 

P A T T E R N 6.5 Record Business Rules as Tests 
141 
Examples 
You need to record the business rules anyway before you can reengi- 
neer the legacy system. 
Recording business rules as tests enables evolution: when new features 
must be added, you can check that the existing business rules are still 
correctly implemented by running the regression tests. On the other 
hand, when the business rules change, you can update the correspond- 
ing tests to reflect the changes. 
Cons 
Tests can only encode concrete scenarios, not the actual logic of the 
business rules themselves. 
When the business logic must deal with an extremely large number of 
cases, it may be impractical to test them all. 
Difficulties 
9 Recording business rules does not mean extracting them. Extracting 
business rules from code with the current technology is a pipe dream. 
9 Recording business rules can be difficult for a system whose original 
developers and users have all left. 
In this example we compute the amount of additional money an employee 
receives for a child. The rule states that a person or couple gets an amount 
of money for every child he, she, or they raise. Basically parents get 150 
Swiss francs per month for every child younger than 12 years, and 180 
Swiss francs for every child between 12 and 18 and for every child between 
18 and 25 as long as the child is not working and is still in the educational 
system. A single parent gets the full 100% of this money as long as he or she 
is working more than 50%. Couples get a percentage of the money that is 
equal to the summed working percentages of both partners. 
The following Smalltalk code shows a test that hardcodes the expected 
outcomes for the different computations. It allows for automatically check- 
ing the outcomes instead of having to print the outcomes and check by 
hand if they are right, and it acts as a regression test. It also documents the 
expected outcome of the different computations. 
tes tMoneyG i ven ForKi ds 
I singlePerson8OoccupationWi thOneKidOf5 
coup I ePerson4Ooccupat i onWi thOneKi dOf5 
coupl ePerson lO0occupati onWi th2Ksi dOf5 
coupl ePersonWi thOneKi dOfl4 I 

142 
C H A P T E R 6 Tests: Your Life Insurance! 
Rationale 
Related 
Patterns 
PATTERN 6.5 continued 
"cases are extracted from a database after the system has 
performed the computation" 
singlePerson8OWithOneKidOf5 := extract .... 
couplePerson4OoccupationWithOneKidOf5 
:= extract .... 
couplePersonlOOoccupationWithOneKidOf5 := extract .... 
couplePersonWithOneKidOfl4 := extract .... 
"tests" 
"We test that the right amount of money is computed correctly" 
self assert: singlePerson8OoccupationWithOneKidOf5 moneyForKid = 150. 
self assert: couplePerson4OoccupationWithOneKidOf5 moneyForKid = 150"4. 
self assert: couplePersonlOOoccupationWith2KidsOf5 moneyForKid = 150"2. 
self assert: couplePersonWithOneKidOfl4 moneyForKid = 180. 
Tests are a good way to document what the system does. By documenting 
business rules as tests, you guarantee that the description of the business 
rules will be in sync with the implementation. 
The beginning of a reengineering project is a good point in time to set 
up a process to document knowledge about the system as explicit tests. 
While you are reverse engineering a legacy system, you may Write Tests to 
Understand (Pattern 6.6). During this process it will be natural to Record 
Business Rules as Tests. In this way you can prime your test base as you 
Grow Your Test Base Incrementally (Pattern 6.2). 
PATTERN 
Write Tests to Understand 
Problem 
Intent: Record your understanding of a piece of code in the form of execut- 
able tests, thus setting the stage for future changes. 
How do you develop an understanding of a part of a legacy system that 
contains neither tests nor accurate and precise documentation? 
This problem is difficult because 
9 Code is always difficult to understand. 

P A T T E R N 6.6 Write Tests to Understand 
143 
Solution 
Trade-offs 
You would like to make hypotheses about what the code is really doing 
and validate them. 
9 You would like to specify as precisely as possible the behavior of the 
system. 
9 You would like to record your understanding to communicate it, but 
you do not want to waste your time writing documents that will be 
obsolete as soon as you start changing the code. 
Yet, solving this problem is feasible because 
9 The piece of code is relatively small and has clearly defined boundaries. 
9 You have the possibility to specify tests and validate them. 
Encode your hypotheses and conclusions as executable tests. 
Pros 
9 Tests help you to validate your understanding. 
9 Tests can provide a precise specification of certain aspects of the sys- 
tem. Tests cannot be fuzzy. 
9 Tests can be applied to gain different levels of understanding. For ex- 
ample, black-box tests can help you to refine your understanding of 
roles and collaborations, whereas white-box tests can help you to gain 
understanding of the implementation of complex logic. 
9 The tests that you develop will help to enable future reengineering 
efforts. 
Tests will force you to be precise about the creation and use of the ob- 
jects under test. 
Cons 
9 Writing tests is time-consuming. 
Difficulties 
9 Obtaining a well-defined context in which you can test the objects is 
difficult, especially if the objects to be tested do not represent specific 
abstractions. Looking for the places where objects you want to under- 
stand are created can help. 
9 Concurrent systems are known to be difficult to test, so tests can miss 
important aspects (such as handling of race conditions). 

144 
C H A P T E R 6 Tests: Your Life Insurance! 
PATTERN 6.6 continued 
Rationale 
By writing automated tests, you exercise parts of the system you want to 
understand, while recording your understanding and setting the stage for 
future reengineering efforts. 
Related 
Patterns 
Before writing any tests, you might want to Refactor to Understand (Pattern 
5.2). As you write your tests, be sure to Tie Code and Questions (Pattern 5.1). 

CHAPTER 
Migration Strategies 
Your reengineering project is well underway. You have developed a good 
understanding of the legacy system, and you have started to Write Tests to 
Enable Evolution (Pattern 6.1). You have gone through a process of"Setting 
Direction" (Chapter 2) and have decided to tackle the Most Valuable First 
(Pattern 2.4). 
How can you be sure that the new system will be accepted by users? 
How do you migrate to the new system while the old system is being used? 
How can you test and evaluate the new system before it is finished? 
Forces 
The strategies you adopt to migrate from the legacy system to the new so- 
lution must resolve the following forces: 
9 
Big-bang migration carries a high risk of failure. 
9 Introducing too many changes at once may alienate users. 
9 Constant feedback helps you stay on track, although it may be difficult 
and costly to achieve. 
9 Users have to get their work done; they don't want to be distracted by 
incomplete solutions. 
9 Legacy data must survive while the system is being used. 
Overview 
It is not enough to reengineer a legacy system and then deploy it. In fact, if 
you try this, you will surely fail (for the same reasons that big Waterfall pro- 
jects in new territories often fail). You must be prepared to introduce the 
new solution gradually, to gain the confidence and collaboration of the 
147 

148 
C H A P T E R 7 Migration Strategies 
users, and you must adopt a strategy for migrating gradually and painlessly 
from the existing system, while it is still being deployed, to the new system. 
The central message of this cluster is to Migrate Systems Incrementally 
(Pattern 7.3). This is, however, easier said than done. In Figure 7.1 on page 
146 we can see that in order to Migrate Systems Incrementally, we should 
consider a large number of other patterns. Since there exists a vast litera- 
ture on system migration, we do not attempt to cover the topic in great 
detail. We have selected, however, the patterns that we consider to be most 
important for reengineering object-oriented legacy systems, and we have 
summarized the main points. Where appropriate, we point you to further 
sources of information. 
Although the central pattern of this cluster is Migrate Systems Incre- 
mentally, the key motivation is provided by Involve the Users and Build 
Confidence. These first three patterns are fundamental patterns for mini- 
mizing risk and increasing the chances of success: 
9 Involve the Users (Pattern 7.1) increases the chance that users will accept 
the new system by involving them closely in the entire reengineering 
process, getting them to use intermediate results, and providing them 
with strong support. It is easier to achieve if you Migrate Systems Incre- 
mentally and Build Confidence step by step. 
9 Build Confidence (Pattern 7.2) helps you overcome skepticism and 
doubt by regularly delivering results that are of value to the users. 
9 Migrate Systems Incrementally (Pattern 7.3) recommends that the old 
system be gradually and incrementally replaced by the new system. 
New results can then be integrated as you proceed, thus helping you to 
Build Confidence and Involve the Users. 
It is very hard to Migrate Systems Incrementally unless you also adhere 
to the following practices: 
9 Prototype the Target Solution (Pattern 7.4) to test the new architecture 
and new technical risks. It is too easy to be tempted to think you don't 
need a prototype since you already have a running system, but this is 
almost always a mistake. 
9 Always Have a Running Version (Pattern 7.5) helps to keep changes in 
sync by ensuring that they are integrated frequently. 
9 Regression Test after Every Change (Pattern 7.6) helps you to Always 
Have a Running Version by making sure that everything that used to 
run still runs. It presupposes that you Write Tests to Enable Evolution 
(Pattern 6.1). 
Depending on the circumstances, there are various practices that may 
help you to Migrate Systems Incrementally: 

P A T T E R N 7.1 Involve the Users 149 
9 Make a Bridge to the New Town (Pattern 7.7) introduces the metaphor 
of a (data) "bridge" to allow you to gradually migrate data from a legacy 
component to its replacement, while the two run in tandem. When all 
the data have been transferred, the legacy component can be retired. 
9 Present the Right Interface (Pattern 7.8) helps you to develop the target 
system in increments by wrapping the old functionality to export the 
abstractions you really want. 
9 Distinguish Public from Published Interfaces (Pattern 7.9) distinguishes 
between stable (public) and unstable (published) interfaces to facilitate 
parallel development within a reengineering team. 
9 Deprecate Obsolete Interfaces (Pattern 7.10) lets you gracefully retire 
obsolete interfaces without immediately invalidating clients. 
Finally, the following two practices may help you avoid making radical 
but unnecessary changes: 
9 Conserve Familiarity (Pattern 7.11) warns you against introducing radi- 
cal interface changes that may alienate users. 
9 Use Profiler before Optimizing (Pattern 7.12) reminds you to delay con- 
sidering performance issues until you can demonstrate that you have a 
problem and can pinpoint the source of the problem. 
PATTERN 
Involve the Users 
Problem 
Also Known As: Engage Customers [Cop195] 
Intent: Maximize acceptance of changes by involving the users at every step. 
How can you be sure that users will accept the reengineered system? 
This problem is difficult because 
9 The old system works. It is clunky, but the users know how it works and 
know how to get around the problems. 
9 People hate to have to learn something new unless it really makes their 
life simpler. 
9 User perceptions of what is needed to improve a system tend to change 
as the system evolves. 

150 
C H A P T E R 7 Migration Strategies 
Solution 
Trade-offs 
PATTERN 
7.1 continued 
9 Users can have difficulty evaluating a paper design. 
9 It is hard to get excited about a new system that is not ready to use. 
Yet, solving this problem is feasible because 
9 Users will try new solutions if they see that their needs are being seri- 
ously addressed. 
9 Users will give you feedback if you give them something useful to use. 
Get the users directly involved in the new development, and support them 
closely in using the new system. 
Steps 
Get the users to tell you where their priorities lie. Start with Most Valuable 
First (Pattern 2.4). Break the priorities down into small steps that can be 
delivered in regular increments, so you can Build Confidence (Pattern 7.2). 
Create an environment that will encourage contact between users and 
developers. Physical location is important. 
Establish simple procedures for delivering intermediate results on a 
regular basis and obtaining feedback. Early prototypes may help, espe- 
cially to evaluate risky new technologies or approaches. A good strategy is 
to Migrate Systems Incrementally (Pattern 7.3) so that users can start using 
the new system as it is being built. You should Conserve Familiarity (Pat- 
tern 7.11) to avoid alienating users. 
Pros 
9 Requirements will continuously be validated and updated, increasing 
your chances that you will move in the right direction. 
9 If the users feel they are getting useful results and they are being sup- 
ported, they will put extra effort into giving useful feedback. 
9 Users will be involved throughout the effort, eliminating the need for a 
special training session late in the project. 
Cons 
Developers may feel that supporting users is distracting them from the 
job of reengineering the system. 

P A T T E R N 7.2 Build Confidence 
1 Sl 
Rationale 
Related 
Patterns 
If you succeed in involving the users, this will raise expectations and 
put extra pressure on your team. For instance, Yourdon mentions that 
prototypes can really raise expectations too much and that you should 
always make clear which parts are not yet working [Your97]. 
Difficulties 
It can be hard to involve the users initially, before you have shown any 
results. 
You can't involve everybody, and the users who are left out might feel 
neglected. 
You need a feedback loop to ensure that you are addressing the real cus- 
tomer needs. By involving and supporting the users, you encourage this 
feedback loop. 
Coplien points out: "Note that 'maintaining product quality' is not the 
problem being solved here. Product quality is only one component of cus- 
tomer satisfaction" [Cop195]. 
Virtually all of the patterns in this cluster support Involve the Users. Mi- 
grate Systems Incrementally (Pattern 7.3) to get the users working with the 
system as it is being reengineered and thereby Build Confidence (Pattern 
7.2). 
The Planning Game [Beck01] is an effective technique to Involve the 
Users by iteratively identifying stories, estimating costs, and committing to 
the stories to be released. 
PATTERN 
Build Confidence 
Problem 
Intent: Improve your chances of overall success by demonstrating results 
in regular increments. 
How can you overcome the high degree of skepticism that customers and 
team members often have for any kind of software project? 
This problem is difficult because 
Few software projects meet requirements, come in on time, and stay 
within budget. The skepticism that accompanies most projects can eas- 
ily lead to defeatism, and projects can fail as a self-fulfilling prophecy. 

152 
C H A P T E R 7 Migration Strategies 
Solution 
PATTERN 7.2 continued 
9 Users rarely get what they really want or need. 
9 It can be hard to convince the users or even your own team that the leg- 
acy system can really be salvaged. 
Yet, solving this problem is feasible because 
9 You don't need to solve all the problems at once. 
Create a positive atmosphere by demonstrating some tangible results as 
early as you can, and continue to do so on a regular basis. 
Steps 
Pick short intervals for delivering new results. At each step, try to agree to- 
gether with the users what are the smallest results that can demonstrate 
real value. 
Trade-offs 
Pros 
9 Both users and developers can measure real progress. 
9 It is easier to estimate the cost of smaller steps. 
Cons 
9 It takes time to frequently synchronize with the users. 
9 Users may resent the extra work it takes to use the new system in tan- 
dem with the old one. 
If you succeed in demonstrating good results early in the project, you 
may raise expectations too high. 
Difficulties 
9 Some requirements can be hard to break down into small steps, partic- 
ularly if they entail architectural changes to the system. 
9 Reengineering teams must be careful not to alienate the developers of 
the original system, since they are one of the most valuable sources of 
information. 
It is not enough to convince users~you must also take care to get com- 
mitment from management. It is hard to convince management in 
small steps. Plan big demos at regular intervals. 

P A T T E R N 7.3 Migrate Systems Incrementally 
153 
Rationale 
Related 
Patterns 
By taking smaller steps, you reduce the risk that an individual step will fail. 
Frequent, positive results help to build confidence. By the same token, 
Extreme Programming advocates Small Releases [Beck00]. Even negative 
results help you to monitor progress and understand the situation better, 
and so help to build up confidence. 
Prototype the Target Solution (Pattern 7.4) and Make a Bridge to the New 
Town (Pattern 7.7) can make it easier to demonstrate results in small steps. 
It is easier to Build Confidence ifyou Involve the Users (Pattern 7.1). 
PATTERN 
Problem 
Solution 
Migrate Systems Incrementally 
Also Known As: Chicken Little [Brod95] 
Intent: Avoid complexity and risk of big-bang reengineering by deploying 
functionality in frequent increments. 
When should you plan to deploy the new system? 
This problem is difficult because 
9 Projects are often planned and funded on large time scales, with "big 
bang" requirements specified up front. 
9 The real requirements are often only clear in hindsight. Users will resist 
adopting a new system that is radically different from what they are 
used to, especially if it does not work flawlessly from the beginning. 
9 The longer you wait to deploy the new system, the longer you must wait 
to get user feedback. 
9 You cannot deploy an incomplete system. Users do not have time to 
waste on incomplete solutions. 
Yet, solving this problem is feasible because 
9 You have a running system that can be extended and modified. 
Deploy a first update of the legacy system as soon as you can, and migrate 
incrementally to the target system. 

154 
C H A P T E R 7 Migration Strategies 
PATTERN 
7.3 continued 
Steps 
9 Decompose the legacy system into parts. 
9 Choose one part to tackle at a time. 
9 Put tests in place for that part and the parts that depend on it. 
9 Take appropriate steps to wrap, reengineer, or replace the legacy com- 
ponent. 
9 Deploy the updated component and obtain feedback. 
9 Iterate. 
Trade-offs 
Pros 
9 You get user feedback early and Build Confidence (Pattern 7.2). 
9 You see immediately when things break. 
9 Users learn the new system as it's being built. 
9 The system is always deployed. 
9 The system is always being tested, so you can't skip testing. 
Cons 
You will have to work harder to keep the system running while you are 
changing it. 
Difficulties 
It can be difficult to migrate to a new architecture. You may want to Pro- 
totype the Target Solution (Pattern 7.4) to get the new architecture in 
place, and Present the Right Interface (Pattern 7.8) to the old system to 
hide the legacy interfaces while you migrate the underlying compo- 
nents. 
It is risky to change a running system. Be sure to Regression Test after 
Every Change (Pattern 7.6). 
Rationale 
You get the best user feedback from a running system. Users are more mo- 
tivated and involved with a system they use daily. 
Known 
Uses 
Migrating Legacy Systems [Brod95] introduces this pattern under the 
name "Chicken Little" (to migrate incrementally means to "take Chicken 

P A T T E R N 7.4 Prototype the Target Solution 
155 
Related 
Patterns 
Little steps"). This book discusses in great detail strategies and techniques 
for incremental migration. 
Apply Most Valuable First (Pattern 2.4) to select the legacy components to 
work on first. Appoint a Navigator (Pattern 2.2) to maintain architectural 
integrity. 
Write Tests to Enable Evolution (Pattern 6.1), and Grow Your Test Base 
Incrementally (Pattern 6.2) as you migrate. Be sure to Test the Interface, 
Not the Implementation (Pattern 6.4) so you do not always have to rewrite 
your tests as you reengineer or replace legacy components. Regression Test 
after Every Change (Pattern 7.6) so you can Always Have a Running Version 
(Pattern 7.5). 
Consider applying Present the Right Interface (Pattern 7.8) for legacy 
components that you do not intend to reengineer or replace. 
You might consider applying Make a Bridge to the New Town (Pattern 
7.7) if you need to migrate data from legacy components that you are 
replacing. 
PATTERN 
Prototype the Target Solution 
Problem 
Intent: Evaluate the risk of migrating to a new target solution by building a 
prototype. 
How do you know if your ideas for the new target system will work? 
This problem is difficult because 
9 It is risky to make radical changes to a working system. 
9 It can be hard to anticipate how design changes will impact existing 
functionality. 
9 A solution that works is more believable than one that has not been 
tested. 
Yet, solving this problem is feasible because 
You don't need to reengineer the whole legacy system to test the new 
ideas. 

156 
C H A P T E R 7 Migration Strategies 
Solution 
Trade-offs 
PATTERN 7.4 continued 
Develop a prototype of the new concept and evaluate it with respect to the 
new, emerging requirements. 
Steps 
Identify the biggest technical risks for your reengineering project. Typi- 
cally they will concern things like 
choice of a new system architecture 
| 
migration of legacy data to new system 
9 adequate performance--or performance gains--with new technol- 
ogy or platform (for example, demonstrating that a certain trans- 
action throughput can be achieved) 
Decide whether to implement an exploratory (i.e., throwaway) proto- 
type that will serve purely to evaluate the feasibility of a technical op- 
tion, or rather an evolutionary prototype that will eventually evolve into 
the new target system. 
| 
An exploratory prototype must be designed to answer very precise 
questions. These may be purely technical questions, such as 
whether the new platform can meet performance constraints set by 
the legacy system, or they may be usability questions that require 
participation of and evaluation by the users. The exploratory proto- 
type does not need to be designed to address any other issues or 
questions and will not be part of the migrated system (although the 
answers it provides will influence the new system). 
| 
An evolutionary prototype, on the other hand, is intended to even- 
tually replace a legacy component and must therefore reflect the tar- 
get architecture. The new architecture must not only adequately 
support the legacy services, but also overcome the obstacles that 
limit the legacy solutions usefulness. The prototype must be de- 
signed to answer these risks first. 
Pros 
9 A prototype can be built quickly, since it does not have to implement all 
the functionality of the legacy system. 
9 You can hack parts of the legacy system to get your prototype running. 
9 You can learn quickly if your ideas for the target system are sound. 

P A T T E R N 7.5 Always Have a Running Version 
157 
Rationale 
Related 
Patterns 
Cons 
9 Users may not be highly motivated to spend a lot of time evaluating a 
throwaway prototype. 
9 You may be tempted to continue to develop the throwaway prototype. 
Difficulties 
It may be hard to convince yourself or your customer of the need for a 
prototype--after all, you already have a running system. 
It can take too much time to get an evolutionary prototype up to speed. 
Consider applying Present the Right Interface (Pattern 7.8) to legacy 
components to provide a good interface for legacy services to the pro- 
totype. 
A prototype can tell you quickly whether a certain technical approach is 
sound or not. Brooks in The Mythical Man-Month [Broo75] advises us to 
"write one to throw away" since it is hard to get it right the first time. 
Love [Love93] takes this one step further and warns us that for object- 
oriented systems we should "write two to throw away"! Foote and u 
[Foot00] argue that, among other things, Throwaway Code is often the best 
way to clarify domain requirements, but they also warn that a prototype 
risks evolving into a "Big Ball of Mud." 
You might consider applying Make a Bridge to the New Town (Pattern 7.7) 
to migrate legacy data to an evolutionary prototype. 
PATTERN 
Always Have a Running Version 
Problem 
Intent: Increase confidence in changes by regularly rebuilding the system. 
How do you convince your customer that you are on the right path? 
This problem is difficult because 
It can be hard to demo a software system under development, or to dis- 
cuss problems with users since there is often no stable, running version 
of the system available. 

158 
C H A P T E R 7 Migration Strategies 
Solution 
Trade-offs 
PATTERN 7.5 continued 
Integrating changes from multiple versions of a system can be slow and 
painful. 
Yet, solving this problem is feasible because 
You don't have to wait until a component is "finished" before integrat- 
ing it. 
Institute a discipline of integrating new changes and developments on a 
daily basis. 
Steps 
9 Have version management and configuration management systems in 
place. 
9 Make sure you have regression tests in place for the parts you are work- 
ing on. 
9 Institute a discipline of short transactions for checking out system 
components and checking them back in again. Plan iterations to be 
as short as possible to allow changes to be integrated into a running 
system. 
Pros 
9 You always have a working version to demo. 
9 You can always have a working version to run your regression tests. 
9 You can quickly validate your changes, thereby helping you to Build 
Confidence (Pattern 7.2). 
Cons 
9 You must continuously integrate changes. 
Difficulties 
9 Large systems may have very long build times. You may need to re- 
architect the system first to enable shorter build times. 
9 It can be hard to break some kinds of large modifications into meaning- 
ful updates that can be individually integrated. 

P A T T E R N 7.6 Regression Test after Every Change 
159 
Rationale 
Related 
Patterns 
Many practitioners advocate a process of continuous integration as a way 
to avoid a risky and painful big-bang integration [Booc94]. 
Regression Test after Every Change minimizes the risk of defects creeping 
in during integration. 
Continuous Integration [Booc94] [Beck00] is a proven way to Always 
Have a Running Version (Pattern 7.5). 
PATTERN 
Regression Test after Every Change 
Intent: Build confidence by making sure that whatever worked before still 
works. 
Problem 
Solution 
How can you be sure that the last change you made won't break the system? 
This problem is difficult because 
In a complex system, small changes can have unexpected side effects. A 
seemingly innocuous change may break something without this being 
immediately discovered. 
Yet, solving this problem is feasible because 
9 You have written test suites that express how the system should behave. 
Run your regression test suite every time you think you have reached a sta- 
ble state. 
Trade-offs 
Pros 
9 It is easier to Always Have a Running Version (Pattern 7.5). 
9 It is easier to Build Confidence (Pattern 7.2) as you proceed. 
Cons 
9 You must relentlessly write the tests. 

160 
C H A P T E R 7 Migration Strategies 
Rationale 
Related 
Patterns 
PATTERN 7.6 continued 
Difficulties 
9 The legacy system may not have adequate regression tests defined. To 
enable evolution, you will have to Grow Your Test Base Incrementally 
(Pattern 6.2). 
9 Tests can only show that defects are present, not that they are absent. 
You may have failed to test precisely the aspect that you have broken. 
9 Running the tests may be very time-consuming, so you might want to 
run only those tests that you think might be affected by your change. 
Categorize your tests to avoid ad hoc testing of changes, but run all the 
tests at least once a day. 
Regression tests tell you that whatever ran before still runs. If you consis- 
tently build up tests for defects you discover and new features, you will end 
up with a reusable test base that gives you confidence that your changes 
are sound and helps you detect problems earlier. 
Davis advocates, "Regression test after every change" [Davi95] as stan- 
dard software development practice. 
You should have already started to Write Tests to Enable Evolution (Pattern 
6.1). 
A common practice in Extreme Programming is to write tests before you 
implement new functionality [Jeff01]. In the context of reengineering, you 
should consider writing tests that will fail before you make a change and 
will pass if the change is correctly implemented. (Unfortunately it is not 
generally possible to design tests that will only pass if the change is cor- 
rect!) 
Regression tests should help you to Retest Persistent Problems (Pattern 
A.1). 
PATTERN 
Make a Bridge to the New Town 
Also Known As: The Bridge to the New Town [Kell00], Keep the Data~Toss 
the Code [Brod95] 
Intent: Migrate data from a legacy system by running the new system in 
parallel, with a bridge in between. 

P A T T E R N 7.7 Make a Bridge to the New Town 
161 
FIGURE 
New System ] 
l:read() 1 
12:write() 
1
.
~
 
1.2:write( 
2.1:write() 
i Legacy System ~ 
[ DataStore 
I 
A bridge helps you to transparently transfer data to the new system. 
Problem 
Solution 
How do you incrementally migrate data from a legacy system to its replace- 
ment while the two systems are running in tandem? 
This problem is difficult because 
9 Some components of the legacy system are beyond repair and should 
be replaced. 
9 Big-bang replacement of critical components is highly risky. 
9 The data manipulated by the legacy components must be kept avail- 
able and alive during the migration. 
Yet, solving this problem is feasible because 
9 You have a running legacy system. 
Make a (data) bridge that will incrementally transfer data from the legacy 
system to the replacement system as new components are ready to take 
the data over from their legacy counterparts (see Figure 7.2). 
Steps 
Identify legacy and replacement components that deal with the same 
logical data entities. 
Implement a "data bridge" that is responsible for redirecting read re- 
quests from the new component to the legacy data source if the data 
have not already been migrated. The bridge is responsible for any nec- 
essary data conversion. The new component should not be aware of the 
bridge. 

162 
C H A P T E R 7 Migration Strategies 
Trade-offs 
Known 
Uses 
Rationale 
Related 
Patterns 
PATTERN 7.7 continued 
9 Adapt the legacy component to redirect write requests to the new com- 
ponent, so that the new data stay up to date. 
9 When all the data have been transferred, remove the bridge and the leg- 
acy component. 
Pros 
9 You can start using the new system without migrating all the legacy data. 
Cons 
9 A data bridge can be tricky to implement correctly if there is not a sim- 
ple mapping between the legacy data and the new data. 
9 Once some of the data has been transferred, it can be hard to go back. 
9 The data bridge will add a performance overhead that may or may not 
be acceptable. 
Difficulties 
"Stepwise migration schemes have proven very effective in large, lay- 
ered business systems. They are not common in let's say CAD applica- 
tions that have check in/check out persistence and a tightly coupled 
and very woven object net" [Kell00]. 
Brodie and Stonebraker discuss much more thoroughly the use of data 
bridges and gateways in Migrating Legacy Systems [Brod95]. 
Keller in "The Bridge to the New Town" [Kell00] focuses more on the 
technical issue of migrating legacy data, and he points out numerous 
examples of the pattern successfully being applied. 
There are many possible variants of this pattern, depending on whether 
the entire legacy system is to be replaced or only a component, and whether 
users should be able to have access to both systems at the same time or not. 
A bridge between the old and new systems allows you to let users start 
using features of the new system before it is complete. The bridge isolates 
the two systems from each other so that the new system can be developed 
according to a new architectural vision without influence from the legacy 
system. 
A bridge helps you Migrate Systems Incrementally (Pattern 7.3) and there- 
by Build Confidence (Pattern 7.2). 

P A T T E R N 7.8 Present the Right Interface 
163 
PATTERN 
Problem 
Solution 
Trade-offs 
Present the Right Interface 
Also Known As: Semantic Wrapper [OcalO0], Sweeping It under the Rug 
[FootO0] 
Intent: Wrap a legacy system to export the right abstractions, even if they 
are not reflected in the existing implementation. 
How should the new target system access legacy services during the mi- 
gration process? 
This problem is difficult because 
9 The target system is not yet complete so you must rely on legacy ser- 
vices during the migration. 
9 The legacy system does not present the interfaces you need for the tar- 
get system. 
9 Implementing new components directly in terms of legacy compo- 
nents will bias the target toward the legacy architecture and design. 
Yet, solving this problem is feasible because 
9 You don't have to access the legacy services directly. 
Identify the abstractions that you want to have in the new system, and 
wrap up the old software to emulate the new abstractions. 
Hints 
Consider, for example, a procedural graphics library that will be used within 
an object-oriented system. It will be too costly and time-consuming to 
reimplement the library in an object-oriented way. It would be easier to 
wrap it as a utility class (i.e., as a class with static methods but no instances), 
but it would be wiser to write a slightly thicker wrapper that presents a 
truly object-oriented interface but is implemented using the underlying 
procedural abstractions. In this way the new system will not be polluted by 
legacy abstractions. 
Pros 
It is easier to wean the target system from legacy services if they can use 
appropriate abstractions from the start. 

164 
C H A P T E R 7 Migration Strategies 
PATTERN 
7.8 continued 
You reduce the risk that the legacy design will adversely influence the 
new target. 
Cons 
The new interface may not be stable, so developers may be reluctant to 
use it. 
Difficulties 
It can be hard to resist the temptation to simply wrap the procedural 
abstractions as utility classes. 
Known 
Uses 
Alan O'Callaghan [Ocal00] presents this pattern as "Semantic Wrapper" 
briefly in the context of the ADAPTOR pattern language, which addresses 
the migration of large-scale, business-critical legacy systems to object- 
oriented and component-based technology. 
Rationale 
Related 
Patterns 
Present the Right Interface frees you from thinking in terms of the legacy 
design and makes it easier to consider alternative approaches. 
Present the Right Interface superficially resembles an Adapter (Pattern A.11), 
since both use wrappers as their implementation technique. An Adapter, 
however, adapts an incompatible interface to another interface expected 
by its clients. Present the Right Interface, on the other hand, introduces a 
new, more suitable interface to a legacy component. 
Be sure to Deprecate Obsolete Interfaces (Pattern 7.10). 
If the new interface implemented by Present the Right Interface is 
not stable, you should Distinguish Public from Published Interfaces (Pat- 
tern 7.9). 
PATTERN 
Distinguish Public from Published Interfaces 
Also Known As: Published Interface [OcalO0] 
Intent: Facilitate parallel development by distinguishing unstable "pub- 
lished interfaces" from stable "public interfaces." 

P A T T E R N 7.9 Distinguish Publicfrom Published Interfaces 165 
Problem 
Solution 
Trade-offs 
How do you enable migration from legacy interfaces to new target inter- 
faces while the new interfaces are still under development? 
This problem is difficult because 
9 You want to enable migration to the new target system as early as possible. 
9 You do not want to freeze the interfaces of new target components too 
early. 
9 Changing the interface to a component that is widely used will slow 
down development. 
Yet, solving this problem is feasible because 
9 You can control the status of the interfaces you provide. 
Distinguish between public interfaces of components that are available to 
the rest of the system, and unstable "published" interfaces of components 
that are available within a subsystem but are not yet ready for prime time. 
Hints 
Since "published" interfaces are not supported by any programming lan- 
guage, you may have to use naming conventions or abuse other features to 
achieve the desired effect. 
9 In Java, consider declaring such interfaces as protected, or giving them 
package scope (undeclared). When the interfaces stabilize, you may 
redeclare them as being pub] i c. 
9 In C++, consider declaring components with published interfaces pri- 
vate or protected, and declare as fri ends the clients that are permitted 
to use them. When the interfaces stabilize, redeclare the components 
as pub] i c, and delete the declarations of fri ends. 
9 In Smalltalk, consider declaring categories of published components. 
Also consider declaring published message categories to distinguish 
stable and unstable messages. 
9 Consider decorating the names of unstable components or interfaces 
to indicate their "published" status. When the component becomes 
public, rename it and patch all its clients or deprecate the version with 
the old name (Deprecate Obsolete Interfaces, Pattern 7.10). 
Pros 
9 Clients of published interfaces are aware that they are likely to change. 

166 
C H A P T E R 7 Migration Strategies 
PATTERN 7.9 continued 
Cons 
9 Identifying an interface as "published" is purely a matter of convention 
and discipline. 
9 Promoting an interface from published to public entails a certain over- 
head for clients who should upgrade to the new interface. 
Difficulties 
Clients can be put in a bind: should they use an unstable published 
interface, or continue to use the legacy service? 
Known 
Uses 
Published Interface is another pattern of the ADAPTOR pattern language 
lOcal00]. 
Rationale 
Clients are in a better position to evaluate the risk of using a component if 
they know its interface is declared to be "published" but not yet public. 
Related 
Patterns 
When you Present the Right Interface (Pattern 7.8) to a legacy component, 
the new interface may not be stable, so be careful to Distinguish Public 
from Published Interfaces (Pattern 7.9). When the new interface stabilizes, 
or is substituted by a stable replacement component, the interface may 
become public. 
Upgrading an interface to public may entail a change to the way it is ac- 
cessed. Be sure to Deprecate Obsolete Interfaces (Pattern 7.10). 
PATTERN 
Deprecate Obsolete Interfaces 
A/so Known As: Deprecation [Stev98] 
Intent: Give clients time to react to changes to public interfaces by flagging 
obsolete interfaces as "deprecated." 
Problem 
How do you modify an interface without invalidating all the clients? 

P A T T E R N 7.10 Deprecate Obsolete Interfaces 
167 
Solution 
This problem is difficult because 
9 Changing a public interface can break many clients. 
9 Leaving an obsolete interface in place will make future maintenance 
more difficult. 
9 Not all changes are for the better. 
Yet, solving this problem is feasible because 
9 The old and the new interfaces can coexist for a period of time. 
Flag the old interface as being "deprecated," thereby notifying clients that 
it will almost certainly be removed in the next upcoming release. 
Steps 
9 You have determined that a public interface should be changed, but 
you do not want to break all clients. Implement the new interface, but 
"deprecate" the old one. The deprecation mechanism should inform 
clients that the interface has changed and that a newer interface is rec- 
ommended instead. 
9 Evaluate to what extent the deprecated interface continues to be used, 
and whether it can be permanently retired. Consider removing it in a 
future release. 
9 Java supports deprecation as a language feature: Deprecate a feature by 
adding the tag @deprecated to its javadoc documentation. The tag is not 
only recognized by the javadoc documentation generator, but the com- 
piler will also generate compile-time warnings if code using deprecated 
features is compiled with the deprecated option. 
9 Other approaches are the following: 
~ Simply inform users in the documentation which interfaces are 
deprecated. 
~ Move or rename the deprecated interface or component. Clients 
can continue to use them but must adapt and recompile to continue 
to use the deprecated form. 
Replace deprecated components by equivalent ones that generate 
run-time warnings or output warnings to a log file. 
o Alternatively, consider configuring the programming environment 
or the deprecated components themselves to generate compile- 
time or link-time warnings. 

168 
C H A P T E R 7 Migration Strategies 
PATTERN 7.1 0 continued 
Trade-offs 
Pros 
9 Clients do not have to immediately adapt to changes. 
9 There is time to change your mind. 
Cons 
9 Clients are free to ignore deprecation. 
Difficulties 
It may be hard to track down all the clients of a deprecated component. 
It can be hard to decide when to really retire a deprecated component. 
If you want to keep the interface but change the semantics, you may 
need to introduce a new component and deprecate the old one. This 
can be the case if certain methods should now return default values 
instead of throwing exceptions (or vice versa). 
Known 
Uses 
Perdita Stevens and Rob Pooley identify Deprecation as a common prac- 
tice for managing evolving APIs in complex systems [Stev98]. 
Rationale 
Deprecation gives you a window of time to evaluate the impact of a change. 
PATTERN 
Problem 
Conserve Familiarity 
Intent: Avoid radical changes that may alienate users. 
How do you accomplish a major overhaul of a legacy system without dis- 
rupting the way users are used to getting their job done? 
This problem is difficult because 
9 The legacy system requires significant changes. 
9 The users are not happy with the legacy system, but they understand 
it well. 

P A T T E R N 7.12 Use Profiler before Optimizing 
169 
Solution 
Yet, solving this problem is feasible because 
9 You can migrate incrementally to a new solution. 
Introduce only a constant, relatively small number of changes with each 
new release. 
Trade-offs 
Rationale 
Related 
Patterns 
Pros 
9 Users do not have to change their work habits too much between releases. 
Difficulties 
Sometimes radical change is necessary. It can be hard to migrate from a 
command-line interface to a GUI while conserving familiarity. 
Too much change between releases increases the risk of hidden defects 
and decreases the chance of user acceptance. 
Lehman and Belady's law of conservation of familiarity suggests that 
the incremental change between releases of a system stays roughly con- 
stant over time [Lehm85]. This is a relatively natural phenomenon because 
to do anything else introduces unnecessary risks. 
To Conserve Familiarity you must Migrate Systems Incrementally (Pattern 
7.3). Involve the Users (Pattern 7.1) to understand what changes will be 
acceptable. Prototype the Target Solution (Pattern 7.4) to evaluate the po- 
tential impact of changes. 
PATTERN 
Problem 
Use Profiler before Optimizing 
Intent: Avoid squandering reengineering effort on needless "optimiza- 
tions" by verifying where the bottlenecks are. 
When should you rewrite a clearly inefficient piece of code? 
This problem is difficult because 
When you are reengineering software, you are likely to encounter many 
naive algorithms in the legacy code. 

170 
C H A P T E R 7 Migration Strategies 
Solution 
Trade-offs 
Rationale 
Related 
Patterns 
PATTERN 7.1 2 continued 
9 It can be hard to predict what will impact performance, and you can 
lose a lot of time on pure supposition. 
9 Optimized code is often more complex than simple, naive code. 
Yet, solving this problem is feasible because 
9 There are tools to tell you where you may have a performance problem. 
Whenever you are tempted to optimize a "clearly inefficient" part of the 
system, first use a profiler to determine whether it is actually a bottleneck. 
Don't optimize anything unless your profiler tells you it will make a differ- 
ence. Ifyou decide to go ahead, prepare benchmarks that will demonstrate 
the performance gains. 
Pros 
You do not waste time optimizing something that will not make a differ- 
ence to overall performance. 
Cons 
9 Naive algorithms will survive longer in the system. 
The performance improvement that you can gain by optimizing a bit of 
code depends on how much time the program spends in that code in a typ- 
ical run. A profiler will tell you how much time that is. 
"Do it, then do it right, then do it fast" is a well-known aphorism that 
has been credited to many different sources. Very likely its origin is outside 
of the field of computer science. The rationale behind it is that you risk 
making a system complex and hard to maintain if you become preoccu- 
pied with performance issues too early. Instead, it is better to first find a 
solution that works, then clean it up once you understand it. Finally, if you 
can identify any important performance bottlenecks, that is the time to 
optimize just those parts that will make a difference. 
As a corollary, it may even be a good idea to replace a bit of complex, 
"optimized" code by a simpler, "naive" solution, if that won't severely im- 
pact performance but will make it easier to make other changes. 
See also Davis's discussion of"Use Profiler before Optimizing" [Davi95]. 
If you Refactor to Understand (Pattern 5.2), you will have started the sec- 
ond step: "do it right." 

CHAPTER 
Detecting 
Duplicated Code 
Fowler and Beck have ranked duplicated code as the first of the top 10 code 
smells indicating the need to refactor a piece of software [Fowl99]. As they 
like to explain it, whenever you duplicate a piece of code, you are taking 
out a loan, in the sense that you are getting something now (an almost 
ready-made piece of software) that you will have to pay for later. There is 
nothing wrong with taking out a loan, but you have a choice between pay- 
ing back a small amount now (by taking out the time to refactor your code 
to eliminate the duplication) or paying back a lot later (in terms of in- 
creased complexity and maintenance costs). 
Data from empirical studies show that typically between 8% and 12% of 
industrial software consists of duplicated code [Duca99]. Although this 
may not seem like much, in fact it is difficult to achieve very high rates of 
duplication. (Imagine what it would take to have a duplication rate of even 
50%9 Duplication rates of 15% to 20% are therefore considered to be severe. 
Forces 
It is important to identify duplicated code for the following reasons: 
9 Duplicated code hampers the introduction of changes, since every 
implemented variant of a piece of functionality will have to be changed. 
Since it is easy to miss some variants, bugs are likely to pop up in other 
places. 
9 Duplicated code replicates and scatters the logic of a system instead of 
grouping it into identifiable artifacts (classes, methods, packages). It 
leads to systems that are more difficult to understand and to change. 
Instead of just having to understand relationships between logical 
parts, you will first have to identify them and then understand their 
relationships. 
173 

174 
C H A P T E R 8 Detecting Duplicated Code 
Duplicated code arises for a variety of reasons: 
Whenever a programmer is implementing a piece of functionality that 
is remotely similar to something that has been done before, it is natural 
to use the existing code as a model for the new task. If it is a matter of 
recombining existing procedures, the task will be simple. But if the 
behavior is more complex, the easiest thing to do is to copy, paste, and 
modify the old code to achieve the functionality. If both the old and 
new pieces of code belong to different applications, the harm is mini- 
mal. But if they are part of the same system, duplicated code has now 
been introduced. 
Sometimes code is copied, pasted, and modified between different ap- 
plications, or different versions of the same application. When multiple 
versions must be maintained simultaneously, or when different appli- 
cations or versions must be merged, you immediately have a dupli- 
cated code problem. 
From a reengineering perspective, usually people know whether or not 
a system suffers from duplication. First, the development team or the man- 
ager will tell you. Second, there are normally some clear signs that duplica- 
tion has been practiced in a project: for example, two developers cannot 
develop four million lines of code in less than eight months without copy- 
ing and pasting existing code. While analyzing the system you will also 
identify duplicated code by accident. There is a major difference, however, 
between knowing that a system contains duplicated code and knowing 
exactly which parts have been duplicated. 
Overview 
Detecting Duplicated Code consists of two patterns: Compare Code 
Mechanically (Pattern 8.1), which describes how we can detect duplicated 
code, and Visualize Code as Dotplots (Pattern 8.2), which shows how 
duplicated code can be better understood by simple matrix visualization 
(see Figure 8.1 on page 172). 
Once you have detected and understood duplication in the system, you 
may decide on a variety of tactics. Various refactoring patterns, such as 
Extract Method (Pattern A.5), may help you to eliminate the duplication. 
Duplication may be a sign of misplaced responsibilities, in which case you 
may decide to Move Behavior Close to Data (Pattern 9.1). 
Complex conditional statements are also a form of duplication and 
may indicate that multiple clients have to duplicate actions that should 
belong to the target class. The pattern cluster "Transform Conditionals to 
Polymorphism" (Chapter 10) can help to resolve these problems. 

P A T T E R N 8.1 Compare Code Mechanically 175 
PATTERN 
Problem 
Solution 
Compare Code Mechanically 
Intent: Discover duplicated code by comparing all the source code files line 
by line. 
How do you discover which parts of an application code have been dupli- 
cated? 
This problem is difficult because 
9 You may suspect that code has been duplicated but you do not have 
any a priori evidence where the duplication occurs. For example, you 
know that two programmers cannot have developed 4 million lines of 
Cobol in one year without having duplicated some code. 
9 Browsing the code is not an effective way of discovering duplication; 
you will only find duplicated code by accident. 
9 Programmers may have not only copied and pasted code, but also 
modified variables or changed the shape of the programs. 
Yet, solving this problem is feasible because 
9 Most duplicated code can be detected by mechanical procedures. 
Textually compare each line of the software source code with all the other 
lines of code. 
Steps 
9 Normalize the lines of code by removing comments, tabs, and blanks. 
9 Remove lines that contain uninteresting code elements (e.g., just el se 
or }). 
9 Compare each line with all the other lines. Reduce search complexity by 
hashing: (1) preprocessing (compute the hash value for each line), and 
(2) actual comparison (compare all lines in the same hash bucket). 
Variations 
This approach may fail to identify some instances of duplicated code due 
to renaming of variables. By deleting all variable identifiers, or by mapping 
them to a common symbol, you can detect similar code patterns, while 

176 
C H A P T E R 8 Detecting Duplicated Code 
Trade-offs 
Example 
PATTERN 8.1 continued 
abstracting from the details of the specific identifiers. This variant, how- 
ever, requires some syntactic processing of the code. 
Pros 
The approach is simple and gives good results while only requiring mod- 
est resources. 
9 It is nearly language independent in the sense that you only have to 
build a lexical analyzer and not a full parser. That's why a simple perl 
script can be sufficient, depending on the level of sophistication that 
you want. 
9 Simple statistics and percentage rates are easily computed and may 
help you to gain credibility or more strength in discussions on resource 
allocation or hiring new people. 
Cons 
9 Code that has been heavily edited after copying may be hard to identify 
as duplicated code. 
9 Systems containing a lot of duplicated code will generate a lot of data 
that can be difficult to analyze effectively. 
Consider the case of a system written in C++ where you suspect duplicated 
code. However, you didn't write the code yourself so you don't know where 
the actual duplication occurs. How can you detect where the duplicated 
code fragments are? Consistent with Keep It Simple (Pattern 2.7), you do 
the simplest thing that may possibly work: you write a little script that first 
normalizes the code to remove all white space from the code and afterward 
compares each line of code against itself. 
The normalization would change the following code: 
e
e
e
 
// assign same fastid as container 
fastid = NULL; 
const char* fidptr = getFastid(); 
if(fidptr 
l= NULL) { 
int l = strlen(fidptr); 
fastid = new char[l+1]; 
char *tmp = (char*) fastid; 

P A T T E R N 8.1 Compare Code Mechanically 177 
for (int i =O;i<l;i++) 
tmp[i] = fidptr[i]; 
tmp[l] = '\0'; 
into 
9 
9 
9 
fastid=NULL; 
constchar*fi dptr=getFasti d () ; 
i f(fidptr! =NULL) 
i nt I =strl en (fi dptr) ; 
fasti d=newchar [l +1] ; 
char*tmp= (char*) fast i d; 
for(inti=O;i<l ;i++) 
tmp[i] =fidptr[i] ; 
tmp[l]='\O' ; 
Afterward, the line-by-line comparison of the code against itself pro- 
duces a report telling which sequences of lines are duplicated: 
L i nes: fast i d=NULL; ; constchar*fi dptr=get Fast i d () ; ; i f (fi dptr ! =NULL) ; 
i ntl =strl en (fi dptr) ; ; fast i d=newchar [l + 1] ; ; 
Locations: 
</typesys t em/Pars er. C>6178/6179/6180/6181/6182 
</typesystem/Parser. C>6198/6199/6200/6201/6202 
Here is a sample of a perl script that will do the trick: 
#! /usr/bin/env perl -w 
# duplocForCPP.pl - detect duplicated lines of code (algorithm only) 
# Synopsis: duplocForCPP.pl filenome ... 
# Takes code (or other) files end collects all line numbers of lines 
# equal to each other within these files. The algorithm is linear (in 
# space and time) to the number of lines in input. 
# Output: Lists of numbers of equaZ lines. 
# Author: Matthias Rieger 
$equi val enceCl assMi nimal Size 
$slidingWindowSize 
$removeKeywords 
=I; 
=5; 
= O; 

178 
C H A P T E R 8 Detecting Duplicated Code 
PATTERN 8.1 continued 
@keywords = qw(if 
then 
else 
for 
{ 
} 
); 
$keywordsRegExp = join ' I ', @keywords; 
@unwantedlines = qw( else 
return 
return; 
return result; 
}else{ 
#else 
#endi f 
{ 
} 
}; 
); 
push @unwantedLines, @keywords; 
@unwantedlines{@unwantedlines} = (1) x @unwantedLines; 
Stotal Lines 
= O; 
$emptyLi nes 
= O; 
$codeLi nes 
= 0; 
@currentLines 
= (); 
@currentLineNos = (); 
~eqLines 
= (); 
$i nComment 
= O; 
$start = (times)[O] ; 
while (<>) { 
chomp; 
$totaILines++; 

P A T T E R N 8.1 Compare Code Mechanically 
119 
# remove comments of type /* */ 
my $codeOnly : "; 
while(($inComment && ml\*/l) II (I$inComment && ml/\*l)) { 
unless($inComment) { $codeOnly .= $" } 
$i nComment = ! $i nComment; 
$ =$'; 
} 
$codeOnly .= $ 
unless $inComment; 
$ 
= $codeOnly; 
slll.*$11; 
sl\s+//g; 
s/$keywordsRegExp//og if $removeKeywords; 
#remove comments of type // 
#remove white space 
#remove keywords 
# remove empty and unwanted Z ines 
if((!$ 
&& $emptyLines++) 
II (defined $unwantedLines{$_} && $codeLines++)) { next } 
$codeLi nes++; 
push @currentLines, $ ; 
n 
push @currentLineNos, $.; 
if($slidingWindowSize < @currentLines) { 
shift @currentLines; 
shift @currentLineNos; 
} 
# print STDERR "Line StotalLines >$ <~n"; 
my $1ineToBeCompared = join ", @currentLines; 
my $1ineNumbersCompared = "<$ARGV>"; # append the name of the file 
$1ineNumbersCompared .= join '/', @currentLineNos; 
# print STDERR "$ZineNumbersCompared~n"; 
if($bucketRef = $eqLines{$1ineToBeCompared}) { 
push @$bucketRef, $I ineNumbersCompared; 
} else { 
$eqLines{$1 ineToBeCompared} = [ $I ineNumbersCompared ] ; 
} 
if(eof) { close ARGV } # Reset linenumber-count for next file 
Send : (times) [O] ; 
$processingTime = Send - $start; 

180 
C H A P T E R 8 Detecting Duplicated Code 
Known 
Uses 
PATTERN 8.1 continued 
# print the equivalence classes 
$numOfMarkedEquivCl asses = O; 
$numOfMarkedEl ements = O; 
foreach $1ine (sort { length $a <=> length $b } keys ~eqLines) { 
if(scalar @{$eqLines{$1ine}} > $equivalenceClassMinimalSize) { 
$n umOfMa rked Equi vC 1 as ses ++; 
$numOfMarkedElements += scalar @{$eqLines{$1ine}}; 
print "Lines: $1ine\n"; 
print "Locations: @{$eqLines{$1ine}}\n\n"; 
} 
print "\n\n\n" ; 
print "Number of Lines processed: $totalLines\n"; 
print "Number of Empty Lines: 
$emptyLines\n"; 
print "Number of Code Lines: 
$codeLines\n"; 
print "Scanning time in seconds: $processingTime\n"; 
print "Lines per second: 
@{ [$total Lines/$processingTime] }\n"; 
print " 
\n"; 
print "Total Number of equivalence classes: @{[scalar keys ~eqLines]}\n"; 
print "Size of Sliding window: 
$slidingWindowSize\n"; 
print "Lower bound of eqiv-class Size: $equivalenceClassMinimalSize\n"; 
print "Number of marked equivalence classes: $numOfMarkedEquivClasses\n"; 
print "Number of marked elements: $numOfMarkedElements\n"; 
In the context of software reengineering, the pattern has been applied to 
detect duplicated code in FAMOOS case studies containing up to 1 million 
lines of C++. It also has been applied to detect duplicated code in a COBOL 
system of 4 million lines of code. DATRIX has investigated multiple ver- 
sions of a large telecommunications system, wading through 89 million 
lines of code in all [Lagu97]. 
PATTERN 
Visualize Code as Dotplots 
Intent: Gain insight into the nature of the duplication by studying the pat- 
terns in the dotplots. 

P A T T E R N 8.2 Visualize Code as Dotplots 
181 
Problem 
Solution 
How can you gain insight into the scope and nature of code duplication in 
a software system? 
This problem is difficult because 
Just knowing where in the system duplicated code exists does not nec- 
essarily help you to understand its nature or what should be done 
about it. 
Yet, solving this problem is feasible because 
9 A picture is worth a thousand words. 
Visualize the code as a matrix in which the two axes represent two source 
code files (possibly the same file), and dots in the matrix occur where 
source code lines are duplicated. 
Steps 
If you want to analyze two files A and B: 
9 Normalize the contents of the two files to eliminate noise (white space, 
etc.). 
9 Let each axis of the matrix represent elements (e.g., the lines of code) of 
the normalized files. 
9 Represent a match between two elements as a dot in the matrix. 
9 Interpret the obtained pictures: a diagonal represents duplicated code 
between the two files. 
To analyze the duplication inside a single file, plot the elements of that 
file on both axes. 
Interpretations 
The interpretation of the obtained matrices are illustrated in Figure 8.2. 
Some interesting configurations formed by the dots in the matrices are the 
following: 
9 Exact copies: Diagonals of dots indicate copied sequences of source code. 
9 Copies with variations: Sequences that have holes in them indicate 
that a portion of a copied sequences has been changed. 
9 Inserts~deletes: Broken sequences with parts shifted to the right or left 
indicate that a portion of code has been inserted or deleted. 

182 
C H A P T E R 8 Detecting Duplicated Code 
PATTERN 8.2 continued 
FIGURE 
Possible sequences of dots and their associated interpretations. 
Repetitiue code elements: Rectangular configurations indicate periodic 
occurrences of the same code. An example is the break at the end of the 
individual cases of a C or C ++ switch statement, or recurring prepro- 
cessor commands like #i fdef SOME CONDITION. 
Trade-offs 
Pros 
9 The approach is largely language independent, since only the code nor- 
malization depends on the language syntax. 
9 The approach works well when reverse engineering large amounts of 
unknown code because the dotplots attract your eye to certain parts of 
the code to be studied more closely. 
9 The idea is simple yet works surprisingly well. A simple version of the 
approach can be implemented by a good programmer using appropri- 
ate tools in a couple of days. (One of our better students made a small 
dotplot browser in Delphi in two days.) 
Cons 
Dotplots only present pair~se comparisons. They do not necessarily 
help you identify all instances of duplicated elements in the entire soft- 
ware system. Although the approach can easily be extended to present 
multiple files across each axis, the comparisons are still only pair~se. 
Difficulties 
A naive implementation of a dotplot visualizer may not scale well to 
large systems. Tuning and optimizing the approach for large data sets 
can compromise the simplicity of the approach. 

P A T T E R N 8.2 Visualize Code as Dotplots 
183 
FIGURE 
Code duplication before and after refactoring. 
9 The interpretation of the data may be more subtle than it appears at 
first glance. Indeed, while comparing multiple files, the diagonals rep- 
resent more duplication than is really in the system because we are 
comparing duplicated fragments with themselves over different files, 
as shown by Figures 8.3 and 8.4. 
9 The screen size limits the amount of information that can be visualized. 
Some success has been achieved with so-called mural visualization ap- 
proaches [Jerd96]. However, these techniques are significantly more 
difficult to implement than simple dotplots and are not worth the extra 
effort. 
Example In Figure 8.3 we see a dotplot of two versions of a piece of software, before 
and after the duplication has been removed. The first version is compared 
to itself in the top-left square. The line down the diagonal simply shows us 
that every line of code is being compared to itself. What is more interesting 
is that several other diagonal lines occur in the dotplot, which means that 
code has been duplicated within this file. A second version of the same file 
is compared to itself in the lower-right square. Here we see no significant 
duplication aside from the main diagonal, which reflects the fact that all 
the duplicated code has been successfully refactored. 

184 
C H A P T E R 8 Detecting Duplicated Code 
PATTERN 
8.2 continued 
A 
~176176176176176176176 
. 
... 
".. 
"'..~176 
eo 
''".ii.ii..i~ii . *".o.~176 
....... ".... 
""., 9 
e'~176 
......... 
m,. 
..... 
:":",. 
9 
"'e ~176176176176176176 
9 , 
~...... 
9 
. .  
.~ 
9 . 
~ ~ 
. 
~ 
""....... 
\ 
FIGURE 
Python file A being compared to itself and to a second file B. 
The bottom-left and top-right squares are mirror images of each other. 
They tell us how the before and after files have been reorganized. Since 
there is no strong diagonal, this tells us that significant reorganization has 
taken place. The diagonal stripes show us which parts of the old version 
have survived and where they appear in the new version. From the dotplot 
alone, we can guess that about half of the code has survived, and another 
half of the code has been significantly rewritten. 
Dotplots are also useful to detect duplication across multiple files. Fig- 
ure 8.4 shows a dotplot comparing two Python files. The comparison of A 
versus A shows that there is essentially no internal duplication. Very likely 
there are some switch statements in the bottom half of the file, indicated 
by the matrix pattern. 
When we compare file A to file B, however, we detect a staggering amount 
of duplication. It looks very much like file B is just a copy of file A that has 
been extended in various ways. Closer investigation showed this to be the 
case. In fact, file A was just an older version of file B that had inadvertently 
been left in the release. 
Dotplots can also be useful to detect other problems. Figure 8.5 pres- 
ents four clones that represent a switch statement over a type variable that 
is used to call individual construction code. The duplicated code could 
perhaps be eliminated by applying "Transform Conditionals to Polymor- 
phism" (Chapter 10). 
Known 
Uses 
The pattern has been applied in biological research to detect DNA se- 
quences [Pust82]. The Dotplot tool [Helf95] has been used to detect simi- 

P A T T E R N 8.2 Visualize Code as Dotplots 
185 
FIGURE 
Dotplots produced by four switch statements. 
larities in manual pages, literary texts, and names from file systems. In the 
FAMOOS project, the pattern has been applied to build Duploc, a tool for 
identifying duplication in software source code [Duca99]. The Dup tool 
[Bake92] has been used to investigate the source code of the X-Window 
system and uses a dotplot matrix graphical representation. 
Related 
Patterns 
Once you have detected duplicated code, numerous refactoring patterns 
may apply, in particular Extract Method (Pattern A.5). 
Very often duplicated code arises because clients assume too many re- 
sponsibilities. In that case, Move Behavior Close to Data (Pattern (9.1) will 
help you to eliminate the duplication. 
Dotplots also help to detect large conditional constructs. You should 
probably Transform "Conditionals to Polymorphism" (Chapter 10) to elimi- 
nate these conditionals and thereby achieve a more flexible design. 

CHAPTER 
Redistribute 
Responsibilities 
You are responsible for reengineering the information system that man- 
ages all employee records for a large branch of the public administration. 
Due to recent political upheavals, you know that there will be many 
changes required in the system to cope with privatization, new laws, and 
new regulations, but you do not know exactly what they will be. The exist- 
ing system consists of a nominally object-oriented reimplementation of an 
older procedural system. The code contains many pseudo-objects" data 
containers masquerading as objects and big procedural "god classes" that 
implement most of the logic of individual subsystems. One class, called 
TaxRevi s i on2000, has a single method consisting essentially of a case state- 
ment that is 3000 lines long. 
As long as the system was relatively stable, this design posed no partic- 
ular problems, but now you see that even relatively modest changes to the 
system require months of planning, testing, and debugging due to weak 
encapsulation of data. You are convinced that migrating to a more object- 
oriented design will make the system more robust and easier to adapt to 
future requirements. But how do you know where the problems lie? Which 
responsibilities should be redistributed? Which data containers should 
you redesign, which ones should you wrap, and which ones are better left 
alone? 
Forces 
As usual, there is a set of conflicting forces to be resolved. 
Data containers (objects that just provide access to data, but have no 
behavior of their own) are a simple and convenient way to share infor- 
mation between many subsystems. Among others, data containers are 
the easiest way to provide access to database entities. 
187 

188 
C H A P T E R 9 Redistribute Responsibilities 
9 
However, data containers expose the data representation and hence are 
difficult to change when many application components depend on 
them. Consequently, a proliferation of data containers leads to fragile 
navigation code in the implementation of business logic. 
9 It is hard to teach an old dog new tricks. Many designers received train- 
ing in functional decomposition and will fall into old habits when doing 
an object design. 
9 However, functional decomposition tends to generate god classes~big 
classes that do all of the work and have a myriad of tiny provider classes 
around them. God classes are hard to extend, modify, or subclass be- 
cause such changes affect large numbers of other methods or instance 
variables. 
Overview 
This cluster deals with problems of misplaced responsibilities. The two 
extreme cases are data containers (classes that are nothing but glorified 
data structures and have almost no identifiable responsibilities) and god 
classes (procedural monsters that assume too many responsibilities). 
Although there are sometimes borderlines cases where data containers 
and god classes may be tolerated, particularly if they are buried in a stable 
part of the system that will not change, generally they are a sign of a fragile 
design. 
Data containers lead to violations of the law ofDemeter (LOD) [Lieb88]. 
In a nutshell, the law of Demeter provides a number of design guidelines to 
reduce coupling between distantly related classes. Although the law of 
Demeter has various forms, depending on whether one focuses on objects 
or classes, and depending on which programming language is being used, 
the law essentially states that methods should only send messages to 
instance variables, method arguments, self, super, and the receiver class. 
Violations of the law of Demeter typically take the form of navigation 
code in which an indirect client accesses an indirect provider by accessing 
either an instance variable or an acquaintance of an intermediate provider. 
The indirect client and provider are thereby unnecessarily coupled, mak- 
ing future enhancements more difficult to realize (Figure 9.2). The inter- 
mediate provider may take the form of a data container or may open its 
encapsulation by providing accessor methods. Designs with many data 
containers present suffer from complex navigation code in which indirect 
clients may have to navigate through a chain of intermediates to reach the 
indirect provider. 
Whereas data containers have too few responsibilities, god classes 
assume too many. A god class can be a single class that implements an 
entire subsystem, consisting of thousands of lines of code and hundreds of 

Overview 
1159 
Indirect 
provider 
doSomething( ) 
provider 
Intermediate 
provider 
+provider 
getProvider() 
intermediate 
/ 
/ 
/ 
/ 
/ 
/ 
Indirect 
client 
f 
/ 
/ 
/ 
i ntermedi ate. provider, doSomethi ng () 
1 
or 
intermediate getProvi der() .doSomethi ng ( 
FIGURE 
An indirect client violates the law of Demeter by navigating through an intermediate 
provider to an indirect provider, unnecessarily coupling the two. 
methods and instance variables. Particularly vicious god classes consist of 
only static instance variables and methods; that is, all data and behavior 
have class scope, and the god class is never instantiated. Such god classes 
are purely procedural beasts and are object-oriented in name only. 
Occasionally some procedural classes known as utility classes are con- 
venient. The best-known examples are object-oriented interfaces to math 
libraries or collections of algorithms. Real god classes, however, are not 
libraries but complete applications or subsystems that control the entire 
application execution. 
God classes and data containers often occur together, with the god 
class assuming all the control of the application and treating other classes 
as glorified data structures. Since they assume too many responsibilities, 
god classes are hard to understand and maintain. Incremental modifica- 
tion and extension of a god class through inheritance is next to impossible 
due to the complexity of its interface and the absence of a clear subclassing 
contract. 
Figure 9.1 on page 186 provides a number of patterns to eliminate data 
containers and god classes by redistributing responsibilities and thereby 
improving encapsulation: 
9 Move Behavior Close to Data (Pattern 9.1) moves behavior defined in 
indirect clients to an intermediate data container to make it more 
"objectlike." This pattern not only decouples indirect clients from the 
contents of the data container, but also typically eliminates duplicated 
code occurring in multiple clients of the data container. 
9 Eliminate Navigation Code (Pattern 9.2) is technically very similar to 
Move Behavior Close to Data (Pattern 9.1) in terms of the reengineering 
steps, but is rather different in its intent. This pattern focuses on redis- 
tributing responsibilities down chains of data containers to eliminate 
navigation code. 

190 
C H A P T E R 9 Redistribute Responsibilities 
Split Up God Class (Pattern 9.3) refactors a procedural god class into a 
number of simple, more cohesive classes by moving all data to external 
data containers, applying Move Behavior Close to Data (Pattern 9.1)to 
promote the data containers to objects, and finally removing or depre- 
cating the facade that remains. 
PATTERN 
Move Behavior Close to Data 
Problem 
Solution 
Intent: Strengthen encapsulation by moving behavior from indirect clients 
to the class containing the data it operates on. 
How do you transform a class from being a mere data container into a real 
service provider? 
This problem is difficult because 
9 Data containers offer only accessor methods or public instance vari- 
ables, and not real behavior, forcing clients to define the behavior 
themselves instead of just using it. New clients typically have to re- 
implement this behavior. 
9 If the internal representation of a data container changes, many clients 
have to be updated. 
9 Data containers cannot be used polymorphically since they define no 
behavior and their interfaces consist mainly of accessor methods. As a 
consequence, clients will be responsible for deciding which behavior is 
called for in any given context. 
Yet, solving this problem is feasible because 
9 You know what operations clients perform with the data. 
Move behavior defined by indirect clients to the container of the data on 
which it operates. 
Detection 
Look for the following: 
Data containers~classes defining mostly public accessor methods and 
few behavior methods (e.g., the number of methods is approximately 
two times larger than the number of attributes). 

P A T T E R N 9.1 Move Behavior Close to Data 
191 
FIGURE 
Provider 
+x: Value 
+y: Value 
+getx():Value 
+setxWalue) 
+gety():Value 
+sety(Value) 
! c,,ont I 1 ,n ,rectc,,en   
I op2() ,, 
ofx andy 
\ 
\ 
\ 
"0" 
y~ 
provider.sety(provider.x + provider. 
.
.
o
 
Provider 
-x: Value 
-y: Value 
-sety(Value) 
+bump()\ 
\ 
X 
% 
provider.sety(provider.x + provider.y) ~ 
Client ! .... 
op2()~ 
\ 
\ 
\ 
Direct client 
of Provider 
provider.bump( 
Classes that were mere data containers are transformed into real service providers. 
9 Duplicated client code that manipulates data of separate provider 
classes. If multiple clients implement different behavior, consider in- 
stead applying Transform Client Type Checks (Pattern 10.2). 
9 Methods in client classes that invoke a sequence of accessor methods 
(see Eliminate Navigation Code, Pattern 9.2). 
Steps 
Move Behavior Close to Data makes use of the refactorings Extract Method 
(Pattern A.5) and Move Method (Pattern A.6), since the behavior in ques- 
tion will have to be extracted from a client method and then moved to a 
provider class (see Figure 9.3). 
1. Identify the client behavior that you want to move, that is, the complete 
method or a part of a method that accesses provider data. 
~ Look for the invocations of the accessor methods of the data con- 
tainer. 
Look for duplicated code in multiple clients that access the same 
provider data. 

192 
C H A P T E R 9 Redistribute Responsibilities 
PATTERN 9.1 continued 
2. Create the corresponding method in the provider class, if it does not 
already exist. Be sure to check that moving the code will not introduce 
any naming conflicts. Tools like the Refactoring Browser [Robe97] auto- 
mate these steps: 
Q If the extracted functionality is a complete method with arguments, 
check that the arguments do not conflict with attributes of the pro- 
vider class. If so, rename the arguments. 
If the extracted functionality uses temporary variables, check that 
the local variables do not conflict with attributes or variables in the 
target scope. If so, rename the temporary variables. 
Check if the extracted functionality accesses local variables of the 
client classes (attributes, temporary variables, etc.). If so, add argu- 
ments to the method to represent these client variables. 
3. Give an intention-revealing name to the new method. Among others, 
intention revealing names do not contain references to the class they 
belong to because this makes the method less reusable. For instance, 
instead of defining a method addToSet () on a class Set, it is better to 
name it simply add (). Similarly, it is not such a good idea to define a 
method binarySearch() on a class Array because the method name 
implies a sorted random access collection, while the name search() 
does not have such implications. 
4. In the client, invoke the new provider method with the correct parame- 
ters. 
5. Clean up the client code. In the case that the moved functionality was a 
complete method of the client class: 
| 
check all the methods that invoke the old, moved method and en- 
sure that they now call the new provider method instead, and 
| 
remove the old method from the client or deprecate it (Deprecate 
Obsolete Interfaces, Pattern 7.10). 
It may be the case that the calling methods defined on the same object 
also have to be moved to the provider. In such a case, repeat the steps 
for the methods. 
6. Repeat for multiple clients. Note that duplicated code in multiple cli- 
ents will be removed in step 2, since there is no need to move code that 
has already been transferred to the provider. If many similar but not 
identical methods are introduced to the provider, consider factoring 
out the duplicated fragments as protected helper methods. 

P A T T E R N 9.1 Move Behavior Close to Data 
193 
Trade-offs 
Pros 
9 Data containers are converted to service providers with clear responsi- 
bilities. 
9 The service providers become more useful to other clients. 
9 Clients are no longer responsible for implementing provider behavior. 
9 Clients are less sensitive to internal changes of the provider. 
9 Code duplication in the system decreases. 
Cons 
If the moved behavior also accesses client data, turning these accesses 
into parameters will make the interface of the provider more complex 
and introduce explicit dependencies from the provider to the client. 
Difficulties 
9 It may not be clear whether client code really should be moved to the 
data provider. Some classes like Stream or Set are really designed as data 
providers. Consider moving the code to the provider if 
the functionality represents a responsibility of the provider. For ex- 
ample, a class Set should provide mathematical operations like 
union and intersection. On the other hand, a generic Set should not 
be responsible for operations on sets of Emp] oyees. 
~:~ the functionality accesses the attributes of the provider. 
~ the functionality is defined by multiple clients. 
9 If the provider is really designed as a data container, consider defining a 
new provider class that wraps an instance of the data provider and 
holds the associated behavior. For example, an Emp ] oyeeSet might wrap 
a Set instance and provide a more suitable interface. 
When the Legacy Solution Is the Solution 
Data containers may have been automatically generated from a database 
schema to provide an object interface to an existing database. It is almost 
always a bad idea to modify generated classes, since you will lose your 
changes if the code ever needs to be regenerated. In this case, you may 
decide to implement wrapper classes to hold the behavior that should be 
associated with the generated classes. Such a wrapper would function as 
an Adapter (Pattern A.11) that converts the generated data container to a 
real service provider. 

194 
C H A P T E R 9 Redistribute Responsibilities 
PATTERN 9.1 continued 
Sometimes you know that a class defined in a library is missing crucial 
functionality~for example, an operation convertToCapi tal s is missing for 
class String. In such a case it is typically impossible to add code to the 
library, so you may have to define it in the client class. In C++, for example, 
it may be the only way to avoid recompilation or to extend a class when the 
code is not available [Alpe98, p. 378]. In Smalltalk you have the possibility 
of extending or modifying the library; however, you should pay particular 
attention to separate the additional code so you can easily merge it with 
future releases of the library and quickly detect any conflicts. 
The Visitor pattern is one of the few cases where you want to have 
classes access the data of a separate provider class. Visitor allows you to 
dynamically add new operations to a set of stable classes without having to 
change them, as shown by the pattern intent (Pattern A.22): 
Represent an operation to be performed on the elements of an object struc- 
ture in a class separate from the elements themselves. Visitor lets you de- 
fine a new operation without changing the classes of the elements on which 
it operates. [Gamm95] 
Configuration classes are classes that represent the configuration of a 
system (e.g., global parameters, language-dependent representation, poli- 
cies in place). For example, in a graphic tool the default size of the boxes, 
edges, and widths of the lines can be stored in such a class, and other 
classes refer to it when needed. 
Mapping classes are classes used to represent mappings between ob- 
jects and their user interface or database representation. For example, a 
software metric tool should graphically represent the available metrics in 
a widget list so that the user can select the metrics to be computed. In such 
a case the graphical representation of the different metrics will certainly 
differ from their internal representation. A mapping class keeps track of 
the association. 
Example One of the recurring complaints of customers is that it takes too much time 
to change the reports generated by the information system. By talking to 
the maintainers you learn that they find generating the reports quite bor- 
ing. "It's always the same code you have to write," says Chris, one of the 
maintainers. "You fetch a record out of the database, print its fields, and 
then proceed to the next record." 
You strongly suspect a case of data containers, and a closer examina- 
tion of the code confirms your suspicion. Almost all of the classes interfac- 
ing with the database contain accessor methods only, and the programs 
generating reports are forced to use these accessors. One striking example 

P A T T E R N 9.1 Move Behavior Close to Data 
195 
FIGURE 
Employee 
+telephoneNrs 
+name()" String 
+address()" String 
Payroll 
+printEmployeeLabel() 1 
\ 
\ 
\ 
\ 
\ 
\ 
\ 
\ 
Accesses employee data 
e~ 
and contains duplicated cod 
/ 
TelephoneGuide 
[ / 
+printEmployeeTelephones ( ) 
/ 
/ 
/ 
/ 
The Payrol 1 and Tel ephone classes access the internal representation of the class 
Employee to print a representation. 
is the case of the Payrol 1 application, which has lots in common with the 
Tel ephoneGui de application. You decide to try to move the common func- 
tionality to the Empl oyee class. 
Before 
As shown in Figure 9.4, both the Payroll and Tel ephoneGui de classes print 
labels, treating Empl oyee instances as data containers. Thus, Payrol ] and 
Tel ephoneGui de are indirect clients of the attributes of Employee and define 
printing code that should have been provided by the Empl oyee class. The 
following code shows how this would look in lava: 
public class Employee { 
public String[] telephoneNumbers = {}; 
,,~ 
public String name() { 
return 
name;} 
public String address() { 
return 
address;} 
B 
public class Payroll { 
public static Employee currentEmployee; 

196 
C H A P T E R 9 Redistribute Responsibilities 
PATTERN 
9.1 continued 
} 
public static void printEmployeeLabel () { 
System. out. pri ntl n (currentEmpl oyee. name ()) ; 
System. out. print I n (current Emp I oyee. address ()) ; 
for (int i=O; i < currentEmployee.telephoneNumbers.length; i++) { 
System. out. print (current Emp I oyee. tel ephoneNumbers [ i ] ) ; 
System.out.print( .... ) ;} 
System.out.println( .... );} 
public class Tel ephoneGui de { 
public static void printEmployeeTelephones (Employee emp) { 
System.out.println(emp.name()) ; 
System.out.println(emp.address()) ; 
for (int i=O; i < emp.telephoneNumbers.length- 1; i++) { 
Sys tem. out. p r i n t (emp. t e I ephoneNumbe rs [ i ] ) ; 
System.out.print("--") ;} 
System. out. print (emp. te I ephoneNumbers [ 
emp.telephoneNumbers.length - 1]); 
System.out.println( .... );} 
Note that although both print methods implement essentially the same 
functionality, there are some slight differences. Among others, Tel ephone- 
Gui de. pri ntEmpl oyeeTel ephones uses a different separator while printing 
out the telephone numbers. 
Steps 
The different separators can easily be dealt with by defining a special 
parameter representing the separator to be used. Thus Tel ephoneGui de. 
pri ntEmp] oyeeTe] ephones gets rewritten as follows: 
public static void printEmployeeTelephones 
(Employee emp, String separator) { 
e 
9 
9 
for (int i:O; ... 
System. out. pri nt (seperator) ; } 
9 9 o} 

P A T T E R N 9.1 Move Behavior Close to Data 
197 
Next, move the pri ntEmpl oyeeTel ephones method from Tel ephoneGuide to 
Empl oyee. Thus, copy the code and replace all references to the emp parame- 
ter with a direct reference to the attributes and methods. Also, ensure that 
the new method has an intention-revealing name and omit the "Employee" 
part from the method name, resulting in a method pri ntLabel. 
public class Employee { 
public void printLabel (String separator) { 
System.out.println(name) ; 
System.out.println(address) ; 
for (int i=O; i < telephoneNumbers.length- 1; i++) { 
System. out. pri nt (te I ephoneNumbers [ i ] ) ; 
System.out.print(separator) ; 
} 
System.out.print (telephoneNumbers[telephoneNumbers. length - 1] ) ; 
System.out.println( .... ); 
Then replace the method bodies of Payroll .printEmployeeLabel and 
Te 1 ephoneGui de. pri ntEmpl oyeeTel ephones with a simple invocation of the 
Employee. pri ntLabel method: 
public class Payroll { 
e 
e 
e 
public static void printEmployeeLabel 
() { 
currentEmployee.printLabel (" ") ; 
9 9 o} 
public class Tel ephoneGui de { 
9 9 9 
public static void printEmployeeTelephones (Employee emp) { 
emp.pri ntLabel ("--") ;} 
e o 
o} 
Finally, verify which other methods refer to the name (), address (), and 
tel ephoneNumbers. If no such methods exist, consider declaring those 
methods and attributes as pri rate. 
After 
After applying Move Behavior Close to Data, the class Employee now pro- 
vides a printLabe] method that takes one argument to represent the dif- 

198 
C H A P T E R 9 Redistribute Responsibilities 
FIGURE 
PATTERN 
9.1 continued 
-name():String 
I \ 
-address(): String ',[ 
\ 
+printLabel (String) ~\\\\ ~ 
\ 
\ 
\ 
Intemal representation ~ 
of Employee is hidden. 
Payroll 
+printEmployeeLabel( ) 
\ 
\ 
\ 
\ 
\ 
\ 
\ 
Invoke external service 
of Employee (printLabel). I 
/ 
/ 
t' 
TelephoneGuide 
+printEmployeeTelephones ( ) 
/ 
/ 
/ 
The Payrol 1 class uses the public interface of the class Employee to print a repre- 
sentation of Employee; data accessors became private. 
ferent separators (see Figure 9.5). This is a better situation because now 
clients do not rely on the internal representation of Emp]oyee. Moreover, by 
moving the behavior near the data it operates, the class represents a con- 
ceptual entity with an emphasis on the services it provides instead of 
structure it implements. 
Rationale 
Keep related data and behavior in one place. 
[Rie196], Heuristic 2.9 
Data containers impede evolution because they expose structure and force 
clients to define their behavior rather than sharing it. By promoting data 
containers to service providers, you reduce coupling between classes and 
improve cohesion of data and behavior. 
Related 
Patterns 
Encapsulate Field (Pattern A.4) offers heuristics that help determine where 
methods should be defined during a design phase. The text offers a ratio- 
nale for applying Move Behavior Close to Data. 

P A T T E R N 9.2 Eliminate Navigation Code 
199 
PATTERN 
Eliminate Navigation Code 
Also Known As: Law of Demeter [Lieb88] 
Intent: Reduce the impact of changes by shifting responsibility down a 
chain of connected classes. 
Problem 
Solution 
How do you reduce coupling due to classes that navigate through the ob- 
ject graph? 
This problem is difficult because 
Changes in the interfaces of a class will affect not only direct clients, but 
also all the indirect clients that navigate to reach it. 
Yet, solving this problem is feasible because 
Navigation code is typically a sign of misplaced responsibilities and 
violation of encapsulation. 
Iteratively move behavior defined by an indirect client to the container of 
the data on which it operates. 
Note that the actual reengineering steps are basically the same as those 
of Move Behavior Close to Data (Pattern 9.1), but the manifestation of the 
problem is rather different, so different detection steps apply. 
Detection 
Look for indirect providers: 
9 Each time a class changes, for example, by modifying its internal repre- 
sentation or collaborators, not only its direct but also its indirect client 
classes have to be changed. 
9 Look for classes that contain a lot public attributes, accessor methods, 
or methods returning as value attributes of the class. 
9 Big aggregation hierarchies containing mostly data classes often play 
the role of indirect provider. 
Look for indirect clients that contain a lot of navigation code. Navigation 
code is of two kinds: 

200 
C H A P T E R 9 Redistribute Responsibilities 
PATTERN 9.2 continued 
A sequence of attribute accesses, for example, a. b. c. d, where b is an at- 
tribute of a, c is an attribute of b, and d an attribute of c. The result of 
such a sequence can be assigned to a variable, or a method of the last 
object can be invoked, for example, a.b.c.d.op(). Such a sequence 
navigation does not occur in Smalltalk, where all the attributes are pro- 
tected. 
A sequence of accessor method calls. In Java and C++ such a sequence 
has the form object.ml().m2().m3(), where object is an expression 
returning an object, ml is a method of the object, m2 a method of the 
object returned by the invocation of ml, m3 a method of the object 
returned by the invocation of m2, and so on. In Smalltalk, navigation 
code has the following form: receiver ml m2... mn The same navigation 
code sequence is repeated in different methods on the same or differ- 
ent clients. 
Navigation code can be detected by simple pattern matching. However, 
to really detect a method call navigation sequence leading to coupled 
classes, you should filter out sequences of calls converting one object to 
another one. For example, the following two Java expressions are not prob- 
lematic because they deal with object conversion: 
I eftSi de (). toStri ng () 
i.getValue().isShort() 
To deal with this case you can 
look for more than two calls, or 
eliminate from consideration known object conversion calls, including 
standard method invocations for converting to and from primitive 
types. 
The use of additional variables can sometimes disguise navigation code, so 
reading the code is often necessary. For instance, the following Java code 
does not contain a chain of invocations: 
Token token; 
token : parseTree, token () ; 
if (token.identifier() ! = null) { 
However, it is equivalent to the following code, which does contain a chain 
of invocations: 

P A T T E R N 9.2 Eliminate Navigation Code 201 
if (parseTree.token().identifier() 
!: null) 
{ 
Smalltalk. Simply searching for sequences of calls in Smalltalk code can 
create a lot of noise because Smalltalk does not have predefined control 
structures but uses messages even for implementing control structures. 
The previous example with the disguised navigation code would read as 
follows in Smalltalk (note the messages i sNil and i fFal se: [... ]): 
I token I 
token "= parseTree token. 
token identifier 
isNil ifFalse.[...] 
The equivalent version with navigation code becomes 
parseTree token identifier 
isNil ifFalse. 
[...] 
The following code segments contain a sequence of invocations but do 
not pose any problems because the first deals with boolean testing and the 
second with conversion (abuse of conversion, in fact)" 
(a i sNode) & (a i sAbstract) i fTrue" [...] 
aCol asSet asSortedCollection asOrderedCollection 
lava. For Java or C++, primitive data types and control structures are not 
implemented using objects, so simple pattern-matching produces less 
noise. For example, a simple Unix command like 
egrep '.*\(\).*\(\).*\(\).' 
*.java 
egrep '.*\..*\..*\..' 
*.java 
identifies lines of code like the following ones, which are examples of navi- 
gation code coupling between classes, and filters out the conversions 
mentioned earlier: 
a. getAbstracti on (). getl denti fi er(). traverse (thi s) 
a. abstract i on. i dent i fi er. traverse (th i s ) 
More sophisticated matching expressions can reduce the noise pro- 
duced by the parentheses of casts or other combinations. 
AST Matching. If you have a way to express tree matching, you can detect 
navigation code. For example, the Rewrite Rule Editor that comes with the 
Refactoring Browser [Robe97] can detect navigation code using the pattern 
'0object 'messl 'mess2 'mess3. To narrow the analysis of the results, you 

202 
C H A P T E R 9 Redistribute Responsibilities 
Trade-offs 
PATTERN 9.2 continued 
should only consider messages that belong to the domain objects and elimi- 
nate all the method selectors of libraries objects like (isNi 1, not, class, 
etc.). 
Steps 
The recipe for eliminating navigation code is to recursively Move Behavior 
Close to Data (Pattern 9.1). Figure 9.6 illustrates the transformation. 
1. Identify the navigation code to move. 
2. Apply Move Behavior Close to Data (Pattern 9.1) to remove one level of 
navigation. (At this point your regression tests should run.) 
3. Repeat if necessary. 
Caution: It is important to note that the refactoring process relies on push- 
ing code from the clients to the prouiders~in the example, from Car to 
Engi ne and from Engi ne to Carburetor. A common mistake is to tryto elimi- 
nate navigation code by defining accessors at the client class level that 
access the attributes of the provider attribute values, for example, defining 
an accessor getCarburetor in the class Car. Instead of reducing coupling 
between the classes, it just increases the number of public accessors and 
makes the system more complex. 
Pros 
9 Chains of dependencies between classes are eliminated, so changes in 
classes at the lowest level will impact fewer clients. 
9 Functionality that was implicit in the system is now named and ex- 
plicitly available to new clients. 
Cons 
The systematic application of Eliminate Navigation Code may lead to 
large interfaces. In particular, if a class defines many instance variables 
that are collections, then Eliminate Navigation Code would force you to 
define a large number of additional methods to shield the underlying 
collections. 

P A T T E R N 9.2 Eliminate Navigation Code 203 
FIGURE 
Carburetor 
+fuelValveOpen: Boolean 
Carburetor 
+fuelValveOpen: Boolean- 
. 
Engine 
Car 
+carburetor: Carburetor 
engine 
+increaseSpeed() 
/ 
/ 
/ 
/ 
engine.carburetor.fuelValveOpen = true 
carburetor.fuelValveOpen = true; 
Enone 
I 
-carburetor: Carburetor 
-engine 
+speedUp() \ 
+increaseSpeed() 
X 
/ 
X 
/ 
X 
1 
/ 
\ 
9 
engine.speedUp( 
Carburetor 
fuelValveOpen: Boolean 
+openFuelValve()x 
\ 
\ 
fuelValveOpen = true; 
Engine 
~ 
Car 
carburetor: Carburetor 
-engine 
+speedUp() \ 
+increaseSpeed l) 
\ 
\ 
/ 
\ 
/ 
carburetor, openFuel Valve () 
~ 
/ 
I 
I 
..o 
engine.speedUp( 
Chains of data containers can be converted into service providers, thereby eliminat- 
ing navigation code and reducing coupling between classes. 

204 
C H A P T E R 9 Redistribute Responsibilities 
Example 
PATTERN 9.2 continued 
Difficulties 
Deciding when to apply Eliminate Navigation Code can be difficult. De- 
fining methods that merely delegate requests to class collaborators 
may not always be the solution. It may happen that giving away inter- 
nal information can reduce the interface of a class. For example, if a 
class implements some well-defined behaviors but also serves as a 
Facade (Pattern A.12) to other collaborators, it may be simpler to give 
access to the collaborator directly to reduce the interface of the class. 
When the Legacy Solution Is the Solution 
Navigation code may be the best solution when objects are graphically 
presented or mapped to a database. In such cases the goal really is to ex- 
pose and mimic the structural relationships between classes. Eliminating 
navigation code will be a futile exercise. 
It is sometimes necessary for a client to talk with its indirect providers. 
This is true when direct providers play the role of an object seruer that 
returns certain objects given certain properties (OOID, keys, etc.). In this 
situation the client calls the object server (a direct provider) that returns 
objects (indirect providers) to which the client sends messages. 
After having modified the Employee, Payroll, and Tel ephoneGui de classes, 
you noticed that it took half an hour to rebuild the whole project. The next 
time you see Chris (one of the maintainers) you ask him why this build 
took so long. "You probably changed the Empl oyee class" he answers. "We 
don't dare touch that class anymore since so many classes depend on it." 
You decide to examine this Emp] oyee class in further detail and find 
many unnecessary dependencies. For instance (as shown in Figure 9.7), 
there is a class Reports, implementing one method countHandledFiles, 
which counts for each Department the number of files that are handled by 
all of its employees. Unfortunately, there is no direct relationship between 
Department and Fi 1 e, and consequently the Repo rtHandl edFi 1 e s must nav- 
igate over a department's empl oyees to enumerate all the f i 1 es and access 
the handled() status. 
The following Java code shows the situation before and after applying 
Eliminate Navigation Code. The bold textual elements highlight problems 
and the solutions in the before and after situations. 

P A T T E R N 9.2 Eliminate Navigation Code 20S 
File 
description( ) 
filelD() 
handled() 
Employee 
+files 
Department 
+employees 
Reports 
currentDepartment 
countHandledFiles() 
/ 
/ 
/ 
/ 
/ 
/ 
int nrHandled = O, nrUnhandled = O; 
for (int i=O; i < department.employees.length; i++) { 
for (int j=O; j < department.employees[i].files.length; 
j++) { 
if (department.employees[i] .files[j] .handled()) { 
nrHandled++; } 
else { 
nrUnhandled++; } } } 
File 
description() 
fileID() 
handled() 
/ 
/ 
/ 
/ 
/ 
/ 
/ 
/ 
/ 
/ 
/ 
I 
/ 
/ 
/ 
/ 
/ 
/ 
Employee 
-files 
countHandledFiles() 
I 
I 
I 
I 
I 
I 
I 
I 
Department 
-employees 
countHandledFiles() 
I 
I 
I 
/ 
/ 
i 
Reports 
currentDepartment 
countHandledFiles() 
/ 
department.countHandledFiles( 
nrHandled, nrUnhandled); 
for (int i=O; i < this.employees.length; 
i++) { 
thi s.employees[i] .countHandledFi les (nrHandled, nrUnhandled) H 
for (int j=O; j < this.files.length; 
j++) { 
if (this.files[j].handled()) 
{ 
nrHandl ed. increment () ; } 
else { 
nrUnhandled.increment() ;}} 
FIGURE 
How to remove the unnecessary dependencies between the Reports class and the 
Fi 1 e and Emp 1 oyee classes. 

206 
C H A P T E R 9 Redistribute Responsibilities 
PATTERN 9.2 continued 
Before 
public class Reports { 
*
*
*
 
public static void countHandledFiles(Department department) { 
int nrHandled = O, nrUnhandled = O; 
...} 
for (int i=O; i < department.employees.length; i++) { 
for (int j=O; j < department.employees[i].files.length; j++) { 
if (department.employees[i] .files[j] .handled()) { 
nrHandl ed++; } 
else { 
nrUnhandl ed++; } } } 
The method countHandledFi l es counts the number of handled files, by 
asking the current department for its employees and for each of these the 
files. The classes Department and Employee have to declare those attri- 
butes public. With this implementation, two problems occur: 
1. The Reports class must know how to enumerate the associations be- 
tween Department, Employee, and File, and this information must be 
accessible in the public interface of each of the classes. If one of these 
public interfaces changes, then this change will affect all associated 
classes. 
2. The method countHandledFi l es is implemented by directly accessing 
the variables empl oyees and f i 1 es. This unnecessarily couples the class 
Reports and the classes Department and Employee. If the class Depart- 
ment or Empl oyee changes the data structure used to hold the associated 
objects, then all the methods in class Reports will have to be adapted. 
Steps 
The solution is to extract the nested for loops as separate methods and 
move them to the appropriate classes. This is actually a two-step process. 
First, extract the outer for loop from Reports.countHandledFi ]es as a 
separate method (name it countHandledFi l es as well) and move it to the 
class Department: 
public class Department { 

P A T T E R N 9.2 Eliminate Navigation Code 207 
public void countHandledFiles 
(Counter nrHandled, Counter nrUnhandled) { 
for (int i=O; i < this.employees.length; i++) { 
for (int j=O; j < this.employees[i].files.length; j++) { 
if (this.employees[i].files[j].handled()) { 
nrHandl ed. increment () ; } 
else { 
nrUnhandled.increment();}}}} 
...} 
public class Reports { 
private static void countHandledFiles(Department department) { 
Counter nrHandled = new Counter (0), nrUnhandled = new Counter (0); 
...} 
department, countHandl edFi I es (nrHandl ed, nrUnhandl ed) ; 
Next, extract the inner for loop from Department. countHandl edFi 1 es 
(also named countHandl edFi les) and move it to the class Employee. 
public class Employee { 
o.o 
public void countHandledFiles 
(Counter nrHandled, Counter nrUnhandled) { 
for (int j--O; j < this.files.length; j++) { 
if (this.files[j].handled()) { 
nrHandled.increment() ;} 
else { 
nrUnhandled.increment();}}} 
...} 
public class Department { 
o
o
o
 
public void countHandledFiles 
(Counter nrHandled, Counter nrUnhandled) { 
for (int i=O; i < this.employees.length; i++) { 
thi s .employees [i ]. countHandl edFi I es (nrHandl ed, nrUnhandl ed) ; } } 
000} 
If all direct accesses to the employees and files variables are removed, 
these attributes can be declared private. 

208 
C H A P T E R 9 Redistribute Responsibilities 
Rationale 
Related 
Patterns 
PATTERN 9.2 continued 
A method "M" of an object "O" should invoke only the methods of the fol- 
lowing kinds of objects. 
1. itself 
2. its parameters 
3. any object it creates/instantiates 
4. its direct component objects 
mLaw of Demeter 
Navigation code is a well-known symptom of misplaced behavior [Lore94] 
[Shar97] [Rie196] that violates the law of Demeter [Lieb88]. It leads to un- 
necessary dependencies between classes, and as a consequence changing 
the representation of a class requires all clients to be adapted. 
Eliminate Navigation Code and Compare Code Mechanically (Pattern 8.1) 
reinforce each other: navigation code that is spread across different clients 
spreads duplicated code over the system. Compare Code Mechanically 
(Pattern 8.1) helps to detect this phenomenon. Eliminate Navigation 
Code brings the duplicated code together, where it is easier to refactor and 
eliminate. 
PATTERN 
Split Up God Class 
Also Known As: The Blob [Brow98], God Class [Rie196] 
Intent: Split up a class with too many responsibilities into a number of 
smaller, cohesive classes. 
Problem 
How do you maintain a class that assumes too many responsibilities? 
This problem is difficult because 
By assuming too many responsibilities, a god class monopolizes con- 
trol of an application. Evolution of the application is difficult because 
nearly every change touches this class and affects multiple responsi- 
bilities. 

PATTERN 9.3 Split Up God Class 
209 
Solution 
9 It is difficult to understand the different abstractions that are inter- 
mixed in a god class. Most of the data of the multiple abstractions is 
accessed from different places. 
9 Identifying where to change a feature without impacting the other func- 
tionality or other objects in the system is difficult. Moreover, changes in 
other objects are likely to impact the god class, thus hampering the evo- 
lution of the system. 
9 It is nearly impossible to change a part of the behavior of a god class in a 
black-box way. 
Yet, solving this problem is feasible because 
9 You don't have to fix the problem in one shot. 
9 You can use Semantic Wrapper to wrap it and present interfaces. 
Incrementally redistribute the responsibilities of the god class either to its 
collaborating classes or to new classes that are pulled out of the god class. 
When there is nothing left of the god class but a facade, remove or depre- 
cate the facade. 
Detection 
A god class may be recognized in various ways: 
9 A single huge class treats many other classes as data structures. 
9 A "root" class or other huge class has a name containing words like 
"System," "Subsystem," "Manager, .... Driver," or "Controller." 
9 Changes to the system always result in changes to the same class. 
9 Changes to the class are extremely difficult because you cannot identify 
which parts of the class they affect. 
9 Reusing the class is nearly impossible because it covers too many 
design concerns. 
9 The class is a domain class holding the majority of attributes and meth- 
ods of a system or subsystem. (Note that the threshold is not absolute 
because some UI frameworks produce big classes with lots of methods, 
and some database interface classes may need a lot of attributes.) 
9 The class has an unrelated set of methods working on separated in- 
stance variables. The cohesiveness of the class is usually low. 
9 The class requires long compile times, even for small modifications. 

210 
C H A P T E R 9 Redistribute Responsibilities 
PATTERN 
9.3 continued 
9 The class is difficult to test due to the many responsibilities it assumes. 
9 The class uses a lot of memory. 
9 People tell you: "This is the heart of the system." 
9 When you ask for the responsibility of a god class, you get various, long, 
and unclear answers. 
God classes are the nightmare of maintainers, so ask what classes are 
huge and difficult to maintain. Ask what is the class they would not like 
to work on. (Variant: Ask people to choose which class they want to 
work on. The one that everybody avoids may be a god class.) 
Steps 
The solution relies on incrementally moving behavior away from the god 
class. During this process, data containers will become more objectlike by 
acquiring the functionality that the god class was performing on their data. 
Some new classes will also be extracted from the god class. 
The following steps describe how this process ideally works. Note, how- 
ever, that god classes can vary greatly in terms of their internal structure, so 
different techniques may be used to implement the transformation steps. 
Furthermore, it should be clear that a god class cannot be cured in one 
shot, so a safe way to proceed is to first transform a god class into a light- 
weight god class, then into a Facade (Pattern A.12) that delegates behavior 
to its acquaintances. Finally, clients are redirected to the refactored data 
containers and the other new objects, and the Facade can be removed. The 
process is illustrated in Figure 9.8. 
The following steps are applied iteratively. Be sure to apply Regression 
Test after Every Change (Pattern 7.6): 
1. Identify cohesive subsets of instance variables of the god class, and con- 
vert them to external data containers. Change the initialization meth- 
ods of the god class to refer to instances of the new data containers. 
2. Identify all classes used as data containers by the god class (including 
those created in step 1) and apply Move Behavior Close to Data (Pattern 
9.1) to promote the data containers into service providers. The original 
methods of the god class will simply delegate behavior to the moved 
methods. 
3. After iteratively applying steps 1 and 2, there will be nothing left of the 
god class except a facade with a big initialization method. Shift the 
responsibility for initialization to a separate class, so only a pure facade 
is left. Iteratively redirect clients to the objects for which the former god 

P A T T E R N 9.3 Split Up God Class 
211 
Clients 
FIGURE 
> God Class 
iv3 
iv4 
ml() 
m2() 
m3() 
m4() 
m5() 
Clients 
DataOne 
ivl 
getlvl() 
> setlvl() 
DataTwo 
iv2 
> getlv2() 
setlv2() 
Facade 
ml() 
m2() 
m3() 
m4() 
m5() 
ml() 
m2() 
ClassThree 
iv3 
iv4 
m5() 
iv4 
m5() 
ClassOne 
ivl 
Clients 
1 
ClassTwo 
iv2 
m3() 
m4() 
ClassOne 
ivl 
ml() 
m2() 
>~ ClassTwo 
iv2 
m3() 
m4() 
A god class is refactored in two stages, first by redistributing responsibilities to data 
containers, or by spawning off new classes, until there is nothing left but a facade, 
and second by removing the facade. 

212 
C H A P T E R 9 Redistribute Responsibilities 
PATTERN 
9.3 continued 
class is now a facade, and either deprecate the facade (see Deprecate 
Obsolete Interfaces, Pattern 7.10) or simply remove it. 
Trade-offs 
Pros 
9 Application control is no longer centralized in a single monolithic 
entity but distributed among entities that each assume a well-defined 
set of responsibilities. The design evolves from a procedural design 
toward an object-oriented design based on autonomous interacting 
objects. 
9 Parts of the original god class are easier to understand and to maintain. 
9 Parts of the original god class are more stable because they deal with 
fewer issues. 
Overall compilation time may be reduced due to the simplification of 
system dependencies. 
Cons 
9 Splitting up a god class is a long, slow, and tedious process. 
9 Maintainers will no longer be able to go to a single god class to locate 
behavior to fix. 
9 The number of classes will increase. 
Difficulties 
God class methods may themselves be large, procedural abstractions 
with too many responsibilities. Such methods may need to be decom- 
posed before cohesive sets of instance variables and methods can be 
teased out as classes. 
When the Legacy Solution Is the Solution 
What is riskier? To Split Up God Class or to leave it alone? A real god class is 
a large, unwieldy beast. Splitting it up into more robust abstractions may 
introduce considerable cost. 
The key issue is whether the god class needs to be maintained. If the 
god class consists of stable legacy code that rarely needs to be extended or 
modified, then refactoring it is a questionable investment of effort. 
Suppose, on the other hand, that it is the clients of the god class that are 
unstable and need to be frequently adapted to changing requirements. 
Then the clients should be shielded from the god class since it is not pre- 

PATTERN 9.3 Split Up God Class 213 
senting a clean interface. Consider instead applying Present the Right Inter- 
face (Pattern 7.8), which will introduce a layer of clean object-oriented 
abstractions between the clients and the god class, and may make it easier 
to evolve the clients. 
Rationale 
Related 
Patterns 
Do not create god classes/objects in your system. 
[Rie196], Heuristic 3.2 
God classes impede evolution because they achieve only a low level of pro- 
cedural abstraction, so changes may affect many parts of the god class, its 
data containers, and its clients. By splitting a god class up into object- 
oriented abstractions, changes will tend to be more localized and therefore 
easier to implement. 
Foote and Yoder in "Big Ball of Mud" [FootO0] note that god classes (and 
worse) arise naturally in software development. 
People build BIG BALLS OF MUD because they work. In many domains, 
they are the only things that have been shown to work. Indeed, they work 
where loftier approaches have yet to demonstrate that they can compete. 
It is not our purpose to condemn BIG BALLS OF MUD. Casual architecture 
is natural during the early stages of a system's evolution. The reader must 
surely suspect, however, that our hope is that we can aspire to do better. By 
recognizing the forces and pressures that lead to architectural malaise, and 
how and when they might be confronted, we hope to set the stage for the 
emergence of truly durable artifacts that can put architects in dominant 
positions for years to come. The key is to ensure that the system, its pro- 
grammers, and, indeed the entire organization, learn about the domain, 
and the architectural opportunities looming within it, as the system grows 
and matures. 
Present the Right Interface (Pattern 7.8) is a competing pattern that 
should be applied when the god class itself rarely needs to be modified or 
extended. 

CHAPTER 
Transform Conditionals 
to Polymorphism 
After duplicated code, data containers, and god classes, one of the most 
striking signs of misplaced responsibilities in object-oriented software is 
the occurrence of large methods consisting almost entirely of case state- 
ments that test the type of some argument. 
Although case statements are not inherently bad, in object-oriented 
code they are frequently a sign that the object doing the testing is assuming 
responsibilities that would better be distributed to the objects being tested. 
Big conditionals arise naturally over time, just as duplicated code does. As 
the software is adapted to handle new cases, these cases pop up as condi- 
tionals in the code. The problem with these big conditionals is that they 
can make the code much more fragile in the long term. 
Forces 
The following forces are at play: 
As requirements change over time, classes in a software system will 
have to be adapted to handle new and special cases. 
9 Adding new classes or subclasses to a system clutters the namespace. 
9 The quickest way to adapt a working piece of software to handle a new 
requirement is often to add a conditional test for the special case at 
some point in the code. 
Over time a simple design tends to get cluttered with many conditional 
tests for special cases. 
Case statements group all the variants into a single place instead of 
spreading the different cases across different classes. However, they 
lead to design that is less flexible if the case statement appears in more 
than one place. 
215 

216 
r H A P T E R 1 0 Transform Conditionals to Polymorphism 
In some programming languages, case statements are a more conven- 
tional idiom to implement varying behavior than polymorphism. 
Large conditionals are often a sign that behavior implemented by cli- 
ents should probably be be shifted to the provider classes. Typically a new 
method will be introduced to the provider hierarchy, and the individual 
cases of the conditional statement will each move to one of the provider 
classes. 
Although the symptom is readily recognizable, the technical details and 
the preferred solution may differ considerably. In particular, when the pro- 
vider hierarchy already exists, and the conditions explicitly check the class 
of the provider instance, the refactoring is relatively straightforward. But 
often the provider hierarchy does not exist, and the conditions test attri- 
butes that only implicitly model type information. Furthermore, the con- 
ditionals may occur not only in external clients, but even in the provider 
hierarchy itself. 
Overview 
Transform Conditionals to Polymorphism is a pattern language that de- 
scribes how to redistribute responsibilities to eliminate these large condi- 
tionals, thereby reducing coupling between classes and improving flexibil- 
ity in the face of future changes. 
This pattern language consists of six patterns that address the most 
common problems that occur when conditionals are used to simulate 
polymorphism. Transform Self Type Checks (Pattern 10.1) and Transform 
Client Type Checks (Pattern 10.2) address the most typical cases that arise 
when explicit type checks are performed. Transform Conditionals into 
Registration (Pattern 10.6) occurs less frequently. We also include Factor 
Out State (Pattern 10.3), Factor Out Strategy (Pattern 10.4) and Introduce 
Null Object (Pattern 10.5), not in order to copy three established design 
patterns (State, Pattern A.18; Strategy, Pattern A.20; and Null Object, Pat- 
tern A.15) but rather to show how these design patterns may apply in a 
reengineering context to eliminate type-checking conditionals. 
Figure 10.1 on page 214 summarizes the relationships and the differ- 
ences between the patterns: 
Transform Self Type Checks (Pattern 10.1) eliminates conditionals over 
type information in a provider class by introducing subclasses for each 
type case. The conditional code is replaced by a single polymorphic 
method call to an instance of one of the new subclasses. 
Transform Client Type Checks (Pattern 10.2) transforms conditionals 
over type information in a client class by introducing a new method to 

P A T T E R N 10.1 Transform Self Type Checks 
217 
each of the provider classes. The conditional is replaced by a single 
polymorphic call to the new method. 
9 Factor Out State (Pattern 10.3) handles a special case of Transform Self 
Type Checks (Pattern 10.1) in which the type information that is being 
tested may change dynamically. Introduce a State object (Pattern A.18) 
in the provider class to model the changing state, and the conditional is 
replaced by a call to a method of the new State object. 
9 Factor Out Strategy (Pattern 10.4) is another special case of Transform 
Self Type Checks (Pattern 10.1) in which the algorithms to handle the 
various provider cases are factored out by introducing a new Strategy 
object (Pattern A.20). The key difference with Factor Out State is that the 
algorithm rather than the state may vary dynamically. 
9 Introduce Null Object (Pattern 10.5) addresses the special case of 
Transform Client Type Checks (Pattern 10.2) in which the test per- 
formed checks whether or not the provider is defined. The conditional 
is eliminated by introducing a Null Object (Pattern A.15) which imple- 
ments the appropriate default behavior. 
9 Transform Conditionals into Registration (Pattern 10.6) addresses the 
situation in which the conditional is responsible for starting up an 
external tool based on some attribute of an object to be handled. The 
solution is to introduce a lookup service where tools are registered as 
plug-ins. The conditional is then replaced by a simple lookup for the 
registered plug-in. The solution is then fully dynamic because new plug- 
ins can be added or removed without any changes to the tool users. 
PATTERN 
Transform Self Type Checks 
Problem 
Intent: Improve the extensibility of a class by replacing a complex condi- 
tional statement with a call to a hook method implemented by subclasses. 
A class is hard to modify or extend because it bundles multiple possible 
behaviors in complex conditional statements that test some attribute rep- 
resenting the current "type" of the object. 
This problem is difficult because 
Conceptually simple extensions require many changes to the condi- 
tional code. 

218 
C H A P T E R 1 0 Transform Conditionals to Polymorphism 
Solution 
PATTERN 10.1 continued 
9 Subclassing is next to impossible without duplicating and adapting the 
methods containing the conditional code. 
9 Adding a new behavior always results in changes to the same set of meth- 
ods and always results in adding a new case to the conditional code. 
Yet, solving this problem is feasible because 
Self type checks simulate polymorphism. The conditional code tells 
you what subclasses you should have instead. 
Identify the methods with complex conditional branches. In each case, re- 
place the conditional code with a call to a new hook method. Identify or 
introduce subclasses corresponding to the cases of the conditional. In 
each of these subclasses, implement the hook method with the code corre- 
sponding to that case in the original case statement. 
Detection 
Most of the time, the type discrimination will jump in your face while you 
are working on the code, so this means that you will not really need to de- 
tect where the checks are made. However, it can be interesting to have sim- 
ple techniques to quickly assess if unknown parts of a system suffer from 
similar practices. This can be a valuable source of information for evaluat- 
ing the state of a system. 
9 Look for long methods with complex decision structures on some im- 
mutable attribute of the object that models type information. In particu- 
lar look for attributes that are set in the constructor and never changed. 
9 Attributes that are used to model type information typically take on val- 
ues from some enumerated type, or from some finite set of constant 
values. Look for constant definitions whose names represent entities or 
concepts that one would usually expect to be associated with classes (like 
Reti redEmpl oyee or Pendi ng0rder). The conditionals will normally just 
compare the value of a fLxed attribute to one of these constant values. 
9 Especially look for classes where multiple methods switch on the same 
attribute. This is another common sign that the attribute is being used 
to simulate a type. 
9 Since methods containing switch statements tend to be long, it may help 
to use a tool that sorts methods by lines of code or visualizes classes and 
methods according to their size. Alternatively, search for classes or meth- 
ods with a large number of conditional statements. 

P A T T E R N 10.1 Transform Self Type Checks 
219 
For languages like C++ or Java where it is common to store the imple- 
mentation of a class in a separate file, it is straightforward to search for 
and count the incidence of conditional keywords (i f, el se, case, etc.). 
On a Unix system, for example, 
grep switch "find . -name "*.cxx" -print" 
enumerates all the files in a directory tree with extension, cxx that con- 
tain a switch. Other text processing tools like agrep offer possibilities 
for posing finer-granularity queries. Text processing languages like perl 
may be better suited for evaluating some kinds of queries, especially 
those that span multiple lines. 
9 C/C++: Legacy C code may simulate classes by means of union types. 
Typically the union type will have one data member that encodes the 
actual type. Look for conditional statements that switch on such data 
members to decide which type to cast a union to and which behavior to 
employ. 
In C++ it is fairly common to find classes with data members that are 
declared as void pointers. Look for conditional statements that cast 
such pointers to a given type based on the value of some other data 
member. The type information may be encoded as an enum or (more 
commonly) as a constant integer value. 
9 Ada: Because Ada83 did not support polymorphism (or subprogram 
access types), discriminated record types are often used to simulate 
polymorphism. Typically an enumeration type provides the set of vari- 
ants, and the conversion to polymorphism is straightforward in Ada95. 
9 Smalltalk: Smalltalk provides only a few ways to manipulate types. 
Look for applications of the methods i sMemberOf: and i sKi ndOf:, which 
signal explicit type checking. Type checks might also be made with tests 
like self class = anotherClass, or with property tests throughout the 
hierarchy using methods like isSymbol, isString, isSequenceable, 
isInteger. 
Steps 
The following steps are illustrated in Figure 10.2: 
1. Identify the class to transform and the different conceptual classes that 
it implements. An enumeration type or set of constants will probably 
document this well. 
2. Introduce a new subclass for each behavior that is implemented. Mod- 
ify clients to instantiate the new subclasses rather than the original 
class. Run the tests. 

220 
C H A P T E R 1 0 Transform Conditionals to Polymorphism 
FIGURE 
PATTERN 
1 0.1 continued 
l "~ 
I thi s.doSomething() 
o
o
o
 
case B" this.doSomething( 
case C ... 
case D 
i c,,on, I 
t" 1 
Im()--l--- 
hook() 
I h~176 
"'" 
..... I hoboken1 Iho'' 
I hoo~~l 
Transformation of explicit type check into self polymorphic method calls. 
3. Identify all methods of the original class that implement varying behav- 
ior by means of conditional statements. If the conditionals are sur- 
rounded by other statements, move them to separate, protected hook 
methods. When each conditional occupies a method of its own, run the 
tests. 
4. Iteratively move the cases of the conditionals down to the correspond- 
ing subclasses, periodically running the tests. 
5. The methods that contain conditional code should now all be empty. 
Replace these by abstract methods and run the tests. 
6. Alternatively, if there are suitable default behaviors, implement these at 
the root of the new hierarchy. 
7. If the logic required to decide which subclass to instantiate is non- 
trivial, consider encapsulating this logic as a factory method of the new 
hierarchy root. Update clients to use the new factory method and run 
the tests. 

P A T T E R N 10.1 Transform Self Type Checks 221 
Trade-offs 
Pros 
New behaviors can now be added in an incremental manner, without 
having to change a set of methods of a single class containing all the be- 
havior. A specific behavior can now be understood independently from 
the other variations. 
9 A new behavior represents its data independently from the others, thereby 
minimizing the possible interference and increasing the understand- 
ability of the separated behaviors. 
9 All behaviors now share a common interface, thereby improving their 
readability. 
Cons 
All the behaviors are now dispersed into multiple but related abstrac- 
tions, so getting an overview of the behavior may be more difficult. 
However, the concepts are related and share the interface represented 
by the abstract class, reducing the problem. 
The larger number of classes makes the design more complex and 
potentially harder to understand. If the original conditional statements 
are simple, it may not be worthwhile to perform this transformation. 
Explicit type checks are not always a problem, and we can sometimes 
tolerate them. Creating new classes increases the number of abstrac- 
tions in the applications and can clutter namespaces. Hence, explicit 
type checks may be an alternative to the creation of new classes when 
the set over which the method selection is fixed and will not evolve 
in the future, and 
the type check is only made in a few places. 
Difficulties 
9 Since the requisite subclasses do not yet exist, it can be hard to tell 
when conditionals are being used to simulate multiple types. 
9 Wherever instances of the transformed class were originally created, 
now instances of different subclasses must be created. If the instan- 
tiation occurred in client code, that code must now be adapted to 
instantiate the right class. Factory objects or methods may be needed 
to hide this complexity from clients. 
9 Ifyou do not have access to the source code of the clients, it may be dif- 
ficult or impossible to apply this pattern since you will not be able to 
change the calls to the constructors. 

222 
C H A P T E R 1 0 Transform Conditionals to Polymorphism 
FIGURE 
PATTERN 
1 0.1 continued 
IAI 
o o o  
Case B... 
Case C 
Case D 
IAI 
\ 
delegate 
I 
A 
mfi 
ho( 
delegate.m ( 
ooo 
B 
l 
hook() 
ho~ 
4 I 
["" 
__L .... 
hook() 
'kO 
"'" 
X 
" 
D 
~k() 
hook() 
IX 
Combining simple delegation and Transform Self Type Checks when the class 
cannot be subclassed. 
If the case statements test more than one attribute, it may be necessary 
to support a more complex hierarchy, possibly requiring multiple inheri- 
tance. Consider splitting the class into parts, each with its own hierarchy. 
When the class containing the original conditionals cannot be sub- 
classed, Transform Self Type Checks can be composed with delegation. 
The idea is to exploit polymorphism on another hierarchy by moving 
part of the state and behavior of the original class into a separate class 
to which the method will delegate, as shown in Figure 10.3. 
When the Legacy Solution Is the Solution 
There are some situations in which explicit type checks may nevertheless 
be the right solution: 
The conditional code may be generated from a special tool. Lexers and 
parsers, for example, may be automatically generated to contain the 
kind of conditional code we are trying to avoid. In these cases, however, 
the generated classes should never be manually extended, but simply 
regenerated from the modified specifications. 

P A T T E R N 10.1 Transform Self Type Checks 223 
[ Clientl I 
Message 
set_value(action: Integer) 
send(channel: Channel) 
set_value(text: String) 
receive(channel: Channel) 
[ Client2 [ 
FIGURE 
class Message { 
public. 
Message(); 
set value(char* text) ; 
m 
set value(int action); 
void send(Channel c); 
void receive(Channel c); 
private" 
void* data ; 
i nt type_; 
static const int TEXT = I; 
static const int ACTION = 2; 
o o  
9 
} 
Initial design and source code. 
Message"send(Channel c) { 
switch (type_) { 
case TEXT" 
case ACTION. 
} 
} 
void Clientl"doit() { ... 
Message * myMessage = 
new Message(); 
myMessage->set_Val ue("... ") ; 
} 
Example 
We worked on a complex system that controls large, physical machines by 
sending them messages. These messages are represented by the class Mes- 
sage and can be of different types. 
Before 
A message class wraps two different kinds of messages (TEXT and ACT I ON) 
that must be serialized to be sent across a network connection, as shown in 
Figure 10.4. We would like to be able to send a new kind of message (say, 
VO ICE), but this will require changes to several methods of Message. 
After 
Since Message conceptually implements two different classes, Text Message 
n 
and Acti on_Message, we introduce these as subclasses of Message, as shown 
in Figure 10.5. We introduce constructors for the new classes, we modify 
the clients to construct instances of Text Message and Action Message 
m 
rather than Message, and we remove the set_val ue() methods. Our regres- 
sion tests should run at this point. 

224 
C H A P T E R 1 0 Transform Conditionals to Polymorphism 
PATTERN 10.1 continued 
I Clientl I 
Message 
I 
send(channel: Channel) 
I 
receive(channel: Channel) I 
I 
Text_Message 
Text_Message(String) 
send(channel: Channel) 
receive(channel: Channel) 
I Client2 I 
I 
Action_Message 
Action_Message(Integer) 
send(channel: Channel) 
receive(channel: Channel) 
FIGURE 
class Message { 
publ i c" 
virtual void 
send(Channel c) = O; 
virtual void 
receive(Channel c) = O; 
o
.
,
 
}; 
class Text Message: public Message 
{ 
publ i c: 
Text Message(char* text) ; 
void send(Channel c); 
void receive(Channel c); 
private: 
char* text; 
o o o  
}; 
Resulting hierarchy and source code. 
class Action_Message" public 
Message { 
publ i c" 
Action Message(int action); 
void send(Channel c); 
void receive(Channel c); 
private- 
int action; 
.
e
.
 
}; 
void Clientl'-doit() {... 
Message * myMessage = new 
Text Message("...") ; 
n 
} 
Now we find methods that switch on the type_ variable. In each case, 
we move the entire switch statement to a separate, protected hook 
method, unless the switch already occupies the entire method. In the case 
of send (), this is already the case, so we do not have to introduce a hook 
method. Again, all our tests should still run. 
Nowwe iteratively move cases of the switch statements from Message to 
its subclasses. The TEXT case of Message" .send() moves to Text_Message" 9 

P A T T E R N 10.2 Transform Client Type Checks 
225 
send() and the ACTION case moves to Action Message: :send(). Every time 
m 
we move such a case, our tests should still run. 
Finally, since the original send() method is now empty, it can be 
redeclared to be abstract (i.e., vi rtual void send(Channel ) = 0). Again, our 
tests should run. 
Rationale 
Related 
Patterns 
Classes that masquerade as multiple data types make a design harder to 
understand and extend. The use of explicit type checks leads to long meth- 
ods that mix several different behaviors. Introducing new behavior then 
requires changes to be made to all such methods instead of simply specify- 
ing one new class representing the new behavior. 
By transforming such classes to hierarchies that explicitly represent the 
multiple data types, you improve cohesion by bringing together all the 
code concerning a single data type, you eliminate a certain amount of du- 
plicated code (i.e., the conditional tests), and you make your design more 
transparent and consequently easier to maintain. 
In Transform Self Type Checks the condition to be transformed tests type 
information that is represented as an attribute of the class itself. 
If the conditional tests the mutable state of the host object, consider in- 
stead applying Factor Out State (Pattern 10.3), or possibly Factor Out Strat- 
egy (Pattern 10.4). 
If the conditional occurs in a client rather than in the provider class 
itself, consider applying Transform Client Type Checks (Pattern 10.2). 
If the conditional code tests some type attribute of a second object in 
order to select some third handler object, consider instead applying Trans- 
form Conditionals into Registration (Pattern 10.6). 
PATTERN 
Transform Client Type Checks 
Intent: Reduce client/provider coupling by transforming conditional code 
that tests the type of the provider into a polymorphic call to a new provider 
method. 
Problem 
How do you reduce the coupling between clients and providers of services, 
where the clients explicitly test the type of providers and have the re- 
sponsibility to compose providers' code? 

226 
C H A P T E R 1 0 Transform Conditionals to Polymorphism 
PATTERN I0.2 continued 
This problem is difficult because 
9 Adding a new subclass to the provider hierarchy requires making 
changes to many clients, especially where the tests occur. 
9 Clients and providers tend to be strongly coupled, since clients are per- 
forming actions that should be the responsibility of the providers. 
Yet, solving this problem is feasible because 
9 The conditionals tell you to which classes you should transfer behavior. 
Solution 
Introduce a new method into the provider hierarchy. Implement the new 
method in each subclass of the provider hierarchy by moving the corre- 
sponding case of the client's conditional to that class. Replace the entire 
conditional in the client by a simple call to the new method. 
Detection 
Apply essentially the same techniques described in Transform Self Type 
Checks (Pattern 10.1) to detect case statements, but look for conditions 
that test the type of a separate service provider that already, implements a 
hierarchy. You should also look for case statements occurring in different 
clients of the same provider hierarchy. 
C++: Legacy C++ code is not likely to make use of run-time type infor- 
mation (RTTI). Instead, type information will likely be encoded in a 
data member that takes its value from some enumerated type repre- 
senting the current class. Look for client code switching on such data 
members. 
9 Ada: Detecting type tests falls into two cases. If the hierarchy is imple- 
mented as a single discriminated record, then you will find case state- 
ments over the discriminant. If the hierarchy is implemented with 
tagged types, then you cannot write a case statement over the types 
(they are not discrete); instead an if-then-else structure will be used. 
9 Smalltalk: As in Transform Self Type Checks (Pattern 10.1), look for 
applications of i sMemberOf: and i sKindOf:, and tests like self cl ass = 
anotherCl ass. 
9 lava: Look for applications of the operator i nstanceof, which tests 
membership of an object in a specific, known class. Although classes in 
Java are not objects as in Smalltalk, each class that is loaded into the vir- 
tual machine is represented by a single instance of java. lang. Cl ass. It 

P A T T E R N 10.2 Transform Client Type Checks 227 
is therefore possible to determine if two objects, x and y, belong to the 
same class by performing the test 
x.getClass() -= y.getClass() 
Alternatively, class membership may be tested by comparing class 
names: 
x. getCl ass (). getName () .equal s (y. getCl ass (). getName ()) 
Steps 
Figure 10.6 illustrates how the following steps transform type-checking 
code into polymorphic methods: 
1. Identify the clients performing explicit type checks. 
2. Add a new, empty method to the root of the provider hierarchy repre- 
senting the action performed in the conditional code. 
3. Iteratively move a case of the conditional to some provider class, re- 
placing it with a call to that method. After each move, the regression 
tests should run. 
4. When all methods have been moved, each case of the conditional con- 
sists of a call to the new method, so replace the entire conditional by a 
single call to the new method. 
5. Consider making the method abstract in the provider's root. Alterna- 
tively implement suitable default behavior here. 
Other Steps to Consider 
9 It may well be that multiple clients are performing exactly the same test 
and taking the same actions. In this case, the duplicated code can be re- 
placed by a single method call after one of the clients has been trans- 
formed. If clients are performing different tests or taking different 
actions, then the pattern must be applied once for each conditional. 
9 If the case statement does not cover all the concrete classes of the pro- 
vider hierarchy, a new abstract class may need to be introduced as a 
common superclass of the concerned classes. The new method will 
then be introduced only for the relevant subtree. Alternatively, if it is 
not possible to introduce such an abstract class given the existing in- 
heritance hierarchy, consider implementing the method at the root with 
either an empty default implementation, or one that raises an exception 
if it is called for an inappropriate class. 
9 If the conditionals are nested, the pattern may need to be applied 
recursively. 

228 
C H A P T E R 1 0 Transform Conditionals to Polymorphism 
PATTERN 
10.2 continued 
s 
~ 
"'" 
i 
r,, 
switch (.class) 
case g. 
.init(); 
((g) a).x(); 
[D[ 
case C" a.init(); 
(IC) a).y() 
case D" ((D) a).z() 
o.o 
Client 
[ 
a :A 
ini 
m()~ 
do 
\ 
Z 
\ 
\ 
ooo 
1 
a.doit(); 
o0o 
x() 
ini 
Idoit(), 
y() 
do! 
this.init() ; 
this.x(); 
A I 
Lnit() 
~oitO 
~ () 
z() 
]doi 
,it()~ 
\ 
\ 
\ 
this.init() ; ~ 
this.y(); 
,it()\ 
\ 
I this.zi ; 
FIGURE 
Transformation of explicit type check into polymorphic method calls. 
Trade-offs 
Pros 
9 The provider hierarchy offers a new, polymorphic service available to 
other clients as well. 
9 The code of the clients is now better organized and does not have to 
deal anymore with concerns that are now under the responsibility of 
the provider. 

P A T T E R N 10.2 Transform Client Type Checks 229 
Example 
9 All the code concerning the behavior of a single provider is now to- 
gether in a single location. 
9 The fact that the provider hierarchy offers a uniform interface allows 
providers to be modified without impacting clients. 
Cons 
Sometimes it is convenient to see the code handling different cases in a 
single location. Transform Client Type Checks redistributes the logic to 
the individual provider classes, with the result that the overview is lost. 
Difficulties 
Normally instances of the provider classes should already have been 
created so we do not have to look for the creation of the instances; how- 
ever, refactoring the interface will affect all clients of the provider 
classes and must not be undertaken without considering the full conse- 
quences of such an action. 
When the Legacy Solution Is the Solution 
Client type checks may nevertheless be the right solution when the provid- 
er instance does not yet exist or when its class cannot be extended: 
9 An Abstract Factory (Pattern A. 10) object may need to test a type vari- 
able in order to know which class to instantiate. For example, a factory 
may stream objects in from a text file representation, and test some 
variable that tells it which class the streamed object should belong to. 
9 Software that interfaces to a non-object-oriented library, such as a leg- 
acy GUI library, may force the developer to simulate the dispatch man- 
ually. It is questionable whether, in such cases, it is cost-effective to 
develop an object-oriented facade to the procedural library. 
9 If the provider hierarchy is frozen (e.g., because the source code is not 
available), then it will not be possible to transfer behavior to the pro- 
vider classes. In this case, wrapper classes may be defined to extend the 
behavior of the provider classes, but the added complexity of defining 
the wrappers may overwhelm any benefits. 
Before 
The following C++ code illustrates misplaced responsibilities since the 
client must explicitly type check instances of Te]ephone to determine what 
action to perform. The code in bold highlights the difficulties with this 
approach. 

230 
C H A P T E R 1 0 Transform Conditionals to Polymorphism 
PATTERN 1 0.2 continued 
class Telephone { 
public: 
enum PhoneType { POTSPHONE, ISDNPHONE, OPERATORPHONE }; 
Telephone() {} 
PhoneType phoneType() { return myType; } 
private: 
PhoneType myType; 
protected: 
void setPhoneType(PhoneType newType) { myType = newType; 
}; 
class POTSPhone : public Telephone { 
pub l i c: 
POTSPhone() { setPhoneType (POTSPHONE) ; } 
void tourneManivelle() ; 
void call(); 
}; 
class ISDNPhone: public Telephone { 
public: 
ISDNPhone() { setPhoneType(ZSDNPHONE) ;} 
void initializeLine(); 
void connect() ; 
}; 
class OperatorPhone: public Telephone { 
public: 
OperatorPhone() { setPhoneType(OPERATORPHONE); } 
void operatorMode(bool onOffToggle) ; 
void call (); 
}; 
void initiateCalls(Telephone ** phoneArray, int numOfCalls) { 
for(int i - O; i<numOfCalls ;i++ ) { 
Telephone * p = phoneArray[i]; 
swi tch (p->phoneType ()) 
{ 
case Tel ephone: : POTSPHONE: 

P A T T E R N 10.2 Transform Client Type Checks 231 
} 
} 
POTSPhone *potsp = (POTSPhone *) p; 
potsp->tourneMani vel le() ; 
potsp->cal I () ; 
break; 
} 
case Telephone: :ISDNPHONE: 
{ 
ISDNPhone *isdnp = (ISDNPhone *) p; 
isdnp->initial izeLine() ; 
i sdnp->connect () ; 
break; 
} 
case Tel ephone: : OPERATORPffONE: 
{ 
OperatorPhone *opp = (OperatorPhone *) p; 
opp->operatorMode (true) ; 
opp->ca I 1 () ; 
break; 
} 
default: 
cerr << "Unrecognized Phonetype" << endl; 
}; 
After 
Figure 10.7 summarizes the changes. After applying the pattern the client 
code will look like the following. We highlight the changes in bold: 
class Telephone { 
public: 
Telephone() 
{} 
virtual 
void makeCall () : O; 
}; 
Class POTSPhone : public Telephone { 
void tourneManivelle() ; 
void call (); 
public: 
POTSPhone() {} 
void makeCall () ; 
}; 
void POTSPhone::makeCall () { 
thi s->tourneMani vel I e() ; 
thi s->cal I () ; 
} 

232 
C H A P T E R 1 0 Transform Conditionals to Polymorphism 
PATTERN 10.2 continued 
I r  phone I 
s 
e
e
e
 
switch (a.class) 
I POTSPhone I I ISDNph~ 
I [ Operat~176 
l 
case TELEPHONE:'POTS: ... 
case TELEPHONE: ISDN: 
case TELEPHONE: OTHERS 
ooo 
Client 
m() 
/ 
/ 
/ 
oe. 
1 
a.makeCal I () 
eoo 
Telephone 
makeCallO 
POTSPhone 
ISDNPhone 
OperatorPhone 
makeCall ( ) 
makeC all ( ) 
makeCall ( ) 
FIGURE 
Transforming explicit type checks to polymorphic method invocations. 
class ISDNPhone" public Telephone { 
void initial izeLine() ; 
void connect() ; 
pub l i c: 
ISDNPhone() { } 
void makeCal I () ; 
}; 
void ISDNPhone::makeCall () { 
this->initializeLine() ; 
thi s->connect () ; 
} 
class OperatorPhone" public Telephone { 
void operatorMode(bool onOffToggle) ; 
void call (); 

P A T T E R N 10.2 Transform Client Type Checks 233 
Rationale 
Related 
Patterns 
public: 
OperatorPhone() 
{ } 
void makeCal I () ; 
I; 
void OperatorPhone::makeCall () { 
thi s->operatorMode (true) ; 
this->call () ; 
} 
void initiateCalls(Telephone 
** phoneArray, int numOfCalls) 
{ 
for(int 
i = O; i<numOfCalls 
;i++ ) { 
phoneArray[i] ->makeCal I () ; 
} 
} 
Riel states: "Explicit case analysis on the type of an object is usually an error. 
The designer should use polymorphism in most of these cases" [Rie196]. 
Indeed, explicit type checks in clients are a sign of misplaced responsibili- 
ties since they increase coupling between clients and providers. Shifting 
these responsibilities to the provider will have the following consequences: 
9 The client and the provider will be more weakly coupled since the client 
will only need to explicitly know the root of the provider hierarchy 
instead of all of its concrete subclasses. 
9 The provider hierarchy may evolve more gracefully, with less chance of 
breaking client code. 
9 The size and complexity of client code is reduced. The collaborations 
between clients and providers become more abstract. 
9 Abstractions implicit in the old design (i.e., the actions of the condi- 
tional cases) will be made explicit as methods and will be available to 
other clients. 
9 Code duplication may be reduced (if the same conditionals occur mul- 
tiply). 
In Transform Client Type Checks the conditional is made on the type infor- 
mation of a provider class. The same situation occurs in Introduce Null 
Object (Pattern 10.5), where the conditional tests over null value before 
invoking the methods. From this point of view, Introduce Null Object is a 
specialization of Transform Client Type Checks. 
Transform Conditionals into Registration (Pattern 10.6) handles the 
special case in which the client's conditional is used to select a third object 
(typically an external application or tool) to handle the argument. 

234 
C H A P T E R 1 0 Transform Conditionals to Polymorphism 
PATTERN 
10.2 continued 
Replace Conditional with Polymorphism (Pattern A.9) is the core re- 
factoring of this reengineering pattern, so the reader may refer to the steps 
described in [Fowl99]. 
PATTERN 
Factor Out State 
Problem 
Solution 
Intent: Eliminate complex conditional code over an object's state by apply- 
ing the State design pattern (Pattern A.18). 
How do you make a class whose behavior depends on a complex evalua- 
tion of its current state more extensible? 
This problem is difficult because 
9 There are several complex conditional statements spread out over the 
methods of the object. Adding new behavior may affect these condi- 
tionals in subtle ways. 
9 Whenever new possible states are introduced, all the methods that test 
state have to be modified. 
Yet, solving this problem is feasible because 
The object's instance variables are typically used to model different 
abstract states, each of which has its own behavior. If you can identify 
these abstract states, you can factor the state and the behavior out into 
a set of simpler, related classes. 
Apply the State pattern (Pattern A.18), that is, encapsulate the state-depen- 
dent behavior into separate objects, delegate calls to these objects, and 
keep the state of the object consistent by referring to the right instance of 
these state objects (see Figure 10.8). 
As in Transform Self Type Checks (Pattern 10.1), transform complex 
conditional code that tests over quantified states into delegated calls to 
state classes. Apply the State pattern, delegating each conditional case to a 
separate State object. We invite you to read the State and State Patterns (Pat- 
tern A.19) for a deep description of the problem and discussion [Gamm95] 
[Alpe98] [Dyso97]. Here we only focus on the reengineering aspects of the 
pattern. 

PATTERN 10.3 Factor Out State 
235 
A 
request(), 
% 
% 
% 
% 
% 
ooo 
case A.... 
case B.... 
case C" ... 
f 
/ 
r 
state = C 
state 
B 
AContext 
request() 
state, handl eRequest () ; 
t 
state = state.nextState() 
state 
AState 
handleRequestO 
nextStateO 
StateA 
StateB 
handleRequest() 
handleRequest() 
nextState() 
nextState() 
% 
Ireturn new 
StateC 
handleRequest() 
nextState() 
FIGURE 
Transformation to go from a state pattern simulated using an explicit state condi- 
tional to a situation where the state pattern has been applied. 
Steps 
1. Identify the interface of a state and the number of states. 
If you are lucky, each conditional will partition the state space in the 
same way, and the number of states will equal the number of cases in 
each conditional. If the conditionals overlap, a finer partitioning will be 
required. 
The interface of a state depends on how the state information is ac- 
cessed and updated, and may need to be refined in the subsequent 
steps. 
2. Create a new abstract class, State, representing the interface ofthe state. 

236 
C H A P T E R I 0 Transform Conditionals to Polymorphism 
Trade-offs 
PATTERN I0.3 continued 
3. Create a new class subclass of State for each state. 
4. Define methods of the interface identified in step 1 in each of the State 
classes by copying the corresponding code of the conditional to the 
new method. Do not forget to change the state of the instance variable 
in the Context to refer to the right instance of State class. The State 
methods have the responsibility to change the Context so that it always 
refers to the next state instance. 
5. Add a new instance variable in the Context class. 
6. You may have to include a reference from the State to the Context class 
to invoke the state transitions from the State classes. 
7. Initialize the newly created instance to refer to a default State class 
instance. 
8. Change the methods of the Context class containing the tests to dele- 
gate the call to the instance variable. 
Step 4 can be performed using the Extract Method operation of the Refac- 
toring Browser. Note that after each step the regression tests should still 
run. The critical step is the last one, in which behavior is delegated to the 
new state objects. 
Pros 
The public interface of the original class does not have to change. Since 
the state instances are accessed by delegation from the original object, 
the clients are unaffected. In the straightforward case the application of 
this pattern has a limited impact on the clients. 
Cons 
The systematic application of this pattern may lead to an explosion in 
the number of classes. 
This pattern should not be applied when (1) there are too many possi- 
ble states or the number of states is not fixed or (2) when it is hard to 
determine from the code how and when state transitions occur. 
When the Legacy Solution Is the Solution 
This pattern should not be applied lightly. 
When the states are clearly identified and it is known that they will not 
be changed, the legacy solution has the advantage of grouping all the 

P A T T E R N 10.4 Factor Out Strategy 
237 
state behavior by functionality instead of spreading it over different 
subclasses. 
In certain domains (such as parsers) table-driven behavior, encoded as 
conditionals over state, is well understood, and factoring out the state 
objects may just make the code harder to understand, and hence to 
maintain. 
Known 
Uses 
The Design Patterns Smalltalk Companion presents a step-by-step code 
transformation [Alpe98]. 
PATTERN 
Problem 
Solution 
Factor Out Strategy 
Intent: Eliminate conditional code that selects a suitable algorithm by ap- 
plying the Strategy design pattern (Pattern A.20). 
How do you make a class whose behavior depends on testing the value of 
some variable more extensible? 
This problem is difficult because 
9 New functionality cannot be added without modifying all the methods 
containing the conditional code. 
9 The conditional code may be spread over several classes that make sim- 
ilar decisions about which algorithm to apply. 
Yet, solving this problem is feasible because 
9 The alternative behaviors are essentially interchangeable. 
Apply the Strategy pattern (Pattern A.20), that is, encapsulate the algorith- 
mic dependent behavior into separate objects with polymorphic inter- 
faces and delegate calls to these objects (see Figure 10.9). 
Steps 
1. Identify the interface of the strategy class. 
2. Create a new abstract class, Strategy, representing the interface of the 
strategies. 

238 
C H A P T E R 1 0 Transform Conditionals to Polymorphism 
FIGURE 
P AT T E R N 10. 4 continued 
A 
operation() 
ooo 
case A" .o 
case B 
case C 
AContext 
operation() 
I 
f 
I 
t 
I 
I 
j,, 
strategy, handl eOperati on () 
... 
~ 
strategy 
AS trategy 
handleOperatio n O 
StrategyA 
StrategyB 
handleOperation ( ) 
handleOp eration ( ) 
Transformation to go from a state pattern simulated using an explicit state condi- 
tional to a situation where the state pattern has been applied. 
3. Create a new class subclass of Strategy for each identified algorithm. 
4. Define methods of the interface identified in step 1 in each of the strategy 
classes by copying the corresponding code of the test to the method. 
5. Add a new instance variable in the Context class to refer to the current 
strategy. 
6. You may have to include a reference from the Strategy to the Context 
class to provide access to the information maintained by the Context 
(see "Difficulties"). 
7. Initialize the newly created instance to refer to a default strategy instance. 
8. Change the methods of the Context class containing the tests by elimi- 
nating the tests and delegating the call to the instance variable. 
Step 4 can be performed using the Extract Method operation of the Refac- 
toring Browser. Note that after each step the regression tests should still 
run. The critical step is the last one, in which behavior is delegated to the 
new Strategy objects. 

P A T T E R N 10.4 Factor Out Strategy 
239 
Trade-offs 
Example 
Related 
Patterns 
Pros 
9 Limited impact. The public interface of the original class does not have 
to change. Since the Strategy instances are accessed by delegation 
from the original object, the clients are unaffected. In a straightforward 
case the application of this pattern has a limited impact on the clients. 
However, the Context interface will be reduced because all the previ- 
ously implemented algorithms are now moved to Strategy classes. So 
you have to check the invocations of these methods and decide on a 
per-case basis. 
9 Improued configurability. After applying this pattern, you will be able 
to plug in new strategies without impacting or modifying the interface 
of the Context. Adding a new strategy does not require recompiling the 
Context class and its clients. 
Cleaner interface. After applying this pattern, the interface of the Con- 
text class and the Strategy classes will be clearer. 
Cons 
9 Class explosion. The systematic application of this pattern may lead to 
a class explosion. If you have 20 different algorithms, you may not want 
to have 20 new classes each with only one method. 
9 Object explosion. Strategies increase the number of instances in an appli- 
cation. 
Difficulties 
There are several ways to share information between the Context and 
the Strategy objects, and the trade-offs can be subtle. The information 
can be passed as argument when the Strategy method is invoked, the 
Context object itself can be passed as argument, or the Strategy objects 
can hold a reference to their context. If the relationship between the 
Context and the Strategy is highly dynamic, then it may be preferable 
to pass this information as a method argument. More detailed discus- 
sions of this issue exist in the literature on the Strategy pattern (Pattern 
A.20) [Gamm95] [Alpe98]. 
The Design Patterns Smalltalk Companion presents a code transformation 
step by step [Alpe98]. 
The symptoms and structure of Factor Out Strategy bear comparison with 
Factor Out State (Pattern 10.3). The main difference consists in the fact that 

240 
C H A P T E R 1 0 Transform Conditionals to Polymorphism 
PATTERN 
10.4 continued 
Factor Out State identifies behavior with different possible states of objects, 
whereas Factor Out Strategy is concerned with interchangeable algorithms 
that are independent of object state. Factor Out Strategy allows you to add 
new strategies without impacting the existing strategy objects. 
PATTERN 
Problem 
Introduce Null Object 
Intent: Eliminate conditional code that tests for null values by applying the 
Null Object design pattern (Pattern A.15). 
How can you ease modification and extension of a class in the presence of 
repeated tests for null values? 
This problem is difficult because 
9 Client methods are always testing that certain values are not null before 
actually invoking their methods. 
9 Adding a new subclass to the client hierarchy requires testing null val- 
ues before invoking some of the provider methods. 
Yet, solving this problem is feasible because 
The client does not need to know that the provider represents a null 
value. 
Solution 
Apply Null Object (Pattern A.15), that is, encapsulate the null behavior as a 
separate provider class so that the client class does not have to perform a 
null test. 
Detection 
Look for idiomatic null tests. 
Null tests may take different forms, depending on the programming 
language and the kind of entity being tested. In Java, for example, a null 
object reference has the value nul], whereas in C++ a null object pointer 
has the value 0. 

P A T T E R N 10.5 Introduce Null Object 
241 
FIGURE 
Client 
m(),, 
\ 
\ 
\ 
\ 
i 
ifia!:Null) 
a.doit() ; 
{ 
e 
o e  
RealObject 
doit() 
Client 
m()l 
I 
I 
I 
.. 
,1 
a doit( 
doit() 
AbstractObject 
doitO 
RealObject 
NullObject 
doit()~ 
I 
I 
I 
I 
Empty' ~ 
Transformation from a situation based on an explicit test of null value to a situation 
where a NullObject is introduced. 
Steps 
Fowler discusses in detail the necessary refactoring steps illustrated in Fig- 
ure 10.10 [Fowl99]. 
1. Identify the interface required for the null behavior. (This will normally 
be identical to that of the nonnull object.) 
2. Create a new abstract superclass as a superclass of the Real Object class. 
3. Create a new subclass of the abstract superclass with a name starting 
with No or Nul I. 
4. Define default methods into the Nul l Obj ect class. 
5. Initialize the instance variable or structure that was checked to now 
hold at least an instance of the Nu 110bj ect class. 
6. Remove the conditional tests from the client. 
If you still want to be able to test for null values in a clean way, you may in- 
troduce a query method called i sNul 1 in Real Object and Nul ]Object classes, 
as described by Fowler [Fowl99]. 

242 
C H A P T E R 1 0 Transform Conditionals to Polymorphism 
Trade-offs 
Example 
PATTERN 
10.5 continued 
Pros 
9 The client code is much simpler after applying the pattern. 
9 The pattern is relatively simple to apply since the interface of the pro- 
vider does not have to be modified. 
Cons 
9 The provider hierarchy becomes more complex. 
Difficulties 
Multiple clients may not agree on the reasonable default behavior of 
the Nu] ]Object. In this case, multiple Nu] ]Object classes may need to be 
defined. 
When the Legacy Solution Is the Solution 
9 If clients do not agree on a common interface. 
9 When very little code uses the variable directly or when the code that 
uses the variable is well encapsulated in a single place. 
The following Smalltalk code is taken from Woolf [Woo198]. Initially the 
code contains explicit null tests: 
Visual Part>>obj ectWantedControl 
9 
9 
9 
^ctrl isNil 
ifFalse: 
[ctrl i sControlWanted 
i fTrue: [sel f] 
ifFalse: [nil]] 
It is then transformed into 
Visual Part>>obj ectWantedControl 
9 
9 
9 
^ctrl i sControlWanted 
i fTrue: [sel f] 
ifFalse: [nil] 
Control I er>>i sControl Wanted 
^sel f vi ewHasCursor 

P A T T E R N 10.6 Transform Conditionals into Registration 
243 
NoContro I I er>>i sCont ro I Wanted 
^false 
PATTERN 
Transform Conditionals into Registration 
Problem 
Intent: Improve the modularity of a system by replacing conditionals in 
clients by a registration mechanism. 
How can you reduce the coupling between tools providing services and cli- 
ents so that the addition or removal of tools does not lead to changing the 
code of the clients? 
This problem is difficult because 
Having one single place to look for all the kinds of tools makes it easy to 
understand the system and easy to add new tools. 
However, every time you remove a tool, you have to remove one case in 
some conditional statement, or else certain parts (tool clients) would 
still reflect the presence of the removed tools, leading to fragile systems. 
Then every time you add a new tool, you have to add a new conditional 
in all the tool clients. 
Yet, solving this problem is feasible because 
Long conditionals make it easy to identify the different type of tools 
used. 
Solution 
Introduce a registration mechanism to which each tool is responsible for 
registering itself, and transform the tool clients to query the registration 
repository instead of performing conditionals. 
Steps 
The following steps summarize how to transform conditionals in tool users 
to a registration mechanism (see Figure 10.11): 
1. Define a class describing plug-in objects~objects encapsulating the 
information necessary for registering a tool. Although the internal struc- 
ture of this class depends on the purpose of the registration, a plug-in 

244 
C H A P T E R 1 0 Transform Conditionals to Polymorphism 
PATTERN 
1 0.6 continued 
/ 
/ 
/ 
/ 
o
o
e
 
case 'xm]'- 
J Tool Client 
. 
read() 
XMLReader 
openFile (File) 
WordReader 
withFile (File) 
XMLReader openFile" selectedFile 
case 'doc" 
WordReader new withFile" selectedFile 
I Tool Client 
. 
read 
(Pl ugi nManager uniquelnstance 
findToolFor" selectedFile suffix 
action 
Plugin Manager 
add (Tool) 
remove (Tool) 
findToolFor (File) 
plugin 
discrimant 
(String)" Boolean 
action() 
FIGURE 
P1 ugi nManager uniquelnstance 
add- (Plugin 
for" XMLReader 
with" 'xml') 
PluginManager uniquelnstance 
remove" 'xml ' 
f 
XMLReader 
load() 
unload() 
WordReader 
load() 
unload() 
Transforming conditionals in tool users by introducing a registration mechanism. 
should provide the necessary information so the tool manager can 
identify it, create instances of the represented tool, and invoke meth- 
ods. To invoke a tool method, a method or a similar mechanism like a 
block closure or inner class should be stored in the plug-in object. 

P A T T E R N 10.6 Transform Conditionals into Registration 
245 
Example 
2. Define a class representing the plug-in manager (i.e., that manages the 
plug-in objects and that will be queried by the tool clients to check the 
presence of the tools). This class will certainly be a singleton since the 
plug-ins representing the tools available should not be lost if a new 
instance of the plug-in manager is created. 
3. For each case of the conditional, define a plug-in object associated with 
the given tool. This plug-in object should be created and registered 
automatically when the tool it represents is loaded, and it should be 
unregistered if and when the tool becomes unavailable. Sometimes 
information from the tool client should be passed to the tool. The cur- 
rent tool client can be passed as argument when the tool is invoked. 
4. Transform the entire conditional expression into a query to the tool 
manager object. This query should return a tool associated with the 
query and invoke it to access the wished functionality. 
5. Remove any tool client actions that directly activate tools. This behav- 
ior is now the responsibility of the plug-in manager. 
The client or the plug-in object may have the responsibility to invoke a 
tool. It is better to let the plug-in object have this responsibility (because it 
already holds the responsibility of representing how to represent the tools) 
and let the clients just say that they need a tool action. 
In Squeak [Inga97], the Fi 1 eLi st is a tool that allows the loading of differ- 
ent kinds of files, such as Smalltalk code, JPEG images, MIDI files, HTML, 
and so on. Depending on the suffix of the selected file, the FileLi st pro- 
poses different actions to the user. We show in the example the loading of 
the different files depending on their format. 
Before 
The Fi l eLi st implementation creates different menu items representing 
the different possible actions depending on the suffix of the files. The dy- 
namic part of the menu is defined in the method menusForFi l eEnding:, 
which takes a file suffix as its argument and returns a menu item contain- 
ing the label of the menu item and the name of the corresponding method 
that should be invoked on the F i 1 eLi s t object. 
Fi I eLi st>>menusForFi I eEndi ng: suffix 
(suffix = 'jpg') ifTrue: 
[^Menultem label:'open image in a window'. 
selector: #openlmagelnWi ndow]. 

246 
C H A P T E R 1 0 Transform Conditionals to Polymorphism 
PATTERN 10.6 continued 
(suffix = morph') ifTrue: 
[^Menultem label : 
load as morph'. 
selector: #openMorphFromFile]. 
(suffix = mid') ifTrue: 
[^Menultem label: 
play midi file'. 
selector: #playMidiFile]. 
(suffix = 
st') ifTrue: 
[^Menultem label: 
fileln'. 
selector: #fi I elnSelection]. 
(suffix = 
swf') ifTrue: 
[^Menultem label : 
open as Flash'. 
selector: #openAsFl ash]. 
(suffix = 3ds') ifTrue: 
[^Menultem label: 
Open 3DS file'. 
selector: #open3DSFi le]. 
(suffix - 
wrl') ifTrue: 
[^Menultem label: 
open in Wonderland'. 
selector: #openVRMLFi I e]. 
(suffix = 
html') ifTrue: 
[^Menultem label: 
open in html browser'. 
selector: #openlnBrowser]. 
(suffix = *') ifTrue: 
[^Menultem label : 
generate HTML'. 
selector: #renderFi I e]. 
The methods whose selectors are associated in the menu are imple- 
mented in the Fi ] eLi st class.We give two examples here. First the method 
checks if the tool it needs is available. If not, it generates a beep; otherwise 
the corresponding tool is created and then used to handle the selected file. 
Fi I eLi st>>open InBrowser 
Smalltalk at: #Scamper ifAbsent: [^ self beep]. 
Scamper openOnUrl: (directory url , fileName encodeForHTTP) 
Fi I eLi st>>openVRMLFi I e 
scene I 
Smalltalk at: #Wonderland ifAbsent: [^ self beep]. 
scene := Wonderland new. 
scene makeActorFromVRML: self ful IName. 

P A T T E R N 10.6 Transform Conditionals into Registration 
24]? 
After 
The solution is to give each tool the responsibility to register itself and let 
the Fi ] eLi st query the registry of available tools to find which tool can be 
invoked. 
Step 1. The solution is to first create the class Tool P1 ugi n representing the 
registration of a given tool. Here we store the suffix files, the menu label, 
and the action to be performed when the tools will be invoked. 
Object subclass: #ToolPlugin 
instanceVariableNames: 'fileSuffix menuLabelName blockToOpen ' 
Step 2. Then the class PluginManager is defined. It defines a structure to 
hold the registered tools and defines behavior to add, remove, and find reg- 
istered tools. 
Object subclass: #PluginManager 
instanceVariableNames: 'plugins ' 
P1 ugi nManager>>i ni ti al i ze 
plugins := OrderedCollection new. 
PluginManager>>addPlugin : aPlugin 
plugins add: aRegistree 
P1 ugi nManager>>removePl ugi n: aBl ock 
(plugins select: aBlock) copy 
do: [:eachl plugins remove: each] 
PluginManager>>findTool For: aSuffix 
"return a registree of a tool being able to treat file of format 
aSuffix" 
^ plugins 
detect: [:each I each suffix = aSuffix] 
i fNone: [nil] 
Note that the fi ndTool For: method could take a block to select which of 
the plug-in objects satisfies it and that it could return a list of plug-ins rep- 
resenting all the tools currently able to treat a given file format. 

248 
C H A P T E R 1 0 Transform Conditionals to Polymorphism 
PATTERN 
1 0.6 continued 
Step 3. Then the tools should register themselves when they are loaded in 
memory. Here we present two registrations, showing that a plug-in object 
is created for each tool. As the tools need some information from the 
Fi ] eLi st object such as the filename or the directory, the action that has to 
be performed takes as a parameter the instance of the Fi 1 eLi st object that 
invokes it ([: fi 1 eLi st ] in the following code). 
In Squeak, when a class specifies a class (static) i ni t i a lize method, 
this method is invoked once the class is loaded in memory. We then spe- 
cialize the class methods i ni ti al i ze on the classes Scamper and Wonderl and 
to invoke the class methods tool Regi strati on defined below: 
Scamper cl ass>>tool Registration 
P1 ugi nManager uniquelnstance 
addPlugin: 
(Tool P1 ugin 
forFileSuffix: 
'html' 
openi ngBl ock: 
[:fileList 
self openOnUrl : 
(fileList directory url , 
fi I eLi st fi I eName encodeForHTTP) ] 
menuLabelName: 'open in html browser') 
Wonderl and cl ass>>tool Registration 
P1 ugi nManager uniquelnstance 
addPlugin: 
(Tool P1 ugin 
forFileSuffix: 
'wrl' 
openingBl ock: 
[:fileList 
I 
I scene I 
scene := self new. 
scene makeActorFromVRML: fi leLi st ful IName] 
menuLabelName: 'open in Wonderland') 
In Squeak, when a class is removed from the system, it receives the 
message removeFromSystenx Here we specialize this method for every tool 
so that it can unregister itself: 

P A T T E R N 10.6 Transform Conditionals into Registration 
249 
Trade-offs 
Scamper cl ass>>removeFromSystem 
super removeFromSystem. 
PluginManager uniquelnstance 
removePlugin: [:plugin i plugin forFileSuffix = 'html'] 
Wonderl and cl ass>>removeFromSystem 
super removeFromSystem. 
P1 ugi nManager uniquelnstance 
removePlugin: [:plugin i plugin forFileSuffix- 
'wrl'] 
Step 4. The FileList object now has to use the Tool sManagerto identify the 
right plug-in object depending on the suffix of the selected file. Then if a 
tool is available for the given suffix, it creates a menu item specifying that 
the FileList has to be passed as argument of the action block associated 
with the tool. If there is no tool, a special menu is created whose action is to 
do nothing. 
Fi I eLi st>>i temsForFi I eEndi ng: suffix 
I plugin i 
plugin := PluginManager uniquelnstance 
findToolFor: suffix ifAbsent: [nil]. 
^ plugins isNil 
ifFalse: 
[Menu label: (plugin menuLabelName) 
actionBlock: 
(plugin openingBlock) 
withParameter: self] 
ifTrue: [ErrorMenu new 
label: 'no tool available for the suffix ', suffix] 
Pros 
9 By applying Transform Conditionals into Registration you obtain a sys- 
tem that is both dynamic and flexible. New tools can be added without 
impacting tool clients. 
9 Tool clients no longer have to check whether a given tool is available. The 
registration mechanism ensures you that the action can be performed. 
9 The interaction protocol between tools and tool clients is now normal- 
ized. 

250 
C H A P T E R 1 0 Transform Conditionals to Polymorphism 
Related 
Patterns 
PATTERN 
10.6 continued 
Cons 
9 You have to define two new classes, one for the object representing tool 
representation (plug-in) and one for the object managing the registered 
tools (plug-in manager). 
Difficulties 
While transforming a branch of the conditional into a plug-in object, 
you will have to define an action associated with the tools via the plug- 
in object. To ensure a clear separation and full dynamic registration, 
this action should be defined on the tool and not anymore on the tool 
client. However, as the tool may need some information from the tool 
client, the tool client should be passed to the tool as a~arameter when 
the action is invoked. This changes the protocol between the tool and 
the tool client from a single invocation on the tool client to a method 
invocation to the tool with an extra parameter. This also implies that in 
some cases the tool client class has to define new public or friend meth- 
ods to allow the tools to access the tool client's data. 
If each single conditional branch is associated only with a single tool, 
only one plug-in object is needed. However, if the same tool can be 
called in different ways, we will have to create multiple plug-in objects. 
When the Legacy Solution Is the Solution 
If there is only a single tool client class, if all the tools are always avail- 
able, and if you will never add or remove a tool at run time, a condi- 
tional is simpler. 
Both Transform Conditionals into Registration and Transform Client Type 
Checks (Pattern 10.2) eliminate conditional expressions that decide which 
method should be invoked on which object. The key difference between 
the two patterns is that Transform Client Type Checks moves behavior 
from the client to the service provider, whereas Transform Conditionals 
into Registration deals with behavior that cannot be moved because it is 
implemented by an external tool. 

P A T T E R N 10.6 Transform Conditionals into Registration 
251 
Script: 
Identifying 
Simulated 
Switches 
in C++ 
This perl script searches the methods in C++ files and lists the occurrences 
of statements used to simulate switch statements with if-then-else, that is, 
matching the following expression: elseXif where X can be replaced by {, / / 
... or some white space including carriage return. 
#!/opt/lo 
$/= ,.., 
# new rec 
$elselfPa 
$ l i necoun 
whi le (<> 
s/(//.* 
$Ic : 
( 
cal/bi n/perl 
ord delim., 
ttern = 'else[\s\n]*{?[\s\n]*if'; 
t= 
i; 
){ 
)//g; # remove C++ style comments 
split /\n/) - I; # count lines 
if(/$elselfPattern/) { 
# count # of lines until first 
# occurrence of "else if" 
$temp = join(","$' ,$&) ; 
$I = $1inecount + split(/\n/,$temp) - I; 
# count the occurrences of else-if pairs, 
# flag the positions for an eventual printout 
$swc = s/(else)([\s\n]*{?[\s\n]*if) 
/$1\n 
* HERE *$2/g; 
printf "\n>os: Statement with 
>o2d else-if's, 
first at: >od", 
SARGV, $swc, $I; 
} 
$1inecount += $Ic; 
if(eof) 
{ 
close ARGV; 
$1inecount = O; 
print "\n" ; 
} 

APPENDIX 
Thumbnail Patterns 
There are many patterns that are not specifically concerned with reengi- 
neering, but are still relevant to the reengineering process. In this appendix 
we have listed only those patterns that are specifically referred to at some 
point in this book. We have grouped them into the following three cate- 
gories: 
Testing patterns. These patterns help you to focus your testing efforts. 
Our principal source is a pattern language by DeLano and Rising 
[DeLa98], although of course a vast literature is available on the subject. 
Binder, for example, devotes an entire book to the subject [Bind99]. 
Refactoring patterns. These patterns focus on individual refactoring 
steps that you might apply during a reengineering project, or that you 
might just as well apply during any forward engineering project. Our 
principal sources are Fowler et al. [Fowl99], and Roberts's Ph.D. thesis 
[Robe99]. 
Design patterns. Very frequently the result of a reengineering operation 
is to put a particular design pattern into place. Here we remind you of 
some of the most common design patterns that pop up in a reengineer- 
ing context. Our main source is, of course, the Design Patterns book 
[Gamm95]. 
PATTERN A.1 
Testing Patterns 
Retest Persistent Problems 
Problem: How do you know what areas of the system should receive con- 
centrated testing, irrespective of the features being implemented? 
Solution: Keep a list of persistent problem areas and test cases to verify 
them, not just for resolving the current problems but also for use in subse- 
quent testing. Test these areas thoroughly, even if there are no new features 
253 

254 
A P P E N D IX ThumbnailPatterns 
going into them. Retest regularly, even one last time before the release goes 
out the door. 
Source: [DeLa98] 
Referenced from: Regression Test after Every Change (Pattern 7.6) 
PATTERN A.2 
PATTERN A.3 
Test Fuzzy Features 
Problem: How can possible problem areas of the system be pinpointed so 
that the most problems can be found in the least amount of time? 
Solution: Study the documentation available on the system. Look for areas 
that seems ambiguous or ill defined. Write test plans that cover these areas 
more thoroughly and concentrate testing in these areas. If designers can 
tell you all about a feature, it probably works. It's what they can't tell you 
that needs attention during testing. 
Source: [DeLa98] 
Referenced from: Grow Your Test Base Incrementally (Pattern 6.2) 
Test Old Bugs 
Problem: What areas of the system should be targeted for testing so that 
the most problems can be found in the least amount of time? 
Solution: Examine problem reports from previous releases to help select 
test cases. Since it would be inefficient to test for all old problems, look at 
problems reported after the last valid snapshot of the system. Categorize 
problem reports to see if a trend is determined that could be used for addi- 
tional testing. 
Source: [DeLa98] 
Referenced from: Grow Your Test Base Incrementally (Pattern 6.2) 
PATTERN A.4 
Refactorings 
Encapsulate Field 
Also Known As: Abstract Instance Variable [Robe99] 
Intent: There is a public field. Make it private and provide accessors. 
Source: [Fowl99] 
Referenced from: Eliminate Navigation Code (Pattern 9.2) 

Refactorings 255 
PATTERN A.5 
Extract Method 
Intent: You have a code fragment that stands on its own. Turn the fragment 
into a method whose name explains the purpose of the method. 
Source: [Fowl99] 
Referenced from: Refactor to Understand (Pattern 5.2), Visualize Code as 
Dotplots (Pattern 8.2), Move Behavior Close to Data (Pattern 9.1) 
PATTERN A.6 
Move Method 
Intent: A method is, or will be, using or used by more features of another 
class than the class on which it is defined. Create a new method with a sim- 
ilar body in the class it uses most. Either turn the old method into a simple 
delegation, or remove it altogether. 
Source: [Fowl99] 
Referenced from: Refactor to Understand (Pattern 5.2), Move Behavior 
Close to Data (Pattern 9.1) 
PATTERN A.7 
Rename Attribute 
Intent: Rename an instance variable and update all references to it. 
Source: [Robe99] 
Referenced from: Refactor to Understand (Pattern 5.2) 
PATTERN A.8 
Rename Method 
Intent: The name of a method does not reveal its purpose. Change the 
name of the method. 
Source: [Fowl99] 
Referenced from: Refactor to Understand (Pattern 5.2) 
PATTERN A.9 
Replace Conditional with Polymorphism 
Intent: You have a conditional that chooses different behavior depending 
on the type of an object. Move each leg of the conditional to an overriding 
method in a subclass. Make the original method abstract. 
Source: [Fowl99] 
Referenced from: Transform Client Type Checks (Pattern 10.2) 

256 
A P P E N D I X Thumbnail Patterns 
Design Patterns 
PAT T E R N A.10 Abstract Factory 
Intent: Provide an interface for creating families of related or dependent 
objects without specifying their concrete classes. 
5ource: [Gamm95] 
Referenced from: Look for the Contracts (Pattern 5.4), Transform Client 
Type Checks (Pattern 10.2) 
PATT E R N A.1 1 Adapter 
Intent: Convert the interface of a class into another interface clients ex- 
pect. Adapter lets classes work together that couldn't otherwise because of 
incompatible interfaces. 
5ource: [Gamm95] 
Referenced from: Present the Right Interface (Pattern 7.8), Move Behavior 
Close to Data (Pattern 9.1) 
PAT T E R N A.12 Facade 
Intent: Provide a unified interface to a set of interfaces in a subsystem. 
Facade defines a higher-level interface that makes the subsystem easier to 
use. 
5ource: [Gamm95] 
Referenced from: Eliminate Navigation Code (Pattern 9.2), Split Up God 
Class (Pattern 9.3) 
PAT T E R N A.13 Factory Method 
Intent: Define an interface for creating an object, but let subclasses decide 
which class to instantiate. Factory Method lets a class defer instantiation to 
subclasses. 
Source: [Gamm95] 
Referenced from: Look for the Contracts (Pattern 5.4) 
PATTERN A.14 Flyweight 
Intent: Use sharing to support large numbers of fine-grained objects 
efficiently. 
Source: [Gamm95] 

Design Patterns 257 
Referenced from: Speculate about Design (Pattern 4.2) 
PATTERN A.15 Null Object 
Intent: A Null Object provides a surrogate for another object that shares 
the same interface but does nothing. Thus, the Null Object encapsulates 
the implementation decisions of how to do nothing and hides those details 
from its collaborators. 
Source: [Woo198] 
Referenced from: Introduce Null Object (Pattern 10.5) 
PATTERN A.16 Quantity 
Problem: Representing a value such as 6 feet or $5. 
Solution: Use a quantity type that includes both the amount and the unit. 
Currencies are a kind of unit. 
Source: [Fowl97] 
Referenced from: Analyze the Persistent Data (Pattern 4.1) 
PAT T E R N A.17 Singleton 
Intent: Ensure a class has only one instance, and provide a global point of 
access to it. 
Source: [Gamm95] 
Referenced from: Read M1 the Code in One Hour (Pattern 3.2) 
PATTERN A.18 State 
Intent: M]ow an object to alter its behavior when its internal state changes. 
The object will appear to change its class. 
Source: [Gamm95] 
Referenced from: Factor Out State (Pattern 10.3) 
PAT T E R N A.19 State Patterns 
Intent: The State Patterns pattern language refines and clarifies the State 
Pattern. 
Source: [Dyso97] 
Referenced from: Factor Out State (Pattern 10.3) 

258 
A P P E N D IX ThumbnailPatterns 
PATTERN A.20 Strategy 
Intent: Define a family of algorithms, encapsulate each one in a separate 
class, and define each class with the same interface so they can be inter- 
changeable. Strategy lets the algorithm vary independently from clients 
that use it. 
Source: [Gamm95] 
Referenced from: Factor Out Strategy (Pattern 10.4) 
PAT T E R N A.21 Template Method 
Intent: Define the skeleton of an algorithm in an operation, deferring some 
steps to subclasses. Template Method lets subclasses redefine certain steps 
of an algorithm without changing the algorithm's structure. 
Source: [Gamm95] 
Referenced from: Look for the Contracts (Pattern 5.4) 
PATT E R N A.22 Visitor 
Intent: Represent an operation to be performed on the elements of an 
object structure. Visitor lets you define a new operation without changing 
the classes of the elements on which it operates. 
Source: [Gamm95] 
Referenced from: Move Behavior Close to Data (Pattern 9.1) 

References 
[Alpe98] 
[Arno92] 
[Bake92] 
[Ball96] 
[Barn94] 
[Bass98] 
[Beck97] 
[Beck98] 
[Beck99] 
[Beck00] 
[Beck01] 
[Beed00] 
[Bell97] 
[Benn99] 
[Bigg891 
Alpert, Sherman R., Kyle Brown, and BobbyWoolf, The Design Patterns Small- 
talk Companion, Addison-Wesley, 1998. 
Arnold, Robert S., Software Reengineering, IEEE, 1992. 
Baker, Brenda S., 'A Program for Identifying Duplicated Code," Computing 
Science and Statistics, vol. 24, 1992, pp. 49-57. 
Ball, T., and S. Eick, "Software Visualization in the Large," IEEE Computer, 
1996, pp. 33-43. 
Barnard, Jack, and Art Price, "Managing Code Inspection Information," 
IEEE Software, vol. 11, no. 2, March 1994, pp. 59-69. 
Bass, Len, Paul Clements, and Rick Kazman, Software Architecture in Prac- 
tice, Addison-Wesley, 1998. 
Beck, Kent, Smalltalk Best Practice Patterns, Prentice Hall, 1997. 
Beck, Kent, and Erich Gamma, "Test Infected: Programmers Love Writing 
Tests," JUnit documentation, 1998. 
Beck, Kent, Kent Beck's Guide to Better Smalltalk, Sigs Books, 1999. 
Beck, Kent, Extreme Programming Explained: Embrace Change, Addison- 
Wesley, 2000. 
Beck, Kent, and Martin Fowler, Planning Extreme Programming, Addison- 
Wesley, 2001. 
Beedle, Mike, Martine Devos, Yonat Sharon, Ken Schwaber, and Jeff Suther- 
land, "SCRUM: A Pattern Language for Hyperproductive Software Devel- 
opment," Pattern Languages of Program Design 4, Neil Harrison, Brian 
Foote, and Hans Rohnert (Eds.), pp. 637-652, Addison-Wesley, 2000. 
Bellin, David, and Susan Suchman Simone, The CRC Card Book, Addison- 
Wesley, 1997. 
Bennett, Simon, Steve McRobb, and Ray Farmer, Object-Oriented System 
Analysis and Design Using UML, McGraw Hill, 1999. 
Biggerstaff, T. J., "Design Recovery for Maintenance and Reuse," IEEE Com- 
puter, October 1989, pp. 36-49. 
259 

260 
REFERENCES 
[Bigg93] 
[Bigg94] 
[Bind99] 
[Blah98] 
[Boeh881 
[Booc94] 
[Bray95] 
[Brod95] 
[Broo75] 
[Broo87] 
[Brow96a] 
[Brow96b] 
[Brow98] 
[Busc96] 
[Came96] 
[Chik92] 
[Cock93] 
[Conw681 
Biggerstaff, Ted J., Bharat G. Mittbander, and Dallas Webster, "The Concept 
Assignment Problem in Program Understanding," Proceedings of the 15th 
International Conference on Software Engineering (ICSE 1993), IEEE, 1993. 
Biggerstaff, Ted J., Bharat G. Mittbander, and Dallas E. Webster, "Program 
Understanding and the Concept Assignment Problem," Communications 
of the ACM, vol. 37, no. 5, May 1994, pp. 72-82. 
Binder, Robert V., Testing Object-Oriented Systems: Models, Patterns, and 
Tools, Addison-Wesley, Object Technology Series, 1999. 
Blaha, M., D. LaPlant, and E. Marvak, "Requirements for Repository Soft- 
ware," Proceedings ofWCRE'98, IEEE, 1998, pp. 164-173. 
Boehm, Barry W., 'A Spiral Model of Software Development and Enhance- 
ment," IEEE Computer, vol. 21, no. 5, 1988, pp. 61-72. 
Booch, Grady, Object Oriented Analysis and Design with Applications (2nd 
edition), Benjamin Cummings, 1994. 
Bray, Olin, and Michael M. Hess, "Reengineering a Configuration Manage- 
ment System," IEEE Software, vol. 12, no. 1, January 1995, pp. 55-63. 
Brodie, Michael L., and Michael Stonebraker, Migrating Legacy Systems, 
Morgan Kaufmann, 1995. 
Brooks, Frederick P., The Mythical Man-Month, Addison-Wesley, 1975. 
Brooks, Frederick P., "No Silver Bullet," IEEE Computer, vol. 20, no. 4, April 
1987, pp. 10-19. 
Brown, Kyle, "Design Reverse-Engineering and Automated Design Pattern 
Detection in Smalltalk," Ph.D. thesis, North Carolina State University, 1996. 
Brown, Kyle, and Bruce G. Whitenack, "Crossing Chasms: A Pattern Lan- 
guage for Object-RDBMS Integration," Pattern Languages of Program 
Design 2, John M. Vlissides, James O. Coplien, and Norman L. Kerth (Eds.), 
pp. 227-238, Addison-Wesley, 1996. 
Brown, William J., Raphael C. Malveau, Hays W. McCormick, III, and 
Thomas J. Mowbray, '~ntiPatterns," John Wiley, 1998. 
Buschmann, Frank, Regine Meunier, Hans Rohnert, Peter Sommerlad, and 
Michael Stad, Pattern-Oriented Software Architecture--A System of Pat- 
terns, John Wiley, 1996. 
Cameron, Debra, Bill Rosenblatt, and Eric Raymond, Learning GNU Emacs 
(2nd edition), O'Reilly, 1996. 
Chikofsky, Elliot J., and James H. Cross, II, "Reverse Engineering and 
Design Recovery: A Taxonomy," Software Reengineering, Robert S. Arnold 
(Ed.), pp. 54-58, IEEE, 1992. 
Cockburn, Alistair, "The Impact of Object-Orientation on Application De- 
velopment,'! IBM Systems Journal, vol. 32, no. 3, March 1993, pp. 420-444. 
Conway, Melvin E., "How Do Committees Invent?," Datamation, vol. 14, 
no. 4, April 1968, pp. 28-31. 

REFERENCES 
261 
[CookO1] 
[Cop192] 
[Cop195] 
[Corb89] 
[Davi95] 
[DeLa98] 
[DeMa82] 
[DeMa99] 
[Deme97] 
[Deme99a] 
[Deme99b] 
[Deme00] 
[Duca99] 
[Duca00] 
Cook, Stephen, Rachel Harrison, and Brian Ritchie, 'Tkssessing the Evolu- 
tion of Financial Management Information Systems," ECOOP 2001 Work- 
shop Reader, LNCS 30, Springer-Verlag, 2001. 
Coplien, James O., Advanced C++: Programming Styles and Idioms, Addison- 
Wesley, 1992. 
Coplien, James O., '7~ Development Process Generative Pattern Language," 
Pattern Languages of Program Design, James O. Coplien, and Douglas 
Schmidt (Eds.), pp. 183-237, Addison-Wesley, 1995. 
Corbi, T. A., "Program Understanding: Challenge for the 1990's," IBM Sys- 
temsJournal, vol. 28, no. 2, 1989, pp. 294-306, republished in [Arno92]. 
Davis, Alan Mark, 201 Principles of Software Development, McGraw-Hill, 
1995. 
DeLano, David E., and Linda Rising, "Patterns for System Testing," Pattern 
Languages of Program Design 3, Robert Martin, Dirk Riehle, and Frank 
Buschmann (Eds.), Addison-Welsey, 1998, pp. 503-527. 
DeMarco, Tom, Controlling Software Projects, Yourdon Press, 1982. 
DeMarco, Tom, and Timothy Lister, Peopleware, Productive Projects and 
Teams (2nd edition), Dorset House, 1999. 
Demeyer, Serge, and Harald Gall (Eds.), Proceedings of the ESEC/FSE Work- 
shop on Object-Oriented Re-engineering, Technical University of Vienna, 
Information Systems Institute, Distributed Systems Group, TUV-1841-97- 
10, September 1997. 
Demeyer, Serge, and St6phane Ducasse, "Metrics, Do They Really Help?," 
Proceedings LMO'99 (Languages et Modbles ~ Objets), Jacques Malenfant 
(Ed.), HERMES Science Publications, Paris, 1999, pp. 69-82. 
Demeyer, Serge, St6phane Ducasse, and Michele Lanza, 'Tk Hybrid Reverse 
Engineering Platform Combining Metrics and Program Visualization," 
Proceedings WCRE'99 (6th Working Conference on Reverse Engineering), 
Francoise Balmas, Mike Blaha, and Spencer Rugaber (Eds.), IEEE, October 
1999. 
Demeyer, Serge, St6phane Ducasse, and Oscar Nierstrasz, "Finding Refac- 
torings via Change Metrics," Proceedings of OOPSLA'2000, ACM SIGPLAN 
Notices, 2000, pp. 166-178. 
Ducasse, St6phane, Matthias Rieger, and Serge Demeyer, 'Tk Language 
Independent Approach for Detecting Duplicated Code," Proceedings 
ICSM'99 (International Conference on Software Maintenance), Hongji 
Yang, and Lee White (Eds.), IEEE, September 1999, pp. 109-118. 
Ducasse, St6phane, Michele Lanza, and Sander Tichelaar, "Moose: An Ex- 
tensible Language-Independent Environment for Reengineering Object- 
Oriented Systems," Proceedings of the Second International Symposium on 
Constructing Software Engineering Tools (COSET2000), June 2000. 

262 
R E F E R E N C E S 
[Dyso97] 
[Fent96] 
[Fje179] 
[Flor97] 
[Foot00] 
[Fowl97] 
[Fowl99] 
[Fros94] 
[Gall98] 
[Gall99] 
[Gamm95] 
[Gilb93] 
[Glass97] 
[Gold95] 
[Hain96] 
[Harri96] 
Dyson, Paul, and Bruse Anderson, "State Patterns," Pattern Languages of 
Program Design 3, Robert Martin, Dirk Riehle, and Frank Buschmann (Eds.), 
Addison-Wesley, 1997. 
Fenton, Norman, and Shari Lawrence Pfleeger, Software Metrics: A Rigor- 
ous and Practical Approach (2nd edition), International Thomson Com- 
puter Press, London, UK, 1996. 
Fjeldstad, R. K., and W. T. Hamlen, "Application Program Maintenance 
Study: Report to Our Respondents," Proceedings of GUIDE 48, The Guide 
Corporation, 1979. 
Florijn, Gert, Marco Meijers, and Pieter van Winsen, "Tool Support for 
Object-Oriented Patterns," Proceedings ECOOP'97, Mehmet Aksit, and 
Satoshi Matsuoka (Eds.), LNCS 1241, Springer-Verlag, Jyvaskyla, Finland, 
June 1997, pp. 472-495. 
Foote, Brian, and Joseph W. Yoder, "Big Ball of Mud," Pattern Languages of 
Program Design, N. Harrison, B. Foote, and H. Rohnert (Eds.), pp. 654-692, 
Addison-Wesley, 2000. 
Fowler, Martin, Analysis Patterns: Reusable Objects Models, Addison-Wesley, 
1997. 
Fowler, Martin, Kent Beck, John Brant, William Opdyke, and Don Roberts, 
Refactoring: Improving the Design of Existing Code, Addison-Wesley, 1999. 
Frost, Stuart, "Modelling for the RDBMS Legacy," Object Magazine, Sep- 
tember 1994, pp. 43-51. 
Gall, Harald, Karin Hajek, and Mehdi Jazayeri, "Detection of Logical Cou- 
pling Based on Product Release History," Proceedings of the International 
Conference on Software Maintenance 1998 (ICSM'98), 1998, pp. 190-198. 
Gall, Harald, and Johannes Weidl, "Object-Model Driven Abstraction-to- 
Code Mapping," Proceedings of the 2nd Workshop on Object-Oriented 
Reengineering (WOOR 1999), Technical University of Vienna, Technical 
Report TUV-1841-99-13, 1999. 
Gamma, Erich, Richard Helm, Ralph Johnson, and John Vlissides, Design 
Patterns, Addison-Wesley, 1995. 
Gilb, Tom, and Dorothy Graham, Software Inspection, Addison-Wesley, 
1993. 
Glass, Robert L., Building Quality Software, Prentice Hall, 1997. 
Goldberg, Adele, and Kenneth S. Rubin, Succeeding with Objects: Decision 
Frameworks for Project Management, Addison-Wesley, 1995. 
Hainaut, J.-L., V. Englebert, J. Henrard, J.-M. Hick, and D. Roland, "Data- 
base Reverse Engineering: From Requirements to CARE Tools," Automated 
Software Engineering, vol. 3, no. 1-2, June 1996. 
Harrison, Neil B., "Organizational Patterns for Teams," Pattern Languages 
of Program Design 2, John M. Vlissides, James O. Coplien, and Norman L. 
Kerth (Eds.), pp. 345-352, Addison-Wesley, 1996. 

REFERENCES 
263 
[Helf95] 
[Inga97] 
[Jack00] 
[Jaco92] 
[Jaco97] 
[Jahn97] 
[Jaza99] 
[Jeff01] 
[Jerd96] 
[Kazm981 
[Kazm99] 
[Kel1981 
[KellO0] 
[Knut92] 
[Lagu97] 
Helfman, Jonathan, "Dotplot Patterns: A Literal Look at Pattern Languages," 
TAPOS, vol. 2, no. 1, 1995, pp. 31-41. 
Ingalls, Daniel, Ted Kaehler, John Maloney, Scott Wallace, and Alan Kay, 
"Back to the Future: The Story of Squeak, A Practical Smalltalk Written in 
Itself," Proceedings OOPSLA '97, ACM SIGPLAN Notices, vol. 21, no. 11, 
November 1997. 
Jackson, Daniel, and John Chapin, "Redesigning Air Traffic Control: An Ex- 
ercise in Software Design," IEEE Software, vol. 17, no. 3, May 2000, pp. 63-70. 
Jacobson, Ivar, Magnus Christerson, Patrik Jonsson, and Gunnar Over- 
gaard, Object-Oriented Software Engineering~A Use Case Driven Approach, 
Addison-Wesley/ACM Press, 1992. 
Jacobson, Ivar, Martin Griss, and Patrik Jonsson, Software Reuse, Addison- 
Wesley/ACM Press, 1997. 
Jahnke, Jens H., Wilhelm Sch~ifer, and Albert Zfindorf, "Generic Fuzzy Rea- 
soning Nets as a Basis of Reverse Engineering Relational Database Applica- 
tions," Proceedings ofESEC/FSE'97, LNCS, 1301, 1997, pp. 193-210. 
Jazayeri, Mehdi, Harald Gall, and Claudio Riva, "Visualizing Software Re- 
lease Histories: The Use of Color and Third Dimension," ICSM'99 Proceed- 
ings (International Conference on Software Maintenance), IEEE, 1999. 
Jeffries, Ron, Ann Anderson, and Chet Hendrickson, Extreme Program- 
ming Installed, Addison-Wesley, 2001. 
Jerding, Dean F., and John T. Stasko, "The Information Mural: Increasing 
Information Bandwidth in Visualizations," Technical Report GIT-GVU-96- 
25, Georgia Institute of Technology, October 1996. 
Kazman, Rick, and S. Jeromy Carriere, "View Extraction and View Fusion in 
Architectural Understanding," Proceedings of the 5th International Confer- 
ence on Software Reuse, Victoria, B.C., 1998. 
Kazman, Rick, and S. J. Carriere, "Playing Detective: Reconstructing Soft- 
ware Architecture from Available Evidence," Automated Software Engi- 
neering, April 1999. 
Keller, Wolfgang, and Jens Coldewey, 'Tkccessing Relational Databases: A 
Pattern Language," Pattern Languages of Program Design 3, Robert Martin, 
Dirk Riehle, and Frank Bushmann (Eds.), pp. 313-343, Addison-Wesley, 
1998. 
Keller, Wolfgang, "The Bridge to the New Town~A Legacy System Migra- 
tion Pattern," Proceedings of Europlop 2000, 2000. 
Knuth, Donald E., Literate Programming, Center for the Study of Language 
and Information, 1992. 
Lagu~, Bruno, Daniel Proulx, Ettore M. Merlo, Jean Mayrand, and John 
Hudepohl, 'Assessing the Benefits of Incorporating Function Clone Detec- 
tion in a Development Process," Proceedings of ICSM (International Con- 
ference on Software Maintenance), IEEE, 1997. 

264 
REFERENCES 
[Lanz99] 
[Lea96] 
[Lehm85] 
[Lieb88] 
[Lore94] 
[Love93] 
[Mayr96] 
[Meye96] 
[Meye98] 
[MullO0] 
[Murp97] 
[Nesi98] 
[Nie193] 
[Oca199] 
[Ocal00] 
[Opdy921 
[PelrO1] 
[Pree94] 
[Prem94] 
Lanza, Michele, "Combining Metrics and Graphs for Object Oriented 
Reverse Engineering," Master's thesis, University of Bern, October 1999. 
Lea, Doug, Concurrent Programming in ]aua, Design Principles and Pat- 
terns, Addison-Wesley, The Java Series, 1996. 
Lehman, M. M., and L. Belady, Program Euolution~Processes of Software 
Change, London Academic Press, 1985. 
Lieberherr, Karl ]., Ian M. Holland, and Arthur Riel, "Object-Oriented Pro- 
gramming: An Objective Sense of Style," Proceedings OOPSLA '88, ACM 
SIGPLANNotices, vol. 23, no. 11, November 1988, pp. 323-334. 
Lorenz, Mark, and ]eft Kidd, Object-Oriented Software Metrics: A Practical 
Guide, Prentice-Hall, 1994. 
Love, Tom, Object LessonsmLessons Learned in Object-Oriented Develop- 
ment Projects, SIGS Books, 1993. 
Mayrand, ]., C. Leblanc, and E. Merlo, "Experiment on the Automatic 
Detection of Function Clones in a Software System Using Metrics," Inter- 
national Conference on Software Systems Using Metrics, 1996, pp. 244-253. 
Meyers, Scott, More Effective C++, Addison-Wesley, 1996. 
Meyers, Scott, Effective C++ (2nd edition), Addison-Wesley, 1998. 
Mfiller, Hausi A., lens H. ]anhke, Dennis B. Smith, Margaret-Anne Storey, 
Scott R. Tilley, and Kenny Wong, "Reverse Engineering: A Roadmap," The 
Future of Software Engineering2000, A. Finkelstein (Ed.), ACM Press, 2000. 
Murphy, Gail C., and David Notkin, "Reengineering with Reflexion Models: 
A Case Study," IEEE Computer, vol. 8, 1997, pp. 29-36. 
Nesi, Paolo, "Managing OO Project Better," IEEE Software, July 1988. 
Nielsen, Jakob, Usability Engineering, Morgan Kaufmann, 1999. 
O'Callaghan, Alan, Ping Dai, and Ray Farmer, "Patterns for Change~Sam- 
ple Patterns from the ADAPTOR Pattern Language," Proceedings of Euro- 
plop 1999, 1999. 
O'Callaghan, Alan, "Patterns for Architectural Praxis," Proceedings of Euro- 
plop 2000, 2000. 
Opdyke, William E, "Refactoring Object-Oriented Frameworks," Ph.D. the- 
sis, University of Illinois, 1992. 
Pelrine, Joseph, and Alan Knight, Mastering ENVY~Developer, Cambridge 
University Press, 2001. 
Pree, Wolfgang, "Meta Patterns--A Means for Capturing the Essentials of 
Reusable Object-Oriented Design," Proceedings ECOOP'94, M. Tokoro and 
R. Pareschi (Eds.), LNCS 821, Springer-Verlag, Bologna, Italy, July 1994, 
pp. 150-162. 
Premerlani, William ]., and Michael R. Blaha, '~kn Approach for Reverse 
Engineering of Relational Databases," Communications of the ACM, vol. 37, 
no. 5, May 1994, pp. 42-49. 

REFERENCES 
265 
[Pres94] 
[Pust82] 
[Reen89] 
[Reen96] 
[Rich99] 
[Rieh98] 
[Rie196] 
[Risi00] 
[Robe97] 
[Robe99] 
[Robs91] 
[Ruga98] 
[Scha99] 
[Schm00] 
[Schn98] 
[Shar97] 
Pressman, Roger S., Software Engineering:A Practitioner's Approach, McGraw- 
Hill, 1994. 
Pustell, J., and E Kafatos, '~ High Speed, High Capacity Homology Matrix: 
Zooming through sv40 and Polyoma," Nucleid Acids Research, vol. 10, 
no. 15, 1982, pp. 4765-4782. 
Reenskaug, Trygve, and Anna Lise Skaar, '~n Environment for Literate 
Smalltalk Programming," Proceedings OOPSLA '89, ACM SIGPLAN Notices, 
vol. 24, no. 10, October 1989, pp. 337-346. 
Reenskaug, Trygve, Working with Objects: The OOram Software Engineer- 
ing Method, Manning Publications, 1996. 
Richner, Tamar, and St6phane Ducasse, "Recovering High-Level Views of 
Object-Oriented Applications from Static and Dynamic Information," Pro- 
ceedings ICSM'99 (International Conference on Software Maintenance), 
Hongji Yang and Lee White (Eds.), IEEE, September 1999, pp. 13-22. 
Riehle, Dirk, and Thomas Gross, "Role Model Based Framework Design 
and Integration," Proceedings OOPSLA '98 ACM SIGPLAN Notices, October 
1998, pp. 117-133. 
Riel, Arthur J., Object-Oriented Design Heuristics, Addison-Wesley, 1996. 
Rising, Linda, "Customer Interaction Patterns," Pattern Languages of Pro- 
gram Design 4, Neil Harrison, Brian Foote, and Hans Rohnert (Eds.), 
pp. 585-609, Addison-Wesley, 2000. 
Roberts, Don, John Brant, and Ralph E. Johnson, '7~ Refactoring Tool for 
Smalltalk," Theory and Practice of Object Systems (TAPOS), vol. 3, no. 4, 
1997, pp. 253-263. 
Roberts, Donald Bradley, "Practical Analysis for Refactoring," Ph.D. thesis, 
University of Illinois, 1999. 
Robson, D. J., K. H. Bennet, B. J. Cornelius, and M. Munro, "Approaches to 
Program Comprehension," Journal of Systems and Software, vol. 14, Febru- 
ary 1991, pp. 79-84, republished in [Arno92]. 
Rugaber, Spencer, and Jim White, "Restoring a Legacy: Lessons Learned," 
IEEE Software, vol. 15, no. 4, July 1998, pp. 28-33. 
Schauer, Reinhard, S6bastian Robitaille, Francois Martel, and Rudolf Keller, 
"Hot Spot Recovery in Object-Oriented Software with Inheritance and 
Composition Template Methods," Proceedings of the International Confer- 
ence on Software Maintenance (ICSM'99), IEEE, 1999. 
Schmidt, Douglas C., Michael Stal, Hans Rohnert, and Frank Buschmann, 
Pattern-Oriented Software Architecture Volume 2~Networked and Concur- 
rent Objects, John Wiley and Sons, 2000. 
Schneider, Geri, and Jason P. Winters, Applying Use Cases, Addison-Wesley, 
1998. 
Sharp, Alec, Smalltalk by Example, McGraw-Hill, 1997. 

266 
REFERENCES 
[Shaw96] 
[Snee99] 
[Somm96] 
[Stev98] 
[Stey96] 
[Tayl00] 
[Thom98] 
[Weid98] 
[Wirf90] 
[Wong95] 
[Woo1981 
[Wuyt98] 
[Your97] 
Shaw, Mary, and David Garlan, Software Architecture: Perspectives on an 
Emerging Discipline, Prentice-Hall, 1996. 
Sneed, Harry M., "Risks Involved in Reengineering Projects," Proceedings 
of the 6th Working Conference on Reverse Engineering (WCRE), IEEE, 1999. 
Sommerville, Ian, Software Engineering (5th edition), Addison-Wesley, 1996. 
Stevens, Perdita, and Rob Pooley, "System Reengineering Patterns," Pro- 
ceedings of FSE-6, ACM-SIGSOFT. 
Steyaert, Patrick, Carine Lucas, Kim Mens, and Theo D'Hondt, "Reuse Con- 
tracts: Managing the Evolution of Reusable Assets," Proceedings of OOPSLA 
'96 Conference, ACM Press, 1996, pp. 268-285. 
Taylor, Paul, "Capable, Productive, and Satisfied: Some Organizational Pat- 
terns for Protecting Productive People," Pattern Languages of Program 
Design, N. Harrison, B. Foote, and H. Rohnert (Eds.), pp. 611-636, Addison- 
Wesley, 2000. 
Thomsett, Rob, "The Year 2000 Bug: A Forgotten Lesson," IEEE Software, 
vol. 15, no. 4, July 1998, pp. 91-93,95. 
Weidl, Johannes, and Harald Gall, "Binding Object Models to Source Code" 
An Approach to Object-Oriented Rearchitecting," Proceedings of the 22nd 
Computer Software and Application Conference (COMPSAC 1998), IEEE, 
1998. 
Wirfs-Brock, Rebecca, Brian Wilkerson, and Lauren Wiener, Designing 
Object-Oriented Software, Prentice Hall, 1990. 
Wong, Kenny, Scott R. Tilley, Hausi A. Miiller, and Margaret-Anne D. Storey, 
"Structural Redocumentation: A Case Study," IEEE Software, vol. 12, no. 1, 
Jan 1995, pp. 46-54. 
Woolf, Bobby, "Null Object," Pattern Languages of Program Design 3, Rob- 
ert Martin, Dirk Riehle, and Frank Buschmann (Eds.), pp. 5-18, Addison- 
Wesley, 1998. 
Wuyts, Roel, "Declarative Reasoning about the Structure Object-Oriented 
Systems," Proceedings of the TOOLS USA '98 Conference, IEEE, 1998, 
pp. 112-124. 
Yourdon, Edward, Death March, Prentice Hall, 1997. 

Index 
A 
Abstract Factory (Pattern A.10), 
111,256 
activities in project plan, 31 
Ada 
detecting client type checks in, 
226 
detecting self type checks in, 219 
Adapter (Pattern A.11), 164, 193, 256 
Agree on Maxims (Pattern 2.1), 
18-19 
Alexander, Christopher, 9-10 
algorithms, white-box testing for, 
139 
Allen, Woody, 42 
Always Have a Running Version 
(Pattern 7.5) 
Build Confidence (Pattern 7.2) 
helped by, 158 
intent, 157 
main discussion, 157-159 
Migrate Systems Incrementally 
(Pattern 7.3) and, 148 
problem, 157-158 
rationale, 159 
Regression Test after Every 
Change (Pattern 7.6) with, 159 
related patterns, 159 
solution, 158 
steps, 158 
tests as precondition to, 123, 127 
trade-offs, 158 
Write Tests to Enable Evolution 
(Pattern 6.1) as prerequisite, 
127 
Analyze the Persistent Data (Pat- 
tern 4.1) 
as bottom-up method, 67, 75 
class diagram derivation, steps 
for, 69-73 
documentation by, 67-68 
example, 74-75 
incorporating associations, 
70-72 
incorporating inheritance, 70 
incorporating operations, 72-73 
intent, 68 
known uses, 76 
limited scope of, 73 
main discussion, 68-76 
preparing an initial model, 69-70 
problem, 68-69 
rationale, 75-76 
Read All the Code in One Hour 
(Pattern 3.2) as preparation 
for, 44 
refining the class diagram, 76 
repeated application of, 67 
Skim the Documentation (Pat- 
tern 3.3) as preparation for, 50 
solution, 69-73 
time required for, 67 
trade-offs, 73-74 
verifying the classes, 72 
what next, 76 
annotating code 
comment-based annotations, 
98-99, 101 
conventions for, 99 
eliminating annotations, 101 
granularity for, 100 
hints, 99-100 
method-based annotations, 99, 
102-103 
motivating programmers, 101 
at point where comment 
applies, 96 
risks of error introduction, 99, 
105 
updating annotations with 
answers, 100 
Appoint a Navigator (Pattern 2.2), 
19, 155 
architectural vision, maintaining, 
19 
architecture, Speculate about 
Architecture variation (Pat- 
tern 4.2), 79 
'~Arranging the furniture" pattern, 
106 
associations 
classes, 71 
complementary, merging, 71 
incorporating in class diagram, 
70-72 
multiplicities for, 72 
qualified, identifying, 72 
AST matching, 201-202 
attributes 
access sequences in navigation 
code, 200 
multiple methods switching on, 
218 
Rename Attribute (Pattern A.7), 
104, 255 
renaming to convey roles, 104 
self type checks and, 218 
automation, as property of well- 
designed tests, 124, 126, 127 
B 
Ball, T., 116 
Beck, Kent, 4, 20, 43, 136, 173 
behavior. See Move Behavior Close 
to Data (Pattern 9.1) 
Belady, L., 169 
"Big Ball of Mud," 213 
Binder, Robert V., 253 
Black-Box Testing pattern. See Test 
the Interface, Not the Imple- 
mentation (Pattern 6.4) 
Blob pattern. See Split Up God 
Class (Pattern 9.3) 
Boehm, Barry, 6 
bottlenecks, Split Up God Class 
(Pattern 9.3) and, 23 
bottom-up approach 
to design extraction, 83 
267 

268 
INDEX 
bottom-up approach (continued) 
to study of source code, 67 
white noise from, 83 
Brant, John, 106 
breakpoints for Step through the 
Execution (Pattern 5.3), 108 
"Bridge to the New Town, The," 
162. See also Make a Bridge 
to the New Town (Pattern 7.7) 
Brodie, Michael L., 162 
Brooks, Frederick P., 95, 157 
Brown, Kyle, 112-113 
bugs 
Chat with the Maintainers 
(Pattern 3.1) about, 32-33 
reengineering needed for, 3 
Build Confidence (Pattern 7.2) 
Always Have a Running Version 
(Pattern 7.5) and, 158 
intent, 151 
Involve the Users (Pattern 7.1) 
and, 148, 151,153 
as key motivation, 148 
main discussion, 151-153 
Make a Bridge to the New Town 
(Pattern 7.7) and, 153, 162 
Migrate Systems Incrementally 
(Pattern 7.3) and, 148 
Most Valuable First pattern 
and, 22 
for overcoming skepticism, 
148, 151 
problem, 151-152 
Prototype the Target Solution 
(Pattern 7.4) and, 153 
rationale, 153 
Regression Test after Every 
Change (Pattern 7.6) and, 159 
related patterns, 153 
risk minimized by, 148 
solution, 152 
trade-offs, 152 
building the system, Do a Mock 
Installation (Pattern 3.5) to 
ensure ability, 58-63 
business model 
need for agreement on, 19 
understanding customer's, 21 
business objects, Speculate about 
Business Objects variation 
(Pattern 4.2), 78 
business rules. See Record Business 
Rules as Tests (Pattern 6.5) 
r 
C++ 
detecting client type checks in, 
226 
detecting self type checks in, 219 
perl script for identifying simu- 
lated switches in, 251 
candidate keys, determining, 69 
case statements 
flexibility lost by, 215 
programming languages and, 
216 
responsibilities assumed by, 215 
See also Transform Conditionals 
to Polymorphism 
change logs/change requests 
concentration of software 
defects and, 22 
for determining valuable arti- 
facts, 21 
fixing unstable design and, 117 
Chat with the Maintainers (Pattern 
3.1) 
after Do a Mock Installation 
(Pattern 3.5), 62 
after Interview during Demo 
(Pattern 3.4), 57, 58 
after Skim the Documentation 
(Pattern 3.3), 50 
for determining causes of 
instability, 117 
example, 34-35 
intent, 31 
known uses, 36-37 
main discussion, 31-37 
as maintainer-oriented meeting, 
36 
problem, 31-32 
questions to ask, 32-33 
rationale, 35-36 
Read All the Code in One Hour 
(Pattern 3.2) and, 40, 43 
related patterns, 37 
solution, 32-33 
trade-offs, 33-34 
verifying information gained, 37 
what next, 37 
checkers graph for class size over- 
view, 88-89 
Chicken Little pattern. See Migrate 
Systems Incrementally (Pat- 
tern 7.3) 
Chikofsky, Elliot I., 5, 9 
class diagram 
adapting based on mismatches, 
78 
encapsulation of data and, 
?5-?6 
incorporating associations, 
?0-?2 
incorporating inheritance, 70 
incorporating operations, 72-73 
initial model for, 69-?0 
maintaining consistency in, 79 
refining, 76 
steps for deriving, 69-73 
steps for refining, ??-?8 
trade-offs, 73-74 
verifying the classes, 72 
See also Analyze the Persistent 
Data (Pattern 4.1); Speculate 
about Design (Pattern 4.2) 
classes 
analyzing inheritance, 89-90 
association classes, 71 
configuration classes, 194 
data providers, 193 
describing plug-in manager, 
245 
describing plug-in objects, 
243-244 
god classes, 188-189, 208-213 
improving extensibility of, 
217-225, 234-243 
Look for the Contracts (Pattern 
5.4), 73, 76, 97, 109-113, 117 
mapping classes, 194 
measuring size of, 88-89 
Read All the Code in One Hour 
(Pattern 3.2) and, 39 
renaming to convey purpose, 105 
Split Up God Class (Pattern 9.3), 
23, 189,208-213 
static structure vs. dynamic 
behavior, 96 
super calls and assumptions 
about subclasses and, 112 
utility classes, 189 
client. See customer 
client type checks. See Transform 
Client Type Checks (Pattern 
10.2) 
coarse-grained architectural prob- 
lems, 8 
code 
annotating, 96, 98-100 
Chat with the Maintainers 
(Pattern 3.1) about, 33 
Compare Code Mechanically 
(Pattern 8.1), 175-180, 208 
duplicated, 3-4, 105, 172-185 
ownership and refactoring, 106 
Read All the Code in One Hour 
(Pattern 3.2), 30, 37, 38-44, 
50, 53, 58 
Refactor to Understand (Pattern 
5.2), 96-97, 103-107, 144, 170 
Tie Code and Questions (Pattern 
5.1), 96, 98-103, 106, 107, 108, 
144 
top-down vs. bottom-up study 
of, 67 
Use Profiler before Optimizing 
(Pattern 7.12), 169-170 
Visualize Code as Dotplots 
(Pattern 8.2), 180-185 
Write Tests to Understand 
(Pattern 6.6), 97, 106, 109, 
122-123, 130, 142-144 

IN D E X 
269 
See also Detecting Duplicated 
Code 
code review. See Read All the Code 
in One Hour (Pattern 3.2) 
code smells 
If It Ain't Broke, Don't Fix It 
(Pattern 2.6) and, 24 
recognizing, 38 
reengineering needed for, 3-4 
reporting, 38 
CodeCrawler tool, 88, 93 
coding idioms, Read All the Code 
in One Hour (Pattern 3.2) 
and, 39 
coding styles, Read All the Code 
in One Hour (Pattern 3.2) 
and, 39 
comments 
annotations based on, 96, 98-99 
misleading, 39, 40, 50 
motivating programmers to 
write, 101 
Read All the Code in One Hour 
(Pattern 3.2) and, 39, 40 
communication 
capturing database schema and 
improvement in, 73 
design structure and, 35 
effective, 66-67 
as force to be aware of, 17, 66-67 
language for, 66-67 
Tie Code and Questions (Pattern 
5.1) for improving, 100 
Compare Code Mechanically 
(Pattern 8.1) 
Eliminate Navigation Code 
(Pattern 9.2) and, 208 
example, 176-180 
intent, 175 
known uses, 180 
main discussion, 175-180 
perl script for, 177-180 
problem, 175 
solution, 175-176 
steps, 175 
trade-offs, 176 
variations, 175-176 
comparing versions or releases. 
See Learn from the Past 
(Pattern 5.5) 
complementary associations, 
merging, 71 
complexity 
flexibility vs., 25 
Keep It Simple (Pattern 2.7), 
24-25 
of legacy systems, 28 
Migrate Systems Incrementally 
(Pattern 7.3) for avoiding, 153 
Most Valuable First (Pattern 2.4) 
and, 22 
Step through the Execution (Pat- 
tern 5.3) and, 108 
concept assignment problem, 84 
conditionals. See Transform Condi- 
tionals to Polymorphism 
confidence 
Always Have a Running Version 
(Pattern 7.5) for, 157, 158 
Build Confidence (Pattern 7.2), 
22, 148, 151-153, 158, 159, 162 
built by testing, 123, 124, 
126-127 
Regression Test after Every 
Change (Pattern 7.6) for, 159 
configuration classes, 194 
Conserve Familiarity (Pattern 
7.11), 149, 168-169 
constructor calls, contracts and, 
111 
Continuous Integration pattern, 
159 
contracts 
defined, 110 
as implicit, 110 
Look for the Contracts (Pattern 
5.4), 109-113 
reuse contracts, 113 
validating, 113 
Conway's law, 35 
Cook, Stephen, 37 
credibility 
Do a Mock Installation (Pattern 
3.5) and, 60 
Interview during Demo (Pattern 
3.4) and, 53 
critical path, Most Valuable First 
(Pattern 2.4) and, 19, 23 
Cross, James H., 5, 9 
culture of continuous 
reengineering, need for, 5, 9 
customer 
changing perceptions of, 22 
determining what is valuable to, 
21-22 
expectations as forces, 122 
initial tasks most valuable to, 
20-21 
measurable goal of, 21 
selling tests to, 124 
stakeholders vs., 21 
test writing by, 140 
"Customer Interaction Patterns," 
57 
D 
data 
Analyze the Persistent Data 
(Pattern 4.1), 44, 50, 67, 68-76 
as deceptive, 66 
encapsulation of, 75-76 
interpreting, 88 
junk, 68, 73 
migrating to new system, 
160-162 
Move Behavior Close to Data 
(Pattern 9.1), 174, 185, 189, 
190-198, 199, 202, 210 
samples for verifying classes, 72 
data bridge, 161,162 
data containers 
defined, 187, 188 
detecting, 190 
forces, 187-188 
generated from database 
schema, 193 
god classes with, 189 
law of Demeter (LOD) violations 
and, 188 
polymorphism and, 190 
responsibilities lacking in, 188, 
190 
as sign of misplaced responsibil- 
ities, 186 
wrapping, 193 
See also Move Behavior Close to 
Data (Pattern 9.1) 
database schema 
data containers generated from, 
193 
improved communication and, 73 
polluted, 74 
See also class diagram 
Davis, Alan Mark, 160, 170 
debuggers, Step through the Exe- 
cution (Pattern 5.3) require- 
ments, 109 
DeLano, David E., 253 
demo. See Interview during Demo 
(Pattern 3.4) 
Demonstrate to Yourself variation 
(Pattern 3.4), 52 
Deprecate Obsolete Interfaces 
(Pattern 7.10), 149, 166-168 
DESEL (Designing for Ease of Sys- 
tem Evolution) project, 37 
design 
evolution of, 96 
implicit aspects of, 95-96, 97 
thumbnail patterns, 253, 
256-258 
design concept recovery. See Spec- 
ulate about Design (Pattern 
4.2) 
design exposure. See Detailed 
Model Capture 
design extraction tools, 111 
Design Patterns, 253 
Design Patterns Smalltalk Com- 
panion, 237, 239 
design problem identification. See 
Study the Exceptional Entities 
(Pattern 4.3) 

210 
INDEX 
DESIRE tool, 84 
Detailed Model Capture 
forces, 95-96 
Learn from the Past (Pattern 
5.5), 113-117 
Look for the Contracts (Pattern 
5.4), 109-113 
map of patterns, 94 
overview, 96-97 
Record Business Rules as Tests 
(Pattern 6.5) and, 97 
Refactor to Understand (Pattern 
5.2), 103-107 
Step through the Execution 
(Pattern 5.3), 107-109 
Test the Interface, Not the 
Implementation (Pattern 6.4) 
and, 97 
Tie Code and Questions (Pattern 
5.1), 98-103 
what next, 97 
See also specific patterns 
details, importance of, 95 
Detecting Duplicated Code 
Compare Code Mechanically 
(Pattern 8.1), 175-180 
Extract Method (Pattern A.5) 
and, 174 
forces, 173-174 
map of patterns, 172 
Move Behavior Close to Data 
(Pattern 9.1) and, 174 
overview, 174 
Transform Conditionals to Poly- 
morphism and, 174, 184, 185 
Visualize Code as Dotplots (Pat- 
tern 8.2), 180-185 
See also specific patterns 
developers 
Chat with the Maintainers 
(Pattern 3.1) about, 33 
departure of, need for 
reengineering and, 3 
as documentation audience, 44, 
46, 49 
duplicated code known by, 174 
team organization and design 
structure, 35 
test writing by, 140 
testing resisted by, 125 
user information from, 52 
vocabulary of, 40 
Distinguish Public from Published 
Interfaces (Pattern 7.9), 149, 
164-166 
Do a Mock Installation (Pattern 
3.5) 
after Read All the Code in One 
Hour (Pattern 3.2), 43 
example, 60-62 
intent, 58 
Interview during Demo (Pattern 
3.4) and, 53, 63 
known uses, 62 
main discussion, 58-63 
patterns complementing, 53 
problem, 58-59 
report for, 59 
solution, 59 
time required for, 59, 60 
trade-offs, 59-60 
verifying maintainers' input, 37 
what next, 62-63 
"Do it, then do it right, then do it 
fast" aphorism, 170 
documentation 
by Analyze the Persistent Data 
(Pattern 4.1), 67-68 
audience for, 44, 46 
Chat with the Maintainers (Pat- 
tern 3.1) about, 33 
class diagram, 69-74, 75-76 
historical and political context 
missing from, 31 
of Initial Understanding, 65-66 
insufficient, 48-49 
of interfaces for stable design 
parts, 117 
language for, 66-67 
misleading, 50 
need for reengineering and, 2 
Record Business Rules as Tests 
(Pattern 6.5), 58, 97, 108, 130, 
139-142 
reverse engineering and 
redocumentation, 7-8 
Skim the Documentation (Pat- 
tern 3.3), 30, 37, 40, 43, 44-50, 
53, 58 
by Speculate about Design (Pat- 
tern 4.2), 67-68 
tests as system description, 124, 
142 
See also reports; Skim the Docu- 
mentation (Pattern 3.3) 
Dotplot tool, 184-185 
dotplots. See Visualize Code as 
Dotplots (Pattern 8.2) 
Dup tool, 185 
duplicated code 
Compare Code Mechanically 
(Pattern 8.1), 175-180, 208 
Extract Method (Pattern A.5) for, 
174 
forces, 173-174 
importance of identifying, 173 
manipulating data of separate 
provider classes, 191 
Move Behavior Close to Data 
(Pattern 9.1) for, 174 
origins of, 174 
perl script for detecting, 177-180 
reengineering needed for, 3-4 
removing during Refactor to 
Understand (Pattern 5.2), 
105 
signs of, 174 
subclassing and, 218 
Transform Conditionals to Poly- 
morphism and, 174, 184, 185 
Visualize Code as Dotplots (Pat- 
tern 8.2), 180-185 
See also Detecting Duplicated 
Code 
dynamic behavior, static structure 
vs., 96 
Eick, S., 116 
Eliminate Navigation Code 
(Pattern 9.2) 
Compare Code Mechanically 
(Pattern 8.1) and, 208 
detection, 199-202 
example, 204-207 
intent, 199 
main discussion, 199-208 
Move Behavior Close to Data 
(Pattern 9.1) and, 199, 202 
overview, 189 
problem, 199 
rationale, 208 
related patterns, 208 
solution, 199-202, 203 
steps, 202 
trade-offs, 202,204 
when the legacy solution is the 
solution, 204 
Encapsulate Field (Pattern A.4), 
198, 254 
encapsulation of data, 75-76 
end users. See users 
Engage Customers pattern. See 
Involve the Users (Pattern 7.1) 
entities, exceptional. See Study the 
Exceptional Entities (Pattern 
4.3) 
evolution 
of design, 96 
of requirements, 5 
evolutionary prototypes 
exploratory prototypes vs., 156 
Make a Bridge to the New Town 
(Pattern 7.7) with, 157 
exceptional values, studying. See 
Study the Exceptional Entities 
(Pattern 4.3) 
execution, stepping through. See 
Step through the Execution 
(Pattern 5.3) 

INDEX 
211 
expectations 
Chat with the Maintainers 
(Pattern 3.1) about, 33, 34 
Involve the Users (Pattern 7.1) 
and, 151 
risks of raising, 22 
explicit type checks. See Transform 
Client Type Checks (Pattern 
10.2); Transform Self Type 
Checks (Pattern 10.1) 
exploratory prototypes, evolution- 
ary prototypes vs., 156 
exposing the design. See Detailed 
Model Capture 
Extract Method of Refactoring 
Browser, 236, 238 
Extract Method (Pattern A.5) 
for eliminating duplicated code, 
174 
Move Behavior Close to Data 
(Pattern 9.1) and, 191 
overview, 255 
Refactor to Understand (Pattern 
5.2) and, 104 
tools for, 105-106 
Visualize Code as Dotplots 
(Pattern 8.2) and, 185 
extracting system design 
as reason for reengineering, 2 
tools, 111 
Extreme Programming, 127, 160 
F 
Facade (Pattern A.12), 210, 256 
Factor Out State (Pattern 10.3) 
in Design Patterns Smalltalk 
Companion, 237 
Extract Method of Refactoring 
Browser and, 236 
Factor Out Strategy (Pattern 
10.4) vs., 239-240 
intent, 234 
known uses, 237 
main discussion, 234-237 
overview, 217 
problem, 234 
solution, 234-236 
State (Pattern A.18) and, 216, 234 
State Patterns (Pattern A.19) 
and, 234 
steps, 235-236 
trade-offs, 236-237 
Transform Self Type Checks 
(Pattern 10.1) and, 225 
when the legacy solution is the 
solution, 236-237 
Factor Out Strategy (Pattern 10.4) 
in Design Patterns Smalltalk 
Companion, 239 
example, 239 
Extract Method of Refactoring 
Browser and, 238 
Factor Out State (Pattern 10.3) 
vs., 239-240 
intent, 237 
main discussion, 237-240 
overview, 217 
problem, 237 
related patterns, 239-240 
solution, 237-238 
steps, 237-238 
Strategy (Pattern A.20) and, 216, 
237 
trade-offs, 239 
Transform Self Type Checks 
(Pattern 10.1) and, 225 
Factory Method (Pattern A.13), 
111,256 
faithful colleagues, 29 
familiarity. See Conserve Familiar- 
ity (Pattern 7.11) 
FAMOOS project 
CodeCrawler tool in, 93 
Compare Code Mechanically 
(Pattern 8.1) in, 180 
Demonstrate to Yourself pattern 
in, 57 
insufficient documentation in, 49 
misleading comments in, 50 
mock installation in, 62 
Read All the Code in One Hour 
(Pattern 3.2) and, 43 
Refactor to Understand (Pattern 
5.2) in, 106 
Visualize Code as Dotplots (Pat- 
tern 8.2) in, 185 
feasibility, assessing during First 
Contact, 26 
feedback. See user feedback 
fence-sitting colleagues, 29 
figures, Skim the Documentation 
(Pattern 3.3) and, 45 
Fi leLi st tool in Squeak, 245-249 
fine-grained design problems, 8 
First Contact 
assessing feasibility during, 26 
Chat with the Maintainers 
(Pattern 3.1), 31-37 
Do a Mock Installation (Pattern 
3.5), 58-63 
forces, 27-29 
Interview during Demo (Pattern 
3.4), 50-58 
map of patterns, 26 
overview, 29-30 
Read All the Code in One Hour 
(Pattern 3.2), 38-44 
Skim the Documentation 
(Pattern 3.3), 44-50 
what next, 30-31 
See also specific patterns 
first impressions 
danger of, 29 
Read All the Code in One Hour 
(Pattern 3.2), 38-44 
Fix Problems, Not Symptoms 
(Pattern 2.5), 19, 23 
Fjeldstadt, R. K., 49 
flexibility 
case statements and loss of, 215 
complexity vs., 25 
Keep It Simple (Pattern 2.7) and, 
24-25 
Florijn, Gert, 112-113 
Flyweight (Pattern A.14), 256-257 
Foote, Brian, 157,213 
forces 
Detailed Model Capture, 95-96 
Detecting Duplicated Code, 
173-174 
First Contact, 27-29 
Initial Understanding, 65-67 
Migration Strategies, 147 
Redistribute Responsibilities, 
187-188 
Setting Direction, 17-18 
Tests: Your Life Insurance!, 
121-122 
Transform Conditionals to Poly- 
morphism, 215-216 
foreign key relationships 
collecting, 69-70 
resolving targets, 71-72 
SQL statements for identifying, 
72 
formal specifications, Skim the 
Documentation (Pattern 3.3) 
and, 45 
forward engineering 
defined, 6 
illustrated, 7 
reverse engineering vs., 6, 56-57 
Fowler, Martin, 20, 173,241,253 
framework for testing. See Use a 
Testing Framework (Pattern 
6.3) 
functionality, Interview during 
Demo (Pattern 3.4) for under- 
standing, 50 
G 
Gamma, Erich, 136 
generality, Keep It Simple (Pattern 
2.7) and, 24-25 
goals 
assessing code quality and, 38 
identifying helpful documenta- 
tion and, 44 
measurable, 21 
primary, 21 

272 
I N D E X 
goals (continued) 
reconsidering after Study the 
Exceptional Entities (Pattern 
4.3), 93 
of reengineering, 1 
See also expectations 
God Class pattern. See Split Up 
God Class (Pattern 9.3) 
god classes 
data containers with, 189 
defined, 188 
detecting, 209-210 
generation of, 188 
maintenance and, 212 
responsibilities assumed by, 
188-189 
Split Up God Class (Pattern 9.3), 
23, 189,208-213 
utility classes vs., 189 
Goldberg, Adele, 19 
go/no-go decision 
in project plan, 31 
Read All the Code in One Hour 
(Pattern 3.2) and, 43 
Skim the Documentation 
(Pattern 3.3) and, 50 
granularity 
coarse-grained architectural 
problems, 8 
of code annotations, 100 
fine-grained design problems, 8 
of testing, 130 
Grow Your Test Base Incrementally 
(Pattern 6.2) 
as basis for Write Tests to Enable 
Evolution (Pattern 6.1), 122 
example, 129-130 
hints, 128-129 
intent, 128 
main discussion, 128-130 
Migrate Systems Incrementally 
(Pattern 7.3) with, 155 
problem, 128 
rationale, 130 
Record Business Rules as Tests 
(Pattern 6.5) and, 130, 142 
Regression Test after Every 
Change (Pattern 7.6) and, 160 
related patterns, 130 
solution, 128-129 
Test the Interface, Not the 
Implementation (Pattern 6.4) 
and, 130 
trade-offs, 129 
Use a Testing Framework 
(Pattern 6.3) and, 130 
Write Tests to Enable Evolution 
(Pattern 6.1) and, 122, 127 
Write Tests to Understand 
(Pattern 6.6) and, 130 
guidelines 
Agree on Maxims (Pattern 2.1), 
18-19 
to set and maintain direction, 16 
H 
Hamlen, W. T., 49 
hashing, for comparing code, 175 
help desk personnel, user informa- 
tion from, 52 
historical context. See Chat with 
the Maintainers (Pattern 3.1) 
hook methods 
detecting semiautomatically, 
113 
specializing classes and, 112 
human dependencies, as reason 
for reengineering, 2 
I 
If It Ain't Broke, Don't Fix It (Pat- 
tern 2.6), 23, 24 
implementation. See Do a Mock 
Installation (Pattern 3.5); Test 
the Interface, Not the Imple- 
mentation (Pattern 6.4) 
implicit aspects of design, 95-96, 
97 
incremental testing strategy. See 
Grow Your Test Base Incre- 
mentally (Pattern 6.2) 
independence, as property of well- 
designed tests, 124, 126 
index, Skim the Documentation 
(Pattern 3.3) and, 45 
indirect clients, 199-200 
indirect providers, 199 
inheritance relationships 
bottom-up design extraction 
approach and, 83 
class inheritance, 89-90 
hierarchy, studying, 89-90 
incorporating in class diagram, 
70 
legacy databases and, 68 
method inheritance, 90, 91 
one to one, 70 
rolled down, 70 
rolled up, 70 
Initial Understanding 
Analyze the Persistent Data (Pat- 
tern 4.1), 68-76 
documentation of, 65-67 
forces, 65-67 
map of patterns, 64 
overview, 67 
Speculate about Design (Pattern 
4.2), 76-84 
Study the Exceptional Entities 
(Pattern 4.3), 84-93 
time required for, 67 
top-down vs. bottom-up study 
of source code, 67 
what next, 67-68 
See also specific patterns 
inside knowledge, need for 
reengineering and, 3 
installation, mock. See Do a Mock 
Installation (Pattern 3.5) 
instantiated objects, Step through 
the Execution (Pattern 5.3) for 
discovering, 107-109 
integration, continuous. See 
Always Have a Running Ver- 
sion (Pattern 7.5) 
interests 
coping with conflicting, 18-19 
as force to be aware of, 17 
interfaces. See public interfaces; 
user interface 
Interview during Demo (Pattern 
3.4) 
after Skim the Documentation 
(Pattern 3.3), 50 
Chat with the Maintainers 
(Pattern 3.1) after, 57, 58 
choosing users for, 51-52, 53 
Demonstrate to Yourself varia- 
tion, 52 
for determining causes of insta- 
bility, 117 
Do a Mock Installation (Pattern 
3.5) and, 53, 63 
example, 54-56 
intent, 50 
interviewing skills needed for, 
53, 56 
known uses, 57 
main discussion, 50-58 
order for applying, 30 
patterns complementing, 40, 43, 
53 
as preparation for Record Busi- 
ness Rules as Tests (Pattern 
6.5), 58 
as preparation for Speculate 
about Design (Pattern 4.2), 58 
problem, 50-51 
rationale, 56-57 
Read All the Code in One Hour 
(Pattern 3.2) and, 40, 43, 53, 
58 
real-time software and, 54 
related patterns, 57 
repeating with various users, 
51-52, 53, 57-58 
report for, 51 
Skim the Documentation 
(Pattern 3.3) and, 53, 58 
solution, 51-52 

IN D E X 
273 
Step through the Execution (Pat- 
tern 5.3) scenarios from, 109 
trade-offs, 53-54 
usage scenarios from, 50-51 
verifying maintainers' input, 37 
what next, 57-58 
interviewing maintainers. See Chat 
with the Maintainers (Pattern 
3.1) 
Introduce Null Object (Pattern 
10.5) 
detection, 240 
example, 242-243 
intent, 240 
main discussion, 240-243 
Null Object (Pattern A.15) and, 
216, 240 
overview, 217 
problem, 240 
solution, 240-241 
steps, 241 
trade-offs, 242 
Transform Client Type Checks 
(Pattern 10.2) and, 233 
Involve the Users (Pattern 7.1) 
Build Confidence (Pattern 7.2) 
and, 148, 151,153 
Conserve Familiarity (Pattern 
?.11) and, 169 
for increasing chances of user 
acceptance, 148 
intent, 149 
Keep It Simple (Pattern 2.7) 
and, 25 
as key motivation, 148 
main discussion, 149-151 
Migrate Systems Incrementally 
(Pattern 7.3) and, 148, 150, 
151 
Most Valuable First pattern 
and, 22 
Planning Game for, 151 
problem, 149-150 
rationale, 151 
related patterns, 151 
risk minimized by, 148 
solution, 150 
steps, 150 
trade-offs, 150-151 
J 
Java 
detecting client type checks in, 
226-227 
detecting navigation code in, 
201 
detecting self type checks in, 219 
Jazayeri, Mehdi, 116 
JUnit 
assertion methods, 132-133 
runBare() template method, 132 
runTest () method, 132 
setup() method, 132, 134 
suite() mthoed, 135 
tearDown() method, 132 
test runner classes, 135 
test subclasses, 132, 133-134 
TestCase class, 132-133 
as testing framework, 131, 
132-136 
TestResul t class, 132 
unit test example, 126 
junk data in relational databases, 73 
K 
Keep It Simple (Pattern 2.7), 24-25 
Keep the Data--Toss the Code pat- 
tern. See Make a Bridge to the 
New Town (Pattern 7.7) 
Keller, Wolfgang, 162 
knowledge, sharing, 66 
L 
language 
for code annotations, 99 
for documentation, 66-67 
testing frameworks, 136 
large structures, Read All the Code 
in One Hour (Pattern 3.2) and, 
39 
large systems. See scale 
law of Demeter (LOD) 
data containers and violations 
of, 188 
defined, 208 
navigation code as violation of, 
188, 208 
See also Eliminate Navigation 
Code (Pattern 9.2) 
Learn from the Past (Pattern 5.5) 
contract evolution and, if3 
hints, I14-i15 
intent, 113 
known uses, 116-i17 
main discussion, I13-I17 
overview, 97 
problem, 113-114 
rationale, i 16 
solution, I14-i15 
trade-offs, 115-I16 
what next, 117 
legacy systems 
assessing via Read All the Code 
in One Hour (Pattern 3.2), 
38-44 
complexity and size of, 28 
concentration of software 
defects in, 22 
distributed and hidden knowl- 
edge of, 20 
focus on object-oriented sys- 
tems, 4-5 
forces to be aware of, 17-18 
goal of reengineering, 1 
inheritance relationships and, 
68 
migrating data from, 160-162 
political context as problemati- 
cal, 31 
reasons for reengineering, 1-2 
splitting into manageable 
pieces, 28 
symptoms of need for 
reengineering, 2-4 
value of, 1 
when the legacy solution is the 
solution, 193-194, 204, 
212-213,222,229,236-237 
Lehman, M. M., 169 
libraries, 194 
LOD. See law of Demeter (LOD) 
Look for the Contracts (Pattern 5.4) 
for documenting the class inter- 
face, 117 
hints, 110-112 
incorporating operations for 
classes and, 73 
intent, 109 
known uses, 112-113 
Learn from the Past (Pattern 5.5) 
with, 113 
main discussion, 109-113 
overview, 97 
problem, 109-110 
Refactor to Understand (Pattern 
5.2) before, 113 
refining class diagram using, 76 
solution, 110-112 
Step through the Execution (Pat- 
tern 5.3) for validation, 113 
trade-offs, 112 
what next, 113 
Love, Tom, 157 
M 
maintenance 
Chat with the Maintainers (Pat- 
tern 3.1), 31-37, 40, 43, 50, 57, 
58, 62, 117 
defined, 9 
god classes and, 212 
as reason for reengineering, 2-4 
reengineering vs., 9 
as second-class work, 35, 36 
turnover in maintenance teams, 
34 
user information from 
maintainers, 52 
See also Chat with the 
Maintainers (Pattern 3.1) 

274 
INDEX 
Make a Bridge to the New Town 
(Pattern 7.7) 
Build Confidence (Pattern 7.2) 
helped by, 153, 162 
intent, 160 
known uses, 162 
large numbers of defects and, 23 
main discussion, 160-162 
Migrate Systems Incrementally 
(Pattern 7.3) helped by, 149, 
155, 162 
problem, 161 
Prototype the Target Solution 
(Pattern 7.4) with, 157 
rationale, 162 
related patterns, 162 
solution, 161-162 
steps, 161-162 
trade-offs, 162 
managers 
duplicated code known by, 174 
user information from, 52 
mapping classes, 194 
maxims 
agreeing on, 18-19 
defined, 19 
Setting Direction patterns as, 19 
meaningful names, 103, 104 
meetings 
Chat with the Maintainers (Pat- 
tern 3.1), 31-37, 40, 43, 50, 57, 
58, 62, 117 
Interview during Demo (Pattern 
3.4), 30, 37, 40, 43, 50-58, 63, 
109, 117 
minutes of, 20 
sharing knowledge via, 66 
Speak to the Round Table (Pat- 
tern 2.3), 20, 66 
Stand Up, 20 
methods 
analyzing inheritance, 90, 91 
annotations based on, 99 
defining bodies with same level 
of abstraction, 105 
Extract Method (Pattern A.5), 104, 
105-106, 174, 185, 191,255 
Factory Method (Pattern A.13), 
111,256 
intention-revealing names for, 
92 
issues for invoking, 110 
key methods, finding, 111 
measuring size of, 90-92 
Move Behavior Close to Data 
(Pattern 9.1) and, 192 
Move Method (Pattern A.6), 25, 
191 
multiple, switching on same 
attribute, 218 
Rename Method (Pattern A.8), 
104, 255 
renaming to convey intent, 104 
replacing condition branches by, 
105 
restarting to verify scenario, 108 
self type checks and, 218 
Template Method (Pattern A.21), 
112, 258 
template/hook methods, 112 
metrics 
for Learn from the Past (Pattern 
5.5), 114, 115 
for Study the Exceptional 
Entities (Pattern 4.3), 86 
Migrate Systems Incrementally 
(Pattern 7.3) 
Always Have a Running Version 
(Pattern 7.5) needed for, 148, 
155 
Appoint a Navigator (Pattern 
2.2) and, 155 
Build Confidence (Pattern 7.2) 
helped by, 148 
as central message of Migration 
Strategies, 148 
Conserve Familiarity (Pattern 
7.11) and, 169 
Deprecate Obsolete Interfaces 
(Pattern 7.10) and, 149 
Distinguish Public from Pub- 
lished Interfaces (Pattern 7.9) 
and, 149 
Grow Your Test Base Increment- 
ally (Pattern 6.2) and, 155 
intent, 153 
Involve the Users (Pattern 7.1) 
helped by, 148, 150, 151 
known uses, 154-155 
main discussion, 153-155 
Make a Bridge to the New Town 
(Pattern 7.7) and, 149, 155, 162 
Most Valuable First (Pattern 2.4) 
and, 155 
Present the Right Interface (Pat- 
tern 7.8) and, 149, 155 
problem, 153 
Prototype the Target Solution 
(Pattern 7.4) needed for, 148 
rationale, 154 
Regression Test after Every 
Change (Pattern 7.6) needed 
for, 148, 155 
related patterns, 155 
risk minimized by, 148 
solution, 153-154 
steps, 154 
Test the Interface, Not the 
Implementation (Pattern 6.4) 
and, 155 
tests enabling, 123, 127 
trade-offs, 154 
user feedback and, 22 
Write Tests to Enable Evolution 
(Pattern 6.1) and, 127, 155 
Migrating Legacy Systems, 162 
Migration Strategies 
Always Have a Running Version 
(Pattern 7.5), 157-159 
Build Confidence (Pattern 7.2), 
151-153 
Conserve Familiarity (Pattern 
7.11), 168-169 
Deprecate Obsolete Interfaces 
(Pattern 7.10), 166-168 
Distinguish Public from Pub- 
lished Interfaces (Pattern 7.9), 
164-166 
forces, 147 
Involve the Users (Pattern 7.1), 
149-151 
Make a Bridge to the New Town 
(Pattern 7.7), 160-162 
map of patterns, 146 
Migrate Systems Incrementally 
(Pattern 7.3), 153-155 
overview, 147-149 
Present the Right Interface (Pat- 
tern 7.8), 163-164 
Prototype the Target Solution 
(Pattern 7.4), 155-157 
Regression Test after Every 
Change (Pattern 7.6), 159-160 
Tests: Your Life Insurance! as 
support for, 123 
Use Profiler before Optimizing 
(Pattern 7.12), 169-170 
See also specific patterns 
minutes, for round table meetings, 
20 
mock installation. See Do a Mock 
Installation (Pattern 3.5) 
Most Valuable First (Pattern 2.4) 
critical path and, 19, 23 
determining what is valuable, 21 
Fix Problems, Not Symptoms 
(Pattern 2.5) and, 23 
if most valuable part is rat's nest, 
22 
main discussion, 20-22 
Migrate Systems Incrementally 
(Pattern 7.3) and, 155 
patterns to employ after, 22 
problem, 20 
risk of raising expectations, 22 
solution, 20 
Move Behavior Close to Data (Pat- 
tern 9.1) 
Adapter (Pattern A.11) and, 193 
detection, 190-191 

INDEX 
215 
for duplicated code, 174, 185 
Eliminate Navigation Code (Pat- 
tern 9.2) and, 199, 202 
Encapsulate Field (Pattern A.4) 
and, 198 
example, 194-198 
Extract Method (Pattern A.5) 
and, 191 
intent, 190 
main discussion, 190-198 
Move Method (Pattern A.6) and, 
191 
overview, 189 
problem, 190 
rationale, 198 
related patterns, 198 
solution, 190-192 
Split Up God Class (Pattern 9.3) 
and, 210 
steps, 191-192 
trade-offs, 193-194 
Transform Client Type Checks 
(Pattern 10.2) vs., 191 
Visitor (Pattern A.22) and, 194 
Visualize Code as Dotplots (Pat- 
tern 8.2) and, 185 
when the legacy solution is the 
solution, 193-194 
Move Method (Pattern A.6), 191, 
255 
multiplicities for associations, 72 
Mythical Man-Month, The, 157 
N 
names 
enumerating for class diagram, 
77 
enumerating for tables, 69 
intention-revealing, for meth- 
ods, 192 
of key methods, 111 
meaningful, 103, 104 
naming conventions and Read 
All the Code in One Hour (Pat- 
tern 3.2), 39 
for published interfaces, 165 
for reengineering patterns, 10, 
11 
tracking in source code, 78 
See also renaming 
navigation code 
accessor method calls in, 200 
attribute access sequences in, 
200 
defined, 188 
detection, 199-202 
Eliminate Navigation Code (Pat- 
tern 9.2), 189, 199-208 
indirect clients and, 199-200 
indirect providers and, 199 
as violation of law of Demeter 
(LOD), 188, 208 
Navigator, appointing, 19, 155 
Null Object (Pattern A.15), 216, 
240, 257 
O 
object-oriented design, mapping 
onto procedural implementa- 
tion, 84 
object-oriented systems 
focus of this book on, 4-5 
reuse costs in, 4-5 
transparency needed for, 4 
objects 
changing internal state of, 108 
difficulties finding, 4 
instantiated at run time, discov- 
ering, 107-109 
plug-in, 145, 150, 243-244 
static structure vs. dynamic 
behavior, 96 
O'Callaghan, Alan, 19, 164 
one-to-one inheritance, 70 
operations, incorporating in class 
diagram, 72-73 
opportunities 
from Initial Understanding, 
67-87 
in project plan, 30 
optimizing. See Use Profiler before 
Optimizing (Pattern 7.12) 
overengineering, temptation of, 18 
P 
parameters linking methods to 
classes, 111 
part-whole relationships, 111 
Pattern 2.1. See Agree on Maxims 
(Pattern 2.1) 
Pattern 2.2. See Appoint a Naviga- 
tor (Pattern 2.2) 
Pattern 2.3. See Speak to the Round 
Table (Pattern 2.3) 
Pattern 2.4. See Most Valuable First 
(Pattern 2.4) 
Pattern 2.5. See Fix Problems, Not 
Symptoms (Pattern 2.5) 
Pattern 2.6. See If It Ain't Broke, 
Don't Fix It (Pattern 2.6) 
Pattern 2.7. See Keep It Simple 
(Pattern 2.7) 
Pattern 3.1. See Chat with the 
Maintainers (Pattern 3.1) 
Pattern 3.2. See Read All the Code 
in One Hour (Pattern 3.2) 
Pattern 3.3. See Skim the Docu- 
mentation (Pattern 3.3) 
Pattern 3.4. See Interview during 
Demo (Pattern 3.4) 
Pattern 3.5. See Do a Mock Installa- 
tion (Pattern 3.5) 
Pattern 4.1. See Analyze the Persis- 
tent Data (Pattern 4.1.) 
Pattern 4.2. See Speculate about 
Design (Pattern 4.2) 
Pattern 4.3. See Study the Excep- 
tional Entities (Pattern 4.3) 
Pattern 5.1. See Tie Code and Ques- 
tions (Pattern 5.1) 
Pattern 5.2. See Refactor to Under- 
stand (Pattern 5.2) 
Pattern 5.3. See Step through the 
Execution (Pattern 5.3) 
Pattern 5.4. See Look for the Con- 
tracts (Pattern 5.4) 
Pattern 5.5. See Learn from the Past 
(Pattern 5.5) 
Pattern 6.1. See Write Tests to 
Enable Evolution (Pattern 6.1) 
Pattern 6.2. See Grow Your Test Base 
Incrementally (Pattern 6.2) 
Pattern 6.3. See Use a Testing 
Framework (Pattern 6.3) 
Pattern 6.4. See Test the Interface, 
Not the Implementation (Pat- 
tern 6.4) 
Pattern 6.5. See Record Business 
Rules as Tests (Pattern 6.5) 
Pattern 6.6. See Write Tests to 
Understand (Pattern 6.6) 
Pattern 7.1. See Involve the Users 
(Pattern 7.1) 
Pattern 7.2. See Build Confidence 
(Pattern 7.2) 
Pattern 7.3. See Migrate Systems 
Incrementally (Pattern 7.3) 
Pattern 7.4. See Prototype the Tar- 
get Solution (Pattern 7.4) 
Pattern 7.5. See Always Have a Run- 
ning Version (Pattern 7.5) 
Pattern 7.6. See Regression Test 
after Every Change (Pattern 
7.6) 
Pattern 7.7. See Make a Bridge to 
the New Town (Pattern 7.7) 
Pattern 7.8. See Present the Right 
Interface (Pattern 7.8) 
Pattern 7.9. See Distinguish Public 
from Published Interfaces 
(Pattern 7.9) 
Pattern 7.10. See Deprecate Obso- 
lete Interfaces (Pattern 7.10) 
Pattern 7.11. See Conserve Famil- 
iarity (Pattern 7.11) 
Pattern 7.12. See Use Profiler 
before Optimizing (Pattern 
7.12) 
Pattern 8.1. See Compare Code 
Mechanically (Pattern 8.1) 

276 
IN D E X 
Pattern 8.2. See Visualize Code as 
Dotplots (Pattern 8.2) 
Pattern 9.1. See Move Behavior 
Close to Data (Pattern 9.1) 
Pattern 9.2. See Eliminate Naviga- 
tion Code (Pattern 9.2) 
Pattern 9.3. See Split Up God Class 
(Pattern 9.3) 
Pattern 10.1. See Transform Self 
Type Checks (Pattern 10.1) 
Pattern 10.2. See Transform Client 
Type Checks (Pattern 10.2) 
Pattern 10.3. See Factor Out State 
(Pattern 10.3) 
Pattern 10.4. See Factor Out Strat- 
egy (Pattern 10.4) 
Pattern 10.5. See Introduce Null 
Object (Pattern 10.5) 
Pattern 10.6. See Transform Con- 
ditionals into Registration 
(Pattern 10.6) 
Pattern A.1. See Retest Persistent 
Problems (Pattern A.1) 
Pattern A.2. See Test Fuzzy Features 
(Pattern A.2) 
Pattern A.3. See Test Old Bugs 
(Pattern A.3) 
Pattern A.4. See Encapsulate Field 
(Pattern A.4) 
Pattern A.5. See Extract Method 
(Pattern A.5) 
Pattern A.6. See Move Method 
(Pattern A.6) 
Pattern A.7. See Rename Attribute 
(Pattern A.7) 
Pattern A.8. See Rename Method 
(Pattern A.8) 
Pattern A.9. See Replace Condi- 
tional with Polymorphism 
(Pattern A.9) 
Pattern A.10. See Abstract Factory 
(Pattern A. 10) 
Pattern A.11. See Adapter (Pattern 
A.11) 
Pattern A.12. See Facade (Pattern 
A.12) 
Pattern A.13. See Factory Method 
(Pattern A.13) 
Pattern A.14. See Flyweight 
(Pattern A.14) 
Pattern A. 15. See Null Object 
(Pattern A. 15) 
Pattern A.16. See Quantity (Pattern 
A.16) 
Pattern A.17. See Singleton (Pattern 
A.17) 
Pattern A.18. See State (Pattern A.18) 
Pattern A. 19. See State Patterns 
(Pattern A.19) 
Pattern A.20. See Strategy (Pattern 
A.20) 
Pattern A.21. See Template Method 
(Pattern A.21) 
Pattern A.22. See Visitor (Pattern 
A.22) 
Pattern Language, A, 9-10 
patterns 
application of, 10 
design patterns vs. reengineer- 
ing patterns, 10-11 
introduction of, 9-10 
Speculate about Patterns varia- 
tion (Pattern 4.2), 78 
See also reengineering patterns; 
specific patterns by name 
performance, as reason for reengi- 
neering, 1-2 
perl scripts 
for detecting duplicated code, 
177-180 
for identifying simulated 
switches in C++, 251 
persistence, as property of well- 
designed tests, 124, 126 
Planning Game, 21, 151 
plug-in manager, 245 
plug-in objects, 145, 150, 243-244 
political context. See Chat with the 
Maintainers (Pattern 3.1) 
polymorphism. See Transform 
Conditionals to Polymor- 
phism 
Pooley, Rob, 168 
porting a system, as reason for 
reengineering, 2 
Present the Right Interface (Pattern 
7.8) 
Adapter (Pattern A.11) vs., 164 
Deprecate Obsolete Interfaces 
(Pattern 7.10) and, 164 
Distinguish Public from Pub- 
lished Interfaces (Pattern 7.9) 
and, 164, 166 
Fix Problems, Not Symptoms 
(Pattern 2.5) and, 23 
hints, 163 
intent, 163 
known uses, 164 
main discussion, 163-164 
Migrate Systems Incrementally 
(Pattern 7.3) helped by, 149, 
155 
problem, 163 
rationale, 164 
related patterns, 164 
solution, 163 
Split Up God Class (Pattern 9.3) 
and, 212-213 
trade-offs, 163-164 
principles 
Agree on Maxims (Pattern 2.1), 
18-19 
to set and maintain direction, 16 
priorities 
asking users about, 150 
difficulties setting, 17 
establishing, 18-19 
Most Valuable First (Pattern 2.4) 
for setting, 20-22, 23 
Planning Game for, 21 
products, need for reengineering 
and, 3 
profiler. See Use Profiler before 
Optimizing (Pattern 7.12) 
programmers 
motivating to write comments, 
101 
testing resisted by, 122 
project plan, items to include, 
30-31 
project scope, in project plan, 30 
Prototype the Target Solution 
(Pattern 7.4) 
Build Confidence (Pattern 7.2) 
helped by, 153 
Conserve Familiarity (Pattern 
7.11) and, 169 
exploratory vs. evolutionary 
prototypes, 156 
intent, 155 
main discussion, 155-157 
Make a Bridge to the New Town 
(Pattern 7.7) with, 157 
Migrate Systems Incrementally 
(Pattern 7.3) and, 148 
problem, 155 
rationale, 157 
related patterns, 157 
solution, 156 
steps, 156 
trade-offs, 156-157 
public interfaces 
Deprecate Obsolete Interfaces 
(Pattern 7.10), 149, 166-168 
Distinguish Public from Pub- 
lished Interfaces (Pattern 7.9), 
149, 164-166 
Present the Right Interface 
(Pattern 7.8), 23, 149, 155, 
163-164, 212-213 
Test the Interface, Not the Im- 
plementation (Pattern 6.4), 
97, 117, 127, 130, 136-139, 155 
Published Interface pattern, 166. 
See also Distinguish Public 
from Published Interfaces 
(Pattern 7.9) 

IN D E X 
277 
Q 
qualified associations, identifying, 
72 
Quantity (Pattern A.16), 257 
R 
Read All the Code in One Hour 
(Pattern 3.2) 
after Skim the Documentation 
(Pattern 3.3), 50 
Chat with the Maintainers 
(Pattern 3.1) and, 40, 43 
checklist for, 39, 42 
Do a Mock Installation (Pattern 
3.5) after, 43 
example, 41-42 
intent, 38 
Interview during Demo (Pattern 
3.4) and, 40, 43, 53, 58 
known uses, 43 
lines read per hour, 40, 42 
main discussion, 38-44 
order for applying, 30 
patterns complementing, 40, 
43, 53, 58 
problem, 38 
rationale, 42 
report for, 38, 42 
Skim the Documentation 
(Pattern 3.3) and, 40, 43 
solution, 38-39 
time allotted for, 40, 42 
trade-offs, 39-40 
traditional code reviews vs., 42 
verifying maintainers' input, 37 
what next, 43-44 
real-time software, Interview dur- 
ing Demo (Pattern 3.4) and, 54 
rebuilding the system, Do a Mock 
Installation (Pattern 3.5) to 
ensure ability, 58-63 
Record Business Rules as Tests 
(Pattern 6.5) 
described, 130 
Detailed Model Capture infor- 
mation and, 97 
examples, 141-142 
Grow Your Test Base Incre- 
mentally (Pattern 6.2) and, 
130 
hints, 140 
intent, 139 
Interview during Demo (Pattern 
3.4) as preparation for, 58 
main discussion, 139-142 
problem, 139-140 
rationale, 142 
related patterns, 142 
solution, 140 
Step through the Execution 
(Pattern 5.3) and, 108 
Test the Interface, Not the 
Implementation (Pattern 6.4) 
vs., 139 
trade-offs, 140-141 
Write Tests to Understand 
(Pattern 6.6) with, 142 
Redistribute Responsibilities 
Eliminate Navigation Code 
(Pattern 9.2), 199-208 
forces, 187-188 
map of patterns, 186 
Move Behavior Close to Data 
(Pattern 9.1), 190-198 
overview, 188-190 
Split Up God Class (Pattern 9.3), 
208-213 
See also Transform Conditionals 
to Polymorphism; specific 
patterns 
reengineering 
big-bang, avoiding risk of, 153 
coarse-grained architectural 
problems, 8 
continuous, 5, 9 
defined, 5 
fine-grained design problems, 8 
forces inherent to, 121 
forces to be aware of, 17-18 
goal of, 1 
illustrated, 7 
maintenance vs., 9 
reasons for, 1-2 
in reengineering life cycle, 8-9 
refactoring, 9 
restructuring, 9 
reverse engineering vs., 5-6 
risks in, 121,123 
symptoms of need for, 2-4 
as transformation at all levels, 6 
See also Detecting Duplicated 
Code; Migration Strategies; 
Redistribute Responsibilities; 
Tests: Your Life Insurance!; 
Transform Conditionals to 
Polymorphism 
reengineering life cycle 
reengineering, 8-9 
reverse engineering, 6-8 
terminology, 5-6 
"waterfall," 13 
reengineering patterns 
criteria for good patterns, 11 
defined, 10 
design patterns vs., 10-11 
form of, 11, 12 
irrelevant or inapplicable, 30 
map of pattern clusters, 11, 13 
names for, 10, 11 
order for applying, 29-30 
overview, 10-11 
See also specific patterns by name 
Refactor to Understand (Pattern 5.2) 
backing up code first, 104 
before Look for the Contracts 
(Pattern 5.4), 113 
before Write Tests to Understand 
(Pattern 6.6), 144 
guidelines, 104-105 
intent, 103 
known uses, 106 
main discussion, 103-107 
overview, 96-97 
problem, 103 
refactorings typical for, 104 
related patterns, 106 
solution, 103-105 
Tie Code and Questions (Pattern 
5.1) with, 103, 106, 107 
trade-offs, 105-106 
Use Profiler before Optimizing 
(Pattern 7.12) and, 170 
what next, 106-107 
Write Tests to Understand (Pat- 
tern 6.6) during, 97, 106 
refactoring 
code ownership and, 106 
defined, 9 
Eliminate Navigation Code (Pat- 
tern 9.2), 189, 199-208 
Encapsulate Field (Pattern A.4), 
198, 254 
Extract Method (Pattern A.5), 
104, 105-106, 174, 185, 191, 
255 
Learn from the Past (Pattern 5.5) 
and, 114 
Move Method (Pattern A.6), 25, 
191 
pinpointing problems and, 23 
Refactor to Understand (Pattern 
5.2), 96-97, 103-107, 144, 170 
regression tests after, 103 
Rename Attribute (Pattern A.7), 
104, 255 
Rename Method (Pattern A.8), 
104, 255 
Replace Conditional with Poly- 
morphism (Pattern A.9), 234, 
255 
Split Up God Class (Pattern 9.3), 
23, 189, 208-213 
thumbnail patterns, 253, 
254-255 
tools for, 105-106 
See also specific patterns 

218 
IN D E X 
Refactoring Browser, 105-106, 
201-202, 236, 238 
Reflection Model, 83-84 
Regression Test after Every Change 
(Pattern 7.6) 
after Split Up God Class (Pattern 
9.3), 210 
Always Have a Running Version 
(Pattern 7.5) with, 159 
Build Confidence (Pattern 7.2) 
helped by, 159 
confidence built by, 123 
Grow Your Test Base Incremen- 
tally (Pattern 6.2) and, 160 
intent, 159 
main discussion, 159-160 
Migrate Systems Incrementally 
(Pattern 7.3) and, 148, 155 
problem, 159 
rationale, 160 
related patterns, 160 
Retest Persistent Problems 
(Pattern A.1) and, 160 
solution, 159 
trade-offs, 159-160 
Write Tests to Enable Evolution 
(Pattern 6.1) and, 160 
relational databases 
class diagram derivation, 69-73 
incorporating associations, 
70-72 
incorporating inheritance, 70 
incorporating operations, 72-73 
initial model for, 69-70 
junk data in, 68, 73 
migrating to another database, 
76 
verifying the classes, 72 
releases, comparing. See Learn 
from the Past (Pattern 5.5) 
remodeling, source code/design 
mismatch and, 78 
Rename Attribute (Pattern A.7), 
104, 255 
Rename Method (Pattern A.8), 104, 
255 
renaming 
attributes to convey roles, 104 
classes to convey purpose, 104 
to correct class diagram mis- 
matches, 78 
Learn from the Past (Pattern 5.5) 
sensitivity to, 116 
with meaningful names, 103, 
104 
methods to convey intent, 104 
Rename Attribute (Pattern A.7), 
104, 255 
Rename Method (Pattern A.8), 
104, 255 
Renovate the Worst First strategy, 
22 
repeatability, as property of well- 
designed tests, 124, 126 
Replace Conditional with Polymor- 
phism (Pattern A.9), 234, 255 
reports 
for Do a Mock Installation 
(Pattern 3.5), 59 
for Interview during Demo 
(Pattern 3.4), 51 
]Unit error reports, 132 
for Read All the Code in One 
Hour (Pattern 3.2), 38, 42 
samples in documentation, 45 
for Skim the Documentation 
(Pattern 3.3), 44-45 
requirements 
continuous validation of, 150 
evolution of, 5 
resources 
applicability of patterns and, 30 
scale of legacy systems and, 28 
Speculate about Design (Pattern 
4.2) and, 79 
time as most precious resource, 
28-29 
responsibilities 
agreeing on, 19 
case statements' assumption of, 
215 
data containers' lack of, 188, 190 
god classes' assumption of, 
188-189 
See also Redistribute Responsi- 
bilities; Transform Condi- 
tionals to Polymorphism 
restructuring, defined, 9 
Retest Persistent Problems (Pattern 
A.1), 123, 160, 253-254 
reuse 
costs of, 4-5 
Keep It Simple (Pattern 2.7) and, 
25 
of stable parts of design, 117 
of tests, 136-139 
reuse contracts, 113 
reverse engineering 
defined, 5 
forward engineering vs., 6, 
56-57 
illustrated, 7 
problem identification during, 
7-8 
redocumentation during, 7-8 
in reengineering life cycle, 6-8 
reengineering vs., 5-6 
See also Detailed Model Capture; 
First Contact; Initial Under- 
standing; Setting Direction 
reverse engineers, Demonstrate to 
Yourself pattern for, 52 
Rewrite Rule Editor, 201-202 
rewriting components, 23 
Riel, Arthur ]., 233 
Rising, Linda, 253 
risks 
of big-bang reengineering, 153 
of error introduction during 
Refactor to Understand 
(Pattern 5.2), 99, 105 
identifying technical risks, 156 
Migration Strategies for mini- 
mizing, 148 
in project plan, 30 
in reengineering, 121,123 
Study the Exceptional Entities 
(Pattern 4.3) and, 68 
Write Tests to Enable Evolution 
(Pattern 6.1) for minimizing, 
123-127 
Roberts, Don, 106, 253 
Robson, D. ]., 43 
rolled-down inheritance, 70 
rolled-up inheritance, 70 
round table meetings, 20 
round-trip engineering tools, 
111 
Rubin, Kenneth S., 19 
S 
sales department personnel, user 
information from, 52 
scale 
build times for large systems, 
158 
identifying design problems in 
large systems, 85 
of legacy systems, 28 
Read All the Code in One Hour 
(Pattern 3.2) and, 40, 41 
Speculate about Design (Pattern 
4.2) and, 79 
Study the Exceptional Entities 
(Pattern 4.3) and, 87 
scenarios for Step through the Exe- 
cution (Pattern 5.3), 107, 108, 
109 
Schauer, Reinhard, 113 
scope of Analyze the Persistent 
Data (Pattern 4.1), 73 
screen dumps, Skim the Documen- 
tation (Pattern 3.3) and, 45 
self-test, Do a Mock Installation 
(Pattern 3.5) and, 59 
self type checks. See Transform Self 
Type Checks (Pattern 10.1) 
"Semantic Wrapper," 164. See also 
Present the Right Interface 
(Pattern 7.8) 

IN D E X 
279 
Setting Direction 
Agree on Maxims (Pattern 2.1), 
18-19 
Appoint a Navigator (Pattern 
2.2), 19 
Fix Problems, Not Symptoms 
(Pattern 2.5), 23 
forces to be aware of, 17-18 
If It Ain't Broke, Don't Fix It 
(Pattern 2.6), 24 
Keep It Simple (Pattern 2.7), 
24-25 
map of patterns, 16 
Most Valuable First (Pattern 2.4), 
20-22 
overview, 18 
principles and guidelines, 16 
Speak to the Round Table 
(Pattern 2.3), 20 
See also specific patterns 
simplicity. See Keep It Simple 
(Pattern 2.7) 
simulated switches, perl script for 
identifying in C++, 251 
Singleton (Pattern A.17), 39,257 
skepticism 
Build Confidence (Pattern 7.2) 
for overcoming, 148, 151 
skeptical colleagues, 29 
Skim the Documentation (Pattern 
3.3) 
example, 47-48 
intent, 44 
Interview during Demo (Pattern 
3.4) and, 53, 58 
items to look for, 45 
known uses, 49-50 
main discussion, 44-50 
order for applying, 30 
patterns complementing, 40, 43, 
53, 58 
problem, 44 
rationale, 48-49 
Read All the Code in One Hour 
(Pattern 3.2) and, 40, 43 
report for, 44-45 
solution, 44-45 
trade-offs, 46 
verifying maintainers' input, 37 
what next, 50 
Smalltalk 
detecting client type checks in, 
226 
detecting navigation code in, 
201 
detecting self type checks in, 219 
extending libraries in, 194 
Sneed, Harry, 106 
sociological issues, technological 
issues vs., 35 
source code browser 
polymorphic method invoca- 
tions and, 114, 115 
for querying method invocation, 
114 
Speak to the Round Table (Pattern 
2.3), 20, 66 
Speculate about Architecture vari- 
ation (Pattern 4.2), 79 
Speculate about Business Objects 
variation (Pattern 4.2), 78 
Speculate about Design (Pattern 
4.2) 
documentation by, 67-68 
example, 80-82 
incorporating operations for 
classes and, 73 
intent, 76 
Interview during Demo (Pattern 
3.4) as preparation for, 58 
known uses, 83-84 
main discussion, 76-84 
patterns acting as preparation 
for, 50, 58 
problem, 76-77 
rationale, 83 
refining class diagram using, 76 
repeated application of, 67 
solution, 77-79 
Speculate about Architecture 
variation, 79 
Speculate about Business Ob- 
jects variation, 78 
Speculate about Patterns varia- 
tion, 78 
time required for, 67 
as top-down method, 67 
trade-offs, 79 
what next, 84 
Speculate about Patterns variation 
(Pattern 4.2), 78 
spiral model of software develop- 
ment, 6 
Split Up God Class (Pattern 9.3) 
bottleneck components and, 23 
detection, 209-2 l0 
Facade (Pattern A.12) and, 210 
intent, 208 
main discussion, 208-213 
Move Behavior Close to Data 
(Pattern 9.1) and, 210 
overview, 189 
Present the Right Interface (Pat- 
tern 7.8) and, 212-213 
problem, 208-209 
rationale, 213 
Regression Test after Every 
Change (Pattern 7.6) after, 2 i0 
related patterns, 213 
solution, 209-212 
steps, 210-212 
trade-offs, 212-213 
when the legacy solution is the 
solution, 212-213 
SQL statement samples for verify- 
ing classes, 72 
Squeak Fi leList tool, 245-249 
stable design 
reusing, 117 
signs of, 115 
stakeholders 
conflicting interests of, 17, 18-19 
customer vs., 21 
differing agendas of, 29 
getting acquainted with, 29 
limited view of, 23 
Stand Up Meetings, 20 
State (Pattern A.18), 216, 234, 257 
State Patterns (Pattern A.19), 234, 
257 
static structure, dynamic behavior 
vs., 96 
Step through the Execution 
(Pattern 5.3) 
debugger needed for, 109 
intent, 107 
main discussion, 107-109 
problem, 107 
Record Business Rules as Tests 
(Pattern 6.5) and, 108 
scenarios for, 107, 108, 109 
solution, 108 
Tie Code and Questions (Pattern 
5.1) with, 108 
trade-offs, 108-109 
validating contracts using, 113 
what next, 109 
Write Tests to Understand (Pat- 
tern 6.6) during, 109 
Stevens, Perdita, 168 
Steyaert, Patrick, 113 
Stonebraker, Michael, 162 
stored tests, 124, 126 
Strategy (Pattern A.20), 216, 237, 
258 
Study the Exceptional Entities 
(Pattern 4.3) 
after Speculate about Design 
(Pattern 4.2), 84 
as bottom-up method, 67 
choosing metrics for, 86 
choosing tools for, 85-86 
code browsing for confirmation, 
87 
example, 88-92 
identifying anomalies, 87 
identifying design problems, 85 
intent, 84 
interpreting results, 86-87 
known uses, 93 

280 
I N D E X 
Study the Exceptional Entities 
(Pattern 4.3) (continued) 
main discussion, 84-93 
normal entities and, 87 
problem, 85 
rationale, 92-93 
Read All the Code in One Hour 
(Pattern 3.2) as preparation 
for, 44 
repeated application of, 67 
risks revealed by, 68 
solution, 85-87 
threshold application and, 86 
time required for, 67 
trade-offs, 87-88 
what next, 93 
success 
initial tasks and, 22 
small, frequent iterations for, 22 
verifying for mock installation, 59 
SUnit, 125, 131 
super calls, class assumptions 
about subclasses and, 112 
Sweeping It under the Rug pattern. 
See Present the Right Interface 
(Pattern 7.8) 
switches 
perl script for identifying simu- 
lated switches in C++, 251 
self type checks and, 218 
symptoms 
fixing problems instead, 23 
of need for reengineering, 2-4 
synchronizing business rules, doc- 
umentation, and implemen- 
tation. See Record Business 
Rules as Tests (Pattern 6.5) 
synchronizing code with questions 
and answers. See Tie Code and 
Questions (Pattern 5.1) 
system administrators, user infor- 
mation from, 52 
system development forces, 
121-122 
systematic testing, 127, 130-131 
T 
table of contents for documenta- 
tion, overview of structure 
from, 45 
teams 
common sense of purpose for, 18 
differing agendas of members, 29 
effective communication for, 
66-67 
keeping synchronized, 20 
knowing capabilities of mem- 
bers, 36 
manageable pieces of legacy 
systems for, 28 
sharing knowledge with, 66 
technological issues, sociological 
issues vs., 35 
technology, as reason for reengi- 
neering, 2 
Template Method (Pattern A.21), 
112,258 
template/hook methods, special- 
izing classes and, 112 
Test Fuzzy Features (Pattern A.2), 
123,254 
Test Old Bugs (Pattern A.3), 123, 254 
Test the Interface, Not the Imple- 
mentation (Pattern 6.4) 
Detailed Model Capture infor- 
mation and, 97 
example, 138-139 
granularity of testing and, 130 
Grow Your Test Base Incremen- 
tally (Pattern 6.2) and, 130 
intent, 136 
known uses, 139 
main discussion, 136-139 
Migrate Systems Incrementally 
(Pattern 7.3) and, 155 
problem, 137 
rationale, 139 
Record Business Rules as Tests 
(Pattern 6.5) vs., 139 
related patterns, 139 
reusing stable parts of design 
and, 117 
solution, 137 
trade-offs, 137-138 
Write Tests to Enable Evolution 
(Pattern 6.1) and, 127 
testing framework. See Use a Test- 
ing Framework (Pattern 6.3) 
tests 
caveat, 121 
in code review checklist, 39 
customer expectations and, 122 
developers' resistance to, 125 
as documentation, 124 
Grow Your Test Base Incre- 
mentally (Pattern 6.2), 122, 
127, 128-130, 142, 155, 160 
introducing incrementally, 
128-130 
migration and, 76, 84 
missing, need for reengineering 
and, 2 
programmers' low priority for, 122 
Record Business Rules as Tests 
(Pattern 6.5), 58, 97, 108, 130, 
139-142 
reengineering and, 84 
Regression Test after Every 
Change (Pattern 7.6), 123, 148, 
155, 159-160, 210 
regression tests after refactoring, 
103 
Retest Persistent Problems (Pat- 
ternA.1), 123, 160, 253-254 
reusable, 136-139 
reusing stable parts of design 
and, 117 
selling to client, 124, 125 
Step through the Execution 
(Pattern 5.3) scenarios as, 109 
system development and, 121 
systematic testing, 127, 130-131 
Test Fuzzy Features (Pattern 
A.2), 123, 254 
Test Old Bugs (Pattern A.3), 123, 
254 
Test the Interface, Not the Im- 
plementation (Pattern 6.4), 
97, 117, 127, 130, 136-139, 155 
thumbnail patterns, 253-254 
Use a Testing Framework 
(Pattern 6.3), 122, 130-136 
well-designed, properties of, 124 
white-box testing for algorithms, 
139 
Write Tests to Enable Evolution 
(Pattern 6.1), 122, 123-127, 160 
Write Tests to Understand 
(Pattern 6.6), 97, 106, 109, 
122-123, 130, 142-144 
writing before implementing 
functionality, 160 
Tests: Your Life Insurance! 
caveat, 121 
forces, 121-122 
Grow Your Test Base Incremen- 
tally (Pattern 6.2), 128-130 
map of patterns, 120 
Migration Strategies supported 
by, 123 
overview, 122-123 
Record Business Rules as Tests 
(Pattern 6.5), 139-142 
Test the Interface, Not the 
Implementation (Pattern 6.4), 
136-139 
Use a Testing Framework 
(Pattern 6.3), 130-136 
Write Tests to Enable Evolution 
(Pattern 6.1), 123-127 
Write Tests to Understand 
(Pattern 6.6), 142-144 
See also specific patterns 
thumbnail patterns 
design patterns, 253,256-258 
refactorings, 253,254-255 
testing patterns, 253-254 
Tie Code and Questions (Pattern 5.1) 
as fundamental, 96 
intent, 98 

INDEX 
281 
known uses, 101-103 
main discussion, 98-103 
problem, 98 
rationale, 101 
Refactor to Understand (Pattern 
5.2) with, 103, 106, 107 
related patterns, 103 
solution, 98-100 
Step through the Execution 
(Pattern 5.3) with, 108 
trade-offs, 100-101 
Write Tests to Understand 
(Pattern 6.6) and, 144 
time 
comments out of date, 40, 50 
deferring time-consuming activ- 
ities, 28-29 
documentation out of date, 45, 
46, 48-49 
introducing tests incrementally, 
128-130 
as most precious resource, 
28-29 
wasting early in a project, 28, 29 
time requirements 
Do a Mock Installation (Pattern 
3.5), 59, 60 
for Initial Understanding, 67 
Interview during Demo (Pattern 
3.4) and, 53 
Keep It Simple (Pattern 2.7) and, 
25 
need for reengineering and, 3 
for Read All the Code in One 
Hour (Pattern 3.2), 40, 42 
for Speculate about Design 
(Pattern 4.2), 79 
tools 
choosing for Study the Excep- 
tional Entities (Pattern 4.3), 
85-86 
for class relationship overview, 
111 
for Learn from the Past (Pattern 
5.5), 114, 115 
for refactoring, 105-106 
testing frameworks, 131,132-136 
for unit testing, 125 
top-down study of source code, 
bottom-up study vs., 67 
Transform Client Type Checks 
(Pattern 10.2) 
detection, 226-227 
example, 229-233 
intent, 225 
Introduce Null Object (Pattern 
10.5) and, 233 
main discussion, 225-234 
Move Behavior Close to Data 
(Pattern 9.1) vs., 191 
overview, 216-217 
problem, 225-226 
rationale, 233 
related patterns, 233-234 
Replace Conditional with Poly- 
morphism (Pattern A.9) and, 
234 
solution, 226-228 
steps, 227-228 
trade-offs, 228-229 
Transform Conditionals into 
Registration (Pattern 10.6) 
and, 233,250 
Transform Self Type Checks 
(Pattern 10.1) and, 225 
when the legacy solution is the 
solution, 229 
Transform Conditionals into Regis- 
tration (Pattern 10.6) 
example, 245-249 
intent, 243 
main discussion, 243-251 
overview, 217 
perl script for identifying simu- 
lated switches in C++, 251 
problem, 243 
related patterns, 250 
solution, 243-245 
trade-offs, 249-250 
Transform Client Type Checks 
(Pattern 10.2) and, 233,250 
Transform Self Type Checks 
(Pattern 10.1) and, 225 
Transform Conditionals to Poly- 
morphism 
duplicated code and, 174, 184, 
185 
Factor Out State (Pattern 10.3), 
234-237 
Factor Out Strategy (Pattern 
10.4), 237-240 
forces, 215-216 
Introduce Null Object (Pattern 
10.5), 240-243 
map of patterns, 214 
overview, 216-217 
Replace Conditional with Poly- 
morphism (Pattern A.9), 255 
Transform Client Type Checks 
(Pattern 10.2), 225-234 
Transform Conditionals into 
Registration (Pattern 10.6), 
243-251 
Transform Self Type Checks 
(Pattern 10.1), 217-225 
See also specific patterns 
Transform Self Type Checks (Pat- 
tern 10.1) 
detection, 218-219 
example, 223-225 
Factor Out State (Pattern 10.3) 
and, 225 
Factor Out Strategy (Pattern 
10.4) and, 225 
intent, 217 
main discussion, 217-225 
overview, 216 
problem, 217-218 
rationale, 225 
related patterns, 225 
solution, 218-220 
steps, 219-220 
trade-offs, 221-223 
Transform Client Type Checks 
(Pattern 10.2) and, 225 
Transform Conditionals into 
Registration (Pattern 10.6) 
and, 225 
when the legacy solution is the 
solution, 222 
type checks. See Transform Client 
Type Checks (Pattern 10.2); 
Transform Self Type Checks 
(Pattern 10.1) 
U 
unbundling monolithic systems, as 
reason for reengineering, 1 
understanding, iteration implied 
by, 66 
unit testing 
JUnit example, 126 
as property of well-designed 
tests, 124 
tools for, 125, 131 
Unix, detecting self type checks in, 
219 
unstable design 
detecting, 115 
dismissing or fixing, 117 
usage scenarios, Interview during 
Demo (Pattern 3.4) for, 50-51, 
58 
Use a Testing Framework (Pattern 
6.3) 
example, 132-136 
Grow Your Test Base Incremen- 
tally (Pattern 6.2) and, 130 
intent, 130 
known uses, 136 
main discussion, 130-136 
organizing tests, 130 
overview, 122 
problem, 130-131 
rationale, 136 
solution, 131 
steps, 131 
trade-offs, 13 l 
Use Profiler before Optimizing 
(Pattern 7.12), 149, 169-170 

282 
I N D E X 
user feedback 
Involve the Users (Pattern 7.1) 
and, 151 
Keep It Simple (Pattern 2.7) and, 
25 
Migrate Systems Incrementally 
(Pattern 7.3) and, 22, 154 
user interface, Interview during 
Demo (Pattern 3.4) for evalu- 
ating, 57 
users 
choosing for Interview during 
Demo (Pattern 3.4), 51-52, 53 
departure of, need for 
reengineering and, 3 
as documentation audience, 44, 
46, 49 
ensuring user acceptance, 
149-151 
Involve the Users (Pattern 7.1), 
22, 25, 148, 149-151,153, 169 
test writing by, 140 
See also Interview during Demo 
(Pattern 3.4); public interfaces 
utility classes, 189 
V 
value 
complexity and, 22 
determining valuable data, 
68-73 
determining what is valuable, 
21-22 
of legacy systems, 1 
Most Valuable First (Pattern 2.4), 
19, 20-22, 23, 155 
variables, comparing code and, 
175-176 
verification 
of class diagram, 72 
of maintainers' input, 37 
of mock installation findings, 
62-63 
of mock installation success, 59 
tests as, 126 
of users' input, 58 
version numbers, documentation 
currency and, 45 
versioning tests, 126 
versions, comparing. See Learn 
from the Past (Pattern 5.5) 
Visitor (Pattern A.22), 194, 258 
Visualize Code as Dotplots (Pattern 
8.2) 
example, 183-184 
Extract Method (Pattern A.5) 
and, 185 
intent, 180 
interpretations, 181-182 
known uses, 184-185 
main discussion, 180-185 
Move Behavior Close to Data 
(Pattern 9.1) and, 185 
problem, 181 
related patterns, 185 
solution, 181-182 
steps, 181 
trade-offs, 182-183 
Transform Conditionals to Poly- 
morphism and, 184, 185 
vocabulary of developers, Read All 
the Code in One Hour (Pat- 
tern 3.2) and, 40 
W,X 
white-box testing, for algorithms, 
139 
Woolf, Bobby, 242 
wrapping 
Adapter (Pattern A.11) for, 193 
data containers, 193 
data provider instances, 193 
Fix Problems, Not Symptoms 
(Pattern 2.5) and, 23 
If It Ain't Broke, Don't Fix It 
(Pattern 2.6) and, 24 
pinpointing problems and, 23 
Present the Right Interface 
(Pattern 7.8), 12, 149, 155, 
163-164, 212-213 
Write Tests to Enable Evolution 
(Pattern 6.1) 
as Always Have a Running Ver- 
sion (Pattern 7.5) prerequisite, 
127 
example, 126 
Grow Your Test Base Incremen- 
tally (Pattern 6.2) and, 122, 127 
importance of, 122 
intent, 123 
main discussion, 123-127 
Migrate Systems Incrementally 
(Pattern 7.3) with, 127, 155 
problem, 123 
properties of well-designed 
tests, 124 
rationale, 126-127 
Regression Test after Every 
Change (Pattern 7.6) and, 160 
related patterns, 127 
solution, 124 
Test the Interface, Not the 
Implementation (Pattern 6.4) 
and, 127 
trade-offs, 124-125 
Write Tests to Understand (Pattern 
6.6) 
during Refactor to Understand 
(Pattern 5.2), 97, 106 
during Step through the Execu- 
tion (Pattern 5.3), 109 
Grow Your Test Base Incremen- 
tally (Pattern 6.2) and, 130 
intent, 142 
main discussion, 142-144 
overview, 122-123 
priming a test base, 130 
problem, 142-143 
rationale, 144 
Record Business Rules as Tests 
(Pattern 6.5) with, 142 
Refactor to Understand (Pattern 
5.2) before, 144 
related patterns, 144 
Retest Persistent Problems 
(Pattern A.1), 123 
solution, 143 
Test Fuzzy Features (Pattern 
A.2), 123 
Test Old Bugs (Pattern A.3), 123 
Tie Code and Questions (Pattern 
5.1) and, 144 
trade-offs, 143 
Y,Z 
Yoder, Joseph W., 157, 213 

