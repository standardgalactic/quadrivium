OPERATING SYSTEMS 
AND SERVICES 

OPERATING SYSTEMS 
AND SERVICES 
edited by 
R.Rajkumar 
Carnegie Mellon University, U.S.A. 
A Special Issue of 
REAL-TIME SYSTEMS 
The International Journal of Time-Critical 
Computing Systems 
Volume 16, Nos. 213 (1999) 
KLUWER ACADEMIC PUBLISHERS 
Boston I Dordrecht I London 

Distributors for North, Central and South America: 
Kluwer Academic Publishers 
101 Philip Drive 
Assinippi Park 
Norwell, Massachusetts 02061 USA 
Telephone (781) 871-6600 
Fax (781) 871-6528 
E-Mail <kluwer@wkap.com> 
Distributors for aU other countries: 
Kluwer Academic Publishers Group 
Distribution Centre 
Post Office Box 322 
3300 AH Dordrecht, THE NETHERLANDS 
Telephone 31 78 6392 392 
Fax 31 786546474 
E-Mail <services@wkap.nl> 
1iIo.. 
,.. Electronic Services <http://www.wkap.nl> 
Library of Congress Cataloging-in-Publication Data 
Operating systems and services 1 edited by R. Rajkumar. 
p. cm. 
"A special issue of Real-time systems, the international journal 
of time-critical computing systems, volume 16, nos. 2/3 (1999)." 
Includes bibliographical references. 
ISBN 0-7923-8548-9 (alk. paper) 
1. Operating systems (Computers) 2. Real-time data processing. I. 
Rajkumar, Ragunathan. II. Real time systems. 
QA76.76.06306391999 
005.4 '3--dc2 I 
Copyright ® 1999 by Kluwer Academic Publishers 
99-28475 
CIP 
All rights reserved. No part of this publication may be reproduced, stored in a 
retrieval system or transmitted in any form or by any means, mechanical, photo-
copying, recording, or otherwise, without the prior written permission of the 
publisher, Kluwer Academic Publishers, 101 Philip Drive, Assinippi Park, Norwell, 
Massachusetts 02061 
Printed on acid-free paper. 

REAL-TIME 
SYSTEMS 
The International 
Journal of 
Time-Critical 
Computing Systems 
Volume 16, Number 2/3, May, 1999 
Special Issue on Operating Systems and Services 
Guest Editor: Raj Rajkumar 
ARMADA Middleware and Communication Services ...................... . 
T. Abdelzaher; S. Dawson, W-c. Feng, F. Jahanian, S. Johnson, A. Mehra, T. Mitton, 
A. Shaikh, K. Shin, Z. Wang and H. Zou 
An Open Environment for Real-Time Applications ......................... . 
· ....................... Z. Deng, 1. W -So Liu, L. Zhang, S. Mouna and A. Frei 
29 
On Developing Distributed Middleware Services for QoS- and Criticality-Based 
Resource Negotiation and Adaptation ............ 1. Huang, Y. Wang and F. Cao 
61 
The Spring System: Integrated Support for Complex Real-Time Systems ....... . 
· . . .. J. A. Stankovic, K. Ramamritham, D. Niehaus, M. Humphrey and G. Wallace 
97 
Expressing and Enforcing Timing Constraints in a Dynamic Real-Time CORBA 
System ............................................................ . 
· . . . . .. V. F. Wolfe, L. C. Dipippo, R. Ginis, M. Squadrito, S. Wohlever and I. Zykh 
127 
Regular Paper: 
To Schedule or to Execute: Decision Support and Performance Implications ..... 
· .............................. B. Hamidzadeh, Y. Atif and K. Ramamritham 
155 

~ 
The International Journal of Time-Critical Computing Systems, 16, 127-153 (1999) 
ft © 1999 Kluwer Academic Publishers, Boston. Manufactured in The Netherlands. 
ARMADA Middleware and Communication 
Services * 
T. ABDELZAHER 
S.DAWSON 
w'-C.FENG 
EJAHANIAN 
S.JOHNSON 
A.MEHRA 
T.MITTON 
A. SHAIKH 
K. SHIN 
Z.WANG 
H.ZOU 
M. BJORKLAND 
P.MARRON 
Real-Time Computing Laboratory, Department of Electrical Engineering and Computer Science, The University 
of Michigan, Ann Arbor, MI48109-2122, USA 
Abstract. 
Real-time embedded systems have evolved during the past several decades from small custom-
designed digital hardware to large distributed processing systems. As these systems become more complex, 
their interoperability, evolvability and cost-effectiveness requirements motivate the use of commercial-off-the-
shelf components. This raises the challenge of constructing dependable and predictable real-time services for 
application developers on top of the inexpensive hardware and software components which has minimal support 
for timeliness and dependability guarantees. We are addressing this challenge in the ARMADA project. 
ARMADA is set of communication and middleware services that provide support for fault-tolerance and end-to-
end guarantees for embedded real-time distributed applications. Since real-time performance of such applications 
depends heavily on the communication subsystem, the first thrust of the project is to develop a predictable 
communication service and architecture to ensure QoS-sensitive message delivery. Fault-tolerance is of paramount 
importance to embedded safety-critical systems. In its second thrust, ARMADA aims to offload the complexity 
of developing fault-tolerant applications from the application programmer by focusing on a collection of modular, 
composable middleware for fault-tolerant group communication and replication under timing constraints. Finally, 
we develop tools for testing and validating the behavior of our services. We give an overview of the ARMADA 
project, describing the architecture and presenting its implementation status. 
Keywords: distributed real-time systems, communication protocols, fault-tolerant systems 
1. Introduction 
ARMADA is a collaborative project between the Real-Time Computing Laboratory (RTCL) 
at the University of Michigan and the Honeywell Technology Center. The goal of the 
project is to develop and demonstrate an integrated set of communication and middleware 
* This work is supported in part by a research grant from the Defense Advanced Research Projects Agency, 
monitored by the U.S. Air Force Rome Laboratory under Grant F30602-95-1-0044. 
1 

128 
ABDELZAHER ET AL. 
services and tools necessary to realize embedded fault-tolerant and real-time services on 
distributed, evolving computing platforms. These techniques and tools together compose 
an environment of capabilities for designing, implementing, modifying, and integrating 
real-time distributed systems. Key challenges addressed by the ARMADA project include: 
timely delivery of services with end-to-end soft/hard real-time constraints; dependability 
of services in the presence of hardware or software failures; scalability of computation 
and communication resources; and exploitation of open systems and emerging standards in 
operating systems and communication services. 
ARMADA communication and middleware services are motivated by the requirements 
of large embedded applications such as command and control, automated flight, shipboard 
computing, and radar data processing. Traditionally, such embedded applications have 
been constructed from special-purpose hardware and software. This approach results in 
high production cost and poor interoperability making the system less evolvable and more 
prone to local failures. A recent trend, therefore, has been to build embedded systems 
using Commercial-Off-The-Shelf (COTS) components such as PC boards, Ethernet links, 
and PC-based real-time operating systems. This makes it possible to take advantage of 
available development tools, leverage on mass production costs, and make better use of 
component interoperability. From a real-time application developer's point of view, the 
approach creates the need for generic high-level software services that facilitate building 
embedded distributed real-time applications on top of inexpensive widely available hard-
ware. Real-time operating systems typically implement elementary subsets of real-time 
services. However, monolithically embedding higher-level support in an operating system 
kernel is not advisable. Different applications have different real-time and fault-tolerance 
requirements. Thus, catering to all possible requirement ranges in a single operating sys-
tem would neither be practical nor efficient. Instead, we believe that a compos able set 
of services should be developed of which only a subset may need to exist for any given 
application. This philosophy advocates the use of a real-time microkernel equipped with 
basic real-time support such as priority-based scheduling and real-time communication, in 
addition to a reconfigurable set of compos able middleware layered on top of the kernel. Ap-
propriate testing and validation tools should be independently developed to verify required 
timeliness and fault-tolerance properties ofthe distributed middleware. 
The ARMADA project is therefore divided into three complementary thrust areas: (i) 
low-level real-time communication support, (ii) middleware services for group communi-
cation and fault-tolerance, and (iii) dependability evaluation and validation tools. Figure 1 
summarizes the structuring of the ARMADA environment. 
The first thrust focused on the design and development of real-time communication ser-
vices for a microkernel. A generic architecture is introduced for designing the communi-
cation subsystem on hosts so that predictability and QoS guarantees are maintained. The 
architecture is independent of the particular communication service. It is illustrated in 
this paper in the context of presenting the design of the real-time channel; a low-level 
communication service that implements a simplex, ordered virtual connection between 
two networked hosts that provides deterministic or statistical end-to-end delay guarantees 
between a sender-receiver pair. 
The second thrust of the project has focused on a collection of modular and composable 
middleware services (or building blocks) for constructing embedded applications. A lay-
2 

ARMADA MIDDLEWARE AND COMMUNICATION SERVICES 
Microkcrncl 
Figure I. Overview of ARMADA Environment. 
APPLICA nONS 
REAL-TIME 
CHAN ELS 
129 
ered open-architecture supports modular insertion of a new service or implementation as 
requirements evolve over the life-span of a system. The ARMADA middleware services 
include a suite of fault-tolerant group communication services with real-time guarantees, 
called RTCAST, to support embedded applications with fault-tolerance and timeliness re-
quirements. RTCAST consists of a collection of middleware including a group membership 
service, a timed atomic multicast service, an admission control and schedulability module, 
and a clock synchronization service. The ARMADA middleware services also include 
a real-time primary-backup replication service, called RTPB, which ensures temporally 
consistent replicated objects on redundant nodes. 
The third thrust of the project is to build a toolset for validating and evaluating the 
timeliness and fault-tolerance capabilities of the target system. Tools under development 
include fault injectors at different levels (e.g. operating system, communication protocol, 
and application), a synthetic real-time workload generator, and a dependability/performance 
monitoring and visualization tool. The focus of the toolset research is on portability, 
flexibility, and usability. 
Figure 2 gives an overview of a prospective application to illustrate the utility of our 
services for embedded real-time fault-tolerant systems. The application, developed at 
Honeywell, is a subset of a command and control facility. Consider a radar installation 
where a set of sensors are used to detect incoming threats (e.g., enemy planes or missiles in 
a battle scenario); hypotheses are formed regarding the identity and positions of the threats, 
and their flight trajectories are computed accordingly. These trajectories are extrapolated 
into the future and deadlines are imposed to intercept them. The time intervals during 
which the estimated threat trajectories are reachable from various ground defense bases 
are estimated; and appropriate resources (weapons) are committed to handle the threats; 
eventually, the weapons are released to intercept the threats. 
3 

130 
ABDELZAHER ET AL. 
I~ 
~ ~ ~I =-= 
Sensory Input 
leo ~1~1:p},~I~ 
1 
Weapon 
Release 
Risk 
oplrilPz'ition 
I Hypothesis 
Assessment 
Testing and 
t I 
I 
Threat 
IdentificatioD 
~ 
~ 
1 
Plotting 
I Trajectory 
I 
Terrain Masking 
Extrapolation 
r 
I Surveillance I 
I_T~~ 
Intelligence 
Estimation 
II.",. 
_II 
I 
-
J Computing l 
. 
. 1 Accessibility I 
Weapon 
. 1 from Bases 
Assignment 
and Scheduling 
I Compute I 
Weap~~Base 
POSItIons 
Figure 2. A command and control application 
The services required to support writing such applications come naturally from their oper-
ating requirements. For example, for the anticipated system load, communication between 
different system components (the different boxes in Figure 2) must occur in bounded time 
to ensure a bounded end-to-end response from threat detection to weapon release. Our 
real-time communication services compute and enforce predictable deterministic bounds 
on message delays given application traffic specification. Critical system components such 
as hypothesis testing and threat identification have high dependability requirements which 
are best met using active replication. For such components, RTCAST exports multicast and 
membership primitives to facilitate fault detection, fault handling, and consistency manage-
ment of actively replicated tasks. Similarly, extrapolated trajectories of identified threats 
represent critical system state. A backup of such state needs to be maintained continually 
and updated to represent the current state within a tolerable consistency (or error) margin. 
Our primary-backup replication service is implemented to meet such temporal consistency 
requirements. Finally, our testing tools decrease development and debugging costs of the 
distributed application. 
The rest of this paper is organized as follows. Section 2 describes the general approach 
for integrating ARMADA services into a microkemel framework. It also presents the 
experimental testbed and implementation environment of this project. The subsequent 
sections focus on the architecture, design, and implementation of key communication and 
middleware services in ARMADA. Section 3 introduces real-time communication service. 
Section 4 presents the RTCAST suite of group communication and fault-tolerance services. 
4 

ARMADA MIDDLEWARE AND COMMUNICATION SERVICES 
131 
Section 5 describes the RTPB (real-time primary-backup) replication service. Section 6 
briefly discusses the dependability evaluation and validation tools developed in this project. 
Section 7 concludes the paper. 
2. Platform 
The services developed in the context of the ARMADA project are to augment the es-
sential capabilities of a real-time microkernel by introducing a composable collection of 
communication, fault-tolerance, and testing tools to provide an integrated framework for 
developing and executing real-time applications. Most of these tools are implemented as 
separate multithreaded servers. Below we describe the experimental testbed and imple-
mentation environment common to the aforementioned services. A detailed description of 
the implementation approach adopted for various services will be given in the context of 
each particular service. 
2.1. 
General Service Implementation Approach 
One common aspect of different middleware services in a distributed real-time system 
is their need to use intermachine communication. All ARMADA services either include 
or are layered on top of a communication layer which provides the features required for 
correct operation of the service and its clients. For example, RTCAST implements com-
munication protocols to perform multicast and integrate failure detection and handling into 
the communication subsystem. Similarly, the Real-Time Channels service implements its 
own signaling and data transfer protocols to reserve resources and transmit real-time data 
along a communication path. Since communication seemed to warrant particular attention 
in the context of this project, we developed a generic real-time communication subsys-
tem architecture. The architecture can be viewed as a way of structuring the design of 
communication-oriented services for predictability, as opposed to being a service in itself. 
This architecture is described in detail in Section 3 and is illustrated by an example ser-
vice: the Real-Time Channel. ARMADA communication services are generally layered 
on top of IP, or UDPIIP. We do not use TCP because its main focus is reliability as opposed 
to predictability and timeliness. Real-time communication protocols, on the other hand, 
should be sensitive to timeliness guarantees, perhaps overriding the reliability requirement. 
For example, in video conferencing and process control, occasional loss of individual data 
items is preferred to receiving reliable streams of stale data. To facilitate the development of 
communication-oriented services, our communication subsystem is implemented using the 
x-kernel object-oriented networking framework originally developed at the University of 
Arizona (Hutchinson and Peterson, 1991), with extensions for controlled allocation of sys-
tem resources (Travostino, Menze and Reynolds, 1996). The advantage of using x-kernel 
is the ease of composing protocol stacks. An x-kernel communication subsystem is imple-
mented as a configurable graph of protocol objects. It allows easy reconfiguration of the 
protocol stack by adding or removing protocols. More details on the x-kernel can be found 
in (Hutchinson and Peterson, 1991). 
Following a microkernel philosophy, argued for in Section 1, our services are designed 
as user-level multithreaded servers. Clients of the service are separate processes that com-
5 

132 
ABDELZAHER ET AL 
municate with the server via the kernel using a user library. The library exports the desired 
middleware API. Communication-oriented services generally implement their own protocol 
stack that lies on top of the kernel-level communication driver. The x -kernel framework per-
mits migration of multithreaded protocol stack execution into the operating system kernel. 
We use this feature to implement server co-location into the microkernel. Such co-location 
improves performance by eliminating extra context switches. Note that the advantages of 
server co-location do not defeat the purpose of choosing a microkernel over a monolithic op-
erating system for a development platform. This is because with a microkernel co-located 
servers (i) can be developed in user space which greatly reduces their development and 
maintenance cost, and (ii) can be selectively included, when needed, into the kernel in 
accordance with the application requirements; this is both more efficient and more sensitive 
to particular application needs. 
The microkernel has to support kernel threads. The priority of threads executing in kernel 
space is, by default, higher than that of threads executing in user space. As a result, threads 
run in a much more predictable manner, and the service does not get starved under overload. 
Furthermore, the in-kernel implementation of x-kernel on our platform replaces some of 
the threads in the device driver by code running in interrupt context. This feature reduces 
communication latencies and makes the server less preemptable when migrated into the 
microkernel. However, since code executing in interrupt context is kept to a minimum, the 
reduction in preeptability has not been a concern in our experiences with co-located code. 
Figure 3-a and 3-b illustrate the configurations of user-level servers and co-located servers 
respectively. An example of server migration into the kernel is given in the context of the 
RTCAST service in Section 4. The RTCAST server was developed in user space (as in 
Figure 3-a), then reconfigured to be integrated the into the kernel (as in Figure 3-b). Whether 
the server runs in user space or is co-located in the microkernel, client processes use the 
same service API to communicate with it. If the service is co-located in the kernel, an 
extra context switch to/from a user-level server process is saved. Automatically-generated 
stubs interface the user library (implementing the service API) to the microkernel or the 
server process. These stubs hide the details of the kernel's local communication mechanism 
from the programmer of the real-time service, thus making service code independent from 
specifics of the underlying microkernel. 
2.2. 
Testbed and Implementation Environment 
In the following sections we describe the implementation of each individual service. To 
provide a common context for that description, we outline here the specifics of the under-
lying implementation platform. Our testbed comprises several Pentium-based PCs (133 
MHz) connected by a Cisco 2900 Ethernet switch (10/100 Mb/s), with each PC connected 
to the switch via 10 Mb/s Ethernet. We have chosen the MK 7.2 microkernel operating 
system from the Open Group (OG)1 Research Institute to provide the essential underlying 
real-time support for our services. The MK microkernel is originally based on release 2.5 
of the Mach operating system from CMU. While not a full-fledged real-time OS, MK 7.2 
supports kernel threads, priority-based scheduling, and includes several important features 
that facilitate provision of QoS guarantees. For example, MK 7.2 supports x-kernel and 
provides a unified framework for allocation and management of communication resources. 
6 

ARMADA MIDDLEWARE AND COMMUNICATION SERVICES 
user 
Application 
Library 
Stub 
Microkernel 
network 
Server 
(and protocol slack) 
00 
, 
, 
, 
, 
I 
I 
, 
-1"" 
I 
I 
r 
I 
Application 
Library 
Stub 
f , 
'--
(a) User-level server configuration 
Figure 3. Service implementation. 
Application 
Application 
Library 
Library 
Stub 
Stub 
user 
;, 
~. 
Mlcrokernel 
~ 
Colocated 
Server 
I 
I 
device driver 
network 
(b) Co-located server 
133 
This framework, known as CORDS (Communication Objects for Real-time Dependable 
Systems) (Travostino, Menze and Reynolds, 1996), was found particularly useful for im-
plementing real-time communication services. Our implementation approach has been to 
utilize the functionality and facilities provided in OG's environment and augment it with 
our own support when necessary. 
From the standpoint of portability, although MK7.2 is a research operating system, 
CORDS support is also available on more mainstream operating systems such as Win-
dows NT. Thus, our software developed for the CORDS environment can easily be ported 
to NT. In fact, such port is currently underway. Porting to other operating systems, such 
as Linux, is more difficult. At the time the presented services were developed Linux did 
not support kernel threads. Thus, it was impossible to implement multithreaded protocol 
stacks inside the Linux kernel. Linux 2.2, however, is expected to have full thread support. 
CORDS support may be replaced by appropriate packet filters to classify incoming traffic. 
Thus, with some modifications, our services may be ported to future versions of Linux, as 
well as other multithreaded operating systems such as Solaris, 
3. ARMADA Real-Time Communication Architecture 
ARMADA provides applications with a communication architecture and service with which 
they can request and utilize guaranteed-QoS connections between two hosts. In this section, 
we hilight the architectural components of the communication service that, together with a 
set of user-specified policies, can implement several real-time communication models. 
Common to QoS-sensitive communication service models are the following three archi-
tectural requirements: (i) performance isolation between connections or sets of connections 
such that malicious behavior or overload of one does not starve resources of the other(s), 
7 

134 
ABDELZAHER ET AL. 
(ii) service differentiation, such as assigning different priorities to connections or classes 
of connections, and (iii) graceful degradation in the presence of overload. We developed 
a Communication Library for Implementing Priority Semantics (CLIPS), that provides 
resource-management mechanisms to satisfy the aforementioned requirements. It exports 
the abstraction of guaranteed-rate communication endpoints. The endpoint, called a clip, 
guarantees a certain throughput in terms of the number of packets sent via it per period, 
and implements a configurable buffer to accommodate bursty sources. One or more con-
nections (or sockets) may be "bound" to the same clip, in which case the clip sets aside 
enough processor bandwidth and memory resources on the end-system to guarantee an 
aggregate specified throughput for the entire connection set. Different clips may have dif-
ferent priorities to allow higher priority traffic to proceed first under overload conditions. 
For example, traffic of a particular application or middleware service can be bound to a 
high priority clip, thereby allowing that application or service to receive precedence over 
other services. Each clip has an associated deadline parameter. The deadline specifies the 
maximum communication subsystem response time for handling packets via the particular 
clip. The CLIPS library implements a traffic policing mechanism, as well as its own default 
admission control policy that can be disabled to revert to pure priority-driven scheduling or 
overridden by a user-specified alternate admission control policy. More details on CLIPS 
will be given below as we present the ARMADA real-time communication service we 
developed for unicast communication. 
3.1. 
Real-time Communication Service 
We have used CLIPS to implement a guaranteed-QoS communication service called the 
real-time channel (Ferrari and Yerman, 1990), (Kandlur, Shin and Ferrari, 1994). A real-
time channel is a unicast virtual connection between a source and destination host with 
associated performance guarantees on message delay and available bandwidth. It satisfies 
three primary architectural requirements for guaranteed-QoS communication (Mehra, In-
diresan and Shin, 1996): (i) maintenance of per-connection QoS guarantees, (ii) overload 
protection via per-connection traffic enforcement, and (iii) fairness to best-effort traffic. 
Real-time communication via real-time channels is performed in three phases. in the first 
phase, the source host S (sender) creates a channel to the destination host D (receiver) by 
specifying the channel's traffic parameters and QoS requirements. Signaling requests are 
sent from S to D via one or more intermediate (I) nodes; replies are delivered in the reverse 
direction from D to S. If successfully established, S can send messages on this channel to D; 
this constitutes the second phase. When the sender is done using the channel, it must close 
the channel (the third phase) so that resources allocated to this channel can be released. 
Figure 4 illustrates the high-level software architecture of our guaranteed-QoS service at 
end-hosts. The core functionality of the communication service is realized via three distinct 
components that interact to provide guaranteed-QoS communication. Applications use the 
service via the real-time communication application programming interface (RTC API); 
RTCOP coordinates end-to-end signaling for resource reservation and reclamation during 
connection set-up or tear-down; and CLIPS performs run-time management of resources for 
QoS-sensitive data transfer. Since platform-specific overheads must be characterized before 
QoS guarantees can be ensured, an execution profiling component is added to measure and 
8 

ARMADA MIDDLEWARE AND COMMUNICATION SERVICES 
135 
APPLICATIONS 
VIDEO 
AT CONTROL 
AUDIO 
Figure 4. Real-time communication service architecture: Our implementation consists of four primary ar-
chitectural components: an application programming interface (RTC API), a signaling and resource reservation 
protocol (RTCOP), support for resource management and run-time data transfer (CLIPS), and execution profiling 
support. Dashed lines indicate interactions on the control path while the data path is denoted by the solid lines. 
parameterize the overheads incurred by the communication service on a particular platform, 
and make these parameters available for admission control decisions. The control path taken 
through the architecture during connection setup is shown in Figure 4 as dashed lines. Data 
is then transferred via RTC API and CLIPS as indicated by the solid lines. Below, we 
discuss the salient features of each architectural component of the service along with its 
interaction with other components to provide QoS guarantees. We also describe how the 
components are used to realize a particular service model. 
3.2. 
RTC Application Inteiface 
The programming interface exported to applications comprises routines for connection 
establishment and teardown, message transmission and reception during data transfer on 
established connections, and initialization and support routines. Table 1 lists some of the 
main routines currently available in RTC API. The API has two parts: a top half that 
interfaces to applications and is responsible for validating application requests and creating 
internal state, and a bottom half which interfaces to RTCOP for signaling (i.e., connection 
setup and teardown), and to CLIPS for QoS-sensitive data transfer. 
The design of RTC API is based in large part on the well-known socket API in BSD 
Unix. Each connection endpoint is a pair (IPaddr, port) formed by the IP address 
of the host (IPaddr) and an unsigned 16-bit port (port) unique on the host, similar to 
an INET domain socket endpoint. In addition to unique endpoints for data transfer, an 
application may use several endpoints to receive signaling requests from other applications. 
Applications willing to be receivers of real-time traffic register their signaling ports with 
9 

136 
ABDELZAHER ET AL 
Table 1. Routines comprising RTC API: This table shows the utility, signaling, and data transfer functions 
that constitute the application interface. The table shows each function name, its parameters, the endpoint 
that invokes it, and a brief description of the operation perfonned. 
Routines 
Parameters 
Invoked By Function Performed 
rtclnit 
none 
both 
service initialization 
rtcGetParameter 
chan id, param type 
both 
query parameter on specified 
real-time connection 
rtcRegisterPort 
localport,agentfunction 
receiver 
register local port and 
agent for signaling 
rtcUnRegisterPort 
local port 
receiver 
unregister local signaling port 
rtcCreateConnection 
remote host/port, QoS: 
sender 
create connection with given 
max rate, max burst size 
parameters to remote 
max msg size, max delay 
endpoint; return connection id 
rtcAcceptConnection 
local port, chan id, 
receiver 
obtain the next connection 
remote host/port 
already established at 
specified local port 
rtcDestroyConnection 
chan id 
sender 
destroy specified real-time 
connection 
rtcSendMessage 
chan id, buf ptr 
sender 
send message on specified 
real-time connection 
rtcRecvMessage 
chand id, buf ptr 
receiver 
receive message on specified 
real-time connection 
a name service or use well-known ports. Applications wishing to create connections must 
first locate the corresponding receiver endpoints before signaling can be initiated. 
Each of the signaling and data transfer routines in Table 1 has its counterpart in the socket 
API. For example, the routine rtcRegisterPort corresponds to the invocation of bind 
and listen in succession, and rtcAcceptConnection corresponds to accept. Simi-
larly, the routines rtcCreateConnection and rtcDestroyConnection correspond 
to connect and close, respectively. 
The key aspect which distinguishes RTC API from the socket API is that the receiving 
application explicitly approves connection establishment and teardown. When registering 
its intent to receive signaling requests, the application specifies an agent function that is 
invoked in response to connection requests. This function, implemented by the receiving 
application, determines whether sufficient application-level resources are available for the 
connection and, if so, reserves necessary resources (e.g., CPU capacity, buffers, etc.) for 
the new connection. It may also perform authentication checks based on the requesting 
endpoint specified in the signaling request. This is unlike the establishment of a TCP 
connection, for example, which is completely transparent to the peer applications. 
10 

ARMADA MIDDLEWARE AND COMMUNICATION SERVICES 
137 
REAL-TIME COMMUNICATION API 
REAL-TIME COMMUNICATION API 
J 
messages!. 
CLIPS 
Passive resources 
tragm/ 1""'-- J 
comm. threads 
RTCQP 
g CPU allocation 
H 
JH ~.m J 
LOWER 
comm. thread 
resource 
PROTOCOL 
8chedLder 
Interface 
LAYERS V 
Link allocation 
packets 1 
link scheduler J 
b'ansmission/reception 
DEVICE DRIVER 
J 
I 
NETWORK 
J 
(a) RTCOP structure 
(b) CLIPS structure 
Figure 5. Internal structures and interfaces: In this figure we show the internal functional structure of RTCOP 
and CLIPS along with their respective interfaces to other components. In (a), data and control paths are represented 
with solid and dashed lines, respectively. 
The QoS-parameters passed to rtcCreateConnection for connection establishment 
describe a linear bounded arrival traffic generation process (Cruz, 1987, Anderson, et al. 
1990). They specify a maximum message size (Smax bytes), maximum message rate (Rmax 
messages/second), and maximum burst size (Bmax messages). Parameters Smax and Rmax 
are used to create a clip with a corresponding guaranteed throughput. The burst size, Bmax, 
determines the buffer size required for the clip_ In the following we describe the end-to-end 
signaling phase that coordinates end-to-end resource reservation. 
3.3. 
Signaling and Resource Reservation with RTCOP 
Requests to create and destroy connections initiate the Real-Time Connection Ordination 
Protocol (RTCOP), a distributed end-to-end signaling protocol. As illustrated in Figure 5( a), 
RTCOP is composed primarily of two relatively independent modules. The request and 
reply handlers manage signaling state and interface to the admission control policy, and the 
communication module handles the tasks of reliably forwarding signaling messages. This 
separation allows simpler replacement of admission control policies or connection state 
management algorithms without affecting communication functions. Note that signaling 
and connection establishment are non-real-time (but reliable) functions. QoS guarantees ap-
ply to the data sent on an established connection but signaling requests are sent as best-effort 
traffic_ 
The request and reply handlers generate and process signaling messages, interface to 
RTC API and CLIPS, and reserve and reclaim resources as needed_ When processing a 
new signaling request, the request handler invokes a multi-step admission control procedure 
to decide whether or not sufficient resources are available for the new request. As a new 
connection request traverses each node of the route from source to destination, the request 
handler invokes admission control which decides if the new connection can be locally 
11 

138 
ABDELZAHER ET AL. 
admitted. Upon successful admission, the handler passes the request on to the next hop. 
When a connection is admitted at all nodes on the route, the reply handler at the destination 
node reserves the required end-system resources by creating a clip for the new real-time 
channel, and generates a positive acknowledgment on the reverse path to the source. As 
the notification is received at each hop, the underlying network-level protocol commits 
network resources, such as link bandwidth, using assumed local router support. When 
the acknowledgement is received at the source the reply handler notifies the application of 
connection establishment and creates the source clip. 
The communication module handles the basic tasks of sending and receiving signaling 
messages, as well as forwarding data packets to and from the applications. Most of the 
protocol processing performed by the communication module is in the control path during 
processing of signaling messages. In the data path it functions as a simple transport protocol, 
forwarding data packets on behalf of applications, much like UDP. As noted earlier, signaling 
messages are transported as best-effort traffic, but are delivered reliably using source-based 
retransmissions. Reliable signaling ensures that a connection is considered established only 
if connection state is successfully installed and sufficient resources reserved at all the nodes 
along the route. The communication module implements duplicate suppression to ensure 
that multiple reservations are not installed for the same connection establishment request. 
Similar considerations apply to connection teardown where all nodes along the route must 
release resources and free connection state. Consistent connection state management at all 
nodes is an essential function of RTCOP. 
RTCOP exports an interface to RTC API for specification of connection establishment 
and teardown requests and replies, and selection of logical ports for connection endpoints. 
The RTC API uses the latter to reserve a signaling port in response to a request from the 
application, for example. RTCOP also interfaces to an underlying routing engine to query 
an appropriate route before initiating signaling for a new connection. In general, the routing 
engine should find a route that can support the desired QoS requirements. However, for 
simplicity we use static (fixed) routes for connections since it suffices to demonstrate the 
capabilities of our architecture and implementation. 
3.4. 
CLIPS-based Resource Scheduling for Data Transfer 
CLIPS implements the necessary end-system resource-management mechanisms to realize 
QoS-sensitive real-time data transfer on an established connection. A separate clip is created 
for each of the two endpoints of a real-time channel. Internal to each clip is a message queue 
to buffer messages generated or received on the corresponding channel, a communication 
handler thread to process these messages, and a packet queue to stage packets waiting 
to be transmitted or received. The CLIPS library implements on the end-system the key 
functional components illustrated in Figure 5(b). 
QoS-sensitive CPU scheduling: The communication handler thread of a clip executes 
in a continuous loop either dequeuing outgoing messages from the clip's message queue 
and fragmenting them (at the source host), or dequeuing incoming packets from the clip's 
packet queue and reassembling messages (at the destination host). Each message must 
be sent within a given local delay bound (deadline). To achieve the best schedulable 
utilization, communication handlers are scheduled based on an earliest-deadline-first (EDF) 
12 

ARMADA MIDDLEWARE AND COMMUNICATION SERVICES 
139 
policy. Since most operating systems do not provide EDF scheduling, CLIPS implements 
it with a user-level scheduler layered on top of the operating system scheduler. The user-
level scheduler runs at a static priority and maintains a list of all threads registered with 
it, sorted by increasing deadline. At any given time, the CLIPS scheduler blocks all of 
the registered threads using kernel semaphores except the one with the earliest deadline, 
which it considers in the running state. The running thread will be allowed to execute 
until it explicitly terminates or yields using a primitive exported by CLIPS. The scheduler 
then blocks the thread on a kernel semaphore and signals the thread with the next earliest 
deadline. Preemption is implemented via a CLIPS primitive invoked upon sending each 
packet. The primitive yields execution to a more urgent thread if one is pending. This 
arrangement implements EDF scheduling within a single protection domain. 
Resource reservatiou: Communication handlers (implemented by CLIPS) execute a user-
defined protocol stack, then return to CLIPS code after processing each message or packet. 
Ideally, each clip should be assigned a CPU budget to prevent a communication client 
from monopolizing the CPU. Since processor capacity reserves are not available on most 
operating systems, the budget is indirectly expressed in terms of a maximum number of 
packets to be processed within a given period. The handler blocks itself after processing 
the maximum number of packets allowed within its stated time period. 
Policing: Associating a budget with each connection handler facilitates traffic enforcement. 
This is because a handler is scheduled for execution only when the budget is non-zero, and 
the budget is not replenished until the next (periodic) invocation of the handler. This 
mechanism ensures that misbehaving connections are policed to their traffic specification. 
QoS-sensitive link bandwidth allocation: Modern operating systems typically implement 
FIFO packet transmission over the communication link. While we cannot avoid FIFO 
queuing in the kernel's network device, CLIPS implements a dynamic priority-based link 
scheduler at the bottom of the user-level protocol stack to schedule outgoing packets in 
a prioritized fashion. The link scheduler implements the EDF scheduling policy using a 
priority heap for outgoing packets. To prevent a FIFO accumulation of outgoing packets 
in the kernel (e.g., while the link is busy), the CLIPS link scheduler does not release a new 
packet until it is notified of the completion of previous packet transmission. Best-effort 
packets are maintained in a separate packet heap within the user-level link scheduler and 
serviced at a lower priority than those on real-time clips. 
Figure 6 demonstrate traffic policing, traffic isolation and performance differentiation in 
real-time channels. A more detailed evaluation is found in (Mehra, Shaikh and Abdekaher, 
1998). 
4. 
RTCAST Group Communication Services 
The previous section introduced the architecture of the ARMADA real-time communication 
service. This architecture sets the ground for implementing real-time services with QoS-
sensitive communication. The second thrust of the project has focused on a collection of 
such services, that provide modular and composable middleware for constructing embedded 
applications. The ARMADA middleware can be divided into two relatively independent 
suites of services: 
• 
RTCAST group communication services, and 
13 

140 
300 
~m~asu~~~P-ut-(Ch-')~~--""-------~ l 
-- measured throughput (ch 2) 
1 
tr - 6. specified throughput (ch 1) 
'i}- - 'V specified throughput (ch 2) 
j 
1
200 
!J~ !J-~~ 
~ ~--~~~~~~~1 
~ 150 
" 
i 
j 100 
~ 
t!l 
I 
250 
5:_~ 
__ =~_L . 
__ ~_~~_~ _J 
80 
180 
280 
380 
480 
580 
Offered load on channel 1 (KBIs) 
(a) Isolation between real-time channels 
ABDELZAHER ET AL. 
300 :--
.~ 
-~ ~~-~-'~~~~~'l 
l 
0 --D RT channel 1 
1 
ir---{] RT chat1nel 2 
250 
!s- -D. BE channel 3 
+~-OT~ocl 
'"' /1 
1001 /' 
! 
! 
I 
~( 
1 
i'-----Lr------J-------Ll----t:r------------o--- T 
o~.~~~~~~-~~~ _~~._"~ 
.. _~~J 
50 
_ 
_ 
~ 
~ 
~ 
_ 
Offered load on best-effort channel (KB/s) 
(b) Isolation between best-effort and real-time 
Figure 6. Traffic isolation: The left graph shows that real time channel I is policed to its traffic specification, 
disallowing violation of that specification. Traffic on real-time channel 1 does not affect the QoS for the other 
real-time channel 2. The right graph shows that increasing best~effort load does not interfere with real-time channel 
throughput. 
• 
RTPB real-time primary-back replication service. 
This section presents the RTCAST suite of group communication and fault-tolerance ser-
vices. Section 5 describes the RTPB (real-time primary-backup) replication service. 
4.1. 
RTCAST Protocols 
The QoS-sensitive communication service described in Section 3 does not support multicast 
channels. Multicast is important, e.g., for efficient data dissemination to a set of destinations, 
or for maintaining replicated state in fault-tolerant systems. If consistency of replicated state 
is desired, a membership algorithm is also needed. RTCAST complements aforementioned 
unicast communication services by mulitcast and membership services for real-time fault-
tolerant applications. RTCAST is based around the process groups paradigm. 
Process groups are a widely-studied paradigm for designing distributed systems in both 
asynchronous (Birman, 1993), (Amir, et al., 1992), (van Renesse, Hickey and Birman, 1994), 
(Mishra, Peterson and Schlichting, 1993) and synchronous (Hermann and Grtinsteidl, 1994), 
(Amir, et al., 1995), (Christian, Dancy and Dehn, 1990) environments. In this approach, a 
distributed system is structured as a group of cooperating processes which provide service 
to the application. A process group may be used, for example, to provide active replication 
of system state or to rapidly disseminate information from an application to a collection of 
processes. Two key primitives for supporting process groups in a distributed environment 
are fault-tolerant multicast communication and group membership. Coordination of a pro-
cess group must address several subtle issues including delivering messages to the group 
in a reliable fashion, maintaining consistent views of group membership, and detecting and 
handling process or communication failures. If multicast messages are atomic and globally 
ordered, consistency of replicated state will be guaranteed. 
14 

ARMADA MIDDLEWARE AND COMMUNICATION SERVICES 
141 
Unreliable Unicast Communication 
Figure 7. Software architecture for the RTCAST middleware services. 
RTCAST is especially designed for real-time applications. In a real-time application, 
timing failures may be as damaging as processor failures. Thus, our membership algorithm 
is more aggressive in ensuring timely progress of the process group. For example, while 
ensuring atomicity of message delivery, RTCAST does not require acknowledgments for 
every message, and message delivery is immediate without needing additional "rounds" 
of message transmissions to ensure that a message was received consistently by all des-
tinations. RTCAST is designed to support hard real-time guarantees without requiring a 
static schedule to be computed a priori for application tasks and messages. Instead, an 
on-line schedulability analysis component performs admission control on multicast mes-
sages. We envision the proposed multicast and membership protocols as part of a larger 
suite of middleware group communication services that form a composable architecture for 
the development of embedded real-time applications. 
As illustrated in Figure 7, the RTCAST suite of services include a timed atomic multicast, 
a group membership service and an admission control service. The first two are tightly 
coupled and thus are considered a single service. Clock synchronization is typically required 
for real-time protocols and is enforced by the clock synchronization service. To support 
portability, a virtual network interface layer exports a uniform network abstraction. Ideally, 
this interface would transparently handle different network topologies, each having different 
connectivity and timing or bandwidth characteristics exporting a generic network abstraction 
to upper layers. The network is assumed to support unicast datagram service. Finally, the 
top layer provides an application programming interface for real-time process group. 
RTCAST supports bounded-time message transport, atomicity, and order for multicasts 
within a group of communicating processes in the presence of processor crashes and com-
munication failures. It guarantees agreement on membership among the communicating 
processors, and ensures that membership changes (e.g., resulting from processor joins or 
departures) are atomic and ordered with respect to multicast messages. RTCAST assumes 
15 

142 
ABDELZAHER ET AL. 
that processes can communicate with the environment only by sending messages. Thus, a 
failed process, for example, cannot adversely affect the environment via a hidden channel. 
RTCAST proceeds as senders in a logical ring take turns in multicasting messages over the 
network. A processor's turn comes when the logical token arrives, or when it times out 
waiting for it. After its last message, each sender multicasts a heartbeat that is used for crash 
detection. The heartbeat received from an immediate predecessor also serves as the logical 
token. Destinations detect missed messages using sequence numbers and when a processor 
detects a receive omission, it crashes. Each processor, when its turn comes, checks for 
missing heartbeats and eliminates the crashed members, if any, from group membership by 
multicasting a membership change message. 
In a token ring, sent messages have a natural order defined by token rotation. We recon-
struct message order at the receivers using a protocol layer below RTCAST which detects 
out-of-order arrival of messages and swaps them, thus forwarding them to RTCAST in 
correct order. RTCAST ensures that "correct" members can reach agreement on replicated 
state by formulating the problem as one of group membership. Since the state of a process 
is determined by the sequence of messages it receives, a processor that detects a message 
receive omission takes itself out of the group, thus maintaining agreement among the re-
maining ones. In a real-time system one may argue that processes waiting for a message 
that does not arrive will miss their deadlines anyway, so it is acceptable to eliminate the 
processor(s) which suffered receive omissions.2 A distinctive feature of RTCAST is that 
processors which did not omit any messages can deliver messages as soon as they arrive 
without compromising protocol semantics. Thus, for example, if a reliable multicast is used 
to disseminate a critical message to a replicated server, and if one of the replicas suffers a 
receive omission, RTCAST will eliminate that replica from the group, while delivering the 
message to the remaining replicas immediately. This is in contrast to delaying delivery of 
the message until all replicas have received it. The approach is motivated by the observation 
that in a real-time system it may be better to sacrifice one replica in the group than delay 
message delivery potentially causing all replicas to miss a hard timing constraint. Finally, 
membership changes are communicated exclusively by membership change messages us-
ing our multicast mechanism. Since message multicast is atomic and ordered, so are the 
membership changes. This guarantees agreement on membership view. 
From an architectural standpoint, RTCAST operation is triggered by two different event 
types, namely message reception, and token reception (or timeout). It is therefore logically 
structured as two event handlers, one for each event type. The message reception handler 
(Figure 8) detects receive omissions if any, delivers messages in order to the application, 
and services protocol control messages. The token handler (Figure 9) is invoked when 
the token is received or when the token timeout expires. It detects processor crashes and 
sends membership change notifications, if any, as well as lets client processes send out their 
messages during the processors finite token hold time. 
4.2. 
RTCAST Design and Implementation 
This section describes some of the major issues in the design and implementation of RT-
CAST; our representative group communication service. A thorough performance evalua-
tion of the service is reported on in (Abdelzaher, et aI., 1996) and (Abdelzaher, et aI., 1997). 
16 

ARMADA MIDDLEWARE AND COMMUNICATION SERVICES 
143 
1. msgJeCeptionJiandlerO 
2. 
if state = RUNNING 
3. 
ifmore msgs from same member 
4. 
if missed msgs --+ CRASH else 
5. 
deliver msg 
6. 
else if msg from different member 
7. 
if missed msgs --+ CRASH else 
8. 
check for missed msgs from processors between current and last senders 
9. 
if no missing msgs 
10. 
deliver current msg 
11. 
else CRASH 
12. 
else if join msg from non-member 
13. 
handle join request 
14. 
if state = JOINING AND msg is a valid join-llck 
15. 
if need more join-llcks 
16. 
wait for additional join_acks 
17. 
else state = RUNNING 
18. end 
Figure 8. Message reception handler 
1. tokenJiandlerO 
2. 
if state = RUNNING 
3. 
for each processor p in current membership view 
4. 
if no heartbeat seen from all predecessors inc!. p 
5. 
remove p from group view 
6. 
multicast new group view 
7. 
send out all queued messages 
8. 
mark the last msg 
9. 
send out heartbeat msg 
10. 
if state = JOINING 
11. 
send out join msg 
12. end 
Figure 9. Token handler 
17 

144 
ABDELZAHER ET AL 
The RTCAST application was implemented and tested over a local Ethernet. Ethernet is 
normally unsuitable for real-time applications due to packet collisions and the subsequent 
retransmissions that make it impossible to impose deterministic bounds on communication 
delay. However, since we use a private Ethernet (i.e. the RTCAST protocol has exclusive 
access to the medium), only one machine can send messages at any given time (namely, 
the token holder). This prevents collisions and guarantees that the Ethernet driver always 
succeeds in transmitting each packet on the first attempt, making message communication 
delays deterministic. The admission control service described previously can take advantage 
of this predictability, e.g., by creating appropriate clips to manage end-system resources on 
each host and make real-time guarantees on messages sent with RTCAST. 
4.2.1. 
Protocol Stack Design 
The RTCAST protocol was designed to be modular, 
so that individual services could be added, changed, or removed without affecting the 
rest of the protocol. Each service is designed as a separate protocol layer within the 
x-kernel (Hutchinson and Peterson, 1991) protocol framework. The x-kernel is an ideal 
choice for implementing the RTCAST middleware services because application require-
ments can be easily met by simply reconfiguring the protocol stack to add or remove services 
as necessary. The RTCAST implementation uses the following protocol layers: 
Admission Control: The Admission Control and Schedulability Analysis (ACSA) layer 
is a distributed protocol that keeps track of communication resources of the entire process 
group. The protocol transparently creates a clip on each host that runs the process group 
to ensure communication throughput guarantees and time-bounded message processing. It 
can support multiple either prioritized or performance isolated process groups on the same 
machine by creating clips of corresponding priority and corresponding minimum throughput 
specification. If real-time guarantees are not needed, this layer can be omitted from the 
protocol stack to reduce overhead. Communication will then proceed on best-effort basis. 
RTCAST: The RTCAST protocol layer encompasses the membership, logical token ring, 
and atomic ordering services described in section 4. 
Multicast Transport: This protocol implements an unreliable multicast abstraction that 
is independent of the underlying network. RTCAST uses the multicast transport layer to 
send messages to the group without having to worry about whether the physical medium 
provides unicast, broadcast, or true multicast support. The details of how the messages 
are actually sent over the network are hidden from higher layers by the multicast transport 
protocol, so it is the only layer that must be modified when RTCAST is run on different 
types of networks. 
Figure 10 shows the full protocol stack as it is implemented on our platform. 
4.2.2. 
Integration Into the Mach Kernel 
As figure 10 shows, the protocol stack repre-
senting the core of the service was migrated into the Mach kernel. While actual RTCAST 
development took place in user space to facilitate debugging, its final co-location within the 
Mach kernel has several performance advantages. First, as with any group communication 
protocol, there can be a high amount of CPU overhead to maintain the group state and 
enforce message semantics. By running in the kernel, the RTCAST protocol can run at the 
highest priority and minimize communication latency due to processing time. Second, in 
18 

ARMADA MIDDLEWARE AND COMMUNICATION SERVICES 
145 
APPLICATTON 
[ SERVICE INTERFACE ) 
APPLICATION 
( 
LIBRARY 
) 
l 
ASCA 
J 
( 
INTERFACE STUB 
) 
l 
RTCAST 
1 
USER 
l 
MCAST 
l 
IP 
J 
I 
EJ~--I 
l 
ETHDRV 
J 
SER 
u 
K 
- - --
- -
- -- - -
- -- -----J 
- - - - -- - - - - - --
ERNEL 
I Kernel Ethernet Driver I 
(a) CORDS User-level Server 
(b) Split In-kernel CORDS Server 
Figure 10. RTCAST protocol stack as implemented 
the current implementation of MK 7.2 there is no operating system support for real-time 
scheduling or capacity reserve. Experience shows that processes running at the user level 
can be starved for CPU time for periods of up to a few seconds, which would be disas-
trous for RTCAST's predictable communication. By running in the kernel, protocol threads 
do not get starved significantly and are scheduled in a much more predictable manner by 
the operating system. Finally, there is a problem with the MK 7.2 implementation of the 
x-kernel, such that threads which are shepherding messages up the protocol stack can be 
queued to run in a different order than the messages arrive from the network. This results in 
out-of-order messages that must be buffered and re-ordered to maintain the total ordering 
guarantees provided by the protocol. Having to buffer and reorder messages also delays 
crash detection, since there is no way of knowing if a missing message is queued somewhere 
in the protocol stack or if the sender suffered a failure. By running the protocol in the kernel, 
message threads are interrupt driven and run immediately after arriving from the network, 
so the message reordering problem does not occur. Protocol performance improved almost 
by an order of magnitude when executed in the kernel. For example, when executed at the 
user-level, the minimum token rotation time was on average 2.6 ms, 5.7 ms, and 9.6 ms 
for groups with one, two, and three members respectively. When running in the kernel, 
the same measurement yielded token rotation times of 0.43 ms, 1.02 ms, and 1.55 ms. We 
found that this improvement extended to all aspects of protocol performance. Note that the 
above figures suggest a potential scalability problem for larger group sizes (such as hundreds 
of nodes). The problem is attributed to the need for software token passing. Integration 
with hardware token passing schemes, such as FDDI, will yield much better performance. 
Alternatively, to improve scalability, we are currently investigating an approach based on 
group composition. Larger process groups are formed by a composition of smaller ones. 
This research is presently underway. Initial results show that composite process groups 
scale much better than monolithic ones. 
19 

146 
ABDELZAHER ET AL. 
Another important focus in developing our group communication rniddleware was de-
signing a robust API that would allow application developers to take advantage of our 
services quickly and easily. RTCAST API includes (i) bandwidth reservation calls, (ii) 
process group membership manipulation functions, (iii) best-effort multicast communica-
tion primitives and (iv) reliable real-time multicast. Bandwidth reservation is used on hosts 
to ensure that a multicast connection has dedicated CPU capacity and network bandwidth 
(i.e. a minimum token hold time). The token hold time and token rotation period specify 
the communication bandwidth allotted to the node. The node can set aside enough end-
system resources to utilize its allotted communication bandwidth by creating a clip (by the 
ACSA layer) of a corresponding throughput thereby providing schedulability guarantees. 
The membership manipulation functions allow processes to join and leave the multicast 
group, query current group membership, create groups, etc. There are two types of group 
communication: real-time multicast communication that guarantees end-to-end response 
time, and best-effort which does not. The advantages of using a best-effort connection is 
that it is optimized for throughput as opposed to meeting individual message deadlines. 
Thus, the service protocol stack is faster on the average (e.g., no per-message admission 
control), but the variance in queuing delays is higher. 
We collaborated with a group of researchers at the Honeywell Technology Center to im-
plement a subset of the fault-tolerant real-time distributed application described in Section 1 
using the RTCAST protocol. Using the insights gained from this motivating application, 
we were able to refine the API to provide the required of functionality while maintaining 
a simple interface that is easy to program. Based on our experience of the application's 
use of the protocol, we also designed a higher-level service library that can be linked with 
the application, and which uses the RTCAST API3• It is concerned with resource manage-
ment in a fault-tolerant system and with providing higher-level abstractions of the protocol 
communication primitives. The service library provides for logical processing nodes and 
resource pools that transparently utilize RTCAST group communication services. These 
abstractions provide a convenient way for application developers to reason about and struc-
ture their redundancy management and failure handling policies while RTCAST does the 
actual work of maintaining replica consistency. 
5. Real-Time Primary-backup (RTPB) Replication Service 
While the previous section introduced a rniddleware service for active replication, in this 
section we present the overall architecture of the ARMADA real-time primary-backup 
replication service. We first give an introduction to the RTPB system, then describe the 
service framework. Finally we discuss implementation of the service that we believe meets 
the objectives. 
5.1. 
1ntroduction to RTPB 
Keeping large amounts of application state consistent in a distributed system, as in the 
state machine approach, may involve a significant overhead. Many real-time applications, 
however, can tolerate minor inconsistencies in replicated state. Thus, to reduce redundancy 
management overhead, our primary-backup replication exploits application data semantics 
20 

ARMADA MIDDLEWARE AND COMMUNICATION SERVICES 
147 
by allowing the backup to maintain a less current copy of the data that resides on the primary. 
The application may have distinct tolerances for the staleness of different data objects. With 
sufficiently recent data, the backup can safely supplant a failed primary; the backup can 
then reconstruct a consistent system state by extrapolating from previous values and new 
sensor readings. However, the system must ensure that the distance between the primary 
and the backup data is bounded within a predefined time window. Data objects may have 
distinct tolerances in how far the backup can lag behind before the object state becomes 
stale. The challenge is to bound the distance between the primary and the backup such that 
consistency is not compromised, while minimizing the overhead in exchanging messages 
between the primary and its backup. 
5.2. 
Service Framework 
A very important issue in designing a replication service is its consistency semantics. 
One category of consistency semantics that is particular relevant to the primary-backup 
replication in a real-time environment is temporal consistency, which is the consistency 
view seen from the perspective of the time continuum. Two types of temporal consistency 
are often needed to ensure proper operation of a primary-backup replicated real-time data 
services system. One is the external temporal consistency between an object of the external 
world and its image on the servers, the other is the inter-object temporal consistency between 
different objects or events. 
A primary-backup system is said to satisfy the external temporal consistency for an object 
i if the timestamp of i at the server is no later than a predetermined time from its timestamp 
at the client (the real data). In other words, in order to provide meaningful and correct 
service, the state of the primary server must closely reflect that of the actual world. This 
consistency is also needed at the backup if the backup were to successfully replace the 
primary when the primary fails. The consistency restriction placed on the backup may not 
be as tight as that on the primary but must be within a tolerable range for the intended 
applications. 
The inter-object temporal consistency is maintained if for any object pair, their temporal 
constraint oij (which is the temporal distance of any two neighboring updates for object i, 
and j, respectively) is observed at both primary and backup. 
Although the usefulness or practical application of the external temporal consistency 
concept is easy to see, the same is not true for inter-object temporal consistency. To 
illustrate the notion of inter-object temporal consistency, considering an airplane during 
taking off. There is a time bound between accelerating the plane and the lifting of the plane 
into air because the runway is of limited length and the airplane can not keep accelerating 
on the runway indefinitely without lifting off. In our primary-backup replicated real-time 
data service, the inter-object temporal consistency constraint between an object pair placed 
on the backup can be different from that placed on the primary. 
5.3. 
RTPB Implementation 
A temporal consistency model for the Real-time Primary-backup (RTPB) replication service 
has been developed (Zou and Jahanian, 1998) and a practical version of the system that 
21 

148 
ABDELZAHER ET AL. 
Primary 
Backup 
Figure 11. RTPB architecture and server protocol stack 
implements the models has been built. Following our compos ability model, the RTPB 
service is implemented as an independent user-level x-kernel based server on our MK 
7.2 based platform. Our system includes a primary server and a backup server. A client 
application resides in the same machine as the primary. The client continuously senses the 
environment and periodically sends updates to the primary. The client accesses the server 
using a library that utilizes the Mach IPC-based interface. The primary is responsible for 
backing up the data on the backup site and limiting the inconsistency of the data between 
the two sites within some required window. The following assumptions are made in the 
implementation: 
• 
Link failures are handled using physical redundancy such that network partitions are 
avoided. 
• 
An upper bound exists on the communication delay between the primary and the backup. 
Missed message deadlines are treated as communication performance failures. 
• 
Servers are assumed to suffer crash failures only. 
Figure 11 shows our system architecture and the x-kernel protocol stack for the replication 
server. The bottom five layers (RTPB to ETHDRV) make up the x-kernel protocol stack. At 
the top level of the stack is our real-time primary-backup (RTPB) protocol. It serves as an 
anchor protocol in the x-kernel protocol stack. From above, it provides an interface to the 
x-kernel based server. From below, it connects with the rest of the protocol stack through the 
x-kernel uniform protocol interface. The underlying transport protocol is UDP. Since UDP 
does not provide reliable delivery of messages, we need to use explicit acknowledgments 
when necessary. 
22 

ARMADA MIDDLEWARE AND COMMUNICATION SERVICES 
149 
The top two layers are the primary-backup hosts and client applications. The primary 
host interacts with the backup host through the underlying RTPB protocol. There are 
two identical versions of the client application residing on the primary and backup hosts 
respectively. Normally, only the client version on the primary is running. But when the 
backup takes over in case of primary failure, it also activates the backup client version and 
bring it up to the most recent state. 
The client application interacts with the RTPB system through the Mach API interface 
we developed for the system. The interface enables the client to create, destroy, manipulate 
and query reliable objects (i.e., those backed-up by our server). Specifically, rtpb_create, 
rtpbJiestroy creates objects on and destroys objects from the RTPB system; rtpb1egister 
register objects with the system; rtpbJlpdate, rtpb-4uery update and query objects; finally 
rtpbJist return a list of objects that are already registered with the RTPB system. Further 
detail on admission control, update scheduling, failure detection and recovery appears in a 
recent report (Zou and Jahanian, 1998). 
5.4. 
RTPB Performance 
The following graph shows the RTPB response time to client request and the temporal 
distance between the primary and backup. Both graphs are depicted as a function of the 
number of objects admitted into the system and are for four different client write rates of 
100, 300, 700, and 1000 milliseconds. 
400.0 
_window size = 100 rna 
•. _ ...... window size = 300 rns 
• 
• window size = 700 rns 
.. 
.. window size"" 1 000 rns 
100.0 
200.0 
30Q,0 
400.0 
500.0 
Number 01 Object Accepted at Primary 
(a) Response time to client 
Figure 12. RTPB performance graphs 
200.0 
I 
100.0 
I 
~ 
~ 100.0 
~ I t SO.O 
~ 
• 
• W = 100 milliseconds 
• 
• W ;; 300 milliseconds 
• .• W = 700 milliseconds 
... 
... W = 1000 milliseconds 
• 
I 
.. .-_--:-1 
-... _.-.. -._---.--
"-c-~__cc" 
.• '-c-~_---':'___ .. _ 
... ~ 
.. _. _·-"-:_~--,,l 
o.~ 00.0 
200.0 
300.0 
400.0 
500.0 
Number of Objects Accepted at Primary 
(b) Primary-backup distance 
Graph (a) shows a fast response time to client request in the range of 200 to 400 mi-
croseconds. This mainly due to the decoupling of client request process from updates to the 
backups. Graph (b) shows that RTPB keeps the backup very close to the primary in terms 
of the temporal distance between the corresponding data copies of the replicated objects. 
In the graph, the distance ranges from 10 to 110 milliseconds which is well within the range 
tolerable by most real-time applications. 
23 

150 
ABDELZAHER ET AL. 
The two graphs show that RTPB indeeds provide fast response to client requests while 
maintain backup(s) very close to the primary in system state. 
6. 
Evaluation Tools 
The third thrust of the ARMADA project is to provide tools for validating and evaluating 
the timeliness and fault tolerance capabilities of the target system. Two tools have been 
developed to date: ORCHESTRA, a message-level fault injection tool for validation and 
evaluation of communication and middleware protocols, and COGENT, a network traffic 
workload generator. The following two subsections describe the two tools briefly. 
6.1. 
ORCHESTRA 
The ARMADA project has been primarily concerned with developing real-time distributed 
middleware protocols and communication services. Ensuring that a distributed system or 
communication protocol meets its prescribed specification is a growing challenge that con-
fronts software developers and system engineers. Meeting this challenge is particularly 
important for applications with strict dependability and timeliness constraints. ORCHESTRA 
is a fault injection environment which can be used to perform fault injection on com-
munication protocols and distributed applications. ORCHESTRA is based on a simple yet 
powerful framework, called script-driven probing and fault injection. The emphasis of 
this approach is on experimental techniques intended to identify specific "problems" in a 
protocol or its implementation rather than the evaluation of system dependability through 
statistical metrics such as fault coverage (e.g. (ArIat, et al. 1990)). Hence, the focus is on 
developing fault injection techniques that can be employed in studying three aspects of a 
target protocol: i) detecting design or implementation errors, ii) identifying violations of 
protocol specifications, and iii) obtaining insights into the design decisions made by the 
implementors. 
In the ORCHESTRA approach, a fault injection layer is inserted into the communication 
protocol stack below the protocol to be tested. As messages are exchanged between protocol 
participants, they pass through the fault injection layer on their path to/from the network. 
Each time a message is sent, ORCHESTRA runs a script called the send filter on the message. 
In the same manner, the receive filter is invoked on each message that is received from the 
network destined for the target protocol. The scripts perform three types of operations on 
messages: 
• 
Message filtering: for intercepting and examining a message. 
• 
Message manipulation: for dropping, delaying, reordering, duplicating, or modifying 
a message. 
• 
Message injection: for probing a participant by introducing a new message into the 
system. 
The ORCHESTRA toolset on the MK 7.2 platform is based on a portable fault injec-
tion core, and has been developed in the CORDS-based x-kernel framework provided 
24 

ARMADA MIDDLEWARE AND COMMUNICATION SERVICES 
151 
by OpenGroup. The tool is implemented as an x-kernel protocol layer which can be 
placed at any level in an x-kernel protocol stack. This tool has been used to perform ex-
periments on both the Group Interprocess Communication (GIPC) services from Open-
Group, and middleware and real-time channel services developed as part of the AR-
MADA project. Further details on ORCHESTRA can be found in several recent reports, 
e.g., (Dawson, Jahanian and Mitton, 1996), (Dawson, Jahanian and Mitton, to appear). 
6.2. 
COGENT: COntrolled GEneration of Network Traffic 
In order to demonstrate the utility of the ARMADA services, it is necessary to evaluate 
them under a range of operating conditions. Because many of the protocols developed rely 
on the communication subsystem, it is important to evaluate them under a range of realistic 
background traffic. Generating such traffic is fairly difficult since traffic characteristics can 
vary widely depending on the environment in which these services are deployed. To this 
end, we've developed COGENT (COntrolled GEneration of Network Traffic). COGENT is a 
networked synthetic workload generator for evaluating system and network performance in 
a controlled, reproducible fashion. It is based on a simple client-server model and allows 
the user to flexibly model network sources in order to evaluate various aspects of network 
and distributed computing. 
Implemented in C++ with a lex/yacc front end, the current version of the tool takes a 
high level specification of the distributed workload and generates highly portable C++ 
code for all of the clients and servers specified. The user can select from a number 
of distributions which have been used to model a variety of network sources such as 
Poisson (Paxson and Floyd, 1994), (Paxson, 1994), Log Normal (Paxson and Floyd, 1994), 
Pareto (Leland, et al. 1994), (Crovella and Bestavros, 1996), (Garrett and Willinger, 1994), 
and Log Extreme (Paxson, 1994). The tool then generates the necessary compilation and 
distribution scripts for building and running the distributed workload. 
COGENT has also been implemented in JAVA. Both the generator and the generated code 
are JAVA based. Because of the portability of JAVA, this implementation simplifies both 
the compilation and distribution of the workload considerably. We also plan on addressing 
CPU issues in order to model common activities at the end hosts as well. Another feature 
being added is the ability for a client or a server to be run in trace-driven mode. That is, to 
run from a web server or a tcpdurnp (McCanne and VanJacobso, 1993) log file. Finally, 
we will be implementing additional source models in order to keep up with the current 
literature. 
7. 
Conclusions 
This paper presented the architecture and current status of the ARMADA project conducted 
at the University of Michigan in collaboration with the Honeywell Technology Center. We 
described a number of communication and middleware services developed in the context of 
this project, and illustrated the general methodology adopted to design and integrate these 
services. For modularity and composability, ARMADA middleware was realized as a set of 
servers on top of a microkernel-based operating system. Special attention was given to the 
communication subsystem since it is a common resource to middleware services developed. 
25 

152 
ABDELZAHER ET AL 
We proposed a general architecture for QoS sensitive communication, and also described a 
communication service that implements this architecture. 
We are currently redesigning an existing command and control application to benefit from 
ARMADA middleware. The application requires bounded time end-to-end communication 
delays guaranteed by our communication subsystem, as well as fault-tolerant replication and 
backup services provided by our RTCAST group communication and membership support, 
and the primary-backup replication service. Testing tools such as ORCHESTRA will 
help assess communication performance and verify the required communication semantics. 
Controlled workload generation using COGENT can assist in creating load conditions of 
interest that may be difficult to exercise via regular operation of the application. 
Our services and tools are designed independently of the underlying microkernel or the 
communication subsystem; our choice of experimentation platform was based largely on 
the rich protocol development environment provided by x-kernel and CORDS. For better 
portability, we are extending our communication subsystem to provide a socket -like API. We 
are also investigating the scalability of the services developed. Scaling to large embedded 
systems may depend on the way the system is constructed from smaller units. We are looking 
into appropriate ways of defining generic structural system components and composing 
large architectures from these components such that certain desirable properties are globally 
preserved. Developing the "tokens" and "operators" of such system composition will enable 
building predictable analytical and semantic models of larger systems from properties of 
their individual constituents. 
Notes 
1. Open Group is formerly known as the Open Software Foundation (OSF) 
2. A lower communication layer may support a bounded number of retransmissions. 
3. The APIs for both the service library and the RTCAST protocol are available at 
http://www.eecs.umich.eduIRTCUarmadaJrtcastiapi.htrnl. 
References 
Abdelzaher, Tarek, Anees Shaikh, Scott Dawson, Farnam Jahanian, and Kang Shin. Rtcast: Lightweight multicast 
for real-time process groups. in submission, available at http://www.eecs.umich.eduIRTCUarmadaJrtcasti. 1997. 
Abdelzaher, Tarek, Anees Shaikh, Farnam Jahanian, and Kang Shin. RTCAST: Lightweight multicast for real-
time process groups. In Proc. IEEE Real-Time Technology and Applications Symposium (RTAS '96), pages 
250-259, Boston, MA, June 1996. 
Amir, Y., D. Dolev, S. Kramer, and D. Mallei. 
Transis: A communication sub-system for high availability. 
Technical Report TR CS91-13, Dept. of Computer Science, Hebrew University, April 1992. 
Amir, Y., LE. Moser, P.M. Melliar-Smith, D.A. Agarwal, and P. Ciarfella. The Totem single-ring ordering and 
membership protocol. ACM Transactions on Computer Systems, \3(4):311-342, November 1995. 
Anderson, D.P., S. Y. Tzou, R. Wahbe, R. Govindan, and M. Andrews. Support for continuous media in the 
DASH system. In Proc. Int'l Con! on Distributed Computing Systems, pages 54-61,1990. 
Arlat, Jean, Martine Aguera, Yves Crouzet, Jean-Charles Fabre, Eliane Martins, and David Powell. Experimental 
evaluation of the fault tolerance of an atomic multicast system. IEEE Trans. Reliability, 39(4):455-467, October 
1990. 
Birman, Kenneth P. The process group approach to reliable distributed computing. Communications o/the ACM, 
36(12):37-53, December 1993. 
26 

ARMADA MIDDLEWARE AND COMMUNICATION SERVICES 
153 
Cristian, E, B. Dancy, and J. Dehn. Fault-tolerance in the advanced automation system. In Proc. of Fault-Tolerant 
Computing Symposium, pages 6-17, June 1990. 
Crovella, Mark and Azer Bestavros. Self-similarity in world wide web traffic: Evidence and possible causes. In 
SIGMETRICS '96, May 1996. 
Cruz, Rene Leonardo. A Calculus for Network Delay and a Note on Topologies of Interconnection Networks. 
PhD thesis, University of Illinois at Urbana-Champaign, July 1987. available as technical report UlLU-ENG-
87-2246. 
Dawson, Scott, Farnam Jahanian, and Todd Mitton. Experiments on six commercial tcp implementations using a 
software fault injection tool. to appear in Software Practice & Experience. 
Dawson, Scott, Farnam Jahanian, and Todd Mitton. Testing of Fault-Tolerant and Real-Time Distributed Systems 
via Protocol Fault Injection. In International Symposium on Fault-Tolerant Computing, pages 404-414, Sendai, 
Japan, June 1996. 
Ferrari, Domenico and Dinesh C. Verma. A scheme for real-time channel establishment in wide-area networks. 
IEEE Journal on Selected Areas in Communications, 8(3):368-379, April 1990. 
Garrett, Mark and Walter Willinger. Analysis, modeling and generation of self-similar vbr video traffic. In 
SIGCOMM '94, pages 269-280,1994. 
Hutchinson, Norman C. and Larry L. Peterson. Thex-Kernel: An architecture for implementing network protocols. 
IEEE Trans. Software Engineering, 17(1):1-13, January 1991. 
Kandlur, D. D., K. G. Shin, and D. Ferrari. Real-time communication in multi-hop networks. IEEE Trans. on 
Parallel and Distributed Systems, 5(10): 1044-1056, October 1994. 
Kopetz, Hermann and Giinter Griinsteidl. TTP - a protocol for fault-tolerant real-time systems. IEEE Computer, 
27(1):14-23, January 1994. 
Leland, Will, Murad S. Taqqu, Walter Willinger, and Daniel Wilson. On the self-similar nature of ethernet traffic 
(extended version). IEEElACM Transactions on Networking, 2(1):1-15, February 1994. 
McCanne, Steve and Van Jacobso. The bsd packet filter: A new architecture for user-level packet capture. In 
Proceedings of the 1993 Winter USENIX Technical Conference, San Diego, CA, January 1993. 
Mehra, Ashish, Atri Indiresan, and Kang Shin. 
Structuring communication software for quality of service 
guarantees. In Proc. 17th Real-Time Systems Symposium, pages 144-/54, December 1996. 
Mehra, Ashish, Anees Shaikh, Tarek Abdelzaher, Zhiqun Wang, and Kang G. Shin. 
Realizing services for 
guaranteed-qos communication on a microkernel operating system. In Proc. Real-Time Systems Symposium, 
Madrid, Spain, December 1998. 
Mishra, S., L.L. Peterson, and R.D. Schlichting. Consul: A communication substrate for fault-tolerant distributed 
programs. Distributed Systems Engineering Journal, 1(2):87-103, December 1993. 
Paxson, Vern. Empirically-derived analytic models of wide-area tcp connections. IEEElACM Transactions on 
Networking, 2(4):316-336, August 1994. 
Paxson, Vern and Sally Floyd. Wide-area traffic: The failure of poisson modeling. In SIGCOMM '94, pages 
257-268, August 1994. 
Travostino, E E.Menze, and EReynolds. Paths: Programming with system resources in support of real-time 
distributed applications. In Proc. IEEE Workshop on Object-Oriented Real-Time Dependable Systems, February 
1996. 
van Renesse, R., T.M. Hickey, and K.P. Birman. 
Design and performance of Horus: A lightweight group 
communications system. 
Technical Report TR94-1442, Dept. of Computer Science, Cornell University, 
August 1994. 
Zou, Hengming and Farnam Jahanian. 
Real-time primary backup (RTPB) replication with temporal consis-
tency guarantees. In Proceedings Inti. Conf on Distributed Computing Systems, pages 48-56, Amsterdam, 
Netherlands, May 1998. 
27 

.tl& The International Journal of Time-Critical Computing Systems, 16, 155-185 (1999) 
ft © 1999 Kluwer Academic Publishers, Boston. Manufactured in The Netherlands. 
An Open Environment for Real-Time Applications 
Z.DENG 
Department of Computer Science, University of Illinois at Urbana-Champaign, Urbana, IL 61801 
JANE w.-S. LIU 
Department of Computer Science, University of Illinois at Urbana-Champaign, Urbana, IL 61801 
L.ZHANG 
Department of Computer Science, University of Illinois at Urbana-Champaign, Urbana, lL 61801 
S.MOUNA 
Department of Computer Science, University of Illinois at Urbana-Champaign, Urbana, lL 61801 
A.PREI 
Department of Computer Science, University of Illinois at Urbana-Champaign, Urbana, IL 61801 
Abstract. This paper describes an open system architecture that allows independently developed hard real-time 
applications to run together and supports their reconfiguration at run-time. In the open system, each real-time 
application is executed by a server. At the lower level, the OS scheduler schedules all the servers on the EDF basis. 
At the upper level, the server scheduler of each server schedules the ready jobs of the application executed by the 
server according to the algorithm chosen for the application. The paper describes the two-level CPU scheduling 
scheme used by the open system and the design and implementation of a uniprocessor open system within the 
framework of the Windows NT operating system. The implementation consists of three key components: the 
two-level hierarchical kernel scheduler, common system service providers, and real-time application programming 
interface. 
Keywords: open-system, real-time application, two-level scheduler 
1. Introduction 
Traditional hard real-time systems are closed systems. Often, all the applications in the 
system are developed together. Whether an application can meet its deadlines can be 
determined only by a global schedulability analysis based on the timing attributes of all 
tasks in all applications that may run at the same time. 
A more ideal environment is an open one. In an open environment, the developer of each 
real-time application can choose to schedule the tasks in the application according to an 
algorithm most suited for the application and validate the schedulability of the application 
independently of other applications that may run together with it. Any real-time application 
can request to start at run-time. The open system has a simple but accurate acceptance test. 
In particular, the test does not rely on a global schedulability analysis. Rather, the test 
treats each multi-threaded real-time application as a black box and uses only a few overall 
timing attributes of the application. Upon receiving a request to start a new real-time 
application, the open system subjects the application to the test and accepts the application 
29 

156 
DENGET AL. 
only if the application passes the test. Once the system accepts a real-time application, it 
schedules the application according to the algorithm chosen by its developer and guarantees 
the schedulability of the application regardless of the behavior of other applications in the 
system. In essence, the open system provides each real-time application with a slower 
virtual processor which isolates the application from other applications in the system. 
This paper describes an open system architecture that can be implemented within the 
framework of a general purpose thread-based operating system (e.g., Solaris, Windows 
NT). It is implemented by modifying the Windows NT operating system. The open system 
extension consists of three key components, 
1. a two-level kernel scheduler and an admission mechanism; 
2. a set of service providersl (e.g., file server, network protocol stack handler) that deliver 
common system services; and 
3. a set of real-time application programming interface (RTAPI) functions for real-time ap-
plications to specify their real-time attributes and communicate with service providers. 
The kernel scheduler implements the two-level hierarchical scheduling scheme described in 
(Deng, Liu, and Sun, 1997; Deng and Liu, 1997). The scheme was developed specifically for 
the purpose of scheduling multi-threaded real-time and non-real-time applications running 
concurrently in an open system. 
Following this introduction, Section 2 describes related work. Section 3 provides a brief 
overview of the open system architecture. Sections 4 and 5 describe the algorithms used 
for the purposes of acceptance test and budget replenishment, respectively. Section 6 
describes the structure of service providers. Section 7 describes the real-time application 
programming interface (RTAPI) provided by the open system. Section 8 describes the 
implementation of the open system in Windows NT. Section 9 gives the performance of the 
open system. Section 10 is a summary and describes future work. To make the paper more 
self-contained, the appendix provides the pseudo-code description of parts of the two-level 
scheduler. 
2. 
Related Work 
In recent years, researchers in the real-time system and communication network areas have 
developed independently several so called fluid-flow resource sharing algorithms. The 
algorithms have different names (e.g., total bandwidth server (Spuri and Buttazzo, 1996), 
constant utilization server (Deng, Liu, and Sun, 1997), proportional resource sharing (Stoic a 
et aI., 1996), weighted fair queueing (Demers, Keshav, and Shenker, 1989), and virtual clock 
(Zhang, 1991) algorithms), but are identical in essence. They all provide tasks (e.g., streams 
of computations or data transmissions) on a processor (i.e., a CPU or data link) a fine-grain 
processor sharing environment. The algorithms do so without relying on fine-grain time 
slicing and, therefore, do not incur the high overhead of fine-grain time slicing. The two-
level scheduler in the open system uses the total bandwidth server and constant utilization 
server algorithms. 
30 

AN OPEN ENVIRONMENT 
157 
There have been many research efforts in building real-time extensions to general purpose 
operating systems. Real-Time Mach (Tokuda, Nakajima, and Rao, 1990) extends Mach to 
support both periodic tasks and aperiodic tasks. Scheduling algorithms provided by Real-
Time Mach include RM (rate monotonic), RM with Deferrable Server, RM with Sporadic 
Server, Fixed Priority and Round Robin (Tokuda, Nakajima, and Rao, 1990). However, at 
any time, all ready threads are scheduled by a single scheduling algorithm. The admission 
control mechanism used in Real-Time Mach is based on the processor reservation method 
(Mercer, Savage, and Tokuda, 1994). Each real-time task makes a reservation for a certain 
fraction of the processor bandwidth when requesting admission. The operating system 
guarantees each admitted task the reserved fraction of processor bandwidth, but does not 
guarantee the timing constraints of the task. In contrast, our open system allows any 
mixture of scheduling algorithms to be used at the same time. Moreover, the open system 
provides each admitted multi-threaded real-time application with both processor bandwidth 
and timing guarantees. 
Sommer, et al. (1996) implemented an execution environment, called the Dreams System, 
for hard real-time applications on Windows NT. The Dreams system supports periodic tasks 
that may be admitted and deleted at run-time. All ready threads are scheduled according to 
the EDF algorithm. The Dream system provides timing guarantees to every real-time task 
that passes its acceptance test, as long as no task overruns. 
RTX (Carpenter et aI., 1997) developed by VenturCom Inc. is a real-time subsystem of 
Windows NT. It is a kernel-mode execution environment for Win32 compatible tasks and 
threads that have hard real-time requirements. The RTX subsystem schedules real-time 
threads using a priority-driven algorithm and controls priority inversions. It uses real-
time threads to service hardware and software interrupts, and thus it provides deterministic 
interrupt response and dispatch latencies. RTX does not provide any admission control 
mechanism. 
Mercer proposed the processor reservation model to support both hard real-time and 
multimedia applications (Mercer, Savage, and Tokuda, 1994). In a system based on this 
model, the operating system maintains and enforces a processor reserve for each real-time 
task in the system. Mercer uses processor reserves as a means to monitor and control 
the processor usage of each activity. In our open system, service providers use a similar 
approach. An application requesting a service gives the service provider its own execution 
budget so that the provider can execute on its behalf. The execution budget is analogous to 
Mercer's processor reserve abstraction. One difference is that our execution budget is not 
replenished periodically. The budget replenishment scheme is designed so that each service 
provider can deliver the requested service in time and the requesting application can meet 
its deadlines. 
3. Open System Architecture 
Figure 1 shows the architecture of an open uniprocessor system. AI, A2, ... , AN denote 
real-time applications in the system. The number N of such applications varies as new 
applications start and existing ones terminate. There are also non-real-time applications. 
In addition to the processor, the system also contains resources. A resource is global if it is 
31 

158 
Non-Real-Time 
Real-Time 
Applications 
Application 
0 D' D 
~ 
USF.R ~\./ 
+ 
KERNEL 
LJ 
t=L P
'TNauv0 
Scheduler: 
50 
I 
I 
[ 
RM-PCP 
.":cheduler 
, 
51 
Figure I. An open system architecture. 
Real-Time 
Application 
G 
• 
JL 
I EDF-SBP 
I 
I Scheduler 
, 
; 
_.--j 
L__ 
5N 
i 
Rcady Queue 
OS Scheduler 
(EDF) 
DENGET AL. 
Communication 
Server 
[--~-.--j 
shared by more than one application and is local if it is used by only one application. Global 
resource contentions among applications are controlled by the nonpreemptable critical 
section (NPS) protocol (Mok, 1983). According to the NPS protocol, whenever a job 
requests a global resource, the request is always granted. For as long as ajob holds a global 
resource, the job is nonpreemptable_ 
To develop a hard real-time application Ak that is to run in the open system, the developer 
first chooses a scheduling algorithm Lk together with a resource access control protocol 
to schedule the jobs in the application and resolve their contention for local resources_ 
To validate that the application can meet its timing requirements, the developer analyzes 
the schedulability of the application assuming that the application runs alone on a virtual 
processor of a certain speed. (We normalize the speed of the virtual processor with respect 
to that of the physical processor. If the execution time of a job is e on the physical processor 
and the speed of the virtual processor is x, then the execution time of the job used in 
the analysis is e/x.) The developer then determines the minimum speed O'k of the virtual 
processor that can ensure the schedulability of the application Ak . We call this speed the 
required capacity of the application. Clearly, the required capacity O'k of every real-time 
32 

AN OPEN ENVIRONMENT 
159 
application Ak developed to run in the open system must be less than one, i.e., (Jk < 1. We 
say that the real-time application Ak is schedulable in the open system if all jobs in Ak meet 
their deadlines when Ak runs in the open system together with other applications and the 
order in which jobs in Ak are executed is determined by the algorithm ~k chosen for Ak . 
3.1. 
Scheduling Hierarchy 
In the open system, all non-real-time applications are executed by a server, which is called 
So, and each real-time application Ak is executed by a server Sk (for k :::: I). In the upper 
level, each server has a scheduler, which we call server scheduler. The server scheduler 
of the server So uses a time-sharing algorithm to schedule ready jobs of all non-real-time 
applications. (In our implementation, this scheduler is the NT native scheduler.) The 
scheduling algorithm ~k used by the server scheduler of server Sk is the algorithm chosen 
for the real-time application Ak. Each server has a ready queue containing ready jobs of 
the application(s) executed by the server. The jobs in the ready queue of each server are 
ordered by the server scheduler according to the algorithm used by the application(s), and 
their contentions for local resources are resolved according to the resource access control 
protocol used by the application(s). 
The lower level scheduler provided by the operating system is called as scheduler. This 
scheduler maintains all the servers in the system. The server So of non-real-time applications 
is a total bandwidth server (Spuri and Buttazzo, 1996). Depending on the characteristics of 
the real-time application Ak (k :::: 1), its server is either a constant utlization server (Deng, 
Liu, and Sun, 1997) or a total bandwidth server. These types of servers are similar. Such a 
server is characterized by its size U, which is the fractional processor bandwidth allocated 
to the server. A server has two additional parameters, budget and deadline; the parameters 
are initially zero. At time t when the OS scheduler gives b time units of budget to either 
server of size U, it sets the new server deadline to max {t, d} + b I U, where d is the current 
server deadline. A server is ready for execution only when it has budget and it consumes its 
budget at the rate of one per unit time when it executes. When a server runs out of budget, 
it is no longer ready to execute until the OS scheduler replenishes its budget (i.e., gives 
the server more budget and a new deadline). We will describe in Section 5 when the OS 
scheduler replenishes the budget and by how much. 
The difference between these two types of servers is that the budget of a total bandwidth 
server is replenished as soon as it is consumed when there are jobs ready to be executed 
by the server. In contrast, the budget of a constant utilization server is never replenished 
prior to its current deadline. Hence, a total bandwidth server is allowed to use background 
processor time while a constant utilization server is not. The open system uses constant 
utilization servers to execute hard real-time applications whenever it is possible so as to 
leave as much background processor time as possible to non-real-time applications. 
The OS scheduler has a ready queue which contains all the ready servers in the system. 
The OS scheduler schedules all the ready servers according to the EDF algorithm. Whenever 
a server is scheduled, it executes the job at the head of its ready queue. 
The operations of the OS scheduler are described by the pseudo code in the Appendix. 
When the system starts, the OS scheduler creates the server So for the non-real-time ap-
33 

160 
DENGET AL. 
plications and a server for each service provider in the open system. (We will return in 
Section 6 to describe the type of servers for service provides.) The open system always 
admits non-real-time applications. Each real-time application Ak starts in the non-real-time 
mode. When it requests to execute in the real-time mode, the operating system subjects 
the application to an acceptance test. If the application Ak passes the test, the open system 
admits the application, and creates a server Sk of an appropriate size and type to execute 
Ak. When a job of real-time application Ak is released, the OS scheduler invokes the server 
scheduler of the server Sk to insert the newly released job in the proper location in the 
server's ready queue. When an application Ak terminates, the OS scheduler destroys the 
server Sk. 
In summary, each scheduling decision in the open system is made in two steps. The 
OS scheduler first finds the server at the head of its ready queue. In tum, that server 
executes the job at the head of the server's ready queue. As a result, all the non-real-
time applications appear to be running in a slower time-sharing environment. If the size 
of the server So is Vo (0 < Vo < 1), the average response time of any non-real-time 
application is no worse than the average response time it would have in a time-sharing 
environment where there is no real-time application and the processor speed is Vo. The 
two-level hierarchical scheduler guarantees that every real-time application is schedulable 
(i.e., meets all its timing requirements) once the scheduler accepts the application. (These 
claims will be substantiated in the next two sections.) 
3.2. 
Predictable Vs. Nonpredictable Applications 
As we will see shortly, the server schedulers of some real-time applications compute or 
estimate occurrence times of application events. In a priority-driven application Ako an 
event is one of the following that may lead to a context switch within the application: 
1. ajob in Ak is released or completes; 
2. a job in Ak requests or releases a local resource; 
3. a job in Ak requests or releases a global resource; and 
4. a job in Ak enters or leaves a nonpreemptable section. 
In a time-driven application, an event is a timer interrupt at which a scheduling decision is 
made. At any time t, the next event of Ak is the one that would have the earliest possible 
occurrence time at or after t if the application Ak were to execute alone on a slow processor 
with speed ak. 
We divide real-time applications into two broad categories: predictable and nonpre-
dictable applications. The server scheduler of a predictable application can compute accu-
rately at any time the occurrence time ofthe next application event, but the server scheduler 
of a nonpredictable application cannot. Predictable applications include all applications 
that are scheduled in a time-driven manner and all applications in which the release times 
of all jobs are know a priori. When an application is scheduled nonpreemptively,2 it is not 
necessary for the server scheduler of its server to determine the occurrence time of the next 
34 

AN OPEN ENVIRONMENT 
161 
application event. For convenience, we include nonpreemptively scheduled applications in 
the predictable category. Nonpredictable applications are those applications that have ape-
riodic and sporadic tasks, and/or periodic tasks with release time jitters and are scheduled 
according to preemptive, priority-driven algorithms. 
4. Admission of New Real-Time Applications 
Again, the open system subjects each real-time application Ak to an acceptance test when 
the application requests to switch to the real-time mode. (In our subsequent discussion, we 
say that the application requests admission.) If Ak passes the acceptance test, the system 
accepts Ak and creates a server Sk to execute Ak. The correctness of the acceptance test used 
by the OS scheduler is supported by the two theorems stated below. They give sufficient 
conditions under which a real-time application Ak with required capacity O"k is schedulable 
in the open system. Their proofs can be found in (Deng, Liu, and Sun, 1997; Deng and Liu, 
1997). 
4.1. 
Theoretical Foundation 
When the system contains no global resources and no application has nonpreemptable 
sections, Theorem 1 is applicable, and all real-time applications can be executed by constant 
utilization servers. 
THEOREM 1 In an open system in which no application has nonpreemptable sections or 
uses global resources, a real-time application Ak whose required capacity is O"k < 1 and 
scheduling algorithm is I;k is schedulable when the application is executed by a constant 
utilization server Sk whose scheduler uses I;k, if all the following conditions are true. 
1. At each replenishment time, the as scheduler never gives the server Sk more budget 
than the remaining execution time of the job at the head of Sk 's ready queue. 
2. During the interval (t, d - q) from any replenishment time t of the server Sk to q time 
units before the corresponding deadline d of the server, for some nonnegative constant 
q which is such that t < d - q, there would be no context switch among the jobs in the 
application Ak if Ak were to execute alone on a slow processor with speed O"k. 
3. (a) If Ak is a predictable application, the server Sk has size Uk = O"k. 
(b) If Ak is a nonpredictable application, the server Sk has size Uk = 8~O"k/(8~ - q), 
where 8~ is the shortest relative deadline of all jobs with release time jitters in Ak. 
4. The total size of all servers including Sk is equal to or less than one. 
By definition, when an application Ak is predictable, the scheduler of its server can 
compute accurately the occurrence time of the next event of Ak. As we will see in the next 
section, with this information, the OS scheduler can replenish the budget of the server so 
35 

162 
DENGET AL. 
that conditions 1 and 2 of Theorem 1 are always true for q = O. Hence, a predictable real-
time application Ak with required capacity (J'k can be accepted if the total size of all servers 
in the system is no more than 1 - (J'k. Once accepted, the size of the constant utilization 
server for the application should be ak. 
On the other hand, if the application Ak is nonpredictable, it will not be possible for its 
server scheduler to compute the occurrence times of future application events accurately. 
Rather than the exact occurrence time of the next application event, the server scheduler 
must use an estimate of this time. The parameter q in Theorem 1 can be thought of as 
the maximum error in this estimate: the actual occurrence time of the next event is never 
sooner than q units of time before the estimated occurrence time. We called this parameter 
the scheduling quantum of the system. It is a design parameter. Condition 3 of Theorem 1 
tells us that the server size required to ensure the schedulability of Ak in the open system 
increases and, hence, the processor utilization decreases with q, but the scheduling overhead 
decreases with q. Sections 5 and 7 will provide details on how the scheduling overhead 
and achievable processor utilization depend on this parameter. 
We now consider the general case where some job in the open system has nonpreemptable 
sections. When such a job is in its nonpreemptable section, the server that executes it is 
nonpreemptable until the nonpreemptable section completes. The execution of jobs in 
other applications can be delayed. Under this condition, Theorem 2 stated below says 
that we must use total bandwidth servers for all real-time applications that are scheduled 
preemptively. 
THEOREM 2 A real-time application Ak whose required capacity is (J'k < 1 and scheduling 
algorithm is ~k is schedulable in the open system when it is executed by a server Sk of size 
Uk whose scheduler uses ~b if all the following conditions are true. 
1. The server Sk is a total bandwidth server if Ak is scheduled according to some preemp-
tive, priority-driven algorithm, and is a constant utilization server if Ak is nonpreemp-
tively scheduled or is time-driven. 
2. (a) If Ak is a nonpreemptive application, Uk is equal to (J'k. At each replenishment 
time of the server, the budget is set to the execution time of the job at the head of 
its ready queue. 
(b) If Ak is preemptive, conditions 1,2 and 3 of Theorem 1 are true. 
3. The total size of all servers in the open system is no more than 1 - maxj;::I{Bj /8j }, 
where Bj is the maximum duration of nonpreemptable sections of all applications other 
than application Aj and 8j is the shortest relative deadline of all jobs in Aj. 
4.2. 
Acceptance Test 
Figure 2 lists the types of information an application Ak provides to the OS scheduler in 
its request for admission. In addition to its required capacity ak and scheduling algorithm 
~k. the application also provides the maximum length Lk of its nonpreemptable sections if 
36 

AN OPEN ENVIRONMENT 
163 
When an application .4. requests admission, it provides in its request the following information: 
• the scheduling algorit.hm Ek and the required capacity (Jk of Ak ; 
• t,he maximum execution time Lk of all nonpreemptable sections or critical sections guarding global 
resources used by Ak ; 
• the jitter factor ilk of Ak ; 
• the existence of aperiodic/sporadic ta.qks in Ak , if any; 
• t,he shortest relative deadline 6~ of all jobs with release time jitters in Ak ; and 
• the shortest relative deadline Jk of all jobs in Ak if Ak is priority driven, or the shortest length Ii. 
between any two consecutive events of Ak if Ak is time-driven. 
1. Fiud the type and the size Uk of the server 8k for Ak in the way described by in Figure 3. 
2. If U,+Uk+maxlSjSN{Bj/Jj} > 1, where Bj = maxi;<j{Li} and N is the total number ofapplieations 
in the system including Ak, reject Ak. Else. admit A., and 
• if Ak is the first application that has nonpreernptable sections or uses global resources adrnitt~d 
into the system, change the server type of all servers that execute preemptive applications to 
total bandwidth server; 
• increase U, by Uk; 
• create a server Sk of the specified type with size Uk for Ak; and 
• set server budget and server deadline d to zero. 
Figure 2. Acceptance test and admission of application Ak. 
its jobs have any, as well as the shortest relative deadline 8k and 8~ of all its jobs and jobs 
with release time jitters, respectively, if the application is priority-driven, or the shortest 
length of intervals between consecutive timer events of the application if the application is 
time-driven. Another parameter provided by the application is its jitter factor D.k. D.k is 
given by 
{ 
Di 
} 
D.k = max 
T;EAk 
Di - D.¢i 
where Di and D.¢i are the relative deadline and release time jitter, respectively, of the 
periodic task T;, and the maximum function is over all periodic tasks in Ak • 
Figures 2 and 3 summarize rules the OS scheduler uses for acceptance test. Theorem 2 
allows us to claim that these rules are correct. In the first step of its acceptance test, the OS 
scheduler determines the type and size of the server for the requesting application Ak. As 
long as no application in the system has nonpreemptable sections or uses global resources, 
the OS scheduler continues to use constant utilization servers for hard real-time applications. 
When the OS scheduler admits the first application that has nonpreemptable sections or uses 
global resources, it changes the servers of all the existing preemptive applications to total 
bandwidth servers. (This change involves only a change of the replenishment rule and can 
37 

164 
DENGETAL. 
Server Type of 5k: 
If some application (including At) in the syst.em has nonpreemptable sect.ions or uses global resourees, 
and if Ak is scheduled by some preemptive algorithm, 51, is a total bandwidth server. Otherwise, Sk is 
a constant utilization server. 
Server Size Uk of ."h: 
If Ak is a predict.able real-time application, 
Otherwise, 
where q is the length of scheduling quantum used in the open system. 
Figure 3. Server type and server size of Sk. 
be done at any time.) If the application Ak is predictable, the size Uk of the server Sk is 
equal to its required capacity ak. If the application is nonpredictable, the size of server Sk 
must be increased to min{D.b 8U(8~ - q)}ak to offset the error in the estimate of the next 
event occurrence time. 
After determining the type and size Uk of the server Sk for the requesting application Ab 
the OS scheduler admits Ak if UI + Uk + fJ :s 1, where 
(1) 
and N is the number of real-time applications including Ak in the open system. The term fJ 
in the inequality takes into account the effect of maximum blocking time that jobs of Ak may 
experience due to nonpreemptivity of other applications. If no application in the system has 
nonpreemptable sections or uses global resources, the inequality becomes Ut + Uk :s 1. 
5. Server Maintenance 
Theorems 1 and 2 not only give us the rules for the acceptance test, but also tell us how 
the servers in the open system should be maintained. In particular, conditions I and 2 in 
Theorem 1 (or Theorem 2) dictate how the server budget is replenished. 
Figure 4 describes the actions taken by the OS scheduler to maintain the server of size 
Uk of a preemptive, priority-driven application Ak • (The server described in this figure is 
a total bandwidth server. Maintenance rules for constant utilization servers and servers of 
nonpreemptive applications can be found in the appendix.) The algorithm governing the 
server budget replenishment differs slightly from the total bandwidth server algorithm in 
(Spuri and Buttazzo, 1996). Specifically, when the budget of the server Sk is exhausted 
before the current server deadline d, the budget is not replenished immediately if ajob J 
38 

AN OPEN ENVIRONMENT 
165 
Maintenance of total bandwidth server Sk whose deadline is d: 
1. When a new job .Ii of Ak arrives at t, 
• invoke the server schednler of Sk to insert .Ii in Sk'S ready queue; 
• update the latest, release time T ~I (j) of the task Ij to which .1, belongs; 
• set .I;'s remaining execution time ei to ei; 
• if .Ii is the only job in the ready queue, 
(a) invoke the server scheduler of Sk to estimate the occurrence time tk of the next event of 
Ak as described in Figure 5, 
(b) set the server budget to (tk - max{t,d})Ub and server deadline d to tk, and 
(e) decrease the remaining execution time ei of .Ii by (tk - max{t,d})Uk. 
2. When a job ill Ak completes at time t, 
• if Sk'S ready queue is not empty and job .1i is at the head of the ready queue, 
-
if t < d and if a job in Ak with a higher priority than that of J, will be released at time 
d, do nothing. 
-
Otherwise, 
* invoke the server scheduler of Sk to estimate the occurrence time tk of t,he next event 
of Ak after time d as described in Figure 5, 
* set the server budget to (tk - d)Uk, and server deadline d to tk. and 
* decrease the remaining execution time e; of .Ii by (tk - d)fh. 
3. After a job .Ii in Ak requests for or releases a local resource, invoke the server schE'duler of Sk to 
change the priorities of some jobs in its ready queue if necessary and move the job with the highest 
priority to the head of its ready queue. 
Figure 4. Maintenance of total bandwidth server Sk for a preemptive, priority-driven application Ak. 
in Ak with a higher priority than the job J' currently at the head of Sk'S ready queue will 
be released at or before time d. This is so that the server cannot use the budget reserved 
for J to execute J'. To ensure that condition 2 of Theorem 1 (or Theorem 2) is met, before 
replenishing the budget of a server Sk (say at time t), the OS scheduler invokes the server 
scheduler to determine the occurrence time tk of the next event of Ak . tk is the earliest time 
a context switch in Ak may occur, The OS scheduler never gives the server more budget 
than (tk - t)Uk. For a predictable application Ako this condition, plus condition 1 of the 
theorems, ensures that before the next context switch of the application, the job currently 
at the head of the server queue never executes for more time than it would if Ak were to 
execute alone on a slow processor of speed Uk. In this way, the OS scheduler ensures that 
if a context switch is to occur at tb the server budget and deadline can be set and the server 
is ready for the execution of the highest priority job at that time. 
If Ak is a nonpredictable application, the server scheduler of Sk is unable to obtain an 
accurate occurrence time of the next event of Ak. The algorithm described in Figure 5 gives 
39 

166 
DENGET AL. 
Input: 
n: 
the number of tasks in Ak 
]Jm~l ... nJ: 
the minlnlulll inter-clrrival time of each task in Ak 
pM [1 ... 11.]: 
the maximum inter-arrival time of each task in Ak 
T .. J [I ... n]: the latest release time of each task ill Ak 
q: 
the length of scheduling quantulII in the open system. 
Calculation of the Next Event Time tk at time t: 
t c t-:lO: 
f(lf (i = I; i :s: n: i + +) { 
r', t- max{t,r .. ,[i] + pm [i]}; 
T, t- r.di] +pM[iJ; 
I, t- min{t"min{r,,+IJ.I'I}L 
if the ready queue of S'k is empty at time t 
tk t- I,: 
else { 
j* earliest possible rele"se time of task i *! 
j* latest possible release time of task i * j 
.Ii t- the job at the head of the ready queue of S'k at. time t; 
e/ t- the amount of time .Ii must attain to reach the point when Ji either completes. 
or requests for or releases a resource, or enters or leaves a nonpreemptable section. 
whichever occurs the earliest: 
tk t- min{te,t + e;'/Ud; 
Figure 5. Calculation of the next event time by the scheduler of the server Sk of a nonpredictable application Ak. 
an estimate. The error in the estimate fk is the error in the estimate of release time fe of the 
job J that will be released first among all jobs in A k • The actual release time of this job is 
never sooner than q time units before the estimate fe. The effect of using the estimate fk 
computed based on the estimate fe is that the as scheduler may give the server Sk up to q Uk 
units more budget than the budget computed based on the accurate occurrence time of the 
next event of Ak. The adverse effect of this over-budgeting is compensated for by letting 
the server Sk have the larger size stated in Figure 3, and thus satisfying the conditions for 
the schedulability of Ak in the open system. 
Again, the parameter q is the scheduling quantum used by the two-level scheduler, and 
its value is chosen by the open system designer, Its value has no effect on a predictable 
application. In the other extreme, when the release times of some jobs in a preemptively 
scheduled application Ak are unknown, not even their ranges, the estimate te of the next 
release time of some job in Ak is q units from the current replenishment time. Consequently, 
the server Sk is given q Uk units of budget each time, and its deadlines are q units apart. 
In other words, the as scheduler maintains Sk in the same manner as the server So for 
non-real-time applications, When the minimum and maximum inter-arrival times of each 
task in the application are known, the server scheduler can get a better estimate but doing so 
40 

AN OPEN ENVIRONMENT 
167 
incurs additional scheduling overhead, which is the time required by the for loop in Figure 5 
and has complexity 0 (n) where n is the number of tasks in the application. In general, the 
smaller the value of q, the more frequently the server budget of Sk is replenished, and the 
higher the scheduling overhead. On the other hand, a smaller value of q means a smaller 
server size Uk of Sb thus less processor bandwidth spent on behalf of Ak and a higher 
achievable processor utilization. 
6. System Service Providers 
Providers of system services such as network and file access are implemented as special 
purpose user-level server applications in the open system. Each service provider is executed 
by a passive server. A passive server has a very small size. It is provided with execution 
budget by two mechanisms. First, the OS scheduler replenishes its budget as if it is a total 
bandwidth server of its size. This budget is used only for administrative purposes. Second, 
the passive server is provided with execution budget and an associated deadline whenever 
an application requests service from the service provider executed by the passive server. 
Thus, the processor time the service provider requires to perform any service is charged to 
the requesting application. This idea is borrowed from Mercer, et al. (1994). 
Upon initialization, the operating system creates a passive server to execute each service 
provider in the system. The service provider has an administrative job which has two 
main responsibilities: (1) to create new jobs in the address space of the service provider in 
response to requests for service from its clients and (2) to process incoming data to identify 
the receiver and notify the receiver. The administrative job is created at initialization time 
and is suspended immediately after it is created. When the administrative job wakes up to 
run, the passive server executes it using the server's own budget. 
Figure 6 gives an overview of the interaction among a system service provider SSP, its 
passive server PS and a real-time client applications Ak • A real-time client application 
requests a service by sending the service provider one of two RTAPI calls: SendDa ta 
and RecvData. (We will describe in the next section RTAPI functions in general and 
these related calls in particular.) The former is called when a client application requests 
the service provider to process outgoing data on its behalf. When the function SendDa ta 
is called by application Ab it invokes the server scheduler of server Sk to get the current 
budget and deadline of Sk. The tuple (budget, deadline) is called the processor reserve of 
application Ak. SendData then wakes up the administrative job of the service provider 
and passes the data and processor reserve.3 When the administrative job executes, it creates 
a work job h to handle the request. Among the parameters of a work job are its budget 
and deadline, which are equal to the respective values given by the processor reserve. The 
workjob is inserted in the ready queue of the passive server PS on the EDFbasis according 
to its deadline. The budget and deadline used by the OS scheduler to schedule the passive 
server are equal to these parameters of the work job at the head of the queue (or the server's 
own budget and deadline when the administrative job is awaken and the server's owner 
deadline is earlier than those of all work jobs). In the mean time, having its budget in effect 
transferred to the passive server, the server Sk is no longer ready for execution until its 
budget is replenished. 
41 

168 
DENGETAL. 
_-----_~ 
budget 
Deferred Action List 
, deadline 
Client Application Ir-__ .... System Service Provider t 
Ak 
(SSP) 
Suspend Queue 
Ready 
Queue 
g 
(EDF) 
.. 
IIIIII 
etbudget I t 
Ready f---
, 
Queue I--
Passive Server , 
(EDF) ---
~~ 
r---
(PS) 
!\ 
wait for budget 
; 
~M ~~'" 
~~~ ., 
OS Scheduler 
Figure 6. System service provider. 
The passive server also has a suspend queue. Whenever the budget of the passive server 
is exhausted but the executing work job A remains incomplete, the job is removed from 
the server's ready queue and inserted in the suspend queue. The passive server then notifies 
the server Sk of the budget exhaustion. Until the work job Jk completes, whenever the job 
in Ak that requested the service from SSP is at the head of Sk'S ready queue at a budget 
replenishment time of Sb the server Sk will transfer the newly replenished budget along 
with the new deadline to the passive server. The passive server then reactivates the work 
job A, setting its budget and deadline accordingly and moving it back to the ready queue. 
When the work job A completes, the passive server notifies the server Sk of the completion 
of service and passes back the remaining budget. 
A client application calls RecvData to request a service provider to process incoming 
data on its behalf. Similar to SendData, the RecvData function also causes a transfer 
budget to the passive server of the system service provider. If the data to be received is 
not available when the requesting application calls RecvData, the call effectively freezes 
the requesting application: the server of the requesting application has no budget, and the 
service provider holding the application's budget cannot execute on behalf of the application 
as the data is not available. To circumvent this problem, the requesting application first calls 
Wai tDa ta to wait for the data. If the data is available, Wai tDa ta returns immediately. 
Otherwise, the job calling Wai tData is blocked. Wai tData function does not transfer 
budget to the service provider. Hence, the server of the requesting application can still 
execute other jobs in the application during the time when the calling job is blocked. When 
incoming data arrives, the administrative job process the data to identify the receiver of the 
incoming data and, after the receiver is identified, wakes up the job that called Wai tDa ta 
42 

AN OPEN ENVIRONMENT 
169 
if the job exists, and Wa itDa ta returns. The requesting application then calls RecvDa ta 
to transfer to the service provider the processor reserve required to process and receive the 
incoming data. 
In effect, a SendData or RecvData call causes a transfer of budget from the server 
of the requesting application to the passive server of the service provider. In this way, 
the processor time used by the service provider in response to a send or receive request is 
charged to the requesting application. The schedulability of other real-time applications in 
the system is not aflected. 
7. 
Real-Time Application Programming Interface (RTAPI) 
Our open system supports periodic tasks and aperiodic tasks, as well as several types of 
periodic servers (Sprunt, Sha, and Lehoczky, 1989), i.e., special kinds of periodic tasks 
used to execute aperiodic tasks. It provides two categories ofRTAPI functions for real-time 
applications. The first one deals with the creation, admission and termination of real-
time applications, as well as task and server specification. The second one deals with the 
communication between real-time applications and system service providers. 
7.1. 
Application and Task Specification 
The following RTAPI functions allow each real-time application to specify its real-time 
attributes. The parameter funcName gives the procedure executed by jobs in the task. 
• 
CreateRealTimeApplication(reqCapacity, Algo, resAccess) 
A real-time application uses this function to specify its required processor capacity, as 
well as the scheduling algorithm and resource access control protocol used to schedule 
its threads. 
• 
CreatePeriodicTask(funcName, phase, period, execTime, 
deadline, jitterFactor, resource) 
This function creates a periodic task with the specified phase, period, maximum exe-
cution time, relative deadline, jitter factor, and resource usage. 
• 
CreateAperiodicTask(funcName, events, execTime, deadline, 
resource) 
This function creates an aperiodic or sporadic task with the specified maximum exccu-
tion time, relative deadline, and resource usage. It also specifies the events that trigger 
the invocation of the task. 
• 
CreatePeriodicServer(type, phase, period, size) 
This function creates a periodic server with the specified type, phase, period, and size. 
• 
BindAperiodicTask(task, server) 
This function binds an aperiodic task to a periodic server, i.e., the aperiodic task will 
be executed by the specified periodic server. 
43 

170 
DENGET AL. 
• 
StartRealTimeApplication(void) 
A real-time application calls this function to request admission into the open system. 
This function returns the result of admission test of the application. 
• 
TerminateRealTimeApplication(void) 
This function terminates the current real-time application. 
All applications start in the open system in non-real-time mode. Non-real-time appli-
cations remain in that mode during their lifetime of execution. Real-time applications, 
however, will switch to real-time mode after their initialization phase. During the ini-
tialization phase, a real-time application first calls the CreateReal TimeApplication 
function to register itself with the system and specify its required capacity, scheduling al-
gorithm, and resource access control protocol. The application then creates all its periodic 
tasks, periodic servers and sporadic and aperiodic tasks. After the application is done with 
its initialization, it notifies the system that it is ready to run in the real-time mode by calling 
StartReal TimeApplication. If the system rejects the application, the application 
never enters the real-time mode. If the system accepts the application, it creates a server to 
execute the application and starts creating a thread for every task in the application. At this 
point, the application is switched to the real-time mode. 
Below is a typical real-time application that uses the RTAPI functions described above. 
The application contains two periodic tasks and one aperiodic task executed by a periodic 
server. We assume that the application is invoked by a QUI-based application that has a 
"Quit" button. If the application is rejected by the system, an error message is displayed 
and the application exits. If the application is admitted into the system, it runs until the user 
presses the "Quit" button or closes the windows. (In the code below, function arguments 
of most Win32 functions are omitted.) 
WinMain(HINSTANCE hlnstance, HINSTANCE hPrevlnstance, PSTR 
szCmdLine, int iCmdShow) 
44 
II Call Win32 functions to register and create a window. 
RegisterClassEx() ; 
CreateDialog() ; 
ShowWindow ( ) ; 
II Start real time application specification with required 
II capacity util. 
CreateRealTimeApplication(util, RM, PCP); 
II create periodic tasks in the application. 
CreatePeriodicTask(function1, ph1, p1, e1, d1, j1, rlist1); 
CreatePeriodicTask{function2, ph2, p2, e2, d2, j2, rlist2); 
II create a periodic server. 
serverHandle = CreatePeriodicServer{DEFERRABLE_SERVER, ph, 

AN OPEN ENVIRONMENT 
171 
p, size); 
II create an aperiodic task and bind it to the server. 
apTaskHandle = CreateAperiodicTask(function3, &event, e3, 
d3, NULL); 
BindAperiodicTask(apTaskHandle, serverHandle); 
II Done with the application initialization, now start the 
application. 
status = StartRealTimeApplication(); 
if (status != STATUS_SUCCESS) { 
MessageBox( ... , "The application is rejected by 
system" , ... ); 
PostQuitMessage(O); 
II start Windows message processing. 
while (GetMessage()) { 
TranslateMessage() ; 
DispatchMessage() ; 
WndProc(HWND hwnd, UINT iMsg, WPARAM wParam, LPARAM lParam) 
{ 
switch (iMsg) { 
case WM_COMMAND: 
switch (LOWORD(wParam)) 
case IDC_QUIT: 
II Quit button pressed, terminate real-time 
application. 
TerminateRealTimeApplication(); 
II destroy the window. 
PostQuitMessage(O); 
break; 
case WM-.DESTROY: 
II windows is to be destroyed, terminate real-time 
application. 
TerminateRealTimeApplication(); 
PostQuitMessage(O) ; 
45 

172 
DENGET AL. 
break; 
default: 
return DefWindowProc(hwnd, iMsg, wParam, lParam); 
return (FALSE); 
7.1.1. 
System Service 
As described earlier, a system service provider itself is a special purpose application. In 
addition to the RTAPI functions used by a normal real-time application, the service provider 
calls the following RTAPI functions to handle requests from other applications and interact 
with the passive server in the kernel that executes the service provider. 
• 
CreateWorkThread(dest, budget, deadline, service) 
The function creates a work job in response to each SendDa ta or RecvDa ta function 
to process the send or receive request. 
• 
DestroyWorkThread(threadHandle) 
This function destroys the work job when the request is processed. It returns the 
remaining unused budget. 
Earlier in the description of system service providers, we mentioned the following RTAPI 
functions that real-time applications use to request for service from system service providers. 
• 
SendData(service, dest, data, length) 
A real-time application requests the specified service provider to send message to 
destination by calling this function. 
• 
WaitData(service, source) 
An application notifies the service provider that it is waiting for incoming data from 
source. The function returns the length of the data if the data is available or when the 
data arrives. 
• 
RecvData(service, source, data, length) 
An application requests the specified service provider to receive message from source 
by calling this function after its previous call WaitData has returned (so incoming 
data is available at the time this function is called.) 
A SendData (or RecvData) function returns when the entire message is sent (or the 
specified length of incoming data is processed), at which time the work job also terminates. 
46 

AN OPEN ENVIRONMENT 
173 
8. 
Implementation 
We choose to implement the open system as a real-time extension to an existing operating 
system, and our choice of the existing operating system is the Windows NT operating system. 
The reasons for this choice include that NT is a popular operating system and a prototype 
open system on this operating system will be a solid proof of the open system concept. One 
approach to implementing the extension is to replace the existing kernel scheduler by our 
two-level hierarchical scheduler. This approach eliminates context switches between the 
OS and server schedulers. The required modification to the kernel is substantial; this is the 
only disadvantage. 
The definition of new kernel data structures and code of the scheduler have approximately 
2000 lines of C code. Our current implementation supports only hard real-time applications 
that are scheduled according to priority-driven algorithms. We have also implemented a 
basic set of RTAPI functions, as well as a communication SSP in the user level as NT 
DLL (dynamically linked library). Total code size of RTAPI is about 600 lines of C code, 
and that of communication SSP is about 800 lines of C code. This section describes the 
implementation of two-level kernel scheduler. 
Thereafter, we use the object model and terminology found in Window NT literature, 
such as (Custer, 1993). In particular, the term object refers to both a data structure that 
defines a class of objects and an instance of the class. 
8.1. 
Kernel Scheduling Objects 
In Windows NT operating system, kernel threads are the basic scheduling entities. Inside 
the NT kernel, a real-time application is a kernel process, and a job in the application is a 
kernel thread. Since the existing NT kernel objects do not have real-time attributes, we add 
real-time extensions to them. 
The real-time extension to a kernel thread object consists of the parameters of the real-
time job (or server) that the thread implements, including its remaining execution time (or 
budget) and priority (or absolute deadline). A pointer to a structure that contains such 
information is added to the kernel thread object. For all non-real-time threads, this pointer 
is NULL. This is how the OS scheduler distinguishes between a real-time thread and a 
non-real-time thread. 
We add a new kernel object, called task. Each periodic, sporadic, or aperiodic task in 
a real-time application is implemented as a task object. Periodic servers used to execute 
aperiodic and sporadic threads are also implemented as task objects. Each task object has 
the real-time attributes (e.g., the period, execution time, and relative deadline) of the task, 
including the resources the task uses. 
Each server in the kernel that executes a real-time application or all the non-real-time 
application is implemented as a server object, which we introduce for this purpose. Figure 7 
shows the server object: the data structure of a server and its server scheduler. Among the 
attributes of the server object are the type and size of the server. The server scheduler 
object contains the parameters of the real-time application the server executes (e.g., the list 
47 

174 
type 
size 
Figure 7. Server and server scheduler. 
algorithm 
scheduler 
DENGET AL. 
Periodic Task list 
Aperiodic Task list 
Ready Thread 
Priority Queue 
Wait Thread list 
Server Parameter 
of periodic tasks, aperiodic tasks, and periodic servers), and the scheduling algorithm and 
resource access control protocol the application uses. 
8.2. 
Two-Level Kernel Scheduler 
Again, in our implementation of the open system, the two-level scheduler replaces the 
native NT kernel scheduler. The native NT kernel scheduler, however, is used as the server 
scheduler of server So. This scheduler uses the NT's 32 priority level queues to schedule 
its ready threads of all non-real-time applications. Server So is created during the kernel 
initialization phase when Windows NT boots. It remains until the system is shutdown. 
The server Sk that executes a real-time application Ak is created when the RTAPI function 
CreateReal TimeApplication is called. It is destroyed if the acceptance test of the 
application Ak fails or, if the test succeeds, when the application Ak terminates. 
After a real-time application Ak is admitted, all threads of periodic tasks that are released 
at the start of the application are inserted in the ready queue of server Sk. The OS scheduler 
then uses a timer deferred procedure call CDPC) object to keep track of the subsequent 
48 

AN OPEN ENVIRONMENT 
175 
release times for each periodic task. At the release time of a periodic task, the correspond-
ing DPC routine is invoked, which inserts the thread of the task in the ready queue of 
server Sk. 
If the real-time application has a periodic server (i.e., an application level server such as 
a deferrable server), the kernel uses a timer DPC object to do the budget replenishment. If 
the ready queue of a periodic server is nonempty, the first thread in the queue is inserted 
in the ready queue of server Sk when the budget of the periodic server is replenished. For 
each aperiodic task in a real-time application Ab the kernel creates a thread object. When 
the thread starts execution, it immediately blocks on the specified event. When the event 
occurs, the server scheduler of Sk inserts the thread in the ready queue of the periodic 
server that executes the aperiodic task. When this thread completes, it starts execution and 
immediately blocks on the specified event again. 
When a thread in application Ak completes (i.e., returns from the function specified for 
the thread), the RTAPI traps to kernel and calls a kernel function to notify the OS scheduler. 
The OS scheduler discards the remaining budget of server Sk,4 then makes a scheduling 
decision. The kernel function returns a value indication if this thread will be invoked again. 
If the thread will not be invoked anymore, the RTAPI terminates the thread and calls a kernel 
function to destroy the thread and its associated task. 
At each replenishment time, the OS scheduler sets up a timer DPC routine that expires at 
the new deadline of the server Sk to keep track of the deadlines of server. Since changing 
the server deadline also changes the priority of the server, the OS scheduler moves Sk to 
the proper place in its ready queue. If the server Sk is at the head of the ready queue of 
the OS scheduler, OS scheduler dispatches the thread at the head of Sk'S ready queue for 
execution. 
When a thread T in the application Ak makes a request to a service provider, the server 
Sk transfers its current budget and deadline to the passive server that executes the service 
provider. Server Sk then adds the thread T along with a flag fr to the service request list 
managed by the scheduler of Sk. The flag fr is initially set to FALSE. If the passive server 
runs out of budget before the work thread created on behalf of thread T completes, the 
passive server notifies the server Sk to set the flag fr to TRUE. The server Sk checks if the 
thread at the head of its ready queue is on the service request list whenever its budget is 
replenished. If the thread is on the list and if the corresponding flag is TRUE, the server Sk 
transfers the new budget and deadline to the passive server and resets the flag to FALSE. 
When the passive server completes the service requested by thread T, it notifies the server 
Sk. Server Sk then removes the thread T from its service request list. 
8.3. 
Tick Scheduling 
In Windows NT, the kernel is interrupted by the system clock every I or 10 ms. We refer to 
this length of time as the tick size. Whenever a system clock interrupt occurs, the execution 
quantum of the currently running thread is decreased by the tick size. NT forces a context 
switch when the execution quantum reaches zero. We use this mechanism to keep track 
of server budget. When the OS scheduler replenishes the budget of a server, the execution 
quantum of the thread at the head of the server's ready queue is set to new server budget. 
49 

176 
DENGETAL. 
When the execution quantum of the thread reaches zero, the server executing the thread 
also runs out of its budget. 
The open system uses timer DPC's to keep track of thread release times and server 
deadlines. A timer DPC routine in Windows NT is not invoked precisely at its expiration 
time. Rather, it is invoked after the interrupt service routine (ISR) of the first clock tick 
(system clock interrupt) at or after its expiration time. Both the acceptance test of real-time 
applications and the implementation of the two-level kernel scheduler take into account of 
this inaccuracy of the timing of DPC invocation. 
Specifically, the two-level scheduler is effectively a tick scheduler: new threads are added 
to the scheduler's ready queue and preemption can occur only at each tick time. As a result, 
the execution of a thread can be delayed for as much as a tick size T,. We took into account 
this delay in the acceptance test by using the value f3 = max 1 <,j <,N { Bj ; T, } instead of the 
value given by Eq. (1). 
We also made sure that the thread release DPC routine is invoked before the deadline 
expiration DPC whenever a thread is released in the same tick interval as the deadline of 
the server executing the thread. Otherwise, if the deadline expiration DPC routine were 
executed first, the OS scheduler would replenish the server budget before the new thread is 
inserted in the server ready queue. As a consequence, a wrong thread could be executed 
by the server if the newly released thread has the highest priority. The amount of budget 
replenished could also be wrong. In Windows NT, if there are two or more timer DPC's 
that expire within same tick interval, the later its expiration time, the earlier its DPC routine 
is invoked. To ensure the correct invocation order of the timer DPC routines, we always 
adjust the expiration time of each thread release DPC towards the end of its expiring tick 
interval, and the expiration time of each server deadline DPC towards the beginning of its 
expiring tick interval. 
Similarly, when a thread release DPC routine is invoked, we find whether there are other 
thread release DPC's of the same server that will expire in that tick interval. Only the last 
thread release DPC routine invoked for the tick interval checks whether the OS scheduler 
needs to replenish the budget of the server. 
9. Performance 
In parallel with our implementation effort, we conducted a simulation study to determine 
the scheduling overhead of the two-level scheduler, in particular, the extra overhead in-
curred by scheduling jobs hierarchically and the dependency of this overhead on different 
scheduling quantum and tick size. In this study, we simulated two systems, a closed 
system and an open system. Both systems consist of an identical set of real-time appli-
cations. Since we cannot mix the scheduling algorithms used by different applications 
in the closed system, we let all applications in the open system use the same scheduling 
algorithm. 
The scheduling overhead consists of the amount of time taken to perform context switches 
and to insert or remove jobs to or from ready queues. For the open system, it also includes 
the amount of time taken to insert and remove servers from the ready server queue of the OS 
50 

AN OPEN ENVIRONMENT 
Table 1. Applications in systems scheduled by EDF algorithm. 
Applications 
Required Capacity 
Al 
0.1098 
A2 
0.0916 
A3 
0.1079 
A4 
0.0955 
As 
0.0970 
A6 
0.0804 
Tasks 
(250,8), (520,14), (650,15)*, (900,25)* 
(270,10), (680,15)* , (800,26)* 
(420,8), (660,13), (1200,35)*, (1250,50)' 
(360,7), (820,10)*, (960,14)*, (1250,30)*, (1600,40)* 
(280,6), (480,10), (760,14)*, (1100,40)" 
(495,20), (750,30)* 
Table 2. Applications in systems scheduled by RM algorithm. 
Applications 
Required Capacity 
Al 
0.1278 
A2 
0.1043 
A3 
0.1122 
A4 
0.1140 
As 
0.1109 
Tasks 
(250,8), (520,14), (650,15)*, (900,25)* 
(270,10), (680,15)*, (800,26)' 
(420,8), (660,13), (1200,35)*, (1250,50)* 
(360,7), (820,10)*, (960,14)*, (1250,30)*, (1600,40)* 
(280,6), (480,10), (760,14)*, (1100,40)* 
177 
scheduler. We compare the total number of context switch operations and insertion/removal 
operations in the open system and the closed system. 
Tables 1 and 2 list the required capacity and the parameters of all tasks in each application 
in either system when all applications are scheduled according to the EDF or RM algorithm, 
respectively. Every real-time application contains only periodic tasks and uses no resources. 
Each task is characterized by a 2-tuple (p, e), where p is the period and e is the worst-case 
execution time of the task. The relative deadline of the task is the same as the period of the 
task. In the simulation of the open system that use nonzero scheduling quantum, the tasks 
marked by stars (*) have large release jitters. (Their release jitters are large enough so that 
the scheduling quantum size, instead of the jitter factors, determines the server size.) The 
schedulability of the closed system is validated by PERTS tools (Liu et al., 1993).5 The 
required capacity of each application is also derived by the PERTS tools. The schedulability 
of the open system is verified by having each application pass the acceptance test used in the 
open system. We note that the applications in the deadline-driven and fixed-priority systems 
are essentially the same. Because of the additional application A6 in the deadline-driven 
system, the total required capacities of all applications in both systems are approximately 
equal. 
Tables 3 and 4 give the size of each server Sk that executes real-time application Ak in 
the open system for different sizes of scheduling quantum when its server scheduler uses 
the EDF or RM algorithm, respectively. Since no application uses global resources or has 
nonpreemptable sections, total server size can be 1.0. The first column marked "N/N' 
give the sizes of the servers when no task has release time jitters, and hence the scheduling 
quantum is zero. When tasks marked by (*) have release time jitters, the scheduling quantum 
varies from 50 to 200. As expected, we see that the larger the scheduling quantum, the 
larger the server size, the less the remaining free processor bandwidth for admitting new 
51 

178 
DENGET AL. 
Table 3. Server size (EDF algorithm). 
Server 
Scheduling Quantum 
NjA 
50 
100 
200 
SI 
0.1098 
0.1190 
0.1298 
0.1568 
S2 
0.0916 
0.0987 
0.1074 
0.1298 
53 
0.1079 
0.1133 
0.1187 
0.1295 
54 
0.0955 
0.1017 
0.1089 
0.1263 
S5 
0.0970 
0.1038 
0.1117 
0.1316 
S6 
0.0804 
0.0861 
0.0928 
0.1095 
Total 
0.5822 
0.6229 
0.6691 
0.7854 
Utilization 
100% 
93.46% 
87.01% 
74.13% 
Table 4. Server size (RM algorithm). 
Server 
Scheduling Quantum 
NjA 
50 
100 
200 
SI 
0.1278 
0.1385 
0.1510 
0.1846 
S2 
0.1043 
0.1126 
0.1223 
0.1478 
53 
0.1122 
0.1178 
0.1234 
0.1346 
54 
0.1140 
0.1214 
0.1298 
0.1508 
55 
0.1109 
0.1187 
0.1277 
0.1505 
Total 
0.5692 
0.6090 
0.6543 
0.7683 
Utilization 
100% 
93.46% 
86.99% 
74.09% 
applications. The last row of each table gives the corresponding processor utilizations, i.e., 
the ratios of total required capacity and total server size. 
Tables 5-7 list the scheduling overhead for different scheduling quanta and tick sizes. The 
values listed in the table are obtained after the systems run for 106 time units. The "Context 
Switches" column in the tables gives the number of context switch operations made in 
each system. "Insertion" and "Removal" columns give the number of insertion/removal 
operations performed. When an item is inserted to a queue of length n, the number of 
operations required is zero if n is zero or log2 (n -
I) if n is nonzero. When an item is 
removed from a queue of length n, the number of operations required is log2 n. 
From these simulation results, we can see that tick size has very little impact on the 
schcduling overhead of either system. The scheduling quantum, on the other hand, signifi-
cantly affects the overhead of the open system. When the scheduling quantum is large, the 
scheduling overhead of the open system is comparable to that of the closed system. While 
the number of context switch operations occurred in the open system is slightly larger, the 
insertion/removal operations are slightly smaller since ready queues in the open system 
are much shorter than the system-wide ready queue in the closed system. Therefore, the 
overall overhead of both systems are similar in this case. When the scheduling quantum 
52 

AN OPEN ENVIRONMENT 
179 
Table 5. Scheduling overhead (no tick used). 
System 
Algorithm 
Scheduling Quantum 
Context Switches 
Insertion 
Removal 
Closed 
EDF 
NjA 
45405 
77996 
77995 
Open 
EDF 
NjA 
49007 
72340 
72340 
Open 
EDF 
200 
53694 
80986 
80985 
Open 
EDF 
100 
83673 
118212 
118212 
Open 
EDF 
50 
158939 
207935 
207934 
Closed 
RM 
NjA 
40298 
65136 
65136 
Open 
RM 
NjA 
44085 
64502 
64499 
Open 
RM 
200 
45275 
63213 
63213 
Open 
RM 
100 
64622 
84314 
84314 
Open 
RM 
50 
121444 
156000 
156000 
Table 6. Scheduling overhead (Tick size 20). 
System 
Algorithm 
Scheduling Quantum 
Context Switches 
Insertion 
Removal 
Closed 
EDF 
NjA 
44518 
78368 
78367 
Open 
EDF 
NjA 
49021 
72110 
72110 
Open 
EDF 
200 
53519 
80688 
80687 
Open 
EDF 
100 
83950 
117982 
117982 
Open 
EDF 
50 
159376 
208272 
208271 
Closed 
RM 
NjA 
39773 
65625 
65625 
Open 
RM 
NjA 
44201 
64226 
64225 
Open 
RM 
200 
44929 
63143 
63143 
Open 
RM 
100 
64398 
84377 
84377 
Open 
RM 
50 
121586 
156225 
156225 
Table 7. Scheduling overhead (Tick size 50). 
System 
Algorithm 
Scheduling Quantum 
Context Switches 
Insertion 
Removal 
Closed 
EDF 
NjA 
42281 
85531 
85530 
Open 
EDF 
NjA 
49147 
72009 
72008 
Open 
EDF 
200 
52738 
80144 
80143 
Open 
EDF 
100 
83501 
116660 
116659 
Open 
EDF 
50 
159078 
208207 
208207 
Closed 
RM 
NjA 
37887 
72136 
72136 
Open 
RM 
NjA 
43884 
63895 
63894 
Open 
RM 
200 
44717 
63804 
63804 
Open 
RM 
100 
64335 
84717 
84717 
Open 
RM 
50 
121096 
155611 
155611 
53 

180 
DENGETAL. 
is small, the open system suffers from frequent context switches. Both the context switch 
operations and insertion/removal operations occur more frequently, and the scheduling 
overhead becomes larger. 
10. Summary and Future Work 
We have described the architecture of the open system and its implementation in Windows 
NT operating system. The open system allows independently developed hard real-time ap-
plications to run together with non-real-time applications and supports their reconfiguration 
at run-time. 
Simulation results show that the scheduling overhead of both the open and the closed 
systems is relatively insensitive to the tick size. On the other hand, the scheduling overhead 
of the open system critically depends on the scheduling quantum. When all real-time 
applications are predictable, the scheduling overhead of the open system is close to that of 
the closed system. When some real-time applications are unpredictable, the overhead is also 
close to that of a closed system when the scheduling quantum is 200 or larger for a system 
of periodic tasks whose period range from 250 to 1600. However, when the scheduling 
quantum is 50, the overhead of the open system is 2 to 3 times higher. 
The achievable processor utilization (i.e., the total required capacity of all schedulable 
real-time applications) also depends on the scheduling quantum. This performance measure 
also depends on the jitter factors and the shortest relative deadlines of all jobs in the real-time 
applications. In order to determine its dependency on these parameters and the scheduling 
quantum, it requires a more extensive evaluation study based on sample actual real-time 
applications. This study is yet to be completed. 
The extra context switch overhead incurred by the two-level scheduler consists of two 
parts: the cost of providing timing isolation to each application and the cost of preventing 
priority inversion due to over-replenishment of server budget. The former is surely to incur 
also in a system that uses the one-level, proportional share resource allocation scheme 
proposed by Stocia, et al. (1996), which also provides timing isolation. We are extending 
our simulation study to include a comparison with that scheme. We expect the context 
switch overhead of the two schemes to be comparable, but because the queues maintained 
by the schedulers the open system are shorter, the insertion/removal cost of the open system 
should be lower. 
In our current implementation, we ignored two important issues: (1) hardware interrupts 
and deferred procedure call (DPC) routines and (2) user-level subsystems in Windows NT. 
Consequently, our open system still cannot always provide timing guarantees to real-time 
applications, even if all real-time applications pass the acceptance test. We will address 
these issues in the next version of the open system. 
Specifically, hardware interrupts in Windows NT can preempt the execution of any real-
time threads. The time taken to process these interrupts, both in the interrupt service 
routines (ISR) and their corresponding DPC routines, is unbounded. This clearly makes 
the schedulability guarantees of real-time applications impossible. 
One solution is to mask off all the hardware interrupts except the clock interrupt and have 
a single-threaded pure poller to poll the interrupt periodically. The poller has a very short 
54 

AN OPEN ENVIRONMENT 
181 
period or relative deadline, thus it almost always has the highest priority among all ready 
servers in the system. When the poller is activated, it is placed in the ready queue of as 
scheduler. When the thread of the poller is scheduled, it checks if the system has interrupts 
pending, and if so, it executes the corresponding ISR's until all interrupts are served or the 
poller consumes all its budget. DPC objects are inserted in the specified DPC queues in 
ISR's to further process each interrupt. Since ISR's are usually very short, the budget of 
the poller can be very small. In this way, the time consumed by ISR's can be accounted for. 
The DPC processing mechanism needs to be modified accordingly, with the exception of 
timer DPC processing, which remains unchanged. The ideal approach is to have a real-time 
thread fk for each real-time application Ak and a non-real-time thread fo for all non-real-
time applications. When an interrupt occurs, the ISR finds the target application of the 
interrupt and enqueues the DPC object. Depending on whether the target application is a 
non-real-time or a real-time one, thread fo or fk is waken up to execute the corresponding 
DPC routine. This is the approach taken by some commercial real-time operation systems 
like Lynx as. Unfortunately, this approach is unrealistic as it requires modifying or even 
rewriting device drivers of all hardware devices in the system. 
We will take a more realistic approach. We divide the hardware into two categories, those 
accessed by real-time applications and those accessed by only non-real-time applications. 
For devices that are accessed only by non-real-time applications, we use a high priority, 
non-real-time thread to perform their DPC processing. This thread is activated and placed 
in the ready queue of server So when some DPC object is inserted in a DPC queue. When 
the thread is scheduled, it executes DPC routines in all DPC queues for the devices of this 
category. For devices that are accessed by real-time applications, we can either take the 
approach described earlier or implement a system service provider for the hardware, as we 
have done for network devices. 
The second issue is the subsystems in Windows NT. Windows NT implements some 
system modules as user level protected subsystems. An example is Win32 subsystem, which 
is executed by a set of non-real-time threads. When an application calls a Win32 function, the 
Win32 function invokes local procedure call (LPC) to place a request in the message queue 
of the Win32 subsystem and the function blocks. After one of the non-real-time threads in 
Win32 subsystem processes the request, the Win32 function resumes. This scheme again 
does not provide timing guarantees for real-time applications that require services from 
the Win32 or other subsystem servers, since there are non-real-time threads involved and 
some subsystems' message queues are FIFO queues. One way to fix this problem is to re-
implement such subsystems used by real-time applications as system service providers. The 
serious disadvantage of this approach is the implementation complexity. Other approaches 
are currently being studied. 
Acknowledgments 
This work was partially supported by DARPA contract F30602-97-2-0121 and NASA con-
tract NAG 1-613. 
55 

182 
DENGET AL. 
Appendix: Two-Level Scheduling Algorithm Pseudo Code 
This appendix describes in pseudo code operations of the actions of the OS scheduler and 
algorithms to maintain servers of nonpreemptive applications and constant utilization server 
of preemptive applications. 
Operations of the OS scheduler 
Initiation: 
• 
Create a total bandwidth server So with size Uo for non-real-time applications and a 
passive server for each service provider. 
• 
Set the total server size Ut of all servers in the system to Uo plus the total size of all 
passive servers. 
Acceptance test and admission of Ak: 
Do according to the algorithm described in Figure 2. 
Maintenance of each server Sk: 
Replenish the server budget and set the server deadline in the manner described in 
Section 5. 
Interaction with server scheduler of each server Sk: 
• 
When a job J in the application Ak is released, invoke the server scheduler of Sk to 
insert J in Sk 's ready queue. 
• 
If the application Ak uses a preemptive scheduling algorithm, before replenishing the 
budget of Sk, invoke the server scheduler of Sk to update the occurrence time tk of the 
next event of Ak • 
• 
When a job J in the application Ak enters its nonpreemptable section, mark the server 
Sk nonpreemptable until the job J in Ak leaves its nonpreemptable section. 
• 
When a job J in the application Ak requests for a global resource, grant J the resource 
and mark the server Sk nonpreemptable until the job J in Ak no longer holds any global 
resource. 
Scheduling of all servers: 
Schedule all servers on the EDF basis, except when a server Sk is marked non-
preemptable; in which case, Sk has the highest priority among all servers in the 
system. 
Termination of a real-time application Ak: 
• 
Destroy the server Sk. 
• 
Decrease Ut by Uk. 
56 

AN OPEN ENVIRONMENT 
183 
Maintenance of Server Sk for a Nonpreemptive Application Ak 
Maintenance of constant utilization server Sk whose deadline is d: 
1. When a new job Ji in Ak arrives at t, 
(a) invoke the server scheduler of Sk to place Ji in the proper location in Sk'S ready 
queue; 
(b) if the current server deadlined d :::s t, set the server budget to ei and server deadline 
d to t + ei/Uk. 
2. At the deadline d of the server Sk, if its ready queue is not empty, set the server budget 
to e and server deadline d to d + e / Uk. where e is the execution time of the job at the 
head of the queue. 
Maintenance of Constant Utilization Server Sk for a Preemptive Application Ak 
Maintenance of constant utilization server Sk whose deadline is d: 
1. When a new job Ji of Ak arrives at t, 
• 
invoke the server scheduler of Sk to insert Ji in Sk'S ready queue and set Ji's 
remaining execution time e; to ei; 
• 
if t 2: d and Ji is the only job in the ready queue, 
(a) invoke the server scheduler of Sk to calculate the occurrence time tk of the next 
event of Ak as described in Figure 5; 
(b) set the server budget to (tk - t)Uk and server deadline d to tk; and 
(c) decrease the remaining execution time e; of Ji by (tk - t)Uk . 
2. At the server deadline d, 
• 
If Sk'S ready queue is not empty and job Ji is at the head of the ready queue, 
(a) invoke the server scheduler of Sk to calculate the occurrence time tk of the next 
event of Ak as described in Figure 5; 
(b) set the server budget to (tk - d) Uk and server deadline d to tk; and 
(c) decrease the remaining execution time e; of Ji by (tk - d)Uk. 
3. After a job Ji in Ak requests for or releases a resource, invoke the server scheduler of 
Sk to change the priorities of some jobs in its ready queue if necessary and to move the 
job with the highest priority to the head of its ready queue. 
57 

184 
DENGET AL. 
Calculation of the Next Event Time by the Scheduler of the Server Sk of a 
Predictable Application Ak 
Input: Calculation of the Next Event Time tk at time t: 
te +- the earliest release time of all jobs in Ak after t; 
if the ready queue of Sk is empty at time t 
tk +- te; 
else { 
Ji +- the jobs at the head of the ready queue of Sk at time t; 
e;' +- the amount of time Ji must attain to reach the point when Ji either completes, 
or requests for or releases a resource, or enters or leaves a nonpreemptable section, 
whichever occurs the earliest; 
tk +- min{te, t + e;' / Uk}; 
Notes 
1. This term is used to avoid overloading the term server, which is a more common name for a service provider. 
The term server is used in this paper to mean something else. 
2. We need to distinguish between nonpreemptively scheduled applications from applications that have nonpre-
emptable sections. A job in a nonpreemptively scheduled application is never preempted by other jobs in the 
application, but may be preempted by jobs in other applications because the server of the application can be 
preempted by servers of other applications. In contrast, when a job is in a nonpreemptable section, it effectively 
executes at the highest priority and cannot be preempted by any job in the system. 
3. In our implementation, the processor reserve is passed by the server Sk to the passive server. Thus, we avoid 
an additional context switch. 
4. This occurs when the corresponding job executes for less than its maximum execution time. 
5. PERTS is a set of graphical based schedulability analysis tool developed by our research group. 
References 
Spuri, M., and Buttazzo, G. 1996. Scheduling aperiodic tasks in dynamic priority systems. Real-Time Systems 
10: 179-210. 
Deng, Z., Liu, J. w.-S., and Sun, J. 1997. A scheme for scheduling hard real-time applications in open system 
environment. Proceedings of 9th Euromicro Workshop on Real-Time Systems, pp. 191-199. 
Deng, Z., and Liu, J. w.-S. 1997. Scheduling real-time applications in an open environment. Proceedings of IEEE 
18th Real-Time Systems Symposium, pp. 308--319. 
Stoica, I., Abdel-Wahab, H., Jeffay, K., Baruah, S., Gehrke, J., and Plaxton, C. 1996. A proportional share 
resource allocation algorithm for real-time, time-shared systems. Proceedings of IEEE 17th Real-Time Systems 
Symposium, pp. 288-299. 
Demers, A., Keshav, S., and Shenker, S. Analysis and simulation of a fair queueing algorithm. Proc. ACM 
SIGCOMM '89, pp. 3-12. 
58 

AN OPEN ENVIRONMENT 
185 
Zhang, L. 1991. VirtualClock: A new traffic control algorithm for packet-switched networks. ACM Transaction 
on Computer Systems 9(2): 101-124. 
Liu, C. L., and Layland, 1. W. 1973. Scheduling algorithms for multiprogramming in a hard real time environment. 
1. Assoc. Comput. Mach. 200): 46-6l. 
Leung, J. Y.-T., and Whitehead, J. 1982. On the complexity of fixed-priority scheduling of periodic real-time 
tasks. Performance Evaluation 2: 237-250. 
Mok, AI. 1983. Fundamental design problems of distributed systems for the hard real-time environment. Ph.D. 
Thesis, MIT, Department of EE and CS, MIT /LCS /TR-297. 
Sommer, S., and Potter, J. 1996. Operating system extension for dynamic real-time applications. Proceedings of 
IEEE 17th Real-TIme Systems Symposium, pp. 45-50. 
Tokuda, H., Nakajima, T., and Rao, P. 1990. Real-time mach: Towards a predictable real-time system. Proceedings 
of the Usenix Mach Workshop, pp. 73-82. 
Carpenter, B., Roman, M., Vasilatos, N., and Zimmerman, M. 1997. The RTX real-time subsystem for Windows 
NT. The USENIX Windows NT Workshop Proceedings, pp. 33-37. 
Mercer, C. W., Savage, S., and Tokuda, H. 1994. Processor capacity reserve: Operating system support for 
multimedia applications. Proceedings of the IEEE International Conference on Multimedia Computing and 
Systems. 
Spruut, B., Sha, L., and Lehoczky, J. P. 1989. Aperiodic task scheduling for hard real-time systems. Real-TIme 
Systems: The International Journal of TIme-Critical Computing Systems 1: 27-60. 
Liu, J. w.-S., Redondo, J. L., Deng, Z., Tia, T. S., Bettati, R., Silberman, A., Storch, M., Ha, R., and Shih, W. K. 
1993. PERTS: A prototyping environment for real-time systems. Proceedings of IEEE 14th Real-Time Systems 
Symposium, pp. 184-188. 
Custer, H. 1993. Inside Windows NT. Microsoft Press. 
59 

~& The International Journal of Time-Critical Computing Systems, 16, 187-221 (I 999) 
ft © 1999 Kluwer Academic Publishers, Boston. Manufactured in The Netherlands. 
On Developing Distributed Middleware Services 
for QoS- and Criticality-Based Resource 
Negotiation and Adaptation* 
J. HUANG 
huang@htc.honeywell.com 
Honeywell Technology Center, 3660 Technology Drive, Minneapolis, MN 55418, USA 
Y. WANG 
ywang@htc.honeywell.com 
Honeywell Technology Center, 3660 Technology Drive, Minneapolis, MN 55418, USA 
F. CAD 
fcao@htc.honeywell.com 
Honeywell Technology Center, 3660 Technology Drive, Minneapolis, MN 55418, USA 
Abstract. The Global Resource Management System (GRMS) provides middleware services for QoS- and 
criticality-based resource negotiation and adaptation across heterogeneous computing nodes and communication 
networks. This paper presents GRMS's design, prototyping, and performance evaluation. We introduce GRMS 
design principles and two key conceptsQunified resource model and ripple scheduling-and describe our archi-
tectural design based on these concepts. Further, we present a decentralized end-to-end two-phase negotiation 
and adaptation protocol with the functionality of distributed, dynamic QoS adjustment and stream preemption. 
We discuss GRMS's system prototyping and lessons learned and report our experimentation and simulation re-
sults, providing insights into design and implementation of a middleware-based distributed resource management 
system. 
Keywords: distributed resource management, adaptive resource management, Quality of Service, QoS negotia-
tion, QoS adaptation, middleware 
1. Introductiou 
In recent years, the notion of Quality of Service (QoS) has been widely discussed and ex-
plored as a means of trading application execution quality for application execution avail-
ability in case of system resource contention (ISO 1996). To support such an application 
need, much research and development work has been done on QoS-based system resource 
management (Hutchinson et aI., 1995) Examples are RSVP (a resource reservation protocol 
for communication networks) (Zhang et aI., 1993), processor reservation (Lee et aI., 1996; 
Tokuda et aI., 1993), and local multiresource reservation and adaptation (Huang et aI., 
1997b; Ramakrishnan et aI., 1995). Most of the work has focused on developing admis-
sion control or scheduling approaches for individual resources, such as network segments 
and system processors. To provide QoS support for distributed applications, end-to-end 
resource management is needed to schedule distributed, heterogeneous resources along the 
application execution path in a collective and coherent manner. Further, a system infrastruc-
* This work was supported by the Honeywell Initiative R&D Program under Grants I4560-ME, 14660-MD, and 
I4760-MC. 
61 

188 
"Critical" class 
"Essential" class 
"Non-essential" class 
HUANG, WANG AND CAO 
QoSmin must be guaranteed. 
No preemption allowed. 
Higher-criticality first. 
Preemption allowed. 
Arbitrary preemption. 
Figure 1-1. Classification of mission-critical applications. 
ture is needed to enable use of various pieces of resource management protocols/ algorithms 
that have been or will be developed for individual resource components. 
In this paper, we present a middleware-oriented Global Resource Management System 
(GRMS) currently being developed in Honeywell that provides distributed applications 
with end-to-end QoS negotiation and adaptation and criticality-based preemption services 
(Huang et aI., 1996; Huang et aI., 1997a). In particular, we consider a class of mission-
critical applications that are 
• 
Distributed-Applications execute across multiple heterogeneous computing nodes as 
well as network segments; 
• 
QoS-aware-At their execution, applications specify and react to such QoS parameters 
as image resolution and data sample rate. In general, the higher an application's QoS, 
the higher its resource demand. An application may specify a QoS range [QoSmin, 
QoSmax] within which the application desires to execute. 
• 
Criticality-driven-More important applications need to be allocated with resources 
first. For instance, an application performing periodic image capturing and flaw de-
tection in advanced process control (Guha et aI., 1995b) can be more important than 
one that monitors floor activities in the controlled plant, and consequently, the image 
stream is more critical than the video stream. In general, we consider three classes of 
applications: "critical," "essential," and "nonessential." As illustrated in Figure 1-1, the 
critical class requires a guarantee of the minimum QoS of applications. In the essential 
class, as many applications as possible need to be executed based on their criticality; 
they may be suspended in case of resource contention. In the nonessential class, as 
many applications as possible need to be executed; they may be suspended arbitrarily. 
• 
Dynamic-Application workload, and in tum resource demand, varies from time to 
time depending on its operation mode. In digital battlefield management, for example, 
detection of a mobile target may trigger a sequence of reactions such as video monitor-
ing, infrared tracking, image library retrieval, target matching and recognition, media 
data fusion and filtering, and command and control (Robinson, 1993). Figure 1-2 shows 
62 

ON DEVELOPING DISTRIBUTED MIDDLEWARE SERVICES 
Workload 
Operation 
Mode 1 
Operation 
Mode 2 
Mode 
Change 
Mode 
Change 
Mode 
Change 
Figure 1-2. Instances of application i and their workloads. 
Operation 
Mode 3 
OoS 
t 
~'DisPlay] 
FDDI 
Node C 
QoS 
t 
TIme 
C970323-03 
QoS 
t 
I 
--------1 Database 
___ --'! '.a.-I. (·.111l.':T;,·1 
NodeD 
NodeE 
Figure 1-3. Applications-an example. 
189 
such a dynamic behavior of application workload. The dynamic workload results in 
dynamic resource demand. 
• 
Stream-oriented-Data flows from the source node, through intermediate processing 
node(s), and to the destination node(s) at a specified rate (e.g., image frames per second). 
An example of such applications is a command and control system, where, as illustrated 
by Figure 1-3, data flow through various computing nodes across heterogeneous networks 
using possibly different resource reservation protocols for monitoring, information filter-
ing, archiving, storage retrieval, commanding, device sensing and actuation, etc. In this 
environment, a certain bandwidth of system resources (network bandwidth, processor cy-
cles, memory space, etc.) may be preallocated to the class of critical applications (e.g., 
device sensing and actuation and audio commanding) that require an absolute guarantee of 
their run-time performance with the minimum QoS under any circumstance. The rest of 
63 

190 
HUANG, WANG AND CAO 
the system resource bandwidth is shared by essential and nonessential applications (e.g., 
video monitoring and Internet browsing), which in case of resource contention are willing 
to trade their QoS for execution and can be preempted by higher-criticality applications. 
To support such mission-critical applications, we define a number of design goals for 
GRMS: 
• 
It must be criticality-cognitive and be able to suspend and resume applications on line 
according to the availability of system resources. The objective is to guarantee execution 
of the class of critical applications and to execute as many as possible higher-criticality 
applications in the essential class. 
• 
It must also provide end-to-end QoS negotiation and adaptation services to support dy-
namic workloads on line. The objective is to execute as many essential and nonessential 
applications as possible and to maximize the applications' QoS as long as resources are 
available. 
• 
GRMS's performance, such as end-to-end resource negotiation time, should scale up 
as the number of distributed computing resources increases. 
• 
GRMS's distributed resource management protocol needs to be reliable or be easily 
enforced with reliability features. 
• 
From the software engineering perspective, the GRMS software should be interoper-
able with existing or future resource reservation protocols/algorithms developed for 
individual resources, and evolvable as operating systems and network protocols evolve 
in the future. 
In the next section, we describe our design principles and concepts for achieving the goals. 
We present the GRMS architecture and its major components in Section 3. In Section 4, we 
focus on our ripple scheduling approach-a key to realizing end-to-end QoS negotiation 
and adaptation and criticality-based preemption. Our system prototyping work and lessons 
learned are described in Section 5. Section 6 reports our performance evaluation results 
obtained from the system prototype and simulation. We review related work in Section 7. 
We conclude our work with its uniqueness and major findings in Section 8. Appendix A 
briefly illustrates the use of the RSVP protocol under the GRMS. 
2. 
Concepts 
In this section, we first describe the design principles that guide our work for toward the 
goals described above. Then we present two key concepts that pervade the GRMS design. 
2.1. Design Principles 
We employed four basic design principles: 
(1) Unifying resource negotiation and execution paradigm-GRMS deals with hetero-
geneous system resources (processor, network, etc.) and, in turn, heterogeneous resource 
64 

ON DEVELOPING DISTRIBUTED MIDDLEWARE SERVICES 
191 
management algorithms/protocols. For instance, for a processor on a computing node, 
different CPU scheduling algorithms/policies such as the rate monotonic scheduling algo-
rithm and earliest-deadline-first policy (Liu et aI., 1973) may be used at different times or 
on different installations to meet different scheduling needs. Another example is the use 
of RSVP and NetEx (Raha et aI., 1996) resource reservation protocols in different network 
domains at the same time or in the same network domain at different times. To ensure that 
GRMS is interoperable with individual resource management components (possibly devel-
oped by different organizations), heterogeneous resource management components must 
be modeled uniformly and GRMS must follow a unified resource management paradigm. 
(2) Decentralized resource management-Distributed resource management can be car-
ried out in different ways in terms of application/resource information provision and 
protocol/algorithm execution. A fundamental difference among different approaches is 
"centralized" vs. "decentralized," where the former relies on a central information base 
and/or a central resource management coordinator but the latter does not. We adopt the lat-
ter approach, requiring the GRMS protocol be decentralized. The motivation is to achieve 
the goals of performance scalability and system reliability. 
(3) Middleware architecture-Resource management software can be implemented at 
different levels of a system environment (Huang, 1995). There are three basic schemes: 
(a) "underneath operating systems" (e.g., (Bollella et al., 1995»; (b) "within an operating 
system" (e.g., (Coulson et aI., 1994); and (c) "on top of operating systems" (e.g., (Huang 
et al., 1997b; Ramakrishnan et al., 1995». Each has its advantages and disadvantages. 
To achieve the goal of software portability and evolvability, we consider the third scheme, 
building a middleware GRMS on top of operating systems and network protocols. With such 
a middleware scheme, the degree of real-time guarantee provided to applications depends 
on, among other factors, the real-time capability and tightness of service time supported by 
the underlying operating system and network. In general, real-time operating system and 
real-time network are required to support hard real-time applications. 
(4) Separating GRMS from application programming model-Different applications may 
be implemented in different programming languages. In general, we require that GRMS 
be independent of the programming model to ensure the openness of the GRMS services. 
A challenging issue is how to provide an application run-time abstraction that is able to 
interface different programming models to GRMS. 
2.2. 
Unified Resource Management Model 
Supporting end-to-end QoS negotiation and criticality-based application preemption re-
quires the system ability to manage heterogeneous resources and coordinate heterogeneous 
resource management components. Guided by our first design principle, "unifying re-
source negotiation and execution paradigm," we use an abstraction, called a resource agent, 
to model various resource management components used for individual resources and com-
puting nodes. A resource agent has the following behavior: 
• 
Assess the capacity and availability of its resource(s), 
• 
Reserve a certain amount of resource(s), 
65 

192 
Scheduling 
Algorithm 
Figure 2 -1. Resource agent abstraction. 
• 
Execute an application task, 
HUANG, WANG AND CAD 
Resource Agent API 
Schedulability I Scheduling 
Analyzer 
Mechanism 
• 
Release the resource(s) previously reserved, and 
• 
Suspend or terminate application task execution. 
As further specified in Section 4, this behavior is defined by a set of services and their 
application programming interface (API), by which resource agents interact with each other 
to carry out the end-to-end resource management. As shown in Figure 2-1, the resource 
agent behavior can be supported internally by three components or the like: 
(1) Scheduling algorithm/protocol-Defines the order and/or time by which its resource 
executes application tasks; 
(2) Schedulability analyzer-Calculates or estimates whether a given set of application 
tasks can be executed by its resource within the task QoS constraints; and 
(3) Scheduling mechanism-Carries out execution operations of application tasks through 
interaction with the underlying operating system or network protocol. 
Clearly, this agent abstraction defines the behavior of resource components, leaving design 
and implementation details to system developers. 
2.3. Ripple Scheduling 
The resource agent concept described above provides a way to deal with heterogeneous 
resource management components in a unified abstraction. This uniform view sets up a 
foundation for development of our second concept: ripple scheduling. Ripple scheduling 
is an approach to end-to-end resource negotiation and adaptation. It conducts distributed 
resource management, in a ripple fashion, across resource agents that reside along the 
execution path of applications. 
The ripple scheduling consists of two major components: scheduling spanning tree and 
atomic two-phase negotiation and adaptation protocol. A scheduling spanning tree can be 
formed based on a given application, its execution path, and the source of its QoS request 
instance. Figure 2-2 shows two spanning tree instances for the application illustrated in 
Figure 1-3. In this example, the vertices of the spanning trees are the node resource agents 
66 

ON DEVELOPING DISTRIBUTED MIDDLEWARE SERVICES 
193 
~ 
Coordinating 
~ AgentonA 
/~AgCntonB 
Agent on DO 
0 Agent on C 
~ 
. 
AgentonEO 
(a) Spanning Tree from QoS Request on Node A 
~~~~~dinatiIlg 
( t ~ltOIlB 
Agent on D 
0 
0 Agent on A 
Agent on C 
Agent on EO 
(b) Spanning Tree from QoS Request on Node D 
Figure 2-2. Scheduling spanning tree--example based on Figure 1-3. (a) Spanning tree from QoS request on 
node A. (b) Spanning tree from QoS request OIl node B. 
of computing nodes A, B, C, D, and E along the application execution path, and the edges 
are defined by the resource negotiation flow between the node agents. The source of a QoS 
request uniquely identifies a resource agent as coordinator agent in the spanning tree. Note 
that the relationship between an application and its spanning tree instance is one-to-one 
(i.e., each application QoS request results in a unique scheduling spanning tree). 
The atomic two-phase negotiation and adaptation protocol is initiated by the coordinator 
agent of a spanning tree when the corresponding application generates a new QoS request. 
The first phase of the protocol performs an end-to-end resource availability assessment; 
that is, the coordinator propagates the QoS requests to all the child resource agents and the 
child agents then propagate back the QoS values that they can support locally. Then the 
coordinating agent determines if the application can be admitted for execution according 
to the result of the resource availability assessment. In the second phase, the coordinating 
agent propagates to all the child agents either a COMMIT command with a committed 
QoS value to execute the application or an ABORT command to release system resources 
reserved during the first phase. 
During each ripple scheduling operation, GRMS may dynamically adjust the QoS values 
of concurrent applications by reducing (called QoS shrinking) and/or increasing (called 
QoS expansion) them within their range settings. The goals are to maximize concurrent 
applications and maximize the QoS of applications, respectively. GRMS may also perform 
distributed preemption to guarantee the class of critical applications and to maximize the 
concurrency of essential applications. 
With the design principle (2), we consider the ripple scheduling approach to be decentral-
ized, first in the sense that individual resource agents do not access any global information; 
second, the two-phase negotiation and adaptation protocol is executed on instances of indi-
vidual spanning trees without a fixed global resource management coordinator. As indicated 
by our performance studies presented in Section 6, this decentralized scheme helps achieve 
performance scalability as well as protocol reliability. 
67 

194 
,- --- . -~ -------
- - - --------~, 
, 
.... 
... , 
Oisll;ibuted System 
Resource MBnIIiI'" 
(05m Agent) 
Figure 3-1. GRMS architecture. 
3. System Architecture 
, , 
, 
End-lo-End 
ResourCe NSgOtiation 
HUANG, WANG AND CAO 
DSRM 
Agent 
Resource 
Management 
Mlddleware 
With the design principles and key concepts introduced above, we now discuss the GRMS 
software architecture and its major components. 
Figure 3-1 shows the GRMS architecture in the context of a layered system environ-
ment consisting of application development and execution layer, resource management 
middleware layer, and commercial-off-the-shelf (COTS) product layer. As highlighted, 
each computing node hosts a set of resource agents, specifically, the distributed system re-
source manager (DSRM) and individual resource managers, which all reside at the resource 
management middleware layer. 
The major components of the GRMS architecture are: 
• 
A run-time abstraction ("session" )-A canonical representation of run-time applica-
tions, serving as an interface between the application programming model and GRMS 
services. This canonical model is defined by an application execution graph with a set 
of system threads and buffers as vertices and data flow paths as edges (Huang et ai., 
1994; Huang et ai., 1996). With the canonical model, we use the notion of session 
to represent instances of run-time applications. An application session instance cor-
responds to a specific application operation mode. As illustrated in Figure 1-2, each 
session instance of an application i may impose a certain workload, thus demanding a 
certain amount of system resources. Further, a distributed application session consists 
of subsessions, each executing on a computing node. Therefore, a distributed session is 
68 

ON DEVELOPING DISTRIBUTED MIDDLEWARE SERVICES 
rr"'~"'7' ~TI~~~~;~J-API 
Reservati n 
EnforccmCJ1[ 
.. !:.t.: 
.... 2: 
... !l:!!. =:cl.l!l==~~~ 
Figure 3·2. Use of different resource scheduling protocols/ algorithms. 
em'ork 
Resource 
Agent 
195 
a unit of distributed resource negotiation, allocation, and scheduling, and a subsession 
is a unit of local resource negotiation, allocation, and scheduling. 
• 
DSRM-A node agent for coordinating end-to-end resource negotiation and adaptation 
over local resource agents and with peer node agents across networks. DSRM executes 
the two-phase negotiation and adaptation protocol, as we introduced previously with 
the concept of ripple scheduling. The focus of our work is on building the DSRM and 
its negotiation and adaptation protocol, which is detailed in Section 4. 
• 
Local resource agents-The set of individual resource managers/schedulers repre-
sented by the agent model. According to our concept of the unified resource abstraction, 
there are two major issues regarding design and implementation of the local resource 
agents. First, each agent should be able to assess the availability of its resource and 
control application task execution over its resource. Since substantial work has been 
done in the area (Stankovic et aI., 1988; van Tilborg et aI., 1991), we do not discuss 
this issue any further in this paper. Second, a resource agent should be able to "plug-
n-play" existing or future scheduling algorithms/protocols for managing its resource. 
To address this issue, we use an "adapter" mechanism. To illustrate this approach, Fig-
ure 3-2 shows the network resource manager agent interfacing three network admission 
control protocols: RSVP (Zhang et aI., 1993), ST-II (Delgrossi et aI., 1995), and NetEx 
(Raha et aI., 1996). As an example, we present the GRMS-RSVP adaptation protocol 
in Appendix A. 
• 
QoS library-This component facilitates GRMS QoS negotiation across the system 
layers, from applications to the middleware resource management to operating systems 
and network layers. Our approach to the QoS translation is to provide a set of mapping 
functions stored in a system library. Layer-software developers are responsible for 
defining and developing the QoS mapping functions, since they know the semantics of 
the QoS with which they deal. At run time, a specific QoS translation is carried out 
by making an up/down call of the corresponding QoS mapping function. Examples of 
such mapping functions are given in Section 5. 
69 

196 
HUANG, WANG AND CAO 
4. Ripple Scheduling 
The primary objectives of GRMS ripple scheduling are to guarantee the class of critical 
applications their minimum QoS, to execute as many higher-criticality essential applica-
tions as possible, and to maximize the degree of QoS of executing applications under the 
application's timing and resource capacity constraints. We have introduced the concept 
of ripple scheduling with a unified resource agent model in Section 2. In this section, we 
describe its design and implications. 
4.1. 
Two-Phase Negotiation and Adaptation Protocol 
At the core of the ripple scheduling is a two-phase atomic negotiation and adaptation protocol 
accompanied by dynamic QoS shrinking, preemption (if necessary), and QoS expansion. 
Specifically, the protocol performs one or more of the following functions: 
• 
Shrinking the QoS of executing sessions, if no sufficient resources are available, to meet 
the goal of maximizing the number of executing sessions; 
• 
Preempting low-criticality sessions, if no sufficient resources are available after QoS 
shrinking, to meet the goal of maximizing the number of high-criticality sessions; 
• 
Expanding the QoS of executing sessions at the end of negotiation to meet the goal of 
maximizing application QoS. 
The protocol is carried out by a set of services provided by resource agents, including: 
• 
ChangeModeO for applications to initiate a session QoS negotiation request with a 
DSRMagent; 
• 
TestAndHold(), Commit(), and Abort() for assessing, reserving, scheduling, and releas-
ing resources; 
• 
ShrinkQoSVirtual(), ShrinkQoSReal(), and ShrinkQoSRevoked() for the on-line QoS 
reduction; 
• 
PreemptVirtualO, PreemptRealO, and PreemptRevokedO for the session preemption; 
• 
ExpandQoSO for the on-line QoS expansion. 
The two-phase negotiation protocol is detailed as follows: 
Phase I: TestAndHold(Si, QoS) 
for the DSRM agent on computing node k: 
LocalAdmission = YES; 
for each local resource agent 
TestAndHold(Si's Task, QoS); 
if all the local resources can support the requested QoS 
70 

ON DEVELOPING DISTRIBUTED MIDDLEWARE SERVICES 
AdjustQoS (00.); 
else 
LocalAdmission = NO; 
if (LocaIAdmission==NO and there exist shrinkable executing sessions) 
status = ShrinkQoSVirtual(Si, ShrinkQoS..Policy); 
if(status == OK) 
LocalAdmission = YES; 
if (LocalAdmission == NO and there exist preemptable sessions) 
status = PreemptVirtual(Si, Preempt..Policy); 
if(status == OK) 
LoealAdmission = YES; 
if this DSRM is the coordinating node in the spanning tree 
if(LocalAdmission == YES) 
for each remote DSRM agent on every child node 
TestAndHold(Si, QoS); 
if all the child nodes can support the QoS 
AdjustQoS(. 0 0); 
start Phase II: Commit(Si, QoS); 
exit; 
start Phase II: Abort(Si); 
if this DSRM is an intermediate node in the spanning tree 
if(LocalAdmission == YES) 
for each remote DSRM agent on every child node 
TestAndHold(Si, QoS); 
if all the child nodes reply with YES 
AdjustQoS(); 
return YES with supportable QoS to the parent DSRM agent; 
return NO to the parent DSRM agent; 
if this DSRM agent is a leaf node in the spanning tree 
if(LocalAdmission == YES) 
return YES w / supportable QoS to the parent DSRM; 
else 
return NO to the parent DSRM agent; 
Phase II: Commit(S~ QoS) 
for DSRM agent on computing node k: 
while (there exists a session Sj to be shrunk by Si) 
ShrinkQoSReal(Sj, Local); II Si shrinks Sj 
while (there exists a session Sj to be preempted by SO 
PreemptReal(Sj, Local); II Si preempts Sj 
for each local resource agent 
Commit(Si's Task, QoS); 
197 
71 

198 
if this DSRM agent is the coordinating or intermediate node 
for each remote DSRM agent on every child node 
Commit(Si, QoS); 
AdmitOthers( ReAdmitYolicy); 
ExpandQoS( ExpandQoSYo[icy); 
exit; 
Phase II: Abort(Si) 
for DSRM agent on computing node k: 
while (there exists a session Sj virtually shrunk by Si) 
ShrinkQoSRevoked( Sj, Local); 
while (there exists a session Sj virtually preempted by Si) 
PreemptRevoked(Sj, Local); 
for each local resource agent 
Abort(Si's Task); 
if this DSRM agent is the coordinating or intermediate node 
for each remote DSRM agent on every child node 
Abort(Si); 
exit; 
4.2. 
Discussions 
HUANG, WANG AND CAO 
A number of subtle issues relate to the two-phase negotiation and adaptation protocol: 
QoS negotiation-The negotiation takes two forms: (1) QoS shrinking of other executing 
sessions to yield sufficient resources for a requesting session, and (2) QoS expansion of 
executing sessions to absorb excess resources of the entire system. Due to the nature of the 
two-phase protocol, the QoS shrinking operation during the first phase takes place only with 
a logical operation, ShrinkQoSVirtual(). At the second phase, the logical QoS shrinking 
operation is either committed via ShrinkQoSReal() or aborted via ShrinkQoSRevoked(). 
The QoS expansion is considered simply another QoS request. 
GRMS supports range-based QoS negotiation, in which a QoS request is specified over 
a range of values [QOSmin, QoSmaxl and the QoS shrinking and expansion operations are 
performed by resource agents according to the QoS range. Since for a given QoS range 
of a session, individual resource agents may support different QoS ranges based on their 
resource availability, a routine AdjustQoS() is employed to consolidate the different QoS 
ranges into one supportable by all the resource agents. 
Criticality-based preemption-Similar to the logical QoS shrinking operation, a logical 
preemption operation, PreemptVirtual(), is performed on executing sessions of a computing 
node in the first phase of the protocol. The actual preemption commitment, PreemptReal(), 
or cancellation, PreemptRevoked(), is performed in the second phase. Two mechanisms 
propagate the virtual preemption message from a DSRM agent to its child DSRM agent(s): a 
synchronous preemption protocol, by which the parent DSRM agent waits for acknowledg-
ment of virtual preemption operations from the child DSRM agent(s), and an asynchronous 
72 

ON DEVELOPING DISTRIBUTED MIDDLEWARE SERVICES 
199 
Sk shrinks Si QoS 
to 10 attl 
Norte: X 
Si 
QoS[IO.30] 
NodeY 
Si shrinks Si OoS to 15 at tI 
Figure 4-1. A race condition during QoS shrinking. 
preemption protocol that does not perform the waiting. We discuss the performance of the 
two mechanisms in Section 6. 
Policies for QoS adjustment and session preemption-There are no optimal solutions 
to the problems of maximizing the number of higher-criticality sessions and maximizing 
the QoS of executing sessions, since achieving such objectives is an NP-hard problem 
even in a centralized system (Huang et al., 1998). Therefore, we consider the ordering 
in performing QoS shrinking, expansion, and preemption operations over a number of 
executing sessions to be a policy issue. For example, policies for QoS shrinking can 
be: (1) the smallest scheduling spanning tree first with the goal of reducing the protocol 
overhead; (2) the largest scheduling spanning tree first with the goal of reducing system-
wide resource consumption to admit more sessions; (3) random ordering; and (4) the 
lowest criticality session first. An objective of our work is to study the performance impact 
of different policies. 
Handling race conditions-The QoS shrinking and preemption operations are performed 
on distributed sessions, which may lead to race conditions where inconsistent QoS shrinking 
and/or preemption decisions may be made on different nodes of a session spanning tree. 
As an example, Figure 4-1 shows a race condition where the QoS of a distributed session 
Si, executing on Nodes X and Y, is being shrunk by concurrent sessions Sj and Sk at the 
same time t1. As a result, the QoS of Si's subsession on X is set to 15, whereas the QoS of 
Si's sub session on Y is set to 10. 
To prevent the potential race conditions, we employed two mechanisms together: (1) a 
compatibility matrix to disable QoS shrinking and preemption operations of sessions re-
questing a QoS change, and (2) distributed locking to obtain the right for QoS shrinking or 
preemption operation on executing sessions. An alternative to the locking-based approach 
is a nonlocking scheme, by which sessions may proceed with their QoS shrinking or pre-
emption operations until a conflict is detected; then the sessions must undo their conflicting 
operations. We view the tradeoffs between the locking and nonlocking approaches similar 
to those encountered in distributed transaction processing, in terms of locking and opti-
mistic concurrency control schemes (Berstein et aI., 1987): each has its advantages and 
disadvantages. Considering the potential of a low degree of locking activities and a high 
degree of "undo" activities in a distributed resource management environment, we chose 
73 

200 
HUANG, WANG AND CAO 
Table 4-1. Ripple scheduling routines. 
Phase I 
Phase II 
TestAndHold(Si) 
PreemptVirtual(Si, Policy) 
ShrinkQoSVirtual(Si,Policy) 
AdjustQoS(QoSI, QoS2) 
Lock(Si,lnvoker) 
UnLock(Si, Invoker) 
Commit 
Commit(Si) 
PreemptReal(Sj, Invoker) 
ShrinkQoSRea1(Sj, Invoker) 
AdmitOthers(Policy) 
ExpandQoS(Policy) 
Suspend(Si, Invoker) 
Abort 
Abort(Si) 
PreemptRevoked(Sj, Invoker) 
ShrinkQoSRevoked(Sj,Invoker) 
the locking approach for GRMS. In Section 6, we present our performance study of the 
distributed locking behavior and its impact on the ripple scheduling. 
Handling Iivelocks-Handling of distributed livelocks is another issue. A livelock may 
occur when two or more distributed sessions with the same criticality are being scheduled 
over the same subset of nodes concurrently or when distributed sessions are trying to obtain 
a lock to perform a QoS shrinking or preemption operation (Huang et aI., 1996). To resolve 
potentiallivelocks, we employ a scheduling retry scheme called Criticality-Based Back-Off 
(Huang et aI., 1996). Under this scheme, an aborted session will make an execution request 
again after a waiting time based on its criticality level. 
In summary, Table 4-1 lists all the routines used by the ripple scheduling protocol. We 
further discuss the software implementation of the protocol in the next section. 
5. System Prototyping and Lessons Learned 
We have implemented a preliminary prototype of GRMS at Honeywell Technology Center. 
Programmed in C++, the prototype runs on Sun SPARC jSolaris 2.5 stations equipped with 
Parallax Video (JPEG) cards and interconnected by a local ATM switch (FORE ASX-200). 
Following the GRMS architecture shown in Figure 3-1 and the ripple scheduling protocol 
discussed in Section 4, we describe the GRMS implementation and our lessons learned 
below. 
5.1. 
Session State and Transitions 
A distributed session is the unit of GRMS resource negotiation, allocation, and scheduling. 
Each subsession running on an individual computing node is associated with a set of states: 
WAIT, MODECHANGE, EXECUTE, and PREEMPTED. The DSRM agent on each node 
executes sessions by manipulating the session states. Figure 5-1 shows the session state 
diagram. 
A (sub)session is always in one of the four states: 
• 
WAIT-when a session arrives at the system waiting for execution or voluntarily stops 
its own execution. 
74 

ON DEVELOPING D1STRIBUTED MlDDLEWARE SERVICES 
Stop 
Register 
Register 
Waiting (sub)sessions 
Preemp/Real, 
AdmltOtherslExpandQoS 
Figure 5-1. Session state and transition. 
Slop 
Suspend 
201 
C970323-01 
• 
MODECHANGE-when a session makes a QoS request resulting in execution of the 
ripple scheduling protocol. 
• 
EXECUTE-when a session executes. As discussed previously, a session is a higher-
level abstraction compared to traditional operating system tasks. Therefore, in the 
EXECUTE state, the individual tasks of a session, such as threads, may be temporarily 
suspended by the CPU scheduler in the underlying operating system, which is trans-
parent to the "session scheduler"-the DSRM agent. 
• 
PREEMPTED-when a session is preempted by a higher-criticality session. 
The GRMS agent maintains a session list of all the subsessions currently in each state. 
The directed arcs in the state diagram represent state transitions. Each transition arc is 
labeled by the notation R Event 
, where Event indicates the cause of a transition and Response 
esponse 
represents the action(s) taken during the transition. 
75 

202 
HUANG, WANG AND CAO 
Register(Program) 
ChangeMode(Program, Block. QoS, ... ) 
Block-Based 
. 
Programming Model ----.-....... -.. __ ~~e"'c<le.!iP.!'!.~!!.m.l 
--
( Program· Session )..--:::; 
~gramMana~ ) 
•• ----... Distributed program management, 
Translator 
QoS propagation 
-
1 
ReglSter(Session) 
Session Mode~ ___ ..... ,..______ 
.. ~;;~~;;~;~~;(;;o~~ 
G DSRM Age:;;-' •• ____ + Two·phase resource 
_ 
~ 
-"" 
• negotiation protocol 
/ 
"-
" 
Register(ChanneIList) 
Task Model 
Two-phase protocol 
nere~isterrr:hanne1J .is!) 
.--~-.- ... 
~ 
Network Agent ) 
~ 
____ Resource Model 
Gmesour;:> 
Commercial (Real· Time) Operating System 
Figure 5-2. Software structures. 
5.2. 
Software Structures 
The GRMS software design follows an object-oriented methodology and layered abstrac-
tions. Figure 5-2 illustrates part of the GRMS software; here, the circles represent object 
instances, arrows show method invocations on the objects, and dotted lines indicate models 
used by the underlying objects. 
Program manager-Serving as an interface between applications and the DSRM agent on 
each computing node, this component provides run-time services for instantiating and exe-
cuting distributed application programs. Applications are programmed using a block-based 
application programming model (Huang et aI., 1997b), which enables quick construction 
of applications by interconnecting application function blocks with stream flow pipelines. 
With this programming model, each application is expressed by a directed graph where 
vertices represent function blocks and edges are data flows. 
Program-Session Translator-This component performs on-line mapping of applica-
tion programs to GRMS sessions. It is invoked by the program manager upon a Regis-
ter() call by an application. As described earlier, a (sub)session consists of system en-
tities such as threads and buffers that execute their corresponding applications on com-
puting nodes (Huang et aI., 1994). The session model is implemented with a graph 
76 

ON DEVELOPING DISTRIBUTED MIDDLEWARE SERVICES 
203 
structure where vertices represent the set of system entities and directed edges are data 
flows. 
QoS library-A number of QoS mapping functions have been implemented for bidirec-
tional QoS translations between applications and sessions. For example, a QoS parameter 
of session threads is a thread execution period. It is a function of JPEG stream Cumulative 
Lost Factor (CLF) and stream rate (Huang et aI., 1998). Hence, the library provides a 
translation function: thread period = (CLF + 1) / rate. This function is invoked when 
the program manager receives a ChangeModeO call from an application to translate the 
application's rate and CLF settings to the thread period. The QoS library also provides a 
QoS adjustment function for the purpose of consolidating QoS values selected by individual 
resource agents during the first phase of QoS negotiation. 
DSRM agent-Invoked by either the program manager or a peer DSRM agent at a remote 
node. When Register() is invoked by the program manager, it creates a (sub)session entry 
and further decomposes the subsession to resource-specific tasks, such as a list of threads 
for the local CPU agent and a list of communication channels for the network agent. 
Then it invokes Register() on its individual resource agents to register the tasks. When 
ChangeMode() is invoked, the DSRM agent generates a scheduling spanning tree (if the 
tree does not exist) and carries out the ripple scheduling described in Section 4. 
Individual resource agents-The CPU scheduler agent simply employs Rate Monotonic 
Analysis (Liu et aI., 1973) for thread scheduling (Huang et aI., 1997b). The display agent 
counts and allocates the Parallax Video resource for concurrent JPEG data streams. The 
network agent currently implements two network access paths-ATM AAL5 and TCP /IP-
with the programming interface in compliance with the agent service APIs specified in 
Section 4. The network resource negotiation service can be implemented in several ways. 
One is to use the RSVP, as described in Appendix A. Another is to interface the NetEx, 
a transport-level real-time ATM scheduler developed by Texas A&M University (Devalla 
et aI., 1997; Feng et aI., 1996; Raha et al., 1996), which is an ongoing research effort 
reported by (Huang et aI., 1997c). 
Task and resource classes-Task is an abstraction general to all the resources and their 
agents. It represents a unit of resource management for a given resource agent and is 
implemented by a C++ template class. For example, a list of threads belonging to a 
subsession on a computing node is designated as a CPU task. As an atomic unit, all the 
threads of the task are scheduled together (Huang etal., 1994). As illustrated in Figure 5-3, a 
CPU scheduler manages a list of tasks for concurrent subsessions. Implemented by a C++ 
template class, Resource is another abstraction for modeling heterogeneous resources. As 
shown in Figure 5-4, we consider each resource as a bucket and the tasks as water, with 
each task filling a certain volume in the bucket. Furthermore, each bucket has a maximum 
resource bandwidth (e.g., 100% utilization in case of CPU) and a schedulable bandwidth 
determined by its agent (e.g., ~69% utilization in case of RMA-based CPU scheduling 
(Liu et aI., 1973)). Each bucket also uses variables-allocated bandwidth and reserved 
bandwidth-to capture resource usage of tasks in the EXECUTE and MODECHANGE 
states, respectively. Figure 5-4 also shows the set of methods the resource class provides to 
resource agents for resource reservation and allocation. As can be seen in Figures 5-3 and 5-
4, the task and resource classes are closely related and are used by individual resource agents. 
77 

204 
HUANG, WANG AND CAO 
CPU [ask list 
~ 
.( hread list Of (Sub)Sr Ion x 
T 'kx 
c::3--+~ 
~~Db}O'iO"i 
Figure 5-3. Tasks managed by a CPU agenl. 
-1 
Maximum bandwicih 
-I 
chcdJlablc 
band\\~dl.h 
1 
Figure 5-4. Resource class and its methods. 
5.3. 
Run-Time Mechanism 
~ 
elCopocity. GnCapllciryl) 
GetAllocated() 
Rnerve() 
Feos;bjlityTesl() 
COIrIJlU'tO 
Aborl() 
GRMS is multithreaded within a process address space on each computing node. Each node 
runs a binary image of the resource agents. Specifically, each DSRM agent is associated with 
a demon thread. As shown in Figure 5-5, this DSRM thread serves both local application 
requests and remote peer requests. A user thread is responsible for application execution. 
Upon a ModeChange() request, the user thread executes the DSRM code locally and the 
DSRM thread carries out the distributed ripple scheduling protocol by communicating with 
its peer thread(s) at the remote node(s). As a peer DSRM, the thread listens to a control 
channel separated from data channels. It receives the DSRM messages from the control 
channel and invokes DSRM methods according to the DSRM message types. 
78 

ON DEVELOPING DISTRmUTED MIDDLEWARE SERVICES 
205 
External 
External 
Control Channel 
Figure 5-5. DSRM run-time mechanism. 
Table 5-1. Lock compatibility matrix. 
session Si 
MODE_CHANGE 
EXECUTE 
ShrinkQoSV(Sj) 
PreemptV(Sj) 
MODE_ 
~hrinkQoSV(Si) 
not allowed 
not allowed 
lock entire Si 
session Sj 
CHANGE 
PreemptV(Si) 
not allowed 
not allowed 
lock entire Si 
EXECU1E 
lock entire Sj 
lock entire Sj 
no conflict 
5.4. 
Locking Mechanism 
As discussed in Section 4, a locking approach is employed to prevent potential race condi-
tions due to decentralized session QoS adjustment and preemption operations. The locking 
mechanism consists oftwo steps: (l) lock compatibility matrix checking, and (2) distributed 
atomic locking. 
Lock compatibility matrix-Table 5-1 shows the lock compatibility matrix, which de-
termines the conditions under which the QoS adjustment and preemption operations may 
conflict. Specifically, given two sessions Si and Sj: 
• 
ShrinkQoSVirtual() and PreemptVirtual() are not allowed to be applied from one session 
to the other if the two sessions are in their MODECHANGE state. 
• 
ShrinkQoSVirtual() or PreemptVirtual() must first request a lock on an entire session 
for QoS shrinking or session preemption operations if the session is already in its 
EXECUTE state. 
Distributed atomic locking-Once a lock request is issued, a distributed locking oper-
ation is performed on the basis of a session spanning tree. In the example illustrated in 
Figure 5-6, both sub sessions of sessions i and j need to execute on node X. In case of 
resource contention, the DSRM agent on node X decides to preempt session j to guarantee 
79 

206 
HUANG, WANG AND CAO 
Node Y 
[QJ 
Figure 5·6. Atomic locking of a session spanning tree. 
execution of session i. To do so, the DSRM sends a lock request to the remote DSRM agent 
on node Y where the coordinator of session j's spanning tree resides. It is this agent that 
sends a lock message to all the DSRM agents along session j's spanning tree to lock all the 
subsessions of session j. This distributed locking operation is atomic in the sense that either 
all or none of the subsessions of a session are locked. This atomicity property ensures the 
consistency of distributed locking operations. 
5.5. 
Lessons Learned 
Through GRMS prototyping, we have also seen certain limitations of the middleware imple-
mentation approach, some of which are due to the constraints of existing vendor products 
and some of which must be addressed to ensure the practical use of middleware-based 
resource management systems. Here are some examples: 
• 
Our implementation experience indicates that it is fairly hard to build a real-time CPU 
scheduler on top of the Solaris 2.5 operating system. One reason is due to the definition 
of the process priority classes, by which the priority of kernel processes is less than 
that of real-time processes. In this case, kernel processes could be blocked by real-
time application processes, which would be assigned with real-time priorities by the 
middleware CPU scheduler. Another reason is the separation of user threads from 
kernel lightweight processes (LPW). To apply real-time scheduling, the middleware 
CPU scheduler must manipulate LWPs instead of user threads. 
• 
It is also difficult to implement the QoS shrinking and expansion mechanisms over 
connection-oriented networks such as ATM. It is impractical to frequently establish 
and tear down data channel connections for dynamic QoS adjustment. Additional 
bandwidth multiplexing schemes need to be developed further. 
• 
Even more difficult is that many resource components such as Parallax JPEG Video, 
disk I/O controller, and X Window cannot be easily controlled by the middleware. It 
is a challenge to build real-time middleware schedulers (even soft real-time) for those 
components. 
80 

ON DEVELOPING DISTRIBUTED MIDDLEWARE SERVICES 
207 
• 
The most challenging problem is how to use a middleware-based resource management 
system in an open environment to support both time-critical and third-party applications 
(such as SpreadSheet). The issue is how to intercept and schedule the third-party 
applications without changing their software and their programming interfaces. This 
issue needs to be addressed if the middleware-based resource management is to be used 
in an open environment (other than embedded systems). 
6. 
Performance Evaluation 
We are conducting both experimentation and simulation to evaluate GRMS's run-time 
behaviors with respect to protocol execution efficiency, protocol scalability, locking impli-
cations, and tradeoffs between various protocol policies. In the following two subsections, 
we present our performance evaluation results obtained from our prototype and simulation 
testbed, respectively. 
6.1. 
Experimentation 
6.1.1. 
Experiment Setup 
Our set of experiment parameters is summarized in Table 6-1. With respect to ripple schedul-
ing, we considered three variations: no criticality-based preemption service, criticality-
based preemption service using an asynchronous preemption protocol, and criticality-based 
preemption service using a synchronous preemption protocol. For the network service 
used by the ripple scheduling protocol, we exercised two network protocols over the ATM 
switch: TCP and ATM AAL5. We ran continuous multimedia applications that captured, 
transferred, and displayed JPEG video frames, at the rate of 30 fps, across the SPARC 
stations along their scheduling spanning trees. To examine the effect of network load on 
ripple scheduling, we introduced "Net Load," which uses ttcp to periodically inject traffic 
from pairs of SPARC stations to the ATM network. Finally, we used "depth of spanning 
trees" to specify the size of individual spanning trees. In the experiments presented below, 
we considered only linear spanning trees, where no DSRM agent had more than one child 
DSRM agent. Further, considering typical stream applications in practice, which are less 
likely to run across more than four processing nodes, we specified the depth of spanning 
trees with no more than three. 
The primary performance metric is "ripple scheduling time," which is the time, measured 
in milliseconds, between the beginning of the ripple scheduling protocol triggered by an 
application's ChangeMode() call and the end of the protocol. 
The performance measurement was done using the Sun TNF tool. Our data collection 
is based on the method of replication: for each experiment setting, we made a number 
of experiment runs and collected experiment data in terms of average, maximum, and 
minimum values. Presented below are only the average values. 
81 

208 
HUANG, WANG AND CAO 
Table 6-1. Protocol, workload, and system settings for the experimentation. 
Parameter 
Ripple scheduling protocol 
"No Preempt" 
"Asynch Preempt" 
"Synch Preempt" 
Network protocol 
TCPjATM 
ATMAAL5 
Application streams 
Stream rate 
Net Load 
None 
40Mbps 
Depth of linear spanning tree 
Meaning 
Two-phase protocol with no criticality-based preemption 
Two-phase protocol with criticality-based, asynchronous preemption 
Two-phase protocol with criticality-based, synchronous preemption 
TCP protocol over ATM 
ATM direct access through AAL5 protocol 
Setting 
Variable 
Variable 
Total number of JPEG streams in the system 
Variable 
Data rate for each stream (unit: frames per sec) 
30 
Network load generated by ttcp (unit: Mbits per sec.) 
Variable 
No load 
40 Mbps load with 12 Kbytes per ttcp packet 
Number of SPARC stations along the spanning tree, minus one 
[I, 3] 
-tIl-
..§.. 80 
CI) 
" • -¢> • "TCP/ATM 
E 
i= 60 
-0-- ATM AAL5 
CSI 
.5 
'3 40 
" 
CI) 
J: 20 
u 
UI 
CI) 
Q. 0 
Co a: 
0 
2 
3 
Depth of Scheduling Spanning Trees 
Figure 6-1. Effect of network protocols (no preemption, no network load). 
6.1.2. 
Experiment Results 
Effect of network communication protocols-We first examined the possible impact of 
different network services on ripple scheduling execution time. Figure 6-1 plots the mea-
sured ripple scheduling times, under TCP / ATM and ATM AAL5 protocols, respectively, 
for linear spanning trees with different depths. The other parameter variables are set as "no 
preemption" for the ripple scheduling protocol and "no network load" for Net Load. The 
magnitude of the scheduling time is around 20 ms. As expected, the TCP incurred a longer 
ripple scheduling time than direct ATM access through AAL5. However, this performance 
difference was not significant when the spanning tree depth was one, and it became smaller 
as the tree depth increased. A number of conditions may have produced this effect. First, 
the ripple scheduling messages are small, each less than 48 bytes, which allows them to fit 
into the ATM cell. With such a small message size, there was little overhead from TCP's 
82 

ON DEVELOPING DISTRffiUTED MIDDLEWARE SERVICES 
209 
'ii' 80 
e 
---<>- -- Net Load: None 
..... 
CI) e 60 
-i:r- Net Load: 40 tv'bps 
j:: 
en 
.5 40 
'S i .c 
u 20 
CJ) 
CI) ii 
Co 
0 
a: 
0 
2 
3 
Depth of Scheduling Spanning Trees 
Figure 6-2. Effect of network load (no preemption, ATM AAL5). 
flow control and congestion control. Thus, the overhead was mainly from the protocol 
execution on individual nodes-the "end system." Second, we observed during the experi-
ment that the end system was not CPU-bound, with node CPU utilization being around 3%. 
Hence, the CPU load was not a factor in the TCP execution time. Third, as the number of 
computing nodes increased, the message round-trip latency became a dominant factor over 
the protocol execution overhead. Therefore. different network protocols such as TCPI ATM 
and ATM AAL5 do not have significant impact on the ripple scheduling time. 
Effect of network load-Next, we examined how network load may have an impact on 
ripple scheduling performance. We conducted this experiment with the ATM AAL5 service 
and without criticality-based preemption. Figure 6-2 shows the performance of the ripple 
scheduling protocol under two Net Load settings, one with no network load and the other 
with a 40 Mbps sustained network load injected from each of the four SPARC stations. 
When the spanning tree depth is doubled from two to four, the scheduling time is increased 
by only 25% with the 40 Mbps load. Based on earlier performance studies conducted on 
the Mercuri testbed (Guha et al., 1995a), the 40 Mbps load (with 12-KByte packet size) is 
relatively high, nearly saturating the network interface at the individual nodes. Therefore, 
for scheduling spanning trees with a relatively small depth, the ripple scheduling performs 
well under high network load. 
Overhead of distributed stream preemption-Last, we observed the performance of 
the distributed session preemption involved in the ripple scheduling. As presented in 
Figure 6-3, we compared three cases: ripple scheduling with no preemption, preemption 
using an asynchronous protocol, and preemption using a synchronous protocol. As ex-
plained in Section 4, the difference between the synchronous and asynchronous preemption 
protocols is that under the former, a (nonleaf node) DSRM agent waits for confirmation 
of successful stream preemption from its child DSRM agents, whereas under the latter it 
does not. The experiment data indicate that the synchronous preemption protocol incurs an 
overhead much more significant than does the asynchronous protocol, as compared to the 
basic two-phase negotiation protocol, which executes neither of the preemption protocols. 
83 

210 
HUANG, WANG AND CAO 
'iil 80 
.§. 
CII 
E 60 
j:: 
D) 
&_---6- ... 
r 
............. .....,A, 
---<>- -. No R"eerrpt 
.5 40 
:; 
'C 
CII 
--0- Asynch R"eerrpt 
- -l:r- - Synch R"eerrpt 
.c 
(.) 20 
(J) 
CII a 
c.. 
0 
a: 
0 
2 
3 
Depth of Scheduling Spanning Trees 
Figure 6-3. Overhead of distributed stream preemption (ATM AALS, no network load). 
Clearly, the protocol execution's efficiency and the reliability of distributed session pre-
emption will lead to the development of hybrid preemption protocols with lower execution 
overhead. 
6.2. 
Simulation 
The experiment data collected from the prototype provide us with first-hand information 
about the GRMS's performance in a real system setting. However, the experimentation 
scope is limited, since many parameter settings such as the number of computing nodes 
and the number of concurrent data streams cannot be varied easily, due to platform or 
environment constraints. Therefore, we have also developed a simulation testbed with 
flexible parameter turning capabilities to provide better insight into the GRMS's run-time 
behavior. 
6.2.1. 
Simulation Model 
We used the Ptolemy simulation tool developed at the University of California at Berkeley. 
Based on Ptolemy, our simulation model consists of three major modules, as illustrated in 
Figure 6-4: 
• 
Workstation module-Contains three components: Workload Generator, DSRM, and 
Local System Resource Management (LSRM). The workload generator simulates ap-
plications at the session level and generates session trees rooted in the local station. 
The arrival rate of new sessions follows Poisson distribution, which is widely used in 
distributed systems. The DSRM component simulates the actual DSRM behavior. It 
receives the workload from the workload generator and the network interface, passes the 
session to the LSRM, checks the QoS, and serves as an agent in the ripple scheduling. 
84 

ON DEVELOPING DISTRIBUTED MIDDLEWARE SERVICES 
211 
Workstations 
Network 
I" 
I " , 
"" 
I \\'orkload (i('nerahlr J 
Figure 6-4. The simulation model. 
The LSRM models the local resource agents, keeps track of local resource utilization, 
and performs local resource negotiation and allocation. 
• 
Network module-The connections of all the workstations in the distributed system 
follow certain topologies. In our study, we assume that they are fully connected. That 
means the sender station can find a path to its receiver station. The network module in 
our simulation is responsible for establishing network connections and determining the 
delay along the connection paths. 
• 
Data collection module-Collects performance data such as time spent by the two-phase 
protocol from the workstation module and the network module. 
6.2.2. 
Simulation Setup 
Table 6-2 shows the protocol, workload, and system parameters and their settings used by 
our simulation study. In addition to the parameters used in the experimentation, we also 
introduced to the simulation the parameters of session arrival time interval, session duration, 
network delay, and number of computing nodes. The parameter value settings are such that 
they are close to those in real systems or can be scaled up to reflect real applications. 
We defined a number of performance metrics to measure how well the GRMS met its 
goals and what the GMRS's internal behaviors were. These metries are: 
. 
. 
Number of executed sessions at criticality level i 
ExecutIOn success ratIO = ------------------
Number of requesting sessions at criticality level i 
Lo k· 
. 
Number of granted locks 
c mg success ratIO = ---------
Number of lock requests 
Preemption success ratio 
Number of completed preemptions 
Number of preemption requests 
Number of Preempt Real() calls 
Number of Preempt Virtual() calls 
85 

212 
HUANG, WANG AND CAO 
Table 6-2. Protocol, workload, and system settings for the simulation. 
Parameter 
Ripple scheduling protocol 
"No Preempt" 
"Preempt" 
Arrival time interval (ATI) 
Session duration 
Depth of linear spanning tree 
Frame rate 
QoSmin 
Criticality 
Link delay 
Nodes 
Meaning 
Two-phase protocol with no criticality-based preemption 
Two-phase protocol with criticality-based, asynchronous preemption 
Session arrival time interval (sec) 
Execution time of application session (sec) [min, max] 
Number of computing nodes along the spanning tree, minus one 
Number of frames per second (fps) 
Minimum QoS in terms of minimum frame rate 
Criticality levels of essential applications 
Network delay between two nodes (ms) 
Number of computing nodes 
Setting 
Variable 
[0.5, 1] 
[1, 10] 
[1,3] 
[5,40] fps 
5 fps 
3 
[3,3] 
8 
QoS shrinking success ratio 
Number of completed QoS shrinking requests 
Total number of QoS shrinking requests 
Numbe r of QoS ShrinkReal( )calls 
Number of QoS Shrink Virtual( )calls 
6.2.3. 
Validation of the Simulation Model 
We validated the simulation model before using it for performance evaluation. Our approach 
was to compare the initial simulation output data with the data we collected from the 
prototype experimentation and to fine-tune parts of the simulation model, such as the 
network link delay parameter and CPU overhead parameter, to make its characteristics 
close to that of the prototype. 
Figure 6-5 shows a result of the model validation with the measurement of the ripple 
scheduling time. This figure is fairly similar to Figure 6-3, which was derived from the 
prototype experimentation. In general, our validation indicates that the simulation model 
behaves correctly. 
6.2.4. 
Simulation Results 
Effectiveness of the preemption-We first examined the effectiveness of the distributed 
session preemption using the metric of Execution Success Ratio. Figure 6-6(a) depicts the 
performance of three groups of concurrent sessions with high, medium, and low criticality. 1 
Clearly, high-criticality sessions reach a 100% execution success ratio, whereas medium-
and low-criticality sessions have success ratios of 80% and 55%, respectively, when their 
spanning tree depth is three. As we increase the workload by reducing the session arrival 
time interval (ATI), as shown in Figure 6-6(b), the execution success ratio of all three groups 
drops, yet the high-criticality sessions perform better than the medium-criticality sessions, 
86 

ON DEVELOPING DISTRIBUTED MIDDLEWARE SERVICES 
213 
UI 80 
E 
..... 
41 
~60 
en 
.5 
:; 40 
11 
.s::. 
a1 20 
41 
Q. 
a. 
-+-No Preempt 
-II-Asynch Preempt 
i:E 
0 F;....-.---+----I-----1 
o 
2 
3 
Depth of Scheduling Spanning Tree 
Figure 6-5. Overhead of ripple scheduling protocol. 
.2 
"IV 0.8 
II: 
'" .. § 0.6 
::> 
I/) 
t: 0.4 
.2 
-+- a-nicality H 
"S " 0.2 
.. 
--.~-. a-nical~y M 
.. 
w 
- .. ··a-mcaIityL 
0 
2 
3 
Depth of SCheduling Spanning Tree 
(a) ATI = 1 
.2 
T-------__ -+ __________ ~ 
"IV 0.8+ 
II: i 
. 
" 0.6 
" 
~ 
g 0.4 
g 
~ 02 
o+----------+--------~ 
1 
2 
3 
Depth of Scheduling Spanning Tree 
(b) ATI = 0.5 
Figure 6-6. Preemption effectiveness. (a) AT! = l. (b) AT! = 0.5. 
which in tum perform better than the low-criticality sessions. Therefore, the distributed 
preemption function embedded in the ripple scheduling protocol is effective in terms of 
supporting mission-critical applications with different levels of criticality. In addition, 
the ripple scheduling protocol is scalable in the sense that the application performance 
degrades in a linear and moderate manner as the depth of the scheduling spanning tree 
increases. 
Behavior of the locking operation-As discussed in Sections 4 and 5, we adopt a 
locking-based concurrency control scheme for preventing the race conditions in distributed 
session QoS adjustment and preemption operations. An issue commonly raised regarding a 
locking scheme is its potential for blocking other lock requesting sessions and thus degrading 
application performance. Our hypothesis is that the locking scheme may work well in 
87 

214 
1 C" 
.Q 0,8 
1ii 
Ie 
III 0,6 
rl 
!,) 
0 
:::I 0-4 
I/) 
.:.: 
!,) 
0 -' 0,2 
0 
HUANG, WANG AND CAO 
2 
-+-ATI:1.0 
'''.'ATI=0.5 
Depth of Scheduling Spanning Tree 
3 
Figure 6-7. Distributed locking behavior. 
the context of ripple scheduling, since, compared with distributed database systems, for 
example, the objects of locking are session spanning tree nodes, not data records, and the 
number of such objects is limited. With this hypothesis in mind, we conducted simulation 
to see the behavior of the distributed locking operation in terms of lock success ratio. As 
shown in Figure 6-7, the measured lock success ratio is nearly 100%, which means that 
there is almost no blocking. Note that from Figure 6-6 we know that the system is loaded 
by concurrent sessions, especially when AT! = 0.5. These observations lead us to conclude 
that the use of locking in ripple scheduling incurs little blocking and therefore the locking 
approach is feasible. 
Behavior of the two-phase preemption mechanism-Following the two-phase ripple 
scheduling protocol, a distributed preemption is carried out in two phases-Preempt Virtual( ) 
in the TestAndHold phase and PreemptReal() or PreemptRevoked() in the Commit/Abort 
phase. Figure 6-8 plots the preemption success ratio, the ratio of PreemptReal() operations 
to PreemptVirtual(j operations. The preemption success ratio is insensitive to the depth 
of session spanning trees but is subject to the workload change, specifically, the session 
arrival time interval. The preemption success ratio is above 95% when AT! = 1 and drops 
to "-'85% when AT! = 0.5. This is because the higher the workload, the higher the resource 
contention, which leads to more distributed QoS adjustment and preemption operations and 
a higher chance for a virtual preemption operation to be aborted. 
Protocol overhead-Figure 6-9 shows the overhead of executing the ripple scheduling 
protocol. The overhead includes protocol message propagation delays and the time spent 
on preemption operation, distributed locking, and executing local resource agents. As ex-
pected, the ripple scheduling time increases as the session spanning tree depth increases. 
An interesting observation is that the ripple scheduling takes longer for sessions with higher 
criticality, which is an undesired behavior for criticality-based system services. This behav-
ior is due to the additional preemption operations that the ripple scheduling protocol needs 
88 

ON DEVELOPING DISTRmUTED MIDDLEWARE SERVICES 
o:f 
• 
.2 
1;i 
IX: 
III 
III 
QI 
O.B 
u 
IJ 
:::I 
CII c 0.7 
0 
-+-ATI=1 
.. 
--•. 
~ ATI=0.5 
0-
E 
~ 0.6 
0-
0.5 
Figure 6·8. Preemption behavior. 
100 
I 80 
CII e 
i= 
C'I 
60 
.~ 
:; 
'i 
.e 
40 
IJ 
CII 
GI 
2: 20 
it: 
2 
Depth of Scheduling Spanning Tree 
-+- Criticality H 
•• .Jm--Criticality M 
w~-'Criticality L 
O+------------r----------~ 
2 
3 
Depth of Scheduling Spanning Tree 
Figure 6-9. Ripple scheduling overhead. 
215 
• 
3 
to perform for higher-criticality sessions. Clearly, this is a tradeoff between the availability 
of distributed criticality support service and the cost of the service. Note that the application 
execution time is generally much longer than the ripple scheduling time, which is less than 
100 ms when session spanning tree depth = 3 and AT! = 1.0. 
Effectiveness of the QoS shrinking-As described in Section 4, the purpose of doing 
on-line QoS shrinking is to maximize the number of concurrent sessions. Figure 6-10 
shows the execution success ratio of distributed sessions served with the distributed QoS 
89 

216 
~ 0,8 j 0.6 
c: 0.4 
~ 
~ 0,2 
w 
-+- Crfficality H 
iii 
Crfficalily M 
---h"'- Criticarlly L 
o+----------+--------~ 
2 
3 
Depth of Scheduling Spanning Tree 
(al ATI = 1 
.2 
'iii 0,8 
a: .. .. 8 0,6 
~ 
6 0.4 
S 
g 
III 0.2 
HUANG, WANG AND CAD 
-+-C'ilicalily H 
''''1iI-- Criticality M 
-::ir-- Crilicali~1 L 
o+----------+--------~ 
2 
3 
Depth of Scheduling Spanning Tree 
(b) ATI=O.5 
Figure 6-10. Effectiveness ofQoS shrinking. (a) ATI = I. (b) AT! = 0.5. 
shrinking function. To see the effectiveness of the QoS shrinking operation, let us compare 
Figure 6-10 with Figure 6-6, which shows the session performance obtained from the same 
simulation parameter settings, but with the QoS shrinking service disabled. As can be 
seen, the QoS shrinking service improves the performance of all the criticality groups. 
Specifically, with a QoS shrinking factor distributed between 0% and 85% and AT! set 
at 0.5, the execution success ratio of depth-3 sessions increases from 0.78 to 1.0 for the 
high-criticality group, from 0.39 to 0.98 for the medium-criticality group, and from 0.29 to 
0.67 for the low-criticality group. 
7. Related Work 
In general, we view the QoS-based resource management problem as an issue of imprecise 
computation that has been extensively studied in the area of real-time computing (Liu et aI., 
1991). The key is to adapt application execution by QoS with the resource capacity con-
straints. In recent years, in the context of continuous multimedia applications, substantial 
effort has been made to develop QoS-based resource management components and systems 
(Huang, 1995). For example, H. Tokuda and T. Kitayama developed a QoS-based admission 
control end system that allows on-line resource negotiation in terms of spatial and tempo-
ral constraints of media data (Tokuda et al., 1993). Dynamic QoS-based CPU scheduling 
was also reported recently in, for example, (Kaneko et al., 1996; Lee et aI., 1996). At 
Honeywell, we proto typed a multiresource management end system for providing QoS-
and criticality-based resource negotiation and adaptation services (Huang et al., 1998) and 
a dynamic processor allocation and adaptation system for embedded parallel applications 
(Jha et aI., 1996). 
Much less progress has been made in addressing the end-to-end QoS support over het-
erogeneous platforms and networks. RSVP (Zhang et al., 1993) tends to address the issue 
from the network perspective. Its ability to manage computing node resources such as 
90 

ON DEVELOPING DISTRIBUTED MIDDLEWARE SERVICES 
217 
CPU, memory, and I/O devices needs to be further investigated. An interesting work is 
from Chatterjee and Strosnider (1995), who developed a heterogeneous resource manage-
ment framework for providing timing guarantees to distributed multimedia applications. 
Their work focuses mainly on mapping and allocation of coarse-level resources such as 
computing platforms with no consideration of on-line QoS negotiation and adaptation. 
Our work presented in this paper applies the distributed transaction processing concept 
(Berstein et aI., 1987) to distributed, adaptive resource management. To our knowledge, no 
one else has investigated such an approach in the context of mission-critical applications as 
characterized in Section 1. 
Regarding approaches to system architecture design, there are three general schemes 
(Huang, 1995). The first is to develop or extend operating systems with QoS negotiation 
and adaptation capabilities. An example is the Chorus extension prototyped at Lancaster 
University (Coulson et aI., 1994). The second is to develop an "extra layer" underneath 
possibly multiple operating systems to support QoS services. This scheme is exemplified 
by the "real-time virtual machine" developed at University of North Carolina (Bollella 
et aI., 1995). The third scheme, often called the "middleware approach," is to build a 
QoS management system on top of existing operating systems and network protocols. 
Examples include a Video-on-Demand resource management system prototyped at DEC 
(Ramakrishnan et aI., 1995), the HeiMOS system prototyped at IBM (Mauthe et aI., 1992), 
and the Presto system prototyped at Honeywell (Huang et aI., 1997b). With the goals of 
achieving software portability, evolvability, and open system design, our GRMS architecture 
is based on the third scheme. 
8. 
Conclusions 
GRMS is a middleware-based global resource management system being developed to 
support end-to-end QoS negotiation and adaptation for mission-critical applications. We 
presented our four design principles and introduced two key concepts of GRMS: a re-
source agent model that unifies heterogeneous resource management components and a 
ripple scheduling approach accompanied by dynamic, distributed QoS adjustment (QoS 
shrinking and expansion) and criticality-based preemption functions. We further detailed 
the two-phase negotiation and adaptation protocol and discussed its implications and our 
solutions. We also described the system software design and implementation. The results of 
our performance evaluation, obtained from the prototype experimentation and simulation, 
indicate that (I) the GRMS ripple scheduling is reasonably efficient; (2) the distributed 
QoS shrinking and criticality-based preemption schemes are feasible and effective; (3) the 
locking approach is suitable for distributed resource management; (4) the GRMS perfor-
mance, in terms of execution success ratio, QoS shrinking and preemption effectiveness, 
and run-time overhead, is scalable with respect to the depth of linear session spanning trees; 
(5) different network access protocols, namely, TCP over ATM and ATM AAL5, have little 
impact on the performance of GRMS ripple scheduling; and (6) network load does not 
have significant impact on protocol performance. Through GRMS prototyping, we have 
also learned lessons and gained insights into development of middleware-based resource 
management services. 
91 

218 
HUANG, WANG AND CAO 
GRMS is unique in several ways. First, it provides end-to-end QoS negotiation and adap-
tation services across multiple computing nodes as well as networks, unlike many existing 
resource management systems that merely deal with either local resources or network seg-
ments. Second, the end-to-end QoS negotiation and adaptation services are provided in the 
forms of dynamic QoS shrinking and expansion, enabling distributed applications to adapt 
to available resources with the highest possible QoS. Third, it supports criticality-based 
distributed stream preemption; thus, it is especially useful to mission-critical applications. 
Fourth, it uses a unified resource model, enabling the use and interoperation of hetero-
geneous resource management algorithms/protocols. Finally, it employs a decentralized 
ripple scheduling protocol to support scalability and reliability of distributed resource man-
agement. 
Acknowledgments 
The authors would like to thank the Rome Lab Presto and DARPA HPNS program teams 
for their work on enhancement of the Mercuri testbed, on which the GRMS prototype is in 
part based. Special thanks to N. R. Vaidyanathan for his work on collecting and analyzing 
the experiment data. 
Appendix A. Interfacing GRMS with RSVP 
Each DSRM agent interacts with its local Network Resource Manager (NRM) agent to 
reserve the network bandwidth. There have been a number of studies on network resource 
reservation and scheduling protocols, such as RSVP (Chatterjee et aI., 1995), ST-II (Zhang 
et aI., 1993), and NetEx (Huang et aI., 1996). We use an adapter approach to interface DSRM 
with other existing network resource reservation protocols. For each network reservation 
protocol, there is a special adapter. As an example, we describe the RSVP adapter that 
interfaces with the RSVP protocol. 
RSVP is a receiver-oriented protocol in which the receiver initiates the reservation pro-
tocol. However, the control flow direction in GRMS is determined by the location of the 
coordinator node in the scheduling spanning tree and can be either the same as or different 
from the data flow direction of the application. Thus, we nced to adapt both situations to 
the RSVP protocol. If the control flow is different from the data flow (i.e., in the scheduling 
spanning tree, the parent is the data receiver), RSVP fits the ripple scheduling protocol, 
since we can issue the RSVP reservation message from the parent. However, if the con-
trol flow direction is the same as that of the data flow (i.e., the child is the data receiver), 
the RSVP reservation protocol should be initiated by the child node. This is carried out 
by delaying the parent node's network reservation until the child replies in the first phase 
of the ripple scheduling. Detailed message flows for these two cases are described as 
follows. 
92 

ON DEVELOPING DISTRIBUTED MIDDLEWARE SERVICES 
219 
Control Flow 
Control Flow 
.... _--_ ...... _._ ... _ ....... __ ..... _ 
.. _-- .... -~ 
Data Flow 
Figure A-i. GRMS-RSVP protocol: Same control and data flow directions. 
y 
Control Flow 
DSRMT 
i_ 
Adapter I 
Control Flow 
AdapterT 
(RSVP S) 
(RSVP R) 
.............. __ .. _ .. -._ .............................. ----_ .... . 
DataFlow 
Figure A-2. GRMS-RSVP protocol: Different control and data flow directions. 
Case 1: The DSRM Control and Application Data Flow Directions are the Same 
1. DSRM I -+ Adapted: NRM_TestAndHold 
2. Adapter I: rapLsender 
3. Adapter I -+ Adapter T: NRM.Jl1sg(reserve) 
4. Adapter T: rapi.Ieserve 
5. Adapter T -+ Adapter I: status of NRM.Jl1sg(reserve)" = OK/NoLOK 
6. Adapter I -+ DSRM I: Yes/No 
Case 2: The DSRM Control and Application Data Flow Directions are Different 
1. DSRM I -+ Adapted: NRM_TestAndHold 
2. Adapter I -+ Adapter T: NRM.Jl1sg(send) 
3. Adapter T: rapLsender 
93 

220 
HUANG, WANG AND CAO 
4. Adapter T -+ Adapter I: status of NRMJIlsg(send)" = OK 
5. Adapter I: rapLreserve 
6. Adapter I -+ DSRM I: Yes/No 
Notes 
1. Note that, based on the application criticality characterization discussed in Section 2, our performance study 
considers only the class of essential applications that are scheduled and can be dynamically preempted. Critical 
applications can be guaranteed with their minimum QoS using static resource allocation (Stankovic et al., 1988). 
References 
Berstein, P. A., Hadzilacos, V., and Goodman, N. 1987. Concurrency Control and Recovery in Database Systems. 
Reading, Massachusetts: Addison-Wesley Publishing Company. 
Bollella, G., and Jeffay, K. 1995. Support for real-time computing within general purpose operating systems: 
Supporting co-resident operating systems. Proceedings of the IEEE Real-Time Technology and Application 
Symposium. Chicago. 
ChatteIjee, S., and Strosnider, J. 1995. A generalized admission control strategy for heterogeneous, distributed 
multimedia systems. Proceedings of the Third ACM International Multimedia Conference. San Fransisco. 
Coulson, G., Blair, G. S., and Robin, P. 1994. Micro-kernel support for continuous media in distributed systems. 
Computer Networks and ISDN Systems (26). 
Delgrossi, L., and Berger, L. (Editors). 1995. Internet stream protocol Version 2 (ST2+). Network Working Group 
RFC 1819. 
Devalla, B., Li, C., Sahoo, A., and Zhao, W. 1997. Connection-oriented real-time communication for mission 
critical applications. Proc. of IEEE National Aerospace and Electronics Conference. 
Feng, E, Li, C., Raha, A., Yu, S., and Zhao, W. 1996. Modeling and regulation of host traffic in ATM networks 
for hard real-time application. Proc. of the IEEE Conference on Local Computer Networks. 
Guha, A., Pavan, A., Liu, J., Rastogi, A., and Steeves, T. 1995a. Supporting real-time and multimedia applications 
on the Mercuri testbed. IEEE Journal on Selected Areas in Communications 13(4). 
Guha, A., Pavan, A., Liu, J. C. L., and Roberts, B. A. I 995b. Controlling the process with distributed multimedia. 
IEEE Multimedia. 
Huang, J., and Du, D.-Z. 1994. Resource management for continuous multimedia database applications. Pro-
ceedings of the 15th IEEE Real-Time Systems Symposium. Puerto Rico. 
Huang, J. 1995. Tutorial: Real-time scheduling technology for continuous multimedia applications. Lecture 
Notes of the 3rdACM Multimedia Conference. San Francisco. 
Huang, J., Wang, Y, and Kenchamana-Hosekote, D. 1996. Decentralized end-to-end scheduling for continuous 
multimedia. Proceedings of the 6th International Workshop on Network and Operating System Support for 
Digital Audio and Video. Japan. 
Huang, J., Wang, Y., Vaidyanathan, N. R., and Cao, E 1997a. GRMS: A global resource management system. 
Proceedings of the 4th IEEE International Conference on Multimedia Computing and Systems. Canada. 
Huang, J., Kenchamanna-Hosekote, D., Agrawal, M., and Richardson, J. 1997b. Presto-A system environment 
for mission-critical multimedia applications. Journal of Real-Time Systems. 
Huang, J., Jha, R., Heimerdinger, W., Muhammad, M., Lauzac, S., Kannikeswaran, B., Schwan, K., Zhao, w., 
and Bettati, R. 1997c. RT-ARM: A real-time adaptive resource management system for distributed mission-
critical applications. Proceedings of the IEEE Workshop on Middleware for Distributed Real-Time Systems and 
Services. 
Huang, J., Wan, P.-J., and Du, D.-Z. 1998. Criticality- and QoS-based multiresource negotiation and adaptation. 
Journal of Real-Time Systems 15(3). 
Hutchison, D., Coulson, G., Campbell, A., and Blair, G. S. 1995. Quality of service management in distributed 
systems, distributed systems management. Morris Sloman, editor, Imperial College London. 
94 

ON DEVELOPING DISTRIBUTED MIDDLEWARE SERVICES 
221 
International Standards Organization. 1996. Information technology-Quality of service-framework. DIS 
13236. ISO/IEC JTCI/SC21 NI0339. 
Jha. R., and Muhammad, M. 1996. Adaptive resource allocation for embedded parallel applications. Proceedings 
of the Third International Conference on High Performance Computing. 
Kaneko, H., Stankovic, J.A., Sen, S., and Ramamritham, K. 1996. Integrated scheduling of multimedia and 
hard-real-time tasks. Proceedings of the IEEE Real·Time Systems Symposium. 
Lee, c., Rajkumar, R., and Mercer, C. 1996. Experiences with processor reservation and dynamic QoS in real-time 
mach. Proceedings of Multimedia Japan 96. 
Liu, C.L., and Layland, J. W 1973. Scheduling algorithms for multiprogramming in a hard real-time environment. 
J. ACM 20(1). 
Liu., J. W. 5., Lin, K.-J., Shih, W-K., Yu, A. c., Chung, J.-Y., and Zhao, W 1991. Algorithms for scheduling 
imprecise computations. IEEE Computer. 
Mauthe, A., Schulz, W., and Steimetz, R. 1992. Inside the Heidelberg multimedia operating system support: 
Real-time processing of continuous media in OS/2. mM Technical Report 43.9214. 
Raha, R., Kamat, S., and Zhao, W. 1996. Admission control for hard real-time connections in ATM LAN. Proc. 
of IEEE International Conference on Computer Communications. 
Ramakrishnan, K. K, Vaitzblit, L., Gary, C., Vahalia, U., Ting, D., Tzelnic, P., Glaser, S., and Duso, W 1995. 
Operating system support for a video-on-demand file service. ACM Multimedia Systems (3). 
Robinson, S. R. (Ed.). 1993. Emerging Systems and Technologies. SPIE Optical Engineering Press. 
Stankovic, J., and Ramaritham, K. (Eds.). 1988. Tutorial: Hard-Real-TIme Systems. IEEE Computer Society 
Press. 
van Tilborg, A. M., and Koob, G. 1991. Foundations of Real-Time Computing-Scheduling and Resource Man-
agement. Kluwer Academic. 
Tokuda, H., and Kitayama, T. 1993. Dynamic QoS control based on real-time threads. Proceedings of the 4th 
International Workshop on Network Supportfor Digital Audio and Video. Lancaster, U.K. 
Zhang, L., Deering, S., Estrin, D., Shenker, S., and Zappala, D. 1993. RSVP: A new resource ReSerVation 
protocol. IEEE Network. 
95 

..
... The International Journal of Time-Critical Computing Systems, 16,223-251 (1999) 
© 1999 Kluwer Academic Publishers, Boston. Manufactured in The Netherlands. 
The Spring System: Integrated Support for 
Complex Real-Time Systems 
JOHN A. STANKOVIC 
stankovic@cs.virginia.edu 
Department of Computer Science, University of Virginia, Charlottesville, Virginia 22903 
KRITHI RAMAMRITHAM 
krithi@cs.umass.edu 
Department of Computer Science, University of Massachusetts, Amherst, Massachusetts 01003 
DOUGLAS NIEHAUS 
niehaus@eecs.ukans.edu 
Department of Electrical Engineering and Computer Science, University of Kansas, Lawrence, Kansas 66045 
MARTY HUMPHREY 
humphrey@cs.virginia.edu 
Department of Computer Science, University of Virginia, Charlottesville, Virginia 22903 
GARY WALLACE 
wallace@cs.umass.edu 
Department of Computer Science, University of Massachusetts, Amherst, Massachusetts 01003 
Abstract. The Spring system is a highly integrated collection of software and hardware that synergistically 
operates to provide end-to-end support in building complex real-time applications. In this paper, we show how 
Spring's specification language, programming language, software generation system, and operating system kernel 
are applied to build a flexible manufacturing testbed. The same ingredients have also been used to realize a 
predictable version of a robot pick and place application used in industry. These applications are good examples 
of complex real-time systems that require flexibility. The goal of this paper is to demonstrate the integrated nature 
of the system and the benefits of integration; in particular, the use of reflective information and the value of function 
and time composition. The lessons learned from these applications and the project as a whole are also presented. 
Keywords: real-time, real-time kernel, mUltiprocessor kernel, real-time scheduling, guarantees, predictability, 
function and time composition, reflection, integrated scheduling, multi-level scheduling, IPC 
1. Introduction 
Complex real-time systems suffer from the lack of tools and runtime software that support 
predictably meeting timing constraints. While it is true that many real-time design tools 
exist, they are surprisingly limited in their abilities to deal with time. As a result, there is 
often a large gap between the specification of the real-time behavioral constraints expressed 
by the design and the constraints on actual behavior supported by the final run-time system, 
in spite of the fact that some of these tools can also automatically produce code. Most of 
the systems are implemented in C and assembler, neither of which has any direct support 
for concurrency or meeting deadlines. While predictable Operating System kernels such as 
VRTX and VXworks can be purchased, they provide necessary but not sufficient support 
for meeting deadlines. For example, while the kernel primitives are predictable, quite often 
worst case execution times for computations running on this system are only estimated (via 
testing), and delays due to blocking are approximated via analysis of possible blocking 
situations. Further, the hardware itself is usually composed of commodity components 
97 

224 
STANKOVIC ET AL. 
designed for average case performance, often significantly reducing the predictability of 
worst case execution times. By costly and careful engineering, systems using all these 
components can be made to function according to the design constraints. However, not 
only are such systems costly, but due to the required hand tuning they are extremely brittle; 
a simple change can precipitate a tortuous period of redesign and analysis. 
The Spring system is a highly integrated collection of software and hardware that syn-
ergistically operates to provide end-to-end support in building complex real-time systems. 
The specification language, called SDL (Niehaus et. al. 1995), explicitly supports specify-
ing a computation's real-time behavioral constraints, end-to-end constraints, concurrency, 
and details of the hardware-software platform that are required to accurately analyze the 
system and achieve predictability. The programming language, Spring-C (Niehaus 1994), 
works in concert with the specification language. Its structure constrains the programmer 
in ways which ensure that worst case execution behavior, including execution times, can 
be automatically predicted for the particular hardware platform being used. Of course, 
such platforms should have predictable instruction execution times. A key aspect of the 
Spring-C compiler is that it automatically identifies all of a computation's potential blocking 
points, i.e., points during execution when it can block for resources or wait for synchronous 
communication to occur. 
The Spring software generation system (SGS), which includes the SDL and Spring-C 
compilers as well as related tools such as assemblers, linkers and loaders, integrates the 
information gathered and derived by its components concerning each computation's execu-
tion behavior. This behavioral information describing blocking points, worst case execution 
times and other information is made available (a) off-line for analysis by scheduling and 
simulation tools, and (b) on-line for dynamic scheduling and other analysis by the ker-
nel. We refer to the data used at run-time as reflective information1• The explicit way 
in which the Spring system automatically addresses blocking and its effect on meeting 
deadlines is one of its key contributions. The run-time kernel, called the Spring ker-
nel (Stankovic and Ramamritham 1991), not only provides predictable primitives, but also 
gives significant added value by solving the central decision problem for the end-users of 
real-time systems - whether a collection of active modules, sharing resources, communicat-
ing, and subject to time constraints will predictably satisfy those constraints. To do this, the 
Spring kernel makes use of the reflective information2 and utilizes an on-line planning and 
scheduling algorithm. This creates an ability to dynamically compose computations along 
both the function and time dimensions. The Spring system also uses a careful hardware 
layout, SpringNet (Stankovic et. aI., 1993), to simplify the design and analysis problem. 
For complex real-time systems, the extra hardware cost is negligible with respect to overall 
system cost. 
The Spring system was in development for more than ten years and many results produced 
along the way have been published. In this paper, except for a small part of Section 2, we 
focus on parts of the system that have not previously been described in the open literature. 
The main goal is to demonstrate the integrated nature of the system and the benefits of 
integration - in particular, the use of reflective information and the value of function and time 
composition. Few real-time research projects have developed novel ideas, implemented 
them in an integrated and complete manner, and then used them in application-based case 
98 

THE SPRING SYSTEM 
225 
studies. There is great value to undertaking a project such as this, and reporting on the key 
results and observations. 
In Section 2, the main components of this integrated system are described. This section 
shows how these components have been designed to work synergistically. The inter-process 
communication (IPC) capabilities of the Spring kernel are then discussed in (Section 3). 
This section shows how the different components of Spring are applied to deal with com-
municating processes. 
To study the integrated approach provided by Spring we employed our solutions on two 
real-world case studies: (1) a flexible manufacturing testbed and (2) a robot pick and 
place application used in industry. These applications are good examples of complex real-
time systems that require flexibility and which can demonstrate the value of reflection and 
(function and time) composition. In this paper, we describe only the first application in 
Section 4 which also contains multi-level scheduling. (The second application is discussed 
in (Bickford et. al. 1996).) The lessons learned from these applications and the project as 
a whole are presented in Section 5. Section 6 discusses the state of art related to this work. 
Section 7 summarizes the paper. 
2. 
The Spring System - Development Environment and Architecture 
This section presents a brief overview of the Spring development environment and the 
Spring target system architecture. Figure 1 illustrates the high level system design and is 
divided into three parts. The heavy black line divides the Spring-C and System Description 
(SDL) languages from an illustration of its potential to serve as a target for higher level 
real-time languages. The dotted line divides the portions of the Spring environment residing 
on the host (above the dotted line) from the portions on the target system (below the dotted 
line). 
The programming model defined by the Spring-C and SDL languages presents a virtual 
machine for use by application programs. This virtual machine is supported on the target 
node hardware by the Spring operating system which is responsible for ensuring that the 
real-time behavior specified by the programmer in the source code is delivered by the 
program executing on the physical machine. For example, behavioral assertions made by 
the programmer in the source language, including assertions about temporal behavior, are 
processed and extended by the programming tools to produce the reflective information 
used by the operating system at run time to determine the best way to produce the desired 
behavior. Behavioral requirements thus flow from top to bottom in the diagram, and can 
have a significant influence on how the hardware implementing the physical machine is 
used. 
Similarly, characteristics of components at lower levels in the diagram which constrain 
the possible execution behaviors have an influence on portions of the system illustrated at 
higher levels in the diagram. The SDL provides a medium within which each layer of the 
system can make information available to other parts of the system. For example, imagine 
that the target hardware implements a non-uniform memory access (NUMA) architecture 
where the access time depends on the location of the information in the NUMA hierarchy 
relative to the CPU accessing it. In this situation, the SDL provides each part of the system 
with the information it needs. The SDL describes the target node's NUMA architecture 
99 

226 
Prototyping and Development 
Environment Research 
RT-Lang Research 
Sys Description Lang 
Spring-C 
Application Code 
Ccode 
Hardware Oesc 
System Software Layout 
Spring Development 
Environment 
Spring Target System 
Figure 1. Spring System Overview 
Hardware 
CPU 
MMU 
Caches 
SSCoP 
SOL 
STANKOVIC ET AL. 
Programming Model 
and Source Language 
Process to Task Group 
Translation 
System Support Tools 
Run-Time Model Management 
Real-Time Hardware Designs 
and the location of every piece of executable program code. This information is used by 
the programming tools which provide execution time predictions for use by the scheduler 
at run time. 
These examples should make it apparent that the designs of each layer of a real-time 
system must be carefully coordinated with that of the others to create a system with truly 
predictable behavior. We use the term vertical slice to describe this approach to sys-
tem design, since it slices across the traditional boundaries between system layers whose 
design and implementation are often addressed almost independently in conventional sys-
tems (Halang and Stoyenko 1991). Passing reflective information, using the SDL, across 
100 

THE SPRING SYSTEM 
227 
layers is key to developing flexible yet predictable real-time systems. Note that the runtime 
system also passes reflective information between system and application layers, and vice 
versa. 
The programming model, Spring-C source language, and software generation system 
(SOS) are the most prominent sections of the host's development environment. However, 
the analysis and support tools, which include the system debugger, are of significant prac-
tical importance. Spring's development environment is currently implemented on UNIX 
workstations, and the SOS provides support for program compilation, linking, analysis, and 
debugging. The executable files prepared by the SOS are downloaded onto the Spring target 
node using the debugger, and then executed under the supervision of the operating system. 
The SOS' s support for cross compilation decouples the selection of host and target architec-
tures. The SOS currently supports three host architectures, DEC Vaxstations, Decstations, 
and DEC Alphas as well as one target architecture, the Motorola 68020. However, many 
parts of the SOS are extensions of the Free Software Foundation's tools (Stallman 1992), 
which support a wide range of hosts, and share their portability. 
The SOS supports the programming environment, which presents the programmer with 
a virtual machine capable of supporting real-time computations. The target system im-
plements the virtual real-time machine which manages computations' execution according 
to their requirements and constraints. The target system runs the Spring operating system 
which includes Spring's scheduler. The Spring scheduler uses the reflective information 
supplied by the SGS and is responsible for ensuring that computations execute according 
to their constraints. This information is supplied in the form required by the Spring sched-
uler, which manages computations represented as precedence related groups of tasks with 
resource and deadline constraints (Zhao and Ramamritham 1987), (Niehaus 1994). This 
algorithm is responsible for dynamic time composition and will be discussed further in 
Section 4. 
2.1. 
SGS Data Flow 
This section discusses how information, including reflective information, about applica-
tion programs flows among the various elements of the SOS and programming environ-
ment in the course of creating and downloading the application's executable images, as 
illustrated in Figure 2. A novel feature, and important contribution, of Spring's SOS is 
the richness and extensive coordinating role played by the SDL. Another novel feature 
and important contribution of the SOS is its translation from a process based represen-
tation of a computation used by the programmer to a representation of a computation's 
execution behavior as precedence-related tasks used by both on-line and off-line sched-
ulers (Zhao and Ramamritham 1987), (Niehaus et. al. 1990), (Niehaus 1994). Detailed 
discussion of the translation method is available elsewhere (Niehaus 1994), (Niehaus 1991). 
It is important to note, however, that the reflective information used by the system is accu-
mulated and derived in the course of this translation. 
Figure 2 is divided into three sections horizontally, illustrating the processing of Spring-C 
and SDL source files, and how the information specified or derived from the source files 
is used off-line by different simulation and analysis tools. The vertical dotted line at the 
right illustrates the border between the host and target systems. The reflective information 
101 

228 
Spring- C 
Source 
Description 
Source 
Object 
Files 
Figure 2. Programming Environment Information Flow 
Executable 
Files 
STANKOVIC ET AL. 
Executable 
Files 
and executables created on the host are downloaded to the target and are used at run-time. 
The bottom section of the figure illustrates how the reflective information is used by off-
line workload generators, scheduling simulators, and simulations of the Spring Scheduling 
Co-Processor (SSCoP). These aspects of the system are peripheral to this paper and are 
discussed elsewhere (Gene 1990), (Niehaus et. al. 1993). 
The top section of Figure 2 illustrates how Spring-C source files are compiled and linked 
by the SGS, while the middle section illustrates the processing of source files which contain 
only SDL statements. The Spring-C compiler spr _cc produces object files containing both 
compiled code and behavioral information either specified in or derivedfrorn the Spring-C 
source during compilation. The SDL compiler sdLcc produces object files containing only 
descriptive information. 
The sdLmerge tool accumulates a description of the application in a database file called 
"full.db" as a series of source files are compiled. This information is used by many elements 
of the programming environment, both for off-line analysis as well as for on-line dynamic 
scheduling. For example, note the arrows pointing out of the file full. db which represent 
information used by the Spring-C compiler spr _cc, the linking loader spr Jd, spr _grp 
which is a tool deriving task group structure when synchronous communication relations 
exist among processes used to implement a computation, and sbug which is a tool supporting 
the downloading and debugging of executables on the target system. 
102 

THE SPRING SYSTEM 
229 
Each time an SGS tool runs it reads the accumulated behavioral descriptions fromfull.db, 
as well as those from any libraries referenced by the source file, as specified by command 
line arguments. This information flow allows spr _cc, for example, to take the worst case 
execution time predictions derived for procedures during the compilation of their source 
files into account when compiling the source of procedures calling them, and thus derives 
an execution time prediction of the calling procedure. Other examples of SDL information 
accumulated and used during compilation include: the target node structure specification, 
the system layout specifying the location of each executable and shared memory segment 
within the target node, and process descriptors specifying the properties of each process. The 
target node structure description includes the address and size of each memory segment. 
The system layout tells sbug where to download every executable image, and tells the 
Spring operating system the name, size, and location of every shared memory segment. 
The process descriptors tells the system everything it needs to know about each process, 
including the executable implementing it, any synchronous communication it engages in 
with other processes, and the representation of the process behavior as a set of tasks required 
by the Spring scheduler. 
While Spring's approach is more complex than those of some conventional systems, the 
compilation ordering constraints are no different in principle from those requiring that all 
the object files required to build an executable be produced before linking occurs. The 
SDL plays a central role in supporting and coordinating the compilation and execution of 
program code. Some of the SDL information is supplied by the programmers, while other 
information is derived during compilation. The crucial point is that all of the information, 
supplied or derived, is represented by the SDL in a common form which is thus available 
to every part of the system. 
The Spring SGS, and the role of the SDL within it, represents an important contribution for 
three reasons. First, it supports information of a wider range and at a greater level of detail 
than other real-time systems, thus supporting the increase reflectivity, predictability, and 
flexibility of the Spring system. Second, the generation and use of the SDL information 
has been fully integrated into all aspects of the SGS and run-time system. The SDL 
thus facilitates the vertical slice approach to integrated design illustrated in Figure 3 by 
simplifying extensive information exchange among normally separate system layers. Third, 
the extensibility of the SDL greatly simplifies creating and integrating new features and tools 
into the system, thus making it easier to maintain an integrated design as the system evolves. 
The extent to which the SGS facilitates the design of predictable complex real-time 
applications is illustrated by its use in (a) the specification and translation of communicating 
processes, discussed in Section 3 and (b) in the development of the flexible manufacturing 
application, discussed in Section 4. 
2.2. 
Spring Node Architecture 
A brief description of the Spring node and network architecture will enable a better under-
standing of the issues discussed in the rest of the paper. SpringN et is a physically distributed 
network of multiprocessor nodes each running the Spring kernel (Stankovic et. aI., 1993). 
Each multiprocessor contains one (or more) application processors (APs), one (or more) 
system processors (SPs), and an 110 subsystem. Ultimately, SPs could be specifically 
103 

230 
Real-Time Application 
Virtual 
Real-Time Machine 
Physical 
Real-Time Machine 
Figure 3. System Layer Relationships 
STANKOVIC ET AL. 
RequirementslSpecifications 
Algorithms 
Process level Architecture 
Real-Time SourcelExecutable 
Requirements {} t Constraints 
Interface 
Virtual 
PhYSical 
Real-Time Language 
External System Services 
Compilation - SGS 
Debugging 
Process Management 
Internal System Services 
Requirements {} t Constraints 
Processors 
Cache 
Memory 
MMU 
designed to offer hardware support to system activities such as guaranteeing computa-
tions (Niehaus et. al. 1993). The 1/0 subsystem is partitioned from the Spring kernel, 
handling non-critical I/O, slow 1/0 devices, and fast sensors. 
One of the most important features of a Spring node (also found in some other real-
time architectures) is its functional partitioning, which enhances predictability by shielding 
applications running on the APs from external interrupts. Environmental interrupts directly 
affect only the SP and I/O processors, indirectly affecting the APs and the applications 
executing on them by generating work whose execution must be added to the execution 
plan maintained by the scheduler. In addition, functional partitioning provides the ability 
to manage different classes of processes separately. 
The current Spring target node, as illustrated in Figure 4, contains 5 processors: one 
system processor (SP), three application processors (APs), an I/O processor board, and a 
"global" memory (GM) board not associated with any processor. Each SP and AP has a 
Motorola 68020 CPU, 68851 MMU, 68881 FPU, and 4Mb oflocal memory which is also 
visible on the system bus. The functional partitioning aspect of the Spring architecture 
104 

THE SPRING SYSTEM 
Ethernet to 
Development Machines 
Node 
Node 
1 
2..-"-
-
I 
I 
.1 
I 
" I 
. 
. 
, 
GM 
AP 
Figure 4. Spring Node Architecture 
. 
:--
. . 
: 
. . 
Node . 
3 
I 
I 
AP 
AP 
. ..• • 
. . . . . . 
• 
. . 
Node 
N 
I 
I 
' . ........ 
l 
Ethernet 
• •• 
110 
File 1/0 
1/0 
1/0 
1/0 
Reflective Memory Ring 
231 
Reflective 
Memory 
Ring 
is implemented by having the system code, including the scheduler, run on the SP while 
application code runs on the APs. We currently have 3 multiprocessor nodes connected 
via two networks: an Ethernet to support non real-time traffic and for downloading the 
system from the development platform, and a fiber optic register insertion ring connecting 
2 Mb shared memory boards in each node. The liD board is currently a stand-alone UNIX 
system supporting both the Spring file system and the node's Ethernet connection. The SP 
can interact with other external devices and sensors through its serial (RS-232) ports. Other 
liD boards, not running UNIX, could be added to support time critical devices. 
The GM shared memory (sometimes called reflective memory), illustrated in Figure 4, 
provides a shared memory model for its 2 Mb (of physically distributed but logically 
centralized memory), and is implemented via the off-the-shelf product called Scramnet 
(SYSTRAN 1991). The memory is "reflective" in that the reflective memory boards in each 
of the Spring nodes always contain the same information, subject to transmission delays 
on the fiber optic ring connecting them. The reflective memory boards thus effectively 
represent a single memory board shared among all the nodes on the ring. 
The isolation of application processes on the APs enables the system to protect them from 
external interrupts, which are handled by the SP. This, in conjunction with the execution 
guarantees provided by the scheduler, allows us to construct a more macroscopic view of 
105 

232 
STANKOVIC ET AL. 
a predictable system. Context switches are reduced because APs do not handle interrupts, 
which simplifies predicting a computation's execution behavior. Better execution time 
behavior predictions make it easier to guarantee that a computation will complete by its 
deadline. Our strategy also partitions the real-time processes into those that require static 
resource allocation, those requiring a dynamic scheduling algorithm in the front-end, and 
those, which typically have higher levels of functionality and greater latency, handled by 
the dynamic on-line guarantee routine. Those requiring static allocation on dedicated I/O 
boards are typically fast I/O device drivers and critical processes. Slow I/O devices can 
be multiplexed through a front-end processor, which might use a cyclic or rate monotonic 
scheduler. The APs support the higher level application processes given dynamic on-line 
guarantees. 
There are two levels in the non-uniform memory access (NUMA) hierarchy of the current 
Spring node architecture, which are represented by the SDL description of a Spring node 
and are taken into account by the SGS when predicting execution time behavior. Access 
by a processor to the memory on its board, a local access, is fastest. Access by a processor 
to the memory of other processors or to the GM board, a global access, is substantially 
slower due to system bus use and must also contend with the local processor if the access 
is to memory on another processor board. The system ensures a predictable worst case 
global access time by using the VME backplane in round robin mode, which enforces fair 
contention (Motorola 1986). The reflective memory represents a potential third level in 
the NUMA hierarchy, especially if its access time includes the time for updating all other 
boards on the ring, but in the current configuration its access time is the same as access to 
any other memory on the system bus. An additional level in the NUMA hierarchy would 
also be created by instruction and data caches, which the current Spring target architecture 
does not possess. 
The NUMA hierarchy must be accounted for during compilation, since the time for a 
memory access, and thus a substantial part of program execution time, is determined by 
the location of the referenced data structure relative to the CPU generating the reference 
within the NUMA hierarchy. The node description and process layout sections of the SDL 
provide the SGS with the explicit information it requires about the location of data structures 
within the NUMA hierarchy, and the CPUs upon which code accessing the data will run. 
This enables the SGS to distinguish local and global memory accesses, and thus to produce 
accurate worst case execution time predictions (Niehaus 1994). This explicit support for 
obtaining WCETs is missing in most other real-time systems. 
3. Interprocess Communication (IPC) 
The goal ofIPC in the Spring kernel is to provide an efficient and predictable communication 
system that allows programs to exchange information in such a way that the system can 
dynamically schedule invoked end-to-end application computations so that they predictably 
meet their deadlines. The IPC subsystem is thus specifically designed to facilitate analysis 
of communication resource requirements (Nahum and Yates 1990), knowledge of which 
is used by the SGS at compile-time, and by the scheduler at run-time. In this section we 
discuss how SGS facilitates the predictable execution of communicating tasks. 
106 

THE SPRING SYSTEM 
233 
Under Spring IPC, messages are sent to ports. Messages are units of information that are 
passed between processes via either synchronous or asynchronous send and receive calls. 
Messages have fixed sizes, and strict copy-by-value semantics. Messages can have deadlines 
that determine when they must be delivered to a port. Messages and ports are also typed by 
both real-time requirements and semantic content. The real-time typing includes: critical, 
essential, soft real-time and non-real-time messages. The semantic typing distinguishes 
synchronous or asynchronous message delivery, which is determined by the port to which 
the message is sent. Ports are kernel protected data structures owned by the receiver. Ports 
are assigned to the reflective (Scramnet) memory when processes are on different nodes. 
Hence, when a message enters a port at one site there is a fast and predictable delivery time 
to the destination because there are no collisions and contentions on the ring. This delivery 
time, both local and remote, is known to the off-line analysis and on-line schedulers as part 
of the reflective information. 
Application software specifies its IPC requirements as it does all other programming 
resources, by using a combination of SDL and Spring-C statements. Application processes 
request connections via the provided IPC system calls which allocate, free, query, and use 
ports. They specify the types of messages, ports and the specific behavioral requirements 
such as synchronous or asynchronous semantics and delivery deadlines. 
The integrated nature of the Spring system is illustrated by the fact that the properties of 
the synchronous IPC subsystem play a vital role in translating from the programming to 
the run-time representation of a computation. The Spring programming model represents 
a computation as a set of communicating processes, a process group. However, at run-time 
the Spring scheduler requires that the behavior of the process group be represented as a set 
of tasks, a task group, with known worst case task execution time, resource use, execution 
precedence relations, and communication relations. The SGS is responsible for translating 
from the programming representation of a computation as a process group to the run-time 
representation as a task group. The SGS' s use and production of the reflective information 
supported by the SDL was discussed briefly in Section 2.1, illustrated in Figure 2, and is 
discussed in detail elsewhere (Niehaus et. al. 1990), (Niehaus 1991), (Niehaus 1994). 
Consider the role of the IPC subsystem in the compilation and execution of a simple 
process group containing two processes: one performing a synchronous send and one 
performing a synchronous receive. When the spr _cc compiles the source code of the 
sending and receiving processes, it identifies the points at which the IPC calls are made 
as well as collect all the details on the type of IPC and its parameters. In the course of 
compilation and linking, each process is decomposed at the IPC class into a set of tasks. 
In this simple example, each process is represented by two tasks, and the computation 
implemented as a group of two processes is represented by a group of jour tasks. The task 
group represents the computation as a whole because of the synchronous communication 
interactions between the processes which are mapped onto execution precedence relations 
by the SGS. Precedence constraints created by the SGS among the four tasks allow the 
scheduler to construct a schedule that, if feasible, guarantees that the entire process group 
completes on time and that, barring transmission errors, the synchronous IPC semantics are 
satisfied. 
Figure 5 illustrates a simple synchronous exchange between P2 the sender and P I the 
receiver. In the task pair representing P2 the first task ends when the process leaves the 
107 

234 
STANKOVIC ET AL. 
'TaskT1 .., 
L- __ --.-J 
Code 
WCET: A 
Code 
RES: 
syncJecv 
'TaskT2 .., 
L- __ --J 
Code 
WCET: B 
Code 
RES: 
Figure 5. Mapping Synchronously Communicating Processes 
program code and enters the IPC sync...send call, and the second task begins with the return 
from that call. In the task pair representing P I the first task ends when the process leaves the 
program code and enters the IPC syncrecv call, and the second task begins with the return 
from that call. It should thus be easy to see that a precedence constraint exists between 
the first and second tasks in the pair representing each process to ensure that the scheduler 
constructs a schedule which executes the task representing the entry to each IPC call before 
it executes the task representing the return from that call. 
There are, however, two other precedence constraints in the task group, from the first 
task in the pair representing each process to the second task in the pair representing the 
other process, which enforce the synchronous IPC semantics. These precedence constraints 
are created by the spr _grp command, illustrated in Figure 2, on the basis of its analysis of 
synchronous communication patterns within the process group. Specifically, it uses the task 
group structure to match all synchronous send and receive pairs. The precedence constraint 
from the first task representing PI, the receiver, to the second task representing P2, the 
sender, ensures that the receiver process must have entered its syncrecv call before the 
sender returns from its sync...send call. 
The precedence constraint from the first task representing P2 to the second task repre-
senting PI has a minimum delay CD associated with it. This relation ensures that the 
sender must have entered its sync...send call at least CD time units before the receiver can 
return from its IPC call. This ensures that the message has been sent and that it has at least 
CD time units in which to makes its way from the sender to the receiver. The spr _grp 
command determines the value CD by consulting the SDL data base provided by the full. db 
file, illustrated in Figure 2, describing the node structure, the network structure, the tasks' 
location, and thus the communication delays which exist between the two tasks in ques-
tion. Note also that the minimum delay CD is associated with the precedence constraint 
between the first and second tasks representing P2. This enforces the Spring synchronous 
IPC semantics which require that the sync...send call not return until the message is available 
on the receive side. 
108 

THE SPRING SYSTEM 
235 
The full set of task group information (e.g., worst case execution time, resource use, 
synchronous communication, and execution precedence constraints) is made available to 
the run-time kernel, and connection information is available to the operating system on all 
nodes where the communicating tasks reside. The distributed scheduling algorithms then 
utilize the communication and task information to guarantee the application level end-to-
end deadline constraint. The algorithm is beyond the scope of this paper; details can be 
found in (Di Natale and Stankovic 1994). Thus at run-time, for example, if a guaranteed 
task performs a synchronous receive, the scheduler knows when to schedule that task such 
that a message should be present. If there are no messages available, it means that either 
the scheduler has not scheduled the tasks correctly, or that an error has occurred, such as 
a lost message or failed task. The error code returned to the receiver is interpreted as an 
exception that must be handled by the application. 
In summary, the Spring IPC provides a set of predictable primitives whose design and 
implementation have been very closely coordinated with the requirements of the real-time 
scheduler. The flow of information from the application, through the SOS, to the run-time 
system has been illustrated. Armed with this information the system can dynamically sched-
ule groups of communicating tasks representing computations in a manner that guarantees 
deadlines are met. 
4. 
Case Study: Flexible Manufacturing 
The flexible manufacturing application discussed in this section illustrates how a com-
plex real-time system that requires flexibility has been developed using the components of 
Spring discussed in the previous three sections. More specifically, the SOS is shown to 
easily support flexible timing and functional composition of computations managing man-
ufacturing activities. This application motivated an additional form of application support, 
the remote process invocation(RPI). Our experience with this application has shown how 
the reflective information processed and derived by the SOS and then made available to the 
Spring scheduler enables responsive control of the varied jobs presented by a manufacturing 
environment. 
4.1. 
Model of a Flexible Manufacturing Testbed (FMT) 
The FMT models dynamic manufacturing systems in which raw materials and orders arrive 
nondeterministically, and the goal is to produce goods in a timely fashion. The value of 
completing the order is a function of the intrinsic value of the manufactured object and the 
time at which the manufactured object is produced relative to the order arrival. A single 
controlling process directs manufacturing processes that service orders. The controlling 
process decides which orders to service based upon the current raw materials and the current 
pool of pending, as-yet-unserviced orders. The controlling process also bases its decisions 
on expectations concerning the future arrival of raw materials and of new orders. 
While the FMT is not intended to precisely model all the intricate details of a real-world 
manufacturing system, it is a comprehensive undertaking. The FMT involves an integration 
of different technologies besides real-time systems (support for predictable response and 
low-level systems integration): robotics (coarse reaching, grasping, automated assembly); 
109 

236 
Rotating Platform 
Camera ~ 
Linear 
Platform 
Figure 6. Schematic of the Flexible Manufacturing Testbed 
STANKOVIC ET AL. 
Robotic Arm 
Bins for omplctcd Orders 
computer vision (object recognition); and automated reasoning (AI techniques for process 
advisors). 
Figure 6 illustrates the key physical components of the testbed: a rotating platform with 
ten bins, a linear platform with five bins, four tubes for holding completed orders, a flapper, 
and a robotic arm. The raw materials of products are represented by balls-either white, 
gray, or black-and arrive nondeterministically into bins on the rotating platform. The 
manufacturing of an order consists of transporting balls of the color specified in the order 
from the rotating platform to the linear platform, and from the linear platform to an available 
tube. To move a ball from the rotating platform to a tube, the ball must first be pushed 
into an assigned slot of the linear table. This is done by first moving the linear table so 
that the assigned slot is in front of the flapper, which is not mobile. When the ball has 
rotated in front of the flapper, the flapper kicks the ball onto the linear platform. A scanner 
is then instructed to find the precise location of the ball within the particular linear table 
bin so that the robotic arm can be instructed to grasp from a precise location. Once the 
ball has been picked up by the grasper, it is moved to a point above the assigned tube, and 
released. Collectively, the physical components represent a set of finite-capacity stations 
in a manufacturing facility. A product must pass between stations in order to be machined 
and combined with other parts. Eventually, the part passes through the last station and is 
transported to a holding station until it leaves the manufacturing site. 
4.2. Run-Time Operation of the Testbed 
Scheduling in many real manufacturing sites exists at two levels of abstraction. At the 
higher level of abstraction, the scheduling involves objects such as materials, machines, 
and orders. The decisions made at this level include the selection of which orders to service 
110 

THE SPRING SYSTEM 
237 
and when to service them, based on the value and deadline of each order and the availability 
of raw materials. The feasibility of servicing an order is determined by the scheduler 
operating at the lower level of abstraction, which, as opposed to the higher level scheduler, 
deals with the computational resources needed to move robots, assemble products, etc. 
For example, the higher level scheduler may decide to make a certain product, but the 
actual manufacturing floor may not be capable of servicing this order in time. In this 
situation, feedback information from the lower level to the higher level allows the higher 
level scheduler to make more informed decisions concerning future orders, which increases 
system productivity as a whole. 
In the FMT, two separate schedulers are used to schedule at the two levels of abstraction. 
The high level scheduling is performed by a process called the AI Planner, the low level 
scheduling is done by the Spring scheduler, and servicing of an order is done by the Spring 
kernel. When an order arrives at the AI Planner from the outside world, the AI Planner 
consults its model of the environment, which includes the raw resources available, and the 
state of the manufacturing system, which includes knowledge of orders currently being 
serviced. When the AI Planner decides to pursue the servicing of an order, the order is 
passed to the Spring scheduler via an interface, which maps the AI Planner's representation 
of work into the Spring representation of work as processes. 
The mapping from the level of the AI Planner to the Spring scheduler is a complicated 
procedure because the two schedulers operate at different levels of abstraction and with 
different resources. The AI Planner is interested in managing the pool of available balls 
and in getting products produced by certain times. The Spring scheduler is interested in 
resources and actions on a much smaller scale - for example, invoking the flapper at the 
correct time, and activating the grasper in a slot of the linear table in which there is a ball. 
The obvious requirement of the AI Planner/Spring Interface program is to map orders to 
the low-level actions that will service the order. There are three levels of abstraction that 
the interface uses to perform its mapping: 
Task A task represents a fine grained model of execution behavior, and task groups are 
used to represent the execution behavior of processes and process groups. A task has 
resource requirements, precedence constraints with other tasks, a deadline, an arrival 
time, and a worst case execution time (WCET). The task is an object that can be directly 
dispatched and executed on a processor by the Spring operating system. The Spring 
scheduler builds a schedule by assigning tasks to execute on processors at specific times. 
Process A process' execution behavior is represented by a set of tasks with precedence 
constraints between them. There are six processes in the FMT, five of which are related 
to robotics and computer vision routines: Move Linear Table, Flap, Scan Linear Table, 
Grasp Ball and Deliver Ball. The sixth process, End Of Order, when executed, informs 
the AI Planner that the order has been serviced. 
Process Group A process group is set of processes with precedence constraints among 
them that represents a single logical action. In the FMT, there are four process groups: 
Move Linear Table PG, Flap PG, and End Of Order PG are each comprised of a single 
process. The fourth process group, Scan Grasp Deliver PG, is a sequential ordering of 
Scan Linear Table, Grasp Ball, and Deliver Ball. Figure 7 shows the individual tasks 
111 

238 
Move Linear Table 
into Flapping Position 
Flap Ball 
onto Linear Table 
:~~I ~I T1~1 ~ 
11 I 
i 
TI IL--------l 
Delay for Move (15 sec.) 
Delay for Flap (15 sec.) 
T3======= 
T4;:::: 
T5 
Scale: 1 em = 2 mSec 
Note: Delays for robotics and computer vision 
routines not drawn to scale. 
Figure 7. Tasks for Each Robotic Process Group 
STANKOVIC ET AL. 
Scan, Grasp, 
and Deliver Ball 
TI 
Delay for Scan (5 sec.) 
~~~~~~~~~~ 
T5 ~ 
~~IL-____________ ~ 
H 
Delay for Grasp (10 sec.) 
TlO I 
Til L-____________ 
~ 
Tl2 ~D~ela~y~fO~r~D~el~iv~er~(I~o~se~c~.) 3' 
Tl3c: 
Tl4 
and their times for each of the robotics and visions process groups (the End of Order 
process group is a single task and is not included here). The "delays" in each process 
group will be discussed shortly. Note that the creation of the tasks and the task groups 
representing the behavior of the process groups is done automatically by the Spring 
SGS, as discussed in Section 2.1 and Section 3, and the reflective information collected 
and derived by the SGS is kept for use by the system at run-time. 
The first step the AI Planner/Spring Interface program takes when a new order arrives 
is to map the order to a set of process groups. This is a dynamic functional composition 
using predeclared primitive process groups to create a set of process groups that meet the 
functional requirements of the new order (which has dynamically arrived). Process groups 
for two types of two-ball orders are shown in Figure 8. On the left of that figure is the 
structure for a two-ball order in which the first ball must be placed in the tube before 
the second ball, and on the right is a two-ball order in which the ordering of balls in the 
tube does not matter. The second step of the interface is to take the SDL based task group 
representations of the process groups' behavior and to connect them, preserving precedence 
constraints between process group components, into a larger task group representation of 
the execution behavior of the computation required to fill the order. The end result of the 
mapping that the interface performs is a potentially complex task graph (which contains all 
the time information needed to perform a time composition) that is passed to the Spring 
112 

THE SPRING SYSTEM 
239 
2 ball order with any ordering of balls 
2 ball order with precise ordering of balls 
Figure 8. Process Groups Structures for Two-Ball Orders 
scheduler. For example, a three ball order creates a task graph of 73 tasks each with a worst 
case execution time, and hundreds of precedence constraints. 
An important aspect of this scheduling hierarchy is the support for dynamic functional and 
timing composition. At run-time, primitive machine actions can be arbitrarily grouped with 
precedence constraints, deadlines on individual actions, and an overall end-to-end deadline. 
This flexibility facilitates the creation of many different product orders. The Spring system 
can compose real-time machine actions on-line because of the amount of reflective infor-
mation generated by the SGS. For example, the tasks of Figure 7 are automatically derived 
through analysis of the Spring-C source code; the attributes of the tasks such as prece-
dence constraints, resource requirements, and deadlines are generated and provided to the 
Spring scheduler automatically. This information enables the Spring system to dynamically 
compose and execute the product orders. 
In addition to mapping from the level of abstraction of an order to the level of abstraction 
of the set of computations that, when executed, will produce the order, the AI Planner/Spring 
Interface is also responsible for selecting particular instances of physical resources to use. 
Either the AI Planner or the Spring scheduler can select the particular balls, the slots on 
the linear table, and the tube, but there are fundamental problems with making either of the 
selections. If the AI Planner selects the bins, slots, and tubes, the manufacturing system 
would miss important opportunism that the Spring scheduler could provide. For example, 
the Spring scheduler could decide that the red ball in bin two of the rotating table should be 
used, because that's the nearest red ball when the flapper is scheduled to execute. Using a 
113 

240 
STANKOVTC ET AL. 
red ball in any other position would mean wasted time waiting for the ball to come around 
in front of the flapper. However, this opportunism is very difficult to achieve, because 
it requires that the Spring scheduler be able to predict which ball to use based on which 
schedule it can build. Dynamically making this decision is complicated and error-prone. For 
these reasons, an intermediate approach was chosen, which is to allow the AI Planner/Spring 
Interface to select which balls to use, which slots of the linear table to use, and which tube 
to use. In a general sense, the interface (an intermediate layer) performs resource allocation 
at a third level, which is between the higher level of the Al Planner, and the lower level of 
the Spring scheduler. 
In designing the FMT, we have recognized that we would like to allow the robotics 
and computer vision routines to be executable directly on the Spring node, or on special-
purpose architectures external to the Spring node itself, as is sometimes required for robotics 
routines. To support this flexibility, we have created the remote process invocation (RPI). If 
the robotics process is executed directly on the Spring node, then all the tasks that comprise 
it are scheduled for execution on an AP. If the process is executed remotely, Spring wraps 
the actual remote process in a pair of Spring tasks, which are executed on the Spring node, 
that directly control the invocation of the remote process. The SP schedules an RPI by 
scheduling a task to execute on an AP that informs the remote process of its parameters 
and starts the remote process, and a task to execute on an AP that confirms that the remote 
process has terminated successfully. For example, in Figure 7, to move the linear table, Task 
T3 informs the linear table controller of its parameters and Task T 4 checks if the move was 
successfully completed. The length of time between the two tasks is equal to the WCET 
of the remote process. That way, if the remote process has not terminated in time, the SP 
can begin cleanup and error-handling procedures immediately after the remote process was 
supposed to finish. By scheduling this way, rcal-time properties and system-level safety 
are ensured. 
In the Spring node being used in the FMT, a Spare board is used as the I/O board shown 
in Figure 4. From the perspective of the Spring kernel, the Sparc acts as a general platform 
on which to run processes remotely. However, from a systems-integration perspective, the 
Sparc allows the robotic and computer vision routines to be developed independently from 
the development of the Spring kernel. For this reason, we currently execute the robotics and 
computer vision routines remotely, while anticipating that eventually they will be executed 
directly on the Spring node. Figure 7 reflects the fact that the robotics and computer visions 
routines are executed remotely. Each delay in the picture represents the worst case duration 
of the corresponding robotic process. Because the worst case execution times of the robotic 
processes are relatively long, the actual overhead due to Spring is negligible. For example, 
the setup tasks for the Move Linear Table process takes a total of 6.203 milliseconds, and 
the cleanup tasks take a total of 0.145 milliseconds. The combined overhead to execute the 
processes remotely therefore represents .04% of the duration of the actual robotic activity 
to move the linear table into position. The overheads for the other two process groups are 
similar. 
The remote process invocation is an important contribution for independent development 
of processes. A process can be executed under real-time constraints, but not necessarily on 
a Spring AP. The SGS fluently and robustly supports development of application code in 
114 

THE SPRING SYSTEM 
241 
this manner. It is important to note that this addition to the SGS was directly motivated by 
the flexible manufacturing domain. 
4.3. 
Multi-Level Scheduling 
The FMT utilizes schedulers operating at multiple levels of abstraction. The high-level 
scheduler is called the AI Planner because of the use of Artificial Intelligence (AI) tech-
niques, which have traditionally not been used in hard real-time systems because of their 
inability to define a worst-case behavior, both in terms of space and time. In addition, the 
efficiency and simplicity often required for hard real-time systems are in contrast to the na-
ture of some AI algorithms. In the flexible manufacturing domain, however, the key is that 
while strict, millisecond-timing requirements will be imposed on the low level scheduler, 
the high level scheduler is intended to deal with time on the range of seconds. Presumably, 
this implies that more computationally-intensive AI methods can be explored. 
The AI Planner ultimately decides how to run the manufacturing facility. Currently, the 
decisions made by the AI Planner include whether to immediately reject an order from 
the outside world because it is either not worth the effort or there are too many current 
pending orders; when to submit an order to Spring given the AI Planner's understanding of 
the state of the manufacturing system; and when to re-submit an order to Spring, if Spring 
had previously rejected it because of unavailability of low-level resources. Because the 
focus of this paper is on the Spring development system, it is not necessary to describe the 
algorithms used by the AI Planner; instead, it is sufficient to state that the AI Planner uses 
a view of the world that is frequently uncertain, due to machine operations taking less than 
worst-case durations. To resolve the uncertainty, the AI Planner interacts with the Spring 
scheduler, periodically querying the Spring scheduler on the state of certain resources. 
Feedback from the Spring scheduler is used to resolve the uncertainty in the AI Planner's 
view of the world: 
• 
When the AI Planner submits an order to the Spring scheduler, if the order is schedulable, 
the Spring scheduler replies with the scheduled start time (sst) and scheduled finish time 
( sft) of the order. 
• 
When the AI Planner is uncertain about the status of the low level machinery, it can ask 
the Spring scheduler for such information. The Spring scheduler replies with a list of 
the sst and sft of all of the orders currently existing in the Spring schedule. In addition, 
the AI Planner can specifically request the sst and sft of a particular order. 
• 
The AI Planner should be notified when an order completes, which the Spring scheduler 
does by scheduling and executing the End of Order process group for each scheduled 
order. 
This case study points out how reflective information is acquired during compilation and 
how it is used at run-time. A key aspect is the need for reflective information not only 
to flow from the application levels into the system, but also from the low level system 
operation back to the applications. The AI Planner is an example of an application that 
greatly benefits from the ability of the Spring system to provide precise, timely information 
concerning the current and planned state of low-level resources. 
115 

242 
STANKOVIC ET AL. 
In summary, a real manufacturing system, albeit a simplified version, has been imple-
mented and has directly tested the assumptions of integrated design, use of reflective in-
formation, and dynamic function and time composition. We have presented a two-level 
partitioning of the overall scheduling in the flexible manufacturing domain, discussed our 
initial attempts at passing information between the two schedulers, and showed the synergy 
between the two schedulers. 
5. Lessons Learned 
The experience of designing and implementing an integrated set of real-time tools and kernel 
and applying them to a flexible manufacturing testbed (Section 4) and a robotic pick and 
place application (described in (Bickford et. al. 1996» has taught us a number of lessons. 
• 
The amount of information the Spring scheduler provides to applications regarding the 
reasons for (the lack of) schedulability and the current state of execution can greatly 
affect performance. Because the Spring system is reflective, the Spring scheduler has 
the ability to dynamically inform applications of resource usage, resource availability, 
and scheduling results. 
For example, in the FMT, the AI Planner used the information from the Spring scheduler 
to update its internal schedule. The AI Planner's schedule has a great deal of uncertainty; 
this uncertainty can be resolved when the Spring scheduler sends periodic updates 
regarding resource utilization and availability. 
• 
Because the Spring scheduler is by necessity heuristic, it is impossible to give, with 
complete certainty, the specific reasons for rejecting a request. That is, while an inability 
to schedule a set of tasks is usually caused by lack of adequate access to a key resource, 
a multiprocessor scheduler's inability to find a schedule for a particular set of tasks may 
not be a product of any intrinsic properties of the tasks, but rather of the manner in which 
the scheduler attempted to build the schedule. This manifests itself in the FMT when 
the Spring scheduler attempts to determine why an order is not currently schedulable, 
given the existence of other orders in the current schedule. The Spring scheduler, or 
any other multiprocessor scheduler for that matter, cannot definitively state the reason 
why a schedule cannot be built-at most, a scheduler can provide its best estimate. 
Applications must be written in such a way that they are cognizant of this limitation. 
• 
The length of time into the future that a real-time scheduler schedules must be dependent 
on the nature and predictability of the environment. In the FMT, a single three-ball order 
submitted to an idle system causes the generation of a schedule that is projected to take 
166 seconds in its worst case!3 Scheduling so far into the future in this domain caused 
problems, because it was difficult to predict, for example, exactly when a particular 
bin would rotate in front of the flapper (due to the physical forces at work, the rate of 
rotation varies largely depending on the number of balls on the rotating table). 
• 
The ability to specify both high level and detailed implementation facts in an integrated 
manner, together with supportive analysis and development tools and a reflective run-
time kernel that makes use of that information, has several key benefits, including 
116 

THE SPRING SYSTEM 
243 
predictability - because each component part is carefully analyzed via develop-
ment tools and the composition is done via mapping software and the scheduling 
algorithms 
flexibility - the reflective information identifies what is permitted and the dynamic 
composition creates acceptable new combinations of tasks 
off-line analysis - all the tools can be run off-line to analyze the system a priori. 
• 
The use of reflective information enhances robustness and provides a key approach to 
dealing with large dynamic real-time systems. It is used for 2-way flow of information 
and is key in admission control, planning, on-line analysis, and overload management. 
• 
Careful timing analysis must focus on the effects of blocking and interrupts. Our 
dual approach of avoiding blocking by having the compiler identify all the potential 
blocking points and then having the scheduler layout an execution plan so that tasks 
sharing resources do not execute at the same time and by using a front end processor 
to buffer the non-deterministic effects of interrupts, provides great dividends in ease of 
analysis and understanding the operation of the system. Our approach to dealing with 
the blocking problem (automatically via the compiler and scheduler) presents a second 
major paradigm for solving this problem (the other being rate monotonic with priority 
ceiling (Sha and Goodenough 1988)). 
• 
Many realistically complex real-time applications contain large collections of tasks with 
sophisticated requirements such as precedence constraints, shared resources, commu-
nication requirements, and varying deadlines and values for the tasks in the system. 
Simple approaches like rate monotonic and earliest deadline scheduling are difficult to 
use in such cases. 
• 
Judicious use of hardware can enhance predictability. Dedicating a scheduling pro-
cessor, using multiple busses and obtaining hardware support such as Scramnet for 
predictable distributed communication makes it easier to get predictability. While we 
have no explicit proof we feel that the extra hardware is well worth the relatively low 
cost given that large real-time system solutions cost orders of magnitude more than the 
hardware and much of that cost is incurred while trying to deal with the issues which 
are simplified by the extra hardware. 
• 
In creating the design for the application, the user (or tools that the user employs) must 
know how the use of shared resources and synchronous communication affects the 
overall run-time representation and subsequent timing performance. An understanding 
of the general properties of the target hardware allows the designer to efficiently specify 
process and resource layout. An understanding of the translation process and the ability 
to control key aspects of it are also required. The software development environment 
should thus not be a black box between the user and the completed executable. This 
increased level of awareness should not be considered a disadvantage, since a real-time 
application and its execution environment should be well-understood for enhancing the 
performance of the application. 
For instance, in the robotic pick and place application, we originally thought that syn-
chronous communication would be the significant factor affecting the resulting run-time 
117 

244 
STANKOVIC ET AL. 
representation. However, the SGS tools automatically analyzed the blocking, synchro-
nization, and communication behavior of the application and revealed that contrary 
to expectation, this application is most affected by the use of shared resources. This 
was due in part to the fact that we constrained the vision and robotic processes to 
communicate among themselves only through shared resources. 
• 
Tools are needed to help the user analyze the resulting task group patterns in order to 
understand the behavior of the executable at run-time. It should be possible to view the 
task group representation in a readable form. At this stage, the user is provided with 
information that allows making intelligent changes or optimizing the application. 
For instance, in the robotic pick and place application (Bickford et. al. 1996), using 
the Spring SGS tools we were able to analyze the task groups' structure and discovered 
that explicit delays and synchronous communication account for only a small number 
of suspension points and that most of the 685 tasks of the compiled application were 
due to resource use specified by the Spring-C with statement. We decided to review the 
code to discover if the huge number of tasks was inherently necessary. It turned out 
that simple changes to the code substantially reduced the total number of tasks, while 
preserving the required semantics. 
• 
Within the Spring-C code the user should pay careful attention to the use of statements 
that cause suspension points. In particular, how resource use is specified is important 
since placement of with statements can greatly affect resulting task group patterns. 
Again, in the robot pick and place application (Bickford et. al. 1996), we discovered 
that there were many sections of code in which we could move with statements to higher 
granularities (e.g., one with surrounding a larger block of code, rather than several within 
the the same block) to make the task decomposition more efficient. This reduced the 
total number of tasks from 685 to 147. 
Because of the automatic nature and added application level support of the tools and 
system, we hypothesize lower overall effort and costs using our approach. 
6. 
Related Work 
This section discusses some of the work most relevant to the issues considered in this paper. 
6.1. 
Real-Time Languages 
Burns and Wellings give a good description of real-time systems in general and describe 
their implementation using straightforward adaptations of techniques used in conventional 
systems to real-time (Bums and Wellings 1989). Real-time languages often add statements 
about the temporal constraints of computations to the syntax of the language. However, 
most current real-time languages using the process model for programming also assume 
118 

THE SPRING SYSTEM 
245 
the conventional run-time model which manages a set of processes preempting one another 
according to their execution priority, competing for resources, and blocking when resources 
are already in use, which tends to limit their ability to predict execution time behavior. 
Several language proposals have been made to explicitly deal with the specification of 
real-time requirements and the assurance of predictability. In one of the early efforts, 
Kligerman and Stoyenko produced a restricted language, Real-Time Euclid, which was 
designed to make schedulability analysis possible under a number of assumptions about the 
system and process behavior (Kligerman and Stoyenko 1986), (Stoyenko 1987). 
More recently, the Real-Time Mach system uses a language with C++ as its starting point, 
adding constructs for specifying timing constraints including start time, deadline, excep-
tion handling, and periods (Ishikawa et. al. 1990). They assume the use of rate monotonic 
scheduling in the underlying system, but little is said about how the WCET, which rate 
monotonic scheduling requires, can be predicted in the object oriented environment. The 
programming language for the Maruti system, MPL, also extends C++ and uses ideas close 
to those of Spring in some areas (Nirkhe et. al. 1990). MPL provides several ways to spec-
ify temporal constraints on blocks of code within an object. Loop bounds are specified 
and recursion forbidden to increase predictability. Kenny and Lin describe the Flex lan-
guage, another extension of C++, which includes a number of timing constraint expressions 
and exception handling clauses (Kenney and Lin 1991). This research addresses the issues 
of approximate processing by adopting a polymorphism analogous to operator overload-
ing (Liu et. al. 1991). In this instance polymorphism refers to supplying several routines 
implementing the same function which have different properties in space and/or time. They 
also describe support for monotonic algorithms which explicitly support computations with 
unpredictable behavior by establishing an initial result early and then iteratively refining it 
until the deadline is reached. 
Real-Time Concurrent C (Gehani and Ramamritham 1991) extends Concurrent C by pro-
viding facilities for building systems with strict timing constraints. Real-Time Concurrent 
C allows processes to execute activities with specified periodicity or deadline constraints, 
to seek dynamic guarantees that timing constraints will be met, and perform alternative 
actions when either the timing constraints cannot be met or the guarantees are not available. 
The guarantee notion in Real-Time Concurrent C was motivated by the similar notion in 
Spring. 
6.2. 
Tools for Behavior Prediction 
Several researchers have considered execution behavior prediction. Amerasinghe developed 
a tool which analyzes the assembly language emitted for a program with respect to a model 
of the target processor (Amerasinghe 1985), (Chen 1985), but does not take the effects 
of pipe lining and instruction caching into account. Harmon produced a tool performing 
what he called micro-analysis (Harmon et. al. 1992). The tool worked directly with the 
executable code, first disassembling it, and then deducing the looping structure. Park and 
Shaw took an approach at the source level, using what they call source level timing schema 
for the basic elements in a restricted subset of C (Park and Shaw 1991). Each timing 
schema describes the execution time for a C language statement or construct. One problem 
119 

246 
STANKOVIC ET AL. 
with this approach is that since the schema are for source level constructs, the method has 
difficulty taking into account any optimizations performed by the compiler which cross 
schema boundaries. To the extent the source level schema fail to predict the assembler code 
actually produced by the compiler, they cannot take the properties of pipelines and caches 
in the target hardware into account effectively. 
An advantage of the approach taken by the Spring project is that its timing analysis is 
integrated into the compiler, and is performed after compiler optimization but before final 
emission of assembler code (Niehaus 1994), (Niehaus 1991). This enables Spring to take 
compiler optimizations into account while also basing its predictions on exactly the code that 
will be executed. It also makes it possible to perform program transformations required to 
enhance predictability and to fully implement the run-time model (Niehaus 1994). Puschner 
and Koza take an approach to determining execution times in the context of the MARS 
system (Puschner and Koza 1990), which is very similar to that taken by Spring in many 
ways. They take a two phase approach, the first phase combines information about program 
structure and timing, and the second analyzes this representation to determine the worst case 
execution time. This permits them to consider optimizations performed by the compiler 
and hardware features, but does not permit them to perform transformations on the code 
during the same phase as their temporal analysis. More recently, a project led by Whalley has 
addressed behavorial prediction for data caches and instruction caches (White et. al. 1997), 
(Arnold et. al. 1994). 
6.3. 
Operating Systems 
For relatively small, less complex, real-time systems, it is often the case that real-time 
systems are supported by a stripped down and optimized versions of timesharing operating 
systems. To reduce the run-time overheads incurred by the kernel and to make the system 
fast, the kernel underlying the real-time system: 
• 
has a fast context switch, 
• 
has a small size (with its associated minimal functionality), 
• 
responds to external interrupts quickly, 
• 
minimizes intervals during which interrupts are disabled, 
• 
provides fixed or variable sized partitions for memory management (i.e., no virtual 
memory) as well as the ability to lock code and data in memory, and 
• 
provides special sequential files that can accumulate data at a fast rate. 
To deal with timing requirements the kernel, providing a limited set of special services 
beyond those provided by a conventional system, it: 
• 
maintains a real-time clock, 
• 
provides a priority scheduling mechanism, 
• 
provides for special alarms and timeouts, and 
120 

THE SPRING SYSTEM 
247 
• 
permits tasks to invoke primitives to delay by a fixed amount of time and to pause/resume 
execution. 
In general, these kernels, as minimal extensions of the techniques used by conventional 
systems, perform multi-tasking. In addition, inter-task communication and synchronization 
are achieved via standard, well-known primitives such as mailboxes, events, signals, and 
semaphores. In this vein, many real-time UNIX operating systems (Furht et. al. 1991), 
and a standard for real-time operating systems, called RT POSIX, have been developed 
(Gallmeister 1995). There are also a large number of proprietary real-time systems, over 
70 commercial real-time kernels exist, which take a similar design approach; examples 
include: QNX, LynxOS, OS-9, VxWorks, and VRTXsa. Research projects also sometimes 
take this approach, the most obvious example being Real-Time Mach, which is an extension 
of Mach (Tokuda et. al. 1990). 
While familiar programming models and standards facilitates porting code to a real-time 
target, how to predict and guarantee execution behavior under systems using this approach 
is still an open question because of the many aspects of conventional operating system 
design which optimize average case performance, rather than supporting the predictability 
of worst case behavior. 
Research systems take a wider variety of approaches which focus more strongly on accu-
rately predicting execution behavior, at least for some section of the system, and satisfying 
execution time behavior constraints. Real-time kernels are also being extended to operate 
in highly cooperative multiprocessor and distributed system environment. For example, the 
Real-Time Mach kernel (Tokuda et. al. 1990) provides a distributed real-time computing 
environment that works in conjunction with the static priority-driven preemptive scheduling 
paradigm. The kernel supports the notion of real-time objects and real-time threads. Each 
real-time object is time encapsulated. This is enforced by a time fence mechanism which 
provides a run time check that ensures that the slack time is greater than the worst case 
execution time for an object invocation about to be performed. If it is, the operation pro-
ceeds, else it is aborted. Each real-time thread can have a value function, timing constraints, 
worst case execution time, phase, and delay value associated with it. The Real-Time Mach 
kernel is also tied to various tools that a priori analyze the system wide schedulability of 
the system. 
The MARS kernel (Kopetz et. al. 1989), (Kopetz and Merker 1985) offers support for 
controlling a distributed application based entirely on time events (rather than asynchronous 
events) from the environment. Emphasis is placed on an a priori static analysis to demon-
strate that all the timing requirements are met. An important feature of this system is that 
flow control on the maximum number of events that the system handles is automatic and this 
fact contributes to the predictability analysis. This system is based on a paradigm, i.e., the 
time driven model, that is different than that found in timesharing systems. The scheduling 
approach is static table-driven. Support for distributed real-time systems includes a hard-
ware based clock synchronization algorithm and a TDMA-like protocol to guarantee timely 
message delivery. 
The MARUTI system (Saksena et. al. 1995) focuses on support for dynamic on-line 
guarantees that tasks will make their deadlines and on fault tolerance. It is object based and 
supports distributed systems. Each object has service access points which are the operations 
(services) that the object provides. Information about objects such as their computation 
121 

248 
STANKOVIC ET AL. 
times and deadlines are retained with the objects to be used by the dynamic planning-
based scheduler. When an object is invoked the scheduler determines if the object can be 
guaranteed to meet its timing constraint. If so, the schedule for it is added to a calendar that 
represents the deterministic manner in which the object will execute and all resources the 
object will require are reserved. 
The Hexagonal Architecture for Real-Time Systems (HARTS) consists of mUltiple sites 
connected by a hexagonal mesh network. Each site may be a uniprocessor or multipro-
cessor and contains an intelligent network processor. The intelligent network processor 
handles much of the low level communication functions. An experimental operating system 
called HARTOS (Shin 1991), (Shin et. al. 1995) is a distributed real-time kernel running 
on HARTS. On each site HARTOS runs in conjunction with the commercial uniprocessor 
OS, pSOS, so, by itself, is not a full operating system. Rather, HARTOS focuses on inter-
process communication, thereby providing some support for distributed real-time systems. 
In particular, HARTOS supports message send and receive, non-queued event signals, re-
liable streams, and message scheduling that provides a best-effort approach in delivering a 
message by its deadline. 
The CHAOS system (Oheith and Schwan 1993) represents an object based approach to 
real-time kernels. This approach allows easy creation of a family of kernels, each tailored 
to a specific hardware or application. This is important because real-time applications vary 
widely in their requirements and it would be beneficial to have one basic paradigm for a 
wide range of applications. The family of kernels is based on a core that supports a real-
time threads package. This core is the machine dependent part. Virtual memory regions, 
synchronization primitives, classes, objects, and invocations all comprise additional support 
provided in each kernel. One of the investigated scheduling approaches is guarantee-
oriented, employing a variation of the preemptive deadline-first scheduling algorithm for 
its feasibility checking. Unlike the scheduling approach used in Spring in which both timing 
and functionality of a task are guaranteed, here, it is verified that a set of tasks can meet 
their deadline requirements based on optimistic assumptions about resource availability, 
for instance. Thus, depending on blocking for resources, a task may not achieve its desired 
functionality, even though it will meet its timing constraint. 
7. 
Summary 
The Spring project conducted research and made contributions to the state of the art in 
many areas of real-time systems, but a significant but subtle contribution is that the individ-
ual contributions were integrated into a single functioning system, and were then used in 
application-based case studies. Among the most important benefits of integration demon-
strated by our experience building and using the system are the use of reflective information 
and the value of function and time composition. The case studies have shown that the SOS, 
the Spring-C and SDL languages, and the Spring kernel all work together to provide an 
effective application programming interface. The value added to the application through 
its implementation using Spring concepts and tools include: 
• 
Predictability: The application's execution behavior is now analyzable and predictable. 
Blocking, concurrency, synchronization, and schedulability analysis, the most difficult 
122 

THE SPRING SYSTEM 
249 
aspects of real-time systems analysis, are supported directly and largely automatically 
by the development tools and the system in cooperation via reflective information. As 
an example, to automatically support blocking analysis, the compiler identifies all the 
blocking points and the on-line scheduler plans execution to avoid blocking and still meet 
time constraints. Designers are not left to figure out the impact of blocking on their own. 
Further, the executables produced contain all the information needed to predictably 
execute the application even when tasks are functionally composed dynamically. 
• 
Guarantees: The online guarantee algorithm dynamically creates a feasible schedule 
for the task group representing the behavior of the application processes when the 
event requiring their execution first arrives. By using reflective information (especially 
concerning potential blocking points) this algorithm performs timing composition in a 
flexible manner. 
• 
Flexibility: Throughout design and coding, and after, the user is greatly aided by being 
able to specify timing constraints at many levels, especially at the level of end-to-end 
scheduling. Making changes to these specifications is easy. The application is then 
able to tolerate updates and changes in the environment (to some extent changes in 
the hardware). Reanalysis is automatic when modifications are made. Dynamic 
recombination of real-time process groups at runtime is also possible, providing the 
potential for even greater flexibility. 
Notes 
I. This is also sometimes called meta data, e.g., in CORBA. However, Spring was the first real·time OS to elevate 
to a central principle the integrated use of reflective information in real-time systems. 
2. Examples of reflective information include: worst case execution time, resource requirements and mode of 
use, and precedence and communication relationships between tasks. Other examples of reflective information 
are given throughout the paper. 
3. There is inevitably more parallelism available within the system which we, for debugging purposes, have 
chosen to ignore for the moment. The focus of the research thus far has been not to create the most efficient 
manufacturing system, but rather to create a realistic model of the manufacturing system in which to investigate 
research issues. 
References 
Amerasinghe, P. An Interactive Timing Analysis Tool for the SARTOR Environment, Master's thesis, University 
of Texas at Austin, 1985. 
Arnold, R., F. Mueller, D. B. Whalley, and M. Harmon, Bounding Worst·Case Instruction Cache Performance, 
Proceedings of the 1994 IEEE Real·Time Systems Symposium, December 1994. 
Bickford, c., M. Teo, G. Wallace, 1.A. Stankovic and K. Ramamritham, A Robotic Assembly Application on the 
Spring Real· Time System, Proceedings of the 1996 IEEE Real· Time Technology and Applications Symposium, 
May 1996. 
Bums, A. and A. Wellings, Real· Time Systems and Their Programming Languages. Addison-Wesley, 1989. 
Chen, M. Timing Analysis Language· TAL Programmer's Manual, Technical report, University of Texas at Austin, 
1985. 
Di Natale, M. and I.A. Stankovic, Dynamic End·to-End Guarantees in Distributed Real·Time Systems, Proc. of 
the 15th Real·Time Systems Symposium, December 1994. 
123 

250 
STANKOVIC ET AL. 
Furht, B., D. Grostick, D. Gluch, G. Rabbat, 1. Parker, and M. McRoberts, Real-Time Unix Systems, Design and 
Application Guide, Kluwer Academic Publishers, Boston, MA., 1991. 
B. Gallmeister, POSIX.4: Programming for the Real World, O'Reilly and Associates, 1995. 
Gehani, N. and K. Ramamritham, Real-Time Concurrent C (C++): A Language for Programming Dynamic 
Real-time Systems, Real-TIme Systems, Vol. 3., No.4, Dec. 1991, pp 377-405. 
Gene, E. The Spring Simulation Testbed - V2 User's Guide, Technical report, Spring Project Documentation, 
1990. 
Gheith, A. and K. Schwan, CHAOS arc: Kernel Support for Multi-Weight Objects, Invocations, and Atomicity 
in Real-Time Applications, ACM Transactions on Computer Systems, Vol 11., No. I, April 1993, pp 33-72. 
Halang, W. and A. Stoyenko, Constructing Predictable Real-Time Systems, Kluwer Academic Publishers, 1991. 
Harmon, M., T. Baker and D. Whalley, A Retargetable Technique for Predicting Execution Time, Proceedings of 
the IEEE Real-Time Systems Symposium, December 1992, pp pages 68-77. 
Ishikawa, Y., H. Tokuda and C. Mercer, Object Oriented Real-Time Language Design: Constructs for Timing 
Constraints, Proceedings of OOPSLAlECOOP, ACM, October 1990. 
Kenney, K. and K. Lin, Building Flexible Real-Time Systems Using the Flex Language, IEEE Computer, Vol. 
24., No.5, May 1991, pp 70-78. 
Kligerman, E. and A. Stoyenko, Real-Time Euclid: A Language for Reliable Real-Time Systems, IEEE Transac-
tions on Software Engineering, September 1986. 
Kopetz, H., A. Damm, C. Koza and D. Mulozzani, Distributed Fault Tolerant Real-Time Systems: The Mars 
Approach,IEEE Micro, 1989, pp 25-40. 
Kopetz, H. and W. Merker, The Architecture of MARS, Proceedings 15th FTCS, June 1985, pp 274-279. 
Liu, J., K. Lin, W. Shih, A. Yu, J. Chung and W. Zhao, Algorithms for Scheduling Imprecise Calculations, IEEE 
Computer, Vol. 24., No.5, May 1991, pp 58-68. 
Molesky, L.D., C. Shen and G. Zlokapa, Predictable Synchronization Mechanisms for Multiprocessor Real-Time 
Systems, Real-Time Systems, Vol. 2., No.3, 1989, pp 163-180. 
Motorola, Inc. MCOR Unit68020 32-bit Microprocessor User's Manual, 1986. 
Nahum, E. and D. Yates, Real-Time IPC for the Spring Kernel, COINS 777 Project Report, University of Mas-
sachusetts, Amherst, MA, May 1990. 
Niehaus, D. Program Representation and Translation for Predictable Real-Time Systems, Proceedings of the IEEE 
Real-Time Systems Symposium, December 1991, pp 53-63. 
Niehaus, D. Program Representation and Execution in Real-Time Multiprocessor Systems, PhD thesis, University 
of Massachusetts, Amherst MA, 1994. 
Niehaus, D., L. Molesky and J.A. Stankovic, Spring System Programming and Run-Time Models, Spring Project 
Documentation, University of Massachusetts, Amherst, MA, June 1990 
Niehaus, D., K. Ramamritham, J.A. Stankovic, G. Wallace, C. Weems, W. Burleson and J. Ko, The Spring 
Scheduling Co-Processor: Design, Use, and Performance, Proceedings of the Fourteenth IEEE Real-Time 
Systems Symposium, December 1993, pp 106-111. 
Niehaus, D., J.A. Stankovic and K. Ramamritham, A Real-Time System Description Language, Proceedings of 
the 1995 IEEE Real-TIme Technology and Applications Symposium, May 1995. 
Nirkhe, V., S. Tripathi and A. Agrawala, Language Support for the Maruti Real-Time System, Proceedings of the 
IEEE Real-TIme Systems Symposium, December 1990. 
Park, C. and A. Shaw, Experiments with a Program Timing Tool Based on Source-Level Timing Schema, IEEE 
Computer, Vol. 24., No.5, May 1991, pp 48-57. 
Pflugel, M., A. Damm and W. Schwabl, Interprocess Communication in MARS, ITG/GI Conference on Commu-
nication in Distributed Systems, Stuttgart, Germany, February 1989. 
Puschner, P. and C. Koza, Calculating the Maximum Execution Time of Real-Time Programs, Real-TIme Systems 
Journal, Vol 1., No.2, 1990. 
Ramarnritham, K., J.A. Stankovic and P. Shiah, Efficient Scheduling Algorithms for Real-Time Multiprocessor 
Systems, IEEE Transactions on Parallel and Distributed Systems, Vol 1., No.2, February 1989, pp. 184-194. 
Ramamritham, K., 1.A. Stankovic, and W. Zhao, Distributed Scheduling of Tasks with Deadlines and Resource 
Requirements, IEEE Transactions on Computers, Vol 38., No.8, August 1989, pp 1110-1123. 
Saksena, M., J. da Silva and A. Agrawala, Design and Implementation of Maruti-II, Advances in Real-Time 
Systems, Sang Son, editor, Prentice-Hall, 1995. 
Saltzer, J.H., D.P. Reed and D.O. Clark, End to End Arguments in System Design, ACMTransactions on Computer 
Systems, Vol 2., No.2, November 1984. 
Sha, L. and 1. Goodenough, Real-Time Scheduling Theory and ADA, Cmufsei-88-tr-33, CMU, November 1988. 
124 

THE SPRING SYSTEM 
251 
Shen, c., K. Ramamritham and J.A. Stankovic, Resource Reclaiming in Multiprocessor Real-Time Systems, IEEE 
Transactions on Parallel and Distributed Systems, Vol 4., No.4, April 1993, pp 382-398. 
Shin, K. HARTS: A Distributed Real-Time Architecture, IEEE Computer, Vol 24., No.5, 1991. 
Shin, K.G., D.D. Kandlur, D.L. Kiskis, P.S. Dodd, H.A. Rosenberg, and A. Indiresan, A Software Overview of 
HARTS: A Distributed Real-Time System, Advances in Real-Time Systems. Sang Son, editor, Prentice-Hall, 
1995. 
Stallman, R. Using and Porting GNU CC, Technical report, Free Software Foundation, May 1992. 
Stankovic, J.A., Misconceptions about Real-Time Computing: A Serious Problem for Next Generation Systems, 
IEEE Computer, October 1988, pp 10-19. 
Stankovic, I.A., D. Niehaus and K. Ramamritham, SpringNet: An Architecture for High Performance Distributed 
Real-Time Computing, Workshop on Parallel and Distributed Real-Time Systems, April 1993. 
Stankovic, J.A. and K. Ramamritham, The Design of the Spring Kernel, Proc. of the 8th Real-Time Systems 
Symposium, December 1987, pp 146--157. 
Stankovic, J.A. and K. Ramamritham, The Spring Kernel: A New Paradigm for Real-Time Systems, IEEE 
Software, Vol 8., No.3, May 1991, pp 62-72. 
Stoyenko, A, A Schedulability Analyzer for Real-Time Euclid, IEEE Real-Time Systems Symposium, December 
1987. 
SYSTRAN Corporation, SCRAMNet Network Reference Manual, Dayton, Ohio, 45432, 1991. 
Tokuda, H., C.w. Mercer, Y. Ishikawa and T. Marchok, Priority Inversions in Real-Time Communication, Proc. 
of the 10th Real-Time Systems Symposium, May 1989, pp 348-359. 
Tokuda, H., T. Nakajima and P. Rao, Real-Time MACH: Towards a Predictable Real-Time System, Proceedings 
of the USENIXMACHWorkshop, 1990. 
White, RT. F. Mueller, C.A Healy, D. B. Whalley, and M. G. Harmon, Timing Analysis for Data Caches and 
Set-Associative Caches, Proceedings of the 1997 IEEE Real-Time Technology and Applications Symposium, 
June 1997. 
Zhao, W. and K. Ramamritham, Simple and Integrated Heuristic Algorithms for Scheduling Tasks with Time and 
Resource Constraints, Journal of Systems and Software, Vol 7., No.3, September 1987, pp 195-205. 
125 

~£ The International Journal of Time-Critical Computing Systems, 16,253-280 (1999) 
~ © 1999 Kluwer Academic Publishers, Boston. Manufactured in The Netherlands. 
Expressing and Enforcing Timing Constraints in a 
Dynamic Real-Time CORBA System 
VICTOR FAY WOLFE 
LISA CINGISER DIPIPPO 
ROMANGINIS 
MICHAEL SQUADRITO 
STEVEN WOHLEVER 
IGORZYKH 
Department of Computer Science, University of Roode Island, Kingston, RI02881 
RUSSELL JOHNSTON 
U.S. Navy SPAWAR Systems Center; San Diego, CA 92152 
Editor: Ragunathan Rajkumar 
wolfe@cs.uri.edu 
dipippo@cs.uri.edu 
ginis@cs.uri.edu 
squadrito@cs.uri.edu 
wohlever@cs.uri.edu 
zykh@cs.uri.edu 
russ@nosc.mil 
Abstract. Distributed real-time applications have presented the need to extend the Object Management Group's 
Common Object Request Broker Architecture (CORBA) standard to support real-time. This paper describes 
a Dynamic Real-Time CORBA system, which supports the expression and enforcement of end-to-end timing 
constraints as an extension to a commercial CORBA system. The paper also describes performance tests that 
demonstrate the system's ability to enforce expressed timing constraints. 
Keywords: real-time, CORBA, distributed, dynamic, timing constraints 
1. Introduction 
Distributed object computing is becoming a widely accepted programming paradigm for 
applications that require seamless interoperability among heterogeneous clients and servers. 
The Object Management Group (OMG), an organization of over 700 distributed soft-
ware vendors and users, has developed the Common Object Request Broker Architecture 
(CORBA) as a standard software specification for such distributed environments. The 
CORBA specification includes an Object Request Broker (ORB), which is the middleware 
that enables the seamless interaction between distributed client objects and server objects; 
Object Services, which facilitate standard client/server interaction with capabilities such as 
naming, event-based synchronization, and concurrency control; and the Inteiface Definition 
Language(IDL), which defines the object interfaces within the CORBA environment. 
Many distributed real-time applications, such as automated manufacturing, telecommuni-
cations, financial services, and simulation, are embracing the object-oriented paradigm and 
have a mandate to use an open systems design. The designers of many of these applications 
are considering CORBA for their architecture, but are finding it is currently inadequate to 
support real-time requirements. CORBA contains neither the services, nor the interface 
facilities to express and enforce end-to-end timing constraints on distributed client/server 
interactions. 
127 

254 
WOLFEETAL. 
In 1995, a Special Interest Group (SIG) was formed within the OMG with the goal of ex-
tending the CORBA standard with support for real-time applications. This SIG (RT SIG) is 
developing a whitepaper (OMG, 1996a) that details requirements for extending/modifying 
CORBA to support real-time. The whitepaper describes requirements for the operating 
environment, for the ORB architecture, and for the CORBA Object Services. 
Our research group at the University of Rhode Island and the U.S Navy's NRaD facility, 
along with collaborators from the MITRE Corporation, produced an early design of real-
time capabilities in a CORBA system (Krupp, 1994), (Wolfe, 1995) which is a partial basis 
for the RT SIG whitepaper. We then implemented a prototype of a real-time CORBA 
environment as an extension to the Orbix CORBA system from lona Technologies. This 
paper describes a prototype system and the issues and techniques for adding real-time 
capabilities to CORBA. 
The RT SIG has put out two requests for proposal (RFPs) for real-time CORBA: one 
for static scheduling and one for dynamic scheduling, because they have recognized a 
need for both. The static scheduling RFP deals with applications with hard real-time 
constraints for which a priori analysis is necessary. The work described here is a design 
and implementation of a dynamic real-time CORBA system that is meant as an exploratory 
response to the dynamic scheduling RFP. 
The prototype is designed to support end-to-end timing constraints in flexible dynamic 
CORBA environments. A dynamic CORBA environment is one in which clients and servers 
may be added and removed, and where constraints may change. This type of environment 
prohibits complete a priori analysis of timing behavior. This Dynamic Real-Time CORBA 
system implements a best-effort approach towards enforcing timing constraints through 
global priority-based scheduling across the CORBA system, but does not offer hard real-
time guarantees. It admits all tasks into the system, and performs appropriate exception 
handling when a timing constraint is missed. It is also important to note that we are not 
designing a Real-Time ORB, but rather exploring techniques for extending ORBs, possibly 
real-time ORBS when they become available, with specific dynamic real-time enforcement 
support. 
The main concept behind this Dynamic Real-Time CORBA system is support for Timed 
Distributed Method Invocations (TDMls). A TDMI is a client's request to a server object 
along with real-time constraint information for the request, such as deadline, importance, 
and quality of service. The components that we added to the Orbix CORBA system express 
and enforce TDMI constraints. These components include a real-time library with types 
for expression of real-time constraints, and extensions to the ORB and Object Services to 
enforce the constraints. A major addition in this system is an Object Service to assign and 
enforce a global priority across the entire CORBA system based on the real-time constraint 
information in the TDMI. Our prototype implementation of this Object Service uses a 
dynamic Earliest Deadline First within Importance scheduling policy on all schedulable 
entities in the CORBA system. The system also provides a CORBA Real-Time Concurrency 
Control Service to enforce consistency of server objects through a form of locking with 
priority inheritance; and provides a Real-Time Event Service to allow real-time event-based 
synchronization and constraints. 
In this paper, we describe the Dynamic Real-Time CORBA design and prototype imple-
mentation along with results of performance tests. We present background on CORBA and 
128 

EXPRESSING AND ENFORCING TIMING CONSTRAINTS 
Track Table Server IDL 
interface Track_table 
readonly attribute short max_len; 
short put (in short index, 
in long data); 
long get(in short index); 
Figure I. Sample IDL and Client Code 
Client Code 
long retval; 
Track_table *p; 
p = bind("my_Track_table"); 
retval = p->get(500); 
255 
Real-Time CORBA requirements in Section 2. Section 2 also describes related RT CORBA 
research. Section 3 describes the design and implementation. The testing environment, 
tests, and test results are described in Section 4. Section 5 concludes by summarizing the 
concepts and techniques for adding real-time capabilities to CORBA and speculates on 
further enhancements towards developing RT CORBA. 
2. Background 
This section provides background on the CORBA architecture and on the OMG RT SIG's 
requirements for extending CORBA for real-time. The section also describes related work 
in real-time CORBA. 
2.i. 
CORBA 
The CORBA standard developed by the OMG deals primarily with the basic framework 
for applications to access objects in a distributed environment. This framework includes 
an object interface specification and the enabling of remote method calls from a client to a 
server object. Issues such as naming, events, relationships, transactions, and concurrency 
control are also addressed in the CORBA 2.0 specification (OMG, 1996b). Services such 
as time synchronization and security are expected to be addressed in later revisions. 
CORBA is designed to allow a programmer to construct object-oriented programs with-
out regard to traditional object boundaries such as address spaces or location of the object 
in a distributed system. The CORBA specification includes: an interface Definition Lan-
guage(IDL), that defines the object interfaces within the CORBA environment; an Object 
Request Broker (ORB), which is the middleware that enables the seamless interaction be-
tween distributed client objects and server objects; and Object Services, which facilitate 
standard client/server interaction with capabilities such as naming, event-based synchro-
nization, and concurrency control. 
CORBA IDL. CORBA IDL is a declarative language that describes the interfaces to server 
object implementations, including the signatures of all server object methods callable by 
clients. As an example, consider an object that acts as a shared table for tracking data 
(represented as long integer values) for clients in a distributed system. CORBA IDL for 
a simple Track_table object is displayed in Figure 1. The IDL keyword interface 
129 

256 
WOLFEET AL. 
Figure 2. CORBA System Components 
indicates a CORBA object (similar to a C++ class declaration). A readonly at tr ibu te 
is a data value in the object that a client may read. This IDL example also specifies two 
methods: put, which stores a data value at a index into the table; and get which returns a 
data value given an index. 
Figure 1 also displays possible client code in C to access the TracLtable object in a 
CORBA environment. The client must first bind to the TracLtable object before calling 
the get method on the server. This method invocation assumes that a Track_table server 
was previously implemented and registered with the CORBA ORB. 
The ORB and Object Services. An ORB provides the services that locate a server ob-
ject implementation for servicing a client's request; establish a connection to the server; 
communicate the data making up the request; activate and deactivate objects and their 
implementations; and generate and interpret object references. 
Figure 2 illustrates the parts of a CORBA system. The client stubs and the server skeletons 
are produced by the IDL compiler. There is a stub and skeleton for each method on a server's 
interface. A method's stub is linked with the client code to hide the details of communicating 
with the server. The skeleton is linked with the server code to allow application developers 
to create servers without knowing the communication details. Server skeleton code is used 
by the ORB in forwarding method invocation requests to the server, and in returning results 
to the client. Using the stubs, the skeletons, the ORB, and a component called the Basic 
Object Adapter, the CORBA system handles all details of the distributed method invocation 
so that the distribution is essentially transparent to both the client and server application 
developers. 
The CORBA standard contains specifications for Object Services that facilitate client/server 
interaction. These services include a naming service for binding a name to an object; an 
event service for notification of named events; and a concurrency control service for locking 
of resources to maintain consistency. A more complete list of the Object Services can be 
found in (OMG, 1996b). 
130 

EXPRESSING AND ENFORCING TIMING CONSTRAINTS 
257 
2.2. 
Real-Time CORBA 
The OMG RT SIG is currently defining the specifications for RT CORBA. The essence of 
its definition is: 
Real-Time CORBA deals with the expression and enforcement of real-time con-
straints on end-to-end execution in a CORBA system. 
Consider a real-time scenario where a client needs to perform a get method from the 
Track_table server of Figure 1 within timing constraints. This interaction means that the 
client must have some way of expressing timing constraints on its request, and that the 
CORBA system must provide an ORB and Object Services that support enforcement of the 
expressed timing constraints. It also means that the underlying operating systems on the 
client and server nodes, along with the network that they use to communicate, must support 
enforcement of real-time constraints. Thus, there are two main categories of real-time 
CORBA requirements: requirements on the operating environment (operating systems and 
networks); and requirements on the CORBA run-time system. The operating environment 
requirements include requirements for synchronized clocks, for bounded message delay, 
for priority-based scheduling, and for priority inheritance of operating environment entities. 
The requirements on the ORB and Object Services involve providing for specification 
and enforcement of end-to-end timing constraints on client/server interactions. Some of 
these requirements are: 
• 
Transmittal of Real-Time Method Invocation Information. The standard should allow a 
client to attach timing constraint information, such as deadline, importance and quality 
of service, to a method invocation. This information will be available to the ORB, 
ORB Services, skeletons, and server implementations in order to enforce the real-time 
constraints. 
• 
Global Priority. The ORB should establish global priorities for all execution so that 
the priorities of any tasks that compete for any resource in the real-time CORBA 
environment are set relative to each other. 
• 
Priority Queueing of All CORBA Services. All real-time CORBA-Ievel software should 
use priority based queuing. For instance, queues of requests for CORBA 2.0 services 
such as Naming should be priority queues. 
• 
Real-Time Events. The real-time CORBA environment should provide the ability for 
clients and servers to determine the absolute time value of "events". These events may 
include the current time (provided by a Global Time Service), or named events provided 
by the CORBA 2.0 Event Service. Furthermore, events should be delivered in an order 
reflecting either the priority of the event or the priority of the event consumer, or both. 
• 
Priority Inheritance. All real-time CORBA-Ievel software that queues one task while 
another is executing should use priority inheritance. This requirement includes the 
locking done by the CORBA 2.0 Concurrency Control Service, but also includes simple 
queuing such as waiting for the Naming Service. 
A concise summary of the real-time CORBA requirements can be found in (Wolfe, 1997) 
and a full listing can be found in the RT SIG whitepaper (OMG, 1996a). 
131 

258 
WOLFE ET AL. 
2.3. 
Related Work 
There have been several real-time CORBA projects initiated over the past few years. One 
early approach to real-time CORBA was to install a non-real-time ORB on real-time oper-
ating systems. These ported ORBs did not take advantage of most of the operating system's 
real-time features. Furthermore, although implementation on a real-time operating system 
may be necessary for real-time CORBA, it is not sufficient to enforce end-to-end timing 
constraints in a distributed system. 
Several projects have sought to realize "real-time ORBs" that are stripped-down, faster, 
versions of existing ORBs. They removed features like CORBA's Dynamic Invocation 
Interface and allowed special protocols with fixed point-to-point connections of clients to 
servers that by-passed most CORBA features. Such high performance might also be neces-
sary in a real-time CORBA system, but it may not be sufficient for predictable enforcement 
of end-to-end timing constraints. 
MITRE has done work (Krupp, 1994), (Bensley, 1996) to identify requirements for the 
use of real-time CORBA in command and control systems. They have prototyped the 
approach by porting the ILU ORB from Xerox to the Lynx real-time operating system. 
This system provides a static distributed scheduling service supporting rate-monotonic and 
deadline-monotonic techniques. 
Researchers at Washington University in St. Louis are developing a high-performance 
endsystem architecture for real-time CORBA called TAO (The ACE ORB) (Harrison, 1996). 
The focus of this work is on hard real-time systems, requiring a priori guarantees of 
Quality of Service (QoS) requirements. The key components of TAO include a Gigabit 
110 subsystem; a method for specifying QoS requirements; a real-time inter-orb protocol 
for transferring QoS parameters; a real-time scheduling service; a real-time object adapter 
with a real-time event service; and presentation layer components. 
Current work at the University of Illinois Urbana-Champaign is extending the TAO system 
to allow for on-line schedulability testing. Along with the statically guaranteed real-time 
tasks, the new system will perform admissions tests on dynamic tasks to ensure scheduling 
feasibility (Feng, 1997). 
The CHORUS/COOL ORB is a flexible real-time ORB that is being developed by Sun 
Micros Systems (Chorus 1996). The design enforces a strict separation between resource 
management policy and mechanism. The design philosophy also calls for providing ap-
plications with full control over operating system-level resources. Given this philosophy, 
the goals of the CHORUS/COOL ORB include: a flexible binding architecture; producing 
minimum CORBA on a minimal ORB; and a real-time operating environment that provides 
access to fine grain resource management. The COOL ORB from Chorus Systems does not 
provide many real-time features itself, but rather relies on the CHORUS operating systems. 
A strength of the COOL ORB is that it imposes minimal overhead on top of the native 
operating systems. 
Along with the dynamic scheduling approach taken in the work described in this paper, our 
research group at URI has also developed a static scheduling approach for real-time CORBA 
(DiPippo, 1999). The design entails the specification of a scheduling service interface that 
allows the passing of global priority throughout the real-time CORBA system, and the 
mapping from global priority to local operating system priority. The design also includes 
132 

EXPRESSING AND ENFORCING TIMING CONSTRAINTS 
259 
a front-end analysis tool which is our augmentation of the PERTS real-time analysis tool 
made by Tri-Pacific Software (TriPacific, 1998), which has been modified to analyze real-
time CORBA clients and servers. The PERTS system performs the analysis, and if the 
real-time CORBA system is found to be schedulable, PERTS provides priorities for the 
clients and servers. 
The preliminary work on some of the projects described in this section, along with our 
research and development described in the next section, has provided the basis for the RT 
SIG whitepaper. The development of this whitepaper, in turn, has provided a common 
set of requirements for real-time CORBA, both static and dynamic. Approaches such as 
CORBA on a real-time operating system and fast CORBA are necessary parts to real-lime 
CORBA development. Static scheduling across the system, such that provided by the 
MITRE prototype, the TAO CORBA system, and the URI scheduling service interface, are 
important steps to supporting hard real-time applications. The incorporation of dynamic 
real-time, where clients and servers can be added or removed, timing constraints may 
change, and priorities are not fixed, is the subject of our work described in the remainder 
of this paper. 
3. 
Dynamic Real-Time CORBA System 
This section describes the Dynamic Real-Time CORBA system, shows how real-time con-
straints are expressed, and details how global dynamic real-time scheduling is performed. 
A depiction of the Dynamic Real-Time CORBA system components is shown in Figure 3. 
This system is designed to augment an existing CORBA system; the prototype implemen-
tation augments the Orbix CORBA system from lona Technologies. The extensions consist 
of minor changes to the basic ORB, modifications and additions to the Object Services, and 
modifications to the client-side and server-side high-level code, stubs, and skeletons. 
The components of our Dynamic Real-Time CORBA system are implemented as a Real-
Time Daemon process (RT Daemon) that executes on each real-time POSIX operating sys-
tem in the system, and as a real-time library that provides type definitions, IDL definitions, 
and code that is used to link in with client and server code. The RT Daemon coordinates 
dynamic aspects of the system including changing global priorities, time synchronization, 
and supporting real-time events. The library code performs tasks such as initial priority 
assignment, handling of real-time information that is associated with all execution in the 
system, and handling of real-time exceptions. The remainder of this section details how 
this is done. 
3.1. 
Underlying System 
Our Dynamic Real-Time CORBA System assumes implementation on an underlying system 
that provides these features: 
• 
Real-time operating systems on all nodes that provide: 
Priority-based scheduling of tasks. 
Priority-based queuing with priority inheritance within the operating system. 
133 

260 
WOLFEET AL. 
Figure 3. Dynamic Real-Time CORBA System 
• 
Clock synchronization among nodes so that any two clocks are with a bounded skew E 
of each other. 
• 
Real-time networking that provides: 
A message delay bound of o. 
Priority-based queuing of all network functions. 
The current implementation uses only operating system features specified in the IEEE 
POSIX Ic real-time operating system standard (POSIX, 1995), which includes priority-
based scheduling of threads and priority-based queueing with priority inheritance. 
As depicted in Figure 3, the changes to the basic ORB include implementing a version of 
the NTP protocol to provide clock synchronization. Also depicted in the figure is a change to 
the ORB to ensure bounded message delays. Although the prototype implementation uses 
a dedicated network between two hosts to achieve bounded message delay, we have done 
research on providing bounded messages delays for a general real-time CORBA system on 
an ATM network; including the Latency Service described in Section 3.3. 
3.2. 
Global Time Service. 
For expressed timing constraints to be meaningful in a distributed system, a common global 
notion of time must be supported. Our Dynamic Real-Time CORBA system implements 
this by synchronizing the clocks and by providing a Global Time Service, which clients 
and servers can call using standard CORBA calls, to get the current time. The Global Time 
Service calls simply make calls to the local operating system to get the (synchronized) time. 
The Global Time Service is described in detail in (Zykh, 1997). 
134 

EXPRESSING AND ENFORCING TIMING CONSTRAINTS 
261 
3.3. 
Latency Service. 
Since bounded message delays are imperative to reasoning about behavior in a distributed 
real-time system, the prototype Dynamic Real-Time CORBA system provides a Latency 
Service to allow clients and servers to determine various qualities of latency bounds in 
the network. The Latency Server accounts for varying "tightness" of bounds by allowing 
requests for bounds to specify the percentage of cases in which the latency bound must 
hold. A 100% specification requires that the bound must always hold. A specification of 
98% specifies that the value of the returned latency must be greater than the actual latency 
98% of the time. The Latency Service uses three methods to provide latency bounds: 
• 
Estimated Latencies - A priori measurements are used to establish latencies. The 
implementation of this form of service is a simple lookup in a table of latencies on each 
node. 
• 
Measured Latencies - The Latency Service performs latency measurements when sys-
tem changes occur. This method typically yields more accurate latency measurements, 
but requires significant overhead in both the call to the Latency Service and in back-
ground measurements taken by the Latency Service(s). 
• 
Analytical Latencies - The Latency Service uses network parameters to calculate ex-
pected latencies. In the prototype, the Latency Service uses SNMP information provided 
by each node to make latency estimates. 
Which form of service the Latency Service provides to a client is determined by the quality 
of the bound needed, as specified by a parameter in the Latency Service call. Typically, 
higher quality bounds, like measured and analytical bounds, require higher overhead and 
take longer to process. The implementation of the Latency Service that provides these 
capabilities on an ATM network is described in (Pallack, 1997). 
3.4. 
Specification of Real-Time Constraints 
The Dynamic Real-Time CORBA system allows clients to express dynamic constraints 
on execution through Timed Distributed Method Invocations (TDMIs). In the prototype 
implementation these constraints include deadlines and importance. Importance is an 
ordinal application-level specification of the relative value to the system of an execution. 
Importance differs from priority, which is an implementation-level attribute used to order 
various executions. Note that although the current system supports only deadline and 
importance specifications, the design is flexible enough to allow other constraints including 
periods and various Quality of Service parameters to be expressed. 
Executions in the Dynamic Real-Time CORBA system use a RT _En vir onment structure 
and a RT _Manager class, both defined in the Real-Time Library, to convey real-time 
information (see Figure 4). ART_Environment structure contains attributes that include 
the importance and deadline. The Dynamic Real-Time CORBA run-time system attaches 
the RT _Environment structure to all executions in the system. Other parts of the Dynamic 
Real-Time CORBArun-time system examine this structure to acquire information necessary 
135 

262 
WOLFE ET AL. 
Node 1 
Node 2 
I 
Client 1 • 
ORB 
I Client 1 • 
~ 
. 
TOMI 
: 
I Clientq • 
Trac~ Table_Client 
II RT Environment and I ~ 
~ 
other parameters 
I 
• 
Server 1 
I 
• 
; 
Clientm 
-
,-,-- ) 
I 
Server 1 • 
~~v<f8~a~ . 
. . 
I 
Server n • 
I Server r • 
I ~ 
EvontCh.~ 
<2 Evont Chan~ 
C:TD .. m~ 
C;TD.07) 
Figure 4, Timed Distributed Method Invocation in The Dynamic Real-Time COREA system 
to enforce the expressed real-time requirements by doing things such as establishing priority 
and setting operating system timers, 
As an example of expressing real-time constraints, consider a client making a TDMI to 
a server that contains a table of tracking data for some tracking application, The client 
requires that the results of its query to the tracking table be returned within a specified 
deadline, 
The following is the IDL for the table CORBA Object: 
#include "rt'info,idl" 
struct Track'Record { 
II contains track ID, position, etc, 
} ; 
interface Track'Table { 
} ; 
void Put(in Track'Record track, in RT'Environment rt'env); 
Track'Record Get (in long track'id, in RT'Environment rt'env); 
The two methods on the table's interface enable clients to insert (Put()) and retrieve 
(Get ()) track data, The code for a client of the table looks as follows: 
136 
#include Track'Table.hh 
#include RT'Manager,h 
#include Track'Table'i.h 
II header file generated by IDL compiler 
II header file for RT'Manager class 
II header file for table implementation 

EXPRESSING AND ENFORCING TIMING CONSTRAINTS 
263 
(1) 
RT'Manager rt'mgr; 
II create instance of RT'Manager 
Track'Table* 
Track'Table'Obj; II declare pointer to table 
int main() 
II main procedure of a CORBA client 
II bind to the appropriate Track'Table (in this case, the 
II one managed by the server named Track'Tab1e'Server). 
(2) 
Track'Table'Obj = Track'Table:: 'bind("Track'Table'Server"); 
CORBA::Long track'id = 42; 
try { 
II set constraints and scheduling parameters 
(3) 
rt'mgr,Set'RT'Constraint'Now(BY,REL,3,O); Ildead1ine=NOW+3sec 
(4) 
rt'mgr,Start'RT'Invocation(); 
II start TDMI: 
1) calculate Global Priority 
II 
2 ) call RT Daemon and register as an active client 
II 
3 ) map Global Priority to this node's priority 
II 
set and change this thread to the new priority 
II 
4) arm the timer 
(5) 
Track'Record track = Track'Table'Obj-> 
Get(track'id, rt'mgr.Get'RT'Env()); 
(6) 
rt'mgr,End'RT'Invocation(); 
(7 ) 
II finish TDMI 1) call RT Daemon and deregister as a client 
2) disarm the timer 
II 
II 
3) restore this thread to its original priority 
catch(const RT'Exception &rtp) { 
II catch RT'Exception 
cout « 
"RT'Exception Raised :" 
«rtp,reason« endl; 
The client first creates a RT _Manager object (Labell in the above code). It then binds 
to the appropriate server (Label 2), Next, it calls the RT _Manager functions necessary to 
set timing constraints and scheduling parameters (Label 3), In the example, we set a relative 
deadline of 3 seconds in the SeLRT _ConstraintO method. The bulk of the work is done 
inside of the StarLRLlnvocationO (Label 4) function and is transparent to the client. 
StarLRT _InvocationO calls the RT Library functions to register the client with the RT 
Daemon on its node, to calculate the priority for the client (described in Section 3.6,1), and 
to arm a timer in the real-time operating system to expire at the client's deadline. 
After the above sequence is complete, the client makes the TDMI to the table (Label 5). 
The RT _Environment that is sent with the call contains the timing information computed 
137 

264 
WOLFEET AL. 
by the RT _Manager. Figure 4 depicts a typical TDMI such as this one. Also in Figure 4, 
note the existence of a RT Daemon on each node. 
When the TDMI request is received by the server skeleton, the execution is scheduled 
on the server's node by server library code going through a procedure similar to that of the 
client: registering the thread as a server with its local RT Daemon, establishing a priority, 
and arming a timer. How this is done is described further in Section 3.6. If the client 
has not missed its deadline when the TDMI returns, then End_RT jnvocationO (Label 
6) disarms the client's deadline timer and performs some clean up. If the timer expires 
(i.e., the deadline is missed), a new real-time CORBA exception of type RT _Exception is 
raised in the client. The client catches this exception (Label 7) and performs any necessary 
recovery operations. 
3.5. 
Real-Time Event Service. 
An important aspect of expressing and enforcing real-time constraints and providing syn-
chronization is the use of real-time events. The current CORBA 2.0 Event Service allows 
for the exchange of named events in the CORBA system. For instance, a client might 
synchronize with another client by waiting for the first client to generate a CORBA event. 
The Dynamic Real-Time CORBA system has a modified Real-Time Event Service that 
prioritizes the delivery of events and delivers the time that the event occurred. Prioritized 
events are based on the global priorities of the producers and consumers as set by the Pri-
ority Service. The (global) time of an event occurrence is important to allow expression of 
timing constraints relative to events. The following example illustrates this concept. 
3.5.1. 
Example of Real-Time Events For Expressing Timing Constraints. 
In the above 
real-time CORBA TDMI example of Section 3.4, the deadline for the client request was 
based on an absolute time that is relative to the current time (three seconds from the current 
time). Now consider the case where the client's deadline is event-driven. Let the deadline 
for the TDMI on the tracking table server be N ewC ontact + 3secs, where N ewContact is 
a named event that occurs when a new contact is entered into the table. In this case, the client 
first has to create a RT _Event object, specify a real-time event ID number, importance of 
the event, and event source (a server name). The revised code for an event-driven client is: 
try 
RT'Event 
rt'event("NewContact",5); 
II create RT'Event object 
rt'event.Set'Importance(1000); 
rt·event.Set'Server'Name("Track·Table'Server"); 
rt·event.Set'Push'Consumer(); 
II act as a push consumer 
II set constraints and scheduling parameters 
II deadline = abs time when Event "NewContact" occurred + 3 secs 
(1) 
rt'mgr.Set'RT'Constraint'Event(BY,&rt'event,3,O); 
138 

EXPRESSING AND ENFORCING TIMING CONSTRAINTS 
265 
(2) 
rt'mgr.Start'RT'Invocation() ; 
II start TDMI 
Track'Record track=Track'Table·Obj~>Get(track·id,rt·mgr.Get'RT'Env()); 
rt'mgr.End'RT'Invocation(); 
II finish TDMI 
The SeLTime~ConstrainLEventO function call (Labell in above code) causes the 
client to wait, with infinite deadline, for a notification that the real-time event has occurred. 
The deadline for the client's request is determined by the absolute time when that event 
occurred plus 3 seconds. This timing constraint is stored in the RT~Environment, and 
the rest of the work is done inside of the StarLRT ~I nvocati onO function as previously 
described (Label 2). 
3.5.2. 
Implementation of Real-Time Event Service. 
The implementation of a RT Event 
Service is based on IP multicasting and takes advantage of multithreading in the local 
operating systems. Each node has a CORBA EvenLChannel (OMG, 1996b) component 
in its RT Daemon that is configured to "listen" to a pre-defined IP multicast group. Each 
real-time event has a unique event ID number, which is mapped to the IP address for the 
multicast group. Suppliers transport real-time event data to each RT Event Channel by 
multicasting to its IP address. Event consumers can wait for delivery of real-time events to 
the IP multicast groups associated with the events, or they can invoke the local RT Event 
Channel to retrieve the real-time event. In the prototype, each RT Event Channel buffers the 
incoming events in priority order so that consumers can look for the buffered high priority 
real-time events first. If the real-time event data is not in the buffer, then the RT Event 
Channel raises a RT exception to the consumer, which is handled as described in Section 
3.4. Further details on the Real-Time Event Service are provided in (Zykb, 1997). 
3.6. 
Global Priority Service and Real-Time Scheduling 
Dynamic real-time scheduling is done by establishing a global priority assignment for 
all execution in the Dynamic Real-Time CORBA system. Each client communicates its 
scheduling parameters to the Global Priority Service, and in tum receives a global priority 
for its execution. These priorities are dynamic and may change over the lifetime of the 
execution. 
We call an execution's priority at an instant in time its Global priority. A Global priority 
is an integer that is derived by the Global Priority Service based on the information in the 
RT ~Environment for the execution. The Global Priority Service ensures that the Global 
priority is meaningful relative to all other Global priorities in the Dynamic Real-Time 
CORBA system. That is, much like a single real-time operating system assigning priorities 
within its local domain, the Global Priority Service assigns priorities that are meaningful 
across the real-time CORBA domain. The RT Daemon on each node maps each execution's 
Global priorities to the priorities on the various schedulable entities that the RT Daemon 
manages. For instance, in the prototype, the RT Daemon maps a client's Global priority 
139 

266 
WOLFEETAL. 
to one of the 60 real-time priorities that the local Solaris operating system allows. An 
execution's global priority is dynamic and may change during the execution for several 
reasons that we describe below, including re-calculation, aging, and inheritance. 
3.6.1. 
Global Priority Calculation. 
The Global Priority Service uses a uniform function 
for all clients and servers in the system to compute Global priority using the attributes in 
the RT _Environment that is associated with the execution. The prototype uses a global 
earliest-deadline-first within importance priority assignment scheme. That is, the proto-
type's global priority function orders priorities based on the importance attribute first, and 
then based on the deadline attribute. A global priority is a seven digit value, where the 
millions digit represents importance, and the lower order digits represent a time differ-
ence (multiplied by 100,000) between the maximum allowable deadline and the deadline 
specified in the RT Environment for the execution. For instance, if the maximum deadline 
is 10 seconds, then execution with importance level 2 and a deadline of 3 seconds has a 
global priority of 2,700,000. Changing the calculation of global priorities based on other 
scheduling policies, such as global rate-monotonic priority assignment, is facilitated by the 
function's central implementation in the Global Priority Service. 
The implementation of the Global Priority Service in the prototype is accomplished 
through a combination of the RT Daemon and code from the RT Library. The library code 
calculates the initial global priority, the RT Daemon handles mapping an execution's global 
priority to a priority on a local node, and also handles changing the global priority. 
3.6.2. 
Priority Mapping. 
The RT Daemon on each node maps the global priority to the 
priorities available on the local real-time operating system. The function that performs the 
mapping must be written for each operating system individually because of the variability 
in ranges of real-time priorities present on different systems (e.g., Solaris has 60 local 
priorities, and LynxOS has 256). In the prototype, which uses RT Solaris operating systems, 
the RT Daemon must map the (wide) range of global priorities into the 60 local priorities. 
The mapping is done by using a statistical model of the likely deadlines and calculating 
global priorities such that TDMIs are probabalistically evenly distributed among the local 
priorities. For example, if there were 60 executions to be scheduled on a Solaris node, the 
mapping would reduce the probability that two executions would be at the same priority. 
Unfortunately mapping of a large range of global priority values into a smaller range of 
priorities can cause more than one global priority to be mapped to a single local priority 
value, which could cause some execution to be out of deadline order. We address the priority 
mapping problem and a solution that is optimal in certain circumstances in (DiPippo, 1999). 
3.6.3. 
Dynamic Global Priority Re-Calculation. 
An execution may have different global 
priorities at different times during its lifetime. For instance, a real-time CORBA client 
could have an initial global priority based solely on its importance with no deadline. It 
then might enter phases of its execution that must be done under deadlines (as speci-
fied by a Set-RT_Constraints RTManager method call in the client). Thus, each 
Start-RT_Invocation call must re-calculate the global priority for the execution that 
140 

EXPRESSING AND ENFORCING TIMING CONSTRAINTS 
267 
makes the call. Similarly, the End..RT_Invoca tion method call, recalculates a global pri-
ority using the deadline (if any) that was in effect before its associated StarLRT _Invocation 
call. 
Another re-calculation of global priority is done when a client makes a TDMI to a server. 
Assume that the client's deadline constraint is delient. This means that the return message 
from the server with results for the client must be received by the client by dclient as measured 
on the client's clock. Recall from Section 3.1 that we assume synchronized clocks with 
maximum skew E, and assume maximum network message delay 8. To calculate the global 
priority at which a server should execute on behalf of the client, the server uses the deadline 
dserver = dclient - 8 - E to pessimistically allow for 8 message delivery time back to the client 
and an E clock skew between its clock and the client's clock. Since this deadline is tighter 
than the client's deadline on whose behalf the server is executing, the TDMI will usually 
have a higher global priority when executing in the server than it will while executing in 
the client. 
3.6.4. 
Global Priority Aging. 
Another change in an execution's global priority is per-
formed by the RT Daemons in the Dynamic Real-Time CORBA system enforcing aging 
of global priorities. Aging is the process of increasing priority as time goes on, which is 
necessary in dynamic earliest-deadline-first scheduling. Each RT Daemon keeps track of 
the global priorities on its node. A RT Daemon increases an execution's global priority if, 
due to the passage of time, the execution's global priority is too low compared to a newly-
arrived execution on the node which the RT Daemon controls. Note that in the prototype 
the aging facility can be "turned off" for real-time scheduling policies that do not require 
aging, such as a static rate-monotonic-based policy. 
Another source of possible of global priority change is priority inheritance in the Real-
Time CORBA Concurrency Control Service, as described next. 
3.7. 
Real-Time Concurrency Control Service. 
CORBA 2.0 provides a Concurrency Control Service to maintain consistent access to 
servers. The Dynamic Real-Time CORBA system includes a Real-Time Concurrency Con-
trol Service that implements priority inheritance (Rajkumar, 1991). When a TDMI requests 
a lock on a resource from the Real-Time Concurrency Control Service, the TDMl's execu-
tion priority is compared to those of all TDMIs holding conflicting locks on that resource. 
Conflicting TDMIs with lower priorities are raised to the requesting TDMl's priority, and 
the requesting TDMI is suspended. Whenever a lock is released, the releasing TDMI resets 
its priority to that of the highest priority TDMI it still blocks (this is possible since clients 
can hold several locks of different types). If it no longer blocks any higher priority TDMIs, 
then the releasing TOMI is reset to its original priority. Finally, the highest priority blocked 
TOMI that can now run is allowed to obtain its lock and continue execution. In designing 
the Real-Time Concurrency Control Service, we needed to consider several issues including 
whether to allow explicit locking and how to handle global priority inheritance. We now 
address these issues and then provide an example of the use of the Real-Time Concurrency 
Control Service. 
141 

268 
WOLFEET AL. 
3.7.1. 
Implicit vs. Explicit Locking. 
When using the CORBA Concurrency Control 
Service, two forms of locking are possible: implicit locking and explicit locking. Implicit 
locking is done within the method code. This placement of lock calls simplifies the usage 
of the resource because clients do not need to know the locking semantics of the resource. 
However, there is a loss of flexibility when using purely implicit locking. For example, 
if a client wishes to execute a sequence of method calls that are protected by the same 
lock, implicit locking is insufficient. Explicit locking provides more flexibility since it 
allows the client that is using the resource to request and release locks when needed. This 
is done by high-level client code explicitly making CORBA Concurrency Control Service 
calls to obtain the necessary locks. However, explicit locking requires the client to know 
which internal locks to use. More importantly, the client must have knowledge of the 
locking semantics for the resource being accessed (i.e., the client must know which locks 
are required for each method on the resource's interface). Aside from the burden this 
places on the client, breaking the encapsulation of the resource is not desirable from an 
object-oriented design perspective. 
3.7.2. 
Transitive Priority Blocking. 
Another issue that must be addressed is that of 
transitive blocking. There are two forms of transitive blocking in which a high priority 
activity A3 is indirectly blocked by a lower priority activity A2 . If AI is the activity that 
directly blocks A2 , then either: 
1. 
A2 is holding a lock that is blocking activity A I; or 
2. 
A2 is executing under a lock held by AI. 
In either case, a transitive blocking chain is formed in which an activity (e.g., A3) is indirectly 
blocked by another activity further down the chain (e.g., A2)' Note thatthis is not the same as 
chained blocking in which an activity is blocked by multiple other activities. The difficulty 
with transitive priority blocking is the fact that these blocking chains can become arbitrarily 
long, especially when activities are allowed to lock multiple resources. This locking can 
require a great deal of overhead to implement. Therefore, the prototype implementation of 
the Real-Time Concurrency Control Service was designed with the following limitations: 
1. No "child" activities can be created under a lock. 
2. An activity can only hold locks on one resource at a time. 
The first restriction disallows explicit locking in the sense that only code local to the activity 
that holds the lock can run while the lock is held. The second restriction is a special case 
of the first restriction since obtaining additional locks after the initial lock would constitute 
starting "child" activities under the initial lock. The only transitive blocking that is allowed 
in the prototype is that which occurs within a LockSet, which is a CORBA 2.0 lock object 
for a single resource. That is, blocking chains are allowed to form as long as all of the 
clients in the chain are clients of the same resource and do not start any "child" activities 
while they hold locks. 
142 

EXPRESSING AND ENFORCING TIMING CONSTRAINTS 
269 
3.7.3. 
Real-Time Concurrency Control Interface. 
One of the goals of the Dynamic Real-
Time CORBA system was to ensure that the interfaces to various CORBA Object Services 
were changed as little as possible. The only change to the CORBA Concurrency Control 
interface is that a RLEnvironment is passed into each TDMI for use in implementing 
priority inheritance. In addition, each method can raise a RT _Exception exception. This 
exception is used to indicate that a timing constraint has been violated during the TDMI. 
The following CORBA IDL shows a subset of the Concurrency Control Service that was 
implemented and extended for real-time. 
module CosConcurrencyControl 
enum lock'mode { 
read, write, upgrade, intention'read, intention'write 
}; 
exception LockNotHeld{}; 
interface LockSet { 
void lock(in lock'mode mode); 
boolean try'lock(in lock'mode mode); 
void unlock(in lock'mode mode); 
raises(LockNotHeld); 
void change'mode(in lock'mode held'mode, in lock'mode new'mode); 
raises (LockNotHeld) ; 
} ; 
} ; 
The revised IDL for the Real-Time Concurrency Control Service is shown here: 
#include "rt'info.idl" 
module CosConcurrencyControl 
enum lock'mode { 
read, write, upgrade, intention'read, intention'write 
}; 
exception LockNotHeld{}; 
interface LockSet { 
void 
lock(in lock'mode mode, in RT'Environment rt'env); 
raises(RT'Exception); 
boolean try'lock(in lock'mode mode, in RT'Environment rt'env); 
void 
void 
raises (RT'Exception) ; 
unlock(in lock'mode mode, in RT'Environment rt'env); 
raises (LockNotHeld, RT'Exception); 
change'mode(in lock'mode held'mode, 
in lock'mode new'mode, 
in RT'Environment rt'env); 
143 

270 
WOLFEETAL. 
raises (LockNotHeld, RT'Exception); 
} ; 
} ; 
The design of the Real-Time Concurrency Control Service makes use of several simpli-
fying restrictions: 
I, Only implicit locking is allowed, 
2, A client can only obtain locks on one LockSet at a time, 
3, A client cannot start "child" activities while the client holds a lock. 
4, Locks must be requested in a pre-determined order, 
The first restriction requires that only the methods on a resource's interface be allowed to 
request locks from the resource's LockSet, The next two restrictions prevent all transitive 
blocking except that which arises between clients of the same LockSet, Finally, the last 
restriction supports the prevention of deadlock, 
3,7.4, 
Example With Real-Time Concurrency Control. 
Consider the case where the track-
ing table requires concurrency control to handle multiple clients and to maintain its data 
in a consistent state, The following code illustrates how the table's Get method imple-
ments implicit locking using the Real-Time Concurrency Control Service provided by the 
Dynamic Real-Time CORBA system. 
Track'Record TrackTable::Get(CORBA: : Long track'id, 
const RT'Environment& rt'env) 
Track'Record track; 
try { 
RT'Env'Mgr rt'mgr(rt'env); 
rt'mgr.Begin'RT(); 
CosConcurrencyControl::LockSet* LockSetObj; 
(1) 
LockSetObj=CosConcurrencyControl::LockSet:: 'bind("Track'Table'Server"); 
(2) 
LockSetObj->lock(CosConcurrencyControl::read, rt'mgr.Get'RT'Env()); 
II Code for retrieval of TrackRecord with the specified ID 
(3) 
LockSetObj->unlock(CosConcurrencyControl::read, rt'mgr.Get'RT'Env()); 
rt'mgr,End'RT(); 
144 

EXPRESSING AND ENFORCING TIMING CONSTRAINTS 
271 
catch(const RT"Exception &rtp) {} 
return track; 
The method first binds to the LockSet object (Labell in above code) that is associated 
with the table (both the LockSet and table are managed by the same server, namely, 
Track1able_Server). The Get method then makes the request for a read lock on behalf 
of the client (Label 2). Thus, the Get method invocation becomes a client of the LockSet 
object. Below is the sequence of steps that occur within the LockSet object when a lock is 
requested: 
1. The Get method invocation requests a lock (CORBA call to LockSet object). 
2. The LockSet object grants the requested lock if it does not conflict with any locks 
currently held (skip Steps 3-5). This simply involves incrementing a counter within the 
LockSet object (each LockSet client has one counter per lock type). 
3. Otherwise, the LockSet object determines which clients hold locks that are blocking 
the requesting client. 
4. The LockSet uses a function in the RT Library to raise the priority of each blocking 
client to that of the requesting client. 
5. The requesting client then waits on the LockSet's condition variable. 
Once the Get method invocation finishes reading from the table, it releases the read lock 
(Label 3). The following is the sequence of steps that occurs when the lock is released: 
1. The Get method invocation requests to release a lock (CORBA call to LockSet object). 
2. The LockSet object releases one instance of the specified lock for that client (remem-
ber that a client can hold multiple instances of a given lock). This simply involves 
decrementing the appropriate counter. If the client does not hold the indicated lock, an 
exception is raised. 
3. The LockSet uses a function in the RT Library to set the releasing client's priority to 
that of the highest priority client still blocked by the releasing client. If it does not block 
any clients, its priority is reset to its original value. 
4. Finally, the LockSet object sends a broadcast signal to its condition variable (the 
intention is to wake the highest priority client that can run). 
Further details of the Real-Time Concurrency Control Service can be found in (Wohlever, 1997). 
145 

272 
WOLFE ET AL. 
3.B. 
Summary 
The Dynamic Real-Time CORBA system has been prototyped as an extension to Orbix, 
but was designed without access to Orbix source code and using only real-time POSIX 
operating system features. Thus, it is suitable for use as the basis of extending many 
different CORBA systems to support real-time. The extensions are packaged as a Real-
Time Library of definitions and linkable code, and a Real-Time Daemon that executes on 
each node in the system. We have provided the prototype to companies including lona 
Technologies, Tri-Pacific Corporation, and Computing Devices International, as well as 
several U.S Navy programs for use in their applications and products. 
4. Performance Tests 
We have performed tests on the prototype implementation of the Dynamic Real-Time 
CORBA system in order to demonstrate how it enforces expressed timing constraints. 
We ran several tests to indicate raw performance numbers for individual features of the 
system. We also ran tests to determine how many client deadlines the prototype missed 
under varying system conditions. In this section we describe the testing environment, as 
well as the tests we performed and the results of the tests. 
Due to the limited size of the prototype, the tests described here are not meant to portray 
the capabilities of a full-scale implementation of the Dynamic Real-Time CORBA system. 
Rather, these tests are meant to illustrate how such an implementation might perform under 
varying conditions. 
All of the tests described below were performed on the two-node isolated network de-
scribed in Section 3. A network delay of approximately 1.2 ms was measured on the 
system. 
4.1. 
Overhead Peiformance Tests 
The tests described here were performed to determine the amount of overhead in the system 
that was due to changes we made to the Orbix system to add real-time capabilities. We 
discuss tests involving Timed Distributed Method Invocations, the Real-Time Event Service, 
and the Real-Time Concurrency Control Service. The results described here are summaries 
of extensive testing performed on each of these Services. For more detailed descriptions of 
these tests and results, see (Wohlever, 1997), (Zykh, 1997). 
4.1.1. 
TDM1 Overhead Tests. 
The results of tests described here are averages over 25 
trials, with an error of I % or less. The tests had a client running on a Sun Sparc IPX 
station, and a server running on a Sun Sparc Station 5. When a client sends a TDMI to 
a server, the first source of overhead is the addition of the RT _Environment structure to 
the method invocation. The extra data copying, moving, dereferencing and transmission 
that must be done by the stubs, skeletons and the ORB amounts to approximately 3 ms per 
method invocation. 
146 

EXPRESSING AND ENFORCING TIMING CONSTRAINTS 
273 
Table 1. Real-Time Event Channel Overhead 
Consumer on same node 
Consumer on different node 
Event Response Time 
90.6 ms 
96.6 ms 
On both the client node and the server node, the bulk of the overhead of the TDMI is 
in the setting up the real-time information. On the client side, most of the overhead was 
produced by the following two methods: 
• 
StarLRT 3nvocationO: The RT _Manager _Client method that registers a client 
with a Real-Time Daemon, calculates and assigns the global priority, and arms a timer 
with a signal handling function. The latency introduced by this method averaged 25.2 
ms. 
• 
End_RT 3nvocationO: The RT _Manager _Client method that deregisters a client 
with a Real-Time Daemon, changes the global priority to its base priority, and disarms 
the timer. The latency introduced by this method averaged 10.7 ms. 
On the server side most of the overhead was produced by the following two methods: 
• 
ST ART _RTO: The RT _Manager _Server method that registers a server's thread 
with a Real-Time Daemon, calculates and assigns the global priority, and arms a timer 
with a signal handling function. The latency introduced by this method averaged 11.4 
ms. 
• 
EN D_RTO: The RT -.Manager _Server method thatderegisters a server's thread with 
a Real-Time Daemon, changes the global priority to its base priority, and disarms the 
timer. The latency introduced by this method averaged 6.1 ms. 
4.1.2. 
Real-Time Event Service Overhead Tests. 
The implementation of the Real-Time 
Event Service was tested by periodically starting up the suppliers on one node that would 
send real-time events to the consumers on another node via the Real-Time Event Channels. 
Table 1 shows the event response time, the time between a supplier generating a real-time 
event and a consumer receiving the event, for each of these tests. 
The tests for the Real-Time Event Channel involved a supplier running on the Sun Sparc 
Station 5, and two consumers, one on the same node, and the other on the Sun Sparc IPX. 
An analysis of the results shown in Table 1 indicates that 85-90% of the overhead was due 
to network communications via IP Multicasting. 
We also performed a set of tests in which a consumer periodically invoked the Real-
Time Event Channel on its node. The overhead for this test was 161.0 ms. These results 
include the time to make a bindO call to the Real-Time Event Channel, which itselftook 
approximately 43.4 ms. 
4.1.3. 
Concurrency Control Overhead Tests. 
The majority of the overhead that was 
added to the Real-Time Concurrency Control Service comes from priority inheritance. We 
ran two tests to compare the overhead involved when priority inheritance was enabled with 
147 

274 
Table 2. Priority Inheritance Overhead Measurements 
PI Enabled 
PI Disabled 
Two Clients 
Low Prio Client unlock 
High Prio Client 
82.60 ms 
129.90 ms 
65.22 ms 
83.54 ms 
WOLFE ET AL. 
overhead when there was no priority inheritance. The results of each test were compiled by 
averaging over 100 trials. The first test involved a single client that requested a write lock 
from a server on another node. The second test involved two clients both trying to access 
the same write lock on a server. In this test, a low priority client first requested and got a 
write lock. Then the high priority client requested the write lock, but was blocked. The 
low priority client released the lock and then the high priority client was granted the lock. 
Table 2 displays the overheads for each of the tests that we performed. A more detailed 
breakdown of the overhead for these tests can be found in (Wohlever, 1997). Notice in 
Table 2 that there are no reported overhead numbers for the low priority client getting the 
write lock in the two client test. This is because there is nothing added to this operation for 
priority inheritance. In all three reported cases, a difference in overhead comes from the 
mechanism used to update the priority of a low priority client for priority inheritance, and 
the mechanism for restoring the priority when a low priority client releases its lock. The 
results for the high priority client also reflect a difference due to a query the RT Daemon to 
detect the priority of the blocking client. 
In all of the overhead performance tests, a majority of the overhead came from CORBA 
calls that were made through the Orbix system. Unfortunately, we did not have access to 
the source code for Orb ix, and so we had to work with the system that was not designed for 
real-time. 
4.2. 
Missed Deadline Performance Tests 
In this set of tests, we compared the prototype with an implementation of a non-real-time 
ORB (Orbix 2.0.l) on a real-time operating system (Solaris 2.5). In this baseline system, 
all clients executed at the same real-time priority, and so scheduling reverted to a round-
robin scheme. We chose this comparison for several reasons. First, the Orbix on Solaris 
implementation provides a good baseline for a "first step" towards real-time CORBA. In 
fact, there have been claims that running a CORBA implementation on a real-time operating 
system can be called Real-Time CORBA (Wolfe, 1997). Second, there are no other existing 
dynamic real-time CORBA implementations available for comparison. 
4.2.1. 
Testing Environment. 
We chose to use percentage of missed deadlines as the 
performance metric because the goal of the prototype is to provide for the expression and 
148 

EXPRESSING AND ENFORCING TIMING CONSTRAINTS 
275 
Table 3. System Parameters 
Parameter 
Baseline Value 
# Nodes 
2 
# Clients 
6 
# Servers 
I 
Client Start Time 
1-13sec 
Client Deadline 
6 sec 
Write Probability 
50% 
enforcement of timing constraints in the CORBA environment. Missed deadline percentage 
is a clear measure of how well timing constraints (deadlines) are enforced. 
To examine different system workloads, we varied the number of clients that execute 
concurrently. We used an increasing range of start times to implement this. That is, in 
some tests, all clients start at the same time, producing a very high workload. In other 
tests the start times for the clients were randomly chosen from a wider range of values. 
Overall, we examined five different start time ranges to represent different workloads. The 
five ranges from which start times were randomly generated for clients to produce varying 
system workloads were: 1-1 seconds (all clients start at the same time); 1-4 seconds (all 
clients start between 1 and 4 seconds after an initial start time); 1-7 seconds; 1-10 seconds; 
and 1-13 seconds. 
Table 3 displays the parameters that we used in the testing. Each test involved two 
nodes. On one of the nodes resided a single server on which all of the method invocations 
were performed. There were certain system limitations that required a small number of 
servers, however for the purposes of the testing, one server was sufficient to demonstrate the 
capabilities of the system. There were 6 clients the other node, each accessing the server on 
the first node. Each client started some time between one second and 13 seconds after an 
initial start time. The range of start times was varied in order to illustrate different system 
workloads. For the baseline test, each client had a deadline of 6 seconds. One of the suites 
oftests we performed (see Section 4.2.2) indicates how system performance changes as the 
clients' deadlines change. Each client performed a single operation, either a read or a write 
on the server. The Write Probability of a client represents the probability that the operation 
performed by the client is a write. Write probability is a measure of contention for the 
server, since the concurrency control for the server must not allow more than one client to 
hold a write lock. In the baseline test, the write probability was 50%. That is, a client's 
operation was just as likely to be a read as a write. Another suite of tests was performed 
to illustrate the effect of write probability on the performance of the system (see Section 
4.2.2). 
4.2.2. 
Tests and Results. 
Along with the baseline test that we performed, we also ran 
two suites of tests to illustrate how deadline and write probability affect the ability to meet 
timing constraints. Each suite of tests was made up of two tests for each start time range. 
Each test was the result of averaging over 15 random trials that produced a 95% confidence 
level with an error of at most 5%. 
149 

276 
WOLFEET AL. 
~ SO 
c 
70 
.-
, 
.... 
.~ 
'0 III 
-CORBA 
It! 
~ ro 
0 
40 
'0 
Q) 
30 
'" '" 
20 
1: 10 
M 
0 
Start Ti me Range 
Figure 5. Baseline Test 
Figure 6. Deadline Tests 
Baseline Test. The parameters for the baseline tests are listed in Table 3. We performed 
this test to illustrate how the system performs under average conditions. 
Figure 5 displays the results for the baseline test. The x-axis of the graph represents 
system workload. The numbers that label the axis represent the outside number of the 
start time range. For instance, we can see that as system workload decreases (start time 
range increases) the percentage of missed deadlines decreases. This is expected since the 
contention for the CPU also decreases. The figure also shows that the Dynamic Real-
Time CORBA system consistently meets more deadlines than the non-real-time CORBA 
implementation. 
Deadline Tests. We performed this suite of tests to illustrate the effect of deadline on 
the ability to meet timing constraints. Because the clients in the baseline test all had a 6 
second deadline, which turned out to be a medium length deadline, this test examined short 
deadlines (4 seconds), and long deadlines (8 seconds). 
150 

EXPRESSING AND ENFORCING TIMING CONSTRAINTS 
277 
Figure 7. Write Probability Tests 
The results of this test are displayed in Figure 6. For long deadlines, both implementations 
performed well, with the Dynamic Real-Time CORBA system performing slightly better 
than the non-real-time CORBA implementation at high system workload. As workload 
increased, both implementations missed no deadlines. This result is due to the fact that 
given a long enough deadline, all of the clients had time to complete, whether or not timing 
constraints were enforced. 
When deadlines were short, however, there was a marked difference between the perfor-
mances of our Dynamic Real-Time CORBA system and the non-real-time CORBA imple-
mentation. The non-real-time CORBA missed every deadline, while our system missed 
more at high system workload and virtually none at low system workload. This result 
illustrates how the enforcement of timing constraints enables more real-time clients to meet 
deadlines in a tight deadline situation. Because the non-real-time CORBA implementation 
schedules clients in a round-robin fashion, none of them was assigned enough CPU time to 
complete. 
Write Probability Tests. In order to illustrate how resource contention affects the system's 
ability to meet timing constraints, we varied the write probability of clients accessing the 
server. The baseline test used a medium write probability of 50%. Therefore, this suite 
of tests examined the effect of low write probability (0%), in which none of the clients 
requested write locks on the server, and high write probability (100%), in which every 
client requested a write lock. 
The results of this test are illustrated in Figure 7. It is clear, again, that the Dynamic 
Real-Time CORBA system missed fewer deadlines than the non-real-time CORBA imple-
mentation. One result that might seem surprising is that under high system workload, both 
systems missed more deadlines when clients requested only read locks, than when clients 
requested only write locks. This is surprising because one would expect that the blocking 
involved in write locking would cause more deadlines to be missed. In the non-real-time 
CORBA implementation, the explanation for this result lies in the fact that when one client 
holds a write lock, and blocks the others, the client holding the lock has an advantage over 
151 

278 
WOLFEET AL. 
the others in a round-robin scheduling scheme. That is, while the client with the lock holds 
the lock, it will be the only execution that can run, and therefore it will be likely to meet 
its deadline. In the case of the Dynamic Real-Time CORBA system, the writing clients 
miss fewer deadlines than the reading clients only at the highest system workload. This is 
because in this test, all clients started at the same time and had the same deadline. Thus, un-
der earliest-deadline-first, each client ran at the same priority, and therefore the scheduling 
policy reverted to round-robin. 
5. Conclusion 
This paper has presented the Dynamic Real-Time CORBA system, which is based on the 
desired features specified by the OMG's Real-Time SIG for CORBA. The focus of our work 
has been on the expression and enforcement of timing constraints on end-to-end client/server 
interactions. Clients can express timing constraints through TDMls and the system enforces 
the timing constraints through various extensions and additions to the CORBA standard. 
The Global Priority Service allow all CORBA requests to be scheduled at all points in the 
distributed system according to the same (real-time) policy. The Real-Time Concurrency 
Control Service provides CORBA object-level locking with bounded priority inversion. 
The Real-Time Event Service enforces the distribution of real-time events in priority order 
with real-time enforcement of event response time. The Global Time Service provides a 
common notion of time across the system. 
The performance results presented here demonstrate the overhead involved with several 
aspects of the implementation as well as the ability of the Dynamic Real-Time CORBA 
system to enforce expressed timing constraints. Because the prototype implementation 
includes two nodes, and has other system resource limitations, the results of the tests must 
be seen as proof of concept and not as definitive results of the design of the system. Full-scale 
development will be performed by companies to which we have provided the prototype, 
including: lona Technologies and Tri-Pacific Inc. 
The Dynamic Real-Time CORBA system provides the groundwork for a full dynamic 
Real-Time CORBA design. However, there is still work to be done. Currently, the schedul-
ing heuristic uses only importance and deadline information in the calculation of the global 
priorities. We are investigating which other Quality of Service (QoS) parameters can be fac-
tored in as scheduling parameters and how to use them to generate the transitive priorities. 
Performance polymorphism, another form of QoS enforcement where the ORB decides 
which method of a server to invoke based on specified QoS parameters and current system 
conditions, is another area of current interest. nother area of current work is in Real-Time 
Concurrency Control Service, where we are incorporating explicit locking in addition to 
the implicit locking described in Section 3. We are also extending the Real-Time Concur-
rency Control Service to use our results in object-based semantic real-time concurrency 
control (DiPippo, 1993), (Squadrito, 1996), (DiPippo, 1997), where method-level locks, 
whose compatibilities are semantically defined, are employed. 
Tackling the substantial requirements posed by using CORBA in a real-time environment 
is a monumental undertaking, but necessary if standard, open, distributed computing en-
vironments are to be used in real-time applications. Work that has been done on porting 
CORBA products to real-time operating systems, and on using high-performance CORBA, 
152 

EXPRESSING AND ENFORCING TIMING CONSTRAINTS 
279 
is necessary for supporting some aspects of real-time, but neglects expression and enforce-
ment of distributed end-to-end real-time constraints. The results presented in this paper are 
important steps towards achieving this goal. 
Acknowledgments 
This work is supported by the U.S. Office of Naval Research grant NOOOl496 1040 1. We 
thank Bhavani Thurasingham and John Maurer of MITRE Corporation, and Peter Krupp 
of Iona Technologies for their insights and pioneering work on real-time CORBA. We also 
thank the members of the OMG Real-Time Special Interest Group for their dedicated and 
sound work in deriving the Real-Time CORBA specification. 
References 
Bensley, E., et. aI. Object-oriented approach for designing evolvable real-time command and control systems. In 
The 1996 Workshop on Real-Time Dependable Systems, February 1996. 
Chorus Systems. Chorus/COOL-ORB R3 prodnct description. Technical Report CSITR-95-157.3, June 1996. 
DiPippo, Lisa B. Cingiser and Victor Fay Wolfe. 
Object-based semantic real-time concurrency control. 
In 
Proceedings of IEEE Real-Time Systems Symposium, December 1993. 
DiPippo, Lisa Cingiser and Victor Fay Wolfe. Object-based semantic real-time concurrency control with bounded 
imprecision. IEEE Transactions on Knowledge and Data Engineering, 9(1):135-147, Jan-Feb 1997. 
DiPippo, Lisa Cingiser, Victor Fay Wolfe, Levan Esibov, Gregory Cooper, Ramachandra Bethmangalkar, Russell 
Johnston, Bhavani Thuraisingham and John Mauer.. 
Scheduling and priority mapping for static real-time 
middleware. Real-Time Systems Journal. To appear 1999. 
Feng, W., U. Syyid and 1.w.-S. Liu. Providing for an open real-time CORBA. In Proceedings of the 1997 IEEE 
Workshop on Middleware for Distributed Real-Time Systems and Services, San Francisco, CA, December 1997. 
Harrison, T., A. Gokhale, D. Schmidt, and G. Parnlkar. 
Operating system support for a high-performance, 
real-time CORBA. In International Workshop on Object-Orientation in Operating Systems: IWOOOS 1996 
Workshop, Seattle, WA, October 1996. 
Krupp, P., Alice Schafer, Bhavani Thuraisingham, and Victor Fay Wolfe. On real-time extensions to the common 
object request broker architecure. In Proceedings of the Object Oriented Programming, Systems, Languages, 
and Applications (OOPSLA) '94 Workshop on Experiences with the Common Object Request Broker Architecture 
(CORBA), Sept. 1994. 
The Realtime Platform Special Interest Group of the OMG. CORBAIRT white paper. 
ftp site: ftp:l/ftp.osaf.org/whitepaperlTempa4.doc, Dec 1996. 
OMG. CORBAservices: Common Object Services Specification. OMG, Inc., 1996. 
Pallack, Robert. 
A study and development of real-time corba on atm. 
Technical Report URI-TR-97-255, 
University of Rhode Island Dept. of Computer Science, May 1997. Masters' Thesis. 
IEEE POSIX. IEEE POSIX lO03.lc Threads API. 1995. 
Rajkumar, Ragunathan. 
Synchronization in Real-Time Systems: A Priority Inheritance Approach. 
Kluwer 
Academic Publishers, Boston, MA, 1991. 
Squadrito, M., Bhavani Thurasingham, Lisa Cingiser DiPippo, and Victor Fay Wolfe. Towards priority ceilings 
in semantic object-based concurrency control. In 1996 International Workshop on Real-Time Database Systems 
and Applications, March 1996. 
TriPacific Software at www.tripac.com. 
Wohlever, Steven C. Concurrency control in a dynamic real-time distributed object computing environment. 
Technical Report URI -TR-97 -253, University of Rhode Island Dept. of Computer Science, May 1997. Masters' 
Thesis. 
Wolfe, V.F., John Black, Bhavani Thuraisingham and Peter Krupp. Towards distributed real-time method invoca-
tions. In Proceedings of the International High Performance Computing conference, Dec. 1995. 
153 

280 
WOLFEETAL. 
Wolfe, V.E, Lisa Cingiser DiPippo, Roman Ginis, Michael Squadrito, Steven Wohlever, Igor Zykh, and Russell 
Johnston. 
Real-time CORBA. In Proceedings of the Third IEEE Real-Time Technology and Applications 
Symposium, June 1997. 
Zykh, Igor. Timed distributed method invocations in CORBA. Technical Report URI-TR-97-254, University of 
Rhode Island Dept. of Computer Science, May 1997. Masters' Thesis. 
154 

~& The International Journal of Time-Critical Computing Systems, 16, 281-313 (1999) 
~ © 1999 Kluwer Academic Publishers, Boston. Manufactured in The Netherlands. 
To Schedule or to Execute: Decision Support and 
Performance Implications 
BABAK HAMIDZADEH 
Department of Electrical & Computer Engineering, University of British Columbia, 
Vancouver, BC, V6T lZ4, Canada 
YACINEATIF 
Information Communication Institute of Singapore, Nanyang Technological University, Singapore 
KRITHI RAMAMRITHAM 
Department of Computer & Information Science, University of Massachusetts, Amherst, MA 01003, U.S.A. 
Abstract. This paper addresses a fundamental trade-off in dynamic scheduling between the cost of scheduling and 
the quality of the resulting schedules. The time allocated to scheduling must be controlled explicitly, in order to 
obtain good-quality schedules in reasonable times. As task constraints are relaxed, the algorithms proposed in this 
paper increase scheduling complexity to optimize longer and obtain high-quality schedules. When task constraints 
are tightened, the algorithms adjust scheduling complexity to reduce the adverse effect of long scheduling times 
on the schedule quality. We show that taking into account the scheduling time is crucial for honoring the deadlines 
of scheduled tasks. We investigate the performance of our algorithms in two scheduling models: one that allows 
idle-time intervals to exist in the schedule and another that does not. The model with idle-time intervals has 
important implications for dynamic scheduling which are discussed in the paper. Experimental evaluation of 
the proposed algorithms shows that our algorithms outperform other candidate algorithms in several parameter 
configurations. 
Keywords: real-time tasks, dynamic scheduling, scheduling time 
1. Introduction 
Real-time task scheduling is characterized by sequencing a set of tasks and assigning system 
resources to comply with each task's time constraints. Based on the time at which scheduling 
is performed, real-time scheduling algorithms have been divided into two categories, namely 
static and dynamic. Static algorithms determine a fixed schedule off-line prior to the start of 
problem solving. Such approaches require complete a priori knowledge of tasks. A static 
schedule may lead to poor utilization of CPU and/or deadline loss if a priori knowledge 
of tasks is not accurate. Dynamic algorithms (Mok, 1983; Sprunt, Sha, and Lehoczky, 
1989; Sprunt, Lehoczky, and Sha, 1988; Sha, Goodenough, and Ralya, 1988; Hong and 
Leung, 1988; Schwan andZhou, 1992) produce schedules on line in the hope of using more 
comprehensive and up-to-date information about the tasks and the environment. 
Due to their on-line nature, the complexity of the dynamic algorithms directly affects their 
performance (Ramamithram and Stankovic, 1984). Using low-complexity algorithms (e.g. 
earliest-deadline-first) benefits from negligible scheduling costs, however, it may diminish 
the quality of the resulting schedules (e.g. in terms of guaranteeing deadline compliance 
(Stankovic et aI., 1995». Using more complex algorithms to search for nearer-to-optimal 
155 

282 
A 
Virtual Quality of 
Best Schedule 
Found so far 
B 
HAMIDZADEH, ATIF AND RAMAMRITHAM 
'" Real Quality uf 
Best Schedule Found so far 
Scheduling Effort 
Figure 1. Trade-off between scheduling time and schedule qUality. 
schedules, on the other hand, may incur large scheduling costs. Schedules may be delivered 
late, due to these high costs and consideration of the newly-arrived tasks may be delayed. 
Figure 1 shows hypothetical patterns in schedule quality as scheduling effort increases. The 
virtual schedule quality in the figure represents deadline-compliance, assuming negligible 
scheduling times. The real schedule quality shows deadline-compliance, while accounting 
for the finite and increasing scheduling effort. Point A, which represents the time where real 
and virtual quality start to differ, signifies a situation where the magnitude of scheduling 
time may cause violation of some task deadlines. Point B represents the optimal trade-off 
between scheduling time and schedule quality. 
Many of the existing dynamic scheduling algorithms ignore the direct effect of scheduling 
time on the schedule qUality. They do not account for the fact that, even for low-complexity 
algorithms (e.g. linear in the number of tasks), the scheduling time can become prohibitively 
large for a large number of tasks. They also do not consider that a polynomial-complexity 
algorithm with large coefficients may still result in long scheduling times that negatively 
affect deadline compliance. 
Dynamic scheduling algorithms have been proposed (Zhao and Ramamritham, 1987; 
Zhao, Ramarnritham, and Stankovic, 1987a; Zhao, Ramarnritham, and Stankovic, 1987b; 
Shen, Ramarnritham, and Stankovic, 1993) that bound the complexity of the scheduling 
algorithm in a predetermined manner. These algorithms lack formulae that automatically 
assign scheduling upper bounds according to environment parameters. The maximum 
number of backtracks in a search- space of all possible schedules has been used in (Zhao and 
Ramarnritham, 1987; Zhao, Ramamritham, and Stankovic, 1987a; Zhao, Ramarnritham, 
and Stankovic, 1987b) to bound the scheduling cost. The actual time spent on scheduling 
using this bound may vary largely from one task set to another. A small number of backtracks 
may not allow long-enough time to schedule a set of tasks with small slacks. 1 The actual 
time to exhaust the limit on backtracks may still be long enough, however, to exceed the 
slack of some scheduled tasks. For task sets with larger slacks, the algorithm may take 
a long time before exhausting the limit on backtracking. The maximum number of tasks 
156 

TO SCHEDULE OR TO EXECUTE 
283 
to schedule has also been used (Shen, Ramamritham, and Stankovic, 1993) to bound the 
scheduling complexity. This technique also suffers from large variations in scheduling time 
from one task set to another using the same bound. The actual time taken to schedule N 
tasks depends on the tightness of deadlines, availability of resources and other constraints 
in the task model. A technique that is less dependent on a particular task set was used 
in (Ramarnrithamn, Stankovic, and Shiah, 1990), which uses a preset number of times a 
feasibility test or a heuristic function is invoked as a limit on scheduling cost. 
An important point that many existing techniques ignore is that task characteristics change 
over time and that the scheduling algorithm must be able to adapt itself to these varying 
characteristics. For example, the number and the slack of a set of tasks that have arrived 
prior to time t\ may be quite different from the number and slacks of tasks that arrived after 
t\ and prior to t2. These two sets of tasks will have different scheduling requirements to 
which the scheduling algorithm should adapt. 
In this paper, we propose a set of techniques, called Time-Controlled Dynamic Scheduling 
(TCDS), to dynamically schedule a set of aperiodic, non-preemptable, real-time tasks on a 
uni-processor architecture. A main contribution of the paper is to address the problem of 
deciding when to invoke the scheduling process and what the magnitude of the scheduling 
quantum should be to guarantee deadlines of already-scheduled tasks, and to maximize the 
percentage of tasks whose deadlines are met. Another contribution is the evaluation of the 
trade-off between the scheduling cost and the schedule quality through a study of a number 
of candidate algorithms. 
The proposed techniques are based on a graph-theoretic framework for dynamic schedul-
ing (Harnidzadeh, Shekhar, and Gopinath, 1993; Hamidzadeh and Shekhar, 1993). The 
algorithms automatically control and allocate the scheduling time in order to minimize 
deadline violation of scheduled and arriving tasks. The complexity of the proposed algo-
rithms varies based on task constraints. When task constraints are relaxed, the algorithms 
increase scheduling complexity to optimize longer, so higher-quality schedules can be ob-
tained. When task constraints are tightened, the algorithms adjust scheduling complexity 
to reduce the adverse effect of long scheduling times on the schedules' quality. 
Many existing dynamic algorithms search for schedules that guarantee deadlines of all the 
tasks ready at a given time. These algorithms reject all the tasks if such a schedule cannot 
be found. At the end of a scheduling phase, TCDS executes the scheduled tasks whose 
deadlines are guaranteed to be met, even if they make up only a fraction of all the tasks that 
were available for scheduling. Scheduling of tasks that were not included in the schedule 
will be postponed until future scheduling phases. In this respect, TCDS makes a trade-off 
between scheduling time and schedule quality. It may defer scheduling of some tasks for 
the sake of controlling scheduling time, guaranteeing the deadlines of already scheduled 
tasks, and considering newly arrived tasks. 
Two scheduling models, one which allows idle-time intervals to exist in the schedule 
(Huang, Kanal, and Tripathi, 1989; Howell and Venkatrao, 1995) and one which does 
not, were investigated. Those of our algorithms that use the idle-time model perform 
scheduling during the idle intervals if the length of such intervals is large enough. The 
use of such idle intervals for dynamic scheduling and its performance implications have 
not been reported to the best of our knowledge. When the idle-time intervals are not large 
157 

284 
HAMIDZADEH, ATIF AND RAMAMRITHAM 
enough, or when the no-idle-time model is used, the algorithm allocates scheduling duration 
based on factors such as slack and/or rate of task arrival. We demonstrate the correctness 
of our algorithms and evaluate them experimentally by comparing their performance with 
another dynamic algorithm. The results show significant performance improvements for 
the proposed algorithms. 
Some of the applications that can benefit from the proposed techniques are real-time sim-
ulation, virtual reality, multimedia, and computer games. Some of these applications are 
related to one another. For example, a computer game may be played in a simulated (virtual) 
world within which data and information are retrieved and are presented using several media 
such as animation, video, audio, images and text. It is not difficult to conceive of many such 
games that are played on-line against a computer program, and that require a computer sys-
tem to present data and information in real-time, and to react to the player's actions dynami-
cally. Scheduling the moves that the computer will execute in reaction to the player's previ-
ous moves and scheduling the retrieval and presentation of the multimedia data in real-time 
can be a complex task, and one which takes a non-negligible amount of time. Due to the on-
line nature of such applications the scheduling time can directly affect performance and can-
not be ignored. The computer system in such applications, will need to control scheduling 
time directly and may have to compromise schedule quality for timeliness. For example, im-
age frames of a video segment that are predicted not to be displayed in a timely manner can be 
dropped from a sequence. This will reduce the playback resolution but will avoid distortion. 
Furthermore, not scheduling some frames that are predicted to be late will release resources 
that can be allocated more effectively to timely delivery and display of other data. Similar 
situations can occur in other applications such as flexible manufacturing, adaptive control 
and real-time transaction management, where complex problem solving is done on-line. 
In these applications too, optimally scheduling tasks may take prohibitively long and can 
adversely affect performance. The proposed techniques are aimed at demonstrating the im-
portance of accounting for scheduling complexity in meeting deadlines in such applications. 
The remainder of this paper is organized as follows. Section 2 specifies the task model 
and problem to be addressed. Section 3 describes the TCDS algorithms and Section 4 
provides an experimental evaluation of their performance. Section 5 concludes the paper 
with a summary of the results. 
2. 
Task Model and Problem 
Aperiodic tasks are tasks with arbitrary arrival times whose characteristics are not known 
a priori. The difficulty of feasibly scheduling aperiodic tasks with hard deadlines (Burns, 
1991 ; Xu and Parnas, 1993) has prompted researchers to address scheduling a class of real-
time tasks to which we refer as semi-hard real-time tasks. Semi-hard tasks are less strict 
than hard real-time tasks. They emphasize the predictability of complying with a task's 
deadline. Semi-hard tasks are defined as those tasks whose deadlines must be guaranteed, 
if they are scheduled to be executed. Note that with this kind of tasks, the penalty for not 
executing a task is lower than executing that task and missing its deadline. Once a task 
is predicted to miss its deadline, in this model, the system is assumed to take contingency 
actions to prevent negative consequences of not performing that task. 
158 

TO SCHEDULE OR TO EXECUTE 
Table 1. Notation. 
Symbol 
Batch 
Ii 
pj 
aj 
Sj 
dj 
te 
Q, 
AQ, 
t, 
te 
RQ, 
SSj 
sej 
aSi 
aej 
Slackj 
Feasible Ii 
Eligible Tj 
Definition 
A set of tasks to schedule 
A Task 
Worst-case processing time of Ii 
Arrival time of Ii 
Earliest start-time of Tj 
Deadline of T; 
Current time 
Allocated scheduling quantum (Upper bound) 
Actual duration of scheduling (A Q, :s Q,). 
Time at which scheduling starts. 
The time at which scheduling ends. (te = t, + A Q,) 
The remaining time of scheduling. (R Q, = Q, - (te - t,)) 
Scheduled start time of T; . 
Scheduled end time of Tj. 
Actual start time of Tj. (asj = te + SSj) 
Actual end time of Tj. (aej = te + sej) 
The maximum time by which the start of T; 's execution can be 
delayed from time te, without missing its deadline. 
(T; E Batch) /\ (asj :::: Sj /\ aej :s dj) 
(T; E Batch) /\ (asj :::: Sj) 
285 
As an example of such tasks, consider a virtual reality or multimedia application in which 
the scenes are updated or video segments are displayed in response to an agent's actions 
or requests. In these applications the scenery or image frames of video segments must be 
displayed and updated at an acceptable rate (e.g. 30 frames/Sec.) and must be displayed 
at regular intervals (i.e. the time interval between displaying frames must remain close to 
constant). Thus, associated with each frame is a deadline at/by which that frame must 
be displayed, otherwise the video or animation will be distorted. In these applications 
discarding a frame (up to a certain number) that is predicted to miss its deadline is often 
better than displaying that frame despite its deadline violation. Discarding a frame that 
is known to miss its deadline releases resources (e.g. bandwidth) that would uselessly be 
allocated to that frame, and more importantly, avoids distorting the video or animation 
playout. Similarly in the virtual reality application, dropping some frames when updating 
the scene is better than showing all frames but not in real time. Similar situations can arise 
in other applications such as manufacturing where safety is an issue. As an example of such 
applications, consider a robotic arm sub-system that is required to schedule and execute, in 
time, a sequence of actions that place that arm in a spot where material is released to the 
robot. The arm sub-system must predict its inability to schedule and execute a sequence of 
actions by the deadline and must inform the system at large, ahead of the deadline, about 
the deadline violation. The system can then stop all operations as a contingency plan to 
prevent negative consequences of spilling or dropping the material. 
In this paper, we address the problem of scheduling a set T of n aperiodic, non-preemptable, 
semi-hard real-time tasks with earliest start times and deadlines on a uniprocessor archi-
tecture. Each task T; in T is characterized by a processing time Pi, arrival time aj, earliest 
159 

286 
HAMIDZADEH, ATIF AND RAMAMRITHAM 
Outcome 
Positive 
Negative 
:::: 
Hit Ratio or 
.S:; 
True 
Scheduled and Missed 
... 
Deadline Compliance 
I.l 
~ 
~ False 
Rejected 
Q... 
Figure 2. Real-time task classification. 
start time or ready time Si and a deadline di (See Table 1 for definition of these and other 
notation). We selected this hard problem (Lenstra, Ronnooy, and Bruchker, 1977) to eval-
uate our algorithms' on-line optimization capabilities in domains where simple algorithms 
(e.g. earliest-deadline-first) fail to provide the necessary deadline compliance guarantees. 
A schedule is defined to be feasible, if all the tasks included in that schedule are feasible. 
A schedule is eligible, if all the tasks in the schedule are eligible. If a schedule includes 
all the tasks in the batch (See Table 1 for the definition of a batch), then it is considered to 
be complete. Otherwise, it is referred to as a partial schedule. We use the framework of 
Figure 2 to clarify our interpretation of some concepts and to discuss the objectives of the 
research discussed in this paper. 
The figure compares the prediction of an algorithm in meeting a task's deadline and the 
actual event or outcome of that prediction (i.e. whether the task's deadline was actually met 
or whether the deadline was missed when the task was executed). Based on the combination 
of predictions and their outcomes, we identify three important categories, namely "True-
Positive," "True-Negative," and "False" or "Rejected." 
True-Positive tasks are those tasks which were predicted by the algorithm to be feasible and 
they, indeed, met their deadlines. Tasks in this category represent a correct prediction and 
commitment to execution on the algorithm's part. In the remainder of the paper, we refer to 
terms such as deadline compliance and hit ratio as the percentage of tasks that belong to the 
True-Positive category. True-Negative tasks are those tasks which were predicted by the al-
gorithm to be feasible but they missed their deadlines when they were executed. Tasks in this 
category represent incorrect prediction on the algorithm's part. In the remainder of this pa-
per, we refer to scheduled-and-missed tasks as those which belong to the True-Negative cat-
egory. The rejected tasks are predicted to miss their deadlines and are never executed. Thus, 
in this framework deadlines of rejected tasks and True-Negative tasks are missed. Note, 
however, that the missed deadlines of tasks in the latter category may have more significant 
consequences than the missed deadlines of the former category, particularly for semi-hard 
real-time tasks. Based on the above framework, our objectives can be formulated as follows: 
• 
Minimize (to zero) the number of scheduled-and-missed (i.e. True-Negative) tasks. 
• 
Minimize the number of rejected tasks. 
• 
Minimize the scheduling cost. 
160 

TO SCHEDULE OR TO EXECUTE 
287 
ts 
te 
(a) I 1 Q~ 
T} 
1 
T2 
1 
1 PI 
1 
4 5 6 
7 8 
9 10 II 12 13 14 15 16 
is 
te 
I 
Qs I T} 
!21 
T 
(b) 
1 
1 
1 
1 
1 
13 1 
1 
4 5 6 
7 8 
9 \0 11 12 13 14 15 16 17 
Figure 3. Example schedules with different scheduling durations. 
The first objective aims at ensuring the reliability of the scheduling process by guaran-
teeing the deadlines of the scheduled tasks. A consequence of the first two objectives will 
be maximized deadline compliance or hit ratio. 
We discuss some of the important issues addressed in this paper through an example. 
Table 2 provides information about a set of tasks to be scheduled. Figure 3 shows two 
different scheduling scenarios. In Figure 3(a), scheduling lasts for 3 time units and takes 
as a batch the first four tasks T1, T2, T3 and T4. The resulting partial schedule consists of 
tasks T1, T2, and T3. As is shown in the example, additional tasks (e.g. Ts, T6, and T7) may 
arrive during the scheduling phase. Scheduling of T4, Ts, T6, and T7 will be postponed to 
future scheduling phases. The schedule in this figure results in violation of T3'S deadline. 
Note that it would be extremely important to know the duration of a scheduling phase, so 
that deadline violation of scheduled tasks could be detected during scheduling and prior 
to start of the tasks' execution. In this example, if we did not know Q., then we would 
not be able to predict T3'S deadline violation. This kind of violation would make T3 a 
True-Negative task. In Figure 3(b), scheduling for an additional time unit will result in 
violation of all scheduled tasks' deadlines. Notice also that, due to a longer scheduling 
phase, additional tasks may arrive and that they may miss their deadlines. The schedules 
resulting from the two scheduling phases in parts (a) and (b) of the figure may not be the 
same (i.e. they may choose different tasks and/or sequence them differently). Thus, it is 
very difficult to judge whether additional scheduling will improve deadline compliance or 
hinder it. It is clear from this example that optimizing the decision about when to schedule 
and for how long is difficult. The difficulty of making such decisions optimally has been 
addressed more formally in our previous work (Hamidzadeh and Shekhar, 1993). 
3. Time-Controlled Dynamic Scheduling (TCDS) 
In a system employing TCDS, scheduling and execution are interleaved as phases of schedul-
ing followed by execution of the result of each scheduling phase. In this section, we first 
introduce the scheduling models used in TCDS algorithms. We then specify the basic 
steps in a scheduling phase of TCDS. The discussion of feasibility checking mechanisms 
161 

288 
HAMIDZADEH, ATIF AND RAMAMRITHAM 
Table 2. Example tasks. 
Fig.3(a) 
Fig.3(b) 
Task 
ai 
Pi 
Si 
di 
SSj 
sej 
aSi 
aej 
aSj 
aej 
T} 
I 
2 
6 
9 
0 
2 
7 
9 
8 
10 
T2 
2 
2 
8 
II 
2 
4 
9 
II 
10 
12 
T3 
3 
4 
10 
14 
4 
8 
II 
15 
12 
16 
T4 
4 
3 
11 
20 
T5 
5 
1 
5 
8 
T6 
6 
2 
6 
16 
T7 
7 
7 
17 
in TCDS algorithms will then follow. Mechanisms for allocation and control of scheduling 
time are discussed thereafter. Finally, we discuss TCDS algorithms' ability to guarantee 
deadlines of scheduled tasks and discuss some implementation issues. 
3.1. 
Scheduling Model 
Scheduling in TCDS is represented as the problem of incrementally searching for a feasible 
schedule in a graph representation G(V,E) of the task space. The nodes Vi E V in G represent 
partial schedules and the edges (Vi, Vj) E E represent extending the partial schedule of a 
node by one task. At each level of G, a task is added to the sequence of previously scheduled 
tasks to incrementally build up the schedule. A constraint on adding a task to the schedule 
is that the new schedule, after adding the task, should remain feasible. Thus, at each level, 
feasibility tests are applied to different nodes to identify the valid tasks that can be added 
to the partial schedule. The incremental schedule construction allows the algorithm to 
produce a partial schedule which is feasible at any point during scheduling. This allows 
TCDS to be interrupted at the end of any iteration and still produce feasible schedules. 
Complete schedules, if they exist, will be at the leaf nodes of G. An example task-space 
for a set of tasks T = {TJ, T2 , T3 , T4 } is shown in Figure 4 (Zhao and Ramamritham, 1987; 
Zhao, Ramamritham, and Stankovic, 1987; Stankovic and Ramamritham, 1987; Bratley, 
Florian, and Robillard, 1971). The choice of feasibility tests can change the scheduling 
characteristics in interesting ways. In the following, we discuss two different strategies for 
designing feasibility tests. 
Tho main classes of algorithms can be recognized. In one class, feasibility checking is 
based on the ability to schedule without leaving idle-time intervals in the schedule. In this 
model, a task is ineligible to be scheduled if it is not ready at the time it is considered to start. 
This leads to more stringent tests on tasks and may cause some ineligible tasks to become 
infeasible when considered later. However, it will increase CPU utilization by disallowing 
idle times. The other class of algorithms allows idle-time intervals to exist in the schedule 
by postponing the tasks' start of execution until they are ready. The algorithms in this class 
relax the feasibility test (i.e. more tasks will be eligible to be scheduled), however, they 
may decrease CPU utilization by allowing idle-time intervals to exist in their schedules. 
162 

TO SCHEDULE OR TO EXECUTE 
289 
I-;:;:;-;:;---:;;;-~I--- Pal1ial Schedule 
Remaining T(l~ks 
Figure 4. Example: Search Space for scheduling T = IT!. T2. T3 , T4}. 
ts 
te 
(a) I I Q~ 
T1 ~ 
T2 
T3 ~ 
I T41 
I 
I 
I 
I 
I 
I .• 
4 5 
6 
7 
8 
9 lO II 12 13 14 15 16 17 18 
19 20 21 22 23 time 
ts 
te 
~ 
Idle interval 
(b) I I Q~ 
T1 
T3 
T2 I 
I 
I 
I 
I 
I 
I 
I 
• 
4 5 
6 
7 8 
9 10 11 12 13 14 15 16 17 
time 
Figure 5. Example schedules using different models. 
We note that in this class of algorithms, postponing a task's scheduled time of execution, 
can render other tasks infeasible. 
Figure 5 and Table 3 provide an example to demonstrate the differences between the two 
scheduling models. Figure 5(a) shows example of a schedule resulting from the model that 
allows idle-time intervals to exist in the schedule. In this model, task T2 is eligible to be 
scheduled after T 1. However, since T2 will not be ready to execute immediately after T1, its 
execution will be delayed until after its earliest start time. Figure 5(b) shows example of a 
schedule resulting from the model without idle times. T 2 in this model is considered not to 
be suitable to be executed after T 1, since this task will not be ready to execute immediately 
after T 1. T 4 is also not ready to be scheduled after T 1. Hence, T 3 is the only eligible 
task to be scheduled after TJ, since this task is ready to execute after T1. Note that (as is 
163 

290 
HAMIDZADEH, ATIF AND RAMAMRITHAM 
Table 3. Example tasks. 
With Idle Time 
Without Idle Time 
Task 
aj 
pj 
Sj 
di 
SS; 
sei 
aSi 
aei 
SS; 
sei 
aSi 
aej 
TJ 
I 
2 
7 
9 
0 
2 
7 
9 
0 
2 
7 
9 
T2 
2 
2 
11 
15 
4 
6 
11 
13 
6 
8 
13 
15 
T3 
3 
4 
9 
17 
6 
10 
13 
17 
2 
6 
9 
13 
T4 
4 
3 
20 
25 
13 
16 
20 
23 
shown in this example) T 4 may be reconsidered for scheduling in the next phase. We would 
like to draw the reader's attention again to the importance of knowing the time by which 
scheduling will end, on the predictability of the algorithm. In later parts of this section, we 
will discuss how TCDS schedules tasks during the idle-time intervals. 
3.2. 
Scheduling Phase 
The input to each scheduling phase j is a set of tasks (i.e. Batch(j)). Initially, Batch(O) 
consists of a set of the arrived tasks. At the end of each scheduling phase j, Batch(j + 1) 
is formed by removing, from Batch(j), the scheduled tasks and tasks whose deadlines are 
predicted to be missed, and by adding the set of tasks that arrived during scheduling phase 
j. In a scheduling model with no idle times, ineligible tasks which were not ready to be 
scheduled in scheduling phase j are postponed to be scheduled in scheduling phase (j + 1) 
(they will be included in Batch(j + 1)). 
In the following discussion, a node in task-space G is defined to be generated, when 
enough memory for a data structure representing that node is allocated and when the node 
and its attributes are evaluated and stored in the data structure. An evaluation of a generated 
node consists of computing the schedule that the node represents and performing a test to see 
whether the schedule is feasible/eligible. Another evaluation may consist of computation 
of a heuristic function associated with that node which indicates the priority value of that 
node. A node is defined to be expanded when its successor nodes are generated. The 
successors of a node Vi are the set of all the k nodes {VI, ••. , Vk} which are connected to 
that node via direct links (Vi, VI),··· (Vi, Vk). 
Scheduling phase j starts at the root node (i.e. empty schedule) of G which represents the 
current partial schedule, CPS. In one iteration of a scheduling phase j, CPS is expanded and 
its feasible/eligible successors are added to the front of a list of candidate nodes, CL. The 
nodes in CL are prospects for being extended further to include more tasks while remaining 
feasible. If a heuristic function exists to evaluate nodes, CL is then sorted according to 
heuristic values with the highest-priority node in front. In the following iterations, the first 
node in CL is removed from the list and is expanded as the new CPS. 
It may so happen that none of the successors of an expanded node pass the feasibility test. 
In such a situation a dead-end is reached and no new nodes are added to CL. The search, in 
this situation, will backtrack to explore other candidates by expanding the first node in CL 
which, in this case, is not a child of CPS and comes from another branch in G. The iterations 
164 

TO SCHEDULE OR TO EXECUTE 
IF (tc + RQij) + sSI ~ sl) 
THEN T[ is ineligible 
ELSE 
IF (tc+RQs(j) + sel ~ dl ) 
THEN T[ is feasible 
ELSE T[ is infeasible 
Figure 6. Feasibility test of Tcns. 
IF (tc+ RQij) + 
sel::S; d,) 
THEN T[ is feasible 
ELSE T[ is infeasible 
Figure 7. Feasibility test of TCDS-l. 
291 
of a scheduling phase continue until either a leaf node is reached, until CL becomes empty, 
or when the limit, Qs(j), on the length of scheduling phase j is reached. An empty CL 
signifies a situation in which there are no more feasible schedules to examine. 
The result of each scheduling phase j is a feasible partial or complete schedule Sj. During 
the execution phase j, the tasks in Sj are executed. A Pseudo-code of TCDS is given in the 
appendix at the end of the paper. Next, we discuss TCDS 's feasibility checking mechanisms. 
3.3. 
Feasibility Checking with and without Idle Times 
TCDS predicts deadline violation of tasks based on a feasibility test that takes into account 
the scheduling time of a phase, as well as the current time, deadline, earliest start time and 
processing time of tasks. Accounting for the scheduling time in the feasibility test ensures 
that no task will miss its deadline due to scheduling time. Figure 6 shows the test for adding 
a task 'f[ to the current partial schedule in scheduling phase j, for the scheduling model 
with no idle times. Note that in this test we mark tasks that are not ready for execution, due 
to the constraint on their start times, as ineligible. The alternative to this scheduling model 
is to permit idle-time intervals in the schedule by delaying the execution of tasks until their 
start time. 
Another version of TCDS, namely TCDS-I, considers the alternative of scheduling with 
idle-times allowed. TCDS-I considers all tasks to be eligible. Figure 7 shows the test for 
adding a task 'f[ to the current partial schedule in scheduling phase j, for the scheduling 
model that permits idle times. A task 'f[ which succeeds the deadline test will be scheduled 
to start its execution at s" if (teCi) + ss,) ::: SI, or at (te(j) + ssz), if (te(j) + SS/) > SI. 
165 

292 
HAMIDZADEH, ATIF AND RAMAMRITIIAM 
This scheduling strategy is likely to decrease the amount of backtracking since fewer dead-
end paths are expected to be encountered using this test. Fewer dead-ends are encountered 
because this test relaxes the restriction on eligibility of tasks, i.e. no task's scheduling is 
denied due to that task's ineligibility. The drawback, however, is that it introduces delays in 
the schedule which reduce the CPU utilization. To increase utilization, TCDS-I performs 
scheduling during the idle intervals. In the following, we discuss techniques in TCDS and 
TCDS-I for allocating the time duration of scheduling phases. As part of this discussion, we 
shall also introduce TCDS-I's mechanisms for performing scheduling during idle intervals. 
3.4. Allocation and Control of Scheduling Time 
TCDS and TCDS-I use a novel on-line parameter tuning and prediction technique to deter-
mine the time and duration of a scheduling phase. The algorithms continually self-adjust 
the allocated time Qs (j) of scheduling phase j using a set of criteria based on parameters 
such as slack, arrival rate, idle-time intervals, or a combination thereof. The motivation for 
designing such criteria is to allocate longer times to scheduling when the task slacks are 
large, or when arrival rates are low. When the slacks are small or arrival rate is high, on 
the other hand, scheduling durations are shortened to honor the deadline of scheduled tasks 
and to examine arriving tasks more frequently. If idle-time intervals exist in the schedule, 
the criteria allow the algorithm to schedule tasks during these intervals to increase CPU 
utilization. We now study several ways of assigning Qs(j). Consider: 
Qs(j) ::::; Min[Slack/ 111 E Batch(j)] 
(SCI) 
This criterion is aimed at placing an upper bound on the amount of time allocated to 
scheduling phase j such that none of the deadlines of tasks in the current batch is violated 
due to scheduling cost. Another criterion for assigning Qs(j) is: 
(SC2) 
SC2 aims at stopping a scheduling phase sooner if arrival rates are higher. This allows us 
to account for incoming tasks soon after their arrivals. In the expression of SC2, )., denotes 
the task arrival rate and k is a coefficient that can be set to control the average number of 
task arrivals during a scheduling phase. Low arrival rates will result in longer scheduling 
phases. This allows the algorithm to search longer for higher-quality schedules and to 
allow a reasonable number of tasks to arrive to be included in the next batch. A criterion 
for assigning Qs (j) using a combination of the previous criteria (i.e. SC 1 and SC2) is: 
Qs(j) ::::; Min[SCl, SC2] 
(SC3) 
The motivation behind SC3 is to account for a combination of constraints on schedul-
ing complexity, so that when one constraint is relaxed, another more strict constraint can 
dominate the control of scheduling complexity. 
As mentioned earlier, TCDS-I is a version of TCDS that uses the scheduling model 
with idle times. The allocated time of scheduling phase j is controlled in TCDS-I by the 
166 

TO SCHEDULE OR TO EXECUTE 
293 
following criterion: 
IF NOT (idle-time) THEN SC3 ELSE (Qs(j) ::: idle-time) 
(SC4) 
TCDS-I combines SC3 with another criterion based on the idle-time available in the 
schedule. In the expression of SC4, idle-time refers to the length of an idle-time interval. 
Note that such an interval may (Le. idle-time > 0) or may not exist (i.e. idle-time = 0) in 
the schedule. If the algorithm encounters a gap in the current schedule, it switches back 
to scheduling. A lower bound on the size of the gap can be imposed to prevent scheduling 
when the gaps are too small. This lower bound can account for context-switching times 
and other overhead associated with switching between task execution and scheduling. In 
the absence of idle-time gaps in the schedule, TCDS and TCDS-I perform similarly. 
Note that, TCDS-I can also take advantage of idle times in the schedule that may result 
when tasks finish earlier than their scheduled finish times. This situation is highly likely to 
occur in practice, since most real-time scheduling algorithms allocate CPU times according 
to the worst-case task execution times. 
3.5. Deadline Guarantee 
Next, we provide a guarantee that, using the above feasibility checking mechanisms and 
criteria for control and allocation of scheduling time, the number of scheduled-and-missed 
(i.e. True-Negative) tasks is zero for TCDS and TCDS-I. 
THEOREM The semi-hard tasks scheduled by TCDS and TCDS-I are guaranteed to meet 
their deadlines, once started. 
Proof: The proof is by contradiction. Let us assume that a task 1[ E Batch(j), is scheduled 
during the jth phase but once started, it misses its deadline. This assumption leads to the 
following condition: 
(1) 
Here we are assuming that the execution of the first task in a schedule will start immediately 
after scheduling ends. On the other hand, the mechanisms for control and allocation of 
scheduling time in TCDS and TCDS-I ensure that: 
(2) 
Combining (1) and (2) leads to: 
(3) 
The feasibility test performed at time tc ensures that: tc + R Qs(j) + set::: d/, contradicting 
inequality (3). Therefore, our assumption regarding deadline violation of 1[ is false, which 
proves the theorem. 
• 
167 

294 
HAMIDZADEH, ATIF AND RAMAMRITHAM 
3.6. Implementation Issues 
In this section we discuss implementation issues regarding the task queues, and invocation 
patterns of the scheduler, among others. The system consists of two queues namely, a job 
queue and a ready queue. When the tasks are first submitted to the system, they are placed 
on the job queue. Some of the tasks are later loaded into memory. A mechanism is required 
to reject tasks on the job queue that miss their deadlines by the time they are considered for 
loading into memory. To reduce unpredictable I/O operations, once a task is removed from 
the job queue and is loaded into memory, it will not be swapped out to get back on the job 
queue. Furthermore, virtual memory is disabled, so that the process is loaded into memory 
in its entirety. Memory is allocated to processes in contiguous segments in variable-size 
partitions. 
Loaded tasks that are ready to execute on the CPU are placed on the ready queue. We 
regard the ready queue as consisting oftwo levels. One level (level one) holds the tasks that 
are ready and are waiting to be scheduled. The other level (level two) holds the scheduled 
tasks. Upon system start up, all tasks are at level one. Upon invocation of the scheduler, 
all tasks at level one are considered as a batch. As discussed earlier, a number of tasks in 
the batch will be scheduled. These tasks are placed, in order of priority, on level two of the 
queue. Ineligible tasks remain at level one to be considered again later. 
The scheduling time quantum is determined by the SC's. as mentioned in previous 
sections. Once the scheduler completes execution, execution of tasks on level two of the 
ready queue begins. Tasks are dispatched from the head of level two of the queue and are 
executed non-preemptively. While scheduled tasks on level two are executed, new tasks 
may arrive into the system. After all tasks on level two are executed, newly arrived tasks are 
added to level one of the ready queue. The scheduler is then invoked to consider the tasks 
on level one again for scheduling. Note that in this form of batch scheduling, the scheduler 
is invoked less frequently which reduces over head of switching between the scheduler and 
the tasks. 
4. Experimental Evaluation 
In this section, we evaluate TCDS algorithms through a number of performance-comparison 
experiments. The experiments are organized as follows: 
• 
In one set of experiments, we evaluate the effect of preset bounds on scheduling cost of 
a limited-backtracking algorithm. We show, in these experiments, that finding a preset 
bound that performs well under all parameter settings is difficult. 
• 
In another set of experiments, we evaluate the effect of different criteria (i.e. SCI, SC2, 
and SC3) for controlling scheduling time in TCDS. Our goal is to see whether we can 
find a simple, hybrid formula that performs well under different conditions such as high 
arrival rates and/or low degrees of laxity. 
• 
A set of experiments were designed to compare TCDS with the basic Earliest -Deadline-
First (EDF) algorithm. These experiments revealed that despite their negligible schedul-
168 

TO SCHEDULE OR TO EXECUTE 
295 
ing costs, the simple algorithms do not perfonn well in task models with complex time 
constraints. 
• 
Experiments were also designed to compare TCDS with the limited-backtracking al-
gorithms. These experiments revealed the improved perfonnance that can result from 
using TCDS. The effect of using heuristics (e.g. nearest-deadline-first) was also inves-
tigated in these experiments. 
• 
The last set of experiments evaluates the perfonnance of TCDS and TCDS-I to reveal 
the effect of scheduling during idle intervals on perfonnance. 
Two-tailed difference-of-means tests were used to show the significance of the difference 
between the candidate algorithms. 
4.1. 
Experiment Design 
In the experiments, a Poisson process was used to create a sequence of aperiodic task 
arrivals. The time window, within which arrivals are observed, was set to 2000 time units. 
The arrival rate A ranged from 0.01 to 0.5. The tasks' earliest start times Sj are assigned a 
value selected with unifonn probability from the interval (aj, Smax), where Smax = aj + M K,. 
MK, is a parameter that controls the degree to which the si's and ai's are set apart. We 
chose 3 as the value of M for the experiments. Ks was set to 5 in the experiments involving 
TCDS, EDF and the limited-backtracking algorithms. Ks was set to 7 in the experiments 
comparing TCDS and TCDS-1. 
The processing times Pi of tasks T; are unifonnly distributed within the interval between 
1 and 50 time units. Deadlines di are unifonnly distributed in the interval (Endi , Dmax) 
where Endi is the finish time of T; assuming it starts at its specified earliest start time Si 
(Le. Endi = Si + Pi), and Dmax is a maximum value a deadline can have and is calculated 
as Dmax = Endj + SF Kd. SF Kd is a parameter that controls the degree of laxity in task 
deadlines. Kd is fixed to 5 in our experiments and the Slack Factor S F2 ranges from 1 to 
10. Larger SF values represent larger slack, whereas small SF values represent smaller 
slack. Another parameter is the constant coefficient k used in criterion SC2 of TCDS for 
allocating scheduling time. This parameter implies the expected task batch size for each 
scheduling phase of TCDS and was set to 5 for the experiments. 
The metrics of perfonnance in our experiments were deadline compliance or hit ratio 
(percentage of the True-Positive tasks), and scheduling effort. Deadline compliance or 
hit ratio measures the percentage of tasks which have completed their execution by their 
deadline. We measure the scheduling cost in logical time units. This time is calculated as 
ER * NG, where NG is the number of nodes (partial schedules) generated in the task-space 
G and E R is the time it takes a particular hardware platfonn to generate a node in G. Clearly 
E R is an architecture- and implementation-dependent parameter. We chose this fonnula to 
be able to measure scheduling effort in an architecture- and implementation-independent 
way. This fonnula is not only an indicator of the time complexity of the algorithms but 
(thanks to NG) it also provides insight into the memory requirements of the algorithms, as 
well. E R was set to 1 in the experiments. 
169 

296 
HAMIDZADEH, ATIF AND RAMAMRITHAM 
4.2. 
Candidate Algorithms 
In our experiments, we compare TCDS with EDF, with a set of limited-backtracking al-
gorithms and with TCDS-I. TCDS and TCDS-I algorithms were discussed in previous 
sections. In this Section, we will describe our implementation of the EDF and the limited-
backtracking algorithms. 
We note that the EDF algorithm, in its classical definition, does not take constraints on 
start time into account. It simply orders tasks based on deadlines and executes them in 
that order. When experimenting with this simplistic version of EDF, we noticed that EDF 
results in very poor performance. Few tasks were executed using this algorithm which 
satisfied their start times as well as their deadlines. In the implementation of the algorithm 
reported in the following experiments, the ready tasks are ordered based on deadlines with 
the nearest deadlines first. In executing the tasks, when a task is found not feasible, because 
the current time is earlier than its earliest start time, the system delays the execution of that 
task until the task's earliest start time and then executes it. In the experiments, we ignored 
the effect of scheduling time on performance of EDF, although we note that for large task 
sets this scheduling cost may no longer be negligible. 
In some of our experiments, we included a set of limited-backtracking algorithms. Below, 
we discuss our implementation of these algorithms. Whereas, TCDS algorithms explic-
itly bound the time allocated for scheduling, limited-backtracking algorithms limit the 
scheduling costs indirectly. Despite their differences, many of the features of the limited-
backtracking algorithms, discussed in our experiments, were inspired by the techniques 
reported in (Zhao and Ramarnritham, 1987; Zhao, Ramamritham, and Stankovic, 1987a; 
Zhao, Ramarnritham, and Stankovic, 1987b; Shen, Ramamritham, and Stankovic, 1993). 
Below, we describe the limited-backtracking algorithms. 
The search for a schedule in the limited-backtracking algorithms is performed in a task-
space G similar to that shown in Figure 4. To keep the scheduling cost low, a limited-
backtracking algorithm bounds the search complexity by specifying a preset backtracing 
level I. The search starts with the root node (i.e. empty schedule) of G as the current partial 
schedule, CPS. During an iteration, CPS is expanded by generating I of its successors. 
This is in contrast with TCDS and TCDS-I which generate all feasible/eligible successors 
of CPS during an iteration. The feasible/eligible nodes among the I successors are first 
sorted according to their heuristic values (if such a heuristic is used) with the best-value 
node in front. They are then added to the front of the candidate list, CL. In the following 
iterations, the first node in CL is removed from the list and is expanded as the new CPS. 
Sorting the successors before adding them to CL gives the limited-backtracking algorithms 
a depth-first character. Recall that in TCDS and TCDS-I the feasible/eligible successors 
are first added to CL and the entire CL is then sorted. This feature gives TCDS and TCDS-I 
a branch-and-bound character. 
If none of the I successors of an expanded node pass the feasibility test, the search will 
backtrack to explore other candidates. This is done by expanding the first node in CL which, 
in this case, is not a child of CPS and comes from another branch in G. The iterations of 
the limited-backtracking algorithm continue until either a leaf node is reached, or until 
CL becomes empty. An empty CL signifies a failure to find a complete feasible schedule. 
170 

TO SCHEDULE OR TO EXECUTE 
297 
HMI 
-- SF=1 
-- SF=4 
~O 
.-.. -. SF=5 
0 
611 
.~ 
i 
40 
20 
II 
(I 
6 
10 
Backrr3(.'kin!! level. 
Figure 8. Deadline compliance of backtracking algorithms for different levels of backtracking at laxities 3, 4 and 
5 (A = 0.03). 
Reaching a leaf signifies that a complete feasible schedule was found. If such a leaf is found, 
the algorithm announces success and the tasks in the schedule are executed. Ineligible tasks 
which were not ready to be scheduled during the current scheduler invocation are postponed 
to be scheduled in later invocations. 
4.3. 
Effect of Different Backtracking Levels on Limited-Backtracking Algorithms 
The choice of the level of backtracking I can affect performance of limited-backtracking 
algorithms significantly. In this section, we provide the results of experiments that attempt 
to test the effect of different levels of backtracking on performance of these algorithms. 
Figures 8 and 9 show the results of our experiments on the limited-backtracking algo-
rithms. Figure 8 demonstrates how the hit ratio varies with different levels of backtracking 
for different SF values. As is shown in this figure, different levels of backtracking perform 
differently under different SF values. We note that very small and very large levels of back-
tracking result in poorer performance. This is because small levels of backtracking do not 
allow the algorithm to spend enough time to search for a good-quality schedule and large 
levels of backtracking result in very large scheduling costs which can, in tum, result in poor 
deadline compliance. For SF value 3, the algorithm reaches its peak deadline compliance at 
a level of backtracking equal to 2. For SF values 4 and 5, the peak performance is reached at 
backtracking levels 7 and 2, respectively. We note that at larger SF values the performance 
does not vary as much as it does at smaller SF values for different backtracking levels. 
We also note that the larger the SF value, the larger the range of backtracking levels will 
be, for which good performance is achieved. These results demonstrate how the limited-
backtracking algorithms reach a peak performance at different levels of backtracking under 
different parameter settings. From these results we conclude that it is difficult to choose a 
preset backtracking level that performs well under all conditions. 
171 

298 
HAMIDZADEH, ATIF AND RAMAMRITHAM 
IIXI 
--
BT2 
-+-
XI) 
BT5 
--.-
BTIO 
0 
.~ 
61) 
:c 
4() 
2() 
I) 
I) 
4 
10 
Laxity 
Figure 9. Deadline compliance of backtracking algorithms BT-2, BT-5 and BT-lO for different laxities (J" = 0.03). 
Figure 9 shows a comparison of three levels of backtracking namely, 2, 5 and 10, with 
varying degrees of laxity. The curves corresponding to different backtracking levels cross 
one another at different degrees of laxity (i.e. different levels of backtracking perform 
best under different conditions). BT2 outperforms BT5 and BTtO at SF value 3, but 
performs poorly for lower SF values. BT5 outperforms BT2 and BTlO at SF value 4. This 
demonstrates the difficulty of choosing one backtracking level that performs well under all 
circumstances. For the comparison studies of later experiments, we chose backtracking 
level 2, since this level of backtracking seems to provide good performance under a variety 
of conditions. 
4.4. 
Performance of Different Criteria for Allocating Scheduling lime in TCDS 
Three criteria for controlling the time and duration of each scheduling phase in TCDS 
were discussed in previous sections: One in which the scheduling time is a function of the 
minimum slack of the tasks in a batch (labelled as SCI), another in which the scheduling 
time is a function of the arrival rate (labelled as SC2) and a third one in which the scheduling 
time is selected as the minimum of the time calculated by the other two criteria (labelled 
as SC3). Figures 10 through 13 show the results of the experiments with these criteria. 
Figures 10 and II show the performance of TCDS with different criteria as the arrival rate 
varies for SF values 4 and 8, respectively. Figures 12 and 13 show the performance of 
TCDS with different criteria as the degree of laxity varies for arrival rate values 0.1 and 0.5, 
respectively. 
As is evident in Figures 11 and 13, the A-based criterion SC2 performs better than the 
slack-based criterion SCI when arrival rates are high and degree of laxity is high. This is 
because the A-based criterion stops scheduling earlier in higher arrival rates to include the 
arriving tasks in the scheduling process more frequently. The slack-based criterion, on the 
172 

TO SCHEDULE OR TO EXECUTE 
299 
0 
'E 
i 
4n 
20 
() 
n.n 
, , 
.. 
0.2 
0.4 
Rate uf Arrival 
.... SCi 
--e-· SC2 
--
SC3 
Figure 10. Deadline compliance of TCDS using different stopping criteria for different arrival rates (SF = 4) . 
.2 e 
:E 
60 
~I 
OJ) 
...... 
0.2 
0.4 
Rate of Arrival 
....... 
SCi 
--e-· SC2 
--
SC3 
Figure i i. Deadline compliance of TeDS using different stopping criteria for different arrival rates (SF = 8). 
other hand, does not effectively account for the arriving tasks under high arrival rates. The 
slack-based criterion performs better than the A-based criterion, on the other hand, when the 
degree of laxity is low, i.e. under tight deadlines (see Figures 10 and 12). This is because 
the slack-based criterion ensures that the scheduling time does not exceed the task slacks. 
As expected, this improves deadline compliance, particularly under tight deadlines. 
An interesting result is the performance of TCDS with the combination criterion (i.e. 
SC3). The figures show that the combination criterion adapts to the dominating factor in 
the task -set to perform as well as the best of the other two criteria. This criterion performs as 
well as theA-based criterion under high arrival rates (see Figures 11 and 13). It also performs 
as well as the slack-based criterion under tight deadlines (see Figures 10 and 12). The reason 
for this behavior is that under tight deadlines the slack-based term in SC3 dominates that 
expression and under high arrival rates the A-based term dominates the expression. 
173 

300 
HAMIDZADEH, ATIF AND RAMAMRITHAM 
.--
.......... 
SCI 
~ 
.& 
. ·e·· SC2 
xu 
--
SC3 
60 
o 
.~ 
:ij 40 
20 
i , 
, 
U Lu..L....,.,~-........... ....Lw..u.L-'-'-'-'~-'....., ....... .....L.....,.JL...o......w 
o 
4 
6 
10 
Laxity 
Figure 12. Deadline compliance of TCDS using different stopping criteria for different laxities (A = 0.1) . 
....... SC1 
so 
. ·e·· SC2 
--
SC3 
60 
.~ 
.. 
£ 
40 
20 
0 
0 
2 
4 
Ii 
10 
Laxity 
Figure 13. Deadline compliance of TCDS using different stopping criteria for different laxities (A = 0.5). 
From the results of this experiment, we conclude that effective criteria for allocating 
scheduling time can be designed which are capable of adapting to different conditions to 
ensure better deadline-compliance in dynamic scheduling of aperiodic tasks. 
4.5. 
Comparison of TCDS and Base Algorithms 
In this section, we present the results of our experiments that compare the performance of 
TCDS with the combination criterion and the EDF algorithm. The results collected for 
these experiments have 99% confidence interval and 0.01 significance level. 
174 

TO SCHEDULE OR TO EXECUTE 
301 
.51 
Ei 
60 
:E 
40 
20 
, 
~ , , 
e-.e-
- - - -o. - - - _o. - - - _o. - - - _. 
0.2 
0.4 
Rate of Arrival 
Figure 14. Deadline compliance for different arrival rates (S F = 6). 
gO 
60 
.~ 40 
i 
20 
() 
Il 
4 
o. •• " 
-.. --
6 
Laxity 
,. .' 
III 
Figure 15. Deadline compliance for different laxities (J.. = 0.3). 
··e-· EDF 
-
reDS 
- ·e-· EDF 
-
reDS 
Figures 14 and 15 show the performance of the algorithms in terms of the percentage of 
the task deadlines that were met. Figure 14 shows the results as the arrival rate varies for 
SF value 6. In this figure, TCDS outperforms EDF, in terms of hit ratio, by as much as a 
factor of 2, for lower arrival rates (e.g. OJ). Although this gap narrows, TCDS continues 
to outperform EDF at higher arrival rates, as well. 
Figure 5 shows the results as the degree oflaxity varies for arrival rate value 0.3. The figure 
shows that under smaller degrees of laxity both algorithms perform poorly, however, EDF 
performs slightly better than TCDS. This we believe is due to the fact that TCDS allocates 
175 

302 
HAMIDZADEH, ATIF AND RAMAMRITHAM 
smaller amounts of time to scheduling under tight deadlines which leads to poorer schedule 
quality. We note that if EDF scheduling times were included in performance, TCDS and 
EDF would perform similarly. For reasonably high degrees of laxity (e.g. SF 2: 5), where 
it is possible to optimize without compromising solution quality, TCDS maintains a high 
level of solution quality as the degree of laxity varies. We note that for higher degrees of 
laxity, TCDS outperforms EDF by as much as a factor of 2. 
From the results of these experiments, we conclude that TCDS outperforms EDF in terms 
of deadline compliance, for a wide range of parameter values. In the following sub-sections 
we shall see that adding EDF as a heuristic to TCDS improves that algorithm's performance 
significantly. 
4.6. 
Comparison oj TCDS and Backtracking Algorithms 
In this section, we present the results of our experiments that compare the performance of 
TCDS with the combination criterion and the limited-backtracking algorithm with back-
tracking level 2 (referred to as BT2). Recall that this level of backtracking was shown to 
perform well for a wide range of parameter values selected in our experiments. As part 
of the experiments, we also show the effect of using the earliest-deadline-first (EDF) as a 
heuristic for prioritizing the tasks in the candidate algorithms. Recall that every generated 
node in G represents extending the current partial schedule CPS by a new task Tn. Using the 
EDF heuristic, the generated nodes in G are ordered based on the deadlines dn of the new 
tasks Tn, with the nearest deadlines first. The curves marked as BT-EDF and TCDS-EDF 
show the performance of algorithms using this heuristic. The results collected for these 
experiments have 99% confidence interval and 0.01 significance level. 
Figures 14 through 17 show the performance of the algorithms in terms of the percentage 
of the task deadlines that were met. As is shown in the figures, TCDS outperforms BT2 
under all parameter configurations. Figures 14 and 15 show the results as the arrival rate 
varies for SF values 4 and 8, respectively. Figure 14 shows that under tighter deadlines, 
TCDS outperforms BT2, in terms of hit ratio by as much as a factor of 20, for lower arrival 
rates (e.g. 0.1). Although this gap narrows, TCDS continues to outperform BT2 at higher 
arrival rates, as well. Adding the EDF heuristic improves the hit ratio for both TCDS and 
BT2. 
Figure IS shows that under looser deadlines, TCDS's hit ratio does not vary as greatly 
as BT2 with increasing arrival rates. As is shown in the figure, TCDS outperforms BT2 
by as much as a factor of 40 at higher arrival rates. TCDS's consistent performance under 
different arrival rates, as shown in Figure 15. is indicative of how TCDS self-adjusts the 
scheduling costs to obtain higher-quality schedules. Under low arrival rates, the algorithm 
optimizes longer to increase hit ratio. Under high arrival rates, it reduces optimization time 
to account for arrived tasks before they miss their deadlines. Adding the EDF heuristic 
improves the performance of both algorithms. This improvement is greater for BT2 than 
for TCDS. The improved performance of TCDS over BT2, however, is maintained for all 
arrival rates when the EDF heuristic is added to both algorithms. 
Figures 16 and 17 show the results as the degree of laxity varies for arrival rate values 
0.1 and 0.5, respectively. The figures show that under low and high arrival rates, TCDS 
176 

TO SCHEDULE OR TO EXECUTE 
303 
..•.. B72-EDF 
- -.-. B72 
-
TCDS-EDF 
-
TCDS 
OliO 
.~ 
tE 40 
20 
0.2 
0,4 
Rate of Amval 
Figure 16. Deadline compliance for different arrival rates (SF = 4). 
I(X) 
~---.-
..•.. B72-EDF 
1\ 
...... - .. , 
_ ...... B72 
80 
-
TCDS·EDF 
'. 
-
TCDS 
, , 
IiO 
, 
0 
, 
.~ 
, 
... 
, , 
:E 
, 
, 
40 
, • 
, 
, , 
• 
20 
, a
o -. , , , , 
0 
~a- -
n.o 
0.2 
0,4 
Rate of Arrival 
Figure 17. Deadline compliance for different arrival rates (SF = 8). 
outperfonns BT2 in tenns of hit ratio. Figure 16 shows that under low arrival rates and 
for reasonably high degrees oflaxity (e.g. SF ::: 5), where it is possible to optimize with-
out compromising solution quality, TCDS maintains a high level of solution quality as 
the degree of laxity varies. This, again, is indicative of TCDS's ability to take maximum 
advantage of available time to optimize schedules on line. Figure 17 shows that, under 
high arrival rates, TCDS outperfonns BT2 by a wide margin, as the degree of laxity in-
creases. This is due to the fact that now two levels of backtracking may mean very long 
scheduling times, because the task space becomes exponentially large as the number of 
tasks increases. 
177 

304 
HAMIDZADEH, ATIF AND RAMAMRITHAM 
HM) r--------=-::::e:=.-:::=i=::::a-r-:-.. 
:.:-:.-:-.IBn1'2;:i-E;;D)jF;:j 
Sil 
o 60 
.~ 
i 40 
20 
4 
I .-. 
I 
Laxity 
, , 
, 
, 
.--
I 
I 
, 
I " 
I 
10 
~~. - . -
B1'2 
TCDS-EDF 
-
TCDS 
Figure 18. Deadline compliance for different laxities (A = 0.1). 
J(K)r----------::;;==-=::::ell-:-.-:: .• 
=-.:-:.IB~1;:;'2~-E;;:JD;)'F~ 
so 
o 
.~ 
.~ 40 
::c 
20 
2 
4 
6 
Laxity 
, 
I , 
I 
, , , , , , 
I 
Figure 19. Deadline compliance for different laxities (A = 0.5). 
10 
...... 81'2 
_ 
TCDS-EDF 
-
TCDS 
Figures 18 through 21 show the performance ofTCDS and BT2 in terms of total scheduling 
cost. As is shown in the Figures, TCDS has lower scheduling costs than BT2 under many 
parameter configurations and shows more stability as the parameter values vary. Figures 18 
and 19 show the scheduling effort of TCDS and BT2 as the arrival rate varies for SF values 
4 and 8, respectively. The figures show that the scheduling effort of BT2 increases, in 
general, as arrival rate increases. The increase in scheduling effort in high arrival rates can 
be attributed to the fact that the scheduling complexity (e.g. size of task space) increases 
exponentially with the number of tasks. Despite the complexity of the problem, we note 
that TCDS's scheduling effort is kept at a low value compared to BT2 and is controlled 
178 

TO SCHEDULE OR TO EXECUTE 
2(XX) 
.,,'1·- - -- .. ____ a - ---. 
,.' '" " . 
' 
, 
' 
, " 
.~.I 
I, 
~ 
" I' 
" 
" " 
I~----~--~ ___ A 
I 
~ 
0.2 
0.4 
Rate of Arriva1 
Figure 20. Scheduling effort for different arrival rates (S F = 4). 
305 
..•.. BT2·EDF 
..•.. BT2 
-
rCDS-ED 
-
TCDS 
in a stable manner as laxity and arrival rate vary. This is an important characteristic of 
TCDS. 
The figures show that, under small degrees of laxity, the EDF heuristic does not re-
duce BT2-EDF's scheduling costs significantly. This is mainly because, in such condi-
tions, finding a feasible schedule is a difficult task that is likely to exhaust the limit on 
backtracking, despite ordering the tasks based on the EDF heuristic. Under higher de-
grees of laxity, however, EDF improves BT2-EDF's performance more significantly. We 
note that at low arrival rates and high degrees of laxity the EDF heuristic reduces the 
scheduling cost of BT2-EDF to lower values than that of TCDS-EDF. This is because, 
under these conditions, scheduling a complete feasible schedule is much less complex. 
In such situations, the EDF heuristic orders the tasks such that many of them will be 
feasibly scheduled without the need for much search and backtracking in the task space. 
TCDS-EDF has higher scheduling costs than BT2.EDF, under these conditions, because 
BT2.EDF examines only two nodes at each level of the task space, whereas TCDS-EDF 
examines all nodes at each level of the task space. Without the need for much backtrack-
ing, examining two nodes at each level is sufficient for reaching a leaf node in the task 
space. 
Figures 20 and 21 show the results as the degree of laxity varies for arrival rate values 
0.1 and 0.5, respectively. The figures show that the scheduling effort of BT2 increases, in 
general, as the degree of laxity increases. The increase in scheduling effort of BT2, as laxity 
increases, can be attributed to the freedom of this algorithm to schedule for a long time 
without reaching dead-end paths. We note that scheduling cost of BT2 does not continue 
indefinitely to increase with increased degrees of laxity. At high-enough degrees of laxity, 
the algorithm will reach feasible schedules quickly without having to do much backtracking. 
At those degrees oflaxity, the two algorithms are expected to perform similarly in terms of 
scheduling effort. This behavior is shown in Figure 21 for SF values 9 and 10 when EDF 
179 

306 
HAMIDZADEH, ATIF AND RAMAMRITHAM 
.. ----.----. 
/ 
/ 
,-
/ , 
/ 
.. 
o ~-.----
OJ) 
0.2 
Rate of Arrival 
I 
I 
0.4 
I 
I 
I 
/ 
/ 
I 
I 
Figure 21. Scheduling effort for different arrival rates (SF = 8). 
I 
I • 
I 
--e-' 
....... ----
BT2-EDF 
BT2 
TCDS-ED! 
TCDS 
is used as a heuristic for both algorithms. Under these conditions, similar scheduling costs 
are incurred by both TCDS-EDF and BT2-EDF. 
From the results of these experiments, we conclude that TCDS outperforms B T2 in terms 
of deadline compliance, for a wide range of parameter values, while incurring smaller 
scheduling costs. Adding the EDF heuristic improves BT2-EDF more significantly than 
TCDS-EDF. TCDS-EDF maintains its improved performance over BT2-EDF in terms of 
deadline compliance. TCDS-EDF maintains its improved performance over BT2-EDF in 
terms of scheduling costs for most parameter settings. When arrival rates are low and the 
degree of laxity is high (i.e. when scheduling becomes an easier task), however, BT2-EDF 
incurs smaller scheduling costs than TCDS-EDF. 
4.7. 
Effect of Scheduling During Idle Intervals 
In this experiment, we compared the performance of TCDS-I and TCDS. The criteria that 
these algorithms used to allocate scheduling time were SC4 and SC3, respectively. This 
experiment was intended to reveal the performance implications of relaxing the feasibility 
test from checking the tasks' readiness, while allowing the scheduling process to take place 
during idle-time intervals. 
Figures 22 through 29 show the results of this experiment. Figures 22 and 23 show the hit 
ratio as the arrival rate varies for SF values 4 and 8, respectively. When the degree of laxity 
is small, Figure 22 shows that under low arrival rates TCDS-I's schedule quality is lower 
than TCDS's. This is attributed to the fact that small laxity leads to small idle intervals 
which result in short scheduling phases. Furthermore, under low arrival rates, TCDS's 
criterion for allocating scheduling time (i.e. SC3) affords the algorithm the lUXUry of longer 
scheduling phases which can result in better schedules. Figure 23, shows the results of the 
comparison when SF is large. In this figure, the task laxities lead to longer idle-time gaps 
resulting in favorable performance for TCDS-I. 
180 

TO SCHEDULE OR TO EXECUTE 
• 
I 
I , 
I , 
4 
I 
I 
I 
I 
I , • 
, 
I 
I 
I , • 
, 
, 
I • 
, 
( ) 
.. --_.' 
() 
2 
(> 
8 
Laxity 
Figure 22. Scheduling effort for different laxities (J.. = 0.1). 
Hxto4 
1:: 
@ '" 
~ 6xlli 
on 
.5 :g 4xl04 
l! 
u 
CIl 
2xHt' 
) 
( o .... ~ 
I 
I a 
,'. 
" , 
.~~ , 
, 
, 
.. -.,-, .. --
4 
6 
Laxity 
Figure 23. Scheduling effort for different laxities (J.. = 0.5). 
.II. a. 
10 
a 
I 
I 
I 
I 
I 
I 
I 
I 
I 
I • 
I 
I 
I 
, , , 
10 
307 
--e·· BT2-EDF 
--... BT2 
-
TCDS-EDF 
-
TCDS 
I 
I 
I 
·-e·· BT2-EDF 
-·a-· BT2 
-
TCDS-t.1JF 
-
TCDS 
Figures 24 and 25 show the results as the degree of laxity varies for arrival rates 0.1 
and 0.5, respectively. Figure 24 clearly shows the effect of laxity on quality of schedules 
resulting from TCDS-I. For smaller degrees of laxity TCDS dominates performance due to 
TCDS-I's small idle-time gaps. We notice, however, that TCDS-I outperforms TCDS for 
higher degrees of laxity, as the looseness in the deadlines create longer scheduling gaps for 
TCDS-I. Figure 25 shows the results of the comparison when the arrival rate is high. The 
two algorithms perform similarly as the effect of idle-times is neutralized by the increase 
in the arrival rate. 
Figures 26 through 29 compare the scheduling effort of TCDS and TCDS-I under dif-
ferent parameter settings. The significant result in these figures is that TCDS-I incurs 
181 

308 
HAMIDZADEH, ATIF AND RAMAMRITHAM 
0 
.~ 
\ 
i 
40 
\ • '. 
20 
0 
0.0 
0.2 
0.4 
Rate uf Arrival 
Figure 24. Deadline compliance for different arrival rates (SF = 4). 
0 
.~ so 
i 
70 
tiO 
0.0 
--.. 
(1.2 
, , , , 
Rate of Arrival 
0.4 
Figure 25. Deadline compliance for different arrival rates (SF = 8). 
- -.- - rCDS-! 
_ 
rCDS 
- -e- - rCDS-j 
_ 
TCDS 
smaller scheduling costs than TCDS, in general. The figures show that TCDS-I's schedul-
ing effort increases with arrival rate. This can be attributed to the fact that as more tasks 
arrive, it takes longer to schedule those tasks. So, if the criterion for allocating scheduling 
time allows it, scheduling will consume a large amount of time. The figures also show 
that scheduling time of TCDS-I increases with laxity as expected. For large-enough de-
grees of laxity, however, the scheduling time is expected to decrease as shown in previous 
experiments. 
The difference-of-means tests do not show significant differences between TCDS and 
TCDS-I. Overall, however, the results show that if laxity is large, TCDS-I is preferable. 
182 

TO SCHEDULE OR TO EXECUTE 
309 
I(Xl 
HO 
liO 
0 
.~ 
:E 
40 
, 
I 
I , • 
20 
, 
, ,. 
0 
0 
4 
10 
Laxity 
Figure 26. Deadline compliance for different laxities (A = 0.1). 
- - e-- rCDS-1 
HO 
-
rCDS 
60 
.S e 40 
£ 
20 
0 
0 
4 
6 
10 
Laxity 
Figure 27. Deadline compliance for different laxities (A = 0.5). 
Also, as we have noticed in the figures, TCDS-I outperfonns TCDS in tenns of minimizing 
the scheduling effort in many parameter settings. 
5. Conclusion 
In this paper, we have proposed a set of dynamic scheduling algorithms, called Time-
Controlled Dynamic Scheduling (TCDS), that are aimed at scheduling a set of aperiodic, 
semi-hard deadlines. Semi-hard deadlines were defined to be a class of real-time tasks in 
183 

310 
HAMIDZADEH, ATIF AND RAMAMRITHAM 
2Stxl,--------------, r--------, 
2(XX) 
1:: @ 
~ 15(X) 
.~ 
:; 
~ HXX) 
V} 
SIX) 
IJ 
-
-
n.D 
0.2 
0.4 
Rate of Arrival 
, , , , 
• 
, 
- -0- - TCDS-I 
_ 
TCDS 
Figure 28. Scheduling effort for different arrival rates (SF = 4). 
X(XX)c--------------, r-------, 
TCDS-/I 
TCDS 
1:: 
.E iii 
6!XX) 
.~ 4(XX) 
:; 
"'" 
..8 
u 
V} 
0----0' 
, , , , 
, 
0.2 
0.4 
Rate of AITival 
Figure 29. Scheduling effort for different arrival rates (SF = 8). 
- -0---
which not executing a task has lower penalty than executing the task and missing its dead-
line. TCDS was designed to address a fundamental contradiction in dynamic scheduling, 
namely the trade-off between the time allocated to scheduling and the quality of the re-
sulting schedules. TCDS controls and allocates scheduling times to produce high deadline 
compliance ratios in the available time. If it is determined that ample time is available, 
TCDS continues to produce higher-quality schedules to meet deadlines of a larger number 
of tasks. If little time is available, on the other hand, TCDS uses the time available to pro-
duce good-quality schedules. TCDS automatically adjusts the amount of time allocated to 
scheduling in different scheduling phases. It uses different criteria for stopping scheduling 
phases based on different problem characteristics such as idle-time intervals, slack, arrival 
184 

TO SCHEDULE OR TO EXECUTE 
HO()() 
6()(X) 
t: 
~ 
Ul 
OIl 
.5 4()()() 
"3 
"1:1 l! 
u 
CI'J 
2()()() 
0 
0 
4 
6 
Laxity 
Figure 30. Scheduling effort for different laxities (A = 0.1). 
HK)OO 
80m 
t: 
~ 6000 
III 
bIl 
.5 
"3 
4(XX) 
"1:1 ., 
.c 
C.) 
CI'J 
2(KKI 
0 
() 
2 
4 
6 
Laxity 
Figure 3/. Scheduling effort for different laxities (A = 0.5). 
10 
- -. - - rcDS-/ 
_ 
rCDS 
311 
rate or combination thereof. By allowing execution of partial (as well as complete) feasi-
ble schedules, TCDS makes a trade-off between scheduling time and schedule quality. It 
defers scheduling of some tasks for the sake of controlling scheduling times, guaranteeing 
the deadlines of already scheduled tasks, and considering newly arrived tasks. 
We evaluated TCDS by comparing its performance with simple algorithms such as EDF 
and with a limited- backtracking algorithm in a number of experiments. The results of 
the experiments show that TCDS outperforms EDF and the limited-backtracking algorithm 
in terms of maximizing the percentage of tasks that meet their deadlines and in terms of 
minimizing scheduling costs. The results also show that adding heuristics, such as Earliest-
185 

312 
HAMIDZADEH, ATIF AND RAMAMRITHAM 
Deadline-First, improve the algorithms' performance. Results of experiments on evaluating 
the effect of scheduling during idle-time intervals reveal that this strategy is effective when 
the lengths of these intervals are large enough. Scheduling during idle times was shown to 
produce high deadline compliance while maintaining low scheduling costs. From the results 
of our experiments, we conclude that effective criteria can be designed to adapt the duration 
of scheduling phases automatically, in order to obtain high deadline compliance while 
incurring reasonably low scheduling costs. As part of our future work, we plan to investigate 
the applicability and extensions of our techniques in a multiprocessor architecture. 
Appendix: Pseudo-code for TCDS Algorithms 
PROCEDURE TCDS (start:node); 
VAR 
queue,succlist: queue-of-nodes; 
x,currenLnode,new _start: node; 
BEGIN 
queue := start; 
WHILE {NOT [leaf(head(queue»] AND [timelefuo_schedule] AND NOT [empty 
(queue)]} DO 
BEGIN 
currenLnode := head(queue); 
delete( currenLnode,queue); 
succJist := successors(currenLnode); 
FOR each x IN succlist DO 
IF feasible(x) THEN insert(x,queue); 
sort (queue); 1* If there exists a heuristic *1 
END 
IF leaf(head(queue» THEN 1* a complete feasible schedule is found *1 
return (schedule(head (queue»); 1* the schedule is delivered for execution *1 
ELSE 
IF NOT [timelefuo-schedule] THEN 1* the criterion for terminating the scheduling 
phase is met *1 
return (schedule(head (queue»); 1* the partial schedule is delivered for execution *1 
ELSE 1* a complete feasible schedule does not exist *1 
return (scheduleJepresented_by(currenLnode»; 1* the partial schedule is delivered 
for execution *1 
allocate_scheduling_time_oLnexLphase; 
currenuask_set := remaining_task_set U arrived_task_set; 
new _start := createJlode( currenUask_set); 
TeDS (new_start) 
END. 
186 

TO SCHEDULE OR TO EXECUTE 
313 
Notes 
I. Slack is defined as the maximum time by which the execution of a task can be delayed without violating that 
task's deadline. 
2. The terms "laxity" and SF are used interchangeably in this section. 
References 
Bratley, P, Florian, M., and Robillard, P. 1971. Scheduling with earliest start and due datc constraints. Naval 
Research Logistics Quarterly 18: 511-517. 
Bums, A. 1991. Scheduling hard real-time systems: A review. Software Engineering Journal 6(3): 116-28. 
Hamidzadeh, B., Shekhar, S., and Gopinath, P. 1993. A general search framework for dynamic scheduling of 
real-time tasks. IEEE Real-Time Operating Systems and Software Workshop. 
Hamidzadch, B., andShekhar, S. 1993. Specification and analysis of real-time problem solvers. IEEE Transactions 
on Software Engineering 19(8). 
Hong, K. S., and Leung, J. Y-T. 1988. On-line scheduling of real-time tasks. Proc. of the 9th IEEE Real-Time 
Systems Symposium, pp. 244-250, 
Howell, R R, and Venkatrao, M. K. 1995. On non-preemptive scheduling of recurring tasks using inserted idle 
times. Information and Computation 117(1): 50-62. 
Lenstra, 1. K., Rinnooy, A. H. G., and Bruchker, P. 1977. Complexity of machine scheduling problems. In Annals 
of Discrete Mathematics, vol. I. North Holland. 
Mok, A. K. 1983. Fundamental design problems of distributed systems for hard real-time environments. Ph.D. 
Thesis, Laboratory for Computer Science, MIT IMIT ILCS. TR-297. 
Ramamritham, K., and Stankovic, J. A. 1984. Dynamic task scheduling in hard real-time distributed systems. 
IEEE Software, 65-75. 
Ramamritham, K., Stankovic, J. A, and Shiah, P. 1990. Efficient scheduling algorithms for real-time multipro-
cessor systems. IEEE Transactions on Parallel and Distributed Systems 1(2): 184-194. 
Schwan, K., and Zhou, H. 1992. Dynamic scheduling of hard real-time tasks and real-time threads. IEEE 
Transactions on Software Engineering. 
Sha, L., Goodenough, J. 8., and Ralya, T. 1988. An analytical approach to real-time software engineering. 
Software Engineering Institute Draft Report. 
Shen, C, Ramamritham, K., and Stankovic, J. A. 1993. Resource reclaiming in mUltiprocessor real-time systems. 
IEEE Transactions on Parallel and Distributed Systems 4(4). 
Sprunt, B., Sha, L., and Lehoczky, J. 1989. Aperiodic task scheduling for hard real-time systems. Journal of 
Real-Time Systems I: 27-60. 
Sprunt, 8., Lehoczky, 1., and Sha, L. 1988. Exploiting unused periodic time for aperiodic service using the 
extended priority exchange algorithms. Proc. of Real-Time Systems Symposium. 
Stankovic, J. A, and Ramamritham, K. 1987. The design of the spring kernel. Proc. of the IEEE Real-Time 
Systems Symposium, pp. 146-157. 
Stankovic, J. A., Spuri, M., Natale, M. D., and ButtazZQ, G. C 1995. Implications of classical scheduling results 
for real-time systems. IEEE Computer 16-25. 
Xu, J., and Parnas, D. L. 1993. On satisfying timing constraints in hard-real-time systems. IEEE Transactions on 
Software Engineering 19(1): 70-84. 
Yuan-Geng Huang, H., Kanal, L. N., and Tripathi, S. K. 1989. Scheduling N jobs on one machine with insert-idle-
time. Proc. of the Second International Conference on Industrial and Engineering Applications of Artificial 
Intelligence and Expert Systems. lEAl AlE-89. 
Zhao, W, and Ramamritham, K. 1987. Simple and integrated heuristic algorithms for scheduling tasks with time 
and resource constraints. Journal of Systems and Software. 
Zhao, w., Ramamritham, K., and Stankovic, J. A 1987a. Preemptive scheduling under time and resource 
constraints. IEEE Transactions on Computers. 
Zhao, W., Ramamritham, K., and Stankovic, J. A. 1987b. Scheduling tasks with resource requirements in hard 
real-time systems. IEEE Transactions on Software Engineering SE-12(5). 
187 

•
~£. The International Journal of Time-Critical Computing Systems, 16, 315-323 (1999) 
~' © 1999 Kluwer Academic Publishers, Boston. Manufactured in The Netherlands. 
Contributing Authors 
T. Abdelzaher received his B.Sc. and M.Sc. degrees in Electrical and Computer Engineering 
from Ain Shams University, Cairo, Egypt, in 1990 and 1994 respectively. Since 1994 he has 
been a Ph.D. student of Professor Kang G. Shin, in the Department of Electrical Engineering 
and Computer Science, at the University of Michigan, Ann Arbor, Michigan. His research 
interests are in the field of QoS-provisioning and real-time computing. 
Tarek Abdelzaher has been an assistant lecturer at Ain Shams University, Cairo, during 
1990-1994. He served as a research assistant for the Egyptian Academy of Scientific 
Research and Technology, Cairo, Egypt from 1991 to 1993. Since 1994 he has been a 
research assistant at the Department of Electrical Engineering and Computer Science, The 
University of Michigan, Ann Arbor, Michigan. His e-mail addressiszaher@eecs.umich.edu 
Yacine Atif received his BSc in Computer Science in 
1992 from the University of Science & Technology 
(Algeria), and an advanced degree in Computer Sci-
ence in 1993 from INRIA (France). He obtained his 
Ph.D. degree in 1996 from the department of computer 
science of the University of Science & Technology 
(Hong Kong). From 1993 to 1994, Dr. Atifwas an in-
structor at the High Industrial Studies Center (France). 
From 1996 to 1997, he was a visiting researcher at 
Purdue University in Indianapolis (USA). Since 1997, 
Dr. Atif is an Assistant-Professor at the school of elec-
trical and electronic engineering of Nanyang Techno-
logical University (Singapore). Dr. Atif published in 
international journals and conferences. His main re-
search areas include Real-Time Systems, Parallel and 
Distributed Processing, Multimedia Presentation and 
Communication, and Electronic Commerce. 
189 

316 
Feng Cao received the Ph.D. degree in computer sci-
ence from the University of Minnesota in 1997, the 
M.S. degree in 1992 and B.S. degree in 1990 in ap-
plied mathematics from Tsinghua University, China. 
He worked as a computer scientist in NIT Multime-
dia Communications Laboratories in 1997 and Honey-
well Technology Center in 1996. He has been work-
ing on voice over IP in Cisco Systems, Inc. from 1998. 
His research interests include multimedia communica-
tions, distributed computing and high-speed network 
design. He has over 20 publications in those areas. 
Lisa Cingiser DiPippo received the BS degree in 
Computer Science from Lafayette College in Easton, 
PA, in 1987. She received the MS degree in Computer 
Science from the University of Rhode Island in 1991, 
and her PhD in Applied Mathematics also from the 
University of Rhode Island in 1995. She is currently an 
Adjunct Assistant Professor at the University of Rhode 
Island, where she has been since May 1995. Her re-
search interests include real-time distributed objects, 
real-time and ohject-oriented databases, real-time se-
mantic concurrency control, distributed virtual envi-
ronments, and real-time object modeling. received the 
BS degree in Computer Science from Lafayette Col-
lege in Easton, PA, in 1987. She received the MS 
degree in Computer Science from the University of 
Rhode Island in 1991, and her PhD in Applied Math-
ematics also from the University of Rhode Island in 
1995. She is currently an Adjunct Assistant Professor 
at the University of Rhode Island, where she has been 
since May 1995. Her research interests include real-
time distributed objects, real-time and ohject-oriented 
databases, real-time semantic concurrency control, 
distributed virtual environments, and real-time object 
modeling. 
w.-c. Feng received a BS degree in computer engineering from Penn State University in 
1992 and an MSE degree in computer science engineering from the University of Michigan 
in 1994. He is currently a PhD candidate in computer science engineering at the University 
of Michigan. His research interests include networking, differential services, congestion 
control, and network performance evaluation. 
190 

317 
Roman Ginis received a BS degree in Computer Science from University of Rhode Island 
in 1996. He has worked as a Database Systems Engineer at MITRE Corporation from 1996-
1997. He is a Ph.D. student in Computer Science at the California Institute of Technology, 
Pasadena, Ca. His research interests are in distributed object systems, real-time middleware, 
formal methods, real-time scheduling and quality of service. 
Babak Hamidzadeh received his M.S. and Ph.D. de-
grees in Computer Science from the University of Min-
nesota in 1989 and 1993, respectively. In that period, 
he also worked as a research associate at The Systems 
and Research Center of Honeywell Inc., and as a re-
search scientist at The Research and Technology Cen-
ter of AIliant Techsystems Inc. for over 3 years. From 
1993 to 1996 he was an Assistant Professor of Com-
puter Science and Computer Engineering at The Hong 
Kong University of Science and Technology. Cur-
rently, he is an Assistant Professor of Electrical and 
Computer Engineering at The University of British 
Columbia. He is also a member of IEEE Computer 
Society. His areas of research include real-time com-
puting, parallel and distributed processing, multime-
dia, and communication networks. 
Dr. Jiandong Huang is a senior principal research sci-
entist at Honeywell Technology Center. His research 
work d~als with QoS-based adaptive resource man-
agement, real-time and fault-tolerant communication 
networks, heterogeneous data management, and mod-
eling and performance evaluation. Currently, he leads 
development of a network product for a new genera-
tion of process control systems. Dr. Huang is also an 
adjunct faculty of the Computer Science Department 
of the University of Minnesota and an adjunct faculty 
of the Graduate Program in Software of the Univer-
sity of St. Thomas, teaching operating systems and 
distributed database management courses. Dr. Huang 
received his Ph.D. degree in Computer Engineering 
from the University of Massachusetts, Amherst, in 
1991. He is a member of Tau Beta Pi, IEEE Computer 
Society, and the Association of Computing Machin-
ery. 
191 

318 
M. Humphrey received a Ph.D. in Computer Sci-
ence from the University of Massachusetts in 1996. 
From 1996 until 1998, he was an Assistant Professor 
in the Department of Computer Science and Engineer-
ing at the University of Colorado in Denver. Currently, 
he is a Research Assistant Professor in the Depart-
ment of Computer Science at the University of Vir-
ginia. His research interests include real-time oper-
ating systems, real-time scheduling, distributed com-
puting, and meta-computing. 
F. Jahanian received the M.S. and Ph.D. degrees in Computer Science from the University 
of Texas at Austin in 1987 and 1989, respectively. He is currently an Associate Professor 
of Electrical Engineering and Computer Science at the University of Michigan. Prior 
to joining the faculty at the University of Michigan in 1993, he had been a Research Staff 
Member at the IBM T.J. Watson Research Center where he led several experimental projects 
in distributed and fault-tolerant systems. His current research interests include real-time 
systems, distributed fault-tolerant computing, and network protocols and architectures. 
Scott Johnson received his BSEE from Duke University in 1994, and an MSE from the 
University of Michigan in 1997. He is currently a PhD candidate in Computer Science and 
Engineering at the University of Michigan, where he works as a research assistant in the 
Real-Time Computing Laboratory. 
His research interests include fault-tolerant distributed systems, group communication, 
and scalability of distributed systems. He is a member of IEEE, Tau Beta Pi, and Eta 
KappaNu. 
192 
Russell Johnston is Principal Investigator for the Dis-
tributed Hybrid Database Architecture Project for the 
Office of Naval Research. He initiated the integration 
of the real-time operating systems, database develop-
ment, networks and protocols in order to provide a 
seamless infrastructure which is being transitioned to 
Joint Service programs. Mr. Johnston was the lead 
in the development for the Joint Directors of Labo-
ratories Tri-Service Distributed Technology Experi-
ment from its conception. In addition, Mr. John-
ston has served on the JDL Tri-Service Panel for C3, 
Distributed Processing Subpanel providing technical 
guidance in developing the Joint Service Distributed 
Technology program. 

319 
A. Mehra received the B.Tech. (Bachelor of Technology) degree in Electrical Engineering 
from the Indian Institute of Technology at Kanpur, India, in 1989, and the M.S.E. and Ph.D. 
degrees in Computer Science and Engineering from the University of Michigan, in 1992 and 
1997, respectively. He is currently a Research Staff Member in the Server and Enterprise 
Networking group at the IBM Thomas 1. Watson Research Center. His primary research 
interests are in operating system and networking support for application quality of service 
requirements, Internet-based network computing, code mobility and security, high-speed 
networking, and performance evaluation. His e-mail addressismehraa@watson.ibm.com. 
D. Niehaus is an Assistant Professor in the EECS 
Department at the University of Kansas since 1993. 
Dr. Niehaus' interests include real-time and distributed 
systems, operating systems, ATM networks, per-
formance measurement, and programming environ-
ments. Current projects include ATM network per-
formance evaluation and characterization, high per-
formance distributed systems using ATM networks, 
real-time ORB implementation and performance eval-
uation, and advanced debugging tools. Dr. Niehaus 
received his Ph.D. in Computer Science from UMass-
Amherst ('87-'93) where his thesis addressed the de-
sign, and implementation of real-time systems. He was a senior software engineer porting 
UNIX to new platforms at Convergent Technologies in 1986 and 1987, and a Member of the 
Technical Staff doing system, network, and development environment tool programming 
at Bell Laboratories and AT&T Information Systems from 1981 to 1986. He received his 
M.S. in Computer, Information, and Control Engineering from the University of Michigan 
in 1981 and his B.S. in Computer Science from Northwestern University in 1980. 
Krithi Ramamritham received the Ph.D. in Com-
puter Science from the University of Utah. Currently 
he is a Visiting Professor at the Indian Institute of 
Technology, Mumbai, on leave from the University of 
Massachusetts, Amherst. He was a Science and En-
gineering Research Council (U.K.) visiting fellow at 
the University of Newcastle upon Tyne, U.K., and has 
held visiting positions at the Technical University of 
Vienna, Austria and at the Indian Institutes of Tech-
nology. 
Ramamritham's interests span the areas of database 
systems and real-time systems. In the real-time arena, 
he has contributed to the development of scheduling algorithms, specification and program-
ming languages, operating system support, architectural support, and design strategies for 
distributed real-time applications. In the database arena, he has been interested in support-
ing novel, advanced applications that expand the limits of traditional databases, especially 
193 

320 
transaction systems. Specifically, his work aims to enhance performance and functionality 
of applications, such as workflows and information retrieval, that require or can benefit 
from transactional support. He has also made significant contributions towards advances 
in real-time database systems. 
Prof. Ramamritham is a Fellow of the IEEE. He served as Program Chair for the 
Real-Time Systems Symposium in 1994 and as General Chair in 1995. Also, he was a 
vice-chair for the Conference on Data Engineering in 1995. He has served on numerous 
program committees of conferences and workshops devoted to databases as well as real-
time systems. He serves on the editorial board of many journals, including the IEEE 
Transactions on Parallel and Distributed Systems and the Real-Time Systems Journal. He 
has co-authored two IEEE tutorial texts real-time systems, a text on advances in database 
transaction processing, and a forthcoming text on scheduling in real-time systems. 
A. Shaikh received the B.S.E.E. and M.S.E.E. degrees from the University of Virginia, 
Charlottesville, both in 1994. He is currently a Ph.D. candidate in Computer Science and 
Engineering at the University of Michigan, Ann Arbor and works as a research assistant in 
the University'S Real-Time Computing Laboratory. 
His research interests include dynamic routing in integrated services networks, multicast 
communication, and real-time distributed systems. He is a member of the IEEE, ACM, Tau 
Beta Pi, and Eta Kappa Nu. 
K. Shin is Professor and Director of the Real-Time Computing Laboratory, Department 
of Electrical Engineering and Computer Science, The University of Michigan, Ann Arbor, 
Michigan. 
He has authored/coauthored about 600 technical papers and numerous book chapters in 
the areas of distributed real-time computing and control, computer networking, fault-tolerant 
computing, and intelligent manufacturing. He has co-authored (jointly with C. M. Krishna) 
a textbook "Real-Time Systems," McGraw Hill, 1997. In 1987, he received the Outstanding 
IEEE Transactions on Automatic Control Paper Award, and in 1989, Research Excellence 
Award from The University of Michigan. In 1985, he founded the Real-Time Computing 
Laboratory, where he and his colleagues are investigating various issues related to real-time 
and fault-tolerant computing. 
His current research focuses on Quality of Service (QoS) sensitive computing and net-
working with emphases on timeliness and dependability. He has also been applying the 
basic research results to telecommunication and multimedia systems, intelligent transporta-
tion systems, embedded systems, and manufacturing applications. 
He received the B.S. degree in Electronics Engineering from Seoul National University, 
Seoul, Korea in 1970, and both the M.S. and Ph.D degrees in Electrical Engineering from 
Cornell University, Ithaca, New York in 1976 and 1978, respectively. From 1978 to 1982 
he was on the faculty of Rensselaer Polytechnic Institute, Troy, New York. He has held 
visiting positions at the U.S. Airforce Flight Dynamics Laboratory, AT&T Bell Labora-
tories, Computer Science Division within the Department of Electrical Engineering and 
Computer Science at UC Berkeley, and International Computer Science Institute, Berke-
ley, CA, IBM T.J. Watson Research Center, and Software Engineering Institute at Carnegie 
194 

321 
Mellon University. He also chaired the Computer Science and Engineering Division, EECS 
Department, The University of Michigan for three years beginning January 1991. 
He is an IEEE fellow, was the Program Chairman of the 1986 IEEE Real-Time Systems 
Symposium (RTSS), the General Chairman of the 1987 RTSS, the Guest Editor of the 1987 
August special issue of IEEE Transactions on Computers on Real-Time Systems, a Program 
Co-Chair for the 1992 International Conference on Parallel Processing, and served numer-
ous technical program committees. He also chaired the IEEE Technical Committee on 
Real-Time Systems during 1991-93, was a Distinguished Visitor of the Computer Society 
of the IEEE, an Editor of IEEE Trans. on Parallel and Distributed Computing, and an Area 
Editor of International Journal of Time-Critical Computing Systems. 
Michael A. Squadrito received the BS degree in Elec-
trical Engineering and the MS degree in Computer 
Science from the University of Rhode Island in 1984 
and 1996 respectively. He worked as an Electrical 
Engineer for General Dynamics from 1984-1992. He 
worked for the MITRE Corporation as a Technical 
Staff member from 1995-1996, and then worked for 
Real-Time Research as a Research Assistant from 
1996-1998. He is currently the Lead Programmer 
at Tantalus Games, Inc. His research interests are 
in real-time distributed objects, real-time middleware, 
and real-time databases. 
J. A. Stankovic is the BP America Professor and Chair 
of the Computer Science Department at the University 
of Virginia. He is a Fellow of the IEEE and a Fellow 
of the ACM. He is also a IEEE Golden Core Mem-
ber. Professor Stankovic also serves on the Board of 
Directors of the Computer Research Association. He 
has held visiting positions in the Computer Science 
Department at Carnegie-Mellon University, at INRIA 
in France, and Scuola Superiore S. Anna in Pisa, Italy. 
He has served as the Chair of the IEEE Technical 
Committee on Real-Time Systems. Prof. Stankovic 
has also served as an IEEE Computer Society Distin-
guished Visitor, has given Distinguished Lectures at 
various Universities, and has been a Keynote Speaker 
at various conferences. He is E-I-C for IEEE Trans-
actions on Parallel and Distributed Systems. His re-
search interests are in distributed computing, real-time 
systems, operating systems, distributed multimedia 
database systems, and global virtual computing. 
195 

322 
G. Wallace received his BS degree in Computer Sci-
ence from the University of Massachusetts in 1976 
and his MS degree in Computer Science from Col-
orado State University in 1979. He has done computer 
systems development for companies including Com-
mercial Union, Monfort of Colorado, and Diversified 
Software, and has consulted for Data Views Corpo-
ration, Sovereign Hill, and Applied Computing Sys-
tems Institute of Massachusetts. He has also done 
computer research for the CSU Psychology and Com-
puter Science Departments. He has been employed 
by the Umass Computer Science Department since 
1982, working in systems administration, and doing 
research in networking, real-time operating systems, 
and currently multimedia information systems. 
Yuewei Wang received the B.E. degree in Computer 
Science and Engineering from Tsinghua University, 
China in 1990, the M.S. degree in Computer Science 
from the Pennsylvania State University in 1992, and 
the Ph.D. degree in Computer Science from Univer-
sity of Minnesota in 1997. From 1995 to 1997, he 
worked in Honeywell Technical Center in develop-
ing a prototype for distributed resource management 
for continuous media. Since 1997, he has been with 
3CX where he is a Technical Lead in the research 
and development of networked streaming media solu-
tions for distance learning and security surveillance. 
His main areas of interests are distributed multime-
dia, high-performance serial storage systems, visual 
programming systems, and high-speed networks. 
Steven Wohlever received his BA degree in Computer 
Science from Western Connecticut State University in 
1995, and his MS degree in Computer Science from 
the University of Rhode Island in 1997. His research 
interests include object-oriented design and program-
ming, real-time computing, and real-time distributed 
objects and middleware. He is currently a member of 
the senior technical staff at the MITRE Corporation in 
Bedford, Massachusetts. 
196 

323 
Victor Fay-Wolfe received the BS degree in Electrical 
Engineering from Tufts University in Medford, Mass. 
in 1983, and the MSE and PhD degrees in Computer 
and Information Science from the University of Penn-
sylvania in 1985 and 1991 respectively. He worked as 
a Computational Design Engineer for General Elec-
tric from 1983-1986. He is an Associate Professor 
of Computer Science at the University of Rhode Is-
land, where he has been since 1991. His research 
interests are in real-time distributed objects, real-time 
middleware, real-time databases, and real-time object 
modeling. He has been an active participant and stan-
dards author in the real-time POSIX, real-time SQL, 
and real-time CORBA groups. 
H. Zou received his BSCS from Huazhong University of Science and Technology, China 
in 1985, and a MSCS from the Institute of Computing Technology, Chinese Academy of 
Sciences in 1988. He is currently a PhD candidate in Computer Science and Engineering 
at the University of Michigan at Ann Arbor, where he works as a research assistant in the 
Real-time Computing Laboratory. Prior to join the University of Michigan in 1996, he 
has worked in Huazhong U. of Sci. and Tech., IBM, NDC/CIS Technologies, and Lucent 
Technologies. 
His research interests include fault-tolerant distributed systems, real-time computing, 
software engineering, algorithms, and networkings. He is a member of Tau Beta Pi. 
Igor Zykh received the BS degree in Applied Math-
ematics from Kabardino-Balkarian State University, 
Nalchik, Russia in 1994, and the MS degree in Com-
puter Science from the University of Rhode Island in 
1997. He has worked as a Programmer/Analyst in the 
Computing Systems Architecture group for Bell At-
lantic Inc. He is currently a Systems Engineer in the 
Infrastructure group of the Online Services division 
at the Vanguard Group. His interests are in real-time, 
distributed object-oriented computing environments, 
real-time, message based middleware, real-time, and 
object-oriented databases. He has been a participant 
of real-time CORBA groups. 
197 

